{
  "metadata": {
    "timestamp": 1736557776071,
    "page": 948,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "terryum/awesome-deep-learning-papers",
      "stars": 25615,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.01,
          "content": "papers/\n"
        },
        {
          "name": "Contributing.md",
          "type": "blob",
          "size": 2.53,
          "content": "# Contributing Guide\n\nYou can directly edit(add/delete/modify) the [README.md](https://github.com/terryum/awesome-deep-learning-papers/blob/master/README.md) file for contribution. If you don't know how to edit the file, please leave a message to the [Issue board](https://github.com/terryum/awesome-deep-learning-papers/issues).\n\n## Awesome list criteria\n\n- **2016** :    +20 citations (:sparkles: +50)\n- **2015** :  +100 citations (:sparkles: +200)\n- **2014** :  +200 citations (:sparkles: +400)\n- **2013** :  +300 citations (:sparkles: +600)\n- **2012** :  +400 citations (:sparkles: +800)\n- **2011** :  +500 citations (:sparkles: +1000)\n- **2010** :  +600 citations (:sparkles: +1200)\n\nThis criteria is not a strict baseline, but a **flexible guideline** for being added to the awesome list. (Since the number of citations is affected by the research area, some papers under the threshold may be added to the list while some over the threshold may not.) If you add papers which are under the above criteria, please provide **enough descriptions** which the papers should be added.\n\n## Edit the awesome list\nYou can **add / delete / modify** the papers on the awesome list.\n\n#### Addition\nAs mentioned above, please provide **enough descriptions** when you push a request, especially for the papers which do not meet the criteria or for the papers for the *Papers Worth Reading* section.\n\nHere is an example of markdown code for a paper on the list.\n\n`Distilling the knowledge in a neural network (2015), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1503.02531)`\n\nThe pdf link which can directly download the pdf file rather than links to another webpage is preferred. If the number of authors are more than two, please write the first author's name only.\n\n#### Deletion\nIf a paper seems to be out-of-date or be a duplication of another paper, you can suggest deletion. Deletion is also an important contribution to maintain a tractable number of papers on the awesome list.\n\n#### Modification\nModification (or Updates) that can usually happen is\n- addition of :sparkles: marks (as increasing number of citations)\n- addition of distinguished researchers\n- move papers from a section from another\n- correction of typo, grammatical error, etc.\n\nNote that you are *not* allowed to add or modify the sections.\n\n## Acknowledgement\n\nThank you for all your contributions. You can also follow my [facebook page](https://www.facebook.com/terryum.io/) or [google plus](https://plus.google.com/+TerryTaeWoongUm/) to get useful information about machine learning and robotics. Thank you!\n\nTerry\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 43.79,
          "content": "# Awesome - Most Cited Deep Learning Papers\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)\n\n[Notice] This list is not being maintained anymore because of the overwhelming amount of deep learning papers published every day since 2017.\n\nA curated list of the most cited deep learning papers (2012-2016)\n\nWe believe that there exist *classic* deep learning papers which are worth reading regardless of their application domain. Rather than providing overwhelming amount of papers, We would like to provide a *curated list* of the awesome deep learning papers which are considered as *must-reads* in certain research domains.\n\n## Background\n\nBefore this list, there exist other *awesome deep learning lists*, for example, [Deep Vision](https://github.com/kjw0612/awesome-deep-vision) and [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn). Also, after this list comes out, another awesome list for deep learning beginners, called [Deep Learning Papers Reading Roadmap](https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap), has been created and loved by many deep learning researchers.\n\nAlthough the *Roadmap List* includes lots of important deep learning papers, it feels overwhelming for me to read them all. As I mentioned in the introduction, I believe that seminal works can give us lessons regardless of their application domain. Thus, I would like to introduce **top 100 deep learning papers** here as a good starting point of overviewing deep learning researches.\n\nTo get the news for newly released papers everyday, follow my [twitter](https://twitter.com/TerryUm_ML) or [facebook page](https://www.facebook.com/terryum.io/)! \n\n## Awesome list criteria\n\n1. A list of **top 100 deep learning papers** published from 2012 to 2016 is suggested.\n2. If a paper is added to the list, another paper (usually from *More Papers from 2016\" section) should be removed to keep top 100 papers. (Thus, removing papers is also important contributions as well as adding papers)\n3. Papers that are important, but failed to be included in the list, will be listed in *More than Top 100* section.\n4. Please refer to *New Papers* and *Old Papers* sections for the papers published in recent 6 months or before 2012.\n\n*(Citation criteria)*\n- **< 6 months** : *New Papers* (by discussion)\n- **2016** :  +60 citations or \"More Papers from 2016\"\n- **2015** :  +200 citations\n- **2014** :  +400 citations\n- **2013** :  +600 citations\n- **2012** :  +800 citations\n- **~2012** : *Old Papers* (by discussion)\n\nPlease note that we prefer seminal deep learning papers that can be applied to various researches rather than application papers. For that reason, some papers that meet the criteria may not be accepted while others can be. It depends on the impact of the paper, applicability to other researches scarcity of the research domain, and so on.\n\n**We need your contributions!**\n\nIf you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and pull a request.\n(Please read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) for further instructions, though just letting me know the title of papers can also be a big contribution to us.)\n\n(Update) You can download all top-100 papers with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/fetch_papers.py) and collect all authors' names with [this](https://github.com/terryum/awesome-deep-learning-papers/blob/master/get_authors.py). Also, [bib file](https://github.com/terryum/awesome-deep-learning-papers/blob/master/top100papers.bib) for all top-100 papers are available. Thanks, doodhwala, [Sven](https://github.com/sunshinemyson) and [grepinsight](https://github.com/grepinsight)!\n\n+ Can anyone contribute the code for obtaining the statistics of the authors of Top-100 papers?\n\n\n## Contents\n\n* [Understanding / Generalization / Transfer](#understanding--generalization--transfer)\n* [Optimization / Training Techniques](#optimization--training-techniques)\n* [Unsupervised / Generative Models](#unsupervised--generative-models)\n* [Convolutional Network Models](#convolutional-neural-network-models)\n* [Image Segmentation / Object Detection](#image-segmentation--object-detection)\n* [Image / Video / Etc](#image--video--etc)\n* [Natural Language Processing / RNNs](#natural-language-processing--rnns)\n* [Speech / Other Domain](#speech--other-domain)\n* [Reinforcement Learning / Robotics](#reinforcement-learning--robotics)\n* [More Papers from 2016](#more-papers-from-2016)\n\n*(More than Top 100)*\n\n* [New Papers](#new-papers) : Less than 6 months\n* [Old Papers](#old-papers) : Before 2012\n* [HW / SW / Dataset](#hw--sw--dataset) : Technical reports\n* [Book / Survey / Review](#book--survey--review)\n* [Video Lectures / Tutorials / Blogs](#video-lectures--tutorials--blogs)\n* [Appendix: More than Top 100](#appendix-more-than-top-100) : More papers not in the list\n\n* * *\n\n### Understanding / Generalization / Transfer\n- **Distilling the knowledge in a neural network** (2015), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1503.02531)\n- **Deep neural networks are easily fooled: High confidence predictions for unrecognizable images** (2015), A. Nguyen et al. [[pdf]](http://arxiv.org/pdf/1412.1897)\n- **How transferable are features in deep neural networks?** (2014), J. Yosinski et al. [[pdf]](http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf)\n- **CNN features off-the-Shelf: An astounding baseline for recognition** (2014), A. Razavian et al. [[pdf]](http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf)\n- **Learning and transferring mid-Level image representations using convolutional neural networks** (2014), M. Oquab et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)\n- **Visualizing and understanding convolutional networks** (2014), M. Zeiler and R. Fergus [[pdf]](http://arxiv.org/pdf/1311.2901)\n- **Decaf: A deep convolutional activation feature for generic visual recognition** (2014), J. Donahue et al. [[pdf]](http://arxiv.org/pdf/1310.1531)\n\n<!---[Key researchers]  [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Jason Yosinski](https://scholar.google.ca/citations?hl=en&user=gxL1qj8AAAAJ) -->\n\n### Optimization / Training Techniques\n- **Training very deep networks** (2015), R. Srivastava et al. [[pdf]](http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf)\n- **Batch normalization: Accelerating deep network training by reducing internal covariate shift** (2015), S. Loffe and C. Szegedy [[pdf]](http://arxiv.org/pdf/1502.03167)\n- **Delving deep into rectifiers: Surpassing human-level performance on imagenet classification** (2015), K. He et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)\n- **Dropout: A simple way to prevent neural networks from overfitting** (2014), N. Srivastava et al. [[pdf]](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n- **Adam: A method for stochastic optimization** (2014), D. Kingma and J. Ba [[pdf]](http://arxiv.org/pdf/1412.6980)\n- **Improving neural networks by preventing co-adaptation of feature detectors** (2012), G. Hinton et al. [[pdf]](http://arxiv.org/pdf/1207.0580.pdf)\n- **Random search for hyper-parameter optimization** (2012) J. Bergstra and Y. Bengio [[pdf]](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a)\n\n<!---[Key researchers] [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Sergey Ioffe](https://scholar.google.ca/citations?user=S5zOyIkAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Diederik P. Kingma](https://scholar.google.ca/citations?hl=en&user=yyIoQu4AAAAJ)-->\n\n### Unsupervised / Generative Models\n- **Pixel recurrent neural networks** (2016), A. Oord et al. [[pdf]](http://arxiv.org/pdf/1601.06759v2.pdf)\n- **Improved techniques for training GANs** (2016), T. Salimans et al. [[pdf]](http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf)\n- **Unsupervised representation learning with deep convolutional generative adversarial networks** (2015), A. Radford et al. [[pdf]](https://arxiv.org/pdf/1511.06434v2)\n- **DRAW: A recurrent neural network for image generation** (2015), K. Gregor et al. [[pdf]](http://arxiv.org/pdf/1502.04623)\n- **Generative adversarial nets** (2014), I. Goodfellow et al. [[pdf]](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)\n- **Auto-encoding variational Bayes** (2013), D. Kingma and M. Welling [[pdf]](http://arxiv.org/pdf/1312.6114)\n- **Building high-level features using large scale unsupervised learning** (2013), Q. Le et al. [[pdf]](http://arxiv.org/pdf/1112.6209)\n\n<!---[Key researchers] [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Ian Goodfellow](https://scholar.google.ca/citations?user=iYN86KEAAAAJ), [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n### Convolutional Neural Network Models\n- **Rethinking the inception architecture for computer vision** (2016), C. Szegedy et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf)\n- **Inception-v4, inception-resnet and the impact of residual connections on learning** (2016), C. Szegedy et al. [[pdf]](http://arxiv.org/pdf/1602.07261)\n- **Identity Mappings in Deep Residual Networks** (2016), K. He et al. [[pdf]](https://arxiv.org/pdf/1603.05027v2.pdf)\n- **Deep residual learning for image recognition** (2016), K. He et al. [[pdf]](http://arxiv.org/pdf/1512.03385)\n- **Spatial transformer network** (2015), M. Jaderberg et al., [[pdf]](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)\n- **Going deeper with convolutions** (2015), C. Szegedy et al.  [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n- **Very deep convolutional networks for large-scale image recognition** (2014), K. Simonyan and A. Zisserman [[pdf]](http://arxiv.org/pdf/1409.1556)\n- **Return of the devil in the details: delving deep into convolutional nets** (2014), K. Chatfield et al. [[pdf]](http://arxiv.org/pdf/1405.3531)\n- **OverFeat: Integrated recognition, localization and detection using convolutional networks** (2013), P. Sermanet et al. [[pdf]](http://arxiv.org/pdf/1312.6229)\n- **Maxout networks** (2013), I. Goodfellow et al. [[pdf]](http://arxiv.org/pdf/1302.4389v4)\n- **Network in network** (2013), M. Lin et al. [[pdf]](http://arxiv.org/pdf/1312.4400)\n- **ImageNet classification with deep convolutional neural networks** (2012), A. Krizhevsky et al. [[pdf]](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n\n<!---[Key researchers]  [Christian Szegedy](https://scholar.google.ca/citations?hl=en&user=3QeF7mAAAAAJ), [Kaming He](https://scholar.google.ca/citations?hl=en&user=DhtAFkwAAAAJ), [Shaoqing Ren](https://scholar.google.ca/citations?hl=en&user=AUhj438AAAAJ), [Jian Sun](https://scholar.google.ca/citations?hl=en&user=ALVSZAYAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ), [Yann LeCun](https://scholar.google.ca/citations?hl=en&user=WLN3QrAAAAAJ)-->\n\n### Image: Segmentation / Object Detection\n- **You only look once: Unified, real-time object detection** (2016), J. Redmon et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf)\n- **Fully convolutional networks for semantic segmentation** (2015), J. Long et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)\n- **Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks** (2015), S. Ren et al. [[pdf]](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf)\n- **Fast R-CNN** (2015), R. Girshick [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf)\n- **Rich feature hierarchies for accurate object detection and semantic segmentation** (2014), R. Girshick et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf)\n- **Spatial pyramid pooling in deep convolutional networks for visual recognition** (2014), K. He et al. [[pdf]](http://arxiv.org/pdf/1406.4729)\n- **Semantic image segmentation with deep convolutional nets and fully connected CRFs**, L. Chen et al. [[pdf]](https://arxiv.org/pdf/1412.7062)\n- **Learning hierarchical features for scene labeling** (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n\n<!---[Key researchers]  [Ross Girshick](https://scholar.google.ca/citations?hl=en&user=W8VIEZgAAAAJ), [Jeff Donahue](https://scholar.google.ca/citations?hl=en&user=UfbuDH8AAAAJ), [Trevor Darrell](https://scholar.google.ca/citations?hl=en&user=bh-uRFMAAAAJ)-->\n\n### Image / Video / Etc\n- **Image Super-Resolution Using Deep Convolutional Networks** (2016), C. Dong et al. [[pdf]](https://arxiv.org/pdf/1501.00092v3.pdf)\n- **A neural algorithm of artistic style** (2015), L. Gatys et al. [[pdf]](https://arxiv.org/pdf/1508.06576)\n- **Deep visual-semantic alignments for generating image descriptions** (2015), A. Karpathy and L. Fei-Fei [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.pdf)\n- **Show, attend and tell: Neural image caption generation with visual attention** (2015), K. Xu et al. [[pdf]](http://arxiv.org/pdf/1502.03044)\n- **Show and tell: A neural image caption generator** (2015), O. Vinyals et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf)\n- **Long-term recurrent convolutional networks for visual recognition and description** (2015), J. Donahue et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Donahue_Long-Term_Recurrent_Convolutional_2015_CVPR_paper.pdf)\n- **VQA: Visual question answering** (2015), S. Antol et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)\n- **DeepFace: Closing the gap to human-level performance in face verification** (2014), Y. Taigman et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf):\n- **Large-scale video classification with convolutional neural networks** (2014), A. Karpathy et al. [[pdf]](http://vision.stanford.edu/pdf/karpathy14.pdf)\n- **Two-stream convolutional networks for action recognition in videos** (2014), K. Simonyan et al. [[pdf]](http://papers.nips.cc/paper/5353-two-stream-convolutional-networks-for-action-recognition-in-videos.pdf)\n- **3D convolutional neural networks for human action recognition** (2013), S. Ji et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2010_JiXYY10.pdf)\n\n<!---[Key researchers]  [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Andrej Karpathy](https://scholar.google.ca/citations?user=l8WuQJgAAAAJ)-->\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ)-->\n\n### Natural Language Processing / RNNs\n- **Neural Architectures for Named Entity Recognition** (2016), G. Lample et al. [[pdf]](http://aclweb.org/anthology/N/N16/N16-1030.pdf)\n- **Exploring the limits of language modeling** (2016), R. Jozefowicz et al. [[pdf]](http://arxiv.org/pdf/1602.02410)\n- **Teaching machines to read and comprehend** (2015), K. Hermann et al. [[pdf]](http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\n- **Effective approaches to attention-based neural machine translation** (2015), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1508.04025)\n- **Conditional random fields as recurrent neural networks** (2015), S. Zheng and S. Jayasumana. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Zheng_Conditional_Random_Fields_ICCV_2015_paper.pdf)\n- **Memory networks** (2014), J. Weston et al. [[pdf]](https://arxiv.org/pdf/1410.3916)\n- **Neural turing machines** (2014), A. Graves et al. [[pdf]](https://arxiv.org/pdf/1410.5401)\n- **Neural machine translation by jointly learning to align and translate** (2014), D. Bahdanau et al. [[pdf]](http://arxiv.org/pdf/1409.0473)\n- **Sequence to sequence learning with neural networks** (2014), I. Sutskever et al. [[pdf]](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n- **Learning phrase representations using RNN encoder-decoder for statistical machine translation** (2014), K. Cho et al. [[pdf]](http://arxiv.org/pdf/1406.1078)\n- **A convolutional neural network for modeling sentences** (2014), N. Kalchbrenner et al. [[pdf]](http://arxiv.org/pdf/1404.2188v1)\n- **Convolutional neural networks for sentence classification** (2014), Y. Kim [[pdf]](http://arxiv.org/pdf/1408.5882)\n- **Glove: Global vectors for word representation** (2014), J. Pennington et al. [[pdf]](http://anthology.aclweb.org/D/D14/D14-1162.pdf)\n- **Distributed representations of sentences and documents** (2014), Q. Le and T. Mikolov [[pdf]](http://arxiv.org/pdf/1405.4053)\n- **Distributed representations of words and phrases and their compositionality** (2013), T. Mikolov et al. [[pdf]](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n- **Efficient estimation of word representations in vector space** (2013), T. Mikolov et al.  [[pdf]](http://arxiv.org/pdf/1301.3781)\n- **Recursive deep models for semantic compositionality over a sentiment treebank** (2013), R. Socher et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.383.1327&rep=rep1&type=pdf)\n- **Generating sequences with recurrent neural networks** (2013), A. Graves. [[pdf]](https://arxiv.org/pdf/1308.0850)\n\n<!---[Key researchers]  [Kyunghyun Cho](https://scholar.google.ca/citations?user=0RAmmIAAAAAJ), [Oriol Vinyals](https://scholar.google.ca/citations?user=NkzyCvUAAAAJ), [Richard Socher](https://scholar.google.ca/citations?hl=en&user=FaOcyfMAAAAJ), [Tomas Mikolov](https://scholar.google.ca/citations?user=oBu8kMMAAAAJ), [Christopher D. Manning](https://scholar.google.ca/citations?user=1zmDOdwAAAAJ), [Yoshua Bengio](https://scholar.google.ca/citations?user=kukA0LcAAAAJ)-->\n\n### Speech / Other Domain\n- **End-to-end attention-based large vocabulary speech recognition** (2016), D. Bahdanau et al. [[pdf]](https://arxiv.org/pdf/1508.04395)\n- **Deep speech 2: End-to-end speech recognition in English and Mandarin** (2015), D. Amodei et al. [[pdf]](https://arxiv.org/pdf/1512.02595)\n- **Speech recognition with deep recurrent neural networks** (2013), A. Graves [[pdf]](http://arxiv.org/pdf/1303.5778.pdf)\n- **Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups** (2012), G. Hinton et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/SPM_DNN_12.pdf)\n- **Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition** (2012) G. Dahl et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.337.7548&rep=rep1&type=pdf)\n- **Acoustic modeling using deep belief networks** (2012), A. Mohamed et al. [[pdf]](http://www.cs.toronto.edu/~asamir/papers/speechDBN_jrnl.pdf)\n\n<!---[Key researchers]  [Alex Graves](https://scholar.google.ca/citations?user=DaFHynwAAAAJ), [Geoffrey Hinton](https://scholar.google.ca/citations?user=JicYPdAAAAAJ), [Dong Yu](https://scholar.google.ca/citations?hl=en&user=tMY31_gAAAAJ)-->\n\n### Reinforcement Learning / Robotics\n- **End-to-end training of deep visuomotor policies** (2016), S. Levine et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-522/source/15-522.pdf)\n- **Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection** (2016), S. Levine et al. [[pdf]](https://arxiv.org/pdf/1603.02199)\n- **Asynchronous methods for deep reinforcement learning** (2016), V. Mnih et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/mniha16.pdf)\n- **Deep Reinforcement Learning with Double Q-Learning** (2016), H. Hasselt et al. [[pdf]](https://arxiv.org/pdf/1509.06461.pdf )\n- **Mastering the game of Go with deep neural networks and tree search** (2016), D. Silver et al. [[pdf]](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)\n- **Continuous control with deep reinforcement learning** (2015), T. Lillicrap et al. [[pdf]](https://arxiv.org/pdf/1509.02971)\n- **Human-level control through deep reinforcement learning** (2015), V. Mnih et al. [[pdf]](http://www.davidqiu.com:8888/research/nature14236.pdf)\n- **Deep learning for detecting robotic grasps** (2015), I. Lenz et al. [[pdf]](http://www.cs.cornell.edu/~asaxena/papers/lenz_lee_saxena_deep_learning_grasping_ijrr2014.pdf)\n- **Playing atari with deep reinforcement learning** (2013), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1312.5602.pdf))\n\n<!---[Key researchers]  [Sergey Levine](https://scholar.google.ca/citations?user=8R35rCwAAAAJ), [Volodymyr Mnih](https://scholar.google.ca/citations?hl=en&user=rLdfJ1gAAAAJ), [David Silver](https://scholar.google.ca/citations?user=-8DNE4UAAAAJ)-->\n\n### More Papers from 2016\n- **Layer Normalization** (2016), J. Ba et al. [[pdf]](https://arxiv.org/pdf/1607.06450v1.pdf)\n- **Learning to learn by gradient descent by gradient descent** (2016), M. Andrychowicz et al. [[pdf]](http://arxiv.org/pdf/1606.04474v1)\n- **Domain-adversarial training of neural networks** (2016), Y. Ganin et al. [[pdf]](http://www.jmlr.org/papers/volume17/15-239/source/15-239.pdf)\n- **WaveNet: A Generative Model for Raw Audio** (2016), A. Oord et al. [[pdf]](https://arxiv.org/pdf/1609.03499v2) [[web]](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)\n- **Colorful image colorization** (2016), R. Zhang et al. [[pdf]](https://arxiv.org/pdf/1603.08511)\n- **Generative visual manipulation on the natural image manifold** (2016), J. Zhu et al. [[pdf]](https://arxiv.org/pdf/1609.03552)\n- **Texture networks: Feed-forward synthesis of textures and stylized images** (2016), D Ulyanov et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/ulyanov16.pdf)\n- **SSD: Single shot multibox detector** (2016), W. Liu et al. [[pdf]](https://arxiv.org/pdf/1512.02325)\n- **SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size** (2016), F. Iandola et al. [[pdf]](http://arxiv.org/pdf/1602.07360)\n- **Eie: Efficient inference engine on compressed deep neural network** (2016), S. Han et al. [[pdf]](http://arxiv.org/pdf/1602.01528)\n- **Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1** (2016), M. Courbariaux et al. [[pdf]](https://arxiv.org/pdf/1602.02830)\n- **Dynamic memory networks for visual and textual question answering** (2016), C. Xiong et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/xiong16.pdf)\n- **Stacked attention networks for image question answering** (2016), Z. Yang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Stacked_Attention_Networks_CVPR_2016_paper.pdf)\n- **Hybrid computing using a neural network with dynamic external memory** (2016), A. Graves et al. [[pdf]](https://www.gwern.net/docs/2016-graves.pdf)\n- **Google's neural machine translation system: Bridging the gap between human and machine translation** (2016), Y. Wu et al. [[pdf]](https://arxiv.org/pdf/1609.08144)\n\n* * *\n\n\n### New papers\n*Newly published papers (< 6 months) which are worth reading*\n- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al. [[pdf]](https://arxiv.org/pdf/1704.04861.pdf)\n- Convolutional Sequence to Sequence Learning (2017), Jonas Gehring et al. [[pdf]](https://arxiv.org/pdf/1705.03122)\n- A Knowledge-Grounded Neural Conversation Model (2017), Marjan Ghazvininejad et al. [[pdf]](https://arxiv.org/pdf/1702.01932)\n- Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour (2017), Priya Goyal et al. [[pdf]](https://research.fb.com/wp-content/uploads/2017/06/imagenet1kin1h3.pdf)\n- TACOTRON: Towards end-to-end speech synthesis (2017), Y. Wang et al. [[pdf]](https://arxiv.org/pdf/1703.10135.pdf)\n- Deep Photo Style Transfer (2017), F. Luan et al. [[pdf]](http://arxiv.org/pdf/1703.07511v1.pdf)\n- Evolution Strategies as a Scalable Alternative to Reinforcement Learning (2017), T. Salimans et al. [[pdf]](http://arxiv.org/pdf/1703.03864v1.pdf)\n- Deformable Convolutional Networks (2017), J. Dai et al. [[pdf]](http://arxiv.org/pdf/1703.06211v2.pdf)\n- Mask R-CNN (2017), K. He et al. [[pdf]](https://128.84.21.199/pdf/1703.06870)\n- Learning to discover cross-domain relations with generative adversarial networks (2017), T. Kim et al. [[pdf]](http://arxiv.org/pdf/1703.05192v1.pdf) \n- Deep voice: Real-time neural text-to-speech (2017), S. Arik et al., [[pdf]](http://arxiv.org/pdf/1702.07825v2.pdf)\n- PixelNet: Representation of the pixels, by the pixels, and for the pixels (2017), A. Bansal et al. [[pdf]](http://arxiv.org/pdf/1702.06506v1.pdf)\n- Batch renormalization: Towards reducing minibatch dependence in batch-normalized models (2017), S. Ioffe. [[pdf]](https://arxiv.org/abs/1702.03275)\n- Wasserstein GAN (2017), M. Arjovsky et al. [[pdf]](https://arxiv.org/pdf/1701.07875v1)\n- Understanding deep learning requires rethinking generalization (2017), C. Zhang et al. [[pdf]](https://arxiv.org/pdf/1611.03530)\n- Least squares generative adversarial networks (2016), X. Mao et al. [[pdf]](https://arxiv.org/abs/1611.04076v2)\n\n\n### Old Papers\n*Classic papers published before 2012*\n- An analysis of single-layer networks in unsupervised feature learning (2011), A. Coates et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_CoatesNL11.pdf)\n- Deep sparse rectifier neural networks (2011), X. Glorot et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2011_GlorotBB11.pdf)\n- Natural language processing (almost) from scratch (2011), R. Collobert et al. [[pdf]](http://arxiv.org/pdf/1103.0398)\n- Recurrent neural network based language model (2010), T. Mikolov et al. [[pdf]](http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf)\n- Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010), P. Vincent et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.297.3484&rep=rep1&type=pdf)\n- Learning mid-level features for recognition (2010), Y. Boureau [[pdf]](http://ece.duke.edu/~lcarin/boureau-cvpr-10.pdf)\n- A practical guide to training restricted boltzmann machines (2010), G. Hinton [[pdf]](http://www.csri.utoronto.ca/~hinton/absps/guideTR.pdf)\n- Understanding the difficulty of training deep feedforward neural networks (2010), X. Glorot and Y. Bengio [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf)\n- Why does unsupervised pre-training help deep learning (2010), D. Erhan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_ErhanCBV10.pdf)\n- Learning deep architectures for AI (2009), Y. Bengio. [[pdf]](http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20(2009).pdf)\n- Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009), H. Lee et al. [[pdf]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.802&rep=rep1&type=pdf)\n- Greedy layer-wise training of deep networks (2007), Y. Bengio et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_739.pdf)\n- Reducing the dimensionality of data with neural networks, G. Hinton and R. Salakhutdinov. [[pdf]](http://homes.mpimf-heidelberg.mpg.de/~mhelmsta/pdf/2006%20Hinton%20Salakhudtkinov%20Science.pdf)\n- A fast learning algorithm for deep belief nets (2006), G. Hinton et al. [[pdf]](http://nuyoo.utm.mx/~jjf/rna/A8%20A%20fast%20learning%20algorithm%20for%20deep%20belief%20nets.pdf)\n- Gradient-based learning applied to document recognition (1998), Y. LeCun et al. [[pdf]](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)\n- Long short-term memory (1997), S. Hochreiter and J. Schmidhuber. [[pdf]](http://www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735)\n\n\n### HW / SW / Dataset\n-  SQuAD: 100,000+ Questions for Machine Comprehension of Text (2016), Rajpurkar et al. [[pdf]](https://arxiv.org/pdf/1606.05250.pdf)\n- OpenAI gym (2016), G. Brockman et al. [[pdf]](https://arxiv.org/pdf/1606.01540)\n- TensorFlow: Large-scale machine learning on heterogeneous distributed systems (2016), M. Abadi et al. [[pdf]](http://arxiv.org/pdf/1603.04467)\n- Theano: A Python framework for fast computation of mathematical expressions, R. Al-Rfou et al.\n- Torch7: A matlab-like environment for machine learning, R. Collobert et al. [[pdf]](https://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf)\n- MatConvNet: Convolutional neural networks for matlab (2015), A. Vedaldi and K. Lenc [[pdf]](http://arxiv.org/pdf/1412.4564)\n- Imagenet large scale visual recognition challenge (2015), O. Russakovsky et al. [[pdf]](http://arxiv.org/pdf/1409.0575)\n- Caffe: Convolutional architecture for fast feature embedding (2014), Y. Jia et al. [[pdf]](http://arxiv.org/pdf/1408.5093)\n\n\n### Book / Survey / Review\n- On the Origin of Deep Learning (2017), H. Wang and Bhiksha Raj. [[pdf]](https://arxiv.org/pdf/1702.07800)\n- Deep Reinforcement Learning: An Overview (2017), Y. Li, [[pdf]](http://arxiv.org/pdf/1701.07274v2.pdf)\n- Neural Machine Translation and Sequence-to-sequence Models(2017): A Tutorial, G. Neubig. [[pdf]](http://arxiv.org/pdf/1703.01619v1.pdf)\n- Neural Network and Deep Learning (Book, Jan 2017), Michael Nielsen. [[html]](http://neuralnetworksanddeeplearning.com/index.html)\n- Deep learning (Book, 2016), Goodfellow et al. [[html]](http://www.deeplearningbook.org/)\n- LSTM: A search space odyssey (2016), K. Greff et al. [[pdf]](https://arxiv.org/pdf/1503.04069.pdf?utm_content=buffereddc5&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer)\n- Tutorial on Variational Autoencoders (2016), C. Doersch. [[pdf]](https://arxiv.org/pdf/1606.05908)\n- Deep learning (2015), Y. LeCun, Y. Bengio and G. Hinton [[pdf]](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)\n- Deep learning in neural networks: An overview (2015), J. Schmidhuber [[pdf]](http://arxiv.org/pdf/1404.7828)\n- Representation learning: A review and new perspectives (2013), Y. Bengio et al. [[pdf]](http://arxiv.org/pdf/1206.5538)\n\n### Video Lectures / Tutorials / Blogs\n\n*(Lectures)*\n- CS231n, Convolutional Neural Networks for Visual Recognition, Stanford University [[web]](http://cs231n.stanford.edu/)\n- CS224d, Deep Learning for Natural Language Processing, Stanford University [[web]](http://cs224d.stanford.edu/)\n- Oxford Deep NLP 2017, Deep Learning for Natural Language Processing, University of Oxford [[web]](https://github.com/oxford-cs-deepnlp-2017/lectures)\n\n*(Tutorials)*\n- NIPS 2016 Tutorials, Long Beach [[web]](https://nips.cc/Conferences/2016/Schedule?type=Tutorial)\n- ICML 2016 Tutorials, New York City [[web]](http://techtalks.tv/icml/2016/tutorials/)\n- ICLR 2016 Videos, San Juan [[web]](http://videolectures.net/iclr2016_san_juan/)\n- Deep Learning Summer School 2016, Montreal [[web]](http://videolectures.net/deeplearning2016_montreal/)\n- Bay Area Deep Learning School 2016, Stanford [[web]](https://www.bayareadlschool.org/)\n\n*(Blogs)*\n- OpenAI [[web]](https://www.openai.com/)\n- Distill [[web]](http://distill.pub/)\n- Andrej Karpathy Blog [[web]](http://karpathy.github.io/)\n- Colah's Blog [[Web]](http://colah.github.io/)\n- WildML [[Web]](http://www.wildml.com/)\n- FastML [[web]](http://www.fastml.com/)\n- TheMorningPaper [[web]](https://blog.acolyer.org)\n\n### Appendix: More than Top 100\n*(2016)*\n- A character-level decoder without explicit segmentation for neural machine translation (2016), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1603.06147)\n- Dermatologist-level classification of skin cancer with deep neural networks (2017), A. Esteva et al. [[html]](http://www.nature.com/nature/journal/v542/n7639/full/nature21056.html)\n- Weakly supervised object localization with multi-fold multiple instance learning (2017), R. Gokberk et al. [[pdf]](https://arxiv.org/pdf/1503.00949)\n- Brain tumor segmentation with deep neural networks (2017), M. Havaei et al. [[pdf]](https://arxiv.org/pdf/1505.03540)\n- Professor Forcing: A New Algorithm for Training Recurrent Networks (2016), A. Lamb et al. [[pdf]](https://arxiv.org/pdf/1610.09038)\n- Adversarially learned inference (2016), V. Dumoulin et al. [[web]](https://ishmaelbelghazi.github.io/ALI/)[[pdf]](https://arxiv.org/pdf/1606.00704v1)\n- Understanding convolutional neural networks (2016), J. Koushik [[pdf]](https://arxiv.org/pdf/1605.09081v1)\n- Taking the human out of the loop: A review of bayesian optimization (2016), B. Shahriari et al. [[pdf]](https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf)\n- Adaptive computation time for recurrent neural networks (2016), A. Graves [[pdf]](http://arxiv.org/pdf/1603.08983)\n- Densely connected convolutional networks (2016), G. Huang et al. [[pdf]](https://arxiv.org/pdf/1608.06993v1)\n- Region-based convolutional networks for accurate object detection and segmentation (2016), R. Girshick et al. \n- Continuous deep q-learning with model-based acceleration (2016), S. Gu et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v48/gu16.pdf)\n- A thorough examination of the cnn/daily mail reading comprehension task (2016), D. Chen et al. [[pdf]](https://arxiv.org/pdf/1606.02858)\n- Achieving open vocabulary neural machine translation with hybrid word-character models, M. Luong and C. Manning. [[pdf]](https://arxiv.org/pdf/1604.00788)\n- Very Deep Convolutional Networks for Natural Language Processing (2016), A. Conneau et al. [[pdf]](https://arxiv.org/pdf/1606.01781)\n- Bag of tricks for efficient text classification (2016), A. Joulin et al. [[pdf]](https://arxiv.org/pdf/1607.01759)\n- Efficient piecewise training of deep structured models for semantic segmentation (2016), G. Lin et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Lin_Efficient_Piecewise_Training_CVPR_2016_paper.pdf)\n- Learning to compose neural networks for question answering (2016), J. Andreas et al. [[pdf]](https://arxiv.org/pdf/1601.01705)\n- Perceptual losses for real-time style transfer and super-resolution (2016), J. Johnson et al. [[pdf]](https://arxiv.org/pdf/1603.08155)\n- Reading text in the wild with convolutional neural networks (2016), M. Jaderberg et al. [[pdf]](http://arxiv.org/pdf/1412.1842)\n- What makes for effective detection proposals? (2016), J. Hosang et al. [[pdf]](https://arxiv.org/pdf/1502.05082)\n- Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks (2016), S. Bell et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Bell_Inside-Outside_Net_Detecting_CVPR_2016_paper.pdf).\n- Instance-aware semantic segmentation via multi-task network cascades (2016), J. Dai et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Dai_Instance-Aware_Semantic_Segmentation_CVPR_2016_paper.pdf)\n- Conditional image generation with pixelcnn decoders (2016), A. van den Oord et al. [[pdf]](http://papers.nips.cc/paper/6527-tree-structured-reinforcement-learning-for-sequential-object-localization.pdf)\n- Deep networks with stochastic depth (2016), G. Huang et al., [[pdf]](https://arxiv.org/pdf/1603.09382)\n- Consistency and Fluctuations For Stochastic Gradient Langevin Dynamics (2016), Yee Whye Teh et al. [[pdf]](http://www.jmlr.org/papers/volume17/teh16a/teh16a.pdf)\n\n*(2015)*\n- Ask your neurons: A neural-based approach to answering questions about images (2015), M. Malinowski et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.pdf)\n- Exploring models and data for image question answering (2015), M. Ren et al. [[pdf]](http://papers.nips.cc/paper/5640-stochastic-variational-inference-for-hidden-markov-models.pdf)\n- Are you talking to a machine? dataset and methods for multilingual image question (2015), H. Gao et al. [[pdf]](http://papers.nips.cc/paper/5641-are-you-talking-to-a-machine-dataset-and-methods-for-multilingual-image-question.pdf)\n- Mind's eye: A recurrent visual representation for image caption generation (2015), X. Chen and C. Zitnick. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Chen_Minds_Eye_A_2015_CVPR_paper.pdf)\n- From captions to visual concepts and back (2015), H. Fang et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Fang_From_Captions_to_2015_CVPR_paper.pdf).\n- Towards AI-complete question answering: A set of prerequisite toy tasks (2015), J. Weston et al. [[pdf]](http://arxiv.org/pdf/1502.05698)\n- Ask me anything: Dynamic memory networks for natural language processing (2015), A. Kumar et al. [[pdf]](http://arxiv.org/pdf/1506.07285)\n- Unsupervised learning of video representations using LSTMs (2015), N. Srivastava et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/srivastava15.pdf)\n- Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding (2015), S. Han et al. [[pdf]](https://arxiv.org/pdf/1510.00149)\n- Improved semantic representations from tree-structured long short-term memory networks (2015), K. Tai et al. [[pdf]](https://arxiv.org/pdf/1503.00075)\n- Character-aware neural language models (2015), Y. Kim et al. [[pdf]](https://arxiv.org/pdf/1508.06615)\n- Grammar as a foreign language (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf)\n- Trust Region Policy Optimization (2015), J. Schulman et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf)\n- Beyond short snippents: Deep networks for video classification (2015) [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ng_Beyond_Short_Snippets_2015_CVPR_paper.pdf)\n- Learning Deconvolution Network for Semantic Segmentation (2015), H. Noh et al. [[pdf]](https://arxiv.org/pdf/1505.04366v1)\n- Learning spatiotemporal features with 3d convolutional networks (2015), D. Tran et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf)\n- Understanding neural networks through deep visualization (2015), J. Yosinski et al. [[pdf]](https://arxiv.org/pdf/1506.06579)\n- An Empirical Exploration of Recurrent Network Architectures (2015), R. Jozefowicz et al.  [[pdf]](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)\n- Deep generative image models using aï¿¼ laplacian pyramid of adversarial networks (2015), E.Denton et al. [[pdf]](http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf)\n- Gated Feedback Recurrent Neural Networks (2015), J. Chung et al. [[pdf]](http://www.jmlr.org/proceedings/papers/v37/chung15.pdf)\n- Fast and accurate deep network learning by exponential linear units (ELUS) (2015), D. Clevert et al. [[pdf]](https://arxiv.org/pdf/1511.07289.pdf%5Cnhttp://arxiv.org/abs/1511.07289%5Cnhttp://arxiv.org/abs/1511.07289)\n- Pointer networks (2015), O. Vinyals et al. [[pdf]](http://papers.nips.cc/paper/5866-pointer-networks.pdf)\n- Visualizing and Understanding Recurrent Networks (2015), A. Karpathy et al. [[pdf]](https://arxiv.org/pdf/1506.02078)\n- Attention-based models for speech recognition (2015), J. Chorowski et al. [[pdf]](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)\n- End-to-end memory networks (2015), S. Sukbaatar et al. [[pdf]](http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf)\n- Describing videos by exploiting temporal structure (2015), L. Yao et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yao_Describing_Videos_by_ICCV_2015_paper.pdf)\n- A neural conversational model (2015), O. Vinyals and Q. Le. [[pdf]](https://arxiv.org/pdf/1506.05869.pdf)\n- Improving distributional similarity with lessons learned from word embeddings, O. Levy et al. [[pdf]] (https://www.transacl.org/ojs/index.php/tacl/article/download/570/124)\n- Transition-Based Dependency Parsing with Stack Long Short-Term Memory (2015), C. Dyer et al. [[pdf]](http://aclweb.org/anthology/P/P15/P15-1033.pdf)\n- Improved Transition-Based Parsing by Modeling Characters instead of Words with LSTMs (2015), M. Ballesteros et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1041.pdf)\n- Finding function in form: Compositional character models for open vocabulary word representation (2015), W. Ling et al. [[pdf]](http://aclweb.org/anthology/D/D15/D15-1176.pdf)\n\n\n*(~2014)*\n- DeepPose: Human pose estimation via deep neural networks (2014), A. Toshev and C. Szegedy [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Toshev_DeepPose_Human_Pose_2014_CVPR_paper.pdf)\n- Learning a Deep Convolutional Network for Image Super-Resolution (2014, C. Dong et al. [[pdf]](https://www.researchgate.net/profile/Chen_Change_Loy/publication/264552416_Lecture_Notes_in_Computer_Science/links/53e583e50cf25d674e9c280e.pdf)\n- Recurrent models of visual attention (2014), V. Mnih et al. [[pdf]](http://arxiv.org/pdf/1406.6247.pdf)\n- Empirical evaluation of gated recurrent neural networks on sequence modeling (2014), J. Chung et al. [[pdf]](https://arxiv.org/pdf/1412.3555)\n- Addressing the rare word problem in neural machine translation (2014), M. Luong et al. [[pdf]](https://arxiv.org/pdf/1410.8206)\n- On the properties of neural machine translation: Encoder-decoder approaches (2014), K. Cho et. al.\n- Recurrent neural network regularization (2014), W. Zaremba et al. [[pdf]](http://arxiv.org/pdf/1409.2329)\n- Intriguing properties of neural networks (2014), C. Szegedy et al. [[pdf]](https://arxiv.org/pdf/1312.6199.pdf)\n- Towards end-to-end speech recognition with recurrent neural networks (2014), A. Graves and N. Jaitly. [[pdf]](http://www.jmlr.org/proceedings/papers/v32/graves14.pdf)\n- Scalable object detection using deep neural networks (2014), D. Erhan et al. [[pdf]](http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf)\n- On the importance of initialization and momentum in deep learning (2013), I. Sutskever et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_sutskever13.pdf)\n- Regularization of neural networks using dropconnect (2013), L. Wan et al. [[pdf]](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2013_wan13.pdf)\n- Learning Hierarchical Features for Scene Labeling (2013), C. Farabet et al. [[pdf]](https://hal-enpc.archives-ouvertes.fr/docs/00/74/20/77/PDF/farabet-pami-13.pdf)\n- Linguistic Regularities in Continuous Space Word Representations (2013), T. Mikolov et al. [[pdf]](http://www.aclweb.org/anthology/N13-1#page=784)\n- Large scale distributed deep networks (2012), J. Dean et al. [[pdf]](http://papers.nips.cc/paper/4687-large-scale-distributed-deep-networks.pdf)\n- A Fast and Accurate Dependency Parser using Neural Networks. Chen and Manning. [[pdf]](http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf)\n\n\n\n## Acknowledgement\n\nThank you for all your contributions. Please make sure to read the [contributing guide](https://github.com/terryum/awesome-deep-learning-papers/blob/master/Contributing.md) before you make a pull request.\n\n## License\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\nTo the extent possible under law, [Terry T. Um](https://www.facebook.com/terryum.io/) has waived all copyright and related or neighboring rights to this work.\n"
        },
        {
          "name": "ReadingNotes.md",
          "type": "blob",
          "size": 0.53,
          "content": "\n\n\n## Robotics\n- [Learning Inverse Dynamics Models in O(n) time with LSTM networks](#learning-inverse-dynamics-models-in-on-time-with-lstm-networks) (2017), Elmar Rueckert, Moritz Nakatenus, Samuele Tosatto, and Jan Peters, Humanoid 2017. (2017/10/03 read).\n\n\n\n\n### Learning Inverse Dynamics Models in O(n) time with LSTM networks\n* Limitation of the current methods\n  * GPR (![Eq:On3])and LWR is not scalable\n* Contribution of this paper\n  * \n\n**Bibtex**: to appear\n\n$$\no(n^{3})\n$$\n\n[Eq:On3]: http://rogercortesi.com/eqn/tempimagedir/eqn8190.png\n"
        },
        {
          "name": "fetch_papers.py",
          "type": "blob",
          "size": 1.61,
          "content": "'''\nAuthor: doodhwala\nPython3 script to fetch the top 100 papers\n'''\n\nimport os, re, requests, codecs\n\ndirectory = 'papers'\nif not os.path.exists(directory):\n    os.makedirs(directory)\n\npapers = []\nwith codecs.open('README.md', encoding='utf-8', mode='r', buffering=1, errors='strict') as f:\n    lines = f.read().split('\\n')\n    heading, section_path = '', ''\n    for line in lines:\n        if('###' in line):\n            heading = line.strip().split('###')[1]\n            win_restricted_chars = re.compile(r'[\\^\\/\\\\\\:\\*\\?\\\"<>\\|]')\n            heading = win_restricted_chars.sub(\"\", heading)\n            section_path = os.path.join(directory, heading)\n            if not os.path.exists(section_path):\n                os.makedirs(section_path)\n        if('[[pdf]]' in line):\n            # The stars ensure you pick up only the top 100 papers\n            # Modify the expression if you want to fetch all other papers as well\n            result = re.search('\\*\\*(.*?)\\*\\*.*?\\[\\[pdf\\]\\]\\((.*?)\\)', line)\n            if(result):\n                paper, url = result.groups()\n                paper = win_restricted_chars.sub(\"\", paper)\n                # Auto - resume functionality\n                if(not os.path.exists(os.path.join(section_path, paper + '.pdf'))):\n                    print('Fetching', paper)\n                    try:\n                        response = requests.get(url)\n                        with open(os.path.join(section_path, paper + '.pdf'), 'wb') as f:\n                            f.write(response.content)\n                    except requests.exceptions.RequestException as e:\n                        print(\"Error: {}\".format(e))\n"
        },
        {
          "name": "get_authors.py",
          "type": "blob",
          "size": 3.35,
          "content": "\n# coding: utf-8\n\nimport re\nimport requests\nfrom html.parser import HTMLParser\nimport codecs\n\nsearch_engine=\"https://www.semanticscholar.org/search?q=\"\npost_fix = \"&sort=relevance&ae=false\"\n\nclass AuthorParser( HTMLParser ):\n    tail_string = \"\" #contains the last tag's name which point to author field\n    m_Stop = False\n    m_authors = []\n    def handle_starttag(self, tag, attr):\n        if self.m_Stop:\n            return\n        if tag == 'article':\n            self.tail_string += tag\n            return\n        if self.tail_string != \"\":\n            #print(\"search already kick-off\")\n            self.tail_string = self.tail_string+\".\"+tag\n            #print(self.tail_string)\n    def handle_endtag(self, tag):\n        if self.m_Stop :\n            return\n        if self.tail_string == \"article\":\n            # ONLY handle the first article\n            self.m_Stop = True\n        if self.tail_string != \"\":\n            tags = self.tail_string.split('.')\n            tags.reverse()\n            for t in tags:\n                if t == tag:\n                    tags.remove(t)\n                    break\n            self.tail_string = \"\"\n            tags.reverse()\n            for i,t in enumerate(tags):\n                self.tail_string = self.tail_string + \".\" + t if i > 0 else t\n\n    def handle_data(self, data):\n        if self.m_Stop:\n            return\n        if self.tail_string == \"article.header.ul.li.span.span.a.span.span\":\n            #print(data)\n            self.m_authors.append(data)\n\n    def get_authors(self):\n        return self.m_authors\n\n    def clean(self):\n        self.m_authors = []\n        self.tail_string= \"\"\n        self.m_Stop = False\n\n\ndef getPaperNames( readme_file ):\n    paper_list = []\n    with codecs.open( readme_file,encoding='utf-8',mode='r',buffering = 1, errors='strict' ) as f:\n        lines = f.read().split('\\n')\n        heading, section_path = '', ''\n        for line in lines:\n            if('###' in line):\n                heading = line.strip().split('###')[1]\n                heading = heading.replace('/', '|')\n\n            if('[[pdf]]' in line):\n                # The stars ensure you pick up only the top 100 papers\n                # Modify the expression if you want to fetch all other papers as well\n                result = re.search('\\*\\*(.*?)\\*\\*.*?\\[\\[pdf\\]\\]\\((.*?)\\)', line)\n                if(result):\n                    paper, url = result.groups()\n                    paper_list.append(paper)\n\n    return paper_list\n\nall_papers = getPaperNames(\"README.md\")\n\nauthor_parser = AuthorParser()\nauthor_dict = {}\nfor index,paper in enumerate(all_papers):\n    paper.replace(\" \", \"%20\")\n    search_result = requests.get(search_engine + paper + post_fix)\n    author_parser.feed(search_result.text)\n    #print( paper, '==>', author_parser.get_authors() )\n    authors = author_parser.get_authors()\n    for weight, author in enumerate( authors):\n        if author not in author_dict.keys():\n            author_dict[author] = []\n                    \n        author_dict[author].append( (weight+1,paper))\n    author_parser.clean()\n    print(\"Processed %d |\"%(index), paper)\n\n# example usage of author information\nwith open( \"author.csv\",'w') as fcsv:\n    for (author, papers) in author_dict.items():\n        score = 0.0\n        for (weight, paper) in papers:\n            score += 1.0/weight\n        print(author,\" score: %.2f\"%score)\n        fcsv.write( author+','+\"%.2f\"%score)\n\n\n\n"
        },
        {
          "name": "top100papers.bib",
          "type": "blob",
          "size": 29.64,
          "content": "@article{hinton2015distilling,\n  title={Distilling the knowledge in a neural network},\n  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},\n  journal={arXiv preprint arXiv:1503.02531},\n  year={2015}\n}\n@inproceedings{nguyen2015deep,\n  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},\n  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={427--436},\n  year={2015}\n}\n@inproceedings{yosinski2014transferable,\n  title={How transferable are features in deep neural networks?},\n  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},\n  booktitle={Advances in neural information processing systems},\n  pages={3320--3328},\n  year={2014}\n}\n@inproceedings{sharif2014cnn,\n  title={CNN features off-the-shelf: an astounding baseline for recognition},\n  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},\n  pages={806--813},\n  year={2014}\n}\n@inproceedings{oquab2014learning,\n  title={Learning and transferring mid-level image representations using convolutional neural networks},\n  author={Oquab, Maxime and Bottou, Leon and Laptev, Ivan and Sivic, Josef},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={1717--1724},\n  year={2014}\n}\n@inproceedings{zeiler2014visualizing,\n  title={Visualizing and understanding convolutional networks},\n  author={Zeiler, Matthew D and Fergus, Rob},\n  booktitle={European conference on computer vision},\n  pages={818--833},\n  year={2014},\n  organization={Springer}\n}\n@inproceedings{donahue2014decaf,\n  title={DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition.},\n  author={Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},\n  booktitle={Icml},\n  volume={32},\n  pages={647--655},\n  year={2014}\n}\n\n@inproceedings{srivastava2015training,\n  title={Training very deep networks},\n  author={Srivastava, Rupesh K and Greff, Klaus and Schmidhuber, J{\\\"u}rgen},\n  booktitle={Advances in neural information processing systems},\n  pages={2377--2385},\n  year={2015}\n}\n\n@article{ioffe2015batch,\n  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},\n  author={Ioffe, Sergey and Szegedy, Christian},\n  journal={arXiv preprint arXiv:1502.03167},\n  year={2015}\n}\n@inproceedings{he2015delving,\n  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle={Proceedings of the IEEE international conference on computer vision},\n  pages={1026--1034},\n  year={2015}\n}\n@article{srivastava2014dropout,\n  title={Dropout: a simple way to prevent neural networks from overfitting.},\n  author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},\n  journal={Journal of Machine Learning Research},\n  volume={15},\n  number={1},\n  pages={1929--1958},\n  year={2014}\n}\n@article{kingma2014adam,\n  title={Adam: A method for stochastic optimization},\n  author={Kingma, Diederik and Ba, Jimmy},\n  journal={arXiv preprint arXiv:1412.6980},\n  year={2014}\n}\n@article{hinton2012improving,\n  title={Improving neural networks by preventing co-adaptation of feature detectors},\n  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},\n  journal={arXiv preprint arXiv:1207.0580},\n  year={2012}\n}\n@article{bergstra2012random,\n  title={Random search for hyper-parameter optimization},\n  author={Bergstra, James and Bengio, Yoshua},\n  journal={Journal of Machine Learning Research},\n  volume={13},\n  number={Feb},\n  pages={281--305},\n  year={2012}\n}\n@article{oord2016pixel,\n  title={Pixel recurrent neural networks},\n  author={Oord, Aaron van den and Kalchbrenner, Nal and Kavukcuoglu, Koray},\n  journal={arXiv preprint arXiv:1601.06759},\n  year={2016}\n}\n@inproceedings{salimans2016improved,\n  title={Improved techniques for training gans},\n  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={2226--2234},\n  year={2016}\n}\n@article{radford2015unsupervised,\n  title={Unsupervised representation learning with deep convolutional generative adversarial networks},\n  author={Radford, Alec and Metz, Luke and Chintala, Soumith},\n  journal={arXiv preprint arXiv:1511.06434},\n  year={2015}\n}\n@article{gregor2015draw,\n  title={DRAW: A recurrent neural network for image generation},\n  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},\n  journal={arXiv preprint arXiv:1502.04623},\n  year={2015}\n}\n@inproceedings{goodfellow2014generative,\n  title={Generative adversarial nets},\n  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},\n  booktitle={Advances in neural information processing systems},\n  pages={2672--2680},\n  year={2014}\n}\n@article{kingma2013auto,\n  title={Auto-encoding variational bayes},\n  author={Kingma, Diederik P and Welling, Max},\n  journal={arXiv preprint arXiv:1312.6114},\n  year={2013}\n}\n@inproceedings{le2013building,\n  title={Building high-level features using large scale unsupervised learning},\n  author={Le, Quoc V},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on},\n  pages={8595--8598},\n  year={2013},\n  organization={IEEE}\n}\n@inproceedings{szegedy2016rethinking,\n  title={Rethinking the inception architecture for computer vision},\n  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={2818--2826},\n  year={2016}\n}\n@article{szegedy2016inception,\n  title={Inception-v4, inception-resnet and the impact of residual connections on learning},\n  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},\n  journal={arXiv preprint arXiv:1602.07261},\n  year={2016}\n}\n@inproceedings{he2016identity,\n  title={Identity mappings in deep residual networks},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle={European Conference on Computer Vision},\n  pages={630--645},\n  year={2016},\n  organization={Springer}\n}\n@inproceedings{he2016deep,\n  title={Deep residual learning for image recognition},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={770--778},\n  year={2016}\n}\n@inproceedings{szegedy2015going,\n  title={Going deeper with convolutions},\n  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={1--9},\n  year={2015}\n}\n@article{simonyan2014very,\n  title={Very deep convolutional networks for large-scale image recognition},\n  author={Simonyan, Karen and Zisserman, Andrew},\n  journal={arXiv preprint arXiv:1409.1556},\n  year={2014}\n}\n@inproceedings{he2014spatial,\n  title={Spatial pyramid pooling in deep convolutional networks for visual recognition},\n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle={European Conference on Computer Vision},\n  pages={346--361},\n  year={2014},\n  organization={Springer}\n}\n@article{chatfield2014return,\n  title={Return of the devil in the details: Delving deep into convolutional nets},\n  author={Chatfield, Ken and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},\n  journal={arXiv preprint arXiv:1405.3531},\n  year={2014}\n}\n@article{sermanet2013overfeat,\n  title={Overfeat: Integrated recognition, localization and detection using convolutional networks},\n  author={Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Micha{\\\"e}l and Fergus, Rob and LeCun, Yann},\n  journal={arXiv preprint arXiv:1312.6229},\n  year={2013}\n}\n@article{goodfellow2013maxout,\n  title={Maxout Networks.},\n  author={Goodfellow, Ian J and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron C and Bengio, Yoshua},\n  journal={ICML (3)},\n  volume={28},\n  pages={1319--1327},\n  year={2013}\n}\n@article{lin2013network,\n  title={Network in network},\n  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},\n  journal={arXiv preprint arXiv:1312.4400},\n  year={2013}\n}\n@inproceedings{krizhevsky2012imagenet,\n  title={Imagenet classification with deep convolutional neural networks},\n  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},\n  booktitle={Advances in neural information processing systems},\n  pages={1097--1105},\n  year={2012}\n}\n@inproceedings{redmon2016you,\n  title={You only look once: Unified, real-time object detection},\n  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={779--788},\n  year={2016}\n}\n@article{girshick2016region,\n  title={Region-based convolutional networks for accurate object detection and segmentation},\n  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={38},\n  number={1},\n  pages={142--158},\n  year={2016},\n  publisher={IEEE}\n}\n@inproceedings{long2015fully,\n  title={Fully convolutional networks for semantic segmentation},\n  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3431--3440},\n  year={2015}\n}\n@inproceedings{ren2015faster,\n  title={Faster r-cnn: Towards real-time object detection with region proposal networks},\n  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},\n  booktitle={Advances in neural information processing systems},\n  pages={91--99},\n  year={2015}\n}\n@inproceedings{girshick2015fast,\n  title={Fast r-cnn},\n  author={Girshick, Ross},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={1440--1448},\n  year={2015}\n}\n@inproceedings{girshick2014rich,\n  title={Rich feature hierarchies for accurate object detection and semantic segmentation},\n  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={580--587},\n  year={2014}\n}\n@article{chen2014semantic,\n  title={Semantic image segmentation with deep convolutional nets and fully connected crfs},\n  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},\n  journal={arXiv preprint arXiv:1412.7062},\n  year={2014}\n}\n@article{farabet2013learning,\n  title={Learning hierarchical features for scene labeling},\n  author={Farabet, Clement and Couprie, Camille and Najman, Laurent and LeCun, Yann},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={35},\n  number={8},\n  pages={1915--1929},\n  year={2013},\n  publisher={IEEE}\n}\n@article{dong2016image,\n  title={Image super-resolution using deep convolutional networks},\n  author={Dong, Chao and Loy, Chen Change and He, Kaiming and Tang, Xiaoou},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={38},\n  number={2},\n  pages={295--307},\n  year={2016},\n  publisher={IEEE}\n}\n@article{gatys2015neural,\n  title={A neural algorithm of artistic style},\n  author={Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},\n  journal={arXiv preprint arXiv:1508.06576},\n  year={2015}\n}\n@inproceedings{karpathy2015deep,\n  title={Deep visual-semantic alignments for generating image descriptions},\n  author={Karpathy, Andrej and Fei-Fei, Li},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3128--3137},\n  year={2015}\n}\n@inproceedings{xu2015show,\n  title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.},\n  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron C and Salakhutdinov, Ruslan and Zemel, Richard S and Bengio, Yoshua},\n  booktitle={ICML},\n  volume={14},\n  pages={77--81},\n  year={2015}\n}\n@inproceedings{vinyals2015show,\n  title={Show and tell: A neural image caption generator},\n  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={3156--3164},\n  year={2015}\n}\n@inproceedings{donahue2015long,\n  title={Long-term recurrent convolutional networks for visual recognition and description},\n  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},\n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n  pages={2625--2634},\n  year={2015}\n}\n@inproceedings{antol2015vqa,\n  title={Vqa: Visual question answering},\n  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={2425--2433},\n  year={2015}\n}\n@inproceedings{taigman2014deepface,\n  title={Deepface: Closing the gap to human-level performance in face verification},\n  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={1701--1708},\n  year={2014}\n}\n@inproceedings{karpathy2014large,\n  title={Large-scale video classification with convolutional neural networks},\n  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},\n  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},\n  pages={1725--1732},\n  year={2014}\n}\n@inproceedings{toshev2014deeppose,\n  title={Deeppose: Human pose estimation via deep neural networks},\n  author={Toshev, Alexander and Szegedy, Christian},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={1653--1660},\n  year={2014}\n}\n@inproceedings{simonyan2014two,\n  title={Two-stream convolutional networks for action recognition in videos},\n  author={Simonyan, Karen and Zisserman, Andrew},\n  booktitle={Advances in neural information processing systems},\n  pages={568--576},\n  year={2014}\n}\n@article{ji20133d,\n  title={3D convolutional neural networks for human action recognition},\n  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},\n  journal={IEEE transactions on pattern analysis and machine intelligence},\n  volume={35},\n  number={1},\n  pages={221--231},\n  year={2013},\n  publisher={IEEE}\n}\n@inproceedings{zheng2015conditional,\n  title={Conditional random fields as recurrent neural networks},\n  author={Zheng, Shuai and Jayasumana, Sadeep and Romera-Paredes, Bernardino and Vineet, Vibhav and Su, Zhizhong and Du, Dalong and Huang, Chang and Torr, Philip HS},\n  booktitle={Proceedings of the IEEE International Conference on Computer Vision},\n  pages={1529--1537},\n  year={2015}\n}\n@article{weston2014memory,\n  title={Memory networks},\n  author={Weston, Jason and Chopra, Sumit and Bordes, Antoine},\n  journal={arXiv preprint arXiv:1410.3916},\n  year={2014}\n}\n@article{graves2014neural,\n  title={Neural turing machines},\n  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},\n  journal={arXiv preprint arXiv:1410.5401},\n  year={2014}\n}\n@article{graves2013generating,\n  title={Generating sequences with recurrent neural networks},\n  author={Graves, Alex},\n  journal={arXiv preprint arXiv:1308.0850},\n  year={2013}\n}\n@article{chung2016character,\n  title={A character-level decoder without explicit segmentation for neural machine translation},\n  author={Chung, Junyoung and Cho, Kyunghyun and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1603.06147},\n  year={2016}\n}\n@article{jozefowicz2016exploring,\n  title={Exploring the limits of language modeling},\n  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},\n  journal={arXiv preprint arXiv:1602.02410},\n  year={2016}\n}\n@inproceedings{hermann2015teaching,\n  title={Teaching machines to read and comprehend},\n  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={1693--1701},\n  year={2015}\n}\n@article{luong2015effective,\n  title={Effective approaches to attention-based neural machine translation},\n  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},\n  journal={arXiv preprint arXiv:1508.04025},\n  year={2015}\n}\n@article{bahdanau2014neural,\n  title={Neural machine translation by jointly learning to align and translate},\n  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1409.0473},\n  year={2014}\n}\n@inproceedings{sutskever2014sequence,\n  title={Sequence to sequence learning with neural networks},\n  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},\n  booktitle={Advances in neural information processing systems},\n  pages={3104--3112},\n  year={2014}\n}\n@article{cho2014learning,\n  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},\n  author={Cho, Kyunghyun and Van Merri{\\\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1406.1078},\n  year={2014}\n}\n@article{kalchbrenner2014convolutional,\n  title={A convolutional neural network for modelling sentences},\n  author={Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},\n  journal={arXiv preprint arXiv:1404.2188},\n  year={2014}\n}\n@article{kim2014convolutional,\n  title={Convolutional neural networks for sentence classification},\n  author={Kim, Yoon},\n  journal={arXiv preprint arXiv:1408.5882},\n  year={2014}\n}\n@inproceedings{pennington2014glove,\n  title={Glove: Global Vectors for Word Representation.},\n  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},\n  booktitle={EMNLP},\n  volume={14},\n  pages={1532--1543},\n  year={2014}\n}\n@inproceedings{le2014distributed,\n  title={Distributed Representations of Sentences and Documents.},\n  author={Le, Quoc V and Mikolov, Tomas},\n  booktitle={ICML},\n  volume={14},\n  pages={1188--1196},\n  year={2014}\n}\n@inproceedings{mikolov2013distributed,\n  title={Distributed representations of words and phrases and their compositionality},\n  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},\n  booktitle={Advances in neural information processing systems},\n  pages={3111--3119},\n  year={2013}\n}\n@article{mikolov2013efficient,\n  title={Efficient estimation of word representations in vector space},\n  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},\n  journal={arXiv preprint arXiv:1301.3781},\n  year={2013}\n}\n@inproceedings{socher2013recursive,\n  title={Recursive deep models for semantic compositionality over a sentiment treebank},\n  author={Socher, Richard and Perelygin, Alex and Wu, Jean Y and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher and others},\n  booktitle={Proceedings of the conference on empirical methods in natural language processing (EMNLP)},\n  volume={1631},\n  pages={1642},\n  year={2013},\n  organization={Citeseer}\n}\n@inproceedings{bahdanau2016end,\n  title={End-to-end attention-based large vocabulary speech recognition},\n  author={Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Brakel, Philemon and Bengio, Yoshua},\n  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on},\n  pages={4945--4949},\n  year={2016},\n  organization={IEEE}\n}\n@article{amodei2015deep,\n  title={Deep speech 2: End-to-end speech recognition in english and mandarin},\n  author={Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and others},\n  journal={arXiv preprint arXiv:1512.02595},\n  year={2015}\n}\n@inproceedings{graves2013speech,\n  title={Speech recognition with deep recurrent neural networks},\n  author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},\n  booktitle={Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},\n  pages={6645--6649},\n  year={2013},\n  organization={IEEE}\n}\n@article{hinton2012deep,\n  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},\n  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},\n  journal={IEEE Signal Processing Magazine},\n  volume={29},\n  number={6},\n  pages={82--97},\n  year={2012},\n  publisher={IEEE}\n}\n@article{dahl2012context,\n  title={Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition},\n  author={Dahl, George E and Yu, Dong and Deng, Li and Acero, Alex},\n  journal={IEEE Transactions on Audio, Speech, and Language Processing},\n  volume={20},\n  number={1},\n  pages={30--42},\n  year={2012},\n  publisher={IEEE}\n}\n@article{mohamed2012acoustic,\n  title={Acoustic modeling using deep belief networks},\n  author={Mohamed, Abdel-rahman and Dahl, George E and Hinton, Geoffrey},\n  journal={IEEE Transactions on Audio, Speech, and Language Processing},\n  volume={20},\n  number={1},\n  pages={14--22},\n  year={2012},\n  publisher={IEEE}\n}\n@article{levine2016end,\n  title={End-to-end training of deep visuomotor policies},\n  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},\n  journal={Journal of Machine Learning Research},\n  volume={17},\n  number={39},\n  pages={1--40},\n  year={2016}\n}\n@article{levine2016learning,\n  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},\n  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Quillen, Deirdre},\n  journal={arXiv preprint arXiv:1603.02199},\n  year={2016}\n}\n@inproceedings{mnih2016asynchronous,\n  title={Asynchronous methods for deep reinforcement learning},\n  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},\n  booktitle={International Conference on Machine Learning},\n  year={2016}\n}\n@inproceedings{van2016deep,\n  title={Deep Reinforcement Learning with Double Q-Learning.},\n  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},\n  booktitle={AAAI},\n  pages={2094--2100},\n  year={2016}\n}\n@article{silver2016mastering,\n  title={Mastering the game of Go with deep neural networks and tree search},\n  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},\n  journal={Nature},\n  volume={529},\n  number={7587},\n  pages={484--489},\n  year={2016},\n  publisher={Nature Publishing Group}\n}\n@article{lillicrap2015continuous,\n  title={Continuous control with deep reinforcement learning},\n  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},\n  journal={arXiv preprint arXiv:1509.02971},\n  year={2015}\n}\n@article{mnih2015human,\n  title={Human-level control through deep reinforcement learning},\n  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},\n  journal={Nature},\n  volume={518},\n  number={7540},\n  pages={529--533},\n  year={2015},\n  publisher={Nature Research}\n}\n@article{lenz2015deep,\n  title={Deep learning for detecting robotic grasps},\n  author={Lenz, Ian and Lee, Honglak and Saxena, Ashutosh},\n  journal={The International Journal of Robotics Research},\n  volume={34},\n  number={4-5},\n  pages={705--724},\n  year={2015},\n  publisher={SAGE Publications Sage UK: London, England}\n}\n@article{mnih2013playing,\n  title={Playing atari with deep reinforcement learning},\n  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},\n  journal={arXiv preprint arXiv:1312.5602},\n  year={2013}\n}\n@article{ba2016layer,\n  title={Layer normalization},\n  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},\n  journal={arXiv preprint arXiv:1607.06450},\n  year={2016}\n}\n@inproceedings{andrychowicz2016learning,\n  title={Learning to learn by gradient descent by gradient descent},\n  author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and de Freitas, Nando},\n  booktitle={Advances in Neural Information Processing Systems},\n  pages={3981--3989},\n  year={2016}\n}\n@article{ganin2016domain,\n  title={Domain-adversarial training of neural networks},\n  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\\c{c}}ois and Marchand, Mario and Lempitsky, Victor},\n  journal={Journal of Machine Learning Research},\n  volume={17},\n  number={59},\n  pages={1--35},\n  year={2016}\n}\n@article{van2016wavenet,\n  title={Wavenet: A generative model for raw audio},\n  author={van den Oord, A{\\\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},\n  journal={CoRR abs/1609.03499},\n  year={2016}\n}\n@inproceedings{zhang2016colorful,\n  title={Colorful image colorization},\n  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},\n  booktitle={European Conference on Computer Vision},\n  pages={649--666},\n  year={2016},\n  organization={Springer}\n}\n@inproceedings{zhu2016generative,\n  title={Generative visual manipulation on the natural image manifold},\n  author={Zhu, Jun-Yan and Kr{\\\"a}henb{\\\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A},\n  booktitle={European Conference on Computer Vision},\n  pages={597--613},\n  year={2016},\n  organization={Springer}\n}\n@inproceedings{ulyanov2016texture,\n  title={Texture networks: Feed-forward synthesis of textures and stylized images},\n  author={Ulyanov, Dmitry and Lebedev, Vadim and Vedaldi, Andrea and Lempitsky, Victor},\n  booktitle={Int. Conf. on Machine Learning (ICML)},\n  year={2016}\n}\n@inproceedings{liu2016ssd,\n  title={SSD: Single shot multibox detector},\n  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},\n  booktitle={European Conference on Computer Vision},\n  pages={21--37},\n  year={2016},\n  organization={Springer}\n}\n@article{iandola2016squeezenet,\n  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},\n  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},\n  journal={arXiv preprint arXiv:1602.07360},\n  year={2016}\n}\n@inproceedings{han2016eie,\n  title={EIE: efficient inference engine on compressed deep neural network},\n  author={Han, Song and Liu, Xingyu and Mao, Huizi and Pu, Jing and Pedram, Ardavan and Horowitz, Mark A and Dally, William J},\n  booktitle={Proceedings of the 43rd International Symposium on Computer Architecture},\n  pages={243--254},\n  year={2016},\n  organization={IEEE Press}\n}\n@article{courbariaux2016binarized,\n  title={Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},\n  author={Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},\n  journal={arXiv preprint arXiv:1602.02830},\n  year={2016}\n}\n@article{xiong2016dynamic,\n  title={Dynamic memory networks for visual and textual question answering},\n  author={Xiong, Caiming and Merity, Stephen and Socher, Richard},\n  journal={arXiv},\n  volume={1603},\n  year={2016}\n}\n@inproceedings{yang2016stacked,\n  title={Stacked attention networks for image question answering},\n  author={Yang, Zichao and He, Xiaodong and Gao, Jianfeng and Deng, Li and Smola, Alex},\n  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},\n  pages={21--29},\n  year={2016}\n}\n@article{graves2016hybrid,\n  title={Hybrid computing using a neural network with dynamic external memory},\n  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\\'n}ska, Agnieszka and Colmenarejo, Sergio G{\\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},\n  journal={Nature},\n  volume={538},\n  number={7626},\n  pages={471--476},\n  year={2016},\n  publisher={Nature Research}\n}\n@article{wu2016google,\n  title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation},\n  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},\n  journal={arXiv preprint arXiv:1609.08144},\n  year={2016}\n}\n"
        }
      ]
    }
  ]
}