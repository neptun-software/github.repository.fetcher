{
  "metadata": {
    "timestamp": 1736563350966,
    "page": 344,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "marcotcr/lime",
      "stars": 11697,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.33203125,
          "content": "# Compiled python modules.\n*.pyc\n\n# Setuptools distribution folder.\n/dist/\n\n/lime/node_modules\n\n# Python egg metadata, regenerated from source files by setuptools.\n/*.egg-info\n\n# Unit test / coverage reports\n.cache\n\n# Created by https://www.gitignore.io/api/pycharm\n\n### PyCharm ###\n# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio and Webstorm\n# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839\n\n# User-specific stuff:\n.idea/workspace.xml\n.idea/tasks.xml\n.idea/dictionaries\n.idea/vcs.xml\n.idea/jsLibraryMappings.xml\n\n# Sensitive or high-churn files:\n.idea/dataSources.ids\n.idea/dataSources.xml\n.idea/dataSources.local.xml\n.idea/sqlDataSources.xml\n.idea/dynamic.xml\n.idea/uiDesigner.xml\n\n# Gradle:\n.idea/gradle.xml\n.idea/libraries\n\n# Mongo Explorer plugin:\n.idea/mongoSettings.xml\n\n## File-based project format:\n*.iws\n\n## Plugin-specific files:\n\n# IntelliJ\n/out/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n### PyCharm Patch ###\n# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721\n\n# *.iml\n# modules.xml\n# .idea/misc.xml \n# *.ipr\n\n# Pycharm\n.idea\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.25,
          "content": "dist: xenial\nsudo: false\nlanguage: python\ncache: pip\npython:\n  - \"3.6\"\n  - \"3.7\"\n# command to install dependencies\ninstall:\n  - python -m pip install -U pip\n  - python -m pip install -e .[dev]\n# command to run tests\nscript:\n  - pytest lime\n  - flake8 lime\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.8232421875,
          "content": "## Contributing\nI am delighted when people want to contribute to LIME. Here are a few things to keep in mind before sending in a pull request:\n* We are now using flake8 as a style guide enforcer (I plan on adding eslint for javascript soon). Make sure your code passes the default flake8 execution.\n* There must be a really good reason to change the external interfaces - I want to avoid breaking previous code as much as possible.\n* If you are adding a new feature, please let me know the use case and the rationale behind how you did it (unless it's obvious)\n\nIf you want to contribute but don't know where to start, take a look at the [issues page](https://github.com/marcotcr/lime/issues), or at the list below.\n\n# Roadmap\nHere are a few high level features I want to incorporate in LIME. If you want to work incrementally in any of these, feel free to start a branch.\n\n1. Creating meaningful tests that we can run before merging things. Right now I run the example notebooks and the few tests we have.\n2. Creating a wrapper that computes explanations for a particular dataset, and suggests instances for the user to look at (similar to what we did in [the paper](http://arxiv.org/abs/1602.04938))\n3. Making LIME work with images in a reasonable time. The explanations we used in the paper took a few minutes, which is too slow.\n4. Thinking through what is needed to use LIME in regression problems. An obvious problem is that features with different scales make it really hard to interpret.\n5. Figuring out better alternatives to discretizing the data for tabular data. Discretizing is definitely more interpretable, but we may just want to treat features as continuous.\n6. Figuring out better ways to sample around a data point for tabular data. One example is sampling columns from the training set assuming independence, or some form of conditional sampling.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.279296875,
          "content": "Copyright (c) 2016, Marco Tulio Correia Ribeiro\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.033203125,
          "content": "include lime/*.js\ninclude LICENSE\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.634765625,
          "content": "# lime\n\n[![Build Status](https://travis-ci.org/marcotcr/lime.svg?branch=master)](https://travis-ci.org/marcotcr/lime)\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/marcotcr/lime/master)\n\nThis project is about explaining what machine learning classifiers (or models) are doing.\nAt the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or images, with a package called lime (short for local interpretable model-agnostic explanations).\nLime is based on the work presented in [this paper](https://arxiv.org/abs/1602.04938) ([bibtex here for citation](https://github.com/marcotcr/lime/blob/master/citation.bib)). Here is a link to the promo video:\n\n<a href=\"https://www.youtube.com/watch?v=hUnRCxnydCc\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/video_screenshot.png\" width=\"450\" alt=\"KDD promo video\"/></a>\n\nOur plan is to add more packages that help users understand and interact meaningfully with machine learning.\n\nLime is able to explain any black box classifier, with two or more classes. All we require is that the classifier implements a function that takes in raw text or a numpy array and outputs a probability for each class. Support for scikit-learn classifiers is built-in.\n\n## Installation\n\nThe lime package is on [PyPI](https://pypi.python.org/pypi/lime). Simply run:\n\n```sh\npip install lime\n```\n\nOr clone the repository and run:\n\n```sh\npip install .\n```\n\nWe dropped python2 support in `0.2.0`, `0.1.1.37` was the last version before that.\n\n## Screenshots\n\nBelow are some screenshots of lime explanations. These are generated in html, and can be easily produced and embedded in ipython notebooks. We also support visualizations using matplotlib, although they don't look as nice as these ones.\n\n#### Two class case, text\n\nNegative (blue) words indicate atheism, while positive (orange) words indicate christian. The way to interpret the weights by applying them to the prediction probabilities. For example, if we remove the words Host and NNTP from the document, we expect the classifier to predict atheism with probability 0.58 - 0.14 - 0.11 = 0.31.\n\n![twoclass](doc/images/twoclass.png)\n\n#### Multiclass case\n\n![multiclass](doc/images/multiclass.png)\n\n#### Tabular data\n\n![tabular](doc/images/tabular.png)\n\n#### Images (explaining prediction of 'Cat' in pros and cons)\n\n<img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/images.png\" width=200 />\n\n## Tutorials and API\n\nFor example usage for text classifiers, take a look at the following two tutorials (generated from ipython notebooks):\n\n- [Basic usage, two class. We explain random forest classifiers.](https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html)\n- [Multiclass case](https://marcotcr.github.io/lime/tutorials/Lime%20-%20multiclass.html)\n\nFor classifiers that use numerical or categorical data, take a look at the following tutorial (this is newer, so please let me know if you find something wrong):\n\n- [Tabular data](https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20continuous%20and%20categorical%20features.html)\n- [Tabular data with H2O models](https://marcotcr.github.io/lime/tutorials/Tutorial_H2O_continuous_and_cat.html)\n- [Latin Hypercube Sampling](doc/notebooks/Latin%20Hypercube%20Sampling.ipynb)\n\nFor image classifiers:\n\n- [Images - basic](https://marcotcr.github.io/lime/tutorials/Tutorial%20-%20images.html)\n- [Images - Faces](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Faces%20and%20GradBoost.ipynb)\n- [Images with Keras](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20Image%20Classification%20Keras.ipynb)\n- [MNIST with random forests](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20MNIST%20and%20RF.ipynb)\n- [Images with PyTorch](https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20images%20-%20Pytorch.ipynb)\n\nFor regression:\n\n- [Simple regression](https://marcotcr.github.io/lime/tutorials/Using%2Blime%2Bfor%2Bregression.html)\n\nSubmodular Pick:\n\n- [Submodular Pick](https://github.com/marcotcr/lime/tree/master/doc/notebooks/Submodular%20Pick%20examples.ipynb)\n\nThe raw (non-html) notebooks for these tutorials are available [here](https://github.com/marcotcr/lime/tree/master/doc/notebooks).\n\nThe API reference is available [here](https://lime-ml.readthedocs.io/en/latest/).\n\n## What are explanations?\n\nIntuitively, an explanation is a local linear approximation of the model's behaviour.\nWhile the model may be very complex globally, it is easier to approximate it around the vicinity of a particular instance.\nWhile treating the model as a black box, we perturb the instance we want to explain and learn a sparse linear model around it, as an explanation.\nThe figure below illustrates the intuition for this procedure. The model's decision function is represented by the blue/pink background, and is clearly nonlinear.\nThe bright red cross is the instance being explained (let's call it X).\nWe sample instances around X, and weight them according to their proximity to X (weight here is indicated by size).\nWe then learn a linear model (dashed line) that approximates the model well in the vicinity of X, but not necessarily globally. For more information, [read our paper](https://arxiv.org/abs/1602.04938), or take a look at [this blog post](https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime).\n\n<img src=\"https://raw.githubusercontent.com/marcotcr/lime/master/doc/images/lime.png\" width=300px />\n\n## Contributing\n\nPlease read [this](CONTRIBUTING.md).\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "citation.bib",
          "type": "blob",
          "size": 0.451171875,
          "content": "@inproceedings{lime,\n  author    = {Marco Tulio Ribeiro and\n               Sameer Singh and\n               Carlos Guestrin},\n  title     = {\"Why Should {I} Trust You?\": Explaining the Predictions of Any Classifier},\n  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on\n               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August\n               13-17, 2016},\n  pages     = {1135--1144},\n  year      = {2016},\n}\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "lime",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.029296875,
          "content": "[flake8]\nmax-line-length = 100"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.7578125,
          "content": "from setuptools import setup, find_packages\n\nsetup(name='lime',\n      version='0.2.0.1',\n      description='Local Interpretable Model-Agnostic Explanations for machine learning classifiers',\n      url='http://github.com/marcotcr/lime',\n      author='Marco Tulio Ribeiro',\n      author_email='marcotcr@gmail.com',\n      license='BSD',\n      packages=find_packages(exclude=['js', 'node_modules', 'tests']),\n      python_requires='>=3.5',\n      install_requires=[\n          'matplotlib',\n          'numpy',\n          'scipy',\n          'tqdm >= 4.29.1',\n          'scikit-learn>=0.18',\n          'scikit-image>=0.12',\n          'pyDOE2==1.3.0'\n      ],\n      extras_require={\n          'dev': ['pytest', 'flake8'],\n      },\n      include_package_data=True,\n      zip_safe=False)\n"
        }
      ]
    }
  ]
}