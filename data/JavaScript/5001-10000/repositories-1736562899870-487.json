{
  "metadata": {
    "timestamp": 1736562899870,
    "page": 487,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Shaunwei/RealChar",
      "stars": 6065,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".env.example",
          "type": "blob",
          "size": 4.474609375,
          "content": "# ----------------------- Language Model Configurations -----------------------\n# Option 1: ReByte Agents (Recommended)\n# Obtain your ReByte API key at https://rebyte.ai > Settings > API Keys\nREBYTE_API_KEY=YOUR_API_KEY\n\n# Option 2: Alternate LLM APIs\n# Supported APIs: OpenAI, Anthropic, Anyscale, Local LLM with Openai Compatiable API\n# Example values:\n# OpenAI: \"gpt-4\", \"gpt-3.5-turbo-16k\", etc.\n# Anthropic: \"claude-instant-1\", \"claude-2\", etc.\n# Anyscale: \"meta-llama/Llama-2-70b-chat-hf\", etc.\n# Local LLM: \"localhost\"\n# LLM_MODEL_USE overwrites frontend choices! Leave empty unless you know what you're doing!\n# LLM_MODEL_USE overwrites frontend choices! Leave empty unless you know what you're doing!\n# LLM_MODEL_USE overwrites frontend choices! Leave empty unless you know what you're doing!\n# LLM_MODEL_USE=gpt-3.5-turbo-16k\n\n# API Keys\n# Note that if not using ReByte, an OPENAI_API_KEY is required for generating embeddings for\n# the knowledge base, no matter what LLM API is being used\n# OPENAI_API_KEY=YOUR_API_KEY\n# ANTHROPIC_API_KEY=YOUR_API_KEY\n# ANYSCALE_ENDPOINT_API_KEY=YOUR_API_KEY\n\n# Local LLM Configuration (with Openai Compatiable API)\n# Example URL: \"http://localhost:8001/v1\"\n# LOCAL_LLM_URL=\n\n# Option 3: Azure OpenAI API\n# For Azure OpenAI, uncomment and set the following entries\n# OPENAI_API_TYPE=azure\n# OPENAI_API_VERSION=2023-03-15-preview\n# Base URL found in the Azure portal under your Azure OpenAI resource\n# OPENAI_API_BASE=https://your-base-url.openai.azure.com\n# OPENAI_API_MODEL_DEPLOYMENT_NAME=gpt-35-turbo\n# OPENAI_API_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002\n\n# ----------------------- Speech to Text Configurations -----------------------\n# Choose engine: LOCAL_WHISPER, LOCAL_WHISPER_X (recommended), WHISPER_X_API, OPENAI_WHISPER, GOOGLE\nSPEECH_TO_TEXT_USE=LOCAL_WHISPER\n\n# Local Whisper Configuration\n# Choose model: \"tiny\", \"base\" (recommended), \"small\", \"medium\", \"large\"\nLOCAL_WHISPER_MODEL=base\n# Uncomment if OpenCC is installed. Set to s2t for traditional Chinese, t2s for simplified Chinese\n# OPENCC=\n# Journal Mode (Optional)\n# Journal mode is resource intensive, only enable if you have GPU and plenty of RAM\n# JOURNAL_MODE=false\n# Obtain HuggingFace ACCESS TOKEN at https://huggingface.co/settings/tokens\n# Grant access to required models. See https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization\n# HF_ACCESS_TOKEN=YOUR_API_KEY\n\n# Whisper X API Configuration\n# WHISPER_X_API_URL=\n# WHISPER_X_API_URL_JOURNAL=\n# WHISPER_X_API_KEY=YOUR_API_KEY\n\n# OpenAI Whisper API Configuration\n# OPENAI_WHISPER_API_KEY=YOUR_API_KEY\n\n# Google Speech to Text API Configuration\n# GOOGLE_APPLICATION_CREDENTIALS=google_credentials.json\n\n# ----------------------- Text to Speech Configurations -----------------------\n# Edge TTS Configuration\nEDGE_TTS_DEFAULT_VOICE=en-US-ChristopherNeural\n\n# Eleven Labs Configuration\n# ELEVEN_LABS_API_KEY=YOUR_API_KEY\n# Set to \"true\" for V2 model access\n# ELEVEN_LABS_USE_V2=true\n\n# Google Text to Speech API Configuration\n# GOOGLE_APPLICATION_CREDENTIALS=google_credentials.json\n\n# XTTS Configuration\n# XTTS_API_KEY=YOUR_API_KEY\n# XTTS_API_URL=\n\n# -------------------------- Database Configurations --------------------------\n# SQLite Database URL (to initialize database see README)\n# Format: sqlite:///<path_to_db_file>\nDATABASE_URL=sqlite:///./test.db\n\n# -------------------------- Optional Configurations --------------------------\n# Firebase Configuration\n# Enable user login by setting USE_AUTH to \"true\", leave empty to disable\n# Obtain Firebase credentials from https://console.firebase.google.com\n# USE_AUTH=true\n# FIREBASE_CONFIG_PATH=firebase_credentials.json\n\n# Google Cloud Storage\n# Use default for RealChar provided characters\n# Use your own bucket to enable uploading avatars, audios and knowledges for your own characters\n# You'll need to create a bucket in Google Cloud Storage and login to gcloud CLI locally\nGCP_STORAGE_URL=https://storage.googleapis.com/assistly\nGCP_STORAGE_BUCKET_NAME=assistly\n\n# LLM Tracing\n# LANGCHAIN_TRACING_V2=false # Default: off\n# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n# LANGCHAIN_API_KEY=YOUR_LANGCHAIN_API_KEY\n# LANGCHAIN_PROJECT=YOUR_LANGCHAIN_PROJECT\n\n# Knowledge Base (Character Catalog)\n# Set to \"false\" to skip updating the knowledge base on startup, else force update. Default: true\n# OVERWRITE_CHROMA=false\n\n# Twilio Integration\n# Obtain Account SID and Auth Token from https://console.twilio.com\n# Use a number you own for outgoing calls\n# TWILIO_ACCOUNT_SID=\n# TWILIO_ACCESS_TOKEN=\n# DEFAULT_CALLOUT_NUMBER=\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.18359375,
          "content": ".vscode/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/#use-with-ide\n.pdm.toml\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env*\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# local database\n*.db\n*.prompt\n\n.DS_Store\n.python-version\n.chroma\n*.ipynb\ngoogle_credentials.json\nfirebase_credentials.json\n\n./node_modules\n\n# scripts\nreset_database.sh\n\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.33984375,
          "content": "repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.0.278\n    hooks:\n      - id: ruff\n  # pre-commit run prettier -a\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.0.1\n    hooks:\n      - id: prettier\n        types_or: [css, javascript, jsx, ts, tsx]\n        args: [--config, client/next-web/.prettierrc]\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.6728515625,
          "content": "# ChangeLog\n\n## [v0.0.1] - 2023-07-19\nRelease Highlights:\n\n### Product releases and updates:\n- iOS App TestFlight public beta (link https://testflight.apple.com/join/JA6p9sZQ)\n- Rewrite Web codebase from vanilla JavaScript to use React framework w/ Javascript\n- Support Unicode in chat messages\n- Various UI refinements\n\n### Integration updates:\n- Support Azure OpenAI\n\n### Observability and quality updates:\n- Support Integration with LangSmith\n- Reduce Docker rebuild time to ~2 seconds\n- Support string based user ID\n- Support Session ID, Platform, Action Type in database records.\n\n### New Tutorial:\n[How to make your own AI character and run it locally](https://youtu.be/meg5Q8vdWeQ)\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.92578125,
          "content": "FROM python:3.11-slim\n\n# Install dependencies necessary to build and run FFmpeg\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    pkg-config \\\n    yasm \\\n    git \\\n    curl \\\n    portaudio19-dev \\\n    libffi-dev \\\n    libssl-dev \\\n    libx264-dev \\\n    libopus-dev\n\nRUN echo \"deb http://deb.debian.org/debian/ bullseye main\\ndeb-src http://deb.debian.org/debian/ bullseye main\" | tee /etc/apt/sources.list.d/ffmpeg.list  &&\\\n    apt-get update && \\\n    apt-get install -y ffmpeg\n\n\nWORKDIR /realtime_ai_character\n\n# Install Python dependencies\nCOPY requirements.txt /realtime_ai_character\nRUN pip install -r /realtime_ai_character/requirements.txt\n\n# Copy the project files\nCOPY ./ /realtime_ai_character\n\n# Expose 8000 port from the docker image.\nEXPOSE 8000\n\n# Make the entrypoint script executable\nRUN chmod +x /realtime_ai_character/entrypoint.sh\n\n# Run the application\nCMD [\"/bin/sh\", \"/realtime_ai_character/entrypoint.sh\"]\n"
        },
        {
          "name": "Dockerfile.postgres",
          "type": "blob",
          "size": 0.6328125,
          "content": "# Use the official PostgreSQL image as a base\nFROM postgres:14.1-alpine\n\n# Install necessary packages to build the extension\nRUN apk add --no-cache \\\n    build-base \\\n    git \\\n    postgresql-dev\n\n# Clone and build pgvector\nRUN git clone https://github.com/ankane/pgvector.git \\\n    && cd pgvector \\\n    && make && make install\n\n# Cleanup unnecessary packages after installation\nRUN apk del build-base git postgresql-dev\n\nRUN echo \"CREATE EXTENSION vector;\" > /docker-entrypoint-initdb.d/init-vector-extension.sql\n\n# Set the shared preload libraries config\nRUN echo \"shared_preload_libraries='pgvector'\" >> /var/lib/postgresql/data/postgresql.conf\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.037109375,
          "content": "MIT License\n\nCopyright (c) 2023 shaun\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.7685546875,
          "content": "# <img src=\"https://storage.googleapis.com/assistly/static/realchar/realchar.svg\" height=\"24px\" style=\"padding-top:4px\"/>RealChar. - Your Realtime AI Character\n<br/>\n<div align=\"center\">\n    <img src=\"https://storage.googleapis.com/assistly/static/realchar/logo.png\" alt=\"RealChar-logo\" width=\"80%\"  style=\"padding: 40px\"/>\n</div>\n<br/>\n<p align=\"center\">\n  🎙️🤖<em>Create, customize and talk to your AI Character/Companion in realtime</em>🎙️🤖\n</p>\n\n<div align=\"center\">\n    <a href=\"https://realchar.ai/join-discord\">\n    <img src=\"https://img.shields.io/badge/discord-join%20chat-blue.svg?style=for-the-badge\" alt=\"Join our Discord\" height=\"20\">\n    </a>\n    <a href=\"https://twitter.com/agishaun\">\n    <img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/agishaun?style=for-the-badge\" height=\"20\">\n    <a href=\"https://github.com/Shaunwei/RealChar\">\n    <img alt=\"GitHub\" src=\"https://img.shields.io/github/stars/Shaunwei/RealChar?style=for-the-badge&color=gold\" height=\"20\">\n    </a>\n    <a href=\"https://github.com/Shaunwei/RealChar/commits/main\">\n    <img alt=\"GitHub\" src=\"https://img.shields.io/github/last-commit/Shaunwei/RealChar/main?style=for-the-badge\" height=\"20\">\n    </a>\n    <a href=\"https://github.com/Shaunwei/RealChar/blob/main/README.md\" target=\"_blank\">\n    <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=green&style=for-the-badge\" alt=\"License\" height=\"20\">\n    </a>\n    <a href=\"https://hub.docker.com/repository/docker/shaunly/real_char/general\" target=\"_blank\">\n    <img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/shaunly/real_char?style=for-the-badge\"  height=\"20\">\n    </a>\n</div>\n\n## ✨ Demo\nTry our site at [RealChar.ai](https://realchar.ai/)\n\nNot sure how to pronounce RealChar? Listen to this 👉 [audip](https://github.com/Shaunwei/RealChar/assets/6148473/45d4773c-eb4f-41e5-a162-f9513d650b76)\n\n### Demo 1 - with Santa Claus!\n\nhttps://github.com/Shaunwei/RealChar/assets/5101573/6b35a80e-5503-4850-973d-254039bd383c\n\n### Demo 2 - with AI Elon about cage fight!\n\nhttps://github.com/Shaunwei/RealChar/assets/5101573/5de0b023-6cf3-4947-84cb-596f429d109e\n\n### Demo 3 - with AI Raiden about AI and \"real\" memory\n\nhttps://github.com/Shaunwei/RealChar/assets/5101573/62a1f3d1-1166-4254-9119-97647be52c42\n\n\n\n__Demo settings: Web, GPT4, ElevenLabs with voice clone, Chroma, Google Speech to Text__\n\n## 🎯 Key Features\n- **Easy to use**: No coding required to create your own AI character.\n- **Customizable**: You can customize your AI character's personality, background, and even voice\n- **Realtime**: Talk to or message your AI character in realtime\n- **Multi-Platform**: You can talk to your AI character on web, terminal and mobile(Yes. we open source our mobile app)\n- **Most up-to-date AI**: We use the most up-to-date AI technology to power your AI character, including OpenAI, Anthropic Claude 2, Chroma, Whisper, ElevenLabs, etc.\n- **Modular**: You can easily swap out different modules to customize your flow. Less opinionated, more flexible. Great project to start your AI Engineering journey.\n\n## 🔬 Tech stack\n<div align=\"center\">\n    <img src=\"https://storage.googleapis.com/assistly/static/realchar/techstackv004.jpg\" alt=\"RealChar-tech-stack\" width=\"100%\"  style=\"padding: 20px\"/>\n</div>\n\n- ✅**Web**: [React JS](https://react.dev/), [Vanilla JS](http://vanilla-js.com/), [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)\n- ✅**Mobile**: [Swift](https://developer.apple.com/swift/), [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API)\n- ✅**Backend**: [FastAPI](https://fastapi.tiangolo.com/), [SQLite](https://www.sqlite.org/index.html), [Docker](https://www.docker.com/)\n- ✅**Data Ingestion**: [LlamaIndex](https://www.llamaindex.ai/), [Chroma](https://www.trychroma.com/)\n- ✅**LLM Orchestration**: [LangChain](https://langchain.com/), [Chroma](https://www.trychroma.com/)\n- ✅**LLM**: [ReByte](https://rebyte.ai/), [OpenAI GPT3.5/4](https://platform.openai.com/docs/api-reference/chat), [Anthropic Claude 2](https://docs.anthropic.com/claude/docs/getting-started-with-claude), [Anyscale Llama2](https://docs.endpoints.anyscale.com/supported-models/meta-llama-Llama-2-70b-chat-hf)\n- ✅**Speech to Text**: [Local WhisperX](https://github.com/m-bain/whisperX), [Local Whisper](https://github.com/openai/whisper), [OpenAI Whisper API](https://platform.openai.com/docs/api-reference/audio), [Google Speech to Text](https://cloud.google.com/speech-to-text/docs#docs)\n- ✅**Text to Speech**: [ElevenLabs](https://beta.elevenlabs.io/), [Edge TTS](https://github.com/rany2/edge-tts), [Google Text to Speech](https://cloud.google.com/text-to-speech?hl=en)\n- ✅**Voice Clone**: [ElevenLabs](https://beta.elevenlabs.io/voice-lab)\n\n## 📚 Comparison with existing products\n<div align=\"center\">\n    <img src=\"https://storage.googleapis.com/assistly/static/realchar/compare.png\">\n</div>\n\n## 📀 Quick Start - Installation via Docker\n\n1.  Create a new `.env` file\n    ```sh\n    cp .env.example .env\n    ```\n    Paste your API keys in `.env` file. A single [ReByte](#11-rebyte-api-key) or [OpenAI](#12-optional-openai-api-token) API key is enough to get started.\n    \n    You can also configure other API keys if you have them.\n\n1.  Start the app with `docker-compose.yaml`\n    ```sh\n    docker compose up\n    ```\n    If you have issues with docker (especially on a non-Linux machine), please refer to https://docs.docker.com/get-docker/ (installation) and https://docs.docker.com/desktop/troubleshoot/overview/ (troubleshooting).\n\n1.  Open http://localhost:3000 and enjoy the app!\n\n## 💿 Developers - Installation via Python\n- **Step 1**. Clone the repo\n   ```sh\n   git clone https://github.com/Shaunwei/RealChar.git && cd RealChar\n    ```\n- **Step 2**. Install requirements\n\n    Install [portaudio](https://people.csail.mit.edu/hubert/pyaudio/) and [ffmpeg](https://ffmpeg.org/download.html) for audio\n    ```sh\n    # for mac\n    brew install portaudio\n    brew install ffmpeg\n    ```\n    ```sh\n    # for ubuntu\n    sudo apt update\n    sudo apt install portaudio19-dev\n    sudo apt install ffmpeg\n    ```\n    Note: \n    \n    - `ffmpeg>=4.4` is needed to work with `torchaudio>=2.1.0`\n\n    - Mac users may need to add ffmpeg library path to `DYLD_LIBRARY_PATH` for torchaudio to work:\n        ```sh\n        export DYLD_LIBRARY_PATH=/opt/homebrew/lib:$DYLD_LIBRARY_PATH\n        ```\n    \n    Then install all python requirements\n    ```sh\n    pip install -r requirements.txt\n    ```\n    If you need a faster local speech to text, install whisperX\n    ```sh\n    pip install git+https://github.com/m-bain/whisperx.git\n    ```\n- **Step 3**. Create an empty [sqlite](https://www.sqlite.org/index.html) database if you have not done so before\n    ```sh\n    sqlite3 test.db \"VACUUM;\"\n    ```\n- **Step 4**. Run db upgrade\n    ```sh\n    alembic upgrade head\n    ```\n    This ensures your database schema is up to date. Please run this after every time you pull the main branch.\n- **Step 5**. Setup `.env`:\n    ```sh\n    cp .env.example .env\n    ```\n    Update API keys and configs following the instructions in the `.env` file.\n    > Note that some features require a working login system. You can get your own OAuth2 login for free with [Firebase](https://firebase.google.com/) if needed. To enable, set `USE_AUTH` to `true` and fill in the `FIREBASE_CONFIG_PATH` field. Also fill in Firebase configs in `client/next-web/.env`.\n- **Step 6**. Run backend server with `cli.py` or use uvicorn directly\n    ```sh\n    python cli.py run-uvicorn\n    # or\n    uvicorn realtime_ai_character.main:app\n    ```\n- **Step 7**. Run frontend client:\n    - web client:\n\n        Create an `.env` file under `client/next-web/`\n        ```sh\n        cp client/next-web/.env.example client/next-web/.env\n        ```\n        Adjust `.env` according to the instruction in `client/next-web/README.md`.\n        \n        Start the frontend server:\n        ```sh\n        python cli.py next-web-dev\n        # or\n        cd client/next-web && npm run dev\n        # or\n        cd client/next-web && npm run build && npm run start\n        ```\n        After running these commands, a local development server will start, and your default web browser will open a new tab/window pointing to this server (usually http://localhost:3000).\n    - (Optional) Terminal client:\n    \n        Run the following command in your terminal\n        ```sh\n        python client/cli.py\n        ```\n    - (Optional) mobile client:\n    \n        open `client/mobile/ios/rac/rac.xcodeproj/project.pbxproj` in Xcode and run the app\n- **Step 8**. Select one character to talk to, then start talking. Use **GPT4** for better conversation and **Wear headphone** for best audio(avoid echo)\n\nNote if you want to remotely connect to a RealChar server, SSL set up is required to establish the audio connection. \n\n## 👨‍🚀 API Keys and Configurations\n\n### 1. LLMs\n\n### 1.1 ReByte API Key\nTo get your ReByte API key, follow these steps:\n\n1. Go to the [ReByte website](https://rebyte.ai/) and sign up for an account if you haven't already.\n1. Once you're logged in, go to Settings > API Keys.\n1. Generate a new API key by clicking on the \"Generate\" button.\n\n### 1.2 (Optional) OpenAI API Token\n<details><summary>👇click me</summary>\nThis application utilizes the OpenAI API to access its powerful language model capabilities. In order to use the OpenAI API, you will need to obtain an API token.\n\nTo get your OpenAI API token, follow these steps:\n\n1. Go to the [OpenAI website](https://beta.openai.com/signup/) and sign up for an account if you haven't already.\n1. Once you're logged in, navigate to the [API keys page](https://beta.openai.com/account/api-keys).\n1. Generate a new API key by clicking on the \"Create API Key\" button.\n\n(Optional) To use Azure OpenAI API instead, refer to the following section:\n\n1. Set API type in your `.env` file:\n`OPENAI_API_TYPE=azure`\n\nIf you want to use the earlier version `2023-03-15-preview`:\n\n`OPENAI_API_VERSION=2023-03-15-preview`\n\n2. To set the base URL for your Azure OpenAI resource.\nYou can find this in the Azure portal under your Azure OpenAI resource.\n\n`OPENAI_API_BASE=https://your-base-url.openai.azure.com`\n\n3. To set the OpenAI model deployment name for your Azure OpenAI resource.\n\n`OPENAI_API_MODEL_DEPLOYMENT_NAME=gpt-35-turbo-16k`\n\n4. To set the OpenAIEmbeddings model deployment name for your Azure OpenAI resource.\n\n`OPENAI_API_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002`\n\n</details>\n\n### 1.3 (Optional) Anthropic(Claude 2) API Token\n<details><summary>👇click me</summary>\n\nTo get your Anthropic API token, follow these steps:\n\n1. Go to the [Anthropic website](https://docs.anthropic.com/claude/docs/getting-started-with-claude) and sign up for an account if you haven't already.\n1. Once you're logged in, navigate to the [API keys page](https://console.anthropic.com/account/keys).\n1. Generate a new API key by clicking on the \"Create Key\" button.\n</details>\n\n### 1.4 (Optional) Anyscale API Token\n<details><summary>👇click me</summary>\n\nTo get your Anyscale API token, follow these steps:\n\n1. Go to the [Anyscale website](https://www.anyscale.com/) and sign up for an account if you haven't already.\n1. Once you're logged in, navigate to the [Credentials page](https://app.endpoints.anyscale.com/credentials).\n1. Generate a new API key by clicking on the \"Generate credential\" button.\n</details>\n\n### 2. Speech to Text\n\nWe support [faster-whisper](https://github.com/SYSTRAN/faster-whisper) and [whisperX](https://github.com/m-bain/whisperX) as the local speech to text engines. Work with CPU and NVIDIA GPU.\n\n### 2.1 (Optional) Google Speech-to-Text API\n<details><summary>👇click me</summary>\n\nTo get your Google Cloud API credentials.json, follow these steps:\n\n1. Go to the [GCP website](https://cloud.google.com/speech-to-text/docs/before-you-begin) and sign up for an account if you haven't already.\n2. Follow the guide to create a project and enable Speech to Text API\n3. Put `google_credentials.json` in the root folder of this project. Check [Create and delete service account keys](https://cloud.google.com/iam/docs/keys-create-delete#iam-service-account-keys-create-console)\n4. Change `SPEECH_TO_TEXT_USE` to use `GOOGLE` in your `.env` file\n</details>\n\n### 2.2 (Optional) OpenAI Whisper API\n<details><summary>👇click me</summary>\n\nSame as [OpenAI API Token](#12-optional-openai-api-token)\n</details>\n\n### 3. Text to Speech\n\nEdge TTS is the default and is free to use.\n\n### 3.1 (Optional) ElevenLabs API Key\n<details><summary>👇click me</summary>\n\n1. Creating an ElevenLabs Account\n\n    Visit [ElevenLabs](https://beta.elevenlabs.io/) to create an account. You'll need this to access the text to speech and voice cloning features.\n\n1. In your Profile Setting, you can get an API Key.\n\n</details>\n\n### 3.2 (Optional) Google Text-to-Speech API\n\n<details><summary>👇click me</summary>\n\nTo get your Google Cloud API credentials.json, follow these steps:\n\n1. Go to the [GCP website](https://cloud.google.com/text-to-speech/docs/quickstart-client-libraries) and sign up for an account if you haven't already.\n2. Follow the guide to create a project and enable Text to Speech API\n3. Put `google_credentials.json` in the root folder of this project. Check [Create and delete service account keys](https://cloud.google.com/iam/docs/keys-create-delete#iam-service-account-keys-create-console)\n</details>\n\n## (Optional) 🔥 Create Your Own Characters\n<details><summary>👇click me</summary>\n\n### Create Characters Locally\nsee [realtime_ai_character/character_catalog/README.md](realtime_ai_character/character_catalog/README.md)\n\n### Create Characters on ReByte.ai\nsee [docs/rebyte_agent_clone_instructions.md](docs/rebyte_agent_clone_instructions.md)\n</details>\n\n## (Optional) ☎️ Twilio Integration\n<details><summary>👇click me</summary>\n\nTo use [Twilio](https://www.twilio.com/en-us) with RealChar, you need to set up a Twilio account. Then, fill in the following environment variables in your `.env` file:\n```sh\nTWILIO_ACCOUNT_SID=YOUR_TWILIO_ACCOUNT_SID\nTWILIO_ACCESS_TOKEN=YOUR_TWILIO_ACCESS_TOKEN\nDEFAULT_CALLOUT_NUMBER=YOUR_PHONE_NUMBER\n```\nYou'll also need to install `torch` and `torchaudio` to use Twilio.\n\nNow, you can receive phone calls from your characters by typing `/call YOURNUMBER` in the text box when chatting with your character.\n\nNote: only US phone numbers and Elevenlabs voiced characters are supported at the moment.\n</details>\n\n## 🆕! Anyscale and LangSmith integration\n<details><summary>👇click me</summary>\n\n### Anyscale\nYou can now use [Anyscale Endpoint](https://app.endpoints.anyscale.com/landing) to serve Llama-2 models in your RealChar easily! Simply register an account with Anyscale Endpoint. Once you get the API key, set this environment variable in your `.env` file:\n```\nANYSCALE_ENDPOINT_API_KEY=<your API Key>\n```\nBy default, we show the largest servable Llama-2 model (70B) in the Web UI. You can change the model name (`meta-llama/Llama-2-70b-chat-hf`) to other models, e.g. 13b or 7b versions.\n\n### LangSmith\nIf you have access to LangSmith, you can edit these environment variables to enable:\n```\nLANGCHAIN_TRACING_V2=false # default off\nLANGCHAIN_ENDPOINT=https://api.smith.langchain.com\nLANGCHAIN_API_KEY=YOUR_LANGCHAIN_API_KEY\nLANGCHAIN_PROJECT=YOUR_LANGCHAIN_PROJECT\n```\nAnd it should work out of the box.\n\n</details>\n\n<br/>\n\n## 📍 Roadmap\n- [x] Launch v0.0.4\n- [x] Create a new character via web UI\n- [x] Lower conversation latency\n- [x] Support Twilio\n- [x] Support ReByte\n- [x] Persistent conversation*\n- [ ] Session management*\n- [ ] Support RAG*\n- [ ] Support Agents/GPTs*\n- [ ] Add additional TTS service*\n\n$*$ These features are powered by [ReByte](https://rebyte.ai/) platform.\n\n## 🫶 Contribute to RealChar\nPlease check out our [Contribution Guide](contribute.md)!\n\n## 💪 Contributors\n<a href=\"https://github.com/Shaunwei/RealChar\">\n  <img src=\"https://contrib.rocks/image?repo=Shaunwei/RealChar\" />\n</a>\n\n## 🎲 Community\n- Join us on [Discord](https://realchar.ai/join-discord)\n"
        },
        {
          "name": "alembic.ini",
          "type": "blob",
          "size": 3.2783203125,
          "content": "# A generic, single database configuration.\n\n[alembic]\n# path to migration scripts\nscript_location = alembic\n\n# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s\n# Uncomment the line below if you want the files to be prepended with date and time\n# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file\n# for all available tokens\n# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s\n\n# sys.path path, will be prepended to sys.path if present.\n# defaults to the current working directory.\nprepend_sys_path = .\n\n# timezone to use when rendering the date within the migration file\n# as well as the filename.\n# If specified, requires the python-dateutil library that can be\n# installed by adding `alembic[tz]` to the pip requirements\n# string value is passed to dateutil.tz.gettz()\n# leave blank for localtime\n# timezone =\n\n# max length of characters to apply to the\n# \"slug\" field\n# truncate_slug_length = 40\n\n# set to 'true' to run the environment during\n# the 'revision' command, regardless of autogenerate\n# revision_environment = false\n\n# set to 'true' to allow .pyc and .pyo files without\n# a source .py file to be detected as revisions in the\n# versions/ directory\n# sourceless = false\n\n# version location specification; This defaults\n# to alembic/versions.  When using multiple version\n# directories, initial revisions must be specified with --version-path.\n# The path separator used here should be the separator specified by \"version_path_separator\" below.\n# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions\n\n# version path separator; As mentioned above, this is the character used to split\n# version_locations. The default within new alembic.ini files is \"os\", which uses os.pathsep.\n# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.\n# Valid values for version_path_separator are:\n#\n# version_path_separator = :\n# version_path_separator = ;\n# version_path_separator = space\nversion_path_separator = os  # Use os.pathsep. Default configuration used for new projects.\n\n# set to 'true' to search source files recursively\n# in each \"version_locations\" directory\n# new in Alembic version 1.10\n# recursive_version_locations = false\n\n# the output encoding used when revision files\n# are written from script.py.mako\n# output_encoding = utf-8\n\nsqlalchemy.url = sqlite:///./test.db\n\n\n[post_write_hooks]\n# post_write_hooks defines scripts or Python functions that are run\n# on newly generated revision scripts.  See the documentation for further\n# detail and examples\n\n# format using \"black\" - use the console_scripts runner, against the \"black\" entrypoint\n# hooks = black\n# black.type = console_scripts\n# black.entrypoint = black\n# black.options = -l 79 REVISION_SCRIPT_FILENAME\n\n# Logging configuration\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n"
        },
        {
          "name": "alembic",
          "type": "tree",
          "content": null
        },
        {
          "name": "cli.py",
          "type": "blob",
          "size": 6.3408203125,
          "content": "#!/usr/bin/env python\n\"\"\"A CLI for building an running RealChar project locally.\"\"\"\nimport click\nimport os\nimport subprocess\nimport sys\n\n\n@click.group()\ndef cli():\n    assert sys.version_info > (3, 10), \"Python version must be newer than 3.10\"\n    pass\n\n\n@click.command()\n@click.option(\n    \"--name\", default=\"realtime-ai-character\", help=\"The name to give to your Docker image.\"\n)\n@click.option(\n    \"--rebuild\", is_flag=True, help=\"Flag to indicate whether to rebuild the Docker image.\"\n)\ndef docker_build(name, rebuild):\n    if rebuild or not image_exists(name):\n        click.secho(f\"Building Docker image: {name}...\", fg=\"green\")\n        if image_exists(name):\n            subprocess.run([\"docker\", \"rmi\", \"-f\", name])\n        subprocess.run([\"docker\", \"build\", \"-t\", name, \".\"])\n    else:\n        click.secho(\n            f\"Docker image: {name} already exists. Skipping build. \"\n            + \"To rebuild, use --rebuild option\",\n            fg=\"yellow\",\n        )\n\n\n@click.command()\n@click.option(\n    \"--name\", default=\"realtime-ai-character\", help=\"The name of the Docker image to run.\"\n)\n@click.option(\n    \"--db-file\", default=None, help=\"Path to the database file to mount inside the container.\"\n)\ndef docker_run(name, db_file):\n    click.secho(f\"Running Docker image: {name}...\", fg=\"green\")\n    if not os.path.isfile(\".env\"):\n        click.secho(\n            \"Warning: .env file not found. Running without environment variables.\", fg=\"yellow\"\n        )\n    # Remove existing container if it exists\n    subprocess.run(\n        [\"docker\", \"rm\", \"-f\", name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n    )\n    if db_file:\n        subprocess.run(\n            [\n                \"docker\",\n                \"run\",\n                \"--env-file\",\n                \".env\",\n                \"--name\",\n                name,\n                \"-p\",\n                \"8000:8000\",\n                \"-v\",\n                f\"{os.path.abspath(db_file)}:/realtime_ai_character/test.db\",\n                name,\n            ]\n        )\n    else:\n        subprocess.run(\n            [\"docker\", \"run\", \"--env-file\", \".env\", \"--name\", name, \"-p\", \"8000:8000\", name]\n        )\n\n\n@click.command()\n@click.option(\n    \"--name\", default=\"realtime-ai-character\", help=\"The name of the Docker image to delete.\"\n)\ndef docker_delete(name):\n    if image_exists(name):\n        click.secho(f\"Deleting Docker image: {name}...\", fg=\"green\")\n        subprocess.run([\"docker\", \"rmi\", \"-f\", name])\n    else:\n        click.secho(f\"Docker image: {name} does not exist.\", fg=\"yellow\")\n\n\n@click.command(context_settings={\"ignore_unknown_options\": True})\n@click.argument(\"args\", nargs=-1, type=click.UNPROCESSED)\ndef run_uvicorn(args):\n    click.secho(\"Running uvicorn server...\", fg=\"green\")\n    subprocess.run(\n        [\n            \"uvicorn\",\n            \"realtime_ai_character.main:app\",\n            \"--ws-ping-interval\",\n            \"60\",\n            \"--ws-ping-timeout\",\n            \"60\",\n            \"--timeout-keep-alive\",\n            \"60\",\n        ]\n        + list(args)\n    )\n\n\n@click.command()\ndef next_web_dev():\n    # Build the web app to be served by FastAPI\n    click.secho(\"Building web app...\", fg=\"green\")\n    subprocess.run([\"npm\", \"install\"], cwd=\"client/next-web\")\n    click.secho(\"Web app dependencies installed.\", fg=\"green\")\n    subprocess.run([\"npm\", \"run\", \"dev\"], cwd=\"client/next-web\")\n    click.secho(\"Web app dev.\", fg=\"green\")\n\n\n@click.command()\n@click.option(\"--file\", \"-f\", default=\"client/next-web/.env\", help=\"Path to the .env file.\")\n@click.option(\"--image-name\", \"-i\", default=\"realchar-next-web\", help=\"Name of the Docker image.\")\n@click.option(\n    \"--rebuild\", is_flag=True, help=\"Flag to indicate whether to rebuild the Docker image.\"\n)\ndef docker_next_web_build(file, image_name, rebuild):\n    \"\"\"Build docker image using client/next-web/.env file for build arguments.\"\"\"\n    if rebuild or not image_exists(image_name):\n        build_args = \"\"\n\n        if not os.path.exists(file):\n            click.echo(f\"File '{file}' does not exist.\")\n            return\n\n        with open(file, \"r\") as f:\n            for line in f:\n                line = line.strip()\n                if line and not line.startswith(\"#\"):\n                    key, value = line.split(\"=\", 1)\n                    build_args += f\" --build-arg {key}={value}\"\n\n        docker_command = (\n            f\"docker build {build_args} -t {image_name}\"\n            + \" client/next-web\"\n        )\n        click.echo(\"Executing: \" + docker_command)\n        result = subprocess.run(docker_command.split())\n\n        if result.returncode == 0:\n            click.secho(\"Docker image built successfully.\", fg=\"green\")\n        else:\n            click.secho(\"Failed to build Docker image.\", fg=\"red\")\n    else:\n        click.secho(\n            f\"Docker image: {image_name} already exists. Skipping build. \"\n            + \"To rebuild, use --rebuild option\",\n            fg=\"yellow\",\n        )\n\n\n@click.command()\n@click.option(\"--file\", \"-f\", default=\"client/next-web/.env\", help=\"Path to the .env file.\")\n@click.option(\n    \"--image-name\", \"-i\", default=\"realchar-next-web\", help=\"The name of the Docker image to run.\"\n)\ndef docker_next_web_run(file, image_name):\n    \"\"\"Run docker image using client/next-web/.env file for environment variables.\"\"\"\n\n    if not os.path.exists(file):\n        click.echo(f\"File '{file}' does not exist.\")\n        return\n\n    click.secho(f\"Running Docker image: {image_name}...\", fg=\"green\")\n    if not os.path.isfile(\"client/next-web/.env\"):\n        click.secho(\n            \"Warning: .env file not found. Running without environment variables.\", fg=\"yellow\"\n        )\n\n    # Remove existing container if it exists\n    subprocess.run(\n        [\"docker\", \"rm\", \"-f\", image_name], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL\n    )\n    subprocess.run(\n        [\n            \"docker\",\n            \"run\",\n            \"--env-file\",\n            file,\n            \"--name\",\n            image_name,\n            \"-p\",\n            \"80:80\",\n            image_name,\n        ]\n    )\n\n\ndef image_exists(name):\n    result = subprocess.run([\"docker\", \"image\", \"inspect\", name], capture_output=True, text=True)\n    return result.returncode == 0\n\n\ncli.add_command(docker_build)\ncli.add_command(docker_run)\ncli.add_command(docker_delete)\ncli.add_command(run_uvicorn)\ncli.add_command(next_web_dev)\ncli.add_command(docker_next_web_build)\ncli.add_command(docker_next_web_run)\n\n\nif __name__ == \"__main__\":\n    cli()\n"
        },
        {
          "name": "client",
          "type": "tree",
          "content": null
        },
        {
          "name": "contribute.md",
          "type": "blob",
          "size": 2.1396484375,
          "content": "# Contribution Guide\nWelcome to the RealChar project contribution guide. If you're looking to help, this is a great place to start. Follow these guidelines to help ensure the process is as smooth as possible for both you and the project maintainers.\n\n# Setup\n1. Fork the RealChar repository\n2. Clone the fork to your local machine\n3. Set the upstream remote to the original RealChar repository\n```bash\ngit clone https://github.com/<your username>/RealChar.git\ncd RealChar\ngit remote add upstream https://github.com/Shaunwei/RealChar.git\n```\n4. Install `pre-commit` and set up the `pre-commit` hooks for the repo:\n```bash\npip install pre-commit\npre-commit install\n```\n\n# Making Changes\nBefore making changes, ensure that you're working with the most recent version of the code:\n\n```bash\ngit checkout main\ngit pull upstream main\n```\n\nCreate a new branch for your changes:\n\n```bash\ngit checkout -b <branch-name>\n```\n\n# Coding Standards\nPlease adhere to the following:\n\n1. Follow existing coding style and conventions.\n2. Write clear, readable, and maintainable code.\n3. Include detailed comments when necessary.\n4. Test your changes thoroughly before submitting your pull request.\n\n# Committing Your Changes\n1. Stage your changes: git add .\n2. Commit your changes: git commit -m \"Your detailed commit message\"\n3. Push your changes to your fork: git push origin <branch-name>\n\n# Submitting a Pull Request\n1. Navigate to the original RealChar repository\n2. Click 'New pull request'\n3. Choose your fork and the branch containing your changes\n4. Give your pull request a title and detailed description\n5. Submit the pull request\n\n# Issue Tracking\nIf you're adding a new feature or fixing a bug, make sure to add or update an issue in the issue tracker. If there's not an existing issue, create a new one. This helps us keep track of what needs to be worked on.\n\n# Code of Conduct\nBy participating in this project, you're expected to uphold our Code of Conduct.\n\n# Where to Get Help\nIf you run into problems or need help, check out our [discord](https://realchar.ai/join-discord).\n\nThank you for considering contributing to RealChar! Your time and expertise is greatly appreciated by the community.\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 1.9912109375,
          "content": "version: '3.8'\n\nservices:\n  db:\n    build:\n      context: .\n      dockerfile: Dockerfile.postgres\n    restart: always\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n      PGDATA: /var/lib/postgresql/data/realchar\n    ports:\n      - '5432:5432'\n    volumes:\n      - db:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  backend:\n    build: \n      context: .\n      dockerfile: Dockerfile\n    ports:\n      - \"8000:8000\"\n    depends_on:\n      db:\n        condition: service_healthy\n    env_file:\n      - ./.env\n    environment:\n      - DATABASE_URL=postgresql://postgres:postgres@db:5432/postgres\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/status\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  web:\n    build:\n      context: ./client/next-web/\n      dockerfile: Dockerfile.dev\n      args:\n        NEXT_PUBLIC_FIREBASE_API_KEY: AIzaSyAVqhwbdB8I56HAMVVlgJKZcfrBkKI2AhQ\n        NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN: assistly-kubernetes.firebaseapp.com\n        NEXT_PUBLIC_FIREBASE_PROJECT_ID: assistly-kubernetes\n        NEXT_PUBLIC_FIREBASE_APP_ID: 1:806733379891:web:48bf124c0d9b90298e6646\n        REACT_APP_BUILD_NUMBER: 0.0.1\n        NEXT_PUBLIC_API_HOST: http://localhost:8000\n        API_HOST: http://backend:8000\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      backend:\n        condition: service_healthy\n      db:\n        condition: service_healthy\n    environment:\n      - NEXT_PUBLIC_FIREBASE_API_KEY=AIzaSyAVqhwbdB8I56HAMVVlgJKZcfrBkKI2AhQ\n      - NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=assistly-kubernetes.firebaseapp.com\n      - NEXT_PUBLIC_FIREBASE_PROJECT_ID=assistly-kubernetes\n      - NEXT_PUBLIC_FIREBASE_APP_ID=1:806733379891:web:48bf124c0d9b90298e6646\n      - REACT_APP_BUILD_NUMBER=0.0.1\n      - NEXT_PUBLIC_API_HOST=http://localhost:8000\n      - API_HOST=http://backend:8000\n\nnetworks:\n  default:\n    driver: bridge\n\nvolumes:\n  db:\n    driver: local\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "entrypoint.sh",
          "type": "blob",
          "size": 0.08984375,
          "content": "#!/bin/sh\nset -e\nalembic upgrade head\nuvicorn realtime_ai_character.main:app --host 0.0.0.0\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.029296875,
          "content": "[tool.ruff]\nline-length = 100\n"
        },
        {
          "name": "realtime_ai_character",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.5810546875,
          "content": "alembic==1.11.1\naioconsole==0.6.2\nanthropic==0.8.1\nbeautifulsoup4==4.12.2\nchromadb==0.4.13\nedge-tts==6.1.9\nemoji==2.9.0\nfastapi[all]==0.103.2\nfaster_whisper==0.9.0\nfirebase_admin==6.2.0\ngoogle-cloud-speech==2.23.0\nhttpx==0.25.0\nlangchain==0.0.308\nllama_index==0.8.39.post2\nnumpy==1.26.0\nopenai==0.27.8\npgvector==0.2.3\npsycopg2-binary==2.9.9\npyaudio==0.2.13\npydantic==2.4.2\npydub==0.25.1\npypdf==3.16.2\npytest==7.4.2\npython-dotenv==1.0.0\nreaderwriterlock==1.0.9\nrebyte-langchain>=0.0.5\nRequests==2.31.0\nsimpleaudio==1.0.4\nSpeechRecognition==3.10.0\nSQLAlchemy==2.0.21\nstarlette==0.27\ntwilio==8.9.0\n"
        },
        {
          "name": "sample_cloud_deployment",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}