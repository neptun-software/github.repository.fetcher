{
  "metadata": {
    "timestamp": 1736562665608,
    "page": 170,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mcollina/autocannon",
      "stars": 7961,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2,
          "content": "# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\nlerna-debug.log*\n\n# Diagnostic reports (https://nodejs.org/api/report.html)\nreport.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n*.lcov\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# Snowpack dependency directory (https://snowpack.dev/)\nweb_modules/\n\n# TypeScript cache\n*.tsbuildinfo\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Microbundle cache\n.rpt2_cache/\n.rts2_cache_cjs/\n.rts2_cache_es/\n.rts2_cache_umd/\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# dotenv environment variables file\n.env\n.env.test\n\n# parcel-bundler cache (https://parceljs.org/)\n.cache\n.parcel-cache\n\n# Next.js build output\n.next\nout\n\n# Nuxt.js build / generate output\n.nuxt\ndist\n\n# Gatsby files\n.cache/\n# Comment in the public line in if your project uses Gatsby and not Next.js\n# https://nextjs.org/blog/next-9-1#public-directory-support\n# public\n\n# vuepress build output\n.vuepress/dist\n\n# Serverless directories\n.serverless/\n\n# FuseBox cache\n.fusebox/\n\n# DynamoDB Local files\n.dynamodb/\n\n# TernJS port file\n.tern-port\n\n# Stores VSCode versions used for testing VSCode extensions\n.vscode-test\n\n# yarn v2\n.yarn/cache\n.yarn/unplugged\n.yarn/build-state.yml\n.yarn/install-state.gz\n.pnp.*\n\n# Vim swap files\n*.swp\n\n# macOS files\n.DS_Store\n\n# lock files\npackage-lock.json\nyarn.lock\n\n# editor files\n.vscode\n.idea\n\n# Compiled binary addons (http://nodejs.org/api/addons.html)\nbuild/Release\n\nprofile-*\n\n.devcontainer\n.history"
        },
        {
          "name": ".npmignore",
          "type": "blob",
          "size": 0.5966796875,
          "content": "# Logs\nlogs\n*.log\nnpm-debug.log*\n\n# Runtime data\npids\n*.pid\n*.seed\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\n\n# Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (http://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directory\nnode_modules\n\n# Optional npm cache directory\n.npm\n\n# Optional REPL history\n.node_repl_history\n\nprofile-*\n\ndemo.gif\nserver.js\n*.png\nappveyor.yml\n.travis.yml\n.github\n.nyc_output\n"
        },
        {
          "name": ".taprc",
          "type": "blob",
          "size": 0.095703125,
          "content": "ts: false\njsx: false\nflow: false\ntimeout: 900\nbranches: 60\nfunctions: 60\nlines: 60\nstatements: 60\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0556640625,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 Matteo Collina\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 35.876953125,
          "content": "![banner](autocannon-banner.png)\n\n# autocannon\n\n![Node.js CI](https://github.com/mcollina/autocannon/workflows/Node.js%20CI/badge.svg)\n\n![demo](https://raw.githubusercontent.com/mcollina/autocannon/master/demo.gif)\n\nAn HTTP/1.1 benchmarking tool written in node, greatly inspired by [wrk][wrk]\nand [wrk2][wrk2], with support for HTTP pipelining and HTTPS.\nOn _my_ box, *autocannon* can produce more load than `wrk` and `wrk2`, see [limitations](#limitations) for more details.\n\n* [Installation](#install)\n* [Usage](#usage)\n* [API](#api)\n* [Acknowledgements](#acknowledgements)\n* [License](#license)\n\n## Install\n\n```\nnpm i autocannon -g\n```\n\nor if you want to use the [API](#api) or as a dependency:\n\n```\nnpm i autocannon --save\n```\n\n## Usage\n\n### Command Line\n\n```\nUsage: autocannon [opts] URL\n\nURL is any valid HTTP or HTTPS URL.\nIf the PORT environment variable is set, the URL can be a path. In that case 'http://localhost:$PORT/path' will be used as the URL.\n\nAvailable options:\n\n  -c/--connections NUM\n        The number of concurrent connections to use. default: 10.\n  -p/--pipelining NUM\n        The number of pipelined requests to use. default: 1.\n  -d/--duration SEC\n        The number of seconds to run the autocannon. default: 10.\n  -a/--amount NUM\n        The number of requests to make before exiting the benchmark. If set, duration is ignored.\n  -L NUM\n        The number of milliseconds to elapse between taking samples. This controls the sample interval, & therefore the total number of samples, which affects statistical analyses. default: 1.\n  -S/--socketPath\n        A path to a Unix Domain Socket or a Windows Named Pipe. A URL is still required to send the correct Host header and path.\n  -w/--workers\n        Number of worker threads to use to fire requests.\n  -W/--warmup\n       Use a warm up interval before starting sampling.\n       This enables startup processes to finish and traffic to normalize before sampling begins\n       use -c and -d sub args e.g. `--warmup [ -c 1 -d 3 ]`\n  --on-port\n        Start the command listed after -- on the command line. When it starts listening on a port,\n        start sending requests to that port. A URL is still required to send requests to\n        the correct path. The hostname can be omitted, `localhost` will be used by default.\n        If the command after -- is `node <script>`, this flag is optional and assumed to be `true`.\n  -m/--method METHOD\n        The HTTP method to use. default: 'GET'.\n  -t/--timeout NUM\n        The number of seconds before timing out and resetting a connection. default: 10\n  -T/--title TITLE\n        The title to place in the results for identification.\n  -b/--body BODY\n        The body of the request.\n        NOTE: This option needs to be used with the '-H/--headers' option in some frameworks\n  -F/--form FORM\n        Upload a form (multipart/form-data). The form options can be a JSON string like\n        '{ \"field 1\": { \"type\": \"text\", \"value\": \"a text value\"}, \"field 2\": { \"type\": \"file\", \"path\": \"path to the file\" } }'\n        or a path to a JSON file containing the form options.\n        When uploading a file the default filename value can be overridden by using the corresponding option:\n        '{ \"field name\": { \"type\": \"file\", \"path\": \"path to the file\", \"options\": { \"filename\": \"myfilename\" } } }'\n        Passing the filepath to the form can be done by using the corresponding option:\n        '{ \"field name\": { \"type\": \"file\", \"path\": \"path to the file\", \"options\": { \"filepath\": \"/some/path/myfilename\" } } }'\n  -i/--input FILE\n        The body of the request. See '-b/body' for more details.\n  -H/--headers K=V\n        The request headers.\n  --har FILE\n        When provided, Autocannon will use requests from the HAR file.\n        CAUTION: you have to specify one or more domains using URL option: only the HAR requests to the same domains will be considered.\n        NOTE: you can still add extra headers with -H/--headers but -m/--method, -F/--form, -i/--input -b/--body will be ignored.\n  -B/--bailout NUM\n        The number of failures before initiating a bailout.\n  -M/--maxConnectionRequests NUM\n        The max number of requests to make per connection to the server.\n  -O/--maxOverallRequests NUM\n        The max number of requests to make overall to the server.\n  -r/--connectionRate NUM\n        The max number of requests to make per second from an individual connection.\n  -R/--overallRate NUM\n        The max number of requests to make per second from all connections.\n        connection rate will take precedence if both are set.\n        NOTE: if using rate limiting and a very large rate is entered which cannot be met, Autocannon will do as many requests as possible per second.\n        Also, latency data will be corrected to compensate for the effects of the coordinated omission issue.\n        If you are not familiar with the coordinated omission issue, you should probably read [this article](http://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html) or watch this [Gil Tene's talk](https://www.youtube.com/watch?v=lJ8ydIuPFeU) on the topic.\n  -C/--ignoreCoordinatedOmission\n        Ignore the coordinated omission issue when requests should be sent at a fixed rate using 'connectionRate' or 'overallRate'.\n        NOTE: it is not recommended to enable this option.\n        When the request rate cannot be met because the server is too slow, many request latencies might be missing and Autocannon might report a misleading latency distribution.\n  -D/--reconnectRate NUM\n        The number of requests to make before resetting a connections connection to the\n        server.\n  -n/--no-progress\n        Don't render the progress bar. default: false.\n  -l/--latency\n        Print all the latency data. default: false.\n  -I/--idReplacement\n        Enable replacement of `[<id>]` with a randomly generated ID within the request body. e.g. `/items/[<id>]`. default: false.\n  -j/--json\n        Print the output as newline delimited JSON. This will cause the progress bar and results not to be rendered. default: false.\n  -f/--forever\n        Run the benchmark forever. Efficiently restarts the benchmark on completion. default: false.\n  -s/--servername\n        Server name for the SNI (Server Name Indication) TLS extension. Defaults to the hostname of the URL when it is not an IP address.\n  -x/--excludeErrorStats\n        Exclude error statistics (non-2xx HTTP responses) from the final latency and bytes per second averages. default: false.\n  -E/--expectBody EXPECTED\n        Ensure the body matches this value. If enabled, mismatches count towards bailout.\n        Enabling this option will slow down the load testing.\n  --renderStatusCodes\n        Print status codes and their respective statistics.\n  --cert\n        Path to cert chain in pem format\n  --key\n        Path to private key for specified cert in pem format\n  --ca\n        Path to trusted ca certificates for the test. This argument accepts both a single file as well as a list of files\n  --debug\n        Print connection errors to stderr.\n  -v/--version\n        Print the version number.\n  -V/--verbose\n        Print the table with results. default: true.\n  -h/--help\n        Print this menu.\n```\n\nautocannon outputs data in tables like this:\n\n```\nRunning 10s test @ http://localhost:3000\n10 connections\n\n┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬──────────┐\n│ Stat    │ 2.5% │ 50%  │ 97.5% │ 99%  │ Avg     │ Stdev   │ Max      │\n├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼──────────┤\n│ Latency │ 0 ms │ 0 ms │ 0 ms  │ 1 ms │ 0.02 ms │ 0.16 ms │ 16.45 ms │\n└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴──────────┘\n┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐\n│ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev   │ Min     │\n├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n│ Req/Sec   │ 20623   │ 20623   │ 25583   │ 26271   │ 25131.2 │ 1540.94 │ 20615   │\n├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤\n│ Bytes/Sec │ 2.29 MB │ 2.29 MB │ 2.84 MB │ 2.92 MB │ 2.79 MB │ 171 kB  │ 2.29 MB │\n└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘\n\nReq/Bytes counts sampled once per second.\n\n251k requests in 10.05s, 27.9 MB read\n```\n\nThere are two tables: one for the request latency, and one for the request volume.\n\nThe latency table lists the request times at the 2.5% percentile, the fast outliers; at 50%, the median; at 97.5%, the slow outliers; at 99%, the very slowest outliers. Here, lower means faster.\n\nThe request volume table lists the number of requests sent and the number of bytes downloaded. These values are sampled once per second. Higher values mean more requests were processed. In the above example, 2.29 MB was downloaded in 1 second in the worst case (slowest 1%). Since we only ran for 10 seconds, there are just 10 samples, the Min value and the 1% and 2.5% percentiles are all the same sample. With longer durations these numbers will differ more.\n\nWhen passing the `-l` flag, a third table lists all the latency percentiles recorded by autocannon:\n\n```\n┌────────────┬──────────────┐\n│ Percentile │ Latency (ms) │\n├────────────┼──────────────┤\n│ 0.001      │ 0            │\n├────────────┼──────────────┤\n│ 0.01       │ 0            │\n├────────────┼──────────────┤\n│ 0.1        │ 0            │\n├────────────┼──────────────┤\n│ 1          │ 0            │\n├────────────┼──────────────┤\n│ 2.5        │ 0            │\n├────────────┼──────────────┤\n│ 10         │ 0            │\n├────────────┼──────────────┤\n│ 25         │ 0            │\n├────────────┼──────────────┤\n│ 50         │ 0            │\n├────────────┼──────────────┤\n│ 75         │ 0            │\n├────────────┼──────────────┤\n│ 90         │ 0            │\n├────────────┼──────────────┤\n│ 97.5       │ 0            │\n├────────────┼──────────────┤\n│ 99         │ 1            │\n├────────────┼──────────────┤\n│ 99.9       │ 1            │\n├────────────┼──────────────┤\n│ 99.99      │ 3            │\n├────────────┼──────────────┤\n│ 99.999     │ 15           │\n└────────────┴──────────────┘\n```\n\nThis can give some more insight if a lot (millions) of requests were sent.\n\n### Programmatically\n\n```js\n'use strict'\n\nconst autocannon = require('autocannon')\n\nautocannon({\n  url: 'http://localhost:3000',\n  connections: 10, //default\n  pipelining: 1, // default\n  duration: 10 // default\n}, console.log)\n\n// async/await\nasync function foo () {\n  const result = await autocannon({\n    url: 'http://localhost:3000',\n    connections: 10, //default\n    pipelining: 1, // default\n    duration: 10 // default\n  })\n  console.log(result)\n}\n\n```\n\n<a name=\"workers\"></a>\n#### Workers\n\nIn workers mode, `autocannon` uses instances of Node's [Worker](https://nodejs.org/dist/latest/docs/api/worker_threads.html#new-workerfilename-options) class to execute the load tests in multiple threads.\n\nThe `amount` and `connections` parameters are divided amongst the workers. If either parameter is not integer divisible by the number of `workers`, the per-worker value is rounded to the lowest integer, or set to `1`, whichever is the higher. All other parameters are applied per-worker as if the test were single-threaded.\n\n**NOTE:** Unlike `amount` and `connections`, the \"overall\" parameters, `maxOverallRequests` and `overallRate`, are applied **_per worker_**. For example, if you set `connections` to `4`, `workers` to `2` and `maxOverallRequests` to `10`, each worker will receive `2` connections and a `maxOverallRequests` of `10`, resulting in `20` requests being sent.\n\n```js\n'use strict'\n\nconst autocannon = require('autocannon')\n\nautocannon({\n  url: 'http://localhost:3000',\n  connections: 10, //default\n  pipelining: 1, // default\n  duration: 10, // default\n  workers: 4\n}, console.log)\n```\n\n**NOTE:** When in workers mode, you need to pass in an absolute file path to all the options that accept a `function`. This is because a function passed into the main process can not be cloned and passed to the worker. So instead, it needs a file that it can `require`. The options with this behaviour are shown in the below example\n\n```js\n'use strict'\n\nconst autocannon = require('autocannon')\n\nautocannon({\n  // ...\n  workers: 4,\n  setupClient: '/full/path/to/setup-client.js',\n  verifyBody: '/full/path/to/verify-body.js'\n  requests: [\n    {\n      // ...\n      onResponse: '/full/path/to/on-response.js'\n    },\n    {\n      // ...\n      setupRequest: '/full/path/to/setup-request.js'\n    }\n  ]\n}, console.log)\n```\n\n## API\n\n### autocannon(opts[, cb])\n\nStart autocannon against the given target.\n\n* `opts`: Configuration options for the autocannon instance. This can have the following attributes. _REQUIRED_.\n    * `url`: The given target. Can be HTTP or HTTPS. More than one URL is allowed, but it is recommended that the number of connections is an integer multiple of the URL. _REQUIRED_.\n    * `socketPath`: A path to a Unix Domain Socket or a Windows Named Pipe. A `url` is still required to send the correct Host header and path. _OPTIONAL_.\n    * `workers`: Number of worker threads to use to fire requests.\n    * `connections`: The number of concurrent connections. _OPTIONAL_ default: `10`.\n    * `duration`: The number of seconds to run the autocannon. Can be a [timestring](https://www.npmjs.com/package/timestring). _OPTIONAL_ default: `10`.\n    * `amount`: A `Number` stating the number of requests to make before ending the test. This overrides duration and takes precedence, so the test won't end until the number of requests needed to be completed is completed. _OPTIONAL_.\n    * `sampleInt`: The number of milliseconds to elapse between taking samples. This controls the sample interval, & therefore the total number of samples, which affects statistical analyses. default: 1.\n    * `timeout`: The number of seconds to wait for a response before. _OPTIONAL_ default: `10`.\n    * `pipelining`: The number of [pipelined requests](https://en.wikipedia.org/wiki/HTTP_pipelining) for each connection. Will cause the `Client` API to throw when greater than 1. _OPTIONAL_ default: `1`.\n    * `bailout`: The threshold of the number of errors when making the requests to the server before this instance bail's out. This instance will take all existing results so far and aggregate them into the results. If none passed here, the instance will ignore errors and never bail out. _OPTIONAL_ default: `undefined`.\n    * `method`: The HTTP method to use. _OPTIONAL_ `default: 'GET'`.\n    * `title`: A `String` to be added to the results for identification. _OPTIONAL_ default: `undefined`.\n    * `body`: A `String` or a `Buffer` containing the body of the request. Insert one or more randomly generated IDs into the body by including `[<id>]` where the randomly generated ID should be inserted (Must also set idReplacement to true). This can be useful in soak testing POST endpoints where one or more fields must be unique. Leave undefined for an empty body. _OPTIONAL_ default: `undefined`.\n    * `form`: A `String` or an `Object` containing the multipart/form-data options or a path to the JSON file containing them\n    * `headers`: An `Object` containing the headers of the request. _OPTIONAL_ default: `{}`.\n    * `initialContext`: An object that you'd like to initialize your context with. Check out [an example of initializing context](./samples/init-context.js). _OPTIONAL_\n    * `setupClient`: A `Function` which will be passed the `Client` object for each connection to be made. This can be used to customise each individual connection headers and body using the API shown below. The changes you make to the client in this function will take precedence over the default `body` and `headers` you pass in here. There is an example of this in the samples folder. _OPTIONAL_ default: `function noop () {}`. When using `workers`, you need to supply a file path that default exports a function instead (Check out the [workers](#workers) section for more details).\n    * `verifyBody`: A `Function` which will be passed the response body for each completed request. Each request, whose `verifyBody` function does not return a truthy value, is counted in `mismatches`. This function will take precedence over the `expectBody`. There is an example of this in the samples folder. When using `workers`, you need to supply a file path that default exports a function (Check out the [workers](#workers) section for more details).\n    * `maxConnectionRequests`: A `Number` stating the max requests to make per connection. `amount` takes precedence if both are set. _OPTIONAL_\n    * `maxOverallRequests`: A `Number` stating the max requests to make overall. Can't be less than `connections`. `maxConnectionRequests` takes precedence if both are set. _OPTIONAL_\n    * `connectionRate`: A `Number` stating the rate of requests to make per second from each individual connection. No rate limiting by default. _OPTIONAL_\n    * `overallRate`: A `Number` stating the rate of requests to make per second from all connections. `connectionRate` takes precedence if both are set. No rate limiting by default. _OPTIONAL_\n    * `ignoreCoordinatedOmission`: A `Boolean` which disables the correction of latencies to compensate for the coordinated omission issue. Does not make sense when no rate of requests has been specified (`connectionRate` or `overallRate`). _OPTIONAL_ default: `false`.\n    * `reconnectRate`: A `Number` that makes the individual connections disconnect and reconnect to the server whenever it has sent that number of requests. _OPTIONAL_\n    * `requests`: An `Array` of `Object`s which represents the sequence of requests to make while benchmarking. Can be used in conjunction with the `body`, `headers` and `method` params above. Check the samples folder for an example of how this might be used. _OPTIONAL_. Contained objects can have these attributes:\n       * `body`: When present, will override `opts.body`. _OPTIONAL_\n       * `headers`: When present, will override `opts.headers`. _OPTIONAL_\n       * `method`: When present, will override `opts.method`. _OPTIONAL_\n       * `path`: When present, will override `opts.path`. _OPTIONAL_\n       * `setupRequest`: A `Function` you may provide to mutate the raw `request` object, e.g. `request.method = 'GET'`. It takes `request` (Object) and `context` (Object) parameters, and must return the modified request. When it returns a falsey value, autocannon will restart from first request. When using `workers`, you need to supply a file path that default exports a function instead (Check out [workers](#workers) section for more details) _OPTIONAL_\n       * `onResponse`: A `Function` you may provide to process the received response. It takes `status` (Number), `body` (String) `context` (Object) parameters and `headers` (Key-Value Object). When using `workers`, you need to supply a file path that default exports a function instead (Check out [workers](#workers) section for more details) _OPTIONAL_\n    * `har`: an `Object` of parsed [HAR](https://w3c.github.io/web-performance/specs/HAR/Overview.html) content. Autocannon will extra and use `entries.request`: `requests`, `method`, `form` and `body` options will be ignored. _NOTE_: you must ensure that entries are targeting the same domain as `url` option. _OPTIONAL_\n    * `idReplacement`: A `Boolean` which enables the replacement of `[<id>]` tags within the request body with a randomly generated ID, allowing for unique fields to be sent with requests. Check out [an example of programmatic usage](./samples/using-id-replacement.js) that can be found in the samples. _OPTIONAL_ default: `false`\n    * `forever`: A `Boolean` which allows you to setup an instance of autocannon that restarts indefinitely after emitting results with the `done` event. Useful for efficiently restarting your instance. To stop running forever, you must cause a `SIGINT` or call the `.stop()` function on your instance. _OPTIONAL_ default: `false`\n    * `servername`: A `String` identifying the server name for the SNI (Server Name Indication) TLS extension. _OPTIONAL_ default: Defaults to the hostname of the URL when it is not an IP address.\n    * `excludeErrorStats`: A `Boolean` which allows you to disable tracking non-2xx code responses in latency and bytes per second calculations. _OPTIONAL_ default: `false`.\n    * `expectBody`: A `String` representing the expected response body. Each request whose response body is not equal to `expectBody`is counted in `mismatches`. If enabled, mismatches count towards bailout. _OPTIONAL_\n    * `tlsOptions`: An `Object` that is passed into `tls.connect` call ([Full list of options](https://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback)). Note: this only applies if your URL is secure.\n    * `skipAggregateResult`: A `Boolean` which allows you to disable the aggregate result phase of an instance run. See [autocannon.aggregateResult](<#autocannon.aggregateResult(results[, opts])>)\n* `cb`: The callback which is called on completion of a benchmark. Takes the following params. _OPTIONAL_.\n    * `err`: If there was an error encountered with the run.\n    * `results`: The results of the run.\n\n**Returns** an instance/event emitter for tracking progress, etc. If `cb` is omitted, the return value can also be used as a Promise.\n\n### Customizing sent requests\n\nWhen running, autocannon will create as many `Client` objects as desired connections. They will run in parallel until the benchmark is over (duration or total number of requests).\nEach client will loop over the `requests` array, would it contain one or several requests.\n\nWhile going through available requests, the client will maintain a `context`: an object you can use in `onResponse` and `setupRequest` functions, to store and read some contextual data.\nPlease check the `request-context.js` file in samples.\n\nNote that `context` object will be reset to `initialContext` (or `{}` it is not provided) when restarting to the first available request, ensuring similar runs.\n\n### Combining connections, overallRate and amount\n\nWhen combining a fixed `amount` of requests with concurrent `connections` and an `overallRate` limit, autocannon will distribute the requests and the intended rate over all connections. If the `overallRate` is not integer divisible, autocannon will configure some connection clients with a higher and some with a lower number of requests/second rate. If now the `amount` *is* integer divisible, all connection clients get the same number of requests. This means that the clients with a higher request rate will finish earlier, than the others, leading to a drop in the perceived request rate.\n\nExample: `connections = 10, overallRate = 17, amount = 5000`\n\n\n### autocannon.track(instance[, opts])\n\nTrack the progress of your autocannon, programmatically.\n\n* `instance`: The instance of autocannon. _REQUIRED_.\n* `opts`: Configuration options for tracking. This can have the following attributes. _OPTIONAL_.\n    * `outputStream`: The stream to output to. default: `process.stderr`.\n    * `renderProgressBar`: A truthy value to enable the rendering of the progress bar. default: `true`.\n    * `renderResultsTable`: A truthy value to enable the rendering of the results table. default: `true`.\n    * `renderLatencyTable`: A truthy value to enable the rendering of the advanced latency table. default: `false`.\n    * `progressBarString`: A `string` defining the format of the progress display output. Must be valid input for the [progress bar module](http://npm.im/progress). default: `'running [:bar] :percent'`.\n\nExample that just prints the table of results on completion:\n\n```js\n'use strict'\n\nconst autocannon = require('autocannon')\n\nconst instance = autocannon({\n  url: 'http://localhost:3000'\n}, console.log)\n\n// this is used to kill the instance on CTRL-C\nprocess.once('SIGINT', () => {\n  instance.stop()\n})\n\n// just render results\nautocannon.track(instance, {renderProgressBar: false})\n```\n\nCheck out [this example](./samples/track-run.js) to see it in use, as well.\n\n### autocannon.printResult(resultObject[, opts])\n\nReturns a text string containing the result tables.\n\n* `resultObject`: The result object of autocannon. _REQUIRED_.\n* `opts`: Configuration options for generating the tables. These may include the following attributes. _OPTIONAL_.\n    * `outputStream`: The stream to which output is directed. It is primarily used to check if the terminal supports color. default: `process.stderr`.\n    * `renderResultsTable`: A truthy value to enable the creation of the results table. default: `true`.\n    * `renderLatencyTable`: A truthy value to enable the creation of the latency table. default: `false`.\n\nExample:\n\n```js\n\"use strict\";\n\nconst { stdout } = require(\"node:process\");\nconst autocannon = require(\"autocannon\");\n\nfunction print(result) {\n  stdout.write(autocannon.printResult(result));\n}\n\nautocannon({ url: \"http://localhost:3000\" }, (err, result) => print(result));\n```\n\n### autocannon.aggregateResult(results[, opts])\n\nAggregate the results of one or more autocannon instance runs, where the instances of autocannon have been run with the `skipAggregateResult` option.\n\nThis is an advanced use case, where you might be running a load test using autocannon across multiple machines and therefore need to defer aggregating the results to a later time.\n\n* `results`: An array of autocannon instance results, where the instances have been run with the `skipAggregateResult` option set to true. _REQUIRED_.\n* `opts`: This is a subset of the options you would pass to the main autocannon API, so you could use the same options object as the one used to run the instances. See [autocannon](<#autocannon(opts[, cb])>) for full descriptions of the options. _REQUIRED_.\n    * `url`: _REQUIRED_\n    * `title`: _OPTIONAL_ default: `undefined`\n    * `socketPath`: _OPTIONAL_\n    * `connections`: _OPTIONAL_ default: `10`.\n    * `sampleInt`: _OPTIONAL_ default: `1`\n    * `pipelining`: _OPTIONAL_ default: `1`\n    * `workers`: _OPTIONAL_ default: `undefined`\n\n### Autocannon events\n\nBecause an autocannon instance is an `EventEmitter`, it emits several events. these are below:\n\n* `start`: Emitted once everything has been setup in your autocannon instance and it has started. Useful for if running the instance forever.\n* `tick`: Emitted every second this autocannon is running a benchmark. Useful for displaying stats, etc. Used by the `track` function. The `tick` event propagates  an object containing the `counter` and `bytes` values, which can be used for extended reports.\n* `done`: Emitted when the autocannon finishes a benchmark. passes the `results` as an argument to the callback.\n* `response`: Emitted when the autocannons http-client gets an HTTP response from the server. This passes the following arguments to the callback:\n    * `client`: The `http-client` itself. Can be used to modify the headers and body the client will send to the server. API below.\n    * `statusCode`: The HTTP status code of the response.\n    * `resBytes`: The response byte length.\n    * `responseTime`: The time taken to get a response after initiating the request.\n* `reqError`: Emitted in the case of a request error e.g. a timeout.\n* `error`: Emitted if there is an error during the setup phase of autocannon.\n\n### Results\n\nThe results object emitted by `done` and passed to the `autocannon()` callback has these properties:\n\n* `title`: Value of the `title` option passed to `autocannon()`.\n* `url`: The URL that was targeted.\n* `socketPath`: The UNIX Domain Socket or Windows Named Pipe that was targeted, or `undefined`.\n* `requests`: A histogram object containing statistics about the number of requests that were sent per second.\n* `latency`: A histogram object containing statistics about response latency.\n* `throughput`: A histogram object containing statistics about the response data throughput per second.\n* `duration`: The amount of time the test took, **in seconds**.\n* `errors`: The number of connection errors (including timeouts) that occurred.\n* `timeouts`: The number of connection timeouts that occurred.\n* `mismatches`: The number of requests with a mismatched body.\n* `start`: A Date object representing when the test started.\n* `finish`: A Date object representing when the test ended.\n* `connections`: The amount of connections used (value of `opts.connections`).\n* `pipelining`: The number of pipelined requests used per connection (value of `opts.pipelining`).\n* `non2xx`: The number of non-2xx response status codes received.\n* `resets`: How many times the requests pipeline was reset due to `setupRequest` returning a falsey value.\n* `statusCodeStats`: Requests counter per status code (e.g. `{ \"200\": { \"count\": \"500\" } }`)\n\nThe histogram objects for `requests`, `latency` and `throughput` are [hdr-histogram-percentiles-obj](https://github.com/thekemkid/hdr-histogram-percentiles-obj) objects and have this shape:\n\n* `min`: The lowest value for this statistic.\n* `max`: The highest value for this statistic.\n* `average`: The average (mean) value.\n* `stddev`: The standard deviation.\n* `p*`: The XXth percentile value for this statistic. The percentile properties are: `p2_5`, `p50`, `p75`, `p90`, `p97_5`, `p99`, `p99_9`, `p99_99`, `p99_999`.\n\n### `Client` API\n\nThis object is passed as the first parameter of both the `setupClient` function and the `response` event from an autocannon instance. You can use this to modify the requests you are sending while benchmarking. This is also an `EventEmitter`, with the events and their params listed below.\n\n* `client.setHeaders(headers)`: Used to modify the headers of the request this client iterator is currently on. `headers` should be an `Object`, or `undefined` if you want to remove your headers.\n* `client.setBody(body)`: Used to modify the body of the request this client iterator is currently on. `body` should be a `String` or `Buffer`, or `undefined` if you want to remove the body.\n* `client.setHeadersAndBody(headers, body)`: Used to modify both the headers and body this client iterator is currently on. `headers` and `body` should take the same form as above.\n* `client.setRequest(request)`: Used to modify the entire request that this client iterator is currently on. Can have `headers`, `body`, `method`, or `path` as attributes. Defaults to the values passed into the autocannon instance when it was created. `Note: call this when modifying multiple request values for faster encoding`\n* `client.setRequests(newRequests)`: Used to overwrite the entire requests array that was passed into the instance on initiation. `Note: call this when modifying multiple requests for faster encoding`\n\n### `Client` events\n\nThe events a `Client` can emit are listed here:\n\n* `headers`: Emitted when a request sent from this client has received the headers of its reply. This received an `Object` as the parameter.\n* `body`: Emitted when a request sent from this client has received the body of a reply. This receives a `Buffer` as the parameter.\n* `response`: Emitted when the client has received a completed response for a request it made. This is passed the following arguments:\n    * `statusCode`: The HTTP status code of the response.\n    * `resBytes`: The response byte length.\n    * `responseTime`: The time taken to get a response after initiating the request.\n* `reset`: Emitted when the requests pipeline was reset due to `setupRequest` returning a falsey value.\n\nExample using the autocannon events and the client API and events:\n\n```js\n'use strict'\n\nconst autocannon = require('autocannon')\n\nconst instance = autocannon({\n  url: 'http://localhost:3000',\n  setupClient: setupClient\n}, (err, result) => handleResults(result))\n// results passed to the callback are the same as those emitted from the done events\ninstance.on('done', handleResults)\n\ninstance.on('tick', () => console.log('ticking'))\n\ninstance.on('response', handleResponse)\n\nfunction setupClient (client) {\n  client.on('body', console.log) // console.log a response body when its received\n}\n\nfunction handleResponse (client, statusCode, resBytes, responseTime) {\n  console.log(`Got response with code ${statusCode} in ${responseTime} milliseconds`)\n  console.log(`response: ${resBytes.toString()}`)\n\n  //update the body or headers\n  client.setHeaders({new: 'header'})\n  client.setBody('new body')\n  client.setHeadersAndBody({new: 'header'}, 'new body')\n}\n\nfunction handleResults(result) {\n  // ...\n}\n```\n\n<a name=\"limitations\"></a>\n## Limitations\n\nAutocannon is written in JavaScript for the Node.js runtime and it is CPU-bound.\nWe have verified that it yields comparable results with `wrk` when benchmarking Node.js\napplications using the `http` module.\nNevertheless, it uses significantly more CPU than other tools that compiles to a binary such as `wrk`.\nAutocannon can saturate the CPU, e.g. the autocannon process reaches 100%: in those cases,\nwe recommend using `wrk2`.\n\nAs an example, let's consider a run with 1000 connections on a server\nwith 4 cores with hyperthreading:\n\n* `wrk` uses 2 threads (by default) and an auxiliary one to collect the\n  metrics with a total load of the CPU of 20% + 20% + 40%.\n* `autocannon` uses a single thread at 80% CPU load.\n\nBoth saturates a Node.js process at around 41k req/sec, however,\n`autocannon` can saturate sooner because it is single-threaded.\n\nNote that `wrk` does not support HTTP/1.1 pipelining. As a result, `autocannon` can create\nmore load on the server than wrk for each open connection.\n\n<a name=\"acknowledgements\"></a>\n## Acknowledgements\n\nThis project was kindly sponsored by [nearForm](http://nearform.com).\n\nLogo and identity designed by Cosmic Fox Design: https://www.behance.net/cosmicfox.\n\n[wrk][wrk] and [wrk2][wrk2] provided great inspiration.\n\n### Chat on Gitter\n\nIf you are using autocannon or you have any questions, let us know: [Gitter](https://gitter.im/mcollina/autocannon)\n\n### Contributors\n\n- [Glen Keane](mailto:glenkeane.94@gmail.com) | [Github](https://github.com/GlenTiki)\n- [Salman Mitha](mailto:salmanmitha@gmail.com) | [Github](https://github.com/salmanm) | [NPM](https://www.npmjs.com/~salmanm)\n\n## License\n\nCopyright [Matteo Collina](https://github.com/mcollina) and other contributors, Licensed under [MIT](./LICENSE).\n\n[node-gyp]: https://github.com/nodejs/node-gyp#installation\n[wrk]: https://github.com/wg/wrk\n[wrk2]: https://github.com/giltene/wrk2\n"
        },
        {
          "name": "autocannon-banner.png",
          "type": "blob",
          "size": 32.49609375,
          "content": null
        },
        {
          "name": "autocannon-logo-hire.png",
          "type": "blob",
          "size": 32.1337890625,
          "content": null
        },
        {
          "name": "autocannon-logo-icon-1000px.png",
          "type": "blob",
          "size": 42.64453125,
          "content": null
        },
        {
          "name": "autocannon-logo-icon-100px.png",
          "type": "blob",
          "size": 3.05078125,
          "content": null
        },
        {
          "name": "autocannon.js",
          "type": "blob",
          "size": 8.990234375,
          "content": "#! /usr/bin/env node\n\n'use strict'\n\nconst crossArgv = require('cross-argv')\nconst fs = require('fs')\nconst os = require('os')\nconst net = require('net')\nconst path = require('path')\nconst URL = require('url').URL\nconst spawn = require('child_process').spawn\nconst managePath = require('manage-path')\nconst hasAsyncHooks = require('has-async-hooks')\nconst subarg = require('@minimistjs/subarg')\nconst printResult = require('./lib/printResult')\nconst initJob = require('./lib/init')\nconst track = require('./lib/progressTracker')\nconst generateSubArgAliases = require('./lib/subargAliases')\nconst { checkURL, ofURL } = require('./lib/url')\nconst { parseHAR } = require('./lib/parseHAR')\nconst _aggregateResult = require('./lib/aggregateResult')\nconst validateOpts = require('./lib/validate')\n\nif (typeof URL !== 'function') {\n  console.error('autocannon requires the WHATWG URL API, but it is not available. Please upgrade to Node 6.13+.')\n  process.exit(1)\n}\n\nmodule.exports = initJob\nmodule.exports.track = track\n\nmodule.exports.start = start\nmodule.exports.printResult = printResult\nmodule.exports.parseArguments = parseArguments\nmodule.exports.aggregateResult = function aggregateResult (results, opts = {}) {\n  if (!Array.isArray(results)) {\n    throw new Error('\"results\" must be an array of results')\n  }\n\n  opts = validateOpts(opts, false)\n\n  if (opts instanceof Error) {\n    throw opts\n  }\n\n  return _aggregateResult(results, opts)\n}\nconst alias = {\n  connections: 'c',\n  pipelining: 'p',\n  timeout: 't',\n  duration: 'd',\n  sampleInt: 'L',\n  amount: 'a',\n  json: 'j',\n  renderLatencyTable: ['l', 'latency'],\n  onPort: 'on-port',\n  method: 'm',\n  headers: ['H', 'header'],\n  body: 'b',\n  form: 'F',\n  servername: 's',\n  bailout: 'B',\n  input: 'i',\n  maxConnectionRequests: 'M',\n  maxOverallRequests: 'O',\n  connectionRate: 'r',\n  overallRate: 'R',\n  ignoreCoordinatedOmission: 'C',\n  reconnectRate: 'D',\n  renderProgressBar: 'progress',\n  renderStatusCodes: 'statusCodes',\n  title: 'T',\n  verbose: 'V',\n  version: 'v',\n  forever: 'f',\n  idReplacement: 'I',\n  socketPath: 'S',\n  excludeErrorStats: 'x',\n  expectBody: 'E',\n  workers: 'w',\n  warmup: 'W',\n  help: 'h'\n}\n\nconst defaults = {\n  connections: 10,\n  timeout: 10,\n  pipelining: 1,\n  duration: 10,\n  sampleInt: 1000,\n  reconnectRate: 0,\n  renderLatencyTable: false,\n  renderProgressBar: true,\n  renderStatusCodes: false,\n  json: false,\n  forever: false,\n  method: 'GET',\n  idReplacement: false,\n  excludeErrorStats: false,\n  debug: false,\n  workers: 0,\n  verbose: true\n}\n\nfunction parseArguments (argvs) {\n  let argv = subarg(argvs, {\n    boolean: ['json', 'n', 'help', 'renderLatencyTable', 'renderProgressBar', 'renderStatusCodes', 'forever', 'idReplacement', 'excludeErrorStats', 'onPort', 'debug', 'ignoreCoordinatedOmission', 'verbose'],\n    alias,\n    default: defaults,\n    '--': true\n  })\n  // subarg does not convert aliases in sub arguments\n  argv = generateSubArgAliases(argv)\n\n  argv.url = argv._.length > 1 ? argv._ : argv._[0]\n\n  // Assume onPort if `-- node` is provided\n  if (argv['--'][0] === 'node') {\n    argv.onPort = true\n  }\n\n  if (argv.onPort) {\n    argv.spawn = argv['--']\n  }\n\n  // support -n to disable the progress bar and results table\n  if (argv.n) {\n    argv.renderProgressBar = false\n    argv.renderResultsTable = false\n    argv.renderStatusCodes = false\n  }\n\n  if (argv.version) {\n    console.log('autocannon', 'v' + require('./package').version)\n    console.log('node', process.version)\n    return\n  }\n\n  if (!checkURL(argv.url) || argv.help) {\n    const help = fs.readFileSync(path.join(__dirname, 'help.txt'), 'utf8')\n    console.error(help)\n    return\n  }\n\n  // if PORT is set (like by `0x`), target `localhost:PORT/path` by default.\n  // this allows doing:\n  //     0x --on-port 'autocannon /path' -- node server.js\n  if (process.env.PORT) {\n    argv.url = ofURL(argv.url).map(url => new URL(url, `http://localhost:${process.env.PORT}`).href)\n  }\n  // Add http:// if it's not there and this is not a /path\n  argv.url = ofURL(argv.url).map(url => {\n    if (url.indexOf('http') !== 0 && url[0] !== '/') {\n      url = `http://${url}`\n    }\n    return url\n  })\n\n  // check that the URL is valid.\n  ofURL(argv.url).map(url => {\n    try {\n      // If --on-port is given, it's acceptable to not have a hostname\n      if (argv.onPort) {\n        new URL(url, 'http://localhost') // eslint-disable-line no-new\n      } else {\n        new URL(url) // eslint-disable-line no-new\n      }\n    } catch (err) {\n      console.error(err.message)\n      console.error('')\n      console.error('When targeting a path without a hostname, the PORT environment variable must be available.')\n      console.error('Use a full URL or set the PORT variable.')\n      process.exit(1)\n    }\n\n    return null // to make linter happy\n  })\n\n  if (argv.input) {\n    argv.body = fs.readFileSync(argv.input, 'utf8')\n  }\n\n  if (argv.headers) {\n    if (!Array.isArray(argv.headers)) {\n      argv.headers = [argv.headers]\n    }\n\n    argv.headers = argv.headers.reduce((obj, header) => {\n      const colonIndex = header.indexOf(':')\n      const equalIndex = header.indexOf('=')\n      const index = Math.min(colonIndex < 0 ? Infinity : colonIndex, equalIndex < 0 ? Infinity : equalIndex)\n      if (Number.isFinite(index) && index > 0) {\n        obj[header.slice(0, index)] = header.slice(index + 1)\n        return obj\n      } else throw new Error(`An HTTP header was not correctly formatted: ${header}`)\n    }, {})\n  }\n\n  if (argv.har) {\n    try {\n      argv.har = JSON.parse(fs.readFileSync(argv.har))\n      // warn users about skipped HAR requests\n      const requestsByOrigin = parseHAR(argv.har)\n      const allowed = ofURL(argv.url, true).map(url => new URL(url).origin)\n      for (const [origin] of requestsByOrigin) {\n        if (!allowed.includes(origin)) {\n          console.error(`Warning: skipping requests to '${origin}' as the target is ${allowed.join(', ')}`)\n        }\n      }\n    } catch (err) {\n      throw new Error(`Failed to load HAR file content: ${err.message}`)\n    }\n  }\n\n  argv.tlsOptions = {}\n\n  if (argv.cert) {\n    try {\n      argv.tlsOptions.cert = fs.readFileSync(argv.cert)\n    } catch (err) {\n      throw new Error(`Failed to load cert file: ${err.message}`)\n    }\n  }\n\n  if (argv.key) {\n    try {\n      argv.tlsOptions.key = fs.readFileSync(argv.key)\n    } catch (err) {\n      throw new Error(`Failed to load key file: ${err.message}`)\n    }\n  }\n\n  if (argv.ca) {\n    if (typeof argv.ca === 'string') {\n      argv.ca = [argv.ca]\n    } else if (Array.isArray(argv.ca._)) {\n      argv.ca = argv.ca._\n    }\n\n    try {\n      argv.tlsOptions.ca = argv.ca.map(caPath => fs.readFileSync(caPath))\n    } catch (err) {\n      throw new Error(`Failed to load ca file: ${err.message}`)\n    }\n  }\n\n  // This is to distinguish down the line whether it is\n  // run via command-line or programmatically\n  argv[Symbol.for('internal')] = true\n\n  return argv\n}\n\nfunction start (argv) {\n  if (!argv) {\n    // we are printing the help\n    return\n  }\n\n  if (argv.onPort) {\n    if (!hasAsyncHooks()) {\n      console.error('The --on-port flag requires the async_hooks builtin module, but it is not available. Please upgrade to Node 8.1+.')\n      process.exit(1)\n    }\n\n    const { socketPath, server } = createChannel((port) => {\n      const url = new URL(argv.url, `http://localhost:${port}`).href\n      const opts = Object.assign({}, argv, {\n        onPort: false,\n        url\n      })\n      const tracker = initJob(opts, () => {\n        proc.kill('SIGINT')\n        server.close()\n      })\n\n      process.once('SIGINT', () => {\n        tracker.stop()\n      })\n    })\n\n    // manage-path always uses the $PATH variable, but we can pretend\n    // that it is equal to $NODE_PATH\n    const alterPath = managePath({ PATH: process.env.NODE_PATH })\n    alterPath.unshift(path.join(__dirname, 'lib/preload'))\n\n    const proc = spawn(argv.spawn[0], argv.spawn.slice(1), {\n      stdio: ['ignore', 'inherit', 'inherit'],\n      env: Object.assign({}, process.env, {\n        NODE_OPTIONS: ['-r', 'autocannonDetectPort'].join(' ') +\n          (process.env.NODE_OPTIONS ? ` ${process.env.NODE_OPTIONS}` : ''),\n        NODE_PATH: alterPath.get(),\n        AUTOCANNON_SOCKET: socketPath\n      })\n    })\n  } else {\n    // if forever is true then a promise is not returned and we need to try ... catch errors\n    try {\n      const tracker = initJob(argv)\n      if (tracker.then) {\n        tracker.catch((err) => {\n          console.error(err.message)\n        })\n      }\n    } catch (err) {\n      console.error(err.message)\n    }\n  }\n}\n\nfunction createChannel (onport) {\n  const pipeName = `${process.pid}.autocannon`\n  const socketPath = process.platform === 'win32'\n    ? `\\\\\\\\?\\\\pipe\\\\${pipeName}`\n    : path.join(os.tmpdir(), pipeName)\n  const server = net.createServer((socket) => {\n    socket.once('data', (chunk) => {\n      const port = chunk.toString()\n      onport(port)\n    })\n  })\n  server.listen(socketPath)\n  server.on('close', () => {\n    try {\n      fs.unlinkSync(socketPath)\n    } catch (err) {}\n  })\n\n  return { socketPath, server }\n}\n\nif (require.main === module) {\n  const argv = crossArgv(process.argv.slice(2))\n  start(parseArguments(argv))\n}\n"
        },
        {
          "name": "cluster.js",
          "type": "blob",
          "size": 0.619140625,
          "content": "'use strict'\n\nconst cluster = require('cluster')\nconst http = require('http')\nconst numCPUs = Math.floor(require('os').cpus().length / 2) || 1\n\nif (cluster.isMaster) {\n  console.log(`Master ${process.pid} is running`)\n\n  for (let i = 0; i < numCPUs; i++) {\n    cluster.fork()\n  }\n\n  cluster.on('exit', (worker, code, signal) => {\n    console.log(`worker ${worker.process.pid} died`)\n  })\n} else {\n  // Workers can share any TCP connection\n  // In this case it is an HTTP server\n  http.createServer((req, res) => {\n    res.writeHead(200)\n    res.end('hello world\\n')\n  }).listen(3000)\n\n  console.log(`Worker ${process.pid} started`)\n}\n"
        },
        {
          "name": "demo.gif",
          "type": "blob",
          "size": 105.3955078125,
          "content": null
        },
        {
          "name": "for-zero-x.js",
          "type": "blob",
          "size": 0.138671875,
          "content": "'use strict'\n\nconst autocannon = require('.')\n\nautocannon({\n  url: 'http://localhost:3000',\n  connections: 10,\n  duration: 10\n}, console.log)\n"
        },
        {
          "name": "help.txt",
          "type": "blob",
          "size": 6.1494140625,
          "content": "Usage: autocannon [opts] URL\n\nURL is any valid HTTP or HTTPS URL.\nIf the PORT environment variable is set, the URL can be a path. In that case 'http://localhost:$PORT/path' will be used as the URL.\n\nAvailable options:\n\n  -c/--connections NUM\n        The number of concurrent connections to use. default: 10.\n  -p/--pipelining NUM\n        The number of pipelined requests to use. default: 1.\n  -d/--duration SEC\n        The number of seconds to run the autocannon. default: 10.\n  -a/--amount NUM\n        The number of requests to make before exiting the benchmark. If set, duration is ignored.\n  -L NUM\n        The number of milliseconds to elapse between taking samples. This controls the sample interval, & therefore the total number of samples, which affects statistical analyses. default: 1.\n  -S/--socketPath\n        A path to a Unix Domain Socket or a Windows Named Pipe. A URL is still required to send the correct Host header and path.\n  -w/--workers\n        Number of worker threads to use to fire requests.\n  -W/--warmup\n       Use a warm up interval before starting sampling.\n       This enables startup processes to finish and traffic to normalize before sampling begins\n       use -c and -d sub args e.g. `--warmup [ -c 1 -d 3 ]`\n  --on-port\n        Start the command listed after -- on the command line. When it starts listening on a port,\n        start sending requests to that port. A URL is still required to send requests to\n        the correct path. The hostname can be omitted, `localhost` will be used by default.\n  -m/--method METHOD\n        The HTTP method to use. default: 'GET'.\n  -t/--timeout NUM\n        The number of seconds before timing out and resetting a connection. default: 10\n  -T/--title TITLE\n        The title to place in the results for identification.\n  -b/--body BODY\n        The body of the request.\n        NOTE: This option needs to be used with the '-H/--headers' option in some frameworks\n  -F/--form FORM\n        Upload a form (multipart/form-data). The form options can be a JSON string like\n        '{ \"field 1\": { \"type\": \"text\", \"value\": \"a text value\"}, \"field 2\": { \"type\": \"file\", \"path\": \"path to the file\" } }'\n        or a path to a JSON file containing the form options.\n        When uploading a file the default filename value can be overridden by using the corresponding option:\n        '{ \"field name\": { \"type\": \"file\", \"path\": \"path to the file\", \"options\": { \"filename\": \"myfilename\" } } }'\n        Passing the filepath to the form can be done by using the corresponding option:\n        '{ \"field name\": { \"type\": \"file\", \"path\": \"path to the file\", \"options\": { \"filepath\": \"/some/path/myfilename\" } } }'\n  -i/--input FILE\n        The body of the request. See '-b/body' for more details.\n  -H/--headers K=V\n        The request headers.\n  --har FILE\n        When provided, Autocannon will use requests from the HAR file.\n        CAUTION: you have to specify one or more domains using URL option: only the HAR requests to the same domains will be considered.\n        NOTE: you can still add extra headers with -H/--headers but -m/--method, -F/--form, -i/--input -b/--body will be ignored.\n  -B/--bailout NUM\n        The number of failures before initiating a bailout.\n  -M/--maxConnectionRequests NUM\n        The max number of requests to make per connection to the server.\n  -O/--maxOverallRequests NUM\n        The max number of requests to make overall to the server.\n  -r/--connectionRate NUM\n        The max number of requests to make per second from an individual connection.\n  -R/--overallRate NUM\n        The max number of requests to make per second from all connections.\n        connection rate will take precedence if both are set.\n        NOTE: if using rate limiting and a very large rate is entered which cannot be met,\n              Autocannon will do as many requests as possible per second. Also, latency data will be corrected to compensate for the effects of the coordinated omission issue. If you are not familiar with the coordinated omission issue, you should probably read [this article](http://highscalability.com/blog/2015/10/5/your-load-generator-is-probably-lying-to-you-take-the-red-pi.html) or watch this [Gil Tene's talk](https://www.youtube.com/watch?v=lJ8ydIuPFeU) on the topic.\n  -C/--ignoreCoordinatedOmission\n        Ignore the coordinated omission issue when requests should be sent at a fixed rate using 'connectionRate' or 'overallRate'.\n        NOTE: it is not recommended to enable this option.\n              When the request rate cannot be met because the server is too slow, many request latencies might be missing and Autocannon might report a misleading latency distribution.\n  -D/--reconnectRate NUM\n        The number of requests to make before resetting a connections connection to the\n        server.\n  -n/--no-progress\n        Don't render the progress bar. default: false.\n  -l/--latency\n        Print all the latency data. default: false.\n  -I/--idReplacement\n        Enable replacement of [<id>] with a randomly generated ID within the request body. default: false.\n  -j/--json\n        Print the output as newline delimited JSON. This will cause the progress bar and results not to be rendered. default: false.\n  -f/--forever\n        Run the benchmark forever. Efficiently restarts the benchmark on completion. default: false.\n  -s/--servername\n        Server name for the SNI (Server Name Indication) TLS extension. Defaults to the hostname of the URL when it is not an IP address.\n  -x/--excludeErrorStats\n        Exclude error statistics (non-2xx HTTP responses) from the final latency and bytes per second averages. default: false.\n  -E/--expectBody EXPECTED\n        Ensure the body matches this value. If enabled, mismatches count towards bailout.\n        Enabling this option will slow down the load testing.\n  --renderStatusCodes\n        Print status codes and their respective statistics.\n  --cert\n        Path to cert chain in pem format\n  --key\n        Path to private key for specified cert in pem format\n  --ca\n        Path to trusted ca certificates for the test. This argument accepts both a single file as well as a list of files\n  --debug\n        Print connection errors to stderr.\n  -v/--version\n        Print the version number.\n  -h/--help\n        Print this menu.\n"
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 1.8935546875,
          "content": "{\n  \"name\": \"autocannon\",\n  \"version\": \"8.0.0\",\n  \"description\": \"Fast HTTP benchmarking tool written in Node.js\",\n  \"main\": \"autocannon.js\",\n  \"bin\": {\n    \"autocannon\": \"autocannon.js\"\n  },\n  \"scripts\": {\n    \"test\": \"standard && tap test/serial/*.test.js test/*.test.js\",\n    \"standard:fix\": \"standard --fix\"\n  },\n  \"pre-commit\": [\n    \"test\"\n  ],\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/mcollina/autocannon.git\"\n  },\n  \"keywords\": [\n    \"http\",\n    \"soak\",\n    \"load\",\n    \"fast\",\n    \"wrk\",\n    \"ab\",\n    \"test\"\n  ],\n  \"author\": \"Matteo Collina <hello@matteocollina.com>\",\n  \"contributors\": [\n    \"Glen Keane <glenkeane.94@gmail.com>\",\n    \"Donald Robertson <donaldarobertson89@gmail.com\",\n    \"Salman Mitha <SalmanMitha@gmail.com>\"\n  ],\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/mcollina/autocannon/issues\"\n  },\n  \"homepage\": \"https://github.com/mcollina/autocannon#readme\",\n  \"devDependencies\": {\n    \"ansi-regex\": \"^5.0.1\",\n    \"bl\": \"^6.0.0\",\n    \"busboy\": \"^0.3.1\",\n    \"pre-commit\": \"^1.1.2\",\n    \"proxyquire\": \"^2.1.3\",\n    \"sinon\": \"^15.0.0\",\n    \"split2\": \"^4.0.0\",\n    \"standard\": \"^17.0.0\",\n    \"tap\": \"^16.0.0\",\n    \"why-is-node-running\": \"^2.3.0\"\n  },\n  \"dependencies\": {\n    \"@minimistjs/subarg\": \"^1.0.0\",\n    \"chalk\": \"^4.1.0\",\n    \"char-spinner\": \"^1.0.1\",\n    \"cli-table3\": \"^0.6.0\",\n    \"color-support\": \"^1.1.1\",\n    \"cross-argv\": \"^2.0.0\",\n    \"form-data\": \"^4.0.0\",\n    \"has-async-hooks\": \"^1.0.0\",\n    \"hdr-histogram-js\": \"^3.0.0\",\n    \"hdr-histogram-percentiles-obj\": \"^3.0.0\",\n    \"http-parser-js\": \"^0.5.2\",\n    \"hyperid\": \"^3.0.0\",\n    \"lodash.chunk\": \"^4.2.0\",\n    \"lodash.clonedeep\": \"^4.5.0\",\n    \"lodash.flatten\": \"^4.4.0\",\n    \"manage-path\": \"^2.0.0\",\n    \"on-net-listen\": \"^1.1.1\",\n    \"pretty-bytes\": \"^5.4.1\",\n    \"progress\": \"^2.0.3\",\n    \"reinterval\": \"^1.1.0\",\n    \"retimer\": \"^3.0.0\",\n    \"semver\": \"^7.3.2\",\n    \"timestring\": \"^6.0.0\"\n  }\n}\n"
        },
        {
          "name": "samples",
          "type": "tree",
          "content": null
        },
        {
          "name": "server.js",
          "type": "blob",
          "size": 0.484375,
          "content": "'use strict'\n\nconst http = require('http')\nconst https = require('https')\nconst fs = require('fs')\nconst path = require('path')\n\nconst options = {\n  key: fs.readFileSync(path.join(__dirname, 'test', '/key.pem')),\n  cert: fs.readFileSync(path.join(__dirname, 'test', '/cert.pem')),\n  passphrase: 'test'\n}\nconst server = http.createServer(handle)\nconst server2 = https.createServer(options, handle)\n\nserver.listen(3000)\nserver2.listen(3001)\n\nfunction handle (req, res) {\n  res.end('hello world')\n}\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}