{
  "metadata": {
    "timestamp": 1736562018134,
    "page": 758,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "EFForg/https-everywhere",
      "stars": 3364,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".build_exclusions",
          "type": "blob",
          "size": 0.244140625,
          "content": "pkg/*.xpi\n*~\n*.sw?\n*/.*.sw?\n*/*/.*.sw?\n*/*/*/.*.sw?\nchrome/content/rules/*.xml\nchrome/content/rules/*.py\nchrome/content/rules/validity-*\nchrome/content/rules/make-*\n*.xcf.gz\n.gitignore\n.eslintrc.json\n.eslintignore\nnode_modules\npackage-lock.json\ntest\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0068359375,
          "content": ".git/*\n"
        },
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.328125,
          "content": "# EditorConfig is awesome: https://EditorConfig.org\n\nroot = true\n\n[*]\nend_of_line = lf\ninsert_final_newline = true\ncharset = utf-8\ntrim_trailing_whitespace = true\n\n[src/chrome/content/rules/*.xml]\nindent_style = tab\nindent_size = 4\n\n[*.{css,html,js,sh}]\nindent_style = space\nindent_size = 2\n\n[*.py]\nindent_style = space\nindent_size = 4\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.294921875,
          "content": "*.pyc\n*.swp\n*~\n.DS_Store\n.idea\n.vagrant\n.venv/\n.venv2/\n.venv3/\nchromium.pem\nfrom-preloads/\npkg/\nsrc/chrome/content/rules/default.rulesets\nsrc/chrome/content/rules/default.rulesets.json\nsrc/defaults/rulesets.sqlite\ntest_profile/\ntokenkeys.py*\nVagrantfile\n.cache/\ngeckodriver.log\nnode_modules/\ncoverage/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.2236328125,
          "content": "[submodule \"translations\"]\n\tpath = translations\n\turl = https://git.torproject.org/translation.git\n\tbranch = https_everywhere\n\n[submodule \"lib-wasm\"]\n\tpath = lib-wasm\n\turl = https://github.com/EFForg/https-everywhere-lib-wasm.git\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.8193359375,
          "content": "sudo: required\nos: linux\ndist: bionic\nlanguage: python\npython: 3.6\ngroup: bionic\nservices:\n  - docker\n  - xvfb\nmatrix:\n  fast_finish: true\n  include:\n    - env: TEST=\"lint\"\n      language: node_js\n      node_js:\n        - \"lts/*\"\n    - env: TEST=\"unittests\"\n      language: node_js\n      node_js:\n        - \"lts/*\"\n    - env: TEST=\"validations\"\n    - env: TEST=\"fetch\"\n    - env: TEST=\"preloaded\"\n    # - addons:\n    #     chrome: beta\n    #   env: TEST=\"chrome beta\" BROWSER=google-chrome-beta\n    - addons:\n        chrome: stable\n      env: TEST=\"chrome stable\" BROWSER=google-chrome-stable\n    - addons:\n        firefox: latest\n      env: TEST=\"firefox\" BROWSER=firefox\n    - addons:\n        firefox: latest-esr\n      env: TEST=\"firefox esr\" BROWSER=firefox\nbefore_script: travis_retry test/setup_travis.sh\nscript: . test/run_travis.sh\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1015625,
          "content": "This project is governed by [EFF's Public Projects Code of Conduct](https://www.eff.org/pages/eppcode).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 27.3984375,
          "content": "# Table of Contents\n\n## General Info\n\n**On May 31st, 2021 we will end manual additions to the rulesets.** Please see [this explanation on the future of HTTPSE Rulesets.](https://github.com/EFForg/https-everywhere/blob/master/docs/adrs/duckduckgo-smarter-encryption.md)\n\nWe will continue accept requests on rulesets already in our list that are causing significant breakage for users through the summer. However, in autumn, we will begin the plan to ultimately move our crowdsourced rulesets out of the extension in favor of the Smarter Encryption Ruleset.\n\n- [Table of Contents](#table-of-contents)\n- [Welcome](#welcome)\n  - [HTTPS Everywhere Source Code Layout](#https-everywhere-source-code-layout)\n  - [Install Dependencies and Test Build](#install-dependencies-and-test-build)\n  - [Precommit Testing](#precommit-testing)\n  - [Testing](#testing)\n    - [Quickly Testing a Ruleset](#quickly-testing-a-ruleset)\n    - [Coverage](#coverage)\n  - [Submitting Changes](#submitting-changes)\n  - [Contributing Rulesets](#contributing-rulesets)\n    - [General Info](#general-info)\n    - [New Rulesets](#new-rulesets)\n    - [Minimum Requirements for a Ruleset PR](#minimum-requirements-for-a-ruleset-pr)\n  - [Ruleset Style Guide](#ruleset-style-guide)\n    - [Motivation](#motivation)\n    - [Indentation & Misc Stylistic Conventions](#indentation--misc-stylistic-conventions)\n    - [Wildcards in Targets](#wildcards-in-targets)\n      - [Left-Wildcards](#left-wildcards)\n      - [Edge-Case: Right-Wildcards](#edge-case-right-wildcards)\n    - [Complicated Regex in Rules](#complicated-regex-in-rules)\n    - [Enumerating Subdomains](#enumerating-subdomains)\n    - [Target Ordering](#target-ordering)\n    - [Rule Ordering](#rule-ordering)\n    - [Non-working hosts](#non-working-hosts)\n    - [Ruleset Names](#ruleset-names)\n      - [Filenames](#filenames)\n    - [Cross-referencing Rulesets](#cross-referencing-rulesets)\n    - [Regex Conventions](#regex-conventions)\n    - [Snapping Redirects](#snapping-redirects)\n    - [Example: Ruleset before style guidelines are applied](#example-ruleset-before-style-guidelines-are-applied)\n    - [Example: Ruleset after style guidelines are applied, with test URLs](#example-ruleset-after-style-guidelines-are-applied-with-test-urls)\n  - [Removal of Rules](#removal-of-rules)\n    - [Regular Rules](#regular-rules)\n    - [HSTS Preloaded Rules](#hsts-preloaded-rules)\n  - [Contributing Code](#contributing-code)\n  - [Contributing Documentation](#contributing-documentation)\n  - [Pull Requests from Deleted Accounts](#pull-requests-from-deleted-accounts)\n  - [Contributing Translations](#contributing-translations)\n\n# Welcome\n\nWelcome, and thank you for your interest in contributing to HTTPS Everywhere! HTTPS Everywhere depends on the open source community for its continued success, so any contribution is appreciated.\n\nOne of the things that makes it easy to contribute to HTTPS Everywhere is that you don't have to be a coder to contribute. That's because HTTPS Everywhere's most important component is the list of rules that tell it when it can request a website over HTTPS. These rules are just XML files that contain regular expressions, so if you can write XML and simple regexes, you can help us add rules and increase HTTPS Everywhere's coverage. No coding skills necessary!\n\nIf you want to have the greatest impact, however, you can help be a ruleset maintainer. Ruleset maintainers are trusted volunteers who examine rulesets contributed by others and work with them to ensure that these rulesets work properly and are styled correctly before they're merged in. While we currently have a couple of extremely dedicated and extremely proficient ruleset maintainers, the backlog of sites to add to HTTPS Everywhere just keeps growing, and they need help! If you would like to volunteer to become one, the best thing to do is to build trust in your work by monitoring the repository, contributing pull requests, and commenting on issues that interest you. Then you can contact us at https-everywhere-rules-owner [at] eff &lt;dot&gt; org expressing your interest in helping out.\n\nIf you get stuck we have two publicly-archived mailing lists: the [https-everywhere list](https://lists.eff.org/mailman/listinfo/https-everywhere) is for discussing the project as a whole, and the [https-everywhere-rulesets list](https://lists.eff.org/mailman/listinfo/https-everywhere-rules) is for discussing the `rulesets` and their contents, including patches and git pull requests.\n\nYou can also find more information on about HTTPS Everywhere on our [FAQ](https://www.eff.org/https-everywhere/faq) page.\n\nAlso, please remember that this project is governed by [EFF's Public Projects Code of Conduct](https://www.eff.org/pages/eppcode).\n\nThanks again, and we look forward to your contributions!\n\n## HTTPS Everywhere Source Code Layout\n\nThere are several main areas of development on HTTPS Everywhere: the rulesets, the core codebase, utilities, and tests.\n\nThe rulesets can be found in the [`rules`](rules) top-level path and include all the rules for redirecting individual sites to HTTPS.  These are written in XML. If you want to get started contributing to HTTPS Everywhere, we recommend starting here.\n\nThe core codebase consists of the code that performs the redirects, the UI, logging code, and ruleset loading.  This encompasses all code delivered with the extension itself that is *not* a ruleset.  It is written in JavaScript, using the `WebExtensions` API (located in [`chromium`](chromium)).\n\nThe utilities ([`utils`](utils) top-level path) include scripts that build the extension, sanitize and perform normalization on rulesets, simplify rules, and help label GitHub issues.  Historically, these utilities have been written in Python.  Many of the newer utilities are written in JavaScript, and are meant to be run in node.  Some of the wrappers for these utilities are in shell scripts.\n\nTests are performed in headless browsers and located in the [`test`](test) top-level path.  These are written in Python, and some of the wrappers for these tests are in shell scripts.\n\nSource Tree:\n\n\t\tchromium/                 WebExtension source code (for Firefox & Chromium/chrome)\n\t\tchromium/external         External dependencies\n\t\tchromium/test             Unit tests\n\n\t\trules/                    Symbolic link to src/chrome/content/rules\n\n\t\tsrc/chrome/content/rules  Ruleset files live here\n\n\t\ttest/                     Travis unit test source code live here\n\n\t\tutils/                    Various utilities (includes some Travis test source)\n\n## Install Dependencies and Test Build\n\nGet the packages you need and install a git hook to run tests before push:\n\n\t\tbash install-dev-dependencies.sh\n\nRun the ruleset validations and browser tests:\n\n\t\tbash test.sh\n\nRun the latest code and rulesets in a standalone Firefox profile:\n\n\t\tbash test/firefox.sh --justrun\n\nRun the latest code and rulesets in a standalone profile for a specific version of Firefox:\n\n\t\tFIREFOX=/path/to/firefox bash test/firefox.sh --justrun\n\nRun the latest code and rulesets in a standalone Chromium profile:\n\n\t\tbash test/chromium.sh --justrun\n\nRun the latest code and rulesets in a standalone Tor Browser profile:\n\n\t\tbash test/tor-browser.sh path_to_tor_browser.tar.xz\n\nBuild the Firefox (.xpi) & Chromium (.crx) extensions:\n\n\t\tbash make.sh\n\nBoth of the build commands store their output under pkg/.\n\n## Precommit Testing\n\nOne can run the available test suites automatically by enabling the precommit\nhook provided with:\n\n\t\tln -s ../../hooks/precommit .git/hooks/pre-commit\n\n## Testing\n\n### Quickly Testing a Ruleset\n\n1. Open a version of the Firefox or Chrome browser without HTTPS Everywhere loaded to the HTTP endpoint\n\n2. From your working ruleset branch, test with running `bash test/firefox.sh --justrun` or `bash test/chromium.sh --justrun` to open a fresh profile with the extension loaded and click around and compare the look and functionality of both sites. If something fails to load or looks strange, you may be able to debug the problem by opening the network tab of your browser debugging tool.  Modify the `ruleset` until you get it in a good state - you'll have to re-run the HTTPS Everywhere-equipped browser upon each change.\n\n### Coverage\n\nPlease reference [HTTPS Ruleset Checker](https://github.com/EFForg/https-everywhere/blob/master/test/rules/README.md) to properly test rulesets against our tests before sending a pull request.\n\n## Submitting Changes\n\nTo submit changes, open a pull request from our [GitHub repository](https://github.com/efforg/https-everywhere).\n\nHTTPS Everywhere is maintained by a limited set of staff and volunteers.  Please be mindful that we may take a while before we're able to review your contributions.\n\n## Contributing Rulesets\n\nThanks for your interest in contributing to the HTTPS Everywhere `rulesets`! There's just a few things you should know before jumping in. First some terminology, which will help you understand how exactly `rulesets` are structured and what each one contains:\n\n* `ruleset`: a scope in which `rules`, `targets`, and `tests` are contained. `rulesets` are usually named after the entity which controls the group of `targets` contained in it.  There is one `ruleset` per XML file within the `src/chrome/content/rules` directory.\n* `target`: a Fully Qualified Domain Name which may include a wildcard specified by `*.` on the left side, which `rules` are applied to. There may be many `targets` within any given `ruleset`.\n* `rule`: a specific regular expression rewrite that is applied for all matching `targets` within the same `ruleset`.  There may be many `rules` within any given `ruleset`.\n* `test`: a URL for which a request is made to ensure that the rewrite is working properly.  There may be many `tests` within any given `ruleset`.\n\n```xml\n<!--\n\t\t\t\tAn example ruleset. Note that this example doesn't necessarily\n\t\t\t\tsatisfy the style criteria described below - we just have it\n\t\t\t\there to show you what the components of a ruleset looks like.\n-->\n<ruleset name=\"eff.org\">\n\t\t\t\t<target host=\"*.eff.org\" />\n\n\t\t\t\t<rule from=\"^http:\" to=\"https:\" />\n\n\t\t\t\t<test url=\"http://www.eff.org/https-everywhere/\" />\n</ruleset>\n```\n\nHTTPS Everywhere includes tens of thousands of `rulesets`.  Any one of these sites can change their HTTPS configuration at any time, so keeping HTTPS Everywhere usable is a task that requires constant maintenance.  At the same time, HTTPS deployment on the web is becoming more and more widespread, thanks to projects like [Let's Encrypt](https://letsencrypt.org/).  This is a very good thing, as it means the web is becoming a safer place!  However, with each new `ruleset` that HTTPS Everywhere includes comes with an increase in both download size upon install and memory usage at runtime.  Rather than adding new `rulesets`, we encourage potential contributors to look for broken `rulesets` and try to fix them first.\n\nSome `rulesets` have the attribute `platform=\"mixedcontent\"`.  These `rulesets` cause problems in browsers that enable active mixed-content (loading insecure resources in a secure page) blocking.  When browsers started enforcing active mixed-content blocking, some HTTPS sites started to break.  That's why we introduced this tag - it disables those `rulesets` for browsers blocking active mixed content.  It is likely that many of these sites have fixed this historical problem, so we particularly encourage `ruleset` contributors to fix these `rulesets` first:\n\n\t\tgit grep -i mixedcontent src/chrome/content/rules\n\n### New Rulesets\n\nIf you want to create new `rulesets` to submit to us, we expect them to be in the `src/chrome/content/rules` directory. That directory also contains a useful script, `make-trivial-rule`, to create a simple `ruleset` for a specified domain. There is also a script in `test/validations/special/run.py`, to check all the pending `rulesets` for several common errors and oversights. For example, if you wanted to make a `ruleset` for the `example.com` domain, you could run:\n\n```bash\ncd src/chrome/content/rules\nbash ./make-trivial-rule example.com\n```\n\nThis would create `Example.com.xml`, which you could then take a look at and edit based on your knowledge of any specific URLs at `example.com` that do or don't work in HTTPS. Please have a look at our Ruleset Style Guide below, where you can find useful tips about finding more subdomains. Our goal is to have as many subdomains covered as we can find.\n\n### Minimum Requirements for a Ruleset PR\n\nThere are several volunteers to HTTPS Everywhere who have graciously dedicated their time to look at the `ruleset` contributions and work with contributors to ensure quality of the pull requests before merging.  It is typical for there to be several back-and-forth communications with these `ruleset` maintainers before a PR is in a good shape to merge.  Please be patient and respectful, the maintainers are donating their time for no benefit other than the satisfaction of making the web more secure.  They are under no obligation to merge your request, and may reject it if it is impossible to ensure quality.  You can identify these volunteers by looking for the \"Collaborator\" identifier in their comments on HTTPS Everywhere issues and pull requests.\n\nIn the back-and-forth process of getting the `ruleset` in good shape, there may be many commits made.  It is this project's convention to squash-and-merge these commits into a single commit before merging into the project.  If your commits are cryptographically signed, we may ask you to squash the commits yourself in order to preserve this signature.  Otherwise, we may squash them ourselves before merging.\n\nWe prefer small, granular changes to the rulesets.  Not only are these easier to test and review, this results in cleaner commits.\n\n## Ruleset Style Guide\n\n### Motivation\n\nRules should be written in a way that is consistent, easy for humans to read and debug, reduces the chance of errors, and makes testing easy.\n\nTo that end here are some style guidelines for writing or modifying rulesets. They are intended to help and simplify in places where choices are ambiguous, but like all guidelines they can be broken if the circumstances require it.\n\n### Indentation & Misc Stylistic Conventions\n\nUse tabs for indentation.  For `tests` and `exclusions`, place them under the `target` that they refer to, indented one additional layer.  See below for an example.\n\nWe provide an [`.editorconfig`](.editorconfig) file in the top-level path, which you can configure your editor of choice to use.  This will enforce proper indentation.\n\nUse double quotes (`\"`, not `'`).\n\n### Wildcards in Targets\n\n#### Left-Wildcards\n\nAvoid using the left-wildcard (`<target host=\"*.example.com\" />`) unless you intend to rewrite all or nearly all subdomains.  If it can be demonstrated that there is comprehensive HTTPS coverage for subdomains, left-wildcards may be appropriate.  Many rules today specify a left-wildcard target, but the rewrite rules only rewrite an explicit list of hostnames.\n\nInstead, prefer listing explicit target hosts and a single rewrite from `\"^http:\"` to `\"^https:\"`. This saves you time as a ruleset author because each explicit target host automatically creates an implicit test URL, reducing the need to add your own test URLs. These also make it easier for someone reading the ruleset to figure out which subdomains are covered.\n\nIf you know all subdomains of a given domain support HTTPS, go ahead and use a left-wildcard, along with a plain rewrite from `\"^http:\"` to `\"^https:\"`. Make sure to add a bunch of test URLs for the more important subdomains.\n\n#### Edge-Case: Right-Wildcards\n\nRight-wildcards (`<target host=\"account.google.*\" />`) are highly discouraged.  Only use them in edge-cases where other solutions are unruly.\n\nExample:\n\n* Complicated rulesets like [`Google.tld_Subdomains.xml`](https://github.com/EFForg/https-everywhere/blob/cb03ac8418a773a309d605231a15a702fce96ce9/src/chrome/content/rules/Google.tld_Subdomains.xml)\n\nWhere they must be used, please add a comment to the `ruleset` explaining why.\n\n### Complicated Regex in Rules\n\nAvoid regexes with long strings of subdomains, e.g. `<rule from=\"^http://(foo|bar|baz|bananas).example.com\" />`. These are hard to read and maintain, and are usually better expressed with a longer list of target hosts, plus a plain rewrite from `\"^http:\"` to `\"^https:\"`.\n\nIn general, avoid using open-ended regex in rules.  In certain cases, open-ended regex may be the most elegant solution.  But carefully consider if there are other options.\n\nExamples:\n\n* Rulesets with a lot of domains that we can catch with a simple regex that would be tedious and error-prone to list individually, like [`360.cn.xml`](https://github.com/EFForg/https-everywhere/blob/9698e64a2de7cf37509ab13ba9dcfd5bd4f84a95/src/chrome/content/rules/360.cn.xml#L98-L103)\n* CDNs with an arbitrarily large number of subdomains ([example](https://github.com/EFForg/https-everywhere/pull/7484#issuecomment-262852427)).\n\n### Enumerating Subdomains\n\nIf you're not sure what subdomains might exist, you can install the `Sublist3r` tool:\n\n\t\tgit clone https://github.com/aboul3la/Sublist3r.git\n\t\tcd Sublist3r\n\t\tsudo pip install -r requirements.txt # or use virtualenv...\n\nThen you can to enumerate the list of subdomains:\n\n\t\tpython sublist3r.py -d example.com -e Baidu,Yahoo,Google,Bing,Ask,Netcraft,Virustotal,SSL\n\nAlternatively, you can iteratively use Google queries and enumerate the list of results like such:\n\n1. site:*.eff.org\n2. site:*.eff.org -site:www.eff.org\n3. site:*.eff.org -site:www.eff.org -site:ssd.eff.org\n\n... and so on.\n\n### Target Ordering\n\nIn all cases where there is a list of domains, sort them in alphabetical order starting from the top level domain at the right reading left, moving ^ and www to the top of their group. For example:\n\n\t\texample.com\n\t\twww.example.com\n\t\ta.example.com\n\t\twww.a.example.com\n\t\tb.a.example.com\n\t\tb.example.com\n\t\texample.net\n\t\twww.example.net\n\t\ta.example.net\n\n### Rule Ordering\n\nIf there are a handful of tricky subdomains, but most subdomains can handle the plain rewrite from `\"^http:\"` to `\"^https:\"`, specify the rules for the tricky subdomains first, and then then plain rule last. Earlier rules will take precedence, and processing stops at the first matching rule. There may be a tiny performance hit for processing exception cases earlier in the ruleset and the common case last, but in most cases the performance issue is trumped by readability.\n\n### Non-working hosts\n\nIt is useful to list hosts that do not work in the comments of a `ruleset`.  This is a stylistic preference but is not strictly required.\n\nFor easy reading, please avoid using UTF characters unless in the rare instances that they are part of the hostname itself.\n\nExample:\n\n```xml\n<!--\n\tInvalid certificate:\n\t\t\t\t\tincomplete.example.com (incomplete certificate chain)\n\t\t\t\t\tselfsigned.example.com\n\t\t\t\t\twronghost.example.com\n\n\tRedirect to HTTP:\n\t\t\t\t\thttponly.example.com\n\n\tRefused:\n\t\t\t\t\tabc.example.com\n\t\t\t\t\tabc.abc.example.com\n\n\tTime out:\n\t\t\t\t\tdrop.example.com\n\n-->\n```\n\nIn most cases, the absence of a `2XX` or `3XX` endpoint indicates that a host should not be included in the set of `targets` and is non-working, *except* when it is clear that the site functions as intended in the absence of such an endpoint.\n\n### Ruleset Names\n\nFor simple sites, the `ruleset` `name` attribute can be either a site description or the domain itself. For example, the [SeattleAquarium.org.xml](https://github.com/EFForg/https-everywhere/blob/30b7a0101d0bb8a492a0f089096bc162de07f778/src/chrome/content/rules/SeattleAquarium.org.xml) ruleset could have a `name` of `Seattle Aquarium`, `SeattleAquarium.org`, or `seattleaquarium.org`.\n\nIf a `ruleset` covers multiple domains, then the `ruleset` `name` should reflect the broader organization, project, or concept for what a ruleset is trying to accomplish.\n\nExamples:\n\n* [`Google.xml`](https://github.com/EFForg/https-everywhere/blob/5.2.10/src/chrome/content/rules/Google.xml) is just named `Google`, and\n* [`Bitly.xml`](https://github.com/EFForg/https-everywhere/blob/5.2.10/src/chrome/content/rules/Bitly.xml) is named `bit.ly`, but\n* [`Bitly_branded_short_domains.xml`](https://raw.githubusercontent.com/EFForg/https-everywhere/5.2.10/src/chrome/content/rules/Bitly_branded_short_domains.xml) is named `Bitly vanity domains`\n\n#### Filenames\n\nFilenames should vaguely resemble the `name` so that someone looking for the file based on the `name` can find it easily. Filenames that start with a capital letter are preferred.  Prefer dashes over underscores in filenames. Dashes are easier to type.\n\n### Cross-referencing Rulesets\n\nThis sort of comment: `For other Migros coverage, see Migros.xml.` is definitely appropriate, in both directions.\n\n### Regex Conventions\n\nWhen matching an arbitrary DNS label (a single component of a hostname), prefer `([\\w-]+)` for a single label (i.e. www), or `([\\w.-]+)` for multiple labels (i.e. www.beta). Avoid more visually complicated options like `([^/:@\\.]+\\.)?`.\n\nFor `securecookie` tags, if you know that all cookies on the included targets can be secured (which in particular means that the cookies are not used by any of its non-securable subdomains), use the trivial\n\n```xml\n<securecookie host=\".+\" name=\".+\" />\n```\n\nwhere we prefer `.+` over `.*` and `.`. They are functionally equivalent, but it's nice to be consistent.\n\nAvoid the negative lookahead operator `?!`. This is almost always better expressed using positive rule tags and negative exclusion tags. Some rulesets have exclusion tags that contain negative lookahead operators, which is very confusing.\n\nPrefer capturing groups `(www\\.)?` over non-capturing `(?:www\\.)?`. The non-capturing form adds extra line noise that makes rules harder to read. Generally you can achieve the same effect by choosing a correspondingly higher index for your replacement group to account for the groups you don't care about.\n\n### Snapping Redirects\n\nAvoid snapping redirects. For instance, if `https://foo.fm` serves HTTPS correctly, but redirects to `https://foo.com`, it's tempting to rewrite `foo.fm` to `foo.com`, to save users the latency of the redirect. However, such rulesets are less obviously correct and require more scrutiny. And the redirect can go out of date and cause problems. HTTPS Everywhere rulesets should change requests the minimum amount necessary to ensure a secure connection.\n\n### Example: Ruleset before style guidelines are applied\n\n```xml\n<ruleset name=\"WHATWG.org\">\n\t\t<target host='whatwg.org' />\n\t\t<target host=\"*.whatwg.org\" />\n\n\t\t<rule from=\"^http://((?:developers|html-differences|images|resources|\\w+\\.spec|wiki|www)\\.)?whatwg\\.org/\"\n\t\tto=\"https://$1whatwg.org/\" />\n</ruleset>\n```\n\n### Example: Ruleset after style guidelines are applied, with test URLs\n\n```xml\n<ruleset name=\"WHATWG.org\">\n\t<target host=\"whatwg.org\" />\n\t<target host=\"www.whatwg.org\" />\n\t<target host=\"developers.whatwg.org\" />\n\t<target host=\"html-differences.whatwg.org\" />\n\t<target host=\"images.whatwg.org\" />\n\t<target host=\"resources.whatwg.org\" />\n\t<target host=\"*.spec.whatwg.org\" />\n\t\t<test url=\"http://html.spec.whatwg.org/\" />\n\t\t<test url=\"http://fetch.spec.whatwg.org/\" />\n\t\t<test url=\"http://xhr.spec.whatwg.org/\" />\n\t\t<test url=\"http://dom.spec.whatwg.org/\" />\n\t<target host=\"wiki.whatwg.org\" />\n\n\t<rule from=\"^http:\" to=\"https:\" />\n</ruleset>\n```\n\n## Removal of Rules\n\n### Regular Rules\n\nIt should be considered a sufficient condition for removal if a contributor can demonstrate that the TLS configuration for either a specific `target` or a ruleset altogether is unstable and/or breaking, or will be unstable and/or breaking in the near future.  It is, of course, preferable that the `ruleset` be fixed rather than removed.\n\n### HSTS Preloaded Rules\n\nIn `utils` we have a tool called `hsts-prune` which removes `targets` from rulesets if they are already contained in the [HSTS preload](https://hstspreload.org/) list for browsers that we support.  To be explicit, the script is an implementation of the following policy:\n\n> Let `included domain` denote either a `target`, or a parent of a `target`.  Let `supported browsers` include the ESR, Dev, and Stable releases of Firefox, and the Stable release of Chromium.  If `included domain` is a parent of the `target`, the `included domain` must be present in the HSTS preload list for all `supported browsers` with the relevant flag which denotes inclusion of subdomains set to `true`.  If `included domain` is the `target` itself, it must be included the HSTS preload list for all `supported browsers`.  Additionally, if the http endpoint of the `target` exists, it must issue a 3XX redirect to the https endpoint for that target.  Additionally, the https endpoint for the `target` must deliver a `Strict-Transport-Security` header with the following directives present:\n>\n> * `max-age` >= 31536000\n> * `includeSubDomains`\n> * `preload`\n>\n> If all the above conditions are met, a contributor may remove the `target` from the HTTPS Everywhere rulesets.  If all targets are removed for a ruleset, the contributor is advised to remove the ruleset file itself.  The ruleset `rule` and `test` tags may need to be modified in order to pass the ruleset coverage test.\n\nEvery new pull request automatically has the `hsts-prune` utility applied to it as part of the continual integration process.  If a new PR introduces a `target` which is preloaded, it will fail the CI test suite.  See:\n\n* `.travis.yml`\n* `test/run_travis.sh`\n\n## Contributing Code\n\nIn addition to `ruleset` contributions, we also encourage code contributions to HTTPS Everywhere.  There are a few considerations to keep in mind when contributing code.\n\nOfficially supported browsers:\n\n* Firefox Stable\n* Firefox ESR\n* Chromium Stable\n\nWe also informally support the Opera browser, but do not have tooling around testing Opera.  Firefox ESR is supported because this is what the [Tor Browser](https://www.torproject.org/projects/torbrowser.html.en), which includes HTTPS Everywhere, is built upon.  For the test commands, refer to [README.md](README.md).\n\nThe current extension maintainer is [@zoracon](https://github.com/zoracon).  You can tag them for PRs which involve the core codebase.\n\nSeveral of our utilities and our full test suite is written in Python.  Eventually we would like the whole codebase to be standardized as JavaScript.  If you are so inclined, it would be helpful to rewrite the tooling and tests into JavaScript while maintaining the functionality.\n\n## Contributing Documentation\n\nStandalone documentation should be written in [Markdown](https://en.wikipedia.org/wiki/Markdown) that follows the [Google style guide](https://github.com/google/styleguide/blob/gh-pages/docguide/style.md). If you are updating existing documentation that does not follow the Google style guide, then you should follow the style of the file you are updating.\n\n* * *\n\n## Pull Requests from Deleted Accounts\n\nSometimes a contributor will [delete their GitHub account](https://help.github.com/articles/deleting-your-user-account/) after submitting a pull request, resulting in the pull request being associated with the [Ghost user (@ghost)](https://github.com/ghost).  These @ghost pull requests can cause problems for HTTPS Everywhere maintainers, leaving questions unanswered and closing off the possibility of receiving maintainer feedback to solicit clarification or request changes.\n\nWe ask that if you want to delete your GitHub account, you either close your HTTPS Everywhere pull requests before you delete your account, or wait to delete your account until we merge your pull requests. Otherwise, maintainers are free to close @ghost pull requests without any comment.\n\n## Contributing Translations\n\nWe are reviewing our process around translations and currently discussing ways to improve. Translations are still processed under the same entity and those who have an account already, do not need to take action at this time. Thank you for your contributions.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.2255859375,
          "content": "FROM electronicfrontierfoundation/https-everywhere-docker-base\nMAINTAINER William Budington \"bill@eff.org\"\nWORKDIR /opt\n\nCOPY test/rules/requirements.txt /tmp/\nRUN pip3 install -r /tmp/requirements.txt\nRUN rm /tmp/requirements.txt\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 0.83203125,
          "content": "HTTPS Everywhere:\nCopyright © 2010-2021 Electronic Frontier Foundation and others\nLicensed GPL v2+\n\nHTTPS Everywhere Rulesets (src/chrome/content/rules):\nTo the extent copyright applies to the rulesets, they can be used according to GPL v2 or later.\n\nThe DuckDuckGo Smarter Encryption list, utilized by HTTPS Everywhere at https://www.https-rulesets.org/ddg, is publicly available under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0. International license. \nIf you'd like to license the list for commercial use, please reach out to: https://help.duckduckgo.com/duckduckgo-help-pages/company/contact-us/\n\nIssue Format Bot (utils/issue-format-bot/*):\nCopyright © 2017 AJ Jordan, AGPLv3+\n\nThe build system incorporates code from Python 3.6 and Python 3 respectively\nCopyright © 2001-2018 Python Software Foundation; All Rights Reserved\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.3779296875,
          "content": "[![Build Status](https://travis-ci.com/EFForg/https-everywhere.svg?branch=master)](https://travis-ci.com/EFForg/https-everywhere)\n[![Coverage Status](https://coveralls.io/repos/github/EFForg/https-everywhere/badge.svg?branch=master)](https://coveralls.io/github/EFForg/https-everywhere?branch=master)\n\n# Update on HTTPS Everywhere\n⚠️This project is no longer being maintained or updated. Please uninstall and direct users to the advice below to switch to HTTPS by default natively.\n\nYou no longer need HTTPS Everywhere to set HTTPS by default! Major browsers now offer native support for an HTTPS only mode.\nFind out how to turn it on [here](https://www.eff.org/https-everywhere/set-https-default-your-browser).\n\nThis extension will be sunset by January 2023.\n\n\n# Getting Started With HTTPS Everywhere\n\nHTTPS Everywhere is a Firefox, Chrome, and Opera extension that encrypts your communications with many major websites, making your browsing more secure. Encrypt the web: [Install HTTPS Everywhere today](https://www.eff.org/https-everywhere).\n\n## For Users\n\nWant to install or uninstall HTTPS Everywhere? Have questions? [View this guide](https://www.eff.org/https-everywhere) for installation and here for [FAQs](https://www.eff.org/https-everywhere/faq).\n\n## For Website Owners and Maintainers\n\nWant to deploy HTTPS on your site? [View this guide](https://www.eff.org/https-everywhere/deploying-https).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.4599609375,
          "content": "# Security Policy\n\n## Supported Versions\n\nUse this section to tell people about which versions of your project are\ncurrently being supported with security updates.\n\n| Browser         |  Supported         |\n| --------------- | ------------------ |\n| Firefox         | :white_check_mark: |\n| Firefox Android | :white_check_mark: |\n| Chrome          | :white_check_mark: |\n| Opera           | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nhttps://www.eff.org/security\n"
        },
        {
          "name": "browser-dist",
          "type": "tree",
          "content": null
        },
        {
          "name": "chromium",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dummy-chromium.pem",
          "type": "blob",
          "size": 0.7041015625,
          "content": "-----BEGIN PRIVATE KEY-----\nMIIB5gIBADANBgkqhkiG9w0BAQEFAASCAdAwggHMAgEAAmEA3BZGOZsEWGEc82Yz\nDdrey4Vp8dV4AQZPu2tM32Z6ZEx2538G3bWu5g0OPzX8Oqvzqr8ZRIvxcBbL3kgZ\n5wnhjVRTlWy0jxZDHCvVsATzhbhAt505zljHaRS1PrCYfV/nAgMBAAECYCQpRMCS\nR9R9oFQdpqXQIGswMIgbmuwQLWmN58ONAu8X4TGIHYiwIVyLKJwaMqcxOTn753Us\n7vFbGwoMnO3Krzh1Xn9z6uKnB7dDotgc9ZIQ5Ja8ExjJhl5iBMSWePYWAQIxAPRo\nyZ+JdWu+/y+/F6KsiCDx8EmdV8Dd09BogXH31S2VtSUEfZd/UDUPgbRgo+c9dwIx\nAOaGNJyJbHY4UCxC2hRBRZGNlic8SaFKEQAtN28gMWMDMgAh0ik8YtrPffBed+bN\nEQIxAOwTAx0MItTt6YLu6x9/0wUva89PIWHzYhKdvtqcbdbYEd4tljntCUYXMktO\nRUKoRQIxAL/3PHKqoc6kwGbLWO2LGVLHNCYCN1J/6j5aaRI6HcZVD9s6TteV+MA8\nD6UOFgz18QIxAJKXHDXXF+LXGsOwRMcp8nqg9Ri9daWW74JWyozFRqIsRhnhDhw9\n8f4cUAPw7BquBw==\n-----END PRIVATE KEY-----\n"
        },
        {
          "name": "hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "install-dev-dependencies.sh",
          "type": "blob",
          "size": 4.2744140625,
          "content": "#!/bin/bash\n# Install packages that are necessary and/or useful to build and debug\n# HTTPS Everywhere\nset -o errexit\n\nif [ \"$1\" != \"--no-prompt\" ]; then\n  echo\n  echo \"Warning: Installing the development dependencies for HTTPS Everywhere\"\n  echo \"may alter your system, installing requirements both within the package\"\n  echo \"management system and also external binaries.\"\n  echo\n  echo -n \"Are you sure you want to continue? [y/N]: \"\n  read CONTINUE\n  CONTINUE=`echo $CONTINUE | xargs | head -c 1 | awk '{print tolower($0)}'`\n  if [ \"$CONTINUE\" != \"y\" ]; then\n    exit\n  fi\n  echo\nfi\n\nif [ $UID != 0 ]; then\n  SUDO_SHIM=sudo\nfi\n\nif [ \"`uname -m`\" == \"x86_64\" ]; then\n  ARCH=64\nelse\n  ARCH=32\nfi\n\n# debian based installation\nif type apt-get>/dev/null 2>&1;  then\n  $SUDO_SHIM apt-get update\n  $SUDO_SHIM apt-get install -y lsb-release\n  BROWSERS=\"firefox chromium-browser\"\n  CHROMEDRIVER=\"chromium-chromedriver\"\n  if [[ \"$(lsb_release -is)\" == \"Debian\" ]]; then\n    # Chromium takes the name of 'chromium' instead of 'chromium-browser' in\n    # Debian 7 (wheezy) and later.\n    BROWSERS=\"firefox-esr chromium\"\n    CHROMEDRIVER=\"chromium-driver\"\n  fi\n  $SUDO_SHIM apt-get install -y libxml2-dev libxml2-utils libxslt1-dev \\\n    python3-dev $BROWSERS zip sqlite3 python3-pip libcurl4-openssl-dev xvfb \\\n    nodejs \\\n    npm \\\n    libssl-dev git curl $CHROMEDRIVER\n  if ! type geckodriver >/dev/null 2>&1;  then\n    curl -LO \"https://github.com/mozilla/geckodriver/releases/download/v0.24.0/geckodriver-v0.24.0-linux$ARCH.tar.gz\"\n    tar -zxvf \"geckodriver-v0.24.0-linux$ARCH.tar.gz\"\n    rm -f \"geckodriver-v0.24.0-linux$ARCH.tar.gz\"\n    $SUDO_SHIM mv geckodriver /usr/bin/geckodriver\n    $SUDO_SHIM chown root /usr/bin/geckodriver\n    $SUDO_SHIM chmod 755 /usr/bin/geckodriver\n  fi\n  if [ ! -f /usr/lib/chromium-browser/chromedriver ] && [ -f `which chromedriver` ]; then\n    $SUDO_SHIM ln -s `which chromedriver` /usr/lib/chromium-browser/chromedriver\n  fi\n\n# macOS installation\nelif type brew >/dev/null 2>&1; then\n  brew list python &>/dev/null || brew install python\n  brew cask install chromedriver\n  brew install libxml2 gnu-sed\n  brew install node\n  if ! echo $PATH | grep -ql /usr/local/bin ; then\n    echo '/usr/local/bin not found in $PATH, please add it.'\n  fi\n\n# distros that use rpm (Fedora, Suse, CentOS) installation\nelif type dnf >/dev/null 2>&1; then\n  $SUDO_SHIM dnf install -y firefox gcc git libcurl-devel libxml2-devel \\\n    libxslt-devel python3-devel redhat-rpm-config xorg-x11-server-Xvfb which \\\n    findutils procps openssl openssl-devel chromium GConf2\n  if ! type chromedriver >/dev/null; then\n    curl -O \"https://chromedriver.storage.googleapis.com/2.23/chromedriver_linux$ARCH.zip\"\n    unzip \"chromedriver_linux$ARCH.zip\"\n    rm -f \"chromedriver_linux$ARCH.zip\"\n    $SUDO_SHIM mv chromedriver /usr/bin/chromedriver\n    $SUDO_SHIM chown root /usr/bin/chromedriver\n    $SUDO_SHIM chmod 755 /usr/bin/chromedriver\n  fi\n  if ! type geckodriver >/dev/null 2>&1;  then\n    curl -LO \"https://github.com/mozilla/geckodriver/releases/download/v0.24.0/geckodriver-v0.24.0-macos.tar.gz\"\n    tar -zxvf \"geckodriver-v0.24.0-macos.tar.gz\"\n    rm -f \"geckodriver-v0.24.0-macos.tar.gz\"\n    $SUDO_SHIM mv geckodriver /usr/bin/geckodriver\n    $SUDO_SHIM chown root /usr/bin/geckodriver\n    $SUDO_SHIM chmod 755 /usr/bin/geckodriver\n  fi\n\n  # This is needed for Firefox on some systems. See here for more information:\n  # https://github.com/EFForg/https-everywhere/pull/5584#issuecomment-238655443\n  if [ ! -f /var/lib/dbus/machine-id ]; then\n    $SUDO_SHIM sh -c 'dbus-uuidgen > /var/lib/dbus/machine-id'\n  fi\n  export PYCURL_SSL_LIBRARY=openssl\n\n  #Node\n  curl -sL https://rpm.nodesource.com/setup_12.x | $SUDO_SHIM bash -\n  $SUDO_SHIM yum install -y nodejs\n  $SUDO_SHIM yum install gcc-c++ make\nelse\n    echo \\\n    \"Your distro isn't supported by this script yet!\"\\\n    \"Please install dependencies manually.\"\n    exit\nfi\n\n# Get the addon SDK submodule and rule checker\ngit submodule init\ngit submodule update\n\n# Install Python packages\npip3 install --user -r requirements.txt\ncd test/rules\npip3 install --user -r requirements.txt\ncd -\ncd test/chromium\npip3 install --user -r requirements.txt\ncd -\n\n# Install Node Package for CRX Verification\n$SUDO_SHIM npm -g i crx3-utils\n\n# Install git hook to run tests before pushing.\nln -sf ../../test.sh .git/hooks/pre-push\n"
        },
        {
          "name": "lib-wasm",
          "type": "commit",
          "content": null
        },
        {
          "name": "make.sh",
          "type": "blob",
          "size": 8.384765625,
          "content": "#!/usr/bin/env bash\n\n# Build an HTTPS Everywhere .crx & .xpi extension\n#\n# To build the current state of the tree:\n#\n#     ./make.sh\n#\n# To build a particular tagged release:\n#\n#     ./make.sh <version number>\n#\n# eg:\n#\n#     ./make.sh 2017.8.15\n#\n# Note that .crx files must be signed; this script makes you a\n# \"dummy-chromium.pem\" private key for you to sign your own local releases,\n# but these .crx files won't detect and upgrade to official HTTPS Everywhere\n# releases signed by EFF :/.  We should find a more elegant arrangement.\n\n! getopt --test > /dev/null\nif [[ ${PIPESTATUS[0]} -ne 4 ]]; then\n  echo 'I’m sorry, `getopt --test` failed in this environment.'\n  exit 1\nfi\n\nOPTIONS=eck:\nLONGOPTS=remove-extension-update,remove-update-channels,key:\n! PARSED=$(getopt --options=$OPTIONS --longoptions=$LONGOPTS --name \"$0\" -- \"$@\")\nif [[ ${PIPESTATUS[0]} -ne 0 ]]; then\n  # e.g. return value is 1\n  #  then getopt has complained about wrong arguments to stdout\n  exit 2\nfi\n\n# read getopt’s output this way to handle the quoting right:\neval set -- \"$PARSED\"\n\nREMOVE_EXTENSION_UPDATE=false\nREMOVE_UPDATE_CHANNELS=false\nKEY=$(pwd)/dummy-chromium.pem\nwhile true; do\n  case \"$1\" in\n    -e|--remove-extension-update)\n      REMOVE_EXTENSION_UPDATE=true\n      shift\n      ;;\n    -c|--remove-update-channels)\n      REMOVE_UPDATE_CHANNELS=true\n      shift\n      ;;\n    -k|--key)\n      KEY=\"$2\"\n      shift 2\n      ;;\n    --)\n      shift\n      break\n      ;;\n    *)\n      echo \"Programming error\"\n      exit 3\n      ;;\n  esac\ndone\n\nif [ \"${KEY:0:1}\" != \"/\" ]; then\n  echo \"Key must be specified as an absolute path.\"\n  exit 4\nfi\n\n\n\n\ncd $(dirname $0)\n\nif [ -n \"$1\" ]; then\n  BRANCH=`git branch | head -n 1 | cut -d \\  -f 2-`\n  SUBDIR=checkout\n  [ -d $SUBDIR ] || mkdir $SUBDIR\n  cp -r -f -a .git $SUBDIR\n  cd $SUBDIR\n  git reset --hard \"$1\"\n  git submodule update --recursive -f\nfi\n\nVERSION=`python3 -c \"import json ; print(json.loads(open('chromium/manifest.json').read())['version'])\"`\n\necho \"Building version\" $VERSION\n\n[ -d pkg ] || mkdir -p pkg\n[ -e pkg/crx-cws ] && rm -rf pkg/crx-cws\n[ -e pkg/crx-eff ] && rm -rf pkg/crx-eff\n[ -e pkg/xpi-amo ] && rm -rf pkg/xpi-amo\n[ -e pkg/xpi-eff ] && rm -rf pkg/xpi-eff\n\n# Clean up obsolete ruleset databases, just in case they still exist.\nrm -f src/chrome/content/rules/default.rulesets src/defaults/rulesets.sqlite\n\nmkdir -p pkg/crx-cws/rules\ncd pkg/crx-cws\ncp -a ../../chromium/* ./\n# Turn the Firefox translations into the appropriate Chrome format:\nrm -rf _locales/\nmkdir _locales/\npython3 ../../utils/chromium-translations.py ../../translations/ _locales/\npython3 ../../utils/chromium-translations.py ../../src/chrome/locale/ _locales/\ndo_not_ship=\"*.py *.xml\"\nrm -f $do_not_ship\n\nmkdir wasm\ncp ../../lib-wasm/pkg/*.wasm wasm\ncp ../../lib-wasm/pkg/*.js wasm\n\ncd ../..\n\npython3 ./utils/merge-rulesets.py || exit 5\n\ncp src/chrome/content/rules/default.rulesets pkg/crx-cws/rules/default.rulesets\n\nsed -i -e \"s/VERSION/$VERSION/g\" pkg/crx-cws/manifest.json\n\nfor x in `cat .build_exclusions`; do\n  rm -rf pkg/crx-cws/$x\ndone\n\ncp -a pkg/crx-cws pkg/crx-eff\ncp -a pkg/crx-cws pkg/xpi-amo\ncp -a pkg/crx-cws pkg/xpi-eff\ncp -a src/META-INF pkg/xpi-amo\ncp -a src/META-INF pkg/xpi-eff\n\n\n# Remove the 'applications' manifest key from the crx version of the extension, change the 'author' string to a hash, and add the \"update_url\" manifest key\n# \"update_url\" needs to be present to avoid problems reported in https://bugs.chromium.org/p/chromium/issues/detail?id=805755\npython3 -c \"import json; m=json.loads(open('pkg/crx-cws/manifest.json').read()); m['author']={'email': 'eff.software.projects@gmail.com'}; del m['applications']; m['update_url'] = 'https://clients2.google.com/service/update2/crx'; open('pkg/crx-cws/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\npython3 -c \"import json; m=json.loads(open('pkg/crx-eff/manifest.json').read()); m['author']={'email': 'eff.software.projects@gmail.com'}; del m['applications']; open('pkg/crx-eff/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\n# Remove the 'update_url' manifest key from the xpi version of the extension delivered to AMO\npython3 -c \"import json; m=json.loads(open('pkg/xpi-amo/manifest.json').read()); del m['applications']['gecko']['update_url']; m['applications']['gecko']['id'] = 'https-everywhere@eff.org'; open('pkg/xpi-amo/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\n\n# Remove the incognito key in AMO packages: #16394\npython3 -c \"import json; m=json.loads(open('pkg/xpi-amo/manifest.json').read()); del m['incognito']; open('pkg/xpi-amo/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\npython3 -c \"import json; m=json.loads(open('pkg/xpi-eff/manifest.json').read()); del m['incognito']; open('pkg/xpi-eff/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\n\n# If the --remove-extension-update flag is set, ensure the extension is unable to update\nif $REMOVE_EXTENSION_UPDATE; then\n  echo \"Flag --remove-extension-update specified.  Removing the XPI extensions' ability to update.\"\n  python3 -c \"import json; m=json.loads(open('pkg/xpi-amo/manifest.json').read()); m['applications']['gecko']['update_url'] = 'https://127.0.0.1'; open('pkg/xpi-amo/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\n  python3 -c \"import json; m=json.loads(open('pkg/xpi-eff/manifest.json').read()); m['applications']['gecko']['update_url'] = 'https://127.0.0.1'; open('pkg/xpi-eff/manifest.json','w').write(json.dumps(m,indent=4,sort_keys=True))\"\nfi\n\n# If the --remove-update-channels flag is set, remove all out-of-band update channels\nif $REMOVE_UPDATE_CHANNELS; then\n  echo \"Flag --remove-update-channels specified.  Removing all out-of-band update channels.\"\n  echo \"require.scopes.update_channels.update_channels = [];\" >> pkg/crx-cws/background-scripts/update_channels.js\n  echo \"require.scopes.update_channels.update_channels = [];\" >> pkg/crx-eff/background-scripts/update_channels.js\n  echo \"require.scopes.update_channels.update_channels = [];\" >> pkg/xpi-amo/background-scripts/update_channels.js\n  echo \"require.scopes.update_channels.update_channels = [];\" >> pkg/xpi-eff/background-scripts/update_channels.js\nfi\n\nif [ -n \"$BRANCH\" ] ; then\n  crx_cws=\"pkg/https-everywhere-$VERSION-cws.crx\"\n  crx_eff=\"pkg/https-everywhere-$VERSION-eff.crx\"\n  xpi_amo=\"pkg/https-everywhere-$VERSION-amo.xpi\"\n  xpi_eff=\"pkg/https-everywhere-$VERSION-eff.xpi\"\n\nelse\n  crx_cws=\"pkg/https-everywhere-$VERSION~pre-cws.crx\"\n  crx_eff=\"pkg/https-everywhere-$VERSION~pre-eff.crx\"\n  xpi_amo=\"pkg/https-everywhere-$VERSION~pre-amo.xpi\"\n  xpi_eff=\"pkg/https-everywhere-$VERSION~pre-eff.xpi\"\nfi\nif ! [ -f \"$KEY\" ] ; then\n  echo \"Making a dummy signing key for local build purposes\"\n  openssl genrsa -out /tmp/dummy-chromium.pem 768\n  openssl pkcs8 -topk8 -nocrypt -in /tmp/dummy-chromium.pem -out $KEY\nfi\n\n\n# now pack the crx'es\nBROWSER=\"chromium-browser\"\nwhich $BROWSER || BROWSER=\"chromium\"\n\n$BROWSER --no-message-box --pack-extension=\"pkg/crx-cws\" --pack-extension-key=\"$KEY\" 2> /dev/null\n$BROWSER --no-message-box --pack-extension=\"pkg/crx-eff\" --pack-extension-key=\"$KEY\" 2> /dev/null\n\nmv pkg/crx-cws.crx $crx_cws\nmv pkg/crx-eff.crx $crx_eff\n\necho >&2 \"CWS crx package has sha256sum: `openssl dgst -sha256 -binary \"$crx_cws\" | xxd -p`\"\necho >&2 \"EFF crx package has sha256sum: `openssl dgst -sha256 -binary \"$crx_eff\" | xxd -p`\"\n\n# now zip up the xpi AMO dir\nname=pkg/xpi-amo\ndir=pkg/xpi-amo\nzip=\"$name.zip\"\n\ncwd=$(pwd -P)\n(cd \"$dir\" && ../../utils/create_zip.py -n \"$cwd/$zip\" -x \"../../.build_exclusions\" .)\necho >&2 \"AMO xpi package has sha256sum: `openssl dgst -sha256 -binary \"$cwd/$zip\" | xxd -p`\"\n\ncp $zip $xpi_amo\n\n# now zip up the xpi EFF dir\nname=pkg/xpi-eff\ndir=pkg/xpi-eff\nzip=\"$name.zip\"\n\ncwd=$(pwd -P)\n(cd \"$dir\" && ../../utils/create_zip.py -n \"$cwd/$zip\" -x \"../../.build_exclusions\" .)\necho >&2 \"EFF xpi package has sha256sum: `openssl dgst -sha256 -binary \"$cwd/$zip\" | xxd -p`\"\n\ncp $zip $xpi_eff\n\nbash utils/android-push.sh \"$xpi_eff\"\n\necho >&2 \"Total included rules: `find src/chrome/content/rules -name \"*.xml\" | wc -l`\"\necho >&2 \"Rules disabled by default: `find src/chrome/content/rules -name \"*.xml\" | xargs grep -F default_off | wc -l`\"\n\n# send the following to stdout so scripts can parse it\n# see test/selenium/shim.py\necho \"Created $xpi_amo\"\necho \"Created $xpi_eff\"\necho \"Created $crx_cws\"\necho \"Created $crx_eff\"\n\nif [ -n \"$BRANCH\" ]; then\n  cd ..\n  cp $SUBDIR/$crx_cws pkg\n  cp $SUBDIR/$crx_eff pkg\n  cp $SUBDIR/$xpi_amo pkg\n  cp $SUBDIR/$xpi_eff pkg\n  rm -rf $SUBDIR\nfi\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.01171875,
          "content": "lxml>=3.3.3\n"
        },
        {
          "name": "rules",
          "type": "blob",
          "size": 0.0234375,
          "content": "src/chrome/content/rules"
        },
        {
          "name": "ruleset-testing.md",
          "type": "blob",
          "size": 2.572265625,
          "content": "# Ruleset coverage requirements\n\nWe have an automated tester that checks URLs for all rulesets to ensure they\nstill work. In order for that tester to work we need input URLs. We have\nadditional testing in place to ensure that all rulesets have a sufficient number\nof test URLs to test them thoroughly.\n\nGoal: 100% coverage of all targets and all branches of all regexes in each\nruleset.\n\nEach ruleset has a number of \"implicit\" test URLs based on the target hosts. For\neach target host e.g. `example.com`, there is an implicit test URL of\n`http://example.com/`. Exception: target hosts that contain a wildcard (\"`*`\")\ndo not create an implicit test URL.\n\nAdditional test URLs can be added with the new `<test>` tag in the XML, e.g.\n`<test url=\"http://example.com/complex-page\" />`.\n\nTest URLs will be matched against the regexes in each `<rule>` and\n`<exclusion>`. A test URL can only match against one `<rule>` and one\n`<exclusion>`. Once all the test URLs have been matched up, we count the number\nof test URLs matching each `<rule>` and each `<exclusion>`, and make sure the\ncount meets the minimum number.  The minimum number of test URLs for each\n`<rule>` or `<exclusion>` is one plus the number of '`*`', '`+`', '`?`', or\n'`|`' characters in the regex. Since each of these characters increases the\ncomplexity of the regex (usually increasing the variety of URLs it can match),\nwe require correspondingly more test URLs to ensure good coverage.\n\n# Example:\n```xml\n<ruleset name=\"example.com\">\n\t<target host=\"example.com\" />\n\t<target host=\"*.example.com\" />\n\n\t<test url=\"http://www.example.com/\" />\n\t<test url=\"http://beta.example.com/\" />\n\n\t<rule from=\"^http://([\\w-]+\\.)?example\\.com/\"\n\t\tto=\"https://$1example.com/\" />\n</ruleset>\n```\nThis ruleset has one implicit test URL from a target host\n(\"`http://example.com/`\"). The other target host has a wildcard, so creates no\nimplicit test URL. There's a single rule. That rule contains a '`+`' and a\n'`?`', so it requires a total of three matching test URLs. We add the necessary\ntest URLs using explicit `<test>` tags.\n\n# Testing and Continuous Build\n\nTesting for ruleset coverage is now part of the Travis CI continuous build.\nCurrently we only test rulesets that have been modified since February 2 2015.\nSubmitting changes to any ruleset that does not meet the coverage requirements\nwill break the build. This means that even fixes of existing rules may require\nadditional work to bring them up to snuff.\n\nTo run the tests locally, first install the development dependencies:\n\n    ./install-dev-dependencies.sh\n\nTo test a specific ruleset:\n\n    test/manual.sh rules/Example.xml\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.sh",
          "type": "blob",
          "size": 0.501953125,
          "content": "#!/bin/bash -ex\n# Run tests for HTTPS Everywhere\n\n# Get into the project-root. This script may be executed as `test.sh`\n# or as .git/hooks/pre-push, so we need to find the directory containing\n# test.sh before we can proceed.\n\nif [ -n \"$GIT_DIR\" ]\nthen\n    # $GIT_DIR is set, so we're running as a hook.\n    cd $GIT_DIR\nelse\n    # Git command exists? Cool, let's CD to the right place.\n    git rev-parse && cd \"$(git rev-parse --show-toplevel)\"\nfi\n\n./test/validations.sh\n./test/firefox.sh $@\n./test/chromium.sh $@\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "translations",
          "type": "commit",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}