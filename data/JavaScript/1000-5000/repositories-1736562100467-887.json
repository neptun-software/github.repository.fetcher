{
  "metadata": {
    "timestamp": 1736562100467,
    "page": 887,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "plasma-umass/browsix",
      "stars": 3172,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.263671875,
          "content": "/node_modules\n/bower_components\n/lib\n/dist\n*~\n/test/*.js\n/core.*\n/fs\n/fs_*\n/lib-dist\n/.tmp\n/bench/*.js\n/app/elements/**/*.js\n*.aux\n*.bbl\n*.log\n*.blg\n*.dvi\n/report.out\n/results\n/benchfs\n/examples/meme-service/frontend/fs/meme-service.js\n/examples/latex-editor/fs/usr/bin\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.498046875,
          "content": "[submodule \"vendor/BrowserFS\"]\n\tpath = vendor/BrowserFS\n\turl = https://github.com/jvilk/BrowserFS\n[submodule \"src/vendor/BrowserFS\"]\n\tpath = src/vendor/BrowserFS\n\turl = https://github.com/jvilk/BrowserFS\n[submodule \"src/kernel/vendor/BrowserFS\"]\n\tpath = src/kernel/vendor/BrowserFS\n\turl = https://github.com/bpowers/BrowserFS\n[submodule \"test/hbench-os\"]\n\tpath = bench/hbench-os\n\turl = https://github.com/bpowers/HBench-OS\n[submodule \"src/init\"]\n\tpath = src/init\n\turl = http://github.com/plasma-umass/systemgo\n"
        },
        {
          "name": ".npmignore",
          "type": "blob",
          "size": 0.2490234375,
          "content": "/node_modules\n/bower_components\n/dist\n*~\n/test/*.js\n/core.*\n/fs\n/fs_*\n/.tmp\n/bench/*.js\n/app/elements/**/*.js\n*.aux\n*.bbl\n*.log\n*.blg\n*.dvi\n/report.out\n/results\n/benchfs\n/examples/meme-service/frontend/fs/meme-service.js\n/examples/latex-editor/fs/usr/bin\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.146484375,
          "content": "University of Massachusetts Amherst\nBobby Powers <bobbypowers@gmail.com>\nCraig Greenberg <csgreenberg@cs.umass.edu>\nEmery Berger <emery@cs.umass.edu>\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.1416015625,
          "content": "Copyright (c) 2016 The Browsix Authors, see AUTHORS file.\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nSee the other LICENSE.* files for additional licenses this project\nfalls under.\n"
        },
        {
          "name": "LICENSE.acorn",
          "type": "blob",
          "size": 1.103515625,
          "content": "Copyright (C) 2012-2016 by various contributors (see https://github.com/ternjs/acorn/blob/master/AUTHORS)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "LICENSE.browserfs",
          "type": "blob",
          "size": 6.0595703125,
          "content": "BrowserFS's license follows:\n\n====\n\nCopyright (c) 2013, 2014, 2015 John Vilk and other BrowserFS contributors.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n====\n\nThis license applies to all parts of BrowserFS, except for the following items:\n\n- The unit tests from Node, located in `test/tests/**/node-*.js`, and their\n  test fixtures, located in `test/fixtures/files/node`. Their license follows:\n  \"\"\"\n    Copyright Joyent, Inc. and other Node contributors. All rights reserved.\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to\n    deal in the Software without restriction, including without limitation the\n    rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n    sell copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in\n    all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n    IN THE SOFTWARE.\n  \"\"\"\n\n- The Emscripten file system in src/generic/emscripten_fs.ts is a modified\n  version of Emscripten's NODEFS. Emscripten's license follows:\n  \"\"\"\n    Emscripten is available under 2 licenses, the MIT license and the\n    University of Illinois/NCSA Open Source License.\n\n    Both are permissive open source licenses, with little if any\n    practical difference between them.\n\n    The reason for offering both is that (1) the MIT license is\n    well-known, while (2) the University of Illinois/NCSA Open Source\n    License allows Emscripten's code to be integrated upstream into\n    LLVM, which uses that license, should the opportunity arise.\n\n    The full text of both licenses follows.\n\n    ==============================================================================\n\n    Copyright (c) 2010-2011 Emscripten authors, see AUTHORS file.\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in\n    all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n    THE SOFTWARE.\n\n    ==============================================================================\n\n    Copyright (c) 2010-2011 Emscripten authors, see AUTHORS file.\n    All rights reserved.\n\n    Permission is hereby granted, free of charge, to any person obtaining a\n    copy of this software and associated documentation files (the\n    \"Software\"), to deal with the Software without restriction, including\n    without limitation the rights to use, copy, modify, merge, publish,\n    distribute, sublicense, and/or sell copies of the Software, and to\n    permit persons to whom the Software is furnished to do so, subject to\n    the following conditions:\n\n        Redistributions of source code must retain the above copyright\n        notice, this list of conditions and the following disclaimers.\n\n        Redistributions in binary form must reproduce the above\n        copyright notice, this list of conditions and the following disclaimers\n        in the documentation and/or other materials provided with the\n        distribution.\n\n        Neither the names of Mozilla,\n        nor the names of its contributors may be used to endorse\n        or promote products derived from this Software without specific prior\n        written permission.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n    OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n    IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR\n    ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n    TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\n    SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n  \"\"\"\n"
        },
        {
          "name": "LICENSE.browserify",
          "type": "blob",
          "size": 2.7822265625,
          "content": "Browserify is licenced under the MIT license.\n\nSome pieces from builtins/ taken from node core under this license:\n\n----\n\nCopyright Joyent, Inc. and other Node contributors.\n\nPermission is hereby granted, free of charge, to any person obtaining a\ncopy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to permit\npersons to whom the Software is furnished to do so, subject to the\nfollowing conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\nOR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\nNO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\nDAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\nUSE OR OTHER DEALINGS IN THE SOFTWARE.\n\n----\n\nbuffer_ieee754.js has this license in it:\n\n----\n\nCopyright (c) 2008-2015, Fair Oaks Labs, Inc.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice,\n   this list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name of Fair Oaks Labs, Inc. nor the names of its contributors\n   may be used to endorse or promote products derived from this software\n   without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\nLIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\nCONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n\nModifications to writeIEEE754 to support negative zeroes made by Brian White\n\n----\n"
        },
        {
          "name": "LICENSE.node",
          "type": "blob",
          "size": 2.2822265625,
          "content": "Node.js is licensed for use as follows:\n\n\"\"\"\nCopyright Node.js contributors. All rights reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n\"\"\"\n\nThis license applies to parts of Node.js originating from the\nhttps://github.com/joyent/node repository:\n\n\"\"\"\nCopyright Joyent, Inc. and other Node contributors. All rights reserved.\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n\"\"\"\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.13671875,
          "content": "\nBOWER     ?= node_modules/.bin/bower\nGULP      ?= node_modules/.bin/gulp\nTSLINT    ?= node_modules/.bin/tslint\nMOCHA     ?= node_modules/.bin/mocha\n\nTEX        = pdflatex\n\nNPM_DEPS   = $(GULP) $(TSLINT) $(MOCHA)\nBUILD_DEPS = $(NPM_DEPS) bower_components\n\nSYSTEMGO   = github.com/rvolosatovs/systemgo\nINIT\t   = fs/usr/bin/init\nSYSTEMCTL  = fs/usr/bin/systemctl\n\n# quiet output, but allow us to look at what commands are being\n# executed by passing 'V=1' to make, without requiring temporarily\n# editing the Makefile.\nifneq ($V, 1)\nMAKEFLAGS += -s\nendif\n\n# GNU make, you are the worst.\n.SUFFIXES:\n%: %,v\n%: RCS/%,v\n%: RCS/%\n%: s.%\n%: SCCS/s.%\n.SUFFIXES: .tex .pdf\n\nall: test-once\n\ndist: $(BUILD_DEPS)\n\t@echo \"  DIST\"\n\t$(GULP) 'build:dist'\n\n.tex.pdf: report.bib\n\t@echo \"  LATEX $@\"\n\t$(TEX) $<\n\tbibtex $(shell echo $< | cut -d '.' -f 1).aux\n\t$(TEX) $<\n\t$(TEX) $<\n\n\nreport: report.pdf\n\ntest-once: $(BUILD_DEPS)\n\t@echo \"  TEST\"\n\t$(GULP)\n\nshell: serve\n\nserve: $(BUILD_DEPS)\n\t@echo \"  SERVE\"\n\t$(GULP) serve\n\nbrowsix-spec: $(BUILD_DEPS)\n\t@echo \"  Browsix SPEC\"\n\t$(GULP) browsix-spec\n\nnode_modules: bower_components package.json\n\t@echo \"  NPM\"\n\tnpm install\n\ttouch -c $@\n\n$(BOWER):\n\t@echo \"  NPM bower\"\n\tnpm install bower\n\ttouch -c $@\n\n$(NPM_DEPS): node_modules\n\ttouch -c $@\n\nbower_components: $(BOWER) bower.json\n\t@echo \"  BOWER\"\n\t$(BOWER) install --silent\n\ttouch -c $@\n\nsyscall-api: $(BUILD_DEPS)\n\t@echo \"  SYSCALL\"\n\tnode_modules/.bin/gulp dist-syscall-api\n\nbin: $(BUILD_DEPS)\n\t@echo \"  BIN\"\n\tnode_modules/.bin/gulp index-fs\n\nsystemgo: init systemctl\n\ninit: $(BUILD_DEPS)\n\t@echo \"  INIT\"\n\tbrowsix-gopherjs build $(SYSTEMGO)/cmd/init -o $(INIT)\n\trm $(INIT).map\n\tchmod +x $(INIT)\n\nsystemctl: $(BUILD_DEPS)\n\t@echo \"  SYSTEMCTL\"\n\tbrowsix-gopherjs build $(SYSTEMGO)/cmd/systemctl -o $(SYSTEMCTL)\n\trm $(SYSTEMCTL).map\n\tchmod +x $(SYSTEMCTL)\n\ntest-browser: $(BUILD_DEPS)\n\t@echo \"  TEST BROWSER\"\n\t$(GULP) test-browser\n\ntest: test-browser\n\nclean:\n\trm -rf dist lib lib-dist fs report.{pdf,aux,bbl,blg,log} test/*.js\n\tfind . -name '*~' | xargs rm -f\n\ndistclean: clean\n\trm -rf node_modules bower_components\n\n.PHONY: all clean distclean test test-browser test-node report test-once shell serve init systemctl\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.1953125,
          "content": "Browsix - Bringing Unix to the Browser\n======================================\n\n[![NPM version](https://badge.fury.io/js/browsix.svg)](http://badge.fury.io/js/browsix)\n[![david-dm-status-badge](https://david-dm.org/plasma-umass/browsix.svg)](https://david-dm.org/jvilk/browserfs#info=dependencies&view=table)\n[![david-dm-status-badge](https://david-dm.org/plasma-umass/browsix/dev-status.svg)](https://david-dm.org/plasma-umass/browsix#info=devDependencies&view=table)\n\nWhile standard operating systems like Unix make it relatively simple\nto build complex applications, web browsers lack the features that\nmake this possible.  This project is Browsix, a JavaScript-only\nframework that brings the essence of Unix to the browser. Browsix\nmakes core Unix features available to web applications (including\npipes, processes, signals, sockets, and a shared file system) and\nextends JavaScript runtimes for C, C++, Go, and Node.js programs so\nthey can run in a Unix-like environment within the browser. Browsix\nalso provides a POSIX-like shell that makes it easy to compose\napplications together for parallel data processing via pipes.\n\n*For more details, check out our [tech\nreport (PDF)](https://web.cs.umass.edu/publication/details.php?id=2414)*.\n\n\nAnother way to think about this is that modern web applications are\nmulti-process by nature - the client and some of the application logic\nlives in the browser, and some of it lives in the cloud, often\nimplemented as\n[microservices](https://en.wikipedia.org/wiki/Microservices).\n\nBrowsix lets you rethink the boundary between code executing in the\nbrowser vs. server-side, while taking advantage of the multi-core\nnature of modern computing devices.\n\nBrowsix enables you to compose the in-browser part of your web\napplications out of processes.  Processes behave as you would expect\ncoming from [Unix](https://en.wikipedia.org/wiki/Unix): they run in\nparallel with the main browser thread, can communicate over pipes,\nsockets, or the filesystem, and can create subprocesses.  This process\nmodel is implemented on top of existing browser APIs, like [web\nworkers](https://en.wikipedia.org/wiki/Web_worker), so it works in all\nmodern browsers.  Browsix applications can be served statically or\nover a [CDN](https://en.wikipedia.org/wiki/Content_delivery_network).\n\n### The Browsix Shell\n\nAs a proof of concept, we've implemented a POSIX-like shell on top of\nBrowsix, along with an implementation of a number of standard Unix\nutilities (`cat`, `tee`, `echo`, `sha1sum`, and friends).  The\nutilities are all standard node programs that will run directly under\nnode, or in the browser under Browsix.  Individual commands are\nexecuted in their own workers, and piping works as expected:\n\n![shell](doc/img/shell.png)\n\nTry it out here: [live demo!](https://unix.bpowers.net/)\n\n### Meme creator\n\nBrowsix is useful for more than web terminals.  With Browsix, you can\nrun Go microservices directly in the browser!  As an example, we have\nimplemented a meme creator, that lets you create memes (sometimes\nknown as image macros) with (hopefully) humorous text on top of\nseveral images.  We wrote this as a standard REST service in Go,\naccepting the text and image type as parameters, and returning a PNG.\nWe used [our modified\nGopherJS](https://github.com/bpowers/browsix-gopherjs) compiler to\ncompile the Go service (including all dependencies, such as the\nTrueType font renderer and image manipulation libraries) to\nJavaScript, and Browsix to run this JavaScript as a process in a\nbackground Web Worker.  We then dynamically route requests to either\nthis in-browser server or a remote server depending on user agent and\nnetwork connectivity.\n\n<div style=\"text-align:center\"><img src=\"doc/meme_screenshot.png\" width=\"423\"></div>\n\n### Details\n\nBrowsix currently supports running node.js, Go, and C/C++ programs.\nIt supports Go with a [modified GopherJS\ncompiler](https://github.com/bpowers/browsix-gopherjs) (requires a\nhost [Go 1.6 install for\nnow](https://github.com/bpowers/browsix-gopherjs/issues/2)), and C/C++\nwith [modifications to\nEmscripten](https://github.com/bpowers/emscripten/tree/_browsix).\n\n### Browsix-SPEC\n\nBrowsix supports executing SPEC CPU2006 and SPEC CPU2017 benchmarks using Browsix-SPEC\ninterface. \n\nUsing Browsix\n-------------\n\nThere are two parts to Browsix: build tooling (the modified Go + C\ncompilers) and runtime support (the kernel + Browsix APIs).\n\nGet browsix through npm:\n\n```\n    $ npm install --save browsix\n```\n\n\nBuilding & Testing\n------------------\n\nBrowsix requires **nodejs 4.3.0** or later, which is more recent than\nthe version packaged in Ubuntu Wiley.  To get a recent version of\nnode, follow the instructions on the [node.js\nwebsite](https://nodejs.org/en/download/package-manager/#debian-and-ubuntu-based-linux-distributions).\nIf you don't know whether you should choose node 4.x or 5.x, choose\n4.x (it is the long-term support branch).\n\nBrowsix has three other dependencies: `git`, `npm` (usually installed\nalong with node), and `make`, and builds on OSX and Linux systems.\nOnce you have those dependencies:\n\n```\n    $ git clone --recursive https://github.com/plasma-umass/browsix\n    $ cd browsix\n    $ make test-once serve\n```\n\nThis will pull the dependencies, build the runtime and all the\nutilities, run a number of tests in either Firefox or Chrome, and then\nlaunch a copy of the shell served locally.\n\n`Dockerfile`\n-----------\n\n```sh\n$ ./docker/build.sh\n....\nroot@3695ed0cdf45:~/browsix# make test-once serve\n  TEST\n[13:07:00] Using gulpfile ~/browsix/gulpfile.js\n[13:07:00] Starting 'copy-node-kernel'...\n[13:07:00] Starting 'copy-node'...\n[13:07:00] Starting 'lint-kernel'...\n[13:07:00] Starting 'lint-browser-node'...\n[13:07:00] Starting 'lint-bin'...\n[13:07:00] Starting 'lint-syscall-api'...\n[13:07:00] Finished 'copy-node-kernel' after 82 ms\n[13:07:02] Finished 'lint-syscall-api' after 1.61 s\n[13:07:04] Finished 'lint-kernel' after 3.72 s\n[13:07:05] Finished 'lint-browser-node' after 4.46 s\n[13:07:05] Finished 'lint-bin' after 5.08 s\n[13:07:05] Starting 'build-bin'...\n[13:07:06] Finished 'copy-node' after 5.16 s\n[13:07:06] Starting 'build-kernel'...\n[13:07:06] Starting 'build-browser-node'...\n...\n```\n\nBuilding and using Browsix-SPEC\n-------------------------------\nAfter building Browsix, build Browsix-SPEC through make:\n```\nmake browsix-spec\n```\nFollow the instructions in browsix-spec.md.\n\nIn-browser node limitations\n---------------------------\n\nBrowsix's `browser-node` implementation has an important to understand\nlimitation: **you must explicitly call `process.exit()`**.  Without\nthis, utilities will work under real-node, but appear to hang under\n`browser-node`.  This is not an intrinsic limitation, but it is a\nhairy implementation detail -- node exits when the event loop is\nempty, and there are no active timers or network callbacks.  For us to\ndo the same thing means we need to hook `setTimeout` and any other\nfunctions that take callbacks to ensure we don't exit early.\n\n\nDocumentation\n-------------\n\nFor a high-level overview of the system design and architecture,\nplease see [this document](doc/report.pdf).\n\n\nContributing\n------------\n\nYou're interested in contributing?  That's great!\n\nThe process is similar to other open-source projects hosted on github:\n\n* Fork the repository\n* Make some changes\n* Commit your changes with a descriptive commit message\n* Open a pull request\n\n\nContact\n-------\n\nIf you have questions or problems, please [open an\nissue](https://github.com/plasma-umass/browsix/issues) on this\nrepository (plasma-umass/browsix).\n\n\nOpen Source\n-----------\n\nThis project is licensed under the MIT license, but also incorporates\ncode from other sources.\n\nBrowsix uses [BrowserFS](https://github.com/jvilk/BrowserFS) for its\nfilesystem, which is [primarily MIT licensed](LICENSE.browserfs).\n\nbrowser-node's [`nextTick`](src/browser-node/browser-node.ts#L114)\nimplementation comes from the\n[acorn](https://github.com/ternjs/acorn) project, released under [the\nMIT license](LICENSE.acorn).\n\nA large portion of browser-node is the\n[node](https://github.com/nodejs/node) standard library, which is [MIT\nlicensed](LICENSE.node).\n\nFunctions to convert buffers to utf-8 strings and back are derivative\nof\n[browserify](https://github.com/substack/node-browserify/blob/master/LICENSE)\nimplementations (ported to TypeScript), [MIT\nlicensed](LICENSE.browserify) as well.\n"
        },
        {
          "name": "analyze.sh",
          "type": "blob",
          "size": 0.896484375,
          "content": "#!/bin/bash\nset -e\n\nif [ $# != 1 ]; then\n    echo \"usage: $0 DIR\"\n    exit 1\nfi\n\nDIR=\"$1\"\n\nRESULTS=\"$DIR/results.tsv\"\n\nHOSTID=\"$(uname -s | tr '[:upper:]' '[:lower:]')-$(uname -m)\"\nHOSTDIR=\"$DIR/$HOSTID/$(hostname)\"\n\necho \"system\ttest\tcommand\tkind\tdata\" >\"$RESULTS\"\ncat \"$DIR/raw\" | grep 'LOG:' | cut -d \"'\" -f 2 | grep -v conf >>\"$RESULTS\"\n\nfor f in $HOSTDIR/lat_*; do\n    TEST=\"$(basename $f)\"\n    cat \"$f\" | while read l; do\n        echo -e \"$HOSTID\\t$TEST\\t_\\trun\\t$l\" >>\"$RESULTS\"\n    done\ndone\n\n\n\n# BROWSERS=\"$(cat \"$RESULTS\" | cut -f 1 | sort -u)\"\n\n# for b in $BROWSERS; do\n#     TESTS=$(cat \"$RESULTS\" | grep \"$b\" | cut -f 2 | sort -u)\n\n#     for t in $TESTS; do\n#         TDIR=\"$DIR/$b/$t\"\n#         mkdir -p \"$TDIR\"\n#         cat \"$RESULTS\" | grep \"$b\" | grep \"$t\" | grep conf | cut -f 5 >\"$TDIR/conf\"\n#         cat \"$RESULTS\" | grep \"$b\" | grep \"$t\" | grep run | cut -f 5 >\"$TDIR/results\"\n#     done\n# done\n"
        },
        {
          "name": "app-spec",
          "type": "tree",
          "content": null
        },
        {
          "name": "app",
          "type": "tree",
          "content": null
        },
        {
          "name": "bench",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark.sh",
          "type": "blob",
          "size": 1.15625,
          "content": "#!/bin/bash\nset -e\n\nFSROOT=\"./benchfs\"\nBIN=\"$FSROOT/usr/bin\"\nHBENCH=\"./bench/hbench-os\"\nSHROOT=\"./fs\"\nRESULTDIRB=\"results/browsix\"\n\nexport FIREFOX_BIN='/opt/firefox-nightly/firefox'\n#export FIREFOX_BIN='/home/bpowers/src/mozilla-central/obj-x86_64-pc-linux-gnu/dist/bin/firefox'\nexport CHROME_BIN='chrome_sab'\n\n#export EMCC_BROWSIX_ASYNC=1\nexport EMFLAGS='-s TOTAL_MEMORY=16000 -Os'\n\nrm -rf \"$HBENCH/bin/browsix-js\"\n\n(cd $HBENCH && emmake make PLATFORM=js-pc-browsix EXT=.js CC=\"emcc $EMFLAGS\" CFLAGS=\"-static -DNO_PORTMAPPER\")\n\n# benchmarks to run\nBENCHMARKS='lat_syscall lat_pipe lat_tcp lat_proc hello lat_fs lat_fslayer mhz'\n\nmkdir -p \"$FSROOT/tmp\"\nmkdir -p \"$BIN\"\n\nfor b in $BENCHMARKS; do\n\tcp -a \"$HBENCH/bin/browsix-js/$b.js\" \"$BIN/$b\"\ndone\n\nexit\nmake bin\n\n# copy in a few extra programs, mainly the shell\ncp \"$SHROOT/usr/bin/sh\" \"$BIN\"\n\nmkdir -p results\n\nRESULTDIR=\"$RESULTDIRB.1\"\nwhile [ -d $RESULTDIR ]; do\n    EXT=`expr $EXT + 1`\n    RESULTDIR=$RESULTDIRB.$EXT\ndone\n\nmkdir -p \"$RESULTDIR\"\n\nnode_modules/.bin/gulp bench >\"$RESULTDIR/raw\"\n\n(cd \"$HBENCH\" && rm -rf Results/linux* && make && make run)\n\nmv \"$HBENCH/Results/linux-x86_64\" \"$RESULTDIR\"\n\n./analyze.sh \"$RESULTDIR\"\n"
        },
        {
          "name": "bower.json",
          "type": "blob",
          "size": 0.525390625,
          "content": "{\n  \"name\": \"browsix\",\n  \"dependencies\": {\n    \"iron-elements\": \"PolymerElements/iron-elements#^1.0.9\",\n    \"neon-elements\": \"PolymerElements/neon-elements#^1.0.0\",\n    \"page\": \"visionmedia/page.js#~1.6.4\",\n    \"paper-elements\": \"PolymerElements/paper-elements#^1.0.7\",\n    \"platinum-elements\": \"PolymerElements/platinum-elements#^2.0.0\",\n    \"polymer\": \"Polymer/polymer#^1.4.0\",\n    \"polymer-ts\": \"~0.1.26\"\n  },\n  \"devDependencies\": {\n    \"web-component-tester\": \"*\",\n    \"test-fixture\": \"PolymerElements/test-fixture#^3.0.0-rc.1\"\n  }\n}\n"
        },
        {
          "name": "browsix-spec.md",
          "type": "blob",
          "size": 6.6298828125,
          "content": "We need Browsix-WASM's `emscripten` and Browsix-SPEC to execute SPEC CPU 2006 and 2017 Benchmarks. Browsix-WASM `emscripten` is available in `browsix-wasm` branch of [Browsix-Emscripten](https://github.com/plasma-umass/browsix-emscripten).\n\nIn below steps we will compile `bzip2` benchmark to WebAssembly and execute it with `ref` size of data set. To compile and execute other benchmarks with `ref` or `test` size of dataset, repeat the below procedure.\n\n## Using Emscripten\nTo use Emscripten 1.37.22, we need binaryen tools and `fastcomp` 1.37.22. The process to build `fastcomp` 1.37.22 is similar to the instructions mentioned on [here](https://emscripten.org/docs/building_from_source/building_fastcomp_manually_from_source.html).\n\n1. Follow instructions on [here](https://webassembly.org/getting-started/developers-guide/) to install the latest `emsdk`. \n2. Clone `fastcomp` and clang and change the directory to `fastcomp-1.37.22`.\n```\ngit clone https://github.com/emscripten-core/emscripten-fastcomp\ncd emsripten-fastcomp\ngit clone https://github.com/emscripten-core/emscripten-fastcomp-clang tools/clang\ncd ..\nmv emscripten-fastcomp fastcomp-1.37.22\n```\n3. Checkout version 1.37.22.\n```\ncd fastcomp-1.37.22\ngit checkout 1.37.22\ncd tools/clang\ngit checkout 1.37.22\ncd ../..\n``` \n5. Create a `build` directory and cd into it.\n```\nmkdir build\ncd build\n```\n6. Configure and make\n```\ncmake .. -DCMAKE_BUILD_TYPE=Release -DLLVM_TARGETS_TO_BUILD=\"host;JSBackend\" -DLLVM_INCLUDE_EXAMPLES=OFF -DLLVM_INCLUDE_TESTS=OFF -DCLANG_INCLUDE_TESTS=OFF\nmake -j4\n```\n7. Open `~/.emscripten` file and set `LLVM_ROOT` to the absolute path of `fastcomp-1.37.22/build/bin` directory.\n8. Clone `emscripten` from https://github.com/plasma-umass/browsix-emscripten.git to `emscripten` or extract `emscripten.tar.xz` to `emscripten`.\n9. `cd emscripten` and execute `./emcc -v` to run sanity checks. If there any errors (which are usually in red color), then double check the process.\n\nNow we can use emscripten's C compiler `emcc` and C++ compiler `em++` to compile C and C++ to WebAssembly or asm.js using Browsix-WASM. \n\n## Compiling SPEC CPU2006 Benchmarks\n\n1. Install SPEC CPU2006 Benchmarks. All instructions __require__ that SPEC CPU2006 suite has been installed in `/spec-cpu2006/`.\n2. Set the values of `CC` and `CXX` variables in `browsix-asmjs.cfg` and `browsix-wasm.cfg` to absolute paths of `emcc` and `em++`. \n3. Copy `browsix-asmjs.cfg` and `browsix-wasm.cfg` to `/spec-cpu2006/config`.\n4. Compile `401.bzip2` benchmark to WebAssembly with `ref` dataset\n```\ncd /spec\n. ./shrc\nrunspec --size=ref --tune=base --config=browsix-wasm.cfg --noreportable --iterations=1 401.bzip2\n```\n5. We can ignore the errors spec scripts throws when it executes the benchmarks compiled binaries. However, there should be __no__ compilation error.\n6. Similarly, to compile to asm.js execute above command but with `--config=browsix-asmjs.cfg`.\n7. A `build` directory will be created in `/spec-cpu2006/benchspec/CPU2006/401.bzip2/build/build_base_browsix-wasm.xxxx/` and similarly for asm.js. In both cases, `bzip2.js` contains compiled asm.js and WebAssembly code for 401.bzip2.\n8. A `run` directory will be created in `/spec-cpu2006/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-wasm.0000`, that contains input files and `speccmds.cmd` describing the commands for `specinvoke` to execute.\n\n## Browsix-SPEC with Browsix-WASM Kernel installation\n1. Install NodeJS 8.5 (or later). The latest 8.x release can be found [here](https://nodejs.org/dist/latest-v8.x/). Notice that `emsdk` provides `nodejs 8.12.0` by default.\n2. Install Linux Kernel's `perf` utility on Ubuntu using\n```\nsudo apt-get install linux-tools-generic linux-tools-`uname -r`\n```\nOr on Fedora/RedHat using\n```\nsudo dnf install perf\n```\n2. Clone this repo to `browsix-spec2006` directory.\n\n3. Build Browsix by\n```\nmake serve\n```\n4. Build Browsix-SPEC by\n```\nmake browsix-spec\n```\n\n## Adding Benchmarks to Browsix-SPEC\nNow we copy compiled binaries of SPEC benchmarks and `run` directory to the corresponding Browsix-SPEC directory in `browsix-spec2006`.\n1. Following commands to copy all run files (assuming your current directory is `browsix-spec2006`). Unfortunately, currently both WebAssembly and asm.js files has to reside in `run_base_<data_size>_browsix-asmjs.0000` directory.\n```\nmkdir -p fs/spec/cpu2006_asmjs/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-asmjs.0000\ncp /spec-cpu2006/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-wasm.0000/* fs/spec/cpu2006_asmjs/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-asmjs.0000/\n```\nTo copy files for asm.js, replace `run_base_ref_browsix-wasm.0000` with `run_base_ref_browsix-asmjs.0000`.\n3. Change file paths to correct file paths in Browsix-SPEC's filesystem in `speccmds.cmd`.\n```\ncd fs/spec/cpu2006_asmjs/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-asmjs.0000/\nsed 's/\\/spec-cpu2006\\/benchspec/\\/spec\\/cpu2006_asmjs\\/benchspec/g' speccmds.cmd > speccmds.cmd-2\nsed 's/\\/run_base_ref_browsix-wasm.0000/\\/run_base_ref_browsix-asmjs.0000/g' speccmds.cmd-2 > speccmds.cmd\ncd ../../../../../../../../\n```\n\n4. Copy executable file(s), i.e. `bzip2.js`.\n```\ncp /spec-cpu2006/benchspec/CPU2006/401.bzip2/build/build_base_browsix-wasm.0000/bzip2.js fs/spec/cpu2006_asmjs/benchspec/CPU2006/401.bzip2/run/run_base_ref_browsix-asmjs.0000/bzip2_base.browsix-wasm\n```\nTo copy `bzip2.js` for asm.js, replace `run_base_ref_browsix-wasm.0000` with `run_base_ref_browsix-asmjs.0000`.\n5. Build `specinvoke` binary provided by SPEC CPU2006 Benchmarks using Emscripten and copy that binary to `browsix-spec2006/fs/usr/bin`.\n6. Update Browsix-WASM's filesystem index.\n```\n./xhrfs-index fs > fs/index.json\n```\n\n## Execute Benchmarks\n1. Execute Browsix-SPEC's server that finds the process executing the benchmark in the browser and attach `perf` to it.\n```\ncd browsix-spec2006\nsudo node spec_server.js\n```\n2. To enable SharedArrayBuffer in Chrome go to `chrome://flags` and enable `Experimental enabled SharedArrayBuffer support in JavaScript.` and in Firefox go to `about:config` and enable `javascript.options.shared_memory`.\n3. To execute the benchmark in Firefox, open Firefox in command line using `firefox -contentproc=2` and to execute the benchmark in Chrome open Chrome in command line using `google-chrome-stable`.\n4. To execute `bzip2` with `ref` dataset, navigate to ` http://localhost:9000/?size=ref&benchmark=bzip2`.\n5. We can use Web Console/Browser Console in Firefox and Developer Tools -> Console in Chrome to see the progress of each benchmark.\n6. When the benchmark is finished, download the resulting tar file that contains the output of the benchmark, `speccmds.out`, `speccmds.err` etc. files.\n7. Data collected by perf is in `browsix-spec2006/perf_data`.\n"
        },
        {
          "name": "chrome_sab",
          "type": "blob",
          "size": 0.123046875,
          "content": "#!/usr/bin/bash\n\nexec google-chrome-beta --js-flags=--harmony-sharedarraybuffer --enable-blink-feature=SharedArrayBuffer \"$@\"\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "gulp-plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "gulpfile.js",
          "type": "blob",
          "size": 17.638671875,
          "content": "'use strict';\n\nvar browserify = require('browserify');\nvar gulp = require('gulp');\nvar gutil = require('gulp-util');\nvar copy = require('gulp-copy');\nvar rename = require('gulp-rename');\nvar merge = require('merge2');\nvar ts = require('gulp-typescript');\nvar lint = require('gulp-tslint');\nvar mocha = require('gulp-mocha');\nvar browserSync = require('browser-sync');\nvar reload = browserSync.reload;\nvar source = require('vinyl-source-stream');\nvar buffer = require('vinyl-buffer');\nvar karma = require('karma');\nvar run = require('gulp-run');\nvar chmod = require('gulp-chmod');\nvar url = require('url');\nvar extend = require('util')._extend;\n\nvar $ = require('gulp-load-plugins')();\nvar del = require('del');\nvar path = require('path');\nvar fs = require('fs');\nvar historyApiFallback = require('connect-history-api-fallback');\n\nvar addShebang = require('./gulp-plugins/add-shebang');\n\n\n// don't do anything when seeing use of several node builtins -- we\n// handle this ourselves.\nvar globalVars = {\n    'RELEASE': function() { return 'false'; },\n    'buffer': function() { return 'require(\"browserfs-browsix-tmp\").BFSRequire(\"buffer\")'; },\n    'Buffer': function() { return 'require(\"browserfs-browsix-tmp\").BFSRequire(\"buffer\").Buffer'; },\n    'process': function() { return \"\" },\n    'setImmediate' : undefined,\n    'clearImmediate' : undefined,\n};\n\nvar builtins = {\n//    'process': function() { return \"\" },\n\n//    'Buffer': function() { return \"\" },\n//    'buffer': require.resolve('bfs-buffer'),\n    'path': require.resolve('bfs-path'),\n};\n\n// each user of our tsconfig.json setup needs a different instance of\n// the 'ts project', as gulp-typescript seems to use it as a dumping\n// ground for mutable state.\nfunction project(extraLibs) {\n    let configFile = fs.readFileSync('tsconfig.json');\n    let config = JSON.parse(configFile).compilerOptions;\n    config.lib = [\n        \"DOM\",\n        \"DOM.Iterable\",\n        \"ScriptHost\",\n        \"es2016\",\n        \"es2017.sharedmemory\",\n    ];\n    if (extraLibs)\n        libs.concat(extraLibs);\n\n    return ts(config);\n}\n\nfunction tsPipeline(src, dst, extraLibs) {\n    return function() {\n        let build = gulp.src(src)\n            .pipe(project(extraLibs));\n\n\treturn merge([\n\t    build.dts.pipe(gulp.dest(dst)),\n\t    build.js.pipe(gulp.dest(dst)),\n\t]);\n    }\n}\n\n// creates tasks representing the build lifecycle of a typescript package:\n// - lint (optional)\n// - build w/ tsc\n// - dist  w/ browserify\nfunction tsTask(subdir, options) {\n    options = options || {};\n    var noBuffer = options.noBuffer;\n    var noGlobal = options.noGlobal;\n    var buildDeps = options.buildDeps || [];\n    var otherSources = options.otherSources || [];\n    var sources = ['src/'+subdir+'/*.ts', 'src/'+subdir+'/**/*.ts'].concat(otherSources);\n\n    gulp.task('lint-'+subdir, function() {\n        return gulp.src(['src/'+subdir+'/*.ts', 'src/'+subdir+'/*/*.ts'])\n            .pipe(lint({\n                formatter: \"verbose\",\n            }))\n            .pipe(lint.report());\n    });\n\n    // run lint by default, but if lint is specified as 'false' skip it\n    if (!options.hasOwnProperty('lint') || options.lint)\n        buildDeps = buildDeps.concat(['lint-'+subdir]);\n\n    gulp.task('build-'+subdir, buildDeps, tsPipeline(sources, 'lib/'+subdir, options.extraLibs));\n\n    var globals = extend({}, globalVars);\n    if (noGlobal)\n        globals['global'] = function() { return \"\"; };\n    if (noBuffer) {\n        globals['buffer'] = function() { return \"\"; };\n        globals['Buffer'] = function() { return \"\"; };\n    }\n\n    gulp.task('dist-'+subdir, ['build-'+subdir], function() {\n        var b = browserify({\n            entries: ['./lib/'+subdir+'/'+subdir+'.js'],\n            builtins: builtins,\n            insertGlobalVars: globals,\n        });\n        b.exclude('webworker-threads');\n\n        return b.bundle()\n            .pipe(source('./lib/'+subdir+'/'+subdir+'.js'))\n            .pipe(buffer())\n            .on('error', gutil.log)\n            .pipe(gulp.dest('./lib-dist/'));\n    });\n}\n\ngulp.task('copy-node-kernel', function() {\n    return gulp.src([\n        'node-modified/lib/binding/http_parser.js',\n    ]).pipe(copy('./lib/kernel/', {prefix: 3}));\n});\n\ngulp.task('copy-node', function() {\n    return gulp.src([\n        'node/lib/internal/util.js',\n        'node/lib/internal/freelist.js',\n        'node-modified/lib/binding/http_parser.js',\n        'node-modified/lib/internal/child_process.js',\n        'node/lib/_linklist.js',\n        'node/lib/_stream_*.js',\n        'node/lib/events.js',\n        'node/lib/constants.js',\n        'node/lib/path.js',\n        'node/lib/stream.js',\n        'node/lib/string_decoder.js',\n        'node/lib/util.js',\n        'node/lib/buffer.js',\n        'node/lib/assert.js',\n        'node/lib/fs.js',\n        'node/lib/vm.js',\n        'node/lib/readline.js',\n        'node/lib/domain.js',\n        'node/lib/timers.js',\n        'node/lib/string_decoder.js',\n        'node/lib/child_process.js',\n        'node/lib/dns.js',\n        'node/lib/dgram.js',\n        'node/lib/cluster.js',\n        'node/lib/net.js',\n        'node/lib/querystring.js',\n        'node/lib/punycode.js',\n        'node/lib/url.js',\n        'node/lib/_http_agent.js',\n        'node/lib/_http_common.js',\n        'node/lib/_http_incoming.js',\n        'node/lib/_http_outgoing.js',\n        'node/lib/_http_client.js',\n        'node/lib/_http_server.js',\n        'node/lib/http.js',\n    ]).pipe(copy('./lib/browser-node/', {prefix: 2}));\n});\n\n// the kernel directly uses BrowserFS's typescript modules - we need\n// to explicitly exclude tests and the browserify main here to avoid\n// confusing tsc :\\\ntsTask('kernel', {buildDeps: ['copy-node-kernel', 'copy-node']});\ntsTask('browser-node', {buildDeps: ['copy-node'], noBuffer: true});\ntsTask('bin');\ntsTask('syscall-api', {buildDeps: ['build-browser-node'], noGlobal: true});\ntsTask('hello-sync', {noGlobal: true});\n\n// next, we need to collect the various pieces we've built, and put\n// then in a sane directory hierarchy.  There is no dist step needed\n// for our binaries - they are self contained and meant to be run\n// directly from node or browser-node.\ngulp.task('build-fs-pre', ['dist-kernel', 'dist-browser-node', 'build-bin', 'dist-syscall-api'], function() {\n\n    var copyKernel = gulp.src('lib-dist/lib/kernel/kernel.js')\n          .pipe(copy('./fs/boot/', {prefix: 3}));\n\n    var copyNode = gulp.src('lib-dist/lib/browser-node/browser-node.js')\n          .pipe(rename(function(path) { path.basename = 'node'; path.extname = ''; }))\n          .pipe(gulp.dest('./fs/usr/bin/'));\n\n    var copyBin = gulp.src('lib/bin/*.js')\n          .pipe(rename(function(path) { path.extname = ''; }))\n          .pipe(addShebang('#!/usr/bin/env node\\n'))\n          .pipe(chmod(755))\n          .pipe(gulp.dest('./fs/usr/bin/'));\n\n    var copyLd = gulp.src('src/ld.js')\n          .pipe(rename(function(path) { path.extname = ''; }))\n          .pipe(chmod(755))\n          .pipe(gulp.dest('./fs/usr/bin/'));\n\n    return merge(copyKernel, copyNode, copyBin, copyLd);\n});\n\ngulp.task('build-fs', ['build-fs-pre'], function() {\n\n    var copyDash1 = gulp.src('src/dash.js')\n          .pipe(rename(function(path) { path.basename = 'sh'; path.extname = ''; }))\n          .pipe(gulp.dest('./fs/bin/'));\n\n    // FIXME: we should just look in 2 dirs on the path\n    var copyDash2 = gulp.src('src/dash.js')\n          .pipe(rename(function(path) { path.basename = 'sh'; path.extname = ''; }))\n          .pipe(gulp.dest('./fs/usr/bin/'));\n\n    return merge(copyDash1, copyDash2);\n});\n\n// finally, we create an index.json file so that BrowserFS can see\n// everything in our nice hierarchy\ngulp.task('index-fs', ['build-fs'], function() {\n    return run('./xhrfs-index fs').exec()\n        .pipe(rename(function(path) {\n            path.basename = 'index';\n            path.extname = '.json';\n        }))\n        .pipe(gulp.dest('./fs'));\n});\n\ngulp.task('copy-dash', [], function() {\n\n});\n\ngulp.task('index-benchfs', [], function() {\n    return run('./xhrfs-index benchfs').exec()\n        .pipe(rename(function(path) {\n            path.basename = 'index';\n            path.extname = '.json';\n        }))\n        .pipe(gulp.dest('./benchfs'));\n});\n\ngulp.task('build-test', ['index-fs'], function() {\n    return gulp.src('test/*.ts')\n        .pipe(project()).js\n        .pipe(gulp.dest('test'));\n});\n\ngulp.task('build-bench', ['index-benchfs'], function() {\n    return gulp.src('bench/*.ts')\n        .pipe(project()).js\n        .pipe(gulp.dest('bench'));\n});\n\n// we compile all our tests into a single javascript file because\n// that is how browserify likes to work :\\\ngulp.task('dist-test', ['build-test'], function() {\n    var testMain = './test/test-all.js';\n    var b = browserify({\n        entries: [testMain],\n        builtins: false,\n        insertGlobalVars: globalVars,\n    });\n    b.exclude('webworker-threads');\n\n    return b.bundle()\n        .pipe(source(testMain))\n        .pipe(buffer())\n        .on('error', gutil.log)\n        .pipe(gulp.dest('./lib-dist/'));\n});\n\ngulp.task('dist-bench', ['build-bench', 'index-benchfs'], function() {\n    var testMain = './bench/bench.js';\n    var b = browserify({\n        entries: [testMain],\n        builtins: false,\n        insertGlobalVars: globalVars,\n    });\n    b.exclude('webworker-threads');\n\n    return b.bundle()\n        .pipe(source(testMain))\n        .pipe(buffer())\n        .on('error', gutil.log)\n        .pipe(gulp.dest('./lib-dist/'));\n});\n\n// this starts karma & rebuild everything on change\ngulp.task('test-browser', ['dist-test'], function(done) {\n    new karma.Server({\n        configFile: __dirname + '/karma.conf.js',\n        singleRun: false,\n        autoWatchBatchDelay: 1000,\n    }, done).start();\n\n    gulp.watch(['src/**/*.ts', 'test/*.ts'], ['dist-test']);\n});\n\n// this runs karma once, exiting gulp on completion or failure\ngulp.task('bench', ['dist-bench'], function(done) {\n    new karma.Server({\n        configFile: __dirname + '/karma.conf.js',\n        singleRun: true,\n        concurrency: 1,\n        colors: false,\n        browserNoActivityTimeout: 100000, // ms\n        reporters: ['dots'],\n        browsers: ['Firefox', 'Chrome'],\n        files: [\n            'lib-dist/bench/bench.js',\n            {\n                pattern: 'benchfs/**/*',\n                included: false,\n                nocache: true,\n            },\n        ],\n    }, done).start();\n});\n\n// this runs karma once, exiting gulp on completion or failure\ngulp.task('default', ['dist-test'], function(done) {\n    new karma.Server({\n        configFile: __dirname + '/karma.conf.js',\n        singleRun: true,\n        browsers: ['Firefox'],\n    }, done).start();\n});\n\n// from this point on is the config for the Terminal web app, written\n// using Polymer.\n\nvar AUTOPREFIXER_BROWSERS = [\n    'ie >= 10',\n    'ie_mob >= 10',\n    'ff >= 30',\n    'chrome >= 34',\n    'safari >= 7',\n    'opera >= 23',\n    'ios >= 7',\n    'android >= 4.4',\n    'bb >= 10'\n];\n\nvar styleTask = function (stylesPath, srcs) {\n    return gulp.src(srcs.map(function(src) {\n        return path.join('app', stylesPath, src);\n    }))\n        .pipe($.changed(stylesPath, {extension: '.css'}))\n        .pipe($.autoprefixer(AUTOPREFIXER_BROWSERS))\n        .pipe(gulp.dest('.tmp/' + stylesPath))\n        .pipe($.cssmin())\n        .pipe(gulp.dest('dist/' + stylesPath))\n        .pipe($.size({title: stylesPath}));\n};\n\nvar imageOptimizeTask = function (src, dest) {\n    return gulp.src(src)\n        .pipe($.cache($.imagemin({\n            progressive: true,\n            interlaced: true\n        })))\n        .pipe(gulp.dest(dest))\n        .pipe($.size({title: 'images'}));\n};\n\nvar optimizeHtmlTask = function (src, dest) {\n    return gulp.src(src)\n    // Replace path for vulcanized assets\n        .pipe($.if('*.html', $.replace('elements/elements.html', 'elements/elements.vulcanized.html')))\n    // In case you are still using useref build blocks\n        .pipe($.if('*.css', $.cssmin()))\n        .pipe($.useref())\n    // Minify any HTML\n        .pipe($.if('*.html', $.minifyHtml({\n            quotes: true,\n            empty: true,\n            spare: true\n        })))\n    // Output files\n        .pipe(gulp.dest(dest))\n        .pipe($.size({title: 'html'}));\n};\n\nfunction gulp_app_tasks (app_path) {\n    // Compile and automatically prefix stylesheets\n    gulp.task(app_path+':styles', function () {\n        return styleTask('styles', ['**/*.css']);\n    });\n\n    gulp.task(app_path+':elements', [app_path+':build', app_path+':copy', app_path+':styles'], function () {\n        return styleTask('elements', ['**/*.css']);\n    });\n\n    // Optimize images\n    gulp.task(app_path+':images', function () {\n        return imageOptimizeTask(app_path+'/images/**/*', 'dist/images');\n    });\n\n    // Copy all files at the root level (app)\n    gulp.task(app_path+':copy', ['index-fs'], function () {\n        var app = gulp.src([\n            app_path+'/*',\n            '!'+app_path+'/test',\n            '!'+app_path+'/cache-config.json',\n        ], {\n            dot: true\n        }).pipe(gulp.dest('dist'));\n\n        var bower = gulp.src([\n            'bower_components/**/*'\n        ]).pipe(gulp.dest('dist/bower_components'));\n\n        var elements = gulp.src([\n            app_path+'/elements/**/*.html',\n            app_path+'/elements/**/*.css',\n            app_path+'/elements/**/*.js',\n        ])\n            .pipe(gulp.dest('dist/elements'));\n\n        var swBootstrap = gulp.src(['bower_components/platinum-sw/bootstrap/*.js'])\n            .pipe(gulp.dest('dist/elements/bootstrap'));\n\n        var swToolbox = gulp.src(['bower_components/sw-toolbox/*.js'])\n            .pipe(gulp.dest('dist/sw-toolbox'));\n\n        var vulcanized = gulp.src([app_path+'/elements/elements.html'])\n            .pipe($.rename('elements.vulcanized.html'))\n            .pipe(gulp.dest('dist/elements'));\n\n        var fs = gulp.src(['fs/**/*'])\n            .pipe(gulp.dest('dist/fs'));\n\n        return merge(app, bower, elements, vulcanized, swBootstrap, swToolbox, fs)\n            .pipe($.size({title: 'copy'}));\n    });\n\n    // Copy web fonts to dist\n    gulp.task(app_path+':fonts', function () {\n        return gulp.src(['app/fonts/**'])\n            .pipe(gulp.dest('dist/fonts'))\n            .pipe($.size({title: 'fonts'}));\n    });\n\n    // Scan your HTML for assets & optimize them\n    gulp.task(app_path+':html', [app_path+':elements'], function () {\n        return optimizeHtmlTask(\n            [app_path+'/**/*.html', '!'+app_path+'app/{elements,test}/**/*.html'],\n            'dist');\n    });\n\n    // Vulcanize granular configuration\n    gulp.task(app_path+':vulcanize', [app_path+':images', app_path+':fonts', app_path+':html'], function () {\n        var DEST_DIR = 'dist/elements';\n        return gulp.src('dist/elements/elements.vulcanized.html')\n            .pipe($.vulcanize({\n                stripComments: true,\n                inlineCss: true,\n                inlineScripts: true\n            }))\n            .pipe(gulp.dest(DEST_DIR))\n            .pipe($.size({title: 'vulcanize'}));\n    });\n\n    // Clean output directory\n    gulp.task(app_path+':clean', function (cb) {\n        del(['.tmp', 'dist'], cb);\n    });\n\n    gulp.task(app_path+':build', ['index-fs'], function (cb) {\n        return gulp.src([\n            app_path+'/elements/**/*.ts',\n        ])\n            .pipe(project()).js\n            .pipe(gulp.dest(app_path+'/elements'));\n\n    });\n}\n\ngulp_app_tasks ('app');\ngulp_app_tasks ('app-spec');\n\ngulp.task ('copy-spec-bins', [], function (cb) {\n    return gulp.src (['spec-bins',]).pipe (gulp.dest ('fs/usr/bin/'));\n});\n\ngulp.task ('create-spec-dirs', [], function (cb) {\n    return gulp.src(\"*.js\", {read:false}).pipe (gulp.dest ('fs/spec/cpu2006_asmjs/benchspec/CPU2006/'));\n});\n\ngulp.task ('browsix-spec', ['copy-spec-bins', 'create-spec-dirs', 'app-spec:build', 'app-spec:styles', 'app-spec:elements', 'app-spec:images']);\n\n// Watch files for changes & reload\ngulp.task('serve', ['app:build', 'app:styles', 'app:elements', 'app:images'], function () {\n    browserSync({\n        port: 5000,\n        notify: false,\n        ghostMode: false,\n        logPrefix: 'browsix',\n        snippetOptions: {\n            rule: {\n                match: '<span id=\"browser-sync-binding\"></span>',\n                fn: function (snippet) {\n                    return snippet;\n                }\n            }\n        },\n        // Run as an https by uncommenting 'https: true'\n        // Note: this uses an unsigned certificate which on first access\n        //       will present a certificate warning in the browser.\n        // https: true,\n        server: {\n            baseDir: ['.tmp', 'app'],\n            routes: {\n                '/bower_components': 'bower_components',\n                '/fs': 'fs',\n                '/benchfs': 'benchfs',\n            },\n            middleware: [],\n        }\n    });\n\n    gulp.watch(['src/kernel/*.ts'], ['dist-kernel', reload]);\n    gulp.watch(['app/**/*.html'], reload);\n    gulp.watch(['app/styles/**/*.css'], ['app:styles', reload]);\n    gulp.watch(['app/elements/**/*.css'], ['app:elements', reload]);\n    gulp.watch(['app/{scripts,elements}/**/*.ts'], ['app:build']);\n    gulp.watch(['app/images/**/*'], reload);\n});\n\n// Build and serve the output from the dist build\ngulp.task('serve:dist', ['build:dist'], function () {\n    browserSync({\n        port: 5001,\n        notify: false,\n        logPrefix: 'browsix',\n        snippetOptions: {\n            rule: {\n                match: '<span id=\"browser-sync-binding\"></span>',\n                fn: function (snippet) {\n                    return snippet;\n                }\n            }\n        },\n        // Run as an https by uncommenting 'https: true'\n        // Note: this uses an unsigned certificate which on first access\n        //       will present a certificate warning in the browser.\n        // https: true,\n        server: 'dist',\n        middleware: [ historyApiFallback() ]\n    });\n});\n\n// Build production files, the default task\ngulp.task('build:dist', ['app:vulcanize']);\n"
        },
        {
          "name": "karma.conf.js",
          "type": "blob",
          "size": 1.8125,
          "content": "// Karma configuration\n// Generated on Fri Oct 02 2015 10:32:16 GMT-0400 (EDT)\n\nmodule.exports = function(config) {\n    config.set({\n        // base path that will be used to resolve all patterns (eg. files, exclude)\n        basePath: '.',\n\n\n        // frameworks to use\n        // available frameworks: https://npmjs.org/browse/keyword/karma-adapter\n        frameworks: ['mocha'],\n\n\n        // list of files / patterns to load in the browser\n        files: [\n            'lib-dist/test/*.js',\n            {\n                pattern: 'fs/**/*',\n                included: false,\n                nocache: true,\n            },\n        ],\n\n\tproxies: {\n\t},\n\n\n        // list of files to exclude\n        exclude: [\n        ],\n\n\n        // preprocess matching files before serving them to the browser\n        // available preprocessors: https://npmjs.org/browse/keyword/karma-preprocessor\n        preprocessors: {\n        },\n\n\n        // test results reporter to use\n        // possible values: 'dots', 'progress'\n        // available reporters: https://npmjs.org/browse/keyword/karma-reporter\n        reporters: ['progress'],\n\n\n        // web server port\n        port: 9876,\n\n\n        // enable / disable colors in the output (reporters and logs)\n        colors: true,\n\n\n        // level of logging\n        // possible values: config.LOG_DISABLE || config.LOG_ERROR || config.LOG_WARN || config.LOG_INFO || config.LOG_DEBUG\n        logLevel: config.LOG_INFO,\n\n\n        // enable / disable watching file and executing tests whenever any file changes\n        autoWatch: true,\n\n\n        // start these browsers\n        // available browser launchers: https://npmjs.org/browse/keyword/karma-launcher\n        browsers: [],\n\n\n        // Continuous Integration mode\n        // if true, Karma captures browsers, runs the tests and exits\n        singleRun: false\n    })\n}\n"
        },
        {
          "name": "node-modified",
          "type": "tree",
          "content": null
        },
        {
          "name": "node",
          "type": "tree",
          "content": null
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 2.041015625,
          "content": "{\n  \"name\": \"browsix\",\n  \"version\": \"0.9.2\",\n  \"description\": \"in-browser, multi-process operating system\",\n  \"main\": \"lib/kernel/kernel.js\",\n  \"scripts\": {\n    \"prepublishOnly\": \"node_modules/.bin/gulp build:dist\",\n    \"test\": \"node_modules/.bin/gulp test-once\"\n  },\n  \"repository\": {\n    \"url\": \"https://github.com/plasma-umass/browsix.git\"\n  },\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/plasma-umass/browsix/issues\"\n  },\n  \"homepage\": \"https://github.com/plasma-umass/browsix\",\n  \"devDependencies\": {\n    \"bfs-buffer\": \"^0.1.7\",\n    \"bfs-path\": \"^0.1.2\",\n    \"bower\": \"^1.8.8\",\n    \"browser-sync\": \"^2.13.0\",\n    \"browserfs-browsix-tmp\": \"0.5.15\",\n    \"browserify\": \"^13.0.1\",\n    \"chai\": \"^4.0.2\",\n    \"connect-history-api-fallback\": \"^1.1.0\",\n    \"del\": \"^3.0.0\",\n    \"express\": \"^4.16.4\",\n    \"gulp\": \"^3.9.1\",\n    \"gulp-autoprefixer\": \"^4.0.0\",\n    \"gulp-cache\": \"^0.4.5\",\n    \"gulp-changed\": \"^1.3.0\",\n    \"gulp-chmod\": \"^1.3.0\",\n    \"gulp-copy\": \"0.0.2\",\n    \"gulp-cssmin\": \"^0.2.0\",\n    \"gulp-if\": \"^2.0.0\",\n    \"gulp-imagemin\": \"^2.4.0\",\n    \"gulp-load-plugins\": \"^1.2.0\",\n    \"gulp-minify-html\": \"^1.0.5\",\n    \"gulp-mocha\": \"^2.2.0\",\n    \"gulp-rename\": \"^1.2.2\",\n    \"gulp-replace\": \"^0.6.1\",\n    \"gulp-run\": \"^1.6.12\",\n    \"gulp-size\": \"^2.0.0\",\n    \"gulp-tslint\": \"^8.1.1\",\n    \"gulp-typescript\": \"^3.1.7\",\n    \"gulp-useref\": \"^3.1.2\",\n    \"gulp-util\": \"^3.0.6\",\n    \"gulp-vulcanize\": \"^6.1.0\",\n    \"karma\": \"^1.1.1\",\n    \"karma-chai\": \"^0.1.0\",\n    \"karma-chrome-launcher\": \"^2.2.0\",\n    \"karma-firefox-launcher\": \"^1.0.0\",\n    \"karma-mocha\": \"^1.1.1\",\n    \"merge2\": \"^1.1.0\",\n    \"mocha\": \"^3.4.2\",\n    \"through2\": \"^2.0.3\",\n    \"tslint\": \"^5.5.0\",\n    \"typescript\": \"^2.4.1\",\n    \"vinyl-buffer\": \"^1.0.0\",\n    \"vinyl-source-stream\": \"^1.1.0\"\n  },\n  \"dependencies\": {\n    \"@types/chai\": \"^4.0.1\",\n    \"@types/dropboxjs\": \"0.0.29\",\n    \"@types/filesystem\": \"0.0.28\",\n    \"@types/mocha\": \"^2.2.41\",\n    \"child_process\": \"^1.0.2\",\n    \"node-binary-marshal\": \"^0.4.2\",\n    \"term.js\": \"github:bpowers/term.js\"\n  },\n  \"engines\": {\n    \"node\": \">=4.3.0\"\n  }\n}\n"
        },
        {
          "name": "spec-bins",
          "type": "tree",
          "content": null
        },
        {
          "name": "spec_server.js",
          "type": "blob",
          "size": 8.7861328125,
          "content": "\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar fs = require(\"fs\");\nvar express = require(\"express\");\nvar bodyParser = require(\"body-parser\");\nvar fs_1 = require(\"fs\");\n//import * as cors from 'cors';\nvar child_process_1 = require(\"child_process\");\nvar Browsers = [\n    {\n        name: \"Chrome\",\n        lowerName: \"chrome\",\n        grepSearch: \"chrome\\\\|chromium\\\\|Chrome\",\n        argumentFilter: \"--type=renderer\",\n        workerName: \"DedicatedWorker\",\n        isBrowser: function (userAgent) { return userAgent.indexOf(\"Chrome\") !== -1 || userAgent.indexOf(\"Chromium\") !== -1; }\n    },\n    {\n        name: \"Firefox\",\n        lowerName: \"firefox\",\n        grepSearch: \"firefox\",\n        argumentFilter: \"-contentproc\",\n        workerName: \"DOM Worker\",\n        isBrowser: function (userAgent) { return userAgent.indexOf('Firefox') !== -1; }\n    }\n];\nvar desiredEvents = [\n    'cpu-cycles',\n    'instructions',\n    'cache-references',\n    'cache-misses',\n    'branch-instructions',\n    'branch-misses',\n    'stalled-cycles-backend',\n    'stalled-cycles-frontend',\n    'L1-dcache-load-misses',\n    'L1-dcache-loads',\n    'L1-dcache-prefetch-misses',\n    'L1-dcache-prefetches',\n    'L1-dcache-stores',\n    'L1-icache-load-misses',\n    'L1-icache-loads',\n    'L1-icache-prefetches',\n    'LLC-load-misses',\n    'LLC-loads',\n    'LLC-stores',\n    'branch-load-misses',\n    'branch-loads',\n    'dTLB-load-misses',\n    'dTLB-loads',\n    'iTLB-load-misses',\n    'iTLB-loads',\n];\nvar rawEvents = [\n    'r00c4',\n    'r00c5',\n    'r04c5',\n    'r01c5',\n    'r04c4',\n    'r01c4',\n    'r08c4',\n    'r01d1',\n    'r02d1',\n    'r04d1',\n    'r08d1',\n    'r10d1',\n    'r20d1',\n    'r81d0',\n    'r82d0',\n    'r412e',\n    'r4f2e',\n    'r1c0',\n];\n//let argv = process.argv.slice(2);\nchild_process_1.exec ('./xhrfs-index fs > fs/index.json');\nif (!fs.existsSync ('perf_data')) {\n    fs.mkdirSync ('perf_data');\n}\nvar events;\nvar app = express();\napp.use(bodyParser.raw({ type: 'application/x-tar' }));\n//app.use(cors());\napp.use('/', express.static('.'));\napp.use('/', express.static('app-spec'));\nvar perfProcesses = [];\nfunction findWorkerTids(pid, workerName) {\n    try {\n        return child_process_1.execSync(\"ls -1 /proc/\" + pid + \"/task\").toString().trim().split(\"\\n\")\n            // Remove non-numerical folders.\n            .map(function (item) { return parseInt(item, 10); })\n            .filter(function (item) { return !isNaN(item); })\n            // Remove non-worker threads.\n            .filter(function (item) {\n            try {\n                return child_process_1.execSync(\"cat /proc/\" + pid + \"/task/\" + item + \"/comm\").toString().trim() === workerName;\n            }\n            catch (e) {\n                return false;\n            }\n        });\n    }\n    catch (e) {\n        return [];\n    }\n}\nfunction tryStartPerf(pid, binary, browser) {\n    return findWorkerTids(pid, browser.workerName).map(function (tid) {\n        var nameBase = \"perf_data/perf-\" + browser.name + \"-\" + binary + \"-\" + pid + \"-\" + tid;\n        var name = nameBase + \".data\";\n        var postfix = 0;\n        while (fs_1.existsSync(name)) {\n            name = nameBase + \"-\" + postfix + \".data\";\n            postfix++;\n        }\n        return child_process_1.spawn(\"perf\", [\"stat\",\n            \"-x,\",\n            \"-e\", events,\n            \"-t\", tid.toString(),\n            \"-o\", name,\n        ], { stdio: 'inherit' });\n    });\n}\napp.get('/start', function (req, res) {\n    var binary = req.query.binary ? req.query.binary : \"unknown\";\n    var userAgent = req.header('user-agent');\n    var possibleBrowsers = Browsers.filter(function (b) { return b.isBrowser(userAgent); });\n    if (possibleBrowsers.length === 0) {\n        console.log(\"Unknown browser: \" + userAgent);\n        res.status(500).send(\"Unknown browser: \" + userAgent);\n        return;\n    }\n    else if (possibleBrowsers.length > 1) {\n        var errMsg = \"userAgent is ambiguous: \" + userAgent + \"\\nPossible browsers: \" + possibleBrowsers.map(function (b) { return b.name; }).join(\", \");\n        console.log(errMsg);\n        res.status(500).send(errMsg);\n        return;\n    }\n    var browser = possibleBrowsers[0];\n    console.log(\"Received /start request for \" + binary + \" in browser \" + browser.name + \".\");\n    // Figure out PID of Chrome.\n    child_process_1.exec(\"ps -eo pid,start_time,args --sort=start_time | grep \\\"\" + browser.grepSearch + \"\\\"\", function (err, stdout, stderr) {\n        if (err || stderr.length > 0) {\n            // Internal Server Error.\n            console.log(\"Failed to find \" + browser.name + \"'s PID.\");\n            res.status(500).send(\"Failed to find \" + browser.name + \"'s PID.\");\n        }\n        else {\n            // Filter out invalid processes\n            var processes = stdout.toString().trim().split(\"\\n\").filter(function (line) { return line.indexOf(browser.argumentFilter) !== -1; });\n            // Desired PID should be last one in list, so search from bottom up\n            for (var i = processes.length - 1; i >= 0; i--) {\n                var process_1 = processes[i].trim();\n                console.log(\"Trying PID: \" + process_1.slice(0, process_1.indexOf(' ')));\n                var pid = parseInt(process_1.slice(0, process_1.indexOf(' ')), 10);\n                if (isNaN(pid)) {\n                    res.status(500).send(\"Failed to parse PID from string \" + process_1);\n                    return;\n                }\n                perfProcesses = tryStartPerf(pid, binary, browser);\n                if (perfProcesses.length > 0) {\n                    console.log(\"Number of perf processed: \" + perfProcesses.length);\n                    res.send();\n                    return;\n                }\n            }\n            console.log(\"Unable to find a suitable \" + browser + \" process.\");\n            res.status(500).send(\"Failed to find a suitable \" + browser + \" process.\");\n        }\n    });\n});\napp.get('/stop', function (req, res) {\n    console.log(\"Received /stop request.\");\n    var count = perfProcesses.length;\n    function exitCounter() {\n        if (--count === 0) {\n            perfProcesses = [];\n            res.send();\n            child_process_1.execSync('chmod -R ugo+r ./perf_data');\n            //child_process_1.execSync('chown -R abhinav ./perf_data');\n        }\n    }\n    perfProcesses.forEach(function (p) {\n        p.on('exit', exitCounter);\n        p.kill('SIGINT');\n    });\n    setTimeout(function () {\n        if (count > 0) {\n            res.status(500).send(\"Unable to end all perf processes.\");\n        }\n    }, 10000);\n    if (perfProcesses.length === 0) {\n        res.send();\n        child_process_1.execSync('chmod -R ugo+r ./perf_data');\n        //child_process_1.execSync('chown -R abhinav ./perf_data');\n    }\n});\napp.get('/exit', function (req, res) {\n    res.send();\n    process.exit();\n});\napp.post('/record', function (req, res) {\n    var userAgent = req.header('user-agent');\n    var possibleBrowsers = Browsers.filter(function (b) { return b.isBrowser(userAgent); });\n    if (possibleBrowsers.length === 0) {\n        console.log(\"Unknown browser: \" + userAgent);\n        res.status(500).send(\"Unknown browser: \" + userAgent);\n        return;\n    }\n    else if (possibleBrowsers.length > 1) {\n        var errMsg = \"userAgent is ambiguous: \" + userAgent + \"\\nPossible browsers: \" + possibleBrowsers.map(function (b) { return b.name; }).join(\", \");\n        console.log(errMsg);\n        res.status(500).send(errMsg);\n        return;\n    }\n    var browser = possibleBrowsers[0];\n    var size = req.query.size;\n    var benchmark = req.query.benchmark;\n    var bsize = req.body.length;\n    console.log(\"Received /record request for \" + benchmark + \" (size: \" + size + \") -- body size \" + bsize);\n    var fileName = \"./results_\" + browser.lowerName + \"_\" + size + \"_\" + benchmark + \".tar\";\n    fs.writeFileSync(fileName, req.body);\n    child_process_1.execSync('chmod -R ugo+r ' + fileName);\n    //child_process_1.execSync('chown -R abhinav ' + fileName);\n    res.send();\n    //process.exit(0);\n});\nchild_process_1.exec(\"perf list --raw-dump\", function (err, stdout, stderr) {\n    if (err || stderr.length > 0) {\n        console.log('perf-list error: ' + stdout);\n        return;\n    }\n    var lines = stdout.split('\\n');\n    var availableEventsList = lines.map(function (l) { return l.split(' '); }).reduce(function (a, b) { return a.concat(b); });\n    var availableEvents = new Set(availableEventsList);\n    var ourEvents = desiredEvents.filter(function (e) { return availableEvents.has(e); });\n    var missingEvents = desiredEvents.filter(function (e) { return !availableEvents.has(e); });\n    console.log('missing events:');\n    console.log(missingEvents);\n    ourEvents = ourEvents.concat(rawEvents);\n    events = ourEvents.join(',');\n    console.log(events);\n    app.listen(9000, 'localhost', function () {\n        console.log(\"Server now listening on http://localhost:9000/\");\n    });\n});\n//# sourceMappingURL=server.js.map\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tsconfig.json",
          "type": "blob",
          "size": 0.2333984375,
          "content": "{\n    \"compilerOptions\": {\n        \"target\": \"es5\",\n        \"module\": \"commonjs\",\n\t\"declaration\": true,\n        \"noImplicitAny\": true,\n        \"removeComments\": true,\n        \"experimentalDecorators\": true,\n        \"newLine\": \"LF\"\n    }\n}\n"
        },
        {
          "name": "tslint.json",
          "type": "blob",
          "size": 1.9931640625,
          "content": "{\n  \"rules\": {\n  \"align\": [true,\n        \"parameters\",\n        \"arguments\",\n        \"statements\"],\n    \"ban\": false,\n    \"class-name\": true,\n    \"comment-format\": [true\n    ],\n    \"curly\": false,\n    \"eofline\": true,\n    \"forin\": true,\n    \"indent\": [true, \"tabs\"],\n    \"interface-name\": false,\n    \"jsdoc-format\": true,\n    \"label-position\": true,\n    \"max-line-length\": [true, 140],\n    \"member-access\": false,\n    \"member-ordering\": [true,\n        \"public-before-private\",\n        \"static-before-instance\",\n        \"variables-before-functions\"\n    ],\n    \"no-any\": false,\n    \"no-arg\": true,\n    \"no-bitwise\": false,\n    \"no-conditional-assignment\": false,\n    \"no-console\": [true,\n        \"debug\",\n        \"info\",\n        \"time\",\n        \"timeEnd\"\n    ],\n    \"no-construct\": true,\n    \"no-constructor-vars\": false,\n    \"no-debugger\": false,\n    \"no-shadowed-variable\": false,\n    \"no-duplicate-variable\": true,\n    \"no-empty\": false,\n    \"no-eval\": true,\n    \"no-internal-module\": true,\n    \"no-require-imports\": false,\n    \"no-string-literal\": false,\n    \"no-switch-case-fall-through\": true,\n    \"no-trailing-whitespace\": true,\n    \"no-unused-expression\": true,\n    \"no-unused-variable\": false,\n    \"no-use-before-declare\": false,\n    \"no-var-keyword\": true,\n    \"no-var-requires\": false,\n    \"one-line\": [true,\n        \"check-open-brace\",\n        \"check-catch\",\n        \"check-whitespace\"\n    ],\n    \"radix\": true,\n    \"semicolon\": true,\n    \"switch-default\": false,\n    \"triple-equals\": [true, \"allow-null-check\"],\n    \"typedef\": [true,\n        \"call-signature\",\n        \"property-declaration\",\n        \"member-variable-declaration\"\n    ],\n    \"typedef-whitespace\": [true, {\n        \"call-signature\": \"nospace\",\n        \"index-signature\": \"nospace\",\n        \"parameter\": \"nospace\",\n        \"property-declaration\": \"nospace\",\n        \"variable-declaration\": \"nospace\"\n    }],\n    \"variable-name\": false,\n    \"whitespace\": [true,\n        \"check-branch\",\n        \"check-decl\",\n        \"check-separator\",\n        \"check-type\"\n    ]\n  }\n}\n"
        },
        {
          "name": "xhrfs-index",
          "type": "blob",
          "size": 2.44921875,
          "content": "#!/usr/bin/env node\n// based on jvilk's XHRIndexer, but in plain JS using async APIs\n\n'use strict';\n\nvar fs = require('fs');\nvar path = require('path');\n\nvar exclude = [\n//        /^\\./, // dotfiles\n        /^bower_components$/,\n        /^node_modules$/,\n        /^build$/,\n        /^dist$/,\n        /~$/, // emacs backups\n];\n\nfunction shouldExclude(name) {\n    for (var i = 0; i < exclude.length; i++) {\n        if (name.match(exclude[i]))\n            return true;\n    }\n    return false;\n}\n\nvar outstanding = 1;\nvar tree = {};\n\nfunction subtreeAt(relative) {\n    if (!relative)\n\treturn tree;\n\n    var parts = relative.split(path.sep);\n    var subtree = tree;\n    // start at 1 to skip the leading /\n    for (var i = 1; i < parts.length; i++)\n        subtree = subtree[parts[i]];\n\n    return subtree;\n}\n\nfunction maybeFinished(file, err, onComplete) {\n    if (--outstanding === 0) {\n\tonComplete(err, tree);\n    }\n}\n\nfunction walkDir(base, curr, onComplete) {\n    var parent = curr.slice(base.length);\n    fs.readdir(curr, function(err, files) {\n\tif (err) {\n\t    process.stderr.write('error reading dir: ' + err);\n\t    maybeFinished(curr, err, onComplete);\n\t    return;\n\t}\n        for (var i = 0; i < files.length; i++) {\n            var file = files[i];\n            if (shouldExclude(file))\n                continue;\n\n\t    outstanding++;\n\n\t    var absFile = path.join(curr, file)\n            fs.stat(absFile, function statFile(absFile, err, stats) {\n\t\tif (err) {\n\t\t    maybeFinished(absFile, err, onComplete);\n\t\t    return;\n\t\t}\n\t\tvar parts = absFile.split(path.sep);\n\t\tvar file = parts[parts.length-1];\n                var subtree = subtreeAt(parent);\n                if (stats.isDirectory()) {\n                    subtree[file] = {};\n                    walkDir(base, absFile, onComplete);\n                } else {\n                    subtree[file] = null;\n\t\t    maybeFinished(absFile, null, onComplete);\n                }\n            }.bind(null, absFile));\n        }\n\tmaybeFinished(curr, null, onComplete);\n    });\n}\n\nfunction main() {\n    var pathToNode = process.argv[0];\n    var pathToScript = process.argv[1];\n    var args = process.argv.slice(2);\n\n    var root = process.cwd();\n    if (args.length > 0)\n        root = args[0];\n\n    walkDir(root, root, function writeJSON(err, tree) {\n        if (err) {\n            process.stderr.write('error: ' + err + '\\n');\n            process.exit(-1);\n            return;\n        }\n        process.stdout.write(JSON.stringify(tree) + '\\n');\n    });\n}\n\nmain();\n"
        }
      ]
    }
  ]
}