{
  "metadata": {
    "timestamp": 1736561420660,
    "page": 64,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "zhayujie/chatgpt-on-wechat",
      "stars": 32537,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.1845703125,
          "content": "[flake8]\nmax-line-length = 176\nselect = E303,W293,W291,W292,E305,E231,E302\nexclude =\n    .tox,\n    __pycache__,\n    *.pyc,\n    .env\n    venv/*\n    .venv/*\n    reports/*\n    dist/*\n    lib/*"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.4287109375,
          "content": ".DS_Store\n.idea\n.vscode\n.venv\n.vs\n.wechaty/\n__pycache__/\nvenv*\n*.pyc\nconfig.json\nQR.png\nnohup.out\ntmp\nplugins.json\nitchat.pkl\n*.log\nuser_datas.pkl\nchatgpt_tool_hub/\nplugins/**/\n!plugins/bdunit\n!plugins/dungeon\n!plugins/finish\n!plugins/godcmd\n!plugins/tool\n!plugins/banwords\n!plugins/banwords/**/\nplugins/banwords/__pycache__\nplugins/banwords/lib/__pycache__\n!plugins/hello\n!plugins/role\n!plugins/keyword\n!plugins/linkai\nclient_config.json\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8203125,
          "content": "repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: fix-byte-order-marker\n      - id: check-case-conflict\n      - id: check-merge-conflict\n      - id: debug-statements\n      - id: pretty-format-json\n        types: [text]\n        files: \\.json(.template)?$\n        args: [ --autofix , --no-ensure-ascii, --indent=2, --no-sort-keys]\n      - id: trailing-whitespace\n        exclude: '(\\/|^)lib\\/'\n        args: [ --markdown-linebreak-ext=md ]\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n        exclude: '(\\/|^)lib\\/'\n  - repo: https://github.com/psf/black\n    rev: 23.3.0\n    hooks:\n      - id: black\n        exclude: '(\\/|^)lib\\/'\n  - repo: https://github.com/PyCQA/flake8\n    rev: 6.0.0\n    hooks:\n      - id: flake8\n        exclude: '(\\/|^)lib\\/'"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.0751953125,
          "content": "FROM ghcr.io/zhayujie/chatgpt-on-wechat:latest\n\nENTRYPOINT [\"/entrypoint.sh\"]"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0263671875,
          "content": "Copyright (c) 2022 zhayujie\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.2568359375,
          "content": "<p align=\"center\"><img src= \"https://github.com/user-attachments/assets/31fb4eab-3be4-477d-aa76-82cf62bfd12c\" alt=\"Chatgpt-on-Wechat\" width=\"600\" /></p>\n\n<p align=\"center\">\n   <a href=\"https://github.com/zhayujie/chatgpt-on-wechat/releases/latest\"><img src=\"https://img.shields.io/github/v/release/zhayujie/chatgpt-on-wechat\" alt=\"Latest release\"></a>\n  <a href=\"https://github.com/zhayujie/chatgpt-on-wechat/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/zhayujie/chatgpt-on-wechat\" alt=\"License: MIT\"></a>\n  <a href=\"https://github.com/zhayujie/chatgpt-on-wechat\"><img src=\"https://img.shields.io/github/stars/zhayujie/chatgpt-on-wechat?style=flat-square\" alt=\"Stars\"></a> <br/>\n</p>\n\nchatgpt-on-wechat（简称CoW）项目是基于大模型的智能对话机器人，支持微信公众号、企业微信应用、飞书、钉钉接入，可选择GPT3.5/GPT4.0/Claude/Gemini/LinkAI/ChatGLM/KIMI/文心一言/讯飞星火/通义千问/LinkAI，能处理文本、语音和图片，通过插件访问操作系统和互联网等外部资源，支持基于自有知识库定制企业AI应用。\n\n# 简介\n\n最新版本支持的功能如下：\n\n-  ✅   **多端部署：** 有多种部署方式可选择且功能完备，目前已支持微信公众号、企业微信应用、飞书、钉钉等部署方式\n-  ✅   **基础对话：** 私聊及群聊的消息智能回复，支持多轮会话上下文记忆，支持 GPT-3.5, GPT-4o-mini, GPT-4o,  GPT-4, Claude-3.5, Gemini, 文心一言, 讯飞星火, 通义千问，ChatGLM-4，Kimi(月之暗面), MiniMax, GiteeAI\n-  ✅   **语音能力：** 可识别语音消息，通过文字或语音回复，支持 azure, baidu, google, openai(whisper/tts) 等多种语音模型\n-  ✅   **图像能力：** 支持图片生成、图片识别、图生图（如照片修复），可选择 Dall-E-3, stable diffusion, replicate, midjourney, CogView-3, vision模型\n-  ✅   **丰富插件：** 支持个性化插件扩展，已实现多角色切换、文字冒险、敏感词过滤、聊天记录总结、文档总结和对话、联网搜索等插件\n-  ✅   **知识库：** 通过上传知识库文件自定义专属机器人，可作为数字分身、智能客服、私域助手使用，基于 [LinkAI](https://link-ai.tech) 实现\n\n## 声明\n\n1. 本项目遵循 [MIT开源协议](/LICENSE)，仅用于技术研究和学习，使用本项目时需遵守所在地法律法规、相关政策以及企业章程，禁止用于任何违法或侵犯他人权益的行为\n2. 境内使用该项目时，请使用国内厂商的大模型服务，并进行必要的内容安全审核及过滤\n3. 本项目主要接入协同办公平台，推荐使用公众号、企微自建应用、钉钉、飞书等接入通道，其他通道为历史产物已不维护\n4. 任何个人、团队和企业，无论以何种方式使用该项目、对何对象提供服务，所产生的一切后果，本项目均不承担任何责任\n\n## 演示\n\nDEMO视频：https://cdn.link-ai.tech/doc/cow_demo.mp4\n\n## 社区\n\n添加小助手微信加入开源项目交流群：\n\n<img width=\"160\" src=\"https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/open-community.png\">\n\n<br>\n\n# 企业服务\n\n<a href=\"https://link-ai.tech\" target=\"_blank\"><img width=\"800\" src=\"https://cdn.link-ai.tech/image/link-ai-intro.jpg\"></a>\n\n> [LinkAI](https://link-ai.tech/) 是面向企业和开发者的一站式AI应用平台，聚合多模态大模型、知识库、Agent 插件、工作流等能力，支持一键接入主流平台并进行管理，支持SaaS、私有化部署多种模式。\n>\n> LinkAI 目前 已在私域运营、智能客服、企业效率助手等场景积累了丰富的 AI 解决方案， 在电商、文教、健康、新消费、科技制造等各行业沉淀了大模型落地应用的最佳实践，致力于帮助更多企业和开发者拥抱 AI 生产力。\n\n**企业服务和产品咨询** 可联系产品顾问：\n\n<img width=\"160\" src=\"https://cdn.link-ai.tech/consultant-s.jpg\">\n\n<br>\n\n# 🏷 更新日志\n>**2024.10.31：** [1.7.3版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.3) 程序稳定性提升、数据库功能、Claude模型优化、linkai插件优化、离线通知\n\n>**2024.09.26：** [1.7.2版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.2)  和 [1.7.1版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.1) 文心，讯飞等模型优化、o1 模型、快速安装和管理脚本\n\n>**2024.08.02：** [1.7.0版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.7.0) 新增 讯飞4.0 模型、知识库引用来源展示、相关插件优化\n\n>**2024.07.19：** [1.6.9版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.9) 新增 gpt-4o-mini 模型、阿里语音识别、企微应用渠道路由优化\n\n>**2024.07.05：** [1.6.8版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.8) 和 [1.6.7版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.7)，Claude3.5, Gemini 1.5 Pro, MiniMax模型、工作流图片输入、模型列表完善\n\n>**2024.06.04：** [1.6.6版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.6) 和 [1.6.5版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.5)，gpt-4o模型、钉钉流式卡片、讯飞语音识别/合成\n\n>**2024.04.26：** [1.6.0版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.6.0)，新增 Kimi 接入、gpt-4-turbo版本升级、文件总结和语音识别问题修复\n\n>**2024.03.26：** [1.5.8版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.8) 和 [1.5.7版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.7)，新增 GLM-4、Claude-3 模型，edge-tts 语音支持\n\n>**2024.01.26：** [1.5.6版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.6) 和 [1.5.5版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.5)，钉钉接入，tool插件升级，4-turbo模型更新\n\n>**2023.11.11：** [1.5.3版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.3) 和 [1.5.4版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.4)，新增通义千问模型、Google Gemini\n\n>**2023.11.10：** [1.5.2版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.2)，新增飞书通道、图像识别对话、黑名单配置\n\n>**2023.11.10：** [1.5.0版本](https://github.com/zhayujie/chatgpt-on-wechat/releases/tag/1.5.0)，新增 `gpt-4-turbo`, `dall-e-3`, `tts` 模型接入，完善图像理解&生成、语音识别&生成的多模态能力\n\n>**2023.10.16：** 支持通过意图识别使用LinkAI联网搜索、数学计算、网页访问等插件，参考[插件文档](https://docs.link-ai.tech/platform/plugins)\n\n>**2023.09.26：** 插件增加 文件/文章链接 一键总结和对话的功能，使用参考：[插件说明](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai#3%E6%96%87%E6%A1%A3%E6%80%BB%E7%BB%93%E5%AF%B9%E8%AF%9D%E5%8A%9F%E8%83%BD)\n\n>**2023.08.08：** 接入百度文心一言模型，通过 [插件](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins/linkai) 支持 Midjourney 绘图\n\n>**2023.06.12：** 接入 [LinkAI](https://link-ai.tech/console) 平台，可在线创建领域知识库，打造专属客服机器人。使用参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n更早更新日志查看: [归档日志](/docs/version/old-version.md)\n\n<br>\n\n# 🚀 快速开始\n\n- 快速开始详细文档：[项目搭建文档](https://docs.link-ai.tech/cow/quick-start)\n\n- 快速安装脚本，详细使用指导：[一键安装启动脚本](https://github.com/zhayujie/chatgpt-on-wechat/wiki/%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC)\n```bash\nbash <(curl -sS https://cdn.link-ai.tech/code/cow/install.sh)\n```\n- 项目管理脚本，详细使用指导：[项目管理脚本](https://github.com/zhayujie/chatgpt-on-wechat/wiki/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86%E8%84%9A%E6%9C%AC)\n## 一、准备\n\n### 1. 账号注册\n\n项目默认使用OpenAI接口，需前往 [OpenAI注册页面](https://beta.openai.com/signup) 创建账号，创建完账号则前往 [API管理页面](https://beta.openai.com/account/api-keys) 创建一个 API Key 并保存下来，后面需要在项目中配置这个key。接口需要海外网络访问及绑定信用卡支付。\n\n> 默认对话模型是 openai 的 gpt-3.5-turbo，计费方式是约每 1000tokens (约750个英文单词 或 500汉字，包含请求和回复) 消耗 $0.002，图片生成是Dell E模型，每张消耗 $0.016。\n\n项目同时也支持使用 LinkAI 接口，无需代理，可使用 Kimi、文心、讯飞、GPT-3.5、GPT-4o 等模型，支持 定制化知识库、联网搜索、MJ绘图、文档总结、工作流等能力。修改配置即可一键使用，参考 [接入文档](https://link-ai.tech/platform/link-app/wechat)。\n\n### 2.运行环境\n\n支持 Linux、MacOS、Windows 系统（可在Linux服务器上长期运行)，同时需安装 `Python`。\n> 建议Python版本在 3.7.1~3.9.X 之间，推荐3.8版本，3.10及以上版本在 MacOS 可用，其他系统上不确定能否正常运行。\n\n> 注意：Docker 或 Railway 部署无需安装python环境和下载源码，可直接快进到下一节。\n\n**(1) 克隆项目代码：**\n\n```bash\ngit clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/\n```\n\n注: 如遇到网络问题可选择国内镜像 https://gitee.com/zhayujie/chatgpt-on-wechat\n\n**(2) 安装核心依赖 (必选)：**\n> 能够使用`itchat`创建机器人，并具有文字交流功能所需的最小依赖集合。\n```bash\npip3 install -r requirements.txt\n```\n\n**(3) 拓展依赖 (可选，建议安装)：**\n\n```bash\npip3 install -r requirements-optional.txt\n```\n> 如果某项依赖安装失败可注释掉对应的行再继续\n\n## 二、配置\n\n配置文件的模板在根目录的`config-template.json`中，需复制该模板创建最终生效的 `config.json` 文件：\n\n```bash\n  cp config-template.json config.json\n```\n\n然后在`config.json`中填入配置，以下是对默认配置的说明，可根据需要进行自定义修改（注意实际使用时请去掉注释，保证JSON格式的完整）：\n\n```bash\n# config.json文件内容示例\n{\n  \"model\": \"gpt-3.5-turbo\",                                   # 模型名称, 支持 gpt-3.5-turbo, gpt-4, gpt-4-turbo, wenxin, xunfei, glm-4, claude-3-haiku, moonshot\n  \"open_ai_api_key\": \"YOUR API KEY\",                          # 如果使用openAI模型则填入上面创建的 OpenAI API KEY\n  \"open_ai_api_base\": \"https://api.openai.com/v1\",            # OpenAI接口代理地址\n  \"proxy\": \"\",                                                # 代理客户端的ip和端口，国内环境开启代理的需要填写该项，如 \"127.0.0.1:7890\"\n  \"single_chat_prefix\": [\"bot\", \"@bot\"],                      # 私聊时文本需要包含该前缀才能触发机器人回复\n  \"single_chat_reply_prefix\": \"[bot] \",                       # 私聊时自动回复的前缀，用于区分真人\n  \"group_chat_prefix\": [\"@bot\"],                              # 群聊时包含该前缀则会触发机器人回复\n  \"group_name_white_list\": [\"ChatGPT测试群\", \"ChatGPT测试群2\"], # 开启自动回复的群名称列表\n  \"group_chat_in_one_session\": [\"ChatGPT测试群\"],              # 支持会话上下文共享的群名称  \n  \"image_create_prefix\": [\"画\", \"看\", \"找\"],                   # 开启图片回复的前缀\n  \"conversation_max_tokens\": 1000,                            # 支持上下文记忆的最多字符数\n  \"speech_recognition\": false,                                # 是否开启语音识别\n  \"group_speech_recognition\": false,                          # 是否开启群组语音识别\n  \"voice_reply_voice\": false,                                 # 是否使用语音回复语音\n  \"character_desc\": \"你是基于大语言模型的AI智能助手，旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。\",  # 人格描述\n  # 订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复，可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n  \"subscribe_msg\": \"感谢您的关注！\\n这里是ChatGPT，可以自由对话。\\n支持语音对话。\\n支持图片输出，画字开头的消息将按要求创作图片。\\n支持角色扮演和文字冒险等丰富插件。\\n输入{trigger_prefix}#help 查看详细指令。\",\n  \"use_linkai\": false,                                        # 是否使用LinkAI接口，默认关闭，开启后可国内访问，使用知识库和MJ\n  \"linkai_api_key\": \"\",                                       # LinkAI Api Key\n  \"linkai_app_code\": \"\"                                       # LinkAI 应用或工作流code\n}\n```\n**配置说明：**\n\n**1.个人聊天**\n\n+ 个人聊天中，需要以 \"bot\"或\"@bot\" 为开头的内容触发机器人，对应配置项 `single_chat_prefix` (如果不需要以前缀触发可以填写  `\"single_chat_prefix\": [\"\"]`)\n+ 机器人回复的内容会以 \"[bot] \" 作为前缀， 以区分真人，对应的配置项为 `single_chat_reply_prefix` (如果不需要前缀可以填写 `\"single_chat_reply_prefix\": \"\"`)\n\n**2.群组聊天**\n\n+ 群组聊天中，群名称需配置在 `group_name_white_list ` 中才能开启群聊自动回复。如果想对所有群聊生效，可以直接填写 `\"group_name_white_list\": [\"ALL_GROUP\"]`\n+ 默认只要被人 @ 就会触发机器人自动回复；另外群聊天中只要检测到以 \"@bot\" 开头的内容，同样会自动回复（方便自己触发），这对应配置项 `group_chat_prefix`\n+ 可选配置: `group_name_keyword_white_list`配置项支持模糊匹配群名称，`group_chat_keyword`配置项则支持模糊匹配群消息内容，用法与上述两个配置项相同。（Contributed by [evolay](https://github.com/evolay))\n+ `group_chat_in_one_session`：使群聊共享一个会话上下文，配置 `[\"ALL_GROUP\"]` 则作用于所有群聊\n\n**3.语音识别**\n\n+ 添加 `\"speech_recognition\": true` 将开启语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，该参数仅支持私聊 (注意由于语音消息无法匹配前缀，一旦开启将对所有语音自动回复，支持语音触发画图)；\n+ 添加 `\"group_speech_recognition\": true` 将开启群组语音识别，默认使用openai的whisper模型识别为文字，同时以文字回复，参数仅支持群聊 (会匹配group_chat_prefix和group_chat_keyword, 支持语音触发画图)；\n+ 添加 `\"voice_reply_voice\": true` 将开启语音回复语音（同时作用于私聊和群聊）\n\n**4.其他配置**\n\n+ `model`: 模型名称，目前支持 `gpt-3.5-turbo`, `gpt-4o-mini`, `gpt-4o`, `gpt-4`, `wenxin` , `claude` , `gemini`, `glm-4`,  `xunfei`, `moonshot`等，全部模型名称参考[common/const.py](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/common/const.py)文件\n+ `temperature`,`frequency_penalty`,`presence_penalty`: Chat API接口参数，详情参考[OpenAI官方文档。](https://platform.openai.com/docs/api-reference/chat)\n+ `proxy`：由于目前 `openai` 接口国内无法访问，需配置代理客户端的地址，详情参考  [#351](https://github.com/zhayujie/chatgpt-on-wechat/issues/351)\n+ 对于图像生成，在满足个人或群组触发条件外，还需要额外的关键词前缀来触发，对应配置 `image_create_prefix `\n+ 关于OpenAI对话及图片接口的参数配置（内容自由度、回复字数限制、图片大小等），可以参考 [对话接口](https://beta.openai.com/docs/api-reference/completions) 和 [图像接口](https://beta.openai.com/docs/api-reference/completions)  文档，在[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中检查哪些参数在本项目中是可配置的。\n+ `conversation_max_tokens`：表示能够记忆的上下文最大字数（一问一答为一组对话，如果累积的对话字数超出限制，就会优先移除最早的一组对话）\n+ `rate_limit_chatgpt`，`rate_limit_dalle`：每分钟最高问答速率、画图速率，超速后排队按序处理。\n+ `clear_memory_commands`: 对话内指令，主动清空前文记忆，字符串数组可自定义指令别名。\n+ `hot_reload`: 程序退出后，暂存等于状态，默认关闭。\n+ `character_desc` 配置中保存着你对机器人说的一段话，他会记住这段话并作为他的设定，你可以为他定制任何人格      (关于会话上下文的更多内容参考该 [issue](https://github.com/zhayujie/chatgpt-on-wechat/issues/43))\n+ `subscribe_msg`：订阅消息，公众号和企业微信channel中请填写，当被订阅时会自动回复， 可使用特殊占位符。目前支持的占位符有{trigger_prefix}，在程序中它会自动替换成bot的触发词。\n\n**5.LinkAI配置 (可选)**\n\n+ `use_linkai`: 是否使用LinkAI接口，开启后可国内访问，使用知识库和 `Midjourney` 绘画, 参考 [文档](https://link-ai.tech/platform/link-app/wechat)\n+ `linkai_api_key`: LinkAI Api Key，可在 [控制台](https://link-ai.tech/console/interface) 创建\n+ `linkai_app_code`: LinkAI 应用或工作流的code，选填\n\n**本说明文档可能会未及时更新，当前所有可选的配置项均在该[`config.py`](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/config.py)中列出。**\n\n## 三、运行\n\n### 1.本地运行\n\n如果是开发机 **本地运行**，直接在项目根目录下执行：\n\n```bash\npython3 app.py                                    # windows环境下该命令通常为 python app.py\n```\n\n终端输出二维码后，进行扫码登录，当输出 \"Start auto replying\" 时表示自动回复程序已经成功运行了（注意：用于登录的账号需要在支付处已完成实名认证）。扫码登录后你的账号就成为机器人了，可以在手机端通过配置的关键词触发自动回复 (任意好友发送消息给你，或是自己发消息给好友)，参考[#142](https://github.com/zhayujie/chatgpt-on-wechat/issues/142)。\n\n### 2.服务器部署\n\n使用nohup命令在后台运行程序：\n\n```bash\nnohup python3 app.py & tail -f nohup.out          # 在后台运行程序并通过日志输出二维码\n```\n扫码登录后程序即可运行于服务器后台，此时可通过 `ctrl+c` 关闭日志，不会影响后台程序的运行。使用 `ps -ef | grep app.py | grep -v grep` 命令可查看运行于后台的进程，如果想要重新启动程序可以先 `kill` 掉对应的进程。日志关闭后如果想要再次打开只需输入 `tail -f nohup.out`。此外，`scripts` 目录下有一键运行、关闭程序的脚本供使用。\n\n> **多账号支持：** 将项目复制多份，分别启动程序，用不同账号扫码登录即可实现同时运行。\n\n> **特殊指令：** 用户向机器人发送 **#reset** 即可清空该用户的上下文记忆。\n\n\n### 3.Docker部署\n\n> 使用docker部署无需下载源码和安装依赖，只需要获取 docker-compose.yml 配置文件并启动容器即可。\n\n> 前提是需要安装好 `docker` 及 `docker-compose`，安装成功的表现是执行 `docker -v` 和 `docker-compose version` (或 docker compose version) 可以查看到版本号，可前往 [docker官网](https://docs.docker.com/engine/install/) 进行下载。\n\n**(1) 下载 docker-compose.yml 文件**\n\n```bash\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n```\n\n下载完成后打开 `docker-compose.yml` 修改所需配置，如 `OPEN_AI_API_KEY` 和 `GROUP_NAME_WHITE_LIST` 等。\n\n**(2) 启动容器**\n\n在 `docker-compose.yml` 所在目录下执行以下命令启动容器：\n\n```bash\nsudo docker compose up -d\n```\n\n运行 `sudo docker ps` 能查看到 NAMES 为 chatgpt-on-wechat 的容器即表示运行成功。\n\n注意：\n\n - 如果 `docker-compose` 是 1.X 版本 则需要执行 `sudo  docker-compose up -d` 来启动容器\n - 该命令会自动去 [docker hub](https://hub.docker.com/r/zhayujie/chatgpt-on-wechat) 拉取 latest 版本的镜像，latest 镜像会在每次项目 release 新的版本时生成\n\n最后运行以下命令可查看容器运行日志，扫描日志中的二维码即可完成登录：\n\n```bash\nsudo docker logs -f chatgpt-on-wechat\n```\n\n**(3) 插件使用**\n\n如果需要在docker容器中修改插件配置，可通过挂载的方式完成，将 [插件配置文件](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/plugins/config.json.template)\n重命名为 `config.json`，放置于 `docker-compose.yml` 相同目录下，并在 `docker-compose.yml` 中的 `chatgpt-on-wechat` 部分下添加 `volumes` 映射:\n\n```\nvolumes:\n  - ./config.json:/app/plugins/config.json\n```\n**注**：采用docker方式部署的详细教程可以参考：[docker部署CoW项目](https://www.wangpc.cc/ai/docker-deploy-cow/)\n### 4. Railway部署\n\n> Railway 每月提供5刀和最多500小时的免费额度。 (07.11更新: 目前大部分账号已无法免费部署)\n\n1. 进入 [Railway](https://railway.app/template/qApznZ?referralCode=RC3znh)\n2. 点击 `Deploy Now` 按钮。\n3. 设置环境变量来重载程序运行的参数，例如`open_ai_api_key`, `character_desc`。\n\n**一键部署:**\n  \n  [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/qApznZ?referralCode=RC3znh)\n\n<br>\n\n# 🔎 常见问题\n\nFAQs： <https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs>\n\n或直接在线咨询 [项目小助手](https://link-ai.tech/app/Kv2fXJcH)  (语料持续完善中，回复仅供参考)\n\n# 🛠️ 开发\n\n欢迎接入更多应用，参考 [Terminal代码](https://github.com/zhayujie/chatgpt-on-wechat/blob/master/channel/terminal/terminal_channel.py) 实现接收和发送消息逻辑即可接入。 同时欢迎增加新的插件，参考 [插件说明文档](https://github.com/zhayujie/chatgpt-on-wechat/tree/master/plugins)。\n\n# ✉ 联系\n\n欢迎提交PR、Issues，以及Star支持一下。程序运行遇到问题可以查看 [常见问题列表](https://github.com/zhayujie/chatgpt-on-wechat/wiki/FAQs) ，其次前往 [Issues](https://github.com/zhayujie/chatgpt-on-wechat/issues) 中搜索。个人开发者可加入开源交流群参与更多讨论，企业用户可联系[产品顾问](https://img-1317903499.cos.ap-guangzhou.myqcloud.com/docs/product-manager-qrcode.jpg)咨询。\n\n# 🌟 贡献者\n\n![cow contributors](https://contrib.rocks/image?repo=zhayujie/chatgpt-on-wechat&max=1000)\n"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 1.7392578125,
          "content": "# encoding:utf-8\n\nimport os\nimport signal\nimport sys\nimport time\n\nfrom channel import channel_factory\nfrom common import const\nfrom config import load_config\nfrom plugins import *\nimport threading\n\n\ndef sigterm_handler_wrap(_signo):\n    old_handler = signal.getsignal(_signo)\n\n    def func(_signo, _stack_frame):\n        logger.info(\"signal {} received, exiting...\".format(_signo))\n        conf().save_user_datas()\n        if callable(old_handler):  #  check old_handler\n            return old_handler(_signo, _stack_frame)\n        sys.exit(0)\n\n    signal.signal(_signo, func)\n\n\ndef start_channel(channel_name: str):\n    channel = channel_factory.create_channel(channel_name)\n    if channel_name in [\"wx\", \"wxy\", \"terminal\", \"wechatmp\",\"web\", \"wechatmp_service\", \"wechatcom_app\", \"wework\",\n                        const.FEISHU, const.DINGTALK]:\n        PluginManager().load_plugins()\n\n    if conf().get(\"use_linkai\"):\n        try:\n            from common import linkai_client\n            threading.Thread(target=linkai_client.start, args=(channel,)).start()\n        except Exception as e:\n            pass\n    channel.startup()\n\n\ndef run():\n    try:\n        # load config\n        load_config()\n        # ctrl + c\n        sigterm_handler_wrap(signal.SIGINT)\n        # kill signal\n        sigterm_handler_wrap(signal.SIGTERM)\n\n        # create channel\n        channel_name = conf().get(\"channel_type\", \"wx\")\n\n        if \"--cmd\" in sys.argv:\n            channel_name = \"terminal\"\n\n        if channel_name == \"wxy\":\n            os.environ[\"WECHATY_LOG\"] = \"warn\"\n\n        start_channel(channel_name)\n\n        while True:\n            time.sleep(1)\n    except Exception as e:\n        logger.error(\"App startup failed!\")\n        logger.exception(e)\n\n\nif __name__ == \"__main__\":\n    run()\n"
        },
        {
          "name": "bot",
          "type": "tree",
          "content": null
        },
        {
          "name": "bridge",
          "type": "tree",
          "content": null
        },
        {
          "name": "channel",
          "type": "tree",
          "content": null
        },
        {
          "name": "common",
          "type": "tree",
          "content": null
        },
        {
          "name": "config-template.json",
          "type": "blob",
          "size": 1.2119140625,
          "content": "{\n  \"channel_type\": \"wx\",\n  \"model\": \"\",\n  \"open_ai_api_key\": \"YOUR API KEY\",\n  \"claude_api_key\": \"YOUR API KEY\",\n  \"text_to_image\": \"dall-e-2\",\n  \"voice_to_text\": \"openai\",\n  \"text_to_voice\": \"openai\",\n  \"proxy\": \"\",\n  \"hot_reload\": false,\n  \"single_chat_prefix\": [\n    \"bot\",\n    \"@bot\"\n  ],\n  \"single_chat_reply_prefix\": \"[bot] \",\n  \"group_chat_prefix\": [\n    \"@bot\"\n  ],\n  \"group_name_white_list\": [\n    \"ChatGPT测试群\",\n    \"ChatGPT测试群2\"\n  ],\n  \"image_create_prefix\": [\n    \"画\"\n  ],\n  \"speech_recognition\": true,\n  \"group_speech_recognition\": false,\n  \"voice_reply_voice\": false,\n  \"conversation_max_tokens\": 2500,\n  \"expires_in_seconds\": 3600,\n  \"character_desc\": \"你是基于大语言模型的AI智能助手，旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。\",\n  \"temperature\": 0.7,\n  \"subscribe_msg\": \"感谢您的关注！\\n这里是AI智能助手，可以自由对话。\\n支持语音对话。\\n支持图片输入。\\n支持图片输出，画字开头的消息将按要求创作图片。\\n支持tool、角色扮演和文字冒险等丰富的插件。\\n输入{trigger_prefix}#help 查看详细指令。\",\n  \"use_linkai\": false,\n  \"linkai_api_key\": \"\",\n  \"linkai_app_code\": \"\"\n}\n"
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 16.2626953125,
          "content": "# encoding:utf-8\n\nimport json\nimport logging\nimport os\nimport pickle\nimport copy\n\nfrom common.log import logger\n\n# 将所有可用的配置项写在字典里, 请使用小写字母\n# 此处的配置值无实际意义，程序不会读取此处的配置，仅用于提示格式，请将配置加入到config.json中\navailable_setting = {\n    # openai api配置\n    \"open_ai_api_key\": \"\",  # openai api key\n    # openai apibase，当use_azure_chatgpt为true时，需要设置对应的api base\n    \"open_ai_api_base\": \"https://api.openai.com/v1\",\n    \"proxy\": \"\",  # openai使用的代理\n    # chatgpt模型， 当use_azure_chatgpt为true时，其名称为Azure上model deployment名称\n    \"model\": \"gpt-3.5-turbo\",  # 可选择: gpt-4o, pt-4o-mini, gpt-4-turbo, claude-3-sonnet, wenxin, moonshot, qwen-turbo, xunfei, glm-4, minimax, gemini等模型，全部可选模型详见common/const.py文件\n    \"bot_type\": \"\",  # 可选配置，使用兼容openai格式的三方服务时候，需填\"chatGPT\"。bot具体名称详见common/const.py文件列出的bot_type，如不填根据model名称判断，\n    \"use_azure_chatgpt\": False,  # 是否使用azure的chatgpt\n    \"azure_deployment_id\": \"\",  # azure 模型部署名称\n    \"azure_api_version\": \"\",  # azure api版本\n    # Bot触发配置\n    \"single_chat_prefix\": [\"bot\", \"@bot\"],  # 私聊时文本需要包含该前缀才能触发机器人回复\n    \"single_chat_reply_prefix\": \"[bot] \",  # 私聊时自动回复的前缀，用于区分真人\n    \"single_chat_reply_suffix\": \"\",  # 私聊时自动回复的后缀，\\n 可以换行\n    \"group_chat_prefix\": [\"@bot\"],  # 群聊时包含该前缀则会触发机器人回复\n    \"no_need_at\": False,  # 群聊回复时是否不需要艾特\n    \"group_chat_reply_prefix\": \"\",  # 群聊时自动回复的前缀\n    \"group_chat_reply_suffix\": \"\",  # 群聊时自动回复的后缀，\\n 可以换行\n    \"group_chat_keyword\": [],  # 群聊时包含该关键词则会触发机器人回复\n    \"group_at_off\": False,  # 是否关闭群聊时@bot的触发\n    \"group_name_white_list\": [\"ChatGPT测试群\", \"ChatGPT测试群2\"],  # 开启自动回复的群名称列表\n    \"group_name_keyword_white_list\": [],  # 开启自动回复的群名称关键词列表\n    \"group_chat_in_one_session\": [\"ChatGPT测试群\"],  # 支持会话上下文共享的群名称\n    \"nick_name_black_list\": [],  # 用户昵称黑名单\n    \"group_welcome_msg\": \"\",  # 配置新人进群固定欢迎语，不配置则使用随机风格欢迎\n    \"trigger_by_self\": False,  # 是否允许机器人触发\n    \"text_to_image\": \"dall-e-2\",  # 图片生成模型，可选 dall-e-2, dall-e-3\n    # Azure OpenAI dall-e-3 配置\n    \"dalle3_image_style\": \"vivid\", # 图片生成dalle3的风格，可选有 vivid, natural\n    \"dalle3_image_quality\": \"hd\", # 图片生成dalle3的质量，可选有 standard, hd\n    # Azure OpenAI DALL-E API 配置, 当use_azure_chatgpt为true时,用于将文字回复的资源和Dall-E的资源分开.\n    \"azure_openai_dalle_api_base\": \"\", # [可选] azure openai 用于回复图片的资源 endpoint，默认使用 open_ai_api_base\n    \"azure_openai_dalle_api_key\": \"\", # [可选] azure openai 用于回复图片的资源 key，默认使用 open_ai_api_key\n    \"azure_openai_dalle_deployment_id\":\"\", # [可选] azure openai 用于回复图片的资源 deployment id，默认使用 text_to_image\n    \"image_proxy\": True,  # 是否需要图片代理，国内访问LinkAI时需要\n    \"image_create_prefix\": [\"画\", \"看\", \"找\"],  # 开启图片回复的前缀\n    \"concurrency_in_session\": 1,  # 同一会话最多有多少条消息在处理中，大于1可能乱序\n    \"image_create_size\": \"256x256\",  # 图片大小,可选有 256x256, 512x512, 1024x1024 (dall-e-3默认为1024x1024)\n    \"group_chat_exit_group\": False,\n    # chatgpt会话参数\n    \"expires_in_seconds\": 3600,  # 无操作会话的过期时间\n    # 人格描述\n    \"character_desc\": \"你是ChatGPT, 一个由OpenAI训练的大型语言模型, 你旨在回答并解决人们的任何问题，并且可以使用多种语言与人交流。\",\n    \"conversation_max_tokens\": 1000,  # 支持上下文记忆的最多字符数\n    # chatgpt限流配置\n    \"rate_limit_chatgpt\": 20,  # chatgpt的调用频率限制\n    \"rate_limit_dalle\": 50,  # openai dalle的调用频率限制\n    # chatgpt api参数 参考https://platform.openai.com/docs/api-reference/chat/create\n    \"temperature\": 0.9,\n    \"top_p\": 1,\n    \"frequency_penalty\": 0,\n    \"presence_penalty\": 0,\n    \"request_timeout\": 180,  # chatgpt请求超时时间，openai接口默认设置为600，对于难问题一般需要较长时间\n    \"timeout\": 120,  # chatgpt重试超时时间，在这个时间内，将会自动重试\n    # Baidu 文心一言参数\n    \"baidu_wenxin_model\": \"eb-instant\",  # 默认使用ERNIE-Bot-turbo模型\n    \"baidu_wenxin_api_key\": \"\",  # Baidu api key\n    \"baidu_wenxin_secret_key\": \"\",  # Baidu secret key\n    \"baidu_wenxin_prompt_enabled\": False,  # Enable prompt if you are using ernie character model\n    # 讯飞星火API\n    \"xunfei_app_id\": \"\",  # 讯飞应用ID\n    \"xunfei_api_key\": \"\",  # 讯飞 API key\n    \"xunfei_api_secret\": \"\",  # 讯飞 API secret\n    \"xunfei_domain\": \"\",  # 讯飞模型对应的domain参数，Spark4.0 Ultra为 4.0Ultra，其他模型详见: https://www.xfyun.cn/doc/spark/Web.html\n    \"xunfei_spark_url\": \"\",  # 讯飞模型对应的请求地址，Spark4.0 Ultra为 wss://spark-api.xf-yun.com/v4.0/chat，其他模型参考详见: https://www.xfyun.cn/doc/spark/Web.html\n    # claude 配置\n    \"claude_api_cookie\": \"\",\n    \"claude_uuid\": \"\",\n    # claude api key\n    \"claude_api_key\": \"\",\n    # 通义千问API, 获取方式查看文档 https://help.aliyun.com/document_detail/2587494.html\n    \"qwen_access_key_id\": \"\",\n    \"qwen_access_key_secret\": \"\",\n    \"qwen_agent_key\": \"\",\n    \"qwen_app_id\": \"\",\n    \"qwen_node_id\": \"\",  # 流程编排模型用到的id，如果没有用到qwen_node_id，请务必保持为空字符串\n    # 阿里灵积(通义新版sdk)模型api key\n    \"dashscope_api_key\": \"\",\n    # Google Gemini Api Key\n    \"gemini_api_key\": \"\",\n    # wework的通用配置\n    \"wework_smart\": True,  # 配置wework是否使用已登录的企业微信，False为多开\n    # 语音设置\n    \"speech_recognition\": True,  # 是否开启语音识别\n    \"group_speech_recognition\": False,  # 是否开启群组语音识别\n    \"voice_reply_voice\": False,  # 是否使用语音回复语音，需要设置对应语音合成引擎的api key\n    \"always_reply_voice\": False,  # 是否一直使用语音回复\n    \"voice_to_text\": \"openai\",  # 语音识别引擎，支持openai,baidu,google,azure,xunfei,ali\n    \"text_to_voice\": \"openai\",  # 语音合成引擎，支持openai,baidu,google,azure,xunfei,ali,pytts(offline),elevenlabs,edge(online)\n    \"text_to_voice_model\": \"tts-1\",\n    \"tts_voice_id\": \"alloy\",\n    # baidu 语音api配置， 使用百度语音识别和语音合成时需要\n    \"baidu_app_id\": \"\",\n    \"baidu_api_key\": \"\",\n    \"baidu_secret_key\": \"\",\n    # 1536普通话(支持简单的英文识别) 1737英语 1637粤语 1837四川话 1936普通话远场\n    \"baidu_dev_pid\": 1536,\n    # azure 语音api配置， 使用azure语音识别和语音合成时需要\n    \"azure_voice_api_key\": \"\",\n    \"azure_voice_region\": \"japaneast\",\n    # elevenlabs 语音api配置\n    \"xi_api_key\": \"\",  # 获取ap的方法可以参考https://docs.elevenlabs.io/api-reference/quick-start/authentication\n    \"xi_voice_id\": \"\",  # ElevenLabs提供了9种英式、美式等英语发音id，分别是“Adam/Antoni/Arnold/Bella/Domi/Elli/Josh/Rachel/Sam”\n    # 服务时间限制，目前支持itchat\n    \"chat_time_module\": False,  # 是否开启服务时间限制\n    \"chat_start_time\": \"00:00\",  # 服务开始时间\n    \"chat_stop_time\": \"24:00\",  # 服务结束时间\n    # 翻译api\n    \"translate\": \"baidu\",  # 翻译api，支持baidu\n    # baidu翻译api的配置\n    \"baidu_translate_app_id\": \"\",  # 百度翻译api的appid\n    \"baidu_translate_app_key\": \"\",  # 百度翻译api的秘钥\n    # itchat的配置\n    \"hot_reload\": False,  # 是否开启热重载\n    # wechaty的配置\n    \"wechaty_puppet_service_token\": \"\",  # wechaty的token\n    # wechatmp的配置\n    \"wechatmp_token\": \"\",  # 微信公众平台的Token\n    \"wechatmp_port\": 8080,  # 微信公众平台的端口,需要端口转发到80或443\n    \"wechatmp_app_id\": \"\",  # 微信公众平台的appID\n    \"wechatmp_app_secret\": \"\",  # 微信公众平台的appsecret\n    \"wechatmp_aes_key\": \"\",  # 微信公众平台的EncodingAESKey，加密模式需要\n    # wechatcom的通用配置\n    \"wechatcom_corp_id\": \"\",  # 企业微信公司的corpID\n    # wechatcomapp的配置\n    \"wechatcomapp_token\": \"\",  # 企业微信app的token\n    \"wechatcomapp_port\": 9898,  # 企业微信app的服务端口,不需要端口转发\n    \"wechatcomapp_secret\": \"\",  # 企业微信app的secret\n    \"wechatcomapp_agent_id\": \"\",  # 企业微信app的agent_id\n    \"wechatcomapp_aes_key\": \"\",  # 企业微信app的aes_key\n    # 飞书配置\n    \"feishu_port\": 80,  # 飞书bot监听端口\n    \"feishu_app_id\": \"\",  # 飞书机器人应用APP Id\n    \"feishu_app_secret\": \"\",  # 飞书机器人APP secret\n    \"feishu_token\": \"\",  # 飞书 verification token\n    \"feishu_bot_name\": \"\",  # 飞书机器人的名字\n    # 钉钉配置\n    \"dingtalk_client_id\": \"\",  # 钉钉机器人Client ID \n    \"dingtalk_client_secret\": \"\",  # 钉钉机器人Client Secret\n    \"dingtalk_card_enabled\": False,\n    \n    # chatgpt指令自定义触发词\n    \"clear_memory_commands\": [\"#清除记忆\"],  # 重置会话指令，必须以#开头\n    # channel配置\n    \"channel_type\": \"\",  # 通道类型，支持：{wx,wxy,terminal,wechatmp,wechatmp_service,wechatcom_app,dingtalk}\n    \"subscribe_msg\": \"\",  # 订阅消息, 支持: wechatmp, wechatmp_service, wechatcom_app\n    \"debug\": False,  # 是否开启debug模式，开启后会打印更多日志\n    \"appdata_dir\": \"\",  # 数据目录\n    # 插件配置\n    \"plugin_trigger_prefix\": \"$\",  # 规范插件提供聊天相关指令的前缀，建议不要和管理员指令前缀\"#\"冲突\n    # 是否使用全局插件配置\n    \"use_global_plugin_config\": False,\n    \"max_media_send_count\": 3,  # 单次最大发送媒体资源的个数\n    \"media_send_interval\": 1,  # 发送图片的事件间隔，单位秒\n    # 智谱AI 平台配置\n    \"zhipu_ai_api_key\": \"\",\n    \"zhipu_ai_api_base\": \"https://open.bigmodel.cn/api/paas/v4\",\n    \"moonshot_api_key\": \"\",\n    \"moonshot_base_url\": \"https://api.moonshot.cn/v1/chat/completions\",\n    # LinkAI平台配置\n    \"use_linkai\": False,\n    \"linkai_api_key\": \"\",\n    \"linkai_app_code\": \"\",\n    \"linkai_api_base\": \"https://api.link-ai.tech\",  # linkAI服务地址\n    \"Minimax_api_key\": \"\",\n    \"Minimax_group_id\": \"\",\n    \"Minimax_base_url\": \"\",\n    \"web_port\": 9899,\n}\n\n\nclass Config(dict):\n    def __init__(self, d=None):\n        super().__init__()\n        if d is None:\n            d = {}\n        for k, v in d.items():\n            self[k] = v\n        # user_datas: 用户数据，key为用户名，value为用户数据，也是dict\n        self.user_datas = {}\n\n    def __getitem__(self, key):\n        if key not in available_setting:\n            raise Exception(\"key {} not in available_setting\".format(key))\n        return super().__getitem__(key)\n\n    def __setitem__(self, key, value):\n        if key not in available_setting:\n            raise Exception(\"key {} not in available_setting\".format(key))\n        return super().__setitem__(key, value)\n\n    def get(self, key, default=None):\n        try:\n            return self[key]\n        except KeyError as e:\n            return default\n        except Exception as e:\n            raise e\n\n    # Make sure to return a dictionary to ensure atomic\n    def get_user_data(self, user) -> dict:\n        if self.user_datas.get(user) is None:\n            self.user_datas[user] = {}\n        return self.user_datas[user]\n\n    def load_user_datas(self):\n        try:\n            with open(os.path.join(get_appdata_dir(), \"user_datas.pkl\"), \"rb\") as f:\n                self.user_datas = pickle.load(f)\n                logger.info(\"[Config] User datas loaded.\")\n        except FileNotFoundError as e:\n            logger.info(\"[Config] User datas file not found, ignore.\")\n        except Exception as e:\n            logger.info(\"[Config] User datas error: {}\".format(e))\n            self.user_datas = {}\n\n    def save_user_datas(self):\n        try:\n            with open(os.path.join(get_appdata_dir(), \"user_datas.pkl\"), \"wb\") as f:\n                pickle.dump(self.user_datas, f)\n                logger.info(\"[Config] User datas saved.\")\n        except Exception as e:\n            logger.info(\"[Config] User datas error: {}\".format(e))\n\n\nconfig = Config()\n\n\ndef drag_sensitive(config):\n    try:\n        if isinstance(config, str):\n            conf_dict: dict = json.loads(config)\n            conf_dict_copy = copy.deepcopy(conf_dict)\n            for key in conf_dict_copy:\n                if \"key\" in key or \"secret\" in key:\n                    if isinstance(conf_dict_copy[key], str):\n                        conf_dict_copy[key] = conf_dict_copy[key][0:3] + \"*\" * 5 + conf_dict_copy[key][-3:]\n            return json.dumps(conf_dict_copy, indent=4)\n\n        elif isinstance(config, dict):\n            config_copy = copy.deepcopy(config)\n            for key in config:\n                if \"key\" in key or \"secret\" in key:\n                    if isinstance(config_copy[key], str):\n                        config_copy[key] = config_copy[key][0:3] + \"*\" * 5 + config_copy[key][-3:]\n            return config_copy\n    except Exception as e:\n        logger.exception(e)\n        return config\n    return config\n\n\ndef load_config():\n    global config\n    config_path = \"./config.json\"\n    if not os.path.exists(config_path):\n        logger.info(\"配置文件不存在，将使用config-template.json模板\")\n        config_path = \"./config-template.json\"\n\n    config_str = read_file(config_path)\n    logger.debug(\"[INIT] config str: {}\".format(drag_sensitive(config_str)))\n\n    # 将json字符串反序列化为dict类型\n    config = Config(json.loads(config_str))\n\n    # override config with environment variables.\n    # Some online deployment platforms (e.g. Railway) deploy project from github directly. So you shouldn't put your secrets like api key in a config file, instead use environment variables to override the default config.\n    for name, value in os.environ.items():\n        name = name.lower()\n        if name in available_setting:\n            logger.info(\"[INIT] override config by environ args: {}={}\".format(name, value))\n            try:\n                config[name] = eval(value)\n            except:\n                if value == \"false\":\n                    config[name] = False\n                elif value == \"true\":\n                    config[name] = True\n                else:\n                    config[name] = value\n\n    if config.get(\"debug\", False):\n        logger.setLevel(logging.DEBUG)\n        logger.debug(\"[INIT] set log level to DEBUG\")\n\n    logger.info(\"[INIT] load config: {}\".format(drag_sensitive(config)))\n\n    config.load_user_datas()\n\n\ndef get_root():\n    return os.path.dirname(os.path.abspath(__file__))\n\n\ndef read_file(path):\n    with open(path, mode=\"r\", encoding=\"utf-8\") as f:\n        return f.read()\n\n\ndef conf():\n    return config\n\n\ndef get_appdata_dir():\n    data_path = os.path.join(get_root(), conf().get(\"appdata_dir\", \"\"))\n    if not os.path.exists(data_path):\n        logger.info(\"[INIT] data path not exists, create it: {}\".format(data_path))\n        os.makedirs(data_path)\n    return data_path\n\n\ndef subscribe_msg():\n    trigger_prefix = conf().get(\"single_chat_prefix\", [\"\"])[0]\n    msg = conf().get(\"subscribe_msg\", \"\")\n    return msg.format(trigger_prefix=trigger_prefix)\n\n\n# global plugin config\nplugin_config = {}\n\n\ndef write_plugin_config(pconf: dict):\n    \"\"\"\n    写入插件全局配置\n    :param pconf: 全量插件配置\n    \"\"\"\n    global plugin_config\n    for k in pconf:\n        plugin_config[k.lower()] = pconf[k]\n\ndef remove_plugin_config(name: str):\n    \"\"\"\n    移除待重新加载的插件全局配置\n    :param name: 待重载的插件名\n    \"\"\"\n    global plugin_config\n    plugin_config.pop(name.lower(), None)\n\n\ndef pconf(plugin_name: str) -> dict:\n    \"\"\"\n    根据插件名称获取配置\n    :param plugin_name: 插件名称\n    :return: 该插件的配置项\n    \"\"\"\n    return plugin_config.get(plugin_name.lower())\n\n\n# 全局配置，用于存放全局生效的状态\nglobal_config = {\"admin_users\": []}\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "lib",
          "type": "tree",
          "content": null
        },
        {
          "name": "nixpacks.toml",
          "type": "blob",
          "size": 0.32421875,
          "content": "[phases.setup]\nnixPkgs = ['python310']\ncmds = ['apt-get update','apt-get install -y --no-install-recommends ffmpeg espeak libavcodec-extra']\n[phases.install]\ncmds = ['python -m venv /opt/venv && . /opt/venv/bin/activate && pip install -r requirements.txt && pip install -r requirements-optional.txt']\n[start]\ncmd = \"python ./app.py\""
        },
        {
          "name": "plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.1572265625,
          "content": "[tool.black]\nline-length = 176\ntarget-version = ['py37']\ninclude = '\\.pyi?$'\nextend-exclude = '.+/(dist|.venv|venv|build|lib)/.+'\n\n[tool.isort]\nprofile = \"black\""
        },
        {
          "name": "requirements-optional.txt",
          "type": "blob",
          "size": 0.7021484375,
          "content": "tiktoken>=0.3.2 # openai calculate token\n\n#voice\npydub>=0.25.1 # need ffmpeg\nSpeechRecognition # google speech to text\ngTTS>=2.3.1 # google text to speech\npyttsx3>=2.90 # pytsx text to speech\nbaidu_aip>=4.16.10 # baidu voice\nazure-cognitiveservices-speech # azure voice\nedge-tts # edge-tts\nnumpy<=1.24.2\nlangid # language detect\nelevenlabs==1.0.3 # elevenlabs TTS\n\n#install plugin\ndulwich\n\n# wechatmp && wechatcom\nweb.py\nwechatpy\n\n# chatgpt-tool-hub plugin\nchatgpt_tool_hub==0.5.0\n\n# xunfei spark\nwebsocket-client==1.2.0\n\n# claude bot\ncurl_cffi\n# claude API\nanthropic\n\n# tongyi qwen\nbroadscope_bailian\n\n# google\ngoogle-generativeai\n\n# dingtalk\ndingtalk_stream\n\n# zhipuai\nzhipuai>=2.0.1\n\n# tongyi qwen new sdk\ndashscope\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1328125,
          "content": "openai==0.27.8\nHTMLParser>=0.0.2\nPyQRCode==1.2.1\nqrcode==7.4.2\nrequests>=2.28.2\nchardet>=5.1.0\nPillow\npre-commit\nweb.py\nlinkai>=0.0.6.0\n"
        },
        {
          "name": "run.sh",
          "type": "blob",
          "size": 6.072265625,
          "content": "#!/usr/bin/env bash\nset -e\n\n# 颜色定义\nRED='\\033[0;31m'    # 红色\nGREEN='\\033[0;32m'  # 绿色\nYELLOW='\\033[0;33m' # 黄色\nBLUE='\\033[0;34m'   # 蓝色\nNC='\\033[0m'        # 无颜色\n\n# 获取当前脚本的目录\nexport BASE_DIR=$(cd \"$(dirname \"$0\")\"; pwd)\necho -e \"${GREEN}📁 BASE_DIR: ${BASE_DIR}${NC}\"\n\n# 检查 config.json 文件是否存在\ncheck_config_file() {\n    if [ ! -f \"${BASE_DIR}/config.json\" ]; then\n        echo -e \"${RED}❌ 错误：未找到 config.json 文件。请确保 config.json 存在于当前目录。${NC}\"\n        exit 1\n    fi\n}\n\n# 检查 Python 版本是否大于等于 3.7，并检查 pip 是否可用\ncheck_python_version() {\n    if ! command -v python3 &> /dev/null; then\n        echo -e \"${RED}❌ 错误：未找到 Python3。请安装 Python 3.7 或以上版本。${NC}\"\n        exit 1\n    fi\n\n    PYTHON_VERSION=$(python3 -c 'import sys; print(f\"{sys.version_info.major}.{sys.version_info.minor}\")')\n    PYTHON_MAJOR=$(echo \"$PYTHON_VERSION\" | cut -d'.' -f1)\n    PYTHON_MINOR=$(echo \"$PYTHON_VERSION\" | cut -d'.' -f2)\n\n    if (( PYTHON_MAJOR < 3 || (PYTHON_MAJOR == 3 && PYTHON_MINOR < 7) )); then\n        echo -e \"${RED}❌ 错误：Python 版本为 ${PYTHON_VERSION}。请安装 Python 3.7 或以上版本。${NC}\"\n        exit 1\n    fi\n\n    if ! python3 -m pip --version &> /dev/null; then\n        echo -e \"${RED}❌ 错误：未找到 pip。请安装 pip。${NC}\"\n        exit 1\n    fi\n}\n\n# 检查并安装缺失的依赖\ninstall_dependencies() {\n    echo -e \"${YELLOW}⏳ 正在安装依赖...${NC}\"\n\n    if [ ! -f \"${BASE_DIR}/requirements.txt\" ]; then\n        echo -e \"${RED}❌ 错误：未找到 requirements.txt 文件。${NC}\"\n        exit 1\n    fi\n\n    # 安装 requirements.txt 中的依赖，使用清华大学的 PyPI 镜像\n     pip3 install -r \"${BASE_DIR}/requirements.txt\" -i https://pypi.tuna.tsinghua.edu.cn/simple\n\n    # 处理 requirements-optional.txt（如果存在）\n    if [ -f \"${BASE_DIR}/requirements-optional.txt\" ]; then\n        echo -e \"${YELLOW}⏳ 正在安装可选的依赖...${NC}\"\n        pip3 install -r \"${BASE_DIR}/requirements-optional.txt\" -i https://pypi.tuna.tsinghua.edu.cn/simple\n    fi\n}\n\n# 启动项目\nrun_project() {\n    echo -e \"${GREEN}🚀 准备启动项目...${NC}\"\n    cd \"${BASE_DIR}\"\n    sleep 2\n\n\n    # 判断操作系统类型\n    OS_TYPE=$(uname)\n\n    if [[ \"$OS_TYPE\" == \"Linux\" ]]; then\n        # 在 Linux 上使用 setsid\n        setsid python3 \"${BASE_DIR}/app.py\" > \"${BASE_DIR}/nohup.out\" 2>&1 &\n        echo -e \"${GREEN}🚀 正在启动 ChatGPT-on-WeChat (Linux)...${NC}\"\n    elif [[ \"$OS_TYPE\" == \"Darwin\" ]]; then\n        # 在 macOS 上直接运行\n        python3 \"${BASE_DIR}/app.py\" > \"${BASE_DIR}/nohup.out\" 2>&1 &\n        echo -e \"${GREEN}🚀 正在启动 ChatGPT-on-WeChat (macOS)...${NC}\"\n    else\n        echo -e \"${RED}❌ 错误：不支持的操作系统 ${OS_TYPE}。${NC}\"\n        exit 1\n    fi\n\n    sleep 2\n    # 显示日志输出，供用户扫码\n    tail -n 30 -f \"${BASE_DIR}/nohup.out\"\n\n}\n# 更新项目\nupdate_project() {\n    echo -e \"${GREEN}🔄 准备更新项目，现在停止项目...${NC}\"\n    cd \"${BASE_DIR}\"\n\n    # 停止项目\n    stop_project\n    echo -e \"${GREEN}🔄 开始更新项目...${NC}\"\n    # 更新代码，从 git 仓库拉取最新代码\n    if [ -d .git ]; then\n        GIT_PULL_OUTPUT=$(git pull)\n        if [ $? -eq 0 ]; then\n            if [[ \"$GIT_PULL_OUTPUT\" == *\"Already up to date.\"* ]]; then\n                echo -e \"${GREEN}✅ 代码已经是最新的。${NC}\"\n            else\n                echo -e \"${GREEN}✅ 代码更新完成。${NC}\"\n            fi\n        else\n            echo -e \"${YELLOW}⚠️ 从 GitHub 更新失败，尝试切换到 Gitee 仓库...${NC}\"\n            # 更改远程仓库为 Gitee\n            git remote set-url origin https://gitee.com/zhayujie/chatgpt-on-wechat.git\n            GIT_PULL_OUTPUT=$(git pull)\n            if [ $? -eq 0 ]; then\n                if [[ \"$GIT_PULL_OUTPUT\" == *\"Already up to date.\"* ]]; then\n                    echo -e \"${GREEN}✅ 代码已经是最新的。${NC}\"\n                else\n                    echo -e \"${GREEN}✅ 从 Gitee 更新成功。${NC}\"\n                fi\n            else\n                echo -e \"${RED}❌ 错误：从 Gitee 更新仍然失败，请检查网络连接。${NC}\"\n                exit 1\n            fi\n        fi\n    else\n        echo -e \"${RED}❌ 错误：当前目录不是 git 仓库，无法更新代码。${NC}\"\n        exit 1\n    fi\n\n    # 安装依赖\n    install_dependencies\n\n    # 启动项目\n    run_project\n}\n\n# 停止项目\nstop_project() {\n    echo -e \"${GREEN}🛑 正在停止项目...${NC}\"\n    cd \"${BASE_DIR}\"\n    pid=$(ps ax | grep -i app.py | grep \"${BASE_DIR}\" | grep python3 | grep -v grep | awk '{print $1}')\n    if [ -z \"$pid\" ] ; then\n        echo -e \"${YELLOW}⚠️ 未找到正在运行的 ChatGPT-on-WeChat。${NC}\"\n        return\n    fi\n\n    echo -e \"${GREEN}🛑 正在运行的 ChatGPT-on-WeChat (PID: ${pid})${NC}\"\n\n    kill ${pid}\n    sleep 3\n\n    if ps -p $pid > /dev/null; then\n        echo -e \"${YELLOW}⚠️ 进程未停止，尝试强制终止...${NC}\"\n        kill -9 ${pid}\n    fi\n\n    echo -e \"${GREEN}✅ 已停止 ChatGPT-on-WeChat (PID: ${pid})${NC}\"\n}\n\n# 主函数，根据用户参数执行操作\ncase \"$1\" in\n    start)\n        check_config_file\n        check_python_version\n        run_project\n        ;;\n    stop)\n        stop_project\n        ;;\n    restart)\n        stop_project\n        check_config_file\n        check_python_version\n        run_project\n        ;;\n    update)\n        check_config_file\n        check_python_version\n        update_project\n        ;;\n    *)\n        echo -e \"${YELLOW}=========================================${NC}\"\n        echo -e \"${YELLOW}用法：${GREEN}$0 ${BLUE}{start|stop|restart|update}${NC}\"\n        echo -e \"${YELLOW}示例：${NC}\"\n        echo -e \"  ${GREEN}$0 ${BLUE}start${NC}\"\n        echo -e \"  ${GREEN}$0 ${BLUE}stop${NC}\"\n        echo -e \"  ${GREEN}$0 ${BLUE}restart${NC}\"\n        echo -e \"  ${GREEN}$0 ${BLUE}update${NC}\"\n        echo -e \"${YELLOW}=========================================${NC}\"\n        exit 1\n        ;;\nesac"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "translate",
          "type": "tree",
          "content": null
        },
        {
          "name": "voice",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}