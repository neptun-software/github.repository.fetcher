{
  "metadata": {
    "timestamp": 1736561435047,
    "page": 84,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Lightning-AI/pytorch-lightning",
      "stars": 28770,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".actions",
          "type": "tree",
          "content": null
        },
        {
          "name": ".azure",
          "type": "tree",
          "content": null
        },
        {
          "name": ".codecov.yml",
          "type": "blob",
          "size": 2.1943359375,
          "content": "# Copyright The Lightning AI team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# see https://docs.codecov.io/docs/codecov-yaml\n# Validation check:\n# $ curl --data-binary @.codecov.yml https://codecov.io/validate\n\n# https://docs.codecov.io/docs/codecovyml-reference\ncodecov:\n  bot: \"codecov-io\"\n  strict_yaml_branch: \"yaml-config\"\n  require_ci_to_pass: yes\n  notify:\n    after_n_builds: 23\n    wait_for_ci: yes\n  # https://docs.codecov.io/docs/codecov-yaml#section-expired-reports\n  max_report_age: off\n\ncoverage:\n  precision: 0 # 2 = xx.xx%, 0 = xx%\n  round: nearest # how coverage is rounded: down/up/nearest\n  range: 40...100 # custom range of coverage colors from red -> yellow -> green\n  status:\n    # https://codecov.readme.io/v1.0/docs/commit-status\n    project:\n      default:\n        informational: true\n        target: 99% # specify the target coverage for each commit status\n        threshold: 30% # allow this little decrease on project\n        # https://github.com/codecov/support/wiki/Filtering-Branches\n        # branches: master\n        if_ci_failed: error\n    # https://github.com/codecov/support/wiki/Patch-Status\n    patch:\n      default:\n        informational: true\n        target: 50% # specify the target \"X%\" coverage to hit\n        threshold: 5% # allow this much decrease on patch\n    changes: false\n\n# https://docs.codecov.com/docs/github-checks#disabling-github-checks-patch-annotations\ngithub_checks:\n  annotations: false\n\nparsers:\n  gcov:\n    branch_detection:\n      conditional: true\n      loop: true\n      macro: false\n      method: false\n  javascript:\n    enable_partials: false\n\ncomment:\n  layout: header, diff\n  require_changes: false\n  behavior: default # update if exists else create new\n  after_n_builds: 23\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.568359375,
          "content": "# copyright Lightning AI team (#16647)\n770b7929255389503e907350e2380ff449229816\n# [App] Add Missing Copyright (#16625)\n2bab2bac01694680b6c3e4f3a19d5bcd361fcaf4\n# adding license (#16450)\ne4c3441b25a8c194a873c8850e9507771de7053c\n# update copyright in PL & Fabric (#16481)\n98f7696d1681974d34fad59c03b4b58d9524ed13\n# add copyr (#6661)\nd471fa30b3bf95cfe601014bac544754067241ca\n# add copyright to tests (#5143)\n35401706bf0b89b07bc1748fdc2df612baa2be2a\n# added copyright notices (#3062)\nf43028f3ae5333b4ef0b08cc34f5560736381962\n# copyright (#2710)\n44d85c12191098b9bad40536375b29b154d91a47\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.7763671875,
          "content": "# project\n.DS_Store\nrun_configs/\nmodel_weights/\npip-wheel-metadata/\nlightning_logs/\n.vscode/\n\n# Documentations\ndocs/venv*/\ndocs/build*/\ndocs/source-fabric/_static/fetched-s3-assets\ndocs/source-pytorch/api\ndocs/source-pytorch/*.md\ndocs/source-pytorch/generated\ndocs/source-pytorch/*/generated\ndocs/source-pytorch/notebooks\ndocs/source-pytorch/_static/images/course_UvA-DL\ndocs/source-pytorch/_static/images/lightning_examples\ndocs/source-pytorch/_static/fetched-s3-assets\ndocs/source-pytorch/integrations/hpu\ndocs/source-pytorch/integrations/strategies/Hivemind.rst\n\ndocs/source-fabric/*/generated\n\n# C extensions\n*.so\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\ntimit_data/\ngrid_generated*\ngrid_ori*\n\n# PyCharm\n.idea/\n\n# Distribution / packaging\n.Python\nide_layouts/\nbuild/\n_build/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nsrc/*/version.info\nsrc/lightning_fabric/*\nsrc/pytorch_lightning/*\n!src/*/__about__.py\n!src/*/__main__.py\n!src/*/__setup__.py\n!src/*/__version__.py\n!src/*/MANIFEST.in\n!src/*/py.typed\n!src/*/README.md\n!src/*/shell-folder_code-lives-lightning.info\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\ntests/tests_tt_dir/\ntests/save_dir\ntests/tests/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n.env.staging\n.env.local\n\n# virtualenv\n.venv\nenv/\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n# pytest\n.pytest_cache/\n# ruff\n.ruff_cache/\n\n# data\n.data/\nDatasets/\nmnist/\nMNIST/\ntests/legacy/checkpoints/\n*.gz\n*ubyte\n\n# pl tests\nml-runs/\nmlruns/\n*.zip\n*.ckpt\ntest-reports/\nwandb\n.forked/\n*.prof\n*.tar.gz\n.neptune/\n\n# dataset generated from bolts in examples.\ncifar-10-batches-py\n*.pt\n# ctags\ntags\n.tags\n*examples/template_react_ui*\nhars*\nartifacts/*\n*docs/examples*\n\n# tutorials\nour_model.tar\ntest.png\nsaved_models\ndata/\n!examples/data/\n!tests/tests_pytorch/utilities/data/\n!requirements/data/\n.shared\n.lightning\nnode_modules/\n\n# examples\n**/events.out.tfevents.*\nexamples/**/*.png\n\n# instalation artifacts\nrequirements/base.txt\n\n# CI\n.wheels/\n\n# sourced notebooks from tutorials\n_notebooks/.notebooks/\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1259765625,
          "content": "[submodule \"_notebooks\"]\n\tpath = _notebooks\n\turl = https://github.com/Lightning-AI/lightning-tutorials.git\n\tbranch = publication\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 3.3564453125,
          "content": "# Copyright The Lightning AI team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ndefault_language_version:\n  python: python3\n\nci:\n  autofix_prs: true\n  autoupdate_commit_msg: \"[pre-commit.ci] pre-commit suggestions\"\n  autoupdate_schedule: quarterly\n  # submodules: true\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n        # keep formatting in README flexible\n        exclude: README.md\n      - id: check-json\n      - id: check-yaml\n      - id: check-toml\n      - id: check-docstring-first\n      - id: check-executables-have-shebangs\n      - id: check-case-conflict\n      - id: check-added-large-files\n        args: [\"--maxkb=350\", \"--enforce-all\"]\n        exclude: |\n          (?x)^(\n              docs/source-pytorch/_static/images/general/fast_2.gif|\n              docs/source-pytorch/_static/images/mnist_imgs/pt_to_pl.jpg|\n              docs/source-pytorch/_static/images/lightning_module/pt_to_pl.png|\n              docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif|\n              docs/source-pytorch/_static/images/general/pl_overview_flat.jpg|\n              docs/source-pytorch/_static/images/general/pl_overview.gif|\n              src/lightning/fabric/CHANGELOG.md|\n              src/lightning/pytorch/CHANGELOG.md\n          )$\n      - id: detect-private-key\n\n  - repo: https://github.com/codespell-project/codespell\n    rev: v2.3.0\n    hooks:\n      - id: codespell\n        additional_dependencies: [tomli]\n        #args: [\"--write-changes\"] # uncomment if you want to get automatic fixing\n\n  - repo: https://github.com/PyCQA/docformatter\n    rev: 06907d0267368b49b9180eed423fae5697c1e909 # todo: fix for docformatter after last 1.7.5\n    hooks:\n      - id: docformatter\n        additional_dependencies: [tomli]\n        args: [\"--in-place\"]\n\n  - repo: https://github.com/sphinx-contrib/sphinx-lint\n    rev: v1.0.0\n    hooks:\n      - id: sphinx-lint\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.6\n    hooks:\n      # try to fix what is possible\n      - id: ruff\n        args: [\"--fix\", \"--unsafe-fixes\"]\n      # perform formatting updates\n      - id: ruff-format\n      # validate if all is fine with preview mode\n      - id: ruff\n\n  - repo: https://github.com/executablebooks/mdformat\n    rev: 0.7.21\n    hooks:\n      - id: mdformat\n        additional_dependencies:\n          - mdformat-gfm\n          #- mdformat-black\n          - mdformat_frontmatter\n        exclude: |\n          (?x)^(\n              src/lightning/fabric/CHANGELOG.md|\n              src/lightning/pytorch/CHANGELOG.md|\n              README.md\n          )$\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v3.1.0\n    hooks:\n      - id: prettier\n        # https://prettier.io/docs/en/options.html#print-width\n        files: \\.(json|yml|yaml|toml)\n        args: [\"--print-width=120\"]\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 1.712890625,
          "content": "# Copyright The Lightning AI team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# .readthedocs.yml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\nsubmodules:\n  include: all\n  recursive: true\n\n# Build documentation in the docs/ directory with Sphinx\n# reference: https://docs.readthedocs.io/en/stable/config-file/v2.html#sphinx\nsphinx:\n  fail_on_warning: true\n\nbuild:\n  os: ubuntu-20.04\n  tools:\n    python: \"3.9\"\n  apt_packages:\n    - texlive-latex-extra\n    - dvipng\n    - texlive-pictures\n  commands:\n    - printenv\n    - pwd ; ls -lh\n    - pip install -U pip awscli py-tree --user\n    - python -m awscli s3 sync --no-sign-request s3://sphinx-packages/ dist/ ; ls -lh dist/\n    - >\n      pip install -e . -q -r _notebooks/.actions/requires.txt \\\n          -r requirements/fabric/docs.txt \\\n          -r requirements/pytorch/docs.txt \\\n          -f 'https://download.pytorch.org/whl/cpu/torch_stable.html' -f dist/ ;\n      pip list\n    # this need to be split so `sphinx-build` is picked from previous installation\n    - bash docs/rtfd-build.sh\n    - cd docs/build ; python -m py_tree --depth_limit=1\n    - mkdir -p _readthedocs ; mv docs/build _readthedocs/html\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.6171875,
          "content": "cff-version: 1.2.0\nmessage: \"If you want to cite the framework, feel free to use this (but only if you loved it 😊)\"\ntitle: \"PyTorch Lightning\"\nabstract: \"The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.\"\ndate-released: 2019-03-30\nauthors:\n  - family-names: \"Falcon\"\n    given-names: \"William\"\n  - name: \"The PyTorch Lightning team\"\nversion: 1.4\ndoi: 10.5281/zenodo.3828935\nlicense: \"Apache-2.0\"\nurl: \"https://www.pytorchlightning.ai\"\nrepository-code: \"https://github.com/Lightning-AI/lightning\"\nkeywords:\n  - machine learning\n  - deep learning\n  - artificial intelligence\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0830078125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018-2021 William Falcon\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.814453125,
          "content": ".PHONY: test clean docs\n\n# to imitate SLURM set only single node\nexport SLURM_LOCALID=0\n# assume you have installed need packages\nexport SPHINX_MOCK_REQUIREMENTS=1\n# install only Lightning Trainer packages\nexport PACKAGE_NAME=pytorch\n\nclean:\n\t# clean all temp runs\n\trm -rf $(shell find . -name \"mlruns\")\n\trm -rf $(shell find . -name \"lightning_log\")\n\trm -rf $(shell find . -name \"lightning_logs\")\n\trm -rf _ckpt_*\n\trm -rf .mypy_cache\n\trm -rf .pytest_cache\n\trm -rf ./docs/build\n\trm -rf ./docs/source-fabric/api/generated\n\trm -rf ./docs/source-pytorch/notebooks\n\trm -rf ./docs/source-pytorch/generated\n\trm -rf ./docs/source-pytorch/*/generated\n\trm -rf ./docs/source-pytorch/api\n\trm -rf build\n\trm -rf dist\n\trm -rf *.egg-info\n\trm -rf src/*.egg-info\n\trm -rf src/lightning_fabric/*/\n\trm -rf src/pytorch_lightning/*/\n\ntest: clean\n\t# Review the CONTRIBUTING documentation for other ways to test.\n\tpip install -e . \\\n\t-r requirements/pytorch/base.txt \\\n\t-r requirements/fabric/base.txt \\\n\t-r requirements/pytorch/test.txt \\\n\n\t# run tests with coverage\n\tpython -m coverage run --source src/lightning/pytorch -m pytest src/lightning/pytorch tests/tests_pytorch -v\n\tpython -m coverage run --source src/lightning/fabric -m pytest src/lightning/fabric tests/tests_fabric -v\n\tpython -m coverage report\n\ndocs: docs-pytorch\n\nsphinx-theme:\n\tpip install -q awscli\n\tmkdir -p dist/\n\taws s3 sync --no-sign-request s3://sphinx-packages/ dist/\n\tpip install lai-sphinx-theme -f dist/\n\ndocs-fabric: clean sphinx-theme\n\tpip install -e .[all] --quiet -r requirements/fabric/docs.txt\n\tcd docs/source-fabric && $(MAKE) html --jobs $(nproc)\n\ndocs-pytorch: clean sphinx-theme\n\tpip install -e .[all] --quiet -r requirements/pytorch/docs.txt -r _notebooks/.actions/requires.txt\n\tcd docs/source-pytorch && $(MAKE) html --jobs $(nproc)\n\nupdate:\n\tgit submodule update --init --recursive --remote\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 25.3212890625,
          "content": "<div align=\"center\">\n\n<img alt=\"Lightning\" src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/ptl_banner.png\" width=\"800px\" style=\"max-width: 100%;\">\n\n<br/>\n<br/>\n\n**The deep learning framework to pretrain, finetune and deploy AI models.**\n\n**NEW- Deploying models? Check out [LitServe](https://github.com/Lightning-AI/litserve), the PyTorch Lightning for model serving**\n\n______________________________________________________________________\n\n<p align=\"center\">\n    <a href=\"#quick-start\" style=\"margin: 0 10px;\">Quick start</a> •\n  <a href=\"#examples\">Examples</a> •\n  <a href=\"#why-pytorch-lightning\">PyTorch Lightning</a> •\n  <a href=\"#lightning-fabric-expert-control\">Fabric</a> •\n  <a href=\"https://lightning.ai/\">Lightning AI</a> •   \n  <a href=\"#community\">Community</a> •\n  <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/\">Docs</a>\n</p>\n\n<!-- DO NOT ADD CONDA DOWNLOADS... README CHANGES MUST BE APPROVED BY EDEN OR WILL -->\n\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pytorch-lightning)](https://pypi.org/project/pytorch-lightning/)\n[![PyPI Status](https://badge.fury.io/py/pytorch-lightning.svg)](https://badge.fury.io/py/pytorch-lightning)\n[![PyPI - Downloads](https://img.shields.io/pypi/dm/pytorch-lightning)](https://pepy.tech/project/pytorch-lightning)\n[![Conda](https://img.shields.io/conda/v/conda-forge/lightning?label=conda&color=success)](https://anaconda.org/conda-forge/lightning)\n[![codecov](https://codecov.io/gh/Lightning-AI/pytorch-lightning/graph/badge.svg?token=SmzX8mnKlA)](https://codecov.io/gh/Lightning-AI/pytorch-lightning)\n\n[![Discord](https://img.shields.io/discord/1077906959069626439?style=plastic)](https://discord.gg/VptPCZkGNa)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/w/lightning-ai/lightning)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/Lightning-AI/lightning/blob/master/LICENSE)\n\n<!--\n[![CodeFactor](https://www.codefactor.io/repository/github/Lightning-AI/lightning/badge)](https://www.codefactor.io/repository/github/Lightning-AI/lightning)\n-->\n\n</div>\n\n<div align=\"center\">\n  \n<p align=\"center\">\n\n&nbsp;\n  \n<a target=\"_blank\" href=\"https://lightning.ai/docs/pytorch/latest/starter/introduction.html#define-a-lightningmodule\">\n  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/get-started-badge.svg\" height=\"36px\" alt=\"Get started\"/>\n</a>\n\n</p>\n\n</div>\n\n&nbsp;\n\n# Lightning has 2 core packages\n\n[PyTorch Lightning: Train and deploy PyTorch at scale](#why-pytorch-lightning).\n<br/>\n[Lightning Fabric: Expert control](#lightning-fabric-expert-control).\n\nLightning gives you granular control over how much abstraction you want to add over PyTorch.\n\n<div align=\"center\">\n    <img src=\"https://pl-public-data.s3.amazonaws.com/assets_lightning/continuum.png\" width=\"80%\">\n</div>\n\n&nbsp;\n\n# Quick start\nInstall Lightning:\n\n```bash\npip install lightning\n```\n\n<!-- following section will be skipped from PyPI description -->\n\n<details>\n  <summary>Advanced install options</summary>\n    <!-- following section will be skipped from PyPI description -->\n\n#### Install with optional dependencies\n\n```bash\npip install lightning['extra']\n```\n\n#### Conda\n\n```bash\nconda install lightning -c conda-forge\n```\n\n#### Install stable version\n\nInstall future release from the source\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/release/stable.zip -U\n```\n\n#### Install bleeding-edge\n\nInstall nightly from the source (no guarantees)\n\n```bash\npip install https://github.com/Lightning-AI/lightning/archive/refs/heads/master.zip -U\n```\n\nor from testing PyPI\n\n```bash\npip install -iU https://test.pypi.org/simple/ pytorch-lightning\n```\n\n</details>\n<!-- end skipping PyPI description -->\n\n### PyTorch Lightning example\nDefine the training workflow. Here's a toy example ([explore real examples](https://lightning.ai/lightning-ai/studios?view=public&section=featured&query=pytorch+lightning)):\n\n```python\n# main.py\n# ! pip install torchvision\nimport torch, torch.nn as nn, torch.utils.data as data, torchvision as tv, torch.nn.functional as F\nimport lightning as L\n\n# --------------------------------\n# Step 1: Define a LightningModule\n# --------------------------------\n# A LightningModule (nn.Module subclass) defines a full *system*\n# (ie: an LLM, diffusion model, autoencoder, or simple image classifier).\n\n\nclass LitAutoEncoder(L.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n\n    def forward(self, x):\n        # in lightning, forward defines the prediction/inference actions\n        embedding = self.encoder(x)\n        return embedding\n\n    def training_step(self, batch, batch_idx):\n        # training_step defines the train loop. It is independent of forward\n        x, _ = batch\n        x = x.view(x.size(0), -1)\n        z = self.encoder(x)\n        x_hat = self.decoder(z)\n        loss = F.mse_loss(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return optimizer\n\n\n# -------------------\n# Step 2: Define data\n# -------------------\ndataset = tv.datasets.MNIST(\".\", download=True, transform=tv.transforms.ToTensor())\ntrain, val = data.random_split(dataset, [55000, 5000])\n\n# -------------------\n# Step 3: Train\n# -------------------\nautoencoder = LitAutoEncoder()\ntrainer = L.Trainer()\ntrainer.fit(autoencoder, data.DataLoader(train), data.DataLoader(val))\n```\n\nRun the model on your terminal\n\n```bash\npip install torchvision\npython main.py\n```\n\n&nbsp;\n\n\n# Why PyTorch Lightning?\n\nPyTorch Lightning is just organized PyTorch - Lightning disentangles PyTorch code to decouple the science from the engineering.\n\n![PT to PL](docs/source-pytorch/_static/images/general/pl_quick_start_full_compressed.gif)\n\n&nbsp;\n\n----\n\n### Examples\nExplore various types of training possible with PyTorch Lightning. Pretrain and finetune ANY kind of model to perform ANY task like classification, segmentation, summarization and more:    \n\n| Task                                                                                                        | Description                                                    | Run |\n|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|---|\n| [Hello world](#hello-simple-model)                                                                          | Pretrain - Hello world example                                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/pytorch-lightning-hello-world\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Image classification](https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning) | Finetune - ResNet-34 model to classify images of cars          | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Image segmentation](https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning)   | Finetune - ResNet-50 model to segment images                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/image-segmentation-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Object detection](https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning)       | Finetune - Faster R-CNN model to detect objects                   | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/object-detection-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |\n| [Text classification](https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning) | Finetune - text classifier (BERT model)                        | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-classification-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Text summarization](https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning)   | Finetune - text summarization (Hugging Face transformer model) | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/text-summarization-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [Audio generation](https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator)        | Finetune - audio generator (transformer model)                 | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-a-personal-ai-music-generator\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> |   \n| [LLM finetuning](https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning)          | Finetune - LLM (Meta Llama 3.1 8B)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/finetune-an-llm-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Image generation](https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning)          | Pretrain - Image generator (diffusion model)                | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/train-a-diffusion-model-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Recommendation system](https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning)  | Train - recommendation system (factorization and embedding)    | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/recommendation-system-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n| [Time-series forecasting](https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning) | Train - Time-series forecasting with LSTM               | <a target=\"_blank\" href=\"https://lightning.ai/lightning-ai/studios/time-series-forecasting-with-pytorch-lightning\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open In Studio\"/></a> | \n\n______________________________________________________________________\n\n## Advanced features\n\nLightning has over [40+ advanced features](https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags) designed for professional AI research at scale.\n\nHere are some examples:\n\n<div align=\"center\">\n    <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/features_2.jpg\" max-height=\"600px\">\n  </div>\n\n<details>\n  <summary>Train on 1000s of GPUs without code changes</summary>\n\n```python\n# 8 GPUs\n# no code changes needed\ntrainer = Trainer(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs\ntrainer = Trainer(accelerator=\"gpu\", devices=8, num_nodes=32)\n```\n\n</details>\n\n<details>\n  <summary>Train on other accelerators like TPUs without code changes</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(accelerator=\"tpu\", devices=8)\n```\n\n</details>\n\n<details>\n  <summary>16-bit precision</summary>\n\n```python\n# no code changes needed\ntrainer = Trainer(precision=16)\n```\n\n</details>\n\n<details>\n  <summary>Experiment managers</summary>\n\n```python\nfrom lightning import loggers\n\n# tensorboard\ntrainer = Trainer(logger=TensorBoardLogger(\"logs/\"))\n\n# weights and biases\ntrainer = Trainer(logger=loggers.WandbLogger())\n\n# comet\ntrainer = Trainer(logger=loggers.CometLogger())\n\n# mlflow\ntrainer = Trainer(logger=loggers.MLFlowLogger())\n\n# neptune\ntrainer = Trainer(logger=loggers.NeptuneLogger())\n\n# ... and dozens more\n```\n\n</details>\n\n<details>\n\n<summary>Early Stopping</summary>\n\n```python\nes = EarlyStopping(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[es])\n```\n\n</details>\n\n<details>\n  <summary>Checkpointing</summary>\n\n```python\ncheckpointing = ModelCheckpoint(monitor=\"val_loss\")\ntrainer = Trainer(callbacks=[checkpointing])\n```\n\n</details>\n\n<details>\n  <summary>Export to torchscript (JIT) (production use)</summary>\n\n```python\n# torchscript\nautoencoder = LitAutoEncoder()\ntorch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n```\n\n</details>\n\n<details>\n  <summary>Export to ONNX (production use)</summary>\n\n```python\n# onnx\nwith tempfile.NamedTemporaryFile(suffix=\".onnx\", delete=False) as tmpfile:\n    autoencoder = LitAutoEncoder()\n    input_sample = torch.randn((1, 64))\n    autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n    os.path.isfile(tmpfile.name)\n```\n\n</details>\n\n______________________________________________________________________\n\n## Advantages over unstructured PyTorch\n\n- Models become hardware agnostic\n- Code is clear to read because engineering code is abstracted away\n- Easier to reproduce\n- Make fewer mistakes because lightning handles the tricky engineering\n- Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\n- Lightning has dozens of integrations with popular machine learning tools.\n- [Tested rigorously with every new PR](https://github.com/Lightning-AI/lightning/tree/master/tests). We test every combination of PyTorch and Python supported versions, every OS, multi GPUs and even TPUs.\n- Minimal running speed overhead (about 300 ms per epoch compared with pure PyTorch).\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/pytorch/stable/\">Read the PyTorch Lightning docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n# Lightning Fabric: Expert control\n\nRun on any device at any scale with expert-level control over PyTorch training loop and scaling strategy. You can even write your own Trainer.\n\nFabric is designed for the most complex models like foundation model scaling, LLMs, diffusion, transformers, reinforcement learning, active learning. Of any size.\n\n<table>\n<tr>\n<th>What to change</th>\n<th>Resulting Fabric Code (copy me!)</th>\n</tr>\n<tr>\n<td>\n<sub>\n\n```diff\n+ import lightning as L\n  import torch; import torchvision as tv\n\n dataset = tv.datasets.CIFAR10(\"data\", download=True,\n                               train=True,\n                               transform=tv.transforms.ToTensor())\n\n+ fabric = L.Fabric()\n+ fabric.launch()\n\n  model = tv.models.resnet18()\n  optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n- device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n- model.to(device)\n+ model, optimizer = fabric.setup(model, optimizer)\n\n  dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n+ dataloader = fabric.setup_dataloaders(dataloader)\n\n  model.train()\n  num_epochs = 10\n  for epoch in range(num_epochs):\n      for batch in dataloader:\n          inputs, labels = batch\n-         inputs, labels = inputs.to(device), labels.to(device)\n          optimizer.zero_grad()\n          outputs = model(inputs)\n          loss = torch.nn.functional.cross_entropy(outputs, labels)\n-         loss.backward()\n+         fabric.backward(loss)\n          optimizer.step()\n          print(loss.data)\n```\n\n</sub>\n<td>\n<sub>\n\n```Python\nimport lightning as L\nimport torch; import torchvision as tv\n\ndataset = tv.datasets.CIFAR10(\"data\", download=True,\n                              train=True,\n                              transform=tv.transforms.ToTensor())\n\nfabric = L.Fabric()\nfabric.launch()\n\nmodel = tv.models.resnet18()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\nmodel, optimizer = fabric.setup(model, optimizer)\n\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\ndataloader = fabric.setup_dataloaders(dataloader)\n\nmodel.train()\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch in dataloader:\n        inputs, labels = batch\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        fabric.backward(loss)\n        optimizer.step()\n        print(loss.data)\n```\n\n</sub>\n</td>\n</tr>\n</table>\n\n## Key features\n\n<details>\n  <summary>Easily switch from running on CPU to GPU (Apple Silicon, CUDA, …), TPU, multi-GPU or even multi-node training</summary>\n\n```python\n# Use your available hardware\n# no code changes needed\nfabric = Fabric()\n\n# Run on GPUs (CUDA or MPS)\nfabric = Fabric(accelerator=\"gpu\")\n\n# 8 GPUs\nfabric = Fabric(accelerator=\"gpu\", devices=8)\n\n# 256 GPUs, multi-node\nfabric = Fabric(accelerator=\"gpu\", devices=8, num_nodes=32)\n\n# Run on TPUs\nfabric = Fabric(accelerator=\"tpu\")\n```\n\n</details>\n\n<details>\n  <summary>Use state-of-the-art distributed training strategies (DDP, FSDP, DeepSpeed) and mixed precision out of the box</summary>\n\n```python\n# Use state-of-the-art distributed training techniques\nfabric = Fabric(strategy=\"ddp\")\nfabric = Fabric(strategy=\"deepspeed\")\nfabric = Fabric(strategy=\"fsdp\")\n\n# Switch the precision\nfabric = Fabric(precision=\"16-mixed\")\nfabric = Fabric(precision=\"64\")\n```\n\n</details>\n\n<details>\n  <summary>All the device logic boilerplate is handled for you</summary>\n\n```diff\n  # no more of this!\n- model.to(device)\n- batch.to(device)\n```\n\n</details>\n\n<details>\n  <summary>Build your own custom Trainer using Fabric primitives for training checkpointing, logging, and more</summary>\n\n```python\nimport lightning as L\n\n\nclass MyCustomTrainer:\n    def __init__(self, accelerator=\"auto\", strategy=\"auto\", devices=\"auto\", precision=\"32-true\"):\n        self.fabric = L.Fabric(accelerator=accelerator, strategy=strategy, devices=devices, precision=precision)\n\n    def fit(self, model, optimizer, dataloader, max_epochs):\n        self.fabric.launch()\n\n        model, optimizer = self.fabric.setup(model, optimizer)\n        dataloader = self.fabric.setup_dataloaders(dataloader)\n        model.train()\n\n        for epoch in range(max_epochs):\n            for batch in dataloader:\n                input, target = batch\n                optimizer.zero_grad()\n                output = model(input)\n                loss = loss_fn(output, target)\n                self.fabric.backward(loss)\n                optimizer.step()\n```\n\nYou can find a more extensive example in our [examples](examples/fabric/build_your_own_trainer)\n\n</details>\n\n______________________________________________________________________\n\n<div align=\"center\">\n    <a href=\"https://lightning.ai/docs/fabric/stable/\">Read the Lightning Fabric docs</a>\n</div>\n\n______________________________________________________________________\n\n&nbsp;\n&nbsp;\n\n## Examples\n\n###### Self-supervised Learning\n\n- [CPC transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#cpc-transforms)\n- [Moco v2 transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#moco-v2-transforms)\n- [SimCLR transforms](https://lightning-bolts.readthedocs.io/en/stable/transforms/self_supervised.html#simclr-transforms)\n\n###### Convolutional Architectures\n\n- [GPT-2](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#gpt-2)\n- [UNet](https://lightning-bolts.readthedocs.io/en/stable/models/convolutional.html#unet)\n\n###### Reinforcement Learning\n\n- [DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#dqn-loss)\n- [Double DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#double-dqn-loss)\n- [Per DQN Loss](https://lightning-bolts.readthedocs.io/en/stable/losses.html#per-dqn-loss)\n\n###### GANs\n\n- [Basic GAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#basic-gan)\n- [DCGAN](https://lightning-bolts.readthedocs.io/en/stable/models/gans.html#dcgan)\n\n###### Classic ML\n\n- [Logistic Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#logistic-regression)\n- [Linear Regression](https://lightning-bolts.readthedocs.io/en/stable/models/classic_ml.html#linear-regression)\n\n&nbsp;\n&nbsp;\n\n## Continuous Integration\n\nLightning is rigorously tested across multiple CPUs, GPUs and TPUs and against major Python and PyTorch versions.\n\n###### \\*Codecov is > 90%+ but build delays may show less\n\n<details>\n  <summary>Current build statuses</summary>\n\n<center>\n\n|       System / PyTorch ver.        | 1.13                                                                                                                                                                                                                            | 2.0                                                                                                                                                                                                                             |                                                                                                               2.1                                                                                                               |\n| :--------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|\n|        Linux py3.9 \\[GPUs\\]        |  |  | [![Build Status](https://dev.azure.com/Lightning-AI/lightning/_apis/build/status%2Fpytorch-lightning%20%28GPUs%29?branchName=master)](https://dev.azure.com/Lightning-AI/lightning/_build/latest?definitionId=24&branchName=master) |\n|  Linux (multiple Python versions)  | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n|   OSX (multiple Python versions)   | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n| Windows (multiple Python versions) | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 | [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                                 |                 [![Test PyTorch](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml/badge.svg)](https://github.com/Lightning-AI/lightning/actions/workflows/ci-tests-pytorch.yml)                 |\n\n</center>\n</details>\n\n&nbsp;\n&nbsp;\n\n## Community\n\nThe lightning community is maintained by\n\n- [10+ core contributors](https://lightning.ai/docs/pytorch/latest/community/governance.html) who are all a mix of professional engineers, Research Scientists, and Ph.D. students from top AI labs.\n- 800+ community contributors.\n\nWant to help us build Lightning and reduce boilerplate for thousands of researchers? [Learn how to make your first contribution here](https://lightning.ai/docs/pytorch/stable/generated/CONTRIBUTING.html)\n\nLightning is also part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/) which requires projects to have solid testing, documentation and support.\n\n### Asking for help\n\nIf you have any questions please:\n\n1. [Read the docs](https://lightning.ai/docs).\n1. [Search through existing Discussions](https://github.com/Lightning-AI/lightning/discussions), or [add a new question](https://github.com/Lightning-AI/lightning/discussions/new)\n1. [Join our discord](https://discord.com/invite/tfXFetEZxv).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.0224609375,
          "content": "developer@lightning.ai\n"
        },
        {
          "name": "_notebooks",
          "type": "commit",
          "content": null
        },
        {
          "name": "dockers",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 6.4736328125,
          "content": "# Copyright The Lightning AI team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n[build-system]\nrequires = [\n    \"setuptools\",\n    \"wheel\",\n    \"packaging\",\n]\n\n\n[tool.black]\nline-length = 120\nexclude = '(_notebooks/.*)'\n\n[tool.docformatter]\nrecursive = true\n# this need to be shorter as some docstings are r\"\"\"...\nwrap-summaries = 119\nwrap-descriptions = 120\nblank = true\n\n[tool.codespell]\n# Todo: enable also python files in a next step\nskip = '*.py'\nquiet-level = 3\n# comma separated list of words; waiting for:\n#  https://github.com/codespell-project/codespell/issues/2839#issuecomment-1731601603\n# also adding links until they ignored by its: nature\n#  https://github.com/codespell-project/codespell/issues/2243#issuecomment-1732019960\nignore-words-list = \"te, compiletime\"\n\n\n[tool.ruff]\nline-length = 120\ntarget-version = \"py39\"\n# Exclude a variety of commonly ignored directories.\nexclude = [\n    \".git\",\n    \"docs\",\n    \"_notebooks\"\n]\n\n[tool.ruff.format]\npreview = true\n\n[tool.ruff.lint]\nselect = [\n    \"E\", \"W\",  # see: https://pypi.org/project/pycodestyle\n    \"F\",  # see: https://pypi.org/project/pyflakes\n    \"S\",  # see: https://pypi.org/project/flake8-bandit\n    \"RUF018\",  # see: https://docs.astral.sh/ruff/rules/assignment-in-assert\n    \"UP\", # see: https://docs.astral.sh/ruff/rules/#pyupgrade-up\n]\nextend-select = [\n    \"I\",  # see: isort\n    \"C4\",  # see: https://pypi.org/project/flake8-comprehensions\n    \"SIM\",  # see: https://pypi.org/project/flake8-simplify\n    \"RET\",  # see: https://pypi.org/project/flake8-return\n    \"PT\",  # see: https://pypi.org/project/flake8-pytest-style\n    \"RUF100\",  # see: https://docs.astral.sh/ruff/rules/unused-noqa/\n]\nignore = [\n    \"E731\",  # Do not assign a lambda expression, use a def\n    \"S108\",\n    \"E203\", # conflicts with black\n]\n\n[tool.ruff.lint.per-file-ignores]\n\".actions/*\" = [\"S101\", \"S310\"]\n\"setup.py\" = [\"S101\"]\n\"examples/**\" = [\n    \"S101\",  # Use of `assert` detected\n    \"S113\",  # todo: Probable use of requests call without\n    \"S104\",  # Possible binding to all interface\n    \"F821\",  # Undefined name `...`\n    \"S311\",  # Standard pseudo-random generators are not suitable for cryptographic purposes\n    \"S501\",  # Probable use of `requests` call with `verify=False` disabling SSL certificate checks\n    \"S108\",  # Probable insecure usage of temporary file or directory: \"/tmp/data/MNIST\"\n]\n\"src/**\" = [\n    \"S101\",  # todo: Use of `assert` detected\n    \"S105\", \"S106\", \"S107\",  # todo: Possible hardcoded password: ...\n    \"S113\",  # todo: Probable use of requests call without timeout\n    \"S301\",  # todo: `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue\n    \"S324\",  # todo: Probable use of insecure hash functions in `hashlib`\n    \"S403\",  # todo: `pickle`, `cPickle`, `dill`, and `shelve` modules are possibly insecure\n    \"S404\",  # todo: `subprocess` module is possibly insecure\n    \"S602\",  # todo: `subprocess` call with `shell=True` identified, security issue\n    \"S603\",  # todo: `subprocess` call: check for execution of untrusted input\n    \"S605\",  # todo: Starting a process with a shell: seems safe, but may be changed in the future; consider rewriting without `shell`\n    \"S607\",  # todo: Starting a process with a partial executable path\n    \"RET504\",  # todo:Unnecessary variable assignment before `return` statement\n    \"RET503\",\n]\n\"tests/**\" = [\n    \"S101\",  # Use of `assert` detected\n    \"S105\", \"S106\",  # todo: Possible hardcoded password: ...\n    \"S301\",  # `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue\n    \"S113\",  # todo: Probable use of requests call without timeout\n    \"S311\",  # todo: Standard pseudo-random generators are not suitable for cryptographic purposes\n    \"S108\",  # todo: Probable insecure usage of temporary file or directory: \"/tmp/sys-customizations-sync\"\n    \"S202\",  # Uses of `tarfile.extractall()`\n    \"S403\",  # `pickle`, `cPickle`, `dill`, and `shelve` modules are possibly insecure\n    \"S404\",  # `subprocess` module is possibly insecure\n    \"S602\",  # todo: `subprocess` call with `shell=True` identified, security issue\n    \"S603\",  # todo: `subprocess` call: check for execution of untrusted input\n    \"S605\",  # todo: Starting a process with a shell: seems safe, but may be changed in the future; consider rewriting without `shell`\n    \"S607\",  # todo: Starting a process with a partial executable path\n    \"RET504\",  # todo:Unnecessary variable assignment before `return` statement\n    \"PT004\",  # todo: Fixture `tmpdir_unittest_fixture` does not return anything, add leading underscore\n    \"PT011\",  # todo: `pytest.raises(ValueError)` is too broad, set the `match` parameter or use a more specific exception\n    \"PT012\",  # todo: `pytest.raises()` block should contain a single simple statement\n    \"PT019\",  # todo: Fixture `_` without value is injected as parameter, use `@pytest.mark.usefixtures` instead\n]\n\n[tool.ruff.lint.mccabe]\n# Unlike Flake8, default to a complexity level of 10.\nmax-complexity = 10\n\n\n[tool.mypy]\nfiles = [\n    \"src/lightning\",\n]\n\ninstall_types = \"True\"\nnon_interactive = \"True\"\ndisallow_untyped_defs = \"True\"\nignore_missing_imports = \"True\"\nshow_error_codes = \"True\"\nwarn_redundant_casts = \"True\"\nwarn_unused_configs = \"True\"\nwarn_unused_ignores = \"True\"\nallow_redefinition = \"True\"\n# disable this rule as the Trainer attributes are defined in the connectors, not in its __init__\ndisable_error_code = \"attr-defined\"\n# style choices\nwarn_no_return = \"False\"\n\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"warnings\",\n    \"pass\",\n    \"rank_zero_warn\",\n    \"raise NotImplementedError\",\n]\n\n\n[tool.pytest.ini_options]\nnorecursedirs = [\n    \".git\",\n    \".github\",\n    \"dist\",\n    \"build\",\n    \"docs\",\n]\naddopts = [\n    \"--strict-markers\",\n    \"--doctest-modules\",\n    \"--color=yes\",\n    \"--disable-pytest-warnings\",\n    \"--ignore=legacy/checkpoints\",\n]\nmarkers = [\n    \"cloud: Run the cloud tests for example\",\n]\nfilterwarnings = [\n    \"error::FutureWarning\",\n]\nxfail_strict = true\njunit_duration_report = \"call\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1025390625,
          "content": "# the default package dependencies\n\n-r ./requirements/fabric/base.txt\n-r ./requirements/pytorch/base.txt\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.65625,
          "content": "#!/usr/bin/env python\n# Copyright The Lightning AI team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"This is the main and only one setup entry point for installing each package as stand-alone as well as joint\ninstallation for all packages.\n\nThere are considered three main scenarios for installing this project:\n\n1. Using PyPI registry when you can install `pytorch-lightning`, etc. or `lightning` for all.\n\n2. Installation from source code after cloning repository.\n    In such case we recommend to use command `pip install .` or `pip install -e .` for development version\n     (development ver. do not copy python files to your pip file system, just create links, so you can edit here)\n    In case you want to install just one package you need to export env. variable before calling `pip`\n\n     - for `pytorch-lightning` use `export PACKAGE_NAME=pytorch ; pip install .`\n     - for `lightning-fabric` use `export PACKAGE_NAME=fabric ; pip install .`\n\n3. Building packages as sdist or binary wheel and installing or publish to PyPI afterwords you use command\n    `python setup.py sdist` or `python setup.py bdist_wheel` accordingly.\n   In case you want to build just a particular package you want to set an environment variable:\n   `PACKAGE_NAME=lightning|pytorch|fabric python setup.py sdist|bdist_wheel`\n\n4. Automated releasing with GitHub action is natural extension of 3) is composed of three consecutive steps:\n    a) determine which packages shall be released based on version increment in `__version__.py` and eventually\n     compared against PyPI registry\n    b) with a parameterization build desired packages in to standard `dist/` folder\n    c) validate packages and publish to PyPI\n\n\"\"\"\n\nimport contextlib\nimport glob\nimport logging\nimport os\nimport tempfile\nfrom collections.abc import Generator, Mapping\nfrom importlib.util import module_from_spec, spec_from_file_location\nfrom types import ModuleType\nfrom typing import Optional\n\nimport setuptools\nimport setuptools.command.egg_info\n\n_PACKAGE_NAME = os.environ.get(\"PACKAGE_NAME\")\n_PACKAGE_MAPPING = {\n    \"lightning\": \"lightning\",\n    \"pytorch\": \"pytorch_lightning\",\n    \"fabric\": \"lightning_fabric\",\n}\n# https://packaging.python.org/guides/single-sourcing-package-version/\n# http://blog.ionelmc.ro/2014/05/25/python-packaging/\n_PATH_ROOT = os.path.dirname(__file__)\n_PATH_SRC = os.path.join(_PATH_ROOT, \"src\")\n_PATH_REQUIRE = os.path.join(_PATH_ROOT, \"requirements\")\n_FREEZE_REQUIREMENTS = os.environ.get(\"FREEZE_REQUIREMENTS\", \"0\").lower() in (\"1\", \"true\")\n\n\ndef _load_py_module(name: str, location: str) -> ModuleType:\n    spec = spec_from_file_location(name, location)\n    assert spec, f\"Failed to load module {name} from {location}\"\n    py = module_from_spec(spec)\n    assert spec.loader, f\"ModuleSpec.loader is None for {name} from {location}\"\n    spec.loader.exec_module(py)\n    return py\n\n\ndef _named_temporary_file(directory: Optional[str] = None) -> str:\n    # `tempfile.NamedTemporaryFile` has issues in Windows\n    # https://github.com/deepchem/deepchem/issues/707#issuecomment-556002823\n    if directory is None:\n        directory = tempfile.gettempdir()\n    return os.path.join(directory, os.urandom(24).hex())\n\n\n@contextlib.contextmanager\ndef _set_manifest_path(manifest_dir: str, aggregate: bool = False, mapping: Mapping = _PACKAGE_MAPPING) -> Generator:\n    if aggregate:\n        # aggregate all MANIFEST.in contents into a single temporary file\n        manifest_path = _named_temporary_file(manifest_dir)\n        lines = []\n        # load manifest and aggregated all manifests\n        for pkg in mapping.values():\n            pkg_manifest = os.path.join(_PATH_SRC, pkg, \"MANIFEST.in\")\n            if os.path.isfile(pkg_manifest):\n                with open(pkg_manifest) as fh:\n                    lines.extend(fh.readlines())\n        # convert lightning_foo to lightning/foo\n        for new, old in mapping.items():\n            if old == \"lightning\":\n                continue  # avoid `lightning` -> `lightning/lightning`\n            lines = [ln.replace(old, f\"lightning/{new}\") for ln in lines]\n        lines = sorted(set(filter(lambda ln: not ln.strip().startswith(\"#\"), lines)))\n        logging.debug(f\"aggregated manifest consists of: {lines}\")\n        with open(manifest_path, mode=\"w\") as fp:\n            fp.writelines(lines)\n    else:\n        manifest_path = os.path.join(manifest_dir, \"MANIFEST.in\")\n        assert os.path.exists(manifest_path)\n    # avoid error: setup script specifies an absolute path\n    manifest_path = os.path.relpath(manifest_path, _PATH_ROOT)\n    logging.info(\"Set manifest path to\", manifest_path)\n    setuptools.command.egg_info.manifest_maker.template = manifest_path\n    yield\n    # cleanup\n    setuptools.command.egg_info.manifest_maker.template = \"MANIFEST.in\"\n    if aggregate:\n        os.remove(manifest_path)\n\n\nif __name__ == \"__main__\":\n    assistant = _load_py_module(name=\"assistant\", location=os.path.join(_PATH_ROOT, \".actions\", \"assistant.py\"))\n\n    if os.path.isdir(_PATH_SRC):\n        # copy the version information to all packages\n        assistant.distribute_version(_PATH_SRC)\n    print(f\"Requested package: '{_PACKAGE_NAME}'\")  # requires `-v` to appear\n\n    local_pkgs = [\n        os.path.basename(p)\n        for p in glob.glob(os.path.join(_PATH_SRC, \"*\"))\n        if os.path.isdir(p) and not p.endswith(\".egg-info\")\n    ]\n    print(f\"Local package candidates: {local_pkgs}\")\n    is_source_install = len(local_pkgs) > 2\n    print(f\"Installing from source: {is_source_install}\")\n    if is_source_install:\n        if _PACKAGE_NAME is not None and _PACKAGE_NAME not in _PACKAGE_MAPPING:\n            raise ValueError(\n                f\"Unexpected package name: {_PACKAGE_NAME}. Possible choices are: {list(_PACKAGE_MAPPING)}\"\n            )\n        package_to_install = _PACKAGE_MAPPING.get(_PACKAGE_NAME, \"lightning\")\n        if package_to_install == \"lightning\":\n            # merge all requirements files\n            assistant._load_aggregate_requirements(_PATH_REQUIRE, _FREEZE_REQUIREMENTS)\n        else:\n            # replace imports and copy the code\n            assistant.create_mirror_package(_PATH_SRC, _PACKAGE_MAPPING)\n    else:\n        assert len(local_pkgs) > 0\n        # PL as a package is distributed together with Fabric, so in such case there are more than one candidate\n        package_to_install = \"pytorch_lightning\" if \"pytorch_lightning\" in local_pkgs else local_pkgs[0]\n    print(f\"Installing package: {package_to_install}\")\n\n    # going to install with `setuptools.setup`\n    pkg_path = os.path.join(_PATH_SRC, package_to_install)\n    pkg_setup = os.path.join(pkg_path, \"__setup__.py\")\n    if not os.path.exists(pkg_setup):\n        raise RuntimeError(f\"Something's wrong, no package was installed. Package name: {_PACKAGE_NAME}\")\n    setup_module = _load_py_module(name=f\"{package_to_install}_setup\", location=pkg_setup)\n    setup_args = setup_module._setup_args()\n    is_main_pkg = package_to_install == \"lightning\"\n    print(f\"Installing as the main package: {is_main_pkg}\")\n    if is_source_install:\n        # we are installing from source, set the correct manifest path\n        with _set_manifest_path(pkg_path, aggregate=is_main_pkg):\n            setuptools.setup(**setup_args)\n    else:\n        setuptools.setup(**setup_args)\n    print(\"Finished setup configuration.\")\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}