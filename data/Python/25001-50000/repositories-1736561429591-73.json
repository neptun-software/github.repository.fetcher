{
  "metadata": {
    "timestamp": 1736561429591,
    "page": 73,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "explosion/spaCy",
      "stars": 30631,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.1513671875,
          "content": "# spaCy\nspacy/data/\ncorpora/\n/models/\nkeys/\n*.json.gz\n\n# Tests\nspacy/tests/package/setup.cfg\nspacy/tests/package/pyproject.toml\nspacy/tests/package/requirements.txt\n\n# Cython / C extensions\ncythonize.json\nspacy/*.html\n*.cpp\n*.c\n*.so\n\n# Vim / VSCode / editors\n*.swp\n*.sw*\nProfile.prof\n.vscode\n.sass-cache\n\n# Python\n.Python\n.python-version\n__pycache__/\n.pytest_cache\n*.py[cod]\n.env/\n.env*\n.~env/\n.venv\nenv3.6/\nvenv/\nenv3.*/\n.dev\n.denv\n.pypyenv\n.pytest_cache/\n.mypy_cache/\n.hypothesis/\n\n# Distribution / packaging\nenv/\nbuild/\ndevelop-eggs/\ndist/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheelhouse/\n*.egg-info/\npip-wheel-metadata/\nPipfile.lock\n.installed.cfg\n*.egg\n.eggs\nMANIFEST\nspacy/git_info.py\n\n# Temporary files\n*.~*\ntmp/\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n\n# Mr Developer\n.mr.developer.cfg\n.project\n.pydevproject\n\n# Rope\n.ropeproject\n\n# Django stuff:\n*.log\n*.pot\n\n# Windows\n*.bat\nThumbs.db\nDesktop.ini\n\n# Mac OS X\n*.DS_Store\n\n# Komodo project files\n*.komodoproject\n\n# Other\n*.tgz\n\n# Pycharm project files\n*.idea\n\n# IPython\n.ipynb_checkpoints/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.29296875,
          "content": "repos:\n-   repo: https://github.com/ambv/black\n    rev: 22.3.0\n    hooks:\n    - id: black\n      language_version: python3.7\n      additional_dependencies: ['click==8.0.4']\n-   repo: https://github.com/pycqa/flake8\n    rev: 5.0.4\n    hooks:\n    - id: flake8\n      args:\n        - \"--config=setup.cfg\"\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.451171875,
          "content": "cff-version: 1.2.0\npreferred-citation:\n  type: article\n  message: \"If you use spaCy, please cite it as below.\"\n  authors:\n  - family-names: \"Honnibal\"\n    given-names: \"Matthew\"\n  - family-names: \"Montani\"\n    given-names: \"Ines\"\n  - family-names: \"Van Landeghem\"\n    given-names: \"Sofie\"\n  - family-names: \"Boyd\"\n    given-names: \"Adriane\"\n  title: \"spaCy: Industrial-strength Natural Language Processing in Python\"\n  doi: \"10.5281/zenodo.1212303\"\n  year: 2020\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 23.60546875,
          "content": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# Contribute to spaCy\n\nThanks for your interest in contributing to spaCy üéâ This page will give you a quick\noverview of how things are organized and most importantly, how to get involved.\n\n## Table of contents\n\n1. [Issues and bug reports](#issues-and-bug-reports)\n2. [Contributing to the code base](#contributing-to-the-code-base)\n3. [Code conventions](#code-conventions)\n4. [Adding tests](#adding-tests)\n5. [Updating the website](#updating-the-website)\n6. [Publishing extensions and plugins](#publishing-spacy-extensions-and-plugins)\n7. [Code of conduct](#code-of-conduct)\n\n## Issues and bug reports\n\nFirst, [do a quick search](https://github.com/issues?q=+is%3Aissue+user%3Aexplosion)\nto see if the issue has already been reported. If so, it's often better to just\nleave a comment on an existing issue, rather than creating a new one. Old issues\nalso often include helpful tips and solutions to common problems. You should\nalso check the [troubleshooting guide](https://spacy.io/usage/#troubleshooting)\nto see if your problem is already listed there.\n\nIf you're looking for help with your code, consider posting a question on the\n[GitHub Discussions board](https://github.com/explosion/spaCy/discussions) or\n[Stack Overflow](http://stackoverflow.com/questions/tagged/spacy). Please\nunderstand that we won't be able to provide individual support via email. We\nalso believe that help is much more valuable if it's **shared publicly**,\nso that more people can benefit from it.\n\n### Submitting issues\n\nWhen opening an issue, use a **descriptive title** and include your\n**environment** (operating system, Python version, spaCy version). Our\n[issue templates](https://github.com/explosion/spaCy/issues/new/choose) help you\nremember the most important details to include. If you've discovered a bug, you\ncan also submit a [regression test](#fixing-bugs) straight away. When you're\nopening an issue to report the bug, simply refer to your pull request in the\nissue body. A few more tips:\n\n- **Describing your issue:** Try to provide as many details as possible. What\n  exactly goes wrong? _How_ is it failing? Is there an error?\n  \"XY doesn't work\" usually isn't that helpful for tracking down problems. Always\n  remember to include the code you ran and if possible, extract only the relevant\n  parts and don't just dump your entire script. This will make it easier for us to\n  reproduce the error.\n\n- **Getting info about your spaCy installation and environment:** You can use the command line interface to print details and\n  even format them as Markdown to copy-paste into GitHub issues:\n  `python -m spacy info --markdown`.\n\n- **Checking the model compatibility:** If you're having problems with a\n  [statistical model](https://spacy.io/models), it may be because the\n  model is incompatible with your spaCy installation. In spaCy v2.0+, you can check\n  this on the command line by running `python -m spacy validate`.\n\n- **Sharing a model's output, like dependencies and entities:** spaCy\n  comes with [built-in visualizers](https://spacy.io/usage/visualizers) that\n  you can run from within your script or a Jupyter notebook. For some issues, it's\n  helpful to **include a screenshot** of the visualization. You can simply drag and\n  drop the image into GitHub's editor and it will be uploaded and included.\n\n- **Sharing long blocks of code or logs:** If you need to include long code,\n  logs or tracebacks, you can wrap them in `<details>` and `</details>`. This\n  [collapses the content](https://developer.mozilla.org/en/docs/Web/HTML/Element/details)\n  so it only becomes visible on click, making the issue easier to read and follow.\n\n### Issue labels\n\n[See this page](https://github.com/explosion/spaCy/labels) for an overview of\nthe system we use to tag our issues and pull requests.\n\n## Contributing to the code base\n\nYou don't have to be an NLP expert or Python pro to contribute, and we're happy\nto help you get started. If you're new to spaCy, a good place to start is the\n[spaCy 101 guide](https://spacy.io/usage/spacy-101) and the\n[`help wanted (easy)`](https://github.com/explosion/spaCy/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted+%28easy%29%22)\nlabel, which we use to tag bugs and feature requests that are easy and\nself-contained. If you've decided to take on one of these problems and you're\nmaking good progress, don't forget to add a quick comment to the issue. You can\nalso use the issue to ask questions, or share your work in progress.\n\n### What belongs in spaCy?\n\nEvery library has a different inclusion philosophy ‚Äî a policy of what should be\nshipped in the core library, and what could be provided in other packages. Our\nphilosophy is to prefer a smaller core library. We generally ask the following\nquestions:\n\n- **What would this feature look like if implemented in a separate package?**\n  Some features would be very difficult to implement externally ‚Äì for example,\n  changes to spaCy's built-in methods. In contrast, a library of word\n  alignment functions could easily live as a separate package that depended on\n  spaCy ‚Äî there's little difference between writing `import word_aligner` and\n  `import spacy.word_aligner`. spaCy makes it easy to implement\n  [custom pipeline components](https://spacy.io/usage/processing-pipelines#custom-components),\n  and add your own attributes, properties and methods to the `Doc`, `Token` and\n  `Span`. If you're looking to implement a new spaCy feature, starting with a\n  custom component package is usually the best strategy. You won't have to worry\n  about spaCy's internals and you can test your module in an isolated\n  environment. And if it works well, we can always integrate it into the core\n  library later.\n\n- **Would the feature be easier to implement if it relied on \"heavy\" dependencies spaCy doesn't currently require?**\n  Python has a very rich ecosystem. Libraries like PyTorch, TensorFlow, scikit-learn, SciPy or Gensim\n  do lots of useful things ‚Äî but we don't want to have them as default\n  dependencies. If the feature requires functionality in one of these libraries,\n  it's probably better to break it out into a different package.\n\n- **Is the feature orthogonal to the current spaCy functionality, or overlapping?**\n  spaCy strongly prefers to avoid having 6 different ways of doing the same thing.\n  As better techniques are developed, we prefer to drop support for \"the old way\".\n  However, it's rare that one approach _entirely_ dominates another. It's very\n  common that there's still a use-case for the \"obsolete\" approach. For instance,\n  [WordNet](https://wordnet.princeton.edu/) is still very useful ‚Äî but word\n  vectors are better for most use-cases, and the two approaches to lexical\n  semantics do a lot of the same things. spaCy therefore only supports word\n  vectors, and support for WordNet is currently left for other packages.\n\n- **Do you need the feature to get basic things done?** We do want spaCy to be\n  at least somewhat self-contained. If we keep needing some feature in our\n  recipes, that does provide some argument for bringing it \"in house\".\n\n### Getting started\n\nTo make changes to spaCy's code base, you need to fork then clone the GitHub repository\nand build spaCy from source. You'll need to make sure that you have a\ndevelopment environment consisting of a Python distribution including header\nfiles, a compiler, [pip](https://pip.pypa.io/en/latest/installing/),\n[virtualenv](https://virtualenv.pypa.io/en/stable/) and\n[git](https://git-scm.com) installed. The compiler is usually the trickiest part.\n\nIf you've made changes to `.pyx` files, you need to **recompile spaCy** before you\ncan test your changes by re-running `python setup.py build_ext --inplace`.\nChanges to `.py` files will be effective immediately.\n\nüìñ **For more details and instructions, see the documentation on [compiling spaCy from source](https://spacy.io/usage/#source) and the [quickstart widget](https://spacy.io/usage/#section-quickstart) to get the right commands for your platform and Python version.**\n\n### Fixing bugs\n\nWhen fixing a bug, first create an\n[issue](https://github.com/explosion/spaCy/issues) if one does not already\nexist. The description text can be very short ‚Äì we don't want to make this too\nbureaucratic.\n\nNext, add a test to the relevant file in the\n[`spacy/tests`](spacy/tests)folder. Then add a [pytest\nmark](https://docs.pytest.org/en/6.2.x/example/markers.html#working-with-custom-markers),\n`@pytest.mark.issue(NUMBER)`, to reference the issue number.\n\n```python\n# Assume you're fixing Issue #1234\n@pytest.mark.issue(1234)\ndef test_issue1234():\n    ...\n```\n\nTest for the bug you're fixing, and make sure the test fails. Next, add and\ncommit your test file. Finally, fix the bug, make sure your test passes and\nreference the issue number in your pull request description.\n\nüìñ **For more information on how to add tests, check out the [tests README](spacy/tests/README.md).**\n\n## Code conventions\n\nCode should loosely follow [pep8](https://www.python.org/dev/peps/pep-0008/).\nspaCy uses [`black`](https://github.com/ambv/black) for code\nformatting and [`flake8`](http://flake8.pycqa.org/en/latest/) for linting its\nPython modules. If you've built spaCy from source, you'll already have both\ntools installed.\n\nAs a general rule of thumb, we use f-strings for any formatting of strings.\nOne exception are calls to Python's `logging` functionality.\nTo avoid unnecessary string conversions in these cases, we use string formatting\ntemplates with `%s` and `%d` etc.\n\n**‚ö†Ô∏è Note that formatting and linting is currently only possible for Python\nmodules in `.py` files, not Cython modules in `.pyx` and `.pxd` files.**\n\n### Pre-Commit Hooks\n\nAfter cloning the repo, after installing the packages from `requirements.txt`, enter the repo folder and run `pre-commit install`.\nEach time a `git commit` is initiated, `black` and `flake8` will run automatically on the modified files only.\n\nIn case of error, or when `black` modified a file, the modified file needs to be `git add` once again and a new\n`git commit` has to be issued.\n\n### Code formatting\n\n[`black`](https://github.com/ambv/black) is an opinionated Python code\nformatter, optimized to produce readable code and small diffs. You can run\n`black` from the command-line, or via your code editor. For example, if you're\nusing [Visual Studio Code](https://code.visualstudio.com/), you can add the\nfollowing to your `settings.json` to use `black` for formatting and auto-format\nyour files on save:\n\n```json\n{\n  \"python.formatting.provider\": \"black\",\n  \"[python]\": {\n    \"editor.formatOnSave\": true\n  }\n}\n```\n\n[See here](https://github.com/ambv/black#editor-integration) for the full\nlist of available editor integrations.\n\n#### Disabling formatting\n\nThere are a few cases where auto-formatting doesn't improve readability ‚Äì for\nexample, in some of the language data files or in the tests that construct `Doc` objects from lists of words and other labels.\nWrapping a block in `# fmt: off` and `# fmt: on` lets you disable formatting\nfor that particular code. Here's an example:\n\n```python\n# fmt: off\ntext = \"I look forward to using Thingamajig.  I've been told it will make my life easier...\"\nheads = [1, 1, 1, 1, 3, 4, 1, 6, 11, 11, 11, 11, 14, 14, 11, 16, 17, 14, 11]\ndeps = [\"nsubj\", \"ROOT\", \"advmod\", \"prep\", \"pcomp\", \"dobj\", \"punct\", \"\",\n        \"nsubjpass\", \"aux\", \"auxpass\", \"ROOT\", \"nsubj\", \"aux\", \"ccomp\",\n        \"poss\", \"nsubj\", \"ccomp\", \"punct\"]\n# fmt: on\n```\n\n### Code linting\n\n[`flake8`](http://flake8.pycqa.org/en/latest/) is a tool for enforcing code\nstyle. It scans one or more files and outputs errors and warnings. This feedback\ncan help you stick to general standards and conventions, and can be very useful\nfor spotting potential mistakes and inconsistencies in your code. The most\nimportant things to watch out for are syntax errors and undefined names, but you\nalso want to keep an eye on unused declared variables or repeated\n(i.e. overwritten) dictionary keys. If your code was formatted with `black`\n(see above), you shouldn't see any formatting-related warnings.\n\nThe `flake8` section in [`setup.cfg`](setup.cfg) defines the configuration we use for this\ncodebase. For example, we're not super strict about the line length, and we're\nexcluding very large files like lemmatization and tokenizer exception tables.\n\nIdeally, running the following command from within the repo directory should\nnot return any errors or warnings:\n\n```bash\nflake8 spacy\n```\n\n#### Disabling linting\n\nSometimes, you explicitly want to write code that's not compatible with our\nrules. For example, a module's `__init__.py` might import a function so other\nmodules can import it from there, but `flake8` will complain about an unused\nimport. And although it's generally discouraged, there might be cases where it\nmakes sense to use a bare `except`.\n\nTo ignore a given line, you can add a comment like `# noqa: F401`, specifying\nthe code of the error or warning we want to ignore. It's also possible to\nignore several comma-separated codes at once, e.g. `# noqa: E731,E123`. Here\nare some examples:\n\n```python\n# The imported class isn't used in this file, but imported here, so it can be\n# imported *from* here by another module.\nfrom .submodule import SomeClass  # noqa: F401\n\ntry:\n    do_something()\nexcept:  # noqa: E722\n    # This bare except is justified, for some specific reason\n    do_something_else()\n```\n\n### Python conventions\n\nAll Python code must be written **compatible with Python 3.6+**. More detailed\ncode conventions can be found in the [developer docs](https://github.com/explosion/spaCy/blob/master/extra/DEVELOPER_DOCS/Code%20Conventions.md).\n\n#### I/O and handling paths\n\nCode that interacts with the file-system should accept objects that follow the\n`pathlib.Path` API, without assuming that the object inherits from `pathlib.Path`.\nIf the function is user-facing and takes a path as an argument, it should check\nwhether the path is provided as a string. Strings should be converted to\n`pathlib.Path` objects. Serialization and deserialization functions should always\naccept **file-like objects**, as it makes the library IO-agnostic. Working on\nbuffers makes the code more general, easier to test, and compatible with Python\n3's asynchronous IO.\n\n#### Composition vs. inheritance\n\nAlthough spaCy uses a lot of classes, **inheritance is viewed with some suspicion**\n‚Äî it's seen as a mechanism of last resort. You should discuss plans to extend\nthe class hierarchy before implementing.\n\n#### Naming conventions\n\nWe have a number of conventions around variable naming that are still being\ndocumented, and aren't 100% strict. A general policy is that instances of the\nclass `Doc` should by default be called `doc`, `Token` &rarr; `token`, `Lexeme` &rarr; `lex`,\n`Vocab` &rarr; `vocab` and `Language` &rarr; `nlp`. You should avoid naming variables that are\nof other types these names. For instance, don't name a text string `doc` ‚Äî you\nshould usually call this `text`. Two general code style preferences further help\nwith naming. First, **lean away from introducing temporary variables**, as these\nclutter your namespace. This is one reason why comprehension expressions are\noften preferred. Second, **keep your functions shortish**, so they can work in a\nsmaller scope. Of course, this is a question of trade-offs.\n\n### Cython conventions\n\nspaCy's core data structures are implemented as [Cython](http://cython.org/) `cdef`\nclasses. Memory is managed through the `cymem.cymem.Pool` class, which allows\nyou to allocate memory which will be freed when the `Pool` object is garbage\ncollected. This means you usually don't have to worry about freeing memory. You\njust have to decide which Python object owns the memory, and make it own the\n`Pool`. When that object goes out of scope, the memory will be freed. You do\nhave to take care that no pointers outlive the object that owns them ‚Äî but this\nis generally quite easy.\n\nAll Cython modules should have the `# cython: infer_types=True` compiler\ndirective at the top of the file. This makes the code much cleaner, as it avoids\nthe need for many type declarations. If possible, you should prefer to declare\nyour functions `nogil`, even if you don't especially care about multi-threading.\nThe reason is that `nogil` functions help the Cython compiler reason about your\ncode quite a lot ‚Äî you're telling the compiler that no Python dynamics are\npossible. This lets many errors be raised, and ensures your function will run\nat C speed.\n\nCython gives you many choices of sequences: you could have a Python list, a\nnumpy array, a memory view, a C++ vector, or a pointer. Pointers are preferred,\nbecause they are fastest, have the most explicit semantics, and let the compiler\ncheck your code more strictly. C++ vectors are also great ‚Äî but you should only\nuse them internally in functions. It's less friendly to accept a vector as an\nargument, because that asks the user to do much more work.\n\nHere's how to get a pointer from a numpy array, memory view or vector:\n\n```cython\ncdef void get_pointers(np.ndarray[int, mode='c'] numpy_array, vector[int] cpp_vector, int[::1] memory_view) nogil:\n    pointer1 = <int*>numpy_array.data\n    pointer2 = cpp_vector.data()\n    pointer3 = &memory_view[0]\n```\n\nBoth C arrays and C++ vectors reassure the compiler that no Python operations\nare possible on your variable. This is a big advantage: it lets the Cython\ncompiler raise many more errors for you.\n\nWhen getting a pointer from a numpy array or memoryview, take care that the data\nis actually stored in C-contiguous order ‚Äî otherwise you'll get a pointer to\nnonsense. The type-declarations in the code above should generate runtime errors\nif buffers with incorrect memory layouts are passed in.\n\nTo iterate over the array, the following style is preferred:\n\n```cython\ncdef int c_total(const int* int_array, int length) nogil:\n    total = 0\n    for item in int_array[:length]:\n        total += item\n    return total\n```\n\nIf this is confusing, consider that the compiler couldn't deal with\n`for item in int_array:` ‚Äî there's no length attached to a raw pointer, so how\ncould we figure out where to stop? The length is provided in the slice notation\nas a solution to this. Note that we don't have to declare the type of `item` in\nthe code above ‚Äî the compiler can easily infer it. This gives us tidy code that\nlooks quite like Python, but is exactly as fast as C ‚Äî because we've made sure\nthe compilation to C is trivial.\n\nYour functions cannot be declared `nogil` if they need to create Python objects\nor call Python functions. This is perfectly okay ‚Äî you shouldn't torture your\ncode just to get `nogil` functions. However, if your function isn't `nogil`, you\nshould compile your module with `cython -a --cplus my_module.pyx` and open the\nresulting `my_module.html` file in a browser. This will let you see how Cython\nis compiling your code. Calls into the Python run-time will be in bright yellow.\nThis lets you easily see whether Cython is able to correctly type your code, or\nwhether there are unexpected problems.\n\nFinally, if you're new to Cython, you should expect to find the first steps a\nbit frustrating. It's a very large language, since it's essentially a superset\nof Python and C++, with additional complexity and syntax from numpy. The\n[documentation](http://docs.cython.org/en/latest/) isn't great, and there are\nmany \"traps for new players\". Working in Cython is very rewarding once you're\nover the initial learning curve. As with C and C++, the first way you write\nsomething in Cython will often be the performance-optimal approach. In contrast,\nPython optimization generally requires a lot of experimentation. Is it faster to\nhave an `if item in my_dict` check, or to use `.get()`? What about `try`/`except`?\nDoes this numpy operation create a copy? There's no way to guess the answers to\nthese questions, and you'll usually be dissatisfied with your results ‚Äî so\nthere's no way to know when to stop this process. In the worst case, you'll make\na mess that invites the next reader to try their luck too. This is like one of\nthose [volcanic gas-traps](http://www.wemjournal.org/article/S1080-6032%2809%2970088-2/abstract),\nwhere the rescuers keep passing out from low oxygen, causing another rescuer to\nfollow ‚Äî only to succumb themselves. In short, just say no to optimizing your\nPython. If it's not fast enough the first time, just switch to Cython.\n\n### Resources to get you started\n\n- [PEP 8 Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/) (python.org)\n- [Official Cython documentation](http://docs.cython.org/en/latest/) (cython.org)\n- [Writing C in Cython](https://explosion.ai/blog/writing-c-in-cython) (explosion.ai)\n- [Multi-threading spaCy‚Äôs parser and named entity recognizer](https://explosion.ai/blog/multithreading-with-cython) (explosion.ai)\n\n## Adding tests\n\nspaCy uses the [pytest](http://doc.pytest.org/) framework for testing. For more\ninfo on this, see the [pytest documentation](http://docs.pytest.org/en/latest/contents.html).\nTests for spaCy modules and classes live in their own directories of the same\nname. For example, tests for the `Tokenizer` can be found in\n[`/spacy/tests/tokenizer`](spacy/tests/tokenizer). To be interpreted and run,\nall test files and test functions need to be prefixed with `test_`.\n\nWhen adding tests, make sure to use descriptive names, keep the code short and\nconcise and only test for one behavior at a time. Try to `parametrize` test\ncases wherever possible, use our pre-defined fixtures for spaCy components and\navoid unnecessary imports. Extensive tests that take a long time should be marked with `@pytest.mark.slow`.\n\nüìñ **For more guidelines and information on how to add tests, check out the [tests README](spacy/tests/README.md).**\n\n## Updating the website\n\nFor instructions on how to build and run the [website](https://spacy.io) locally see **[Setup and installation](https://github.com/explosion/spaCy/blob/master/website/README.md#setup-and-installation-setup)** in the _website_ directory's README.\n\nThe docs can always use another example or more detail, and they should always\nbe up to date and not misleading. To quickly find the correct file to edit,\nsimply click on the \"Suggest edits\" button at the bottom of a page.\n\nüìñ **For more info and troubleshooting guides, check out the [website README](website).**\n\n## Publishing spaCy extensions and plugins\n\nWe're very excited about all the new possibilities for **community extensions**\nand plugins in spaCy v3.0, and we can't wait to see what you build with it!\n\n- An extension or plugin should add substantial functionality, be\n  **well-documented** and **open-source**. It should be available for users to download\n  and install as a Python package ‚Äì for example via [PyPi](http://pypi.python.org).\n\n- Extensions that write to `Doc`, `Token` or `Span` attributes should be wrapped\n  as [pipeline components](https://spacy.io/usage/processing-pipelines#custom-components)\n  that users can **add to their processing pipeline** using `nlp.add_pipe()`.\n\n- When publishing your extension on GitHub, **tag it** with the topics\n  [`spacy`](https://github.com/topics/spacy?o=desc&s=stars) and\n  [`spacy-extensions`](https://github.com/topics/spacy-extension?o=desc&s=stars)\n  to make it easier to find. Those are also the topics we're linking to from the\n  spaCy website. If you're sharing your project on Twitter, feel free to tag\n  [@spacy_io](https://twitter.com/spacy_io) so we can check it out.\n\n- Once your extension is published, you can open a\n  [PR](https://github.com/explosion/spaCy/pulls) to suggest it for the\n  [Universe](https://spacy.io/universe) page.\n\nüìñ **For more tips and best practices, see the [checklist for developing spaCy extensions](https://spacy.io/usage/processing-pipelines#extensions).**\n\n## Code of conduct\n\nspaCy adheres to the\n[Contributor Covenant Code of Conduct](http://contributor-covenant.org/version/1/4/).\nBy participating, you are expected to uphold this code.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.1015625,
          "content": "The MIT License (MIT)\n\nCopyright (C) 2016-2024 ExplosionAI GmbH, 2016 spaCy GmbH, 2015 Matthew Honnibal\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.2412109375,
          "content": "recursive-include spacy *.pyi *.pyx *.pxd *.txt *.cfg *.jinja *.toml *.hh\ninclude LICENSE\ninclude README.md\ninclude pyproject.toml\ninclude spacy/py.typed\nrecursive-include spacy/cli *.yml\nrecursive-include licenses *\nrecursive-exclude spacy *.cpp\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.4765625,
          "content": "SHELL := /bin/bash\n\nifndef SPACY_EXTRAS\noverride SPACY_EXTRAS = spacy-lookups-data==1.0.3\nendif\n\nifndef PYVER\noverride PYVER = 3.8\nendif\n\nVENV := ./env$(PYVER)\n\nversion := $(shell \"bin/get-version.sh\")\npackage := $(shell \"bin/get-package.sh\")\n\nifndef SPACY_BIN\noverride SPACY_BIN = $(package)-$(version).pex\nendif\n\nifndef WHEELHOUSE\noverride WHEELHOUSE = \"./wheelhouse\"\nendif\n\n\ndist/$(SPACY_BIN) : $(WHEELHOUSE)/spacy-$(PYVER)-$(version).stamp\n\t$(VENV)/bin/pex \\\n\t\t-f $(WHEELHOUSE) \\\n\t\t--no-index \\\n\t\t--disable-cache \\\n\t\t-o $@ \\\n\t\t$(package)==$(version) \\\n\t\t$(SPACY_EXTRAS)\n\tchmod a+rx $@\n\tcp $@ dist/spacy.pex\n\ndist/pytest.pex : $(WHEELHOUSE)/pytest-*.whl\n\t$(VENV)/bin/pex -f $(WHEELHOUSE) --no-index --disable-cache -m pytest -o $@ pytest pytest-timeout mock\n\tchmod a+rx $@\n\n$(WHEELHOUSE)/spacy-$(PYVER)-$(version).stamp : $(VENV)/bin/pex setup.py spacy/*.py* spacy/*/*.py*\n\t$(VENV)/bin/pip wheel . -w $(WHEELHOUSE)\n\t$(VENV)/bin/pip wheel $(SPACY_EXTRAS) -w $(WHEELHOUSE)\n\n\ttouch $@\n\n$(WHEELHOUSE)/pytest-%.whl : $(VENV)/bin/pex\n\t$(VENV)/bin/pip wheel pytest pytest-timeout mock -w $(WHEELHOUSE)\n\n$(VENV)/bin/pex :\n\tpython$(PYVER) -m venv $(VENV)\n\t$(VENV)/bin/pip install -U pip setuptools pex wheel\n\t$(VENV)/bin/pip install numpy\n\n.PHONY : clean test\n\ntest : dist/spacy-$(version).pex dist/pytest.pex\n\t( . $(VENV)/bin/activate ; \\\n\tPEX_PATH=dist/spacy-$(version).pex ./dist/pytest.pex --pyargs spacy -x ; )\n\nclean : setup.py\n\trm -rf dist/*\n\trm -rf $(WHEELHOUSE)/*\n\trm -rf $(VENV)\n\tpython setup.py clean --all\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.619140625,
          "content": "<a href=\"https://explosion.ai\"><img src=\"https://explosion.ai/assets/img/logo.svg\" width=\"125\" height=\"125\" align=\"right\" /></a>\n\n# spaCy: Industrial-strength NLP\n\nspaCy is a library for **advanced Natural Language Processing** in Python and\nCython. It's built on the very latest research, and was designed from day one to\nbe used in real products.\n\nspaCy comes with [pretrained pipelines](https://spacy.io/models) and currently\nsupports tokenization and training for **70+ languages**. It features\nstate-of-the-art speed and **neural network models** for tagging, parsing,\n**named entity recognition**, **text classification** and more, multi-task\nlearning with pretrained **transformers** like BERT, as well as a\nproduction-ready [**training system**](https://spacy.io/usage/training) and easy\nmodel packaging, deployment and workflow management. spaCy is commercial\nopen-source software, released under the\n[MIT license](https://github.com/explosion/spaCy/blob/master/LICENSE).\n\nüí´ **Version 3.7 out now!**\n[Check out the release notes here.](https://github.com/explosion/spaCy/releases)\n\n[![tests](https://github.com/explosion/spaCy/actions/workflows/tests.yml/badge.svg)](https://github.com/explosion/spaCy/actions/workflows/tests.yml)\n[![Current Release Version](https://img.shields.io/github/release/explosion/spacy.svg?style=flat-square&logo=github)](https://github.com/explosion/spaCy/releases)\n[![pypi Version](https://img.shields.io/pypi/v/spacy.svg?style=flat-square&logo=pypi&logoColor=white)](https://pypi.org/project/spacy/)\n[![conda Version](https://img.shields.io/conda/vn/conda-forge/spacy.svg?style=flat-square&logo=conda-forge&logoColor=white)](https://anaconda.org/conda-forge/spacy)\n[![Python wheels](https://img.shields.io/badge/wheels-%E2%9C%93-4c1.svg?longCache=true&style=flat-square&logo=python&logoColor=white)](https://github.com/explosion/wheelwright/releases)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg?style=flat-square)](https://github.com/ambv/black)\n<br />\n[![PyPi downloads](https://static.pepy.tech/personalized-badge/spacy?period=total&units=international_system&left_color=grey&right_color=orange&left_text=pip%20downloads)](https://pypi.org/project/spacy/)\n[![Conda downloads](https://img.shields.io/conda/dn/conda-forge/spacy?label=conda%20downloads)](https://anaconda.org/conda-forge/spacy)\n[![spaCy on Twitter](https://img.shields.io/twitter/follow/spacy_io.svg?style=social&label=Follow)](https://twitter.com/spacy_io)\n\n## üìñ Documentation\n\n| Documentation                                                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                              |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| ‚≠êÔ∏è **[spaCy 101]**                                                                                                                                                                                                       | New to spaCy? Here's everything you need to know!                                                                                                                                                                                                                                                                                            |\n| üìö **[Usage Guides]**                                                                                                                                                                                                     | How to use spaCy and its features.                                                                                                                                                                                                                                                                                                           |\n| üöÄ **[New in v3.0]**                                                                                                                                                                                                      | New features, backwards incompatibilities and migration guide.                                                                                                                                                                                                                                                                               |\n| ü™ê **[Project Templates]**                                                                                                                                                                                                | End-to-end workflows you can clone, modify and run.                                                                                                                                                                                                                                                                                          |\n| üéõ **[API Reference]**                                                                                                                                                                                                     | The detailed reference for spaCy's API.                                                                                                                                                                                                                                                                                                      |\n| ‚è© **[GPU Processing]**                                                                                                                                                                                                    | Use spaCy with CUDA-compatible GPU processing.                                                                                                                                                                                                                                                                                               |\n| üì¶ **[Models]**                                                                                                                                                                                                           | Download trained pipelines for spaCy.                                                                                                                                                                                                                                                                                                        |\n| ü¶ô **[Large Language Models]**                                                                                                                                                                                            | Integrate LLMs into spaCy pipelines.                                                                                                                                                                                                                                                                                                        |\n| üåå **[Universe]**                                                                                                                                                                                                         | Plugins, extensions, demos and books from the spaCy ecosystem.                                                                                                                                                                                                                                                                               |\n| ‚öôÔ∏è **[spaCy VS Code Extension]**                                                                                                                                                                                          | Additional tooling and features for working with spaCy's config files.                                                                                                                                                                                                                                                                       |\n| üë©‚Äçüè´ **[Online Course]**                                                                                                                                                                                                    | Learn spaCy in this free and interactive online course.                                                                                                                                                                                                                                                                                      |\n| üì∞ **[Blog]**                                                                                                                                                                                                             | Read about current spaCy and Prodigy development, releases, talks and more from Explosion.                                                                                                                                                                                                                 |\n| üì∫ **[Videos]**                                                                                                                                                                                                           | Our YouTube channel with video tutorials, talks and more.                                                                                                                                                                                                                                                                                    |\n| üõ† **[Changelog]**                                                                                                                                                                                                         | Changes and version history.                                                                                                                                                                                                                                                                                                                 |\n| üíù **[Contribute]**                                                                                                                                                                                                       | How to contribute to the spaCy project and code base.                                                                                                                                                                                                                                                                                        |\n| üëï **[Swag]**                                                                                                                                                                                                             | Support us and our work with unique, custom-designed swag!                                                                                                                                                                                                                                                                                   |\n| <a href=\"https://explosion.ai/tailored-solutions\"><img src=\"https://github.com/explosion/spaCy/assets/13643239/36d2a42e-98c0-4599-90e1-788ef75181be\" width=\"150\" alt=\"Tailored Solutions\"/></a> | Custom NLP consulting, implementation and strategic advice by spaCy‚Äôs core development team. Streamlined, production-ready, predictable and maintainable. Send us an email or take our 5-minute questionnaire, and well'be in touch! **[Learn more &rarr;](https://explosion.ai/tailored-solutions)**                 |\n\n[spacy 101]: https://spacy.io/usage/spacy-101\n[new in v3.0]: https://spacy.io/usage/v3\n[usage guides]: https://spacy.io/usage/\n[api reference]: https://spacy.io/api/\n[gpu processing]: https://spacy.io/usage#gpu\n[models]: https://spacy.io/models\n[large language models]: https://spacy.io/usage/large-language-models\n[universe]: https://spacy.io/universe\n[spacy vs code extension]: https://github.com/explosion/spacy-vscode\n[videos]: https://www.youtube.com/c/ExplosionAI\n[online course]: https://course.spacy.io\n[blog]: https://explosion.ai\n[project templates]: https://github.com/explosion/projects\n[changelog]: https://spacy.io/usage#changelog\n[contribute]: https://github.com/explosion/spaCy/blob/master/CONTRIBUTING.md\n[swag]: https://explosion.ai/merch\n\n## üí¨ Where to ask questions\n\nThe spaCy project is maintained by the [spaCy team](https://explosion.ai/about).\nPlease understand that we won't be able to provide individual support via email.\nWe also believe that help is much more valuable if it's shared publicly, so that\nmore people can benefit from it.\n\n| Type                            | Platforms                               |\n| ------------------------------- | --------------------------------------- |\n| üö® **Bug Reports**              | [GitHub Issue Tracker]                  |\n| üéÅ **Feature Requests & Ideas** | [GitHub Discussions]                    |\n| üë©‚Äçüíª **Usage Questions**          | [GitHub Discussions] ¬∑ [Stack Overflow] |\n| üóØ **General Discussion**        | [GitHub Discussions]                    |\n\n[github issue tracker]: https://github.com/explosion/spaCy/issues\n[github discussions]: https://github.com/explosion/spaCy/discussions\n[stack overflow]: https://stackoverflow.com/questions/tagged/spacy\n\n## Features\n\n- Support for **70+ languages**\n- **Trained pipelines** for different languages and tasks\n- Multi-task learning with pretrained **transformers** like BERT\n- Support for pretrained **word vectors** and embeddings\n- State-of-the-art speed\n- Production-ready **training system**\n- Linguistically-motivated **tokenization**\n- Components for named **entity recognition**, part-of-speech-tagging,\n  dependency parsing, sentence segmentation, **text classification**,\n  lemmatization, morphological analysis, entity linking and more\n- Easily extensible with **custom components** and attributes\n- Support for custom models in **PyTorch**, **TensorFlow** and other frameworks\n- Built in **visualizers** for syntax and NER\n- Easy **model packaging**, deployment and workflow management\n- Robust, rigorously evaluated accuracy\n\nüìñ **For more details, see the\n[facts, figures and benchmarks](https://spacy.io/usage/facts-figures).**\n\n## ‚è≥ Install spaCy\n\nFor detailed installation instructions, see the\n[documentation](https://spacy.io/usage).\n\n- **Operating system**: macOS / OS X ¬∑ Linux ¬∑ Windows (Cygwin, MinGW, Visual\n  Studio)\n- **Python version**: Python 3.7+ (only 64 bit)\n- **Package managers**: [pip] ¬∑ [conda] (via `conda-forge`)\n\n[pip]: https://pypi.org/project/spacy/\n[conda]: https://anaconda.org/conda-forge/spacy\n\n### pip\n\nUsing pip, spaCy releases are available as source packages and binary wheels.\nBefore you install spaCy and its dependencies, make sure that your `pip`,\n`setuptools` and `wheel` are up to date.\n\n```bash\npip install -U pip setuptools wheel\npip install spacy\n```\n\nTo install additional data tables for lemmatization and normalization you can\nrun `pip install spacy[lookups]` or install\n[`spacy-lookups-data`](https://github.com/explosion/spacy-lookups-data)\nseparately. The lookups package is needed to create blank models with\nlemmatization data, and to lemmatize in languages that don't yet come with\npretrained models and aren't powered by third-party libraries.\n\nWhen using pip it is generally recommended to install packages in a virtual\nenvironment to avoid modifying system state:\n\n```bash\npython -m venv .env\nsource .env/bin/activate\npip install -U pip setuptools wheel\npip install spacy\n```\n\n### conda\n\nYou can also install spaCy from `conda` via the `conda-forge` channel. For the\nfeedstock including the build recipe and configuration, check out\n[this repository](https://github.com/conda-forge/spacy-feedstock).\n\n```bash\nconda install -c conda-forge spacy\n```\n\n### Updating spaCy\n\nSome updates to spaCy may require downloading new statistical models. If you're\nrunning spaCy v2.0 or higher, you can use the `validate` command to check if\nyour installed models are compatible and if not, print details on how to update\nthem:\n\n```bash\npip install -U spacy\npython -m spacy validate\n```\n\nIf you've trained your own models, keep in mind that your training and runtime\ninputs must match. After updating spaCy, we recommend **retraining your models**\nwith the new version.\n\nüìñ **For details on upgrading from spaCy 2.x to spaCy 3.x, see the\n[migration guide](https://spacy.io/usage/v3#migrating).**\n\n## üì¶ Download model packages\n\nTrained pipelines for spaCy can be installed as **Python packages**. This means\nthat they're a component of your application, just like any other module. Models\ncan be installed using spaCy's [`download`](https://spacy.io/api/cli#download)\ncommand, or manually by pointing pip to a path or URL.\n\n| Documentation              |                                                                  |\n| -------------------------- | ---------------------------------------------------------------- |\n| **[Available Pipelines]**  | Detailed pipeline descriptions, accuracy figures and benchmarks. |\n| **[Models Documentation]** | Detailed usage and installation instructions.                    |\n| **[Training]**             | How to train your own pipelines on your data.                    |\n\n[available pipelines]: https://spacy.io/models\n[models documentation]: https://spacy.io/usage/models\n[training]: https://spacy.io/usage/training\n\n```bash\n# Download best-matching version of specific model for your spaCy installation\npython -m spacy download en_core_web_sm\n\n# pip install .tar.gz archive or .whl from path or URL\npip install /Users/you/en_core_web_sm-3.0.0.tar.gz\npip install /Users/you/en_core_web_sm-3.0.0-py3-none-any.whl\npip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n```\n\n### Loading and using models\n\nTo load a model, use [`spacy.load()`](https://spacy.io/api/top-level#spacy.load)\nwith the model name or a path to the model data directory.\n\n```python\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(\"This is a sentence.\")\n```\n\nYou can also `import` a model directly via its full name and then call its\n`load()` method with no arguments.\n\n```python\nimport spacy\nimport en_core_web_sm\n\nnlp = en_core_web_sm.load()\ndoc = nlp(\"This is a sentence.\")\n```\n\nüìñ **For more info and examples, check out the\n[models documentation](https://spacy.io/docs/usage/models).**\n\n## ‚öí Compile from source\n\nThe other way to install spaCy is to clone its\n[GitHub repository](https://github.com/explosion/spaCy) and build it from\nsource. That is the common way if you want to make changes to the code base.\nYou'll need to make sure that you have a development environment consisting of a\nPython distribution including header files, a compiler,\n[pip](https://pip.pypa.io/en/latest/installing/),\n[virtualenv](https://virtualenv.pypa.io/en/latest/) and\n[git](https://git-scm.com) installed. The compiler part is the trickiest. How to\ndo that depends on your system.\n\n| Platform    |                                                                                                                                                                                                                                                                     |\n| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Ubuntu**  | Install system-level dependencies via `apt-get`: `sudo apt-get install build-essential python-dev git` .                                                                                                                                                            |\n| **Mac**     | Install a recent version of [XCode](https://developer.apple.com/xcode/), including the so-called \"Command Line Tools\". macOS and OS X ship with Python and git preinstalled.                                                                                        |\n| **Windows** | Install a version of the [Visual C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) or [Visual Studio Express](https://visualstudio.microsoft.com/vs/express/) that matches the version that was used to compile your Python interpreter. |\n\nFor more details and instructions, see the documentation on\n[compiling spaCy from source](https://spacy.io/usage#source) and the\n[quickstart widget](https://spacy.io/usage#section-quickstart) to get the right\ncommands for your platform and Python version.\n\n```bash\ngit clone https://github.com/explosion/spaCy\ncd spaCy\n\npython -m venv .env\nsource .env/bin/activate\n\n# make sure you are using the latest pip\npython -m pip install -U pip setuptools wheel\n\npip install -r requirements.txt\npip install --no-build-isolation --editable .\n```\n\nTo install with extras:\n\n```bash\npip install --no-build-isolation --editable .[lookups,cuda102]\n```\n\n## üö¶ Run tests\n\nspaCy comes with an [extensive test suite](spacy/tests). In order to run the\ntests, you'll usually want to clone the repository and build spaCy from source.\nThis will also install the required development dependencies and test utilities\ndefined in the [`requirements.txt`](requirements.txt).\n\nAlternatively, you can run `pytest` on the tests from within the installed\n`spacy` package. Don't forget to also install the test utilities via spaCy's\n[`requirements.txt`](requirements.txt):\n\n```bash\npip install -r requirements.txt\npython -m pytest --pyargs spacy\n```\n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "build-constraints.txt",
          "type": "blob",
          "size": 0.0712890625,
          "content": "# build version constraints for use with wheelwright\nnumpy>=2.0.0,<3.0.0\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "extra",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "netlify.toml",
          "type": "blob",
          "size": 4.5478515625,
          "content": "redirects = [\n    # Netlify\n    {from = \"https://spacy.netlify.com/*\", to=\"https://spacy.io/:splat\", force = true },\n    # Subdomain for branches\n    {from = \"https://nightly.spacy.io/*\", to=\"https://spacy.io/:splat\", force = true},\n    {from = \"https://v2.spacy.io/*\", to=\"https://v2-spacy-io.spacy.io/:splat\", force = true, status = 200},\n    # Old subdomains\n    {from = \"https://survey.spacy.io/*\", to = \"https://spacy.io\", force = true},\n    {from = \"http://survey.spacy.io/*\", to = \"https://spacy.io\", force = true},\n    {from = \"https://alpha.spacy.io/*\", to = \"https://spacy.io\", force = true},\n    {from = \"http://alpha.spacy.io/*\", to = \"https://spacy.io\", force = true},\n    # Old demos\n    {from = \"/demos/*\", to = \"https://explosion.ai/demos/:splat\", force = true},\n    # Old blog\n    {from = \"/blog/*\", to = \"https://explosion.ai/blog/:splat\", force = true},\n    {from = \"/feed\", to = \"https://explosion.ai/feed\", force = true},\n    {from = \"/feed.xml\", to = \"https://explosion.ai/feed\", force = true},\n    # Old documentation pages (1.x)\n    {from = \"/docs/usage/processing-text\", to = \"/usage/linguistic-features\", force = true},\n    {from = \"/docs/usage/deep-learning\", to = \"/usage/training\", force = true},\n    {from = \"/docs/usage/pos-tagging\", to = \"/usage/linguistic-features#pos-tagging\", force = true},\n    {from = \"/docs/usage/dependency-parse\", to = \"/usage/linguistic-features#dependency-parse\", force = true},\n    {from = \"/docs/usage/entity-recognition\", to = \"/usage/linguistic-features#named-entities\", force = true},\n    {from = \"/docs/usage/word-vectors-similarities\", to = \"/usage/vectors-similarity\", force = true},\n    {from = \"/docs/usage/customizing-tokenizer\", to = \"/usage/linguistic-features#tokenization\", force = true},\n    {from = \"/docs/usage/language-processing-pipeline\", to = \"/usage/processing-pipelines\", force = true},\n    {from = \"/docs/usage/customizing-pipeline\", to = \"/usage/processing-pipelines\", force = true},\n    {from = \"/docs/usage/training-ner\", to = \"/usage/training\", force = true},\n    {from = \"/docs/usage/tutorials\", to = \"/usage/examples\", force = true},\n    {from = \"/docs/usage/data-model\", to = \"/api\", force = true},\n    {from = \"/docs/usage/cli\", to = \"/api/cli\", force = true},\n    {from = \"/docs/usage/lightning-tour\", to = \"/usage/spacy-101#lightning-tour\", force = true},\n    {from = \"/docs/api/language-models\", to = \"/usage/models#languages\", force = true},\n    {from = \"/docs/api/spacy\", to = \"/docs/api/top-level\", force = true},\n    {from = \"/docs/api/displacy\", to = \"/api/top-level#displacy\", force = true},\n    {from = \"/docs/api/util\", to = \"/api/top-level#util\", force = true},\n    {from = \"/docs/api/features\", to = \"/models/#architecture\", force = true},\n    {from = \"/docs/api/philosophy\", to = \"/usage/spacy-101\", force = true},\n    {from = \"/docs/usage/showcase\", to = \"/universe\", force = true},\n    {from = \"/tutorials/load-new-word-vectors\", to = \"/usage/linguistic-features\", force = true},\n    {from = \"/tutorials\", to = \"/usage/examples\", force = true},\n    # Old documentation pages (v2.x)\n    {from = \"/usage/adding-languages\", to = \"/usage/linguistic-features\", force = true},\n    {from = \"/usage/vectors-similarity\", to = \"/usage/linguistic-features#vectors-similarity\", force = true},\n    {from = \"/api/goldparse\", to = \"/api/top-level\", force = true},\n    {from = \"/api/goldcorpus\", to = \"/api/corpus\", force = true},\n    {from = \"/api/annotation\", to = \"/api/data-formats\", force = true},\n    {from = \"/usage/examples\", to = \"/usage/projects\", force = true},\n    # Rewrite all other docs pages to /\n    {from = \"/docs/*\", to = \"/:splat\"},\n    # Updated documentation pages\n    {from = \"/usage/resources\", to = \"/universe\", force = true},\n    {from = \"/usage/lightning-tour\", to = \"/usage/spacy-101#lightning-tour\", force = true},\n    {from = \"/usage/linguistic-features#rule-based-matching\", to = \"/usage/rule-based-matching\", force = true},\n    {from = \"/models/comparison\", to = \"/models\", force = true},\n    {from = \"/api/#section-cython\", to = \"/api/cython\", force = true},\n    {from = \"/api/#cython\", to = \"/api/cython\", force = true},\n    {from = \"/api/sentencesegmenter\", to=\"/api/sentencizer\"},\n    {from = \"/universe\", to = \"/universe/project/:id\", query = {id = \":id\"}, force = true},\n    {from = \"/universe\", to = \"/universe/category/:category\", query = {category = \":category\"}, force = true},\n    # Renamed universe projects\n    {from = \"/universe/project/spacy-pytorch-transformers\", to = \"/universe/project/spacy-transformers\", force = true},\n    # Old model pages\n    {from = \"/models/en-starters\", to = \"/models/en\", force = true},\n]\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.7021484375,
          "content": "[build-system]\nrequires = [\n    \"setuptools\",\n    \"cython>=0.25,<3.0\",\n    \"cymem>=2.0.2,<2.1.0\",\n    \"preshed>=3.0.2,<3.1.0\",\n    \"murmurhash>=0.28.0,<1.1.0\",\n    \"thinc>=8.3.0,<8.4.0\",\n    \"numpy>=2.0.0,<3.0.0\"\n]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.cibuildwheel]\nbuild = \"*\"\nskip = \"pp* cp36* cp37* cp38* *-win32 *i686*\"\ntest-skip = \"\"\nfree-threaded-support = false\n\narchs = [\"native\"]\n\nbuild-frontend = \"default\"\nconfig-settings = {}\ndependency-versions = \"pinned\"\nenvironment = { PIP_CONSTRAINT = \"build-constraints.txt\" }\n\nenvironment-pass = []\nbuild-verbosity = 0\n\nbefore-all = \"curl https://sh.rustup.rs -sSf | sh -s -- -y --profile minimal --default-toolchain stable\"\nbefore-build = \"pip install -r requirements.txt && python setup.py clean\"\nrepair-wheel-command = \"\"\n\ntest-command = \"\"\nbefore-test = \"\"\ntest-requires = []\ntest-extras = []\n\ncontainer-engine = \"docker\"\n\nmanylinux-x86_64-image = \"manylinux2014\"\nmanylinux-i686-image = \"manylinux2014\"\nmanylinux-aarch64-image = \"manylinux2014\"\nmanylinux-ppc64le-image = \"manylinux2014\"\nmanylinux-s390x-image = \"manylinux2014\"\nmanylinux-pypy_x86_64-image = \"manylinux2014\"\nmanylinux-pypy_i686-image = \"manylinux2014\"\nmanylinux-pypy_aarch64-image = \"manylinux2014\"\n\nmusllinux-x86_64-image = \"musllinux_1_2\"\nmusllinux-i686-image = \"musllinux_1_2\"\nmusllinux-aarch64-image = \"musllinux_1_2\"\nmusllinux-ppc64le-image = \"musllinux_1_2\"\nmusllinux-s390x-image = \"musllinux_1_2\"\n\n[tool.cibuildwheel.linux]\nrepair-wheel-command = \"auditwheel repair -w {dest_dir} {wheel}\"\n\n[tool.cibuildwheel.macos]\nrepair-wheel-command = \"delocate-wheel --require-archs {delocate_archs} -w {dest_dir} -v {wheel}\"\n\n[tool.cibuildwheel.windows]\n\n[tool.cibuildwheel.pyodide]\n\n\n[tool.isort]\nprofile = \"black\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.876953125,
          "content": "# Our libraries\nspacy-legacy>=3.0.11,<3.1.0\nspacy-loggers>=1.0.0,<2.0.0\ncymem>=2.0.2,<2.1.0\npreshed>=3.0.2,<3.1.0\nthinc>=8.3.0,<8.4.0\nml_datasets>=0.2.0,<0.3.0\nmurmurhash>=0.28.0,<1.1.0\nwasabi>=0.9.1,<1.2.0\nsrsly>=2.4.3,<3.0.0\ncatalogue>=2.0.6,<2.1.0\ntyper>=0.3.0,<1.0.0\nweasel>=0.1.0,<0.5.0\n# Third party dependencies\nnumpy>=2.0.0,<3.0.0\nrequests>=2.13.0,<3.0.0\ntqdm>=4.38.0,<5.0.0\npydantic>=1.7.4,!=1.8,!=1.8.1,<3.0.0\njinja2\nlangcodes>=3.2.0,<4.0.0\n# Official Python utilities\nsetuptools\npackaging>=20.0\n# Development dependencies\npre-commit>=2.13.0\ncython>=0.25,<3.0\npytest>=5.2.0,!=7.1.0\npytest-timeout>=1.3.0,<2.0.0\nmock>=2.0.0,<3.0.0\nflake8>=3.8.0,<6.0.0\nhypothesis>=3.27.0,<7.0.0\nmypy>=1.5.0,<1.6.0; platform_machine != \"aarch64\" and python_version >= \"3.8\"\ntypes-mock>=0.1.1\ntypes-setuptools>=57.0.0\ntypes-requests\ntypes-setuptools>=57.0.0\nblack==22.3.0\ncython-lint>=0.15.0\nisort>=5.0,<6.0\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 3.771484375,
          "content": "[metadata]\ndescription = Industrial-strength Natural Language Processing (NLP) in Python\nurl = https://spacy.io\nauthor = Explosion\nauthor_email = contact@explosion.ai\nlicense = MIT\nlong_description = file: README.md\nlong_description_content_type = text/markdown\nclassifiers =\n    Development Status :: 5 - Production/Stable\n    Environment :: Console\n    Intended Audience :: Developers\n    Intended Audience :: Science/Research\n    License :: OSI Approved :: MIT License\n    Operating System :: POSIX :: Linux\n    Operating System :: MacOS :: MacOS X\n    Operating System :: Microsoft :: Windows\n    Programming Language :: Cython\n    Programming Language :: Python :: 3\n    Programming Language :: Python :: 3.9\n    Programming Language :: Python :: 3.10\n    Programming Language :: Python :: 3.11\n    Programming Language :: Python :: 3.12\n    Programming Language :: Python :: 3.13\n    Topic :: Scientific/Engineering\nproject_urls =\n    Release notes = https://github.com/explosion/spaCy/releases\n    Source = https://github.com/explosion/spaCy\n\n[options]\nzip_safe = false\ninclude_package_data = true\npython_requires = >=3.9,<3.14\n# NOTE: This section is superseded by pyproject.toml and will be removed in\n# spaCy v4\nsetup_requires =\n    cython>=0.25,<3.0\n    numpy>=2.0.0,<3.0.0; python_version < \"3.9\"\n    numpy>=2.0.0,<3.0.0; python_version >= \"3.9\"\n    # We also need our Cython packages here to compile against\n    cymem>=2.0.2,<2.1.0\n    preshed>=3.0.2,<3.1.0\n    murmurhash>=0.28.0,<1.1.0\n    thinc>=8.3.0,<8.4.0\ninstall_requires =\n    # Our libraries\n    spacy-legacy>=3.0.11,<3.1.0\n    spacy-loggers>=1.0.0,<2.0.0\n    murmurhash>=0.28.0,<1.1.0\n    cymem>=2.0.2,<2.1.0\n    preshed>=3.0.2,<3.1.0\n    thinc>=8.3.0,<8.4.0\n    wasabi>=0.9.1,<1.2.0\n    srsly>=2.4.3,<3.0.0\n    catalogue>=2.0.6,<2.1.0\n    weasel>=0.1.0,<0.5.0\n    # Third-party dependencies\n    typer>=0.3.0,<1.0.0\n    tqdm>=4.38.0,<5.0.0\n    numpy>=1.15.0; python_version < \"3.9\"\n    numpy>=1.19.0; python_version >= \"3.9\"\n    requests>=2.13.0,<3.0.0\n    pydantic>=1.7.4,!=1.8,!=1.8.1,<3.0.0\n    jinja2\n    # Official Python utilities\n    setuptools\n    packaging>=20.0\n    langcodes>=3.2.0,<4.0.0\n\n[options.entry_points]\nconsole_scripts =\n    spacy = spacy.cli:setup_cli\n\n[options.extras_require]\nlookups =\n    spacy_lookups_data>=1.0.3,<1.1.0\ntransformers =\n    spacy_transformers>=1.1.2,<1.4.0\ncuda =\n    cupy>=5.0.0b4,<13.0.0\ncuda80 =\n    cupy-cuda80>=5.0.0b4,<13.0.0\ncuda90 =\n    cupy-cuda90>=5.0.0b4,<13.0.0\ncuda91 =\n    cupy-cuda91>=5.0.0b4,<13.0.0\ncuda92 =\n    cupy-cuda92>=5.0.0b4,<13.0.0\ncuda100 =\n    cupy-cuda100>=5.0.0b4,<13.0.0\ncuda101 =\n    cupy-cuda101>=5.0.0b4,<13.0.0\ncuda102 =\n    cupy-cuda102>=5.0.0b4,<13.0.0\ncuda110 =\n    cupy-cuda110>=5.0.0b4,<13.0.0\ncuda111 =\n    cupy-cuda111>=5.0.0b4,<13.0.0\ncuda112 =\n    cupy-cuda112>=5.0.0b4,<13.0.0\ncuda113 =\n    cupy-cuda113>=5.0.0b4,<13.0.0\ncuda114 =\n    cupy-cuda114>=5.0.0b4,<13.0.0\ncuda115 =\n    cupy-cuda115>=5.0.0b4,<13.0.0\ncuda116 =\n    cupy-cuda116>=5.0.0b4,<13.0.0\ncuda117 =\n    cupy-cuda117>=5.0.0b4,<13.0.0\ncuda11x =\n    cupy-cuda11x>=11.0.0,<13.0.0\ncuda12x =\n    cupy-cuda12x>=11.5.0,<13.0.0\ncuda-autodetect =\n    cupy-wheel>=11.0.0,<13.0.0\napple =\n    thinc-apple-ops>=1.0.0,<2.0.0\n# Language tokenizers with external dependencies\nja =\n    sudachipy>=0.5.2,!=0.6.1\n    sudachidict_core>=20211220\nko =\n    natto-py>=0.9.0\nth =\n    pythainlp>=2.0\n\n[bdist_wheel]\nuniversal = false\n\n[sdist]\nformats = gztar\n\n[flake8]\nignore = E203, E266, E501, E731, W503, E741, F541\nmax-line-length = 80\nselect = B,C,E,F,W,T4,B9\nexclude =\n    .env,\n    .git,\n    __pycache__,\n    _tokenizer_exceptions_list.py,\n\n[tool:pytest]\nmarkers =\n    slow: mark a test as slow\n    issue: reference specific issue\n\n[mypy]\nignore_missing_imports = True\nno_implicit_optional = True\nplugins = pydantic.mypy, thinc.mypy\nallow_redefinition = True\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.75390625,
          "content": "#!/usr/bin/env python\nfrom setuptools import Extension, setup, find_packages\nimport sys\nimport numpy\nfrom setuptools.command.build_ext import build_ext\nfrom sysconfig import get_path\nfrom pathlib import Path\nimport shutil\nfrom Cython.Build import cythonize\nfrom Cython.Compiler import Options\nimport os\nimport subprocess\n\n\nROOT = Path(__file__).parent\nPACKAGE_ROOT = ROOT / \"spacy\"\n\n\n# Preserve `__doc__` on functions and classes\n# http://docs.cython.org/en/latest/src/userguide/source_files_and_compilation.html#compiler-options\nOptions.docstrings = True\n\nPACKAGES = find_packages()\nMOD_NAMES = [\n    \"spacy.training.alignment_array\",\n    \"spacy.training.example\",\n    \"spacy.parts_of_speech\",\n    \"spacy.strings\",\n    \"spacy.lexeme\",\n    \"spacy.vocab\",\n    \"spacy.attrs\",\n    \"spacy.kb.candidate\",\n    \"spacy.kb.kb\",\n    \"spacy.kb.kb_in_memory\",\n    \"spacy.ml.parser_model\",\n    \"spacy.morphology\",\n    \"spacy.pipeline.dep_parser\",\n    \"spacy.pipeline._edit_tree_internals.edit_trees\",\n    \"spacy.pipeline.morphologizer\",\n    \"spacy.pipeline.multitask\",\n    \"spacy.pipeline.ner\",\n    \"spacy.pipeline.pipe\",\n    \"spacy.pipeline.trainable_pipe\",\n    \"spacy.pipeline.sentencizer\",\n    \"spacy.pipeline.senter\",\n    \"spacy.pipeline.tagger\",\n    \"spacy.pipeline.transition_parser\",\n    \"spacy.pipeline._parser_internals.arc_eager\",\n    \"spacy.pipeline._parser_internals.ner\",\n    \"spacy.pipeline._parser_internals.nonproj\",\n    \"spacy.pipeline._parser_internals._state\",\n    \"spacy.pipeline._parser_internals.stateclass\",\n    \"spacy.pipeline._parser_internals.transition_system\",\n    \"spacy.pipeline._parser_internals._beam_utils\",\n    \"spacy.tokenizer\",\n    \"spacy.training.align\",\n    \"spacy.training.gold_io\",\n    \"spacy.tokens.doc\",\n    \"spacy.tokens.span\",\n    \"spacy.tokens.token\",\n    \"spacy.tokens.span_group\",\n    \"spacy.tokens.graph\",\n    \"spacy.tokens.morphanalysis\",\n    \"spacy.tokens._retokenize\",\n    \"spacy.matcher.matcher\",\n    \"spacy.matcher.phrasematcher\",\n    \"spacy.matcher.dependencymatcher\",\n    \"spacy.symbols\",\n    \"spacy.vectors\",\n]\nCOMPILE_OPTIONS = {\n    \"msvc\": [\"/Ox\", \"/EHsc\"],\n    \"mingw32\": [\"-O2\", \"-Wno-strict-prototypes\", \"-Wno-unused-function\"],\n    \"other\": [\"-O2\", \"-Wno-strict-prototypes\", \"-Wno-unused-function\"],\n}\nLINK_OPTIONS = {\"msvc\": [\"-std=c++11\"], \"mingw32\": [\"-std=c++11\"], \"other\": []}\nCOMPILER_DIRECTIVES = {\n    \"language_level\": -3,\n    \"embedsignature\": True,\n    \"annotation_typing\": False,\n    \"profile\": sys.version_info < (3, 12),\n}\n# Files to copy into the package that are otherwise not included\nCOPY_FILES = {\n    ROOT / \"setup.cfg\": PACKAGE_ROOT / \"tests\" / \"package\",\n    ROOT / \"pyproject.toml\": PACKAGE_ROOT / \"tests\" / \"package\",\n    ROOT / \"requirements.txt\": PACKAGE_ROOT / \"tests\" / \"package\",\n}\n\n\n# By subclassing build_extensions we have the actual compiler that will be used which is really known only after finalize_options\n# http://stackoverflow.com/questions/724664/python-distutils-how-to-get-a-compiler-that-is-going-to-be-used\nclass build_ext_options:\n    def build_options(self):\n        for e in self.extensions:\n            e.extra_compile_args += COMPILE_OPTIONS.get(\n                self.compiler.compiler_type, COMPILE_OPTIONS[\"other\"]\n            )\n        for e in self.extensions:\n            e.extra_link_args += LINK_OPTIONS.get(\n                self.compiler.compiler_type, LINK_OPTIONS[\"other\"]\n            )\n\n\nclass build_ext_subclass(build_ext, build_ext_options):\n    def build_extensions(self):\n        if self.parallel is None and os.environ.get(\"SPACY_NUM_BUILD_JOBS\") is not None:\n            self.parallel = int(os.environ.get(\"SPACY_NUM_BUILD_JOBS\"))\n        build_ext_options.build_options(self)\n        build_ext.build_extensions(self)\n\n\n# Include the git version in the build (adapted from NumPy)\n# Copyright (c) 2005-2020, NumPy Developers.\n# BSD 3-Clause license, see licenses/3rd_party_licenses.txt\ndef write_git_info_py(filename=\"spacy/git_info.py\"):\n    def _minimal_ext_cmd(cmd):\n        # construct minimal environment\n        env = {}\n        for k in [\"SYSTEMROOT\", \"PATH\", \"HOME\"]:\n            v = os.environ.get(k)\n            if v is not None:\n                env[k] = v\n        # LANGUAGE is used on win32\n        env[\"LANGUAGE\"] = \"C\"\n        env[\"LANG\"] = \"C\"\n        env[\"LC_ALL\"] = \"C\"\n        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT, env=env)\n        return out\n\n    git_version = \"Unknown\"\n    if Path(\".git\").exists():\n        try:\n            out = _minimal_ext_cmd([\"git\", \"rev-parse\", \"--short\", \"HEAD\"])\n            git_version = out.strip().decode(\"ascii\")\n        except Exception:\n            pass\n    elif Path(filename).exists():\n        # must be a source distribution, use existing version file\n        try:\n            a = open(filename, \"r\")\n            lines = a.readlines()\n            git_version = lines[-1].split('\"')[1]\n        except Exception:\n            pass\n        finally:\n            a.close()\n\n    text = \"\"\"# THIS FILE IS GENERATED FROM SPACY SETUP.PY\n#\nGIT_VERSION = \"%(git_version)s\"\n\"\"\"\n    a = open(filename, \"w\")\n    try:\n        a.write(text % {\"git_version\": git_version})\n    finally:\n        a.close()\n\n\ndef clean(path):\n    for path in path.glob(\"**/*\"):\n        if path.is_file() and path.suffix in (\".so\", \".cpp\", \".html\"):\n            print(f\"Deleting {path.name}\")\n            path.unlink()\n\n\ndef setup_package():\n    write_git_info_py()\n    if len(sys.argv) > 1 and sys.argv[1] == \"clean\":\n        return clean(PACKAGE_ROOT)\n\n    with (PACKAGE_ROOT / \"about.py\").open(\"r\") as f:\n        about = {}\n        exec(f.read(), about)\n\n    for copy_file, target_dir in COPY_FILES.items():\n        if copy_file.exists():\n            shutil.copy(str(copy_file), str(target_dir))\n            print(f\"Copied {copy_file} -> {target_dir}\")\n\n    include_dirs = [\n        numpy.get_include(),\n        get_path(\"include\"),\n    ]\n    ext_modules = []\n    ext_modules.append(\n        Extension(\n            \"spacy.matcher.levenshtein\",\n            [\n                \"spacy/matcher/levenshtein.pyx\",\n                \"spacy/matcher/polyleven.c\",\n            ],\n            language=\"c\",\n            include_dirs=include_dirs,\n        )\n    )\n    for name in MOD_NAMES:\n        mod_path = name.replace(\".\", \"/\") + \".pyx\"\n        ext = Extension(\n            name,\n            [mod_path],\n            language=\"c++\",\n            include_dirs=include_dirs,\n            extra_compile_args=[\"-std=c++11\"],\n        )\n        ext_modules.append(ext)\n    print(\"Cythonizing sources\")\n    ext_modules = cythonize(ext_modules, compiler_directives=COMPILER_DIRECTIVES)\n\n    setup(\n        name=\"spacy\",\n        packages=PACKAGES,\n        version=about[\"__version__\"],\n        ext_modules=ext_modules,\n        cmdclass={\"build_ext\": build_ext_subclass},\n        package_data={\"\": [\"*.pyx\", \"*.pxd\", \"*.pxi\"]},\n    )\n\n\nif __name__ == \"__main__\":\n    setup_package()\n"
        },
        {
          "name": "spacy",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}