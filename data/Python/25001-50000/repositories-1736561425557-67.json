{
  "metadata": {
    "timestamp": 1736561425557,
    "page": 67,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Pythagora-io/gpt-pilot",
      "stars": 32174,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.19140625,
          "content": "__pycache__/\n.venv/\nvenv/\n.vscode/\n.idea/\nhtmlcov/\ndist/\nworkspace/\npilot-env/\nvenv/\n\n.coverage\n*.code-workspace\n.*_cache\n.env\n*.pyc\n*.db\n*.db-shm\n*.db-wal\nconfig.json\npoetry.lock\n.DS_Store\n*.log\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.7099609375,
          "content": "fail_fast: true\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    # Ruff version.\n    rev: v0.3.5\n    hooks:\n      # Run the linter.\n      - id: ruff\n        args: [ --fix ]\n      # Run the formatter.\n      - id: ruff-format\n  - repo: local\n    hooks:\n      # Check there are no migrations missing\n      - id: alembic\n        name: alembic\n        stages: [commit]\n        types: [python]\n        entry: alembic -c core/db/alembic.ini check\n        language: system\n        pass_filenames: false\n  - repo: local\n    hooks:\n      # Run the tests\n      - id: pytest\n        name: pytest\n        stages: [commit]\n        types: [python]\n        entry: pytest\n        language: system\n        pass_filenames: false\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 4.12890625,
          "content": "# Functional Source License, Version 1.1, MIT Future License\n\n## Abbreviation\n\nFSL-1.1-MIT\n\n## Notice\n\nCopyright 2024 Pythagora Technologies, Inc.\n\n## Terms and Conditions\n\n### Licensor (\"We\")\n\nThe party offering the Software under these Terms and Conditions.\n\n### The Software\n\nThe \"Software\" is each version of the software that we make available under\nthese Terms and Conditions, as indicated by our inclusion of these Terms and\nConditions with the Software.\n\n### License Grant\n\nSubject to your compliance with this License Grant and the Patents,\nRedistribution and Trademark clauses below, we hereby grant you the right to\nuse, copy, modify, create derivative works, publicly perform, publicly display\nand redistribute the Software for any Permitted Purpose identified below.\n\n### Permitted Purpose\n\nA Permitted Purpose is any purpose other than a Competing Use. A Competing Use\nmeans making the Software available to others in a commercial product or\nservice that:\n\n1. substitutes for the Software;\n\n2. substitutes for any other product or service we offer using the Software\n   that exists as of the date we make the Software available; or\n\n3. offers the same or substantially similar functionality as the Software.\n\nPermitted Purposes specifically include using the Software:\n\n1. for your internal use and access;\n\n2. for non-commercial education;\n\n3. for non-commercial research; and\n\n4. in connection with professional services that you provide to a licensee\n   using the Software in accordance with these Terms and Conditions.\n\n### Patents\n\nTo the extent your use for a Permitted Purpose would necessarily infringe our\npatents, the license grant above includes a license under our patents. If you\nmake a claim against any party that the Software infringes or contributes to\nthe infringement of any patent, then your patent license to the Software ends\nimmediately.\n\n### Redistribution\n\nThe Terms and Conditions apply to all copies, modifications and derivatives of\nthe Software.\n\nIf you redistribute any copies, modifications or derivatives of the Software,\nyou must include a copy of or a link to these Terms and Conditions and not\nremove any copyright notices provided in or with the Software.\n\n### Disclaimer\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND WITHOUT WARRANTIES OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING WITHOUT LIMITATION WARRANTIES OF FITNESS FOR A PARTICULAR\nPURPOSE, MERCHANTABILITY, TITLE OR NON-INFRINGEMENT.\n\nIN NO EVENT WILL WE HAVE ANY LIABILITY TO YOU ARISING OUT OF OR RELATED TO THE\nSOFTWARE, INCLUDING INDIRECT, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES,\nEVEN IF WE HAVE BEEN INFORMED OF THEIR POSSIBILITY IN ADVANCE.\n\n### Trademarks\n\nExcept for displaying the License Details and identifying us as the origin of\nthe Software, you have no right under these Terms and Conditions to use our\ntrademarks, trade names, service marks or product names.\n\n## Grant of Future License\n\nWe hereby irrevocably grant you an additional license to use the Software under\nthe MIT license that is effective on the second anniversary of the date we make\nthe Software available. On or after that date, you may use the Software under\nthe MIT license, in which case the following will apply:\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\nof the Software, and to permit persons to whom the Software is furnished to do\nso, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.248046875,
          "content": "<div align=\"center\">\n\n# üßë‚Äç‚úàÔ∏è GPT PILOT üßë‚Äç‚úàÔ∏è\n\n</div>\n\n---\n\n<div align=\"center\">\n\n[![Discord Follow](https://dcbadge.vercel.app/api/server/HaqXugmxr9?style=flat)](https://discord.gg/HaqXugmxr9)\n[![GitHub Repo stars](https://img.shields.io/github/stars/Pythagora-io/gpt-pilot?style=social)](https://github.com/Pythagora-io/gpt-pilot)\n[![Twitter Follow](https://img.shields.io/twitter/follow/HiPythagora?style=social)](https://twitter.com/HiPythagora)\n\n</div>\n\n---\n\n<div align=\"center\">\n<a href=\"https://www.ycombinator.com/\" target=\"_blank\"><img src=\"https://s3.amazonaws.com/assets.pythagora.ai/yc/PNG/Black.png\" alt=\"Pythagora-io%2Fgpt-pilot | Trendshift\" style=\"width: 250px; height: 93px;\"/></a>\n</div>\n<br>\n<div align=\"center\">\n<a href=\"https://trendshift.io/repositories/466\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/466\" alt=\"Pythagora-io%2Fgpt-pilot | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<br>\n<br>\n\n<div align=\"center\">\n\n### GPT Pilot doesn't just generate code, it builds apps!\n\n</div>\n\n---\n<div align=\"center\">\n\n[![See it in action](https://i3.ytimg.com/vi/4g-1cPGK0GA/maxresdefault.jpg)](https://youtu.be/4g-1cPGK0GA)\n\n(click to open the video in YouTube) (1:40min)\n\n</div>\n\n---\n\nüì´ If you would like to get updates on future releases or just get in touch, join our [Discord server](https://discord.gg/HaqXugmxr9) or you [can add your email here](http://eepurl.com/iD6Mpo). üì¨\n\n---\n\n<!-- TOC -->\n* [üîå Requirements](#-requirements)\n* [üö¶How to start using gpt-pilot?](#how-to-start-using-gpt-pilot)\n* [üîé Examples](#-examples)\n* [üê≥ How to start gpt-pilot in docker?](#-how-to-start-gpt-pilot-in-docker)\n* [üßë‚ÄçüíªÔ∏è CLI arguments](#-cli-arguments)\n* [üèó How GPT Pilot works?](#-how-gpt-pilot-works)\n* [üï¥How's GPT Pilot different from _Smol developer_ and _GPT engineer_?](#hows-gpt-pilot-different-from-smol-developer-and-gpt-engineer)\n* [üçª Contributing](#-contributing)\n* [üîó Connect with us](#-connect-with-us)\n* [üåü Star history](#-star-history)\n<!-- TOC -->\n\n---\n\nGPT Pilot aims to research how much LLMs can be utilized to generate fully working, production-ready apps while the developer oversees the implementation.\n\n**The main idea is that AI can write most of the code for an app (maybe 95%), but for the rest, 5%, a developer is and will be needed until we get full AGI**.\n\nIf you are interested in our learnings during this project, you can check [our latest blog posts](https://blog.pythagora.ai/2024/02/19/gpt-pilot-what-did-we-learn-in-6-months-of-working-on-a-codegen-pair-programmer/).\n\n---\n\n<br>\n\n<div align=\"center\">\n\n### **[üëâ Examples of apps written by GPT Pilot üëà](https://github.com/Pythagora-io/gpt-pilot/wiki/Apps-created-with-GPT-Pilot)**\n\n</div>\n<br>\n\n---\n\n# üîå Requirements\n\n- **Python 3.9+**\n\n# üö¶How to start using gpt-pilot?\n\n### If you're new to GPT Pilot:\n\nAfter you have Python and (optionally) PostgreSQL installed, follow these steps:\n\n1. `git clone https://github.com/Pythagora-io/gpt-pilot.git` (clone the repo)\n2. `cd gpt-pilot` (go to the repo folder)\n3. `python3 -m venv venv` (create a virtual environment)\n4. `source venv/bin/activate` (or on Windows `venv\\Scripts\\activate`) (activate the virtual environment)\n5. `pip install -r requirements.txt` (install the dependencies)\n6. `cp example-config.json config.json` (create `config.json` file)\n7. Set your key and other settings in `config.json` file:\n   - LLM Provider (`openai`, `anthropic` or `groq`) key and endpoints (leave `null` for default) (note that Azure and OpenRouter are suppored via the `openai` setting)\n   - Your API key (if `null`, will be read from the environment variables)\n   - database settings: sqlite is used by default, PostgreSQL should also work\n   - optionally update `fs.ignore_paths` and add files or folders which shouldn't be tracked by GPT Pilot in workspace, useful to ignore folders created by compilers\n8. `python main.py` (start GPT Pilot)\n\nAll generated code will be stored in the folder `workspace` inside the folder named after the app name you enter upon starting the pilot.\n\n### If you're upgrading from GPT Pilot v0.1\n\nAssuming you already have the git repository with an earlier version:\n\n1. `git pull` (update the repo)\n2. `source pilot-env/bin/activate` (or on Windows `pilot-env\\Scripts\\activate`) (activate the virtual environment)\n3. `pip install -r requirements.txt` (install the new dependencies)\n4. `python main.py --import-v0 pilot/gpt-pilot` (this should import your settings and existing projects)\n\nThis will create a new database `pythagora.db` and import all apps from the old database. For each app,\nit will import the start of the latest task you were working on.\n\nTo verify that the import was successful, you can run `python main.py --list` to see all the apps you have created,\nand check `config.json` to check the settings were correctly converted to the new config file format (and make\nany adjustments if needed).\n\n# üîé [Examples](https://github.com/Pythagora-io/gpt-pilot/wiki/Apps-created-with-GPT-Pilot)\n\n[Click here](https://github.com/Pythagora-io/gpt-pilot/wiki/Apps-created-with-GPT-Pilot) to see all example apps created with GPT Pilot.\n\n## üê≥ How to start gpt-pilot in docker?\n1. `git clone https://github.com/Pythagora-io/gpt-pilot.git` (clone the repo)\n2. Update the `docker-compose.yml` environment variables, which can be done via `docker compose config`. If you wish to use a local model, please go to [https://localai.io/basics/getting_started/](https://localai.io/basics/getting_started/).\n3. By default, GPT Pilot will read & write to `~/gpt-pilot-workspace` on your machine, you can also edit this in `docker-compose.yml`\n4. run `docker compose build`. this will build a gpt-pilot container for you.\n5. run `docker compose up`.\n6. access the web terminal on `port 7681`\n7. `python main.py` (start GPT Pilot)\n\nThis will start two containers, one being a new image built by the `Dockerfile` and a Postgres database. The new image also has [ttyd](https://github.com/tsl0922/ttyd) installed so that you can easily interact with gpt-pilot. Node is also installed on the image and port 3000 is exposed.\n\n### PostgreSQL support\n\nGPT Pilot uses built-in SQLite database by default. If you want to use the PostgreSQL database, you need to additional install `asyncpg` and `psycopg2` packages:\n\n```bash\npip install asyncpg psycopg2\n```\n\nThen, you need to update the `config.json` file to set `db.url` to `postgresql+asyncpg://<user>:<password>@<db-host>/<db-name>`.\n\n# üßë‚ÄçüíªÔ∏è CLI arguments\n\n### List created projects (apps)\n\n```bash\npython main.py --list\n```\n\nNote: for each project (app), this also lists \"branches\". Currently we only support having one branch (called \"main\"), and in the future we plan to add support for multiple project branches.\n\n### Load and continue from the latest step in a project (app)\n\n```bash\npython main.py --project <app_id>\n```\n\n### Load and continue from a specific step in a project (app)\n\n```bash\npython main.py --project <app_id> --step <step>\n```\n\nWarning: this will delete all progress after the specified step!\n\n### Delete project (app)\n\n```bash\npython main.py --delete <app_id>\n```\n\nDelete project with the specified `app_id`. Warning: this cannot be undone!\n\n### Import projects from v0.1\n\n```bash\npython main.py --import-v0 <path>\n```\n\nThis will import projects from the old GPT Pilot v0.1 database. The path should be the path to the old GPT Pilot v0.1 database. For each project, it will import the start of the latest task you were working on. If the project was already imported, the import procedure will skip it (won't overwrite the project in the database).\n\n### Other command-line options\n\nThere are several other command-line options that mostly support calling GPT Pilot from our VSCode extension. To see all the available options, use the `--help` flag:\n\n```bash\npython main.py --help\n```\n\n# üèó How GPT Pilot works?\nHere are the steps GPT Pilot takes to create an app:\n\n1. You enter the app name and the description.\n2. **Product Owner agent** like in real life, does nothing. :)\n3. **Specification Writer agent** asks a couple of questions to understand the requirements better if project description is not good enough.\n4. **Architect agent** writes up technologies that will be used for the app and checks if all technologies are installed on the machine and installs them if not.\n5. **Tech Lead agent** writes up development tasks that the Developer must implement.\n6. **Developer agent** takes each task and writes up what needs to be done to implement it. The description is in human-readable form.\n7. **Code Monkey agent** takes the Developer's description and the existing file and implements the changes.\n8. **Reviewer agent** reviews every step of the task and if something is done wrong Reviewer sends it back to Code Monkey.\n9. **Troubleshooter agent** helps you to give good feedback to GPT Pilot when something is wrong.\n10. **Debugger agent** hate to see him, but he is your best friend when things go south.\n11. **Technical Writer agent** writes documentation for the project.\n\n<br>\n\n# üï¥How's GPT Pilot different from _Smol developer_ and _GPT engineer_?\n\n- **GPT Pilot works with the developer to create a fully working production-ready app** - I don't think AI can (at least in the near future) create apps without a developer being involved. So, **GPT Pilot codes the app step by step** just like a developer would in real life. This way, it can debug issues as they arise throughout the development process. If it gets stuck, you, the developer in charge, can review the code and fix the issue. Other similar tools give you the entire codebase at once - this way, bugs are much harder to fix for AI and for you as a developer.\n  <br><br>\n- **Works at scale** - GPT Pilot isn't meant to create simple apps but rather so it can work at any scale. It has mechanisms that filter out the code, so in each LLM conversation, it doesn't need to store the entire codebase in context, but it shows the LLM only the relevant code for the current task it's working on. Once an app is finished, you can continue working on it by writing instructions on what feature you want to add.\n\n# üçª Contributing\nIf you are interested in contributing to GPT Pilot, join [our Discord server](https://discord.gg/HaqXugmxr9), check out open [GitHub issues](https://github.com/Pythagora-io/gpt-pilot/issues), and see if anything interests you. We would be happy to get help in resolving any of those. The best place to start is by reviewing blog posts mentioned above to understand how the architecture works before diving into the codebase.\n\n## üñ• Development\nOther than the research, GPT Pilot needs to be debugged to work in different scenarios. For example, we realized that the quality of the code generated is very sensitive to the size of the development task. When the task is too broad, the code has too many bugs that are hard to fix, but when the development task is too narrow, GPT also seems to struggle in getting the task implemented into the existing code.\n\n## üìä Telemetry\nTo improve GPT Pilot, we are tracking some events from which you can opt out at any time. You can read more about it [here](./docs/TELEMETRY.md).\n\n# üîó Connect with us\nüåü As an open-source tool, it would mean the world to us if you starred the GPT-pilot repo üåü\n\nüí¨ Join [the Discord server](https://discord.gg/HaqXugmxr9) to get in touch.\n"
        },
        {
          "name": "core",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "example-config.json",
          "type": "blob",
          "size": 2.841796875,
          "content": "{\n  // Configuration for the LLM providers that can be used. Pythagora supports\n  // OpenAI, Azure, Anthropic and Groq. OpenRouter and local LLMs (such as LM-Studio)\n  // also work, you can use \"openai\" provider to define these.\n  \"llm\": {\n    \"openai\": {\n      // Base url to the provider/server, omitting the trailing \"chat/completions\" part.\n      \"base_url\": null,\n      \"api_key\": null,\n      \"connect_timeout\": 60.0,\n      \"read_timeout\": 20.0\n    },\n    // Example config for Anthropic (see https://docs.anthropic.com/docs/api-reference)\n    \"anthropic\": {\n      \"base_url\": \"https://api.anthropic.com\",\n      \"api_key\": \"your-api-key\",\n      \"connect_timeout\": 60.0,\n      \"read_timeout\": 20.0\n    },\n    // Example config for Azure OpenAI (see https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#chat-completions)\n    \"azure\": {\n      \"base_url\": \"https://your-resource-name.openai.azure.com/\",\n      \"api_key\": \"your-api-key\",\n      \"connect_timeout\": 60.0,\n      \"read_timeout\": 20.0,\n      \"extra\": {\n        \"azure_deployment\": \"your-azure-deployment-id\",\n        \"api_version\": \"2024-02-01\"\n      }\n    }\n  },\n  // Each agent can use a different model or configuration. The default, as before, is GPT4 Turbo\n  // for most tasks and GPT3.5 Turbo to generate file descriptions. The agent name here should match\n  // the Python class name.\n  \"agent\": {\n    \"default\": {\n      \"provider\": \"openai\",\n      \"model\": \"gpt-4o-2024-05-13\",\n      \"temperature\": 0.5\n    }\n  },\n  // Logging configuration outputs debug log to \"pythagora.log\" by default. If you set this to null,\n  // the log will be sent to stdout.\n  \"log\": {\n    \"level\": \"DEBUG\",\n    \"format\": \"%(asctime)s %(levelname)s [%(name)s] %(message)s\",\n    \"output\": \"pythagora.log\"\n  },\n  // Database to use. Pythagora uses asyncio so asyncio-compatible database engine should be specified.\n  // If \"debug_sql\" is set to True, all SQL queries will be logged.\n  \"db\": {\n    \"url\": \"sqlite+aiosqlite:///pythagora.db\",\n    \"debug_sql\": false\n  },\n  \"ui\": {\n    \"type\": \"plain\"\n  },\n  \"fs\": {\n    \"type\": \"local\",\n    // Root directory of the workspace. Pythagora will store all projects under this directory by default.\n    \"workspace_root\": \"workspace\",\n    // Directories, files and patterns to ignore when examining the files in the project.\n    // Note that Pythagora already ignores all binary (non-text) files by default.\n    \"ignore_paths\": [\n      \".git\",\n      \".gpt-pilot\",\n      \".idea\",\n      \".vscode\",\n      \".next\",\n      \".DS_Store\",\n      \"__pycache__\",\n      \"site-packages\",\n      \"node_modules\",\n      \"package-lock.json\",\n      \"venv\",\n      \"dist\",\n      \"build\",\n      \"target\",\n      \"*.min.js\",\n      \"*.min.css\",\n      \"*.svg\",\n      \"*.csv\",\n      \"*.log\",\n      \"go.sum\"\n    ],\n    // Files larger than 50KB will be ignored, even if they otherwise wouldn't be.\n    \"ignore_size_threshold\": 50000\n  }\n}\n"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 1.2177734375,
          "content": "#!/usr/bin/env python\n\n\nimport os.path\nimport sys\n\ntry:\n    from core.cli.main import run_pythagora\nexcept ImportError as err:\n    pythagora_root = os.path.dirname(__file__)\n    venv_path = os.path.join(pythagora_root, \"venv\")\n    requirements_path = os.path.join(pythagora_root, \"requirements.txt\")\n    if sys.prefix == sys.base_prefix:\n        venv_python_path = os.path.join(venv_path, \"scripts\" if sys.platform == \"win32\" else \"bin\", \"python\")\n        print(f\"Python environment for Pythagora is not set up: module `{err.name}` is missing.\", file=sys.stderr)\n        print(f\"Please create Python virtual environment: {sys.executable} -m venv {venv_path}\", file=sys.stderr)\n        print(\n            f\"Then install the required dependencies with: {venv_python_path} -m pip install -r {requirements_path}\",\n            file=sys.stderr,\n        )\n    else:\n        print(\n            f\"Python environment for Pythagora is not completely set up: module `{err.name}` is missing\",\n            file=sys.stderr,\n        )\n        print(\n            f\"Please run `{sys.executable} -m pip install -r {requirements_path}` to finish Python setup, and rerun Pythagora.\",\n            file=sys.stderr,\n        )\n    sys.exit(255)\n\nsys.exit(run_pythagora())\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.4794921875,
          "content": "[tool.poetry]\nname = \"gpt-pilot\"\nversion = \"1.0.0\"\ndescription = \"Build complete apps using AI agents\"\nauthors = [\"Senko Rasic <senko@pythagora.ai>\"]\nlicense = \"FSL-1.1-MIT\"\nreadme = \"README.md\"\npackages = [{include = \"core\", from = \".\"}]\nrepository = \"https://github.com/Pythagora-io/pythagora-core\"\nhomepage = \"https://pythagora.ai\"\nkeywords = [\"ai\", \"llm\"]\n\n[[tool.poetry.source]]\nname = \"PyPI\"\npriority = \"primary\"\n\n[[tool.poetry.source]]\nname = \"testpypi\"\nurl = \"https://test.pypi.org/legacy/\"\npriority = \"explicit\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n[tool.poetry.dependencies]\npython = \"^3.9\"\npydantic = \"^2.7.1\"\nopenai = \"^1.27.0\"\nanthropic = \"^0.25.8\"\ngroq = \"^0.6.0\"\njinja2 = \"^3.1.3\"\ntiktoken = \"^0.6.0\"\nsqlalchemy = { version = \"^2.0.29\", extras = [\"asyncio\"] }\naiosqlite = \"^0.20.0\"\npsutil = \"^5.9.8\"\nhttpx = \"^0.27.0\"\nalembic = \"^1.13.1\"\npython-dotenv = \"^1.0.1\"\nprompt-toolkit = \"^3.0.45\"\njsonref = \"^1.1.0\"\ntenacity = \"9.0.0\"\n\n[tool.poetry.group.dev.dependencies]\npytest = \"^8.1.1\"\nruff = \"^0.3.5\"\npytest-cov = \"^5.0.0\"\npytest-asyncio = \"^0.23.6\"\npytest-timeout = \"^2.3.1\"\npre-commit = \"^3.7.0\"\n\n[tool.pytest.ini_options]\naddopts = \"-ra -q --cov=core --no-cov-on-fail --timeout 10\"\npythonpath = [\".\"]\n\n[tool.coverage.report]\nexclude_lines = [\"if TYPE_CHECKING:\", \"raise NotImplementedError()\"]\nomit = [\"core/db/migrations/*\", \"core/templates/tpl/*\"]\n\n[tool.ruff]\nline-length = 120\nindent-width = 4\ntarget-version = \"py39\"\nlint.extend-select = [\"I\"]\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.734375,
          "content": "aiosqlite==0.20.0\nalembic==1.13.2\nannotated-types==0.7.0\nanthropic==0.25.9\nanyio==4.4.0\ncertifi==2024.7.4\ncharset-normalizer==3.3.2\ncolorama==0.4.6\ndistro==1.9.0\nexceptiongroup==1.2.2\nfilelock==3.15.4\nfsspec==2024.6.1\ngreenlet==3.0.3\ngroq==0.6.0\nh11==0.14.0\nhttpcore==1.0.5\nhttpx==0.27.0\nhuggingface-hub==0.24.5\nidna==3.7\njinja2==3.1.4\njiter==0.5.0\njsonref==1.1.0\nmako==1.3.5\nmarkupsafe==2.1.5\nopenai==1.40.6\npackaging==24.1\nprompt-toolkit==3.0.47\npsutil==5.9.8\npydantic-core==2.20.1\npydantic==2.8.2\npython-dotenv==1.0.1\npyyaml==6.0.2\nregex==2024.7.24\nrequests==2.32.3\nsniffio==1.3.1\nsqlalchemy==2.0.32\nsqlalchemy[asyncio]==2.0.32\ntenacity==9.0.0\ntiktoken==0.6.0\ntokenizers==0.20.0\ntqdm==4.66.5\ntyping-extensions==4.12.2\nurllib3==2.2.2\nwcwidth==0.2.13\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}