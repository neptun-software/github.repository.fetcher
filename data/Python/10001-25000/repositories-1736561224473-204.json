{
  "metadata": {
    "timestamp": 1736561224473,
    "page": 204,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "microsoft/nni",
      "stars": 14100,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.3515625,
          "content": "# The following types are treated as text\n# EOL are converted to LF\n*.tsx   text    eol=lf\n*.ts    text    eol=lf\n*.py    text    eol=lf\n*.sh    text    eol=lf\n\n# The following types are treated as binary\n# These files appear mostly in docs/ folder\n.ipynb  binary\n.pickle binary\n\n# Linguist override (for github)\ndocs/source/tutorials/*     linguist-generated\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.482421875,
          "content": "/nni/version.py\n/nni_node/\n/toolchain/\n\n# unit test generated files\n/test/model_path/\n/test/temp.json\n/test/ut/sdk/*.pth\n/ts/nni_manager/exp_profile.json\n/ts/nni_manager/metrics.json\n/ts/nni_manager/trial_jobs.json\n/test/ut/retiarii/_debug_graph_data.json\n/test/ut/retiarii/out.tmp\n\n# example generated files\n/nni_assets/**/data/\n\n# Logs\nlogs\n*.log\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Runtime data\npids\n*.pid\n*.seed\n*.pid.lock\n\n# Build package\ndist/\n\n# Directory for instrumented libs generated by jscoverage/JSCover\nlib-cov\n\n# Coverage directory used by tools like istanbul\ncoverage\njunit/\ncoverage.xml\ntest-*.xml\n.coverage.*\nhtmlcov/\n.coverage\n\n# nyc test coverage\n.nyc_output\n\n# Grunt intermediate storage (http://gruntjs.com/creating-plugins#storing-task-files)\n.grunt\n\n# Bower dependency directory (https://bower.io/)\nbower_components\n\n# node-waf configuration\n.lock-wscript\n\n# Compiled binary addons (https://nodejs.org/api/addons.html)\nbuild/Release\n\n# Dependency directories\nnode_modules/\njspm_packages/\n\n# TypeScript v1 declaration files\ntypings/\n\n# Optional npm cache directory\n.npm\n\n# Optional eslint cache\n.eslintcache\n\n# Optional REPL history\n.node_repl_history\n\n# Output of 'npm pack'\n*.tgz\n\n# Yarn Integrity file\n.yarn-integrity\n\n# next.js build output\n.next\n\n# Pycharm Project files\n.idea\n\n# Python cache files\n__pycache__\nbuild\n*.egg-info\n.eggs/\nsetup.pye\n**/__init__.pye\n**/.ipynb_checkpoints\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# VSCode\n.vscode\n.vs\n.history\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 1.0224609375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-20.04\n  tools:\n    python: \"3.9\"\n    nodejs: \"16\"  # specified but actually not used\n    # You can also specify other tool versions:\n    # rust: \"1.55\"\n    # golang: \"1.17\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/source/conf.py\n\n# Optionally declare the Python requirements required to build your docs\npython:\n  install:\n  - requirements: dependencies/develop.txt\n  - requirements: dependencies/required.txt\n  # The issue with smac and swig prevents us from installing required_extra.\n  # As a result, the docstring from several tuners including SMAC, PPO cannot be rendered.\n  # - requirements: dependencies/required_extra.txt\n  - requirements: dependencies/recommended.txt\n  # We cannot have `python setup.py install` here,\n  # because it's not supported by NNI.\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.220703125,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- name: \"Microsoft\"\ntitle: \"Neural Network Intelligence\"\ndate-released: 2021-01-14\nurl: \"https://github.com/microsoft/nni\"\nversion: 2.0\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.474609375,
          "content": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT license.\n\nFROM nvidia/cuda:11.3.1-cudnn8-runtime-ubuntu20.04\n\nARG NNI_RELEASE\n\nLABEL maintainer='Microsoft NNI Team<nni@microsoft.com>'\n\nENV DEBIAN_FRONTEND=noninteractive \n\nRUN apt-get -y update\nRUN apt-get -y install \\\n    automake \\\n    build-essential \\\n    cmake \\\n    curl \\\n    git \\\n    openssh-server \\\n    python3 \\\n    python3-dev \\\n    python3-pip \\\n    sudo \\\n    unzip \\\n    wget \\\n    zip\nRUN apt-get clean\nRUN rm -rf /var/lib/apt/lists/*\n\nRUN ln -s python3 /usr/bin/python\n\nRUN python3 -m pip --no-cache-dir install pip==22.0.3 setuptools==60.9.1 wheel==0.37.1\n\nRUN python3 -m pip --no-cache-dir install \\\n    lightgbm==3.3.2 \\\n    numpy==1.22.2 \\\n    pandas==1.4.1 \\\n    scikit-learn==1.0.2 \\\n    scipy==1.8.0\n\nRUN python3 -m pip --no-cache-dir install \\\n    torch==1.10.2+cu113 \\\n    torchvision==0.11.3+cu113 \\\n    torchaudio==0.10.2+cu113 \\\n    -f https://download.pytorch.org/whl/cu113/torch_stable.html\nRUN python3 -m pip --no-cache-dir install pytorch-lightning==1.6.1\n\nRUN python3 -m pip --no-cache-dir install tensorflow==2.9.1\n\nRUN python3 -m pip --no-cache-dir install azureml==0.2.7 azureml-sdk==1.38.0\n\nCOPY dist/nni-${NNI_RELEASE}-py3-none-manylinux1_x86_64.whl .\nRUN python3 -m pip install nni-${NNI_RELEASE}-py3-none-manylinux1_x86_64.whl\nRUN rm nni-${NNI_RELEASE}-py3-none-manylinux1_x86_64.whl\n\nENV PATH=/root/.local/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/bin:/usr/bin:/usr/sbin\n\nWORKDIR /root\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.048828125,
          "content": "Copyright (c) Microsoft Corporation.\n\nMIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 16.9873046875,
          "content": "<div align=\"center\">\n<img src=\"docs/img/nni_logo.png\" width=\"600\"/>\n</div>\n\n<br/>\n\n[![MIT licensed](https://img.shields.io/badge/license-MIT-brightgreen.svg)](LICENSE)\n[![Issues](https://img.shields.io/github/issues-raw/Microsoft/nni.svg)](https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen)\n[![Bugs](https://img.shields.io/github/issues/Microsoft/nni/bug.svg)](https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen+label%3Abug)\n[![Pull Requests](https://img.shields.io/github/issues-pr-raw/Microsoft/nni.svg)](https://github.com/Microsoft/nni/pulls?q=is%3Apr+is%3Aopen)\n[![Version](https://img.shields.io/github/release/Microsoft/nni.svg)](https://github.com/Microsoft/nni/releases)\n[![Documentation Status](https://readthedocs.org/projects/nni/badge/?version=stable)](https://nni.readthedocs.io/en/stable/?badge=stable)\n[![](https://img.shields.io/github/contributors-anon/microsoft/nni)](https://github.com/microsoft/nni/graphs/contributors)\n\n\n\n[<img src=\"docs/img/readme_banner.png\" width=\"100%\"/>](https://nni.readthedocs.io/en/stable)\n\nNNI automates feature engineering, neural architecture search, hyperparameter tuning, and model compression for deep learning. Find the latest features, API, examples and tutorials in our **[official documentation](https://nni.readthedocs.io/) ([简体中文版点这里](https://nni.readthedocs.io/zh/stable))**.\n\n## What's NEW! &nbsp;<a href=\"#nni-released-reminder\"><img width=\"48\" src=\"docs/img/release_icon.png\"></a>\n\n* **New release**: [v3.0 preview is available](https://github.com/microsoft/nni/releases/tag/v3.0rc1) - _released on May-5-2022_\n* **New demo available**: [Youtube entry](https://www.youtube.com/channel/UCKcafm6861B2mnYhPbZHavw) | [Bilibili 入口](https://space.bilibili.com/1649051673) - _last updated on June-22-2022_\n* **New research paper**: [SparTA: Deep-Learning Model Sparsity via Tensor-with-Sparsity-Attribute](https://www.usenix.org/system/files/osdi22-zheng-ningxin.pdf) - _published in OSDI 2022_\n* **New research paper**: [Privacy-preserving Online AutoML for Domain-Specific Face Detection](https://openaccess.thecvf.com/content/CVPR2022/papers/Yan_Privacy-Preserving_Online_AutoML_for_Domain-Specific_Face_Detection_CVPR_2022_paper.pdf) - _published in CVPR 2022_\n* **Newly upgraded documentation**: [Doc upgraded](https://nni.readthedocs.io/en/stable)\n\n\n## Installation\n\nSee the [NNI installation guide](https://nni.readthedocs.io/en/stable/installation.html) to install from pip, or build from source.\n\nTo install the current release:\n\n```\n$ pip install nni\n```\n\nTo update NNI to the latest version, add `--upgrade` flag to the above commands.\n\n## NNI capabilities in a glance\n\n<img src=\"docs/img/overview.svg\" width=\"100%\"/>\n\n<table>\n<tbody>\n<tr align=\"center\" valign=\"bottom\">\n<td></td>\n<td>\n<b>Hyperparameter Tuning</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n<td>\n<b>Neural Architecture Search</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n<td>\n<b>Model Compression</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n</tr>\n<tr valign=\"top\">\n<td align=\"center\" valign=\"middle\">\n<b>Algorithms</b>\n</td>\n<td>\n<ul>\n<li><b>Exhaustive search</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.gridsearch_tuner.GridSearchTuner\">Grid Search</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.random_tuner.RandomTuner\">Random</a></li>\n</ul>\n<li><b>Heuristic search</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.hyperopt_tuner.HyperoptTuner\">Anneal</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.evolution_tuner.EvolutionTuner\">Evolution</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.hyperband_advisor.Hyperband\">Hyperband</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.pbt_tuner.PBTTuner\">PBT</a></li>\n</ul>\n<li><b>Bayesian optimization</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.bohb_advisor.BOHB\">BOHB</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.dngo_tuner.DNGOTuner\">DNGO</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.gp_tuner.GPTuner\">GP</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.metis_tuner.MetisTuner\">Metis</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.smac_tuner.SMACTuner\">SMAC</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/reference/hpo.html#nni.algorithms.hpo.tpe_tuner.TpeTuner\">TPE</a></li>\n</ul>\n</ul>\n</td>\n<td>\n<ul>\n<li><b>Multi-trial</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#grid-search-strategy\">Grid Search</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#policy-based-rl-strategy\">Policy Based RL</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#random-strategy\">Random</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#regularized-evolution-strategy\">Regularized Evolution</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#tpe-strategy\">TPE</a></li>\n</ul>\n<li><b>One-shot</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#darts-strategy\">DARTS</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#enas-strategy\">ENAS</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#fbnet-strategy\">FBNet</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#proxylessnas-strategy\">ProxylessNAS</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html#spos-strategy\">SPOS</a></li>\n</ul>\n</ul>\n</td>\n<td>\n<ul>\n<li><b>Pruning</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#level-pruner\">Level</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#l1-norm-pruner\">L1 Norm</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#taylor-fo-weight-pruner\">Taylor FO Weight</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#movement-pruner\">Movement</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#agp-pruner\">AGP</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html#auto-compress-pruner\">Auto Compress</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/pruner.html\">More...</a></li>\n</ul>\n<li><b>Quantization</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#naive-quantizer\">Naive</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#qat-quantizer\">QAT</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#lsq-quantizer\">LSQ</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#observer-quantizer\">Observer</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#dorefa-quantizer\">DoReFa</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/compression/quantizer.html#bnn-quantizer\">BNN</a></li>\n</ul>\n</ul>\n</td>\n<tr align=\"center\" valign=\"bottom\">\n<td></td>\n<td>\n<b>Supported Frameworks</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n<td>\n<b>Training Services</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n<td>\n<b>Tutorials</b>\n<img src=\"docs/img/bar.png\" />\n</td>\n</tr>\n<tr valign=\"top\">\n<td align=\"center\" valign=\"middle\">\n<b>Supports</b>\n</td>\n<td>\n<ul>\n<li>PyTorch</li>\n<li>TensorFlow</li>\n<li>Scikit-learn</li>\n<li>XGBoost</li>\n<li>LightGBM</li>\n<li>MXNet</li>\n<li>Caffe2</li>\n<li>More...</li>\n</ul>\n</td>\n<td>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/local.html\">Local machine</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/remote.html\">Remote SSH servers</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/aml.html\">Azure Machine Learning (AML)</a></li>\n<li><b>Kubernetes Based</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/openpai.html\">OpenAPI</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/kubeflow.html\">Kubeflow</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/frameworkcontroller.html\">FrameworkController</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/adaptdl.html\">AdaptDL</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/paidlc.html\">PAI DLC</a></li>\n</ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/experiment/hybrid.html\">Hybrid training services</a></li>\n</ul>\n</td>\n<td>\n<ul>\n<li><b>HPO</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/hpo_quickstart_pytorch/main.html\">PyTorch</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/hpo_quickstart_tensorflow/main.html\">TensorFlow</a></li>\n</ul>\n<li><b>NAS</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/hello_nas.html\">Hello NAS</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/nasbench_as_dataset.html\">NAS Benchmarks</a></li>\n</ul>\n<li><b>Compression</b></li>\n<ul>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/pruning_quick_start.html\">Pruning</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/pruning_speed_up.html\">Pruning Speedup</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/quantization_quick_start.html\">Quantization</a></li>\n<li><a href=\"https://nni.readthedocs.io/en/latest/tutorials/quantization_speed_up.html\">Quantization Speedup</a></li>\n</ul>\n</ul>\n</td>\n</tbody>\n</table>\n\n<img src=\"docs/static/img/webui.gif\" alt=\"webui\" width=\"100%\"/>\n\n## Resources\n\n* [NNI Documentation Homepage](https://nni.readthedocs.io/en/stable)\n* [NNI Installation Guide](https://nni.readthedocs.io/en/stable/installation.html)\n* [NNI Examples](https://nni.readthedocs.io/en/latest/examples.html)\n* [Python API Reference](https://nni.readthedocs.io/en/latest/reference/python_api.html)\n* [Releases (Change Log)](https://nni.readthedocs.io/en/latest/release.html)\n* [Related Research and Publications](https://nni.readthedocs.io/en/latest/notes/research_publications.html)\n* [Youtube Channel of NNI](https://www.youtube.com/channel/UCKcafm6861B2mnYhPbZHavw)\n* [Bilibili Space of NNI](https://space.bilibili.com/1649051673)\n* [Webinar of Introducing Retiarii: A deep learning exploratory-training framework on NNI](https://note.microsoft.com/MSR-Webinar-Retiarii-Registration-Live.html)\n* [Community Discussions](https://github.com/microsoft/nni/discussions)\n\n## Contribution guidelines\n\nIf you want to contribute to NNI, be sure to review the [contribution guidelines](https://nni.readthedocs.io/en/stable/notes/contributing.html), which includes instructions of submitting feedbacks, best coding practices, and code of conduct.\n\nWe use [GitHub issues](https://github.com/microsoft/nni/issues) to track tracking requests and bugs.\nPlease use [NNI Discussion](https://github.com/microsoft/nni/discussions) for general questions and new ideas.\nFor questions of specific use cases, please go to [Stack Overflow](https://stackoverflow.com/questions/tagged/nni).\n\nParticipating discussions via the following IM groups is also welcomed.\n\n|Gitter||WeChat|\n|----|----|----|\n|![image](https://user-images.githubusercontent.com/39592018/80665738-e0574a80-8acc-11ea-91bc-0836dc4cbf89.png)| OR |![image](https://github.com/scarlett2018/nniutil/raw/master/wechat.png)|\n\nOver the past few years, NNI has received thousands of feedbacks on GitHub issues, and pull requests from hundreds of contributors.\nWe appreciate all contributions from community to make NNI thrive.\n\n<img src=\"https://img.shields.io/github/contributors-anon/microsoft/nni\"/>\n\n<a href=\"https://github.com/microsoft/nni/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=microsoft/nni&max=240&columns=18\" /></a>\n\n## Test status\n\n### Essentials\n\n| Type | Status |\n| :---: | :---: |\n| Fast test | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/fast%20test?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=54&branchName=master) |\n| Full test - HPO | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20HPO?repoName=microsoft%2Fnni&branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=90&repoName=microsoft%2Fnni&branchName=master) |\n| Full test - NAS | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20NAS?repoName=microsoft%2Fnni&branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=89&repoName=microsoft%2Fnni&branchName=master) |\n| Full test - compression | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20compression?repoName=microsoft%2Fnni&branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=91&repoName=microsoft%2Fnni&branchName=master) |\n\n### Training services\n\n| Type | Status |\n| :---: | :---: |\n| Local - linux | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20local%20-%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=92&branchName=master) |\n| Local - windows | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20local%20-%20windows?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=98&branchName=master) |\n| Remote - linux to linux | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20remote%20-%20linux%20to%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=64&branchName=master) |\n| Remote - windows to windows | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20remote%20-%20windows%20to%20windows?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=99&branchName=master) |\n| OpenPAI | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20openpai%20-%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=65&branchName=master) |\n| Frameworkcontroller | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20frameworkcontroller?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=70&branchName=master) |\n| Kubeflow | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20kubeflow?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=69&branchName=master) |\n| Hybrid | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20hybrid?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=79&branchName=master) |\n| AzureML | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20aml?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=78&branchName=master) |\n\n## Related Projects\n\nTargeting at openness and advancing state-of-art technology, [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/) had also released few other open source projects.\n\n* [OpenPAI](https://github.com/Microsoft/pai) : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.\n* [FrameworkController](https://github.com/Microsoft/frameworkcontroller) : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.\n* [MMdnn](https://github.com/Microsoft/MMdnn) : A comprehensive, cross-framework solution to convert, visualize and diagnose deep neural network models. The \"MM\" in MMdnn stands for model management and \"dnn\" is an acronym for deep neural network.\n* [SPTAG](https://github.com/Microsoft/SPTAG) : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.\n* [nn-Meter](https://github.com/microsoft/nn-Meter) : An accurate inference latency predictor for DNN models on diverse edge devices.\n\nWe encourage researchers and students leverage these projects to accelerate the AI development and research.\n\n## License\n\nThe entire codebase is under [MIT license](LICENSE).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.7158203125,
          "content": "<!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK -->\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc751383(v=technet.10)), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://msrc.microsoft.com/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://www.microsoft.com/en-us/msrc/pgp-key-msrc).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc). \n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://microsoft.com/msrc/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://www.microsoft.com/en-us/msrc/cvd).\n\n<!-- END MICROSOFT SECURITY.MD BLOCK -->\n"
        },
        {
          "name": "crowdin.yml",
          "type": "blob",
          "size": 0.4560546875,
          "content": "project_id_env: CROWDIN_PROJECT_ID\napi_token_env: CROWDIN_PERSONAL_TOKEN\npreserve_hierarchy: true\nfiles:\n  - source: /docs/en_US/**/*\n    ignore:\n      - /docs/zh_CN/**/*\n    translation: /docs/%locale_with_underscore%/**/%original_file_name%\n  - source: '/**/*.[mM][dD]'\n    ignore:\n      - '/**/*_%locale_with_underscore%.md'\n      - /docs\n      - /%locale_with_underscore%\n      - /.github\n    translation: /%original_path%/%file_name%_%locale_with_underscore%.md\n"
        },
        {
          "name": "dependencies",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "nni",
          "type": "tree",
          "content": null
        },
        {
          "name": "nni_assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "pipelines",
          "type": "tree",
          "content": null
        },
        {
          "name": "pylintrc",
          "type": "blob",
          "size": 1.2109375,
          "content": "# Usage:\n#       python3 -m pylint --rcfile=PATH_TO_THIS_FILE PACKAGE_NAME\n# or\n#       python3 -m pylint --rcfile=PATH_TO_THIS_FILE SOURCE_FILE.py\n\n[SETTINGS]\n\nmax-line-length=140\n\nmax-args=8\nmax-locals=15\nmax-statements=50\nmax-attributes=15\n\nconst-naming-style=any\n\n# based on pylint 2.1.1\ndisable=W,C,R,I,no-member\n\n# will be enforced on CI Pipeline\nenable= unused-wildcard-import,\n        bad-whitespace,\n        unused-import,\n        bad-continuation,\n        wrong-import-order,\n        trailing-whitespace,\n        logging-not-lazy,\n        line-too-long,\n        unused-variable,\n        wildcard-import,\n#        useless-super-delegation,\n        len-as-condition,\n        logging-format-interpolation,\n        redefined-builtin,\n        deprecated-method \n\n# will change to `enable` one day\n# disable= missing-docstring\n\n# will not be enforced on CI but highly recommend contributor fixing it\n# enable=no-member,\n#        too-many-branches,\n#        protected-access \n\nignore-patterns=test*\n\n# List of members which are set dynamically and missed by pylint inference\ngenerated-members=numpy.*,torch.*,tensorflow.*,pycuda.*,tensorrt.*\n\nignored-modules=tensorflow,_winapi,msvcrt,tensorrt,pycuda,nni_node\n\nignore-paths=nni/retiarii\n"
        },
        {
          "name": "pyrightconfig.json",
          "type": "blob",
          "size": 0.787109375,
          "content": "{\n    \"ignore\": [\n        \"nni/algorithms/compression/pytorch\",\n        \"nni/algorithms/compression/tensorflow\",\n        \"nni/algorithms/compression/v2/pytorch/base/pruner.py\",\n        \"nni/algorithms/compression/v2/pytorch/pruning/amc_pruner.py\",\n        \"nni/algorithms/feature_engineering\",\n        \"nni/algorithms/hpo\",\n        \"nni/algorithms/nas\",\n        \"nni/common/device.py\",\n        \"nni/common/graph_utils.py\",\n        \"nni/compression\",\n        \"nni/retiarii\",\n        \"nni/smartparam.py\",\n        \"nni/tools/annotation\",\n        \"nni/tools/gpu_tool\",\n        \"nni/tools/jupyter_extension\",\n        \"nni/tools/nni_manager_scripts/collect_gpu_info.py\",\n        \"nni/tools/nnictl\",\n        \"nni/tools/trial_tool\"\n    ],\n    \"reportMissingImports\": false,\n    \"reportPrivateImportUsage\": false\n}\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 9.533203125,
          "content": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT license.\n\n\"\"\"\nScript for installation and distribution.\n\nYou can use environment variable `NNI_RELEASE` to set release version.\n\nIf release version is not set, default to a development build whose version string will be `999.dev0`.\n\n\n## Prepare Environment ##\n\nInstall development dependencies:\n\n  $ pip install -U -r dependencies/setup.txt\n  $ pip install -r dependencies/develop.txt\n\n\n## Development ##\n\nBuild and install for development:\n\n  $ python setup.py develop\n\nUninstall:\n\n  $ pip uninstall nni\n\nRemove generated files: (use \"--all\" to remove built wheel)\n\n  $ python setup.py clean [--all]\n\nCompile TypeScript modules without re-install:\n\n  $ python setup.py build_ts\n\n\n## Release ##\n\nBuild wheel package:\n\n  $ NNI_RELEASE=2.0 python setup.py build_ts\n  $ NNI_RELEASE=2.0 python setup.py bdist_wheel -p manylinux1_x86_64\n\nfor jupyterlab 2.x package:\n  $ JUPYTER_LAB_VERSION=2.3.1 NNI_RELEASE=2.0 python setup.py build_ts\n  $ JUPYTER_LAB_VERSION=2.3.1 NNI_RELEASE=2.0 python setup.py bdist_wheel -p manylinux1_x86_64\n\nWhere \"2.0\" is version string and \"manylinux1_x86_64\" is platform.\nThe platform may also be \"macosx_10_9_x86_64\" or \"win_amd64\".\n\n`build_ts` must be manually invoked before `bdist_wheel`,\nor setuptools cannot locate JS files which should be packed into wheel.\n\"\"\"\n\nfrom distutils.cmd import Command\nfrom distutils.command.build import build\nfrom distutils.command.clean import clean\nimport glob\nimport os\nimport shutil\nimport sys\n\nimport setuptools\nfrom setuptools.command.develop import develop\n\nimport setup_ts\n\nrelease = os.environ.get('NNI_RELEASE')\n\n#def _get_jupyter_lab_version():\n#    try:\n#        import jupyterlab\n#        return jupyterlab.__version__\n#    except ImportError:\n#        return '3.x'\n\n#jupyter_lab_major_version = _get_jupyter_lab_version().split('.')[0]\n\n#def check_jupyter_lab_version():\n#    environ_version = os.environ.get('JUPYTER_LAB_VERSION')\n#\n#    jupyter_lab_version = _get_jupyter_lab_version()\n#\n#    if environ_version:\n#        if jupyter_lab_version.split('.')[0] != environ_version.split('.')[0]:\n#            sys.exit(f'ERROR: To build a jupyter lab extension, run \"JUPYTER_LAB_VERSION={jupyter_lab_version}\", current: {environ_version} ')\n#    elif jupyter_lab_version.split('.')[0] != '3':\n#        sys.exit(f'ERROR: To build a jupyter lab extension, run \"JUPYTER_LAB_VERSION={jupyter_lab_version}\" first for nondefault version(3.x)')\n\ndef _setup():\n    setuptools.setup(\n        name = 'nni',\n        version = release or '999.dev0',\n        description = 'Neural Network Intelligence project',\n        long_description = open('README.md', encoding='utf-8').read(),\n        long_description_content_type = 'text/markdown',\n        url = 'https://github.com/Microsoft/nni',\n        author = 'Microsoft NNI Team',\n        author_email = 'nni@microsoft.com',\n        license = 'MIT',\n        classifiers = [\n            'License :: OSI Approved :: MIT License',\n            'Operating System :: MacOS :: MacOS X',\n            'Operating System :: Microsoft :: Windows :: Windows 10',\n            'Operating System :: POSIX :: Linux',\n            'Programming Language :: Python :: 3 :: Only',\n            'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        ],\n\n        packages = _find_python_packages(),\n        package_data = {\n            'nni': _find_requirements_txt() + _find_default_config(),  # setuptools issue #1806\n            'nni_assets': _find_asset_files(),\n            'nni_node': _find_node_files()  # note: this does not work before building\n        },\n\n        data_files = _get_data_files(),\n\n        python_requires = '>=3.7',\n        install_requires = _read_requirements_txt('dependencies/required.txt'),\n        extras_require = {\n            'Anneal': _read_requirements_txt('dependencies/required_extra.txt', 'Anneal'),\n            'SMAC': _read_requirements_txt('dependencies/required_extra.txt', 'SMAC'),\n            'BOHB': _read_requirements_txt('dependencies/required_extra.txt', 'BOHB'),\n            'PPOTuner': _read_requirements_txt('dependencies/required_extra.txt', 'PPOTuner'),\n            'DNGO': _read_requirements_txt('dependencies/required_extra.txt', 'DNGO'),\n            'all': _read_requirements_txt('dependencies/required_extra.txt'),\n        },\n        setup_requires = ['requests'],\n\n        entry_points = {\n            'console_scripts' : [\n                'nnictl = nni.tools.nnictl.nnictl:parse_args'\n            ]\n        },\n\n        cmdclass = {\n            'build': Build,\n            'build_ts': BuildTs,\n            'clean': Clean,\n            'develop': Develop,\n        }\n    )\n\ndef _get_data_files():\n    data_files = []\n#    if jupyter_lab_major_version == '2':\n#        extension_file = glob.glob(\"nni_node/jupyter-extension/extensions/nni-jupyter-extension*.tgz\")\n#        data_files = [('share/jupyter/lab/extensions', extension_file)]\n    return data_files\n\ndef _find_python_packages():\n    packages = []\n    for dirpath, dirnames, filenames in os.walk('nni'):\n        if '/__pycache__' not in dirpath and '/.mypy_cache' not in dirpath and '/default_config' not in dirpath:\n            packages.append(dirpath.replace('/', '.'))\n    return sorted(packages) + ['nni_assets', 'nni_node']\n\ndef _find_requirements_txt():\n    requirement_files = []\n    for dirpath, dirnames, filenames in os.walk('nni'):\n        if 'requirements.txt' in filenames:\n            requirement_files.append(os.path.join(dirpath[len('nni/'):], 'requirements.txt'))\n    return requirement_files\n\ndef _find_default_config():\n    return ['runtime/default_config/' + name for name in os.listdir('nni/runtime/default_config')]\n\ndef _find_asset_files():\n    files = []\n    for dirpath, dirnames, filenames in os.walk('nni_assets'):\n        for filename in filenames:\n            if os.path.splitext(filename)[1] == '.py':\n                files.append(os.path.join(dirpath[len('nni_assets/'):], filename))\n    return sorted(files)\n\ndef _find_node_files():\n    if not os.path.exists('nni_node'):\n        if release and 'build_ts' not in sys.argv and 'clean' not in sys.argv:\n            sys.exit('ERROR: To build a release version, run \"python setup.py build_ts\" first')\n        return []\n    files = []\n    for dirpath, dirnames, filenames in os.walk('nni_node'):\n        for filename in filenames:\n            files.append(os.path.join(dirpath[len('nni_node/'):], filename))\n    if '__init__.py' in files:\n        files.remove('__init__.py')\n    return sorted(files)\n\ndef _read_requirements_txt(file_path, section=None):\n    with open(file_path) as f:\n        lines = [line.strip() for line in f.readlines() if line.strip()]  # remove whitespaces and empty lines\n    if section is None:\n        return [line for line in lines if not line.startswith('#')]\n    selected_lines = []\n    started = False\n    for line in lines:\n        if started:\n            if line.startswith('#'):\n                return selected_lines\n            else:\n                selected_lines.append(line)\n        elif line.startswith('# ' + section):\n            started = True\n    return selected_lines\n\ndef _using_conda_or_virtual_environment():\n    return sys.prefix != sys.base_prefix or os.path.isdir(os.path.join(sys.prefix, 'conda-meta'))\n\nclass BuildTs(Command):\n    description = 'build TypeScript modules'\n\n    user_options = []\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        #check_jupyter_lab_version()\n        setup_ts.build(release)\n\nclass Build(build):\n    def run(self):\n        if not release:\n            sys.exit('Please set environment variable \"NNI_RELEASE=<release_version>\"')\n\n        #check_jupyter_lab_version()\n\n        if os.path.islink('nni_node/main.js'):\n            sys.exit('A development build already exists. Please uninstall NNI and run \"python3 setup.py clean\".')\n        open('nni/version.py', 'w').write(f\"__version__ = '{release}'\")\n        super().run()\n\nclass Develop(develop):\n    user_options = develop.user_options + [\n        ('no-user', None, 'Prevent automatically adding \"--user\"'),\n        ('skip-ts', None, 'Prevent building TypeScript modules')\n    ]\n\n    boolean_options = develop.boolean_options + ['no-user', 'skip-ts']\n\n    def initialize_options(self):\n        super().initialize_options()\n        self.no_user = None\n        self.skip_ts = None\n\n    def finalize_options(self):\n        # if `--user` or `--no-user` is explicitly set, do nothing\n        # otherwise activate `--user` if using system python\n        if not self.user and not self.no_user:\n            self.user = not _using_conda_or_virtual_environment()\n        super().finalize_options()\n\n    def run(self):\n        open('nni/version.py', 'w').write(\"__version__ = '999.dev0'\")\n        if not self.skip_ts:\n            setup_ts.build(release=None)\n        super().run()\n\nclass Clean(clean):\n    def finalize_options(self):\n        self._all = self.all\n        self.all = True  # always use `clean --all`\n        super().finalize_options()\n\n    def run(self):\n        super().run()\n        setup_ts.clean()\n        _clean_temp_files()\n        shutil.rmtree('nni.egg-info', ignore_errors=True)\n        if self._all:\n            shutil.rmtree('dist', ignore_errors=True)\n\n\ndef _clean_temp_files():\n    for pattern in _temp_files:\n        for path in glob.glob(pattern):\n            if os.path.islink(path) or os.path.isfile(path):\n                os.remove(path)\n            else:\n                shutil.rmtree(path)\n\n_temp_files = [\n    # unit test\n    'test/model_path/',\n    'test/temp.json',\n    'test/ut/sdk/*.pth',\n\n    # example\n    'nni_assets/**/data/',\n]\n\n\nif __name__ == '__main__':\n    _setup()\n"
        },
        {
          "name": "setup_ts.py",
          "type": "blob",
          "size": 11.982421875,
          "content": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT license.\n\n\"\"\"\nScript for building TypeScript modules.\nThis script is called by `setup.py` and common users should avoid using this directly.\n\nIt compiles TypeScript source files in `ts` directory,\nand copies (or links) JavaScript output as well as dependencies to `nni_node`.\n\nYou can set environment `GLOBAL_TOOLCHAIN=1` to use global node and npm, if you know what you are doing.\n\"\"\"\n\nfrom io import BytesIO\nimport json\nimport os\nfrom pathlib import Path\nimport platform\nimport shutil\nimport subprocess\nimport sys\nimport tarfile\nimport traceback\nfrom zipfile import ZipFile\n\n\nnode_version = 'v18.15.0'\n\ndef _print(*args, color='cyan'):\n    color_code = {'yellow': 33, 'cyan': 36}[color]\n    if sys.platform == 'win32':\n        print(*args, flush=True)\n    else:\n        print(f'\\033[1;{color_code}m#', *args, '\\033[0m', flush=True)\n\n#def _get_jupyter_lab_version():\n#    try:\n#        import jupyterlab\n#        return jupyterlab.__version__\n#    except ImportError:\n#        return '3.x'\n\ndef _get_glibc_minor_version():  # type: () -> int | None\n    try:\n        from pip._internal.utils.glibc import glibc_version_string\n        glibc_version = glibc_version_string()\n        if glibc_version is None:\n            return None\n        glibc_major, glibc_minor = map(int, glibc_version.split('.'))\n        if glibc_major < 2:\n            raise RuntimeError('Unsupported glibc version: ' + glibc_version)\n        elif glibc_major == 2:\n            _print(f'Detected glibc version: {glibc_version}')\n            return glibc_minor\n        return None\n    except ImportError:\n        _print('Unsupported pip version. Assuming glibc not found.', color='yellow')\n        return None\n\ndef _get_node_downloader():\n    if platform.machine() == 'x86_64':\n        glibc_minor = _get_glibc_minor_version()\n        if glibc_minor is None or glibc_minor >= 28:\n            _arch = 'x64'\n        elif glibc_minor >= 27:\n            _print('Detected deprecated glibc version < 2.28. Please upgrade as soon as possible.', color='yellow')\n            _arch = 'glibc-2.27'\n        else:\n            _print('glibc version is too low. We will try to use the node version compiled with glibc 2.23, '\n                   'but it might not work.', color='yellow')\n            _print('Please check your glibc version by running `ldd --version`, and upgrade it if necessary.',\n                   color='yellow')\n            _arch = 'glibc-2.23'\n    else:\n        _arch = platform.machine()\n\n    if _arch.startswith('glibc'):\n        node_legacy_version = 'v18.12.1'  # We might not upgrade node version for legacy builds every time.\n        node_spec = f'node-{node_legacy_version}-{sys.platform}-x64'\n        node_download_url = f'https://nni.blob.core.windows.net/cache/toolchain/node-{node_legacy_version}-{sys.platform}-{_arch}.tar.gz'\n        node_extractor = lambda data: tarfile.open(fileobj=BytesIO(data), mode='r:gz')\n    else:\n        node_spec = f'node-{node_version}-{sys.platform}-' + _arch\n        node_download_url = f'https://nodejs.org/dist/{node_version}/{node_spec}.tar.xz'\n        node_extractor = lambda data: tarfile.open(fileobj=BytesIO(data), mode='r:xz')\n    return node_download_url, node_spec, node_extractor\n\n#jupyter_lab_major_version = _get_jupyter_lab_version().split('.')[0]\n\ndef build(release):\n    \"\"\"\n    Compile TypeScript modules and copy or symlink to nni_node directory.\n\n    `release` is the version number without leading letter \"v\".\n\n    If `release` is None or empty, this is a development build and uses symlinks on Linux/macOS;\n    otherwise this is a release build and copies files instead.\n    On Windows it always copies files because creating symlink requires extra privilege.\n    \"\"\"\n    if release or not os.environ.get('GLOBAL_TOOLCHAIN'):\n        download_toolchain()\n    prepare_nni_node()\n    #update_package()\n    compile_ts(release)\n    if release or sys.platform == 'win32':\n        copy_nni_node(release)\n    else:\n        symlink_nni_node()\n    #restore_package()\n\ndef clean():\n    \"\"\"\n    Remove TypeScript-related intermediate files.\n    Python intermediate files are not touched here.\n    \"\"\"\n    shutil.rmtree('nni_node', ignore_errors=True)\n    shutil.rmtree('toolchain', ignore_errors=True)\n\n    for file_or_dir in generated_files:\n        path = Path(file_or_dir)\n        if path.is_symlink() or path.is_file():\n            path.unlink()\n        elif path.is_dir():\n            shutil.rmtree(path)\n\n\nif sys.platform == 'linux' or sys.platform == 'darwin':\n    node_executable = 'node'\n    node_download_url, node_spec, node_extractor = _get_node_downloader()\n    node_executable_in_tarball = 'bin/node'\n\n    npm_executable = 'bin/npm'\n\n    path_env_separator = ':'\n\nelif sys.platform == 'win32':\n    node_executable = 'node.exe'\n    node_spec = f'node-{node_version}-win-x64'\n    node_download_url = f'https://nodejs.org/dist/{node_version}/{node_spec}.zip'\n    node_extractor = lambda data: ZipFile(BytesIO(data))\n    node_executable_in_tarball = 'node.exe'\n\n    npm_executable = 'npm.cmd'\n\n    path_env_separator = ';'\n\nelse:\n    raise RuntimeError('Unsupported system')\n\n\ndef download_toolchain():\n    \"\"\"\n    Download and extract node.\n    \"\"\"\n    if Path('toolchain/node', node_executable_in_tarball).is_file():\n        return\n\n    Path('toolchain').mkdir(exist_ok=True)\n    import requests  # place it here so setup.py can install it before importing\n\n    _print(f'Downloading node.js from {node_download_url}')\n    resp = requests.get(node_download_url)\n    resp.raise_for_status()\n    _print('Extracting node.js')\n    tarball = node_extractor(resp.content)\n    tarball.extractall('toolchain')\n    shutil.rmtree('toolchain/node', ignore_errors=True)\n    Path('toolchain', node_spec).rename('toolchain/node')\n\n#def update_package():\n#    if jupyter_lab_major_version == '2':\n#        package_json = json.load(open('ts/jupyter_extension/package.json'))\n#        json.dump(package_json, open('ts/jupyter_extension/.package_default.json', 'w'), indent=2)\n#\n#        package_json['scripts']['build'] = 'tsc && jupyter labextension link .'\n#        package_json['dependencies']['@jupyterlab/application'] = '^2.3.0'\n#        package_json['dependencies']['@jupyterlab/launcher'] = '^2.3.0'\n#\n#        package_json['jupyterlab']['outputDir'] = 'build'\n#        json.dump(package_json, open('ts/jupyter_extension/package.json', 'w'), indent=2)\n#        print(f'updated package.json with {json.dumps(package_json, indent=2)}')\n\n#def restore_package():\n#    if jupyter_lab_major_version == '2':\n#        package_json = json.load(open('ts/jupyter_extension/.package_default.json'))\n#        print(f'stored package.json with {json.dumps(package_json, indent=2)}')\n#        json.dump(package_json, open('ts/jupyter_extension/package.json', 'w'), indent=2)\n#        os.remove('ts/jupyter_extension/.package_default.json')\n\ndef prepare_nni_node():\n    \"\"\"\n    Create clean nni_node diretory, then copy node runtime to it.\n    \"\"\"\n    shutil.rmtree('nni_node', ignore_errors=True)\n    Path('nni_node').mkdir()\n\n    Path('nni_node/__init__.py').write_text('\"\"\"NNI node.js modules.\"\"\"\\n')\n\n    node_src = Path('toolchain/node', node_executable_in_tarball)\n    node_dst = Path('nni_node', node_executable)\n    shutil.copy(node_src, node_dst)\n\n\ndef compile_ts(release):\n    \"\"\"\n    Use npm to download dependencies and compile TypeScript code.\n    \"\"\"\n    _print('Building NNI manager')\n    _npm('ts/nni_manager', 'install')\n    _npm('ts/nni_manager', 'run', 'build')\n    # todo: I don't think these should be here\n    shutil.rmtree('ts/nni_manager/dist/config', ignore_errors=True)\n    shutil.copytree('ts/nni_manager/config', 'ts/nni_manager/dist/config')\n\n    _print('Building web UI')\n    _npm('ts/webui', 'install')\n    if release:\n        _npm('ts/webui', 'run', 'release')\n    else:\n        _npm('ts/webui', 'run', 'build')\n\n    #_print('Building JupyterLab extension')\n    #try:\n    #    _yarn('ts/jupyter_extension')\n    #    _yarn('ts/jupyter_extension', 'build')\n    #except Exception:\n    #    if release:\n    #        raise\n    #    _print('Failed to build JupyterLab extension, skip for develop mode', color='yellow')\n    #    _print(traceback.format_exc(), color='yellow')\n\n\ndef symlink_nni_node():\n    \"\"\"\n    Create symlinks to compiled JS files.\n    If you manually modify and compile TS source files you don't need to install again.\n    \"\"\"\n    _print('Creating symlinks')\n\n    for path in Path('ts/nni_manager/dist').iterdir():\n        _symlink(path, Path('nni_node', path.name))\n    _symlink('ts/nni_manager/package.json', 'nni_node/package.json')\n    _symlink('ts/nni_manager/node_modules', 'nni_node/node_modules')\n\n    _symlink('ts/webui/build', 'nni_node/static')\n\n    #if jupyter_lab_major_version == '2':\n    #    _symlink('ts/jupyter_extension/build', 'nni_node/jupyter-extension')\n    #    _symlink(os.path.join(sys.exec_prefix, 'share/jupyter/lab/extensions'), 'nni_node/jupyter-extension/extensions')\n    #elif Path('ts/jupyter_extension/dist').exists():\n    #    _symlink('ts/jupyter_extension/dist', 'nni_node/jupyter-extension')\n\n\ndef copy_nni_node(version):\n    \"\"\"\n    Copy compiled JS files to nni_node.\n    This is meant for building release package, so you need to provide version string.\n    The version will written to `package.json` in nni_node directory,\n    while `package.json` in ts directory will be left unchanged.\n    \"\"\"\n    _print('Copying files')\n\n    if sys.version_info >= (3, 8):\n        shutil.copytree('ts/nni_manager/dist', 'nni_node', dirs_exist_ok=True)\n    else:\n        for item in os.listdir('ts/nni_manager/dist'):\n            subsrc = os.path.join('ts/nni_manager/dist', item)\n            subdst = os.path.join('nni_node', item)\n            if os.path.isdir(subsrc):\n                shutil.copytree(subsrc, subdst)\n            else:\n                shutil.copy2(subsrc, subdst)\n    shutil.copyfile('ts/nni_manager/package-lock.json', 'nni_node/package-lock.lock')\n    Path('nni_node/nni_manager.tsbuildinfo').unlink()\n\n    package_json = json.load(open('ts/nni_manager/package.json'))\n    if version:\n        while len(version.split('.')) < 3:  # node.js semver requires at least three parts\n            version = version + '.0'\n        package_json['version'] = version\n    json.dump(package_json, open('nni_node/package.json', 'w'), indent=2)\n\n    if sys.platform == 'win32':\n        # On Windows, manually install node-gyp for sqlite3.\n        _npm('ts/nni_manager', 'install', '--global', 'node-gyp')\n\n    # reinstall without development dependencies\n    prod_path = Path('nni_node').resolve()\n    _npm(str(prod_path), 'install', '--omit', 'dev')\n\n    shutil.copytree('ts/webui/build', 'nni_node/static')\n\n    #if jupyter_lab_major_version == '2':\n    #    shutil.copytree('ts/jupyter_extension/build', 'nni_node/jupyter-extension/build')\n    #    shutil.copytree(os.path.join(sys.exec_prefix, 'share/jupyter/lab/extensions'), 'nni_node/jupyter-extension/extensions')\n    #elif version or Path('ts/jupyter_extension/dist').exists():\n    #    shutil.copytree('ts/jupyter_extension/dist', 'nni_node/jupyter-extension')\n\n\n_npm_env = dict(os.environ)\n# `Path('nni_node').resolve()` does not work on Windows if the directory not exists\n_npm_env['PATH'] = str(Path().resolve() / 'nni_node') + path_env_separator + os.environ['PATH']\n_npm_path = Path().resolve() / 'toolchain/node' / npm_executable\n\ndef _npm(path, *args):\n    _print('npm ' + ' '.join(args) + f' (path: {path})')\n    if os.environ.get('GLOBAL_TOOLCHAIN'):\n        subprocess.run(['npm', *args], cwd=path, check=True)\n    else:\n        subprocess.run([str(_npm_path), *args], cwd=path, check=True, env=_npm_env)\n\n\ndef _symlink(target_file, link_location):\n    target = Path(target_file)\n    link = Path(link_location)\n    relative = os.path.relpath(target, link.parent)\n    link.symlink_to(relative, target.is_dir())\n\n\ngenerated_files = [\n    'ts/nni_manager/dist',\n    'ts/nni_manager/node_modules',\n    'ts/webui/build',\n    'ts/webui/node_modules',\n\n    # unit test\n    'ts/nni_manager/.nyc_output',\n    'ts/nni_manager/coverage',\n    'ts/nni_manager/exp_profile.json',\n    'ts/nni_manager/metrics.json',\n    'ts/nni_manager/trial_jobs.json',\n]\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "ts",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}