{
  "metadata": {
    "timestamp": 1736561192540,
    "page": 159,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "assafelovic/gpt-researcher",
      "stars": 15617,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".cursorrules",
          "type": "blob",
          "size": 5.7978515625,
          "content": "# Project Overview This project, named GPT-Researcher, LLM based autonomous agent that conducts local and web research on any topic and generates a comprehensive report with citations, is built using Next.js and TypeScript. It integrates various libraries for their strenghts. Your primary goal is to help with Next.js app router patterns, TypeScript type safety, Tailwind CSS best practices, code quality standards, and Python/FastAPI backend optimizations. # Key URLs - Project Home Page: https://gptr.dev/ - GitHub Repository: https://github.com/assafelovic/gpt-researcher - Documentation: https://docs.gptr.dev/ # Project Structure - Frontend user interface built with Next.js, TypeScript, and Tailwind CSS in `/frontend` - Static FastAPI version for lightweight deployments - Next.js version for production use with enhanced features - Multi-agent research system using LangChain and LangGraph in `/backend/multi_agents` - Browser, Editor, Researcher, Reviewer, Revisor, Writer, and Publisher agents - Task configuration and agent coordination - Document processing using Unstructured and PyMuPDF in `/backend/document_processing` - PDF, DOCX, and web content parsing - Text extraction and preprocessing - Report generation using LangChain and Jinja2 templates in `/backend/report_generation` - Template-based report structuring - Dynamic content formatting - Multiple output formats in `/backend/output_formats` - PDF via md2pdf - Markdown via mistune - DOCX via python-docx - Format conversion utilities - Export functionality - GPT Researcher core functionality in `/gpt_researcher` - Web scraping and content aggregation - Research planning and execution - Source validation and tracking - Query processing and response generation - Testing infrastructure in `/tests` - Unit tests for individual components - Integration tests for agent interactions - End-to-end research workflow tests - Mock data and fixtures for testing # Language Model Configuration - Default model: gpt-4-turbo - Alternative models: gpt-3.5-turbo, claude-3-opus - Temperature settings for different tasks - Context window management - Token limit handling - Cost optimization strategies # Error Handling - Research failure recovery - API rate limiting - Network timeout handling - Invalid input management - Source validation errors - Report generation failures # Performance - Parallel processing strategies - Caching mechanisms - Memory management - Response streaming - Resource allocation - Query optimization # Development Workflow - Branch naming conventions - Commit message format - PR review process - Testing requirements - Documentation updates - Version control guidelines # API Documentation - REST endpoints - WebSocket events - Request/Response formats - Authentication methods - Rate limits - Error codes # Monitoring - Performance metrics - Error tracking - Usage statistics - Cost monitoring - Research quality metrics - User feedback tracking # Frontend Components - Static FastAPI version for lightweight deployments - Next.js version for production use with enhanced features # Backend Components - Multi-agent system architecture - Document processing pipeline - Report generation system - Output format handlers # Core Research Components - Web scraping and aggregation - Research planning and execution - Source validation - Query processing # Testing - Unit tests - Integration tests - End-to-end tests - Performance testing # Rule Violation Monitoring - Alert developer when changes conflict with project structure - Warn about deviations from coding standards - Flag unauthorized framework or library additions - Monitor for security and performance anti-patterns - Track API usage patterns that may violate guidelines - Report TypeScript strict mode violations - Identify accessibility compliance issues # Development Guidelines - Use TypeScript with strict mode enabled - Follow ESLint and Prettier configurations - Ensure components are responsive and accessible - Use Tailwind CSS for styling, following the project's design system - Minimize AI-generated comments, prefer self-documenting code - Follow React best practices and hooks guidelines - Validate all user inputs and API responses - Use existing components as reference implementations # Important Scripts - `npm run dev`: Start development server - `npm run build`: Build for production - `npm run test`: Run test suite - `python -m pytest`: Run Python tests - `docker-compose up`: Start all services - `docker-compose run gpt-researcher-tests`: Run test suite in container - `python -m uvicorn backend.server.server:app --host=0.0.0.0 --port=8000`: Start FastAPI server - `python -m uvicorn backend.server.server:app --reload`: Start FastAPI server with auto-reload for development - `python main.py`: Run the main application directly # AI Integration Guidelines - Prioritize type safety in all AI interactions - Follow LangChain and LangGraph best practices - Implement proper error handling for AI responses - Maintain context window limits - Handle rate limiting and API quotas - Validate AI outputs before processing - Log AI interactions for debugging # Lexicon - **GPT Researcher**: Autonomous research agent system - **Multi-Agent System**: Coordinated AI agents for research tasks - **Research Pipeline**: End-to-end research workflow - **Agent Roles**: Browser, Editor, Researcher, Reviewer, Revisor, Writer, Publisher - **Source Validation**: Verification of research sources - **Report Generation**: Process of creating final research output # Additional Resources - [Next.js Documentation](https://nextjs.org/docs) - [TypeScript Handbook](https://www.typescriptlang.org/docs/) - [Tailwind CSS Documentation](https://tailwindcss.com/docs) - [LangChain Documentation](https://python.langchain.com/docs/) - [FastAPI Documentation](https://fastapi.tiangolo.com/) - [Project Documentation](https://docs.gptr.dev/) End all your comments with a :-) symbol."
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0126953125,
          "content": ".git\noutput/\n"
        },
        {
          "name": ".env.example",
          "type": "blob",
          "size": 0.048828125,
          "content": "OPENAI_API_KEY=\nTAVILY_API_KEY=\nDOC_PATH=./my-docs"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5263671875,
          "content": "#Ignore env containing secrets\n.env\n.venv\n.envrc\n\n#Ignore Virtual Env\nenv/\nvenv/\n.venv/\n\n# Other Environments\nENV/\nenv.bak/\nvenv.bak/\n\n#Ignore generated outputs\noutputs/\n*.lock\ndist/\ngpt_researcher.egg-info/\n\n#Ignore my local docs\nmy-docs/\n\n#Ignore pycache\n**/__pycache__/\n\n#Ignore mypy cache\n.mypy_cache/\nnode_modules\n.idea\n.DS_Store\n.docusaurus\nbuild\ndocs/build\n\n.vscode/launch.json\n.langgraph-data/\n.next/\npackage-lock.json\n\n#Vim swp files\n*.swp\n\n# Log files\nlogs/\n*.orig\n*.log\nserver_log.txt\n\n#Cursor Rules\n.cursorrules\nCURSOR_RULES.md"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.0419921875,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe, as members, contributors, and leaders, pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, sexual identity, or\norientation.\n\nWe commit to acting and interacting in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n- Demonstrating empathy and kindness toward others\n- Being respectful of differing opinions, viewpoints, and experiences\n- Giving and gracefully accepting constructive feedback\n- Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\n- Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n- The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n- Trolling, insulting or derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or email address, without their explicit permission\n- Other conduct that could reasonably be considered inappropriate in a professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior deemed inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that do not\nalign with this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies to all community spaces and also applies when\nan individual is officially representing the community in public spaces.\nExamples include using an official email address, posting via an official\nsocial media account, or acting as an appointed representative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\n[Assaf.elovic@gmail.com](mailto:Assaf.elovic@gmail.com).\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period. This includes\navoiding interactions in community spaces and external channels like social media.\nViolating these terms may lead to a temporary or permanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any interaction or public\ncommunication with the community for a specified period. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of groups of individuals.\n\n**Consequence**: A permanent ban from any public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.7197265625,
          "content": "# Contributing to GPT Researcher\n\nFirst off, we'd like to welcome you and thank you for your interest and effort in contributing to our open-source project ❤️. Contributions of all forms are welcome—from new features and bug fixes to documentation and more.\n\nWe are on a mission to build the #1 AI agent for comprehensive, unbiased, and factual research online, and we need your support to achieve this grand vision.\n\nPlease take a moment to review this document to make the contribution process easy and effective for everyone involved.\n\n## Reporting Issues\n\nIf you come across any issue or have an idea for an improvement, don't hesitate to create an issue on GitHub. Describe your problem in sufficient detail, providing as much relevant information as possible. This way, we can reproduce the issue before attempting to fix it or respond appropriately.\n\n## Contributing Code\n\n1. **Fork the repository and create your branch from `master`.**  \n   If it’s not an urgent bug fix, branch from `master` and work on the feature or fix there.\n\n2. **Make your changes.**  \n   Implement your changes following best practices for coding in the project's language.\n\n3. **Test your changes.**  \n   Ensure that your changes pass all tests if any exist. If the project doesn’t have automated tests, test your changes manually to confirm they behave as expected.\n\n4. **Follow the coding style.**  \n   Ensure your code adheres to the coding conventions used throughout the project, including indentation, accurate comments, etc.\n\n5. **Commit your changes.**  \n   Make your Git commits informative and concise. This is very helpful for others when they look at the Git log.\n\n6. **Push to your fork and submit a pull request.**  \n   When your work is ready and passes tests, push your branch to your fork of the repository and submit a pull request from there.\n\n7. **Pat yourself on the back and wait for review.**  \n   Your work is done, congratulations! Now sit tight. The project maintainers will review your submission as soon as possible. They might suggest changes or ask for improvements. Both constructive conversation and patience are key to the collaboration process.\n\n## Documentation\n\nIf you would like to contribute to the project's documentation, please follow the same steps: fork the repository, make your changes, test them, and submit a pull request.\n\nDocumentation is a vital part of any software. It's not just about having good code; ensuring that users and contributors understand what's going on, how to use the software, or how to contribute is crucial.\n\nWe're grateful for all our contributors, and we look forward to building the world's leading AI research agent hand-in-hand with you. Let's harness the power of open source and AI to change the world together!\n"
        },
        {
          "name": "CURSOR_RULES.md",
          "type": "blob",
          "size": 6.1025390625,
          "content": "> **Note**: This is a readable copy of the `.cursorrules` file maintained for legibility. The actual rules are implemented from the `.cursorrules` file in the root directory.\n\n# GPT-Researcher Cursor Rules\n\n## Project Overview\nThis project, named GPT-Researcher, is an LLM-based autonomous agent that conducts local and web research on any topic and generates a comprehensive report with citations. It is built using Next.js and TypeScript, integrating various libraries for their strengths.\n\nYour primary goal is to help with:\n- Next.js app router patterns\n- TypeScript type safety\n- Tailwind CSS best practices\n- Code quality standards\n- Python/FastAPI backend optimizations\n\n## Key URLs\n- Project Home Page: https://gptr.dev/\n- GitHub Repository: https://github.com/assafelovic/gpt-researcher\n- Documentation: https://docs.gptr.dev/\n\n## Project Structure\n- Frontend user interface built with Next.js, TypeScript, and Tailwind CSS in `/frontend`\n  - Static FastAPI version for lightweight deployments\n  - Next.js version for production use with enhanced features\n\n- Multi-agent research system using LangChain and LangGraph in `/backend/multi_agents`\n  - Browser, Editor, Researcher, Reviewer, Revisor, Writer, and Publisher agents\n  - Task configuration and agent coordination\n\n- Document processing using Unstructured and PyMuPDF in `/backend/document_processing`\n  - PDF, DOCX, and web content parsing\n  - Text extraction and preprocessing\n\n- Report generation using LangChain and Jinja2 templates in `/backend/report_generation`\n  - Template-based report structuring\n  - Dynamic content formatting\n\n- Multiple output formats in `/backend/output_formats`\n  - PDF via md2pdf\n  - Markdown via mistune\n  - DOCX via python-docx\n  - Format conversion utilities\n  - Export functionality\n\n- GPT Researcher core functionality in `/gpt_researcher`\n  - Web scraping and content aggregation\n  - Research planning and execution\n  - Source validation and tracking\n  - Query processing and response generation\n\n- Testing infrastructure in `/tests`\n  - Unit tests for individual components\n  - Integration tests for agent interactions\n  - End-to-end research workflow tests\n  - Mock data and fixtures for testing\n\n## Language Model Configuration\n- Default model: gpt-4-turbo\n- Alternative models: gpt-3.5-turbo, claude-3-opus\n- Temperature settings for different tasks\n- Context window management\n- Token limit handling\n- Cost optimization strategies\n\n## Error Handling\n- Research failure recovery\n- API rate limiting\n- Network timeout handling\n- Invalid input management\n- Source validation errors\n- Report generation failures\n\n## Performance\n- Parallel processing strategies\n- Caching mechanisms\n- Memory management\n- Response streaming\n- Resource allocation\n- Query optimization\n\n## Development Workflow\n- Branch naming conventions\n- Commit message format\n- PR review process\n- Testing requirements\n- Documentation updates\n- Version control guidelines\n\n## API Documentation\n- REST endpoints\n- WebSocket events\n- Request/Response formats\n- Authentication methods\n- Rate limits\n- Error codes\n\n## Monitoring\n- Performance metrics\n- Error tracking\n- Usage statistics\n- Cost monitoring\n- Research quality metrics\n- User feedback tracking\n\n## Frontend Components\n- Static FastAPI version for lightweight deployments\n- Next.js version for production use with enhanced features\n\n## Backend Components\n- Multi-agent system architecture\n- Document processing pipeline\n- Report generation system\n- Output format handlers\n\n## Core Research Components\n- Web scraping and aggregation\n- Research planning and execution\n- Source validation\n- Query processing\n\n## Testing\n- Unit tests\n- Integration tests\n- End-to-end tests\n- Performance testing\n\n## Rule Violation Monitoring\n- Alert developer when changes conflict with project structure\n- Warn about deviations from coding standards\n- Flag unauthorized framework or library additions\n- Monitor for security and performance anti-patterns\n- Track API usage patterns that may violate guidelines\n- Report TypeScript strict mode violations\n- Identify accessibility compliance issues\n\n## Development Guidelines\n- Use TypeScript with strict mode enabled\n- Follow ESLint and Prettier configurations\n- Ensure components are responsive and accessible\n- Use Tailwind CSS for styling, following the project's design system\n- Minimize AI-generated comments, prefer self-documenting code\n- Follow React best practices and hooks guidelines\n- Validate all user inputs and API responses\n- Use existing components as reference implementations\n\n## Important Scripts\n- `npm run dev`: Start development server\n- `npm run build`: Build for production\n- `npm run test`: Run test suite\n- `python -m pytest`: Run Python tests\n- `python -m uvicorn backend.server.server:app --host=0.0.0.0 --port=8000`: Start FastAPI server\n- `python -m uvicorn backend.server.server:app --reload`: Start FastAPI server with auto-reload for development\n- `python main.py`: Run the main application directly\n- `docker-compose up`: Start all services\n- `docker-compose run gpt-researcher-tests`: Run test suite in container\n\n## AI Integration Guidelines\n- Prioritize type safety in all AI interactions\n- Follow LangChain and LangGraph best practices\n- Implement proper error handling for AI responses\n- Maintain context window limits\n- Handle rate limiting and API quotas\n- Validate AI outputs before processing\n- Log AI interactions for debugging\n\n## Lexicon\n- **GPT Researcher**: Autonomous research agent system\n- **Multi-Agent System**: Coordinated AI agents for research tasks\n- **Research Pipeline**: End-to-end research workflow\n- **Agent Roles**: Browser, Editor, Researcher, Reviewer, Revisor, Writer, Publisher\n- **Source Validation**: Verification of research sources\n- **Report Generation**: Process of creating final research output\n\n## Additional Resources\n- [Next.js Documentation](https://nextjs.org/docs)\n- [TypeScript Handbook](https://www.typescriptlang.org/docs/)\n- [Tailwind CSS Documentation](https://tailwindcss.com/docs)\n- [LangChain Documentation](https://python.langchain.com/docs/)\n- [FastAPI Documentation](https://fastapi.tiangolo.com/)\n- [Project Documentation](https://docs.gptr.dev/)\n\n_Note: End all your comments with a :-) symbol._ "
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.7529296875,
          "content": "# Stage 1: Browser and build tools installation\nFROM python:3.11.4-slim-bullseye AS install-browser\n\n# Install Chromium, Chromedriver, Firefox, Geckodriver, and build tools in one layer\nRUN apt-get update && \\\n    apt-get satisfy -y \"chromium, chromium-driver (>= 115.0)\" && \\\n    apt-get install -y --no-install-recommends firefox-esr wget build-essential && \\\n    wget https://github.com/mozilla/geckodriver/releases/download/v0.33.0/geckodriver-v0.33.0-linux64.tar.gz && \\\n    tar -xvzf geckodriver-v0.33.0-linux64.tar.gz && \\\n    chmod +x geckodriver && \\\n    mv geckodriver /usr/local/bin/ && \\\n    rm geckodriver-v0.33.0-linux64.tar.gz && \\\n    chromium --version && chromedriver --version && \\\n    rm -rf /var/lib/apt/lists/*  # Clean up apt lists to reduce image size\n\n# Stage 2: Python dependencies installation\nFROM install-browser AS gpt-researcher-install\n\nENV PIP_ROOT_USER_ACTION=ignore\nWORKDIR /usr/src/app\n\n# Copy and install Python dependencies in a single layer to optimize cache usage\nCOPY ./requirements.txt ./requirements.txt\nCOPY ./multi_agents/requirements.txt ./multi_agents/requirements.txt\n\nRUN pip install --no-cache-dir -r requirements.txt && \\\n    pip install --no-cache-dir -r multi_agents/requirements.txt\n\n# Stage 3: Final stage with non-root user and app\nFROM gpt-researcher-install AS gpt-researcher\n\n# Create a non-root user for security\nRUN useradd -ms /bin/bash gpt-researcher && \\\n    chown -R gpt-researcher:gpt-researcher /usr/src/app\n\nUSER gpt-researcher\nWORKDIR /usr/src/app\n\n# Copy the rest of the application files with proper ownership\nCOPY --chown=gpt-researcher:gpt-researcher ./ ./\n\n# Expose the application's port\nEXPOSE 8000\n\n# Define the default command to run the application\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Procfile",
          "type": "blob",
          "size": 0.076171875,
          "content": "web: python -m uvicorn backend.server.server:app --host=0.0.0.0 --port=${PORT}"
        },
        {
          "name": "README-ja_JP.md",
          "type": "blob",
          "size": 12.12109375,
          "content": "<div align=\"center\">\n<!--<h1 style=\"display: flex; align-items: center; gap: 10px;\">\n  <img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/a45bac7c-092c-42e5-8eb6-69acbf20dde5\" alt=\"Logo\" width=\"25\">\n  GPT Researcher\n</h1>-->\n<img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3\" alt=\"Logo\" width=\"80\">\n\n\n####\n\n[![公式サイト](https://img.shields.io/badge/公式サイト-gptr.dev-blue?style=for-the-badge&logo=world&logoColor=white)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev)\n[![Discord Follow](https://img.shields.io/discord/1127851779011391548?style=for-the-badge&logo=discord&label=Chat%20on%20Discord)](https://discord.gg/QgZXvJAccX)\n\n[![PyPI version](https://img.shields.io/pypi/v/gpt-researcher?logo=pypi&logoColor=white&style=flat)](https://badge.fury.io/py/gpt-researcher)\n![GitHub Release](https://img.shields.io/github/v/release/assafelovic/gpt-researcher?style=flat&logo=github)\n[![Open In Colab](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&label=%20&style=flat&logoSize=40)](https://colab.research.google.com/github/assafelovic/gpt-researcher/blob/master/docs/docs/examples/pip-run.ipynb)\n[![Docker Image Version](https://img.shields.io/docker/v/elestio/gpt-researcher/latest?arch=amd64&style=flat&logo=docker&logoColor=white&color=1D63ED)](https://hub.docker.com/r/gptresearcher/gpt-researcher)\n[![Twitter Follow](https://img.shields.io/twitter/follow/assaf_elovic?style=social)](https://twitter.com/assaf_elovic)\n\n[English](README.md) |\n[中文](README-zh_CN.md) |\n[日本語](README-ja_JP.md) |\n[한국어](README-ko_KR.md)\n</div>\n\n# 🔎 GPT Researcher\n\n**GPT Researcher は、さまざまなタスクに対する包括的なオンラインリサーチのために設計された自律エージェントです。**\n\nこのエージェントは、詳細で事実に基づいた偏りのない研究レポートを生成することができ、関連するリソース、アウトライン、およびレッスンに焦点を当てるためのカスタマイズオプションを提供します。最近の [Plan-and-Solve](https://arxiv.org/abs/2305.04091) および [RAG](https://arxiv.org/abs/2005.11401) 論文に触発され、GPT Researcher は速度、決定論、および信頼性の問題に対処し、同期操作ではなく並列化されたエージェント作業を通じてより安定したパフォーマンスと高速化を提供します。\n\n**私たちの使命は、AIの力を活用して、個人や組織に正確で偏りのない事実に基づいた情報を提供することです。**\n\n## なぜGPT Researcherなのか？\n\n- 手動の研究タスクで客観的な結論を形成するには時間がかかることがあり、適切なリソースと情報を見つけるのに数週間かかることもあります。\n- 現在のLLMは過去の情報に基づいて訓練されており、幻覚のリスクが高く、研究タスクにはほとんど役に立ちません。\n- 現在のLLMは短いトークン出力に制限されており、長く詳細な研究レポート（2,000語以上）には不十分です。\n- Web検索を可能にするサービス（ChatGPT + Webプラグインなど）は、限られたリソースとコンテンツのみを考慮し、場合によっては表面的で偏った回答をもたらします。\n- Webソースの選択のみを使用すると、研究タスクの正しい結論を導く際にバイアスが生じる可能性があります。\n\n## アーキテクチャ\n主なアイデアは、「プランナー」と「実行」エージェントを実行することであり、プランナーは研究する質問を生成し、実行エージェントは生成された各研究質問に基づいて最も関連性の高い情報を探します。最後に、プランナーはすべての関連情報をフィルタリングおよび集約し、研究レポートを作成します。<br /> <br /> \nエージェントは、研究タスクを完了するために gpt-4o-mini と gpt-4o（128K コンテキスト）の両方を活用します。必要に応じてそれぞれを使用することでコストを最適化します。**平均的な研究タスクは完了するのに約3分かかり、コストは約0.1ドルです**。\n\n<div align=\"center\">\n<img align=\"center\" height=\"500\" src=\"https://cowriter-images.s3.amazonaws.com/architecture.png\">\n</div>\n\n\n詳細説明:\n* 研究クエリまたはタスクに基づいて特定のドメインエージェントを作成します。\n* 研究タスクに対する客観的な意見を形成する一連の研究質問を生成します。\n* 各研究質問に対して、与えられたタスクに関連する情報をオンラインリソースから収集するクローラーエージェントをトリガーします。\n* 各収集されたリソースについて、関連情報に基づいて要約し、そのソースを追跡します。\n* 最後に、すべての要約されたソースをフィルタリングおよび集約し、最終的な研究レポートを生成します。\n\n## デモ\nhttps://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda\n\n## チュートリアル\n - [動作原理](https://docs.gptr.dev/blog/building-gpt-researcher)\n - [インストール方法](https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea)\n - [ライブデモ](https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8)\n\n## 特徴\n- 📝 研究、アウトライン、リソース、レッスンレポートを生成\n- 🌐 各研究で20以上のWebソースを集約し、客観的で事実に基づいた結論を形成\n- 🖥️ 使いやすいWebインターフェース（HTML/CSS/JS）を含む\n- 🔍 JavaScriptサポート付きのWebソースをスクレイピング\n- 📂 訪問および使用されたWebソースのコンテキストを追跡\n- 📄 研究レポートをPDF、Wordなどにエクスポート\n\n## 📖 ドキュメント\n\n完全なドキュメントについては、[こちら](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started)を参照してください：\n\n- 入門（インストール、環境設定、簡単な例）\n- 操作例（デモ、統合、dockerサポート）\n- 参考資料（API完全ドキュメント）\n- Tavilyアプリケーションインターフェースの統合（コア概念の高度な説明）\n\n## クイックスタート\n> **ステップ 0** - Python 3.11 以降をインストールします。[こちら](https://www.tutorialsteacher.com/python/install-python)を参照して、ステップバイステップのガイドを確認してください。\n\n<br />\n\n> **ステップ 1** - プロジェクトをダウンロードします\n\n```bash\n$ git clone https://github.com/assafelovic/gpt-researcher.git\n$ cd gpt-researcher\n```\n\n<br />\n\n> **ステップ2** - 依存関係をインストールします\n```bash\n$ pip install -r requirements.txt\n```\n<br />\n\n> **ステップ 3** - OpenAI キーと Tavily API キーを使用して .env ファイルを作成するか、直接エクスポートします\n\n```bash\n$ export OPENAI_API_KEY={Your OpenAI API Key here}\n```\n```bash\n$ export TAVILY_API_KEY={Your Tavily API Key here}\n```\n\n- **LLMには、[OpenAI GPT](https://platform.openai.com/docs/guides/gpt) を使用することをお勧めします**が、[Langchain Adapter](https://python.langchain.com/docs/guides/adapters/openai) がサポートする他の LLM モデル（オープンソースを含む）を使用することもできます。llm モデルとプロバイダーを config/config.py で変更するだけです。[このガイド](https://python.langchain.com/docs/integrations/llms/) に従って、LLM を Langchain と統合する方法を学んでください。\n- **検索エンジンには、[Tavily Search API](https://app.tavily.com)（LLM 用に最適化されています）を使用することをお勧めします**が、他の検索エンジンを選択することもできます。config/config.py で検索プロバイダーを「duckduckgo」、「googleAPI」、「googleSerp」、「searchapi」、「searx」に変更するだけです。次に、config.py ファイルに対応する env API キーを追加します。\n- **最適なパフォーマンスを得るために、[OpenAI GPT](https://platform.openai.com/docs/guides/gpt) モデルと [Tavily Search API](https://app.tavily.com) を使用することを強くお勧めします。**\n<br />\n\n> **ステップ 4** - FastAPI を使用してエージェントを実行します\n\n```bash\n$ uvicorn main:app --reload\n```\n<br />\n\n> **ステップ 5** - 任意のブラウザで http://localhost:8000 にアクセスして、リサーチを楽しんでください！\n\nDocker の使い方や機能とサービスの詳細については、[ドキュメント](https://docs.gptr.dev) ページをご覧ください。\n\n## 🚀 貢献\n私たちは貢献を大歓迎します！興味がある場合は、[貢献](CONTRIBUTING.md) をご覧ください。\n\n私たちの[ロードマップ](https://trello.com/b/3O7KBePw/gpt-researcher-roadmap) ページを確認し、私たちの使命に参加することに興味がある場合は、[Discord コミュニティ](https://discord.gg/QgZXvJAccX) を通じてお問い合わせください。\n\n## ✉️ サポート / お問い合わせ\n- [コミュニティディスカッション](https://discord.gg/spBgZmm3Xe)\n- 私たちのメール: support@tavily.com\n\n## 🛡 免責事項\n\nこのプロジェクト「GPT Researcher」は実験的なアプリケーションであり、明示または黙示のいかなる保証もなく「現状のまま」提供されます。私たちは学術目的のためにMITライセンスの下でコードを共有しています。ここに記載されている内容は学術的なアドバイスではなく、学術論文や研究論文での使用を推奨するものではありません。\n\n私たちの客観的な研究主張に対する見解：\n1. 私たちのスクレイピングシステムの主な目的は、不正確な事実を減らすことです。どうやって解決するのか？私たちがスクレイピングするサイトが多ければ多いほど、誤ったデータの可能性は低くなります。各研究で20の情報を収集し、それらがすべて間違っている可能性は非常に低いです。\n2. 私たちの目標はバイアスを排除することではなく、可能な限りバイアスを減らすことです。**私たちはここでコミュニティとして最も効果的な人間と機械の相互作用を探求しています**。\n3. 研究プロセスでは、人々も自分が研究しているトピックに対してすでに意見を持っているため、バイアスがかかりやすいです。このツールは多くの意見を収集し、偏った人が決して読まないであろう多様な見解を均等に説明します。\n\n**GPT-4 言語モデルの使用は、トークンの使用により高額な費用がかかる可能性があることに注意してください**。このプロジェクトを利用することで、トークンの使用状況と関連する費用を監視および管理する責任があることを認めたことになります。OpenAI API の使用状況を定期的に確認し、予期しない料金が発生しないように必要な制限やアラートを設定することを強くお勧めします。\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#assafelovic/gpt-researcher\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n  </picture>\n</a>\n</p>\n"
        },
        {
          "name": "README-ko_KR.md",
          "type": "blob",
          "size": 15.3583984375,
          "content": "<div align=\"center\">\n<!--<h1 style=\"display: flex; align-items: center; gap: 10px;\">\n  <img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/a45bac7c-092c-42e5-8eb6-69acbf20dde5\" alt=\"Logo\" width=\"25\">\n  GPT Researcher\n</h1>-->\n<img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3\" alt=\"Logo\" width=\"80\">\n\n\n####\n\n[![Website](https://img.shields.io/badge/Official%20Website-gptr.dev-teal?style=for-the-badge&logo=world&logoColor=white&color=0891b2)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev)\n[![Discord Follow](https://img.shields.io/discord/1127851779011391548?style=for-the-badge&logo=discord&label=Chat%20on%20Discord)](https://discord.gg/QgZXvJAccX)\n\n[![PyPI version](https://img.shields.io/pypi/v/gpt-researcher?logo=pypi&logoColor=white&style=flat)](https://badge.fury.io/py/gpt-researcher)\n![GitHub Release](https://img.shields.io/github/v/release/assafelovic/gpt-researcher?style=flat&logo=github)\n[![Open In Colab](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&label=%20&style=flat&logoSize=40)](https://colab.research.google.com/github/assafelovic/gpt-researcher/blob/master/docs/docs/examples/pip-run.ipynb)\n[![Docker Image Version](https://img.shields.io/docker/v/elestio/gpt-researcher/latest?arch=amd64&style=flat&logo=docker&logoColor=white&color=1D63ED)](https://hub.docker.com/r/gptresearcher/gpt-researcher)\n[![Twitter Follow](https://img.shields.io/twitter/follow/assaf_elovic?style=social)](https://twitter.com/assaf_elovic)\n\n[English](README.md) |\n[中文](README-zh_CN.md) |\n[日本語](README-ja_JP.md) |\n[한국어](README-ko_KR.md)\n</div>\n\n# 🔎 GPT Researcher\n\n**GPT Researcher는 다양한 작업을 대해 포괄적인 온라인 연구를 수행하도록 설계된 자율 에이전트입니다.**\n\n이 에이전트는 세부적이고 사실에 기반하며 편견 없는 연구 보고서를 생성할 수 있으며, 관련 리소스와 개요에 초점을 맞춘 맞춤형 옵션을 제공합니다.  최근 발표된 [Plan-and-Solve](https://arxiv.org/abs/2305.04091) 및 [RAG](https://arxiv.org/abs/2005.11401) 논문에서 영감을 받아 GPT Researcher는 잘못된 정보, 속도, 결정론적 접근 방식, 신뢰성 문제를 해결하고, 동기화 작업이 아닌 병렬 에이전트 작업을 통해 더 안정적이고 빠른 성능을 제공합니다.\n\n**우리의 목표는 AI의 힘을 활용하여 개인과 조직에게 정확하고 편향 없는 사실에 기반한 정보를 제공하는 것입니다.**\n\n## 왜 GPT Researcher인가?\n\n- 직접 수행하는 연구 과정은 객관적인 결론을 도출하는 데 시간이 오래 걸리며, 적절한 리소스와 정보를 찾는 데 몇 주가 걸릴 수 있습니다.\n- 현재의 대규모 언어 모델(LLM)은 과거 정보에 기반해 훈련되었으며, 환각 현상이 발생할 위험이 높아 연구 작업에는 적합하지 않습니다.\n- 현재 LLM은 짧은 토큰 출력으로 제한되며, 2,000단어 이상의 길고 자세한 연구 보고서를 작성하는 데는 충분하지 않습니다.\n- 웹 검색을 지원하는 서비스(예: ChatGPT 또는 Perplexity)는 제한된 리소스와 콘텐츠만을 고려하여 경우에 따라 피상적이고 편향된 답변을 제공합니다.\n- 웹 소스만을 사용하면 연구 작업에서 올바른 결론을 도출할 때 편향이 발생할 수 있습니다.\n\n## 데모\nhttps://github.com/user-attachments/assets/092e9e71-7e27-475d-8c4f-9dddd28934a3\n\n## 아키텍처\n주요 아이디어는 \"플래너\"와 \"실행\" 에이전트를 실행하는 것으로, 플래너는 연구할 질문을 생성하고, 실행 에이전트는 생성된 각 연구 질문에 따라 가장 관련성 높은 정보를 찾습니다. 마지막으로 플래너는 모든 관련 정보를 필터링하고 집계하여 연구 보고서를 작성합니다.\n<br /> <br /> \n에이전트는 `gpt-4o-mini`와 `gpt-4o`(128K 컨텍스트)를 활용하여 연구 작업을 완료합니다. 필요에 따라 각각을 사용하여 비용을 최적화합니다. **평균 연구 작업은 약 2분이 소요되며, 비용은 약 $0.005입니다.**.\n\n<div align=\"center\">\n<img align=\"center\" height=\"600\" src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/4ac896fd-63ab-4b77-9688-ff62aafcc527\">\n</div>\n\n구체적으로:\n* 연구 쿼리 또는 작업을 기반으로 도메인별 에이전트를 생성합니다.\n* 주어진 작업에 대해 객관적인 의견을 형성할 수 있는 일련의 연구 질문을 생성합니다.\n* 각 연구 질문에 대해 크롤러 에이전트를 실행하여 작업과 관련된 정보를 온라인 리소스에서 수집합니다.\n* 수집된 각 리소스에서 관련 정보를 요약하고 출처를 기록합니다.\n* 마지막으로, 요약된 모든 정보를 필터링하고 집계하여 최종 연구 보고서를 생성합니다.\n\n## 튜토리얼\n - [동작원리](https://docs.gptr.dev/blog/building-gpt-researcher)\n - [설치방법](https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea)\n - [라이브 데모](https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8)\n\n\n## 기능\n- 📝 로컬 문서 및 웹 소스를 사용하여 연구, 개요, 리소스 및 학습 보고서 생성\n- 📜 2,000단어 이상의 길고 상세한 연구 보고서 생성 가능\n- 🌐 연구당 20개 이상의 웹 소스를 집계하여 객관적이고 사실에 기반한 결론 도출\n- 🖥️ 경량 HTML/CSS/JS와 프로덕션용 (NextJS + Tailwind) UX/UI 포함\n- 🔍 자바스크립트 지원 웹 소스 스크래핑 기능\n- 📂 연구 과정에서 맥락과 메모리 추적 및 유지\n- 📄 연구 보고서를 PDF, Word 등으로 내보내기 지원\n\n## 📖 문서\n\n전체 문서(설치, 환경 설정, 간단한 예시)를 보려면 [여기](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started)를 참조하세요.\n\n- 시작하기 (설치, 환경 설정, 간단한 예시)\n- 맞춤 설정 및 구성\n- 사용 방법 예시 (데모, 통합, 도커 지원)\n- 참고자료 (전체 API 문서)\n\n## ⚙️ 시작하기\n### 설치\n> **1단계** - Python 3.11 또는 그 이상의 버전을 설치하세요. [여기](https://www.tutorialsteacher.com/python/install-python)를 참조하여 단계별 가이드를 확인하세요.\n\n> **2단계** - 프로젝트를 다운로드하고 해당 디렉토리로 이동하세요.\n\n```bash\ngit clone https://github.com/assafelovic/gpt-researcher.git\ncd gpt-researcher\n```\n\n> **3단계** - 두 가지 방법으로 API 키를 설정하세요: 직접 export하거나 `.env` 파일에 저장하세요.\n\nLinux/Windows에서 임시 설정을 하려면 export 방법을 사용하세요:\n\n```bash\nexport OPENAI_API_KEY={OpenAI API 키 입력}\nexport TAVILY_API_KEY={Tavily API 키 입력}\n```\n\n더 영구적인 설정을 원한다면, 현재의 `gpt-researcher` 디렉토리에 `.env` 파일을 생성하고 환경 변수를 입력하세요 (export 없이).\n\n- 기본 LLM은 [GPT](https://platform.openai.com/docs/guides/gpt)이지만, `claude`, `ollama3`, `gemini`, `mistral` 등 다른 LLM도 사용할 수 있습니다. LLM 제공자를 변경하는 방법은 [LLMs 문서](https://docs.gptr.dev/docs/gpt-researcher/llms/llms)를 참조하세요. 이 프로젝트는 OpenAI GPT 모델에 최적화되어 있습니다.\n- 기본 검색기는 [Tavily](https://app.tavily.com)이지만, `duckduckgo`, `google`, `bing`, `searchapi`, `serper`, `searx`, `arxiv`, `exa` 등의 검색기를 사용할 수 있습니다. 검색 제공자를 변경하는 방법은 [검색기 문서](https://docs.gptr.dev/docs/gpt-researcher/retrievers)를 참조하세요.\n\n### 빠른 시작\n\n> **1단계** - 필요한 종속성 설치\n\n```bash\npip install -r requirements.txt\n```\n\n> **2단계** - FastAPI로 에이전트 실행\n\n```bash\npython -m uvicorn main:app --reload\n```\n\n> **3단계** - 브라우저에서 http://localhost:8000 으로 이동하여 연구를 시작하세요!\n\n<br />\n\n**[Poetry](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started#poetry) 또는 [가상 환경](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started#virtual-environment)에 대해 배우고 싶다면, [문서](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started)를 참조하세요.**\n\n### PIP 패키지로 실행하기\n```bash\npip install gpt-researcher\n```\n\n```python\n...\nfrom gpt_researcher import GPTResearcher\n\nquery = \"왜 Nvidia 주식이 오르고 있나요?\"\nresearcher = GPTResearcher(query=query, report_type=\"research_report\")\n# 주어진 질문에 대한 연구 수행\nresearch_result = await researcher.conduct_research()\n# 보고서 작성\nreport = await researcher.write_report()\n...\n```\n\n**더 많은 예제와 구성 옵션은 [PIP 문서](https://docs.gptr.dev/docs/gpt-researcher/gptr/pip-package)를 참조하세요.**\n\n## Docker로 실행\n\n> **1단계** - [Docker 설치](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started-with-docker)\n\n> **2단계** - `.env.example` 파일을 복사하고 API 키를 추가한 후, 파일을 `.env`로 저장하세요.\n\n> **3단계** - docker-compose 파일에서 실행하고 싶지 않은 서비스를 주석 처리하세요.\n\n```bash\n$ docker-compose up --build\n```\n\n> **4단계** - docker-compose 파일에서 아무 것도 주석 처리하지 않았다면, 기본적으로 두 가지 프로세스가 시작됩니다:\n - localhost:8000에서 실행 중인 Python 서버<br>\n - localhost:3000에서 실행 중인 React 앱<br>\n\n브라우저에서 localhost:3000으로 이동하여 연구를 시작하세요!\n\n## 📄 로컬 문서로 연구하기\n\nGPT Researcher를 사용하여 로컬 문서를 기반으로 연구 작업을 수행할 수 있습니다. 현재 지원되는 파일 형식은 PDF, 일반 텍스트, CSV, Excel, Markdown, PowerPoint, Word 문서입니다.\n\n1단계: `DOC_PATH` 환경 변수를 설정하여 문서가 있는 폴더를 지정하세요.\n\n```bash\nexport DOC_PATH=\"./my-docs\"\n```\n\n2단계:\n - 프론트엔드 앱을 localhost:8000에서 실행 중이라면, \"Report Source\" 드롭다운 옵션에서 \"My Documents\"를 선택하세요.\n - GPT Researcher를 [PIP 패키지](https://docs.tavily.com/docs/gpt-researcher/pip-package)로 실행 중이라면, `report_source` 인수를 \"local\"로 설정하여 `GPTResearcher` 클래스를 인스턴스화하세요. [코드 예제](https://docs.gptr.dev/docs/gpt-researcher/context/tailored-research)를 참조하세요.\n\n## 👪 다중 에이전트 어시스턴트\n\nAI가 프롬프트 엔지니어링 및 RAG에서 다중 에이전트 시스템으로 발전함에 따라, 우리는 [LangGraph](https://python.langchain.com/v0.1/docs/langgraph/)로 구축된 새로운 다중 에이전트 어시스턴트를 소개합니다.\n\nLangGraph를 사용하면 여러 에이전트의 전문 기술을 활용하여 연구 과정의 깊이와 질을 크게 향상시킬 수 있습니다. 최근 [STORM](https://arxiv.org/abs/2402.14207) 논문에서 영감을 받아, 이 프로젝트는 AI 에이전트 팀이 주제에 대한 연구를 계획에서 출판까지 함께 수행하는 방법을 보여줍니다.\n\n평균 실행은 5-6 페이지 분량의 연구 보고서를 PDF, Docx, Markdown 형식으로 생성합니다.\n\n[여기](https://github.com/assafelovic/gpt-researcher/tree/master/multi_agents)에서 확인하거나 [문서](https://docs.gptr.dev/docs/gpt-researcher/multi_agents/langgraph)에서 자세한 내용을 참조하세요.\n\n## 🖥️ 프론트엔드 애플리케이션\n\nGPT-Researcher는 사용자 경험을 개선하고 연구 프로세스를 간소화하기 위해 향상된 프론트엔드를 제공합니다. 프론트엔드는 다음과 같은 기능을 제공합니다:\n\n- 연구 쿼리를 입력할 수 있는 직관적인 인터페이스\n- 연구 작업의 실시간 진행 상황 추적\n- 연구 결과의 대화형 디스플레이\n- 맞춤형 연구 경험을 위한 설정 가능\n\n두 가지 배포 옵션이 있습니다:\n1. FastAPI로 제공되는 경량 정적 프론트엔드\n2. 고급 기능을 제공하는 NextJS 애플리케이션\n\n프론트엔드 기능에 대한 자세한 설치 방법 및 정보를 원하시면 [문서 페이지](https://docs.gptr.dev/docs/gpt-researcher/frontend/frontend)를 참조하세요.\n\n## 🚀 기여하기\n우리는 기여를 적극 환영합니다! 관심이 있다면 [기여 가이드](https://github.com/assafelovic/gpt-researcher/blob/master/CONTRIBUTING.md)를 확인해 주세요.\n\n[로드맵](https://trello.com/b/3O7KBePw/gpt-researcher-roadmap) 페이지를 확인하고, 우리 [Discord 커뮤니티](https://discord.gg/QgZXvJAccX)에 가입하여 우리의 목표에 함께 참여해 주세요.\n<a href=\"https://github.com/assafelovic/gpt-researcher/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=assafelovic/gpt-researcher\" />\n</a>\n\n## ✉️ 지원 / 문의\n- [커뮤니티 Discord](https://discord.gg/spBgZmm3Xe)\n- 저자 이메일: assaf.elovic@gmail.com\n\n## 🛡️ 면책 조항\n\n이 프로젝트인 GPT Researcher는 실험적인 응용 프로그램이며, 명시적이거나 묵시적인 보증 없이 \"있는 그대로\" 제공됩니다. 우리는 이 코드를 학술적 목적으로 Apache 2 라이선스 하에 공유하고 있습니다. 여기에 있는 것은 학술적 조언이 아니며, 학술 또는 연구 논문에 사용하는 것을 권장하지 않습니다.\n\n편향되지 않은 연구 주장에 대한 우리의 견해:\n1. GPT Researcher의 주요 목표는 잘못된 정보와 편향된 사실을 줄이는 것입니다. 그 방법은 무엇일까요? 우리는 더 많은 사이트를 스크래핑할수록 잘못된 데이터의 가능성이 줄어든다고 가정합니다. 여러 사이트에서 정보를 스크래핑하고 가장 빈번한 정보를 선택하면, 모든 정보가 틀릴 확률은 매우 낮습니다.\n2. 우리는 편향을 완전히 제거하려고 하지는 않지만, 가능한 한 줄이는 것을 목표로 합니다. **우리는 인간과 LLM의 가장 효과적인 상호작용을 찾기 위한 커뮤니티입니다.**\n3. 연구에서 사람들도 이미 자신이 연구하는 주제에 대해 의견을 가지고 있기 때문에 편향되는 경향이 있습니다. 이 도구는 많은 의견을 스크래핑하며, 편향된 사람이라면 결코 읽지 않았을 다양한 견해를 고르게 설명합니다.\n\n**GPT-4 모델을 사용할 경우, 토큰 사용량 때문에 비용이 많이 들 수 있습니다.** 이 프로젝트를 사용하는 경우, 자신의 토큰 사용량 및 관련 비용을 모니터링하고 관리하는 것은 본인의 책임입니다. OpenAI API 사용량을 정기적으로 확인하고, 예상치 못한 비용을 방지하기 위해 필요한 한도를 설정하거나 알림을 설정하는 것이 좋습니다.\n\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#assafelovic/gpt-researcher\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n  </picture>\n</a>\n</p>\n"
        },
        {
          "name": "README-zh_CN.md",
          "type": "blob",
          "size": 9.3251953125,
          "content": "<div align=\"center\">\n<!--<h1 style=\"display: flex; align-items: center; gap: 10px;\">\n  <img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/a45bac7c-092c-42e5-8eb6-69acbf20dde5\" alt=\"Logo\" width=\"25\">\n  GPT Researcher\n</h1>-->\n<img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3\" alt=\"Logo\" width=\"80\">\n\n\n####\n\n[![Website](https://img.shields.io/badge/Official%20Website-gptr.dev-teal?style=for-the-badge&logo=world&logoColor=white&color=0891b2)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev)\n[![Discord Follow](https://img.shields.io/discord/1127851779011391548?style=for-the-badge&logo=discord&label=Chat%20on%20Discord)](https://discord.gg/QgZXvJAccX)\n\n[![PyPI version](https://img.shields.io/pypi/v/gpt-researcher?logo=pypi&logoColor=white&style=flat)](https://badge.fury.io/py/gpt-researcher)\n![GitHub Release](https://img.shields.io/github/v/release/assafelovic/gpt-researcher?style=flat&logo=github)\n[![Open In Colab](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&label=%20&style=flat&logoSize=40)](https://colab.research.google.com/github/assafelovic/gpt-researcher/blob/master/docs/docs/examples/pip-run.ipynb)\n[![Docker Image Version](https://img.shields.io/docker/v/elestio/gpt-researcher/latest?arch=amd64&style=flat&logo=docker&logoColor=white&color=1D63ED)](https://hub.docker.com/r/gptresearcher/gpt-researcher)\n[![Twitter Follow](https://img.shields.io/twitter/follow/assaf_elovic?style=social)](https://twitter.com/assaf_elovic)\n\n[English](README.md) |\n[中文](README-zh_CN.md) |\n[日本語](README-ja_JP.md) |\n[한국어](README-ko_KR.md)\n</div>\n\n# 🔎 GPT Researcher\n\n**GPT Researcher 是一个智能体代理，专为各种任务的综合在线研究而设计。**\n\n代理可以生成详细、正式且客观的研究报告，并提供自定义选项，专注于相关资源、结构框架和经验报告。受最近发表的[Plan-and-Solve](https://arxiv.org/abs/2305.04091) 和[RAG](https://arxiv.org/abs/2005.11401) 论文的启发，GPT Researcher 解决了速度、确定性和可靠性等问题，通过并行化的代理运行，而不是同步操作，提供了更稳定的性能和更高的速度。\n\n**我们的使命是利用人工智能的力量，为个人和组织提供准确、客观和事实的信息。**\n\n## 为什么选择GPT Researcher?\n\n- 因为人工研究任务形成客观结论可能需要时间和经历，有时甚至需要数周才能找到正确的资源和信息。\n- 目前的LLM是根据历史和过时的信息进行训练的，存在严重的幻觉风险，因此几乎无法胜任研究任务。\n- 网络搜索的解决方案（例如 ChatGPT + Web 插件）仅考虑有限的资源和内容，在某些情况下会导致肤浅的结论或不客观的答案。\n- 只使用部分资源可能会在确定研究问题或任务的正确结论时产生偏差。\n\n## 架构\n主要思想是运行“**计划者**”和“**执行**”代理，而**计划者**生成问题进行研究，“**执行**”代理根据每个生成的研究问题寻找最相关的信息。最后，“**计划者**”过滤和聚合所有相关信息并创建研究报告。<br /> <br /> \n代理同时利用 gpt-40-mini 和 gpt-4o（128K 上下文）来完成一项研究任务。我们仅在必要时使用这两种方法对成本进行优化。**研究任务平均耗时约 3 分钟，成本约为 ~0.1 美元**。\n\n<div align=\"center\">\n<img align=\"center\" height=\"500\" src=\"https://cowriter-images.s3.amazonaws.com/architecture.png\">\n</div>\n\n\n详细说明:\n* 根据研究搜索或任务创建特定领域的代理。\n* 生成一组研究问题，这些问题共同形成答案对任何给定任务的客观意见。\n* 针对每个研究问题，触发一个爬虫代理，从在线资源中搜索与给定任务相关的信息。\n* 对于每一个抓取的资源，根据相关信息进行汇总，并跟踪其来源。\n* 最后，对所有汇总的资料来源进行过滤和汇总，并生成最终研究报告。\n\n## 演示\nhttps://github.com/assafelovic/gpt-researcher/assets/13554167/a00c89a6-a295-4dd0-b58d-098a31c40fda\n\n## 教程\n - [运行原理](https://docs.gptr.dev/blog/building-gpt-researcher)\n - [如何安装](https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea)\n - [现场演示](https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8)\n\n## 特性\n- 📝 生成研究问题、大纲、资源和课题报告\n- 🌐 每项研究汇总超过20个网络资源，形成客观和真实的结论\n- 🖥️ 包括易于使用的web界面 (HTML/CSS/JS)\n- 🔍 支持JavaScript网络资源抓取功能\n- 📂 追踪访问过和使用过的网络资源和来源\n- 📄 将研究报告导出为PDF或其他格式...\n\n## 📖 文档\n\n请参阅[此处](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started)，了解完整文档：\n\n- 入门（安装、设置环境、简单示例）\n- 操作示例（演示、集成、docker 支持）\n- 参考资料（API完整文档）\n- Tavily 应用程序接口集成（核心概念的高级解释）\n\n## 快速开始\n> **步骤 0** - 安装 Python 3.11 或更高版本。[参见此处](https://www.tutorialsteacher.com/python/install-python) 获取详细指南。\n\n<br />\n\n> **步骤 1** - 下载项目\n\n```bash\n$ git clone https://github.com/assafelovic/gpt-researcher.git\n$ cd gpt-researcher\n```\n\n<br />\n\n> **步骤2** -安装依赖项\n```bash\n$ pip install -r requirements.txt\n```\n<br />\n\n> **第 3 步** - 使用 OpenAI 密钥和 Tavily API 密钥创建 .env 文件，或直接导出该文件\n\n```bash\n$ export OPENAI_API_KEY={Your OpenAI API Key here}\n```\n```bash\n$ export TAVILY_API_KEY={Your Tavily API Key here}\n```\n\n- **LLM，我们推荐使用 [OpenAI GPT](https://platform.openai.com/docs/guides/gpt)**，但您也可以使用 [Langchain Adapter](https://python.langchain.com/docs/guides/adapters/openai) 支持的任何其他 LLM 模型（包括开源），只需在 config/config.py 中更改 llm 模型和提供者即可。请按照 [这份指南](https://python.langchain.com/docs/integrations/llms/) 学习如何将 LLM 与 Langchain 集成。\n- **对于搜索引擎，我们推荐使用 [Tavily Search API](https://app.tavily.com)（已针对 LLM 进行优化）**，但您也可以选择其他搜索引擎，只需将 config/config.py 中的搜索提供程序更改为 \"duckduckgo\"、\"googleAPI\"、\"searchapi\"、\"googleSerp \"或 \"searx \"即可。然后在 config.py 文件中添加相应的 env API 密钥。\n- **我们强烈建议使用 [OpenAI GPT](https://platform.openai.com/docs/guides/gpt) 模型和 [Tavily Search API](https://app.tavily.com) 以获得最佳性能。**\n<br />\n\n> **第 4 步** - 使用 FastAPI 运行代理\n\n```bash\n$ uvicorn main:app --reload\n```\n<br />\n\n> **第 5 步** - 在任何浏览器上访问 http://localhost:8000，享受研究乐趣！\n\n要了解如何开始使用 Docker 或了解有关功能和服务的更多信息，请访问 [documentation](https://docs.gptr.dev) 页面。\n\n## 🚀 贡献\n我们非常欢迎您的贡献！如果您感兴趣，请查看 [contributing](CONTRIBUTING.md)。\n\n如果您有兴趣加入我们的任务，请查看我们的 [路线图](https://trello.com/b/3O7KBePw/gpt-researcher-roadmap) 页面，并通过我们的 [Discord 社区](https://discord.gg/QgZXvJAccX) 联系我们。\n\n## ✉️ 支持 / 联系我们\n- [社区讨论区](https://discord.gg/spBgZmm3Xe)\n- 我们的邮箱: support@tavily.com\n\n## 🛡 免责声明\n\n本项目 \"GPT Researcher \"是一个实验性应用程序，按 \"现状 \"提供，不做任何明示或暗示的保证。我们根据 MIT 许可分享用于学术目的的代码。本文不提供任何学术建议，也不建议在学术或研究论文中使用。\n\n我们对客观研究主张的看法：\n1.  我们抓取系统的全部目的是减少不正确的事实。如何解决？我们抓取的网站越多，错误数据的可能性就越小。我们每项研究都会收集20条信息，它们全部错误的可能性极低。\n2. 我们的目标不是消除偏见，而是尽可能减少偏见。**作为一个社区，我们在这里探索最有效的人机互动**。\n3. 在研究过程中，人们也容易产生偏见，因为大多数人对自己研究的课题都有自己的看法。这个工具可以搜罗到许多观点，并均匀地解释各种不同的观点，而有偏见的人是绝对读不到这些观点的。\n\n**请注意，使用 GPT-4 语言模型可能会因使用令牌而产生高昂费用**。使用本项目即表示您承认有责任监控和管理自己的令牌使用情况及相关费用。强烈建议您定期检查 OpenAI API 的使用情况，并设置任何必要的限制或警报，以防止发生意外费用。\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#assafelovic/gpt-researcher\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n  </picture>\n</a>\n</p>\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.4296875,
          "content": "<div align=\"center\" id=\"top\">\n\n<img src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/20af8286-b386-44a5-9a83-3be1365139c3\" alt=\"Logo\" width=\"80\">\n\n####\n\n[![Website](https://img.shields.io/badge/Official%20Website-gptr.dev-teal?style=for-the-badge&logo=world&logoColor=white&color=0891b2)](https://gptr.dev)\n[![Documentation](https://img.shields.io/badge/Documentation-DOCS-f472b6?logo=googledocs&logoColor=white&style=for-the-badge)](https://docs.gptr.dev)\n[![Discord Follow](https://dcbadge.vercel.app/api/server/QgZXvJAccX?style=for-the-badge&theme=clean-inverted&?compact=true)](https://discord.gg/QgZXvJAccX)\n\n[![PyPI version](https://img.shields.io/pypi/v/gpt-researcher?logo=pypi&logoColor=white&style=flat)](https://badge.fury.io/py/gpt-researcher)\n![GitHub Release](https://img.shields.io/github/v/release/assafelovic/gpt-researcher?style=flat&logo=github)\n[![Open In Colab](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=grey&color=yellow&label=%20&style=flat&logoSize=40)](https://colab.research.google.com/github/assafelovic/gpt-researcher/blob/master/docs/docs/examples/pip-run.ipynb)\n[![Docker Image Version](https://img.shields.io/docker/v/elestio/gpt-researcher/latest?arch=amd64&style=flat&logo=docker&logoColor=white&color=1D63ED)](https://hub.docker.com/r/gptresearcher/gpt-researcher)\n[![Twitter Follow](https://img.shields.io/twitter/follow/assaf_elovic?style=social)](https://twitter.com/assaf_elovic)\n\n[English](README.md) | [中文](README-zh_CN.md) | [日本語](README-ja_JP.md) | [한국어](README-ko_KR.md)\n\n</div>\n\n# 🔎 GPT Researcher\n\n**GPT Researcher is an autonomous agent designed for comprehensive web and local research on any given task.** \n\nThe agent produces detailed, factual, and unbiased research reports with citations. GPT Researcher provides a full suite of customization options to create tailor made and domain specific research agents. Inspired by the recent [Plan-and-Solve](https://arxiv.org/abs/2305.04091) and [RAG](https://arxiv.org/abs/2005.11401) papers, GPT Researcher addresses misinformation, speed, determinism, and reliability by offering stable performance and increased speed through parallelized agent work.\n\n**Our mission is to empower individuals and organizations with accurate, unbiased, and factual information through AI.**\n\n## Why GPT Researcher?\n\n- Objective conclusions for manual research can take weeks, requiring vast resources and time.\n- LLMs trained on outdated information can hallucinate, becoming irrelevant for current research tasks.\n- Current LLMs have token limitations, insufficient for generating long research reports.\n- Limited web sources in existing services lead to misinformation and shallow results.\n- Selective web sources can introduce bias into research tasks.\n\n## Demo\nhttps://github.com/user-attachments/assets/2cc38f6a-9f66-4644-9e69-a46c40e296d4\n\n## Architecture\n\nThe core idea is to utilize 'planner' and 'execution' agents. The planner generates research questions, while the execution agents gather relevant information. The publisher then aggregates all findings into a comprehensive report.\n\n<div align=\"center\">\n<img align=\"center\" height=\"600\" src=\"https://github.com/assafelovic/gpt-researcher/assets/13554167/4ac896fd-63ab-4b77-9688-ff62aafcc527\">\n</div>\n\nSteps:\n* Create a task-specific agent based on a research query.\n* Generate questions that collectively form an objective opinion on the task.\n* Use a crawler agent for gathering information for each question.\n* Summarize and source-track each resource.\n* Filter and aggregate summaries into a final research report.\n\n## Tutorials\n - [How it Works](https://docs.gptr.dev/blog/building-gpt-researcher)\n - [How to Install](https://www.loom.com/share/04ebffb6ed2a4520a27c3e3addcdde20?sid=da1848e8-b1f1-42d1-93c3-5b0b9c3b24ea)\n - [Live Demo](https://www.loom.com/share/6a3385db4e8747a1913dd85a7834846f?sid=a740fd5b-2aa3-457e-8fb7-86976f59f9b8)\n\n## Features\n\n- 📝 Generate detailed research reports using web and local documents.\n- 🖼️ Smart image scraping and filtering for reports.\n- 📜 Generate detailed reports exceeding 2,000 words.\n- 🌐 Aggregate over 20 sources for objective conclusions.\n- 🖥️ Frontend available in lightweight (HTML/CSS/JS) and production-ready (NextJS + Tailwind) versions.\n- 🔍 JavaScript-enabled web scraping.\n- 📂 Maintains memory and context throughout research.\n- 📄 Export reports to PDF, Word, and other formats.\n\n## 📖 Documentation\n\nSee the [Documentation](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started) for:\n- Installation and setup guides\n- Configuration and customization options\n- How-To examples\n- Full API references\n\n## ⚙️ Getting Started\n\n### Installation\n\n1. Install Python 3.11 or later. [Guide](https://www.tutorialsteacher.com/python/install-python).\n2. Clone the project and navigate to the directory:\n\n    ```bash\n    git clone https://github.com/assafelovic/gpt-researcher.git\n    cd gpt-researcher\n    ```\n\n3. Set up API keys by exporting them or storing them in a `.env` file.\n\n    ```bash\n    export OPENAI_API_KEY={Your OpenAI API Key here}\n    export TAVILY_API_KEY={Your Tavily API Key here}\n    ```\n\n4. Install dependencies and start the server:\n\n    ```bash\n    pip install -r requirements.txt\n    python -m uvicorn main:app --reload\n    ```\n\nVisit [http://localhost:8000](http://localhost:8000) to start.\n\nFor other setups (e.g., Poetry or virtual environments), check the [Getting Started page](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started).\n\n## Run as PIP package\n```bash\npip install gpt-researcher\n\n```\n### Example Usage:\n```python\n...\nfrom gpt_researcher import GPTResearcher\n\nquery = \"why is Nvidia stock going up?\"\nresearcher = GPTResearcher(query=query, report_type=\"research_report\")\n# Conduct research on the given query\nresearch_result = await researcher.conduct_research()\n# Write the report\nreport = await researcher.write_report()\n...\n```\n\n**For more examples and configurations, please refer to the [PIP documentation](https://docs.gptr.dev/docs/gpt-researcher/gptr/pip-package) page.**\n\n\n## Run with Docker\n\n> **Step 1** - [Install Docker](https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started-with-docker)\n\n> **Step 2** - Clone the '.env.example' file, add your API Keys to the cloned file and save the file as '.env'\n\n> **Step 3** - Within the docker-compose file comment out services that you don't want to run with Docker.\n\n```bash\ndocker-compose up --build\n```\n\nIf that doesn't work, try running it without the dash:\n```bash\ndocker compose up --build\n```\n\n\n> **Step 4** - By default, if you haven't uncommented anything in your docker-compose file, this flow will start 2 processes:\n - the Python server running on localhost:8000<br>\n - the React app running on localhost:3000<br>\n\nVisit localhost:3000 on any browser and enjoy researching!\n\n\n\n## 📄 Research on Local Documents\n\nYou can instruct the GPT Researcher to run research tasks based on your local documents. Currently supported file formats are: PDF, plain text, CSV, Excel, Markdown, PowerPoint, and Word documents.\n\nStep 1: Add the env variable `DOC_PATH` pointing to the folder where your documents are located.\n\n```bash\nexport DOC_PATH=\"./my-docs\"\n```\n\nStep 2: \n - If you're running the frontend app on localhost:8000, simply select \"My Documents\" from the \"Report Source\" Dropdown Options.\n - If you're running GPT Researcher with the [PIP package](https://docs.tavily.com/docs/gpt-researcher/pip-package), pass the `report_source` argument as \"local\" when you instantiate the `GPTResearcher` class [code sample here](https://docs.gptr.dev/docs/gpt-researcher/context/tailored-research).\n\n\n## 👪 Multi-Agent Assistant\nAs AI evolves from prompt engineering and RAG to multi-agent systems, we're excited to introduce our new multi-agent assistant built with [LangGraph](https://python.langchain.com/v0.1/docs/langgraph/).\n\nBy using LangGraph, the research process can be significantly improved in depth and quality by leveraging multiple agents with specialized skills. Inspired by the recent [STORM](https://arxiv.org/abs/2402.14207) paper, this project showcases how a team of AI agents can work together to conduct research on a given topic, from planning to publication.\n\nAn average run generates a 5-6 page research report in multiple formats such as PDF, Docx and Markdown.\n\nCheck it out [here](https://github.com/assafelovic/gpt-researcher/tree/master/multi_agents) or head over to our [documentation](https://docs.gptr.dev/docs/gpt-researcher/multi_agents/langgraph) for more information.\n\n## 🖥️ Frontend Applications\n\nGPT-Researcher now features an enhanced frontend to improve the user experience and streamline the research process. The frontend offers:\n\n- An intuitive interface for inputting research queries\n- Real-time progress tracking of research tasks\n- Interactive display of research findings\n- Customizable settings for tailored research experiences\n\nTwo deployment options are available:\n1. A lightweight static frontend served by FastAPI\n2. A feature-rich NextJS application for advanced functionality\n\nFor detailed setup instructions and more information about the frontend features, please visit our [documentation page](https://docs.gptr.dev/docs/gpt-researcher/frontend/frontend).\n\n## 🚀 Contributing\nWe highly welcome contributions! Please check out [contributing](https://github.com/assafelovic/gpt-researcher/blob/master/CONTRIBUTING.md) if you're interested.\n\nPlease check out our [roadmap](https://trello.com/b/3O7KBePw/gpt-researcher-roadmap) page and reach out to us via our [Discord community](https://discord.gg/QgZXvJAccX) if you're interested in joining our mission.\n<a href=\"https://github.com/assafelovic/gpt-researcher/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=assafelovic/gpt-researcher\" />\n</a>\n## ✉️ Support / Contact us\n- [Community Discord](https://discord.gg/spBgZmm3Xe)\n- Author Email: assaf.elovic@gmail.com\n\n## 🛡 Disclaimer\n\nThis project, GPT Researcher, is an experimental application and is provided \"as-is\" without any warranty, express or implied. We are sharing codes for academic purposes under the Apache 2 license. Nothing herein is academic advice, and NOT a recommendation to use in academic or research papers.\n\nOur view on unbiased research claims:\n1. The main goal of GPT Researcher is to reduce incorrect and biased facts. How? We assume that the more sites we scrape the less chances of incorrect data. By scraping multiple sites per research, and choosing the most frequent information, the chances that they are all wrong is extremely low.\n2. We do not aim to eliminate biases; we aim to reduce it as much as possible. **We are here as a community to figure out the most effective human/llm interactions.**\n3. In research, people also tend towards biases as most have already opinions on the topics they research about. This tool scrapes many opinions and will evenly explain diverse views that a biased person would never have read.\n\n---\n\n<p align=\"center\">\n<a href=\"https://star-history.com/#assafelovic/gpt-researcher\">\n  <picture>\n    <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date&theme=dark\" />\n    <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n    <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=assafelovic/gpt-researcher&type=Date\" />\n  </picture>\n</a>\n</p>\n\n\n<p align=\"right\">\n  <a href=\"#top\">⬆️ Back to Top</a>\n</p>\n"
        },
        {
          "name": "backend",
          "type": "tree",
          "content": null
        },
        {
          "name": "citation.cff",
          "type": "blob",
          "size": 0.2783203125,
          "content": "cff-version: 1.0.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n  - family-names: Elovic\n    given-names: Assaf\ntitle: gpt-researcher\nversion: 0.5.4\ndate-released: 2023-07-23\nrepository-code: https://github.com/assafelovic/gpt-researcher\nurl: https://gptr.dev"
        },
        {
          "name": "cli.py",
          "type": "blob",
          "size": 2.8642578125,
          "content": "\"\"\"\nProvides a command line interface for the GPTResearcher class.\n\nUsage:\n\n```shell\npython cli.py \"<query>\" --report_type <report_type>\n```\n\n\"\"\"\nimport asyncio\nimport argparse\nfrom argparse import RawTextHelpFormatter\nfrom uuid import uuid4\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom gpt_researcher import GPTResearcher\nfrom gpt_researcher.utils.enum import ReportType\nfrom backend.report_type import DetailedReport\n\n# =============================================================================\n# CLI\n# =============================================================================\n\ncli = argparse.ArgumentParser(\n    description=\"Generate a research report.\",\n    # Enables the use of newlines in the help message\n    formatter_class=RawTextHelpFormatter)\n\n# =====================================\n# Arg: Query\n# =====================================\n\ncli.add_argument(\n    # Position 0 argument\n    \"query\",\n    type=str,\n    help=\"The query to conduct research on.\")\n\n# =====================================\n# Arg: Report Type\n# =====================================\n\nchoices = [report_type.value for report_type in ReportType]\n\nreport_type_descriptions = {\n    ReportType.ResearchReport.value: \"Summary - Short and fast (~2 min)\",\n    ReportType.DetailedReport.value: \"Detailed - In depth and longer (~5 min)\",\n    ReportType.ResourceReport.value: \"\",\n    ReportType.OutlineReport.value: \"\",\n    ReportType.CustomReport.value: \"\",\n    ReportType.SubtopicReport.value: \"\"\n}\n\ncli.add_argument(\n    \"--report_type\",\n    type=str,\n    help=\"The type of report to generate. Options:\\n\" + \"\\n\".join(\n        f\"  {choice}: {report_type_descriptions[choice]}\" for choice in choices\n    ),\n    # Deserialize ReportType as a List of strings:\n    choices=choices,\n    required=True)\n\n# =============================================================================\n# Main\n# =============================================================================\n\n\nasync def main(args):\n    \"\"\" \n    Conduct research on the given query, generate the report, and write\n    it as a markdown file to the output directory.\n    \"\"\"\n    if args.report_type == 'detailed_report':\n        detailed_report = DetailedReport(\n            query=args.query,\n            report_type=\"research_report\",\n            report_source=\"web_search\",\n        )\n\n        report = await detailed_report.run()\n    else:\n        researcher = GPTResearcher(\n            query=args.query,\n            report_type=args.report_type)\n\n        await researcher.conduct_research()\n\n        report = await researcher.write_report()\n\n    # Write the report to a file\n    artifact_filepath = f\"outputs/{uuid4()}.md\"\n    os.makedirs(\"outputs\", exist_ok=True)\n    with open(artifact_filepath, \"w\") as f:\n        f.write(report)\n\n    print(f\"Report written to '{artifact_filepath}'\")\n\nif __name__ == \"__main__\":\n    load_dotenv()\n    args = cli.parse_args()\n    asyncio.run(main(args))\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 1.208984375,
          "content": "services:\n  gpt-researcher:\n    pull_policy: build\n    image: gptresearcher/gpt-researcher\n    build: ./\n    environment: \n      OPENAI_API_KEY: ${OPENAI_API_KEY}\n      TAVILY_API_KEY: ${TAVILY_API_KEY}\n      LANGCHAIN_API_KEY: ${LANGCHAIN_API_KEY}\n      LOGGING_LEVEL: INFO\n    volumes:\n      - ./outputs:/usr/src/app/outputs\n    restart: always\n    ports:\n      - 8000:8000\n  gptr-nextjs:\n    pull_policy: build\n    image: gptresearcher/gptr-nextjs\n    stdin_open: true\n    environment:\n      CHOKIDAR_USEPOLLING: true\n      LOGGING_LEVEL: INFO\n    build:\n      dockerfile: Dockerfile.dev\n      context: frontend/nextjs\n    volumes:\n      - /app/node_modules\n      - ./frontend/nextjs:/app\n      - ./outputs:/app/outputs\n    restart: always\n    ports:\n      - 3000:3000\n\n  gpt-researcher-tests:\n    image: gptresearcher/gpt-researcher-tests\n    build: ./\n    environment: \n      OPENAI_API_KEY: ${OPENAI_API_KEY}\n      TAVILY_API_KEY: ${TAVILY_API_KEY}\n      LANGCHAIN_API_KEY: ${LANGCHAIN_API_KEY}\n      LOGGING_LEVEL: INFO\n    profiles: [\"test\"]\n    command: >\n      /bin/sh -c \"\n      pip install pytest pytest-asyncio faiss-cpu &&\n      python -m pytest tests/report-types.py &&\n      python -m pytest tests/vector-store.py\n      \"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "frontend",
          "type": "tree",
          "content": null
        },
        {
          "name": "gpt_researcher",
          "type": "tree",
          "content": null
        },
        {
          "name": "langgraph.json",
          "type": "blob",
          "size": 0.1533203125,
          "content": "{\n  \"python_version\": \"3.11\",\n  \"dependencies\": [\n    \"./multi_agents\"\n  ],\n  \"graphs\": {\n    \"agent\": \"./multi_agents/agent.py:graph\"\n  },\n  \"env\": \".env\"\n}"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 0.9521484375,
          "content": "from dotenv import load_dotenv\nimport logging\nfrom pathlib import Path\n\n# Create logs directory if it doesn't exist\nlogs_dir = Path(\"logs\")\nlogs_dir.mkdir(exist_ok=True)\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        # File handler for general application logs\n        logging.FileHandler('logs/app.log'),\n        # Stream handler for console output\n        logging.StreamHandler()\n    ]\n)\n\n# Suppress verbose fontTools logging\nlogging.getLogger('fontTools').setLevel(logging.WARNING)\nlogging.getLogger('fontTools.subset').setLevel(logging.WARNING)\nlogging.getLogger('fontTools.ttLib').setLevel(logging.WARNING)\n\n# Create logger instance\nlogger = logging.getLogger(__name__)\n\nload_dotenv()\n\nfrom backend.server.server import app\n\nif __name__ == \"__main__\":\n    import uvicorn\n    \n    logger.info(\"Starting server...\")\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
        },
        {
          "name": "multi_agents",
          "type": "tree",
          "content": null
        },
        {
          "name": "poetry.toml",
          "type": "blob",
          "size": 0.0302734375,
          "content": "[virtualenvs]\nin-project = true"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.33203125,
          "content": "[tool.poetry]\nname = \"gpt-researcher\"\nversion = \"0.8.5\"\ndescription = \"GPT Researcher is an autonomous agent designed for comprehensive online research on a variety of tasks.\"\nauthors = [\"Assaf Elovic <assaf.elovic@gmail.com>\"]\nlicense = \"MIT\"\nreadme = \"README.md\"\n\n[tool.poetry.dependencies]\npython = \">=3.10,<3.12\"\nbeautifulsoup4 = \">=4.12.2\"\ncolorama = \">=0.4.6\"\nduckduckgo_search = \">=4.1.1\"\nmd2pdf = \">=1.0.1\"\nopenai = \">=1.3.3\"\npython-dotenv = \">=1.0.0\"\npyyaml = \">=6.0.1\"\nuvicorn = \">=0.24.0.post1\"\npydantic = \">=2.5.1\"\nfastapi = \">=0.104.1\"\npython-multipart = \">=0.0.6\"\nmarkdown = \">=3.5.1\"\nlangchain = \"^0.2\"\nlanggraph = \">=0.0.29,<0.3\"\nlangchain_community = \"^0.2\"\nlangchain-openai = \"^0.1\"\ntavily-python = \">=0.2.8\"\npermchain = \">=0.0.6\"\narxiv = \">=2.0.0\"\nPyMuPDF = \">=1.23.6\"\nrequests = \">=2.31.0\"\njinja2 = \">=3.1.2\"\naiofiles = \">=23.2.1\"\nSQLAlchemy = \">=2.0.28\"\nmistune = \"^3.0.2\"\nhtmldocx = \"^0.0.6\"\npython-docx = \"^1.1.0\"\nlxml = { version = \">=4.9.2\", extras = [\"html_clean\"] }\nunstructured = \">=0.13,<0.16\"\ntiktoken = \">=0.7.0\"\njson-repair = \"^0.29.8\"\njson5 = \"^0.9.25\"\nloguru = \"^0.7.2\"\nwebsockets = \"^13.1\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n[tool.pytest.ini_options]\nasyncio_mode = \"strict\"\naddopts = \"-v\"\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\nasyncio_fixture_loop_scope = \"function\""
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.390625,
          "content": "# dependencies\nbeautifulsoup4\ncolorama\nmd2pdf\npython-dotenv\npyyaml\nuvicorn\npydantic\nfastapi\npython-multipart\nmarkdown\nlangchain\nlangchain_community\nlangchain-openai\nlangchain-ollama\nlanggraph\ntiktoken\ngpt-researcher\narxiv\nPyMuPDF\nrequests\njinja2\naiofiles\nmistune\npython-docx\nhtmldocx\nlxml_html_clean\nwebsockets\nunstructured\njson_repair\njson5\nloguru\n\n# uncomment for testing\n# pytest\n# pytest-asyncio\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.3408203125,
          "content": "from setuptools import find_packages, setup\n\nLATEST_VERSION = \"0.10.10\"\n\nexclude_packages = [\n    \"selenium\",\n    \"webdriver\",\n    \"fastapi\",\n    \"fastapi.*\",\n    \"uvicorn\",\n    \"jinja2\",\n    \"gpt-researcher\",\n    \"langgraph\"\n]\n\nwith open(r\"README.md\", \"r\", encoding=\"utf-8\") as f:\n    long_description = f.read()\n\nwith open(\"requirements.txt\", \"r\") as f:\n    reqs = [line.strip() for line in f if not any(pkg in line for pkg in exclude_packages)]\n\nsetup(\n    name=\"gpt-researcher\",\n    version=LATEST_VERSION,\n    description=\"GPT Researcher is an autonomous agent designed for comprehensive web research on any task\",\n    package_dir={'gpt_researcher': 'gpt_researcher'},\n    packages=find_packages(exclude=exclude_packages),\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/assafelovic/gpt-researcher\",\n    author=\"Assaf Elovic\",\n    author_email=\"assaf.elovic@gmail.com\",\n    license=\"MIT\",\n    classifiers=[\n        \"License :: OSI Approved :: MIT License\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Education\",\n        \"Intended Audience :: Science/Research\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    ],\n    install_requires=reqs,\n\n\n)"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}