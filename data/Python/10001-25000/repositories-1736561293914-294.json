{
  "metadata": {
    "timestamp": 1736561293914,
    "page": 294,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PaddlePaddle/PaddleNLP",
      "stars": 12283,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.8388671875,
          "content": "# This file is used by clang-format to autoformat paddle source code\n#\n# The clang-format is part of llvm toolchain.\n# It need to install llvm and clang to format source code style.\n#\n# The basic usage is,\n#   clang-format -i -style=file PATH/TO/SOURCE/CODE\n#\n# The -style=file implicit use \".clang-format\" file located in one of\n# parent directory.\n# The -i means inplace change.\n#\n# The document of clang-format is\n#   http://clang.llvm.org/docs/ClangFormat.html\n#   http://clang.llvm.org/docs/ClangFormatStyleOptions.html\n---\nLanguage:        Cpp\nBasedOnStyle:  Google\nIndentWidth:     2\nTabWidth:        2\nContinuationIndentWidth: 4\nMaxEmptyLinesToKeep: 2\nAccessModifierOffset: -2  # The private/protected/public has no indent in class\nStandard:  Cpp11\nAllowAllParametersOfDeclarationOnNextLine: true\nBinPackParameters: false\nBinPackArguments: false\n...\n\n"
        },
        {
          "name": ".clang_format.hook",
          "type": "blob",
          "size": 0.3525390625,
          "content": "#!/usr/bin/env bash\nset -e\n\nreadonly VERSION=\"3.8\"\n\nversion=$(clang-format -version)\n\nif ! [[ $version == *\"$VERSION\"* ]]; then\n    echo \"clang-format version check failed.\"\n    echo \"a version contains '$VERSION' is needed, but get '$version'\"\n    echo \"you can install the right version, and make an soft-link to '\\$PATH' env\"\n    exit -1\nfi\n\nclang-format $@\n"
        },
        {
          "name": ".copyright.hook",
          "type": "blob",
          "size": 4.1806640625,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport io\nimport re\nimport sys\nimport os\nimport datetime\n\nCOPYRIGHT = '''Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.'''\n\ndef _generate_copyright(comment_mark):\n    copyright=COPYRIGHT.split(os.linesep)\n    header = copyright[0].rstrip()\n\n    p = re.search('(\\d{4})', header).group(0)\n    now = datetime.datetime.now()\n\n    header = header.replace(p,str(now.year))\n\n    ans=[comment_mark + \" \" + header + os.linesep]\n    for idx, line in enumerate(copyright[1:]):\n        ans.append(comment_mark + \" \" + line.rstrip() + os.linesep)\n\n    return ans\n\ndef _get_comment_mark(path):\n    lang_type=re.compile(r\"\\.(py|sh)$\")\n    if lang_type.search(path) is not None:\n        return \"#\"\n\n    lang_type=re.compile(r\"\\.(h|c|hpp|cc|cpp|cu|go|cuh|proto)$\")\n    if lang_type.search(path) is not None:\n        return \"//\"\n\n    return None\n\n\nRE_ENCODE = re.compile(r\"^[ \\t\\v]*#.*?coding[:=]\", re.IGNORECASE)\nRE_COPYRIGHT = re.compile(r\".*Copyright( \\(c\\))* \\d{4}\", re.IGNORECASE)\nRE_SHEBANG = re.compile(r\"^[ \\t\\v]*#[ \\t]?\\!\")\n\ndef _check_copyright(path):\n    head=[]\n    try:\n        with open(path, encoding=\"utf-8\") as f:\n            head = [next(f) for x in range(4)]\n    except StopIteration:\n        pass\n\n    for idx, line in enumerate(head):\n        if RE_COPYRIGHT.search(line) is not None:\n            return True\n\n    return False\n\ndef generate_copyright(path, comment_mark):\n    original_contents = io.open(path, encoding=\"utf-8\").readlines()\n    head = original_contents[0:4]\n\n    insert_line_no=0\n    for i, line in enumerate(head):\n        if RE_ENCODE.search(line) or RE_SHEBANG.search(line):\n            insert_line_no=i+1\n\n    copyright = _generate_copyright(comment_mark)\n    if insert_line_no == 0:\n        new_contents = copyright\n        if len(original_contents) > 0 and len(original_contents[0].strip()) != 0:\n            new_contents.append(os.linesep)\n        new_contents.extend(original_contents)\n    else:\n        new_contents=original_contents[0:insert_line_no]\n        new_contents.append(os.linesep)\n        new_contents.extend(copyright)\n        if len(original_contents) > insert_line_no and len(original_contents[insert_line_no].strip()) != 0:\n            new_contents.append(os.linesep)\n        new_contents.extend(original_contents[insert_line_no:])\n    new_contents=\"\".join(new_contents)\n\n    with io.open(path, 'w') as output_file:\n        output_file.write(new_contents)\n\n\n\ndef main(argv=None):\n    parser = argparse.ArgumentParser(\n        description='Checker for copyright declaration.')\n    parser.add_argument('filenames', nargs='*', help='Filenames to check')\n    args = parser.parse_args(argv)\n\n    retv = 0\n    for path in args.filenames:\n        comment_mark = _get_comment_mark(path)\n        if comment_mark is None:\n            print(\"warning:Unsupported file\", path, file=sys.stderr)\n            continue\n\n        if _check_copyright(path):\n            continue\n\n        generate_copyright(path, comment_mark)\n\n\nif __name__ == '__main__':\n    exit(main())\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.1796875,
          "content": "[flake8]\nignore = E203, E402, E501, E731, E741, W503, W605, E722\nmax-line-length = 119\n\n# E402: module level import not at top of file\nper-file-ignores =\n    __init__.py:F401,F403,E402"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.541015625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\nbuild*\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n*.doctree\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pycharm\n.DS_Store\n.idea/\nFETCH_HEAD\n\n# vscode\n.vscode\n./ppdiffusers/ppdiffusers/version.py\n\n# third party\ncsrc/third_party/\ndataset/\noutput/\n\n# gen codes\nautogen/\n\n# cutlass kernel\n!csrc/gpu/cutlass_kernels/gemm/collective/builders"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.2392578125,
          "content": "[submodule \"csrc/third_party/cutlass\"]\n\tpath = csrc/third_party/cutlass\n\turl = https://github.com/NVIDIA/cutlass.git\n[submodule \"csrc/third_party/nlohmann_json\"]\n\tpath = csrc/third_party/nlohmann_json\n\turl = https://github.com/nlohmann/json.git\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.7109375,
          "content": "exclude: 'slm/model_zoo/gpt-3;csrc/third_party'\nrepos:\n# For Python files\n-   repo: https://github.com/psf/black.git\n    rev: 22.8.0\n    hooks:\n    -   id: black\n        files: \\.(py|pyi)$\n        additional_dependencies: [toml]\n-   repo: https://github.com/PyCQA/isort\n    rev: 5.11.5\n    hooks:\n    -   id: isort\n-   repo: https://github.com/PyCQA/flake8\n    rev: 4.0.1\n    hooks:\n    -   id: flake8\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.1.0\n    hooks:\n    -   id: check-merge-conflict\n    -   id: check-symlinks\n    -   id: detect-private-key\n        files: (?!.*paddle)^.*$\n    -   id: end-of-file-fixer\n        files: \\.md$\n    -   id: trailing-whitespace\n        files: \\.md$\n-   repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.1.14\n    hooks:\n    -   id: forbid-crlf\n        files: \\.md$\n    -   id: remove-crlf\n        files: \\.md$\n    -   id: forbid-tabs\n        files: \\.md$\n    -   id: remove-tabs\n        files: \\.md$\n-   repo: local\n    hooks:\n    -   id: copyright_checker\n        name: copyright_checker\n        entry: python .copyright.hook\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto|xpu|kps|py|sh)$\n# For Markdown files\n-   repo: local\n    hooks:\n    -   id: add-spaces-between-chinese-and-english\n        name: Add spaces between Chinese and English characters\n        entry: python scripts/codestyle/check_spaces.py\n        language: python\n        files: \\.(md|markdown)$\n        pass_filenames: true\n# For dead links\n-   repo: local\n    hooks:\n    -   id: check-dead-links\n        name: Check dead links\n        entry: python scripts/codestyle/check_dead_links.py\n        language: python\n        files: \\.(md|markdown|rst)$\n        pass_filenames: true\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.5693359375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\nbuild:\n  os: \"ubuntu-20.04\"\n  tools:\n    python: \"3.10\"\n\nsubmodules:\n  include: all\n  recursive: true\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n   configuration: docs/conf.py\n\n# Optionally build your docs in additional formats such as PDF\n#formats:\n#   - pdf\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.9853515625,
          "content": "**ç®€ä½“ä¸­æ–‡**ğŸ€„ | [EnglishğŸŒ](.github/CONTRIBUTING_en.md)\n\n# Contributing to PaddleNLP\n\næˆ‘ä»¬éå¸¸æ¬¢è¿å¹¶å¸Œæœ›æ‚¨å¯¹`PaddleNLP`åšå‡ºå¼€æºè´¡çŒ®ã€‚åœ¨æ‚¨å¼€å§‹æäº¤æ‚¨çš„è´¡çŒ®ä¹‹å‰ï¼Œè¯·å…ˆè¡Œç­¾ç½²[PaddlePaddle è´¡çŒ®è€…è®¸å¯åè®®](https://cla-assistant.io/PaddlePaddle/PaddleNLP)ã€‚\næœ¬æ–‡æ¥ä¸‹æ¥å°†ä»‹ç»æˆ‘ä»¬çš„å¼€å‘ä¸è´¡çŒ®æµç¨‹ï¼š\n\n## è´¡çŒ®æ–¹å¼\n\næˆ‘ä»¬æ¬¢è¿ä¸åŒçš„å‘`PaddleNLP`åšå‡ºè´¡çŒ®çš„æ–¹å¼ï¼Œä¾‹å¦‚ï¼š\n\n- ä¿®å¤å·²çŸ¥çš„ Issue\n- æäº¤æ–°çš„ Issueï¼Œä¾‹å¦‚æå‡ºåŠŸèƒ½éœ€æ±‚æˆ–è€… bug æŠ¥å‘Š\n- å®ç°æ–°çš„æ¨¡å‹ç»“æ„\n\nå¦‚æœæ‚¨ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹ï¼Œè¯·æŸ¥çœ‹ Issues æ¿å—ä¸­çš„`Good First Issue`æ ‡ç­¾ã€‚å®ƒä¸ºæ‚¨æä¾›ä¸€ä¸ªå¯¹åˆå­¦è€…å‹å¥½çš„å·²çŸ¥ Issue åˆ—è¡¨ï¼Œå¯ä»¥é™ä½è´¡çŒ®çš„é—¨æ§›ï¼Œå¸®åŠ©æ‚¨å¼€å§‹ä¸ºå¼€æºåšå‡ºè´¡çŒ®ã€‚æ‚¨åªéœ€åœ¨æ‚¨æƒ³å¤„ç†çš„ Issue ä¸­å‘ŠçŸ¥æˆ‘ä»¬æ‚¨æƒ³è´Ÿè´£æ­¤ Issue å³å¯ã€‚\n\n## å¼€å‘æµç¨‹\n\nPaddleNLP ä½¿ç”¨ [Git åˆ†æ”¯æ¨¡å‹](http://nvie.com/posts/a-successful-git-branching-model/)ã€‚å¯¹äºå¸¸è§çš„å¼€æºè´¡çŒ®ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹çš„è´¡çŒ®æµç¨‹ï¼š\n\n### 1. Fork\n\n   å› ä¸º PaddleNLP çš„å¼€å‘ç¤¾åŒºä¸€ç›´åœ¨å‘å±•ï¼Œå¦‚æœæ¯ä½è´¡çŒ®è€…éƒ½ç›´æ¥å‘å®˜æ–¹ Repo æäº¤ commit å°†ä¼šéš¾ä»¥ç®¡ç†ã€‚å› æ­¤ï¼Œè¯·ä»æ‚¨çš„åˆ†æ”¯ä¸­æäº¤ Pull Requestsã€‚å»ºè®®æ‚¨é€šè¿‡ GitHub çš„[â€œForkâ€æŒ‰é’®](https://help.github.com/articles/fork-a-repo/)æ¥åˆ›å»ºæ‚¨çš„ Fork åˆ†æ”¯ã€‚\n\n### 2. Clone\n\n   è¯·è¿è¡Œä¸€ä¸‹å‘½ä»¤å°†æ‚¨çš„åˆ†æ”¯ clone åˆ°æœ¬åœ°\n\n   ```bash\n   git clone https://github.com/<your-github-account>/PaddleNLP\n   cd PaddleNLP\n   ```\n\n### 3. åˆ›å»ºæœ¬åœ°å¼€å‘åˆ†æ”¯\n\n   å¯¹äºæ·»åŠ æ–°åŠŸèƒ½æˆ–ä¿®å¤é”™è¯¯ç­‰æ—¥å¸¸å·¥ä½œï¼Œè¯·åœ¨å¼€å‘å‰åˆ›å»ºæ‚¨çš„æœ¬åœ°å¼€å‘åˆ†æ”¯ï¼š\n\n   ```bash\n   git checkout -b my-cool-feature\n   ```\n\n### 4. é…ç½®å¼€å‘ç¯å¢ƒ\n\n   åœ¨å¼€å§‹ç¼–ç ä¹‹å‰ï¼Œæ‚¨éœ€è¦è®¾ç½®å¼€å‘ç¯å¢ƒã€‚æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿›è¡Œæ‰€æœ‰å¼€å‘ï¼Œä¾‹å¦‚[venv](https://docs.python.org/3/library/venv.html)æˆ–[conda](https://docs.conda.io/en/latest/)ã€‚\n   è¯·æ‚¨è®¾ç½®å¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n\n   ```bash\n   make install\n   ```\n\n   è¿™å°†è®¾ç½® `PaddleNLP` çš„æ‰€æœ‰ä¾èµ–ä»¥åŠ [`pre-commit`](http://pre-commit.com/) å·¥å…·ã€‚\n\n   å¦‚æœæ‚¨éœ€è¦å¼€å‘ `examples` æˆ– `applications` æ¨¡å—å¹¶åŠ è½½ `PaddleNLP`ï¼Œè¯·ç¡®ä¿ä»¥å¯ç¼–è¾‘æ¨¡å¼ï¼ˆ`-e`ï¼‰å®‰è£… `PaddleNLP`ã€‚\n   å¦‚æœåœ¨è™šæ‹Ÿç¯å¢ƒä¸­å·²ç»å®‰è£… `PaddleNLP` ï¼Œè¯·ä½¿ç”¨ `pip uninstall paddlenlp` å°†å…¶åˆ é™¤ï¼Œç„¶åä»¥å¯ç¼–è¾‘æ¨¡å¼é‡æ–°å®‰è£…å®ƒ\n   `pip install -e .`\n\n### 5. å¼€å‘\n\n   å½“æ‚¨å¼€å‘æ—¶ï¼Œè¯·ç¡®ä¿æ‚¨æ–°å¢çš„ä»£ç ä¼šè¢«å•å…ƒæµ‹è¯•æ‰€è¦†ç›–ã€‚æˆ‘ä»¬æ‰€æœ‰çš„å•å…ƒæµ‹è¯•éƒ½å¯ä»¥åœ¨ `tests` ç›®å½•ä¸‹æ‰¾åˆ°ã€‚\n   æ‚¨å¯ä»¥ä¿®æ”¹ç°æœ‰å•å…ƒæµ‹è¯•ä»¥è¦†ç›–æ–°åŠŸèƒ½ï¼Œä¹Ÿå¯ä»¥ä»å¤´å¼€å§‹åˆ›å»ºæ–°æµ‹è¯•ã€‚\n   å½“æ‚¨å®Œæˆä»£ç æ—¶ï¼Œæ‚¨åº”è¯¥ç¡®ä¿ç›¸å…³çš„å•å…ƒæµ‹è¯•å¯ä»¥é€šè¿‡ã€‚æ‚¨å¯ä»¥åƒè¿™æ ·è¿è¡Œå—æ›´æ”¹å½±å“çš„æµ‹è¯•ï¼š\n\n   ```bash\n   pytest tests/<test_to_run>.py\n   ```\n\n### 6. Commit\n\n   æˆ‘ä»¬ä½¿ç”¨ [`pre-commit`](http://pre-commit.com/)å·¥å…·ï¼ˆåŒ…æ‹¬[black](https://black.readthedocs.io/en/stable/)ã€[isort](https:/ /pycqa.github.io/isort/) å’Œ\n   [flake8](https://flake8.pycqa.org/en/latest/)ï¼‰æ¥æ£€æŸ¥æ¯æ¬¡æäº¤ä¸­çš„ä»£ç å’Œæ–‡æ¡£çš„é£æ ¼ã€‚å½“ä½ è¿è¡Œ `git commit` æ—¶ï¼Œä½ ä¼šçœ‹åˆ°\n   ç±»ä¼¼äºä»¥ä¸‹å†…å®¹ï¼š\n\n   ```text\n    âœ  (my-virtual-env) git commit -m \"commiting my cool feature\"\n    black....................................................................Passed\n    isort....................................................................Passed\n    flake8...................................................................Passed\n    check for merge conflicts................................................Passed\n    check for broken symlinks............................(no files to check)Skipped\n    detect private key.......................................................Passed\n    fix end of files.....................................(no files to check)Skipped\n    trim trailing whitespace.............................(no files to check)Skipped\n    CRLF end-lines checker...............................(no files to check)Skipped\n    CRLF end-lines remover...............................(no files to check)Skipped\n    No-tabs checker......................................(no files to check)Skipped\n    Tabs remover.........................................(no files to check)Skipped\n    copyright_checker........................................................Passed\n   ```\n\n   ä½†å¤§å¤šæ•°æ—¶å€™äº‹æƒ…å¹¶æ²¡æœ‰é‚£ä¹ˆé¡ºåˆ©ã€‚å½“æ‚¨çš„ä»£ç æˆ–æ–‡æ¡£ä¸ç¬¦åˆæ ‡å‡†æ—¶ï¼Œ`pre-commit` æ£€æŸ¥å°†å¤±è´¥ã€‚\n\n   ```text\n    âœ  (my-virtual-env) git commit -m \"commiting my cool feature\"\n    black....................................................................Passed\n    isort....................................................................Failed\n    - hook id: isort\n    - files were modified by this hook\n\n    Fixing examples/information_extraction/waybill_ie/run_ernie_crf.py\n\n    flake8...................................................................Passed\n    check for merge conflicts................................................Passed\n    check for broken symlinks............................(no files to check)Skipped\n    detect private key.......................................................Passed\n    fix end of files.....................................(no files to check)Skipped\n    trim trailing whitespace.............................(no files to check)Skipped\n    CRLF end-lines checker...............................(no files to check)Skipped\n    CRLF end-lines remover...............................(no files to check)Skipped\n    No-tabs checker......................................(no files to check)Skipped\n    Tabs remover.........................................(no files to check)Skipped\n    copyright_checker........................................................Passed\n   ```\n\n   æˆ‘ä»¬çš„å·¥å…·å°†è‡ªåŠ¨ä¿®å¤å¤§éƒ¨åˆ†æ ·å¼é”™è¯¯ï¼Œä½†æ˜¯æœ‰äº›é”™è¯¯éœ€è¦æ‰‹åŠ¨è§£å†³ã€‚å¹¸è¿çš„æ˜¯ï¼Œé”™è¯¯ä¿¡æ¯ä¸€èˆ¬é€šä¿—æ˜“æ‡‚ï¼Œå¾ˆå®¹æ˜“ä¿®å¤ã€‚\n   è§£å†³é”™è¯¯åï¼Œæ‚¨å¯ä»¥å†æ¬¡è¿è¡Œ `git add <files>` å’Œ `git commit`ï¼Œè¿™å°†å†æ¬¡è§¦å‘ pre-commit ã€‚\n   ä¸€æ—¦ pre-commit æ£€æŸ¥é€šè¿‡ï¼Œæ‚¨å°±å¯ä»¥æ¨é€ä»£ç äº†ã€‚\n\n   [Google](https://google.com/) æˆ– [StackOverflow](https://stackoverflow.com/) æ˜¯å¸®åŠ©æ‚¨äº†è§£ä»£ç é£æ ¼é”™è¯¯çš„å¥½å·¥å…·ã€‚\n   å¦‚æœæ‚¨ä»ç„¶æ— æ³•å¼„æ¸…æ¥šï¼Œè¯·ä¸è¦æ‹…å¿ƒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ `git commit -m \"style error\" --no-verify` æäº¤ï¼Œæˆ‘ä»¬å¾ˆä¹æ„åœ¨æ‚¨åˆ›å»º Pull Request åå¸®åŠ©æ‚¨ã€‚\n\n### 7. git pull ä¸ä»£ç å†²çª\n\n   æœ‰ç»éªŒçš„ Git ç”¨æˆ·ç»å¸¸ä»å®˜æ–¹ Repo ä¸­ git pullã€‚å› ä¸ºè¿™æ ·å­ä»–ä»¬ä¼šåŠæ—©æ³¨æ„åˆ°ä¸å…¶ä»–äººçš„ä»£ç å†²çªï¼Œå¹¶ä¸”è®©ä»£ç å†²çªæ›´å®¹æ˜“è§£å†³\n\n   ```bash\n   git remote add upstream https://github.com/PaddlePaddle/PaddleNLP\n   git pull upstream develop\n   ```\n\n### 8. git push ä¸æäº¤ Pull Request\n\n   æ‚¨å¯ä»¥å°†æ‚¨çš„æœ¬åœ°å¼€å‘åˆ†æ”¯ä¸­çš„å·¥ä½œ push åˆ°æ‚¨çš„ fork çš„åˆ†æ”¯ä¸­ï¼š\n\n   ```bash\n   git push origin my-cool-stuff\n   ```\n\n   git push ä¹‹åï¼Œæ‚¨å¯ä»¥æäº¤ Pull Requestï¼Œè¯·æ±‚[å®˜æ–¹ repo](https://github.com/PaddlePaddle/PaddleNLP) é‡‡çº³æ‚¨çš„å¼€å‘å·¥ä½œã€‚è¯·æ‚¨ä¾ç…§[è¿™äº›æ­¥éª¤](https://help.github.com/articles/creating-a-pull-request/)åˆ›å»º Pull Requestã€‚\n\n### 9. åˆ é™¤å·²ç»åˆå…¥çš„æœ¬åœ°å’Œè¿œç¨‹åˆ†æ”¯\n\n   ä¸ºäº†ä¿æŒæ‚¨æœ¬åœ°çš„å·¥ä½œåŒºå’Œ fork åˆ†æ”¯çš„å¹²å‡€æ•´æ´ï¼Œå»ºè®®æ‚¨åœ¨ Pull Request åˆå…¥ä¹‹ååˆ é™¤æœ¬åœ°çš„æ®‹ä½™åˆ†æ”¯ï¼š\n\n   ```bash\n   git push origin my-cool-stuff\n   git checkout develop\n   git pull upstream develop\n   git branch -d my-cool-stuff\n   ```\n\n## ä»£ç  Review\n\n- åœ¨æ‚¨çš„ Pull Request èƒ½å¤Ÿé¡ºåˆ©é€šè¿‡æœ¬åœ°æµ‹è¯•ä»¥åŠ CI çš„æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥åœ¨ Pull Request ä¸­ @ ç›¸å…³çš„ Reviewerï¼Œæé†’ä»–ä»¬å°½å¿«å¯¹æ‚¨çš„ Pull Request è¿›è¡Œ Reviewã€‚\n\n- è¯·å¤„ç† Reviewer çš„æ¯ä¸€æ¡è¯„è®ºã€‚å¦‚æœæ‚¨å·²æŒ‰ç…§è¯„è®ºä¿®æ”¹ï¼Œè¯·å›å¤â€œå®Œæˆâ€ï¼›å¦åˆ™ï¼Œå¯ä»¥åœ¨è¯„è®ºä¸‹å±•å¼€è®¨è®ºã€‚\n\n- å¦‚æœæ‚¨ä¸å¸Œæœ›æ‚¨çš„ Reviewer è¢«ç”µå­é‚®ä»¶é€šçŸ¥æ·¹æ²¡ï¼Œæ‚¨å¯ä»¥[æ‰¹é‡å›å¤](https://help.github.com/articles/reviewing-proposed-changes-in-a-pull-request/)ã€‚\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.169921875,
          "content": "Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright (c) 2016 PaddlePaddle Authors. All Rights Reserved.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.98828125,
          "content": "# Makefile for PaddleNLP\n#\n# \tGitHb: https://github.com/PaddlePaddle/PaddleNLP\n# \tAuthor: Paddle Team https://github.com/PaddlePaddle\n#\n\n.PHONY: all\nall : lint test\ncheck_dirs := applications examples model_zoo paddlenlp pipelines ppdiffusers scripts tests \n# # # # # # # # # # # # # # # Format Block # # # # # # # # # # # # # # # \n\nformat:\n\tpre-commit run isort\n\tpre-commit run black\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n# # # # # # # # # # # # # # # Lint Block # # # # # # # # # # # # # # # \n\n.PHONY: lint\nlint:\n\t$(eval modified_py_files := $(shell python scripts/get_modified_files.py $(check_dirs)))\n\t@if test -n \"$(modified_py_files)\"; then \\\n\t\techo ${modified_py_files}; \\\n\t\tpre-commit run --files ${modified_py_files}; \\\n\telse \\\n\t\techo \"No library .py files were modified\"; \\\n\tfi\t\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n# # # # # # # # # # # # # # # Test Block # # # # # # # # # # # # # # # \n\n.PHONY: test\ntest: unit-test\n\nunit-test:\n\tPYTHONPATH=$(shell pwd) pytest -v \\\n\t\t-n auto \\\n\t\t--retries 1 --retry-delay 1 \\\n\t\t--durations 20 \\\n\t\t--cov paddlenlp \\\n\t\t--cov-report xml:coverage.xml\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n.PHONY: install\ninstall:\n\tpip install --pre paddlepaddle -i https://www.paddlepaddle.org.cn/packages/nightly/cpu/\n\tpip install -r requirements-dev.txt\n\tpip install -r requirements.txt\n\tpip install -r paddlenlp/experimental/autonlp/requirements.txt\n\tpre-commit install\n\n\n.PHONY: deploy-ppdiffusers\ndeploy-ppdiffusers:\n\tcd ppdiffusers && make install && make\n\n.PHONY: deploy-paddle-pipelines\ndeploy-paddle-pipelines:\n\tcd pipelines && make install && make\n\n.PHONY: deploy-paddlenlp\ndeploy-paddlenlp:\n\t# install related package\n\tmake install\n\t# build\n\tpython3 setup.py sdist bdist_wheel\n\t# upload\n\ttwine upload --skip-existing dist/*\n\n.PHONY: regression-all\nrelease: \n\tbash ./scripts/regression/run_release.sh 0 0,1 all\n\n.PHONY: regression-key\nkey: \n\tbash ./scripts/regression/run_release.sh 0 0,1 p0\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 31.4619140625,
          "content": "**ç®€ä½“ä¸­æ–‡**ğŸ€„ | [EnglishğŸŒ](./README_en.md)\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png\" align=\"middle\"  width=\"500\" />\n</p>\n\n------------------------------------------------------------------------------------------\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af\"></a>\n    <a href=\"https://pypi.org/project/paddlenlp/\"><img src=\"https://img.shields.io/pypi/dm/paddlenlp?color=9cf\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf\"></a>\n</p>\n\n<h4 align=\"center\">\n  <a href=#ç‰¹æ€§> ç‰¹æ€§ </a> |\n  <a href=#æ¨¡å‹æ”¯æŒ> æ¨¡å‹æ”¯æŒ </a> |\n  <a href=#å®‰è£…> å®‰è£… </a> |\n  <a href=#å¿«é€Ÿå¼€å§‹> å¿«é€Ÿå¼€å§‹ </a> |\n  <a href=#ç¤¾åŒºäº¤æµ> ç¤¾åŒºäº¤æµ </a>\n</h4>\n\n**PaddleNLP**æ˜¯ä¸€æ¬¾åŸºäºé£æ¡¨æ·±åº¦å­¦ä¹ æ¡†æ¶çš„å¤§è¯­è¨€æ¨¡å‹(LLM)å¼€å‘å¥—ä»¶ï¼Œæ”¯æŒåœ¨å¤šç§ç¡¬ä»¶ä¸Šè¿›è¡Œé«˜æ•ˆçš„å¤§æ¨¡å‹è®­ç»ƒã€æ— æŸå‹ç¼©ä»¥åŠé«˜æ€§èƒ½æ¨ç†ã€‚PaddleNLP å…·å¤‡**ç®€å•æ˜“ç”¨**å’Œ**æ€§èƒ½æè‡´**çš„ç‰¹ç‚¹ï¼Œè‡´åŠ›äºåŠ©åŠ›å¼€å‘è€…å®ç°é«˜æ•ˆçš„å¤§æ¨¡å‹äº§ä¸šçº§åº”ç”¨ã€‚\n\n<a href=\"https://trendshift.io/repositories/2246\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2246\" alt=\"PaddlePaddle%2FPaddleNLP | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n## News ğŸ“¢\n* **2024.12.16 [PaddleNLP v3.0 Beta3](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta3)**ï¼šå¤§æ¨¡å‹åŠŸèƒ½å…¨æ–°å‡çº§ï¼Œæ–°å¢äº† Llama-3.2ã€DeepSeekV2æ¨¡å‹ï¼Œå‡çº§äº† TokenizerFastï¼Œå¿«é€Ÿåˆ†è¯ï¼Œé‡æ„äº† SFTTrainerï¼Œä¸€é”®å¼€å¯ SFT è®­ç»ƒã€‚æ­¤å¤–ï¼ŒPaddleNLP è¿˜æ”¯æŒäº†ä¼˜åŒ–å™¨çŠ¶æ€çš„å¸è½½å’Œé‡è½½åŠŸèƒ½ï¼Œå®ç°äº†ç²¾ç»†åŒ–çš„é‡æ–°è®¡ç®—ï¼Œè®­ç»ƒæ€§èƒ½æå‡7%ã€‚åœ¨ Unified Checkpoint æ–¹é¢ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†å¼‚æ­¥ä¿å­˜é€»è¾‘ï¼Œæ–°å¢ Checkpoint å‹ç¼©åŠŸèƒ½ï¼Œå¯èŠ‚çœ78.5%å­˜å‚¨ç©ºé—´ã€‚\næœ€åï¼Œåœ¨å¤§æ¨¡å‹æ¨ç†æ–¹é¢ï¼Œå‡çº§ Append Attentionï¼Œæ”¯æŒäº† FP8é‡åŒ–ï¼Œæ”¯æŒæŠ•æœºè§£ç ã€‚\n\n* **2024.12.13 ğŸ“šã€Šé£æ¡¨å¤§æ¨¡å‹å¥—ä»¶ Unified Checkpoint æŠ€æœ¯ã€‹**ï¼ŒåŠ é€Ÿæ¨¡å‹å­˜å‚¨95%ï¼ŒèŠ‚çœç©ºé—´78%ã€‚æ”¯æŒå…¨åˆ†å¸ƒå¼ç­–ç•¥è°ƒæ•´è‡ªé€‚åº”è½¬æ¢ï¼Œæå‡æ¨¡å‹è®­ç»ƒçš„çµæ´»æ€§ä¸å¯æ‰©å±•æ€§ã€‚è®­ç»ƒ-å‹ç¼©-æ¨ç†ç»Ÿä¸€å­˜å‚¨åè®®ï¼Œæ— éœ€æ‰‹åŠ¨è½¬æ¢æå‡å…¨æµç¨‹ä½“éªŒã€‚Checkpoint æ— æŸå‹ç¼©ç»“åˆå¼‚æ­¥ä¿å­˜ï¼Œå®ç°ç§’çº§å­˜å‚¨å¹¶é™ä½æ¨¡å‹å­˜å‚¨æˆæœ¬ã€‚é€‚ç”¨äºæ™ºèƒ½åˆ¶é€ ã€æŒ‡æŒ¥äº¤é€šã€åŒ»ç–—å¥åº·ã€é‡‘èæœåŠ¡ç­‰äº§ä¸šå®é™…åœºæ™¯ã€‚12æœˆ24æ—¥ï¼ˆå‘¨äºŒï¼‰19ï¼š00ç›´æ’­ä¸ºæ‚¨è¯¦ç»†è§£è¯»è¯¥æŠ€æœ¯å¦‚ä½•ä¼˜åŒ–å¤§æ¨¡å‹è®­ç»ƒæµç¨‹ã€‚æŠ¥åé“¾æ¥ï¼šhttps://www.wjx.top/vm/huZkHn9.aspx?udsid=787976\n\n* **2024.11.28 ğŸ“šã€ŠFlashRAG-Paddle | åŸºäº PaddleNLP çš„é«˜æ•ˆå¼€å‘ä¸è¯„æµ‹ RAG æ¡†æ¶ã€‹**ï¼Œä¸ºæ–‡æœ¬æ›´å¿«æ›´å¥½æ„å»ºå‡†ç¡®åµŒå…¥è¡¨ç¤ºã€åŠ é€Ÿæ¨ç†ç”Ÿæˆé€Ÿåº¦ã€‚PaddleNLP æ”¯æŒè¶…å¤§ Batch åµŒå…¥è¡¨ç¤ºå­¦ä¹ ä¸å¤šç¡¬ä»¶é«˜æ€§èƒ½æ¨ç†ï¼Œæ¶µç›– INT8/INT4é‡åŒ–æŠ€æœ¯åŠå¤šç§é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–ä¸ TensorCore æ·±åº¦ä¼˜åŒ–ã€‚å†…ç½®å…¨ç¯èŠ‚ç®—å­èåˆæŠ€æœ¯ï¼Œä½¿å¾— FlashRAG æ¨ç†æ€§èƒ½ç›¸æ¯” transformers åŠ¨æ€å›¾æå‡70%ä»¥ä¸Šï¼Œç»“åˆæ£€ç´¢å¢å¼ºçŸ¥è¯†è¾“å‡ºç»“æœæ›´åŠ å‡†ç¡®ï¼Œå¸¦æ¥æ•æ·é«˜æ•ˆçš„ä½¿ç”¨ä½“éªŒã€‚ç›´æ’­æ—¶é—´ï¼š12æœˆ3æ—¥ï¼ˆå‘¨äºŒï¼‰19ï¼š00ã€‚æŠ¥åé“¾æ¥ï¼šhttps://www.wjx.top/vm/eaBa1vA.aspx?udsid=682361\n\n\n\n<details><summary> <b>ç‚¹å‡»å±•å¼€</b> </summary><div>\n\n* **2024.08.08 ğŸ“šã€Šé£æ¡¨äº§ä¸šçº§å¤§è¯­è¨€æ¨¡å‹å¼€å‘åˆ©å™¨ PaddleNLP 3.0 é‡ç£…å‘å¸ƒã€‹**ï¼Œè®­å‹æ¨å…¨æµç¨‹è´¯é€šï¼Œä¸»æµæ¨¡å‹å…¨è¦†ç›–ã€‚å¤§æ¨¡å‹è‡ªåŠ¨å¹¶è¡Œï¼Œåƒäº¿æ¨¡å‹è®­æ¨å…¨æµç¨‹å¼€ç®±å³ç”¨ã€‚æä¾›äº§ä¸šçº§é«˜æ€§èƒ½ç²¾è°ƒä¸å¯¹é½è§£å†³æ–¹æ¡ˆï¼Œå‹ç¼©æ¨ç†é¢†å…ˆï¼Œå¤šç¡¬ä»¶é€‚é…ã€‚è¦†ç›–äº§ä¸šçº§æ™ºèƒ½åŠ©æ‰‹ã€å†…å®¹åˆ›ä½œã€çŸ¥è¯†é—®ç­”ã€å…³é”®ä¿¡æ¯æŠ½å–ç­‰åº”ç”¨åœºæ™¯ã€‚ç›´æ’­æ—¶é—´ï¼š8æœˆ22æ—¥ï¼ˆå‘¨å››ï¼‰19ï¼š00ã€‚æŠ¥åé“¾æ¥ï¼šhttps://www.wjx.top/vm/Y2f7FFY.aspx?udsid=143844\n\n* **2024.06.27 [PaddleNLP v3.0 Beta](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta0)**ï¼šæ‹¥æŠ±å¤§æ¨¡å‹ï¼Œä½“éªŒå…¨å‡çº§ã€‚ç»Ÿä¸€å¤§æ¨¡å‹å¥—ä»¶ï¼Œå®ç°å›½äº§è®¡ç®—èŠ¯ç‰‡å…¨æµç¨‹æ¥å…¥ï¼›å…¨é¢æ”¯æŒé£æ¡¨4D å¹¶è¡Œé…ç½®ã€é«˜æ•ˆç²¾è°ƒç­–ç•¥ã€é«˜æ•ˆå¯¹é½ç®—æ³•ã€é«˜æ€§èƒ½æ¨ç†ç­‰å¤§æ¨¡å‹äº§ä¸šçº§åº”ç”¨æµç¨‹ï¼›è‡ªç ”æè‡´æ”¶æ•›çš„ RsLoRA+ç®—æ³•ã€è‡ªåŠ¨æ‰©ç¼©å®¹å­˜å‚¨æœºåˆ¶ Unified Checkpoint å’Œé€šç”¨åŒ–æ”¯æŒçš„ FastFFNã€FusedQKV åŠ©åŠ›å¤§æ¨¡å‹è®­æ¨ï¼›ä¸»æµæ¨¡å‹æŒç»­æ”¯æŒæ›´æ–°ï¼Œæä¾›é«˜æ•ˆè§£å†³æ–¹æ¡ˆã€‚\n\n* **2024.04.24 [PaddleNLP v2.8](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.8.0)**ï¼šè‡ªç ”æè‡´æ”¶æ•›çš„ RsLoRA+ç®—æ³•ï¼Œå¤§å¹…æå‡ PEFT è®­ç»ƒæ”¶æ•›é€Ÿåº¦ä»¥åŠè®­ç»ƒæ•ˆæœï¼›å¼•å…¥é«˜æ€§èƒ½ç”ŸæˆåŠ é€Ÿåˆ° RLHF PPO ç®—æ³•ï¼Œæ‰“ç ´ PPO è®­ç»ƒä¸­ç”Ÿæˆé€Ÿåº¦ç“¶é¢ˆï¼ŒPPO è®­ç»ƒæ€§èƒ½å¤§å¹…é¢†å…ˆã€‚é€šç”¨åŒ–æ”¯æŒ FastFFNã€FusedQKV ç­‰å¤šä¸ªå¤§æ¨¡å‹è®­ç»ƒæ€§èƒ½ä¼˜åŒ–æ–¹å¼ï¼Œå¤§æ¨¡å‹è®­ç»ƒæ›´å¿«ã€æ›´ç¨³å®šã€‚\n</div></details>\n\n## ç‰¹æ€§\n\n### <a href=#å¤šç¡¬ä»¶è®­æ¨ä¸€ä½“> ğŸ”§ å¤šç¡¬ä»¶è®­æ¨ä¸€ä½“ </a>\n\næ”¯æŒè‹±ä¼Ÿè¾¾ GPUã€æ˜†ä»‘ XPUã€æ˜‡è…¾ NPUã€ç‡§åŸ GCU å’Œæµ·å…‰ DCU ç­‰å¤šä¸ªç¡¬ä»¶çš„å¤§æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ï¼Œå¥—ä»¶æ¥å£æ”¯æŒç¡¬ä»¶å¿«é€Ÿåˆ‡æ¢ï¼Œå¤§å¹…é™ä½ç¡¬ä»¶åˆ‡æ¢ç ”å‘æˆæœ¬ã€‚\nå½“å‰æ”¯æŒçš„è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹ï¼š[å¤šç¡¬ä»¶è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹åˆ—è¡¨](./docs/model_zoo/model_list_multy_device.md)\n\n### <a href=#é«˜æ•ˆæ˜“ç”¨çš„é¢„è®­ç»ƒ> ğŸš€ é«˜æ•ˆæ˜“ç”¨çš„é¢„è®­ç»ƒ </a>\n\næ”¯æŒçº¯æ•°æ®å¹¶è¡Œç­–ç•¥ã€åˆ†ç»„å‚æ•°åˆ‡ç‰‡çš„æ•°æ®å¹¶è¡Œç­–ç•¥ã€å¼ é‡æ¨¡å‹å¹¶è¡Œç­–ç•¥å’Œæµæ°´çº¿æ¨¡å‹å¹¶è¡Œç­–ç•¥çš„4D é«˜æ€§èƒ½è®­ç»ƒï¼ŒTrainer æ”¯æŒåˆ†å¸ƒå¼ç­–ç•¥é…ç½®åŒ–ï¼Œé™ä½å¤æ‚åˆ†å¸ƒå¼ç»„åˆå¸¦æ¥çš„ä½¿ç”¨æˆæœ¬ï¼›\n[Unified Checkpoint å¤§æ¨¡å‹å­˜å‚¨å·¥å…·](./llm/docs/unified_checkpoint.md)å¯ä»¥ä½¿å¾—è®­ç»ƒæ–­ç‚¹æ”¯æŒæœºå™¨èµ„æºåŠ¨æ€æ‰©ç¼©å®¹æ¢å¤ã€‚æ­¤å¤–ï¼Œå¼‚æ­¥ä¿å­˜ï¼Œæ¨¡å‹å­˜å‚¨å¯åŠ é€Ÿ95%ï¼ŒCheckpoint å‹ç¼©ï¼Œå¯èŠ‚çœ78.5%å­˜å‚¨ç©ºé—´ã€‚\n\n### <a href=#é«˜æ•ˆç²¾è°ƒ> ğŸ¤— é«˜æ•ˆç²¾è°ƒ </a>\n\nç²¾è°ƒç®—æ³•æ·±åº¦ç»“åˆé›¶å¡«å……æ•°æ®æµå’Œ [FlashMask](./llm/docs/flashmask.md) é«˜æ€§èƒ½ç®—å­ï¼Œé™ä½è®­ç»ƒæ— æ•ˆæ•°æ®å¡«å……å’Œè®¡ç®—ï¼Œå¤§å¹…æå‡ç²¾è°ƒè®­ç»ƒååã€‚\n\n### <a href=#æ— æŸå‹ç¼©å’Œé«˜æ€§èƒ½æ¨ç†> ğŸ›ï¸ æ— æŸå‹ç¼©å’Œé«˜æ€§èƒ½æ¨ç† </a>\n\nå¤§æ¨¡å‹å¥—ä»¶é«˜æ€§èƒ½æ¨ç†æ¨¡å—å†…ç½®åŠ¨æ€æ’å…¥å’Œå…¨ç¯èŠ‚ç®—å­èåˆç­–ç•¥ï¼Œæå¤§åŠ å¿«å¹¶è¡Œæ¨ç†é€Ÿåº¦ã€‚åº•å±‚å®ç°ç»†èŠ‚å°è£…åŒ–ï¼Œå®ç°å¼€ç®±å³ç”¨çš„é«˜æ€§èƒ½å¹¶è¡Œæ¨ç†èƒ½åŠ›ã€‚\n\n------------------------------------------------------------------------------------------\n\n## æ¨¡å‹æ”¯æŒ\n\n* æ¨¡å‹å‚æ•°å·²æ”¯æŒ LLaMA ç³»åˆ—ã€Baichuan ç³»åˆ—ã€Bloom ç³»åˆ—ã€ChatGLM ç³»åˆ—ã€Gemma ç³»åˆ—ã€Mistral ç³»åˆ—ã€OPT ç³»åˆ—å’Œ Qwen ç³»åˆ—ï¼Œè¯¦ç»†åˆ—è¡¨ğŸ‘‰ã€LLMã€‘æ¨¡å‹å‚æ•°æ”¯æŒåˆ—è¡¨å¦‚ä¸‹ï¼š\n\n|                                          æ¨¡å‹ç³»åˆ—                                           | æ¨¡å‹åç§°                                                                                                                                                                                                                                                                                                                                                                                      |\n|:-------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|      [LLaMA](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)       | facebook/llama-7b, facebook/llama-13b, facebook/llama-30b, facebook/llama-65b                                                                                                                                                                                                                                                                                                                 |\n|      [Llama2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Llama-2-7b, meta-llama/Llama-2-7b-chat, meta-llama/Llama-2-13b, meta-llama/Llama-2-13b-chat, meta-llama/Llama-2-70b, meta-llama/Llama-2-70b-chat                                                                                                                                                                                                                                   |\n|      [Llama3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Meta-Llama-3-8B, meta-llama/Meta-Llama-3-8B-Instruct, meta-llama/Meta-Llama-3-70B, meta-llama/Meta-Llama-3-70B-Instruct                                                                                                                                                                                                                                                            |\n|     [Llama3.1](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Meta-Llama-3.1-8B, meta-llama/Meta-Llama-3.1-8B-Instruct, meta-llama/Meta-Llama-3.1-70B, meta-llama/Meta-Llama-3.1-70B-Instruct, meta-llama/Meta-Llama-3.1-405B, meta-llama/Meta-Llama-3.1-405B-Instruct, meta-llama/Llama-Guard-3-8B                                                                                                                                              |\n|     [Llama3.2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.2-1B, meta-llama/Llama-3.2-1B-Instruct, meta-llama/Llama-3.2-3B, meta-llama/Llama-3.2-3B-Instruct, meta-llama/Llama-Guard-3-1B                                                                                                                                                                                                                                             |\n|     [Llama3.3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.3-70B-Instruct                                                                                                                                                                                                                                                                                                                                                             |\n|   [Baichuan](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)    | baichuan-inc/Baichuan-7B, baichuan-inc/Baichuan-13B-Base, baichuan-inc/Baichuan-13B-Chat                                                                                                                                                                                                                                                                                                      |\n|   [Baichuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)   | baichuan-inc/Baichuan2-7B-Base, baichuan-inc/Baichuan2-7B-Chat, baichuan-inc/Baichuan2-13B-Base, baichuan-inc/Baichuan2-13B-Chat                                                                                                                                                                                                                                                              |\n|      [Bloom](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/bloom)       | bigscience/bloom-560m, bigscience/bloom-560m-bf16, bigscience/bloom-1b1, bigscience/bloom-3b, bigscience/bloom-7b1, bigscience/bloomz-560m, bigscience/bloomz-1b1, bigscience/bloomz-3b, bigscience/bloomz-7b1-mt, bigscience/bloomz-7b1-p3, bigscience/bloomz-7b1, bellegroup/belle-7b-2m                                                                                                    |\n|    [ChatGLM](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm/)    | THUDM/chatglm-6b, THUDM/chatglm-6b-v1.1                                                                                                                                                                                                                                                                                                                                                       |\n|   [ChatGLM2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm2-6b                                                                                                                                                                                                                                                                                                                                                                             |\n|   [ChatGLM3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm3-6b                                                                                                                                                                                                                                                                                                                                                                             |\n| [DeepSeekV2](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V2, deepseek-ai/DeepSeek-V2-Chat, deepseek-ai/DeepSeek-V2-Lite, deepseek-ai/DeepSeek-V2-Lite-Chat, deepseek-ai/DeepSeek-Coder-V2-Base, deepseek-ai/DeepSeek-Coder-V2-Instruct, deepseek-ai/DeepSeek-Coder-V2-Lite-Base, deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct                                                                                                      |\n| [DeepSeekV3](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V3, deepseek-ai/DeepSeek-V3-Base                                                                                                                                                                                                                                                                                                                                         |\n|      [Gemma](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/gemma)       | google/gemma-7b, google/gemma-7b-it, google/gemma-2b, google/gemma-2b-it                                                                                                                                                                                                                                                                                                                      |\n|    [Mistral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mistral)     | mistralai/Mistral-7B-Instruct-v0.3, mistralai/Mistral-7B-v0.1                                                                                                                                                                                                                                                                                                                                 |\n|    [Mixtral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mixtral)     | mistralai/Mixtral-8x7B-Instruct-v0.1                                                                                                                                                                                                                                                                                                                                                          |\n|        [OPT](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/opt)         | facebook/opt-125m, facebook/opt-350m, facebook/opt-1.3b, facebook/opt-2.7b, facebook/opt-6.7b, facebook/opt-13b, facebook/opt-30b, facebook/opt-66b, facebook/opt-iml-1.3b, opt-iml-max-1.3b                                                                                                                                                                                                  |\n|       [Qwen](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | qwen/qwen-7b, qwen/qwen-7b-chat, qwen/qwen-14b, qwen/qwen-14b-chat, qwen/qwen-72b, qwen/qwen-72b-chat,                                                                                                                                                                                                                                                                                        |\n|     [Qwen1.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen1.5-0.5B, Qwen/Qwen1.5-0.5B-Chat, Qwen/Qwen1.5-1.8B, Qwen/Qwen1.5-1.8B-Chat, Qwen/Qwen1.5-4B, Qwen/Qwen1.5-4B-Chat, Qwen/Qwen1.5-7B, Qwen/Qwen1.5-7B-Chat, Qwen/Qwen1.5-14B, Qwen/Qwen1.5-14B-Chat, Qwen/Qwen1.5-32B, Qwen/Qwen1.5-32B-Chat, Qwen/Qwen1.5-72B, Qwen/Qwen1.5-72B-Chat, Qwen/Qwen1.5-110B, Qwen/Qwen1.5-110B-Chat, Qwen/Qwen1.5-MoE-A2.7B, Qwen/Qwen1.5-MoE-A2.7B-Chat |\n|      [Qwen2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | Qwen/Qwen2-0.5B, Qwen/Qwen2-0.5B-Instruct, Qwen/Qwen2-1.5B, Qwen/Qwen2-1.5B-Instruct, Qwen/Qwen2-7B, Qwen/Qwen2-7B-Instruct, Qwen/Qwen2-72B, Qwen/Qwen2-72B-Instruct, Qwen/Qwen2-57B-A14B, Qwen/Qwen2-57B-A14B-Instruct                                                                                                                                                                       |\n|    [Qwen2-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)    | Qwen/Qwen2-Math-1.5B, Qwen/Qwen2-Math-1.5B-Instruct, Qwen/Qwen2-Math-7B, Qwen/Qwen2-Math-7B-Instruct, Qwen/Qwen2-Math-72B, Qwen/Qwen2-Math-72B-Instruct, Qwen/Qwen2-Math-RM-72B                                                                                                                                                                                                               |\n|     [Qwen2.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen2.5-0.5B, Qwen/Qwen2.5-0.5B-Instruct, Qwen/Qwen2.5-1.5B, Qwen/Qwen2.5-1.5B-Instruct, Qwen/Qwen2.5-3B, Qwen/Qwen2.5-3B-Instruct, Qwen/Qwen2.5-7B, Qwen/Qwen2.5-7B-Instruct, Qwen/Qwen2.5-14B, Qwen/Qwen2.5-14B-Instruct, Qwen/Qwen2.5-32B, Qwen/Qwen2.5-32B-Instruct, Qwen/Qwen2.5-72B, Qwen/Qwen2.5-72B-Instruct                                                                     |\n|   [Qwen2.5-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Math-1.5B, Qwen/Qwen2.5-Math-1.5B-Instruct, Qwen/Qwen2.5-Math-7B, Qwen/Qwen2.5-Math-7B-Instruct, Qwen/Qwen2.5-Math-72B, Qwen/Qwen2.5-Math-72B-Instruct, Qwen/Qwen2.5-Math-RM-72B                                                                                                                                                                                                 |\n|  [Qwen2.5-Coder](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Coder-1.5B, Qwen/Qwen2.5-Coder-1.5B-Instruct, Qwen/Qwen2.5-Coder-7B, Qwen/Qwen2.5-Coder-7B-Instruct                                                                                                                                                                                                                                                                              |\n|      [Yuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/yuan/)       | IEITYuan/Yuan2-2B, IEITYuan/Yuan2-51B, IEITYuan/Yuan2-102B                                                                                                                                                                                                                                                                                                                                    |\n\n* 4D å¹¶è¡Œå’Œç®—å­ä¼˜åŒ–å·²æ”¯æŒ LLaMA ç³»åˆ—ã€Baichuan ç³»åˆ—ã€Bloom ç³»åˆ—ã€ChatGLM ç³»åˆ—ã€Gemma ç³»åˆ—ã€Mistral ç³»åˆ—ã€OPT ç³»åˆ—å’Œ Qwen ç³»åˆ—ï¼Œã€LLMã€‘æ¨¡å‹4D å¹¶è¡Œå’Œç®—å­æ”¯æŒåˆ—è¡¨å¦‚ä¸‹ï¼š\n\n\n| æ¨¡å‹åç§°/å¹¶è¡Œèƒ½åŠ›æ”¯æŒ | æ•°æ®å¹¶è¡Œ | å¼ é‡æ¨¡å‹å¹¶è¡Œ |          | å‚æ•°åˆ†ç‰‡å¹¶è¡Œ |        |        | æµæ°´çº¿å¹¶è¡Œ |\n|:---------------------:|:--------:|:------------:|:--------:|:------------:|:------:|:------:|:----------:|\n|                       |          |   åŸºç¡€èƒ½åŠ›   | åºåˆ—å¹¶è¡Œ |    stage1    | stage2 | stage3 |            |\n|         Llama         |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|         Qwen          |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|        Qwen1.5        |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|         Qwen2         |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|     Mixtral(moe)      |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|        Mistral        |    âœ…     |      âœ…       |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|       Baichuan        |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|       Baichuan2       |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|        ChatGLM        |    âœ…     |      âœ…       |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|       ChatGLM2        |    âœ…     |      ğŸš§      |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|       ChatGLM3        |    âœ…     |      ğŸš§      |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|         Bloom         |    âœ…     |      âœ…       |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|      GPT-2/GPT-3      |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|          OPT          |    âœ…     |      âœ…       |    ğŸš§    |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n|         Gemma         |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     âœ…      |\n|         Yuan2         |    âœ…     |      âœ…       |    âœ…     |      âœ…       |   âœ…    |   âœ…    |     ğŸš§     |\n\n* å¤§æ¨¡å‹é¢„è®­ç»ƒã€ç²¾è°ƒï¼ˆåŒ…å« SFTã€PEFT æŠ€æœ¯ï¼‰ã€å¯¹é½ã€é‡åŒ–å·²æ”¯æŒ LLaMA ç³»åˆ—ã€Baichuan ç³»åˆ—ã€Bloom ç³»åˆ—ã€ChatGLM ç³»åˆ—ã€Mistral ç³»åˆ—ã€OPT ç³»åˆ—å’Œ Qwen ç³»åˆ—ï¼Œã€LLMã€‘æ¨¡å‹é¢„è®­ç»ƒã€ç²¾è°ƒã€å¯¹é½ã€é‡åŒ–æ”¯æŒåˆ—è¡¨å¦‚ä¸‹ï¼š\n\n\n| Model                                      | Pretrain | SFT | LoRA | FlashMask | Prefix Tuning | DPO/SimPO/ORPO/KTO | RLHF | Mergekit | Quantization |\n|--------------------------------------------|:--------:|:---:|:----:|:---------:|:-------------:|:------------------:|:----:|:--------:|:------------:|\n| [Llama](./llm/config/llama)                |    âœ…     |  âœ…  |  âœ…   |     âœ…     |       âœ…       |         âœ…          |  âœ…   |    âœ…     |      âœ…       |\n| [Qwen](./llm/config/qwen)                  |    âœ…     |  âœ…  |  âœ…   |     âœ…     |       âœ…       |         âœ…          |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [Mixtral](./llm/config/mixtral)            |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |      ğŸš§       |         âœ…          |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [Mistral](./llm/config/mistral)            |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |       âœ…       |         âœ…          |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [Baichuan/Baichuan2](./llm/config/llama)   |    âœ…     |  âœ…  |  âœ…   |     âœ…     |       âœ…       |         âœ…          |  ğŸš§  |    âœ…     |      âœ…       |\n| [ChatGLM-6B](./llm/config/chatglm)         |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |       âœ…       |         ğŸš§         |  ğŸš§  |    âœ…     |      âœ…       |\n| [ChatGLM2/ChatGLM3](./llm/config/chatglm2) |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |       âœ…       |         âœ…          |  ğŸš§  |    âœ…     |      âœ…       |\n| [Bloom](./llm/config/bloom)                |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |       âœ…       |         ğŸš§         |  ğŸš§  |    âœ…     |      âœ…       |\n| [GPT-3](./llm/config/gpt-3)                |    âœ…     |  âœ…  |  ğŸš§  |    ğŸš§     |      ğŸš§       |         ğŸš§         |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [OPT](./llm/config/opt)                    |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |      ğŸš§       |         ğŸš§         |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [Gemma](./llm/config/gemma)                |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |      ğŸš§       |         âœ…          |  ğŸš§  |    âœ…     |      ğŸš§      |\n| [Yuan](./llm/config/yuan)                  |    âœ…     |  âœ…  |  âœ…   |    ğŸš§     |      ğŸš§       |         âœ…          |  ğŸš§  |    âœ…     |      ğŸš§      |\n* [å¤§æ¨¡å‹æ¨ç†](./llm/docs/predict/inference.md)å·²æ”¯æŒ LLaMA ç³»åˆ—ã€Qwen ç³»åˆ—ã€Mistral ç³»åˆ—ã€ChatGLM ç³»åˆ—ã€Bloom ç³»åˆ—å’Œ Baichuan ç³»åˆ—ï¼Œæ”¯æŒ Weight Only INT8åŠ INT4æ¨ç†ï¼Œæ”¯æŒ WACï¼ˆæƒé‡ã€æ¿€æ´»ã€Cache KVï¼‰è¿›è¡Œ INT8ã€FP8é‡åŒ–çš„æ¨ç†ï¼Œã€LLMã€‘æ¨¡å‹æ¨ç†æ”¯æŒåˆ—è¡¨å¦‚ä¸‹ï¼š\n\n|          æ¨¡å‹åç§°/é‡åŒ–ç±»å‹æ”¯æŒ           | FP16/BF16 | WINT8 | WINT4 | INT8-A8W8 | FP8-A8W8 | INT8-A8W8C8 |\n|:----------------------------------------:|:---------:|:-----:|:-----:|:---------:|:--------:|:-----------:|\n|   [LLaMA](./llm/docs/predict/llama.md)   |     âœ…     |   âœ…   |   âœ…   |     âœ…     |    âœ…     |      âœ…      |\n|    [Qwen](./llm/docs/predict/qwen.md)    |     âœ…     |   âœ…   |   âœ…   |     âœ…     |    âœ…     |      âœ…      |\n|  [Qwen-Moe](./llm/docs/predict/qwen.md)  |     âœ…     |   âœ…   |   âœ…   |    ğŸš§     |    ğŸš§    |     ğŸš§      |\n| [Mixtral](./llm/docs/predict/mixtral.md) |     âœ…     |   âœ…   |   âœ…   |    ğŸš§     |    ğŸš§    |     ğŸš§      |\n|                 ChatGLM                  |     âœ…     |   âœ…   |   âœ…   |    ğŸš§     |    ğŸš§    |     ğŸš§      |\n|                  Bloom                   |     âœ…     |   âœ…   |   âœ…   |    ğŸš§     |    ğŸš§    |     ğŸš§      |\n|                 BaiChuan                 |     âœ…     |   âœ…   |   âœ…   |     âœ…     |    âœ…     |     ğŸš§      |\n\n## å®‰è£…\n\n### ç¯å¢ƒä¾èµ–\n\n* python >= 3.8\n* paddlepaddle >= 3.0.0b0\n\nå¦‚æœæ‚¨å°šæœªå®‰è£… PaddlePaddleï¼Œè¯·å‚è€ƒ [é£æ¡¨å®˜ç½‘](https://www.paddlepaddle.org.cn/) è¿›è¡Œå®‰è£…ã€‚\n\n### pip å®‰è£…\n\n```shell\npip install --upgrade paddlenlp==3.0.0b3\n```\n\næˆ–è€…å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…æœ€æ–° develop åˆ†æ”¯ä»£ç ï¼š\n\n```shell\npip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html\n```\n\næ›´å¤šå…³äº PaddlePaddle å’Œ PaddleNLP å®‰è£…çš„è¯¦ç»†æ•™ç¨‹è¯·æŸ¥çœ‹[Installation](./docs/get_started/installation.rst)ã€‚\n\n------------------------------------------------------------------------------------------\n\n## å¿«é€Ÿå¼€å§‹\n\n### å¤§æ¨¡å‹æ–‡æœ¬ç”Ÿæˆ\n\nPaddleNLP æä¾›äº†æ–¹ä¾¿æ˜“ç”¨çš„ Auto APIï¼Œèƒ½å¤Ÿå¿«é€Ÿçš„åŠ è½½æ¨¡å‹å’Œ Tokenizerã€‚è¿™é‡Œä»¥ä½¿ç”¨ `Qwen/Qwen2-0.5B` æ¨¡å‹åšæ–‡æœ¬ç”Ÿæˆä¸ºä¾‹ï¼š\n\n```python\n>>> from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n>>> model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", dtype=\"float16\")\n>>> input_features = tokenizer(\"ä½ å¥½ï¼è¯·è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ã€‚\", return_tensors=\"pd\")\n>>> outputs = model.generate(**input_features, max_length=128)\n>>> print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True))\n['æˆ‘æ˜¯ä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå¤©æ°”ã€æ–°é—»ã€å†å²ã€æ–‡åŒ–ã€ç§‘å­¦ã€æ•™è‚²ã€å¨±ä¹ç­‰ã€‚è¯·é—®æ‚¨æœ‰ä»€ä¹ˆéœ€è¦äº†è§£çš„å—ï¼Ÿ']\n```\n\n### å¤§æ¨¡å‹é¢„è®­ç»ƒ\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # å¦‚å·²cloneæˆ–ä¸‹è½½PaddleNLPå¯è·³è¿‡\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\ncd .. # change folder to PaddleNLP/llm\n# å¦‚éœ€ä½¿ç”¨use_fused_rms_norm=trueï¼Œéœ€è¦å‰å¾€slm/model_zoo/gpt-3/external_opså®‰è£…fused_ln\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_pretrain.py ./config/llama/pretrain_argument.json --use_fused_rms_norm false\n```\n\n### å¤§æ¨¡å‹ SFT ç²¾è°ƒ\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # å¦‚å·²cloneæˆ–ä¸‹è½½PaddleNLPå¯è·³è¿‡\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_finetune.py ./config/llama/sft_argument.json\n```\n\næ›´å¤šå¤§æ¨¡å‹å…¨æµç¨‹æ­¥éª¤ï¼Œè¯·å‚è€ƒ[é£æ¡¨å¤§æ¨¡å‹å¥—ä»¶](./llm)ä»‹ç»ã€‚\nå¦å¤–æˆ‘ä»¬è¿˜æä¾›äº†å¿«é€Ÿå¾®è°ƒæ–¹å¼, æ— éœ€ clone æºä»£ç ï¼š\n\n```python\nfrom paddlenlp.trl import SFTConfig, SFTTrainer\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ZHUI/alpaca_demo\", split=\"train\")\n\ntraining_args = SFTConfig(output_dir=\"Qwen/Qwen2.5-0.5B-SFT\", device=\"gpu\")\ntrainer = SFTTrainer(\n    args=training_args,\n    model=\"Qwen/Qwen2.5-0.5B\",\n    train_dataset=dataset,\n)\ntrainer.train()\n```\n\næ›´å¤š PaddleNLP å†…å®¹å¯å‚è€ƒï¼š\n\n* [ç²¾é€‰æ¨¡å‹åº“](./slm/model_zoo)ï¼ŒåŒ…å«ä¼˜è´¨é¢„è®­ç»ƒæ¨¡å‹çš„ç«¯åˆ°ç«¯å…¨æµç¨‹ä½¿ç”¨ã€‚\n* [å¤šåœºæ™¯ç¤ºä¾‹](./slm/examples)ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨ PaddleNLP è§£å†³ NLP å¤šç§æŠ€æœ¯é—®é¢˜ï¼ŒåŒ…å«åŸºç¡€æŠ€æœ¯ã€ç³»ç»Ÿåº”ç”¨ä¸æ‹“å±•åº”ç”¨ã€‚\n* [äº¤äº’å¼æ•™ç¨‹](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995)ï¼Œåœ¨ğŸ†“å…è´¹ç®—åŠ›å¹³å° AI Studio ä¸Šå¿«é€Ÿå­¦ä¹  PaddleNLPã€‚\n\n------------------------------------------------------------------------------------------\n\n## ç¤¾åŒºäº¤æµ\n\n* å¾®ä¿¡æ‰«æäºŒç»´ç å¹¶å¡«å†™é—®å·ï¼Œå³å¯åŠ å…¥äº¤æµç¾¤ä¸ä¼—å¤šç¤¾åŒºå¼€å‘è€…ä»¥åŠå®˜æ–¹å›¢é˜Ÿæ·±åº¦äº¤æµ.\n\n<div align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/3a58cc9f-69c7-4ccb-b6f5-73e966b8051a\" width=\"150\" height=\"150\" />\n</div>\n\n## Citation\n\nå¦‚æœ PaddleNLP å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨\n\n```bibtex\n@misc{=paddlenlp,\n    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},\n    author={PaddleNLP Contributors},\n    howpublished = {\\url{https://github.com/PaddlePaddle/PaddleNLP}},\n    year={2021}\n}\n```\n\n## Acknowledge\n\næˆ‘ä»¬å€Ÿé‰´äº† Hugging Face çš„[Transformers](https://github.com/huggingface/transformers)ğŸ¤—å…³äºé¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„ä¼˜ç§€è®¾è®¡ï¼Œåœ¨æ­¤å¯¹ Hugging Face ä½œè€…åŠå…¶å¼€æºç¤¾åŒºè¡¨ç¤ºæ„Ÿè°¢ã€‚\n\n## License\n\nPaddleNLP éµå¾ª[Apache-2.0å¼€æºåè®®](./LICENSE)ã€‚\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 9.7080078125,
          "content": "[ç®€ä½“ä¸­æ–‡ğŸ€„](./README.md) | **EnglishğŸŒ**\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png\" align=\"middle\"  width=\"500\" />\n</p>\n\n------------------------------------------------------------------------------------------\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af\"></a>\n    <a href=\"https://pypi.org/project/paddlenlp/\"><img src=\"https://img.shields.io/pypi/dm/paddlenlp?color=9cf\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf\"></a>\n</p>\n\n<h4 align=\"center\">\n    <a href=#Features> Features </a> |\n    <a href=#Support-Models> Supported Models </a> |\n    <a href=#Installation> Installation </a> |\n    <a href=#Quick-start> Quick Start </a> |\n    <a href=#community> Community </a>\n</h4>\n\n**PaddleNLP** is a Large Language Model (LLM) development suite based on the PaddlePaddle deep learning framework, supporting efficient large model training, lossless compression, and high-performance inference on various hardware devices. With its **simplicity** and **ultimate performance**, PaddleNLP is dedicated to helping developers achieve efficient industrial applications of large models.\n\n## News ğŸ“¢\n\n* **2024.06.27 [PaddleNLP v3.0 Beta](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta0)**ï¼šEmbrace large models and experience a complete upgrade. With a unified large model suite, we achieve full-process access to domestically produced computing chips. We fully support industrial-level application processes for large models, such as PaddlePaddle's 4D parallel configuration, efficient fine-tuning strategies, efficient alignment algorithms, and high-performance reasoning. Our developed RsLoRA+ algorithm, full checkpoint storage mechanism Unified Checkpoint, and generalized support for FastFNN and FusedQKV all contribute to the training and inference of large models. We continuously support updates to mainstream models for providing efficient solutions.\n\n* **2024.04.24 [PaddleNLP v2.8](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.8.0)**ï¼šOur self-developed RsLoRA+ algorithm with extreme convergence significantly improves the convergence speed and training effectiveness of PEFT training. By introducing high-performance generation acceleration into the RLHF PPO algorithm, we have broken through the generation speed bottleneck in PPO training, achieving a significant lead in PPO training performance. We generally support multiple large model training performance optimization methods such as FastFFN and FusedQKV, making large model training faster and more stable.\n\n## Features\n\n### <a href=#Integrated training and inference on multiple hardware platforms> ğŸ”§ Integrated training and inference on multiple hardware platforms </a>\n\nOur development suit supports large model training and inference on multiple hardware platforms, including NVIDIA GPUs, Kunlun XPUs, Ascend NPUs, Enflame GCUs, and Hygon DCUs. The toolkit's interface allows for quick hardware switching, significantly reducing research and development costs associated with hardware transitions.\n\n### <a href=Efficient and easy-to-use pre-training> ğŸš€ Efficient and easy-to-use pre-training </a>\n\nWe support 4D high-performance training with data parallelism, sharding parallelism, tensor parallelism, and pipeline parallelism. The Trainer supports configurable distributed strategies, reducing the cost associated with complex distributed combinations. The Unified Checkpoint large model storage format supports dynamic scaling of model parameter distribution during training, thereby reducing the migration cost caused by hardware switching.\n\n### <a href=#Efficient fine-tuning> ğŸ¤— Efficient fine-tuning </a>\n\nThe fine-tuning algorithms are deeply integrated with zero-padding data streams and high-performance FlashMask operators, reducing invalid data padding and computation during training, and significantly improving the throughput of fine-tuning training.\n\n### <a href=#Lossless compression and high-performance inference> ğŸ›ï¸ Lossless compression and high-performance inference </a>\n\nThe high-performance inference module of the large model toolkit incorporates dynamic insertion and operator fusion strategies throughout the entire process, greatly accelerating parallel inference speed. The underlying implementation details are encapsulated, enabling out-of-the-box high-performance parallel inference capabilities.\n\n------------------------------------------------------------------------------------------\n\n## Support Models\n\nDetailed list ğŸ‘‰ [Supported Model List](https://github.com/PaddlePaddle/PaddleNLP/issues/8663)\n\n## Installation\n\n### Prerequisites\n\n* python >= 3.8\n* paddlepaddle >= 3.0.0b0\n\n### Pip Installation\n\n```shell\npip install --upgrade paddlenlp==3.0.0b2\n```\n\nor you can install the latest develop branch code with the following command:\n\n```shell\npip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html\n```\n\nMore information about PaddlePaddle installation please refer to [PaddlePaddle's Website](https://www.paddlepaddle.org.cn).\n\n------------------------------------------------------------------------------------------\n\n## Quick Start\n\n### Text generation with large language model\n\nPaddleNLP provides a convenient and easy-to-use Auto API, which can quickly load models and Tokenizers. Here, we use the `Qwen/Qwen2-0.5B` large model as an example for text generation:\n\n```python\n>>> from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n>>> model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", dtype=\"float16\")\n>>> input_features = tokenizer(\"ä½ å¥½ï¼è¯·è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ã€‚\", return_tensors=\"pd\")\n>>> outputs = model.generate(**input_features, max_length=128)\n>>> print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True))\n['æˆ‘æ˜¯ä¸€ä¸ªAIè¯­è¨€æ¨¡å‹ï¼Œæˆ‘å¯ä»¥å›ç­”å„ç§é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šå¤©æ°”ã€æ–°é—»ã€å†å²ã€æ–‡åŒ–ã€ç§‘å­¦ã€æ•™è‚²ã€å¨±ä¹ç­‰ã€‚è¯·é—®æ‚¨æœ‰ä»€ä¹ˆéœ€è¦äº†è§£çš„å—ï¼Ÿ']\n```\n\n### Pre-training for large language model\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # if cloned or downloaded, can skip this step\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_pretrain.py ./config/llama/pretrain_argument.json\n```\n\n### SFT finetuning forlarge language model\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # if cloned or downloaded, can skip this step\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_finetune.py ./config/llama/sft_argument.json\n```\n\nFor more steps in the entire large model process, please refer to the[Large Model Full-Process Suite](./llm).\n\nFor more PaddleNLP content, please refer to:\n\n* [Model Library](./slm/model_zoo)ï¼Œwhich includes end-to-end usage of high-quality pre-trained models.\n* [Multi-scenario Examples](./slm/examples)ï¼Œto understand how to use PaddleNLP to solve various NLP technical problems, including basic techniques, system applications, and extended applications.\n* [Interactive Tutorial](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995)ï¼Œto quickly learn PaddleNLP on the free computing platform AI Studio.\n\n------------------------------------------------------------------------------------------\n\n## Community\n\n### Slack\n\nTo connect with other users and contributors, welcome to join our [Slack channel](https://paddlenlp.slack.com/).\n\n### WeChat\n\nScan the QR code below with your Wechatâ¬‡ï¸. You can access to official technical exchange group. Look forward to your participation.\n\n<div align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/3a58cc9f-69c7-4ccb-b6f5-73e966b8051a\" width=\"150\" height=\"150\" />\n</div>\n\n## Citation\n\nIf you find PaddleNLP useful in your research, please consider citing\n\n```bibtext\n@misc{=paddlenlp,\n    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},\n    author={PaddleNLP Contributors},\n    howpublished = {\\url{https://github.com/PaddlePaddle/PaddleNLP}},\n    year={2021}\n}\n```\n\n## Acknowledge\n\nWe have borrowed from Hugging Face's [Transformers](https://github.com/huggingface/transformers)ğŸ¤— excellent design on pretrained models usage, and we would like to express our gratitude to the authors of Hugging Face and its open source community.\n\n## License\n\nPaddleNLP is provided under the [Apache-2.0 License](./LICENSE).\n"
        },
        {
          "name": "csrc",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "llm",
          "type": "tree",
          "content": null
        },
        {
          "name": "ops",
          "type": "tree",
          "content": null
        },
        {
          "name": "paddlenlp",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.859375,
          "content": "[tool.isort]\nprofile = 'black'\nknown_third_party = [\"paddle\"]\nskip = ['paddlenlp/transformers/__init__.py']\n\n[tool.black]\nline-length = 119\ntarget_version = ['py35', 'py36', 'py37', 'py38', 'py39', 'py310']\nexclude = ['.flake8']\n\n[tool.pytest.ini_options]\nminversion = \"6.0\"\naddopts = \"-ra -q \"\npythonpath = [\".\"]\ntestpaths = [\n    \"tests/data\",\n    \"tests/dataaug\",\n    \"tests/datasets\",\n    \"tests/embeddings\",\n    \"tests/experimental\",\n    \"tests/generation\",\n    \"tests/layers\",\n    \"tests/metrics\",\n    \"tests/pose\",\n    \"tests/ops\",\n    \"tests/trainer\",\n    \"tests/transformers\",\n    \"tests/peft\",\n    \"tests/prompt\",\n    \"tests/mergekit\",\n    # \"tests/taskflow\",  TODO (paddle 2.5.1 breaks this test suite, debug later)\n    \"tests/utils\",\n]\npython_files = [\n    \"test.py\",\n    \"test_*.py\"\n]\nfilterwarnings = [\n    \"ignore::UserWarning\",\n    'ignore::DeprecationWarning',\n]\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.3076171875,
          "content": "paddleocr\npre-commit\npytest==8.1.1\nparameterized\npytest-cov\nregex\npytest-xdist\npytest-timeout\nemoji\nftfy\nyacs\nunidecode\nsoundfile\nlibrosa\nnumpy==1.23.5\nrouge\ntiktoken\nvisualdl\nwandb\ntensorboard\ntensorboardX\nmodelscope\nhyperopt\nh5py\ndeploy\nray\nloguru\ndata\nwget\nhuggingface_hub>=0.19.2\ntiktoken\ntokenizers>=0.21,<0.22"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3798828125,
          "content": "jieba\nblobfile\ncolorlog\ncolorama\nseqeval\ndill<0.3.5\nmultiprocess<=0.70.12.2\ndatasets >= 2.0.0\ntqdm\npaddlefsl\nsentencepiece\nhuggingface_hub>=0.19.2\nonnx>=1.10.0\nprotobuf>=3.20.2\npaddle2onnx\nFlask-Babel\nvisualdl\nfastapi\nuvicorn\ntyper\nrich\nsafetensors\nfast_dataindex>=0.1.1 ; platform_system == \"Linux\"\naistudio-sdk>=0.1.3\njinja2\nregex\nnumpy<=1.26.4\ntiktoken\ntokenizers>=0.21,<0.22\nomegaconf\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.421875,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport errno\nimport io\nimport os\nimport re\nimport subprocess\nfrom datetime import datetime\n\nimport setuptools\n\nPADDLENLP_STABLE_VERSION = \"PADDLENLP_STABLE_VERSION\"\n\n\ndef read_requirements_file(filepath):\n    with open(filepath) as fin:\n        requirements = fin.read()\n    return requirements\n\n\ndef is_git_repo(dir: str) -> bool:\n    \"\"\"Is the given directory version-controlled with git?\"\"\"\n    return os.path.exists(os.path.join(dir, \".git\"))\n\n\ndef have_git() -> bool:\n    \"\"\"Can we run the git executable?\"\"\"\n    try:\n        subprocess.check_output([\"git\", \"--help\"])\n        return True\n    except subprocess.CalledProcessError:\n        return False\n    except OSError:\n        return False\n\n\ndef git_revision(dir: str) -> bytes:\n    \"\"\"Get the SHA-1 of the HEAD of a git repository.\"\"\"\n    return subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=dir).strip()\n\n\ndef git_checkout(dir: str, filename: str) -> bytes:\n    \"\"\"Get the SHA-1 of the HEAD of a git repository.\"\"\"\n    return subprocess.check_output([\"git\", \"checkout\", filename], cwd=dir).strip()\n\n\ndef is_dirty(dir: str) -> bool:\n    \"\"\"Check whether a git repository has uncommitted changes.\"\"\"\n    output = subprocess.check_output([\"git\", \"status\", \"-uno\", \"--porcelain\"], cwd=dir)\n    return output.strip() != b\"\"\n\n\ncommit = \"unknown\"\npaddlenlp_dir = os.path.abspath(os.path.dirname(__file__))\nif commit.endswith(\"unknown\") and is_git_repo(paddlenlp_dir) and have_git():\n    commit = git_revision(paddlenlp_dir).decode(\"utf-8\")\n    if is_dirty(paddlenlp_dir):\n        commit += \".dirty\"\n\n\ndef write_version_py(filename=\"paddlenlp/version/__init__.py\"):\n    cnt = '''# THIS FILE IS GENERATED FROM PADDLENLP SETUP.PY\ncommit           = '%(commit)s'\n\n__all__ = ['show']\n\ndef show():\n    \"\"\"Get the corresponding commit id of paddlenlp.\n\n    Returns:\n        The commit-id of paddlenlp will be output.\n\n        full_version: version of paddlenlp\n\n\n    Examples:\n        .. code-block:: python\n\n            import paddlenlp\n\n            paddlenlp.version.show()\n            # commit: 1ef5b94a18773bb0b1bba1651526e5f5fc5b16fa\n\n    \"\"\"\n    print(\"commit:\", commit)\n\n'''\n    commit_id = commit\n    content = cnt % {\"commit\": commit_id}\n\n    dirname = os.path.dirname(filename)\n\n    try:\n        os.makedirs(dirname)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n    with open(filename, \"w\") as f:\n        f.write(content)\n\n\n# only use this file to contral the version\n__version__ = \"3.0.0b3.post\"\nif os.getenv(PADDLENLP_STABLE_VERSION):\n    __version__ = __version__.replace(\".post\", \"\")\nelse:\n    formatted_date = datetime.now().date().strftime(\"%Y%m%d\")\n    __version__ = __version__.replace(\".post\", \".post{}\".format(formatted_date))\n\n\n# write the version information for the develop version\ndef append_version_py(filename=\"paddlenlp/__init__.py\"):\n    assert os.path.exists(filename), f\"{filename} does not exist!\"\n\n    with open(filename, \"r\") as file:\n        file_content = file.read()\n\n    pattern = r\"^# \\[VERSION_INFO\\].*$\"\n    modified_content = re.sub(pattern, f'\\n__version__ = \"{__version__}\"\\n\\n', file_content, flags=re.MULTILINE)\n    with open(filename, \"w\") as file:\n        file.write(modified_content)\n\n\nappend_version_py(filename=\"paddlenlp/__init__.py\")\n\nextras = {}\nREQUIRED_PACKAGES = read_requirements_file(\"requirements.txt\")\nextras[\"tests\"] = read_requirements_file(\"tests/requirements.txt\")\nextras[\"docs\"] = read_requirements_file(\"docs/requirements.txt\")\nextras[\"autonlp\"] = read_requirements_file(\"paddlenlp/experimental/autonlp/requirements.txt\")\nextras[\"dev\"] = extras[\"tests\"] + extras[\"docs\"] + extras[\"autonlp\"]\n\n\ndef read(*names, **kwargs):\n    with io.open(os.path.join(os.path.dirname(__file__), *names), encoding=kwargs.get(\"encoding\", \"utf8\")) as fp:\n        return fp.read()\n\n\ndef get_package_data_files(package, data, package_dir=None):\n    \"\"\"\n    Helps to list all specified files in package including files in directories\n    since `package_data` ignores directories.\n    \"\"\"\n    if package_dir is None:\n        package_dir = os.path.join(*package.split(\".\"))\n    all_files = []\n    for f in data:\n        path = os.path.join(package_dir, f)\n        if os.path.isfile(path):\n            all_files.append(f)\n            continue\n        for root, _dirs, files in os.walk(path, followlinks=True):\n            root = os.path.relpath(root, package_dir)\n            for file in files:\n                file = os.path.join(root, file)\n                if file not in all_files:\n                    all_files.append(file)\n    return all_files\n\n\nif commit != \"unknown\":\n    write_version_py(filename=\"paddlenlp/version/__init__.py\")\n\ntry:\n    setuptools.setup(\n        name=\"paddlenlp\",\n        version=__version__,\n        author=\"PaddleNLP Team\",\n        author_email=\"paddlenlp@baidu.com\",\n        description=\"Easy-to-use and powerful NLP library with Awesome model zoo, supporting wide-range of NLP tasks from research to industrial applications, including Neural Search, Question Answering, Information Extraction and Sentiment Analysis end-to-end system.\",\n        long_description=read(\"README_en.md\"),\n        long_description_content_type=\"text/markdown\",\n        url=\"https://github.com/PaddlePaddle/PaddleNLP\",\n        license_files=(\"LICENSE\",),\n        packages=setuptools.find_packages(\n            where=\".\",\n            exclude=(\"examples*\", \"tests*\", \"applications*\", \"fast_generation*\", \"model_zoo*\"),\n        ),\n        package_data={\n            \"paddlenlp.ops\": get_package_data_files(\n                \"paddlenlp.ops\", [\"CMakeLists.txt\", \"README.md\", \"cmake\", \"fast_transformer\", \"patches\", \"optimizer\"]\n            ),\n            \"paddlenlp.transformers.layoutxlm\": get_package_data_files(\n                \"paddlenlp.transformers.layoutxlm\", [\"visual_backbone.yaml\"]\n            ),\n            \"paddlenlp.experimental\": get_package_data_files(\"paddlenlp.experimental\", [\"transformers\"]),\n        },\n        setup_requires=[\"cython\", \"numpy\"],\n        install_requires=REQUIRED_PACKAGES,\n        entry_points={\"console_scripts\": [\"paddlenlp = paddlenlp.cli:main\"]},\n        extras_require=extras,\n        python_requires=\">=3.8\",\n        classifiers=[\n            \"Programming Language :: Python :: 3\",\n            \"Programming Language :: Python :: 3.8\",\n            \"Programming Language :: Python :: 3.9\",\n            \"Programming Language :: Python :: 3.10\",\n            \"License :: OSI Approved :: Apache Software License\",\n            \"Operating System :: OS Independent\",\n        ],\n        license=\"Apache 2.0\",\n    )\nexcept Exception as e:\n    git_checkout(paddlenlp_dir, \"paddlenlp/version/__init__.py\") if commit != \"unknown\" else None\n    git_checkout(paddlenlp_dir, \"paddlenlp/__init__.py\") if commit != \"unknown\" else None\n    raise e\n\ngit_checkout(paddlenlp_dir, \"paddlenlp/version/__init__.py\") if commit != \"unknown\" else None\ngit_checkout(paddlenlp_dir, \"paddlenlp/__init__.py\") if commit != \"unknown\" else None\n"
        },
        {
          "name": "slm",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}