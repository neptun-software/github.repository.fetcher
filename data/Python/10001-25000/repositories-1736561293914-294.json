{
  "metadata": {
    "timestamp": 1736561293914,
    "page": 294,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PaddlePaddle/PaddleNLP",
      "stars": 12283,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.8388671875,
          "content": "# This file is used by clang-format to autoformat paddle source code\n#\n# The clang-format is part of llvm toolchain.\n# It need to install llvm and clang to format source code style.\n#\n# The basic usage is,\n#   clang-format -i -style=file PATH/TO/SOURCE/CODE\n#\n# The -style=file implicit use \".clang-format\" file located in one of\n# parent directory.\n# The -i means inplace change.\n#\n# The document of clang-format is\n#   http://clang.llvm.org/docs/ClangFormat.html\n#   http://clang.llvm.org/docs/ClangFormatStyleOptions.html\n---\nLanguage:        Cpp\nBasedOnStyle:  Google\nIndentWidth:     2\nTabWidth:        2\nContinuationIndentWidth: 4\nMaxEmptyLinesToKeep: 2\nAccessModifierOffset: -2  # The private/protected/public has no indent in class\nStandard:  Cpp11\nAllowAllParametersOfDeclarationOnNextLine: true\nBinPackParameters: false\nBinPackArguments: false\n...\n\n"
        },
        {
          "name": ".clang_format.hook",
          "type": "blob",
          "size": 0.3525390625,
          "content": "#!/usr/bin/env bash\nset -e\n\nreadonly VERSION=\"3.8\"\n\nversion=$(clang-format -version)\n\nif ! [[ $version == *\"$VERSION\"* ]]; then\n    echo \"clang-format version check failed.\"\n    echo \"a version contains '$VERSION' is needed, but get '$version'\"\n    echo \"you can install the right version, and make an soft-link to '\\$PATH' env\"\n    exit -1\nfi\n\nclang-format $@\n"
        },
        {
          "name": ".copyright.hook",
          "type": "blob",
          "size": 4.1806640625,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom __future__ import absolute_import\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nimport argparse\nimport io\nimport re\nimport sys\nimport os\nimport datetime\n\nCOPYRIGHT = '''Copyright (c) 2022 PaddlePaddle Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.'''\n\ndef _generate_copyright(comment_mark):\n    copyright=COPYRIGHT.split(os.linesep)\n    header = copyright[0].rstrip()\n\n    p = re.search('(\\d{4})', header).group(0)\n    now = datetime.datetime.now()\n\n    header = header.replace(p,str(now.year))\n\n    ans=[comment_mark + \" \" + header + os.linesep]\n    for idx, line in enumerate(copyright[1:]):\n        ans.append(comment_mark + \" \" + line.rstrip() + os.linesep)\n\n    return ans\n\ndef _get_comment_mark(path):\n    lang_type=re.compile(r\"\\.(py|sh)$\")\n    if lang_type.search(path) is not None:\n        return \"#\"\n\n    lang_type=re.compile(r\"\\.(h|c|hpp|cc|cpp|cu|go|cuh|proto)$\")\n    if lang_type.search(path) is not None:\n        return \"//\"\n\n    return None\n\n\nRE_ENCODE = re.compile(r\"^[ \\t\\v]*#.*?coding[:=]\", re.IGNORECASE)\nRE_COPYRIGHT = re.compile(r\".*Copyright( \\(c\\))* \\d{4}\", re.IGNORECASE)\nRE_SHEBANG = re.compile(r\"^[ \\t\\v]*#[ \\t]?\\!\")\n\ndef _check_copyright(path):\n    head=[]\n    try:\n        with open(path, encoding=\"utf-8\") as f:\n            head = [next(f) for x in range(4)]\n    except StopIteration:\n        pass\n\n    for idx, line in enumerate(head):\n        if RE_COPYRIGHT.search(line) is not None:\n            return True\n\n    return False\n\ndef generate_copyright(path, comment_mark):\n    original_contents = io.open(path, encoding=\"utf-8\").readlines()\n    head = original_contents[0:4]\n\n    insert_line_no=0\n    for i, line in enumerate(head):\n        if RE_ENCODE.search(line) or RE_SHEBANG.search(line):\n            insert_line_no=i+1\n\n    copyright = _generate_copyright(comment_mark)\n    if insert_line_no == 0:\n        new_contents = copyright\n        if len(original_contents) > 0 and len(original_contents[0].strip()) != 0:\n            new_contents.append(os.linesep)\n        new_contents.extend(original_contents)\n    else:\n        new_contents=original_contents[0:insert_line_no]\n        new_contents.append(os.linesep)\n        new_contents.extend(copyright)\n        if len(original_contents) > insert_line_no and len(original_contents[insert_line_no].strip()) != 0:\n            new_contents.append(os.linesep)\n        new_contents.extend(original_contents[insert_line_no:])\n    new_contents=\"\".join(new_contents)\n\n    with io.open(path, 'w') as output_file:\n        output_file.write(new_contents)\n\n\n\ndef main(argv=None):\n    parser = argparse.ArgumentParser(\n        description='Checker for copyright declaration.')\n    parser.add_argument('filenames', nargs='*', help='Filenames to check')\n    args = parser.parse_args(argv)\n\n    retv = 0\n    for path in args.filenames:\n        comment_mark = _get_comment_mark(path)\n        if comment_mark is None:\n            print(\"warning:Unsupported file\", path, file=sys.stderr)\n            continue\n\n        if _check_copyright(path):\n            continue\n\n        generate_copyright(path, comment_mark)\n\n\nif __name__ == '__main__':\n    exit(main())\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.1796875,
          "content": "[flake8]\nignore = E203, E402, E501, E731, E741, W503, W605, E722\nmax-line-length = 119\n\n# E402: module level import not at top of file\nper-file-ignores =\n    __init__.py:F401,F403,E402"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.541015625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\nbuild*\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n*.doctree\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pycharm\n.DS_Store\n.idea/\nFETCH_HEAD\n\n# vscode\n.vscode\n./ppdiffusers/ppdiffusers/version.py\n\n# third party\ncsrc/third_party/\ndataset/\noutput/\n\n# gen codes\nautogen/\n\n# cutlass kernel\n!csrc/gpu/cutlass_kernels/gemm/collective/builders"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.2392578125,
          "content": "[submodule \"csrc/third_party/cutlass\"]\n\tpath = csrc/third_party/cutlass\n\turl = https://github.com/NVIDIA/cutlass.git\n[submodule \"csrc/third_party/nlohmann_json\"]\n\tpath = csrc/third_party/nlohmann_json\n\turl = https://github.com/nlohmann/json.git\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.7109375,
          "content": "exclude: 'slm/model_zoo/gpt-3;csrc/third_party'\nrepos:\n# For Python files\n-   repo: https://github.com/psf/black.git\n    rev: 22.8.0\n    hooks:\n    -   id: black\n        files: \\.(py|pyi)$\n        additional_dependencies: [toml]\n-   repo: https://github.com/PyCQA/isort\n    rev: 5.11.5\n    hooks:\n    -   id: isort\n-   repo: https://github.com/PyCQA/flake8\n    rev: 4.0.1\n    hooks:\n    -   id: flake8\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.1.0\n    hooks:\n    -   id: check-merge-conflict\n    -   id: check-symlinks\n    -   id: detect-private-key\n        files: (?!.*paddle)^.*$\n    -   id: end-of-file-fixer\n        files: \\.md$\n    -   id: trailing-whitespace\n        files: \\.md$\n-   repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.1.14\n    hooks:\n    -   id: forbid-crlf\n        files: \\.md$\n    -   id: remove-crlf\n        files: \\.md$\n    -   id: forbid-tabs\n        files: \\.md$\n    -   id: remove-tabs\n        files: \\.md$\n-   repo: local\n    hooks:\n    -   id: copyright_checker\n        name: copyright_checker\n        entry: python .copyright.hook\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto|xpu|kps|py|sh)$\n# For Markdown files\n-   repo: local\n    hooks:\n    -   id: add-spaces-between-chinese-and-english\n        name: Add spaces between Chinese and English characters\n        entry: python scripts/codestyle/check_spaces.py\n        language: python\n        files: \\.(md|markdown)$\n        pass_filenames: true\n# For dead links\n-   repo: local\n    hooks:\n    -   id: check-dead-links\n        name: Check dead links\n        entry: python scripts/codestyle/check_dead_links.py\n        language: python\n        files: \\.(md|markdown|rst)$\n        pass_filenames: true\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.5693359375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\nbuild:\n  os: \"ubuntu-20.04\"\n  tools:\n    python: \"3.10\"\n\nsubmodules:\n  include: all\n  recursive: true\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n   configuration: docs/conf.py\n\n# Optionally build your docs in additional formats such as PDF\n#formats:\n#   - pdf\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.9853515625,
          "content": "**简体中文**🀄 | [English🌎](.github/CONTRIBUTING_en.md)\n\n# Contributing to PaddleNLP\n\n我们非常欢迎并希望您对`PaddleNLP`做出开源贡献。在您开始提交您的贡献之前，请先行签署[PaddlePaddle 贡献者许可协议](https://cla-assistant.io/PaddlePaddle/PaddleNLP)。\n本文接下来将介绍我们的开发与贡献流程：\n\n## 贡献方式\n\n我们欢迎不同的向`PaddleNLP`做出贡献的方式，例如：\n\n- 修复已知的 Issue\n- 提交新的 Issue，例如提出功能需求或者 bug 报告\n- 实现新的模型结构\n\n如果您不知道从哪里开始，请查看 Issues 板块中的`Good First Issue`标签。它为您提供一个对初学者友好的已知 Issue 列表，可以降低贡献的门槛，帮助您开始为开源做出贡献。您只需在您想处理的 Issue 中告知我们您想负责此 Issue 即可。\n\n## 开发流程\n\nPaddleNLP 使用 [Git 分支模型](http://nvie.com/posts/a-successful-git-branching-model/)。对于常见的开源贡献，我们有以下的贡献流程：\n\n### 1. Fork\n\n   因为 PaddleNLP 的开发社区一直在发展，如果每位贡献者都直接向官方 Repo 提交 commit 将会难以管理。因此，请从您的分支中提交 Pull Requests。建议您通过 GitHub 的[“Fork”按钮](https://help.github.com/articles/fork-a-repo/)来创建您的 Fork 分支。\n\n### 2. Clone\n\n   请运行一下命令将您的分支 clone 到本地\n\n   ```bash\n   git clone https://github.com/<your-github-account>/PaddleNLP\n   cd PaddleNLP\n   ```\n\n### 3. 创建本地开发分支\n\n   对于添加新功能或修复错误等日常工作，请在开发前创建您的本地开发分支：\n\n   ```bash\n   git checkout -b my-cool-feature\n   ```\n\n### 4. 配置开发环境\n\n   在开始编码之前，您需要设置开发环境。我们强烈建议您在虚拟环境中进行所有开发，例如[venv](https://docs.python.org/3/library/venv.html)或[conda](https://docs.conda.io/en/latest/)。\n   请您设置并激活虚拟环境后，运行以下命令：\n\n   ```bash\n   make install\n   ```\n\n   这将设置 `PaddleNLP` 的所有依赖以及 [`pre-commit`](http://pre-commit.com/) 工具。\n\n   如果您需要开发 `examples` 或 `applications` 模块并加载 `PaddleNLP`，请确保以可编辑模式（`-e`）安装 `PaddleNLP`。\n   如果在虚拟环境中已经安装 `PaddleNLP` ，请使用 `pip uninstall paddlenlp` 将其删除，然后以可编辑模式重新安装它\n   `pip install -e .`\n\n### 5. 开发\n\n   当您开发时，请确保您新增的代码会被单元测试所覆盖。我们所有的单元测试都可以在 `tests` 目录下找到。\n   您可以修改现有单元测试以覆盖新功能，也可以从头开始创建新测试。\n   当您完成代码时，您应该确保相关的单元测试可以通过。您可以像这样运行受更改影响的测试：\n\n   ```bash\n   pytest tests/<test_to_run>.py\n   ```\n\n### 6. Commit\n\n   我们使用 [`pre-commit`](http://pre-commit.com/)工具（包括[black](https://black.readthedocs.io/en/stable/)、[isort](https:/ /pycqa.github.io/isort/) 和\n   [flake8](https://flake8.pycqa.org/en/latest/)）来检查每次提交中的代码和文档的风格。当你运行 `git commit` 时，你会看到\n   类似于以下内容：\n\n   ```text\n    ➜  (my-virtual-env) git commit -m \"commiting my cool feature\"\n    black....................................................................Passed\n    isort....................................................................Passed\n    flake8...................................................................Passed\n    check for merge conflicts................................................Passed\n    check for broken symlinks............................(no files to check)Skipped\n    detect private key.......................................................Passed\n    fix end of files.....................................(no files to check)Skipped\n    trim trailing whitespace.............................(no files to check)Skipped\n    CRLF end-lines checker...............................(no files to check)Skipped\n    CRLF end-lines remover...............................(no files to check)Skipped\n    No-tabs checker......................................(no files to check)Skipped\n    Tabs remover.........................................(no files to check)Skipped\n    copyright_checker........................................................Passed\n   ```\n\n   但大多数时候事情并没有那么顺利。当您的代码或文档不符合标准时，`pre-commit` 检查将失败。\n\n   ```text\n    ➜  (my-virtual-env) git commit -m \"commiting my cool feature\"\n    black....................................................................Passed\n    isort....................................................................Failed\n    - hook id: isort\n    - files were modified by this hook\n\n    Fixing examples/information_extraction/waybill_ie/run_ernie_crf.py\n\n    flake8...................................................................Passed\n    check for merge conflicts................................................Passed\n    check for broken symlinks............................(no files to check)Skipped\n    detect private key.......................................................Passed\n    fix end of files.....................................(no files to check)Skipped\n    trim trailing whitespace.............................(no files to check)Skipped\n    CRLF end-lines checker...............................(no files to check)Skipped\n    CRLF end-lines remover...............................(no files to check)Skipped\n    No-tabs checker......................................(no files to check)Skipped\n    Tabs remover.........................................(no files to check)Skipped\n    copyright_checker........................................................Passed\n   ```\n\n   我们的工具将自动修复大部分样式错误，但是有些错误需要手动解决。幸运的是，错误信息一般通俗易懂，很容易修复。\n   解决错误后，您可以再次运行 `git add <files>` 和 `git commit`，这将再次触发 pre-commit 。\n   一旦 pre-commit 检查通过，您就可以推送代码了。\n\n   [Google](https://google.com/) 或 [StackOverflow](https://stackoverflow.com/) 是帮助您了解代码风格错误的好工具。\n   如果您仍然无法弄清楚，请不要担心。您可以使用 `git commit -m \"style error\" --no-verify` 提交，我们很乐意在您创建 Pull Request 后帮助您。\n\n### 7. git pull 与代码冲突\n\n   有经验的 Git 用户经常从官方 Repo 中 git pull。因为这样子他们会及早注意到与其他人的代码冲突，并且让代码冲突更容易解决\n\n   ```bash\n   git remote add upstream https://github.com/PaddlePaddle/PaddleNLP\n   git pull upstream develop\n   ```\n\n### 8. git push 与提交 Pull Request\n\n   您可以将您的本地开发分支中的工作 push 到您的 fork 的分支中：\n\n   ```bash\n   git push origin my-cool-stuff\n   ```\n\n   git push 之后，您可以提交 Pull Request，请求[官方 repo](https://github.com/PaddlePaddle/PaddleNLP) 采纳您的开发工作。请您依照[这些步骤](https://help.github.com/articles/creating-a-pull-request/)创建 Pull Request。\n\n### 9. 删除已经合入的本地和远程分支\n\n   为了保持您本地的工作区和 fork 分支的干净整洁，建议您在 Pull Request 合入之后删除本地的残余分支：\n\n   ```bash\n   git push origin my-cool-stuff\n   git checkout develop\n   git pull upstream develop\n   git branch -d my-cool-stuff\n   ```\n\n## 代码 Review\n\n- 在您的 Pull Request 能够顺利通过本地测试以及 CI 的情况下，您可以在 Pull Request 中 @ 相关的 Reviewer，提醒他们尽快对您的 Pull Request 进行 Review。\n\n- 请处理 Reviewer 的每一条评论。如果您已按照评论修改，请回复“完成”；否则，可以在评论下展开讨论。\n\n- 如果您不希望您的 Reviewer 被电子邮件通知淹没，您可以[批量回复](https://help.github.com/articles/reviewing-proposed-changes-in-a-pull-request/)。\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.169921875,
          "content": "Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright (c) 2016 PaddlePaddle Authors. All Rights Reserved.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.98828125,
          "content": "# Makefile for PaddleNLP\n#\n# \tGitHb: https://github.com/PaddlePaddle/PaddleNLP\n# \tAuthor: Paddle Team https://github.com/PaddlePaddle\n#\n\n.PHONY: all\nall : lint test\ncheck_dirs := applications examples model_zoo paddlenlp pipelines ppdiffusers scripts tests \n# # # # # # # # # # # # # # # Format Block # # # # # # # # # # # # # # # \n\nformat:\n\tpre-commit run isort\n\tpre-commit run black\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n# # # # # # # # # # # # # # # Lint Block # # # # # # # # # # # # # # # \n\n.PHONY: lint\nlint:\n\t$(eval modified_py_files := $(shell python scripts/get_modified_files.py $(check_dirs)))\n\t@if test -n \"$(modified_py_files)\"; then \\\n\t\techo ${modified_py_files}; \\\n\t\tpre-commit run --files ${modified_py_files}; \\\n\telse \\\n\t\techo \"No library .py files were modified\"; \\\n\tfi\t\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n# # # # # # # # # # # # # # # Test Block # # # # # # # # # # # # # # # \n\n.PHONY: test\ntest: unit-test\n\nunit-test:\n\tPYTHONPATH=$(shell pwd) pytest -v \\\n\t\t-n auto \\\n\t\t--retries 1 --retry-delay 1 \\\n\t\t--durations 20 \\\n\t\t--cov paddlenlp \\\n\t\t--cov-report xml:coverage.xml\n\n# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n\n.PHONY: install\ninstall:\n\tpip install --pre paddlepaddle -i https://www.paddlepaddle.org.cn/packages/nightly/cpu/\n\tpip install -r requirements-dev.txt\n\tpip install -r requirements.txt\n\tpip install -r paddlenlp/experimental/autonlp/requirements.txt\n\tpre-commit install\n\n\n.PHONY: deploy-ppdiffusers\ndeploy-ppdiffusers:\n\tcd ppdiffusers && make install && make\n\n.PHONY: deploy-paddle-pipelines\ndeploy-paddle-pipelines:\n\tcd pipelines && make install && make\n\n.PHONY: deploy-paddlenlp\ndeploy-paddlenlp:\n\t# install related package\n\tmake install\n\t# build\n\tpython3 setup.py sdist bdist_wheel\n\t# upload\n\ttwine upload --skip-existing dist/*\n\n.PHONY: regression-all\nrelease: \n\tbash ./scripts/regression/run_release.sh 0 0,1 all\n\n.PHONY: regression-key\nkey: \n\tbash ./scripts/regression/run_release.sh 0 0,1 p0\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 31.4619140625,
          "content": "**简体中文**🀄 | [English🌎](./README_en.md)\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png\" align=\"middle\"  width=\"500\" />\n</p>\n\n------------------------------------------------------------------------------------------\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af\"></a>\n    <a href=\"https://pypi.org/project/paddlenlp/\"><img src=\"https://img.shields.io/pypi/dm/paddlenlp?color=9cf\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf\"></a>\n</p>\n\n<h4 align=\"center\">\n  <a href=#特性> 特性 </a> |\n  <a href=#模型支持> 模型支持 </a> |\n  <a href=#安装> 安装 </a> |\n  <a href=#快速开始> 快速开始 </a> |\n  <a href=#社区交流> 社区交流 </a>\n</h4>\n\n**PaddleNLP**是一款基于飞桨深度学习框架的大语言模型(LLM)开发套件，支持在多种硬件上进行高效的大模型训练、无损压缩以及高性能推理。PaddleNLP 具备**简单易用**和**性能极致**的特点，致力于助力开发者实现高效的大模型产业级应用。\n\n<a href=\"https://trendshift.io/repositories/2246\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2246\" alt=\"PaddlePaddle%2FPaddleNLP | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n## News 📢\n* **2024.12.16 [PaddleNLP v3.0 Beta3](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta3)**：大模型功能全新升级，新增了 Llama-3.2、DeepSeekV2模型，升级了 TokenizerFast，快速分词，重构了 SFTTrainer，一键开启 SFT 训练。此外，PaddleNLP 还支持了优化器状态的卸载和重载功能，实现了精细化的重新计算，训练性能提升7%。在 Unified Checkpoint 方面，进一步优化了异步保存逻辑，新增 Checkpoint 压缩功能，可节省78.5%存储空间。\n最后，在大模型推理方面，升级 Append Attention，支持了 FP8量化，支持投机解码。\n\n* **2024.12.13 📚《飞桨大模型套件 Unified Checkpoint 技术》**，加速模型存储95%，节省空间78%。支持全分布式策略调整自适应转换，提升模型训练的灵活性与可扩展性。训练-压缩-推理统一存储协议，无需手动转换提升全流程体验。Checkpoint 无损压缩结合异步保存，实现秒级存储并降低模型存储成本。适用于智能制造、指挥交通、医疗健康、金融服务等产业实际场景。12月24日（周二）19：00直播为您详细解读该技术如何优化大模型训练流程。报名链接：https://www.wjx.top/vm/huZkHn9.aspx?udsid=787976\n\n* **2024.11.28 📚《FlashRAG-Paddle | 基于 PaddleNLP 的高效开发与评测 RAG 框架》**，为文本更快更好构建准确嵌入表示、加速推理生成速度。PaddleNLP 支持超大 Batch 嵌入表示学习与多硬件高性能推理，涵盖 INT8/INT4量化技术及多种高效注意力机制优化与 TensorCore 深度优化。内置全环节算子融合技术，使得 FlashRAG 推理性能相比 transformers 动态图提升70%以上，结合检索增强知识输出结果更加准确，带来敏捷高效的使用体验。直播时间：12月3日（周二）19：00。报名链接：https://www.wjx.top/vm/eaBa1vA.aspx?udsid=682361\n\n\n\n<details><summary> <b>点击展开</b> </summary><div>\n\n* **2024.08.08 📚《飞桨产业级大语言模型开发利器 PaddleNLP 3.0 重磅发布》**，训压推全流程贯通，主流模型全覆盖。大模型自动并行，千亿模型训推全流程开箱即用。提供产业级高性能精调与对齐解决方案，压缩推理领先，多硬件适配。覆盖产业级智能助手、内容创作、知识问答、关键信息抽取等应用场景。直播时间：8月22日（周四）19：00。报名链接：https://www.wjx.top/vm/Y2f7FFY.aspx?udsid=143844\n\n* **2024.06.27 [PaddleNLP v3.0 Beta](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta0)**：拥抱大模型，体验全升级。统一大模型套件，实现国产计算芯片全流程接入；全面支持飞桨4D 并行配置、高效精调策略、高效对齐算法、高性能推理等大模型产业级应用流程；自研极致收敛的 RsLoRA+算法、自动扩缩容存储机制 Unified Checkpoint 和通用化支持的 FastFFN、FusedQKV 助力大模型训推；主流模型持续支持更新，提供高效解决方案。\n\n* **2024.04.24 [PaddleNLP v2.8](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.8.0)**：自研极致收敛的 RsLoRA+算法，大幅提升 PEFT 训练收敛速度以及训练效果；引入高性能生成加速到 RLHF PPO 算法，打破 PPO 训练中生成速度瓶颈，PPO 训练性能大幅领先。通用化支持 FastFFN、FusedQKV 等多个大模型训练性能优化方式，大模型训练更快、更稳定。\n</div></details>\n\n## 特性\n\n### <a href=#多硬件训推一体> 🔧 多硬件训推一体 </a>\n\n支持英伟达 GPU、昆仑 XPU、昇腾 NPU、燧原 GCU 和海光 DCU 等多个硬件的大模型和自然语言理解模型训练和推理，套件接口支持硬件快速切换，大幅降低硬件切换研发成本。\n当前支持的自然语言理解模型：[多硬件自然语言理解模型列表](./docs/model_zoo/model_list_multy_device.md)\n\n### <a href=#高效易用的预训练> 🚀 高效易用的预训练 </a>\n\n支持纯数据并行策略、分组参数切片的数据并行策略、张量模型并行策略和流水线模型并行策略的4D 高性能训练，Trainer 支持分布式策略配置化，降低复杂分布式组合带来的使用成本；\n[Unified Checkpoint 大模型存储工具](./llm/docs/unified_checkpoint.md)可以使得训练断点支持机器资源动态扩缩容恢复。此外，异步保存，模型存储可加速95%，Checkpoint 压缩，可节省78.5%存储空间。\n\n### <a href=#高效精调> 🤗 高效精调 </a>\n\n精调算法深度结合零填充数据流和 [FlashMask](./llm/docs/flashmask.md) 高性能算子，降低训练无效数据填充和计算，大幅提升精调训练吞吐。\n\n### <a href=#无损压缩和高性能推理> 🎛️ 无损压缩和高性能推理 </a>\n\n大模型套件高性能推理模块内置动态插入和全环节算子融合策略，极大加快并行推理速度。底层实现细节封装化，实现开箱即用的高性能并行推理能力。\n\n------------------------------------------------------------------------------------------\n\n## 模型支持\n\n* 模型参数已支持 LLaMA 系列、Baichuan 系列、Bloom 系列、ChatGLM 系列、Gemma 系列、Mistral 系列、OPT 系列和 Qwen 系列，详细列表👉【LLM】模型参数支持列表如下：\n\n|                                          模型系列                                           | 模型名称                                                                                                                                                                                                                                                                                                                                                                                      |\n|:-------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|      [LLaMA](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)       | facebook/llama-7b, facebook/llama-13b, facebook/llama-30b, facebook/llama-65b                                                                                                                                                                                                                                                                                                                 |\n|      [Llama2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Llama-2-7b, meta-llama/Llama-2-7b-chat, meta-llama/Llama-2-13b, meta-llama/Llama-2-13b-chat, meta-llama/Llama-2-70b, meta-llama/Llama-2-70b-chat                                                                                                                                                                                                                                   |\n|      [Llama3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Meta-Llama-3-8B, meta-llama/Meta-Llama-3-8B-Instruct, meta-llama/Meta-Llama-3-70B, meta-llama/Meta-Llama-3-70B-Instruct                                                                                                                                                                                                                                                            |\n|     [Llama3.1](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Meta-Llama-3.1-8B, meta-llama/Meta-Llama-3.1-8B-Instruct, meta-llama/Meta-Llama-3.1-70B, meta-llama/Meta-Llama-3.1-70B-Instruct, meta-llama/Meta-Llama-3.1-405B, meta-llama/Meta-Llama-3.1-405B-Instruct, meta-llama/Llama-Guard-3-8B                                                                                                                                              |\n|     [Llama3.2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.2-1B, meta-llama/Llama-3.2-1B-Instruct, meta-llama/Llama-3.2-3B, meta-llama/Llama-3.2-3B-Instruct, meta-llama/Llama-Guard-3-1B                                                                                                                                                                                                                                             |\n|     [Llama3.3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.3-70B-Instruct                                                                                                                                                                                                                                                                                                                                                             |\n|   [Baichuan](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)    | baichuan-inc/Baichuan-7B, baichuan-inc/Baichuan-13B-Base, baichuan-inc/Baichuan-13B-Chat                                                                                                                                                                                                                                                                                                      |\n|   [Baichuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)   | baichuan-inc/Baichuan2-7B-Base, baichuan-inc/Baichuan2-7B-Chat, baichuan-inc/Baichuan2-13B-Base, baichuan-inc/Baichuan2-13B-Chat                                                                                                                                                                                                                                                              |\n|      [Bloom](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/bloom)       | bigscience/bloom-560m, bigscience/bloom-560m-bf16, bigscience/bloom-1b1, bigscience/bloom-3b, bigscience/bloom-7b1, bigscience/bloomz-560m, bigscience/bloomz-1b1, bigscience/bloomz-3b, bigscience/bloomz-7b1-mt, bigscience/bloomz-7b1-p3, bigscience/bloomz-7b1, bellegroup/belle-7b-2m                                                                                                    |\n|    [ChatGLM](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm/)    | THUDM/chatglm-6b, THUDM/chatglm-6b-v1.1                                                                                                                                                                                                                                                                                                                                                       |\n|   [ChatGLM2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm2-6b                                                                                                                                                                                                                                                                                                                                                                             |\n|   [ChatGLM3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm3-6b                                                                                                                                                                                                                                                                                                                                                                             |\n| [DeepSeekV2](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V2, deepseek-ai/DeepSeek-V2-Chat, deepseek-ai/DeepSeek-V2-Lite, deepseek-ai/DeepSeek-V2-Lite-Chat, deepseek-ai/DeepSeek-Coder-V2-Base, deepseek-ai/DeepSeek-Coder-V2-Instruct, deepseek-ai/DeepSeek-Coder-V2-Lite-Base, deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct                                                                                                      |\n| [DeepSeekV3](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V3, deepseek-ai/DeepSeek-V3-Base                                                                                                                                                                                                                                                                                                                                         |\n|      [Gemma](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/gemma)       | google/gemma-7b, google/gemma-7b-it, google/gemma-2b, google/gemma-2b-it                                                                                                                                                                                                                                                                                                                      |\n|    [Mistral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mistral)     | mistralai/Mistral-7B-Instruct-v0.3, mistralai/Mistral-7B-v0.1                                                                                                                                                                                                                                                                                                                                 |\n|    [Mixtral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mixtral)     | mistralai/Mixtral-8x7B-Instruct-v0.1                                                                                                                                                                                                                                                                                                                                                          |\n|        [OPT](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/opt)         | facebook/opt-125m, facebook/opt-350m, facebook/opt-1.3b, facebook/opt-2.7b, facebook/opt-6.7b, facebook/opt-13b, facebook/opt-30b, facebook/opt-66b, facebook/opt-iml-1.3b, opt-iml-max-1.3b                                                                                                                                                                                                  |\n|       [Qwen](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | qwen/qwen-7b, qwen/qwen-7b-chat, qwen/qwen-14b, qwen/qwen-14b-chat, qwen/qwen-72b, qwen/qwen-72b-chat,                                                                                                                                                                                                                                                                                        |\n|     [Qwen1.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen1.5-0.5B, Qwen/Qwen1.5-0.5B-Chat, Qwen/Qwen1.5-1.8B, Qwen/Qwen1.5-1.8B-Chat, Qwen/Qwen1.5-4B, Qwen/Qwen1.5-4B-Chat, Qwen/Qwen1.5-7B, Qwen/Qwen1.5-7B-Chat, Qwen/Qwen1.5-14B, Qwen/Qwen1.5-14B-Chat, Qwen/Qwen1.5-32B, Qwen/Qwen1.5-32B-Chat, Qwen/Qwen1.5-72B, Qwen/Qwen1.5-72B-Chat, Qwen/Qwen1.5-110B, Qwen/Qwen1.5-110B-Chat, Qwen/Qwen1.5-MoE-A2.7B, Qwen/Qwen1.5-MoE-A2.7B-Chat |\n|      [Qwen2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | Qwen/Qwen2-0.5B, Qwen/Qwen2-0.5B-Instruct, Qwen/Qwen2-1.5B, Qwen/Qwen2-1.5B-Instruct, Qwen/Qwen2-7B, Qwen/Qwen2-7B-Instruct, Qwen/Qwen2-72B, Qwen/Qwen2-72B-Instruct, Qwen/Qwen2-57B-A14B, Qwen/Qwen2-57B-A14B-Instruct                                                                                                                                                                       |\n|    [Qwen2-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)    | Qwen/Qwen2-Math-1.5B, Qwen/Qwen2-Math-1.5B-Instruct, Qwen/Qwen2-Math-7B, Qwen/Qwen2-Math-7B-Instruct, Qwen/Qwen2-Math-72B, Qwen/Qwen2-Math-72B-Instruct, Qwen/Qwen2-Math-RM-72B                                                                                                                                                                                                               |\n|     [Qwen2.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen2.5-0.5B, Qwen/Qwen2.5-0.5B-Instruct, Qwen/Qwen2.5-1.5B, Qwen/Qwen2.5-1.5B-Instruct, Qwen/Qwen2.5-3B, Qwen/Qwen2.5-3B-Instruct, Qwen/Qwen2.5-7B, Qwen/Qwen2.5-7B-Instruct, Qwen/Qwen2.5-14B, Qwen/Qwen2.5-14B-Instruct, Qwen/Qwen2.5-32B, Qwen/Qwen2.5-32B-Instruct, Qwen/Qwen2.5-72B, Qwen/Qwen2.5-72B-Instruct                                                                     |\n|   [Qwen2.5-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Math-1.5B, Qwen/Qwen2.5-Math-1.5B-Instruct, Qwen/Qwen2.5-Math-7B, Qwen/Qwen2.5-Math-7B-Instruct, Qwen/Qwen2.5-Math-72B, Qwen/Qwen2.5-Math-72B-Instruct, Qwen/Qwen2.5-Math-RM-72B                                                                                                                                                                                                 |\n|  [Qwen2.5-Coder](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Coder-1.5B, Qwen/Qwen2.5-Coder-1.5B-Instruct, Qwen/Qwen2.5-Coder-7B, Qwen/Qwen2.5-Coder-7B-Instruct                                                                                                                                                                                                                                                                              |\n|      [Yuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/yuan/)       | IEITYuan/Yuan2-2B, IEITYuan/Yuan2-51B, IEITYuan/Yuan2-102B                                                                                                                                                                                                                                                                                                                                    |\n\n* 4D 并行和算子优化已支持 LLaMA 系列、Baichuan 系列、Bloom 系列、ChatGLM 系列、Gemma 系列、Mistral 系列、OPT 系列和 Qwen 系列，【LLM】模型4D 并行和算子支持列表如下：\n\n\n| 模型名称/并行能力支持 | 数据并行 | 张量模型并行 |          | 参数分片并行 |        |        | 流水线并行 |\n|:---------------------:|:--------:|:------------:|:--------:|:------------:|:------:|:------:|:----------:|\n|                       |          |   基础能力   | 序列并行 |    stage1    | stage2 | stage3 |            |\n|         Llama         |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|         Qwen          |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|        Qwen1.5        |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|         Qwen2         |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|     Mixtral(moe)      |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     🚧     |\n|        Mistral        |    ✅     |      ✅       |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|       Baichuan        |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|       Baichuan2       |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|        ChatGLM        |    ✅     |      ✅       |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|       ChatGLM2        |    ✅     |      🚧      |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|       ChatGLM3        |    ✅     |      🚧      |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|         Bloom         |    ✅     |      ✅       |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|      GPT-2/GPT-3      |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|          OPT          |    ✅     |      ✅       |    🚧    |      ✅       |   ✅    |   ✅    |     🚧     |\n|         Gemma         |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     ✅      |\n|         Yuan2         |    ✅     |      ✅       |    ✅     |      ✅       |   ✅    |   ✅    |     🚧     |\n\n* 大模型预训练、精调（包含 SFT、PEFT 技术）、对齐、量化已支持 LLaMA 系列、Baichuan 系列、Bloom 系列、ChatGLM 系列、Mistral 系列、OPT 系列和 Qwen 系列，【LLM】模型预训练、精调、对齐、量化支持列表如下：\n\n\n| Model                                      | Pretrain | SFT | LoRA | FlashMask | Prefix Tuning | DPO/SimPO/ORPO/KTO | RLHF | Mergekit | Quantization |\n|--------------------------------------------|:--------:|:---:|:----:|:---------:|:-------------:|:------------------:|:----:|:--------:|:------------:|\n| [Llama](./llm/config/llama)                |    ✅     |  ✅  |  ✅   |     ✅     |       ✅       |         ✅          |  ✅   |    ✅     |      ✅       |\n| [Qwen](./llm/config/qwen)                  |    ✅     |  ✅  |  ✅   |     ✅     |       ✅       |         ✅          |  🚧  |    ✅     |      🚧      |\n| [Mixtral](./llm/config/mixtral)            |    ✅     |  ✅  |  ✅   |    🚧     |      🚧       |         ✅          |  🚧  |    ✅     |      🚧      |\n| [Mistral](./llm/config/mistral)            |    ✅     |  ✅  |  ✅   |    🚧     |       ✅       |         ✅          |  🚧  |    ✅     |      🚧      |\n| [Baichuan/Baichuan2](./llm/config/llama)   |    ✅     |  ✅  |  ✅   |     ✅     |       ✅       |         ✅          |  🚧  |    ✅     |      ✅       |\n| [ChatGLM-6B](./llm/config/chatglm)         |    ✅     |  ✅  |  ✅   |    🚧     |       ✅       |         🚧         |  🚧  |    ✅     |      ✅       |\n| [ChatGLM2/ChatGLM3](./llm/config/chatglm2) |    ✅     |  ✅  |  ✅   |    🚧     |       ✅       |         ✅          |  🚧  |    ✅     |      ✅       |\n| [Bloom](./llm/config/bloom)                |    ✅     |  ✅  |  ✅   |    🚧     |       ✅       |         🚧         |  🚧  |    ✅     |      ✅       |\n| [GPT-3](./llm/config/gpt-3)                |    ✅     |  ✅  |  🚧  |    🚧     |      🚧       |         🚧         |  🚧  |    ✅     |      🚧      |\n| [OPT](./llm/config/opt)                    |    ✅     |  ✅  |  ✅   |    🚧     |      🚧       |         🚧         |  🚧  |    ✅     |      🚧      |\n| [Gemma](./llm/config/gemma)                |    ✅     |  ✅  |  ✅   |    🚧     |      🚧       |         ✅          |  🚧  |    ✅     |      🚧      |\n| [Yuan](./llm/config/yuan)                  |    ✅     |  ✅  |  ✅   |    🚧     |      🚧       |         ✅          |  🚧  |    ✅     |      🚧      |\n* [大模型推理](./llm/docs/predict/inference.md)已支持 LLaMA 系列、Qwen 系列、Mistral 系列、ChatGLM 系列、Bloom 系列和 Baichuan 系列，支持 Weight Only INT8及 INT4推理，支持 WAC（权重、激活、Cache KV）进行 INT8、FP8量化的推理，【LLM】模型推理支持列表如下：\n\n|          模型名称/量化类型支持           | FP16/BF16 | WINT8 | WINT4 | INT8-A8W8 | FP8-A8W8 | INT8-A8W8C8 |\n|:----------------------------------------:|:---------:|:-----:|:-----:|:---------:|:--------:|:-----------:|\n|   [LLaMA](./llm/docs/predict/llama.md)   |     ✅     |   ✅   |   ✅   |     ✅     |    ✅     |      ✅      |\n|    [Qwen](./llm/docs/predict/qwen.md)    |     ✅     |   ✅   |   ✅   |     ✅     |    ✅     |      ✅      |\n|  [Qwen-Moe](./llm/docs/predict/qwen.md)  |     ✅     |   ✅   |   ✅   |    🚧     |    🚧    |     🚧      |\n| [Mixtral](./llm/docs/predict/mixtral.md) |     ✅     |   ✅   |   ✅   |    🚧     |    🚧    |     🚧      |\n|                 ChatGLM                  |     ✅     |   ✅   |   ✅   |    🚧     |    🚧    |     🚧      |\n|                  Bloom                   |     ✅     |   ✅   |   ✅   |    🚧     |    🚧    |     🚧      |\n|                 BaiChuan                 |     ✅     |   ✅   |   ✅   |     ✅     |    ✅     |     🚧      |\n\n## 安装\n\n### 环境依赖\n\n* python >= 3.8\n* paddlepaddle >= 3.0.0b0\n\n如果您尚未安装 PaddlePaddle，请参考 [飞桨官网](https://www.paddlepaddle.org.cn/) 进行安装。\n\n### pip 安装\n\n```shell\npip install --upgrade paddlenlp==3.0.0b3\n```\n\n或者可通过以下命令安装最新 develop 分支代码：\n\n```shell\npip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html\n```\n\n更多关于 PaddlePaddle 和 PaddleNLP 安装的详细教程请查看[Installation](./docs/get_started/installation.rst)。\n\n------------------------------------------------------------------------------------------\n\n## 快速开始\n\n### 大模型文本生成\n\nPaddleNLP 提供了方便易用的 Auto API，能够快速的加载模型和 Tokenizer。这里以使用 `Qwen/Qwen2-0.5B` 模型做文本生成为例：\n\n```python\n>>> from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n>>> model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", dtype=\"float16\")\n>>> input_features = tokenizer(\"你好！请自我介绍一下。\", return_tensors=\"pd\")\n>>> outputs = model.generate(**input_features, max_length=128)\n>>> print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True))\n['我是一个AI语言模型，我可以回答各种问题，包括但不限于：天气、新闻、历史、文化、科学、教育、娱乐等。请问您有什么需要了解的吗？']\n```\n\n### 大模型预训练\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # 如已clone或下载PaddleNLP可跳过\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\ncd .. # change folder to PaddleNLP/llm\n# 如需使用use_fused_rms_norm=true，需要前往slm/model_zoo/gpt-3/external_ops安装fused_ln\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_pretrain.py ./config/llama/pretrain_argument.json --use_fused_rms_norm false\n```\n\n### 大模型 SFT 精调\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # 如已clone或下载PaddleNLP可跳过\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_finetune.py ./config/llama/sft_argument.json\n```\n\n更多大模型全流程步骤，请参考[飞桨大模型套件](./llm)介绍。\n另外我们还提供了快速微调方式, 无需 clone 源代码：\n\n```python\nfrom paddlenlp.trl import SFTConfig, SFTTrainer\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ZHUI/alpaca_demo\", split=\"train\")\n\ntraining_args = SFTConfig(output_dir=\"Qwen/Qwen2.5-0.5B-SFT\", device=\"gpu\")\ntrainer = SFTTrainer(\n    args=training_args,\n    model=\"Qwen/Qwen2.5-0.5B\",\n    train_dataset=dataset,\n)\ntrainer.train()\n```\n\n更多 PaddleNLP 内容可参考：\n\n* [精选模型库](./slm/model_zoo)，包含优质预训练模型的端到端全流程使用。\n* [多场景示例](./slm/examples)，了解如何使用 PaddleNLP 解决 NLP 多种技术问题，包含基础技术、系统应用与拓展应用。\n* [交互式教程](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995)，在🆓免费算力平台 AI Studio 上快速学习 PaddleNLP。\n\n------------------------------------------------------------------------------------------\n\n## 社区交流\n\n* 微信扫描二维码并填写问卷，即可加入交流群与众多社区开发者以及官方团队深度交流.\n\n<div align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/3a58cc9f-69c7-4ccb-b6f5-73e966b8051a\" width=\"150\" height=\"150\" />\n</div>\n\n## Citation\n\n如果 PaddleNLP 对您的研究有帮助，欢迎引用\n\n```bibtex\n@misc{=paddlenlp,\n    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},\n    author={PaddleNLP Contributors},\n    howpublished = {\\url{https://github.com/PaddlePaddle/PaddleNLP}},\n    year={2021}\n}\n```\n\n## Acknowledge\n\n我们借鉴了 Hugging Face 的[Transformers](https://github.com/huggingface/transformers)🤗关于预训练模型使用的优秀设计，在此对 Hugging Face 作者及其开源社区表示感谢。\n\n## License\n\nPaddleNLP 遵循[Apache-2.0开源协议](./LICENSE)。\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 9.7080078125,
          "content": "[简体中文🀄](./README.md) | **English🌎**\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png\" align=\"middle\"  width=\"500\" />\n</p>\n\n------------------------------------------------------------------------------------------\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af\"></a>\n    <a href=\"https://pypi.org/project/paddlenlp/\"><img src=\"https://img.shields.io/pypi/dm/paddlenlp?color=9cf\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf\"></a>\n</p>\n\n<h4 align=\"center\">\n    <a href=#Features> Features </a> |\n    <a href=#Support-Models> Supported Models </a> |\n    <a href=#Installation> Installation </a> |\n    <a href=#Quick-start> Quick Start </a> |\n    <a href=#community> Community </a>\n</h4>\n\n**PaddleNLP** is a Large Language Model (LLM) development suite based on the PaddlePaddle deep learning framework, supporting efficient large model training, lossless compression, and high-performance inference on various hardware devices. With its **simplicity** and **ultimate performance**, PaddleNLP is dedicated to helping developers achieve efficient industrial applications of large models.\n\n## News 📢\n\n* **2024.06.27 [PaddleNLP v3.0 Beta](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta0)**：Embrace large models and experience a complete upgrade. With a unified large model suite, we achieve full-process access to domestically produced computing chips. We fully support industrial-level application processes for large models, such as PaddlePaddle's 4D parallel configuration, efficient fine-tuning strategies, efficient alignment algorithms, and high-performance reasoning. Our developed RsLoRA+ algorithm, full checkpoint storage mechanism Unified Checkpoint, and generalized support for FastFNN and FusedQKV all contribute to the training and inference of large models. We continuously support updates to mainstream models for providing efficient solutions.\n\n* **2024.04.24 [PaddleNLP v2.8](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.8.0)**：Our self-developed RsLoRA+ algorithm with extreme convergence significantly improves the convergence speed and training effectiveness of PEFT training. By introducing high-performance generation acceleration into the RLHF PPO algorithm, we have broken through the generation speed bottleneck in PPO training, achieving a significant lead in PPO training performance. We generally support multiple large model training performance optimization methods such as FastFFN and FusedQKV, making large model training faster and more stable.\n\n## Features\n\n### <a href=#Integrated training and inference on multiple hardware platforms> 🔧 Integrated training and inference on multiple hardware platforms </a>\n\nOur development suit supports large model training and inference on multiple hardware platforms, including NVIDIA GPUs, Kunlun XPUs, Ascend NPUs, Enflame GCUs, and Hygon DCUs. The toolkit's interface allows for quick hardware switching, significantly reducing research and development costs associated with hardware transitions.\n\n### <a href=Efficient and easy-to-use pre-training> 🚀 Efficient and easy-to-use pre-training </a>\n\nWe support 4D high-performance training with data parallelism, sharding parallelism, tensor parallelism, and pipeline parallelism. The Trainer supports configurable distributed strategies, reducing the cost associated with complex distributed combinations. The Unified Checkpoint large model storage format supports dynamic scaling of model parameter distribution during training, thereby reducing the migration cost caused by hardware switching.\n\n### <a href=#Efficient fine-tuning> 🤗 Efficient fine-tuning </a>\n\nThe fine-tuning algorithms are deeply integrated with zero-padding data streams and high-performance FlashMask operators, reducing invalid data padding and computation during training, and significantly improving the throughput of fine-tuning training.\n\n### <a href=#Lossless compression and high-performance inference> 🎛️ Lossless compression and high-performance inference </a>\n\nThe high-performance inference module of the large model toolkit incorporates dynamic insertion and operator fusion strategies throughout the entire process, greatly accelerating parallel inference speed. The underlying implementation details are encapsulated, enabling out-of-the-box high-performance parallel inference capabilities.\n\n------------------------------------------------------------------------------------------\n\n## Support Models\n\nDetailed list 👉 [Supported Model List](https://github.com/PaddlePaddle/PaddleNLP/issues/8663)\n\n## Installation\n\n### Prerequisites\n\n* python >= 3.8\n* paddlepaddle >= 3.0.0b0\n\n### Pip Installation\n\n```shell\npip install --upgrade paddlenlp==3.0.0b2\n```\n\nor you can install the latest develop branch code with the following command:\n\n```shell\npip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html\n```\n\nMore information about PaddlePaddle installation please refer to [PaddlePaddle's Website](https://www.paddlepaddle.org.cn).\n\n------------------------------------------------------------------------------------------\n\n## Quick Start\n\n### Text generation with large language model\n\nPaddleNLP provides a convenient and easy-to-use Auto API, which can quickly load models and Tokenizers. Here, we use the `Qwen/Qwen2-0.5B` large model as an example for text generation:\n\n```python\n>>> from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n>>> model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", dtype=\"float16\")\n>>> input_features = tokenizer(\"你好！请自我介绍一下。\", return_tensors=\"pd\")\n>>> outputs = model.generate(**input_features, max_length=128)\n>>> print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True))\n['我是一个AI语言模型，我可以回答各种问题，包括但不限于：天气、新闻、历史、文化、科学、教育、娱乐等。请问您有什么需要了解的吗？']\n```\n\n### Pre-training for large language model\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # if cloned or downloaded, can skip this step\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_pretrain.py ./config/llama/pretrain_argument.json\n```\n\n### SFT finetuning forlarge language model\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # if cloned or downloaded, can skip this step\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_finetune.py ./config/llama/sft_argument.json\n```\n\nFor more steps in the entire large model process, please refer to the[Large Model Full-Process Suite](./llm).\n\nFor more PaddleNLP content, please refer to:\n\n* [Model Library](./slm/model_zoo)，which includes end-to-end usage of high-quality pre-trained models.\n* [Multi-scenario Examples](./slm/examples)，to understand how to use PaddleNLP to solve various NLP technical problems, including basic techniques, system applications, and extended applications.\n* [Interactive Tutorial](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995)，to quickly learn PaddleNLP on the free computing platform AI Studio.\n\n------------------------------------------------------------------------------------------\n\n## Community\n\n### Slack\n\nTo connect with other users and contributors, welcome to join our [Slack channel](https://paddlenlp.slack.com/).\n\n### WeChat\n\nScan the QR code below with your Wechat⬇️. You can access to official technical exchange group. Look forward to your participation.\n\n<div align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/3a58cc9f-69c7-4ccb-b6f5-73e966b8051a\" width=\"150\" height=\"150\" />\n</div>\n\n## Citation\n\nIf you find PaddleNLP useful in your research, please consider citing\n\n```bibtext\n@misc{=paddlenlp,\n    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},\n    author={PaddleNLP Contributors},\n    howpublished = {\\url{https://github.com/PaddlePaddle/PaddleNLP}},\n    year={2021}\n}\n```\n\n## Acknowledge\n\nWe have borrowed from Hugging Face's [Transformers](https://github.com/huggingface/transformers)🤗 excellent design on pretrained models usage, and we would like to express our gratitude to the authors of Hugging Face and its open source community.\n\n## License\n\nPaddleNLP is provided under the [Apache-2.0 License](./LICENSE).\n"
        },
        {
          "name": "csrc",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "llm",
          "type": "tree",
          "content": null
        },
        {
          "name": "ops",
          "type": "tree",
          "content": null
        },
        {
          "name": "paddlenlp",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.859375,
          "content": "[tool.isort]\nprofile = 'black'\nknown_third_party = [\"paddle\"]\nskip = ['paddlenlp/transformers/__init__.py']\n\n[tool.black]\nline-length = 119\ntarget_version = ['py35', 'py36', 'py37', 'py38', 'py39', 'py310']\nexclude = ['.flake8']\n\n[tool.pytest.ini_options]\nminversion = \"6.0\"\naddopts = \"-ra -q \"\npythonpath = [\".\"]\ntestpaths = [\n    \"tests/data\",\n    \"tests/dataaug\",\n    \"tests/datasets\",\n    \"tests/embeddings\",\n    \"tests/experimental\",\n    \"tests/generation\",\n    \"tests/layers\",\n    \"tests/metrics\",\n    \"tests/pose\",\n    \"tests/ops\",\n    \"tests/trainer\",\n    \"tests/transformers\",\n    \"tests/peft\",\n    \"tests/prompt\",\n    \"tests/mergekit\",\n    # \"tests/taskflow\",  TODO (paddle 2.5.1 breaks this test suite, debug later)\n    \"tests/utils\",\n]\npython_files = [\n    \"test.py\",\n    \"test_*.py\"\n]\nfilterwarnings = [\n    \"ignore::UserWarning\",\n    'ignore::DeprecationWarning',\n]\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.3076171875,
          "content": "paddleocr\npre-commit\npytest==8.1.1\nparameterized\npytest-cov\nregex\npytest-xdist\npytest-timeout\nemoji\nftfy\nyacs\nunidecode\nsoundfile\nlibrosa\nnumpy==1.23.5\nrouge\ntiktoken\nvisualdl\nwandb\ntensorboard\ntensorboardX\nmodelscope\nhyperopt\nh5py\ndeploy\nray\nloguru\ndata\nwget\nhuggingface_hub>=0.19.2\ntiktoken\ntokenizers>=0.21,<0.22"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3798828125,
          "content": "jieba\nblobfile\ncolorlog\ncolorama\nseqeval\ndill<0.3.5\nmultiprocess<=0.70.12.2\ndatasets >= 2.0.0\ntqdm\npaddlefsl\nsentencepiece\nhuggingface_hub>=0.19.2\nonnx>=1.10.0\nprotobuf>=3.20.2\npaddle2onnx\nFlask-Babel\nvisualdl\nfastapi\nuvicorn\ntyper\nrich\nsafetensors\nfast_dataindex>=0.1.1 ; platform_system == \"Linux\"\naistudio-sdk>=0.1.3\njinja2\nregex\nnumpy<=1.26.4\ntiktoken\ntokenizers>=0.21,<0.22\nomegaconf\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.421875,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport errno\nimport io\nimport os\nimport re\nimport subprocess\nfrom datetime import datetime\n\nimport setuptools\n\nPADDLENLP_STABLE_VERSION = \"PADDLENLP_STABLE_VERSION\"\n\n\ndef read_requirements_file(filepath):\n    with open(filepath) as fin:\n        requirements = fin.read()\n    return requirements\n\n\ndef is_git_repo(dir: str) -> bool:\n    \"\"\"Is the given directory version-controlled with git?\"\"\"\n    return os.path.exists(os.path.join(dir, \".git\"))\n\n\ndef have_git() -> bool:\n    \"\"\"Can we run the git executable?\"\"\"\n    try:\n        subprocess.check_output([\"git\", \"--help\"])\n        return True\n    except subprocess.CalledProcessError:\n        return False\n    except OSError:\n        return False\n\n\ndef git_revision(dir: str) -> bytes:\n    \"\"\"Get the SHA-1 of the HEAD of a git repository.\"\"\"\n    return subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=dir).strip()\n\n\ndef git_checkout(dir: str, filename: str) -> bytes:\n    \"\"\"Get the SHA-1 of the HEAD of a git repository.\"\"\"\n    return subprocess.check_output([\"git\", \"checkout\", filename], cwd=dir).strip()\n\n\ndef is_dirty(dir: str) -> bool:\n    \"\"\"Check whether a git repository has uncommitted changes.\"\"\"\n    output = subprocess.check_output([\"git\", \"status\", \"-uno\", \"--porcelain\"], cwd=dir)\n    return output.strip() != b\"\"\n\n\ncommit = \"unknown\"\npaddlenlp_dir = os.path.abspath(os.path.dirname(__file__))\nif commit.endswith(\"unknown\") and is_git_repo(paddlenlp_dir) and have_git():\n    commit = git_revision(paddlenlp_dir).decode(\"utf-8\")\n    if is_dirty(paddlenlp_dir):\n        commit += \".dirty\"\n\n\ndef write_version_py(filename=\"paddlenlp/version/__init__.py\"):\n    cnt = '''# THIS FILE IS GENERATED FROM PADDLENLP SETUP.PY\ncommit           = '%(commit)s'\n\n__all__ = ['show']\n\ndef show():\n    \"\"\"Get the corresponding commit id of paddlenlp.\n\n    Returns:\n        The commit-id of paddlenlp will be output.\n\n        full_version: version of paddlenlp\n\n\n    Examples:\n        .. code-block:: python\n\n            import paddlenlp\n\n            paddlenlp.version.show()\n            # commit: 1ef5b94a18773bb0b1bba1651526e5f5fc5b16fa\n\n    \"\"\"\n    print(\"commit:\", commit)\n\n'''\n    commit_id = commit\n    content = cnt % {\"commit\": commit_id}\n\n    dirname = os.path.dirname(filename)\n\n    try:\n        os.makedirs(dirname)\n    except OSError as e:\n        if e.errno != errno.EEXIST:\n            raise\n\n    with open(filename, \"w\") as f:\n        f.write(content)\n\n\n# only use this file to contral the version\n__version__ = \"3.0.0b3.post\"\nif os.getenv(PADDLENLP_STABLE_VERSION):\n    __version__ = __version__.replace(\".post\", \"\")\nelse:\n    formatted_date = datetime.now().date().strftime(\"%Y%m%d\")\n    __version__ = __version__.replace(\".post\", \".post{}\".format(formatted_date))\n\n\n# write the version information for the develop version\ndef append_version_py(filename=\"paddlenlp/__init__.py\"):\n    assert os.path.exists(filename), f\"{filename} does not exist!\"\n\n    with open(filename, \"r\") as file:\n        file_content = file.read()\n\n    pattern = r\"^# \\[VERSION_INFO\\].*$\"\n    modified_content = re.sub(pattern, f'\\n__version__ = \"{__version__}\"\\n\\n', file_content, flags=re.MULTILINE)\n    with open(filename, \"w\") as file:\n        file.write(modified_content)\n\n\nappend_version_py(filename=\"paddlenlp/__init__.py\")\n\nextras = {}\nREQUIRED_PACKAGES = read_requirements_file(\"requirements.txt\")\nextras[\"tests\"] = read_requirements_file(\"tests/requirements.txt\")\nextras[\"docs\"] = read_requirements_file(\"docs/requirements.txt\")\nextras[\"autonlp\"] = read_requirements_file(\"paddlenlp/experimental/autonlp/requirements.txt\")\nextras[\"dev\"] = extras[\"tests\"] + extras[\"docs\"] + extras[\"autonlp\"]\n\n\ndef read(*names, **kwargs):\n    with io.open(os.path.join(os.path.dirname(__file__), *names), encoding=kwargs.get(\"encoding\", \"utf8\")) as fp:\n        return fp.read()\n\n\ndef get_package_data_files(package, data, package_dir=None):\n    \"\"\"\n    Helps to list all specified files in package including files in directories\n    since `package_data` ignores directories.\n    \"\"\"\n    if package_dir is None:\n        package_dir = os.path.join(*package.split(\".\"))\n    all_files = []\n    for f in data:\n        path = os.path.join(package_dir, f)\n        if os.path.isfile(path):\n            all_files.append(f)\n            continue\n        for root, _dirs, files in os.walk(path, followlinks=True):\n            root = os.path.relpath(root, package_dir)\n            for file in files:\n                file = os.path.join(root, file)\n                if file not in all_files:\n                    all_files.append(file)\n    return all_files\n\n\nif commit != \"unknown\":\n    write_version_py(filename=\"paddlenlp/version/__init__.py\")\n\ntry:\n    setuptools.setup(\n        name=\"paddlenlp\",\n        version=__version__,\n        author=\"PaddleNLP Team\",\n        author_email=\"paddlenlp@baidu.com\",\n        description=\"Easy-to-use and powerful NLP library with Awesome model zoo, supporting wide-range of NLP tasks from research to industrial applications, including Neural Search, Question Answering, Information Extraction and Sentiment Analysis end-to-end system.\",\n        long_description=read(\"README_en.md\"),\n        long_description_content_type=\"text/markdown\",\n        url=\"https://github.com/PaddlePaddle/PaddleNLP\",\n        license_files=(\"LICENSE\",),\n        packages=setuptools.find_packages(\n            where=\".\",\n            exclude=(\"examples*\", \"tests*\", \"applications*\", \"fast_generation*\", \"model_zoo*\"),\n        ),\n        package_data={\n            \"paddlenlp.ops\": get_package_data_files(\n                \"paddlenlp.ops\", [\"CMakeLists.txt\", \"README.md\", \"cmake\", \"fast_transformer\", \"patches\", \"optimizer\"]\n            ),\n            \"paddlenlp.transformers.layoutxlm\": get_package_data_files(\n                \"paddlenlp.transformers.layoutxlm\", [\"visual_backbone.yaml\"]\n            ),\n            \"paddlenlp.experimental\": get_package_data_files(\"paddlenlp.experimental\", [\"transformers\"]),\n        },\n        setup_requires=[\"cython\", \"numpy\"],\n        install_requires=REQUIRED_PACKAGES,\n        entry_points={\"console_scripts\": [\"paddlenlp = paddlenlp.cli:main\"]},\n        extras_require=extras,\n        python_requires=\">=3.8\",\n        classifiers=[\n            \"Programming Language :: Python :: 3\",\n            \"Programming Language :: Python :: 3.8\",\n            \"Programming Language :: Python :: 3.9\",\n            \"Programming Language :: Python :: 3.10\",\n            \"License :: OSI Approved :: Apache Software License\",\n            \"Operating System :: OS Independent\",\n        ],\n        license=\"Apache 2.0\",\n    )\nexcept Exception as e:\n    git_checkout(paddlenlp_dir, \"paddlenlp/version/__init__.py\") if commit != \"unknown\" else None\n    git_checkout(paddlenlp_dir, \"paddlenlp/__init__.py\") if commit != \"unknown\" else None\n    raise e\n\ngit_checkout(paddlenlp_dir, \"paddlenlp/version/__init__.py\") if commit != \"unknown\" else None\ngit_checkout(paddlenlp_dir, \"paddlenlp/__init__.py\") if commit != \"unknown\" else None\n"
        },
        {
          "name": "slm",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}