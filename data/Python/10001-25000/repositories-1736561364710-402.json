{
  "metadata": {
    "timestamp": 1736561364710,
    "page": 402,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "THUDM/CogVideo",
      "stars": 10227,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.255859375,
          "content": "*__pycache__/\nsamples*/\nruns/\ncheckpoints/\nmaster_ip\nlogs/\n*.DS_Store\n.idea\noutput*\ntest*\nvenv\n**/.swp\n**/*.log\n**/*.debug\n**/.vscode\n\n**/*debug*\n**/.gitignore\n**/finetune/*-lora-*\n**/finetune/Disney-*\n**/wandb\n**/results\n**/*.mp4\n**/validation_set\nCogVideo-1.0\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.09375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2024 CogVideo Model Team @ Zhipu AI\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MODEL_LICENSE",
          "type": "blob",
          "size": 5.5693359375,
          "content": "The CogVideoX License\n\n1. Definitions\n\nâ€œLicensorâ€ means the CogVideoX Model Team that distributes its Software.\n\nâ€œSoftwareâ€ means the CogVideoX model parameters made available under this license.\n\n2. License Grant\n\nUnder the terms and conditions of this license, the licensor hereby grants you a non-exclusive, worldwide, non-transferable, non-sublicensable, revocable, royalty-free copyright license. The intellectual property rights of the generated content belong to the user to the extent permitted by applicable local laws.\nThis license allows you to freely use all open-source models in this repository for academic research. Users who wish to use the models for commercial purposes must register and obtain a basic commercial license in https://open.bigmodel.cn/mla/form .\nUsers who have registered and obtained the basic commercial license can use the models for commercial activities for free, but must comply with all terms and conditions of this license. Additionally, the number of service users (visits) for your commercial activities must not exceed 1 million visits per month.\nIf the number of service users (visits) for your commercial activities exceeds 1 million visits per month, you need to contact our business team to obtain more commercial licenses.\nThe above copyright statement and this license statement should be included in all copies or significant portions of this software.\n\n3. Restriction\n\nYou will not use, copy, modify, merge, publish, distribute, reproduce, or create derivative works of the Software, in whole or in part, for any military, or illegal purposes.\n\nYou will not use the Software for any act that may undermine China's national security and national unity, harm the public interest of society, or infringe upon the rights and interests of human beings.\n\n4. Disclaimer\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n5. Limitation of Liability\n\nEXCEPT TO THE EXTENT PROHIBITED BY APPLICABLE LAW, IN NO EVENT AND UNDER NO LEGAL THEORY, WHETHER BASED IN TORT, NEGLIGENCE, CONTRACT, LIABILITY, OR OTHERWISE WILL ANY LICENSOR BE LIABLE TO YOU FOR ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES, OR ANY OTHER COMMERCIAL LOSSES, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.\n\n6. Dispute Resolution\n\nThis license shall be governed and construed in accordance with the laws of Peopleâ€™s Republic of China. Any dispute arising from or in connection with this License shall be submitted to Haidian District People's Court in Beijing.\n\nNote that the license is subject to update to a more comprehensive version.  For any questions related to the license and copyright, please contact us at license@zhipuai.cn.\n\n1. å®šä¹‰\n\nâ€œè®¸å¯æ–¹â€æ˜¯æŒ‡åˆ†å‘å…¶è½¯ä»¶çš„ CogVideoX æ¨¡å‹å›¢é˜Ÿã€‚\n\nâ€œè½¯ä»¶â€æ˜¯æŒ‡æ ¹æ®æœ¬è®¸å¯æä¾›çš„ CogVideoX æ¨¡å‹å‚æ•°ã€‚\n\n2. è®¸å¯æˆäºˆ\n\næ ¹æ®æœ¬è®¸å¯çš„æ¡æ¬¾å’Œæ¡ä»¶ï¼Œè®¸å¯æ–¹ç‰¹æ­¤æˆäºˆæ‚¨éæ’ä»–æ€§ã€å…¨çƒæ€§ã€ä¸å¯è½¬è®©ã€ä¸å¯å†è®¸å¯ã€å¯æ’¤é”€ã€å…ç‰ˆç¨çš„ç‰ˆæƒè®¸å¯ã€‚ç”Ÿæˆå†…å®¹çš„çŸ¥è¯†äº§æƒæ‰€å±ï¼Œå¯æ ¹æ®é€‚ç”¨å½“åœ°æ³•å¾‹çš„è§„å®šï¼Œåœ¨æ³•å¾‹å…è®¸çš„èŒƒå›´å†…ç”±ç”¨æˆ·äº«æœ‰ç”Ÿæˆå†…å®¹çš„çŸ¥è¯†äº§æƒæˆ–å…¶ä»–æƒåˆ©ã€‚\næœ¬è®¸å¯å…è®¸æ‚¨å…è´¹ä½¿ç”¨æœ¬ä»“åº“ä¸­çš„æ‰€æœ‰å¼€æºæ¨¡å‹è¿›è¡Œå­¦æœ¯ç ”ç©¶ã€‚å¯¹äºå¸Œæœ›å°†æ¨¡å‹ç”¨äºå•†ä¸šç›®çš„çš„ç”¨æˆ·ï¼Œéœ€åœ¨ https://open.bigmodel.cn/mla/form å®Œæˆç™»è®°å¹¶è·å¾—åŸºç¡€å•†ç”¨æˆæƒã€‚\n\nç»è¿‡ç™»è®°å¹¶è·å¾—åŸºç¡€å•†ç”¨æˆæƒçš„ç”¨æˆ·å¯ä»¥å…è´¹ä½¿ç”¨æœ¬æ¨¡å‹è¿›è¡Œå•†ä¸šæ´»åŠ¨ï¼Œä½†å¿…é¡»éµå®ˆæœ¬è®¸å¯çš„æ‰€æœ‰æ¡æ¬¾å’Œæ¡ä»¶ã€‚\nåœ¨æœ¬è®¸å¯è¯ä¸‹ï¼Œæ‚¨çš„å•†ä¸šæ´»åŠ¨çš„æœåŠ¡ç”¨æˆ·æ•°é‡ï¼ˆè®¿é—®é‡ï¼‰ä¸å¾—è¶…è¿‡100ä¸‡äººæ¬¡è®¿é—® / æ¯æœˆã€‚å¦‚æœè¶…è¿‡ï¼Œæ‚¨éœ€è¦ä¸æˆ‘ä»¬çš„å•†ä¸šå›¢é˜Ÿè”ç³»ä»¥è·å¾—æ›´å¤šçš„å•†ä¸šè®¸å¯ã€‚\nä¸Šè¿°ç‰ˆæƒå£°æ˜å’Œæœ¬è®¸å¯å£°æ˜åº”åŒ…å«åœ¨æœ¬è½¯ä»¶çš„æ‰€æœ‰å‰¯æœ¬æˆ–é‡è¦éƒ¨åˆ†ä¸­ã€‚\n\n3.é™åˆ¶\n\næ‚¨ä¸å¾—å‡ºäºä»»ä½•å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºæœ¬è½¯ä»¶çš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚\n\næ‚¨ä¸å¾—åˆ©ç”¨æœ¬è½¯ä»¶ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚\n\n4.å…è´£å£°æ˜\n\næœ¬è½¯ä»¶â€œæŒ‰åŸæ ·â€æä¾›ï¼Œä¸æä¾›ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå¯¹é€‚é”€æ€§ã€ç‰¹å®šç”¨é€”çš„é€‚ç”¨æ€§å’Œéä¾µæƒæ€§çš„ä¿è¯ã€‚\nåœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œä½œè€…æˆ–ç‰ˆæƒæŒæœ‰äººå‡ä¸å¯¹ä»»ä½•ç´¢èµ”ã€æŸå®³æˆ–å…¶ä»–è´£ä»»è´Ÿè´£ï¼Œæ— è®ºæ˜¯åœ¨åˆåŒè¯‰è®¼ã€ä¾µæƒè¡Œä¸ºè¿˜æ˜¯å…¶ä»–æ–¹é¢ï¼Œç”±è½¯ä»¶æˆ–è½¯ä»¶çš„ä½¿ç”¨æˆ–å…¶ä»–äº¤æ˜“å¼•èµ·ã€ç”±è½¯ä»¶å¼•èµ·æˆ–ä¸ä¹‹ç›¸å…³ è½¯ä»¶ã€‚\n\n5. è´£ä»»é™åˆ¶\n\né™¤é€‚ç”¨æ³•å¾‹ç¦æ­¢çš„èŒƒå›´å¤–ï¼Œåœ¨ä»»ä½•æƒ…å†µä¸‹ä¸”æ ¹æ®ä»»ä½•æ³•å¾‹ç†è®ºï¼Œæ— è®ºæ˜¯åŸºäºä¾µæƒè¡Œä¸ºã€ç–å¿½ã€åˆåŒã€è´£ä»»æˆ–å…¶ä»–åŸå› ï¼Œä»»ä½•è®¸å¯æ–¹å‡ä¸å¯¹æ‚¨æ‰¿æ‹…ä»»ä½•ç›´æ¥ã€é—´æ¥ã€ç‰¹æ®Šã€å¶ç„¶ã€ç¤ºèŒƒæ€§ã€ æˆ–é—´æ¥æŸå®³ï¼Œæˆ–ä»»ä½•å…¶ä»–å•†ä¸šæŸå¤±ï¼Œå³ä½¿è®¸å¯äººå·²è¢«å‘ŠçŸ¥æ­¤ç±»æŸå®³çš„å¯èƒ½æ€§ã€‚\n\n6.äº‰è®®è§£å†³\n\næœ¬è®¸å¯å—ä¸­åäººæ°‘å…±å’Œå›½æ³•å¾‹ç®¡è¾–å¹¶æŒ‰å…¶è§£é‡Šã€‚ å› æœ¬è®¸å¯å¼•èµ·çš„æˆ–ä¸æœ¬è®¸å¯æœ‰å…³çš„ä»»ä½•äº‰è®®åº”æäº¤åŒ—äº¬å¸‚æµ·æ·€åŒºäººæ°‘æ³•é™¢ã€‚\n\nè¯·æ³¨æ„ï¼Œè®¸å¯è¯å¯èƒ½ä¼šæ›´æ–°åˆ°æ›´å…¨é¢çš„ç‰ˆæœ¬ã€‚ æœ‰å…³è®¸å¯å’Œç‰ˆæƒçš„ä»»ä½•é—®é¢˜ï¼Œè¯·é€šè¿‡ license@zhipuai.cn ä¸æˆ‘ä»¬è”ç³»ã€‚"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 26.8330078125,
          "content": "# CogVideo & CogVideoX\n\n[ä¸­æ–‡é˜…è¯»](./README_zh.md)\n\n[æ—¥æœ¬èªã§èª­ã‚€](./README_ja.md)\n\n<div align=\"center\">\n<img src=resources/logo.svg width=\"50%\"/>\n</div>\n<p align=\"center\">\nExperience the CogVideoX-5B model online at <a href=\"https://huggingface.co/spaces/THUDM/CogVideoX-5B\" target=\"_blank\"> ğŸ¤— Huggingface Space</a> or <a href=\"https://modelscope.cn/studios/ZhipuAI/CogVideoX-5b-demo\" target=\"_blank\"> ğŸ¤– ModelScope Space</a>\n</p>\n<p align=\"center\">\nğŸ“š View the <a href=\"https://arxiv.org/abs/2408.06072\" target=\"_blank\">paper</a> and <a href=\"https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh\" target=\"_blank\">user guide</a>\n</p>\n<p align=\"center\">\n    ğŸ‘‹ Join our <a href=\"resources/WECHAT.md\" target=\"_blank\">WeChat</a> and <a href=\"https://discord.gg/dCGfUsagrD\" target=\"_blank\">Discord</a> \n</p>\n<p align=\"center\">\nğŸ“ Visit <a href=\"https://chatglm.cn/video?lang=en?fr=osm_cogvideo\">QingYing</a> and <a href=\"https://open.bigmodel.cn/?utm_campaign=open&_channel_track_key=OWTVNma9\">API Platform</a> to experience larger-scale commercial video generation models.\n</p>\n\n## Project Updates\n\n- ğŸ”¥ğŸ”¥ **News**: ```2025/01/08```: We have updated the code for `Lora` fine-tuning based on the `diffusers` version model, which uses less GPU memory. For more details, please see [here](finetune/README.md).\n- ğŸ”¥ **News**: ```2024/11/15```: We released the `CogVideoX1.5` model in the diffusers version. Only minor parameter adjustments are needed to continue using previous code.\n- ğŸ”¥ **News**: ```2024/11/08```: We have released the CogVideoX1.5 model. CogVideoX1.5 is an upgraded version of the open-source model CogVideoX.\nThe CogVideoX1.5-5B series supports 10-second videos with higher resolution, and CogVideoX1.5-5B-I2V supports video generation at any resolution. \nThe SAT code has already been updated, while the diffusers version is still under adaptation. Download the SAT version code [here](https://huggingface.co/THUDM/CogVideoX1.5-5B-SAT).\n- ğŸ”¥ **News**: ```2024/10/13```: A more cost-effective fine-tuning framework for `CogVideoX-5B` that works with a single\n  4090 GPU, [cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory), has been released. It supports\n  fine-tuning with multiple resolutions. Feel free to use it!\n- ğŸ”¥ **News**: ```2024/10/10```: We have updated our technical report. Please\n  click [here](https://arxiv.org/pdf/2408.06072) to view it. More training details and a demo have been added. To see\n  the demo, click [here](https://yzy-thu.github.io/CogVideoX-demo/).- ğŸ”¥ **News**: ```2024/10/09```: We have publicly\n  released the [technical documentation](https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh) for CogVideoX\n  fine-tuning on Feishu, further increasing distribution flexibility. All examples in the public documentation can be\n  fully reproduced.\n- ğŸ”¥ **News**: ```2024/9/19```: We have open-sourced the CogVideoX series image-to-video model **CogVideoX-5B-I2V**.\n  This model can take an image as a background input and generate a video combined with prompt words, offering greater\n  controllability. With this, the CogVideoX series models now support three tasks: text-to-video generation, video\n  continuation, and image-to-video generation. Welcome to try it online\n  at [Experience](https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space).\n- ğŸ”¥ ```2024/9/19```: The Caption\n  model [CogVLM2-Caption](https://huggingface.co/THUDM/cogvlm2-llama3-caption), used in the training process of\n  CogVideoX to convert video data into text descriptions, has been open-sourced. Welcome to download and use it.\n- ğŸ”¥ ```2024/8/27```: We have open-sourced a larger model in the CogVideoX series, **CogVideoX-5B**. We have\n  significantly optimized the model's inference performance, greatly lowering the inference threshold. \n  You can run **CogVideoX-2B** on older GPUs like `GTX 1080TI`, and **CogVideoX-5B** on desktop GPUs like `RTX 3060`. Please strictly\n  follow the [requirements](requirements.txt) to update and install dependencies, and refer\n  to [cli_demo](inference/cli_demo.py) for inference code. Additionally, the open-source license for \n  the **CogVideoX-2B** model has been changed to the **Apache 2.0 License**.\n- ğŸ”¥ ```2024/8/6```: We have open-sourced **3D Causal VAE**, used for **CogVideoX-2B**, which can reconstruct videos with\n  almost no loss.\n- ğŸ”¥ ```2024/8/6```: We have open-sourced the first model of the CogVideoX series video generation models, **CogVideoX-2B\n  **.\n- ğŸŒ± **Source**: ```2022/5/19```: We have open-sourced the CogVideo video generation model (now you can see it in\n  the `CogVideo` branch). This is the first open-source large Transformer-based text-to-video generation model. You can\n  access the [ICLR'23 paper](https://arxiv.org/abs/2205.15868) for technical details.\n\n## Table of Contents\n\nJump to a specific section:\n\n- [Quick Start](#quick-start)\n  - [Prompt Optimization](#prompt-optimization)\n  - [SAT](#sat)\n  - [Diffusers](#diffusers)\n- [Gallery](#gallery)\n  - [CogVideoX-5B](#cogvideox-5b)\n  - [CogVideoX-2B](#cogvideox-2b)\n- [Model Introduction](#model-introduction)\n- [Friendly Links](#friendly-links)\n- [Project Structure](#project-structure)\n  - [Quick Start with Colab](#quick-start-with-colab)\n  - [Inference](#inference)\n  - [finetune](#finetune)\n  - [sat](#sat-1)\n  - [Tools](#tools)\n- [CogVideo(ICLR'23)](#cogvideoiclr23)\n- [Citation](#citation)\n- [Model-License](#model-license)\n\n## Quick Start\n\n### Prompt Optimization\n\nBefore running the model, please refer to [this guide](inference/convert_demo.py) to see how we use large models like\nGLM-4 (or other comparable products, such as GPT-4) to optimize the model. This is crucial because the model is trained\nwith long prompts, and a good prompt directly impacts the quality of the video generation.\n\n### SAT\n\n**Please make sure your Python version is between 3.10 and 3.12, inclusive of both 3.10 and 3.12.**\n\nFollow instructions in [sat_demo](sat/README.md): Contains the inference code and fine-tuning code of SAT weights. It is\nrecommended to improve based on the CogVideoX model structure. Innovative researchers use this code to better perform\nrapid stacking and development.\n\n### Diffusers\n\n**Please make sure your Python version is between 3.10 and 3.12, inclusive of both 3.10 and 3.12.**\n\n```\npip install -r requirements.txt\n```\n\nThen follow [diffusers_demo](inference/cli_demo.py): A more detailed explanation of the inference code, mentioning the\nsignificance of common parameters.\n\nFor more details on quantized inference, please refer\nto [diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao/). With Diffusers and TorchAO, quantized inference\nis also possible leading to memory-efficient inference as well as speedup in some cases when compiled. A full list of\nmemory and time benchmarks with various settings on A100 and H100 has been published\nat [diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao).\n\n## Gallery\n\n### CogVideoX-5B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/cf5953ea-96d3-48fd-9907-c4708752c714\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/fe0a78e6-b669-4800-8cf0-b5f9b5145b52\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/c182f606-8f8c-421d-b414-8487070fcfcb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/7db2bbce-194d-434d-a605-350254b6c298\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/62b01046-8cab-44cc-bd45-4d965bb615ec\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/d78e552a-4b3f-4b81-ac3f-3898079554f6\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/30894f12-c741-44a2-9e6e-ddcacc231e5b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/926575ca-7150-435b-a0ff-4900a963297b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\n### CogVideoX-2B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/ea3af39a-3160-4999-90ec-2f7863c5b0e9\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/9de41efd-d4d1-4095-aeda-246dd834e91d\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/941d6661-6a8d-4a1b-b912-59606f0b2841\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/938529c4-91ae-4f60-b96b-3c3947fa63cb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\nTo view the corresponding prompt words for the gallery, please click [here](resources/galary_prompt.md)\n\n## Model Introduction\n\nCogVideoX is an open-source version of the video generation model originating\nfrom [QingYing](https://chatglm.cn/video?lang=en?fr=osm_cogvideo). The table below displays the list of video generation\nmodels we currently offer, along with their foundational information.\n\n<table style=\"border-collapse: collapse; width: 100%;\">\n  <tr>\n    <th style=\"text-align: center;\">Model Name</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B (Latest)</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B-I2V (Latest)</th>\n    <th style=\"text-align: center;\">CogVideoX-2B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B-I2V</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Release Date</td>\n    <th style=\"text-align: center;\">November 8, 2024</th>\n    <th style=\"text-align: center;\">November 8, 2024</th>\n    <th style=\"text-align: center;\">August 6, 2024</th>\n    <th style=\"text-align: center;\">August 27, 2024</th>\n    <th style=\"text-align: center;\">September 19, 2024</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Video Resolution</td>\n    <td colspan=\"1\" style=\"text-align: center;\">1360 * 768</td>\n    <td colspan=\"1\" style=\"text-align: center;\"> Min(W, H) = 768 <br> 768 â‰¤ Max(W, H) â‰¤ 1360 <br> Max(W, H) % 16 = 0 </td>\n    <td colspan=\"3\" style=\"text-align: center;\">720 * 480</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Inference Precision</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16 (Recommended)</b>, FP16, FP32, FP8*, INT8, Not supported: INT4</td>\n    <td style=\"text-align: center;\"><b>FP16*(Recommended)</b>, BF16, FP32, FP8*, INT8, Not supported: INT4</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16 (Recommended)</b>, FP16, FP32, FP8*, INT8, Not supported: INT4</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Single GPU Memory Usage<br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 76GB <br><b>diffusers BF16: from 10GB*</b><br><b>diffusers INT8(torchao): from 7GB*</b></td>\n    <td style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> FP16: 18GB <br><b>diffusers FP16: 4GB minimum* </b><br><b>diffusers INT8 (torchao): 3.6GB minimum*</b></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 26GB <br><b>diffusers BF16 : 5GB minimum* </b><br><b>diffusers INT8 (torchao): 4.4GB minimum* </b></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Multi-GPU Memory Usage</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 24GB* using diffusers</b><br></td>\n    <td style=\"text-align: center;\"><b>FP16: 10GB* using diffusers</b><br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 15GB* using diffusers</b><br></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Inference Speed<br>(Step = 50, FP/BF16)</td>\n    <td colspan=\"2\" style=\"text-align: center;\">Single A100: ~1000 seconds (5-second video)<br>Single H100: ~550 seconds (5-second video)</td>\n    <td style=\"text-align: center;\">Single A100: ~90 seconds<br>Single H100: ~45 seconds</td>\n    <td colspan=\"2\" style=\"text-align: center;\">Single A100: ~180 seconds<br>Single H100: ~90 seconds</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Prompt Language</td>\n    <td colspan=\"5\" style=\"text-align: center;\">English*</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Prompt Token Limit</td>\n    <td colspan=\"2\" style=\"text-align: center;\">224 Tokens</td>\n    <td colspan=\"3\" style=\"text-align: center;\">226 Tokens</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Video Length</td>\n    <td colspan=\"2\" style=\"text-align: center;\">5 seconds or 10 seconds</td>\n    <td colspan=\"3\" style=\"text-align: center;\">6 seconds</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Frame Rate</td>\n    <td colspan=\"2\" style=\"text-align: center;\">16 frames / second </td>\n    <td colspan=\"3\" style=\"text-align: center;\">8 frames / second </td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Position Encoding</td>\n    <td colspan=\"2\" style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_sincos_pos_embed</td> \n    <td style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_rope_pos_embed + learnable_pos_embed</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Download Link (Diffusers)</td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-2b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-2b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-2b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸŸ£ WiseModel</a></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">Download Link (SAT)</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5b-SAT\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸŸ£ WiseModel</a></td>\n    <td colspan=\"3\" style=\"text-align: center;\"><a href=\"./sat/README_zh.md\">SAT</a></td>\n  </tr>\n</table>\n\n**Data Explanation**\n\n+ While testing using the diffusers library, all optimizations included in the diffusers library were enabled. This\n  scheme has not been tested for actual memory usage on devices outside of **NVIDIA A100 / H100** architectures.\n  Generally, this scheme can be adapted to all **NVIDIA Ampere architecture** and above devices. If optimizations are\n  disabled, memory consumption will multiply, with peak memory usage being about 3 times the value in the table.\n  However, speed will increase by about 3-4 times. You can selectively disable some optimizations, including:\n\n```\npipe.enable_sequential_cpu_offload()\npipe.vae.enable_slicing()\npipe.vae.enable_tiling()\n```\n\n+ For multi-GPU inference, the `enable_sequential_cpu_offload()` optimization needs to be disabled.\n+ Using INT8 models will slow down inference, which is done to accommodate lower-memory GPUs while maintaining minimal\n  video quality loss, though inference speed will significantly decrease.\n+ The CogVideoX-2B model was trained in `FP16` precision, and all CogVideoX-5B models were trained in `BF16` precision.\n  We recommend using the precision in which the model was trained for inference.\n+ [PytorchAO](https://github.com/pytorch/ao) and [Optimum-quanto](https://github.com/huggingface/optimum-quanto/) can be\n  used to quantize the text encoder, transformer, and VAE modules to reduce the memory requirements of CogVideoX. This\n  allows the model to run on free T4 Colabs or GPUs with smaller memory! Also, note that TorchAO quantization is fully\n  compatible with `torch.compile`, which can significantly improve inference speed. FP8 precision must be used on\n  devices with NVIDIA H100 and above, requiring source installation of `torch`, `torchao` Python packages. CUDA 12.4 is recommended.\n+ The inference speed tests also used the above memory optimization scheme. Without memory optimization, inference speed\n  increases by about 10%. Only the `diffusers` version of the model supports quantization.\n+ The model only supports English input; other languages can be translated into English for use via large model\n  refinement.\n\n\n## Friendly Links\n\nWe highly welcome contributions from the community and actively contribute to the open-source community. The following\nworks have already been adapted for CogVideoX, and we invite everyone to use them:\n\n+ [CogVideoX-Fun](https://github.com/aigc-apps/CogVideoX-Fun): CogVideoX-Fun is a modified pipeline based on the\n  CogVideoX architecture, supporting flexible resolutions and multiple launch methods.\n+ [CogStudio](https://github.com/pinokiofactory/cogstudio): A separate repository for CogVideo's Gradio Web UI, which\n  supports more functional Web UIs.\n+ [Xorbits Inference](https://github.com/xorbitsai/inference): A powerful and comprehensive distributed inference\n  framework, allowing you to easily deploy your own models or the latest cutting-edge open-source models with just one\n  click.\n+ [ComfyUI-CogVideoXWrapper](https://github.com/kijai/ComfyUI-CogVideoXWrapper) Use the ComfyUI framework to integrate\n  CogVideoX into your workflow.\n+ [VideoSys](https://github.com/NUS-HPC-AI-Lab/VideoSys): VideoSys provides a user-friendly, high-performance\n  infrastructure for video generation, with full pipeline support and continuous integration of the latest models and\n  techniques.\n+ [AutoDL Space](https://www.codewithgpu.com/i/THUDM/CogVideo/CogVideoX-5b-demo): A one-click deployment Huggingface\n  Space image provided by community members.\n+ [Interior Design Fine-Tuning Model](https://huggingface.co/collections/bertjiazheng/koolcogvideox-66e4762f53287b7f39f8f3ba):\n  is a fine-tuned model based on CogVideoX, specifically designed for interior design.\n+ [xDiT](https://github.com/xdit-project/xDiT): xDiT is a scalable inference engine for Diffusion Transformers (DiTs)\n  on multiple GPU Clusters. xDiT supports real-time image and video generations services.\n  [cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory): A cost-effective\n  fine-tuning framework for CogVideoX, compatible with the `diffusers` version model. Supports more resolutions, and\n  fine-tuning CogVideoX-5B can be done with a single 4090 GPU.\n+ [CogVideoX-Interpolation](https://github.com/feizc/CogvideX-Interpolation): A pipeline based on the modified CogVideoX\n  structure, aimed at providing greater flexibility for keyframe interpolation generation.\n+ [DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio): DiffSynth Studio is a diffusion engine. It has\n  restructured the architecture, including text encoders, UNet, VAE, etc., enhancing computational performance while\n  maintaining compatibility with open-source community models. The framework has been adapted for CogVideoX.\n+ [CogVideoX-Controlnet](https://github.com/TheDenk/cogvideox-controlnet): A simple ControlNet module code that includes the CogVideoX model.\n+ [VideoTuna](https://github.com/VideoVerses/VideoTuna): VideoTuna is the first repo that integrates multiple AI video generation models for text-to-video, image-to-video, text-to-image generation.\n+ [ConsisID](https://github.com/PKU-YuanGroup/ConsisID): An identity-preserving text-to-video generation model, bases on CogVideoX-5B, which keep the face consistent in the generated video by frequency decomposition.\n+ [A Step by Step Tutorial](https://www.youtube.com/watch?v=5UCkMzP2VLE&ab_channel=SECourses): A step-by-step guide on installing and optimizing the CogVideoX1.5-5B-I2V model in Windows and cloud environments. Special thanks to the [FurkanGozukara](https://github.com/FurkanGozukara) for his effort and support!\n\n## Project Structure\n\nThis open-source repository will guide developers to quickly get started with the basic usage and fine-tuning examples\nof the **CogVideoX** open-source model.\n\n### Quick Start with Colab\n\nHere provide three projects that can be run directly on free Colab T4 instances:\n\n+ [CogVideoX-5B-T2V-Colab.ipynb](https://colab.research.google.com/drive/1pCe5s0bC_xuXbBlpvIH1z0kfdTLQPzCS?usp=sharing):\n  CogVideoX-5B Text-to-Video Colab code.\n+ [CogVideoX-5B-T2V-Int8-Colab.ipynb](https://colab.research.google.com/drive/1DUffhcjrU-uz7_cpuJO3E_D4BaJT7OPa?usp=sharing):\n  CogVideoX-5B Quantized Text-to-Video Inference Colab code, which takes about 30 minutes per run.\n+ [CogVideoX-5B-I2V-Colab.ipynb](https://colab.research.google.com/drive/17CqYCqSwz39nZAX2YyonDxosVKUZGzcX?usp=sharing):\n  CogVideoX-5B Image-to-Video Colab code.\n+ [CogVideoX-5B-V2V-Colab.ipynb](https://colab.research.google.com/drive/1comfGAUJnChl5NwPuO8Ox5_6WCy4kbNN?usp=sharing):\n  CogVideoX-5B Video-to-Video Colab code.\n\n### Inference\n\n+ [dcli_demo](inference/cli_demo.py): A more detailed inference code explanation, including the significance of\n  common parameters. All of this is covered here.\n+ [cli_demo_quantization](inference/cli_demo_quantization.py):\n  Quantized model inference code that can run on devices with lower memory. You can also modify this code to support\n  running CogVideoX models in FP8 precision.\n+ [diffusers_vae_demo](inference/cli_vae_demo.py): Code for running VAE inference separately.\n+ [space demo](inference/gradio_composite_demo): The same GUI code as used in the Huggingface Space, with frame\n  interpolation and super-resolution tools integrated.\n\n<div style=\"text-align: center;\">\n    <img src=\"resources/web_demo.png\" style=\"width: 100%; height: auto;\" />\n</div>\n\n+ [convert_demo](inference/convert_demo.py): How to convert user input into long-form input suitable for CogVideoX.\n  Since CogVideoX is trained on long texts, we need to transform the input text distribution to match the training data\n  using an LLM. The script defaults to using GLM-4, but it can be replaced with GPT, Gemini, or any other large language\n  model.\n+ [gradio_web_demo](inference/gradio_composite_demo): A simple Gradio web application demonstrating how to use the\n  CogVideoX-2B / 5B model to generate videos. Similar to our Huggingface Space, you can use this script to run a simple\n  web application for video generation.\n\n### finetune\n\n+ [finetune_demo](finetune/README.md): Fine-tuning scheme and details of the diffusers version of the CogVideoX model.\n\n### sat\n\n+ [sat_demo](sat/README.md): Contains the inference code and fine-tuning code of SAT weights. It is recommended to\n  improve based on the CogVideoX model structure. Innovative researchers use this code to better perform rapid stacking\n  and development.\n\n### Tools\n\nThis folder contains some tools for model conversion / caption generation, etc.\n\n+ [convert_weight_sat2hf](tools/convert_weight_sat2hf.py): Converts SAT model weights to Huggingface model weights.\n+ [caption_demo](tools/caption/README.md): Caption tool, a model that understands videos and outputs descriptions in\n  text.\n+ [export_sat_lora_weight](tools/export_sat_lora_weight.py): SAT fine-tuning model export tool, exports the SAT Lora\n  Adapter in diffusers format.\n+ [load_cogvideox_lora](tools/load_cogvideox_lora.py): Tool code for loading the diffusers version of fine-tuned Lora\n  Adapter.\n+ [llm_flux_cogvideox](tools/llm_flux_cogvideox/llm_flux_cogvideox.py): Automatically generate videos using an\n  open-source local large language model + Flux + CogVideoX.\n+ [parallel_inference_xdit](tools/parallel_inference/parallel_inference_xdit.py):\n  Supported by [xDiT](https://github.com/xdit-project/xDiT), parallelize the\n  video generation process on multiple GPUs.\n\n## CogVideo(ICLR'23)\n\nThe official repo for the\npaper: [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/abs/2205.15868)\nis on the [CogVideo branch](https://github.com/THUDM/CogVideo/tree/CogVideo)\n\n**CogVideo is able to generate relatively high-frame-rate videos.**\nA 4-second clip of 32 frames is shown below.\n\n![High-frame-rate sample](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/appendix-sample-highframerate.png)\n\n![Intro images](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/intro-image.png)\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/2fa19651-e925-4a2a-b8d6-b3f216d490ba\" width=\"80%\" controls autoplay></video>\n</div>\n\n\nThe demo for CogVideo is at [https://models.aminer.cn/cogvideo](https://models.aminer.cn/cogvideo/), where you can get\nhands-on practice on text-to-video generation. *The original input is in Chinese.*\n\n## Citation\n\nğŸŒŸ If you find our work helpful, please leave us a star and cite our paper.\n\n```\n@article{yang2024cogvideox,\n  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},\n  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},\n  journal={arXiv preprint arXiv:2408.06072},\n  year={2024}\n}\n@article{hong2022cogvideo,\n  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},\n  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},\n  journal={arXiv preprint arXiv:2205.15868},\n  year={2022}\n}\n```\n\nWe welcome your contributions! You can click [here](resources/contribute.md) for more information.\n\n## Model-License\n\nThe code in this repository is released under the [Apache 2.0 License](LICENSE).\n\nThe CogVideoX-2B model (including its corresponding Transformers module and VAE module) is released under\nthe [Apache 2.0 License](LICENSE).\n\nThe CogVideoX-5B model (Transformers module, include I2V and T2V) is released under\nthe [CogVideoX LICENSE](https://huggingface.co/THUDM/CogVideoX-5b/blob/main/LICENSE).\n"
        },
        {
          "name": "README_ja.md",
          "type": "blob",
          "size": 30.72265625,
          "content": "# CogVideo & CogVideoX\n\n[Read this in English](./README.md)\n\n[ä¸­æ–‡é˜…è¯»](./README_zh.md)\n\n<div align=\"center\">\n<img src=resources/logo.svg width=\"50%\"/>\n</div>\n<p align=\"center\">\n<a href=\"https://huggingface.co/spaces/THUDM/CogVideoX-5B\" target=\"_blank\"> ğŸ¤— Huggingface Space</a> ã¾ãŸã¯ <a href=\"https://modelscope.cn/studios/ZhipuAI/CogVideoX-5b-demo\" target=\"_blank\"> ğŸ¤– ModelScope Space</a> ã§ CogVideoX-5B ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ä½“é¨“ã—ã¦ãã ã•ã„\n</p>\n<p align=\"center\">\nğŸ“š <a href=\"https://arxiv.org/abs/2408.06072\" target=\"_blank\">è«–æ–‡</a>ã¨<a href=\"https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh\" target=\"_blank\">ä½¿ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ</a>ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n</p>\n<p align=\"center\">\n    ğŸ‘‹ <a href=\"resources/WECHAT.md\" target=\"_blank\">WeChat</a> ã¨ <a href=\"https://discord.gg/dCGfUsagrD\" target=\"_blank\">Discord</a> ã«å‚åŠ \n</p>\n<p align=\"center\">\nğŸ“ <a href=\"https://chatglm.cn/video?lang=en?fr=osm_cogvideo\">æ¸…å½±</a> ã¨ <a href=\"https://open.bigmodel.cn/?utm_campaign=open&_channel_track_key=OWTVNma9\">APIãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </a> ã‚’è¨ªå•ã—ã¦ã€ã‚ˆã‚Šå¤§è¦æ¨¡ãªå•†ç”¨ãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä½“é¨“.\n</p>\n\n## æ›´æ–°ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n- ğŸ”¥ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2025/01/08```: ç§ãŸã¡ã¯`diffusers`ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸ`Lora`å¾®èª¿æ•´ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ã‚ˆã‚Šå°‘ãªã„VRAMï¼ˆãƒ“ãƒ‡ã‚ªãƒ¡ãƒ¢ãƒªï¼‰ã§å‹•ä½œã—ã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](finetune/README_ja.md)ã‚’ã”è¦§ãã ã•ã„ã€‚\n- ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/11/15```: `CogVideoX1.5`ãƒ¢ãƒ‡ãƒ«ã®diffusersãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚ã‚ãšã‹ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã§ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾åˆ©ç”¨å¯èƒ½ã§ã™ã€‚\n- ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/11/08```: `CogVideoX1.5` ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚CogVideoX1.5 ã¯ CogVideoX ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™ã€‚\nCogVideoX1.5-5B ã‚·ãƒªãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ã¯ã€10ç§’ é•·ã®å‹•ç”»ã¨ã‚ˆã‚Šé«˜ã„è§£åƒåº¦ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€`CogVideoX1.5-5B-I2V` ã¯ä»»æ„ã®è§£åƒåº¦ã§ã®å‹•ç”»ç”Ÿæˆã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚\nSAT ã‚³ãƒ¼ãƒ‰ã¯ã™ã§ã«æ›´æ–°ã•ã‚Œã¦ãŠã‚Šã€`diffusers` ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ç¾åœ¨é©å¿œä¸­ã§ã™ã€‚\nSAT ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ‰ã¯ [ã“ã¡ã‚‰](https://huggingface.co/THUDM/CogVideoX1.5-5B-SAT) ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚\n- ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/10/13```: ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€å˜ä¸€ã®4090 GPUã§`CogVideoX-5B`\n  ã‚’å¾®èª¿æ•´ã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ [cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory)\n  ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚è¤‡æ•°ã®è§£åƒåº¦ã§ã®å¾®èª¿æ•´ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ãœã²ã”åˆ©ç”¨ãã ã•ã„ï¼\n- ğŸ”¥**ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/10/10```:\n  æŠ€è¡“å ±å‘Šæ›¸ã‚’æ›´æ–°ã—ã€ã‚ˆã‚Šè©³ç´°ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æƒ…å ±ã¨ãƒ‡ãƒ¢ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚\n- ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/10/10```: æŠ€è¡“å ±å‘Šæ›¸ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚[ã“ã¡ã‚‰](https://arxiv.org/pdf/2408.06072)\n  ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã”è¦§ãã ã•ã„ã€‚ã•ã‚‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®è©³ç´°ã¨ãƒ‡ãƒ¢ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¢ã‚’è¦‹ã‚‹ã«ã¯[ã“ã¡ã‚‰](https://yzy-thu.github.io/CogVideoX-demo/)\n  ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\n- ğŸ”¥**ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/10/09```: é£›æ›¸ã®[æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh)\n  ã§CogVideoXã®å¾®èª¿æ•´ã‚¬ã‚¤ãƒ‰ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚åˆ†é…ã®è‡ªç”±åº¦ã‚’ã•ã‚‰ã«é«˜ã‚ã‚‹ãŸã‚ã€å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã®ã™ã¹ã¦ã®ä¾‹ãŒå®Œå…¨ã«å†ç¾å¯èƒ½ã§ã™ã€‚\n- ğŸ”¥**ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/9/19```: CogVideoXã‚·ãƒªãƒ¼ã‚ºã®ç”»åƒç”Ÿæˆãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ« **CogVideoX-5B-I2V**\n  ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ç”»åƒã‚’èƒŒæ™¯å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¯ãƒ¼ãƒ‰ã¨çµ„ã¿åˆã‚ã›ã¦ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã€ã‚ˆã‚Šé«˜ã„åˆ¶å¾¡æ€§ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€CogVideoXã‚·ãƒªãƒ¼ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ“ãƒ‡ã‚ªç”Ÿæˆã€ãƒ“ãƒ‡ã‚ªã®ç¶™ç¶šã€ç”»åƒã‹ã‚‰ãƒ“ãƒ‡ã‚ªç”Ÿæˆã®3ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã®[ä½“é¨“](https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space)\n  ã‚’ãŠæ¥½ã—ã¿ãã ã•ã„ã€‚\n- ğŸ”¥ **ãƒ‹ãƒ¥ãƒ¼ã‚¹**: ```2024/9/19```:\n  CogVideoXã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã§ãƒ“ãƒ‡ã‚ªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆè¨˜è¿°ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ« [CogVLM2-Caption](https://huggingface.co/THUDM/cogvlm2-llama3-caption)\n  ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚\n- ğŸ”¥ ```2024/8/27```: CogVideoXã‚·ãƒªãƒ¼ã‚ºã®ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ« **CogVideoX-5B**\n  ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–æ€§èƒ½ã‚’å¤§å¹…ã«æœ€é©åŒ–ã—ã€æ¨è«–ã®ãƒãƒ¼ãƒ‰ãƒ«ã‚’å¤§å¹…ã«ä¸‹ã’ã¾ã—ãŸã€‚`GTX 1080TI` ãªã©ã®æ—§å‹GPUã§\n  **CogVideoX-2B** ã‚’ã€`RTX 3060` ãªã©ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—GPUã§ **CogVideoX-5B**\n  ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚ä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã«ã€[è¦ä»¶](requirements.txt)\n  ã‚’å³å®ˆã—ã€æ¨è«–ã‚³ãƒ¼ãƒ‰ã¯ [cli_demo](inference/cli_demo.py) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚ã•ã‚‰ã«ã€**CogVideoX-2B** ãƒ¢ãƒ‡ãƒ«ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒ\n  **Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹** ã«å¤‰æ›´ã•ã‚Œã¾ã—ãŸã€‚\n- ğŸ”¥ ```2024/8/6```: **CogVideoX-2B** ç”¨ã® **3D Causal VAE** ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ“ãƒ‡ã‚ªã‚’ã»ã¼ç„¡æå¤±ã§å†æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n- ğŸ”¥ ```2024/8/6```: CogVideoXã‚·ãƒªãƒ¼ã‚ºã®ãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã€**CogVideoX-2B** ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸã€‚\n- ğŸŒ± **ã‚½ãƒ¼ã‚¹**: ```2022/5/19```: CogVideoãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã—ãŸï¼ˆç¾åœ¨ã€`CogVideo`\n  ãƒ–ãƒ©ãƒ³ãƒã§ç¢ºèªã§ãã¾ã™ï¼‰ã€‚ã“ã‚Œã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«åŸºã¥ãåˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æŠ€è¡“çš„ãªè©³ç´°ã«ã¤ã„ã¦ã¯ã€[ICLR'23è«–æ–‡](https://arxiv.org/abs/2205.15868)\n  ã‚’ã”è¦§ãã ã•ã„ã€‚\n\n**ã‚ˆã‚Šå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ãŒã€ã‚ˆã‚Šå¤§ããªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ç™»å ´äºˆå®šã§ã™ã€‚ãŠæ¥½ã—ã¿ã«ï¼**\n\n## ç›®æ¬¡\n\nç‰¹å®šã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚¸ãƒ£ãƒ³ãƒ—ï¼š\n\n- [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)\n  - [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–](#ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–)\n  - [SAT](#sat)\n  - [Diffusers](#diffusers)\n- [Gallery](#gallery)\n  - [CogVideoX-5B](#cogvideox-5b)\n  - [CogVideoX-2B](#cogvideox-2b)\n- [ãƒ¢ãƒ‡ãƒ«ç´¹ä»‹](#ãƒ¢ãƒ‡ãƒ«ç´¹ä»‹)\n- [å‹å¥½çš„ãƒªãƒ³ã‚¯](#å‹å¥½çš„ãƒªãƒ³ã‚¯)\n- [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ](#ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ )\n  - [Colabã§ã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#colabã§ã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)\n  - [Inference](#inference)\n  - [finetune](#finetune)\n  - [sat](#sat-1)\n  - [ãƒ„ãƒ¼ãƒ«](#ãƒ„ãƒ¼ãƒ«)\n- [CogVideo(ICLR'23)](#cogvideoiclr23)\n- [å¼•ç”¨](#å¼•ç”¨)\n- [ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å¥‘ç´„](#ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å¥‘ç´„)\n\n## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n\n### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–\n\nãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€[ã“ã¡ã‚‰](inference/convert_demo.py)\nã‚’å‚è€ƒã«ã—ã¦ã€GLM-4ï¼ˆã¾ãŸã¯åŒç­‰ã®è£½å“ã€ä¾‹ãˆã°GPT-4ï¼‰ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã©ã®ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹ã‹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚ã“ã‚Œã¯éå¸¸ã«é‡è¦ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯é•·ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€è‰¯ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒãƒ“ãƒ‡ã‚ªç”Ÿæˆã®å“è³ªã«ç›´æ¥å½±éŸ¿ã‚’ä¸ãˆã¾ã™ã€‚\n\n### SAT\n\n[sat_demo](sat/README.md) ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãã ã•ã„:\nSATã‚¦ã‚§ã‚¤ãƒˆã®æ¨è«–ã‚³ãƒ¼ãƒ‰ã¨å¾®èª¿æ•´ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚CogVideoXãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«åŸºã¥ã„ã¦æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚é©æ–°çš„ãªç ”ç©¶è€…ã¯ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦è¿…é€Ÿãªã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¨é–‹ç™ºã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n### Diffusers\n\n```\npip install -r requirements.txt\n```\n\næ¬¡ã« [diffusers_demo](inference/cli_demo.py) ã‚’å‚ç…§ã—ã¦ãã ã•ã„: æ¨è«–ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ãªèª¬æ˜ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ä¸€èˆ¬çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„å‘³ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã¦ã„ã¾ã™ã€‚\n\né‡å­åŒ–æ¨è«–ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao/) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚Diffusers\nã¨ TorchAO ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€é‡å­åŒ–æ¨è«–ã‚‚å¯èƒ½ã¨ãªã‚Šã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„æ¨è«–ã‚„ã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«å ´åˆã«ã‚ˆã£ã¦ã¯é€Ÿåº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚A100\nãŠã‚ˆã³ H100\nä¸Šã§ã®ã•ã¾ã–ã¾ãªè¨­å®šã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªãŠã‚ˆã³æ™‚é–“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Œå…¨ãªãƒªã‚¹ãƒˆã¯ã€[diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao)\nã«å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n## Gallery\n\n### CogVideoX-5B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/cf5953ea-96d3-48fd-9907-c4708752c714\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/fe0a78e6-b669-4800-8cf0-b5f9b5145b52\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/c182f606-8f8c-421d-b414-8487070fcfcb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/7db2bbce-194d-434d-a605-350254b6c298\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/62b01046-8cab-44cc-bd45-4d965bb615ec\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/d78e552a-4b3f-4b81-ac3f-3898079554f6\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/30894f12-c741-44a2-9e6e-ddcacc231e5b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/926575ca-7150-435b-a0ff-4900a963297b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\n### CogVideoX-2B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/ea3af39a-3160-4999-90ec-2f7863c5b0e9\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/9de41efd-d4d1-4095-aeda-246dd834e91d\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/941d6661-6a8d-4a1b-b912-59606f0b2841\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/938529c4-91ae-4f60-b96b-3c3947fa63cb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\nã‚®ãƒ£ãƒ©ãƒªãƒ¼ã®å¯¾å¿œã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€[ã“ã¡ã‚‰](resources/galary_prompt.md)ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„\n\n## ãƒ¢ãƒ‡ãƒ«ç´¹ä»‹\n\nCogVideoXã¯ã€[æ¸…å½±](https://chatglm.cn/video?fr=osm_cogvideox) ã¨åŒæºã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ç‰ˆãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚\nä»¥ä¸‹ã®è¡¨ã«ã€æä¾›ã—ã¦ã„ã‚‹ãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬æƒ…å ±ã‚’ç¤ºã—ã¾ã™:\n\n<table style=\"border-collapse: collapse; width: 100%;\">\n  <tr>\n    <th style=\"text-align: center;\">ãƒ¢ãƒ‡ãƒ«å</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B (æœ€æ–°)</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B-I2V (æœ€æ–°)</th>\n    <th style=\"text-align: center;\">CogVideoX-2B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B-I2V</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å…¬é–‹æ—¥</td>\n    <th style=\"text-align: center;\">2024å¹´11æœˆ8æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´11æœˆ8æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´8æœˆ6æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´8æœˆ27æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´9æœˆ19æ—¥</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ“ãƒ‡ã‚ªè§£åƒåº¦</td>\n    <td colspan=\"1\" style=\"text-align: center;\">1360 * 768</td>\n    <td colspan=\"1\" style=\"text-align: center;\"> Min(W, H) = 768 <br> 768 â‰¤ Max(W, H) â‰¤ 1360 <br> Max(W, H) % 16 = 0 </td>\n    <td colspan=\"3\" style=\"text-align: center;\">720 * 480</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">æ¨è«–ç²¾åº¦</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16(æ¨å¥¨)</b>, FP16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼ŒINT4éå¯¾å¿œ</td>\n    <td style=\"text-align: center;\"><b>FP16*(æ¨å¥¨)</b>, BF16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼ŒINT4éå¯¾å¿œ</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16(æ¨å¥¨)</b>, FP16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼ŒINT4éå¯¾å¿œ</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å˜ä¸€GPUãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡<br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 76GB <br><b>diffusers BF16ï¼š10GBã‹ã‚‰*</b><br><b>diffusers INT8(torchao)ï¼š7GBã‹ã‚‰*</b></td>\n    <td style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> FP16: 18GB <br><b>diffusers FP16: 4GBä»¥ä¸Š* </b><br><b>diffusers INT8(torchao): 3.6GBä»¥ä¸Š*</b></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 26GB <br><b>diffusers BF16 : 5GBä»¥ä¸Š* </b><br><b>diffusers INT8(torchao): 4.4GBä»¥ä¸Š* </b></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">è¤‡æ•°GPUæ¨è«–ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 24GB* using diffusers</b><br></td>\n    <td style=\"text-align: center;\"><b>FP16: 10GB* diffusersä½¿ç”¨</b><br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 15GB* diffusersä½¿ç”¨</b><br></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">æ¨è«–é€Ÿåº¦<br>(Step = 50, FP/BF16)</td>\n    <td colspan=\"2\" style=\"text-align: center;\">ã‚·ãƒ³ã‚°ãƒ«A100: ~1000ç§’(5ç§’ãƒ“ãƒ‡ã‚ª)<br>ã‚·ãƒ³ã‚°ãƒ«H100: ~550ç§’(5ç§’ãƒ“ãƒ‡ã‚ª)</td>\n    <td style=\"text-align: center;\">ã‚·ãƒ³ã‚°ãƒ«A100: ~90ç§’<br>ã‚·ãƒ³ã‚°ãƒ«H100: ~45ç§’</td>\n    <td colspan=\"2\" style=\"text-align: center;\">ã‚·ãƒ³ã‚°ãƒ«A100: ~180ç§’<br>ã‚·ãƒ³ã‚°ãƒ«H100: ~90ç§’</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨€èª</td>\n    <td colspan=\"5\" style=\"text-align: center;\">è‹±èª*</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•ã®ä¸Šé™</td>\n    <td colspan=\"2\" style=\"text-align: center;\">224ãƒˆãƒ¼ã‚¯ãƒ³</td>\n    <td colspan=\"3\" style=\"text-align: center;\">226ãƒˆãƒ¼ã‚¯ãƒ³</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ“ãƒ‡ã‚ªé•·ã•</td>\n    <td colspan=\"2\" style=\"text-align: center;\">5ç§’ã¾ãŸã¯10ç§’</td>\n    <td colspan=\"3\" style=\"text-align: center;\">6ç§’</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ</td>\n    <td colspan=\"2\" style=\"text-align: center;\">16ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’</td>\n    <td colspan=\"3\" style=\"text-align: center;\">8ãƒ•ãƒ¬ãƒ¼ãƒ /ç§’</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°</td>\n    <td colspan=\"2\" style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_sincos_pos_embed</td> \n    <td style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_rope_pos_embed + learnable_pos_embed</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ (Diffusers)</td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-2b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-2b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-2b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸŸ£ WiseModel</a></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ (SAT)</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5b-SAT\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸŸ£ WiseModel</a></td>\n    <td colspan=\"3\" style=\"text-align: center;\"><a href=\"./sat/README_zh.md\">SAT</a></td>\n  </tr>\n</table>\n\n**ãƒ‡ãƒ¼ã‚¿è§£èª¬**\n\n+ diffusersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆã™ã‚‹éš›ã«ã¯ã€`diffusers`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæä¾›ã™ã‚‹å…¨ã¦ã®æœ€é©åŒ–ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã¾ã™ã€‚ã“ã®æ–¹æ³•ã¯\n  **NVIDIA A100 / H100**ä»¥å¤–ã®ãƒ‡ãƒã‚¤ã‚¹ã§ã®ãƒ¡ãƒ¢ãƒª/ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã®ãƒ†ã‚¹ãƒˆã¯è¡Œã£ã¦ã„ã¾ã›ã‚“ã€‚é€šå¸¸ã€ã“ã®æ–¹æ³•ã¯**NVIDIA\n  Ampereã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**\n  ä»¥ä¸Šã®å…¨ã¦ã®ãƒ‡ãƒã‚¤ã‚¹ã«é©å¿œã§ãã¾ã™ã€‚æœ€é©åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹ã¨ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã¯å€å¢—ã—ã€ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯è¡¨ã®3å€ã«ãªã‚Šã¾ã™ãŒã€é€Ÿåº¦ã¯ç´„3ã€œ4å€å‘ä¸Šã—ã¾ã™ã€‚ä»¥ä¸‹ã®æœ€é©åŒ–ã‚’éƒ¨åˆ†çš„ã«ç„¡åŠ¹ã«ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™:\n\n```\npipe.enable_sequential_cpu_offload()\npipe.vae.enable_slicing()\npipe.vae.enable_tiling()\n```\n\n+ ãƒãƒ«ãƒGPUã§æ¨è«–ã™ã‚‹å ´åˆã€`enable_sequential_cpu_offload()`æœ€é©åŒ–ã‚’ç„¡åŠ¹ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n+ INT8ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã¨æ¨è«–é€Ÿåº¦ãŒä½ä¸‹ã—ã¾ã™ãŒã€ã“ã‚Œã¯ãƒ¡ãƒ¢ãƒªã®å°‘ãªã„GPUã§æ­£å¸¸ã«æ¨è«–ã‚’è¡Œã„ã€ãƒ“ãƒ‡ã‚ªå“è³ªã®æå¤±ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ãŸã‚ã®æªç½®ã§ã™ã€‚æ¨è«–é€Ÿåº¦ã¯å¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚\n+ CogVideoX-2Bãƒ¢ãƒ‡ãƒ«ã¯`FP16`ç²¾åº¦ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šã€CogVideoX-5Bãƒ¢ãƒ‡ãƒ«ã¯`BF16`\n  ç²¾åº¦ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã¾ã™ã€‚æ¨è«–æ™‚ã«ã¯ãƒ¢ãƒ‡ãƒ«ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸç²¾åº¦ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n+ [PytorchAO](https://github.com/pytorch/ao)ãŠã‚ˆã³[Optimum-quanto](https://github.com/huggingface/optimum-quanto/)\n  ã¯ã€CogVideoXã®ãƒ¡ãƒ¢ãƒªè¦ä»¶ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã«ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒã€ãŠã‚ˆã³VAEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é‡å­åŒ–ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç„¡æ–™ã®T4\n  Colabã‚„ã‚ˆã‚Šå°‘ãªã„ãƒ¡ãƒ¢ãƒªã®GPUã§ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚åŒæ§˜ã«é‡è¦ãªã®ã¯ã€TorchAOã®é‡å­åŒ–ã¯`torch.compile`\n  ã¨å®Œå…¨ã«äº’æ›æ€§ãŒã‚ã‚Šã€æ¨è«–é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ç‚¹ã§ã™ã€‚`NVIDIA H100`ãŠã‚ˆã³ãã‚Œä»¥ä¸Šã®ãƒ‡ãƒã‚¤ã‚¹ã§ã¯`FP8`\n  ç²¾åº¦ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã¯ã€`torch`ã€`torchao` Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚`CUDA 12.4`ã®ä½¿ç”¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n+ æ¨è«–é€Ÿåº¦ãƒ†ã‚¹ãƒˆã‚‚åŒæ§˜ã«ã€ä¸Šè¨˜ã®ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’ä½¿ç”¨ã—ãªã„å ´åˆã€æ¨è«–é€Ÿåº¦ã¯ç´„10ï¼…å‘ä¸Šã—ã¾ã™ã€‚\n  `diffusers`ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã®ã¿ãŒé‡å­åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n+ ãƒ¢ãƒ‡ãƒ«ã¯è‹±èªå…¥åŠ›ã®ã¿ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€ä»–ã®è¨€èªã¯å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ã‚’é€šã˜ã¦è‹±èªã«ç¿»è¨³ã§ãã¾ã™ã€‚\n\n\n## å‹å¥½çš„ãƒªãƒ³ã‚¯\n\nã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‹ã‚‰ã®è²¢çŒ®ã‚’å¤§æ­“è¿ã—ã€ç§ãŸã¡ã‚‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ç©æ¥µçš„ã«è²¢çŒ®ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ä½œå“ã¯ã™ã§ã«CogVideoXã«å¯¾å¿œã—ã¦ãŠã‚Šã€ãœã²ã”åˆ©ç”¨ãã ã•ã„ï¼š\n\n+ [CogVideoX-Fun](https://github.com/aigc-apps/CogVideoX-Fun):\n  CogVideoX-Funã¯ã€CogVideoXã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åŸºã«ã—ãŸæ”¹è‰¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã€è‡ªç”±ãªè§£åƒåº¦ã¨è¤‡æ•°ã®èµ·å‹•æ–¹æ³•ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n+ [CogStudio](https://github.com/pinokiofactory/cogstudio): CogVideo ã® Gradio Web UI ã®åˆ¥ã®ãƒªãƒã‚¸ãƒˆãƒªã€‚ã‚ˆã‚Šé«˜æ©Ÿèƒ½ãª Web\n  UI ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n+ [Xorbits Inference](https://github.com/xorbitsai/inference):\n  å¼·åŠ›ã§åŒ…æ‹¬çš„ãªåˆ†æ•£æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚„æœ€æ–°ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚\n+ [ComfyUI-CogVideoXWrapper](https://github.com/kijai/ComfyUI-CogVideoXWrapper)\n  ComfyUIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã€CogVideoXã‚’ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«çµ±åˆã—ã¾ã™ã€‚\n+ [VideoSys](https://github.com/NUS-HPC-AI-Lab/VideoSys): VideoSysã¯ã€ä½¿ã„ã‚„ã™ãé«˜æ€§èƒ½ãªãƒ“ãƒ‡ã‚ªç”Ÿæˆã‚¤ãƒ³ãƒ•ãƒ©ã‚’æä¾›ã—ã€æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚„æŠ€è¡“ã‚’ç¶™ç¶šçš„ã«çµ±åˆã—ã¦ã„ã¾ã™ã€‚\n+ [AutoDLã‚¤ãƒ¡ãƒ¼ã‚¸](https://www.codewithgpu.com/i/THUDM/CogVideo/CogVideoX-5b-demo): ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¡ãƒ³ãƒãƒ¼ãŒæä¾›ã™ã‚‹Huggingface\n  Spaceã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã€‚\n+ [ã‚¤ãƒ³ãƒ†ãƒªã‚¢ãƒ‡ã‚¶ã‚¤ãƒ³å¾®èª¿æ•´ãƒ¢ãƒ‡ãƒ«](https://huggingface.co/collections/bertjiazheng/koolcogvideox-66e4762f53287b7f39f8f3ba):\n  ã¯ã€CogVideoXã‚’åŸºç›¤ã«ã—ãŸå¾®èª¿æ•´ãƒ¢ãƒ‡ãƒ«ã§ã€ã‚¤ãƒ³ãƒ†ãƒªã‚¢ãƒ‡ã‚¶ã‚¤ãƒ³å°‚ç”¨ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n+ [xDiT](https://github.com/xdit-project/xDiT):\n  xDiTã¯ã€è¤‡æ•°ã®GPUã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸Šã§DiTsã‚’ä¸¦åˆ—æ¨è«–ã™ã‚‹ãŸã‚ã®ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚xDiTã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ç”»åƒãŠã‚ˆã³ãƒ“ãƒ‡ã‚ªç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚\n+ [CogVideoX-Interpolation](https://github.com/feizc/CogvideX-Interpolation):\n  ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“ç”Ÿæˆã«ãŠã„ã¦ã€ã‚ˆã‚Šå¤§ããªæŸ”è»Ÿæ€§ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã€CogVideoXæ§‹é€ ã‚’åŸºã«ã—ãŸä¿®æ­£ç‰ˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚\n+ [DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio): DiffSynth\n  Studioã¯ã€æ‹¡æ•£ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã€UNetã€VAEãªã©ã‚’å«ã‚€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å†æ§‹ç¯‰ã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ã¨ã®äº’æ›æ€§ã‚’ç¶­æŒã—ã¤ã¤ã€è¨ˆç®—æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯CogVideoXã«é©å¿œã—ã¦ã„ã¾ã™ã€‚\n+ [CogVideoX-Controlnet](https://github.com/TheDenk/cogvideox-controlnet): CogVideoXãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€ã‚·ãƒ³ãƒ—ãƒ«ãªControlNetãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã€‚\n+ [VideoTuna](https://github.com/VideoVerses/VideoTuna): VideoTuna ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ“ãƒ‡ã‚ªã€ç”»åƒã‹ã‚‰ãƒ“ãƒ‡ã‚ªã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒç”Ÿæˆã®ãŸã‚ã®è¤‡æ•°ã®AIãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã—ãŸæœ€åˆã®ãƒªãƒã‚¸ãƒˆãƒªã§ã™ã€‚\n+ [ConsisID](https://github.com/PKU-YuanGroup/ConsisID): ä¸€è²«æ€§ã®ã‚ã‚‹é¡”ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ã€å‘¨æ³¢æ•°åˆ†è§£ã‚’ä½¿ç”¨ã™ã‚‹CogVideoX-5Bã«åŸºã¥ã„ãŸã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¿æŒå‹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€‚\n+ [ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://www.youtube.com/watch?v=5UCkMzP2VLE&ab_channel=SECourses): WindowsãŠã‚ˆã³ã‚¯ãƒ©ã‚¦ãƒ‰ã§ã®CogVideoX1.5-5B-I2Vãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨æœ€é©åŒ–ã«é–¢ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰ã€‚[FurkanGozukara](https://github.com/FurkanGozukara)æ°ã®å°½åŠ›ã¨ã‚µãƒãƒ¼ãƒˆã«æ„Ÿè¬ã„ãŸã—ã¾ã™ï¼\n\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ \n\nã“ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã¯ã€**CogVideoX** ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•ã¨å¾®èª¿æ•´ã®ä¾‹ã‚’è¿…é€Ÿã«é–‹å§‹ã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚\n\n### Colabã§ã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n\nç„¡æ–™ã®Colab T4ä¸Šã§ç›´æ¥å®Ÿè¡Œã§ãã‚‹3ã¤ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n\n+ [CogVideoX-5B-T2V-Colab.ipynb](https://colab.research.google.com/drive/1pCe5s0bC_xuXbBlpvIH1z0kfdTLQPzCS?usp=sharing):\n  CogVideoX-5B ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ“ãƒ‡ã‚ªã¸ã®ç”Ÿæˆç”¨Colabã‚³ãƒ¼ãƒ‰ã€‚\n+ [CogVideoX-5B-T2V-Int8-Colab.ipynb](https://colab.research.google.com/drive/1DUffhcjrU-uz7_cpuJO3E_D4BaJT7OPa?usp=sharing):\n  CogVideoX-5B ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ“ãƒ‡ã‚ªã¸ã®é‡å­åŒ–æ¨è«–ç”¨Colabã‚³ãƒ¼ãƒ‰ã€‚1å›ã®å®Ÿè¡Œã«ç´„30åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚\n+ [CogVideoX-5B-I2V-Colab.ipynb](https://colab.research.google.com/drive/17CqYCqSwz39nZAX2YyonDxosVKUZGzcX?usp=sharing):\n  CogVideoX-5B ç”»åƒã‹ã‚‰ãƒ“ãƒ‡ã‚ªã¸ã®ç”Ÿæˆç”¨Colabã‚³ãƒ¼ãƒ‰ã€‚\n+ [CogVideoX-5B-V2V-Colab.ipynb](https://colab.research.google.com/drive/1comfGAUJnChl5NwPuO8Ox5_6WCy4kbNN?usp=sharing):\n  CogVideoX-5B ãƒ“ãƒ‡ã‚ªã‹ã‚‰ãƒ“ãƒ‡ã‚ªã¸ã®ç”Ÿæˆç”¨Colabã‚³ãƒ¼ãƒ‰ã€‚\n\n### Inference\n\n+ [cli_demo](inference/cli_demo.py): æ¨è«–ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ãªèª¬æ˜ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ä¸€èˆ¬çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„å‘³ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã¦ã„ã¾ã™ã€‚\n+ [cli_demo_quantization](inference/cli_demo_quantization.py):\n  é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚³ãƒ¼ãƒ‰ã§ã€ä½ãƒ¡ãƒ¢ãƒªã®ãƒ‡ãƒã‚¤ã‚¹ã§ã‚‚å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚ã¾ãŸã€ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¦ã€FP8 ç²¾åº¦ã® CogVideoX\n  ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n+ [diffusers_vae_demo](inference/cli_vae_demo.py): VAEæ¨è«–ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œã«ã¯ç¾åœ¨71GBã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ã§ã™ãŒã€å°†æ¥çš„ã«ã¯æœ€é©åŒ–ã•ã‚Œã‚‹äºˆå®šã§ã™ã€‚\n+ [space demo](inference/gradio_composite_demo): Huggingface Spaceã¨åŒã˜GUIã‚³ãƒ¼ãƒ‰ã§ã€ãƒ•ãƒ¬ãƒ¼ãƒ è£œé–“ã‚„è¶…è§£åƒãƒ„ãƒ¼ãƒ«ãŒçµ„ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\n<div style=\"text-align: center;\">\n    <img src=\"resources/web_demo.png\" style=\"width: 100%; height: auto;\" />\n</div>\n\n+ [convert_demo](inference/convert_demo.py):\n  ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’CogVideoXã«é©ã—ãŸå½¢å¼ã«å¤‰æ›ã™ã‚‹æ–¹æ³•ã€‚CogVideoXã¯é•·ã„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åˆ†å¸ƒã¨ä¸€è‡´ã•ã›ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯GLM-4ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€GPTã€Geminiãªã©ã®ä»–ã®LLMã«ç½®ãæ›ãˆã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n+ [gradio_web_demo](inference/gradio_web_demo.py): CogVideoX-2B / 5B ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€ã‚·ãƒ³ãƒ—ãƒ«ãª\n  Gradio Web UI ãƒ‡ãƒ¢ã§ã™ã€‚ç§ãŸã¡ã® Huggingface Space ã¨åŒæ§˜ã«ã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ Web ãƒ‡ãƒ¢ã‚’èµ·å‹•ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n### finetune\n\n+ [train_cogvideox_lora](finetune/README_ja.md): CogVideoX diffusers å¾®èª¿æ•´æ–¹æ³•ã®è©³ç´°ãªèª¬æ˜ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§\n  CogVideoX ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n### sat\n\n+ [sat_demo](sat/README.md):\n  SATã‚¦ã‚§ã‚¤ãƒˆã®æ¨è«–ã‚³ãƒ¼ãƒ‰ã¨å¾®èª¿æ•´ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚CogVideoXãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«åŸºã¥ã„ã¦æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚é©æ–°çš„ãªç ”ç©¶è€…ã¯ã€ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦è¿…é€Ÿãªã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¨é–‹ç™ºã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n### ãƒ„ãƒ¼ãƒ«\n\nã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«å¤‰æ›/ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆãªã©ã®ãƒ„ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚\n\n+ [convert_weight_sat2hf](tools/convert_weight_sat2hf.py): SAT ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ Huggingface ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã«å¤‰æ›ã—ã¾ã™ã€‚\n+ [caption_demo](tools/caption/README_ja.md): Caption ãƒ„ãƒ¼ãƒ«ã€ãƒ“ãƒ‡ã‚ªã‚’ç†è§£ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã§å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚\n+ [export_sat_lora_weight](tools/export_sat_lora_weight.py): SAT ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ„ãƒ¼ãƒ«ã€SAT Lora\n  Adapter ã‚’ diffusers å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n+ [load_cogvideox_lora](tools/load_cogvideox_lora.py): diffusers ç‰ˆã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ Lora Adapter\n  ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ‰ã€‚\n+ [llm_flux_cogvideox](tools/llm_flux_cogvideox/llm_flux_cogvideox.py): ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ã‚«ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« +\n  Flux + CogVideoX ã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•çš„ã«å‹•ç”»ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n+ [parallel_inference_xdit](tools/parallel_inference/parallel_inference_xdit.py)ï¼š\n  [xDiT](https://github.com/xdit-project/xDiT)\n  ã«ã‚ˆã£ã¦ã‚µãƒãƒ¼ãƒˆã•ã‚Œã€ãƒ“ãƒ‡ã‚ªç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’è¤‡æ•°ã® GPU ã§ä¸¦åˆ—åŒ–ã—ã¾ã™ã€‚\n+ [cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory): CogVideoXã®ä½ã‚³ã‚¹ãƒˆå¾®èª¿æ•´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€\n  `diffusers`ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã«é©å¿œã—ã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šå¤šãã®è§£åƒåº¦ã«å¯¾å¿œã—ã€å˜ä¸€ã®4090 GPUã§CogVideoX-5Bã®å¾®èª¿æ•´ãŒå¯èƒ½ã§ã™ã€‚\n\n## CogVideo(ICLR'23)\n\nè«–æ–‡ã®å…¬å¼ãƒªãƒã‚¸ãƒˆãƒª: [CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/abs/2205.15868)\nã¯ [CogVideo branch](https://github.com/THUDM/CogVideo/tree/CogVideo) ã«ã‚ã‚Šã¾ã™ã€‚\n\n**CogVideoã¯æ¯”è¼ƒçš„é«˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã®ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚**\n32ãƒ•ãƒ¬ãƒ¼ãƒ ã®4ç§’é–“ã®ã‚¯ãƒªãƒƒãƒ—ãŒä»¥ä¸‹ã«ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n![High-frame-rate sample](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/appendix-sample-highframerate.png)\n\n![Intro images](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/intro-image.png)\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/2fa19651-e925-4a2a-b8d6-b3f216d490ba\" width=\"80%\" controls autoplay></video>\n</div>\n\n\nCogVideoã®ãƒ‡ãƒ¢ã¯ [https://models.aminer.cn/cogvideo](https://models.aminer.cn/cogvideo/) ã§ä½“é¨“ã§ãã¾ã™ã€‚\n*å…ƒã®å…¥åŠ›ã¯ä¸­å›½èªã§ã™ã€‚*\n\n## å¼•ç”¨\n\nğŸŒŸ ç§ãŸã¡ã®ä»•äº‹ãŒå½¹ç«‹ã¤ã¨æ€ã‚ã‚ŒãŸå ´åˆã€ãœã²ã‚¹ã‚¿ãƒ¼ã‚’ä»˜ã‘ã¦ã„ãŸã ãã€è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ãã ã•ã„ã€‚\n\n```\n@article{yang2024cogvideox,\n  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},\n  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},\n  journal={arXiv preprint arXiv:2408.06072},\n  year={2024}\n}\n@article{hong2022cogvideo,\n  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},\n  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},\n  journal={arXiv preprint arXiv:2205.15868},\n  year={2022}\n}\n```\n\nã‚ãªãŸã®è²¢çŒ®ã‚’ãŠå¾…ã¡ã—ã¦ã„ã¾ã™ï¼è©³ç´°ã¯[ã“ã¡ã‚‰](resources/contribute_ja.md)ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚\n\n## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å¥‘ç´„\n\nã“ã®ãƒªãƒã‚¸ãƒˆãƒªã®ã‚³ãƒ¼ãƒ‰ã¯ [Apache 2.0 License](LICENSE) ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nCogVideoX-2B ãƒ¢ãƒ‡ãƒ« (å¯¾å¿œã™ã‚‹Transformersãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚„VAEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å«ã‚€) ã¯\n[Apache 2.0 License](LICENSE) ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nCogVideoX-5B ãƒ¢ãƒ‡ãƒ«ï¼ˆTransformers ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ç”»åƒç”Ÿæˆãƒ“ãƒ‡ã‚ªã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ“ãƒ‡ã‚ªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å«ã‚€ï¼‰ ã¯\n[CogVideoX LICENSE](https://huggingface.co/THUDM/CogVideoX-5b/blob/main/LICENSE) ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 24.5771484375,
          "content": "# CogVideo & CogVideoX\n\n[Read this in English](./README.md)\n\n[æ—¥æœ¬èªã§èª­ã‚€](./README_ja.md)\n\n<div align=\"center\">\n<img src=resources/logo.svg width=\"50%\"/>\n</div>\n<p align=\"center\">\nåœ¨ <a href=\"https://huggingface.co/spaces/THUDM/CogVideoX-5B\" target=\"_blank\"> ğŸ¤— Huggingface Space</a> æˆ– <a href=\"https://modelscope.cn/studios/ZhipuAI/CogVideoX-5b-demo\" target=\"_blank\"> ğŸ¤– ModelScope Space</a> åœ¨çº¿ä½“éªŒ CogVideoX-5B æ¨¡å‹\n</p>\n<p align=\"center\">\nğŸ“š æŸ¥çœ‹ <a href=\"https://arxiv.org/abs/2408.06072\" target=\"_blank\">è®ºæ–‡</a> å’Œ <a href=\"https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh\" target=\"_blank\">ä½¿ç”¨æ–‡æ¡£</a>\n</p>\n<p align=\"center\">\n    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href=\"resources/WECHAT.md\" target=\"_blank\">å¾®ä¿¡</a> å’Œ  <a href=\"https://discord.gg/dCGfUsagrD\" target=\"_blank\">Discord</a> \n</p>\n<p align=\"center\">\nğŸ“ å‰å¾€<a href=\"https://chatglm.cn/video?fr=osm_cogvideox\"> æ¸…å½±</a> å’Œ <a href=\"https://open.bigmodel.cn/?utm_campaign=open&_channel_track_key=OWTVNma9\"> APIå¹³å°</a> ä½“éªŒæ›´å¤§è§„æ¨¡çš„å•†ä¸šç‰ˆè§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚\n</p>\n\n## é¡¹ç›®æ›´æ–°\n\n- ğŸ”¥ğŸ”¥ **News**: ```2025/01/08```: æˆ‘ä»¬æ›´æ–°äº†åŸºäº`diffusers`ç‰ˆæœ¬æ¨¡å‹çš„`Lora`å¾®è°ƒä»£ç ï¼Œå ç”¨æ˜¾å­˜æ›´ä½ï¼Œè¯¦æƒ…è¯·è§[è¿™é‡Œ](finetune/README_zh.md)ã€‚\n- ğŸ”¥ **News**: ```2024/11/15```: æˆ‘ä»¬å‘å¸ƒ `CogVideoX1.5` æ¨¡å‹çš„diffusersç‰ˆæœ¬ï¼Œä»…éœ€è°ƒæ•´éƒ¨åˆ†å‚æ•°ä»…å¯æ²¿ç”¨ä¹‹å‰çš„ä»£ç ã€‚\n- ğŸ”¥ **News**: ```2024/11/08```: æˆ‘ä»¬å‘å¸ƒ `CogVideoX1.5` æ¨¡å‹ã€‚CogVideoX1.5 æ˜¯ CogVideoX å¼€æºæ¨¡å‹çš„å‡çº§ç‰ˆæœ¬ã€‚ \nCogVideoX1.5-5B ç³»åˆ—æ¨¡å‹æ”¯æŒ **10ç§’** é•¿åº¦çš„è§†é¢‘å’Œæ›´é«˜çš„åˆ†è¾¨ç‡ï¼Œå…¶ä¸­ `CogVideoX1.5-5B-I2V` æ”¯æŒ **ä»»æ„åˆ†è¾¨ç‡** çš„è§†é¢‘ç”Ÿæˆï¼ŒSATä»£ç å·²ç»æ›´æ–°ã€‚`diffusers`ç‰ˆæœ¬è¿˜åœ¨é€‚é…ä¸­ã€‚SATç‰ˆæœ¬ä»£ç å‰å¾€ [è¿™é‡Œ](https://huggingface.co/THUDM/CogVideoX1.5-5B-SAT) ä¸‹è½½ã€‚\n- ğŸ”¥**News**: ```2024/10/13```: æˆæœ¬æ›´ä½ï¼Œå•å¡4090å¯å¾®è°ƒ `CogVideoX-5B`\n  çš„å¾®è°ƒæ¡†æ¶[cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory)å·²ç»æ¨å‡ºï¼Œå¤šç§åˆ†è¾¨ç‡å¾®è°ƒï¼Œæ¬¢è¿ä½¿ç”¨ã€‚\n- ğŸ”¥ **News**: ```2024/10/10```: æˆ‘ä»¬æ›´æ–°äº†æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Š,è¯·ç‚¹å‡» [è¿™é‡Œ](https://arxiv.org/pdf/2408.06072)\n  æŸ¥çœ‹ï¼Œé™„ä¸Šäº†æ›´å¤šçš„è®­ç»ƒç»†èŠ‚å’Œdemoï¼Œå…³äºdemoï¼Œç‚¹å‡»[è¿™é‡Œ](https://yzy-thu.github.io/CogVideoX-demo/) æŸ¥çœ‹ã€‚\n- ğŸ”¥ **News**: ```2024/10/09```: æˆ‘ä»¬åœ¨é£ä¹¦[æŠ€æœ¯æ–‡æ¡£](https://zhipu-ai.feishu.cn/wiki/DHCjw1TrJiTyeukfc9RceoSRnCh\")\n  å…¬å¼€CogVideoXå¾®è°ƒæŒ‡å¯¼ï¼Œä»¥è¿›ä¸€æ­¥å¢åŠ åˆ†å‘è‡ªç”±åº¦ï¼Œå…¬å¼€æ–‡æ¡£ä¸­æ‰€æœ‰ç¤ºä¾‹å¯ä»¥å®Œå…¨å¤ç°\n- ğŸ”¥ **News**: ```2024/9/19```: æˆ‘ä»¬å¼€æº CogVideoX ç³»åˆ—å›¾ç”Ÿè§†é¢‘æ¨¡å‹ **CogVideoX-5B-I2V**\n  ã€‚è¯¥æ¨¡å‹å¯ä»¥å°†ä¸€å¼ å›¾åƒä½œä¸ºèƒŒæ™¯è¾“å…¥ï¼Œç»“åˆæç¤ºè¯ä¸€èµ·ç”Ÿæˆè§†é¢‘ï¼Œå…·æœ‰æ›´å¼ºçš„å¯æ§æ€§ã€‚\n  è‡³æ­¤ï¼ŒCogVideoXç³»åˆ—æ¨¡å‹å·²ç»æ”¯æŒæ–‡æœ¬ç”Ÿæˆè§†é¢‘ï¼Œè§†é¢‘ç»­å†™ï¼Œå›¾ç‰‡ç”Ÿæˆè§†é¢‘ä¸‰ç§ä»»åŠ¡ã€‚æ¬¢è¿å‰å¾€åœ¨çº¿[ä½“éªŒ](https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space)ã€‚\n- ğŸ”¥ **News**: ```2024/9/19```: CogVideoX è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨äºå°†è§†é¢‘æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æè¿°çš„ Caption\n  æ¨¡å‹ [CogVLM2-Caption](https://huggingface.co/THUDM/cogvlm2-llama3-caption)\n  å·²ç»å¼€æºã€‚æ¬¢è¿å‰å¾€ä¸‹è½½å¹¶ä½¿ç”¨ã€‚\n- ğŸ”¥ ```2024/8/27```:  æˆ‘ä»¬å¼€æº CogVideoX ç³»åˆ—æ›´å¤§çš„æ¨¡å‹ **CogVideoX-5B**\n  ã€‚æˆ‘ä»¬å¤§å¹…åº¦ä¼˜åŒ–äº†æ¨¡å‹çš„æ¨ç†æ€§èƒ½ï¼Œæ¨ç†é—¨æ§›å¤§å¹…é™ä½ï¼Œæ‚¨å¯ä»¥åœ¨ `GTX 1080TI` ç­‰æ—©æœŸæ˜¾å¡è¿è¡Œ **CogVideoX-2B**ï¼Œåœ¨ `RTX 3060`\n  ç­‰æ¡Œé¢ç«¯ç”œå“å¡è¿è¡Œ **CogVideoX-5B** æ¨¡å‹ã€‚ è¯·ä¸¥æ ¼æŒ‰ç…§[è¦æ±‚](requirements.txt)\n  æ›´æ–°å®‰è£…ä¾èµ–ï¼Œæ¨ç†ä»£ç è¯·æŸ¥çœ‹ [cli_demo](inference/cli_demo.py)ã€‚åŒæ—¶ï¼Œ**CogVideoX-2B** æ¨¡å‹å¼€æºåè®®å·²ç»ä¿®æ”¹ä¸º**Apache 2.0 åè®®**ã€‚\n- ğŸ”¥ ```2024/8/6```: æˆ‘ä»¬å¼€æº **3D Causal VAE**ï¼Œç”¨äº **CogVideoX-2B**ï¼Œå¯ä»¥å‡ ä¹æ— æŸåœ°é‡æ„è§†é¢‘ã€‚\n- ğŸ”¥ ```2024/8/6```: æˆ‘ä»¬å¼€æº CogVideoX ç³»åˆ—è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç¬¬ä¸€ä¸ªæ¨¡å‹, **CogVideoX-2B**ã€‚\n- ğŸŒ± **Source**: ```2022/5/19```: æˆ‘ä»¬å¼€æºäº† CogVideo è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆç°åœ¨ä½ å¯ä»¥åœ¨ `CogVideo` åˆ†æ”¯ä¸­çœ‹åˆ°ï¼‰ï¼Œè¿™æ˜¯é¦–ä¸ªå¼€æºçš„åŸºäº\n  Transformer çš„å¤§å‹æ–‡æœ¬ç”Ÿæˆè§†é¢‘æ¨¡å‹ï¼Œæ‚¨å¯ä»¥è®¿é—® [ICLR'23 è®ºæ–‡](https://arxiv.org/abs/2205.15868) æŸ¥çœ‹æŠ€æœ¯ç»†èŠ‚ã€‚\n\n## ç›®å½•\n\nè·³è½¬åˆ°æŒ‡å®šéƒ¨åˆ†ï¼š\n\n- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)\n  - [æç¤ºè¯ä¼˜åŒ–](#æç¤ºè¯ä¼˜åŒ–)\n  - [SAT](#sat)\n  - [Diffusers](#diffusers)\n- [è§†é¢‘ä½œå“](#è§†é¢‘ä½œå“)\n  - [CogVideoX-5B](#cogvideox-5b)\n  - [CogVideoX-2B](#cogvideox-2b)\n- [æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)\n- [å‹æƒ…é“¾æ¥](#å‹æƒ…é“¾æ¥)\n- [å®Œæ•´é¡¹ç›®ä»£ç ç»“æ„](#å®Œæ•´é¡¹ç›®ä»£ç ç»“æ„)\n  - [Colab å¿«é€Ÿä½¿ç”¨](#colab-å¿«é€Ÿä½¿ç”¨)\n  - [inference](#inference)\n  - [finetune](#finetune)\n  - [sat](#sat-1)\n  - [tools](#tools)\n- [CogVideo(ICLR'23)](#cogvideoiclr23)\n- [å¼•ç”¨](#å¼•ç”¨)\n- [æ¨¡å‹åè®®](#æ¨¡å‹åè®®)\n\n## å¿«é€Ÿå¼€å§‹\n\n### æç¤ºè¯ä¼˜åŒ–\n\nåœ¨å¼€å§‹è¿è¡Œæ¨¡å‹ä¹‹å‰ï¼Œè¯·å‚è€ƒ [è¿™é‡Œ](inference/convert_demo.py) æŸ¥çœ‹æˆ‘ä»¬æ˜¯æ€ä¹ˆä½¿ç”¨GLM-4(æˆ–è€…åŒçº§åˆ«çš„å…¶ä»–äº§å“ï¼Œä¾‹å¦‚GPT-4)\nå¤§æ¨¡å‹å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–çš„ï¼Œè¿™å¾ˆé‡è¦ï¼Œ\nç”±äºæ¨¡å‹æ˜¯åœ¨é•¿æç¤ºè¯ä¸‹è®­ç»ƒçš„ï¼Œä¸€ä¸ªå¥½çš„æç¤ºè¯ç›´æ¥å½±å“äº†è§†é¢‘ç”Ÿæˆçš„è´¨é‡ã€‚\n\n### SAT\n\næŸ¥çœ‹satæ–‡ä»¶å¤¹ä¸‹çš„ [sat_demo](sat/README.md)ï¼šåŒ…å«äº† SAT æƒé‡çš„æ¨ç†ä»£ç å’Œå¾®è°ƒä»£ç ï¼Œæ¨èåŸºäºæ­¤ä»£ç è¿›è¡Œ CogVideoX\næ¨¡å‹ç»“æ„çš„æ”¹è¿›ï¼Œç ”ç©¶è€…ä½¿ç”¨è¯¥ä»£ç å¯ä»¥æ›´å¥½çš„è¿›è¡Œå¿«é€Ÿçš„è¿­ä»£å’Œå¼€å‘ã€‚\n\n### Diffusers\n\n```\npip install -r requirements.txt\n```\n\næŸ¥çœ‹[diffusers_demo](inference/cli_demo.py)ï¼šåŒ…å«å¯¹æ¨ç†ä»£ç æ›´è¯¦ç»†çš„è§£é‡Šï¼ŒåŒ…æ‹¬å„ç§å…³é”®çš„å‚æ•°ã€‚\n\næ¬²äº†è§£æ›´å¤šå…³äºé‡åŒ–æ¨ç†çš„ç»†èŠ‚ï¼Œè¯·å‚è€ƒ [diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao/)ã€‚ä½¿ç”¨ Diffusers\nå’Œ TorchAOï¼Œé‡åŒ–æ¨ç†ä¹Ÿæ˜¯å¯èƒ½çš„ï¼Œè¿™å¯ä»¥å®ç°å†…å­˜é«˜æ•ˆçš„æ¨ç†ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹ç¼–è¯‘åé€Ÿåº¦æœ‰æ‰€æå‡ã€‚æœ‰å…³åœ¨ A100 å’Œ H100\nä¸Šä½¿ç”¨å„ç§è®¾ç½®çš„å†…å­˜å’Œæ—¶é—´åŸºå‡†æµ‹è¯•çš„å®Œæ•´åˆ—è¡¨ï¼Œå·²å‘å¸ƒåœ¨ [diffusers-torchao](https://github.com/sayakpaul/diffusers-torchao)\nä¸Šã€‚\n\n## è§†é¢‘ä½œå“\n\n### CogVideoX-5B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/cf5953ea-96d3-48fd-9907-c4708752c714\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/fe0a78e6-b669-4800-8cf0-b5f9b5145b52\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/c182f606-8f8c-421d-b414-8487070fcfcb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/7db2bbce-194d-434d-a605-350254b6c298\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/62b01046-8cab-44cc-bd45-4d965bb615ec\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/d78e552a-4b3f-4b81-ac3f-3898079554f6\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/30894f12-c741-44a2-9e6e-ddcacc231e5b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/926575ca-7150-435b-a0ff-4900a963297b\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\n### CogVideoX-2B\n\n<table border=\"0\" style=\"width: 100%; text-align: left; margin-top: 20px;\">\n  <tr>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/ea3af39a-3160-4999-90ec-2f7863c5b0e9\" width=\"100%\" controls autoplay loop></video>\n      </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/9de41efd-d4d1-4095-aeda-246dd834e91d\" width=\"100%\" controls autoplay loop></video>\n      </td>\n       <td>\n          <video src=\"https://github.com/user-attachments/assets/941d6661-6a8d-4a1b-b912-59606f0b2841\" width=\"100%\" controls autoplay loop></video>\n     </td>\n      <td>\n          <video src=\"https://github.com/user-attachments/assets/938529c4-91ae-4f60-b96b-3c3947fa63cb\" width=\"100%\" controls autoplay loop></video>\n     </td>\n  </tr>\n</table>\n\n\næŸ¥çœ‹ç”»å»Šçš„å¯¹åº”æç¤ºè¯ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](resources/galary_prompt.md)\n\n## æ¨¡å‹ä»‹ç»\n\nCogVideoXæ˜¯ [æ¸…å½±](https://chatglm.cn/video?fr=osm_cogvideox) åŒæºçš„å¼€æºç‰ˆæœ¬è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚\nä¸‹è¡¨å±•ç¤ºæˆ‘ä»¬æä¾›çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ç›¸å…³åŸºç¡€ä¿¡æ¯:\n\n<table  style=\"border-collapse: collapse; width: 100%;\">\n  <tr>\n    <th style=\"text-align: center;\">æ¨¡å‹å</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B (æœ€æ–°)</th>\n    <th style=\"text-align: center;\">CogVideoX1.5-5B-I2V (æœ€æ–°)</th>\n    <th style=\"text-align: center;\">CogVideoX-2B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B</th>\n    <th style=\"text-align: center;\">CogVideoX-5B-I2V </th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å‘å¸ƒæ—¶é—´</td>\n    <th style=\"text-align: center;\">2024å¹´11æœˆ8æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´11æœˆ8æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´8æœˆ6æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´8æœˆ27æ—¥</th>\n    <th style=\"text-align: center;\">2024å¹´9æœˆ19æ—¥</th>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">è§†é¢‘åˆ†è¾¨ç‡</td>\n    <td colspan=\"1\" style=\"text-align: center;\">1360 * 768</td>\n    <td colspan=\"1\" style=\"text-align: center;\"> Min(W, H) = 768 <br> 768 â‰¤ Max(W, H) â‰¤ 1360 <br> Max(W, H) % 16 = 0 </td>\n    <td colspan=\"3\" style=\"text-align: center;\">720 * 480</td>\n    </tr>\n  <tr>\n    <td style=\"text-align: center;\">æ¨ç†ç²¾åº¦</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16(æ¨è)</b>, FP16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼Œä¸æ”¯æŒINT4</td>\n    <td style=\"text-align: center;\"><b>FP16*(æ¨è)</b>, BF16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼Œä¸æ”¯æŒINT4</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16(æ¨è)</b>, FP16, FP32ï¼ŒFP8*ï¼ŒINT8ï¼Œä¸æ”¯æŒINT4</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å•GPUæ˜¾å­˜æ¶ˆè€—<br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 76GB <br><b>diffusers BF16 : 10GBèµ·* </b><br><b>diffusers INT8(torchao): 7Gèµ·* </b></td>\n    <td style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> FP16: 18GB <br><b>diffusers FP16: 4GBèµ·* </b><br><b>diffusers INT8(torchao): 3.6Gèµ·*</b></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://github.com/THUDM/SwissArmyTransformer\">SAT</a> BF16: 26GB <br><b>diffusers BF16 : 5GBèµ·* </b><br><b>diffusers INT8(torchao): 4.4Gèµ·* </b></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å¤šGPUæ¨ç†æ˜¾å­˜æ¶ˆè€—</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 24GB* using diffusers</b><br></td>\n    <td style=\"text-align: center;\"><b>FP16: 10GB* using diffusers</b><br></td>\n    <td colspan=\"2\" style=\"text-align: center;\"><b>BF16: 15GB* using diffusers</b><br></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">æ¨ç†é€Ÿåº¦<br>(Step = 50, FP/BF16)</td>\n    <td colspan=\"2\" style=\"text-align: center;\">å•å¡A100: ~1000ç§’(5ç§’è§†é¢‘)<br>å•å¡H100: ~550ç§’(5ç§’è§†é¢‘)</td>\n    <td style=\"text-align: center;\">å•å¡A100: ~90ç§’<br>å•å¡H100: ~45ç§’</td>\n    <td colspan=\"2\" style=\"text-align: center;\">å•å¡A100: ~180ç§’<br>å•å¡H100: ~90ç§’</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">æç¤ºè¯è¯­è¨€</td>\n    <td colspan=\"5\" style=\"text-align: center;\">English*</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">æç¤ºè¯é•¿åº¦ä¸Šé™</td>\n    <td colspan=\"2\" style=\"text-align: center;\">224 Tokens</td>\n    <td colspan=\"3\" style=\"text-align: center;\">226 Tokens</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">è§†é¢‘é•¿åº¦</td>\n    <td colspan=\"2\" style=\"text-align: center;\">5 ç§’ æˆ– 10 ç§’</td>\n    <td colspan=\"3\" style=\"text-align: center;\">6 ç§’</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">å¸§ç‡</td>\n    <td colspan=\"2\" style=\"text-align: center;\">16 å¸§ / ç§’ </td>\n    <td colspan=\"3\" style=\"text-align: center;\">8 å¸§ / ç§’ </td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ä½ç½®ç¼–ç </td>\n    <td colspan=\"2\" style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_sincos_pos_embed</td> \n    <td style=\"text-align: center;\">3d_rope_pos_embed</td>\n    <td style=\"text-align: center;\">3d_rope_pos_embed + learnable_pos_embed</td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ä¸‹è½½é“¾æ¥ (Diffusers)</td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5B-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5B-I2V\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-2b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-2b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-2b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b\">ğŸŸ£ WiseModel</a></td>\n    <td style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX-5b-I2V\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX-5b-I2V\">ğŸŸ£ WiseModel</a></td>\n  </tr>\n  <tr>\n    <td style=\"text-align: center;\">ä¸‹è½½é“¾æ¥ (SAT)</td>\n    <td colspan=\"2\" style=\"text-align: center;\"><a href=\"https://huggingface.co/THUDM/CogVideoX1.5-5b-SAT\">ğŸ¤— HuggingFace</a><br><a href=\"https://modelscope.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸ¤– ModelScope</a><br><a href=\"https://wisemodel.cn/models/ZhipuAI/CogVideoX1.5-5b-SAT\">ğŸŸ£ WiseModel</a></td>\n    <td colspan=\"3\" style=\"text-align: center;\"><a href=\"./sat/README_zh.md\">SAT</a></td>\n  </tr>\n</table>\n\n**æ•°æ®è§£é‡Š**\n\n+ ä½¿ç”¨ diffusers åº“è¿›è¡Œæµ‹è¯•æ—¶ï¼Œå¯ç”¨äº†å…¨éƒ¨`diffusers`åº“è‡ªå¸¦çš„ä¼˜åŒ–ï¼Œè¯¥æ–¹æ¡ˆæœªæµ‹è¯•åœ¨é**NVIDIA A100 / H100**\n  å¤–çš„è®¾å¤‡ä¸Šçš„å®é™…æ˜¾å­˜ / å†…å­˜å ç”¨ã€‚é€šå¸¸ï¼Œè¯¥æ–¹æ¡ˆå¯ä»¥é€‚é…äºæ‰€æœ‰ **NVIDIA å®‰åŸ¹æ¶æ„**\n  ä»¥ä¸Šçš„è®¾å¤‡ã€‚è‹¥å…³é—­ä¼˜åŒ–ï¼Œæ˜¾å­˜å ç”¨ä¼šæˆå€å¢åŠ ï¼Œå³°å€¼æ˜¾å­˜çº¦ä¸ºè¡¨æ ¼çš„3å€ã€‚ä½†é€Ÿåº¦æå‡3-4å€å·¦å³ã€‚ä½ å¯ä»¥é€‰æ‹©æ€§çš„å…³é—­éƒ¨åˆ†ä¼˜åŒ–ï¼Œè¿™äº›ä¼˜åŒ–åŒ…æ‹¬:\n\n```\npipe.enable_sequential_cpu_offload()\npipe.vae.enable_slicing()\npipe.vae.enable_tiling()\n```\n\n+ å¤šGPUæ¨ç†æ—¶ï¼Œéœ€è¦å…³é—­ `enable_sequential_cpu_offload()` ä¼˜åŒ–ã€‚\n+ ä½¿ç”¨ INT8 æ¨¡å‹ä¼šå¯¼è‡´æ¨ç†é€Ÿåº¦é™ä½ï¼Œæ­¤ä¸¾æ˜¯ä¸ºäº†æ»¡è¶³æ˜¾å­˜è¾ƒä½çš„æ˜¾å¡èƒ½æ­£å¸¸æ¨ç†å¹¶ä¿æŒè¾ƒå°‘çš„è§†é¢‘è´¨é‡æŸå¤±ï¼Œæ¨ç†é€Ÿåº¦å¤§å¹…é™ä½ã€‚\n+ CogVideoX-2B æ¨¡å‹é‡‡ç”¨ `FP16` ç²¾åº¦è®­ç»ƒï¼Œ æœæœ‰ CogVideoX-5B æ¨¡å‹é‡‡ç”¨ `BF16` ç²¾åº¦è®­ç»ƒã€‚æˆ‘ä»¬æ¨èä½¿ç”¨æ¨¡å‹è®­ç»ƒçš„ç²¾åº¦è¿›è¡Œæ¨ç†ã€‚\n+ [PytorchAO](https://github.com/pytorch/ao) å’Œ [Optimum-quanto](https://github.com/huggingface/optimum-quanto/)\n  å¯ä»¥ç”¨äºé‡åŒ–æ–‡æœ¬ç¼–ç å™¨ã€Transformer å’Œ VAE æ¨¡å—ï¼Œä»¥é™ä½ CogVideoX çš„å†…å­˜éœ€æ±‚ã€‚è¿™ä½¿å¾—åœ¨å…è´¹çš„ T4 Colab æˆ–æ›´å°æ˜¾å­˜çš„ GPU\n  ä¸Šè¿è¡Œæ¨¡å‹æˆä¸ºå¯èƒ½ï¼åŒæ ·å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒTorchAO é‡åŒ–å®Œå…¨å…¼å®¹ `torch.compile`ï¼Œè¿™å¯ä»¥æ˜¾è‘—æé«˜æ¨ç†é€Ÿåº¦ã€‚åœ¨ `NVIDIA H100`\n  åŠä»¥ä¸Šè®¾å¤‡ä¸Šå¿…é¡»ä½¿ç”¨ `FP8` ç²¾åº¦ï¼Œè¿™éœ€è¦æºç å®‰è£… `torch`ã€`torchao` Python åŒ…ã€‚å»ºè®®ä½¿ç”¨ `CUDA 12.4`ã€‚\n+ æ¨ç†é€Ÿåº¦æµ‹è¯•åŒæ ·é‡‡ç”¨äº†ä¸Šè¿°æ˜¾å­˜ä¼˜åŒ–æ–¹æ¡ˆï¼Œä¸é‡‡ç”¨æ˜¾å­˜ä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œæ¨ç†é€Ÿåº¦æå‡çº¦10%ã€‚ åªæœ‰`diffusers`ç‰ˆæœ¬æ¨¡å‹æ”¯æŒé‡åŒ–ã€‚\n+ æ¨¡å‹ä»…æ”¯æŒè‹±è¯­è¾“å…¥ï¼Œå…¶ä»–è¯­è¨€å¯ä»¥é€šè¿‡å¤§æ¨¡å‹æ¶¦è‰²æ—¶ç¿»è¯‘ä¸ºè‹±è¯­ã€‚\n\n## å‹æƒ…é“¾æ¥\n\næˆ‘ä»¬éå¸¸æ¬¢è¿æ¥è‡ªç¤¾åŒºçš„è´¡çŒ®ï¼Œå¹¶ç§¯æçš„è´¡çŒ®å¼€æºç¤¾åŒºã€‚ä»¥ä¸‹ä½œå“å·²ç»å¯¹CogVideoXè¿›è¡Œäº†é€‚é…ï¼Œæ¬¢è¿å¤§å®¶ä½¿ç”¨:\n\n+ [CogVideoX-Fun](https://github.com/aigc-apps/CogVideoX-Fun):\n  CogVideoX-Funæ˜¯ä¸€ä¸ªåŸºäºCogVideoXç»“æ„ä¿®æ”¹åçš„çš„pipelineï¼Œæ”¯æŒè‡ªç”±çš„åˆ†è¾¨ç‡ï¼Œå¤šç§å¯åŠ¨æ–¹å¼ã€‚\n+ [CogStudio](https://github.com/pinokiofactory/cogstudio): CogVideo çš„ Gradio Web UIå•ç‹¬å®ç°ä»“åº“ï¼Œæ”¯æŒæ›´å¤šåŠŸèƒ½çš„ Web UIã€‚\n+ [Xorbits Inference](https://github.com/xorbitsai/inference): æ€§èƒ½å¼ºå¤§ä¸”åŠŸèƒ½å…¨é¢çš„åˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ï¼Œè½»æ¾ä¸€é”®éƒ¨ç½²ä½ è‡ªå·±çš„æ¨¡å‹æˆ–å†…ç½®çš„å‰æ²¿å¼€æºæ¨¡å‹ã€‚\n+ [ComfyUI-CogVideoXWrapper](https://github.com/kijai/ComfyUI-CogVideoXWrapper) ä½¿ç”¨ComfyUIæ¡†æ¶ï¼Œå°†CogVideoXåŠ å…¥åˆ°ä½ çš„å·¥ä½œæµä¸­ã€‚\n+ [VideoSys](https://github.com/NUS-HPC-AI-Lab/VideoSys): VideoSys æä¾›äº†æ˜“ç”¨ä¸”é«˜æ€§èƒ½çš„è§†é¢‘ç”ŸæˆåŸºç¡€è®¾æ–½ï¼Œæ”¯æŒå®Œæ•´çš„ç®¡é“ï¼Œå¹¶æŒç»­é›†æˆæœ€æ–°çš„æ¨¡å‹å’ŒæŠ€æœ¯ã€‚\n+ [AutoDLé•œåƒ](https://www.codewithgpu.com/i/THUDM/CogVideo/CogVideoX-5b-demo): ç”±ç¤¾åŒºæˆå‘˜æä¾›çš„ä¸€é”®éƒ¨ç½²Huggingface\n  Spaceé•œåƒã€‚\n+ [å®¤å†…è®¾è®¡å¾®è°ƒæ¨¡å‹](https://huggingface.co/collections/bertjiazheng/koolcogvideox-66e4762f53287b7f39f8f3ba) åŸºäº\n  CogVideoXçš„å¾®è°ƒæ¨¡å‹ï¼Œå®ƒä¸“ä¸ºå®¤å†…è®¾è®¡è€Œè®¾è®¡\n+ [xDiT](https://github.com/xdit-project/xDiT): xDiTæ˜¯ä¸€ä¸ªç”¨äºåœ¨å¤šGPUé›†ç¾¤ä¸Šå¯¹DiTså¹¶è¡Œæ¨ç†çš„å¼•æ“ã€‚xDiTæ”¯æŒå®æ—¶å›¾åƒå’Œè§†é¢‘ç”ŸæˆæœåŠ¡ã€‚\n+ [CogVideoX-Interpolation](https://github.com/feizc/CogvideX-Interpolation): åŸºäº CogVideoX ç»“æ„ä¿®æ”¹çš„ç®¡é“ï¼Œæ—¨åœ¨ä¸ºå…³é”®å¸§æ’å€¼ç”Ÿæˆæä¾›æ›´å¤§çš„çµæ´»æ€§ã€‚\n+ [DiffSynth-Studio](https://github.com/modelscope/DiffSynth-Studio): DiffSynth å·¥ä½œå®¤æ˜¯ä¸€æ¬¾æ‰©æ•£å¼•æ“ã€‚é‡æ„äº†æ¶æ„ï¼ŒåŒ…æ‹¬æ–‡æœ¬ç¼–ç å™¨ã€UNetã€VAE\n  ç­‰ï¼Œåœ¨ä¿æŒä¸å¼€æºç¤¾åŒºæ¨¡å‹å…¼å®¹æ€§çš„åŒæ—¶ï¼Œæå‡äº†è®¡ç®—æ€§èƒ½ã€‚è¯¥æ¡†æ¶å·²ç»é€‚é… CogVideoXã€‚\n+ [CogVideoX-Controlnet](https://github.com/TheDenk/cogvideox-controlnet): ä¸€ä¸ªåŒ…å« CogvideoX æ¨¡å‹çš„ç®€å• Controlnet æ¨¡å—çš„ä»£ç ã€‚\n+ [VideoTuna](https://github.com/VideoVerses/VideoTuna)ï¼šVideoTuna æ˜¯é¦–ä¸ªé›†æˆå¤šç§ AI è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ä»“åº“ï¼Œæ”¯æŒæ–‡æœ¬è½¬è§†é¢‘ã€å›¾åƒè½¬è§†é¢‘ã€æ–‡æœ¬è½¬å›¾åƒç”Ÿæˆã€‚\n+ [ConsisID](https://github.com/PKU-YuanGroup/ConsisID): ä¸€ç§èº«ä»½ä¿æŒçš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ŒåŸºäº CogVideoX-5Bï¼Œé€šè¿‡é¢‘ç‡åˆ†è§£åœ¨ç”Ÿæˆçš„è§†é¢‘ä¸­ä¿æŒé¢éƒ¨ä¸€è‡´æ€§ã€‚\n+ [æ•™ç¨‹](https://www.youtube.com/watch?v=5UCkMzP2VLE&ab_channel=SECourses): ä¸€ä¸ªå…³äºåœ¨Windowså’Œäº‘ç¯å¢ƒä¸­å®‰è£…å’Œä¼˜åŒ–CogVideoX1.5-5B-I2Væ¨¡å‹çš„åˆ†æ­¥æŒ‡å—ã€‚ç‰¹åˆ«æ„Ÿè°¢[FurkanGozukara](https://github.com/FurkanGozukara)çš„åŠªåŠ›å’Œæ”¯æŒï¼\n\n\n## å®Œæ•´é¡¹ç›®ä»£ç ç»“æ„\n\næœ¬å¼€æºä»“åº“å°†å¸¦é¢†å¼€å‘è€…å¿«é€Ÿä¸Šæ‰‹ **CogVideoX** å¼€æºæ¨¡å‹çš„åŸºç¡€è°ƒç”¨æ–¹å¼ã€å¾®è°ƒç¤ºä¾‹ã€‚\n\n### Colab å¿«é€Ÿä½¿ç”¨\n\nè¿™é‡Œæä¾›äº†ä¸‰ä¸ªèƒ½ç›´æ¥åœ¨å…è´¹çš„ Colab T4ä¸Š è¿è¡Œçš„é¡¹ç›®\n\n+ [CogVideoX-5B-T2V-Colab.ipynb](https://colab.research.google.com/drive/1pCe5s0bC_xuXbBlpvIH1z0kfdTLQPzCS?usp=sharing):\n  CogVideoX-5B æ–‡å­—ç”Ÿæˆè§†é¢‘ Colab ä»£ç ã€‚\n+ [CogVideoX-5B-T2V-Int8-Colab.ipynb](https://colab.research.google.com/drive/1DUffhcjrU-uz7_cpuJO3E_D4BaJT7OPa?usp=sharing):\n  CogVideoX-5B æ–‡å­—ç”Ÿæˆè§†é¢‘é‡åŒ–æ¨ç† Colab ä»£ç ï¼Œè¿è¡Œä¸€æ¬¡å¤§çº¦éœ€è¦30åˆ†é’Ÿã€‚\n+ [CogVideoX-5B-I2V-Colab.ipynb](https://colab.research.google.com/drive/17CqYCqSwz39nZAX2YyonDxosVKUZGzcX?usp=sharing):\n  CogVideoX-5B å›¾ç‰‡ç”Ÿæˆè§†é¢‘ Colab ä»£ç ã€‚\n+ [CogVideoX-5B-V2V-Colab.ipynb](https://colab.research.google.com/drive/1comfGAUJnChl5NwPuO8Ox5_6WCy4kbNN?usp=sharing):\n  CogVideoX-5B è§†é¢‘ç”Ÿæˆè§†é¢‘ Colab ä»£ç ã€‚\n\n### inference\n\n+ [cli_demo](inference/cli_demo.py): æ›´è¯¦ç»†çš„æ¨ç†ä»£ç è®²è§£ï¼Œå¸¸è§å‚æ•°çš„æ„ä¹‰ï¼Œåœ¨è¿™é‡Œéƒ½ä¼šæåŠã€‚\n+ [cli_demo_quantization](inference/cli_demo_quantization.py):\n  é‡åŒ–æ¨¡å‹æ¨ç†ä»£ç ï¼Œå¯ä»¥åœ¨æ˜¾å­˜è¾ƒä½çš„è®¾å¤‡ä¸Šè¿è¡Œï¼Œä¹Ÿå¯ä»¥åŸºäºæ­¤ä»£ç ä¿®æ”¹ï¼Œä»¥æ”¯æŒè¿è¡ŒFP8ç­‰ç²¾åº¦çš„CogVideoXæ¨¡å‹ã€‚è¯·æ³¨æ„ï¼ŒFP8\n  ä»…æµ‹è¯•é€šè¿‡ï¼Œä¸”å¿…é¡»å°† `torch-nightly`,`torchao`æºä»£ç å®‰è£…ï¼Œä¸å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ã€‚\n+ [diffusers_vae_demo](inference/cli_vae_demo.py): å•ç‹¬æ‰§è¡ŒVAEçš„æ¨ç†ä»£ç ã€‚\n+ [space demo](inference/gradio_composite_demo): Huggingface SpaceåŒæ¬¾çš„ GUI ä»£ç ï¼Œæ¤å…¥äº†æ’å¸§ï¼Œè¶…åˆ†å·¥å…·ã€‚\n\n<div style=\"text-align: center;\">\n    <img src=\"resources/web_demo.png\" style=\"width: 100%; height: auto;\" />\n</div>\n\n+ [convert_demo](inference/convert_demo.py): å¦‚ä½•å°†ç”¨æˆ·çš„è¾“å…¥è½¬æ¢æˆé€‚åˆ\n  CogVideoXçš„é•¿è¾“å…¥ã€‚å› ä¸ºCogVideoXæ˜¯åœ¨é•¿æ–‡æœ¬ä¸Šè®­ç»ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æŠŠè¾“å…¥æ–‡æœ¬çš„åˆ†å¸ƒé€šè¿‡LLMè½¬æ¢ä¸ºå’Œè®­ç»ƒä¸€è‡´çš„é•¿æ–‡æœ¬ã€‚è„šæœ¬ä¸­é»˜è®¤ä½¿ç”¨GLM-4ï¼Œä¹Ÿå¯ä»¥æ›¿æ¢ä¸ºGPTã€Geminiç­‰ä»»æ„å¤§è¯­è¨€æ¨¡å‹ã€‚\n+ [gradio_web_demo](inference/gradio_composite_demo/app.py): ä¸ Huggingface Space å®Œå…¨ç›¸åŒçš„ä»£ç å®ç°ï¼Œå¿«é€Ÿéƒ¨ç½² CogVideoX\n  GUIä½“éªŒã€‚\n\n### finetune\n\n+ [train_cogvideox_lora](finetune/README_zh.md): diffusersç‰ˆæœ¬ CogVideoX æ¨¡å‹å¾®è°ƒæ–¹æ¡ˆå’Œç»†èŠ‚ã€‚\n\n### sat\n\n+ [sat_demo](sat/README_zh.md): åŒ…å«äº† SAT æƒé‡çš„æ¨ç†ä»£ç å’Œå¾®è°ƒä»£ç ï¼Œæ¨èåŸºäº CogVideoX\n  æ¨¡å‹ç»“æ„è¿›è¡Œæ”¹è¿›ï¼Œåˆ›æ–°çš„ç ”ç©¶è€…ä½¿ç”¨æ”¹ä»£ç ä»¥æ›´å¥½çš„è¿›è¡Œå¿«é€Ÿçš„å †å å’Œå¼€å‘ã€‚\n\n### tools\n\næœ¬æ–‡ä»¶å¤¹åŒ…å«äº†ä¸€äº›å·¥å…·ï¼Œç”¨äºæ¨¡å‹çš„è½¬æ¢ / Caption ç­‰å·¥ä½œã€‚\n\n+ [convert_weight_sat2hf](tools/convert_weight_sat2hf.py): å°† SAT æ¨¡å‹æƒé‡è½¬æ¢ä¸º Huggingface æ¨¡å‹æƒé‡ã€‚\n+ [caption_demo](tools/caption/README_zh.md):  Caption å·¥å…·ï¼Œå¯¹è§†é¢‘ç†è§£å¹¶ç”¨æ–‡å­—è¾“å‡ºçš„æ¨¡å‹ã€‚\n+ [export_sat_lora_weight](tools/export_sat_lora_weight.py):  SATå¾®è°ƒæ¨¡å‹å¯¼å‡ºå·¥å…·ï¼Œå°†\n  SAT Lora Adapter å¯¼å‡ºä¸º diffusers æ ¼å¼ã€‚\n+ [load_cogvideox_lora](tools/load_cogvideox_lora.py): è½½å…¥diffusersç‰ˆå¾®è°ƒLora Adapterçš„å·¥å…·ä»£ç ã€‚\n+ [llm_flux_cogvideox](tools/llm_flux_cogvideox/llm_flux_cogvideox.py): ä½¿ç”¨å¼€æºæœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ + Flux +\n  CogVideoXå®ç°è‡ªåŠ¨åŒ–ç”Ÿæˆè§†é¢‘ã€‚\n+ [parallel_inference_xdit](tools/parallel_inference/parallel_inference_xdit.py):\n  åœ¨å¤šä¸ª GPU ä¸Šå¹¶è¡ŒåŒ–è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ï¼Œ\n  ç”±[xDiT](https://github.com/xdit-project/xDiT)æä¾›æ”¯æŒã€‚\n+ [cogvideox-factory](https://github.com/a-r-r-o-w/cogvideox-factory): CogVideoXä½æˆæ–‡å¾®è°ƒæ¡†æ¶ï¼Œé€‚é…`diffusers`\n  ç‰ˆæœ¬æ¨¡å‹ã€‚æ”¯æŒæ›´å¤šåˆ†è¾¨ç‡ï¼Œå•å¡4090å³å¯å¾®è°ƒ CogVideoX-5B ã€‚\n\n## CogVideo(ICLR'23)\n\n[CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers](https://arxiv.org/abs/2205.15868)\nçš„å®˜æ–¹repoä½äº[CogVideo branch](https://github.com/THUDM/CogVideo/tree/CogVideo)ã€‚\n\n**CogVideoå¯ä»¥ç”Ÿæˆé«˜å¸§ç‡è§†é¢‘ï¼Œä¸‹é¢å±•ç¤ºäº†ä¸€ä¸ª32å¸§çš„4ç§’è§†é¢‘ã€‚**\n\n![High-frame-rate sample](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/appendix-sample-highframerate.png)\n\n![Intro images](https://raw.githubusercontent.com/THUDM/CogVideo/CogVideo/assets/intro-image.png)\n\n\n<div align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/ea3af39a-3160-4999-90ec-2f7863c5b0e9\" width=\"80%\" controls autoplay></video>\n</div>\n\nCogVideoçš„demoç½‘ç«™åœ¨[https://models.aminer.cn/cogvideo](https://models.aminer.cn/cogvideo/)ã€‚æ‚¨å¯ä»¥åœ¨è¿™é‡Œä½“éªŒæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆã€‚\n*åŸå§‹è¾“å…¥ä¸ºä¸­æ–‡ã€‚*\n\n## å¼•ç”¨\n\nğŸŒŸ å¦‚æœæ‚¨å‘ç°æˆ‘ä»¬çš„å·¥ä½œæœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨æˆ‘ä»¬çš„æ–‡ç« ï¼Œç•™ä¸‹å®è´µçš„stars\n\n```\n@article{yang2024cogvideox,\n  title={CogVideoX: Text-to-Video Diffusion Models with An Expert Transformer},\n  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},\n  journal={arXiv preprint arXiv:2408.06072},\n  year={2024}\n}\n@article{hong2022cogvideo,\n  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},\n  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},\n  journal={arXiv preprint arXiv:2205.15868},\n  year={2022}\n}\n```\n\næˆ‘ä»¬æ¬¢è¿æ‚¨çš„è´¡çŒ®ï¼Œæ‚¨å¯ä»¥ç‚¹å‡»[è¿™é‡Œ](resources/contribute_zh.md)æŸ¥çœ‹æ›´å¤šä¿¡æ¯ã€‚\n\n## æ¨¡å‹åè®®\n\næœ¬ä»“åº“ä»£ç ä½¿ç”¨ [Apache 2.0 åè®®](LICENSE) å‘å¸ƒã€‚\n\nCogVideoX-2B æ¨¡å‹ (åŒ…æ‹¬å…¶å¯¹åº”çš„Transformersæ¨¡å—ï¼ŒVAEæ¨¡å—) æ ¹æ® [Apache 2.0 åè®®](LICENSE) è®¸å¯è¯å‘å¸ƒã€‚\n\nCogVideoX-5B æ¨¡å‹ (Transformers æ¨¡å—ï¼ŒåŒ…æ‹¬å›¾ç”Ÿè§†é¢‘ï¼Œæ–‡ç”Ÿè§†é¢‘ç‰ˆæœ¬)\næ ¹æ® [CogVideoX LICENSE](https://huggingface.co/THUDM/CogVideoX-5b/blob/main/LICENSE)\nè®¸å¯è¯å‘å¸ƒã€‚\n"
        },
        {
          "name": "finetune",
          "type": "tree",
          "content": null
        },
        {
          "name": "inference",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.6826171875,
          "content": "[tool.ruff]\nline-length = 119\n\n[tool.ruff.lint]\n# Never enforce `E501` (line length violations).\nignore = [\"C901\", \"E501\", \"E741\", \"F402\", \"F823\"]\nselect = [\"C\", \"E\", \"F\", \"I\", \"W\"]\n\n# Ignore import violations in all `__init__.py` files.\n[tool.ruff.lint.per-file-ignores]\n\"__init__.py\" = [\"E402\", \"F401\", \"F403\", \"F811\"]\n\n[tool.ruff.lint.isort]\nlines-after-imports = 2\n\n[tool.ruff.format]\n# Like Black, use double quotes for strings.\nquote-style = \"double\"\n\n# Like Black, indent with spaces, rather than tabs.\nindent-style = \"space\"\n\n# Like Black, respect magic trailing commas.\nskip-magic-trailing-comma = false\n\n# Like Black, automatically detect the appropriate line ending.\nline-ending = \"auto\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.25,
          "content": "diffusers>=0.31.0\naccelerate>=1.1.1\ntransformers>=4.46.2\nnumpy==1.26.0\ntorch>=2.5.0\ntorchvision>=0.20.0\nsentencepiece>=0.2.0\nSwissArmyTransformer>=0.4.12\ngradio>=5.5.0\nimageio>=2.35.1\nimageio-ffmpeg>=0.5.1\nopenai>=1.54.0\nmoviepy>=1.0.3\nscikit-video>=1.1.11"
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "sat",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}