{
  "metadata": {
    "timestamp": 1736561153833,
    "page": 104,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjExMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PrefectHQ/prefect",
      "stars": 17982,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".codespellrc",
          "type": "blob",
          "size": 0.369140625,
          "content": "[codespell]\nskip = .git,*.pdf,*.svg,versioneer.py,package-lock.json,_vendor,*.css,.codespellrc,tests/utilities/test_text.py\n# from https://github.com/PrefectHQ/prefect/pull/10813#issuecomment-1732676130\nignore-regex = .*lazy=\\\"selectin\\\"|.*e import Bloc$|America/Nome\n\nignore-words-list = selectin,aci,wqs,aks,ines,dependant,fsspec,automations,nmme,afterall\n\ncheck-hidden = true"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.5400390625,
          "content": "# Python artifacts\n__pycache__/\n*.py[cod]\n*$py.class\n*.egg-info/\n*.egg\ndist/\nsdist/\n.python-version\n\n# Test artifacts\n.coverage*\n.pytest_cache/\n\n# Type checking artifacts\n.mypy_cache/\n.dmypy.json\ndmypy.json\n.pyre/\n\n# IPython\nprofile_default/\nipython_config.py\n\n# Environments\n.python-version\n.env\n.venv\nenv/\nvenv/\n\n# Documentation artifacts\ndocs/\nsite/\n\n# UI artifacts\nsrc/prefect/server/ui/*\nui/node_modules\nui-v2/\n\n# Databases\n*.db\n\n# MacOS\n.DS_Store\n\n# Dask\ndask-worker-space/\n\n# Editors\n.idea/\n.vscode/\n\n# Other\ntests/\ncompat-tests/\nbenches/\nbuild/\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0361328125,
          "content": "src/prefect/_version.py export-subst\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.935546875,
          "content": "# Python artifacts\n__pycache__/\n*.py[cod]\n*$py.class\n*.egg-info/\n*.egg\nbuild/\ndist/\nsdist/\n\n# Test artifacts\n.benchmarks/\n.coverage\n.coverage.*.*\n.prefect-results\n.pytest_cache/\n\n# Type checking artifacts\n.mypy_cache/\n.dmypy.json\ndmypy.json\n.pyre/\n\n# IPython\nprofile_default/\nipython_config.py\n*.ipynb_checkpoints/*\n\n# Profiling\n/prof\n\n# Environments\n.python-version\n.env\n.venv\nenv/\nvenv/\n\n# Documentation artifacts\n# gschema.json\nsite/\n.cache/\nsrc/mkdocs-material\n\n# UI artifacts\nsrc/prefect/server/ui/*\nsrc/prefect/server/ui_build/*\n**/node_modules\n\n# Databases\n*.db\n\n# API artifacts\n\n# MacOS\n.DS_Store\n\n# Dask\ndask-worker-space/\n\n# Editors\n.idea/\n.vscode/\n!ui/.vscode/\n\n# Prefect files\nprefect.toml\nprefect.yaml\n\n# Deployment recipes\n!src/prefect/deployments/recipes/*/**\n\n# For development doc server if link\nlibcairo.2.dylib\n\n# setuptools-scm generated files\nsrc/integrations/*/**/_version.py\n*.log\n\n# Pyright type analysis report\nprefect-analysis.json\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.0986328125,
          "content": "[submodule \"compat-tests\"]\n\tpath = compat-tests\n\turl = https://github.com/PrefectHQ/compat-tests.git\n"
        },
        {
          "name": ".nvmrc",
          "type": "blob",
          "size": 0.0078125,
          "content": "18.18.0\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 3.576171875,
          "content": "repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: \"v0.2.1\"\n    hooks:\n      - id: ruff\n        language_version: python3\n        args: [--fix, --exit-non-zero-on-fix, --show-fixes]\n      - id: ruff-format\n  - repo: https://github.com/codespell-project/codespell\n    rev: v2.2.6\n    hooks:\n      - id: codespell\n        exclude: package-lock.json|_vendor/.*|docs/styles/.*\n  - repo: https://github.com/netromdk/vermin\n    rev: v1.6.0\n    hooks:\n      - id: vermin\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.9.0\n    hooks:\n      - id: mypy\n        additional_dependencies:\n          - pydantic>=1.10.0,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0\n          - types-cachetools==5.3.0.5\n          - types-pyyaml==6.0.12.9\n        files: |\n          (?x)^(\n            src/prefect/server/models/.*|\n            src/prefect/concurrency/.*|\n            src/prefect/events/.*|\n            src/prefect/input/.*\n          )$\n  - repo: local\n    hooks:\n      - id: generate-mintlify-openapi-docs\n        name: Generating OpenAPI docs for Mintlify\n        language: system\n        entry: uv run --with 'pydantic>=2.9.0' ./scripts/generate_mintlify_openapi_docs.py\n        pass_filenames: false\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              src/prefect/server/api/.*|\n              src/prefect/server/schemas/.*|\n              src/prefect/server/events/.*|\n              scripts/generate_mintlify_openapi_docs.py\n          )$\n      - id: generate-settings-schema\n        name: Generating Settings Schema\n        language: system\n        entry: uv run --with 'pydantic>=2.9.0' ./scripts/generate_settings_schema.py\n        pass_filenames: false\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              src/prefect/settings/models/.*|\n              scripts/generate_settings_schema.py\n          )$\n      - id: generate-settings-ref\n        name: Generating Settings Reference\n        language: system\n        entry: uv run --with 'pydantic>=2.9.0' ./scripts/generate_settings_ref.py\n        pass_filenames: false\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              src/prefect/settings/models/.*|\n              scripts/generate_settings_ref.py\n          )$\n      - id: lint-ui-v2\n        name: Lint UI v2\n        language: system\n        entry: sh\n        args:\n          [\n            \"-c\",\n            \"cd ui-v2 && npm i --no-upgrade --silent --no-progress && npm run lint\",\n          ]\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              ui-v2/.*\n          )$\n        pass_filenames: false\n      - id: format-ui-v2\n        name: Format UI v2\n        language: system\n        entry: sh\n        args:\n          [\n            \"-c\",\n            \"cd ui-v2 && npm i --no-upgrade --silent --no-progress && npm run format\",\n          ]\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              ui-v2/.*\n          )$\n        pass_filenames: false\n      - id: service-sync-ui-v2-openapi\n        name: Sync UI v2 OpenAPI\n        language: system\n        entry: sh\n        args:\n          [\n            \"-c\",\n            \"cd ui-v2 && npm i --no-upgrade --silent --no-progress && npm run service-sync\",\n          ]\n        files: |\n          (?x)^(\n              .pre-commit-config.yaml|\n              .pre-commit-config.yaml|\n              src/prefect/server/api/.*|\n              src/prefect/server/schemas/.*|\n              src/prefect/server/events/.*|\n              src/prefect/server/utilities/schemas/.*|\n              ui-v2/package.json\n          )$\n        pass_filenames: false\n"
        },
        {
          "name": ".prefectignore",
          "type": "blob",
          "size": 0.380859375,
          "content": "# prefect artifacts\n.prefectignore\n\n# python artifacts\n__pycache__/\n*.py[cod]\n*$py.class\n*.egg-info/\n*.egg\n\n# Type checking artifacts\n.mypy_cache/\n.dmypy.json\ndmypy.json\n.pyre/\n\n# IPython\nprofile_default/\nipython_config.py\n*.ipynb_checkpoints/*\n\n# Environments\n.python-version\n.env\n.venv\nenv/\nvenv/\n\n# MacOS\n.DS_Store\n\n# Dask\ndask-worker-space/\n\n# Editors\n.idea/\n.vscode/\n\n# VCS\n.git/\n.hg/\n"
        },
        {
          "name": ".ruff.toml",
          "type": "blob",
          "size": 0.7314453125,
          "content": "src = [\"src\"]\n\n# Use Ruff for sorting imports\nlint.extend-select = [\"I\"]\n\n# Do not enforce line length; black does this for code and we do not care about comments / docs\nlint.ignore = [\"E501\"]\n\n[lint.per-file-ignores]\n# Do not enforce usage and import order rules in init files\n\"__init__.py\" = [\"E402\", \"F401\", \"I\"]\n\"main.py\" = [\"E402\", \"F401\", \"I\"]\n\n# Do not fix import in compatibility module\n\"src/prefect/utilities/compat.py\" = [\"F401\", \"I\"]\n\n# Allow wild imports in conftest\n\"tests/conftest.py\" = [\"F405\", \"E402\", \"F403\"]\n\n# Allow fake items in __all__ for runtime\n\"src/prefect/runtime/*\" = [\"F822\"]\n\n# Do not enforce line length limits in migrations\n\"src/prefect/server/database/migrations/**/*\" = [\"E501\"]\n\n[lint.isort]\nknown-third-party = []\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.22265625,
          "content": "## Our pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making \nparticipation in our project and our community a harassment-free experience for everyone. This is regardless of age, body size, \ndisability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, \nnationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our standards\n\nExamples of behavior that contribute to creating a positive environment include:\n\n*   Using welcoming and inclusive language\n*   Being respectful of differing viewpoints and experiences\n*   Gracefully accepting constructive criticism\n*   Focusing on what is best for the community\n*   Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n*   The use of sexualized language or imagery and unwelcome sexual attention or advances\n*   Trolling, insulting/derogatory comments, and personal or political attacks\n*   Public or private harassment\n*   Publishing others' private information, such as a physical or electronic address, without explicit permission\n*   Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior. They are expected to take appropriate and \nfair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, \nand other contributions that are not aligned to this Code of Conduct. They may ban—temporarily or permanently—any contributor for \nother behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces. It also applies when an individual represents the project or its \ncommunity in public spaces. Examples of representing a project or community include using an official project email address, \nposting through an official social media account, or acting as an appointed representative at an online or offline event. \nProject maintainers may further clarify what \"representation of a project\" means.\n\n## Enforcement\n\nReport instances of abusive, harassing, or otherwise unacceptable behavior by contacting Chris White at \n[chris@prefect.io](mailto:chris@prefect.io). All complaints are reviewed and investigated. Each complaint will receive a \nresponse that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain \nconfidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted \nseparately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent \nrepercussions, as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant, version 1.4](https://www.contributor-covenant.org/version/1/4/code-of-conduct.html). \nSee the [Contributor Covenant FAQ](https://www.contributor-covenant.org/faq) for more information.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 4.25,
          "content": "# The version of Python in the final image\nARG PYTHON_VERSION=3.9\n# The base image to use for the final image; Prefect and its Python requirements will\n# be installed in this image. The default is the official Python slim image.\n# The following images are also available in this file:\n#   prefect-conda: Derivative of continuum/miniconda3 with a 'prefect' environment. Used for the 'conda' flavor.\n# Any image tag can be used, but it must have apt and pip.\nARG BASE_IMAGE=python:${PYTHON_VERSION}-slim\n# The version used to build the Python distributable.\nARG BUILD_PYTHON_VERSION=3.9\n# THe version used to build the UI distributable.\nARG NODE_VERSION=18.18.0\n# Any extra Python requirements to install\nARG EXTRA_PIP_PACKAGES=\"\"\n\n# Build the UI distributable.\nFROM node:${NODE_VERSION}-bullseye-slim AS ui-builder\n\nWORKDIR /opt/ui\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    # Required for arm64 builds\n    chromium \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Install a newer npm to avoid esbuild errors\nRUN npm install -g npm@8\n\n# Install dependencies separately so they cache\nCOPY ./ui/package*.json ./\nRUN npm ci\n\n# Build static UI files\nCOPY ./ui .\nRUN npm run build\n\n\n# Build the Python distributable.\n# Without this build step, versioneer cannot infer the version without git\n# see https://github.com/python-versioneer/python-versioneer/issues/215\nFROM python:${BUILD_PYTHON_VERSION}-slim AS python-builder\n\nWORKDIR /opt/prefect\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    gpg \\\n    git=1:2.* \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Copy the repository in; requires full git history for versions to generate correctly\nCOPY . ./\n\n# Package the UI into the distributable.\nCOPY --from=ui-builder /opt/ui/dist ./src/prefect/server/ui\n\n# Create a source distributable archive; ensuring existing dists are removed first\nRUN rm -rf dist && python setup.py sdist\nRUN mv \"dist/$(python setup.py --fullname).tar.gz\" \"dist/prefect.tar.gz\"\n\n\n# Setup a base final image from miniconda\nFROM continuumio/miniconda3 AS prefect-conda\n\n# Create a new conda environment with our required Python version\nARG PYTHON_VERSION\nRUN conda create \\\n    python=${PYTHON_VERSION} \\\n    --name prefect\n\n# Use the prefect environment by default\nRUN echo \"conda activate prefect\" >> ~/.bashrc\nSHELL [\"/bin/bash\", \"--login\", \"-c\"]\n\n\n\n# Build the final image with Prefect installed and our entrypoint configured\nFROM ${BASE_IMAGE} AS final\n\nENV LC_ALL=C.UTF-8\nENV LANG=C.UTF-8\n\nENV UV_LINK_MODE=copy\nENV UV_SYSTEM_PYTHON=1\n\nLABEL maintainer=\"help@prefect.io\" \\\n    io.prefect.python-version=${PYTHON_VERSION} \\\n    org.label-schema.schema-version=\"1.0\" \\\n    org.label-schema.name=\"prefect\" \\\n    org.label-schema.url=\"https://www.prefect.io/\"\n\nWORKDIR /opt/prefect\n\n# Install system requirements\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    tini=0.19.* \\\n    build-essential \\\n    git=1:2.* \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Install UV from official image - pin to specific version for build caching\nCOPY --from=ghcr.io/astral-sh/uv:0.5.8 /uv /uvx /bin/\n\n# Install dependencies using a temporary mount for requirements files\nRUN --mount=type=bind,source=requirements-client.txt,target=/tmp/requirements-client.txt \\\n    --mount=type=bind,source=requirements.txt,target=/tmp/requirements.txt \\\n    --mount=type=bind,source=requirements-otel.txt,target=/tmp/requirements-otel.txt \\\n    --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install --system -r /tmp/requirements.txt -r /tmp/requirements-client.txt -r /tmp/requirements-otel.txt\n\n# Install prefect from the sdist\nCOPY --from=python-builder /opt/prefect/dist ./dist\n\n# Extras to include during installation\nARG PREFECT_EXTRAS\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv pip install \"./dist/prefect.tar.gz${PREFECT_EXTRAS:-\"\"}\" && \\\n    rm -rf dist/\n\n# Remove setuptools\nRUN uv pip uninstall setuptools\n\n# Install any extra packages\nARG EXTRA_PIP_PACKAGES\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    [ -z \"${EXTRA_PIP_PACKAGES:-\"\"}\" ] || uv pip install \"${EXTRA_PIP_PACKAGES}\"\n\n# Smoke test\nRUN prefect version\n\n# Setup entrypoint\nCOPY scripts/entrypoint.sh ./entrypoint.sh\nENTRYPOINT [\"/usr/bin/tini\", \"-g\", \"--\", \"/opt/prefect/entrypoint.sh\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2019- Prefect Technologies, Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 1.1025390625,
          "content": "# Things to always exclude\nglobal-exclude .git*\nglobal-exclude .ipynb_checkpoints\nglobal-exclude *.py[co]\nglobal-exclude __pycache__/**\n\n# Top-level Config\ninclude LICENSE\ninclude MANIFEST.in\ninclude setup.cfg\ninclude versioneer.py\ninclude requirements.txt\ninclude requirements-dev.txt\ninclude requirements-client.txt\ninclude src/prefect/_version.py\ninclude src/prefect/py.typed\ninclude src/prefect/settings/profiles.toml\ninclude src/prefect/deployments/recipes/*/*.yaml\ninclude src/prefect/deployments/templates/*.yaml\ninclude src/prefect/.prefectignore\ninclude src/prefect/logging/logging.yml\ninclude src/prefect/cli/templates/*.yaml\ninclude src/prefect/server/collection_blocks_data.json\ninclude src/prefect/server/api/collections_data/views/*.json\n\n# Migrations\ninclude src/prefect/server/database/alembic.ini\ninclude src/prefect/server/database/_migrations/*\ninclude src/prefect/server/database/_migrations/versions/*\ninclude src/prefect/server/database/_migrations/versions/*/*\n\n# SQL templates\ngraft src/prefect/server/database/sql\n\n# Package files and data\ngraft src/prefect/server/ui\ngraft src/prefect/server/api/static\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.296875,
          "content": ".PHONY: docs\n\ndocs:\n\t@if [ ! -x \"./scripts/serve_docs\" ]; then \\\n\t\techo \"Error: The 'serve_docs' script is not executable.\"; \\\n\t\techo \"Please make it executable by running:\"; \\\n\t\techo \"  chmod +x \\\"./scripts/serve_docs\\\"\"; \\\n\t\techo \"Then, run 'make docs' again.\"; \\\n\t\texit 1; \\\n\tfi\n\t@./scripts/serve_docs"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.091796875,
          "content": "<p align=\"center\"><img src=\"https://github.com/PrefectHQ/prefect/assets/3407835/c654cbc6-63e8-4ada-a92a-efd2f8f24b85\" width=1000></p>\n\n<p align=\"center\">\n    <a href=\"https://pypi.python.org/pypi/prefect/\" alt=\"PyPI version\">\n        <img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/prefect?color=0052FF&labelColor=090422\"></a>\n    <a href=\"https://github.com/prefecthq/prefect/\" alt=\"Stars\">\n        <img src=\"https://img.shields.io/github/stars/prefecthq/prefect?color=0052FF&labelColor=090422\" /></a>\n    <a href=\"https://pepy.tech/badge/prefect/\" alt=\"Downloads\">\n        <img src=\"https://img.shields.io/pypi/dm/prefect?color=0052FF&labelColor=090422\" /></a>\n    <a href=\"https://github.com/prefecthq/prefect/pulse\" alt=\"Activity\">\n        <img src=\"https://img.shields.io/github/commit-activity/m/prefecthq/prefect?color=0052FF&labelColor=090422\" /></a>\n    <br>\n    <a href=\"https://prefect.io/slack\" alt=\"Slack\">\n        <img src=\"https://img.shields.io/badge/slack-join_community-red.svg?color=0052FF&labelColor=090422&logo=slack\" /></a>\n    <a href=\"https://www.youtube.com/c/PrefectIO/\" alt=\"YouTube\">\n        <img src=\"https://img.shields.io/badge/youtube-watch_videos-red.svg?color=0052FF&labelColor=090422&logo=youtube\" /></a>\n</p>\n\n# Prefect\n\nPrefect is a workflow orchestration framework for building data pipelines in Python.\nIt's the simplest way to elevate a script into a resilient production workflow.\nWith Prefect, you can build resilient, dynamic data pipelines that react to the world around them and recover from unexpected changes.\n\nWith just a few lines of code, data teams can confidently automate any data process with features such as scheduling, caching, retries, and event-based automations.\n\nWorkflow activity is tracked and can be monitored with a self-hosted [Prefect server](https://docs.prefect.io/latest/manage/self-host/?utm_source=oss&utm_medium=oss&utm_campaign=oss_gh_repo&utm_term=none&utm_content=none) instance or managed [Prefect Cloud](https://www.prefect.io/cloud-vs-oss?utm_source=oss&utm_medium=oss&utm_campaign=oss_gh_repo&utm_term=none&utm_content=none) dashboard.\n\n## Getting started\n\nPrefect requires Python 3.9 or later. To [install the latest or upgrade to the latest version of Prefect](https://docs.prefect.io/get-started/install), run the following command:\n\n```bash\npip install -U prefect\n```\n\nThen create and run a Python file that uses Prefect `flow` and `task` decorators to orchestrate and observe your workflow - in this case, a simple script that fetches the number of GitHub stars from a repository:\n\n```python\nfrom prefect import flow, task\nimport httpx\n\n\n@task(log_prints=True)\ndef get_stars(repo: str):\n    url = f\"https://api.github.com/repos/{repo}\"\n    count = httpx.get(url).json()[\"stargazers_count\"]\n    print(f\"{repo} has {count} stars!\")\n\n\n@flow(name=\"GitHub Stars\")\ndef github_stars(repos: list[str]):\n    for repo in repos:\n        get_stars(repo)\n\n\n# run the flow!\nif __name__==\"__main__\":\n    github_stars([\"PrefectHQ/Prefect\"])\n```\n\nFire up a Prefect server and open the UI at http://localhost:4200 to see what happened:\n\n```bash\nprefect server start\n```\n\nTo run your workflow on a schedule, turn it into a deployment and schedule it to run every minute by changing the last line of your script to the following:\n\n```python\nif __name__ == \"__main__\":\n    github_stars.serve(\n        name=\"first-deployment\",\n        cron=\"* * * * *\",\n        parameters={\"repos\": [\"PrefectHQ/prefect\"]}\n    )\n```\n\nYou now have a process running locally that is looking for scheduled deployments!\nAdditionally you can run your workflow manually from the UI or CLI. You can even run deployments in response to [events](https://docs.prefect.io/latest/automate/?utm_source=oss&utm_medium=oss&utm_campaign=oss_gh_repo&utm_term=none&utm_content=none).\n\n> [!NOTE]\n> To explore different infrastructure options for your workflows, check out the [deployment documentation](https://docs.prefect.io/v3/deploy).\n\n\n## Prefect Cloud\n\nPrefect Cloud provides workflow orchestration for the modern data enterprise. By automating over 200 million data tasks monthly, Prefect empowers diverse organizations — from Fortune 50 leaders such as Progressive Insurance to innovative disruptors such as Cash App — to increase engineering productivity, reduce pipeline errors, and cut data workflow compute costs.\n\nRead more about Prefect Cloud [here](https://www.prefect.io/cloud-vs-oss?utm_source=oss&utm_medium=oss&utm_campaign=oss_gh_repo&utm_term=none&utm_content=none) or sign up to [try it for yourself](https://app.prefect.cloud?utm_source=oss&utm_medium=oss&utm_campaign=oss_gh_repo&utm_term=none&utm_content=none).\n\n## prefect-client\n\nIf your use case is geared towards communicating with Prefect Cloud or a remote Prefect server, check out our\n[prefect-client](https://pypi.org/project/prefect-client/). It is a lighter-weight option for accessing client-side functionality in the Prefect SDK and is ideal for use in ephemeral execution environments.\n\n## Next steps\n\n- Check out the [Docs](https://docs.prefect.io/).\n- Join the [Prefect Slack community](https://prefect.io/slack).\n- Learn how to [contribute to Prefect](https://docs.prefect.io/contribute/).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.4716796875,
          "content": "# How to report a security issue\n\nTo report a (suspected) security issue, please email `bugbounty@prefect.io` and follow the instructions for our [bug bounty program](https://www.prefect.io/bug-bounty).\n\nPrefect will acknowledge receipt of your report in a timely manner, usually within 48 hours. After the initial reply to your report, the security team will keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance.\n"
        },
        {
          "name": "benches",
          "type": "tree",
          "content": null
        },
        {
          "name": "client",
          "type": "tree",
          "content": null
        },
        {
          "name": "compat-tests",
          "type": "commit",
          "content": null
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.513671875,
          "content": "services:\n  test-db:\n    image: postgres:14\n    ports:\n      - 15432:5432\n    environment:\n      POSTGRES_USER: prefect\n      POSTGRES_PASSWORD: prefect\n      POSTGRES_DB: prefect\n      LANG: 'C.UTF-8'\n      LANGUAGE: 'C.UTF-8'\n      LC_ALL: 'C.UTF-8'\n      LC_COLLATE: 'C.UTF-8'\n      LC_CTYPE: 'C.UTF-8'\n    tmpfs: /var/lib/postgresql/data\n    command:\n      - postgres\n      - -c\n      - max_connections=250\n  registry:\n      image: registry:2\n      container_name: prefect-test-registry\n      ports:\n        - \"5555:5000\"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "flows",
          "type": "tree",
          "content": null
        },
        {
          "name": "load_testing",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 1.541015625,
          "content": "site_name: Prefect SDK\nsite_url: https://docs-3.prefect.io/\nrepo_url: https://github.com/PrefectHQ/prefect\ndocs_dir: docs/mkdocs\nextra_css:\n    - stylesheets/theme.css\n    - stylesheets/admonitions.css\n    - stylesheets/api_ref.css\n    - stylesheets/rest_ref.css\n    - stylesheets/syntax_highlights.css\n    - stylesheets/extra.css\nmarkdown_extensions:\n    - admonition\n    - attr_list\n    - codehilite\n    - md_in_html\n    - meta\n    - pymdownx.highlight:\n          use_pygments: true\n    - pymdownx.details\n    - pymdownx.tabbed:\n          alternate_style: true\n\ntheme:\n    name: material\n    features:\n        - announce.dismiss\n        - content.code.copy\n        - navigation.tabs.sticky\n        - search.suggest\n        - search.highlight\n        - navigation.path\n        - navigation.indexes\n        - content.tabs.link\n    font:\n        text: Inter\n        code: Source Code Pro\n    logo: logo-word-white.svg\n    palette:\n        - media: \"(prefers-color-scheme: light)\"\n          accent: \"#0225AC\"\n          primary: \"#0225AC\"\n          scheme: default\n          toggle:\n              icon: material/weather-sunny\n              name: Switch to dark mode\n        - media: \"(prefers-color-scheme: dark)\"\n          accent: \"#0225AC\"\n          primary: \"#0225AC\"\n          scheme: slate\n          toggle:\n              icon: material/weather-night\n              name: Switch to light mode\n\nplugins:\n    - search\n    - mkdocstrings:\n          default_handler: python\n          handlers:\n              python:\n                  paths: [src]\nwatch:\n    - mkdocs.yml\n    - src\n"
        },
        {
          "name": "old-sqlite.Dockerfile",
          "type": "blob",
          "size": 1.4775390625,
          "content": "# Build the Python distributable\nFROM python:3.9-slim AS python-builder\n\nWORKDIR /opt/prefect\n\n# Install git for version calculation\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y \\\n    git \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Copy the repository for version calculation\nCOPY . .\n\n# Create source distribution\nRUN python setup.py sdist && \\\n    mv \"dist/$(python setup.py --fullname).tar.gz\" \"dist/prefect.tar.gz\"\n\n# Final image\nFROM python:3.9-slim\n\n# Accept SQLite version as build argument\nARG SQLITE_VERSION=\"3310100\"\nARG SQLITE_YEAR=\"2020\"\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    wget\n\n# Download and compile SQLite\nRUN wget https://www.sqlite.org/${SQLITE_YEAR}/sqlite-autoconf-${SQLITE_VERSION}.tar.gz \\\n    && tar xvfz sqlite-autoconf-${SQLITE_VERSION}.tar.gz \\\n    && cd sqlite-autoconf-${SQLITE_VERSION} \\\n    && ./configure \\\n    && make \\\n    && make install \\\n    && ldconfig \\\n    && cd .. \\\n    && rm -rf sqlite-autoconf-${SQLITE_VERSION}*\n\n# Install uv for faster pip operations\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv\nENV UV_SYSTEM_PYTHON=1\n\n# Set library path to use our compiled SQLite\nENV LD_LIBRARY_PATH=/usr/local/lib\n\nWORKDIR /app\n\n# Copy the built distributable\nCOPY --from=python-builder /opt/prefect/dist/prefect.tar.gz ./dist/\n\n# Install requirements and Prefect\nCOPY requirements*.txt ./\nRUN uv pip install -r requirements.txt\nRUN uv pip install ./dist/prefect.tar.gz\n\n\n"
        },
        {
          "name": "requirements-client.txt",
          "type": "blob",
          "size": 1.0546875,
          "content": "anyio >= 4.4.0, < 5.0.0\nasgi-lifespan >= 1.0, < 3.0\ncachetools >= 5.3, < 6.0\ncloudpickle >= 2.0, < 4.0\ncoolname >= 1.0.4, < 3.0.0\ncroniter >= 1.0.12, < 7.0.0\nexceptiongroup >= 1.0.0\nfastapi >= 0.111.0, < 1.0.0\nfsspec >= 2022.5.0\ngraphviz >= 0.20.1\ngriffe >= 0.49.0, <2.0.0\nhttpcore >=1.0.5, < 2.0.0\nhttpx[http2] >= 0.23, != 0.23.2\nimportlib_metadata >= 4.4; python_version < '3.10'\njsonpatch >= 1.32, < 2.0\njsonschema >= 4.0.0, < 5.0.0\nopentelemetry-api >= 1.27.0, < 2.0.0\norjson >= 3.7, < 4.0\npackaging >= 21.3, < 24.3\npathspec >= 0.8.0\npendulum >= 3.0.0, <4\nprometheus-client >= 0.20.0\npydantic >= 2.7, < 3.0.0, != 2.10.0\npydantic_core >= 2.12.0, < 3.0.0\npydantic_extra_types >= 2.8.2, < 3.0.0\npydantic_settings > 2.2.1\npython_dateutil >= 2.8.2, < 3.0.0\npython-slugify >= 5.0, < 9.0\npython-socks[asyncio] >= 2.5.3, < 3.0\npyyaml >= 5.4.1, < 7.0.0\nrfc3339-validator >= 0.1.4, < 0.2.0\nrich >= 11.0, < 14.0\nruamel.yaml >= 0.17.0\nsniffio >=1.3.0, < 2.0.0\ntoml >= 0.10.0\ntyping_extensions >= 4.5.0, < 5.0.0\nujson >= 5.8.0, < 6.0.0\nuvicorn >=0.14.0, !=0.29.0\nwebsockets >= 10.4, < 14.0"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.81640625,
          "content": "ruff\ncairosvg\ncodespell>=2.2.6\nipython\njinja2\nmoto >= 5\nmypy >= 1.9.0\nnumpy\npillow\npre-commit\npluggy >= 1.4.0\npytest >= 8.3\npytest-asyncio >= 0.24\npytest-benchmark\npytest-cov\npytest-env\npytest-flakefinder\npytest-mypy-plugins >= 3.2.0\npytest-timeout\npytest-xdist >= 3.6.1\npyyaml\nredis>=5.0.1\nsetuptools\nuv>=0.4.5\nvale\nvermin\nvirtualenv\nwatchfiles\nrespx\n\n# type stubs\ntypes-cachetools\ntypes-PyYAML\n\n# documentation\nmkdocs\nmkdocs-material\nmkdocstrings[python]\nmkdocs-gen-files\n\n# OpenTelemetry\n# Other than the `test-utils` package these versions should match the versions\n# in `requirements-otel.txt`\nopentelemetry-distro >= 0.48b0, < 1.0.0\nopentelemetry-exporter-otlp >= 1.27.0, < 2.0.0\nopentelemetry-instrumentation >= 0.48b0, < 1.0.0\nopentelemetry-instrumentation-logging >= 0.48b0, < 1.0.0\nopentelemetry-test-utils >= 0.48b0, < 1.0.0\n"
        },
        {
          "name": "requirements-markdown-tests.txt",
          "type": "blob",
          "size": 0.287109375,
          "content": "pytest-markdown-docs >= 0.6.0\n\npandas\nprefect-aws\nprefect-azure[blob_storage]\nprefect-bitbucket\nprefect-dask\nprefect-databricks\n# prefect-dbt\nprefect-email\nprefect-gcp\nprefect-github\nprefect-gitlab\nprefect-kubernetes\nprefect-ray\nprefect-shell\nprefect-slack\nprefect-snowflake\nprefect-sqlalchemy\n"
        },
        {
          "name": "requirements-otel.txt",
          "type": "blob",
          "size": 0.2724609375,
          "content": "# When updating this file, please also bump the versions in\n# `requirements-dev.txt`\n\nopentelemetry-distro >= 0.48b0, < 1.0.0\nopentelemetry-exporter-otlp >= 1.27.0, < 2.0.0\nopentelemetry-instrumentation >= 0.48b0, < 1.0.0\nopentelemetry-instrumentation-logging >= 0.48b0, < 1.0.0\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.4453125,
          "content": "-r requirements-client.txt\n\naiosqlite >= 0.17.0, < 1.0.0\nalembic >= 1.7.5, < 2.0.0\napprise >= 1.1.0, < 2.0.0\nasyncpg >= 0.23, < 1.0.0\nclick >= 8.0, < 8.2\ncryptography >= 36.0.1\ndateparser >= 1.1.1, < 2.0.0\ndocker >= 4.0, < 8.0\ngraphviz >= 0.20.1\njinja2 >= 3.0.0, < 4.0.0\njinja2-humanize-extension >= 0.4.0\nhumanize >= 4.9.0, < 5.0.0\npytz >= 2021.1, < 2025\nreadchar >= 4.0.0, < 5.0.0\nsqlalchemy[asyncio] >= 2.0, < 3.0.0\ntyper >= 0.12.0, != 0.12.2, < 0.14.0\n"
        },
        {
          "name": "schemas",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "settings_schema.json",
          "type": "blob",
          "size": 74.087890625,
          "content": "{\n    \"$defs\": {\n        \"APISettings\": {\n            \"description\": \"Settings for interacting with the Prefect API\",\n            \"properties\": {\n                \"url\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The URL of the Prefect API. If not set, the client will attempt to infer it.\",\n                    \"title\": \"Url\"\n                },\n                \"key\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"password\",\n                            \"type\": \"string\",\n                            \"writeOnly\": true\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The API key used for authentication with the Prefect API. Should be kept secret.\",\n                    \"title\": \"Key\"\n                },\n                \"tls_insecure_skip_verify\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, disables SSL checking to allow insecure requests. This is recommended only during development, e.g. when using self-signed certificates.\",\n                    \"title\": \"Tls Insecure Skip Verify\",\n                    \"type\": \"boolean\"\n                },\n                \"ssl_cert_file\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"This configuration settings option specifies the path to an SSL certificate file.\",\n                    \"title\": \"Ssl Cert File\"\n                },\n                \"enable_http2\": {\n                    \"default\": false,\n                    \"description\": \"If true, enable support for HTTP/2 for communicating with an API. If the API does not support HTTP/2, this will have no effect and connections will be made via HTTP/1.1.\",\n                    \"title\": \"Enable Http2\",\n                    \"type\": \"boolean\"\n                },\n                \"request_timeout\": {\n                    \"default\": 60.0,\n                    \"description\": \"The default timeout for requests to the API\",\n                    \"title\": \"Request Timeout\",\n                    \"type\": \"number\"\n                }\n            },\n            \"title\": \"APISettings\",\n            \"type\": \"object\"\n        },\n        \"CLISettings\": {\n            \"description\": \"Settings for controlling CLI behavior\",\n            \"properties\": {\n                \"colors\": {\n                    \"default\": true,\n                    \"description\": \"If True, use colors in CLI output. If `False`, output will not include colors codes.\",\n                    \"title\": \"Colors\",\n                    \"type\": \"boolean\"\n                },\n                \"prompt\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"boolean\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"If `True`, use interactive prompts in CLI commands. If `False`, no interactive prompts will be used. If `None`, the value will be dynamically determined based on the presence of an interactive-enabled terminal.\",\n                    \"title\": \"Prompt\"\n                },\n                \"wrap_lines\": {\n                    \"default\": true,\n                    \"description\": \"If `True`, wrap text by inserting new lines in long lines in CLI output. If `False`, output will not be wrapped.\",\n                    \"title\": \"Wrap Lines\",\n                    \"type\": \"boolean\"\n                }\n            },\n            \"title\": \"CLISettings\",\n            \"type\": \"object\"\n        },\n        \"ClientMetricsSettings\": {\n            \"description\": \"Settings for controlling metrics reporting from the client\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": false,\n                    \"description\": \"Whether or not to enable Prometheus metrics in the client.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"port\": {\n                    \"default\": 4201,\n                    \"description\": \"The port to expose the client Prometheus metrics on.\",\n                    \"title\": \"Port\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"ClientMetricsSettings\",\n            \"type\": \"object\"\n        },\n        \"ClientSettings\": {\n            \"description\": \"Settings for controlling API client behavior\",\n            \"properties\": {\n                \"max_retries\": {\n                    \"default\": 5,\n                    \"description\": \"\\n        The maximum number of retries to perform on failed HTTP requests.\\n        Defaults to 5. Set to 0 to disable retries.\\n        See `PREFECT_CLIENT_RETRY_EXTRA_CODES` for details on which HTTP status codes are\\n        retried.\\n        \",\n                    \"minimum\": 0,\n                    \"title\": \"Max Retries\",\n                    \"type\": \"integer\"\n                },\n                \"retry_jitter_factor\": {\n                    \"default\": 0.2,\n                    \"description\": \"\\n        A value greater than or equal to zero to control the amount of jitter added to retried\\n        client requests. Higher values introduce larger amounts of jitter.\\n        Set to 0 to disable jitter. See `clamped_poisson_interval` for details on the how jitter\\n        can affect retry lengths.\\n        \",\n                    \"minimum\": 0.0,\n                    \"title\": \"Retry Jitter Factor\",\n                    \"type\": \"number\"\n                },\n                \"retry_extra_codes\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"maximum\": 599,\n                            \"minimum\": 100,\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"items\": {\n                                \"maximum\": 599,\n                                \"minimum\": 100,\n                                \"type\": \"integer\"\n                            },\n                            \"type\": \"array\",\n                            \"uniqueItems\": true\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"description\": \"\\n        A list of extra HTTP status codes to retry on. Defaults to an empty list.\\n        429, 502 and 503 are always retried. Please note that not all routes are idempotent and retrying\\n        may result in unexpected behavior.\\n        \",\n                    \"examples\": [\n                        \"404,429,503\",\n                        \"429\",\n                        [\n                            404,\n                            429,\n                            503\n                        ]\n                    ],\n                    \"title\": \"Retry Extra Codes\"\n                },\n                \"csrf_support_enabled\": {\n                    \"default\": true,\n                    \"description\": \"\\n        Determines if CSRF token handling is active in the Prefect client for API\\n        requests.\\n\\n        When enabled (`True`), the client automatically manages CSRF tokens by\\n        retrieving, storing, and including them in applicable state-changing requests\\n        \",\n                    \"title\": \"Csrf Support Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"metrics\": {\n                    \"$ref\": \"#/$defs/ClientMetricsSettings\"\n                }\n            },\n            \"title\": \"ClientSettings\",\n            \"type\": \"object\"\n        },\n        \"CloudSettings\": {\n            \"description\": \"Settings for interacting with Prefect Cloud\",\n            \"properties\": {\n                \"api_url\": {\n                    \"default\": \"https://api.prefect.cloud/api\",\n                    \"description\": \"API URL for Prefect Cloud. Used for authentication with Prefect Cloud.\",\n                    \"title\": \"Api Url\",\n                    \"type\": \"string\"\n                },\n                \"ui_url\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The URL of the Prefect Cloud UI. If not set, the client will attempt to infer it.\",\n                    \"title\": \"Ui Url\"\n                }\n            },\n            \"title\": \"CloudSettings\",\n            \"type\": \"object\"\n        },\n        \"DeploymentsSettings\": {\n            \"description\": \"Settings for configuring deployments defaults\",\n            \"properties\": {\n                \"default_work_pool_name\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The default work pool to use when creating deployments.\",\n                    \"title\": \"Default Work Pool Name\"\n                },\n                \"default_docker_build_namespace\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The default Docker namespace to use when building images.\",\n                    \"examples\": [\n                        \"my-dockerhub-registry\",\n                        \"4999999999999.dkr.ecr.us-east-2.amazonaws.com/my-ecr-repo\"\n                    ],\n                    \"title\": \"Default Docker Build Namespace\"\n                }\n            },\n            \"title\": \"DeploymentsSettings\",\n            \"type\": \"object\"\n        },\n        \"FlowsSettings\": {\n            \"description\": \"Settings for controlling flow behavior\",\n            \"properties\": {\n                \"default_retries\": {\n                    \"default\": 0,\n                    \"description\": \"This value sets the default number of retries for all flows.\",\n                    \"minimum\": 0,\n                    \"title\": \"Default Retries\",\n                    \"type\": \"integer\"\n                },\n                \"default_retry_delay_seconds\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"number\"\n                        },\n                        {\n                            \"items\": {\n                                \"type\": \"number\"\n                            },\n                            \"type\": \"array\"\n                        }\n                    ],\n                    \"default\": 0,\n                    \"description\": \"This value sets the default retry delay seconds for all flows.\",\n                    \"title\": \"Default Retry Delay Seconds\"\n                }\n            },\n            \"title\": \"FlowsSettings\",\n            \"type\": \"object\"\n        },\n        \"InternalSettings\": {\n            \"properties\": {\n                \"logging_level\": {\n                    \"default\": \"ERROR\",\n                    \"description\": \"The default logging level for Prefect's internal machinery loggers.\",\n                    \"enum\": [\n                        \"DEBUG\",\n                        \"INFO\",\n                        \"WARNING\",\n                        \"ERROR\",\n                        \"CRITICAL\"\n                    ],\n                    \"title\": \"Logging Level\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"InternalSettings\",\n            \"type\": \"object\"\n        },\n        \"LoggingSettings\": {\n            \"description\": \"Settings for controlling logging behavior\",\n            \"properties\": {\n                \"level\": {\n                    \"default\": \"INFO\",\n                    \"description\": \"The default logging level for Prefect loggers.\",\n                    \"enum\": [\n                        \"DEBUG\",\n                        \"INFO\",\n                        \"WARNING\",\n                        \"ERROR\",\n                        \"CRITICAL\"\n                    ],\n                    \"title\": \"Level\",\n                    \"type\": \"string\"\n                },\n                \"config_path\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"path\",\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The path to a custom YAML logging configuration file.\",\n                    \"title\": \"Config Path\"\n                },\n                \"extra_loggers\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"items\": {\n                                \"type\": \"string\"\n                            },\n                            \"type\": \"array\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"Additional loggers to attach to Prefect logging at runtime.\",\n                    \"title\": \"Extra Loggers\"\n                },\n                \"log_prints\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, `print` statements in flows and tasks will be redirected to the Prefect logger for the given run.\",\n                    \"title\": \"Log Prints\",\n                    \"type\": \"boolean\"\n                },\n                \"colors\": {\n                    \"default\": true,\n                    \"description\": \"If `True`, use colors in CLI output. If `False`, output will not include colors codes.\",\n                    \"title\": \"Colors\",\n                    \"type\": \"boolean\"\n                },\n                \"markup\": {\n                    \"default\": false,\n                    \"description\": \"\\n        Whether to interpret strings wrapped in square brackets as a style.\\n        This allows styles to be conveniently added to log messages, e.g.\\n        `[red]This is a red message.[/red]`. However, the downside is, if enabled,\\n        strings that contain square brackets may be inaccurately interpreted and\\n        lead to incomplete output, e.g.\\n        `[red]This is a red message.[/red]` may be interpreted as\\n        `[red]This is a red message.[/red]`.\\n        \",\n                    \"title\": \"Markup\",\n                    \"type\": \"boolean\"\n                },\n                \"to_api\": {\n                    \"$ref\": \"#/$defs/LoggingToAPISettings\"\n                }\n            },\n            \"title\": \"LoggingSettings\",\n            \"type\": \"object\"\n        },\n        \"LoggingToAPISettings\": {\n            \"description\": \"Settings for controlling logging to the API\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"If `True`, logs will be sent to the API.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"batch_interval\": {\n                    \"default\": 2.0,\n                    \"description\": \"The number of seconds between batched writes of logs to the API.\",\n                    \"title\": \"Batch Interval\",\n                    \"type\": \"number\"\n                },\n                \"batch_size\": {\n                    \"default\": 4000000,\n                    \"description\": \"The number of logs to batch before sending to the API.\",\n                    \"title\": \"Batch Size\",\n                    \"type\": \"integer\"\n                },\n                \"max_log_size\": {\n                    \"default\": 1000000,\n                    \"description\": \"The maximum size in bytes for a single log.\",\n                    \"title\": \"Max Log Size\",\n                    \"type\": \"integer\"\n                },\n                \"when_missing_flow\": {\n                    \"default\": \"warn\",\n                    \"description\": \"\\n        Controls the behavior when loggers attempt to send logs to the API handler from outside of a flow.\\n        \\n        All logs sent to the API must be associated with a flow run. The API log handler can\\n        only be used outside of a flow by manually providing a flow run identifier. Logs\\n        that are not associated with a flow run will not be sent to the API. This setting can\\n        be used to determine if a warning or error is displayed when the identifier is missing.\\n\\n        The following options are available:\\n\\n        - \\\"warn\\\": Log a warning message.\\n        - \\\"error\\\": Raise an error.\\n        - \\\"ignore\\\": Do not log a warning message or raise an error.\\n        \",\n                    \"enum\": [\n                        \"warn\",\n                        \"error\",\n                        \"ignore\"\n                    ],\n                    \"title\": \"When Missing Flow\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"LoggingToAPISettings\",\n            \"type\": \"object\"\n        },\n        \"ResultsSettings\": {\n            \"description\": \"Settings for controlling result storage behavior\",\n            \"properties\": {\n                \"default_serializer\": {\n                    \"default\": \"pickle\",\n                    \"description\": \"The default serializer to use when not otherwise specified.\",\n                    \"title\": \"Default Serializer\",\n                    \"type\": \"string\"\n                },\n                \"persist_by_default\": {\n                    \"default\": false,\n                    \"description\": \"The default setting for persisting results when not otherwise specified.\",\n                    \"title\": \"Persist By Default\",\n                    \"type\": \"boolean\"\n                },\n                \"default_storage_block\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The `block-type/block-document` slug of a block to use as the default result storage.\",\n                    \"title\": \"Default Storage Block\"\n                },\n                \"local_storage_path\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"path\",\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The path to a directory to store results in.\",\n                    \"title\": \"Local Storage Path\"\n                }\n            },\n            \"title\": \"ResultsSettings\",\n            \"type\": \"object\"\n        },\n        \"RunnerServerSettings\": {\n            \"description\": \"Settings for controlling runner server behavior\",\n            \"properties\": {\n                \"enable\": {\n                    \"default\": false,\n                    \"description\": \"Whether or not to enable the runner's webserver.\",\n                    \"title\": \"Enable\",\n                    \"type\": \"boolean\"\n                },\n                \"host\": {\n                    \"default\": \"localhost\",\n                    \"description\": \"The host address the runner's webserver should bind to.\",\n                    \"title\": \"Host\",\n                    \"type\": \"string\"\n                },\n                \"port\": {\n                    \"default\": 8080,\n                    \"description\": \"The port the runner's webserver should bind to.\",\n                    \"title\": \"Port\",\n                    \"type\": \"integer\"\n                },\n                \"log_level\": {\n                    \"default\": \"error\",\n                    \"description\": \"The log level of the runner's webserver.\",\n                    \"enum\": [\n                        \"DEBUG\",\n                        \"INFO\",\n                        \"WARNING\",\n                        \"ERROR\",\n                        \"CRITICAL\"\n                    ],\n                    \"title\": \"Log Level\",\n                    \"type\": \"string\"\n                },\n                \"missed_polls_tolerance\": {\n                    \"default\": 2,\n                    \"description\": \"Number of missed polls before a runner is considered unhealthy by its webserver.\",\n                    \"title\": \"Missed Polls Tolerance\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"RunnerServerSettings\",\n            \"type\": \"object\"\n        },\n        \"RunnerSettings\": {\n            \"description\": \"Settings for controlling runner behavior\",\n            \"properties\": {\n                \"process_limit\": {\n                    \"default\": 5,\n                    \"description\": \"Maximum number of processes a runner will execute in parallel.\",\n                    \"title\": \"Process Limit\",\n                    \"type\": \"integer\"\n                },\n                \"poll_frequency\": {\n                    \"default\": 10,\n                    \"description\": \"Number of seconds a runner should wait between queries for scheduled work.\",\n                    \"title\": \"Poll Frequency\",\n                    \"type\": \"integer\"\n                },\n                \"server\": {\n                    \"$ref\": \"#/$defs/RunnerServerSettings\"\n                }\n            },\n            \"title\": \"RunnerSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerAPISettings\": {\n            \"description\": \"Settings for controlling API server behavior\",\n            \"properties\": {\n                \"host\": {\n                    \"default\": \"127.0.0.1\",\n                    \"description\": \"The API's host address (defaults to `127.0.0.1`).\",\n                    \"title\": \"Host\",\n                    \"type\": \"string\"\n                },\n                \"port\": {\n                    \"default\": 4200,\n                    \"description\": \"The API's port address (defaults to `4200`).\",\n                    \"title\": \"Port\",\n                    \"type\": \"integer\"\n                },\n                \"default_limit\": {\n                    \"default\": 200,\n                    \"description\": \"The default limit applied to queries that can return multiple objects, such as `POST /flow_runs/filter`.\",\n                    \"title\": \"Default Limit\",\n                    \"type\": \"integer\"\n                },\n                \"keepalive_timeout\": {\n                    \"default\": 5,\n                    \"description\": \"\\n        The API's keep alive timeout (defaults to `5`).\\n        Refer to https://www.uvicorn.org/settings/#timeouts for details.\\n\\n        When the API is hosted behind a load balancer, you may want to set this to a value\\n        greater than the load balancer's idle timeout.\\n\\n        Note this setting only applies when calling `prefect server start`; if hosting the\\n        API with another tool you will need to configure this there instead.\\n        \",\n                    \"title\": \"Keepalive Timeout\",\n                    \"type\": \"integer\"\n                },\n                \"csrf_protection_enabled\": {\n                    \"default\": false,\n                    \"description\": \"\\n        Controls the activation of CSRF protection for the Prefect server API.\\n\\n        When enabled (`True`), the server enforces CSRF validation checks on incoming\\n        state-changing requests (POST, PUT, PATCH, DELETE), requiring a valid CSRF\\n        token to be included in the request headers or body. This adds a layer of\\n        security by preventing unauthorized or malicious sites from making requests on\\n        behalf of authenticated users.\\n\\n        It is recommended to enable this setting in production environments where the\\n        API is exposed to web clients to safeguard against CSRF attacks.\\n\\n        Note: Enabling this setting requires corresponding support in the client for\\n        CSRF token management. See PREFECT_CLIENT_CSRF_SUPPORT_ENABLED for more.\\n        \",\n                    \"title\": \"Csrf Protection Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"csrf_token_expiration\": {\n                    \"default\": \"PT1H\",\n                    \"description\": \"\\n        Specifies the duration for which a CSRF token remains valid after being issued\\n        by the server.\\n\\n        The default expiration time is set to 1 hour, which offers a reasonable\\n        compromise. Adjust this setting based on your specific security requirements\\n        and usage patterns.\\n        \",\n                    \"format\": \"duration\",\n                    \"title\": \"Csrf Token Expiration\",\n                    \"type\": \"string\"\n                },\n                \"cors_allowed_origins\": {\n                    \"default\": \"*\",\n                    \"description\": \"\\n        A comma-separated list of origins that are authorized to make cross-origin requests to the API.\\n\\n        By default, this is set to `*`, which allows requests from all origins.\\n        \",\n                    \"title\": \"Cors Allowed Origins\",\n                    \"type\": \"string\"\n                },\n                \"cors_allowed_methods\": {\n                    \"default\": \"*\",\n                    \"description\": \"\\n        A comma-separated list of methods that are authorized to make cross-origin requests to the API.\\n\\n        By default, this is set to `*`, which allows requests from all methods.\\n        \",\n                    \"title\": \"Cors Allowed Methods\",\n                    \"type\": \"string\"\n                },\n                \"cors_allowed_headers\": {\n                    \"default\": \"*\",\n                    \"description\": \"\\n        A comma-separated list of headers that are authorized to make cross-origin requests to the API.\\n\\n        By default, this is set to `*`, which allows requests from all headers.\\n        \",\n                    \"title\": \"Cors Allowed Headers\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"ServerAPISettings\",\n            \"type\": \"object\"\n        },\n        \"ServerDatabaseSettings\": {\n            \"description\": \"Settings for controlling server database behavior\",\n            \"properties\": {\n                \"connection_url\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"password\",\n                            \"type\": \"string\",\n                            \"writeOnly\": true\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"\\n        A database connection URL in a SQLAlchemy-compatible\\n        format. Prefect currently supports SQLite and Postgres. Note that all\\n        Prefect database engines must use an async driver - for SQLite, use\\n        `sqlite+aiosqlite` and for Postgres use `postgresql+asyncpg`.\\n\\n        SQLite in-memory databases can be used by providing the url\\n        `sqlite+aiosqlite:///file::memory:?cache=shared&uri=true&check_same_thread=false`,\\n        which will allow the database to be accessed by multiple threads. Note\\n        that in-memory databases can not be accessed from multiple processes and\\n        should only be used for simple tests.\\n        \",\n                    \"title\": \"Connection Url\"\n                },\n                \"driver\": {\n                    \"anyOf\": [\n                        {\n                            \"enum\": [\n                                \"postgresql+asyncpg\",\n                                \"sqlite+aiosqlite\"\n                            ],\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The database driver to use when connecting to the database. If not set, the driver will be inferred from the connection URL.\",\n                    \"title\": \"Driver\"\n                },\n                \"host\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The database server host.\",\n                    \"title\": \"Host\"\n                },\n                \"port\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The database server port.\",\n                    \"title\": \"Port\"\n                },\n                \"user\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The user to use when connecting to the database.\",\n                    \"title\": \"User\"\n                },\n                \"name\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The name of the Prefect database on the remote server, or the path to the database file for SQLite.\",\n                    \"title\": \"Name\"\n                },\n                \"password\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"password\",\n                            \"type\": \"string\",\n                            \"writeOnly\": true\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The password to use when connecting to the database. Should be kept secret.\",\n                    \"title\": \"Password\"\n                },\n                \"echo\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, SQLAlchemy will log all SQL issued to the database. Defaults to `False`.\",\n                    \"title\": \"Echo\",\n                    \"type\": \"boolean\"\n                },\n                \"migrate_on_start\": {\n                    \"default\": true,\n                    \"description\": \"If `True`, the database will be migrated on application startup.\",\n                    \"title\": \"Migrate On Start\",\n                    \"type\": \"boolean\"\n                },\n                \"timeout\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"number\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": 10.0,\n                    \"description\": \"A statement timeout, in seconds, applied to all database interactions made by the API. Defaults to 10 seconds.\",\n                    \"title\": \"Timeout\"\n                },\n                \"connection_timeout\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"number\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": 5,\n                    \"description\": \"A connection timeout, in seconds, applied to database connections. Defaults to `5`.\",\n                    \"title\": \"Connection Timeout\"\n                },\n                \"sqlalchemy_pool_size\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"Controls connection pool size when using a PostgreSQL database with the Prefect API. If not set, the default SQLAlchemy pool size will be used.\",\n                    \"title\": \"Sqlalchemy Pool Size\"\n                },\n                \"sqlalchemy_max_overflow\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"Controls maximum overflow of the connection pool when using a PostgreSQL database with the Prefect API. If not set, the default SQLAlchemy maximum overflow value will be used.\",\n                    \"title\": \"Sqlalchemy Max Overflow\"\n                }\n            },\n            \"title\": \"ServerDatabaseSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerDeploymentsSettings\": {\n            \"properties\": {\n                \"concurrency_slot_wait_seconds\": {\n                    \"default\": 30.0,\n                    \"description\": \"The number of seconds to wait before retrying when a deployment flow run cannot secure a concurrency slot from the server.\",\n                    \"minimum\": 0.0,\n                    \"title\": \"Concurrency Slot Wait Seconds\",\n                    \"type\": \"number\"\n                }\n            },\n            \"title\": \"ServerDeploymentsSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerEphemeralSettings\": {\n            \"description\": \"Settings for controlling ephemeral server behavior\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": false,\n                    \"description\": \"\\n        Controls whether or not a subprocess server can be started when no API URL is provided.\\n        \",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"startup_timeout_seconds\": {\n                    \"default\": 20,\n                    \"description\": \"\\n        The number of seconds to wait for the server to start when ephemeral mode is enabled.\\n        Defaults to `10`.\\n        \",\n                    \"title\": \"Startup Timeout Seconds\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"ServerEphemeralSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerEventsSettings\": {\n            \"description\": \"Settings for controlling behavior of the events subsystem\",\n            \"properties\": {\n                \"stream_out_enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to stream events out to the API via websockets.\",\n                    \"title\": \"Stream Out Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"related_resource_cache_ttl\": {\n                    \"default\": \"PT5M\",\n                    \"description\": \"The number of seconds to cache related resources for in the API.\",\n                    \"format\": \"duration\",\n                    \"title\": \"Related Resource Cache Ttl\",\n                    \"type\": \"string\"\n                },\n                \"maximum_labels_per_resource\": {\n                    \"default\": 500,\n                    \"description\": \"The maximum number of labels a resource may have.\",\n                    \"title\": \"Maximum Labels Per Resource\",\n                    \"type\": \"integer\"\n                },\n                \"maximum_related_resources\": {\n                    \"default\": 500,\n                    \"description\": \"The maximum number of related resources an Event may have.\",\n                    \"title\": \"Maximum Related Resources\",\n                    \"type\": \"integer\"\n                },\n                \"maximum_size_bytes\": {\n                    \"default\": 1500000,\n                    \"description\": \"The maximum size of an Event when serialized to JSON\",\n                    \"title\": \"Maximum Size Bytes\",\n                    \"type\": \"integer\"\n                },\n                \"expired_bucket_buffer\": {\n                    \"default\": \"PT1M\",\n                    \"description\": \"The amount of time to retain expired automation buckets\",\n                    \"format\": \"duration\",\n                    \"title\": \"Expired Bucket Buffer\",\n                    \"type\": \"string\"\n                },\n                \"proactive_granularity\": {\n                    \"default\": \"PT5S\",\n                    \"description\": \"How frequently proactive automations are evaluated\",\n                    \"format\": \"duration\",\n                    \"title\": \"Proactive Granularity\",\n                    \"type\": \"string\"\n                },\n                \"retention_period\": {\n                    \"default\": \"P7D\",\n                    \"description\": \"The amount of time to retain events in the database.\",\n                    \"format\": \"duration\",\n                    \"title\": \"Retention Period\",\n                    \"type\": \"string\"\n                },\n                \"maximum_websocket_backfill\": {\n                    \"default\": \"PT15M\",\n                    \"description\": \"The maximum range to look back for backfilling events for a websocket subscriber.\",\n                    \"format\": \"duration\",\n                    \"title\": \"Maximum Websocket Backfill\",\n                    \"type\": \"string\"\n                },\n                \"websocket_backfill_page_size\": {\n                    \"default\": 250,\n                    \"description\": \"The page size for the queries to backfill events for websocket subscribers.\",\n                    \"exclusiveMinimum\": 0,\n                    \"title\": \"Websocket Backfill Page Size\",\n                    \"type\": \"integer\"\n                },\n                \"messaging_broker\": {\n                    \"default\": \"prefect.server.utilities.messaging.memory\",\n                    \"description\": \"Which message broker implementation to use for the messaging system, should point to a module that exports a Publisher and Consumer class.\",\n                    \"title\": \"Messaging Broker\",\n                    \"type\": \"string\"\n                },\n                \"messaging_cache\": {\n                    \"default\": \"prefect.server.utilities.messaging.memory\",\n                    \"description\": \"Which cache implementation to use for the events system.  Should point to a module that exports a Cache class.\",\n                    \"title\": \"Messaging Cache\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"ServerEventsSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerFlowRunGraphSettings\": {\n            \"description\": \"Settings for controlling behavior of the flow run graph\",\n            \"properties\": {\n                \"max_nodes\": {\n                    \"default\": 10000,\n                    \"description\": \"The maximum size of a flow run graph on the v2 API\",\n                    \"title\": \"Max Nodes\",\n                    \"type\": \"integer\"\n                },\n                \"max_artifacts\": {\n                    \"default\": 10000,\n                    \"description\": \"The maximum number of artifacts to show on a flow run graph on the v2 API\",\n                    \"title\": \"Max Artifacts\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"ServerFlowRunGraphSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesCancellationCleanupSettings\": {\n            \"description\": \"Settings for controlling the cancellation cleanup service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the cancellation cleanup service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"loop_seconds\": {\n                    \"default\": 20,\n                    \"description\": \"The cancellation cleanup service will look for non-terminal tasks and subflows this often. Defaults to `20`.\",\n                    \"title\": \"Loop Seconds\",\n                    \"type\": \"number\"\n                }\n            },\n            \"title\": \"ServerServicesCancellationCleanupSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesEventPersisterSettings\": {\n            \"description\": \"Settings for controlling the event persister service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the event persister service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"batch_size\": {\n                    \"default\": 20,\n                    \"description\": \"The number of events the event persister will attempt to insert in one batch.\",\n                    \"exclusiveMinimum\": 0,\n                    \"title\": \"Batch Size\",\n                    \"type\": \"integer\"\n                },\n                \"flush_interval\": {\n                    \"default\": 5,\n                    \"description\": \"The maximum number of seconds between flushes of the event persister.\",\n                    \"exclusiveMinimum\": 0.0,\n                    \"title\": \"Flush Interval\",\n                    \"type\": \"number\"\n                }\n            },\n            \"title\": \"ServerServicesEventPersisterSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesFlowRunNotificationsSettings\": {\n            \"description\": \"Settings for controlling the flow run notifications service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the flow run notifications service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                }\n            },\n            \"title\": \"ServerServicesFlowRunNotificationsSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesForemanSettings\": {\n            \"description\": \"Settings for controlling the foreman service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the foreman service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"loop_seconds\": {\n                    \"default\": 15,\n                    \"description\": \"The foreman service will check for offline workers this often. Defaults to `15`.\",\n                    \"title\": \"Loop Seconds\",\n                    \"type\": \"number\"\n                },\n                \"inactivity_heartbeat_multiple\": {\n                    \"default\": 3,\n                    \"description\": \"\\n        The number of heartbeats that must be missed before a worker is marked as offline. Defaults to `3`.\\n        \",\n                    \"title\": \"Inactivity Heartbeat Multiple\",\n                    \"type\": \"integer\"\n                },\n                \"fallback_heartbeat_interval_seconds\": {\n                    \"default\": 30,\n                    \"description\": \"\\n        The number of seconds to use for online/offline evaluation if a worker's heartbeat\\n        interval is not set. Defaults to `30`.\\n        \",\n                    \"title\": \"Fallback Heartbeat Interval Seconds\",\n                    \"type\": \"integer\"\n                },\n                \"deployment_last_polled_timeout_seconds\": {\n                    \"default\": 60,\n                    \"description\": \"\\n        The number of seconds before a deployment is marked as not ready if it has not been\\n        polled. Defaults to `60`.\\n        \",\n                    \"title\": \"Deployment Last Polled Timeout Seconds\",\n                    \"type\": \"integer\"\n                },\n                \"work_queue_last_polled_timeout_seconds\": {\n                    \"default\": 60,\n                    \"description\": \"\\n        The number of seconds before a work queue is marked as not ready if it has not been\\n        polled. Defaults to `60`.\\n        \",\n                    \"title\": \"Work Queue Last Polled Timeout Seconds\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"ServerServicesForemanSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesLateRunsSettings\": {\n            \"description\": \"Settings for controlling the late runs service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the late runs service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"loop_seconds\": {\n                    \"default\": 5,\n                    \"description\": \"\\n        The late runs service will look for runs to mark as late this often. Defaults to `5`.\\n        \",\n                    \"title\": \"Loop Seconds\",\n                    \"type\": \"number\"\n                },\n                \"after_seconds\": {\n                    \"default\": \"PT15S\",\n                    \"description\": \"\\n        The late runs service will mark runs as late after they have exceeded their scheduled start time by this many seconds. Defaults to `5` seconds.\\n        \",\n                    \"format\": \"duration\",\n                    \"title\": \"After Seconds\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"ServerServicesLateRunsSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesPauseExpirationsSettings\": {\n            \"description\": \"Settings for controlling the pause expiration service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"\\n        Whether or not to start the paused flow run expiration service in the server\\n        application. If disabled, paused flows that have timed out will remain in a Paused state\\n        until a resume attempt.\\n        \",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"loop_seconds\": {\n                    \"default\": 5,\n                    \"description\": \"\\n        The pause expiration service will look for runs to mark as failed this often. Defaults to `5`.\\n        \",\n                    \"title\": \"Loop Seconds\",\n                    \"type\": \"number\"\n                }\n            },\n            \"title\": \"ServerServicesPauseExpirationsSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesSchedulerSettings\": {\n            \"description\": \"Settings for controlling the scheduler service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the scheduler service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"loop_seconds\": {\n                    \"default\": 60,\n                    \"description\": \"\\n        The scheduler loop interval, in seconds. This determines\\n        how often the scheduler will attempt to schedule new flow runs, but has no\\n        impact on how quickly either flow runs or task runs are actually executed.\\n        Defaults to `60`.\\n        \",\n                    \"title\": \"Loop Seconds\",\n                    \"type\": \"number\"\n                },\n                \"deployment_batch_size\": {\n                    \"default\": 100,\n                    \"description\": \"\\n        The number of deployments the scheduler will attempt to\\n        schedule in a single batch. If there are more deployments than the batch\\n        size, the scheduler immediately attempts to schedule the next batch; it\\n        does not sleep for `scheduler_loop_seconds` until it has visited every\\n        deployment once. Defaults to `100`.\\n        \",\n                    \"title\": \"Deployment Batch Size\",\n                    \"type\": \"integer\"\n                },\n                \"max_runs\": {\n                    \"default\": 100,\n                    \"description\": \"\\n        The scheduler will attempt to schedule up to this many\\n        auto-scheduled runs in the future. Note that runs may have fewer than\\n        this many scheduled runs, depending on the value of\\n        `scheduler_max_scheduled_time`.  Defaults to `100`.\\n        \",\n                    \"title\": \"Max Runs\",\n                    \"type\": \"integer\"\n                },\n                \"min_runs\": {\n                    \"default\": 3,\n                    \"description\": \"\\n        The scheduler will attempt to schedule at least this many\\n        auto-scheduled runs in the future. Note that runs may have more than\\n        this many scheduled runs, depending on the value of\\n        `scheduler_min_scheduled_time`.  Defaults to `3`.\\n        \",\n                    \"title\": \"Min Runs\",\n                    \"type\": \"integer\"\n                },\n                \"max_scheduled_time\": {\n                    \"default\": \"P100D\",\n                    \"description\": \"\\n        The scheduler will create new runs up to this far in the\\n        future. Note that this setting will take precedence over\\n        `scheduler_max_runs`: if a flow runs once a month and\\n        `scheduler_max_scheduled_time` is three months, then only three runs will be\\n        scheduled. Defaults to 100 days (`8640000` seconds).\\n        \",\n                    \"format\": \"duration\",\n                    \"title\": \"Max Scheduled Time\",\n                    \"type\": \"string\"\n                },\n                \"min_scheduled_time\": {\n                    \"default\": \"PT1H\",\n                    \"description\": \"\\n        The scheduler will create new runs at least this far in the\\n        future. Note that this setting will take precedence over `scheduler_min_runs`:\\n        if a flow runs every hour and `scheduler_min_scheduled_time` is three hours,\\n        then three runs will be scheduled even if `scheduler_min_runs` is 1. Defaults to\\n        \",\n                    \"format\": \"duration\",\n                    \"title\": \"Min Scheduled Time\",\n                    \"type\": \"string\"\n                },\n                \"insert_batch_size\": {\n                    \"default\": 500,\n                    \"description\": \"\\n        The number of runs the scheduler will attempt to insert in a single batch.\\n        Defaults to `500`.\\n        \",\n                    \"title\": \"Insert Batch Size\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"ServerServicesSchedulerSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesSettings\": {\n            \"description\": \"Settings for controlling server services\",\n            \"properties\": {\n                \"cancellation_cleanup\": {\n                    \"$ref\": \"#/$defs/ServerServicesCancellationCleanupSettings\"\n                },\n                \"event_persister\": {\n                    \"$ref\": \"#/$defs/ServerServicesEventPersisterSettings\"\n                },\n                \"flow_run_notifications\": {\n                    \"$ref\": \"#/$defs/ServerServicesFlowRunNotificationsSettings\"\n                },\n                \"foreman\": {\n                    \"$ref\": \"#/$defs/ServerServicesForemanSettings\"\n                },\n                \"late_runs\": {\n                    \"$ref\": \"#/$defs/ServerServicesLateRunsSettings\"\n                },\n                \"scheduler\": {\n                    \"$ref\": \"#/$defs/ServerServicesSchedulerSettings\"\n                },\n                \"pause_expirations\": {\n                    \"$ref\": \"#/$defs/ServerServicesPauseExpirationsSettings\"\n                },\n                \"task_run_recorder\": {\n                    \"$ref\": \"#/$defs/ServerServicesTaskRunRecorderSettings\"\n                },\n                \"triggers\": {\n                    \"$ref\": \"#/$defs/ServerServicesTriggersSettings\"\n                }\n            },\n            \"title\": \"ServerServicesSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesTaskRunRecorderSettings\": {\n            \"description\": \"Settings for controlling the task run recorder service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the task run recorder service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                }\n            },\n            \"title\": \"ServerServicesTaskRunRecorderSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerServicesTriggersSettings\": {\n            \"description\": \"Settings for controlling the triggers service\",\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to start the triggers service in the server application.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                }\n            },\n            \"title\": \"ServerServicesTriggersSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerSettings\": {\n            \"description\": \"Settings for controlling server behavior\",\n            \"properties\": {\n                \"logging_level\": {\n                    \"default\": \"WARNING\",\n                    \"description\": \"The default logging level for the Prefect API server.\",\n                    \"enum\": [\n                        \"DEBUG\",\n                        \"INFO\",\n                        \"WARNING\",\n                        \"ERROR\",\n                        \"CRITICAL\"\n                    ],\n                    \"title\": \"Logging Level\",\n                    \"type\": \"string\"\n                },\n                \"analytics_enabled\": {\n                    \"default\": true,\n                    \"description\": \"\\n        When enabled, Prefect sends anonymous data (e.g. count of flow runs, package version)\\n        on server startup to help us improve our product.\\n        \",\n                    \"title\": \"Analytics Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"metrics_enabled\": {\n                    \"default\": false,\n                    \"description\": \"Whether or not to enable Prometheus metrics in the API.\",\n                    \"title\": \"Metrics Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"log_retryable_errors\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, log retryable errors in the API and it's services.\",\n                    \"title\": \"Log Retryable Errors\",\n                    \"type\": \"boolean\"\n                },\n                \"register_blocks_on_start\": {\n                    \"default\": true,\n                    \"description\": \"If set, any block types that have been imported will be registered with the backend on application startup. If not set, block types must be manually registered.\",\n                    \"title\": \"Register Blocks On Start\",\n                    \"type\": \"boolean\"\n                },\n                \"memoize_block_auto_registration\": {\n                    \"default\": true,\n                    \"description\": \"Controls whether or not block auto-registration on start\",\n                    \"title\": \"Memoize Block Auto Registration\",\n                    \"type\": \"boolean\"\n                },\n                \"memo_store_path\": {\n                    \"anyOf\": [\n                        {\n                            \"format\": \"path\",\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The path to the memo store file.\",\n                    \"title\": \"Memo Store Path\"\n                },\n                \"deployment_schedule_max_scheduled_runs\": {\n                    \"default\": 50,\n                    \"description\": \"The maximum number of scheduled runs to create for a deployment.\",\n                    \"title\": \"Deployment Schedule Max Scheduled Runs\",\n                    \"type\": \"integer\"\n                },\n                \"api\": {\n                    \"$ref\": \"#/$defs/ServerAPISettings\"\n                },\n                \"database\": {\n                    \"$ref\": \"#/$defs/ServerDatabaseSettings\"\n                },\n                \"deployments\": {\n                    \"$ref\": \"#/$defs/ServerDeploymentsSettings\",\n                    \"description\": \"Settings for controlling server deployments behavior\"\n                },\n                \"ephemeral\": {\n                    \"$ref\": \"#/$defs/ServerEphemeralSettings\"\n                },\n                \"events\": {\n                    \"$ref\": \"#/$defs/ServerEventsSettings\",\n                    \"description\": \"Settings for controlling server events behavior\"\n                },\n                \"flow_run_graph\": {\n                    \"$ref\": \"#/$defs/ServerFlowRunGraphSettings\",\n                    \"description\": \"Settings for controlling flow run graph behavior\"\n                },\n                \"services\": {\n                    \"$ref\": \"#/$defs/ServerServicesSettings\",\n                    \"description\": \"Settings for controlling server services behavior\"\n                },\n                \"tasks\": {\n                    \"$ref\": \"#/$defs/ServerTasksSettings\",\n                    \"description\": \"Settings for controlling server tasks behavior\"\n                },\n                \"ui\": {\n                    \"$ref\": \"#/$defs/ServerUISettings\",\n                    \"description\": \"Settings for controlling server UI behavior\"\n                }\n            },\n            \"title\": \"ServerSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerTasksSchedulingSettings\": {\n            \"description\": \"Settings for controlling server-side behavior related to task scheduling\",\n            \"properties\": {\n                \"max_scheduled_queue_size\": {\n                    \"default\": 1000,\n                    \"description\": \"The maximum number of scheduled tasks to queue for submission.\",\n                    \"title\": \"Max Scheduled Queue Size\",\n                    \"type\": \"integer\"\n                },\n                \"max_retry_queue_size\": {\n                    \"default\": 100,\n                    \"description\": \"The maximum number of retries to queue for submission.\",\n                    \"title\": \"Max Retry Queue Size\",\n                    \"type\": \"integer\"\n                },\n                \"pending_task_timeout\": {\n                    \"default\": \"PT0S\",\n                    \"description\": \"How long before a PENDING task are made available to another task worker.\",\n                    \"format\": \"duration\",\n                    \"title\": \"Pending Task Timeout\",\n                    \"type\": \"string\"\n                }\n            },\n            \"title\": \"ServerTasksSchedulingSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerTasksSettings\": {\n            \"description\": \"Settings for controlling server-side behavior related to tasks\",\n            \"properties\": {\n                \"tag_concurrency_slot_wait_seconds\": {\n                    \"default\": 30,\n                    \"description\": \"The number of seconds to wait before retrying when a task run cannot secure a concurrency slot from the server.\",\n                    \"minimum\": 0.0,\n                    \"title\": \"Tag Concurrency Slot Wait Seconds\",\n                    \"type\": \"number\"\n                },\n                \"max_cache_key_length\": {\n                    \"default\": 2000,\n                    \"description\": \"The maximum number of characters allowed for a task run cache key.\",\n                    \"title\": \"Max Cache Key Length\",\n                    \"type\": \"integer\"\n                },\n                \"scheduling\": {\n                    \"$ref\": \"#/$defs/ServerTasksSchedulingSettings\"\n                }\n            },\n            \"title\": \"ServerTasksSettings\",\n            \"type\": \"object\"\n        },\n        \"ServerUISettings\": {\n            \"properties\": {\n                \"enabled\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to serve the Prefect UI.\",\n                    \"title\": \"Enabled\",\n                    \"type\": \"boolean\"\n                },\n                \"api_url\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The connection url for communication from the UI to the API. Defaults to `PREFECT_API_URL` if set. Otherwise, the default URL is generated from `PREFECT_SERVER_API_HOST` and `PREFECT_SERVER_API_PORT`.\",\n                    \"title\": \"Api Url\"\n                },\n                \"serve_base\": {\n                    \"default\": \"/\",\n                    \"description\": \"The base URL path to serve the Prefect UI from.\",\n                    \"title\": \"Serve Base\",\n                    \"type\": \"string\"\n                },\n                \"static_directory\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The directory to serve static files from. This should be used when running into permissions issues when attempting to serve the UI from the default directory (for example when running in a Docker container).\",\n                    \"title\": \"Static Directory\"\n                }\n            },\n            \"title\": \"ServerUISettings\",\n            \"type\": \"object\"\n        },\n        \"TasksRunnerSettings\": {\n            \"properties\": {\n                \"thread_pool_max_workers\": {\n                    \"anyOf\": [\n                        {\n                            \"exclusiveMinimum\": 0,\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The maximum number of workers for ThreadPoolTaskRunner.\",\n                    \"title\": \"Thread Pool Max Workers\"\n                }\n            },\n            \"title\": \"TasksRunnerSettings\",\n            \"type\": \"object\"\n        },\n        \"TasksSchedulingSettings\": {\n            \"properties\": {\n                \"default_storage_block\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"string\"\n                        },\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": null,\n                    \"description\": \"The `block-type/block-document` slug of a block to use as the default storage for autonomous tasks.\",\n                    \"title\": \"Default Storage Block\"\n                },\n                \"delete_failed_submissions\": {\n                    \"default\": true,\n                    \"description\": \"Whether or not to delete failed task submissions from the database.\",\n                    \"title\": \"Delete Failed Submissions\",\n                    \"type\": \"boolean\"\n                }\n            },\n            \"title\": \"TasksSchedulingSettings\",\n            \"type\": \"object\"\n        },\n        \"TasksSettings\": {\n            \"properties\": {\n                \"refresh_cache\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, enables a refresh of cached results: re-executing the task will refresh the cached results.\",\n                    \"title\": \"Refresh Cache\",\n                    \"type\": \"boolean\"\n                },\n                \"default_retries\": {\n                    \"default\": 0,\n                    \"description\": \"This value sets the default number of retries for all tasks.\",\n                    \"minimum\": 0,\n                    \"title\": \"Default Retries\",\n                    \"type\": \"integer\"\n                },\n                \"default_retry_delay_seconds\": {\n                    \"anyOf\": [\n                        {\n                            \"type\": \"integer\"\n                        },\n                        {\n                            \"type\": \"number\"\n                        },\n                        {\n                            \"items\": {\n                                \"type\": \"number\"\n                            },\n                            \"type\": \"array\"\n                        }\n                    ],\n                    \"default\": 0,\n                    \"description\": \"This value sets the default retry delay seconds for all tasks.\",\n                    \"title\": \"Default Retry Delay Seconds\"\n                },\n                \"runner\": {\n                    \"$ref\": \"#/$defs/TasksRunnerSettings\",\n                    \"description\": \"Settings for controlling task runner behavior\"\n                },\n                \"scheduling\": {\n                    \"$ref\": \"#/$defs/TasksSchedulingSettings\",\n                    \"description\": \"Settings for controlling client-side task scheduling behavior\"\n                }\n            },\n            \"title\": \"TasksSettings\",\n            \"type\": \"object\"\n        },\n        \"TestingSettings\": {\n            \"properties\": {\n                \"test_mode\": {\n                    \"default\": false,\n                    \"description\": \"If `True`, places the API in test mode. This may modify behavior to facilitate testing.\",\n                    \"title\": \"Test Mode\",\n                    \"type\": \"boolean\"\n                },\n                \"unit_test_mode\": {\n                    \"default\": false,\n                    \"description\": \"This setting only exists to facilitate unit testing. If `True`, code is executing in a unit test context. Defaults to `False`.\",\n                    \"title\": \"Unit Test Mode\",\n                    \"type\": \"boolean\"\n                },\n                \"unit_test_loop_debug\": {\n                    \"default\": true,\n                    \"description\": \"If `True` turns on debug mode for the unit testing event loop.\",\n                    \"title\": \"Unit Test Loop Debug\",\n                    \"type\": \"boolean\"\n                },\n                \"test_setting\": {\n                    \"anyOf\": [\n                        {},\n                        {\n                            \"type\": \"null\"\n                        }\n                    ],\n                    \"default\": \"FOO\",\n                    \"description\": \"This setting only exists to facilitate unit testing. If in test mode, this setting will return its value. Otherwise, it returns `None`.\",\n                    \"title\": \"Test Setting\"\n                }\n            },\n            \"title\": \"TestingSettings\",\n            \"type\": \"object\"\n        },\n        \"WorkerSettings\": {\n            \"properties\": {\n                \"heartbeat_seconds\": {\n                    \"default\": 30,\n                    \"description\": \"Number of seconds a worker should wait between sending a heartbeat.\",\n                    \"title\": \"Heartbeat Seconds\",\n                    \"type\": \"number\"\n                },\n                \"query_seconds\": {\n                    \"default\": 10,\n                    \"description\": \"Number of seconds a worker should wait between queries for scheduled work.\",\n                    \"title\": \"Query Seconds\",\n                    \"type\": \"number\"\n                },\n                \"prefetch_seconds\": {\n                    \"default\": 10,\n                    \"description\": \"The number of seconds into the future a worker should query for scheduled work.\",\n                    \"title\": \"Prefetch Seconds\",\n                    \"type\": \"number\"\n                },\n                \"webserver\": {\n                    \"$ref\": \"#/$defs/WorkerWebserverSettings\",\n                    \"description\": \"Settings for a worker's webserver\"\n                }\n            },\n            \"title\": \"WorkerSettings\",\n            \"type\": \"object\"\n        },\n        \"WorkerWebserverSettings\": {\n            \"properties\": {\n                \"host\": {\n                    \"default\": \"0.0.0.0\",\n                    \"description\": \"The host address the worker's webserver should bind to.\",\n                    \"title\": \"Host\",\n                    \"type\": \"string\"\n                },\n                \"port\": {\n                    \"default\": 8080,\n                    \"description\": \"The port the worker's webserver should bind to.\",\n                    \"title\": \"Port\",\n                    \"type\": \"integer\"\n                }\n            },\n            \"title\": \"WorkerWebserverSettings\",\n            \"type\": \"object\"\n        }\n    },\n    \"description\": \"Settings for Prefect using Pydantic settings.\\n\\nSee https://docs.pydantic.dev/latest/concepts/pydantic_settings\",\n    \"properties\": {\n        \"home\": {\n            \"default\": \"~/.prefect\",\n            \"description\": \"The path to the Prefect home directory. Defaults to ~/.prefect\",\n            \"format\": \"path\",\n            \"title\": \"Home\",\n            \"type\": \"string\"\n        },\n        \"profiles_path\": {\n            \"anyOf\": [\n                {\n                    \"format\": \"path\",\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"default\": null,\n            \"description\": \"The path to a profiles configuration file.\",\n            \"title\": \"Profiles Path\"\n        },\n        \"debug_mode\": {\n            \"default\": false,\n            \"description\": \"If True, enables debug mode which may provide additional logging and debugging features.\",\n            \"title\": \"Debug Mode\",\n            \"type\": \"boolean\"\n        },\n        \"api\": {\n            \"$ref\": \"#/$defs/APISettings\"\n        },\n        \"cli\": {\n            \"$ref\": \"#/$defs/CLISettings\"\n        },\n        \"client\": {\n            \"$ref\": \"#/$defs/ClientSettings\",\n            \"description\": \"Settings for for controlling API client behavior\"\n        },\n        \"cloud\": {\n            \"$ref\": \"#/$defs/CloudSettings\"\n        },\n        \"deployments\": {\n            \"$ref\": \"#/$defs/DeploymentsSettings\"\n        },\n        \"flows\": {\n            \"$ref\": \"#/$defs/FlowsSettings\"\n        },\n        \"internal\": {\n            \"$ref\": \"#/$defs/InternalSettings\",\n            \"description\": \"Settings for internal Prefect machinery\"\n        },\n        \"logging\": {\n            \"$ref\": \"#/$defs/LoggingSettings\"\n        },\n        \"results\": {\n            \"$ref\": \"#/$defs/ResultsSettings\"\n        },\n        \"runner\": {\n            \"$ref\": \"#/$defs/RunnerSettings\"\n        },\n        \"server\": {\n            \"$ref\": \"#/$defs/ServerSettings\"\n        },\n        \"tasks\": {\n            \"$ref\": \"#/$defs/TasksSettings\",\n            \"description\": \"Settings for controlling task behavior\"\n        },\n        \"testing\": {\n            \"$ref\": \"#/$defs/TestingSettings\",\n            \"description\": \"Settings used during testing\"\n        },\n        \"worker\": {\n            \"$ref\": \"#/$defs/WorkerSettings\",\n            \"description\": \"Settings for controlling worker behavior\"\n        },\n        \"ui_url\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"default\": null,\n            \"description\": \"The URL of the Prefect UI. If not set, the client will attempt to infer it.\",\n            \"title\": \"Ui Url\"\n        },\n        \"silence_api_url_misconfiguration\": {\n            \"default\": false,\n            \"description\": \"\\n        If `True`, disable the warning when a user accidentally misconfigure its `PREFECT_API_URL`\\n        Sometimes when a user manually set `PREFECT_API_URL` to a custom url,reverse-proxy for example,\\n        we would like to silence this warning so we will set it to `FALSE`.\\n        \",\n            \"title\": \"Silence Api Url Misconfiguration\",\n            \"type\": \"boolean\"\n        },\n        \"experimental_warn\": {\n            \"default\": true,\n            \"description\": \"If `True`, warn on usage of experimental features.\",\n            \"title\": \"Experimental Warn\",\n            \"type\": \"boolean\"\n        },\n        \"async_fetch_state_result\": {\n            \"default\": false,\n            \"description\": \"\\n        Determines whether `State.result()` fetches results automatically or not.\\n        In Prefect 2.6.0, the `State.result()` method was updated to be async\\n        to facilitate automatic retrieval of results from storage which means when\\n        writing async code you must `await` the call. For backwards compatibility,\\n        the result is not retrieved by default for async users. You may opt into this\\n        per call by passing  `fetch=True` or toggle this setting to change the behavior\\n        globally.\\n        \",\n            \"title\": \"Async Fetch State Result\",\n            \"type\": \"boolean\"\n        },\n        \"experimental_enable_schedule_concurrency\": {\n            \"default\": false,\n            \"description\": \"Whether or not to enable concurrency for scheduled tasks.\",\n            \"title\": \"Experimental Enable Schedule Concurrency\",\n            \"type\": \"boolean\"\n        }\n    },\n    \"title\": \"Settings\",\n    \"type\": \"object\"\n}"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 4.4140625,
          "content": "[tool:pytest]\ntestpaths = tests\naddopts = -rfEs --mypy-only-local-stub\nnorecursedirs = *.egg-info .git .mypy_cache node_modules .pytest_cache .vscode\n\npython_files =\n    test_*.py\n    bench_*.py\n\npython_functions =\n    test_*\n    bench_*\n\nmarkers =\n    service(arg): a service integration test. For example 'docker'\n    enable_api_log_handler: by default, sending logs to the API is disabled. Tests marked with this use the handler.\n    clear_db: marker to clear the database after test completion\n\nenv =\n    # NOTE: Additional Prefect setting values are set dynamically in conftest.py\n    PREFECT_TESTING_TEST_MODE = 1\n    PREFECT_TESTING_UNIT_TEST_MODE = 1\n    PREFECT_SERVER_LOGGING_LEVEL = DEBUG\n\nasyncio_mode = auto\nasyncio_default_fixture_loop_scope = session\ntimeout = 90\n\n# Error on unhandled warnings\nfilterwarnings =\n    error\n\n    # tornado uses deprecated `get_event_loop`\n    ignore::DeprecationWarning:tornado.platform.asyncio.*\n    ignore::DeprecationWarning:tornado.ioloop\n    ignore:Default value default=\n    # Temporary directories are cleaned up implicitly on Windows\n    # It is unclear if this comes from an external tool or our own usage\n    # Here the start of the path is included to only filter warnings on Windows\n    ignore:Implicitly cleaning up:ResourceWarning\n    # Dask leaves files open when using file locks\n    # See https://github.com/dask/distributed/pull/6122\n    ignore::ResourceWarning:distributed.diskutils\n    # Dask may not close sockets on cluster teardown\n    ignore:unclosed:ResourceWarning:distributed.node\n    # Google suggests installing a module for better error messages\n    ignore::ImportWarning:google.api_core.exceptions\n    # SQLAlchemy leaves some cursors unawaited\n    ignore:coroutine 'Connection.cursor' was never awaited:RuntimeWarning\n    ignore:coroutine 'AsyncAdapt_asyncpg_cursor._prepare_and_execute' was never awaited:RuntimeWarning\n    # This warning is raised on Windows by Python internals\n    ignore:the imp module is deprecated:DeprecationWarning\n    # Dockerpy is behind on this one\n    ignore:distutils Version classes are deprecated:DeprecationWarning\n    # distutils is deprecated, but we are using it directly in prefect/filesystems.py\n    ignore:The distutils package is deprecated:DeprecationWarning\n    ignore:Skipped unsupported reflection of expression-based index:sqlalchemy.exc.SAWarning\n    # Required to pass --cov-config to pytest\n    ignore:The --rsyncdir command line argument and rsyncdirs config variable are deprecated.:DeprecationWarning\n    ignore:Prefect will drop support for Python 3.7:FutureWarning\n    ignore:`PREFECT_API_URL` uses `/account/` but should use `/accounts/`.:UserWarning\n    ignore:`PREFECT_API_URL` should have `/api` after the base URL.:UserWarning\n    # datetime.datetime.utcnow() is deprecated as of Python 3.12, waiting on 3rd party fixes in boto3 https://github.com/boto/boto3/issues/3889\n    ignore:datetime\\.datetime\\.utcnow\\(\\) is deprecated and scheduled for removal in a future version\\..*:DeprecationWarning\n    ignore:datetime\\.datetime\\.utcfromtimestamp\\(\\) is deprecated and scheduled for removal in a future version\\..*:DeprecationWarning\n    # We know that under certain constraints, SQLAlchemy connections may leak during\n    # the test suite before they can be cleaned up properly, but this is not a failure\n    # of the tests.\n    ignore::sqlalchemy.exc.SAWarning\n    ignore::ResourceWarning\n    ignore::pytest.PytestUnraisableExceptionWarning\n    ignore::pluggy.PluggyTeardownRaisedWarning\n\n\n[mypy]\nplugins=\n    pydantic.mypy\n\nignore_missing_imports = True\nfollow_imports = skip\n\n[mypy-ruamel]\nignore_missing_imports = True\n\n[versioneer]\nVCS = git\nstyle = pep440\nversionfile_source = src/prefect/_version.py\nversionfile_build = prefect/_version.py\nversion_regex = ^(\\d+\\.\\d+\\.\\d+(?:[a-zA-Z0-9]+(?:\\.[a-zA-Z0-9]+)*)?)$\ntag_prefix =\nparentdir_prefix =\n\n[coverage:run]\nbranch = True\n\n[coverage:report]\nexclude_lines =\n    # Don't complain about abstract methods, they aren't run:\n    @(abc\\.)?abstractmethod\n    # if TYPE_CHECKING: lines are never nun\n    if TYPE_CHECKING:\nomit =\n    src/prefect/server/database/migrations/versions/*\n\nignore_errors = True\n\n[vermin]\nmake_paths_absolute = no\nbackports =\n    typing_extensions\nformat = parsable\neval_annotations = yes\nonly_show_violations = yes\ntargets = 3.9-\nexclusion_regex = ^src/prefect/_vendor/.*$|^src/prefect/utilities/compat\\.py$|^tests/workers/test_process_worker.py$|^tests/test_background_tasks.py$|^src/integrations/.*/tests/.*$\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.1435546875,
          "content": "from pathlib import Path\n\nimport versioneer\nfrom setuptools import find_packages, setup  # type: ignore\n\n\ndef read_requirements(file: str) -> list[str]:\n    requirements: list[str] = []\n    if Path(file).exists():\n        requirements = open(file).read().strip().split(\"\\n\")\n    return requirements\n\n\nclient_requires = read_requirements(\"requirements-client.txt\")\ninstall_requires = read_requirements(\"requirements.txt\")[1:] + client_requires\ndev_requires = read_requirements(\"requirements-dev.txt\")\notel_requires = read_requirements(\"requirements-otel.txt\")\n\nsetup(\n    # Package metadata\n    name=\"prefect\",\n    description=\"Workflow orchestration and management.\",\n    author=\"Prefect Technologies, Inc.\",\n    author_email=\"help@prefect.io\",\n    url=\"https://www.prefect.io\",\n    project_urls={\n        \"Changelog\": \"https://github.com/PrefectHQ/prefect/releases\",\n        \"Documentation\": \"https://docs.prefect.io\",\n        \"Source\": \"https://github.com/PrefectHQ/prefect\",\n        \"Tracker\": \"https://github.com/PrefectHQ/prefect/issues\",\n    },\n    long_description=open(\"README.md\").read(),\n    long_description_content_type=\"text/markdown\",\n    # Versioning\n    version=versioneer.get_version(),\n    cmdclass=versioneer.get_cmdclass(),\n    # Package setup\n    packages=find_packages(where=\"src\"),\n    package_dir={\"\": \"src\"},\n    include_package_data=True,\n    # CLI\n    entry_points={\n        \"console_scripts\": [\"prefect=prefect.cli:app\"],\n        \"mkdocs.plugins\": [\n            \"render_swagger = prefect.utilities.render_swagger:SwaggerPlugin\",\n        ],\n    },\n    # Requirements\n    python_requires=\">=3.9\",\n    install_requires=install_requires,\n    extras_require={\n        \"dev\": dev_requires,\n        \"otel\": otel_requires,\n        # Infrastructure extras\n        \"aws\": \"prefect-aws>=0.5.0\",\n        \"azure\": \"prefect-azure>=0.4.0\",\n        \"gcp\": \"prefect-gcp>=0.6.0\",\n        \"docker\": \"prefect-docker>=0.6.0\",\n        \"kubernetes\": \"prefect-kubernetes>=0.4.0\",\n        \"shell\": \"prefect-shell>=0.3.0\",\n        # Distributed task execution extras\n        \"dask\": \"prefect-dask>=0.3.0\",\n        \"ray\": \"prefect-ray>=0.4.0\",\n        # Version control extras\n        \"bitbucket\": \"prefect-bitbucket>=0.3.0\",\n        \"github\": \"prefect-github>=0.3.0\",\n        \"gitlab\": \"prefect-gitlab>=0.3.0\",\n        # Database extras\n        \"databricks\": \"prefect-databricks>=0.3.0\",\n        \"dbt\": \"prefect-dbt>=0.6.0\",\n        \"snowflake\": \"prefect-snowflake>=0.28.0\",\n        \"sqlalchemy\": \"prefect-sqlalchemy>=0.5.0\",\n        \"redis\": \"prefect-redis>=0.2.0\",\n        # Monitoring extras\n        \"email\": \"prefect-email>=0.4.0\",\n        \"slack\": \"prefect-slack>=0.3.0\",\n    },\n    classifiers=[\n        \"Natural Language :: English\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: System Administrators\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Topic :: Software Development :: Libraries\",\n    ],\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "ui-v2",
          "type": "tree",
          "content": null
        },
        {
          "name": "ui",
          "type": "tree",
          "content": null
        },
        {
          "name": "versioneer.py",
          "type": "blob",
          "size": 84.640625,
          "content": "# Version: 0.29\n\n\"\"\"The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/python-versioneer/python-versioneer\n* Brian Warner\n* License: Public Domain (Unlicense)\n* Compatible with: Python 3.7, 3.8, 3.9, 3.10, 3.11 and pypy3\n* [![Latest Version][pypi-image]][pypi-url]\n* [![Build Status][travis-image]][travis-url]\n\nThis is a tool for managing a recorded version number in setuptools-based\npython projects. The goal is to remove the tedious and error-prone \"update\nthe embedded version string\" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\nVersioneer provides two installation modes. The \"classic\" vendored mode installs\na copy of versioneer into your repository. The experimental build-time dependency mode\nis intended to allow you to skip this step and simplify the process of upgrading.\n\n### Vendored mode\n\n* `pip install versioneer` to somewhere in your $PATH\n   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is\n     available, so you can also use `conda install -c conda-forge versioneer`\n* add a `[tool.versioneer]` section to your `pyproject.toml` or a\n  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n   * Note that you will need to add `tomli; python_version < \"3.11\"` to your\n     build-time dependencies if you use `pyproject.toml`\n* run `versioneer install --vendor` in your source tree, commit the results\n* verify version information with `python setup.py version`\n\n### Build-time dependency mode\n\n* `pip install versioneer` to somewhere in your $PATH\n   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is\n     available, so you can also use `conda install -c conda-forge versioneer`\n* add a `[tool.versioneer]` section to your `pyproject.toml` or a\n  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n* add `versioneer` (with `[toml]` extra, if configuring in `pyproject.toml`)\n  to the `requires` key of the `build-system` table in `pyproject.toml`:\n  ```toml\n  [build-system]\n  requires = [\"setuptools\", \"versioneer[toml]\"]\n  build-backend = \"setuptools.build_meta\"\n  ```\n* run `versioneer install --no-vendor` in your source tree, commit the results\n* verify version information with `python setup.py version`\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github's\n  \"tarball from tag\" feature\n* a release tarball, produced by \"setup.py sdist\", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. \"git describe\" (for checkouts), which knows\n  about recent \"tags\" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. \"myproject-1.2\" instead of just \"1.2\"), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n\"0.7-1-g574ab98-dirty\" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of \"574ab98\", and is \"dirty\" (it has\nuncommitted changes).\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a 'setup.py sdist' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the \"outside\" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `['version']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project's version\n  string. The default \"pep440\" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the \"Styles\" section\n  below for alternative styles.\n\n* `['full-revisionid']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. \"1076c978a8d3cfc70f408fe5974aa6c092c949ac\".\n\n* `['date']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `['dirty']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `['error']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of \"unknown\".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an \"about\" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()['version']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, \"pep440\", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional \"local\nversion\" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example \"0.11+2.g1076c97.dirty\" indicates that the\ntree is like the \"1076c97\" commit but has uncommitted changes (\".dirty\"), and\nthat this commit is two revisions (\"+2\") beyond the \"0.11\" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. \"0.11\".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of \"0+unknown\". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/python-versioneer/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  \"master\" and \"slave\" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other languages) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/python-versioneer/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/python-versioneer/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n\"Entry-point scripts\" (`setup(entry_points={\"console_scripts\": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/python-versioneer/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg` and `pyproject.toml`, if necessary,\n  to include any new configuration settings indicated by the release notes.\n  See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install --[no-]vendor` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n## Similar projects\n\n* [setuptools_scm](https://github.com/pypa/setuptools_scm/) - a non-vendored build-time\n  dependency\n* [minver](https://github.com/jbweston/miniver) - a lightweight reimplementation of\n  versioneer\n* [versioningit](https://github.com/jwodder/versioningit) - a PEP 518-based setuptools\n  plugin\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the \"Unlicense\", as described in\nhttps://unlicense.org/.\n\n[pypi-image]: https://img.shields.io/pypi/v/versioneer.svg\n[pypi-url]: https://pypi.python.org/pypi/versioneer/\n[travis-image]:\nhttps://img.shields.io/travis/com/python-versioneer/python-versioneer.svg\n[travis-url]: https://travis-ci.com/github/python-versioneer/python-versioneer\n\n\"\"\"\n# pylint:disable=invalid-name,import-outside-toplevel,missing-function-docstring\n# pylint:disable=missing-class-docstring,too-many-branches,too-many-statements\n# pylint:disable=raise-missing-from,too-many-lines,too-many-locals,import-error\n# pylint:disable=too-few-public-methods,redefined-outer-name,consider-using-with\n# pylint:disable=attribute-defined-outside-init,too-many-arguments\n\nimport configparser\nimport errno\nimport functools\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Callable, Dict, List, NoReturn, Optional, Tuple, Union, cast\n\nhave_tomllib = True\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    try:\n        import tomli as tomllib\n    except ImportError:\n        have_tomllib = False\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n    VCS: str\n    style: str\n    tag_prefix: str\n    versionfile_source: str\n    versionfile_build: Optional[str]\n    parentdir_prefix: Optional[str]\n    verbose: Optional[bool]\n\n\ndef get_root() -> str:\n    \"\"\"Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    \"\"\"\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    pyproject_toml = os.path.join(root, \"pyproject.toml\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (\n        os.path.exists(setup_py)\n        or os.path.exists(pyproject_toml)\n        or os.path.exists(versioneer_py)\n    ):\n        # allow 'python path/to/setup.py COMMAND'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, \"setup.py\")\n        pyproject_toml = os.path.join(root, \"pyproject.toml\")\n        versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (\n        os.path.exists(setup_py)\n        or os.path.exists(pyproject_toml)\n        or os.path.exists(versioneer_py)\n    ):\n        err = (\n            \"Versioneer was unable to run the project root directory. \"\n            \"Versioneer requires setup.py to be executed from \"\n            \"its immediate directory (like 'python setup.py COMMAND'), \"\n            \"or in a way that lets it use sys.argv[0] to find the root \"\n            \"(like 'python path/to/setup.py COMMAND').\"\n        )\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # \"versioneer\" may be imported multiple times, and python's shared\n        # module-import table will cache the first one. So we can't use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        my_path = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(my_path)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir and \"VERSIONEER_PEP518\" not in globals():\n            print(\n                \"Warning: build in %s is using versioneer.py from %s\"\n                % (os.path.dirname(my_path), versioneer_py)\n            )\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root: str) -> VersioneerConfig:\n    \"\"\"Read the project setup.cfg file to determine Versioneer config.\"\"\"\n    # This might raise OSError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks \"VCS=\"). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    root_pth = Path(root)\n    pyproject_toml = root_pth / \"pyproject.toml\"\n    setup_cfg = root_pth / \"setup.cfg\"\n    section: Union[Dict[str, Any], configparser.SectionProxy, None] = None\n    if pyproject_toml.exists() and have_tomllib:\n        try:\n            with open(pyproject_toml, \"rb\") as fobj:\n                pp = tomllib.load(fobj)\n            section = pp[\"tool\"][\"versioneer\"]\n        except (tomllib.TOMLDecodeError, KeyError) as e:\n            print(f\"Failed to load config from {pyproject_toml}: {e}\")\n            print(\"Try to load it from setup.cfg\")\n    if not section:\n        parser = configparser.ConfigParser()\n        with open(setup_cfg) as cfg_file:\n            parser.read_file(cfg_file)\n        parser.get(\"versioneer\", \"VCS\")  # raise error if missing\n\n        section = parser[\"versioneer\"]\n\n    # `cast`` really shouldn't be used, but its simplest for the\n    # common VersioneerConfig users at the moment. We verify against\n    # `None` values elsewhere where it matters\n\n    cfg = VersioneerConfig()\n    cfg.VCS = section[\"VCS\"]\n    cfg.style = section.get(\"style\", \"\")\n    cfg.versionfile_source = cast(str, section.get(\"versionfile_source\"))\n    cfg.versionfile_build = section.get(\"versionfile_build\")\n    cfg.tag_prefix = cast(str, section.get(\"tag_prefix\"))\n    if cfg.tag_prefix in (\"''\", '\"\"', None):\n        cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = section.get(\"parentdir_prefix\")\n    if isinstance(section, configparser.SectionProxy):\n        # Make sure configparser translates to bool\n        cfg.verbose = section.getboolean(\"verbose\")\n    else:\n        cfg.verbose = section.get(\"verbose\")\n\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY: Dict[str, str] = {}\nHANDLERS: Dict[str, Dict[str, Callable]] = {}\n\n\ndef register_vcs_handler(vcs: str, method: str) -> Callable:  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n\n    def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(\n    commands: List[str],\n    args: List[str],\n    cwd: Optional[str] = None,\n    verbose: bool = False,\n    hide_stderr: bool = False,\n    env: Optional[Dict[str, str]] = None,\n) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n\n    popen_kwargs: Dict[str, Any] = {}\n    if sys.platform == \"win32\":\n        # This hides the console window if pythonw.exe is used\n        startupinfo = subprocess.STARTUPINFO()\n        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        popen_kwargs[\"startupinfo\"] = startupinfo\n\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen(\n                [command] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n                **popen_kwargs,\n            )\n            break\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, process.returncode\n    return stdout, process.returncode\n\n\nLONG_VERSION_PY[\"git\"] = r'''\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain.\n# Generated by versioneer-0.29\n# https://github.com/python-versioneer/python-versioneer\n\n\"\"\"Git implementation of _version.py.\"\"\"\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\nimport functools\n\n\ndef get_keywords() -> Dict[str, str]:\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"%(DOLLAR)sFormat:%%d%(DOLLAR)s\"\n    git_full = \"%(DOLLAR)sFormat:%%H%(DOLLAR)s\"\n    git_date = \"%(DOLLAR)sFormat:%%ci%(DOLLAR)s\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n    VCS: str\n    style: str\n    tag_prefix: str\n    parentdir_prefix: str\n    versionfile_source: str\n    verbose: bool\n\n\ndef get_config() -> VersioneerConfig:\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"%(STYLE)s\"\n    cfg.tag_prefix = \"%(TAG_PREFIX)s\"\n    cfg.parentdir_prefix = \"%(PARENTDIR_PREFIX)s\"\n    cfg.versionfile_source = \"%(VERSIONFILE_SOURCE)s\"\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n\n\nLONG_VERSION_PY: Dict[str, str] = {}\nHANDLERS: Dict[str, Dict[str, Callable]] = {}\n\n\ndef register_vcs_handler(vcs: str, method: str) -> Callable:  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(\n    commands: List[str],\n    args: List[str],\n    cwd: Optional[str] = None,\n    verbose: bool = False,\n    hide_stderr: bool = False,\n    env: Optional[Dict[str, str]] = None,\n) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n\n    popen_kwargs: Dict[str, Any] = {}\n    if sys.platform == \"win32\":\n        # This hides the console window if pythonw.exe is used\n        startupinfo = subprocess.STARTUPINFO()\n        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        popen_kwargs[\"startupinfo\"] = startupinfo\n\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n                                       stdout=subprocess.PIPE,\n                                       stderr=(subprocess.PIPE if hide_stderr\n                                               else None), **popen_kwargs)\n            break\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %%s\" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %%s\" %% (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %%s (error)\" %% dispcmd)\n            print(\"stdout was %%s\" %% stdout)\n        return None, process.returncode\n    return stdout, process.returncode\n\n\ndef versions_from_parentdir(\n    parentdir_prefix: str,\n    root: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\"version\": dirname[len(parentdir_prefix):],\n                    \"full-revisionid\": None,\n                    \"dirty\": False, \"error\": None, \"date\": None}\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\"Tried directories %%s but none started with prefix %%s\" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs: str) -> Dict[str, str]:\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords: Dict[str, str] = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(\n    keywords: Dict[str, str],\n    tag_prefix: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r'\\d', r)}\n        if verbose:\n            print(\"discarding '%%s', no digits\" %% \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %%s\" %% \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r'\\d', r):\n                continue\n            if verbose:\n                print(\"picking %%s\" %% r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None,\n                    \"date\": date}\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\", \"date\": None}\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(\n    tag_prefix: str,\n    root: str,\n    verbose: bool,\n    runner: Callable = run_command\n) -> Dict[str, Any]:\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    # GIT_DIR can interfere with correct operation of Versioneer.\n    # It may be intended to be passed to the Versioneer-versioned project,\n    # but that should not change where we get our version from.\n    env = os.environ.copy()\n    env.pop(\"GIT_DIR\", None)\n    runner = functools.partial(runner, env=env)\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n                   hide_stderr=not verbose)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %%s not under git control\" %% root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(GITS, [\n        \"describe\", \"--tags\", \"--dirty\", \"--always\", \"--long\",\n        \"--match\", f\"{tag_prefix}[[:digit:]]*\"\n    ], cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces: Dict[str, Any] = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"],\n                             cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%%s'\"\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%%s' doesn't start with prefix '%%s'\"\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[\"error\"] = (\"tag '%%s' doesn't start with prefix '%%s'\"\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--left-right\"], cwd=root)\n        pieces[\"distance\"] = len(out.split())  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces: Dict[str, Any]) -> str:\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces: Dict[str, Any]) -> str:\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%%d.g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = \"0+untagged.%%d.g%%s\" %% (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%%d.g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%%d.g%%s\" %% (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef pep440_split_post(ver: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n\n\ndef render_pep440_pre(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%%d.dev%%d\" %% (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%%d\" %% (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%%d\" %% pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%%s\" %% pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%%s\" %% pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_post_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%%s\" %% pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%%s\" %% pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_old(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces: Dict[str, Any], style: str) -> Dict[str, Any]:\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%%s'\" %% style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None,\n            \"date\": pieces.get(\"date\")}\n\n\ndef get_versions() -> Dict[str, Any]:\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for _ in cfg.versionfile_source.split('/'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find root of source tree\",\n                \"date\": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to compute version\", \"date\": None}\n'''\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs: str) -> Dict[str, str]:\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords: Dict[str, str] = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(\n    keywords: Dict[str, str],\n    tag_prefix: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r\"\\d\", r)}\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r\"\\d\", r):\n                continue\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\n                \"version\": r,\n                \"full-revisionid\": keywords[\"full\"].strip(),\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": date,\n            }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": keywords[\"full\"].strip(),\n        \"dirty\": False,\n        \"error\": \"no suitable tags\",\n        \"date\": None,\n    }\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(\n    tag_prefix: str, root: str, verbose: bool, runner: Callable = run_command\n) -> Dict[str, Any]:\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    # GIT_DIR can interfere with correct operation of Versioneer.\n    # It may be intended to be passed to the Versioneer-versioned project,\n    # but that should not change where we get our version from.\n    env = os.environ.copy()\n    env.pop(\"GIT_DIR\", None)\n    runner = functools.partial(runner, env=env)\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root, hide_stderr=not verbose)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(\n        GITS,\n        [\n            \"describe\",\n            \"--tags\",\n            \"--dirty\",\n            \"--always\",\n            \"--long\",\n            \"--match\",\n            f\"{tag_prefix}[[:digit:]]*\",\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces: Dict[str, Any] = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\"^(.+)-(\\d+)-g([0-9a-f]+)$\", git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = \"unable to parse git-describe output: '%s'\" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = \"tag '%s' doesn't start with prefix '%s'\" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--left-right\"], cwd=root)\n        pieces[\"distance\"] = len(out.split())  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces\n\n\ndef do_vcs_install(versionfile_source: str, ipy: Optional[str]) -> None:\n    \"\"\"Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    files = [versionfile_source]\n    if ipy:\n        files.append(ipy)\n    if \"VERSIONEER_PEP518\" not in globals():\n        try:\n            my_path = __file__\n            if my_path.endswith((\".pyc\", \".pyo\")):\n                my_path = os.path.splitext(my_path)[0] + \".py\"\n            versioneer_file = os.path.relpath(my_path)\n        except NameError:\n            versioneer_file = \"versioneer.py\"\n        files.append(versioneer_file)\n    present = False\n    try:\n        with open(\".gitattributes\", \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(versionfile_source):\n                    if \"export-subst\" in line.strip().split()[1:]:\n                        present = True\n                        break\n    except OSError:\n        pass\n    if not present:\n        with open(\".gitattributes\", \"a+\") as fobj:\n            fobj.write(f\"{versionfile_source} export-subst\\n\")\n        files.append(\".gitattributes\")\n    run_command(GITS, [\"add\", \"--\"] + files)\n\n\ndef versions_from_parentdir(\n    parentdir_prefix: str,\n    root: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                \"version\": dirname[len(parentdir_prefix) :],\n                \"full-revisionid\": None,\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": None,\n            }\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            \"Tried directories %s but none started with prefix %s\"\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n\n\nSHORT_VERSION_PY = \"\"\"\n# This file was generated by 'versioneer.py' (0.29) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = '''\n%s\n'''  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n\"\"\"\n\n\ndef versions_from_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except OSError:\n        raise NotThisMethod(\"unable to read _version.py\")\n    mo = re.search(\n        r\"version_json = '''\\n(.*)'''  # END VERSION_JSON\", contents, re.M | re.S\n    )\n    if not mo:\n        mo = re.search(\n            r\"version_json = '''\\r\\n(.*)'''  # END VERSION_JSON\", contents, re.M | re.S\n        )\n    if not mo:\n        raise NotThisMethod(\"no version_json in _version.py\")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename: str, versions: Dict[str, Any]) -> None:\n    \"\"\"Write the given version number to the given _version.py file.\"\"\"\n    contents = json.dumps(versions, sort_keys=True, indent=1, separators=(\",\", \": \"))\n    with open(filename, \"w\") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(\"set %s to '%s'\" % (filename, versions[\"version\"]))\n\n\ndef plus_or_dot(pieces: Dict[str, Any]) -> str:\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces: Dict[str, Any]) -> str:\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef pep440_split_post(ver: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n\n\ndef render_pep440_pre(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%d.dev%d\" % (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%d\" % (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_post_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_old(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces: Dict[str, Any], style: str) -> Dict[str, Any]:\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\n            \"version\": \"unknown\",\n            \"full-revisionid\": pieces.get(\"long\"),\n            \"dirty\": None,\n            \"error\": pieces[\"error\"],\n            \"date\": None,\n        }\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\n        \"version\": rendered,\n        \"full-revisionid\": pieces[\"long\"],\n        \"dirty\": pieces[\"dirty\"],\n        \"error\": None,\n        \"date\": pieces.get(\"date\"),\n    }\n\n\nclass VersioneerBadRootError(Exception):\n    \"\"\"The project root directory is unknown or missing key files.\"\"\"\n\n\ndef get_versions(verbose: bool = False) -> Dict[str, Any]:\n    \"\"\"Get the project version from whatever source is available.\n\n    Returns dict with two keys: 'version' and 'full'.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, \"please set [versioneer]VCS= in setup.cfg\"\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, \"unrecognized VCS '%s'\" % cfg.VCS\n    verbose = verbose or bool(cfg.verbose)  # `bool()` used to avoid `None`\n    assert (\n        cfg.versionfile_source is not None\n    ), \"please set versioneer.versionfile_source\"\n    assert cfg.tag_prefix is not None, \"please set versioneer.tag_prefix\"\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. 'git\n    # describe'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by 'setup.py sdist',\n    # and for users of a tarball/zipball created by 'git archive' or github's\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(\"get_keywords\")\n    from_keywords_f = handlers.get(\"keywords\")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(\"got version from expanded keyword %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(\"got version from file %s %s\" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(\"pieces_from_vcs\")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(\"got version from VCS %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(\"got version from parentdir %s\" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(\"unable to compute version\")\n\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": None,\n        \"dirty\": None,\n        \"error\": \"unable to compute version\",\n        \"date\": None,\n    }\n\n\ndef get_version() -> str:\n    \"\"\"Get the short version string for this project.\"\"\"\n    return get_versions()[\"version\"]\n\n\ndef get_cmdclass(cmdclass: Optional[Dict[str, Any]] = None):\n    \"\"\"Get the custom setuptools subclasses used by Versioneer.\n\n    If the package uses a different cmdclass (e.g. one from numpy), it\n    should be provide as an argument.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in\n        # sys.modules by the time B's setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it's pre-build state, so the\n        # parent is protected against the child's \"import versioneer\". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent's versioneer too.\n        # Also see https://github.com/python-versioneer/python-versioneer/issues/52\n\n    cmds = {} if cmdclass is None else cmdclass.copy()\n\n    # we add \"version\" to setuptools\n    from setuptools import Command\n\n    class cmd_version(Command):\n        description = \"report generated version string\"\n        user_options: List[Tuple[str, str, str]] = []\n        boolean_options: List[str] = []\n\n        def initialize_options(self) -> None:\n            pass\n\n        def finalize_options(self) -> None:\n            pass\n\n        def run(self) -> None:\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            print(\" date: %s\" % vers.get(\"date\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])\n\n    cmds[\"version\"] = cmd_version\n\n    # we override \"build_py\" in setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn't copied too, 'git describe' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # pip install -e . and setuptool/editable_wheel will invoke build_py\n    # but the build_py command is not expected to copy any files.\n\n    # we override different \"build_py\" commands for both environments\n    if \"build_py\" in cmds:\n        _build_py: Any = cmds[\"build_py\"]\n    else:\n        from setuptools.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            if getattr(self, \"editable_mode\", False):\n                # During editable installs `.py` and data files are\n                # not copied to build_lib\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n    cmds[\"build_py\"] = cmd_build_py\n\n    if \"build_ext\" in cmds:\n        _build_ext: Any = cmds[\"build_ext\"]\n    else:\n        from setuptools.command.build_ext import build_ext as _build_ext\n\n    class cmd_build_ext(_build_ext):\n        def run(self) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_ext.run(self)\n            if self.inplace:\n                # build_ext --inplace will only build extensions in\n                # build/lib<..> dir with no _version.py to write to.\n                # As in place builds will already have a _version.py\n                # in the module dir, we do not need to write one.\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if not cfg.versionfile_build:\n                return\n            target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)\n            if not os.path.exists(target_versionfile):\n                print(\n                    f\"Warning: {target_versionfile} does not exist, skipping \"\n                    \"version update. This can happen if you are running build_ext \"\n                    \"without first running build_py.\"\n                )\n                return\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile, versions)\n\n    cmds[\"build_ext\"] = cmd_build_ext\n\n    if \"cx_Freeze\" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe  # type: ignore\n        # nczeczulin reports that py2exe won't like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   \"version\": versioneer.get_version().split(\"+\", 1)[0], # FILEVERSION\n        #   \"product_version\": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self) -> None:\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            \"DOLLAR\": \"$\",\n                            \"STYLE\": cfg.style,\n                            \"TAG_PREFIX\": cfg.tag_prefix,\n                            \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                            \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[\"build_exe\"] = cmd_build_exe\n        del cmds[\"build_py\"]\n\n    if \"py2exe\" in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.setuptools_buildexe import py2exe as _py2exe  # type: ignore\n        except ImportError:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # type: ignore\n\n        class cmd_py2exe(_py2exe):\n            def run(self) -> None:\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            \"DOLLAR\": \"$\",\n                            \"STYLE\": cfg.style,\n                            \"TAG_PREFIX\": cfg.tag_prefix,\n                            \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                            \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[\"py2exe\"] = cmd_py2exe\n\n    # sdist farms its file list building out to egg_info\n    if \"egg_info\" in cmds:\n        _egg_info: Any = cmds[\"egg_info\"]\n    else:\n        from setuptools.command.egg_info import egg_info as _egg_info\n\n    class cmd_egg_info(_egg_info):\n        def find_sources(self) -> None:\n            # egg_info.find_sources builds the manifest list and writes it\n            # in one shot\n            super().find_sources()\n\n            # Modify the filelist and normalize it\n            root = get_root()\n            cfg = get_config_from_root(root)\n            self.filelist.append(\"versioneer.py\")\n            if cfg.versionfile_source:\n                # There are rare cases where versionfile_source might not be\n                # included by default, so we must be explicit\n                self.filelist.append(cfg.versionfile_source)\n            self.filelist.sort()\n            self.filelist.remove_duplicates()\n\n            # The write method is hidden in the manifest_maker instance that\n            # generated the filelist and was thrown away\n            # We will instead replicate their final normalization (to unicode,\n            # and POSIX-style paths)\n            from setuptools import unicode_utils\n\n            normalized = [\n                unicode_utils.filesys_decode(f).replace(os.sep, \"/\")\n                for f in self.filelist.files\n            ]\n\n            manifest_filename = os.path.join(self.egg_info, \"SOURCES.txt\")\n            with open(manifest_filename, \"w\") as fobj:\n                fobj.write(\"\\n\".join(normalized))\n\n    cmds[\"egg_info\"] = cmd_egg_info\n\n    # we override different \"sdist\" commands for both environments\n    if \"sdist\" in cmds:\n        _sdist: Any = cmds[\"sdist\"]\n    else:\n        from setuptools.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self) -> None:\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir: str, files: List[str]) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(\n                target_versionfile, self._versioneer_generated_versions\n            )\n\n    cmds[\"sdist\"] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = \"\"\"\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or 'python versioneer.py setup'.\n\"\"\"\n\nSAMPLE_CONFIG = \"\"\"\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n\"\"\"\n\nOLD_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\n\nINIT_PY_SNIPPET = \"\"\"\nfrom . import {0}\n__version__ = {0}.get_versions()['version']\n\"\"\"\n\n\ndef do_setup() -> int:\n    \"\"\"Do main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (OSError, configparser.NoSectionError, configparser.NoOptionError) as e:\n        if isinstance(e, (OSError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\", file=sys.stderr)\n            with open(os.path.join(root, \"setup.cfg\"), \"a\") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print(\" creating %s\" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, \"w\") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(\n            LONG\n            % {\n                \"DOLLAR\": \"$\",\n                \"STYLE\": cfg.style,\n                \"TAG_PREFIX\": cfg.tag_prefix,\n                \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n            }\n        )\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source), \"__init__.py\")\n    maybe_ipy: Optional[str] = ipy\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, \"r\") as f:\n                old = f.read()\n        except OSError:\n            old = \"\"\n        module = os.path.splitext(os.path.basename(cfg.versionfile_source))[0]\n        snippet = INIT_PY_SNIPPET.format(module)\n        if OLD_SNIPPET in old:\n            print(\" replacing boilerplate in %s\" % ipy)\n            with open(ipy, \"w\") as f:\n                f.write(old.replace(OLD_SNIPPET, snippet))\n        elif snippet not in old:\n            print(\" appending to %s\" % ipy)\n            with open(ipy, \"a\") as f:\n                f.write(snippet)\n        else:\n            print(\" %s unmodified\" % ipy)\n    else:\n        print(\" %s doesn't exist, ok\" % ipy)\n        maybe_ipy = None\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(cfg.versionfile_source, maybe_ipy)\n    return 0\n\n\ndef scan_setup_py() -> int:\n    \"\"\"Validate the contents of setup.py against Versioneer's expectations.\"\"\"\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass()\" in line:\n                found.add(\"cmdclass\")\n            if \"versioneer.get_version()\" in line:\n                found.add(\"get_version\")\n            if \"versioneer.VCS\" in line:\n                setters = True\n            if \"versioneer.versionfile_source\" in line:\n                setters = True\n    if len(found) != 3:\n        print(\"\")\n        print(\"Your setup.py appears to be missing some important items\")\n        print(\"(but I might be wrong). Please make sure it has something\")\n        print(\"roughly like the following:\")\n        print(\"\")\n        print(\" import versioneer\")\n        print(\" setup( version=versioneer.get_version(),\")\n        print(\"        cmdclass=versioneer.get_cmdclass(),  ...)\")\n        print(\"\")\n        errors += 1\n    if setters:\n        print(\"You should remove lines like 'versioneer.VCS = ' and\")\n        print(\"'versioneer.versionfile_source = ' . This configuration\")\n        print(\"now lives in setup.cfg, and should be removed from setup.py\")\n        print(\"\")\n        errors += 1\n    return errors\n\n\ndef setup_command() -> NoReturn:\n    \"\"\"Set up Versioneer and exit with appropriate error code.\"\"\"\n    errors = do_setup()\n    errors += scan_setup_py()\n    sys.exit(1 if errors else 0)\n\n\nif __name__ == \"__main__\":\n    cmd = sys.argv[1]\n    if cmd == \"setup\":\n        setup_command()\n"
        }
      ]
    }
  ]
}