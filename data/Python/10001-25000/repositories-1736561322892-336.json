{
  "metadata": {
    "timestamp": 1736561322892,
    "page": 336,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PaddlePaddle/PaddleSpeech",
      "stars": 11363,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.8388671875,
          "content": "# This file is used by clang-format to autoformat paddle source code\n#\n# The clang-format is part of llvm toolchain.\n# It need to install llvm and clang to format source code style.\n#\n# The basic usage is,\n#   clang-format -i -style=file PATH/TO/SOURCE/CODE\n#\n# The -style=file implicit use \".clang-format\" file located in one of\n# parent directory.\n# The -i means inplace change.\n#\n# The document of clang-format is\n#   http://clang.llvm.org/docs/ClangFormat.html\n#   http://clang.llvm.org/docs/ClangFormatStyleOptions.html\n---\nLanguage:        Cpp\nBasedOnStyle:  Google\nIndentWidth:     4\nTabWidth:        4\nContinuationIndentWidth: 4\nMaxEmptyLinesToKeep: 2\nAccessModifierOffset: -2  # The private/protected/public has no indent in class\nStandard:  Cpp11\nAllowAllParametersOfDeclarationOnNextLine: true\nBinPackParameters: false\nBinPackArguments: false\n...\n\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 1.3740234375,
          "content": "[flake8]\n\n########## OPTIONS ##########\n# Set the maximum length that any line (with some exceptions) may be.\nmax-line-length = 120\n\n\n################### FILE PATTERNS ##########################\n# Provide a comma-separated list of glob patterns to exclude from checks.\nexclude =\n    # git folder\n    .git,\n    # python cache\n    __pycache__,\n    # third party\n    utils/compute-wer.py,\n    third_party/,\n# Provide a comma-separate list of glob patterns to include for checks.\nfilename =\n    *.py\n\n\n########## RULES ##########\n\n# ERROR CODES\n#\n# E/W  - PEP8 errors/warnings (pycodestyle)\n# F    - linting errors (pyflakes)\n# C    - McCabe complexity error (mccabe)\n#\n# W503 - line break before binary operator\n\n# Specify a list of codes to ignore.\nignore =\n    W503\n    E252,E262,E127,E265,E126,E266,E241,E261,E128,E125,E129\n    W291,W293,W605\n    E203,E305,E402,E501,E721,E741,F403,F405,F821,F841,F999,W503,W504,C408,E302,W291,E303,\n    # shebang has extra meaning in fbcode lints, so I think it's not worth trying\n    # to line this up with executable bit\n    EXE001,\n    # these ignores are from flake8-bugbear; please fix!\n    B007,B008,\n    # these ignores are from flake8-comprehensions; please fix!\n    C400,C401,C402,C403,C404,C405,C407,C411,C413,C414,C415\n\n\nper-file-ignores =\n    */__init__.py: F401\n\n# Specify the list of error codes you wish Flake8 to report.\nselect =\n    E,\n    W,\n    F,\n    C\n"
        },
        {
          "name": ".gitconfig",
          "type": "blob",
          "size": 0.62109375,
          "content": "[alias]\n  st = status\n  ci = commit\n  br = branch\n  co = checkout\n  df = diff\n  l = log --pretty=format:\\\"%h %ad | %s%d [%an]\\\" --graph --date=short\n  ll = log --stat\n\n[merge]\n  tool = vimdiff\n\n[core]\n  excludesfile = ~/.gitignore\n  editor = vim\n\n[color]\n  branch = auto\n  diff = auto\n  status = auto\n\n[color \"branch\"]\n  current = yellow reverse\n  local = yellow\n  remote = green\n\n[color \"diff\"]\n  meta = yellow bold\n  frag = magenta bold\n  old = red bold\n  new = green bold\n\n[color \"status\"]\n  added = yellow\n  changed = green\n  untracked = cyan\n\n[push]\n  default = matching\n\n[credential]\n  helper = store\n\n[user]\n  name =\n  email =\n\n\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7373046875,
          "content": ".DS_Store\n*.pyc\n.vscode\n*.log\n*.wav\n*.pdmodel\n*.pdiparams*\n*.zip\n*.tar\n*.tar.gz\n.ipynb_checkpoints\n*.npz\n*.done\n*.whl\n*.egg-info\nbuild\n*output/\n.history\n\naudio/dist/\naudio/fc_patch/\n\ndocs/build/\ndocs/topic/ctc/warp-ctc/\n\ntools/venv\ntools/kenlm\ntools/sox-14.4.2\ntools/soxbindings\ntools/montreal-forced-aligner/\ntools/Montreal-Forced-Aligner/\ntools/sctk\ntools/sctk-20159b5/\ntools/kaldi\ntools/OpenBLAS/\ntools/Miniconda3-latest-Linux-x86_64.sh\ntools/activate_python.sh\ntools/miniconda.sh\ntools/CRF++-0.58/\ntools/liblbfgs-1.10/\ntools/srilm/\ntools/env.sh\ntools/openfst-1.8.1/\ntools/libsndfile/\ntools/python-soundfile/\ntools/onnx\ntools/onnxruntime\ntools/Paddle2ONNX\ntools/onnx-simplifier/\n\nspeechx/fc_patch/\n\nthird_party/ctc_decoders/paddlespeech_ctcdecoders.py\n"
        },
        {
          "name": ".mergify.yml",
          "type": "blob",
          "size": 3.171875,
          "content": "pull_request_rules:\n  - name: automatic merge for develop when CI passes and 1 reviews\n    conditions:\n      - \"approved-reviews-by>=1\"\n      - check-success=Travis CI - Pull Request\n      - base=develop\n    actions:\n      merge:\n        method: merge\n  - name: delete head branch after merged\n    conditions:\n      - merged\n    actions:\n      delete_head_branch: {}\n  - name: \"add label=auto-merge for PR by mergify\"\n    conditions:\n      - author=mergify[bot]\n    actions:\n      label:\n        add: [\"auto-merge\"]\n  - name: warn on conflicts\n    conditions:\n      - conflict\n    actions:\n      comment:\n        message: This pull request is now in conflict :(\n      label:\n        add: [\"conflicts\"]\n  - name: unlabel conflicts\n    conditions:\n      - -conflict\n    actions:\n      label:\n        remove: [\"conflicts\"]\n  - name: \"auto add label=Dataset\"\n    conditions:\n      - files~=^dataset/\n    actions:\n      label:\n        add: [\"Dataset\"]\n  - name: \"auto add label=S2T\"\n    conditions:\n      - files~=^paddlespeech/s2t/\n    actions:\n      label:\n        add: [\"S2T\"]\n  - name: \"auto add label=T2S\"\n    conditions:\n      - files~=^paddlespeech/t2s/\n    actions:\n      label:\n        add: [\"T2S\"]\n  - name: \"auto add label=Audio\"\n    conditions:\n      - files~=^paddlespeech/audio/\n    actions:\n      label:\n        add: [\"Audio\"]\n  - name: \"auto add label=Vector\"\n    conditions:\n      - files~=^paddlespeech/vector/\n    actions:\n      label:\n        add: [\"Vector\"]\n  - name: \"auto add label=Text\"\n    conditions:\n      - files~=^paddlespeech/text/\n    actions:\n      label:\n        add: [\"Text\"]\n  - name: \"auto add label=Example\"\n    conditions:\n      - files~=^examples/\n    actions:\n      label:\n        add: [\"Example\"]\n  - name: \"auto add label=CLI\"\n    conditions:\n      - files~=^paddlespeech/cli\n    actions:\n      label:\n        add: [\"CLI\"]\n  - name: \"auto add label=Server\"\n    conditions:\n      - files~=^paddlespeech/server\n    actions:\n      label:\n        add: [\"Server\"]\n  - name: \"auto add label=Demo\"\n    conditions:\n      - files~=^demos/\n    actions:\n      label:\n        add: [\"Demo\"]\n  - name: \"auto add label=README\"\n    conditions:\n      - files~=(README.md|READEME_cn.md)\n    actions:\n      label:\n        add: [\"README\"]\n  - name: \"auto add label=Documentation\"\n    conditions:\n      - files~=^(docs/|CHANGELOG.md)\n    actions:\n      label:\n        add: [\"Documentation\"]\n  - name: \"auto add label=CI\"\n    conditions:\n      - files~=^(.circleci/|ci/|.github/|.travis.yml|.travis|env.sh)\n    actions:\n      label:\n        add: [\"CI\"]\n  - name: \"auto add label=Installation\"\n    conditions:\n      - files~=^(tools/|setup.py|setup.cfg|setup_audio.py)\n    actions:\n      label:\n        add: [\"Installation\"]\n  - name: \"auto add label=Test\"\n    conditions:\n      - files~=^(tests/)\n    actions:\n      label:\n        add: [\"Test\"]\n  - name: \"auto add label=mergify\"\n    conditions:\n      - files~=^.mergify.yml\n    actions:\n      label:\n        add: [\"mergify\"]\n  - name: \"auto add label=Docker\"\n    conditions:\n      - files~=^docker/\n    actions:\n      label:\n        add: [\"Docker\"]\n  - name: \"auto add label=Deployment\"\n    conditions:\n      - files~=^runtime/\n    actions:\n      label:\n        add: [\"Deployment\"]\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.6201171875,
          "content": "repos:\n-   repo: https://github.com/pre-commit/mirrors-yapf.git\n    rev: v0.16.0\n    hooks:\n    -   id: yapf\n        files: \\.py$\n        exclude: (?=runtime/engine/kaldi|audio/paddleaudio/src|third_party).*(\\.cpp|\\.cc|\\.h\\.hpp|\\.py)$\n\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: a11d9314b22d8f8c7556443875b731ef05965464\n    hooks:\n    -   id: check-merge-conflict\n    -   id: check-symlinks\n    -   id: detect-private-key\n        files: (?!.*paddle)^.*$\n    -   id: end-of-file-fixer\n        files: \\.md$\n    #-   id: trailing-whitespace\n    #    files: \\.md$\n    -   id: requirements-txt-fixer\n        exclude: (?=third_party).*$\n    -   id: check-yaml\n    -   id: check-json\n    -   id: pretty-format-json\n        args:\n        - --no-sort-keys\n        - --autofix\n    -   id: check-merge-conflict\n      #    -   id: flake8\n      #        aergs:\n      #        -  --ignore=E501,E228,E226,E261,E266,E128,E402,W503\n      #        -  --builtins=G,request\n      #        -  --jobs=1\n      #        exclude: (?=runtime/engine/kaldi|audio/paddleaudio/src|third_party).*(\\.cpp|\\.cc|\\.h\\.hpp|\\.py)$\n\n-   repo : https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.0.1\n    hooks:\n    -   id: forbid-crlf\n        files: \\.md$\n    -   id: remove-crlf\n        files: \\.md$\n    -   id: forbid-tabs\n        files: \\.md$\n    -   id: remove-tabs\n        files: \\.md$\n\n-   repo: local\n    hooks:\n    -   id: clang-format\n        name: clang-format\n        description: Format files with ClangFormat\n        entry: bash .pre-commit-hooks/clang-format.hook -i\n        language: system\n        files: \\.(h\\+\\+|h|hh|hxx|hpp|cuh|c|cc|cpp|cu|c\\+\\+|cxx|tpp|txx)$\n        exclude: (?=runtime/engine/kaldi|audio/paddleaudio/src|runtime/patch|runtime/tools/fstbin|runtime/tools/lmbin|third_party/ctc_decoders|runtime/engine/common/utils).*(\\.cpp|\\.cc|\\.h|\\.hpp|\\.py)$ \n    -   id: cpplint\n        name: cpplint\n        description: Static code analysis of C/C++ files\n        language: python\n        files: \\.(h\\+\\+|h|hh|hxx|hpp|cuh|c|cc|cpp|cu|c\\+\\+|cxx|tpp|txx)$\n        exclude: (?=runtime/engine/kaldi|runtime/engine/common/matrix|audio/paddleaudio/src|runtime/patch|runtime/tools/fstbin|runtime/tools/lmbin|third_party/ctc_decoders|runtime/engine/common/utils).*(\\.cpp|\\.cc|\\.h|\\.hpp|\\.py)$ \n        entry: cpplint --filter=-build,-whitespace,+whitespace/comma,-whitespace/indent\n-   repo: https://github.com/asottile/reorder_python_imports\n    rev: v2.4.0\n    hooks:\n      - id: reorder-python-imports\n        exclude: (?=runtime/engine/kaldi|audio/paddleaudio/src|runtime/patch|runtime/tools/fstbin|runtime/tools/lmbin|third_party/ctc_decoders).*(\\.cpp|\\.cc|\\.h\\.hpp|\\.py)$\n"
        },
        {
          "name": ".pre-commit-hooks",
          "type": "tree",
          "content": null
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.6142578125,
          "content": "# .readthedocs.yml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/source/conf.py\n\n# Build documentation with MkDocs\n#mkdocs:\n#  configuration: mkdocs.yml\n\n# Optionally build your docs in additional formats such as PDF\nformats: []\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  version: 3.7\n  install:\n    - requirements: docs/requirements.txt\n    - method: setuptools\n      path: .\n  system_packages: true\n"
        },
        {
          "name": ".style.yapf",
          "type": "blob",
          "size": 0.046875,
          "content": "[style]\nbased_on_style = pep8\ncolumn_limit = 80\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.7001953125,
          "content": "language: cpp\ncache: ccache\nsudo: required\ndist: Bionic \nservices:\n  - docker\nos:\n  - linux\nenv:\n  - JOB=PRE_COMMIT\n\naddons:\n  apt:\n    packages:\n      - git\n      - python3-pip\n      - python3-dev\n\nbefore_install:\n  -  python3 --version\n  -  python3 -m pip --version\n  -  pip3 --version\n  -  sudo pip3 install -U virtualenv pre-commit pip\n  -  docker pull paddlepaddle/paddle:latest\n\nscript:\n  - exit_code=0\n  - docker run -i --rm -v \"$PWD:/py_unittest\" paddlepaddle/paddle:latest /bin/bash -c\n    'cd /py_unittest && bash .travis/precommit.sh && source env.sh && bash .travis/unittest.sh' || exit_code=$(( exit_code | $? ))\n    exit $exit_code\n\nnotifications:\n  email:\n    on_success: change\n    on_failure: always\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.07421875,
          "content": "include paddlespeech/t2s/exps/*.txt\ninclude paddlespeech/t2s/frontend/*.yaml"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 48.02734375,
          "content": "([ç®€ä½“ä¸­æ–‡](./README_cn.md)|English)\n<p align=\"center\">\n  <img src=\"./docs/images/PaddleSpeech_logo.png\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-red.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleSpeech?color=ffa\"></a>\n    <a href=\"support os\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.8+-aff.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleSpeech?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleSpeech?color=3af\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleSpeech?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?color=ccf\"></a>\n    <a href=\"=https://pypi.org/project/paddlespeech/\"><img src=\"https://img.shields.io/pypi/dm/PaddleSpeech\"></a>\n    <a href=\"=https://pypi.org/project/paddlespeech/\"><img src=\"https://static.pepy.tech/badge/paddlespeech\"></a>\n    <a href=\"https://huggingface.co/spaces\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue\"></a>\n</p>\n<div align=\"center\">  \n<h4>\n    <a href=\"#quick-start\"> Quick Start </a>\n  | <a href=\"#documents\"> Documents </a>\n  | <a href=\"#model-list\"> Models List </a>\n  | <a href=\"https://aistudio.baidu.com/aistudio/course/introduce/25130\"> AIStudio Courses </a>\n  | <a href=\"https://arxiv.org/abs/2205.12007\"> NAACL2022 Best Demo Award Paper </a>\n  | <a href=\"https://gitee.com/paddlepaddle/PaddleSpeech\"> Gitee </a>\n</h4>\n</div>\n\n------------------------------------------------------------------------------------\n\n**PaddleSpeech** is an open-source toolkit on [PaddlePaddle](https://github.com/PaddlePaddle/Paddle) platform for a variety of critical tasks in speech and audio, with the state-of-art and influential models. \n\n**PaddleSpeech** won the [NAACL2022 Best Demo Award](https://2022.naacl.org/blog/best-demo-award/), please check out our paper on [Arxiv](https://arxiv.org/abs/2205.12007).\n\n##### Speech Recognition\n\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Input Audio  </th>\n      <th width=\"550\"> Recognition Result  </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200 style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td >I knocked at the door on the ancient side of the building.</td>\n    </tr>\n    <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td>æˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n##### Speech Translation (English to Chinese)\n\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Input Audio  </th>\n      <th width=\"550\"> Translations Result  </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200 style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td >æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n##### Text-to-Speech\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th width=\"550\" > Input Text</th>\n      <th>Synthetic Audio</th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td>Life was like a box of chocolates, you never know what you're gonna get.</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/tacotron2_ljspeech_waveflow_samples_0.2/sentence_1.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>æ—©ä¸Šå¥½ï¼Œä»Šå¤©æ˜¯2020/10/29ï¼Œæœ€ä½æ¸©åº¦æ˜¯-3Â°Cã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/parakeet_espnet_fs2_pwg_demo/tn_g2p/parakeet/001.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å­£å§¬å¯‚ï¼Œé›†é¸¡ï¼Œé¸¡å³æ£˜é¸¡ã€‚æ£˜é¸¡é¥¥å½ï¼Œå­£å§¬åŠç®•ç¨·æµé¸¡ã€‚é¸¡æ—¢æµï¼Œè·»å§¬ç¬ˆï¼Œå­£å§¬å¿Œï¼Œæ€¥å’­é¸¡ï¼Œé¸¡æ€¥ï¼Œç»§åœ¾å‡ ï¼Œå­£å§¬æ€¥ï¼Œå³ç±ç®•å‡»é¸¡ï¼Œç®•ç–¾å‡»å‡ ä¼ï¼Œä¼å³é½‘ï¼Œé¸¡å½é›†å‡ åŸºï¼Œå­£å§¬æ€¥æå±å‡»é¸¡ï¼Œé¸¡æ—¢æ®›ï¼Œå­£å§¬æ¿€ï¼Œå³è®°ã€Šå­£å§¬å‡»é¸¡è®°ã€‹ã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/jijiji.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ parrot è™šæ‹Ÿè€å¸ˆï¼Œæˆ‘ä»¬æ¥è¯»ä¸€é¦–è¯—ï¼Œæˆ‘ä¸æ˜¥é£çš†è¿‡å®¢ï¼ŒI and the spring breeze are passing byï¼Œä½ æºç§‹æ°´æ½æ˜Ÿæ²³ï¼Œyou take the autumn water to take the galaxyã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/labixiaoxin.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å®œå®¶å””ç³»äº‹å¿…è¦ä½ è®²ï¼Œä½†ç³»ä½ æ‰€è®²å˜…è¯´è¯å°†ä¼šå˜æˆå‘ˆå ‚è¯ä¾›ã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/chengtangzhenggong.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å„ä¸ªå›½å®¶æœ‰å„ä¸ªå›½å®¶å˜…å›½æ­Œ</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/gegege.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\nFor more synthesized audios, please refer to [PaddleSpeech Text-to-Speech samples](https://paddlespeech.readthedocs.io/en/latest/tts/demo.html).\n\n##### Punctuation Restoration\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th width=\"390\"> Input Text </th>\n      <th width=\"390\"> Output Text </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td>ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­</td>\n      <td>ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n### Features\n\nVia the easy-to-use, efficient, flexible and scalable implementation, our vision is to empower both industrial application and academic research, including training, inference & testing modules, and deployment process. To be more specific, this toolkit features at:\n- ğŸ“¦  **Ease of Use**: low barriers to install, [CLI](#quick-start), [Server](#quick-start-server), and [Streaming Server](#quick-start-streaming-server) is available to quick-start your journey.\n- ğŸ†  **Align to the State-of-the-Art**: we provide high-speed and ultra-lightweight models, and also cutting-edge technology. \n- ğŸ†  **Streaming ASR and TTS System**: we provide production ready streaming asr and streaming tts system.\n- ğŸ’¯  **Rule-based Chinese frontend**: our frontend contains Text Normalization and Grapheme-to-Phoneme (G2P, including Polyphone and Tone Sandhi). Moreover, we use self-defined linguistic rules to adapt Chinese context.\n- ğŸ“¦  **Varieties of Functions that Vitalize both Industrial and Academia**:\n  - ğŸ›ï¸  *Implementation of critical audio tasks*: this toolkit contains audio functions like  Automatic Speech Recognition, Text-to-Speech Synthesis, Speaker Verfication, KeyWord Spotting, Audio Classification, and Speech Translation, etc.\n  - ğŸ”¬  *Integration of mainstream models and datasets*: the toolkit implements modules that participate in the whole pipeline of the speech tasks, and uses mainstream datasets like LibriSpeech, LJSpeech, AIShell, CSMSC, etc. See also [model list](#model-list) for more details.\n  - ğŸ§©  *Cascaded models application*: as an extension of the typical traditional audio tasks, we combine the workflows of the aforementioned tasks with other fields like Natural language processing (NLP) and Computer Vision (CV).\n\n### Recent Update\n- ğŸ‘‘ 2023.05.31: Add [WavLM ASR-en](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/librispeech/asr5), WavLM fine-tuning for ASR on LibriSpeech.\n- ğŸ‰ 2023.05.18: Add [Squeezeformer](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1), Squeezeformer training for ASR on Aishell.\n- ğŸ‘‘ 2023.05.04: Add [HuBERT ASR-en](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/librispeech/asr4), HuBERT fine-tuning for ASR on LibriSpeech.\n- âš¡ 2023.04.28: Fix [0-d tensor](https://github.com/PaddlePaddle/PaddleSpeech/pull/3214), with the upgrade of paddlepaddle==2.5, the problem of modifying 0-d tensor has been solved.\n- ğŸ‘‘ 2023.04.25: Add [AMP for U2 conformer](https://github.com/PaddlePaddle/PaddleSpeech/pull/3167).\n- ğŸ”¥ 2023.04.06: Add [subtitle file (.srt format) generation example](./demos/streaming_asr_server).\n- ğŸ”¥ 2023.03.14: Add SVS(Singing Voice Synthesis) examples with Opencpop dataset, including [DiffSinger](./examples/opencpop/svs1)ã€[PWGAN](./examples/opencpop/voc1) and [HiFiGAN](./examples/opencpop/voc5), the effect is continuously optimized.\n- ğŸ‘‘ 2023.03.09: Add [Wav2vec2ASR-zh](./examples/aishell/asr3).\n- ğŸ‰ 2023.03.07: Add [TTS ARM Linux C++ Demo (with C++ Chinese Text Frontend)](./demos/TTSArmLinux).\n- ğŸ”¥ 2023.03.03 Add Voice Conversion [StarGANv2-VC synthesize pipeline](./examples/vctk/vc3).\n- ğŸ‰ 2023.02.16: Add [Cantonese TTS](./examples/canton/tts3).\n- ğŸ”¥ 2023.01.10: Add [code-switch asr CLI and Demos](./demos/speech_recognition).\n- ğŸ‘‘ 2023.01.06: Add [code-switch asr tal_cs recipe](./examples/tal_cs/asr1/).\n- ğŸ‰ 2022.12.02: Add [end-to-end Prosody Prediction pipeline](./examples/csmsc/tts3_rhy) (including using prosody labels in Acoustic Model).\n- ğŸ‰ 2022.11.30: Add [TTS Android Demo](./demos/TTSAndroid).\n- ğŸ¤— 2022.11.28: PP-TTS and PP-ASR demos are available in [AIStudio](https://aistudio.baidu.com/aistudio/modelsoverview) and [official website\n of paddlepaddle](https://www.paddlepaddle.org.cn/models).\n- ğŸ‘‘ 2022.11.18: Add [Whisper CLI and Demos](https://github.com/PaddlePaddle/PaddleSpeech/pull/2640), support multi language recognition and translation.\n- ğŸ”¥ 2022.11.18: Add [Wav2vec2 CLI and Demos](./demos/speech_ssl), Support ASR and Feature Extraction.\n- ğŸ‰ 2022.11.17: Add [male voice for TTS](https://github.com/PaddlePaddle/PaddleSpeech/pull/2660).\n- ğŸ”¥ 2022.11.07: Add [U2/U2++ C++ High Performance Streaming ASR Deployment](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/runtime/examples/u2pp_ol/wenetspeech).\n- ğŸ‘‘ 2022.11.01: Add [Adversarial Loss](https://arxiv.org/pdf/1907.04448.pdf) for [Chinese English mixed TTS](./examples/zh_en_tts/tts3).\n- ğŸ”¥ 2022.10.26: Add [Prosody Prediction](./examples/other/rhy) for TTS.\n- ğŸ‰ 2022.10.21: Add [SSML](https://github.com/PaddlePaddle/PaddleSpeech/discussions/2538) for TTS Chinese Text Frontend.\n- ğŸ‘‘ 2022.10.11: Add [Wav2vec2ASR-en](./examples/librispeech/asr3), wav2vec2.0 fine-tuning for ASR on LibriSpeech.\n- ğŸ”¥ 2022.09.26: Add Voice Cloning, TTS finetune, and [ERNIE-SAT](https://arxiv.org/abs/2211.03545) in [PaddleSpeech Web Demo](./demos/speech_web).\n- âš¡ 2022.09.09: Add AISHELL-3 Voice Cloning [example](./examples/aishell3/vc2) with ECAPA-TDNN speaker encoder.\n- âš¡ 2022.08.25: Release TTS [finetune](./examples/other/tts_finetune/tts3) example.\n- ğŸ”¥ 2022.08.22: Add [ERNIE-SAT](https://arxiv.org/abs/2211.03545) models: [ERNIE-SAT-vctk](./examples/vctk/ernie_sat)ã€[ERNIE-SAT-aishell3](./examples/aishell3/ernie_sat)ã€[ERNIE-SAT-zh_en](./examples/aishell3_vctk/ernie_sat).\n- ğŸ”¥ 2022.08.15: Add [g2pW](https://github.com/GitYCC/g2pW) into TTS Chinese Text Frontend.\n- ğŸ”¥ 2022.08.09: Release [Chinese English mixed TTS](./examples/zh_en_tts/tts3).\n- âš¡ 2022.08.03: Add ONNXRuntime infer for  TTS CLI.\n- ğŸ‰ 2022.07.18: Release VITS: [VITS-csmsc](./examples/csmsc/vits)ã€[VITS-aishell3](./examples/aishell3/vits)ã€[VITS-VC](./examples/aishell3/vits-vc).\n- ğŸ‰ 2022.06.22: All TTS models support ONNX format.\n- ğŸ€ 2022.06.17: Add [PaddleSpeech Web Demo](./demos/speech_web).\n- ğŸ‘‘ 2022.05.13: Release [PP-ASR](./docs/source/asr/PPASR.md)ã€[PP-TTS](./docs/source/tts/PPTTS.md)ã€[PP-VPR](docs/source/vpr/PPVPR.md).\n- ğŸ‘ğŸ» 2022.05.06: `PaddleSpeech Streaming Server` is available for `Streaming ASR` with `Punctuation Restoration` and `Token Timestamp` and `Text-to-Speech`.\n- ğŸ‘ğŸ» 2022.05.06: `PaddleSpeech Server` is available for `Audio Classification`, `Automatic Speech Recognition` and `Text-to-Speech`, `Speaker Verification` and `Punctuation Restoration`.\n- ğŸ‘ğŸ» 2022.03.28: `PaddleSpeech CLI` is available for `Speaker Verification`.\n- ğŸ‘ğŸ» 2021.12.10: `PaddleSpeech CLI` is available for `Audio Classification`, `Automatic Speech Recognition`, `Speech Translation (English to Chinese)` and `Text-to-Speech`.\n\n### Community\n- Scan the QR code below with your Wechat, you can access to official technical exchange group and get the bonus ( more than 20GB learning materials, such as papers, codes and videos ) and the live link of the lessons. Look forward to your participation.\n\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/30135920/212860467-9e943cc3-8be8-49a4-97fd-7c94aad8e979.jpg\"  width = \"200\"  />\n</div>\n\n## Installation\n\nWe strongly recommend our users to install PaddleSpeech in **Linux** with *python>=3.8* and *paddlepaddle<=2.5.1*. Some new versions of Paddle do not have support for adaptation in PaddleSpeech, so currently only versions 2.5.1 and earlier can be supported.\n\n### **Dependency Introduction**\n\n+ gcc >= 4.8.5\n+ paddlepaddle <= 2.5.1\n+ python >= 3.8\n+ OS support:  Linux(recommend), Windows, Mac OSX\n\nPaddleSpeech depends on paddlepaddle. For installation, please refer to the official website of [paddlepaddle](https://www.paddlepaddle.org.cn/en) and choose according to your own machine. Here is an example of the cpu version.\n\n```bash\npip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\n```\nYou can also specify the version of paddlepaddle or install the develop version. \n```bash\n# install 2.4.1 version. Note, 2.4.1 is just an example, please follow the minimum dependency of paddlepaddle for your selection\npip install paddlepaddle==2.4.1 -i https://mirror.baidu.com/pypi/simple\n# install develop version\npip install paddlepaddle==0.0.0 -f https://www.paddlepaddle.org.cn/whl/linux/cpu-mkl/develop.html\n```\n\nThere are two quick installation methods for PaddleSpeech, one is pip installation, and the other is source code compilation (recommended).\n### pip install\n\n```shell\npip install pytest-runner\npip install paddlespeech\n```\n\n### source code compilation\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git\ncd PaddleSpeech\npip install pytest-runner\npip install .\n```\n\nFor more installation problems, such as conda environment, librosa-dependent, gcc problems, kaldi installation, etc., you can refer to this [installation document](./docs/source/install.md). If you encounter problems during installation, you can leave a message on [#2150](https://github.com/PaddlePaddle/PaddleSpeech/issues/2150) and find related problems\n\n\n<a name=\"quickstart\"></a>\n## Quick Start\n\nDevelopers can have a try of our models with [PaddleSpeech Command Line](./paddlespeech/cli/README.md) or Python. Change `--input` to test your own audio/text and support 16k wav format audio.\n\n**You can also quickly experience it in AI Studio ğŸ‘‰ğŸ» [PaddleSpeech API Demo](https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&shared=1&ts=1660876445786)**\n\n\nTest audio sample download\n\n```shell\nwget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav\nwget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\n```\n\n### Automatic Speech Recognition\n\n<details><summary>&emsp;ï¼ˆClick to expandï¼‰Open Source Speech Recognition</summary>\n\n**command line experience**\n\n```shell\npaddlespeech asr --lang zh --input zh.wav\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.asr.infer import ASRExecutor\n>>> asr = ASRExecutor()\n>>> result = asr(audio_file=\"zh.wav\")\n>>> print(result)\næˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·\n```\n</details>\n\n### Text-to-Speech\n\n<details><summary>&emsp;Open Source Speech Synthesis</summary>\n\nOutput 24k sample rate wav format audio\n\n\n**command line experience**\n\n```shell\npaddlespeech tts --input \"ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼\" --output output.wav\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.tts.infer import TTSExecutor\n>>> tts = TTSExecutor()\n>>> tts(text=\"ä»Šå¤©å¤©æ°”ååˆ†ä¸é”™ã€‚\", output=\"output.wav\")\n```\n- You can experience in [Huggingface Spaces](https://huggingface.co/spaces) [TTS Demo](https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS)\n\n</details>\n\n### Audio Classification\n\n<details><summary>&emsp;An open-domain sound classification tool</summary>\n\nSound classification model based on 527 categories of AudioSet dataset\n\n**command line experience**\n\n```shell\npaddlespeech cls --input zh.wav\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.cls.infer import CLSExecutor\n>>> cls = CLSExecutor()\n>>> result = cls(audio_file=\"zh.wav\")\n>>> print(result)\nSpeech 0.9027186632156372\n```\n\n</details>\n\n### Voiceprint Extraction\n\n<details><summary>&emsp;Industrial-grade voiceprint extraction tool</summary>\n\n**command line experience**\n\n```shell\npaddlespeech vector --task spk --input zh.wav\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.vector import VectorExecutor\n>>> vec = VectorExecutor()\n>>> result = vec(audio_file=\"zh.wav\")\n>>> print(result) # 187ç»´å‘é‡\n[ -0.19083306   9.474295   -14.122263    -2.0916545    0.04848729\n   4.9295826    1.4780062    0.3733844   10.695862     3.2697146\n  -4.48199     -0.6617882   -9.170393   -11.1568775   -1.2358263 ...]\n```\n\n</details>\n\n### Punctuation Restoration\n\n<details><summary>&emsp;Quick recovery of text punctuation, works with ASR models</summary>\n\n**command line experience**\n\n```shell\npaddlespeech text --task punc --input ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.text.infer import TextExecutor\n>>> text_punc = TextExecutor()\n>>> result = text_punc(text=\"ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­\")\nä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚\n```\n\n</details>\n\n### Speech Translation\n\n<details><summary>&emsp;End-to-end English to Chinese Speech Translation Tool</summary>\n\nUse pre-compiled kaldi related tools, only support experience in Ubuntu system\n\n**command line experience**\n\n```shell\npaddlespeech st --input en.wav\n```\n\n**Python API experience**\n\n```python\n>>> from paddlespeech.cli.st.infer import STExecutor\n>>> st = STExecutor()\n>>> result = st(audio_file=\"en.wav\")\n['æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ ã€‚']\n```\n\n</details>\n\n\n<a name=\"quickstartserver\"></a>\n## Quick Start Server\n\nDevelopers can have a try of our speech server with [PaddleSpeech Server Command Line](./paddlespeech/server/README.md).\n\n**You can try it quickly in AI Studio (recommend): [SpeechServer](https://aistudio.baidu.com/aistudio/projectdetail/4354592?sUid=2470186&shared=1&ts=1660877827034)**\n\n**Start server**     \n\n```shell\npaddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\n```\n\n**Access Speech Recognition Services**     \n\n```shell\npaddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input input_16k.wav\n```\n\n**Access Text to Speech Services**     \n\n```shell\npaddlespeech_client tts --server_ip 127.0.0.1 --port 8090 --input \"æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚\" --output output.wav\n```\n\n**Access Audio Classification Services**     \n```shell\npaddlespeech_client cls --server_ip 127.0.0.1 --port 8090 --input input.wav\n```\n\n\nFor more information about server command lines, please see: [speech server demos](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_server)\n\n\n<a name=\"quickstartstreamingserver\"></a>\n## Quick Start Streaming Server\n\nDevelopers can have a try of  [streaming asr](./demos/streaming_asr_server/README.md) and [streaming tts](./demos/streaming_tts_server/README.md) server.\n\n**Start Streaming Speech Recognition Server**\n\n```\npaddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml\n```\n\n**Access Streaming Speech Recognition Services**     \n\n```\npaddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input input_16k.wav\n```\n\n**Start Streaming Text to Speech  Server**\n\n```\npaddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml\n```\n\n**Access Streaming Text to Speech Services**     \n\n```\npaddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol http --input \"æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚\" --output output.wav\n```\n\nFor more information please see:  [streaming asr](./demos/streaming_asr_server/README.md) and [streaming tts](./demos/streaming_tts_server/README.md) \n\n<a name=\"ModelList\"></a>\n\n## Model List\n\nPaddleSpeech supports a series of most popular models. They are summarized in [released models](./docs/source/released_model.md) and attached with available pretrained models.\n\n<a name=\"SpeechToText\"></a>\n\n**Speech-to-Text** contains *Acoustic Model*, *Language Model*, and *Speech Translation*, with the following details:\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th>Speech-to-Text Module Type</th>\n      <th>Dataset</th>\n      <th>Model Type</th>\n      <th>Example</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td rowspan=\"4\">Speech Recogination</td>\n      <td rowspan=\"2\" >Aishell</td>\n      <td >DeepSpeech2 RNN + Conv based Models</td>\n      <td>\n      <a href = \"./examples/aishell/asr0\">deepspeech2-aishell</a>\n      </td>\n    </tr>\n    <tr>\n      <td>Transformer based Attention Models </td>\n      <td>\n      <a href = \"./examples/aishell/asr1\">u2.transformer.conformer-aishell</a>\n      </td>\n    </tr>\n    <tr>\n      <td> Librispeech</td>\n      <td>Transformer based Attention Models </td>\n      <td>\n      <a href = \"./examples/librispeech/asr0\">deepspeech2-librispeech</a> / <a href = \"./examples/librispeech/asr1\">transformer.conformer.u2-librispeech</a>  / <a href = \"./examples/librispeech/asr2\">transformer.conformer.u2-kaldi-librispeech</a>\n      </td>\n      </td>\n    </tr>\n  <tr>\n      <td>TIMIT</td>\n      <td>Unified Streaming & Non-streaming Two-pass</td>\n      <td>\n    <a href = \"./examples/timit/asr1\"> u2-timit</a>\n      </td>\n  </tr>\n  <tr>\n  <td>Alignment</td>\n  <td>THCHS30</td>\n  <td>MFA</td>\n  <td>\n  <a href = \".examples/thchs30/align0\">mfa-thchs30</a>\n  </td>\n  </tr>\n   <tr>\n      <td rowspan=\"1\">Language Model</td>\n      <td colspan = \"2\">Ngram Language Model</td>\n      <td>\n      <a href = \"./examples/other/ngram_lm\">kenlm</a>\n      </td>\n    </tr>\n  <tr>\n      <td rowspan=\"2\">Speech Translation (English to Chinese)</td> \n      <td rowspan=\"2\">TED En-Zh</td>\n      <td>Transformer + ASR MTL</td>\n      <td>\n      <a href = \"./examples/ted_en_zh/st0\">transformer-ted</a>\n      </td>\n  </tr>\n  <tr>\n      <td>FAT + Transformer + ASR MTL</td>\n      <td>\n      <a href = \"./examples/ted_en_zh/st1\">fat-st-ted</a>\n      </td>\n  </tr>\n  </tbody>\n</table>\n\n<a name=\"TextToSpeech\"></a>\n\n**Text-to-Speech** in PaddleSpeech mainly contains three modules: *Text Frontend*, *Acoustic Model* and *Vocoder*. Acoustic Model and Vocoder models are listed as follow:\n\n<table>\n  <thead>\n    <tr>\n      <th> Text-to-Speech Module Type </th>\n      <th> Model Type </th>\n      <th> Dataset </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td> Text Frontend </td>\n      <td colspan=\"2\"> &emsp; </td>\n      <td>\n      <a href = \"./examples/other/tn\">tn</a> / <a href = \"./examples/other/g2p\">g2p</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"6\">Acoustic Model</td>\n      <td>Tacotron2</td>\n      <td>LJSpeech / CSMSC</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts0\">tacotron2-ljspeech</a> / <a href = \"./examples/csmsc/tts0\">tacotron2-csmsc</a>\n      </td>\n    </tr>\n    <tr>\n      <td>Transformer TTS</td>\n      <td>LJSpeech</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts1\">transformer-ljspeech</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SpeedySpeech</td>\n      <td>CSMSC</td>\n      <td >\n      <a href = \"./examples/csmsc/tts2\">speedyspeech-csmsc</a>\n      </td>\n    </tr>\n    <tr>\n      <td>FastSpeech2</td>\n      <td>LJSpeech / VCTK / CSMSC / AISHELL-3 / ZH_EN / finetune</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts3\">fastspeech2-ljspeech</a> / <a href = \"./examples/vctk/tts3\">fastspeech2-vctk</a> / <a href = \"./examples/csmsc/tts3\">fastspeech2-csmsc</a> / <a href = \"./examples/aishell3/tts3\">fastspeech2-aishell3</a> / <a href = \"./examples/zh_en_tts/tts3\">fastspeech2-zh_en</a> / <a href = \"./examples/other/tts_finetune/tts3\">fastspeech2-finetune</a>\n      </td>\n    </tr>\n    <tr>\n      <td><a href = \"https://arxiv.org/abs/2211.03545\">ERNIE-SAT</a></td>\n      <td>VCTK / AISHELL-3 / ZH_EN</td>\n      <td>\n      <a href = \"./examples/vctk/ernie_sat\">ERNIE-SAT-vctk</a> / <a href = \"./examples/aishell3/ernie_sat\">ERNIE-SAT-aishell3</a> / <a href = \"./examples/aishell3_vctk/ernie_sat\">ERNIE-SAT-zh_en</a>\n      </td>\n    </tr>\n    <tr>\n      <td>DiffSinger</td>\n      <td>Opencpop</td>\n      <td>\n      <a href = \"./examples/opencpop/svs1\">DiffSinger-opencpop</a>\n      </td>\n   </tr>\n   <tr>\n      <td rowspan=\"6\">Vocoder</td>\n      <td >WaveFlow</td>\n      <td >LJSpeech</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc0\">waveflow-ljspeech</a>\n      </td>\n    </tr>\n    <tr>\n      <td >Parallel WaveGAN</td>\n      <td >LJSpeech / VCTK / CSMSC / AISHELL-3 / Opencpop</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc1\">PWGAN-ljspeech</a> / <a href = \"./examples/vctk/voc1\">PWGAN-vctk</a> / <a href = \"./examples/csmsc/voc1\">PWGAN-csmsc</a> /  <a href = \"./examples/aishell3/voc1\">PWGAN-aishell3</a> / <a href = \"./examples/opencpop/voc1\">PWGAN-opencpop</a>\n      </td>\n    </tr>\n    <tr>\n      <td >Multi Band MelGAN</td>\n      <td >CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc3\">Multi Band MelGAN-csmsc</a> \n      </td>\n    </tr> \n    <tr>\n      <td >Style MelGAN</td>\n      <td >CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc4\">Style MelGAN-csmsc</a> \n      </td>\n    </tr>\n    <tr>\n      <td>HiFiGAN</td>\n      <td>LJSpeech / VCTK / CSMSC / AISHELL-3 / Opencpop</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc5\">HiFiGAN-ljspeech</a> / <a href = \"./examples/vctk/voc5\">HiFiGAN-vctk</a> / <a href = \"./examples/csmsc/voc5\">HiFiGAN-csmsc</a> / <a href = \"./examples/aishell3/voc5\">HiFiGAN-aishell3</a> / <a href = \"./examples/opencpop/voc5\">HiFiGAN-opencpop</a>\n      </td>\n    </tr>\n    <tr>\n      <td>WaveRNN</td>\n      <td>CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc6\">WaveRNN-csmsc</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"5\">Voice Cloning</td>\n      <td>GE2E</td>\n      <td >Librispeech, etc.</td>\n      <td>\n      <a href = \"./examples/other/ge2e\">GE2E</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (GE2E + Tacotron2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc0\">VC0</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (GE2E + FastSpeech2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc1\">VC1</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (ECAPA-TDNN + FastSpeech2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc2\">VC2</a>\n      </td>\n    </tr>\n    <tr>\n      <td>GE2E + VITS</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vits-vc\">VITS-VC</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"3\">End-to-End</td>\n      <td>VITS</td>\n      <td>CSMSC / AISHELL-3</td>\n      <td>\n      <a href = \"./examples/csmsc/vits\">VITS-csmsc</a> / <a href = \"./examples/aishell3/vits\">VITS-aishell3</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"AudioClassification\"></a>\n\n**Audio Classification**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Task </th>\n      <th> Dataset </th>\n      <th> Model Type </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>Audio Classification</td>\n      <td>ESC-50</td>\n      <td>PANN</td>\n      <td>\n      <a href = \"./examples/esc50/cls0\">pann-esc50</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"KeywordSpotting\"></a>\n\n**Keyword Spotting**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Task </th>\n      <th> Dataset </th>\n      <th> Model Type </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>Keyword Spotting</td>\n      <td>hey-snips</td>\n      <td>MDTC</td>\n      <td>\n      <a href = \"./examples/hey_snips/kws0\">mdtc-hey-snips</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"SpeakerVerification\"></a>\n\n**Speaker Verification**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Task </th>\n      <th> Dataset </th>\n      <th> Model Type </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>Speaker Verification</td>\n      <td>VoxCeleb1/2</td>\n      <td>ECAPA-TDNN</td>\n      <td>\n      <a href = \"./examples/voxceleb/sv0\">ecapa-tdnn-voxceleb12</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"SpeakerDiarization\"></a>\n\n**Speaker Diarization**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Task </th>\n      <th> Dataset </th>\n      <th> Model Type </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>Speaker Diarization</td>\n     <td>AMI</td>\n      <td>ECAPA-TDNN + AHC / SC</td>\n      <td>\n      <a href = \"./examples/ami/sd0\">ecapa-tdnn-ami</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"PunctuationRestoration\"></a>\n\n**Punctuation Restoration**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> Task </th>\n      <th> Dataset </th>\n      <th> Model Type </th>\n      <th> Example </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>Punctuation Restoration</td>\n      <td>IWLST2012_zh</td>\n      <td>Ernie Linear</td>\n      <td>\n      <a href = \"./examples/iwslt2012/punc0\">iwslt2012-punc0</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## Documents\n\nNormally, [Speech SoTA](https://paperswithcode.com/area/speech), [Audio SoTA](https://paperswithcode.com/area/audio) and [Music SoTA](https://paperswithcode.com/area/music) give you an overview of the hot academic topics in the related area. To focus on the tasks in PaddleSpeech, you will find the following guidelines are helpful to grasp the core ideas.\n\n- [Installation](./docs/source/install.md)\n- [Quick Start](#quickstart)\n- [Some Demos](./demos/README.md)\n- Tutorials\n  - [Automatic Speech Recognition](./docs/source/asr/quick_start.md)\n    - [Introduction](./docs/source/asr/models_introduction.md)\n    - [Data Preparation](./docs/source/asr/data_preparation.md)\n    - [Ngram LM](./docs/source/asr/ngram_lm.md)\n  - [Text-to-Speech](./docs/source/tts/quick_start.md)\n    - [Introduction](./docs/source/tts/models_introduction.md)\n    - [Advanced Usage](./docs/source/tts/advanced_usage.md)\n    - [Chinese Rule Based Text Frontend](./docs/source/tts/zh_text_frontend.md)\n    - [Test Audio Samples](https://paddlespeech.readthedocs.io/en/latest/tts/demo.html)\n  - Speaker Verification\n    - [Audio Searching](./demos/audio_searching/README.md)\n    - [Speaker Verification](./demos/speaker_verification/README.md)\n  - [Audio Classification](./demos/audio_tagging/README.md)\n  - [Speech Translation](./demos/speech_translation/README.md)\n  - [Speech Server](./demos/speech_server/README.md)\n- [Released Models](./docs/source/released_model.md)\n  - [Speech-to-Text](#SpeechToText)\n  - [Text-to-Speech](#TextToSpeech)\n  - [Audio Classification](#AudioClassification)\n  - [Speaker Verification](#SpeakerVerification)\n  - [Speaker Diarization](#SpeakerDiarization)\n  - [Punctuation Restoration](#PunctuationRestoration)\n- [Community](#Community)\n- [Welcome to contribute](#contribution)\n- [License](#License)\n\nThe Text-to-Speech module is originally called [Parakeet](https://github.com/PaddlePaddle/Parakeet), and now merged with this repository. If you are interested in academic research about this task, please see [TTS research overview](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/docs/source/tts#overview). Also, [this document](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/tts/models_introduction.md) is a good guideline for the pipeline components.\n\n\n## â­ Examples\n- **[PaddleBoBo](https://github.com/JiehangXie/PaddleBoBo): Use PaddleSpeech TTS to generate virtual human voice.**\n  \n<div align=\"center\"><a href=\"https://www.bilibili.com/video/BV1cL411V71o?share_source=copy_web\"><img src=\"https://ai-studio-static-online.cdn.bcebos.com/06fd746ab32042f398fb6f33f873e6869e846fe63c214596ae37860fe8103720\" / width=\"500px\"></a></div>\n\n- [PaddleSpeech Demo Video](https://paddlespeech.readthedocs.io/en/latest/demo_video.html)\n\n- **[VTuberTalk](https://github.com/jerryuhoo/VTuberTalk): Use PaddleSpeech TTS and ASR to clone voice from videos.**\n\n\n## Citation\n\nTo cite PaddleSpeech for research, please use the following format.\n\n```text\n@inproceedings{zhang2022paddlespeech,\n    title = {PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit},\n    author = {Hui Zhang, Tian Yuan, Junkun Chen, Xintong Li, Renjie Zheng, Yuxin Huang, Xiaojie Chen, Enlei Gong, Zeyu Chen, Xiaoguang Hu, dianhai yu, Yanjun Ma, Liang Huang},\n    booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations},\n    year = {2022},\n    publisher = {Association for Computational Linguistics},\n}\n\n@InProceedings{pmlr-v162-bai22d,\n  title = {{A}$^3${T}: Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing},\n  author = {Bai, He and Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Li, Xintong and Huang, Liang},\n  booktitle = {Proceedings of the 39th International Conference on Machine Learning},\n  pages = {1399--1411},\n  year = {2022},\n  volume = {162},\n  series = {Proceedings of Machine Learning Research},\n  month = {17--23 Jul},\n  publisher = {PMLR},\n  pdf = {https://proceedings.mlr.press/v162/bai22d/bai22d.pdf},\n  url = {https://proceedings.mlr.press/v162/bai22d.html},\n}\n\n@inproceedings{zheng2021fused,\n  title={Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation},\n  author={Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Huang, Liang},\n  booktitle={International Conference on Machine Learning},\n  pages={12736--12746},\n  year={2021},\n  organization={PMLR}\n}\n```\n\n<a name=\"contribution\"></a>\n## Contribute to PaddleSpeech\n\nYou are warmly welcome to submit questions in [discussions](https://github.com/PaddlePaddle/PaddleSpeech/discussions) and bug reports in [issues](https://github.com/PaddlePaddle/PaddleSpeech/issues)! Also, we highly appreciate if you are willing to contribute to this project!\n\n### Contributors\n<p align=\"center\">\n<a href=\"https://github.com/zh794390558\"><img src=\"https://avatars.githubusercontent.com/u/3038472?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Jackwaterveg\"><img src=\"https://avatars.githubusercontent.com/u/87408988?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/yt605155624\"><img src=\"https://avatars.githubusercontent.com/u/24568452?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Honei\"><img src=\"https://avatars.githubusercontent.com/u/11361692?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/KPatr1ck\"><img src=\"https://avatars.githubusercontent.com/u/22954146?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kuke\"><img src=\"https://avatars.githubusercontent.com/u/3064195?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lym0302\"><img src=\"https://avatars.githubusercontent.com/u/34430015?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/SmileGoat\"><img src=\"https://avatars.githubusercontent.com/u/56786796?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/xinghai-sun\"><img src=\"https://avatars.githubusercontent.com/u/7038341?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/pkuyym\"><img src=\"https://avatars.githubusercontent.com/u/5782283?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/LittleChenCc\"><img src=\"https://avatars.githubusercontent.com/u/10339970?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/qingen\"><img src=\"https://avatars.githubusercontent.com/u/3139179?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/D-DanielYang\"><img src=\"https://avatars.githubusercontent.com/u/23690325?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Mingxue-Xu\"><img src=\"https://avatars.githubusercontent.com/u/92848346?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/745165806\"><img src=\"https://avatars.githubusercontent.com/u/20623194?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/jerryuhoo\"><img src=\"https://avatars.githubusercontent.com/u/24245709?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/WilliamZhang06\"><img src=\"https://avatars.githubusercontent.com/u/97937340?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chrisxu2016\"><img src=\"https://avatars.githubusercontent.com/u/18379485?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/iftaken\"><img src=\"https://avatars.githubusercontent.com/u/30135920?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lfchener\"><img src=\"https://avatars.githubusercontent.com/u/6771821?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/BarryKCL\"><img src=\"https://avatars.githubusercontent.com/u/48039828?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/mmglove\"><img src=\"https://avatars.githubusercontent.com/u/38800877?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/gongel\"><img src=\"https://avatars.githubusercontent.com/u/24390500?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/luotao1\"><img src=\"https://avatars.githubusercontent.com/u/6836917?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/wanghaoshuang\"><img src=\"https://avatars.githubusercontent.com/u/7534971?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kslz\"><img src=\"https://avatars.githubusercontent.com/u/54951765?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/JiehangXie\"><img src=\"https://avatars.githubusercontent.com/u/51190264?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/david-95\"><img src=\"https://avatars.githubusercontent.com/u/15189190?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/THUzyt21\"><img src=\"https://avatars.githubusercontent.com/u/91456992?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/buchongyu2\"><img src=\"https://avatars.githubusercontent.com/u/29157444?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/iclementine\"><img src=\"https://avatars.githubusercontent.com/u/16222986?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/phecda-xu\"><img src=\"https://avatars.githubusercontent.com/u/46859427?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/freeliuzc\"><img src=\"https://avatars.githubusercontent.com/u/23568094?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ZeyuChen\"><img src=\"https://avatars.githubusercontent.com/u/1371212?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ccrrong\"><img src=\"https://avatars.githubusercontent.com/u/101700995?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AK391\"><img src=\"https://avatars.githubusercontent.com/u/81195143?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/qingqing01\"><img src=\"https://avatars.githubusercontent.com/u/7845005?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/0x45f\"><img src=\"https://avatars.githubusercontent.com/u/23097963?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/vpegasus\"><img src=\"https://avatars.githubusercontent.com/u/22723154?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ericxk\"><img src=\"https://avatars.githubusercontent.com/u/4719594?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Betterman-qs\"><img src=\"https://avatars.githubusercontent.com/u/61459181?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/sneaxiy\"><img src=\"https://avatars.githubusercontent.com/u/32832641?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Doubledongli\"><img src=\"https://avatars.githubusercontent.com/u/20540661?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/apps/dependabot\"><img src=\"https://avatars.githubusercontent.com/in/29110?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kvinwang\"><img src=\"https://avatars.githubusercontent.com/u/6442159?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chenkui164\"><img src=\"https://avatars.githubusercontent.com/u/34813030?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/PaddleZhang\"><img src=\"https://avatars.githubusercontent.com/u/97284124?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/billishyahao\"><img src=\"https://avatars.githubusercontent.com/u/96406262?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/BrightXiaoHan\"><img src=\"https://avatars.githubusercontent.com/u/25839309?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/jiqiren11\"><img src=\"https://avatars.githubusercontent.com/u/82639260?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ryanrussell\"><img src=\"https://avatars.githubusercontent.com/u/523300?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/GT-ZhangAcer\"><img src=\"https://avatars.githubusercontent.com/u/46156734?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/tensor-tang\"><img src=\"https://avatars.githubusercontent.com/u/21351065?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/hysunflower\"><img src=\"https://avatars.githubusercontent.com/u/52739577?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/oyjxer\"><img src=\"https://avatars.githubusercontent.com/u/16233945?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/JamesLim-sy\"><img src=\"https://avatars.githubusercontent.com/u/61349199?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/limpidezza\"><img src=\"https://avatars.githubusercontent.com/u/71760778?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/windstamp\"><img src=\"https://avatars.githubusercontent.com/u/34057289?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AshishKarel\"><img src=\"https://avatars.githubusercontent.com/u/58069375?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chesterkuo\"><img src=\"https://avatars.githubusercontent.com/u/6285069?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/YDX-2147483647\"><img src=\"https://avatars.githubusercontent.com/u/73375426?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AdamBear\"><img src=\"https://avatars.githubusercontent.com/u/2288870?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/wwhu\"><img src=\"https://avatars.githubusercontent.com/u/6081200?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lispc\"><img src=\"https://avatars.githubusercontent.com/u/2833376?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/harisankarh\"><img src=\"https://avatars.githubusercontent.com/u/1307053?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/pengzhendong\"><img src=\"https://avatars.githubusercontent.com/u/10704539?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Jackiexiao\"><img src=\"https://avatars.githubusercontent.com/u/18050469?s=60&v=4\" width=75 height=75></a>\n</p>\n\n## Acknowledgement\n- Many thanks to [HighCWu](https://github.com/HighCWu) for adding [VITS-aishell3](./examples/aishell3/vits) and [VITS-VC](./examples/aishell3/vits-vc) examples.\n- Many thanks to [david-95](https://github.com/david-95) for fixing multi-punctuation bugã€contributing to multiple program and data, and adding [SSML](https://github.com/PaddlePaddle/PaddleSpeech/discussions/2538) for TTS Chinese Text Frontend. \n- Many thanks to [BarryKCL](https://github.com/BarryKCL) for improving TTS Chinses Frontend based on [G2PW](https://github.com/GitYCC/g2pW).\n- Many thanks to [yeyupiaoling](https://github.com/yeyupiaoling)/[PPASR](https://github.com/yeyupiaoling/PPASR)/[PaddlePaddle-DeepSpeech](https://github.com/yeyupiaoling/PaddlePaddle-DeepSpeech)/[VoiceprintRecognition-PaddlePaddle](https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle)/[AudioClassification-PaddlePaddle](https://github.com/yeyupiaoling/AudioClassification-PaddlePaddle) for years of attention, constructive advice and great help.\n- Many thanks to [mymagicpower](https://github.com/mymagicpower) for the Java implementation of ASR upon [short](https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_sdk) and [long](https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_long_audio_sdk) audio files.\n- Many thanks to [JiehangXie](https://github.com/JiehangXie)/[PaddleBoBo](https://github.com/JiehangXie/PaddleBoBo) for developing Virtual Uploader(VUP)/Virtual YouTuber(VTuber) with PaddleSpeech TTS function.\n- Many thanks to [745165806](https://github.com/745165806)/[PaddleSpeechTask](https://github.com/745165806/PaddleSpeechTask) for contributing Punctuation Restoration model.\n- Many thanks to [kslz](https://github.com/745165806) for supplementary Chinese documents.\n- Many thanks to [awmmmm](https://github.com/awmmmm) for contributing fastspeech2 aishell3 conformer pretrained model.\n- Many thanks to [phecda-xu](https://github.com/phecda-xu)/[PaddleDubbing](https://github.com/phecda-xu/PaddleDubbing) for developing a dubbing tool with GUI based on PaddleSpeech TTS model.\n- Many thanks to [jerryuhoo](https://github.com/jerryuhoo)/[VTuberTalk](https://github.com/jerryuhoo/VTuberTalk) for developing a GUI tool based on PaddleSpeech TTS and code for making datasets from videos based on PaddleSpeech ASR.\n- Many thanks to [vpegasus](https://github.com/vpegasus)/[xuesebot](https://github.com/vpegasus/xuesebot) for developing a rasa chatbot,which is able to speak and listen thanks to PaddleSpeech.\n- Many thanks to [chenkui164](https://github.com/chenkui164)/[FastASR](https://github.com/chenkui164/FastASR) for the C++ inference implementation of PaddleSpeech ASR.\n- Many thanks to [heyudage](https://github.com/heyudage)/[VoiceTyping](https://github.com/heyudage/VoiceTyping) for the real-time voice typing tool implementation of PaddleSpeech ASR streaming services.\n- Many thanks to [EscaticZheng](https://github.com/EscaticZheng)/[ps3.9wheel-install](https://github.com/EscaticZheng/ps3.9wheel-install) for the python3.9 prebuilt wheel for PaddleSpeech installation in Windows without Viusal Studio.\nBesides, PaddleSpeech depends on a lot of open source repositories. See [references](./docs/source/reference.md) for more information.\n- Many thanks to [chinobing](https://github.com/chinobing)/[FastAPI-PaddleSpeech-Audio-To-Text](https://github.com/chinobing/FastAPI-PaddleSpeech-Audio-To-Text) for converting audio to text based on FastAPI and PaddleSpeech.\n- Many thanks to [MistEO](https://github.com/MistEO)/[Pallas-Bot](https://github.com/MistEO/Pallas-Bot) for QQ bot based on PaddleSpeech TTS.\n\n<a name=\"License\"></a>\n## License\n\nPaddleSpeech is provided under the [Apache-2.0 License](./LICENSE).\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/PaddlePaddle/PaddleSpeech.svg)](https://starchart.cc/PaddlePaddle/PaddleSpeech)\n"
        },
        {
          "name": "README_cn.md",
          "type": "blob",
          "size": 47.4892578125,
          "content": "(ç®€ä½“ä¸­æ–‡|[English](./README.md))\n<p align=\"center\">\n  <img src=\"./docs/images/PaddleSpeech_logo.png\" />\n</p>\n\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-red.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleSpeech?color=ffa\"></a>\n    <a href=\"support os\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.8+-aff.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleSpeech?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleSpeech?color=3af\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleSpeech?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleSpeech/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?color=ccf\"></a>\n    <a href=\"=https://pypi.org/project/paddlespeech/\"><img src=\"https://img.shields.io/pypi/dm/PaddleSpeech\"></a>\n    <a href=\"=https://pypi.org/project/paddlespeech/\"><img src=\"https://static.pepy.tech/badge/paddlespeech\"></a>\n    <a href=\"https://huggingface.co/spaces\"><img src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue\"></a>\n</p>\n<div align=\"center\">  \n<h4>\n    <a href=\"#å®‰è£…\"> å®‰è£… </a>\n  | <a href=\"#å¿«é€Ÿå¼€å§‹\"> å¿«é€Ÿå¼€å§‹ </a>\n  | <a href=\"#æ•™ç¨‹æ–‡æ¡£\"> æ•™ç¨‹æ–‡æ¡£ </a>\n  | <a href=\"#æ¨¡å‹åˆ—è¡¨\"> æ¨¡å‹åˆ—è¡¨ </a>\n  | <a href=\"https://aistudio.baidu.com/aistudio/course/introduce/25130\"> AIStudio è¯¾ç¨‹ </a>\n  | <a href=\"https://arxiv.org/abs/2205.12007\"> NAACL2022 è®ºæ–‡ </a>\n  | <a href=\"https://gitee.com/paddlepaddle/PaddleSpeech\"> Gitee \n</h4>\n</div>\n\n\n------------------------------------------------------------------------------------\n\n**PaddleSpeech** æ˜¯åŸºäºé£æ¡¨ [PaddlePaddle](https://github.com/PaddlePaddle/Paddle) çš„è¯­éŸ³æ–¹å‘çš„å¼€æºæ¨¡å‹åº“ï¼Œç”¨äºè¯­éŸ³å’ŒéŸ³é¢‘ä¸­çš„å„ç§å…³é”®ä»»åŠ¡çš„å¼€å‘ï¼ŒåŒ…å«å¤§é‡åŸºäºæ·±åº¦å­¦ä¹ å‰æ²¿å’Œæœ‰å½±å“åŠ›çš„æ¨¡å‹ï¼Œä¸€äº›å…¸å‹çš„åº”ç”¨ç¤ºä¾‹å¦‚ä¸‹ï¼š\n\n**PaddleSpeech** è£è· [NAACL2022 Best Demo Award](https://2022.naacl.org/blog/best-demo-award/), è¯·è®¿é—® [Arxiv](https://arxiv.org/abs/2205.12007) è®ºæ–‡ã€‚\n  \n### æ•ˆæœå±•ç¤º\n\n##### è¯­éŸ³è¯†åˆ«\n\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> è¾“å…¥éŸ³é¢‘  </th>\n      <th width=\"550\"> è¯†åˆ«ç»“æœ </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200 style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td >I knocked at the door on the ancient side of the building.</td>\n    </tr>\n    <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td>æˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n##### è¯­éŸ³ç¿»è¯‘ (è‹±è¯‘ä¸­)\n\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> è¾“å…¥éŸ³é¢‘ </th>\n      <th width=\"550\"> ç¿»è¯‘ç»“æœ </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200 style=\"max-width: 100%;\"></a><br>\n      </td>\n      <td >æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n##### è¯­éŸ³åˆæˆ\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th width=\"550\">è¾“å…¥æ–‡æœ¬</th>\n      <th>åˆæˆéŸ³é¢‘</th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td >Life was like a box of chocolates, you never know what you're gonna get.</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/tacotron2_ljspeech_waveflow_samples_0.2/sentence_1.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td >æ—©ä¸Šå¥½ï¼Œä»Šå¤©æ˜¯2020/10/29ï¼Œæœ€ä½æ¸©åº¦æ˜¯-3Â°Cã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/parakeet_espnet_fs2_pwg_demo/tn_g2p/parakeet/001.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td >å­£å§¬å¯‚ï¼Œé›†é¸¡ï¼Œé¸¡å³æ£˜é¸¡ã€‚æ£˜é¸¡é¥¥å½ï¼Œå­£å§¬åŠç®•ç¨·æµé¸¡ã€‚é¸¡æ—¢æµï¼Œè·»å§¬ç¬ˆï¼Œå­£å§¬å¿Œï¼Œæ€¥å’­é¸¡ï¼Œé¸¡æ€¥ï¼Œç»§åœ¾å‡ ï¼Œå­£å§¬æ€¥ï¼Œå³ç±ç®•å‡»é¸¡ï¼Œç®•ç–¾å‡»å‡ ä¼ï¼Œä¼å³é½‘ï¼Œé¸¡å½é›†å‡ åŸºï¼Œå­£å§¬æ€¥æå±å‡»é¸¡ï¼Œé¸¡æ—¢æ®›ï¼Œå­£å§¬æ¿€ï¼Œå³è®°ã€Šå­£å§¬å‡»é¸¡è®°ã€‹ã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/jijiji.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ parrot è™šæ‹Ÿè€å¸ˆï¼Œæˆ‘ä»¬æ¥è¯»ä¸€é¦–è¯—ï¼Œæˆ‘ä¸æ˜¥é£çš†è¿‡å®¢ï¼ŒI and the spring breeze are passing byï¼Œä½ æºç§‹æ°´æ½æ˜Ÿæ²³ï¼Œyou take the autumn water to take the galaxyã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/labixiaoxin.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å®œå®¶å””ç³»äº‹å¿…è¦ä½ è®²ï¼Œä½†ç³»ä½ æ‰€è®²å˜…è¯´è¯å°†ä¼šå˜æˆå‘ˆå ‚è¯ä¾›ã€‚</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/chengtangzhenggong.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n    <tr>\n      <td>å„ä¸ªå›½å®¶æœ‰å„ä¸ªå›½å®¶å˜…å›½æ­Œ</td>\n      <td align = \"center\">\n      <a href=\"https://paddlespeech.bj.bcebos.com/Parakeet/docs/demos/gegege.wav\" rel=\"nofollow\">\n            <img align=\"center\" src=\"./docs/images/audio_icon.png\" width=\"200\" style=\"max-width: 100%;\"></a><br>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\næ›´å¤šåˆæˆéŸ³é¢‘ï¼Œå¯ä»¥å‚è€ƒ [PaddleSpeech è¯­éŸ³åˆæˆéŸ³é¢‘ç¤ºä¾‹](https://paddlespeech.readthedocs.io/en/latest/tts/demo.html)ã€‚\n\n##### æ ‡ç‚¹æ¢å¤\n<div align = \"center\">\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th width=\"390\"> è¾“å…¥æ–‡æœ¬ </th>\n      <th width=\"390\"> è¾“å‡ºæ–‡æœ¬ </th>\n    </tr>\n  </thead>\n  <tbody>\n   <tr>\n      <td>ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­</td>\n      <td>ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚</td>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n### ç‰¹æ€§\n\næœ¬é¡¹ç›®é‡‡ç”¨äº†æ˜“ç”¨ã€é«˜æ•ˆã€çµæ´»ä»¥åŠå¯æ‰©å±•çš„å®ç°ï¼Œæ—¨åœ¨ä¸ºå·¥ä¸šåº”ç”¨ã€å­¦æœ¯ç ”ç©¶æä¾›æ›´å¥½çš„æ”¯æŒï¼Œå®ç°çš„åŠŸèƒ½åŒ…å«è®­ç»ƒã€æ¨æ–­ä»¥åŠæµ‹è¯•æ¨¡å—ï¼Œä»¥åŠéƒ¨ç½²è¿‡ç¨‹ï¼Œä¸»è¦åŒ…æ‹¬\n- ğŸ“¦ **æ˜“ç”¨æ€§**: å®‰è£…é—¨æ§›ä½ï¼Œå¯ä½¿ç”¨ [CLI](#quick-start) å¿«é€Ÿå¼€å§‹ã€‚\n- ğŸ† **å¯¹æ ‡ SoTA**: æä¾›äº†é«˜é€Ÿã€è½»é‡çº§æ¨¡å‹ï¼Œä¸”å€Ÿé‰´äº†æœ€å‰æ²¿çš„æŠ€æœ¯ã€‚\n- ğŸ† **æµå¼ ASR å’Œ TTS ç³»ç»Ÿ**ï¼šå·¥ä¸šçº§çš„ç«¯åˆ°ç«¯æµå¼è¯†åˆ«ã€æµå¼åˆæˆç³»ç»Ÿã€‚\n- ğŸ’¯ **åŸºäºè§„åˆ™çš„ä¸­æ–‡å‰ç«¯**: æˆ‘ä»¬çš„å‰ç«¯åŒ…å«æ–‡æœ¬æ­£åˆ™åŒ–å’Œå­—éŸ³è½¬æ¢ï¼ˆG2Pï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå®šä¹‰è¯­è¨€è§„åˆ™æ¥é€‚åº”ä¸­æ–‡è¯­å¢ƒã€‚\n- **å¤šç§å·¥ä¸šç•Œä»¥åŠå­¦æœ¯ç•Œä¸»æµåŠŸèƒ½æ”¯æŒ**:\n  - ğŸ›ï¸ å…¸å‹éŸ³é¢‘ä»»åŠ¡: æœ¬å·¥å…·åŒ…æä¾›äº†éŸ³é¢‘ä»»åŠ¡å¦‚éŸ³é¢‘åˆ†ç±»ã€è¯­éŸ³ç¿»è¯‘ã€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ã€æ–‡æœ¬è½¬è¯­éŸ³ã€è¯­éŸ³åˆæˆã€å£°çº¹è¯†åˆ«ã€KWSç­‰ä»»åŠ¡çš„å®ç°ã€‚\n  - ğŸ”¬ ä¸»æµæ¨¡å‹åŠæ•°æ®é›†: æœ¬å·¥å…·åŒ…å®ç°äº†å‚ä¸æ•´æ¡è¯­éŸ³ä»»åŠ¡æµæ°´çº¿çš„å„ä¸ªæ¨¡å—ï¼Œå¹¶ä¸”é‡‡ç”¨äº†ä¸»æµæ•°æ®é›†å¦‚ LibriSpeechã€LJSpeechã€AIShellã€CSMSCï¼Œè¯¦æƒ…è¯·è§ [æ¨¡å‹åˆ—è¡¨](#model-list)ã€‚\n  - ğŸ§© çº§è”æ¨¡å‹åº”ç”¨: ä½œä¸ºä¼ ç»Ÿè¯­éŸ³ä»»åŠ¡çš„æ‰©å±•ï¼Œæˆ‘ä»¬ç»“åˆäº†è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰ä»»åŠ¡ï¼Œå®ç°æ›´æ¥è¿‘å®é™…éœ€æ±‚çš„äº§ä¸šçº§åº”ç”¨ã€‚\n\n### è¿‘æœŸæ›´æ–°\n- ğŸ‘‘ 2023.05.31: æ–°å¢ [WavLM ASR-en](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/librispeech/asr5), åŸºäºWavLMçš„è‹±è¯­è¯†åˆ«å¾®è°ƒï¼Œä½¿ç”¨LibriSpeechæ•°æ®é›†\n- ğŸ‰ 2023.05.18: æ–°å¢ [Squeezeformer](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/examples/aishell/asr1), ä½¿ç”¨Squeezeformerè¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨Aishellæ•°æ®é›†\n- ğŸ‘‘ 2023.05.04: æ–°å¢ [HuBERT ASR-en](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/examples/librispeech/asr4), åŸºäºHuBERTçš„è‹±è¯­è¯†åˆ«å¾®è°ƒï¼Œä½¿ç”¨LibriSpeechæ•°æ®é›†\n- âš¡ 2023.04.28: ä¿®æ­£ [0-d tensor](https://github.com/PaddlePaddle/PaddleSpeech/pull/3214), é…åˆPaddlePaddle2.5å‡çº§ä¿®æ”¹äº†0-d tensorçš„é—®é¢˜ã€‚\n- ğŸ‘‘ 2023.04.25: æ–°å¢ [U2 conformer çš„ AMP è®­ç»ƒ](https://github.com/PaddlePaddle/PaddleSpeech/pull/3167).\n- ğŸ‘‘ 2023.04.06: æ–°å¢ [srtæ ¼å¼å­—å¹•ç”ŸæˆåŠŸèƒ½](./demos/streaming_asr_server)ã€‚\n- ğŸ”¥ 2023.03.14: æ–°å¢åŸºäº Opencpop æ•°æ®é›†çš„ SVS (æ­Œå”±åˆæˆ) ç¤ºä¾‹ï¼ŒåŒ…å« [DiffSinger](./examples/opencpop/svs1)ã€[PWGAN](./examples/opencpop/voc1) å’Œ [HiFiGAN](./examples/opencpop/voc5)ï¼Œæ•ˆæœæŒç»­ä¼˜åŒ–ä¸­ã€‚\n- ğŸ‘‘ 2023.03.09: æ–°å¢ [Wav2vec2ASR-zh](./examples/aishell/asr3)ã€‚\n- ğŸ‰ 2023.03.07: æ–°å¢ [TTS ARM Linux C++ éƒ¨ç½²ç¤ºä¾‹ (åŒ…å« C++ ä¸­æ–‡æ–‡æœ¬å‰ç«¯æ¨¡å—)](./demos/TTSArmLinux)ã€‚\n- ğŸ”¥ 2023.03.03: æ–°å¢å£°éŸ³è½¬æ¢æ¨¡å‹ [StarGANv2-VC åˆæˆæµç¨‹](./examples/vctk/vc3)ã€‚\n- ğŸ‰ 2023.02.16: æ–°å¢[ç²¤è¯­è¯­éŸ³åˆæˆ](./examples/canton/tts3)ã€‚\n- ğŸ”¥ 2023.01.10: æ–°å¢[ä¸­è‹±æ··åˆ ASR CLI å’Œ Demos](./demos/speech_recognition)ã€‚\n- ğŸ‘‘ 2023.01.06: æ–°å¢ [ASR ä¸­è‹±æ··åˆ tal_cs è®­ç»ƒæ¨ç†æµç¨‹](./examples/tal_cs/asr1/)ã€‚\n- ğŸ‰ 2022.12.02: æ–°å¢[ç«¯åˆ°ç«¯éŸµå¾‹é¢„æµ‹å…¨æµç¨‹](./examples/csmsc/tts3_rhy) (åŒ…å«åœ¨å£°å­¦æ¨¡å‹ä¸­ä½¿ç”¨éŸµå¾‹æ ‡ç­¾)ã€‚\n- ğŸ‰ 2022.11.30: æ–°å¢ [TTS Android éƒ¨ç½²ç¤ºä¾‹](./demos/TTSAndroid)ã€‚\n- ğŸ¤— 2022.11.28: PP-TTS and PP-ASR ç¤ºä¾‹å¯åœ¨ [AIStudio](https://aistudio.baidu.com/aistudio/modelsoverview) å’Œ[é£æ¡¨å®˜ç½‘](https://www.paddlepaddle.org.cn/models)ä½“éªŒï¼\n- ğŸ‘‘ 2022.11.18: æ–°å¢ [Whisper CLI å’Œ Demos](https://github.com/PaddlePaddle/PaddleSpeech/pull/2640), æ”¯æŒå¤šç§è¯­è¨€çš„è¯†åˆ«ä¸ç¿»è¯‘ã€‚\n- ğŸ”¥ 2022.11.18: æ–°å¢ [Wav2vec2 CLI å’Œ Demos](./demos/speech_ssl), æ”¯æŒ ASR å’Œç‰¹å¾æå–ã€‚\n- ğŸ‰ 2022.11.17: TTS æ–°å¢[é«˜è´¨é‡ç”·æ€§éŸ³è‰²](https://github.com/PaddlePaddle/PaddleSpeech/pull/2660)ã€‚\n- ğŸ”¥ 2022.11.07: æ–°å¢ [U2/U2++ é«˜æ€§èƒ½æµå¼ ASR C++ éƒ¨ç½²](./speechx/examples/u2pp_ol/wenetspeech)ã€‚\n- ğŸ‘‘ 2022.11.01: [ä¸­è‹±æ–‡æ··åˆ TTS](./examples/zh_en_tts/tts3) æ–°å¢ [Adversarial Loss](https://arxiv.org/pdf/1907.04448.pdf) æ¨¡å—ã€‚\n- ğŸ”¥ 2022.10.26: TTS æ–°å¢[éŸµå¾‹é¢„æµ‹](./develop/examples/other/rhy)åŠŸèƒ½ã€‚\n- ğŸ‰ 2022.10.21: TTS ä¸­æ–‡æ–‡æœ¬å‰ç«¯æ–°å¢ [SSML](https://github.com/PaddlePaddle/PaddleSpeech/discussions/2538) åŠŸèƒ½ã€‚\n- ğŸ‘‘ 2022.10.11: æ–°å¢ [Wav2vec2ASR-en](./examples/librispeech/asr3), åœ¨ LibriSpeech ä¸Šé’ˆå¯¹ ASR ä»»åŠ¡å¯¹ wav2vec2.0 çš„ finetuningã€‚\n- ğŸ”¥ 2022.09.26: æ–°å¢ Voice Cloning, TTS finetune å’Œ [ERNIE-SAT](https://arxiv.org/abs/2211.03545) åˆ° [PaddleSpeech ç½‘é¡µåº”ç”¨](./demos/speech_web)ã€‚\n- âš¡ 2022.09.09: æ–°å¢åŸºäº ECAPA-TDNN å£°çº¹æ¨¡å‹çš„ AISHELL-3 Voice Cloning [ç¤ºä¾‹](./examples/aishell3/vc2)ã€‚\n- âš¡ 2022.08.25: å‘å¸ƒ TTS [finetune](./examples/other/tts_finetune/tts3) ç¤ºä¾‹ã€‚\n- ğŸ”¥ 2022.08.22: æ–°å¢ [ERNIE-SAT](https://arxiv.org/abs/2211.03545) æ¨¡å‹: [ERNIE-SAT-vctk](./examples/vctk/ernie_sat)ã€[ERNIE-SAT-aishell3](./examples/aishell3/ernie_sat)ã€[ERNIE-SAT-zh_en](./examples/aishell3_vctk/ernie_sat)ã€‚\n- ğŸ”¥ 2022.08.15: å°† [g2pW](https://github.com/GitYCC/g2pW) å¼•å…¥ TTS ä¸­æ–‡æ–‡æœ¬å‰ç«¯ã€‚\n- ğŸ”¥ 2022.08.09: å‘å¸ƒ[ä¸­è‹±æ–‡æ··åˆ TTS](./examples/zh_en_tts/tts3)ã€‚\n- âš¡ 2022.08.03: TTS CLI æ–°å¢ ONNXRuntime æ¨ç†æ–¹å¼ã€‚\n- ğŸ‰ 2022.07.18: å‘å¸ƒ VITS æ¨¡å‹: [VITS-csmsc](./examples/csmsc/vits)ã€[VITS-aishell3](./examples/aishell3/vits)ã€[VITS-VC](./examples/aishell3/vits-vc)ã€‚\n- ğŸ‰ 2022.06.22: æ‰€æœ‰ TTS æ¨¡å‹æ”¯æŒäº† ONNX æ ¼å¼ã€‚\n- ğŸ€ 2022.06.17: æ–°å¢ [PaddleSpeech ç½‘é¡µåº”ç”¨](./demos/speech_web)ã€‚\n- ğŸ‘‘ 2022.05.13: PaddleSpeech å‘å¸ƒ [PP-ASR](./docs/source/asr/PPASR_cn.md) æµå¼è¯­éŸ³è¯†åˆ«ç³»ç»Ÿã€[PP-TTS](./docs/source/tts/PPTTS_cn.md) æµå¼è¯­éŸ³åˆæˆç³»ç»Ÿã€[PP-VPR](docs/source/vpr/PPVPR_cn.md) å…¨é“¾è·¯å£°çº¹è¯†åˆ«ç³»ç»Ÿ\n- ğŸ‘ğŸ» 2022.05.06: PaddleSpeech Streaming Server ä¸Šçº¿ï¼è¦†ç›–äº†è¯­éŸ³è¯†åˆ«ï¼ˆæ ‡ç‚¹æ¢å¤ã€æ—¶é—´æˆ³ï¼‰å’Œè¯­éŸ³åˆæˆã€‚\n- ğŸ‘ğŸ» 2022.05.06: PaddleSpeech Server ä¸Šçº¿ï¼è¦†ç›–äº†å£°éŸ³åˆ†ç±»ã€è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆã€å£°çº¹è¯†åˆ«ï¼Œæ ‡ç‚¹æ¢å¤ã€‚\n- ğŸ‘ğŸ» 2022.03.28: PaddleSpeech CLI è¦†ç›–å£°éŸ³åˆ†ç±»ã€è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³ç¿»è¯‘ï¼ˆè‹±è¯‘ä¸­ï¼‰ã€è¯­éŸ³åˆæˆå’Œå£°çº¹éªŒè¯ã€‚\n- ğŸ‘ğŸ» 2021.12.10: PaddleSpeech CLI æ”¯æŒè¯­éŸ³åˆ†ç±», è¯­éŸ³è¯†åˆ«, è¯­éŸ³ç¿»è¯‘ï¼ˆè‹±è¯‘ä¸­ï¼‰å’Œè¯­éŸ³åˆæˆã€‚\n\n\n ### ğŸ”¥ åŠ å…¥æŠ€æœ¯äº¤æµç¾¤è·å–å…¥ç¾¤ç¦åˆ©\n\n - 3 æ—¥ç›´æ’­è¯¾é“¾æ¥: æ·±åº¦è§£è¯» ã€ä¸€å¥è¯è¯­éŸ³åˆæˆã€‘ã€å°æ ·æœ¬è¯­éŸ³åˆæˆã€‘ã€å®šåˆ¶åŒ–è¯­éŸ³è¯†åˆ«ã€‘è¯­éŸ³äº¤äº’æŠ€æœ¯\n - 20G å­¦ä¹ å¤§ç¤¼åŒ…ï¼šè§†é¢‘è¯¾ç¨‹ã€å‰æ²¿è®ºæ–‡ä¸å­¦ä¹ èµ„æ–™\n  \nå¾®ä¿¡æ‰«æäºŒç»´ç å…³æ³¨å…¬ä¼—å·ï¼Œç‚¹å‡»â€œé©¬ä¸ŠæŠ¥åâ€å¡«å†™é—®å·åŠ å…¥å®˜æ–¹äº¤æµç¾¤ï¼Œè·å¾—æ›´é«˜æ•ˆçš„é—®é¢˜ç­”ç–‘ï¼Œä¸å„è¡Œå„ä¸šå¼€å‘è€…å……åˆ†äº¤æµï¼ŒæœŸå¾…æ‚¨çš„åŠ å…¥ã€‚\n\n<div align=\"center\">\n<img src=\"https://user-images.githubusercontent.com/30135920/212860467-9e943cc3-8be8-49a4-97fd-7c94aad8e979.jpg\"  width = \"200\"  />\n</div>\n\n<a name=\"å®‰è£…\"></a>\n## å®‰è£…\n\næˆ‘ä»¬å¼ºçƒˆå»ºè®®ç”¨æˆ·åœ¨ **Linux** ç¯å¢ƒä¸‹ï¼Œ*3.8* ä»¥ä¸Šç‰ˆæœ¬çš„ *python* ä¸Šå®‰è£… PaddleSpeechã€‚åŒæ—¶ï¼Œæœ‰ä¸€äº›Paddleæ–°ç‰ˆæœ¬çš„å†…å®¹æ²¡æœ‰åœ¨åšé€‚é…çš„æ”¯æŒï¼Œå› æ­¤ç›®å‰åªèƒ½ä½¿ç”¨2.5.1åŠä¹‹å‰çš„ç‰ˆæœ¬ã€‚\n\n### ç›¸å…³ä¾èµ–\n+ gcc >= 4.8.5\n+ paddlepaddle <= 2.5.1\n+ python >= 3.8\n+ linux(æ¨è), mac, windows\n\nPaddleSpeech ä¾èµ–äº paddlepaddleï¼Œå®‰è£…å¯ä»¥å‚è€ƒ[ paddlepaddle å®˜ç½‘](https://www.paddlepaddle.org.cn/)ï¼Œæ ¹æ®è‡ªå·±æœºå™¨çš„æƒ…å†µè¿›è¡Œé€‰æ‹©ã€‚è¿™é‡Œç»™å‡º cpu ç‰ˆæœ¬ç¤ºä¾‹ï¼Œå…¶å®ƒç‰ˆæœ¬å¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±æœºå™¨çš„æƒ…å†µè¿›è¡Œå®‰è£…ã€‚\n\n```shell\npip install paddlepaddle -i https://mirror.baidu.com/pypi/simple\n```\nä½ ä¹Ÿå¯ä»¥å®‰è£…æŒ‡å®šç‰ˆæœ¬çš„paddlepaddleï¼Œæˆ–è€…å®‰è£… develop ç‰ˆæœ¬ã€‚\n```bash\n# å®‰è£…2.4.1ç‰ˆæœ¬. æ³¨æ„ï¼š2.4.1åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯·æŒ‰ç…§å¯¹paddlepaddleçš„æœ€å°ä¾èµ–è¿›è¡Œé€‰æ‹©ã€‚\npip install paddlepaddle==2.4.1 -i https://mirror.baidu.com/pypi/simple\n# å®‰è£… develop ç‰ˆæœ¬\npip install paddlepaddle==0.0.0 -f https://www.paddlepaddle.org.cn/whl/linux/cpu-mkl/develop.html\n```\nPaddleSpeech å¿«é€Ÿå®‰è£…æ–¹å¼æœ‰ä¸¤ç§ï¼Œä¸€ç§æ˜¯ pip å®‰è£…ï¼Œä¸€ç§æ˜¯æºç ç¼–è¯‘ï¼ˆæ¨èï¼‰ã€‚\n\n### pip å®‰è£…\n```shell\npip install pytest-runner\npip install paddlespeech\n```\n\n### æºç ç¼–è¯‘\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleSpeech.git\ncd PaddleSpeech\npip install pytest-runner\npip install .\n```\n\næ›´å¤šå…³äºå®‰è£…é—®é¢˜ï¼Œå¦‚ conda ç¯å¢ƒï¼Œlibrosa ä¾èµ–çš„ç³»ç»Ÿåº“ï¼Œgcc ç¯å¢ƒé—®é¢˜ï¼Œkaldi å®‰è£…ç­‰ï¼Œå¯ä»¥å‚è€ƒè¿™ç¯‡[å®‰è£…æ–‡æ¡£](docs/source/install_cn.md)ï¼Œå¦‚å®‰è£…ä¸Šé‡åˆ°é—®é¢˜å¯ä»¥åœ¨ [#2150](https://github.com/PaddlePaddle/PaddleSpeech/issues/2150) ä¸Šç•™è¨€ä»¥åŠæŸ¥æ‰¾ç›¸å…³é—®é¢˜\n\n<a name=\"å¿«é€Ÿå¼€å§‹\"></a>\n## å¿«é€Ÿå¼€å§‹\nå®‰è£…å®Œæˆåï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œæˆ–è€… Python å¿«é€Ÿå¼€å§‹ï¼Œå‘½ä»¤è¡Œæ¨¡å¼ä¸‹æ”¹å˜ `--input` å¯ä»¥å°è¯•ç”¨è‡ªå·±çš„éŸ³é¢‘æˆ–æ–‡æœ¬æµ‹è¯•ï¼Œæ”¯æŒ 16k wav æ ¼å¼éŸ³é¢‘ã€‚\n\nä½ ä¹Ÿå¯ä»¥åœ¨ `aistudio` ä¸­å¿«é€Ÿä½“éªŒ ğŸ‘‰ğŸ»[ä¸€é”®é¢„æµ‹ï¼Œå¿«é€Ÿä¸Šæ‰‹ Speech å¼€å‘ä»»åŠ¡](https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&shared=1&ts=1660878142250)ã€‚\n\næµ‹è¯•éŸ³é¢‘ç¤ºä¾‹ä¸‹è½½\n```shell\nwget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/zh.wav\nwget -c https://paddlespeech.bj.bcebos.com/PaddleAudio/en.wav\n```\n\n### è¯­éŸ³è¯†åˆ«\n<details><summary>&emsp;ï¼ˆç‚¹å‡»å¯å±•å¼€ï¼‰å¼€æºä¸­æ–‡è¯­éŸ³è¯†åˆ«</summary>\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech asr --lang zh --input zh.wav\n```\n\nPython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.asr.infer import ASRExecutor\n>>> asr = ASRExecutor()\n>>> result = asr(audio_file=\"zh.wav\")\n>>> print(result)\næˆ‘è®¤ä¸ºè·‘æ­¥æœ€é‡è¦çš„å°±æ˜¯ç»™æˆ‘å¸¦æ¥äº†èº«ä½“å¥åº·\n```\n</details>\n\n### è¯­éŸ³åˆæˆ\n\n<details><summary>&emsp;å¼€æºä¸­æ–‡è¯­éŸ³åˆæˆ</summary>\n\nè¾“å‡º 24k é‡‡æ ·ç‡wavæ ¼å¼éŸ³é¢‘\n\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech tts --input \"ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼\" --output output.wav\n```\n\nPython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.tts.infer import TTSExecutor\n>>> tts = TTSExecutor()\n>>> tts(text=\"ä»Šå¤©å¤©æ°”ååˆ†ä¸é”™ã€‚\", output=\"output.wav\")\n```\n- è¯­éŸ³åˆæˆçš„ web demo å·²ç»é›†æˆè¿›äº† [Huggingface Spaces](https://huggingface.co/spaces). è¯·å‚è€ƒ: [TTS Demo](https://huggingface.co/spaces/KPatrick/PaddleSpeechTTS)\n\n</details>\n\n### å£°éŸ³åˆ†ç±»   \n\n<details><summary>&emsp;é€‚é…å¤šåœºæ™¯çš„å¼€æ”¾é¢†åŸŸå£°éŸ³åˆ†ç±»å·¥å…·</summary>\n\nåŸºäº AudioSet æ•°æ®é›† 527 ä¸ªç±»åˆ«çš„å£°éŸ³åˆ†ç±»æ¨¡å‹\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech cls --input zh.wav\n```\n\npython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.cls.infer import CLSExecutor\n>>> cls = CLSExecutor()\n>>> result = cls(audio_file=\"zh.wav\")\n>>> print(result)\nSpeech 0.9027186632156372\n```\n\n</details>\n\n### å£°çº¹æå–\n\n<details><summary>&emsp;å·¥ä¸šçº§å£°çº¹æå–å·¥å…·</summary>\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech vector --task spk --input zh.wav\n```\n\nPython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.vector import VectorExecutor\n>>> vec = VectorExecutor()\n>>> result = vec(audio_file=\"zh.wav\")\n>>> print(result) # 187ç»´å‘é‡\n[ -0.19083306   9.474295   -14.122263    -2.0916545    0.04848729\n   4.9295826    1.4780062    0.3733844   10.695862     3.2697146\n  -4.48199     -0.6617882   -9.170393   -11.1568775   -1.2358263 ...]\n```\n\n</details>\n\n### æ ‡ç‚¹æ¢å¤ \n\n<details><summary>&emsp;ä¸€é”®æ¢å¤æ–‡æœ¬æ ‡ç‚¹ï¼Œå¯ä¸ASRæ¨¡å‹é…åˆä½¿ç”¨</summary>\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech text --task punc --input ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­\n```\n\nPython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.text.infer import TextExecutor\n>>> text_punc = TextExecutor()\n>>> result = text_punc(text=\"ä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šä½ ä¸‹åˆæœ‰ç©ºå—æˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­\")\nä»Šå¤©çš„å¤©æ°”çœŸä¸é”™å•Šï¼ä½ ä¸‹åˆæœ‰ç©ºå—ï¼Ÿæˆ‘æƒ³çº¦ä½ ä¸€èµ·å»åƒé¥­ã€‚\n```\n\n</details>\n\n### è¯­éŸ³ç¿»è¯‘\n\n<details><summary>&emsp;ç«¯åˆ°ç«¯è‹±è¯‘ä¸­è¯­éŸ³ç¿»è¯‘å·¥å…·</summary>\n\nä½¿ç”¨é¢„ç¼–è¯‘çš„ kaldi ç›¸å…³å·¥å…·ï¼Œåªæ”¯æŒåœ¨ Ubuntu ç³»ç»Ÿä¸­ä½“éªŒ\n\nå‘½ä»¤è¡Œä¸€é”®ä½“éªŒ\n\n```shell\npaddlespeech st --input en.wav\n```\n\npython API ä¸€é”®é¢„æµ‹\n\n```python\n>>> from paddlespeech.cli.st.infer import STExecutor\n>>> st = STExecutor()\n>>> result = st(audio_file=\"en.wav\")\n['æˆ‘ åœ¨ è¿™æ ‹ å»ºç­‘ çš„ å¤è€ é—¨ä¸Š æ•²é—¨ ã€‚']\n```\n\n</details>\n\n\n<a name=\"å¿«é€Ÿä½¿ç”¨æœåŠ¡\"></a>\n## å¿«é€Ÿä½¿ç”¨æœåŠ¡\nå®‰è£…å®Œæˆåï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œä¸€é”®å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼Œè¯­éŸ³åˆæˆï¼ŒéŸ³é¢‘åˆ†ç±»ç­‰å¤šç§æœåŠ¡ã€‚\n\nä½ å¯ä»¥åœ¨ AI Studio ä¸­å¿«é€Ÿä½“éªŒï¼š[SpeechServer ä¸€é”®éƒ¨ç½²](https://aistudio.baidu.com/aistudio/projectdetail/4354592?sUid=2470186&shared=1&ts=1660878208266)\n\n**å¯åŠ¨æœåŠ¡**     \n```shell\npaddlespeech_server start --config_file ./demos/speech_server/conf/application.yaml\n```\n\n**è®¿é—®è¯­éŸ³è¯†åˆ«æœåŠ¡**     \n```shell\npaddlespeech_client asr --server_ip 127.0.0.1 --port 8090 --input input_16k.wav\n```\n\n**è®¿é—®è¯­éŸ³åˆæˆæœåŠ¡**     \n```shell\npaddlespeech_client tts --server_ip 127.0.0.1 --port 8090 --input \"æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚\" --output output.wav\n```\n\n**è®¿é—®éŸ³é¢‘åˆ†ç±»æœåŠ¡**     \n```shell\npaddlespeech_client cls --server_ip 127.0.0.1 --port 8090 --input input.wav\n```\n\næ›´å¤šæœåŠ¡ç›¸å…³çš„å‘½ä»¤è¡Œä½¿ç”¨ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [demos](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/demos/speech_server)\n\n<a name=\"å¿«é€Ÿä½¿ç”¨æµå¼æœåŠ¡\"></a>\n## å¿«é€Ÿä½¿ç”¨æµå¼æœåŠ¡\n\nå¼€å‘è€…å¯ä»¥å°è¯• [æµå¼ ASR](./demos/streaming_asr_server/README.md) å’Œ [æµå¼ TTS](./demos/streaming_tts_server/README.md) æœåŠ¡.\n\n**å¯åŠ¨æµå¼ ASR æœåŠ¡**\n\n```\npaddlespeech_server start --config_file ./demos/streaming_asr_server/conf/application.yaml\n```\n\n**è®¿é—®æµå¼ ASR æœåŠ¡**     \n\n```\npaddlespeech_client asr_online --server_ip 127.0.0.1 --port 8090 --input input_16k.wav\n```\n\n**å¯åŠ¨æµå¼ TTS æœåŠ¡**\n\n```\npaddlespeech_server start --config_file ./demos/streaming_tts_server/conf/tts_online_application.yaml\n```\n\n**è®¿é—®æµå¼ TTS æœåŠ¡**     \n\n```\npaddlespeech_client tts_online --server_ip 127.0.0.1 --port 8092 --protocol http --input \"æ‚¨å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ç™¾åº¦é£æ¡¨è¯­éŸ³åˆæˆæœåŠ¡ã€‚\" --output output.wav\n```\n\næ›´å¤šä¿¡æ¯å‚çœ‹ï¼š [æµå¼ ASR](./demos/streaming_asr_server/README.md) å’Œ [æµå¼ TTS](./demos/streaming_tts_server/README.md) \n\n<a name=\"æ¨¡å‹åˆ—è¡¨\"></a>\n## æ¨¡å‹åˆ—è¡¨\nPaddleSpeech æ”¯æŒå¾ˆå¤šä¸»æµçš„æ¨¡å‹ï¼Œå¹¶æä¾›äº†é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¦æƒ…è¯·è§[æ¨¡å‹åˆ—è¡¨](./docs/source/released_model.md)ã€‚\n\n<a name=\"è¯­éŸ³è¯†åˆ«æ¨¡å‹\"></a>\n\nPaddleSpeech çš„ **è¯­éŸ³è½¬æ–‡æœ¬** åŒ…å«è¯­éŸ³è¯†åˆ«å£°å­¦æ¨¡å‹ã€è¯­éŸ³è¯†åˆ«è¯­è¨€æ¨¡å‹å’Œè¯­éŸ³ç¿»è¯‘, è¯¦æƒ…å¦‚ä¸‹ï¼š\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th>è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å—ç±»å‹</th>\n      <th>æ•°æ®é›†</th>\n      <th>æ¨¡å‹ç±»å‹</th>\n      <th>è„šæœ¬</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td rowspan=\"4\">è¯­éŸ³è¯†åˆ«</td>\n      <td rowspan=\"2\" >Aishell</td>\n      <td >DeepSpeech2 RNN + Conv based Models</td>\n      <td>\n      <a href = \"./examples/aishell/asr0\">deepspeech2-aishell</a>\n      </td>\n    </tr>\n    <tr>\n      <td>Transformer based Attention Models </td>\n      <td>\n      <a href = \"./examples/aishell/asr1\">u2.transformer.conformer-aishell</a>\n      </td>\n    </tr>\n      <tr>\n      <td> Librispeech</td>\n      <td>Transformer based Attention Models </td>\n      <td>\n      <a href = \"./examples/librispeech/asr0\">deepspeech2-librispeech</a> / <a href = \"./examples/librispeech/asr1\">transformer.conformer.u2-librispeech</a>  / <a href = \"./examples/librispeech/asr2\">transformer.conformer.u2-kaldi-librispeech</a>\n      </td>\n      </td>\n    </tr>\n    <tr>\n      <td>TIMIT</td>\n      <td>Unified Streaming & Non-streaming Two-pass</td>\n      <td>\n    <a href = \"./examples/timit/asr1\"> u2-timit</a>\n      </td>\n    </tr>\n  <tr>\n  <td>å¯¹é½</td>\n  <td>THCHS30</td>\n  <td>MFA</td>\n  <td>\n  <a href = \".examples/thchs30/align0\">mfa-thchs30</a>\n  </td>\n  </tr>\n   <tr>\n      <td rowspan=\"1\">è¯­è¨€æ¨¡å‹</td>\n      <td colspan = \"2\">Ngram è¯­è¨€æ¨¡å‹</td>\n      <td>\n      <a href = \"./examples/other/ngram_lm\">kenlm</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"2\">è¯­éŸ³ç¿»è¯‘ï¼ˆè‹±è¯‘ä¸­ï¼‰</td> \n      <td rowspan=\"2\">TED En-Zh</td>\n      <td>Transformer + ASR MTL</td>\n      <td>\n      <a href = \"./examples/ted_en_zh/st0\">transformer-ted</a>\n      </td>\n  </tr>\n  <tr>\n      <td>FAT + Transformer + ASR MTL</td>\n      <td>\n      <a href = \"./examples/ted_en_zh/st1\">fat-st-ted</a>\n      </td>\n  </tr>\n  </tbody>\n</table>\n\n<a name=\"è¯­éŸ³åˆæˆæ¨¡å‹\"></a>\n\nPaddleSpeech çš„ **è¯­éŸ³åˆæˆ** ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šæ–‡æœ¬å‰ç«¯ã€å£°å­¦æ¨¡å‹å’Œå£°ç å™¨ã€‚å£°å­¦æ¨¡å‹å’Œå£°ç å™¨æ¨¡å‹å¦‚ä¸‹ï¼š\n\n<table>\n  <thead>\n    <tr>\n      <th> è¯­éŸ³åˆæˆæ¨¡å—ç±»å‹ </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> æ•°æ®é›†  </th>\n      <th> è„šæœ¬  </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n    <td> æ–‡æœ¬å‰ç«¯</td>\n    <td colspan=\"2\"> &emsp; </td>\n    <td>\n    <a href = \"./examples/other/tn\">tn</a> / <a href = \"./examples/other/g2p\">g2p</a>\n    </td>\n   </tr>\n   <tr>\n      <td rowspan=\"6\">å£°å­¦æ¨¡å‹</td>\n      <td>Tacotron2</td>\n      <td>LJSpeech / CSMSC</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts0\">tacotron2-ljspeech</a> / <a href = \"./examples/csmsc/tts0\">tacotron2-csmsc</a>\n      </td>\n   </tr>\n   <tr>\n      <td>Transformer TTS</td>\n      <td>LJSpeech</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts1\">transformer-ljspeech</a>\n      </td>\n   </tr>\n   <tr>\n      <td>SpeedySpeech</td>\n      <td>CSMSC</td>\n      <td >\n      <a href = \"./examples/csmsc/tts2\">speedyspeech-csmsc</a>\n      </td>\n   </tr>\n   <tr>\n      <td>FastSpeech2</td>\n      <td>LJSpeech / VCTK / CSMSC / AISHELL-3 / ZH_EN / finetune</td>\n      <td>\n      <a href = \"./examples/ljspeech/tts3\">fastspeech2-ljspeech</a> / <a href = \"./examples/vctk/tts3\">fastspeech2-vctk</a> / <a href = \"./examples/csmsc/tts3\">fastspeech2-csmsc</a> / <a href = \"./examples/aishell3/tts3\">fastspeech2-aishell3</a> / <a href = \"./examples/zh_en_tts/tts3\">fastspeech2-zh_en</a> / <a href = \"./examples/other/tts_finetune/tts3\">fastspeech2-finetune</a>\n      </td>\n   </tr>\n   <tr>\n      <td><a href = \"https://arxiv.org/abs/2211.03545\">ERNIE-SAT</a></td>\n      <td>VCTK / AISHELL-3 / ZH_EN</td>\n      <td>\n      <a href = \"./examples/vctk/ernie_sat\">ERNIE-SAT-vctk</a> / <a href = \"./examples/aishell3/ernie_sat\">ERNIE-SAT-aishell3</a> / <a href = \"./examples/aishell3_vctk/ernie_sat\">ERNIE-SAT-zh_en</a>\n      </td>\n   </tr>\n   <tr>\n      <td>DiffSinger</td>\n      <td>Opencpop</td>\n      <td>\n      <a href = \"./examples/opencpop/svs1\">DiffSinger-opencpop</a>\n      </td>\n   </tr>\n   <tr>\n      <td rowspan=\"6\">å£°ç å™¨</td>\n      <td >WaveFlow</td>\n      <td >LJSpeech</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc0\">waveflow-ljspeech</a>\n      </td>\n    </tr>\n    <tr>\n      <td >Parallel WaveGAN</td>\n      <td >LJSpeech / VCTK / CSMSC / AISHELL-3 / Opencpop</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc1\">PWGAN-ljspeech</a> / <a href = \"./examples/vctk/voc1\">PWGAN-vctk</a> / <a href = \"./examples/csmsc/voc1\">PWGAN-csmsc</a> /  <a href = \"./examples/aishell3/voc1\">PWGAN-aishell3</a> / <a href = \"./examples/opencpop/voc1\">PWGAN-opencpop</a>\n      </td>\n    </tr>\n    <tr>\n      <td >Multi Band MelGAN</td>\n      <td >CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc3\">Multi Band MelGAN-csmsc</a> \n      </td>\n    </tr>\n    <tr>\n      <td >Style MelGAN</td>\n      <td >CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc4\">Style MelGAN-csmsc</a> \n      </td>\n    </tr>\n    <tr>\n      <td >HiFiGAN</td>\n      <td >LJSpeech / VCTK / CSMSC / AISHELL-3 / Opencpop</td>\n      <td>\n      <a href = \"./examples/ljspeech/voc5\">HiFiGAN-ljspeech</a> / <a href = \"./examples/vctk/voc5\">HiFiGAN-vctk</a> / <a href = \"./examples/csmsc/voc5\">HiFiGAN-csmsc</a> / <a href = \"./examples/aishell3/voc5\">HiFiGAN-aishell3</a> / <a href = \"./examples/opencpop/voc5\">HiFiGAN-opencpop</a>\n      </td>\n    </tr>\n    <tr>\n      <td >WaveRNN</td>\n      <td >CSMSC</td>\n      <td>\n      <a href = \"./examples/csmsc/voc6\">WaveRNN-csmsc</a>\n      </td>\n    </tr>\n    <tr>\n      <td rowspan=\"5\">å£°éŸ³å…‹éš†</td>\n      <td>GE2E</td>\n      <td >Librispeech, etc.</td>\n      <td>\n      <a href = \"./examples/other/ge2e\">GE2E</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (GE2E + Tacotron2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc0\">VC0</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (GE2E + FastSpeech2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc1\">VC1</a>\n      </td>\n    </tr>\n    <tr>\n      <td>SV2TTS (ECAPA-TDNN + FastSpeech2)</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vc2\">VC2</a>\n      </td>\n    </tr>\n    <tr>\n      <td>GE2E + VITS</td>\n      <td>AISHELL-3</td>\n      <td>\n      <a href = \"./examples/aishell3/vits-vc\">VITS-VC</a>\n      </td>\n    </tr>\n     <tr>\n      <td rowspan=\"3\">ç«¯åˆ°ç«¯</td>\n      <td>VITS</td>\n      <td>CSMSC / AISHELL-3</td>\n      <td>\n      <a href = \"./examples/csmsc/vits\">VITS-csmsc</a> / <a href = \"./examples/aishell3/vits\">VITS-aishell3</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n<a name=\"å£°éŸ³åˆ†ç±»æ¨¡å‹\"></a>\n**å£°éŸ³åˆ†ç±»**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> ä»»åŠ¡ </th>\n      <th> æ•°æ®é›† </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> è„šæœ¬</th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>å£°éŸ³åˆ†ç±»</td>\n      <td>ESC-50</td>\n      <td>PANN</td>\n      <td>\n      <a href = \"./examples/esc50/cls0\">pann-esc50</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n\n<a name=\"è¯­éŸ³å”¤é†’æ¨¡å‹\"></a>\n\n**è¯­éŸ³å”¤é†’**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> ä»»åŠ¡ </th>\n      <th> æ•°æ®é›† </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> è„šæœ¬ </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>è¯­éŸ³å”¤é†’</td>\n      <td>hey-snips</td>\n      <td>MDTC</td>\n      <td>\n      <a href = \"./examples/hey_snips/kws0\">mdtc-hey-snips</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"å£°çº¹è¯†åˆ«æ¨¡å‹\"></a>\n\n**å£°çº¹è¯†åˆ«**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> ä»»åŠ¡ </th>\n      <th> æ•°æ®é›† </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> è„šæœ¬ </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>å£°çº¹è¯†åˆ«</td>\n      <td>VoxCeleb1/2</td>\n      <td>ECAPA-TDNN</td>\n      <td>\n      <a href = \"./examples/voxceleb/sv0\">ecapa-tdnn-voxceleb12</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"è¯´è¯äººæ—¥å¿—æ¨¡å‹\"></a>\n\n**è¯´è¯äººæ—¥å¿—**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> ä»»åŠ¡ </th>\n      <th> æ•°æ®é›† </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> è„šæœ¬ </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>è¯´è¯äººæ—¥å¿—</td>\n      <td>AMI</td>\n      <td>ECAPA-TDNN + AHC / SC</td>\n      <td>\n      <a href = \"./examples/ami/sd0\">ecapa-tdnn-ami</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"æ ‡ç‚¹æ¢å¤æ¨¡å‹\"></a>\n\n**æ ‡ç‚¹æ¢å¤**\n\n<table style=\"width:100%\">\n  <thead>\n    <tr>\n      <th> ä»»åŠ¡ </th>\n      <th> æ•°æ®é›† </th>\n      <th> æ¨¡å‹ç±»å‹ </th>\n      <th> è„šæœ¬ </th>\n    </tr>\n  </thead>\n  <tbody>\n  <tr>\n      <td>æ ‡ç‚¹æ¢å¤</td>\n      <td>IWLST2012_zh</td>\n      <td>Ernie Linear</td>\n      <td>\n      <a href = \"./examples/iwslt2012/punc0\">iwslt2012-punc0</a>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n<a name=\"æ•™ç¨‹æ–‡æ¡£\"></a>\n## æ•™ç¨‹æ–‡æ¡£\n\nå¯¹äº PaddleSpeech çš„æ‰€å…³æ³¨çš„ä»»åŠ¡ï¼Œä»¥ä¸‹æŒ‡å—æœ‰åŠ©äºå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå…¥é—¨ï¼Œäº†è§£è¯­éŸ³ç›¸å…³æ ¸å¿ƒæ€æƒ³ã€‚\n\n- [ä¸‹è½½å®‰è£…](./docs/source/install_cn.md)\n- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)\n- NotebookåŸºç¡€æ•™ç¨‹\n  - [å£°éŸ³åˆ†ç±»](./docs/tutorial/cls/cls_tutorial.ipynb)\n  - [è¯­éŸ³è¯†åˆ«](./docs/tutorial/asr/tutorial_transformer.ipynb)\n  - [è¯­éŸ³ç¿»è¯‘](./docs/tutorial/st/st_tutorial.ipynb)\n  - [å£°éŸ³åˆæˆ](./docs/tutorial/tts/tts_tutorial.ipynb)\n  - [ç¤ºä¾‹Demo](./demos/README.md)\n- è¿›é˜¶æ–‡æ¡£  \n  - [è¯­éŸ³è¯†åˆ«è‡ªå®šä¹‰è®­ç»ƒ](./docs/source/asr/quick_start.md)\n    - [ç®€ä»‹](./docs/source/asr/models_introduction.md)\n    - [æ•°æ®å‡†å¤‡](./docs/source/asr/data_preparation.md)\n    - [Ngram è¯­è¨€æ¨¡å‹](./docs/source/asr/ngram_lm.md)\n  - [è¯­éŸ³åˆæˆè‡ªå®šä¹‰è®­ç»ƒ](./docs/source/tts/quick_start.md)\n    - [ç®€ä»‹](./docs/source/tts/models_introduction.md)\n    - [è¿›é˜¶ç”¨æ³•](./docs/source/tts/advanced_usage.md)\n    - [ä¸­æ–‡æ–‡æœ¬å‰ç«¯](./docs/source/tts/zh_text_frontend.md)\n    - [æµ‹è¯•è¯­éŸ³æ ·æœ¬](https://paddlespeech.readthedocs.io/en/latest/tts/demo.html)\n  - å£°çº¹è¯†åˆ«\n    - [å£°çº¹è¯†åˆ«](./demos/speaker_verification/README_cn.md)\n    - [éŸ³é¢‘æ£€ç´¢](./demos/audio_searching/README_cn.md)\n  - [å£°éŸ³åˆ†ç±»](./demos/audio_tagging/README_cn.md)\n  - [è¯­éŸ³ç¿»è¯‘](./demos/speech_translation/README_cn.md)\n  - [æœåŠ¡åŒ–éƒ¨ç½²](./demos/speech_server/README_cn.md)\n- [æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)\n  - [è¯­éŸ³è¯†åˆ«](#è¯­éŸ³è¯†åˆ«æ¨¡å‹)\n  - [è¯­éŸ³åˆæˆ](#è¯­éŸ³åˆæˆæ¨¡å‹)\n  - [å£°éŸ³åˆ†ç±»](#å£°éŸ³åˆ†ç±»æ¨¡å‹)\n  - [å£°çº¹è¯†åˆ«](#å£°çº¹è¯†åˆ«æ¨¡å‹)\n  - [è¯´è¯äººæ—¥å¿—](#è¯´è¯äººæ—¥å¿—æ¨¡å‹)\n  - [æ ‡ç‚¹æ¢å¤](#æ ‡ç‚¹æ¢å¤æ¨¡å‹)\n- [æŠ€æœ¯äº¤æµç¾¤](#æŠ€æœ¯äº¤æµç¾¤)\n- [æ¬¢è¿è´¡çŒ®](#æ¬¢è¿è´¡çŒ®)\n- [License](#License)\n\n\nè¯­éŸ³åˆæˆæ¨¡å—æœ€åˆè¢«ç§°ä¸º [Parakeet](https://github.com/PaddlePaddle/Parakeet)ï¼Œç°åœ¨ä¸æ­¤ä»“åº“åˆå¹¶ã€‚å¦‚æœæ‚¨å¯¹è¯¥ä»»åŠ¡çš„å­¦æœ¯ç ”ç©¶æ„Ÿå…´è¶£ï¼Œè¯·å‚é˜… [TTS ç ”ç©¶æ¦‚è¿°](https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/docs/source/tts#overview)ã€‚æ­¤å¤–ï¼Œ[æ¨¡å‹ä»‹ç»](https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/docs/source/tts/models_introduction.md) æ˜¯äº†è§£è¯­éŸ³åˆæˆæµç¨‹çš„ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡å—ã€‚\n\n\n## â­ åº”ç”¨æ¡ˆä¾‹\n- **[PaddleBoBo](https://github.com/JiehangXie/PaddleBoBo): ä½¿ç”¨ PaddleSpeech çš„è¯­éŸ³åˆæˆæ¨¡å—ç”Ÿæˆè™šæ‹Ÿäººçš„å£°éŸ³ã€‚**\n  \n<div align=\"center\"><a href=\"https://www.bilibili.com/video/BV1cL411V71o?share_source=copy_web\"><img src=\"https://ai-studio-static-online.cdn.bcebos.com/06fd746ab32042f398fb6f33f873e6869e846fe63c214596ae37860fe8103720\" / width=\"500px\"></a></div>\n\n- [PaddleSpeech ç¤ºä¾‹è§†é¢‘](https://paddlespeech.readthedocs.io/en/latest/demo_video.html)\n\n\n- **[VTuberTalk](https://github.com/jerryuhoo/VTuberTalk): ä½¿ç”¨ PaddleSpeech çš„è¯­éŸ³åˆæˆå’Œè¯­éŸ³è¯†åˆ«ä»è§†é¢‘ä¸­å…‹éš†äººå£°ã€‚**\n\n<div align=\"center\">\n<img src=\"https://raw.githubusercontent.com/jerryuhoo/VTuberTalk/main/gui/gui.png\"  width = \"500px\"  />\n</div>\n\n\n## å¼•ç”¨\n\nè¦å¼•ç”¨ PaddleSpeech è¿›è¡Œç ”ç©¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼è¿›è¡Œå¼•ç”¨ã€‚\n```text\n@InProceedings{pmlr-v162-bai22d,\n  title = {{A}$^3${T}: Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing},\n  author = {Bai, He and Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Li, Xintong and Huang, Liang},\n  booktitle = {Proceedings of the 39th International Conference on Machine Learning},\n  pages = {1399--1411},\n  year = {2022},\n  volume = {162},\n  series = {Proceedings of Machine Learning Research},\n  month = {17--23 Jul},\n  publisher = {PMLR},\n  pdf = {https://proceedings.mlr.press/v162/bai22d/bai22d.pdf},\n  url = {https://proceedings.mlr.press/v162/bai22d.html},\n}\n\n@inproceedings{zhang2022paddlespeech,\n    title = {PaddleSpeech: An Easy-to-Use All-in-One Speech Toolkit},\n    author = {Hui Zhang, Tian Yuan, Junkun Chen, Xintong Li, Renjie Zheng, Yuxin Huang, Xiaojie Chen, Enlei Gong, Zeyu Chen, Xiaoguang Hu, dianhai yu, Yanjun Ma, Liang Huang},\n    booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations},\n    year = {2022},\n    publisher = {Association for Computational Linguistics},\n}\n\n@inproceedings{zheng2021fused,\n  title={Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation},\n  author={Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Huang, Liang},\n  booktitle={International Conference on Machine Learning},\n  pages={12736--12746},\n  year={2021},\n  organization={PMLR}\n}\n```\n\n<a name=\"æ¬¢è¿è´¡çŒ®\"></a>\n## å‚ä¸ PaddleSpeech çš„å¼€å‘\n\nçƒ­çƒˆæ¬¢è¿æ‚¨åœ¨ [Discussions](https://github.com/PaddlePaddle/PaddleSpeech/discussions) ä¸­æäº¤é—®é¢˜ï¼Œå¹¶åœ¨ [Issues](https://github.com/PaddlePaddle/PaddleSpeech/issues) ä¸­æŒ‡å‡ºå‘ç°çš„ bugã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬éå¸¸å¸Œæœ›æ‚¨å‚ä¸åˆ° PaddleSpeech çš„å¼€å‘ä¸­ï¼\n\n### è´¡çŒ®è€…\n<p align=\"center\">\n<a href=\"https://github.com/zh794390558\"><img src=\"https://avatars.githubusercontent.com/u/3038472?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Jackwaterveg\"><img src=\"https://avatars.githubusercontent.com/u/87408988?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/yt605155624\"><img src=\"https://avatars.githubusercontent.com/u/24568452?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Honei\"><img src=\"https://avatars.githubusercontent.com/u/11361692?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/KPatr1ck\"><img src=\"https://avatars.githubusercontent.com/u/22954146?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kuke\"><img src=\"https://avatars.githubusercontent.com/u/3064195?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lym0302\"><img src=\"https://avatars.githubusercontent.com/u/34430015?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/SmileGoat\"><img src=\"https://avatars.githubusercontent.com/u/56786796?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/xinghai-sun\"><img src=\"https://avatars.githubusercontent.com/u/7038341?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/pkuyym\"><img src=\"https://avatars.githubusercontent.com/u/5782283?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/LittleChenCc\"><img src=\"https://avatars.githubusercontent.com/u/10339970?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/qingen\"><img src=\"https://avatars.githubusercontent.com/u/3139179?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/D-DanielYang\"><img src=\"https://avatars.githubusercontent.com/u/23690325?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Mingxue-Xu\"><img src=\"https://avatars.githubusercontent.com/u/92848346?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/745165806\"><img src=\"https://avatars.githubusercontent.com/u/20623194?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/jerryuhoo\"><img src=\"https://avatars.githubusercontent.com/u/24245709?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/WilliamZhang06\"><img src=\"https://avatars.githubusercontent.com/u/97937340?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chrisxu2016\"><img src=\"https://avatars.githubusercontent.com/u/18379485?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/iftaken\"><img src=\"https://avatars.githubusercontent.com/u/30135920?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lfchener\"><img src=\"https://avatars.githubusercontent.com/u/6771821?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/BarryKCL\"><img src=\"https://avatars.githubusercontent.com/u/48039828?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/mmglove\"><img src=\"https://avatars.githubusercontent.com/u/38800877?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/gongel\"><img src=\"https://avatars.githubusercontent.com/u/24390500?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/luotao1\"><img src=\"https://avatars.githubusercontent.com/u/6836917?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/wanghaoshuang\"><img src=\"https://avatars.githubusercontent.com/u/7534971?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kslz\"><img src=\"https://avatars.githubusercontent.com/u/54951765?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/JiehangXie\"><img src=\"https://avatars.githubusercontent.com/u/51190264?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/david-95\"><img src=\"https://avatars.githubusercontent.com/u/15189190?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/THUzyt21\"><img src=\"https://avatars.githubusercontent.com/u/91456992?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/buchongyu2\"><img src=\"https://avatars.githubusercontent.com/u/29157444?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/iclementine\"><img src=\"https://avatars.githubusercontent.com/u/16222986?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/phecda-xu\"><img src=\"https://avatars.githubusercontent.com/u/46859427?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/freeliuzc\"><img src=\"https://avatars.githubusercontent.com/u/23568094?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ZeyuChen\"><img src=\"https://avatars.githubusercontent.com/u/1371212?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ccrrong\"><img src=\"https://avatars.githubusercontent.com/u/101700995?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AK391\"><img src=\"https://avatars.githubusercontent.com/u/81195143?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/qingqing01\"><img src=\"https://avatars.githubusercontent.com/u/7845005?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/0x45f\"><img src=\"https://avatars.githubusercontent.com/u/23097963?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/vpegasus\"><img src=\"https://avatars.githubusercontent.com/u/22723154?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ericxk\"><img src=\"https://avatars.githubusercontent.com/u/4719594?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Betterman-qs\"><img src=\"https://avatars.githubusercontent.com/u/61459181?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/sneaxiy\"><img src=\"https://avatars.githubusercontent.com/u/32832641?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Doubledongli\"><img src=\"https://avatars.githubusercontent.com/u/20540661?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/apps/dependabot\"><img src=\"https://avatars.githubusercontent.com/in/29110?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/kvinwang\"><img src=\"https://avatars.githubusercontent.com/u/6442159?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chenkui164\"><img src=\"https://avatars.githubusercontent.com/u/34813030?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/PaddleZhang\"><img src=\"https://avatars.githubusercontent.com/u/97284124?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/billishyahao\"><img src=\"https://avatars.githubusercontent.com/u/96406262?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/BrightXiaoHan\"><img src=\"https://avatars.githubusercontent.com/u/25839309?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/jiqiren11\"><img src=\"https://avatars.githubusercontent.com/u/82639260?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/ryanrussell\"><img src=\"https://avatars.githubusercontent.com/u/523300?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/GT-ZhangAcer\"><img src=\"https://avatars.githubusercontent.com/u/46156734?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/tensor-tang\"><img src=\"https://avatars.githubusercontent.com/u/21351065?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/hysunflower\"><img src=\"https://avatars.githubusercontent.com/u/52739577?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/oyjxer\"><img src=\"https://avatars.githubusercontent.com/u/16233945?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/JamesLim-sy\"><img src=\"https://avatars.githubusercontent.com/u/61349199?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/limpidezza\"><img src=\"https://avatars.githubusercontent.com/u/71760778?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/windstamp\"><img src=\"https://avatars.githubusercontent.com/u/34057289?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AshishKarel\"><img src=\"https://avatars.githubusercontent.com/u/58069375?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/chesterkuo\"><img src=\"https://avatars.githubusercontent.com/u/6285069?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/YDX-2147483647\"><img src=\"https://avatars.githubusercontent.com/u/73375426?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/AdamBear\"><img src=\"https://avatars.githubusercontent.com/u/2288870?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/wwhu\"><img src=\"https://avatars.githubusercontent.com/u/6081200?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/lispc\"><img src=\"https://avatars.githubusercontent.com/u/2833376?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/harisankarh\"><img src=\"https://avatars.githubusercontent.com/u/1307053?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/pengzhendong\"><img src=\"https://avatars.githubusercontent.com/u/10704539?s=60&v=4\" width=75 height=75></a>\n<a href=\"https://github.com/Jackiexiao\"><img src=\"https://avatars.githubusercontent.com/u/18050469?s=60&v=4\" width=75 height=75></a>\n</p>\n\n## è‡´è°¢\n- éå¸¸æ„Ÿè°¢ [HighCWu](https://github.com/HighCWu) æ–°å¢ [VITS-aishell3](./examples/aishell3/vits) å’Œ [VITS-VC](./examples/aishell3/vits-vc) ä»£ç ç¤ºä¾‹ã€‚\n- éå¸¸æ„Ÿè°¢ [david-95](https://github.com/david-95) ä¿®å¤ TTS å¥å°¾å¤šæ ‡ç‚¹ç¬¦å·å‡ºé”™çš„é—®é¢˜ï¼Œè´¡çŒ®è¡¥å……å¤šæ¡ç¨‹åºå’Œæ•°æ®ã€‚ä¸º TTS ä¸­æ–‡æ–‡æœ¬å‰ç«¯æ–°å¢ [SSML](https://github.com/PaddlePaddle/PaddleSpeech/discussions/2538) åŠŸèƒ½ã€‚\n- éå¸¸æ„Ÿè°¢ [BarryKCL](https://github.com/BarryKCL) åŸºäº [G2PW](https://github.com/GitYCC/g2pW) å¯¹ TTS ä¸­æ–‡æ–‡æœ¬å‰ç«¯çš„ä¼˜åŒ–ã€‚\n- éå¸¸æ„Ÿè°¢ [yeyupiaoling](https://github.com/yeyupiaoling)/[PPASR](https://github.com/yeyupiaoling/PPASR)/[PaddlePaddle-DeepSpeech](https://github.com/yeyupiaoling/PaddlePaddle-DeepSpeech)/[VoiceprintRecognition-PaddlePaddle](https://github.com/yeyupiaoling/VoiceprintRecognition-PaddlePaddle)/[AudioClassification-PaddlePaddle](https://github.com/yeyupiaoling/AudioClassification-PaddlePaddle) å¤šå¹´æ¥çš„å…³æ³¨å’Œå»ºè®®ï¼Œä»¥åŠåœ¨è¯¸å¤šé—®é¢˜ä¸Šçš„å¸®åŠ©ã€‚\n- éå¸¸æ„Ÿè°¢ [mymagicpower](https://github.com/mymagicpower) é‡‡ç”¨PaddleSpeech å¯¹ ASR çš„[çŸ­è¯­éŸ³](https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_sdk)åŠ[é•¿è¯­éŸ³](https://github.com/mymagicpower/AIAS/tree/main/3_audio_sdks/asr_long_audio_sdk)è¿›è¡Œ Java å®ç°ã€‚\n- éå¸¸æ„Ÿè°¢ [JiehangXie](https://github.com/JiehangXie)/[PaddleBoBo](https://github.com/JiehangXie/PaddleBoBo) é‡‡ç”¨ PaddleSpeech è¯­éŸ³åˆæˆåŠŸèƒ½å®ç° Virtual Uploader(VUP)/Virtual YouTuber(VTuber) è™šæ‹Ÿä¸»æ’­ã€‚\n- éå¸¸æ„Ÿè°¢ [745165806](https://github.com/745165806)/[PaddleSpeechTask](https://github.com/745165806/PaddleSpeechTask) è´¡çŒ®æ ‡ç‚¹é‡å»ºç›¸å…³æ¨¡å‹ã€‚\n- éå¸¸æ„Ÿè°¢ [kslz](https://github.com/kslz) è¡¥å……ä¸­æ–‡æ–‡æ¡£ã€‚\n- éå¸¸æ„Ÿè°¢ [awmmmm](https://github.com/awmmmm) æä¾› fastspeech2 aishell3 conformer é¢„è®­ç»ƒæ¨¡å‹ã€‚\n- éå¸¸æ„Ÿè°¢ [phecda-xu](https://github.com/phecda-xu)/[PaddleDubbing](https://github.com/phecda-xu/PaddleDubbing) åŸºäº PaddleSpeech çš„ TTS æ¨¡å‹æ­å»ºå¸¦ GUI æ“ä½œç•Œé¢çš„é…éŸ³å·¥å…·ã€‚\n- éå¸¸æ„Ÿè°¢ [jerryuhoo](https://github.com/jerryuhoo)/[VTuberTalk](https://github.com/jerryuhoo/VTuberTalk) åŸºäº PaddleSpeech çš„ TTS GUI ç•Œé¢å’ŒåŸºäº ASR åˆ¶ä½œæ•°æ®é›†çš„ç›¸å…³ä»£ç ã€‚\n- éå¸¸æ„Ÿè°¢ [vpegasus](https://github.com/vpegasus)/[xuesebot](https://github.com/vpegasus/xuesebot) åŸºäº PaddleSpeech çš„ ASR ä¸ TTS è®¾è®¡çš„å¯å¬ã€è¯´å¯¹è¯æœºå™¨äººã€‚\n- éå¸¸æ„Ÿè°¢ [chenkui164](https://github.com/chenkui164)/[FastASR](https://github.com/chenkui164/FastASR) å¯¹ PaddleSpeech çš„ ASR è¿›è¡Œ C++ æ¨ç†å®ç°ã€‚\n- éå¸¸æ„Ÿè°¢ [heyudage](https://github.com/heyudage)/[VoiceTyping](https://github.com/heyudage/VoiceTyping) åŸºäº PaddleSpeech çš„ ASR æµå¼æœåŠ¡å®ç°çš„å®æ—¶è¯­éŸ³è¾“å…¥æ³•å·¥å…·ã€‚\n- éå¸¸æ„Ÿè°¢ [EscaticZheng](https://github.com/EscaticZheng)/[ps3.9wheel-install](https://github.com/EscaticZheng/ps3.9wheel-install) å¯¹PaddleSpeechåœ¨Windowsä¸‹çš„å®‰è£…æä¾›äº†æ— éœ€Visua Studioï¼ŒåŸºäºpython3.9çš„é¢„ç¼–è¯‘ä¾èµ–å®‰è£…åŒ…ã€‚\n- éå¸¸æ„Ÿè°¢ [chinobing](https://github.com/chinobing)/[FastAPI-PaddleSpeech-Audio-To-Text](https://github.com/chinobing/FastAPI-PaddleSpeech-Audio-To-Text) åˆ©ç”¨ FastAPI å®ç° PaddleSpeech è¯­éŸ³è½¬æ–‡å­—ï¼Œæ–‡ä»¶ä¸Šä¼ ã€åˆ†å‰²ã€è½¬æ¢è¿›åº¦æ˜¾ç¤ºã€åå°æ›´æ–°ä»»åŠ¡å¹¶ä»¥ csv æ ¼å¼è¾“å‡ºã€‚\n- éå¸¸æ„Ÿè°¢ [MistEO](https://github.com/MistEO)/[Pallas-Bot](https://github.com/MistEO/Pallas-Bot) åŸºäº PaddleSpeech TTS çš„ QQ Bot é¡¹ç›®ã€‚\n\næ­¤å¤–ï¼ŒPaddleSpeech ä¾èµ–äºè®¸å¤šå¼€æºå­˜å‚¨åº“ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [references](./docs/source/reference.md)ã€‚\n\n## License\n\nPaddleSpeech åœ¨ [Apache-2.0 è®¸å¯](./LICENSE) ä¸‹æä¾›ã€‚\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/PaddlePaddle/PaddleSpeech.svg)](https://starchart.cc/PaddlePaddle/PaddleSpeech)\n"
        },
        {
          "name": "audio",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataset",
          "type": "tree",
          "content": null
        },
        {
          "name": "demos",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "paddlespeech",
          "type": "tree",
          "content": null
        },
        {
          "name": "runtime",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.17578125,
          "content": "[build_ext]\ndebug=0\n\n[metadata]\nlicense_file = LICENSE\ndescription-file = README.md\n\n[magformat]\nformatters=yapf\n\n[easy_install]\nindex-url=https://pypi.tuna.tsinghua.edu.cn/simple\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 8.8662109375,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport contextlib\nimport inspect\nimport io\nimport os\nimport subprocess as sp\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import Command\nfrom setuptools import find_packages\nfrom setuptools import setup\nfrom setuptools.command.develop import develop\nfrom setuptools.command.install import install\nfrom setuptools.command.test import test\n\nHERE = Path(os.path.abspath(os.path.dirname(__file__)))\n\nVERSION = '0.0.0'\nCOMMITID = 'none'\n\nbase = [\n    \"braceexpand\",\n    \"editdistance\",\n    \"g2p_en\",\n    \"g2pM\",\n    \"h5py\",\n    \"hyperpyyaml\",\n    \"inflect\",\n    \"jsonlines\",\n    # paddleaudio align with librosa==0.8.1, which need numpy==1.23.x\n    \"numpy==1.23.5\",\n    \"librosa==0.8.1\",\n    \"scipy>=1.4.0, <=1.12.0\",\n    \"loguru\",\n    \"matplotlib<=3.8.4\",\n    \"nara_wpe\",\n    \"onnxruntime>=1.11.0\",\n    \"opencc==1.1.6\",\n    \"opencc-python-reimplemented\",\n    \"pandas\",\n    \"paddleaudio>=1.1.0\",\n    \"paddlenlp>=2.4.8\",\n    \"paddleslim>=2.3.4\",\n    \"ppdiffusers>=0.9.0\",\n    \"paddlespeech_feat\",\n    \"praatio>=5.0.0, <=5.1.1\",\n    \"prettytable\",\n    \"pydantic>=1.10.14, <2.0\",\n    \"pypinyin<=0.44.0\",\n    \"pypinyin-dict\",\n    \"python-dateutil\",\n    \"pyworld>=0.2.12\",\n    \"pyyaml\",\n    \"resampy\",\n    \"sacrebleu\",\n    \"soundfile\",\n    \"textgrid\",\n    \"timer\",\n    \"ToJyutping==0.2.1\",\n    \"typeguard==2.13.3\",\n    \"webrtcvad\",\n    \"yacs~=0.1.8\",\n    \"zhon\",\n]\n\nserver = [\"pattern_singleton\", \"websockets\"]\n\nrequirements = {\n    \"install\":\n    base + server,\n    \"develop\": [\n        \"ConfigArgParse\",\n        \"coverage\",\n        \"gpustat\",\n        \"paddlespeech_ctcdecoders\",\n        \"phkit\",\n        \"pypi-kenlm\",\n        \"snakeviz\",\n        \"sox\",\n        \"soxbindings\",\n        \"unidecode\",\n        \"yq\",\n        \"pre-commit\",\n    ]\n}\n\n\ndef check_call(cmd: str, shell=False, executable=None):\n    try:\n        sp.check_call(\n            cmd.split(),\n            shell=shell,\n            executable=\"/bin/bash\" if shell else executable)\n    except sp.CalledProcessError as e:\n        print(\n            f\"{__file__}:{inspect.currentframe().f_lineno}: CMD: {cmd}, Error:\",\n            e.output,\n            file=sys.stderr)\n        raise e\n\n\ndef check_output(cmd: str, shell=False):\n    try:\n        out_bytes = sp.check_output(cmd.split())\n    except sp.CalledProcessError as e:\n        out_bytes = e.output  # Output generated before error\n        code = e.returncode  # Return code\n        print(\n            f\"{__file__}:{inspect.currentframe().f_lineno}: CMD: {cmd}, Error:\",\n            out_bytes,\n            file=sys.stderr)\n    return out_bytes.strip().decode('utf8')\n\n\n@contextlib.contextmanager\ndef pushd(new_dir):\n    old_dir = os.getcwd()\n    os.chdir(new_dir)\n    print(new_dir)\n    yield\n    os.chdir(old_dir)\n    print(old_dir)\n\n\ndef read(*names, **kwargs):\n    with io.open(\n            os.path.join(os.path.dirname(__file__), *names),\n            encoding=kwargs.get(\"encoding\", \"utf8\")) as fp:\n        return fp.read()\n\n\ndef _remove(files: str):\n    for f in files:\n        f.unlink()\n\n\n################################# Install ##################################\n\n\ndef _post_install(install_lib_dir):\n    # tools/make\n    tool_dir = HERE / \"tools\"\n    _remove(tool_dir.glob(\"*.done\"))\n    with pushd(tool_dir):\n        check_call(\"make\")\n    print(\"tools install.\")\n\n    # ctcdecoder\n    ctcdecoder_dir = HERE / 'third_party/ctc_decoders'\n    with pushd(ctcdecoder_dir):\n        check_call(\"bash -e setup.sh\")\n    print(\"ctcdecoder install.\")\n\n\nclass DevelopCommand(develop):\n    def run(self):\n        develop.run(self)\n        # must after develop.run, or pkg install by shell will not see\n        self.execute(_post_install, (self.install_lib, ), msg=\"Post Install...\")\n\n\nclass InstallCommand(install):\n    def run(self):\n        install.run(self)\n\n\nclass TestCommand(test):\n    def finalize_options(self):\n        test.finalize_options(self)\n        self.test_args = []\n        self.test_suite = True\n\n    def run_tests(self):\n        # Run nose ensuring that argv simulates running nosetests directly\n        import nose\n        nose.run_exit(argv=['nosetests', '-w', 'tests'])\n\n\n# cmd: python setup.py upload\nclass UploadCommand(Command):\n    description = \"Build and publish the package.\"\n    user_options = []\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run(self):\n        try:\n            print(\"Removing previous dist/ ...\")\n            shutil.rmtree(str(HERE / \"dist\"))\n        except OSError:\n            pass\n        print(\"Building source distribution...\")\n        sp.check_call([sys.executable, \"setup.py\", \"sdist\"])\n        print(\"Uploading package to PyPi...\")\n        sp.check_call([\"twine\", \"upload\", \"dist/*\"])\n        sys.exit()\n\n\n################################# Version ##################################\ndef write_version_py(filename='paddlespeech/__init__.py'):\n    import paddlespeech\n    if hasattr(paddlespeech,\n               \"__version__\") and paddlespeech.__version__ == VERSION:\n        return\n    with open(filename, \"a\") as f:\n        out_str = f\"\\n__version__ = '{VERSION}'\\n\"\n        print(out_str)\n        f.write(f\"\\n__version__ = '{VERSION}'\\n\")\n\n    COMMITID = check_output(\"git rev-parse HEAD\")\n    with open(filename, 'a') as f:\n        out_str = f\"\\n__commit__ = '{COMMITID}'\\n\"\n        print(out_str)\n        f.write(f\"\\n__commit__ = '{COMMITID}'\\n\")\n\n    print(f\"{inspect.currentframe().f_code.co_name} done\")\n\n\ndef remove_version_py(filename='paddlespeech/__init__.py'):\n    with open(filename, \"r\") as f:\n        lines = f.readlines()\n    with open(filename, \"w\") as f:\n        for line in lines:\n            if \"__version__\" in line or \"__commit__\" in line:\n                continue\n            f.write(line)\n    print(f\"{inspect.currentframe().f_code.co_name} done\")\n\n\n@contextlib.contextmanager\ndef version_info():\n    write_version_py()\n    yield\n    remove_version_py()\n\n\n################################# Steup ##################################\nsetup_info = dict(\n    # Metadata\n    name='paddlespeech',\n    version=VERSION,\n    author='PaddlePaddle Speech and Language Team',\n    author_email='paddlesl@baidu.com',\n    url='https://github.com/PaddlePaddle/PaddleSpeech',\n    license='Apache 2.0',\n    description='Speech tools and models based on Paddlepaddle',\n    long_description=read(\"README.md\"),\n    long_description_content_type=\"text/markdown\",\n    keywords=[\n        \"SSL\"\n        \"speech\",\n        \"asr\",\n        \"tts\",\n        \"speaker verfication\",\n        \"speech classfication\",\n        \"text frontend\",\n        \"MFA\",\n        \"paddlepaddle\",\n        \"paddleaudio\",\n        \"streaming asr\",\n        \"streaming tts\",\n        \"beam search\",\n        \"ctcdecoder\",\n        \"deepspeech2\",\n        \"wav2vec2\",\n        \"hubert\",\n        \"wavlm\",\n        \"transformer\",\n        \"conformer\",\n        \"fastspeech2\",\n        \"hifigan\",\n        \"gan vocoders\",\n    ],\n    python_requires='>=3.7',\n    install_requires=requirements[\"install\"],\n    extras_require={\n        'develop':\n        requirements[\"develop\"],\n        'doc': [\n            \"sphinx\", \"sphinx-rtd-theme\", \"numpydoc\", \"myst_parser\",\n            \"recommonmark>=0.5.0\", \"sphinx-markdown-tables\", \"sphinx-autobuild\"\n        ],\n        'test': ['nose', 'torchaudio==0.10.2'],\n    },\n    cmdclass={\n        'develop': DevelopCommand,\n        'install': InstallCommand,\n        'upload': UploadCommand,\n        'test': TestCommand,\n    },\n\n    # Package info\n    packages=find_packages(\n        include=['paddlespeech*'], exclude=['utils', 'third_party']),\n    zip_safe=True,\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Intended Audience :: Developers',\n        'Intended Audience :: Science/Research',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n    ],\n    entry_points={\n        'console_scripts': [\n            'paddlespeech=paddlespeech.cli.entry:_execute',\n            'paddlespeech_server=paddlespeech.server.entry:server_execute',\n            'paddlespeech_client=paddlespeech.server.entry:client_execute'\n        ]\n    })\n\nwith version_info():\n    setup(**setup_info, include_package_data=True)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}