{
  "metadata": {
    "timestamp": 1736561083600,
    "page": 12,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "deepinsight/insightface",
      "stars": 23975,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.140625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n.DS_Store\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.1015625,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\ncontact@insightface.ai.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.6884765625,
          "content": "\n# InsightFace: 2D and 3D Face Analysis Project\n\n<div align=\"left\">\n  <img src=\"https://insightface.ai/assets/img/custom/logo3.jpg\" width=\"240\"/>\n</div>\n\n[InsightFace](https://insightface.ai) project is mainly maintained By [Jia Guo](mailto:guojia@gmail.com?subject=[GitHub]%20InsightFace%20Project) and [Jiankang Deng](https://jiankangdeng.github.io/). \n\nFor all main contributors, please check [contributing](#contributing).\n\n## License\n\nThe code of InsightFace is released under the MIT License. There is no limitation for both academic and commercial usage.\n\nThe training data containing the annotation (and the models trained with these data) are available for non-commercial research purposes only.\n\nBoth manual-downloading models from our github repo and auto-downloading models with our [python-library](python-package) follow the above license policy(which is for non-commercial research purposes only).\n\n## Top News\n\n**`2024-08-01`** We have integrated our most advanced face-swapping models: **inswapper\\_cyn** and **inswapper\\_dax**, into the [Picsi.Ai face-swapping](https://www.picsi.ai) service. These models outperform almost all similar commercial products and our open-source model inswapper\\_128. Please visit the [Picsi.Ai](https://www.picsi.ai) website to use the service and get help.\n\n**`2024-05-04`** We have added [InspireFace](cpp-package/inspireface), which is a cross-platform face recognition SDK developed in C/C++, supporting multiple operating systems and various backends. \n\n**`2023-04-01`**: We integrated our most advanced face-swapping models: **inswapper\\_cyn** and **inswapper\\_dax** and move the service to Discord bot, which also support editing on Midjourney generated images, see detail at [web-demos/swapping_discord](web-demos/swapping_discord) and our [Picsi.Ai](https://www.picsi.ai) website.\n\n**`2022-08-12`**: We achieved Rank-1st of \n[Perspective Projection Based Monocular 3D Face Reconstruction Challenge](https://tianchi.aliyun.com/competition/entrance/531961/introduction)\nof [ECCV-2022 WCPA Workshop](https://sites.google.com/view/wcpa2022), [paper](https://arxiv.org/abs/2208.07142) and [code](reconstruction/jmlr).\n\n**`2021-11-30`**: [MFR-Ongoing](challenges/mfr) challenge launched(same with IFRT), which is an extended version of [iccv21-mfr](challenges/iccv21-mfr).\n\n**`2021-10-29`**: We achieved 1st place on the [VISA track](https://pages.nist.gov/frvt/plots/11/visa.html) of [NIST-FRVT 1:1](https://pages.nist.gov/frvt/html/frvt11.html) by using Partial FC (Xiang An, Jiankang Deng, Jia Guo).\n\n## ChangeLogs\n\n**`2024-08-01`** We have integrated our most advanced face-swapping models: **inswapper\\_cyn** and **inswapper\\_dax**, into the [Picsi.Ai face-swapping](https://www.picsi.ai) service. These models outperform almost all similar commercial products and our open-source model inswapper\\_128. Please visit the [Picsi.Ai](https://www.picsi.ai) website to use the service and get help.\n\n**`2024-05-04`** We have added [InspireFace](cpp-package/inspireface), which is a cross-platform face recognition SDK developed in C/C++, supporting multiple operating systems and various backends. \n\n**`2024-04-17`**: [Monocular Identity-Conditioned Facial Reflectance Reconstruction](https://arxiv.org/abs/2404.00301) accepted by [CVPR-2024](https://cvpr.thecvf.com/Conferences/2024).\n\n**`2023-08-08`**: We released the implementation of [Generalizing Gaze Estimation with Weak-Supervision from Synthetic Views](https://arxiv.org/abs/2212.02997) at [reconstruction/gaze](reconstruction/gaze).\n\n**`2023-05-03`**: We have launched the ongoing version of wild face anti-spoofing challenge. See details [here](https://github.com/deepinsight/insightface/tree/master/challenges/cvpr23-fas-wild#updates).\n\n**`2023-04-01`**: We integrated our most advanced face-swapping models: **inswapper\\_cyn** and **inswapper\\_dax** and move the service to Discord bot, which also support editing on Midjourney generated images, see detail at [web-demos/swapping_discord](web-demos/swapping_discord) and our [Picsi.Ai](https://www.picsi.ai) website.\n\n**`2023-02-13`**: We launch a large scale in the wild face anti-spoofing challenge on CVPR23 Workshop, see details at [challenges/cvpr23-fas-wild](challenges/cvpr23-fas-wild).\n\n**`2022-11-28`**: Single line code for facial identity swapping in our python packge ver 0.7, please check the example [here](examples/in_swapper).\n\n**`2022-10-28`**: [MFR-Ongoing](http://iccv21-mfr.com) website is refactored, please create issues if there's any bug.\n\n**`2022-09-22`**: Now we have [web-demos](web-demos): [face-localization](http://demo.insightface.ai:7007/), [face-recognition](http://demo.insightface.ai:7008/), and [face-swapping](http://demo.insightface.ai:7009/).\n\n**`2022-08-12`**: We achieved Rank-1st of \n[Perspective Projection Based Monocular 3D Face Reconstruction Challenge](https://tianchi.aliyun.com/competition/entrance/531961/introduction)\nof [ECCV-2022 WCPA Workshop](https://sites.google.com/view/wcpa2022), [paper](https://arxiv.org/abs/2208.07142) and [code](reconstruction/jmlr).\n\n**`2022-03-30`**: [Partial FC](https://arxiv.org/abs/2203.15565) accepted by CVPR-2022.\n\n**`2022-02-23`**: [SCRFD](detection/scrfd) accepted by [ICLR-2022](https://iclr.cc/Conferences/2022).\n\n**`2021-11-30`**: [MFR-Ongoing](challenges/mfr) challenge launched(same with IFRT), which is an extended version of [iccv21-mfr](challenges/iccv21-mfr).\n\n**`2021-10-29`**: We achieved 1st place on the [VISA track](https://pages.nist.gov/frvt/plots/11/visa.html) of [NIST-FRVT 1:1](https://pages.nist.gov/frvt/html/frvt11.html) by using Partial FC (Xiang An, Jiankang Deng, Jia Guo).\n\n**`2021-10-11`**: [Leaderboard](https://insightface.ai/mfr21) of [ICCV21 - Masked Face Recognition Challenge](challenges/iccv21-mfr) released. Video: [Youtube](https://www.youtube.com/watch?v=lL-7l5t6x2w), [Bilibili](https://www.bilibili.com/video/BV15b4y1h79N/).\n\n**`2021-06-05`**: We launch a [Masked Face Recognition Challenge & Workshop](challenges/iccv21-mfr) on ICCV 2021.\n\n\n\n## Introduction\n\n[InsightFace](https://insightface.ai) is an open source 2D&3D deep face analysis toolbox, mainly based on PyTorch and MXNet. \n\nPlease check our [website](https://insightface.ai) for detail.\n\nThe master branch works with **PyTorch 1.6+** and/or **MXNet=1.6-1.8**, with **Python 3.x**.\n\nInsightFace efficiently implements a rich variety of state of the art algorithms of face recognition, face detection and face alignment, which optimized for both training and deployment.\n\n## Quick Start\n\nPlease start with our [python-package](python-package/), for testing detection, recognition and alignment models on input images.\n\n\n### ArcFace Video Demo\n\n\n[<img src=https://insightface.ai/assets/img/github/facerecognitionfromvideo.PNG width=\"760\" />](https://www.youtube.com/watch?v=y-D1tReryGA&t=81s)\n\n\nPlease click the image to watch the Youtube video. For Bilibili users, click [here](https://www.bilibili.com/video/av38041494?from=search&seid=11501833604850032313).\n\n\n\n## Projects\n\nThe [page](https://insightface.ai/projects) on InsightFace website also describes all supported projects in InsightFace.\n\nYou may also interested in some [challenges](https://insightface.ai/challenges) hold by InsightFace.\n\n\n\n## Face Recognition\n\n### Introduction\n\nIn this module, we provide training data, network settings and loss designs for deep face recognition.\n\nThe supported methods are as follows:\n\n- [x] [ArcFace_mxnet (CVPR'2019)](recognition/arcface_mxnet)\n- [x] [ArcFace_torch (CVPR'2019)](recognition/arcface_torch)\n- [x] [SubCenter ArcFace (ECCV'2020)](recognition/subcenter_arcface)\n- [x] [PartialFC_mxnet (CVPR'2022)](recognition/partial_fc)\n- [x] [PartialFC_torch (CVPR'2022)](recognition/arcface_torch)\n- [x] [VPL (CVPR'2021)](recognition/vpl)\n- [x] [Arcface_oneflow](recognition/arcface_oneflow)\n- [x] [ArcFace_Paddle (CVPR'2019)](recognition/arcface_paddle)\n\nCommonly used network backbones are included in most of the methods, such as IResNet, MobilefaceNet, MobileNet, InceptionResNet_v2, DenseNet, etc..\n\n\n### Datasets\n\nThe training data includes, but not limited to the cleaned MS1M, VGG2 and CASIA-Webface datasets, which were already packed in MXNet binary format. Please [dataset](recognition/_datasets_) page for detail.\n\n### Evaluation\n\nWe provide standard IJB and Megaface evaluation pipelines in [evaluation](recognition/_evaluation_)\n\n\n### Pretrained Models\n\n**Please check [Model-Zoo](https://github.com/deepinsight/insightface/wiki/Model-Zoo) for more pretrained models.**\n\n### Third-party Re-implementation of ArcFace\n\n- TensorFlow: [InsightFace_TF](https://github.com/auroua/InsightFace_TF)\n- TensorFlow: [tf-insightface](https://github.com/AIInAi/tf-insightface)\n- TensorFlow:[insightface](https://github.com/Fei-Wang/insightface)\n- PyTorch: [InsightFace_Pytorch](https://github.com/TreB1eN/InsightFace_Pytorch)\n- PyTorch: [arcface-pytorch](https://github.com/ronghuaiyang/arcface-pytorch)\n- Caffe: [arcface-caffe](https://github.com/xialuxi/arcface-caffe)\n- Caffe: [CombinedMargin-caffe](https://github.com/gehaocool/CombinedMargin-caffe)\n- Tensorflow: [InsightFace-tensorflow](https://github.com/luckycallor/InsightFace-tensorflow)\n- TensorRT: [wang-xinyu/tensorrtx](https://github.com/wang-xinyu/tensorrtx)  \n- TensorRT: [InsightFace-REST](https://github.com/SthPhoenix/InsightFace-REST)\n- ONNXRuntime C++: [ArcFace-ONNXRuntime](https://github.com/DefTruth/lite.ai.toolkit/blob/main/lite/ort/cv/glint_arcface.cpp)\n- ONNXRuntime Go: [arcface-go](https://github.com/jack139/arcface-go)\n- MNN: [ArcFace-MNN](https://github.com/DefTruth/lite.ai.toolkit/blob/main/lite/mnn/cv/mnn_glint_arcface.cpp)\n- TNN: [ArcFace-TNN](https://github.com/DefTruth/lite.ai.toolkit/blob/main/lite/tnn/cv/tnn_glint_arcface.cpp)\n- NCNN: [ArcFace-NCNN](https://github.com/DefTruth/lite.ai.toolkit/blob/main/lite/ncnn/cv/ncnn_glint_arcface.cpp)\n\n## Face Detection\n\n### Introduction\n\n<div align=\"left\">\n  <img src=\"https://insightface.ai/assets/img/github/11513D05.jpg\" width=\"640\"/>\n</div>\n\nIn this module, we provide training data with annotation, network settings and loss designs for face detection training, evaluation and inference.\n\nThe supported methods are as follows:\n\n- [x] [RetinaFace (CVPR'2020)](detection/retinaface)\n- [x] [SCRFD (Arxiv'2021)](detection/scrfd)\n- [x] [blazeface_paddle](detection/blazeface_paddle)\n\n[RetinaFace](detection/retinaface) is a practical single-stage face detector which is accepted by [CVPR 2020](https://openaccess.thecvf.com/content_CVPR_2020/html/Deng_RetinaFace_Single-Shot_Multi-Level_Face_Localisation_in_the_Wild_CVPR_2020_paper.html). We provide training code, training dataset, pretrained models and evaluation scripts. \n\n[SCRFD](detection/scrfd) is an efficient high accuracy face detection approach which is initialy described in [Arxiv](https://arxiv.org/abs/2105.04714). We provide an easy-to-use pipeline to train high efficiency face detectors with NAS supporting.\n\n\n## Face Alignment\n\n### Introduction\n\n<div align=\"left\">\n  <img src=\"https://insightface.ai/assets/img/custom/thumb_sdunet.png\" width=\"600\"/>\n</div>\n\nIn this module, we provide datasets and training/inference pipelines for face alignment.\n\nSupported methods:\n\n- [x] [SDUNets (BMVC'2018)](alignment/heatmap)\n- [x] [SimpleRegression](alignment/coordinate_reg)\n\n\n[SDUNets](alignment/heatmap) is a heatmap based method which accepted on [BMVC](http://bmvc2018.org/contents/papers/0051.pdf).\n\n[SimpleRegression](alignment/coordinate_reg) provides very lightweight facial landmark models with fast coordinate regression. The input of these models is loose cropped face image while the output is the direct landmark coordinates.\n\n\n## Citation\n\nIf you find *InsightFace* useful in your research, please consider to cite the following related papers:\n\n```\n@inproceedings{ren2023pbidr,\n  title={Facial Geometric Detail Recovery via Implicit Representation},\n  author={Ren, Xingyu and Lattas, Alexandros and Gecer, Baris and Deng, Jiankang and Ma, Chao and Yang, Xiaokang},\n  booktitle={2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG)},  \n  year={2023}\n }\n\n@article{guo2021sample,\n  title={Sample and Computation Redistribution for Efficient Face Detection},\n  author={Guo, Jia and Deng, Jiankang and Lattas, Alexandros and Zafeiriou, Stefanos},\n  journal={arXiv preprint arXiv:2105.04714},\n  year={2021}\n}\n\n@inproceedings{gecer2021ostec,\n  title={OSTeC: One-Shot Texture Completion},\n  author={Gecer, Baris and Deng, Jiankang and Zafeiriou, Stefanos},\n  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  year={2021}\n}\n\n@inproceedings{an_2022_pfc_cvpr,\n  title={Killing Two Birds with One Stone: Efficient and Robust Training of Face Recognition CNNs by Partial FC},\n  author={An, Xiang and Deng, Jiangkang and Guo, Jia and Feng, Ziyong and Zhu, Xuhan and Jing, Yang and Tongliang, Liu},\n  booktitle={CVPR},\n  year={2022}\n}\n@inproceedings{an_2021_pfc_iccvw,\n  title={Partial FC: Training 10 Million Identities on a Single Machine},\n  author={An, Xiang and Zhu, Xuhan and Gao, Yuan and Xiao, Yang and Zhao, Yongle and Feng, Ziyong and Wu, Lan and Qin, Bin and Zhang, Ming and Zhang, Debing and Fu, Ying},\n  booktitle={ICCVW},\n  year={2021},\n}\n\n\n@inproceedings{deng2020subcenter,\n  title={Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces},\n  author={Deng, Jiankang and Guo, Jia and Liu, Tongliang and Gong, Mingming and Zafeiriou, Stefanos},\n  booktitle={Proceedings of the IEEE Conference on European Conference on Computer Vision},\n  year={2020}\n}\n\n@inproceedings{Deng2020CVPR,\ntitle = {RetinaFace: Single-Shot Multi-Level Face Localisation in the Wild},\nauthor = {Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},\nbooktitle = {CVPR},\nyear = {2020}\n}\n\n@inproceedings{guo2018stacked,\n  title={Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment},\n  author={Guo, Jia and Deng, Jiankang and Xue, Niannan and Zafeiriou, Stefanos},\n  booktitle={BMVC},\n  year={2018}\n}\n\n@article{deng2018menpo,\n  title={The Menpo benchmark for multi-pose 2D and 3D facial landmark localisation and tracking},\n  author={Deng, Jiankang and Roussos, Anastasios and Chrysos, Grigorios and Ververas, Evangelos and Kotsia, Irene and Shen, Jie and Zafeiriou, Stefanos},\n  journal={IJCV},\n  year={2018}\n}\n\n@inproceedings{deng2018arcface,\ntitle={ArcFace: Additive Angular Margin Loss for Deep Face Recognition},\nauthor={Deng, Jiankang and Guo, Jia and Niannan, Xue and Zafeiriou, Stefanos},\nbooktitle={CVPR},\nyear={2019}\n}\n```\n\n## Contributing\n\nMain contributors:\n\n- [Jia Guo](https://github.com/nttstar), ``guojia[at]gmail.com``\n- [Jiankang Deng](https://github.com/jiankangdeng) ``jiankangdeng[at]gmail.com``\n- [Xiang An](https://github.com/anxiangsir) ``anxiangsir[at]gmail.com``\n- [Jack Yu](https://github.com/szad670401) ``jackyu961127[at]gmail.com``\n- [Baris Gecer](https://barisgecer.github.io/) ``barisgecer[at]msn.com``\n"
        },
        {
          "name": "alignment",
          "type": "tree",
          "content": null
        },
        {
          "name": "attribute",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "challenges",
          "type": "tree",
          "content": null
        },
        {
          "name": "cpp-package",
          "type": "tree",
          "content": null
        },
        {
          "name": "detection",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "generation",
          "type": "tree",
          "content": null
        },
        {
          "name": "model_zoo",
          "type": "tree",
          "content": null
        },
        {
          "name": "parsing",
          "type": "tree",
          "content": null
        },
        {
          "name": "python-package",
          "type": "tree",
          "content": null
        },
        {
          "name": "recognition",
          "type": "tree",
          "content": null
        },
        {
          "name": "reconstruction",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.046875,
          "content": "Cython>=0.29.28\ncmake>=3.22.3    \nnumpy>=1.22.3\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "web-demos",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}