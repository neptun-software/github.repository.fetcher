{
  "metadata": {
    "timestamp": 1736561139674,
    "page": 85,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "stitionai/devika",
      "stars": 18733,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".assets",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.0263671875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/#use-with-ide\n.pdm.toml\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\nconfig.toml\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n.idea/\n\nnotes.md\ndata/"
        },
        {
          "name": "ARCHITECTURE.md",
          "type": "blob",
          "size": 12.4443359375,
          "content": "# Devika Architecture\n\nDevika is an advanced AI software engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve a given objective. This document provides a detailed technical overview of Devika's system architecture and how the various components work together.\n\n## Table of Contents\n\n1. [Overview](#overview)\n2. [Agent Core](#agent-core)\n3. [Agents](#agents)\n   - [Planner](#planner)\n   - [Researcher](#researcher) \n   - [Coder](#coder)\n   - [Action](#action)\n   - [Runner](#runner)\n   - [Feature](#feature)\n   - [Patcher](#patcher)\n   - [Reporter](#reporter)\n   - [Decision](#decision)\n4. [Language Models](#language-models)\n5. [Browser Interaction](#browser-interaction) \n6. [Project Management](#project-management)\n7. [Agent State Management](#agent-state-management)\n8. [Services](#services)\n9. [Utilities](#utilities)\n10. [Conclusion](#conclusion)\n\n## Overview\n\nAt a high level, Devika consists of the following key components:\n\n- **Agent Core**: Orchestrates the overall AI planning, reasoning and execution process. Communicates with various sub-agents.\n- **Agents**: Specialized sub-agents that handle specific tasks like planning, research, coding, patching, reporting etc.  \n- **Language Models**: Leverages large language models (LLMs) like Claude, GPT-4, GPT-3 for natural language understanding and generation.\n- **Browser Interaction**: Enables web browsing, information gathering, and interaction with web elements.\n- **Project Management**: Handles organization and persistence of project-related data. \n- **Agent State Management**: Tracks and persists the dynamic state of the AI agent across interactions.\n- **Services**: Integrations with external services like GitHub, Netlify for enhanced capabilities.\n- **Utilities**: Supporting modules for configuration, logging, vector search, PDF generation etc.\n\nLet's dive into each of these components in more detail.\n\n## Agent Core\n\nThe `Agent` class serves as the central engine that drives Devika's AI planning and execution loop. Here's how it works:\n\n1. When a user provides a high-level prompt, the `execute` method is invoked on the Agent. \n2. The prompt is first passed to the Planner agent to generate a step-by-step plan.\n3. The Researcher agent then takes this plan and extracts relevant search queries and context.\n4. The Agent performs web searches using Bing Search API and crawls the top results. \n5. The raw crawled content is passed through the Formatter agent to extract clean, relevant information.\n6. This researched context, along with the step-by-step plan, is fed to the Coder agent to generate code.\n7. The generated code is saved to the project directory on disk.\n8. If the user interacts further with a follow-up prompt, the `subsequent_execute` method is invoked.\n9. The Action agent determines the appropriate action to take based on the user's message (run code, deploy, write tests, add feature, fix bug, write report etc.)\n10. The corresponding specialized agent is invoked to perform the action (Runner, Feature, Patcher, Reporter).\n11. Results are communicated back to the user and the project files are updated.\n\nThroughout this process, the Agent Core is responsible for:\n- Managing conversation history and project-specific context\n- Updating agent state and internal monologue \n- Accumulating context keywords across agent prompts\n- Emulating the \"thinking\" process of the AI through timed agent state updates\n- Handling special commands through the Decision agent (e.g. git clone, browser interaction session)\n\n## Agents\n\nDevika's cognitive abilities are powered by a collection of specialized sub-agents. Each agent is implemented as a separate Python class. Agents communicate with the underlying LLMs through prompt templates defined in Jinja2 format. Key agents include:\n\n### Planner\n- Generates a high-level step-by-step plan based on the user's prompt\n- Extracts focus area and provides a summary\n- Uses few-shot prompting to provide examples of the expected response format\n\n### Researcher\n- Takes the generated plan and extracts relevant search queries \n- Ranks and filters queries based on relevance and specificity\n- Prompts the user for additional context if required\n- Aims to maximize information gain while minimizing number of searches\n\n### Coder\n- Generates code based on the step-by-step plan and researched context\n- Segments code into appropriate files and directories\n- Includes informative comments and documentation\n- Handles a variety of languages and frameworks\n- Validates code syntax and style\n\n### Action\n- Determines the appropriate action to take based on the user's follow-up prompt\n- Maps user intent to a specific action keyword (run, test, deploy, fix, implement, report)\n- Provides a human-like confirmation of the action to the user\n\n### Runner\n- Executes the written code in a sandboxed environment \n- Handles different OS environments (Mac, Linux, Windows)\n- Streams command output to user in real-time\n- Gracefully handles errors and exceptions\n\n### Feature\n- Implements a new feature based on user's specification\n- Modifies existing project files while maintaining code structure and style\n- Performs incremental testing to verify feature is working as expected\n\n### Patcher\n- Debugs and fixes issues based on user's description or error message\n- Analyzes existing code to identify potential root causes\n- Suggests and implements fix, with explanation of the changes made\n\n### Reporter\n- Generates a comprehensive report summarizing the project\n- Includes high-level overview, technical design, setup instructions, API docs etc.\n- Formats report in a clean, readable structure with table of contents\n- Exports report as a PDF document\n\n### Decision\n- Handles special command-like instructions that don't fit other agents\n- Maps commands to specific functions (git clone, browser interaction etc.)\n- Executes the corresponding function with provided arguments\n\nEach agent follows a common pattern:\n1. Prepare a prompt by rendering the Jinja2 template with current context\n2. Query the LLM to get a response based on the prompt\n3. Validate and parse the LLM's response to extract structured output\n4. Perform any additional processing or side-effects (e.g. save to disk)\n5. Return the result to the Agent Core for further action\n\nAgents aim to be stateless and idempotent where possible. State and history is managed by the Agent Core and passed into the agents as needed. This allows for a modular, composable design.\n\n## Language Models\n\nDevika's natural language processing capabilities are driven by state-of-the-art LLMs. The `LLM` class provides a unified interface to interact with different language models:\n\n- **Claude** (Anthropic): Claude models like claude-v1.3, claude-instant-v1.0 etc.\n- **GPT-4/GPT-3** (OpenAI): Models like gpt-4, gpt-3.5-turbo etc.\n- **Self-hosted models** (via [Ollama](https://ollama.com/)): Allows using open-source models in a self-hosted environment\n\nThe `LLM` class abstracts out the specifics of each provider's API, allowing agents to interact with the models in a consistent way. It supports:\n- Listing available models\n- Generating completions based on a prompt\n- Tracking and accumulating token usage over time\n\nChoosing the right model for a given use case depends on factors like desired quality, speed, cost etc. The modular design allows swapping out models easily.\n\n## Browser Interaction\n\nDevika can interact with webpages in an automated fashion to gather information and perform actions. This is powered by the `Browser` and `Crawler` classes.\n\nThe `Browser` class uses Playwright to provide high-level web automation primitives:\n- Spawning a browser instance (Chromium)\n- Navigating to a URL\n- Querying DOM elements \n- Extracting page content as text, Markdown, PDF etc.\n- Taking a screenshot of the page\n\nThe `Crawler` class defines an agent that can interact with a webpage based on natural language instructions. It leverages:\n- Pre-defined browser actions like scroll, click, type etc.\n- A prompt template that provides examples of how to use these actions\n- LLM to determine the best action to take based on current page content and objective\n\nThe `start_interaction` function sets up a loop where:\n1. The current page content and objective is passed to the LLM \n2. The LLM returns the next best action to take (e.g. \"CLICK 12\" or \"TYPE 7 machine learning\")\n3. The Crawler executes this action on the live page\n4. The process repeats from the updated page state\n\nThis allows performing a sequence of actions to achieve a higher-level objective (e.g. research a topic, fill out a form, interact with an app etc.)\n\n## Project Management\n\nThe `ProjectManager` class is responsible for creating, updating and querying projects and their associated metadata. Key functions include:\n\n- Creating a new project and initializing its directory structure\n- Deleting a project and its associated files\n- Adding a message to a project's conversation history\n- Retrieving messages for a given project\n- Getting the latest user/AI message in a conversation\n- Listing all projects\n- Zipping a project's files for export\n\nProject metadata is persisted in a SQLite database using SQLModel. The `Projects` table stores:\n- Project name\n- JSON-serialized conversation history\n\nThis allows the agent to work on multiple projects simultaneously and retain conversation history across sessions.\n\n## Agent State Management\n\nAs the AI agent works on a task, we need to track and display its internal state to the user. The `AgentState` class handles this by providing an interface to:\n\n- Initialize a new agent state \n- Add a state to the current sequence of states for a project\n- Update the latest state for a project\n- Query the latest state or entire state history for a project\n- Mark the agent as active/inactive or task as completed\n\nAgent state includes information like:\n- Current step or action being executed\n- Internal monologue reflecting the agent's current \"thoughts\"\n- Browser interactions (URL visited, screenshot)\n- Terminal interactions (command executed, output)\n- Token usage so far\n\nLike projects, agent states are also persisted in the SQLite DB using SQLModel. The `AgentStateModel` table stores:\n- Project name\n- JSON-serialized list of states\n\nHaving a persistent log of agent states is useful for:\n- Providing real-time visibility to the user\n- Auditing and debugging agent behavior\n- Resuming from interruptions or failures\n\n## Services\n\nDevika integrates with external services to augment its capabilities:\n\n- **GitHub**: Performing git operations like clone/pull, listing repos/commits/files etc.\n- **Netlify**: Deploying web apps and sites seamlessly\n\nThe `GitHub` and `Netlify` classes provide lightweight wrappers around the respective service APIs. \nThey handle authentication, making HTTP requests, and parsing responses.\n\nThis allows Devika to perform actions like:\n- Cloning a repo given a GitHub URL\n- Listing a user's GitHub repos \n- Creating a new Netlify site\n- Deploying a directory to Netlify \n- Providing the deployed site URL to the user\n\nIntegrations are done in a modular way so that new services can be added easily.\n\n## Utilities  \n\nDevika makes use of several utility modules to support its functioning:\n\n- `Config`: Loads and provides access to configuration settings (API keys, folder paths etc.) \n- `Logger`: Sets up logging to console and file, with support for log levels and colors\n- `ReadCode`: Recursively reads code files in a directory and converts them into a Markdown format\n- `SentenceBERT`: Extracts keywords and semantic information from text using SentenceBERT embeddings\n- `Experts`: A collection of domain-specific knowledge bases to assist in certain areas (e.g. webdev, physics, chemistry, math)\n\nThe utility modules aim to provide reusable functionality that is used across different parts of the system.\n\n## Conclusion\n\nDevika is a complex system that combines multiple AI and automation techniques to deliver an intelligent programming assistant. Key design principles include:\n\n- Modularity: Breaking down functionality into specialized agents and services\n- Flexibility: Supporting different LLMs, services and domains in a pluggable fashion  \n- Persistence: Storing project and agent state in a DB to enable pause/resume and auditing\n- Transparency: Surfacing agent thought process and interactions to user in real-time\n\nBy understanding how the different components work together, we can extend, optimize and scale Devika to take on increasingly sophisticated software engineering tasks. The agent-based architecture provides a strong foundation to build more advanced AI capabilities in the future.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.0390625,
          "content": "# Welcome Contributors\nWe welcome contributions to enhance Devika's capabilities and improve its performance. To report bugs, create a [GitHub issue](https://github.com/stitionai/devika/issues).\n\n> Before contributing, read through the existing issues and pull requests to see if someone else is already working on something similar. That way you can avoid duplicating efforts.\n\nTo contribute, please follow these steps:\n\n1. Fork the Devika repository on GitHub.\n2. Create a new branch for your feature or bug fix.\n3. Make your changes and ensure that the code passes all tests.\n4. Submit a pull request describing your changes and their benefits.\n\n\n### Pull Request Guidelines\nWhen submitting a pull request, please follow these guidelines:\n\n1. **Title**: please include following prefixes: \n   - `Feature:` for new features\n   - `Fix:` for bug fixes\n   - `Docs:` for documentation changes\n   - `Refactor:` for code refactoring\n   - `Improve:` for performance improvements\n   - `Other:` for other changes\n\n   for example: \n      - `Feature: added new feature to the code`\n      - `Fix: fixed the bug in the code`\n\n2. **Description**: Provide a clear and detailed description of your changes in the pull request. Explain the problem you are solving, the approach you took, and any potential side effects or limitations of your changes.\n3. **Documentation**: Update the relevant documentation to reflect your changes. This includes the README file, code comments, and any other relevant documentation.\n4. **Dependencies**: If your changes require new dependencies, ensure that they are properly documented and added to the `requirements.txt` or `package.json` files.\n5. if the pull request does not meet the above guidelines, it may be closed without merging.\n\n\n**Note**: Please ensure that you have the latest version of the code before creating a pull request. If you have an existing fork, just sync your fork with the latest version of the Devika repository.\n\n\nPlease adhere to the coding conventions, maintain clear documentation, and provide thorough testing for your contributions.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0390625,
          "content": "MIT License\n\nCopyright (c) 2024 stition\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.779296875,
          "content": "\n.PHONY = setup deps compose-up compose-down compose-destroy\n\n# to check if docker is installed on the machine \nDOCKER := $(shell command -v docker)\nDOCKER_COMPOSE := $(shell command -v docker-compose)\ndeps:\nifndef DOCKER\n\t@echo \"Docker is not available. Please install docker\"\n\t@echo \"try running sudo apt-get install docker\"\n\t@exit 1\nendif\nifndef DOCKER_COMPOSE\n\t@echo \"docker-compose is not available. Please install docker-compose\"\n\t@echo \"try running sudo apt-get install docker-compose\"\n\t@exit 1\nendif\n\nsetup:\n\tsh +x build\n\ncompose-down: deps\n\tdocker volume ls\n\tdocker-compose ps\n\tdocker images\n\tdocker-compose down;\n\ncompose-up: deps compose-down\n\tdocker-compose up --build\n\ncompose-destroy: deps\n\tdocker images | grep -i devika | awk '{print $$3}' | xargs docker rmi -f\n\tdocker volume prune"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.7978515625,
          "content": "<p align=\"center\">\n  <img src=\".assets/devika-avatar.png\" alt=\"Devika Logo\" width=\"250\">\n</p>\n\n<h1 align=\"center\">🚀 Devika - Agentic AI Software Engineer 👩‍💻</h1>\n\n![devika screenshot](.assets/devika-screenshot.png)\n\n> [!IMPORTANT]  \n> This project is currently in a very early development/experimental stage. There are a lot of unimplemented/broken features at the moment. Contributions are welcome to help out with the progress!\n\n## Table of Contents\n\n- [About](#about)\n- [Key Features](#key-features)\n- [System Architecture](#system-architecture)\n- [Getting Started](#getting-started)\n  - [Requirements](#requirements)\n  - [Installation](#installation)\n  - [How to use](#how-to-use)\n- [Configuration](#configuration)\n- [Contributing](#contributing)\n- [Help and Support](#help-and-support)\n- [License](#license)\n\n## About\n\nDevika is an advanced AI software engineer that can understand high-level human instructions, break them down into steps, research relevant information, and write code to achieve the given objective. Devika utilizes large language models, planning and reasoning algorithms, and web browsing abilities to intelligently develop software.\n\nDevika aims to revolutionize the way we build software by providing an AI pair programmer who can take on complex coding tasks with minimal human guidance. Whether you need to create a new feature, fix a bug, or develop an entire project from scratch, Devika is here to assist you.\n\n> [!NOTE]\n> Devika is modeled after [Devin](https://www.cognition-labs.com/introducing-devin) by Cognition AI. This project aims to be an open-source alternative to Devin with an \"overly ambitious\" goal to meet the same score as Devin in the [SWE-bench](https://www.swebench.com/) Benchmarks... and eventually beat it?\n\n## Demos\n\nhttps://github.com/stitionai/devika/assets/26198477/cfed6945-d53b-4189-9fbe-669690204206\n\n## Key Features\n\n- 🤖 Supports **Claude 3**, **GPT-4**, **Gemini**, **Mistral** , **Groq** and **Local LLMs** via [Ollama](https://ollama.com). For optimal performance: Use the **Claude 3** family of models.\n- 🧠 Advanced AI planning and reasoning capabilities\n- 🔍 Contextual keyword extraction for focused research\n- 🌐 Seamless web browsing and information gathering\n- 💻 Code writing in multiple programming languages\n- 📊 Dynamic agent state tracking and visualization\n- 💬 Natural language interaction via chat interface\n- 📂 Project-based organization and management\n- 🔌 Extensible architecture for adding new features and integrations\n\n## System Architecture\n\nRead [**README.md**](docs/architecture) for the detailed documentation.\n\n\n## Getting Started\n\n### Requirements\n```\nVersion's requirements\n  - Python >= 3.10 and < 3.12\n  - NodeJs >= 18\n  - bun\n```\n\n- Install uv - Python Package manager [download](https://github.com/astral-sh/uv)\n- Install bun - JavaScript runtime [download](https://bun.sh/docs/installation)\n- For ollama [ollama setup guide](docs/Installation/ollama.md) (optinal: if you don't want to use the local models then you can skip this step)\n- For API models, configure the API keys via setting page in UI.\n\n\n### Installation\n\nTo install Devika, follow these steps:\n\n1. Clone the Devika repository:\n   ```bash\n   git clone https://github.com/stitionai/devika.git\n   ```\n2. Navigate to the project directory:\n   ```bash\n   cd devika\n   ```\n3. Create a virtual environment and install the required dependencies (you can use any virtual environment manager):\n   ```bash\n   uv venv\n   \n   # On macOS and Linux.\n   source .venv/bin/activate\n\n   # On Windows.\n   .venv\\Scripts\\activate\n\n   uv pip install -r requirements.txt\n   ```\n4. Install the playwright for browsering capabilities:\n   ```bash\n   playwright install --with-deps # installs browsers in playwright (and their deps) if required\n   ```\n5. Start the Devika server:\n   ```bash\n   python devika.py\n   ```\n6. if everything is working fine, you see the following output:\n   ```bash\n   root: INFO   : Devika is up and running!\n   ```\n7. Now, for frontend, open a new terminal and navigate to the `ui` directory:\n   ```bash\n   cd ui/\n   bun install\n   bun run start\n   ```\n8. Access the Devika web interface by opening a browser and navigating to `http://127.0.0.1:3001`\n\n### how to use\n\nTo start using Devika, follow these steps:\n\n1. Open the Devika web interface in your browser.\n2. To create a project, click on 'select project' and then click on 'new project'.\n3. Select the search engine and model configuration for your project.\n4. In the chat interface, provide a high-level objective or task description for Devika to work on.\n5. Devika will process your request, break it down into steps, and start working on the task.\n6. Monitor Devika's progress, view generated code, and provide additional guidance or feedback as needed.\n7. Once Devika completes the task, review the generated code and project files.\n8. Iterate and refine the project as desired by providing further instructions or modifications.\n\n## Configuration\n\nDevika requires certain configuration settings and API keys to function properly:\n\nwhen you first time run Devika, it will create a `config.toml` file for you in the root directory. You can configure the following settings in the settings page via UI:\n\n- API KEYS\n   - `BING`: Your Bing Search API key for web searching capabilities.\n   - `GOOGLE_SEARCH`: Your Google Search API key for web searching capabilities.\n   - `GOOGLE_SEARCH_ENGINE_ID`: Your Google Search Engine ID for web searching using Google.\n   - `OPENAI`: Your OpenAI API key for accessing GPT models.\n   - `GEMINI`: Your Gemini API key for accessing Gemini models.\n   - `CLAUDE`: Your Anthropic API key for accessing Claude models.\n   - `MISTRAL`: Your Mistral API key for accessing Mistral models.\n   - `GROQ`: Your Groq API key for accessing Groq models.\n   - `NETLIFY`: Your Netlify API key for deploying and managing web projects.\n\n- API_ENDPOINTS\n   - `BING`: The Bing API endpoint for web searching.\n   - `GOOGLE`: The Google API endpoint for web searching.\n   - `OLLAMA`: The Ollama API endpoint for accessing Local LLMs.\n   - `OPENAI`: The OpenAI API endpoint for accessing OpenAI models.\n\nMake sure to keep your API keys secure and do not share them publicly. For setting up the Bing and Google search API keys, follow the instructions in the [search engine setup](docs/Installation/search_engine.md)\n\n\n## Contributing\n\nWe welcome contributions to enhance Devika's capabilities and improve its performance. To contribute, please see the [`CONTRIBUTING.md`](CONTRIBUTING.md) file for steps.\n\n## Help and Support\n\nIf you have any questions, feedback, or suggestions, please feel free to reach out to us. you can raise an issue in the [issue tracker](https://github.com/stitionai/devika/issues) or join the [discussions](https://github.com/stitionai/devika/discussions) for general discussions.\n\nWe also have a Discord server for the Devika community, where you can connect with other users, share your experiences, ask questions, and collaborate on the project. To join the Devika community Discord server, [click here](https://discord.gg/CYRp43878y).\n\n## License\n\nDevika is released under the [MIT License](https://opensource.org/licenses/MIT). See the `LICENSE` file for more information.\n\n## Star History\n\n<div align=\"center\">\n<a href=\"https://star-history.com/#stitionai/devika&Date\">\n <picture>\n   <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://api.star-history.com/svg?repos=stitionai/devika&type=Date&theme=dark\" />\n   <source media=\"(prefers-color-scheme: light)\" srcset=\"https://api.star-history.com/svg?repos=stitionai/devika&type=Date\" />\n   <img alt=\"Star History Chart\" src=\"https://api.star-history.com/svg?repos=stitionai/devika&type=Date\" />\n </picture>\n</a>\n</div>\n\n---\n\nWe hope you find Devika to be a valuable tool in your software development journey. If you have any questions, feedback, or suggestions, please don't hesitate to reach out. Happy coding with Devika!\n"
        },
        {
          "name": "ROADMAP.md",
          "type": "blob",
          "size": 0.5068359375,
          "content": "# Roadmap\n\n- [ ] Create an extensive testing suite for all [Agents](https://github.com/stitionai/devika/tree/main/src/agents).\n- [ ] Catch down on all runtime errors and prepare for Project Devika stable release.\n- [ ] Document and implement easy cross-platform installation/setup scripts and packages.\n- [ ] Create tutorial videos on the installation steps, setup, and usage for Windows, Linux, and MacOS.\n- [ ] Focusing on the Claude 3 Opus model, test Devika on the [SWE-Bench](https://www.swebench.com/) benchmarks."
        },
        {
          "name": "app.dockerfile",
          "type": "blob",
          "size": 0.8486328125,
          "content": "FROM debian:12\n\n# setting up build variable\nARG VITE_API_BASE_URL\nENV VITE_API_BASE_URL=${VITE_API_BASE_URL}\n\n# setting up os env\nUSER root\nWORKDIR /home/nonroot/client\nRUN groupadd -r nonroot && useradd -r -g nonroot -d /home/nonroot/client -s /bin/bash nonroot\n\n# install node js \nRUN apt-get update && apt-get upgrade -y\nRUN apt-get install -y build-essential software-properties-common curl sudo wget git\nRUN curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -\nRUN apt-get install nodejs\n\n# copying devika app client only\nCOPY ui /home/nonroot/client/ui\nCOPY src /home/nonroot/client/src\nCOPY config.toml /home/nonroot/client/\n\nRUN cd ui && npm install && npm install -g npm && npm install -g bun\nRUN chown -R nonroot:nonroot /home/nonroot/client\n\nUSER nonroot\nWORKDIR /home/nonroot/client/ui\n\nENTRYPOINT [ \"npx\", \"bun\", \"run\", \"dev\", \"--\", \"--host\" ]"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "devika.dockerfile",
          "type": "blob",
          "size": 1.19140625,
          "content": "FROM debian:12\n\n# setting up os env\nUSER root\nWORKDIR /home/nonroot/devika\nRUN groupadd -r nonroot && useradd -r -g nonroot -d /home/nonroot/devika -s /bin/bash nonroot\n\nENV PYTHONUNBUFFERED 1\nENV PYTHONDONTWRITEBYTECODE 1\n\n# setting up python3\nRUN apt-get update && apt-get upgrade -y\nRUN apt-get install -y build-essential software-properties-common curl sudo wget git\nRUN apt-get install -y python3 python3-pip\nRUN curl -fsSL https://astral.sh/uv/install.sh | sudo -E bash -\nRUN $HOME/.cargo/bin/uv venv\nENV PATH=\"/home/nonroot/devika/.venv/bin:$HOME/.cargo/bin:$PATH\"\n\n# copy devika python engine only\nRUN $HOME/.cargo/bin/uv venv\nCOPY requirements.txt /home/nonroot/devika/\nRUN UV_HTTP_TIMEOUT=100000 $HOME/.cargo/bin/uv pip install -r requirements.txt \n\nRUN playwright install-deps chromium\nRUN playwright install chromium\n\nCOPY src /home/nonroot/devika/src\nCOPY config.toml /home/nonroot/devika/\nCOPY sample.config.toml /home/nonroot/devika/\nCOPY devika.py /home/nonroot/devika/\nRUN chown -R nonroot:nonroot /home/nonroot/devika\n\nUSER nonroot\nWORKDIR /home/nonroot/devika\nENV PATH=\"/home/nonroot/devika/.venv/bin:$HOME/.cargo/bin:$PATH\"\nRUN mkdir /home/nonroot/devika/db\n\nENTRYPOINT [ \"python3\", \"-m\", \"devika\" ]\n"
        },
        {
          "name": "devika.py",
          "type": "blob",
          "size": 6.216796875,
          "content": "\"\"\"\n    DO NOT REARRANGE THE ORDER OF THE FUNCTION CALLS AND VARIABLE DECLARATIONS\n    AS IT MAY CAUSE IMPORT ERRORS AND OTHER ISSUES\n\"\"\"\nfrom gevent import monkey\nmonkey.patch_all()\nfrom src.init import init_devika\ninit_devika()\n\n\nfrom flask import Flask, request, jsonify, send_file\nfrom flask_cors import CORS\nfrom src.socket_instance import socketio, emit_agent\nimport os\nimport logging\nfrom threading import Thread\nimport tiktoken\n\nfrom src.apis.project import project_bp\nfrom src.config import Config\nfrom src.logger import Logger, route_logger\nfrom src.project import ProjectManager\nfrom src.state import AgentState\nfrom src.agents import Agent\nfrom src.llm import LLM\n\n\napp = Flask(__name__)\nCORS(app, resources={r\"/*\": {\"origins\": # Change the origin to your frontend URL\n                             [\n                                 \"https://localhost:3000\",\n                                 \"http://localhost:3000\",\n                                 ]}}) \napp.register_blueprint(project_bp)\nsocketio.init_app(app)\n\n\nlog = logging.getLogger(\"werkzeug\")\nlog.disabled = True\n\n\nTIKTOKEN_ENC = tiktoken.get_encoding(\"cl100k_base\")\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nmanager = ProjectManager()\nAgentState = AgentState()\nconfig = Config()\nlogger = Logger()\n\n\n# initial socket\n@socketio.on('socket_connect')\ndef test_connect(data):\n    print(\"Socket connected :: \", data)\n    emit_agent(\"socket_response\", {\"data\": \"Server Connected\"})\n\n\n@app.route(\"/api/data\", methods=[\"GET\"])\n@route_logger(logger)\ndef data():\n    project = manager.get_project_list()\n    models = LLM().list_models()\n    search_engines = [\"Bing\", \"Google\", \"DuckDuckGo\"]\n    return jsonify({\"projects\": project, \"models\": models, \"search_engines\": search_engines})\n\n\n@app.route(\"/api/messages\", methods=[\"POST\"])\ndef get_messages():\n    data = request.json\n    project_name = data.get(\"project_name\")\n    messages = manager.get_messages(project_name)\n    return jsonify({\"messages\": messages})\n\n\n# Main socket\n@socketio.on('user-message')\ndef handle_message(data):\n    logger.info(f\"User message: {data}\")\n    message = data.get('message')\n    base_model = data.get('base_model')\n    project_name = data.get('project_name')\n    search_engine = data.get('search_engine').lower()\n\n    agent = Agent(base_model=base_model, search_engine=search_engine)\n\n    state = AgentState.get_latest_state(project_name)\n    if not state:\n        thread = Thread(target=lambda: agent.execute(message, project_name))\n        thread.start()\n    else:\n        if AgentState.is_agent_completed(project_name):\n            thread = Thread(target=lambda: agent.subsequent_execute(message, project_name))\n            thread.start()\n        else:\n            emit_agent(\"info\", {\"type\": \"warning\", \"message\": \"previous agent doesn't completed it's task.\"})\n            last_state = AgentState.get_latest_state(project_name)\n            if last_state[\"agent_is_active\"] or not last_state[\"completed\"]:\n                thread = Thread(target=lambda: agent.execute(message, project_name))\n                thread.start()\n            else:\n                thread = Thread(target=lambda: agent.subsequent_execute(message, project_name))\n                thread.start()\n\n@app.route(\"/api/is-agent-active\", methods=[\"POST\"])\n@route_logger(logger)\ndef is_agent_active():\n    data = request.json\n    project_name = data.get(\"project_name\")\n    is_active = AgentState.is_agent_active(project_name)\n    return jsonify({\"is_active\": is_active})\n\n\n@app.route(\"/api/get-agent-state\", methods=[\"POST\"])\n@route_logger(logger)\ndef get_agent_state():\n    data = request.json\n    project_name = data.get(\"project_name\")\n    agent_state = AgentState.get_latest_state(project_name)\n    return jsonify({\"state\": agent_state})\n\n\n@app.route(\"/api/get-browser-snapshot\", methods=[\"GET\"])\n@route_logger(logger)\ndef browser_snapshot():\n    snapshot_path = request.args.get(\"snapshot_path\")\n    return send_file(snapshot_path, as_attachment=True)\n\n\n@app.route(\"/api/get-browser-session\", methods=[\"GET\"])\n@route_logger(logger)\ndef get_browser_session():\n    project_name = request.args.get(\"project_name\")\n    agent_state = AgentState.get_latest_state(project_name)\n    if not agent_state:\n        return jsonify({\"session\": None})\n    else:\n        browser_session = agent_state[\"browser_session\"]\n        return jsonify({\"session\": browser_session})\n\n\n@app.route(\"/api/get-terminal-session\", methods=[\"GET\"])\n@route_logger(logger)\ndef get_terminal_session():\n    project_name = request.args.get(\"project_name\")\n    agent_state = AgentState.get_latest_state(project_name)\n    if not agent_state:\n        return jsonify({\"terminal_state\": None})\n    else:\n        terminal_state = agent_state[\"terminal_session\"]\n        return jsonify({\"terminal_state\": terminal_state})\n\n\n@app.route(\"/api/run-code\", methods=[\"POST\"])\n@route_logger(logger)\ndef run_code():\n    data = request.json\n    project_name = data.get(\"project_name\")\n    code = data.get(\"code\")\n    # TODO: Implement code execution logic\n    return jsonify({\"message\": \"Code execution started\"})\n\n\n@app.route(\"/api/calculate-tokens\", methods=[\"POST\"])\n@route_logger(logger)\ndef calculate_tokens():\n    data = request.json\n    prompt = data.get(\"prompt\")\n    tokens = len(TIKTOKEN_ENC.encode(prompt))\n    return jsonify({\"token_usage\": tokens})\n\n\n@app.route(\"/api/token-usage\", methods=[\"GET\"])\n@route_logger(logger)\ndef token_usage():\n    project_name = request.args.get(\"project_name\")\n    token_count = AgentState.get_latest_token_usage(project_name)\n    return jsonify({\"token_usage\": token_count})\n\n\n@app.route(\"/api/logs\", methods=[\"GET\"])\ndef real_time_logs():\n    log_file = logger.read_log_file()\n    return jsonify({\"logs\": log_file})\n\n\n@app.route(\"/api/settings\", methods=[\"POST\"])\n@route_logger(logger)\ndef set_settings():\n    data = request.json\n    config.update_config(data)\n    return jsonify({\"message\": \"Settings updated\"})\n\n\n@app.route(\"/api/settings\", methods=[\"GET\"])\n@route_logger(logger)\ndef get_settings():\n    configs = config.get_config()\n    return jsonify({\"settings\": configs})\n\n\n@app.route(\"/api/status\", methods=[\"GET\"])\n@route_logger(logger)\ndef status():\n    return jsonify({\"status\": \"server is running!\"})\n\nif __name__ == \"__main__\":\n    logger.info(\"Devika is up and running!\")\n    socketio.run(app, debug=False, port=1337, host=\"0.0.0.0\")\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 1.1875,
          "content": "version: \"3.9\"\n\nservices:\n  ollama-service:\n    image: ollama/ollama:latest\n    expose:\n      - 11434\n    ports:\n      - 11434:11434\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:11434/ || exit 1\"]\n      interval: 5s\n      timeout: 30s\n      retries: 5\n      start_period: 30s\n    networks:\n      - devika-subnetwork\n\n  devika-backend-engine:\n    build:\n      context: .\n      dockerfile: devika.dockerfile\n    depends_on:\n      - ollama-service\n    expose:\n      - 1337\n    ports:\n      - 1337:1337\n    environment:\n      - OLLAMA_HOST=http://ollama-service:11434\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:1337/ || exit 1\"]\n      interval: 5s\n      timeout: 30s\n      retries: 5\n      start_period: 30s\n    volumes:\n      - devika-backend-dbstore:/home/nonroot/devika/db\n    networks:\n      - devika-subnetwork\n\n  devika-frontend-app:\n    build:\n      context: .\n      dockerfile: app.dockerfile\n      args:\n        - VITE_API_BASE_URL=http://127.0.0.1:1337\n    depends_on:\n      - devika-backend-engine\n    expose:\n      - 3000\n    ports:\n      - 3000:3000\n    networks:\n      - devika-subnetwork\n\nnetworks:\n  devika-subnetwork:\n\nvolumes:\n  devika-backend-dbstore:"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3310546875,
          "content": "flask\nflask-cors\ntoml\nurllib3\nrequests\ncolorama\nfastlogging\nJinja2\nmistletoe\nmarkdownify\npdfminer.six\nplaywright\npytest-playwright\ntiktoken\nollama\nopenai\nanthropic\ngoogle-generativeai\nsqlmodel\nkeybert\nGitPython\nnetlify-py\nMarkdown\nxhtml2pdf\nmistralai\nFlask-SocketIO\neventlet\ngroq\nduckduckgo-search\norjson\ngevent\ngevent-websocket\ncurl_cffi\n"
        },
        {
          "name": "sample.config.toml",
          "type": "blob",
          "size": 0.8212890625,
          "content": "[STORAGE]\nSQLITE_DB = \"data/db/devika.db\"\nSCREENSHOTS_DIR = \"data/screenshots\"\nPDFS_DIR = \"data/pdfs\"\nPROJECTS_DIR = \"data/projects\"\nLOGS_DIR = \"data/logs\"\nREPOS_DIR = \"data/repos\"\n\n[API_KEYS]\nBING = \"<YOUR_BING_API_KEY>\"\nGOOGLE_SEARCH = \"<YOUR_GOOGLE_SEARCH_API_KEY>\"\nGOOGLE_SEARCH_ENGINE_ID = \"<YOUR_GOOGLE_SEARCH_ENGINE_ID>\"\nCLAUDE = \"<YOUR_CLAUDE_API_KEY>\"\nOPENAI = \"<YOUR_OPENAI_API_KEY>\"\nGEMINI = \"<YOUR_GEMINI_API_KEY>\"\nMISTRAL = \"<YOUR_MISTRAL_API_KEY>\"\nGROQ = \"<YOUR_GROQ_API_KEY>\"\nNETLIFY = \"<YOUR_NETLIFY_API_KEY>\"\n\n[API_ENDPOINTS]\nBING = \"https://api.bing.microsoft.com/v7.0/search\"\nGOOGLE = \"https://www.googleapis.com/customsearch/v1\"\nOLLAMA = \"http://127.0.0.1:11434\"\n\nLM_STUDIO = \"http://localhost:1234/v1\"\nOPENAI = \"https://api.openai.com/v1\"\n\n\n[LOGGING]\nLOG_REST_API = \"true\"\nLOG_PROMPTS = \"false\"\n\n[TIMEOUT]\nINFERENCE = 60"
        },
        {
          "name": "setup.sh",
          "type": "blob",
          "size": 0.1162109375,
          "content": "#!/bin/bash\n\npip3 install -r requirements.txt\nplaywright install\npython3 -m playwright install-deps\ncd ui/\nbun install\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "ui",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}