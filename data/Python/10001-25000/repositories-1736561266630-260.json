{
  "metadata": {
    "timestamp": 1736561266630,
    "page": 260,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PaddlePaddle/PaddleDetection",
      "stars": 12988,
      "defaultBranch": "release/2.8",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.119140625,
          "content": "# Virtualenv\n/.venv/\n/venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n.ipynb_checkpoints/\n*.py[cod]\n\n# C extensions\n*.so\n\n# json file\n*.json\n\n# log file\n*.log\n\n# Distribution / packaging\n/bin/\n*build/\n/develop-eggs/\n*dist/\n/eggs/\n/lib/\n/lib64/\n/output/\n/inference_model/\n/output_inference/\n/parts/\n/sdist/\n/var/\n*.egg-info/\n/.installed.cfg\n/*.egg\n/.eggs\n\n# AUTHORS and ChangeLog will be generated while packaging\n/AUTHORS\n/ChangeLog\n\n# BCloud / BuildSubmitter\n/build_submitter.*\n/logger_client_log\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\n.tox/\n.coverage\n.cache\n.pytest_cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n\n# Sphinx documentation\n/docs/_build/\n\n*.tar\n*.pyc\n\n.idea/\n\ndataset/coco/annotations\ndataset/coco/train2017\ndataset/coco/val2017\ndataset/voc/VOCdevkit\ndataset/fruit/fruit-detection/\ndataset/voc/test.txt\ndataset/voc/trainval.txt\ndataset/wider_face/WIDER_test\ndataset/wider_face/WIDER_train\ndataset/wider_face/WIDER_val\ndataset/wider_face/wider_face_split\ndataset/mot/*\ndataset/mot/**\n\nlog/*\n\nppdet/version.py\n\n# NPU meta folder\nkernel_meta/\n\n# MAC\n*.DS_Store\n\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.1845703125,
          "content": "repos:\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: a11d9314b22d8f8c7556443875b731ef05965464\n    hooks:\n    -   id: check-merge-conflict\n    -   id: check-symlinks\n    -   id: detect-private-key\n        files: (?!.*paddle)^.*$\n    -   id: end-of-file-fixer\n        files: \\.(md|yml)$\n    -   id: trailing-whitespace\n        files: \\.(md|yml)$\n-   repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.0.1\n    hooks:\n    -   id: forbid-crlf\n        files: \\.(md|yml)$\n    -   id: remove-crlf\n        files: \\.(md|yml)$\n    -   id: forbid-tabs\n        files: \\.(md|yml)$\n    -   id: remove-tabs\n        files: \\.(md|yml)$\n-   repo: local\n    hooks:\n    -   id: clang-format-with-version-check\n        name: clang-format\n        description: Format files with ClangFormat.\n        entry: bash ./.travis/codestyle/clang_format.hook -i\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto)$\n\n-   repo: local\n    hooks:\n    -   id: cpplint-cpp-source\n        name: cpplint\n        description: Check C++ code style using cpplint.py.\n        entry: bash ./.travis/codestyle/cpplint_pre_commit.hook\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx)$\n"
        },
        {
          "name": ".style.yapf",
          "type": "blob",
          "size": 0.046875,
          "content": "[style]\nbased_on_style = pep8\ncolumn_limit = 80\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.833984375,
          "content": "language: cpp\ncache: ccache\nsudo: required\ndist: trusty\nservices:\n  - docker\nos:\n  - linux\nenv:\n  - JOB=PRE_COMMIT\n\naddons:\n  apt:\n    packages:\n      - git\n      - python\n      - python-pip\n      - python2.7-dev\n  ssh_known_hosts: 13.229.163.131\nbefore_install:\n  - sudo pip install -U virtualenv pre-commit pip -i https://pypi.tuna.tsinghua.edu.cn/simple\n  - docker pull paddlepaddle/paddle:latest\n  - git pull https://github.com/PaddlePaddle/PaddleDetection develop\n\nscript:\n  - exit_code=0\n  - .travis/precommit.sh || exit_code=$(( exit_code | $? ))\n  # - docker run -i --rm -v \"$PWD:/py_unittest\" paddlepaddle/paddle:latest /bin/bash -c\n  #   'cd /py_unittest; sh .travis/unittest.sh' || exit_code=$(( exit_code | $? ))\n  - if [ $exit_code -eq 0  ]; then true; else exit 1; fi;\n\nnotifications:\n  email:\n    on_success: change\n    on_failure: always\n"
        },
        {
          "name": ".travis",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.01171875,
          "content": "README_cn.md"
        },
        {
          "name": "README_cn.md",
          "type": "blob",
          "size": 60.7255859375,
          "content": "ç®€ä½“ä¸­æ–‡ | [English](README_en.md)\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/48054808/160532560-34cf7a1f-d950-435e-90d2-4b0a679e5119.png\" align=\"middle\" width = \"800\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleDetection?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?color=ccf\"></a>\n</p>\n</div>\n\n## ğŸ’Œç›®å½•\n- [ğŸ’Œç›®å½•](#ç›®å½•)\n- [ğŸŒˆç®€ä»‹](#ç®€ä»‹)\n- [ğŸ“£æœ€æ–°è¿›å±•](#æœ€æ–°è¿›å±•)\n- [âš¡ï¸å¿«é€Ÿå¼€å§‹](#ï¸å¿«é€Ÿå¼€å§‹)\n- [ğŸ”¥ä½ä»£ç å…¨æµç¨‹å¼€å‘](#ä½ä»£ç å…¨æµç¨‹å¼€å‘)\n- [ğŸ‘«å¼€æºç¤¾åŒº](#å¼€æºç¤¾åŒº)\n- [âœ¨ä¸»è¦ç‰¹æ€§](#ä¸»è¦ç‰¹æ€§)\n    - [ğŸ§©æ¨¡å—åŒ–è®¾è®¡](#æ¨¡å—åŒ–è®¾è®¡)\n    - [ğŸ“±ä¸°å¯Œçš„æ¨¡å‹åº“](#ä¸°å¯Œçš„æ¨¡å‹åº“)\n    - [ğŸ—ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹|äº§ä¸šå·¥å…·](#ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹äº§ä¸šå·¥å…·)\n    - [ğŸ’¡ğŸ†äº§ä¸šçº§éƒ¨ç½²å®è·µ](#äº§ä¸šçº§éƒ¨ç½²å®è·µ)\n- [ğŸ±å®‰è£…](#å®‰è£…)\n- [ğŸ”¥æ•™ç¨‹](#æ•™ç¨‹)\n- [ğŸ”‘FAQ](#faq)\n- [ğŸ§©æ¨¡å—ç»„ä»¶](#æ¨¡å—ç»„ä»¶)\n- [ğŸ“±æ¨¡å‹åº“](#æ¨¡å‹åº“)\n- [âš–ï¸æ¨¡å‹æ€§èƒ½å¯¹æ¯”](#ï¸æ¨¡å‹æ€§èƒ½å¯¹æ¯”)\n    - [ğŸ–¥ï¸æœåŠ¡å™¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”](#ï¸æœåŠ¡å™¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”)\n    - [âŒšï¸ç§»åŠ¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”](#ï¸ç§»åŠ¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”)\n- [ğŸ—ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹|äº§ä¸šå·¥å…·](#ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹äº§ä¸šå·¥å…·-1)\n  - [ğŸ’PP-YOLOE é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹](#pp-yoloe-é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹)\n  - [ğŸ’PP-YOLOE-R é«˜æ€§èƒ½æ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹](#pp-yoloe-r-é«˜æ€§èƒ½æ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹)\n  - [ğŸ’PP-YOLOE-SOD é«˜ç²¾åº¦å°ç›®æ ‡æ£€æµ‹æ¨¡å‹](#pp-yoloe-sod-é«˜ç²¾åº¦å°ç›®æ ‡æ£€æµ‹æ¨¡å‹)\n  - [ğŸ’«PP-PicoDet è¶…è½»é‡å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹](#pp-picodet-è¶…è½»é‡å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹)\n  - [ğŸ“¡PP-Tracking å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ](#pp-tracking-å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ)\n  - [â›·ï¸PP-TinyPose äººä½“éª¨éª¼å…³é”®ç‚¹è¯†åˆ«](#ï¸pp-tinypose-äººä½“éª¨éª¼å…³é”®ç‚¹è¯†åˆ«)\n  - [ğŸƒğŸ»PP-Human å®æ—¶è¡Œäººåˆ†æå·¥å…·](#pp-human-å®æ—¶è¡Œäººåˆ†æå·¥å…·)\n  - [ğŸï¸PP-Vehicle å®æ—¶è½¦è¾†åˆ†æå·¥å…·](#ï¸pp-vehicle-å®æ—¶è½¦è¾†åˆ†æå·¥å…·)\n- [ğŸ’¡äº§ä¸šå®è·µèŒƒä¾‹](#äº§ä¸šå®è·µèŒƒä¾‹)\n- [ğŸ†ä¼ä¸šåº”ç”¨æ¡ˆä¾‹](#ä¼ä¸šåº”ç”¨æ¡ˆä¾‹)\n- [ğŸ“è®¸å¯è¯ä¹¦](#è®¸å¯è¯ä¹¦)\n- [ğŸ“Œå¼•ç”¨](#å¼•ç”¨)\n\n\n## ğŸŒˆç®€ä»‹\n\nPaddleDetectionæ˜¯ä¸€ä¸ªåŸºäºPaddlePaddleçš„ç›®æ ‡æ£€æµ‹ç«¯åˆ°ç«¯å¼€å‘å¥—ä»¶ï¼Œåœ¨æä¾›ä¸°å¯Œçš„æ¨¡å‹ç»„ä»¶å’Œæµ‹è¯•åŸºå‡†çš„åŒæ—¶ï¼Œæ³¨é‡ç«¯åˆ°ç«¯çš„äº§ä¸šè½åœ°åº”ç”¨ï¼Œé€šè¿‡æ‰“é€ äº§ä¸šçº§ç‰¹è‰²æ¨¡å‹|å·¥å…·ã€å»ºè®¾äº§ä¸šåº”ç”¨èŒƒä¾‹ç­‰æ‰‹æ®µï¼Œå¸®åŠ©å¼€å‘è€…å®ç°æ•°æ®å‡†å¤‡ã€æ¨¡å‹é€‰å‹ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹æ‰“é€šï¼Œå¿«é€Ÿè¿›è¡Œè½åœ°åº”ç”¨ã€‚\n\nä¸»è¦æ¨¡å‹æ•ˆæœç¤ºä¾‹å¦‚ä¸‹ï¼ˆç‚¹å‡»æ ‡é¢˜å¯å¿«é€Ÿè·³è½¬ï¼‰ï¼š\n\n|                                                  [**é€šç”¨ç›®æ ‡æ£€æµ‹**](#pp-yoloe-é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹)                                                  |                                                [**å°ç›®æ ‡æ£€æµ‹**](#pp-yoloe-sod-é«˜ç²¾åº¦å°ç›®æ ‡æ£€æµ‹æ¨¡å‹)                                                |                                                  [**æ—‹è½¬æ¡†æ£€æµ‹**](#pp-yoloe-r-é«˜æ€§èƒ½æ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹)                                                  |                                            [**3Dç›®æ ‡ç‰©æ£€æµ‹**](https://github.com/PaddlePaddle/Paddle3D)                                            |\n| :--------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------: |\n| <img src='https://user-images.githubusercontent.com/61035602/206095864-f174835d-4e9a-42f7-96b8-d684fc3a3687.png' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095892-934be83a-f869-4a31-8e52-1074184149d1.jpg' height=\"126px\" width=\"180px\"> |  <img src='https://user-images.githubusercontent.com/61035602/206111796-d9a9702a-c1a0-4647-b8e9-3e1307e9d34c.png' height=\"126px\" width=\"180px\">  | <img src='https://user-images.githubusercontent.com/61035602/206095622-cf6dbd26-5515-472f-9451-b39bbef5b1bf.gif' height=\"126px\" width=\"180px\"> |\n|                                                              [**äººè„¸æ£€æµ‹**](#æ¨¡å‹åº“)                                                               |                                                [**2Då…³é”®ç‚¹æ£€æµ‹**](#ï¸pp-tinypose-äººä½“éª¨éª¼å…³é”®ç‚¹è¯†åˆ«)                                                 |                                                  [**å¤šç›®æ ‡è¿½è¸ª**](#pp-tracking-å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ)                                                   |                                                              [**å®ä¾‹åˆ†å‰²**](#æ¨¡å‹åº“)                                                               |\n| <img src='https://user-images.githubusercontent.com/61035602/206095684-72f42233-c9c7-4bd8-9195-e34859bd08bf.jpg' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206100220-ab01d347-9ff9-4f17-9718-290ec14d4205.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206111753-836e7827-968e-4c80-92ef-7a78766892fc.gif' height=\"126px\" width=\"180px\"  > | <img src='https://user-images.githubusercontent.com/61035602/206095831-cc439557-1a23-4a99-b6b0-b6f2e97e8c57.jpg' height=\"126px\" width=\"180px\"> |\n|                                               [**è½¦è¾†åˆ†æâ€”â€”è½¦ç‰Œè¯†åˆ«**](#ï¸pp-vehicle-å®æ—¶è½¦è¾†åˆ†æå·¥å…·)                                               |                                               [**è½¦è¾†åˆ†æâ€”â€”è½¦æµç»Ÿè®¡**](#ï¸pp-vehicle-å®æ—¶è½¦è¾†åˆ†æå·¥å…·)                                               |                                                [**è½¦è¾†åˆ†æâ€”â€”è¿ç« æ£€æµ‹**](#ï¸pp-vehicle-å®æ—¶è½¦è¾†åˆ†æå·¥å…·)                                                |                                               [**è½¦è¾†åˆ†æâ€”â€”å±æ€§åˆ†æ**](#ï¸pp-vehicle-å®æ—¶è½¦è¾†åˆ†æå·¥å…·)                                               |\n| <img src='https://user-images.githubusercontent.com/61035602/206099328-2a1559e0-3b48-4424-9bad-d68f9ba5ba65.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095918-d0e7ad87-7bbb-40f1-bcc1-37844e2271ff.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206100295-7762e1ab-ffce-44fb-b69d-45fb93657fa0.gif' height=\"126px\" width=\"180px\"  > | <img src='https://user-images.githubusercontent.com/61035602/206095905-8255776a-d8e6-4af1-b6e9-8d9f97e5059d.gif' height=\"126px\" width=\"180px\"> |\n|                                                [**è¡Œäººåˆ†æâ€”â€”é—¯å…¥åˆ†æ**](#pp-human-å®æ—¶è¡Œäººåˆ†æå·¥å…·)                                                |                                                [**è¡Œäººåˆ†æâ€”â€”è¡Œä¸ºåˆ†æ**](#pp-human-å®æ—¶è¡Œäººåˆ†æå·¥å…·)                                                |                                                 [**è¡Œäººåˆ†æâ€”â€”å±æ€§åˆ†æ**](#pp-human-å®æ—¶è¡Œäººåˆ†æå·¥å…·)                                                 |                                                [**è¡Œäººåˆ†æâ€”â€”äººæµç»Ÿè®¡**](#pp-human-å®æ—¶è¡Œäººåˆ†æå·¥å…·)                                                |\n| <img src='https://user-images.githubusercontent.com/61035602/206095792-ae0ac107-cd8e-492a-8baa-32118fc82b04.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095778-fdd73e5d-9f91-48c7-9d3d-6f2e02ec3f79.gif' height=\"126px\" width=\"180px\"> |  <img src='https://user-images.githubusercontent.com/61035602/206095709-2c3a209e-6626-45dd-be16-7f0bf4d48a14.gif' height=\"126px\" width=\"180px\">  | <img src=\"https://user-images.githubusercontent.com/61035602/206113351-cc59df79-8672-4d76-b521-a15acf69ae78.gif\" height=\"126px\" width=\"180px\"> |\n\nåŒæ—¶ï¼ŒPaddleDetectionæä¾›äº†æ¨¡å‹çš„åœ¨çº¿ä½“éªŒåŠŸèƒ½ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©è‡ªå·±çš„æ•°æ®è¿›è¡Œåœ¨çº¿æ¨ç†ã€‚\n\n\n## ğŸ“£æœ€æ–°è¿›å±•\n\n- **ğŸ”¥2024.10.1 æ·»åŠ ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²é¢†åŸŸä¸€ç«™å¼å…¨æµç¨‹å¼€å‘èƒ½åŠ›**:  \n  *  é£æ¡¨ä½ä»£ç å¼€å‘å·¥å…·PaddleXï¼Œä¾æ‰˜äºPaddleDetectionçš„å…ˆè¿›æŠ€æœ¯ï¼Œæ”¯æŒäº†ç›®æ ‡æ£€æµ‹é¢†åŸŸçš„**ä¸€ç«™å¼å…¨æµç¨‹**å¼€å‘èƒ½åŠ›ï¼š\n     * ğŸ¨ [**æ¨¡å‹ä¸°å¯Œä¸€é”®è°ƒç”¨**](docs/paddlex/quick_start.md)ï¼šå°†é€šç”¨ç›®æ ‡æ£€æµ‹ã€å°ç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²æ¶‰åŠçš„**55ä¸ªæ¨¡å‹**æ•´åˆä¸º3æ¡æ¨¡å‹äº§çº¿ï¼Œé€šè¿‡æç®€çš„**Python APIä¸€é”®è°ƒç”¨**ï¼Œå¿«é€Ÿä½“éªŒæ¨¡å‹æ•ˆæœã€‚æ­¤å¤–ï¼ŒåŒä¸€å¥—APIï¼Œä¹Ÿæ”¯æŒå›¾åƒåˆ†ç±»ã€å›¾åƒåˆ†å‰²ã€æ–‡æœ¬å›¾åƒæ™ºèƒ½åˆ†æã€é€šç”¨OCRã€æ—¶åºé¢„æµ‹ç­‰å…±è®¡**200+æ¨¡å‹**ï¼Œå½¢æˆ20+å•åŠŸèƒ½æ¨¡å—ï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œ**æ¨¡å‹ç»„åˆä½¿ç”¨**ã€‚\n     * ğŸš€ [**æé«˜æ•ˆç‡é™ä½é—¨æ§›**](docs/paddlex/overview.md)ï¼šæä¾›åŸºäº**ç»Ÿä¸€å‘½ä»¤**å’Œ**å›¾å½¢ç•Œé¢**ä¸¤ç§æ–¹å¼ï¼Œå®ç°æ¨¡å‹ç®€æ´é«˜æ•ˆçš„ä½¿ç”¨ã€ç»„åˆä¸å®šåˆ¶ã€‚æ”¯æŒ**é«˜æ€§èƒ½éƒ¨ç½²ã€æœåŠ¡åŒ–éƒ¨ç½²å’Œç«¯ä¾§éƒ¨ç½²**ç­‰å¤šç§éƒ¨ç½²æ–¹å¼ã€‚æ­¤å¤–ï¼Œå¯¹äºå„ç§ä¸»æµç¡¬ä»¶å¦‚**è‹±ä¼Ÿè¾¾GPUã€æ˜†ä»‘èŠ¯ã€æ˜‡è…¾ã€å¯’æ­¦çºªå’Œæµ·å…‰**ç­‰ï¼Œè¿›è¡Œæ¨¡å‹å¼€å‘æ—¶ï¼Œéƒ½å¯ä»¥**æ— ç¼åˆ‡æ¢**ã€‚\n     \n  *  æ·»åŠ å®ä¾‹åˆ†å‰²SOTAæ¨¡å‹[**Mask-RT-DETR**](https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/cv_modules/instance_segmentation.html)\n\n**ğŸ”¥è¶…è¶ŠYOLOv8ï¼Œé£æ¡¨æ¨å‡ºç²¾åº¦æœ€é«˜çš„å®æ—¶æ£€æµ‹å™¨RT-DETRï¼**\n\n  <div align=\"center\">\n  <img src=\"https://github.com/PaddlePaddle/PaddleDetection/assets/17582080/196b0a10-d2e8-401c-9132-54b9126e0a33\"  height = \"500\" caption='' />\n  <p></p>\n  </div>\n\n  - `RT-DETRè§£è¯»æ–‡ç« ä¼ é€é—¨`ï¼š\n    -  [ã€Šè¶…è¶ŠYOLOv8ï¼Œé£æ¡¨æ¨å‡ºç²¾åº¦æœ€é«˜çš„å®æ—¶æ£€æµ‹å™¨RT-DETRï¼ã€‹](https://mp.weixin.qq.com/s/o03QM2rZNjHVto36gcV0Yw)\n  - `ä»£ç ä¼ é€é—¨`ï¼š[RT-DETR](https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/rtdetr)\n\n\n## [âš¡ï¸å¿«é€Ÿå¼€å§‹](/docs/paddlex/quick_start.md)\n\n## [ğŸ”¥ä½ä»£ç å…¨æµç¨‹å¼€å‘](/docs/paddlex/overview.md)\n\n\n## ğŸ‘«å¼€æºç¤¾åŒº\n\n\n- **ğŸ…ï¸ç¤¾åŒºè´¡çŒ®ï¼š** PaddleDetectionéå¸¸æ¬¢è¿ä½ åŠ å…¥åˆ°é£æ¡¨ç¤¾åŒºçš„å¼€æºå»ºè®¾ä¸­ï¼Œå‚ä¸è´¡çŒ®æ–¹å¼å¯ä»¥å‚è€ƒ[å¼€æºé¡¹ç›®å¼€å‘æŒ‡å—](docs/contribution/README.md)ã€‚\n- [**ğŸˆç¤¾åŒºè¿‘æœŸæ´»åŠ¨**](community.md)\n\n\n\n## âœ¨ä¸»è¦ç‰¹æ€§\n\n#### ğŸ§©æ¨¡å—åŒ–è®¾è®¡\nPaddleDetectionå°†æ£€æµ‹æ¨¡å‹è§£è€¦æˆä¸åŒçš„æ¨¡å—ç»„ä»¶ï¼Œé€šè¿‡è‡ªå®šä¹‰æ¨¡å—ç»„ä»¶ç»„åˆï¼Œç”¨æˆ·å¯ä»¥ä¾¿æ·é«˜æ•ˆåœ°å®Œæˆæ£€æµ‹æ¨¡å‹çš„æ­å»ºã€‚`ä¼ é€é—¨`ï¼š[ğŸ§©æ¨¡å—ç»„ä»¶](#æ¨¡å—ç»„ä»¶)ã€‚\n\n#### ğŸ“±ä¸°å¯Œçš„æ¨¡å‹åº“\nPaddleDetectionæ”¯æŒå¤§é‡çš„æœ€æ–°ä¸»æµçš„ç®—æ³•åŸºå‡†ä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¶µç›–2D/3Dç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€äººè„¸æ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹ã€å¤šç›®æ ‡è·Ÿè¸ªã€åŠç›‘ç£å­¦ä¹ ç­‰æ–¹å‘ã€‚`ä¼ é€é—¨`ï¼š[ğŸ“±æ¨¡å‹åº“](#æ¨¡å‹åº“)ã€[âš–ï¸æ¨¡å‹æ€§èƒ½å¯¹æ¯”](#ï¸æ¨¡å‹æ€§èƒ½å¯¹æ¯”)ã€‚\n\n#### ğŸ—ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹|äº§ä¸šå·¥å…·\nPaddleDetectionæ‰“é€ äº§ä¸šçº§ç‰¹è‰²æ¨¡å‹ä»¥åŠåˆ†æå·¥å…·ï¼šPP-YOLOE+ã€PP-PicoDetã€PP-TinyPoseã€PP-HumanV2ã€PP-Vehicleç­‰ï¼Œé’ˆå¯¹é€šç”¨ã€é«˜é¢‘å‚ç±»åº”ç”¨åœºæ™¯æä¾›æ·±åº¦ä¼˜åŒ–è§£å†³æ–¹æ¡ˆä»¥åŠé«˜åº¦é›†æˆçš„åˆ†æå·¥å…·ï¼Œé™ä½å¼€å‘è€…çš„è¯•é”™ã€é€‰æ‹©æˆæœ¬ï¼Œé’ˆå¯¹ä¸šåŠ¡åœºæ™¯å¿«é€Ÿåº”ç”¨è½åœ°ã€‚`ä¼ é€é—¨`ï¼š[ğŸ—ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹|äº§ä¸šå·¥å…·](#ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹äº§ä¸šå·¥å…·-1)ã€‚\n\n#### ğŸ’¡ğŸ†äº§ä¸šçº§éƒ¨ç½²å®è·µ\nPaddleDetectionæ•´ç†å·¥ä¸šã€å†œä¸šã€æ—ä¸šã€äº¤é€šã€åŒ»ç–—ã€é‡‘èã€èƒ½æºç”µåŠ›ç­‰AIåº”ç”¨èŒƒä¾‹ï¼Œæ‰“é€šæ•°æ®æ ‡æ³¨-æ¨¡å‹è®­ç»ƒ-æ¨¡å‹è°ƒä¼˜-é¢„æµ‹éƒ¨ç½²å…¨æµç¨‹ï¼ŒæŒç»­é™ä½ç›®æ ‡æ£€æµ‹æŠ€æœ¯äº§ä¸šè½åœ°é—¨æ§›ã€‚`ä¼ é€é—¨`ï¼š[ğŸ’¡äº§ä¸šå®è·µèŒƒä¾‹](#äº§ä¸šå®è·µèŒƒä¾‹)ã€[ğŸ†ä¼ä¸šåº”ç”¨æ¡ˆä¾‹](#ä¼ä¸šåº”ç”¨æ¡ˆä¾‹)ã€‚\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206431371-912a14c8-ce1e-48ec-ae6f-7267016b308e.png\" align=\"middle\" width=\"1280\"/>\n</p>\n</div>\n\n\n## ğŸ±å®‰è£…\n\nå‚è€ƒ[å®‰è£…è¯´æ˜](docs/tutorials/INSTALL_cn.md)è¿›è¡Œå®‰è£…ã€‚\n\n## ğŸ”¥æ•™ç¨‹\n\n**æ·±åº¦å­¦ä¹ å…¥é—¨æ•™ç¨‹**\n\n- [é›¶åŸºç¡€å…¥é—¨æ·±åº¦å­¦ä¹ ](https://www.paddlepaddle.org.cn/tutorials/projectdetail/4676538)\n- [é›¶åŸºç¡€å…¥é—¨ç›®æ ‡æ£€æµ‹](https://aistudio.baidu.com/aistudio/education/group/info/1617)\n\n**å¿«é€Ÿå¼€å§‹**\n\n- [å¿«é€Ÿä½“éªŒ](docs/tutorials/QUICK_STARTED_cn.md)\n- [ç¤ºä¾‹ï¼š30åˆ†é’Ÿå¿«é€Ÿå¼€å‘äº¤é€šæ ‡å¿—æ£€æµ‹æ¨¡å‹](docs/tutorials/GETTING_STARTED_cn.md)\n\n**æ•°æ®å‡†å¤‡**\n- [æ•°æ®å‡†å¤‡](docs/tutorials/data/README.md)\n- [æ•°æ®å¤„ç†æ¨¡å—](docs/advanced_tutorials/READER.md)\n\n**é…ç½®æ–‡ä»¶è¯´æ˜**\n- [RCNNå‚æ•°è¯´æ˜](docs/tutorials/config_annotation/faster_rcnn_r50_fpn_1x_coco_annotation.md)\n- [PP-YOLOå‚æ•°è¯´æ˜](docs/tutorials/config_annotation/ppyolo_r50vd_dcn_1x_coco_annotation.md)\n\n**æ¨¡å‹å¼€å‘**\n\n- [æ–°å¢æ£€æµ‹æ¨¡å‹](docs/advanced_tutorials/MODEL_TECHNICAL.md)\n- äºŒæ¬¡å¼€å‘\n  - [ç›®æ ‡æ£€æµ‹](docs/advanced_tutorials/customization/detection.md)\n  - [å…³é”®ç‚¹æ£€æµ‹](docs/advanced_tutorials/customization/keypoint_detection.md)\n  - [å¤šç›®æ ‡è·Ÿè¸ª](docs/advanced_tutorials/customization/pphuman_mot.md)\n  - [è¡Œä¸ºè¯†åˆ«](docs/advanced_tutorials/customization/action_recognotion/)\n  - [å±æ€§è¯†åˆ«](docs/advanced_tutorials/customization/pphuman_attribute.md)\n\n**éƒ¨ç½²æ¨ç†**\n\n- [æ¨¡å‹å¯¼å‡ºæ•™ç¨‹](deploy/EXPORT_MODEL.md)\n- [æ¨¡å‹å‹ç¼©](https://github.com/PaddlePaddle/PaddleSlim)\n  - [å‰ªè£/é‡åŒ–/è’¸é¦æ•™ç¨‹](configs/slim)\n- [Paddle Inferenceéƒ¨ç½²](deploy/README.md)\n  - [Pythonç«¯æ¨ç†éƒ¨ç½²](deploy/python)\n  - [C++ç«¯æ¨ç†éƒ¨ç½²](deploy/cpp)\n- [Paddle Liteéƒ¨ç½²](deploy/lite)\n- [Paddle Servingéƒ¨ç½²](deploy/serving)\n- [ONNXæ¨¡å‹å¯¼å‡º](deploy/EXPORT_ONNX_MODEL.md)\n- [æ¨ç†benchmark](deploy/BENCHMARK_INFER.md)\n\n## ğŸ”‘FAQ\n- [FAQ/å¸¸è§é—®é¢˜æ±‡æ€»](docs/tutorials/FAQ)\n\n## ğŸ§©æ¨¡å—ç»„ä»¶\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"center\">\n      <td>\n        <b>Backbones</b>\n      </td>\n      <td>\n        <b>Necks</b>\n      </td>\n      <td>\n        <b>Loss</b>\n      </td>\n      <td>\n        <b>Common</b>\n      </td>\n      <td>\n      <b>Data Augmentation</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n      <ul>\n          <li><a href=\"ppdet/modeling/backbones/resnet.py\">ResNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/res2net.py\">CSPResNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/senet.py\">SENet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/res2net.py\">Res2Net</a></li>\n          <li><a href=\"ppdet/modeling/backbones/hrnet.py\">HRNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/lite_hrnet.py\">Lite-HRNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/darknet.py\">DarkNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/csp_darknet.py\">CSPDarkNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/mobilenet_v1.py\">MobileNetV1</a></li>\n          <li><a href=\"ppdet/modeling/backbones/mobilenet_v3.py\">MobileNetV1</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/shufflenet_v2.py\">ShuffleNetV2</a></li>\n          <li><a href=\"ppdet/modeling/backbones/ghostnet.py\">GhostNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/blazenet.py\">BlazeNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/dla.py\">DLA</a></li>\n          <li><a href=\"ppdet/modeling/backbones/hardnet.py\">HardNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/lcnet.py\">LCNet</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/esnet.py\">ESNet</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/swin_transformer.py\">Swin-Transformer</a></li>\n          <li><a href=\"ppdet/modeling/backbones/convnext.py\">ConvNeXt</a></li>\n          <li><a href=\"ppdet/modeling/backbones/vgg.py\">VGG</a></li>\n          <li><a href=\"ppdet/modeling/backbones/vision_transformer.py\">Vision Transformer</a></li>\n          <li><a href=\"configs/convnext\">ConvNext</a></li>\n      </ul>\n      </td>\n      <td>\n      <ul>\n        <li><a href=\"ppdet/modeling/necks/bifpn.py\">BiFPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/blazeface_fpn.py\">BlazeFace-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/centernet_fpn.py\">CenterNet-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/csp_pan.py\">CSP-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/custom_pan.py\">Custom-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/fpn.py\">FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/es_pan.py\">ES-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/hrfpn.py\">HRFPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/lc_pan.py\">LC-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/ttf_fpn.py\">TTF-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/yolo_fpn.py\">YOLO-FPN</a></li>\n      </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"ppdet/modeling/losses/smooth_l1_loss.py\">Smooth-L1</a></li>\n          <li><a href=\"ppdet/modeling/losses/detr_loss.py\">Detr Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/fairmot_loss.py\">Fairmot Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/fcos_loss.py\">Fcos Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/gfocal_loss.py\">GFocal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/jde_loss.py\">JDE Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/keypoint_loss.py\">KeyPoint Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/solov2_loss.py\">SoloV2 Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/focal_loss.py\">Focal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/iou_loss.py\">GIoU/DIoU/CIoU</a></li>  \n          <li><a href=\"ppdet/modeling/losses/iou_aware_loss.py\">IoUAware</a></li>\n          <li><a href=\"ppdet/modeling/losses/sparsercnn_loss.py\">SparseRCNN Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/ssd_loss.py\">SSD Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/focal_loss.py\">YOLO Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/yolo_loss.py\">CT Focal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/varifocal_loss.py\">VariFocal Loss</a></li>\n        </ul>\n      </td>\n      <td>\n      </ul>\n          <li><b>Post-processing</b></li>\n        <ul>\n        <ul>\n           <li><a href=\"ppdet/modeling/post_process.py\">SoftNMS</a></li>\n            <li><a href=\"ppdet/modeling/post_process.py\">MatrixNMS</a></li>\n            </ul>\n            </ul>\n          <li><b>Training</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"tools/train.py#L62\">FP16 training</a></li>\n            <li><a href=\"docs/tutorials/DistributedTraining_cn.md\">Multi-machine training </a></li>\n                        </ul>\n            </ul>\n          <li><b>Common</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"ppdet/modeling/backbones/resnet.py#L41\">Sync-BN</a></li>\n            <li><a href=\"configs/gn/README.md\">Group Norm</a></li>\n            <li><a href=\"configs/dcn/README.md\">DCNv2</a></li>\n            <li><a href=\"ppdet/optimizer/ema.py\">EMA</a></li>\n        </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"ppdet/data/transform/operators.py\">Resize</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Lighting</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Flipping</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Expand</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Crop</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Color Distort</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Random Erasing</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Mixup </a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">AugmentHSV</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Mosaic</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Cutmix </a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Grid Mask</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Auto Augment</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Random Perspective</a></li>  \n        </ul>\n      </td>\n    </tr>\n</td>\n    </tr>\n  </tbody>\n</table>\n\n## ğŸ“±æ¨¡å‹åº“\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"center\">\n      <td>\n        <b>2D Detection</b>\n      </td>\n      <td>\n        <b>Multi Object Tracking</b>\n      </td>\n      <td>\n        <b>KeyPoint Detection</b>\n      </td>\n      <td>\n      <b>Others</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n        <ul>\n            <li><a href=\"configs/faster_rcnn/README.md\">Faster RCNN</a></li>\n            <li><a href=\"ppdet/modeling/necks/fpn.py\">FPN</a></li>\n            <li><a href=\"configs/cascade_rcnn/README.md\">Cascade-RCNN</a></li>\n            <li><a href=\"configs/rcnn_enhance\">PSS-Det</a></li>\n            <li><a href=\"configs/retinanet/README.md\">RetinaNet</a></li>\n            <li><a href=\"configs/yolov3/README.md\">YOLOv3</a></li>  \n            <li><a href=\"configs/yolof/README.md\">YOLOF</a></li>  \n            <li><a href=\"configs/yolox/README.md\">YOLOX</a></li>  \n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5\">YOLOv5</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov6\">YOLOv6</a></li>  \n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7\">YOLOv7</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov8\">YOLOv8</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/rtmdet\">RTMDet</a></li>\n            <li><a href=\"configs/ppyolo/README_cn.md\">PP-YOLO</a></li>\n            <li><a href=\"configs/ppyolo#pp-yolo-tiny\">PP-YOLO-Tiny</a></li>\n            <li><a href=\"configs/picodet\">PP-PicoDet</a></li>\n            <li><a href=\"configs/ppyolo/README_cn.md\">PP-YOLOv2</a></li>\n            <li><a href=\"configs/ppyoloe/README_legacy.md\">PP-YOLOE</a></li>\n            <li><a href=\"configs/ppyoloe/README_cn.md\">PP-YOLOE+</a></li>\n            <li><a href=\"configs/smalldet\">PP-YOLOE-SOD</a></li>\n            <li><a href=\"configs/rotate/README.md\">PP-YOLOE-R</a></li>\n            <li><a href=\"configs/ssd/README.md\">SSD</a></li>\n            <li><a href=\"configs/centernet\">CenterNet</a></li>\n            <li><a href=\"configs/fcos\">FCOS</a></li>  \n            <li><a href=\"configs/rotate/fcosr\">FCOSR</a></li>  \n            <li><a href=\"configs/ttfnet\">TTFNet</a></li>\n            <li><a href=\"configs/tood\">TOOD</a></li>\n            <li><a href=\"configs/gfl\">GFL</a></li>\n            <li><a href=\"configs/gfl/gflv2_r50_fpn_1x_coco.yml\">GFLv2</a></li>\n            <li><a href=\"configs/detr\">DETR</a></li>\n            <li><a href=\"configs/deformable_detr\">Deformable DETR</a></li>\n            <li><a href=\"configs/sparse_rcnn\">Sparse RCNN</a></li>\n      </ul>\n      </td>\n      <td>\n        <ul>\n           <li><a href=\"configs/mot/jde\">JDE</a></li>\n            <li><a href=\"configs/mot/fairmot\">FairMOT</a></li>\n            <li><a href=\"configs/mot/deepsort\">DeepSORT</a></li>\n            <li><a href=\"configs/mot/bytetrack\">ByteTrack</a></li>\n            <li><a href=\"configs/mot/ocsort\">OC-SORT</a></li>\n            <li><a href=\"configs/mot/botsort\">BoT-SORT</a></li>\n            <li><a href=\"configs/mot/centertrack\">CenterTrack</a></li>\n        </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"configs/keypoint/hrnet\">HRNet</a></li>\n            <li><a href=\"configs/keypoint/higherhrnet\">HigherHRNet</a></li>\n            <li><a href=\"configs/keypoint/lite_hrnet\">Lite-HRNet</a></li>\n            <li><a href=\"configs/keypoint/tiny_pose\">PP-TinyPose</a></li>\n        </ul>\n</td>\n<td>\n</ul>\n          <li><b>Instance Segmentation</b></li>\n        <ul>\n        <ul>\n          <li><a href=\"configs/mask_rcnn\">Mask RCNN</a></li>\n            <li><a href=\"configs/cascade_rcnn\">Cascade Mask RCNN</a></li>\n            <li><a href=\"configs/solov2\">SOLOv2</a></li>\n        </ul>\n      </ul>\n          <li><b>Face Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"configs/face_detection\">BlazeFace</a></li>\n        </ul>\n        </ul>\n          <li><b>Semi-Supervised Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"configs/semi_det\">DenseTeacher</a></li>\n        </ul>\n        </ul>\n          <li><b>3D Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">Smoke</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">CaDDN</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">PointPillars</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">CenterPoint</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">SequeezeSegV3</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">IA-SSD</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">PETR</a></li>\n        </ul>\n        </ul>\n          <li><b>Vehicle Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"deploy/pipeline/README.md\">PP-Vehicle</a></li>\n        </ul>\n        </ul>\n          <li><b>Human Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"deploy/pipeline/README.md\">PP-Human</a></li>\n            <li><a href=\"deploy/pipeline/README.md\">PP-HumanV2</a></li>\n        </ul>\n        </ul>\n          <li><b>Sport Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleSports\">PP-Sports</a></li>\n        </ul>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## âš–ï¸æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n\n#### ğŸ–¥ï¸æœåŠ¡å™¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n\nå„æ¨¡å‹ç»“æ„å’Œéª¨å¹²ç½‘ç»œçš„ä»£è¡¨æ¨¡å‹åœ¨COCOæ•°æ®é›†ä¸Šç²¾åº¦mAPå’Œå•å¡Tesla V100ä¸Šé¢„æµ‹é€Ÿåº¦(FPS)å¯¹æ¯”å›¾ã€‚\n\n  <div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206434766-caaa781b-b922-481f-af09-15faac9ed33b.png\" width=\"800\"/>\n</div>\n\n<details>\n<summary><b> æµ‹è¯•è¯´æ˜(ç‚¹å‡»å±•å¼€)</b></summary>\n\n- ViTä¸ºViT-Cascade-Faster-RCNNæ¨¡å‹ï¼ŒCOCOæ•°æ®é›†mAPé«˜è¾¾55.7%\n- Cascade-Faster-RCNNä¸ºCascade-Faster-RCNN-ResNet50vd-DCNï¼ŒPaddleDetectionå°†å…¶ä¼˜åŒ–åˆ°COCOæ•°æ®mAPä¸º47.8%æ—¶æ¨ç†é€Ÿåº¦ä¸º20FPS\n- PP-YOLOEæ˜¯å¯¹PP-YOLO v2æ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ŒLç‰ˆæœ¬åœ¨COCOæ•°æ®é›†mAPä¸º51.6%ï¼ŒTesla V100é¢„æµ‹é€Ÿåº¦78.1FPS\n- PP-YOLOE+æ˜¯å¯¹PPOLOEæ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ŒLç‰ˆæœ¬åœ¨COCOæ•°æ®é›†mAPä¸º53.3%ï¼ŒTesla V100é¢„æµ‹é€Ÿåº¦78.1FPS\n- YOLOXå’ŒYOLOv5å‡ä¸ºåŸºäºPaddleDetectionå¤ç°ç®—æ³•ï¼ŒYOLOv5ä»£ç åœ¨[PaddleYOLO](https://github.com/PaddlePaddle/PaddleYOLO)ä¸­ï¼Œå‚ç…§[PaddleYOLO_MODEL](docs/feature_models/PaddleYOLO_MODEL.md)\n- å›¾ä¸­æ¨¡å‹å‡å¯åœ¨[ğŸ“±æ¨¡å‹åº“](#æ¨¡å‹åº“)ä¸­è·å–\n</details>\n\n#### âŒšï¸ç§»åŠ¨ç«¯æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n\nå„ç§»åŠ¨ç«¯æ¨¡å‹åœ¨COCOæ•°æ®é›†ä¸Šç²¾åº¦mAPå’Œé«˜é€šéªé¾™865å¤„ç†å™¨ä¸Šé¢„æµ‹é€Ÿåº¦(FPS)å¯¹æ¯”å›¾ã€‚\n\n  <div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206434741-10460690-8fc3-4084-a11a-16fe4ce2fc85.png\" width=\"550\"/>\n</div>\n\n\n<details>\n<summary><b> æµ‹è¯•è¯´æ˜(ç‚¹å‡»å±•å¼€)</b></summary>\n\n- æµ‹è¯•æ•°æ®å‡ä½¿ç”¨é«˜é€šéªé¾™865(4xA77+4xA55)å¤„ç†å™¨ï¼Œbatch sizeä¸º1, å¼€å¯4çº¿ç¨‹æµ‹è¯•ï¼Œæµ‹è¯•ä½¿ç”¨NCNNé¢„æµ‹åº“ï¼Œæµ‹è¯•è„šæœ¬è§[MobileDetBenchmark](https://github.com/JiweiMaster/MobileDetBenchmark)\n- PP-PicoDetåŠPP-YOLO-Tinyä¸ºPaddleDetectionè‡ªç ”æ¨¡å‹ï¼Œå¯åœ¨[ğŸ“±æ¨¡å‹åº“](#æ¨¡å‹åº“)ä¸­è·å–ï¼Œå…¶ä½™æ¨¡å‹PaddleDetectionæš‚æœªæä¾›\n</details>\n\n## ğŸ—ï¸äº§ä¸šç‰¹è‰²æ¨¡å‹|äº§ä¸šå·¥å…·\n\näº§ä¸šç‰¹è‰²æ¨¡å‹ï½œäº§ä¸šå·¥å…·æ˜¯PaddleDetectioné’ˆå¯¹äº§ä¸šé«˜é¢‘åº”ç”¨åœºæ™¯æ‰“é€ çš„å…¼é¡¾ç²¾åº¦å’Œé€Ÿåº¦çš„æ¨¡å‹ä»¥åŠå·¥å…·ç®±ï¼Œæ³¨é‡ä»æ•°æ®å¤„ç†-æ¨¡å‹è®­ç»ƒ-æ¨¡å‹è°ƒä¼˜-æ¨¡å‹éƒ¨ç½²çš„ç«¯åˆ°ç«¯æ‰“é€šï¼Œä¸”æä¾›äº†å®é™…ç”Ÿäº§ç¯å¢ƒä¸­çš„å®è·µèŒƒä¾‹ä»£ç ï¼Œå¸®åŠ©æ‹¥æœ‰ç±»ä¼¼éœ€æ±‚çš„å¼€å‘è€…é«˜æ•ˆçš„å®Œæˆäº§å“å¼€å‘è½åœ°åº”ç”¨ã€‚\n\nè¯¥ç³»åˆ—æ¨¡å‹ï½œå·¥å…·å‡å·²PPå‰ç¼€å‘½åï¼Œå…·ä½“ä»‹ç»ã€é¢„è®­ç»ƒæ¨¡å‹ä»¥åŠäº§ä¸šå®è·µèŒƒä¾‹ä»£ç å¦‚ä¸‹ã€‚\n\n### ğŸ’PP-YOLOE é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPP-YOLOEæ˜¯åŸºäºPP-YOLOv2çš„å“è¶Šçš„å•é˜¶æ®µAnchor-freeæ¨¡å‹ï¼Œè¶…è¶Šäº†å¤šç§æµè¡Œçš„YOLOæ¨¡å‹ã€‚PP-YOLOEé¿å…äº†ä½¿ç”¨è¯¸å¦‚Deformable Convolutionæˆ–è€…Matrix NMSä¹‹ç±»çš„ç‰¹æ®Šç®—å­ï¼Œä»¥ä½¿å…¶èƒ½è½»æ¾åœ°éƒ¨ç½²åœ¨å¤šç§å¤šæ ·çš„ç¡¬ä»¶ä¸Šã€‚å…¶ä½¿ç”¨å¤§è§„æ¨¡æ•°æ®é›†obj365é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œå¯ä»¥åœ¨ä¸åŒåœºæ™¯æ•°æ®é›†ä¸Šå¿«é€Ÿè°ƒä¼˜æ”¶æ•›ã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-YOLOEè¯´æ˜](configs/ppyoloe/README_cn.md)ã€‚\n\n`ä¼ é€é—¨`ï¼š[arXivè®ºæ–‡](https://arxiv.org/abs/2203.16250)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| æ¨¡å‹åç§°    | COCOç²¾åº¦ï¼ˆmAPï¼‰ | V100 TensorRT FP16é€Ÿåº¦(FPS) | æ¨èéƒ¨ç½²ç¡¬ä»¶ |                        é…ç½®æ–‡ä»¶                         |                                        æ¨¡å‹ä¸‹è½½                                         |\n| :---------- | :-------------: | :-------------------------: | :----------: | :-----------------------------------------------------: | :-------------------------------------------------------------------------------------: |\n| PP-YOLOE+_l |      53.3       |            149.2            |    æœåŠ¡å™¨    | [é“¾æ¥](configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml) | [ä¸‹è½½åœ°å€](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_m_80e_coco.pdparams) |\n\n`ä¼ é€é—¨`ï¼š[å…¨éƒ¨é¢„è®­ç»ƒæ¨¡å‹](configs/ppyoloe/README_cn.md)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š | ç±»åˆ«              | äº®ç‚¹                                                                                          | æ–‡æ¡£è¯´æ˜                                                      | æ¨¡å‹ä¸‹è½½                                            |\n| ---- | ----------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | --------------------------------------------------- |\n| å†œä¸š | å†œä½œç‰©æ£€æµ‹        | ç”¨äºè‘¡è„æ ½åŸ¹ä¸­åŸºäºå›¾åƒçš„ç›‘æµ‹å’Œç°åœºæœºå™¨äººæŠ€æœ¯ï¼Œæä¾›äº†æ¥è‡ª5ç§ä¸åŒè‘¡è„å“ç§çš„å®åœ°å®ä¾‹             | [PP-YOLOE+ ä¸‹æ¸¸ä»»åŠ¡](./configs/ppyoloe/application/README.md) | [ä¸‹è½½é“¾æ¥](./configs/ppyoloe/application/README.md) |\n| é€šç”¨ | ä½å…‰åœºæ™¯æ£€æµ‹      | ä½å…‰æ•°æ®é›†ä½¿ç”¨ExDarkï¼ŒåŒ…æ‹¬ä»æä½å…‰ç¯å¢ƒåˆ°æš®å…‰ç¯å¢ƒç­‰10ç§ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„å›¾ç‰‡ã€‚                  | [PP-YOLOE+ ä¸‹æ¸¸ä»»åŠ¡](./configs/ppyoloe/application/README.md) | [ä¸‹è½½é“¾æ¥](./configs/ppyoloe/application/README.md) |\n| å·¥ä¸š | PCBç”µè·¯æ¿ç‘•ç–µæ£€æµ‹ | å·¥ä¸šæ•°æ®é›†ä½¿ç”¨PKU-Market-PCBï¼Œè¯¥æ•°æ®é›†ç”¨äºå°åˆ·ç”µè·¯æ¿ï¼ˆPCBï¼‰çš„ç‘•ç–µæ£€æµ‹ï¼Œæä¾›äº†6ç§å¸¸è§çš„PCBç¼ºé™· | [PP-YOLOE+ ä¸‹æ¸¸ä»»åŠ¡](./configs/ppyoloe/application/README.md) | [ä¸‹è½½é“¾æ¥](./configs/ppyoloe/application/README.md) |\n</details>\n\n### ğŸ’PP-YOLOE-R é«˜æ€§èƒ½æ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPP-YOLOE-Ræ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å•é˜¶æ®µAnchor-freeæ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹ï¼ŒåŸºäºPP-YOLOE+å¼•å…¥äº†ä¸€ç³»åˆ—æ”¹è¿›ç­–ç•¥æ¥æå‡æ£€æµ‹ç²¾åº¦ã€‚æ ¹æ®ä¸åŒçš„ç¡¬ä»¶å¯¹ç²¾åº¦å’Œé€Ÿåº¦çš„è¦æ±‚ï¼ŒPP-YOLOE-RåŒ…å«s/m/l/xå››ä¸ªå°ºå¯¸çš„æ¨¡å‹ã€‚åœ¨DOTA 1.0æ•°æ®é›†ä¸Šï¼ŒPP-YOLOE-R-lå’ŒPP-YOLOE-R-xåœ¨å•å°ºåº¦è®­ç»ƒå’Œæµ‹è¯•çš„æƒ…å†µä¸‹åˆ†åˆ«è¾¾åˆ°äº†78.14mAPå’Œ78.28 mAPï¼Œè¿™åœ¨å•å°ºåº¦è¯„ä¼°ä¸‹è¶…è¶Šäº†å‡ ä¹æ‰€æœ‰çš„æ—‹è½¬æ¡†æ£€æµ‹æ¨¡å‹ã€‚é€šè¿‡å¤šå°ºåº¦è®­ç»ƒå’Œæµ‹è¯•ï¼ŒPP-YOLOE-R-lå’ŒPP-YOLOE-R-xçš„æ£€æµ‹ç²¾åº¦è¿›ä¸€æ­¥æå‡è‡³80.02mAPå’Œ80.73 mAPï¼Œè¶…è¶Šäº†æ‰€æœ‰çš„Anchor-freeæ–¹æ³•å¹¶ä¸”å’Œæœ€å…ˆè¿›çš„Anchor-basedçš„ä¸¤é˜¶æ®µæ¨¡å‹ç²¾åº¦å‡ ä¹ç›¸å½“ã€‚åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼ŒPP-YOLOE-Ré¿å…ä½¿ç”¨ç‰¹æ®Šçš„ç®—å­ï¼Œä¾‹å¦‚Deformable Convolutionæˆ–Rotated RoI Alignï¼Œä½¿å…¶èƒ½è½»æ¾åœ°éƒ¨ç½²åœ¨å¤šç§å¤šæ ·çš„ç¡¬ä»¶ä¸Šã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-YOLOE-Rè¯´æ˜](configs/rotate/ppyoloe_r)ã€‚\n\n`ä¼ é€é—¨`ï¼š[arXivè®ºæ–‡](https://arxiv.org/abs/2211.02386)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n|     æ¨¡å‹     | Backbone |  mAP  | V100 TRT FP16 (FPS) | RTX 2080 Ti TRT FP16 (FPS) | Params (M) | FLOPs (G) | å­¦ä¹ ç‡ç­–ç•¥ | è§’åº¦è¡¨ç¤º | æ•°æ®å¢å¹¿ | GPUæ•°ç›® | æ¯GPUå›¾ç‰‡æ•°ç›® |                                      æ¨¡å‹ä¸‹è½½                                       |                                                            é…ç½®æ–‡ä»¶                                                            |\n| :----------: | :------: | :---: | :-----------------: | :------------------------: | :--------: | :-------: | :--------: | :------: | :------: | :-----: | :-----------: | :---------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------: |\n| PP-YOLOE-R-l |  CRN-l   | 80.02 |        69.7         |            48.3            |   53.29    |  281.65   |     3x     |    oc    |  MS+RR   |    4    |       2       | [model](https://paddledet.bj.bcebos.com/models/ppyoloe_r_crn_l_3x_dota_ms.pdparams) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/rotate/ppyoloe_r/ppyoloe_r_crn_l_3x_dota_ms.yml) |\n\n`ä¼ é€é—¨`ï¼š[å…¨éƒ¨é¢„è®­ç»ƒæ¨¡å‹](configs/rotate/ppyoloe_r)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š | ç±»åˆ«       | äº®ç‚¹                                                                  | æ–‡æ¡£è¯´æ˜                                                                                | æ¨¡å‹ä¸‹è½½                                                              |\n| ---- | ---------- | --------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| é€šç”¨ | æ—‹è½¬æ¡†æ£€æµ‹ | æ‰‹æŠŠæ‰‹æ•™ä½ ä¸Šæ‰‹PP-YOLOE-Ræ—‹è½¬æ¡†æ£€æµ‹ï¼Œ10åˆ†é’Ÿå°†è„ŠæŸ±æ•°æ®é›†ç²¾åº¦è®­ç»ƒè‡³95mAP | [åŸºäºPP-YOLOE-Rçš„æ—‹è½¬æ¡†æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/5058293) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/5058293) |\n</details>\n\n### ğŸ’PP-YOLOE-SOD é«˜ç²¾åº¦å°ç›®æ ‡æ£€æµ‹æ¨¡å‹\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPP-YOLOE-SOD(Small Object Detection)æ˜¯PaddleDetectionå›¢é˜Ÿé’ˆå¯¹å°ç›®æ ‡æ£€æµ‹æå‡ºçš„æ£€æµ‹æ–¹æ¡ˆï¼Œåœ¨VisDrone-DETæ•°æ®é›†ä¸Šå•æ¨¡å‹ç²¾åº¦è¾¾åˆ°38.5mAPï¼Œè¾¾åˆ°äº†SOTAæ€§èƒ½ã€‚å…¶åˆ†åˆ«åŸºäºåˆ‡å›¾æ‹¼å›¾æµç¨‹ä¼˜åŒ–çš„å°ç›®æ ‡æ£€æµ‹æ–¹æ¡ˆä»¥åŠåŸºäºåŸå›¾æ¨¡å‹ç®—æ³•ä¼˜åŒ–çš„å°ç›®æ ‡æ£€æµ‹æ–¹æ¡ˆã€‚åŒæ—¶æä¾›äº†æ•°æ®é›†è‡ªåŠ¨åˆ†æè„šæœ¬ï¼Œåªéœ€è¾“å…¥æ•°æ®é›†æ ‡æ³¨æ–‡ä»¶ï¼Œä¾¿å¯å¾—åˆ°æ•°æ®é›†ç»Ÿè®¡ç»“æœï¼Œè¾…åŠ©åˆ¤æ–­æ•°æ®é›†æ˜¯å¦æ˜¯å°ç›®æ ‡æ•°æ®é›†ä»¥åŠæ˜¯å¦éœ€è¦é‡‡ç”¨åˆ‡å›¾ç­–ç•¥ï¼ŒåŒæ—¶ç»™å‡ºç½‘ç»œè¶…å‚æ•°å‚è€ƒå€¼ã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-YOLOE-SOD å°ç›®æ ‡æ£€æµ‹æ¨¡å‹](configs/smalldet)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n- VisDroneæ•°æ®é›†é¢„è®­ç»ƒæ¨¡å‹\n\n| æ¨¡å‹                | COCOAPI mAP<sup>val<br>0.5:0.95 | COCOAPI mAP<sup>val<br>0.5 | COCOAPI mAP<sup>test_dev<br>0.5:0.95 | COCOAPI mAP<sup>test_dev<br>0.5 | MatlabAPI mAP<sup>test_dev<br>0.5:0.95 | MatlabAPI mAP<sup>test_dev<br>0.5 |                                              ä¸‹è½½                                               |                           é…ç½®æ–‡ä»¶                           |\n| :------------------ | :-----------------------------: | :------------------------: | :----------------------------------: | :-----------------------------: | :------------------------------------: | :-------------------------------: | :---------------------------------------------------------------------------------------------: | :----------------------------------------------------------: |\n| **PP-YOLOE+_SOD-l** |            **31.9**             |          **52.1**          |               **25.6**               |            **43.5**             |               **30.25**                |             **51.18**             | [ä¸‹è½½é“¾æ¥](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_sod_crn_l_80e_visdrone.pdparams) | [é…ç½®æ–‡ä»¶](visdrone/ppyoloe_plus_sod_crn_l_80e_visdrone.yml) |\n\n`ä¼ é€é—¨`ï¼š[å…¨éƒ¨é¢„è®­ç»ƒæ¨¡å‹](configs/smalldet)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š | ç±»åˆ«       | äº®ç‚¹                                                 | æ–‡æ¡£è¯´æ˜                                                                                          | æ¨¡å‹ä¸‹è½½                                                              |\n| ---- | ---------- | ---------------------------------------------------- | ------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| é€šç”¨ | å°ç›®æ ‡æ£€æµ‹ | åŸºäºPP-YOLOE-SODçš„æ— äººæœºèˆªæ‹å›¾åƒæ£€æµ‹æ¡ˆä¾‹å…¨æµç¨‹å®æ“ã€‚ | [åŸºäºPP-YOLOE-SODçš„æ— äººæœºèˆªæ‹å›¾åƒæ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/5036782) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/5036782) |\n</details>\n\n### ğŸ’«PP-PicoDet è¶…è½»é‡å®æ—¶ç›®æ ‡æ£€æµ‹æ¨¡å‹\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nå…¨æ–°çš„è½»é‡çº§ç³»åˆ—æ¨¡å‹PP-PicoDetï¼Œåœ¨ç§»åŠ¨ç«¯å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œæˆä¸ºå…¨æ–°SOTAè½»é‡çº§æ¨¡å‹ã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-PicoDetè¯´æ˜](configs/picodet/README.md)ã€‚\n\n`ä¼ é€é—¨`ï¼š[arXivè®ºæ–‡](https://arxiv.org/abs/2111.00902)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| æ¨¡å‹åç§°  | COCOç²¾åº¦ï¼ˆmAPï¼‰ | éªé¾™865 å››çº¿ç¨‹é€Ÿåº¦(FPS) |  æ¨èéƒ¨ç½²ç¡¬ä»¶  |                       é…ç½®æ–‡ä»¶                       |                                       æ¨¡å‹ä¸‹è½½                                       |\n| :-------- | :-------------: | :---------------------: | :------------: | :--------------------------------------------------: | :----------------------------------------------------------------------------------: |\n| PicoDet-L |      36.1       |          39.7           | ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ | [é“¾æ¥](configs/picodet/picodet_l_320_coco_lcnet.yml) | [ä¸‹è½½åœ°å€](https://paddledet.bj.bcebos.com/models/picodet_l_320_coco_lcnet.pdparams) |\n\n`ä¼ é€é—¨`ï¼š[å…¨éƒ¨é¢„è®­ç»ƒæ¨¡å‹](configs/picodet/README.md)ã€‚\n</details>\n\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š     | ç±»åˆ«         | äº®ç‚¹                                                                                                                           | æ–‡æ¡£è¯´æ˜                                                                                                          | æ¨¡å‹ä¸‹è½½                                                                                      |\n| -------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |\n| æ™ºæ…§åŸå¸‚ | é“è·¯åƒåœ¾æ£€æµ‹ | é€šè¿‡åœ¨å¸‚æ”¿ç¯å«è½¦è¾†ä¸Šå®‰è£…æ‘„åƒå¤´å¯¹è·¯é¢åƒåœ¾æ£€æµ‹å¹¶åˆ†æï¼Œå®ç°å¯¹è·¯é¢é—æ’’çš„åƒåœ¾è¿›è¡Œç›‘æ§ï¼Œè®°å½•å¹¶é€šçŸ¥ç¯å«äººå‘˜æ¸…ç†ï¼Œå¤§å¤§æå‡äº†ç¯å«äººæ•ˆã€‚ | [åŸºäºPP-PicoDetçš„è·¯é¢åƒåœ¾æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0) |\n</details>\n\n### ğŸ“¡PP-Tracking å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPaddleDetectionå›¢é˜Ÿæä¾›äº†å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»ŸPP-Trackingï¼Œæ˜¯åŸºäºPaddlePaddleæ·±åº¦å­¦ä¹ æ¡†æ¶çš„ä¸šç•Œé¦–ä¸ªå¼€æºçš„å®æ—¶å¤šç›®æ ‡è·Ÿè¸ªç³»ç»Ÿï¼Œå…·æœ‰æ¨¡å‹ä¸°å¯Œã€åº”ç”¨å¹¿æ³›å’Œéƒ¨ç½²é«˜æ•ˆä¸‰å¤§ä¼˜åŠ¿ã€‚ PP-Trackingæ”¯æŒå•é•œå¤´è·Ÿè¸ª(MOT)å’Œè·¨é•œå¤´è·Ÿè¸ª(MTMCT)ä¸¤ç§æ¨¡å¼ï¼Œé’ˆå¯¹å®é™…ä¸šåŠ¡çš„éš¾ç‚¹å’Œç—›ç‚¹ï¼Œæä¾›äº†è¡Œäººè·Ÿè¸ªã€è½¦è¾†è·Ÿè¸ªã€å¤šç±»åˆ«è·Ÿè¸ªã€å°ç›®æ ‡è·Ÿè¸ªã€æµé‡ç»Ÿè®¡ä»¥åŠè·¨é•œå¤´è·Ÿè¸ªç­‰å„ç§å¤šç›®æ ‡è·Ÿè¸ªåŠŸèƒ½å’Œåº”ç”¨ï¼Œéƒ¨ç½²æ–¹å¼æ”¯æŒAPIè°ƒç”¨å’ŒGUIå¯è§†åŒ–ç•Œé¢ï¼Œéƒ¨ç½²è¯­è¨€æ”¯æŒPythonå’ŒC++ï¼Œéƒ¨ç½²å¹³å°ç¯å¢ƒæ”¯æŒLinuxã€NVIDIA Jetsonç­‰ã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-Trackingè¯´æ˜](configs/mot/README.md)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| æ¨¡å‹åç§°  |               æ¨¡å‹ç®€ä»‹               |          ç²¾åº¦          | é€Ÿåº¦(FPS) |      æ¨èéƒ¨ç½²ç¡¬ä»¶      |                          é…ç½®æ–‡ä»¶                          |                                              æ¨¡å‹ä¸‹è½½                                              |\n| :-------- | :----------------------------------: | :--------------------: | :-------: | :--------------------: | :--------------------------------------------------------: | :------------------------------------------------------------------------------------------------: |\n| ByteTrack |   SDEå¤šç›®æ ‡è·Ÿè¸ªç®—æ³• ä»…åŒ…å«æ£€æµ‹æ¨¡å‹   |   MOT-17 test:  78.4   |     -     | æœåŠ¡å™¨ã€ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ |     [é“¾æ¥](configs/mot/bytetrack/bytetrack_yolox.yml)      |  [ä¸‹è½½åœ°å€](https://bj.bcebos.com/v1/paddledet/models/mot/yolox_x_24e_800x1440_mix_det.pdparams)   |\n| FairMOT   | JDEå¤šç›®æ ‡è·Ÿè¸ªç®—æ³• å¤šä»»åŠ¡è”åˆå­¦ä¹ æ–¹æ³• |   MOT-16 test: 75.0    |     -     | æœåŠ¡å™¨ã€ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ | [é“¾æ¥](configs/mot/fairmot/fairmot_dla34_30e_1088x608.yml) |     [ä¸‹è½½åœ°å€](https://paddledet.bj.bcebos.com/models/mot/fairmot_dla34_30e_1088x608.pdparams)     |\n| OC-SORT   |   SDEå¤šç›®æ ‡è·Ÿè¸ªç®—æ³• ä»…åŒ…å«æ£€æµ‹æ¨¡å‹   | MOT-17 half val:  75.5 |     -     | æœåŠ¡å™¨ã€ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ |        [é“¾æ¥](configs/mot/ocsort/ocsort_yolox.yml)         | [ä¸‹è½½åœ°å€](https://bj.bcebos.com/v1/paddledet/models/mot/yolox_x_24e_800x1440_mix_mot_ch.pdparams) |\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š | ç±»åˆ«       | äº®ç‚¹                       | æ–‡æ¡£è¯´æ˜                                                                                       | æ¨¡å‹ä¸‹è½½                                                              |\n| ---- | ---------- | -------------------------- | ---------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| é€šç”¨ | å¤šç›®æ ‡è·Ÿè¸ª | å¿«é€Ÿä¸Šæ‰‹å•é•œå¤´ã€å¤šé•œå¤´è·Ÿè¸ª | [PP-Trackingä¹‹æ‰‹æŠŠæ‰‹ç©è½¬å¤šç›®æ ‡è·Ÿè¸ª](https://aistudio.baidu.com/aistudio/projectdetail/3022582) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/3022582) |\n</details>\n\n### â›·ï¸PP-TinyPose äººä½“éª¨éª¼å…³é”®ç‚¹è¯†åˆ«\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPaddleDetection ä¸­çš„å…³é”®ç‚¹æ£€æµ‹éƒ¨åˆ†ç´§è·Ÿæœ€å…ˆè¿›çš„ç®—æ³•ï¼ŒåŒ…æ‹¬ Top-Down å’Œ Bottom-Up ä¸¤ç§æ–¹æ³•ï¼Œå¯ä»¥æ»¡è¶³ç”¨æˆ·çš„ä¸åŒéœ€æ±‚ã€‚åŒæ—¶ï¼ŒPaddleDetection æä¾›é’ˆå¯¹ç§»åŠ¨ç«¯è®¾å¤‡ä¼˜åŒ–çš„è‡ªç ”å®æ—¶å…³é”®ç‚¹æ£€æµ‹æ¨¡å‹ PP-TinyPoseã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-TinyPoseè¯´æ˜](configs/keypoint/tiny_pose)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n|  æ¨¡å‹åç§°   |               æ¨¡å‹ç®€ä»‹               | COCOç²¾åº¦ï¼ˆAPï¼‰ |         é€Ÿåº¦(FPS)         |  æ¨èéƒ¨ç½²ç¡¬ä»¶  |                        é…ç½®æ–‡ä»¶                         |                                         æ¨¡å‹ä¸‹è½½                                         |\n| :---------: | :----------------------------------: | :------------: | :-----------------------: | :------------: | :-----------------------------------------------------: | :--------------------------------------------------------------------------------------: |\n| PP-TinyPose | è½»é‡çº§å…³é”®ç‚¹ç®—æ³•<br/>è¾“å…¥å°ºå¯¸256x192 |      68.8      | éªé¾™865 å››çº¿ç¨‹: 158.7 FPS | ç§»åŠ¨ç«¯ã€åµŒå…¥å¼ | [é“¾æ¥](configs/keypoint/tiny_pose/tinypose_256x192.yml) | [ä¸‹è½½åœ°å€](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_256x192.pdparams) |\n\n`ä¼ é€é—¨`ï¼š[å…¨éƒ¨é¢„è®­ç»ƒæ¨¡å‹](configs/keypoint/README.md)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š | ç±»åˆ« | äº®ç‚¹                                                                                                                                     | æ–‡æ¡£è¯´æ˜                                                                                             | æ¨¡å‹ä¸‹è½½                                                              |\n| ---- | ---- | ---------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| è¿åŠ¨ | å¥èº« | æä¾›ä»æ¨¡å‹é€‰å‹ã€æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒä¼˜åŒ–ï¼Œåˆ°åå¤„ç†é€»è¾‘å’Œæ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹å¯å¤ç”¨æ–¹æ¡ˆï¼Œæœ‰æ•ˆè§£å†³äº†å¤æ‚å¥èº«åŠ¨ä½œçš„é«˜æ•ˆè¯†åˆ«ï¼Œæ‰“é€ AIè™šæ‹Ÿå¥èº«æ•™ç»ƒï¼ | [åŸºäºPP-TinyPoseå¢å¼ºç‰ˆçš„æ™ºèƒ½å¥èº«åŠ¨ä½œè¯†åˆ«](https://aistudio.baidu.com/aistudio/projectdetail/4385813) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/4385813) |\n</details>\n\n### ğŸƒğŸ»PP-Human å®æ—¶è¡Œäººåˆ†æå·¥å…·\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPaddleDetectionæ·±å…¥æ¢ç´¢æ ¸å¿ƒè¡Œä¸šçš„é«˜é¢‘åœºæ™¯ï¼Œæä¾›äº†è¡Œäººå¼€ç®±å³ç”¨åˆ†æå·¥å…·ï¼Œæ”¯æŒå›¾ç‰‡/å•é•œå¤´è§†é¢‘/å¤šé•œå¤´è§†é¢‘/åœ¨çº¿è§†é¢‘æµå¤šç§è¾“å…¥æ–¹å¼ï¼Œå¹¿æ³›åº”ç”¨äºæ™ºæ…§äº¤é€šã€æ™ºæ…§åŸå¸‚ã€å·¥ä¸šå·¡æ£€ç­‰é¢†åŸŸã€‚æ”¯æŒæœåŠ¡å™¨ç«¯éƒ¨ç½²åŠTensorRTåŠ é€Ÿï¼ŒT4æœåŠ¡å™¨ä¸Šå¯è¾¾åˆ°å®æ—¶ã€‚\nPP-Humanæ”¯æŒå››å¤§äº§ä¸šçº§åŠŸèƒ½ï¼šäº”å¤§å¼‚å¸¸è¡Œä¸ºè¯†åˆ«ã€26ç§äººä½“å±æ€§åˆ†æã€å®æ—¶äººæµè®¡æ•°ã€è·¨é•œå¤´ï¼ˆReIDï¼‰è·Ÿè¸ªã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-Humanè¡Œäººåˆ†æå·¥å…·ä½¿ç”¨æŒ‡å—](deploy/pipeline/README.md)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n|        ä»»åŠ¡        | T4 TensorRT FP16: é€Ÿåº¦ï¼ˆFPSï¼‰ | æ¨èéƒ¨ç½²ç¡¬ä»¶ |                                                                                                                                         æ¨¡å‹ä¸‹è½½                                                                                                                                         |                             æ¨¡å‹ä½“ç§¯                              |\n| :----------------: | :---------------------------: | :----------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------: |\n| è¡Œäººæ£€æµ‹ï¼ˆé«˜ç²¾åº¦ï¼‰ |             39.8              |    æœåŠ¡å™¨    |                                                                                              [ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                               |                               182M                                |\n| è¡Œäººè·Ÿè¸ªï¼ˆé«˜ç²¾åº¦ï¼‰ |             31.4              |    æœåŠ¡å™¨    |                                                                                             [å¤šç›®æ ‡è·Ÿè¸ª](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                              |                               182M                                |\n| å±æ€§è¯†åˆ«ï¼ˆé«˜ç²¾åº¦ï¼‰ |          å•äºº 117.6           |    æœåŠ¡å™¨    |                                      [ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [å±æ€§è¯†åˆ«](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_small_person_attribute_954_infer.zip)                                       |                  ç›®æ ‡æ£€æµ‹ï¼š182M<br>å±æ€§è¯†åˆ«ï¼š86M                  |\n|      æ‘”å€’è¯†åˆ«      |           å•äºº 100            |    æœåŠ¡å™¨    | [å¤šç›®æ ‡è·Ÿè¸ª](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip) <br> [å…³é”®ç‚¹æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip) <br> [åŸºäºå…³é”®ç‚¹è¡Œä¸ºè¯†åˆ«](https://bj.bcebos.com/v1/paddledet/models/pipeline/STGCN.zip) | å¤šç›®æ ‡è·Ÿè¸ªï¼š182M<br>å…³é”®ç‚¹æ£€æµ‹ï¼š101M<br>åŸºäºå…³é”®ç‚¹è¡Œä¸ºè¯†åˆ«ï¼š21.8M |\n|      é—¯å…¥è¯†åˆ«      |             31.4              |    æœåŠ¡å™¨    |                                                                                             [å¤šç›®æ ‡è·Ÿè¸ª](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                              |                               182M                                |\n|      æ‰“æ¶è¯†åˆ«      |             50.8              |    æœåŠ¡å™¨    |                                                                                              [è§†é¢‘åˆ†ç±»](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                               |                                90M                                |\n|      æŠ½çƒŸè¯†åˆ«      |             340.1             |    æœåŠ¡å™¨    |                                    [ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[åŸºäºäººä½“idçš„ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/ppyoloe_crn_s_80e_smoking_visdrone.zip)                                    |            ç›®æ ‡æ£€æµ‹ï¼š182M<br>åŸºäºäººä½“idçš„ç›®æ ‡æ£€æµ‹ï¼š27M            |\n|     æ‰“ç”µè¯è¯†åˆ«     |             166.7             |    æœåŠ¡å™¨    |                                      [ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[åŸºäºäººä½“idçš„å›¾åƒåˆ†ç±»](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_tiny_calling_halfbody.zip)                                       |            ç›®æ ‡æ£€æµ‹ï¼š182M<br>åŸºäºäººä½“idçš„å›¾åƒåˆ†ç±»ï¼š45M            |\n\n`ä¼ é€é—¨`ï¼š[å®Œæ•´é¢„è®­ç»ƒæ¨¡å‹](deploy/pipeline/README.md)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š     | ç±»åˆ«     | äº®ç‚¹                                                                                                                                           | æ–‡æ¡£è¯´æ˜                                                                                               | æ¨¡å‹ä¸‹è½½                                                                                 |\n| -------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------- |\n| æ™ºèƒ½å®‰é˜² | æ‘”å€’æ£€æµ‹ | é£æ¡¨è¡Œäººåˆ†æPP-Humanä¸­æä¾›çš„æ‘”å€’è¯†åˆ«ç®—æ³•ï¼Œé‡‡ç”¨äº†å…³é”®ç‚¹+æ—¶ç©ºå›¾å·ç§¯ç½‘ç»œçš„æŠ€æœ¯ï¼Œå¯¹æ‘”å€’å§¿åŠ¿æ— é™åˆ¶ã€èƒŒæ™¯ç¯å¢ƒæ— è¦æ±‚ã€‚                                | [åŸºäºPP-Human v2çš„æ‘”å€’æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/4606001)                 | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/4606001)                    |\n| æ™ºèƒ½å®‰é˜² | æ‰“æ¶è¯†åˆ« | æœ¬é¡¹ç›®åŸºäºPaddleVideoè§†é¢‘å¼€å‘å¥—ä»¶è®­ç»ƒæ‰“æ¶è¯†åˆ«æ¨¡å‹ï¼Œç„¶åå°†è®­ç»ƒå¥½çš„æ¨¡å‹é›†æˆåˆ°PaddleDetectionçš„PP-Humanä¸­ï¼ŒåŠ©åŠ›è¡Œäººè¡Œä¸ºåˆ†æã€‚                     | [åŸºäºPP-Humançš„æ‰“æ¶è¯†åˆ«](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1) |\n| æ™ºèƒ½å®‰é˜² | æ‘”å€’æ£€æµ‹ | åŸºäºPP-Humanå®Œæˆæ¥å®¢åˆ†ææ•´ä½“æµç¨‹ã€‚ä½¿ç”¨PP-Humanå®Œæˆæ¥å®¢åˆ†æä¸­éå¸¸å¸¸è§çš„åœºæ™¯ï¼š 1. æ¥å®¢å±æ€§è¯†åˆ«(å•é•œå’Œè·¨å¢ƒå¯è§†åŒ–ï¼‰ï¼›2. æ¥å®¢è¡Œä¸ºè¯†åˆ«ï¼ˆæ‘”å€’è¯†åˆ«ï¼‰ã€‚ | [åŸºäºPP-Humançš„æ¥å®¢åˆ†ææ¡ˆä¾‹æ•™ç¨‹](https://aistudio.baidu.com/aistudio/projectdetail/4537344)            | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/4537344)                    |\n</details>\n\n### ğŸï¸PP-Vehicle å®æ—¶è½¦è¾†åˆ†æå·¥å…·\n\n<details>\n<summary><b> ç®€ä»‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\nPaddleDetectionæ·±å…¥æ¢ç´¢æ ¸å¿ƒè¡Œä¸šçš„é«˜é¢‘åœºæ™¯ï¼Œæä¾›äº†è½¦è¾†å¼€ç®±å³ç”¨åˆ†æå·¥å…·ï¼Œæ”¯æŒå›¾ç‰‡/å•é•œå¤´è§†é¢‘/å¤šé•œå¤´è§†é¢‘/åœ¨çº¿è§†é¢‘æµå¤šç§è¾“å…¥æ–¹å¼ï¼Œå¹¿æ³›åº”ç”¨äºæ™ºæ…§äº¤é€šã€æ™ºæ…§åŸå¸‚ã€å·¥ä¸šå·¡æ£€ç­‰é¢†åŸŸã€‚æ”¯æŒæœåŠ¡å™¨ç«¯éƒ¨ç½²åŠTensorRTåŠ é€Ÿï¼ŒT4æœåŠ¡å™¨ä¸Šå¯è¾¾åˆ°å®æ—¶ã€‚\nPP-Vehicleå›Šæ‹¬å››å¤§äº¤é€šåœºæ™¯æ ¸å¿ƒåŠŸèƒ½ï¼šè½¦ç‰Œè¯†åˆ«ã€å±æ€§è¯†åˆ«ã€è½¦æµé‡ç»Ÿè®¡ã€è¿ç« æ£€æµ‹ã€‚\n\n`ä¼ é€é—¨`ï¼š[PP-Vehicleè½¦è¾†åˆ†æå·¥å…·æŒ‡å—](deploy/pipeline/README.md)ã€‚\n\n</details>\n\n<details>\n<summary><b> é¢„è®­ç»ƒæ¨¡å‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n|        ä»»åŠ¡        | T4 TensorRT FP16: é€Ÿåº¦(FPS) | æ¨èéƒ¨ç½²ç¡¬ä»¶ |                                                                                           æ¨¡å‹æ–¹æ¡ˆ                                                                                           |                æ¨¡å‹ä½“ç§¯                 |\n| :----------------: | :-------------------------: | :----------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-------------------------------------: |\n| è½¦è¾†æ£€æµ‹ï¼ˆé«˜ç²¾åº¦ï¼‰ |            38.9             |    æœåŠ¡å™¨    |                                                [ç›®æ ‡æ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                |                  182M                   |\n| è½¦è¾†è·Ÿè¸ªï¼ˆé«˜ç²¾åº¦ï¼‰ |             25              |    æœåŠ¡å™¨    |                                               [å¤šç›®æ ‡è·Ÿè¸ª](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                               |                  182M                   |\n|      è½¦ç‰Œè¯†åˆ«      |            213.7            |    æœåŠ¡å™¨    | [è½¦ç‰Œæ£€æµ‹](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_det_infer.tar.gz) <br> [è½¦ç‰Œè¯†åˆ«](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_rec_infer.tar.gz) | è½¦ç‰Œæ£€æµ‹ï¼š3.9M  <br> è½¦ç‰Œå­—ç¬¦è¯†åˆ«ï¼š 12M |\n|      è½¦è¾†å±æ€§      |            136.8            |    æœåŠ¡å™¨    |                                                  [å±æ€§è¯†åˆ«](https://bj.bcebos.com/v1/paddledet/models/pipeline/vehicle_attribute_model.zip)                                                  |                  7.2M                   |\n\n`ä¼ é€é—¨`ï¼š[å®Œæ•´é¢„è®­ç»ƒæ¨¡å‹](deploy/pipeline/README.md)ã€‚\n</details>\n\n<details>\n<summary><b> äº§ä¸šåº”ç”¨ä»£ç ç¤ºä¾‹(ç‚¹å‡»å±•å¼€)</b></summary>\n\n| è¡Œä¸š     | ç±»åˆ«             | äº®ç‚¹                                                                                                               | æ–‡æ¡£è¯´æ˜                                                                                      | æ¨¡å‹ä¸‹è½½                                                              |\n| -------- | ---------------- | ------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| æ™ºæ…§äº¤é€š | äº¤é€šç›‘æ§è½¦è¾†åˆ†æ | æœ¬é¡¹ç›®åŸºäºPP-Vehicleæ¼”ç¤ºæ™ºæ…§äº¤é€šä¸­æœ€åˆšéœ€çš„è½¦æµé‡ç›‘æ§ã€è½¦è¾†è¿åœæ£€æµ‹ä»¥åŠè½¦è¾†ç»“æ„åŒ–ï¼ˆè½¦ç‰Œã€è½¦å‹ã€é¢œè‰²ï¼‰åˆ†æä¸‰å¤§åœºæ™¯ã€‚ | [åŸºäºPP-Vehicleçš„äº¤é€šç›‘æ§åˆ†æç³»ç»Ÿ](https://aistudio.baidu.com/aistudio/projectdetail/4512254) | [ä¸‹è½½é“¾æ¥](https://aistudio.baidu.com/aistudio/projectdetail/4512254) |\n</details>\n\n## ğŸ’¡äº§ä¸šå®è·µèŒƒä¾‹\n\näº§ä¸šå®è·µèŒƒä¾‹æ˜¯PaddleDetectioné’ˆå¯¹é«˜é¢‘ç›®æ ‡æ£€æµ‹åº”ç”¨åœºæ™¯ï¼Œæä¾›çš„ç«¯åˆ°ç«¯å¼€å‘ç¤ºä¾‹ï¼Œå¸®åŠ©å¼€å‘è€…æ‰“é€šæ•°æ®æ ‡æ³¨-æ¨¡å‹è®­ç»ƒ-æ¨¡å‹è°ƒä¼˜-é¢„æµ‹éƒ¨ç½²å…¨æµç¨‹ã€‚\né’ˆå¯¹æ¯ä¸ªèŒƒä¾‹æˆ‘ä»¬éƒ½é€šè¿‡[AI-Studio](https://ai.baidu.com/ai-doc/AISTUDIO/Tk39ty6ho)æä¾›äº†é¡¹ç›®ä»£ç ä»¥åŠè¯´æ˜ï¼Œç”¨æˆ·å¯ä»¥åŒæ­¥è¿è¡Œä½“éªŒã€‚\n\n`ä¼ é€é—¨`ï¼š[äº§ä¸šå®è·µèŒƒä¾‹å®Œæ•´åˆ—è¡¨](industrial_tutorial/README.md)\n\n- [åŸºäºPP-YOLOE-Rçš„æ—‹è½¬æ¡†æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/5058293)\n- [åŸºäºPP-YOLOE-SODçš„æ— äººæœºèˆªæ‹å›¾åƒæ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/5036782)\n- [åŸºäºPP-Vehicleçš„äº¤é€šç›‘æ§åˆ†æç³»ç»Ÿ](https://aistudio.baidu.com/aistudio/projectdetail/4512254)\n- [åŸºäºPP-Human v2çš„æ‘”å€’æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/4606001)\n- [åŸºäºPP-TinyPoseå¢å¼ºç‰ˆçš„æ™ºèƒ½å¥èº«åŠ¨ä½œè¯†åˆ«](https://aistudio.baidu.com/aistudio/projectdetail/4385813)\n- [åŸºäºPP-Humançš„æ‰“æ¶è¯†åˆ«](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1)\n- [åŸºäºFaster-RCNNçš„ç“·ç –è¡¨é¢ç‘•ç–µæ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/2571419)\n- [åŸºäºPaddleDetectionçš„PCBç‘•ç–µæ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/2367089)\n- [åŸºäºFairMOTå®ç°äººæµé‡ç»Ÿè®¡](https://aistudio.baidu.com/aistudio/projectdetail/2421822)\n- [åŸºäºYOLOv3å®ç°è·Œå€’æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/2500639)\n- [åŸºäºPP-PicoDetv2 çš„è·¯é¢åƒåœ¾æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0)\n- [åŸºäºäººä½“å…³é”®ç‚¹æ£€æµ‹çš„åˆè§„æ£€æµ‹](https://aistudio.baidu.com/aistudio/projectdetail/4061642?contributionType=1)\n- [åŸºäºPP-Humançš„æ¥å®¢åˆ†ææ¡ˆä¾‹æ•™ç¨‹](https://aistudio.baidu.com/aistudio/projectdetail/4537344)\n- æŒç»­æ›´æ–°ä¸­...\n\n## ğŸ†ä¼ä¸šåº”ç”¨æ¡ˆä¾‹\n\nä¼ä¸šåº”ç”¨æ¡ˆä¾‹æ˜¯ä¼ä¸šåœ¨å®ç”Ÿäº§ç¯å¢ƒä¸‹è½åœ°åº”ç”¨PaddleDetectionçš„æ–¹æ¡ˆæ€è·¯ï¼Œç›¸æ¯”äº§ä¸šå®è·µèŒƒä¾‹å…¶æ›´å¤šå¼ºè°ƒæ•´ä½“æ–¹æ¡ˆè®¾è®¡æ€è·¯ï¼Œå¯ä¾›å¼€å‘è€…åœ¨é¡¹ç›®æ–¹æ¡ˆè®¾è®¡ä¸­åšå‚è€ƒã€‚\n\n`ä¼ é€é—¨`ï¼š[ä¼ä¸šåº”ç”¨æ¡ˆä¾‹å®Œæ•´åˆ—è¡¨](https://www.paddlepaddle.org.cn/customercase)\n\n- [ä¸­å›½å—æ–¹ç”µç½‘â€”â€”å˜ç”µç«™æ™ºæ…§å·¡æ£€](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2330)\n- [å›½é“ç”µæ°”â€”â€”è½¨é“åœ¨çº¿æ™ºèƒ½å·¡æ£€ç³»ç»Ÿ](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2280)\n- [äº¬ä¸œç‰©æµâ€”â€”å›­åŒºè½¦è¾†è¡Œä¸ºè¯†åˆ«](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2611)\n- [ä¸­å…´å…‹æ‹‰â€”å‚åŒºä¼ ç»Ÿä»ªè¡¨ç»Ÿè®¡ç›‘æµ‹](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2618)\n- [å®å¾·æ—¶ä»£â€”åŠ¨åŠ›ç”µæ± é«˜ç²¾åº¦è´¨é‡æ£€æµ‹](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2609)\n- [ä¸­å›½ç§‘å­¦é™¢ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢â€”â€”é«˜å°”å¤«çƒåœºé¥æ„Ÿç›‘æµ‹](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2483)\n- [å¾¡èˆªæ™ºèƒ½â€”â€”åŸºäºè¾¹ç¼˜çš„æ— äººæœºæ™ºèƒ½å·¡æ£€](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2481)\n- [æ™®å®™æ— äººæœºâ€”â€”é«˜ç²¾åº¦æ£®æ—å·¡æ£€](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2121)\n- [é¢†é‚¦æ™ºèƒ½â€”â€”çº¢å¤–æ— æ„Ÿæµ‹æ¸©ç›‘æ§](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2615)\n- [åŒ—äº¬åœ°é“â€”â€”å£ç½©æ£€æµ‹](https://mp.weixin.qq.com/s/znrqaJmtA7CcjG0yQESWig)\n- [éŸ³æ™ºè¾¾â€”â€”å·¥å‚äººå‘˜è¿è§„è¡Œä¸ºæ£€æµ‹](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2288)\n- [åå¤å¤©ä¿¡â€”â€”è¾“ç…¤çš®å¸¦æœºå™¨äººæ™ºèƒ½å·¡æ£€](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2331)\n- [ä¼˜æ©ç‰©è”ç½‘â€”â€”ç¤¾åŒºä½æˆ·åˆ†ç±»æ”¯æŒå¹¿å‘Šç²¾å‡†æŠ•æ”¾](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2485)\n- [è³è‚æ…§è§†â€”â€”å®¤å†…3Dç‚¹äº‘åœºæ™¯ç‰©ä½“åˆ†å‰²ä¸æ£€æµ‹](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2599)\n- æŒç»­æ›´æ–°ä¸­...\n\n## ğŸ“è®¸å¯è¯ä¹¦\n\næœ¬é¡¹ç›®çš„å‘å¸ƒå—[Apache 2.0 license](LICENSE)è®¸å¯è®¤è¯ã€‚\n\n\n## ğŸ“Œå¼•ç”¨\n\n```\n@misc{ppdet2019,\ntitle={PaddleDetection, Object detection and instance segmentation toolkit based on PaddlePaddle.},\nauthor={PaddlePaddle Authors},\nhowpublished = {\\url{https://github.com/PaddlePaddle/PaddleDetection}},\nyear={2019}\n}\n```\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 42.66015625,
          "content": "[ç®€ä½“ä¸­æ–‡](README_cn.md) | English\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/48054808/160532560-34cf7a1f-d950-435e-90d2-4b0a679e5119.png\" align=\"middle\" width = \"800\" />\n</p>\n\n**A High-Efficient Development Toolkit for Object Detection based onÂ [PaddlePaddle](https://github.com/paddlepaddle/paddle)**\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleDetection?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?color=ccf\"></a>\n</p>\n</div>\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/205581915-aa8d6bee-5624-4aec-8059-76b5ebaf96f1.gif\" width=\"800\"/>\n\n</div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157793354-6e7f381a-0aa6-4bb7-845c-9acf2ecc05c3.png\" width=\"20\"/> Product Update\n\n- ğŸ”¥ **2022.11.15ï¼šSOTA rotated object detector and small object detector based on PP-YOLOE**\n  - Rotated object detector [PP-YOLOE-R](configs/rotate/ppyoloe_r)\n    - SOTA Anchor-free rotated object detection model with high accuracy and efficiency\n    - A series of models, named s/m/l/x, for cloud and edge devices\n    - Avoiding using special operators to be deployed friendly with TensorRT.\n  - Small object detector [PP-YOLOE-SOD](configs/smalldet)\n    - End-to-end detection pipeline based on sliced images\n    - SOTA model on VisDrone based on original images.\n\n- 2022.8.26ï¼šPaddleDetection releases[release/2.5 version](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.5)\n\n  - ğŸ—³ Model featuresï¼š\n\n    - Release [PP-YOLOE+](configs/ppyoloe): Increased accuracy by a maximum of 2.4% mAP to 54.9% mAP, 3.75 times faster model training convergence rate, and up to 2.3 times faster end-to-end inference speed; improved generalization for multiple downstream tasks\n    - Release [PicoDet-NPU](configs/picodet) model which supports full quantization deployment of models; add [PicoDet](configs/picodet) layout analysis model\n    - Release [PP-TinyPose Plus](./configs/keypoint/tiny_pose/). With 9.1% AP accuracy improvement in physical exercise, dance, and other scenarios, our PP-TinyPose Plus supports unconventional movements such as turning to one side, lying down, jumping, and high lifts\n\n  - ğŸ”® Functions in different scenarios\n\n    - Release the pedestrian analysis tool [PP-Human v2](./deploy/pipeline). It introduces four new behavior recognition: fighting, telephoning, smoking, and trespassing. The underlying algorithm performance is optimized, covering three core algorithm capabilities: detection, tracking, and attributes of pedestrians. Our model provides end-to-end development and model optimization strategies for beginners and supports online video streaming input.\n    - First release [PP-Vehicle](./deploy/pipeline), which has four major functions: license plate recognition, vehicle attribute analysis (color, model), traffic flow statistics, and violation detection. It is compatible with input formats, including pictures, online video streaming, and video. And we also offer our users a comprehensive set of tutorials for customization.\n\n  - ğŸ’¡ Cutting-edge algorithmsï¼š\n\n    - Release [PaddleYOLO](https://github.com/PaddlePaddle/PaddleYOLO) which overs classic and latest models of [YOLO family](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/docs/MODEL_ZOO_en.md): YOLOv3, PP-YOLOE (a real-time high-precision object detection model developed by Baidu PaddlePaddle), and cutting-edge detection algorithms such as YOLOv4, YOLOv5, YOLOX, YOLOv6, YOLOv7 and YOLOv8\n    - Newly add high precision detection model based on [ViT](configs/vitdet) backbone network, with a 55.7% mAP accuracy on COCO dataset; newly add multi-object tracking model [OC-SORT](configs/mot/ocsort); newly add [ConvNeXt](configs/convnext) backbone network.\n\n  - ğŸ“‹ Industrial applications: Newly add [Smart Fitness](https://aistudio.baidu.com/aistudio/projectdetail/4385813), [Fighting recognition](https://aistudio.baidu.com/aistudio/projectdetail/4086987?channelType=0&channel=0),[ and Visitor Analysis](https://aistudio.baidu.com/aistudio/projectdetail/4230123?channelType=0&channel=0).\n\n- 2022.3.24ï¼šPaddleDetection released[release/2.4 version](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4)  \n  - Release high-performanace SOTA object detection model [PP-YOLOE](configs/ppyoloe). It integrates cloud and edge devices and provides S/M/L/X versions. In particular, Verson L has the accuracy as 51.4% on COCO test 2017 dataset, inference speed as 78.1 FPS on a single Test V100. It supports mixed precision training, 33% faster than PP-YOLOv2. Its full range of multi-sized models can meet different hardware arithmetic requirements, and adaptable to server, edge-device GPU and other AI accelerator cards on servers.\n  - Release ultra-lightweight SOTA object detection model [PP-PicoDet Plus](configs/picodet) with 2% improvement in accuracy and 63% improvement in CPU inference speed. Add PicoDet-XS model with a 0.7M parameter, providing model sparsification and quantization functions for model acceleration. No specific post processing module is required for all the hardware, simplifying the deployment.  \n  - Release the real-time pedestrian analysis tool [PP-Human](deploy/pphuman). It has four major functions: pedestrian tracking, visitor flow statistics, human attribute recognition and falling detection. For falling detection, it is optimized based on real-life data with accurate recognition of various types of falling posture. It can adapt to different environmental background, light and camera angle.\n  - Add [YOLOX](configs/yolox) object detection model with nano/tiny/S/M/L/X. X version has the accuracy as 51.8% on COCO  Val2017 dataset.\n\n- [More releases](https://github.com/PaddlePaddle/PaddleDetection/releases)\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157795569-9fc77c85-732f-4870-9be0-99a7fe2cff27.png\" alt=\"\" width=\"20\"> Brief Introduction\n\n**PaddleDetection** is an end-to-end object detection development kit based on PaddlePaddle. Providing **over 30 model algorithm** and **over 300 pre-trained models**, it covers object detection,Â instance segmentation,Â keypoint detection, multi-object tracking. In particular, PaddleDetection offers **high- performance & light-weight** industrial SOTA models on **servers and mobile** devices, champion solution and cutting-edge algorithm. PaddleDetection provides various data augmentation methods, configurable network components, loss functions and other advanced optimization & deployment schemes. In addition to running through the whole process of data processing, model development, training, compression and deployment, PaddlePaddle also provides rich cases and tutorials to accelerate the industrial application of algorithm.\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/189122825-ee1c1db2-b5f9-42c0-88b4-7975e1ec239d.gif\" width=\"800\"/>\n</div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157799599-e6a66855-bac6-4e75-b9c0-96e13cb9612f.png\" width=\"20\"/> Features\n\n- **Rich model library**:Â PaddleDetection provides over 250 pre-trained modelsÂ including **object detection,Â instance segmentation,Â face recognition, multi-object tracking**. It covers a variety ofÂ **global competition champion**Â schemes.\n- **Simple to use**: Modular design, decoupling each network component, easy for developers to build and try various detection models and optimization strategies, quick access to high-performance, customized algorithm.\n- **Getting Through End to End**: PaddlePaddle gets through end to end from data augmentation, constructing models, training, compression, depolyment. It also supports multi-architecture, multi-device deployment forÂ **cloud and edge** device.\n- **High Performance**:Â Due to the high performance core, PaddlePaddle has clear advantages in training speed and memory occupation. It also supports FP16 training and multi-machine training.\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/202131382-45fd2de6-3805-460e-a70c-66db7188d37c.png\" width=\"800\"/>\n</div>\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157800467-2a9946ad-30d1-49a9-b9db-ba33413d9c90.png\" alt=\"\" width=\"20\"> Exchanges\n\n- If you have any question or suggestion, please give us your valuable input via [GitHub Issues](https://github.com/PaddlePaddle/PaddleDetection/issues)\n\n  Welcome to join PaddleDetection user groups on WeChat (scan the QR code, add and reply \"D\" to the assistant)\n\n  <div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/34162360/177678712-4655747d-4290-4ad9-b7a1-4564a5418ac6.jpg\"  width = \"200\" />  \n  </div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157827140-03ffaff7-7d14-48b4-9440-c38986ea378c.png\" width=\"20\"/> Kit Structure\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"bottom\">\n      <td>\n        <b>Architectures</b>\n      </td>\n      <td>\n        <b>Backbones</b>\n      </td>\n      <td>\n        <b>Components</b>\n      </td>\n      <td>\n        <b>Data Augmentation</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n        <ul>\n        <details><summary><b>Object Detection</b></summary>\n          <ul>\n            <li>Faster RCNN</li>\n            <li>FPN</li>\n            <li>Cascade-RCNN</li>\n            <li>PSS-Det</li>\n            <li>RetinaNet</li>\n            <li>YOLOv3</li>  \n            <li>YOLOF</li>  \n            <li>YOLOX</li>  \n            <li>YOLOv5</li>  \n            <li>YOLOv6</li>  \n            <li>YOLOv7</li>  \n            <li>YOLOv8</li>  \n            <li>RTMDet</li>  \n            <li>PP-YOLO</li>\n            <li>PP-YOLO-Tiny</li>\n            <li>PP-PicoDet</li>\n            <li>PP-YOLOv2</li>\n            <li>PP-YOLOE</li>\n            <li>PP-YOLOE+</li>\n            <li>PP-YOLOE-SOD</li>\n            <li>PP-YOLOE-R</li>\n            <li>SSD</li>\n            <li>CenterNet</li>\n            <li>FCOS</li>  \n            <li>FCOSR</li>  \n            <li>TTFNet</li>\n            <li>TOOD</li>\n            <li>GFL</li>\n            <li>GFLv2</li>\n            <li>DETR</li>\n            <li>Deformable DETR</li>\n            <li>Swin Transformer</li>\n            <li>Sparse RCNN</li>\n         </ul></details>\n        <details><summary><b>Instance Segmentation</b></summary>\n         <ul>\n            <li>Mask RCNN</li>\n            <li>Cascade Mask RCNN</li>\n            <li>SOLOv2</li>\n        </ul></details>\n        <details><summary><b>Face Detection</b></summary>\n        <ul>\n            <li>BlazeFace</li>\n        </ul></details>\n        <details><summary><b>Multi-Object-Tracking</b></summary>\n        <ul>\n            <li>JDE</li>\n            <li>FairMOT</li>\n            <li>DeepSORT</li>\n            <li>ByteTrack</li>\n            <li>OC-SORT</li>\n            <li>BoT-SORT</li>\n            <li>CenterTrack</li>\n        </ul></details>\n        <details><summary><b>KeyPoint-Detection</b></summary>\n        <ul>\n            <li>HRNet</li>\n            <li>HigherHRNet</li>\n            <li>Lite-HRNet</li>\n            <li>PP-TinyPose</li>\n        </ul></details>\n      </ul>\n      </td>\n      <td>\n        <details><summary><b>Details</b></summary>\n        <ul>\n          <li>ResNet(&vd)</li>\n          <li>Res2Net(&vd)</li>\n          <li>CSPResNet</li>\n          <li>SENet</li>\n          <li>Res2Net</li>\n          <li>HRNet</li>\n          <li>Lite-HRNet</li>\n          <li>DarkNet</li>\n          <li>CSPDarkNet</li>\n          <li>MobileNetv1/v3</li>  \n          <li>ShuffleNet</li>\n          <li>GhostNet</li>\n          <li>BlazeNet</li>\n          <li>DLA</li>\n          <li>HardNet</li>\n          <li>LCNet</li>  \n          <li>ESNet</li>  \n          <li>Swin-Transformer</li>\n          <li>ConvNeXt</li>\n          <li>Vision Transformer</li>\n        </ul></details>\n      </td>\n      <td>\n        <details><summary><b>Common</b></summary>\n          <ul>\n            <li>Sync-BN</li>\n            <li>Group Norm</li>\n            <li>DCNv2</li>\n            <li>EMA</li>\n          </ul> </details>\n        </ul>\n        <details><summary><b>KeyPoint</b></summary>\n          <ul>\n            <li>DarkPose</li>\n          </ul></details>\n        </ul>\n        <details><summary><b>FPN</b></summary>\n          <ul>\n            <li>BiFPN</li>\n            <li>CSP-PAN</li>\n            <li>Custom-PAN</li>\n            <li>ES-PAN</li>\n            <li>HRFPN</li>\n          </ul> </details>\n        </ul>  \n        <details><summary><b>Loss</b></summary>\n          <ul>\n            <li>Smooth-L1</li>\n            <li>GIoU/DIoU/CIoU</li>  \n            <li>IoUAware</li>\n            <li>Focal Loss</li>\n            <li>CT Focal Loss</li>\n            <li>VariFocal Loss</li>\n          </ul> </details>\n        </ul>  \n        <details><summary><b>Post-processing</b></summary>\n          <ul>\n            <li>SoftNMS</li>\n            <li>MatrixNMS</li>  \n          </ul> </details>  \n        </ul>\n        <details><summary><b>Speed</b></summary>\n          <ul>\n            <li>FP16 training</li>\n            <li>Multi-machine training </li>  \n          </ul> </details>  \n        </ul>  \n      </td>\n      <td>\n        <details><summary><b>Details</b></summary>\n        <ul>\n          <li>Resize</li>  \n          <li>Lighting</li>  \n          <li>Flipping</li>  \n          <li>Expand</li>\n          <li>Crop</li>\n          <li>Color Distort</li>  \n          <li>Random Erasing</li>  \n          <li>Mixup </li>\n          <li>AugmentHSV</li>\n          <li>Mosaic</li>\n          <li>Cutmix </li>\n          <li>Grid Mask</li>\n          <li>Auto Augment</li>  \n          <li>Random Perspective</li>  \n        </ul> </details>  \n      </td>  \n    </tr>\n\n</td>\n    </tr>\n  </tbody>\n</table>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157801371-9a9a8c65-1690-4123-985a-e0559a7f9494.png\" width=\"20\"/> Model Performance\n\n<details>\n<summary><b> Performance comparison of Cloud models</b></summary>\n\nThe comparison between COCO mAP and FPS on Tesla V100 of representative models of each architectures and backbones.\n\n<div align=\"center\">\n  <img src=\"docs/images/fps_map.png\" />\n</div>\n\n**Clarificationï¼š**\n\n- `ViT` standsÂ forÂ `ViT-Cascade-Faster-RCNN`, which has highest mAP on COCO as 55.7%\n- `Cascade-Faster-RCNN`stands forÂ `Cascade-Faster-RCNN-ResNet50vd-DCN`, which has been optimized to 20 FPS inference speed when COCO mAP as 47.8% in PaddleDetection models\n- `PP-YOLOE` are optimized `PP-YOLO v2`. It reached accuracy as 51.4% on COCO dataset, inference speed as 78.1 FPS on Tesla V100\n- `PP-YOLOE+` are optimized `PP-YOLOE`. It reached accuracy as 53.3% on COCO dataset, inference speed as 78.1 FPS on Tesla V100\n- The models in the figure are available in the[ model library](#æ¨¡å‹åº“)\n\n</details>\n\n<details>\n<summary><b> Performance omparison on mobiles</b></summary>\n\nThe comparison between COCO mAP and FPS on Qualcomm Snapdragon 865 processor of models on mobile devices.\n\n<div align=\"center\">\n  <img src=\"docs/images/mobile_fps_map.png\" width=600/>\n</div>\n\n**Clarificationï¼š**\n\n- Tests were conducted on Qualcomm Snapdragon 865 (4 \\*A77 + 4 \\*A55) batch_size=1, 4 thread, and NCNN inference library, test script see [MobileDetBenchmark](https://github.com/JiweiMaster/MobileDetBenchmark)\n- [PP-PicoDet](configs/picodet) and [PP-YOLO-Tiny](configs/ppyolo) are self-developed models of PaddleDetection, and other models are not tested yet.\n\n</details>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157829890-a535b8a6-631c-4c87-b861-64d4b32b2d6a.png\" width=\"20\"/> Model libraries\n\n<details>\n<summary><b> 1. General detection</b></summary>\n\n#### PP-YOLOE series Recommended scenarios: Cloud GPU such as Nvidia V100, T4 and edge devices such as Jetson series\n\n| Model      | COCO Accuracyï¼ˆmAPï¼‰ | V100 TensorRT FP16 Speed(FPS) | Configuration                                           | Download                                                                                 |\n|:---------- |:------------------:|:-----------------------------:|:-------------------------------------------------------:|:----------------------------------------------------------------------------------------:|\n| PP-YOLOE+_s | 43.9        | 333.3                     | [link](configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml)     | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_s_80e_coco.pdparams)      |\n| PP-YOLOE+_m | 50.0        | 208.3                     | [link](configs/ppyoloe/ppyoloe_plus_crn_m_80e_coco.yml)     | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_m_80e_coco.pdparams)     |\n| PP-YOLOE+_l | 53.3        | 149.2                     | [link](configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml) | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_l_80e_coco.pdparams) |\n| PP-YOLOE+_x | 54.9        | 95.2                      | [link](configs/ppyoloe/ppyoloe_plus_crn_x_80e_coco.yml) | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_x_80e_coco.pdparams) |\n\n#### PP-PicoDet series Recommended scenarios: Mobile chips and x86 CPU devices, such as ARM CPU(RK3399, Raspberry Pi) and NPU(BITMAIN)\n\n| Model      | COCO Accuracyï¼ˆmAPï¼‰ | Snapdragon 865Â four-thread speed (ms) | Configuration                                         | Download                                                                              |\n|:---------- |:------------------:|:-------------------------------------:|:-----------------------------------------------------:|:-------------------------------------------------------------------------------------:|\n| PicoDet-XS | 23.5               | 7.81                                  | [Link](configs/picodet/picodet_xs_320_coco_lcnet.yml) | [Download](https://paddledet.bj.bcebos.com/models/picodet_xs_320_coco_lcnet.pdparams) |\n| PicoDet-S  | 29.1               | 9.56                                  | [Link](configs/picodet/picodet_s_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_s_320_coco_lcnet.pdparams)  |\n| PicoDet-M  | 34.4               | 17.68                                 | [Link](configs/picodet/picodet_m_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_m_320_coco_lcnet.pdparams)  |\n| PicoDet-L  | 36.1               | 25.21                                 | [Link](configs/picodet/picodet_l_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_l_320_coco_lcnet.pdparams)  |\n\n#### [Frontier detection algorithm](docs/feature_models/PaddleYOLO_MODEL.md)\n\n| Model    | COCO Accuracyï¼ˆmAPï¼‰ | V100 TensorRT FP16 speed(FPS) | Configuration                                                                                                  | Download                                                                       |\n|:-------- |:------------------:|:-----------------------------:|:--------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------:|\n| [YOLOX-l](configs/yolox)  | 50.1               | 107.5                         | [Link](configs/yolox/yolox_l_300e_coco.yml)                                                                    | [Download](https://paddledet.bj.bcebos.com/models/yolox_l_300e_coco.pdparams)  |\n| [YOLOv5-l](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5) | 48.6               | 136.0                         | [Link](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5/yolov5_l_300e_coco.yml) | [Download](https://paddledet.bj.bcebos.com/models/yolov5_l_300e_coco.pdparams) |\n| [YOLOv7-l](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7) | 51.0        | 135.0                     | [é“¾æ¥](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7/yolov7_l_300e_coco.yml) | [ä¸‹è½½åœ°å€](https://paddledet.bj.bcebos.com/models/yolov7_l_300e_coco.pdparams) |\n\n#### Other general purpose models [doc](docs/MODEL_ZOO_en.md)\n\n</details>\n\n<details>\n<summary><b> 2. Instance segmentation</b></summary>\n\n| Model             | Introduction                                             | Recommended Scenarios                         | COCO Accuracy(mAP)               | Configuration                                                           | Download                                                                                              |\n|:----------------- |:-------------------------------------------------------- |:--------------------------------------------- |:--------------------------------:|:-----------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------:|\n| Mask RCNN         | Two-stage instance segmentation algorithm                | <div style=\"width: 50pt\">Edge-Cloud end</div> | box AP: 41.4 <br/> mask AP: 37.5 | [Link](configs/mask_rcnn/mask_rcnn_r50_vd_fpn_2x_coco.yml)              | [Download](https://paddledet.bj.bcebos.com/models/mask_rcnn_r50_vd_fpn_2x_coco.pdparams)              |\n| Cascade Mask RCNN | Two-stage instance segmentation algorithm                | <div style=\"width: 50pt\">Edge-Cloud end</div> | box AP: 45.7 <br/> mask AP: 39.7 | [Link](configs/mask_rcnn/cascade_mask_rcnn_r50_vd_fpn_ssld_2x_coco.yml) | [Download](https://paddledet.bj.bcebos.com/models/cascade_mask_rcnn_r50_vd_fpn_ssld_2x_coco.pdparams) |\n| SOLOv2            | Lightweight single-stage instance segmentation algorithm | <div style=\"width: 50pt\">Edge-Cloud end</div> | mask AP: 38.0                    | [Link](configs/solov2/solov2_r50_fpn_3x_coco.yml)                       | [Download](https://paddledet.bj.bcebos.com/models/solov2_r50_fpn_3x_coco.pdparams)                    |\n\n</details>\n\n<details>\n<summary><b> 3. Keypoint detection</b></summary>\n\n| Model                | Introduction                                                                                  | Recommended scenarios                         | COCO Accuracyï¼ˆAPï¼‰ | Speed                             | Configuration                                             | Download                                                                                    |\n|:-------------------- |:--------------------------------------------------------------------------------------------- |:--------------------------------------------- |:-----------------:|:---------------------------------:|:---------------------------------------------------------:|:-------------------------------------------------------------------------------------------:|\n| HRNet-w32 + DarkPose | <div style=\"width: 130pt\">Top-down Keypoint detection algorithm<br/>Input size: 384x288</div> | <div style=\"width: 50pt\">Edge-Cloud end</div> | 78.3              | T4 TensorRT FP16 2.96ms           | [Link](configs/keypoint/hrnet/dark_hrnet_w32_384x288.yml) | [Download](https://paddledet.bj.bcebos.com/models/keypoint/dark_hrnet_w32_384x288.pdparams) |\n| HRNet-w32 + DarkPose | Top-down Keypoint detection algorithm<br/>Input size: 256x192                                 | Edge-Cloud end                                | 78.0              | T4 TensorRT FP16 1.75ms           | [Link](configs/keypoint/hrnet/dark_hrnet_w32_256x192.yml) | [Download](https://paddledet.bj.bcebos.com/models/keypoint/dark_hrnet_w32_256x192.pdparams) |\n| PP-TinyPose          | Light-weight keypoint algorithm<br/>Input size: 256x192                                       | Mobile                                        | 68.8              | Snapdragon 865Â four-thread 6.30ms | [Link](configs/keypoint/tiny_pose/tinypose_256x192.yml)   | [Download](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_256x192.pdparams)    |\n| PP-TinyPose          | Light-weight keypoint algorithm<br/>Input size: 128x96                                        | Mobile                                        | 58.1              | Snapdragon 865Â four-thread 2.37ms | [Link](configs/keypoint/tiny_pose/tinypose_128x96.yml)    | [Download](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_128x96.pdparams)     |\n\n#### Other keypoint detection models [doc](configs/keypoint)\n\n</details>\n\n<details>\n<summary><b> 4. Multi-object tracking PP-Tracking</b></summary>\n\n| Model     | Introduction                                                  | Recommended scenarios | Accuracy               | Configuration                                                           | Download                                                                                              |\n|:--------- |:------------------------------------------------------------- |:--------------------- |:----------------------:|:-----------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------:|\n| ByteTrack | SDE Multi-object tracking algorithm with detection model only | Edge-Cloud end        | MOT-17 half val:  77.3 | [Link](configs/mot/bytetrack/detector/yolox_x_24e_800x1440_mix_det.yml) | [Download](https://paddledet.bj.bcebos.com/models/mot/deepsort/yolox_x_24e_800x1440_mix_det.pdparams) |\n| FairMOT   | JDE multi-object tracking algorithm multi-task learning       | Edge-Cloud end        | MOT-16 test: 75.0      | [Link](configs/mot/fairmot/fairmot_dla34_30e_1088x608.yml)              | [Download](https://paddledet.bj.bcebos.com/models/mot/fairmot_dla34_30e_1088x608.pdparams)            |\n| OC-SORT   | SDE multi-object tracking algorithm with detection model only       | Edge-Cloud end        | MOT-16 half val: 75.5      | [Link](configs/mot/ocsort/ocsort_yolox.yml)              | -            |\n\n#### Other multi-object tracking models [docs](configs/mot)\n\n</details>\n\n<details>\n<summary><b> 5. Industrial real-time pedestrain analysis tool-PP Human</b></summary>\n\n| Task                                   | End-to-End Speedï¼ˆmsï¼‰ | Model                                                                                                                                                                                                                                                                                                                           | Size                                                                                                   |\n|:--------------------------------------:|:--------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------:|\n| Pedestrian detection (high precision)  | 25.1ms               | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Pedestrian detection (lightweight)     | 16.2ms               | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Pedestrian tracking (high precision)   | 31.8ms               | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Pedestrian tracking (lightweight)      | 21.0ms               | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Attribute recognition (high precision) | Single person8.5ms   | [ObjectÂ detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [AttributeÂ recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/strongbaseline_r50_30e_pa100k.zip)                                                                                                         | Object detectionï¼š182M<br>Attribute recognitionï¼š86M                                                     |\n| Attribute recognition (lightweight)    | Single person 7.1ms  | [ObjectÂ detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [AttributeÂ recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/strongbaseline_r50_30e_pa100k.zip)                                                                                                         | Object detectionï¼š182M<br>Attribute recognitionï¼š86M                                                     |\n| Falling detection                      | Single person 10ms   | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip) <br> [KeypointÂ detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip) <br> [Behavior detection based on key points](https://bj.bcebos.com/v1/paddledet/models/pipeline/STGCN.zip) | Multi-object trackingï¼š182M<br>Keypoint detectionï¼š101M<br>Behavior detection based on key points: 21.8M |\n| Intrusion detection                    | 31.8ms               | [Multi-objectÂ tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Fighting detection                     | 19.7ms               | [VideoÂ classification](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                       | 90M                                                                                                    |\n| Smoking detection                      | Single person 15.1ms | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[Object detection based on Human Id](https://bj.bcebos.com/v1/paddledet/models/pipeline/ppyoloe_crn_s_80e_smoking_visdrone.zip)                                                                                        | Object detectionï¼š182M<br>Object detection based on Human ID: 27M                                       |\n| Phoning detection                      | Single person ms     | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[Image classification based on Human ID](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_tiny_calling_halfbody.zip)                                                                                         | Object detectionï¼š182M<br>Image classification based on Human IDï¼š45M                                    |\n\nPlease refer to [docs](deploy/pipeline/README_en.md) for details.\n\n</details>\n\n<details>\n<summary><b> 6. Industrial real-time vehicle analysis tool-PP Vehicle</b></summary>\n\n| Task                                   | End-to-End Speedï¼ˆmsï¼‰ | Model                                                                                                                                                                                                                                                                                                                           | Size                                                                                                   |\n|:--------------------------------------:|:--------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------:|\n| Vehicle detection (high precision)  | 25.7ms               | [object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Vehicle detection (lightweight)     | 13.2ms               | [object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Vehicle tracking (high precision)   | 40ms               | [multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Vehicle tracking (lightweight)      | 25ms               | [multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Plate Recognition                   | 4.68ms     | [plate detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_det_infer.tar.gz)<br>[plate recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_rec_infer.tar.gz)                                                                                         | Plate detectionï¼š3.9M<br>Plate recognitionï¼š12M                                    |\n| Vehicle attribute      | 7.31ms               | [attribute recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/vehicle_attribute_model.zip)                                                                                                                                                                                                                      | 7.2M                                                                                                    |\n\nPlease refer to [docs](deploy/pipeline/README_en.md) for details.\n\n</details>\n\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157828296-d5eb0ccb-23ea-40f5-9957-29853d7d13a9.png\" width=\"20\"/>Document tutorials\n\n### Introductory tutorials\n\n- [Installation](docs/tutorials/INSTALL_cn.md)\n- [Quick start](docs/tutorials/QUICK_STARTED_cn.md)\n- [Data preparation](docs/tutorials/data/README.md)\n- [Geting Started on PaddleDetection](docs/tutorials/GETTING_STARTED_cn.md)\n- [FAQ](docs/tutorials/FAQ)\n\n### Advanced tutorials\n\n- Configuration\n\n  - [RCNN Configuration](docs/tutorials/config_annotation/faster_rcnn_r50_fpn_1x_coco_annotation.md)\n  - [PP-YOLO Configuration](docs/tutorials/config_annotation/ppyolo_r50vd_dcn_1x_coco_annotation.md)\n\n- Compression based on [PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim)\n\n  - [Pruning/Quantization/Distillation Tutorial](configs/slim)\n\n- [Inference deployment](deploy/README.md)\n\n  - [Export model for inference](deploy/EXPORT_MODEL.md)\n\n  - [Paddle Inference deployment](deploy/README.md)\n\n    - [Inference deployment with Python](deploy/python)\n    - [Inference deployment with C++](deploy/cpp)\n\n  - [Paddle-Lite deployment](deploy/lite)\n\n  - [Paddle Serving deployment](deploy/serving)\n\n  - [ONNX model export](deploy/EXPORT_ONNX_MODEL.md)\n\n  - [Inference benchmark](deploy/BENCHMARK_INFER.md)\n\n- Advanced development\n\n  - [Data processing module](docs/advanced_tutorials/READER.md)\n  - [New object detection models](docs/advanced_tutorials/MODEL_TECHNICAL.md)\n  - Custumization\n    - [Object detection](docs/advanced_tutorials/customization/detection.md)\n    - [Keypoint detection](docs/advanced_tutorials/customization/keypoint_detection.md)\n    - [Multiple object tracking](docs/advanced_tutorials/customization/pphuman_mot.md)\n    - [Action recognition](docs/advanced_tutorials/customization/action_recognotion/)\n    - [Attribute recognition](docs/advanced_tutorials/customization/pphuman_attribute.md)\n\n### Courses\n\n- **[Theoretical foundation] [Object detection 7-day camp](https://aistudio.baidu.com/aistudio/education/group/info/1617):** Overview of object detection tasks, details of RCNN series object detection algorithm and YOLO series object detection algorithm, PP-YOLO optimization strategy and case sharing, introduction and practice of AnchorFree series algorithm\n\n- **[Industrial application] [AI Fast Track industrial object detection technology and application](https://aistudio.baidu.com/aistudio/education/group/info/23670):** Super object detection algorithms, real-time pedestrian analysis system PP-Human, breakdown and practice of object detection industrial application\n\n- **[Industrial features] 2022.3.26** **[Smart City Industry Seven-Day Class](https://aistudio.baidu.com/aistudio/education/group/info/25620)** : Urban planning, Urban governance, Smart governance service, Traffic management, community governance.\n\n- **[Academic exchange] 2022.9.27 [YOLO Vision Event](https://www.youtube.com/playlist?list=PL1FZnkj4ad1NHVC7CMc3pjSQ-JRK-Ev6O):** As the first YOLO-themed event, PaddleDetection was invited to communicate with the experts in the field of Computer Vision around the world.\n\n### [Industrial tutorial examples](./industrial_tutorial/README.md)\n\n- [Rotated object detection based on PP-YOLOE-R](https://aistudio.baidu.com/aistudio/projectdetail/5058293)\n\n- [Aerial image detection based on PP-YOLOE-SOD](https://aistudio.baidu.com/aistudio/projectdetail/5036782)\n\n- [Fall down recognition based on PP-Human v2](https://aistudio.baidu.com/aistudio/projectdetail/4606001)\n\n- [Intelligent fitness recognition based on PP-TinyPose Plus](https://aistudio.baidu.com/aistudio/projectdetail/4385813)\n\n- [Road litter detection based on PP-PicoDet Plus](https://aistudio.baidu.com/aistudio/projectdetail/3561097)\n\n- [Visitor flow statistics based on FairMOT](https://aistudio.baidu.com/aistudio/projectdetail/2421822)\n\n- [Guest analysis based on PP-Human](https://aistudio.baidu.com/aistudio/projectdetail/4537344)\n\n- [More examples](./industrial_tutorial/README.md)\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157836473-1cf451fa-f01f-4148-ba68-b6d06d5da2f9.png\" alt=\"\" width=\"20\"> Applications\n\n- [Fitness app on android mobile](https://github.com/zhiboniu/pose_demo_android)\n- [PP-Tracking GUI Visualization Interface](https://github.com/yangyudong2020/PP-Tracking_GUi)\n\n## Recommended third-party tutorials\n\n- [Deployment of PaddleDetection for Windows I ](https://zhuanlan.zhihu.com/p/268657833)\n- [Deployment of PaddleDetection for Windows II](https://zhuanlan.zhihu.com/p/280206376)\n- [Deployment of PaddleDetection on Jestson Nano](https://zhuanlan.zhihu.com/p/319371293)\n- [How to deploy YOLOv3 model on Raspberry Pi for Helmet detection](https://github.com/PaddleCV-FAQ/PaddleDetection-FAQ/blob/main/Lite%E9%83%A8%E7%BD%B2/yolov3_for_raspi.md)\n- [Use SSD-MobileNetv1 for a project -- From dataset to deployment on Raspberry Pi](https://github.com/PaddleCV-FAQ/PaddleDetection-FAQ/blob/main/Lite%E9%83%A8%E7%BD%B2/ssd_mobilenet_v1_for_raspi.md)\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835981-ef6057b4-6347-4768-8fcc-cd07fcc3d8b0.png\" width=\"20\"/> Version updates\n\nPlease refer to the[ Release note ](https://github.com/PaddlePaddle/Paddle/wiki/PaddlePaddle-2.3.0-Release-Note-EN)for more details about the updates\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157835345-f5d24128-abaf-4813-b793-d2e5bdc70e5a.png\" alt=\"\" width=\"20\">  License\n\nPaddlePaddle is provided under the [Apache 2.0 license](LICENSE)\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835796-08d4ffbc-87d9-4622-89d8-cf11a44260fc.png\" width=\"20\"/> Contribute your code\n\nWe appreciate your contributions and your feedbackï¼\n\n- Thank [Mandroide](https://github.com/Mandroide) for code cleanup and\n- Thank [FL77N](https://github.com/FL77N/) for `Sparse-RCNN`model\n- Thank [Chen-Song](https://github.com/Chen-Song) for `Swin Faster-RCNN`model\n- Thank [yangyudong](https://github.com/yangyudong2020), [hchhtc123](https://github.com/hchhtc123) for developing PP-Tracking GUI interface\n- Thank Shigure19 for developing PP-TinyPose fitness APP\n- Thank [manangoel99](https://github.com/manangoel99) for Wandb visualization methods\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835276-9aab9d1c-1c46-446b-bdd4-5ab75c5cfa48.png\" width=\"20\"/> Quote\n\n```\n@misc{ppdet2019,\ntitle={PaddleDetection, Object detection and instance segmentation toolkit based on PaddlePaddle.},\nauthor={PaddlePaddle Authors},\nhowpublished = {\\url{https://github.com/PaddlePaddle/PaddleDetection}},\nyear={2019}\n}\n```\n"
        },
        {
          "name": "activity",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataset",
          "type": "tree",
          "content": null
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "deploy",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "industrial_tutorial",
          "type": "tree",
          "content": null
        },
        {
          "name": "ppdet",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.30078125,
          "content": "numpy < 2.0\ntqdm\ntypeguard\nvisualdl>=2.2.0\nopencv-python <= 4.6.0\nPyYAML\nshapely\nscipy\nterminaltables\nCython\npycocotools\nsetuptools\nPillow\n\n# for MOT evaluation and inference\nlapx\nmotmetrics\nsklearn==0.0\n\n# for vehicleplate in deploy/pipeline/ppvehicle\npyclipper\n\n# for culane data augumetation\nimgaug>=0.4.0"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.919921875,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport os.path as osp\nimport glob\nimport shutil\nimport subprocess\nfrom setuptools import find_packages, setup\n\n# ==============  version definition  ==============\n\nPPDET_VERSION = \"0.0.0\"\n\n\ndef parse_version():\n    return PPDET_VERSION.replace('-', '')\n\n\ndef git_commit():\n    try:\n        cmd = ['git', 'rev-parse', 'HEAD']\n        git_commit = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE, ).communicate()[0].strip()\n        git_commit = git_commit.decode()\n    except:\n        git_commit = 'Unknown'\n\n    return str(git_commit)\n\n\ndef write_version_py(filename='ppdet/version.py'):\n    ver_str = \"\"\"# THIS FILE IS GENERATED FROM PADDLEPADDLE SETUP.PY\n#\nfull_version    = '%(version)s'\ncommit          = '%(commit)s'\n\"\"\"\n\n    _git_commit = git_commit()\n    with open(filename, 'w') as f:\n        f.write(ver_str % {'version': PPDET_VERSION, 'commit': _git_commit})\n\n\nwrite_version_py()\n\n# ==============  version definition  ==============\n\n\ndef readme():\n    with open('README.md', encoding='utf-8') as f:\n        content = f.read()\n    return content\n\n\ndef parse_requirements(fname):\n    with open(fname, encoding=\"utf-8-sig\") as f:\n        requirements = f.readlines()\n    return requirements\n\n\ndef package_model_zoo():\n    cur_dir = osp.dirname(osp.realpath(__file__))\n    cfg_dir = osp.join(cur_dir, \"configs\")\n    cfgs = glob.glob(osp.join(cfg_dir, '*/*.yml'))\n\n    valid_cfgs = []\n    for cfg in cfgs:\n        # exclude dataset base config\n        if osp.split(osp.split(cfg)[0])[1] not in ['datasets']:\n            valid_cfgs.append(cfg)\n    model_names = [\n        osp.relpath(cfg, cfg_dir).replace(\".yml\", \"\") for cfg in valid_cfgs\n    ]\n\n    model_zoo_file = osp.join(cur_dir, 'ppdet', 'model_zoo', 'MODEL_ZOO')\n    with open(model_zoo_file, 'w') as wf:\n        for model_name in model_names:\n            wf.write(\"{}\\n\".format(model_name))\n\n    return [model_zoo_file]\n\n\npackages = [\n    'ppdet',\n    'ppdet.core',\n    'ppdet.data',\n    'ppdet.engine',\n    'ppdet.metrics',\n    'ppdet.modeling',\n    'ppdet.model_zoo',\n    'ppdet.slim',\n    'ppdet.utils',\n]\n\nif __name__ == \"__main__\":\n    setup(\n        name='paddledet',\n        packages=find_packages(exclude=(\"configs\", \"tools\", \"deploy\")),\n        package_data={'ppdet.model_zoo': package_model_zoo()},\n        author='PaddlePaddle',\n        version=parse_version(),\n        install_requires=parse_requirements('./requirements.txt'),\n        description='Object detection and instance segmentation toolkit based on PaddlePaddle',\n        long_description=readme(),\n        long_description_content_type='text/markdown',\n        url='https://github.com/PaddlePaddle/PaddleDetection',\n        download_url='https://github.com/PaddlePaddle/PaddleDetection.git',\n        keywords=['ppdet paddle ppyolo'],\n        classifiers=[\n            'Intended Audience :: Developers',\n            'License :: OSI Approved :: Apache Software License',\n            'Operating System :: OS Independent',\n            'Natural Language :: Chinese (Simplified)',\n            'Programming Language :: Python :: 3',\n            'Programming Language :: Python :: 3.5',\n            'Programming Language :: Python :: 3.6',\n            'Programming Language :: Python :: 3.7',\n            'Programming Language :: Python :: 3.8', 'Topic :: Utilities'\n        ],\n        license='Apache License 2.0',\n        ext_modules=[])\n"
        },
        {
          "name": "test_tipc",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}