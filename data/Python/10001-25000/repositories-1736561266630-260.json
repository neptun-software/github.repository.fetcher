{
  "metadata": {
    "timestamp": 1736561266630,
    "page": 260,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "PaddlePaddle/PaddleDetection",
      "stars": 12988,
      "defaultBranch": "release/2.8",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.119140625,
          "content": "# Virtualenv\n/.venv/\n/venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n.ipynb_checkpoints/\n*.py[cod]\n\n# C extensions\n*.so\n\n# json file\n*.json\n\n# log file\n*.log\n\n# Distribution / packaging\n/bin/\n*build/\n/develop-eggs/\n*dist/\n/eggs/\n/lib/\n/lib64/\n/output/\n/inference_model/\n/output_inference/\n/parts/\n/sdist/\n/var/\n*.egg-info/\n/.installed.cfg\n/*.egg\n/.eggs\n\n# AUTHORS and ChangeLog will be generated while packaging\n/AUTHORS\n/ChangeLog\n\n# BCloud / BuildSubmitter\n/build_submitter.*\n/logger_client_log\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\n.tox/\n.coverage\n.cache\n.pytest_cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n\n# Sphinx documentation\n/docs/_build/\n\n*.tar\n*.pyc\n\n.idea/\n\ndataset/coco/annotations\ndataset/coco/train2017\ndataset/coco/val2017\ndataset/voc/VOCdevkit\ndataset/fruit/fruit-detection/\ndataset/voc/test.txt\ndataset/voc/trainval.txt\ndataset/wider_face/WIDER_test\ndataset/wider_face/WIDER_train\ndataset/wider_face/WIDER_val\ndataset/wider_face/wider_face_split\ndataset/mot/*\ndataset/mot/**\n\nlog/*\n\nppdet/version.py\n\n# NPU meta folder\nkernel_meta/\n\n# MAC\n*.DS_Store\n\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.1845703125,
          "content": "repos:\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: a11d9314b22d8f8c7556443875b731ef05965464\n    hooks:\n    -   id: check-merge-conflict\n    -   id: check-symlinks\n    -   id: detect-private-key\n        files: (?!.*paddle)^.*$\n    -   id: end-of-file-fixer\n        files: \\.(md|yml)$\n    -   id: trailing-whitespace\n        files: \\.(md|yml)$\n-   repo: https://github.com/Lucas-C/pre-commit-hooks\n    rev: v1.0.1\n    hooks:\n    -   id: forbid-crlf\n        files: \\.(md|yml)$\n    -   id: remove-crlf\n        files: \\.(md|yml)$\n    -   id: forbid-tabs\n        files: \\.(md|yml)$\n    -   id: remove-tabs\n        files: \\.(md|yml)$\n-   repo: local\n    hooks:\n    -   id: clang-format-with-version-check\n        name: clang-format\n        description: Format files with ClangFormat.\n        entry: bash ./.travis/codestyle/clang_format.hook -i\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx|proto)$\n\n-   repo: local\n    hooks:\n    -   id: cpplint-cpp-source\n        name: cpplint\n        description: Check C++ code style using cpplint.py.\n        entry: bash ./.travis/codestyle/cpplint_pre_commit.hook\n        language: system\n        files: \\.(c|cc|cxx|cpp|cu|h|hpp|hxx)$\n"
        },
        {
          "name": ".style.yapf",
          "type": "blob",
          "size": 0.046875,
          "content": "[style]\nbased_on_style = pep8\ncolumn_limit = 80\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.833984375,
          "content": "language: cpp\ncache: ccache\nsudo: required\ndist: trusty\nservices:\n  - docker\nos:\n  - linux\nenv:\n  - JOB=PRE_COMMIT\n\naddons:\n  apt:\n    packages:\n      - git\n      - python\n      - python-pip\n      - python2.7-dev\n  ssh_known_hosts: 13.229.163.131\nbefore_install:\n  - sudo pip install -U virtualenv pre-commit pip -i https://pypi.tuna.tsinghua.edu.cn/simple\n  - docker pull paddlepaddle/paddle:latest\n  - git pull https://github.com/PaddlePaddle/PaddleDetection develop\n\nscript:\n  - exit_code=0\n  - .travis/precommit.sh || exit_code=$(( exit_code | $? ))\n  # - docker run -i --rm -v \"$PWD:/py_unittest\" paddlepaddle/paddle:latest /bin/bash -c\n  #   'cd /py_unittest; sh .travis/unittest.sh' || exit_code=$(( exit_code | $? ))\n  - if [ $exit_code -eq 0  ]; then true; else exit 1; fi;\n\nnotifications:\n  email:\n    on_success: change\n    on_failure: always\n"
        },
        {
          "name": ".travis",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.01171875,
          "content": "README_cn.md"
        },
        {
          "name": "README_cn.md",
          "type": "blob",
          "size": 60.7255859375,
          "content": "简体中文 | [English](README_en.md)\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/48054808/160532560-34cf7a1f-d950-435e-90d2-4b0a679e5119.png\" align=\"middle\" width = \"800\" />\n</p>\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleDetection?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?color=ccf\"></a>\n</p>\n</div>\n\n## 💌目录\n- [💌目录](#目录)\n- [🌈简介](#简介)\n- [📣最新进展](#最新进展)\n- [⚡️快速开始](#️快速开始)\n- [🔥低代码全流程开发](#低代码全流程开发)\n- [👫开源社区](#开源社区)\n- [✨主要特性](#主要特性)\n    - [🧩模块化设计](#模块化设计)\n    - [📱丰富的模型库](#丰富的模型库)\n    - [🎗️产业特色模型|产业工具](#️产业特色模型产业工具)\n    - [💡🏆产业级部署实践](#产业级部署实践)\n- [🍱安装](#安装)\n- [🔥教程](#教程)\n- [🔑FAQ](#faq)\n- [🧩模块组件](#模块组件)\n- [📱模型库](#模型库)\n- [⚖️模型性能对比](#️模型性能对比)\n    - [🖥️服务器端模型性能对比](#️服务器端模型性能对比)\n    - [⌚️移动端模型性能对比](#️移动端模型性能对比)\n- [🎗️产业特色模型|产业工具](#️产业特色模型产业工具-1)\n  - [💎PP-YOLOE 高精度目标检测模型](#pp-yoloe-高精度目标检测模型)\n  - [💎PP-YOLOE-R 高性能旋转框检测模型](#pp-yoloe-r-高性能旋转框检测模型)\n  - [💎PP-YOLOE-SOD 高精度小目标检测模型](#pp-yoloe-sod-高精度小目标检测模型)\n  - [💫PP-PicoDet 超轻量实时目标检测模型](#pp-picodet-超轻量实时目标检测模型)\n  - [📡PP-Tracking 实时多目标跟踪系统](#pp-tracking-实时多目标跟踪系统)\n  - [⛷️PP-TinyPose 人体骨骼关键点识别](#️pp-tinypose-人体骨骼关键点识别)\n  - [🏃🏻PP-Human 实时行人分析工具](#pp-human-实时行人分析工具)\n  - [🏎️PP-Vehicle 实时车辆分析工具](#️pp-vehicle-实时车辆分析工具)\n- [💡产业实践范例](#产业实践范例)\n- [🏆企业应用案例](#企业应用案例)\n- [📝许可证书](#许可证书)\n- [📌引用](#引用)\n\n\n## 🌈简介\n\nPaddleDetection是一个基于PaddlePaddle的目标检测端到端开发套件，在提供丰富的模型组件和测试基准的同时，注重端到端的产业落地应用，通过打造产业级特色模型|工具、建设产业应用范例等手段，帮助开发者实现数据准备、模型选型、模型训练、模型部署的全流程打通，快速进行落地应用。\n\n主要模型效果示例如下（点击标题可快速跳转）：\n\n|                                                  [**通用目标检测**](#pp-yoloe-高精度目标检测模型)                                                  |                                                [**小目标检测**](#pp-yoloe-sod-高精度小目标检测模型)                                                |                                                  [**旋转框检测**](#pp-yoloe-r-高性能旋转框检测模型)                                                  |                                            [**3D目标物检测**](https://github.com/PaddlePaddle/Paddle3D)                                            |\n| :--------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------: |\n| <img src='https://user-images.githubusercontent.com/61035602/206095864-f174835d-4e9a-42f7-96b8-d684fc3a3687.png' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095892-934be83a-f869-4a31-8e52-1074184149d1.jpg' height=\"126px\" width=\"180px\"> |  <img src='https://user-images.githubusercontent.com/61035602/206111796-d9a9702a-c1a0-4647-b8e9-3e1307e9d34c.png' height=\"126px\" width=\"180px\">  | <img src='https://user-images.githubusercontent.com/61035602/206095622-cf6dbd26-5515-472f-9451-b39bbef5b1bf.gif' height=\"126px\" width=\"180px\"> |\n|                                                              [**人脸检测**](#模型库)                                                               |                                                [**2D关键点检测**](#️pp-tinypose-人体骨骼关键点识别)                                                 |                                                  [**多目标追踪**](#pp-tracking-实时多目标跟踪系统)                                                   |                                                              [**实例分割**](#模型库)                                                               |\n| <img src='https://user-images.githubusercontent.com/61035602/206095684-72f42233-c9c7-4bd8-9195-e34859bd08bf.jpg' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206100220-ab01d347-9ff9-4f17-9718-290ec14d4205.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206111753-836e7827-968e-4c80-92ef-7a78766892fc.gif' height=\"126px\" width=\"180px\"  > | <img src='https://user-images.githubusercontent.com/61035602/206095831-cc439557-1a23-4a99-b6b0-b6f2e97e8c57.jpg' height=\"126px\" width=\"180px\"> |\n|                                               [**车辆分析——车牌识别**](#️pp-vehicle-实时车辆分析工具)                                               |                                               [**车辆分析——车流统计**](#️pp-vehicle-实时车辆分析工具)                                               |                                                [**车辆分析——违章检测**](#️pp-vehicle-实时车辆分析工具)                                                |                                               [**车辆分析——属性分析**](#️pp-vehicle-实时车辆分析工具)                                               |\n| <img src='https://user-images.githubusercontent.com/61035602/206099328-2a1559e0-3b48-4424-9bad-d68f9ba5ba65.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095918-d0e7ad87-7bbb-40f1-bcc1-37844e2271ff.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206100295-7762e1ab-ffce-44fb-b69d-45fb93657fa0.gif' height=\"126px\" width=\"180px\"  > | <img src='https://user-images.githubusercontent.com/61035602/206095905-8255776a-d8e6-4af1-b6e9-8d9f97e5059d.gif' height=\"126px\" width=\"180px\"> |\n|                                                [**行人分析——闯入分析**](#pp-human-实时行人分析工具)                                                |                                                [**行人分析——行为分析**](#pp-human-实时行人分析工具)                                                |                                                 [**行人分析——属性分析**](#pp-human-实时行人分析工具)                                                 |                                                [**行人分析——人流统计**](#pp-human-实时行人分析工具)                                                |\n| <img src='https://user-images.githubusercontent.com/61035602/206095792-ae0ac107-cd8e-492a-8baa-32118fc82b04.gif' height=\"126px\" width=\"180px\"> | <img src='https://user-images.githubusercontent.com/61035602/206095778-fdd73e5d-9f91-48c7-9d3d-6f2e02ec3f79.gif' height=\"126px\" width=\"180px\"> |  <img src='https://user-images.githubusercontent.com/61035602/206095709-2c3a209e-6626-45dd-be16-7f0bf4d48a14.gif' height=\"126px\" width=\"180px\">  | <img src=\"https://user-images.githubusercontent.com/61035602/206113351-cc59df79-8672-4d76-b521-a15acf69ae78.gif\" height=\"126px\" width=\"180px\"> |\n\n同时，PaddleDetection提供了模型的在线体验功能，用户可以选择自己的数据进行在线推理。\n\n\n## 📣最新进展\n\n- **🔥2024.10.1 添加目标检测、实例分割领域一站式全流程开发能力**:  \n  *  飞桨低代码开发工具PaddleX，依托于PaddleDetection的先进技术，支持了目标检测领域的**一站式全流程**开发能力：\n     * 🎨 [**模型丰富一键调用**](docs/paddlex/quick_start.md)：将通用目标检测、小目标检测和实例分割涉及的**55个模型**整合为3条模型产线，通过极简的**Python API一键调用**，快速体验模型效果。此外，同一套API，也支持图像分类、图像分割、文本图像智能分析、通用OCR、时序预测等共计**200+模型**，形成20+单功能模块，方便开发者进行**模型组合使用**。\n     * 🚀 [**提高效率降低门槛**](docs/paddlex/overview.md)：提供基于**统一命令**和**图形界面**两种方式，实现模型简洁高效的使用、组合与定制。支持**高性能部署、服务化部署和端侧部署**等多种部署方式。此外，对于各种主流硬件如**英伟达GPU、昆仑芯、昇腾、寒武纪和海光**等，进行模型开发时，都可以**无缝切换**。\n     \n  *  添加实例分割SOTA模型[**Mask-RT-DETR**](https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/cv_modules/instance_segmentation.html)\n\n**🔥超越YOLOv8，飞桨推出精度最高的实时检测器RT-DETR！**\n\n  <div align=\"center\">\n  <img src=\"https://github.com/PaddlePaddle/PaddleDetection/assets/17582080/196b0a10-d2e8-401c-9132-54b9126e0a33\"  height = \"500\" caption='' />\n  <p></p>\n  </div>\n\n  - `RT-DETR解读文章传送门`：\n    -  [《超越YOLOv8，飞桨推出精度最高的实时检测器RT-DETR！》](https://mp.weixin.qq.com/s/o03QM2rZNjHVto36gcV0Yw)\n  - `代码传送门`：[RT-DETR](https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/rtdetr)\n\n\n## [⚡️快速开始](/docs/paddlex/quick_start.md)\n\n## [🔥低代码全流程开发](/docs/paddlex/overview.md)\n\n\n## 👫开源社区\n\n\n- **🏅️社区贡献：** PaddleDetection非常欢迎你加入到飞桨社区的开源建设中，参与贡献方式可以参考[开源项目开发指南](docs/contribution/README.md)。\n- [**🎈社区近期活动**](community.md)\n\n\n\n## ✨主要特性\n\n#### 🧩模块化设计\nPaddleDetection将检测模型解耦成不同的模块组件，通过自定义模块组件组合，用户可以便捷高效地完成检测模型的搭建。`传送门`：[🧩模块组件](#模块组件)。\n\n#### 📱丰富的模型库\nPaddleDetection支持大量的最新主流的算法基准以及预训练模型，涵盖2D/3D目标检测、实例分割、人脸检测、关键点检测、多目标跟踪、半监督学习等方向。`传送门`：[📱模型库](#模型库)、[⚖️模型性能对比](#️模型性能对比)。\n\n#### 🎗️产业特色模型|产业工具\nPaddleDetection打造产业级特色模型以及分析工具：PP-YOLOE+、PP-PicoDet、PP-TinyPose、PP-HumanV2、PP-Vehicle等，针对通用、高频垂类应用场景提供深度优化解决方案以及高度集成的分析工具，降低开发者的试错、选择成本，针对业务场景快速应用落地。`传送门`：[🎗️产业特色模型|产业工具](#️产业特色模型产业工具-1)。\n\n#### 💡🏆产业级部署实践\nPaddleDetection整理工业、农业、林业、交通、医疗、金融、能源电力等AI应用范例，打通数据标注-模型训练-模型调优-预测部署全流程，持续降低目标检测技术产业落地门槛。`传送门`：[💡产业实践范例](#产业实践范例)、[🏆企业应用案例](#企业应用案例)。\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206431371-912a14c8-ce1e-48ec-ae6f-7267016b308e.png\" align=\"middle\" width=\"1280\"/>\n</p>\n</div>\n\n\n## 🍱安装\n\n参考[安装说明](docs/tutorials/INSTALL_cn.md)进行安装。\n\n## 🔥教程\n\n**深度学习入门教程**\n\n- [零基础入门深度学习](https://www.paddlepaddle.org.cn/tutorials/projectdetail/4676538)\n- [零基础入门目标检测](https://aistudio.baidu.com/aistudio/education/group/info/1617)\n\n**快速开始**\n\n- [快速体验](docs/tutorials/QUICK_STARTED_cn.md)\n- [示例：30分钟快速开发交通标志检测模型](docs/tutorials/GETTING_STARTED_cn.md)\n\n**数据准备**\n- [数据准备](docs/tutorials/data/README.md)\n- [数据处理模块](docs/advanced_tutorials/READER.md)\n\n**配置文件说明**\n- [RCNN参数说明](docs/tutorials/config_annotation/faster_rcnn_r50_fpn_1x_coco_annotation.md)\n- [PP-YOLO参数说明](docs/tutorials/config_annotation/ppyolo_r50vd_dcn_1x_coco_annotation.md)\n\n**模型开发**\n\n- [新增检测模型](docs/advanced_tutorials/MODEL_TECHNICAL.md)\n- 二次开发\n  - [目标检测](docs/advanced_tutorials/customization/detection.md)\n  - [关键点检测](docs/advanced_tutorials/customization/keypoint_detection.md)\n  - [多目标跟踪](docs/advanced_tutorials/customization/pphuman_mot.md)\n  - [行为识别](docs/advanced_tutorials/customization/action_recognotion/)\n  - [属性识别](docs/advanced_tutorials/customization/pphuman_attribute.md)\n\n**部署推理**\n\n- [模型导出教程](deploy/EXPORT_MODEL.md)\n- [模型压缩](https://github.com/PaddlePaddle/PaddleSlim)\n  - [剪裁/量化/蒸馏教程](configs/slim)\n- [Paddle Inference部署](deploy/README.md)\n  - [Python端推理部署](deploy/python)\n  - [C++端推理部署](deploy/cpp)\n- [Paddle Lite部署](deploy/lite)\n- [Paddle Serving部署](deploy/serving)\n- [ONNX模型导出](deploy/EXPORT_ONNX_MODEL.md)\n- [推理benchmark](deploy/BENCHMARK_INFER.md)\n\n## 🔑FAQ\n- [FAQ/常见问题汇总](docs/tutorials/FAQ)\n\n## 🧩模块组件\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"center\">\n      <td>\n        <b>Backbones</b>\n      </td>\n      <td>\n        <b>Necks</b>\n      </td>\n      <td>\n        <b>Loss</b>\n      </td>\n      <td>\n        <b>Common</b>\n      </td>\n      <td>\n      <b>Data Augmentation</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n      <ul>\n          <li><a href=\"ppdet/modeling/backbones/resnet.py\">ResNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/res2net.py\">CSPResNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/senet.py\">SENet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/res2net.py\">Res2Net</a></li>\n          <li><a href=\"ppdet/modeling/backbones/hrnet.py\">HRNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/lite_hrnet.py\">Lite-HRNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/darknet.py\">DarkNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/csp_darknet.py\">CSPDarkNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/mobilenet_v1.py\">MobileNetV1</a></li>\n          <li><a href=\"ppdet/modeling/backbones/mobilenet_v3.py\">MobileNetV1</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/shufflenet_v2.py\">ShuffleNetV2</a></li>\n          <li><a href=\"ppdet/modeling/backbones/ghostnet.py\">GhostNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/blazenet.py\">BlazeNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/dla.py\">DLA</a></li>\n          <li><a href=\"ppdet/modeling/backbones/hardnet.py\">HardNet</a></li>\n          <li><a href=\"ppdet/modeling/backbones/lcnet.py\">LCNet</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/esnet.py\">ESNet</a></li>  \n          <li><a href=\"ppdet/modeling/backbones/swin_transformer.py\">Swin-Transformer</a></li>\n          <li><a href=\"ppdet/modeling/backbones/convnext.py\">ConvNeXt</a></li>\n          <li><a href=\"ppdet/modeling/backbones/vgg.py\">VGG</a></li>\n          <li><a href=\"ppdet/modeling/backbones/vision_transformer.py\">Vision Transformer</a></li>\n          <li><a href=\"configs/convnext\">ConvNext</a></li>\n      </ul>\n      </td>\n      <td>\n      <ul>\n        <li><a href=\"ppdet/modeling/necks/bifpn.py\">BiFPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/blazeface_fpn.py\">BlazeFace-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/centernet_fpn.py\">CenterNet-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/csp_pan.py\">CSP-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/custom_pan.py\">Custom-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/fpn.py\">FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/es_pan.py\">ES-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/hrfpn.py\">HRFPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/lc_pan.py\">LC-PAN</a></li>\n        <li><a href=\"ppdet/modeling/necks/ttf_fpn.py\">TTF-FPN</a></li>\n        <li><a href=\"ppdet/modeling/necks/yolo_fpn.py\">YOLO-FPN</a></li>\n      </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"ppdet/modeling/losses/smooth_l1_loss.py\">Smooth-L1</a></li>\n          <li><a href=\"ppdet/modeling/losses/detr_loss.py\">Detr Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/fairmot_loss.py\">Fairmot Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/fcos_loss.py\">Fcos Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/gfocal_loss.py\">GFocal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/jde_loss.py\">JDE Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/keypoint_loss.py\">KeyPoint Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/solov2_loss.py\">SoloV2 Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/focal_loss.py\">Focal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/iou_loss.py\">GIoU/DIoU/CIoU</a></li>  \n          <li><a href=\"ppdet/modeling/losses/iou_aware_loss.py\">IoUAware</a></li>\n          <li><a href=\"ppdet/modeling/losses/sparsercnn_loss.py\">SparseRCNN Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/ssd_loss.py\">SSD Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/focal_loss.py\">YOLO Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/yolo_loss.py\">CT Focal Loss</a></li>\n          <li><a href=\"ppdet/modeling/losses/varifocal_loss.py\">VariFocal Loss</a></li>\n        </ul>\n      </td>\n      <td>\n      </ul>\n          <li><b>Post-processing</b></li>\n        <ul>\n        <ul>\n           <li><a href=\"ppdet/modeling/post_process.py\">SoftNMS</a></li>\n            <li><a href=\"ppdet/modeling/post_process.py\">MatrixNMS</a></li>\n            </ul>\n            </ul>\n          <li><b>Training</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"tools/train.py#L62\">FP16 training</a></li>\n            <li><a href=\"docs/tutorials/DistributedTraining_cn.md\">Multi-machine training </a></li>\n                        </ul>\n            </ul>\n          <li><b>Common</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"ppdet/modeling/backbones/resnet.py#L41\">Sync-BN</a></li>\n            <li><a href=\"configs/gn/README.md\">Group Norm</a></li>\n            <li><a href=\"configs/dcn/README.md\">DCNv2</a></li>\n            <li><a href=\"ppdet/optimizer/ema.py\">EMA</a></li>\n        </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"ppdet/data/transform/operators.py\">Resize</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Lighting</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Flipping</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Expand</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Crop</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Color Distort</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Random Erasing</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Mixup </a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">AugmentHSV</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Mosaic</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Cutmix </a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Grid Mask</a></li>\n          <li><a href=\"ppdet/data/transform/operators.py\">Auto Augment</a></li>  \n          <li><a href=\"ppdet/data/transform/operators.py\">Random Perspective</a></li>  \n        </ul>\n      </td>\n    </tr>\n</td>\n    </tr>\n  </tbody>\n</table>\n\n## 📱模型库\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"center\">\n      <td>\n        <b>2D Detection</b>\n      </td>\n      <td>\n        <b>Multi Object Tracking</b>\n      </td>\n      <td>\n        <b>KeyPoint Detection</b>\n      </td>\n      <td>\n      <b>Others</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n        <ul>\n            <li><a href=\"configs/faster_rcnn/README.md\">Faster RCNN</a></li>\n            <li><a href=\"ppdet/modeling/necks/fpn.py\">FPN</a></li>\n            <li><a href=\"configs/cascade_rcnn/README.md\">Cascade-RCNN</a></li>\n            <li><a href=\"configs/rcnn_enhance\">PSS-Det</a></li>\n            <li><a href=\"configs/retinanet/README.md\">RetinaNet</a></li>\n            <li><a href=\"configs/yolov3/README.md\">YOLOv3</a></li>  \n            <li><a href=\"configs/yolof/README.md\">YOLOF</a></li>  \n            <li><a href=\"configs/yolox/README.md\">YOLOX</a></li>  \n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5\">YOLOv5</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov6\">YOLOv6</a></li>  \n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7\">YOLOv7</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov8\">YOLOv8</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/rtmdet\">RTMDet</a></li>\n            <li><a href=\"configs/ppyolo/README_cn.md\">PP-YOLO</a></li>\n            <li><a href=\"configs/ppyolo#pp-yolo-tiny\">PP-YOLO-Tiny</a></li>\n            <li><a href=\"configs/picodet\">PP-PicoDet</a></li>\n            <li><a href=\"configs/ppyolo/README_cn.md\">PP-YOLOv2</a></li>\n            <li><a href=\"configs/ppyoloe/README_legacy.md\">PP-YOLOE</a></li>\n            <li><a href=\"configs/ppyoloe/README_cn.md\">PP-YOLOE+</a></li>\n            <li><a href=\"configs/smalldet\">PP-YOLOE-SOD</a></li>\n            <li><a href=\"configs/rotate/README.md\">PP-YOLOE-R</a></li>\n            <li><a href=\"configs/ssd/README.md\">SSD</a></li>\n            <li><a href=\"configs/centernet\">CenterNet</a></li>\n            <li><a href=\"configs/fcos\">FCOS</a></li>  \n            <li><a href=\"configs/rotate/fcosr\">FCOSR</a></li>  \n            <li><a href=\"configs/ttfnet\">TTFNet</a></li>\n            <li><a href=\"configs/tood\">TOOD</a></li>\n            <li><a href=\"configs/gfl\">GFL</a></li>\n            <li><a href=\"configs/gfl/gflv2_r50_fpn_1x_coco.yml\">GFLv2</a></li>\n            <li><a href=\"configs/detr\">DETR</a></li>\n            <li><a href=\"configs/deformable_detr\">Deformable DETR</a></li>\n            <li><a href=\"configs/sparse_rcnn\">Sparse RCNN</a></li>\n      </ul>\n      </td>\n      <td>\n        <ul>\n           <li><a href=\"configs/mot/jde\">JDE</a></li>\n            <li><a href=\"configs/mot/fairmot\">FairMOT</a></li>\n            <li><a href=\"configs/mot/deepsort\">DeepSORT</a></li>\n            <li><a href=\"configs/mot/bytetrack\">ByteTrack</a></li>\n            <li><a href=\"configs/mot/ocsort\">OC-SORT</a></li>\n            <li><a href=\"configs/mot/botsort\">BoT-SORT</a></li>\n            <li><a href=\"configs/mot/centertrack\">CenterTrack</a></li>\n        </ul>\n      </td>\n      <td>\n        <ul>\n          <li><a href=\"configs/keypoint/hrnet\">HRNet</a></li>\n            <li><a href=\"configs/keypoint/higherhrnet\">HigherHRNet</a></li>\n            <li><a href=\"configs/keypoint/lite_hrnet\">Lite-HRNet</a></li>\n            <li><a href=\"configs/keypoint/tiny_pose\">PP-TinyPose</a></li>\n        </ul>\n</td>\n<td>\n</ul>\n          <li><b>Instance Segmentation</b></li>\n        <ul>\n        <ul>\n          <li><a href=\"configs/mask_rcnn\">Mask RCNN</a></li>\n            <li><a href=\"configs/cascade_rcnn\">Cascade Mask RCNN</a></li>\n            <li><a href=\"configs/solov2\">SOLOv2</a></li>\n        </ul>\n      </ul>\n          <li><b>Face Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"configs/face_detection\">BlazeFace</a></li>\n        </ul>\n        </ul>\n          <li><b>Semi-Supervised Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"configs/semi_det\">DenseTeacher</a></li>\n        </ul>\n        </ul>\n          <li><b>3D Detection</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">Smoke</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">CaDDN</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">PointPillars</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">CenterPoint</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">SequeezeSegV3</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">IA-SSD</a></li>\n            <li><a href=\"https://github.com/PaddlePaddle/Paddle3D\">PETR</a></li>\n        </ul>\n        </ul>\n          <li><b>Vehicle Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"deploy/pipeline/README.md\">PP-Vehicle</a></li>\n        </ul>\n        </ul>\n          <li><b>Human Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"deploy/pipeline/README.md\">PP-Human</a></li>\n            <li><a href=\"deploy/pipeline/README.md\">PP-HumanV2</a></li>\n        </ul>\n        </ul>\n          <li><b>Sport Analysis Toolbox</b></li>\n        <ul>\n        <ul>\n            <li><a href=\"https://github.com/PaddlePaddle/PaddleSports\">PP-Sports</a></li>\n        </ul>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## ⚖️模型性能对比\n\n#### 🖥️服务器端模型性能对比\n\n各模型结构和骨干网络的代表模型在COCO数据集上精度mAP和单卡Tesla V100上预测速度(FPS)对比图。\n\n  <div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206434766-caaa781b-b922-481f-af09-15faac9ed33b.png\" width=\"800\"/>\n</div>\n\n<details>\n<summary><b> 测试说明(点击展开)</b></summary>\n\n- ViT为ViT-Cascade-Faster-RCNN模型，COCO数据集mAP高达55.7%\n- Cascade-Faster-RCNN为Cascade-Faster-RCNN-ResNet50vd-DCN，PaddleDetection将其优化到COCO数据mAP为47.8%时推理速度为20FPS\n- PP-YOLOE是对PP-YOLO v2模型的进一步优化，L版本在COCO数据集mAP为51.6%，Tesla V100预测速度78.1FPS\n- PP-YOLOE+是对PPOLOE模型的进一步优化，L版本在COCO数据集mAP为53.3%，Tesla V100预测速度78.1FPS\n- YOLOX和YOLOv5均为基于PaddleDetection复现算法，YOLOv5代码在[PaddleYOLO](https://github.com/PaddlePaddle/PaddleYOLO)中，参照[PaddleYOLO_MODEL](docs/feature_models/PaddleYOLO_MODEL.md)\n- 图中模型均可在[📱模型库](#模型库)中获取\n</details>\n\n#### ⌚️移动端模型性能对比\n\n各移动端模型在COCO数据集上精度mAP和高通骁龙865处理器上预测速度(FPS)对比图。\n\n  <div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/61035602/206434741-10460690-8fc3-4084-a11a-16fe4ce2fc85.png\" width=\"550\"/>\n</div>\n\n\n<details>\n<summary><b> 测试说明(点击展开)</b></summary>\n\n- 测试数据均使用高通骁龙865(4xA77+4xA55)处理器，batch size为1, 开启4线程测试，测试使用NCNN预测库，测试脚本见[MobileDetBenchmark](https://github.com/JiweiMaster/MobileDetBenchmark)\n- PP-PicoDet及PP-YOLO-Tiny为PaddleDetection自研模型，可在[📱模型库](#模型库)中获取，其余模型PaddleDetection暂未提供\n</details>\n\n## 🎗️产业特色模型|产业工具\n\n产业特色模型｜产业工具是PaddleDetection针对产业高频应用场景打造的兼顾精度和速度的模型以及工具箱，注重从数据处理-模型训练-模型调优-模型部署的端到端打通，且提供了实际生产环境中的实践范例代码，帮助拥有类似需求的开发者高效的完成产品开发落地应用。\n\n该系列模型｜工具均已PP前缀命名，具体介绍、预训练模型以及产业实践范例代码如下。\n\n### 💎PP-YOLOE 高精度目标检测模型\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPP-YOLOE是基于PP-YOLOv2的卓越的单阶段Anchor-free模型，超越了多种流行的YOLO模型。PP-YOLOE避免了使用诸如Deformable Convolution或者Matrix NMS之类的特殊算子，以使其能轻松地部署在多种多样的硬件上。其使用大规模数据集obj365预训练模型进行预训练，可以在不同场景数据集上快速调优收敛。\n\n`传送门`：[PP-YOLOE说明](configs/ppyoloe/README_cn.md)。\n\n`传送门`：[arXiv论文](https://arxiv.org/abs/2203.16250)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n| 模型名称    | COCO精度（mAP） | V100 TensorRT FP16速度(FPS) | 推荐部署硬件 |                        配置文件                         |                                        模型下载                                         |\n| :---------- | :-------------: | :-------------------------: | :----------: | :-----------------------------------------------------: | :-------------------------------------------------------------------------------------: |\n| PP-YOLOE+_l |      53.3       |            149.2            |    服务器    | [链接](configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml) | [下载地址](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_m_80e_coco.pdparams) |\n\n`传送门`：[全部预训练模型](configs/ppyoloe/README_cn.md)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业 | 类别              | 亮点                                                                                          | 文档说明                                                      | 模型下载                                            |\n| ---- | ----------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | --------------------------------------------------- |\n| 农业 | 农作物检测        | 用于葡萄栽培中基于图像的监测和现场机器人技术，提供了来自5种不同葡萄品种的实地实例             | [PP-YOLOE+ 下游任务](./configs/ppyoloe/application/README.md) | [下载链接](./configs/ppyoloe/application/README.md) |\n| 通用 | 低光场景检测      | 低光数据集使用ExDark，包括从极低光环境到暮光环境等10种不同光照条件下的图片。                  | [PP-YOLOE+ 下游任务](./configs/ppyoloe/application/README.md) | [下载链接](./configs/ppyoloe/application/README.md) |\n| 工业 | PCB电路板瑕疵检测 | 工业数据集使用PKU-Market-PCB，该数据集用于印刷电路板（PCB）的瑕疵检测，提供了6种常见的PCB缺陷 | [PP-YOLOE+ 下游任务](./configs/ppyoloe/application/README.md) | [下载链接](./configs/ppyoloe/application/README.md) |\n</details>\n\n### 💎PP-YOLOE-R 高性能旋转框检测模型\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPP-YOLOE-R是一个高效的单阶段Anchor-free旋转框检测模型，基于PP-YOLOE+引入了一系列改进策略来提升检测精度。根据不同的硬件对精度和速度的要求，PP-YOLOE-R包含s/m/l/x四个尺寸的模型。在DOTA 1.0数据集上，PP-YOLOE-R-l和PP-YOLOE-R-x在单尺度训练和测试的情况下分别达到了78.14mAP和78.28 mAP，这在单尺度评估下超越了几乎所有的旋转框检测模型。通过多尺度训练和测试，PP-YOLOE-R-l和PP-YOLOE-R-x的检测精度进一步提升至80.02mAP和80.73 mAP，超越了所有的Anchor-free方法并且和最先进的Anchor-based的两阶段模型精度几乎相当。在保持高精度的同时，PP-YOLOE-R避免使用特殊的算子，例如Deformable Convolution或Rotated RoI Align，使其能轻松地部署在多种多样的硬件上。\n\n`传送门`：[PP-YOLOE-R说明](configs/rotate/ppyoloe_r)。\n\n`传送门`：[arXiv论文](https://arxiv.org/abs/2211.02386)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n|     模型     | Backbone |  mAP  | V100 TRT FP16 (FPS) | RTX 2080 Ti TRT FP16 (FPS) | Params (M) | FLOPs (G) | 学习率策略 | 角度表示 | 数据增广 | GPU数目 | 每GPU图片数目 |                                      模型下载                                       |                                                            配置文件                                                            |\n| :----------: | :------: | :---: | :-----------------: | :------------------------: | :--------: | :-------: | :--------: | :------: | :------: | :-----: | :-----------: | :---------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------: |\n| PP-YOLOE-R-l |  CRN-l   | 80.02 |        69.7         |            48.3            |   53.29    |  281.65   |     3x     |    oc    |  MS+RR   |    4    |       2       | [model](https://paddledet.bj.bcebos.com/models/ppyoloe_r_crn_l_3x_dota_ms.pdparams) | [config](https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/rotate/ppyoloe_r/ppyoloe_r_crn_l_3x_dota_ms.yml) |\n\n`传送门`：[全部预训练模型](configs/rotate/ppyoloe_r)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业 | 类别       | 亮点                                                                  | 文档说明                                                                                | 模型下载                                                              |\n| ---- | ---------- | --------------------------------------------------------------------- | --------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| 通用 | 旋转框检测 | 手把手教你上手PP-YOLOE-R旋转框检测，10分钟将脊柱数据集精度训练至95mAP | [基于PP-YOLOE-R的旋转框检测](https://aistudio.baidu.com/aistudio/projectdetail/5058293) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/5058293) |\n</details>\n\n### 💎PP-YOLOE-SOD 高精度小目标检测模型\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPP-YOLOE-SOD(Small Object Detection)是PaddleDetection团队针对小目标检测提出的检测方案，在VisDrone-DET数据集上单模型精度达到38.5mAP，达到了SOTA性能。其分别基于切图拼图流程优化的小目标检测方案以及基于原图模型算法优化的小目标检测方案。同时提供了数据集自动分析脚本，只需输入数据集标注文件，便可得到数据集统计结果，辅助判断数据集是否是小目标数据集以及是否需要采用切图策略，同时给出网络超参数参考值。\n\n`传送门`：[PP-YOLOE-SOD 小目标检测模型](configs/smalldet)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n- VisDrone数据集预训练模型\n\n| 模型                | COCOAPI mAP<sup>val<br>0.5:0.95 | COCOAPI mAP<sup>val<br>0.5 | COCOAPI mAP<sup>test_dev<br>0.5:0.95 | COCOAPI mAP<sup>test_dev<br>0.5 | MatlabAPI mAP<sup>test_dev<br>0.5:0.95 | MatlabAPI mAP<sup>test_dev<br>0.5 |                                              下载                                               |                           配置文件                           |\n| :------------------ | :-----------------------------: | :------------------------: | :----------------------------------: | :-----------------------------: | :------------------------------------: | :-------------------------------: | :---------------------------------------------------------------------------------------------: | :----------------------------------------------------------: |\n| **PP-YOLOE+_SOD-l** |            **31.9**             |          **52.1**          |               **25.6**               |            **43.5**             |               **30.25**                |             **51.18**             | [下载链接](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_sod_crn_l_80e_visdrone.pdparams) | [配置文件](visdrone/ppyoloe_plus_sod_crn_l_80e_visdrone.yml) |\n\n`传送门`：[全部预训练模型](configs/smalldet)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业 | 类别       | 亮点                                                 | 文档说明                                                                                          | 模型下载                                                              |\n| ---- | ---------- | ---------------------------------------------------- | ------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| 通用 | 小目标检测 | 基于PP-YOLOE-SOD的无人机航拍图像检测案例全流程实操。 | [基于PP-YOLOE-SOD的无人机航拍图像检测](https://aistudio.baidu.com/aistudio/projectdetail/5036782) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/5036782) |\n</details>\n\n### 💫PP-PicoDet 超轻量实时目标检测模型\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\n全新的轻量级系列模型PP-PicoDet，在移动端具有卓越的性能，成为全新SOTA轻量级模型。\n\n`传送门`：[PP-PicoDet说明](configs/picodet/README.md)。\n\n`传送门`：[arXiv论文](https://arxiv.org/abs/2111.00902)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n| 模型名称  | COCO精度（mAP） | 骁龙865 四线程速度(FPS) |  推荐部署硬件  |                       配置文件                       |                                       模型下载                                       |\n| :-------- | :-------------: | :---------------------: | :------------: | :--------------------------------------------------: | :----------------------------------------------------------------------------------: |\n| PicoDet-L |      36.1       |          39.7           | 移动端、嵌入式 | [链接](configs/picodet/picodet_l_320_coco_lcnet.yml) | [下载地址](https://paddledet.bj.bcebos.com/models/picodet_l_320_coco_lcnet.pdparams) |\n\n`传送门`：[全部预训练模型](configs/picodet/README.md)。\n</details>\n\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业     | 类别         | 亮点                                                                                                                           | 文档说明                                                                                                          | 模型下载                                                                                      |\n| -------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------- |\n| 智慧城市 | 道路垃圾检测 | 通过在市政环卫车辆上安装摄像头对路面垃圾检测并分析，实现对路面遗撒的垃圾进行监控，记录并通知环卫人员清理，大大提升了环卫人效。 | [基于PP-PicoDet的路面垃圾检测](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0) |\n</details>\n\n### 📡PP-Tracking 实时多目标跟踪系统\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPaddleDetection团队提供了实时多目标跟踪系统PP-Tracking，是基于PaddlePaddle深度学习框架的业界首个开源的实时多目标跟踪系统，具有模型丰富、应用广泛和部署高效三大优势。 PP-Tracking支持单镜头跟踪(MOT)和跨镜头跟踪(MTMCT)两种模式，针对实际业务的难点和痛点，提供了行人跟踪、车辆跟踪、多类别跟踪、小目标跟踪、流量统计以及跨镜头跟踪等各种多目标跟踪功能和应用，部署方式支持API调用和GUI可视化界面，部署语言支持Python和C++，部署平台环境支持Linux、NVIDIA Jetson等。\n\n`传送门`：[PP-Tracking说明](configs/mot/README.md)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n| 模型名称  |               模型简介               |          精度          | 速度(FPS) |      推荐部署硬件      |                          配置文件                          |                                              模型下载                                              |\n| :-------- | :----------------------------------: | :--------------------: | :-------: | :--------------------: | :--------------------------------------------------------: | :------------------------------------------------------------------------------------------------: |\n| ByteTrack |   SDE多目标跟踪算法 仅包含检测模型   |   MOT-17 test:  78.4   |     -     | 服务器、移动端、嵌入式 |     [链接](configs/mot/bytetrack/bytetrack_yolox.yml)      |  [下载地址](https://bj.bcebos.com/v1/paddledet/models/mot/yolox_x_24e_800x1440_mix_det.pdparams)   |\n| FairMOT   | JDE多目标跟踪算法 多任务联合学习方法 |   MOT-16 test: 75.0    |     -     | 服务器、移动端、嵌入式 | [链接](configs/mot/fairmot/fairmot_dla34_30e_1088x608.yml) |     [下载地址](https://paddledet.bj.bcebos.com/models/mot/fairmot_dla34_30e_1088x608.pdparams)     |\n| OC-SORT   |   SDE多目标跟踪算法 仅包含检测模型   | MOT-17 half val:  75.5 |     -     | 服务器、移动端、嵌入式 |        [链接](configs/mot/ocsort/ocsort_yolox.yml)         | [下载地址](https://bj.bcebos.com/v1/paddledet/models/mot/yolox_x_24e_800x1440_mix_mot_ch.pdparams) |\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业 | 类别       | 亮点                       | 文档说明                                                                                       | 模型下载                                                              |\n| ---- | ---------- | -------------------------- | ---------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| 通用 | 多目标跟踪 | 快速上手单镜头、多镜头跟踪 | [PP-Tracking之手把手玩转多目标跟踪](https://aistudio.baidu.com/aistudio/projectdetail/3022582) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/3022582) |\n</details>\n\n### ⛷️PP-TinyPose 人体骨骼关键点识别\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPaddleDetection 中的关键点检测部分紧跟最先进的算法，包括 Top-Down 和 Bottom-Up 两种方法，可以满足用户的不同需求。同时，PaddleDetection 提供针对移动端设备优化的自研实时关键点检测模型 PP-TinyPose。\n\n`传送门`：[PP-TinyPose说明](configs/keypoint/tiny_pose)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n|  模型名称   |               模型简介               | COCO精度（AP） |         速度(FPS)         |  推荐部署硬件  |                        配置文件                         |                                         模型下载                                         |\n| :---------: | :----------------------------------: | :------------: | :-----------------------: | :------------: | :-----------------------------------------------------: | :--------------------------------------------------------------------------------------: |\n| PP-TinyPose | 轻量级关键点算法<br/>输入尺寸256x192 |      68.8      | 骁龙865 四线程: 158.7 FPS | 移动端、嵌入式 | [链接](configs/keypoint/tiny_pose/tinypose_256x192.yml) | [下载地址](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_256x192.pdparams) |\n\n`传送门`：[全部预训练模型](configs/keypoint/README.md)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业 | 类别 | 亮点                                                                                                                                     | 文档说明                                                                                             | 模型下载                                                              |\n| ---- | ---- | ---------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| 运动 | 健身 | 提供从模型选型、数据准备、模型训练优化，到后处理逻辑和模型部署的全流程可复用方案，有效解决了复杂健身动作的高效识别，打造AI虚拟健身教练！ | [基于PP-TinyPose增强版的智能健身动作识别](https://aistudio.baidu.com/aistudio/projectdetail/4385813) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/4385813) |\n</details>\n\n### 🏃🏻PP-Human 实时行人分析工具\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPaddleDetection深入探索核心行业的高频场景，提供了行人开箱即用分析工具，支持图片/单镜头视频/多镜头视频/在线视频流多种输入方式，广泛应用于智慧交通、智慧城市、工业巡检等领域。支持服务器端部署及TensorRT加速，T4服务器上可达到实时。\nPP-Human支持四大产业级功能：五大异常行为识别、26种人体属性分析、实时人流计数、跨镜头（ReID）跟踪。\n\n`传送门`：[PP-Human行人分析工具使用指南](deploy/pipeline/README.md)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n|        任务        | T4 TensorRT FP16: 速度（FPS） | 推荐部署硬件 |                                                                                                                                         模型下载                                                                                                                                         |                             模型体积                              |\n| :----------------: | :---------------------------: | :----------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------: |\n| 行人检测（高精度） |             39.8              |    服务器    |                                                                                              [目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                               |                               182M                                |\n| 行人跟踪（高精度） |             31.4              |    服务器    |                                                                                             [多目标跟踪](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                              |                               182M                                |\n| 属性识别（高精度） |          单人 117.6           |    服务器    |                                      [目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [属性识别](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_small_person_attribute_954_infer.zip)                                       |                  目标检测：182M<br>属性识别：86M                  |\n|      摔倒识别      |           单人 100            |    服务器    | [多目标跟踪](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip) <br> [关键点检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip) <br> [基于关键点行为识别](https://bj.bcebos.com/v1/paddledet/models/pipeline/STGCN.zip) | 多目标跟踪：182M<br>关键点检测：101M<br>基于关键点行为识别：21.8M |\n|      闯入识别      |             31.4              |    服务器    |                                                                                             [多目标跟踪](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                              |                               182M                                |\n|      打架识别      |             50.8              |    服务器    |                                                                                              [视频分类](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                               |                                90M                                |\n|      抽烟识别      |             340.1             |    服务器    |                                    [目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[基于人体id的目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/ppyoloe_crn_s_80e_smoking_visdrone.zip)                                    |            目标检测：182M<br>基于人体id的目标检测：27M            |\n|     打电话识别     |             166.7             |    服务器    |                                      [目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[基于人体id的图像分类](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_tiny_calling_halfbody.zip)                                       |            目标检测：182M<br>基于人体id的图像分类：45M            |\n\n`传送门`：[完整预训练模型](deploy/pipeline/README.md)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业     | 类别     | 亮点                                                                                                                                           | 文档说明                                                                                               | 模型下载                                                                                 |\n| -------- | -------- | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------- |\n| 智能安防 | 摔倒检测 | 飞桨行人分析PP-Human中提供的摔倒识别算法，采用了关键点+时空图卷积网络的技术，对摔倒姿势无限制、背景环境无要求。                                | [基于PP-Human v2的摔倒检测](https://aistudio.baidu.com/aistudio/projectdetail/4606001)                 | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/4606001)                    |\n| 智能安防 | 打架识别 | 本项目基于PaddleVideo视频开发套件训练打架识别模型，然后将训练好的模型集成到PaddleDetection的PP-Human中，助力行人行为分析。                     | [基于PP-Human的打架识别](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1) |\n| 智能安防 | 摔倒检测 | 基于PP-Human完成来客分析整体流程。使用PP-Human完成来客分析中非常常见的场景： 1. 来客属性识别(单镜和跨境可视化）；2. 来客行为识别（摔倒识别）。 | [基于PP-Human的来客分析案例教程](https://aistudio.baidu.com/aistudio/projectdetail/4537344)            | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/4537344)                    |\n</details>\n\n### 🏎️PP-Vehicle 实时车辆分析工具\n\n<details>\n<summary><b> 简介(点击展开)</b></summary>\n\nPaddleDetection深入探索核心行业的高频场景，提供了车辆开箱即用分析工具，支持图片/单镜头视频/多镜头视频/在线视频流多种输入方式，广泛应用于智慧交通、智慧城市、工业巡检等领域。支持服务器端部署及TensorRT加速，T4服务器上可达到实时。\nPP-Vehicle囊括四大交通场景核心功能：车牌识别、属性识别、车流量统计、违章检测。\n\n`传送门`：[PP-Vehicle车辆分析工具指南](deploy/pipeline/README.md)。\n\n</details>\n\n<details>\n<summary><b> 预训练模型(点击展开)</b></summary>\n\n|        任务        | T4 TensorRT FP16: 速度(FPS) | 推荐部署硬件 |                                                                                           模型方案                                                                                           |                模型体积                 |\n| :----------------: | :-------------------------: | :----------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-------------------------------------: |\n| 车辆检测（高精度） |            38.9             |    服务器    |                                                [目标检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                |                  182M                   |\n| 车辆跟踪（高精度） |             25              |    服务器    |                                               [多目标跟踪](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                               |                  182M                   |\n|      车牌识别      |            213.7            |    服务器    | [车牌检测](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_det_infer.tar.gz) <br> [车牌识别](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_rec_infer.tar.gz) | 车牌检测：3.9M  <br> 车牌字符识别： 12M |\n|      车辆属性      |            136.8            |    服务器    |                                                  [属性识别](https://bj.bcebos.com/v1/paddledet/models/pipeline/vehicle_attribute_model.zip)                                                  |                  7.2M                   |\n\n`传送门`：[完整预训练模型](deploy/pipeline/README.md)。\n</details>\n\n<details>\n<summary><b> 产业应用代码示例(点击展开)</b></summary>\n\n| 行业     | 类别             | 亮点                                                                                                               | 文档说明                                                                                      | 模型下载                                                              |\n| -------- | ---------------- | ------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- |\n| 智慧交通 | 交通监控车辆分析 | 本项目基于PP-Vehicle演示智慧交通中最刚需的车流量监控、车辆违停检测以及车辆结构化（车牌、车型、颜色）分析三大场景。 | [基于PP-Vehicle的交通监控分析系统](https://aistudio.baidu.com/aistudio/projectdetail/4512254) | [下载链接](https://aistudio.baidu.com/aistudio/projectdetail/4512254) |\n</details>\n\n## 💡产业实践范例\n\n产业实践范例是PaddleDetection针对高频目标检测应用场景，提供的端到端开发示例，帮助开发者打通数据标注-模型训练-模型调优-预测部署全流程。\n针对每个范例我们都通过[AI-Studio](https://ai.baidu.com/ai-doc/AISTUDIO/Tk39ty6ho)提供了项目代码以及说明，用户可以同步运行体验。\n\n`传送门`：[产业实践范例完整列表](industrial_tutorial/README.md)\n\n- [基于PP-YOLOE-R的旋转框检测](https://aistudio.baidu.com/aistudio/projectdetail/5058293)\n- [基于PP-YOLOE-SOD的无人机航拍图像检测](https://aistudio.baidu.com/aistudio/projectdetail/5036782)\n- [基于PP-Vehicle的交通监控分析系统](https://aistudio.baidu.com/aistudio/projectdetail/4512254)\n- [基于PP-Human v2的摔倒检测](https://aistudio.baidu.com/aistudio/projectdetail/4606001)\n- [基于PP-TinyPose增强版的智能健身动作识别](https://aistudio.baidu.com/aistudio/projectdetail/4385813)\n- [基于PP-Human的打架识别](https://aistudio.baidu.com/aistudio/projectdetail/4086987?contributionType=1)\n- [基于Faster-RCNN的瓷砖表面瑕疵检测](https://aistudio.baidu.com/aistudio/projectdetail/2571419)\n- [基于PaddleDetection的PCB瑕疵检测](https://aistudio.baidu.com/aistudio/projectdetail/2367089)\n- [基于FairMOT实现人流量统计](https://aistudio.baidu.com/aistudio/projectdetail/2421822)\n- [基于YOLOv3实现跌倒检测](https://aistudio.baidu.com/aistudio/projectdetail/2500639)\n- [基于PP-PicoDetv2 的路面垃圾检测](https://aistudio.baidu.com/aistudio/projectdetail/3846170?channelType=0&channel=0)\n- [基于人体关键点检测的合规检测](https://aistudio.baidu.com/aistudio/projectdetail/4061642?contributionType=1)\n- [基于PP-Human的来客分析案例教程](https://aistudio.baidu.com/aistudio/projectdetail/4537344)\n- 持续更新中...\n\n## 🏆企业应用案例\n\n企业应用案例是企业在实生产环境下落地应用PaddleDetection的方案思路，相比产业实践范例其更多强调整体方案设计思路，可供开发者在项目方案设计中做参考。\n\n`传送门`：[企业应用案例完整列表](https://www.paddlepaddle.org.cn/customercase)\n\n- [中国南方电网——变电站智慧巡检](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2330)\n- [国铁电气——轨道在线智能巡检系统](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2280)\n- [京东物流——园区车辆行为识别](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2611)\n- [中兴克拉—厂区传统仪表统计监测](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2618)\n- [宁德时代—动力电池高精度质量检测](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2609)\n- [中国科学院空天信息创新研究院——高尔夫球场遥感监测](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2483)\n- [御航智能——基于边缘的无人机智能巡检](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2481)\n- [普宙无人机——高精度森林巡检](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2121)\n- [领邦智能——红外无感测温监控](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2615)\n- [北京地铁——口罩检测](https://mp.weixin.qq.com/s/znrqaJmtA7CcjG0yQESWig)\n- [音智达——工厂人员违规行为检测](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2288)\n- [华夏天信——输煤皮带机器人智能巡检](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2331)\n- [优恩物联网——社区住户分类支持广告精准投放](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2485)\n- [螳螂慧视——室内3D点云场景物体分割与检测](https://www.paddlepaddle.org.cn/support/news?action=detail&id=2599)\n- 持续更新中...\n\n## 📝许可证书\n\n本项目的发布受[Apache 2.0 license](LICENSE)许可认证。\n\n\n## 📌引用\n\n```\n@misc{ppdet2019,\ntitle={PaddleDetection, Object detection and instance segmentation toolkit based on PaddlePaddle.},\nauthor={PaddlePaddle Authors},\nhowpublished = {\\url{https://github.com/PaddlePaddle/PaddleDetection}},\nyear={2019}\n}\n```\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 42.66015625,
          "content": "[简体中文](README_cn.md) | English\n\n<div align=\"center\">\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/48054808/160532560-34cf7a1f-d950-435e-90d2-4b0a679e5119.png\" align=\"middle\" width = \"800\" />\n</p>\n\n**A High-Efficient Development Toolkit for Object Detection based on [PaddlePaddle](https://github.com/paddlepaddle/paddle)**\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleDetection?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleDetection/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleDetection?color=ccf\"></a>\n</p>\n</div>\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/205581915-aa8d6bee-5624-4aec-8059-76b5ebaf96f1.gif\" width=\"800\"/>\n\n</div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157793354-6e7f381a-0aa6-4bb7-845c-9acf2ecc05c3.png\" width=\"20\"/> Product Update\n\n- 🔥 **2022.11.15：SOTA rotated object detector and small object detector based on PP-YOLOE**\n  - Rotated object detector [PP-YOLOE-R](configs/rotate/ppyoloe_r)\n    - SOTA Anchor-free rotated object detection model with high accuracy and efficiency\n    - A series of models, named s/m/l/x, for cloud and edge devices\n    - Avoiding using special operators to be deployed friendly with TensorRT.\n  - Small object detector [PP-YOLOE-SOD](configs/smalldet)\n    - End-to-end detection pipeline based on sliced images\n    - SOTA model on VisDrone based on original images.\n\n- 2022.8.26：PaddleDetection releases[release/2.5 version](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.5)\n\n  - 🗳 Model features：\n\n    - Release [PP-YOLOE+](configs/ppyoloe): Increased accuracy by a maximum of 2.4% mAP to 54.9% mAP, 3.75 times faster model training convergence rate, and up to 2.3 times faster end-to-end inference speed; improved generalization for multiple downstream tasks\n    - Release [PicoDet-NPU](configs/picodet) model which supports full quantization deployment of models; add [PicoDet](configs/picodet) layout analysis model\n    - Release [PP-TinyPose Plus](./configs/keypoint/tiny_pose/). With 9.1% AP accuracy improvement in physical exercise, dance, and other scenarios, our PP-TinyPose Plus supports unconventional movements such as turning to one side, lying down, jumping, and high lifts\n\n  - 🔮 Functions in different scenarios\n\n    - Release the pedestrian analysis tool [PP-Human v2](./deploy/pipeline). It introduces four new behavior recognition: fighting, telephoning, smoking, and trespassing. The underlying algorithm performance is optimized, covering three core algorithm capabilities: detection, tracking, and attributes of pedestrians. Our model provides end-to-end development and model optimization strategies for beginners and supports online video streaming input.\n    - First release [PP-Vehicle](./deploy/pipeline), which has four major functions: license plate recognition, vehicle attribute analysis (color, model), traffic flow statistics, and violation detection. It is compatible with input formats, including pictures, online video streaming, and video. And we also offer our users a comprehensive set of tutorials for customization.\n\n  - 💡 Cutting-edge algorithms：\n\n    - Release [PaddleYOLO](https://github.com/PaddlePaddle/PaddleYOLO) which overs classic and latest models of [YOLO family](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/docs/MODEL_ZOO_en.md): YOLOv3, PP-YOLOE (a real-time high-precision object detection model developed by Baidu PaddlePaddle), and cutting-edge detection algorithms such as YOLOv4, YOLOv5, YOLOX, YOLOv6, YOLOv7 and YOLOv8\n    - Newly add high precision detection model based on [ViT](configs/vitdet) backbone network, with a 55.7% mAP accuracy on COCO dataset; newly add multi-object tracking model [OC-SORT](configs/mot/ocsort); newly add [ConvNeXt](configs/convnext) backbone network.\n\n  - 📋 Industrial applications: Newly add [Smart Fitness](https://aistudio.baidu.com/aistudio/projectdetail/4385813), [Fighting recognition](https://aistudio.baidu.com/aistudio/projectdetail/4086987?channelType=0&channel=0),[ and Visitor Analysis](https://aistudio.baidu.com/aistudio/projectdetail/4230123?channelType=0&channel=0).\n\n- 2022.3.24：PaddleDetection released[release/2.4 version](https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4)  \n  - Release high-performanace SOTA object detection model [PP-YOLOE](configs/ppyoloe). It integrates cloud and edge devices and provides S/M/L/X versions. In particular, Verson L has the accuracy as 51.4% on COCO test 2017 dataset, inference speed as 78.1 FPS on a single Test V100. It supports mixed precision training, 33% faster than PP-YOLOv2. Its full range of multi-sized models can meet different hardware arithmetic requirements, and adaptable to server, edge-device GPU and other AI accelerator cards on servers.\n  - Release ultra-lightweight SOTA object detection model [PP-PicoDet Plus](configs/picodet) with 2% improvement in accuracy and 63% improvement in CPU inference speed. Add PicoDet-XS model with a 0.7M parameter, providing model sparsification and quantization functions for model acceleration. No specific post processing module is required for all the hardware, simplifying the deployment.  \n  - Release the real-time pedestrian analysis tool [PP-Human](deploy/pphuman). It has four major functions: pedestrian tracking, visitor flow statistics, human attribute recognition and falling detection. For falling detection, it is optimized based on real-life data with accurate recognition of various types of falling posture. It can adapt to different environmental background, light and camera angle.\n  - Add [YOLOX](configs/yolox) object detection model with nano/tiny/S/M/L/X. X version has the accuracy as 51.8% on COCO  Val2017 dataset.\n\n- [More releases](https://github.com/PaddlePaddle/PaddleDetection/releases)\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157795569-9fc77c85-732f-4870-9be0-99a7fe2cff27.png\" alt=\"\" width=\"20\"> Brief Introduction\n\n**PaddleDetection** is an end-to-end object detection development kit based on PaddlePaddle. Providing **over 30 model algorithm** and **over 300 pre-trained models**, it covers object detection, instance segmentation, keypoint detection, multi-object tracking. In particular, PaddleDetection offers **high- performance & light-weight** industrial SOTA models on **servers and mobile** devices, champion solution and cutting-edge algorithm. PaddleDetection provides various data augmentation methods, configurable network components, loss functions and other advanced optimization & deployment schemes. In addition to running through the whole process of data processing, model development, training, compression and deployment, PaddlePaddle also provides rich cases and tutorials to accelerate the industrial application of algorithm.\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/189122825-ee1c1db2-b5f9-42c0-88b4-7975e1ec239d.gif\" width=\"800\"/>\n</div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157799599-e6a66855-bac6-4e75-b9c0-96e13cb9612f.png\" width=\"20\"/> Features\n\n- **Rich model library**: PaddleDetection provides over 250 pre-trained models including **object detection, instance segmentation, face recognition, multi-object tracking**. It covers a variety of **global competition champion** schemes.\n- **Simple to use**: Modular design, decoupling each network component, easy for developers to build and try various detection models and optimization strategies, quick access to high-performance, customized algorithm.\n- **Getting Through End to End**: PaddlePaddle gets through end to end from data augmentation, constructing models, training, compression, depolyment. It also supports multi-architecture, multi-device deployment for **cloud and edge** device.\n- **High Performance**: Due to the high performance core, PaddlePaddle has clear advantages in training speed and memory occupation. It also supports FP16 training and multi-machine training.\n\n<div  align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/22989727/202131382-45fd2de6-3805-460e-a70c-66db7188d37c.png\" width=\"800\"/>\n</div>\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157800467-2a9946ad-30d1-49a9-b9db-ba33413d9c90.png\" alt=\"\" width=\"20\"> Exchanges\n\n- If you have any question or suggestion, please give us your valuable input via [GitHub Issues](https://github.com/PaddlePaddle/PaddleDetection/issues)\n\n  Welcome to join PaddleDetection user groups on WeChat (scan the QR code, add and reply \"D\" to the assistant)\n\n  <div align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/34162360/177678712-4655747d-4290-4ad9-b7a1-4564a5418ac6.jpg\"  width = \"200\" />  \n  </div>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157827140-03ffaff7-7d14-48b4-9440-c38986ea378c.png\" width=\"20\"/> Kit Structure\n\n<table align=\"center\">\n  <tbody>\n    <tr align=\"center\" valign=\"bottom\">\n      <td>\n        <b>Architectures</b>\n      </td>\n      <td>\n        <b>Backbones</b>\n      </td>\n      <td>\n        <b>Components</b>\n      </td>\n      <td>\n        <b>Data Augmentation</b>\n      </td>\n    </tr>\n    <tr valign=\"top\">\n      <td>\n        <ul>\n        <details><summary><b>Object Detection</b></summary>\n          <ul>\n            <li>Faster RCNN</li>\n            <li>FPN</li>\n            <li>Cascade-RCNN</li>\n            <li>PSS-Det</li>\n            <li>RetinaNet</li>\n            <li>YOLOv3</li>  \n            <li>YOLOF</li>  \n            <li>YOLOX</li>  \n            <li>YOLOv5</li>  \n            <li>YOLOv6</li>  \n            <li>YOLOv7</li>  \n            <li>YOLOv8</li>  \n            <li>RTMDet</li>  \n            <li>PP-YOLO</li>\n            <li>PP-YOLO-Tiny</li>\n            <li>PP-PicoDet</li>\n            <li>PP-YOLOv2</li>\n            <li>PP-YOLOE</li>\n            <li>PP-YOLOE+</li>\n            <li>PP-YOLOE-SOD</li>\n            <li>PP-YOLOE-R</li>\n            <li>SSD</li>\n            <li>CenterNet</li>\n            <li>FCOS</li>  \n            <li>FCOSR</li>  \n            <li>TTFNet</li>\n            <li>TOOD</li>\n            <li>GFL</li>\n            <li>GFLv2</li>\n            <li>DETR</li>\n            <li>Deformable DETR</li>\n            <li>Swin Transformer</li>\n            <li>Sparse RCNN</li>\n         </ul></details>\n        <details><summary><b>Instance Segmentation</b></summary>\n         <ul>\n            <li>Mask RCNN</li>\n            <li>Cascade Mask RCNN</li>\n            <li>SOLOv2</li>\n        </ul></details>\n        <details><summary><b>Face Detection</b></summary>\n        <ul>\n            <li>BlazeFace</li>\n        </ul></details>\n        <details><summary><b>Multi-Object-Tracking</b></summary>\n        <ul>\n            <li>JDE</li>\n            <li>FairMOT</li>\n            <li>DeepSORT</li>\n            <li>ByteTrack</li>\n            <li>OC-SORT</li>\n            <li>BoT-SORT</li>\n            <li>CenterTrack</li>\n        </ul></details>\n        <details><summary><b>KeyPoint-Detection</b></summary>\n        <ul>\n            <li>HRNet</li>\n            <li>HigherHRNet</li>\n            <li>Lite-HRNet</li>\n            <li>PP-TinyPose</li>\n        </ul></details>\n      </ul>\n      </td>\n      <td>\n        <details><summary><b>Details</b></summary>\n        <ul>\n          <li>ResNet(&vd)</li>\n          <li>Res2Net(&vd)</li>\n          <li>CSPResNet</li>\n          <li>SENet</li>\n          <li>Res2Net</li>\n          <li>HRNet</li>\n          <li>Lite-HRNet</li>\n          <li>DarkNet</li>\n          <li>CSPDarkNet</li>\n          <li>MobileNetv1/v3</li>  \n          <li>ShuffleNet</li>\n          <li>GhostNet</li>\n          <li>BlazeNet</li>\n          <li>DLA</li>\n          <li>HardNet</li>\n          <li>LCNet</li>  \n          <li>ESNet</li>  \n          <li>Swin-Transformer</li>\n          <li>ConvNeXt</li>\n          <li>Vision Transformer</li>\n        </ul></details>\n      </td>\n      <td>\n        <details><summary><b>Common</b></summary>\n          <ul>\n            <li>Sync-BN</li>\n            <li>Group Norm</li>\n            <li>DCNv2</li>\n            <li>EMA</li>\n          </ul> </details>\n        </ul>\n        <details><summary><b>KeyPoint</b></summary>\n          <ul>\n            <li>DarkPose</li>\n          </ul></details>\n        </ul>\n        <details><summary><b>FPN</b></summary>\n          <ul>\n            <li>BiFPN</li>\n            <li>CSP-PAN</li>\n            <li>Custom-PAN</li>\n            <li>ES-PAN</li>\n            <li>HRFPN</li>\n          </ul> </details>\n        </ul>  \n        <details><summary><b>Loss</b></summary>\n          <ul>\n            <li>Smooth-L1</li>\n            <li>GIoU/DIoU/CIoU</li>  \n            <li>IoUAware</li>\n            <li>Focal Loss</li>\n            <li>CT Focal Loss</li>\n            <li>VariFocal Loss</li>\n          </ul> </details>\n        </ul>  \n        <details><summary><b>Post-processing</b></summary>\n          <ul>\n            <li>SoftNMS</li>\n            <li>MatrixNMS</li>  \n          </ul> </details>  \n        </ul>\n        <details><summary><b>Speed</b></summary>\n          <ul>\n            <li>FP16 training</li>\n            <li>Multi-machine training </li>  \n          </ul> </details>  \n        </ul>  \n      </td>\n      <td>\n        <details><summary><b>Details</b></summary>\n        <ul>\n          <li>Resize</li>  \n          <li>Lighting</li>  \n          <li>Flipping</li>  \n          <li>Expand</li>\n          <li>Crop</li>\n          <li>Color Distort</li>  \n          <li>Random Erasing</li>  \n          <li>Mixup </li>\n          <li>AugmentHSV</li>\n          <li>Mosaic</li>\n          <li>Cutmix </li>\n          <li>Grid Mask</li>\n          <li>Auto Augment</li>  \n          <li>Random Perspective</li>  \n        </ul> </details>  \n      </td>  \n    </tr>\n\n</td>\n    </tr>\n  </tbody>\n</table>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157801371-9a9a8c65-1690-4123-985a-e0559a7f9494.png\" width=\"20\"/> Model Performance\n\n<details>\n<summary><b> Performance comparison of Cloud models</b></summary>\n\nThe comparison between COCO mAP and FPS on Tesla V100 of representative models of each architectures and backbones.\n\n<div align=\"center\">\n  <img src=\"docs/images/fps_map.png\" />\n</div>\n\n**Clarification：**\n\n- `ViT` stands for `ViT-Cascade-Faster-RCNN`, which has highest mAP on COCO as 55.7%\n- `Cascade-Faster-RCNN`stands for `Cascade-Faster-RCNN-ResNet50vd-DCN`, which has been optimized to 20 FPS inference speed when COCO mAP as 47.8% in PaddleDetection models\n- `PP-YOLOE` are optimized `PP-YOLO v2`. It reached accuracy as 51.4% on COCO dataset, inference speed as 78.1 FPS on Tesla V100\n- `PP-YOLOE+` are optimized `PP-YOLOE`. It reached accuracy as 53.3% on COCO dataset, inference speed as 78.1 FPS on Tesla V100\n- The models in the figure are available in the[ model library](#模型库)\n\n</details>\n\n<details>\n<summary><b> Performance omparison on mobiles</b></summary>\n\nThe comparison between COCO mAP and FPS on Qualcomm Snapdragon 865 processor of models on mobile devices.\n\n<div align=\"center\">\n  <img src=\"docs/images/mobile_fps_map.png\" width=600/>\n</div>\n\n**Clarification：**\n\n- Tests were conducted on Qualcomm Snapdragon 865 (4 \\*A77 + 4 \\*A55) batch_size=1, 4 thread, and NCNN inference library, test script see [MobileDetBenchmark](https://github.com/JiweiMaster/MobileDetBenchmark)\n- [PP-PicoDet](configs/picodet) and [PP-YOLO-Tiny](configs/ppyolo) are self-developed models of PaddleDetection, and other models are not tested yet.\n\n</details>\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157829890-a535b8a6-631c-4c87-b861-64d4b32b2d6a.png\" width=\"20\"/> Model libraries\n\n<details>\n<summary><b> 1. General detection</b></summary>\n\n#### PP-YOLOE series Recommended scenarios: Cloud GPU such as Nvidia V100, T4 and edge devices such as Jetson series\n\n| Model      | COCO Accuracy（mAP） | V100 TensorRT FP16 Speed(FPS) | Configuration                                           | Download                                                                                 |\n|:---------- |:------------------:|:-----------------------------:|:-------------------------------------------------------:|:----------------------------------------------------------------------------------------:|\n| PP-YOLOE+_s | 43.9        | 333.3                     | [link](configs/ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml)     | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_s_80e_coco.pdparams)      |\n| PP-YOLOE+_m | 50.0        | 208.3                     | [link](configs/ppyoloe/ppyoloe_plus_crn_m_80e_coco.yml)     | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_m_80e_coco.pdparams)     |\n| PP-YOLOE+_l | 53.3        | 149.2                     | [link](configs/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml) | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_l_80e_coco.pdparams) |\n| PP-YOLOE+_x | 54.9        | 95.2                      | [link](configs/ppyoloe/ppyoloe_plus_crn_x_80e_coco.yml) | [download](https://paddledet.bj.bcebos.com/models/ppyoloe_plus_crn_x_80e_coco.pdparams) |\n\n#### PP-PicoDet series Recommended scenarios: Mobile chips and x86 CPU devices, such as ARM CPU(RK3399, Raspberry Pi) and NPU(BITMAIN)\n\n| Model      | COCO Accuracy（mAP） | Snapdragon 865 four-thread speed (ms) | Configuration                                         | Download                                                                              |\n|:---------- |:------------------:|:-------------------------------------:|:-----------------------------------------------------:|:-------------------------------------------------------------------------------------:|\n| PicoDet-XS | 23.5               | 7.81                                  | [Link](configs/picodet/picodet_xs_320_coco_lcnet.yml) | [Download](https://paddledet.bj.bcebos.com/models/picodet_xs_320_coco_lcnet.pdparams) |\n| PicoDet-S  | 29.1               | 9.56                                  | [Link](configs/picodet/picodet_s_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_s_320_coco_lcnet.pdparams)  |\n| PicoDet-M  | 34.4               | 17.68                                 | [Link](configs/picodet/picodet_m_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_m_320_coco_lcnet.pdparams)  |\n| PicoDet-L  | 36.1               | 25.21                                 | [Link](configs/picodet/picodet_l_320_coco_lcnet.yml)  | [Download](https://paddledet.bj.bcebos.com/models/picodet_l_320_coco_lcnet.pdparams)  |\n\n#### [Frontier detection algorithm](docs/feature_models/PaddleYOLO_MODEL.md)\n\n| Model    | COCO Accuracy（mAP） | V100 TensorRT FP16 speed(FPS) | Configuration                                                                                                  | Download                                                                       |\n|:-------- |:------------------:|:-----------------------------:|:--------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------:|\n| [YOLOX-l](configs/yolox)  | 50.1               | 107.5                         | [Link](configs/yolox/yolox_l_300e_coco.yml)                                                                    | [Download](https://paddledet.bj.bcebos.com/models/yolox_l_300e_coco.pdparams)  |\n| [YOLOv5-l](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5) | 48.6               | 136.0                         | [Link](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov5/yolov5_l_300e_coco.yml) | [Download](https://paddledet.bj.bcebos.com/models/yolov5_l_300e_coco.pdparams) |\n| [YOLOv7-l](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7) | 51.0        | 135.0                     | [链接](https://github.com/PaddlePaddle/PaddleYOLO/tree/develop/configs/yolov7/yolov7_l_300e_coco.yml) | [下载地址](https://paddledet.bj.bcebos.com/models/yolov7_l_300e_coco.pdparams) |\n\n#### Other general purpose models [doc](docs/MODEL_ZOO_en.md)\n\n</details>\n\n<details>\n<summary><b> 2. Instance segmentation</b></summary>\n\n| Model             | Introduction                                             | Recommended Scenarios                         | COCO Accuracy(mAP)               | Configuration                                                           | Download                                                                                              |\n|:----------------- |:-------------------------------------------------------- |:--------------------------------------------- |:--------------------------------:|:-----------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------:|\n| Mask RCNN         | Two-stage instance segmentation algorithm                | <div style=\"width: 50pt\">Edge-Cloud end</div> | box AP: 41.4 <br/> mask AP: 37.5 | [Link](configs/mask_rcnn/mask_rcnn_r50_vd_fpn_2x_coco.yml)              | [Download](https://paddledet.bj.bcebos.com/models/mask_rcnn_r50_vd_fpn_2x_coco.pdparams)              |\n| Cascade Mask RCNN | Two-stage instance segmentation algorithm                | <div style=\"width: 50pt\">Edge-Cloud end</div> | box AP: 45.7 <br/> mask AP: 39.7 | [Link](configs/mask_rcnn/cascade_mask_rcnn_r50_vd_fpn_ssld_2x_coco.yml) | [Download](https://paddledet.bj.bcebos.com/models/cascade_mask_rcnn_r50_vd_fpn_ssld_2x_coco.pdparams) |\n| SOLOv2            | Lightweight single-stage instance segmentation algorithm | <div style=\"width: 50pt\">Edge-Cloud end</div> | mask AP: 38.0                    | [Link](configs/solov2/solov2_r50_fpn_3x_coco.yml)                       | [Download](https://paddledet.bj.bcebos.com/models/solov2_r50_fpn_3x_coco.pdparams)                    |\n\n</details>\n\n<details>\n<summary><b> 3. Keypoint detection</b></summary>\n\n| Model                | Introduction                                                                                  | Recommended scenarios                         | COCO Accuracy（AP） | Speed                             | Configuration                                             | Download                                                                                    |\n|:-------------------- |:--------------------------------------------------------------------------------------------- |:--------------------------------------------- |:-----------------:|:---------------------------------:|:---------------------------------------------------------:|:-------------------------------------------------------------------------------------------:|\n| HRNet-w32 + DarkPose | <div style=\"width: 130pt\">Top-down Keypoint detection algorithm<br/>Input size: 384x288</div> | <div style=\"width: 50pt\">Edge-Cloud end</div> | 78.3              | T4 TensorRT FP16 2.96ms           | [Link](configs/keypoint/hrnet/dark_hrnet_w32_384x288.yml) | [Download](https://paddledet.bj.bcebos.com/models/keypoint/dark_hrnet_w32_384x288.pdparams) |\n| HRNet-w32 + DarkPose | Top-down Keypoint detection algorithm<br/>Input size: 256x192                                 | Edge-Cloud end                                | 78.0              | T4 TensorRT FP16 1.75ms           | [Link](configs/keypoint/hrnet/dark_hrnet_w32_256x192.yml) | [Download](https://paddledet.bj.bcebos.com/models/keypoint/dark_hrnet_w32_256x192.pdparams) |\n| PP-TinyPose          | Light-weight keypoint algorithm<br/>Input size: 256x192                                       | Mobile                                        | 68.8              | Snapdragon 865 four-thread 6.30ms | [Link](configs/keypoint/tiny_pose/tinypose_256x192.yml)   | [Download](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_256x192.pdparams)    |\n| PP-TinyPose          | Light-weight keypoint algorithm<br/>Input size: 128x96                                        | Mobile                                        | 58.1              | Snapdragon 865 four-thread 2.37ms | [Link](configs/keypoint/tiny_pose/tinypose_128x96.yml)    | [Download](https://bj.bcebos.com/v1/paddledet/models/keypoint/tinypose_128x96.pdparams)     |\n\n#### Other keypoint detection models [doc](configs/keypoint)\n\n</details>\n\n<details>\n<summary><b> 4. Multi-object tracking PP-Tracking</b></summary>\n\n| Model     | Introduction                                                  | Recommended scenarios | Accuracy               | Configuration                                                           | Download                                                                                              |\n|:--------- |:------------------------------------------------------------- |:--------------------- |:----------------------:|:-----------------------------------------------------------------------:|:-----------------------------------------------------------------------------------------------------:|\n| ByteTrack | SDE Multi-object tracking algorithm with detection model only | Edge-Cloud end        | MOT-17 half val:  77.3 | [Link](configs/mot/bytetrack/detector/yolox_x_24e_800x1440_mix_det.yml) | [Download](https://paddledet.bj.bcebos.com/models/mot/deepsort/yolox_x_24e_800x1440_mix_det.pdparams) |\n| FairMOT   | JDE multi-object tracking algorithm multi-task learning       | Edge-Cloud end        | MOT-16 test: 75.0      | [Link](configs/mot/fairmot/fairmot_dla34_30e_1088x608.yml)              | [Download](https://paddledet.bj.bcebos.com/models/mot/fairmot_dla34_30e_1088x608.pdparams)            |\n| OC-SORT   | SDE multi-object tracking algorithm with detection model only       | Edge-Cloud end        | MOT-16 half val: 75.5      | [Link](configs/mot/ocsort/ocsort_yolox.yml)              | -            |\n\n#### Other multi-object tracking models [docs](configs/mot)\n\n</details>\n\n<details>\n<summary><b> 5. Industrial real-time pedestrain analysis tool-PP Human</b></summary>\n\n| Task                                   | End-to-End Speed（ms） | Model                                                                                                                                                                                                                                                                                                                           | Size                                                                                                   |\n|:--------------------------------------:|:--------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------:|\n| Pedestrian detection (high precision)  | 25.1ms               | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Pedestrian detection (lightweight)     | 16.2ms               | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Pedestrian tracking (high precision)   | 31.8ms               | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Pedestrian tracking (lightweight)      | 21.0ms               | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Attribute recognition (high precision) | Single person8.5ms   | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [Attribute recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/strongbaseline_r50_30e_pa100k.zip)                                                                                                         | Object detection：182M<br>Attribute recognition：86M                                                     |\n| Attribute recognition (lightweight)    | Single person 7.1ms  | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br> [Attribute recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/strongbaseline_r50_30e_pa100k.zip)                                                                                                         | Object detection：182M<br>Attribute recognition：86M                                                     |\n| Falling detection                      | Single person 10ms   | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip) <br> [Keypoint detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip) <br> [Behavior detection based on key points](https://bj.bcebos.com/v1/paddledet/models/pipeline/STGCN.zip) | Multi-object tracking：182M<br>Keypoint detection：101M<br>Behavior detection based on key points: 21.8M |\n| Intrusion detection                    | 31.8ms               | [Multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Fighting detection                     | 19.7ms               | [Video classification](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)                                                                                                                                                                                                                       | 90M                                                                                                    |\n| Smoking detection                      | Single person 15.1ms | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[Object detection based on Human Id](https://bj.bcebos.com/v1/paddledet/models/pipeline/ppyoloe_crn_s_80e_smoking_visdrone.zip)                                                                                        | Object detection：182M<br>Object detection based on Human ID: 27M                                       |\n| Phoning detection                      | Single person ms     | [Object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip)<br>[Image classification based on Human ID](https://bj.bcebos.com/v1/paddledet/models/pipeline/PPHGNet_tiny_calling_halfbody.zip)                                                                                         | Object detection：182M<br>Image classification based on Human ID：45M                                    |\n\nPlease refer to [docs](deploy/pipeline/README_en.md) for details.\n\n</details>\n\n<details>\n<summary><b> 6. Industrial real-time vehicle analysis tool-PP Vehicle</b></summary>\n\n| Task                                   | End-to-End Speed（ms） | Model                                                                                                                                                                                                                                                                                                                           | Size                                                                                                   |\n|:--------------------------------------:|:--------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------:|\n| Vehicle detection (high precision)  | 25.7ms               | [object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Vehicle detection (lightweight)     | 13.2ms               | [object detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Vehicle tracking (high precision)   | 40ms               | [multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_ppvehicle.zip)                                                                                                                                                                                                                      | 182M                                                                                                   |\n| Vehicle tracking (lightweight)      | 25ms               | [multi-object tracking](https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_s_36e_pipeline.zip)                                                                                                                                                                                                                      | 27M                                                                                                    |\n| Plate Recognition                   | 4.68ms     | [plate detection](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_det_infer.tar.gz)<br>[plate recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/ch_PP-OCRv3_rec_infer.tar.gz)                                                                                         | Plate detection：3.9M<br>Plate recognition：12M                                    |\n| Vehicle attribute      | 7.31ms               | [attribute recognition](https://bj.bcebos.com/v1/paddledet/models/pipeline/vehicle_attribute_model.zip)                                                                                                                                                                                                                      | 7.2M                                                                                                    |\n\nPlease refer to [docs](deploy/pipeline/README_en.md) for details.\n\n</details>\n\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157828296-d5eb0ccb-23ea-40f5-9957-29853d7d13a9.png\" width=\"20\"/>Document tutorials\n\n### Introductory tutorials\n\n- [Installation](docs/tutorials/INSTALL_cn.md)\n- [Quick start](docs/tutorials/QUICK_STARTED_cn.md)\n- [Data preparation](docs/tutorials/data/README.md)\n- [Geting Started on PaddleDetection](docs/tutorials/GETTING_STARTED_cn.md)\n- [FAQ](docs/tutorials/FAQ)\n\n### Advanced tutorials\n\n- Configuration\n\n  - [RCNN Configuration](docs/tutorials/config_annotation/faster_rcnn_r50_fpn_1x_coco_annotation.md)\n  - [PP-YOLO Configuration](docs/tutorials/config_annotation/ppyolo_r50vd_dcn_1x_coco_annotation.md)\n\n- Compression based on [PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim)\n\n  - [Pruning/Quantization/Distillation Tutorial](configs/slim)\n\n- [Inference deployment](deploy/README.md)\n\n  - [Export model for inference](deploy/EXPORT_MODEL.md)\n\n  - [Paddle Inference deployment](deploy/README.md)\n\n    - [Inference deployment with Python](deploy/python)\n    - [Inference deployment with C++](deploy/cpp)\n\n  - [Paddle-Lite deployment](deploy/lite)\n\n  - [Paddle Serving deployment](deploy/serving)\n\n  - [ONNX model export](deploy/EXPORT_ONNX_MODEL.md)\n\n  - [Inference benchmark](deploy/BENCHMARK_INFER.md)\n\n- Advanced development\n\n  - [Data processing module](docs/advanced_tutorials/READER.md)\n  - [New object detection models](docs/advanced_tutorials/MODEL_TECHNICAL.md)\n  - Custumization\n    - [Object detection](docs/advanced_tutorials/customization/detection.md)\n    - [Keypoint detection](docs/advanced_tutorials/customization/keypoint_detection.md)\n    - [Multiple object tracking](docs/advanced_tutorials/customization/pphuman_mot.md)\n    - [Action recognition](docs/advanced_tutorials/customization/action_recognotion/)\n    - [Attribute recognition](docs/advanced_tutorials/customization/pphuman_attribute.md)\n\n### Courses\n\n- **[Theoretical foundation] [Object detection 7-day camp](https://aistudio.baidu.com/aistudio/education/group/info/1617):** Overview of object detection tasks, details of RCNN series object detection algorithm and YOLO series object detection algorithm, PP-YOLO optimization strategy and case sharing, introduction and practice of AnchorFree series algorithm\n\n- **[Industrial application] [AI Fast Track industrial object detection technology and application](https://aistudio.baidu.com/aistudio/education/group/info/23670):** Super object detection algorithms, real-time pedestrian analysis system PP-Human, breakdown and practice of object detection industrial application\n\n- **[Industrial features] 2022.3.26** **[Smart City Industry Seven-Day Class](https://aistudio.baidu.com/aistudio/education/group/info/25620)** : Urban planning, Urban governance, Smart governance service, Traffic management, community governance.\n\n- **[Academic exchange] 2022.9.27 [YOLO Vision Event](https://www.youtube.com/playlist?list=PL1FZnkj4ad1NHVC7CMc3pjSQ-JRK-Ev6O):** As the first YOLO-themed event, PaddleDetection was invited to communicate with the experts in the field of Computer Vision around the world.\n\n### [Industrial tutorial examples](./industrial_tutorial/README.md)\n\n- [Rotated object detection based on PP-YOLOE-R](https://aistudio.baidu.com/aistudio/projectdetail/5058293)\n\n- [Aerial image detection based on PP-YOLOE-SOD](https://aistudio.baidu.com/aistudio/projectdetail/5036782)\n\n- [Fall down recognition based on PP-Human v2](https://aistudio.baidu.com/aistudio/projectdetail/4606001)\n\n- [Intelligent fitness recognition based on PP-TinyPose Plus](https://aistudio.baidu.com/aistudio/projectdetail/4385813)\n\n- [Road litter detection based on PP-PicoDet Plus](https://aistudio.baidu.com/aistudio/projectdetail/3561097)\n\n- [Visitor flow statistics based on FairMOT](https://aistudio.baidu.com/aistudio/projectdetail/2421822)\n\n- [Guest analysis based on PP-Human](https://aistudio.baidu.com/aistudio/projectdetail/4537344)\n\n- [More examples](./industrial_tutorial/README.md)\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157836473-1cf451fa-f01f-4148-ba68-b6d06d5da2f9.png\" alt=\"\" width=\"20\"> Applications\n\n- [Fitness app on android mobile](https://github.com/zhiboniu/pose_demo_android)\n- [PP-Tracking GUI Visualization Interface](https://github.com/yangyudong2020/PP-Tracking_GUi)\n\n## Recommended third-party tutorials\n\n- [Deployment of PaddleDetection for Windows I ](https://zhuanlan.zhihu.com/p/268657833)\n- [Deployment of PaddleDetection for Windows II](https://zhuanlan.zhihu.com/p/280206376)\n- [Deployment of PaddleDetection on Jestson Nano](https://zhuanlan.zhihu.com/p/319371293)\n- [How to deploy YOLOv3 model on Raspberry Pi for Helmet detection](https://github.com/PaddleCV-FAQ/PaddleDetection-FAQ/blob/main/Lite%E9%83%A8%E7%BD%B2/yolov3_for_raspi.md)\n- [Use SSD-MobileNetv1 for a project -- From dataset to deployment on Raspberry Pi](https://github.com/PaddleCV-FAQ/PaddleDetection-FAQ/blob/main/Lite%E9%83%A8%E7%BD%B2/ssd_mobilenet_v1_for_raspi.md)\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835981-ef6057b4-6347-4768-8fcc-cd07fcc3d8b0.png\" width=\"20\"/> Version updates\n\nPlease refer to the[ Release note ](https://github.com/PaddlePaddle/Paddle/wiki/PaddlePaddle-2.3.0-Release-Note-EN)for more details about the updates\n\n## <img title=\"\" src=\"https://user-images.githubusercontent.com/48054808/157835345-f5d24128-abaf-4813-b793-d2e5bdc70e5a.png\" alt=\"\" width=\"20\">  License\n\nPaddlePaddle is provided under the [Apache 2.0 license](LICENSE)\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835796-08d4ffbc-87d9-4622-89d8-cf11a44260fc.png\" width=\"20\"/> Contribute your code\n\nWe appreciate your contributions and your feedback！\n\n- Thank [Mandroide](https://github.com/Mandroide) for code cleanup and\n- Thank [FL77N](https://github.com/FL77N/) for `Sparse-RCNN`model\n- Thank [Chen-Song](https://github.com/Chen-Song) for `Swin Faster-RCNN`model\n- Thank [yangyudong](https://github.com/yangyudong2020), [hchhtc123](https://github.com/hchhtc123) for developing PP-Tracking GUI interface\n- Thank Shigure19 for developing PP-TinyPose fitness APP\n- Thank [manangoel99](https://github.com/manangoel99) for Wandb visualization methods\n\n## <img src=\"https://user-images.githubusercontent.com/48054808/157835276-9aab9d1c-1c46-446b-bdd4-5ab75c5cfa48.png\" width=\"20\"/> Quote\n\n```\n@misc{ppdet2019,\ntitle={PaddleDetection, Object detection and instance segmentation toolkit based on PaddlePaddle.},\nauthor={PaddlePaddle Authors},\nhowpublished = {\\url{https://github.com/PaddlePaddle/PaddleDetection}},\nyear={2019}\n}\n```\n"
        },
        {
          "name": "activity",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataset",
          "type": "tree",
          "content": null
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "deploy",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "industrial_tutorial",
          "type": "tree",
          "content": null
        },
        {
          "name": "ppdet",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.30078125,
          "content": "numpy < 2.0\ntqdm\ntypeguard\nvisualdl>=2.2.0\nopencv-python <= 4.6.0\nPyYAML\nshapely\nscipy\nterminaltables\nCython\npycocotools\nsetuptools\nPillow\n\n# for MOT evaluation and inference\nlapx\nmotmetrics\nsklearn==0.0\n\n# for vehicleplate in deploy/pipeline/ppvehicle\npyclipper\n\n# for culane data augumetation\nimgaug>=0.4.0"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.919921875,
          "content": "# Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport os.path as osp\nimport glob\nimport shutil\nimport subprocess\nfrom setuptools import find_packages, setup\n\n# ==============  version definition  ==============\n\nPPDET_VERSION = \"0.0.0\"\n\n\ndef parse_version():\n    return PPDET_VERSION.replace('-', '')\n\n\ndef git_commit():\n    try:\n        cmd = ['git', 'rev-parse', 'HEAD']\n        git_commit = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE, ).communicate()[0].strip()\n        git_commit = git_commit.decode()\n    except:\n        git_commit = 'Unknown'\n\n    return str(git_commit)\n\n\ndef write_version_py(filename='ppdet/version.py'):\n    ver_str = \"\"\"# THIS FILE IS GENERATED FROM PADDLEPADDLE SETUP.PY\n#\nfull_version    = '%(version)s'\ncommit          = '%(commit)s'\n\"\"\"\n\n    _git_commit = git_commit()\n    with open(filename, 'w') as f:\n        f.write(ver_str % {'version': PPDET_VERSION, 'commit': _git_commit})\n\n\nwrite_version_py()\n\n# ==============  version definition  ==============\n\n\ndef readme():\n    with open('README.md', encoding='utf-8') as f:\n        content = f.read()\n    return content\n\n\ndef parse_requirements(fname):\n    with open(fname, encoding=\"utf-8-sig\") as f:\n        requirements = f.readlines()\n    return requirements\n\n\ndef package_model_zoo():\n    cur_dir = osp.dirname(osp.realpath(__file__))\n    cfg_dir = osp.join(cur_dir, \"configs\")\n    cfgs = glob.glob(osp.join(cfg_dir, '*/*.yml'))\n\n    valid_cfgs = []\n    for cfg in cfgs:\n        # exclude dataset base config\n        if osp.split(osp.split(cfg)[0])[1] not in ['datasets']:\n            valid_cfgs.append(cfg)\n    model_names = [\n        osp.relpath(cfg, cfg_dir).replace(\".yml\", \"\") for cfg in valid_cfgs\n    ]\n\n    model_zoo_file = osp.join(cur_dir, 'ppdet', 'model_zoo', 'MODEL_ZOO')\n    with open(model_zoo_file, 'w') as wf:\n        for model_name in model_names:\n            wf.write(\"{}\\n\".format(model_name))\n\n    return [model_zoo_file]\n\n\npackages = [\n    'ppdet',\n    'ppdet.core',\n    'ppdet.data',\n    'ppdet.engine',\n    'ppdet.metrics',\n    'ppdet.modeling',\n    'ppdet.model_zoo',\n    'ppdet.slim',\n    'ppdet.utils',\n]\n\nif __name__ == \"__main__\":\n    setup(\n        name='paddledet',\n        packages=find_packages(exclude=(\"configs\", \"tools\", \"deploy\")),\n        package_data={'ppdet.model_zoo': package_model_zoo()},\n        author='PaddlePaddle',\n        version=parse_version(),\n        install_requires=parse_requirements('./requirements.txt'),\n        description='Object detection and instance segmentation toolkit based on PaddlePaddle',\n        long_description=readme(),\n        long_description_content_type='text/markdown',\n        url='https://github.com/PaddlePaddle/PaddleDetection',\n        download_url='https://github.com/PaddlePaddle/PaddleDetection.git',\n        keywords=['ppdet paddle ppyolo'],\n        classifiers=[\n            'Intended Audience :: Developers',\n            'License :: OSI Approved :: Apache Software License',\n            'Operating System :: OS Independent',\n            'Natural Language :: Chinese (Simplified)',\n            'Programming Language :: Python :: 3',\n            'Programming Language :: Python :: 3.5',\n            'Programming Language :: Python :: 3.6',\n            'Programming Language :: Python :: 3.7',\n            'Programming Language :: Python :: 3.8', 'Topic :: Utilities'\n        ],\n        license='Apache License 2.0',\n        ext_modules=[])\n"
        },
        {
          "name": "test_tipc",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}