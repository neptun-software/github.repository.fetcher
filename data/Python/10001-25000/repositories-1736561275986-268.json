{
  "metadata": {
    "timestamp": 1736561275986,
    "page": 268,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "NVIDIA/NeMo",
      "stars": 12788,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.1796875,
          "content": "__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\nenv\npip-log.txt\npip-delete-this-directory.txt\n.tox\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n*.log\n.git\n**/*.nemo\n**/*.ckpt\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.544921875,
          "content": "# log and data files\n*.model\n*.pkl\n#*.ipynb\noutput\noutput_2048\nresult\n*.pt\ntests/data/asr\n.DS_Store\nbert.pt.json\nwork\nruns\nfastspeech_output\n.hydra\n.bash_history.local\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n**.pyc\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.idea\n.Python\nwandb\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\n#parts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/build\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# Override Jupyter in Github Language states for more accurate estimate of repo code.\n# Reference: https://github.com/github/linguist/blob/master/docs/overrides.md#generated-code\n*.ipynb linguist-generated\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don’t work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# VSCode project settins\n.vscode/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n/docs/html\n/docs/docs_zh/zh\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Emacs backup files\n*~\n\ncifar-10-batches-py\n*.tar.gz\n\n# Test data.\ntests/.data\ntests/data\n\n# outputs folder\nexamples/*/outputs\nexamples/*/NeMo_experiments\nexamples/*/nemo_experiments\nexamples/*/.hydra\nexamples/*/wandb\nexamples/*/data\nwandb\ndump.py\n\ndocs/sources/source/test_build/\n\n# Checkpoints, config files and temporary files created in tutorials.\nexamples/neural_graphs/*.chkpt\nexamples/neural_graphs/*.yml\n\n.hydra/\nnemo_experiments/\n\nslurm*.out\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.7470703125,
          "content": "# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ndefault_language_version:\n  python: python3\n\nci:\n  autofix_prs: true\n  autoupdate_commit_msg: '[pre-commit.ci] pre-commit suggestions'\n  autoupdate_schedule: quarterly\n  # skip all hooks that can change the files, use GitHub Action \"code-formatting.yml\" for this\n  skip: [black,isort]\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.3.0\n    hooks:\n      - id: check-yaml\n      - id: check-case-conflict\n      - id: detect-private-key\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: requirements-txt-fixer\n\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        name: Format imports\n        exclude: docs/\n\n  # Using this mirror lets us use mypyc-compiled black, which is about 2x faster\n  - repo: https://github.com/psf/black-pre-commit-mirror\n    rev: 24.3.0\n    hooks:\n      - id: black\n        # It is recommended to specify the latest version of Python\n        # supported by your project here, or alternatively use\n        # pre-commit's default_language_version, see\n        # https://pre-commit.com/#top_level-default_language_version\n        language_version: python3.10\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 0.2197265625,
          "content": "[MAIN]\nignore-paths=tests\nmax-line-length=119\n\n[MESSAGES CONTROL]\ndisable=all\n\nenable=C0115,C0116,W0611,C0301\n# C0115: missing-class-docstring\n# C0116: missing-function-docstring\n# W0611: unused-import\n# C0301: line-too-long\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 1.1767578125,
          "content": "# =============================================================================\n# Copyright (c) 2020 NVIDIA. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required field.\nversion: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.10\"\n\n# Build documentation in the docs/ directory with Sphinx.\nsphinx:\n  configuration: docs/source/conf.py\n\n# Set the version of Python and requirements required to build your docs\npython:\n  install:\n    - requirements: requirements/requirements_docs.txt\n"
        },
        {
          "name": ".secrets.baseline",
          "type": "blob",
          "size": 72.5654296875,
          "content": "{\n  \"version\": \"1.5.0\",\n  \"plugins_used\": [\n    {\n      \"name\": \"ArtifactoryDetector\"\n    },\n    {\n      \"name\": \"AWSKeyDetector\"\n    },\n    {\n      \"name\": \"AzureStorageKeyDetector\"\n    },\n    {\n      \"name\": \"Base64HighEntropyString\",\n      \"limit\": 4.5\n    },\n    {\n      \"name\": \"BasicAuthDetector\"\n    },\n    {\n      \"name\": \"CloudantDetector\"\n    },\n    {\n      \"name\": \"DiscordBotTokenDetector\"\n    },\n    {\n      \"name\": \"GitHubTokenDetector\"\n    },\n    {\n      \"name\": \"GitLabTokenDetector\"\n    },\n    {\n      \"name\": \"HexHighEntropyString\",\n      \"limit\": 3.0\n    },\n    {\n      \"name\": \"IbmCloudIamDetector\"\n    },\n    {\n      \"name\": \"IbmCosHmacDetector\"\n    },\n    {\n      \"name\": \"IPPublicDetector\"\n    },\n    {\n      \"name\": \"JwtTokenDetector\"\n    },\n    {\n      \"name\": \"KeywordDetector\",\n      \"keyword_exclude\": \"\"\n    },\n    {\n      \"name\": \"MailchimpDetector\"\n    },\n    {\n      \"name\": \"NpmDetector\"\n    },\n    {\n      \"name\": \"OpenAIDetector\"\n    },\n    {\n      \"name\": \"PrivateKeyDetector\"\n    },\n    {\n      \"name\": \"PypiTokenDetector\"\n    },\n    {\n      \"name\": \"SendGridDetector\"\n    },\n    {\n      \"name\": \"SlackDetector\"\n    },\n    {\n      \"name\": \"SoftlayerDetector\"\n    },\n    {\n      \"name\": \"SquareOAuthDetector\"\n    },\n    {\n      \"name\": \"StripeDetector\"\n    },\n    {\n      \"name\": \"TelegramBotTokenDetector\"\n    },\n    {\n      \"name\": \"TwilioKeyDetector\"\n    }\n  ],\n  \"filters_used\": [\n    {\n      \"path\": \"detect_secrets.filters.allowlist.is_line_allowlisted\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.common.is_baseline_file\",\n      \"filename\": \".secrets.baseline\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.common.is_ignored_due_to_verification_policies\",\n      \"min_level\": 2\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_indirect_reference\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_likely_id_string\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_lock_file\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_not_alphanumeric_string\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_potential_uuid\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_prefixed_with_dollar_sign\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_sequential_string\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_swagger_file\"\n    },\n    {\n      \"path\": \"detect_secrets.filters.heuristic.is_templated_secret\"\n    }\n  ],\n  \"results\": {\n    \".github/workflows/node-reboot.yml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \".github/workflows/node-reboot.yml\",\n        \"hashed_secret\": \"3e26d6750975d678acb8fa35a0f69237881576b0\",\n        \"is_verified\": false,\n        \"line_number\": 52\n      }\n    ],\n    \"docs/source/nlp/question_answering.rst\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"docs/source/nlp/question_answering.rst\",\n        \"hashed_secret\": \"22e6f19f702bbd215acc1862da6acba7e874674e\",\n        \"is_verified\": false,\n        \"line_number\": 130\n      }\n    ],\n    \"examples/multimodal/multimodal_llm/neva/conf/lita_config.yaml\": [\n      {\n        \"type\": \"Base64 High Entropy String\",\n        \"filename\": \"examples/multimodal/multimodal_llm/neva/conf/lita_config.yaml\",\n        \"hashed_secret\": \"a90ca639abde504aba67797b0663923a0075fe6e\",\n        \"is_verified\": false,\n        \"line_number\": 75\n      }\n    ],\n    \"examples/multimodal/multimodal_llm/neva/conf/neva_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/multimodal/multimodal_llm/neva/conf/neva_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 50\n      }\n    ],\n    \"examples/nlp/information_retrieval/conf/megatron_gpt_embedder_generate_config.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/information_retrieval/conf/megatron_gpt_embedder_generate_config.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 165\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_baichuan2_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_baichuan2_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 38\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_chatglm_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_chatglm_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 38\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_falcon_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_falcon_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 37\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_gpt_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_gpt_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 41\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_griffin_generate_config.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_griffin_generate_config.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 239\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_llama_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_llama_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 38\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_mamba_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_mamba_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 40\n      }\n    ],\n    \"examples/nlp/language_modeling/conf/megatron_qwen2_inference.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/conf/megatron_qwen2_inference.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 38\n      }\n    ],\n    \"examples/nlp/language_modeling/tuning/conf/megatron_gpt_generate_config.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/tuning/conf/megatron_gpt_generate_config.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 160\n      }\n    ],\n    \"examples/nlp/language_modeling/tuning/conf/megatron_mamba_generate_config.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/tuning/conf/megatron_mamba_generate_config.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 168\n      }\n    ],\n    \"examples/nlp/language_modeling/tuning/conf/megatron_t5_generate_config.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"examples/nlp/language_modeling/tuning/conf/megatron_t5_generate_config.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 157\n      }\n    ],\n    \"scripts/checkpoint_converters/convert_mistral_7b_hf_to_nemo.py\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"scripts/checkpoint_converters/convert_mistral_7b_hf_to_nemo.py\",\n        \"hashed_secret\": \"e0308bd21bffc156d79208f9ecf130370a015002\",\n        \"is_verified\": false,\n        \"line_number\": 471\n      }\n    ],\n    \"scripts/dataset_processing/nlp/intent_and_slot/assistant_utils.py\": [\n      {\n        \"type\": \"Base64 High Entropy String\",\n        \"filename\": \"scripts/dataset_processing/nlp/intent_and_slot/assistant_utils.py\",\n        \"hashed_secret\": \"adfce53cfc5a36ea58ba816ea6d005231db6455c\",\n        \"is_verified\": false,\n        \"line_number\": 40\n      }\n    ],\n    \"scripts/nlp_language_modeling/service_launch_scripts/conf/retro_web_server.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"scripts/nlp_language_modeling/service_launch_scripts/conf/retro_web_server.yaml\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 9\n      }\n    ],\n    \"scripts/nlp_language_modeling/service_launch_scripts/env_variables.sh\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"scripts/nlp_language_modeling/service_launch_scripts/env_variables.sh\",\n        \"hashed_secret\": \"109f4b3c50d7b0df729d299bc6f8e9ef9066971f\",\n        \"is_verified\": false,\n        \"line_number\": 33\n      }\n    ],\n    \"scripts/tts_dataset_files/cmudict-0.7b_nv22.10\": [\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/cmudict-0.7b_nv22.10\",\n        \"hashed_secret\": \"27b998c0976876189b861934085bba2964e49a11\",\n        \"is_verified\": false,\n        \"line_number\": 4873\n      }\n    ],\n    \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\": [\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"6a1c698aa2f0b96b536710f5a2abd0ca64fdb2c1\",\n        \"is_verified\": false,\n        \"line_number\": 8415\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"9a611ff964db23d7cd8a6f63beb7471144f6be92\",\n        \"is_verified\": false,\n        \"line_number\": 8421\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"f2f0bc1252ccb8bbc113859849f8c36be203fd9e\",\n        \"is_verified\": false,\n        \"line_number\": 8424\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"b65cab561c4acd1e20bafd08ce19a9e7b5ea9e1c\",\n        \"is_verified\": false,\n        \"line_number\": 8431\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"c08ba5eff4953649130e83149817e1087c183358\",\n        \"is_verified\": false,\n        \"line_number\": 8433\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"b182776899d0959f28f3d80c7d50317de5c0fb2b\",\n        \"is_verified\": false,\n        \"line_number\": 8441\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"e466719c0309450475aa6b0e0c53a2211db0176d\",\n        \"is_verified\": false,\n        \"line_number\": 8442\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"0e7ae57946d9c88ce5f017ac50640e2c93c5277b\",\n        \"is_verified\": false,\n        \"line_number\": 8443\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"6d13086a143b48a00e3aa745a955095fbbc075b2\",\n        \"is_verified\": false,\n        \"line_number\": 8444\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"d206dd2b79987f5989b23a7a43d6163ed48312f0\",\n        \"is_verified\": false,\n        \"line_number\": 8446\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"be10bcbbe755bdd51e856af50af01bb4f95bfedb\",\n        \"is_verified\": false,\n        \"line_number\": 8449\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"2f00d2108827b933019dbedc8cc3f9c84f3bfe1e\",\n        \"is_verified\": false,\n        \"line_number\": 8451\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"a705c12d23346a892256fa95c892304bd8f4d265\",\n        \"is_verified\": false,\n        \"line_number\": 8454\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"2471810862c167bed6c3a8383dd410aedb8cb7e1\",\n        \"is_verified\": false,\n        \"line_number\": 8456\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"34befc5cf63e9c9259c7e75714c81db892419549\",\n        \"is_verified\": false,\n        \"line_number\": 8464\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"343d4559dcb06080b6fc5a9f42fbb88b6e343526\",\n        \"is_verified\": false,\n        \"line_number\": 8470\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"96631b5faaa50b4d24076072a357a13f48f1435f\",\n        \"is_verified\": false,\n        \"line_number\": 8472\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"c5be9fd8c751b6d2ff6219c63de90e4aa9f97546\",\n        \"is_verified\": false,\n        \"line_number\": 8477\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"4f68de76b2c605cb67d99b1e97b1461ef4618db2\",\n        \"is_verified\": false,\n        \"line_number\": 8479\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"90d1db77f31a86c5e0081468e0dbda8172b70131\",\n        \"is_verified\": false,\n        \"line_number\": 8508\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"6f3ce73b5dfbe7e4948bdad86c804ce74e17e0cf\",\n        \"is_verified\": false,\n        \"line_number\": 8510\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"a1f22c6489b0cf0016b9364619a7d7eed95b6364\",\n        \"is_verified\": false,\n        \"line_number\": 8512\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"b55ad569f88dc7e42868047f4f4a59c3cb6c110a\",\n        \"is_verified\": false,\n        \"line_number\": 8519\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"f2c207cddfe45b6c893619c3757f264f721025c6\",\n        \"is_verified\": false,\n        \"line_number\": 8521\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"d1371bfdfaf5d02731488ca6b6f12e51617813ab\",\n        \"is_verified\": false,\n        \"line_number\": 8549\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"76d22e171aa272dbdd6d1d67c23d9f700362f09a\",\n        \"is_verified\": false,\n        \"line_number\": 8555\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"0efe19de03cdaa4a382654246b4bff22dd79e518\",\n        \"is_verified\": false,\n        \"line_number\": 8568\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"d318e8342db9deb2f6827f39fad6229ca4e4521a\",\n        \"is_verified\": false,\n        \"line_number\": 8581\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"fb99a4a93e08e86cf5f4475aba66e85def711752\",\n        \"is_verified\": false,\n        \"line_number\": 8586\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"04ebb8445e6050d78c4636b19a17221387216b0d\",\n        \"is_verified\": false,\n        \"line_number\": 8588\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"2ec592daffb8a6e8c402690f7aadac6475c5f2ec\",\n        \"is_verified\": false,\n        \"line_number\": 8591\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"f7df3933dce6e3f5843b7e55ccff8f2516302229\",\n        \"is_verified\": false,\n        \"line_number\": 8601\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"fe860f7095f48e2f6a63b97124da4afd8c987895\",\n        \"is_verified\": false,\n        \"line_number\": 8606\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"abd3d69f7d8c98bb7fe98cb6aa41bf3d42d23911\",\n        \"is_verified\": false,\n        \"line_number\": 8609\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"2070834a550a6fbae2a3912e1117fa9f4270752b\",\n        \"is_verified\": false,\n        \"line_number\": 8619\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"e7d64bf030b802c205af2832114589c141ea1f33\",\n        \"is_verified\": false,\n        \"line_number\": 8622\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"c84bccf09830b2804e4d59e8bf82393ae76a8b03\",\n        \"is_verified\": false,\n        \"line_number\": 8625\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"86888ce709ad4a2590221da4f4d602a254443470\",\n        \"is_verified\": false,\n        \"line_number\": 8628\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"ae5da5b749fe3b2aea4957c7ee83938a75622bb7\",\n        \"is_verified\": false,\n        \"line_number\": 8645\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"94ccf1bc68c1a19f5733d9ac6e5bb60166e6530d\",\n        \"is_verified\": false,\n        \"line_number\": 8647\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"892dbf65134c4dfb554a16f5fc387ef153e269ed\",\n        \"is_verified\": false,\n        \"line_number\": 8697\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"61bfa79fd6923bc44a8c8c500b8992a66f5ae340\",\n        \"is_verified\": false,\n        \"line_number\": 8703\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"db880cb9754850e54f247dc1f7d1cce5f80ec056\",\n        \"is_verified\": false,\n        \"line_number\": 8718\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"a020736e7f661dc0d7985bfdcfadb7dce8db6216\",\n        \"is_verified\": false,\n        \"line_number\": 8719\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"ee8ddcdb18d90b8ddc8d9d4bb28e7fe700965ea8\",\n        \"is_verified\": false,\n        \"line_number\": 8720\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"f5726d5cd941bc5fd7cd26fdbf6d1ed5750e55bd\",\n        \"is_verified\": false,\n        \"line_number\": 8721\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"49e5b074ecc6a910f32617b1d2103849177a254e\",\n        \"is_verified\": false,\n        \"line_number\": 8750\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"e0a73b397eafd55a2f9cac7b031bf8716bc2b79e\",\n        \"is_verified\": false,\n        \"line_number\": 8751\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"9c593b1ecb2cfed50a12793d23fb3fc0cd5f5e21\",\n        \"is_verified\": false,\n        \"line_number\": 8762\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"e1db0a80a43c626e55171566c5823588cfb02fd8\",\n        \"is_verified\": false,\n        \"line_number\": 8764\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"a5f7d1f0a545e46e361e56191788d0f5fee625fb\",\n        \"is_verified\": false,\n        \"line_number\": 8772\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"4d199d4ccaea5f654b23dbc22e54acd79cc76e8c\",\n        \"is_verified\": false,\n        \"line_number\": 8774\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"865d1b874b4cd866febe48e024ed94af5303f808\",\n        \"is_verified\": false,\n        \"line_number\": 8775\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"fa25b96c74c4f77bb3eb89c55a7ab88550d12de5\",\n        \"is_verified\": false,\n        \"line_number\": 8776\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"a21fc67d6e3ff4d5f39596793a9e2b01c608d69f\",\n        \"is_verified\": false,\n        \"line_number\": 8777\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"b2e00015ad1a9cb779655b48a19eff8c834bc36e\",\n        \"is_verified\": false,\n        \"line_number\": 8778\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"ca51add4d292a3744a883a8844bcbf067b34b468\",\n        \"is_verified\": false,\n        \"line_number\": 8779\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"8479cbf554082f4f4b3c9587f21c62f406940e93\",\n        \"is_verified\": false,\n        \"line_number\": 8782\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"d1edb7ebbefe0dd0dfcddce8e0b7e63e74430a5b\",\n        \"is_verified\": false,\n        \"line_number\": 8784\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"c8b9b705e819ebeba33d4ff4f6dc638a9ee1f47c\",\n        \"is_verified\": false,\n        \"line_number\": 8787\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"250c748db4a13f7a3cff6ff0934bb0338e9f3190\",\n        \"is_verified\": false,\n        \"line_number\": 8788\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"6035f3432d36e33f2a57c3c6ee62014a9fb95a19\",\n        \"is_verified\": false,\n        \"line_number\": 8789\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_ES/es_ES_nv230301.dict\",\n        \"hashed_secret\": \"82b23ffc5cea766826613f29718bc1e3023f58e8\",\n        \"is_verified\": false,\n        \"line_number\": 8790\n      }\n    ],\n    \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\": [\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"6a1c698aa2f0b96b536710f5a2abd0ca64fdb2c1\",\n        \"is_verified\": false,\n        \"line_number\": 8743\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"9a611ff964db23d7cd8a6f63beb7471144f6be92\",\n        \"is_verified\": false,\n        \"line_number\": 8751\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"f2f0bc1252ccb8bbc113859849f8c36be203fd9e\",\n        \"is_verified\": false,\n        \"line_number\": 8755\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"b65cab561c4acd1e20bafd08ce19a9e7b5ea9e1c\",\n        \"is_verified\": false,\n        \"line_number\": 8764\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"c08ba5eff4953649130e83149817e1087c183358\",\n        \"is_verified\": false,\n        \"line_number\": 8766\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"b182776899d0959f28f3d80c7d50317de5c0fb2b\",\n        \"is_verified\": false,\n        \"line_number\": 8774\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"e466719c0309450475aa6b0e0c53a2211db0176d\",\n        \"is_verified\": false,\n        \"line_number\": 8775\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"0e7ae57946d9c88ce5f017ac50640e2c93c5277b\",\n        \"is_verified\": false,\n        \"line_number\": 8776\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"6d13086a143b48a00e3aa745a955095fbbc075b2\",\n        \"is_verified\": false,\n        \"line_number\": 8777\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"d206dd2b79987f5989b23a7a43d6163ed48312f0\",\n        \"is_verified\": false,\n        \"line_number\": 8779\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"be10bcbbe755bdd51e856af50af01bb4f95bfedb\",\n        \"is_verified\": false,\n        \"line_number\": 8782\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"2f00d2108827b933019dbedc8cc3f9c84f3bfe1e\",\n        \"is_verified\": false,\n        \"line_number\": 8784\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"a705c12d23346a892256fa95c892304bd8f4d265\",\n        \"is_verified\": false,\n        \"line_number\": 8787\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"2471810862c167bed6c3a8383dd410aedb8cb7e1\",\n        \"is_verified\": false,\n        \"line_number\": 8789\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"34befc5cf63e9c9259c7e75714c81db892419549\",\n        \"is_verified\": false,\n        \"line_number\": 8797\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"343d4559dcb06080b6fc5a9f42fbb88b6e343526\",\n        \"is_verified\": false,\n        \"line_number\": 8803\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"96631b5faaa50b4d24076072a357a13f48f1435f\",\n        \"is_verified\": false,\n        \"line_number\": 8805\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"c5be9fd8c751b6d2ff6219c63de90e4aa9f97546\",\n        \"is_verified\": false,\n        \"line_number\": 8810\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"4f68de76b2c605cb67d99b1e97b1461ef4618db2\",\n        \"is_verified\": false,\n        \"line_number\": 8812\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"90d1db77f31a86c5e0081468e0dbda8172b70131\",\n        \"is_verified\": false,\n        \"line_number\": 8841\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"6f3ce73b5dfbe7e4948bdad86c804ce74e17e0cf\",\n        \"is_verified\": false,\n        \"line_number\": 8843\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"a1f22c6489b0cf0016b9364619a7d7eed95b6364\",\n        \"is_verified\": false,\n        \"line_number\": 8845\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"b55ad569f88dc7e42868047f4f4a59c3cb6c110a\",\n        \"is_verified\": false,\n        \"line_number\": 8854\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"f2c207cddfe45b6c893619c3757f264f721025c6\",\n        \"is_verified\": false,\n        \"line_number\": 8856\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"d1371bfdfaf5d02731488ca6b6f12e51617813ab\",\n        \"is_verified\": false,\n        \"line_number\": 8884\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"76d22e171aa272dbdd6d1d67c23d9f700362f09a\",\n        \"is_verified\": false,\n        \"line_number\": 8890\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"0efe19de03cdaa4a382654246b4bff22dd79e518\",\n        \"is_verified\": false,\n        \"line_number\": 8903\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"d318e8342db9deb2f6827f39fad6229ca4e4521a\",\n        \"is_verified\": false,\n        \"line_number\": 8916\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"fb99a4a93e08e86cf5f4475aba66e85def711752\",\n        \"is_verified\": false,\n        \"line_number\": 8921\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"04ebb8445e6050d78c4636b19a17221387216b0d\",\n        \"is_verified\": false,\n        \"line_number\": 8923\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"2ec592daffb8a6e8c402690f7aadac6475c5f2ec\",\n        \"is_verified\": false,\n        \"line_number\": 8926\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"f7df3933dce6e3f5843b7e55ccff8f2516302229\",\n        \"is_verified\": false,\n        \"line_number\": 8936\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"fe860f7095f48e2f6a63b97124da4afd8c987895\",\n        \"is_verified\": false,\n        \"line_number\": 8941\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"abd3d69f7d8c98bb7fe98cb6aa41bf3d42d23911\",\n        \"is_verified\": false,\n        \"line_number\": 8944\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"2070834a550a6fbae2a3912e1117fa9f4270752b\",\n        \"is_verified\": false,\n        \"line_number\": 8954\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"e7d64bf030b802c205af2832114589c141ea1f33\",\n        \"is_verified\": false,\n        \"line_number\": 8958\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"c84bccf09830b2804e4d59e8bf82393ae76a8b03\",\n        \"is_verified\": false,\n        \"line_number\": 8962\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"86888ce709ad4a2590221da4f4d602a254443470\",\n        \"is_verified\": false,\n        \"line_number\": 8966\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"ae5da5b749fe3b2aea4957c7ee83938a75622bb7\",\n        \"is_verified\": false,\n        \"line_number\": 8997\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"94ccf1bc68c1a19f5733d9ac6e5bb60166e6530d\",\n        \"is_verified\": false,\n        \"line_number\": 8999\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"892dbf65134c4dfb554a16f5fc387ef153e269ed\",\n        \"is_verified\": false,\n        \"line_number\": 9050\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"61bfa79fd6923bc44a8c8c500b8992a66f5ae340\",\n        \"is_verified\": false,\n        \"line_number\": 9058\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"db880cb9754850e54f247dc1f7d1cce5f80ec056\",\n        \"is_verified\": false,\n        \"line_number\": 9076\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"a020736e7f661dc0d7985bfdcfadb7dce8db6216\",\n        \"is_verified\": false,\n        \"line_number\": 9077\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"ee8ddcdb18d90b8ddc8d9d4bb28e7fe700965ea8\",\n        \"is_verified\": false,\n        \"line_number\": 9078\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"f5726d5cd941bc5fd7cd26fdbf6d1ed5750e55bd\",\n        \"is_verified\": false,\n        \"line_number\": 9079\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"49e5b074ecc6a910f32617b1d2103849177a254e\",\n        \"is_verified\": false,\n        \"line_number\": 9108\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"e0a73b397eafd55a2f9cac7b031bf8716bc2b79e\",\n        \"is_verified\": false,\n        \"line_number\": 9109\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"9c593b1ecb2cfed50a12793d23fb3fc0cd5f5e21\",\n        \"is_verified\": false,\n        \"line_number\": 9120\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"e1db0a80a43c626e55171566c5823588cfb02fd8\",\n        \"is_verified\": false,\n        \"line_number\": 9122\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"a5f7d1f0a545e46e361e56191788d0f5fee625fb\",\n        \"is_verified\": false,\n        \"line_number\": 9130\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"4d199d4ccaea5f654b23dbc22e54acd79cc76e8c\",\n        \"is_verified\": false,\n        \"line_number\": 9132\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"865d1b874b4cd866febe48e024ed94af5303f808\",\n        \"is_verified\": false,\n        \"line_number\": 9133\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"fa25b96c74c4f77bb3eb89c55a7ab88550d12de5\",\n        \"is_verified\": false,\n        \"line_number\": 9134\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"a21fc67d6e3ff4d5f39596793a9e2b01c608d69f\",\n        \"is_verified\": false,\n        \"line_number\": 9135\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"b2e00015ad1a9cb779655b48a19eff8c834bc36e\",\n        \"is_verified\": false,\n        \"line_number\": 9136\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"ca51add4d292a3744a883a8844bcbf067b34b468\",\n        \"is_verified\": false,\n        \"line_number\": 9137\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"8479cbf554082f4f4b3c9587f21c62f406940e93\",\n        \"is_verified\": false,\n        \"line_number\": 9140\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"d1edb7ebbefe0dd0dfcddce8e0b7e63e74430a5b\",\n        \"is_verified\": false,\n        \"line_number\": 9142\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"c8b9b705e819ebeba33d4ff4f6dc638a9ee1f47c\",\n        \"is_verified\": false,\n        \"line_number\": 9145\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"250c748db4a13f7a3cff6ff0934bb0338e9f3190\",\n        \"is_verified\": false,\n        \"line_number\": 9146\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"6035f3432d36e33f2a57c3c6ee62014a9fb95a19\",\n        \"is_verified\": false,\n        \"line_number\": 9147\n      },\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/es_LA/es_LA_nv230301.dict\",\n        \"hashed_secret\": \"82b23ffc5cea766826613f29718bc1e3023f58e8\",\n        \"is_verified\": false,\n        \"line_number\": 9148\n      }\n    ],\n    \"scripts/tts_dataset_files/ipa_cmudict-0.7b_nv23.01.txt\": [\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"scripts/tts_dataset_files/ipa_cmudict-0.7b_nv23.01.txt\",\n        \"hashed_secret\": \"27b998c0976876189b861934085bba2964e49a11\",\n        \"is_verified\": false,\n        \"line_number\": 4886\n      }\n    ],\n    \"tests/hydra/config1_invalid.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"tests/hydra/config1_invalid.yaml\",\n        \"hashed_secret\": \"e5e9fa1ba31ecd1ae84f75caaa474f3a663f05f4\",\n        \"is_verified\": false,\n        \"line_number\": 2\n      }\n    ],\n    \"tests/hydra/config_subdir/config2_invalid.yaml\": [\n      {\n        \"type\": \"Secret Keyword\",\n        \"filename\": \"tests/hydra/config_subdir/config2_invalid.yaml\",\n        \"hashed_secret\": \"ebf1f14a3530cd22650b951908b5159f1f2a3ca8\",\n        \"is_verified\": false,\n        \"line_number\": 2\n      }\n    ],\n    \"tests/infer_data_path.py\": [\n      {\n        \"type\": \"Base64 High Entropy String\",\n        \"filename\": \"tests/infer_data_path.py\",\n        \"hashed_secret\": \"8e0937151cfd9750db688fbe66be37d0c53ed6ab\",\n        \"is_verified\": false,\n        \"line_number\": 63\n      }\n    ],\n    \"tutorials/asr/Multilang_ASR.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"23ab3508f39164c81139e2bc866ebe46b69248f3\",\n        \"is_verified\": false,\n        \"line_number\": 562\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"bfbd2a23ecc348e67d5cb55f2db6bf9f9cebb325\",\n        \"is_verified\": false,\n        \"line_number\": 563\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"81dee32e25f1d0c256140df030b2531dde332acb\",\n        \"is_verified\": false,\n        \"line_number\": 564\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4af542b2d6e243a440ad4cf2815d6e2237808df5\",\n        \"is_verified\": false,\n        \"line_number\": 565\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"a67ed767388e7eece04b5c6f7b568ddf29edac7c\",\n        \"is_verified\": false,\n        \"line_number\": 566\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"c022505b9f732f0cb352fe8ed5fc278912b46488\",\n        \"is_verified\": false,\n        \"line_number\": 567\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"182d4019337b9c8786b6e34a83441a21bad1874b\",\n        \"is_verified\": false,\n        \"line_number\": 568\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"740eb48367bc73edfc56bc4414e9b2662736566c\",\n        \"is_verified\": false,\n        \"line_number\": 569\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"b1aef696788110cd1e18595d6cebb0959d36adfa\",\n        \"is_verified\": false,\n        \"line_number\": 570\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"c7fe8bf177365ffe460c15da553c7368ddfdbaa7\",\n        \"is_verified\": false,\n        \"line_number\": 571\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f3112d03411e69f7a23d5d1582079e1173cd032e\",\n        \"is_verified\": false,\n        \"line_number\": 572\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"46859f9c2007195e9762d88c36247d018859f09d\",\n        \"is_verified\": false,\n        \"line_number\": 676\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"afc8f88c8c20204370c5f35925ef36fc71c71379\",\n        \"is_verified\": false,\n        \"line_number\": 677\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"df94d52f84db3fa667993f544ea80aca4f9a2125\",\n        \"is_verified\": false,\n        \"line_number\": 678\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"783c5002441b0a6225cc26f71864f7f8504ef819\",\n        \"is_verified\": false,\n        \"line_number\": 679\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"469b7833ff898575016f6df77172c9fc910efdf7\",\n        \"is_verified\": false,\n        \"line_number\": 680\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"90771a6f73123f8665fe199fa920d06ff407ec72\",\n        \"is_verified\": false,\n        \"line_number\": 681\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"cbf4db9d163e190540825e529b55b551ba21733a\",\n        \"is_verified\": false,\n        \"line_number\": 682\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4f58de63d50f78243fadbf94a08fc58fb51d1428\",\n        \"is_verified\": false,\n        \"line_number\": 683\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"2dc56a67a4ab217c7197c4ce468e0dbe7f20d54b\",\n        \"is_verified\": false,\n        \"line_number\": 684\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"a4d526869e953d0eebcfd7948f798ba1d39397c4\",\n        \"is_verified\": false,\n        \"line_number\": 685\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"8109bf627c2f367f0f75ec0fc4079040d46ea65b\",\n        \"is_verified\": false,\n        \"line_number\": 686\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"05d48a4ba182e2966da054c756e527a7304b586e\",\n        \"is_verified\": false,\n        \"line_number\": 1148\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"a091c7128789cea09adabf026a3dbd7b0febcfef\",\n        \"is_verified\": false,\n        \"line_number\": 1149\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"38403bcc580ba265c4918eaea606399cf37689a2\",\n        \"is_verified\": false,\n        \"line_number\": 1150\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"d572b2cd7c13cbb69a638f2b978da146b34340df\",\n        \"is_verified\": false,\n        \"line_number\": 1151\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f97db3647a1e5869756fc4019bf198e900034e67\",\n        \"is_verified\": false,\n        \"line_number\": 1152\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"ae0722be63cd884e5788cc8153a9f7728d54f72c\",\n        \"is_verified\": false,\n        \"line_number\": 1153\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"d694e89fef75e8d868accaba50c224a1f2dd8399\",\n        \"is_verified\": false,\n        \"line_number\": 1154\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"8e2fe85dc67f14fa2f02ffa465974dec89655856\",\n        \"is_verified\": false,\n        \"line_number\": 1155\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"e23d0990cdb54a3d1dc3c9bcf922242fc7bacc64\",\n        \"is_verified\": false,\n        \"line_number\": 1156\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"d49a849228aa07e957274e8b1349405868626e56\",\n        \"is_verified\": false,\n        \"line_number\": 1157\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"a32050f253ef8a9f61b37ac26180efb6acf0bb30\",\n        \"is_verified\": false,\n        \"line_number\": 1158\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"834213b15871dbd6b30f517de52ec9df2730eb7b\",\n        \"is_verified\": false,\n        \"line_number\": 1196\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"b0555871dc9fc34a149b82e62fc72fc654b84667\",\n        \"is_verified\": false,\n        \"line_number\": 1197\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"32fe03ac71cc6c8a31c72e21c9aec64557cb4fba\",\n        \"is_verified\": false,\n        \"line_number\": 1198\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"3e712f05fedce2068adf4f6ac44b3759a1fbbd59\",\n        \"is_verified\": false,\n        \"line_number\": 1199\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f8472c93db4afd582aafddcc5a2dd8d568cb3e43\",\n        \"is_verified\": false,\n        \"line_number\": 1200\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"1d8c14b1e24558e9cdbd47644f36c5675edcdcca\",\n        \"is_verified\": false,\n        \"line_number\": 1201\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"2a11395949beadb049a0cd129b6f5e3aa3782814\",\n        \"is_verified\": false,\n        \"line_number\": 1202\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"edae2d92434824df126daa3340589b60da2afa67\",\n        \"is_verified\": false,\n        \"line_number\": 1203\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"cc9e0c1b12b1abaffa7eb6cbccbee72f65ac1535\",\n        \"is_verified\": false,\n        \"line_number\": 1204\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"e80f107771869ec656d0cf6e8486486b69f922ae\",\n        \"is_verified\": false,\n        \"line_number\": 1205\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"160fb2093e3388000d26c76d25428170a035bdcf\",\n        \"is_verified\": false,\n        \"line_number\": 1206\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"9488ce4f041c4c3b404ff21110170940ce5295f2\",\n        \"is_verified\": false,\n        \"line_number\": 2028\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4fb50b7293c24d257d3b39eec254517e73cd27be\",\n        \"is_verified\": false,\n        \"line_number\": 2029\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"2d3ad63f96d6f447f63a2ec9d451ba34a8c8013e\",\n        \"is_verified\": false,\n        \"line_number\": 2030\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"7c0a1424bcd4d5086497ba05ff5d2b5c11112655\",\n        \"is_verified\": false,\n        \"line_number\": 2031\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"5582b5110b9376a45e2329d2d127f972673287a9\",\n        \"is_verified\": false,\n        \"line_number\": 2032\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"e99b32711f4beb0cd40130d75016b45ec188eac0\",\n        \"is_verified\": false,\n        \"line_number\": 2033\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"5cbed1a68bafa82a8a0ff59f03c8f28148081f1e\",\n        \"is_verified\": false,\n        \"line_number\": 2034\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"d7604ec9987dc19cfd2e512d1fdab6f1ceb41a7c\",\n        \"is_verified\": false,\n        \"line_number\": 2035\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"b329420ee2aa11facc5a652f2bb32ca0f186c442\",\n        \"is_verified\": false,\n        \"line_number\": 2036\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f16bb2651aa872a8d12dd98e11efb58bd23da895\",\n        \"is_verified\": false,\n        \"line_number\": 2037\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"74032a5243a1cf863a7e84e1749a3fac81e7290f\",\n        \"is_verified\": false,\n        \"line_number\": 2038\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"b5b39748fce09b60e94b21b466c52c791d627cba\",\n        \"is_verified\": false,\n        \"line_number\": 2039\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"db98703d26bdf4616c4e65036986b6355611211f\",\n        \"is_verified\": false,\n        \"line_number\": 2040\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4d14a5871469d7490614a53cab3fbfc52a7279e5\",\n        \"is_verified\": false,\n        \"line_number\": 2041\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"258ddab91bab22bd68bc3015ea889521fa3fdacd\",\n        \"is_verified\": false,\n        \"line_number\": 2042\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"6d7a940238710f5f734f1816fc47959ef7f95636\",\n        \"is_verified\": false,\n        \"line_number\": 2043\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"de52434f2efe55aed0df2256de9abd275539cf0b\",\n        \"is_verified\": false,\n        \"line_number\": 2044\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4cd4d2a18051aaad9320442a4377cd18577f73f9\",\n        \"is_verified\": false,\n        \"line_number\": 2045\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"954ca4decf6425679bb28e223ff6b137c1e9ce6e\",\n        \"is_verified\": false,\n        \"line_number\": 2046\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f6b0d563b01f1250220b29dbdf5f70c14d206be7\",\n        \"is_verified\": false,\n        \"line_number\": 2047\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"99285fb5e057fc901d1877f1f0c8b8c94ecd1358\",\n        \"is_verified\": false,\n        \"line_number\": 2048\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"faa5674f871179e8abe110c410403b51893c917f\",\n        \"is_verified\": false,\n        \"line_number\": 2049\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"92a0615e0edaf88003fb0b6f70dc77de93828bb8\",\n        \"is_verified\": false,\n        \"line_number\": 2103\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"77351aa360f4c3e50ef4cd700bba74219d5b5aa2\",\n        \"is_verified\": false,\n        \"line_number\": 2104\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"c7226bd151222bb3ab574a4d21d83d97ed054112\",\n        \"is_verified\": false,\n        \"line_number\": 2105\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"f73edb9e83b0f41052050055ac563973a6850afb\",\n        \"is_verified\": false,\n        \"line_number\": 2106\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"346a54ded37ddfd7de0b98b3f8a6fefb92c97ec5\",\n        \"is_verified\": false,\n        \"line_number\": 2107\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"078cde4cd776c14c9166304412a643cff409faa0\",\n        \"is_verified\": false,\n        \"line_number\": 2108\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4a3c4394031a7842a72b787cf5b08a165e8b7206\",\n        \"is_verified\": false,\n        \"line_number\": 2109\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"406aa8259676acb13859b17f5e1f94fcdb69c0d6\",\n        \"is_verified\": false,\n        \"line_number\": 2110\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"3607002f0fabd7bbbe4e90715beb1c85a6ade333\",\n        \"is_verified\": false,\n        \"line_number\": 2111\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"465ee282a0d7b2cf762d9dbce0b1f356d75bc15d\",\n        \"is_verified\": false,\n        \"line_number\": 2112\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"44608c743318ec5489b23a388f4f6e0f724ac0a8\",\n        \"is_verified\": false,\n        \"line_number\": 2113\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"1a4251d6b7ba19233f16766868ac29e3428db4f0\",\n        \"is_verified\": false,\n        \"line_number\": 2203\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"55dd3f4c1b8682cf8ec7b21243cdffe0127f0e03\",\n        \"is_verified\": false,\n        \"line_number\": 2204\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"220d1fa41654cb432843792dd63e8f446eedefa9\",\n        \"is_verified\": false,\n        \"line_number\": 2205\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"35654d3cde31330d1e3fd05a04d4cbea41c1f993\",\n        \"is_verified\": false,\n        \"line_number\": 2206\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"119aea04e3efd1c741bfd98fe51439d6bb280a95\",\n        \"is_verified\": false,\n        \"line_number\": 2207\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"b5c60cd211f3aac2db08a223c0571d1e53e7c60d\",\n        \"is_verified\": false,\n        \"line_number\": 2208\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"4039b99a1c2bdca7737ed4f7934e5a9db2e76f8c\",\n        \"is_verified\": false,\n        \"line_number\": 2209\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"6c04b8e8560c27e7c586a92b046c532da6b1e50c\",\n        \"is_verified\": false,\n        \"line_number\": 2210\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"6a76bf0f171be18b2c3bd53219235c3ab16fdc7f\",\n        \"is_verified\": false,\n        \"line_number\": 2211\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"025bef6ec65b88f3999f1b25157b7a6e17f5bfcd\",\n        \"is_verified\": false,\n        \"line_number\": 2212\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"026954128506e379050cbea083edbddd1c1777b6\",\n        \"is_verified\": false,\n        \"line_number\": 2213\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"745cfb125e37dee46e2952e02a0a4d5d5d56f546\",\n        \"is_verified\": false,\n        \"line_number\": 2314\n      },\n      {\n        \"type\": \"Base64 High Entropy String\",\n        \"filename\": \"tutorials/asr/Multilang_ASR.ipynb\",\n        \"hashed_secret\": \"543a58dd6dadfca9bc28a7f164e6b36c0b6e9a96\",\n        \"is_verified\": false,\n        \"line_number\": 4799\n      }\n    ],\n    \"tutorials/multimodal/DreamBooth Tutorial.ipynb\": [\n      {\n        \"type\": \"Base64 High Entropy String\",\n        \"filename\": \"tutorials/multimodal/DreamBooth Tutorial.ipynb\",\n        \"hashed_secret\": \"effe1444a4c73d23e5fc2a9f28048e1dd0653e82\",\n        \"is_verified\": false,\n        \"line_number\": 223\n      }\n    ],\n    \"tutorials/multimodal/Multimodal Data Preparation.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/multimodal/Multimodal Data Preparation.ipynb\",\n        \"hashed_secret\": \"5251fc51eb9d18d0de87c87ea09e4af9d1bf7a9f\",\n        \"is_verified\": false,\n        \"line_number\": 18\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/multimodal/Multimodal Data Preparation.ipynb\",\n        \"hashed_secret\": \"194c1dff6224941326fe1d95936ba0e22fd60bb2\",\n        \"is_verified\": false,\n        \"line_number\": 65\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/multimodal/Multimodal Data Preparation.ipynb\",\n        \"hashed_secret\": \"fe852a949d021998ad30bdd6a73a20c82221d486\",\n        \"is_verified\": false,\n        \"line_number\": 217\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/multimodal/Multimodal Data Preparation.ipynb\",\n        \"hashed_secret\": \"b641cbe299c9e27b480cc8a823bb020d45962236\",\n        \"is_verified\": false,\n        \"line_number\": 658\n      }\n    ],\n    \"tutorials/nlp/ITN_with_Thutmose_Tagger.ipynb\": [\n      {\n        \"type\": \"Artifactory Credentials\",\n        \"filename\": \"tutorials/nlp/ITN_with_Thutmose_Tagger.ipynb\",\n        \"hashed_secret\": \"b5077fe6f2a92ca029dc6b5c022321b3828a2998\",\n        \"is_verified\": false,\n        \"line_number\": 876\n      }\n    ],\n    \"tutorials/nlp/Token_Classification-BioMegatron.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/nlp/Token_Classification-BioMegatron.ipynb\",\n        \"hashed_secret\": \"308d692d0307f53df800c91720fb271d62078391\",\n        \"is_verified\": false,\n        \"line_number\": 689\n      }\n    ],\n    \"tutorials/speaker_tasks/Speaker_Diarization_Inference.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/speaker_tasks/Speaker_Diarization_Inference.ipynb\",\n        \"hashed_secret\": \"80903ddedcf4ec0a2ee5911cefa7e1ad52419dcc\",\n        \"is_verified\": false,\n        \"line_number\": 990\n      }\n    ],\n    \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"3d52dd8e15de7d018930a034453752599cecfb95\",\n        \"is_verified\": false,\n        \"line_number\": 18\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"8dd2391af4e9a5dc76b28f46ff201e1e7c9942f0\",\n        \"is_verified\": false,\n        \"line_number\": 38\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"af149e43b0d4f9e4554b6b7a3260eafbfe1b5d8e\",\n        \"is_verified\": false,\n        \"line_number\": 89\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"bb0c7befac27daf54e33d8e8b179598866feae04\",\n        \"is_verified\": false,\n        \"line_number\": 112\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"645a085cdd80cde400cc162bfa2c24a286ca24c8\",\n        \"is_verified\": false,\n        \"line_number\": 132\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"592340cf9486ccc3b0eff57e8f78ccf1f90add85\",\n        \"is_verified\": false,\n        \"line_number\": 147\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"a9fdd91c2d3e03d3a8f039126c275d27c4adc5b2\",\n        \"is_verified\": false,\n        \"line_number\": 198\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"eb455e1717efd60ca3896632c94a2b41d87855f2\",\n        \"is_verified\": false,\n        \"line_number\": 212\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"096179c125fa827fde3bb88f53873aeaa3f7709f\",\n        \"is_verified\": false,\n        \"line_number\": 263\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"9b895d433fc031a41bf872d697038c218e909066\",\n        \"is_verified\": false,\n        \"line_number\": 283\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"daf16ebe45194e3ebed5c2cc59f334279d51fa0f\",\n        \"is_verified\": false,\n        \"line_number\": 334\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"0d39ffb347d6fcd6c7b3519310756c1020091c6c\",\n        \"is_verified\": false,\n        \"line_number\": 357\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"8eedca919f4fb2dafb68c2afc1faf76088ab12e0\",\n        \"is_verified\": false,\n        \"line_number\": 377\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"7bc61a4c215f078b7de911363bedd91b471fa213\",\n        \"is_verified\": false,\n        \"line_number\": 392\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"3088c565074b06f94684576b96b4d5b59560497c\",\n        \"is_verified\": false,\n        \"line_number\": 443\n      },\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tools/DefinedCrowd_x_NeMo_ASR_Training_Tutorial.ipynb\",\n        \"hashed_secret\": \"209b86707a2f8f8253ce09587ca7ac1f6eefd4da\",\n        \"is_verified\": false,\n        \"line_number\": 457\n      }\n    ],\n    \"tutorials/tts/FastPitch_Finetuning.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tts/FastPitch_Finetuning.ipynb\",\n        \"hashed_secret\": \"e915298ac5414db160aada21c7a235431ddfa98d\",\n        \"is_verified\": false,\n        \"line_number\": 717\n      }\n    ],\n    \"tutorials/tts/FastPitch_MixerTTS_Training.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tts/FastPitch_MixerTTS_Training.ipynb\",\n        \"hashed_secret\": \"e915298ac5414db160aada21c7a235431ddfa98d\",\n        \"is_verified\": false,\n        \"line_number\": 611\n      }\n    ],\n    \"tutorials/tts/Inference_ModelSelect.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tts/Inference_ModelSelect.ipynb\",\n        \"hashed_secret\": \"98307baca81149afa8a07a7cbe7ebc48c447d4be\",\n        \"is_verified\": false,\n        \"line_number\": 315\n      }\n    ],\n    \"tutorials/tts/NeMo_TTS_Primer.ipynb\": [\n      {\n        \"type\": \"Hex High Entropy String\",\n        \"filename\": \"tutorials/tts/NeMo_TTS_Primer.ipynb\",\n        \"hashed_secret\": \"e915298ac5414db160aada21c7a235431ddfa98d\",\n        \"is_verified\": false,\n        \"line_number\": 2063\n      }\n    ]\n  },\n  \"generated_at\": \"2024-11-14T09:37:19Z\"\n}\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 71.8076171875,
          "content": "# Changelog\n\n<!-- Next changelog -->\n## NVIDIA Neural Modules 2.1.0\n\n### Highlights\n\n- Training\n  - Fault Tolerance\n    - Straggler Detection\n    - Auto Relaunch\n- LLM & MM\n  - MM models\n    - Llava-next\n    - Llama 3.2\n  - Sequence Model Parallel for NeVa\n  - Enable Energon\n  - SigLIP (NeMo 1.0 only)\n  - LLM 2.0 migration\n    - Starcoder2\n    - Gemma 2\n    - T5\n    - Baichuan\n    - BERT\n    - Mamba\n    - ChatGLM\n  - DoRA support\n- Export\n  - Nemo 2.0 base model export path for NIM\n  - PTQ in Nemo 2.0\n- ASR\n  - Timestamps with TDT decoder\n  - Timestamps option with .transcribe()\n\n### Detailed Changelogs:\n\n#### ASR\n\n<details><summary>Changelog</summary>\n\n- [Fix] Fixed sampler override and audio_key in prepare_audio_data by @anteju :: PR: #10980\n- Akoumparouli/mixtral recipe fix r2.0.0 by @akoumpa :: PR: #10994\n- TDT compute timestamps option and Extra Whitespace handling for SPE by @monica-sekoyan :: PR: #10875\n- ci: Switch to CPU only runner by @ko3n1g :: PR: #11035\n- Fix timestamps tests by @monica-sekoyan :: PR: #11053\n- ci: Pin release freeze by @ko3n1g :: PR: #11143\n- Fix RNN-T loss memory usage by @artbataev :: PR: #11144\n- Added deprecation notice by @Ssofja :: PR: #11133\n- Fixes for Canary adapters tutorial by @pzelasko :: PR: #11184\n- add ipython import guard by @nithinraok :: PR: #11191\n- Self Supervised Pre-Training tutorial Fix by @monica-sekoyan :: PR: #11206\n- update the return type by @nithinraok :: PR: #11210\n- Timestamps to transcribe by @nithinraok :: PR: #10950\n- [Doc fixes] update file names, installation instructions, bad links by @erastorgueva-nv :: PR: #11045\n- Beam search algorithm implementation for TDT models by @lilithgrigoryan :: PR: #10903\n- Update import 'pytorch_lightning' -> 'lightning.pytorch' by @maanug-nv :: PR: #11252\n- Remove pytorch-lightning by @maanug-nv :: PR: #11306\n- update hypothesis when passed through cfg by @nithinraok :: PR: #11366\n- Revert \"update hypothesis when passed through cfg\" by @pablo-garay :: PR: #11373\n- Fix transcribe speech by @nithinraok :: PR: #11379\n- Lhotse support for transcribe_speech_parallel by @nune-tadevosyan :: PR: #11249\n- Sortformer Diarizer 4spk v1 model PR Part 1: models, modules and dataloaders by @tango4j :: PR: #11282\n- Removing unnecessary lines by @nune-tadevosyan :: PR: #11408\n- Support for initializing lhotse shar dataloader via field: list[path] mapping by @pzelasko :: PR: #11460\n- New extended prompt format for Canary, short utterances inference fix, and training micro-optimizations by @pzelasko :: PR: #11058\n- Fixing Multi_Task_Adapters.ipynb by replacing canary2 with canary_custom by @weiqingw4ng :: PR: #11636\n\n</details>\n\n#### TTS\n\n<details><summary>Changelog</summary>\n\n- [Doc fixes] update file names, installation instructions, bad links by @erastorgueva-nv :: PR: #11045\n- Add T5TTS by @blisc :: PR: #11193\n- Update import 'pytorch_lightning' -> 'lightning.pytorch' by @maanug-nv :: PR: #11252\n- Remove pytorch-lightning by @maanug-nv :: PR: #11306\n- Add nvidia/low-frame-rate-speech-codec-22khz model on docs by @Edresson :: PR: #11457\n\n</details>\n\n#### NLP / NMT\n\n<details><summary>Changelog</summary>\n\n- Move collectiob.nlp imports inline for t5 by @marcromeyn :: PR: #10877\n- Use a context-manager when opening files by @akoumpa :: PR: #10895\n- Packed sequence bug fixes by @cuichenx :: PR: #10898\n- ckpt convert bug fixes by @dimapihtar :: PR: #10878\n- remove deprecated ci tests by @dimapihtar :: PR: #10922\n- Update T5 tokenizer (adding additional tokens to tokenizer config) by @huvunvidia :: PR: #10972\n- Add support and recipes for HF models via AutoModelForCausalLM by @akoumpa :: PR: #10962\n- gpt3 175b cli by @malay-nagda :: PR: #10985\n- Fix for crash with LoRA + tp_overlap_comm=false + sequence_parallel=true by @vysarge :: PR: #10920\n- Update `BaseMegatronSampler` for compatibility with PTL's `_BatchProgress` by @ashors1 :: PR: #11016\n- add deprecation note by @dimapihtar :: PR: #11024\n- Update ModelOpt Width Pruning example defaults by @kevalmorabia97 :: PR: #10902\n- switch to NeMo 2.0 recipes by @dimapihtar :: PR: #10948\n- NeMo 1.0: upcycle dense to moe by @akoumpa :: PR: #11002\n- Gemma2 in Nemo2 with Recipes by @suiyoubi :: PR: #11037\n- Add Packed Seq option to GPT based models by @suiyoubi :: PR: #11100\n- Fix MCoreGPTModel import in llm.gpt.model.base by @hemildesai :: PR: #11109\n- TP+MoE peft fix by @akoumpa :: PR: #11114\n- GPT recipes to use full te spec by @JimmyZhang12 :: PR: #11119\n- Virtual pipeline parallel support for LoRA in NLPAdapterModelMixin by @vysarge :: PR: #11128\n- update nemo args for mcore flash decode arg change by @HuiyingLi :: PR: #11138\n- Call `ckpt_to_weights_subdir` from `MegatronCheckpointIO` by @ashors1 :: PR: #10897\n- [Doc fixes] update file names, installation instructions, bad links by @erastorgueva-nv :: PR: #11045\n- fix(export): GPT models w/ bias=False convert properly by @terrykong :: PR: #11255\n- Use MegatronDataSampler in HfDatasetDataModule by @akoumpa :: PR: #11274\n- Add T5TTS by @blisc :: PR: #11193\n- ci: Exclude CPU machines from scan by @ko3n1g :: PR: #11300\n- Revert \"fix(export): GPT models w/ bias=False convert properly\" by @terrykong :: PR: #11301\n- remove redundant docs by @sharathts :: PR: #11302\n- Update import 'pytorch_lightning' -> 'lightning.pytorch' by @maanug-nv :: PR: #11252\n- Add `attention_bias` argument in transformer block and transformer layer modules, addressing change in MCore by @yaoyu-33 :: PR: #11289\n- Remove pytorch-lightning by @maanug-nv :: PR: #11306\n- Update T5 attention-mask shapes to be compatible with all attention-backend in new TE versions by @huvunvidia :: PR: #11059\n- Add support for restoring from 2.0 checkpoint in 1.0 by @hemildesai :: PR: #11347\n- Fix Gemma2 Attention Args by @suiyoubi :: PR: #11365\n- mlm conversion & tiktokenizer support by @dimapihtar :: PR: #11349\n- [Nemo1] Generate sharded optimizer state dicts only if needed for saving by @ananthsub :: PR: #11451\n- add hindi tn/itn coverage by @mgrafu :: PR: #11382\n- chore(beep boop 🤖): Bump `MCORE_TAG=67a50f2...` (2024-11-28) by @ko3n1g :: PR: #11427\n- Handle exception when importing RetroGPTChunkDatasets by @guyueh1 :: PR: #11415\n- Update restore from config for gpt type continual training in NeMo1 by @yaoyu-33 :: PR: #11471\n- ci: Re-enable `L2_Megatron_LM_To_NeMo_Conversion` by @ko3n1g :: PR: #11484\n- Apply packed sequence params change for fused rope compatibility by @ananthsub :: PR: #11506\n- Huvu/tiktoken tokenizer update by @huvunvidia :: PR: #11494\n\n</details>\n\n#### Text Normalization / Inverse Text Normalization\n\n<details><summary>Changelog</summary>\n\n- Adding support for LightningDataModule inside Fabric-API by @marcromeyn :: PR: #10879\n- Add registry to register all needed classes with artifacts in nemo.lightning.io by @hemildesai :: PR: #10861\n- Update import 'pytorch_lightning' -> 'lightning.pytorch' by @maanug-nv :: PR: #11252\n- Remove pytorch-lightning by @maanug-nv :: PR: #11306\n- add hindi tn/itn coverage by @mgrafu :: PR: #11382\n\n</details>\n\n#### Export\n\n<details><summary>Changelog</summary>\n\n- Update engine build step for TRT-LLM 0.13.0 by @janekl :: PR: #10880\n- Nemo 2.0 ckpt support in TRT-LLM export by @oyilmaz-nvidia :: PR: #10891\n- Fix TRTLLM parallel_embedding by @meatybobby :: PR: #10975\n- Export & deploy updates (part I) by @janekl :: PR: #10941\n- Add doc-strings to import & export + improve logging by @marcromeyn :: PR: #11078\n- NeMo-UX: fix nemo-ux export path by @akoumpa :: PR: #11081\n- Fix TRTLLM nemo2 activation parsing by @meatybobby :: PR: #11062\n- Support exporting Nemotron-340B for TensorRT-LLM by @jinyangyuan-nvidia :: PR: #11015\n- vLLM Hugging Face exporter by @oyilmaz-nvidia :: PR: #11124\n- Fix export of configuration parameters to Weights and Biases by @soluwalana :: PR: #10995\n- Change activation parsing in TRTLLM by @meatybobby :: PR: #11173\n- Remove builder_opt param from trtllm-build for TensorRT-LLM >= 0.14.0 by @janekl :: PR: #11259\n- fix(export): GPT models w/ bias=False convert properly by @terrykong :: PR: #11255\n- fix(export): update API for disabling device reassignment in TRTLLM for Aligner by @terrykong :: PR: #10863\n- Add openai-gelu in gated activation for TRTLLM export by @meatybobby :: PR: #11293\n- Revert \"fix(export): GPT models w/ bias=False convert properly\" by @terrykong :: PR: #11301\n- Adding alinger export by @shanmugamr1992 :: PR: #11269\n- Export & deploy updates (part II) by @janekl :: PR: #11344\n- Introducing TensorRT lazy export and caching option with trt_compile()  by @borisfom :: PR: #11266\n- fix: export converts properly if no model_prefix by @terrykong :: PR: #11477\n\n</details>\n\n#### Bugfixes\n\n<details><summary>Changelog</summary>\n\n- Change default ckpt name by @maanug-nv :: PR: #11277\n- Fix patching of NeMo tokenizers for correct Lambada evaluation by @janekl :: PR: #11326\n\n</details>\n\n#### Uncategorized:\n\n<details><summary>Changelog</summary>\n\n- ci: Use Slack group by @ko3n1g :: PR: #10866\n- Bump `Dockerfile.ci` (2024-10-14) by @ko3n1g :: PR: #10871\n- Fix peft resume by @cuichenx :: PR: #10887\n- call __post_init__ after altering config values by @akoumpa :: PR: #10885\n- Late import prettytable by @maanug-nv :: PR: #10912\n- Bump `Dockerfile.ci` (2024-10-17) by @ko3n1g :: PR: #10919\n- Warning for missing FP8 checkpoint support for vLLM deployment by @janekl :: PR: #10906\n- Fix artifact saving by @hemildesai :: PR: #10914\n- Lora improvement by @cuichenx :: PR: #10918\n- Huvu/t5 nemo2.0 peft by @huvunvidia :: PR: #10916\n- perf recipes and Mcore DistOpt params by @malay-nagda :: PR: #10883\n- ci: Fix cherry pick team by @ko3n1g :: PR: #10945\n- Fix requirements for MacOS by @artbataev :: PR: #10930\n- Fix nemo 2.0 recipes  by @BoxiangW :: PR: #10915\n- Akoumparouli/nemo ux fix dir or string artifact by @akoumpa :: PR: #10936\n- Fix typo in docstring by @ashors1 :: PR: #10955\n- [Nemo CICD] Remove deprecated tests by @pablo-garay :: PR: #10960\n- Restore NeMo 2.0 T5 pretraining CICD test by @huvunvidia :: PR: #10952\n- Convert perf plugin env vars to strings by @hemildesai :: PR: #10947\n- disable dynamo for ddp checker by @akoumpa :: PR: #10961\n- Bump `Dockerfile.ci` (2024-10-21) by @ko3n1g :: PR: #10965\n- respect warnings' filters by @akoumpa :: PR: #10953\n- Alit/mamba recipe by @JRD971000 :: PR: #10935\n- Long context performance doc hot fix by @youngeunkwon0405 :: PR: #10946\n- Performance mode by @malay-nagda :: PR: #10926\n- Bump `Dockerfile.ci` (2024-10-22) by @ko3n1g :: PR: #10979\n- Add more recipes by @cuichenx :: PR: #10957\n- ci: Update tests by @ko3n1g :: PR: #10987\n- Bump `Dockerfile.ci` (2024-10-23) by @ko3n1g :: PR: #11001\n- llm.generate fixes by @HuiyingLi :: PR: #10983\n- use __dict__ in check by @akoumpa :: PR: #11012\n- LoRA support for HF::AutoModelForCausalLM by @akoumpa :: PR: #10982\n- Change default for always_save_context to True by @athitten :: PR: #11014\n- Fix pip install by @marcromeyn :: PR: #11026\n- Change dist ckpt defaults by @ShriyaPalsamudram :: PR: #10913\n- Fix _strategy_lib tests by @maanug-nv :: PR: #11033\n- Basic online dynamic FP8 quantization with vLLM by @janekl :: PR: #10904\n- Expose packed seq in finetuning recipes by @cuichenx :: PR: #11006\n- PEFT Inference by @cuichenx :: PR: #11030\n- added Lhotse online augmentation tutorial for SE by @nasretdinovr :: PR: #10944\n- Bump `Dockerfile.ci` (2024-10-27) by @ko3n1g :: PR: #11051\n- ci: Send team alerts on specific keywords by @ko3n1g :: PR: #10986\n- Qwen2 Recipe by @suiyoubi :: PR: #10974\n- Bump `Dockerfile.ci` (2024-10-28) by @ko3n1g :: PR: #11054\n- Generalizing Inference pipeline in NeMo 2.0 to support encoder-decoder models by @huvunvidia :: PR: #10924\n- [Bug fix] In energon MultiModalSampleConfig use default_factory in dataclass by @guyueh1 :: PR: #11041\n- fix: Resolve mutable default issue in MultiModalSampleConfig dataclass by @michal2409 :: PR: #11061\n- SC1/SC2 Recipe by @suiyoubi :: PR: #10971\n- Wrap batch_sampler with _IndexBatchSamplerWrapper by @farhadrgh :: PR: #10934\n- Performance fine-tuning recipes for llama3 8b + 70b by @vysarge :: PR: #11046\n- Set TE spec name for NeMo to HF checkpoint converters by @kevalmorabia97 :: PR: #11036\n- ci: Re-add secrets detector by @ko3n1g :: PR: #11038\n- Adding nemo-run recipes for NeMo 2.0 T5  by @huvunvidia :: PR: #10964\n- Minor fixes for NeMo 2.0 PTQ by @Laplasjan107 :: PR: #11079\n- Add copyright check by @pablo-garay :: PR: #11048\n- Fix finalize model grad for PEFT by @cuichenx :: PR: #11065\n- ci: Less verbose infra alerts by @ko3n1g :: PR: #11080\n- Add copyright notice by @pablo-garay :: PR: #11085\n- ci: Fix cron schedule  by @ko3n1g :: PR: #11076\n- ci: Use code-freeze via Nemo-FW-Templates by @ko3n1g :: PR: #11073\n- Akoumparouli/hf lit module peft ckpt bugfix by @akoumpa :: PR: #11022\n- PEFT perf and TE spec fixes by @JimmyZhang12 :: PR: #11070\n- Bump `Dockerfile.ci` (2024-10-30) by @ko3n1g :: PR: #11092\n- NeMorun for NeMo 2.0 T5 finetuning by @huvunvidia :: PR: #11040\n- fix model_checkpoint.py by @ethanhe42 :: PR: #11057\n- Update PTQ tests and ModelOpt version by @janekl :: PR: #11095\n- Fix datasets in CLI by @marcromeyn :: PR: #11097\n- Fix yaml serialization in io mixin by @hemildesai :: PR: #11106\n- disable overlap_param_gather_with_optimizer_step by @JimmyZhang12 :: PR: #11102\n- nemo1 to nemo2 checkpoint convert by @HuiyingLi :: PR: #10937\n- fix expert regex filter by @akoumpa :: PR: #11103\n- Remove stale checkpoint deletion on checkpoint saving failure by @akoumpa :: PR: #11116\n- NeMo-UX: Mistral/mixtral peft ci test by @akoumpa :: PR: #11094\n- Make nemo.collections.llm PreTrainingDataModule num samples configurable by @hemildesai :: PR: #11088\n- Fix packed seq path by @cuichenx :: PR: #11121\n- Allow arguments passed to dataset class + Gemma recipe fix by @cuichenx :: PR: #11125\n- Nemotron Recipe by @suiyoubi :: PR: #11118\n- NeMo-UX: HF PeFT fix by @akoumpa :: PR: #11096\n- Remove deprecated tests by @pablo-garay :: PR: #11134\n- Recipe Fix for NeMo CI by @suiyoubi :: PR: #11127\n- Fix freeze_model call in peft by @cuichenx :: PR: #11146\n- Bump `Dockerfile.ci` (2024-11-05) by @ko3n1g :: PR: #11159\n- NeMo-UX: Add sgd optim by @akoumpa :: PR: #11157\n- Update copyright check by @pablo-garay :: PR: #11168\n- add lora recipt for 405b by @JRD971000 :: PR: #10991\n- dit training diagrams by @zpx01 :: PR: #10873\n- ci: Switch to FW templates for build by @ko3n1g :: PR: #11077\n- Bump `Dockerfile.ci` (2024-11-06) by @ko3n1g :: PR: #11174\n- feat: Run PyLint by @ko3n1g :: PR: #11147\n- Add Alpaca Finetune Datamodule by @suiyoubi :: PR: #11185\n- Updated Diffusion Collection README by @zpx01 :: PR: #11179\n- Add support for Cosmos Tokenizers by @jojennin :: PR: #11194\n- Run formatting only if files changed. Echo message if pylint fails. by @artbataev :: PR: #11188\n- Bump `Dockerfile.ci` (2024-11-07) by @ko3n1g :: PR: #11196\n- Fix rotary_percentage parsing in nemo2 config by @meatybobby :: PR: #11197\n- ci: Update cherry pick workflow by @ko3n1g :: PR: #11202\n- ci: Build, test, publish a wheel by @ko3n1g :: PR: #11183\n- Bump `Dockerfile.ci` (2024-11-08) by @ko3n1g :: PR: #11222\n- update default pipeline_parallelism_type by @akoumpa :: PR: #11213\n- check actual value of vocab_file by @akoumpa :: PR: #11228\n- Fix VP Initialization Issue with Latest MCore by @suiyoubi :: PR: #11209\n- ci: Run Pylint strictly on new files, softly on history by @ko3n1g :: PR: #11212\n- ci: Add release workflow by @ko3n1g :: PR: #11180\n- Fix llm.generate by @hemildesai :: PR: #11217\n- Bump `Dockerfile.ci` (2024-11-11) by @ko3n1g :: PR: #11247\n- Bump `Dockerfile.ci` (2024-11-12) by @ko3n1g :: PR: #11254\n- Handling tokenizer in PTQ for Nemo 2.0 by @janekl :: PR: #11237\n- Fix finetuning datamodule resume by @cuichenx :: PR: #11187\n- ci: Move `bump mcore` to templates by @ko3n1g :: PR: #11229\n- ci: Fix secrets detector by @ko3n1g :: PR: #11205\n- chore(beep boop 🤖): Bump `MCORE_TAG=aded519...` (2024-11-12) by @ko3n1g :: PR: #11260\n- ci: Run secrets detector on `pull_request_target` by @ko3n1g :: PR: #11263\n- Advanced Diffusion Training Features by @zpx01 :: PR: #11246\n- Update pruning and distillation tutorial notebooks by @gvenkatakris :: PR: #11091\n- update nemo1->2 conversion according to changes in main by @HuiyingLi :: PR: #11253\n- Add llama 3.1 recipes by @cuichenx :: PR: #11273\n- Fix Finetune Recipe by @suiyoubi :: PR: #11267\n- Configure no restart validation loop in nl.Trainer by @hemildesai :: PR: #11029\n- Handle _io_unflatten_object when _thread_local.output_dir is not available by @hemildesai :: PR: #11199\n- Remove opencc upperbound by @thomasdhc :: PR: #10909\n- Fix head_size in NeMo to HF checkpoint converters for width pruned model support by @eagle705 :: PR: #11230\n- Fixes per comments by @gvenkatakris :: PR: #11280\n- Create phi3mini.py by @mayani-nv :: PR: #11281\n- ci: Fix release workflow by @ko3n1g :: PR: #11286\n- fix perf plugin CUDA_DEVICE_MAX_CONNECTIONS setting by @JimmyZhang12 :: PR: #11299\n- PTQ via NeMo-Run CLI by @janekl :: PR: #10984\n- PTQ memory optimization by @Laplasjan107 :: PR: #11257\n- Update README.md for collection page by @yaoyu-33 :: PR: #11223\n- Adding multimodal examples by @shanmugamr1992 :: PR: #11279\n- Add HF untrusted code toggle by @akoumpa :: PR: #11313\n- P2p chunk size setting in nemo 2.0 by @erhoo82 :: PR: #11312\n- Nemo2 batcheval by @HuiyingLi :: PR: #11158\n- DoRA by @cuichenx :: PR: #11104\n- Profiling - support Chakra & Kineto trace dumping by @lilyw97 :: PR: #11115\n- NeMo 2.0 SFT PEFT notebooks by @HuiyingLi :: PR: #10874\n- Update symlink option for save_last in ModelCheckpoint by @paul-gibbons :: PR: #11319\n- ci: Pass-through of `workflow_event` by @ko3n1g :: PR: #11322\n- Add StragglerDetection and auto-relaunch to NeMo2.0 by @ShriyaPalsamudram :: PR: #11328\n- Huvu/t5 nemo2.0 nemoci by @huvunvidia :: PR: #11291\n- TE acceleration using callbacks by @oyilmaz-nvidia :: PR: #11261\n- Leave target_module as default in PEFT Recipes by @cuichenx :: PR: #11334\n- More robust tar file loading from AIStore by @pzelasko :: PR: #11323\n- Fix CLIP transformer layer api by @yaoyu-33 :: PR: #11337\n- pass trust_remote_code to AutoTokenizer by @akoumpa :: PR: #11343\n- Fix linear layer replacement by @oyilmaz-nvidia :: PR: #11356\n- fix typo by @JRD971000 :: PR: #11351\n- Add torchrun local executor to recipes by @marcromeyn :: PR: #11342\n- Add PP support in NeVA along with few bug fixes by @yaoyu-33 :: PR: #11170\n- nemo2 peft merge by @HuiyingLi :: PR: #11017\n- Add dora recipes by @cuichenx :: PR: #11330\n- add fix to recipe by @JRD971000 :: PR: #11368\n- Add missing test to CICD needed list by @pablo-garay :: PR: #11376\n- update SquadDataModule to use run.config by @huvunvidia :: PR: #11358\n- Add llama 3.2 1b and 3b by @cuichenx :: PR: #11335\n- calculate metrics for nemo2 sftpeft notebook by @HuiyingLi :: PR: #11381\n- Enable packed dataset for validation; add a2a_experimental argument by @michal2409 :: PR: #11378\n- Fix DDP unused param error when TE is enabled in NeMo Lite by @oyilmaz-nvidia :: PR: #11364\n- Update llama32 vision (mllama) use attention bias by @yaoyu-33 :: PR: #11316\n- Fix environment variables in torchrun executor by @hemildesai :: PR: #11363\n- Add sample generate to PTQ for NeMo 2.0 by @Laplasjan107 :: PR: #11339\n- Fix selective restore by explicitly verifying keys by @hemildesai :: PR: #11377\n- Minor fix by @gvenkatakris :: PR: #11353\n- Add a fix for single-GPU nsys. by @tfogal :: PR: #11354\n- capitalize HF as HF instead of Hf by @akoumpa :: PR: #11384\n- ci: Add HF cache by @ko3n1g :: PR: #11398\n- Remove logic to skip checkpoint save if checkpoint exists by @ashors1 :: PR: #11362\n- Rewire tokenizer exception handling in model resume by @cuichenx :: PR: #11375\n- Adding LLava-Next model class by @yashaswikarnati :: PR: #11399\n- Fix vllm test issue when run_accuracy is enabled by @oyilmaz-nvidia :: PR: #11413\n- data modules for llava_next by @yashaswikarnati :: PR: #11400\n- Fix strategies saving unsharded optimizer states by @ananthsub :: PR: #11392\n- Adjust CLI support for PTQ by @janekl :: PR: #11421\n- Nemo run recipe's and example scripts for Llava Next by @yashaswikarnati :: PR: #11405\n- Huvu/t5 nemo2.0 nemoci 3b11b by @huvunvidia :: PR: #11388\n- ci: Allow dry-run of release by @ko3n1g :: PR: #11418\n- fix dtype when init HF model from config by @akoumpa :: PR: #11420\n- Handle import errors in virtual environment when running vLLM tests by @janekl :: PR: #11435\n- Fix loss mask when answer_only_loss=True by @ashors1 :: PR: #11444\n- [audio] Keep input directory structure when saving processed files by @anteju :: PR: #11403\n- Add different recipe examples to NeMo 2.0 by @BoxiangW :: PR: #11317\n- [Scripts] Remove fixed seed for adding noise by @anteju :: PR: #11401\n- Add option to provide prior NeMo 2 ckpt path to convert_nemo1_to_nemo… by @hemildesai :: PR: #11452\n- PTQ CLI and param updates by @janekl :: PR: #11459\n- Add tests for resiliency feature integration by @maanug-nv :: PR: #11406\n- ci: Disable HexHighEntropyString plugin by @ko3n1g :: PR: #11470\n- Fix broken links by @shashank3959 :: PR: #11294\n- Nemo 2.0 canonical lora by @cuichenx :: PR: #11416\n- ci: Run secrets detector on merge-commit by @ko3n1g :: PR: #11479\n- Formatting (minor) by @pablo-garay :: PR: #11485\n- Fix bug related to naming by @pablo-garay :: PR: #11487\n- Add BERT Model To NeMo2.0 by @suiyoubi :: PR: #11333\n- Update Nemo Distributed Checkpoint User Guide by @FortunaZhang :: PR: #11489\n- fix: regular torch optims (e.g., sgd) no longer error with closure spec by @terrykong :: PR: #11189\n- Add recipe configs validating by @BoxiangW :: PR: #10954\n- Fix finetuning PP by @cuichenx :: PR: #11474\n- [docs] Documentation for audio collection by @anteju :: PR: #11426\n- config hierarchy by @malay-nagda :: PR: #11145\n- Force param sync when using distributed optimizer and overlap_param_gather by @hemildesai :: PR: #11486\n- chore(beep boop 🤖): Bump `MCORE_TAG=bd677bf...` (2024-12-06) by @ko3n1g :: PR: #11492\n- Remove default mutable arguments from AbstractEmbModel constructor by @ananthsub :: PR: #11348\n- minor fix for nemo2 sftpeft readme by @HuiyingLi :: PR: #11502\n- Update Llama3 Fine-Tuning Notebook by @roclark :: PR: #11522\n- Fix CI issue on validation config by @BoxiangW :: PR: #11521\n- Freeze tags in in `r2.1.0` by @github-actions[bot] :: PR: #11556\n- Cherrypick all + R2.1.0 fix cicd  by @pablo-garay :: PR: #11622\n- Cherry pick `Add fix docstring for speech commands (11638)` into `r2.1.0` by @ko3n1g :: PR: #11639\n- Cherrypick #11628 to r2.1.0 by @nasretdinovr :: PR: #11630\n- Update package_info.py by @ko3n1g :: PR: #11646\n- Cherry pick `Add fix docstring for VAD (11659)` into `r2.1.0` by @ko3n1g :: PR: #11660\n- Fix tokenizer trust_remote_code by @cuichenx :: PR: #11657\n- Cherrypick 11568 by @cuichenx :: PR: #11656\n- Cherry pick `Downgrading the 'datasets' package from 3.0.0 to 2.21.0 for Multilang_ASR.ipynb and ASR_CTC_Language_Finetuning.ipynb (11675)` into `r2.1.0` by @ko3n1g :: PR: #11677\n- r2.1.0 cherrypick by @pablo-garay :: PR: #11680\n- Cherry pick `Rename multimodal data module - EnergonMultiModalDataModule (11654)` into `r2.1.0` by @ko3n1g :: PR: #11685\n- chore: Bump to `r2.1.0rc2` by @ko3n1g :: PR: #11693\n- r2.1.0 ptl fix by @pablo-garay :: PR: #11694\n\n</details>\n\n## NVIDIA Neural Modules 2.1.0rc2\n\nPrerelease: NVIDIA Neural Modules 2.1.0rc2 (2024-12-21)\n\n## NVIDIA Neural Modules 2.1.0rc1\n\nPrerelease: NVIDIA Neural Modules 2.1.0rc1 (2024-12-20)\n\n## NVIDIA Neural Modules 2.1.0rc0\n\nPrerelease: NVIDIA Neural Modules 2.1.0rc0 (2024-12-12)\n\n## NVIDIA Neural Modules 2.0.0rc1\n\n### Highlights\n\n#### Large language models\n\n- PEFT: QLoRA support, LoRA/QLora for Mixture-of-Experts (MoE) dense layer\n- State Space Models & Hybrid Architecture support (Mamba2 and NV-Mamba2-hybrid)\n- Support Nemotron, Minitron, Gemma2, Qwen, RAG\n- Custom Tokenizer training in NeMo\n- Update the Auto-Configurator for EP, CP and FSDP\n\n#### Multimodal\n\n- NeVA: Add SOTA LLM backbone support (Mixtral/LLaMA3) and suite of model parallelism support (PP/EP)\n- Support Language Instructed Temporal-Localization Assistant (LITA) on top of video NeVA\n\n#### ASR\n\n- SpeechLM and SALM\n- Adapters for Canary Customization\n- Pytorch allocator in PyTorch 2.2 improves training speed up to 30% for all ASR models\n- Cuda Graphs for Transducer Inference\n- Replaced webdataset with Lhotse - gives up to 2x speedup\n- Transcription Improvements - Speedup and QoL Changes\n- ASR Prompt Formatter for multimodal Canary\n\n#### Export & Deploy\n\n- In framework PyTriton deployment with backends: - PyTorch - vLLM - TRT-LLM update to 0.10\n- TRT-LLM C++ runtime\n\n### Detailed Changelogs\n\n#### ASR\n\n<details><summary>Changelog</summary>\n\n- Support dataloader as input to `audio` for transcription by @titu1994 :: PR: #9201  \n- Clean up dev docs collection section by @yaoyu-33 :: PR: #9205  \n- Fix Online_Offline_Microphone_VAD_Demo.ipynb by @stevehuang52 :: PR: #9251  \n- Remove .nemo instead of renaming by @mikolajblaz :: PR: #9281  \n- Fix GreedyBatchedCTCInfer regression from GreedyCTCInfer. by @galv :: PR: #9347\n- Revert \"Fix GreedyBatchedCTCInfer regression from GreedyCTCInfer.\" by @titu1994 :: PR: #9351\n- Prompt formatter API and canary transcribe tensor input support by @pzelasko :: PR: #9206\n- Fix prompt formatter's defaults=None case in multi-task model by @pzelasko :: PR: #9366\n- move AED chunked infer script by @stevehuang52 :: PR: #9367\n- Use model-cast-to-bfloat16 rather than AMP-to-bfloat16 for inference. by @galv :: PR: #9198\n- ci: Fix `L2_Segmentation_Tool_Parallel_ctc_segmentation_test_L2_Eng_C… by @ko3n1g :: PR: #9399\n- Fix logging message for ASR by @titu1994 :: PR: #9469\n- Add support to change Multi task model prompt by @titu1994 :: PR: #9542\n- Enable encoder adapters for Canary and MultiTaskAED models by @titu1994 :: PR: #9409\n- Audio model collection by @anteju :: PR: #9263\n- TitaNet Batch Verify Speaker by @monica-sekoyan :: PR: #9337\n- Fix the arguments  of forward_for_export function in msdd_models by @tango4j :: PR: #9624\n- chore: Pin branch in notebooks by @ko3n1g :: PR: #9697\n- refactor: notebook branch release by @ko3n1g :: PR: #9711\n- Canary Adapters tutorial (#9670) by @nithinraok :: PR: #9777\n- typos and branch name update to r2.0.0rc1 by @nithinraok :: PR: #9846\n- Fix RNNT alignments test by @artbataev :: PR: #9770\n- By default trust remote code from HF Datasets by @nithinraok :: PR: #9886\n- Temporarily disable cuda graph based RNN-T greedy inference for r2.0.0rc1 by @galv :: PR: #9904\n- Enable CUDA graphs by default, but require CUDA 12.6 for full graphs by @artbataev :: PR: #9919\n- update branch name for script by @nithinraok :: PR: #9936\n- updte branch by @nithinraok :: PR: #9942\n</details>\n\n#### TTS\n\n<details><summary>Changelog</summary>\n\n- Clean up dev docs collection section by @yaoyu-33 :: PR: #9205\n- Add mel codec checkpoints by @anteju :: PR: #9228\n- GPU unit tests: Mark flaky tests to be fixed by @pablo-garay :: PR: #9559\n- chore: Pin branch in notebooks by @ko3n1g :: PR: #9697\n- refactor: notebook branch release by @ko3n1g :: PR: #9711\n\n</details>\n\n#### LLM/Multimodal\n  \n<details><summary>Changelog</summary>\n\n- Update nemo.export module for quantized models by @janekl :: PR: #9218\n- Add save option to the TRT-LLM export test script by @oyilmaz-nvidia :: PR: #9221\n- Checkpoint resuming compatible for 2403 container by @suiyoubi :: PR: #9199\n- Clean up dev docs collection section by @yaoyu-33 :: PR: #9205\n- use get with fallback when reading checkpoint_callback_params by @akoumpa :: PR: #9223\n- Revert rope fusion defaults by @cuichenx :: PR: #9237\n- fix import by @akoumpa :: PR: #9240\n- Add TRT-LLM params like max_num_tokens and opt_num_tokens by @oyilmaz-nvidia :: PR: #9210\n- sum-reduce grad_norm in DP+CP domain by @erhoo82 :: PR: #9262\n- Alit/bert convert fix by @JRD971000 :: PR: #9285\n- conv1d stable version by @JRD971000 :: PR: #9330\n- Fix trainer builder when exp_manager is not in config by @yaoyu-33 :: PR: #9293\n- Fix Peft Weights Loading in NeVA by @yaoyu-33 :: PR: #9341\n- Skip sequence_parallel allreduce when using Mcore DistOpt by @akoumpa :: PR: #9344\n- Fix FSDP gradient calculation with orig params by @janEbert :: PR: #9335\n- TRT-LLM Export Code Cleanup by @oyilmaz-nvidia :: PR: #9270\n- support null/None truncation field by @arendu :: PR: #9355\n- NeVa token fusion by @paul-gibbons :: PR: #9245\n- bugfix if using mcore distOpt with sft by @akoumpa :: PR: #9356\n- Re-org export code by @oyilmaz-nvidia :: PR: #9353\n- QLoRA by @cuichenx :: PR: #9340\n- PeFT fix for distOpt by @akoumpa :: PR: #9392\n- [NeMo-UX] Integrating mcore's DistributedDataParallel into MegatronStrategy by @marcromeyn :: PR: #9387\n- cherry pick of #9266 by @dimapihtar :: PR: #9411\n- Enable specifying alpha for PTQ INT8 SmoothQuant method by @janekl :: PR: #9423\n- add support for new mcore ds features by @dimapihtar :: PR: #9388\n- LoRA for MoE Layer by @cuichenx :: PR: #9396\n- Mistral-7B: apply user's precision to output checkpoint by @akoumpa :: PR: #9222\n- Add option to merge distributed optimizer buckets by @timmoon10 :: PR: #9414\n- TRT-LLM 0.10 Update by @oyilmaz-nvidia :: PR: #9402\n- In-framework deployment by @oyilmaz-nvidia :: PR: #9438\n- Bugfix missing variables and argument changes to MegatronPretrainingRandomSampler by @jstjohn :: PR: #9458\n- Hyena Operator by @guyjacob :: PR: #9264\n- Refactor Quantizer for reusing in QAT by @kevalmorabia97 :: PR: #9276\n- move load state dict after initialize parallel state in nlp_model by @ryxli :: PR: #9382\n- Enable user to optionally upgrade Megatron by @jstjohn :: PR: #9478\n- Fix unwrap model by @cuichenx :: PR: #9480\n- fix operator precedence by @akoumpa :: PR: #9403\n- [NeMo-UX] Adding context- & expert-parallelism to MegatronStrategy by @marcromeyn :: PR: #9525\n- update mcoreddp call by @akoumpa :: PR: #9345\n- mcore distOpt restore fix by @akoumpa :: PR: #9421\n- vLLM Export Support by @apanteleev :: PR: #9381\n- PL: Delete precision if using plugin. TODO switch to MegatronTrainerB… by @akoumpa :: PR: #9535\n- extend get_gpt_layer_modelopt_spec to support MoE by @akoumpa :: PR: #9532\n- fix mock data generation for legacy dataset by @dimapihtar :: PR: #9530\n- add reset learning rate functionality by @dimapihtar :: PR: #9372\n- Use closed-formula to round by multiple by @akoumpa :: PR: #9307\n- GPU unit tests: Mark flaky tests to be fixed by @pablo-garay :: PR: #9559\n- Consolidate gpt continue training script into pretraining script by @yaoyu-33 :: PR: #9413\n- Enable encoder adapters for Canary and MultiTaskAED models by @titu1994 :: PR: #9409\n- PTQ refinements by @janekl :: PR: #9574\n- Add ModelOpt QAT example for Llama2 SFT model by @kevalmorabia97 :: PR: #9326\n- Multimodal projection layer adapter fix for PP>1 by @paul-gibbons :: PR: #9445\n- Add offline quantization script for QLoRA deployment by @cuichenx :: PR: #9455\n- Make QLoRA more model-agnostic by @cuichenx :: PR: #9488\n- Set n_gpu to None in nemo export by @oyilmaz-nvidia :: PR: #9593\n- [NeMo-UX] Fix Megatron-optimizer by @marcromeyn :: PR: #9599\n- Chat template support for megatron_gpt_eval.py by @akoumpa :: PR: #9354\n- [NeMo-UX] Add PEFT by @cuichenx :: PR: #9490\n- Alit/mamba tmp by @JRD971000 :: PR: #9612\n- Enable MCore checkpointing optimizations by @mikolajblaz :: PR: #9505\n- Change mixtral moe key name for trt-llm by @oyilmaz-nvidia :: PR: #9620\n- fix ckpt load bug by @dimapihtar :: PR: #9621\n- Alit/mamba by @JRD971000 :: PR: #9575\n- Unwrap ckpt_io for model opt (async save) by @mikolajblaz :: PR: #9622\n- MCore T5 support for NeMo - Training by @huvunvidia :: PR: #9432\n- [Nemo-UX] Expose transformer_layer_spec inside GPTConfig by @marcromeyn :: PR: #9592\n- Update NeMo Clip to Use MCore Modules by @yaoyu-33 :: PR: #9594\n- Mistral + Mixtral Support for NeVa by @paul-gibbons :: PR: #9459\n- Adding support for mcore generate by @shanmugamr1992 :: PR: #9566\n- Improve error messaging during trt-llm export by @oyilmaz-nvidia :: PR: #9638\n- [Cherrypick] support lora when kv_channel != hidden_size / num_heads by @cuichenx :: PR: #9644\n- Parametrize FPS group by @mikolajblaz :: PR: #9648\n- Cherry-pick megatron export fix from main by @borisfom :: PR: #9643\n- add documentation for reset_lr feature by @dimapihta\n- chore: Pin branch in notebooks by @ko3n1g :: PR: #9697\n- Cherry pick: LITA Integration by @Slyne :: PR: #9684\n- SDXL improvements (and support for Draft+) by @rohitrango :: PR: #9654\n- Gemma 2 by @cuichenx :: PR: #9672\n- Allows non-strict load with distributed checkpoints by @mikolajblaz :: PR: #9613\n- refactor: notebook branch release by @ko3n1g :: PR: #9711\n- [NeMo-UX] Make TE and Apex dependencies optional by @ashors1 :: PR: #9550\n- Alit/r2.0.0 by @JRD971000 :: PR: #9718\n- Manually cherry-pick from PR 9679 (PR to main - Support SFT/Eval/PEFT for mcore T5) by @huvunvidia :: PR: #9737\n- In framework export by @oyilmaz-nvidia :: PR: #9658\n- T5 changes based on mcore changes by @pablo-garay :: PR: #9829\n- [NeMo-UX] Use single instance of loss reductions in GPTModel by @hemildesai :: PR: #9801\n- deprecate NeMo NLP tutorial by @dimapihtar :: PR: #9864\n- Disable nvFuser setup with PyTorch 23.11 and later by @athitten :: PR: #9837\n- make torch_dist ckpt strategy as default by @dimapihtar :: PR: #9852\n- add rampup bs documentation by @dimapihtar :: PR: #9884\n- copy of #9576 by @dimapihtar :: PR: #9986\n- Support Nvidia Torch and Arch versions by @thomasdhc :: PR: #9897\n- Bug fix for pooler causing dist checkpointing exception by @shanmugamr1992 :: PR: #10008\n\n</details>\n\n#### Export\n\n<details><summary>Changelog</summary>\n\n- Update nemo.export module for quantized models by @janekl :: PR: #9218\n- Add save option to the TRT-LLM export test script by @oyilmaz-nvidia :: PR: #9221\n- Add TRT-LLM params like max_num_tokens and opt_num_tokens by @oyilmaz-nvidia :: PR: #9210\n- TRT-LLM Export Code Cleanup by @oyilmaz-nvidia :: PR: #9270\n- Re-org export code by @oyilmaz-nvidia :: PR: #9353\n- Use TensorRT-LLM native parameter names in nemo.export module by @janekl :: PR: #9424\n- TRT-LLM 0.10 Update by @oyilmaz-nvidia :: PR: #9402\n- vLLM Export Support by @apanteleev :: PR: #9381\n- Add page context fmha option in TensorRTLLM export by @meatybobby :: PR: #9526\n- Test C++ runtime on demand in nemo_export.py to avoid possible OOMs by @janekl :: PR: #9544\n- Fix nemo export test by @oyilmaz-nvidia :: PR: #9547\n- Add tps and pps params to the export script by @oyilmaz-nvidia :: PR: #9558\n- Add Multimodal Exporter by @meatybobby :: PR: #9256\n- Set n_gpu to None in nemo export by @oyilmaz-nvidia :: PR: #9593\n- Inflight nemo model export support by @JimmyZhang12 :: PR: #9527\n- vLLM Export Improvements by @apanteleev :: PR: #9596\n- Akoumparouli/nemo ux mixtral export by @akoumpa :: PR: #9603\n- Change mixtral moe key name for trt-llm by @oyilmaz-nvidia :: PR: #9620\n- Fix the arguments  of forward_for_export function in msdd_models by @tango4j :: PR: #9624\n- Improve error messaging during trt-llm export by @oyilmaz-nvidia :: PR: #9638\n- Cherry-pick megatron export fix from main by @borisfom :: PR: #9643\n- In framework export by @oyilmaz-nvidia :: PR: #9658\n- Add missing imports for torch dist ckpt in export by @oyilmaz-nvidia :: PR: #9826~\n\n</details>\n\n\n\n\n#### Bugfixes\n  \n<details><summary>Changelog</summary>\n\n- use get with fallback when reading checkpoint_callback_params by @akoumpa :: PR: #9223\n- fix import by @akoumpa :: PR: #9240\n- Remove .nemo instead of renaming by @mikolajblaz :: PR: #9281\n- call set_expert_model_parallel_world_size instead of set_cpu_expert_m… by @akoumpa :: PR: #9275\n- Fix typos in Mixtral NeMo->HF and Starcoder2 NeMo->HF conversion scripts by @evellasques :: PR: #9325\n- Skip sequence_parallel allreduce when using Mcore DistOpt by @akoumpa :: PR: #9344\n- Add OpenAI format response to r2.0.0rc1 by @athitten :: PR: #9796\n- [NeMo UX] Support generating datasets using different train/valid/test distributions by @ashors1 :: PR: #9771\n- Add missing imports for torch dist ckpt in export by @oyilmaz-nvidia :: PR: #9826\n\n</details>\n\n#### General Improvements\n\n<details><summary>Changelog</summary>\n\n- [Nemo CICD] run_cicd_for_release_branches_also by @pablo-garay :: PR: #9213\n- rename paths2audiofiles to audio by @github-actions[bot] :: PR: #9220\n- Fix ASR_Context_Biasing.ipynb contains FileNotFoundError by @github-actions[bot] :: PR: #9234\n- ci: Remove duplicated job by @ko3n1g :: PR: #9258\n- Fix document links by @yaoyu-33 :: PR: #9260\n- Pin transformers by @github-actions[bot] :: PR: #9273\n- Fix loading github raw images on notebook by @github-actions[bot] :: PR: #9283\n- Accept None as an argument to decoder_lengths in GreedyBatchedCTCInfer::forward by @github-actions[bot] :: PR: #9278\n- Refactor Sequence Packing Script by @cuichenx :: PR: #9271\n- [Nemo-UX] Move code to collections + fix some small bugs by @marcromeyn :: PR: #9277\n- Fix typo in HF tutorial by @github-actions[bot] :: PR: #9304\n- Expand documentation for data parallelism and distributed optimizer by @timmoon10 :: PR: #9227\n- Install alerting by @ko3n1g :: PR: #9311\n- typos by @github-actions[bot] :: PR: #9315\n- FP8 feature documentation by @ksivaman :: PR: #9265\n- [Nemo CICD] Comment out flaky tests by @pablo-garay :: PR: #9333\n- Fixed typos in README.rst by @gdevakumar :: PR: #9322\n- Update README.rst to clarify installation via Conda by @SimonCW :: PR: #9323\n- [Nemo CICD] update flaky test by @pablo-garay :: PR: #9339\n- fix lora and ptuning and isort/black by @github-actions[bot] :: PR: #9295\n- Fix P-tuning for Llama based models by @github-actions[bot] :: PR: #9300\n- add large model stable training fix and contrastive loss update for variable seq by @github-actions[bot] :: PR: #9348\n- Guard cuda memory allocator update by @github-actions[bot] :: PR: #9313\n- [Nemo CICD] Remove unnecessary commented out code by @pablo-garay :: PR: #9364\n- Update Gemma conversion script by @yaoyu-33 :: PR: #9365\n- Fix GreedyBatchedCTCInfer regression from GreedyCTCInfer. (#9347) by @github-actions[bot] :: PR: #9371\n- Re-enable cuda graphs in training modes. by @github-actions[bot] :: PR: #9343\n- fix typo infer_seq_lenght -> infer_seq_length by @akoumpa :: PR: #9370\n- Make a backward compatibility for old MSDD configs in label models by @github-actions[bot] :: PR: #9378\n- Dgalvez/fix greedy batch strategy name r2.0.0rc0 by @github-actions[bot] :: PR: #9253\n- Update README.rst by @jgerh :: PR: #9393\n- Force diarizer to use CUDA if cuda is available and if device=None. by @github-actions[bot] :: PR: #9390\n- ci: Properly catch failed tests by introduction of workflow templates by @ko3n1g :: PR: #9324\n- Fix T5 G2P Input and Output Types by @github-actions[bot] :: PR: #9269\n- Huvu/rag pipeline citest by @huvunvidia :: PR: #9384\n- Fix circular import for MM dataprep notebook by @github-actions[bot] :: PR: #9292\n- add check if num layers is divisible by pp size by @github-actions[bot] :: PR: #9298\n- [Nemo CICD] timeouts fix by @pablo-garay :: PR: #9407\n- [NeMo-UX] Removing un-used ModelConfig class by @marcromeyn :: PR: #9389\n- Add tutorial for Llama-3-8B lora training and deployment by @shashank3959 :: PR: #9359\n- [NeMo-UX] Removing default_path from ModelConnector by @marcromeyn :: PR: #9401\n- Fix README by @ericharper :: PR: #9415\n- [SD] Fix SD CUDA Graph Failure by @alpha0422 :: PR: #9319\n- [NeMo-UX] Adding file-lock to Connector by @marcromeyn :: PR: #9400\n- Add Dev Container Bug Report by @pablo-garay :: PR: #9430\n- Akoumparouli/profiling docs by @akoumpa :: PR: #9420\n- ci: Enrich notifications by @ko3n1g :: PR: #9412\n- Fix failing RIR unit test with lhotse 1.24+ by @pzelasko :: PR: #9444\n- [NeMo-UX] Adding support for mcore distributed optimizer by @marcromeyn :: PR: #9435\n- Use ModelOpt build_tensorrt_llm for building engines for qnemo checkpoints by @janekl :: PR: #9452\n- ci(notifications): Fix extraction of last 2K chars by @ko3n1g :: PR: #9450\n- Update readme with mlperf news by @ericharper :: PR: #9457\n- [NeMo-UX] Add nsys callback by @ashors1 :: PR: #9461\n- [NeMo UX] Introducing optimizer module by @marcromeyn :: PR: #9454\n- Fix minor import bug in deploy module by @oyilmaz-nvidia :: PR: #9463\n- ci(notifications): Fetch all jobs by @ko3n1g :: PR: #9465\n- Update build_dataset.py by @stevehuang52 :: PR: #9467\n- bionemo: bn2/add pipelineparallel dtype by @skothenhill-nv :: PR: #9475\n- [NeMo-UX] Integrate experiment manager features with NeMo-UX APIs by @ashors1 :: PR: #9460\n- Add python_requires by @galv :: PR: #9431\n- [NeMo-UX] Fixing imports of NeMoLogging, AutoResume & ModelCheckpoint by @marcromeyn :: PR: #9476\n- Modelopt Refactor for SDXL Quantization by @suiyoubi :: PR: #9279\n- [NeMo-UX] Fixing defaults in llm.train & Mistral7BModel by @marcromeyn :: PR: #9486\n- In framework deploy using deploy script by @oyilmaz-nvidia :: PR: #9468\n- [NeMo-UX] Integrate tokenizer import into model.import_ckpt by @marcromeyn :: PR: #9485\n- append to file by @malay-nagda :: PR: #9483\n- [NeMo-UX] Fix bug in import_ckpt by @marcromeyn :: PR: #9492\n- Add nemotron news by @ericharper :: PR: #9510\n- Add CICD test for Stable Diffusion by @michal2409 :: PR: #9464\n- Akoumparouli/nemo ux mixtral by @akoumpa :: PR: #9446\n- [NeMo-UX] Llama and Gemma by @cuichenx :: PR: #9528\n- [NeMo-UX] minor logging bug fixes by @ashors1 :: PR: #9529\n- Update neva conversion script from and to HF by @yaoyu-33 :: PR: #9296\n- [Nemo-UX] IO fixes by @marcromeyn :: PR: #9512\n- Fix lhotse tests for v1.24.2 by @pzelasko :: PR: #9546\n- [Nemo CICD] Make GPU Unit Tests non-optional by @pablo-garay :: PR: #9551\n- Add Python AIStore SDK to container and bump min Lhotse version by @pzelasko :: PR: #9537\n- [NeMo-UX] Fix tokenizer IO by @marcromeyn :: PR: #9555\n- [NeMo UX] Move mistral_7b.py to mistral.py by @akoumpa :: PR: #9545\n- ci: Do not attempt to send slack on fork by @ko3n1g :: PR: #9556\n- Fix SDXL incorrect name in Docs by @suiyoubi :: PR: #9534\n- Bump PTL version by @athitten :: PR: #9557\n- [Resiliency] Straggler detection by @jbieniusiewi :: PR: #9473\n- [NeMo-UX] Switch to torch_dist as default distributed checkpointing backend by @ashors1 :: PR: #9541\n- [NeMo-UX] Checkpointing bug fixes by @ashors1 :: PR: #9562\n- Expose MCore path_to_cache option by @maanug-nv :: PR: #9570\n- [NeMo-UX] Fix Trainer serialization by @marcromeyn :: PR: #9571\n- Update click version requirement by @thomasdhc :: PR: #9580\n- [Fault tolerance] Heartbeat detection by @maanug-nv :: PR: #9352\n- [Nemo-UX] Add fabric-API for manual forward-pass by @marcromeyn :: PR: #9577\n- [Nemo-UX] Add SDK-factories to llm-collection by @marcromeyn :: PR: #9589\n- [NeMo-UX] Some improvements to NeMoLogger by @marcromeyn :: PR: #9591\n- Set no_sync_func & grad_sync_fucn by @akoumpa :: PR: #9601\n- [NeMo-UX] Fix nemo logger when trainer has no loggers by @ashors1 :: PR: #9607\n- Fix the dictionary  format returned by the `scheduler` method by @sararb :: PR: #9609\n- [NeMo-UX] Dataloading enhancements and bug fixes by @ashors1 :: PR: #9595\n- Fix serialization of AutoResume by @sararb :: PR: #9616\n- Jsonl support by @adityavavre :: PR: #9611\n- Akoumparouli/mistral import instruct chat template fix by @akoumpa :: PR: #9567\n- Remove .cuda calls, use device isntead by @akoumpa :: PR: #9602\n- fix converter defautl args by @akoumpa :: PR: #9565\n- fix: remove non_blocking from PTL's .cuda call by @akoumpa :: PR: #9618\n- NeVA Minor Fixes by @yaoyu-33 :: PR: #9608\n- [NeMo-UX] fix pretrianing data sizes and weights by @cuichenx :: PR: #9627\n- [NeMo-UX] async checkpointing support by @ashors1 :: PR: #9466\n- Change default parallel_save to False by @mikolajblaz :: PR: #9632\n- Add REST API to deploy module by @athitten :: PR: #9539\n- ci: Timeout per step, not job by @ko3n1g :: PR: #9635\n- [NeMo-UX] Fix when optimizers are setup for PEFT by @marcromeyn :: PR: #9619\n- [NeMo-UX] Fix pipeline parallel bug by @ashors1 :: PR: #9637\n- Fixing import error fior llama-index (RAG pipeline) by @pablo-garay :: PR: #9662\n- llama CI fix by @rohitrango :: PR: #9663\n- [NeMo-UX] Make 'load_directly_on_device' configurable by @ashors1 :: PR: #9657\n- [Nemo-UX] Including all trainable-params in a PEFT-checkpoint by @marcromeyn :: PR: #9650\n- [NeMo-UX] Fix imports so local configuration of runs works again by @marcromeyn :: PR: #9690\n- Set TE flag in legacy -> mcore conversion script by @terrykong :: PR: #9722\n- Update starthere docs text by @erastorgueva-nv :: PR: #9724\n- TorchAudio installation workaround for incorrect `PYTORCH_VERSION` variable by @artbataev :: PR: #9736\n- [NeMo-UX] Match nemo 1's default behavior for drop_last and pad_samples_to_global_batch_size by @ashors1 :: PR: #9707\n- add a bit more for timeout (#9702) by @pablo-garay :: PR: #9754\n- Fix missing parallelisms by @maanug-nv :: PR: #9725\n- update branch by @nithinraok :: PR: #9764\n- Fix data preprocessing script by @cuichenx :: PR: #9759\n- vLLM 0.5.1 update by @apanteleev :: PR: #9779\n- upper bound hf-hub by @akoumpa :: PR: #9805\n- Fix few issues and docs for neva and clip in r2.0.0rc1 by @yaoyu-33 :: PR: #9681\n- add dummy vision and text transformer config (assumed mcore to be false) by @rohitrango :: PR: #9699\n- fix lita bugs by @Slyne :: PR: #9810\n- [NeMo-UX] Log `val_loss` by @ashors1 :: PR: #9814\n- [NeMo-UX] Fix some dataloading bugs by @ashors1 :: PR: #9807\n- [NeMo-UX] Adding recipes by @marcromeyn :: PR: #9720\n- [NeMo-UX] Set async_save from strategy rather than ModelCheckpoint by @ashors1 :: PR: #9800\n- Fix hf hub for 0.24+ by @titu1994 :: PR: #9806\n- [NeMo-UX] Fix a minor bug with async checkpointing by @ashors1 :: PR: #9856\n- [NeMo-UX] make progress bar easier to parse by @ashors1 :: PR: #9877\n- Docs: add \"Nemo Fundamentals\" page by @erastorgueva-nv :: PR: #9835\n- Create __init__.py by @stevehuang52 :: PR: #9892\n- [NeMo-UX] Fixes to make PreemptionCallback work by @hemildesai :: PR: #9830\n- Fix Docker build. Make Dockerfile consistent with CI by @artbataev :: PR: #9784\n- Multimodal data prep notebook fix by @cuichenx :: PR: #9910\n- [NeMo-UX] Add distributed checkpointing unit tests by @ashors1 :: PR: #9794\n- r2.0.0rc1 fix for dist checkpoint loading by @yaoyu-33 :: PR: #9854\n- [NeMo-UX] Rename sdk references to NeMo Run by @hemildesai :: PR: #9872\n- [NeMo-UX] Fix some serialization bugs by @ashors1 :: PR: #9868\n- add mixtral neva tutorial (moe + token fusion + siglip) by @paul-gibbons :: PR: #9926\n- [NeMo-UX] Add more NeMo Logger tests by @ashors1 :: PR: #9795\n- Akoumparouli/mixtral fixes for r2.0.0rc1 by @akoumpa :: PR: #9911\n- R2.0.0rc1 clip fix by @Slyne :: PR: #9871\n- [NeMo-UX] Add missing docstrings and update some defaults by @ashors1 :: PR: #9895\n- Add REST service requirements.txt by @oyilmaz-nvidia :: PR: #9923\n- add bert latest fix by @JRD971000 :: PR: #9921\n- remove empy reconfigure_limit_batches by @akoumpa :: PR: #9934\n- fix mem by @terrykong :: PR: #9964\n- Run a sample query for a quantized model conditionally by @janekl :: PR: #9965\n- Add pydantic-settings  by @oyilmaz-nvidia :: PR: #9961\n- Resiliency features update by @jbieniusiewi :: PR: #9714\n- [NeMo-UX] Wrap task config save in a try/except by @ashors1 :: PR: #9956\n- [NeMo-UX] Update default PTL logging `save_dir` by @ashors1 :: PR: #9954\n- Fix lita tutorial by @Slyne :: PR: #9980\n- Add deploy and REST API support to NeMo 2.0 by @athitten :: PR: #9834\n- ci: Allow changelog manual (#10156) by @ko3n1g :: PR: #10157\n- docs: Add changelog by @ko3n1g :: PR: #10155\n- add manifest file by @ko3n1g :: PR: #10161\n\n</details>\n\n## NVIDIA Neural Modules 2.0.0rc0\n\n### Highlights\n\n#### LLM and MM\n\n##### Models\n\n- Megatron Core RETRO\n  - Pre-training\n  - Zero-shot Evaluation\n\n- Pretraining, conversion, evaluation, SFT, and PEFT for:\n  - Mixtral 8X22B\n  - Llama 3\n  - SpaceGemma\n\n- Embedding Models Fine Tuning\n  - Mistral\n  - BERT\n\n- BERT models\n  - Context Parallel\n  - Distributed checkpoint\n\n- Video capabilities with NeVa\n\n##### Performance\n\n- Distributed Checkpointing\n  - Torch native backend\n  - Parallel read/write\n  - Async write\n\n- Multimodal LLM (LLAVA/NeVA)\n  - Pipeline Parallelism support\n  - Sequence packing support\n\n##### Export\n\n- Integration of Export & Deploy Modules into NeMo Framework container\n  - Upgrade to TRT-LLM 0.9\n\n#### Speech (ASR & TTS)\n\n##### Models\n\n- AED Multi Task Models (Canary) - Multi-Task Multi-Lingual Speech Recognition / Speech Translation model\n- Multimodal Domain - Speech LLM supporting SALM Model\n- Parakeet-tdt_ctc-1.1b Model - RTFx of > 1500 (can transcribe 1500 seconds of audio in 1 second)\n- Audio Codec 16kHz Small - NeMo Neural Audio Codec for discretizing speech for use in LLMs\n  - mel_codec_22khz_medium\n  - mel_codec_44khz_medium\n\n##### Perf Improvements\n\n- Transcribe() upgrade - Enables one line transcribe with files, tensors, data loaders\n- Frame looping algorithm for RNNT faster decoding - Improves Real Time Factor (RTF) by 2-3x\n- Cuda Graphs + Label-Looping algorithm for RNN-T and TDT Decoding - Transducer Greedy decoding at over 1500x RTFx, on par with CTC Non-Autoregressive models\n- Semi Sorted Batching support - External User contribution that speeds up training by 15-30%.\n\n##### Customization\n\n- Context biasing for CTC word stamping - Improve accuracy for custom vocabulary and pronunciation\n  - Longform Inference\n  - Longform inference support for AED models\n- Transcription of multi-channel audio for AED models\n\n##### Misc\n\n- Upgraded webdataset - Speech and LLM / Multimodal unified container\n\n### Detailed Changelogs\n\n#### ASR\n  \n<details><summary>Changelog</summary>\n\n- Enable using hybrid asr models in CTC Segmentation tool by @erastorgueva-nv :: PR: #8828\n- TDT confidence fix by @GNroy :: PR: #8982\n- Fix union type annotations for autodoc+mock-import rendering by @pzelasko :: PR: #8956\n- NeMo dev doc restructure by @yaoyu-33 :: PR: #8896\n- Improved random seed configuration for Lhotse dataloaders with docs by @pzelasko :: PR: #9001\n- Fix #8948, allow preprocessor to be stream captured to a cuda graph when doing per_feature normalization by @galv :: PR: #8964\n- [ASR] Support for transcription of multi-channel audio for AED models by @anteju :: PR: #9007\n- Add ASR latest news by @titu1994 :: PR: #9073\n- Fix docs errors and most warnings by @erastorgueva-nv :: PR: #9006\n- PyTorch CUDA allocator optimization for dynamic batch shape dataloading in ASR by @pzelasko :: PR: #9061\n- RNN-T and TDT inference: use CUDA graphs by default by @artbataev :: PR: #8972\n- Fix #8891 by supported GPU-side batched CTC Greedy Decoding by @galv :: PR: #9100\n- Update branch for notebooks and ci in release by @ericharper :: PR: #9189\n- Enable CUDA graphs by default only for transcription by @artbataev :: PR: #9196\n- rename paths2audiofiles to audio by @nithinraok :: PR: #9209\n- Fix ASR_Context_Biasing.ipynb contains FileNotFoundError by @andrusenkoau :: PR: #9233\n- Cherrypick: Support dataloader as input to `audio` for transcription (#9201) by @titu1994 :: PR: #9235\n- Update Online_Offline_Microphone_VAD_Demo.ipynb by @stevehuang52 :: PR: #9252\n- Dgalvez/fix greedy batch strategy name r2.0.0rc0 by @galv :: PR: #9243\n- Accept None as an argument to decoder_lengths in GreedyBatchedCTCInfer::forward by @galv :: PR: #9246\n- Fix loading github raw images on notebook by @nithinraok :: PR: #9282\n- typos by @nithinraok :: PR: #9314\n- Re-enable cuda graphs in training modes. by @galv :: PR: #9338\n- add large model stable training fix and contrastive loss update for variable seq by @nithinraok :: PR: #9259\n- Fix conv1d package in r2.0.0rc0  by @pablo-garay :: PR: #9369\n- Fix GreedyBatchedCTCInfer regression from GreedyCTCInfer. (#9347) by @titu1994 :: PR: #9350\n- Make a backward compatibility for old MSDD configs in label models by @tango4j :: PR: #9377\n- Force diarizer to use CUDA if cuda is available and if device=None. by @tango4j :: PR: #9380\n\n</details>\n  \n#### TTS\n\n<details><summary>Changelog</summary>\n\n- [TTS] Add tutorial for training audio codecs by @rlangman :: PR: #8723\n- Update radtts.py by @blisc :: PR: #9097\n- [Nemo CICD] RADTTS test optional by @pablo-garay :: PR: #9112\n- Remove Radtts CI test by @blisc :: PR: #9144\n- Fix T5 G2P Input and Output Types by @blisc :: PR: #9224\n\n</details>\n\n#### LLM and MM\n\n<details><summary>Changelog</summary>\n\n- Rachitg/dpa by @rachitgarg91 :: PR: #8911\n- Remove precision args in trainer due to PTL update by @yaoyu-33 :: PR: #8908\n- Huvu/mcore retro by @huvunvidia :: PR: #8861\n- fsdp tp > 1 bug fix by @dimapihtar :: PR: #8947\n- Fix memory leak at loss func by @minitu :: PR: #8868\n- change the condition for get qkv tensor from linear_qkv output in mcoremixin by @HuiyingLi :: PR: #8965\n- Add safety checks for 'data' key in MegatronGPTModel cfg by @HuiyingLi :: PR: #8991\n- [NeMo-UX] Adding MegatronParallel by @cuichenx :: PR: #8987\n- Skip top_p computations when set to 1.0 by @odelalleau :: PR: #8905\n- Gemma bug by @cuichenx :: PR: #8962\n- [NeMo-UX] Adding megatron strategy by @marcromeyn :: PR: #8995\n- Quantized checkpoint support in export and deploy modules by @janekl :: PR: #8859\n- add geglu to mlp swap by @JRD971000 :: PR: #8999\n- add timeout for new_group by @acphile :: PR: #8998\n- Zero-shot evaluation pipeline for mcore RETRO by @huvunvidia :: PR: #8941\n- Added fusion for squared relu by @sanandaraj5597 :: PR: #8963\n- Developer Documents for mcore RETRO by @huvunvidia :: PR: #9026\n- [NeMo-UX] Adding GPTModel & MockDataModule by @marcromeyn :: PR: #9011\n- Adding unit test for mcore RETRO model by @huvunvidia :: PR: #9022\n- docs and simplification of cmd args by @arendu :: PR: #8979\n- [NeMo-UX] Add checkpoint-io to MegatronStrategy by @marcromeyn :: PR: #9057\n- Enable Sequence Packing and Pipeline Parallel in NeVA by @yaoyu-33 :: PR: #8957\n- Mingyuanm/add back fp8 support to sd by @Victor49152 :: PR: #9070\n- unfused lora by @arendu :: PR: #9004\n- Handle case where num_query_groups is set to null for LoRA config setup by @vysarge :: PR: #9075\n- Alit/griffin by @JRD971000 :: PR: #9021\n- Implement DistributedCheckpointIO by @mikolajblaz :: PR: #9016\n- Video Neva Pretraining + Inference Implementation by @paul-gibbons :: PR: #9095\n- HF to .nemo for Mixtral-8x22B-instruct by @akoumpa :: PR: #9060\n- mcore ds updates by @dimapihtar :: PR: #8951\n- Alit/griffin perf by @JRD971000 :: PR: #9107\n- Add assert for max_steps to be positive in MegatronGPTSFTModel by @athitten :: PR: #9110\n- Extend sequence length padding for GPT SFT to account for context parallel by @vysarge :: PR: #8869\n- Update gpt dataset config parameter for mock by @thomasdhc :: PR: #9118\n- Add Mcore DistributedDataParallel and distributed optimizer into Nemo by @gdengk :: PR: #9034\n- Revert \"Add assert for max_steps to be positive in MegatronGPTSFTMode… by @pablo-garay :: PR: #9128\n- scripts to convert HF lora to nemo by @arendu :: PR: #9102\n- Prevent duplicated checkpoints by @mikolajblaz :: PR: #9015\n- add TN/ITN link in speech tools list by @erastorgueva-nv :: PR: #9142\n- Cleanup deprecated files and temporary changes by @cuichenx :: PR: #9088\n- Use DP+CP groups as the FSDP sharding domain by @erhoo82 :: PR: #9145\n- CUDA memory profile by @erhoo82 :: PR: #9096\n- Fix missing func for T5 model by @gdengk :: PR: #9141\n- Add knob for load_directly_on_device by @mikolajblaz :: PR: #9125\n- Revert rope fusion defaults by @cuichenx :: PR: #9238\n- Update nemo.export module for quantized models by @janekl :: PR: #9250\n- Fix circular import for MM dataprep notebook by @cuichenx :: PR: #9287\n- neva media_type + text generation default fix by @paul-gibbons :: PR: #9257\n- fix lora and ptuning and isort/black by @oyilmaz-nvidia :: PR: #9290\n- add check if num layers is divisible by pp size by @dimapihtar :: PR: #9208\n- Fix P-tuning for Llama based models by @apanteleev :: PR: #9297\n- add deprecation warnings by @pablo-garay :: PR: #9266\n- move pooler under post_process by @dimapihtar :: PR: #9328\n- add deprecation note for nmt by @dimapihtar :: PR: #9342\n- Fix incorrect checkpoint removal logic (#9192) by @mikolajblaz :: PR: #9204\n- fix fp16 precision issue by @dimapihtar :: PR: #9376\n- Fix module.training for Neva in FusedAttn backward which causes nan by @yaoyu-33 :: PR: #8877\n\n</details>\n\n#### Export\n\n<details><summary>Changelog</summary>\n\n- Updates for TRT-LLM 0.9 by @oyilmaz-nvidia :: PR: #8873\n- Mingyuanm/sdxl export by @Victor49152 :: PR: #8926\n- Avoid unpacking NeMo checkpoints before exporting to TRT-LLM by @apanteleev :: PR: #8866\n- Update gemma for trt-llm 0.9 by @oyilmaz-nvidia :: PR: #8974\n- TRT-LLM export P-tuning related fixes by @apanteleev :: PR: #8863\n\n</details>\n\n#### General Improvements\n\n<details><summary>Changelog</summary>\n\n- Update package info by @ericharper :: PR: #8793\n- [Nemo CICD] Update mcore 4.13.24 by @pablo-garay :: PR: #8917\n- Akoumparouli/low mem mixtral ckpt converter by @akoumpa :: PR: #8895\n- Adding RETRO tests to Action Tests (cicd-main.yml)  by @huvunvidia :: PR: #8942\n- Akoumparouli/fix sd train 2 by @akoumpa :: PR: #8883\n- Update te install for jenkins by @ericharper :: PR: #8954\n- [Nemo CICD] Add last job depending on others for blocking check by @pablo-garay :: PR: #8959\n- Minor quantization pipeline updates by @janekl :: PR: #8924\n- Fix External CLIP Converter by @yaoyu-33 :: PR: #8960\n- PP support in LoRA merge script by @cuichenx :: PR: #8934\n- Update PR template by @ericharper :: PR: #8978\n- Update Latest News by @shashank3959 :: PR: #8837\n- Fix incorrect link to latest news in README by @shashank3959 :: PR: #8985\n- Update dependency install for LLM and MM by @ericharper :: PR: #8990\n- Temporarily remove mcore dep by @ericharper :: PR: #9010\n- [Nemo CICD] further specialize runners for more parallelism by @pablo-garay :: PR: #9036\n- Update mm dataprep notebook based on feedback by @cuichenx :: PR: #9029\n- Fix import in lora merge script by @cuichenx :: PR: #9032\n- [Nemo CICD] Run when labeled:Run CICD by @pablo-garay :: PR: #9044\n- [Nemo CICD] Add tag/label for 1-gpu runner by @pablo-garay :: PR: #9046\n- [Nemo CICD] checkout v4 by @pablo-garay :: PR: #9048\n- [Nemo CICD] Remove temp test change by @pablo-garay :: PR: #9049\n- remove in-place addition for dreambooth train with text encoder by @Victor49152 :: PR: #8825\n- Mingyuanm/sdxl quantization notebook by @Victor49152 :: PR: #9042\n- [Nemo CICD] Trigger on comment issued by @pablo-garay :: PR: #9062\n- zarr ckpt to torch_dist ckpt converter by @dimapihtar :: PR: #8842\n- Restore PTQ tests for Llama2 (reopened) by @janekl :: PR: #9064\n- add clip H config by @JRD971000 :: PR: #9082\n- [NeMo-UX] Add mixed-precision plugin by @marcromeyn :: PR: #9065\n- Comment baichuan test and update pr template by @ericharper :: PR: #9085\n- Add safe extraction of nemo tar files by @athitten :: PR: #8976\n- Improved `shard_id` parsing in `LazyNemoTarredIterator`, enables AIS dataloading by @pzelasko :: PR: #9077\n- [NeMo-UX] Add mistral-7b model by @marcromeyn :: PR: #9066\n- Llama3 Conversion Script Update by @suiyoubi :: PR: #9089\n- dehardcode test string by @JimmyZhang12 :: PR: #8865\n- [Nemo CICD] Try trigger cicd run on comment by @pablo-garay :: PR: #9111\n- Lhotse dataloading: RIR augmentation and nemo/tarred input support for RIR and noise aug by @pzelasko :: PR: #9109\n- mixtral evaluation PR by @Slyne :: PR: #8989\n- [Nemo CICD] Revert: run GHA cicd on comment by @pablo-garay :: PR: #9119\n- [Nemo CICD] Comment out flaky test: running too long by @pablo-garay :: PR: #9123\n- [Nemo CICD] Add timeout to unit tests by @pablo-garay :: PR: #9132\n- [Nemo CICD] Indicate optional test in name (prefix) by @pablo-garay :: PR: #9139\n- video neva null image+video folder path fix by @paul-gibbons :: PR: #9116\n- [NeMo-UX] Add data module by @cuichenx :: PR: #9133\n- NeMo Inference Requirements by @oyilmaz-nvidia :: PR: #9093\n- Remove debug print by @maanug-nv :: PR: #9074\n- Remove legacy CI by @pablo-garay :: PR: #9149\n- Update support for push_to_hf_hub() by @titu1994 :: PR: #9159\n- [Nemo CICD] comment out flaky PTQ tests by @pablo-garay :: PR: #9160\n- Update branch by @ericharper :: PR: #9211\n- dist adam transpose fix by @dimapihtar :: PR: #9239\n- [Nemo CICD] Increase time limit for Speech_Checkpoints_tests (#9186) by @pablo-garay :: PR: #9247\n- Pin transformers by @ericharper :: PR: #9261\n- Fix typo in HF tutorial by @titu1994 :: PR: #9302\n\n</details>\n\n## NVIDIA Neural Modules 1.23.0\n\n### Highlights\n\n#### Models\n\n##### Nvidia Starcoder 2 - 15B\n\n- Announcement - https://developer.nvidia.com/blog/unlock-your-llm-coding-potential-with-starcoder2/\n- AI Foundation Model Inference  - https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-foundation/models/starcoder2-15b\n- https://huggingface.co/bigcode/starcoder2-15b\n\n##### NeMo Canary\nAnnouncement - https://nvidia.github.io/NeMo/blogs/2024/2024-02-canary/\n\n- https://huggingface.co/nvidia/canary-1b\n\n#### NeMo LLM\n\n- Falcon\n- Code Llama\n- StarCoder\n- GPT perf improvements\n- Context parallelism\n- Mistral\n- Mixtral (without expert parallelism)\n- Mcore GPT Dataset integration\n\n#### NeMo MM\n- CLIP\n- Stable Diffusion (supporting LoRA)\n- Imagen\n- ControlNet (for SD)\n- Instruct pix2pix (for SD)\n- LLAVA\n- NeVA\n- DreamFusion++\n- NSFW filtering\n\n#### NeMo ASR\n\n- Lhotse Dataloading support #7880\n- Canary: Multi task multi lingual ASR #8242\n- LongForm Audio for Diarization #7737\n- Faster algorithm for RNN-T Greedy #7926\n- Cache-Aware streaming notebook #8296\n\n#### NeMo TTS\n\n#### NeMo Vision\n\n#### Known Issues\n\n##### ASR\n\n###### RNNT WER calculation when fused batch size > 1 during validation / test step()\n\nPreviously, the RNNT metric was stateful while the CTC one was not ([r1.22.0](https://github.com/NVIDIA/NeMo/blob/r1.22.0/nemo/collections/asr/metrics/rnnt_wer_bpe.py#L419-L420), [r1.23.0](https://github.com/NVIDIA/NeMo/blob/r1.23.0/nemo/collections/asr/metrics/wer.py#L333))\n\nTherefore this calculation in the RNNT joint for fused operation worked properly. However with the unification of metrics in r1.23.0, a bug was introduced where only the last sub-batch of metrics calculates the scores and does not accumulate. This is patched via https://github.com/NVIDIA/NeMo/pull/8587 and will be fixed in the next release.\n\n**Workaround**: Explicitly disable fused batch size during inference using the following command \n\n```python\nfrom omegaconf import open_dict\nmodel = ...\ndecoding_cfg = model.cfg.decoding\nwith open_dict(decoding_cfg):\n  decoding_cfg.fused_batch_size = -1\nmodel.change_decoding_strategy(decoding_cfg)\n```\n\nNote: This bug does not affect scores calculated via model.transcribe() (since it does not calculate metrics during inference, just text), or using the `transcribe_speech.py` or `speech_to_text_eval.py` in `examples/asr`.\n\n###### Two failing unit tests due to a change in expected results, caused by lhotse version update\n\n#### Container\n\nFor additional information regarding NeMo containers, please visit: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo\n\n`docker pull nvcr.io/nvidia/nemo:24.01.speech`\n\n#### ASR\n\n<details><summary>Changelog</summary>\n\n- Update link to yaml file in ASR_with_Transducers.ipynb by @Faith-Nchifor :: PR: #8014\n- Use convert_hf_dataset_to_nemo by @karpnv :: PR: #8017\n- Update asr_language_modeling.rst: Add a missing word by @martin0258 :: PR: #8007\n- spelling mistake by @orena1 :: PR: #7903\n- update asr eval by @stevehuang52 :: PR: #8045\n- fix noise aug by @stevehuang52 :: PR: #8057\n- Various fixes for typos and urls by @titu1994 :: PR: #8066\n- [Fix] Increase length check tolerance to prevent test failing by @anteju :: PR: #8067\n- Add text metrics to asr eval by @stevehuang52 :: PR: #8087\n- fix device setting to allow using accelerator cpu by @orena1 :: PR: #8084\n- .ctm in data simulator annotator compliant with RT-09 specification by @popcornell :: PR: #8004\n- Fix AST eval by @stevehuang52 :: PR: #8112\n- fix: numba.*_num_threads resets torch num_threads #8141 by @itzsimpl :: PR: #8145\n- Update dependencies by @titu1994 :: PR: #8156\n- NeMo + Lhotse integration by @pzelasko :: PR: #7880\n- Speedup RNN-T greedy decoding by @artbataev :: PR: #7926\n- [docker] Install k2 before NeMo for faster image rebuilding by @pzelasko :: PR: #8204\n- [docs] Add --force_codec to tarred dataset creation examples by @pzelasko :: PR: #8227\n- Temporarily use the previous RNN-T decoding algorithm as default by @artbataev :: PR: #8226\n- Make TDT inference not require duration params by @hainan-xv :: PR: #8207\n- Cache Aware Streaming tutorial notebook by @erastorgueva-nv :: PR: #8296\n- fix path location and branch by @nithinraok :: PR: #8304\n- Attention encoder-decoder models for multiple speech-to-text tasks  … by @titu1994 :: PR: #8324\n- Remove asr webapp by @titu1994 :: PR: #8347\n- remove _target_ at model level in aed model config [ASR] by @krishnacpuvvada :: PR: #8351\n- Add change_vocabulary and save_tokenizers() support to Multitask ASR models by @titu1994 :: PR: #8357\n- Change default beam size by @titu1994 :: PR: #8371\n-  adding jenkins test for speech_to_text_aed model by @krishnacpuvvada :: PR: #8368\n- Add Finetuning tutorial with HF Datasets by @nithinraok :: PR: #8356\n- wer fix by @tbartley94 :: PR: #8404\n- add ensemble decoding fix by @nithinraok :: PR: #8427\n- Update k2 by @artbataev :: PR: #8492\n\n</details>\n\n#### TTS\n\n<details><summary>Changelog</summary>\n\n- [TTS] Scale sampler steps by number of devices by @rlangman :: PR: #7947\n- Add All Multimodal Source Code Part 2: Text to image, x to nerf by @yaoyu-33 :: PR: #7970\n- [TTS] Add period discriminator and feature matching loss to codec recipe by @rlangman :: PR: #7884\n- Added VectorQuantizer base class by @anteju :: PR: #8011\n\n</details>\n\n#### LLMS\n\n<details><summary>Changelog</summary>\n\n- Add interface to set NCCL options of each process group by @erhoo82 :: PR: #7923\n- Support O2 training of PEFT and SFT by @cuichenx :: PR: #7971\n- [NLP] Access scaler only in FP16 case by @janekl :: PR: #7916\n- [NLP] Minor improvements in Llama conversion script by @janekl :: PR: #7978\n- [NLP] Use helpers from utils_funcs.py in Llama conversion by @janekl :: PR: #7979\n- [NLP] Remove replace_sampler_ddp (deprecated in Trainer) by @janekl :: PR: #7981\n- Reworked MegatronPretrainingRandomBatchSampler to correctly handle epochs > 1 by @trias702 :: PR: #7920\n- Remove deprecated arguments from TE's TransformerLayer by @jbaczek :: PR: #7917\n- Add All Multimodal Source Code by @yaoyu-33 :: PR: #7791\n- First draft of mcore bert model in NeMo by @shanmugamr1992 :: PR: #7814\n- Support Falcon Variants (7B/40B/180B) in Mcore NeMo by @xuanzic :: PR: #7666\n- FSDP + Tensor Parallelism by @erhoo82 :: PR: #7897\n- Packed Sequence by @cuichenx :: PR: #7945\n- Adding method back that was removed accidentally by @ericharper :: PR: #8038\n- [NLP] ArtifactItem with init=True to make it debuggable by @janekl :: PR: #7980\n- SFT patch: (1) enable sequence parallelism and (2) enable profile by @erhoo82 :: PR: #7963\n- migration to PTL 2.0 for spellmapper model by @bene-ges :: PR: #7924\n- Change the megatron config lr scheduler default and fix to change partitions script by @shan18 :: PR: #8094\n- (1) Add SHARP interface to M-CORE, (2) use send/recv to send train loss to the first rank instead of b-cast by @erhoo82 :: PR: #7793\n- Reconfigure limit_val_batches only for int by @athitten :: PR: #8099\n- Fixing wrapper and moving it to base class by @shanmugamr1992 :: PR: #8055\n- fix gated_linear_unit bug by @Agoniii :: PR: #8042\n- Fix Adapter for MCore models by @cuichenx :: PR: #8124\n- add war fix for sync issues by @gshennvm :: PR: #8130\n- Improve PEFT UX by @cuichenx :: PR: #8131\n- Enhance flexibility by passing callbacks as method argument by @michal2409 :: PR: #8015\n- context parallelism by @xrennvidia :: PR: #7739\n- Make pipelined TP comm overlap available with mcore by @erhoo82 :: PR: #8005\n- remove deprecated scripts by @arendu :: PR: #8138\n- adding OnlineSampleMapping by @arendu :: PR: #8137\n- Add distopt support for FP8 params and BF16 optimizer state by @timmoon10 :: PR: #7909\n- Revert adding OnlineSampleMapping by @pablo-garay :: PR: #8164\n- Token count and sequence length logging for MegatronGPTSFTModel by @vysarge :: PR: #8136\n- Use latest apex internal API by @jbaczek :: PR: #8129\n- tune specific params in the base model by @arendu :: PR: #7745\n- Virtual pipeline parallel support for MegatronGPTSFTModel by @vysarge :: PR: #7964\n- removed deprecated peft model by @arendu :: PR: #8183\n- remove more deprecated files by @arendu :: PR: #8169\n- Pre-generate cu_seqlens argmin and max_seqlen to remove host-to-device sync by @erhoo82 :: PR: #8108\n- Add the interface to use SHARP to FSDP strategy by @erhoo82 :: PR: #8202\n- Multimodal required NLP base model changes by @yaoyu-33 :: PR: #8188\n- [NLP] Improve and unify loading state_dict for community models by @janekl :: PR: #7977\n- Rename Finetuning Scripts by @cuichenx :: PR: #8201\n- Final multimodal PR with our recent developments on MM side by @yaoyu-33 :: PR: #8127\n- Add include_text parameter to SFT dataloaders by @Kipok :: PR: #8198\n- Add random_seed argument to generate by @Kipok :: PR: #8162\n- Added support for neptune logger by @harishankar-gopalan :: PR: #8210\n- Pre-compute max_seqlen and cu_seqlens_argmin in all model-parallel cases by @erhoo82 :: PR: #8222\n- Use PackedSeqParams in accordance with changes in Megatron-LM by @cuichenx :: PR: #8205\n- Fix to peft & virtual pipeline parallel unsupported check by @vysarge :: PR: #8216\n- Fixed the tp overlap switch by @sanandaraj5597 :: PR: #8195\n- add knobs for rope/swiglu fusion by @lhb8125 :: PR: #8184\n- Added sample cpu_offloading switch to YAML by @sanandaraj5597 :: PR: #8148\n- Syncing random seed between ranks in generate by @Kipok :: PR: #8230\n- add first_val_step to mcore scheduler by @JimmyZhang12 :: PR: #8150\n- Correct padding for SFT input data to account for sequence parallel + TE's fp8 op dimension requirements by @vysarge :: PR: #8240\n- Mistral 7b conversion script by @akoumpa :: PR: #8052\n- switch to mcore dataset [with FIM support] by @dimapihtar :: PR: #8149\n- Mixtral to NeMo conversion script. by @akoumpa :: PR: #8155\n- fixes to accomendate mcore changes by @HuiyingLi :: PR: #8261\n- Allow MegatronPretrainingRandomSampler to do multi-epoch training by @trias702 :: PR: #8239\n- Add dist ckpt support for regular optimizers by @mikolajblaz :: PR: #7749\n- add deallocate pipeline output optimization by @JimmyZhang12 :: PR: #8279\n- Fix memory leak caused by context parallelism hanging references by omegaconf by @JimmyZhang12 :: PR: #8299\n- distributed fused adam + rampup bs support by @dimapihtar :: PR: #8302\n- Update PEFT Doc by @cuichenx :: PR: #8262\n- Converter script fixes for mixtral/mistral by @akoumpa :: PR: #8272\n- Keep max_seqlen and cu_seqlens_argmin for later micro-batches when PP>1 by @erhoo82 :: PR: #8334\n- Enable megatron core loggers for GPT pretraining by @ashbhandare :: PR: #8354\n- mcore ds fix by @dimapihtar :: PR: #8283\n- release updates by @dimapihtar :: PR: #8378\n- Mcore customization doc by @HuiyingLi :: PR: #8298\n- updated link to pubmed by @nithinraok :: PR: #8402\n- mcore customization doc minor fix by @HuiyingLi :: PR: #8421\n- Fixing mcore bert for TP, PP and SP by @shanmugamr1992 :: PR: #8336\n- Add settings to suppress bf16 compile errors in CI on V100 by @athitten :: PR: #8481\n- MoE parameter passing by @akoumpa :: PR: #8255\n- Add fp8 support for SD/Update notebook paths by @Victor49152 :: PR: #8489\n\n</details>\n\n#### NeMo Tools\n\n<details><summary>Changelog</summary>\n\n- SDE bugfix log by @Jorjeous :: PR: #8430\n\n</details>\n\n#### General Improvements\n\n<details><summary>Changelog</summary>\n\n- Add news section to README by @ericharper :: PR: #7984\n- Fixing conversion script to work for code llama by @shanmugamr1992 :: PR: #7997\n- Fix crash when converting to mcore a model using rotary embeddings by @odelalleau :: PR: #7998\n- Added a procedure for Windows users, README by @Jorjeous :: PR: #7942\n- Update manifest.py to speedup loading tarred datasets by @stevehuang52 :: PR: #7900\n- [Fix] Fixed name of a test by @anteju :: PR: #7986\n- Fix lora merge script by @cuichenx :: PR: #8113\n- Support transcoding audio formats when saving tarred datasets (FLAC, OPUS) by @pzelasko :: PR: #8102\n- README edit to change Apple Silicon install instructions (to fix a break introduced by pytorch 2) by @stephenmcconnachie :: PR: #8122\n- Fixes NVIDIA/apex installation to not erroneously install the  pkg by @terrykong :: PR: #8126\n- Graphviz fix by @GNroy :: PR: #7843\n- Update README.rst by @fayejf :: PR: #8154\n- Fix TP>1 issue for conversion script by @cuichenx :: PR: #8144\n- Support torch jit script by @artbataev :: PR: #8027\n- NeMo Multimodal Docs and Tests Initial PR by @yaoyu-33 :: PR: #8028\n- Remove left-over prints in NeMo+Lhotse code by @pzelasko :: PR: #8180\n- Upgrade to DLFW PyTorch 23.12 by @ericharper :: PR: #8163\n- Add Lhotse support for  key in NeMo manifests by @pzelasko :: PR: #8197\n- Fix CPU Initialization and TP>1 for LoRA Merge Script by @cuichenx :: PR: #8199\n- Add support in Neural Typecheck to disable semantic checks by @titu1994 :: PR: #8212\n- Pin lhotse=1.19.2 in r1.23.0 by @pzelasko :: PR: #8303\n- Multimodal r1.23.0 bug fix  by @yaoyu-33 :: PR: #8315\n- MCore dataset compatibility for tokenizers by @vysarge :: PR: #8390\n- Update NFA video download link by @erastorgueva-nv :: PR: #8406\n- Update MM Dataprep Tutorial by @cuichenx :: PR: #8410\n- Fix dreambooth data sampler issue by @yaoyu-33 :: PR: #8400\n- Fix a bug in CTM line processing function for multi-speaker data simulations by @tango4j :: PR: #8416\n- Akoumparouli/mistral bugfix by @akoumpa :: PR: #8353\n- pin to 0.5.0 by @ericharper :: PR: #8465\n- Update NeMo Multimodal Requirements by @yaoyu-33 :: PR: #8515\n- Fix link in multimodal dataprep tutorial by @cuichenx :: PR: #8517\n\n</details>\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 1.052734375,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\ntitle: \"NeMo: a toolkit for Conversational AI and Large Language Models\"\nurl: https://nvidia.github.io/NeMo/\nrepository-code: https://github.com/NVIDIA/NeMo\nauthors:\n  - family-names: Harper\n    given-names: Eric\n  - family-names: Majumdar\n    given-names: Somshubra\n  - family-names: Kuchaiev\n    given-names: Oleksii\n  - family-names: Jason\n    given-names: Li\n  - family-names: Zhang\n    given-names: Yang\n  - family-names: Bakhturina\n    given-names: Evelina\n  - family-names: Noroozi \n    given-names: Vahid\n  - family-names: Subramanian\n    given-names: Sandeep\n  - family-names: Nithin\n    given-names: Koluguri\n  - family-names: Jocelyn\n    given-names: Huang\n  - family-names: Jia\n    given-names: Fei\n  - family-names: Balam\n    given-names: Jagadeesh\n  - family-names: Yang\n    given-names: Xuesong\n  - family-names: Livne\n    given-names: Micha\n  - family-names: Dong\n    given-names: Yi\n  - family-names: Naren\n    given-names: Sean\n  - family-names: Ginsburg\n    given-names: Boris\n\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.298828125,
          "content": "# Contributions are welcome!\n\nWe do all of NeMo's development in the open. Contributions from NeMo community are welcome.\n\n\n# Pull Requests (PR) Guidelines\n\n**Send your PRs to the `main` branch**\n\n1) Make sure your PR does one thing. Have a clear answer to \"What does this PR do?\".\n2) Read General Principles and style guide below\n3) Make sure you sign your commits. E.g. use ``git commit -s`` when before your commit\n4) Make sure all unittests finish successfully before sending PR ``pytest`` or (if yor dev box does not have GPU) ``pytest --cpu`` from NeMo's root folder\n5) Send your PR and request a review\n\n## Unit tests\nQuick tests (locally, while developing)\n```\npytest\n# If you don't have NVIDIA GPU do:\n# pytest --cpu\n```\nFull tests, including pre-trained model downloads\n```\npytest --with_downloads\n```\n\n## Whom should you ask for review:\n1. For changes to NeMo's core: @ericharper, @titu1994, @blisc, or @okuchaiev  \n1. For changes to NeMo's ASR collection: @titu1994, @redoctopus, @jbalam-nv, or @okuchaiev\n1. For changes to NeMo's NLP collection: @MaximumEntropy, @ericharper, @ekmb, @yzhang123, @VahidooX, @vladgets, or @okuchaiev \n1. For changes to NeMo's TTS collection: @blisc, or @okuchaiev\n\nNote that some people may self-assign to review your PR - in which case, please wait for them to add a review.\n\nYour  pull requests must pass all checks and peer-review before they can be merged.\n\n# General principles\n1. **User-oriented**: make it easy for end users, even at the cost of writing more code in the background\n1. **Robust**: make it hard for users to make mistakes.\n1. **Well-tested**: please add simple, fast unittests. Consider adding CI tests for end-to-end functionality.\n1. **Reusable**: for every piece of code, think about how it can be reused in the future and make it easy to be reused.\n1. **Readable**: code should be easier to read.\n1. **Legal**: if you copy even one line of code from the Internet, make sure that the code allows the license that NeMo supports. Give credit and link back to the code.\n1. **Sensible**: code should make sense. If you think a piece of code might be confusing, write comments.\n\n## Class naming conventions\n* No “I”, “Interface”, “NM” nor “NeMo” pre/postfixes anywhere\n* Core interfaces have simple names: Typing, Cloud, Serialization, FileIO*\n* Core classes have the simplest names ever: NeuralModule, Model, Graph, Dataset, Loss, Module*\n* Abstract classes in the Model hierarchy have Model postfix\n* A config class for MyModel should be called MyModelConfig\n* Leaf Neural Module classes have simple names without any postfixes (e.g. AudioPreprocess)\n* Leaf Datasets have Dataset postfix (e.g. AudioToSpeechLabelDataset)\n* Leaf Losses have Loss postfix (e.g. CTCLoss)\n* Leaf Models do not have any postfix, just name (e.g. QuartzNet)\n\n## Python style\nWe use ``black`` as our style guide. To check whether your code will pass style check (from the NeMo's repo folder) run:\n``python setup.py style`` and if it does not pass run ``python setup.py style --fix``.\n\n1. Include docstrings for every class and method exposed to the user.\n1. Use Python 3 type hints for every class and method exposed to the user.\n1. Avoid wild import: ``from X import *`` unless in ``X.py``, ``__all__`` is defined.\n1. Minimize the use of ``**kwargs``.\n1. ``RaiseError`` is preferred to ``assert``. Write: ```if X: raise Error``` instead of ```assert X```.\n1. Classes are preferred to standalone methods.\n1. Methods should be atomic. A method shouldn't be longer than 75 lines, e.g. can be fit into the computer screen without scrolling.\n1. If a method has arguments that don't fit into one line, each argument should be in its own line for readability.\n1. Add ``__init__.py`` for every folder.\n1. F-strings are prefered to formatted strings.\n1. Loggers are preferred to print. In NeMo, you can use logger from ``from nemo.utils import logging``\n1. Private functions (functions start with ``_``) shouldn't be called outside its host file.\n1. If a comment lasts multiple lines, use ``'''`` instead of ``#``.\n\n# Collections\nCollection is a logical grouping of related Neural Modules. It is a grouping of modules that share a domain area or semantics.\nWhen contributing module to a collection, please make sure it belongs to that category. \nIf you would like to start a new one and contribute back to the platform, you are very welcome to do so.  \n"
        },
        {
          "name": "Dockerfile.ci",
          "type": "blob",
          "size": 3.1416015625,
          "content": "# syntax=docker/dockerfile:1-labs\n\n# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nARG BASE_IMAGE=nvcr.io/nvidia/pytorch:24.07-py3\nARG IMAGE_LABEL\nFROM ${BASE_IMAGE}\nARG IMAGE_LABEL\nLABEL \"nemo.library\"=${IMAGE_LABEL}\n\nENV TRANSFORMERS_OFFLINE=0\nENV HYDRA_FULL_ERROR=1\nENV PYTHONUNBUFFERED=1\n\n# APT packages\nRUN <<\"EOF\" bash -ex\napt-get update\napt-get install -y bc libsox-fmt-all -y\napt-get clean\nEOF\n\nWORKDIR /workspace\n\n# Install Mamba Dependancy\nARG CAUSAL_CONV_TAG=v1.2.2.post1\n\nRUN <<\"EOF\" bash -ex\n# Mamba dependancy installation\n\ngit clone --depth 1 --branch ${CAUSAL_CONV_TAG} https://github.com/Dao-AILab/causal-conv1d && \\\n  cd causal-conv1d && \\\n  python setup.py install && \\\n  cd .. && \\\n  rm -rf causal-conv1d\n\nEOF\n\nRUN pip install hatchling   # needed to install nemo-run\nARG NEMO_RUN_TAG=34259bd3e752fef94045a9a019e4aaf62bd11ce2\nRUN pip install nemo_run@git+https://github.com/NVIDIA/NeMo-Run.git@${NEMO_RUN_TAG}\n\n# Install NeMo requirements\nARG TE_TAG=7d576ed25266a17a7b651f2c12e8498f67e0baea\nARG MODELOPT_VERSION=0.21.0\nARG MCORE_TAG=bd677bfb13ac2f19deaa927adc6da6f9201d66aa\n\nARG APEX_TAG=810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c\nRUN \\\n  --mount=type=bind,source=requirements,target=requirements \\\n  --mount=type=bind,source=tools,target=tools \\\n  --mount=type=bind,source=setup.py,target=setup.py \\\n  --mount=type=bind,source=nemo/package_info.py,target=nemo/package_info.py \\\n  --mount=type=bind,source=nemo/__init__.py,target=nemo/__init__.py <<\"EOF\" bash -ex\npip install --no-cache-dir --no-build-isolation --extra-index-url https://pypi.nvidia.com \\\n\"transformer-engine @ git+https://github.com/NVIDIA/TransformerEngine.git@${TE_TAG}\" \\\n\"megatron_core @ git+https://github.com/NVIDIA/Megatron-LM.git@${MCORE_TAG}\" \\\n\"nvidia-modelopt[torch]~=${MODELOPT_VERSION}\" \\\n\"apex @ git+https://github.com/NVIDIA/apex.git@${APEX_TAG}\" \\\n\"unstructured==0.14.9\" \\\n\"llama-index==0.10.43\" \\\n\"onnxscript @ git+https://github.com/microsoft/onnxscript\" \\\n-r tools/ctc_segmentation/requirements.txt \\\n\".[all]\"\n\n# Megatron Core installation\ngit clone https://github.com/NVIDIA/Megatron-LM.git && \\\npushd Megatron-LM && \\\ngit checkout ${MCORE_TAG} && \\\n  pushd megatron/core/datasets && \\\n  make && \\\n  popd && \\\npopd\nexport PYTHONPATH=\"${PYTHONPATH}:/workspace/Megatron-LM\"\n\n# Install nvidia-resiliency-ext\npip install --no-cache-dir \"git+https://github.com/NVIDIA/nvidia-resiliency-ext.git@97aad77609d2e25ed38ac5c99f0c13f93c48464e\"\n\nEOF\n\n# Copy over NeMo code\nCOPY ./ ./\nRUN <<\"EOF\" bash -ex\npip install --no-cache-dir --no-build-isolation \".[all]\"\n\n# set permission\nchmod 777 -R /workspace\nEOF\n\nENV PYTHONPATH=\"${PYTHONPATH}:/workspace/Megatron-LM\"\n"
        },
        {
          "name": "Dockerfile.speech",
          "type": "blob",
          "size": 7.0771484375,
          "content": "# syntax=docker/dockerfile:experimental\n\n# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nARG BASE_IMAGE=nvcr.io/nvidia/pytorch:24.02-py3\n\n# build an image that includes only the nemo dependencies, ensures that dependencies\n# are included first for optimal caching, and useful for building a development\n# image (by specifying build target as `nemo-deps`)\nFROM ${BASE_IMAGE} as nemo-deps\n\n# dependency flags; should be declared after FROM\n# torchaudio: not required by default\nARG REQUIRE_TORCHAUDIO=false\n# k2: not required by default\nARG REQUIRE_K2=false\n# ais cli: not required by default, install only if required\nARG REQUIRE_AIS_CLI=false\n\n# Ensure apt-get won't prompt for selecting options\nENV DEBIAN_FRONTEND=noninteractive\n# libavdevice-dev required for latest torchaudio\nRUN apt-get update && \\\n  apt-get upgrade -y && \\\n  apt-get install -y \\\n  libsndfile1 sox \\\n  libfreetype6 \\\n  swig \\\n  ffmpeg \\\n  libavdevice-dev && \\\n  rm -rf /var/lib/apt/lists/*\n\n# libtool, ... , libgts-dev are required for graphviz\n# graphviz is required for k2 and pynini visualization\nRUN apt-get update && \\\n  apt-get install -y \\\n  libtool \\\n  libltdl-dev \\\n  automake \\\n  autoconf \\\n  bison \\\n  flex \\\n  tcl \\\n  ghostscript \\\n  libgd-dev \\\n  fontconfig \\\n  libcairo2-dev \\\n  libpango1.0-dev \\\n  libgts-dev && \\\n  rm -rf /var/lib/apt/lists/*\n\nWORKDIR /workspace/\n\nARG TE_TAG=7d576ed25266a17a7b651f2c12e8498f67e0baea\nARG MCORE_TAG=338af51452a53982d202e8386db6233adad1ce86\nARG APEX_TAG=810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c\n# Install megatron core, this can be removed once 0.3 pip package is released\n# We leave it here in case we need to work off of a specific commit in main\nRUN git clone https://github.com/NVIDIA/Megatron-LM.git && \\\n  cd Megatron-LM && \\\n  git checkout ${MCORE_TAG} && \\\n  pip install .\n\n# Performance optimizations for distributed optimizer: https://github.com/NVIDIA/apex/pull/1771\nRUN git clone https://github.com/NVIDIA/apex.git && \\\n  cd apex && \\\n  git checkout ${APEX_TAG} && \\\n  pip install -v --no-build-isolation --disable-pip-version-check --no-cache-dir \\\n    --config-settings \"--build-option=--cpp_ext --cuda_ext --fast_layer_norm --distributed_adam --deprecated_fused_adam\" ./\n\n# Transformer Engine 1.2.0\nRUN git clone https://github.com/NVIDIA/TransformerEngine.git && \\\n  cd TransformerEngine && \\\n  git fetch origin ${TE_TAG} && \\\n  git checkout FETCH_HEAD && \\\n  git submodule init && git submodule update && \\\n  NVTE_FRAMEWORK=pytorch NVTE_WITH_USERBUFFERS=1 MPI_HOME=/usr/local/mpi pip install .\n\nWORKDIR /tmp/\n\n# uninstall stuff from base container\nRUN pip3 uninstall -y sacrebleu torchtext\n\n# build torchaudio\nWORKDIR /tmp/torchaudio_build\nCOPY scripts/installers /tmp/torchaudio_build/scripts/installers/\nRUN INSTALL_MSG=$(/bin/bash /tmp/torchaudio_build/scripts/installers/install_torchaudio_latest.sh); INSTALL_CODE=$?; \\\n  echo ${INSTALL_MSG}; \\\n  if [ ${INSTALL_CODE} -ne 0 ]; then \\\n  echo \"torchaudio installation failed\";  \\\n  if [ \"${REQUIRE_TORCHAUDIO}\" = true ]; then \\\n  exit ${INSTALL_CODE};  \\\n  else echo \"Skipping failed torchaudio installation\"; fi \\\n  else echo \"torchaudio installed successfully\"; fi\n\nCOPY scripts /tmp/nemo/scripts/\n# install correct graphviz version (k2 and pynini visualization tool), skip if installation fails\nRUN INSTALL_MSG=$(/bin/bash /tmp/nemo/scripts/installers/install_graphviz.sh --docker); INSTALL_CODE=$?; \\\n  echo ${INSTALL_MSG}; \\\n  if [ ${INSTALL_CODE} -ne 0 ]; then \\\n  echo \"graphviz installation failed\";  \\\n  if [ \"${REQUIRE_K2}\" = true ]; then \\\n  exit ${INSTALL_CODE};  \\\n  else echo \"Skipping failed graphviz installation\"; fi \\\n  else echo \"graphviz installed successfully\"; fi\n\n# install k2, skip if installation fails\nCOPY scripts /tmp/nemo/scripts/\nRUN INSTALL_MSG=$(/bin/bash /tmp/nemo/scripts/installers/install_k2.sh); INSTALL_CODE=$?; \\\n  echo ${INSTALL_MSG}; \\\n  if [ ${INSTALL_CODE} -ne 0 ]; then \\\n  echo \"k2 installation failed\";  \\\n  if [ \"${REQUIRE_K2}\" = true ]; then \\\n  exit ${INSTALL_CODE};  \\\n  else echo \"Skipping failed k2 installation\"; fi \\\n  else echo \"k2 installed successfully\"; fi\n\n# install nemo dependencies\nWORKDIR /tmp/nemo\nENV LHOTSE_REQUIRE_TORCHAUDIO=0\nCOPY requirements .\n# exclude requirements_vllm.txt, since `vllm==0.5.x` breaks the container due to hardcoded requirements `torch==2.3.0`\nRUN for f in $(ls requirements*.txt | grep -v 'requirements_vllm.txt'); do \\\n    pip3 install --disable-pip-version-check --no-cache-dir -r $f; done\n\n# install flash attention\nRUN pip install flash-attn\n# install numba for latest containers\nRUN pip install numba>=0.57.1\n\n# copy nemo source into a scratch image\nFROM scratch as nemo-src\nCOPY . .\n\n# start building the final container\nFROM nemo-deps as nemo\nARG NEMO_VERSION=2.0.0\n\n# Check that NEMO_VERSION is set. Build will fail without this. Expose NEMO and base container\n# version information as runtime environment variable for introspection purposes\nRUN /usr/bin/test -n \"$NEMO_VERSION\" && \\\n  /bin/echo \"export NEMO_VERSION=${NEMO_VERSION}\" >> /root/.bashrc && \\\n  /bin/echo \"export BASE_IMAGE=${BASE_IMAGE}\" >> /root/.bashrc\n\n# Install NeMo\nRUN --mount=from=nemo-src,target=/tmp/nemo,rw cd /tmp/nemo && pip install \".[all]\"\n\n# Check install\n# NB: adjusting LD_LIBRARY_PATH (only here, should not be persistent!) is a temporary hack\n# to avoid failure if CUDA is unavailable (`docker build` does not expose GPUs)\n# The error is raised in NeMo Core, and the main reason is reinstalled Transformer-Engine;\nRUN export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CUDA_HOME}/compat/lib.real && \\\n  python -c \"import nemo.collections.asr as nemo_asr\" && \\\n  python -c \"import nemo.collections.nlp as nemo_nlp\" && \\\n  python -c \"import nemo.collections.tts as nemo_tts\" && \\\n  python -c \"import nemo_text_processing.text_normalization as text_normalization\"\n\n\n# copy scripts/examples/tests into container for end user\nWORKDIR /workspace/nemo\nCOPY scripts /workspace/nemo/scripts\nCOPY examples /workspace/nemo/examples\nCOPY tests /workspace/nemo/tests\nCOPY tutorials /workspace/nemo/tutorials\n# COPY README.rst LICENSE /workspace/nemo/\n\nRUN printf \"#!/bin/bash\\njupyter lab --no-browser --allow-root --ip=0.0.0.0\" >> start-jupyter.sh && \\\n  chmod +x start-jupyter.sh\n\n# If required, install AIS CLI and Python AIS SDK\nRUN INSTALL_MSG=$(/bin/bash /tmp/nemo/scripts/installers/install_ais_cli_latest.sh && pip install aistore); INSTALL_CODE=$?; \\\n  echo ${INSTALL_MSG}; \\\n  if [ ${INSTALL_CODE} -ne 0 ]; then \\\n  echo \"AIS CLI installation failed\"; \\\n  if [ \"${REQUIRE_AIS_CLI}\" = true ]; then \\\n  exit ${INSTALL_CODE}; \\\n  else echo \"Skipping AIS CLI installation\"; fi \\\n  else echo \"AIS CLI installed successfully\"; fi\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.08984375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.021484375,
          "content": "include requirements/*"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 30.015625,
          "content": "[![Project Status: Active -- The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)\n[![Documentation](https://readthedocs.com/projects/nvidia-nemo/badge/?version=main)](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/)\n[![CodeQL](https://github.com/nvidia/nemo/actions/workflows/codeql.yml/badge.svg?branch=main&event=push)](https://github.com/nvidia/nemo/actions/workflows/codeql.yml)\n[![NeMo core license and license for collections in this repo](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://github.com/NVIDIA/NeMo/blob/master/LICENSE)\n[![Release version](https://badge.fury.io/py/nemo-toolkit.svg)](https://badge.fury.io/py/nemo-toolkit)\n[![Python version](https://img.shields.io/pypi/pyversions/nemo-toolkit.svg)](https://badge.fury.io/py/nemo-toolkit)\n[![PyPi total downloads](https://static.pepy.tech/personalized-badge/nemo-toolkit?period=total&units=international_system&left_color=grey&right_color=brightgreen&left_text=downloads)](https://pepy.tech/project/nemo-toolkit)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n\n# **NVIDIA NeMo Framework**\n\n## Latest News\n\n<!-- markdownlint-disable -->\n<details open>\n  <summary><b>NeMo 2.0</b></summary>\n      We've released NeMo 2.0, an update on the NeMo Framework which prioritizes modularity and ease-of-use. Please refer to the <a href=https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html>NeMo Framework User Guide</a> to get started.\n    </details>\n  </details>\n\n<details open>\n  <summary><b>Large Language Models and Multimodal Models</b></summary>\n      <details>\n      <summary>\n        <a href=\"https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/llama/index.html#new-llama-3-1-support for more information/\">\n        New Llama 3.1 Support\n        </a> (2024-07-23)\n      </summary>\n        The NeMo Framework now supports training and customizing the Llama 3.1 collection of LLMs from Meta.\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://aws.amazon.com/blogs/machine-learning/accelerate-your-generative-ai-distributed-training-workloads-with-the-nvidia-nemo-framework-on-amazon-eks/\">\n          Accelerate your Generative AI Distributed Training Workloads with the NVIDIA NeMo Framework on Amazon EKS\n        </a> (2024-07-16)\n      </summary>\n     NVIDIA NeMo Framework now runs distributed training workloads on an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. For step-by-step instructions on creating an EKS cluster and running distributed training workloads with NeMo, see the GitHub repository <a href=\"https://github.com/aws-samples/awsome-distributed-training/tree/main/3.test_cases/2.nemo-launcher/EKS/\"> here.</a>\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/nvidia-nemo-accelerates-llm-innovation-with-hybrid-state-space-model-support/\">\n          NVIDIA NeMo Accelerates LLM Innovation with Hybrid State Space Model Support\n        </a> (2024/06/17)\n      </summary>\n     NVIDIA NeMo and Megatron Core now support pre-training and fine-tuning of state space models (SSMs). NeMo also supports training models based on the Griffin architecture as described by Google DeepMind. \n      <br><br>\n    </details>\n      <details>\n      <summary>\n        <a href=\"https://huggingface.co/models?sort=trending&search=nvidia%2Fnemotron-4-340B\">\n          NVIDIA releases 340B base, instruct, and reward models pretrained on a total of 9T tokens.\n        </a> (2024-06-18)\n      </summary>\n      See documentation and tutorials for SFT, PEFT, and PTQ with \n      <a href=\"https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/nemotron/index.html\">\n        Nemotron 340B \n      </a>\n      in the NeMo Framework User Guide.\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/nvidia-sets-new-generative-ai-performance-and-scale-records-in-mlperf-training-v4-0/\">\n          NVIDIA sets new generative AI performance and scale records in MLPerf Training v4.0\n        </a> (2024/06/12)\n      </summary>\n      Using NVIDIA NeMo Framework and NVIDIA Hopper GPUs NVIDIA was able to scale to 11,616 H100 GPUs and achieve near-linear performance scaling on LLM pretraining. \n      NVIDIA also achieved the highest LLM fine-tuning performance and raised the bar for text-to-image training.\n      <br><br>\n    </details>\n    <details>\n        <summary>\n          <a href=\"https://cloud.google.com/blog/products/compute/gke-and-nvidia-nemo-framework-to-train-generative-ai-models\">\n            Accelerate your generative AI journey with NVIDIA NeMo Framework on GKE\n          </a> (2024/03/16)\n        </summary>\n        An end-to-end walkthrough to train generative AI models on the Google Kubernetes Engine (GKE) using the NVIDIA NeMo Framework is available at https://github.com/GoogleCloudPlatform/nvidia-nemo-on-gke. \n        The walkthrough includes detailed instructions on how to set up a Google Cloud Project and pre-train a GPT model using the NeMo Framework.\n        <br><br>\n      </details>\n</details>\n\n<details open>\n  <summary><b>Speech Recognition</b></summary>\n  <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/accelerating-leaderboard-topping-asr-models-10x-with-nvidia-nemo/\">\n          Accelerating Leaderboard-Topping ASR Models 10x with NVIDIA NeMo\n        </a> (2024/09/24)\n      </summary>\n      NVIDIA NeMo team released a number of inference optimizations for CTC, RNN-T, and TDT models that resulted in up to 10x inference speed-up. \n      These models now exceed an inverse real-time factor (RTFx) of 2,000, with some reaching RTFx of even 6,000.\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/new-standard-for-speech-recognition-and-translation-from-the-nvidia-nemo-canary-model/\">\n          New Standard for Speech Recognition and Translation from the NVIDIA NeMo Canary Model\n        </a> (2024/04/18)\n      </summary>\n      The NeMo team just released Canary, a multilingual model that transcribes speech in English, Spanish, German, and French with punctuation and capitalization. \n      Canary also provides bi-directional translation, between English and the three other supported languages.\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/pushing-the-boundaries-of-speech-recognition-with-nemo-parakeet-asr-models/\">\n          Pushing the Boundaries of Speech Recognition with NVIDIA NeMo Parakeet ASR Models\n        </a> (2024/04/18)\n      </summary>\n      NVIDIA NeMo, an end-to-end platform for the development of multimodal generative AI models at scale anywhere—on any cloud and on-premises—released the Parakeet family of automatic speech recognition (ASR) models. \n      These state-of-the-art ASR models, developed in collaboration with Suno.ai, transcribe spoken English with exceptional accuracy.\n      <br><br>\n    </details>\n  <details>\n    <summary>\n      <a href=\"https://developer.nvidia.com/blog/turbocharge-asr-accuracy-and-speed-with-nvidia-nemo-parakeet-tdt/\">\n        Turbocharge ASR Accuracy and Speed with NVIDIA NeMo Parakeet-TDT\n      </a> (2024/04/18)\n    </summary>\n    NVIDIA NeMo, an end-to-end platform for developing multimodal generative AI models at scale anywhere—on any cloud and on-premises—recently released Parakeet-TDT. \n    This new addition to the  NeMo ASR Parakeet model family boasts better accuracy and 64% greater speed over the previously best model, Parakeet-RNNT-1.1B.\n    <br><br>\n  </details>\n</details>\n<!-- markdownlint-enable -->\n\n## Introduction\n\nNVIDIA NeMo Framework is a scalable and cloud-native generative AI\nframework built for researchers and PyTorch developers working on Large\nLanguage Models (LLMs), Multimodal Models (MMs), Automatic Speech\nRecognition (ASR), Text to Speech (TTS), and Computer Vision (CV)\ndomains. It is designed to help you efficiently create, customize, and\ndeploy new generative AI models by leveraging existing code and\npre-trained model checkpoints.\n\nFor technical documentation, please see the [NeMo Framework User\nGuide](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html).\n\n## What's New in NeMo 2.0\n\nNVIDIA NeMo 2.0 introduces several significant improvements over its predecessor, NeMo 1.0, enhancing flexibility, performance, and scalability.\n\n- **Python-Based Configuration** - NeMo 2.0 transitions from YAML files to a Python-based configuration, providing more flexibility and control. This shift makes it easier to extend and customize configurations programmatically.\n\n- **Modular Abstractions** - By adopting PyTorch Lightning’s modular abstractions, NeMo 2.0 simplifies adaptation and experimentation. This modular approach allows developers to more easily modify and experiment with different components of their models.\n\n- **Scalability** - NeMo 2.0 seamlessly scaling large-scale experiments across thousands of GPUs using [NeMo-Run](https://github.com/NVIDIA/NeMo-Run), a powerful tool designed to streamline the configuration, execution, and management of machine learning experiments across computing environments.\n\nOverall, these enhancements make NeMo 2.0 a powerful, scalable, and user-friendly framework for AI model development.\n\n> [!IMPORTANT]  \n> NeMo 2.0 is currently supported by the LLM (large language model) and VLM (vision language model) collections.\n\n### Get Started with NeMo 2.0\n\n- Refer to the [Quickstart](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html) for examples of using NeMo-Run to launch NeMo 2.0 experiments locally and on a slurm cluster.\n- For more information about NeMo 2.0, see the [NeMo Framework User Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/index.html).\n- [NeMo 2.0 Recipes](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/recipes) contains additional examples of launching large-scale runs using NeMo 2.0 and NeMo-Run.\n- For an in-depth exploration of the main features of NeMo 2.0, see the [Feature Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/features/index.html#feature-guide).\n- To transition from NeMo 1.0 to 2.0, see the [Migration Guide](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/migration/index.html#migration-guide) for step-by-step instructions.\n\n## LLMs and MMs Training, Alignment, and Customization\n\nAll NeMo models are trained with\n[Lightning](https://github.com/Lightning-AI/lightning). Training is\nautomatically scalable to 1000s of GPUs. You can check the performance benchmarks using the\nlatest NeMo Framework container [here](https://docs.nvidia.com/nemo-framework/user-guide/latest/performance/performance_summary.html).\n\nWhen applicable, NeMo models leverage cutting-edge distributed training\ntechniques, incorporating [parallelism\nstrategies](https://docs.nvidia.com/nemo-framework/user-guide/latest/modeloverview.html)\nto enable efficient training of very large models. These techniques\ninclude Tensor Parallelism (TP), Pipeline Parallelism (PP), Fully\nSharded Data Parallelism (FSDP), Mixture-of-Experts (MoE), and Mixed\nPrecision Training with BFloat16 and FP8, as well as others.\n\nNeMo Transformer-based LLMs and MMs utilize [NVIDIA Transformer\nEngine](https://github.com/NVIDIA/TransformerEngine) for FP8 training on\nNVIDIA Hopper GPUs, while leveraging [NVIDIA Megatron\nCore](https://github.com/NVIDIA/Megatron-LM/tree/main/megatron/core) for\nscaling Transformer model training.\n\nNeMo LLMs can be aligned with state-of-the-art methods such as SteerLM,\nDirect Preference Optimization (DPO), and Reinforcement Learning from\nHuman Feedback (RLHF). See [NVIDIA NeMo\nAligner](https://github.com/NVIDIA/NeMo-Aligner) for more information.\n\nIn addition to supervised fine-tuning (SFT), NeMo also supports the\nlatest parameter efficient fine-tuning (PEFT) techniques such as LoRA,\nP-Tuning, Adapters, and IA3. Refer to the [NeMo Framework User\nGuide](https://docs.nvidia.com/nemo-framework/user-guide/latest/sft_peft/index.html)\nfor the full list of supported models and techniques.\n\n## LLMs and MMs Deployment and Optimization\n\nNeMo LLMs and MMs can be deployed and optimized with [NVIDIA NeMo\nMicroservices](https://developer.nvidia.com/nemo-microservices-early-access).\n\n## Speech AI\n\nNeMo ASR and TTS models can be optimized for inference and deployed for\nproduction use cases with [NVIDIA Riva](https://developer.nvidia.com/riva).\n\n## NeMo Framework Launcher\n\n> [!IMPORTANT]  \n> NeMo Framework Launcher is compatible with NeMo version 1.0 only. [NeMo-Run](https://github.com/NVIDIA/NeMo-Run) is recommended for launching experiments using NeMo 2.0.\n\n[NeMo Framework\nLauncher](https://github.com/NVIDIA/NeMo-Megatron-Launcher) is a\ncloud-native tool that streamlines the NeMo Framework experience. It is\nused for launching end-to-end NeMo Framework training jobs on CSPs and\nSlurm clusters.\n\nThe NeMo Framework Launcher includes extensive recipes, scripts,\nutilities, and documentation for training NeMo LLMs. It also includes\nthe NeMo Framework [Autoconfigurator](https://github.com/NVIDIA/NeMo-Megatron-Launcher#53-using-autoconfigurator-to-find-the-optimal-configuration),\nwhich is designed to find the optimal model parallel configuration for\ntraining on a specific cluster.\n\nTo get started quickly with the NeMo Framework Launcher, please see the\n[NeMo Framework\nPlaybooks](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html).\nThe NeMo Framework Launcher does not currently support ASR and TTS\ntraining, but it will soon.\n\n## Get Started with NeMo Framework\n\nGetting started with NeMo Framework is easy. State-of-the-art pretrained\nNeMo models are freely available on [Hugging Face\nHub](https://huggingface.co/models?library=nemo&sort=downloads&search=nvidia)\nand [NVIDIA\nNGC](https://catalog.ngc.nvidia.com/models?query=nemo&orderBy=weightPopularDESC).\nThese models can be used to generate text or images, transcribe audio,\nand synthesize speech in just a few lines of code.\n\nWe have extensive\n[tutorials](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/starthere/tutorials.html)\nthat can be run on [Google Colab](https://colab.research.google.com) or\nwith our [NGC NeMo Framework\nContainer](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo).\nWe also have\n[playbooks](https://docs.nvidia.com/nemo-framework/user-guide/latest/playbooks/index.html)\nfor users who want to train NeMo models with the NeMo Framework\nLauncher.\n\nFor advanced users who want to train NeMo models from scratch or\nfine-tune existing NeMo models, we have a full suite of [example\nscripts](https://github.com/NVIDIA/NeMo/tree/main/examples) that support\nmulti-GPU/multi-node training.\n\n## Key Features\n\n- [Large Language Models](nemo/collections/nlp/README.md)\n- [Multimodal](nemo/collections/multimodal/README.md)\n- [Automatic Speech Recognition](nemo/collections/asr/README.md)\n- [Text to Speech](nemo/collections/tts/README.md)\n- [Computer Vision](nemo/collections/vision/README.md)\n\n## Requirements\n\n- Python 3.10 or above\n- Pytorch 1.13.1 or above\n- NVIDIA GPU (if you intend to do model training)\n\n## Developer Documentation\n\n| Version | Status                                                                                                                                                              | Description                                                                                                                    |\n| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |\n| Latest  | [![Documentation Status](https://readthedocs.com/projects/nvidia-nemo/badge/?version=main)](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/)     | [Documentation of the latest (i.e. main) branch.](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/)          |\n| Stable  | [![Documentation Status](https://readthedocs.com/projects/nvidia-nemo/badge/?version=stable)](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/) | [Documentation of the stable (i.e. most recent release)](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/) |\n\n## Install NeMo Framework\n\nThe NeMo Framework can be installed in a variety of ways, depending on\nyour needs. Depending on the domain, you may find one of the following\ninstallation methods more suitable.\n\n- Conda / Pip - Refer to [Conda](#conda) and [Pip](#pip) for\n  installation instructions.\n  - This is the recommended method for ASR and TTS domains.\n  - When using a Nvidia PyTorch container as the base, this is the\n      recommended method for all domains.\n- Docker Containers - Refer to [Docker containers](#docker-containers)\n  for installation instructions.\n  - NeMo Framework container -\n      [nvcr.io/nvidia/nemo:24.05]{.title-ref}\n- LLMs and MMs Dependencies - Refer to [LLMs and MMs\n    Dependencies](#install-llms-and-mms-dependencies) for installation\n    instructions.\n\n**Important: We strongly recommended that you start with a base NVIDIA\nPyTorch container: nvcr.io/nvidia/pytorch:24.02-py3.**\n\n### Conda\n\nInstall NeMo in a fresh Conda environment:\n\n```bash\nconda create --name nemo python==3.10.12\nconda activate nemo\n```\n\nInstall PyTorch using their\n[configurator](https://pytorch.org/get-started/locally/):\n\n```bash\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n```\n\nThe command to install PyTorch may depend on your system. Use the\nconfigurator linked above to find the right command for your system.\n\nThen, install NeMo via Pip or from Source. We do not provide NeMo on the\nconda-forge or any other Conda channel.\n\n### Pip\n\nTo install the nemo_toolkit, use the following installation method:\n\n```bash\napt-get update && apt-get install -y libsndfile1 ffmpeg\npip install Cython packaging\npip install nemo_toolkit['all']\n```\n\nDepending on the shell used, you may need to use the\n`\"nemo_toolkit[all]\"` specifier instead in the above command.\n\n### Pip from a Specific Domain\n\nTo install a specific domain of NeMo, you must first install the\nnemo_toolkit using the instructions listed above. Then, you run the\nfollowing domain-specific commands:\n\n```bash\npip install nemo_toolkit['asr']\npip install nemo_toolkit['nlp']\npip install nemo_toolkit['tts']\npip install nemo_toolkit['vision']\npip install nemo_toolkit['multimodal']\n```\n\n### Pip from a Source Branch\n\nIf you want to work with a specific version of NeMo from a particular\nGitHub branch (e.g main), use the following installation method:\n\n```bash\napt-get update && apt-get install -y libsndfile1 ffmpeg\npip install Cython packaging\npython -m pip install git+https://github.com/NVIDIA/NeMo.git@{BRANCH}#egg=nemo_toolkit[all]\n```\n\n### Build from Source\n\nIf you want to clone the NeMo GitHub repository and contribute to NeMo\nopen-source development work, use the following installation method:\n\n```bash\napt-get update && apt-get install -y libsndfile1 ffmpeg\ngit clone https://github.com/NVIDIA/NeMo\ncd NeMo\n./reinstall.sh\n```\n\nIf you only want the toolkit without the additional Conda-based\ndependencies, you can replace `reinstall.sh` with `pip install -e .`\nwhen your PWD is the root of the NeMo repository.\n\n### Mac Computers with Apple Silicon\n\nTo install NeMo on Mac computers with the Apple M-Series GPU, you need\nto create a new Conda environment, install PyTorch 2.0 or higher, and\nthen install the nemo_toolkit.\n\n**Important: This method is only applicable to the ASR domain.**\n\nRun the following code:\n\n```shell\n# [optional] install mecab using Homebrew, to use sacrebleu for NLP collection\n# you can install Homebrew here: https://brew.sh\nbrew install mecab\n\n# [optional] install pynini using Conda, to use text normalization\nconda install -c conda-forge pynini\n\n# install Cython manually\npip install cython packaging\n\n# clone the repo and install in development mode\ngit clone https://github.com/NVIDIA/NeMo\ncd NeMo\npip install 'nemo_toolkit[all]'\n\n# Note that only the ASR toolkit is guaranteed to work on MacBook - so for MacBook use pip install 'nemo_toolkit[asr]'\n```\n\n### Windows Computers\n\nTo install the Windows Subsystem for Linux (WSL), run the following code\nin PowerShell:\n\n```shell\nwsl --install\n# [note] If you run wsl --install and see the WSL help text, it means WSL is already installed.\n```\n\nTo learn more about installing WSL, refer to [Microsoft\\'s official\ndocumentation](https://learn.microsoft.com/en-us/windows/wsl/install).\n\nAfter installing your Linux distribution with WSL, two options are\navailable:\n\n**Option 1:** Open the distribution (Ubuntu by default) from the Start\nmenu and follow the instructions.\n\n**Option 2:** Launch the Terminal application. Download it from\n[Microsoft\\'s Windows Terminal\npage](https://learn.microsoft.com/en-us/windows/terminal) if not\ninstalled.\n\nNext, follow the instructions for Linux systems, as provided above. For\nexample:\n\n```bash\napt-get update && apt-get install -y libsndfile1 ffmpeg\ngit clone https://github.com/NVIDIA/NeMo\ncd NeMo\n./reinstall.sh\n```\n\n### RNNT\n\nFor optimal performance of a Recurrent Neural Network Transducer (RNNT),\ninstall the Numba package from Conda.\n\nRun the following code:\n\n```bash\nconda remove numba\npip uninstall numba\nconda install -c conda-forge numba\n```\n\n## Install LLMs and MMs Dependencies\n\nIf you work with the LLM and MM domains, three additional dependencies\nare required: NVIDIA Apex, NVIDIA Transformer Engine, and NVIDIA\nMegatron Core. When working with the [main]{.title-ref} branch, these\ndependencies may require a recent commit.\n\nThe most recent working versions of these dependencies are here:\n\n```bash\nexport apex_commit=810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c\nexport te_commit=bfe21c3d68b0a9951e5716fb520045db53419c5e\nexport mcore_commit=02871b4df8c69fac687ab6676c4246e936ce92d0\nexport nv_pytorch_tag=24.02-py3\n```\n\nWhen using a released version of NeMo, please refer to the [Software\nComponent\nVersions](https://docs.nvidia.com/nemo-framework/user-guide/latest/softwarecomponentversions.html)\nfor the correct versions.\n\n### PyTorch Container\n\nWe recommended that you start with a base NVIDIA PyTorch container:\nnvcr.io/nvidia/pytorch:24.02-py3.\n\nIf starting with a base NVIDIA PyTorch container, you must first launch\nthe container:\n\n```bash\ndocker run \\\n  --gpus all \\\n  -it \\\n  --rm \\\n  --shm-size=16g \\\n  --ulimit memlock=-1 \\\n  --ulimit stack=67108864 \\\n  nvcr.io/nvidia/pytorch:$nv_pytorch_tag\n```\n\nNext, you need to install the dependencies.\n\n### Apex\n\nNVIDIA Apex is required for LLM and MM domains. Although Apex is\npre-installed in the NVIDIA PyTorch container, you may need to update it\nto a newer version.\n\nTo install Apex, run the following code:\n\n```bash\ngit clone https://github.com/NVIDIA/apex.git\ncd apex\ngit checkout $apex_commit\npip install . -v --no-build-isolation --disable-pip-version-check --no-cache-dir --config-settings \"--build-option=--cpp_ext --cuda_ext --fast_layer_norm --distributed_adam --deprecated_fused_adam --group_norm\"\n```\n\nWhen attempting to install Apex separately from the NVIDIA PyTorch\ncontainer, you might encounter an error if the CUDA version on your\nsystem is different from the one used to compile PyTorch. To bypass this\nerror, you can comment out the relevant line in the setup file located\nin the Apex repository on GitHub here:\n<https://github.com/NVIDIA/apex/blob/master/setup.py#L32>.\n\ncuda-nvprof is needed to install Apex. The version should match the CUDA\nversion that you are using.\n\nTo install cuda-nvprof, run the following code:\n\n```bash\nconda install -c nvidia cuda-nvprof=11.8\n```\n\nFinally, install the packaging:\n\n```bash\npip install packaging\n```\n\nTo install the most recent versions of Apex locally, it might be\nnecessary to remove the [pyproject.toml]{.title-ref} file from the Apex\ndirectory.\n\n### Transformer Engine\n\nNVIDIA Transformer Engine is required for LLM and MM domains. Although\nthe Transformer Engine is pre-installed in the NVIDIA PyTorch container,\nyou may need to update it to a newer version.\n\nThe Transformer Engine facilitates training with FP8 precision on NVIDIA\nHopper GPUs and introduces many enhancements for the training of\nTransformer-based models. Refer to [Transformer Engine](https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/installation.html)\nfor information.\n\nTo install Transformer Engine, run the following code:\n\n```bash\ngit clone https://github.com/NVIDIA/TransformerEngine.git && \\\ncd TransformerEngine && \\\ngit checkout $te_commit && \\\ngit submodule init && git submodule update && \\\nNVTE_FRAMEWORK=pytorch NVTE_WITH_USERBUFFERS=1 MPI_HOME=/usr/local/mpi pip install .\n```\n\nTransformer Engine requires PyTorch to be built with at least CUDA 11.8.\n\n### Megatron Core\n\nMegatron Core is required for LLM and MM domains. Megatron Core is a\nlibrary for scaling large Transformer-based models. NeMo LLMs and MMs\nleverage Megatron Core for model parallelism, transformer architectures,\nand optimized PyTorch datasets.\n\nTo install Megatron Core, run the following code:\n\n```bash\ngit clone https://github.com/NVIDIA/Megatron-LM.git && \\\ncd Megatron-LM && \\\ngit checkout $mcore_commit && \\\npip install . && \\\ncd megatron/core/datasets && \\\nmake\n```\n\n## NeMo Text Processing\n\nNeMo Text Processing, specifically Inverse Text Normalization, is now a\nseparate repository. It is located here:\n<https://github.com/NVIDIA/NeMo-text-processing>.\n\n## Docker Containers\n\nNeMo containers are launched concurrently with NeMo version updates.\nNeMo Framework now supports LLMs, MMs, ASR, and TTS in a single\nconsolidated Docker container. You can find additional information about\nreleased containers on the [NeMo releases\npage](https://github.com/NVIDIA/NeMo/releases).\n\nTo use a pre-built container, run the following code:\n\n```bash\ndocker pull nvcr.io/nvidia/nemo:24.05\n```\n\nTo build a nemo container with Dockerfile from a branch, run the\nfollowing code:\n\n```bash\nDOCKER_BUILDKIT=1 docker build -f Dockerfile -t nemo:latest\n```\n\nIf you choose to work with the main branch, we recommend using NVIDIA\\'s\nPyTorch container version 23.10-py3 and then installing from GitHub.\n\n```bash\ndocker run --gpus all -it --rm -v <nemo_github_folder>:/NeMo --shm-size=8g \\\n-p 8888:8888 -p 6006:6006 --ulimit memlock=-1 --ulimit \\\nstack=67108864 --device=/dev/snd nvcr.io/nvidia/pytorch:23.10-py3\n```\n\n## Future Work\n\nThe NeMo Framework Launcher does not currently support ASR and TTS\ntraining, but it will soon.\n\n## Discussions Board\n\nFAQ can be found on the NeMo [Discussions\nboard](https://github.com/NVIDIA/NeMo/discussions). You are welcome to\nask questions or start discussions on the board.\n\n## Contribute to NeMo\n\nWe welcome community contributions! Please refer to\n[CONTRIBUTING.md](https://github.com/NVIDIA/NeMo/blob/stable/CONTRIBUTING.md)\nfor the process.\n\n## Publications\n\nWe provide an ever-growing list of\n[publications](https://nvidia.github.io/NeMo/publications/) that utilize\nthe NeMo Framework.\n\nTo contribute an article to the collection, please submit a pull request\nto the `gh-pages-src` branch of this repository. For detailed\ninformation, please consult the README located at the [gh-pages-src\nbranch](https://github.com/NVIDIA/NeMo/tree/gh-pages-src#readme).\n\n## Blogs\n\n<!-- markdownlint-disable -->\n<details open>\n  <summary><b>Large Language Models and Multimodal Models</b></summary>\n    <details>\n      <summary>\n        <a href=\"https://blogs.nvidia.com/blog/bria-builds-responsible-generative-ai-using-nemo-picasso/\">\n          Bria Builds Responsible Generative AI for Enterprises Using NVIDIA NeMo, Picasso\n        </a> (2024/03/06)\n      </summary>\n      Bria, a Tel Aviv startup at the forefront of visual generative AI for enterprises now leverages the NVIDIA NeMo Framework. \n      The Bria.ai platform uses reference implementations from the NeMo Multimodal collection, trained on NVIDIA Tensor Core GPUs, to enable high-throughput and low-latency image generation. \n      Bria has also adopted NVIDIA Picasso, a foundry for visual generative AI models, to run inference.\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://developer.nvidia.com/blog/new-nvidia-nemo-framework-features-and-nvidia-h200-supercharge-llm-training-performance-and-versatility/\">\n          New NVIDIA NeMo Framework Features and NVIDIA H200\n        </a> (2023/12/06)\n      </summary>\n      NVIDIA NeMo Framework now includes several optimizations and enhancements, \n      including: \n      1) Fully Sharded Data Parallelism (FSDP) to improve the efficiency of training large-scale AI models, \n      2) Mix of Experts (MoE)-based LLM architectures with expert parallelism for efficient LLM training at scale, \n      3) Reinforcement Learning from Human Feedback (RLHF) with TensorRT-LLM for inference stage acceleration, and \n      4) up to 4.2x speedups for Llama 2 pre-training on NVIDIA H200 Tensor Core GPUs.\n      <br><br>\n      <a href=\"https://developer.nvidia.com/blog/new-nvidia-nemo-framework-features-and-nvidia-h200-supercharge-llm-training-performance-and-versatility\">\n      <img src=\"https://github.com/sbhavani/TransformerEngine/blob/main/docs/examples/H200-NeMo-performance.png\" alt=\"H200-NeMo-performance\" style=\"width: 600px;\"></a>\n      <br><br>\n    </details>\n    <details>\n      <summary>\n        <a href=\"https://blogs.nvidia.com/blog/nemo-amazon-titan/\">\n          NVIDIA now powers training for Amazon Titan Foundation models\n        </a> (2023/11/28)\n      </summary>\n      NVIDIA NeMo Framework now empowers the Amazon Titan foundation models (FM) with efficient training of large language models (LLMs). \n      The Titan FMs form the basis of Amazon’s generative AI service, Amazon Bedrock. \n      The NeMo Framework provides a versatile framework for building, customizing, and running LLMs.\n      <br><br>\n    </details>\n</details>\n<!-- markdownlint-enable -->\n\n## Licenses\n\n- [NeMo GitHub Apache 2.0\n  license](https://github.com/NVIDIA/NeMo?tab=Apache-2.0-1-ov-file#readme)\n- NeMo is licensed under the [NVIDIA AI PRODUCT\n  AGREEMENT](https://www.nvidia.com/en-us/data-center/products/nvidia-ai-enterprise/eula/).\n  By pulling and using the container, you accept the terms and\n  conditions of this license.\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "external",
          "type": "tree",
          "content": null
        },
        {
          "name": "nemo",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 5.3349609375,
          "content": "# Copyright (c) 2023, NVIDIA CORPORATION.  All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n[build-system]\nrequires = [\"setuptools >= 61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"nemo-toolkit\"\ndynamic = [\"dependencies\", \"optional-dependencies\", \"version\"]\ndescription = \"NeMo - a toolkit for Conversational AI\"\nreadme = \"README.md\"\nlicense = {file = \"LICENSE\"}\nrequires-python = \">=3.10\"\nauthors = [{ name = \"NVIDIA\", email = \"nemo-toolkit@nvidia.com\" }]\nmaintainers = [{ name = \"NVIDIA\", email = \"nemo-toolkit@nvidia.com\" }]\nkeywords = [\n    \"NLP\",\n    \"NeMo\",\n    \"deep\",\n    \"gpu\",\n    \"language\",\n    \"learning\",\n    \"learning\",\n    \"machine\",\n    \"nvidia\",\n    \"pytorch\",\n    \"speech\",\n    \"torch\",\n    \"tts\",\n]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Environment :: Console\",\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Information Technology\",\n    \"Intended Audience :: Science/Research\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Natural Language :: English\",\n    \"Operating System :: OS Independent\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    \"Topic :: Scientific/Engineering :: Image Recognition\",\n    \"Topic :: Scientific/Engineering :: Mathematics\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Topic :: Software Development :: Libraries\",\n    \"Topic :: Utilities\",\n]\n\n[tool.setuptools.dynamic]\ndependencies = { file = [\"requirements/requirements.txt\"] }\n\n[tool.setuptools]\npy-modules = [\"nemo\"]\n\n[project.entry-points.\"nemo_run.cli\"]\nllm = \"nemo.collections.llm\"\n\n[project.urls]\nDownload = \"https://github.com/NVIDIA/NeMo/releases\"\nHomepage = \"https://github.com/nvidia/nemo\"\n\n[tool.isort]\nprofile = \"black\"  # black-compatible\nline_length = 119  # should match black parameters\nignore_whitespace = true  # ignore whitespace for compatibility with the initial style\npy_version = 310  # python 3.10 as a target version\nknown_first_party = [\"nemo\"]  # FIRSTPARTY section\nknown_third_party = [\"nemo_text_processing\", \"examples\", \"scripts\"]  # THIRDPARTY section\nsections = [\"FUTURE\", \"STDLIB\", \"THIRDPARTY\", \"FIRSTPARTY\", \"LOCALFOLDER\"]\ndefault_section = \"THIRDPARTY\"\nextend_skip = [\"setup.py\", \"docs/source/conf.py\"]\n\n\n[tool.black]\nline_length = 119\nskip_string_normalization = true\n# major year version is stable, see details in\n# https://black.readthedocs.io/en/stable/the_black_code_style/index.html\n# `required_version` is necessary for consistency (other `black` versions will fail to reformat files)\nrequired_version = \"24\"\ntarget-version = ['py310', 'py311', 'py312']\nextend-exclude = '''\n# A regex preceded with ^/ will apply only to files and directories\n# in the root of the project.\n# include here only current collections, new collections should not be ignored\n# exclude the collection once it is reformatted (due to changes in PRs)\n(\n  ^\\/docs\\/\n  | ^\\/external\\/\n  | ^\\/examples\\/\n  | ^\\/nemo\\/collections\\/asr\\/\n  | ^\\/nemo\\/collections\\/common\\/\n  | ^\\/nemo\\/collections\\/multimodal\\/\n  | ^\\/nemo\\/collections\\/nlp\\/\n  | ^\\/nemo\\/collections\\/tts\\/\n  | ^\\/nemo\\/collections\\/vision\\/\n  | ^\\/nemo\\/core\\/\n  | ^\\/nemo\\/utils\\/\n  | ^\\/scripts\\/\n  | ^\\/tests\\/\n  | ^\\/tools\\/\n  | ^\\/tutorials\\/\n  | ^\\/setup.py\n)\n'''\n\n[tool.pytest.ini_options]\n# durations=0 will display all tests execution time, sorted in ascending order starting from from the slowest one.\n# -vv will also display tests with durration = 0.00s\naddopts = \"--verbose --pyargs --durations=0 --strict-markers\"  # always add these arguments to pytest\ntestpaths = [\"tests\"]\n# directories to ignore when discovering tests\nnorecursedirs = [\n    \"nemo\",\n    \"nemo_text_processing\",\n    \"external\",\n    \"examples\",\n    \"docs\",\n    \"scripts\",\n    \"tools\",\n    \"tutorials\",\n    \"*.egg\",\n    \".*\",\n    \"_darcs\",\n    \"build\",\n    \"CVS\",\n    \"dist\",\n    \"venv\",\n    \"{arch}\"\n]\n# markers to select tests, use `pytest --markers` to see all available markers, `pytest -m \"<marker>\"` to select tests\nmarkers = [\n    \"unit: marks unit test, i.e. testing a single, well isolated functionality (deselect with '-m \\\"not unit\\\"')\",\n    \"integration: marks test checking the elements when integrated into subsystems (deselect with '-m \\\"not integration\\\"')\",\n    \"system: marks test working at the highest integration level (deselect with '-m \\\"not system\\\"')\",\n    \"acceptance: marks test checking whether the developed product/model passes the user defined acceptance criteria (deselect with '-m \\\"not acceptance\\\"')\",\n    \"docs: mark tests related to documentation (deselect with '-m \\\"not docs\\\"')\",\n    \"skipduringci: marks tests that are skipped ci as they are addressed by Jenkins jobs but should be run to test user setups\",\n    \"pleasefixme: marks tests that are broken and need fixing\",\n]\n"
        },
        {
          "name": "reinstall.sh",
          "type": "blob",
          "size": 0.931640625,
          "content": "#!/usr/bin/env bash\nset -e\n\nINSTALL_OPTION=${1:-\"dev\"}\n\nPIP=pip\n\n${PIP} install -U ${PIP}\n\necho 'Uninstalling stuff'\n${PIP} uninstall -y nemo_toolkit\n${PIP} uninstall -y sacrebleu\n\n# Kept for legacy purposes\n${PIP} uninstall -y nemo_asr\n${PIP} uninstall -y nemo_nlp\n${PIP} uninstall -y nemo_tts\n\nif [ -n \"${NVIDIA_PYTORCH_VERSION}\" ]; then\n  echo 'Installing NeMo in NVIDIA PyTorch container:' \"${NVIDIA_PYTORCH_VERSION}\" 'so will not install numba'\nelse\n  if [ -n \"${CONDA_PREFIX}\" ]; then\n    NUMBA_VERSION=0.57.1\n    echo 'Installing numba=='${NUMBA_VERSION}\n    conda install -y -c conda-forge numba==${NUMBA_VERSION}\n  fi\nfi\n\necho 'Installing nemo'\nif [[ \"$INSTALL_OPTION\" == \"dev\" ]]; then\n    ${PIP} install --editable \".[all]\"\nelse\n    rm -rf dist/\n    ${PIP} install build pytest-runner\n    python -m build --no-isolation --wheel\n    DIST_FILE=$(find ./dist -name \"*.whl\" | head -n 1)\n    ${PIP} install \"${DIST_FILE}[all]\"\nfi\n\necho 'All done!'\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 8.93359375,
          "content": "# ! /usr/bin/python\n# -*- coding: utf-8 -*-\n\n# Copyright (c) 2020, NVIDIA CORPORATION.  All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Setup for pip package.\"\"\"\n\nimport codecs\nimport importlib.util\nimport os\nimport subprocess\nfrom distutils import cmd as distutils_cmd\nfrom distutils import log as distutils_log\nfrom itertools import chain\n\nimport setuptools\n\nspec = importlib.util.spec_from_file_location('package_info', 'nemo/package_info.py')\npackage_info = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(package_info)\n\n\n__contact_emails__ = package_info.__contact_emails__\n__contact_names__ = package_info.__contact_names__\n__description__ = package_info.__description__\n__download_url__ = package_info.__download_url__\n__homepage__ = package_info.__homepage__\n__keywords__ = package_info.__keywords__\n__license__ = package_info.__license__\n__package_name__ = package_info.__package_name__\n__repository_url__ = package_info.__repository_url__\n__version__ = package_info.__version__\n\n\nwith open(\"README.md\", \"r\", encoding='utf-8') as fh:\n    long_description = fh.read()\n    long_description_content_type = \"text/markdown\"\n\n\n###############################################################################\n#                             Dependency Loading                              #\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n\ndef req_file(filename, folder=\"requirements\"):\n    with open(os.path.join(folder, filename), encoding='utf-8') as f:\n        content = f.readlines()\n    # you may also want to remove whitespace characters\n    # Example: `\\n` at the end of each line\n    return [x.strip() for x in content]\n\n\ninstall_requires = req_file(\"requirements.txt\")\n\nextras_require = {\n    # User packages\n    'test': req_file(\"requirements_test.txt\"),\n    # Lightning Collections Packages\n    'core': req_file(\"requirements_lightning.txt\"),\n    'common': req_file('requirements_common.txt'),\n    # domain packages\n    'asr': req_file(\"requirements_asr.txt\"),\n    'nlp': req_file(\"requirements_nlp.txt\"),\n    'tts': req_file(\"requirements_tts.txt\"),\n    'slu': req_file(\"requirements_slu.txt\"),\n    'multimodal': req_file(\"requirements_multimodal.txt\"),\n    'audio': req_file(\"requirements_audio.txt\"),\n    'deploy': req_file(\"requirements_deploy.txt\"),\n}\n\n\nextras_require['all'] = list(chain(*extras_require.values()))\n\n# Add lightning requirements as needed\nextras_require['common'] = list(chain(extras_require['common'], extras_require['core']))\nextras_require['test'] = list(\n    chain(\n        extras_require['tts'],\n        extras_require['core'],\n        extras_require['common'],\n    )\n)\nextras_require['asr'] = list(chain(extras_require['asr'], extras_require['core'], extras_require['common']))\nextras_require['nlp'] = list(\n    chain(\n        extras_require['nlp'],\n        extras_require['core'],\n        extras_require['common'],\n    )\n)\nextras_require['tts'] = list(\n    chain(\n        extras_require['tts'],\n        extras_require['core'],\n        extras_require['common'],\n    )\n)\nextras_require['multimodal'] = list(\n    chain(\n        extras_require['multimodal'],\n        extras_require['nlp'],\n        extras_require['core'],\n        extras_require['common'],\n    )\n)\nextras_require['audio'] = list(chain(extras_require['audio'], extras_require['core'], extras_require['common']))\n\n# TTS has extra dependencies\nextras_require['tts'] = list(chain(extras_require['tts'], extras_require['asr']))\n\nextras_require['slu'] = list(chain(extras_require['slu'], extras_require['asr']))\n\n\n###############################################################################\n#                            Code style checkers                              #\n# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% #\n\n\nclass StyleCommand(distutils_cmd.Command):\n    __ISORT_BASE = 'isort'\n    __BLACK_BASE = 'black'\n    description = 'Checks overall project code style.'\n    user_options = [\n        ('scope=', None, 'Folder of file to operate within.'),\n        ('fix', None, 'True if tries to fix issues in-place.'),\n    ]\n\n    def __call_checker(self, base_command, scope, check):\n        command = list(base_command)\n\n        command.append(scope)\n\n        if check:\n            command.extend(['--check', '--diff'])\n\n        self.announce(\n            msg='Running command: %s' % str(' '.join(command)),\n            level=distutils_log.INFO,\n        )\n\n        return_code = subprocess.call(command)\n\n        return return_code\n\n    def _isort(self, scope, check):\n        return self.__call_checker(\n            base_command=self.__ISORT_BASE.split(),\n            scope=scope,\n            check=check,\n        )\n\n    def _black(self, scope, check):\n        return self.__call_checker(\n            base_command=self.__BLACK_BASE.split(),\n            scope=scope,\n            check=check,\n        )\n\n    def _pass(self):\n        self.announce(msg='\\033[32mPASS\\x1b[0m', level=distutils_log.INFO)\n\n    def _fail(self):\n        self.announce(msg='\\033[31mFAIL\\x1b[0m', level=distutils_log.INFO)\n\n    # noinspection PyAttributeOutsideInit\n    def initialize_options(self):\n        self.scope = '.'\n        self.fix = ''\n\n    def run(self):\n        scope, check = self.scope, not self.fix\n        isort_return = self._isort(scope=scope, check=check)\n        black_return = self._black(scope=scope, check=check)\n\n        if isort_return == 0 and black_return == 0:\n            self._pass()\n        else:\n            self._fail()\n            exit(isort_return if isort_return != 0 else black_return)\n\n    def finalize_options(self):\n        pass\n\n\n###############################################################################\n\nsetuptools.setup(\n    name=__package_name__,\n    # Versions should comply with PEP440.  For a discussion on single-sourcing\n    # the version across setup.py and the project code, see\n    # https://packaging.python.org/en/latest/single_source_version.html\n    version=__version__,\n    description=__description__,\n    long_description=long_description,\n    long_description_content_type=long_description_content_type,\n    # The project's main homepage.\n    url=__repository_url__,\n    download_url=__download_url__,\n    # Author details\n    author=__contact_names__,\n    author_email=__contact_emails__,\n    # maintainer Details\n    maintainer=__contact_names__,\n    maintainer_email=__contact_emails__,\n    # The licence under which the project is released\n    license=__license__,\n    classifiers=[\n        # How mature is this project? Common values are\n        #  1 - Planning\n        #  2 - Pre-Alpha\n        #  3 - Alpha\n        #  4 - Beta\n        #  5 - Production/Stable\n        #  6 - Mature\n        #  7 - Inactive\n        'Development Status :: 5 - Production/Stable',\n        # Indicate who your project is intended for\n        'Intended Audience :: Developers',\n        'Intended Audience :: Science/Research',\n        'Intended Audience :: Information Technology',\n        # Indicate what your project relates to\n        'Topic :: Scientific/Engineering',\n        'Topic :: Scientific/Engineering :: Mathematics',\n        'Topic :: Scientific/Engineering :: Image Recognition',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'Topic :: Software Development :: Libraries',\n        'Topic :: Software Development :: Libraries :: Python Modules',\n        'Topic :: Utilities',\n        # Pick your license as you wish (should match \"license\" above)\n        'License :: OSI Approved :: Apache Software License',\n        # Supported python versions\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.10',\n        # Additional Setting\n        'Environment :: Console',\n        'Natural Language :: English',\n        'Operating System :: OS Independent',\n    ],\n    packages=setuptools.find_packages(),\n    python_requires='>=3.10',\n    install_requires=install_requires,\n    # List additional groups of dependencies here (e.g. development\n    # dependencies). You can install these using the following syntax,\n    # $ pip install -e \".[all]\"\n    # $ pip install nemo_toolkit[all]\n    extras_require=extras_require,\n    # Add in any packaged data.\n    include_package_data=True,\n    exclude=['tools', 'tests'],\n    package_data={'': ['*.tsv', '*.txt', '*.far', '*.fst', '*.cpp', 'Makefile']},\n    zip_safe=False,\n    # PyPI package information.\n    keywords=__keywords__,\n    # Custom commands.\n    cmdclass={'style': StyleCommand},\n    entry_points={\n        \"nemo_run.cli\": [\n            \"llm = nemo.collections.llm\",\n        ],\n    },\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "tutorials",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}