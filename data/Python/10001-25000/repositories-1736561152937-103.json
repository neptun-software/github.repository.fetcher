{
  "metadata": {
    "timestamp": 1736561152937,
    "page": 103,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjExMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "spotify/luigi",
      "stars": 18011,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.27734375,
          "content": "[report]\nomit =\n    luigi/mrrunner.py\n    test/_test_time_generated_module*.py\n    */python?.?/*\n    */site-packages/nose/*\n    *__init__*\n    *test/*\n    */.tox/*\n    */setup.py\n    */bin/luigidc\n    hadoop_test.py\n    minicluster.py\n\n[run]\nparallel=True\nconcurrency=multiprocessing\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.275390625,
          "content": ".coverage.*\ndoc/api/*.rst\ntest/gcloud-credentials.json\n.hypothesis/\n\n.nicesetup\n\nclient.cfg\nluigi.cfg\n\nhadoop_test.py\nminicluster.py\nmrrunner.py\npig_property_file\n\npackages.tar\n\n# Ignore the data files\ndata\ntest/data\nexamples/data\n\nVagrantfile\n\n*.pickle\n*.rej\n*.orig\n\n# Created by https://www.gitignore.io\n\n### Python ###\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n# NOTE : lib/ prevents inclusion of static/visualiser/lib\n#lib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\nmy_dir\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndoc/_build/\n\n# PyBuilder\ntarget/\n\n\n### Vim ###\n[._]*.s[a-w][a-z]\n[._]s[a-w][a-z]\n*.un~\nSession.vim\n.netrwhist\n*~\n\n\n### PyCharm ###\n# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm\n\n*.iml\n\n## Directory-based project format:\n.idea/\n# if you remove the above rule, at least ignore the following:\n\n# User-specific stuff:\n# .idea/workspace.xml\n# .idea/tasks.xml\n# .idea/dictionaries\n\n# Sensitive or high-churn files:\n# .idea/dataSources.ids\n# .idea/dataSources.xml\n# .idea/sqlDataSources.xml\n# .idea/dynamic.xml\n# .idea/uiDesigner.xml\n\n# Gradle:\n# .idea/gradle.xml\n# .idea/libraries\n\n# Mongo Explorer plugin:\n# .idea/mongoSettings.xml\n\n## File-based project format:\n*.ipr\n*.iws\n\n## Plugin-specific files:\n\n# IntelliJ\nout/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\n\n\n### Vagrant ###\n.vagrant/\n\n\n### OSX ###\n.DS_Store\n.AppleDouble\n.LSOverride\n\n# Icon must end with two \\r\nIcon\n\n\n# Thumbnails\n._*\n\n# Files that might appear on external disk\n.Spotlight-V100\n.Trashes\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.177734375,
          "content": "version: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.9\"\n\nsphinx:\n  configuration: doc/conf.py\n\nformats:\n  - pdf\n  - epub\n\npython:\n  install:\n    - method: pip\n      path: .\n"
        },
        {
          "name": "CONTRIBUTING.rst",
          "type": "blob",
          "size": 2.11328125,
          "content": "Code of conduct\n---------------\n\nThis project adheres to the `Open Code of Conduct \n<https://github.com/spotify/code-of-conduct/blob/master/code-of-conduct.md>`_.  By \nparticipating, you are expected to honor this code.\n\nRunning the tests\n-----------------\n\n\nWe are always happy to receive Pull Requests. When you open a PR, it will\nautomatically build on Travis. So you're not strictly required to test the\npatch locally before submitting it.\n\nIf you do want to run the tests locally you'll need to ``pip install tox`` and\nthen run one of the tox commands below.\n\nYou will need a ``tox --version`` of at least 2.0.\n\n.. code:: bash\n\n    # These commands are pretty fast and will tell if you've\n    # broken something major:\n    tox -e flake8\n    tox -e py37-core\n\n    # You can also test particular files for even faster iterations\n    tox -e py37-core test/rpc_test.py\n\n    # The visualiser tests require phantomjs to be installed on your path\n    tox -e visualiser\n\n    # And some of the others involve downloading and running Hadoop:\n    tox -e py33-cdh\n    tox -e py34-hdp\n\nWhere ``flake8`` is the lint checking, ``py37`` is obviously Python 3.7.\n``core`` are tests that do not require external components and ``cdh`` and\n``hdp`` are two different hadoop distributions. For most local development it's\nusually enough to run the lint checking and a python version for ``core``\nand let Travis run for the whole matrix.\n\nFor `cdh` and `hdp`, tox will download the hadoop distribution for you. You\nhowever have to have Java installed and the `JAVA_HOME` environment variable\nset.\n\nFor more details, check out the ``.travis.yml`` and ``tox.ini`` files.\n\nWriting documentation\n=====================\n\nAll documentation for Luigi is written in `reStructuredText/Sphinx markup\n<http://sphinx-doc.org/domains.html#the-python-domain>`_ and are both in the\ncode as docstrings and in `.rst`. Pull requests should come with documentation\nwhen appropriate.\n\nYou verify that your documentation code compiles by running\n\n.. code:: bash\n\n    tox -e docs\n\nAfter that, you can check how it renders locally with your browser\n\n.. code:: bash\n\n    firefox doc/_build/html/index.html\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0791015625,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2012-2021 Spotify AB\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.13671875,
          "content": "include README.rst\ninclude LICENSE\ninclude examples/*.py\ninclude test/*.py\nrecursive-include luigi/static *\ninclude luigi/templates/*.html\n\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 12.6904296875,
          "content": ".. figure:: https://raw.githubusercontent.com/spotify/luigi/master/doc/luigi.png\n   :alt: Luigi Logo\n   :align: center\n\n.. image:: https://img.shields.io/endpoint.svg?url=https%3A%2F%2Factions-badge.atrox.dev%2Fspotify%2Fluigi%2Fbadge&label=build&logo=none&%3Fref%3Dmaster&style=flat\n    :target: https://actions-badge.atrox.dev/spotify/luigi/goto?ref=master\n\n.. image:: https://img.shields.io/codecov/c/github/spotify/luigi/master.svg?style=flat\n    :target: https://codecov.io/gh/spotify/luigi?branch=master\n\n.. image:: https://img.shields.io/pypi/v/luigi.svg?style=flat\n   :target: https://pypi.python.org/pypi/luigi\n\n.. image:: https://img.shields.io/pypi/l/luigi.svg?style=flat\n   :target: https://pypi.python.org/pypi/luigi\n\n.. image:: https://readthedocs.org/projects/luigi/badge/?version=stable\n    :target: https://luigi.readthedocs.io/en/stable/?badge=stable\n    :alt: Documentation Status\n\nLuigi is a Python (3.7, 3.8, 3.9, 3.10, 3.11, 3.12 tested) package that helps you build complex\npipelines of batch jobs. It handles dependency resolution, workflow management,\nvisualization, handling failures, command line integration, and much more.\n\nGetting Started\n---------------\n\nRun ``pip install luigi`` to install the latest stable version from `PyPI\n<https://pypi.python.org/pypi/luigi>`_. `Documentation for the latest release\n<https://luigi.readthedocs.io/en/stable/>`__ is hosted on readthedocs.\n\nRun ``pip install luigi[toml]`` to install Luigi with `TOML-based configs\n<https://luigi.readthedocs.io/en/stable/configuration.html>`__ support.\n\nFor the bleeding edge code, ``pip install\ngit+https://github.com/spotify/luigi.git``. `Bleeding edge documentation\n<https://luigi.readthedocs.io/en/latest/>`__ is also available.\n\nBackground\n----------\n\nThe purpose of Luigi is to address all the plumbing typically associated\nwith long-running batch processes. You want to chain many tasks,\nautomate them, and failures *will* happen. These tasks can be anything,\nbut are typically long running things like\n`Hadoop <http://hadoop.apache.org/>`_ jobs, dumping data to/from\ndatabases, running machine learning algorithms, or anything else.\n\nThere are other software packages that focus on lower level aspects of\ndata processing, like `Hive <http://hive.apache.org/>`__,\n`Pig <http://pig.apache.org/>`_, or\n`Cascading <http://www.cascading.org/>`_. Luigi is not a framework to\nreplace these. Instead it helps you stitch many tasks together, where\neach task can be a `Hive query <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.hive.html>`__,\na `Hadoop job in Java <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.hadoop_jar.html>`_,\na  `Spark job in Scala or Python <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.spark.html>`_,\na Python snippet,\n`dumping a table <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.sqla.html>`_\nfrom a database, or anything else. It's easy to build up\nlong-running pipelines that comprise thousands of tasks and take days or\nweeks to complete. Luigi takes care of a lot of the workflow management\nso that you can focus on the tasks themselves and their dependencies.\n\nYou can build pretty much any task you want, but Luigi also comes with a\n*toolbox* of several common task templates that you use. It includes\nsupport for running\n`Python mapreduce jobs <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.hadoop.html>`_\nin Hadoop, as well as\n`Hive <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.hive.html>`__,\nand `Pig <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.pig.html>`__,\njobs. It also comes with\n`file system abstractions for HDFS <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.hdfs.html>`_,\nand local files that ensures all file system operations are atomic. This\nis important because it means your data pipeline will not crash in a\nstate containing partial data.\n\nVisualiser page\n---------------\n\nThe Luigi server comes with a web interface too, so you can search and filter\namong all your tasks.\n\n.. figure:: https://raw.githubusercontent.com/spotify/luigi/master/doc/visualiser_front_page.png\n   :alt: Visualiser page\n\nDependency graph example\n------------------------\n\nJust to give you an idea of what Luigi does, this is a screen shot from\nsomething we are running in production. Using Luigi's visualiser, we get\na nice visual overview of the dependency graph of the workflow. Each\nnode represents a task which has to be run. Green tasks are already\ncompleted whereas yellow tasks are yet to be run. Most of these tasks\nare Hadoop jobs, but there are also some things that run locally and\nbuild up data files.\n\n.. figure:: https://raw.githubusercontent.com/spotify/luigi/master/doc/user_recs.png\n   :alt: Dependency graph\n\nPhilosophy\n----------\n\nConceptually, Luigi is similar to `GNU\nMake <http://www.gnu.org/software/make/>`_ where you have certain tasks\nand these tasks in turn may have dependencies on other tasks. There are\nalso some similarities to `Oozie <http://oozie.apache.org/>`_\nand `Azkaban <https://azkaban.github.io/>`_. One major\ndifference is that Luigi is not just built specifically for Hadoop, and\nit's easy to extend it with other kinds of tasks.\n\nEverything in Luigi is in Python. Instead of XML configuration or\nsimilar external data files, the dependency graph is specified *within\nPython*. This makes it easy to build up complex dependency graphs of\ntasks, where the dependencies can involve date algebra or recursive\nreferences to other versions of the same task. However, the workflow can\ntrigger things not in Python, such as running\n`Pig scripts <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.pig.html>`_\nor `scp'ing files <https://luigi.readthedocs.io/en/latest/api/luigi.contrib.ssh.html>`_.\n\nWho uses Luigi?\n---------------\n\nWe use Luigi internally at `Spotify <https://www.spotify.com>`_ to run\nthousands of tasks every day, organized in complex dependency graphs.\nMost of these tasks are Hadoop jobs. Luigi provides an infrastructure\nthat powers all kinds of stuff including recommendations, toplists, A/B\ntest analysis, external reports, internal dashboards, etc.\n\nSince Luigi is open source and without any registration walls, the exact number\nof Luigi users is unknown. But based on the number of unique contributors, we\nexpect hundreds of enterprises to use it. Some users have written blog posts\nor held presentations about Luigi:\n\n* `Spotify <https://www.spotify.com>`_ `(presentation, 2014) <http://www.slideshare.net/erikbern/luigi-presentation-nyc-data-science>`__\n* `Foursquare <https://foursquare.com/>`_ `(presentation, 2013) <http://www.slideshare.net/OpenAnayticsMeetup/luigi-presentation-17-23199897>`__\n* `Mortar Data (Datadog) <https://www.datadoghq.com/>`_ `(documentation / tutorial) <http://help.mortardata.com/technologies/luigi>`__\n* `Stripe <https://stripe.com/>`_ `(presentation, 2014) <http://www.slideshare.net/PyData/python-as-part-of-a-production-machine-learning-stack-by-michael-manapat-pydata-sv-2014>`__\n* `Buffer <https://buffer.com/>`_ `(blog, 2014) <https://buffer.com/resources/buffers-new-data-architecture/>`__\n* `SeatGeek <https://seatgeek.com/>`_ `(blog, 2015) <http://chairnerd.seatgeek.com/building-out-the-seatgeek-data-pipeline/>`__\n* `Treasure Data <https://www.treasuredata.com/>`_ `(blog, 2015) <http://blog.treasuredata.com/blog/2015/02/25/managing-the-data-pipeline-with-git-luigi/>`__\n* `Growth Intelligence <http://growthintel.com/>`_ `(presentation, 2015) <http://www.slideshare.net/growthintel/a-beginners-guide-to-building-data-pipelines-with-luigi>`__\n* `AdRoll <https://www.adroll.com/>`_ `(blog, 2015) <http://tech.adroll.com/blog/data/2015/09/22/data-pipelines-docker.html>`__\n* 17zuoye `(presentation, 2015) <https://speakerdeck.com/mvj3/luiti-an-offline-task-management-framework>`__\n* `Custobar <https://www.custobar.com/>`_ `(presentation, 2016) <http://www.slideshare.net/teemukurppa/managing-data-workflows-with-luigi>`__\n* `Blendle <https://launch.blendle.com/>`_ `(presentation) <http://www.anneschuth.nl/wp-content/uploads/sea-anneschuth-streamingblendle.pdf#page=126>`__\n* `TrustYou <http://www.trustyou.com/>`_ `(presentation, 2015) <https://speakerdeck.com/mfcabrera/pydata-berlin-2015-processing-hotel-reviews-with-python>`__\n* `Groupon <https://www.groupon.com/>`_ / `OrderUp <https://orderup.com>`_ `(alternative implementation) <https://github.com/groupon/luigi-warehouse>`__\n* `Red Hat - Marketing Operations <https://www.redhat.com>`_ `(blog, 2017) <https://github.com/rh-marketingops/rh-mo-scc-luigi>`__\n* `GetNinjas <https://www.getninjas.com.br/>`_ `(blog, 2017) <https://labs.getninjas.com.br/using-luigi-to-create-and-monitor-pipelines-of-batch-jobs-eb8b3cd2a574>`__\n* `voyages-sncf.com <https://www.voyages-sncf.com/>`_ `(presentation, 2017) <https://github.com/voyages-sncf-technologies/meetup-afpy-nantes-luigi>`__\n* `Open Targets <https://www.opentargets.org/>`_ `(blog, 2017) <https://blog.opentargets.org/using-containers-with-luigi>`__\n* `Leipzig University Library <https://ub.uni-leipzig.de>`_ `(presentation, 2016) <https://de.slideshare.net/MartinCzygan/build-your-own-discovery-index-of-scholary-eresources>`__ / `(project) <https://finc.info/de/datenquellen>`__\n* `Synetiq <https://synetiq.net/>`_ `(presentation, 2017) <https://www.youtube.com/watch?v=M4xUQXogSfo>`__\n* `Glossier <https://www.glossier.com/>`_ `(blog, 2018) <https://medium.com/glossier/how-to-build-a-data-warehouse-what-weve-learned-so-far-at-glossier-6ff1e1783e31>`__\n* `Data Revenue <https://www.datarevenue.com/>`_ `(blog, 2018) <https://www.datarevenue.com/en/blog/how-to-scale-your-machine-learning-pipeline>`_\n* `Uppsala University <http://pharmb.io>`_ `(tutorial) <http://uppnex.se/twiki/do/view/Courses/EinfraMPS2015/Luigi.html>`_   / `(presentation, 2015) <https://www.youtube.com/watch?v=f26PqSXZdWM>`_ / `(slides, 2015) <https://www.slideshare.net/SamuelLampa/building-workflows-with-spotifys-luigi>`_ / `(poster, 2015) <https://pharmb.io/poster/2015-sciluigi/>`_ / `(paper, 2016) <https://doi.org/10.1186/s13321-016-0179-6>`_ / `(project) <https://github.com/pharmbio/sciluigi>`_\n* `GIPHY <https://giphy.com/>`_ `(blog, 2019) <https://engineering.giphy.com/luigi-the-10x-plumber-containerizing-scaling-luigi-in-kubernetes/>`__\n* `xtream <https://xtreamers.io/>`__ `(blog, 2019) <https://towardsdatascience.com/lessons-from-a-real-machine-learning-project-part-1-from-jupyter-to-luigi-bdfd0b050ca5>`__\n* `CIAN <https://cian.ru/>`__ `(presentation, 2019) <https://www.highload.ru/moscow/2019/abstracts/6030>`__\n\nSome more companies are using Luigi but haven't had a chance yet to write about it:\n\n* `Schibsted <http://www.schibsted.com/>`_\n* `enbrite.ly <http://enbrite.ly/>`_\n* `Dow Jones / The Wall Street Journal <http://wsj.com>`_\n* `Hotels.com <https://hotels.com>`_\n* `Newsela <https://newsela.com>`_\n* `Squarespace <https://www.squarespace.com/>`_\n* `OAO <https://adops.com/>`_\n* `Grovo <https://grovo.com/>`_\n* `Weebly <https://www.weebly.com/>`_\n* `Deloitte <https://www.Deloitte.co.uk/>`_\n* `Stacktome <https://stacktome.com/>`_\n* `LINX+Neemu+Chaordic <https://www.chaordic.com.br/>`_\n* `Foxberry <https://www.foxberry.com/>`_\n* `Okko <https://okko.tv/>`_\n* `ISVWorld <http://isvworld.com/>`_\n* `Big Data <https://bigdata.com.br/>`_\n* `Movio <https://movio.co.nz/>`_\n* `Bonnier News <https://www.bonniernews.se/>`_\n* `Starsky Robotics <https://www.starsky.io/>`_\n* `BaseTIS <https://www.basetis.com/>`_\n* `Hopper <https://www.hopper.com/>`_\n* `VOYAGE GROUP/Zucks <https://zucks.co.jp/en/>`_\n* `Textpert <https://www.textpert.ai/>`_\n* `Tracktics <https://www.tracktics.com/>`_\n* `Whizar <https://www.whizar.com/>`_\n* `xtream <https://www.xtreamers.io/>`__\n* `Skyscanner <https://www.skyscanner.net/>`_\n* `Jodel <https://www.jodel.com/>`_\n* `Mekar <https://mekar.id/en/>`_\n* `M3 <https://corporate.m3.com/en/>`_\n* `Assist Digital <https://www.assistdigital.com/>`_\n* `Meltwater <https://www.meltwater.com/>`_\n* `DevSamurai <https://www.devsamurai.com/>`_\n* `Veridas <https://veridas.com/>`_\n* `Aidentified <https://www.aidentified.com/>`_\n\nWe're more than happy to have your company added here. Just send a PR on GitHub.\n\nExternal links\n--------------\n\n* `Mailing List <https://groups.google.com/d/forum/luigi-user/>`_ for discussions and asking questions. (Google Groups)\n* `Releases <https://pypi.python.org/pypi/luigi>`_ (PyPI)\n* `Source code <https://github.com/spotify/luigi>`_ (GitHub)\n* `Hubot Integration <https://github.com/houzz/hubot-luigi>`_ plugin for Slack, Hipchat, etc (GitHub)\n\nAuthors\n-------\n\nLuigi was built at `Spotify <https://www.spotify.com>`_, mainly by\n`Erik Bernhardsson <https://github.com/erikbern>`_ and\n`Elias Freider <https://github.com/freider>`_.\n`Many other people <https://github.com/spotify/luigi/graphs/contributors>`_\nhave contributed since open sourcing in late 2012.\n`Arash Rouhani <https://github.com/tarrasch>`_ was the chief maintainer from 2015 to 2019, and now\nSpotify's Data Team maintains Luigi.\n"
        },
        {
          "name": "RELEASE-PROCESS.rst",
          "type": "blob",
          "size": 1.0166015625,
          "content": "For maintainers of Luigi, who have push access to pypi. Here's how you upload\nLuigi to pypi.\n\n#. Make sure [twine](https://pypi.org/project/twine/) is installed ``pip install twine``.\n#. Update version number in `luigi/__meta__.py`.\n#. Commit, perhaps simply with a commit message like ``Version x.y.z``.\n#. Push to GitHub at [spotify/luigi](https://github.com/spotify/luigi).\n#. Clean up previous distributions by executing ``rm -rf dist``\n#. Build a source distribution by executing ``python setup.py sdist``\n#. Upload to pypi by executing ``twine upload dist/*``\n#. Add a tag on github (https://github.com/spotify/luigi/releases),\n   including a handwritten changelog, possibly inspired from previous notes.\n\nCurrently, Luigi is not released on any particular schedule and it is not\nstrictly abiding semantic versioning. Whenever possible, bump major version when you make incompatible API changes, minor version when you add functionality in a backwards compatible manner, and patch version when you make backwards compatible bug fixes.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.2587890625,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease report sensitive security issues via Spotify's [bug-bounty program](https://hackerone.com/spotify) by following this [instruction](https://docs.hackerone.com/programs/security-page.html), rather than GitHub. \n"
        },
        {
          "name": "bin",
          "type": "tree",
          "content": null
        },
        {
          "name": "catalog-info.yaml",
          "type": "blob",
          "size": 0.109375,
          "content": "apiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: luigi\nspec:\n  type: library\n  owner: dataex\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 1.009765625,
          "content": "codecov:\n  require_ci_to_pass: yes\n  notify:\n    after_n_builds: 24\n    wait_for_ci: yes\n\ncoverage:\n  precision: 2  # Just copied from default\n  round: down  # Just copied from default\n  range: \"70...100\"  # Just copied from default\n\n  status:\n    project:\n      default: false  # disable the default status that measures entire project\n      core:\n        target: 92%\n        paths: \"luigi/*.py\" \n    patch:  # Just copied from default\n      default:\n        if_no_uploads: error\n\n    changes: true  # Just copied from default\n  \n  ignore:\n    - \"examples/\"\n    - \"luigi/tools\"  # These are tested as actual run commands without coverage\n    # List modules who's tests are not run by Travis or\n    # are run in a subprocesses (like on cluster).\n    - \"luigi/contrib/gcs.py\"\n    - \"luigi/contrib/bigquery.py\"\n    - \"luigi/contrib/bigquery_avro.py\"\n    - \"luigi/contrib/hdfs/\"\n    - \"luigi/contrib/hadoop.py\"\n    - \"luigi/contrib/mrrunner.py\"\n    - \"luigi/contrib/kubernetes.py\"\n\n# For luigi we do not want any comments\ncomment: false\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "luigi",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.615234375,
          "content": "# Copyright (c) 2012 Spotify AB\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"); you may not\n# use this file except in compliance with the License. You may obtain a copy of\n# the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n# License for the specific language governing permissions and limitations under\n# the License.\n\nimport os\nimport sys\n\nfrom setuptools import setup\n\n\ndef get_static_files(path):\n    return [os.path.join(dirpath.replace(\"luigi/\", \"\"), ext)\n            for (dirpath, dirnames, filenames) in os.walk(path)\n            for ext in [\"*.html\", \"*.js\", \"*.css\", \"*.png\",\n                        \"*.eot\", \"*.svg\", \"*.ttf\", \"*.woff\", \"*.woff2\"]]\n\n\nluigi_package_data = sum(map(get_static_files, [\"luigi/static\", \"luigi/templates\"]), [\"py.typed\"])\n\nreadme_note = \"\"\"\n.. note::\n\n   For the latest source, discussion, etc, please visit the\n   `GitHub repository <https://github.com/spotify/luigi>`_\n\"\"\"\n\nwith open('README.rst') as fobj:\n    long_description = \"\\n\\n\" + readme_note + \"\\n\\n\" + fobj.read()\n\ninstall_requires = ['python-dateutil>=2.7.5,<3', 'tenacity>=8,<9', 'tornado>=5.0,<7']\n\n# Can't use python-daemon>=2.2.0 if on windows\n#     See https://pagure.io/python-daemon/issue/18\nif sys.platform == 'nt':\n    install_requires.append('python-daemon<2.2.0')\nelse:\n    install_requires.append('python-daemon')\n\nif os.environ.get('READTHEDOCS', None) == 'True':\n    # So that we can build documentation for luigi.db_task_history and luigi.contrib.sqla\n    install_requires.append('sqlalchemy')\n    # readthedocs don't like python-daemon, see #1342\n    install_requires = [x for x in install_requires if not x.startswith('python-daemon')]\n    install_requires.append('sphinx>=1.4.4')  # Value mirrored in doc/conf.py\n\n# load meta package infos\nmeta = {}\nwith open(\"luigi/__meta__.py\", \"r\") as f:\n    exec(f.read(), meta)\n\nsetup(\n    name='luigi',\n    version=meta['__version__'],\n    description=meta['__doc__'].strip(),\n    long_description=long_description,\n    author=meta['__author__'],\n    url=meta['__contact__'],\n    license=meta['__license__'],\n    packages=[\n        'luigi',\n        'luigi.configuration',\n        'luigi.contrib',\n        'luigi.contrib.hdfs',\n        'luigi.tools'\n    ],\n    package_data={\n        'luigi': luigi_package_data\n    },\n    entry_points={\n        'console_scripts': [\n            'luigi = luigi.cmdline:luigi_run',\n            'luigid = luigi.cmdline:luigid',\n            'luigi-grep = luigi.tools.luigi_grep:main',\n            'luigi-deps = luigi.tools.deps:main',\n            'luigi-deps-tree = luigi.tools.deps_tree:main'\n        ]\n    },\n    install_requires=install_requires,\n    extras_require={\n        'jsonschema': ['jsonschema'],\n        'prometheus': ['prometheus-client>=0.5,<0.15'],\n        'toml': ['toml<2.0.0'],\n    },\n    classifiers=[\n        'Development Status :: 5 - Production/Stable',\n        'Environment :: Console',\n        'Environment :: Web Environment',\n        'Intended Audience :: Developers',\n        'Intended Audience :: System Administrators',\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3.7',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n        'Topic :: System :: Monitoring',\n    ],\n)\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 4.8408203125,
          "content": "[tox]\nenvlist = py{37,38,39,310,311,312}-{cdh,hdp,core,contrib,apache,aws,gcloud,postgres,unixsocket,azureblob,dropbox}, visualiser, docs, flake8\nskipsdist = True\n\n[pytest]\naddopts = --cov=luigi -vv --strict-markers --ignore-glob=\"**/_*\" --fulltrace\ntestpaths = test\nmarkers =\n    contrib: tests related to luigi/contrib\n    apache: tests related to apache\n    aws: tests related to AWS\n    postgres: tests related to postgresql\n    mysql: tests related to mysql\n    scheduler: tests related to scheduler\n    cdh: tests related to cdh\n    hdp: tests related to hdp\n    gcloud: tests related to GCP\n    unixsocket: tests related to unixsocket\n    dropbox: tests related to dropbox\n    azureblob: tests related to azure\n\n[testenv]\nusedevelop = True\ninstall_command = pip install {opts} {packages}\ndeps =\n    pytest<7.0\n    pytest-cov>=2.0,<3.0\n    mock<2.0\n    moto>=1.3.10,<5.0\n    HTTPretty==0.8.10\n    docker>=2.1.0\n    boto>=2.42,<3.0\n    boto3>=1.11.0\n    pyhive[presto]==0.6.1\n    s3transfer>=0.3,<4.0\n    sqlalchemy<1.4\n    elasticsearch>=1.0.0,<2.0.0\n    psutil<4.0\n    cdh,hdp: hdfs>=2.0.4,<3.0.0\n    postgres: psycopg2<3.0\n    postgres: pg8000>=1.23.0\n    mysql-connector-python>=8.0.12\n    py35,py36: mysql-connector-python<8.0.32\n    gcloud: google-api-python-client>=1.6.6,<2.0\n    avro-python3\n    gcloud: google-auth==1.4.1\n    gcloud: google-auth-httplib2==0.0.3\n    google-compute-engine\n    coverage>=5.0,<6\n    codecov>=1.4.0\n    requests>=2.20.0,<=2.31.0\n    unixsocket: requests-unixsocket<1.0\n    pygments\n    hypothesis>=6.7.0,<7.0.0\n    selenium==3.0.2\n    pymongo==3.4.0\n    toml<2.0.0\n    responses<1.0.0\n    azure-storage-blob<=12.20.0\n    datadog==0.22.0\n    prometheus-client>=0.5.0,<0.15\n    dropbox: dropbox>=11.0.0\n    jsonschema\n    mypy\n    types-toml\n    types-python-dateutil\n    types-requests\npassenv =\n    USER JAVA_HOME POSTGRES_USER DATAPROC_TEST_PROJECT_ID GCS_TEST_PROJECT_ID GCS_TEST_BUCKET GOOGLE_APPLICATION_CREDENTIALS TRAVIS_BUILD_ID TRAVIS TRAVIS_BRANCH TRAVIS_JOB_NUMBER TRAVIS_PULL_REQUEST TRAVIS_JOB_ID TRAVIS_REPO_SLUG TRAVIS_COMMIT CI DROPBOX_APP_TOKEN DOCKERHUB_TOKEN GITHUB_ACTIONS OVERRIDE_SKIP_CI_TESTS\nsetenv =\n    LC_ALL = en_US.utf-8\n    cdh: HADOOP_DISTRO=cdh\n    cdh: HADOOP_HOME={toxinidir}/.tox/hadoop-cdh\n    hdp: HADOOP_DISTRO=hdp\n    hdp: HADOOP_HOME={toxinidir}/.tox/hadoop-hdp\n    LUIGI_CONFIG_PATH={toxinidir}/test/testconfig/luigi.cfg\n    COVERAGE_PROCESS_START={toxinidir}/.coveragerc\n    FULL_COVERAGE=true\n    AWS_DEFAULT_REGION=us-east-1\n    AWS_ACCESS_KEY_ID=accesskey\n    AWS_SECRET_ACCESS_KEY=secretkey\n    AZURITE_ACCOUNT_NAME=devstoreaccount1\n    AZURITE_ACCOUNT_KEY=YXp1cml0ZQ==\n    AZURITE_CUSTOM_DOMAIN=localhost:10000\ncommands =\n    cdh,hdp: {toxinidir}/scripts/ci/setup_hadoop_env.sh\n    azureblob: {toxinidir}/scripts/ci/install_start_azurite.sh {toxinidir}/scripts/ci\n    python --version\n    ## main commands\n    contrib: python test/runtests.py -m contrib {posargs:}\n    apache: python test/runtests.py -m apache {posargs:}\n    aws: python test/runtests.py -m aws {posargs:}\n    postgres: python test/runtests.py -m postgres {posargs:}\n    scheduler: python test/runtests.py -m scheduler {posargs:}\n    cdh,hdp: python test/runtests.py -m minicluster {posargs:}\n    gcloud: python test/runtests.py -m gcloud {posargs:}\n    unixsocket: python test/runtests.py -m unixsocket {posargs:}\n    dropbox: python test/runtests.py -m dropbox {posargs:}\n    azureblob: python test/runtests.py -m azureblob {posargs:}\n    core: python test/runtests.py --doctest-modules -m \"not minicluster and not gcloud and not postgres and not unixsocket and not contrib and not apache and not aws and not azureblob and not dropbox\" {posargs:}\n    ##\n    azureblob: {toxinidir}/scripts/ci/stop_azurite.sh\n\n[testenv:visualiser]\nusedevelop = True\ndeps =\n    mock<2.0\n    selenium==3.0.2\npassenv = {[testenv]passenv}\nsetenv =\n    LC_ALL = en_US.utf-8\n    LUIGI_CONFIG_PATH={toxinidir}/test/testconfig/luigi.cfg\n    TEST_VISUALISER=1\ncommands =\n    python --version\n    pytest test/visualiser\n\n# Flake8 Configuration, inspired from https://gitlab.com/pycqa/flake8/blob/master/tox.ini\n# By putting it here, local flake8 runs will also pick it up.\n[flake8]\nmax-line-length = 160\nbuiltins = unicode\n\n[testenv:flake8]\nbasepython=python3\ndeps =\n    flake8>=3.2.0\ncommands =\n    flake8 --exclude=doc,.tox\n    flake8 --max-line-length=100 --ignore=E265 doc\n\n[testenv:isort]\nbasepython=python3\ndeps = isort\ncommands = isort -w 120 -rc luigi test examples bin\n\n[testenv:docs]\nbasepython=python3\n# Build documentation using sphinx.\n# Call this using `tox -e docs`.\ndeps =\n    sqlalchemy\n    boto3\n    jinja2==3.0.3\n    Sphinx>=1.4.4,<2.0\n    sphinx_rtd_theme\n    azure-storage-blob<=12.20.0\n    prometheus-client==0.5.0\n    alabaster<0.7.13\ncommands =\n# build API docs\n    sphinx-apidoc -o doc/api -T luigi --separate\n\n# build HTML docs\n    sphinx-build -W -b html -d {envtmpdir}/doctrees doc doc/_build/html\n"
        }
      ]
    }
  ]
}