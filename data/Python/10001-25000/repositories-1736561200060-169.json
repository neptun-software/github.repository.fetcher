{
  "metadata": {
    "timestamp": 1736561200060,
    "page": 169,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "microsoft/Bringing-Old-Photos-Back-to-Life",
      "stars": 15258,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0224609375,
          "content": "__pycache__/\n*.pyc\n*~\n\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.43359375,
          "content": "# Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.326171875,
          "content": "FROM nvidia/cuda:11.1-base-ubuntu20.04\n\nRUN apt update && DEBIAN_FRONTEND=noninteractive apt install git bzip2 wget unzip python3-pip python3-dev cmake libgl1-mesa-dev python-is-python3 libgtk2.0-dev -yq\nADD . /app\nWORKDIR /app\nRUN cd Face_Enhancement/models/networks/ &&\\\n  git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch &&\\\n  cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm . &&\\\n  cd ../../../\n\nRUN cd Global/detection_models &&\\\n  git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch &&\\\n  cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm . &&\\\n  cd ../../\n\nRUN cd Face_Detection/ &&\\\n  wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 &&\\\n  bzip2 -d shape_predictor_68_face_landmarks.dat.bz2 &&\\\n  cd ../ \n\nRUN cd Face_Enhancement/ &&\\\n  wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip &&\\\n  unzip checkpoints.zip &&\\\n  cd ../ &&\\\n  cd Global/ &&\\\n  wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip &&\\\n  unzip checkpoints.zip &&\\\n  rm -f checkpoints.zip &&\\\n  cd ../\n\nRUN pip3 install numpy\n\nRUN pip3 install dlib\n\nRUN pip3 install -r requirements.txt\n\nRUN git clone https://github.com/NVlabs/SPADE.git\n\nRUN cd SPADE/ && pip3 install -r requirements.txt\n\nRUN cd ..\n\nCMD [\"python3\", \"run.py\"]\n"
        },
        {
          "name": "Face_Detection",
          "type": "tree",
          "content": null
        },
        {
          "name": "Face_Enhancement",
          "type": "tree",
          "content": null
        },
        {
          "name": "GUI.py",
          "type": "blob",
          "size": 7.0712890625,
          "content": "import numpy as np\nimport cv2\nimport PySimpleGUI as sg\nimport os.path\nimport argparse\nimport os\nimport sys\nimport shutil\nfrom subprocess import call\n\ndef modify(image_filename=None, cv2_frame=None):\n\n    def run_cmd(command):\n        try:\n            call(command, shell=True)\n        except KeyboardInterrupt:\n            print(\"Process interrupted\")\n            sys.exit(1)\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_folder\", type=str,\n                        default= image_filename, help=\"Test images\")\n    parser.add_argument(\n        \"--output_folder\",\n        type=str,\n        default=\"./output\",\n        help=\"Restored images, please use the absolute path\",\n    )\n    parser.add_argument(\"--GPU\", type=str, default=\"-1\", help=\"0,1,2\")\n    parser.add_argument(\n        \"--checkpoint_name\", type=str, default=\"Setting_9_epoch_100\", help=\"choose which checkpoint\"\n    )\n    parser.add_argument(\"--with_scratch\",default=\"--with_scratch\" ,action=\"store_true\")\n    opts = parser.parse_args()\n\n    gpu1 = opts.GPU\n\n    # resolve relative paths before changing directory\n    opts.input_folder = os.path.abspath(opts.input_folder)\n    opts.output_folder = os.path.abspath(opts.output_folder)\n    if not os.path.exists(opts.output_folder):\n        os.makedirs(opts.output_folder)\n\n    main_environment = os.getcwd()\n\n    # Stage 1: Overall Quality Improve\n    print(\"Running Stage 1: Overall restoration\")\n    os.chdir(\"./Global\")\n    stage_1_input_dir = opts.input_folder\n    stage_1_output_dir = os.path.join(\n        opts.output_folder, \"stage_1_restore_output\")\n    if not os.path.exists(stage_1_output_dir):\n        os.makedirs(stage_1_output_dir)\n\n    if not opts.with_scratch:\n        stage_1_command = (\n            \"python test.py --test_mode Full --Quality_restore --test_input \"\n            + stage_1_input_dir\n            + \" --outputs_dir \"\n            + stage_1_output_dir\n            + \" --gpu_ids \"\n            + gpu1\n        )\n        run_cmd(stage_1_command)\n    else:\n\n        mask_dir = os.path.join(stage_1_output_dir, \"masks\")\n        new_input = os.path.join(mask_dir, \"input\")\n        new_mask = os.path.join(mask_dir, \"mask\")\n        stage_1_command_1 = (\n            \"python detection.py --test_path \"\n            + stage_1_input_dir\n            + \" --output_dir \"\n            + mask_dir\n            + \" --input_size full_size\"\n            + \" --GPU \"\n            + gpu1\n        )\n        stage_1_command_2 = (\n            \"python test.py --Scratch_and_Quality_restore --test_input \"\n            + new_input\n            + \" --test_mask \"\n            + new_mask\n            + \" --outputs_dir \"\n            + stage_1_output_dir\n            + \" --gpu_ids \"\n            + gpu1\n        )\n        run_cmd(stage_1_command_1)\n        run_cmd(stage_1_command_2)\n\n    # Solve the case when there is no face in the old photo\n    stage_1_results = os.path.join(stage_1_output_dir, \"restored_image\")\n    stage_4_output_dir = os.path.join(opts.output_folder, \"final_output\")\n    if not os.path.exists(stage_4_output_dir):\n        os.makedirs(stage_4_output_dir)\n    for x in os.listdir(stage_1_results):\n        img_dir = os.path.join(stage_1_results, x)\n        shutil.copy(img_dir, stage_4_output_dir)\n\n    print(\"Finish Stage 1 ...\")\n    print(\"\\n\")\n\n    # Stage 2: Face Detection\n\n    print(\"Running Stage 2: Face Detection\")\n    os.chdir(\".././Face_Detection\")\n    stage_2_input_dir = os.path.join(stage_1_output_dir, \"restored_image\")\n    stage_2_output_dir = os.path.join(\n        opts.output_folder, \"stage_2_detection_output\")\n    if not os.path.exists(stage_2_output_dir):\n        os.makedirs(stage_2_output_dir)\n    stage_2_command = (\n        \"python detect_all_dlib.py --url \" + stage_2_input_dir +\n        \" --save_url \" + stage_2_output_dir\n    )\n    run_cmd(stage_2_command)\n    print(\"Finish Stage 2 ...\")\n    print(\"\\n\")\n\n    # Stage 3: Face Restore\n    print(\"Running Stage 3: Face Enhancement\")\n    os.chdir(\".././Face_Enhancement\")\n    stage_3_input_mask = \"./\"\n    stage_3_input_face = stage_2_output_dir\n    stage_3_output_dir = os.path.join(\n        opts.output_folder, \"stage_3_face_output\")\n    if not os.path.exists(stage_3_output_dir):\n        os.makedirs(stage_3_output_dir)\n    stage_3_command = (\n        \"python test_face.py --old_face_folder \"\n        + stage_3_input_face\n        + \" --old_face_label_folder \"\n        + stage_3_input_mask\n        + \" --tensorboard_log --name \"\n        + opts.checkpoint_name\n        + \" --gpu_ids \"\n        + gpu1\n        + \" --load_size 256 --label_nc 18 --no_instance --preprocess_mode resize --batchSize 4 --results_dir \"\n        + stage_3_output_dir\n        + \" --no_parsing_map\"\n    )\n    run_cmd(stage_3_command)\n    print(\"Finish Stage 3 ...\")\n    print(\"\\n\")\n\n    # Stage 4: Warp back\n    print(\"Running Stage 4: Blending\")\n    os.chdir(\".././Face_Detection\")\n    stage_4_input_image_dir = os.path.join(\n        stage_1_output_dir, \"restored_image\")\n    stage_4_input_face_dir = os.path.join(stage_3_output_dir, \"each_img\")\n    stage_4_output_dir = os.path.join(opts.output_folder, \"final_output\")\n    if not os.path.exists(stage_4_output_dir):\n        os.makedirs(stage_4_output_dir)\n    stage_4_command = (\n        \"python align_warp_back_multiple_dlib.py --origin_url \"\n        + stage_4_input_image_dir\n        + \" --replace_url \"\n        + stage_4_input_face_dir\n        + \" --save_url \"\n        + stage_4_output_dir\n    )\n    run_cmd(stage_4_command)\n    print(\"Finish Stage 4 ...\")\n    print(\"\\n\")\n\n    print(\"All the processing is done. Please check the results.\")\n\n# --------------------------------- The GUI ---------------------------------\n\n# First the window layout...\n\nimages_col = [[sg.Text('Input file:'), sg.In(enable_events=True, key='-IN FILE-'), sg.FileBrowse()],\n              [sg.Button('Modify Photo', key='-MPHOTO-'), sg.Button('Exit')],\n              [sg.Image(filename='', key='-IN-'), sg.Image(filename='', key='-OUT-')],]\n# ----- Full layout -----\nlayout = [[sg.VSeperator(), sg.Column(images_col)]]\n\n# ----- Make the window -----\nwindow = sg.Window('Bringing-old-photos-back-to-life', layout, grab_anywhere=True)\n\n# ----- Run the Event Loop -----\nprev_filename = colorized = cap = None\nwhile True:\n    event, values = window.read()\n    if event in (None, 'Exit'):\n        break\n\n    elif event == '-MPHOTO-':\n        try:\n            n1 = filename.split(\"/\")[-2]\n            n2 = filename.split(\"/\")[-3]\n            n3 = filename.split(\"/\")[-1]\n            filename= str(f\"./{n2}/{n1}\")\n            modify(filename)\n           \n            global f_image\n            f_image = f'./output/final_output/{n3}'\n            image = cv2.imread(f_image)\n            window['-OUT-'].update(data=cv2.imencode('.png', image)[1].tobytes())\n            \n        except:\n            continue\n\n    elif event == '-IN FILE-':      # A single filename was chosen\n        filename = values['-IN FILE-']\n        if filename != prev_filename:\n            prev_filename = filename\n            try:\n                image = cv2.imread(filename)\n                window['-IN-'].update(data=cv2.imencode('.png', image)[1].tobytes())\n            except:\n                continue\n\n# ----- Exit program -----\nwindow.close()"
        },
        {
          "name": "Global",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.1142578125,
          "content": "    MIT License\n\n    Copyright (c) Microsoft Corporation.\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.0146484375,
          "content": "# Old Photo Restoration (Official PyTorch Implementation)\n\n<img src='imgs/0001.jpg'/>\n\n### [Project Page](http://raywzy.com/Old_Photo/) | [Paper (CVPR version)](https://arxiv.org/abs/2004.09484) | [Paper (Journal version)](https://arxiv.org/pdf/2009.07047v1.pdf) | [Pretrained Model](https://hkustconnect-my.sharepoint.com/:f:/g/personal/bzhangai_connect_ust_hk/Em0KnYOeSSxFtp4g_dhWdf0BdeT3tY12jIYJ6qvSf300cA?e=nXkJH2) | [Colab Demo](https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA?usp=sharing)  | [Replicate Demo & Docker Image](https://replicate.ai/zhangmozhe/bringing-old-photos-back-to-life) :fire:\n\n**Bringing Old Photos Back to Life, CVPR2020 (Oral)**\n\n**Old Photo Restoration via Deep Latent Space Translation, TPAMI 2022**\n\n[Ziyu Wan](http://raywzy.com/)<sup>1</sup>,\n[Bo Zhang](https://www.microsoft.com/en-us/research/people/zhanbo/)<sup>2</sup>,\n[Dongdong Chen](http://www.dongdongchen.bid/)<sup>3</sup>,\n[Pan Zhang](https://panzhang0212.github.io/)<sup>4</sup>,\n[Dong Chen](https://www.microsoft.com/en-us/research/people/doch/)<sup>2</sup>,\n[Jing Liao](https://liaojing.github.io/html/)<sup>1</sup>,\n[Fang Wen](https://www.microsoft.com/en-us/research/people/fangwen/)<sup>2</sup> <br>\n<sup>1</sup>City University of Hong Kong, <sup>2</sup>Microsoft Research Asia, <sup>3</sup>Microsoft Cloud AI, <sup>4</sup>USTC\n\n<!-- ## Notes of this project\nThe code originates from our research project and the aim is to demonstrate the research idea, so we have not optimized it from a product perspective. And we will spend time to address some common issues, such as out of memory issue, limited resolution, but will not involve too much in engineering problems, such as speedup of the inference, fastapi deployment and so on. **We welcome volunteers to contribute to this project to make it more usable for practical application.** -->\n\n## :sparkles: News\n**2022.3.31**: Our new work regarding old film restoration will be published in CVPR 2022. For more details, please refer to the [project website](http://raywzy.com/Old_Film/) and [github repo](https://github.com/raywzy/Bringing-Old-Films-Back-to-Life).\n\nThe framework now supports the restoration of high-resolution input.\n\n<img src='imgs/HR_result.png'>\n\nTraining code is available and welcome to have a try and learn the training details. \n\nYou can now play with our [Colab](https://colab.research.google.com/drive/1NEm6AsybIiC5TwTU_4DqDkQO0nFRB-uA?usp=sharing) and try it on your photos. \n\n## Requirement\nThe code is tested on Ubuntu with Nvidia GPUs and CUDA installed. Python>=3.6 is required to run the code.\n\n## Installation\n\nClone the Synchronized-BatchNorm-PyTorch repository for\n\n```\ncd Face_Enhancement/models/networks/\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../../\n```\n\n```\ncd Global/detection_models\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../\n```\n\nDownload the landmark detection pretrained model\n\n```\ncd Face_Detection/\nwget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\nbzip2 -d shape_predictor_68_face_landmarks.dat.bz2\ncd ../\n```\n\nDownload the pretrained model, put the file `Face_Enhancement/checkpoints.zip` under `./Face_Enhancement`, and put the file `Global/checkpoints.zip` under `./Global`. Then unzip them respectively.\n\n```\ncd Face_Enhancement/\nwget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/face_checkpoints.zip\nunzip face_checkpoints.zip\ncd ../\ncd Global/\nwget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/global_checkpoints.zip\nunzip global_checkpoints.zip\ncd ../\n```\n\nInstall dependencies:\n\n```bash\npip install -r requirements.txt\n```\n\n## :rocket: How to use?\n\n**Note**: GPU can be set 0 or 0,1,2 or 0,2; use -1 for CPU\n\n### 1) Full Pipeline\n\nYou could easily restore the old photos with one simple command after installation and downloading the pretrained model.\n\nFor images without scratches:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0\n```\n\nFor scratched images:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0 \\\n              --with_scratch\n```\n\n**For high-resolution images with scratches**:\n\n```\npython run.py --input_folder [test_image_folder_path] \\\n              --output_folder [output_path] \\\n              --GPU 0 \\\n              --with_scratch \\\n              --HR\n```\n\nNote: Please try to use the absolute path. The final results will be saved in `./output_path/final_output/`. You could also check the produced results of different steps in `output_path`.\n\n### 2) Scratch Detection\n\nCurrently we don't plan to release the scratched old photos dataset with labels directly. If you want to get the paired data, you could use our pretrained model to test the collected images to obtain the labels.\n\n```\ncd Global/\npython detection.py --test_path [test_image_folder_path] \\\n                    --output_dir [output_path] \\\n                    --input_size [resize_256|full_size|scale_256]\n```\n\n<img src='imgs/scratch_detection.png'>\n\n### 3) Global Restoration\n\nA triplet domain translation network is proposed to solve both structured degradation and unstructured degradation of old photos.\n\n<p align=\"center\">\n<img src='imgs/pipeline.PNG' width=\"50%\" height=\"50%\"/>\n</p>\n\n```\ncd Global/\npython test.py --Scratch_and_Quality_restore \\\n               --test_input [test_image_folder_path] \\\n               --test_mask [corresponding mask] \\\n               --outputs_dir [output_path]\n\npython test.py --Quality_restore \\\n               --test_input [test_image_folder_path] \\\n               --outputs_dir [output_path]\n```\n\n<img src='imgs/global.png'>\n\n\n### 4) Face Enhancement\n\nWe use a progressive generator to refine the face regions of old photos. More details could be found in our journal submission and `./Face_Enhancement` folder.\n\n<p align=\"center\">\n<img src='imgs/face_pipeline.jpg' width=\"60%\" height=\"60%\"/>\n</p>\n\n\n<img src='imgs/face.png'>\n\n> *NOTE*: \n> This repo is mainly for research purpose and we have not yet optimized the running performance. \n> \n> Since the model is pretrained with 256*256 images, the model may not work ideally for arbitrary resolution.\n\n### 5) GUI\n\nA user-friendly GUI which takes input of image by user and shows result in respective window.\n\n#### How it works:\n\n1. Run GUI.py file.\n2. Click browse and select your image from test_images/old_w_scratch folder to remove scratches.\n3. Click Modify Photo button.\n4. Wait for a while and see results on GUI window.\n5. Exit window by clicking Exit Window and get your result image in output folder.\n\n<img src='imgs/gui.PNG'>\n\n## How to train?\n\n### 1) Create Training File\n\nPut the folders of VOC dataset, collected old photos (e.g., Real_L_old and Real_RGB_old) into one shared folder. Then\n```\ncd Global/data/\npython Create_Bigfile.py\n```\nNote: Remember to modify the code based on your own environment.\n\n### 2) Train the VAEs of domain A and domain B respectively\n\n```\ncd ..\npython train_domain_A.py --use_v2_degradation --continue_train --training_dataset domain_A --name domainA_SR_old_photos --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 100 --no_html --gpu_ids 0,1,2,3 --self_gen --nThreads 4 --n_downsample_global 3 --k_size 4 --use_v2 --mc 64 --start_r 1 --kl 1 --no_cgan --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder]\n\npython train_domain_B.py --continue_train --training_dataset domain_B --name domainB_old_photos --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder]  --no_instance --resize_or_crop crop_only --batchSize 120 --no_html --gpu_ids 0,1,2,3 --self_gen --nThreads 4 --n_downsample_global 3 --k_size 4 --use_v2 --mc 64 --start_r 1 --kl 1 --no_cgan --outputs_dir [your_output_folder]  --checkpoints_dir [your_ckpt_folder]\n```\nNote: For the --name option, please ensure your experiment name contains \"domainA\" or \"domainB\", which will be used to select different dataset.\n\n### 3) Train the mapping network between domains\n\nTrain the mapping without scratches:\n```\npython train_mapping.py --use_v2_degradation --training_dataset mapping --use_vae_which_epoch 200 --continue_train --name mapping_quality --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 80 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder]\n```\n\n\nTraing the mapping with scraches:\n```\npython train_mapping.py --no_TTUR --NL_res --random_hole --use_SN --correlation_renormalize --training_dataset mapping --NL_use_mask --NL_fusion_method combine --non_local Setting_42 --use_v2_degradation --use_vae_which_epoch 200 --continue_train --name mapping_scratch --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 36 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder] --irregular_mask [absolute_path_of_mask_file]\n```\n\nTraing the mapping with scraches (Multi-Scale Patch Attention for HR input):\n```\npython train_mapping.py --no_TTUR --NL_res --random_hole --use_SN --correlation_renormalize --training_dataset mapping --NL_use_mask --NL_fusion_method combine --non_local Setting_42 --use_v2_degradation --use_vae_which_epoch 200 --continue_train --name mapping_Patch_Attention --label_nc 0 --loadSize 256 --fineSize 256 --dataroot [your_data_folder] --no_instance --resize_or_crop crop_only --batchSize 36 --no_html --gpu_ids 0,1,2,3 --nThreads 8 --load_pretrainA [ckpt_of_domainA_SR_old_photos] --load_pretrainB [ckpt_of_domainB_old_photos] --l2_feat 60 --n_downsample_global 3 --mc 64 --k_size 4 --start_r 1 --mapping_n_block 6 --map_mc 512 --use_l1_feat --niter 150 --niter_decay 100 --outputs_dir [your_output_folder] --checkpoints_dir [your_ckpt_folder] --irregular_mask [absolute_path_of_mask_file] --mapping_exp 1\n```\n\n\n## Citation\n\nIf you find our work useful for your research, please consider citing the following papers :)\n\n```bibtex\n@inproceedings{wan2020bringing,\ntitle={Bringing Old Photos Back to Life},\nauthor={Wan, Ziyu and Zhang, Bo and Chen, Dongdong and Zhang, Pan and Chen, Dong and Liao, Jing and Wen, Fang},\nbooktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\npages={2747--2757},\nyear={2020}\n}\n```\n\n```bibtex\n@article{wan2020old,\n  title={Old Photo Restoration via Deep Latent Space Translation},\n  author={Wan, Ziyu and Zhang, Bo and Chen, Dongdong and Zhang, Pan and Chen, Dong and Liao, Jing and Wen, Fang},\n  journal={arXiv preprint arXiv:2009.07047},\n  year={2020}\n}\n```\n\nIf you are also interested in the legacy photo/video colorization, please refer to [this work](https://github.com/zhangmozhe/video-colorization).\n\n## Maintenance\n\nThis project is currently maintained by Ziyu Wan and is for academic research use only. If you have any questions, feel free to contact raywzy@gmail.com.\n\n## License\n\nThe codes and the pretrained model in this repository are under the MIT license as specified by the LICENSE file. We use our labeled dataset to train the scratch detection model.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.71484375,
          "content": "<!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK -->\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc751383(v=technet.10)), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://msrc.microsoft.com/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://www.microsoft.com/en-us/msrc/pgp-key-msrc).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc). \n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://microsoft.com/msrc/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://www.microsoft.com/en-us/msrc/cvd).\n\n<!-- END MICROSOFT SECURITY.MD BLOCK -->"
        },
        {
          "name": "ansible.yaml",
          "type": "blob",
          "size": 3.423828125,
          "content": "---\r\n- name: Bringing-Old-Photos-Back-to-Life\r\n  hosts: all\r\n  gather_facts: no\r\n\r\n# Succesfully tested on Ubuntu 18.04\\20.04 and Debian 10 \r\n\r\n  pre_tasks: \r\n  - name: install packages\r\n    package:\r\n      name:\r\n        - python3\r\n        - python3-pip\r\n        - python3-venv\r\n        - git\r\n        - unzip\r\n        - tar\r\n        - lbzip2\r\n        - build-essential\r\n        - cmake\r\n        - ffmpeg\r\n        - libsm6\r\n        - libxext6\r\n        - libgl1-mesa-glx\r\n      state: latest\r\n    become: yes\r\n\r\n  tasks:\r\n  - name: git clone repo\r\n    git:\r\n      repo: 'https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git'\r\n      dest: Bringing-Old-Photos-Back-to-Life\r\n      clone: yes\r\n\r\n  - name: requirements setup\r\n    pip:\r\n      requirements: \"~/Bringing-Old-Photos-Back-to-Life/requirements.txt\"\r\n      virtualenv: \"~/Bringing-Old-Photos-Back-to-Life/.venv\"\r\n      virtualenv_command: /usr/bin/python3 -m venv .venv\r\n\r\n  - name: additional pip packages #requirements lack some packs\r\n    pip:\r\n      name: \r\n          - setuptools \r\n          - wheel\r\n          - scikit-build\r\n      virtualenv: \"~/Bringing-Old-Photos-Back-to-Life/.venv\"\r\n      virtualenv_command: /usr/bin/python3 -m venv .venv\r\n\r\n  - name: git clone batchnorm-pytorch\r\n    git:\r\n      repo: 'https://github.com/vacancy/Synchronized-BatchNorm-PyTorch'\r\n      dest: Synchronized-BatchNorm-PyTorch\r\n      clone: yes\r\n\r\n  - name: copy sync_batchnorm to face_enhancement\r\n    copy:\r\n      src: Synchronized-BatchNorm-PyTorch/sync_batchnorm\r\n      dest: Bringing-Old-Photos-Back-to-Life/Face_Enhancement/models/networks/\r\n      remote_src: yes\r\n\r\n  - name: copy sync_batchnorm to global\r\n    copy:\r\n      src: Synchronized-BatchNorm-PyTorch/sync_batchnorm\r\n      dest: Bringing-Old-Photos-Back-to-Life/Global/detection_models\r\n      remote_src: yes\r\n\r\n  - name: check if shape_predictor_68_face_landmarks.dat\r\n    stat:\r\n      path: Bringing-Old-Photos-Back-to-Life/Face_Detection/shape_predictor_68_face_landmarks.dat\r\n    register: p\r\n\r\n  - name: get shape_predictor_68_face_landmarks.dat.bz2\r\n    get_url:\r\n      url: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\r\n      dest: Bringing-Old-Photos-Back-to-Life/Face_Detection/\r\n    when: p.stat.exists == False\r\n\r\n  - name: unarchive shape_predictor_68_face_landmarks.dat.bz2\r\n    shell: 'bzip2 -d Bringing-Old-Photos-Back-to-Life/Face_Detection/shape_predictor_68_face_landmarks.dat.bz2'\r\n    when: p.stat.exists == False\r\n\r\n  - name: check if face_enhancement\r\n    stat:\r\n      path: Bringing-Old-Photos-Back-to-Life/Face_Enhancement/checkpoints/Setting_9_epoch_100/latest_net_G.pth\r\n    register: fc\r\n\r\n  - name: unarchive Face_Enhancement/checkpoints.zip\r\n    unarchive:\r\n      src: https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\r\n      dest: Bringing-Old-Photos-Back-to-Life/Face_Enhancement/\r\n      remote_src: yes\r\n    when: fc.stat.exists == False\r\n\r\n  - name: check if global\r\n    stat:\r\n      path: Bringing-Old-Photos-Back-to-Life/Global/checkpoints/detection/FT_Epoch_latest.pt\r\n    register: gc\r\n\r\n  - name: unarchive Global/checkpoints.zip\r\n    unarchive:\r\n      src: https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\r\n      dest: Bringing-Old-Photos-Back-to-Life/Global/\r\n      remote_src: yes\r\n    when: gc.stat.exists == False\r\n\r\n# Do not forget to execute 'source .venv/bin/activate' inside Bringing-Old-Photos-Back-to-Life before starting run.py"
        },
        {
          "name": "cog.yaml",
          "type": "blob",
          "size": 0.5380859375,
          "content": "build:\n  gpu: true\n  python_version: \"3.8\"\n  system_packages:\n    - \"libgl1-mesa-glx\"\n    - \"libglib2.0-0\"\n  python_packages:\n    - \"cmake==3.21.2\"\n    - \"torchvision==0.9.0\"\n    - \"torch==1.8.0\"\n    - \"numpy==1.19.4\"\n    - \"opencv-python==4.4.0.46\"\n    - \"scipy==1.5.3\"\n    - \"tensorboardX==2.4\"\n    - \"dominate==2.6.0\"\n    - \"easydict==1.9\"\n    - \"PyYAML==5.3.1\"\n    - \"scikit-image==0.18.3\"\n    - \"dill==0.3.4\"\n    - \"einops==0.3.0\"\n    - \"PySimpleGUI==4.46.0\"\n    - \"ipython==7.19.0\"\n  run:\n    - pip install dlib\n\npredict: \"predict.py:Predictor\"\n"
        },
        {
          "name": "download-weights",
          "type": "blob",
          "size": 0.8271484375,
          "content": "#!/bin/sh\n\ncd Face_Enhancement/models/networks\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../../\n\ncd Global/detection_models\ngit clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\ncp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\ncd ../../\n\n# download the landmark detection model\ncd Face_Detection/\nwget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\nbzip2 -d shape_predictor_68_face_landmarks.dat.bz2\ncd ../\n\n# download the pretrained model\ncd Face_Enhancement/\nwget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\nunzip checkpoints.zip\ncd ../\n\ncd Global/\nwget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\nunzip checkpoints.zip\ncd ../\n"
        },
        {
          "name": "imgs",
          "type": "tree",
          "content": null
        },
        {
          "name": "kubernetes-pod.yml",
          "type": "blob",
          "size": 0.7099609375,
          "content": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: photo-back2life\nspec:\n  containers:\n    - name: photos-back2life\n      image: <YOUR IMAGE>\n      volumeMounts:\n      - mountPath: /in\n        name: in-folder\n      - mountPath: /out\n        name: out-folder\n      command: \n        - python\n        - /app/run.py\n      args:\n        - --input_folder\n        - /in\n        - --output_folder\n        - /out\n        - --GPU \n        - '0'\n        - --with_scratch\n      resources:\n        limits:\n          memory: 4Gi\n          cpu: 0\n          nvidia.com/gpu: 1      \n  volumes:\n  - name: in-folder\n    hostPath:\n      path: /srv/in\n      type: Directory   \n  - name: out-folder\n    hostPath:\n      path: /srv/out\n      type: Directory\n"
        },
        {
          "name": "predict.py",
          "type": "blob",
          "size": 7.896484375,
          "content": "import tempfile\nfrom pathlib import Path\nimport argparse\nimport shutil\nimport os\nimport glob\nimport cv2\nimport cog\nfrom run import run_cmd\n\n\nclass Predictor(cog.Predictor):\n    def setup(self):\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            \"--input_folder\", type=str, default=\"input/cog_temp\", help=\"Test images\"\n        )\n        parser.add_argument(\n            \"--output_folder\",\n            type=str,\n            default=\"output\",\n            help=\"Restored images, please use the absolute path\",\n        )\n        parser.add_argument(\"--GPU\", type=str, default=\"0\", help=\"0,1,2\")\n        parser.add_argument(\n            \"--checkpoint_name\",\n            type=str,\n            default=\"Setting_9_epoch_100\",\n            help=\"choose which checkpoint\",\n        )\n        self.opts = parser.parse_args(\"\")\n        self.basepath = os.getcwd()\n        self.opts.input_folder = os.path.join(self.basepath, self.opts.input_folder)\n        self.opts.output_folder = os.path.join(self.basepath, self.opts.output_folder)\n        os.makedirs(self.opts.input_folder, exist_ok=True)\n        os.makedirs(self.opts.output_folder, exist_ok=True)\n\n    @cog.input(\"image\", type=Path, help=\"input image\")\n    @cog.input(\n        \"HR\",\n        type=bool,\n        default=False,\n        help=\"whether the input image is high-resolution\",\n    )\n    @cog.input(\n        \"with_scratch\",\n        type=bool,\n        default=False,\n        help=\"whether the input image is scratched\",\n    )\n    def predict(self, image, HR=False, with_scratch=False):\n        try:\n            os.chdir(self.basepath)\n            input_path = os.path.join(self.opts.input_folder, os.path.basename(image))\n            shutil.copy(str(image), input_path)\n\n            gpu1 = self.opts.GPU\n\n            ## Stage 1: Overall Quality Improve\n            print(\"Running Stage 1: Overall restoration\")\n            os.chdir(\"./Global\")\n            stage_1_input_dir = self.opts.input_folder\n            stage_1_output_dir = os.path.join(\n                self.opts.output_folder, \"stage_1_restore_output\"\n            )\n\n            os.makedirs(stage_1_output_dir, exist_ok=True)\n\n            if not with_scratch:\n\n                stage_1_command = (\n                        \"python test.py --test_mode Full --Quality_restore --test_input \"\n                        + stage_1_input_dir\n                        + \" --outputs_dir \"\n                        + stage_1_output_dir\n                        + \" --gpu_ids \"\n                        + gpu1\n                )\n                run_cmd(stage_1_command)\n            else:\n\n                mask_dir = os.path.join(stage_1_output_dir, \"masks\")\n                new_input = os.path.join(mask_dir, \"input\")\n                new_mask = os.path.join(mask_dir, \"mask\")\n                stage_1_command_1 = (\n                        \"python detection.py --test_path \"\n                        + stage_1_input_dir\n                        + \" --output_dir \"\n                        + mask_dir\n                        + \" --input_size full_size\"\n                        + \" --GPU \"\n                        + gpu1\n                )\n\n                if HR:\n                    HR_suffix = \" --HR\"\n                else:\n                    HR_suffix = \"\"\n\n                stage_1_command_2 = (\n                        \"python test.py --Scratch_and_Quality_restore --test_input \"\n                        + new_input\n                        + \" --test_mask \"\n                        + new_mask\n                        + \" --outputs_dir \"\n                        + stage_1_output_dir\n                        + \" --gpu_ids \"\n                        + gpu1\n                        + HR_suffix\n                )\n\n                run_cmd(stage_1_command_1)\n                run_cmd(stage_1_command_2)\n\n            ## Solve the case when there is no face in the old photo\n            stage_1_results = os.path.join(stage_1_output_dir, \"restored_image\")\n            stage_4_output_dir = os.path.join(self.opts.output_folder, \"final_output\")\n            os.makedirs(stage_4_output_dir, exist_ok=True)\n            for x in os.listdir(stage_1_results):\n                img_dir = os.path.join(stage_1_results, x)\n                shutil.copy(img_dir, stage_4_output_dir)\n\n            print(\"Finish Stage 1 ...\")\n            print(\"\\n\")\n\n            ## Stage 2: Face Detection\n\n            print(\"Running Stage 2: Face Detection\")\n            os.chdir(\".././Face_Detection\")\n            stage_2_input_dir = os.path.join(stage_1_output_dir, \"restored_image\")\n            stage_2_output_dir = os.path.join(\n                self.opts.output_folder, \"stage_2_detection_output\"\n            )\n            os.makedirs(stage_2_output_dir, exist_ok=True)\n\n            stage_2_command = (\n                    \"python detect_all_dlib_HR.py --url \"\n                    + stage_2_input_dir\n                    + \" --save_url \"\n                    + stage_2_output_dir\n            )\n\n            run_cmd(stage_2_command)\n            print(\"Finish Stage 2 ...\")\n            print(\"\\n\")\n\n            ## Stage 3: Face Restore\n            print(\"Running Stage 3: Face Enhancement\")\n            os.chdir(\".././Face_Enhancement\")\n            stage_3_input_mask = \"./\"\n            stage_3_input_face = stage_2_output_dir\n            stage_3_output_dir = os.path.join(\n                self.opts.output_folder, \"stage_3_face_output\"\n            )\n\n            os.makedirs(stage_3_output_dir, exist_ok=True)\n\n            self.opts.checkpoint_name = \"FaceSR_512\"\n            stage_3_command = (\n                    \"python test_face.py --old_face_folder \"\n                    + stage_3_input_face\n                    + \" --old_face_label_folder \"\n                    + stage_3_input_mask\n                    + \" --tensorboard_log --name \"\n                    + self.opts.checkpoint_name\n                    + \" --gpu_ids \"\n                    + gpu1\n                    + \" --load_size 512 --label_nc 18 --no_instance --preprocess_mode resize --batchSize 1 --results_dir \"\n                    + stage_3_output_dir\n                    + \" --no_parsing_map\"\n            )\n\n            run_cmd(stage_3_command)\n            print(\"Finish Stage 3 ...\")\n            print(\"\\n\")\n\n            ## Stage 4: Warp back\n            print(\"Running Stage 4: Blending\")\n            os.chdir(\".././Face_Detection\")\n            stage_4_input_image_dir = os.path.join(stage_1_output_dir, \"restored_image\")\n            stage_4_input_face_dir = os.path.join(stage_3_output_dir, \"each_img\")\n            stage_4_output_dir = os.path.join(self.opts.output_folder, \"final_output\")\n            os.makedirs(stage_4_output_dir, exist_ok=True)\n\n            stage_4_command = (\n                    \"python align_warp_back_multiple_dlib_HR.py --origin_url \"\n                    + stage_4_input_image_dir\n                    + \" --replace_url \"\n                    + stage_4_input_face_dir\n                    + \" --save_url \"\n                    + stage_4_output_dir\n            )\n\n            run_cmd(stage_4_command)\n            print(\"Finish Stage 4 ...\")\n            print(\"\\n\")\n\n            print(\"All the processing is done. Please check the results.\")\n\n            final_output = os.listdir(os.path.join(self.opts.output_folder, \"final_output\"))[0]\n\n            image_restore = cv2.imread(os.path.join(self.opts.output_folder, \"final_output\", final_output))\n\n            out_path = Path(tempfile.mkdtemp()) / \"out.png\"\n\n            cv2.imwrite(str(out_path), image_restore)\n        finally:\n            clean_folder(self.opts.input_folder)\n            clean_folder(self.opts.output_folder)\n        return out_path\n\n\ndef clean_folder(folder):\n    for filename in os.listdir(folder):\n        file_path = os.path.join(folder, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print(f\"Failed to delete {file_path}. Reason:{e}\")\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1328125,
          "content": "torch\ntorchvision\ndlib\nscikit-image\neasydict\nPyYAML\ndominate>=2.3.1\ndill\ntensorboardX\nscipy\nopencv-python\neinops\nPySimpleGUI\nmatplotlib\n"
        },
        {
          "name": "run.py",
          "type": "blob",
          "size": 6.6162109375,
          "content": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\nimport os\nimport argparse\nimport shutil\nimport sys\nfrom subprocess import call\n\ndef run_cmd(command):\n    try:\n        call(command, shell=True)\n    except KeyboardInterrupt:\n        print(\"Process interrupted\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--input_folder\", type=str, default=\"./test_images/old\", help=\"Test images\")\n    parser.add_argument(\n        \"--output_folder\",\n        type=str,\n        default=\"./output\",\n        help=\"Restored images, please use the absolute path\",\n    )\n    parser.add_argument(\"--GPU\", type=str, default=\"6,7\", help=\"0,1,2\")\n    parser.add_argument(\n        \"--checkpoint_name\", type=str, default=\"Setting_9_epoch_100\", help=\"choose which checkpoint\"\n    )\n    parser.add_argument(\"--with_scratch\", action=\"store_true\")\n    parser.add_argument(\"--HR\", action='store_true')\n    opts = parser.parse_args()\n\n    gpu1 = opts.GPU\n\n    # resolve relative paths before changing directory\n    opts.input_folder = os.path.abspath(opts.input_folder)\n    opts.output_folder = os.path.abspath(opts.output_folder)\n    if not os.path.exists(opts.output_folder):\n        os.makedirs(opts.output_folder)\n\n    main_environment = os.getcwd()\n\n    ## Stage 1: Overall Quality Improve\n    print(\"Running Stage 1: Overall restoration\")\n    os.chdir(\"./Global\")\n    stage_1_input_dir = opts.input_folder\n    stage_1_output_dir = os.path.join(opts.output_folder, \"stage_1_restore_output\")\n    if not os.path.exists(stage_1_output_dir):\n        os.makedirs(stage_1_output_dir)\n\n    if not opts.with_scratch:\n        stage_1_command = (\n            \"python test.py --test_mode Full --Quality_restore --test_input \"\n            + stage_1_input_dir\n            + \" --outputs_dir \"\n            + stage_1_output_dir\n            + \" --gpu_ids \"\n            + gpu1\n        )\n        run_cmd(stage_1_command)\n    else:\n\n        mask_dir = os.path.join(stage_1_output_dir, \"masks\")\n        new_input = os.path.join(mask_dir, \"input\")\n        new_mask = os.path.join(mask_dir, \"mask\")\n        stage_1_command_1 = (\n            \"python detection.py --test_path \"\n            + stage_1_input_dir\n            + \" --output_dir \"\n            + mask_dir\n            + \" --input_size full_size\"\n            + \" --GPU \"\n            + gpu1\n        )\n\n        if opts.HR:\n            HR_suffix=\" --HR\"\n        else:\n            HR_suffix=\"\"\n\n        stage_1_command_2 = (\n            \"python test.py --Scratch_and_Quality_restore --test_input \"\n            + new_input\n            + \" --test_mask \"\n            + new_mask\n            + \" --outputs_dir \"\n            + stage_1_output_dir\n            + \" --gpu_ids \"\n            + gpu1 + HR_suffix\n        )\n\n        run_cmd(stage_1_command_1)\n        run_cmd(stage_1_command_2)\n\n    ## Solve the case when there is no face in the old photo\n    stage_1_results = os.path.join(stage_1_output_dir, \"restored_image\")\n    stage_4_output_dir = os.path.join(opts.output_folder, \"final_output\")\n    if not os.path.exists(stage_4_output_dir):\n        os.makedirs(stage_4_output_dir)\n    for x in os.listdir(stage_1_results):\n        img_dir = os.path.join(stage_1_results, x)\n        shutil.copy(img_dir, stage_4_output_dir)\n\n    print(\"Finish Stage 1 ...\")\n    print(\"\\n\")\n\n    ## Stage 2: Face Detection\n\n    print(\"Running Stage 2: Face Detection\")\n    os.chdir(\".././Face_Detection\")\n    stage_2_input_dir = os.path.join(stage_1_output_dir, \"restored_image\")\n    stage_2_output_dir = os.path.join(opts.output_folder, \"stage_2_detection_output\")\n    if not os.path.exists(stage_2_output_dir):\n        os.makedirs(stage_2_output_dir)\n    if opts.HR:\n        stage_2_command = (\n            \"python detect_all_dlib_HR.py --url \" + stage_2_input_dir + \" --save_url \" + stage_2_output_dir\n        )\n    else:\n        stage_2_command = (\n            \"python detect_all_dlib.py --url \" + stage_2_input_dir + \" --save_url \" + stage_2_output_dir\n        )\n    run_cmd(stage_2_command)\n    print(\"Finish Stage 2 ...\")\n    print(\"\\n\")\n\n    ## Stage 3: Face Restore\n    print(\"Running Stage 3: Face Enhancement\")\n    os.chdir(\".././Face_Enhancement\")\n    stage_3_input_mask = \"./\"\n    stage_3_input_face = stage_2_output_dir\n    stage_3_output_dir = os.path.join(opts.output_folder, \"stage_3_face_output\")\n    if not os.path.exists(stage_3_output_dir):\n        os.makedirs(stage_3_output_dir)\n    \n    if opts.HR:\n        opts.checkpoint_name='FaceSR_512'\n        stage_3_command = (\n            \"python test_face.py --old_face_folder \"\n            + stage_3_input_face\n            + \" --old_face_label_folder \"\n            + stage_3_input_mask\n            + \" --tensorboard_log --name \"\n            + opts.checkpoint_name\n            + \" --gpu_ids \"\n            + gpu1\n            + \" --load_size 512 --label_nc 18 --no_instance --preprocess_mode resize --batchSize 1 --results_dir \"\n            + stage_3_output_dir\n            + \" --no_parsing_map\"\n        ) \n    else:\n        stage_3_command = (\n            \"python test_face.py --old_face_folder \"\n            + stage_3_input_face\n            + \" --old_face_label_folder \"\n            + stage_3_input_mask\n            + \" --tensorboard_log --name \"\n            + opts.checkpoint_name\n            + \" --gpu_ids \"\n            + gpu1\n            + \" --load_size 256 --label_nc 18 --no_instance --preprocess_mode resize --batchSize 4 --results_dir \"\n            + stage_3_output_dir\n            + \" --no_parsing_map\"\n        )\n    run_cmd(stage_3_command)\n    print(\"Finish Stage 3 ...\")\n    print(\"\\n\")\n\n    ## Stage 4: Warp back\n    print(\"Running Stage 4: Blending\")\n    os.chdir(\".././Face_Detection\")\n    stage_4_input_image_dir = os.path.join(stage_1_output_dir, \"restored_image\")\n    stage_4_input_face_dir = os.path.join(stage_3_output_dir, \"each_img\")\n    stage_4_output_dir = os.path.join(opts.output_folder, \"final_output\")\n    if not os.path.exists(stage_4_output_dir):\n        os.makedirs(stage_4_output_dir)\n    if opts.HR:\n        stage_4_command = (\n            \"python align_warp_back_multiple_dlib_HR.py --origin_url \"\n            + stage_4_input_image_dir\n            + \" --replace_url \"\n            + stage_4_input_face_dir\n            + \" --save_url \"\n            + stage_4_output_dir\n        )\n    else:\n        stage_4_command = (\n            \"python align_warp_back_multiple_dlib.py --origin_url \"\n            + stage_4_input_image_dir\n            + \" --replace_url \"\n            + stage_4_input_face_dir\n            + \" --save_url \"\n            + stage_4_output_dir\n        )\n    run_cmd(stage_4_command)\n    print(\"Finish Stage 4 ...\")\n    print(\"\\n\")\n\n    print(\"All the processing is done. Please check the results.\")\n\n"
        },
        {
          "name": "test_images",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}