{
  "metadata": {
    "timestamp": 1736561215756,
    "page": 193,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "horovod/horovod",
      "stars": 14333,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".buildkite",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 0.12890625,
          "content": "---\nBasedOnStyle: LLVM\n---\nLanguage: Cpp\n# Force pointers to the type for C++.\nDerivePointerAlignment: false\nPointerAlignment: Left\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.185546875,
          "content": "*.pyc\n*.so\n.idea\n.eggs\n\n.vscode/\n.idea/\n\nhorovod.egg-info\ndist\nbuild\ndocs/_build\n\nenv\nvenv/\n\nexamples/**/checkpoint*\n\nhorovod/tensorflow/mpi_lib.so\nhorovod/torch/test_cuda/\nlightning_logs\n\n\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 2.099609375,
          "content": "[submodule \"third_party/lbfgs\"]\n\tpath = third_party/lbfgs\n\turl = https://github.com/yixuan/LBFGSpp.git\n[submodule \"third_party/eigen\"]\n\tpath = third_party/eigen\n\turl = https://gitlab.com/cantonios/eigen.git\n[submodule \"third_party/boost/assert\"]\n\tpath = third_party/boost/assert\n\turl = https://github.com/boostorg/assert.git\n[submodule \"third_party/boost/lockfree\"]\n\tpath = third_party/boost/lockfree\n\turl = https://github.com/boostorg/lockfree.git\n[submodule \"third_party/boost/static_assert\"]\n\tpath = third_party/boost/static_assert\n\turl = https://github.com/boostorg/static_assert.git\n[submodule \"third_party/boost/parameter\"]\n\tpath = third_party/boost/parameter\n\turl = https://github.com/boostorg/parameter.git\n[submodule \"third_party/boost/utility\"]\n\tpath = third_party/boost/utility\n\turl = https://github.com/boostorg/utility.git\n[submodule \"third_party/boost/config\"]\n\tpath = third_party/boost/config\n\turl = https://github.com/boostorg/config.git\n[submodule \"third_party/boost/core\"]\n\tpath = third_party/boost/core\n\turl = https://github.com/boostorg/core.git\n[submodule \"third_party/boost/type_traits\"]\n\tpath = third_party/boost/type_traits\n\turl = https://github.com/boostorg/type_traits.git\n[submodule \"third_party/boost/preprocessor\"]\n\tpath = third_party/boost/preprocessor\n\turl = https://github.com/boostorg/preprocessor.git\n[submodule \"third_party/boost/iterator\"]\n\tpath = third_party/boost/iterator\n\turl = https://github.com/boostorg/iterator.git\n[submodule \"third_party/boost/mpl\"]\n\tpath = third_party/boost/mpl\n\turl = https://github.com/boostorg/mpl.git\n[submodule \"third_party/boost/detail\"]\n\tpath = third_party/boost/detail\n\turl = https://github.com/boostorg/detail.git\n[submodule \"third_party/boost/predef\"]\n\tpath = third_party/boost/predef\n\turl = https://github.com/boostorg/predef.git\n[submodule \"third_party/flatbuffers\"]\n\tpath = third_party/flatbuffers\n\turl = https://github.com/google/flatbuffers.git\n[submodule \"third_party/gloo\"]\n\tpath = third_party/gloo\n\turl = https://github.com/facebookincubator/gloo.git\n[submodule \"third_party/HTTPRequest\"]\n\tpath = third_party/HTTPRequest\n\turl = https://github.com/elnormous/HTTPRequest\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 1.1240234375,
          "content": "# Copyright (c) 2019 Uber Technologies, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n#\n# ReadTheDocs.io build configuration: supply addition pip install options\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n#\nversion: 2\n\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.8\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n  fail_on_warning: true\n\n# Don't build any extra formats\nformats: []\n\n# Requirements for building docs\npython:\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 38.0068359375,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [Unreleased] - YYYY-MM-DD\n\n### Added\n\n### Changed\n\n### Deprecated\n\n### Removed\n\n### Fixed\n\n\n## [v0.28.1] - 2023-06-12\n\n### Fixed\n\n- Fixed build with gcc 12. ([#3925](https://github.com/horovod/horovod/pull/3925))\n- PyTorch: Fixed build on ROCm. ([#3928](https://github.com/horovod/horovod/pull/3928))\n- TensorFlow: Fixed local_rank_op. ([#3940](https://github.com/horovod/horovod/pull/3940))\n\n\n## [v0.28.0] - 2023-05-10\n\n### Added\n\n- TensorFlow: Added new `get_local_and_global_gradients` to PartialDistributedGradientTape to retrieve local and non-local gradients separately. ([#3859](https://github.com/horovod/horovod/pull/3859))\n\n### Changed\n\n- Improved reducescatter performance by allocating output tensors before enqueuing the operation. ([#3824](https://github.com/horovod/horovod/pull/3824))\n- TensorFlow: Ensured that `tf.logical_and` within allreduce `tf.cond` runs on CPU. ([#3885](https://github.com/horovod/horovod/pull/3885))\n- TensorFlow: Added support for Keras 2.11+ optimizers. ([#3860](https://github.com/horovod/horovod/pull/3860))\n- `CUDA_VISIBLE_DEVICES` environment variable is no longer passed to remote nodes. ([#3865](https://github.com/horovod/horovod/pull/3865))\n\n### Fixed\n\n- Fixed build with ROCm. ([#3839](https://github.com/horovod/horovod/pull/3839), [#3848](https://github.com/horovod/horovod/pull/3848))\n- Fixed build of Docker image horovod-nvtabular. ([#3851](https://github.com/horovod/horovod/pull/3851))\n- Fixed linking recent NCCL by defaulting CUDA runtime library linkage to static and ensuring that weak symbols are overridden. ([#3867](https://github.com/horovod/horovod/pull/3867), [#3846](https://github.com/horovod/horovod/pull/3846))\n- Fixed compatibility with TensorFlow 2.12 and recent nightly versions. ([#3864](https://github.com/horovod/horovod/pull/3864), [#3894](https://github.com/horovod/horovod/pull/3894), [#3906](https://github.com/horovod/horovod/pull/3906), [#3907](https://github.com/horovod/horovod/pull/3907))\n- Fixed missing arguments of Keras allreduce function. ([#3905](https://github.com/horovod/horovod/pull/3905))\n- Updated with_device functions in MXNet and PyTorch to skip unnecessary cudaSetDevice calls. ([#3912](https://github.com/horovod/horovod/pull/3912))\n\n\n## [v0.27.0] - 2023-02-01\n\n### Added\n\n- Keras: Added `PartialDistributedOptimizer` API. ([#3738](https://github.com/horovod/horovod/pull/3738))\n- Added `HOROVOD_SPARK_USE_LOCAL_RANK_GPU_INDEX` environment variable to ignore GPU device indices assigned by Spark and always use local rank GPU device in Spark estimators. ([#3737](https://github.com/horovod/horovod/pull/3737))\n- Added support for reducescatter arguments `prescale_factor` and `postscale_factor` and moved averaging into Horovod backend. ([#3815](https://github.com/horovod/horovod/pull/3815))\n- Spark Estimator: Added support for custom data loaders in TorchEstimator. ([#3787](https://github.com/horovod/horovod/pull/3787))\n- Spark Estimator: Added NVTabular data loader for TorchEstimator. ([#3787](https://github.com/horovod/horovod/pull/3787))\n\n### Changed\n\n- Improved NCCL performance for fused allgather operations through padding for better memory alignment. ([#3727](https://github.com/horovod/horovod/pull/3727))\n- Improved look-ahead tensor fusion buffer size estimates when allgather and other operations are mixed. ([#3727](https://github.com/horovod/horovod/pull/3727))\n\n### Fixed\n\n- ROCm: Fixed GPU MPI operations support in build. ([#3746](https://github.com/horovod/horovod/pull/3746))\n- PyTorch: Fixed linking order to avoid using Gloo from PyTorch dynamic libraries. ([#3750](https://github.com/horovod/horovod/pull/3750))\n- Fixed memory leak in `MPI_GPUAllgather`. ([#3727](https://github.com/horovod/horovod/pull/3727))\n- TensorFlow: Fixed deprecation warnings when building with TensorFlow 2.11. ([#3767](https://github.com/horovod/horovod/pull/3767))\n- Keras: Added support for additional arguments to `SyncBatchNormalization._moments()`. ([#3775](https://github.com/horovod/horovod/pull/3775))\n- Fixed version number parsing with pypa/packaging 22.0. ([#3794](https://github.com/horovod/horovod/pull/3794))\n- TensorFlow: Fixed linking with nightly versions leading up to TensorFlow 2.12. ([#3755](https://github.com/horovod/horovod/pull/3755))\n- TensorFlow: Fixed handling of `tf.IndexedSlices` types when scaling local gradients. ([#3786](https://github.com/horovod/horovod/pull/3786))\n- Added missing `MEMCPY_IN_FUSION_BUFFER` timeline event for reducescatter. ([#3808](https://github.com/horovod/horovod/pull/3808))\n- Fixed build of Docker image horovod-nvtabular. ([#3817](https://github.com/horovod/horovod/pull/3817))\n- TensorFlow: Several fixes for allreduce and grouped allreduce handling of `tf.IndexedSlices`. ([#3813](https://github.com/horovod/horovod/pull/3813))\n- Spark: Restricted PyArrow to versions < 11.0. ([#3830](https://github.com/horovod/horovod/pull/3830))\n- TensorFlow: Resolved conflicts between multiple optimizer wrappers reusing the same gradient accumulation counter. ([#3783](https://github.com/horovod/horovod/pull/3783))\n- TensorFlow/Keras: Fixed `DistributedOptimizer` with Keras 2.11+. ([#3822](https://github.com/horovod/horovod/pull/3822))\n- PyTorch, ROCm: Fixed allreduce average on process sets. ([#3815](https://github.com/horovod/horovod/pull/3815))\n\n## [v0.26.1] - 2022-10-14\n\n### Fixed\n\n- Fixed packaging import during install to occur after install_requires. ([#3741](https://github.com/horovod/horovod/pull/3741))\n\n## [v0.26.0] - 2022-10-13\n\n### Added\n\n- Spark Estimator: Added support for custom data loaders in KerasEstimator. ([#3603](https://github.com/horovod/horovod/pull/3603))\n- Spark Estimator: Added NVTabular data loader for KerasEstimator. ([#3603](https://github.com/horovod/horovod/pull/3603))\n- Spark Estimator: Added gradient accumulation support to Spark torch estimator. ([#3681](https://github.com/horovod/horovod/pull/3681))\n- TensorFlow: Added `register_local_var` functionality to distributed optimizers and local gradient aggregators. ([#3695](https://github.com/horovod/horovod/pull/3695))\n- TensorFlow: Added support for local variables for `BroadcastGlobalVariablesCallback`. ([#3703](https://github.com/horovod/horovod/pull/3703))\n- Enabled use of native `ncclAvg` op for NCCL allreduces. ([#3646](https://github.com/horovod/horovod/pull/3646))\n- Added support for additional reduction operations for `allreduce` (min, max, product). ([#3660](https://github.com/horovod/horovod/pull/3660))\n- Added 2D torus `allreduce` using NCCL. ([#3608](https://github.com/horovod/horovod/pull/3608))\n- Added support for Petastorm reader level parallel shuffling. ([#3665](https://github.com/horovod/horovod/pull/3665))\n- Added random seed support for Lightning datamodule to generate reproducible data loading outputs. ([#3665](https://github.com/horovod/horovod/pull/3665))\n- Added support for `int8` and `uint8` `allreduce` and `grouped_allreduce` in TensorFlow. ([#3649](https://github.com/horovod/horovod/pull/3649))\n- Added support for batched memory copies in `GPUAllgather`. ([#3590](https://github.com/horovod/horovod/pull/3590))\n- Added support for batched memory copies in `GPUReducescatter`. ([#3621](https://github.com/horovod/horovod/pull/3621))\n- Added `hvd.grouped_allgather()` and `hvd.grouped_reducescatter()` operations. ([#3594](https://github.com/horovod/horovod/pull/3594))\n- Added warning messages if output tensor memory allocations fail. ([#3594](https://github.com/horovod/horovod/pull/3594))\n- Added `register_local_source` and `use_generic_names` funtionality to `DistributedGradientTape`. ([#3628](https://github.com/horovod/horovod/pull/3628))\n- Added `PartialDistributedGradientTape()` API for model parallel use cases. ([#3643](https://github.com/horovod/horovod/pull/3643))\n- Spark/Lightning: Added `reader_worker_count` and `reader_pool_type`. ([#3612](https://github.com/horovod/horovod/pull/3612))\n- Spark/Lightning: Added `transformation_edit_fields` and `transformation_removed_fields` param for `EstimatorParams`. ([#3651](https://github.com/horovod/horovod/pull/3651))\n- TensorFlow: Added doc string for `hvd.grouped_allreduce()`. ([#3594](https://github.com/horovod/horovod/pull/3594))\n- ROCm: Enabled `alltoall`. ([#3654](https://github.com/horovod/horovod/pull/3654))\n\n### Changed\n\n- Default Petastorm reader pool is changed from `process` to `thread` for lower memory usage. ([#3665](https://github.com/horovod/horovod/pull/3665))\n- Keras: Support only legacy optimizers in Keras 2.11+. ([#3725](https://github.com/horovod/horovod/pull/3725))\n- Gloo: When negotiating, use `gather` rather than `allgather`. ([#3633](https://github.com/horovod/horovod/pull/3633))\n- Use `packaging.version` instead of `distutils` version classes. ([#3700](https://github.com/horovod/horovod/pull/3700))\n\n### Deprecated\n\n- Deprecated field `shuffle_buffer_size` from `EstimatorParams`. Use `shuffle` to enable shuffle or not. ([#3665](https://github.com/horovod/horovod/pull/3665))\n\n### Removed\n\n- Build: Removed std::regex use for better cxxabi11 compatibility. ([#3584](https://github.com/horovod/horovod/pull/3584))\n\n### Fixed\n\n- TensorFlow: Fixed the optimizer iteration increments when `backward_passes_per_step > 1`. ([#3631](https://github.com/horovod/horovod/pull/3631))\n- Fixed `FuseResponses()` on `BATCHED_D2D_PADDING` edge cases for Reducescatter and/or ROCm. ([#3621](https://github.com/horovod/horovod/pull/3621))\n- PyTorch: Fixed Reducescatter functions to raise `HorovodInternalError` rather than `RuntimeError`. ([#3594](https://github.com/horovod/horovod/pull/3594))\n- PyTorch on GPUs without GPU operations: Fixed grouped allreduce to set CPU device in tensor table. ([#3594](https://github.com/horovod/horovod/pull/3594))\n- Fixed race condition in PyTorch allocation handling. ([#3639](https://github.com/horovod/horovod/pull/3639))\n- Build: Fixed finding `nvcc` (if not in `$PATH`) with older versions of CMake. ([#3682](https://github.com/horovod/horovod/pull/3682))\n- Fixed `reducescatter()` and `grouped_reducescatter()` to raise clean exceptions for scalar inputs. ([#3699](https://github.com/horovod/horovod/pull/3699))\n- Updated Eigen submodule to fix build on macOS with aarch64. ([#3619](https://github.com/horovod/horovod/pull/3619))\n- Build: Correctly select files in `torch/` directory to be hipified. ([#3588](https://github.com/horovod/horovod/pull/3588))\n- Build: Modify regex match for CUDA|ROCm in `FindPytorch.cmake`. ([#3593](https://github.com/horovod/horovod/pull/3593))\n- Build: Fixed ROCm-specific build failure. ([#3630](https://github.com/horovod/horovod/pull/3630))\n\n## [v0.25.0] - 2022-06-20\n\n### Added\n\n- Added `hvd.reducescatter()` operation with implementations in NCCL, MPI, and Gloo. ([#3299](https://github.com/horovod/horovod/pull/3299), [#3574](https://github.com/horovod/horovod/pull/3574))\n- Added AMD GPU XLA Op Implementation. ([#3486](https://github.com/horovod/horovod/pull/3486))\n- Added Horovod job to spin up distributed TensorFlow Data Service. ([#3525](https://github.com/horovod/horovod/pull/3525))\n- Spark: Expose random seed as an optional parameter. ([#3517](https://github.com/horovod/horovod/pull/3517))\n- Add Helm Chart. ([#3546](https://github.com/horovod/horovod/pull/3546))\n- Elastic: Add elastic run API. ([#3503](https://github.com/horovod/horovod/pull/3503))\n- Spark Estimator: Expose random seed for model training reproducibility. ([#3517](https://github.com/horovod/horovod/pull/3517))\n- Spark Estimator: Add option whether to use GPUs at all. ([#3526](https://github.com/horovod/horovod/pull/3526))\n- Spark Estimator: Expose parameter to set start method for `multiprocessing`. ([#3580](https://github.com/horovod/horovod/pull/3580))\n\n### Changed\n\n- MXNet: Updated allreduce functions to newer `op` API. ([#3299](https://github.com/horovod/horovod/pull/3299))\n- TensorFlow: Make TensorFlow output allocations asynchronous when using NCCL backend. ([#3464](https://github.com/horovod/horovod/pull/3464))\n- TensorFlow: Clear locally accumulated gradient by assigning with `zeros_like` to avoid infinite gradient not correctly cleared up. ([#3505](https://github.com/horovod/horovod/pull/3505))\n- Make `HorovodVersionMismatchError` subclass `ImportError` instead of just a standard `Exception`. ([#3549](https://github.com/horovod/horovod/pull/3549))\n- Elastic: Catch any exception to prevent the discovery thread from silently dying. ([#3436](https://github.com/horovod/horovod/pull/3436))\n- Horovodrun: Exit check_build (`--check-build`) via `sys.exit` to flush stdout. ([#3272](https://github.com/horovod/horovod/pull/3272))\n- Spark: Use `env` to set environment vars in remote shell. ([#3489](https://github.com/horovod/horovod/pull/3489))\n- Build: Avoid redundant ptx generation for maximum specified compute capability. ([#3509](https://github.com/horovod/horovod/pull/3509))\n\n### Deprecated\n\n- MXNet: Deprecated `average` argument of allreduce functions. ([#3299](https://github.com/horovod/horovod/pull/3299))\n- Public and internal APIs: deprecate use of np, min_np, max_np. Use num_proc, min_num_proc, and max_num_proc, respectively, instead. ([#3409](https://github.com/horovod/horovod/pull/3409))\n- Horovodrun: Providing multiple NICS as comma-separated string via `--network-interface` is deprecated,\n  use `--network-interface` multiple times or `--network-interfaces` instead. ([#3506](https://github.com/horovod/horovod/pull/3506))\n- horovod.run: Argument `network_interface` with comma-separated string is deprecated,\n  use `network_interfaces` with `Iterable[str]` instead. ([#3506](https://github.com/horovod/horovod/pull/3506))\n\n### Fixed\n\n- Fallback to NCCL shared lib if static one is not found. ([#3500]((https://github.com/horovod/horovod/pull/3500))\n- Spark/Lightning: Added missing `tranform_spec` for Petastorm datamodule. ([#3543](https://github.com/horovod/horovod/pull/3543))\n- Spark/Lightning: Fixed PTL Spark example with checkpoint usage by calling `save_hyperparameters()`. ([#3527](https://github.com/horovod/horovod/pull/3527))\n- Elastic: Fixed empty hostname returned from `HostDiscoveryScript`. ([#3490](https://github.com/horovod/horovod/pull/3490))\n- TensorFlow 2.9: Fixed build for API change related to `tensorflow_accelerator_device_info`. ([#3513](https://github.com/horovod/horovod/pull/3513))\n- TensorFlow 2.10: Bumped build partially to C++17. ([#3558](https://github.com/horovod/horovod/pull/3558))\n- TensorFlow: Fixed gradient update timing in TF `AggregationHelperEager`. ([#3496](https://github.com/horovod/horovod/pull/3496))\n- TensorFlow: Fixed resource `NotFoundError` in TF `AggregationHelper`. ([#3499](https://github.com/horovod/horovod/pull/3499))\n\n## [v0.24.3] - 2022-04-21\n\n### Fixed\n\n- Make DBFSLocalStore support \"file:/dbfs/...\", implement get_localized_path. ([#3510](https://github.com/horovod/horovod/pull/3510))\n\n## [v0.24.2] - 2022-03-10\n\n### Fixed\n\n- Setup: Require fsspec >= 2010.07.0 ([#3451](https://github.com/horovod/horovod/pull/3451))\n- Fix ignored cuda arch flags ([#3462]((https://github.com/horovod/horovod/pull/3462))\n\n## [v0.24.1] - 2022-03-03\n\n### Fixed\n\n- Extended CMake build script to often find CUDA even if `nvcc` is not in `$PATH`. ([#3444](https://github.com/horovod/horovod/pull/3444))\n\n## [v0.24.0] - 2022-03-01\n\n### Added\n\n- Ray: Added elastic keyword parameters to RayExecutor API: This API supports both static (non-elastic) and elastic Horovod jobs. ([#3190](https://github.com/horovod/horovod/issues/3190))\n- TensorFlow: Added in-place broadcasting of variables. ([#3128](https://github.com/horovod/horovod/pull/3128))\n- Elastic: Added support for resurrecting blacklisted hosts. ([#3319](https://github.com/horovod/horovod/pull/3319))\n- MXNet: Added support for MXNet async dependency engine. ([#3242](https://github.com/horovod/horovod/pull/3242), [#2963](https://github.com/horovod/horovod/pull/2963))\n- Spark/Lightning: Added history to lightning estimator. ([#3214](https://github.com/horovod/horovod/pull/3214))\n\n### Changed\n\n- Moved to CMake version 3.13 with first-class CUDA language support and re-enabled parallelized builds. Uses a temporary installation of CMake if CMake 3.13 is not found. ([#3261](https://github.com/horovod/horovod/pull/3261), [#3371](https://github.com/horovod/horovod/pull/3371))\n- Moved released Docker image `horovod` and `horovod-cpu` to Ubuntu 20.04 and Python 3.8. ([#3393](https://github.com/horovod/horovod/pull/3393))\n- Spark Estimator: Don't shuffle row groups if training data requires non-shuffle ([#3369](https://github.com/horovod/horovod/pull/3369))\n- Spark/Lightning: Reduced memory footprint of async dataloader. ([#3239](https://github.com/horovod/horovod/pull/3239))\n- Elastic: Improved handling NCCL errors under elastic scenario. ([#3112](https://github.com/horovod/horovod/pull/3112))\n- Spark/Lightning: Do not overwrite model with checkpoint by default. ([#3201](https://github.com/horovod/horovod/pull/3201))\n- Make checkpoint name optional so that user can save to h5 format. ([#3411](https://github.com/horovod/horovod/pull/3411))\n\n### Deprecated\n\n- Deprecated ElasticRayExecutor APIs in favor of the new RayExecutor API. ([#3190](https://github.com/horovod/horovod/issues/3190))\n\n### Removed\n\n- Spark: Removed `h5py<3` constraint as this is not needed anymore for Tensorflow >2.5.0. ([#3301](https://github.com/horovod/horovod/pull/3301))\n\n### Fixed\n\n- Elastic Spark: Fixed indices in initial task-to-task registration. ([#3410](https://github.com/horovod/horovod/pull/3410))\n- PyTorch: Fixed GIL-related deadlock with PyTorch 1.10.1. ([#3352](https://github.com/horovod/horovod/issues/3352))\n- PyTorch: Fixed finalization of ProcessSetTable. ([#3351](https://github.com/horovod/horovod/pull/3351))\n- Fixed remote trainers to point to the correct shared lib path. ([#3258](https://github.com/horovod/horovod/pull/3258))\n- Fixed imports from `tensorflow.python.keras` with tensorflow 2.6.0+. ([#3403](https://github.com/horovod/horovod/pull/3403))\n- Fixed Adasum communicator init logic. ([#3379](https://github.com/horovod/horovod/pull/3379))\n- Lightning: Fixed resume logger. ([#3375](https://github.com/horovod/horovod/pull/3375))\n- Fixed the checkpoint directory structure for pytorch and pytorch lightning. ([#3362](https://github.com/horovod/horovod/pull/3362))\n- Fixed possible integer overflow in multiplication. ([#3368](https://github.com/horovod/horovod/pull/3368))\n- Fixed the `pytorch_lightning_mnist.py` example. ([#3245](https://github.com/horovod/horovod/pull/3245), [#3290](https://github.com/horovod/horovod/pull/3290))\n- Fixed barrier segmentation fault. ([#3313](https://github.com/horovod/horovod/pull/3313))\n- Fixed `hvd.barrier()` tensor queue management. ([#3300](https://github.com/horovod/horovod/pull/3300))\n- Fixed PyArrow \"list index out of range\" IndexError. ([#3274](https://github.com/horovod/horovod/pull/3274))\n- Elastic: Fixed all workers sometimes failing on elastic Horovod failure. ([#3264](https://github.com/horovod/horovod/issues/3264))\n- Spark/Lightning: Fixed setting `limit_train_batches` and `limit_val_batches`. ([#3237](https://github.com/horovod/horovod/pull/3237))\n- Elastic: Fixed ElasticSampler and `hvd.elastic.state` losing some indices of processed samples when nodes dropped. ([#3143](https://github.com/horovod/horovod/issues/3143))\n- Spark/Lightning: Fixed history metrics for estimator serialization. ([#3216](https://github.com/horovod/horovod/pull/3216))\n- Ray: Fixed RayExecutor to fail when `num_workers=0` and `num_hosts=None`. ([#3210](https://github.com/horovod/horovod/pull/3210))\n- Spark/Lightning: Fixed checkpoint callback `dirpath` typo. ([#3204](https://github.com/horovod/horovod/pull/3204))\n\n## [v0.23.0] - 2021-10-06\n\n### Added\n\n- Added process sets to concurrently run collective operations on subsets of Horovod processes in TensorFlow, PyTorch, and MXNet. ([#2839](https://github.com/horovod/horovod/pull/2839), [#3042](https://github.com/horovod/horovod/pull/3042), [#3043](https://github.com/horovod/horovod/pull/3043), [#3054](https://github.com/horovod/horovod/pull/3054), [#3083](https://github.com/horovod/horovod/pull/3083), [#3090](https://github.com/horovod/horovod/pull/3090))\n- Added XLA support for Allreduce via `tf.function(jit_compile=True)`. ([#3053](https://github.com/horovod/horovod/pull/3053))\n- Added fused buffer scaling and unpack/pack kernels on GPU. ([#2973](https://github.com/horovod/horovod/pull/2973))\n- Added support for NCCL on CUDA 11.4. ([#3182](https://github.com/horovod/horovod/issues/3182))\n- Added fp16 compression for MXNet. ([#2987](https://github.com/horovod/horovod/issues/2987))\n- Added terminate_on_nan flag to Spark Lightning estimator. ([#3088](https://github.com/horovod/horovod/issues/3088))\n- Added barrier() API to torch module to support simple synchronization among ranks and to achieve parity with PyTorch DDP and similar frameworks. [#3139](https://github.com/horovod/horovod/pull/3139)\n- Added params for customizing Tensorboard callback. ([#3153](https://github.com/horovod/horovod/issues/3153))\n- Added `hvd.cross_rank()` for keras. ([#3008](https://github.com/horovod/horovod/issues/3008))\n- Added barrier() API to torch module to support simple synchronization among ranks and to achieve parity with PyTorch DDP and similar frameworks. [#3139](https://github.com/horovod/horovod/pull/3139)\n\n### Changed\n\n- Implemented more asynchronous dependency handling on GPU. ([#2963](https://github.com/horovod/horovod/pull/2963))\n- Ray: RayExecutor will now use the current placement group instead of always creating a new one. ([#3134](https://github.com/horovod/horovod/pull/3134))\n- Lightning: turned off shuffling for validation dataset. ([#2974](https://github.com/horovod/horovod/pull/2974))\n- Ray: RayExecutor will use the current placement group if one exists. ([#3134](https://github.com/horovod/horovod/pull/3134))\n- Extended `hvd.join()` to return the last rank that joined. ([#3097](https://github.com/horovod/horovod/pull/3097)\n\n### Deprecated\n\n### Removed\n\n- Spark/Keras: remove bare Keras support. ([#3191](https://github.com/horovod/horovod/pull/3191))\n\n### Fixed\n\n- Fix Horovod develop/editable install mode and incremental builds. ([#3074](https://github.com/horovod/horovod/pull/3074))\n- Estimator/Lightning: use lightning datamodule. ([#3084](https://github.com/horovod/horovod/pull/3084))\n- Fix Horovod Spark StringType and numpy type mapping issue. ([#3146](https://github.com/horovod/horovod/pull/3146))\n- Fixed error in Keras LearningRateScheduler. ([#3135](https://github.com/horovod/horovod/pull/3135))\n- Fixed bug in Lightning Profiler on Ray. ([#3122](https://github.com/horovod/horovod/pull/3122))\n- Fixed torch op lazy release to prevent OOM in elastic training. ([#3110](https://github.com/horovod/horovod/pull/3110))\n- Lightning: Fixed usage of the checkpoint callback. ([#3186](https://github.com/horovod/horovod/pull/3186))\n- Fixed MPICH support to use Intel MPI's implementation. ([#3148](https://github.com/horovod/horovod/pull/3148))\n- Fixed race condition in PyTorch async dataloader. ([#3120](https://github.com/horovod/horovod/pull/3120))\n- Keras: Fixed learning rate scheduler. ([#3142](https://github.com/horovod/horovod/pull/3142), [#3135](https://github.com/horovod/horovod/pull/3135))\n\n## [v0.22.1] - 2021-06-10\n\n### Added\n\n- Estimator: added support for loading data from S3, GCS, ADLS, and other remote filesystems. ([#2927](https://github.com/horovod/horovod/issues/2927))\n- Estimator: added custom Spark data loader interface. ([#2938](https://github.com/horovod/horovod/issues/2923))\n- LightningEstimator: added support to supply a logger and associated parameter to control the frequency of logging. ([#2926](https://github.com/horovod/horovod/pull/2926))\n- Estimator: added check to ensure all ranks have the same device type. ([#2942](https://github.com/horovod/horovod/pull/2942))\n\n### Changed\n\n- Changed behavior from using TensorBoardLogger to now using it as a fallback if a logger is not supplied. ([#2926](https://github.com/horovod/horovod/pull/2926))\n- Ray: disabled capturing child tasks in placement group. ([#2920](https://github.com/horovod/horovod/pull/2920))\n\n### Fixed\n\n- Fixed `hvd.tensorflow.keras.Compression`, accidentally removed in v0.22.0. ([#2945](https://github.com/horovod/horovod/pull/2945))\n- TorchEstimator: fixed usage of `validation_steps` in place of `validation_steps_per_epoch`. ([#2918](https://github.com/horovod/horovod/pull/2918))\n- TensorFlow: fixed C++ API for TF v2.6.0. ([#2932](https://github.com/horovod/horovod/pull/2932))\n- PyTorch: fixed `sparse_allreduce_async` for PyTorch v0.10.0. ([#2965](https://github.com/horovod/horovod/pull/2965))\n\n## [v0.22.0] - 2021-05-18\n\n### Added\n\n- Added pytorch_lightning spark estimator which enables training pytorch_lightning models. ([#2713](https://github.com/horovod/horovod/pull/2713))\n- Added NVTX tracing hooks for profiling with Nsight Systems. ([#2723](https://github.com/horovod/horovod/pull/2723))\n- Added a generic `num_workers` API for ``RayExecutor`` ([#2870](https://github.com/horovod/horovod/pull/2870))\n- Supports Ray Client without code changes. ([#2882](https://github.com/horovod/horovod/pull/2882))\n- Supports inmemory cache option for Keras Estimator. ([#2896](https://github.com/horovod/horovod/pull/2896))\n- Added FP16 support for GPU tensor in mxnet. ([#2915](https://github.com/horovod/horovod/pull/2915))\n- Added response caching for allgather operations. ([#2872](https://github.com/horovod/horovod/pull/2872))\n- Estimator: add petastorm reader_pool_type into constructor ([#2903](https://github.com/horovod/horovod/pull/2903))\n\n### Changed\n\n- Changed `alltoall` to return the received splits as a second return value if non-uniform splits are sent. ([#2631](https://github.com/horovod/horovod/pull/2631))\n- Changed ``RayExecutor`` to use [Ray Placement Groups](https://docs.ray.io/en/master/placement-group.html) for worker colocation. ([#2824](https://github.com/horovod/horovod/pull/2824))\n- Changed ``Inmemory dataloader`` usage for Torch Estimator with petastorm v0.11.0 release. ([#2896](https://github.com/horovod/horovod/pull/2896))\n\n### Fixed\n\n- Changed RayExecutor to use Ray node ID to enable multi-container:single-host setups. ([#2883](https://github.com/horovod/horovod/pull/2882))\n- Support sparse gradients aggregation in TF1 Keras. ([#2879](https://github.com/horovod/horovod/pull/2879))\n- Respect `global_step` parameter for LegacyOptimizers when aggregating gradients.  ([#2879](https://github.com/horovod/horovod/pull/2879))\n- Fixed compatibility with PyTorch 1.9.0. ([#2829](https://github.com/horovod/horovod/pull/2829))\n\n## [v0.21.3] - 2021-02-15\n\n### Added\n\n- Add `groups` parameter in `DistributedOptimizer` for custom allreduce groups. ([#2523](https://github.com/horovod/horovod/pull/2523))\n\n### Removed\n\n- Removed `num_groups` parameter in `DistributedOptimizer`, replaced with `groups`. ([#2523](https://github.com/horovod/horovod/pull/2523))\n\n### Fixed\n\n- Fixed worker desynchronization deadlock issue in TensorFlow 2.4. ([#2647](https://github.com/horovod/horovod/pull/2647))\n- Deduped Keras `LearningRateWarmupCallback` log after gradual learning rate warmup. ([#2661](https://github.com/horovod/horovod/pull/2661))\n\n## [v0.21.2] - 2021-02-08\n\n### Added\n\n- Added support for Intel(R) MPI in horovodrun. ([#2374](https://github.com/horovod/horovod/pull/2374))\n- Add support for callbacks in Ray Elastic Executor. ([#2639](https://github.com/horovod/horovod/pull/2639))\n- Added forwarding of stdout/stderr captured to driver over Gloo. ([#2646](https://github.com/horovod/horovod/pull/2646))\n\n### Fixed\n\n- Fixed broadcast_optimizer_state to handle NoneType params for PyTorch 1.8. ([#2624](https://github.com/horovod/horovod/pull/2624))\n- Fixed `local_rank` support for Ray. ([#2596](https://github.com/horovod/horovod/pull/2596))\n- Fixed DL estimators to obtain the output df schema without sampling the input. ([#2611](https://github.com/horovod/horovod/pull/2611))\n- Fixed wrong default for horovod.tensorflow.keras.allreduce average ([#2627](https://github.com/horovod/horovod/pull/2627))\n\n## [v0.21.1] - 2021-01-06\n\n### Added\n\n- Added in-memory dataset caching param to `TorchEstimator`. ([#2434](https://github.com/horovod/horovod/pull/2434))\n- Added `val_batch_size` param to the Estimator API. ([#2505](https://github.com/horovod/horovod/pull/2505))\n- Added support for TorchScript modules when using `TorchEstimator`. ([#2494](https://github.com/horovod/horovod/pull/2494))\n\n### Changed\n\n- Migrated to oneCCL aligned with oneAPI specification v1.0. ([#2513](https://github.com/horovod/horovod/pull/2513))\n- Added knob to set cache hint for oneCCL allreduce. ([#2560](https://github.com/horovod/horovod/pull/2560))\n- Renamed `horovodrun` arg `--ccl-bgt-affinity` to `--thread-affinity`. ([#2562](https://github.com/horovod/horovod/pull/2562))\n- Changed default build parallelism from `-j8` to `-j1` to address potential race condition. ([#2572](https://github.com/horovod/horovod/pull/2572))\n\n### Fixed\n\n- Fixed building Horovod for ROCm PyTorch with newer hipify script. ([#2360](https://github.com/horovod/horovod/pull/2360))\n- Fixed \"Executable class\" support for Ray. ([#2510](https://github.com/horovod/horovod/pull/2510))\n- Fixed TorchEstimator returning model without switching to eval mode. ([#2517](https://github.com/horovod/horovod/pull/2517))\n- Remove ssh reliance for Ray elastic training. ([#2528](https://github.com/horovod/horovod/pull/2528))\n- Fixed error handling for changing framework without reinstalling horovod. ([#2529](https://github.com/horovod/horovod/pull/2529))\n- Fixed \"Intermediate path does not exist\" error with DBFSLocalStore. ([#2526](https://github.com/horovod/horovod/pull/2526))\n- Avoid synchronization if workers are only shrinked in elastic mode. ([#2514](https://github.com/horovod/horovod/pull/2514))\n- Fixed Ray resource test. ([#2575](https://github.com/horovod/horovod/pull/2575))\n- Fixed usage of env variable `HOROVOD_GLOO_TIMEOUT_SECONDS` with `horovodrun`. ([#2571](https://github.com/horovod/horovod/pull/2571))\n\n## [v0.21.0] - 2020-11-23\n\n### Added\n\n- Added support for backward_passes_per_step > 1 for TF Keras graph mode. ([#2346](https://github.com/horovod/horovod/pull/2346))\n- Added support for backward_passes_per_step > 1 for TF Keras eager execution. ([#2371](https://github.com/horovod/horovod/pull/2371))\n- Added support for backward_passes_per_step > 1 for TF LegacyOptimizer in graph mode. ([#2401](https://github.com/horovod/horovod/pull/2401))\n- Added grouped allreduce to enable more efficient tensor fusion and deterministic training. ([#2453](https://github.com/horovod/horovod/pull/2453))\n- Add support for specifying `op` and `compression` in `horovod.tensorflow.keras.allreduce()`. ([#2423](https://github.com/horovod/horovod/pull/2423))\n- Adding support for batched D2D memcopy kernel on GPU. ([#2435](https://github.com/horovod/horovod/pull/2435))\n- Added schema inference in Spark Estimator without sampling. ([#2373](https://github.com/horovod/horovod/pull/2373))\n- Added `Store.create(\"dbfs:/\")` mapping to `DBFSLocalStore(\"/dbfs/...\")`. ([#2376](https://github.com/horovod/horovod/pull/2376))\n\n### Changed\n\n- Changed Keras callbacks to require parameter `initial_lr` of `LearningRateScheduleCallback` and `LearningRateWarmupCallback`. ([#2459](https://github.com/horovod/horovod/pull/2459))\n- Changed default cycle time from 5ms to 1ms and fusion threshold from 64MB to 128MB. ([#2468](https://github.com/horovod/horovod/pull/2468))\n\n### Fixed\n\n- Fixed support for TensorFlow v2.4.0. ([#2381](https://github.com/horovod/horovod/pull/2381))\n- Fixed averaging using CUDA half2 implementation one element half buffers. ([#2375](https://github.com/horovod/horovod/pull/2375))\n- Fixed `HOROVOD_THREAD_AFFINITY` when using oneCCL. ([#2350](https://github.com/horovod/horovod/pull/2350))\n- Added timeout to SSH check in horovodrun to prevent hanging. ([#2448](https://github.com/horovod/horovod/pull/2448))\n- Added `HOROVOD_GLOO_TIMEOUT_SECONDS` value to error messages. ([#2436](https://github.com/horovod/horovod/pull/2436))\n- Fixed race condition in dynamic timeline API. ([#2341](https://github.com/horovod/horovod/pull/2341))\n- Fixed --log-hide-timestamp to apply to driver logs with Gloo. ([#2388](https://github.com/horovod/horovod/pull/2388))\n- Fixed the search order of Eigen and Flatbuffers paths. ([#2473](https://github.com/horovod/horovod/pull/2473))\n- Fixed type checks in `TorchEstimator` to correctly use `isinstance()`. ([#2480](https://github.com/horovod/horovod/pull/2480))\n\n## [0.20.3] - 2020-10-01\n\n### Added\n\n- Added Elastic Ray integration. ([#2291](https://github.com/horovod/horovod/pull/2291))\n\n### Changed\n\n- Removed dependency on SSH access for Ray. ([#2275](https://github.com/horovod/horovod/pull/2275))\n\n## [0.20.2] - 2020-09-25\n\n### Fixed\n\n- Fixed building Horovod without HOROVOD_WITHOUT_MXNET when MXNet is not installed. ([#2334](https://github.com/horovod/horovod/pull/2334))\n\n## [0.20.1] - 2020-09-25\n\n### Added\n\n- Added Databricks storage `DBFSLocalStore` and support for GPU-aware scheduling to horovod.spark Estimator. ([#2234](https://github.com/horovod/horovod/pull/2234))\n- Added ElasticSampler and PyTorch Elastic ImageNet example. ([#2297](https://github.com/horovod/horovod/pull/2297))\n- Added ability to dynamically start and stop timeline programmatically. ([#2215](https://github.com/horovod/horovod/pull/2215))\n- Added support for Gloo on macOS. ([#2254](https://github.com/horovod/horovod/pull/2254))\n- Exposed name argument to TensorFlow allreduce operation. ([#2325](https://github.com/horovod/horovod/pull/2325))\n- Added option to strip outer name scope from Horovod ops in TensorFlow. ([#2328](https://github.com/horovod/horovod/pull/2328))\n\n### Fixed\n\n- Fixed usage of VERBOSE=1 when setting custom MAKEFLAGS. ([#2239](https://github.com/horovod/horovod/pull/2239))\n- Fixed bugs in Keras Elastic Callback classes. ([#2289](https://github.com/horovod/horovod/pull/2289))\n- Fixed RelWithDebInfo build and made it the default with -03 optimizations. ([#2305](https://github.com/horovod/horovod/pull/2305))\n- Fixed usage of tf.cond in TensorFlow alltoall gradient. ([#2327](https://github.com/horovod/horovod/pull/2327))\n- Fixed allreduce averaging for TF IndexedSlices in ROCm path. ([#2279](https://github.com/horovod/horovod/pull/2279))\n- Include stdexcept to handle certain compiler / frameworks that don't include it already. ([#2238](https://github.com/horovod/horovod/pull/2238))\n- Fixed Debug builds by setting compiler options based on CMake build type. ([#2263](https://github.com/horovod/horovod/pull/2263))\n- Skipped launching zero-sized send/recvs for NCCLAlltoall. ([#2273](https://github.com/horovod/horovod/pull/2273))\n- Fixed missing run in tf keras elastic mode. ([#2272](https://github.com/horovod/horovod/pull/2272))\n- Fixed loss function in TensorFlow2 elastic synthetic benchmark. ([#2265](https://github.com/horovod/horovod/pull/2265))\n- Fixed usage of HOROVOD_MIXED_INSTALL env var in alltoall tests. ([#2266](https://github.com/horovod/horovod/pull/2266))\n- Removed keras requirement from Ray example. ([#2262](https://github.com/horovod/horovod/pull/2262))\n\n## [0.20.0] - 2020-09-02\n\n### Added\n\n- Added bare-metal elastic mode implementation to enable auto-scaling and fault tolerance. ([#1849](https://github.com/horovod/horovod/pull/1849))\n- Added Elastic Horovod support for Spark auto-scaling. ([#1956](https://github.com/horovod/horovod/pull/1956))\n- Added All-to-All operation for TensorFlow, PyTorch, and MXNet. ([#2143](https://github.com/horovod/horovod/pull/2143))\n- Added support for `gradient_predivide_factor` and averaging in Horovod backend. ([#1949](https://github.com/horovod/horovod/pull/1949))\n- Added NCCL implementation of the allgather operation. ([#1952](https://github.com/horovod/horovod/pull/1952))\n- Added `HOROVOD_GPU_OPERATIONS` installation variable to simplify enabling NCCL support for all GPU operations. ([#1960](https://github.com/horovod/horovod/pull/1960))\n- Added TensorFlow implementation of `SyncBatchNormalization` layer. ([#2075](https://github.com/horovod/horovod/pull/2075))\n- Added `hvd.is_initialized()` method. ([#2020](https://github.com/horovod/horovod/pull/2020))\n- Added `hvd.allgather_object` function for TensorFlow, PyTorch, and MXNet. ([#2166](https://github.com/horovod/horovod/pull/2166))\n- Added `hvd.broadcast_object` function for MXNet. ([#2122](https://github.com/horovod/horovod/pull/2122))\n- Added `label_shapes` parameter to KerasEstimator and TorchEstimator. ([#2140](https://github.com/horovod/horovod/pull/2140))\n- Added optional `modelCheckPoint` callback to KerasEstimator params. ([#2124](https://github.com/horovod/horovod/pull/2124))\n- Added `ssh_identity_file` argument to `horovodrun`. ([#2201](https://github.com/horovod/horovod/pull/2201))\n- Added support for `horovodrun` on `kubeflow/mpi-job`. ([#2199](https://github.com/horovod/horovod/pull/2199))\n- Added Ray integration. ([#2218](https://github.com/horovod/horovod/pull/2218))\n\n### Changed\n\n- Moved `horovod.run.runner.run` to `horovod.run`. ([#2099](https://github.com/horovod/horovod/pull/2099))\n- HOROVOD_THREAD_AFFINITY accepts multiple values, one for every Horovod rank ([#2131](https://github.com/horovod/horovod/pull/2131))\n- Migrated build system for native libraries to CMake ([#2009](https://github.com/horovod/horovod/pull/2009))\n\n### Deprecated\n\n- HOROVOD_CCL_BGT_AFFINITY is deprected. Use HOROVOD_THREAD_AFFINITY instead ([#2131](https://github.com/horovod/horovod/pull/2131))\n\n### Removed\n\n- Dropped support for Python 2. ([#1954](https://github.com/horovod/horovod/pull/1954))\n- Dropped support for TensorFlow < 1.15. ([#2169](https://github.com/horovod/horovod/pull/2169))\n- Dropped support for PyTorch < 1.2. ([#2086](https://github.com/horovod/horovod/pull/2086))\n\n### Fixed\n\n- Fixed MXNet allgather implementation to correctly handle resizing the output buffer. ([#2092](https://github.com/horovod/horovod/pull/2092))\n- Fixed Keras Spark Estimator incompatibility with TensorFlow 1.15 due to `tf.autograph`. ([#2069](https://github.com/horovod/horovod/pull/2069))\n- Fixed API compatibility with PyTorch 1.6. ([#2051](https://github.com/horovod/horovod/pull/2051))\n- Fixed Keras API compatibility with TensorFlow 2.4.0. ([#2178](https://github.com/horovod/horovod/pull/2178))\n- Fixed allgather gradient for TensorFlow 2 in cases where the tensor shape is not known during graph construction. ([#2121](https://github.com/horovod/horovod/pull/2121))\n- Fixed running using Gloo with an imbalanced number of workers per host. ([#2212](https://github.com/horovod/horovod/pull/2212))\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 17.4873046875,
          "content": "cmake_minimum_required(VERSION 3.13 FATAL_ERROR)\nif(POLICY CMP0074)\n    # 1. Introduced with 3.12.4.\n    # 2. *_ROOT variables will be checked\n    cmake_policy(SET CMP0074 NEW)\nendif()\n\nfind_program(CCACHE_PROGRAM ccache)\nif(CCACHE_PROGRAM)\n    set(CMAKE_C_COMPILER_LAUNCHER \"${CCACHE_PROGRAM}\")\n    set(CMAKE_CXX_COMPILER_LAUNCHER \"${CCACHE_PROGRAM}\")\n    set(CMAKE_CUDA_COMPILER_LAUNCHER \"${CCACHE_PROGRAM}\")\nelse()\n    message(STATUS \"Could not find CCache. Consider installing CCache to speed up compilation.\")\nendif()\n\nproject(horovod CXX)\n\nset(CMAKE_CXX_STANDARD 14)\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\nset(CMAKE_CXX_EXTENSIONS OFF)\n\n# Configure path to modules (for find_package)\nset(CMAKE_MODULE_PATH\n        ${CMAKE_MODULE_PATH}\n        \"${PROJECT_SOURCE_DIR}/cmake/Modules/\"\n        \"${PROJECT_SOURCE_DIR}/cmake/upstream/\")\ninclude(cmake/Utilities.cmake)\n\ncreate_metadata()\n\n# 3rd-parties\ninclude_directories(\"third_party/HTTPRequest/include\"\n        \"third_party/boost/assert/include\"\n        \"third_party/boost/config/include\"\n        \"third_party/boost/core/include\"\n        \"third_party/boost/detail/include\"\n        \"third_party/boost/iterator/include\"\n        \"third_party/boost/lockfree/include\"\n        \"third_party/boost/mpl/include\"\n        \"third_party/boost/parameter/include\"\n        \"third_party/boost/predef/include\"\n        \"third_party/boost/preprocessor/include\"\n        \"third_party/boost/static_assert/include\"\n        \"third_party/boost/type_traits/include\"\n        \"third_party/boost/utility/include\"\n        \"third_party/lbfgs/include\")\n\n# Predefined Eigen and Flatbuffers headers path, they could be replaced by tensorflow headers path\nset(EIGEN_INCLUDE_PATH \"${PROJECT_SOURCE_DIR}/third_party/eigen\")\nset(FLATBUFFERS_INCLUDE_PATH \"${PROJECT_SOURCE_DIR}/third_party/flatbuffers/include\")\n\n# Sources\nlist(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/common.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/controller.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/fusion_buffer_manager.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/group_table.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/half.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/logging.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/message.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/operations.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/parameter_manager.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/process_set.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/response_cache.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/stall_inspector.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/thread_pool.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/timeline.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/tensor_queue.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/ops/collective_operations.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/ops/operation_manager.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/optim/bayesian_optimization.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/optim/gaussian_process.cc\"\n        \"${PROJECT_SOURCE_DIR}/horovod/common/utils/env_parser.cc\")\n\n# Default Macro\nadd_definitions(-DEIGEN_MPL2_ONLY=1)\n\n# Remove platform default std\nstring(REGEX REPLACE  \"-std=[^ ]+\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n# Pickup ar from environmental variable if available\nif(DEFINED ENV{AR})\n    set(CMAKE_AR $ENV{AR})\nendif()\n\n# Add default project CXX flags\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -pthread -fPIC -Wall -ftree-vectorize\")\n\n# RelWithDebInfo uses -O2, prefer performance over debug info in RelWithDebInfo build type\nstring(REPLACE \"-O2\" \"-O3\" CMAKE_C_FLAGS_RELWITHDEBINFO \"${CMAKE_C_FLAGS_RELWITHDEBINFO}\")\nstring(REPLACE \"-O2\" \"-O3\" CMAKE_CXX_FLAGS_RELWITHDEBINFO \"${CMAKE_CXX_FLAGS_RELWITHDEBINFO}\")\nstring(REPLACE \"-O2\" \"-O3\" CMAKE_CUDA_FLAGS_RELWITHDEBINFO \"${CMAKE_CUDA_FLAGS_RELWITHDEBINFO}\")\n\n# Add architecture specific optimization flags\nset(ARCH_FLAGS \"-mf16c\" \"-mavx\" \"-mfma\")\nset_build_arch_flags(\"${ARCH_FLAGS}\")\n# Specify Horovod exports\nif(${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n    set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -undefined dynamic_lookup -Wl,-exported_symbols_list,${CMAKE_SOURCE_DIR}/horovod.exp\")\n    set(CMAKE_MACOSX_RPATH TRUE)\nelse()\n    set(CMAKE_SHARED_LINKER_FLAGS \"${CMAKE_SHARED_LINKER_FLAGS} -Wl,--version-script=${CMAKE_SOURCE_DIR}/horovod.lds -Wl,-Bsymbolic-functions -Wl,-z,relro,-z,now\")\nendif()\n# GPU Operations\nset(HOROVOD_GPU $ENV{HOROVOD_GPU})\nset(HOROVOD_GPU_OPERATIONS $ENV{HOROVOD_GPU_OPERATIONS})\nif(DEFINED HOROVOD_GPU_OPERATIONS AND NOT \"${HOROVOD_GPU_OPERATIONS}\" MATCHES \"^(MPI|NCCL)$\")\n    message(FATAL_ERROR \"HOROVOD_GPU_OPERATIONS=${HOROVOD_GPU_OPERATIONS} is invalid, supported values are '', 'MPI', and 'NCCL'.\")\nendif()\nset_gpu_op(HOROVOD_GPU_ALLREDUCE \"MPI;NCCL;DDL\")\nset_gpu_op(HOROVOD_GPU_ALLGATHER \"MPI;NCCL\")\nset_gpu_op(HOROVOD_GPU_BROADCAST \"MPI;NCCL\")\nset_gpu_op(HOROVOD_GPU_ALLTOALL \"MPI;NCCL\")\nset_gpu_op(HOROVOD_GPU_REDUCESCATTER \"MPI;NCCL\")\n\nforeach(VAR in ITEMS HOROVOD_GPU_ALLREDUCE HOROVOD_GPU_ALLGATHER HOROVOD_GPU_BROADCAST HOROVOD_GPU_ALLTOALL HOROVOD_GPU_REDUCESCATTER)\n    if(DEFINED ${VAR})\n        string(SUBSTRING ${${VAR}} 0 1 ${VAR})\n        convert_to_ascii_dec(ASCII_DEC ${${VAR}})\n        add_definitions(-D${VAR}=${ASCII_DEC})\n    endif()\nendforeach()\n\n# PYTHON\nif(NOT PYTHON_EXECUTABLE)\n    find_package(Python 3.6 COMPONENTS Interpreter REQUIRED)\n    set(PY_EXE ${Python_EXECUTABLE})\nelse()\n    set(PY_EXE ${PYTHON_EXECUTABLE})\nendif()\nmessage(STATUS \"Using command ${PY_EXE}\")\n\n# MPI\nif (NOT \"$ENV{HOROVOD_WITHOUT_MPI}\" STREQUAL \"1\")\n    set(MPI_REQUIRED \"\")\n    if (\"$ENV{HOROVOD_WITH_MPI}\" STREQUAL \"1\")\n        set(MPI_REQUIRED \"REQUIRED\")\n    endif ()\n    find_package(MPI ${MPI_REQUIRED})\n    if(MPI_FOUND)\n        include_directories(SYSTEM ${MPI_INCLUDE_PATH})\n        list(APPEND LINKER_LIBS ${MPI_LIBRARIES})\n        list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/mpi/mpi_context.cc\"\n                \"${PROJECT_SOURCE_DIR}/horovod/common/mpi/mpi_controller.cc\"\n                \"${PROJECT_SOURCE_DIR}/horovod/common/ops/mpi_operations.cc\"\n                \"${PROJECT_SOURCE_DIR}/horovod/common/ops/adasum/adasum_mpi.cc\"\n                \"${PROJECT_SOURCE_DIR}/horovod/common/ops/adasum_mpi_operations.cc\")\n        add_definitions(-DHAVE_MPI=1)\n        set(HAVE_MPI TRUE)\n    endif()\nendif()\n\n# CUDA and ROCM\nset(CMAKE_CUDA_HOST_COMPILER \"${CMAKE_CXX_COMPILER}\")\nif(NOT DEFINED CMAKE_CUDA_RUNTIME_LIBRARY)\n    set(CMAKE_CUDA_RUNTIME_LIBRARY \"Static\")  # Set to \"Static\" or \"Shared\", effective from CMake 3.17\nendif()\nif(DEFINED ENV{HOROVOD_CUDA_HOME})\n    set(CMAKE_CUDA_COMPILER \"$ENV{HOROVOD_CUDA_HOME}/bin/nvcc\")\nendif()\ninclude(CheckLanguage)\ncheck_language(CUDA)\nif(NOT CMAKE_CUDA_COMPILER)\n    find_package(CUDAToolkit)\n    if(CUDAToolkit_BIN_DIR)\n        message(\"CUDA compiler was not found in $PATH, but searching again in CUDA Toolkit binary directory\")\n        unset(CMAKE_CUDA_COMPILER CACHE)  # need to clear this from cache, else some versions of CMake go into an infinite loop\n        set(CMAKE_CUDA_COMPILER \"${CUDAToolkit_BIN_DIR}/nvcc\")\n        check_language(CUDA)\n    endif()\nendif()\nif(CMAKE_CUDA_COMPILER)\n    if((CMAKE_CXX_COMPILER_ID MATCHES GNU) AND (CMAKE_SYSTEM_PROCESSOR MATCHES ppc64le))\n        if(CMAKE_CXX_COMPILER_VERSION VERSION_GREATER 8.0)\n            set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -std=c++11\")\n        endif()\n    endif()\n    enable_language(CUDA)\nendif()\n\nmacro(ADD_CUDA)\n    find_package(CUDAToolkit REQUIRED)\n    include_directories(SYSTEM ${CMAKE_CUDA_TOOLKIT_INCLUDE_DIRECTORIES})\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/cuda_operations.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/ops/gpu_operations.cc\")\n    # CUDA + MPI\n    if(HAVE_MPI)\n        list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/mpi_gpu_operations.cc\")\n    endif()\n    add_definitions(-DHAVE_CUDA=1 -DHAVE_GPU=1)\n    set(HAVE_CUDA TRUE)\n    if(NOT CMAKE_SOURCE_DIR STREQUAL CMAKE_CURRENT_SOURCE_DIR)\n        set(HAVE_SUB_PROJECT_CUDA TRUE PARENT_SCOPE)\n    endif()\nendmacro()\n\nif(DEFINED HOROVOD_GPU_ALLREDUCE OR DEFINED HOROVOD_GPU_ALLGATHER OR DEFINED HOROVOD_GPU_BROADCAST OR DEFINED HOROVOD_GPU_ALLTOALL OR DEFINED HOROVOD_GPU_REDUCESCATTER)\n    if(NOT DEFINED HOROVOD_GPU OR HOROVOD_GPU STREQUAL \"CUDA\")\n        add_cuda()\n    elseif(HOROVOD_GPU STREQUAL \"ROCM\")\n        find_package(ROCM REQUIRED)\n        include_directories(SYSTEM ${ROCM_INCLUDE_DIRS})\n        list(APPEND LINKER_LIBS ${ROCM_LIBRARIES})\n        set(CMAKE_CXX_FLAGS \"${ROCM_COMPILE_FLAGS} ${CMAKE_CXX_FLAGS}\")\n        list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/hip_operations.cc\"\n                            \"${PROJECT_SOURCE_DIR}/horovod/common/ops/gpu_operations.cc\")\n        if(HAVE_MPI)\n            list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/mpi_gpu_operations.cc\")\n        endif()\n        add_definitions(-DHAVE_ROCM=1 -DHAVE_GPU=1)\n        set(HAVE_ROCM TRUE)\n    else()\n        message(FATAL_ERROR \"Unknown HOROVOD_GPU type: ${HOROVOD_GPU}\")\n    endif()\nendif()\n\n# NCCL\nif(HOROVOD_GPU_ALLREDUCE STREQUAL \"N\" OR HOROVOD_GPU_ALLGATHER STREQUAL \"N\" OR HOROVOD_GPU_BROADCAST STREQUAL \"N\" OR HOROVOD_GPU_ALLTOALL STREQUAL \"N\" OR HOROVOD_GPU_REDUCESCATTER STREQUAL \"N\")\n    if(HAVE_ROCM)\n        find_package(rccl REQUIRED)\n        include_directories(SYSTEM ${RCCL_INCLUDE_DIRS})\n        list(APPEND LINKER_LIBS roc::rccl)\n    else()\n        find_package(NCCL REQUIRED)\n        if (NCCL_MAJOR_VERSION LESS \"2\")\n            message(FATAL_ERROR \"Horovod requires NCCL 2.0 or later version please upgrade.\")\n        endif()\n        string(TOLOWER \"${CMAKE_CUDA_RUNTIME_LIBRARY}\" lowercase_CMAKE_CUDA_RUNTIME_LIBRARY)\n        get_filename_component(NCCL_LIBRARY_FILE_NAME ${NCCL_LIBRARIES} NAME)\n        if (CMAKE_VERSION VERSION_GREATER_EQUAL 3.17\n            AND lowercase_CMAKE_CUDA_RUNTIME_LIBRARY STREQUAL \"shared\"\n            AND NCCL_LIBRARY_FILE_NAME MATCHES \"static\")\n            message(WARNING \"Linking NCCL statically, but linking CUDA runtime library dynamically. This combination is not supported with typical builds of NCCL.\")\n        endif()\n        include_directories(SYSTEM ${NCCL_INCLUDE_DIRS})\n        list(APPEND LINKER_LIBS ${NCCL_LIBRARIES})\n        if(NCCL_LIBRARY_FILE_NAME MATCHES \"static\" AND lowercase_CMAKE_CUDA_RUNTIME_LIBRARY STREQUAL \"static\")\n            # ensure that weak symbols from NCCL's enhcompat.cc are properly overwritten by symbols from libcudart_static.a (https://github.com/horovod/horovod/pull/3846)\n            list(APPEND LINKER_LIBS -Wl,--whole-archive cudart_static -Wl,--no-whole-archive)\n        endif()\n    endif()\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/nccl_operations.cc\")\n    add_definitions(-DHAVE_NCCL=1)\n    set(HAVE_NCCL TRUE)\nendif()\n\n# DDL\nif(HOROVOD_GPU_ALLREDUCE STREQUAL \"D\")\n    message(DEPRECATION \"DDL backend has been deprecated. Please, start using the NCCL backend by building Horovod with \"\n                        \"'HOROVOD_GPU_OPERATIONS=NCCL'. Will be removed in v0.21.0.\")\n    list(APPEND LINKER_LIBS \"${CUDAToolkit_LIBRARY_DIR}/libddl.so\" \"${CUDAToolkit_LIBRARY_DIR}/libddl_pack.so\")\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/mpi/ddl_mpi_context_manager.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/ops/ddl_operations.cc\")\n    add_definitions(-DHAVE_DDL=1)\n    set(HAVE_DDL TRUE)\nendif()\n\n# oneCCL\nset(CCL_ROOT $ENV{CCL_ROOT})\nif(DEFINED CCL_ROOT)\n    set(CCL_CONFIGURATION $ENV{CCL_CONFIGURATION})\n    include_directories(${CCL_ROOT}/include/${CCL_CONFIGURATION})\n    list(APPEND LINKER_LIBS \"${CCL_ROOT}/lib/${CCL_CONFIGURATION}/libccl.so\")\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/ccl_operations.cc\")\n    add_definitions(-DHAVE_CCL=1)\n    set(HAVE_CCL TRUE)\nendif()\n\nset(HOROVOD_ALLOW_MIXED_GPU_IMPL $ENV{HOROVOD_ALLOW_MIXED_GPU_IMPL})\nif(HOROVOD_GPU_ALLREDUCE STREQUAL \"N\" AND (HOROVOD_GPU_ALLGATHER STREQUAL \"M\" OR HOROVOD_GPU_BROADCAST STREQUAL \"M\" OR HOROVOD_GPU_ALLTOALL STREQUAL \"M\" OR HOROVOD_GPU_REDUCESCATTER STREQUAL \"M\") AND\n   NOT HOROVOD_ALLOW_MIXED_GPU_IMPL STREQUAL \"1\")\nmessage(FATAL_ERROR \"You should not mix NCCL and MPI GPU due to a possible deadlock.\\n\"\n                    \"If you are sure you want to mix them, set the \"\n                    \"HOROVOD_ALLOW_MIXED_GPU_IMPL environment variable to '1'.\")\nendif()\n\n# NVTX\nif (NOT \"$ENV{HOROVOD_WITHOUT_NVTX}\" STREQUAL \"1\")\n    set(NVTX_REQUIRED \"\")\n    if (\"$ENV{HOROVOD_WITH_NVTX}\" STREQUAL \"1\")\n        set(NVTX_REQUIRED \"REQUIRED\")\n    endif ()\n    find_package(NVTX ${NVTX_REQUIRED})\n    if(NVTX_FOUND)\n        include_directories(SYSTEM ${NVTX_INCLUDE_DIRS})\n        list(APPEND LINKER_LIBS ${NVTX_LIBRARIES})\n        add_definitions(-DHAVE_NVTX=1)\n        list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/nvtx_op_range.cc\")\n        set(HAVE_NVTX TRUE)\n    endif()\nendif()\n\n# Gloo\nif (NOT \"$ENV{HOROVOD_WITHOUT_GLOO}\" STREQUAL \"1\")\n    if(HAVE_MPI)\n        set(USE_MPI TRUE)\n    else()\n        set(USE_MPI FALSE)\n    endif()\n    if(${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n        set(USE_LIBUV ON CACHE BOOL \"use libuv for gloo transport\" FORCE)\n    endif()\n    set(CMAKE_POLICY_DEFAULT_CMP0074 NEW)\n    add_subdirectory(third_party/gloo)\n    include_directories(third_party/gloo)\n    target_compile_definitions(gloo PRIVATE _GLIBCXX_USE_CXX11_ABI=1)\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/gloo/gloo_context.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/gloo/gloo_controller.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/gloo/http_store.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/gloo/memory_store.cc\"\n                        \"${PROJECT_SOURCE_DIR}/horovod/common/ops/gloo_operations.cc\")\n    add_definitions(-DHAVE_GLOO=1)\n    set(HAVE_GLOO TRUE)\nendif()\n\n# NCCL + MPI\nif (HAVE_NCCL AND HAVE_MPI)\n    list(APPEND SOURCES \"${PROJECT_SOURCE_DIR}/horovod/common/ops/adasum_gpu_operations.cc\")\nendif()\n\nset(HOROVOD_CPU_OPERATIONS $ENV{HOROVOD_CPU_OPERATIONS})\nif(DEFINED HOROVOD_CPU_OPERATIONS)\n    message(STATUS \"Set default CPU operation to \" ${HOROVOD_CPU_OPERATIONS})\n    if(HOROVOD_CPU_OPERATIONS STREQUAL \"MPI\")\n        if(NOT HAVE_MPI)\n            message(FATAL_ERROR \"MPI is not installed, try changing HOROVOD_CPU_OPERATIONS.\")\n        endif()\n        add_definitions(-DHOROVOD_CPU_OPERATIONS_DEFAULT=M)\n    elseif(HOROVOD_CPU_OPERATIONS STREQUAL \"MLSL\")\n        message(FATAL_ERROR \"Intel(R) MLSL was removed. Upgrade to oneCCL and set HOROVOD_CPU_OPERATIONS=CCL.\")\n    elseif(HOROVOD_CPU_OPERATIONS STREQUAL \"CCL\")\n        if(NOT HAVE_CCL)\n            message(FATAL_ERROR \"oneCCL is not installed, try changing HOROVOD_CPU_OPERATIONS.\")\n        endif()\n        add_definitions(-DHOROVOD_CPU_OPERATIONS_DEFAULT=C)\n    elseif(HOROVOD_CPU_OPERATIONS STREQUAL \"GLOO\")\n        if(NOT HAVE_GLOO)\n            message(FATAL_ERROR \"Cannot set both HOROVOD_WITHOUT_GLOO and HOROVOD_CPU_OPERATIONS=GLOO.\")\n        endif()\n        add_definitions(-DHOROVOD_CPU_OPERATIONS_DEFAULT=G)\n    endif()\nendif()\n\n# Get Python suffix\nexecute_process(COMMAND ${PY_EXE} -c \"import sysconfig; print(next(x for x in [sysconfig.get_config_var('EXT_SUFFIX'), sysconfig.get_config_var('SO'), '.so'] if x))\"\n                OUTPUT_VARIABLE Python_SUFFIX OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_QUIET)\n\n# TF\nadd_subdirectory(horovod/tensorflow)\n# PyTorch\nadd_subdirectory(horovod/torch)\n#MXNet\nadd_subdirectory(horovod/mxnet)\n\n# Correctly wrap up json format\nfile(APPEND \"${CMAKE_LIBRARY_OUTPUT_DIRECTORY_ROOT}/metadata.json\" \"\\\"dummy\\\": \\\"none\\\"\\n}\")\n\n# CUDA kernels\nif(HAVE_CUDA OR HAVE_SUB_PROJECT_CUDA)\n    add_subdirectory(horovod/common/ops/cuda)\nendif()\n\nif(HAVE_ROCM)\n    add_subdirectory(horovod/common/ops/rocm)\nendif()\n\n# if we need compatible c++ abi\n# Duplicate gloo folder and add it as a new sub-project\nif(HAVE_GLOO AND ((DEFINED Tensorflow_CXX11 AND NOT Tensorflow_CXX11) OR (DEFINED Pytorch_CXX11 AND NOT Pytorch_CXX11) OR (DEFINED Mxnet_CXX11 AND NOT Mxnet_CXX11)))\n    file(COPY ${PROJECT_SOURCE_DIR}/third_party/gloo/ DESTINATION ${PROJECT_SOURCE_DIR}/third_party/compatible_gloo)\n    file(READ ${PROJECT_SOURCE_DIR}/third_party/compatible_gloo/gloo/CMakeLists.txt GLOO_CMAKE)\n    string(REPLACE \"gloo \" \"compatible_gloo \" GLOO_CMAKE \"${GLOO_CMAKE}\")\n    file(WRITE ${PROJECT_SOURCE_DIR}/third_party/compatible_gloo/gloo/CMakeLists.txt \"${GLOO_CMAKE}\")\n    add_subdirectory(third_party/compatible_gloo)\n    target_compile_definitions(compatible_gloo PRIVATE _GLIBCXX_USE_CXX11_ABI=0)\nendif()\n\n# Gloo for c++17 TF\nif(HAVE_GLOO AND ((DEFINED Tensorflow_CXX17 AND Tensorflow_CXX17) OR (DEFINED Pytorch_CXX17 AND Pytorch_CXX17)))\n    file(COPY ${PROJECT_SOURCE_DIR}/third_party/gloo/ DESTINATION ${PROJECT_SOURCE_DIR}/third_party/compatible17_gloo)\n    file(READ ${PROJECT_SOURCE_DIR}/third_party/compatible17_gloo/gloo/CMakeLists.txt GLOO_CMAKE)\n    string(REPLACE \"gloo \" \"compatible17_gloo \" GLOO_CMAKE \"${GLOO_CMAKE}\")\n    file(WRITE ${PROJECT_SOURCE_DIR}/third_party/compatible17_gloo/gloo/CMakeLists.txt \"${GLOO_CMAKE}\")\n    file(READ ${PROJECT_SOURCE_DIR}/third_party/compatible17_gloo/CMakeLists.txt GLOO_CMAKE)\n    string(REPLACE \"-std=c++11\" \"-std=c++17\" GLOO_CMAKE \"${GLOO_CMAKE}\")\n    string(PREPEND GLOO_CMAKE \"set(CMAKE_CXX_STANDARD 17)\\n\")\n    file(WRITE ${PROJECT_SOURCE_DIR}/third_party/compatible17_gloo/CMakeLists.txt \"${GLOO_CMAKE}\")\n    add_subdirectory(third_party/compatible17_gloo)\n    if (Tensorflow_CXX11 OR Pytorch_CXX11)\n        target_compile_definitions(compatible17_gloo PRIVATE _GLIBCXX_USE_CXX11_ABI=1)\n    else()\n       target_compile_definitions(compatible17_gloo PRIVATE _GLIBCXX_USE_CXX11_ABI=0)\n    endif()\nendif()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.3544921875,
          "content": "# Code of Conduct\n\nHorovod is a project hosted under the LF AI Foundation. As such, we would like to urge you to please be mindful of and adhere to the Linux Foundation’s [Code of Conduct](https://lfprojects.org/policies/code-of-conduct/) when contributing to the Horovod.\n\nIf you have any questions or concerns, please email info@lfai.foundation.\n\nThank you. \n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.595703125,
          "content": "## Contributing to Horovod\n\n**Thanks for taking the time to contribute!**\n\nRefer to the following guidelines to contribute new functionality or bug fixes to Horovod:\n1. Use [autopep8](https://github.com/hhatto/autopep8) to format the Python code.\n2. Use [clang-format](https://clang.llvm.org/docs/ClangFormat.html) to format C++ code.\n3. Add unit tests for any new code you write.\n4. Run unit tests in both CPU and GPU environments.\n\n### Code of Conduct\n\nPlease be mindful of and adhere to the Linux Foundation's\n[Code of Conduct](https://lfprojects.org/policies/code-of-conduct) when contributing to Horovod.\n"
        },
        {
          "name": "Dockerfile.test.cpu",
          "type": "blob",
          "size": 15.5166015625,
          "content": "ARG UBUNTU_VERSION=20.04\nFROM ubuntu:${UBUNTU_VERSION}\n\n# Arguments for the build. UBUNTU_VERSION needs to be repeated because\n# the first usage only applies to the FROM tag.\nARG UBUNTU_VERSION=20.04\nARG MPI_KIND=OpenMPI\nARG PYTHON_VERSION=3.6\nARG GPP_VERSION=7\n# NOTE: keep versions in sync with setup.py extras_require{'dev'}:\nARG TENSORFLOW_PACKAGE=tensorflow-cpu==1.15.0\nARG KERAS_PACKAGE=keras==2.2.4\nARG PYTORCH_PACKAGE=torch==1.2.0+cpu\nARG PYTORCH_LIGHTNING_PACKAGE=pytorch_lightning==0.7.6\nARG TORCHVISION_PACKAGE=torchvision==0.4.0+cpu\nARG MXNET_PACKAGE=mxnet==1.5.0\nARG PYSPARK_PACKAGE=pyspark==2.4.7\n# if SPARK_PACKAGE is set, installs Spark into /spark from the tgz archive\n# if SPARK_PACKAGE is a preview version, installs PySpark from the tgz archive\n# see https://archive.apache.org/dist/spark/ for available packages, version must match PYSPARK_PACKAGE\nARG SPARK_PACKAGE=spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\nARG CCL_PACKAGE=master\nARG HOROVOD_BUILD_FLAGS=\"\"\n\n# to avoid interaction with apt-get\nENV DEBIAN_FRONTEND=noninteractive\n\n# Set default shell to /bin/bash\nSHELL [\"/bin/bash\", \"-euo\", \"pipefail\", \"-c\"]\n\n# Log given ARGs (and all other environment vars)\nRUN env | sort\n\n# Prepare to install specific g++ versions\nRUN apt-get update -qq && apt-get install -y --no-install-recommends software-properties-common && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Adding this repo may fail with \"Error: retrieving gpg key timed out\" using default keyserver, so adding an alternative keyserver first\nRUN mkdir -p ~/.gnupg/; \\\n    echo \"keyserver keyserver.ubuntu.com\" >> ~/.gnupg/gpg.conf; \\\n    add-apt-repository ppa:ubuntu-toolchain-r/test\n\n# Install essential packages.\nRUN apt-get update -qq && apt-get install -y --no-install-recommends \\\n        wget \\\n        ca-certificates \\\n        cmake \\\n        openssh-client \\\n        openssh-server \\\n        git \\\n        build-essential \\\n        g++-${GPP_VERSION} \\\n        moreutils && \\\n    rm -rf /var/lib/apt/lists/*\n\n# setup ssh service\nRUN ssh-keygen -f /root/.ssh/id_rsa -q -N ''\nRUN cp -v /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n\n# Install Python.\nRUN apt-get update -qq && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-distutils && \\\n    rm -rf /var/lib/apt/lists/*\nRUN ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python\nRUN ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python${PYTHON_VERSION/%.*/}\nRUN if [[ ${PYTHON_VERSION} != \"3.7\" ]]; then \\\n        wget --progress=dot:mega https://bootstrap.pypa.io/get-pip.py; \\\n    else \\\n        wget --progress=dot:mega https://bootstrap.pypa.io/pip/3.7/get-pip.py; \\\n    fi && python get-pip.py && rm get-pip.py\n\nRUN pip install --no-cache-dir -U --force requests \"pytest<8\" mock pytest-forked parameterized\n\n# Add launch helper scripts\nRUN echo \"env SPARK_HOME=/spark SPARK_DRIVER_MEM=512m PYSPARK_PYTHON=/usr/bin/python${PYTHON_VERSION} PYSPARK_DRIVER_PYTHON=/usr/bin/python${PYTHON_VERSION} \\\"\\$@\\\"\" > /spark_env.sh\nRUN echo /spark_env.sh pytest -v --capture=no --continue-on-collection-errors --junit-xml=/artifacts/junit.\\$1.\\${HOROVOD_RANK:-\\${OMPI_COMM_WORLD_RANK:-\\${PMI_RANK}}}.\\$2.xml \\${@:2} > /pytest.sh\nRUN echo /spark_env.sh pytest -v --capture=no --continue-on-collection-errors --junit-xml=/artifacts/junit.\\$1.standalone.\\$2.xml --forked \\${@:2} > /pytest_standalone.sh\nRUN chmod a+x /spark_env.sh\nRUN chmod a+x /pytest.sh\nRUN chmod a+x /pytest_standalone.sh\n\n# Install Spark stand-alone cluster.\nRUN if [[ -n ${SPARK_PACKAGE} ]]; then \\\n        wget --progress=dot:giga \"https://www.apache.org/dyn/closer.lua/spark/${SPARK_PACKAGE}?action=download\" -O - | tar -xzC /tmp; \\\n        archive=$(basename \"${SPARK_PACKAGE}\") bash -c \"mv -v /tmp/\\${archive/%.tgz/} /spark\"; \\\n    fi\n\n# Install PySpark.\nRUN apt-get update -qq && apt install -y openjdk-8-jdk-headless\nRUN if [[ ${SPARK_PACKAGE} != *\"-preview\"* ]]; then \\\n        pip install --no-cache-dir ${PYSPARK_PACKAGE}; \\\n    else \\\n        apt-get update -qq && apt-get install pandoc; \\\n        pip install --no-cache-dir pypandoc; \\\n        (cd /spark/python && python setup.py sdist && pip install --no-cache-dir dist/pyspark-*.tar.gz && rm dist/pyspark-*); \\\n    fi\n\n# Pin cloudpickle to 1.3.0\n# Dill breaks clouldpickle > 1.3.0 when using Spark2\n# https://github.com/cloudpipe/cloudpickle/issues/393\nRUN if [[ ${PYSPARK_PACKAGE} == \"pyspark==2.\"* ]]; then \\\n        pip install --no-cache-dir cloudpickle==1.3.0; \\\n    fi\n\n# Install Ray.\nRUN pip install --no-cache-dir ray\n\n# Install MPI.\nRUN if [[ ${MPI_KIND} == \"OpenMPI\" ]]; then \\\n        wget --progress=dot:mega -O /tmp/openmpi-4.1.4-bin.tar.gz https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.4.tar.gz && \\\n            cd /tmp && tar -zxf /tmp/openmpi-4.1.4-bin.tar.gz && \\\n            mkdir openmpi-4.1.4/build && cd openmpi-4.1.4/build && ../configure --prefix=/usr/local && \\\n            make -j all && make install && ldconfig && \\\n            echo \"mpirun -allow-run-as-root -np 2 -H localhost:2 -bind-to none -map-by slot -mca mpi_abort_print_stack 1 -tag-output\" > /mpirun_command; \\\n    elif [[ ${MPI_KIND} == \"ONECCL\" ]]; then \\\n        wget --progress=dot:mega -O /tmp/oneccl.tar.gz https://github.com/oneapi-src/oneCCL/archive/${CCL_PACKAGE}.tar.gz && \\\n            cd /tmp && tar -zxf oneccl.tar.gz && \\\n            mkdir oneCCL-${CCL_PACKAGE}/build && cd oneCCL-${CCL_PACKAGE}/build && cmake .. -DCMAKE_INSTALL_PREFIX=/usr/local/oneccl -DCMAKE_BUILD_TYPE=Release && make -j install && \\\n            rm /tmp/oneccl.tar.gz && rm -Rf /tmp/oneCCL-${CCL_PACKAGE} && \\\n            sed -i 's/if \\[ -z \\\"\\${I_MPI_ROOT}\\\" \\]/if [ -z \\\"${I_MPI_ROOT:-}\\\" ]/g' /usr/local/oneccl/env/setvars.sh && \\\n            sed -i 's/ \\$1/ \\${1:-}/g' /usr/local/oneccl/env/setvars.sh && \\\n            echo \". /usr/local/oneccl/env/setvars.sh\" > /oneccl_env && \\\n            chmod +x /oneccl_env && \\\n            echo \"export CCL_ATL_TRANSPORT=ofi; \\\n                  export HOROVOD_CCL_CACHE=1; \\\n                  echo \\\"\\$(env)\\\"; \\\n                  echo \\\"mpirun is \\$(which mpirun)\\\"; \\\n                  echo \\\"LD_LIBRARY_PATH is \\$(echo \\$LD_LIBRARY_PATH)\\\"; \\\n                  echo \\\"oneCCL links with \\$(ldd /usr/local/oneccl/lib/libccl.so)\\\"; \\\n                  mpirun -np 2 -hosts localhost \\$@\" > /mpirun_command_ofi && \\\n            chmod +x /mpirun_command_ofi && \\\n            cp /mpirun_command_ofi /mpirun_command_mpi && \\\n            sed -i 's/export CCL_ATL_TRANSPORT=ofi;/export CCL_ATL_TRANSPORT=mpi;/g' /mpirun_command_mpi && \\\n            sed -i 's/export HOROVOD_CCL_CACHE=1;/export HOROVOD_CCL_CACHE=0;/g' /mpirun_command_mpi && \\\n            echo \"/mpirun_command_mpi\" > /mpirun_command && \\\n            echo \"-L/usr/local/oneccl/lib -lmpi -I/usr/local/oneccl/include\" > /mpicc_oneccl && \\\n            chmod +x /mpicc_oneccl; \\\n    elif [[ ${MPI_KIND} == \"MPICH\" ]]; then \\\n        apt-get update -qq && apt-get install -y mpich && \\\n            echo \"mpirun -np 2 -l\" > /mpirun_command; \\\n    fi\n\n# Install mpi4py.\n# This requires SETUPTOOLS_USE_DISTUTILS=stdlib as with setuptools>=60.1.0 installing mpi4py broke\n# https://github.com/mpi4py/mpi4py/issues/157#issuecomment-1001022274\nRUN if [[ ${MPI_KIND} != \"None\" ]]; then \\\n        if [[ ${MPI_KIND} == \"ONECCL\" ]]; then \\\n            export I_MPI_ROOT=/usr/local/oneccl; \\\n            export MPICC=/usr/local/oneccl/bin/mpicc; \\\n        fi; \\\n        SETUPTOOLS_USE_DISTUTILS=stdlib pip install --no-cache-dir mpi4py; \\\n    fi\n\n# Install TensorFlow and Keras (releases).\n# Pin scipy!=1.4.0: https://github.com/scipy/scipy/issues/11237\n# Pin protobuf~=3.20 for tensorflow<2.6.5: https://github.com/tensorflow/tensorflow/issues/56077\nRUN if [[ ${TENSORFLOW_PACKAGE} != \"tf-nightly\" ]]; then \\\n        PROTOBUF_PACKAGE=\"\"; \\\n        if [[ ${TENSORFLOW_PACKAGE} == tensorflow*==1.15.* ]] || \\\n           [[ ${TENSORFLOW_PACKAGE} == tensorflow-cpu==2.[012345].* ]]; then \\\n            PROTOBUF_PACKAGE=\"protobuf~=3.20\"; \\\n        fi; \\\n        pip install --no-cache-dir ${TENSORFLOW_PACKAGE} ${PROTOBUF_PACKAGE}; \\\n        if [[ ${KERAS_PACKAGE} != \"None\" ]]; then \\\n            pip uninstall -y keras; \\\n            pip install --no-cache-dir ${KERAS_PACKAGE} \"scipy!=1.4.0\" \"pandas<1.1.0\" \"numpy<1.24.0\"; \\\n        fi; \\\n        mkdir -p ~/.keras; \\\n        python -c \"import tensorflow as tf; tf.keras.datasets.mnist.load_data()\"; \\\n    fi\n\n# Pin h5py < 3 for tensorflow: https://github.com/tensorflow/tensorflow/issues/44467\nRUN pip install 'h5py<3.0' 'numpy<1.24.0' --force-reinstall\n\n# Install PyTorch (releases).\n# Pin Pillow<7.0 for torchvision < 0.5.0: https://github.com/pytorch/vision/issues/1718\n# Pin Pillow!=8.3.0 for torchvision: https://github.com/pytorch/vision/issues/4146\n# installing pytorch lightning < 1.8.4 with pip > 23.2.1 fails with:\n#   invalid metadata: .* suffix can only be used with == or != operators\n# https://github.com/pypa/pipx/issues/998\nRUN if [[ ${PYTORCH_PACKAGE} != \"torch-nightly\" ]]; then \\\n        pip install --no-cache-dir ${PYTORCH_PACKAGE} ${TORCHVISION_PACKAGE} -f https://download.pytorch.org/whl/torch_stable.html; \\\n        if [[ \"${TORCHVISION_PACKAGE/%+*/}\" == torchvision==0.[1234].* ]]; then \\\n            pip install --no-cache-dir \"Pillow<7.0\" --no-deps; \\\n        else \\\n            pip install --no-cache-dir \"Pillow!=8.3.0\" --no-deps; \\\n        fi; \\\n        \\\n        IFS=. read maj min patch <<< `cut -d \"=\" -f 3 <<< \"${PYTORCH_LIGHTNING_PACKAGE}\"`; \\\n        if [[ $maj < 1 || $maj == 1 && ( $min < 8 || $min == 8 && $patch < 4) ]]; then \\\n            pip install -U pip==23.2.1; \\\n        fi; \\\n        \\\n        pip install ${PYTORCH_LIGHTNING_PACKAGE}; \\\n    fi\n\n\n# Install MXNet (releases).\nRUN if [[ ${MXNET_PACKAGE} != \"mxnet-nightly\" ]]; then \\\n        pip install --no-cache-dir ${MXNET_PACKAGE} ; \\\n    fi\n\n# Prefetch Spark MNIST dataset.\nRUN mkdir -p /work /data && wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/mnist.bz2 -O /data/mnist.bz2\n\n# Prefetch Spark Rossmann dataset.\nRUN mkdir -p /work /data && wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/rossmann.tgz -O - | tar -xzC /data\n\n# Prefetch PyTorch datasets.\nRUN wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/pytorch_datasets.tgz -O - | tar -xzC /data\n\n### END OF CACHE ###\nCOPY . /horovod\n\n# Install nightly packages here so they do not get cached\n\n# Install TensorFlow and Keras (nightly).\n# Pin scipy!=1.4.0: https://github.com/scipy/scipy/issues/11237\nRUN if [[ ${TENSORFLOW_PACKAGE} == \"tf-nightly\" ]]; then \\\n        pip install --no-cache-dir ${TENSORFLOW_PACKAGE}; \\\n        if [[ ${KERAS_PACKAGE} != \"None\" ]]; then \\\n            pip uninstall -y keras-nightly; \\\n            pip install --no-cache-dir ${KERAS_PACKAGE} \"scipy!=1.4.0\" \"pandas<1.1.0\" \"numpy<1.24.0\"; \\\n        fi; \\\n        mkdir -p ~/.keras; \\\n        python -c \"import tensorflow as tf; tf.keras.datasets.mnist.load_data()\"; \\\n    fi\n\n# Install PyTorch (nightly).\n# Pin Pillow!=8.3.0 for torchvision: https://github.com/pytorch/vision/issues/4146\n# installing pytorch lightning < 1.8.4 with pip > 23.2.1 fails with:\n#   invalid metadata: .* suffix can only be used with == or != operators\n# https://github.com/pypa/pipx/issues/998\nRUN if [[ ${PYTORCH_PACKAGE} == \"torch-nightly\" ]]; then \\\n        pip install --no-cache-dir --pre torch ${TORCHVISION_PACKAGE} -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html; \\\n        pip install --no-cache-dir \"Pillow!=8.3.0\" --no-deps; \\\n        \\\n        IFS=. read maj min patch <<< `cut -d \"=\" -f 3 <<< \"${PYTORCH_LIGHTNING_PACKAGE}\"`; \\\n        if [[ $maj < 1 || $maj == 1 && ( $min < 8 || $min == 8 && $patch < 4) ]]; then \\\n            pip install -U pip==23.2.1; \\\n        fi; \\\n        \\\n        pip install ${PYTORCH_LIGHTNING_PACKAGE}; \\\n    fi\n\n# Install MXNet (nightly).\nRUN if [[ ${MXNET_PACKAGE} == \"mxnet-nightly\" ]]; then \\\n        pip install --no-cache-dir --pre mxnet -f https://dist.mxnet.io/python/all; \\\n    fi\n\n# Install Horovod.\nRUN if [[ ${MPI_KIND} == \"ONECCL\" ]]; then \\\n      if [ -z \"${LD_LIBRARY_PATH:-}\" ]; then \\\n          export LD_LIBRARY_PATH=\"\"; \\\n      fi; \\\n      if [ -z \"${PYTHONPATH:-}\" ]; then \\\n          export PYTHONPATH=\"\"; \\\n      fi; \\\n      . /usr/local/oneccl/env/setvars.sh; \\\n      export I_MPI_ROOT=/usr/local/oneccl; \\\n      echo \"horovod python setup.py sdist, mpicxx is $(which mpicxx)\"; \\\n    fi; \\\n    cd /horovod && \\\n    python setup.py sdist && \\\n    bash -c \"${HOROVOD_BUILD_FLAGS} HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install --no-cache-dir -v $(ls /horovod/dist/horovod-*.tar.gz)[spark,ray] 'protobuf~=3.20'\"\n\n# Show the effective python package version to easily spot version differences\nRUN pip freeze | sort\n\n# Assert installed package versions\nRUN /horovod/assert-package-versions.sh\n\n# Hack for compatibility of MNIST example with TensorFlow 1.1.0.\nRUN if [[ ${TENSORFLOW_PACKAGE} == \"tensorflow==1.1.0\" ]]; then \\\n        sed -i \"s/from tensorflow import keras/from tensorflow.contrib import keras/\" /horovod/examples/tensorflow/tensorflow_mnist.py; \\\n    fi\n\n# Hack TensorFlow MNIST example to be smaller.\nRUN sed -i \"s/last_step=20000/last_step=100/\" /horovod/examples/tensorflow/tensorflow_mnist.py\n\n# Hack TensorFlow Eager MNIST example to be smaller.\nRUN sed -i \"s/dataset.take(20000/dataset.take(100/\" /horovod/examples/tensorflow/tensorflow_mnist_eager.py\n\n# Hack TensorFlow 2.0 example to be smaller.\nRUN sed -i \"s/dataset.take(10000/dataset.take(100/\" /horovod/examples/tensorflow2/tensorflow2_mnist.py\n\n# Hack TensorFlow 2.0 Data Service example to be smaller.\nRUN sed -i \"s/ epochs=24/ epochs=2/\" /horovod/examples/tensorflow2/tensorflow2_mnist_data_service_train_fn_*_side_dispatcher.py\n\n# Hack Keras MNIST advanced example to be smaller.\nRUN sed -i \"s/'--epochs', type=int, default=24,/'--epochs', type=int, default=2,/\" /horovod/examples/keras/keras_mnist_advanced.py\nRUN sed -i \"s/model.add(Conv2D(32, kernel_size=(3, 3),/model.add(Conv2D(1, kernel_size=(3, 3),/\" /horovod/examples/keras/keras_mnist_advanced.py\nRUN sed -i \"s/model.add(Conv2D(64, (3, 3), activation='relu'))//\" /horovod/examples/keras/keras_mnist_advanced.py\n\n# Hack TensorFlow 2.0 Keras MNIST advanced example to be smaller.\nRUN sed -i \"s/epochs=24/epochs=2/\" /horovod/examples/tensorflow2/tensorflow2_keras_mnist.py\nRUN sed -i \"s/tf.keras.layers.Conv2D(32, \\\\[3, 3\\\\],/tf.keras.layers.Conv2D(1, [3, 3],/\" /horovod/examples/tensorflow2/tensorflow2_keras_mnist.py\nRUN sed -i -E \"s/\\s+tf.keras.layers.Conv2D\\(64, \\\\[3, 3\\\\], activation='relu'\\),//\" /horovod/examples/tensorflow2/tensorflow2_keras_mnist.py\n\n# Hack PyTorch MNIST example to be smaller.\nRUN sed -i \"s/'--epochs', type=int, default=10,/'--epochs', type=int, default=2,/\" /horovod/examples/pytorch/pytorch_mnist.py\nRUN sed -i \"s/self.fc1 = nn.Linear(320, 50)/self.fc1 = nn.Linear(784, 50)/\" /horovod/examples/pytorch/pytorch_mnist.py\nRUN sed -i \"s/x = F.relu(F.max_pool2d(self.conv1(x), 2))//\" /horovod/examples/pytorch/pytorch_mnist.py\nRUN sed -i \"s/x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))//\" /horovod/examples/pytorch/pytorch_mnist.py\nRUN sed -i \"s/x = x.view(-1, 320)/x = x.view(-1, 784)/\" /horovod/examples/pytorch/pytorch_mnist.py\n\n# Hack Keras Spark Rossmann Run example to be smaller.\nRUN sed -i \"s/x = Dense(1000,/x = Dense(100,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_run.py\nRUN sed -i \"s/x = Dense(500,/x = Dense(50,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_run.py\n\n# Hack Keras Spark Rossmann Estimator example to be smaller.\nRUN sed -i \"s/x = Dense(1000,/x = Dense(100,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_estimator.py\nRUN sed -i \"s/x = Dense(500,/x = Dense(50,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_estimator.py\n"
        },
        {
          "name": "Dockerfile.test.gpu",
          "type": "blob",
          "size": 13.6884765625,
          "content": "ARG CUDA_DOCKER_VERSION=10.0-devel-ubuntu20.04\nFROM nvidia/cuda:${CUDA_DOCKER_VERSION}\n\n# Arguments for the build. CUDA_DOCKER_VERSION needs to be repeated because\n# the first usage only applies to the FROM tag.\nARG CUDA_DOCKER_VERSION=10.0-devel-ubuntu20.04\nARG CUDNN_VERSION=7.6.0.64-1+cuda10.0\nARG NCCL_VERSION_OVERRIDE=2.4.7-1+cuda10.0\nARG MPI_KIND=OpenMPI\nARG PYTHON_VERSION=3.6\nARG GPP_VERSION=7\nARG TENSORFLOW_PACKAGE=tensorflow-gpu==1.15.0\nARG KERAS_PACKAGE=keras==2.2.4\nARG PYTORCH_PACKAGE=torch==1.2.0\nARG PYTORCH_LIGHTNING_PACKAGE=pytorch_lightning==0.7.6\nARG TORCHVISION_PACKAGE=torchvision==0.4.0\nARG MXNET_PACKAGE=mxnet-cu100==1.5.0\nARG PYSPARK_PACKAGE=pyspark==2.4.7\n# if SPARK_PACKAGE is set, installs Spark into /spark from the tgz archive\n# if SPARK_PACKAGE is a preview version, installs PySpark from the tgz archive\n# see https://archive.apache.org/dist/spark/ for available packages, version must match PYSPARK_PACKAGE\nARG SPARK_PACKAGE=spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\nARG HOROVOD_BUILD_FLAGS=\"HOROVOD_GPU_OPERATIONS=NCCL\"\nARG HOROVOD_MIXED_INSTALL=0\n\n# to avoid interaction with apt-get\nENV DEBIAN_FRONTEND=noninteractive\n\n# Set default shell to /bin/bash\nSHELL [\"/bin/bash\", \"-euo\", \"pipefail\", \"-c\"]\n\n# Log given ARGs (and all other environment vars)\nRUN env | sort\n\n# Extract ubuntu distribution version and download the corresponding key.\n# This is to fix CI failures caused by the new rotating key mechanism rolled out by Nvidia.\n# Refer to https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212771 for more details.\n#RUN DIST=$(echo ${CUDA_DOCKER_VERSION#*ubuntu} | sed 's/\\.//'); \\\n#    apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu${DIST}/x86_64/3bf863cc.pub && \\\n#    apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu${DIST}/x86_64/7fa2af80.pub\n\n# Prepare to install specific g++ versions\nRUN apt-get update -qq && apt-get install -y --no-install-recommends software-properties-common && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Adding this repo may fail with \"Error: retrieving gpg key timed out\" using default keyserver, so adding an alternative keyserver first\nRUN mkdir -p ~/.gnupg/; \\\n    echo \"keyserver keyserver.ubuntu.com\" >> ~/.gnupg/gpg.conf; \\\n    add-apt-repository ppa:ubuntu-toolchain-r/test\n\n# Install essential packages.\nRUN CUDNN_MAJOR=$(cut -d '.' -f 1 <<< \"${CUDNN_VERSION}\"); \\\n    apt-get update -qq && apt-get install -y --allow-downgrades --allow-change-held-packages --no-install-recommends \\\n        wget \\\n        ca-certificates \\\n        cmake \\\n        openssh-client \\\n        openssh-server \\\n        git \\\n        build-essential \\\n        g++-${GPP_VERSION} \\\n        moreutils \\\n        libcudnn${CUDNN_MAJOR}=${CUDNN_VERSION} \\\n        libnccl2=${NCCL_VERSION_OVERRIDE} \\\n        libnccl-dev=${NCCL_VERSION_OVERRIDE} && \\\n    rm -rf /var/lib/apt/lists/*\n\n# setup ssh service\nRUN ssh-keygen -f /root/.ssh/id_rsa -q -N ''\nRUN cp -v /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n\n# Install Python.\nRUN apt-get update -qq && apt-get install -y python${PYTHON_VERSION} python${PYTHON_VERSION}-dev python${PYTHON_VERSION}-distutils && \\\n    rm -rf /var/lib/apt/lists/*\nRUN ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python\nRUN ln -s -f /usr/bin/python${PYTHON_VERSION} /usr/bin/python${PYTHON_VERSION/%.*/}\nRUN if [[ ${PYTHON_VERSION} != \"3.7\" ]]; then \\\n        wget --progress=dot:mega https://bootstrap.pypa.io/get-pip.py; \\\n    else \\\n        wget --progress=dot:mega https://bootstrap.pypa.io/pip/3.7/get-pip.py; \\\n    fi && python get-pip.py && rm get-pip.py\n\nRUN pip install --no-cache-dir -U --force requests \"pytest<8\" mock pytest-forked parameterized\n\n# Add launch helper scripts\nRUN echo \"env SPARK_HOME=/spark SPARK_DRIVER_MEM=512m PYSPARK_PYTHON=/usr/bin/python${PYTHON_VERSION} PYSPARK_DRIVER_PYTHON=/usr/bin/python${PYTHON_VERSION} \\\"\\$@\\\"\" > /spark_env.sh\nRUN echo /spark_env.sh pytest -v --capture=no --continue-on-collection-errors --junit-xml=/artifacts/junit.\\$1.\\${HOROVOD_RANK:-\\${OMPI_COMM_WORLD_RANK:-\\${PMI_RANK}}}.\\$2.xml \\${@:2} > /pytest.sh\nRUN echo /spark_env.sh pytest -v --capture=no --continue-on-collection-errors --junit-xml=/artifacts/junit.\\$1.standalone.\\$2.xml --forked \\${@:2} > /pytest_standalone.sh\nRUN chmod a+x /spark_env.sh\nRUN chmod a+x /pytest.sh\nRUN chmod a+x /pytest_standalone.sh\n\n# Install Spark stand-alone cluster.\nRUN if [[ -n ${SPARK_PACKAGE} ]]; then \\\n        wget --progress=dot:giga \"https://www.apache.org/dyn/closer.lua/spark/${SPARK_PACKAGE}?action=download\" -O - | tar -xzC /tmp; \\\n        archive=$(basename \"${SPARK_PACKAGE}\") bash -c \"mv -v /tmp/\\${archive/%.tgz/} /spark\"; \\\n    fi\n\n# Install PySpark.\nRUN apt-get update -qq && apt install -y openjdk-8-jdk-headless\nRUN if [[ ${SPARK_PACKAGE} != *\"-preview\"* ]]; then \\\n        pip install --no-cache-dir ${PYSPARK_PACKAGE}; \\\n    else \\\n        apt-get update -qq && apt-get install pandoc; \\\n        pip install --no-cache-dir pypandoc; \\\n        (cd /spark/python && python setup.py sdist && pip install --no-cache-dir dist/pyspark-*.tar.gz && rm dist/pyspark-*); \\\n    fi\n\n# Install Ray.\nRUN pip install --no-cache-dir ray\n\n# Install MPI.\nRUN if [[ ${MPI_KIND} == \"OpenMPI\" ]]; then \\\n        wget --progress=dot:mega -O /tmp/openmpi-4.1.4-bin.tar.gz https://download.open-mpi.org/release/open-mpi/v4.1/openmpi-4.1.4.tar.gz && \\\n            cd /tmp && tar -zxf /tmp/openmpi-4.1.4-bin.tar.gz && \\\n            mkdir openmpi-4.1.4/build && cd openmpi-4.1.4/build && ../configure --prefix=/usr/local && \\\n            make -j all && make install && ldconfig && \\\n            echo \"mpirun -allow-run-as-root -np 2 -H localhost:2 -bind-to none -map-by slot -mca mpi_abort_print_stack 1 -tag-output\" > /mpirun_command; \\\n    elif [[ ${MPI_KIND} == \"MPICH\" ]]; then \\\n        apt-get update -qq && apt-get install -y mpich && \\\n            echo \"mpirun -np 2 -l\" > /mpirun_command; \\\n    fi\n\n# Set default NCCL parameters\nRUN echo NCCL_DEBUG=INFO >> /etc/nccl.conf\n\n# Install mpi4py.\n# This requires SETUPTOOLS_USE_DISTUTILS=stdlib as with setuptools>=60.1.0 installing mpi4py broke\n# https://github.com/mpi4py/mpi4py/issues/157#issuecomment-1001022274\nRUN if [[ ${MPI_KIND} != \"None\" ]]; then \\\n        SETUPTOOLS_USE_DISTUTILS=stdlib pip install --no-cache-dir mpi4py; \\\n    fi\n\n# Install TensorFlow and Keras (releases).\n# Pin scipy!=1.4.0: https://github.com/scipy/scipy/issues/11237\n# Pin protobuf~=3.20 for tensorflow<2.6.5: https://github.com/tensorflow/tensorflow/issues/56077\nRUN if [[ ${TENSORFLOW_PACKAGE} != \"tf-nightly\" ]]; then \\\n        if [[ ${TENSORFLOW_PACKAGE} == nvidia-tensorflow==* ]]; then \\\n            pip install nvidia-pyindex; \\\n        fi; \\\n        PROTOBUF_PACKAGE=\"\"; \\\n        if [[ ${TENSORFLOW_PACKAGE} == tensorflow-gpu==1.15.* ]] || \\\n           [[ ${TENSORFLOW_PACKAGE} == tensorflow-gpu==2.[012345].* ]] || \\\n           [[ ${TENSORFLOW_PACKAGE} == nvidia-tensorflow==* ]]; then \\\n            PROTOBUF_PACKAGE=\"protobuf~=3.20\"; \\\n        fi; \\\n        pip install --no-cache-dir ${TENSORFLOW_PACKAGE} ${PROTOBUF_PACKAGE}; \\\n        if [[ ${KERAS_PACKAGE} != \"None\" ]]; then \\\n            pip uninstall -y keras; \\\n            pip install --no-cache-dir ${KERAS_PACKAGE} \"scipy!=1.4.0\" \"pandas<1.1.0\" \"numpy<1.24.0\"; \\\n        fi; \\\n        mkdir -p ~/.keras; \\\n        ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs; \\\n        python -c \"import tensorflow as tf; tf.keras.datasets.mnist.load_data()\"; \\\n        ldconfig; \\\n    fi\n\n# Pin h5py < 3 for tensorflow: https://github.com/tensorflow/tensorflow/issues/44467\nRUN pip install 'h5py<3.0' 'numpy<1.24.0' --force-reinstall\n\n# Install PyTorch (releases).\n# Pin Pillow<7.0 for torchvision < 0.5.0: https://github.com/pytorch/vision/issues/1718\n# Pin Pillow!=8.3.0 for torchvision: https://github.com/pytorch/vision/issues/4146\n# installing pytorch lightning < 1.8.4 with pip > 23.2.1 fails with:\n#   invalid metadata: .* suffix can only be used with == or != operators\n# https://github.com/pypa/pipx/issues/998\nRUN if [[ ${PYTORCH_PACKAGE} != \"torch-nightly-cu\"* ]]; then \\\n        pip install --no-cache-dir ${PYTORCH_PACKAGE} ${TORCHVISION_PACKAGE} -f https://download.pytorch.org/whl/${PYTORCH_PACKAGE/*+/}/torch_stable.html; \\\n        if [[ \"${TORCHVISION_PACKAGE/%+*/}\" == torchvision==0.[1234].* ]]; then \\\n            pip install --no-cache-dir \"Pillow<7.0\" --no-deps; \\\n        else \\\n            pip install --no-cache-dir \"Pillow!=8.3.0\" --no-deps; \\\n        fi; \\\n        \\\n        IFS=. read maj min patch <<< `cut -d \"=\" -f 3 <<< \"${PYTORCH_LIGHTNING_PACKAGE}\"`; \\\n        if [[ $maj < 1 || $maj == 1 && ( $min < 8 || $min == 8 && $patch < 4) ]]; then \\\n            pip install -U pip==23.2.1; \\\n        fi; \\\n        \\\n        pip install ${PYTORCH_LIGHTNING_PACKAGE}; \\\n    fi\n\n# Install MXNet (releases).\nRUN if [[ ${MXNET_PACKAGE} != \"mxnet-nightly-cu\"* ]]; then \\\n        pip install --no-cache-dir ${MXNET_PACKAGE} ; \\\n    fi\n\n# Prefetch Spark MNIST dataset.\nRUN mkdir -p /work /data && wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/mnist.bz2 -O /data/mnist.bz2\n\n# Prefetch Spark Rossmann dataset.\nRUN mkdir -p /work /data && wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/rossmann.tgz -O - | tar -xzC /data\n\n# Prefetch PyTorch datasets.\nRUN wget --progress=dot:mega https://horovod-datasets.s3.amazonaws.com/pytorch_datasets.tgz -O - | tar -xzC /data\n\n### END OF CACHE ###\nCOPY . /horovod\n\n# Install nightly packages here so they do not get cached\n\n# Install TensorFlow and Keras (nightly).\n# Pin scipy!=1.4.0: https://github.com/scipy/scipy/issues/11237\nRUN if [[ ${TENSORFLOW_PACKAGE} == \"tf-nightly\" ]]; then \\\n        pip install --no-cache-dir ${TENSORFLOW_PACKAGE}; \\\n        if [[ ${KERAS_PACKAGE} != \"None\" ]]; then \\\n            pip uninstall -y keras-nightly; \\\n            pip install --no-cache-dir ${KERAS_PACKAGE} \"scipy!=1.4.0\" \"pandas<1.1.0\" \"numpy<1.24.0\"; \\\n        fi; \\\n        mkdir -p ~/.keras; \\\n        ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs; \\\n        python -c \"import tensorflow as tf; tf.keras.datasets.mnist.load_data()\"; \\\n        ldconfig; \\\n    fi\n\n# Install PyTorch (nightly).\n# Pin Pillow!=8.3.0 for torchvision: https://github.com/pytorch/vision/issues/4146\n# installing pytorch lightning < 1.8.4 with pip > 23.2.1 fails with:\n#   invalid metadata: .* suffix can only be used with == or != operators\n# https://github.com/pypa/pipx/issues/998\nRUN if [[ ${PYTORCH_PACKAGE} == \"torch-nightly-cu\"* ]]; then \\\n        pip install --no-cache-dir --pre torch ${TORCHVISION_PACKAGE} -f https://download.pytorch.org/whl/nightly/${PYTORCH_PACKAGE/#torch-nightly-/}/torch_nightly.html; \\\n        pip install --no-cache-dir \"Pillow!=8.3.0\" --no-deps; \\\n        \\\n        IFS=. read maj min patch <<< `cut -d \"=\" -f 3 <<< \"${PYTORCH_LIGHTNING_PACKAGE}\"`; \\\n        if [[ $maj < 1 || $maj == 1 && ( $min < 8 || $min == 8 && $patch < 4) ]]; then \\\n            pip install -U pip==23.2.1; \\\n        fi; \\\n        \\\n        pip install ${PYTORCH_LIGHTNING_PACKAGE}; \\\n    fi\n\n# Install MXNet (nightly).\nRUN if [[ ${MXNET_PACKAGE} == \"mxnet-nightly-cu\"* ]]; then \\\n        pip install --no-cache-dir --pre ${MXNET_PACKAGE/-nightly/} -f https://dist.mxnet.io/python/${MXNET_PACKAGE/#mxnet-nightly-/}; \\\n    fi\n\n# Install Horovod.\nRUN cd /horovod && \\\n    python setup.py sdist && \\\n    ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \\\n    bash -c \"${HOROVOD_BUILD_FLAGS} HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_MXNET=1 pip install --no-cache-dir -v $(ls /horovod/dist/horovod-*.tar.gz)[spark,ray] 'protobuf~=3.20'\" && \\\n    ldconfig\n\n# Show the effective python package version to easily spot version differences\nRUN pip freeze | sort\n\n# Assert installed package versions\nRUN /horovod/assert-package-versions.sh\n\n# Hack for compatibility of MNIST example with TensorFlow 1.1.0.\nRUN if [[ ${TENSORFLOW_PACKAGE} == \"tensorflow-gpu==1.1.0\" ]]; then \\\n        sed -i \"s/from tensorflow import keras/from tensorflow.contrib import keras/\" /horovod/examples/tensorflow/tensorflow_mnist.py; \\\n    fi\n\n# Hack TensorFlow MNIST example to be smaller.\nRUN sed -i \"s/last_step=20000/last_step=100/\" /horovod/examples/tensorflow/tensorflow_mnist.py\n\n# Hack TensorFlow Eager MNIST example to be smaller.\nRUN sed -i \"s/dataset.take(20000/dataset.take(100/\" /horovod/examples/tensorflow/tensorflow_mnist_eager.py\n\n# Hack TensorFlow 2.0 example to be smaller.\nRUN sed -i \"s/dataset.take(10000/dataset.take(100/\" /horovod/examples/tensorflow2/tensorflow2_mnist.py\n\n# Hack TensorFlow 2.0 Data Service example to be smaller.\nRUN sed -i \"s/ epochs=24/ epochs=2/\" /horovod/examples/tensorflow2/tensorflow2_mnist_data_service_train_fn_*_side_dispatcher.py\n\n# Hack Keras MNIST advanced example to be smaller.\nRUN sed -i \"s/'--epochs', type=int, default=24,/'--epochs', type=int, default=2,/\" /horovod/examples/keras/keras_mnist_advanced.py\n\n# Hack TensorFlow 2.0 Keras MNIST advanced example to be smaller.\nRUN sed -i \"s/epochs=24/epochs=2/\" /horovod/examples/tensorflow2/tensorflow2_keras_mnist.py\n\n# Hack PyTorch MNIST example to be smaller.\nRUN sed -i \"s/'--epochs', type=int, default=10,/'--epochs', type=int, default=2,/\" /horovod/examples/pytorch/pytorch_mnist.py\n\n# Hack Keras Spark Rossmann Run example to be smaller.\nRUN sed -i \"s/x = Dense(1000,/x = Dense(100,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_run.py\nRUN sed -i \"s/x = Dense(500,/x = Dense(50,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_run.py\n\n# Hack Keras Spark Rossmann Estimator example to be smaller.\nRUN sed -i \"s/x = Dense(1000,/x = Dense(100,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_estimator.py\nRUN sed -i \"s/x = Dense(500,/x = Dense(50,/g\" /horovod/examples/spark/keras/keras_spark_rossmann_estimator.py\n\n# Export HOROVOD_MIXED_INSTALL\nENV HOROVOD_MIXED_INSTALL=${HOROVOD_MIXED_INSTALL}\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 3.6416015625,
          "content": "## Governance of the Horovod Project\n\nHorovod is a graduated projected within the [LF AI & Data Foundation](https://lfaidata.foundation/).\n\n### Charter\n\nYou can find Horovod Charter [here](https://wiki.lfai.foundation/download/attachments/7733301/Horovod%20Project%20Technical%20Charter%2012-22-2018%20FINAL.pdf?version=1&modificationDate=1558389484000&api=v2)\n\n### Technical Steering Committee\n\nHorovod development is governed by the Horovod Technical Steering Committee (TSC). The TSC consists of voting and\nnon-voting members, in addition to a chairman responsible for running TSC meetings, setting the meeting agenda, and\ncalling votes on proposals.\n\nCurrent chairman of the Horovod TSC:\n* [Travis Addair](https://github.com/tgaddair) - Predibase\n\nCurrent voting members of the Horovod TSC:\n* [Alex Sergeev](https://github.com/alsrgv) - Carbon Robotics\n* [Travis Addair](https://github.com/tgaddair) - Predibase\n* [Can Karakus](https://github.com/karakusc) - Amazon\n* [Josh Romero](https://github.com/romerojosh) - NVIDIA\n* [Nicolas Castet](https://github.com/nvcastet) - NVIDIA\n* [Enrico Minack](https://github.com/EnricoMi) - G-Research\n* [Xu Ning](https://github.com/thuningxu) - Snap Inc.\n* [Todd Mytkowicz](https://github.com/klipto) - Microsoft\n* [Max Gerlach](https://github.com/maxhgerlach) - DeepL\n\nCurrent non-voting members of the Horovod TSC:\n* [Leonard Lausen](https://github.com/leezu) - Amazon\n* [Jonathan Dekhtiar](https://github.com/DEKHTIARJonathan) - NVIDIA\n* [Richard Liaw](https://github.com/richardliaw) - Anyscale\n* [Neil Conway](https://github.com/neilconway) - Determined AI, HPE\n* [Min Cai](https://github.com/mincai) - Uber\n* [Chongxiao Cao](https://github.com/chongxiaoc) - Uber\n* [Ryan Beethe](https://github.com/rb-determined-ai) - Determined AI, HPE\n* [Abin Shahab](https://github.com/ashahab) - LinkedIn\n* [TJ Xu](https://github.com/Tixxx) - NVIDIA\n* [Keqiu Hu](https://github.com/oliverhu) - LinkedIn\n* [Peng Zhang](https://github.com/irasit) - Uber\n\nEmeritus members of the Horovod TSC:\n* [Lin Yuan](https://github.com/apeforest)\n* [Haibin Lin](https://github.com/eric-haibin-lin)\n* [Yuxi Hu](https://github.com/yuxihu)\n* [Emad Barsoum](https://github.com/ebarsoum)\n* [Aaron Harlap](https://github.com/aaron276h)\n* [Jaliya Ekanayake](https://github.com/jaliyae)\n* [Kaarthik Sivashanmugam](https://github.com/skaarthik)\n* [Armand McQueen](https://github.com/armandmcqueen)\n\nNon-voting members of the TSC (\"maintainers\") have commit access to the Horovod GitHub repository, and take part in the\nstanding TSC meetings and mailing lists. Emeritus members are no longer active maintainers of the project, but are\nwelcome to participate in any TSC meeting.\n\nThe Horovod TSC meets monthly and publishes meeting notes via a [mailing list](https://lists.lfai.foundation/g/horovod-tsc).\nThis mailing list can also be utilized to reach out to the TSC.  Major decisions regarding the technical directions of\nthe Horovod project will be brought before the TSC for discussion, with an accompanying proposal document termed an RFC\n(Request for Comments).\n\nTechnical decisions made by the TSC should be unanimous, with each voting and non-voting member either agreeing to the\nproposal or abstaining for it to pass.  If consensus cannot be reached, then the proposal is to be put to a vote\namong the voting members of the TSC, at which point a majority of the voting TSC must agree to the proposal for it to\npass.\n\nDecisions to add or change members of the TSC in either a voting or non-voting capacity are handled the same as other\nproposals (without an RFC): an attempt is made to reach a unanimous decision among the entire TSC, followed by a vote\namong the voting members if no consensus can be reached.\n"
        },
        {
          "name": "Jenkinsfile.ppc64le",
          "type": "blob",
          "size": 2.7666015625,
          "content": "pipeline {\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '30'))\n        timeout(time: 30, unit: 'MINUTES')\n    }\n    agent {\n        docker {\n            alwaysPull true\n            // Open-CE 1.4.1 has CUDA 10.2, NCCL 2.8.3, TensorFlow 2.6.0, and PyTorch 1.9.1\n            image 'tensorflowppc64le/tensorflow-ppc64le:osuosl-ubi7-horovod-opence1.4.1-py3.9-ppc64le'\n            args '--cap-add=SYS_PTRACE --shm-size=256g'\n            label 'power8-gpu'\n            registryCredentialsId 'TensorFlow'\n        }\n    }\n    stages {\n        stage ('UPDATE_GITHUB_STATUS') {\n            steps {\n                setBuildStatus(\"ppc64le Build/Tests Pending\", \"PENDING\");\n            }\n        }\n        stage ('BUILD_HOROVOD') {\n            steps {\n                sh '''#!/usr/bin/env bash\n                      git submodule update --init --recursive\n                      . ${CONDA_INIT}\n                      conda activate ${CONDA_ENV}\n                      set -xe\n                      HOROVOD_WITHOUT_MXNET=1 HOROVOD_WITHOUT_GLOO=1 HOROVOD_WITH_PYTORCH=1 HOROVOD_WITH_TENSORFLOW=1 \\\n                          HOROVOD_CUDA_HOME=\"/usr/local/cuda\" HOROVOD_GPU_OPERATIONS=NCCL \\\n                          pip install -v . --no-cache-dir --no-deps\n                '''\n            }\n        }\n        stage ('TEST_HOROVOD') {\n            steps {\n                ansiColor('xterm') {\n                    sh '''#!/usr/bin/env bash\n                          . ${CONDA_INIT}\n                          conda activate ${CONDA_ENV}\n                          set -xe\n\n                          # TensorFlow unit tests\n                          horovodrun -n 2 -H localhost:2 pytest -k 'not multi_gpu' -v -s test/parallel/test_tensorflow.py\n                          # Container has only 2 GPUs, so run the 'multi_gpu' test seperatly on one process\n                          horovodrun -n 1 -H localhost:1 pytest -k 'multi_gpu' -v -s test/parallel/test_tensorflow.py\n\n                          # PyTorch unit tests\n                          horovodrun -n 2 -H localhost:2 pytest -v -s test/parallel/test_torch.py\n                    '''\n                }\n            }\n        }\n    } // end of stages\n    post {\n        success {\n            setBuildStatus(\"ppc64le Build/Tests Passed\", \"SUCCESS\");\n        }\n        failure {\n            setBuildStatus(\"ppc64le Build/Tests Failed\", \"FAILURE\");\n        }\n        unstable {\n            setBuildStatus(\"ppc64le Build/Tests Failed\", \"FAILURE\");\n        }\n    }\n} //end of pipeline\n\nvoid setBuildStatus(String message, String state) {\n    githubNotify context: 'ppc64le-checks', description: \"${message}\",  status: \"${state}\",\n                 targetUrl: \"https://powerci.osuosl.org/job/Horovod_PPC64LE_GPU_PIPELINE/view/change-requests/job/${BRANCH_NAME}/${BUILD_NUMBER}/console\"\n}\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.68359375,
          "content": "   Horovod\n   Copyright 2018 Uber Technologies, Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 1.228515625,
          "content": "recursive-include * *.h *.hpp *.cc *.cu *.md *.cmake CMakeLists.txt\n\ninclude LICENSE horovod.lds horovod.exp CMakeLists.txt\ninclude cmake/build_utils.py\nprune .eggs\n\n# prune eigen LGPL2\ngraft third_party/eigen/Eigen\nexclude third_party/eigen/Eigen/Eigen\nexclude third_party/eigen/Eigen/IterativeLinearSolvers\nexclude third_party/eigen/Eigen/MetisSupport\nexclude third_party/eigen/Eigen/Sparse\nexclude third_party/eigen/Eigen/SparseCholesky\nexclude third_party/eigen/Eigen/SparseLU\nexclude third_party/eigen/Eigen/src/IterativeSolvers/*\nexclude third_party/eigen/Eigen/src/OrderingMethods/Amd.h\nexclude third_party/eigen/Eigen/src/SparseCholesky/*\nexclude third_party/eigen/unsupported/test/mpreal/mpreal.h\nexclude third_party/eigen/unsupported/Eigen/FFT\nexclude third_party/eigen/unsupported/Eigen/MPRealSupport\nexclude third_party/eigen/doc/PreprocessorDirectives.dox\nexclude third_party/eigen/doc/UsingIntelMKL.dox\nexclude third_party/eigen/doc/SparseLinearSystems.dox\nexclude third_party/eigen/COPYING.GPL\nexclude third_party/eigen/COPYING.LGPL\nexclude third_party/eigen/COPYING.README\n\n# include cmake related files for submodule gloo\ngraft third_party/gloo/cmake\nrecursive-include third_party/gloo CMakeLists.txt\nrecursive-include third_party/gloo *.in\n"
        },
        {
          "name": "NOTICE",
          "type": "blob",
          "size": 12.587890625,
          "content": "   Horovod includes derived work from the following:\n\n   FlatBuffers\n   Copyright (c) 2014 Google Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n          http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n   baidu-research/tensorflow-allreduce\n   Copyright (c) 2015, The TensorFlow Authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n          http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n   NVIDIA/cutlass\n   Copyright (c) 2017, NVIDIA CORPORATION.  All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are met:\n      *  Redistributions of source code must retain the above copyright\n         notice, this list of conditions and the following disclaimer.\n      *  Redistributions in binary form must reproduce the above copyright\n         notice, this list of conditions and the following disclaimer in the\n         documentation and/or other materials provided with the distribution.\n      *  Neither the name of the NVIDIA CORPORATION nor the\n         names of its contributors may be used to endorse or promote products\n         derived from this software without specific prior written permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n   ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n   WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n   DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY\n   DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n   (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n   LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n   ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n   SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n   scikit-learn\n   Copyright (c) 2007–2018 The scikit-learn developers. All rights reserved.\n\n   Licensed under the New BSD License:\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are met:\n\n     a. Redistributions of source code must retain the above copyright notice,\n        this list of conditions and the following disclaimer.\n     b. Redistributions in binary form must reproduce the above copyright\n        notice, this list of conditions and the following disclaimer in the\n        documentation and/or other materials provided with the distribution.\n     c. Neither the name of the Scikit-learn Developers  nor the names of\n        its contributors may be used to endorse or promote products\n        derived from this software without specific prior written\n        permission.\n\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n   ARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR\n   ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n   SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n   CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n   LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n   OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\n   DAMAGE.\n\n   The derived work can be found in the files:\n\n        - horovod/common/optim/gaussian_process.h\n        - horovod/common/optim/gaussian_process.cc\n\n   krasserm/bayesian-machine-learning (http://krasserm.github.io)\n   Copyright 2018 Martin Krasser. All Rights Reserved.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n        http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n   The derived work can be found in the files:\n\n        - horovod/common/optim/bayesian_optimization.h\n        - horovod/common/optim/bayesian_optimization.cc\n        - horovod/common/optim/gaussian_process.h\n        - horovod/common/optim/gaussian_process.cc\n\n   fastai/fastai\n   Copyright 2017 onwards, fast.ai, Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n          http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n   The derived work can be found in the files:\n\n        - examples/spark/keras/keras_spark_rossmann_run.py\n\n   elnormous/HTTPRequest\n   Copyright (c) 2017, Elviss Strazdiņš\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are met:\n\n   * Redistributions of source code must retain the above copyright notice, this\n     list of conditions and the following disclaimer.\n\n   * Redistributions in binary form must reproduce the above copyright notice,\n     this list of conditions and the following disclaimer in the documentation\n     and/or other materials provided with the distribution.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n   DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n   FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n   DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n   SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n   CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n   OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n   pytorch\n   From PyTorch:\n\n   Copyright (c) 2016-     Facebook, Inc            (Adam Paszke)\n   Copyright (c) 2014-     Facebook, Inc            (Soumith Chintala)\n   Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)\n   Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)\n   Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)\n   Copyright (c) 2011-2013 NYU                      (Clement Farabet)\n   Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)\n   Copyright (c) 2006      Idiap Research Institute (Samy Bengio)\n   Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)\n\n   From Caffe2:\n\n   Copyright (c) 2016-present, Facebook Inc. All rights reserved.\n\n   All contributions by Facebook:\n   Copyright (c) 2016 Facebook Inc.\n   \n   All contributions by Google:\n   Copyright (c) 2015 Google Inc.\n   All rights reserved.\n   \n   All contributions by Yangqing Jia:\n   Copyright (c) 2015 Yangqing Jia\n   All rights reserved.\n   \n   All contributions from Caffe:\n   Copyright(c) 2013, 2014, 2015, the respective contributors\n   All rights reserved.\n   \n   All other contributions:\n   Copyright(c) 2015, 2016 the respective contributors\n   All rights reserved.\n   \n   Caffe2 uses a copyright model similar to Caffe: each contributor holds\n   copyright over their contributions to Caffe2. The project versioning records\n   all such contribution and copyright details. If a contributor wants to further\n   mark their specific copyright on a particular contribution, they should\n   indicate their copyright solely in the commit message of the change when it is\n   committed.\n\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions are met:\n\n   1. Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n\n   2. Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n\n   3. Neither the names of Facebook, Deepmind Technologies, NYU, NEC Laboratories America\n      and IDIAP Research Institute nor the names of its contributors may be\n      used to endorse or promote products derived from this software without\n      specific prior written permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n   AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n   ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n   LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n   CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n   SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n   INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n   CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n   ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n   POSSIBILITY OF SUCH DAMAGE.\n\n   The derived work can be found in the files:\n\n        - horovod/torch/sync_batch_norm.py\n\n   CMake - Cross Platform Makefile Generator\n   Copyright 2000-2020 Kitware, Inc. and Contributors\n   All rights reserved.\n\n   Redistribution and use in source and binary forms, with or without\n   modification, are permitted provided that the following conditions\n   are met:\n\n   * Redistributions of source code must retain the above copyright\n     notice, this list of conditions and the following disclaimer.\n\n   * Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n\n   * Neither the name of Kitware, Inc. nor the names of Contributors\n     may be used to endorse or promote products derived from this\n     software without specific prior written permission.\n\n   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n   \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n   HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n      The derived work can be found in the files:\n\n          - cmake/upstream/FindCUDAToolkit.cmake\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 16.0556640625,
          "content": ".. raw:: html\n\n    <p align=\"center\"><img src=\"https://user-images.githubusercontent.com/16640218/34506318-84d0c06c-efe0-11e7-8831-0425772ed8f2.png\" alt=\"Logo\" width=\"200\"/></p>\n    <br/>\n\nHorovod\n=======\n\n.. raw:: html\n\n   <div align=\"center\">\n\n.. image:: https://badge.fury.io/py/horovod.svg\n   :target: https://badge.fury.io/py/horovod\n   :alt: PyPI Version\n\n.. image:: https://badge.buildkite.com/6f976bc161c69d9960fc00de01b69deb6199b25680a09e5e26.svg?branch=master\n   :target: https://buildkite.com/horovod/horovod\n   :alt: Build Status\n\n.. image:: https://readthedocs.org/projects/horovod/badge/?version=latest\n   :target: https://horovod.readthedocs.io/en/latest/\n   :alt: Documentation Status\n\n.. image:: https://img.shields.io/badge/slack-chat-green.svg?logo=slack\n   :target: https://forms.gle/cPGvty5hp31tGfg79\n   :alt: Slack\n\n.. raw:: html\n\n   </div>\n\n.. raw:: html\n\n   <div align=\"center\">\n\n.. image:: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n   :target: https://img.shields.io/badge/License-Apache%202.0-blue.svg\n   :alt: License\n\n.. image:: https://app.fossa.com/api/projects/git%2Bgithub.com%2Fhorovod%2Fhorovod.svg?type=shield\n   :target: https://app.fossa.com/projects/git%2Bgithub.com%2Fhorovod%2Fhorovod?ref=badge_shield\n   :alt: FOSSA Status\n\n.. image:: https://bestpractices.coreinfrastructure.org/projects/2373/badge\n   :target: https://bestpractices.coreinfrastructure.org/projects/2373\n   :alt: CII Best Practices\n\n.. image:: https://pepy.tech/badge/horovod\n   :target: https://pepy.tech/project/horovod\n   :alt: Downloads\n\n.. raw:: html\n\n   </div>\n\n.. inclusion-marker-start-do-not-remove\n\n|\n\nHorovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\nThe goal of Horovod is to make distributed deep learning fast and easy to use.\n\n\n.. raw:: html\n\n   <p><img src=\"https://raw.githubusercontent.com/lfai/artwork/master/lfaidata-assets/lfaidata-project-badge/graduate/color/lfaidata-project-badge-graduate-color.png\" alt=\"LF AI & Data\" width=\"200\"/></p>\n\n\nHorovod is hosted by the `LF AI & Data Foundation <https://lfdl.io>`_ (LF AI & Data). If you are a company that is deeply\ncommitted to using open source technologies in artificial intelligence, machine, and deep learning, and want to support\nthe communities of open source projects in these domains, consider joining the LF AI & Data Foundation. For details\nabout who's involved and how Horovod plays a role, read the Linux Foundation `announcement <https://lfdl.io/press/2018/12/13/lf-deep-learning-welcomes-horovod-distributed-training-framework-as-newest-project/>`_.\n\n|\n\n.. contents::\n\n|\n\nDocumentation\n-------------\n\n- `Latest Release <https://horovod.readthedocs.io/en/stable>`_\n- `master <https://horovod.readthedocs.io/en/latest>`_\n\n|\n\nWhy Horovod?\n------------\nThe primary motivation for this project is to make it easy to take a single-GPU training script and successfully scale\nit to train across many GPUs in parallel. This has two aspects:\n\n1. How much modification does one have to make to a program to make it distributed, and how easy is it to run it?\n2. How much faster would it run in distributed mode?\n\nInternally at Uber we found the MPI model to be much more straightforward and require far less code changes than previous\nsolutions such as Distributed TensorFlow with parameter servers. Once a training script has been written for scale with\nHorovod, it can run on a single-GPU, multiple-GPUs, or even multiple hosts without any further code changes.\nSee the `Usage <#usage>`__ section for more details.\n\nIn addition to being easy to use, Horovod is fast. Below is a chart representing the benchmark that was done on 128\nservers with 4 Pascal GPUs each connected by RoCE-capable 25 Gbit/s network:\n\n.. image:: https://user-images.githubusercontent.com/16640218/38965607-bf5c46ca-4332-11e8-895a-b9c137e86013.png\n   :alt: 512-GPU Benchmark\n\nHorovod achieves 90% scaling efficiency for both Inception V3 and ResNet-101, and 68% scaling efficiency for VGG-16.\nSee `Benchmarks <docs/benchmarks.rst>`_ to find out how to reproduce these numbers.\n\nWhile installing MPI and NCCL itself may seem like an extra hassle, it only needs to be done once by the team dealing\nwith infrastructure, while everyone else in the company who builds the models can enjoy the simplicity of training them at\nscale.\n\n\nInstall\n-------\nTo install Horovod on Linux or macOS:\n\n1. Install `CMake <https://cmake.org/install/>`__\n\n.. raw:: html\n\n    <p/>\n\n2. If you've installed TensorFlow from `PyPI <https://pypi.org/project/tensorflow>`__, make sure that ``g++-5`` or above is installed.\n   Starting with TensorFlow 2.10 a C++17-compliant compiler like ``g++8`` or above will be required.\n\n   If you've installed PyTorch from `PyPI <https://pypi.org/project/torch>`__, make sure that ``g++-5`` or above is installed.\n\n   If you've installed either package from `Conda <https://conda.io>`_, make sure that the ``gxx_linux-64`` Conda package is installed.\n\n.. raw:: html\n\n    <p/>\n\n3. Install the ``horovod`` pip package.\n\n   To run on CPUs:\n\n   .. code-block:: bash\n\n      $ pip install horovod\n\n   To run on GPUs with NCCL:\n\n   .. code-block:: bash\n\n      $ HOROVOD_GPU_OPERATIONS=NCCL pip install horovod\n\nFor more details on installing Horovod with GPU support, read `Horovod on GPU <docs/gpus.rst>`_.\n\nFor the full list of Horovod installation options, read the `Installation Guide <docs/install.rst>`_.\n\nIf you want to use MPI, read `Horovod with MPI <docs/mpi.rst>`_.\n\nIf you want to use Conda, read `Building a Conda environment with GPU support for Horovod <docs/conda.rst>`_.\n\nIf you want to use Docker, read `Horovod in Docker <docs/docker.rst>`_.\n\nTo compile Horovod from source, follow the instructions in the `Contributor Guide <docs/contributors.rst>`_.\n\n\nConcepts\n--------\nHorovod core principles are based on `MPI <http://mpi-forum.org/>`_ concepts such as *size*, *rank*,\n*local rank*, **allreduce**, **allgather**, **broadcast**, and **alltoall**. See `this page <docs/concepts.rst>`_\nfor more details.\n\nSupported frameworks\n--------------------\nSee these pages for Horovod examples and best practices:\n\n- `Horovod with TensorFlow <docs/tensorflow.rst>`_\n- `Horovod with XLA in Tensorflow <xla.rst>`_\n- `Horovod with Keras <docs/keras.rst>`_\n- `Horovod with PyTorch <docs/pytorch.rst>`_\n- `Horovod with MXNet <docs/mxnet.rst>`_\n\nUsage\n-----\n\nTo use Horovod, make the following additions to your program:\n\n1. Run ``hvd.init()`` to initialize Horovod.\n\n.. raw:: html\n\n    <p/>\n\n2. Pin each GPU to a single process to avoid resource contention.\n\n   With the typical setup of one GPU per process, set this to *local rank*. The first process on\n   the server will be allocated the first GPU, the second process will be allocated the second GPU, and so forth.\n\n.. raw:: html\n\n    <p/>\n\n\n3. Scale the learning rate by the number of workers.\n\n   Effective batch size in synchronous distributed training is scaled by the number of workers.\n   An increase in learning rate compensates for the increased batch size.\n\n.. raw:: html\n\n    <p/>\n\n\n4. Wrap the optimizer in ``hvd.DistributedOptimizer``.\n\n   The distributed optimizer delegates gradient computation to the original optimizer, averages gradients using **allreduce** or **allgather**, and then applies those averaged gradients.\n\n.. raw:: html\n\n    <p/>\n\n\n5. Broadcast the initial variable states from rank 0 to all other processes.\n\n   This is necessary to ensure consistent initialization of all workers when training is started with random weights or restored from a checkpoint.\n\n.. raw:: html\n\n    <p/>\n\n\n6. Modify your code to save checkpoints only on worker 0 to prevent other workers from corrupting them.\n\n.. raw:: html\n\n    <p/>\n\n\nExample using TensorFlow v1 (see the `examples <https://github.com/horovod/horovod/blob/master/examples/>`_ directory for full training examples):\n\n.. code-block:: python\n\n    import tensorflow as tf\n    import horovod.tensorflow as hvd\n\n\n    # Initialize Horovod\n    hvd.init()\n\n    # Pin GPU to be used to process local rank (one GPU per process)\n    config = tf.ConfigProto()\n    config.gpu_options.visible_device_list = str(hvd.local_rank())\n\n    # Build model...\n    loss = ...\n    opt = tf.train.AdagradOptimizer(0.01 * hvd.size())\n\n    # Add Horovod Distributed Optimizer\n    opt = hvd.DistributedOptimizer(opt)\n\n    # Add hook to broadcast variables from rank 0 to all other processes during\n    # initialization.\n    hooks = [hvd.BroadcastGlobalVariablesHook(0)]\n\n    # Make training operation\n    train_op = opt.minimize(loss)\n\n    # Save checkpoints only on worker 0 to prevent other workers from corrupting them.\n    checkpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None\n\n    # The MonitoredTrainingSession takes care of session initialization,\n    # restoring from a checkpoint, saving to a checkpoint, and closing when done\n    # or an error occurs.\n    with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,\n                                           config=config,\n                                           hooks=hooks) as mon_sess:\n      while not mon_sess.should_stop():\n        # Perform synchronous training.\n        mon_sess.run(train_op)\n\n\nRunning Horovod\n---------------\nThe example commands below show how to run distributed training.\nSee `Run Horovod <docs/running.rst>`_ for more details, including RoCE/InfiniBand tweaks and tips for dealing with hangs.\n\n1. To run on a machine with 4 GPUs:\n\n   .. code-block:: bash\n\n        $ horovodrun -np 4 -H localhost:4 python train.py\n\n2. To run on 4 machines with 4 GPUs each:\n\n   .. code-block:: bash\n\n       $ horovodrun -np 16 -H server1:4,server2:4,server3:4,server4:4 python train.py\n\n3. To run using Open MPI without the ``horovodrun`` wrapper, see `Running Horovod with Open MPI <docs/mpi.rst>`_.\n\n4. To run in Docker, see `Horovod in Docker <docs/docker.rst>`_.\n\n5. To run on Kubernetes, see `Helm Chart <https://github.com/horovod/horovod/tree/master/docker/helm/>`_, `Kubeflow MPI Operator <https://github.com/kubeflow/mpi-operator/>`_, `FfDL <https://github.com/IBM/FfDL/tree/master/etc/examples/horovod/>`_, and `Polyaxon <https://docs.polyaxon.com/integrations/horovod/>`_.\n\n6. To run on Spark, see `Horovod on Spark <docs/spark.rst>`_.\n\n7. To run on Ray, see `Horovod on Ray <docs/ray.rst>`_.\n\n8. To run in Singularity, see `Singularity <https://github.com/sylabs/examples/tree/master/machinelearning/horovod>`_.\n\n9. To run in a LSF HPC cluster (e.g. Summit), see `LSF <docs/lsf.rst>`_.\n\n10. To run on Hadoop Yarn, see `TonY <https://github.com/linkedin/TonY/>`_.\n\nGloo\n----\n`Gloo <https://github.com/facebookincubator/gloo>`_ is an open source collective communications library developed by Facebook.\n\nGloo comes included with Horovod, and allows users to run Horovod without requiring MPI to be installed.\n\nFor environments that have support both MPI and Gloo, you can choose to use Gloo at runtime by passing the ``--gloo`` argument to ``horovodrun``:\n\n.. code-block:: bash\n\n     $ horovodrun --gloo -np 2 python train.py\n\nmpi4py\n------\nHorovod supports mixing and matching Horovod collectives with other MPI libraries, such as `mpi4py <https://mpi4py.scipy.org>`_,\nprovided that the MPI was built with multi-threading support.\n\nYou can check for MPI multi-threading support by querying the ``hvd.mpi_threads_supported()`` function.\n\n.. code-block:: python\n\n    import horovod.tensorflow as hvd\n\n    # Initialize Horovod\n    hvd.init()\n\n    # Verify that MPI multi-threading is supported.\n    assert hvd.mpi_threads_supported()\n\n    from mpi4py import MPI\n    assert hvd.size() == MPI.COMM_WORLD.Get_size()\n\nYou can also initialize Horovod with an `mpi4py` sub-communicator, in which case each sub-communicator\nwill run an independent Horovod training.\n\n.. code-block:: python\n\n    from mpi4py import MPI\n    import horovod.tensorflow as hvd\n\n    # Split COMM_WORLD into subcommunicators\n    subcomm = MPI.COMM_WORLD.Split(color=MPI.COMM_WORLD.rank % 2,\n                                   key=MPI.COMM_WORLD.rank)\n\n    # Initialize Horovod\n    hvd.init(comm=subcomm)\n\n    print('COMM_WORLD rank: %d, Horovod rank: %d' % (MPI.COMM_WORLD.rank, hvd.rank()))\n\n\nInference\n---------\nLearn how to optimize your model for inference and remove Horovod operations from the graph `here <docs/inference.rst>`_.\n\n\nTensor Fusion\n-------------\nOne of the unique things about Horovod is its ability to interleave communication and computation coupled with the ability\nto batch small **allreduce** operations, which results in improved performance. We call this batching feature Tensor Fusion.\n\nSee `here <docs/tensor-fusion.rst>`__ for full details and tweaking instructions.\n\n\nHorovod Timeline\n----------------\nHorovod has the ability to record the timeline of its activity, called Horovod Timeline.\n\n.. image:: https://user-images.githubusercontent.com/16640218/29735271-9e148da0-89ac-11e7-9ae0-11d7a099ac89.png\n   :alt: Horovod Timeline\n\nUse Horovod timeline to analyze Horovod performance.\nSee `here <docs/timeline.rst>`__ for full details and usage instructions.\n\n\nAutomated Performance Tuning\n----------------------------\nSelecting the right values to efficiently make use of Tensor Fusion and other advanced Horovod features can involve\na good amount of trial and error. We provide a system to automate this performance optimization process called\n**autotuning**, which you can enable with a single command line argument to ``horovodrun``.\n\nSee `here <docs/autotune.rst>`__ for full details and usage instructions.\n\n\nHorovod Process Sets\n--------------------\nHorovod allows you to concurrently run distinct collective operations in different groups of processes taking part in\none distributed training. Set up ``hvd.process_set`` objects to make use of this capability.\n\nSee `Process Sets <docs/process_set.rst>`__ for detailed instructions.\n\n\nGuides\n------\n1. Run distributed training in Microsoft Azure using `Batch AI and Horovod <https://github.com/Azure/BatchAI/tree/master/recipes/Horovod>`_.\n2. `Distributed model training using Horovod <https://spell.ml/blog/distributed-model-training-using-horovod-XvqEGRUAACgAa5th>`_.\n\nSend us links to any user guides you want to publish on this site\n\nTroubleshooting\n---------------\nSee `Troubleshooting <docs/troubleshooting.rst>`_ and submit a `ticket <https://github.com/horovod/horovod/issues/new>`_\nif you can't find an answer.\n\n\nCitation\n--------\nPlease cite Horovod in your publications if it helps your research:\n\n::\n\n    @article{sergeev2018horovod,\n      Author = {Alexander Sergeev and Mike Del Balso},\n      Journal = {arXiv preprint arXiv:1802.05799},\n      Title = {Horovod: fast and easy distributed deep learning in {TensorFlow}},\n      Year = {2018}\n    }\n\n\nPublications\n------------\n1. Sergeev, A., Del Balso, M. (2017) *Meet Horovod: Uber’s Open Source Distributed Deep Learning Framework for TensorFlow*.\nRetrieved from `https://eng.uber.com/horovod/ <https://eng.uber.com/horovod/>`_\n\n2. Sergeev, A. (2017) *Horovod - Distributed TensorFlow Made Easy*. Retrieved from\n`https://www.slideshare.net/AlexanderSergeev4/horovod-distributed-tensorflow-made-easy <https://www.slideshare.net/AlexanderSergeev4/horovod-distributed-tensorflow-made-easy>`_\n\n3. Sergeev, A., Del Balso, M. (2018) *Horovod: fast and easy distributed deep learning in TensorFlow*. Retrieved from\n`arXiv:1802.05799 <https://arxiv.org/abs/1802.05799>`_\n\n\nReferences\n----------\nThe Horovod source code was based off the Baidu `tensorflow-allreduce <https://github.com/baidu-research/tensorflow-allreduce>`_\nrepository written by Andrew Gibiansky and Joel Hestness. Their original work is described in the article\n`Bringing HPC Techniques to Deep Learning <http://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/>`_.\n\nGetting Involved\n----------------\n- `Community Slack <https://forms.gle/cPGvty5hp31tGfg79>`_ for collaboration and discussion\n- `Horovod Announce <https://lists.lfai.foundation/g/horovod-announce>`_ for updates on the project\n- `Horovod Technical-Discuss <https://lists.lfai.foundation/g/horovod-technical-discuss>`_ for public discussion\n- `Horovod Security <https://lists.lfai.foundation/g/horovod-security>`_ to report security vulnerabilities\n\n\n.. inclusion-marker-end-do-not-remove\n   Place contents above here if they should also appear in read-the-docs.\n   Contents below are already part of the read-the-docs table of contents.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.2607421875,
          "content": "# Security Policy\n\n## Reporting a Vulnerability\n\nPlease report security vulnerabilities to horovod-security@lists.lfaidata.foundation.\n\nAnyone can post to this mailing list, however, only active maintainers of the Horovod project will be able to read to the message.\n"
        },
        {
          "name": "assert-package-versions.sh",
          "type": "blob",
          "size": 1.3447265625,
          "content": "#!/bin/bash\n\nset -euo pipefail\n\nresult=0\n\nfor var in TENSORFLOW_PACKAGE KERAS_PACKAGE PYTORCH_PACKAGE PYTORCH_LIGHTNING_PACKAGE TORCHVISION_PACKAGE MXNET_PACKAGE PYSPARK_PACKAGE\ndo\n  if [ -z \"${!var-}\" ]\n  then\n    echo -e \"$var \\u001b[31mnot set\\u001b[0m\"\n    result=1\n    continue\n  fi\n\n  pattern=\"${!var}\"\n  if [ \"$pattern\" == \"None\" ]\n  then\n    continue\n  elif [[ \"$pattern\" == \"tf-nightly\" ]]\n  then\n    flag=\"-P\"\n    pattern=\"$pattern==.*\\\\.dev20\\\\d{6}\"\n  elif [[ \"$pattern\" == \"torch-nightly\"* ]] ||\n       [[ \"$pattern\" == \"torchvision\" ]]\n  then\n    flag=\"-P\"\n    pattern=\"${pattern/-nightly*/}==.*\\\\.dev20\\\\d{6}.*\"\n  elif [[ \"$pattern\" == \"mxnet-nightly\"* ]]\n  then\n    flag=\"-P\"\n    pattern=\"${pattern/-nightly/}==.*20\\\\d{6}\"\n  else\n    flag=\"-Fx\"\n  fi\n\n  found=$(pip freeze | grep -i $flag \"$pattern\" || true)\n  if [ -n \"$found\" ]\n  then\n    if [ \"$found\" == \"$pattern\" ]\n    then\n      echo -e \"$found \\u001b[32mfound\\u001b[0m\"\n    else\n      echo -e \"$found \\u001b[32mfound\\u001b[0m (matches ${!var} / $pattern)\"\n    fi\n  else\n    found=$(pip freeze | grep -i \"^${pattern/=*/==}\" || true)\n    if [ -n \"$found\" ]\n    then\n      echo -e \"$found \\u001b[31mfound BUT\\u001b[0m ${!var} / $pattern \\u001b[31mexpected\\u001b[0m\"\n    else\n      echo -e \"$pattern \\u001b[31mNOT found\\u001b[0m (no match for ${!var} / $pattern)\"\n    fi\n    result=1\n  fi\ndone\n\nexit $result\n\n"
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.test.yml",
          "type": "blob",
          "size": 11.517578125,
          "content": "version: '2.3'\nservices:\n  test-cpu-base:\n    build:\n      context: .\n      dockerfile: Dockerfile.test.cpu\n      args:\n        UBUNTU_VERSION: 20.04\n        GPP_VERSION: 7\n        MPI_KIND: None\n        PYTHON_VERSION: 3.8\n        TENSORFLOW_PACKAGE: tensorflow-cpu==2.12.0\n        KERAS_PACKAGE: keras==2.12.0\n        PYTORCH_PACKAGE: torch==2.0.0+cpu\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.15.1+cpu\n        MXNET_PACKAGE: mxnet==1.9.1\n        PYSPARK_PACKAGE: pyspark==3.4.0\n        SPARK_PACKAGE: spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n        HOROVOD_BUILD_FLAGS: HOROVOD_WITH_GLOO=1\n    privileged: true\n    shm_size: 8gb\n\n  # our baseline first\n  test-cpu-gloo-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-cpu-base\n\n  # permute MPI kinds\n  test-cpu-mpich-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        MPI_KIND: MPICH\n        HOROVOD_BUILD_FLAGS: HOROVOD_WITHOUT_GLOO=1\n  test-cpu-oneccl-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        MPI_KIND: ONECCL\n        HOROVOD_BUILD_FLAGS: HOROVOD_WITHOUT_GLOO=1\n  test-cpu-openmpi-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        MPI_KIND: OpenMPI\n        HOROVOD_BUILD_FLAGS: HOROVOD_WITHOUT_GLOO=1\n  test-cpu-openmpi-gloo-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        MPI_KIND: OpenMPI\n\n  # run_gloo_integration expects tf1 to have Gloo mpi kind to run 'Elastic Spark * Tests'\n  # Tensorflow 1.15.5 is only available for Python 3.7\n  # Python 3.7 is only available on Ubuntu 18.04\n  # torch==1.8.1 is the latest we can test in this setup\n  # there is no mxnet-1.6.0.post0 and mxnet-1.6.0 does not work with horovod\n  # https://github.com/apache/incubator-mxnet/issues/16193\n  # so we test with mxnet 1.5.1\n  test-cpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        # On Ubuntu 18.04 our setup.py will pull in a recent CMake and use that only to build Horovod\n        UBUNTU_VERSION: 18.04\n        PYTHON_VERSION: 3.7\n        # there is no tensorflow-cpu>1.15.0, so we use tensorflow==1.15.5\n        TENSORFLOW_PACKAGE: tensorflow==1.15.5\n        KERAS_PACKAGE: keras==2.2.4\n        PYTORCH_PACKAGE: torch==1.8.1+cpu\n        TORCHVISION_PACKAGE: torchvision==0.9.1+cpu\n        MXNET_PACKAGE: mxnet==1.5.1.post0\n  test-cpu-gloo-py3_8-tf2_10_1-keras2_10_0-torch1_12_1-mxnet1_7_0_p2-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        TENSORFLOW_PACKAGE: tensorflow-cpu==2.10.1\n        KERAS_PACKAGE: keras==2.10.0\n        PYTORCH_PACKAGE: torch==1.12.1+cpu\n        TORCHVISION_PACKAGE: torchvision==0.13.1+cpu\n        MXNET_PACKAGE: mxnet==1.7.0.post2\n  test-cpu-gloo-py3_8-tf2_11_1-keras2_11_0-torch1_13_1-mxnet1_8_0_p0-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        TENSORFLOW_PACKAGE: tensorflow-cpu==2.11.1\n        KERAS_PACKAGE: keras==2.11.0\n        PYTORCH_PACKAGE: torch==1.13.1+cpu\n        TORCHVISION_PACKAGE: torchvision==0.14.1+cpu\n        MXNET_PACKAGE: mxnet==1.8.0.post0\n  # then our baseline again, omitted ...\n  test-cpu-openmpi-gloo-py3_8-tfhead-keras_none-torchhead-mxnethead-pyspark3_4_0:\n    extends: test-cpu-base\n    build:\n      args:\n        MPI_KIND: OpenMPI\n        TENSORFLOW_PACKAGE: tf-nightly\n        KERAS_PACKAGE: None\n        PYTORCH_PACKAGE: torch-nightly\n        TORCHVISION_PACKAGE: torchvision\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        MXNET_PACKAGE: mxnet-nightly\n  # these are the lowest framework versions that Horovod compiles with, but they are not tested\n  test-cpu-openmpi-gloo-py3_7-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin:\n    extends: test-cpu-base\n    build:\n      args:\n        UBUNTU_VERSION: 18.04\n        PYTHON_VERSION: 3.7\n        MPI_KIND: OpenMPI\n        TENSORFLOW_PACKAGE: tensorflow-cpu==1.15.0\n        KERAS_PACKAGE: keras==2.2.4\n        PYTORCH_PACKAGE: torch==1.5.0+cpu\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==0.7.3\n        TORCHVISION_PACKAGE: torchvision==0.6.0+cpu\n        MXNET_PACKAGE: mxnet==1.4.1\n        PYSPARK_PACKAGE: pyspark==2.4.0\n        SPARK_PACKAGE: spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n\n  # we deviate from baseline here because PySpark 2.4 requires Python 3.7 and\n  # Tensorflow 2.11.0 is the last version that supports that Python\n  # Torch 1.13.1 is the last version that supports that Python\n  test-cpu-gloo-py3_7-tf2_11_0-keras2_11_0-torch1_13_1-mxnet1_9_1-pyspark2_4_8:\n    extends: test-cpu-base\n    build:\n      args:\n        # PySpark 2.4.8 is only available for Python 3.7\n        # Python 3.7 is only available on Ubuntu 18.04\n        # Tensorflow 2.11.0 is the last version supporting that Python\n        # Torch 1.13.1 is the last version supporting that Python\n        UBUNTU_VERSION: 18.04\n        PYTHON_VERSION: 3.7\n        TENSORFLOW_PACKAGE: tensorflow-cpu==2.11.0\n        KERAS_PACKAGE: keras==2.11.0\n        PYTORCH_PACKAGE: torch==1.13.1+cpu\n        TORCHVISION_PACKAGE: torchvision==0.14.1+cpu\n        PYSPARK_PACKAGE: pyspark==2.4.8\n        SPARK_PACKAGE: spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n  test-cpu-gloo-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_3_2:\n    extends: test-cpu-base\n    build:\n      args:\n        PYTHON_VERSION: 3.8\n        PYSPARK_PACKAGE: pyspark==3.3.2\n        SPARK_PACKAGE: spark-3.3.2/spark-3.3.2-bin-hadoop2.tgz\n  # then our baseline again, omitted ...\n\n  test-gpu-base:\n    build:\n      context: .\n      dockerfile: Dockerfile.test.gpu\n      args:\n        GPP_VERSION: 7\n        MPI_KIND: None\n        PYTHON_VERSION: 3.8\n        PYSPARK_PACKAGE: pyspark==3.4.0\n        SPARK_PACKAGE: spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n        HOROVOD_BUILD_FLAGS: HOROVOD_GPU_OPERATIONS=NCCL\n        HOROVOD_MIXED_INSTALL: 0\n    runtime: nvidia\n    # We plumb CUDA_VISIBLE_DEVICES instead of NVIDIA_VISIBLE_DEVICES because\n    # the latter does not work in privileged mode that we use in the containers.\n    environment:\n      - CUDA_VISIBLE_DEVICES\n    privileged: true\n    shm_size: 8gb\n\n  # available versions for CUDNN_VERSION and NCCL_VERSION_OVERRIDE can be found at\n  #   https://developer.download.nvidia.com/compute/cuda/repos/{OS}/x86_64/\n\n  # Mainline tensorflow-gpu==1.15.5 is compiled against and linked to CUDA 10.0, but appropriate containers aren't\n  # available anymore. Hence, we use the updated Python 3.8 wheel provided by Nvidia, see\n  # https://github.com/NVIDIA/tensorflow. For this reason versions of torch and mxnet also deviate from the CPU path.\n  test-gpu-gloo-py3_8-tf1_15_5-keras2_2_4-torch1_12_1-mxnet1_8_0_p0-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.6.2-devel-ubuntu20.04\n        CUDNN_VERSION: 8.4.1.50-1+cuda11.6\n        NCCL_VERSION_OVERRIDE: 2.11.4-1+cuda11.6\n        PYTHON_VERSION: 3.8\n        TENSORFLOW_PACKAGE: nvidia-tensorflow==1.15.5+nv22.4\n        KERAS_PACKAGE: keras==2.2.4\n        PYTORCH_PACKAGE: torch==1.12.1+cu116\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.13.1+cu116\n        MXNET_PACKAGE: mxnet-cu112==1.8.0.post0\n  # The container isn't provided for CUDA 10 anymore. The lowest version of mxnet available for cu112 is 1.8.0.post0.\n  test-gpu-gloo-py3_8-tf2_10_1-keras2_10_0-torch1_12_1-mxnet1_8_0_p0-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.6.2-devel-ubuntu20.04\n        CUDNN_VERSION: 8.4.1.50-1+cuda11.6\n        NCCL_VERSION_OVERRIDE: 2.11.4-1+cuda11.6\n        TENSORFLOW_PACKAGE: tensorflow-gpu==2.10.1\n        KERAS_PACKAGE: keras==2.10.0\n        PYTORCH_PACKAGE: torch==1.12.1+cu116\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.13.1+cu116\n        MXNET_PACKAGE: mxnet-cu112==1.8.0.post0\n  test-gpu-gloo-py3_8-tf2_11_1-keras2_11_0-torch1_13_1-mxnet1_8_0_p0-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.6.2-devel-ubuntu20.04\n        CUDNN_VERSION: 8.4.1.50-1+cuda11.6\n        NCCL_VERSION_OVERRIDE: 2.11.4-1+cuda11.6\n        # tensorflow package supports GPU from 2.11.1 and 2.12.0 on\n        TENSORFLOW_PACKAGE: tensorflow==2.11.1\n        KERAS_PACKAGE: keras==2.11.0\n        PYTORCH_PACKAGE: torch==1.13.1+cu116\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.14.1+cu116\n        MXNET_PACKAGE: mxnet-cu112==1.8.0.post0\n  test-gpu-openmpi-gloo-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.8.0-devel-ubuntu20.04\n        CUDNN_VERSION: 8.6.0.163-1+cuda11.8\n        NCCL_VERSION_OVERRIDE: 2.16.5-1+cuda11.8\n        MPI_KIND: OpenMPI\n        # tensorflow package supports GPU from 2.11.1 and 2.12.0 on\n        TENSORFLOW_PACKAGE: tensorflow==2.12.0\n        KERAS_PACKAGE: keras==2.12.0\n        PYTORCH_PACKAGE: torch==2.0.0+cu118\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.15.1+cu118\n        MXNET_PACKAGE: mxnet-cu112==1.9.1\n  test-gpu-openmpi-gloo-py3_8-tfhead-keras_none-torchhead-mxnethead-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.8.0-devel-ubuntu20.04\n        CUDNN_VERSION: 8.6.0.163-1+cuda11.8\n        NCCL_VERSION_OVERRIDE: 2.16.5-1+cuda11.8\n        MPI_KIND: OpenMPI\n        TENSORFLOW_PACKAGE: tf-nightly\n        KERAS_PACKAGE: None\n        PYTORCH_PACKAGE: torch-nightly-cu118\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision\n        MXNET_PACKAGE: mxnet-nightly-cu112\n  # These are the lowest framework versions that Horovod compiles with on the CUDA 11.x container, but they are not tested.\n  # Versions of python, mxnet, and pyspark differ from the CPU build with minimum versions.\n  test-gpu-openmpi-gloo-py3_8-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.6.2-devel-ubuntu20.04\n        CUDNN_VERSION: 8.4.1.50-1+cuda11.6\n        NCCL_VERSION_OVERRIDE: 2.11.4-1+cuda11.6\n        MPI_KIND: OpenMPI\n        PYTHON_VERSION: 3.8\n        TENSORFLOW_PACKAGE: nvidia-tensorflow==1.15.5+nv22.4\n        KERAS_PACKAGE: keras==2.2.4\n        # torch ships its own CUDA libraries\n        PYTORCH_PACKAGE: torch==1.5.0+cu101\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==0.7.3\n        TORCHVISION_PACKAGE: torchvision==0.6.0+cu101\n        MXNET_PACKAGE: mxnet-cu112==1.8.0.post0\n        # On Python 3.8 Spark 3.0.0 is the lowest supported version\n        PYSPARK_PACKAGE: pyspark==3.0.0\n        SPARK_PACKAGE: spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n\n  test-mixed-openmpi-gloo-py3_8-tf2_12_0-keras2_12_0-torch2_0_0-mxnet1_9_1-pyspark3_4_0:\n    extends: test-gpu-base\n    build:\n      args:\n        CUDA_DOCKER_VERSION: 11.8.0-devel-ubuntu20.04\n        CUDNN_VERSION: 8.6.0.163-1+cuda11.8\n        NCCL_VERSION_OVERRIDE: 2.16.5-1+cuda11.8\n        MPI_KIND: OpenMPI\n        # tensorflow package supports GPU from 2.11.1 and 2.12.0 on\n        TENSORFLOW_PACKAGE: tensorflow==2.12.0\n        KERAS_PACKAGE: keras==2.12.0\n        PYTORCH_PACKAGE: torch==2.0.0+cu118\n        PYTORCH_LIGHTNING_PACKAGE: pytorch-lightning==1.5.9\n        TORCHVISION_PACKAGE: torchvision==0.15.1+cu118\n        MXNET_PACKAGE: mxnet-cu112==1.9.1\n        HOROVOD_BUILD_FLAGS: \"\"\n        HOROVOD_MIXED_INSTALL: 1\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "horovod.exp",
          "type": "blob",
          "size": 0.111328125,
          "content": "*horovod*\n# PyTorch binding\n*PyInit*\n*initmpi_lib_v2*\n# Legacy PyTorch binding\n*init_mpi_lib*\n*init_mpi_lib_impl*\n"
        },
        {
          "name": "horovod.lds",
          "type": "blob",
          "size": 0.169921875,
          "content": "{\n  global:\n    *horovod*;\n    # PyTorch binding\n    *PyInit*;\n    *initmpi_lib_v2*;\n    # Legacy PyTorch binding\n    *init_mpi_lib*;\n    *init_mpi_lib_impl*;\n  local: *;\n};\n"
        },
        {
          "name": "horovod",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0380859375,
          "content": "[tool:pytest]\nnorecursedirs=test/utils\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 10.6943359375,
          "content": "# Copyright 2019 Uber Technologies, Inc. All Rights Reserved.\n# Modifications copyright Microsoft\n# Modifications copyright (C) 2020, NVIDIA CORPORATION. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\nimport atexit\nimport io\nimport os\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nimport textwrap\n\nfrom setuptools import setup, Extension, find_packages\nfrom setuptools.command.build_ext import build_ext\n\nfrom horovod import __version__\n\n_FRAMEWORK_METADATA_FILE = 'horovod/metadata.json'\n\nclass CMakeExtension(Extension):\n    def __init__(self, name, cmake_lists_dir='.', sources=None, **kwa):\n        if sources is None:\n            sources = []\n        Extension.__init__(self, name, sources=sources, **kwa)\n        self.cmake_lists_dir = os.path.abspath(cmake_lists_dir)\n\n\ntensorflow_mpi_lib = CMakeExtension('horovod.tensorflow.mpi_lib',\n                                    cmake_lists_dir='.', sources=[])\ntorch_mpi_lib_v2 = CMakeExtension('horovod.torch.mpi_lib_v2',\n                                  cmake_lists_dir='.', sources=[])\nmxnet_mpi_lib = CMakeExtension('horovod.mxnet.mpi_lib',\n                               cmake_lists_dir='.', sources=[])\n\ndef is_build_action():\n    if len(sys.argv) <= 1:\n        return False\n\n    if sys.argv[1].startswith('build'):\n        return True\n\n    if sys.argv[1].startswith('bdist'):\n        return True\n\n    if sys.argv[1].startswith('install'):\n        return True\n\n    if sys.argv[1].startswith('develop'):\n        return True\n\ndef get_cmake_bin():\n    from packaging import version\n\n    if 'HOROVOD_CMAKE' in os.environ:\n        return os.environ['HOROVOD_CMAKE']\n\n    cmake_bin = 'cmake'\n    try:\n        out = subprocess.check_output([cmake_bin, '--version'])\n    except OSError:\n        cmake_installed_version = version.parse(\"0.0\")\n    else:\n        cmake_installed_version = version.parse(re.search(r'version\\s*([\\d.]+)', out.decode()).group(1))\n\n    if cmake_installed_version < version.parse(\"3.13.0\"):\n        print(\"Could not find a recent CMake to build Horovod. \"\n              \"Attempting to install CMake 3.13 to a temporary location via pip.\", flush=True)\n        cmake_temp_dir = tempfile.TemporaryDirectory(prefix=\"horovod-cmake-tmp\")\n        atexit.register(cmake_temp_dir.cleanup)\n        try:\n            _ = subprocess.check_output([\"pip\", \"install\", \"--target\", cmake_temp_dir.name, \"cmake~=3.13.0\"])\n        except Exception:\n            raise RuntimeError(\"Failed to install temporary CMake. \"\n                               \"Please update your CMake to 3.13+ or set HOROVOD_CMAKE appropriately.\")\n        cmake_bin = os.path.join(cmake_temp_dir.name, \"bin\", \"run_cmake\")\n        with io.open(cmake_bin, \"w\") as f_run_cmake:\n            f_run_cmake.write(\n                f\"#!/bin/sh\\nPYTHONPATH={cmake_temp_dir.name} {os.path.join(cmake_temp_dir.name, 'bin', 'cmake')} \\\"$@\\\"\")\n        os.chmod(cmake_bin, 0o755)\n\n    return cmake_bin\n\n\nclass custom_build_ext(build_ext):\n    def build_extensions(self):\n        if os.getenv('HOROVOD_SKIP_COMPILE') == '1':\n            # Skip building extensions using CMake\n            print(\"Horovod is being installed without native libraries\")\n            return\n\n        cmake_bin = get_cmake_bin()\n\n        config = 'Debug' if self.debug or os.environ.get('HOROVOD_DEBUG') == \"1\" else 'RelWithDebInfo'\n\n        ext_name = self.extensions[0].name\n        build_dir = self.get_ext_fullpath(ext_name).replace(self.get_ext_filename(ext_name), '')\n        build_dir = os.path.abspath(build_dir)\n\n        cmake_args = ['-DCMAKE_BUILD_TYPE=' + config,\n                      '-DCMAKE_LIBRARY_OUTPUT_DIRECTORY_{}={}'.format(config.upper(), build_dir),\n                      '-DPYTHON_EXECUTABLE:FILEPATH=' + sys.executable]\n\n        make_args = ['-j8'] if not os.environ.get('MAKEFLAGS') else []\n        if self.verbose:\n            make_args.append('VERBOSE=1')\n\n        cmake_build_args = ['--config', config]\n        if make_args:\n            # -- specifies that these args are going to the native build tool: make\n            cmake_build_args += ['--'] + make_args\n\n        cmake_build_dir = os.path.join(self.build_temp, config)\n        if not os.path.exists(cmake_build_dir):\n            os.makedirs(cmake_build_dir)\n\n        config_and_build_commands = [\n            [cmake_bin, self.extensions[0].cmake_lists_dir] + cmake_args,\n            [cmake_bin, '--build', '.'] + cmake_build_args\n        ]\n\n        if self.verbose:\n            print(f\"Running CMake in {cmake_build_dir}:\")\n            for command in config_and_build_commands:\n                print(\" \".join(command))\n            sys.stdout.flush()\n\n        # Config and build the extension\n        try:\n            for command in config_and_build_commands:\n                subprocess.check_call(command, cwd=cmake_build_dir)\n        except OSError as e:\n            raise RuntimeError('CMake failed: {}'.format(str(e)))\n\n        if sys.argv[1].startswith('develop'):\n            # Copy over metadata.json file from build directory\n            shutil.copyfile(os.path.join(build_dir, _FRAMEWORK_METADATA_FILE),\n                            os.path.join(self.extensions[0].cmake_lists_dir, _FRAMEWORK_METADATA_FILE))\n            # Remove unfound frameworks, otherwise develop mode will fail the install\n            self.extensions = [x for x in self.extensions if os.path.exists(self.get_ext_fullpath(x.name))]\n\n\n# python packages required to use horovod in general\nrequire_list = ['cloudpickle', 'psutil', 'pyyaml', 'dataclasses;python_version<\"3.7\"', 'packaging']\n\n# framework dependencies\ntensorflow_require_list = ['tensorflow']\n# for protobuf constraint see ray_require_list\ntensorflow_cpu_require_list = ['tensorflow-cpu']\ntensorflow_gpu_require_list = ['tensorflow-gpu']\nkeras_require_list = ['keras>=2.0.8,!=2.0.9,!=2.1.0,!=2.1.1']\n# pytorch-lightning 1.3.8 is a stable version to work with horovod\npytorch_require_list = ['torch']\nmxnet_require_list = ['mxnet>=1.4.1']\npyspark_require_list = ['pyspark>=2.3.2;python_version<\"3.8\"',\n                        'pyspark>=3.0.0;python_version>=\"3.8\"']\nspark_require_list = ['numpy', 'petastorm>=0.12.0', 'pyarrow>=0.15.0,<11.0', 'fsspec>=2021.07.0']\n# https://github.com/ray-project/ray/pull/17465\n# google-api-core>=2.9.0 depends on protobuf<5.0.0dev,>=3.20.1, which conflicts with\n#   tensorflow protobuf~=3.20 and pytorch-lightning protobuf<3.20,>=3.9.2\nray_require_list = ['ray', 'aioredis<2', 'google-api-core<2.9.0']\npytorch_spark_require_list = pytorch_require_list + \\\n                             spark_require_list + \\\n                             pyspark_require_list + \\\n                             ['pytorch_lightning>=1.3.8,<1.5.10']\n\n# all frameworks' dependencies\nall_frameworks_require_list = tensorflow_require_list + \\\n                              keras_require_list + \\\n                              pytorch_require_list + \\\n                              mxnet_require_list + \\\n                              spark_require_list + \\\n                              pyspark_require_list\n\n# python packages required / recommended to develop horovod\n# these are the earliest versions to work with Python 3.8\n# keep in sync with Dockerfile.test.cpu\n# NOTE: do not use versions with +cpu or +gpu here as users would need to add --find-links to pip\ndev_require_list = ['tensorflow-cpu==2.2.0',\n                    'keras==2.3.1',\n                    'torch==1.4.0',\n                    'torchvision==0.5.0',\n                    'pytorch_lightning>=1.3.8,<1.5.10',\n                    'mxnet==1.5.0',\n                    'pyspark==3.0.1'] + spark_require_list\n# torchvision 0.5.0 depends on torch==1.4.0\n\n# python packages required only to run tests\ntest_require_list = ['mock', 'pytest<8', 'pytest-forked', 'pytest-subtests', 'parameterized']\n\n# Skip cffi if pytorch extension explicitly disabled\nif not os.environ.get('HOROVOD_WITHOUT_PYTORCH'):\n    require_list.append('cffi>=1.4.0')\n\n\ndef get_package_version():\n    return __version__ + \"+\" + os.environ['HOROVOD_LOCAL_VERSION'] if 'HOROVOD_LOCAL_VERSION' in os.environ else __version__\n\n\nsetup(name='horovod',\n      version=get_package_version(),\n      packages=find_packages(),\n      description='Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.',\n      author='The Horovod Authors',\n      license='Apache 2.0',\n      long_description=textwrap.dedent('''\\\n          Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.\n          The goal of Horovod is to make distributed Deep Learning fast and easy to use.'''),\n      url='https://github.com/horovod/horovod',\n      keywords=['deep learning', 'tensorflow', 'keras', 'pytorch', 'mxnet', 'spark', 'AI'],\n      classifiers=[\n          'License :: OSI Approved :: Apache Software License',\n          'Development Status :: 4 - Beta',\n          'Intended Audience :: Developers',\n          'Topic :: Scientific/Engineering :: Artificial Intelligence',\n      ],\n      ext_modules=[tensorflow_mpi_lib, torch_mpi_lib_v2, mxnet_mpi_lib],\n      cmdclass={'build_ext': custom_build_ext},\n      # cffi is required for PyTorch\n      # If cffi is specified in setup_requires, it will need libffi to be installed on the machine,\n      # which is undesirable.  Luckily, `install` action will install cffi before executing build,\n      # so it's only necessary for `build*` or `bdist*` actions.\n      setup_requires=require_list if is_build_action() else [],\n      install_requires=require_list,\n      tests_require=test_require_list,\n      extras_require={\n          'all-frameworks': all_frameworks_require_list,\n          'tensorflow': tensorflow_require_list,\n          'tensorflow-cpu': tensorflow_cpu_require_list,\n          'tensorflow-gpu': tensorflow_gpu_require_list,\n          'keras': keras_require_list,\n          'pytorch': pytorch_require_list,\n          'mxnet': mxnet_require_list,\n          'spark': spark_require_list + pyspark_require_list,\n          'pytorch-spark': pytorch_spark_require_list,\n          'ray': ray_require_list,\n          'dev': dev_require_list,\n          'test': test_require_list,\n      },\n      python_requires='>=3.6',\n      zip_safe=False,\n      entry_points={\n          'console_scripts': [\n              'horovodrun = horovod.runner.launch:run_commandline'\n          ]\n      })\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}