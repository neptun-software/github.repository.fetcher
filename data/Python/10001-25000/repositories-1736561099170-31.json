{
  "metadata": {
    "timestamp": 1736561099170,
    "page": 31,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pytorch/examples",
      "stars": 22599,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3154296875,
          "content": "dcgan/data\ndata\n*.pyc\nOpenNMT/data\ncpp/mnist/build\ncpp/dcgan/build\ndcgan/*.png\ndcgan/*.pth\nsnli/.data\nsnli/.vector_cache\nsnli/results\nword_language_model/model.pt\nfast_neural_style/saved_models\nfast_neural_style/saved_models.zip\ngcn/cora/\ngat/cora/\ndocs/build\ndocs/venv\n\n# vi backups\n*~\n\n# development\n.vscode\n**/.DS_Store\n"
        },
        {
          "name": "CODEOWNERS",
          "type": "blob",
          "size": 0.6328125,
          "content": "# This is a comment.\n# Each line is a file pattern followed by one or more owners.\n\n# Github Actions, tests and CI\n./github/ @msaroufim\nrun_python_examples.sh @msaroufim\n\n# Distributed examples \n# Can also add the distributed oncall\n./distributed/ @mrshenli @pritamdamania87 @rohan-varma @H-Huang\n./mnist_hogwild/ @mrshenli @pritamdamania87 @rohan-varma @H-Huang\n\n# FX examples \n./fx/ @jamesr66a @Chillee\n\n# Domain Examples \n./reinforcement_learning/ @msaroufim \n./word_language_model/ @msaroufim\n\n# Need an owner \n./regression/\n./mnist/\n./imagenet/\n./super_resolution/ \n./time_sequence_prediction/\n./vae/\n\n# Legacy examples\n./cpp/\n./legacy/snli/ \n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2744140625,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing other's private information, such as physical or electronic\n  address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.3857421875,
          "content": "# Contributing to examples\n\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Pull Requests\n\nWe actively welcome your pull requests.\n\nIf you're new, we encourage you to take a look at issues tagged with [good first issue](https://github.com/pytorch/examples/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n\n### For new examples\n\n0. Create a GitHub issue proposing a new example and make sure it's substantially different from an existing one.\n1. Fork the repo and create your branch from `main`.\n2. If you've added code that should be tested, add tests to `run_python_examples.sh`.\n3. Create a `README.md`.\n4. Add a card with a brief description of your example and link to the repo to\n   the `docs/source/index.rst` file and build the docs by running:\n\n   ```\n   cd docs\n   virtualenv venv\n   source venv/bin/activate\n   pip install -r requirements.txt\n   make html\n   ```\n\n   When done working with `virtualenv`, run `deactivate`.\n\n5. Verify that there are no issues in your doc build. You can check the preview locally\n   by installing [sphinx-serve](https://pypi.org/project/sphinx-serve/)\n   then running `sphinx-serve -b build`.\n6. Ensure your test passes locally.\n7. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n8. Address any feedback in code review promptly.\n\n## For bug fixes\n\n1. Fork the repo and create your branch from `main`.\n2. Make sure you have a GPU-enabled machine, either locally or in the cloud. `g4dn.4xlarge` is a good starting point on AWS.\n3. Make your code change.\n4. First, install all dependencies with `./run_python_examples.sh \"install_deps\"`.\n5. Then, make sure that `./run_python_examples.sh` passes locally by running the script end to end.\n6. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n7. Address any feedback in code review promptly.\n\n## Contributor License Agreement (\"CLA\")\n\nTo accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\n\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\n## License\n\nBy contributing to examples, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.484375,
          "content": "BSD 3-Clause License\n\nCopyright (c) 2017, Pytorch contributors\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.546875,
          "content": "# PyTorch Examples\n\n![Run Examples](https://github.com/pytorch/examples/workflows/Run%20Examples/badge.svg)\n\nhttps://pytorch.org/examples/\n\n`pytorch/examples` is a repository showcasing examples of using [PyTorch](https://github.com/pytorch/pytorch). The goal is to have curated, short, few/no dependencies _high quality_ examples that are substantially different from each other that can be emulated in your existing work.\n\n- For tutorials: https://github.com/pytorch/tutorials\n- For changes to pytorch.org: https://github.com/pytorch/pytorch.github.io\n- For a general model hub: https://pytorch.org/hub/ or https://huggingface.co/models\n- For recipes on how to run PyTorch in production: https://github.com/facebookresearch/recipes\n- For general Q&A and support: https://discuss.pytorch.org/\n\n## Available models\n\n- [Image classification (MNIST) using Convnets](./mnist/README.md)\n- [Word-level Language Modeling using RNN and Transformer](./word_language_model/README.md)\n- [Training Imagenet Classifiers with Popular Networks](./imagenet/README.md)\n- [Generative Adversarial Networks (DCGAN)](./dcgan/README.md)\n- [Variational Auto-Encoders](./vae/README.md)\n- [Superresolution using an efficient sub-pixel convolutional neural network](./super_resolution/README.md)\n- [Hogwild training of shared ConvNets across multiple processes on MNIST](mnist_hogwild)\n- [Training a CartPole to balance in OpenAI Gym with actor-critic](./reinforcement_learning/README.md)\n- [Natural Language Inference (SNLI) with GloVe vectors, LSTMs, and torchtext](snli)\n- [Time sequence prediction - use an LSTM to learn Sine waves](./time_sequence_prediction/README.md)\n- [Implement the Neural Style Transfer algorithm on images](./fast_neural_style/README.md)\n- [Reinforcement Learning with Actor Critic and REINFORCE algorithms on OpenAI gym](./reinforcement_learning/README.md)\n- [PyTorch Module Transformations using fx](./fx/README.md)\n- Distributed PyTorch examples with [Distributed Data Parallel](./distributed/ddp/README.md) and [RPC](./distributed/rpc)\n- [Several examples illustrating the C++ Frontend](cpp)\n- [Image Classification Using Forward-Forward](./mnist_forward_forward/README.md)\n- [Language Translation using Transformers](./language_translation/README.md)\n\n\n\nAdditionally, a list of good examples hosted in their own repositories:\n\n- [Neural Machine Translation using sequence-to-sequence RNN with attention (OpenNMT)](https://github.com/OpenNMT/OpenNMT-py)\n\n## Contributing\n\nIf you'd like to contribute your own example or fix a bug please make sure to take a look at [CONTRIBUTING.md](CONTRIBUTING.md).\n"
        },
        {
          "name": "cpp",
          "type": "tree",
          "content": null
        },
        {
          "name": "dcgan",
          "type": "tree",
          "content": null
        },
        {
          "name": "distributed",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "fast_neural_style",
          "type": "tree",
          "content": null
        },
        {
          "name": "fx",
          "type": "tree",
          "content": null
        },
        {
          "name": "gat",
          "type": "tree",
          "content": null
        },
        {
          "name": "gcn",
          "type": "tree",
          "content": null
        },
        {
          "name": "imagenet",
          "type": "tree",
          "content": null
        },
        {
          "name": "language_translation",
          "type": "tree",
          "content": null
        },
        {
          "name": "legacy",
          "type": "tree",
          "content": null
        },
        {
          "name": "mnist",
          "type": "tree",
          "content": null
        },
        {
          "name": "mnist_forward_forward",
          "type": "tree",
          "content": null
        },
        {
          "name": "mnist_hogwild",
          "type": "tree",
          "content": null
        },
        {
          "name": "mnist_rnn",
          "type": "tree",
          "content": null
        },
        {
          "name": "regression",
          "type": "tree",
          "content": null
        },
        {
          "name": "reinforcement_learning",
          "type": "tree",
          "content": null
        },
        {
          "name": "run_cpp_examples.sh",
          "type": "blob",
          "size": 4.01953125,
          "content": "#!/usr/bin/env bash\n# This script runs through the code in each of the cpp examples.\n# The purpose is just as an integration test, not to actually train models in any meaningful way.\n\n# Optionally specify a comma separated list of examples to run.\n# can be run as:\n# ./run_cpp_examples.sh \"get_libtorch,run_all,clean\"\n# To get libtorch, run all examples, and remove temporary/changed data files.\n\nBASE_DIR=`pwd`\"/\"`dirname $0`\necho \"BASE_DIR: $BASE_DIR\"\nEXAMPLES=`echo $1 | sed -e 's/ //g'`\nHOME_DIR=$HOME\nERRORS=\"\"\n\nfunction error() {\n  ERR=$1\n  ERRORS=\"$ERRORS\\n$ERR\"\n  echo $ERR\n}\n\nfunction get_libtorch() {\n  echo \"Getting libtorch\"\n  cd $HOME_DIR\n  if [ ! -d \"libtorch\" ]; then\n    wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-cxx11-abi-shared-with-deps-latest.zip\n    unzip libtorch-cxx11-abi-shared-with-deps-latest.zip\n  fi\n\n  if [ $? -eq 0 ]; then\n    echo \"Successfully downloaded and extracted libtorch\"\n    LIBTORCH_PATH=\"$HOME_DIR/libtorch\"   # Store the LibTorch path in a variable.\n    echo \"LibTorch path: $LIBTORCH_PATH\" # Print the LibTorch path\n  else\n    error \"Failed to download or extract LibTorch\"\n  fi\n}\n\nfunction start() {\n  EXAMPLE=${FUNCNAME[1]}\n  cd $BASE_DIR/cpp/$EXAMPLE\n  echo \"Running example: $EXAMPLE\"\n}\n\nfunction check_run_success() {\n  if [ $? -eq 0 ]; then\n    echo \"Successfully ran $1\"\n  else\n    echo \"Failed to run $1\"\n    error \"Failed to run $1\"\n    exit 1\n  fi\n}\n\nfunction autograd() {\n  start\n  mkdir build\n  cd build\n  cmake -DCMAKE_PREFIX_PATH=$LIBTORCH_PATH ..\n  make\n  if [ $? -eq 0 ]; then\n    echo \"Successfully built $EXAMPLE\"\n    ./$EXAMPLE # Run the executable\n    check_run_success $EXAMPLE\n  else\n    error \"Failed to build $EXAMPLE\"\n    exit 1\n  fi\n}\n\nfunction custom-dataset() {\n  start\n  # Download the dataset and unzip it\n  if [ ! -d \"$BASE_DIR/cpp/$EXAMPLE/dataset\" ]; then\n    wget https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip\n    unzip caltech-101.zip\n    cd caltech-101\n    tar -xzf 101_ObjectCategories.tar.gz\n    mv 101_ObjectCategories $BASE_DIR/cpp/$EXAMPLE/dataset\n  fi\n  # build the executable and run it\n  cd $BASE_DIR/cpp/$EXAMPLE\n  mkdir build\n  cd build\n  cmake -DCMAKE_PREFIX_PATH=$LIBTORCH_PATH ..\n  make\n  if [ $? -eq 0 ]; then\n    echo \"Successfully built $EXAMPLE\"\n    cd $BASE_DIR/cpp/$EXAMPLE\n    ./build/$EXAMPLE # Run the executable\n    check_run_success $EXAMPLE\n  else\n    error \"Failed to build $EXAMPLE\"\n    exit 1\n  fi\n}\nfunction dcgan() {\n  start\n  mkdir build\n  cd build\n  cmake -DCMAKE_PREFIX_PATH=$LIBTORCH_PATH ..\n  make\n  if [ $? -eq 0 ]; then\n    echo \"Successfully built $EXAMPLE\"\n    ./$EXAMPLE --epochs 5 # Run the executable with kNumberOfEpochs = 5\n    check_run_success $EXAMPLE\n  else\n    error \"Failed to build $EXAMPLE\"\n    exit 1\n  fi\n}\n\nfunction mnist() {\n  start\n  mkdir build\n  cd build\n  cmake -DCMAKE_PREFIX_PATH=$LIBTORCH_PATH ..\n  make\n  if [ $? -eq 0 ]; then\n    echo \"Successfully built $EXAMPLE\"\n    ./$EXAMPLE # Run the executable\n    check_run_success $EXAMPLE\n  else\n    error \"Failed to build $EXAMPLE\"\n    exit 1\n  fi\n}\n\nfunction regression() {\n  start\n  mkdir build\n  cd build\n  cmake -DCMAKE_PREFIX_PATH=$LIBTORCH_PATH ..\n  make\n  if [ $? -eq 0 ]; then\n    echo \"Successfully built $EXAMPLE\"\n    ./$EXAMPLE # Run the executable\n    check_run_success $EXAMPLE\n  else\n    error \"Failed to build $EXAMPLE\"\n    exit 1\n  fi\n}\n\nfunction clean() {\n  cd $BASE_DIR\n  echo \"Running clean to remove cruft\"\n  # Remove the build directories\n  find . -type d -name 'build' -exec rm -rf {} +\n  # Remove the libtorch directory\n  rm -rf $HOME_DIR/libtorch\n  rm -f $HOME_DIR/libtorch-shared-with-deps-latest.zip\n  echo \"Clean completed\"\n}\n\nfunction run_all() {\n  autograd\n  custom-dataset\n  regression\n  dcgan\n  mnist\n  \n}\n\n# by default, run all examples\nif [ \"\" == \"$EXAMPLES\" ]; then\n  run_all\nelse\n  for i in $(echo $EXAMPLES | sed \"s/,/ /g\")\n  do\n    echo \"Starting $i\"\n    $i\n    echo \"Finished $i, status $?\"\n  done\nfi\n\nif [ \"\" == \"$ERRORS\" ]; then\n  echo \"Completed successfully with status $?\"\nelse\n  echo \"Some examples failed:\"\n  printf \"$ERRORS\"\n  exit 1\nfi\n"
        },
        {
          "name": "run_distributed_examples.sh",
          "type": "blob",
          "size": 1.84765625,
          "content": "#!/usr/bin/env bash\n#\n# This script runs through the code in each of the python examples.\n# The purpose is just as an integration test, not to actually train models in any meaningful way.\n# For that reason, most of these set epochs = 1 and --dry-run.\n#\n# Optionally specify a comma separated list of examples to run.\n# can be run as:\n# ./run_python_examples.sh \"install_deps,run_all,clean\"\n# to pip install dependencies (other than pytorch), run all examples, and remove temporary/changed data files.\n# Expects pytorch, torchvision to be installed.\n\nBASE_DIR=\"$(pwd)/$(dirname $0)\"\nsource $BASE_DIR/utils.sh\n\nUSE_CUDA=$(python -c \"import torch; print(torch.cuda.is_available())\")\ncase $USE_CUDA in\n  \"True\")\n    echo \"using cuda\"\n    CUDA=1\n    CUDA_FLAG=\"--cuda\"\n    ;;\n  \"False\")\n    echo \"not using cuda\"\n    CUDA=0\n    CUDA_FLAG=\"\"\n    ;;\n  \"\")\n    exit 1;\n    ;;\nesac\n\nfunction distributed() {\n    start\n    bash tensor_parallelism/run_example.sh tensor_parallelism/tensor_parallel_example.py || error \"tensor parallel example failed\"\n    bash tensor_parallelism/run_example.sh tensor_parallelism/sequence_parallel_example.py || error \"sequence parallel example failed\"\n    bash tensor_parallelism/run_example.sh tensor_parallelism/fsdp_tp_example.py || error \"2D parallel example failed\"\n    python ddp/main.py || error \"ddp example failed\"\n}\n\nfunction clean() {\n  cd $BASE_DIR\n  echo \"running clean to remove cruft\"\n}\n\nfunction run_all() {\n  distributed\n}\n\n# by default, run all examples\nif [ \"\" == \"$EXAMPLES\" ]; then\n  run_all\nelse\n  for i in $(echo $EXAMPLES | sed \"s/,/ /g\")\n  do\n    echo \"Starting $i\"\n    $i\n    echo \"Finished $i, status $?\"\n  done\nfi\n\nif [ \"\" == \"$ERRORS\" ]; then\n  echo \"Completed successfully with status $?\"\nelse\n  echo \"Some distributed examples failed:\"\n  printf \"$ERRORS\\n\"\n  #Exit with error (0-255) in case of failure in one of the tests.\n  exit 1\n\nfi\n"
        },
        {
          "name": "run_python_examples.sh",
          "type": "blob",
          "size": 6.7861328125,
          "content": "#!/usr/bin/env bash\n#\n# This script runs through the code in each of the python examples.\n# The purpose is just as an integration test, not to actually train models in any meaningful way.\n# For that reason, most of these set epochs = 1 and --dry-run.\n#\n# Optionally specify a comma separated list of examples to run.\n# can be run as:\n# ./run_python_examples.sh \"install_deps,run_all,clean\"\n# to pip install dependencies (other than pytorch), run all examples, and remove temporary/changed data files.\n# Expects pytorch, torchvision to be installed.\n\nBASE_DIR=\"$(pwd)/$(dirname $0)\"\nsource $BASE_DIR/utils.sh\n\nUSE_CUDA=$(python -c \"import torchvision, torch; print(torch.cuda.is_available())\")\ncase $USE_CUDA in\n  \"True\")\n    echo \"using cuda\"\n    CUDA=1\n    CUDA_FLAG=\"--cuda\"\n    ;;\n  \"False\")\n    echo \"not using cuda\"\n    CUDA=0\n    CUDA_FLAG=\"\"\n    ;;\n  \"\")\n    exit 1;\n    ;;\nesac\n\nfunction dcgan() {\n  start\n  python main.py --dataset fake $CUDA_FLAG --mps --dry-run || error \"dcgan failed\"\n}\n\nfunction fast_neural_style() {\n  start\n  if [ ! -d \"saved_models\" ]; then\n    echo \"downloading saved models for fast neural style\"\n    python download_saved_models.py\n  fi\n  test -d \"saved_models\" || { error \"saved models not found\"; return; }\n\n  echo \"running fast neural style model\"\n  python neural_style/neural_style.py eval --content-image images/content-images/amber.jpg --model saved_models/candy.pth --output-image images/output-images/amber-candy.jpg --cuda $CUDA --mps || error \"neural_style.py failed\"\n}\n\nfunction imagenet() {\n  start\n  if [[ ! -d \"sample/val\" || ! -d \"sample/train\" ]]; then\n    mkdir -p sample/val/n\n    mkdir -p sample/train/n\n    curl -O \"https://upload.wikimedia.org/wikipedia/commons/5/5a/Socks-clinton.jpg\" || { error \"couldn't download sample image for imagenet\"; return; }\n    mv Socks-clinton.jpg sample/train/n\n    cp sample/train/n/* sample/val/n/\n  fi\n  python main.py --epochs 1 sample/ || error \"imagenet example failed\"\n}\n\nfunction language_translation() {\n  start\n  python -m spacy download en || error \"couldn't download en package from spacy\"\n  python -m spacy download de || error \"couldn't download de package from spacy\"\n  python main.py -e 1 --enc_layers 1 --dec_layers 1 --backend cpu --logging_dir output/ --dry_run || error \"language translation example failed\"\n}\n\nfunction mnist() {\n  start\n  python main.py --epochs 1 --dry-run || error \"mnist example failed\"\n}\nfunction mnist_forward_forward() {\n  start\n  python main.py --epochs 1 --no_mps --no_cuda || error \"mnist forward forward failed\"\n\n}\nfunction mnist_hogwild() {\n  start\n  python main.py --epochs 1 --dry-run $CUDA_FLAG || error \"mnist hogwild failed\"\n}\n\nfunction mnist_rnn() {\n  start\n  python main.py --epochs 1 --dry-run || error \"mnist rnn example failed\"\n}\n\nfunction regression() {\n  start\n  python main.py --epochs 1 $CUDA_FLAG || error \"regression failed\"\n}\n\nfunction siamese_network() {\n  start\n  python main.py --epochs 1 --dry-run || error \"siamese network example failed\"\n}\n\nfunction reinforcement_learning() {\n  start\n  python reinforce.py || error \"reinforcement learning reinforce failed\"\n  python actor_critic.py || error \"reinforcement learning actor_critic failed\"\n}\n\nfunction snli() {\n  start\n  echo \"installing 'en' model if not installed\"\n  python -m spacy download en || { error \"couldn't download 'en' model needed for snli\";  return; }\n  echo \"training...\"\n  python train.py --epochs 1 --dev_every 1 --no-bidirectional --dry-run || error \"couldn't train snli\"\n}\n\nfunction fx() {\n  start\n  # python custom_tracer.py || error \"fx custom tracer has failed\" UnboundLocalError: local variable 'tabulate' referenced before assignment\n  python invert.py || error \"fx invert has failed\"\n  python module_tracer.py || error \"fx module tracer has failed\"\n  python primitive_library.py || error \"fx primitive library has failed\"\n  python profiling_tracer.py || error \"fx profiling tracer has failed\"\n  python replace_op.py || error \"fx replace op has failed\"\n  python subgraph_rewriter_basic_use.py || error \"fx subgraph has failed\"\n  python wrap_output_dynamically.py || error \"vmap output dynamically has failed\"\n}\n\nfunction super_resolution() {\n  start\n  python main.py --upscale_factor 3 --batchSize 4 --testBatchSize 100 --nEpochs 1 --lr 0.001 --mps || error \"super resolution failed\"\n}\n\nfunction time_sequence_prediction() {\n  start\n  python generate_sine_wave.py || { error \"generate sine wave failed\";  return; }\n  python train.py --steps 2 || error \"time sequence prediction training failed\"\n}\n\nfunction vae() {\n  start\n  python main.py --epochs 1 || error \"vae failed\"\n}\n\nfunction vision_transformer() {\n  start\n  python main.py --epochs 1 --dry-run || error \"vision transformer example failed\"\n}\n\nfunction word_language_model() {\n  start\n  python main.py --epochs 1 --dry-run $CUDA_FLAG --mps || error \"word_language_model failed\"\n}\n\nfunction gcn() {\n  start\n  python main.py --epochs 1 --dry-run || error \"graph convolutional network failed\"\n}\n\nfunction gat() {\n  start\n  python main.py --epochs 1 --dry-run || error \"graph attention network failed\"\n}\n\nfunction clean() {\n  cd $BASE_DIR\n  echo \"running clean to remove cruft\"\n  rm -rf dcgan/fake_samples_epoch_000.png \\\n    dcgan/netD_epoch_0.pth \\\n    dcgan/netG_epoch_0.pth \\\n    dcgan/real_samples.png \\\n    fast_neural_style/saved_models.zip \\\n    fast_neural_style/saved_models/ \\\n    imagenet/checkpoint.pth.tar \\\n    imagenet/lsun/ \\\n    imagenet/model_best.pth.tar \\\n    imagenet/sample/ \\\n\tlanguage_translation/output/ \\\n    snli/.data/ \\\n    snli/.vector_cache/ \\\n    snli/results/ \\\n    super_resolution/dataset/ \\\n    super_resolution/model_epoch_1.pth \\\n    time_sequence_prediction/predict*.pdf \\\n    time_sequence_prediction/traindata.pt \\\n    word_language_model/model.pt \\\n    gcn/cora/ \\\n    gat/cora/ || error \"couldn't clean up some files\"\n\n  git checkout fast_neural_style/images/output-images/amber-candy.jpg || error \"couldn't clean up fast neural style image\"\n}\n\nfunction run_all() {\n  # cpp moved to `run_cpp_examples.sh```\n  dcgan\n  # distributed moved to `run_distributed_examples.sh`\n  fast_neural_style\n  imagenet\n  # language_translation\n  mnist\n  mnist_forward_forward\n  mnist_hogwild\n  mnist_rnn\n  regression\n  reinforcement_learning\n  siamese_network\n  super_resolution\n  time_sequence_prediction\n  vae\n  # vision_transformer - example broken see https://github.com/pytorch/examples/issues/1184 and https://github.com/pytorch/examples/pull/1258 for more details\n  word_language_model\n  fx\n  gcn\n  gat\n}\n\n# by default, run all examples\nif [ \"\" == \"$EXAMPLES\" ]; then\n  run_all\nelse\n  for i in $(echo $EXAMPLES | sed \"s/,/ /g\")\n  do\n    echo \"Starting $i\"\n    $i\n    echo \"Finished $i, status $?\"\n  done\nfi\n\nif [ \"\" == \"$ERRORS\" ]; then\n  echo \"Completed successfully with status $?\"\nelse\n  echo \"Some python examples failed:\"\n  printf \"$ERRORS\\n\"\n  #Exit with error (0-255) in case of failure in one of the tests.\n  exit 1\n\nfi\n"
        },
        {
          "name": "runtime.txt",
          "type": "blob",
          "size": 0.00390625,
          "content": "3.8\n"
        },
        {
          "name": "siamese_network",
          "type": "tree",
          "content": null
        },
        {
          "name": "super_resolution",
          "type": "tree",
          "content": null
        },
        {
          "name": "time_sequence_prediction",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils.sh",
          "type": "blob",
          "size": 0.83203125,
          "content": "#!/usr/bin/env bash\n# This script contains utility functions and initialize exmaple scripts.\n# Eg: run_python_examples.sh, run_distributed_examples.sh\n\nBASE_DIR=\"$(pwd)/$(dirname $0)\"\nEXAMPLES=$(echo $1 | sed -e 's/ //g')\n\n# Redirect 'python' calls to 'python3'\npython() {\n    command python3 \"$@\"\n}\n\nERRORS=${ERRORS-\"\"}\n\nfunction error() {\n  ERR=$1\n  if [ \"\" == \"$ERRORS\" ]; then\n    ERRORS=\"$ERR\"\n  else\n    ERRORS=\"$ERRORS\\n$ERR\"\n  fi\n}\n\nfunction install_deps() {\n  echo \"installing requirements\"\n  cat $BASE_DIR/*/requirements.txt | \\\n    sort -u | \\\n    # testing the installed version of torch, so don't pip install it.\n    grep -vE '^torch$' | \\\n    pip install -r /dev/stdin || \\\n    { error \"failed to install dependencies\"; exit 1; }\n}\n\nfunction start() {\n  EXAMPLE=${FUNCNAME[1]}\n  cd $BASE_DIR/$EXAMPLE\n  echo \"Running example: $EXAMPLE\"\n}\n"
        },
        {
          "name": "vae",
          "type": "tree",
          "content": null
        },
        {
          "name": "word_language_model",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}