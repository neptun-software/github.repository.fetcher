{
  "metadata": {
    "timestamp": 1736561289476,
    "page": 289,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "plasma-umass/scalene",
      "stars": 12348,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.390625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Created by https://www.gitignore.io/api/visualstudiocode\n# Edit at https://www.gitignore.io/?templates=visualstudiocode\n\n### VisualStudioCode ###\n.vscode/*      # Maybe .vscode/**/* instead - see comments\n!.vscode/settings.json\n!.vscode/tasks.json\n!.vscode/launch.json\n!.vscode/extensions.json\n\n### VisualStudioCode Patch ###\n# Ignore all local history of files\n**/.history\n\n# End of https://www.gitignore.io/api/visualstudiocode\n\n.idea\nscalene/libscalene.dylib\nscalene/libscalene.dylib.dSYM/Contents/Info.plist\nscalene/libscalene.dylib.dSYM/Contents/Resources/DWARF/libscalene.dylib\n\n# Vendor is regenerated by `make`\nvendor/\n!vendor/README.md\n\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 1.0087890625,
          "content": "# Read the Docs configuration file for Sphinx projects\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the OS, Python version and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n    # You can also specify other tool versions:\n    # nodejs: \"20\"\n    # rust: \"1.70\"\n    # golang: \"1.20\"\n\n# Build documentation in the \"docs/\" directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n  # You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs\n  # builder: \"dirhtml\"\n  # Fail on all warnings to avoid broken references\n  # fail_on_warning: true\n\n# Optionally build your docs in additional formats such as PDF and ePub\n# formats:\n#   - pdf\n#   - epub\n\n# Optional but recommended, declare the Python requirements required\n# to build your documentation\n# See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html\n# python:\n#   install:\n#     - requirements: docs/requirements.txt"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 1.0712890625,
          "content": "cff-version: 1.0.0\nmessage: \"If you use or refer to Scalene, please cite it as below.\"\nauthors:\n- family-names: \"Berger\"\n  given-names: \"Emery D.\"\n  orcid: \"https://orcid.org/0000-0002-3222-3271\"\n- family-names: \"Altmayer Pizzorno\"\n  given-names: \"Juan\"\n  orcid: \"https://orcid.org/0000-0002-1891-2919\"\n- family-names: \"Stern\"\n  given-names: \"Sam\"\ntitle: \"Scalene: a high-performance, high-precision CPU, GPU, and memory profiler for Python\"\nversion: 1.5.9\ndate-released: 2022-07-24\nurl: \"https://github.com/plasma-umass/scalene\"\npreferred-citation:\n  type: conference-paper\n  authors:\n  - family-names: \"Berger\"\n    given-names: \"Emery D.\"\n    orcid: \"https://orcid.org/0000-0002-3222-3271\"\n  - family-names: \"Stern\"\n    given-names: \"Sam\"\n  - family-names: \"Altmayer Pizzorno\"\n    given-names: \"Juan\"\n    orcid: \"https://orcid.org/0000-0002-1891-2919\"\n  journal: \"17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2023)\"\n  month: 7\n  start: 51 # First page number\n  end: 64 # Last page number\n  title: \"Triangulating Python Performance Issues with Scalene\"\n  year: 2023\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.275390625,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at Emery.berger@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "GNUmakefile",
          "type": "blob",
          "size": 3.0234375,
          "content": "LIBNAME = scalene\nPYTHON = python3\nPYTHON_SOURCES = scalene/[a-z]*.py\nJS_SOURCES = scalene/scalene-gui/*.js\nC_SOURCES = src/source/*.cpp src/include/*.h*\n\n.PHONY: black clang-format prettier format upload vendor-deps\n\n# CXXFLAGS = -std=c++14 -g -O0 # FIXME\nCXXFLAGS = -std=c++14 -Wall -g -O3 -DNDEBUG -D_REENTRANT=1 -DHL_USE_XXREALLOC=1 -pipe -fno-builtin-malloc -fvisibility=hidden -Wno-unused-result\n# CXX = g++\n\nINCLUDES  = -Isrc -Isrc/include\nINCLUDES := $(INCLUDES) -Ivendor/Heap-Layers -Ivendor/Heap-Layers/wrappers -Ivendor/Heap-Layers/utility\nINCLUDES := $(INCLUDES) -Ivendor/printf\n# python3-config may not be available in venv and such\nINCLUDES := $(INCLUDES) -I$(shell python3 -c \"import sysconfig; print(sysconfig.get_path('include'))\")\n\nifeq ($(shell uname -s),Darwin)\n  LIBFILE := lib$(LIBNAME).dylib\n  WRAPPER := vendor/Heap-Layers/wrappers/macwrapper.cpp\n  ifneq (,$(filter $(shell uname -p),arm arm64))  # this means \"if arm or arm64\"\n    ARCH := -arch arm64 -arch arm64e \n  else\n    ARCH := -arch x86_64\n  endif\n  CXXFLAGS := -std=c++14 -Wall -g -O3 -DNDEBUG -D_REENTRANT=1 -DHL_USE_XXREALLOC=1 -pipe -fno-builtin-malloc -fvisibility=hidden -flto -ftls-model=initial-exec -ftemplate-depth=1024 $(ARCH) -compatibility_version 1 -current_version 1 -dynamiclib\n  SED_INPLACE = -i ''\n\nelse # non-Darwin\n  LIBFILE := lib$(LIBNAME).so\n  WRAPPER := vendor/Heap-Layers/wrappers/gnuwrapper.cpp\n  INCLUDES := $(INCLUDES) -I/usr/include/nptl \n  CXXFLAGS := $(CXXFLAGS) -fPIC -shared -Bsymbolic\n  RPATH_FLAGS :=\n  SED_INPLACE = -i\n\nendif\n\nSRC := src/source/lib$(LIBNAME).cpp $(WRAPPER) vendor/printf/printf.cpp\n\nOUTDIR=scalene\n\nall: $(OUTDIR)/$(LIBFILE)\n\n$(OUTDIR)/$(LIBFILE): vendor-deps $(SRC) $(C_SOURCES) GNUmakefile\n\t$(CXX) $(CXXFLAGS) $(INCLUDES) $(SRC) -o $(OUTDIR)/$(LIBFILE) -ldl -lpthread\n\nclean:\n\trm -f $(OUTDIR)/$(LIBFILE) scalene/*.so scalene/*.dylib\n\trm -rf $(OUTDIR)/$(LIBFILE).dSYM\n\trm -rf scalene.egg-info\n\trm -rf build dist *egg-info\n\n$(WRAPPER) : vendor/Heap-Layers\n\nvendor/Heap-Layers:\n\tcd vendor && git clone https://github.com/emeryberger/Heap-Layers\n\nTMP := $(shell mktemp -d || echo /tmp)\n\nvendor/printf/printf.cpp:\n\tcd vendor && git clone https://github.com/mpaland/printf\n\tcd vendor/printf && ln -s printf.c printf.cpp\n\tsed -e 's/^#define printf printf_/\\/\\/&/' vendor/printf/printf.h > $(TMP)/printf.h.$$ && mv $(TMP)/printf.h.$$ vendor/printf/printf.h\n\tsed -e 's/^#define vsnprintf vsnprintf_/\\/\\/&/' vendor/printf/printf.h > $(TMP)/printf.h.$$ && mv $(TMP)/printf.h.$$ vendor/printf/printf.h\n\nvendor-deps: vendor/Heap-Layers vendor/printf/printf.cpp\n\nmypy:\n\t-mypy --no-warn-unused-ignores $(PYTHON_SOURCES)\n\nformat: black clang-format prettier\n\nclang-format:\n\t-clang-format -i $(C_SOURCES) --style=google\n\nblack:\n\t-black -l 79 $(PYTHON_SOURCES)\n\nprettier:\n\t-npx prettier -w $(JS_SOURCES)\n\nbdist: vendor-deps\n\t$(PYTHON) -m build --wheel\nifeq ($(shell uname -s),Linux)\n\tauditwheel repair dist/*.whl\n\trm -f dist/*.whl\n\tmv wheelhouse/*.whl dist/\nendif\n\nsdist: vendor-deps\n\t$(PYTHON) -m build --sdist\n\nupload: sdist bdist # to pypi\n\t$(PYTHON) -m twine upload dist/*\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.091796875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.119140625,
          "content": "graft vendor/Heap-Layers\nprune vendor/Heap-Layers/.git\ngraft vendor/printf\nprune vendor/printf/.git\nexclude scalene/old/*\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.333984375,
          "content": "LIBNAME = scalene\nPYTHON = python3\nPYTHON_SOURCES = scalene/[a-z]*.py\nC_SOURCES = src/source/get_line_atomic.cpp src/include/*.h* # src/source/libscalene.cpp \n\nCXXFLAGS = /Ox /DNDEBUG /std:c++14 /Zi\nCXX = cl\n\nMAIN_INCLUDES  = -Isrc -Isrc/include\nINCLUDES = $(MAIN_INCLUDES) -Ivendor/Heap-Layers -Ivendor/Heap-Layers/wrappers -Ivendor/Heap-Layers/utility -Ivendor/printf\n\nLIBFILE = lib$(LIBNAME).dll\nWRAPPER = # vendor/Heap-Layers/wrappers/gnuwrapper.cpp\n\nSRC = src/source/lib$(LIBNAME).cpp $(WRAPPER) vendor/printf/printf.cpp\n\nall:  # vendor-deps $(SRC) $(OTHER_DEPS)\n# $(CXX) $(CXXFLAGS) $(INCLUDES) $(SRC) /o $(LIBFILE)\n\nmypy:\n\t-mypy $(PYTHON_SOURCES)\n\nformat: black isort clang-format\n\nclang-format:\n\t-clang-format -i $(C_SOURCES) --style=google\n\nisort:\n\t-isort $(PYTHON_SOURCES)\n\nblack:\n\t-black -l 79 $(PYTHON_SOURCES)\n\nvendor/Heap-Layers:\n\tcd vendor && git clone https://github.com/emeryberger/Heap-Layers\n\nvendor/printf/printf.cpp:\n\tcd vendor && git clone https://github.com/mpaland/printf\n\tcd vendor\\printf && copy printf.c printf.cpp\n\nvendor-deps: clear-vendor-dirs vendor/Heap-Layers vendor/printf/printf.cpp\n\nclear-vendor-dirs:\n\tif exist vendor\\ (rmdir /Q /S vendor)\n\tmkdir vendor\n\npkg: vendor/Heap-Layers vendor/printf/printf.cpp\n\t-rm -rf dist build *egg-info\n\t$(PYTHON) setup.py sdist bdist_wheel\n\nupload: pkg # to pypi\n\t$(PYTHON) -m twine upload dist/*\n"
        },
        {
          "name": "Pipfile",
          "type": "blob",
          "size": 0.2080078125,
          "content": "[[source]]\nname = \"pypi\"\nurl = \"https://pypi.org/simple\"\nverify_ssl = true\n\n[dev-packages]\nnumpy = \"*\"\npyperf = \"*\"\npytest = \"*\"\nwheel = \"*\"\n\n[packages]\ncloudpickle = \"*\"\nnvidia-ml-py = \"*\"\nrich = \"*\"\nwheel = \"*\"\n"
        },
        {
          "name": "Pipfile.lock",
          "type": "blob",
          "size": 8.3193359375,
          "content": "{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"1b3352dc4c084bab46f08dbb4d89f16a3665912992c7d7e45e8b9f8a2d204e74\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {},\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"cloudpickle\": {\n            \"hashes\": [\n                \"sha256:61f594d1f4c295fa5cd9014ceb3a1fc4a70b0de1164b94fbc2d854ccba056f9f\",\n                \"sha256:d89684b8de9e34a2a43b3460fbca07d09d6e25ce858df4d5a44240403b6178f5\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.2.1\"\n        },\n        \"markdown-it-py\": {\n            \"hashes\": [\n                \"sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1\",\n                \"sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb\"\n            ],\n            \"markers\": \"python_version >= '3.8'\",\n            \"version\": \"==3.0.0\"\n        },\n        \"mdurl\": {\n            \"hashes\": [\n                \"sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8\",\n                \"sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==0.1.2\"\n        },\n        \"nvidia-ml-py\": {\n            \"hashes\": [\n                \"sha256:8d81e5ed993c84006454102af84c4bffdf72ba5c51212b6c0121c65688983e14\",\n                \"sha256:ae246ec810a05438375ce345e35171bc3f4a906487e9ea2632473d7e4f4bd375\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==12.535.77\"\n        },\n        \"pygments\": {\n            \"hashes\": [\n                \"sha256:13fc09fa63bc8d8671a6d247e1eb303c4b343eaee81d861f3404db2935653692\",\n                \"sha256:1daff0494820c69bc8941e407aa20f577374ee88364ee10a98fdbe0aece96e29\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==2.16.1\"\n        },\n        \"rich\": {\n            \"hashes\": [\n                \"sha256:146a90b3b6b47cac4a73c12866a499e9817426423f57c5a66949c086191a8808\",\n                \"sha256:fb9d6c0a0f643c99eed3875b5377a184132ba9be4d61516a55273d3554d75a39\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==13.5.2\"\n        },\n        \"wheel\": {\n            \"hashes\": [\n                \"sha256:12b911f083e876e10c595779709f8a88a59f45aacc646492a67fe9ef796c1b47\",\n                \"sha256:473219bd4cbedc62cea0cb309089b593e47c15c4a2531015f94e4e3b9a0f6981\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.41.1\"\n        }\n    },\n    \"develop\": {\n        \"iniconfig\": {\n            \"hashes\": [\n                \"sha256:2d91e135bf72d31a410b17c16da610a82cb55f6b0477d1a902134b24a455b8b3\",\n                \"sha256:b6a85871a79d2e3b22d2d1b94ac2824226a63c6b741c88f7ae975f18b6778374\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==2.0.0\"\n        },\n        \"numpy\": {\n            \"hashes\": [\n                \"sha256:0d60fbae8e0019865fc4784745814cff1c421df5afee233db6d88ab4f14655a2\",\n                \"sha256:1a1329e26f46230bf77b02cc19e900db9b52f398d6722ca853349a782d4cff55\",\n                \"sha256:1b9735c27cea5d995496f46a8b1cd7b408b3f34b6d50459d9ac8fe3a20cc17bf\",\n                \"sha256:2792d23d62ec51e50ce4d4b7d73de8f67a2fd3ea710dcbc8563a51a03fb07b01\",\n                \"sha256:3e0746410e73384e70d286f93abf2520035250aad8c5714240b0492a7302fdca\",\n                \"sha256:4c3abc71e8b6edba80a01a52e66d83c5d14433cbcd26a40c329ec7ed09f37901\",\n                \"sha256:5883c06bb92f2e6c8181df7b39971a5fb436288db58b5a1c3967702d4278691d\",\n                \"sha256:5c97325a0ba6f9d041feb9390924614b60b99209a71a69c876f71052521d42a4\",\n                \"sha256:60e7f0f7f6d0eee8364b9a6304c2845b9c491ac706048c7e8cf47b83123b8dbf\",\n                \"sha256:76b4115d42a7dfc5d485d358728cdd8719be33cc5ec6ec08632a5d6fca2ed380\",\n                \"sha256:7dc869c0c75988e1c693d0e2d5b26034644399dd929bc049db55395b1379e044\",\n                \"sha256:834b386f2b8210dca38c71a6e0f4fd6922f7d3fcff935dbe3a570945acb1b545\",\n                \"sha256:8b77775f4b7df768967a7c8b3567e309f617dd5e99aeb886fa14dc1a0791141f\",\n                \"sha256:90319e4f002795ccfc9050110bbbaa16c944b1c37c0baeea43c5fb881693ae1f\",\n                \"sha256:b79e513d7aac42ae918db3ad1341a015488530d0bb2a6abcbdd10a3a829ccfd3\",\n                \"sha256:bb33d5a1cf360304754913a350edda36d5b8c5331a8237268c48f91253c3a364\",\n                \"sha256:bec1e7213c7cb00d67093247f8c4db156fd03075f49876957dca4711306d39c9\",\n                \"sha256:c5462d19336db4560041517dbb7759c21d181a67cb01b36ca109b2ae37d32418\",\n                \"sha256:c5652ea24d33585ea39eb6a6a15dac87a1206a692719ff45d53c5282e66d4a8f\",\n                \"sha256:d7806500e4f5bdd04095e849265e55de20d8cc4b661b038957354327f6d9b295\",\n                \"sha256:db3ccc4e37a6873045580d413fe79b68e47a681af8db2e046f1dacfa11f86eb3\",\n                \"sha256:dfe4a913e29b418d096e696ddd422d8a5d13ffba4ea91f9f60440a3b759b0187\",\n                \"sha256:eb942bfb6f84df5ce05dbf4b46673ffed0d3da59f13635ea9b926af3deb76926\",\n                \"sha256:f08f2e037bba04e707eebf4bc934f1972a315c883a9e0ebfa8a7756eabf9e357\",\n                \"sha256:fd608e19c8d7c55021dffd43bfe5492fab8cc105cc8986f813f8c3c048b38760\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.25.2\"\n        },\n        \"packaging\": {\n            \"hashes\": [\n                \"sha256:994793af429502c4ea2ebf6bf664629d07c1a9fe974af92966e4b8d2df7edc61\",\n                \"sha256:a392980d2b6cffa644431898be54b0045151319d1e7ec34f0cfed48767dd334f\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==23.1\"\n        },\n        \"pluggy\": {\n            \"hashes\": [\n                \"sha256:c2fd55a7d7a3863cba1a013e4e2414658b1d07b6bc57b3919e0c63c9abb99849\",\n                \"sha256:d12f0c4b579b15f5e054301bb226ee85eeeba08ffec228092f8defbaa3a4c4b3\"\n            ],\n            \"markers\": \"python_version >= '3.7'\",\n            \"version\": \"==1.2.0\"\n        },\n        \"psutil\": {\n            \"hashes\": [\n                \"sha256:104a5cc0e31baa2bcf67900be36acde157756b9c44017b86b2c049f11957887d\",\n                \"sha256:3c6f686f4225553615612f6d9bc21f1c0e305f75d7d8454f9b46e901778e7217\",\n                \"sha256:4aef137f3345082a3d3232187aeb4ac4ef959ba3d7c10c33dd73763fbc063da4\",\n                \"sha256:5410638e4df39c54d957fc51ce03048acd8e6d60abc0f5107af51e5fb566eb3c\",\n                \"sha256:5b9b8cb93f507e8dbaf22af6a2fd0ccbe8244bf30b1baad6b3954e935157ae3f\",\n                \"sha256:7a7dd9997128a0d928ed4fb2c2d57e5102bb6089027939f3b722f3a210f9a8da\",\n                \"sha256:89518112647f1276b03ca97b65cc7f64ca587b1eb0278383017c2a0dcc26cbe4\",\n                \"sha256:8c5f7c5a052d1d567db4ddd231a9d27a74e8e4a9c3f44b1032762bd7b9fdcd42\",\n                \"sha256:ab8ed1a1d77c95453db1ae00a3f9c50227ebd955437bcf2a574ba8adbf6a74d5\",\n                \"sha256:acf2aef9391710afded549ff602b5887d7a2349831ae4c26be7c807c0a39fac4\",\n                \"sha256:b258c0c1c9d145a1d5ceffab1134441c4c5113b2417fafff7315a917a026c3c9\",\n                \"sha256:be8929ce4313f9f8146caad4272f6abb8bf99fc6cf59344a3167ecd74f4f203f\",\n                \"sha256:c607bb3b57dc779d55e1554846352b4e358c10fff3abf3514a7a6601beebdb30\",\n                \"sha256:ea8518d152174e1249c4f2a1c89e3e6065941df2fa13a1ab45327716a23c2b48\"\n            ],\n            \"markers\": \"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\",\n            \"version\": \"==5.9.5\"\n        },\n        \"pyperf\": {\n            \"hashes\": [\n                \"sha256:171aea69b8efde61210e512166d8764e7765a9c7678b768052174b01f349f247\",\n                \"sha256:9f81bf78335428ddf9845f1388dfb56181e744a69e93d8506697a56dc67b6d5f\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.6.1\"\n        },\n        \"pytest\": {\n            \"hashes\": [\n                \"sha256:78bf16451a2eb8c7a2ea98e32dc119fd2aa758f1d5d66dbf0a59d69a3969df32\",\n                \"sha256:b4bf8c45bd59934ed84001ad51e11b4ee40d40a1229d2c79f9c592b0a3f6bd8a\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==7.4.0\"\n        },\n        \"wheel\": {\n            \"hashes\": [\n                \"sha256:12b911f083e876e10c595779709f8a88a59f45aacc646492a67fe9ef796c1b47\",\n                \"sha256:473219bd4cbedc62cea0cb309089b593e47c15c4a2531015f94e4e3b9a0f6981\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==0.41.1\"\n        }\n    }\n}\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 21.404296875,
          "content": "![scalene](https://github.com/plasma-umass/scalene/raw/master/docs/scalene-icon-white.png)\n\n# Scalene: a Python CPU+GPU+memory profiler with AI-powered optimization proposals\n\nby [Emery Berger](https://emeryberger.com), [Sam Stern](https://samstern.me/), and [Juan Altmayer Pizzorno](https://github.com/jaltmayerpizzorno).\n\n[![Scalene community Slack](https://github.com/plasma-umass/scalene/raw/master/docs/images/slack-logo.png)](https://join.slack.com/t/scaleneprofil-jge3234/shared_invite/zt-110vzrdck-xJh5d4gHnp5vKXIjYD3Uwg)[Scalene community Slack](https://join.slack.com/t/scaleneprofil-jge3234/shared_invite/zt-110vzrdck-xJh5d4gHnp5vKXIjYD3Uwg)\n\n[![PyPI Latest Release](https://img.shields.io/pypi/v/scalene.svg)](https://pypi.org/project/scalene/)[![Anaconda-Server Badge](https://img.shields.io/conda/v/conda-forge/scalene)](https://anaconda.org/conda-forge/scalene) [![Downloads](https://static.pepy.tech/badge/scalene)](https://pepy.tech/project/scalene)[![Anaconda downloads](https://img.shields.io/conda/d/conda-forge/scalene?logo=conda)](https://anaconda.org/conda-forge/scalene) [![Downloads](https://static.pepy.tech/badge/scalene/month)](https://pepy.tech/project/scalene) ![Python versions](https://img.shields.io/pypi/pyversions/scalene.svg?style=flat-square)[![Visual Studio Code Extension version](https://img.shields.io/visual-studio-marketplace/v/emeryberger.scalene?logo=visualstudiocode)](https://marketplace.visualstudio.com/items?itemName=EmeryBerger.scalene) ![License](https://img.shields.io/github/license/plasma-umass/scalene)\n\n![Ozsvald tweet](https://github.com/plasma-umass/scalene/raw/master/docs/Ozsvald-tweet.png)\n\n(tweet from Ian Ozsvald, author of [_High Performance Python_](https://smile.amazon.com/High-Performance-Python-Performant-Programming/dp/1492055026/ref=sr_1_1?crid=texbooks))\n\n![Semantic Scholar success story](https://github.com/plasma-umass/scalene/raw/master/docs/semantic-scholar-success.png)\n\n***Scalene web-based user interface:*** [http://plasma-umass.org/scalene-gui/](http://plasma-umass.org/scalene-gui/)\n \n## About Scalene\n\nScalene is a high-performance CPU, GPU *and* memory profiler for\nPython that does a number of things that other Python profilers do not\nand cannot do.  It runs orders of magnitude faster than many other\nprofilers while delivering far more detailed information. It is also\nthe first profiler ever to incorporate AI-powered proposed\noptimizations.\n\n### AI-powered optimization suggestions\n\n> **Note**\n>\n> To enable AI-powered optimization suggestions, you need to enter an [OpenAI key](https://openai.com/api/) in the box under \"Advanced options\". _Your account will need to have a positive balance for this to work_ (check your balance at https://platform.openai.com/account/usage).\n>\n> <img width=\"487\" alt=\"Scalene advanced options\" src=\"https://user-images.githubusercontent.com/1612723/211639253-ec926b38-3efe-4a20-8514-e10dde94ec01.png\">\n\nOnce you've entered your OpenAI key (see above), click on the lightning bolt (⚡) beside any line or the explosion (💥) for an entire region of code to generate a proposed optimization. Click on a proposed optimization to copy it to the clipboard.\n\n<img width=\"571\" alt=\"example proposed optimization\" src=\"https://user-images.githubusercontent.com/1612723/211639968-37cf793f-3290-43d1-9282-79e579558388.png\">\n\nYou can click as many times as you like on the lightning bolt or explosion, and it will generate different suggested optimizations. Your mileage may vary, but in some cases, the suggestions are quite impressive (e.g., order-of-magnitude improvements). \n  \n### Quick Start\n\n#### Installing Scalene:\n\n```console\npython3 -m pip install -U scalene\n```\n\nor\n\n```console\nconda install -c conda-forge scalene\n```\n\n#### Using Scalene:\n\nAfter installing Scalene, you can use Scalene at the command line, or as a Visual Studio Code extension.\n\n<details>\n  <summary>\n    Using the Scalene VS Code Extension:\n  </summary>\n  \n\nFirst, install <a href=\"https://marketplace.visualstudio.com/items?itemName=EmeryBerger.scalene\">the Scalene extension from the VS Code Marketplace</a> or by searching for it within VS Code by typing Command-Shift-X (Mac) or Ctrl-Shift-X (Windows). Once that's installed, click Command-Shift-P or Ctrl-Shift-P to open the <a href=\"https://code.visualstudio.com/docs/getstarted/userinterface\">Command Palette</a>. Then select <b>\"Scalene: AI-powered profiling...\"</b> (you can start typing Scalene and it will pop up if it's installed). Run that and, assuming your code runs for at least a second, a Scalene profile will appear in a webview.\n  \n<img width=\"734\" alt=\"Screenshot 2023-09-20 at 7 09 06 PM\" src=\"https://github.com/plasma-umass/scalene/assets/1612723/7e78e3d2-e649-4f02-86fd-0da2a259a1a4\">\n\n</details>\n\n<details>\n<summary>\nCommonly used command-line options:\n</summary>\n\n```console\nscalene your_prog.py                             # full profile (outputs to web interface)\npython3 -m scalene your_prog.py                  # equivalent alternative\n\nscalene --cli your_prog.py                       # use the command-line only (no web interface)\n\nscalene --cpu your_prog.py                       # only profile CPU\nscalene --cpu --gpu your_prog.py                 # only profile CPU and GPU\nscalene --cpu --gpu --memory your_prog.py        # profile everything (same as no options)\n\nscalene --reduced-profile your_prog.py           # only profile lines with significant usage\nscalene --profile-interval 5.0 your_prog.py      # output a new profile every five seconds\n\nscalene (Scalene options) --- your_prog.py (...) # use --- to tell Scalene to ignore options after that point\nscalene --help                                   # lists all options\n```\n\n</details>\n\n<details>\n<summary>\nUsing Scalene programmatically in your code:\n</summary>\n\nInvoke using `scalene` as above and then:\n\n```Python\nfrom scalene import scalene_profiler\n\n# Turn profiling on\nscalene_profiler.start()\n\n# your code\n\n# Turn profiling off\nscalene_profiler.stop()\n```\n\n```Python\nfrom scalene.scalene_profiler import enable_profiling\n\nwith enable_profiling():\n    # do something\n```\n\n</details>\n\n<details>\n<summary>\nUsing Scalene to profile only specific functions via <code>@profile</code>:\n</summary>\n\nJust preface any functions you want to profile with the `@profile` decorator and run it with Scalene:\n\n```Python\n# do not import profile!\n\n@profile\ndef slow_function():\n    import time\n    time.sleep(3)\n```\n\n</details>\n\n#### Web-based GUI\n\nScalene has both a CLI and a web-based GUI [(demo here)](http://plasma-umass.org/scalene-gui/).\n\nBy default, once Scalene has profiled your program, it will open a\ntab in a web browser with an interactive user interface (all processing is done\nlocally). Hover over bars to see breakdowns of CPU and memory\nconsumption, and click on underlined column headers to sort the\ncolumns. The generated file `profile.html` is self-contained and can be saved for later use.\n\n[![Scalene web GUI](https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/scalene-gui-example.png)](https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/scalene-gui-example-full.png)\n\n\n## Scalene Overview\n\n### Scalene talk (PyCon US 2021)\n\n[This talk](https://youtu.be/5iEf-_7mM1k) presented at PyCon 2021 walks through Scalene's advantages and how to use it to debug the performance of an application (and provides some technical details on its internals). We highly recommend watching this video!\n\n[![Scalene presentation at PyCon 2021](https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/scalene-video-img.png)](https://youtu.be/5iEf-_7mM1k \"Scalene presentation at PyCon 2021\")\n\n### Fast and Accurate\n\n- Scalene is **_fast_**. It uses sampling instead of instrumentation or relying on Python's tracing facilities. Its overhead is typically no more than 10-20% (and often less).\n\n- Scalene is **accurate**. We tested CPU profiler accuracy and found that Scalene is among the most accurate profilers, correctly measuring time taken.\n\n![Profiler accuracy](https://github.com/plasma-umass/scalene/raw/master/docs/cpu-accuracy-comparison.png)\n\n- Scalene performs profiling **_at the line level_** _and_ **_per function_**, pointing to the functions and the specific lines of code responsible for the execution time in your program.\n\n### CPU profiling\n\n- Scalene **separates out time spent in Python from time in native code** (including libraries). Most Python programmers aren't going to optimize the performance of native code (which is usually either in the Python implementation or external libraries), so this helps developers focus their optimization efforts on the code they can actually improve.\n- Scalene **highlights hotspots** (code accounting for significant percentages of CPU time or memory allocation) in red, making them even easier to spot.\n- Scalene also separates out **system time**, making it easy to find I/O bottlenecks.\n\n### GPU profiling\n\n- Scalene reports **GPU time** (currently limited to NVIDIA-based systems).\n\n### Memory profiling\n\n- Scalene **profiles memory usage**. In addition to tracking CPU usage, Scalene also points to the specific lines of code responsible for memory growth. It accomplishes this via an included specialized memory allocator.\n- Scalene separates out the percentage of **memory consumed by Python code vs. native code**.\n- Scalene produces **_per-line_ memory profiles**.\n- Scalene **identifies lines with likely memory leaks**.\n- Scalene **profiles _copying volume_**, making it easy to spot inadvertent copying, especially due to crossing Python/library boundaries (e.g., accidentally converting `numpy` arrays into Python arrays, and vice versa).\n\n### Other features\n\n- Scalene can produce **reduced profiles** (via `--reduced-profile`) that only report lines that consume more than 1% of CPU or perform at least 100 allocations.\n- Scalene supports `@profile` decorators to profile only specific functions.\n- When Scalene is profiling a program launched in the background (via `&`), you can **suspend and resume profiling**.\n\n# Comparison to Other Profilers\n\n## Performance and Features\n\nBelow is a table comparing the **performance and features** of various profilers to Scalene.\n\n![Performance and feature comparison](https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/profiler-comparison.png)\n\n- **Slowdown**: the slowdown when running a benchmark from the Pyperformance suite. Green means less than 2x overhead. Scalene's overhead is just a 35% slowdown.\n\nScalene has all of the following features, many of which only Scalene supports:\n\n- **Lines or functions**: does the profiler report information only for entire functions, or for every line -- Scalene does both.\n- **Unmodified Code**: works on unmodified code.\n- **Threads**: supports Python threads.\n- **Multiprocessing**: supports use of the `multiprocessing` library -- _Scalene only_\n- **Python vs. C time**: breaks out time spent in Python vs. native code (e.g., libraries) -- _Scalene only_\n- **System time**: breaks out system time (e.g., sleeping or performing I/O) -- _Scalene only_\n- **Profiles memory**: reports memory consumption per line / function\n- **GPU**: reports time spent on an NVIDIA GPU (if present) -- _Scalene only_\n- **Memory trends**: reports memory use over time per line / function -- _Scalene only_\n- **Copy volume**: reports megabytes being copied per second -- _Scalene only_\n- **Detects leaks**: automatically pinpoints lines responsible for likely memory leaks -- _Scalene only_\n\n## Output\n\nIf you include the `--cli` option, Scalene prints annotated source code for the program being profiled\n(as text, JSON (`--json`), or HTML (`--html`)) and any modules it\nuses in the same directory or subdirectories (you can optionally have\nit `--profile-all` and only include files with at least a\n`--cpu-percent-threshold` of time).  Here is a snippet from\n`pystone.py`.\n\n![Example profile](https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/sample-profile-pystone.png)\n\n* **Memory usage at the top**: Visualized by \"sparklines\", memory consumption over the runtime of the profiled code.\n* **\"Time Python\"**: How much time was spent in Python code.\n* **\"native\"**: How much time was spent in non-Python code (e.g., libraries written in C/C++).\n* **\"system\"**: How much time was spent in the system (e.g., I/O).\n* **\"GPU\"**: (not shown here) How much time spent on the GPU, if your system has an NVIDIA GPU installed.\n* **\"Memory Python\"**: How much of the memory allocation happened on the Python side of the code, as opposed to in non-Python code (e.g., libraries written in C/C++).\n* **\"net\"**: Positive net memory numbers indicate total memory allocation in megabytes; negative net memory numbers indicate memory reclamation.\n* **\"timeline / %\"**: Visualized by \"sparklines\", memory consumption generated by this line over the program runtime, and the percentages of total memory activity this line represents.\n* **\"Copy (MB/s)\"**: The amount of megabytes being copied per second (see \"About Scalene\").\n\n##  Scalene\n\nThe following command runs Scalene on a provided example program.\n\n```console\nscalene test/testme.py\n```\n\n<details>\n <summary>\n  Click to see all Scalene's options (available by running with <code>--help</code>)\n </summary>\n\n```console\n    % scalene --help\n     usage: scalene [-h] [--outfile OUTFILE] [--html] [--reduced-profile]\n                    [--profile-interval PROFILE_INTERVAL] [--cpu-only]\n                    [--profile-all] [--profile-only PROFILE_ONLY]\n                    [--use-virtual-time]\n                    [--cpu-percent-threshold CPU_PERCENT_THRESHOLD]\n                    [--cpu-sampling-rate CPU_SAMPLING_RATE]\n                    [--malloc-threshold MALLOC_THRESHOLD]\n     \n     Scalene: a high-precision CPU and memory profiler.\n     https://github.com/plasma-umass/scalene\n     \n     command-line:\n        % scalene [options] yourprogram.py\n     or\n        % python3 -m scalene [options] yourprogram.py\n     \n     in Jupyter, line mode:\n        %scrun [options] statement\n     \n     in Jupyter, cell mode:\n        %%scalene [options]\n        code...\n        code...\n     \n     optional arguments:\n       -h, --help            show this help message and exit\n       --outfile OUTFILE     file to hold profiler output (default: stdout)\n       --html                output as HTML (default: text)\n       --reduced-profile     generate a reduced profile, with non-zero lines only (default: False)\n       --profile-interval PROFILE_INTERVAL\n                             output profiles every so many seconds (default: inf)\n       --cpu-only            only profile CPU time (default: profile CPU, memory, and copying)\n       --profile-all         profile all executed code, not just the target program (default: only the target program)\n       --profile-only PROFILE_ONLY\n                             profile only code in filenames that contain the given strings, separated by commas (default: no restrictions)\n       --use-virtual-time    measure only CPU time, not time spent in I/O or blocking (default: False)\n       --cpu-percent-threshold CPU_PERCENT_THRESHOLD\n                             only report profiles with at least this percent of CPU time (default: 1%)\n       --cpu-sampling-rate CPU_SAMPLING_RATE\n                             CPU sampling rate (default: every 0.01s)\n       --malloc-threshold MALLOC_THRESHOLD\n                             only report profiles with at least this many allocations (default: 100)\n     \n     When running Scalene in the background, you can suspend/resume profiling\n     for the process ID that Scalene reports. For example:\n     \n        % python3 -m scalene [options] yourprogram.py &\n      Scalene now profiling process 12345\n        to suspend profiling: python3 -m scalene.profile --off --pid 12345\n        to resume profiling:  python3 -m scalene.profile --on  --pid 12345\n```\n</details>\n\n### Scalene with Jupyter\n\n<details>\n<summary>\nInstructions for installing and using Scalene with Jupyter notebooks\n</summary>\n\n[This notebook](https://nbviewer.jupyter.org/github/plasma-umass/scalene/blob/master/docs/scalene-demo.ipynb) illustrates the use of Scalene in Jupyter.\n\nInstallation:\n\n```console\n!pip install scalene\n%load_ext scalene\n```\n\nLine mode:\n\n```console\n%scrun [options] statement\n```\n\nCell mode:\n\n```console\n%%scalene [options]\ncode...\ncode...\n```\n</details>\n\n## Installation\n\n<details open>\n<summary>Using <code>pip</code> (Mac OS X, Linux, Windows, and WSL2)</summary>\n\nScalene is distributed as a `pip` package and works on Mac OS X, Linux (including Ubuntu in [Windows WSL2](https://docs.microsoft.com/en-us/windows/wsl/wsl2-index)) and (with limitations) Windows platforms.\n\n> **Note**\n>\n> The Windows version currently only supports CPU and GPU profiling, but not memory or copy profiling.\n> \n\nYou can install it as follows:\n```console\n  % pip install -U scalene\n```\n\nor\n```console\n  % python3 -m pip install -U scalene\n```\n\nYou may need to install some packages first.\n\nSee https://stackoverflow.com/a/19344978/4954434 for full instructions for all Linux flavors.\n\nFor Ubuntu/Debian:\n\n```console\n  % sudo apt install git python3-all-dev\n```\n</details>\n\n<details>\n<summary>Using <code>conda</code> (Mac OS X, Linux, Windows, and WSL2)</summary>\n\n```console\n  % conda install -c conda-forge scalene\n```\n\nScalene is distributed as a `conda` package and works on Mac OS X, Linux (including Ubuntu in [Windows WSL2](https://docs.microsoft.com/en-us/windows/wsl/wsl2-index)) and (with limitations) Windows platforms.\n\n> **Note**\n>\n> The Windows version currently only supports CPU and GPU profiling, but not memory or copy profiling.\n> \n</details>\n\n<details>\n<summary>On ArchLinux</summary>\n\nYou can install Scalene on Arch Linux via the [AUR\npackage](https://aur.archlinux.org/packages/python-scalene-git/). Use your favorite AUR helper, or\nmanually download the `PKGBUILD` and run `makepkg -cirs` to build. Note that this will place\n`libscalene.so` in `/usr/lib`; modify the below usage instructions accordingly.\n</details>\n\n# Frequently Asked Questions\n\n<details>\n<summary>\nCan I use Scalene with PyTest?\n</summary>\n\n**A:** Yes! You can run it as follows (for example):\n\n`python3 -m scalene --- -m pytest your_test.py` \n\n</details>\n\n<details>\n<summary>\nIs there any way to get shorter profiles or do more targeted profiling?\n</summary>\n\n**A:** Yes! There are several options:\n\n1. Use `--reduced-profile` to include only lines and files with memory/CPU/GPU activity.\n2. Use `--profile-only` to include only filenames containing specific strings (as in, `--profile-only foo,bar,baz`).\n3. Decorate functions of interest with `@profile` to have Scalene report _only_ those functions.\n4. Turn profiling on and off programmatically by importing Scalene profiler (`from scalene import scalene_profiler`) and then turning profiling on and off via `scalene_profiler.start()` and `scalene_profiler.stop()`. By default, Scalene runs with profiling on, so to delay profiling until desired, use the `--off` command-line option (`python3 -m scalene --off yourprogram.py`).\n</details>\n\n<details>\n<summary>\nHow do I run Scalene in PyCharm?\n</summary>\n\n**A:**  In PyCharm, you can run Scalene at the command line by opening the terminal at the bottom of the IDE and running a Scalene command (e.g., `python -m scalene <your program>`). Use the options `--cli`, `--html`, and `--outfile <your output.html>` to generate an HTML file that you can then view in the IDE.\n</details>\n\n<details>\n<summary>\nHow do I use Scalene with Django?\n</summary>\n\n**A:** Pass in the `--noreload` option (see https://github.com/plasma-umass/scalene/issues/178).\n</details>\n\n\n<details>\n<summary>\nDoes Scalene work with gevent/Greenlets?\n</summary>\n\n**A:** Yes! Put the following code in the beginning of your program, or modify the call to `monkey.patch_all` as below:\n\n```python\nfrom gevent import monkey\nmonkey.patch_all(thread=False)\n```\n</details>\n\n\n\n<details>\n<summary>\nHow do I use Scalene with PyTorch on the Mac?\n</summary>\n\n**A:** Scalene works with PyTorch version 1.5.1 on Mac OS X. There's a bug in newer versions of PyTorch (https://github.com/pytorch/pytorch/issues/57185) that interferes with Scalene (discussion here: https://github.com/plasma-umass/scalene/issues/110), but only on Macs.\n</details>\n\n# Technical Information\n\nFor details about how Scalene works, please see the following paper, which won the Jay Lepreau Best Paper Award at [OSDI 2023](https://www.usenix.org/conference/osdi23/presentation/berger): [Triangulating Python Performance Issues with Scalene](https://arxiv.org/pdf/2212.07597). (Note that this paper does not include information about the AI-driven proposed optimizations.)\n\n<details>\n<summary>\nTo cite Scalene in an academic paper, please use the following:\n</summary>\n\n```latex\n@inproceedings{288540,\nauthor = {Emery D. Berger and Sam Stern and Juan Altmayer Pizzorno},\ntitle = {Triangulating Python Performance Issues with {S}calene},\nbooktitle = {{17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23)}},\nyear = {2023},\nisbn = {978-1-939133-34-2},\naddress = {Boston, MA},\npages = {51--64},\nurl = {https://www.usenix.org/conference/osdi23/presentation/berger},\npublisher = {USENIX Association},\nmonth = jul\n}\n```\n</details>\n\n\n# Success Stories\n\nIf you use Scalene to successfully debug a performance problem, please [add a comment to this issue](https://github.com/plasma-umass/scalene/issues/58)!\n\n\n# Acknowledgements\n\nLogo created by [Sophia Berger](https://www.linkedin.com/in/sophia-berger/).\n\nThis material is based upon work supported by the National Science\nFoundation under Grant No. 1955610. Any opinions, findings, and\nconclusions or recommendations expressed in this material are those of\nthe author(s) and do not necessarily reflect the views of the National\nScience Foundation.\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "index.rst",
          "type": "blob",
          "size": 23.6455078125,
          "content": ".. figure::\n   https://github.com/plasma-umass/scalene/raw/master/docs/scalene-icon-white.png\n   :alt: scalene\n\n   scalene\n\nScalene: a Python CPU+GPU+memory profiler with AI-powered optimization proposals\n================================================================================\n\nby `Emery Berger <https://emeryberger.com>`__, `Sam\nStern <https://samstern.me/>`__, and `Juan Altmayer\nPizzorno <https://github.com/jaltmayerpizzorno>`__.\n\n|Scalene community Slack|\\ `Scalene community\nSlack <https://join.slack.com/t/scaleneprofil-jge3234/shared_invite/zt-110vzrdck-xJh5d4gHnp5vKXIjYD3Uwg>`__\n\n|PyPI Latest Release|\\ |Anaconda-Server Badge| |Downloads|\\ |Anaconda\ndownloads| |image1| |Python versions|\\ |Visual Studio Code Extension\nversion| |License|\n\n.. figure::\n   https://github.com/plasma-umass/scalene/raw/master/docs/Ozsvald-tweet.png\n   :alt: Ozsvald tweet\n\n   Ozsvald tweet\n\n(tweet from Ian Ozsvald, author of `High Performance\nPython <https://smile.amazon.com/High-Performance-Python-Performant-Programming/dp/1492055026/ref=sr_1_1?crid=texbooks>`__)\n\n.. figure::\n   https://github.com/plasma-umass/scalene/raw/master/docs/semantic-scholar-success.png\n   :alt: Semantic Scholar success story\n\n   Semantic Scholar success story\n\n**Scalene web-based user interface:**\nhttp://plasma-umass.org/scalene-gui/\n\nAbout Scalene\n-------------\n\nScalene is a high-performance CPU, GPU *and* memory profiler for Python\nthat does a number of things that other Python profilers do not and\ncannot do. It runs orders of magnitude faster than many other profilers\nwhile delivering far more detailed information. It is also the first\nprofiler ever to incorporate AI-powered proposed optimizations.\n\nAI-powered optimization suggestions\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n   **Note**\n\n   To enable AI-powered optimization suggestions, you need to enter an\n   `OpenAI key <https://openai.com/api/>`__ in the box under “Advanced\n   options”. *Your account will need to have a positive balance for this\n   to work* (check your balance at\n   https://platform.openai.com/account/usage).\n\nOnce you’ve entered your OpenAI key (see above), click on the lightning\nbolt (⚡) beside any line or the explosion (💥) for an entire region of\ncode to generate a proposed optimization. Click on a proposed\noptimization to copy it to the clipboard.\n\nYou can click as many times as you like on the lightning bolt or\nexplosion, and it will generate different suggested optimizations. Your\nmileage may vary, but in some cases, the suggestions are quite\nimpressive (e.g., order-of-magnitude improvements).\n\nQuick Start\n~~~~~~~~~~~\n\nInstalling Scalene:\n^^^^^^^^^^^^^^^^^^^\n\n.. code:: console\n\n   python3 -m pip install -U scalene\n\nor\n\n.. code:: console\n\n   conda install -c conda-forge scalene\n\nUsing Scalene:\n^^^^^^^^^^^^^^\n\nAfter installing Scalene, you can use Scalene at the command line, or as\na Visual Studio Code extension.\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nUsing the Scalene VS Code Extension:\n\n.. raw:: html\n\n   </summary>\n\nFirst, install the Scalene extension from the VS Code Marketplace or by\nsearching for it within VS Code by typing Command-Shift-X (Mac) or\nCtrl-Shift-X (Windows). Once that’s installed, click Command-Shift-P or\nCtrl-Shift-P to open the Command Palette. Then select “Scalene:\nAI-powered profiling…” (you can start typing Scalene and it will pop up\nif it’s installed). Run that and, assuming your code runs for at least a\nsecond, a Scalene profile will appear in a webview.\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nCommonly used command-line options:\n\n.. raw:: html\n\n   </summary>\n\n.. code:: console\n\n   scalene your_prog.py                             # full profile (outputs to web interface)\n   python3 -m scalene your_prog.py                  # equivalent alternative\n\n   scalene --cli your_prog.py                       # use the command-line only (no web interface)\n\n   scalene --cpu your_prog.py                       # only profile CPU\n   scalene --cpu --gpu your_prog.py                 # only profile CPU and GPU\n   scalene --cpu --gpu --memory your_prog.py        # profile everything (same as no options)\n\n   scalene --reduced-profile your_prog.py           # only profile lines with significant usage\n   scalene --profile-interval 5.0 your_prog.py      # output a new profile every five seconds\n\n   scalene (Scalene options) --- your_prog.py (...) # use --- to tell Scalene to ignore options after that point\n   scalene --help                                   # lists all options\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nUsing Scalene programmatically in your code:\n\n.. raw:: html\n\n   </summary>\n\nInvoke using ``scalene`` as above and then:\n\n.. code:: python\n\n   from scalene import scalene_profiler\n\n   # Turn profiling on\n   scalene_profiler.start()\n\n   # your code\n\n   # Turn profiling off\n   scalene_profiler.stop()\n\n.. code:: python\n\n   from scalene.scalene_profiler import enable_profiling\n\n   with enable_profiling():\n       # do something\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nUsing Scalene to profile only specific functions via @profile:\n\n.. raw:: html\n\n   </summary>\n\nJust preface any functions you want to profile with the ``@profile``\ndecorator and run it with Scalene:\n\n.. code:: python\n\n   # do not import profile!\n\n   @profile\n   def slow_function():\n       import time\n       time.sleep(3)\n\n.. raw:: html\n\n   </details>\n\nWeb-based GUI\n^^^^^^^^^^^^^\n\nScalene has both a CLI and a web-based GUI `(demo\nhere) <http://plasma-umass.org/scalene-gui/>`__.\n\nBy default, once Scalene has profiled your program, it will open a tab\nin a web browser with an interactive user interface (all processing is\ndone locally). Hover over bars to see breakdowns of CPU and memory\nconsumption, and click on underlined column headers to sort the columns.\nThe generated file ``profile.html`` is self-contained and can be saved\nfor later use.\n\n|Scalene web GUI|\n\nScalene Overview\n----------------\n\nScalene talk (PyCon US 2021)\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n`This talk <https://youtu.be/5iEf-_7mM1k>`__ presented at PyCon 2021\nwalks through Scalene’s advantages and how to use it to debug the\nperformance of an application (and provides some technical details on\nits internals). We highly recommend watching this video!\n\n|Scalene presentation at PyCon 2021|\n\nFast and Accurate\n~~~~~~~~~~~~~~~~~\n\n-  Scalene is **fast**. It uses sampling instead of instrumentation or\n   relying on Python’s tracing facilities. Its overhead is typically no\n   more than 10-20% (and often less).\n\n-  Scalene is **accurate**. We tested CPU profiler accuracy and found\n   that Scalene is among the most accurate profilers, correctly\n   measuring time taken.\n\n.. figure::\n   https://github.com/plasma-umass/scalene/raw/master/docs/cpu-accuracy-comparison.png\n   :alt: Profiler accuracy\n\n   Profiler accuracy\n\n-  Scalene performs profiling **at the line level** *and* **per\n   function**, pointing to the functions and the specific lines of code\n   responsible for the execution time in your program.\n\nCPU profiling\n~~~~~~~~~~~~~\n\n-  Scalene **separates out time spent in Python from time in native\n   code** (including libraries). Most Python programmers aren’t going to\n   optimize the performance of native code (which is usually either in\n   the Python implementation or external libraries), so this helps\n   developers focus their optimization efforts on the code they can\n   actually improve.\n-  Scalene **highlights hotspots** (code accounting for significant\n   percentages of CPU time or memory allocation) in red, making them\n   even easier to spot.\n-  Scalene also separates out **system time**, making it easy to find\n   I/O bottlenecks.\n\nGPU profiling\n~~~~~~~~~~~~~\n\n-  Scalene reports **GPU time** (currently limited to NVIDIA-based\n   systems).\n\nMemory profiling\n~~~~~~~~~~~~~~~~\n\n-  Scalene **profiles memory usage**. In addition to tracking CPU usage,\n   Scalene also points to the specific lines of code responsible for\n   memory growth. It accomplishes this via an included specialized\n   memory allocator.\n-  Scalene separates out the percentage of **memory consumed by Python\n   code vs. native code**.\n-  Scalene produces **per-line memory profiles**.\n-  Scalene **identifies lines with likely memory leaks**.\n-  Scalene **profiles copying volume**, making it easy to spot\n   inadvertent copying, especially due to crossing Python/library\n   boundaries (e.g., accidentally converting ``numpy`` arrays into\n   Python arrays, and vice versa).\n\nOther features\n~~~~~~~~~~~~~~\n\n-  Scalene can produce **reduced profiles** (via ``--reduced-profile``)\n   that only report lines that consume more than 1% of CPU or perform at\n   least 100 allocations.\n-  Scalene supports ``@profile`` decorators to profile only specific\n   functions.\n-  When Scalene is profiling a program launched in the background (via\n   ``&``), you can **suspend and resume profiling**.\n\nComparison to Other Profilers\n=============================\n\nPerformance and Features\n------------------------\n\nBelow is a table comparing the **performance and features** of various\nprofilers to Scalene.\n\n.. figure::\n   https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/profiler-comparison.png\n   :alt: Performance and feature comparison\n\n   Performance and feature comparison\n\n-  **Slowdown**: the slowdown when running a benchmark from the\n   Pyperformance suite. Green means less than 2x overhead. Scalene’s\n   overhead is just a 35% slowdown.\n\nScalene has all of the following features, many of which only Scalene\nsupports:\n\n-  **Lines or functions**: does the profiler report information only for\n   entire functions, or for every line – Scalene does both.\n-  **Unmodified Code**: works on unmodified code.\n-  **Threads**: supports Python threads.\n-  **Multiprocessing**: supports use of the ``multiprocessing`` library\n   – *Scalene only*\n-  **Python vs. C time**: breaks out time spent in Python vs. native\n   code (e.g., libraries) – *Scalene only*\n-  **System time**: breaks out system time (e.g., sleeping or performing\n   I/O) – *Scalene only*\n-  **Profiles memory**: reports memory consumption per line / function\n-  **GPU**: reports time spent on an NVIDIA GPU (if present) – *Scalene\n   only*\n-  **Memory trends**: reports memory use over time per line / function –\n   *Scalene only*\n-  **Copy volume**: reports megabytes being copied per second – *Scalene\n   only*\n-  **Detects leaks**: automatically pinpoints lines responsible for\n   likely memory leaks – *Scalene only*\n\nOutput\n------\n\nIf you include the ``--cli`` option, Scalene prints annotated source\ncode for the program being profiled (as text, JSON (``--json``), or HTML\n(``--html``)) and any modules it uses in the same directory or\nsubdirectories (you can optionally have it ``--profile-all`` and only\ninclude files with at least a ``--cpu-percent-threshold`` of time). Here\nis a snippet from ``pystone.py``.\n\n.. figure::\n   https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/sample-profile-pystone.png\n   :alt: Example profile\n\n   Example profile\n\n-  **Memory usage at the top**: Visualized by “sparklines”, memory\n   consumption over the runtime of the profiled code.\n-  **“Time Python”**: How much time was spent in Python code.\n-  **“native”**: How much time was spent in non-Python code (e.g.,\n   libraries written in C/C++).\n-  **“system”**: How much time was spent in the system (e.g., I/O).\n-  **“GPU”**: (not shown here) How much time spent on the GPU, if your\n   system has an NVIDIA GPU installed.\n-  **“Memory Python”**: How much of the memory allocation happened on\n   the Python side of the code, as opposed to in non-Python code (e.g.,\n   libraries written in C/C++).\n-  **“net”**: Positive net memory numbers indicate total memory\n   allocation in megabytes; negative net memory numbers indicate memory\n   reclamation.\n-  **“timeline / %”**: Visualized by “sparklines”, memory consumption\n   generated by this line over the program runtime, and the percentages\n   of total memory activity this line represents.\n-  **“Copy (MB/s)”**: The amount of megabytes being copied per second\n   (see “About Scalene”).\n\nScalene\n-------\n\nThe following command runs Scalene on a provided example program.\n\n.. code:: console\n\n   scalene test/testme.py\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nClick to see all Scalene’s options (available by running with –help)\n\n.. raw:: html\n\n   </summary>\n\n.. code:: console\n\n       % scalene --help\n        usage: scalene [-h] [--outfile OUTFILE] [--html] [--reduced-profile]\n                       [--profile-interval PROFILE_INTERVAL] [--cpu-only]\n                       [--profile-all] [--profile-only PROFILE_ONLY]\n                       [--use-virtual-time]\n                       [--cpu-percent-threshold CPU_PERCENT_THRESHOLD]\n                       [--cpu-sampling-rate CPU_SAMPLING_RATE]\n                       [--malloc-threshold MALLOC_THRESHOLD]\n        \n        Scalene: a high-precision CPU and memory profiler.\n        https://github.com/plasma-umass/scalene\n        \n        command-line:\n           % scalene [options] yourprogram.py\n        or\n           % python3 -m scalene [options] yourprogram.py\n        \n        in Jupyter, line mode:\n           %scrun [options] statement\n        \n        in Jupyter, cell mode:\n           %%scalene [options]\n           code...\n           code...\n        \n        optional arguments:\n          -h, --help            show this help message and exit\n          --outfile OUTFILE     file to hold profiler output (default: stdout)\n          --html                output as HTML (default: text)\n          --reduced-profile     generate a reduced profile, with non-zero lines only (default: False)\n          --profile-interval PROFILE_INTERVAL\n                                output profiles every so many seconds (default: inf)\n          --cpu-only            only profile CPU time (default: profile CPU, memory, and copying)\n          --profile-all         profile all executed code, not just the target program (default: only the target program)\n          --profile-only PROFILE_ONLY\n                                profile only code in filenames that contain the given strings, separated by commas (default: no restrictions)\n          --use-virtual-time    measure only CPU time, not time spent in I/O or blocking (default: False)\n          --cpu-percent-threshold CPU_PERCENT_THRESHOLD\n                                only report profiles with at least this percent of CPU time (default: 1%)\n          --cpu-sampling-rate CPU_SAMPLING_RATE\n                                CPU sampling rate (default: every 0.01s)\n          --malloc-threshold MALLOC_THRESHOLD\n                                only report profiles with at least this many allocations (default: 100)\n        \n        When running Scalene in the background, you can suspend/resume profiling\n        for the process ID that Scalene reports. For example:\n        \n           % python3 -m scalene [options] yourprogram.py &\n         Scalene now profiling process 12345\n           to suspend profiling: python3 -m scalene.profile --off --pid 12345\n           to resume profiling:  python3 -m scalene.profile --on  --pid 12345\n\n.. raw:: html\n\n   </details>\n\nScalene with Jupyter\n~~~~~~~~~~~~~~~~~~~~\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nInstructions for installing and using Scalene with Jupyter notebooks\n\n.. raw:: html\n\n   </summary>\n\n`This\nnotebook <https://nbviewer.jupyter.org/github/plasma-umass/scalene/blob/master/docs/scalene-demo.ipynb>`__\nillustrates the use of Scalene in Jupyter.\n\nInstallation:\n\n.. code:: console\n\n   !pip install scalene\n   %load_ext scalene\n\nLine mode:\n\n.. code:: console\n\n   %scrun [options] statement\n\nCell mode:\n\n.. code:: console\n\n   %%scalene [options]\n   code...\n   code...\n\n.. raw:: html\n\n   </details>\n\nInstallation\n------------\n\n.. raw:: html\n\n   <details open>\n\n.. raw:: html\n\n   <summary>\n\nUsing pip (Mac OS X, Linux, Windows, and WSL2)\n\n.. raw:: html\n\n   </summary>\n\nScalene is distributed as a ``pip`` package and works on Mac OS X, Linux\n(including Ubuntu in `Windows\nWSL2 <https://docs.microsoft.com/en-us/windows/wsl/wsl2-index>`__) and\n(with limitations) Windows platforms.\n\n   **Note**\n\n   The Windows version currently only supports CPU and GPU profiling,\n   but not memory or copy profiling.\n\nYou can install it as follows:\n\n.. code:: console\n\n     % pip install -U scalene\n\nor\n\n.. code:: console\n\n     % python3 -m pip install -U scalene\n\nYou may need to install some packages first.\n\nSee https://stackoverflow.com/a/19344978/4954434 for full instructions\nfor all Linux flavors.\n\nFor Ubuntu/Debian:\n\n.. code:: console\n\n     % sudo apt install git python3-all-dev\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nUsing conda (Mac OS X, Linux, Windows, and WSL2)\n\n.. raw:: html\n\n   </summary>\n\n.. code:: console\n\n     % conda install -c conda-forge scalene\n\nScalene is distributed as a ``conda`` package and works on Mac OS X,\nLinux (including Ubuntu in `Windows\nWSL2 <https://docs.microsoft.com/en-us/windows/wsl/wsl2-index>`__) and\n(with limitations) Windows platforms.\n\n   **Note**\n\n   The Windows version currently only supports CPU and GPU profiling,\n   but not memory or copy profiling.\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nOn ArchLinux\n\n.. raw:: html\n\n   </summary>\n\nYou can install Scalene on Arch Linux via the `AUR\npackage <https://aur.archlinux.org/packages/python-scalene-git/>`__. Use\nyour favorite AUR helper, or manually download the ``PKGBUILD`` and run\n``makepkg -cirs`` to build. Note that this will place ``libscalene.so``\nin ``/usr/lib``; modify the below usage instructions accordingly.\n\n.. raw:: html\n\n   </details>\n\nFrequently Asked Questions\n==========================\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nCan I use Scalene with PyTest?\n\n.. raw:: html\n\n   </summary>\n\n**A:** Yes! You can run it as follows (for example):\n\n``python3 -m scalene --- -m pytest your_test.py``\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nIs there any way to get shorter profiles or do more targeted profiling?\n\n.. raw:: html\n\n   </summary>\n\n**A:** Yes! There are several options:\n\n1. Use ``--reduced-profile`` to include only lines and files with\n   memory/CPU/GPU activity.\n2. Use ``--profile-only`` to include only filenames containing specific\n   strings (as in, ``--profile-only foo,bar,baz``).\n3. Decorate functions of interest with ``@profile`` to have Scalene\n   report *only* those functions.\n4. Turn profiling on and off programmatically by importing Scalene\n   profiler (``from scalene import scalene_profiler``) and then turning\n   profiling on and off via ``scalene_profiler.start()`` and\n   ``scalene_profiler.stop()``. By default, Scalene runs with profiling\n   on, so to delay profiling until desired, use the ``--off``\n   command-line option (``python3 -m scalene --off yourprogram.py``).\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nHow do I run Scalene in PyCharm?\n\n.. raw:: html\n\n   </summary>\n\n**A:** In PyCharm, you can run Scalene at the command line by opening\nthe terminal at the bottom of the IDE and running a Scalene command\n(e.g., ``python -m scalene <your program>``). Use the options ``--cli``,\n``--html``, and ``--outfile <your output.html>`` to generate an HTML\nfile that you can then view in the IDE.\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nHow do I use Scalene with Django?\n\n.. raw:: html\n\n   </summary>\n\n**A:** Pass in the ``--noreload`` option (see\nhttps://github.com/plasma-umass/scalene/issues/178).\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nDoes Scalene work with gevent/Greenlets?\n\n.. raw:: html\n\n   </summary>\n\n**A:** Yes! Put the following code in the beginning of your program, or\nmodify the call to ``monkey.patch_all`` as below:\n\n.. code:: python\n\n   from gevent import monkey\n   monkey.patch_all(thread=False)\n\n.. raw:: html\n\n   </details>\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nHow do I use Scalene with PyTorch on the Mac?\n\n.. raw:: html\n\n   </summary>\n\n**A:** Scalene works with PyTorch version 1.5.1 on Mac OS X. There’s a\nbug in newer versions of PyTorch\n(https://github.com/pytorch/pytorch/issues/57185) that interferes with\nScalene (discussion here:\nhttps://github.com/plasma-umass/scalene/issues/110), but only on Macs.\n\n.. raw:: html\n\n   </details>\n\nTechnical Information\n=====================\n\nFor details about how Scalene works, please see the following paper,\nwhich won the Jay Lepreau Best Paper Award at `OSDI\n2023 <https://www.usenix.org/conference/osdi23/presentation/berger>`__:\n`Triangulating Python Performance Issues with\nScalene <https://arxiv.org/pdf/2212.07597>`__. (Note that this paper\ndoes not include information about the AI-driven proposed\noptimizations.)\n\n.. raw:: html\n\n   <details>\n\n.. raw:: html\n\n   <summary>\n\nTo cite Scalene in an academic paper, please use the following:\n\n.. raw:: html\n\n   </summary>\n\n.. code:: latex\n\n   @inproceedings{288540,\n   author = {Emery D. Berger and Sam Stern and Juan Altmayer Pizzorno},\n   title = {Triangulating Python Performance Issues with {S}calene},\n   booktitle = {{17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23)}},\n   year = {2023},\n   isbn = {978-1-939133-34-2},\n   address = {Boston, MA},\n   pages = {51--64},\n   url = {https://www.usenix.org/conference/osdi23/presentation/berger},\n   publisher = {USENIX Association},\n   month = jul\n   }\n\n.. raw:: html\n\n   </details>\n\nSuccess Stories\n===============\n\nIf you use Scalene to successfully debug a performance problem, please\n`add a comment to this\nissue <https://github.com/plasma-umass/scalene/issues/58>`__!\n\nAcknowledgements\n================\n\nLogo created by `Sophia\nBerger <https://www.linkedin.com/in/sophia-berger/>`__.\n\nThis material is based upon work supported by the National Science\nFoundation under Grant No. 1955610. Any opinions, findings, and\nconclusions or recommendations expressed in this material are those of\nthe author(s) and do not necessarily reflect the views of the National\nScience Foundation.\n\n.. |Scalene community Slack| image:: https://github.com/plasma-umass/scalene/raw/master/docs/images/slack-logo.png\n   :target: https://join.slack.com/t/scaleneprofil-jge3234/shared_invite/zt-110vzrdck-xJh5d4gHnp5vKXIjYD3Uwg\n.. |PyPI Latest Release| image:: https://img.shields.io/pypi/v/scalene.svg\n   :target: https://pypi.org/project/scalene/\n.. |Anaconda-Server Badge| image:: https://img.shields.io/conda/v/conda-forge/scalene\n   :target: https://anaconda.org/conda-forge/scalene\n.. |Downloads| image:: https://static.pepy.tech/badge/scalene\n   :target: https://pepy.tech/project/scalene\n.. |Anaconda downloads| image:: https://img.shields.io/conda/d/conda-forge/scalene?logo=conda\n   :target: https://anaconda.org/conda-forge/scalene\n.. |image1| image:: https://static.pepy.tech/badge/scalene/month\n   :target: https://pepy.tech/project/scalene\n.. |Python versions| image:: https://img.shields.io/pypi/pyversions/scalene.svg?style=flat-square\n.. |Visual Studio Code Extension version| image:: https://img.shields.io/visual-studio-marketplace/v/emeryberger.scalene?logo=visualstudiocode\n   :target: https://marketplace.visualstudio.com/items?itemName=EmeryBerger.scalene\n.. |License| image:: https://img.shields.io/github/license/plasma-umass/scalene\n.. |Scalene web GUI| image:: https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/scalene-gui-example.png\n   :target: https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/scalene-gui-example-full.png\n.. |Scalene presentation at PyCon 2021| image:: https://raw.githubusercontent.com/plasma-umass/scalene/master/docs/images/scalene-video-img.png\n   :target: https://youtu.be/5iEf-_7mM1k\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 1.0673828125,
          "content": "[mypy]\nscripts_are_modules = True\nshow_traceback = True\nplugins = pydantic.mypy\n\n# Options to make the checking stricter.\ncheck_untyped_defs = True\ndisallow_any_unimported = True\ndisallow_untyped_defs = True\ndisallow_any_generics = True\nwarn_no_return = True\nno_implicit_optional = True\nwarn_return_any = True\ndisallow_untyped_calls = True\ndisallow_incomplete_defs = True\nwarn_redundant_casts = True\n\n# Display the codes needed for # type: ignore[code] annotations.\nshow_error_codes = True\n\n# It's useful to try this occasionally, and keep it clean; but when\n# someone fixes a type error we don't want to add a burden for them.\nwarn_unused_ignores = True\n\n# We use a lot of third-party libraries we don't have stubs for, as\n# well as a handful of our own modules that we haven't told mypy how\n# to find.  Ignore them.  (For some details, see:\n# `git log -p -S ignore_missing_imports mypy.ini`.)\n#\n# This doesn't get in the way of using the stubs we *do* have.\nignore_missing_imports = True\n\n# Warn of unreachable or redundant code.\nwarn_unreachable = False\n# was True\n\nstrict_optional = True\n\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 2.080078125,
          "content": "[project]\nname = \"scalene\"\ndescription = \"Scalene: A high-resolution, low-overhead CPU, GPU, and memory profiler for Python with AI-powered optimization suggestions\"\nreadme = \"README.md\"\nkeywords = [\"performance\", \"profiler\", \"optimization\", \"CPU\", \"GPU\", \"memory\", \"LLM\"]\nauthors = [\n    {name = \"Emery Berger\", email = \"emery@cs.umass.edu\"},\n    {name = \"Sam Stern\", email = \"jstern@umass.edu\"},\n    {name = \"Juan Altmayer Pizzorno\", email = \"juan@altmayer.com\"},\n]\nrequires-python = \">=3.8,!=3.11.0\"\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Framework :: IPython\",\n    \"Framework :: Jupyter\",\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Science/Research\",\n    \"Topic :: Software Development\",\n    \"Topic :: Software Development :: Debuggers\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Operating System :: POSIX :: Linux\",\n    \"Operating System :: MacOS :: MacOS X\",\n    \"Operating System :: Microsoft :: Windows\"\n]\n# see https://peps.python.org/pep-0508/#environment-markers for conditional syntax\ndependencies = [\n    \"wheel>=0.36.1\",\n    \"rich>=10.7.0\",\n    \"cloudpickle>=2.2.1\",\n    # \"pynvml>=11.0.0,<=11.5\",\n    \"nvidia-ml-py>=12.555.43; platform_system !='Darwin'\",\n    \"Jinja2>=3.0.3\",\n    \"psutil>=5.9.2\",\n    \"numpy>=1.24.0,!=1.27\",\n    \"astunparse>=1.6.3; python_version < '3.9'\",\n    \"pydantic>=2.6\",    \n]\ndynamic = [\"version\"]   # computed by setup.py\n\n[project.urls]\n\"Homepage\" = \"https://github.com/plasma-umass/scalene\"\n\"Repository\" = \"https://github.com/plasma-umass/scalene\"\n\n[project.scripts]\nscalene = \"scalene.__main__:main\"\n\n[build-system]\nbuild-backend = \"setuptools.build_meta\"\nrequires = [\n    \"setuptools>=65.5.0\",\n    \"setuptools_scm>=8\",\n    \"wheel\",\n    \"cython\",\n]\n"
        },
        {
          "name": "pyrightconfig.json",
          "type": "blob",
          "size": 0.1455078125,
          "content": "{\n    \"include\": [\"scalene\"],\n    \"useLibraryCodeForTypes\": true,\n    \"reportInvalidStringEscapeSequence\": false,\n    \"typeCheckingMode\" : \"basic\"\n}\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.037109375,
          "content": "[tool:pytest]\nnorecursedirs = tests/*\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.5166015625,
          "content": "astunparse>=1.6.3; python_version < '3.9'\ncloudpickle==2.2.1\nCython>=0.29.28\ngit+https://github.com/plasma-umass/crdp.git#egg=crdp\nipython>=8.10\nJinja2==3.0.3\nlxml==5.1.0\npackaging>=24\npsutil>=5.9.2\npyperf==2.0.0\nrich>=10.7.0\nsetuptools>=65.5.1\nnvidia-ml-py>=12.555.43; platform_system !='Darwin'\nwheel>=0.43.0\n# Per https://github.com/pypa/setuptools/issues/4483#issuecomment-2236528158\nordered-set>=3.1.1\nmore_itertools>=8.8\njaraco.text>=3.7\nimportlib_resources>=5.10.2\nimportlib_metadata>=6\ntomli>=2.0.1\nplatformdirs >= 2.6.2\n"
        },
        {
          "name": "scalene-image-white.png",
          "type": "blob",
          "size": 89.9951171875,
          "content": null
        },
        {
          "name": "scalene",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.685546875,
          "content": "from setuptools import setup, find_packages\nfrom setuptools.extension import Extension\nfrom os import path, environ\nimport sys\nimport sysconfig\nfrom pathlib import Path\n\n# needed for isolated environment\nsys.path.insert(0, str(Path(__file__).parent.resolve()))\nfrom scalene.scalene_config import scalene_version\nsys.path.pop(0)\n\n\nif sys.platform == 'darwin':\n    import sysconfig\n    mdt = 'MACOSX_DEPLOYMENT_TARGET'\n    target = environ[mdt] if mdt in environ else sysconfig.get_config_var(mdt)\n    # target >= 10.9 is required for gcc/clang to find libstdc++ headers\n    if [int(n) for n in target.split('.')] < [10, 9]:\n        from os import execve\n        newenv = environ.copy()\n        newenv[mdt] = '10.9'\n        execve(sys.executable, [sys.executable] + sys.argv, newenv)\n\n\ndef compiler_archs(compiler: str):\n    \"\"\"Discovers what platforms the given compiler supports; intended for MacOS use\"\"\"\n    import tempfile\n    import subprocess\n\n    print(f\"Compiler: {compiler}\")\n    arch_flags = []\n\n    # see also the architectures tested for in .github/workflows/build-and-upload.yml\n    for arch in ['x86_64', 'arm64', 'arm64e']:\n        with tempfile.TemporaryDirectory() as tmpdir:\n            cpp = Path(tmpdir) / 'test.cxx'; cpp.write_text('int main() {return 0;}\\n')\n            out = Path(tmpdir) / 'a.out'\n            p = subprocess.run([compiler, \"-arch\", arch, str(cpp), \"-o\", str(out)], capture_output=True)\n            if p.returncode == 0:\n                arch_flags += ['-arch', arch]\n\n    print(f\"Discovered {compiler} arch flags: {arch_flags}\")\n    return arch_flags\n\ndef extra_compile_args():\n    \"\"\"Returns extra compiler args for platform.\"\"\"\n    if sys.platform == 'win32':\n        return ['/std:c++14'] # for Visual Studio C++\n\n    return ['-std=c++14']\n\ndef make_command():\n#    return 'nmake' if sys.platform == 'win32' else 'make'  # 'nmake' isn't found on github actions' VM\n    return 'make'\n\ndef dll_suffix():\n    \"\"\"Returns the file suffix (\"extension\") of a DLL\"\"\"\n    if (sys.platform == 'win32'): return '.dll'\n    if (sys.platform == 'darwin'): return '.dylib'\n    return '.so'\n\ndef read_file(name):\n    \"\"\"Returns a file's contents\"\"\"\n    with open(path.join(path.dirname(__file__), name), encoding=\"utf-8\") as f:\n        return f.read()\n\nimport setuptools.command.egg_info\nclass EggInfoCommand(setuptools.command.egg_info.egg_info):\n    \"\"\"Custom command to download vendor libs before creating the egg_info.\"\"\"\n    def run(self):\n        if sys.platform != 'win32':\n            self.spawn([make_command(), 'vendor-deps'])\n        super().run()\n\n# Force building platform-specific wheel to avoid the Windows wheel\n# (which doesn't include libscalene, and thus would be considered \"pure\")\n# being used for other platforms.\ntry:\n    from wheel.bdist_wheel import bdist_wheel\n    class BdistWheelCommand(bdist_wheel):\n        def finalize_options(self):\n            super().finalize_options()\n            self.root_is_pure = False\nexcept (ImportError, ModuleNotFoundError):\n    # Disable wheel if `wheel` not installed.\n    print(\"If this installation does not work, run `pip install setuptools wheel` and try again.\")\n    BdistWheelCommand = None\n\nimport setuptools.command.build_ext\nclass BuildExtCommand(setuptools.command.build_ext.build_ext):\n    \"\"\"Custom command that runs 'make' to generate libscalene, and also does MacOS\n       supported --arch flag discovery.\"\"\"\n\n    def build_extensions(self):\n        arch_flags = []\n        if sys.platform == 'darwin':\n            # The only sure way to tell which compiler build_ext is going to use\n            # seems to be to customize a build_ext and look at its internal flags :(\n            # Also, note that self.plat_name here isn't \"...-universal2\" even if that\n            # is what we're building; that's only in bdist_wheel.plat_name.\n            arch_flags += compiler_archs(self.compiler.compiler_cxx[0])\n            for ext in self.extensions:\n                # While the flags _could_ be different between the programs used for\n                # C and C++ compilation and linking, we have no way to adapt them here,\n                # so it seems best to just use them and let it error out if not recognized.\n                ext.extra_compile_args += arch_flags\n                ext.extra_link_args += arch_flags\n\n        super().build_extensions()\n\n        # No build of DLL for Windows currently.\n        if sys.platform != 'win32':\n            self.build_libscalene(arch_flags)   # XXX should we pass compiler_cxx here?\n\n    def build_libscalene(self, arch_flags):\n        scalene_temp = path.join(self.build_temp, 'scalene')\n        scalene_lib = path.join(self.build_lib, 'scalene')\n        libscalene = 'libscalene' + dll_suffix()\n        self.mkpath(scalene_temp)\n        self.mkpath(scalene_lib)\n        self.spawn([make_command(), 'OUTDIR=' + scalene_temp,\n                   'ARCH=' + ' '.join(arch_flags)])\n        self.copy_file(path.join(scalene_temp, libscalene),\n                       path.join(scalene_lib, libscalene))\n\n    def copy_extensions_to_source(self):\n        # self.inplace is temporarily overridden while running build_extensions,\n        # so inplace copying (for pip install -e, setup.py develop) must be done here.\n\n        super().copy_extensions_to_source()\n\n        if sys.platform != 'win32':\n            scalene_lib = path.join(self.build_lib, 'scalene')\n            inplace_dir = self.get_finalized_command('build_py').get_package_dir('scalene')\n            libscalene = 'libscalene' + dll_suffix()\n            self.copy_file(path.join(scalene_lib, libscalene),\n                           path.join(inplace_dir, libscalene))\n\nget_line_atomic = Extension('scalene.get_line_atomic',\n    include_dirs=['.', 'vendor/Heap-Layers', 'vendor/Heap-Layers/utility'],\n    sources=['src/source/get_line_atomic.cpp'],\n    extra_compile_args=extra_compile_args(),\n    py_limited_api=True, # for binary compatibility\n    language=\"c++\"\n)\n\npywhere = Extension('scalene.pywhere',\n    include_dirs=['.', 'src', 'src/include'],\n    depends = ['src/include/traceconfig.hpp'],\n    sources = ['src/source/pywhere.cpp', 'src/source/traceconfig.cpp'],\n    extra_compile_args=extra_compile_args(),\n    py_limited_api=False,\n    language=\"c++\")\n\n# If we're testing packaging, build using a \".devN\" suffix in the version number,\n# so that we can upload new files (as testpypi/pypi don't allow re-uploading files with\n# the same name as previously uploaded).\n# Numbering scheme: https://www.python.org/dev/peps/pep-0440\ndev_build = ('.dev' + environ['DEV_BUILD']) if 'DEV_BUILD' in environ else ''\n\ndef bdist_wheel_options():\n    if sys.platform == 'darwin':\n        # Build universal wheels on MacOS.\n        # ---\n        # On MacOS >= 11, all builds are compatible within a major MacOS version, so Python \"floors\"\n        # all minor versions to 0, leading to tags like like \"macosx_11_0_universal2\". If you use\n        # the actual (non-0) minor name in the build platform, it isn't recognized.\n        # ---\n        # It would be nice to check whether we're actually building multi-architecture,\n        # but that depends on the platforms supported by the compiler build_ext wants to use,\n        # which is hard to obtain (see BuildExtCommand above).\n        import platform\n        v = platform.mac_ver()[0]\n        major = int(v.split('.')[0])\n        if major >= 11:\n            v = f\"{major}.0\"\n        return {'plat_name': f\"macosx-{v}-universal2\"}\n\n    return {}\n\nsetup(\n    version=scalene_version + dev_build,\n    packages=find_packages(),\n    cmdclass={\n        'bdist_wheel': BdistWheelCommand,\n        'egg_info': EggInfoCommand,\n        'build_ext': BuildExtCommand,\n    },\n    ext_modules=([get_line_atomic, pywhere] if sys.platform != 'win32' else []),\n    include_package_data=True,\n    options={'bdist_wheel': bdist_wheel_options()},\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "vendor",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}