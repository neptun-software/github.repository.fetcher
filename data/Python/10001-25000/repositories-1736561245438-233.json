{
  "metadata": {
    "timestamp": 1736561245438,
    "page": 233,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lss233/chatgpt-mirai-qq-bot",
      "stars": 13583,
      "defaultBranch": "browser-version",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.056640625,
          "content": "config.json\nconfig.json.old\nconfig.cfg\n.chatgpt_cache.json"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1181640625,
          "content": "config.json\nconfig.cfg\n__pycache__/\npython3.11/\n.idea/\ndata/*.json\n.chatgpt_cache.json\nDockerfile.dev\n**/.DS_Store\nvenv/\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.833984375,
          "content": "FROM python:3.10.13-slim-bullseye\n\nENV DEBIAN_FRONTEND=noninteractive\n\nCOPY ./fonts/sarasa-mono-sc-regular.ttf /usr/share/fonts/\n\nRUN apt-get update && \\\n    apt install --no-install-recommends xvfb binutils build-essential qtbase5-dev wkhtmltopdf ffmpeg dbus -yq && \\\n    (strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5 || true) && \\\n    apt-get clean && \\\n    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN export DBUS_SESSION_BUS_ADDRESS=`dbus-daemon --fork --config-file=/usr/share/dbus-1/session.conf --print-address`\n\nRUN mkdir -p /app\nWORKDIR /app\n\nCOPY requirements.txt /app\nRUN pip install --no-cache-dir -r requirements.txt && pip cache purge\n\nRUN apt-get remove --purge -yq binutils\n\nCOPY . /app\n\nCMD [\"/bin/bash\", \"/app/docker/start.sh\"]\n"
        },
        {
          "name": "Dockerfile-cn",
          "type": "blob",
          "size": 0.88671875,
          "content": "FROM python:3.11.2-slim-bullseye\n\nENV DEBIAN_FRONTEND=noninteractive\n\nCOPY ./fonts/sarasa-mono-sc-regular.ttf /usr/share/fonts/\n\nRUN sed -i s@/deb.debian.org/@/mirrors.aliyun.com/@g /etc/apt/sources.list\nRUN cat /etc/apt/sources.list\n\nRUN apt-get update && \\\n    apt install --no-install-recommends xvfb binutils qtbase5-dev wkhtmltopdf ffmpeg -yq && \\\n    (strip --remove-section=.note.ABI-tag /usr/lib/x86_64-linux-gnu/libQt5Core.so.5 || true) && \\\n    apt-get remove --purge -yq binutils && \\\n    apt-get clean && \\\n    apt-get purge -y --auto-remove -o APT::AutoRemove::RecommendsImportant=false && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN mkdir -p /app\nWORKDIR /app\n\nCOPY requirements.txt /app\nRUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn --no-cache-dir -r requirements.txt && pip cache purge\n\nCOPY . /app\n\nCMD [\"/bin/bash\", \"/app/docker/start.sh\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 33.7138671875,
          "content": "                    GNU AFFERO GENERAL PUBLIC LICENSE\n                       Version 3, 19 November 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU Affero General Public License is a free, copyleft license for\nsoftware and other kinds of works, specifically designed to ensure\ncooperation with the community in the case of network server software.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nour General Public Licenses are intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  Developers that use our General Public Licenses protect your rights\nwith two steps: (1) assert copyright on the software, and (2) offer\nyou this License which gives you legal permission to copy, distribute\nand/or modify the software.\n\n  A secondary benefit of defending all users' freedom is that\nimprovements made in alternate versions of the program, if they\nreceive widespread use, become available for other developers to\nincorporate.  Many developers of free software are heartened and\nencouraged by the resulting cooperation.  However, in the case of\nsoftware used on network servers, this result may fail to come about.\nThe GNU General Public License permits making a modified version and\nletting the public access it on a server without ever releasing its\nsource code to the public.\n\n  The GNU Affero General Public License is designed specifically to\nensure that, in such cases, the modified source code becomes available\nto the community.  It requires the operator of a network server to\nprovide the source code of the modified version running there to the\nusers of that server.  Therefore, public use of a modified version, on\na publicly accessible server, gives the public access to the source\ncode of the modified version.\n\n  An older license, called the Affero General Public License and\npublished by Affero, was designed to accomplish similar goals.  This is\na different license, not a version of the Affero GPL, but Affero has\nreleased a new version of the Affero GPL which permits relicensing under\nthis license.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU Affero General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Remote Network Interaction; Use with the GNU General Public License.\n\n  Notwithstanding any other provision of this License, if you modify the\nProgram, your modified version must prominently offer all users\ninteracting with it remotely through a computer network (if your version\nsupports such interaction) an opportunity to receive the Corresponding\nSource of your version by providing access to the Corresponding Source\nfrom a network server at no charge, through some standard or customary\nmeans of facilitating copying of software.  This Corresponding Source\nshall include the Corresponding Source for any work covered by version 3\nof the GNU General Public License that is incorporated pursuant to the\nfollowing paragraph.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the work with which it is combined will remain governed by version\n3 of the GNU General Public License.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU Affero General Public License from time to time.  Such new versions\nwill be similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU Affero General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU Affero General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU Affero General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU Affero General Public License as published\n    by the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU Affero General Public License for more details.\n\n    You should have received a copy of the GNU Affero General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If your software can interact with users remotely through a computer\nnetwork, you should also make sure that it provides a way for users to\nget its source.  For example, if your program is a web application, its\ninterface could display a \"Source\" link that leads users to an archive\nof the code.  There are many ways you could offer source, and different\nsolutions will be better for different programs; see section 13 for the\nspecific requirements.\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU AGPL, see\n<https://www.gnu.org/licenses/>.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.0830078125,
          "content": "![cover](https://user-images.githubusercontent.com/117586514/230783378-34ddb86a-c8d3-47a6-baa5-86e39200b258.png)\n\n------------------------------------\n<p align=\"center\">\n  <h2 align=\"center\">ChatGPT for Bot</h2>\n  <p align=\"center\">\n    一款支持各种主流语言模型的聊天的机器人！\n    <br/>\n    <br/>\n    <a href=\"https://chatgpt-qq.lss233.com/\"><strong>» 查看使用教程 »</strong></a>\n    <br/>\n  </p>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/lss233/chatgpt-mirai-qq-bot/stargazers\"><img src=\"https://img.shields.io/github/stars/lss233/chatgpt-mirai-qq-bot?color=E2CDBC&amp;logo=github&amp;style=for-the-badge\" alt=\"Github stars\"></a>\n  <a href=\"https://github.com/lss233/chatgpt-mirai-qq-bot/actions/workflows/docker-latest.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/lss233/chatgpt-mirai-qq-bot/docker-latest.yml?color=E2CDBC&amp;logo=docker&amp;logoColor=white&amp;style=for-the-badge\" alt=\"Docker build latest\"></a>\n  <a href=\"https://hub.docker.com/r/lss233/chatgpt-mirai-qq-bot/\"><img src=\"https://img.shields.io/docker/pulls/lss233/chatgpt-mirai-qq-bot?color=E2CDBC&amp;logo=docker&amp;logoColor=white&amp;style=for-the-badge\" alt=\"Docker Pulls\"></a>\n  <a href=\"./LICENSE\"><img src=\"https://img.shields.io/github/license/lss233/chatgpt-mirai-qq-bot?&amp;color=E2CDBC&amp;style=for-the-badge\" alt=\"License\"></a>\n</p>\n\n***\n\n* [Discord 一群](https://discord.gg/cc3S2R6RQV)、\n  [QQ 二群](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=S1R4eIlODtyKZsEKfWxb2-nOIHELbeJY&authKey=kAftCAALE8OJgwQnArrD6zPtncCAaY456QgUXT3l2OMJ57NwRXRkhv4KL7DzOLzs&noverify=0&group_code=373254418)、\n  [QQ 三群](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=urlhCH8y7Ro2S-iXt63X4s5eILUny4Iw&authKey=ejiwoNa4Yez6IMLyf2vj%2FeRiC1frdFrNNekbRfaPnSQbcD7bgebo5y5A7rPaRKBq&noverify=0&group_code=533109074)、\n  [QQ 四群](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=Ibiu6EmXof30Fa7MJ5j8nJFwaUGTf5bM&authKey=YKx5a%2BK5qnWkk5VlsxxDfYl0nCrKSekQm%2FoLQVqr%2FcO%2FQY2S6N24XdI23XugBrF0&noverify=0&group_code=799737883)、\n  [QQ 五群](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=lDkVPDAeiz6M-ig9cdS9tqhSH6_topox&authKey=B%2FRPYVUjk3dYPw5D4o6C2TpqeoKTG0nXEiKDCG%2Bh4JYY2RPqDQGt37SGl32j0hHw&noverify=0&group_code=805081636)、\n  [QQ 开发群](http://qm.qq.com/cgi-bin/qm/qr?_wv=1027&k=lisyXibhUj93DgIZptQu3VZ4ka3F5-rW&authKey=PBCzRQX4Zei%2BB6n5Tdyp9p5bqcF0tLBlfGANT4dSSKQIFYR66WwaZSMEDahWo%2FzZ&noverify=0&group_code=701933732)  \n  会发布最新的项目动态、视频教程、问题答疑和交流。 \n  加群之前先看[这里](https://github.com/lss233/chatgpt-mirai-qq-bot/issues)的内容能不能解决你的问题。  \n  如果不能解决，把遇到的问题、**日志**和配置文件准备好后再提问。\n* [调试群](https://jq.qq.com/?_wv=1027&k=TBX8Saq7) 这个群里有很多 ChatGPT QQ 机器人，不解答技术问题。 \n\n| ![猫娘问答](https://img.shields.io/badge/-%E7%8C%AB%E5%A8%98%E9%97%AE%E7%AD%94-E2CDBC?style=for-the-badge)                     | ![生活助手](https://img.shields.io/badge/-生活助手-E2CDBC?style=for-the-badge)                   | ![文字 RPG](https://img.shields.io/badge/-文字RPG-E2CDBC?style=for-the-badge)            |\n|------------------------------|------------------------------|------------------------------|\n| ![image](https://user-images.githubusercontent.com/8984680/230702158-73967aa9-01be-44d6-bbd9-24437e333140.png) | ![image](https://user-images.githubusercontent.com/8984680/230702177-de96f89b-053e-4313-a131-715af969db04.png) | ![image](https://user-images.githubusercontent.com/8984680/230702635-fb1de3bf-acbd-46ca-8d6f-caa47368b4d4.png) |\n\n\n\n\n**⚡ 支持**   \n* [x] 图片发送\n* [x] 关键词触发回复\n* [x] 多账号支持\n* [x] 百度云内容审核\n* [x] 额度限制 \n* [x] 人格设定\n* [x] 支持 Mirai、 go-cqhttp、 Telegram、Discord、微信  \n* [x] 可作为 HTTP 服务端提供 Web API\n* [x] 支持 ChatGPT 网页版\n* [x] 支持 ChatGPT Plus\n* [x] 支持 ChatGPT API\n* [x] 支持 Bing 聊天\n* [x] 支持 Google bard\n* [x] 支持 poe.com 网页版\n* [x] 支持 文心一言 网页版\n* [x] 支持 ChatGLM-6B 本地版\n\n**🤖 多平台兼容**  \n\n我们支持多种聊天平台。  \n\n| 平台       | 群聊回复 | 私聊回复 | 条件触发 | 管理员指令 | 绘图  | 语音回复 |\n|----------|------|------|------|-------|-----|------|\n| Mirai    | 支持   | 支持   | 支持   | 支持    | 支持  | 支持   |\n| OneBot   | 支持   | 支持   | 支持   | 支持    | 支持  | 支持   |\n| Telegram | 支持   | 支持   | 部分支持 | 部分支持  | 支持  | 支持   |\n| Discord  | 支持   | 支持   | 部分支持 | 不支持   | 支持  | 支持   |\n| 企业微信 | 支持   | 支持   | 支持 | 不支持  | 支持  | 支持   |\n| 个人微信 | 支持   | 支持   | 支持 | 不支持  | 支持  | 支持   |\n\n## 🐎 命令\n\n**你可以在 [Wiki](https://github.com/lss233/chatgpt-mirai-qq-bot/wiki/) 了解机器人的内部命令。**  \n\n\n## 🔧 搭建\n\n如果你是手机党，可以看这个纯用手机的部署教程（使用 Linux 服务器）：https://www.bilibili.com/video/av949514538\n\n\n<details>\n    <summary>AidLux: 仅使用旧安卓手机进行部署</summary>\n执行下面这行命令启动自动安装脚本。  \n\n```bash\nbash -c \"$(wget -O- https://gist.githubusercontent.com/B17w153/f77c2726c4eca4e05b488f9af58823a5/raw/4410356eba091d3259c48506fb68112e68db729b/install_bot_aidlux.sh)\"\n```\n[部署教程](https://github.com/lss233/chatgpt-for-bot-docs/tree/main/bu-shu-jiao-cheng/kuai-su-bu-shu-jiao-cheng/linux-yi-jian-bu-shu-jiao-cheng.md)\n  \n\n</details>\n\n\n\n<details>\n    <summary>Linux: 通过快速部署脚本部署 （新人推荐)</summary>\n执行下面这行命令启动自动部署脚本。  \n它会为你安装 Docker、 Docker Compose 和编写配置文件。  \n\n```bash\nbash -c \"$(wget -O- https://gist.githubusercontent.com/lss233/2fdd75be3f0724739368d0dcd9d1367d/raw/62a790da4a391af096074b3355c2c2b7ecab3c28/chatgpt-mirai-installer-gocqhttp.sh)\"\n```\n\n</details>\n\n<details>\n    <summary>Linux: 通过 Docker Compose 部署 （自带 Mirai)</summary>\n我们使用 `docker-compose.yaml` 整合了 [lss233/mirai-http](https://github.com/lss233/mirai-http-docker) 和本项目来实现快速部署。  \n但是在部署过程中仍然需要一些步骤来进行配置。  \n\n你可以在 [Wiki](https://github.com/lss233/chatgpt-mirai-qq-bot/wiki/%E4%BD%BF%E7%94%A8-Docker-Compose-%E9%83%A8%E7%BD%B2%EF%BC%88Mirai---%E6%9C%AC%E9%A1%B9%E7%9B%AE%EF%BC%89) 查看搭建教程。\n\n</details>\n\n<details>\n    <summary>Linux: 通过 Docker 部署 （适合已经有 Mirai 的用户)</summary>\n\n1. 找个合适的位置，写你的 `config.cfg`。\n\n2.  执行以下命令，启动 bot：\n```bash\n# 修改 /path/to/config.cfg 为你 config.cfg 的位置\n# XPRA_PASSWORD=123456 中的 123456 是你的 Xpra 密码，建议修改\ndocker run --name mirai-chatgpt-bot \\\n    -v /path/to/config.cfg:/app/config.cfg \\\n    --network host \\\n    lss233/chatgpt-mirai-qq-bot:browser-version\n```\n\n</details>\n\n<details>\n    <summary>Windows: 快速部署包 (自带 Mirai/go-cqhttp，新人推荐）</summary>\n\n我们为 Windows 用户制作了一个快速启动包，可以在 [Release](https://github.com/lss233/chatgpt-mirai-qq-bot/releases) 中找到。    \n\n文件名为：`quickstart-windows-go-cqhttp-amd64.zip`（推荐） 或者 `quickstart-windows-mirai-amd64.zip`\n\n</details>\n\n<details>\n    <summary>Mac: 快速部署包 (自带 Mirai，新人推荐）</summary>\n\nWindows快速部署包Mac用户也可以使用，@magisk317 已测试通过，功能基本都正常\n不过，需要注意的是，如果需要使用图片模式，由于`wkhtmltoimage.exe`在Mac上无法运行，可以使用`wkhtmltopdf`代替，安装命令：\n```\nbrew install --cask wkhtmltopdf\n```\nbrew的安装及使用方法详见：[链接](https://brew.sh/index_zh-cn)\n</details>\n\n<details>\n    <summary>手动部署</summary>\n\n提示：你需要 Python >= 3.11 才能运行本项目  \n\n1. 部署 Mirai ，安装 mirai-http-api 插件。\n\n2. 下载本项目:\n```bash\ngit clone https://github.com/lss233/chatgpt-mirai-qq-bot\ncd chatgpt-mirai-qq-bot\npip3 install -r requirements.txt\n```\n\n3. 参照项目文档调整配置文件。\n\n\n4. 启动 bot.\n```bash\npython3 bot.py\n```\n</details>\n\n**[广告] 免费 OpenAI API Key**  \n<img src=https://user-images.githubusercontent.com/8984680/232325002-c3e4550e-f642-45fc-b51c-f570386721c3.png width=300px />  \n你可以在[这里获取免费的 OpenAI API Key](https://freeopenai.xyz/) 测试使用。\n## 🕸 HTTP API\n\n<details>\n    <summary>在 `config.cfg` 中加入以下配置后，将额外提供 HTTP API 支持。</summary>\n\n```toml\n[http]\n# 填写提供服务的端口\nhost = \"0.0.0.0\"\nport = 8080\ndebug = false\n```\n启动后将提供以下接口：  \n\n**POST**    `/v1/chat`  \n\n**请求参数**  \n\n|参数名|必选|类型|说明|\n|:---|:---|:---|:---|\n|session_id| 是 | String |会话ID，默认：`friend-default_session`|\n|username| 是 | String |用户名，默认：`某人`|\n|message| 是 | String |消息，不能为空|  \n\n**请求示例**\n```json\n{\n    \"session_id\": \"friend-123456\",\n    \"username\": \"testuser\",\n    \"message\": \"ping\"\n}\n```\n**响应格式**\n|参数名|类型|说明|\n|:---|:---|:---|\n|result| String |SUCESS,DONE,FAILED|\n|message| String[] |文本返回，支持多段返回|\n|voice| String[] |音频返回，支持多个音频的base64编码；参考：data:audio/mpeg;base64,,iVBORw0KGgoAAAANS...|\n|image| String[] |图片返回，支持多个图片的base64编码；参考：data:image/png;base64,UhEUgAAAgAAAAIACAIA...|\n\n**响应示例**  \n```json\n{\n    \"result\": \"DONE\",\n    \"message\": [\"pong!\"],\n    \"voice\": [],\n    \"image\": []\n}\n```\n\n**POST**    `/v2/chat`  \n\n**请求参数**  \n\n|参数名|必选|类型|说明|\n|:---|:---|:---|:---|\n|session_id| 是 | String |会话ID，默认：`friend-default_session`|\n|username| 是 | String |用户名，默认：`某人`|\n|message| 是 | String |消息，不能为空|  \n\n**请求示例**\n```json\n{\n    \"session_id\": \"friend-123456\",\n    \"username\": \"testuser\",\n    \"message\": \"ping\"\n}\n```\n\n* 请注意，`session_id`请采用规范格式。其格式为`friend-`（好友）或`group-`（群组）加字符串\n\n示例\n```\nfriend-R6sxRvblulTZqNC\ngroup-M3jpvxv26mKVM\n```\n\n如果不能正确继续是好友还是群组，将一律按照群组处理\n\n**响应格式**\n字符串：request_id\n\n**响应示例**  \n```\n1681525479905\n```\n\n* 请注意，返回的内容可能会带有引号。请去除引号。（包括 `\"` 和 `'` ）\n\n```\n '1681525479905'\n```\n\n**GET**    `/v2/chat/response`  \n\n**请求参数**  \n\n|参数名|必选|类型|说明|\n|:---|:---|:---|:---|\n|request_id| 是 | String |请求id，/v2/chat返回的值|\n\n**请求示例**\n```\n/v2/chat/response?request_id=1681525479905\n```\n* 请注意，request_id不能带有引号（包括 `\"` 和 `'` ）。\n下列为错误示范\n```\n/v2/chat/response?request_id='1681525479905'\n```\n```\n/v2/chat/response?request_id=\"1681525479905\"\n```\n```\n/v2/chat/response?request_id='1681525479905\"\n```\n```\n/v2/chat/response?request_id=\"1681525479905'\n```\n\n**响应格式**\n|参数名|类型|说明|\n|:---|:---|:---|\n|result| String |SUCESS,DONE,FAILED|\n|message| String[] |文本返回，支持多段返回|\n|voice| String[] |音频返回，支持多个音频的base64编码；参考：data:audio/mpeg;base64,,iVBORw0KGgoAAAANS...|\n|image| String[] |图片返回，支持多个图片的base64编码；参考：data:image/png;base64,UhEUgAAAgAAAAIACAIA...|\n\n* 每次请求返回增量并清空。DONE、FAILED之后没有更多返回。\n\n**响应示例**  \n```json\n{\n    \"result\": \"DONE\",\n    \"message\": [\"pong!\"],\n    \"voice\": [\"data:audio/mpeg;base64,iVBORw0KGgoAAAANS...\"],\n    \"image\": [\"data:image/png;base64,UhEUgAAAgAAAAIACAIA...\", \"data:image/png;base64,UhEUgAAAgAAAAIACAIA...\"]\n}\n```\n* 请注意，当返回 `SUCCESS`的时候表示等待\n```json\n{\"result\": \"SUCCESS\", \"message\": [], \"voice\": [], \"image\": []}\n```\n* 请注意，可能有多条`DONE`，请一直请求，直到出现`FAILED`。`FAILED`表示回复完毕。\n```json\n{\"result\": \"FAILED\", \"message\": [\"\\u6ca1\\u6709\\u66f4\\u591a\\u4e86\\uff01\"], \"voice\": [], \"image\": []}\n```\n* 请注意`DONE`和`FAILED`之间可能会穿插`SUCCESS`。整个回复周期可能会大于一分钟。\n\n</details>\n\n## 🦊 加载预设\n\n如果你想让机器人自动带上某种聊天风格，可以使用预设功能。  \n\n我们自带了 `猫娘` 和 `正常` 两种预设，你可以在 `presets` 文件夹下了解预设的写法。  \n\n使用 `加载预设 猫娘` 来加载猫娘预设。\n\n下面是一些预设的小视频，你可以看看效果：\n* MOSS： https://www.bilibili.com/video/av309604568\n* 丁真：https://www.bilibili.com/video/av267013053\n* 小黑子：https://www.bilibili.com/video/av309604568\n* 高启强：https://www.bilibili.com/video/av779555493\n\n关于预设系统的详细教程：[Wiki](https://github.com/lss233/chatgpt-mirai-qq-bot/wiki/%F0%9F%90%B1-%E9%A2%84%E8%AE%BE%E7%B3%BB%E7%BB%9F)\n\n你可以在 [Awesome ChatGPT QQ Presets](https://github.com/lss233/awesome-chatgpt-qq-presets/tree/master) 获取由大家分享的预设。\n\n你也可以参考 [Awesome-ChatGPT-prompts-ZH_CN](https://github.com/L1Xu4n/Awesome-ChatGPT-prompts-ZH_CN) 来调教你的 ChatGPT，还可以参考 [Awesome ChatGPT Prompts](https://github.com/f/awesome-chatgpt-prompts) 来解锁更多技能。\n\n## 📷 文字转图片\n\n在发送代码或者向 QQ 群发送消息失败时，自动将消息转为图片发送。  \n\n字体文件存放于 `fonts/` 目录中。  \n\n默认使用的字体是 [更纱黑体](https://github.com/be5invis/Sarasa-Gothic)。  \n\n## 🎙 文字转语音\n\n自 v2.2.5 开始，我们支持接入微软的 Azure 引擎 和 VITS 引擎，让你的机器人发送语音。\n\n**提示**：在 Windows 平台上使用语音功能需要安装最新的 VC 运行库，你可以在[这里](https://learn.microsoft.com/zh-CN/cpp/windows/latest-supported-vc-redist?view=msvc-170)下载。`\n\n## 🎈 相似项目\n\n如果你自己也有做机器人的想法，可以看看下面这些项目：\n - [Ariadne](https://github.com/GraiaProject/Ariadne) - 一个优雅且完备的 Python QQ 机器人框架 （主要是这个 ！！！）\n - [mirai-api-http](https://github.com/project-mirai/mirai-api-http) - 提供HTTP API供所有语言使用 mirai QQ 机器人\n - [Reverse Engineered ChatGPT by OpenAI](https://github.com/acheong08/ChatGPT) - 非官方 ChatGPT Python 支持库  \n\n本项目基于以上项目开发，所以你可以给他们也点个 star ！\n\n\n除了我们以外，还有这些很出色的项目：  \n\n* [LlmKira / Openaibot](https://github.com/LlmKira/Openaibot) - 全平台，多模态理解的 OpenAI 机器人\n* [RockChinQ / QChatGPT](https://github.com/RockChinQ/QChatGPT) - 基于 OpenAI 官方 API， 使用 GPT-3 的 QQ 机器人\n* [fuergaosi233 / wechat-chatgpt](https://github.com/fuergaosi233/wechat-chatgpt) - 在微信上迅速接入 ChatGPT\n\n\n## 🛠 贡献者名单   \n\n欢迎提出新的点子、 Pull Request。  \n\n<a href=\"https://github.com/lss233/chatgpt-mirai-qq-bot/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=lss233/chatgpt-mirai-qq-bot\" />\n</a>\n\nMade with [contrib.rocks](https://contrib.rocks).\n\n## 💪 支持我们\n\n如果我们这个项目对你有所帮助，请给我们一颗 ⭐️\n"
        },
        {
          "name": "adapter",
          "type": "tree",
          "content": null
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "bot.py",
          "type": "blob",
          "size": 1.8974609375,
          "content": "import os\nimport sys\nimport creart\nsys.path.append(os.getcwd())\nfrom asyncio import AbstractEventLoop\nimport asyncio\nfrom utils.exithooks import hook\nfrom loguru import logger\nfrom constants import config, botManager\nfrom utils.edge_tts import load_edge_tts_voices\n\nloop = creart.create(AbstractEventLoop)\n\nloop.run_until_complete(botManager.login())\n\nbots = []\n\n# 将log输出到stdout\nlogger.configure(handlers=[{\"sink\": sys.stdout}])\n\nif config.mirai:\n    logger.info(\"检测到 mirai 配置，将启动 mirai 模式……\")\n    from platforms.ariadne_bot import start_task\n\n    bots.append(loop.create_task(start_task()))\n\nif config.onebot:\n    logger.info(\"检测到 Onebot 配置，将启动 Onebot 模式……\")\n    from platforms.onebot_bot import start_task\n\n    bots.append(loop.create_task(start_task()))\nif config.telegram:\n    logger.info(\"检测到 telegram 配置，将启动 telegram bot 模式……\")\n    from platforms.telegram_bot import start_task\n\n    bots.append(loop.create_task(start_task()))\nif config.discord:\n    logger.info(\"检测到 discord 配置，将启动 discord bot 模式……\")\n    from platforms.discord_bot import start_task\n\n    bots.append(loop.create_task(start_task()))\nif config.http:\n    logger.info(\"检测到 http 配置，将启动 http service 模式……\")\n    from platforms.http_service import start_task\n\n    bots.append(loop.create_task(start_task()))\nif config.wecom:\n    logger.info(\"检测到 Wecom 配置，将启动 Wecom Bot 模式……\")\n    from platforms.wecom_bot import start_task\n\n    bots.append(loop.create_task(start_task()))\ntry:\n    logger.info(\"[Edge TTS] 读取 Edge TTS 可用音色列表……\")\n    loop.run_until_complete(load_edge_tts_voices())\n    logger.info(\"[Edge TTS] 读取成功！\")\nexcept Exception as e:\n    logger.exception(e)\n    logger.error(\"[Edge TTS] 读取失败！\")\n\nhook()\nloop.run_until_complete(asyncio.gather(*bots))\nloop.run_forever()\n"
        },
        {
          "name": "chatbot",
          "type": "tree",
          "content": null
        },
        {
          "name": "config.example.cfg",
          "type": "blob",
          "size": 1.3447265625,
          "content": "# 这里是 ChatGPT for QQ 的所有配置文件\n# 请注意：以 \"#\" 开头的文本均为注释\n# 不会被程序读取\n# 如果你想要使用某个设置，请确保前面没有 \"#\" 号\n\n########################\n# 配置文件编写教程：\n# https://chatgpt-qq.lss233.com/\n########################\n\n[mirai]\nqq = 请修改为你机器人的QQ号\nmanager_qq = 请修改为机器人管理员的QQ号（你本人的 QQ 号）\n\n# 此处设置应该与 mirai api http 中的端口号一致\nreverse_ws_port = 8554\n\n[openai]\n[[openai.accounts]]\naccess_token = \"这里填写你的 access_token（其他接入方式请看教程）\"\n# 国内用户可能需要配置代理\n# proxy=\"http://127.0.0.1:7890\"\n\n[gpt4free]\n# 可配置的模型，参考：https://github.com/xtekky/gpt4free#models\n[[gpt4free.accounts]]\n# 参考：https://github.com/xtekky/gpt4free#models，注意Provider需要首字母大写！\nprovider = 'g4f.Provider.GetGpt'\n# 参考：https://github.com/xtekky/gpt4free#models\nmodel = 'gpt-3.5-turbo'\n# 切换AI用的名字，例如： 切换AI g4f-chatgpt\nalias = 'g4f-chatgpt'\n# ping bot时针对此AI的描述\ndescription = 'gpt4free的gpt-3.5-turbo'\n\n[presets]\n# 切换预设的命令： 加载预设 猫娘\ncommand = \"加载预设 (\\\\w+)\"\n\n[presets.keywords]\n# 预设关键词 <-> 实际文件\n\"聊天\" = \"presets/issue402.txt\"\n\"猫娘\" = \"presets/catgirl.txt\"\n"
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 27.8681640625,
          "content": "from __future__ import annotations\n\nimport os\nimport sys\nfrom typing import List, Union, Literal, Dict, Optional\n\nimport toml\nfrom charset_normalizer import from_bytes\nfrom loguru import logger\nfrom pydantic import BaseModel, BaseConfig, Extra\n\n\nclass Onebot(BaseModel):\n    manager_qq: int = 0\n    \"\"\"机器人管理员的 QQ 号\"\"\"\n    reverse_ws_host: str = \"0.0.0.0\"\n    \"\"\"go-cqhttp 的 反向 ws 主机号\"\"\"\n    reverse_ws_port: Optional[int] = 8566\n    \"\"\"go-cqhttp 的 反向 ws 端口号，填写后开启 反向 ws 模式\"\"\"\n\n\nclass Mirai(BaseModel):\n    qq: int\n    \"\"\"Bot 的 QQ 号\"\"\"\n    manager_qq: int = 0\n    \"\"\"机器人管理员的 QQ 号\"\"\"\n    api_key: str = \"1234567890\"\n    \"\"\"mirai-api-http 的 verifyKey\"\"\"\n    http_url: str = \"http://localhost:8080\"\n    \"\"\"mirai-api-http 的 http 适配器地址\"\"\"\n    ws_url: str = \"http://localhost:8080\"\n    \"\"\"mirai-api-http 的 ws 适配器地址\"\"\"\n    reverse_ws_host: str = \"0.0.0.0\"\n    \"\"\"mirai-api-http 的 反向 ws 主机号\"\"\"\n    reverse_ws_port: Optional[int] = None\n    \"\"\"mirai-api-http 的 反向 ws 端口号，填写后开启 反向 ws 模式\"\"\"\n\n\nclass TelegramBot(BaseModel):\n    bot_token: str\n    \"\"\"Bot 大爹给的 token\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n    manager_chat: Optional[int] = None\n    \"\"\"管理员的 chat id\"\"\"\n\n\nclass DiscordBot(BaseModel):\n    bot_token: str\n    \"\"\"Discord Bot 的 token\"\"\"\n\n\nclass HttpService(BaseModel):\n    host: str = \"0.0.0.0\"\n    \"\"\"0.0.0.0则不限制访问地址\"\"\"\n    port: int = 8080\n    \"\"\"Http service port, 默认8080\"\"\"\n    debug: bool = False\n    \"\"\"是否开启debug，错误时展示日志\"\"\"\n\n\nclass WecomBot(BaseModel):\n    host: str = \"0.0.0.0\"\n    \"\"\"企业微信回调地址，需要能够被公网访问，0.0.0.0则不限制访问地址\"\"\"\n    port: int = 5001\n    \"\"\"Http service port, 默认5001\"\"\"\n    debug: bool = False\n    \"\"\"是否开启debug，错误时展示日志\"\"\"\n    corp_id: str\n    \"\"\"企业微信 的 企业 ID\"\"\"\n    agent_id: str\n    \"\"\"企业微信应用 的 AgentId\"\"\"\n    secret: str\n    \"\"\"企业微信应用 的 Secret\"\"\"\n    token: str\n    \"\"\"企业微信应用 API 令牌 的 Token\"\"\"\n    encoding_aes_key: str\n    \"\"\"企业微信应用 API 令牌 的 EncodingAESKey\"\"\"\n\n\nclass OpenAIParams(BaseModel):\n    temperature: float = 0.5\n    max_tokens: int = 4000\n    top_p: float = 1.0\n    presence_penalty: float = 0.0\n    frequency_penalty: float = 0.0\n    min_tokens: int = 1000\n    compressed_session: bool = False\n    compressed_tokens: int = 1000\n    stream: bool = True\n\n\nclass OpenAIAuths(BaseModel):\n    browserless_endpoint: Optional[str] = \"https://chatgpt-proxy.lss233.com/api/\"\n    \"\"\"自定义无浏览器登录模式的接入点\"\"\"\n    api_endpoint: Optional[str] = None\n    \"\"\"自定义 OpenAI API 的接入点\"\"\"\n\n    gpt_params: OpenAIParams = OpenAIParams()\n\n    accounts: List[Union[OpenAIEmailAuth, OpenAISessionTokenAuth, OpenAIAccessTokenAuth, OpenAIAPIKey]] = []\n\n\nclass OpenAIAuthBase(BaseModel):\n    mode: str = \"browserless\"\n    \"\"\"OpenAI 的登录模式，可选的值：browserless - 无浏览器登录 browser - 浏览器登录\"\"\"\n    proxy: Union[str, None] = None\n    \"\"\"可选的代理地址\"\"\"\n    driver_exec_path: Union[str, None] = None\n    \"\"\"可选的 Chromedriver 路径\"\"\"\n    browser_exec_path: Union[str, None] = None\n    \"\"\"可选的 Chrome 浏览器路径\"\"\"\n    conversation: Union[str, None] = None\n    \"\"\"初始化对话所使用的UUID\"\"\"\n    paid: bool = False\n    \"\"\"使用 ChatGPT Plus\"\"\"\n    gpt4: bool = False\n    \"\"\"使用 GPT-4\"\"\"\n    model: Optional[str] = None\n    \"\"\"使用的默认模型，此选项优先级最高\"\"\"\n    verbose: bool = False\n    \"\"\"启用详尽日志模式\"\"\"\n    title_pattern: str = \"\"\n    \"\"\"自动修改标题，为空则不修改\"\"\"\n    auto_remove_old_conversations: bool = False\n    \"\"\"自动删除旧的对话\"\"\"\n\n    class Config(BaseConfig):\n        extra = Extra.allow\n\n\nclass OpenAIEmailAuth(OpenAIAuthBase):\n    email: str\n    \"\"\"OpenAI 注册邮箱\"\"\"\n    password: str\n    \"\"\"OpenAI 密码\"\"\"\n    isMicrosoftLogin: bool = False\n    \"\"\"是否通过 Microsoft 登录\"\"\"\n\n\nclass OpenAISessionTokenAuth(OpenAIAuthBase):\n    session_token: str\n    \"\"\"OpenAI 的 session_token\"\"\"\n\n\nclass OpenAIAccessTokenAuth(OpenAIAuthBase):\n    access_token: str\n    \"\"\"OpenAI 的 access_token\"\"\"\n\n\nclass OpenAIAPIKey(OpenAIAuthBase):\n    api_key: str\n    \"\"\"OpenAI 的 api_key\"\"\"\n\n\nclass PoeCookieAuth(BaseModel):\n    p_b: str\n    \"\"\"登陆 poe.com 后 Cookie 中 p_b 的值\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass BingCookiePath(BaseModel):\n    cookie_content: str\n    \"\"\"Bing 的 Cookie 文件内容\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass BardCookiePath(BaseModel):\n    cookie_content: str\n    \"\"\"Bard 的 Cookie 文件内容\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass PoeAuths(BaseModel):\n    accounts: List[PoeCookieAuth] = []\n    \"\"\"Poe 的账号列表\"\"\"\n\n\nclass TTSAccounts(BaseModel):\n    speech_key: str\n    \"\"\"TTS KEY\"\"\"\n    speech_service_region: str\n    \"\"\"TTS 地区\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass BingAuths(BaseModel):\n    show_suggestions: bool = True\n    \"\"\"在 Bing 的回复后加上猜你想问\"\"\"\n    show_references: bool = True\n    \"\"\"在 Bing 的回复前加上引用资料\"\"\"\n    show_remaining_count: bool = True\n    \"\"\"在 Bing 的回复后加上剩余次数\"\"\"\n\n    use_drawing: bool = False\n    \"\"\"使用 Bing 画图\"\"\"\n\n    wss_link: str = \"wss://sydney.bing.com/sydney/ChatHub\"\n    \"\"\"Bing 的 Websocket 接入点\"\"\"\n    bing_endpoint: str = \"https://edgeservices.bing.com/edgesvc/turing/conversation/create\"\n    \"\"\"Bing 的会话创建接入点\"\"\"\n    accounts: List[BingCookiePath] = []\n    \"\"\"Bing 的账号列表\"\"\"\n    max_messages: int = 30\n    \"\"\"Bing 的最大消息数，仅展示用\"\"\"\n\n\nclass BardAuths(BaseModel):\n    accounts: List[BardCookiePath] = []\n    \"\"\"Bard 的账号列表\"\"\"\n\n\nclass YiyanCookiePath(BaseModel):\n    BDUSS: Optional[str] = None\n    \"\"\"百度 Cookie 中的 BDUSS 字段\"\"\"\n    BAIDUID: Optional[str] = None\n    \"\"\"百度 Cookie 中的 BAIDUID 字段\"\"\"\n    cookie_content: Optional[str] = None\n    \"\"\"百度 Cookie （已弃用）\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass XinghuoCookiePath(BaseModel):\n    ssoSessionId: str\n    \"\"\"星火 Cookie 中的 ssoSessionId 字段\"\"\"\n    fd: Optional[str] = \"\"\n    \"\"\"星火请求中的 fd 字段\"\"\"\n    GtToken: Optional[\n        str] = \"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\"\n    \"\"\"星火请求中的 GtToken 字段\"\"\"\n    sid: Optional[str] = \"\"\n    \"\"\"星火请求中的 sid 字段\"\"\"\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n\nclass YiyanAuths(BaseModel):\n    accounts: List[YiyanCookiePath] = []\n    \"\"\"文心一言的账号列表\"\"\"\n\n\nclass XinghuoAuths(BaseModel):\n    accounts: List[XinghuoCookiePath] = []\n    \"\"\"讯飞星火大模型的账号列表\"\"\"\n\n\nclass ChatGLMAPI(BaseModel):\n    api_endpoint: str\n    \"\"\"自定义 ChatGLM API 的接入点\"\"\"\n    max_turns: int = 10\n    \"\"\"最大对话轮数\"\"\"\n    timeout: int = 120\n    \"\"\"请求超时时间（单位：秒）\"\"\"\n\n\nclass ChatGLMAuths(BaseModel):\n    accounts: List[ChatGLMAPI] = []\n    \"\"\"ChatGLM的账号列表\"\"\"\n\n\nclass G4fModels(BaseModel):\n    provider: str\n    \"\"\"ai提供方\"\"\"\n    model: str\n    \"\"\"ai模型\"\"\"\n    alias: str\n    \"\"\"模型缩写\"\"\"\n    description: str\n    \"\"\"介绍\"\"\"\n\n\nclass G4fAuths(BaseModel):\n    accounts: List[G4fModels] = []\n    \"\"\"支持的模型\"\"\"\n\n\nclass SlackAppAccessToken(BaseModel):\n    channel_id: str\n    \"\"\"负责与机器人交互的 Channel ID\"\"\"\n\n    access_token: str\n    \"\"\"安装 Slack App 时获得的 access_token\"\"\"\n\n    proxy: Optional[str] = None\n    \"\"\"可选的代理地址，留空则检测系统代理\"\"\"\n\n    app_endpoint: str = \"https://chatgpt-proxy.lss233.com/claude-in-slack/backend-api/\"\n    \"\"\"API 的接入点\"\"\"\n\n\nclass SlackAuths(BaseModel):\n    accounts: List[SlackAppAccessToken] = []\n    \"\"\"Slack App 账号信息\"\"\"\n\n\nclass TextToImage(BaseModel):\n    always: bool = False\n    \"\"\"强制开启，设置后所有的会话强制以图片发送\"\"\"\n    default: bool = False\n    \"\"\"默认开启，设置后新会话默认以图片模式发送\"\"\"\n    font_size: int = 30\n    \"\"\"字号\"\"\"\n    width: int = 1000\n    \"\"\"生成图片宽度\"\"\"\n    font_path: str = \"fonts/sarasa-mono-sc-regular.ttf\"\n    \"\"\"字体路径\"\"\"\n    offset_x: int = 50\n    \"\"\"横坐标\"\"\"\n    offset_y: int = 50\n    \"\"\"纵坐标\"\"\"\n    wkhtmltoimage: Union[str, None] = None\n\n\nclass TextToSpeech(BaseModel):\n    always: bool = False\n    \"\"\"设置后所有的会话都会转语音再发一次\"\"\"\n    engine: str = \"azure\"\n    \"\"\"文字转语音引擎选择，当前有azure和vits\"\"\"\n    default: str = \"zh-CN-XiaoxiaoNeural\"\n    \"\"\"默认设置为Azure语音音色\"\"\"\n    default_voice_prefix: List[str] = [\"zh-CN\", \"zh-TW\"]\n    \"\"\"默认的提示音色前缀\"\"\"\n\n\nclass AzureConfig(BaseModel):\n    tts_speech_key: Optional[str] = None\n    \"\"\"TTS KEY\"\"\"\n    tts_speech_service_region: Optional[str] = None\n    \"\"\"TTS 地区\"\"\"\n\n\nclass VitsConfig(BaseModel):\n    api_url: str = \"\"\n    \"\"\"VITS API 地址，目前仅支持基于MoeGoe的API\"\"\"\n    lang: str = \"zh\"\n    \"\"\"VITS_API目标语言\"\"\"\n    speed: float = 1.4\n    \"\"\"VITS语言语速\"\"\"\n    timeout: int = 30\n    \"\"\"语音生成超时时间\"\"\"\n\n\nclass Trigger(BaseModel):\n    prefix: List[str] = [\"\"]\n    \"\"\"全局的触发响应前缀，同时适用于私聊和群聊，默认不需要\"\"\"\n    prefix_friend: List[str] = []\n    \"\"\"私聊中的触发响应前缀，默认不需要\"\"\"\n    prefix_group: List[str] = []\n    \"\"\"群聊中的触发响应前缀，默认不需要\"\"\"\n\n    prefix_ai: Dict[str, List[str]] = {}\n    \"\"\"特定类型 AI 的前缀，以此前缀开头将直接发消息至指定 AI 会话\"\"\"\n\n    require_mention: Literal[\"at\", \"mention\", \"none\"] = \"at\"\n    \"\"\"群内 [需要 @ 机器人 / 需要 @ 或以机器人名称开头 / 不需要 @] 才响应（请注意需要先 @ 机器人后接前缀）\"\"\"\n    reset_command: List[str] = [\"重置会话\"]\n    \"\"\"重置会话的命令\"\"\"\n    rollback_command: List[str] = [\"回滚会话\"]\n    \"\"\"回滚会话的命令\"\"\"\n    prefix_image: List[str] = [\"画\", \"看\"]\n    \"\"\"图片创建前缀\"\"\"\n    switch_model: str = r\"切换模型 (.+)\"\n    \"\"\"切换当前上下文的模型\"\"\"\n    switch_command: str = r\"切换AI (.+)\"\n    \"\"\"切换AI的命令\"\"\"\n    switch_voice: str = r\"切换语音 (.+)\"\n    \"\"\"切换tts语音音色的命令\"\"\"\n    mixed_only_command: List[str] = [\"图文混合模式\"]\n    \"\"\"切换至图文混合模式\"\"\"\n    image_only_command: List[str] = [\"图片模式\"]\n    \"\"\"切换至图片回复模式\"\"\"\n    text_only_command: List[str] = [\"文本模式\"]\n    \"\"\"切换至文本回复模式\"\"\"\n    ignore_regex: List[str] = []\n    \"\"\"忽略满足条件的正则表达式\"\"\"\n    allowed_models: List[str] = [\n        \"gpt-3.5-turbo\",\n        \"gpt-3.5-turbo-0301\",\n        \"text-davinci-002-render-sha\",\n        \"text-davinci-002-render-paid\"\n    ]\n    \"\"\"允许普通用户切换的模型列表\"\"\"\n    allow_switching_ai: bool = True\n    \"\"\"允许普通用户切换AI\"\"\"\n    ping_command: List[str] = [\"ping\"]\n    \"\"\"获取服务状态\"\"\"\n\n\nclass Response(BaseModel):\n    mode: str = \"mixed\"\n    \"\"\"响应模式，支持：mixed - 图文混合, for.ce-text  - 仅文字, force-image - 仅图片\"\"\"\n\n    buffer_delay: float = 15\n    \"\"\"设置响应缓存时长（秒），机器人会提前返回部分文本\"\"\"\n\n    default_ai: Union[str, None] = None\n    \"\"\"默认使用的 AI 类型，不填写时自动推测\"\"\"\n\n    error_format: str = \"出现故障！如果这个问题持续出现，请和我说“重置会话” 来开启一段新的会话，或者发送 “回滚对话” 来回溯到上一条对话，你上一条说的我就当作没看见。\\n原因：{exc}\"\n    \"\"\"发生错误时发送的消息，请注意可以插入 {exc} 作为异常占位符\"\"\"\n\n    error_network_failure: str = \"网络故障！连接服务器失败，我需要更好的网络才能服务！\\n{exc}\"\n    \"\"\"发生网络错误时发送的消息，请注意可以插入 {exc} 作为异常占位符\"\"\"\n\n    error_session_authenciate_failed: str = \"身份验证失败！无法登录至 ChatGPT 服务器，请检查账号信息是否正确！\\n{exc}\"\n    \"\"\"发生网络错误时发送的消息，请注意可以插入 {exc} 作为异常占位符\"\"\"\n\n    error_request_too_many: str = \"糟糕！当前 ChatGPT 接入点收到的请求太多了，我需要一段时间冷静冷静。请过一会儿再来找我！\\n预计恢复时间：{exc}(Code: 429)\\n\"\n\n    error_request_concurrent_error: str = \"当前有其他人正在和我进行聊天，请稍后再给我发消息吧！\"\n\n    error_server_overloaded: str = \"抱歉，当前服务器压力有点大，请稍后再找我吧！\"\n    \"\"\"服务器提示 429 错误时的回复 \"\"\"\n\n    error_drawing: str = \"画图失败！原因： {exc}\"\n\n    placeholder: str = (\n        \"您好！我是 Assistant，一个由 OpenAI 训练的大型语言模型。我不是真正的人，而是一个计算机程序，可以通过文本聊天来帮助您解决问题。如果您有任何问题，请随时告诉我，我将尽力回答。\\n\"\n        \"如果您需要重置我们的会话，请回复`重置会话`。\"\n    )\n    \"\"\"对空消息回复的占位符\"\"\"\n\n    reset = \"会话已重置。\"\n    \"\"\"重置会话时发送的消息\"\"\"\n\n    rollback_success = \"已回滚至上一条对话，你刚刚发的我就忘记啦！\"\n    \"\"\"成功回滚时发送的消息\"\"\"\n\n    rollback_fail = \"回滚失败，没有更早的记录了！如果你想要重新开始，请发送：{reset}\"\n    \"\"\"回滚失败时发送的消息\"\"\"\n\n    quote: bool = True\n    \"\"\"是否回复触发的那条消息\"\"\"\n\n    timeout: float = 30.0\n    \"\"\"发送提醒前允许的响应时间\"\"\"\n\n    timeout_format: str = \"我还在思考中，请再等一下~\"\n    \"\"\"响应时间过长时要发送的提醒\"\"\"\n\n    max_timeout: float = 600.0\n    \"\"\"最长等待时间，超过此时间取消回应\"\"\"\n\n    cancel_wait_too_long: str = \"啊哦，这个问题有点难，让我想了好久也没想明白。试试换个问法？\"\n    \"\"\"发送提醒前允许的响应时间\"\"\"\n\n    max_queue_size: int = 10\n    \"\"\"等待处理的消息的最大数量，如果要关闭此功能，设置为 0\"\"\"\n\n    queue_full: str = \"抱歉！我现在要回复的人有点多，暂时没有办法接收新的消息了，请过会儿再给我发吧！\"\n    \"\"\"队列满时的提示\"\"\"\n\n    queued_notice_size: int = 3\n    \"\"\"新消息加入队列会发送通知的长度最小值\"\"\"\n\n    queued_notice: str = \"消息已收到！当前我还有{queue_size}条消息要回复，请您稍等。\"\n    \"\"\"新消息进入队列时，发送的通知。 queue_size 是当前排队的消息数\"\"\"\n\n    ping_response: str = \"当前AI：{current_ai} / 当前语音：{current_voice}\\n指令：\\n切换AI XXX / 切换语音 XXX\" \\\n                         \"\\n\\n可用AI：\\n{supported_ai}\"\n    \"\"\"ping返回内容\"\"\"\n    ping_tts_response: str = \"\\n可用语音：\\n{supported_tts}\"\n    \"\"\"ping tts 返回\"\"\"\n\n\nclass System(BaseModel):\n    accept_group_invite: bool = False\n    \"\"\"自动接收邀请入群请求\"\"\"\n\n    accept_friend_request: bool = False\n    \"\"\"自动接收好友请求\"\"\"\n\n    auto_reset_timeout_seconds: int = 8 * 3600\n    \"\"\"会话闲置多长时间后会重置， -1 不重置\"\"\"\n\n\nclass BaiduCloud(BaseModel):\n    check: bool = False\n    \"\"\"是否启动百度云内容安全审核\"\"\"\n    baidu_api_key: str = \"\"\n    \"\"\"百度云API_KEY 24位英文数字字符串\"\"\"\n    baidu_secret_key: str = \"\"\n    \"\"\"百度云SECRET_KEY 32位的英文数字字符串\"\"\"\n    prompt_message: str = \"[百度云]请珍惜机器人，当前返回内容不合规\"\n    \"\"\"不合规消息自定义返回\"\"\"\n\n\nclass Preset(BaseModel):\n    command: str = r\"加载预设 (\\w+)\"\n    keywords: dict[str, str] = {}\n    loaded_successful: str = \"预设加载成功！\"\n    scan_dir: str = \"./presets\"\n    hide: bool = False\n    \"\"\"是否禁止使用其他人 .预设列表 命令来查看预设\"\"\"\n\n\nclass Ratelimit(BaseModel):\n    warning_rate: float = 0.8\n    \"\"\"额度使用达到此比例时进行警告\"\"\"\n\n    warning_msg: str = \"\\n\\n警告：额度即将耗尽！\\n目前已发送：{usage}条消息，最大限制为{limit}条消息/小时，请调整您的节奏。\\n额度限制整点重置，当前服务器时间：{current_time}\"\n    \"\"\"警告消息\"\"\"\n\n    exceed: str = \"已达到额度限制，请等待下一小时继续和我对话。\"\n    \"\"\"超额消息\"\"\"\n\n    draw_warning_msg: str = \"\\n\\n警告：额度即将耗尽！\\n目前已画：{usage}个图，最大限制为{limit}个图/小时，请调整您的节奏。\\n额度限制整点重置，当前服务器时间：{current_time}\"\n    \"\"\"警告消息\"\"\"\n\n    draw_exceed: str = \"已达到额度限制，请等待下一小时再使用画图功能。\"\n    \"\"\"超额消息\"\"\"\n\n\nclass SDWebUI(BaseModel):\n    class ScriptArg(BaseModel):\n        ad_model: str\n\n    class ScriptConfig(BaseModel):\n        args: List['SDWebUI.ScriptArg']\n    \n    api_url: str\n    \"\"\"API 基地址，如：http://127.0.0.1:7890\"\"\"\n    prompt_prefix: str = 'masterpiece, best quality, illustration, extremely detailed 8K wallpaper'\n    \"\"\"内置提示词，所有的画图内容都会加上这些提示词\"\"\"\n    negative_prompt: str = 'NG_DeepNegative_V1_75T, badhandv4, EasyNegative, bad hands, missing fingers, cropped legs, worst quality, low quality, normal quality, jpeg artifacts, blurry,missing arms, long neck, Humpbacked,multiple breasts, mutated hands and fingers, long body, mutation, poorly drawn , bad anatomy,bad shadow,unnatural body, fused breasts, bad breasts, more than one person,wings on halo,small wings, 2girls, lowres, bad anatomy, text, error, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, out of frame, lowres, text, error, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, nsfw, nake, nude, blood'\n    \"\"\"负面提示词\"\"\"\n    sampler_index: str = 'DPM++ SDE Karras'\n    filter_nsfw: bool = True\n    denoising_strength: float = 0.45\n    steps: int = 25\n    enable_hr: bool = False\n    seed: int = -1\n    batch_size: int = 1\n    n_iter: int = 1\n    cfg_scale: float = 7.5\n    restore_faces: bool = False\n    authorization: str = ''\n    alwayson_scripts: Dict[str, 'SDWebUI.ScriptConfig'] = {}\n    \"\"\"登录api的账号:密码\"\"\"\n\n    timeout: float = 10.0\n    \"\"\"超时时间\"\"\"\n\n    class Config(BaseConfig):\n        extra = Extra.allow\nSDWebUI.update_forward_refs()\nSDWebUI.ScriptConfig.update_forward_refs()\n\n\nclass Config(BaseModel):\n    # === Platform Settings ===\n    onebot: Optional[Onebot] = None\n    mirai: Optional[Mirai] = None\n    telegram: Optional[TelegramBot] = None\n    discord: Optional[DiscordBot] = None\n    http: Optional[HttpService] = None\n    wecom: Optional[WecomBot] = None\n\n    # === Account Settings ===\n    openai: OpenAIAuths = OpenAIAuths()\n    bing: BingAuths = BingAuths()\n    bard: BardAuths = BardAuths()\n    azure: AzureConfig = AzureConfig()\n    yiyan: YiyanAuths = YiyanAuths()\n    chatglm: ChatGLMAuths = ChatGLMAuths()\n    poe: PoeAuths = PoeAuths()\n    slack: SlackAuths = SlackAuths()\n    xinghuo: XinghuoAuths = XinghuoAuths()\n    gpt4free: G4fAuths = G4fAuths()\n\n    # === Response Settings ===\n    text_to_image: TextToImage = TextToImage()\n    text_to_speech: TextToSpeech = TextToSpeech()\n    trigger: Trigger = Trigger()\n    response: Response = Response()\n    system: System = System()\n    presets: Preset = Preset()\n    ratelimit: Ratelimit = Ratelimit()\n    baiducloud: BaiduCloud = BaiduCloud()\n    vits: VitsConfig = VitsConfig()\n\n    # === External Utilities ===\n    sdwebui: Optional[SDWebUI] = None\n\n    def scan_presets(self):\n        for keyword, path in self.presets.keywords.items():\n            if os.path.isfile(path):\n                logger.success(f\"检查预设：{keyword} <==> {path} [成功]\")\n            else:\n                logger.error(f\"检查预设：{keyword} <==> {path} [失败：文件不存在]\")\n        for root, _, files in os.walk(self.presets.scan_dir, topdown=False):\n            for name in files:\n                if not name.endswith(\".txt\"):\n                    continue\n                path = os.path.join(root, name)\n                name = name.removesuffix('.txt')\n                if name in self.presets.keywords:\n                    logger.error(f\"注册预设：{name} <==> {path} [失败：关键词已存在]\")\n                    continue\n                self.presets.keywords[name] = path\n                logger.success(f\"注册预设：{name} <==> {path} [成功]\")\n\n    def load_preset(self, keyword):\n        try:\n            with open(self.presets.keywords[keyword], \"rb\") as f:\n                if guessed_str := from_bytes(f.read()).best():\n                    return str(guessed_str).replace('<|im_end|>', '').replace('\\r', '').split('\\n\\n')\n                else:\n                    raise ValueError(\"无法识别预设的 JSON 格式，请检查编码！\")\n\n        except KeyError as e:\n            raise ValueError(\"预设不存在！\") from e\n        except FileNotFoundError as e:\n            raise ValueError(\"预设文件不存在！\") from e\n        except Exception as e:\n            logger.exception(e)\n            logger.error(\"配置文件有误，请重新修改！\")\n\n    OpenAIAuths.update_forward_refs()\n\n    @staticmethod\n    def __load_json_config() -> Config:\n        try:\n            import json\n            with open(\"config.json\", \"rb\") as f:\n                if guessed_str := from_bytes(f.read()).best():\n                    return Config.parse_obj(json.loads(str(guessed_str)))\n                else:\n                    raise ValueError(\"无法识别 JSON 格式！\")\n        except Exception as e:\n            logger.exception(e)\n            logger.error(\"配置文件有误，请重新修改！\")\n            exit(-1)\n\n    @staticmethod\n    def load_config() -> Config:\n        if env_config := os.environ.get('CHATGPT_FOR_BOT_FULL_CONFIG', ''):\n            return Config.parse_obj(toml.loads(env_config))\n        try:\n            if (\n                    not os.path.exists('config.cfg')\n                    or os.path.getsize('config.cfg') <= 0\n            ) and os.path.exists('config.json'):\n                logger.info(\"正在转换旧版配置文件……\")\n                Config.save_config(Config.__load_json_config())\n                logger.warning(\"提示：配置文件已经修改为 config.cfg，原来的 config.json 将被重命名为 config.json.old。\")\n                try:\n                    os.rename('config.json', 'config.json.old')\n                except Exception as e:\n                    logger.error(e)\n                    logger.error(\"无法重命名配置文件，请自行处理。\")\n            with open(\"config.cfg\", \"rb\") as f:\n                if guessed_str := from_bytes(f.read()).best():\n                    return Config.parse_obj(toml.loads(str(guessed_str)))\n                else:\n                    raise ValueError(\"无法识别配置文件，请检查是否输入有误！\")\n        except Exception as e:\n            logger.exception(e)\n            logger.error(\"配置文件有误，请重新修改！\")\n            exit(-1)\n\n    @staticmethod\n    def save_config(config: Config):\n        try:\n            with open(\"config.cfg\", \"wb\") as f:\n                parsed_str = toml.dumps(config.dict()).encode(sys.getdefaultencoding())\n                f.write(parsed_str)\n        except Exception as e:\n            logger.exception(e)\n            logger.warning(\"配置保存失败。\")\n"
        },
        {
          "name": "constants.py",
          "type": "blob",
          "size": 0.9228515625,
          "content": "from enum import Enum\n\nfrom config import Config\nfrom manager.bot import BotManager\n\nconfig = Config.load_config()\nconfig.scan_presets()\n\nbotManager = BotManager(config)\n\n\nclass LlmName(Enum):\n    SlackClaude = \"slack-claude\"\n    PoeSage = \"poe-sage\"\n    PoeGPT4 = \"poe-gpt4\"\n    PoeGPT432k = \"poe-gpt432k\"\n    PoeClaude2 = \"poe-claude2\"\n    PoeClaude = \"poe-claude\"\n    PoeClaude100k = \"poe-claude100k\"\n    PoeChatGPT = \"poe-chatgpt\"\n    PoeChatGPT16k = \"poe-chatgpt16k\"\n    PoeLlama2 = \"poe-llama2\"\n    PoePaLM = \"poe-palm\"\n    ChatGPT_Web = \"chatgpt-web\"\n    ChatGPT_Api = \"chatgpt-api\"\n    Bing = \"bing\"\n    BingC = \"bing-c\"\n    BingB = \"bing-b\"\n    BingP = \"bing-p\"\n    Bard = \"bard\"\n    YiYan = \"yiyan\"\n    ChatGLM = \"chatglm-api\"\n    XunfeiXinghuo = \"xinghuo\"\n\n\nclass BotPlatform(Enum):\n    AriadneBot = \"mirai\"\n    DiscordBot = \"discord\"\n    Onebot = \"onebot\"\n    TelegramBot = \"telegram\"\n    HttpService = \"http\"\n    WecomBot = \"wecom\"\n"
        },
        {
          "name": "conversation.py",
          "type": "blob",
          "size": 12.2802734375,
          "content": "import contextlib\nimport time\nfrom datetime import datetime\nfrom typing import List, Dict, Optional\n\nimport httpx\nfrom EdgeGPT.EdgeGPT import ConversationStyle\nfrom graia.amnesia.message import MessageChain\nfrom graia.ariadne.message.element import Image as GraiaImage, Element\nfrom loguru import logger\n\nfrom adapter.baidu.yiyan import YiyanAdapter\nfrom adapter.botservice import BotAdapter\nfrom adapter.chatgpt.api import ChatGPTAPIAdapter\nfrom adapter.chatgpt.web import ChatGPTWebAdapter\nfrom adapter.claude.slack import ClaudeInSlackAdapter\nfrom adapter.google.bard import BardAdapter\nfrom adapter.gpt4free.g4f_helper import parse as g4f_parse\nfrom adapter.gpt4free.gpt4free import Gpt4FreeAdapter\nfrom adapter.ms.bing import BingAdapter\nfrom adapter.quora.poe import PoeBot, PoeAdapter\nfrom adapter.thudm.chatglm_6b import ChatGLM6BAdapter\nfrom adapter.xunfei.xinghuo import XinghuoAdapter\nfrom constants import LlmName\nfrom constants import config\nfrom drawing import DrawingAPI, SDWebUI as SDDrawing, OpenAI as OpenAIDrawing\nfrom exceptions import PresetNotFoundException, BotTypeNotFoundException, NoAvailableBotException, \\\n    CommandRefusedException, DrawingFailedException\nfrom middlewares.draw_ratelimit import MiddlewareRatelimit\nfrom renderer import Renderer\nfrom renderer.merger import BufferedContentMerger, LengthContentMerger\nfrom renderer.renderer import MixedContentMessageChainRenderer, MarkdownImageRenderer, PlainTextRenderer\nfrom renderer.splitter import MultipleSegmentSplitter\nfrom utils import retry\nfrom utils.text_to_speech import TtsVoice, TtsVoiceManager\n\nhandlers = {}\n\nmiddlewares = MiddlewareRatelimit()\n\n\nclass ConversationContext:\n    type: str\n    adapter: BotAdapter\n    \"\"\"聊天机器人适配器\"\"\"\n\n    splitter: Renderer\n    \"\"\"消息分隔器\"\"\"\n    merger: Renderer\n    \"\"\"消息合并器\"\"\"\n    renderer: Renderer\n    \"\"\"消息渲染器\"\"\"\n\n    drawing_adapter: DrawingAPI = None\n    \"\"\"绘图引擎\"\"\"\n\n    preset: str = None\n\n    preset_decoration_format: Optional[str] = \"{prompt}\"\n    \"\"\"预设装饰文本\"\"\"\n\n    conversation_voice: TtsVoice = None\n    \"\"\"语音音色\"\"\"\n\n    @property\n    def current_model(self):\n        return self.adapter.current_model\n\n    @property\n    def supported_models(self):\n        return self.adapter.supported_models\n\n    def __init__(self, _type: str, session_id: str):\n        self.session_id = session_id\n\n        self.last_resp = ''\n\n        self.last_resp_time = -1\n\n        self.switch_renderer()\n\n        if config.text_to_speech.always:\n            tts_engine = config.text_to_speech.engine\n            tts_voice = config.text_to_speech.default\n            try:\n                self.conversation_voice = TtsVoiceManager.parse_tts_voice(tts_engine, tts_voice)\n            except KeyError as e:\n                logger.error(f\"Failed to load {tts_engine} tts voice setting -> {tts_voice}\")\n        if _type == LlmName.ChatGPT_Web.value:\n            self.adapter = ChatGPTWebAdapter(self.session_id)\n        elif _type == LlmName.ChatGPT_Api.value:\n            self.adapter = ChatGPTAPIAdapter(self.session_id)\n        elif PoeBot.parse(_type):\n            self.adapter = PoeAdapter(self.session_id, PoeBot.parse(_type))\n        elif _type == LlmName.Bing.value:\n            self.adapter = BingAdapter(self.session_id)\n        elif _type == LlmName.BingC.value:\n            self.adapter = BingAdapter(self.session_id, ConversationStyle.creative)\n        elif _type == LlmName.BingB.value:\n            self.adapter = BingAdapter(self.session_id, ConversationStyle.balanced)\n        elif _type == LlmName.BingP.value:\n            self.adapter = BingAdapter(self.session_id, ConversationStyle.precise)\n        elif _type == LlmName.Bard.value:\n            self.adapter = BardAdapter(self.session_id)\n        elif _type == LlmName.YiYan.value:\n            self.adapter = YiyanAdapter(self.session_id)\n        elif _type == LlmName.ChatGLM.value:\n            self.adapter = ChatGLM6BAdapter(self.session_id)\n        elif _type == LlmName.SlackClaude.value:\n            self.adapter = ClaudeInSlackAdapter(self.session_id)\n        elif _type == LlmName.XunfeiXinghuo.value:\n            self.adapter = XinghuoAdapter(self.session_id)\n        elif g4f_parse(_type):\n            self.adapter = Gpt4FreeAdapter(self.session_id, g4f_parse(_type))\n        else:\n            raise BotTypeNotFoundException(_type)\n        self.type = _type\n\n        # 没有就算了\n        if config.sdwebui:\n            self.drawing_adapter = SDDrawing()\n        elif config.bing.use_drawing:\n            with contextlib.suppress(NoAvailableBotException):\n                self.drawing_adapter = BingAdapter(self.session_id, ConversationStyle.creative)\n        else:\n            with contextlib.suppress(NoAvailableBotException):\n                self.drawing_adapter = OpenAIDrawing(self.session_id)\n\n    def switch_renderer(self, mode: Optional[str] = None):\n        # 目前只有这一款\n        self.splitter = MultipleSegmentSplitter()\n\n        if config.response.buffer_delay > 0:\n            self.merger = BufferedContentMerger(self.splitter)\n        else:\n            self.merger = LengthContentMerger(self.splitter)\n\n        if not mode:\n            mode = \"image\" if config.text_to_image.default or config.text_to_image.always else config.response.mode\n\n        if mode == \"image\" or config.text_to_image.always:\n            self.renderer = MarkdownImageRenderer(self.merger)\n        elif mode == \"mixed\":\n            self.renderer = MixedContentMessageChainRenderer(self.merger)\n        elif mode == \"text\":\n            self.renderer = PlainTextRenderer(self.merger)\n        else:\n            self.renderer = MixedContentMessageChainRenderer(self.merger)\n        if mode != \"image\" and config.text_to_image.always:\n            raise CommandRefusedException(\"不要！由于配置文件设置强制开了图片模式，我不会切换到其他任何模式。\")\n\n    async def reset(self):\n        await self.adapter.on_reset()\n        self.last_resp = ''\n        self.last_resp_time = -1\n        # 在重置会话时自动加载默认预设\n        async for value in self.load_preset('default'):\n            pass\n        yield config.response.reset\n\n    @retry((httpx.ConnectError, httpx.ConnectTimeout, TimeoutError))\n    async def ask(self, prompt: str, chain: MessageChain = None, name: str = None):\n        await self.check_and_reset()\n        # 检查是否为 画图指令\n        for prefix in config.trigger.prefix_image:\n            if prompt.startswith(prefix) and not isinstance(self.adapter, YiyanAdapter):\n                # TODO(lss233): 此部分可合并至 RateLimitMiddleware\n                respond_str = middlewares.handle_draw_request(self.session_id, prompt)\n                # TODO(lss233): 这什么玩意\n                if respond_str != \"1\":\n                    yield respond_str\n                    return\n                if not self.drawing_adapter:\n                    yield \"未配置画图引擎，无法使用画图功能！\"\n                    return\n                prompt = prompt.removeprefix(prefix)\n                try:\n                    if chain.has(GraiaImage):\n                        images = await self.drawing_adapter.img_to_img(chain.get(GraiaImage), prompt)\n                    else:\n                        images = await self.drawing_adapter.text_to_img(prompt)\n                    for i in images:\n                        yield i\n                except Exception as e:\n                    raise DrawingFailedException from e\n                respond_str = middlewares.handle_draw_respond_completed(self.session_id, prompt)\n                if respond_str != \"1\":\n                    yield respond_str\n                return\n\n        if self.preset_decoration_format:\n            prompt = (\n                self.preset_decoration_format.replace(\"{prompt}\", prompt)\n                .replace(\"{nickname}\", name)\n                .replace(\"{last_resp}\", self.last_resp)\n                .replace(\"{date}\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n            )\n\n        async with self.renderer:\n            async for item in self.adapter.ask(prompt):\n                if isinstance(item, Element):\n                    yield item\n                else:\n                    yield await self.renderer.render(item)\n                self.last_resp = item or ''\n                self.last_resp_time = int(time.time())\n            yield await self.renderer.result()\n\n    async def rollback(self):\n        resp = await self.adapter.rollback()\n        if isinstance(resp, bool):\n            yield config.response.rollback_success if resp else config.response.rollback_fail.format(\n                reset=config.trigger.reset_command)\n        else:\n            yield resp\n\n    async def switch_model(self, model_name):\n        return await self.adapter.switch_model(model_name)\n\n    async def load_preset(self, keyword: str):\n        self.preset_decoration_format = None\n        if keyword in config.presets.keywords:\n            presets = config.load_preset(keyword)\n            for text in presets:\n                if not text.strip() or not text.startswith('#'):\n                    # 判断格式是否为 role: 文本\n                    if ':' in text:\n                        role, text = text.split(':', 1)\n                    else:\n                        role = 'system'\n\n                    if role == 'user_send':\n                        self.preset_decoration_format = text\n                        continue\n\n                    if role == 'voice':\n                        self.conversation_voice = TtsVoiceManager.parse_tts_voice(config.text_to_speech.engine,\n                                                                                  text.strip())\n                        logger.debug(f\"Set conversation voice to {self.conversation_voice.full_name}\")\n                        continue\n                    \n                    # Replace {date} in system prompt\n                    text = text.replace(\"{date}\", datetime.now().strftime('%Y-%m-%d'))\n                    async for item in self.adapter.preset_ask(role=role.lower().strip(), text=text.strip()):\n                        yield item\n        elif keyword != 'default':\n            raise PresetNotFoundException(keyword)\n        self.preset = keyword\n\n    def delete_message(self, respond_msg):\n        # TODO: adapt to all platforms\n        pass\n\n    async def check_and_reset(self):\n        timeout_seconds = config.system.auto_reset_timeout_seconds\n        current_time = time.time()\n        if timeout_seconds == -1 or self.last_resp_time == -1 or current_time - self.last_resp_time < timeout_seconds:\n            return\n        logger.debug(f\"Reset conversation({self.session_id}) after {current_time - self.last_resp_time} seconds.\")\n        async for _resp in self.reset():\n            logger.debug(_resp)\n\n\nclass ConversationHandler:\n    \"\"\"\n    每个聊天窗口拥有一个 ConversationHandler，\n    负责管理多个不同的 ConversationContext\n    \"\"\"\n    conversations: Dict[str, ConversationContext]\n    \"\"\"当前聊天窗口下所有的会话\"\"\"\n\n    current_conversation: ConversationContext = None\n\n    session_id: str = 'unknown'\n\n    def __init__(self, session_id: str):\n        self.conversations = {}\n        self.session_id = session_id\n\n    def list(self) -> List[ConversationContext]:\n        ...\n\n    \"\"\"\n    获取或创建新的上下文\n    这里的代码和 create 是一样的\n    因为 create 之后会加入多会话功能\n    \"\"\"\n\n    async def first_or_create(self, _type: str):\n        if _type in self.conversations:\n            return self.conversations[_type]\n        conversation = ConversationContext(_type, self.session_id)\n        self.conversations[_type] = conversation\n        return conversation\n\n    \"\"\"创建新的上下文\"\"\"\n\n    async def create(self, _type: str):\n        if _type in self.conversations:\n            return self.conversations[_type]\n        conversation = ConversationContext(_type, self.session_id)\n        self.conversations[_type] = conversation\n        return conversation\n\n    \"\"\"切换对话上下文\"\"\"\n\n    def switch(self, index: int) -> bool:\n        if len(self.conversations) > index:\n            self.current_conversation = self.conversations[index]\n            return True\n        return False\n\n    @classmethod\n    async def get_handler(cls, session_id: str):\n        if session_id not in handlers:\n            handlers[session_id] = ConversationHandler(session_id)\n        return handlers[session_id]\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.clean.yaml",
          "type": "blob",
          "size": 0.607421875,
          "content": "version: '3.4'\nservices:\n  chatgpt:\n    image: lss233/chatgpt-mirai-qq-bot:browser-version\n    restart: always\n    environment:\n      LANG: 'C.UTF-8'\n      XPRA_PASSWORD: 'lss233' # XPRA 密码，建议修改\n    volumes:\n      - ./config.cfg:/app/config.cfg\n      - ./data:/app/data\n      - ./presets:/app/presets # 如果你想自定义预设，就解除注释\n      # - ./fonts:/app/fonts # 如果你想自定义字体，就解除注释\n  watchtower: # [可选] 自动更新\n    image: containrrr/watchtower\n    volumes: # 如果启动失败，请修改下面这条：\n      - /var/run/docker.sock:/var/run/docker.sock\n"
        },
        {
          "name": "docker-compose.go-cqhttp.yaml",
          "type": "blob",
          "size": 0.646484375,
          "content": "version: '3.4'\nservices:\n  gocqhttp:\n    image: silicer/go-cqhttp:latest\n    restart: always\n    environment:\n      LANG: 'C.UTF-8'\n    volumes:\n      - ./gocqhttp/:/data/\n  chatgpt:\n    image: lss233/chatgpt-mirai-qq-bot:browser-version\n    restart: always\n    environment:\n      LANG: 'C.UTF-8'\n    volumes:\n      - ./config.cfg:/app/config.cfg\n      - ./data:/app/data\n      - ./presets:/app/presets\n      # - ./fonts:/app/fonts # 如果你想自定义字体，就解除注释\n  watchtower: # [可选] 自动更新\n    image: containrrr/watchtower\n    volumes: # 如果启动失败，请修改下面这条：\n      - /var/run/docker.sock:/var/run/docker.sock\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 0.8154296875,
          "content": "version: '3.4'\nservices:\n  mirai:\n    image: lss233/mirai-http:latest\n    restart: always\n    environment:\n      LANG: 'C.UTF-8'\n    volumes:\n      - ./mirai/bots:/app/bots\n      - ./mirai/config:/app/config\n      - ./mirai/data:/app/data\n      # - ./mirai/config.json:/app/config.json # 如果你要修改 mcl 的设置，就解除这个注释\n  chatgpt:\n    image: lss233/chatgpt-mirai-qq-bot:browser-version\n    restart: always\n    environment:\n      LANG: 'C.UTF-8'\n    volumes:\n      - ./config.cfg:/app/config.cfg\n      - ./data:/app/data\n      - ./presets:/app/presets\n      # - ./fonts:/app/fonts # 如果你想自定义字体，就解除注释\n  watchtower: # [可选] 自动更新\n    image: containrrr/watchtower\n    volumes: # 如果启动失败，请修改下面这条：\n      - /var/run/docker.sock:/var/run/docker.sock\n"
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "drawing",
          "type": "tree",
          "content": null
        },
        {
          "name": "exceptions",
          "type": "tree",
          "content": null
        },
        {
          "name": "fonts",
          "type": "tree",
          "content": null
        },
        {
          "name": "manager",
          "type": "tree",
          "content": null
        },
        {
          "name": "middlewares",
          "type": "tree",
          "content": null
        },
        {
          "name": "platforms",
          "type": "tree",
          "content": null
        },
        {
          "name": "presets",
          "type": "tree",
          "content": null
        },
        {
          "name": "renderer",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.7353515625,
          "content": "# Robot-frame\ngraia-ariadne==0.11.7\ngraia-broadcast==0.23.2\ngraiax-silkcoder\npython-telegram-bot==20.4\ndiscord.py\nwechatpy~=2.0.0a26\n\n# LLM-Upstream-library\nrevChatGPT~=6.8.6\nopenai~=0.27.8\nEdgeGPT==0.13.2\nOpenAIAuth>=2.0.0\nBingImageCreator~=0.4.4\npoe-api==0.5.2\ntiktoken~=0.4.0\n\n# TTS-related-dependencies\nazure-cognitiveservices-speech\nedge-tts\n\n# Other-dependencies\ntoml~=0.10.2\nPillow>=9.3.0\ntinydb~=4.8.0\nloguru~=0.7.0\nasyncio~=3.4.3\npydantic\nmarkdown~=3.4.4\npython-markdown-math~=0.8\npygments~=2.15.1\nimgkit~=1.2.3\nqrcode~=7.4.2\naiohttp~=3.8.5\nurllib3~=2.0.4\nrequests~=2.31.0\nuuid~=1.30\naiocqhttp~=1.4.4\ntls-client\npython-dateutil~=2.8.2\nregex~=2023.6.3\nhttpx~=0.24.1\nQuart==0.17.0\ncreart~=0.3.0\npydub~=0.25.1\nhttpcore~=0.17.3\ng4f~=0.0.2.6\ncreart\n"
        },
        {
          "name": "test.py",
          "type": "blob",
          "size": 1.66796875,
          "content": "import os\nimport sys\n\n\nsys.path.append(os.getcwd())\nfrom constants import botManager\n\nfrom graia.ariadne.message.chain import MessageChain\nfrom graia.ariadne.message.element import Plain, Image\nfrom loguru import logger\n\nfrom universal import handle_message\n\nimport asyncio\n\nfrom renderer.renderer import MixedContentMessageChainRenderer\nfrom renderer.merger import BufferedContentMerger\nfrom renderer.splitter import MultipleSegmentSplitter\n\n\nrenderer = MultipleSegmentSplitter()\n\nrenderer = BufferedContentMerger(renderer)\n\nrenderer = MixedContentMessageChainRenderer(renderer)\n\n\nasync def render(text: str):\n    async with renderer:\n        total_text = ''\n        for i in data:\n            await asyncio.sleep(0.03)\n            partial = await renderer.render(i)\n            if partial:\n                print(partial)\n                print('---')\n        result = await renderer.result()\n        print('result', result)\n\n\nif __name__ == '__main__':\n    async def response(msg):\n        if isinstance(msg, MessageChain):\n            logger.debug(f\"Say MessageChain with {len(msg)} items\")\n            for elem in msg:\n                if isinstance(elem, Plain):\n                    logger.debug(f\"Say Plain: {elem}\")\n                elif isinstance(elem, Image):\n                    logger.debug(f\"Say Image: {elem}\")\n        else:\n            logger.debug(f\"Say Other: {msg}\")\n    asyncio.run(botManager.login())\n    asyncio.run(handle_message(\n        response,\n        f\"friend-1234567890\",\n        \"切换AI bing-c\",\n        is_manager=False\n    ))\n    asyncio.run(handle_message(\n        response,\n        f\"friend-1234567890\",\n        \"告诉我全球天气情况\",\n        is_manager=False\n    ))\n"
        },
        {
          "name": "universal.py",
          "type": "blob",
          "size": 14.2763671875,
          "content": "import asyncio\nimport re\nfrom typing import Callable\n\nimport httpcore\nimport httpx\nimport openai\nfrom graia.ariadne.message.chain import MessageChain\nfrom graia.ariadne.message.element import Plain\nfrom httpx import ConnectTimeout\nfrom loguru import logger\nfrom requests.exceptions import SSLError, ProxyError, RequestException\nfrom urllib3.exceptions import MaxRetryError\n\nfrom constants import botManager, BotPlatform\nfrom constants import config\nfrom conversation import ConversationHandler, ConversationContext\nfrom exceptions import PresetNotFoundException, BotRatelimitException, ConcurrentMessageException, \\\n    BotTypeNotFoundException, NoAvailableBotException, BotOperationNotSupportedException, CommandRefusedException, \\\n    DrawingFailedException\nfrom middlewares.baiducloud import MiddlewareBaiduCloud\nfrom middlewares.concurrentlock import MiddlewareConcurrentLock\nfrom middlewares.ratelimit import MiddlewareRatelimit\nfrom middlewares.timeout import MiddlewareTimeout\nfrom utils.text_to_speech import get_tts_voice, TtsVoiceManager, VoiceType\n\nmiddlewares = [MiddlewareTimeout(), MiddlewareRatelimit(), MiddlewareBaiduCloud(), MiddlewareConcurrentLock()]\n\n\nasync def get_ping_response(conversation_context: ConversationContext):\n    current_voice = conversation_context.conversation_voice.alias if conversation_context.conversation_voice else \"无\"\n    response = config.response.ping_response.format(current_ai=conversation_context.type,\n                                                    current_voice=current_voice,\n                                                    supported_ai=botManager.bots_info())\n    tts_voices = await TtsVoiceManager.list_tts_voices(\n        config.text_to_speech.engine, config.text_to_speech.default_voice_prefix)\n    if tts_voices:\n        supported_tts = \",\".join([v.alias for v in tts_voices])\n        response += config.response.ping_tts_response.format(supported_tts=supported_tts)\n    return response\n\n\nasync def handle_message(_respond: Callable, session_id: str, message: str,\n                         chain: MessageChain = MessageChain(\"Unsupported\"), is_manager: bool = False,\n                         nickname: str = '某人', request_from=BotPlatform.AriadneBot):\n    conversation_context = None\n\n    def wrap_request(n, m):\n        \"\"\"\n        Wrapping send messages\n        \"\"\"\n        async def call(session_id, message, conversation_context, respond):\n            await m.handle_request(session_id, message, respond, conversation_context, n)\n\n        return call\n\n    def wrap_respond(n, m):\n        \"\"\"\n        Wrapping respond messages\n        \"\"\"\n        async def call(session_id, message, rendered, respond):\n            await m.handle_respond(session_id, message, rendered, respond, n)\n\n        return call\n\n    async def respond(msg: str):\n        \"\"\"\n        Respond method\n        \"\"\"\n        if not msg:\n            return\n        ret = await _respond(msg)\n        for m in middlewares:\n            await m.on_respond(session_id, message, msg)\n\n        # TODO: 之后重构成 platforms 的 respond 只处理 MessageChain\n        if isinstance(msg, str):\n            msg = MessageChain([Plain(msg)])\n\n        nonlocal conversation_context\n        if not conversation_context:\n            try:\n                conversation_context = conversation_handler.current_conversation\n            except NameError:\n                logger.warning(f\"收到空消息时尚未定义conversation_handler，报错已忽略\")\n\n        if not conversation_context:\n            return ret\n        # TTS Converting\n        if conversation_context.conversation_voice and isinstance(msg, MessageChain):\n            if request_from in [BotPlatform.Onebot, BotPlatform.AriadneBot]:\n                voice_type = VoiceType.Silk\n            elif request_from == BotPlatform.HttpService:\n                voice_type = VoiceType.Mp3\n            else:\n                voice_type = VoiceType.Wav\n            tasks = []\n            for elem in msg:\n                task = asyncio.create_task(get_tts_voice(elem, conversation_context, voice_type))\n                tasks.append(task)\n            while tasks:\n                done, tasks = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)\n                for voice_task in done:\n                    voice = await voice_task\n                    if voice:\n                        await _respond(voice)\n\n        return ret\n\n    async def request(_session_id, prompt: str, conversation_context, _respond):\n        \"\"\"\n        Request method\n        \"\"\"\n\n        task = None\n\n        # 不带前缀 - 正常初始化会话\n        if bot_type_search := re.search(config.trigger.switch_command, prompt):\n            if not (config.trigger.allow_switching_ai or is_manager):\n                await respond(\"不好意思，只有管理员才能切换AI！\")\n                return\n            conversation_handler.current_conversation = (\n                await conversation_handler.create(\n                    bot_type_search[1].strip()\n                )\n            )\n            await respond(f\"已切换至 {bot_type_search[1].strip()} AI，现在开始和我聊天吧！\")\n            return\n        # 最终要选择的对话上下文\n        if not conversation_context:\n            conversation_context = conversation_handler.current_conversation\n        # 此处为会话存在后可执行的指令\n\n        # 重置会话\n        if prompt in config.trigger.reset_command:\n            task = conversation_context.reset()\n\n        elif prompt in config.trigger.rollback_command:\n            task = conversation_context.rollback()\n\n        elif prompt in config.trigger.ping_command:\n            await respond(await get_ping_response(conversation_context))\n            return\n\n        elif voice_type_search := re.search(config.trigger.switch_voice, prompt):\n            if not config.azure.tts_speech_key and config.text_to_speech.engine == \"azure\":\n                await respond(\"未配置 Azure TTS 账户，无法切换语音！\")\n            new_voice = voice_type_search[1].strip()\n            if new_voice in ['关闭', \"None\"]:\n                conversation_context.conversation_voice = None\n                await respond(\"已关闭语音，让我们继续聊天吧！\")\n            elif config.text_to_speech.engine == \"vits\":\n                from utils.vits_tts import vits_api_instance\n                try:\n                    voice_name = await vits_api_instance.set_id(new_voice)\n                    conversation_context.conversation_voice = TtsVoiceManager.parse_tts_voice(\"vits\", voice_name)\n                    await respond(f\"已切换至 {voice_name} 语音，让我们继续聊天吧！\")\n                except ValueError:\n                    await respond(\"提供的语音ID无效，请输入一个有效的数字ID。\")\n                except Exception as e:\n                    await respond(str(e))\n            elif config.text_to_speech.engine == \"edge\":\n                tts_voice = TtsVoiceManager.parse_tts_voice(\"edge\", new_voice)\n                if tts_voice:\n                    conversation_context.conversation_voice = tts_voice\n                    await respond(f\"已切换至 {tts_voice.alias} 语音，让我们继续聊天吧！\")\n                else:\n                    available_voice = \",\".join([v.alias for v in await TtsVoiceManager.list_tts_voices(\n                        \"edge\", config.text_to_speech.default_voice_prefix)])\n                    await respond(f\"提供的语音ID无效，请输入一个有效的语音ID。如：{available_voice}。\")\n                    conversation_context.conversation_voice = None\n            elif config.text_to_speech.engine == \"azure\":\n                tts_voice = TtsVoiceManager.parse_tts_voice(\"azure\", new_voice)\n                conversation_context.conversation_voice = tts_voice\n                if tts_voice:\n                    await respond(f\"已切换至 {tts_voice.full_name} 语音，让我们继续聊天吧！\")\n                else:\n                    await respond(\"提供的语音ID无效，请输入一个有效的语音ID。\")\n            else:\n                await respond(\"未配置文字转语音引擎，无法使用语音功能。\")\n            return\n\n        elif prompt in config.trigger.mixed_only_command:\n            conversation_context.switch_renderer(\"mixed\")\n            await respond(\"已切换至图文混合模式，接下来我的回复将会以图文混合的方式呈现！\")\n            return\n\n        elif prompt in config.trigger.image_only_command:\n            conversation_context.switch_renderer(\"image\")\n            await respond(\"已切换至纯图片模式，接下来我的回复将会以图片呈现！\")\n            return\n\n        elif prompt in config.trigger.text_only_command:\n            conversation_context.switch_renderer(\"text\")\n            await respond(\"已切换至纯文字模式，接下来我的回复将会以文字呈现（被吞除外）！\")\n            return\n\n        elif switch_model_search := re.search(config.trigger.switch_model, prompt):\n            model_name = switch_model_search[1].strip()\n            if model_name in conversation_context.supported_models:\n                if not (is_manager or model_name in config.trigger.allowed_models):\n                    await respond(f\"不好意思，只有管理员才能切换到 {model_name} 模型！\")\n                else:\n                    await conversation_context.switch_model(model_name)\n                    await respond(f\"已切换至 {model_name} 模型，让我们聊天吧！\")\n            else:\n                logger.warning(f\"模型 {model_name} 不在支持列表中，下次将尝试使用此模型创建对话。\")\n                await conversation_context.switch_model(model_name)\n                await respond(\n                    f\"模型 {model_name} 不在支持列表中，下次将尝试使用此模型创建对话，目前AI仅支持：{conversation_context.supported_models}！\")\n            return\n\n        # 加载预设\n        if preset_search := re.search(config.presets.command, prompt):\n            logger.trace(f\"{session_id} - 正在执行预设： {preset_search[1]}\")\n            async for _ in conversation_context.reset(): ...\n            task = conversation_context.load_preset(preset_search[1])\n        elif not conversation_context.preset:\n            # 当前没有预设\n            logger.trace(f\"{session_id} - 未检测到预设，正在执行默认预设……\")\n            # 隐式加载不回复预设内容\n            async for _ in conversation_context.load_preset('default'): ...\n\n        # 没有任务那就聊天吧！\n        if not task:\n            task = conversation_context.ask(prompt=prompt, chain=chain, name=nickname)\n        async for rendered in task:\n            if rendered:\n                if not str(rendered).strip():\n                    logger.warning(\"检测到内容为空的输出，已忽略\")\n                    continue\n                action = lambda session_id, prompt, rendered, respond: respond(rendered)\n                for m in middlewares:\n                    action = wrap_respond(action, m)\n\n                # 开始处理 handle_response\n                await action(session_id, prompt, rendered, respond)\n        for m in middlewares:\n            await m.handle_respond_completed(session_id, prompt, respond)\n\n    try:\n        if not message.strip():\n            return await respond(config.response.placeholder)\n\n        for r in config.trigger.ignore_regex:\n            if re.match(r, message):\n                logger.debug(f\"此消息满足正则表达式： {r}，忽略……\")\n                return\n\n        # 此处为会话不存在时可以执行的指令\n        conversation_handler = await ConversationHandler.get_handler(session_id)\n        # 指定前缀对话\n        if ' ' in message and (config.trigger.allow_switching_ai or is_manager):\n            for ai_type, prefixes in config.trigger.prefix_ai.items():\n                for prefix in prefixes:\n                    if f'{prefix} ' in message:\n                        conversation_context = await conversation_handler.first_or_create(ai_type)\n                        message = message.removeprefix(f'{prefix} ')\n                        break\n                else:\n                    # Continue if the inner loop wasn't broken.\n                    continue\n                # Inner loop was broken, break the outer.\n                break\n        if not conversation_handler.current_conversation:\n            conversation_handler.current_conversation = await conversation_handler.create(\n                config.response.default_ai)\n\n        action = request\n        for m in middlewares:\n            action = wrap_request(action, m)\n\n        # 开始处理\n        await action(session_id, message.strip(), conversation_context, respond)\n    except DrawingFailedException as e:\n        logger.exception(e)\n        await _respond(config.response.error_drawing.format(exc=e.__cause__ or '未知'))\n    except CommandRefusedException as e:\n        await _respond(str(e))\n    except openai.error.InvalidRequestError as e:\n        await _respond(f\"服务器拒绝了您的请求，原因是： {str(e)}\")\n    except BotOperationNotSupportedException:\n        await _respond(\"暂不支持此操作，抱歉！\")\n    except ConcurrentMessageException as e:  # Chatbot 账号同时收到多条消息\n        await _respond(config.response.error_request_concurrent_error)\n    except BotRatelimitException as e:  # Chatbot 账号限流\n        await _respond(config.response.error_request_too_many.format(exc=e))\n    except NoAvailableBotException as e:  # 预设不存在\n        await _respond(f\"当前没有可用的{e}账号，不支持使用此 AI！\")\n    except BotTypeNotFoundException as e:  # 预设不存在\n        respond_msg = f\"AI类型{e}不存在，请检查你的输入是否有问题！目前仅支持：\\n\"\n        respond_msg += botManager.bots_info()\n        await _respond(respond_msg)\n    except PresetNotFoundException:  # 预设不存在\n        await _respond(\"预设不存在，请检查你的输入是否有问题！\")\n    except (RequestException, SSLError, ProxyError, MaxRetryError, ConnectTimeout, ConnectTimeout,\n            httpcore.ReadTimeout, httpx.TimeoutException) as e:  # 网络异常\n        await _respond(config.response.error_network_failure.format(exc=e))\n    except Exception as e:  # 未处理的异常\n        logger.exception(e)\n        await _respond(config.response.error_format.format(exc=e))\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}