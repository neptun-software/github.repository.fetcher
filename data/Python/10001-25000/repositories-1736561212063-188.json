{
  "metadata": {
    "timestamp": 1736561212063,
    "page": 188,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "albumentations-team/albumentations",
      "stars": 14466,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0595703125,
          "content": "*.py linguist-language=python\n*.ipynb linguist-documentation\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.28125,
          "content": "# Created by .ignore support plugin (hsz.mobi)\n### Python template\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n### JetBrains template\n# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio and WebStorm\n# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839\n\n# User-specific stuff:\n.idea/**/workspace.xml\n.idea/**/tasks.xml\n.idea/dictionaries\n\n# Sensitive or high-churn files:\n.idea/**/dataSources/\n.idea/**/dataSources.ids\n.idea/**/dataSources.local.xml\n.idea/**/sqlDataSources.xml\n.idea/**/dynamic.xml\n.idea/**/uiDesigner.xml\n\n# Gradle:\n.idea/**/gradle.xml\n.idea/**/libraries\n\n# CMake\ncmake-build-debug/\ncmake-build-release/\n\n# Mongo Explorer plugin:\n.idea/**/mongoSettings.xml\n\n## File-based project format:\n*.iws\n\n## Plugin-specific files:\n\n# IntelliJ\nout/\n\n# mpeltonen/sbt-idea plugin\n.idea_modules/\n\n# JIRA plugin\natlassian-ide-plugin.xml\n\n# Cursive Clojure plugin\n.idea/replstate.xml\n\n# Crashlytics plugin (for Android Studio and IntelliJ)\ncom_crashlytics_export_strings.xml\ncrashlytics.properties\ncrashlytics-build.properties\nfabric.properties\n\n.idea\n\nconda_build/\n\n.vscode/\n\n*.ipynb\n\n.ruff_cache/\n\ndata/\n"
        },
        {
          "name": ".markdownlint.json",
          "type": "blob",
          "size": 0.08203125,
          "content": "{\n    \"default\": true,\n    \"MD013\": false,\n    \"MD033\": false,\n    \"MD045\": false\n}\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 2.56640625,
          "content": "ci:\n  autofix_commit_msg: |\n    [pre-commit.ci] auto fixes from pre-commit.com hooks\n\n    for more information, see https://pre-commit.ci\n  autofix_prs: true\n  autoupdate_branch: ''\n  autoupdate_commit_msg: '[pre-commit.ci] pre-commit autoupdate'\n  autoupdate_schedule: weekly\n  skip: [ ]\n  submodules: false\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-added-large-files\n      - id: check-ast\n      - id: check-builtin-literals\n      - id: check-case-conflict\n      - id: check-docstring-first\n      - id: check-executables-have-shebangs\n      - id: check-shebang-scripts-are-executable\n      - id: check-symlinks\n      - id: check-toml\n      - id: check-xml\n      - id: detect-private-key\n      - id: forbid-new-submodules\n      - id: forbid-submodules\n      - id: mixed-line-ending\n      - id: destroyed-symlinks\n      - id: fix-byte-order-marker\n      - id: check-json\n      - id: debug-statements\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n      - id: requirements-txt-fixer\n  - repo: local\n    hooks:\n    - id: check-docstrings\n      name: Check Docstrings for '---' sequences\n      entry: python tools/check_docstrings.py\n      language: python\n      types: [python]\n  - repo: local\n    hooks:\n      - id: check-albucore-version\n        name: Check albucore version\n        entry: python ./tools/check_albucore_version.py\n        language: system\n        files: setup.py\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    # Ruff version.\n    rev: v0.8.6\n    hooks:\n      # Run the linter.\n      - id: ruff\n        exclude: '__pycache__/'\n        args: [ --fix ]\n      # Run the formatter.\n      - id: ruff-format\n  - repo: https://github.com/pre-commit/pygrep-hooks\n    rev: v1.10.0\n    hooks:\n      - id: python-check-mock-methods\n      - id: python-use-type-annotations\n      - id: python-check-blanket-noqa\n      - id: python-use-type-annotations\n      - id: text-unicode-replacement-char\n  - repo: https://github.com/codespell-project/codespell\n    rev: v2.3.0\n    hooks:\n      - id: codespell\n        additional_dependencies: [\"tomli\"]\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.43.0\n    hooks:\n      - id: markdownlint\n  - repo: https://github.com/tox-dev/pyproject-fmt\n    rev: \"v2.5.0\"\n    hooks:\n      - id: pyproject-fmt\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.14.1\n    hooks:\n      - id: mypy\n        files: ^albumentations/\n        additional_dependencies: [ types-PyYAML, types-setuptools, pydantic>=2.9]\n        args:\n          [ --config-file=pyproject.toml ]\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.185546875,
          "content": "version: 2\n\nsphinx:\n  configuration: docs/conf.py\n\nformats:\n  - htmlzip\n  - pdf\n  - epub\n\npython:\n  version: 3.9\n  system_packages: true\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.3544921875,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in the Albumentations project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socioeconomic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as physical or electronic addresses, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at [https://www.contributor-covenant.org/version/1/4/code-of-conduct.html](https://www.contributor-covenant.org/version/1/4/code-of-conduct.html)\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\n[https://www.contributor-covenant.org/faq](https://www.contributor-covenant.org/faq)\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.921875,
          "content": "# Contributing to Albumentations\n\nThank you for your interest in contributing to [Albumentations](https://albumentations.ai/)! This guide will help you get started with contributing to our image augmentation library.\n\n## Quick Start\n\nFor small changes (e.g., bug fixes), feel free to submit a PR directly.\n\nFor larger changes:\n\n1. Create an [issue](https://github.com/albumentations-team/albumentations/issues) outlining your proposed change\n2. Join our [Discord community](https://discord.gg/e6zHCXTvaN) to discuss your idea\n\n## Contribution Guides\n\nWe've organized our contribution guidelines into focused documents:\n\n- [Environment Setup Guide](docs/contributing/environment_setup.md) - How to set up your development environment\n- [Coding Guidelines](docs/contributing/coding_guidelines.md) - Code style, best practices, and technical requirements\n\n## Contribution Process\n\n1. **Find an Issue**: Look for open issues or propose a new one. For newcomers, look for issues labeled \"good first issue\"\n2. **Set Up**: Follow our [Environment Setup Guide](docs/contributing/environment_setup.md)\n3. **Create a Branch**: `git checkout -b feature/my-new-feature`\n4. **Make Changes**: Write code following our [Coding Guidelines](docs/contributing/coding_guidelines.md)\n5. **Test**: Add tests and ensure all tests pass\n6. **Submit**: Open a Pull Request with a clear description of your changes\n\n## Code Review Process\n\n1. Maintainers will review your contribution\n2. Address any feedback or questions\n3. Once approved, your code will be merged\n\n## Project Structure\n\n- `albumentations/` - Main source code\n- `tests/` - Test suite\n- `docs/` - Documentation\n\n## Getting Help\n\n- Join our [Discord community](https://discord.gg/e6zHCXTvaN)\n- Open a GitHub [issue](https://github.com/albumentations-team/albumentations/issues)\n- Ask questions in your pull request\n\n## License\n\nBy contributing, you agree that your contributions will be licensed under the project's MIT License.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.087890625,
          "content": "MIT License\n\nCopyright (c) 2017 Vladimir Iglovikov, Alexander Buslaev, Alexander Parinov,\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MAINTAINERS.md",
          "type": "blob",
          "size": 0.1640625,
          "content": "# Project Maintainers\n\n## Current Maintainer\n\nVladimir Iglovikov\n\n## Emeritus Team Members\n\n- Alexander Buslaev\n- Alex Parinov\n- Eugene Khvedchenya\n- Mikhail Druzhinin\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.3271484375,
          "content": "include LICENSE\ninclude README.md\n\nprune docs/_build\nglobal-exclude docs/augs_overview/*/images/*.jpg\n\nglobal-exclude *.py[co] .DS_Store\n\n# Exclude test, tools, and benchmark directories\nprune tests\nprune tools\nprune benchmark\nprune conda.recipe\nprune codecov.yaml\nprune pre-commit-config.yaml\nprune .github\nprune requirements-dev.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 32.685546875,
          "content": "# Albumentations\n\n[![PyPI version](https://badge.fury.io/py/albumentations.svg)](https://badge.fury.io/py/albumentations)\n![CI](https://github.com/albumentations-team/albumentations/workflows/CI/badge.svg)\n[![PyPI Downloads](https://img.shields.io/pypi/dm/albumentations.svg?label=PyPI%20downloads)](\nhttps://pypi.org/project/albumentations/)\n[![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/albumentations.svg?label=Conda%20downloads)](\nhttps://anaconda.org/conda-forge/albumentations)\n[![Stack Overflow](https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg)](\nhttps://stackoverflow.com/questions/tagged/albumentations)\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)\n[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Albumentations%20Guru-006BFF)](https://gurubase.io/g/albumentations)\n\n[Docs](https://albumentations.ai/docs/) | [Discord](https://discord.gg/AKPrrDYNAt) | [Twitter](https://twitter.com/albumentations) | [LinkedIn](https://www.linkedin.com/company/100504475/)\n\nAlbumentations is a Python library for image augmentation. Image augmentation is used in deep learning and computer vision tasks to increase the quality of trained models. The purpose of image augmentation is to create new training samples from the existing data.\n\nHere is an example of how you can apply some [pixel-level](#pixel-level-transforms) augmentations from Albumentations to create new images from the original one:\n![parrot](https://habrastorage.org/webt/bd/ne/rv/bdnerv5ctkudmsaznhw4crsdfiw.jpeg)\n\n## Why Albumentations\n\n- **Complete Computer Vision Support**: Works with [all major CV tasks](#i-want-to-use-albumentations-for-the-specific-task-such-as-classification-or-segmentation) including classification, segmentation (semantic & instance), object detection, and pose estimation.\n- **Simple, Unified API**: [One consistent interface](#a-simple-example) for all data types - RGB/grayscale/multispectral images, masks, bounding boxes, and keypoints.\n- **Rich Augmentation Library**: [70+ high-quality augmentations](https://albumentations.ai/docs/api_reference/transforms/) to enhance your training data.\n- **Fast**: Consistently benchmarked as the [fastest augmentation library](https://albumentations.ai/docs/benchmarks/), with optimizations for production use.\n- **Deep Learning Integration**: Works with [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), and other frameworks. Part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/).\n- **Created by Experts**: Built by [developers with deep experience in computer vision and machine learning competitions](#authors).\n\n## Community-Driven Project, Supported By\n\nAlbumentations thrives on developer contributions. We appreciate our sponsors who help sustain the project's infrastructure.\n\n| 🏆 Gold Sponsors |\n|-----------------|\n| Your company could be here |\n\n| 🥈 Silver Sponsors |\n|-------------------|\n| <a href=\"https://datature.io\" target=\"_blank\"><img src=\"https://albumentations.ai/assets/sponsors/datature-full.png\" width=\"100\" alt=\"Datature\"/></a> |\n\n| 🥉 Bronze Sponsors |\n|-------------------|\n| <a href=\"https://roboflow.com\" target=\"_blank\"><img src=\"https://albumentations.ai/assets/sponsors/roboflow.png\" width=\"100\" alt=\"Roboflow\"/></a> |\n\n---\n\n### 💝 Become a Sponsor\n\nYour sponsorship is a way to say \"thank you\" to the maintainers and contributors who spend their free time building and maintaining Albumentations. Sponsors are featured on our website and README. View sponsorship tiers on [GitHub Sponsors](https://github.com/sponsors/albumentations-team)\n\n## Table of contents\n\n- [Albumentations](#albumentations)\n  - [Why Albumentations](#why-albumentations)\n  - [Community-Driven Project, Supported By](#community-driven-project-supported-by)\n    - [💝 Become a Sponsor](#-become-a-sponsor)\n  - [Table of contents](#table-of-contents)\n  - [Authors](#authors)\n    - [Current Maintainer](#current-maintainer)\n    - [Emeritus Core Team Members](#emeritus-core-team-members)\n  - [Installation](#installation)\n  - [Documentation](#documentation)\n  - [A simple example](#a-simple-example)\n  - [Getting started](#getting-started)\n    - [I am new to image augmentation](#i-am-new-to-image-augmentation)\n    - [I want to use Albumentations for the specific task such as classification or segmentation](#i-want-to-use-albumentations-for-the-specific-task-such-as-classification-or-segmentation)\n    - [I want to know how to use Albumentations with deep learning frameworks](#i-want-to-know-how-to-use-albumentations-with-deep-learning-frameworks)\n    - [I want to explore augmentations and see Albumentations in action](#i-want-to-explore-augmentations-and-see-albumentations-in-action)\n  - [Who is using Albumentations](#who-is-using-albumentations)\n    - [See also](#see-also)\n  - [List of augmentations](#list-of-augmentations)\n    - [Pixel-level transforms](#pixel-level-transforms)\n    - [Spatial-level transforms](#spatial-level-transforms)\n  - [A few more examples of **augmentations**](#a-few-more-examples-of-augmentations)\n    - [Semantic segmentation on the Inria dataset](#semantic-segmentation-on-the-inria-dataset)\n    - [Medical imaging](#medical-imaging)\n    - [Object detection and semantic segmentation on the Mapillary Vistas dataset](#object-detection-and-semantic-segmentation-on-the-mapillary-vistas-dataset)\n    - [Keypoints augmentation](#keypoints-augmentation)\n  - [Benchmarking results](#benchmarking-results)\n    - [System Information](#system-information)\n    - [Benchmark Parameters](#benchmark-parameters)\n    - [Library Versions](#library-versions)\n  - [Performance Comparison](#performance-comparison)\n  - [Contributing](#contributing)\n  - [Community](#community)\n  - [Citing](#citing)\n\n## Authors\n\n### Current Maintainer\n\n[**Vladimir I. Iglovikov**](https://www.linkedin.com/in/iglovikov/) | [Kaggle Grandmaster](https://www.kaggle.com/iglovikov)\n\n### Emeritus Core Team Members\n\n[**Mikhail Druzhinin**](https://www.linkedin.com/in/mikhail-druzhinin-548229100/) | [Kaggle Expert](https://www.kaggle.com/dipetm)\n\n[**Alex Parinov**](https://www.linkedin.com/in/alex-parinov/) | [Kaggle Master](https://www.kaggle.com/creafz)\n\n[**Alexander Buslaev**](https://www.linkedin.com/in/al-buslaev/) | [Kaggle Master](https://www.kaggle.com/albuslaev)\n\n[**Eugene Khvedchenya**](https://www.linkedin.com/in/cvtalks/) | [Kaggle Grandmaster](https://www.kaggle.com/bloodaxe)\n\n## Installation\n\nAlbumentations requires Python 3.9 or higher. To install the latest version from PyPI:\n\n```bash\npip install -U albumentations\n```\n\nOther installation options are described in the [documentation](https://albumentations.ai/docs/getting_started/installation/).\n\n## Documentation\n\nThe full documentation is available at **[https://albumentations.ai/docs/](https://albumentations.ai/docs/)**.\n\n## A simple example\n\n```python\nimport albumentations as A\nimport cv2\n\n# Declare an augmentation pipeline\ntransform = A.Compose([\n    A.RandomCrop(width=256, height=256),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n])\n\n# Read an image with OpenCV and convert it to the RGB colorspace\nimage = cv2.imread(\"image.jpg\")\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Augment an image\ntransformed = transform(image=image)\ntransformed_image = transformed[\"image\"]\n```\n\n## Getting started\n\n### I am new to image augmentation\n\nPlease start with the [introduction articles](https://albumentations.ai/docs/#learning-path) about why image augmentation is important and how it helps to build better models.\n\n### I want to use Albumentations for the specific task such as classification or segmentation\n\nIf you want to use Albumentations for a specific task such as classification, segmentation, or object detection, refer to the [set of articles](https://albumentations.ai/docs/#quick-start-guide) that has an in-depth description of this task. We also have a [list of examples](https://albumentations.ai/docs/examples/) on applying Albumentations for different use cases.\n\n### I want to know how to use Albumentations with deep learning frameworks\n\nWe have [examples of using Albumentations](https://albumentations.ai/docs/#examples-of-how-to-use-albumentations-with-different-deep-learning-frameworks) along with PyTorch and TensorFlow.\n\n### I want to explore augmentations and see Albumentations in action\n\nCheck the [online demo of the library](https://albumentations-demo.herokuapp.com/). With it, you can apply augmentations to different images and see the result. Also, we have a [list of all available augmentations and their targets](#list-of-augmentations).\n\n## Who is using Albumentations\n\n<a href=\"https://www.apple.com/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/apple.jpeg\" width=\"100\"/></a>\n<a href=\"https://research.google/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/google.png\" width=\"100\"/></a>\n<a href=\"https://opensource.fb.com/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/meta_research.png\" width=\"100\"/></a>\n<a href=\"https://www.nvidia.com/en-us/research/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/nvidia_research.jpeg\" width=\"100\"/></a>\n<a href=\"https://www.amazon.science/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/amazon_science.png\" width=\"100\"/></a>\n<a href=\"https://opensource.microsoft.com/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/microsoft.png\" width=\"100\"/></a>\n<a href=\"https://engineering.salesforce.com/open-source/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/salesforce_open_source.png\" width=\"100\"/></a>\n<a href=\"https://stability.ai/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/stability.png\" width=\"100\"/></a>\n<a href=\"https://www.ibm.com/opensource/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/ibm.jpeg\" width=\"100\"/></a>\n<a href=\"https://huggingface.co/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/hugging_face.png\" width=\"100\"/></a>\n<a href=\"https://www.sony.com/en/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/sony.png\" width=\"100\"/></a>\n<a href=\"https://opensource.alibaba.com/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/alibaba.png\" width=\"100\"/></a>\n<a href=\"https://opensource.tencent.com/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/tencent.png\" width=\"100\"/></a>\n<a href=\"https://h2o.ai/\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/albumentations-team/albumentations.ai/main/website/public/assets/industry/h2o_ai.png\" width=\"100\"/></a>\n\n### See also\n\n- [A list of papers that cite Albumentations](https://scholar.google.com/citations?view_op=view_citation&citation_for_view=vkjh9X0AAAAJ:r0BpntZqJG4C).\n- [Open source projects that use Albumentations](https://github.com/albumentations-team/albumentations/network/dependents?dependent_type=PACKAGE).\n\n## List of augmentations\n\n### Pixel-level transforms\n\nPixel-level transforms will change just an input image and will leave any additional targets such as masks, bounding boxes, and keypoints unchanged. For volumetric data (volumes and 3D masks), these transforms are applied independently to each slice along the Z-axis (depth dimension), maintaining consistency across the volume. The list of pixel-level transforms:\n\n- [AdditiveNoise](https://explore.albumentations.ai/transform/AdditiveNoise)\n- [AdvancedBlur](https://explore.albumentations.ai/transform/AdvancedBlur)\n- [AutoContrast](https://explore.albumentations.ai/transform/AutoContrast)\n- [Blur](https://explore.albumentations.ai/transform/Blur)\n- [CLAHE](https://explore.albumentations.ai/transform/CLAHE)\n- [ChannelDropout](https://explore.albumentations.ai/transform/ChannelDropout)\n- [ChannelShuffle](https://explore.albumentations.ai/transform/ChannelShuffle)\n- [ChromaticAberration](https://explore.albumentations.ai/transform/ChromaticAberration)\n- [ColorJitter](https://explore.albumentations.ai/transform/ColorJitter)\n- [Defocus](https://explore.albumentations.ai/transform/Defocus)\n- [Downscale](https://explore.albumentations.ai/transform/Downscale)\n- [Emboss](https://explore.albumentations.ai/transform/Emboss)\n- [Equalize](https://explore.albumentations.ai/transform/Equalize)\n- [FDA](https://explore.albumentations.ai/transform/FDA)\n- [FancyPCA](https://explore.albumentations.ai/transform/FancyPCA)\n- [FromFloat](https://explore.albumentations.ai/transform/FromFloat)\n- [GaussNoise](https://explore.albumentations.ai/transform/GaussNoise)\n- [GaussianBlur](https://explore.albumentations.ai/transform/GaussianBlur)\n- [GlassBlur](https://explore.albumentations.ai/transform/GlassBlur)\n- [HistogramMatching](https://explore.albumentations.ai/transform/HistogramMatching)\n- [HueSaturationValue](https://explore.albumentations.ai/transform/HueSaturationValue)\n- [ISONoise](https://explore.albumentations.ai/transform/ISONoise)\n- [Illumination](https://explore.albumentations.ai/transform/Illumination)\n- [ImageCompression](https://explore.albumentations.ai/transform/ImageCompression)\n- [InvertImg](https://explore.albumentations.ai/transform/InvertImg)\n- [MedianBlur](https://explore.albumentations.ai/transform/MedianBlur)\n- [MotionBlur](https://explore.albumentations.ai/transform/MotionBlur)\n- [MultiplicativeNoise](https://explore.albumentations.ai/transform/MultiplicativeNoise)\n- [Normalize](https://explore.albumentations.ai/transform/Normalize)\n- [PixelDistributionAdaptation](https://explore.albumentations.ai/transform/PixelDistributionAdaptation)\n- [PlanckianJitter](https://explore.albumentations.ai/transform/PlanckianJitter)\n- [PlasmaBrightnessContrast](https://explore.albumentations.ai/transform/PlasmaBrightnessContrast)\n- [PlasmaShadow](https://explore.albumentations.ai/transform/PlasmaShadow)\n- [Posterize](https://explore.albumentations.ai/transform/Posterize)\n- [RGBShift](https://explore.albumentations.ai/transform/RGBShift)\n- [RandomBrightnessContrast](https://explore.albumentations.ai/transform/RandomBrightnessContrast)\n- [RandomFog](https://explore.albumentations.ai/transform/RandomFog)\n- [RandomGamma](https://explore.albumentations.ai/transform/RandomGamma)\n- [RandomGravel](https://explore.albumentations.ai/transform/RandomGravel)\n- [RandomRain](https://explore.albumentations.ai/transform/RandomRain)\n- [RandomShadow](https://explore.albumentations.ai/transform/RandomShadow)\n- [RandomSnow](https://explore.albumentations.ai/transform/RandomSnow)\n- [RandomSunFlare](https://explore.albumentations.ai/transform/RandomSunFlare)\n- [RandomToneCurve](https://explore.albumentations.ai/transform/RandomToneCurve)\n- [RingingOvershoot](https://explore.albumentations.ai/transform/RingingOvershoot)\n- [SaltAndPepper](https://explore.albumentations.ai/transform/SaltAndPepper)\n- [Sharpen](https://explore.albumentations.ai/transform/Sharpen)\n- [ShotNoise](https://explore.albumentations.ai/transform/ShotNoise)\n- [Solarize](https://explore.albumentations.ai/transform/Solarize)\n- [Spatter](https://explore.albumentations.ai/transform/Spatter)\n- [Superpixels](https://explore.albumentations.ai/transform/Superpixels)\n- [TemplateTransform](https://explore.albumentations.ai/transform/TemplateTransform)\n- [TextImage](https://explore.albumentations.ai/transform/TextImage)\n- [ToFloat](https://explore.albumentations.ai/transform/ToFloat)\n- [ToGray](https://explore.albumentations.ai/transform/ToGray)\n- [ToRGB](https://explore.albumentations.ai/transform/ToRGB)\n- [ToSepia](https://explore.albumentations.ai/transform/ToSepia)\n- [UnsharpMask](https://explore.albumentations.ai/transform/UnsharpMask)\n- [ZoomBlur](https://explore.albumentations.ai/transform/ZoomBlur)\n\n### Spatial-level transforms\n\nSpatial-level transforms will simultaneously change both an input image as well as additional targets such as masks, bounding boxes, and keypoints. For volumetric data (volumes and 3D masks), these transforms are applied independently to each slice along the Z-axis (depth dimension), maintaining consistency across the volume. The following table shows which additional targets are supported by each transform:\n\n- Volume: 3D array of shape (D, H, W) or (D, H, W, C) where D is depth, H is height, W is width, and C is number of channels (optional)\n- Mask3D: Binary or multi-class 3D mask of shape (D, H, W) where each slice represents segmentation for the corresponding volume slice\n\n| Transform                                                                                        | Image | Mask | BBoxes | Keypoints | Volume | Mask3D |\n| ------------------------------------------------------------------------------------------------ | :---: | :--: | :----: | :-------: | :----: | :----: |\n| [Affine](https://explore.albumentations.ai/transform/Affine)                                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [AtLeastOneBBoxRandomCrop](https://explore.albumentations.ai/transform/AtLeastOneBBoxRandomCrop) | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [BBoxSafeRandomCrop](https://explore.albumentations.ai/transform/BBoxSafeRandomCrop)             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [CenterCrop](https://explore.albumentations.ai/transform/CenterCrop)                             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [CoarseDropout](https://explore.albumentations.ai/transform/CoarseDropout)                       | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [ConstrainedCoarseDropout](https://explore.albumentations.ai/transform/ConstrainedCoarseDropout) | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Crop](https://explore.albumentations.ai/transform/Crop)                                         | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [CropAndPad](https://explore.albumentations.ai/transform/CropAndPad)                             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [CropNonEmptyMaskIfExists](https://explore.albumentations.ai/transform/CropNonEmptyMaskIfExists) | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [D4](https://explore.albumentations.ai/transform/D4)                                             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [ElasticTransform](https://explore.albumentations.ai/transform/ElasticTransform)                 | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Erasing](https://explore.albumentations.ai/transform/Erasing)                                   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [FrequencyMasking](https://explore.albumentations.ai/transform/FrequencyMasking)                 | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [GridDistortion](https://explore.albumentations.ai/transform/GridDistortion)                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [GridDropout](https://explore.albumentations.ai/transform/GridDropout)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [GridElasticDeform](https://explore.albumentations.ai/transform/GridElasticDeform)               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [HorizontalFlip](https://explore.albumentations.ai/transform/HorizontalFlip)                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Lambda](https://explore.albumentations.ai/transform/Lambda)                                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [LongestMaxSize](https://explore.albumentations.ai/transform/LongestMaxSize)                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [MaskDropout](https://explore.albumentations.ai/transform/MaskDropout)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Morphological](https://explore.albumentations.ai/transform/Morphological)                       | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [NoOp](https://explore.albumentations.ai/transform/NoOp)                                         | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [OpticalDistortion](https://explore.albumentations.ai/transform/OpticalDistortion)               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [OverlayElements](https://explore.albumentations.ai/transform/OverlayElements)                   | ✓     | ✓    |        |           |        |        |\n| [Pad](https://explore.albumentations.ai/transform/Pad)                                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [PadIfNeeded](https://explore.albumentations.ai/transform/PadIfNeeded)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Perspective](https://explore.albumentations.ai/transform/Perspective)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [PiecewiseAffine](https://explore.albumentations.ai/transform/PiecewiseAffine)                   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [PixelDropout](https://explore.albumentations.ai/transform/PixelDropout)                         | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomCrop](https://explore.albumentations.ai/transform/RandomCrop)                             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomCropFromBorders](https://explore.albumentations.ai/transform/RandomCropFromBorders)       | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomCropNearBBox](https://explore.albumentations.ai/transform/RandomCropNearBBox)             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomGridShuffle](https://explore.albumentations.ai/transform/RandomGridShuffle)               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomResizedCrop](https://explore.albumentations.ai/transform/RandomResizedCrop)               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomRotate90](https://explore.albumentations.ai/transform/RandomRotate90)                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomScale](https://explore.albumentations.ai/transform/RandomScale)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomSizedBBoxSafeCrop](https://explore.albumentations.ai/transform/RandomSizedBBoxSafeCrop)   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [RandomSizedCrop](https://explore.albumentations.ai/transform/RandomSizedCrop)                   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Resize](https://explore.albumentations.ai/transform/Resize)                                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Rotate](https://explore.albumentations.ai/transform/Rotate)                                     | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [SafeRotate](https://explore.albumentations.ai/transform/SafeRotate)                             | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [ShiftScaleRotate](https://explore.albumentations.ai/transform/ShiftScaleRotate)                 | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [SmallestMaxSize](https://explore.albumentations.ai/transform/SmallestMaxSize)                   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [ThinPlateSpline](https://explore.albumentations.ai/transform/ThinPlateSpline)                   | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [TimeMasking](https://explore.albumentations.ai/transform/TimeMasking)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [TimeReverse](https://explore.albumentations.ai/transform/TimeReverse)                           | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [Transpose](https://explore.albumentations.ai/transform/Transpose)                               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [VerticalFlip](https://explore.albumentations.ai/transform/VerticalFlip)                         | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n| [XYMasking](https://explore.albumentations.ai/transform/XYMasking)                               | ✓     | ✓    | ✓      | ✓         | ✓      | ✓      |\n\n### 3D transforms\n\n3D transforms operate on volumetric data and can modify both the input volume and associated 3D mask.\n\nWhere:\n\n- Volume: 3D array of shape (D, H, W) or (D, H, W, C) where D is depth, H is height, W is width, and C is number of channels (optional)\n- Mask3D: Binary or multi-class 3D mask of shape (D, H, W) where each slice represents segmentation for the corresponding volume slice\n\n| Transform                                                                      | Volume | Mask3D | Keypoints |\n| ------------------------------------------------------------------------------ | :----: | :----: | :-------: |\n| [CenterCrop3D](https://explore.albumentations.ai/transform/CenterCrop3D)       | ✓      | ✓      | ✓         |\n| [CoarseDropout3D](https://explore.albumentations.ai/transform/CoarseDropout3D) | ✓      | ✓      | ✓         |\n| [CubicSymmetry](https://explore.albumentations.ai/transform/CubicSymmetry)     | ✓      | ✓      | ✓         |\n| [Pad3D](https://explore.albumentations.ai/transform/Pad3D)                     | ✓      | ✓      | ✓         |\n| [PadIfNeeded3D](https://explore.albumentations.ai/transform/PadIfNeeded3D)     | ✓      | ✓      | ✓         |\n| [RandomCrop3D](https://explore.albumentations.ai/transform/RandomCrop3D)       | ✓      | ✓      | ✓         |\n\n## A few more examples of **augmentations**\n\n### Semantic segmentation on the Inria dataset\n\n![inria](https://habrastorage.org/webt/su/wa/np/suwanpeo6ww7wpwtobtrzd_cg20.jpeg)\n\n### Medical imaging\n\n![medical](https://habrastorage.org/webt/1i/fi/wz/1ifiwzy0lxetc4nwjvss-71nkw0.jpeg)\n\n### Object detection and semantic segmentation on the Mapillary Vistas dataset\n\n![vistas](https://habrastorage.org/webt/rz/-h/3j/rz-h3jalbxic8o_fhucxysts4tc.jpeg)\n\n### Keypoints augmentation\n\n<img src=\"https://habrastorage.org/webt/e-/6k/z-/e-6kz-fugp2heak3jzns3bc-r8o.jpeg\" width=100%>\n\n## Benchmarking results\n\n### System Information\n\n- Platform: macOS-15.0.1-arm64-arm-64bit\n- Processor: arm\n- CPU Count: 10\n- Python Version: 3.12.7\n\n### Benchmark Parameters\n\n- Number of images: 1000\n- Runs per transform: 10\n- Max warmup iterations: 1000\n\n### Library Versions\n\n- albumentations: 1.4.20\n- augly: 1.0.0\n- imgaug: 0.4.0\n- kornia: 0.7.3\n- torchvision: 0.20.0\n\n## Performance Comparison\n\nNumber - is the number of uint8 RGB images processed per second on a single CPU core. Higher is better.\n\n| Transform         | albumentations<br>1.4.20   | augly<br>1.0.0   | imgaug<br>0.4.0   | kornia<br>0.7.3   | torchvision<br>0.20.0   |\n|:------------------|:---------------------------|:-----------------|:------------------|:------------------|:------------------------|\n| HorizontalFlip    | **8618 ± 1233**            | 4807 ± 818       | 6042 ± 788        | 390 ± 106         | 914 ± 67                |\n| VerticalFlip      | **22847 ± 2031**           | 9153 ± 1291      | 10931 ± 1844      | 1212 ± 402        | 3198 ± 200              |\n| Rotate            | **1146 ± 79**              | 1119 ± 41        | 1136 ± 218        | 143 ± 11          | 181 ± 11                |\n| Affine            | 682 ± 192                  | -                | **774 ± 97**      | 147 ± 9           | 130 ± 12                |\n| Equalize          | **892 ± 61**               | -                | 581 ± 54          | 152 ± 19          | 479 ± 12                |\n| RandomCrop80      | **47341 ± 20523**          | 25272 ± 1822     | 11503 ± 441       | 1510 ± 230        | 32109 ± 1241            |\n| ShiftRGB          | **2349 ± 76**              | -                | 1582 ± 65         | -                 | -                       |\n| Resize            | **2316 ± 166**             | 611 ± 78         | 1806 ± 63         | 232 ± 24          | 195 ± 4                 |\n| RandomGamma       | **8675 ± 274**             | -                | 2318 ± 269        | 108 ± 13          | -                       |\n| Grayscale         | **3056 ± 47**              | 2720 ± 932       | 1681 ± 156        | 289 ± 75          | 1838 ± 130              |\n| RandomPerspective | 412 ± 38                   | -                | **554 ± 22**      | 86 ± 11           | 96 ± 5                  |\n| GaussianBlur      | **1728 ± 89**              | 242 ± 4          | 1090 ± 65         | 176 ± 18          | 79 ± 3                  |\n| MedianBlur        | **868 ± 60**               | -                | 813 ± 30          | 5 ± 0             | -                       |\n| MotionBlur        | **4047 ± 67**              | -                | 612 ± 18          | 73 ± 2            | -                       |\n| Posterize         | **9094 ± 301**             | -                | 2097 ± 68         | 430 ± 49          | 3196 ± 185              |\n| JpegCompression   | **918 ± 23**               | 778 ± 5          | 459 ± 35          | 71 ± 3            | 625 ± 17                |\n| GaussianNoise     | 166 ± 12                   | 67 ± 2           | **206 ± 11**      | 75 ± 1            | -                       |\n| Elastic           | 201 ± 5                    | -                | **235 ± 20**      | 1 ± 0             | 2 ± 0                   |\n| Clahe             | **454 ± 22**               | -                | 335 ± 43          | 94 ± 9            | -                       |\n| CoarseDropout     | **13368 ± 744**            | -                | 671 ± 38          | 536 ± 87          | -                       |\n| Blur              | **5267 ± 543**             | 246 ± 3          | 3807 ± 325        | -                 | -                       |\n| ColorJitter       | **628 ± 55**               | 255 ± 13         | -                 | 55 ± 18           | 46 ± 2                  |\n| Brightness        | **8956 ± 300**             | 1163 ± 86        | -                 | 472 ± 101         | 429 ± 20                |\n| Contrast          | **8879 ± 1426**            | 736 ± 79         | -                 | 425 ± 52          | 335 ± 35                |\n| RandomResizedCrop | **2828 ± 186**             | -                | -                 | 287 ± 58          | 511 ± 10                |\n| Normalize         | **1196 ± 56**              | -                | -                 | 626 ± 40          | 519 ± 12                |\n| PlankianJitter    | **2204 ± 385**             | -                | -                 | 813 ± 211         | -                       |\n\n## Contributing\n\nTo create a pull request to the repository, follow the documentation at [CONTRIBUTING.md](CONTRIBUTING.md)\n\n![https://github.com/albuemntations-team/albumentation/graphs/contributors](https://contrib.rocks/image?repo=albumentations-team/albumentations)\n\n## Community\n\n- [LinkedIn](https://www.linkedin.com/company/albumentations/)\n- [Twitter](https://twitter.com/albumentations)\n- [Discord](https://discord.gg/AKPrrDYNAt)\n\n## Citing\n\nIf you find this library useful for your research, please consider citing [Albumentations: Fast and Flexible Image Augmentations](https://www.mdpi.com/2078-2489/11/2/125):\n\n```bibtex\n@Article{info11020125,\n    AUTHOR = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},\n    TITLE = {Albumentations: Fast and Flexible Image Augmentations},\n    JOURNAL = {Information},\n    VOLUME = {11},\n    YEAR = {2020},\n    NUMBER = {2},\n    ARTICLE-NUMBER = {125},\n    URL = {https://www.mdpi.com/2078-2489/11/2/125},\n    ISSN = {2078-2489},\n    DOI = {10.3390/info11020125}\n}\n```\n"
        },
        {
          "name": "albumentations",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yaml",
          "type": "blob",
          "size": 0.7138671875,
          "content": "coverage:\n  status:\n    project:\n      default:\n        target: auto\n        threshold: 1%  # Adding threshold for more flexibility\n    patch:\n      default:\n        target: auto\n        threshold: 1%  # Adding threshold for patch coverage\n\n  ignore:\n    - \"tests/\"\n    - \"tools/\"\n    - \"benchmark/\"\n\nflag_management:\n  individual_flags:\n    - name: smart-tests\n      carryforward: true\n      carryforward_mode: \"labels\"\n      statuses:\n        - type: \"project\"\n        - type: \"patch\"\n\ncli:\n  plugins:\n    pycoverage:\n      report_type: \"json\"\n\ncodecov:\n  require_ci_to_pass: false\n\n# Adding explicit paths to include\nparsers:\n  gcov:\n    branch_detection:\n      conditional: yes\n      loop: yes\n      method: no\n      macro: no\n"
        },
        {
          "name": "conda.recipe",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 5.85546875,
          "content": "[build-system]\nbuild-backend = \"setuptools.build_meta\"\n\nrequires = [ \"setuptools>=45\", \"wheel\" ]\n\n[project]\nname = \"albumentations\"\n\nversion = \"2.0.0\"\n\ndescription = \"Fast, flexible, and advanced augmentation library for deep learning, computer vision, and medical imaging. Albumentations offers a wide range of transformations for both 2D (images, masks, bboxes, keypoints) and 3D (volumes, volumetric masks) data, with optimized performance and seamless integration into ML workflows.\"\nreadme = \"README.md\"\nkeywords = [\n  \"2D augmentation\",\n  \"3D augmentation\",\n  \"aerial photography\",\n  \"anomaly detection\",\n\n  \"artificial intelligence\",\n\n  \"autonomous driving\",\n  \"bounding boxes\",\n  # Core Computer Vision Tasks\n  \"classification\",\n  # Technical Domains\n  \"computer vision\",\n  \"computer vision library\",\n  \"data augmentation\",\n\n  \"data preprocessing\",\n  \"data science\",\n  \"deep learning\",\n  \"deep learning library\",\n\n  \"depth estimation\",\n  \"face recognition\",\n  # Performance & Features\n  \"fast augmentation\",\n  # Data Types & Processing\n  \"image augmentation\",\n  \"image processing\",\n  \"image transformation\",\n  # Data Structures\n  \"images\",\n  \"instance segmentation\",\n  \"keras\",\n  \"keypoint detection\",\n  \"keypoints\",\n  \"machine learning\",\n  \"machine learning tools\",\n  \"masks\",\n  # Application Domains\n  \"medical imaging\",\n  \"microscopy\",\n  \"object counting\",\n  \"object detection\",\n  \"optimized performance\",\n  \"panoptic segmentation\",\n  \"pose estimation\",\n  # Development\n  \"python library\",\n  # ML Frameworks\n  \"pytorch\",\n  \"quality inspection\",\n\n  \"real-time processing\",\n\n  \"robotics vision\",\n  \"satellite imagery\",\n  \"semantic segmentation\",\n  \"tensorflow\",\n  \"volumes\",\n  \"volumetric data\",\n  \"volumetric masks\",\n\n]\nlicense = { file = \"LICENSE\" }\n\nmaintainers = [ { name = \"Vladimir Iglovikov\" } ]\n\nauthors = [ { name = \"Vladimir Iglovikov\" } ]\nrequires-python = \">=3.9\"\n\nclassifiers = [\n  # Development Status\n  \"Development Status :: 5 - Production/Stable\",\n\n  # Intended Audience\n  \"Intended Audience :: Developers\",\n  \"Intended Audience :: Healthcare Industry\",    # valid for medical applications\n  \"Intended Audience :: Information Technology\",\n\n  \"Intended Audience :: Science/Research\",\n  # License\n  \"License :: OSI Approved :: MIT License\",\n\n  # Operating System\n  \"Operating System :: OS Independent\",\n\n  # Python Versions\n  \"Programming Language :: Python\",\n  \"Programming Language :: Python :: 3 :: Only\",\n  \"Programming Language :: Python :: 3.9\",\n  \"Programming Language :: Python :: 3.10\",\n  \"Programming Language :: Python :: 3.11\",\n  \"Programming Language :: Python :: 3.12\",\n\n  \"Programming Language :: Python :: 3.13\",\n  # Topics - Scientific\n  \"Topic :: Scientific/Engineering\",\n  \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n  \"Topic :: Scientific/Engineering :: Astronomy\",\n  \"Topic :: Scientific/Engineering :: Atmospheric Science\",\n\n  \"Topic :: Scientific/Engineering :: Bio-Informatics\",\n  \"Topic :: Scientific/Engineering :: Image Processing\",\n  \"Topic :: Scientific/Engineering :: Physics\",\n  \"Topic :: Scientific/Engineering :: Visualization\",\n  # Topics - Software Development\n  \"Topic :: Software Development :: Libraries\",\n  \"Topic :: Software Development :: Libraries :: Python Modules\",\n\n  # Typing\n  \"Typing :: Typed\",\n]\n\ndynamic = [ \"dependencies\" ]\noptional-dependencies.hub = [ \"huggingface-hub\" ]\noptional-dependencies.pytorch = [ \"torch\" ]\n\noptional-dependencies.text = [ \"pillow\" ]\nurls.Homepage = \"https://albumentations.ai\"\n\n[tool.setuptools]\npackages = { find = { include = [\n  \"albumentations*\",\n], exclude = [\n  \"tests\",\n  \"tools\",\n  \"benchmark\",\n] } }\n\npackage-data = { albumentations = [ \"*.txt\", \"*.md\" ] }\n\n[tool.setuptools.exclude-package-data]\n\"*\" = [ \"tests*\", \"tools*\", \"benchmark*\", \"conda.recipe*\" ]\n\n[tool.ruff]\n# Exclude a variety of commonly ignored directories.\ntarget-version = \"py39\"\n\nline-length = 120\nindent-width = 4\n\n# Assume Python 3.9\nexclude = [\n  \".bzr\",\n  \".direnv\",\n  \".eggs\",\n  \".git\",\n  \".git-rewrite\",\n  \".hg\",\n  \".ipynb_checkpoints\",\n  \".mypy_cache\",\n  \".nox\",\n  \".pants.d\",\n  \".pyenv\",\n  \".pytest_cache\",\n  \".pytype\",\n  \".ruff_cache\",\n  \".svn\",\n  \".tox\",\n  \".venv\",\n  \".vscode\",\n  \"__pypackages__\",\n  \"_build\",\n  \"benchmark\",\n  \"buck-out\",\n  \"build\",\n  \"dist\",\n  \"node_modules\",\n  \"setup.py\",\n  \"site\",\n  \"site-packages\",\n  \"tests\",\n  \"tools\",\n  \"venv\",\n]\n\nformat.indent-style = \"space\"\n# Like Black, respect magic trailing commas.\nformat.quote-style = \"double\"\n# Like Black, indent with spaces, rather than tabs.\nformat.line-ending = \"auto\"\nformat.skip-magic-trailing-comma = false\n# Like Black, automatically detect the appropriate line ending.\nlint.select = [ \"ALL\" ]\nlint.ignore = [\n  \"ANN001\",\n  \"ANN204\",\n  \"ANN401\",\n  \"ARG001\",\n  \"ARG002\",\n  \"B008\",\n  \"B027\",\n  \"D100\",\n  \"D101\",\n  \"D102\",\n  \"D103\",\n  \"D104\",\n  \"D105\",\n  \"D106\",\n  \"D107\",\n  \"D205\",\n  \"D415\",\n  \"EM101\",\n  \"EM102\",\n  \"F403\",\n  \"FBT001\",\n  \"FBT002\",\n  \"FBT003\",\n  \"G004\",\n  \"PLR0911\",\n  \"PLR0913\",\n  \"PLR2004\",\n  \"PTH123\",\n  \"S311\",\n  \"S608\",\n  \"TC001\",\n  \"TC002\",\n  \"TC003\",\n  \"TRY003\",\n]\n\n# Allow fix for all enabled rules (when `--fix`) is provided.\n\nlint.explicit-preview-rules = true\nlint.fixable = [ \"ALL\" ]\nlint.unfixable = [  ]\n# Allow unused variables when underscore-prefixed.\nlint.dummy-variable-rgx = \"^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\"\n# Like Black, use double quotes for strings.\nlint.pydocstyle.convention = \"google\"\n\n[tool.mypy]\nplugins = [ \"pydantic.mypy\" ]\n\npython_version = \"3.9\"\nignore_missing_imports = true\nfollow_imports = \"silent\"\nwarn_redundant_casts = true\nwarn_unused_ignores = true\ndisallow_any_generics = true\ncheck_untyped_defs = true\nno_implicit_reexport = true\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = true\n\n[tool.albumentations.maintainers]\nemeritus = [\n  \"Alexander Buslaev\",\n  \"Alex Parinov\",\n  \"Eugene Khvedchenya\",\n  \"Mikhail Druzhinin\",\n]\n\n[tool.pydantic-mypy]\ninit_forbid_extra = true\ninit_typed = true\nwarn_required_dynamic_aliases = true\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.2060546875,
          "content": "deepdiff>=8.0.1\neval-type-backport\npre_commit>=3.5.0\npytest>=8.3.3\npytest_cov>=5.0.0\npytest_mock>=3.14.0\nrequests>=2.31.0\nscikit-image\ntomli>=2.0.1\ntorch>=2.3.1\ntorchvision>=0.18.1\ntypes-PyYAML\ntypes-setuptools\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.41796875,
          "content": "import re\n\nfrom pkg_resources import DistributionNotFound, get_distribution\nfrom setuptools import setup, find_packages\n\nINSTALL_REQUIRES = [\n    \"numpy>=1.24.4\",\n    \"scipy>=1.10.0\",\n    \"PyYAML\",\n    \"typing-extensions>=4.9.0; python_version<'3.10'\",\n    \"pydantic>=2.9.2\",\n    \"albucore==0.0.23\",\n    \"eval-type-backport; python_version<'3.10'\",\n]\n\nMIN_OPENCV_VERSION = \"4.9.0.80\"\n\nCHOOSE_INSTALL_REQUIRES = [\n    (\n        (f\"opencv-python>={MIN_OPENCV_VERSION}\", f\"opencv-contrib-python>={MIN_OPENCV_VERSION}\", f\"opencv-contrib-python-headless>={MIN_OPENCV_VERSION}\"),\n        f\"opencv-python-headless>={MIN_OPENCV_VERSION}\",\n    ),\n]\n\ndef choose_requirement(mains: tuple[str, ...], secondary: str) -> str:\n    chosen = secondary\n    for main in mains:\n        try:\n            name = re.split(r\"[!<>=]\", main)[0]\n            get_distribution(name)\n            chosen = main\n            break\n        except DistributionNotFound:\n            pass\n    return chosen\n\ndef get_install_requirements(install_requires: list[str], choose_install_requires: list[tuple[tuple[str, ...], str]]) -> list[str]:\n    for mains, secondary in choose_install_requires:\n        install_requires.append(choose_requirement(mains, secondary))\n    return install_requires\n\nsetup(\n    packages=find_packages(exclude=[\"tests\", \"tools\", \"benchmark\"], include=['albumentations*']),\n    install_requires=get_install_requirements(INSTALL_REQUIRES, CHOOSE_INSTALL_REQUIRES),\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}