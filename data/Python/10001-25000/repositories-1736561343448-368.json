{
  "metadata": {
    "timestamp": 1736561343448,
    "page": 368,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openai/DALL-E",
      "stars": 10818,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.13671875,
          "content": "# OS specific\n*.DS_Store\n\n# Python\n/build\n/dist\n__pycache__\n*.ipynb_checkpoints\n*.egg-info\n\n# Vim\n*.vim\n*.swk\n*.swl\n*.swm\n*.swn\n*.swo\n*.swp\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.3720703125,
          "content": "Modified MIT License\n\nSoftware Copyright (c) 2021 OpenAI\n\nWe don’t claim ownership of the content you create with the DALL-E discrete VAE, so it is yours to\ndo with as you please. We only ask that you use the model responsibly and clearly indicate that it\nwas used.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and\nassociated documentation files (the \"Software\"), to deal in the Software without restriction,\nincluding without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense,\nand/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included\nin all copies or substantial portions of the Software.\nThe above copyright notice and this permission notice need not be included\nwith content created by the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\nINCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\nBE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE\nOR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.4619140625,
          "content": "# Overview\n\n[[Blog]](https://openai.com/blog/dall-e/) [[Paper]](https://arxiv.org/abs/2102.12092) [[Model Card]](model_card.md) [[Usage]](notebooks/usage.ipynb)\n\nThis is the official PyTorch package for the discrete VAE used for DALL·E. The transformer used to generate the images from the text is not part of this code release.\n\n# Installation\n\nBefore running [the example notebook](notebooks/usage.ipynb), you will need to install the package using\n\n\tpip install DALL-E\n"
        },
        {
          "name": "dall_e",
          "type": "tree",
          "content": null
        },
        {
          "name": "model_card.md",
          "type": "blob",
          "size": 2.0166015625,
          "content": "# Model Card: DALL·E dVAE\n\nFollowing [Model Cards for Model Reporting (Mitchell et al.)](https://arxiv.org/abs/1810.03993) and [Lessons from\nArchives (Jo & Gebru)](https://arxiv.org/pdf/1912.10389.pdf), we're providing some information about about the discrete\nVAE (dVAE) that was used to train DALL·E.\n\n## Model Details\n\nThe dVAE was developed by researchers at OpenAI to reduce the memory footprint of the transformer trained on the\ntext-to-image generation task. The details involved in training the dVAE are described in [the paper][dalle_paper]. This\nmodel card describes the first version of the model, released in February 2021. The model consists of a convolutional\nencoder and decoder whose architectures are described [here](dall_e/encoder.py) and [here](dall_e/decoder.py), respectively.\nFor questions or comments about the models or the code release, please file a Github issue.\n\n## Model Use\n\n### Intended Use\n\nThe model is intended for others to use for training their own generative models.\n\n### Out-of-Scope Use Cases\n\nThis model is inappropriate for high-fidelity image processing applications. We also do not recommend its use as a\ngeneral-purpose image compressor.\n\n## Training Data\n\nThe model was trained on publicly available text-image pairs collected from the internet. This data consists partly of\n[Conceptual Captions][cc] and a filtered subset of [YFCC100M][yfcc100m]. We used a subset of the filters described in\n[Sharma et al.][cc_paper] to construct this dataset; further details are described in [our paper][dalle_paper]. We will\nnot be releasing the dataset.\n\n## Performance and Limitations\n\nThe heavy compression from the encoding process results in a noticeable loss of detail in the reconstructed images. This\nrenders it inappropriate for applications that require fine-grained details of the image to be preserved.\n\n[dalle_paper]: https://arxiv.org/abs/2102.12092\n[cc]: https://ai.google.com/research/ConceptualCaptions\n[cc_paper]: https://www.aclweb.org/anthology/P18-1238/\n[yfcc100m]: http://projects.dfki.uni-kl.de/yfcc100m/\n"
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0595703125,
          "content": "Pillow\nblobfile\nmypy\nnumpy\npytest\nrequests\ntorch\ntorchvision\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.556640625,
          "content": "from setuptools import setup\n\ndef parse_requirements(filename):\n\tlines = (line.strip() for line in open(filename))\n\treturn [line for line in lines if line and not line.startswith(\"#\")]\n\nsetup(name='DALL-E',\n        version='0.1',\n        description='PyTorch package for the discrete VAE used for DALL·E.',\n        url='http://github.com/openai/DALL-E',\n        author='Aditya Ramesh',\n        author_email='aramesh@openai.com',\n        license='BSD',\n        packages=['dall_e'],\n        install_requires=parse_requirements('requirements.txt'),\n        zip_safe=True)\n"
        }
      ]
    }
  ]
}