{
  "metadata": {
    "timestamp": 1736561355061,
    "page": 386,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/ParlAI",
      "stars": 10498,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.1455078125,
          "content": "# .coveragerc to control coverage.py\n[run]\nbranch = False\n\n# make sure we report these folders\nsource =\n    .\n\n# skip these files\nomit =\n    .eggs/*\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.2431640625,
          "content": "[flake8]\nexclude = .git,__pycache__,parlai_internal,legacy_agents,task_config.py,.eggs\nextend-ignore =\n    E741\n    E501\n    D107\n    D105\n    E203\n    E266\n    W503\n    F403\n    F541\n    E305\nselect = C,E,F,W,B,B950,RST,PAI,BLK\n\nmax-line-length=80\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.6474609375,
          "content": "# from the tutorial\nparlai/agents/parrot/\n\n# these are autogenerated by streaming datasets\n*.lengths\n\n# MISC\n*.tmp\n.watchmanconfig\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\n.vector_cache/\nenv/\nbuild/\ndata/\ndata\nlogs/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nnode_modules/\nparts/\nsdist/\nvar/\nconvai2_submissions/\nparlai_internal/\nparlai_external/\nparlai_fb/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n.hypothesis/\ntest-results/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n# autogenerated files\ndocs/source/*.inc\ndocs/source/agent_refs\n\n# PyBuilder\ntarget/\n\n# IPython Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# dotenv\n.env\n\n#emacs\n*~\n\\#*\\#\n.\\#*\n\n# virtualenv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n\n# Rope project settings\n.ropeproject\n\n# OS X files\n.DS_Store\n\n# Editor temporaries\n*.swn\n*.swo\n*.swp\n*~\n\n# MTurk\ntmp/\n*.pickle\n# Heroku things\nheroku-cli-*\n*.db\n# Hydra\noutputs/\n# Mephisto\n_generated/\n\n# IntelliJ IDEA\n.idea\n*.iml\n\n# VSCode\n*.vscode\n\n# mypy cache\n.mypy_cache\n\n# npm compilation\nparlai/crowdsourcing/**/package-lock.json\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.3095703125,
          "content": "repos:\n-   repo: https://github.com/psf/black\n    rev: 22.3.0\n    hooks:\n    -   id: black\n        language_version: python3\n-   repo: local\n    hooks:\n    -   id: git-secrets\n        language: script\n        entry: .github/scripts/git-secrets --pre_commit_hook\n        name: git-secrets\n        require_serial: true\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2763671875,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.966796875,
          "content": "# Contributing to ParlAI\n\nWhile we are seeding this project with an initial set of popular tasks and a few\nmodels and examples, ongoing contributions from the research community are\ndesired to increase the pool of tasks, models, and baselines.\n\n\n## Pull Requests\nWe actively welcome your pull requests.\n\n1. Fork the repo and then clone the forked repository. (See this [github guide](https://guides.github.com/activities/forking/) on forking for more info).\n   **If you have already cloned the repo directly and committed changes, follow the steps in the [section below](#moving-changes-youve-committed-to-a-fork)**\n2. Create your branch from `main`. Set up your environment\n   and run `pre-commit install` once.\n3. Make your changes\n4. If you've added code that should be tested, [add tests](http://parl.ai/docs/tutorial_tests.html).\n5. If you've changed APIs, update the documentation.\n6. Autoformat and lint your code (`bash autoformat.sh`)\n7. (Optional) Ensure the test suite passes. Run `python -m pytest -m unit`.\n8. If you've added a new dataset, you should also run\n   `python -m pytest -m data`. Copy-paste the output into a comment in your PR.\n9. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n10. Link [CircleCI](https://circleci.com/vcs-authorize/) to your github account\n   if you haven't done so previously (and make sure the CircleCI tests run\n   successfully on the PR after you push your changes).\n11. Push your changes!\n12. Once the PR is accepted and CI is passing, we will merge the PR for you.\n\n### Moving changes you've committed to a fork\n1. Fork the repo\n2. In your local repo, rename your origin remote to upstream\n   ```\n   git remote rename origin upstream\n   ```\n3. Point origin to the forked repo (instead of to the original repo)\n   ```\n   git remote add origin git@github...<FORK>\n   ```\n4. Fetch from the new origin\n   ```\n   git fetch origin\n   ```\n5. Make your local branch track the remote branch (of the forked repo)\n   ```\n   git branch --set-upstream-to origin/main main\n   ```\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\nWe use GitHub issues for general feature discussion, Q&A and public bugs tracking.\nPlease ensure your description is clear and has sufficient instructions to be able to\nreproduce the issue or understand the problem.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## Coding Style\nWe try to follow the PEP style guidelines and encourage you to as well. You\nshould run the `lint_changed.sh` script before you submit.\n\n## License\nBy contributing to ParlAI, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.189453125,
          "content": "# Copyright (c) Meta, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\nFROM nvidia/cuda:11.1.1-cudnn8-devel-ubuntu18.04\n\n# Installing the required packages\nRUN apt update -y\nRUN apt install -y git curl\n\n# Installing Anaconda\nWORKDIR /root\nRUN curl https://repo.anaconda.com/archive/Anaconda3-2021.05-Linux-x86_64.sh -o anaconda_installer.sh\nRUN bash anaconda_installer.sh -b -p\nENV PATH=\"/root/anaconda3/bin:$PATH\"\n\n# Installing recommmended pre-requirements\nRUN conda install \"pytorch<1.13.0,>=1.4.0\" torchvision torchaudio -c pytorch-lts -c nvidia\nRUN pip install spacy==3.2.4 tokenizers pandas transformers fairseq contractions boto3==1.17.95 botocore==1.20.95\n\n# Configuring packages for English\nRUN python -m spacy download en_core_web_sm\nRUN echo \"import nltk; nltk.download(\\\"stopwords\\\"); nltk.download(\\\"punkt\\\")\" > nltk_dl_script.py\nRUN python nltk_dl_script.py\n\n# Download the ParlAI Github repo\nRUN git clone https://github.com/facebookresearch/ParlAI.git ~/ParlAI\n\n# Running ParlAI install\nRUN cd ~/ParlAI && \\\n    pip install -r requirements.txt && \\\n    python setup.py develop\n\nCMD [\"parlai\", \"party\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.060546875,
          "content": "MIT License\n\nCopyright (c) Facebook, Inc. and its affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "NEWS.md",
          "type": "blob",
          "size": 10.37890625,
          "content": "## News\n\n**Archive Information**\nWe are now making most of our major announcements on [Twitter](https://twitter.com/parlai_parley) and in our\n[Release Notes](https://github.com/facebookresearch/ParlAI/releases).\n\n### Older news\n\n2020-07-21: We have added a new `parlai` super command, complete with [autocompletion](https://parl.ai/docs/tutorial_tipsntricks.html#command-line-tool).\n\n2020-07-17: We've added a new tutorial showing how to [speed up training](https://parl.ai/docs/tutorial_fast.html).\n\n2020-04-28: [BlenderBot](https://parl.ai/projects/recipes/) has been released, including 2.7B and 9.4B parameter models. It received some attention in the media, including [Engadget](https://www.engadget.com/facebook-chatbot-ai-open-source-blender-150001320.html), [Technology Review](https://www.technologyreview.com/2020/04/29/1000795/facebook-ai-chatbot-blender-beats-google-meena/), [Fortune](https://fortune.com/2020/04/29/facebook-creates-the-most-human-chatbot-yet/), and [Wired](https://www.wired.com/story/new-chatbot-tries-artificial-empathy/).\n\n2020-02-04: [GPT2 fine-tuning for dialogue](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents/hugging_face)  now supported in ParlAI!\n\n2020-01-17: [All-in-One Image-Grounded Conversational Agents project](https://twitter.com/parlai_parley/status/1218204771859017732) built in ParlAI \n\n2020-01-15: [Seb Ruder's 10 ML & NLP Research Highlights of 2019 post](https://ruder.io/research-highlights-2019/) mentions at least two works built with ParlAI.\n\n2019-12-19: [Amazon's TopicChat dataset uses ParlAI](https://twitter.com/parlai_parley/status/1207716855525367808).\n\n2019-12-11: [OneCommon Corpus is now available in ParlAI](https://twitter.com/futsaludy/status/1204661465967259648). Thanks to our colleague Takato Yamazaki\n\n2019-11-10: [Dialogue unlikelihood project](https://parl.ai/projects/dialogue_unlikelihood/) for improving consistency in dialogue generation. \n\n2019-11-09: The [Gender bias project page](https://parl.ai/projects/genderation_bias/) mitigates bias in dialogue generation.\n\n2019-11-09: The [Dodeca dialogue project page](https://parl.ai/projects/dodecadialogue/) is up with paper and leaderboard -- multi-tasking on many dialogue tasks with strong results!\n\n2019-09-16: The [Dialogue Safety project page](https://parl.ai/projects/dialogue_safety/) is updated with pretrained models, data, and an interactive demonstration.\n\n2019-06-12: The [Personality-Captions project page](http://parl.ai/projects/personality_captions/) is updated with pretrained models, specialized model code, and an interactive demo.\n\n2019-06-12: Added [HotpotQA](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks/quac) as another dataset.\n\n2019-05-15: Added [QuAC](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks/quac), Question Answering in Context dataset, and [COQA](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks/coqa), Conversational Question Answering Challenge datasets.\n\n2019-05-03: The [What makes a good Conversation project page](https://parl.ai/projects/controllable_dialogue/) is now available with pretrained models.\n\n2019-03-15: The [Wizard of Wikipedia project page](http://parl.ai/projects/wizard_of_wikipedia/) is updated with pretrained models and specialized model code.\n\n2019-03-09: Added [LIGHT](http://parl.ai/projects/light) text adventure game research platform for learning to speak and act. [[press]](https://venturebeat.com/2019/03/08/facebook-ai-researchers-create-a-text-based-adventure-to-study-how-ai-speak-and-act/)\n\n2019-03-06: Added [Self-feeding Chatbot](http://parl.ai/projects/self_feeding) for leveraging user textual feedback to improve the chatbot's abilities. [[press]](https://venturebeat.com/2019/01/17/facebook-and-stanford-researchers-design-a-chatbot-that-learns-from-its-mistakes/)\n\n2019-02-07: Added [BERT Ranker agents](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents/bert_ranker), several variations of a ranking model based on the pretrained language model BERT.\n\n2019-01-16: ParlAI has been relicensed under the MIT open source license.\n\n2018-12-13: Added [Daily Dialog](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/dailydialog/agents.py), an open-domain daily dialogue dataset.\n\n2018-11-05: Added [Wizard of Wikipedia](http://parl.ai/projects/wizard_of_wikipedia/), a dataset for knowledge-powered conversation.\n\n2018-11-02: Added [Image-Chat](https://klshuster.github.io/image_chat/), a dataset for engaging personality-conditioned dialogue grounded in images.\n\n2018-10-25: Added [Personality-Captions](https://arxiv.org/abs/1810.10665), a dataset for engaging image captioning via personality.\n\n2018-08-29: Added new cleaner version of seq2seq model with new TorchAgent parent class, along with folder (parlai/legacy_agents) for deprecated model code\n\n2018-07-17: Added [Qangaroo](http://qangaroo.cs.ucl.ac.uk/) (a.k.a. WikiHop and MedHop), two reading comprehension datasets with multiple hops, and [SQuAD 2](https://rajpurkar.github.io/SQuAD-explorer/).\n\n2018-05-22: Two new tasks added: [COCO Image Captioning](http://cocodataset.org/#captions-2015) and [Flickr30k Entities](http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/)\n\n2018-04-13: [NIPS ConvAI2 competition!](http://convai.io/) Train Dialogue Agents to chat about personal interests and get to know their dialogue partner -- using the PersonaChat dataset as a training source, with data and baseline code in ParlAI. Competition starts now! Ends September 1st.\n\n2018-03-13: Added [ParlAI-Messenger](http://parl.ai/static/docs/messenger.html), a new method for connecting human agents to a world in ParlAI using Facebook Messenger. Host your bots on Facebook Messenger to expose them to a broad audience!\n\n2018-03-05: Added [Multimodal Low-Rank Bilinear Attention Network (MLB)](https://github.com/facebookresearch/ParlAI/blob/main/parlai/agents/mlb_vqa/mlb_vqa.py) model for VQA V1 and V2 tasks, adapted from an implementation [here](https://github.com/Cadene/vqa.pytorch) based on [this paper](https://arxiv.org/abs/1610.04325). To use it, please follow the instructions [in the agent file](https://github.com/facebookresearch/ParlAI/blob/main/parlai/agents/mlb_vqa/mlb_vqa.py).\n\n2018-02-12: Added a [Wikipedia task](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/wikipedia/agents.py), which provides a dump of Wikipedia articles from 2/3/2018.\n\n2018-02-07: Added a [language model](https://github.com/facebookresearch/ParlAI/blob/main/parlai/agents/language_model/language_model.py) adapted from [this](https://github.com/pytorch/examples/tree/main/word_language_model) Pytorch model to parlai/agents.\n\n2018-01-23: Several new tasks added: [SNLI](https://nlp.stanford.edu/projects/snli/), [MultiNLI](https://arxiv.org/abs/1704.05426), [COPA](http://people.ict.usc.edu/~gordon/copa.html), [NarrativeQA](https://github.com/deepmind/narrativeqa), Twitter and [Persona-Chat](https://arxiv.org/abs/1801.07243).\n\n2017-11-30: Several new tasks added: [SCAN](https://github.com/brendenlake/SCAN), [ConvAI](http://convai.io/data/), [NVLR](http://lic.nlp.cornell.edu/nlvr/) and [ISWLT14](http://wit3.fbk.eu).\n\n2017-10-19: [ParlAI Request For Proposals: Winners Announced!](https://research.fb.com/announcing-the-winners-of-the-facebook-parlai-research-awards/)\n\n2017-10-13: [New model added: Fairseq-py](https://github.com/facebookresearch/fairseq-py)\n\n2017-10-12: [New task added: Stanford's MutualFriends](https://stanfordnlp.github.io/cocoa/)\n\n2017-09-22: [New task added: babi+](https://www.researchgate.net/publication/319128941_Challenging_Neural_Dialogue_Models_with_Natural_Data_Memory_Networks_Fail_on_Incremental_Phenomena)\n\n2017-09-21: [New task added: WMT En-De training set, with more WMT tasks on the way](https://nlp.stanford.edu/projects/nmt/)\n\n2017-08-25: [New task added: Deal or No Deal](https://github.com/facebookresearch/end-to-end-negotiator)\n\n2017-08-15: [New task added: CLEVR](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/task_list.py)\n\n2017-07-20: [ParlAI Request For Proposals: Funding university teams - 7 awards are available - deadline Aug 25](https://research.fb.com/programs/research-awards/proposals/parlai/)\n\n2017-07-20: [added building an (seq2seq) agent tutorial](http://www.parl.ai/static/docs/seq2seq_tutorial.html)\n\n2017-07-12: [Several new tasks added: MS Marco, TriviaQA, InsuranceQA, personalized-dialog and MNIST_QA](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/task_list.py)\n\n2017-06-27: [ExecutableWorld class for interactive worlds with dialog](https://github.com/facebookresearch/ParlAI/pull/170)\n\n2017-06-21: [MTurk now supports multiple assignments per HIT](https://github.com/facebookresearch/ParlAI/pull/156)\n\n2017-06-20: [updated MTurk tutorial to reflect new design](http://parl.ai/static/docs/mturk.html)\n\n2017-06-20: [MTurk now uses general world and agent classes](https://github.com/facebookresearch/ParlAI/pull/128)\n\n2017-06-16: [added Creating a New Task tutorial](http://parl.ai/static/docs/task_tutorial.html)\n\n2017-05-31: [added Seq2Seq model](https://github.com/facebookresearch/ParlAI/pull/96)\n\n2017-05-30: [added interactive mode with local human agent](https://github.com/facebookresearch/ParlAI/pull/110)\n\n2017-05-22: [added MTurk tutorial](http://parl.ai/static/docs/mturk.html)\n\n2017-05-14: [added basic tutorial](http://parl.ai/static/docs/basic_tutorial.html)\n\n2017-05-15: ParlAI press: [TechCrunch](https://techcrunch.com/2017/05/15/facebooks-parlai-is-where-researchers-will-push-the-boundaries-of-conversational-ai/), [CNBC](http://www.cnbc.com/2017/05/12/facebook-releases-parlai-to-speed-realistic-chat-bot-development.html), [The Verge](https://www.theverge.com/2017/5/15/15640886/facebook-parlai-chatbot-research-ai-chatbot), [Scientific American](https://www.scientificamerican.com/article/facebook-wants-to-make-chatbots-more-conversational/), [Engadget](https://www.engadget.com/2017/05/15/facebook-parlAI-chatbot-training/), [Venture Beat](https://venturebeat.com/2017/05/15/facebook-to-launch-parlai-a-testing-ground-for-ai-and-bots/), [Wired](https://www.wired.com/2017/05/inside-facebooks-training-ground-making-chatbots-chattier/), [MIT Technology review](https://www.technologyreview.com/s/607854/facebook-wants-to-merge-ai-systems-for-a-smarter-chatbot/).\n\n2017-05-12: [added VQA V2.0 and Visual Dialog V0.9 tasks](https://github.com/facebookresearch/ParlAI/pull/54)\n\n2017-05-01: [ParlAI released!](https://code.facebook.com/posts/266433647155520/parlai-a-new-software-platform-for-dialog-research/)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.4072265625,
          "content": "<p align=\"center\">\n <img width=\"70%\" src=\"docs/source/\\_static/img/parlai.png\" />\n</p>\n\n<p align=\"center\">\n   <a href=\"https://github.com/facebookresearch/ParlAI/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"CircleCI\" />\n  </a>\n   <a href=\"https://pypi.org/project/parlai/\">\n    <img src=\"https://img.shields.io/pypi/v/parlai?color=blue&label=release\" alt=\"CircleCI\" />\n  </a>\n    <a href=\"https://circleci.com/gh/facebookresearch/ParlAI/tree/main\">\n    <img src=\"https://img.shields.io/circleci/build/github/facebookresearch/ParlAI/main\" alt=\"Coverage\" />\n  </a>\n    <a href=\"https://codecov.io/gh/facebookresearch/ParlAI\">\n    <img src=\"https://img.shields.io/codecov/c/github/facebookresearch/ParlAI\" alt=\"GitHub contributors\" />\n  </a>\n    <a href=\"https://img.shields.io/github/contributors/facebookresearch/ParlAI\">\n    <img src=\"https://img.shields.io/github/contributors/facebookresearch/ParlAI\"/>\n  </a>\n    <a href=\"https://twitter.com/parlai_parley\">\n    <img src=\"https://img.shields.io/twitter/follow/parlai_parley?label=Twitter&style=social\" alt=\"Twitter\" />\n  </a>\n </p>\n\n-------------------------------------------------------------------------------------------------------------------------------------------------------\n\n[ParlAI](http://parl.ai) (pronounced “par-lay”) is a python framework for\nsharing, training and testing dialogue models, from open-domain chitchat, to\ntask-oriented dialogue, to visual question answering.\n\nIts goal is to provide researchers:\n\n- **100+ popular datasets available all in one place, with the same API**, among them [PersonaChat](https://arxiv.org/abs/1801.07243), [DailyDialog](https://arxiv.org/abs/1710.03957), [Wizard of Wikipedia](https://openreview.net/forum?id=r1l73iRqKm), [Empathetic Dialogues](https://arxiv.org/abs/1811.00207), [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/), [MS MARCO](http://www.msmarco.org/), [QuAC](https://www.aclweb.org/anthology/D18-1241), [HotpotQA](https://hotpotqa.github.io/), [QACNN & QADailyMail](https://arxiv.org/abs/1506.03340), [CBT](https://arxiv.org/abs/1511.02301), [BookTest](https://arxiv.org/abs/1610.00956), [bAbI Dialogue tasks](https://arxiv.org/abs/1605.07683), [Ubuntu Dialogue](https://arxiv.org/abs/1506.08909), [OpenSubtitles](http://opus.lingfil.uu.se/OpenSubtitles.php),  [Image Chat](https://arxiv.org/abs/1811.00945), [VQA](http://visualqa.org/), [VisDial](https://arxiv.org/abs/1611.08669) and [CLEVR](http://cs.stanford.edu/people/jcjohns/clevr/). See the complete list [here](https://github.com/facebookresearch/ParlAI/blob/main/parlai/tasks/task_list.py).\n- a wide set of [**reference models**](https://parl.ai/docs/agents_list.html) -- from retrieval baselines to Transformers.\n- a large [zoo of **pretrained models**](https://parl.ai/docs/zoo.html) ready to use off-the-shelf\n- seamless **integration of [Amazon Mechanical Turk](https://www.mturk.com/mturk/welcome)** for data collection and human evaluation\n- **integration with [Facebook Messenger](https://parl.ai/docs/tutorial_chat_service.html)** to connect agents with humans in a chat interface\n- a large range of **helpers to create your own agents** and train on several tasks with **multitasking**\n- **multimodality**, some tasks use text and images\n\n\nParlAI is described in the following paper:\n[“ParlAI: A Dialog Research Software Platform\", arXiv:1705.06476](https://arxiv.org/abs/1705.06476)\nor see these [more up-to-date slides](https://drive.google.com/file/d/1JfUW4AVrjSp8X8Fp0_rTTRoLxUfW0aUm/view?usp=sharing).\n\nFollow us on [Twitter](https://twitter.com/parlai_parley) and check out our [Release\nnotes](https://github.com/facebookresearch/ParlAI/releases) to see the latest\ninformation about new features & updates, and the website\n[http://parl.ai](http://parl.ai) for further docs. For an archived list of updates,\ncheck out [NEWS.md](https://github.com/facebookresearch/ParlAI/blob/main/NEWS.md).\n\n<p align=\"center\"><img width=\"90%\" src=\"https://raw.githubusercontent.com/facebookresearch/ParlAI/main/docs/source/_static/img/parlai_example.png\" /></p>\n\n## Interactive Tutorial\n\nFor those who want to start with ParlAI now, you can try our [Colab Tutorial](https://colab.research.google.com/drive/1bRMvN0lGXaTF5fuTidgvlAl-Lb41F7AD#scrollTo=KtVz5dCUmFkN).\n\n## Installing ParlAI\n\n### Operating System\n\nParlAI should work as inteded under Linux or macOS. We do not support Windows at this time, but many users [report success on Windows using Python 3.8](https://github.com/facebookresearch/ParlAI/issues/3989) and issues with Python 3.9. We are happy to accept patches that improve Windows support.\n\n### Python Interpreter\n\nParlAI currently requires Python3.8+.\n\n### Requirements\n\nParlAI supports [Pytorch](https://pytorch.org) 1.6 or higher.\nAll requirements of the core modules are listed in [`requirements.txt`](https://github.com/facebookresearch/ParlAI/blob/main/requirements.txt). However, some models included (in [`parlai/agents`](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents)) have additional requirements.\n\n## Virtual Environment\n\nWe *strongly* recommend you install ParlAI in a virtual environment using [venv](https://docs.python.org/3/library/venv.html) or [conda](https://www.anaconda.com/).\n\n### End User Installation\n\nIf you want to use ParlAI without modifications, you can install it with:\n\n```bash\ncd /path/to/your/parlai-app\npython3.8 -m venv venv\nvenv/bin/pip install --upgrade pip setuptools wheel\nvenv/bin/pip install parlai\n```\n\n### Developer Installation\n\nMany users will want to modify some parts of ParlAI. To set up a development\nenvironment, run the following commands to clone the repository and install\nParlAI:\n\n```bash\ngit clone https://github.com/facebookresearch/ParlAI.git ~/ParlAI\ncd ~/ParlAI\npython3.8 -m venv venv\nvenv/bin/pip install --upgrade pip setuptools wheel\nvenv/bin/python setup.py develop\n```\n\n> **Note**\n> Sometimes the install from source maynot work due to dependencies (specially in PyTorch related packaged).\n> In that case try building a fresh conda environment and running the similar to the following:\n> `conda install pytorch==2.0.0 torchvision torchaudio torchtext pytorch-cuda=11.8 -c pytorch -c nvidia`.\n> Check torch setup documentation for your CUDA and OS versions.\n\nAll needed data will be downloaded to `~/ParlAI/data`. If you need to clear out\nthe space used by these files, you can safely delete these directories and any\nfiles needed will be downloaded again.\n\n## Documentation\n\n - [Quick Start](https://parl.ai/docs/tutorial_quick.html)\n - [Basics: world, agents, teachers, action and observations](https://parl.ai/docs/tutorial_basic.html)\n - [Creating a new dataset/task](http://parl.ai/docs/tutorial_task.html)\n - [List of available tasks/datasets](https://parl.ai/docs/tasks.html)\n - [Creating a seq2seq agent](https://parl.ai/docs/tutorial_torch_generator_agent.html)\n - [List of available agents](https://parl.ai/docs/agents_list.html)\n - [Model zoo (list pretrained models)](https://parl.ai/docs/zoo.html)\n - [Running crowdsourcing tasks](http://parl.ai/docs/tutorial_crowdsourcing.html)\n - [Plug into Facebook Messenger](https://parl.ai/docs/tutorial_chat_service.html)\n\n\n## Examples\n\nA large set of scripts can be found in [`parlai/scripts`](https://github.com/facebookresearch/ParlAI/tree/main/parlai/scripts). Here are a few of them.\nNote: If any of these examples fail, check the [installation section](#installing-parlai) to see if you have missed something.\n\nDisplay 10 random examples from the SQuAD task\n```bash\nparlai display_data -t squad\n```\n\nEvaluate an IR baseline model on the validation set of the Personachat task:\n```bash\nparlai eval_model -m ir_baseline -t personachat -dt valid\n```\n\nTrain a single layer transformer on PersonaChat (requires pytorch and torchtext).\nDetail: embedding size 300, 4 attention heads,  2 epochs using batchsize 64, word vectors are initialized with fasttext and the other elements of the batch are used as negative during training.\n```bash\nparlai train_model -t personachat -m transformer/ranker -mf /tmp/model_tr6 --n-layers 1 --embedding-size 300 --ffn-size 600 --n-heads 4 --num-epochs 2 -veps 0.25 -bs 64 -lr 0.001 --dropout 0.1 --embedding-type fasttext_cc --candidates batch\n```\n\n## Code Organization\n\nThe code is set up into several main directories:\n\n- [**core**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/core): contains the primary code for the framework\n- [**agents**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/agents): contains agents which can interact with the different tasks (e.g. machine learning models)\n- [**scripts**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/scripts): contains a number of useful scripts, like training, evaluating, interactive chatting, ...\n- [**tasks**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/tasks): contains code for the different tasks available from within ParlAI\n- [**mturk**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/mturk): contains code for setting up Mechanical Turk, as well as sample MTurk tasks\n- [**messenger**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/chat_service/services/messenger): contains code for interfacing with Facebook Messenger\n- [**utils**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/utils): contains a wide number of frequently used utility methods\n- [**crowdsourcing**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/crowdsourcing): contains code for running crowdsourcing tasks, such as on Amazon Mechanical Turk\n- [**chat_service**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/chat_service/services/messenger): contains code for interfacing with services such as Facebook Messenger\n- [**zoo**](https://github.com/facebookresearch/ParlAI/tree/main/parlai/zoo): contains code to directly download and use pretrained models from our model zoo\n\n## Support\nIf you have any questions, bug reports or feature requests, please don't hesitate to post on our [Github Issues page](https://github.com/facebookresearch/ParlAI/issues).\nYou may also be interested in checking out our [FAQ](https://parl.ai/docs/faq.html) and\nour [Tips n Tricks](https://parl.ai/docs/tutorial_tipsntricks.html).\n\nPlease remember to follow our [Code of Conduct](https://github.com/facebookresearch/ParlAI/blob/main/CODE_OF_CONDUCT.md).\n\n## Contributing\nWe welcome PRs from the community!\n\nYou can find information about contributing to ParlAI in our\n[Contributing](https://github.com/facebookresearch/ParlAI/blob/main/CONTRIBUTING.md)\ndocument.\n\n\n## The Team\nParlAI is currently maintained by Moya Chen, Emily Dinan, Dexter Ju, Mojtaba\nKomeili, Spencer Poff, Pratik Ringshia, Stephen Roller, Kurt Shuster,\nEric Michael Smith, Megan Ung, Jack Urbanek, Jason Weston, Mary Williamson,\nand Jing Xu. Kurt Shuster is the current Tech Lead.\n\nFormer major contributors and maintainers include Alexander H. Miller, Margaret\nLi, Will Feng, Adam Fisch, Jiasen Lu, Antoine Bordes, Devi Parikh, Dhruv Batra,\nFilipe de Avila Belbute Peres, Chao Pan, and Vedant Puri.\n\n## Citation\n\nPlease cite the [arXiv paper](https://arxiv.org/abs/1705.06476) if you use ParlAI in your work:\n\n```\n@article{miller2017parlai,\n  title={ParlAI: A Dialog Research Software Platform},\n  author={{Miller}, A.~H. and {Feng}, W. and {Fisch}, A. and {Lu}, J. and {Batra}, D. and {Bordes}, A. and {Parikh}, D. and {Weston}, J.},\n  journal={arXiv preprint arXiv:{1705.06476}},\n  year={2017}\n}\n```\n\n## License\nParlAI is MIT licensed. See the **[LICENSE](https://github.com/facebookresearch/ParlAI/blob/main/LICENSE)** file for details.\n"
        },
        {
          "name": "autoformat.sh",
          "type": "blob",
          "size": 4.7109375,
          "content": "#!/bin/bash\n\n# Copyright (c) Facebook, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n# exit on errors\nset -e\n\n# configuration options for our doc formatting\nDOCOPTS=\"--pre-summary-newline --wrap-descriptions 88 --wrap-summaries 88 \\\n    --make-summary-multi-line\"\n\nusage () {\n    # prints the help message\n    cat <<EOF\nUsage: $0\n\nAutoformats (or checks) code so it conforms with ParlAI standards. By default,\nruns black, flake8, and docformatter only on the changed files in the current branch.\n\nOptional Arguments\n\n  -a, --all          run on all files, not just changed ones.\n  -b, --black        only run black.\n  -c, --check        perform a check, but don't make any changes.\n  -d, --doc          only run docformatter.\n  -f, --flake8       only run flake8.\n  -h, --help         print this help message and exit\n  -i, --internal     run within parlai_internal\n  -z, --fb     run within parlai_fb\nEOF\n}\n\nreroot() {\n    # possibly rewrite all filenames if root is nonempty\n    if [[ \"$1\" != \"\" ]]; then\n        cat | xargs -I '{}' realpath --relative-to=. $1/'{}'\n    else\n        cat\n    fi\n}\n\nonlyexists() {\n    # filter filenames based on what exists on disk\n    while read fn; do\n        if [ -f \"${fn}\" ]; then\n            echo \"$fn\"\n        fi\n    done\n}\n\n# parse the command line args\nRUN_ALL_FILES=0\nRUNALL=1\nINTERNAL=0\nFB=0\nCHECK=0\nCMD=\"\"\nwhile true; do\n  case $1 in\n    -h | --help)\n      usage\n      exit 0\n      ;;\n    -a | --all)\n      RUN_ALL_FILES=1\n      ;;\n    -f | --flake8)\n      [[ \"$CMD\" != \"\" ]] && (echo \"Don't mix args.\" && false);\n      RUNALL=0\n      CMD=\"flake8\"\n      ;;\n    -c | --check)\n      CHECK=1\n      ;;\n    -d | --doc)\n      [[ \"$CMD\" != \"\" ]] && (echo \"Don't mix args.\" && false);\n      CMD=\"docformatter\"\n      RUNALL=0\n      ;;\n    -i | --internal)\n      INTERNAL=1\n      ;;\n    -z | --fb)\n      FB=1\n      ;;\n    -b | --black)\n      [[ \"$CMD\" != \"\" ]] && (echo \"Don't mix args.\" && false);\n      CMD=\"black\"\n      RUNALL=0\n      ;;\n    \"\")\n      break\n      ;;\n    *)\n      usage\n      echo\n      echo \"Cannot handle arg $1.\"\n      exit 1\n      ;;\n  esac\n  shift\ndone\n\n\n# decide which repo we're working on\nif [[ $INTERNAL -eq 1 ]]; then\n    ROOT=\"$(git -C ./parlai_internal/ rev-parse --show-toplevel)\"\n    REPO=\"-C ./parlai_internal\"\nelif [[ $FB -eq 1 ]]; then\n    ROOT=\"$(git -C ./parlai_fb/ rev-parse --show-toplevel)\"\n    REPO=\"-C ./parlai_fb\"\nelse\n    ROOT=\"\"\n    REPO=\"\"\nfi\n\n# find out what files we're working on\nif [[ $RUN_ALL_FILES -eq 1 ]]; then\n    CHECK_FILES=\"$(git $REPO ls-files | grep '\\.py$' | reroot $ROOT | onlyexists $ROOT | tr '\\n' ' ')\"\nelse\n    CHECK_FILES=\"$(git $REPO diff --name-only main... | grep '\\.py$' | reroot $ROOT | onlyexists | tr '\\n' ' ')\"\nfi\n\n# if we're doing all the tests, we should run them in serial\nif [[ $RUNALL -eq 1 ]]\nthen\n    if [[ $CHECK -eq 1 ]]; then A=\"$A --check\"; fi\n    if [[ $INTERNAL -eq 1 ]]; then A=\"$A --internal\"; fi\n    if [[ $FB -eq 1 ]]; then A=\"$A --fb\"; fi\n    if [[ $RUN_ALL_FILES -eq 1 ]]; then A=\"$A --all\"; fi\n    bash $0 --black $A\n    bash $0 --doc $A\n    bash $0 --flake8 $A\n    exit 0\nfi\n\n# finally do the actual checks\nif [ \"$CHECK_FILES\" != \"\" ]\nthen\n    if [[ \"$CMD\" == \"black\" ]]\n    then\n        command -v black >/dev/null || \\\n            ( echo \"Please run \\`pip install black\\` and rerun $0.\" && false )\n        if [[ $CHECK -eq 0 ]]\n        then\n            black $CHECK_FILES\n        else\n            if ! ( black --check $CHECK_FILES 2>/dev/null ); then\n                echo -e \"\\033[0;31mSome files need to be blacked.\\033[0m\"\n                echo \"Please run \\`bash ./autoformat.sh\\` and commit the changes.\"\n                exit 1\n            fi\n        fi\n    elif [[ \"$CMD\" == \"docformatter\" ]]\n    then\n        command -v docformatter > /dev/null || \\\n            ( echo \"Please run \\`pip install docformatter\\` and rerun $0.\" && false )\n        if [[ $CHECK -eq 0 ]]\n        then\n            docformatter -i $DOCOPTS $CHECK_FILES\n        else\n            if ! docformatter -c $DOCOPTS $CHECK_FILES > /dev/null 2>&1; then\n                echo -e \"\\033[0;31mSome docstrings need to be formatted.\\033[0m\"\n                echo \"Please run \\`./autoformat.sh\\` and commit the changes.\"\n                exit 1\n            fi\n        fi\n    elif [[ \"$CMD\" == \"flake8\" ]]\n    then\n        command -v flake8 >/dev/null || \\\n            ( echo \"Please run \\`pip install flake8\\` and rerun $0.\" && false )\n\n        # soft complaint on too-long-lines\n        flake8 --select=E501 --show-source $CHECK_FILES\n        # hard complaint on really long lines\n        flake8 --max-line-length=127 --show-source $CHECK_FILES\n    else\n        echo \"Don't know how to \\`$CMD\\`.\"\n        exit 1\n    fi\nfi\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.1025390625,
          "content": "coverage:\n  status:\n    project: off\n    patch: off\n    changes: off\nignore:\n  - parlai/tasks/*/build.py\n"
        },
        {
          "name": "conftest.py",
          "type": "blob",
          "size": 4.0283203125,
          "content": "#!/usr/bin/env python3\n\n# Copyright (c) Facebook, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\n\"\"\"\nThis is used to configure markers on tests based on filename.\n\nWe use this to split up tests into different circleci runs.\n\"\"\"\n\nimport os\nimport pathlib\nimport random\nimport collections\nimport pytest\nimport subprocess\n\n\n# TODO: rename the folders nicer so they make more sense, maybe even have\n# a 1:1 correspondance with the circleci name\n\n\n# -----------------------------------------------------------------------\n# From https://github.com/ryanwilsonperkin/pytest-circleci-parallelized.\n# MIT licensed, Copyright Ryan Wilson-Perkin.\n# -----------------------------------------------------------------------\ndef get_class_name(item):\n    class_name, module_name = None, None\n    for parent in reversed(item.listchain()):\n        if isinstance(parent, pytest.Class):\n            class_name = parent.name\n        elif isinstance(parent, pytest.Module):\n            module_name = parent.module.__name__\n            break\n\n    # heuristic:\n    # - better to group gpu and task tests, since tests from those modules\n    #   are likely to share caching more\n    # - split up the rest by class name because slow tests tend to be in\n    #   the same module\n    if class_name and '.tasks.' not in module_name:\n        return \"{}.{}\".format(module_name, class_name)\n    else:\n        return module_name\n\n\ndef filter_tests_with_circleci(test_list):\n    circleci_input = \"\\n\".join(test_list).encode(\"utf-8\")\n    p = subprocess.Popen(\n        [\"circleci\", \"tests\", \"split\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE\n    )\n    circleci_output, _ = p.communicate(circleci_input)\n    return [\n        line.strip() for line in circleci_output.decode(\"utf-8\").strip().split(\"\\n\")\n    ]\n\n\n# -----------------------------------------------------------------------\nMARKER_RULES = [\n    ('parlai_internal', 'internal'),\n    ('crowdsourcing/', 'crowdsourcing'),\n    ('nightly/gpu', 'nightly_gpu'),\n    ('nightly/cpu/', 'nightly_cpu'),\n    ('datatests/', 'data'),\n    ('parlai/tasks/', 'teacher'),\n    ('tasks/', 'tasks'),\n    ('tod/', 'tod'),\n]\n\n\ndef pytest_collection_modifyitems(config, items):\n    marker_expr = config.getoption('markexpr')\n\n    deselected = []\n\n    # first add all the markers, possibly filtering\n    # python 3.4/3.5 compat: rootdir = pathlib.Path(str(config.rootdir))\n    rootdir = pathlib.Path(config.rootdir)\n    for item in items:\n        rel_path = str(pathlib.Path(item.fspath).relative_to(rootdir))\n        for file_pattern, marker in MARKER_RULES:\n            if file_pattern in rel_path:\n                item.add_marker(marker)\n                if marker_expr and marker != marker_expr:\n                    deselected.append(item)\n                break\n        else:\n            assert \"/\" not in rel_path[6:], f\"Couldn't categorize '{rel_path}'\"\n            item.add_marker(\"unit\")\n            if marker_expr not in ['', 'unit']:\n                deselected.append(item)\n\n    # kill everything that wasn't grabbed\n    for item in deselected:\n        items.remove(item)\n\n    if 'CIRCLE_NODE_TOTAL' in os.environ:\n        # circleci, split up the parallelism by classes\n        class_mapping = collections.defaultdict(list)\n        for item in items:\n            class_name = get_class_name(item)\n            class_mapping[class_name].append(item)\n\n        test_groupings = list(class_mapping.keys())\n        random.Random(1339).shuffle(test_groupings)\n\n        filtered_tests = filter_tests_with_circleci(test_groupings)\n        new_items = []\n        for name in filtered_tests:\n            new_items.extend(class_mapping[name])\n            items[:] = new_items\n\n\ndef pytest_sessionfinish(session, exitstatus):\n    \"\"\"\n    Ensure that pytest doesn't report failure when no tests are collected.\n\n    This can sometimes happen due to the way we distribute tests across multiple circle\n    nodes.\n    \"\"\"\n    if exitstatus == pytest.ExitCode.NO_TESTS_COLLECTED:\n        session.exitstatus = pytest.ExitCode.OK\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "example_parlai_internal",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.1005859375,
          "content": "[mypy]\npython_version = 3.7\nignore_missing_imports = true\nfiles = parlai,projects,tests\npretty = false\n"
        },
        {
          "name": "parlai",
          "type": "tree",
          "content": null
        },
        {
          "name": "projects",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.185546875,
          "content": "[tool.black]\nline-length = 88\nskip-string-normalization = true\ntarget-version = ['py36', 'py37', 'py38']\ninclude = '\\.pyi?$'\nexclude = '''\n/(\n    \\.eggs\n  | \\.git\n  | parlai_internal\n)/\n'''\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.26171875,
          "content": "[pytest]\ntestpaths = tests parlai/tasks\npython_files = test.py test_*.py\naddopts = --strict-markers --disable-warnings --durations=10\nmarkers =\n    crowdsourcing\n    nightly_gpu\n    nightly_cpu\n    teacher\n    data\n    tasks\n    unit\n    internal\n    nofbcode\n    tod\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 1.1455078125,
          "content": "# Comment to bump caches\ncoloredlogs==14.0\ndatasets<2.2.2,>=1.4.1\ndocutils<0.16,>=0.14\nemoji==0.5.4\nfairscale~=0.4.1\ndocformatter~=1.4.0\nflake8-bugbear==19.8.0\nflake8==3.7.8\nfuzzywuzzy==0.18.0\ngoogle-cloud-storage==1.43.0\niopath~=0.1.8\ngitdb2==2.0.5\nGitPython==3.1.37\nhydra-core>=1.1.0\nipython==7.31.1\ntorch==2.0.0\ntorchvision==0.15.1\njoblib==1.2.0\nnltk==3.6.6\nomegaconf>=2.1.1\npandas==1.4.0\npytest_regressions==2.4.2\npytest==7.3.0\npexpect==4.7.0\nPillow==10.0.1\npy-gfm==1.0.2\npy-rouge==1.1\npyyaml==5.4\npyzmq==18.1.0\nregex>=2021.8.3\nmyst-parser<1\nattrs~=20.2.0\nrequests-mock==1.7.0\nrequests<3,>=2.21.0\n# scikit-learn==0.23.1\nscipy==1.10.0\nsh==1.12.14\nsphinx_rtd_theme==0.4.3\nsphinx-autodoc-typehints~=1.10.3\nSphinx~=5.1.0\nsubword-nmt==0.3.7\ntensorboardX<=2.5.0\ntokenizers>=0.13.3\ntomli>=2.0.0\ntorchtext==0.15.1\ntornado==6.3.2\ntqdm~=4.62.1\ntyping-extensions==4.5.0\nUnidecode==1.1.1\nurllib3<1.27,>=1.26.5\nwebsocket-client==0.56.0\njsonlines==1.2.0\nnumpy~=1.23.0\nmarkdown<=3.3.2 # Pin to something that works so tests are happy\njinja2==3.0.3\nninja~=1.10.2.3\nprotobuf<=3.20.3, >=3.8.0\ncontractions~=0.1.72\nfsspec~=2022.2.0\ngoogle-api-core<=2.11.0\nopenai<=0.27.7\nlitellm>=0.1.400\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.62109375,
          "content": "#!/usr/bin/env python3\n\n# Copyright (c) Facebook, Inc. and its affiliates.\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\nimport sys\n\nfrom setuptools import setup, find_packages\n\nVERSION = '1.7.2'  # if you update, update parlai/__init__.py too!\n\nif sys.version_info < (3, 8):\n    sys.exit('Sorry, Python >=3.8 is required for ParlAI.')\n\nwith open('README.md', encoding=\"utf8\") as f:\n    # strip the header and badges etc\n    readme = f.read().split('--------------------')[-1]\n\nwith open('requirements.txt') as f:\n    reqs = []\n    for line in f:\n        line = line.strip()\n        reqs.append(line.split('==')[0])\n\n\nif __name__ == '__main__':\n    setup(\n        name='parlai',\n        version=VERSION,\n        description='Unified platform for dialogue research.',\n        long_description=readme,\n        long_description_content_type='text/markdown',\n        url='http://parl.ai/',\n        python_requires='>=3.8',\n        packages=find_packages(exclude=('data', 'docs', 'tests', 'parlai_internal*')),\n        install_requires=reqs,\n        include_package_data=True,\n        package_data={'': ['*.txt', '*.md', '*.opt', '*.cu', '*.cpp']},\n        entry_points={\n            \"flake8.extension\": [\"PAI = parlai.utils.flake8:ParlAIChecker\"],\n            \"console_scripts\": [\"parlai=parlai.__main__:main\"],\n        },\n        classifiers=[\n            \"Programming Language :: Python :: 3\",\n            \"License :: OSI Approved :: MIT License\",\n            \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n            \"Natural Language :: English\",\n        ],\n    )\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}