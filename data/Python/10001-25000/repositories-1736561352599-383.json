{
  "metadata": {
    "timestamp": 1736561352599,
    "page": 383,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "huggingface/trl",
      "stars": 10564,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.560546875,
          "content": "*.bak\n.gitattributes\n.last_checked\n.gitconfig\n*.bak\n*.log\n*~\n~*\n_tmp*\ntmp*\ntags\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n.vscode\n*.swp\n\n# osx generated files\n.DS_Store\n.DS_Store?\n.Trashes\nehthumbs.db\nThumbs.db\n.idea\n\n# pytest\n.pytest_cache\n\n# tools/trust-doc-nbs\ndocs_src/.last_checked\n\n# symlinks to fastai\ndocs_src/fastai\ntools/fastai\n\n# link checker\nchecklink/cookies.txt\n\n# .gitconfig is now autogenerated\n.gitconfig\n\n# wandb files\nnbs/wandb/\nexamples/notebooks/wandb/\nwandb/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.4697265625,
          "content": "repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.6.3\n    hooks:\n      - id: ruff\n        types_or: [ python, pyi ]\n        args: [ --fix ]\n      - id: ruff-format\n        types_or: [ python, pyi ]\n\n  # - repo: https://github.com/codespell-project/codespell\n  #   rev: v2.1.0\n  #   hooks:\n  #     - id: codespell\n  #       args:\n  #         - --ignore-words-list=nd,reacher,thist,ths,magent,ba\n  #         - --skip=docs/css/termynal.css,docs/js/termynal.js\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 1.1123046875,
          "content": "cff-version: 1.2.0\ntitle: 'TRL: Transformer Reinforcement Learning'\nmessage: >-\n  If you use this software, please cite it using the\n  metadata from this file.\ntype: software\nauthors:\n  - given-names: Leandro\n    family-names: von Werra\n  - given-names: Younes\n    family-names: Belkada\n  - given-names: Lewis\n    family-names: Tunstall\n  - given-names: Edward\n    family-names: Beeching\n  - given-names: Tristan\n    family-names: Thrush\n  - given-names: Nathan\n    family-names: Lambert\n  - given-names: Shengyi\n    family-names: Huang\n  - given-names: Kashif\n    family-names: Rasul\n  - given-names: Quentin\n    family-names: GallouÃ©dec\nrepository-code: 'https://github.com/huggingface/trl'\nabstract: \"With trl you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the transformers library by \\U0001F917 Hugging Face. Therefore, pre-trained language models can be directly loaded via transformers. At this point, most decoder and encoder-decoder architectures are supported.\"\nkeywords:\n  - rlhf\n  - deep-learning\n  - pytorch\n  - transformers\nlicense: Apache-2.0\nversion: 0.13\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.359375,
          "content": "\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nfeedback@huggingface.co.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 17.001953125,
          "content": "# How to contribute to TRL?\n\nEveryone is welcome to contribute, and we value everybody's contribution. Code\ncontributions are not the only way to help the community. Answering questions, helping\nothers, and improving the documentation are also immensely valuable.\n\nIt also helps us if you spread the word! Reference the library in blog posts\nabout the awesome projects it made possible, shout out on Twitter every time it has\nhelped you, or simply â­ï¸ the repository to say thank you.\n\nHowever you choose to contribute, please be mindful and respect our\n[code of conduct](https://github.com/huggingface/trl/blob/main/CODE_OF_CONDUCT.md).\n\n**This guide was heavily inspired by the awesome [scikit-learn guide to contributing](https://github.com/scikit-learn/scikit-learn/blob/main/CONTRIBUTING.md).**\n\n## Ways to contribute\n\nThere are several ways you can contribute to TRL:\n\n* Fix outstanding issues with the existing code.\n* Submit issues related to bugs or desired new features.\n* Implement trainers for new post-training algorithms.\n* Contribute to the examples or the documentation.\n\nIf you don't know where to start, there is a special [Good First\nIssue](https://github.com/huggingface/trl/contribute) listing. It will give you a list of\nopen issues that are beginner-friendly and help you start contributing to open-source. The best way to do that is to open a Pull Request and link it to the issue that you'd like to work on. We try to give priority to opened PRs as we can easily track the progress of the fix, and if the contributor does not have time anymore, someone else can take the PR over.\n\nFor something slightly more challenging, you can also take a look at the [Good Second Issue](https://github.com/huggingface/trl/labels/Good%20Second%20Issue) list. In general though, if you feel like you know what you're doing, go for it and we'll help you get there! ðŸš€\n\n> All contributions are equally valuable to the community. ðŸ¥°\n\nBefore you start contributing make sure you have installed all the dev tools:\n\n```bash\npip install -e .[dev]\n```\n\n## Fixing outstanding issues\n\nIf you notice an issue with the existing code and have a fix in mind, feel free to [start contributing](#create-a-pull-request) and open a Pull Request!\n\n## Submitting a bug-related issue or feature request\n\nDo your best to follow these guidelines when submitting a bug-related issue or a feature request. It will make it easier for us to come back to you quickly and with good feedback.\n\n### Did you find a bug?\n\nThe TRL library is robust and reliable thanks to users who report the problems they encounter.\n\nBefore you report an issue, we would really appreciate it if you could **make sure the bug was not\nalready reported** (use the search bar on GitHub under Issues). Your issue should also be related to bugs in the library itself, and not your code.\n\nOnce you've confirmed the bug hasn't already been reported, please include the following information in your issue so we can quickly resolve it:\n\n* Your **OS type and version**, **Python**, **PyTorch**, **TRL** and **Transformers** versions.\n* A short, self-contained, code snippet that allows us to reproduce the bug in\n  less than 30s.\n* The *full* traceback if an exception is raised.\n* Attach any other additional information, like screenshots, you think may help.\n\nTo get the OS and software versions automatically, run the following command:\n\n```bash\ntrl env\n```\n\n### Do you want a new feature?\n\nIf there is a new feature you'd like to see in TRL, please open an issue and describe:\n\n1. What is the *motivation* behind this feature? Is it related to a problem or frustration with the library? Is it a feature related to something you need for a project? Is it something you worked on and think it could benefit the community?\n\n   Whatever it is, we'd love to hear about it!\n\n2. Describe your requested feature in as much detail as possible. The more you can tell us about it, the better we'll be able to help you.\n3. Provide a *code snippet* that demonstrates the feature's usage.\n4. If the feature is related to a paper, please include a link.\n\nIf your issue is well written we're already 80% of the way there by the time you create it.\n\n## Do you want to implement a new trainer?\n\nNew post-training methods are published frequently and those that satisfy the following criteria are good candidates to be integrated into TRL:\n\n* **Simplicity:** Does the new method achieve similar performance as prior methods, but with less complexity? A good example is Direct Preference Optimization (DPO) [[Rafailov et al, 2023]](https://huggingface.co/papers/2305.18290), which provided a simpler and compelling alternative to RLHF methods.\n* **Efficiency:** Does the new method provide a significant improvement in training efficiency? A good example is Odds Ratio Preference Optimization (ORPO) [[Hong et al, 2023]](https://huggingface.co/papers/2403.07691), which utilizes a similar objective as DPO but requires half the GPU VRAM.\n\nMethods that only provide incremental improvements at the expense of added complexity or compute costs are unlikely to be included in TRL.\n\nIf you want to implement a trainer for a new post-training method, first open an issue and provide the following information:\n\n* A short description of the method and a link to the paper.\n* Link to the implementation if it is open-sourced.\n* Link to model weights trained with the method if they are available.\n\nBased on the community and maintainer feedback, the next step will be to implement the trainer and config classes. See the following examples for inspiration:\n\n* Paired preference optimisation: [`dpo_trainer.py`](./trl/trainer/dpo_trainer.py) and [`dpo_config.py`](./trl/trainer/dpo_config.py)\n* RL-based optimisation: [`rloo_trainer.py](./trl/trainer/rloo_trainer.py) and [`rloo_config.py](./trl/trainer/rloo_config.py)\n* Online optimisation: [`online_dpo_trainer.py`](./trl/trainer/online_dpo_trainer.py) and [`online_dpo_config.py`](./trl/trainer/online_dpo_config.py)\n\n## Do you want to add documentation?\n\nWe're always looking for improvements to the documentation that make it more clear and accurate. Please let us know how the documentation can be improved, such as typos, dead links, and any missing, unclear, or inaccurate content... We'll be happy to make the changes or help you contribute if you're interested!\n\n## Submitting a pull request (PR)\n\nBefore writing code, we strongly advise you to search through the existing PRs or\nissues to make sure that nobody is already working on the same thing. If you are\nunsure, it is always a good idea to open an issue to get some feedback.\n\nYou will need basic `git` proficiency to be able to contribute to\nTRL. `git` is not the easiest tool to use but it has the greatest\nmanual. Type `git --help` in a shell and enjoy. If you prefer books, [Pro\nGit](https://git-scm.com/book/en/v2) is a very good reference.\n\nFollow these steps to start contributing:\n\n1. Fork the [repository](https://github.com/huggingface/trl) by\n   clicking on the 'Fork' button on the repository's page. This creates a copy of the code\n   under your GitHub user account.\n\n2. Clone your fork to your local disk, and add the base repository as a remote. The following command\n   assumes you have your public SSH key uploaded to GitHub. See the following guide for more\n   [information](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository).\n\n   ```bash\n   $ git clone git@github.com:<your Github handle>/trl.git\n   $ cd trl\n   $ git remote add upstream https://github.com/huggingface/trl.git\n   ```\n\n3. Create a new branch to hold your development changes, and do this for every new PR you work on.\n\n   Start by synchronizing your `main` branch with the `upstream/main` branch (more details in the [GitHub Docs](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/syncing-a-fork)):\n\n   ```bash\n   $ git checkout main\n   $ git fetch upstream\n   $ git merge upstream/main\n   ```\n\n   Once your `main` branch is synchronized, create a new branch from it:\n\n   ```bash\n   $ git checkout -b a-descriptive-name-for-my-changes\n   ```\n\n   **Do not** work on the `main` branch.\n\n4. Set up a development environment by running the following command in a conda or a virtual environment you've created for working on this library:\n\n   ```bash\n   $ pip install -e .[dev]\n   ```\n\n   (If TRL was already installed in the virtual environment, remove\n   it with `pip uninstall trl` before reinstalling it.)\n\n   Alternatively, if you are using [Visual Studio Code](https://code.visualstudio.com/Download), the fastest way to get set up is by using\n   the provided Dev Container. Documentation on how to get started with dev containers is available [here](https://code.visualstudio.com/docs/remote/containers).\n\n5. Develop the features on your branch.\n\n   As you work on the features, you should make sure that the test suite\n   passes. You should run the tests impacted by your changes like this (see \n   below an explanation regarding the environment variable):\n\n   ```bash\n   $ pytest tests/<TEST_TO_RUN>.py\n   ```\n   \n   > For the following commands leveraging the `make` utility, we recommend using the WSL system when running on\n   > Windows. More information [here](https://docs.microsoft.com/en-us/windows/wsl/about).\n\n   You can also run the full suite with the following command.\n\n   ```bash\n   $ make test\n   ```\n\n    TRL relies on `ruff` for maintaining consistent code formatting across its source files. Before submitting any PR, you should apply automatic style corrections and run code verification checks.\n\n    We provide a `precommit` target in the `Makefile` that simplifies this process by running all required checks and optimizations on only the files modified by your PR.\n\n    To apply these checks and corrections in one step, use:\n\n    ```bash\n    $ make precommit\n    ```\n\n    This command runs the following:\n    - Executes `pre-commit` hooks to automatically fix style issues with `ruff` and other tools.\n    - Runs additional scripts such as adding copyright information.\n\n    If you prefer to apply the style corrections separately or review them individually, the `pre-commit` hook will handle the formatting for the files in question.\n\n   Once you're happy with your changes, add changed files using `git add` and\n   make a commit with `git commit` to record your changes locally:\n\n   ```bash\n   $ git add modified_file.py\n   $ git commit\n   ```\n\n   Please write [good commit messages](https://chris.beams.io/posts/git-commit/).\n\n   It is a good idea to sync your copy of the code with the original\n   repository regularly. This way you can quickly account for changes:\n\n   ```bash\n   $ git fetch upstream\n   $ git rebase upstream/main\n   ```\n\n   Push the changes to your account using:\n\n   ```bash\n   $ git push -u origin a-descriptive-name-for-my-changes\n   ```\n\n6. Once you are satisfied (**and the checklist below is happy too**), go to the\n   webpage of your fork on GitHub. Click on 'Pull request' to send your changes\n   to the project maintainers for review.\n\n7. It's ok if maintainers ask you for changes. It happens to core contributors too! To ensure everyone can review your changes in the pull request, work on your local branch and push the updates to your fork. They will automatically appear in the pull request.\n\n\n### Checklist\n\n1. The title of your pull request should be a summary of its contribution;\n2. If your pull request addresses an issue, please mention the issue number in\n   the pull request description to make sure they are linked (and people\n   consulting the issue know you are working on it);\n3. To indicate a work in progress please prefix the title with `[WIP]`, or mark\n   the PR as a draft PR. These are useful to avoid duplicated work, and to differentiate\n   it from PRs ready to be merged;\n4. Make sure existing tests pass;\n5. Add high-coverage tests. No quality testing = no merge.\n\n\n### Tests\n\nAn extensive test suite is included to test the library behavior and several examples. Library tests can be found in\nthe [tests folder](https://github.com/huggingface/trl/tree/main/tests).\n\nWe use `pytest` to run the tests. From the root of the\nrepository here's how to run tests with `pytest` for the library:\n\n```bash\n$ python -m pytest -sv ./tests\n```\n\nThat's how `make test` is implemented (without the `pip install` line)!\n\nYou can specify a smaller set of tests to test only the feature\nyou're working on.\n\n### Deprecation and Backward Compatibility\n\nOur approach to deprecation and backward compatibility is flexible and based on the featureâ€™s usage and impact. Each deprecation is carefully evaluated, aiming to balance innovation with user needs.\n\nWhen a feature or component is marked for deprecation, its use will emit a warning message. This warning will include:\n\n- **Transition Guidance**: Instructions on how to migrate to the alternative solution or replacement.\n- **Removal Version**: The target version when the feature will be removed, providing users with a clear timeframe to transition.\n\nExample:\n   \n   ```python\n   warnings.warn(\n       \"The `Trainer.foo` method is deprecated and will be removed in version 0.14.0. \"\n       \"Please use the `Trainer.bar` class instead.\",\n       FutureWarning,\n   )\n   ```\n\nThe deprecation and removal schedule is based on each feature's usage and impact, with examples at two extremes:\n\n- **Experimental or Low-Use Features**: For a feature that is experimental or has limited usage, backward compatibility may not be maintained between releases. Users should therefore anticipate potential breaking changes from one version to the next.\n\n- **Widely-Used Components**: For a feature with high usage, we aim for a more gradual transition period of approximately **5 months**, generally scheduling deprecation around **5 minor releases** after the initial warning.\n\nThese examples represent the two ends of a continuum. The specific timeline for each feature will be determined individually, balancing innovation with user stability needs.\n\n### Working with warnings\n\nWarnings play a critical role in guiding users toward resolving potential issues, but they should be used thoughtfully to avoid unnecessary noise. Unlike logging, which provides informational context or operational details, warnings signal conditions that require attention and action. Overusing warnings can dilute their importance, leading users to ignore them entirely.\n\n#### Definitions\n\n- **Correct**: An operation is correct if it is valid, follows the intended approach, and aligns with the current best practices or guidelines within the codebase. This is the recommended or intended way to perform the operation.\n- **Supported**: An operation is supported if it is technically valid and works within the current codebase, but it may not be the most efficient, optimal, or recommended way to perform the task. This includes deprecated features or legacy approaches that still work but may be phased out in the future.\n\n#### Choosing the right message\n\n- **Correct â†’ No warning**:  \n   If the operation is fully valid and expected, no message should be issued. The system is working as intended, so no warning is necessary.  \n\n- **Correct but deserves attention â†’ No warning, possibly a log message**:\n   When an operation is correct but uncommon or requires special attention, providing an informational message can be helpful. This keeps users informed without implying any issue. If available, use the logger to output this message. Example:  \n\n   ```python\n   logger.info(\"This is an informational message about a rare but correct operation.\")\n   ```\n\n- **Correct but very likely a mistake â†’ Warning with option to disable**:  \n   In rare cases, you may want to issue a warning for a correct operation thatâ€™s very likely a mistake. In such cases, you must provide an option to suppress the warning. This can be done with a flag in the function. Example:  \n\n   ```python\n   def my_function(foo, bar, _warn=True):\n       if foo == bar:\n           if _warn:\n               warnings.warn(\"foo and bar are the same, this is likely a mistake. Ignore this warning by setting `_warn=False`.\")\n           # Do something\n   ```\n\n- **Supported but not correct â†’ Warning**:  \n   If the operation is technically supported but is deprecated, suboptimal, or could cause future issues (e.g., conflicting arguments), a warning should be raised. This message should be actionable, meaning it must explain how to resolve the issue. Example:  \n\n   ```python\n   def my_function(foo, bar):\n       if foo and bar:\n           warnings.warn(\"Both `foo` and `bar` were provided, but only one is allowed. Ignoring `foo`. Please pass only one of these arguments.\")\n           # Do something\n   ```\n\n- **Not supported â†’ Exception**:  \n   If the operation is invalid or unsupported, raise an exception. This indicates that the operation cannot be performed and requires immediate attention. Example:  \n\n   ```python\n   def my_function(foo, bar):\n       if foo and bar:\n           raise ValueError(\"Both `foo` and `bar` were provided, but only one is allowed. Please pass only one of these arguments.\")\n   ```\n\nBy following this classification, you ensure that warnings, information, and exceptions are used appropriately, providing clear guidance to the user without cluttering the system with unnecessary messages.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1337890625,
          "content": "include settings.ini\ninclude LICENSE\ninclude CONTRIBUTING.md\ninclude README.md\nrecursive-exclude * __pycache__\ninclude trl/templates/*.md"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 1.0947265625,
          "content": ".PHONY: test precommit common_tests slow_tests test_examples tests_gpu\n\ncheck_dirs := examples tests trl\n\nACCELERATE_CONFIG_PATH = `pwd`/examples/accelerate_configs\nCOMMAND_FILES_PATH = `pwd`/commands\n\ntest:\n\tpython -m pytest -n auto --dist=loadfile -s -v --reruns 5 --reruns-delay 1 --only-rerun '(OSError|Timeout|HTTPError.*502|HTTPError.*504||not less than or equal to 0.01)' ./tests/\n\nprecommit:\n\tpre-commit run --all-files\n\tpython scripts/add_copyrights.py\n\ntests_gpu:\n\tpython -m pytest tests/test_* $(if $(IS_GITHUB_CI),--report-log \"common_tests.log\",)\n\nslow_tests:\n\tpython -m pytest tests/slow/test_* $(if $(IS_GITHUB_CI),--report-log \"slow_tests.log\",)\n\ntest_examples:\n\ttouch temp_results_sft_tests.txt\n\tfor file in $(ACCELERATE_CONFIG_PATH)/*.yaml; do \\\n\t\tTRL_ACCELERATE_CONFIG=$${file} bash $(COMMAND_FILES_PATH)/run_sft.sh; \\\n\t\techo $$?','$${file} >> temp_results_sft_tests.txt; \\\n\tdone\n\n\ttouch temp_results_dpo_tests.txt\n\tfor file in $(ACCELERATE_CONFIG_PATH)/*.yaml; do \\\n\t\tTRL_ACCELERATE_CONFIG=$${file} bash $(COMMAND_FILES_PATH)/run_dpo.sh; \\\n\t\techo $$?','$${file} >> temp_results_dpo_tests.txt; \\\n\tdone\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.0390625,
          "content": "# TRL - Transformer Reinforcement Learning\n\n<div style=\"text-align: center\">\n<img src=\"https://huggingface.co/datasets/trl-lib/documentation-images/resolve/main/trl_banner_dark.png\" alt=\"TRL Banner\">\n</div>\n\n<hr> <br>\n\n<h3 align=\"center\">\n    <p>A comprehensive library to post-train foundation models</p>\n</h3>\n\n<p align=\"center\">\n    <a href=\"https://github.com/huggingface/trl/blob/main/LICENSE\"><img alt=\"License\" src=\"https://img.shields.io/github/license/huggingface/trl.svg?color=blue\"></a>\n    <a href=\"https://huggingface.co/docs/trl/index\"><img alt=\"Documentation\" src=\"https://img.shields.io/website/http/huggingface.co/docs/trl/index.svg?down_color=red&down_message=offline&up_color=blue&up_message=online\"></a>\n    <a href=\"https://github.com/huggingface/trl/releases\"><img alt=\"GitHub release\" src=\"https://img.shields.io/github/release/huggingface/trl.svg\"></a>\n</p>\n\n## Overview\n\nTRL is a cutting-edge library designed for post-training foundation models using advanced techniques like Supervised Fine-Tuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Built on top of the [ðŸ¤— Transformers](https://github.com/huggingface/transformers) ecosystem, TRL supports a variety of model architectures and modalities, and can be scaled-up across various hardware setups.\n\n## Highlights\n\n- **Efficient and scalable**: \n    - Leverages [ðŸ¤— Accelerate](https://github.com/huggingface/accelerate) to scale from single GPU to multi-node clusters using methods like DDP and DeepSpeed.\n    - Full integration with [`PEFT`](https://github.com/huggingface/peft) enables training on large models with modest hardware via quantization and LoRA/QLoRA.\n    - Integrates [Unsloth](https://github.com/unslothai/unsloth) for accelerating training using optimized kernels.\n\n- **Command Line Interface (CLI)**: A simple interface lets you fine-tune and interact with models without needing to write code.\n\n- **Trainers**: Various fine-tuning methods are easily accessible via trainers like [`SFTTrainer`](https://huggingface.co/docs/trl/sft_trainer), [`DPOTrainer`](https://huggingface.co/docs/trl/dpo_trainer), [`RewardTrainer`](https://huggingface.co/docs/trl/reward_trainer), [`ORPOTrainer`](https://huggingface.co/docs/trl/orpo_trainer) and more.\n\n- **AutoModels**: Use pre-defined model classes like [`AutoModelForCausalLMWithValueHead`](https://huggingface.co/docs/trl/models#trl.AutoModelForCausalLMWithValueHead) to simplify reinforcement learning (RL) with LLMs.\n\n## Installation\n\n### Python Package\n\nInstall the library using `pip`:\n\n```bash\npip install trl\n```\n\n### From source\n\nIf you want to use the latest features before an official release, you can install TRL from source:\n\n```bash\npip install git+https://github.com/huggingface/trl.git\n```\n\n### Repository\n\nIf you want to use the examples you can clone the repository with the following command:\n\n```bash\ngit clone https://github.com/huggingface/trl.git\n```\n\n## Command Line Interface (CLI)\n\nYou can use the TRL Command Line Interface (CLI) to quickly get started with Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO), or vibe check your model with the chat CLI: \n\n**SFT:**\n\n```bash\ntrl sft --model_name_or_path Qwen/Qwen2.5-0.5B \\\n    --dataset_name trl-lib/Capybara \\\n    --output_dir Qwen2.5-0.5B-SFT\n```\n\n**DPO:**\n\n```bash\ntrl dpo --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct \\\n    --dataset_name argilla/Capybara-Preferences \\\n    --output_dir Qwen2.5-0.5B-DPO \n```\n\n**Chat:**\n\n```bash\ntrl chat --model_name_or_path Qwen/Qwen2.5-0.5B-Instruct\n```\n\nRead more about CLI in the [relevant documentation section](https://huggingface.co/docs/trl/main/en/clis) or use `--help` for more details.\n\n## How to use\n\nFor more flexibility and control over training, TRL provides dedicated trainer classes to post-train language models or PEFT adapters on a custom dataset. Each trainer in TRL is a light wrapper around the ðŸ¤— Transformers trainer and natively supports distributed training methods like DDP, DeepSpeed ZeRO, and FSDP.\n\n### `SFTTrainer`\n\nHere is a basic example of how to use the `SFTTrainer`:\n\n```python\nfrom trl import SFTConfig, SFTTrainer\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"trl-lib/Capybara\", split=\"train\")\n\ntraining_args = SFTConfig(output_dir=\"Qwen/Qwen2.5-0.5B-SFT\")\ntrainer = SFTTrainer(\n    args=training_args,\n    model=\"Qwen/Qwen2.5-0.5B\",\n    train_dataset=dataset,\n)\ntrainer.train()\n```\n\n### `RewardTrainer`\n\nHere is a basic example of how to use the `RewardTrainer`:\n\n```python\nfrom trl import RewardConfig, RewardTrainer\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"Qwen/Qwen2.5-0.5B-Instruct\", num_labels=1\n)\nmodel.config.pad_token_id = tokenizer.pad_token_id\n\ndataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\n\ntraining_args = RewardConfig(output_dir=\"Qwen2.5-0.5B-Reward\", per_device_train_batch_size=2)\ntrainer = RewardTrainer(\n    args=training_args,\n    model=model,\n    processing_class=tokenizer,\n    train_dataset=dataset,\n)\ntrainer.train()\n```\n\n### `RLOOTrainer`\n\n`RLOOTrainer` implements a [REINFORCE-style optimization](https://huggingface.co/papers/2402.14740) for RLHF that is more performant and memory-efficient than PPO. Here is a basic example of how to use the `RLOOTrainer`:\n\n```python\nfrom trl import RLOOConfig, RLOOTrainer, apply_chat_template\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\nreward_model = AutoModelForSequenceClassification.from_pretrained(\n    \"Qwen/Qwen2.5-0.5B-Instruct\", num_labels=1\n)\nref_policy = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\npolicy = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n\ndataset = load_dataset(\"trl-lib/ultrafeedback-prompt\")\ndataset = dataset.map(apply_chat_template, fn_kwargs={\"tokenizer\": tokenizer})\ndataset = dataset.map(lambda x: tokenizer(x[\"prompt\"]), remove_columns=\"prompt\")\n\ntraining_args = RLOOConfig(output_dir=\"Qwen2.5-0.5B-RL\")\ntrainer = RLOOTrainer(\n    config=training_args,\n    processing_class=tokenizer,\n    policy=policy,\n    ref_policy=ref_policy,\n    reward_model=reward_model,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n)\ntrainer.train()\n```\n\n### `DPOTrainer`\n\n`DPOTrainer` implements the popular [Direct Preference Optimization (DPO) algorithm](https://huggingface.co/papers/2305.18290) that was used to post-train Llama 3 and many other models. Here is a basic example of how to use the `DPOTrainer`:\n\n```python\nfrom datasets import load_dataset\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom trl import DPOConfig, DPOTrainer\n\nmodel = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\ndataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\ntraining_args = DPOConfig(output_dir=\"Qwen2.5-0.5B-DPO\")\ntrainer = DPOTrainer(model=model, args=training_args, train_dataset=dataset, processing_class=tokenizer)\ntrainer.train()\n```\n\n## Development\n\nIf you want to contribute to `trl` or customize it to your needs make sure to read the [contribution guide](https://github.com/huggingface/trl/blob/main/CONTRIBUTING.md) and make sure you make a dev install:\n\n```bash\ngit clone https://github.com/huggingface/trl.git\ncd trl/\npip install -e .[dev]\n```\n\n## Citation\n\n```bibtex\n@misc{vonwerra2022trl,\n  author = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin GallouÃ©dec},\n  title = {TRL: Transformer Reinforcement Learning},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/huggingface/trl}}\n}\n```\n\n## License\n\nThis repository's source code is available under the [Apache-2.0 License](LICENSE).\n"
        },
        {
          "name": "commands",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.546875,
          "content": "[tool.ruff]\ntarget-version = \"py37\"\nline-length = 119\n\n[tool.ruff.lint]\nignore = [\n    \"B028\", # warning without explicit stacklevel\n    \"C408\", # dict() calls (stylistic)\n    \"C901\", # function complexity\n    \"E501\",\n]\nextend-select = [\"E\", \"F\", \"I\", \"W\", \"UP\", \"B\", \"T\", \"C\"]\n\n[tool.ruff.lint.per-file-ignores]\n# Allow prints in auxiliary scripts\n\"examples/**.py\" = [\"T201\"]\n\"scripts/**.py\" = [\"T201\"]\n# Ignore import violations in all `__init__.py` files.\n\"__init__.py\" = [\"F401\"]\n\n[tool.ruff.lint.isort]\nlines-after-imports = 2\nknown-first-party = [\"trl\"]\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0439453125,
          "content": "accelerate\ndatasets\nrich\ntransformers>=4.46.0"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0322265625,
          "content": "[metadata]\nlicense_file = LICENSE"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 5.0712890625,
          "content": "# Copyright 2025 The HuggingFace Team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"trl is an open library for RL with transformer models.\n\nNote:\n\n   VERSION needs to be formatted following the MAJOR.MINOR.PATCH convention\n   (we need to follow this convention to be able to retrieve versioned scripts)\n\nSimple check list for release from AllenNLP repo: https://github.com/allenai/allennlp/blob/master/setup.py\n\nTo create the package for pypi.\n\n0. Prerequisites:\n   - Dependencies:\n     - twine: \"pip install twine\"\n   - Create an account in (and join the 'trl' project):\n     - PyPI: https://pypi.org/\n     - Test PyPI: https://test.pypi.org/\n\n1. Change the version in:\n   - __init__.py\n   - setup.py\n\n2. Commit these changes: \"git commit -m 'Release: VERSION'\"\n\n3. Add a tag in git to mark the release: \"git tag VERSION -m 'Add tag VERSION for pypi'\"\n   Push the tag to remote: git push --tags origin main\n\n4. Build both the sources and the wheel. Do not change anything in setup.py between\n   creating the wheel and the source distribution (obviously).\n\n   First, delete any \"build\" directory that may exist from previous builds.\n\n   For the wheel, run: \"python setup.py bdist_wheel\" in the top level directory.\n   (this will build a wheel for the python version you use to build it).\n\n   For the sources, run: \"python setup.py sdist\"\n   You should now have a /dist directory with both .whl and .tar.gz source versions.\n\n5. Check that everything looks correct by uploading the package to the pypi test server:\n\n   twine upload dist/* -r pypitest --repository-url=https://test.pypi.org/legacy/\n\n   Check that you can install it in a virtualenv/notebook by running:\n   pip install huggingface_hub fsspec aiohttp\n   pip install -U tqdm\n   pip install -i https://testpypi.python.org/pypi evaluate\n\n6. Upload the final version to actual pypi:\n   twine upload dist/* -r pypi\n\n7. Fill release notes in the tag in github once everything is looking hunky-dory.\n\n8. Change the version in __init__.py and setup.py to X.X.X+1.dev0 (e.g. VERSION=1.18.3 -> 1.18.4.dev0).\n   Then push the change with a message 'set dev version'\n\"\"\"\n\nfrom setuptools import find_packages, setup\n\n\n__version__ = \"0.14.0.dev0\"  # expected format is one of x.y.z.dev0, or x.y.z.rc1 or x.y.z (no to dashes, yes to dots)\n\nREQUIRED_PKGS = [\n    \"accelerate>=0.34.0\",\n    \"datasets>=2.21.0\",\n    \"rich\",  # rich shouldn't be a required package for trl, we should remove it from here\n    \"transformers>=4.46.0\",\n]\nEXTRAS = {\n    # Windows support is partially supported with DeepSpeed https://github.com/microsoft/DeepSpeed/tree/master#windows\n    \"deepspeed\": [\"deepspeed>=0.14.4; sys_platform != 'win32'\"],\n    \"diffusers\": [\"diffusers>=0.18.0\"],\n    \"judges\": [\"openai>=1.23.2\", \"llm-blender>=0.0.2\"],\n    # liger-kernel depends on triton, which is only available on Linux https://github.com/triton-lang/triton#compatibility\n    \"liger\": [\"liger-kernel>=0.4.0; sys_platform != 'win32'\"],\n    \"mergekit\": [\"mergekit>=0.0.5.1\"],\n    \"peft\": [\"peft>=0.8.0\"],\n    \"quantization\": [\"bitsandbytes\"],\n    \"scikit\": [\"scikit-learn\"],\n    \"test\": [\"parameterized\", \"pytest-cov\", \"pytest-rerunfailures\", \"pytest-xdist\", \"pytest\"],\n    \"vlm\": [\"Pillow\"],\n}\nEXTRAS[\"dev\"] = []\nfor reqs in EXTRAS.values():\n    EXTRAS[\"dev\"].extend(reqs)\n\n\nsetup(\n    name=\"trl\",\n    license=\"Apache 2.0\",\n    classifiers=[\n        \"Development Status :: 2 - Pre-Alpha\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Science/Research\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n    ],\n    url=\"https://github.com/huggingface/trl\",\n    entry_points={\n        \"console_scripts\": [\"trl=trl.cli:main\"],\n    },\n    include_package_data=True,\n    package_data={\n        \"trl\": [\"templates/*.md\"],\n    },\n    packages=find_packages(exclude={\"tests\", \"tests.slow\"}),\n    install_requires=REQUIRED_PKGS,\n    extras_require=EXTRAS,\n    python_requires=\">=3.9\",\n    long_description=open(\"README.md\", encoding=\"utf-8\").read(),\n    long_description_content_type=\"text/markdown\",\n    zip_safe=False,\n    version=__version__,\n    description=\"Train transformer language models with reinforcement learning.\",\n    keywords=\"ppo, transformers, huggingface, gpt2, language modeling, rlhf\",\n    author=\"Leandro von Werra\",\n    author_email=\"leandro.vonwerra@gmail.com\",\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "trl",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}