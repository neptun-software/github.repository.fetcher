{
  "metadata": {
    "timestamp": 1736561155841,
    "page": 107,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjExMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "quantopian/zipline",
      "stars": 17903,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".appveyor.yml",
          "type": "blob",
          "size": 6.2587890625,
          "content": "#matrix:\n#  fast_finish: true\n\nenvironment:\n  global:\n    # SDK v7.0 MSVC Express 2008's SetEnv.cmd script will fail if the\n    # /E:ON and /V:ON options are not enabled in the batch script intepreter\n    # See: http://stackoverflow.com/a/13751649/163740\n    CMD_IN_ENV: \"cmd /E:ON /V:ON /C .\\\\ci\\\\appveyor\\\\run_with_env.cmd\"\n\n    # 1. Generated a token for appveyor at https://anaconda.org/quantopian/settings/access with scope api:write.\n    #   Can also be done via anaconda CLI with\n    #     $ anaconda auth --create --name my_appveyor_token\n    # 2. Generated secure env var below via appveyor's Encrypt data tool at https://ci.appveyor.com/tools/encrypt.\n    #   See https://www.appveyor.com/docs/build-configuration/#secure-variables.\n    ANACONDA_TOKEN:\n      secure: \"kXWRGusUvfZgrrWTTH3Eou2NGy3UTlMz/6vjwY00bWZdbE6LsgByBb8ARMV+BzR4\"\n\n    CONDA_ROOT_PYTHON_VERSION: \"2.7\"\n\n    PYTHON_ARCH: \"64\"\n    PANDAS_VERSION: \"0.18.1\"\n    NUMPY_VERSION: \"1.11.3\"\n    SCIPY_VERSION: \"0.17.1\"\n\n  matrix:\n    - PYTHON_VERSION: \"2.7\"\n    - PYTHON_VERSION: \"3.5\"\n\n    - PYTHON_VERSION: \"3.5\"\n      PANDAS_VERSION: \"0.22.0\"\n      NUMPY_VERSION: \"1.14.1\"\n      SCIPY_VERSION: \"1.0.0\"\n      STATSMODELS_VERSION: \"0.9.0\"\n      PANDAS_DATAREADER_VERSION: \"0.4.0\"\n      DASK_VERSION: \"0.17.1\"\n\n    - PYTHON_VERSION: \"3.6\"\n      PANDAS_VERSION: \"0.22.0\"\n      NUMPY_VERSION: \"1.14.1\"\n      SCIPY_VERSION: \"1.0.0\"\n      STATSMODELS_VERSION: \"0.9.0\"\n      PANDAS_DATAREADER_VERSION: \"0.4.0\"\n      DASK_VERSION: \"0.17.1\"\n\n# We always use a 64-bit machine, but can build x86 distributions\n# with the PYTHON_ARCH variable (which is used by CMD_IN_ENV).\nplatform:\n  - x64\n\ncache:\n  - '%LOCALAPPDATA%\\pip\\Cache'\n\n# all our python builds have to happen in tests_script...\nbuild: false\n\ninit:\n  - \"ECHO %PYTHON_VERSION% %PYTHON_ARCH% %PYTHON%\"\n  - \"ECHO %NUMPY_VERSION%\"\n\ninstall:\n  # If there is a newer build queued for the same PR, cancel this one.\n  # The AppVeyor 'rollout builds' option is supposed to serve the same\n  # purpose but it is problematic because it tends to cancel builds pushed\n  # directly to master instead of just PR builds (or the converse).\n  # credits: JuliaLang developers.\n  - ps: if ($env:APPVEYOR_PULL_REQUEST_NUMBER -and $env:APPVEYOR_BUILD_NUMBER -ne ((Invoke-RestMethod `\n        https://ci.appveyor.com/api/projects/$env:APPVEYOR_ACCOUNT_NAME/$env:APPVEYOR_PROJECT_SLUG/history?recordsNumber=50).builds | `\n        Where-Object pullRequestId -eq $env:APPVEYOR_PULL_REQUEST_NUMBER)[0].buildNumber) { `\n          throw \"There are newer queued builds for this pull request, failing early.\" }\n\n  - ps: $NPY_VERSION_ARR=$env:NUMPY_VERSION -split '.', 0, 'simplematch'\n  - ps: $env:CONDA_NPY=$NPY_VERSION_ARR[0..1] -join \"\"\n  - ps: $PY_VERSION_ARR=$env:PYTHON_VERSION -split '.', 0, 'simplematch'\n  - ps: $env:CONDA_PY=$PY_VERSION_ARR[0..1] -join \"\"\n  - SET PYTHON=C:\\Python%CONDA_PY%_64\n  # Get cygwin's git out of our PATH.  See https://github.com/omnia-md/conda-dev-recipes/pull/16/files#diff-180360612c6b8c4ed830919bbb4dd459\n  - \"del C:\\\\cygwin\\\\bin\\\\git.exe\"\n  # this installs the appropriate Miniconda (Py2/Py3, 32/64 bit),\n  - powershell .\\ci\\appveyor\\install.ps1\n  - SET PATH=%PYTHON%;%PYTHON%\\Scripts;%PATH%\n  - sed -i \"s/numpy==.*/numpy==%NUMPY_VERSION%/\" etc/requirements_locked.txt\n  - sed -i \"s/pandas==.*/pandas==%PANDAS_VERSION%/\" etc/requirements_locked.txt\n  - sed -i \"s/scipy==.*/scipy==%SCIPY_VERSION%/\" etc/requirements_locked.txt\n  - IF NOT \"%STATSMODELS_VERSION%\"==\"\" sed -i \"s/statsmodels==.*/statsmodels==%STATSMODELS_VERSION%/\" etc/requirements_locked.txt\n  - IF NOT \"%PANDAS_DATAREADER_VERSION%\"==\"\" sed -i \"s/pandas-datareader==.*/pandas-datareader==%PANDAS_DATAREADER_VERSION%/\" etc/requirements_locked.txt\n  - IF NOT \"%DASK_VERSION%\"==\"\" sed -i \"s/dask\\[dataframe\\]==.*/dask\\[dataframe\\]==%DASK_VERSION%/\" etc/requirements_locked.txt\n  - cat etc/requirements_locked.txt\n  - conda info -a\n  - conda install conda=4.3.30 conda-build=3.0.28 anaconda-client=1.6.3 --yes -q\n  - conda list\n  # https://blog.ionelmc.ro/2014/12/21/compiling-python-extensions-on-windows/ for 64bit C compilation\n  - ps: copy .\\ci\\appveyor\\vcvars64.bat \"C:\\Program Files (x86)\\Microsoft Visual Studio 10.0\\VC\\bin\\amd64\"\n  - \"ECHO APPVEYOR_PULL_REQUEST_NUMBER: %APPVEYOR_PULL_REQUEST_NUMBER% APPVEYOR_REPO_BRANCH: %APPVEYOR_REPO_BRANCH%\"\n  - \"%CMD_IN_ENV% python .\\\\ci\\\\make_conda_packages.py\"\n\n  # test that we can conda install zipline in a new env\n  - conda create -n installenv --yes -q --use-local python=%PYTHON_VERSION% numpy=%NUMPY_VERSION% zipline -c quantopian -c https://conda.anaconda.org/quantopian/label/ci\n\n  - ps: $env:BCOLZ_VERSION=(sls \"bcolz==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  - ps: $env:NUMEXPR_VERSION=(sls \"numexpr==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  - ps: $env:PYTABLES_VERSION=(sls \"tables==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  - ps: $env:H5PY_VERSION=(sls \"h5py==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  - ps: $env:TALIB_VERSION=(sls \"ta-lib==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  # We conda install certifi at the pinned exact version because it is a transitive dependency of zipline via requests and uses distutils for packaging.\n  # Since conda installs latest certifi by default, we would fail to uninstall that new version when trying to install the pinned version using pip later in the build:\n  # \"Cannot uninstall 'certifi'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\"\n  - ps: $env:CERTIFI_VERSION=(sls \"certifi==([^ ]*)\" .\\etc\\requirements_locked.txt -ca).matches.groups[1].value\n  - conda create -n testenv --yes -q --use-local \"pip<19\" python=%PYTHON_VERSION% numpy=%NUMPY_VERSION% pandas=%PANDAS_VERSION% scipy=%SCIPY_VERSION% ta-lib=%TALIB_VERSION% bcolz=%BCOLZ_VERSION% numexpr=%NUMEXPR_VERSION% pytables=%PYTABLES_VERSION% h5py=%H5PY_VERSION% certifi=%CERTIFI_VERSION% -c quantopian -c https://conda.anaconda.org/quantopian/label/ci\n  - activate testenv\n  - bash etc/dev-install --cache-dir=%LOCALAPPDATA%\\pip\\Cache\\pip_np%CONDA_NPY%py%CONDA_PY%\n  - python -m pip freeze | sort\n\ntest_script:\n  - nosetests -e zipline.utils.numpy_utils\n  - flake8 zipline tests\n\nbranches:\n  only:\n    - master\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.1044921875,
          "content": "[report]\nomit =\n    */python?.?/*\n    */site-packages/nose/*\nexclude_lines =\n    raise NotImplementedError\n"
        },
        {
          "name": ".dir-locals.el",
          "type": "blob",
          "size": 0.134765625,
          "content": "((nil . ((sentence-end-double-space . t)))\n (python-mode . ((fill-column . 79)\n                 (python-fill-docstring-style . django))))\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.046875,
          "content": "MANIFEST.in\n**/*pyc\n.eggs\ndist\nbuild\n*.egg-info\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.046875,
          "content": "zipline/_version.py export-subst\n*.ipynb binary\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7802734375,
          "content": ".bundle\ndb/*.sqlite3\nlog/*.log\n*.log\ntmp/**/*\ntmp/*\n*.swp\n*~\n#mac autosaving file\n.DS_Store\n*.py[co]\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.tox\ntest.log\n.noseids\n*.xlsx\n\n# Compiled python files\n*.py[co]\n\n# Packages\n*.egg\n.eggs/*\n*.egg-info\ndist\nbuild\neggs\ncover\nparts\nbin\nvar\nsdist\ndevelop-eggs\n.installed.cfg\ncoverage.xml\nhtmlcov\nnosetests.xml\n\n# C Extensions\n*.o\n*.so\n*.out\n# git add -f if needed\n*.c\n\n# Vim\n*.swp\n*.swo\n\n# Built documentation\ndocs/_build/*\n\n# Un-tarred example data input. We should only commit the tarball.\ntests/resources/example_data/*\n\n# database of vbench\nbenchmarks.db\n\n# Vagrant temp folder\n.vagrant\n\n# Intellij IDE temp project files\n.project\nzipline.iml\n\n# PyCharm custom settings\n.idea\n\nTAGS\n\n.ipynb_checkpoints/\n\n.gdb_history\n\n*.dSYM/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.275390625,
          "content": "repos:\n- repo: https://github.com/pre-commit/pre-commit-hooks\n  rev: 'v2.4.0'\n  hooks:\n  - id: check-added-large-files\n  - id: check-merge-conflict\n  - id: end-of-file-fixer\n  - id: trailing-whitespace\n\n- repo: https://gitlab.com/pycqa/flake8\n  rev: '3.7.9'\n  hooks:\n  - id: flake8\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 5.4853515625,
          "content": "language: python\nfast_finish: true\npython:\n  - 2.7\n  - 3.5\n  - 3.6\nenv:\n  global:\n    # 1. Generated a token for travis at https://anaconda.org/quantopian/settings/access with scope api:write.\n    #   Can also be done via anaconda CLI with\n    #     $ TOKEN=$(anaconda auth --create --name my_travis_token)\n    # 2. Generated secure env var below with travis gem via\n    #     $ travis encrypt ANACONDA_TOKEN=$TOKEN\n    #   See https://github.com/travis-ci/travis.rb#installation.\n    #   If authenticating travis gem with github, a github token with the following scopes\n    #   is sufficient: [\"read:org\", \"user:email\", \"repo_deployment\", \"repo:status\", \"write:repo_hook\"]\n    #   See https://docs.travis-ci.com/api#external-apis.\n    - secure: \"MxLrJ0ry2NtZXp4zESb0KP+AUuVns96XfPyZgmxrMOjH4epqLiP5NxaY/5UF9oTEdNQDnPO3Rw7M8rH8vuX5dzOVzP2/miAc+ltFQmlaXuERY5fu2LYTST8MCxokiuD4fdaFPFiaCCSrk+zQZSX2uDn161vK+FqZyGAQ9EEJebQ=\"\n    - CONDA_ROOT_PYTHON_VERSION: \"2.7\"\n  matrix:\n    - OLD_PANDAS=1\n    - NEW_PANDAS=1\nmatrix:\n  exclude:\n    - python: 2.7\n      env: NEW_PANDAS=1\n    - python: 3.6\n      env: OLD_PANDAS=1\n#  include:\n#    # Workaround Travis OSX not natively supporting Python.\n#    - os: osx\n#      language: generic\n#      env: TRAVIS_PYTHON_VERSION=2.7 OLD_PANDAS=1\n#    - os: osx\n#      language: generic\n#      env: TRAVIS_PYTHON_VERSION=3.5 OLD_PANDAS=1\n#    - os: osx\n#      language: generic\n#      env: TRAVIS_PYTHON_VERSION=3.5 NEW_PANDAS=1\n\ncache:\n  directories:\n    - $HOME/.cache/.pip/\n\nbefore_install:\n  - source ./ci/travis/install_miniconda.sh\n  - |\n    if [ \"$OLD_PANDAS\" ]; then\n      NUMPY_VERSION=1.11.3 PANDAS_VERSION=0.18.1 SCIPY_VERSION=0.17.1\n    else\n      NUMPY_VERSION=1.14.1 PANDAS_VERSION=0.22.0 SCIPY_VERSION=1.0.0 STATSMODELS_VERSION=0.9.0 PANDAS_DATAREADER_VERSION=0.4.0 DASK_VERSION=0.17.1\n    fi\n  - source ./ci/travis/overwrite_requirements.sh\n  - cat etc/requirements_locked.txt\n\ninstall:\n  - conda info -a\n  - conda install conda=4.3.30 conda-build=3.0.28 anaconda-client=1.6.3 --yes -q\n  - conda list\n\n  - TALIB_VERSION=$(cat ./etc/requirements_locked.txt | grep \"ta-lib\" | sed \"s/ta-lib==\\([^ ]*\\) *.*/\\1/\")\n  - CERTIFI_VERSION=$(cat ./etc/requirements_locked.txt | grep \"certifi\" | sed \"s/certifi==\\([^ ]*\\) *.*/\\1/\")\n  - IFS='.' read -r -a NPY_VERSION_ARR <<< \"$NUMPY_VERSION\"\n  - CONDA_NPY=${NPY_VERSION_ARR[0]}${NPY_VERSION_ARR[1]}\n  - CONDA_PY=$TRAVIS_PYTHON_VERSION\n\n  - if [[ \"$TRAVIS_SECURE_ENV_VARS\" = \"true\" && \"$TRAVIS_BRANCH\" = \"master\" && \"$TRAVIS_PULL_REQUEST\" = \"false\" ]]; then DO_UPLOAD=\"true\"; else DO_UPLOAD=\"false\"; fi\n  - |\n    for recipe in $(ls -d conda/*/ | xargs -I {} basename {}); do\n      if [[ \"$recipe\" = \"zipline\" ]]; then continue; fi\n\n      conda build conda/$recipe --python=$CONDA_PY --numpy=$CONDA_NPY --skip-existing --old-build-string -c quantopian -c quantopian/label/ci\n      RECIPE_OUTPUT=$(conda build conda/$recipe --python=$CONDA_PY --numpy=$CONDA_NPY --old-build-string --output)\n      if [[ -f \"$RECIPE_OUTPUT\" && \"$DO_UPLOAD\" = \"true\" ]]; then anaconda -t $ANACONDA_TOKEN upload \"$RECIPE_OUTPUT\" -u quantopian --label ci; fi\n    done\n  # Make sure stdout is in blocking mode. If we don't, then conda create will barf during downloads.\n  # See https://github.com/travis-ci/travis-ci/issues/4704#issuecomment-348435959 for details.\n  - python -c 'import os,sys,fcntl; flags = fcntl.fcntl(sys.stdout, fcntl.F_GETFL); fcntl.fcntl(sys.stdout, fcntl.F_SETFL, flags&~os.O_NONBLOCK);'\n  # We conda install certifi at the pinned exact version because it is a transitive dependency of zipline via requests and uses distutils for packaging.\n  # Since conda installs latest certifi by default, we would fail to uninstall that new version when trying to install the pinned version using pip later in the build:\n  # \"Cannot uninstall 'certifi'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\"\n  - conda create -n testenv --use-local --yes -c quantopian -c quantopian/label/ci pip python=$TRAVIS_PYTHON_VERSION numpy=$NUMPY_VERSION pandas=$PANDAS_VERSION scipy=$SCIPY_VERSION ta-lib=$TALIB_VERSION libgfortran=3.0 certifi=$CERTIFI_VERSION\n  - source activate testenv\n\n  # XXX: With TRAVIS and CI both set, pip installing bcolz tries to compile it with coverage on py2, which fails to link against gcov on OSX.\n  # https://github.com/Blosc/bcolz/blob/8234a7505da5188dbaf415b7e36d4609d2c8c2f1/setup.py#L134-L136\n  - TRAVIS='' EXTERNAL_REQUIREMENTS='coveralls' etc/dev-install --cache-dir=\"$HOME/.cache/.pip/pip_np$CONDA_NPY\"\n\nbefore_script:\n  - pip freeze | sort\nscript:\n  - flake8 zipline tests\n  - nosetests --with-coverage\n  # deactivate env to get access to anaconda command\n  - source deactivate\n\n  # unshallow the clone so the conda build can clone it.\n  - git fetch --unshallow --tags\n  - exec 3>&1; ZP_OUT=$(conda build conda/zipline --python=$CONDA_PY --numpy=$CONDA_NPY -c quantopian -c quantopian/label/ci | tee >(cat - >&3))\n  - ZP_OUTPUT=$(echo \"$ZP_OUT\" | grep \"anaconda upload \" | awk '{print $NF}')\n  - if [ -z \"$ZP_OUTPUT\" ]; then exit 1; fi\n  # test that we can conda install zipline in a new env\n  - conda create -n installenv --yes -q --use-local python=$TRAVIS_PYTHON_VERSION numpy=$NUMPY_VERSION zipline -c quantopian -c https://conda.anaconda.org/quantopian/label/ci\n  - if [[ \"$DO_UPLOAD\" = \"true\" ]]; then anaconda -t $ANACONDA_TOKEN upload $ZP_OUTPUT -u quantopian --label ci; fi\n  # reactivate env (necessary for coveralls)\n  - source activate testenv\n\nafter_success:\n  - coveralls\n\nbranches:\n  only:\n    - master\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.6474609375,
          "content": "Eddie Hebert\nfawce\nThomas Wiecki\nStephen Diehl\nscottsanderson\nScott Sanderson\nRichard Frank\nJonathan Kamens\ntwiecki\nJoe Jevnik\nDelaney Granizo-Mackenzie\nTobias Brandt\nBen McCann\nJohn Ricklefs\nJenkins T. Quantopian, III\nJeremiah Lowin\njbredeche\nBrian Fink\nDavid Edwards\nMatti Hanninen\nRyan Day\nllllllllll\nDavid Stephens\nTim\nDale Jung\nJamie Kirkpatrick\nJean Bredeche\nWes McKinney\njikamens\nAidan\nColin Alexander\nElektra58\nJason Kölker\nJeremi Joslin\nLuke Schiefelbein\nMartin Dengler\nMete Atamel\nMichael Schatzow\nMoises Trovo\nNicholas Pezolano\nPankaj Garg\nPaolo Bernardi\nPeter Cawthron\nPhilipp Kosel\nSuminda Dharmasena\nThe Gitter Badger\nTony Lambiris\nTony Worm\nstanh\n"
        },
        {
          "name": "CONTRIBUTING.rst",
          "type": "blob",
          "size": 0.6826171875,
          "content": "Contributing to Zipline\n=======================\nFor developers of Zipline, people who want to contribute to the Zipline codebase or documentation, or people who want to install from source and make local changes to their copy of Zipline, please refer to the `Development Guidelines`__ if you would like to contribute.\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements and ideas are welcome. We `track issues`__ on `GitHub`__ and also have a `mailing list`__ where you can ask questions.\n\n__ https://www.zipline.io/development-guidelines.html\n__ https://github.com/quantopian/zipline/issues\n__ https://github.com/\n__ https://groups.google.com/forum/#!forum/zipline\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.4365234375,
          "content": "#\n# Dockerfile for an image with the currently checked out version of zipline installed. To build:\n#\n#    docker build -t quantopian/zipline .\n#\n# To run the container:\n#\n#    docker run -v /path/to/your/notebooks:/projects -v ~/.zipline:/root/.zipline -p 8888:8888/tcp --name zipline -it quantopian/zipline\n#\n# To access Jupyter when running docker locally (you may need to add NAT rules):\n#\n#    https://127.0.0.1\n#\n# default password is jupyter.  to provide another, see:\n#    http://jupyter-notebook.readthedocs.org/en/latest/public_server.html#preparing-a-hashed-password\n#\n# once generated, you can pass the new value via `docker run --env` the first time\n# you start the container.\n#\n# You can also run an algo using the docker exec command.  For example:\n#\n#    docker exec -it zipline zipline run -f /projects/my_algo.py --start 2015-1-1 --end 2016-1-1 -o /projects/result.pickle\n#\nFROM python:3.5\n\n#\n# set up environment\n#\nENV TINI_VERSION v0.10.0\nADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"--\"]\n\nENV PROJECT_DIR=/projects \\\n    NOTEBOOK_PORT=8888 \\\n    SSL_CERT_PEM=/root/.jupyter/jupyter.pem \\\n    SSL_CERT_KEY=/root/.jupyter/jupyter.key \\\n    PW_HASH=\"u'sha1:31cb67870a35:1a2321318481f00b0efdf3d1f71af523d3ffc505'\" \\\n    CONFIG_PATH=/root/.jupyter/jupyter_notebook_config.py\n\n#\n# install TA-Lib and other prerequisites\n#\n\nRUN mkdir ${PROJECT_DIR} \\\n    && apt-get -y update \\\n    && apt-get -y install libfreetype6-dev libpng-dev libopenblas-dev liblapack-dev gfortran libhdf5-dev \\\n    && curl -L https://downloads.sourceforge.net/project/ta-lib/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz | tar xvz\n\n#\n# build and install zipline from source.  install TA-Lib after to ensure\n# numpy is available.\n#\n\nWORKDIR /ta-lib\n\nRUN pip install 'numpy>=1.11.1,<2.0.0' \\\n  && pip install 'scipy>=0.17.1,<1.0.0' \\\n  && pip install 'pandas>=0.18.1,<1.0.0' \\\n  && ./configure --prefix=/usr \\\n  && make \\\n  && make install \\\n  && pip install TA-Lib \\\n  && pip install matplotlib \\\n  && pip install jupyter\n\n#\n# This is then only file we need from source to remain in the\n# image after build and install.\n#\n\nADD ./etc/docker_cmd.sh /\n\n#\n# make port available. /zipline is made a volume\n# for developer testing.\n#\nEXPOSE ${NOTEBOOK_PORT}\n\n#\n# build and install the zipline package into the image\n#\n\nADD . /zipline\nWORKDIR /zipline\nRUN pip install -e .\n\n#\n# start the jupyter server\n#\n\nWORKDIR ${PROJECT_DIR}\nCMD /docker_cmd.sh\n"
        },
        {
          "name": "Dockerfile-dev",
          "type": "blob",
          "size": 1.2861328125,
          "content": "#\n# Dockerfile for an image with the currently checked out version of zipline installed. To build:\n#\n#    docker build -t quantopian/ziplinedev -f Dockerfile-dev .\n#\n# Note: the dev build requires a quantopian/zipline image, which you can build as follows:\n#\n#    docker build -t quantopian/zipline -f Dockerfile\n#\n# To run the container:\n#\n#    docker run -v /path/to/your/notebooks:/projects -v ~/.zipline:/root/.zipline -p 8888:8888/tcp --name ziplinedev -it quantopian/ziplinedev\n#\n# To access Jupyter when running docker locally (you may need to add NAT rules):\n#\n#    https://127.0.0.1\n#\n# default password is jupyter.  to provide another, see:\n#    http://jupyter-notebook.readthedocs.org/en/latest/public_server.html#preparing-a-hashed-password\n#\n# once generated, you can pass the new value via `docker run --env` the first time\n# you start the container.\n#\n# You can also run an algo using the docker exec command.  For example:\n#\n#    docker exec -it ziplinedev zipline run -f /projects/my_algo.py --start 2015-1-1 --end 2016-1-1 /projects/result.pickle\n#\nFROM quantopian/zipline\n\nWORKDIR /zipline\n\nRUN pip install -r etc/requirements_dev.txt -r etc/requirements_blaze.txt\n# Clean out any cython assets. The pip install re-builds them.\nRUN find . -type f -name '*.c' -exec rm {} + && pip install -e .[all]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0810546875,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 Quantopian, Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.2568359375,
          "content": "include LICENSE\n\ninclude etc/requirements*.txt\ninclude etc/requirements*.in\nrecursive-include zipline *.pyi\nrecursive-include zipline *.pxi\nrecursive-include zipline *.pxd\n\nrecursive-include zipline/resources *.*\ninclude versioneer.py\ninclude zipline/_version.py\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 6.3125,
          "content": ".. image:: https://media.quantopian.com/logos/open_source/zipline-logo-03_.png\n    :target: https://www.zipline.io\n    :width: 212px\n    :align: center\n    :alt: Zipline\n\n=============\n\n|Gitter|\n|pypi version status|\n|pypi pyversion status|\n|travis status|\n|appveyor status|\n|Coverage Status|\n\nZipline is a Pythonic algorithmic trading library. It is an event-driven\nsystem for backtesting. Zipline is currently used in production as the backtesting and live-trading\nengine powering `Quantopian <https://www.quantopian.com>`_ -- a free,\ncommunity-centered, hosted platform for building and executing trading\nstrategies. Quantopian also offers a `fully managed service for professionals <https://factset.quantopian.com>`_\nthat includes Zipline, Alphalens, Pyfolio, FactSet data, and more.\n\n- `Join our Community! <https://groups.google.com/forum/#!forum/zipline>`_\n- `Documentation <https://www.zipline.io>`_\n- Want to Contribute? See our `Development Guidelines <https://www.zipline.io/development-guidelines>`_\n\nFeatures\n========\n\n- **Ease of Use:** Zipline tries to get out of your way so that you can\n  focus on algorithm development. See below for a code example.\n- **\"Batteries Included\":** many common statistics like\n  moving average and linear regression can be readily accessed from\n  within a user-written algorithm.\n- **PyData Integration:** Input of historical data and output of performance statistics are\n  based on Pandas DataFrames to integrate nicely into the existing\n  PyData ecosystem.\n- **Statistics and Machine Learning Libraries:** You can use libraries like matplotlib, scipy,\n  statsmodels, and sklearn to support development, analysis, and\n  visualization of state-of-the-art trading systems.\n\nInstallation\n============\n\nZipline currently supports Python 2.7, 3.5, and 3.6, and may be installed via\neither pip or conda.\n\n**Note:** Installing Zipline is slightly more involved than the average Python\npackage. See the full `Zipline Install Documentation`_ for detailed\ninstructions.\n\nFor a development installation (used to develop Zipline itself), create and\nactivate a virtualenv, then run the ``etc/dev-install`` script.\n\nQuickstart\n==========\n\nSee our `getting started tutorial <https://www.zipline.io/beginner-tutorial>`_.\n\nThe following code implements a simple dual moving average algorithm.\n\n.. code:: python\n\n    from zipline.api import order_target, record, symbol\n\n    def initialize(context):\n        context.i = 0\n        context.asset = symbol('AAPL')\n\n\n    def handle_data(context, data):\n        # Skip first 300 days to get full windows\n        context.i += 1\n        if context.i < 300:\n            return\n\n        # Compute averages\n        # data.history() has to be called with the same params\n        # from above and returns a pandas dataframe.\n        short_mavg = data.history(context.asset, 'price', bar_count=100, frequency=\"1d\").mean()\n        long_mavg = data.history(context.asset, 'price', bar_count=300, frequency=\"1d\").mean()\n\n        # Trading logic\n        if short_mavg > long_mavg:\n            # order_target orders as many shares as needed to\n            # achieve the desired number of shares.\n            order_target(context.asset, 100)\n        elif short_mavg < long_mavg:\n            order_target(context.asset, 0)\n\n        # Save values for later inspection\n        record(AAPL=data.current(context.asset, 'price'),\n               short_mavg=short_mavg,\n               long_mavg=long_mavg)\n\n\nYou can then run this algorithm using the Zipline CLI.\nFirst, you must download some sample pricing and asset data:\n\n.. code:: bash\n\n    $ zipline ingest\n    $ zipline run -f dual_moving_average.py --start 2014-1-1 --end 2018-1-1 -o dma.pickle --no-benchmark\n\nThis will download asset pricing data data sourced from Quandl, and stream it through the algorithm over the specified time range.\nThen, the resulting performance DataFrame is saved in ``dma.pickle``, which you can load and analyze from within Python.\n\nYou can find other examples in the ``zipline/examples`` directory.\n\nQuestions?\n==========\n\nIf you find a bug, feel free to `open an issue <https://github.com/quantopian/zipline/issues/new>`_ and fill out the issue template.\n\nContributing\n============\n\nAll contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome. Details on how to set up a development environment can be found in our `development guidelines <https://www.zipline.io/development-guidelines>`_.\n\nIf you are looking to start working with the Zipline codebase, navigate to the GitHub `issues` tab and start looking through interesting issues. Sometimes there are issues labeled as `Beginner Friendly <https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Beginner+Friendly%22>`_ or `Help Wanted <https://github.com/quantopian/zipline/issues?q=is%3Aissue+is%3Aopen+label%3A%22Help+Wanted%22>`_.\n\nFeel free to ask questions on the `mailing list <https://groups.google.com/forum/#!forum/zipline>`_ or on `Gitter <https://gitter.im/quantopian/zipline>`_.\n\n.. note::\n\n   Please note that Zipline is not a community-led project. Zipline is\n   maintained by the Quantopian engineering team, and we are quite small and\n   often busy.\n\n   Because of this, we want to warn you that we may not attend to your pull\n   request, issue, or direct mention in months, or even years. We hope you\n   understand, and we hope that this note might help reduce any frustration or\n   wasted time.\n\n\n.. |Gitter| image:: https://badges.gitter.im/Join%20Chat.svg\n   :target: https://gitter.im/quantopian/zipline?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n.. |pypi version status| image:: https://img.shields.io/pypi/v/zipline.svg\n   :target: https://pypi.python.org/pypi/zipline\n.. |pypi pyversion status| image:: https://img.shields.io/pypi/pyversions/zipline.svg\n   :target: https://pypi.python.org/pypi/zipline\n.. |travis status| image:: https://travis-ci.org/quantopian/zipline.svg?branch=master\n   :target: https://travis-ci.org/quantopian/zipline\n.. |appveyor status| image:: https://ci.appveyor.com/api/projects/status/3dg18e6227dvstw6/branch/master?svg=true\n   :target: https://ci.appveyor.com/project/quantopian/zipline/branch/master\n.. |Coverage Status| image:: https://coveralls.io/repos/quantopian/zipline/badge.svg\n   :target: https://coveralls.io/r/quantopian/zipline\n\n.. _`Zipline Install Documentation` : https://www.zipline.io/install\n"
        },
        {
          "name": "Vagrantfile",
          "type": "blob",
          "size": 0.2783203125,
          "content": "# -*- mode: ruby -*-\n# vi: set ft=ruby :\n\nVagrant.configure(\"2\") do |config|\n  config.vm.box = \"ubuntu/trusty64\"\n  config.vm.provider :virtualbox do |vb|\n    vb.customize [\"modifyvm\", :id, \"--memory\", 2048, \"--cpus\", 2]\n  end\n  config.vm.provision \"shell\", path: \"vagrant_init.sh\"\nend\n"
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "conda",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "etc",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.58203125,
          "content": "[nosetests]\nverbosity=2\nwith-ignore-docstrings=1\nwith-timer=1\ntimer-top-n=15\ncover-package=zipline\nwith-doctest=1\ntestmatch=(?:^|[\\\\b_\\\\.-])[Tt]est(?!ing)\nlogging-level=INFO\n\n[metadata]\ndescription-file = README.rst\nlicense_file = LICENSE\n\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n[versioneer]\nVCS=git\nstyle=pep440\nversionfile_source=zipline/_version.py\nversionfile_build=zipline/_version.py\ntag_prefix=\nparentdir_prefix= zipline-\n\n[flake8]\nexclude =\n    versioneer.py\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 9.728515625,
          "content": "#!/usr/bin/env python\n#\n# Copyright 2014 Quantopian, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import print_function\nimport os\nimport re\nimport sys\nfrom operator import lt, gt, eq, le, ge\nfrom os.path import (\n    abspath,\n    dirname,\n    join,\n)\nfrom distutils.version import StrictVersion\nfrom setuptools import (\n    Extension,\n    find_packages,\n    setup,\n)\n\nimport versioneer\n\n\nclass LazyBuildExtCommandClass(dict):\n    \"\"\"\n    Lazy command class that defers operations requiring Cython and numpy until\n    they've actually been downloaded and installed by setup_requires.\n    \"\"\"\n    def __contains__(self, key):\n        return (\n            key == 'build_ext'\n            or super(LazyBuildExtCommandClass, self).__contains__(key)\n        )\n\n    def __setitem__(self, key, value):\n        if key == 'build_ext':\n            raise AssertionError(\"build_ext overridden!\")\n        super(LazyBuildExtCommandClass, self).__setitem__(key, value)\n\n    def __getitem__(self, key):\n        if key != 'build_ext':\n            return super(LazyBuildExtCommandClass, self).__getitem__(key)\n\n        from Cython.Distutils import build_ext as cython_build_ext\n        import numpy\n\n        # Cython_build_ext isn't a new-style class in Py2.\n        class build_ext(cython_build_ext, object):\n            \"\"\"\n            Custom build_ext command that lazily adds numpy's include_dir to\n            extensions.\n            \"\"\"\n            def build_extensions(self):\n                \"\"\"\n                Lazily append numpy's include directory to Extension includes.\n\n                This is done here rather than at module scope because setup.py\n                may be run before numpy has been installed, in which case\n                importing numpy and calling `numpy.get_include()` will fail.\n                \"\"\"\n                numpy_incl = numpy.get_include()\n                for ext in self.extensions:\n                    ext.include_dirs.append(numpy_incl)\n\n                super(build_ext, self).build_extensions()\n        return build_ext\n\n\ndef window_specialization(typename):\n    \"\"\"Make an extension for an AdjustedArrayWindow specialization.\"\"\"\n    return Extension(\n        'zipline.lib._{name}window'.format(name=typename),\n        ['zipline/lib/_{name}window.pyx'.format(name=typename)],\n        depends=['zipline/lib/_windowtemplate.pxi'],\n    )\n\n\next_modules = [\n    Extension('zipline.assets._assets', ['zipline/assets/_assets.pyx']),\n    Extension('zipline.assets.continuous_futures',\n              ['zipline/assets/continuous_futures.pyx']),\n    Extension('zipline.lib.adjustment', ['zipline/lib/adjustment.pyx']),\n    Extension('zipline.lib._factorize', ['zipline/lib/_factorize.pyx']),\n    window_specialization('float64'),\n    window_specialization('int64'),\n    window_specialization('int64'),\n    window_specialization('uint8'),\n    window_specialization('label'),\n    Extension('zipline.lib.rank', ['zipline/lib/rank.pyx']),\n    Extension('zipline.data._equities', ['zipline/data/_equities.pyx']),\n    Extension('zipline.data._adjustments', ['zipline/data/_adjustments.pyx']),\n    Extension('zipline._protocol', ['zipline/_protocol.pyx']),\n    Extension(\n        'zipline.finance._finance_ext',\n        ['zipline/finance/_finance_ext.pyx'],\n    ),\n    Extension('zipline.gens.sim_engine', ['zipline/gens/sim_engine.pyx']),\n    Extension(\n        'zipline.data._minute_bar_internal',\n        ['zipline/data/_minute_bar_internal.pyx']\n    ),\n    Extension(\n        'zipline.data._resample',\n        ['zipline/data/_resample.pyx']\n    ),\n    Extension(\n        'zipline.pipeline.loaders.blaze._core',\n        ['zipline/pipeline/loaders/blaze/_core.pyx'],\n        depends=['zipline/lib/adjustment.pxd'],\n    ),\n]\n\n\nSTR_TO_CMP = {\n    '<': lt,\n    '<=': le,\n    '=': eq,\n    '==': eq,\n    '>': gt,\n    '>=': ge,\n}\n\nSYS_VERSION = '.'.join(list(map(str, sys.version_info[:3])))\n\n\ndef _filter_requirements(lines_iter, filter_names=None,\n                         filter_sys_version=False):\n    for line in lines_iter:\n        line = line.strip()\n        if not line or line.startswith('#'):\n            continue\n\n        match = REQ_PATTERN.match(line)\n        if match is None:\n            raise AssertionError(\"Could not parse requirement: %r\" % line)\n\n        name = match.group('name')\n        if filter_names is not None and name not in filter_names:\n            continue\n\n        if filter_sys_version and match.group('pyspec'):\n            pycomp, pyspec = match.group('pycomp', 'pyspec')\n            comp = STR_TO_CMP[pycomp]\n            pyver_spec = StrictVersion(pyspec)\n            if comp(SYS_VERSION, pyver_spec):\n                # pip install -r understands lines with ;python_version<'3.0',\n                # but pip install -e does not.  Filter here, removing the\n                # env marker.\n                yield line.split(';')[0]\n            continue\n\n        yield line\n\n\nREQ_PATTERN = re.compile(\n    r\"(?P<name>[^=<>;]+)((?P<comp>[<=>]{1,2})(?P<spec>[^;]+))?\"\n    r\"(?:(;\\W*python_version\\W*(?P<pycomp>[<=>]{1,2})\\W*\"\n    r\"(?P<pyspec>[0-9.]+)))?\\W*\"\n)\n\n\ndef _conda_format(req):\n    def _sub(m):\n        name = m.group('name').lower()\n        if name == 'numpy':\n            return 'numpy x.x'\n        if name == 'tables':\n            name = 'pytables'\n\n        comp, spec = m.group('comp', 'spec')\n        if comp and spec:\n            formatted = '%s %s%s' % (name, comp, spec)\n        else:\n            formatted = name\n        pycomp, pyspec = m.group('pycomp', 'pyspec')\n        if pyspec:\n            # Compare the two-digit string versions as ints.\n            selector = ' # [int(py) %s int(%s)]' % (\n                pycomp, ''.join(pyspec.split('.')[:2]).ljust(2, '0')\n            )\n            return formatted + selector\n\n        return formatted\n\n    return REQ_PATTERN.sub(_sub, req, 1)\n\n\ndef read_requirements(path,\n                      conda_format=False,\n                      filter_names=None):\n    \"\"\"\n    Read a requirements file, expressed as a path relative to Zipline root.\n    \"\"\"\n    real_path = join(dirname(abspath(__file__)), path)\n    with open(real_path) as f:\n        reqs = _filter_requirements(f.readlines(), filter_names=filter_names,\n                                    filter_sys_version=not conda_format)\n\n        if conda_format:\n            reqs = map(_conda_format, reqs)\n\n        return list(reqs)\n\n\ndef install_requires(conda_format=False):\n    return read_requirements('etc/requirements.in', conda_format=conda_format)\n\n\ndef extras_requires(conda_format=False):\n    extras = {\n        extra: read_requirements('etc/requirements_{0}.in'.format(extra),\n                                 conda_format=conda_format)\n        for extra in ('dev', 'talib')\n    }\n    extras['all'] = [req for reqs in extras.values() for req in reqs]\n\n    return extras\n\n\ndef setup_requirements(requirements_path, module_names,\n                       conda_format=False):\n    module_names = set(module_names)\n    module_lines = read_requirements(requirements_path,\n                                     conda_format=conda_format,\n                                     filter_names=module_names)\n\n    if len(set(module_lines)) != len(module_names):\n        raise AssertionError(\n            \"Missing requirements. Looking for %s, but found %s.\"\n            % (module_names, module_lines)\n        )\n    return module_lines\n\n\nconda_build = os.path.basename(sys.argv[0]) in ('conda-build',  # unix\n                                                'conda-build-script.py')  # win\n\nsetup_requires = setup_requirements(\n    'etc/requirements_build.in',\n    ('Cython', 'numpy'),\n    conda_format=conda_build,\n)\n\nconditional_arguments = {\n    'setup_requires' if not conda_build else 'build_requires': setup_requires,\n}\n\nif 'sdist' in sys.argv:\n    with open('README.rst') as f:\n        conditional_arguments['long_description'] = f.read()\n\n\nsetup(\n    name='zipline',\n    url=\"https://zipline.io\",\n    version=versioneer.get_version(),\n    cmdclass=LazyBuildExtCommandClass(versioneer.get_cmdclass()),\n    description='A backtester for financial algorithms.',\n    entry_points={\n        'console_scripts': [\n            'zipline = zipline.__main__:main',\n        ],\n    },\n    author='Quantopian Inc.',\n    author_email='opensource@quantopian.com',\n    packages=find_packages(include=['zipline', 'zipline.*']),\n    ext_modules=ext_modules,\n    include_package_data=True,\n    package_data={root.replace(os.sep, '.'):\n                  ['*.pyi', '*.pyx', '*.pxi', '*.pxd']\n                  for root, dirnames, filenames in os.walk('zipline')\n                  if '__pycache__' not in root},\n    license='Apache 2.0',\n    classifiers=[\n        'Development Status :: 4 - Beta',\n        'License :: OSI Approved :: Apache Software License',\n        'Natural Language :: English',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 2.7',\n        'Programming Language :: Python :: 3.5',\n        'Programming Language :: Python :: 3.6',\n        'Operating System :: OS Independent',\n        'Intended Audience :: Science/Research',\n        'Topic :: Office/Business :: Financial',\n        'Topic :: Scientific/Engineering :: Information Analysis',\n        'Topic :: System :: Distributed Computing',\n    ],\n    install_requires=install_requires(conda_format=conda_build),\n    extras_require=extras_requires(conda_format=conda_build),\n    **conditional_arguments\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "vagrant_init.sh",
          "type": "blob",
          "size": 2.357421875,
          "content": "#!/bin/bash\n\n# This script will be run by Vagrant to\n# set up everything necessary to use Zipline.\n\n# Because this is intended be a disposable dev VM setup,\n# no effort is made to use virtualenv/virtualenvwrapper\n\n# It is assumed that you have \"vagrant up\"\n# from the root of the zipline github checkout.\n# This will put the zipline code in the\n# /vagrant folder in the system.\nset -e\n\nVAGRANT_LOG=\"/home/vagrant/vagrant.log\"\n\n# Need to \"hold\" grub-pc so that it doesn't break\n# the rest of the package installs (in case of a \"apt-get upgrade\")\n# (grub-pc will complain that your boot device changed, probably\n#  due to something that vagrant did, and break your console)\n\necho \"Obstructing updates to grub-pc...\" | tee -a \"$VAGRANT_LOG\"\napt-mark hold grub-pc 2>&1 | tee -a \"$VAGRANT_LOG\"\n\necho \"Adding python apt repo...\" | tee -a \"$VAGRANT_LOG\"\napt-add-repository -y ppa:fkrull/deadsnakes-python2.7 2>&1 | tee -a \"$VAGRANT_LOG\"\necho \"Updating apt-get caches...\" | tee -a \"$VAGRANT_LOG\"\napt-get -y update 2>&1 | tee -a \"$VAGRANT_LOG\"\n\necho \"Installing required system packages...\" | tee -a \"$VAGRANT_LOG\"\napt-get -y install python2.7 python-dev g++ make libfreetype6-dev libpng-dev libopenblas-dev liblapack-dev gfortran pkg-config git 2>&1 | tee -a \"$VAGRANT_LOG\"\n\necho \"Installing ta-lib...\" | tee -a \"$VAGRANT_LOG\"\nwget https://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz --no-verbose -a \"$VAGRANT_LOG\"\ntar -xvzf ta-lib-0.4.0-src.tar.gz 2>&1 | tee -a \"$VAGRANT_LOG\"\ncd ta-lib/\n./configure --prefix=/usr 2>&1 | tee -a \"$VAGRANT_LOG\"\nmake 2>&1 | tee -a \"$VAGRANT_LOG\"\nsudo make install 2>&1 | tee -a \"$VAGRANT_LOG\"\ncd ../\n\necho \"Installing pip and setuptools...\" | tee -a \"$VAGRANT_LOG\"\nwget https://bootstrap.pypa.io/get-pip.py 2>&1 | tee -a \"$VAGRANT_LOG\"\npython get-pip.py 2>&1 >> \"$VAGRANT_LOG\" | tee -a \"$VAGRANT_LOG\"\necho \"Installing zipline python dependencies...\" | tee -a \"$VAGRANT_LOG\"\npip install -r /vagrant/etc/requirements.in -r  2>&1 /vagrant/etc/requirements_dev.in -c /vagrant/etc/requirements_locked.txt | tee -a \"$VAGRANT_LOG\"\necho \"Installing zipline package itself...\" | tee -a \"$VAGRANT_LOG\"\n# Clean out any cython assets. The pip install re-builds them.\nfind /vagrant/ -type f -name '*.c' -exec rm {} +\npip install -e /vagrant[all] -c /vagrant/etc/requirements_locked.txt 2>&1 | tee -a \"$VAGRANT_LOG\"\necho \"Finished!  zipline repo is in '/vagrant'.\" | tee -a \"$VAGRANT_LOG\"\n"
        },
        {
          "name": "versioneer.py",
          "type": "blob",
          "size": 61.009765625,
          "content": "\n# Version: 0.15\n\n\"\"\"\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/warner/python-versioneer\n* Brian Warner\n* License: Public Domain\n* Compatible With: python2.6, 2.7, 3.2, 3.3, 3.4, and pypy\n* [![Latest Version]\n(https://pypip.in/version/versioneer/badge.svg?style=flat)\n](https://pypi.python.org/pypi/versioneer/)\n* [![Build Status]\n(https://travis-ci.org/warner/python-versioneer.png?branch=master)\n](https://travis-ci.org/warner/python-versioneer)\n\nThis is a tool for managing a recorded version number in distutils-based\npython projects. The goal is to remove the tedious and error-prone \"update\nthe embedded version string\" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\n* `pip install versioneer` to somewhere to your $PATH\n* add a `[versioneer]` section to your setup.cfg (see below)\n* run `versioneer install` in your source tree, commit the results\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github's\n  \"tarball from tag\" feature\n* a release tarball, produced by \"setup.py sdist\", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. \"git describe\" (for checkouts), which knows\n  about recent \"tags\" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. \"myproject-1.2\" instead of just \"1.2\"), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n\"0.7-1-g574ab98-dirty\" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of \"574ab98\", and is \"dirty\" (it has\nuncommitted changes.\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a 'setup.py sdist' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nFirst, decide on values for the following configuration variables:\n\n* `VCS`: the version control system you use. Currently accepts \"git\".\n\n* `style`: the style of version string to be produced. See \"Styles\" below for\n  details. Defaults to \"pep440\", which looks like\n  `TAG[+DISTANCE.gSHORTHASH[.dirty]]`.\n\n* `versionfile_source`:\n\n  A project-relative pathname into which the generated version strings should\n  be written. This is usually a `_version.py` next to your project's main\n  `__init__.py` file, so it can be imported at runtime. If your project uses\n  `src/myproject/__init__.py`, this should be `src/myproject/_version.py`.\n  This file should be checked in to your VCS as usual: the copy created below\n  by `setup.py setup_versioneer` will include code that parses expanded VCS\n  keywords in generated tarballs. The 'build' and 'sdist' commands will\n  replace it with a copy that has just the calculated version string.\n\n  This must be set even if your project does not have any modules (and will\n  therefore never import `_version.py`), since \"setup.py sdist\" -based trees\n  still need somewhere to record the pre-calculated version strings. Anywhere\n  in the source tree should do. If there is a `__init__.py` next to your\n  `_version.py`, the `setup.py setup_versioneer` command (described below)\n  will append some `__version__`-setting assignments, if they aren't already\n  present.\n\n* `versionfile_build`:\n\n  Like `versionfile_source`, but relative to the build directory instead of\n  the source directory. These will differ when your setup.py uses\n  'package_dir='. If you have `package_dir={'myproject': 'src/myproject'}`,\n  then you will probably have `versionfile_build='myproject/_version.py'` and\n  `versionfile_source='src/myproject/_version.py'`.\n\n  If this is set to None, then `setup.py build` will not attempt to rewrite\n  any `_version.py` in the built tree. If your project does not have any\n  libraries (e.g. if it only builds a script), then you should use\n  `versionfile_build = None` and override `distutils.command.build_scripts`\n  to explicitly insert a copy of `versioneer.get_version()` into your\n  generated script.\n\n* `tag_prefix`:\n\n  a string, like 'PROJECTNAME-', which appears at the start of all VCS tags.\n  If your tags look like 'myproject-1.2.0', then you should use\n  tag_prefix='myproject-'. If you use unprefixed tags like '1.2.0', this\n  should be an empty string.\n\n* `parentdir_prefix`:\n\n  a optional string, frequently the same as tag_prefix, which appears at the\n  start of all unpacked tarball filenames. If your tarball unpacks into\n  'myproject-1.2.0', this should be 'myproject-'. To disable this feature,\n  just omit the field from your `setup.cfg`.\n\nThis tool provides one script, named `versioneer`. That script has one mode,\n\"install\", which writes a copy of `versioneer.py` into the current directory\nand runs `versioneer.py setup` to finish the installation.\n\nTo versioneer-enable your project:\n\n* 1: Modify your `setup.cfg`, adding a section named `[versioneer]` and\n  populating it with the configuration values you decided earlier (note that\n  the option names are not case-sensitive):\n\n  ````\n  [versioneer]\n  VCS = git\n  style = pep440\n  versionfile_source = src/myproject/_version.py\n  versionfile_build = myproject/_version.py\n  tag_prefix = \"\"\n  parentdir_prefix = myproject-\n  ````\n\n* 2: Run `versioneer install`. This will do the following:\n\n  * copy `versioneer.py` into the top of your source tree\n  * create `_version.py` in the right place (`versionfile_source`)\n  * modify your `__init__.py` (if one exists next to `_version.py`) to define\n    `__version__` (by calling a function from `_version.py`)\n  * modify your `MANIFEST.in` to include both `versioneer.py` and the\n    generated `_version.py` in sdist tarballs\n\n  `versioneer install` will complain about any problems it finds with your\n  `setup.py` or `setup.cfg`. Run it multiple times until you have fixed all\n  the problems.\n\n* 3: add a `import versioneer` to your setup.py, and add the following\n  arguments to the setup() call:\n\n        version=versioneer.get_version(),\n        cmdclass=versioneer.get_cmdclass(),\n\n* 4: commit these changes to your VCS. To make sure you won't forget,\n  `versioneer install` will mark everything it touched for addition using\n  `git add`. Don't forget to add `setup.py` and `setup.cfg` too.\n\n## Post-Installation Usage\n\nOnce established, all uses of your tree from a VCS checkout should get the\ncurrent version string. All generated tarballs should include an embedded\nversion string (so users who unpack them will not need a VCS tool installed).\n\nIf you distribute your project through PyPI, then the release process should\nboil down to two steps:\n\n* 1: git tag 1.0\n* 2: python setup.py register sdist upload\n\nIf you distribute it through github (i.e. users use github to generate\ntarballs with `git archive`), the process is:\n\n* 1: git tag 1.0\n* 2: git push; git push --tags\n\nVersioneer will report \"0+untagged.NUMCOMMITS.gHASH\" until your tree has at\nleast one tag in its history.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the \"outside\" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `['version']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project's version\n  string. The default \"pep440\" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the \"Styles\" section\n  below for alternative styles.\n\n* `['full-revisionid']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. \"1076c978a8d3cfc70f408fe5974aa6c092c949ac\".\n\n* `['dirty']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `['error']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of \"unknown\".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an \"about\" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()['version']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, \"pep440\", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional \"local\nversion\" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example \"0.11+2.g1076c97.dirty\" indicates that the\ntree is like the \"1076c97\" commit but has uncommitted changes (\".dirty\"), and\nthat this commit is two revisions (\"+2\") beyond the \"0.11\" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. \"0.11\".\n\nOther styles are available. See details.md in the Versioneer source tree for\ndescriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of \"0+unknown\". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg`, if necessary, to include any new configuration settings\n  indicated by the release notes\n* re-run `versioneer install` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n### Upgrading to 0.15\n\nStarting with this version, Versioneer is configured with a `[versioneer]`\nsection in your `setup.cfg` file. Earlier versions required the `setup.py` to\nset attributes on the `versioneer` module immediately after import. The new\nversion will refuse to run (raising an exception during import) until you\nhave provided the necessary `setup.cfg` section.\n\nIn addition, the Versioneer package provides an executable named\n`versioneer`, and the installation process is driven by running `versioneer\ninstall`. In 0.14 and earlier, the executable was named\n`versioneer-installer` and was run without an argument.\n\n### Upgrading to 0.14\n\n0.14 changes the format of the version string. 0.13 and earlier used\nhyphen-separated strings like \"0.11-2-g1076c97-dirty\". 0.14 and beyond use a\nplus-separated \"local version\" section strings, with dot-separated\ncomponents, like \"0.11+2.g1076c97\". PEP440-strict tools did not like the old\nformat, but should be ok with the new one.\n\n### Upgrading from 0.11 to 0.12\n\nNothing special.\n\n### Upgrading from 0.10 to 0.11\n\nYou must add a `versioneer.VCS = \"git\"` to your `setup.py` before re-running\n`setup.py setup_versioneer`. This will enable the use of additional\nversion-control systems (SVN, etc) in the future.\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n\n## License\n\nTo make Versioneer easier to embed, all its code is hereby released into the\npublic domain. The `_version.py` that it creates is also in the public\ndomain.\n\n\"\"\"\n\nfrom __future__ import print_function\ntry:\n    import configparser\nexcept ImportError:\n    import ConfigParser as configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\n\n\nclass VersioneerConfig:\n    pass\n\n\ndef get_root():\n    # we require that all commands are run from the project root, i.e. the\n    # directory that contains setup.py, setup.cfg, and versioneer.py .\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        # allow 'python path/to/setup.py COMMAND'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, \"setup.py\")\n        versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (os.path.exists(setup_py) or os.path.exists(versioneer_py)):\n        err = (\"Versioneer was unable to run the project root directory. \"\n               \"Versioneer requires setup.py to be executed from \"\n               \"its immediate directory (like 'python setup.py COMMAND'), \"\n               \"or in a way that lets it use sys.argv[0] to find the root \"\n               \"(like 'python path/to/setup.py COMMAND').\")\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # \"versioneer\" may be imported multiple times, and python's shared\n        # module-import table will cache the first one. So we can't use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        me = os.path.realpath(os.path.abspath(__file__))\n        if os.path.splitext(me)[0] != os.path.splitext(versioneer_py)[0]:\n            print(\"Warning: build in %s is using versioneer.py from %s\"\n                  % (os.path.dirname(me), versioneer_py))\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root):\n    # This might raise EnvironmentError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks \"VCS=\"). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    setup_cfg = os.path.join(root, \"setup.cfg\")\n    parser = configparser.SafeConfigParser()\n    with open(setup_cfg, \"r\") as f:\n        parser.readfp(f)\n    VCS = parser.get(\"versioneer\", \"VCS\")  # mandatory\n\n    def get(parser, name):\n        if parser.has_option(\"versioneer\", name):\n            return parser.get(\"versioneer\", name)\n        return None\n    cfg = VersioneerConfig()\n    cfg.VCS = VCS\n    cfg.style = get(parser, \"style\") or \"\"\n    cfg.versionfile_source = get(parser, \"versionfile_source\")\n    cfg.versionfile_build = get(parser, \"versionfile_build\")\n    cfg.tag_prefix = get(parser, \"tag_prefix\")\n    cfg.parentdir_prefix = get(parser, \"parentdir_prefix\")\n    cfg.verbose = get(parser, \"verbose\")\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    pass\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n        return None\n    return stdout\nLONG_VERSION_PY['git'] = '''\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain. Generated by\n# versioneer-0.15 (https://github.com/warner/python-versioneer)\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\n\n\ndef get_keywords():\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"%(DOLLAR)sFormat:%%d%(DOLLAR)s\"\n    git_full = \"%(DOLLAR)sFormat:%%H%(DOLLAR)s\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full}\n    return keywords\n\n\nclass VersioneerConfig:\n    pass\n\n\ndef get_config():\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"%(STYLE)s\"\n    cfg.tag_prefix = \"%(TAG_PREFIX)s\"\n    cfg.parentdir_prefix = \"%(PARENTDIR_PREFIX)s\"\n    cfg.versionfile_source = \"%(VERSIONFILE_SOURCE)s\"\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    pass\n\n\nLONG_VERSION_PY = {}\nHANDLERS = {}\n\n\ndef register_vcs_handler(vcs, method):  # decorator\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %%s\" %% dispcmd)\n                print(e)\n            return None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %%s\" %% (commands,))\n        return None\n    stdout = p.communicate()[0].strip()\n    if sys.version_info[0] >= 3:\n        stdout = stdout.decode()\n    if p.returncode != 0:\n        if verbose:\n            print(\"unable to run %%s (error)\" %% dispcmd)\n        return None\n    return stdout\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    # Source tarballs conventionally unpack into a directory that includes\n    # both the project name and a version string.\n    dirname = os.path.basename(root)\n    if not dirname.startswith(parentdir_prefix):\n        if verbose:\n            print(\"guessing rootdir is '%%s', but '%%s' doesn't start with \"\n                  \"prefix '%%s'\" %% (root, dirname, parentdir_prefix))\n        raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n    return {\"version\": dirname[len(parentdir_prefix):],\n            \"full-revisionid\": None,\n            \"dirty\": False, \"error\": None}\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs):\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():\n            if line.strip().startswith(\"git_refnames =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"refnames\"] = mo.group(1)\n            if line.strip().startswith(\"git_full =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"full\"] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = set([r for r in refs if re.search(r'\\d', r)])\n        if verbose:\n            print(\"discarding '%%s', no digits\" %% \",\".join(refs-tags))\n    if verbose:\n        print(\"likely tags: %%s\" %% \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(\"picking %%s\" %% r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None\n                    }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\"}\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    # this runs 'git' from the root of the source tree. This only gets called\n    # if the git-archive 'subst' keywords were *not* expanded, and\n    # _version.py hasn't already been rewritten with a short version string,\n    # meaning we're inside a checked out source tree.\n\n    if not os.path.exists(os.path.join(root, \".git\")):\n        if verbose:\n            print(\"no .git in %%s\" %% root)\n        raise NotThisMethod(\"no .git directory\")\n\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    # if there is a tag, this yields TAG-NUM-gHEX[-dirty]\n    # if there are no tags, this yields HEX[-dirty] (no NUM)\n    describe_out = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n                                      \"--always\", \"--long\"],\n                               cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%%s'\"\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%%s' doesn't start with prefix '%%s'\"\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[\"error\"] = (\"tag '%%s' doesn't start with prefix '%%s'\"\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        count_out = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n                                cwd=root)\n        pieces[\"distance\"] = int(count_out)  # total number of commits\n\n    return pieces\n\n\ndef plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces):\n    # now build up version string, with post-release \"local version\n    # identifier\". Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    # get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    # exceptions:\n    # 1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%%d.g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%%d.g%%s\" %% (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    # TAG[.post.devDISTANCE] . No -dirty\n\n    # exceptions:\n    # 1: no tags. 0.post.devDISTANCE\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%%d\" %% pieces[\"distance\"]\n    else:\n        # exception #1\n        rendered = \"0.post.dev%%d\" %% pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    # TAG[.postDISTANCE[.dev0]+gHEX] . The \".dev0\" means dirty. Note that\n    # .dev0 sorts backwards (a dirty tree will appear \"older\" than the\n    # corresponding clean one), but you shouldn't be releasing software with\n    # -dirty anyways.\n\n    # exceptions:\n    # 1: no tags. 0.postDISTANCE[.dev0]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%%s\" %% pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%%s\" %% pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    # TAG[.postDISTANCE[.dev0]] . The \".dev0\" means dirty.\n\n    # exceptions:\n    # 1: no tags. 0.postDISTANCE[.dev0]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces):\n    # TAG[-DISTANCE-gHEX][-dirty], like 'git describe --tags --dirty\n    # --always'\n\n    # exceptions:\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    # TAG-DISTANCE-gHEX[-dirty], like 'git describe --tags --dirty\n    # --always -long'. The distance/hash is unconditional.\n\n    # exceptions:\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%%s'\" %% style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None}\n\n\ndef get_versions():\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for i in cfg.versionfile_source.split('/'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find root of source tree\"}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to compute version\"}\n'''\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs):\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords = {}\n    try:\n        f = open(versionfile_abs, \"r\")\n        for line in f.readlines():\n            if line.strip().startswith(\"git_refnames =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"refnames\"] = mo.group(1)\n            if line.strip().startswith(\"git_full =\"):\n                mo = re.search(r'=\\s*\"(.*)\"', line)\n                if mo:\n                    keywords[\"full\"] = mo.group(1)\n        f.close()\n    except EnvironmentError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(keywords, tag_prefix, verbose):\n    if not keywords:\n        raise NotThisMethod(\"no keywords at all, weird\")\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = set([r.strip() for r in refnames.strip(\"()\").split(\",\")])\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = set([r[len(TAG):] for r in refs if r.startswith(TAG)])\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = set([r for r in refs if re.search(r'\\d', r)])\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs-tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None\n                    }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\"}\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):\n    # this runs 'git' from the root of the source tree. This only gets called\n    # if the git-archive 'subst' keywords were *not* expanded, and\n    # _version.py hasn't already been rewritten with a short version string,\n    # meaning we're inside a checked out source tree.\n\n    if not os.path.exists(os.path.join(root, \".git\")):\n        if verbose:\n            print(\"no .git in %s\" % root)\n        raise NotThisMethod(\"no .git directory\")\n\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    # if there is a tag, this yields TAG-NUM-gHEX[-dirty]\n    # if there are no tags, this yields HEX[-dirty] (no NUM)\n    describe_out = run_command(GITS, [\"describe\", \"--tags\", \"--dirty\",\n                                      \"--always\", \"--long\"],\n                               cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out = run_command(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n        if not mo:\n            # unparseable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%s'\"\n                               % describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = (\"tag '%s' doesn't start with prefix '%s'\"\n                               % (full_tag, tag_prefix))\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        count_out = run_command(GITS, [\"rev-list\", \"HEAD\", \"--count\"],\n                                cwd=root)\n        pieces[\"distance\"] = int(count_out)  # total number of commits\n\n    return pieces\n\n\ndef do_vcs_install(manifest_in, versionfile_source, ipy):\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    files = [manifest_in, versionfile_source]\n    if ipy:\n        files.append(ipy)\n    try:\n        me = __file__\n        if me.endswith(\".pyc\") or me.endswith(\".pyo\"):\n            me = os.path.splitext(me)[0] + \".py\"\n        versioneer_file = os.path.relpath(me)\n    except NameError:\n        versioneer_file = \"versioneer.py\"\n    files.append(versioneer_file)\n    present = False\n    try:\n        f = open(\".gitattributes\", \"r\")\n        for line in f.readlines():\n            if line.strip().startswith(versionfile_source):\n                if \"export-subst\" in line.strip().split()[1:]:\n                    present = True\n        f.close()\n    except EnvironmentError:\n        pass\n    if not present:\n        f = open(\".gitattributes\", \"a+\")\n        f.write(\"%s export-subst\\n\" % versionfile_source)\n        f.close()\n        files.append(\".gitattributes\")\n    run_command(GITS, [\"add\", \"--\"] + files)\n\n\ndef versions_from_parentdir(parentdir_prefix, root, verbose):\n    # Source tarballs conventionally unpack into a directory that includes\n    # both the project name and a version string.\n    dirname = os.path.basename(root)\n    if not dirname.startswith(parentdir_prefix):\n        if verbose:\n            print(\"guessing rootdir is '%s', but '%s' doesn't start with \"\n                  \"prefix '%s'\" % (root, dirname, parentdir_prefix))\n        raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n    return {\"version\": dirname[len(parentdir_prefix):],\n            \"full-revisionid\": None,\n            \"dirty\": False, \"error\": None}\n\nSHORT_VERSION_PY = \"\"\"\n# This file was generated by 'versioneer.py' (0.15) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\nimport sys\n\nversion_json = '''\n%s\n'''  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n\"\"\"\n\n\ndef versions_from_file(filename):\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except EnvironmentError:\n        raise NotThisMethod(\"unable to read _version.py\")\n    mo = re.search(r\"version_json = '''\\n(.*)'''  # END VERSION_JSON\",\n                   contents, re.M | re.S)\n    if not mo:\n        raise NotThisMethod(\"no version_json in _version.py\")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename, versions):\n    os.unlink(filename)\n    contents = json.dumps(versions, sort_keys=True,\n                          indent=1, separators=(\",\", \": \"))\n    with open(filename, \"w\") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(\"set %s to '%s'\" % (filename, versions[\"version\"]))\n\n\ndef plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces):\n    # now build up version string, with post-release \"local version\n    # identifier\". Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    # get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    # exceptions:\n    # 1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_pre(pieces):\n    # TAG[.post.devDISTANCE] . No -dirty\n\n    # exceptions:\n    # 1: no tags. 0.post.devDISTANCE\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \".post.dev%d\" % pieces[\"distance\"]\n    else:\n        # exception #1\n        rendered = \"0.post.dev%d\" % pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces):\n    # TAG[.postDISTANCE[.dev0]+gHEX] . The \".dev0\" means dirty. Note that\n    # .dev0 sorts backwards (a dirty tree will appear \"older\" than the\n    # corresponding clean one), but you shouldn't be releasing software with\n    # -dirty anyways.\n\n    # exceptions:\n    # 1: no tags. 0.postDISTANCE[.dev0]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_old(pieces):\n    # TAG[.postDISTANCE[.dev0]] . The \".dev0\" means dirty.\n\n    # exceptions:\n    # 1: no tags. 0.postDISTANCE[.dev0]\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces):\n    # TAG[-DISTANCE-gHEX][-dirty], like 'git describe --tags --dirty\n    # --always'\n\n    # exceptions:\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces):\n    # TAG-DISTANCE-gHEX[-dirty], like 'git describe --tags --dirty\n    # --always -long'. The distance/hash is unconditional.\n\n    # exceptions:\n    # 1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None}\n\n\nclass VersioneerBadRootError(Exception):\n    pass\n\n\ndef get_versions(verbose=False):\n    # returns dict with two keys: 'version' and 'full'\n\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, \"please set [versioneer]VCS= in setup.cfg\"\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, \"unrecognized VCS '%s'\" % cfg.VCS\n    verbose = verbose or cfg.verbose\n    assert cfg.versionfile_source is not None, \\\n        \"please set versioneer.versionfile_source\"\n    assert cfg.tag_prefix is not None, \"please set versioneer.tag_prefix\"\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. 'git\n    # describe'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by 'setup.py sdist',\n    # and for users of a tarball/zipball created by 'git archive' or github's\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(\"get_keywords\")\n    from_keywords_f = handlers.get(\"keywords\")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(\"got version from expanded keyword %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(\"got version from file %s %s\" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(\"pieces_from_vcs\")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(\"got version from VCS %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(\"got version from parentdir %s\" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(\"unable to compute version\")\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None, \"error\": \"unable to compute version\"}\n\n\ndef get_version():\n    return get_versions()[\"version\"]\n\n\ndef get_cmdclass():\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in\n        # sys.modules by the time B's setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it's pre-build state, so the\n        # parent is protected against the child's \"import versioneer\". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent's versioneer too.\n        # Also see https://github.com/warner/python-versioneer/issues/52\n\n    cmds = {}\n\n    # we add \"version\" to both distutils and setuptools\n    from distutils.core import Command\n\n    class cmd_version(Command):\n        description = \"report generated version string\"\n        user_options = []\n        boolean_options = []\n\n        def initialize_options(self):\n            pass\n\n        def finalize_options(self):\n            pass\n\n        def run(self):\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])\n    cmds[\"version\"] = cmd_version\n\n    # we override \"build_py\" in both distutils and setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n\n    from distutils.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib,\n                                                  cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n    cmds[\"build_py\"] = cmd_build_py\n\n    if \"cx_Freeze\" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe\n\n        class cmd_build_exe(_build_exe):\n            def run(self):\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(LONG %\n                            {\"DOLLAR\": \"$\",\n                             \"STYLE\": cfg.style,\n                             \"TAG_PREFIX\": cfg.tag_prefix,\n                             \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                             \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                             })\n        cmds[\"build_exe\"] = cmd_build_exe\n        del cmds[\"build_py\"]\n\n    # we override different \"sdist\" commands for both environments\n    if \"setuptools\" in sys.modules:\n        from setuptools.command.sdist import sdist as _sdist\n    else:\n        from distutils.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self):\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir, files):\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile,\n                                  self._versioneer_generated_versions)\n    cmds[\"sdist\"] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = \"\"\"\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix = \"\"\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or 'python versioneer.py setup'.\n\"\"\"\n\nSAMPLE_CONFIG = \"\"\"\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n\"\"\"\n\nINIT_PY_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\n\n\ndef do_setup():\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (EnvironmentError, configparser.NoSectionError,\n            configparser.NoOptionError) as e:\n        if isinstance(e, (EnvironmentError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\",\n                  file=sys.stderr)\n            with open(os.path.join(root, \"setup.cfg\"), \"a\") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print(\" creating %s\" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, \"w\") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(LONG % {\"DOLLAR\": \"$\",\n                        \"STYLE\": cfg.style,\n                        \"TAG_PREFIX\": cfg.tag_prefix,\n                        \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                        \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        })\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source),\n                       \"__init__.py\")\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, \"r\") as f:\n                old = f.read()\n        except EnvironmentError:\n            old = \"\"\n        if INIT_PY_SNIPPET not in old:\n            print(\" appending to %s\" % ipy)\n            with open(ipy, \"a\") as f:\n                f.write(INIT_PY_SNIPPET)\n        else:\n            print(\" %s unmodified\" % ipy)\n    else:\n        print(\" %s doesn't exist, ok\" % ipy)\n        ipy = None\n\n    # Make sure both the top-level \"versioneer.py\" and versionfile_source\n    # (PKG/_version.py, used by runtime code) are in MANIFEST.in, so\n    # they'll be copied into source distributions. Pip won't be able to\n    # install the package without this.\n    manifest_in = os.path.join(root, \"MANIFEST.in\")\n    simple_includes = set()\n    try:\n        with open(manifest_in, \"r\") as f:\n            for line in f:\n                if line.startswith(\"include \"):\n                    for include in line.split()[1:]:\n                        simple_includes.add(include)\n    except EnvironmentError:\n        pass\n    # That doesn't cover everything MANIFEST.in can do\n    # (http://docs.python.org/2/distutils/sourcedist.html#commands), so\n    # it might give some false negatives. Appending redundant 'include'\n    # lines is safe, though.\n    if \"versioneer.py\" not in simple_includes:\n        print(\" appending 'versioneer.py' to MANIFEST.in\")\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include versioneer.py\\n\")\n    else:\n        print(\" 'versioneer.py' already in MANIFEST.in\")\n    if cfg.versionfile_source not in simple_includes:\n        print(\" appending versionfile_source ('%s') to MANIFEST.in\" %\n              cfg.versionfile_source)\n        with open(manifest_in, \"a\") as f:\n            f.write(\"include %s\\n\" % cfg.versionfile_source)\n    else:\n        print(\" versionfile_source already in MANIFEST.in\")\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-time keyword\n    # substitution.\n    do_vcs_install(manifest_in, cfg.versionfile_source, ipy)\n    return 0\n\n\ndef scan_setup_py():\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass()\" in line:\n                found.add(\"cmdclass\")\n            if \"versioneer.get_version()\" in line:\n                found.add(\"get_version\")\n            if \"versioneer.VCS\" in line:\n                setters = True\n            if \"versioneer.versionfile_source\" in line:\n                setters = True\n    if len(found) != 3:\n        print(\"\")\n        print(\"Your setup.py appears to be missing some important items\")\n        print(\"(but I might be wrong). Please make sure it has something\")\n        print(\"roughly like the following:\")\n        print(\"\")\n        print(\" import versioneer\")\n        print(\" setup( version=versioneer.get_version(),\")\n        print(\"        cmdclass=versioneer.get_cmdclass(),  ...)\")\n        print(\"\")\n        errors += 1\n    if setters:\n        print(\"You should remove lines like 'versioneer.VCS = ' and\")\n        print(\"'versioneer.versionfile_source = ' . This configuration\")\n        print(\"now lives in setup.cfg, and should be removed from setup.py\")\n        print(\"\")\n        errors += 1\n    return errors\n\nif __name__ == \"__main__\":\n    cmd = sys.argv[1]\n    if cmd == \"setup\":\n        errors = do_setup()\n        errors += scan_setup_py()\n        if errors:\n            sys.exit(1)\n"
        },
        {
          "name": "zipline",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}