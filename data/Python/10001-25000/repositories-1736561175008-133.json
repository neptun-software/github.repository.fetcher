{
  "metadata": {
    "timestamp": 1736561175008,
    "page": 133,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pytorch/vision",
      "stars": 16452,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 2.5732421875,
          "content": "---\nAccessModifierOffset: -1\nAlignAfterOpenBracket: AlwaysBreak\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlinesLeft: true\nAlignOperands:   false\nAlignTrailingComments: false\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Empty\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: false\nBinPackParameters: false\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: false\nColumnLimit:     80\nCommentPragmas:  '^ IWYU pragma:'\n#CompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nForEachMacros:   [ FOR_EACH_RANGE, FOR_EACH, ]\nIncludeCategories:\n  - Regex:           '^<.*\\.h(pp)?>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIndentCaseLabels: true\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 2000000\nPointerAlignment: Left\nReflowComments:  true\nSortIncludes:    true\nSpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles:  false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Cpp11\nTabWidth:        8\nUseTab:          Never\n---\nLanguage: ObjC\nColumnLimit: 120\nAlignAfterOpenBracket: Align\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: false\n...\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.6005859375,
          "content": "# This file keeps git blame clean.\n# See https://docs.github.com/en/repositories/working-with-files/using-files/viewing-a-file#ignore-commits-in-the-blame-view\n\n# Add ufmt (usort + black) as code formatter (#4384)\n5f0edb97b46e5bff71dc19dedef05c5396eeaea2\n# update python syntax >=3.6 (#4585)\nd367a01a18a3ae6bee13d8be3b63fd6a581ea46f\n# Upgrade usort to 1.0.2 and black to 22.3.0 (#5106) \n6ca9c76adb6daf2695d603ad623a9cf1c4f4806f\n# Fix unnecessary exploded black formatting (#7709)\na335d916db0694770e8152f41e19195de3134523\n# Renaming: `BoundingBox` -> `BoundingBoxes` (#7778)\n332bff937c6711666191880fab57fa2f23ae772e\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.119140625,
          "content": "*.pkl binary\n# Jupyter notebook\n\n# For text count\n# *.ipynb text\n\n# To ignore it use below\n*.ipynb linguist-documentation\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5751953125,
          "content": "build/\ndist/\ntorchvision.egg-info/\ntorchvision/version.py\n*/**/__pycache__\n*/__pycache__\n*/*.pyc\n*/**/*.pyc\n*/**/**/*.pyc\n*/**/*~\n*~\n\ndocs/build\n# sphinx-gallery\ndocs/source/auto_examples/\ndocs/source/gen_modules/\ndocs/source/generated/\ndocs/source/models/generated/\ndocs/source/sg_execution_times.rst\n# pytorch-sphinx-theme gets installed here\ndocs/src\n\n.coverage\nhtmlcov\n.*.swp\n*.so*\n*.dylib*\n*/*.so*\n*/*.dylib*\n*.swp\n*.swo\ngen.yml\n.mypy_cache\n.vscode/\n.idea/\n*.orig\n*-checkpoint.ipynb\n*.venv\n\n## Xcode User settings\nxcuserdata/\n\n# direnv\n.direnv\n.envrc\n\nscripts/release_notes/data.json\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.7158203125,
          "content": "repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.0.1\n    hooks:\n      - id: check-docstring-first\n      - id: check-toml\n      - id: check-yaml\n        exclude: packaging/.*\n        args:\n          - --allow-multiple-documents\n      - id: mixed-line-ending\n        args: [--fix=lf]\n      - id: end-of-file-fixer\n\n  - repo: https://github.com/omnilib/ufmt\n    rev: v1.3.3\n    hooks:\n      - id: ufmt\n        additional_dependencies:\n          - black == 22.3.0\n          - usort == 1.0.2\n\n  - repo: https://github.com/PyCQA/flake8\n    rev: 5.0.4\n    hooks:\n      - id: flake8\n        args: [--config=setup.cfg]\n\n  - repo: https://github.com/PyCQA/pydocstyle\n    rev: 6.1.1\n    hooks:\n      - id: pydocstyle\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.423828125,
          "content": "cff-version: 1.2.0\ntitle: \"TorchVision: PyTorch's Computer Vision library\"\nmessage: >-\n  If you find TorchVision useful in your work, please\n  consider citing the following BibTeX entry.\ntype: software\nauthors:\n  - given-names: TorchVision maintainers and contributors\nurl: \"https://github.com/pytorch/vision\"\nlicense: \"BSD-3-Clause\"\ndate-released: \"2016-11-06\"\njournal: \"GitHub repository\"\npublisher: \"GitHub\"\nkey: \"torchvision2016\"\n"
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 5.4169921875,
          "content": "cmake_minimum_required(VERSION 3.18)\nproject(torchvision)\nset(CMAKE_CXX_STANDARD 17)\nfile(STRINGS version.txt TORCHVISION_VERSION)\n\noption(WITH_CUDA \"Enable CUDA support\" OFF)\noption(WITH_MPS \"Enable MPS support\" OFF)\noption(WITH_PNG \"Enable features requiring LibPNG.\" ON)\noption(WITH_JPEG \"Enable features requiring LibJPEG.\" ON)\n# Libwebp is disabled by default, which means enabling it from cmake is largely\n# untested. Since building from cmake is very low pri anyway, this is OK. If\n# you're a user and you need this, please open an issue (and a PR!).\noption(WITH_WEBP \"Enable features requiring LibWEBP.\" OFF)\n# Same here\noption(WITH_AVIF \"Enable features requiring LibAVIF.\" OFF)\n\nif(WITH_CUDA)\n  enable_language(CUDA)\n  add_definitions(-D__CUDA_NO_HALF_OPERATORS__)\n  add_definitions(-DWITH_CUDA)\n  set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} --expt-relaxed-constexpr\")\nendif()\n\nif(WITH_MPS)\n  enable_language(OBJC OBJCXX)\n  add_definitions(-DWITH_MPS)\nendif()\n\nfind_package(Torch REQUIRED)\n\nif (WITH_PNG)\n    add_definitions(-DPNG_FOUND)\n    find_package(PNG REQUIRED)\nendif()\n\nif (WITH_JPEG)\n    add_definitions(-DJPEG_FOUND)\n    find_package(JPEG REQUIRED)\nendif()\n\nif (WITH_WEBP)\n    add_definitions(-DWEBP_FOUND)\n    find_package(WEBP REQUIRED)\nendif()\n\nif (WITH_AVIF)\n    add_definitions(-DAVIF_FOUND)\n    find_package(AVIF REQUIRED)\nendif()\n\nfunction(CUDA_CONVERT_FLAGS EXISTING_TARGET)\n    get_property(old_flags TARGET ${EXISTING_TARGET} PROPERTY INTERFACE_COMPILE_OPTIONS)\n    if(NOT \"${old_flags}\" STREQUAL \"\")\n        string(REPLACE \";\" \",\" CUDA_flags \"${old_flags}\")\n        set_property(TARGET ${EXISTING_TARGET} PROPERTY INTERFACE_COMPILE_OPTIONS\n            \"$<$<BUILD_INTERFACE:$<COMPILE_LANGUAGE:CXX>>:${old_flags}>$<$<BUILD_INTERFACE:$<COMPILE_LANGUAGE:CUDA>>:-Xcompiler=${CUDA_flags}>\"\n            )\n    endif()\nendfunction()\n\nif(MSVC)\n  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /wd4819\")\n  if(WITH_CUDA)\n    set(CMAKE_CUDA_FLAGS \"${CMAKE_CUDA_FLAGS} -Xcompiler=/wd4819\")\n    foreach(diag cc_clobber_ignored integer_sign_change useless_using_declaration\n      set_but_not_used field_without_dll_interface\n      base_class_has_different_dll_interface\n      dll_interface_conflict_none_assumed\n      dll_interface_conflict_dllexport_assumed\n      implicit_return_from_non_void_function\n      unsigned_compare_with_zero\n      declared_but_not_referenced\n      bad_friend_decl)\n      string(APPEND CMAKE_CUDA_FLAGS \" -Xcudafe --diag_suppress=${diag}\")\n    endforeach()\n    CUDA_CONVERT_FLAGS(torch_cpu)\n    if(TARGET torch_cuda)\n      CUDA_CONVERT_FLAGS(torch_cuda)\n    endif()\n    if(TARGET torch_cuda_cu)\n      CUDA_CONVERT_FLAGS(torch_cuda_cu)\n    endif()\n    if(TARGET torch_cuda_cpp)\n      CUDA_CONVERT_FLAGS(torch_cuda_cpp)\n    endif()\n  endif()\nendif()\n\ninclude(GNUInstallDirs)\ninclude(CMakePackageConfigHelpers)\n\nset(TVCPP torchvision/csrc)\nlist(APPEND ALLOW_LISTED ${TVCPP} ${TVCPP}/io/image ${TVCPP}/io/image/cpu ${TVCPP}/io/image/cpu/giflib ${TVCPP}/models ${TVCPP}/ops\n  ${TVCPP}/ops/autograd ${TVCPP}/ops/cpu ${TVCPP}/io/image/cuda)\nif(WITH_CUDA)\n    list(APPEND ALLOW_LISTED ${TVCPP}/ops/cuda ${TVCPP}/ops/autocast)\nendif()\nif(WITH_MPS)\n    list(APPEND ALLOW_LISTED ${TVCPP}/ops/mps)\nendif()\n\nFOREACH(DIR ${ALLOW_LISTED})\n    file(GLOB ALL_SOURCES ${ALL_SOURCES} ${DIR}/*.*)\nENDFOREACH()\n\nadd_library(${PROJECT_NAME} SHARED ${ALL_SOURCES})\ntarget_link_libraries(${PROJECT_NAME} PRIVATE ${TORCH_LIBRARIES})\n\nif(WITH_MPS)\n  find_library(metal NAMES Metal)\n  find_library(foundation NAMES Foundation)\n  target_link_libraries(${PROJECT_NAME} PRIVATE ${metal} ${foundation})\nendif()\n\nif (WITH_PNG)\n    target_link_libraries(${PROJECT_NAME} PRIVATE ${PNG_LIBRARY})\nendif()\n\nif (WITH_JPEG)\n    target_link_libraries(${PROJECT_NAME} PRIVATE ${JPEG_LIBRARIES})\nendif()\n\nif (WITH_WEBP)\n    target_link_libraries(${PROJECT_NAME} PRIVATE ${WEBP_LIBRARIES})\nendif()\n\nif (WITH_AVIF)\n    target_link_libraries(${PROJECT_NAME} PRIVATE ${AVIF_LIBRARIES})\nendif()\n\nset_target_properties(${PROJECT_NAME} PROPERTIES\n  EXPORT_NAME TorchVision\n  INSTALL_RPATH ${TORCH_INSTALL_PREFIX}/lib)\n\ninclude_directories(torchvision/csrc)\n\nif (WITH_PNG)\n    include_directories(${PNG_INCLUDE_DIRS})\nendif()\n\nif (WITH_JPEG)\n    include_directories(${JPEG_INCLUDE_DIRS})\nendif()\n\nif (WITH_WEBP)\n    include_directories(${WEBP_INCLUDE_DIRS})\nendif()\n\nif (WITH_AVIF)\n    include_directories(${AVIF_INCLUDE_DIRS})\nendif()\n\nset(TORCHVISION_CMAKECONFIG_INSTALL_DIR \"share/cmake/TorchVision\" CACHE STRING \"install path for TorchVisionConfig.cmake\")\n\nconfigure_package_config_file(cmake/TorchVisionConfig.cmake.in\n  \"${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfig.cmake\"\n  INSTALL_DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})\n\nwrite_basic_package_version_file(${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfigVersion.cmake\n  VERSION ${TORCHVISION_VERSION}\n  COMPATIBILITY AnyNewerVersion)\n\ninstall(FILES ${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfig.cmake\n  ${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfigVersion.cmake\n  DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})\n\ninstall(TARGETS ${PROJECT_NAME}\n  EXPORT TorchVisionTargets\n  LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n  )\n\ninstall(EXPORT TorchVisionTargets\n  NAMESPACE TorchVision::\n  DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})\n\nFOREACH(INPUT_DIR ${ALLOW_LISTED})\n    string(REPLACE \"${TVCPP}\" \"${CMAKE_INSTALL_INCLUDEDIR}/${PROJECT_NAME}\" OUTPUT_DIR ${INPUT_DIR})\n    file(GLOB INPUT_FILES ${INPUT_DIR}/*.*)\n    install(FILES ${INPUT_FILES} DESTINATION ${OUTPUT_DIR})\nENDFOREACH()\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2646484375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\naddress, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\nprofessional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <conduct@pytorch.org>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 8.625,
          "content": "# Contributing to Torchvision\n\nWe want to make contributing to this project as easy and transparent as possible.\n\n## TL;DR\n\nWe appreciate all contributions. If you are interested in contributing to Torchvision, there are many ways to help out.\nYour contributions may fall into the following categories:\n\n- It helps the project if you could\n    - Report issues you're facing\n    - Give a :+1: on issues that others reported and that are relevant to you\n\n- Answering queries on the issue tracker, investigating bugs are very valuable contributions to the project.\n\n- You would like to improve the documentation. This is no less important than improving the library itself!\nIf you find a typo in the documentation, do not hesitate to submit a GitHub pull request.\n\n- If you would like to fix a bug\n    - please pick one from the [list of open issues labelled as \"help wanted\"](https://github.com/pytorch/vision/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)\n    - comment on the issue that you want to work on this issue\n    - send a PR with your fix, see below.\n\n- If you plan to contribute new features, utility functions or extensions, please first open an issue and discuss the feature with us.\n\n## Issues\n\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\n## Development installation\n\n\n### Dependencies\n\nStart by installing the **nightly** build of PyTorch following the [official\ninstructions](https://pytorch.org/get-started/locally/). Note that the official\ninstructions may ask you to install torchvision itself. If you are doing development\non torchvision, you should not install prebuilt torchvision packages.\n\n**Optionally**, install `libpng` and `libjpeg-turbo` if you want to enable\nsupport for\nnative encoding / decoding of PNG and JPEG formats in\n[torchvision.io](https://pytorch.org/vision/stable/io.html#image):\n\n```bash\nconda install libpng libjpeg-turbo -c pytorch\n```\n\nNote: you can use the `TORCHVISION_INCLUDE` and `TORCHVISION_LIBRARY`\nenvironment variables to tell the build system where to find those libraries if\nthey are in specific locations. Take a look at\n[setup.py](https://github.com/pytorch/vision/blob/main/setup.py) for more\ndetails.\n\n### Clone and install torchvision\n\n```bash\ngit clone https://github.com/pytorch/vision.git\ncd vision\npython setup.py develop  # use install instead of develop if you don't care about development.\n# or, for OSX\n# MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++ python setup.py develop\n# for C++ debugging, use DEBUG=1\n# DEBUG=1 python setup.py develop\n```\n\nBy default, GPU support is built if CUDA is found and `torch.cuda.is_available()` is true. It's possible to force\nbuilding GPU support by setting `FORCE_CUDA=1` environment variable, which is useful when building a docker image.\n\nWe don't officially support building from source using `pip`, but _if_ you do, you'll need to use the\n`--no-build-isolation` flag.\n\n#### Other development dependencies (some of these are needed to run tests):\n\n```\npip install expecttest flake8 typing mypy pytest pytest-mock scipy requests\n```\n\n## Development Process\n\nIf you plan to modify the code or documentation, please follow the steps below:\n\n1. Fork the repository and create your branch from `main`.\n2. If you have modified the code (new feature or bug-fix), please add unit tests.\n3. If you have changed APIs, update the documentation. Make sure the documentation builds.\n4. Ensure the test suite passes.\n5. Make sure your code passes the formatting checks (see below).\n\nFor more details about pull requests,\nplease read [GitHub's guides](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request).\n\nIf you would like to contribute a new model, please see [here](#New-architecture-or-improved-model-weights).\n\nIf you would like to contribute a new dataset, please see [here](#New-dataset).\n\n### Code formatting and typing\n\n#### Formatting\n\nThe torchvision code is formatted by [black](https://black.readthedocs.io/en/stable/),\nand checked against pep8 compliance with [flake8](https://flake8.pycqa.org/en/latest/).\nInstead of relying directly on `black` however, we rely on\n[ufmt](https://github.com/omnilib/ufmt), for compatibility reasons with Facebook\ninternal infrastructure.\n\nTo format your code, install `ufmt` with `pip install ufmt==1.3.3 black==22.3.0 usort==1.0.2` and use e.g.:\n\n```bash\nufmt format torchvision\n```\n\nFor the vast majority of cases, this is all you should need to run. For the\nformatting to be a bit faster, you can also choose to only apply `ufmt` to the\nfiles that were edited in your PR with e.g.:\n\n```bash\nufmt format `git diff main --name-only`\n```\n\nSimilarly, you can check for `flake8` errors with `flake8 torchvision`, although\nthey should be fairly rare considering that most of the errors are automatically\ntaken care of by `ufmt` already.\n\n##### Pre-commit hooks\n\nFor convenience and **purely optionally**, you can rely on [pre-commit\nhooks](https://pre-commit.com/) which will run both `ufmt` and `flake8` prior to\nevery commit.\n\nFirst install the `pre-commit` package with `pip install pre-commit`, and then\nrun `pre-commit install` at the root of the repo for the hooks to be set up -\nthat's it.\n\nFeel free to read the [pre-commit docs](https://pre-commit.com/#usage) to learn\nmore and improve your workflow. You'll see for example that `pre-commit run\n--all-files` will run both `ufmt` and `flake8` without the need for you to\ncommit anything, and that the `--no-verify` flag can be added to `git commit` to\ntemporarily deactivate the hooks.\n\n#### Type annotations\n\nThe codebase has type annotations, please make sure to add type hints if required. We use `mypy` tool for type checking:\n```bash\nmypy --config-file mypy.ini\n```\n\n### Unit tests\n\nBefore running tests make sure to install [test dependencies](#other-development-dependencies-some-of-these-are-needed-to-run-tests).\n\nIf you have modified the code by adding a new feature or a bug-fix, please add unit tests for that. To run a specific\ntest:\n```bash\npytest test/<test-module.py> -vvv -k <test_myfunc>\n# e.g. pytest test/test_transforms.py -vvv -k test_center_crop\n```\n\nIf you would like to run all tests:\n```bash\npytest test -vvv\n```\n\nTests that require internet access should be in\n`test/test_internet.py`.\n\n### Documentation\n\nTorchvision uses [Google style](http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)\nfor formatting docstrings. Length of line inside docstrings block must be limited to 120 characters.\n\nPlease, follow the instructions to build and deploy the documentation locally.\n\n#### Install requirements\n\n```bash\ncd docs\npip install -r requirements.txt\n```\n\n#### Build\n\n```bash\ncd docs\nmake html-noplot\n```\n\nThen open `docs/build/html/index.html` in your favorite browser.\n\nThe docs are also automatically built when you submit a PR. The job that\nbuilds the docs is named `build_docs`. You can access the rendered docs by\nclicking on that job and then going to the \"Artifacts\" tab.\n\nYou can clean the built docs and re-start the build from scratch by doing ``make\nclean``.\n\n#### Building the example gallery - or not\n\nIn most cases, running `make html-noplot` is enough to build the docs for your\nspecific use-case. The `noplot` part tells sphinx **not** to build the examples\nin the [gallery](https://pytorch.org/vision/stable/auto_examples/index.html),\nwhich saves a lot of building time.\n\nIf you need to build all the examples in the gallery, then you can use `make\nhtml`.\n\nYou can also choose to only build a subset of the examples by using the\n``EXAMPLES_PATTERN`` env variable, which accepts a regular expression. For\nexample ``EXAMPLES_PATTERN=\"transforms\" make html`` will only build the examples\nwith \"transforms\" in their name.\n\n### New architecture or improved model weights\n\nPlease refer to the guidelines in [Contributing to Torchvision - Models](https://github.com/pytorch/vision/blob/main/CONTRIBUTING_MODELS.md).\n\n### New dataset\n\nPlease, do not send any PR with a new dataset without discussing\nit in an issue as, most likely, it will not be accepted.\n\n### Pull Request\n\nIf all previous checks (flake8, mypy, unit tests) are passing, please send a PR. Submitted PR will pass other tests on\ndifferent operating systems, python versions and hardware.\n\nFor more details about pull requests workflow,\nplease read [GitHub's guides](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request).\n\n## License\n\nBy contributing to Torchvision, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n\nContributors are also required to [sign our Contributor License Agreement](https://code.facebook.com/cla).\n"
        },
        {
          "name": "CONTRIBUTING_MODELS.md",
          "type": "blob",
          "size": 5.6025390625,
          "content": "# Contributing to Torchvision - Models\n\n- [New Model Architectures - Overview](#new-model-architectures---overview)\n\n- [New Weights for Existing Model Architectures](#new-weights-for-existing-model-architectures)\n\n## New Model Architectures - Overview\n\nFor someone who would be interested in adding a model architecture, it is also expected to train the model, so here are a few important considerations:\n\n- Training big models requires lots of resources and the cost quickly adds up\n\n- Reproducing models is fun but also risky as you might not always get the results reported on the paper. It might require a huge amount of effort to close the gap\n\n- The contribution might not get merged if we significantly lack in terms of accuracy, speed etc\n\n- Including new models in TorchVision might not be the best approach, so other options such as releasing the model through to [Pytorch Hub](https://pytorch.org/hub/) should be considered\n\nSo, before starting any work and submitting a PR there are a few critical things that need to be taken into account in order to make sure the planned contribution is within the context of TorchVision, and the requirements and expectations are discussed beforehand. If this step is skipped and a PR is submitted without prior discussion it will almost certainly be rejected.\n\n### 1. Preparation work\n\n- Start by looking into this [issue](https://github.com/pytorch/vision/issues/2707) in order to have an idea of the models that are being considered, express your willingness to add a new model and discuss with the community whether this model should be included in TorchVision. It is very important at this stage to make sure that there is an agreement on the value of having this model in TorchVision and there is no one else already working on it.\n\n- If the decision is to include the new model, then please create a new ticket which will be used for all design and implementation discussions prior to the PR. One of the TorchVision maintainers will reach out at this stage and this will be your POC from this point onwards in order to provide support, guidance and regular feedback.\n\n### 2.  Implement the model\n\nPlease take a look at existing models in TorchVision to get familiar with the idioms. Also, please look at recent contributions for new models. If in doubt about any design decisions you can ask for feedback on the issue created in step 1.  Example of things to take into account:\n\n- The implementation should be as close as possible to the canonical implementation/paper\n- The PR must include the code implementation, documentation and tests\n- It should also extend the existing reference scripts used to train the model\n- The weights need to reproduce closely the results of the paper in terms of accuracy, even though the final weights to be deployed will be those trained by the TorchVision maintainers\n- The PR description should include commands/configuration used to train the model, so that the TorchVision maintainers can easily run them to verify the implementation and generate the final model to be released\n- Make sure we re-use existing components as much as possible (inheritance)\n- New primitives (transforms, losses, etc.) can be added if necessary, but the final location will be determined after discussion with the dedicated maintainer\n- Please take a look at the detailed [implementation and documentation guidelines](https://github.com/pytorch/vision/issues/5319) for a fine grain list of things not to be missed\n\n### 3. Train the model with reference scripts\n\nTo validate the new model against the common benchmark, as well as to generate pre-trained weights, you must use TorchVision’s reference scripts to train the model.\n\nMake sure all logs and a final (or best) checkpoint are saved, because it is expected that a submission shows that a model has been successfully trained  and the results are in line with the original paper/repository. This will allow the reviewers to quickly check the validity of the submission, but please note that the final model to be released will be re-trained by the maintainers in order to verify reproducibility,  ensure that the changes occurred during the PR review did not introduce any bugs, and to avoid moving around a large amount of data (including all checkpoints and logs).\n\n### 4. Submit a PR\n\nSubmit a PR and tag the assigned maintainer. This PR should:\n\n- Link the original ticket\n- Provide a link for the original paper and the original repository if available\n- Highlight the important test metrics and how they compare to the original paper\n- Highlight any design choices that deviate from the original paper/implementation and rationale for these choices\n\n## New Weights for Existing Model Architectures\n\nThe process of improving existing models, for instance improving accuracy by retraining the model with a different set of hyperparameters or augmentations, is the following:\n\n1. Open a ticket and discuss with the community and maintainers whether this improvement should be added to TorchVision. Note that to add new weights the improvement should be significant.\n\n2. Train the model using TorchVision reference scripts. You can add new primitives (transforms, losses, etc) when necessary, but the final location will be determined after discussion with the dedicated maintainer.\n\n3. Open a PR with the new weights, together with the training logs and the checkpoint chosen so the reviewers can verify the submission.  Details on how the model was trained, i.e., the training command using the reference scripts, should be included in the PR.\n\n4. The PR reviewers should replicate the results on their side to verify the submission and if all goes well the new weights should be ready to be released!\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4814453125,
          "content": "BSD 3-Clause License\n\nCopyright (c) Soumith Chintala 2016, \nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.09375,
          "content": "include README.md\ninclude LICENSE\n\nrecursive-exclude * __pycache__\nrecursive-exclude * *.py[co]\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.4482421875,
          "content": "# torchvision\n\n[![total torchvision downloads](https://pepy.tech/badge/torchvision)](https://pepy.tech/project/torchvision)\n[![documentation](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Ftorchvision%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://pytorch.org/vision/stable/index.html)\n\nThe torchvision package consists of popular datasets, model architectures, and common image transformations for computer\nvision.\n\n## Installation\n\nPlease refer to the [official\ninstructions](https://pytorch.org/get-started/locally/) to install the stable\nversions of `torch` and `torchvision` on your system.\n\nTo build source, refer to our [contributing\npage](https://github.com/pytorch/vision/blob/main/CONTRIBUTING.md#development-installation).\n\nThe following is the corresponding `torchvision` versions and supported Python\nversions.\n\n| `torch`            | `torchvision`      | Python              |\n| ------------------ | ------------------ | ------------------- |\n| `main` / `nightly` | `main` / `nightly` | `>=3.9`, `<=3.12`   |\n| `2.5`              | `0.20`             | `>=3.9`, `<=3.12`   |\n| `2.4`              | `0.19`             | `>=3.8`, `<=3.12`   |\n| `2.3`              | `0.18`             | `>=3.8`, `<=3.12`   |\n| `2.2`              | `0.17`             | `>=3.8`, `<=3.11`   |\n| `2.1`              | `0.16`             | `>=3.8`, `<=3.11`   |\n| `2.0`              | `0.15`             | `>=3.8`, `<=3.11`   |\n\n<details>\n    <summary>older versions</summary>\n\n| `torch` | `torchvision`     | Python                    |\n|---------|-------------------|---------------------------|\n| `1.13`  | `0.14`            | `>=3.7.2`, `<=3.10`       |\n| `1.12`  | `0.13`            | `>=3.7`, `<=3.10`         |\n| `1.11`  | `0.12`            | `>=3.7`, `<=3.10`         |\n| `1.10`  | `0.11`            | `>=3.6`, `<=3.9`          |\n| `1.9`   | `0.10`            | `>=3.6`, `<=3.9`          |\n| `1.8`   | `0.9`             | `>=3.6`, `<=3.9`          |\n| `1.7`   | `0.8`             | `>=3.6`, `<=3.9`          |\n| `1.6`   | `0.7`             | `>=3.6`, `<=3.8`          |\n| `1.5`   | `0.6`             | `>=3.5`, `<=3.8`          |\n| `1.4`   | `0.5`             | `==2.7`, `>=3.5`, `<=3.8` |\n| `1.3`   | `0.4.2` / `0.4.3` | `==2.7`, `>=3.5`, `<=3.7` |\n| `1.2`   | `0.4.1`           | `==2.7`, `>=3.5`, `<=3.7` |\n| `1.1`   | `0.3`             | `==2.7`, `>=3.5`, `<=3.7` |\n| `<=1.0` | `0.2`             | `==2.7`, `>=3.5`, `<=3.7` |\n\n</details>\n\n## Image Backends\n\nTorchvision currently supports the following image backends:\n\n- torch tensors\n- PIL images:\n    - [Pillow](https://python-pillow.org/)\n    - [Pillow-SIMD](https://github.com/uploadcare/pillow-simd) - a **much faster** drop-in replacement for Pillow with SIMD.\n\nRead more in in our [docs](https://pytorch.org/vision/stable/transforms.html).\n\n## [UNSTABLE] Video Backend\n\nTorchvision currently supports the following video backends:\n\n- [pyav](https://github.com/PyAV-Org/PyAV) (default) - Pythonic binding for ffmpeg libraries.\n- video_reader - This needs ffmpeg to be installed and torchvision to be built from source. There shouldn't be any\n  conflicting version of ffmpeg installed. Currently, this is only supported on Linux.\n\n```\nconda install -c conda-forge 'ffmpeg<4.3'\npython setup.py install\n```\n\n# Using the models on C++\n\nRefer to [example/cpp](https://github.com/pytorch/vision/tree/main/examples/cpp).\n\n**DISCLAIMER**: the `libtorchvision` library includes the torchvision\ncustom ops as well as most of the C++ torchvision APIs. Those APIs do not come\nwith any backward-compatibility guarantees and may change from one version to\nthe next. Only the Python APIs are stable and with backward-compatibility\nguarantees. So, if you need stability within a C++ environment, your best bet is\nto export the Python APIs via torchscript.\n\n## Documentation\n\nYou can find the API documentation on the pytorch website: <https://pytorch.org/vision/stable/index.html>\n\n## Contributing\n\nSee the [CONTRIBUTING](CONTRIBUTING.md) file for how to help out.\n\n## Disclaimer on Datasets\n\nThis is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets,\nvouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility to\ndetermine whether you have permission to use the dataset under the dataset's license.\n\nIf you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset\nto be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the ML\ncommunity!\n\n## Pre-trained Model License\n\nThe pre-trained models provided in this library may have their own licenses or terms and conditions derived from the\ndataset used for training. It is your responsibility to determine whether you have permission to use the models for your\nuse case.\n\nMore specifically, SWAG models are released under the CC-BY-NC 4.0 license. See\n[SWAG LICENSE](https://github.com/facebookresearch/SWAG/blob/main/LICENSE) for additional details.\n\n## Citing TorchVision\n\nIf you find TorchVision useful in your work, please consider citing the following BibTeX entry:\n\n```bibtex\n@software{torchvision2016,\n    title        = {TorchVision: PyTorch's Computer Vision library},\n    author       = {TorchVision maintainers and contributors},\n    year         = 2016,\n    journal      = {GitHub repository},\n    publisher    = {GitHub},\n    howpublished = {\\url{https://github.com/pytorch/vision}}\n}\n```\n"
        },
        {
          "name": "android",
          "type": "tree",
          "content": null
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmake",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "gallery",
          "type": "tree",
          "content": null
        },
        {
          "name": "hubconf.py",
          "type": "blob",
          "size": 2.4892578125,
          "content": "# Optional list of dependencies required by the package\ndependencies = [\"torch\"]\n\nfrom torchvision.models import get_model_weights, get_weight\nfrom torchvision.models.alexnet import alexnet\nfrom torchvision.models.convnext import convnext_base, convnext_large, convnext_small, convnext_tiny\nfrom torchvision.models.densenet import densenet121, densenet161, densenet169, densenet201\nfrom torchvision.models.efficientnet import (\n    efficientnet_b0,\n    efficientnet_b1,\n    efficientnet_b2,\n    efficientnet_b3,\n    efficientnet_b4,\n    efficientnet_b5,\n    efficientnet_b6,\n    efficientnet_b7,\n    efficientnet_v2_l,\n    efficientnet_v2_m,\n    efficientnet_v2_s,\n)\nfrom torchvision.models.googlenet import googlenet\nfrom torchvision.models.inception import inception_v3\nfrom torchvision.models.maxvit import maxvit_t\nfrom torchvision.models.mnasnet import mnasnet0_5, mnasnet0_75, mnasnet1_0, mnasnet1_3\nfrom torchvision.models.mobilenetv2 import mobilenet_v2\nfrom torchvision.models.mobilenetv3 import mobilenet_v3_large, mobilenet_v3_small\nfrom torchvision.models.optical_flow import raft_large, raft_small\nfrom torchvision.models.regnet import (\n    regnet_x_16gf,\n    regnet_x_1_6gf,\n    regnet_x_32gf,\n    regnet_x_3_2gf,\n    regnet_x_400mf,\n    regnet_x_800mf,\n    regnet_x_8gf,\n    regnet_y_128gf,\n    regnet_y_16gf,\n    regnet_y_1_6gf,\n    regnet_y_32gf,\n    regnet_y_3_2gf,\n    regnet_y_400mf,\n    regnet_y_800mf,\n    regnet_y_8gf,\n)\nfrom torchvision.models.resnet import (\n    resnet101,\n    resnet152,\n    resnet18,\n    resnet34,\n    resnet50,\n    resnext101_32x8d,\n    resnext101_64x4d,\n    resnext50_32x4d,\n    wide_resnet101_2,\n    wide_resnet50_2,\n)\nfrom torchvision.models.segmentation import (\n    deeplabv3_mobilenet_v3_large,\n    deeplabv3_resnet101,\n    deeplabv3_resnet50,\n    fcn_resnet101,\n    fcn_resnet50,\n    lraspp_mobilenet_v3_large,\n)\nfrom torchvision.models.shufflenetv2 import (\n    shufflenet_v2_x0_5,\n    shufflenet_v2_x1_0,\n    shufflenet_v2_x1_5,\n    shufflenet_v2_x2_0,\n)\nfrom torchvision.models.squeezenet import squeezenet1_0, squeezenet1_1\nfrom torchvision.models.swin_transformer import swin_b, swin_s, swin_t, swin_v2_b, swin_v2_s, swin_v2_t\nfrom torchvision.models.vgg import vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19, vgg19_bn\nfrom torchvision.models.video import (\n    mc3_18,\n    mvit_v1_b,\n    mvit_v2_s,\n    r2plus1d_18,\n    r3d_18,\n    s3d,\n    swin3d_b,\n    swin3d_s,\n    swin3d_t,\n)\nfrom torchvision.models.vision_transformer import vit_b_16, vit_b_32, vit_h_14, vit_l_16, vit_l_32\n"
        },
        {
          "name": "ios",
          "type": "tree",
          "content": null
        },
        {
          "name": "maintainer_guide.md",
          "type": "blob",
          "size": 3.8193359375,
          "content": "# Torchvision maintainers guide\n\nThis document aims at documenting user-facing policies / principles used when\ndeveloping and maintaining torchvision. Other maintainer info (e.g. release\nprocess) can be found in the meta-internal wiki.\n\n### What is public and what is private?\n\nFor the Python API, torchvision largely follows the [PyTorch\npolicy](https://github.com/pytorch/pytorch/wiki/Public-API-definition-and-documentation)\nwhich is consistent with other major packages\n([numpy](https://numpy.org/neps/nep-0023-backwards-compatibility.html),\n[scikit-learn](https://scikit-learn.org/dev/glossary.html#term-API) etc.).\nWe recognize that his policy is somewhat imperfect for some edge cases, and that\nit's difficult to come up with an accurate technical definition. In broad terms,\nwhich are usually well understood by users, the policy is that:\n\n- modules that can be accessed without leading underscore are public\n- objects in a public file that don't have a leading underscore are public\n- class attributes are public iff they have no leading underscore\n- the rest of the modules / objects / class attributes are considered private\n\nThe public API has backward-compatible (BC) guarantees defined in our\ndeprecation policy (see below). The private API has not BC guarantees.\n\nFor C++, code is private. For Meta employees: if a C++ change breaks fbcode, fix\nfbcode or revert the change. We should be careful about models running in\nproduction and relying on torchvision ops.\n\nThe `test` folder is not importable and is **private.** Even meta-internal\nprojects should *not* rely on it (it has happened in the past and is now\nprogrammatically impossible).\n\nThe training references do not have BC guarantees. Breaking changes are\npossible, but we should make sure that the tutorials are still running properly,\nand that their intended narrative is preserved (by e.g. checking outputs,\netc.).\n\nThe rest of the folders (build, android, ios, etc.) are private and have no BC\nguarantees.\n\n### Deprecation policy.\n\nBecause they're disruptive, **deprecations should only be used sparingly**.\n\nWe largely follow the [PyTorch\npolicy](https://github.com/pytorch/pytorch/wiki/PyTorch's-Python-Frontend-Backward-and-Forward-Compatibility-Policy):\nbreaking changes require a deprecation period of at least 2 versions.\n\nDeprecations should clearly indicate their deadline in the docs and warning\nmessages. Avoid not committing to a deadline, or keeping deprecated APIs for too\nlong: it gives no incentive for users to update their code, sends conflicting\nmessages (\"why was this API removed while this other one is still around?\"), and\naccumulates debt in the project.\n\n### Should this attribute be public? Should this function be private?\n\nWhen designing an API it’s not always obvious what should be exposed as public,\nand what should be kept as a private implementation detail. The following\nguidelines can be useful:\n\n* Functional consistency throughout the library is a top priority, for users and\n  developers’ sake. In doubt and unless it’s clearly wrong, expose what other\n  similar classes expose.\n* Think really hard about the users and their use-cases, and try to expose what\n  they would need to address those use-cases. Aggressively keep everything else\n  private. Remember that the “private -> public” direction is way smoother than\n  the “public -> private” one: in doubt, keep it private.\n* When thinking about use-cases, the general API motto applies: make what’s\n  simple and common easy, and make what’s complex possible (80% / 20% rule).\n  There might be a ~1% left that’s not addressed: that’s OK. Also, **make what’s\n  wrong very hard**, if not impossible.\n\nAs a good practice, always create new files and even classes with a leading\nunderscore in their name. This way, everything is private by default and the\nonly public surface is explicitly present in an `__init__.py` file.\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 2.2255859375,
          "content": "[mypy]\n\nfiles = torchvision\nshow_error_codes = True\npretty = True\nallow_redefinition = True\nno_implicit_optional = True\nwarn_redundant_casts = True\n\n[mypy-torchvision.prototype.datapoints.*]\n\n; untyped definitions and calls\ndisallow_untyped_defs = True\n\n; None and Optional handling\nno_implicit_optional = True\n\n; warnings\nwarn_unused_ignores = True\n\n; miscellaneous strictness flags\nallow_redefinition = True\n\n[mypy-torchvision.prototype.transforms.*]\n\nignore_errors = True\n\n[mypy-torchvision.prototype.datasets.*]\n\nignore_errors = True\n\n[mypy-torchvision.io.image.*]\n\nignore_errors = True\n\n[mypy-torchvision.io.video.*]\n\nignore_errors = True\n\n[mypy-torchvision.io.video_reader]\n\nignore_errors = True\n\n[mypy-torchvision.models.densenet.*]\n\nignore_errors=True\n\n[mypy-torchvision.models.maxvit.*]\n\nignore_errors=True\n\n[mypy-torchvision.models.detection.anchor_utils]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.transform]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.roi_heads]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.faster_rcnn]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.mask_rcnn]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.keypoint_rcnn]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.retinanet]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.ssd]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.ssdlite]\n\nignore_errors = True\n\n[mypy-torchvision.models.detection.fcos]\n\nignore_errors = True\n\n[mypy-torchvision.ops.*]\n\nignore_errors = True\n\n[mypy-torchvision.transforms._functional_pil]\n\nignore_errors = True\n\n[mypy-torchvision.transforms.functional.*]\n\nignore_errors = True\n\n[mypy-torchvision.transforms.transforms.*]\n\nignore_errors = True\n\n[mypy-PIL.*]\n\nignore_missing_imports = True\n\n[mypy-numpy.*]\n\nignore_missing_imports = True\n\n[mypy-scipy.*]\n\nignore_missing_imports = True\n\n[mypy-pycocotools.*]\n\nignore_missing_imports = True\n\n[mypy-lmdb.*]\n\nignore_missing_imports = True\n\n[mypy-accimage.*]\n\nignore_missing_imports = True\n\n[mypy-av.*]\n\nignore_missing_imports = True\n\n[mypy-defusedxml.*]\n\nignore_missing_imports = True\n\n[mypy-torchdata.*]\n\nignore_missing_imports = True\n\n[mypy-h5py.*]\n\nignore_missing_imports = True\n\n[mypy-gdown.*]\n\nignore_missing_imports = True\n"
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.203125,
          "content": "[tool.usort]\n\nfirst_party_detection = false\n\n[tool.black]\n\nline-length = 120\ntarget-version = [\"py38\"]\n\n[tool.ufmt]\n\nexcludes = [\n    \"gallery\",\n]\n\n[build-system]\n\nrequires = [\"setuptools\", \"torch\", \"wheel\"]\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.2978515625,
          "content": "[pytest]\naddopts =\n    # show tests that (f)ailed, (E)rror, or (X)passed in the summary\n    -rfEX\n    # Make tracebacks shorter\n    --tb=short\n    # enable all warnings\n    -Wd\n    --ignore=test/test_datasets_download.py\n    --ignore-glob=test/test_prototype_*.py\ntestpaths =\n    test\nxfail_strict = True\n"
        },
        {
          "name": "references",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.556640625,
          "content": "[bdist_wheel]\nuniversal=1\n\n[metadata]\nlicense_files = LICENSE\n\n[pep8]\nmax-line-length = 120\n\n[flake8]\n# note: we ignore all 501s (line too long) anyway as they're taken care of by black\nmax-line-length = 120\nignore = E203, E402, W503, W504, F821, E501, B, C4, EXE\nper-file-ignores =\n    __init__.py: F401, F403, F405\n    ./hubconf.py: F401\n    torchvision/models/mobilenet.py: F401, F403\n    torchvision/models/quantization/mobilenet.py: F401, F403\n    test/smoke_test.py: F401\nexclude = venv\n\n[pydocstyle]\nselect = D417 # Missing argument descriptions in the docstring\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 21.580078125,
          "content": "import distutils.command.clean\nimport distutils.spawn\nimport glob\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport warnings\nfrom pathlib import Path\n\nimport torch\nfrom pkg_resources import DistributionNotFound, get_distribution, parse_version\nfrom setuptools import find_packages, setup\nfrom torch.utils.cpp_extension import BuildExtension, CppExtension, CUDA_HOME, CUDAExtension, ROCM_HOME\n\nFORCE_CUDA = os.getenv(\"FORCE_CUDA\", \"0\") == \"1\"\nFORCE_MPS = os.getenv(\"FORCE_MPS\", \"0\") == \"1\"\nDEBUG = os.getenv(\"DEBUG\", \"0\") == \"1\"\nUSE_PNG = os.getenv(\"TORCHVISION_USE_PNG\", \"1\") == \"1\"\nUSE_JPEG = os.getenv(\"TORCHVISION_USE_JPEG\", \"1\") == \"1\"\nUSE_WEBP = os.getenv(\"TORCHVISION_USE_WEBP\", \"1\") == \"1\"\nUSE_NVJPEG = os.getenv(\"TORCHVISION_USE_NVJPEG\", \"1\") == \"1\"\nNVCC_FLAGS = os.getenv(\"NVCC_FLAGS\", None)\n# Note: the GPU video decoding stuff used to be called \"video codec\", which\n# isn't an accurate or descriptive name considering there are at least 2 other\n# video deocding backends in torchvision. I'm renaming this to \"gpu video\n# decoder\" where possible, keeping user facing names (like the env var below) to\n# the old scheme for BC.\nUSE_GPU_VIDEO_DECODER = os.getenv(\"TORCHVISION_USE_VIDEO_CODEC\", \"1\") == \"1\"\n# Same here: \"use ffmpeg\" was used to denote \"use cpu video decoder\".\nUSE_CPU_VIDEO_DECODER = os.getenv(\"TORCHVISION_USE_FFMPEG\", \"1\") == \"1\"\n\nTORCHVISION_INCLUDE = os.environ.get(\"TORCHVISION_INCLUDE\", \"\")\nTORCHVISION_LIBRARY = os.environ.get(\"TORCHVISION_LIBRARY\", \"\")\nTORCHVISION_INCLUDE = TORCHVISION_INCLUDE.split(os.pathsep) if TORCHVISION_INCLUDE else []\nTORCHVISION_LIBRARY = TORCHVISION_LIBRARY.split(os.pathsep) if TORCHVISION_LIBRARY else []\n\nROOT_DIR = Path(__file__).absolute().parent\nCSRS_DIR = ROOT_DIR / \"torchvision/csrc\"\nIS_ROCM = (torch.version.hip is not None) and (ROCM_HOME is not None)\nBUILD_CUDA_SOURCES = (torch.cuda.is_available() and ((CUDA_HOME is not None) or IS_ROCM)) or FORCE_CUDA\n\npackage_name = os.getenv(\"TORCHVISION_PACKAGE_NAME\", \"torchvision\")\n\nprint(\"Torchvision build configuration:\")\nprint(f\"{FORCE_CUDA = }\")\nprint(f\"{FORCE_MPS = }\")\nprint(f\"{DEBUG = }\")\nprint(f\"{USE_PNG = }\")\nprint(f\"{USE_JPEG = }\")\nprint(f\"{USE_WEBP = }\")\nprint(f\"{USE_NVJPEG = }\")\nprint(f\"{NVCC_FLAGS = }\")\nprint(f\"{USE_CPU_VIDEO_DECODER = }\")\nprint(f\"{USE_GPU_VIDEO_DECODER = }\")\nprint(f\"{TORCHVISION_INCLUDE = }\")\nprint(f\"{TORCHVISION_LIBRARY = }\")\nprint(f\"{IS_ROCM = }\")\nprint(f\"{BUILD_CUDA_SOURCES = }\")\n\n\ndef get_version():\n    with open(ROOT_DIR / \"version.txt\") as f:\n        version = f.readline().strip()\n    sha = \"Unknown\"\n\n    try:\n        sha = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=str(ROOT_DIR)).decode(\"ascii\").strip()\n    except Exception:\n        pass\n\n    if os.getenv(\"BUILD_VERSION\"):\n        version = os.getenv(\"BUILD_VERSION\")\n    elif sha != \"Unknown\":\n        version += \"+\" + sha[:7]\n\n    return version, sha\n\n\ndef write_version_file(version, sha):\n    # Exists for BC, probably completely useless.\n    with open(ROOT_DIR / \"torchvision/version.py\", \"w\") as f:\n        f.write(f\"__version__ = '{version}'\\n\")\n        f.write(f\"git_version = {repr(sha)}\\n\")\n        f.write(\"from torchvision.extension import _check_cuda_version\\n\")\n        f.write(\"if _check_cuda_version() > 0:\\n\")\n        f.write(\"    cuda = _check_cuda_version()\\n\")\n\n\ndef get_requirements():\n    def get_dist(pkgname):\n        try:\n            return get_distribution(pkgname)\n        except DistributionNotFound:\n            return None\n\n    pytorch_dep = os.getenv(\"TORCH_PACKAGE_NAME\", \"torch\")\n    if os.getenv(\"PYTORCH_VERSION\"):\n        pytorch_dep += \"==\" + os.getenv(\"PYTORCH_VERSION\")\n\n    requirements = [\n        \"numpy\",\n        pytorch_dep,\n    ]\n\n    # Excluding 8.3.* because of https://github.com/pytorch/vision/issues/4934\n    pillow_ver = \" >= 5.3.0, !=8.3.*\"\n    pillow_req = \"pillow-simd\" if get_dist(\"pillow-simd\") is not None else \"pillow\"\n    requirements.append(pillow_req + pillow_ver)\n\n    return requirements\n\n\ndef get_macros_and_flags():\n    define_macros = []\n    extra_compile_args = {\"cxx\": []}\n    if BUILD_CUDA_SOURCES:\n        if IS_ROCM:\n            define_macros += [(\"WITH_HIP\", None)]\n            nvcc_flags = []\n        else:\n            define_macros += [(\"WITH_CUDA\", None)]\n            if NVCC_FLAGS is None:\n                nvcc_flags = []\n            else:\n                nvcc_flags = NVCC_FLAGS.split(\" \")\n        extra_compile_args[\"nvcc\"] = nvcc_flags\n\n    if sys.platform == \"win32\":\n        define_macros += [(\"torchvision_EXPORTS\", None)]\n        extra_compile_args[\"cxx\"].append(\"/MP\")\n\n    if DEBUG:\n        extra_compile_args[\"cxx\"].append(\"-g\")\n        extra_compile_args[\"cxx\"].append(\"-O0\")\n        if \"nvcc\" in extra_compile_args:\n            # we have to remove \"-OX\" and \"-g\" flag if exists and append\n            nvcc_flags = extra_compile_args[\"nvcc\"]\n            extra_compile_args[\"nvcc\"] = [f for f in nvcc_flags if not (\"-O\" in f or \"-g\" in f)]\n            extra_compile_args[\"nvcc\"].append(\"-O0\")\n            extra_compile_args[\"nvcc\"].append(\"-g\")\n    else:\n        extra_compile_args[\"cxx\"].append(\"-g0\")\n\n    return define_macros, extra_compile_args\n\n\ndef make_C_extension():\n    print(\"Building _C extension\")\n\n    sources = (\n        list(CSRS_DIR.glob(\"*.cpp\"))\n        + list(CSRS_DIR.glob(\"ops/*.cpp\"))\n        + list(CSRS_DIR.glob(\"ops/autocast/*.cpp\"))\n        + list(CSRS_DIR.glob(\"ops/autograd/*.cpp\"))\n        + list(CSRS_DIR.glob(\"ops/cpu/*.cpp\"))\n        + list(CSRS_DIR.glob(\"ops/quantized/cpu/*.cpp\"))\n    )\n    mps_sources = list(CSRS_DIR.glob(\"ops/mps/*.mm\"))\n\n    if IS_ROCM:\n        from torch.utils.hipify import hipify_python\n\n        hipify_python.hipify(\n            project_directory=str(ROOT_DIR),\n            output_directory=str(ROOT_DIR),\n            includes=\"torchvision/csrc/ops/cuda/*\",\n            show_detailed=True,\n            is_pytorch_extension=True,\n        )\n        cuda_sources = list(CSRS_DIR.glob(\"ops/hip/*.hip\"))\n        for header in CSRS_DIR.glob(\"ops/cuda/*.h\"):\n            shutil.copy(str(header), str(CSRS_DIR / \"ops/hip\"))\n    else:\n        cuda_sources = list(CSRS_DIR.glob(\"ops/cuda/*.cu\"))\n\n    if BUILD_CUDA_SOURCES:\n        Extension = CUDAExtension\n        sources += cuda_sources\n    else:\n        Extension = CppExtension\n        if torch.backends.mps.is_available() or FORCE_MPS:\n            sources += mps_sources\n\n    define_macros, extra_compile_args = get_macros_and_flags()\n    return Extension(\n        name=\"torchvision._C\",\n        sources=sorted(str(s) for s in sources),\n        include_dirs=[CSRS_DIR],\n        define_macros=define_macros,\n        extra_compile_args=extra_compile_args,\n    )\n\n\ndef find_libpng():\n    # Returns (found, include dir, library dir, library name)\n    if sys.platform in (\"linux\", \"darwin\"):\n        libpng_config = shutil.which(\"libpng-config\")\n        if libpng_config is None:\n            warnings.warn(\"libpng-config not found\")\n            return False, None, None, None\n        min_version = parse_version(\"1.6.0\")\n        png_version = parse_version(\n            subprocess.run([libpng_config, \"--version\"], stdout=subprocess.PIPE).stdout.strip().decode(\"utf-8\")\n        )\n        if png_version < min_version:\n            warnings.warn(\"libpng version {png_version} is less than minimum required version {min_version}\")\n            return False, None, None, None\n\n        include_dir = (\n            subprocess.run([libpng_config, \"--I_opts\"], stdout=subprocess.PIPE)\n            .stdout.strip()\n            .decode(\"utf-8\")\n            .split(\"-I\")[1]\n        )\n        library_dir = subprocess.run([libpng_config, \"--libdir\"], stdout=subprocess.PIPE).stdout.strip().decode(\"utf-8\")\n        library = \"png\"\n    else:  # Windows\n        pngfix = shutil.which(\"pngfix\")\n        if pngfix is None:\n            warnings.warn(\"pngfix not found\")\n            return False, None, None, None\n        pngfix_dir = Path(pngfix).absolute().parent.parent\n\n        library_dir = str(pngfix_dir / \"lib\")\n        include_dir = str(pngfix_dir / \"include/libpng16\")\n        library = \"libpng\"\n\n    return True, include_dir, library_dir, library\n\n\ndef find_library(header):\n    # returns (found, include dir, library dir)\n    # if include dir or library dir is None, it means that the library is in\n    # standard paths and don't need to be added to compiler / linker search\n    # paths\n\n    searching_for = f\"Searching for {header}\"\n\n    for folder in TORCHVISION_INCLUDE:\n        if (Path(folder) / header).exists():\n            print(f\"{searching_for} in {Path(folder) / header}. Found in TORCHVISION_INCLUDE.\")\n            return True, None, None\n    print(f\"{searching_for}. Didn't find in TORCHVISION_INCLUDE.\")\n\n    # Try conda-related prefixes. If BUILD_PREFIX is set it means conda-build is\n    # being run. If CONDA_PREFIX is set then we're in a conda environment.\n    for prefix_env_var in (\"BUILD_PREFIX\", \"CONDA_PREFIX\"):\n        if (prefix := os.environ.get(prefix_env_var)) is not None:\n            prefix = Path(prefix)\n            if sys.platform == \"win32\":\n                prefix = prefix / \"Library\"\n            include_dir = prefix / \"include\"\n            library_dir = prefix / \"lib\"\n            if (include_dir / header).exists():\n                print(f\"{searching_for}. Found in {prefix_env_var}.\")\n                return True, str(include_dir), str(library_dir)\n        print(f\"{searching_for}. Didn't find in {prefix_env_var}.\")\n\n    if sys.platform == \"linux\":\n        for prefix in (Path(\"/usr/include\"), Path(\"/usr/local/include\")):\n            if (prefix / header).exists():\n                print(f\"{searching_for}. Found in {prefix}.\")\n                return True, None, None\n            print(f\"{searching_for}. Didn't find in {prefix}\")\n\n    return False, None, None\n\n\ndef make_image_extension():\n    print(\"Building image extension\")\n\n    include_dirs = TORCHVISION_INCLUDE.copy()\n    library_dirs = TORCHVISION_LIBRARY.copy()\n\n    libraries = []\n    define_macros, extra_compile_args = get_macros_and_flags()\n\n    image_dir = CSRS_DIR / \"io/image\"\n    sources = list(image_dir.glob(\"*.cpp\")) + list(image_dir.glob(\"cpu/*.cpp\")) + list(image_dir.glob(\"cpu/giflib/*.c\"))\n\n    if IS_ROCM:\n        sources += list(image_dir.glob(\"hip/*.cpp\"))\n        # we need to exclude this in favor of the hipified source\n        sources.remove(image_dir / \"image.cpp\")\n    else:\n        sources += list(image_dir.glob(\"cuda/*.cpp\"))\n\n    Extension = CppExtension\n\n    if USE_PNG:\n        png_found, png_include_dir, png_library_dir, png_library = find_libpng()\n        if png_found:\n            print(\"Building torchvision with PNG support\")\n            print(f\"{png_include_dir = }\")\n            print(f\"{png_library_dir = }\")\n            include_dirs.append(png_include_dir)\n            library_dirs.append(png_library_dir)\n            libraries.append(png_library)\n            define_macros += [(\"PNG_FOUND\", 1)]\n        else:\n            warnings.warn(\"Building torchvision without PNG support\")\n\n    if USE_JPEG:\n        jpeg_found, jpeg_include_dir, jpeg_library_dir = find_library(header=\"jpeglib.h\")\n        if jpeg_found:\n            print(\"Building torchvision with JPEG support\")\n            print(f\"{jpeg_include_dir = }\")\n            print(f\"{jpeg_library_dir = }\")\n            if jpeg_include_dir is not None and jpeg_library_dir is not None:\n                # if those are None it means they come from standard paths that are already in the search paths, which we don't need to re-add.\n                include_dirs.append(jpeg_include_dir)\n                library_dirs.append(jpeg_library_dir)\n            libraries.append(\"jpeg\")\n            define_macros += [(\"JPEG_FOUND\", 1)]\n        else:\n            warnings.warn(\"Building torchvision without JPEG support\")\n\n    if USE_WEBP:\n        webp_found, webp_include_dir, webp_library_dir = find_library(header=\"webp/decode.h\")\n        if webp_found:\n            print(\"Building torchvision with WEBP support\")\n            print(f\"{webp_include_dir = }\")\n            print(f\"{webp_library_dir = }\")\n            if webp_include_dir is not None and webp_library_dir is not None:\n                # if those are None it means they come from standard paths that are already in the search paths, which we don't need to re-add.\n                include_dirs.append(webp_include_dir)\n                library_dirs.append(webp_library_dir)\n            webp_library = \"libwebp\" if sys.platform == \"win32\" else \"webp\"\n            libraries.append(webp_library)\n            define_macros += [(\"WEBP_FOUND\", 1)]\n        else:\n            warnings.warn(\"Building torchvision without WEBP support\")\n\n    if USE_NVJPEG and (torch.cuda.is_available() or FORCE_CUDA):\n        nvjpeg_found = CUDA_HOME is not None and (Path(CUDA_HOME) / \"include/nvjpeg.h\").exists()\n\n        if nvjpeg_found:\n            print(\"Building torchvision with NVJPEG image support\")\n            libraries.append(\"nvjpeg\")\n            define_macros += [(\"NVJPEG_FOUND\", 1)]\n            Extension = CUDAExtension\n        else:\n            warnings.warn(\"Building torchvision without NVJPEG support\")\n    elif USE_NVJPEG:\n        warnings.warn(\"Building torchvision without NVJPEG support\")\n\n    return Extension(\n        name=\"torchvision.image\",\n        sources=sorted(str(s) for s in sources),\n        include_dirs=include_dirs,\n        library_dirs=library_dirs,\n        define_macros=define_macros,\n        libraries=libraries,\n        extra_compile_args=extra_compile_args,\n    )\n\n\ndef make_video_decoders_extensions():\n    print(\"Building video decoder extensions\")\n\n    build_without_extensions_msg = \"Building without video decoders extensions.\"\n    if sys.platform != \"linux\" or (sys.version_info.major == 3 and sys.version_info.minor == 9):\n        # FIXME: Building torchvision with ffmpeg on MacOS or with Python 3.9\n        # FIXME: causes crash. See the following GitHub issues for more details.\n        # FIXME: https://github.com/pytorch/pytorch/issues/65000\n        # FIXME: https://github.com/pytorch/vision/issues/3367\n        print(\"Can only build video decoder extensions on linux and Python != 3.9\")\n        return []\n\n    ffmpeg_exe = shutil.which(\"ffmpeg\")\n    if ffmpeg_exe is None:\n        print(f\"{build_without_extensions_msg} Couldn't find ffmpeg binary.\")\n        return []\n\n    def find_ffmpeg_libraries():\n        ffmpeg_libraries = {\"libavcodec\", \"libavformat\", \"libavutil\", \"libswresample\", \"libswscale\"}\n\n        ffmpeg_bin = os.path.dirname(ffmpeg_exe)\n        ffmpeg_root = os.path.dirname(ffmpeg_bin)\n        ffmpeg_include_dir = os.path.join(ffmpeg_root, \"include\")\n        ffmpeg_library_dir = os.path.join(ffmpeg_root, \"lib\")\n\n        gcc = os.environ.get(\"CC\", shutil.which(\"gcc\"))\n        platform_tag = subprocess.run([gcc, \"-print-multiarch\"], stdout=subprocess.PIPE)\n        platform_tag = platform_tag.stdout.strip().decode(\"utf-8\")\n\n        if platform_tag:\n            # Most probably a Debian-based distribution\n            ffmpeg_include_dir = [ffmpeg_include_dir, os.path.join(ffmpeg_include_dir, platform_tag)]\n            ffmpeg_library_dir = [ffmpeg_library_dir, os.path.join(ffmpeg_library_dir, platform_tag)]\n        else:\n            ffmpeg_include_dir = [ffmpeg_include_dir]\n            ffmpeg_library_dir = [ffmpeg_library_dir]\n\n        for library in ffmpeg_libraries:\n            library_found = False\n            for search_path in ffmpeg_include_dir + TORCHVISION_INCLUDE:\n                full_path = os.path.join(search_path, library, \"*.h\")\n                library_found |= len(glob.glob(full_path)) > 0\n\n            if not library_found:\n                print(f\"{build_without_extensions_msg}\")\n                print(f\"{library} header files were not found.\")\n                return None, None\n\n        return ffmpeg_include_dir, ffmpeg_library_dir\n\n    ffmpeg_include_dir, ffmpeg_library_dir = find_ffmpeg_libraries()\n    if ffmpeg_include_dir is None or ffmpeg_library_dir is None:\n        return []\n\n    print(\"Found ffmpeg:\")\n    print(f\"  ffmpeg include path: {ffmpeg_include_dir}\")\n    print(f\"  ffmpeg library_dir: {ffmpeg_library_dir}\")\n\n    extensions = []\n    if USE_CPU_VIDEO_DECODER:\n        print(\"Building with CPU video decoder support\")\n\n        # TorchVision base decoder + video reader\n        video_reader_src_dir = os.path.join(ROOT_DIR, \"torchvision\", \"csrc\", \"io\", \"video_reader\")\n        video_reader_src = glob.glob(os.path.join(video_reader_src_dir, \"*.cpp\"))\n        base_decoder_src_dir = os.path.join(ROOT_DIR, \"torchvision\", \"csrc\", \"io\", \"decoder\")\n        base_decoder_src = glob.glob(os.path.join(base_decoder_src_dir, \"*.cpp\"))\n        # Torchvision video API\n        videoapi_src_dir = os.path.join(ROOT_DIR, \"torchvision\", \"csrc\", \"io\", \"video\")\n        videoapi_src = glob.glob(os.path.join(videoapi_src_dir, \"*.cpp\"))\n        # exclude tests\n        base_decoder_src = [x for x in base_decoder_src if \"_test.cpp\" not in x]\n\n        combined_src = video_reader_src + base_decoder_src + videoapi_src\n\n        extensions.append(\n            CppExtension(\n                # This is an aweful name. It should be \"cpu_video_decoder\". Keeping for BC.\n                \"torchvision.video_reader\",\n                combined_src,\n                include_dirs=[\n                    base_decoder_src_dir,\n                    video_reader_src_dir,\n                    videoapi_src_dir,\n                    str(CSRS_DIR),\n                    *ffmpeg_include_dir,\n                    *TORCHVISION_INCLUDE,\n                ],\n                library_dirs=ffmpeg_library_dir + TORCHVISION_LIBRARY,\n                libraries=[\n                    \"avcodec\",\n                    \"avformat\",\n                    \"avutil\",\n                    \"swresample\",\n                    \"swscale\",\n                ],\n                extra_compile_args=[\"-std=c++17\"] if os.name != \"nt\" else [\"/std:c++17\", \"/MP\"],\n                extra_link_args=[\"-std=c++17\" if os.name != \"nt\" else \"/std:c++17\"],\n            )\n        )\n\n    if USE_GPU_VIDEO_DECODER:\n        # Locating GPU video decoder headers and libraries\n        # CUDA_HOME should be set to the cuda root directory.\n        # TORCHVISION_INCLUDE and TORCHVISION_LIBRARY should include the locations\n        # to the headers and libraries below\n        if not (\n            BUILD_CUDA_SOURCES\n            and CUDA_HOME is not None\n            and any([os.path.exists(os.path.join(folder, \"cuviddec.h\")) for folder in TORCHVISION_INCLUDE])\n            and any([os.path.exists(os.path.join(folder, \"nvcuvid.h\")) for folder in TORCHVISION_INCLUDE])\n            and any([os.path.exists(os.path.join(folder, \"libnvcuvid.so\")) for folder in TORCHVISION_LIBRARY])\n            and any([os.path.exists(os.path.join(folder, \"libavcodec\", \"bsf.h\")) for folder in ffmpeg_include_dir])\n        ):\n            print(\"Could not find necessary dependencies. Refer the setup.py to check which ones are needed.\")\n            print(\"Building without GPU video decoder support\")\n            return extensions\n        print(\"Building torchvision with GPU video decoder support\")\n\n        gpu_decoder_path = os.path.join(CSRS_DIR, \"io\", \"decoder\", \"gpu\")\n        gpu_decoder_src = glob.glob(os.path.join(gpu_decoder_path, \"*.cpp\"))\n        cuda_libs = os.path.join(CUDA_HOME, \"lib64\")\n        cuda_inc = os.path.join(CUDA_HOME, \"include\")\n\n        _, extra_compile_args = get_macros_and_flags()\n        extensions.append(\n            CUDAExtension(\n                \"torchvision.gpu_decoder\",\n                gpu_decoder_src,\n                include_dirs=[CSRS_DIR] + TORCHVISION_INCLUDE + [gpu_decoder_path] + [cuda_inc] + ffmpeg_include_dir,\n                library_dirs=ffmpeg_library_dir + TORCHVISION_LIBRARY + [cuda_libs],\n                libraries=[\n                    \"avcodec\",\n                    \"avformat\",\n                    \"avutil\",\n                    \"swresample\",\n                    \"swscale\",\n                    \"nvcuvid\",\n                    \"cuda\",\n                    \"cudart\",\n                    \"z\",\n                    \"pthread\",\n                    \"dl\",\n                    \"nppicc\",\n                ],\n                extra_compile_args=extra_compile_args,\n            )\n        )\n\n    return extensions\n\n\nclass clean(distutils.command.clean.clean):\n    def run(self):\n        with open(\".gitignore\") as f:\n            ignores = f.read()\n            for wildcard in filter(None, ignores.split(\"\\n\")):\n                for filename in glob.glob(wildcard):\n                    try:\n                        os.remove(filename)\n                    except OSError:\n                        shutil.rmtree(filename, ignore_errors=True)\n\n        # It's an old-style class in Python 2.7...\n        distutils.command.clean.clean.run(self)\n\n\nif __name__ == \"__main__\":\n    version, sha = get_version()\n    write_version_file(version, sha)\n\n    print(f\"Building wheel {package_name}-{version}\")\n\n    with open(\"README.md\") as f:\n        readme = f.read()\n\n    extensions = [\n        make_C_extension(),\n        make_image_extension(),\n        *make_video_decoders_extensions(),\n    ]\n\n    setup(\n        name=package_name,\n        version=version,\n        author=\"PyTorch Core Team\",\n        author_email=\"soumith@pytorch.org\",\n        url=\"https://github.com/pytorch/vision\",\n        description=\"image and video datasets and models for torch deep learning\",\n        long_description=readme,\n        long_description_content_type=\"text/markdown\",\n        license=\"BSD\",\n        packages=find_packages(exclude=(\"test\",)),\n        package_data={package_name: [\"*.dll\", \"*.dylib\", \"*.so\", \"prototype/datasets/_builtin/*.categories\"]},\n        zip_safe=False,\n        install_requires=get_requirements(),\n        extras_require={\n            \"gdown\": [\"gdown>=4.7.3\"],\n            \"scipy\": [\"scipy\"],\n        },\n        ext_modules=extensions,\n        python_requires=\">=3.8\",\n        cmdclass={\n            \"build_ext\": BuildExtension.with_options(no_python_abi_suffix=True),\n            \"clean\": clean,\n        },\n    )\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "torchvision",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.0087890625,
          "content": "0.22.0a0\n"
        }
      ]
    }
  ]
}