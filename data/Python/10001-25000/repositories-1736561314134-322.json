{
  "metadata": {
    "timestamp": 1736561314134,
    "page": 322,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openai/shap-e",
      "stars": 11752,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0341796875,
          "content": "__pycache__/\n.DS_Store\n*.egg-info/\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.037109375,
          "content": "MIT License\n\nCopyright (c) 2023 OpenAI\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.17578125,
          "content": "# Shap-E\n\nThis is the official code and model release for [Shap-E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463).\n\n * See [Usage](#usage) for guidance on how to use this repository.\n * See [Samples](#samples) for examples of what our text-conditional model can generate.\n\n# Samples\n\nHere are some highlighted samples from our text-conditional model. For random samples on selected prompts, see [samples.md](samples.md).\n\n<table>\n    <tbody>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_chair_that_looks_like_an_avocado/2.gif\" alt=\"A chair that looks like an avocado\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/an_airplane_that_looks_like_a_banana/3.gif\" alt=\"An airplane that looks like a banana\">\n            </td align=\"center\">\n            <td align=\"center\">\n                <img src=\"samples/a_spaceship/0.gif\" alt=\"A spaceship\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A chair that looks<br>like an avocado</td>\n            <td align=\"center\">An airplane that looks<br>like a banana</td>\n            <td align=\"center\">A spaceship</td>\n        </tr>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_birthday_cupcake/3.gif\" alt=\"A birthday cupcake\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_chair_that_looks_like_a_tree/2.gif\" alt=\"A chair that looks like a tree\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_green_boot/3.gif\" alt=\"A green boot\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A birthday cupcake</td>\n            <td align=\"center\">A chair that looks<br>like a tree</td>\n            <td align=\"center\">A green boot</td>\n        </tr>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_penguin/1.gif\" alt=\"A penguin\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/ube_ice_cream_cone/3.gif\" alt=\"Ube ice cream cone\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_bowl_of_vegetables/2.gif\" alt=\"A bowl of vegetables\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A penguin</td>\n            <td align=\"center\">Ube ice cream cone</td>\n            <td align=\"center\">A bowl of vegetables</td>\n        </tr>\n    </tbody>\n<table>\n\n# Usage\n\nInstall with `pip install -e .`.\n\nTo get started with examples, see the following notebooks:\n\n* [sample_text_to_3d.ipynb](shap_e/examples/sample_text_to_3d.ipynb) - sample a 3D model, conditioned on a text prompt.\n* [sample_image_to_3d.ipynb](shap_e/examples/sample_image_to_3d.ipynb) - sample a 3D model, conditioned on a synthetic view image. To get the best result, you should remove background from the input image.\n* [encode_model.ipynb](shap_e/examples/encode_model.ipynb) - loads a 3D model or a trimesh, creates a batch of multiview renders and a point cloud, encodes them into a latent, and renders it back. For this to work, install Blender version 3.3.1 or higher, and set the environment variable `BLENDER_PATH` to the path of the Blender executable.\n"
        },
        {
          "name": "model-card.md",
          "type": "blob",
          "size": 6.2138671875,
          "content": "# Model Card: Shap-E\n\nThis is the official codebase for running the latent diffusion models described in [Shap-E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463). These models were trained and released by OpenAI. Following [Model Cards for Model Reporting (Mitchell et al.)](https://arxiv.org/abs/1810.03993), we're providing some information about how the models were trained and evaluated.\n\n# Model Details\n\nShap-E includes two kinds of models: an encoder and a latent diffusion model.\n\n 1. **The encoder** converts 3D assets into the parameters of small neural networks which represent the 3D shape and texture as an implicit function. The resulting implicit function can be rendered from arbitrary viewpoints or imported into downstream applications as a mesh.\n 2. **The latent diffusion model** generates novel implicit functions conditioned on either images or text descriptions. As above, these samples can be rendered or exported as a mesh. Specifically, these models produce latents which must be linearly projected to get the final implicit function parameters. The final projection layer of the encoder is used for this purpose.\n\nLike [Point-E](https://github.com/openai/point-e/blob/main/model-card.md), Shap-E can often generate coherent 3D objects when conditioned on a rendering from a single viewpoint. When conditioned on text prompts directly, Shap-E is also often capable of producing recognizable objects, although it sometimes struggles to combine multiple objects or concepts.\n\nSamples from Shap-E are typically lower fidelity than professional 3D assets and often have rough edges, holes, or blurry surface textures.\n\n# Model Date\n\nApril 2023\n\n# Model Versions\n\nThe following model checkpoints are available in this repository:\n\n * `transmitter` - the encoder and corresponding projection layers for converting encoder outputs into implicit neural representations.\n * `decoder` - just the final projection layer component of `transmitter`. This is a smaller checkpoint than `transmitter` since it does not include parameters for encoding 3D assets. This is the minimum required model to convert diffusion outputs into implicit neural representations.\n * `text300M` - the text-conditional latent diffusion model.\n * `image300M` - the image-conditional latent diffusion model.\n\n# Paper & Samples\n\n[Paper link](https://arxiv.org/abs/2305.02463) / [Samples](samples.md)\n\n# Training data\n\nThe encoder and image-conditional diffusion models are trained on the [same dataset as Point-E](https://github.com/openai/point-e/blob/main/model-card.md#training-data). However, a few changes to the post-processing were made:\n\n * We rendered 60 views (instead of 20) of each model when computing point clouds, to avoid small cracks.\n * We produced 16K points in each point cloud instead of 4K.\n * We simplified the lighting and material setup to only include diffuse materials.\n\nFor our text-conditional diffusion model, we expanded our dataset with roughly a million more 3D assets. Additionally, we collected 120K captions from human annotators for a high-quality subset of our 3D assets.\n\n# Evaluated Use\n\nWe release these models with the intention of furthering progress in the field of generative modeling. However, we acknowledge that our models have certain constraints and biases, which is why we advise against employing them for commercial purposes at this time. We are aware that the utilization of our models could extend to areas beyond our expectations, and defining specific criteria for what is considered suitable for \"research\" purposes presents a challenge. Specifically, we advise caution when using these models in contexts that demand high accuracy, where minor imperfections in the generated 3D assets could have adverse consequences.\n\nSpecifically, these models have been evaluated on the following tasks for research purposes:\n\n * Generating 3D renderings or meshes conditioned on single, synthetic images\n * Generating 3D renderings or meshes conditioned on text descriptions\n\n# Performance & Limitations\n\nOur image-conditional model has only been evaluated on a highly specific distribution of synthetic renderings. Even in these cases, the model still sometimes fails to infer the correct occluded parts of an object or produces geometry that is inconsistent with the given rendered images. These failure modes are similar to those of Point-E. The resulting 3D assets often have rough edges, holes, or blurry surface textures.\n\nOur text-conditional model can also produce a somewhat large and diverse vocabulary of objects. This model is often capable of producing objects with requested colors and textures, and sometimes even combining multiple objects. However, it often fails for more complex prompts that require placing multiple objects in a scene or binding attributes to objects. It also typically fails to produce a desired number of objects when a certain quantity is requested.\n\nWe find that our text-conditional model can sometimes produce samples which reflect gender biases. For example, samples for \"a nurse\" typically have a different body shape than samples for \"a doctor\". When probing for potential misuses, we also found that our text-conditional model is capable of producing 3D assets related to violence, such as guns or tanks. However, the resulting quality of these samples is poor enough that they look unrealistic and toy like.\n\nAs with Point-E, our dataset consists of many simple, cartoonish 3D assets, and our generative models are prone to imitating this style.\n\nWe believe our models will have many potential use cases. For example, our text-conditional model could enable users to quickly produce many 3D assets, allowing for rapid prototyping for computer graphics applications or 3D printing.\n\nThe use of 3D printing in concert with our models could potentially be harmful, for example if used to create dangerous objects or fabricate tools or parts that are deployed without external validation.\n\nGenerative 3D models share many challenges and constraints with image generation models. This includes the tendency to generate content that may be biased or detrimental, as well as the potential for dual-use applications. As the capabilities of these models evolve, further investigation is required to gain a clearer understanding of how these risks manifest.\n"
        },
        {
          "name": "samples.md",
          "type": "blob",
          "size": 15.66796875,
          "content": "# Samples\n\nHere is a collection of prompts and four random text-conditional samples for each prompt. Samples are rendered at 128x128 resolution with NeRF.\n\n<table><tbody><tr><th align=\"center\">Prompt</th><th></th><th></th><th></th><th></th><tr><td align=\"center\">a penguin</td><td align=\"center\"><img src=\"samples/a_penguin/0.gif\" alt=\"a penguin\"></td><td align=\"center\"><img src=\"samples/a_penguin/1.gif\" alt=\"a penguin\"></td><td align=\"center\"><img src=\"samples/a_penguin/2.gif\" alt=\"a penguin\"></td><td align=\"center\"><img src=\"samples/a_penguin/3.gif\" alt=\"a penguin\"></td></tr><tr><td align=\"center\">a campfire</td><td align=\"center\"><img src=\"samples/a_campfire/0.gif\" alt=\"a campfire\"></td><td align=\"center\"><img src=\"samples/a_campfire/1.gif\" alt=\"a campfire\"></td><td align=\"center\"><img src=\"samples/a_campfire/2.gif\" alt=\"a campfire\"></td><td align=\"center\"><img src=\"samples/a_campfire/3.gif\" alt=\"a campfire\"></td></tr><tr><td align=\"center\">an elephant</td><td align=\"center\"><img src=\"samples/an_elephant/0.gif\" alt=\"an elephant\"></td><td align=\"center\"><img src=\"samples/an_elephant/1.gif\" alt=\"an elephant\"></td><td align=\"center\"><img src=\"samples/an_elephant/2.gif\" alt=\"an elephant\"></td><td align=\"center\"><img src=\"samples/an_elephant/3.gif\" alt=\"an elephant\"></td></tr><tr><td align=\"center\">a donut with pink icing</td><td align=\"center\"><img src=\"samples/a_donut_with_pink_icing/0.gif\" alt=\"a donut with pink icing\"></td><td align=\"center\"><img src=\"samples/a_donut_with_pink_icing/1.gif\" alt=\"a donut with pink icing\"></td><td align=\"center\"><img src=\"samples/a_donut_with_pink_icing/2.gif\" alt=\"a donut with pink icing\"></td><td align=\"center\"><img src=\"samples/a_donut_with_pink_icing/3.gif\" alt=\"a donut with pink icing\"></td></tr><tr><td align=\"center\">a voxelized dog</td><td align=\"center\"><img src=\"samples/a_voxelized_dog/0.gif\" alt=\"a voxelized dog\"></td><td align=\"center\"><img src=\"samples/a_voxelized_dog/1.gif\" alt=\"a voxelized dog\"></td><td align=\"center\"><img src=\"samples/a_voxelized_dog/2.gif\" alt=\"a voxelized dog\"></td><td align=\"center\"><img src=\"samples/a_voxelized_dog/3.gif\" alt=\"a voxelized dog\"></td></tr><tr><td align=\"center\">ube ice cream cone</td><td align=\"center\"><img src=\"samples/ube_ice_cream_cone/0.gif\" alt=\"ube ice cream cone\"></td><td align=\"center\"><img src=\"samples/ube_ice_cream_cone/1.gif\" alt=\"ube ice cream cone\"></td><td align=\"center\"><img src=\"samples/ube_ice_cream_cone/2.gif\" alt=\"ube ice cream cone\"></td><td align=\"center\"><img src=\"samples/ube_ice_cream_cone/3.gif\" alt=\"ube ice cream cone\"></td></tr><tr><td align=\"center\">a birthday cupcake</td><td align=\"center\"><img src=\"samples/a_birthday_cupcake/0.gif\" alt=\"a birthday cupcake\"></td><td align=\"center\"><img src=\"samples/a_birthday_cupcake/1.gif\" alt=\"a birthday cupcake\"></td><td align=\"center\"><img src=\"samples/a_birthday_cupcake/2.gif\" alt=\"a birthday cupcake\"></td><td align=\"center\"><img src=\"samples/a_birthday_cupcake/3.gif\" alt=\"a birthday cupcake\"></td></tr><tr><td align=\"center\">shepherds pie</td><td align=\"center\"><img src=\"samples/shepherds_pie/0.gif\" alt=\"shepherds pie\"></td><td align=\"center\"><img src=\"samples/shepherds_pie/1.gif\" alt=\"shepherds pie\"></td><td align=\"center\"><img src=\"samples/shepherds_pie/2.gif\" alt=\"shepherds pie\"></td><td align=\"center\"><img src=\"samples/shepherds_pie/3.gif\" alt=\"shepherds pie\"></td></tr><tr><td align=\"center\">a bowl of vegetables</td><td align=\"center\"><img src=\"samples/a_bowl_of_vegetables/0.gif\" alt=\"a bowl of vegetables\"></td><td align=\"center\"><img src=\"samples/a_bowl_of_vegetables/1.gif\" alt=\"a bowl of vegetables\"></td><td align=\"center\"><img src=\"samples/a_bowl_of_vegetables/2.gif\" alt=\"a bowl of vegetables\"></td><td align=\"center\"><img src=\"samples/a_bowl_of_vegetables/3.gif\" alt=\"a bowl of vegetables\"></td></tr><tr><td align=\"center\">a cheeseburger</td><td align=\"center\"><img src=\"samples/a_cheeseburger/0.gif\" alt=\"a cheeseburger\"></td><td align=\"center\"><img src=\"samples/a_cheeseburger/1.gif\" alt=\"a cheeseburger\"></td><td align=\"center\"><img src=\"samples/a_cheeseburger/2.gif\" alt=\"a cheeseburger\"></td><td align=\"center\"><img src=\"samples/a_cheeseburger/3.gif\" alt=\"a cheeseburger\"></td></tr><tr><td align=\"center\">a plate of mushy green peas</td><td align=\"center\"><img src=\"samples/a_plate_of_mushy_green_peas/0.gif\" alt=\"a plate of mushy green peas\"></td><td align=\"center\"><img src=\"samples/a_plate_of_mushy_green_peas/1.gif\" alt=\"a plate of mushy green peas\"></td><td align=\"center\"><img src=\"samples/a_plate_of_mushy_green_peas/2.gif\" alt=\"a plate of mushy green peas\"></td><td align=\"center\"><img src=\"samples/a_plate_of_mushy_green_peas/3.gif\" alt=\"a plate of mushy green peas\"></td></tr><tr><td align=\"center\">a traffic cone</td><td align=\"center\"><img src=\"samples/a_traffic_cone/0.gif\" alt=\"a traffic cone\"></td><td align=\"center\"><img src=\"samples/a_traffic_cone/1.gif\" alt=\"a traffic cone\"></td><td align=\"center\"><img src=\"samples/a_traffic_cone/2.gif\" alt=\"a traffic cone\"></td><td align=\"center\"><img src=\"samples/a_traffic_cone/3.gif\" alt=\"a traffic cone\"></td></tr><tr><td align=\"center\">a car that looks like an avocado</td><td align=\"center\"><img src=\"samples/a_car_that_looks_like_an_avocado/0.gif\" alt=\"a car that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_car_that_looks_like_an_avocado/1.gif\" alt=\"a car that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_car_that_looks_like_an_avocado/2.gif\" alt=\"a car that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_car_that_looks_like_an_avocado/3.gif\" alt=\"a car that looks like an avocado\"></td></tr><tr><td align=\"center\">an airplane that looks like a banana</td><td align=\"center\"><img src=\"samples/an_airplane_that_looks_like_a_banana/0.gif\" alt=\"an airplane that looks like a banana\"></td><td align=\"center\"><img src=\"samples/an_airplane_that_looks_like_a_banana/1.gif\" alt=\"an airplane that looks like a banana\"></td><td align=\"center\"><img src=\"samples/an_airplane_that_looks_like_a_banana/2.gif\" alt=\"an airplane that looks like a banana\"></td><td align=\"center\"><img src=\"samples/an_airplane_that_looks_like_a_banana/3.gif\" alt=\"an airplane that looks like a banana\"></td></tr><tr><td align=\"center\">a stop sign</td><td align=\"center\"><img src=\"samples/a_stop_sign/0.gif\" alt=\"a stop sign\"></td><td align=\"center\"><img src=\"samples/a_stop_sign/1.gif\" alt=\"a stop sign\"></td><td align=\"center\"><img src=\"samples/a_stop_sign/2.gif\" alt=\"a stop sign\"></td><td align=\"center\"><img src=\"samples/a_stop_sign/3.gif\" alt=\"a stop sign\"></td></tr><tr><td align=\"center\">a spaceship</td><td align=\"center\"><img src=\"samples/a_spaceship/0.gif\" alt=\"a spaceship\"></td><td align=\"center\"><img src=\"samples/a_spaceship/1.gif\" alt=\"a spaceship\"></td><td align=\"center\"><img src=\"samples/a_spaceship/2.gif\" alt=\"a spaceship\"></td><td align=\"center\"><img src=\"samples/a_spaceship/3.gif\" alt=\"a spaceship\"></td></tr><tr><td align=\"center\">a race car</td><td align=\"center\"><img src=\"samples/a_race_car/0.gif\" alt=\"a race car\"></td><td align=\"center\"><img src=\"samples/a_race_car/1.gif\" alt=\"a race car\"></td><td align=\"center\"><img src=\"samples/a_race_car/2.gif\" alt=\"a race car\"></td><td align=\"center\"><img src=\"samples/a_race_car/3.gif\" alt=\"a race car\"></td></tr><tr><td align=\"center\">a schoolbus</td><td align=\"center\"><img src=\"samples/a_schoolbus/0.gif\" alt=\"a schoolbus\"></td><td align=\"center\"><img src=\"samples/a_schoolbus/1.gif\" alt=\"a schoolbus\"></td><td align=\"center\"><img src=\"samples/a_schoolbus/2.gif\" alt=\"a schoolbus\"></td><td align=\"center\"><img src=\"samples/a_schoolbus/3.gif\" alt=\"a schoolbus\"></td></tr><tr><td align=\"center\">a firetruck</td><td align=\"center\"><img src=\"samples/a_firetruck/0.gif\" alt=\"a firetruck\"></td><td align=\"center\"><img src=\"samples/a_firetruck/1.gif\" alt=\"a firetruck\"></td><td align=\"center\"><img src=\"samples/a_firetruck/2.gif\" alt=\"a firetruck\"></td><td align=\"center\"><img src=\"samples/a_firetruck/3.gif\" alt=\"a firetruck\"></td></tr><tr><td align=\"center\">a rusty old car</td><td align=\"center\"><img src=\"samples/a_rusty_old_car/0.gif\" alt=\"a rusty old car\"></td><td align=\"center\"><img src=\"samples/a_rusty_old_car/1.gif\" alt=\"a rusty old car\"></td><td align=\"center\"><img src=\"samples/a_rusty_old_car/2.gif\" alt=\"a rusty old car\"></td><td align=\"center\"><img src=\"samples/a_rusty_old_car/3.gif\" alt=\"a rusty old car\"></td></tr><tr><td align=\"center\">a fast car</td><td align=\"center\"><img src=\"samples/a_fast_car/0.gif\" alt=\"a fast car\"></td><td align=\"center\"><img src=\"samples/a_fast_car/1.gif\" alt=\"a fast car\"></td><td align=\"center\"><img src=\"samples/a_fast_car/2.gif\" alt=\"a fast car\"></td><td align=\"center\"><img src=\"samples/a_fast_car/3.gif\" alt=\"a fast car\"></td></tr><tr><td align=\"center\">a chair that looks like an avocado</td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_an_avocado/0.gif\" alt=\"a chair that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_an_avocado/1.gif\" alt=\"a chair that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_an_avocado/2.gif\" alt=\"a chair that looks like an avocado\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_an_avocado/3.gif\" alt=\"a chair that looks like an avocado\"></td></tr><tr><td align=\"center\">a chair that looks like fruit</td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_fruit/0.gif\" alt=\"a chair that looks like fruit\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_fruit/1.gif\" alt=\"a chair that looks like fruit\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_fruit/2.gif\" alt=\"a chair that looks like fruit\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_fruit/3.gif\" alt=\"a chair that looks like fruit\"></td></tr><tr><td align=\"center\">a chair that looks like a tree</td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_tree/0.gif\" alt=\"a chair that looks like a tree\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_tree/1.gif\" alt=\"a chair that looks like a tree\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_tree/2.gif\" alt=\"a chair that looks like a tree\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_tree/3.gif\" alt=\"a chair that looks like a tree\"></td></tr><tr><td align=\"center\">a chair that looks like a zebra</td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_zebra/0.gif\" alt=\"a chair that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_zebra/1.gif\" alt=\"a chair that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_zebra/2.gif\" alt=\"a chair that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_zebra/3.gif\" alt=\"a chair that looks like a zebra\"></td></tr><tr><td align=\"center\">a chair that looks like a swimming pool</td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_swimming_pool/0.gif\" alt=\"a chair that looks like a swimming pool\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_swimming_pool/1.gif\" alt=\"a chair that looks like a swimming pool\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_swimming_pool/2.gif\" alt=\"a chair that looks like a swimming pool\"></td><td align=\"center\"><img src=\"samples/a_chair_that_looks_like_a_swimming_pool/3.gif\" alt=\"a chair that looks like a swimming pool\"></td></tr><tr><td align=\"center\">the person is running</td><td align=\"center\"><img src=\"samples/the_person_is_running/0.gif\" alt=\"the person is running\"></td><td align=\"center\"><img src=\"samples/the_person_is_running/1.gif\" alt=\"the person is running\"></td><td align=\"center\"><img src=\"samples/the_person_is_running/2.gif\" alt=\"the person is running\"></td><td align=\"center\"><img src=\"samples/the_person_is_running/3.gif\" alt=\"the person is running\"></td></tr><tr><td align=\"center\">the person is sitting</td><td align=\"center\"><img src=\"samples/the_person_is_sitting/0.gif\" alt=\"the person is sitting\"></td><td align=\"center\"><img src=\"samples/the_person_is_sitting/1.gif\" alt=\"the person is sitting\"></td><td align=\"center\"><img src=\"samples/the_person_is_sitting/2.gif\" alt=\"the person is sitting\"></td><td align=\"center\"><img src=\"samples/the_person_is_sitting/3.gif\" alt=\"the person is sitting\"></td></tr><tr><td align=\"center\">the person is lying down</td><td align=\"center\"><img src=\"samples/the_person_is_lying_down/0.gif\" alt=\"the person is lying down\"></td><td align=\"center\"><img src=\"samples/the_person_is_lying_down/1.gif\" alt=\"the person is lying down\"></td><td align=\"center\"><img src=\"samples/the_person_is_lying_down/2.gif\" alt=\"the person is lying down\"></td><td align=\"center\"><img src=\"samples/the_person_is_lying_down/3.gif\" alt=\"the person is lying down\"></td></tr><tr><td align=\"center\">a person that looks like a zebra</td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_zebra/0.gif\" alt=\"a person that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_zebra/1.gif\" alt=\"a person that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_zebra/2.gif\" alt=\"a person that looks like a zebra\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_zebra/3.gif\" alt=\"a person that looks like a zebra\"></td></tr><tr><td align=\"center\">a person that looks like a leopard</td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_leopard/0.gif\" alt=\"a person that looks like a leopard\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_leopard/1.gif\" alt=\"a person that looks like a leopard\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_leopard/2.gif\" alt=\"a person that looks like a leopard\"></td><td align=\"center\"><img src=\"samples/a_person_that_looks_like_a_leopard/3.gif\" alt=\"a person that looks like a leopard\"></td></tr><tr><td align=\"center\">a pair of shorts</td><td align=\"center\"><img src=\"samples/a_pair_of_shorts/0.gif\" alt=\"a pair of shorts\"></td><td align=\"center\"><img src=\"samples/a_pair_of_shorts/1.gif\" alt=\"a pair of shorts\"></td><td align=\"center\"><img src=\"samples/a_pair_of_shorts/2.gif\" alt=\"a pair of shorts\"></td><td align=\"center\"><img src=\"samples/a_pair_of_shorts/3.gif\" alt=\"a pair of shorts\"></td></tr><tr><td align=\"center\">a designer dress</td><td align=\"center\"><img src=\"samples/a_designer_dress/0.gif\" alt=\"a designer dress\"></td><td align=\"center\"><img src=\"samples/a_designer_dress/1.gif\" alt=\"a designer dress\"></td><td align=\"center\"><img src=\"samples/a_designer_dress/2.gif\" alt=\"a designer dress\"></td><td align=\"center\"><img src=\"samples/a_designer_dress/3.gif\" alt=\"a designer dress\"></td></tr><tr><td align=\"center\">banana shoes</td><td align=\"center\"><img src=\"samples/banana_shoes/0.gif\" alt=\"banana shoes\"></td><td align=\"center\"><img src=\"samples/banana_shoes/1.gif\" alt=\"banana shoes\"></td><td align=\"center\"><img src=\"samples/banana_shoes/2.gif\" alt=\"banana shoes\"></td><td align=\"center\"><img src=\"samples/banana_shoes/3.gif\" alt=\"banana shoes\"></td></tr><tr><td align=\"center\">a green boot</td><td align=\"center\"><img src=\"samples/a_green_boot/0.gif\" alt=\"a green boot\"></td><td align=\"center\"><img src=\"samples/a_green_boot/1.gif\" alt=\"a green boot\"></td><td align=\"center\"><img src=\"samples/a_green_boot/2.gif\" alt=\"a green boot\"></td><td align=\"center\"><img src=\"samples/a_green_boot/3.gif\" alt=\"a green boot\"></td></tr><tr><td align=\"center\">a pair of sunglasses</td><td align=\"center\"><img src=\"samples/a_pair_of_sunglasses/0.gif\" alt=\"a pair of sunglasses\"></td><td align=\"center\"><img src=\"samples/a_pair_of_sunglasses/1.gif\" alt=\"a pair of sunglasses\"></td><td align=\"center\"><img src=\"samples/a_pair_of_sunglasses/2.gif\" alt=\"a pair of sunglasses\"></td><td align=\"center\"><img src=\"samples/a_pair_of_sunglasses/3.gif\" alt=\"a pair of sunglasses\"></td></tr></tbody></table>\n\n"
        },
        {
          "name": "samples",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.7822265625,
          "content": "from setuptools import setup\n\nsetup(\n    name=\"shap-e\",\n    packages=[\n        \"shap_e\",\n        \"shap_e.diffusion\",\n        \"shap_e.models\",\n        \"shap_e.models.generation\",\n        \"shap_e.models.nerf\",\n        \"shap_e.models.nerstf\",\n        \"shap_e.models.nn\",\n        \"shap_e.models.stf\",\n        \"shap_e.models.transmitter\",\n        \"shap_e.rendering\",\n        \"shap_e.rendering.blender\",\n        \"shap_e.rendering.raycast\",\n        \"shap_e.util\",\n    ],\n    install_requires=[\n        \"filelock\",\n        \"Pillow\",\n        \"torch\",\n        \"fire\",\n        \"humanize\",\n        \"requests\",\n        \"tqdm\",\n        \"matplotlib\",\n        \"scikit-image\",\n        \"scipy\",\n        \"numpy\",\n        \"blobfile\",\n        \"clip @ git+https://github.com/openai/CLIP.git\",\n    ],\n    author=\"OpenAI\",\n)\n"
        },
        {
          "name": "shap_e",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}