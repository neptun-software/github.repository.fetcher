{
  "metadata": {
    "timestamp": 1736561254587,
    "page": 247,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "scipy/scipy",
      "stars": 13272,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".cirrus.star",
          "type": "blob",
          "size": 1.85546875,
          "content": "# The guide to programming cirrus-ci tasks using starlark is found at\n# https://cirrus-ci.org/guide/programming-tasks/\n#\n# In this simple starlark script we simply check conditions for whether\n# a CI run should go ahead. If the conditions are met, then we just\n# return the yaml containing the tasks to be run.\n\nload(\"cirrus\", \"env\", \"fs\", \"http\")\n\ndef main(ctx):\n    ######################################################################\n    # Should wheels be built?\n    # Only test on the scipy/scipy repository\n    # Test if the run was triggered by:\n    # - a cron job called \"nightly\". The cron job is not set in this file,\n    #   but on the cirrus-ci repo page\n    # - commit message containing [wheel build]\n    ######################################################################\n\n    if env.get(\"CIRRUS_REPO_FULL_NAME\") != \"scipy/scipy\":\n        return []\n\n    if env.get(\"CIRRUS_CRON\", \"\") == \"nightly\":\n        return fs.read(\"ci/cirrus_wheels.yml\")\n\n    # Obtain commit message for the event. Unfortunately CIRRUS_CHANGE_MESSAGE\n    # only contains the actual commit message on a non-PR trigger event.\n    # For a PR event it contains the PR title and description.\n    SHA = env.get(\"CIRRUS_CHANGE_IN_REPO\")\n    url = \"https://api.github.com/repos/scipy/scipy/git/commits/\" + SHA\n    dct = http.get(url).json()\n    if \"[wheel build]\" in dct[\"message\"]:\n        return fs.read(\"ci/cirrus_wheels.yml\")\n\n    # this configuration runs a single linux_aarch64 + macosx_arm64 run.\n    # there's no need to do this during a wheel run as they automatically build\n    # and test over a wider range of Pythons.\n    PR = int(env.get(\"CIRRUS_PR\", -1))\n    if PR < 0:\n        return []\n\n    if \"[skip cirrus]\" in dct[\"message\"] or \"[skip ci]\" in dct[\"message\"] or \"[lint only]\" in dct[\"message\"] or \"[docs only]\" in dct[\"message\"]:\n        return []\n\n    return fs.read(\"ci/cirrus_general_ci.yml\")\n"
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.1181640625,
          "content": "[run]\nbranch = True\ninclude = */scipy/*\nomit =\n    scipy/signal/_max_len_seq_inner.py\ndisable_warnings = include-ignored\n"
        },
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 1.6396484375,
          "content": "# Adopt ruff linter and \"lint everything\" (gh-17878)\n6c4a3f3551f9ee52a75c8c3999a57bed8ea67deb\n# Whitespace clean up in stats (gh-17892)\n076710d528273563048c2b05bb3ad2f8b03fdb95\n# Cython lint\nc1c91d3933291046c72a8e1569c0c4703a51ba45\n# Release entries move\nb9cb3d075dad2b1ee9c145f9e69192d6eeda4f1e\n# Rename `fft/tests/test_numpy.py` to `test_basic.py`\n79099da5aefd2f76092b999823e45a6519e41005\n# Line length clean up in misc (gh-19491)\n8870c5d01a6f91a737db4642343ef997a63c8584\n# Line length clean up in fftpack (gh-19503)\n39787f146137b0ec9d31907989c6f104ba7eed76\n# Line length clean up in `scipyoptdoc.py` (gh-19505)\n49858c5fb2bf479b17a0bf42a7397d73f45f1b31\n# Line length clean up in odr (gh-19514)\n877f1cc34ad2147340684bcadfbf884d47f5a954\n# Line length clean up in fft (gh-19520)\n9d41d85c472438cf17211b843de7c770868d25a4\n# Blanket noqa clean up (gh-19529)\n664a42c9a7945a0a47f876baa6d27fb4c31c6847\n# Unused noqa clean up (gh-19529)\n05b872da4f498d923dbf5f5f38691b9a21580914\n# Clean up for UP lint rules (gh-19516)\n9cf72e4599e0a22902ef3bc1a42e645240b1734d\n# Clean up for B028 lint rule (gh-19623)\n81662226aac5c6b978825b381d2793b16d3b354f\n# Clean up for enabling line length check (gh-19609)\nfa9f13e6906e7d00510d593f7f982db30e4e4f14\n# Using clang-format with `special` C++ files (gh-19613)\necef3490da68a0c53ba543c618bab0c8e15dccee\n# Change to indent width of 4 in clang-format (gh-19660)\n852776a3fe0f3d08c0bed9174f6ac33f653a8677\n# Style cleanup in `pyproject.toml`\n7b921fd28659b02544bfb46368ddadd1048b37aa\n# Style cleanup to always `import numpy as np`\nceafa8e730887b81cf10d483ce375559ebd1de09\n# Clean-up for UP031, UP032 lint rules (gh-21029)\nd1b5af016e907e037136b7a38e485437165490f2\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.84375,
          "content": "# Excluding files from an sdist generated by meson-python\n#########################################################\n\n# Note: when adding to this list, be aware that you need to commit your changes\n# before they take effect (can be confusing during testing)\n.circleci/* export-ignore\n.github/* export-ignore\nci/* export-ignore\n.coveragerc export-ignore\n.git* export-ignore\n*.yml export-ignore\n*.yaml export-ignore\n.mailmap export-ignore\n\n\n# Dealing with line endings\n###########################\n\n* text=auto\n\n# Don't want to convert line endings of this file, causes test failure on\n# Windows\nscipy/io/matlab/tests/data/japanese_utf8.txt binary\n\n# Numerical data files\nscipy/special/tests/data/*.txt binary\nscipy/special/tests/data/*/*.txt binary\nscipy/special/tests/data/*/*/*.txt binary\n\n# Release notes, reduce number of conflicts.\ndoc/release/*.rst merge=union\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 7.3935546875,
          "content": "# Editor temporary/working/backup files #\n#########################################\n.#*\n[#]*#\n*~\n*$\n*.bak\n.idea/\n*.kdev4\n*.org\n.project\n.pydevproject\n*.rej\n.settings/\n.spyproject/\n.*.sw[nop]\n.sw[nop]\n*.tmp\n*.vim\ntags\n.venv/\nvenv/\n.theia/\n.vscode/\n\n# Compiled source #\n###################\n*.a\n*.com\n*.class\n*.dll\n*.exe\n*.l[ao]\n*.o\n*.o.d\n*.py[ocd]\n*.so\n_configtest.c\n\n# Packages #\n############\n# it's better to unpack these files and commit the raw source\n# git has its own built in compression methods\n*.7z\n*.bz2\n*.bzip2\n*.dmg\n*.gz\n*.iso\n*.jar\n*.rar\n*.tar\n*.tbz2\n*.tgz\n*.zip\n\n# Python files #\n################\n# build directory\nbuild\n# sphinx build directory\ndoc/_build\n# cython files\ncythonize.dat\n# sdist directory\ndist\n# Egg metadata\n*.egg-info\n# tox testing tool\n.tox\n# The shelf plugin uses this dir\n./.shelf\nMANIFEST\n# distutils configuration\nsite.cfg\nsetup.cfg\n# other temporary files\n.coverage\n.deps\n.libs\n.eggs\npip-wheel-metadata\n\n# Meson #\n#########\n.mesonpy-native-file.ini\ninstalldir/\nbuild-install/\n.mesonpy/\n\n# doit\n######\n.doit.db.dat\n.doit.db.dir\n.doit.db.db\n.doit.db\ndoc/source/.jupyterlite.doit.db\n\n# Logs and databases #\n######################\n*.log\n*.sql\n*.sqlite\n\n# pytest cache #\n################\n.cache/\n.pytest_cache/\n\n# GitHub cache #\n################\ngh_cache.json\n\n# mypy cache #\n##############\n.mypy_cache/\n\n# linter #\n##########\n.ruff_cache/\n.pre-commit-workdir/\n\n# Patches #\n###########\n*.patch\n*.diff\n\n# OS generated files #\n######################\n.directory\n.fseventsd\n.DS_Store*\n.gdb_history\n.VolumeIcon.icns\nehthumbs.db\nIcon?\nThumbs.db\n*.dSYM\n\n# Documentation generated files #\n#################################\ndoc/frontpage/build\ndoc/source/reference/generated\n**/.ipynb_checkpoints\ndoc/source/_contents\n\n# Things specific to this project #\n###################################\nbenchmarks/env\nbenchmarks/results\nbenchmarks/scipy\nbenchmarks/html\nbenchmarks/scipy-benchmarks\n.github/workflows/.pixi\n.openblas\nscipy/_distributor_init_local.py\nscipy/__config__.py\nscipy/_lib/_ccallback_c.c\nscipy/_lib/messagestream.c\nscipy/_lib/src/messagestream_config.h\nscipy/_lib/_test_deprecation_call.c\nscipy/_lib/_test_deprecation_def.c\nscipy/_lib/_test_deprecation_def.h\nscipy/cluster/_vq.c\nscipy/cluster/_hierarchy.c\nscipy/cluster/_optimal_leaf_ordering.c\nscipy/fftpack/_fftpackmodule.c\nscipy/fftpack/convolvemodule.c\nscipy/fftpack/convolve.c\nscipy/fftpack/src/dct.c\nscipy/fftpack/src/dst.c\nscipy/integrate/_dopmodule.c\nscipy/integrate/_lsodamodule.c\nscipy/integrate/_vodemodule.c\nscipy/integrate/_dop-f2pywrappers.f\nscipy/integrate/_lsoda-f2pywrappers.f\nscipy/integrate/_vode-f2pywrappers.f\nscipy/interpolate/_rbfinterp_pythran.cpp\nscipy/interpolate/_ppoly.c\nscipy/interpolate/_rgi_cython.c\nscipy/interpolate/_bspl.c\nscipy/interpolate/interpnd.c\nscipy/interpolate/src/dfitpack-f2pywrappers.f\nscipy/interpolate/src/dfitpackmodule.c\nscipy/io/_test_fortranmodule.c\nscipy/io/matlab/_mio5_utils.c\nscipy/io/matlab/_mio_utils.c\nscipy/io/matlab/_streams.c\nscipy/lib/blas/cblas.pyf\nscipy/lib/blas/cblasmodule.c\nscipy/lib/blas/fblas-f2pywrappers.f\nscipy/lib/blas/fblas.pyf\nscipy/lib/blas/fblasmodule.c\nscipy/lib/blas/fblaswrap.f\nscipy/lib/lapack/clapack.pyf\nscipy/lib/lapack/clapackmodule.c\nscipy/lib/lapack/flapack.pyf\nscipy/lib/lapack/flapackmodule.c\nscipy/linalg/_cblasmodule.c\nscipy/linalg/_clapackmodule.c\nscipy/linalg/_fblas-f2pywrappers.f\nscipy/linalg/_fblasmodule.c\nscipy/linalg/_flapack-f2pywrappers.f\nscipy/linalg/_flapackmodule.c\nscipy/linalg/_interpolativemodule.c\nscipy/linalg/_solve_toeplitz.c\nscipy/linalg/_decomp_update.c\nscipy/linalg/_decomp_update.pyx\nscipy/linalg/_cythonized_array_utils.c\nscipy/linalg/_blas_subroutine_wrappers.f\nscipy/linalg/_blas_subroutines.h\nscipy/linalg/_lapack_subroutine_wrappers.f\nscipy/linalg/_lapack_subroutines.h\nscipy/linalg/cblas.pyf\nscipy/linalg/clapack.pyf\nscipy/linalg/cython_blas.c\nscipy/linalg/cython_lapack.c\nscipy/linalg/fblas.pyf\nscipy/linalg/flapack.pyf\nscipy/linalg/cython_blas.pxd\nscipy/linalg/cython_blas.pyx\nscipy/linalg/cython_lapack.pxd\nscipy/linalg/cython_lapack.pyx\nscipy/linalg/src/id_dist/src/*_subr_*.f\nscipy/linalg/_matfuncs_sqrtm_triu.c\nscipy/linalg/_matfuncs_sqrtm_triu.cpp\nscipy/ndimage/src/_ni_label.c\nscipy/ndimage/src/_cytest.c\nscipy/optimize/_bglu_dense.c\nscipy/optimize/cobyla/_cobylamodule.c\nscipy/optimize/_group_columns.cpp\nscipy/optimize/lbfgsb_src/_lbfgsbmodule.c\nscipy/optimize/lbfgsb_src/_lbfgsb-f2pywrappers.f\nscipy/optimize/__nnls/__nnlsmodule.c\nscipy/optimize/slsqp/_slsqpmodule.c\nscipy/optimize/_lsq/givens_elimination.c\nscipy/optimize/_trlib/_trlib.c\nscipy/optimize/tnc/moduleTNC.c\nscipy/optimize/tnc/_moduleTNC.c\nscipy/signal/_peak_finding_utils.c\nscipy/signal/_max_len_seq_inner.c\nscipy/signal/_max_len_seq_inner.cpp\nscipy/signal/_sosfilt.c\nscipy/signal/_upfirdn_apply.c\nscipy/signal/_correlate_nd.c\nscipy/signal/_lfilter.c\nscipy/signal/_bspline_util.c\nscipy/sparse/_csparsetools.c\nscipy/sparse/_csparsetools.pyx\nscipy/sparse/csgraph/_min_spanning_tree.c\nscipy/sparse/csgraph/_shortest_path.cxx\nscipy/sparse/csgraph/_tools.c\nscipy/sparse/csgraph/_traversal.c\nscipy/sparse/csgraph/_flow.c\nscipy/sparse/csgraph/_matching.c\nscipy/sparse/csgraph/_reordering.c\nscipy/sparse/linalg/dsolve/umfpack/_umfpack.py\nscipy/sparse/linalg/dsolve/umfpack/_umfpack_wrap.c\nscipy/sparse/linalg/_eigen/arpack/_arpack-f2pywrappers.f\nscipy/sparse/linalg/_eigen/arpack/_arpackmodule.c\nscipy/sparse/linalg/_eigen/arpack/arpack.pyf\nscipy/sparse/linalg/_isolve/iterative/BiCGREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/BiCGSTABREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/CGREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/CGSREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/GMRESREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/QMRREVCOM.f\nscipy/sparse/linalg/_isolve/iterative/STOPTEST2.f\nscipy/sparse/linalg/_isolve/iterative/_iterative.pyf\nscipy/sparse/linalg/_isolve/iterative/_iterativemodule.c\nscipy/sparse/linalg/_isolve/iterative/getbreak.f\nscipy/sparse/sparsetools/bsr_impl.h\nscipy/sparse/sparsetools/csc_impl.h\nscipy/sparse/sparsetools/csr_impl.h\nscipy/sparse/sparsetools/other_impl.h\nscipy/sparse/sparsetools/sparsetools_impl.h\nscipy/spatial/_ckdtree.cxx\nscipy/spatial/ckdtree.h\nscipy/spatial/_hausdorff.c\nscipy/spatial/_qhull.c\nscipy/spatial/_voronoi.c\nscipy/spatial/transform/_rotation.c\nscipy/special/_comb.c\nscipy/special/_ellip_harm_2.c\nscipy/special/_ellip_harm_2.h\nscipy/special/_logit.c\nscipy/special/_test_internal.c\nscipy/special/_ufuncs.c\nscipy/special/_ufuncs.h\nscipy/special/_ufuncs.pyx\nscipy/special/_ufuncs_cxx.cxx\nscipy/special/_ufuncs_cxx.h\nscipy/special/_ufuncs_cxx.pxd\nscipy/special/_ufuncs_cxx.pyx\nscipy/special/_ufuncs_cxx_defs.h\nscipy/special/_ufuncs_defs.h\nscipy/special/cython_special.c\nscipy/special/cython_special.h\nscipy/special/_specfunmodule.c\nscipy/special/tests/data/*.npz\nscipy/special/ellint_carlson_cpp_lite/Makefile\nscipy/special/ellint_carlson_cpp_lite/cellint.*\nscipy/special/ellint_carlson_cpp_lite/tests\nscipy/stats/_rank.c\nscipy/stats/_mvn-f2pywrappers.f\nscipy/stats/_mvnmodule.c\nscipy/stats/_statlibmodule.c\nscipy/stats/vonmises_cython.c\nscipy/stats/_stats.c\nscipy/stats/_levy_stable/levyst.c\nscipy/stats/_biasedurn.cxx\nscipy/stats/_biasedurn.pyx\nscipy/stats/biasedurn.cxx\nscipy/stats/_sobol.c\nscipy/stats/_qmc_cy.cxx\nscipy/stats/_hypotests_pythran.cpp\nscipy/stats/_unuran/unuran_wrapper.c\nscipy/stats/_rcont/rcont.c\nscipy/stats/_stats_pythran.cpp\nscipy/version.py\nscipy/special/_exprel.c\nscipy/optimize/_group_columns.c\nscipy/optimize/cython_optimize/_zeros.c\nscipy/optimize/cython_optimize/_zeros.pyx\nscipy/optimize/lbfgsb/_lbfgsbmodule.c\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.2958984375,
          "content": "[submodule \"doc/source/_static/scipy-mathjax\"]\n\tpath = doc/source/_static/scipy-mathjax\n\turl = https://github.com/scipy/scipy-mathjax.git\n[submodule \"scipy/sparse/linalg/_propack/PROPACK\"]\n\tpath = scipy/sparse/linalg/_propack/PROPACK\n\turl = https://github.com/scipy/PROPACK.git\n\tshallow = true\n[submodule \"scipy/_lib/unuran\"]\n\tpath = scipy/_lib/unuran\n\turl = https://github.com/scipy/unuran.git\n\tshallow = true\n[submodule \"scipy/_lib/boost_math\"]\n\tpath = scipy/_lib/boost_math\n\turl = https://github.com/boostorg/math.git\n\tshallow = true\n[submodule \"scipy/_lib/array_api_compat\"]\n\tpath = scipy/_lib/array_api_compat\n\turl = https://github.com/data-apis/array-api-compat.git\n[submodule \"scipy/_lib/pocketfft\"]\n\tpath = scipy/_lib/pocketfft\n\turl = https://github.com/scipy/pocketfft\n[submodule \"scipy/_lib/cobyqa\"]\n\tpath = scipy/_lib/cobyqa\n\turl = https://github.com/cobyqa/cobyqa.git\n[submodule \"scipy/_lib/array_api_extra\"]\n\tpath = scipy/_lib/array_api_extra\n\turl = https://github.com/data-apis/array-api-extra.git\n# All submodules used as a Meson `subproject` are required to be under the\n# subprojects/ directory - see:\n# https://mesonbuild.com/Subprojects.html#why-must-all-subprojects-be-inside-a-single-directory\n[submodule \"subprojects/highs\"]\n\tpath = subprojects/highs\n\turl = https://github.com/scipy/HiGHs\n\tshallow = true\n"
        },
        {
          "name": ".mailmap",
          "type": "blob",
          "size": 42.3134765625,
          "content": "#\n# Canonical author name mapping for git and tools/authors.py, in format:\n#\n#     Canonical Name <canonical.email@somewhere> Alias Name <alias.email@somewhere>\n#\n# The email address parts should match what is in git log. The tools/authors.py does\n# not care about them, so it is possible to leave the email part empty, but in this\n# case git commands won't recognize the alias.\n#\n# This file is up-to-date if the command git log --format=\"%aN <%aE>\" | sort -u\n# does not list the same person multiple times.\n#\n@awakenting <awakenting@users.noreply.github.com> awakenting <awakenting@users.noreply.github.com>\n@axiru <axiru@users.noreply.gihub.com> axiru <axiru@users.noreply.gihub.com>\n@cel4 <cel4@users.noreply.github.com> cel4 <cel4@users.noreply.github.com>\n@chemelnucfin <aw@sp3.com> aw <aw@sp3.com>\n@endolith <endolith@gmail.com> Endolith <endolith@gmail.com>\n@endolith <endolith@gmail.com> endolith <endolith@gmail.com>\n@FormerPhysicist <Former@physicist.net> FormerPhysicist <Former@physicist.net>\n@gaulinmp <gaulinmp+git@gmail.com> Mac <gaulinmp+git@gmail.com>\n@h-vetinari <h.vetinari@gmx.com> h-vetinari <h.vetinari@gmx.com>\n@h-vetinari <h.vetinari@gmx.com> H. Vetinari <h.vetinari@gmx.com>\n@ksemb <ksms@gmx.de> ksemb <ksms@gmx.de>\n@kshitij12345 <kshitijkalambarkar@gmail.com> kshitij12345 <kshitijkalambarkar@gmail.com>\n@luzpaz <luzpaz@users.noreply.github.com> Unknown <kunda@scribus.net>\n@luzpaz <luzpaz@users.noreply.github.com> luz.paz <luzpaz@users.noreply.github.com>\n@luzpaz <luzpaz@users.noreply.github.com> luzpaz <luzpaz@users.noreply.github.com>\n@mamrehn <mamrehn@users.noreply.github.com> mamrehn <mamrehn@users.noreply.github.com>\n@NKrvavica <35114994+NKrvavica@users.noreply.github.com> NKrvavica <35114994+NKrvavica@users.noreply.github.com>\n@rafalalgo <rafal.byczek@student.uj.edu.pl> rafalalgo <rafal.byczek@student.uj.edu.pl>\n@samyak0210 <30871632+samyak0210@users.noreply.github.com> samyak0210 <30871632+samyak0210@users.noreply.github.com>\n@soluwalana <soluwalana@gmail.com> Sam O <soluwalana@gmail.com>\n@sudheerachary <sudheerachary115@gmail.com> sudheer <sudheerachary115@gmail.com>\n@Tokixix <mateusztok@gmail.com> Mateusz <mateusztok@gmail.com>\n@Tokixix <mateusztok@gmail.com> Tokixix <mateusztok@gmail.com>\n@tttthomasssss <th0mas.ko6er@gmail.com> Thomas <th0mas.ko6er@gmail.com>\n@vkk800 <vkk800@users.noreply.github.com> vkk800 <vkk800@users.noreply.github.com>\n@wirew0rm <wirew0rm@users.noreply.github.com> wirew0rm <wirew0rm@users.noreply.github.com>\n@xoviat <xoviat@users.noreply.github.com> xoviat <xoviat@users.noreply.github.com>\n@yanxun827 <yanxun827@gmail.com> yanxun827 <yanxun827@gmail.com>\n@ybeltukov <ybeltukov@gmail.com> ybeltukov <ybeltukov@gmail.com>\n@ziejcow <jan.gwinner@gmail.com>ziejcow <jan.gwinner@gmail.com>\nADmitri <admitri42@gmail.com> ADmitri <ADmitri42@gmail.com>\nAditya Karumanchi <karumanchi.1@osu.edu> AdityaKarumanchi <karumanchi.1@osu.edu>\nAditya Vijaykumar <vijaykumar.aditya@gmail.com> adivijaykumar <vijaykumar.aditya@gmail.com>\nAkash Goel <goelakas@amazon.com> Goel <goelakas@amazon.com>\nAlbert Steppi <albert_steppi@hms.harvard.edu> steppi <albert_steppi@hms.harvard.edu>\nAldrian Obaja <> ubuntu <>\nAlex Griffing <argriffi@ncsu.edu> alex <argriffi@ncsu.edu>\nAlex Griffing <argriffi@ncsu.edu> argriffing <argriffing@gmail.com>\nAlex Griffing <argriffi@ncsu.edu> argriffing <argriffing@users.noreply.github.com>\nAlvaro Sanchez-Gonzalez <sanchezgnzlz.alvaro@gmail.com> alvarosg <sanchezgnzlz.alvaro@gmail.com>\nAman Pratik <amanpratik10@gmail.com> amanp10 <amanpratik10@gmail.com>\nAman Singh <bewithaman@outlook.com> bewithaman <bewithaman@outlook.com>\nAman Thakral <aman.thakral@gmail.com> aman-thakral <aman.thakral@gmail.com>\nAmato Kasahara <thisisdummy@example.com> kshramt <thisisdummy@example.com>\nAnany Shrey Jain <31594632+ananyashreyjain@users.noreply.github.com> ananyashreyjain <31594632+ananyashreyjain@users.noreply.github.com>\nAnders Bech Borchersen <anb@es.aau.dk> andbo <anb@es.aau.dk>\nAnirudh Dagar <anirudhdagar6@gmail.com> Anirudh <anirudhdagar6@gmail.com>\nAndreas Hilboll <andreas@hilboll.de> Andreas H <andreas@hilboll.de>\nAndreas Hilboll <andreas@hilboll.de> Andreas Hilboll <andreas-h@users.noreply.github.com>\nAnreas Weh <andreas.weh@web.de> DerWeh <andreas.weh@web.de>\nAndreea Georgescu <ageorgescu@ucla.edu> Andreea_G <ageorgescu@ucla.edu>\nAndriy Gelman <andriy.gelman@gmail.com> talih0 <andriy.gelman@gmail.com>\nAndrew Fowlie <andrew.j.fowlie@googlemail.com> andrew <andrew.j.fowlie@googlemail.com>\nAndrew Fowlie <andrew.j.fowlie@googlemail.com> Andrew Fowlie <andrewfowlie@users.noreply.github.com>\nAndrew Knyazev <42650045+lobpcg@users.noreply.github.com> lobpcg <42650045+lobpcg@users.noreply.github.com>\nAndrew Knyazev <42650045+lobpcg@users.noreply.github.com> Andrew Knyazev <andrew.knyazev@ucdenver.edu>\nAndrew Knyazev <42650045+lobpcg@users.noreply.github.com> Andrew Knyazev, Professor Emeritus <andrew.knyazev@ucdenver.edu>\nAndrew Nelson <andyfaff@gmail.com> Andrew Nelson <andrew@Andrews-MacBook-Pro.local>\nAndrew Nelson <andyfaff@gmail.com> Andrew Nelson <anz@d121131.ncnr.nist.gov>\nAndrew Sczesnak <andrewscz@gmail.com> polyatail <andrewscz@gmail.com>\nAngeline G. Burrell <angeline.burrell@nrl.navy.mil> Angeline Burrell <aburrell@users.noreply.github.com>\nAngeline G. Burrell <angeline.burrell@nrl.navy.mil> Angeline Burrell <angeline.burrell@nrl.navy.mil>\nAnne Archibald <peridot.faceted@gmail.com> aarchiba <peridot.faceted@gmail.com>\nAnne Archibald <peridot.faceted@gmail.com> Anne Archibald <archibald@astron.nl>\nAntonio Horta Ribeiro <antonior92@gmail.com> antonio <antonior92@gmail.com>\nAntonio Horta Ribeiro <antonior92@gmail.com> Antonio H Ribeiro <antonior92@gmail.com>\nAnushka Suyal <126159239+anushkasuyal@users.noreply.github.com> anushkasuyal <anushkasuyal@hotmail.com>\nAriel Rokem <arokem@gmail.com> ariel.rokem <ariel.rokem@localhost>\nArnaud Baguet <107650207+quantresearch1@users.noreply.github.com> quantresearch1 <107650207+quantresearch1@users.noreply.github.com>\nArno Marty <arno.marty@etu.u-bordeaux.fr> korneix <arno.marty@etu.u-bordeaux.fr>\nArno Onken <arno.onken@iit.it> Arno Onken <asnelt@users.noreply.github.com>\nArthur Volant <arthurvolant@gmail.com> Arthur <37664438+V0lantis@users.noreply.github.com>\nAshwin Pathak <ashwinpathak20nov1996@gmail.com> ashwinpathak20 <ashwinpathak20nov1996@gmail.com>\nAshwin Pathak <ashwinpathak20nov1996@gmail.com> ashwinpathak20nov1996 <ashwinpathak20nov1996@gmail.com>\nAtaf Fazledin Ahamed <rabidahamed@gmail.com> fazledyn <rabidahamed@gmail.com>\nAtsushi Sakai <asakai.amsl+github@gmail.com> Atsushi Sakai <example@co.jp>\nAviv Yaish <aviv.yaish@mail.huji.ac.il> Aviv <aviv.yaish@mail.huji.ac.il>\nBalint Pato <balintp@google.com> balopat <balintp@google.com>\nBehzad Nouri <behzadnouri@gmail.com> behzad nouri <behzadnouri@gmail.com>\nBen Beasley <code@musicinmybrain.net> Benjamin A. Beasley <code@musicinmybrain.net>\nBenjamin Root <> weathergod <>\nBenjamin Santos <caos21@users.noreply.github.com> Benjamin <caos21@users.noreply.github.com>\nBenny Malengier <benny.malengier@gmail.com> Benny <benny.malengier@gmail.com>\nBenoît Wygas <97663334+bewygs@users.noreply.github.com> bewygs <97663334+bewygs@users.noreply.github.com>\nBerkay Antmen <berkay.antmen@shopify.com> bantmen <berkay.antmen@shopify.com>\nBharat Raghunathan <bharatraghunthan9767@gmail.com> Bharat123rox <bharatraghunthan9767@gmail.com>\nBharat Raghunathan <bharatraghunthan9767@gmail.com> Bharat123Rox <bharatraghunthan9767@gmail.com>\nBhavika Tekwani <bhavicka.7992@gmail.com> bhavikat <bhavicka.7992@gmail.com>\nBlair Azzopardi <blairuk@gmail.com> bsdz <blairuk@gmail.com>\nBlair Azzopardi <blairuk@gmail.com> Blair Azzopardi <bsdz@users.noreply.github.com>\nBoyu Liu <114795525+qqwqqw689@users.noreply.github.com> qqwqqw689 <114795525+qqwqqw689@users.noreply.github.com>\nBrandon David <brandon.david@zoho.com> brandondavid <brandon.david@zoho.com>\nBrett Graham <brettgraham@gmail.com> Brett <brettgraham@gmail.com>\nBrett R. Murphy <bmurphy@enthought.com> brettrmurphy <bmurphy@enthought.com>\nBrian Hawthorne <brian.hawthorne@localhost> brian.hawthorne <brian.hawthorne@localhost>\nBrian Newsom <brian.newsom@colorado.edu> Brian Newsom <Brian.Newsom@Colorado.edu>\nCaio Agiani <agianicaio@gmail.com> caioagiani <agianicaio@gmail.com>\nCallum Jacob Hays <callumjhays@gmail.com> callumJHays <callumjhays@gmail.com>\nCarlos Ramos Carreño <vnmabus@gmail.com> vnmabus <vnmabus@gmail.com>\nCharles Jekel <cjekel@gmail.com> cjekel <cjekel@gmail.com>\nCharles Masson <charles.masson@datadoghq.com> charlesmasson <charles.masson@datadoghq.com>\nChelsea Liu <chelsea.liu@datadoghq.com> Chelsea <chelsea.liu@datadoghq.com>\nChelsea Liu <chelsea.liu@datadoghq.com> chelsea.l <chelsea.liu@datadoghq.com>\nChris Burns <chris.burns@localhost> chris.burns <chris.burns@localhost>\nChristoph Hohnerlein <mail@chohner.com> chohner <mail@chohner.com>\nChris Lasher <> gotgenes <>\nChristian Clauss <cclauss@me.com> cclauss <cclauss@me.com>\nChristoph Baumgarten <christoph.baumgarten@gmail.com> chrisb83 <33071866+chrisb83@users.noreply.github.com>\nChristoph Baumgarten <christoph.baumgarten@gmail.com> chrisb83 <christoph.baumgarten@gmail.com>\nChristoph Baumgarten <christoph.baumgarten@gmail.com> Christoph Baumgarten <33071866+chrisb83@users.noreply.github.com>\nChristoph Baumgarten <christoph.baumgarten@gmail.com> baumgarc <christoph.baumgarten@gmail.com>\nChristoph Gohlke <cgohlke@uci.edu> cgohlke <cgohlke@uci.edu>\nChristoph Gohlke <cgohlke@uci.edu> Christolph Gohlke <>\nChristoph Gohlke <cgohlke@uci.edu> cgholke <>\nChristoph Gohlke <cgohlke@uci.edu> cgohlke <cjgohlke@gmail.com>\nChristoph Gohlke <cgohlke@uci.edu> Christoph Gohlke <cjgohlke@gmail.com>\nChristopher Kuster <ckuster@carrollu.edu> ckuster <ckuster@carrollu.edu>\nCJ Carey <perimosocordiae@gmail.com> CJ Carey <cjcarey@google.com>\nClemens Novak <clemens@familie-novak.net> cnovak <clemens@familie-novak.net>\nClemens Novak <clemens@familie-novak.net> Clemens <clemens@familie-novak.net>\nClemens Schmid <5190547+clemisch@users.noreply.github.com> clemisch <5190547+clemisch@users.noreply.github.com>\nCollin RM Stocks <> Collin Stocks <>\nCollin Tokheim <collintokheim@gmail.com> ctokheim <collintokheim@gmail.com>\nCong Ma <cong.ma@obspm.fr> Cong Ma <cong.ma@uct.ac.za>\nDaan Wynen <black.puppydog@gmx.de> Daan Wynen <black-puppydog@users.noreply.github.com>\nDamian Eads <damian.eads@localhost> damian.eads <damian.eads@localhost>\nDavid Ellis <ducksual@gmail.com> davidcellis <ducksual@gmail.com>\nDaniel Garcia <daniel.garcia@suse.com> danigm <daniel.garcia@suse.com>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel Smith <smith.daniel.br@gmail.com>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel Smith <smithd.daniel.br@gmail.com>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel Smith <smithd@daniel-laptop.(none)>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel B. Smith <Daniel.Smith.Br@gmail.com>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel B. Smith <neuromathdan@gmail.com>\nDaniel B. Smith <smith.daniel.br@gmail.com> Daniel <smith.daniel.br@gmail.com>\nDaniel Schmitz <danielschmitzsiegen@gmail.com> dschmitz89 <danielschmitzsiegen@gmail.com>\nDanilo Augusto <daniloaugusto.ita16@gmail.com> daniloagst <daniloaugusto.ita16@gmail.com>\nDanilo Horta <danilo.horta@gmail.com> Horta <danilo.horta@gmail.com>\nDavid Huard <dhuard@localhost> dhuard <dhuard@localhost>\nDavid Simcha <> dsimcha <>\nDavid M Cooke <> cookedm <>\nDavid Menéndez Hurtado <davidmenhur@gmail.com> Dapid <davidmenhur@gmail.com>\nDavid Menéndez Hurtado <davidmenhur@gmail.com> David Menéndez Hurtado <david.menendez.hurtado@scilifelab.se>\nDavid Menéndez Hurtado <davidmenhur@gmail.com> David Menendez Hurtado <davidmenhur@gmail.com>\nDavid Nicholson <nicholdav@gmail.com> NickleDave <nicholdav@gmail.com>\nDavid Warde-Farley <wardefar@iro.umontreal.ca> david.warde-farley <david.warde-farley@localhost>\nDeepak Kumar Gouda <deepakgouda1729@gmail.com> deepakgouda <deepakgouda1729@gmail.com>\nDenis Laxalde <denis@laxalde.org> Denis Laxalde <denis.laxalde@logilab.fr>\nDenis Laxalde <denis@laxalde.org> Denis Laxalde <denis.laxalde@mcgill.ca>\nDenis Laxalde <denis@laxalde.org> Denis Laxalde <denis@mail.laxalde.org>\nDerek Homeier <> Derek Homeir <>\nDerek Homeier <> Derek Homier <>\nDerrick Chambers <d-chambers@users.noreply.github.com> Derrick <d-chambers@users.noreply.github.com>\nDezmond Goff <goff.dezmond@gmail.com> Dezmond <goff.dezmond@gmail.com>\nDiana Sukhoverkhova <diana.suhoverhova@mail.ru> Diana <diana.suhoverhova@mail.ru>\nDieter Werthmüller <dieter@werthmuller.org> Dieter Werthmüller <mail@werthmuller.org>\nDieter Werthmüller <dieter@werthmuller.org> Dieter Werthmüller <prisae@users.noreply.github.com>\nDieter Werthmüller <dieter@werthmuller.org> prisae <dieter@werthmuller.org>\nDima Pasechnik <dimpase@gmail.com> Dima Pasechnik <dima@pasechnik.info>\nDmitrey Kroshko <dmitrey.kroshko@localhost> dmitrey.kroshko <dmitrey.kroshko@localhost>\nDomen Gorjup <domen_gorjup@hotmail.com> domengorjup <domen_gorjup@hotmail.com>\nDonnie Erb <55961724+derb12@users.noreply.github.com> derb12 <55961724+derb12@users.noreply.github.com>\nDowon Yi <akahard2dj@naver.com> Dowon <akahard2dj@naver.com>\nDávid Bodnár <david.bodnar@st.ovgu.de> bdvd <david.bodnar@st.ovgu.de>\nEd Schofield <edschofield@localhost> edschofield <edschofield@localhost>\nEgor Zemlyanoy <egorz734@mail.ru> egorz734 <egorz734@mail.ru>\nEgor Zemlyanoy <egorz734@mail.ru> Egorz734 <egorz734@mail.ru>\nEgor Zemlyanoy <egorz734@mail.ru> Egor <egorz734@mail.ru>\nEllie Litwack <ellie@PF2WXP6T.ad.bac.work> ellieLitwack <ellie@PF2WXP6T.ad.bac.work>\nEric Larson <larson.eric.d@gmail.com> Eric89GXL <larson.eric.d@gmail.com>\nEric Quintero <eric.antonio.quintero@gmail.com> e-q <eric.antonio.quintero@gmail.com>\nEric Quintero <eric.antonio.quintero@gmail.com> Eric Quintero <e-q@users.noreply.github.com>\nEric Soroos <eric-github@soroos.net> wiredfool <eric-github@soroos.net>\nÉtienne Tremblay <45673646+30blay@users.noreply.github.com> 30blay <45673646+30blay@users.noreply.github.com>\nEvandro <15084103+evbernardes@users.noreply.github.com> evbernardes <evbernardes@gmail.com>\nEvgeni Burovski <evgeny.burovskiy@gmail.com> Zhenya <evgeni@burovski.me>\nEvgeni Burovski <evgeny.burovskiy@gmail.com> Evgeni Burovski <evgeni@burovski.me>\nEvan W Jones <60061381+E-W-Jones@users.noreply.github.com> Evan <60061381+E-W-Jones@users.noreply.github.com>\nFabian Pedregosa <fabian@fseoane.net> Fabian Pedregosa <fabian.pedregosa@inria.fr>\nFabian Pedregosa <fabian@fseoane.net> Fabian Pedregosa <pedregosa@google.com>\nFabian Rost <fabian.rost@tu-dresden.de> Fabian Rost <fabrost@pks.mpg.de>\nFelix Berkenkamp <befelix@ethz.ch> Felix <befelix@ethz.ch>\nFelix Berkenkamp <befelix@ethz.ch> Felix Berkenkamp <fberkenkamp@gmail.com>\nFeras Saad <fsaad@cmu.edu> Feras A. Saad <fsaad@cmu.edu>\nFrederic Renner <frederic.renner@cern.ch> Fred-Renner <74908835+Fred-Renner@users.noreply.github.com>\nFlorian Wilhelm <Florian.Wilhelm@gmail.com> Florian Wilhelm <Florian.Wilhelm@blue-yonder.com>\nFrançois Boulogne <fboulogne sciunto org> François Boulogne <fboulogne at april dot org>\nFrançois Boulogne <fboulogne sciunto org> François Boulogne <fboulogne@sciunto.org>\nFrançois Boulogne <fboulogne sciunto org> François Boulogne <devel@sciunto.org>\nFrançois Magimel <magimel.francois@gmail.com> François Magimel <francois.magimel@etu.enseeiht.fr>\nFranz Forstmayr <forstmayr.franz@gmail.com> FranzForstmayr <franz.forstmayr@rosenberger.com>\nFranz Forstmayr <forstmayr.franz@gmail.com> FranzForstmayr <forstmayr.franz@gmail.com>\nFranz Forstmayr <forstmayr.franz@gmail.com> Franz Forstmayr <franz.forstmayr@rosenberger.com>\nFranz Forstmayr <forstmayr.franz@gmail.com> Franz <forstmayr.franz@gmail.com>\nFranziska Horn <cod3licious@users.noreply.github.com> cod3licious <cod3licious@users.noreply.github.com>\nFukumu Tsutsumi <levelfourslv@gmail.com> levelfour <levelfourslv@gmail.com>\nG Young <gfyoung17@gmail.com> gfyoung <gfyoung17@gmail.com>\nG Young <gfyoung17@gmail.com> gfyoung <gfyoung@mit.edu>\nGagandeep Singh <gdp.1807@gmail.com> czgdp1807 <gdp.1807@gmail.com>\nGanesh Kathiresan <ganesh3597@gmail.com> ganesh-k13 <ganesh3597@gmail.com>\nGarrett Reynolds <garrettreynolds5@gmail.com> Garrett-R <garrettreynolds5@gmail.com>\nGaël Varoquaux <gael.varoquaux@normalesup.org> Gael varoquaux <gael.varoquaux@normalesup.org>\nGavin Zhang <zhanggan@cn.ibm.com> GavinZhang <zhanggan@cn.ibm.com>\nGavin Zhang <zhanggan@cn.ibm.com> Gavin Zhang <zheddie@163.com>\nGeordie McBain <gdmcbain@protonmail.com> G. D. McBain <gdmcbain@protonmail.com>\nGang Zhao <zhaog6@lsec.cc.ac.cn> zhaog6 <31978442+zhaog6@users.noreply.github.com>\nGian Marco Messa <gianmarco.messa@gmail.com> messagian <gianmarco.messa@gmail.com>\nGideon Genadi Kogan <41887702+ggkogan@users.noreply.github.com> ggkogan <41887702+ggkogan@users.noreply.github.com>\nGina Helfrich <Dr-G@users.noreply.github.com> Gina <Dr-G@users.noreply.github.com>\nGiorgio Patrini <giorgio.patrini@anu.edu.au> giorgiop <giorgio.patrini@anu.edu.au>\nGiorgio Patrini <giorgio.patrini@anu.edu.au> giorgiop <giorgio.patrini@nicta.com.au>\nGregory R. Lee <grlee77@gmail.com> Gregory R. Lee <gregory.lee@cchmc.org>\nGregory R. Lee <grlee77@gmail.com> Gregory Lee <grlee77@gmail.com>\nGolnaz Irannejad <golnazirannejad@gmail.com> golnazir <golnazirannejad@gmail.com>\nGuillaume Horel <thrasibule@users.noreply.github.com> Thrasibule <thrasibule@users.noreply.github.com>\nGuo Fei <<guofei9987@foxmail.com> Guofei <<guofei9987@foxmail.com>\nGuus Kamphuis <guuskamphuis@gmail.com> ZoutigeWolf <guuskamphuis@gmail.com>\nHameer Abbasi <einstein.edison@gmail.com> Hameer Abbasi <hameerabbasi@yahoo.com>\nHan Genuit <> 87 <>\nHan Genuit <> Han <>\nHarshal Prakash Patankar <pharshalp@gmail.com> pharshalp <pharshalp@gmail.com>\nHervé Audren <h.audren@gmail.com> Herve Audren <h.audren@gmail.com>\nHeshy Roskes <heshyr@gmail.com> <hroskes@jhu.edu>\nHeshy Roskes <heshyr@gmail.com> <jroskes1@jhu.edu>\nHelder Cesar <heldercro@gmail.com> Helder <heldercro@gmail.com>\nHelmut Toplitzer <helmut.toplitzer@ait.ac.at> HelmutAIT <helmut.toplitzer@ait.ac.at>\nHenry Lin <hlin117@gmail.com> hlin117 <hlin117@gmail.com>\nHiroki IKEDA <ikeda_hiroki@icloud.com> IKEDA Hiroki <ikeda_hiroki@icloud.com>\nHugo van Kemenade <hugovk@users.noreply.github.com> Hugo <hugovk@users.noreply.github.com>\nHuize Wang <huizew@gmail.com> Huize <huizew@gmail.com>\nHuize Wang <huizew@gmail.com> Huize Wang <huizew@users.noreply.github.com>\nMax Silbiger <hollowaytape@retro-type.com> hollowaytape <hollowaytape@retro-type.com>\nIon Elberdin <ionelberdin@gmail.com> Ion <ionelberdin@gmail.com>\nIlhan Polat <ilhanpolat@gmail.com> ilayn <ilhanpolat@gmail.com>\nIrvin Probst <irvin.probst@ensta-bretagne.fr> I--P <irvin.probst@ensta-bretagne.fr>\nIrwin Zaid <irwin.zaid@gmail.com> izaid <hi@irwinzaid.com>\nJacob Carey <jacobcvt12@gmail.com> Jacob Carey <Jacobcvt12@users.noreply.github.com>\nJacob Ogle <jacob.ogle94@outlook.com> jacobogle <jacob.ogle94@outlook.com>\nJacob Vanderplas <jakevdp@gmail.com> Jake VanderPlas <jakevdp@gmail.com>\nJacob Vanderplas <jakevdp@gmail.com> Jake Vanderplas <jakevdp@gmail.com>\nJacob Vanderplas <jakevdp@gmail.com> Jake Vanderplas <jakevdp@yahoo.com>\nJacob Vanderplas <jakevdp@gmail.com> Jake Vanderplas <vanderplas@astro.washington.edu>\nJacob Vanderplas <jakevdp@gmail.com> Jacob Vanderplas <jakevdp@yahoo.com>\nJacopo Tissino <jacopok@gmail.com> Jacopo <jacopok@gmail.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> jaimefrio <jaime.frio@gmail.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> Jaime <jaime.frio@gmail.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> Jaime Fernandez <jaimefrio@google.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> Jaime Fernandez del Rio <jaimefrio@google.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> Jaime Fernandez <jaime.frio@gmail.com>\nJaime Fernandez del Rio <jaime.frio@gmail.com> Jaime Fernandez <jaime@Jaimes-iMac.local>\nJakob Jakobson <43045863+jakobjakobson13@users.noreply.github.com> Jakob Jakobson <31574479+JakobJakobson@users.noreply.github.com>\nJakob Jakobson <43045863+jakobjakobson13@users.noreply.github.com> jakobjakobson13 <43045863+jakobjakobson13@users.noreply.github.com>\nJakub Dyczek <34447984+JDkuba@users.noreply.github.com> JDkuba <34447984+JDkuba@users.noreply.github.com>\nJames T. Webber <jamestwebber@gmail.com> jamestwebber <jamestwebber@gmail.com>\nJames T. Webber <jamestwebber@gmail.com> James Webber <jamestwebber@users.noreply.github.com>\nJames T. Webber <jamestwebber@gmail.com> James Webber <j@meswebber.com>\nJan Schlüter <jan.schlueter@ofai.at> Jan Schlueter <jan.schlueter@ofai.at>\nJan Schlüter <jan.schlueter@ofai.at> Jan Schlüter <github@jan-schlueter.de>\nJan Soedingrekso <jan.soedingrekso@tu-dortmund.de> sudojan <jan.soedingrekso@tu-dortmund.de>\nJan Vleeshouwers <j.m.vleeshouwers@tue.nl> janvle <j.m.vleeshouwers@tue.nl>\nJan Vleeshouwers <j.m.vleeshouwers@tue.nl> Vleeshouwers <j.m.vleeshouwers@tue.nl>\nJanani Padmanabhan <jenny.stone125@gmail.com> janani <janani@janani-Vostro-3446.(none)>\nJanani Padmanabhan <jenny.stone125@gmail.com> Janani <jenny.stone125@gmail.com>\nJanez Demšar <janez.demsar@fri.uni-lj.si> janez <janez.demsar@fri.uni-lj.si>\nJanez Demšar <janez.demsar@fri.uni-lj.si> janezd <janez.demsar@fri.uni-lj.si>\nJarrod Millman <jarrod.millman@gmail.com> Jarrod Millman <millman@berkeley.edu>\nJean-François B. <jfbu@free.fr> jfbu <jfbu@free.fr>\nJean-François B. <jfbu@free.fr> Jean-François B <jfbu@free.fr>\nJeff Armstrong <jeff@approximatrix.com> ArmstrongJ <approximatrix@gmail.com>\nJeff Armstrong <jeff@approximatrix.com> Jeff Armstrong <jeff@approximatrix.com>\nJesse Engel <jesse.engel@gmail.com> jesseengel <jesse.engel@gmail.com>\nJesse Livezey <jesse.livezey@gmail.com> Jesse Livezey <jlivezey@lbl.gov>\nJin-Guo Liu <cacate0129@gmail.com> GiggleLiu <cacate0129@gmail.com>\nJ.L. Lanfranchi <jll1062@phys.psu.edu> J. L. Lanfranchi <jllanfranchi@users.noreply.github.com>\nJ.L. Lanfranchi <jll1062@phys.psu.edu> J.L. Lanfranchi <jllanfranchi@users.noreply.github.com>\nJoe Driscoll <32208193+jwd0023@users.noreply.github.com> jwd0023 <jwd0023@auburn.edu>\nJoel Nothman <joel.nothman@gmail.com> jnothman <jnothman@student.usyd.edu.au>\nJoel Nothman <joel.nothman@gmail.com> Joel Nothman <jnothman@student.usyd.edu.au>\nJohannes Kulick <jkkulick@amazon.de> Johannes Kulick <kulick@hildensia.de>\nJohannes Schmitz <johannes.schmitz1@gmail.com> johschmitz <johannes.schmitz1@gmail.com>\nJona Sassenhagen <jona.sassenhagen@gmail.com> jona-sassenhagen <jona.sassenhagen@gmail.com>\nJonas Bosse <jonas.bosse@posteo.de> jonasBoss <jonas.bosse@posteo.de>\nJonathan Conroy <jonathanconroy14@gmail.com> jonathanconroy <jonathanconroy14@gmail.com>\nJonathan Sutton <j.sutton.mail@gmail.com> suttonje <j.sutton.mail@gmail.com>\nJonathan Sutton <j.sutton.mail@gmail.com> SUTTON Jonathan [fcs] <fcs@oil.ornl.gov>\nJonathan Sutton <j.sutton.mail@gmail.com> Jonathan Sutton <fcs@oil.ornl.gov> \nJonathan Sutton <j.sutton.mail@gmail.com> Jonathan Sutton <fcs@dell-hwqwz12>\nJonathan Sutton <j.sutton.mail@gmail.com> Jonathan Sutton <fcs@oil.ornl.gov>\nJonathan Tammo Siebert <siebertjonathan@aim.com> jotasi <siebertjonathan@aim.com>\nJonathan Taylor <jonathan.taylor@localhost> jonathan.taylor <jonathan.taylor@localhost>\nJordão Bragantini <jordao.bragantini@gmail.com> Jordão Bragantini <jordao.bragantini@czbiohub.org>\nJoris Vankerschaver <joris.vankerschaver@gmail.com> Joris Vankerschaver <jvankerschaver@enthought.com>\nJoscha Reimer <jor@informatik.uni-kiel.de> jor <jor@informatik.uni-kiel.de>\nJosef Perktold <josef.pktd@gmail.com> josef-pktd <josef.pktd@gmail.com>\nJosef Perktold <josef.pktd@gmail.com> josef <josef@localhost>\nJoseph Albert <jxa357@psu.edu> jcalbert <jxa357@psu.edu>\nJoseph Albert <jxa357@psu.edu> <jcacnts@gmail.com>\nJoseph Albert <jxa357@psu.edu> <4261275+jcalbert@users.noreply.github.com>\nJoseph Fox-Rabinovitz <joseph.r.fox-rabinovitz@nasa.gov> Mad Physicist <madphysicist@users.noreply.github.com>\nJoseph Fox-Rabinovitz <joseph.r.fox-rabinovitz@nasa.gov> Joseph Fox-Rabinovitz <madphysicist@users.noreply.github.com>\nJosh Lawrence <josh.k.lawrence@gmail.com> wa03 <josh.k.lawrence@gmail.com>\nJosh Lefler <jlefty94@gmail.com> jlefty <jlefty94@gmail.com>\nJosh Wilson <person142@users.noreply.github.com> Josh <person142@users.noreply.github.com>\nJosue Melka <yoch.melka@gmail.com> yoch <yoch.melka@gmail.com>\nJuan M. Bello-Rivas <jmbr@superadditive.com> Juan M. Bello-Rivas <jmbr@users.noreply.github.com>\nJuan Nunez-Iglesias <juan.nunez-iglesias@monash.edu> Juan Nunez-Iglesias <juan.n@unimelb.edu.au>\nJuan Nunez-Iglesias <juan.nunez-iglesias@monash.edu> Juan Nunez-Iglesias <jni.soma@gmail.com>\nJuha Remes <jremes@outlook.com> newman101 <jremes@outlook.com>\nJulien Jerphanion <git@jjerphan.xyz> Julien Jerphanion (@jjerphan) <git@jjerphan.xyz>\nKai Striega <kaistriega@gmail.com> kai-striega <kaistriega@gmail.com>\nKai Striega <kaistriega@gmail.com> Kai <kaistriega@gmail.com>\nKai Striega <kaistriega@gmail.com> kai <kaistriega@gmail.com>\nKai Striega <kaistriega@gmail.com> kai-striega <kaistriega+github@gmail.com>\nKai Striega <kaistriega@gmail.com> Kai Striega <kaistriega+github@gmail.com>\nKat Huang <kat@aya.yale.edu> kat <kat@aya.yale.edu>\nKenji S Emerson <psmd.iberutaru@gmail.com> Sparrow <psmd.iberutaru@gmail.com>\nKentaro Yamamoto <38549987+yamaken1343@users.noreply.github.com> yamaken <38549987+yamaken1343@users.noreply.github.com>\nKevin Richard Green <kevin.richard.green@gmail.com> kevinrichardgreen <kevin.richard.green@gmail.com>\nKlaus Sembritzki <klausem@gmail.com> klaus <klausem@gmail.com>\nKlesk Chonkin <kleskjr@gmail.com> kleskjr <kleskjr@gmail.com>\nKrzysztof Pióro <38890793+krzysztofpioro@users.noreply.github.com> krzysztofpioro <38890793+krzysztofpioro@users.noreply.github.com>\nLam Yuen Hei <lamyuenhei@gmail.com> Hei <lamyuenhei@gmail.com>\nLars Buitinck <larsmans@gmail.com> Lars <larsmans@users.noreply.github.com>\nLars Buitinck <larsmans@gmail.com> Lars Buitinck <larsmans@users.noreply.github.com>\nLars Buitinck <larsmans@gmail.com> Lars Buitinck <l.buitinck@esciencecenter.nl>\nLars Buitinck <larsmans@gmail.com> Lars Buitinck <L.J.Buitinck@uva.nl>\nLars G <lagru@mailbox.org> Lars G <lagru@users.noreply.github.com>\nLars G <lagru@mailbox.org> Lars Grueter <lagru@mailbox.org>\nLars G <lagru@mailbox.org> Lars Grüter <lagru@users.noreply.github.com>\nLaurynas Mikšys <lmiksys@gmail.com> Laurynas <lmiksys@gmail.com>\nLei Ma <emptymalei@qq.com> OctoMiao <emptymalei@qq.com>\nLevi John Wolf <levi.john.wolf@gmail.com> ljwolf <levi.john.wolf@gmail.com>\nLiam Damewood <damewood@physics.ucdavis.edu> ldamewood <damewood@physics.ucdavis.edu>\nLiming Wang <lmwang@gmail.com> lmwang <lmwang@gmail.com>\nLindsey Hiltner <lindsey.hiltner@gmail.com> L. Hiltner <lhilt@users.noreply.github.com>\nLindsey Hiltner <lindsey.hiltner@gmail.com> L Hiltner <lhilt@users.noreply.github.com>\nLijun Wang <szcfweiya@gmail.com> szcf-weiya <szcfweiya@gmail.com>\nLorenzo Luengo <> loluengo <>\nLucas Colley <lucas.colley8@gmail.com> lucascolley <51488791+lucascolley@users.noreply.github.com>\nLucas Roberts <rlucas7@vt.edu> Lucas Roberts <rlucas7@users.noreply.github.com>\nLucía Cheung <cheunglucia@gmail.com> ludcila <cheunglucia@gmail.com>\nLuke Zoltan Kelley <lkelley@cfa.harvard.edu> lzkelley <lkelley@cfa.harvard.edu>\nMaja Gwozdz <maja.k.gwozdz@gmail.com> mkg33 <maja.k.gwozdz@gmail.com>\nMaja Gwozdz <maja.k.gwozdz@gmail.com> Maja Gwóźdź <maja.k.gwozdz@gmail.com>\nMak Sze Chun <makszechun@gmail.com> makbigc <makszechun@gmail.com>\nMalayaja Chutani <42006125+malch2@users.noreply.github.com> malch2 <42006125+malch2@users.noreply.github.com>\nMalik Idrees Hasan Khan  <pencilartassault@hotmail.com> MalikIdreesHasa <pencilartassault@hotmail.com>\nMalte Esders <git@maltimore.info> Maltimore <git@maltimore.info>\nMandeep Singh <mandeep.singh@zomato.com> Mandeep Singh <daxlab@users.noreply.github.com>\nM.J. Nichol <mjnichol@alumni.uwaterloo.ca> voyager6868 <mjnichol@alumni.uwaterloo.ca>\nManiteja Nandana <manitejanmt@gmail.com> maniteja123 <manitejanmt@gmail.com>\nMarc Honnorat <marc.honnorat@gmail.com> honnorat <marc.honnorat@gmail.com>\nMarcello Seri <mseri@users.noreply.github.com> mseri <mseri@users.noreply.github.com>\nMarco Maggi <124086916+m-maggi@users.noreply.github.com> m-maggi <124086916+m-maggi@users.noreply.github.com>\nMark E Fuller <mark.e.fuller@gmx.de> Mark E. Fuller <mark.e.fuller@gmx.de>\nMark Wiebe <> Mark <>\nMartin Manns <mmanns@gmx.net> manns <mmanns@gmx.net>\nMartin Reinecke <martin.reinecke1@gmx.de> mreineck <martin.reinecke1@gmx.de>\nMarvin Kastner <1kastner@informatik.uni-hamburg.de> 1kastner <1kastner@informatik.uni-hamburg.de>\nMatt Haberland <mdhaber@mit.edu> <mhaberla@calpoly.edu>\nMatt Haberland <mdhaber@mit.edu> <matthaberland@Matts-MacBook-Pro.local>\nMatt Haberland <mdhaber@mit.edu> mdhaber <mdhaber@users.noreply.github.com>\nMatt Knox <mattknox.ca> mattknox_ca <mattknox_ca@localhost>\nMatteo Visconti <matteo.visconti.gr@dartmouth.edu> Matteo Visconti dOC <matteo.visconti.gr@dartmouth.edu>\nMatthew H Flamm <matthewhflamm@gmail.com> Flamm, Matthew H <matthewhflamm@gmail.com>\nMatthew H Flamm <matthewhflamm@gmail.com> MatthewFlamm <39341281+MatthewFlamm@users.noreply.github.com>\nMatthew H Flamm <matthewhflamm@gmail.com> Matthew Flamm <matthewhflamm@gmail.com>\nMatthias Bussonnier <bussonniermatthias@gmail.com> M Bussonnier <bussonniermatthias@gmail.com>\nMathias Zechmeister <32583239+mzechmeister@users.noreply.github.com> mzechmeister <32583239+mzechmeister@users.noreply.github.com>\nMatti Picus <matti.picus@gmail.com> mattip <matti.picus@gmail.com>\nMax Argus <argus.max@gmail.com> BlGene <argus.max@gmail.com>\nMax Argus <argus.max@gmail.com> max argus <argus.max@gmail.com>\nMax Bolingbroke <batterseapower@hotmail.com> DSG User <>\nMax Bolingbroke <batterseapower@hotmail.com> Max Bolingbroke <Max.Bolingbroke@gsacapital.com>\nMelissa Weber Mendonça <melissawm@gmail.com> melissawm <melissawm.github@gmail.com>\nMelissa Weber Mendonça <melissawm@gmail.com> Melissa Weber Mendonça <melissawm.github@gmail.com>\nMelissa Weber Mendonça <melissawm@gmail.com> Melissa Weber <melissawm.github@gmail.com>\nMichael Benfield <mike.benfield@gmail.com> mikebenfield <mike.benfield@gmail.com>\nMichael Droettboom <> mdroe <>\nMichael Dunphy <Michael.Dunphy@dfo-mpo.gc.ca> Michael Dunphy <mdunphy@users.noreply.github.com>\nMichael Hirsch <scienceopen@noreply.github.com> michael <scienceopen@noreply.github.com>\nMichael Hirsch <scienceopen@noreply.github.com> Michael Hirsch <scienceopen@users.noreply.github.com>\nMichael James Bedford <SunsetOrange@users.noreply.github.com> Michael <SunsetOrange@users.noreply.github.com>\nMichael Marien <marien.mich@gmail.com> michaelmarien <marien.mich@gmail.com>\nMiguel A. Batalla <miguelangel@batalla.pro> mabatalla <miguelangel@batalla.pro>\nMikhail Pak <mikhail.pak@tum.de> mp4096 <mikhail.pak@tum.de>\nMilad Sadeghi DM <EverLookNeverSee@Protonmail.ch> ELNS <57490926+EverLookNeverSee@users.noreply.github.com>\nMuhammad Firmansyah Kasim <firman.kasim@gmail.com> mfkasim91 <firman.kasim@gmail.com>\nNathan Bell <wnbell@localhost> wnbell <wnbell@localhost>\nNathan Woods <woodscn@lanl.gov> Charles Nathan Woods <woodscn@pn1504346.lanl.gov>\nNathan Woods <woodscn@lanl.gov> Nathan Woods <charlesnwoods@gmail.com>\nNathan Woods <woodscn@lanl.gov> Nathan Woods <woodscn@pn1504346.lanl.gov>\nNeil Girdhar <mistersheik@gmail.com> Neil <mistersheik@gmail.com>\nNicholas McKibben <nicholas.bgp@gmail.com> mckib2 <nicholas.bgp@gmail.com>\nNickolai Belakovski <nbelakovski@users.noreply.github.com> nbelakovski <nbelakovski@users.noreply.github.com>\nNicky van Foreest <vanforeest@gmail.com> Nicky van Foreest <ndvanforeest@users.noreply.github.com>\nNicola Montecchio <nicola.montecchio@gmail.com> nicola montecchio <nicola.montecchio@gmail.com>\nNicolas Bloyet <nicolas.bloyet@gmail.com> theplatypus <nicolas.bloyet@gmail.com>\nNikita Karetnikov <nkaretnikov@quansight.com> Nikita Karetnikov (ニキータ カレートニコフ) <nikita@karetnikov.org>\nNikolai Nowaczyk <mail@nikno.de> Nikolai <mail@nikno.de>\nNikolas Moya <nikolasmoya@gmail.com> nmoya <nikolasmoya@gmail.com>\nNikolay Mayorov <nikolay.mayorov@zoho.com> Nikolay Mayorov <n59_ru@hotmail.com>\nNikolay Mayorov <nikolay.mayorov@zoho.com> Nikolay Mayorov <nmayorov@users.noreply.github.com>\nNoel Kippers <n.kippers@catawiki.nl> RothNRK <n.kippers@catawiki.nl>\nNoel Kippers <n.kippers@catawiki.nl> Noel Kippers <RothNRK@users.noreply.github.com>\nOleksandr Pavlyk <oleksandr.pavlyk@intel.com> Oleksandr Pavlyk <oleksandr-pavlyk@users.noreply.github.com>\nOrestis Floros <orestisf1993@gmail.com> Orestis <orestisf1993@gmail.com>\nPablo Winant <pablo.winant@gmail.com> pablo.winant@gmail.com <Pablo Winant>\nPamphile Roy <roy.pamphile@gmail.com> Pamphile ROY <proy@bongfish.com>\nPamphile Roy <roy.pamphile@gmail.com> Pamphile ROY <roy.pamphile@gmail.com>\nPamphile Roy <roy.pamphile@gmail.com> Tupui <23188539+tupui@users.noreply.github.com>\nPatrick Snape <patricksnape@gmail.com> patricksnape <patricksnape@gmail.com>\nPaul Kienzle <pkienzle@gmail.com> Paul Kienzle <pkienzle@nist.gov>\nPaul van Mulbregt <pvanmulbregt@users.noreply.github.com> pvanmulbregt <pvanmulbregt@users.noreply.github.com>\nPhilippe DONNAT <pdonnat@hcmdom.local> pdonnat <46384882+pdonnat@users.noreply.github.com>\nPeadar Coyle <peadarcoyle@googlemail.com> springcoil <peadarcoyle@googlemail.com>\nPedro López-Adeva Fernández-Layos <plopezadeva@gmail.com> plafl <plopezadeva@gmail.com>\nPedro López-Adeva Fernández-Layos <plopezadeva@gmail.com> Pedro López-Adeva Fernández-Layos <plafl@users.noreply.github.com>\nPer Brodtkorb <per.andreas.brodtkorb@gmail.com> pbrod <per.andreas.brodtkorb@gmail.com>\nPer Brodtkorb <per.andreas.brodtkorb@gmail.com> pab <pab@MP815.ffi.no>\nPer Brodtkorb <per.andreas.brodtkorb@gmail.com> Per A Brodtkorb <per.andreas.brodtkorb@gmail.com>\nPerry Lee <mclee@aftercollege.com> Perry <mclee@aftercollege.com>\nPete Bunch <pete.bunch@gmail.com> Pete <pete.bunch@gmail.com>\nPeter Bell <peterbell10@live.co.uk> peterbell10 <peterbell10@live.co.uk>\nPeter Lysakovski <30794408+Lskvk@users.noreply.github.com> Lskvk <30794408+Lskvk@users.noreply.github.com>\nPeter Mahler Larsen <pete.mahler.larsen@gmail.com> pmla <pete.mahler.larsen@gmail.com>\nPeter Mahler Larsen <pete.mahler.larsen@gmail.com> Peter <peter.mahler.larsen@gmail.com>\nPeter Mahler Larsen <pete.mahler.larsen@gmail.com> Peter Larsen <peter.mahler.larsen@gmail.com>\nPeter Mahler Larsen <pete.mahler.larsen@gmail.com> pmla <peter.mahler.larsen@gmail.com>\nPeyton Murray <peynmurray@gmail.com> pdmurray <peynmurray@gmail.com>\nPeyton Murray <peynmurray@gmail.com> Peyton Murray <peytonmurray@gmail.com>\nPhilip DeBoer <philip.deboer@gmail.com> Philip DeBoer <philip_deboer@scotiacapital.com>\nPhillip Weinberg <weinbe58@bu.edu> weinbe58 <weinbe58@bu.edu>\nPierre de Buyl <pdebuyl@pdebuyl.be> Pierre de Buyl <pdebuyl@ulb.ac.be>\nPierre GM <pierregm@localhost> pierregm <pierregm@localhost>\nPoom Chiarawongse <eight1911@gmail.com> Poom Chiarawongse <tchiarawongs@gmail.com>\nPoom Chiarawongse <eight1911@gmail.com> poom <eight1911@gmail.com>\nQuentin Barthélemy <q.barthelemy@gmail.com> qbarthelemy <q.barthelemy@gmail.com>\nRadoslaw Guzinski <radoslaw.guzinski@esa.int> radosuav <rmgu@dhi-gras.com>\nRadoslaw Guzinski <radoslaw.guzinski@esa.int> radosuav <radoslaw.guzinski@esa.int>\nRalf Gommers <ralf.gommers@gmail.com> rgommers <ralf.gommers@googlemail.com>\nRalf Gommers <ralf.gommers@gmail.com> Ralf Gommers <ralf.gommers@googlemail.com>\nRaphael Wettinger <ra@phael.org> raphael <ra@phael.org>\nRaphael Wettinger <ra@phael.org> raphaelw <raphael.wettinger@googlemail.com>\nReidar Kind <53039431+reidarkind@users.noreply.github.com> reidarkind <53039431+reidarkind@users.noreply.github.com>\nRenee Otten <reneeotten@users.noreply.github.com> reneeotten <reneeotten@users.noreply.github.com>\nReshama Shaikh <reshama.stat@gmail.com> reshamas <reshama.stat@gmail.com>\nRichard Gowers <richardjgowers@gmail.com> richardjgowers <richardjgowers@gmail.com>\nRick Paris <rick.paris@mlb.com> rparis <rick.paris@mlb.com>\nRob Falck <robfalck@gmail.com> rob.falck <rob.falck@localhost>\nRobert David Grant <rgrant@enthought.com> Robert David Grant <robert.david.grant@gmail.com>\nRobert Kern <rkern@enthought.com> Robert Kern <robert.kern@gmail.com>\nRobert Uhl <robert.uhl@rwth-aachen.de> Robert Uhl <62612220+robertuhl@users.noreply.github.com>\nRoman Mirochnik <roman.mirochnik@hpe.com> mirochni <roman.mirochnik@hpe.com>\nRuikang Sun <srk888666@qq.com> SunRuikang <srk888666@qq.com>\nRupak Das <dr10ru@yahoo.co.in> Rupak <dr10ru@yahoo.co.in>\nRuslan Yevdokymov <evruslan17@gmail.com> Ruslan Yevdokymov <38809160+ruslanye@users.noreply.github.com>\nRyan Gibson <ryan.alexander.gibson@gmail.com> ragibson <ryan.alexander.gibson@gmail.com>\nSam Lewis <sam.vr.lewis@gmail.com> Sam Lewis <samvrlewis@users.noreply.github.com>\nSam McCormack <sampmccormack@gmail.com> Sam McCormack <TheGreatCabbage@users.noreply.github.com>\nSam Mason <sam@samason.uk> Sam Mason <sam.mason@warwick.ac.uk>\nSam Rosen <7624861+SamGRosen@users.noreply.github.com> SamGRosen <7624861+SamGRosen@users.noreply.github.com>\nSamuel Wallan <44255917+swallan@users.noreply.github.com> swallan <44255917+swallan@users.noreply.github.com>\nSamuel Wallan <44255917+swallan@users.noreply.github.com> Sam Wallan <44255917+swallan@users.noreply.github.com>\nSanti Hernandez <santi-hernandez@hotmail.com> santiher <santi-hernandez@hotmail.com>\nSanti Villalba <sdvillal@gmail.com> santi <sdvillal@gmail.com>\nSara Fridovich-Keil <sfk@eecs.berkeley.edu> [Sara Fridovich-Keil] <[sfk@eecs.berkeley.edu]>\nSaurabh Agarwal <shourabh.agarwal@gmail.com> saurabhkgpee <shourabh.agarwal@gmail.com>\nScott Sievert <me@scottsievert.com> scottsievert <sieve121@umn.edu>\nScott Sievert <me@scottsievert.com> <stsievert@users.noreply.github.com>\nScott Sievert <me@scottsievert.com> <scott@stsievert.com>\nScott Sievert <me@scottsievert.com> <github@stsievert.com>\nSean Cheah <cheah_sean@yahoo.com> thalassemia <cheah_sean@yahoo.com>\nSebastian Haase <> sebhaase <>\nSebastian Pucilowski <smopucilowski@gmail.com> Sebastian Pucilowski <smopucilowski@users.noreply.github.com>\nSebastian Skoupý <sebastian.skoupy@gmail.com> Sebascn <sebastian.skoupy@gmail.com>\nShivnaren Srinivasan <shivnaren@gmail.com> srinivasan <shivnaren@gmail.com>\nSkipper Seabold <jsseabold@gmail.com> skip <skip@localhost>\nShinya SUZUKI <sshinya@bio.titech.ac.jp> Shinya SUZUKI <minasitawakou@gmail.com>\nSmit Lunagariya <55887635+Smit-create@users.noreply.github.com> Smit-create <55887635+Smit-create@users.noreply.github.com>\nSmit Lunagariya <smitlunagariya.mat18@itbhu.ac.in> Smit-create <smitlunagariya.mat18@itbhu.ac.in>\nSourav Singh <souravsingh@users.noreply.github.com> Sourav Singh <4314261+souravsingh@users.noreply.github.com>\nSrikiran <srikiran@dhcp-v233-179.pv.reshsg.uci.edu> sriki18 <sriki18@users.noreply.github.com>\nStefan Endres <stefan.c.endres@gmail.com> stefan-endres <stefan.c.endres@gmail.com>\nStefan Endres <stefan.c.endres@gmail.com> Stefan Endres <Stefan.C.Endres@gmail.com>\nStefan Peterson <stefan.peterson@rubico.com> sjpet <stefan.peterson@rubico.com>\nStefan Peterson <stefan.peterson@rubico.com> Stefan Peterson <sjpet@users.noreply.github.com>\nStefan van der Walt <stefanv@berkeley.edu> Stefan van der Walt <sjvdwalt@gmail.com>\nStefan van der Walt <stefanv@berkeley.edu> Stefan van der Walt <stefan@sun.ac.za>\nSteve Richardson <arichar6@gmail.com> arichar6 <arichar6@gmail.com>\nSteven Adams <166521727+hugehope@users.noreply.github.com> hugehope <166521727+hugehope@users.noreply.github.com>\nSturla Molden <sturla@molden.no> sturlamolden <sturla@molden.no>\nSturla Molden <sturla@molden.no> Sturla Molden <sturlamolden@users.noreply.github.com>\nSturla Molden <sturla@molden.no> unknown <sturlamo@PK-FYS-1121C.uio.no>\nSumit Binnani <sumitbinnani.developer@gmail.com> sumitbinnani <sumitbinnani.developer@gmail.com>\nSylvain Bellemare <sbellem@gmail.com> Sylvain Bellemare <sylvain.bellemare@ezeep.com>\nSylvain Gubian <sylvain.gubian@pmi.com> Sylvain Gubian <Sylvain.Gubian@pmi.com>\nSytse Knypstra <S.Knypstra@rug.nl> SytseK <S.Knypstra@rug.nl>\nTakumasa Nakamura <n.takumasa@gmail.com> Takumasa N <n.takumasa@gmail.com>\nTakuya Oshima <oshima@eng.niigata-u.ac.jp> Takuya OSHIMA <oshima@eng.niigata-u.ac.jp>\nTerry Jones <terry@fluidinfo.com> terrycojones <terry@fluidinfo.com>\nThibault de Coincy <80053070+ThibaultDECO@users.noreply.github.com> ThibaultDECO <80053070+ThibaultDECO@users.noreply.github.com>\nThomas Duvernay <td75013@hotmail.fr> Patol75 <td75013@hotmail.fr>\nThomas Kluyver <takowl@gmail.com> Thomas Kluyver <thomas@kluyver.me.uk>\nThouis (Ray) Jones <thouis@gmail.com> Thouis (Ray) Jones <thouis@seas.harvard.edu>\nTiago M.D. Pereira <tiagomdp@gmail.com> tiagopereira <tiagomdp@gmail.com>\nTim Cera <tim@cerazone.net> timcera <tim@cerazone.net>\nTim Leslie <tim.leslie@gmail.com> Tim Leslie <timl@breakawayconsulting.com.au>\nTobias Megies <megies@geophysik.uni-muenchen.de> Tobias Megies <megies@users.noreply.github.com>\nTobias Schmidt <royalts@gmail.com> RoyalTS <royalts@gmail.com>\nTodd Goodall <beyondmetis@gmail.com> Todd <beyondmetis@gmail.com>\nTodd Jennings <toddrjen@gmail.com> Todd <toddrjen@gmail.com>\nTom Adamczewski <tadamczewskipublic@gmail.com> tadamcz <tadamczewskipublic@gmail.com>\nTom Waite <tom.waite@localhost> tom.waite <tom.waite@localhost>\nTom Donoghue <tdonoghue@ucsd.edu> TomDonoghue <tdonoghue@ucsd.edu>\nTomer Sery <tomer.sery@nextsilicon.com> Tomer.Sery <tomer.sery@nextsilicon.com>\nTony S. Yu <tsyu80@gmail.com> tonysyu <tsyu80@gmail.com>\nTony S. Yu <tsyu80@gmail.com> Tony S Yu <tsyu80@gmail.com>\nToshiki Kataoka <tos.lunar@gmail.com> Toshiki Kataoka <kataoka@preferred.jp>\nToshiki Kataoka <tos.lunar@gmail.com> tosh1ki <tosh1ki@yahoo.co.jp>\nTravis Oliphant <teoliphant@gmail.com> Travis E. Oliphant <teoliphant@gmail.com>\nTravis Oliphant <teoliphant@gmail.com> Travis Oliphant <oliphant@enthought.com>\nUwe Schmitt <uwe.schmitt@localhost> uwe.schmitt <uwe.schmitt@localhost>\nVicky Close <vicky.r.close@gmail.com> vickyclose <vicky.r.close@gmail.com>\nVladyslav Rachek <wsw.raczek@gmail.com> Vladyslav Rachek <36896640+erheron@users.noreply.github.com>\nWarren Weckesser <warren.weckesser@gmail.com> warren.weckesser <warren.weckesser@localhost>\nWarren Weckesser <warren.weckesser@gmail.com> Warren Weckesser <warren.weckesser@enthought.com>\nWarren Weckesser <warren.weckesser@gmail.com> Warren Weckesser <warren.weckesser@localhost>\nWarren Weckesser <warren.weckesser@gmail.com> warren <warren.weckesser@gmail.com>\nWendy Liu <ilostwaldo@gmail.com> dellsystem <ilostwaldo@gmail.com>\nWill Tirone <will.tirone1@gmail.com> WillTirone <42592742+WillTirone@users.noreply.github.com>\nWill Tirone <will.tirone1@gmail.com> willtirone <will.tirone1@gmail.com>\nXiao Yuan <yuanx749@gmail.com> yuanx749 <yuanx749@gmail.com>\nXingyu Liu <38244988+charlotte12l@users.noreply.github.com> 刘星雨 <liuxingyu.12@bytedance.com>\nYagiz Olmez <57116432+yagizolmez@users.noreply.github.com> yagizolmez <yagizolmez@pop-os.localdomain>\nYu Feng <rainwoodman@gmail.com> Yu Feng <yfeng1@waterfall.dyn.berkeley.edu>\nYves-Rémi Van Eycke <yves-remi@hotmail.com> vanpact <yves-remi@hotmail.com>\nZé Vinícius <jvmirca@gmail.com> Ze Vinicius <jvmirca@gmail.com>\nZhida Shang <57895730+futuer-szd@users.noreply.github.com> Futuer <57895730+futuer-szd@users.noreply.github.com>\nZoufiné Lauer-Bare <raszoufine@gmail.com> zolabar <raszoufine@gmail.com>\n"
        },
        {
          "name": "CITATION.bib",
          "type": "blob",
          "size": 1.2470703125,
          "content": "@ARTICLE{2020SciPy-NMeth,\n  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and\n            Haberland, Matt and Reddy, Tyler and Cournapeau, David and\n            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and\n            Bright, Jonathan and {van der Walt}, St{\\'e}fan J. and\n            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and\n            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and\n            Kern, Robert and Larson, Eric and Carey, C J and\n            Polat, {\\.I}lhan and Feng, Yu and Moore, Eric W. and\n            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and\n            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and\n            Harris, Charles R. and Archibald, Anne M. and\n            Ribeiro, Ant{\\^o}nio H. and Pedregosa, Fabian and\n            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},\n  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific\n            Computing in Python}},\n  journal = {Nature Methods},\n  year    = {2020},\n  volume  = {17},\n  pages   = {261--272},\n  url     = {https://doi.org/10.1038/s41592-019-0686-2},\n  adsurl  = {https://ui.adsabs.harvard.edu/abs/2020NatMe..17..261V},\n  doi     = {10.1038/s41592-019-0686-2},\n}\n"
        },
        {
          "name": "CONTRIBUTING.rst",
          "type": "blob",
          "size": 1.0859375,
          "content": "=============================\nSciPy pull request guidelines\n=============================\n\nPull requests are always welcome, and the SciPy community appreciates\nany help you give. Note that a code of conduct applies to all spaces\nmanaged by the SciPy project, including issues and pull requests:\nhttps://docs.scipy.org/doc/scipy/dev/conduct/code_of_conduct.html\n\nWhen submitting a pull request, we ask you to check the following:\n\n1. **Unit tests**, **documentation**, and **code style** are in order.\n   For details, please read\n   https://docs.scipy.org/doc/scipy/dev/hacking.html\n\n   It's also OK to submit work in progress if you're unsure of what\n   this exactly means, in which case you'll likely be asked to make\n   some further changes.\n\n2. The contributed code will be **licensed under SciPy's license**,\n   https://github.com/scipy/scipy/blob/main/LICENSE.txt.\n   If you did not write the code yourself, you ensure the existing\n   license is compatible and include the license information in the\n   contributed files, or obtain permission from the original\n   author to relicense the contributed code.\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.4951171875,
          "content": "Copyright (c) 2001-2002 Enthought, Inc. 2003, SciPy Developers.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions\nare met:\n\n1. Redistributions of source code must retain the above copyright\n   notice, this list of conditions and the following disclaimer.\n\n2. Redistributions in binary form must reproduce the above\n   copyright notice, this list of conditions and the following\n   disclaimer in the documentation and/or other materials provided\n   with the distribution.\n\n3. Neither the name of the copyright holder nor the names of its\n   contributors may be used to endorse or promote products derived\n   from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "LICENSES_bundled.txt",
          "type": "blob",
          "size": 12.5791015625,
          "content": "\n----\n\nThe SciPy repository and source distributions bundle a number of libraries that\nare compatibly licensed.  We list these here.\n\n\nName: Decorator\nFiles: scipy/_lib/decorator.py\nLicense: 2-clause BSD\n  For details, see the header inside scipy/_lib/decorator.py\n\nName: fast_matrix_market\nFiles: scipy/io/_fast_matrix_market/*\nLicense: 2-clause BSD\n  For details, see scipy/io/_fast_matrix_market/LICENSE.txt\n\nName: pystreambuf\nFiles: scipy/io/_fast_matrix_market/src/pystreambuf.h\nLicense: 3-clause BSD\n  For details, see the header inside scipy/io/_fast_matrix_market/src/pystreambuf.h\n\nName: fast_float\nFiles: scipy/io/_fast_matrix_market/fast_matrix_market/dependencies/fast_float/*\nLicense: MIT\n  For details, see scipy/io/_fast_matrix_market/fast_matrix_market/dependencies/fast_float/LICENSE-MIT\n\nName: ryu\nFiles: scipy/io/_fast_matrix_market/fast_matrix_market/dependencies/ryu/*\nLicense: BSL-1.0\n  For details, see scipy/io/_fast_matrix_market/fast_matrix_market/dependencies/ryu/LICENSE-BOOST\n\nName: ID\nFiles: scipy/linalg/src/id_dist/*\nLicense: 3-clause BSD\n  For details, see scipy/linalg/src/id_dist/doc/doc.tex\n\nName: L-BFGS-B\nFiles: scipy/optimize/lbfgsb/*\nLicense: BSD license\n  For details, see scipy/optimize/lbfgsb/README\n\nName: LAPJVsp\nFiles: scipy/sparse/csgraph/_matching.pyx\nLicense: 3-clause BSD\nCopyright 1987-, A. Volgenant/Amsterdam School of Economics,\n                 University of Amsterdam\n\n  Distributed under 3-clause BSD license with permission from\n  University of Amsterdam.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n  1. Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n\n  2. Redistributions in binary form must reproduce the above copyright notice,\n     this list of conditions and the following disclaimer in the documentation\n    and/or other materials provided with the distribution.\n\n  3. Neither the name of the copyright holder nor the names of its contributors\n     may be used to endorse or promote products derived from this software\n    without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n  POSSIBILITY OF SUCH DAMAGE.\n\n\nName: SuperLU\nFiles: scipy/sparse/linalg/dsolve/SuperLU/*\nLicense: 3-clause BSD\n  For details, see scipy/sparse/linalg/dsolve/SuperLU/License.txt\n\nName: ARPACK\nFiles: scipy/sparse/linalg/eigen/arpack/ARPACK/*\nLicense: 3-clause BSD\n  For details, see scipy/sparse/linalg/eigen/arpack/ARPACK/COPYING\n\nName: Qhull\nFiles: scipy/spatial/qhull/*\nLicense: Qhull license (BSD-like)\n  For details, see scipy/spatial/qhull/COPYING.txt\n\nName: Cephes\nFiles: scipy/special/cephes/*\nLicense: 3-clause BSD\n  Distributed under 3-clause BSD license with permission from the author,\n  see https://lists.debian.org/debian-legal/2004/12/msg00295.html\n\n  Cephes Math Library Release 2.8:  June, 2000\n  Copyright 1984, 1995, 2000 by Stephen L. Moshier\n\n  This software is derived from the Cephes Math Library and is\n  incorporated herein by permission of the author.\n\n  All rights reserved.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n      * Redistributions of source code must retain the above copyright\n        notice, this list of conditions and the following disclaimer.\n      * Redistributions in binary form must reproduce the above copyright\n        notice, this list of conditions and the following disclaimer in the\n        documentation and/or other materials provided with the distribution.\n      * Neither the name of the <organization> nor the\n        names of its contributors may be used to endorse or promote products\n        derived from this software without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n  DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY\n  DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n  (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n  ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n  SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nName: Faddeeva\nFiles: scipy/special/Faddeeva.*\nLicense: MIT\n  Copyright (c) 2012 Massachusetts Institute of Technology\n\n  Permission is hereby granted, free of charge, to any person obtaining\n  a copy of this software and associated documentation files (the\n  \"Software\"), to deal in the Software without restriction, including\n  without limitation the rights to use, copy, modify, merge, publish,\n  distribute, sublicense, and/or sell copies of the Software, and to\n  permit persons to whom the Software is furnished to do so, subject to\n  the following conditions:\n\n  The above copyright notice and this permission notice shall be\n  included in all copies or substantial portions of the Software.\n\n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n  NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n  LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n  OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n  WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nName: qd\nFiles: scipy/special/cephes/dd_*.[ch]\nLicense: modified BSD license (\"BSD-LBNL-License.doc\")\n  This work was supported by the Director, Office of Science, Division\n  of Mathematical, Information, and Computational Sciences of the\n  U.S. Department of Energy under contract numbers DE-AC03-76SF00098 and\n  DE-AC02-05CH11231.\n\n  Copyright (c) 2003-2009, The Regents of the University of California,\n  through Lawrence Berkeley National Laboratory (subject to receipt of\n  any required approvals from U.S. Dept. of Energy) All rights reserved.\n\n  1. Redistribution and use in source and binary forms, with or\n  without modification, are permitted provided that the following\n  conditions are met:\n\n  (1) Redistributions of source code must retain the copyright\n  notice, this list of conditions and the following disclaimer.\n\n  (2) Redistributions in binary form must reproduce the copyright\n  notice, this list of conditions and the following disclaimer in\n  the documentation and/or other materials provided with the\n  distribution.\n\n  (3) Neither the name of the University of California, Lawrence\n  Berkeley National Laboratory, U.S. Dept. of Energy nor the names\n  of its contributors may be used to endorse or promote products\n  derived from this software without specific prior written\n  permission.\n\n  2. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n  3. You are under no obligation whatsoever to provide any bug fixes,\n  patches, or upgrades to the features, functionality or performance of\n  the source code (\"Enhancements\") to anyone; however, if you choose to\n  make your Enhancements available either publicly, or directly to\n  Lawrence Berkeley National Laboratory, without imposing a separate\n  written license agreement for such Enhancements, then you hereby grant\n  the following license: a non-exclusive, royalty-free perpetual license\n  to install, use, modify, prepare derivative works, incorporate into\n  other computer software, distribute, and sublicense such enhancements\n  or derivative works thereof, in binary and source code form.\n\nName: pypocketfft\nFiles: scipy/fft/_pocketfft/[pocketfft.h, pypocketfft.cxx]\nLicense: 3-Clause BSD\n  For details, see scipy/fft/_pocketfft/LICENSE.md\n\nName: uarray\nFiles: scipy/_lib/uarray/*\nLicense: 3-Clause BSD\n  For details, see scipy/_lib/uarray/LICENSE\n\nName: ampgo\nFiles: benchmarks/benchmarks/go_benchmark_functions/*.py\nLicense: MIT\n  Functions for testing global optimizers, forked from the AMPGO project,\n  https://code.google.com/archive/p/ampgo\n\nName: pybind11\nFiles: no source files are included, however pybind11 binary artifacts are\n  included with every binary build of SciPy.\nLicense:\n  Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>, All rights reserved.\n\n  Redistribution and use in source and binary forms, with or without\n  modification, are permitted provided that the following conditions are met:\n\n  1. Redistributions of source code must retain the above copyright notice, this\n     list of conditions and the following disclaimer.\n\n  2. Redistributions in binary form must reproduce the above copyright notice,\n     this list of conditions and the following disclaimer in the documentation\n     and/or other materials provided with the distribution.\n\n  3. Neither the name of the copyright holder nor the names of its contributors\n     may be used to endorse or promote products derived from this software\n     without specific prior written permission.\n\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n  DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nName: HiGHS\nFiles: scipy/optimize/_highs/*\nLicense: MIT\n  For details, see scipy/optimize/_highs/LICENCE\n\nName: Boost\nFiles: scipy/_lib/boost_math/*\nLicense: Boost Software License - Version 1.0\n  For details, see scipy/_lib/boost_math/LICENSE.txt\n\nName: Biasedurn\nFiles: scipy/stats/biasedurn/*\nLicense 3-Clause BSD\n  For details, see scipy/stats/biasedurn/license.txt\n\nName: UNU.RAN\nFiles: scipy/_lib/unuran/*\nLicense 3-Clause BSD\n  For details, see scipy/_lib/unuran/license.txt\n\nName: NumPy\nFiles: scipy/stats/_rcont/[logfactorial.h,logfactorial.c]\nLicense 3-Clause BSD\n  For details, see header inside scipy/stats/_rcont/logfactorial.h\n  and scipy/stats/_rcont/logfactorial.c\n\nName: array-api-compat\nFiles: scipy/_lib/array-api-compat/*\nLicense: MIT\n  For details, see scipy/_lib/array-api-compat/LICENCE\n\nName: Tempita\nFiles: scipy/_build_utils/tempita/*\nLicense: MIT\n  For details, see scipy/_build_utils/tempita/LICENCE.txt\n\nName: mdspan\nFiles: scipy/special/special/third_party/kokkos/mdspan.hpp\nLicense: Apache License v2.0 with LLVM Exceptions\n  For details, see scipy/special/special/third_party/kokkos/mdspan.hpp\n\nName: Chebfun\nFiles: scipy/interpolate/[_aaa.py, tests/test_aaa.py]\nLicense 3-Clause BSD\n  For details, see scipy/interpolate/_aaa.py\n\nName: getLebedevSphere\nFiles: scipy/integrate/_lebedev.py\nLicense 2-Clause BSD\n  For details, see scipy/integrate/_lebedev.py"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 3.4921875,
          "content": ".. image:: https://raw.githubusercontent.com/scipy/scipy/main/doc/source/_static/logo.svg\n  :target: https://scipy.org\n  :width: 110\n  :height: 110\n  :align: left \n\n.. image:: https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A\n  :target: https://numfocus.org\n\n.. image:: https://img.shields.io/pypi/dm/scipy.svg?label=Pypi%20downloads\n  :target: https://pypi.org/project/scipy/\n\n.. image:: https://img.shields.io/conda/dn/conda-forge/scipy.svg?label=Conda%20downloads\n  :target: https://anaconda.org/conda-forge/scipy\n\n.. image:: https://img.shields.io/badge/stackoverflow-Ask%20questions-blue.svg\n  :target: https://stackoverflow.com/questions/tagged/scipy\n\n.. image:: https://img.shields.io/badge/DOI-10.1038%2Fs41592--019--0686--2-blue.svg\n  :target: https://www.nature.com/articles/s41592-019-0686-2\n\nSciPy (pronounced \"Sigh Pie\") is an open-source software for mathematics,\nscience, and engineering. It includes modules for statistics, optimization,\nintegration, linear algebra, Fourier transforms, signal and image processing,\nODE solvers, and more.\n\n- **Website:** https://scipy.org\n- **Documentation:** https://docs.scipy.org/doc/scipy/\n- **Development version of the documentation:** https://scipy.github.io/devdocs\n- **SciPy development forum:** https://discuss.scientific-python.org/c/contributor/scipy\n- **Stack Overflow:** https://stackoverflow.com/questions/tagged/scipy\n- **Source code:** https://github.com/scipy/scipy\n- **Contributing:** https://scipy.github.io/devdocs/dev/index.html\n- **Bug reports:** https://github.com/scipy/scipy/issues\n- **Code of Conduct:** https://docs.scipy.org/doc/scipy/dev/conduct/code_of_conduct.html\n- **Report a security vulnerability:** https://tidelift.com/docs/security\n- **Citing in your work:** https://www.scipy.org/citing-scipy/\n\nSciPy is built to work with\nNumPy arrays, and provides many user-friendly and efficient numerical routines,\nsuch as routines for numerical integration and optimization. Together, they\nrun on all popular operating systems, are quick to install, and are free of\ncharge. NumPy and SciPy are easy to use, but powerful enough to be depended\nupon by some of the world's leading scientists and engineers. If you need to\nmanipulate numbers on a computer and display or publish the results, give\nSciPy a try!\n\nFor the installation instructions, see `our install\nguide <https://scipy.org/install/>`__.\n\n\nCall for Contributions\n----------------------\n\nWe appreciate and welcome contributions. Small improvements or fixes are always appreciated; issues labeled as \"good\nfirst issue\" may be a good starting point. Have a look at `our contributing\nguide <https://scipy.github.io/devdocs/dev/index.html>`__.\n\nWriting code isn’t the only way to contribute to SciPy. You can also:\n\n- review pull requests\n- triage issues\n- develop tutorials, presentations, and other educational materials\n- maintain and improve `our website <https://github.com/scipy/scipy.org>`__\n- develop graphic design for our brand assets and promotional materials\n- help with outreach and onboard new contributors\n- write grant proposals and help with other fundraising efforts\n\nIf you’re unsure where to start or how your skills fit in, reach out! You can\nask on the `forum <https://discuss.scientific-python.org/c/contributor/scipy>`__\nor here, on GitHub, by leaving a comment on a relevant issue that is already\nopen.\n\nIf you are new to contributing to open source, `this\nguide <https://opensource.guide/how-to-contribute/>`__ helps explain why, what,\nand how to get involved.\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev.py",
          "type": "blob",
          "size": 58.5302734375,
          "content": "#! /usr/bin/env python3\n\n'''\nDeveloper CLI: building (meson), tests, benchmark, etc.\n\nThis file contains tasks definitions for doit (https://pydoit.org).\nAnd also a CLI interface using click (https://click.palletsprojects.com).\n\nThe CLI is ideal for project contributors while,\ndoit interface is better suited for authoring the development tasks.\n\nREQUIREMENTS:\n--------------\n- see environment.yml: doit, pydevtool, click, rich-click\n\n# USAGE:\n\n## 1 - click API\n\nCommands can added using default Click API. i.e.\n\n```\n@cli.command()\n@click.argument('extra_argv', nargs=-1)\n@click.pass_obj\ndef python(ctx_obj, extra_argv):\n    \"\"\"Start a Python shell with PYTHONPATH set\"\"\"\n```\n\n## 2 - class based Click command definition\n\n`CliGroup` provides an alternative class based API to create Click commands.\n\nJust use the `cls_cmd` decorator. And define a `run()` method\n\n```\n@cli.cls_cmd('test')\nclass Test():\n    \"\"\"Run tests\"\"\"\n\n    @classmethod\n    def run(cls):\n        print('Running tests...')\n```\n\n- Command may make use a Click.Group context defining a `ctx` class attribute\n- Command options are also define as class attributes\n\n```\n@cli.cls_cmd('test')\nclass Test():\n    \"\"\"Run tests\"\"\"\n    ctx = CONTEXT\n\n    verbose = Option(\n        ['--verbose', '-v'], default=False, is_flag=True, help=\"verbosity\")\n\n    @classmethod\n    def run(cls, **kwargs): # kwargs contains options from class and CONTEXT\n        print('Running tests...')\n```\n\n## 3 - class based interface can be run as a doit task by subclassing from Task\n\n- Extra doit task metadata can be defined as class attribute TASK_META.\n- `run()` method will be used as python-action by task\n\n```\n@cli.cls_cmd('test')\nclass Test(Task):   # Task base class, doit will create a task\n    \"\"\"Run tests\"\"\"\n    ctx = CONTEXT\n\n    TASK_META = {\n        'task_dep': ['build'],\n    }\n\n    @classmethod\n    def run(cls, **kwargs):\n        pass\n```\n\n## 4 - doit tasks with cmd-action \"shell\" or dynamic metadata\n\nDefine method `task_meta()` instead of `run()`:\n\n```\n@cli.cls_cmd('refguide-check')\nclass RefguideCheck(Task):\n    @classmethod\n    def task_meta(cls, **kwargs):\n        return {\n```\n\n'''\n\nimport os\nimport subprocess\nimport sys\nimport warnings\nimport shutil\nimport json\nimport datetime\nimport time\nimport importlib\nimport importlib.util\nimport errno\nimport contextlib\nimport sysconfig\nimport math\nimport traceback\nfrom concurrent.futures.process import _MAX_WINDOWS_WORKERS\n\nfrom pathlib import Path\nfrom collections import namedtuple\nfrom types import ModuleType as new_module\nfrom dataclasses import dataclass\n\nimport click\nfrom click import Option, Argument\nfrom doit.cmd_base import ModuleTaskLoader\nfrom doit.reporter import ZeroReporter\nfrom doit.exceptions import TaskError\nfrom doit.api import run_tasks\nfrom doit import task_params\nfrom pydevtool.cli import UnifiedContext, CliGroup, Task\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.theme import Theme\nfrom rich_click import rich_click\n\nDOIT_CONFIG = {\n    'verbosity': 2,\n    'minversion': '0.36.0',\n}\n\n\nconsole_theme = Theme({\n    \"cmd\": \"italic gray50\",\n})\n\nif sys.platform == 'win32':\n    class EMOJI:\n        cmd = \">\"\nelse:\n    class EMOJI:\n        cmd = \":computer:\"\n\n\nrich_click.STYLE_ERRORS_SUGGESTION = \"yellow italic\"\nrich_click.SHOW_ARGUMENTS = True\nrich_click.GROUP_ARGUMENTS_OPTIONS = False\nrich_click.SHOW_METAVARS_COLUMN = True\nrich_click.USE_MARKDOWN = True\nrich_click.OPTION_GROUPS = {\n    \"dev.py\": [\n        {\n            \"name\": \"Options\",\n            \"options\": [\n                \"--help\", \"--build-dir\", \"--no-build\", \"--install-prefix\"],\n        },\n    ],\n\n    \"dev.py test\": [\n        {\n            \"name\": \"Options\",\n            \"options\": [\"--help\", \"--verbose\", \"--parallel\", \"--coverage\",\n                        \"--durations\"],\n        },\n        {\n            \"name\": \"Options: test selection\",\n            \"options\": [\"--submodule\", \"--tests\", \"--mode\"],\n        },\n    ],\n}\nrich_click.COMMAND_GROUPS = {\n    \"dev.py\": [\n        {\n            \"name\": \"build & testing\",\n            \"commands\": [\"build\", \"test\"],\n        },\n        {\n            \"name\": \"static checkers\",\n            \"commands\": [\"lint\", \"mypy\"],\n        },\n        {\n            \"name\": \"environments\",\n            \"commands\": [\"shell\", \"python\", \"ipython\", \"show_PYTHONPATH\"],\n        },\n        {\n            \"name\": \"documentation\",\n            \"commands\": [\"doc\", \"refguide-check\", \"smoke-docs\", \"smoke-tutorial\"],\n        },\n        {\n            \"name\": \"release\",\n            \"commands\": [\"notes\", \"authors\"],\n        },\n        {\n            \"name\": \"benchmarking\",\n            \"commands\": [\"bench\"],\n        },\n    ]\n}\n\n\nclass ErrorOnlyReporter(ZeroReporter):\n    desc = \"\"\"Report errors only\"\"\"\n\n    def runtime_error(self, msg):\n        console = Console()\n        console.print(\"[red bold] msg\")\n\n    def add_failure(self, task, fail_info):\n        console = Console()\n        if isinstance(fail_info, TaskError):\n            console.print(f'[red]Task Error - {task.name}'\n                          f' => {fail_info.message}')\n        if fail_info.traceback:\n            console.print(Panel(\n                \"\".join(fail_info.traceback),\n                title=f\"{task.name}\",\n                subtitle=fail_info.message,\n                border_style=\"red\",\n            ))\n\n\nCONTEXT = UnifiedContext({\n    'build_dir': Option(\n        ['--build-dir'], metavar='BUILD_DIR',\n        default='build', show_default=True,\n        help=':wrench: Relative path to the build directory.'),\n    'no_build': Option(\n        [\"--no-build\", \"-n\"], default=False, is_flag=True,\n        help=(\":wrench: Do not build the project\"\n              \" (note event python only modification require build).\")),\n    'install_prefix': Option(\n        ['--install-prefix'], default=None, metavar='INSTALL_DIR',\n        help=(\":wrench: Relative path to the install directory.\"\n              \" Default is <build-dir>-install.\")),\n})\n\n\ndef run_doit_task(tasks):\n    \"\"\"\n      :param tasks: (dict) task_name -> {options}\n    \"\"\"\n    loader = ModuleTaskLoader(globals())\n    doit_config = {\n        'verbosity': 2,\n        'reporter': ErrorOnlyReporter,\n    }\n    return run_tasks(loader, tasks, extra_config={'GLOBAL': doit_config})\n\n\nclass CLI(CliGroup):\n    context = CONTEXT\n    run_doit_task = run_doit_task\n\n\n@click.group(cls=CLI)\n@click.pass_context\ndef cli(ctx, **kwargs):\n    \"\"\"Developer Tool for SciPy\n\n    \\bCommands that require a built/installed instance are marked with :wrench:.\n\n\n    \\b**python dev.py --build-dir my-build test -s stats**\n\n    \"\"\"\n    CLI.update_context(ctx, kwargs)\n\n\nPROJECT_MODULE = \"scipy\"\nPROJECT_ROOT_FILES = ['scipy', 'LICENSE.txt', 'meson.build']\n\n\n@dataclass\nclass Dirs:\n    \"\"\"\n        root:\n            Directory where scr, build config and tools are located\n            (and this file)\n        build:\n            Directory where build output files (i.e. *.o) are saved\n        install:\n            Directory where .so from build and .py from src are put together.\n        site:\n            Directory where the built SciPy version was installed.\n            This is a custom prefix, followed by a relative path matching\n            the one the system would use for the site-packages of the active\n            Python interpreter.\n    \"\"\"\n    # all paths are absolute\n    root: Path\n    build: Path\n    installed: Path\n    site: Path  # <install>/lib/python<version>/site-packages\n\n    def __init__(self, args=None):\n        \"\"\":params args: object like Context(build_dir, install_prefix)\"\"\"\n        self.root = Path(__file__).parent.absolute()\n        if not args:\n            return\n\n        self.build = Path(args.build_dir).resolve()\n        if args.install_prefix:\n            self.installed = Path(args.install_prefix).resolve()\n        else:\n            self.installed = self.build.parent / (self.build.stem + \"-install\")\n\n        # relative path for site-package with py version\n        # i.e. 'lib/python3.10/site-packages'\n        self.site = self.get_site_packages()\n\n    def add_sys_path(self):\n        \"\"\"Add site dir to sys.path / PYTHONPATH\"\"\"\n        site_dir = str(self.site)\n        sys.path.insert(0, site_dir)\n        os.environ['PYTHONPATH'] = \\\n            os.pathsep.join((site_dir, os.environ.get('PYTHONPATH', '')))\n\n    def get_site_packages(self):\n        \"\"\"\n        Depending on whether we have debian python or not,\n        return dist_packages path or site_packages path.\n        \"\"\"\n        if sys.version_info >= (3, 12):\n            plat_path = Path(sysconfig.get_path('platlib'))\n        else:\n            # infer meson install path for python < 3.12 in\n            # debian patched python\n            if 'deb_system' in sysconfig.get_scheme_names():\n                plat_path = Path(sysconfig.get_path('platlib', 'deb_system'))\n            else:\n                plat_path = Path(sysconfig.get_path('platlib'))\n        return self.installed / plat_path.relative_to(sys.exec_prefix)\n\n\n@contextlib.contextmanager\ndef working_dir(new_dir):\n    current_dir = os.getcwd()\n    try:\n        os.chdir(new_dir)\n        yield\n    finally:\n        os.chdir(current_dir)\n\n\ndef import_module_from_path(mod_name, mod_path):\n    \"\"\"Import module with name `mod_name` from file path `mod_path`\"\"\"\n    spec = importlib.util.spec_from_file_location(mod_name, mod_path)\n    mod = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(mod)\n    return mod\n\n\ndef get_test_runner(project_module):\n    \"\"\"\n    get Test Runner from locally installed/built project\n    \"\"\"\n    __import__(project_module)\n    # scipy._lib._testutils:PytestTester\n    test = sys.modules[project_module].test\n    version = sys.modules[project_module].__version__\n    mod_path = sys.modules[project_module].__file__\n    mod_path = os.path.abspath(os.path.join(os.path.dirname(mod_path)))\n    return test, version, mod_path\n\n\n############\n\n@cli.cls_cmd('build')\nclass Build(Task):\n    \"\"\":wrench: Build & install package on path.\n\n    \\b\n    ```shell-session\n    Examples:\n\n    $ python dev.py build --asan ;\n        ASAN_OPTIONS=detect_leaks=0:symbolize=1:strict_init_order=true\n        LD_PRELOAD=$(gcc --print-file-name=libasan.so)\n        python dev.py test -v -t\n        ./scipy/ndimage/tests/test_morphology.py -- -s\n    ```\n    \"\"\"\n    ctx = CONTEXT\n\n    werror = Option(\n        ['--werror'], default=False, is_flag=True,\n        help=\"Treat warnings as errors\")\n    gcov = Option(\n        ['--gcov'], default=False, is_flag=True,\n        help=\"enable C code coverage via gcov (requires GCC).\"\n             \"gcov output goes to build/**/*.gc*\")\n    asan = Option(\n        ['--asan'], default=False, is_flag=True,\n        help=(\"Build and run with AddressSanitizer support. \"\n              \"Note: the build system doesn't check whether \"\n              \"the project is already compiled with ASan. \"\n              \"If not, you need to do a clean build (delete \"\n              \"build and build-install directories).\"))\n    debug = Option(\n        ['--debug', '-d'], default=False, is_flag=True, help=\"Debug build\")\n    release = Option(\n        ['--release', '-r'], default=False, is_flag=True, help=\"Release build\")\n    parallel = Option(\n        ['--parallel', '-j'], default=None, metavar='N_JOBS',\n        help=(\"Number of parallel jobs for building. \"\n              \"This defaults to the number of available physical CPU cores\"))\n    setup_args = Option(\n        ['--setup-args', '-C'], default=[], multiple=True,\n        help=(\"Pass along one or more arguments to `meson setup` \"\n              \"Repeat the `-C` in case of multiple arguments.\"))\n    show_build_log = Option(\n        ['--show-build-log'], default=False, is_flag=True,\n        help=\"Show build output rather than using a log file\")\n    with_scipy_openblas = Option(\n        ['--with-scipy-openblas'], default=False, is_flag=True,\n        help=(\"If set, use the `scipy-openblas32` wheel installed into the \"\n              \"current environment as the BLAS/LAPACK to build against.\"))\n    with_accelerate = Option(\n        ['--with-accelerate'], default=False, is_flag=True,\n        help=(\"If set, use `Accelerate` as the BLAS/LAPACK to build against.\"\n              \" Takes precedence over -with-scipy-openblas (macOS only)\")\n    )\n    tags = Option(\n        ['--tags'], default=\"runtime,python-runtime,tests,devel\",\n        show_default=True, help=\"Install tags to be used by meson.\"\n    )\n\n    @classmethod\n    def setup_build(cls, dirs, args):\n        \"\"\"\n        Setting up meson-build\n        \"\"\"\n        for fn in PROJECT_ROOT_FILES:\n            if not (dirs.root / fn).exists():\n                print(\"To build the project, run dev.py in \"\n                      \"git checkout or unpacked source\")\n                sys.exit(1)\n\n        env = dict(os.environ)\n        cmd = [\"meson\", \"setup\", dirs.build, \"--prefix\", dirs.installed]\n        build_dir = dirs.build\n        run_dir = Path()\n        if build_dir.exists() and not (build_dir / 'meson-info').exists():\n            if list(build_dir.iterdir()):\n                raise RuntimeError(\"Can't build into non-empty directory \"\n                                   f\"'{build_dir.absolute()}'\")\n\n        if sys.platform == \"cygwin\":\n            # Cygwin only has netlib lapack, but can link against\n            # OpenBLAS rather than netlib blas at runtime.  There is\n            # no libopenblas-devel to enable linking against\n            # openblas-specific functions or OpenBLAS Lapack\n            cmd.extend([\"-Dlapack=lapack\", \"-Dblas=blas\"])\n\n        build_options_file = (\n            build_dir / \"meson-info\" / \"intro-buildoptions.json\")\n        if build_options_file.exists():\n            with open(build_options_file) as f:\n                build_options = json.load(f)\n            installdir = None\n            for option in build_options:\n                if option[\"name\"] == \"prefix\":\n                    installdir = option[\"value\"]\n                    break\n            if installdir != str(dirs.installed):\n                run_dir = build_dir\n                cmd = [\"meson\", \"setup\", \"--reconfigure\",\n                       \"--prefix\", str(dirs.installed)]\n            else:\n                return\n        if args.werror:\n            cmd += [\"--werror\"]\n        if args.debug or args.release:\n            if args.debug and args.release:\n                raise ValueError(\"Set at most one of `--debug` and `--release`!\")\n            if args.debug:\n                buildtype = 'debug'\n                cflags_unwanted = ('-O1', '-O2', '-O3')\n            elif args.release:\n                buildtype = 'release'\n                cflags_unwanted = ('-O0', '-O1', '-O2')\n            cmd += [f\"-Dbuildtype={buildtype}\"]\n            if 'CFLAGS' in os.environ.keys():\n                # Check that CFLAGS doesn't contain something that supercedes -O0\n                # for a plain debug build (conda envs tend to set -O2)\n                cflags = os.environ['CFLAGS'].split()\n                for flag in cflags_unwanted:\n                    if flag in cflags:\n                        raise ValueError(f\"A {buildtype} build isn't possible, \"\n                                         f\"because CFLAGS contains `{flag}`.\"\n                                          \"Please also check CXXFLAGS and FFLAGS.\")\n        if args.gcov:\n            cmd += ['-Db_coverage=true']\n        if args.asan:\n            cmd += ['-Db_sanitize=address,undefined']\n        if args.setup_args:\n            cmd += [str(arg) for arg in args.setup_args]\n        if args.with_accelerate:\n            # on a mac you probably want to use accelerate over scipy_openblas\n            cmd += [\"-Dblas=accelerate\"]\n        elif args.with_scipy_openblas:\n            cls.configure_scipy_openblas()\n            env['PKG_CONFIG_PATH'] = os.pathsep.join([\n                    os.getcwd(),\n                    env.get('PKG_CONFIG_PATH', '')\n                    ])\n\n        # Setting up meson build\n        cmd_str = ' '.join([str(p) for p in cmd])\n        cls.console.print(f\"{EMOJI.cmd} [cmd] {cmd_str}\")\n        ret = subprocess.call(cmd, env=env, cwd=run_dir)\n        if ret == 0:\n            print(\"Meson build setup OK\")\n        else:\n            print(\"Meson build setup failed!\")\n            sys.exit(1)\n        return env\n\n    @classmethod\n    def build_project(cls, dirs, args, env):\n        \"\"\"\n        Build a dev version of the project.\n        \"\"\"\n        cmd = [\"ninja\", \"-C\", str(dirs.build)]\n        if args.parallel is None:\n            # Use number of physical cores rather than ninja's default of 2N+2,\n            # to avoid out of memory issues (see gh-17941 and gh-18443)\n            n_cores = cpu_count(only_physical_cores=True)\n            cmd += [f\"-j{n_cores}\"]\n        else:\n            cmd += [\"-j\", str(args.parallel)]\n\n        # Building with ninja-backend\n        cmd_str = ' '.join([str(p) for p in cmd])\n        cls.console.print(f\"{EMOJI.cmd} [cmd] {cmd_str}\")\n        ret = subprocess.call(cmd, env=env, cwd=dirs.root)\n\n        if ret == 0:\n            print(\"Build OK\")\n        else:\n            print(\"Build failed!\")\n            sys.exit(1)\n\n    @classmethod\n    def install_project(cls, dirs, args):\n        \"\"\"\n        Installs the project after building.\n        \"\"\"\n        if dirs.installed.exists():\n            non_empty = len(os.listdir(dirs.installed))\n            if non_empty and not dirs.site.exists():\n                raise RuntimeError(\"Can't install in non-empty directory: \"\n                                   f\"'{dirs.installed}'\")\n        cmd = [\"meson\", \"install\", \"-C\", args.build_dir,\n               \"--only-changed\", \"--tags\", args.tags]\n        log_filename = dirs.root / 'meson-install.log'\n        start_time = datetime.datetime.now()\n        cmd_str = ' '.join([str(p) for p in cmd])\n        cls.console.print(f\"{EMOJI.cmd} [cmd] {cmd_str}\")\n        if args.show_build_log:\n            ret = subprocess.call(cmd, cwd=dirs.root)\n        else:\n            print(\"Installing, see meson-install.log...\")\n            with open(log_filename, 'w') as log:\n                p = subprocess.Popen(cmd, stdout=log, stderr=log,\n                                     cwd=dirs.root)\n\n            try:\n                # Wait for it to finish, and print something to indicate the\n                # process is alive, but only if the log file has grown (to\n                # allow continuous integration environments kill a hanging\n                # process accurately if it produces no output)\n                last_blip = time.time()\n                last_log_size = os.stat(log_filename).st_size\n                while p.poll() is None:\n                    time.sleep(0.5)\n                    if time.time() - last_blip > 60:\n                        log_size = os.stat(log_filename).st_size\n                        if log_size > last_log_size:\n                            elapsed = datetime.datetime.now() - start_time\n                            print(f\"    ... installation in progress ({elapsed} \"\n                                  \"elapsed)\")\n                            last_blip = time.time()\n                            last_log_size = log_size\n\n                ret = p.wait()\n            except:  # noqa: E722\n                p.terminate()\n                raise\n        elapsed = datetime.datetime.now() - start_time\n\n        if ret != 0:\n            if not args.show_build_log:\n                with open(log_filename) as f:\n                    print(f.read())\n            print(f\"Installation failed! ({elapsed} elapsed)\")\n            sys.exit(1)\n\n        # ignore everything in the install directory.\n        with open(dirs.installed / \".gitignore\", \"w\") as f:\n            f.write(\"*\")\n\n        if sys.platform == \"cygwin\":\n            rebase_cmd = [\"/usr/bin/rebase\", \"--database\", \"--oblivious\"]\n            rebase_cmd.extend(Path(dirs.installed).glob(\"**/*.dll\"))\n            subprocess.check_call(rebase_cmd)\n\n        print(\"Installation OK\")\n        return\n\n    @classmethod\n    def configure_scipy_openblas(self, blas_variant='32'):\n        \"\"\"Create scipy-openblas.pc and scipy/_distributor_init_local.py\n\n        Requires a pre-installed scipy-openblas32 wheel from PyPI.\n        \"\"\"\n        basedir = os.getcwd()\n        pkg_config_fname = os.path.join(basedir, \"scipy-openblas.pc\")\n\n        if os.path.exists(pkg_config_fname):\n            return None\n\n        module_name = f\"scipy_openblas{blas_variant}\"\n        try:\n            openblas = importlib.import_module(module_name)\n        except ModuleNotFoundError:\n            raise RuntimeError(f\"Importing '{module_name}' failed. \"\n                               \"Make sure it is installed and reachable \"\n                               \"by the current Python executable. You can \"\n                               f\"install it via 'pip install {module_name}'.\")\n\n        local = os.path.join(basedir, \"scipy\", \"_distributor_init_local.py\")\n        with open(local, \"w\", encoding=\"utf8\") as fid:\n            fid.write(f\"import {module_name}\\n\")\n\n        with open(pkg_config_fname, \"w\", encoding=\"utf8\") as fid:\n            fid.write(openblas.get_pkg_config())\n\n    @classmethod\n    def run(cls, add_path=False, **kwargs):\n        kwargs.update(cls.ctx.get(kwargs))\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n\n        cls.console = Console(theme=console_theme)\n        dirs = Dirs(args)\n        if args.no_build:\n            print(\"Skipping build\")\n        else:\n            env = cls.setup_build(dirs, args)\n            cls.build_project(dirs, args, env)\n            cls.install_project(dirs, args)\n\n        # add site to sys.path\n        if add_path:\n            dirs.add_sys_path()\n\n\n@cli.cls_cmd('test')\nclass Test(Task):\n    \"\"\":wrench: Run tests.\n\n    \\b\n    ```python\n    Examples:\n\n    $ python dev.py test -s {SAMPLE_SUBMODULE}\n    $ python dev.py test -t scipy.optimize.tests.test_minimize_constrained\n    $ python dev.py test -s cluster -m full --durations 20\n    $ python dev.py test -s stats -- --tb=line  # `--` passes next args to pytest\n    $ python dev.py test -b numpy -b torch -s cluster\n    ```\n    \"\"\"\n    ctx = CONTEXT\n\n    verbose = Option(\n        ['--verbose', '-v'], default=False, is_flag=True,\n        help=\"more verbosity\")\n    # removed doctests as currently not supported by _lib/_testutils.py\n    # doctests = Option(['--doctests'], default=False)\n    coverage = Option(\n        ['--coverage', '-c'], default=False, is_flag=True,\n        help=(\"report coverage of project code. \"\n              \"HTML output goes under build/coverage\"))\n    durations = Option(\n        ['--durations', '-d'], default=None, metavar=\"NUM_TESTS\",\n        help=\"Show timing for the given number of slowest tests\"\n    )\n    submodule = Option(\n        ['--submodule', '-s'], default=None, metavar='MODULE_NAME',\n        help=\"Submodule whose tests to run (cluster, constants, ...)\")\n    tests = Option(\n        ['--tests', '-t'], default=None, multiple=True, metavar='TESTS',\n        help='Specify tests to run')\n    mode = Option(\n        ['--mode', '-m'], default='fast', metavar='MODE', show_default=True,\n        help=(\"'fast', 'full', or something that could be passed to \"\n              \"`pytest -m` as a marker expression\"))\n    parallel = Option(\n        ['--parallel', '-j'], default=1, metavar='N_JOBS',\n        help=\"Number of parallel jobs for testing\"\n    )\n    array_api_backend = Option(\n        ['--array-api-backend', '-b'], default=None, metavar='ARRAY_BACKEND',\n        multiple=True,\n        help=(\n            \"Array API backend \"\n            \"('all', 'numpy', 'torch', 'cupy', 'array_api_strict', 'jax.numpy').\"\n        )\n    )\n    # Argument can't have `help=`; used to consume all of `-- arg1 arg2 arg3`\n    pytest_args = Argument(\n        ['pytest_args'], nargs=-1, metavar='PYTEST-ARGS', required=False\n    )\n\n    TASK_META = {\n        'task_dep': ['build'],\n    }\n\n    @staticmethod\n    def run_lcov(dirs):\n        print(\"Capturing lcov info...\")\n        LCOV_OUTPUT_FILE = os.path.join(dirs.build, \"lcov.info\")\n        LCOV_OUTPUT_DIR = os.path.join(dirs.build, \"lcov\")\n        BUILD_DIR = str(dirs.build)\n\n        try:\n            os.unlink(LCOV_OUTPUT_FILE)\n        except OSError:\n            pass\n        try:\n            shutil.rmtree(LCOV_OUTPUT_DIR)\n        except OSError:\n            pass\n\n        lcov_cmd = [\n            \"lcov\", \"--capture\",\n            \"--directory\", BUILD_DIR,\n            \"--output-file\", LCOV_OUTPUT_FILE,\n            \"--no-external\"]\n        lcov_cmd_str = \" \".join(lcov_cmd)\n        emit_cmdstr(\" \".join(lcov_cmd))\n        try:\n            subprocess.call(lcov_cmd)\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                print(f\"Error when running '{lcov_cmd_str}': {err}\\n\"\n                    \"You need to install LCOV (https://lcov.readthedocs.io/en/latest/) \"\n                    \"to capture test coverage of C/C++/Fortran code in SciPy.\")\n                return False\n            raise\n\n        print(\"Generating lcov HTML output...\")\n        genhtml_cmd = [\n            \"genhtml\", \"-q\", LCOV_OUTPUT_FILE,\n            \"--output-directory\", LCOV_OUTPUT_DIR,\n            \"--legend\", \"--highlight\"]\n        emit_cmdstr(genhtml_cmd)\n        ret = subprocess.call(genhtml_cmd)\n        if ret != 0:\n            print(\"genhtml failed!\")\n        else:\n            print(\"HTML output generated under build/lcov/\")\n\n        return ret == 0\n\n    @classmethod\n    def scipy_tests(cls, args, pytest_args):\n        dirs = Dirs(args)\n        dirs.add_sys_path()\n        print(f\"SciPy from development installed path at: {dirs.site}\")\n\n        # FIXME: support pos-args with doit\n        extra_argv = list(pytest_args[:]) if pytest_args else []\n        if extra_argv and extra_argv[0] == '--':\n            extra_argv = extra_argv[1:]\n\n        if args.coverage:\n            dst_dir = dirs.root / args.build_dir / 'coverage'\n            fn = dst_dir / 'coverage_html.js'\n            if dst_dir.is_dir() and fn.is_file():\n                shutil.rmtree(dst_dir)\n            extra_argv += ['--cov-report=html:' + str(dst_dir)]\n            shutil.copyfile(dirs.root / '.coveragerc',\n                            dirs.site / '.coveragerc')\n\n        if args.durations:\n            extra_argv += ['--durations', args.durations]\n\n        # convert options to test selection\n        if args.submodule:\n            tests = [PROJECT_MODULE + \".\" + args.submodule]\n        elif args.tests:\n            tests = args.tests\n        else:\n            tests = None\n\n        if len(args.array_api_backend) != 0:\n            os.environ['SCIPY_ARRAY_API'] = json.dumps(list(args.array_api_backend))\n\n        runner, version, mod_path = get_test_runner(PROJECT_MODULE)\n        # FIXME: changing CWD is not a good practice\n        with working_dir(dirs.site):\n            print(f\"Running tests for {PROJECT_MODULE} version:{version}, \"\n                  f\"installed at:{mod_path}\")\n            # runner verbosity - convert bool to int\n            verbose = int(args.verbose) + 1\n\n            was_built_with_gcov_flag = len(list(dirs.build.rglob(\"*.gcno\"))) > 0\n            if was_built_with_gcov_flag:\n                config = importlib.import_module(\"scipy.__config__\").show(mode='dicts')\n                compilers_config = config['Compilers']\n                cpp = compilers_config['c++']['name']\n                c = compilers_config['c']['name']\n                fortran = compilers_config['fortran']['name']\n                if not (c == 'gcc' and cpp == 'gcc' and fortran == 'gcc'):\n                    print(\"SciPy was built with --gcov flag which requires \"\n                          \"LCOV while running tests.\\nFurther, LCOV usage \"\n                          \"requires GCC for C, C++ and Fortran codes in SciPy.\\n\"\n                          \"Compilers used currently are:\\n\"\n                          f\"  C: {c}\\n  C++: {cpp}\\n  Fortran: {fortran}\\n\"\n                          \"Therefore, exiting without running tests.\")\n                    exit(1) # Exit because tests will give missing symbol error\n            result = runner(  # scipy._lib._testutils:PytestTester\n                args.mode,\n                verbose=verbose,\n                extra_argv=extra_argv,\n                doctests=False,\n                coverage=args.coverage,\n                tests=tests,\n                parallel=args.parallel)\n            if args.coverage and was_built_with_gcov_flag:\n                if not result:\n                    print(\"Tests should succeed to generate \"\n                          \"coverage reports using LCOV\")\n                else:\n                    return cls.run_lcov(dirs)\n        return result\n\n    @classmethod\n    def run(cls, pytest_args, **kwargs):\n        \"\"\"run unit-tests\"\"\"\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        return cls.scipy_tests(args, pytest_args)\n\n\n@cli.cls_cmd('smoke-docs')\nclass SmokeDocs(Task):\n    # XXX This essntially is a copy-paste of the Task class. Consider de-duplicating.\n    ctx = CONTEXT\n\n    verbose = Option(\n        ['--verbose', '-v'], default=False, is_flag=True,\n        help=\"more verbosity\")\n    durations = Option(\n        ['--durations', '-d'], default=None, metavar=\"NUM_TESTS\",\n        help=\"Show timing for the given number of slowest tests\"\n    )\n    submodule = Option(\n        ['--submodule', '-s'], default=None, metavar='MODULE_NAME',\n        help=\"Submodule whose tests to run (cluster, constants, ...)\")\n    tests = Option(\n        ['--tests', '-t'], default=None, multiple=True, metavar='TESTS',\n        help='Specify tests to run')\n    parallel = Option(\n        ['--parallel', '-j'], default=1, metavar='N_JOBS',\n        help=\"Number of parallel jobs for testing\"\n    )\n    # Argument can't have `help=`; used to consume all of `-- arg1 arg2 arg3`\n    pytest_args = Argument(\n        ['pytest_args'], nargs=-1, metavar='PYTEST-ARGS', required=False\n    )\n\n    TASK_META = {\n        'task_dep': ['build'],\n    }\n\n    @classmethod\n    def scipy_tests(cls, args, pytest_args):\n        dirs = Dirs(args)\n        dirs.add_sys_path()\n        print(f\"SciPy from development installed path at: {dirs.site}\")\n\n        # prevent obscure error later; cf https://github.com/numpy/numpy/pull/26691/\n        if not importlib.util.find_spec(\"scipy_doctest\"):\n            raise ModuleNotFoundError(\"Please install scipy-doctest\")\n\n        # FIXME: support pos-args with doit\n        extra_argv = list(pytest_args[:]) if pytest_args else []\n        if extra_argv and extra_argv[0] == '--':\n            extra_argv = extra_argv[1:]\n\n        if args.durations:\n            extra_argv += ['--durations', args.durations]\n\n        # convert options to test selection\n        if args.submodule:\n            tests = [PROJECT_MODULE + \".\" + args.submodule]\n        elif args.tests:\n            tests = args.tests\n        else:\n            tests = None\n\n        # Request doctesting; use strategy=api unless -t path/to/specific/file\n        # also switch off assertion rewriting: not useful for doctests\n        extra_argv += [\"--doctest-modules\", \"--assert=plain\"]\n        if not args.tests:\n            extra_argv += ['--doctest-collect=api']\n\n        runner, version, mod_path = get_test_runner(PROJECT_MODULE)\n        # FIXME: changing CWD is not a good practice\n        with working_dir(dirs.site):\n            print(f\"Running tests for {PROJECT_MODULE} version:{version}, \"\n                  f\"installed at:{mod_path}\")\n            # runner verbosity - convert bool to int\n            verbose = int(args.verbose) + 1\n            result = runner(  # scipy._lib._testutils:PytestTester\n                \"fast\",\n                verbose=verbose,\n                extra_argv=extra_argv,\n                doctests=True,\n                coverage=False,\n                tests=tests,\n                parallel=args.parallel)\n        return result\n\n    @classmethod\n    def run(cls, pytest_args, **kwargs):\n        \"\"\"run unit-tests\"\"\"\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        return cls.scipy_tests(args, pytest_args)\n\n\n@cli.cls_cmd('smoke-tutorials')\nclass SmokeTutorials(Task):\n    \"\"\":wrench: Run smoke-tests on tutorial files.\"\"\"\n    ctx = CONTEXT\n\n    tests = Option(\n        ['--tests', '-t'], default=None, multiple=True, metavar='TESTS',\n        help='Specify *rst files to smoke test')\n    verbose = Option(\n        ['--verbose', '-v'], default=False, is_flag=True, help=\"verbosity\")\n\n    pytest_args = Argument(\n        ['pytest_args'], nargs=-1, metavar='PYTEST-ARGS', required=False\n    )\n\n    @classmethod\n    def task_meta(cls, **kwargs):\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        dirs = Dirs(args)\n\n        cmd = ['pytest']\n        if args.tests:\n            cmd += list(args.tests)\n        else:\n            cmd += ['doc/source/tutorial', '--doctest-glob=*rst']\n        if args.verbose:\n            cmd += ['-v']\n\n        pytest_args = kwargs.pop('pytest_args', None)\n        extra_argv = list(pytest_args[:]) if pytest_args else []\n        if extra_argv and extra_argv[0] == '--':\n            extra_argv = extra_argv[1:]\n        cmd += extra_argv\n\n        cmd_str = ' '.join(cmd)\n        return {\n            'actions': [f'env PYTHONPATH={dirs.site} {cmd_str}'],\n            'task_dep': ['build'],\n            'io': {'capture': False},\n        }\n\n\n@cli.cls_cmd('bench')\nclass Bench(Task):\n    \"\"\":wrench: Run benchmarks.\n\n    \\b\n    ```python\n     Examples:\n\n    $ python dev.py bench -t integrate.SolveBVP\n    $ python dev.py bench -t linalg.Norm\n    $ python dev.py bench --compare main\n    ```\n    \"\"\"\n    ctx = CONTEXT\n    TASK_META = {\n        'task_dep': ['build'],\n    }\n    submodule = Option(\n        ['--submodule', '-s'], default=None, metavar='SUBMODULE',\n        help=\"Submodule whose tests to run (cluster, constants, ...)\")\n    tests = Option(\n        ['--tests', '-t'], default=None, multiple=True,\n        metavar='TESTS', help='Specify tests to run')\n    compare = Option(\n        ['--compare', '-c'], default=None, metavar='COMPARE', multiple=True,\n        help=(\n            \"Compare benchmark results of current HEAD to BEFORE. \"\n            \"Use an additional --bench COMMIT to override HEAD with COMMIT. \"\n            \"Note that you need to commit your changes first!\"))\n\n    @staticmethod\n    def run_asv(dirs, cmd):\n        EXTRA_PATH = ['/usr/lib/ccache', '/usr/lib/f90cache',\n                      '/usr/local/lib/ccache', '/usr/local/lib/f90cache']\n        bench_dir = dirs.root / 'benchmarks'\n        sys.path.insert(0, str(bench_dir))\n        # Always use ccache, if installed\n        env = dict(os.environ)\n        env['PATH'] = os.pathsep.join(EXTRA_PATH +\n                                      env.get('PATH', '').split(os.pathsep))\n        # Control BLAS/LAPACK threads\n        env['OPENBLAS_NUM_THREADS'] = '1'\n        env['MKL_NUM_THREADS'] = '1'\n\n        # Limit memory usage\n        from benchmarks.common import set_mem_rlimit\n        try:\n            set_mem_rlimit()\n        except (ImportError, RuntimeError):\n            pass\n        try:\n            return subprocess.call(cmd, env=env, cwd=bench_dir)\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                cmd_str = \" \".join(cmd)\n                print(f\"Error when running '{cmd_str}': {err}\\n\")\n                print(\"You need to install Airspeed Velocity \"\n                      \"(https://airspeed-velocity.github.io/asv/)\")\n                print(\"to run Scipy benchmarks\")\n                return 1\n            raise\n\n    @classmethod\n    def scipy_bench(cls, args):\n        dirs = Dirs(args)\n        dirs.add_sys_path()\n        print(f\"SciPy from development installed path at: {dirs.site}\")\n        with working_dir(dirs.site):\n            runner, version, mod_path = get_test_runner(PROJECT_MODULE)\n            extra_argv = []\n            if args.tests:\n                extra_argv.append(args.tests)\n            if args.submodule:\n                extra_argv.append([args.submodule])\n\n            bench_args = []\n            for a in extra_argv:\n                bench_args.extend(['--bench', ' '.join(str(x) for x in a)])\n            if not args.compare:\n                print(f\"Running benchmarks for Scipy version {version} at {mod_path}\")\n                cmd = ['asv', 'run', '--dry-run', '--show-stderr',\n                       '--python=same', '--quick'] + bench_args\n                retval = cls.run_asv(dirs, cmd)\n                sys.exit(retval)\n            else:\n                if len(args.compare) == 1:\n                    commit_a = args.compare[0]\n                    commit_b = 'HEAD'\n                elif len(args.compare) == 2:\n                    commit_a, commit_b = args.compare\n                else:\n                    print(\"Too many commits to compare benchmarks for\")\n                # Check for uncommitted files\n                if commit_b == 'HEAD':\n                    r1 = subprocess.call(['git', 'diff-index', '--quiet',\n                                          '--cached', 'HEAD'])\n                    r2 = subprocess.call(['git', 'diff-files', '--quiet'])\n                    if r1 != 0 or r2 != 0:\n                        print(\"*\" * 80)\n                        print(\"WARNING: you have uncommitted changes --- \"\n                              \"these will NOT be benchmarked!\")\n                        print(\"*\" * 80)\n\n                # Fix commit ids (HEAD is local to current repo)\n                p = subprocess.Popen(['git', 'rev-parse', commit_b],\n                                     stdout=subprocess.PIPE)\n                out, err = p.communicate()\n                commit_b = out.strip()\n\n                p = subprocess.Popen(['git', 'rev-parse', commit_a],\n                                     stdout=subprocess.PIPE)\n                out, err = p.communicate()\n                commit_a = out.strip()\n                cmd_compare = [\n                    'asv', 'continuous', '--show-stderr', '--factor', '1.05',\n                    '--quick', commit_a, commit_b\n                ] + bench_args\n                cls.run_asv(dirs, cmd_compare)\n                sys.exit(1)\n\n    @classmethod\n    def run(cls, **kwargs):\n        \"\"\"run benchmark\"\"\"\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        cls.scipy_bench(args)\n\n\n###################\n# linters\n\ndef emit_cmdstr(cmd):\n    \"\"\"Print the command that's being run to stdout\n\n    Note: cannot use this in the below tasks (yet), because as is these command\n    strings are always echoed to the console, even if the command isn't run\n    (but for example the `build` command is run).\n    \"\"\"\n    console = Console(theme=console_theme)\n    # The [cmd] square brackets controls the font styling, typically in italics\n    # to differentiate it from other stdout content\n    console.print(f\"{EMOJI.cmd} [cmd] {cmd}\")\n\n\n@task_params([{\"name\": \"fix\", \"default\": False}, {\"name\": \"all\", \"default\": False}])\ndef task_lint(fix, all):\n    # Lint just the diff since branching off of main using a\n    # stricter configuration.\n    # emit_cmdstr(os.path.join('tools', 'lint.py') + ' --diff-against main')\n    cmd = str(Dirs().root / 'tools' / 'lint.py') + ' --diff-against=main'\n    if fix:\n        cmd += ' --fix'\n    if all:\n        cmd += ' --all'\n    return {\n        'basename': 'lint',\n        'actions': [cmd],\n        'doc': 'Lint only files modified since last commit (stricter rules)',\n    }\n\n@task_params([])\ndef task_check_python_h_first():\n    # Lint just the diff since branching off of main using a\n    # stricter configuration.\n    # emit_cmdstr(os.path.join('tools', 'lint.py') + ' --diff-against main')\n    cmd = \"{!s} --diff-against=main\".format(\n        Dirs().root / 'tools' / 'check_python_h_first.py'\n    )\n    return {\n        'basename': 'check_python_h_first',\n        'actions': [cmd],\n        'doc': (\n            'Check Python.h order only files modified since last commit '\n            '(stricter rules)'\n        ),\n    }\n\n\ndef task_check_unicode():\n    # emit_cmdstr(os.path.join('tools', 'check_unicode.py'))\n    return {\n        'basename': 'check_unicode',\n        'actions': [str(Dirs().root / 'tools' / 'check_unicode.py')],\n        'doc': 'Check for disallowed Unicode characters in the SciPy Python '\n               'and Cython source code.',\n    }\n\n\ndef task_check_test_name():\n    # emit_cmdstr(os.path.join('tools', 'check_test_name.py'))\n    return {\n        \"basename\": \"check_testname\",\n        \"actions\": [str(Dirs().root / \"tools\" / \"check_test_name.py\")],\n        \"doc\": \"Check tests are correctly named so that pytest runs them.\"\n    }\n\n\n@cli.cls_cmd('lint')\nclass Lint:\n    \"\"\":dash: Run linter on modified (or all) files and check for\n    disallowed Unicode characters and possibly-invalid test names.\"\"\"\n    fix = Option(\n        ['--fix'], default=False, is_flag=True, help='Attempt to auto-fix errors'\n    )\n    all = Option(\n        ['--all'], default=False, is_flag=True,\n        help='lint all files instead of just modified files.'\n    )\n\n    @classmethod\n    def run(cls, fix, all):\n        run_doit_task({\n            'lint': {'fix': fix, 'all': all},\n            'check_unicode': {},\n            'check_testname': {},\n            'check_python_h_first': {},\n        })\n\n\n@cli.cls_cmd('mypy')\nclass Mypy(Task):\n    \"\"\":wrench: Run mypy on the codebase.\"\"\"\n    ctx = CONTEXT\n\n    TASK_META = {\n        'task_dep': ['build'],\n    }\n\n    @classmethod\n    def run(cls, **kwargs):\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        dirs = Dirs(args)\n\n        try:\n            import mypy.api\n        except ImportError as e:\n            raise RuntimeError(\n                \"Mypy not found. Please install it by running \"\n                \"pip install -r mypy_requirements.txt from the repo root\"\n            ) from e\n\n        config = dirs.root / \"mypy.ini\"\n        check_path = PROJECT_MODULE\n\n        with working_dir(dirs.site):\n            # By default mypy won't color the output since it isn't being\n            # invoked from a tty.\n            os.environ['MYPY_FORCE_COLOR'] = '1'\n            # Change to the site directory to make sure mypy doesn't pick\n            # up any type stubs in the source tree.\n            emit_cmdstr(f\"mypy.api.run --config-file {config} {check_path}\")\n            report, errors, status = mypy.api.run([\n                \"--config-file\",\n                str(config),\n                check_path,\n            ])\n        print(report, end='')\n        print(errors, end='', file=sys.stderr)\n        return status == 0\n\n\n##########################################\n# DOC\n\n@cli.cls_cmd('doc')\nclass Doc(Task):\n    \"\"\":wrench: Build documentation.\n\n    TARGETS: Sphinx build targets [default: 'html']\n\n    Running `python dev.py doc -j8 html` is equivalent to:\n    1. Execute build command (skip by passing the global `-n` option).\n    2. Set the PYTHONPATH environment variable\n       (query with `python dev.py -n show_PYTHONPATH`).\n    3. Run make on `doc/Makefile`, i.e.: `make -C doc -j8 TARGETS`\n\n    To remove all generated documentation do: `python dev.py -n doc clean`\n    \"\"\"\n    ctx = CONTEXT\n\n    args = Argument(['args'], nargs=-1, metavar='TARGETS', required=False)\n    list_targets = Option(\n        ['--list-targets', '-t'], default=False, is_flag=True,\n        help='List doc targets',\n    )\n    parallel = Option(\n        ['--parallel', '-j'], default=1, metavar='N_JOBS',\n        help=\"Number of parallel jobs\"\n    )\n    no_cache = Option(\n        ['--no-cache'], default=False, is_flag=True,\n        help=\"Forces a full rebuild of the docs. Note that this may be \" + \\\n             \"needed in order to make docstring changes in C/Cython files \" + \\\n             \"show up.\"\n    )\n\n    @classmethod\n    def task_meta(cls, list_targets, parallel, no_cache, args, **kwargs):\n        if list_targets:  # list MAKE targets, remove default target\n            task_dep = []\n            targets = ''\n        else:\n            task_dep = ['build']\n            targets = ' '.join(args) if args else 'html'\n\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        build_args = Args(**kwargs)\n        dirs = Dirs(build_args)\n\n        make_params = [f'PYTHON=\"{sys.executable}\"']\n        if parallel or no_cache:\n            sphinxopts = \"\"\n            if parallel:\n                sphinxopts += f\"-j{parallel} \"\n            if no_cache:\n                sphinxopts += \"-E\"\n            make_params.append(f'SPHINXOPTS=\"{sphinxopts}\"')\n\n        return {\n            'actions': [\n                # move to doc/ so local scipy does not get imported\n                (f'cd doc; env PYTHONPATH=\"{dirs.site}\" '\n                 f'make {\" \".join(make_params)} {targets}'),\n            ],\n            'task_dep': task_dep,\n            'io': {'capture': False},\n        }\n\n\n@cli.cls_cmd('refguide-check')\nclass RefguideCheck(Task):\n    \"\"\":wrench: Run refguide check.\"\"\"\n    ctx = CONTEXT\n\n    submodule = Option(\n        ['--submodule', '-s'], default=None, metavar='SUBMODULE',\n        help=\"Submodule whose tests to run (cluster, constants, ...)\")\n    verbose = Option(\n        ['--verbose', '-v'], default=False, is_flag=True, help=\"verbosity\")\n\n    @classmethod\n    def task_meta(cls, **kwargs):\n        kwargs.update(cls.ctx.get())\n        Args = namedtuple('Args', [k for k in kwargs.keys()])\n        args = Args(**kwargs)\n        dirs = Dirs(args)\n\n        cmd = [f'{sys.executable}',\n               str(dirs.root / 'tools' / 'refguide_check.py')]\n        if args.verbose:\n            cmd += ['-vvv']\n        if args.submodule:\n            cmd += [args.submodule]\n        cmd_str = ' '.join(cmd)\n        return {\n            'actions': [f'env PYTHONPATH={dirs.site} {cmd_str}'],\n            'task_dep': ['build'],\n            'io': {'capture': False},\n        }\n\n\n##########################################\n# ENVS\n\n@cli.cls_cmd('python')\nclass Python:\n    \"\"\":wrench: Start a Python shell with PYTHONPATH set.\n\n    ARGS: Arguments passed to the Python interpreter.\n          If not set, an interactive shell is launched.\n\n    Running `python dev.py shell my_script.py` is equivalent to:\n    1. Execute build command (skip by passing the global `-n` option).\n    2. Set the PYTHONPATH environment variable\n       (query with `python dev.py -n show_PYTHONPATH`).\n    3. Run interpreter: `python my_script.py`\n    \"\"\"\n    ctx = CONTEXT\n    pythonpath = Option(\n        ['--pythonpath', '-p'], metavar='PYTHONPATH', default=None,\n        help='Paths to prepend to PYTHONPATH')\n    extra_argv = Argument(\n        ['extra_argv'], nargs=-1, metavar='ARGS', required=False)\n\n    @classmethod\n    def _setup(cls, pythonpath, **kwargs):\n        vals = Build.opt_defaults()\n        vals.update(kwargs)\n        Build.run(add_path=True, **vals)\n        if pythonpath:\n            for p in reversed(pythonpath.split(os.pathsep)):\n                sys.path.insert(0, p)\n\n    @classmethod\n    def run(cls, pythonpath, extra_argv=None, **kwargs):\n        cls._setup(pythonpath, **kwargs)\n        if extra_argv:\n            # Don't use subprocess, since we don't want to include the\n            # current path in PYTHONPATH.\n            sys.argv = extra_argv\n            with open(extra_argv[0]) as f:\n                script = f.read()\n            sys.modules['__main__'] = new_module('__main__')\n            ns = dict(__name__='__main__', __file__=extra_argv[0])\n            exec(script, ns)\n        else:\n            import code\n            code.interact()\n\n\n@cli.cls_cmd('ipython')\nclass Ipython(Python):\n    \"\"\":wrench: Start IPython shell with PYTHONPATH set.\n\n    Running `python dev.py ipython` is equivalent to:\n    1. Execute build command (skip by passing the global `-n` option).\n    2. Set the PYTHONPATH environment variable\n       (query with `python dev.py -n show_PYTHONPATH`).\n    3. Run the `ipython` interpreter.\n    \"\"\"\n    ctx = CONTEXT\n    pythonpath = Python.pythonpath\n\n    @classmethod\n    def run(cls, pythonpath, **kwargs):\n        cls._setup(pythonpath, **kwargs)\n        import IPython\n        IPython.embed(user_ns={})\n\n\n@cli.cls_cmd('shell')\nclass Shell(Python):\n    \"\"\":wrench: Start Unix shell with PYTHONPATH set.\n\n    Running `python dev.py shell` is equivalent to:\n    1. Execute build command (skip by passing the global `-n` option).\n    2. Open a new shell.\n    3. Set the PYTHONPATH environment variable in shell\n       (query with `python dev.py -n show_PYTHONPATH`).\n    \"\"\"\n    ctx = CONTEXT\n    pythonpath = Python.pythonpath\n    extra_argv = Python.extra_argv\n\n    @classmethod\n    def run(cls, pythonpath, extra_argv, **kwargs):\n        cls._setup(pythonpath, **kwargs)\n        shell = os.environ.get('SHELL', 'sh')\n        click.echo(f\"Spawning a Unix shell '{shell}' ...\")\n        os.execv(shell, [shell] + list(extra_argv))\n        sys.exit(1)\n\n\n@cli.cls_cmd('show_PYTHONPATH')\nclass ShowDirs(Python):\n    \"\"\":information: Show value of the PYTHONPATH environment variable used in\n    this script.\n\n    PYTHONPATH sets the default search path for module files for the\n    interpreter. Here, it includes the path to the local SciPy build\n    (typically `.../build-install/lib/python3.10/site-packages`).\n\n    Use the global option `-n` to skip the building step, e.g.:\n    `python dev.py -n show_PYTHONPATH`\n    \"\"\"\n    ctx = CONTEXT\n    pythonpath = Python.pythonpath\n    extra_argv = Python.extra_argv\n\n    @classmethod\n    def run(cls, pythonpath, extra_argv, **kwargs):\n        cls._setup(pythonpath, **kwargs)\n        py_path = os.environ.get('PYTHONPATH', '')\n        click.echo(f\"PYTHONPATH={py_path}\")\n\n\n@cli.command()\n@click.argument('version_args', nargs=2)\n@click.pass_obj\ndef notes(ctx_obj, version_args):\n    \"\"\":ledger: Release notes and log generation.\n\n    \\b\n    ```python\n     Example:\n\n    $ python dev.py notes v1.7.0 v1.8.0\n    ```\n    \"\"\"\n    if version_args:\n        sys.argv = version_args\n        log_start = sys.argv[0]\n        log_end = sys.argv[1]\n    cmd = f\"python tools/write_release_and_log.py {log_start} {log_end}\"\n    click.echo(cmd)\n    try:\n        subprocess.run([cmd], check=True, shell=True)\n    except subprocess.CalledProcessError:\n        print('Error caught: Incorrect log start or log end version')\n\n\n@cli.command()\n@click.argument('revision_args', nargs=2)\n@click.pass_obj\ndef authors(ctx_obj, revision_args):\n    \"\"\":ledger: Generate list of authors who contributed within revision\n    interval.\n\n    \\b\n    ```python\n    Example:\n\n    $ python dev.py authors v1.7.0 v1.8.0\n    ```\n    \"\"\"\n    if revision_args:\n        sys.argv = revision_args\n        start_revision = sys.argv[0]\n        end_revision = sys.argv[1]\n    cmd = f\"python tools/authors.py {start_revision}..{end_revision}\"\n    click.echo(cmd)\n    try:\n        subprocess.run([cmd], check=True, shell=True)\n    except subprocess.CalledProcessError:\n        print('Error caught: Incorrect revision start or revision end')\n\n\n# The following CPU core count functions were taken from loky/backend/context.py\n# See https://github.com/joblib/loky\n\n# Cache for the number of physical cores to avoid repeating subprocess calls.\n# It should not change during the lifetime of the program.\nphysical_cores_cache = None\n\n\ndef cpu_count(only_physical_cores=False):\n    \"\"\"Return the number of CPUs the current process can use.\n\n    The returned number of CPUs accounts for:\n     * the number of CPUs in the system, as given by\n       ``multiprocessing.cpu_count``;\n     * the CPU affinity settings of the current process\n       (available on some Unix systems);\n     * Cgroup CPU bandwidth limit (available on Linux only, typically\n       set by docker and similar container orchestration systems);\n     * the value of the LOKY_MAX_CPU_COUNT environment variable if defined.\n    and is given as the minimum of these constraints.\n\n    If ``only_physical_cores`` is True, return the number of physical cores\n    instead of the number of logical cores (hyperthreading / SMT). Note that\n    this option is not enforced if the number of usable cores is controlled in\n    any other way such as: process affinity, Cgroup restricted CPU bandwidth\n    or the LOKY_MAX_CPU_COUNT environment variable. If the number of physical\n    cores is not found, return the number of logical cores.\n\n    Note that on Windows, the returned number of CPUs cannot exceed 61 (or 60 for\n    Python < 3.10), see:\n    https://bugs.python.org/issue26903.\n\n    It is also always larger or equal to 1.\n    \"\"\"\n    # Note: os.cpu_count() is allowed to return None in its docstring\n    os_cpu_count = os.cpu_count() or 1\n    if sys.platform == \"win32\":\n        # On Windows, attempting to use more than 61 CPUs would result in a\n        # OS-level error. See https://bugs.python.org/issue26903. According to\n        # https://learn.microsoft.com/en-us/windows/win32/procthread/processor-groups\n        # it might be possible to go beyond with a lot of extra work but this\n        # does not look easy.\n        os_cpu_count = min(os_cpu_count, _MAX_WINDOWS_WORKERS)\n\n    cpu_count_user = _cpu_count_user(os_cpu_count)\n    aggregate_cpu_count = max(min(os_cpu_count, cpu_count_user), 1)\n\n    if not only_physical_cores:\n        return aggregate_cpu_count\n\n    if cpu_count_user < os_cpu_count:\n        # Respect user setting\n        return max(cpu_count_user, 1)\n\n    cpu_count_physical, exception = _count_physical_cores()\n    if cpu_count_physical != \"not found\":\n        return cpu_count_physical\n\n    # Fallback to default behavior\n    if exception is not None:\n        # warns only the first time\n        warnings.warn(\n            \"Could not find the number of physical cores for the \"\n            f\"following reason:\\n{exception}\\n\"\n            \"Returning the number of logical cores instead. You can \"\n            \"silence this warning by setting LOKY_MAX_CPU_COUNT to \"\n            \"the number of cores you want to use.\",\n            stacklevel=2\n        )\n        traceback.print_tb(exception.__traceback__)\n\n    return aggregate_cpu_count\n\n\ndef _cpu_count_cgroup(os_cpu_count):\n    # Cgroup CPU bandwidth limit available in Linux since 2.6 kernel\n    cpu_max_fname = \"/sys/fs/cgroup/cpu.max\"\n    cfs_quota_fname = \"/sys/fs/cgroup/cpu/cpu.cfs_quota_us\"\n    cfs_period_fname = \"/sys/fs/cgroup/cpu/cpu.cfs_period_us\"\n    if os.path.exists(cpu_max_fname):\n        # cgroup v2\n        # https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html\n        with open(cpu_max_fname) as fh:\n            cpu_quota_us, cpu_period_us = fh.read().strip().split()\n    elif os.path.exists(cfs_quota_fname) and os.path.exists(cfs_period_fname):\n        # cgroup v1\n        # https://www.kernel.org/doc/html/latest/scheduler/sched-bwc.html#management\n        with open(cfs_quota_fname) as fh:\n            cpu_quota_us = fh.read().strip()\n        with open(cfs_period_fname) as fh:\n            cpu_period_us = fh.read().strip()\n    else:\n        # No Cgroup CPU bandwidth limit (e.g. non-Linux platform)\n        cpu_quota_us = \"max\"\n        cpu_period_us = 100_000  # unused, for consistency with default values\n\n    if cpu_quota_us == \"max\":\n        # No active Cgroup quota on a Cgroup-capable platform\n        return os_cpu_count\n    else:\n        cpu_quota_us = int(cpu_quota_us)\n        cpu_period_us = int(cpu_period_us)\n        if cpu_quota_us > 0 and cpu_period_us > 0:\n            return math.ceil(cpu_quota_us / cpu_period_us)\n        else:  # pragma: no cover\n            # Setting a negative cpu_quota_us value is a valid way to disable\n            # cgroup CPU bandwidth limits\n            return os_cpu_count\n\n\ndef _cpu_count_affinity(os_cpu_count):\n    # Number of available CPUs given affinity settings\n    if hasattr(os, \"sched_getaffinity\"):\n        try:\n            return len(os.sched_getaffinity(0))\n        except NotImplementedError:\n            pass\n\n    # On PyPy and possibly other platforms, os.sched_getaffinity does not exist\n    # or raises NotImplementedError, let's try with the psutil if installed.\n    try:\n        import psutil\n\n        p = psutil.Process()\n        if hasattr(p, \"cpu_affinity\"):\n            return len(p.cpu_affinity())\n\n    except ImportError:  # pragma: no cover\n        if (\n            sys.platform == \"linux\"\n            and os.environ.get(\"LOKY_MAX_CPU_COUNT\") is None\n        ):\n            # PyPy does not implement os.sched_getaffinity on Linux which\n            # can cause severe oversubscription problems. Better warn the\n            # user in this particularly pathological case which can wreck\n            # havoc, typically on CI workers.\n            warnings.warn(\n                \"Failed to inspect CPU affinity constraints on this system. \"\n                \"Please install psutil or explicitly set LOKY_MAX_CPU_COUNT.\",\n                stacklevel=4\n            )\n\n    # This can happen for platforms that do not implement any kind of CPU\n    # infinity such as macOS-based platforms.\n    return os_cpu_count\n\n\ndef _cpu_count_user(os_cpu_count):\n    \"\"\"Number of user defined available CPUs\"\"\"\n    cpu_count_affinity = _cpu_count_affinity(os_cpu_count)\n\n    cpu_count_cgroup = _cpu_count_cgroup(os_cpu_count)\n\n    # User defined soft-limit passed as a loky specific environment variable.\n    cpu_count_loky = int(os.environ.get(\"LOKY_MAX_CPU_COUNT\", os_cpu_count))\n\n    return min(cpu_count_affinity, cpu_count_cgroup, cpu_count_loky)\n\n\ndef _count_physical_cores():\n    \"\"\"Return a tuple (number of physical cores, exception)\n\n    If the number of physical cores is found, exception is set to None.\n    If it has not been found, return (\"not found\", exception).\n\n    The number of physical cores is cached to avoid repeating subprocess calls.\n    \"\"\"\n    exception = None\n\n    # First check if the value is cached\n    global physical_cores_cache\n    if physical_cores_cache is not None:\n        return physical_cores_cache, exception\n\n    # Not cached yet, find it\n    try:\n        if sys.platform == \"linux\":\n            cpu_info = subprocess.run(\n                \"lscpu --parse=core\".split(), capture_output=True, text=True\n            )\n            cpu_info = cpu_info.stdout.splitlines()\n            cpu_info = {line for line in cpu_info if not line.startswith(\"#\")}\n            cpu_count_physical = len(cpu_info)\n        elif sys.platform == \"win32\":\n            cpu_info = subprocess.run(\n                \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n                capture_output=True,\n                text=True,\n            )\n            cpu_info = cpu_info.stdout.splitlines()\n            cpu_info = [\n                l.split(\",\")[1]\n                for l in cpu_info\n                if (l and l != \"Node,NumberOfCores\")\n            ]\n            cpu_count_physical = sum(map(int, cpu_info))\n        elif sys.platform == \"darwin\":\n            cpu_info = subprocess.run(\n                \"sysctl -n hw.physicalcpu\".split(),\n                capture_output=True,\n                text=True,\n            )\n            cpu_info = cpu_info.stdout\n            cpu_count_physical = int(cpu_info)\n        else:\n            raise NotImplementedError(f\"unsupported platform: {sys.platform}\")\n\n        # if cpu_count_physical < 1, we did not find a valid value\n        if cpu_count_physical < 1:\n            raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n\n    except Exception as e:\n        exception = e\n        cpu_count_physical = \"not found\"\n\n    # Put the result in cache\n    physical_cores_cache = cpu_count_physical\n\n    return cpu_count_physical, exception\n\n\nif __name__ == '__main__':\n    cli()\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "environment.yml",
          "type": "blob",
          "size": 1.4248046875,
          "content": "# Please refer to https://scipy.github.io/devdocs/building/index.html\n# To use:\n#   $ conda env create -f environment.yml  # `mamba` works too for this command\n#   $ conda activate scipy-dev\n#\nname: scipy-dev\nchannels:\n  - conda-forge\ndependencies:\n  - python\n  - cython>=3.0.8\n  - compilers  # Currently unavailable for Windows. Comment out this line and download Rtools and add <path>\\ucrt64\\bin\\ to your path: https://cran.r-project.org/bin/windows/Rtools/rtools40.html\n  - meson\n  - meson-python\n  - ninja\n  - numpy\n  - openblas\n  - pkg-config\n  - libblas=*=*openblas  # helps avoid pulling in MKL\n  - pybind11\n  # scipy.datasets dependency\n  - pooch\n  # ---\n  - pythran\n  # For testing and benchmarking\n  - pytest\n  - pytest-cov\n  - pytest-xdist\n  - pytest-timeout\n  - asv >=0.6\n  - conda-build\n  - hypothesis\n  - array-api-strict<2.1.1\n  # For type annotations\n  - mypy\n  - typing_extensions\n  - types-psutil\n  # For building docs\n  - sphinx<8.0.0\n  - intersphinx-registry\n  - numpydoc\n  - ipython\n  - setuptools<67.3  # avoid pkg_resources deprecation warnings from MPL/scikit-umfpack\n  - matplotlib\n  - pydata-sphinx-theme>=0.15.2\n  - sphinx-copybutton\n  - sphinx-design\n  - jupytext\n  - myst-nb\n  - jupyterlite-sphinx>=0.17.1\n  - jupyterlite-pyodide-kernel\n  # Some optional test dependencies\n  - mpmath\n  - gmpy2\n  - threadpoolctl\n  # For CLI\n  - rich-click\n  - click\n  - doit>=0.36.0\n  - pydevtool\n  # For linting\n  - ruff>=0.0.292\n  - cython-lint\n"
        },
        {
          "name": "meson.build",
          "type": "blob",
          "size": 6.0234375,
          "content": "project(\n  'scipy',\n  'c', 'cpp', 'cython',\n  version: run_command(['tools/gitversion.py'], check: true).stdout().strip(),\n  license: 'BSD-3',\n  meson_version: '>= 1.5.0',\n  default_options: [\n    'buildtype=debugoptimized',\n    'b_ndebug=if-release',\n    'c_std=c17',\n    'cpp_std=c++17',\n    'blas=openblas',\n    'lapack=openblas'\n  ],\n)\n\npy3 = import('python').find_installation(pure: false)\npy3_dep = py3.dependency()\n\nmin_numpy_version = '1.23.5'  # keep in sync with pyproject.toml\n\n# Emit a warning for 32-bit Python installs on Windows; users are getting\n# unexpected from-source builds there because we no longer provide wheels.\nis_windows = host_machine.system() == 'windows'\nif is_windows and py3.has_variable('EXT_SUFFIX')\n  ext_suffix = py3.get_variable('EXT_SUFFIX')\n  if ext_suffix.contains('win32')\n    warning('You are building from source on a 32-bit Python install. SciPy does not provide 32-bit wheels; install 64-bit Python if you are having issues!')\n  endif\nendif\n\ncc = meson.get_compiler('c')\ncpp = meson.get_compiler('cpp')\ncy = meson.get_compiler('cython')\n# generator() doesn't accept compilers, only found programs - cast it.\ncython = find_program(cy.cmd_array()[0])\n\n# Check compiler is recent enough (see \"Toolchain Roadmap\" for details)\nif cc.get_id() == 'gcc'\n  if not cc.version().version_compare('>=9.1')\n    error('SciPy requires GCC >= 9.1')\n  endif\nelif cc.get_id() == 'clang' or cc.get_id() == 'clang-cl'\n  if not cc.version().version_compare('>=12.0')\n    error('SciPy requires clang >= 12.0')\n  endif\nelif cc.get_id() == 'msvc'\n  if not cc.version().version_compare('>=19.20')\n    error('SciPy requires at least vc142 (default with Visual Studio 2019) ' + \\\n          'when building with MSVC')\n  endif\nendif\nif not cy.version().version_compare('>=3.0.8')\n  error('SciPy requires Cython >= 3.0.8')\nendif\n\n_global_c_args = cc.get_supported_arguments(\n  '-Wno-unused-but-set-variable',\n  '-Wno-unused-function',\n  '-Wno-conversion',\n  '-Wno-misleading-indentation',\n)\nadd_project_arguments(_global_c_args, language : 'c')\n\n# We need -lm for all C code (assuming it uses math functions, which is safe to\n# assume for SciPy). For C++ it isn't needed, because libstdc++/libc++ is\n# guaranteed to depend on it. For Fortran code, Meson already adds `-lm`.\nm_dep = cc.find_library('m', required : false)\nif m_dep.found()\n  add_project_link_arguments('-lm', language : 'c')\nendif\n\nif host_machine.system() == 'os400'\n  # IBM i system, needed to avoid build errors - see gh-17193\n  add_project_arguments('-D__STDC_FORMAT_MACROS', language : 'cpp')\n  add_project_link_arguments('-Wl,-bnotextro', language : ['c', 'cpp', 'fortran'])\nendif\n\n# Adding at project level causes many spurious -lgfortran flags.\nadd_languages('fortran', native: false)\nff = meson.get_compiler('fortran')\nif ff.get_id() == 'gcc'\n  # -std=legacy is not supported by all Fortran compilers, but very useful with\n  # gfortran since it avoids a ton of warnings that we don't care about.\n  # Needs fixing in Meson, see https://github.com/mesonbuild/meson/issues/11633.\n  add_project_arguments('-std=legacy', language: 'fortran')\nendif\n\nif ff.has_argument('-Wno-conversion')\n  add_project_arguments('-Wno-conversion', language: 'fortran')\nendif\n\nif host_machine.system() == 'darwin'\n  if cc.has_link_argument('-Wl,-dead_strip')\n    # Allow linker to strip unused symbols\n    add_project_link_arguments('-Wl,-dead_strip', language : ['c', 'cpp', 'fortran'])\n  endif\nendif\n\n# Intel compilers default to fast-math, so disable it if we detect Intel\n# compilers. A word of warning: this may not work with the conda-forge\n# compilers, because those have the annoying habit of including lots of flags\n# that are gcc-specific in CFLAGS/CXXFLAGS/FFLAGS, which throws off the\n# detection logic below. You have to remove the wrong flags (only `-isystem`\n# is actually needed, everything else shouldn't be there).\n_intel_cflags = []\n_intel_fflags = []\nif cc.get_id() in ['intel', 'intel-llvm']\n  _intel_cflags += cc.get_supported_arguments('-fp-model=strict')\nelif cc.get_id() in ['intel-cl', 'intel-llvm-cl']\n  _intel_cflags += cc.get_supported_arguments('/fp:strict')\nendif\nif ff.get_id() in ['intel', 'intel-llvm']\n  _intel_fflags = ff.get_supported_arguments('-fp-model=strict')\n  minus0_arg = ['-assume', 'minus0']\n  if ff.has_multi_arguments(minus0_arg)\n    _intel_fflags += minus0_arg\n  endif\nelif ff.get_id() in ['intel-cl', 'intel-llvm-cl']\n  # Intel Fortran on Windows does things differently, so deal with that\n  # (also specify dynamic linking and the right name mangling)\n  _intel_fflags = ff.get_supported_arguments(\n    '/fp:strict', '/MD', '/names:lowercase', '/assume:underscore',\n    '/assume:minus0'\n  )\nendif\nadd_project_arguments(_intel_cflags, language: ['c', 'cpp'])\nadd_project_arguments(_intel_fflags, language: 'fortran')\n\n# Hide symbols when building on Linux with GCC. For Python extension modules,\n# we only need `PyInit_*` to be public, anything else may cause problems. So we\n# use a linker script to avoid exporting those symbols (this is in addition to\n# Meson using `-fvisibility=hidden` for C and `-fvisibility-inlines-hidden` for\n# C++ code. See gh-15996 for details.\n_linker_script = meson.project_source_root() / 'scipy/_build_utils/link-version-pyinit.map'\nversion_link_args = ['-Wl,--version-script=' + _linker_script]\n# Note that FreeBSD only accepts version scripts when -shared is passed,\n# hence we need to pass that to `cc.links` explicitly (flag is already\n# present for `extension_module` invocations).\nif not cc.links('', name: '-Wl,--version-script', args: ['-shared', version_link_args])\n  version_link_args = []\nendif\n\ngenerate_f2pymod = find_program('tools/generate_f2pymod.py')\ntempita = find_program('scipy/_build_utils/tempita.py')\n\nuse_pythran = get_option('use-pythran')\nif use_pythran\n  pythran = find_program('pythran', native: true, version: '>=0.14.0')\n  # xsimd is unvendored from pythran by conda-forge, and due to a compiler\n  # activation bug the default <prefix>/include/ may not be visible (see\n  # gh-15698). Hence look for xsimd explicitly.\n  xsimd_dep = dependency('xsimd', required: false)\nendif\n\nsubdir('scipy')\n"
        },
        {
          "name": "meson.options",
          "type": "blob",
          "size": 0.7412109375,
          "content": "option('blas', type: 'string', value: 'openblas',\n        description: 'option for BLAS library switching')\noption('lapack', type: 'string', value: 'openblas',\n        description: 'option for LAPACK library switching')\noption('use-g77-abi', type: 'boolean', value: false,\n        description: 'If set to true, forces using g77 compatibility wrappers ' +\n                     'for LAPACK functions. The default is to use gfortran ' +\n                     'ABI for all LAPACK libraries except MKL.')\noption('use-pythran', type: 'boolean', value: true,\n        description: 'If set to false, disables using Pythran (it falls back ' +\n                     'to either pure Python code or Cython code, depending on ' +\n                     'the implementation).')\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 14.654296875,
          "content": "[mypy]\nwarn_redundant_casts = True\n# This is too fragile - can be tested locally with `True` once in a while,\n# and especially when upgrading to a new Mypy version. However, Mypy is\n# not consistent enough for this to be a reasonable default.\nwarn_unused_ignores = False\nshow_error_codes = True\nplugins = numpy.typing.mypy_plugin\n\n#\n# Typing tests is low priority, but enabling type checking on the\n# untyped test functions is still high-value because it helps test the\n# typing.\n#\n\n[mypy-scipy.special.tests.test_orthogonal]\ncheck_untyped_defs = True\n\n[mypy-scipy.special.tests.test_sf_error]\ncheck_untyped_defs = True\n\n[mypy-scipy.special.tests.test_boost_ufuncs]\nignore_errors = True\n\n[mypy-scipy.spatial.tests.test_spherical_voronoi]\ncheck_untyped_defs = True\n\n#\n# The ratchet\n#\n\n#\n# Standard library modules that don't have types\n#\n\n[mypy-cffi]\nignore_missing_imports = True\n\n#\n# Third party dependencies that don't have types.\n#\n\n[mypy-sksparse]\nignore_missing_imports = True\n\n[mypy-sksparse.*]\nignore_missing_imports = True\n\n[mypy-sparse]\nignore_missing_imports = True\n\n[mypy-scikits]\nignore_missing_imports = True\n\n[mypy-scikits.*]\nignore_missing_imports = True\n\n[mypy-uarray]\nignore_missing_imports = True\n\n[mypy-pythran]\nignore_missing_imports = True\n\n[mypy-pythran.*]\nignore_missing_imports = True\n\n[mypy-mpmath]\nignore_missing_imports = True\n\n[mypy-threadpoolctl]\nignore_missing_imports = True\n\n[mypy-sympy.*]\nignore_missing_imports = True\n\n[mypy-matplotlib.*]\nignore_missing_imports = True\n\n[mypy-pytest_timeout.*]\nignore_missing_imports = True\n\n[mypy-pooch]\nignore_missing_imports = True\n\n[mypy-appdirs]\nignore_missing_imports = True\n\n[mypy-array_api_strict]\nignore_missing_imports = True\n\n[mypy-sphinx.*]\nignore_missing_imports = True\n\n#\n# Extension modules without stubs.\n#\n\n[mypy-scipy.signal._peak_finding_utils]\nignore_missing_imports = True\n\n[mypy-scipy.signal._upfirdn_apply]\nignore_missing_imports = True\n\n[mypy-scipy.integrate._test_odeint_banded]\nignore_missing_imports = True\n\n[mypy-scipy.integrate._test_multivariate]\nignore_missing_imports = True\n\n[mypy-scipy._lib._ccallback_c]\nignore_missing_imports = True\n\n[mypy-scipy.cluster._hierarchy]\nignore_missing_imports = True\n\n[mypy-scipy.optimize._bglu_dense]\nignore_missing_imports = True\n\n[mypy-scipy.optimize._slsqp]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._dfitpack]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._interpnd]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._bspl]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._dierckx]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._rgi_cython]\nignore_missing_imports = True\n\n[mypy-scipy.linalg.cython_blas]\nignore_missing_imports = True\n\n[mypy-scipy.linalg._decomp_update]\nignore_missing_imports = True\n\n[mypy-scipy.linalg._solve_toeplitz]\nignore_missing_imports = True\n\n[mypy-scipy.linalg._decomp_interpolative]\nignore_missing_imports = True\n\n[mypy-scipy.optimize._group_columns]\nignore_missing_imports = True\n\n[mypy-scipy.io.matlab._mio5_utils]\nignore_missing_imports = True\n\n[mypy-scipy.io.matlab._streams]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.linalg._dsolve._superlu]\nignore_missing_imports = True\n\n[mypy-scipy.io.matlab._mio_utils]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._tools]\nignore_missing_imports = True\n\n[mypy-scipy.sparse._sparsetools]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._reordering]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._matching]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._flow]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._min_spanning_tree]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._traversal]\nignore_missing_imports = True\n\n[mypy-scipy.sparse.csgraph._shortest_path]\nignore_missing_imports = True\n\n[mypy-scipy.spatial.transform._rotation]\nignore_missing_imports = True\n\n[mypy-scipy.fft._pocketfft.pypocketfft]\nignore_missing_imports = True\n\n[mypy-scipy.signal._max_len_seq_inner]\nignore_missing_imports = True\n\n[mypy-scipy.special._ellip_harm_2]\nignore_missing_imports = True\n\n[mypy-scipy.special._gufuncs]\nignore_missing_imports = True\n\n[mypy-scipy._lib._fpumode]\nignore_missing_imports = True\n\n[mypy-scipy.optimize._trlib._trlib]\nignore_missing_imports = True\n\n[mypy-scipy.stats._biasedurn]\nignore_missing_imports = True\n\n[mypy-scipy.stats._stats_pythran]\nignore_missing_imports = True\n\n[mypy-scipy.interpolate._rbfinterp_pythran]\nignore_missing_imports = True\n\n[mypy-scipy.stats._statlib]\nignore_missing_imports = True\n\n[mypy-scipy.stats._levy_stable.levyst]\nignore_missing_imports = True\n\n[mypy-scipy.stats._rcont.rcont]\nignore_missing_imports = True\n\n#\n# Files with various errors. Likely some false positives, but likely\n# some real bugs too.\n#\n[mypy-scipy.conftest]\nignore_errors = True\n\n[mypy-scipy.__config__]\nignore_errors = True\n\n[mypy-scipy._build_utils.tempita]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_signaltools]\nignore_errors = True\n\n[mypy-scipy.stats._variation]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_rank]\nignore_errors = True\n\n[mypy-scipy.stats._continuous_distns]\nignore_errors = True\n\n[mypy-scipy.stats.distributions]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_distributions]\nignore_errors = True\n\n[mypy-scipy.integrate.tests.test_integrate]\nignore_errors = True\n\n[mypy-scipy.signal._ltisys]\nignore_errors = True\n\n[mypy-scipy.signal._support_alternative_backends]\nignore_errors = True\n\n[mypy-scipy.signal._signal_api]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_upfirdn]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_splines]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_short_time_fft]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_savitzky_golay]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_result_type]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_max_len_seq]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_ltisys]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_dltisys]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_fir_filter_design]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_filter_design]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_spectral]\nignore_errors = True\n\n[mypy-scipy.signal.tests._scipy_spectral_test_shim]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_cont2discrete]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_czt]\nignore_errors = True\n\n[mypy-scipy.integrate._ode]\nignore_errors = True\n\n[mypy-scipy.optimize.tests.test_nonlin]\nignore_errors = True\n\n[mypy-scipy.integrate._bvp]\nignore_errors = True\n\n[mypy-scipy.optimize.tests.test_least_squares]\nignore_errors = True\n\n[mypy-scipy.optimize.tests.test_linprog]\nignore_errors = True\n\n[mypy-scipy.optimize._tstutils]\nignore_errors = True\n\n[mypy-scipy.optimize]\nignore_errors = True\n\n[mypy-scipy.optimize._lsq.least_squares]\nignore_errors = True\n\n[mypy-scipy.optimize._trustregion_constr.minimize_trustregion_constr]\nignore_errors = True\n\n[mypy-scipy.optimize._linprog]\nignore_errors = True\n\n[mypy-scipy.optimize._linprog_util]\nignore_errors = True\n\n[mypy-scipy.optimize._linprog_highs]\nignore_errors = True\n\n[mypy-scipy.optimize._highspy.*]\nignore_errors = True\n\n[mypy-scipy.optimize._trustregion]\nignore_errors = True\n\n[mypy-scipy.optimize._trustregion_dogleg]\nignore_errors = True\n\n[mypy-scipy.optimize._trustregion_ncg]\nignore_errors = True\n\n[mypy-scipy.optimize._cobyla_py]\nignore_errors = True\n\n[mypy-scipy.optimize._linprog_ip]\nignore_errors = True\n\n[mypy-scipy.optimize._minpack_py]\nignore_errors = True\n\n[mypy-scipy.optimize._nnls]\nignore_errors = True\n\n[mypy-scipy.optimize._optimize]\nignore_errors = True\n\n[mypy-scipy.optimize._pava_pybind]\nignore_missing_imports = True\n\n[mypy-scipy.optimize._basinhopping]\nignore_errors = True\n\n[mypy-scipy.integrate._ivp.radau]\nignore_errors = True\n\n[mypy-scipy.optimize._trustregion_constr.tests.test_projections]\nignore_errors = True\n\n[mypy-scipy.integrate._quadrature]\nignore_errors = True\n\n[mypy-scipy.integrate.quadrature]\nignore_errors = True\n\n[mypy-scipy.linalg.tests.test_fblas]\nignore_errors = True\n\n[mypy-scipy.signal.windows._windows]\nignore_errors = True\n\n[mypy-scipy.signal._spline_filters]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.test_gcrotmk]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.test_lgmres]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.test_utils]\nignore_errors = True\n\n[mypy-scipy.sparse.tests.test_base]\nignore_errors = True\n\n[mypy-scipy.linalg._basic]\nignore_errors = True\n\n[mypy-scipy.linalg.lapack]\nignore_errors = True\n\n[mypy-scipy.fftpack._pseudo_diffs]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.utils]\nignore_errors = True\n\n[mypy-scipy.integrate._quad_vec]\nignore_errors = True\n\n[mypy-scipy.sparse._compressed]\nignore_errors = True\n\n[mypy-scipy.sparse._coo]\nignore_errors = True\n\n[mypy-scipy.sparse._csr]\nignore_errors = True\n\n[mypy-scipy.sparse._data]\nignore_errors = True\n\n[mypy-scipy.sparse._dok]\nignore_errors = True\n\n[mypy-scipy.sparse._index]\nignore_errors = True\n\n[mypy-scipy]\nignore_errors = True\n\n[mypy-scipy.fft]\nignore_errors = True\n\n[mypy-scipy.fft._helper]\nignore_errors = True\n\n[mypy-scipy.fft._pocketfft.basic]\nignore_errors = True\n\n[mypy-scipy.fft._pocketfft.realtransforms]\nignore_errors = True\n\n[mypy-scipy._lib._pep440]\nignore_errors = True\n\n[mypy-scipy._lib.decorator]\nignore_errors = True\n\n[mypy-scipy._lib._bunch]\nignore_errors = True\n\n[mypy-scipy.io.arff._arffread]\nignore_errors = True\n\n[mypy-scipy.io._netcdf]\nignore_errors = True\n\n[mypy-scipy.sparse._sputils]\nignore_errors = True\n\n[mypy-scipy.linalg._generate_pyx]\nignore_errors = True\n\n[mypy-scipy.sparse.tests.test_sparsetools]\nignore_errors = True\n\n[mypy-scipy.stats._discrete_distns]\nignore_errors = True\n\n[mypy-scipy.stats._qmc]\nignore_errors = True\n\n[mypy-scipy.spatial.tests.test_distance]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_qmc]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_sampling]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_odds_ratio]\nignore_errors = True\n\n#\n# Files referencing compiled code that needs stubs added.\n#\n\n[mypy-scipy.stats.tests.test_multivariate]\nignore_errors = True\n\n[mypy-scipy.signal.tests.test_windows]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_continuous_basic]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_continuous_fit_censored]\nignore_errors = True\n\n[mypy-scipy.linalg.tests.test_decomp]\nignore_errors = True\n\n[mypy-scipy.linalg.tests.test_lapack]\nignore_errors = True\n\n[mypy-scipy.signal]\nignore_errors = True\n\n[mypy-scipy.signal._fir_filter_design]\nignore_errors = True\n\n[mypy-scipy.signal._signaltools]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._eigen.tests.test_svds]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_discrete_distns]\nignore_errors = True\n\n[mypy-scipy.stats.tests.test_discrete_basic]\nignore_errors = True\n\n[mypy-scipy.stats._mstats_extras]\nignore_errors = True\n\n[mypy-scipy.stats._multivariate]\nignore_errors = True\n\n[mypy-scipy.stats._kde]\nignore_errors = True\n\n[mypy-scipy.stats._morestats]\nignore_errors = True\n\n[mypy-scipy.stats._stats_py]\nignore_errors = True\n\n[mypy-scipy.interpolate.tests.test_interpolate]\nignore_errors = True\n\n[mypy-scipy.integrate._odepack_py]\nignore_errors = True\n\n[mypy-scipy.integrate._quadpack_py]\nignore_errors = True\n\n[mypy-scipy.integrate.tests.test_bvp]\nignore_errors = True\n\n[mypy-scipy.optimize.tests.test_lbfgsb_setulb]\nignore_errors = True\n\n[mypy-scipy.spatial.transform.tests.test_rotation_groups]\nignore_errors = True\n\n[mypy-scipy.cluster.tests.test_vq]\nignore_errors = True\n\n[mypy-scipy.optimize._lsq.lsq_linear]\nignore_errors = True\n\n[mypy-scipy.optimize._lsq.trf_linear]\nignore_errors = True\n\n[mypy-scipy.optimize._lsq.dogbox]\nignore_errors = True\n\n[mypy-scipy.optimize._lsq.trf]\nignore_errors = True\n\n[mypy-scipy.optimize._dual_annealing]\nignore_errors = True\n\n[mypy-scipy.optimize._lsap]\nignore_errors = True\n\n[mypy-scipy.optimize._lbfgsb_py]\nignore_errors = True\n\n[mypy-scipy.optimize._linesearch]\nignore_errors = True\n\n[mypy-scipy.optimize._tnc]\nignore_errors = True\n\n[mypy-scipy.optimize._zeros_py]\nignore_errors = True\n\n[mypy-scipy.optimize.moduleTNC]\nignore_errors = True\n\n[mypy-scipy.optimize.minpack2]\nignore_errors = True\n\n[mypy-scipy.cluster.hierarchy]\nignore_errors = True\n\n[mypy-scipy.cluster.vq]\nignore_errors = True\n\n[mypy-scipy.interpolate.tests.test_bsplines]\nignore_errors = True\n\n[mypy-scipy.spatial.tests.test__plotutils]\nignore_errors = True\n\n[mypy-scipy.integrate._ivp.bdf]\nignore_errors = True\n\n[mypy-scipy.interpolate._bsplines]\nignore_errors = True\n\n[mypy-scipy.interpolate._fitpack_impl]\nignore_errors = True\n\n[mypy-scipy.interpolate._interpolate]\nignore_errors = True\n\n[mypy-scipy.interpolate._ndgriddata]\nignore_errors = True\n\n[mypy-scipy.interpolate._rbf]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.test_lsmr]\nignore_errors = True\n\n[mypy-scipy.linalg.tests.test_blas]\nignore_errors = True\n\n[mypy-scipy.linalg.tests.test_cython_lapack]\nignore_errors = True\n\n[mypy-scipy.optimize._remove_redundancy]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._dsolve.tests.test_linsolve]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._eigen.lobpcg.tests.test_lobpcg]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.demo_lgmres]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.tests.test_lsqr]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg.tests.test_matfuncs]\nignore_errors = True\n\n[mypy-scipy.io.tests.test_fortran]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._eigen.arpack.arpack]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._matfuncs]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve.iterative]\nignore_errors = True\n\n[mypy-scipy.sparse.linalg._isolve._gcrotmk]\nignore_errors = True\n\n[mypy-scipy.spatial.tests.test_kdtree]\nignore_errors = True\n\n[mypy-scipy.special._basic]\nignore_errors = True\n\n[mypy-scipy.special._multiufuncs]\nignore_errors = True\n\n[mypy-scipy.linalg._matfuncs_sqrtm]\nignore_errors = True\n\n[mypy-scipy.linalg.blas]\nignore_errors = True\n\n[mypy-scipy.sparse._lil]\nignore_errors = True\n\n[mypy-scipy.ndimage.tests.test_c_api]\nignore_errors = True\n\n[mypy-scipy.ndimage.tests.test_filters]\nignore_errors = True\n\n[mypy-scipy.ndimage.tests.test_fourier]\nignore_errors = True\n\n[mypy-scipy._lib.tests.test_ccallback]\nignore_errors = True\n\n[mypy-scipy.ndimage._filters]\nignore_errors = True\n\n[mypy-scipy.ndimage._fourier]\nignore_errors = True\n\n[mypy-scipy.ndimage._interpolation]\nignore_errors = True\n\n[mypy-scipy.ndimage._measurements]\nignore_errors = True\n\n[mypy-scipy.ndimage._morphology]\nignore_errors = True\n\n[mypy-scipy.ndimage.utils.generate_label_testvectors]\nignore_errors = True\n\n[mypy-scipy.ndimage._support_alternative_backends]\nignore_errors = True\n\n[mypy-scipy.odr._odrpack]\nignore_errors = True\n\n[mypy-scipy.optimize.tests.test_cython_optimize]\nignore_errors = True\n\n#\n# Vendored code\n#\n\n[mypy-scipy._lib._uarray.*]\nignore_errors = True\n\n[mypy-scipy._lib.array_api_compat.*]\nignore_errors = True\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 5.490234375,
          "content": "# Note that in maintenance branches, all build dependencies should\n# have an upper bound equal to the most recent already-released version\n# of the dependency. This to prevent that a future backwards-incompatible\n# release will break the source build of a SciPy release.\n# Do accept micro (bug-fix) releases. So for example, if pybind11 2.4.3 is\n# the most recent version on PyPI:\n#\n#     \"pybind11>=2.4.3,<2.5.0\",\n#\n# Upper bounds in release branches must have notes on why they are added.\n# Distro packages can ignore upper bounds added only to prevent future\n# breakage; if we add pins or bounds because of known problems then they need\n# them too.\n\n# Run tools/generate_requirements.txt when making changes to any dependencies\n\n[build-system]\nbuild-backend = 'mesonpy'\nrequires = [\n    \"meson-python>=0.15.0\",\n    \"Cython>=3.0.8\",        # when updating version, also update check in meson.build\n    \"pybind11>=2.13.2\",     # when updating version, also update check in scipy/meson.build\n    \"pythran>=0.14.0\",\n\n    # numpy requirement for wheel builds for distribution on PyPI - building\n    # against 2.x yields wheels that are also compatible with numpy 1.x at\n    # runtime.\n    # Note that building against numpy 1.x works fine too - users and\n    # redistributors can do this by installing the numpy version they like and\n    # disabling build isolation.\n    \"numpy>=2.0.0rc1\",\n]\n\n[project]\nname = \"scipy\"\nversion = \"1.16.0.dev0\"\n# TODO: add `license-files` once PEP 639 is accepted (see meson-python#88)\n#       at that point, no longer include them in `py3.install_sources()`\nlicense = { file = \"LICENSE.txt\" }\ndescription = \"Fundamental algorithms for scientific computing in Python\"\nmaintainers = [\n    { name = \"SciPy Developers\", email = \"scipy-dev@python.org\" },\n]\n# Note: Python and NumPy upper version bounds should be set correctly in\n# release branches, see:\n#     https://scipy.github.io/devdocs/dev/core-dev/index.html#version-ranges-for-numpy-and-other-dependencies\nrequires-python = \">=3.10\"\ndependencies = [\n    \"numpy>=1.23.5\",\n] # keep in sync with `min_numpy_version` in meson.build\nreadme = \"README.rst\"\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Science/Research\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: BSD License\",\n    \"Programming Language :: C\",\n    \"Programming Language :: Python\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3.13\",\n    \"Topic :: Software Development :: Libraries\",\n    \"Topic :: Scientific/Engineering\",\n    \"Operating System :: Microsoft :: Windows\",\n    \"Operating System :: POSIX :: Linux\",\n    \"Operating System :: POSIX\",\n    \"Operating System :: Unix\",\n    \"Operating System :: MacOS\",\n]\n\n[project.optional-dependencies]\ntest = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-timeout\",\n    \"pytest-xdist\",\n    \"asv\",\n    \"mpmath\",\n    \"gmpy2\",\n    \"threadpoolctl\",\n    \"scikit-umfpack\",\n    \"pooch\",\n    \"hypothesis>=6.30\",\n    \"array-api-strict>=2.0,<2.1.1\",\n    \"Cython\",\n    \"meson\",\n    'ninja; sys_platform != \"emscripten\"',\n]\ndoc = [\n    \"sphinx>=5.0.0,<8.0.0\",\n    \"intersphinx_registry\",\n    \"pydata-sphinx-theme>=0.15.2\",\n    \"sphinx-copybutton\",\n    \"sphinx-design>=0.4.0\",\n    \"matplotlib>=3.5\",\n    \"numpydoc\",\n    \"jupytext\",\n    \"myst-nb\",\n    \"pooch\",\n    \"jupyterlite-sphinx>=0.17.1\",\n    \"jupyterlite-pyodide-kernel\",\n]\ndev = [\n    \"mypy==1.10.0\",\n    \"typing_extensions\",\n    \"types-psutil\",\n    \"pycodestyle\",\n    \"ruff>=0.0.292\",\n    \"cython-lint>=0.12.2\",\n    \"rich-click\",\n    \"doit>=0.36.0\",\n    \"pydevtool\",\n]\n\n[project.urls]\nhomepage = \"https://scipy.org/\"\ndocumentation = \"https://docs.scipy.org/doc/scipy/\"\nsource = \"https://github.com/scipy/scipy\"\ndownload = \"https://github.com/scipy/scipy/releases\"\ntracker = \"https://github.com/scipy/scipy/issues\"\n\n[tool.doit]\ndodoFile = \"dev.py\"\n\n[tool.meson-python.args]\ninstall = ['--skip-subprojects']\n\n[tool.cibuildwheel]\nskip = \"cp36-* cp37-* cp38-* pp* *_ppc64le *_i686 *_s390x\"\n# We're only testing with essential test dependencies, not optional ones.\n# Some of those require binary wheels (often missing for some platforms),\n# or they slow down the test suite runs too much or simply aren't necessary.\ntest-requires = [\n    \"pytest\",\n    \"pytest-xdist\",\n    \"threadpoolctl\",\n    \"pooch\",\n    \"hypothesis\",\n]\nbefore-test = \"bash {project}/tools/wheels/cibw_before_test.sh {project}\"\ntest-command = \"bash {project}/tools/wheels/cibw_test_command.sh {project}\"\n\n[tool.cibuildwheel.linux]\nmanylinux-x86_64-image = \"manylinux2014\"\nmanylinux-aarch64-image = \"manylinux2014\"\nbefore-build = \"bash {project}/tools/wheels/cibw_before_build_linux.sh {project}\"\n\n[tool.cibuildwheel.linux.environment]\n# /project will be the $PWD equivalent inside the docker used to build the wheel\nPKG_CONFIG_PATH = \"/project/\"\n\n[tool.cibuildwheel.macos]\nbefore-build = \"bash {project}/tools/wheels/cibw_before_build_macos.sh {project}\"\n\n[tool.cibuildwheel.macos.environment]\nPKG_CONFIG_PATH = \"{project}\"\n\n[tool.cibuildwheel.windows]\nbefore-build = \"bash {project}/tools/wheels/cibw_before_build_win.sh {project}\"\nrepair-wheel-command = \"bash ./tools/wheels/repair_windows.sh {wheel} {dest_dir}\"\n\n[tool.cibuildwheel.windows.environment]\n# This does not work because pkg-config does not like backslashes,\nPKG_CONFIG_PATH = \"{project}\"\n# do this instead (which will override this setting)\n# set CIBW_ENVIRONMENT_WINDOWS=PKG_CONFIG_PATH=PWD.replace('\\\\', '/')\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 1.8056640625,
          "content": "[pytest]\naddopts = -l\nnorecursedirs = doc tools scipy/_lib/array_api_compat scipy/_lib/cobyqa scipy/_lib/highs\njunit_family=xunit2\n\nfilterwarnings =\n    error\n    always::scipy._lib._testutils.FPUModeChangeWarning\n    ignore:.*deprecated and ignored since IPython.*:DeprecationWarning\n    once:.*LAPACK bug 0038.*:RuntimeWarning\n    ignore:can't resolve package from __spec__ or __package__, falling back on __name__ and __path__:ImportWarning\n    ignore:assertions not in test modules or plugins:pytest.PytestConfigWarning\n    ignore:'environmentfilter' is renamed to 'pass_environment'\n    ignore:'contextfunction' is renamed to 'pass_context'\n    ignore:.*The distutils.* is deprecated.*:DeprecationWarning\n    ignore:\\s*.*numpy.distutils.*:DeprecationWarning\n    ignore:.*`numpy.core` has been made officially private.*:DeprecationWarning\n    ignore:.*In the future `np.long` will be defined as.*:FutureWarning\n    ignore:.*JAX is multithreaded.*:RuntimeWarning\n    ignore:.*The 2023.12 version of the array API specification is still preliminary.*:UserWarning\n    ignore:^Using the slower implmentation::cupy\n    ignore:Using the slower implementation::cupy\n    ignore:Jitify is performing a one-time only warm-up::cupy\n    ignore:.*scipy.misc.*:DeprecationWarning\n\nmarkers =\n    slow: Tests that are very slow\n    xslow: mark test as extremely slow (not run unless explicitly requested)\n    xfail_on_32bit: mark test as failing on 32-bit platforms\n    array_api_backends: test iterates on all array API backends\n    skip_xp_backends(backends, reason=None, np_only=False, cpu_only=False, exceptions=None): mark the desired skip configuration for the `skip_xp_backends` fixture\n    xfail_xp_backends(backends, reason=None, np_only=False, cpu_only=False, exceptions=None): mark the desired xfail configuration for the `xfail_xp_backends` fixture\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scipy",
          "type": "tree",
          "content": null
        },
        {
          "name": "subprojects",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}