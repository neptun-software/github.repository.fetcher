{
  "metadata": {
    "timestamp": 1736561183896,
    "page": 146,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "microsoft/qlib",
      "stars": 15945,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".deepsource.toml",
          "type": "blob",
          "size": 0.1748046875,
          "content": "version = 1\n\ntest_patterns = [\"tests/test_*.py\"]\n\nexclude_patterns = [\"examples/**\"]\n\n[[analyzers]]\nname = \"python\"\nenabled = true\n\n  [analyzers.meta]\n  runtime_version = \"3.x.x\"\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.0478515625,
          "content": "__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\n.env\n.git\n\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5908203125,
          "content": "# https://github.com/github/gitignore/blob/master/Python.gitignore\n__pycache__/\n\n*.pyc\n*.pyd\n*.so\n*.ipynb\n.ipynb_checkpoints\n_build\nbuild/\ndist/\n\n*.pkl\n*.hd5\n*.csv\n\n.env\n.vim\n.nvimrc\n.vscode\n\nqlib/VERSION.txt\nqlib/data/_libs/expanding.cpp\nqlib/data/_libs/rolling.cpp\nexamples/estimator/estimator_example/\nexamples/rl/data/\nexamples/rl/checkpoints/\nexamples/rl/outputs/\nexamples/rl_order_execution/data/\nexamples/rl_order_execution/outputs/\n\n*.egg-info/\n\n# test related\ntest-output.xml\n.output\n.data\n\n# special software\nmlruns/\n\ntags\n\n.pytest_cache/\n.mypy_cache/\n.vscode/\n\n*.swp\n\n./pretrain\n.idea/\n.aider*\n"
        },
        {
          "name": ".mypy.ini",
          "type": "blob",
          "size": 0.3505859375,
          "content": "[mypy]\nexclude = (?x)(\n    ^qlib/backtest/high_performance_ds\\.py$\n    | ^qlib/contrib\n    | ^qlib/data\n    | ^qlib/model\n    | ^qlib/strategy\n    | ^qlib/tests\n    | ^qlib/utils\n    | ^qlib/workflow\n    | ^qlib/config\\.py$\n    | ^qlib/log\\.py$\n    | ^qlib/__init__\\.py$\n  )\nignore_missing_imports = true\ndisallow_incomplete_defs = true\nfollow_imports = skip\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.271484375,
          "content": "repos:\n-   repo: https://github.com/psf/black\n    rev: 23.7.0\n    hooks:\n    -   id: black\n        args: [\"qlib\", \"-l 120\"]\n\n-   repo: https://github.com/PyCQA/flake8\n    rev: 4.0.1\n    hooks:\n        - id: flake8\n          args: [\"--ignore=E501,F541,E266,E402,W503,E731,E203\"]\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 0.212890625,
          "content": "[TYPECHECK]\n# https://stackoverflow.com/a/53572939 \n# List of members which are set dynamically and missed by Pylint inference\n# system, and so shouldn't trigger E1101 when accessed.\ngenerated-members=numpy.*, torch.*\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.560546875,
          "content": "# .readthedocs.yml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.8\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n\n# Build all formats\nformats: all\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  install:\n    - requirements: docs/requirements.txt\n    - method: pip\n      path: .\n"
        },
        {
          "name": "CHANGES.rst",
          "type": "blob",
          "size": 7.4326171875,
          "content": "Changelog\n=========\nHere you can see the full list of changes between each QLib release.\n\nVersion 0.1.0\n-------------\nThis is the initial release of QLib library.\n\nVersion 0.1.1\n-------------\nPerformance optimize. Add more features and operators.\n\nVersion 0.1.2\n-------------\n- Support operator syntax. Now ``High() - Low()`` is equivalent to ``Sub(High(), Low())``.\n- Add more technical indicators.\n\nVersion 0.1.3\n-------------\nBug fix and add instruments filtering mechanism.\n\nVersion 0.2.0\n-------------\n- Redesign ``LocalProvider`` database format for performance improvement.\n- Support load features as string fields.\n- Add scripts for database construction.\n- More operators and technical indicators.\n\nVersion 0.2.1\n-------------\n- Support registering user-defined ``Provider``.\n- Support use operators in string format, e.g. ``['Ref($close, 1)']`` is valid field format.\n- Support dynamic fields in ``$some_field`` format. And existing fields like ``Close()`` may be deprecated in the future.\n\nVersion 0.2.2\n-------------\n- Add ``disk_cache`` for reusing features (enabled by default).\n- Add ``qlib.contrib`` for experimental model construction and evaluation.\n\n\nVersion 0.2.3\n-------------\n- Add ``backtest`` module\n- Decoupling the Strategy, Account, Position, Exchange from the backtest module\n\nVersion 0.2.4\n-------------\n- Add ``profit attribution`` module\n- Add ``rick_control`` and ``cost_control`` strategies\n\nVersion 0.3.0\n-------------\n- Add ``estimator`` module\n\nVersion 0.3.1\n-------------\n- Add ``filter`` module\n\nVersion 0.3.2\n-------------\n- Add real price trading, if the ``factor`` field in the data set is incomplete, use ``adj_price`` trading\n- Refactor ``handler`` ``launcher`` ``trainer`` code\n- Support ``backtest`` configuration parameters in the configuration file\n- Fix bug in position ``amount`` is 0\n- Fix bug of ``filter`` module\n\nVersion 0.3.3\n-------------\n- Fix bug of ``filter`` module\n\nVersion 0.3.4\n-------------\n- Support for ``finetune model``\n- Refactor ``fetcher`` code\n\nVersion 0.3.5\n-------------\n- Support multi-label training, you can provide multiple label in ``handler``. (But LightGBM doesn't support due to the algorithm itself)\n- Refactor ``handler`` code, dataset.py is no longer used, and you can deploy your own labels and features in ``feature_label_config``\n- Handler only offer DataFrame. Also, ``trainer`` and model.py only receive DataFrame\n- Change ``split_rolling_data``, we roll the data on market calendar now, not on normal date\n- Move some date config from ``handler`` to ``trainer``\n\nVersion 0.4.0\n-------------\n- Add `data` package that holds all data-related codes\n- Reform the data provider structure\n- Create a server for data centralized management `qlib-server <https://amc-msra.visualstudio.com/trading-algo/_git/qlib-server>`_\n- Add a `ClientProvider` to work with server\n- Add a pluggable cache mechanism\n- Add a recursive backtracking algorithm to inspect the furthest reference date for an expression\n\n.. note::\n    The ``D.instruments`` function does not support ``start_time``, ``end_time``, and ``as_list`` parameters, if you want to get the results of previous versions of ``D.instruments``, you can do this:\n\n\n    >>> from qlib.data import D\n    >>> instruments = D.instruments(market='csi500')\n    >>> D.list_instruments(instruments=instruments, start_time='2015-01-01', end_time='2016-02-15', as_list=True)\n\n\nVersion 0.4.1\n-------------\n- Add support Windows\n- Fix ``instruments`` type bug\n- Fix ``features`` is empty bug(It will cause failure in updating)\n- Fix ``cache`` lock and update bug\n- Fix use the same cache for the same field (the original space will add a new cache)\n- Change \"logger handler\" from config\n- Change model load support 0.4.0 later\n- The default value of the ``method`` parameter of ``risk_analysis`` function is changed from **ci** to **si**\n\n\nVersion 0.4.2\n-------------\n- Refactor DataHandler\n- Add ``Alpha360`` DataHandler\n\n\nVersion 0.4.3\n-------------\n- Implementing Online Inference and Trading Framework\n- Refactoring The interfaces of backtest and strategy module.\n\n\nVersion 0.4.4\n-------------\n- Optimize cache generation performance\n- Add report module\n- Fix bug when using ``ServerDatasetCache`` offline.\n- In the previous version of ``long_short_backtest``, there is a case of ``np.nan`` in long_short. The current version ``0.4.4`` has been fixed, so ``long_short_backtest`` will be different from the previous version.\n- In the ``0.4.2`` version of ``risk_analysis`` function, ``N`` is ``250``, and ``N`` is ``252`` from ``0.4.3``, so ``0.4.2`` is ``0.002122`` smaller than the ``0.4.3`` the backtest result is slightly different between ``0.4.2`` and ``0.4.3``.\n- refactor the argument of backtest function.\n    - **NOTE**:\n      - The default arguments of topk margin strategy is changed. Please pass the arguments explicitly if you want to get the same backtest result as previous version.\n      - The TopkWeightStrategy is changed slightly. It will try to sell the stocks more than ``topk``.  (The backtest result of TopkAmountStrategy remains the same)\n- The margin ratio mechanism is supported in the Topk Margin strategies.\n\n\nVersion 0.4.5\n-------------\n- Add multi-kernel implementation for both client and server.\n    - Support a new way to load data from client which skips dataset cache.\n    - Change the default dataset method from single kernel implementation to multi kernel implementation.\n- Accelerate the high frequency data reading by optimizing the relative modules.\n- Support a new method to write config file by using dict.\n\nVersion 0.4.6\n-------------\n- Some bugs are fixed\n    - The default config in `Version 0.4.5` is not friendly to daily frequency data.\n    - Backtest error in TopkWeightStrategy when `WithInteract=True`.\n\n\nVersion 0.5.0\n-------------\n- First opensource version\n    - Refine the docs, code\n    - Add baselines\n    - public data crawler\n\n\nVersion 0.8.0\n-------------\n- The backtest is greatly refactored.\n    - Nested decision execution framework is supported\n    - There are lots of changes for daily trading, it is hard to list all of them. But a few important changes could be noticed\n        - The trading limitation is more accurate;\n            - In `previous version <https://github.com/microsoft/qlib/blob/v0.7.2/qlib/contrib/backtest/exchange.py#L160>`__, longing and shorting actions share the same action.\n            - In `current version <https://github.com/microsoft/qlib/blob/7c31012b507a3823117bddcc693fc64899460b2a/qlib/backtest/exchange.py#L304>`__, the trading limitation is different between logging and shorting action.\n        - The constant is different when calculating annualized metrics.\n            - `Current version <https://github.com/microsoft/qlib/blob/7c31012b507a3823117bddcc693fc64899460b2a/qlib/contrib/evaluate.py#L42>`_ uses more accurate constant than `previous version <https://github.com/microsoft/qlib/blob/v0.7.2/qlib/contrib/evaluate.py#L22>`__\n        - `A new version <https://github.com/microsoft/qlib/blob/7c31012b507a3823117bddcc693fc64899460b2a/qlib/tests/data.py#L17>`__ of data is released. Due to the unstability of Yahoo data source, the data may be different after downloading data again.\n        - Users could check out the backtesting results between  `Current version <https://github.com/microsoft/qlib/tree/7c31012b507a3823117bddcc693fc64899460b2a/examples/benchmarks>`__ and `previous version <https://github.com/microsoft/qlib/tree/v0.7.2/examples/benchmarks>`__\n\n\nOther Versions\n--------------\nPlease refer to `Github release Notes <https://github.com/microsoft/qlib/releases>`_\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.43359375,
          "content": "# Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.77734375,
          "content": "FROM continuumio/miniconda3:latest\n\nWORKDIR /qlib\n\nCOPY . .\n\nRUN apt-get update && \\\n    apt-get install -y build-essential\n\nRUN conda create --name qlib_env python=3.8 -y\nRUN echo \"conda activate qlib_env\" >> ~/.bashrc\nENV PATH /opt/conda/envs/qlib_env/bin:$PATH\n\nRUN python -m pip install --upgrade pip\n\nRUN python -m pip install numpy==1.23.5\nRUN python -m pip install pandas==1.5.3\nRUN python -m pip install importlib-metadata==5.2.0\nRUN python -m pip install \"cloudpickle<3\"\nRUN python -m pip install scikit-learn==1.3.2\n\nRUN python -m pip install cython packaging tables matplotlib statsmodels\nRUN python -m pip install pybind11 cvxpy\n\nARG IS_STABLE=\"yes\"\n\nRUN if [ \"$IS_STABLE\" = \"yes\" ]; then \\\n        python -m pip install pyqlib; \\\n    else \\\n        python setup.py install; \\\n    fi\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.1142578125,
          "content": "    MIT License\n\n    Copyright (c) Microsoft Corporation.\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1083984375,
          "content": "exclude tests/*\ninclude qlib/*\ninclude qlib/*/*\ninclude qlib/*/*/*\ninclude qlib/*/*/*/*\ninclude qlib/*/*/*/*/*\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 8.6640625,
          "content": ".PHONY: clean deepclean prerequisite dependencies lightgbm rl develop lint docs package test analysis all install dev black pylint flake8 mypy nbqa nbconvert lint build upload docs-gen\n#You can modify it according to your terminal\nSHELL := /bin/bash\n\n########################################################################################\n# Variables\n########################################################################################\n\n# Documentation target directory, will be adapted to specific folder for readthedocs.\nPUBLIC_DIR := $(shell [ \"$$READTHEDOCS\" = \"True\" ] && echo \"$$READTHEDOCS_OUTPUT/html\" || echo \"public\")\n\nSO_DIR := qlib/data/_libs\nSO_FILES := $(wildcard $(SO_DIR)/*.so)\n\nifeq ($(OS),Windows_NT)\n    IS_WINDOWS = true\nelse\n    IS_WINDOWS = false\nendif\n\n########################################################################################\n# Development Environment Management\n########################################################################################\n# Remove common intermediate files.\nclean:\n\t-rm -rf \\\n\t\t$(PUBLIC_DIR) \\\n\t\tqlib/data/_libs/*.cpp \\\n\t\tqlib/data/_libs/*.so \\\n\t\tmlruns \\\n\t\tpublic \\\n\t\tbuild \\\n\t\t.coverage \\\n\t\t.mypy_cache \\\n\t\t.pytest_cache \\\n\t\t.ruff_cache \\\n\t\tPipfile* \\\n\t\tcoverage.xml \\\n\t\tdist \\\n\t\trelease-notes.md\n\n\tfind . -name '*.egg-info' -print0 | xargs -0 rm -rf\n\tfind . -name '*.pyc' -print0 | xargs -0 rm -f\n\tfind . -name '*.swp' -print0 | xargs -0 rm -f\n\tfind . -name '.DS_Store' -print0 | xargs -0 rm -f\n\tfind . -name '__pycache__' -print0 | xargs -0 rm -rf\n\n# Remove pre-commit hook, virtual environment alongside itermediate files.\ndeepclean: clean\n\tif command -v pre-commit > /dev/null 2>&1; then pre-commit uninstall --hook-type pre-push; fi\n\tif command -v pipenv >/dev/null 2>&1 && pipenv --venv >/dev/null 2>&1; then pipenv --rm; fi\n\n# Prerequisite section\n# What this code does is compile two Cython modules, rolling and expanding, using setuptools and Cython,\n# and builds them as binary expansion modules that can be imported directly into Python.\n# Since pyproject.toml can't do that, we compile it here.\n\n# pywinpty as a dependency of jupyter on windows, if you use pip install pywinpty installation,\n# will first download the tar.gz file, and then locally compiled and installed,\n# this will lead to some unnecessary trouble, so we choose to install the compiled whl file, to avoid trouble.\nprerequisite:\n\t@if [ -n \"$(SO_FILES)\" ]; then \\\n\t\techo \"Shared library files exist, skipping build.\"; \\\n\telse \\\n\t\techo \"No shared library files found, building...\"; \\\n\t\tpip install --upgrade setuptools wheel; \\\n\t\tpython -m pip install cython numpy; \\\n\t\tpython -c \"from setuptools import setup, Extension; from Cython.Build import cythonize; import numpy; extensions = [Extension('qlib.data._libs.rolling', ['qlib/data/_libs/rolling.pyx'], language='c++', include_dirs=[numpy.get_include()]), Extension('qlib.data._libs.expanding', ['qlib/data/_libs/expanding.pyx'], language='c++', include_dirs=[numpy.get_include()])]; setup(ext_modules=cythonize(extensions, language_level='3'), script_args=['build_ext', '--inplace'])\"; \\\n\tfi\n\n\t@if [ \"$(IS_WINDOWS)\" = \"true\" ]; then \\\n\t\tpython -m pip install pywinpty --only-binary=:all:; \\\n\tfi\n\n# Install the package in editable mode.\ndependencies:\n\tpython -m pip install -e .\n\nlightgbm:\n\tpython -m pip install lightgbm --prefer-binary\n\nrl:\n\tpython -m pip install -e .[rl]\n\ndevelop:\n\tpython -m pip install -e .[dev]\n\nlint:\n\tpython -m pip install -e .[lint]\n\ndocs:\n\tpython -m pip install -e .[docs]\n\npackage:\n\tpython -m pip install -e .[package]\n\ntest:\n\tpython -m pip install -e .[test]\n\nanalysis:\n\tpython -m pip install -e .[analysis]\n\nall:\n\tpython -m pip install -e .[pywinpty,dev,lint,docs,package,test,analysis,rl]\n\ninstall: prerequisite dependencies\n\ndev: prerequisite all\n\n########################################################################################\n# Lint and pre-commit\n########################################################################################\n\n# Check lint with black.\nblack:\n\tblack . -l 120 --check --diff\n\n# Check code folder with pylint.\n# TODO: These problems we will solve in the future. Important among them are: W0221, W0223, W0237, E1102\n# \tC0103: invalid-name\n# \tC0209: consider-using-f-string\n# \tR0402: consider-using-from-import\n# \tR1705: no-else-return\n# \tR1710: inconsistent-return-statements\n# \tR1725: super-with-arguments\n# \tR1735: use-dict-literal\n# \tW0102: dangerous-default-value\n# \tW0212: protected-access\n# \tW0221: arguments-differ\n# \tW0223: abstract-method\n# \tW0231: super-init-not-called\n# \tW0237: arguments-renamed\n# \tW0612: unused-variable\n# \tW0621: redefined-outer-name\n# \tW0622: redefined-builtin\n# \tFIXME: specify exception type\n# \tW0703: broad-except\n# \tW1309: f-string-without-interpolation\n# \tE1102: not-callable\n# \tE1136: unsubscriptable-object\n# \tW4904: deprecated-class\n# \tR0917: too-many-positional-arguments\n# \tE1123: unexpected-keyword-arg\n# References for disable error: https://pylint.pycqa.org/en/latest/user_guide/messages/messages_overview.html\n# We use sys.setrecursionlimit(2000) to make the recursion depth larger to ensure that pylint works properly (the default recursion depth is 1000).\n# References for parameters: https://github.com/PyCQA/pylint/issues/4577#issuecomment-1000245962\npylint:\n\tpylint --disable=C0104,C0114,C0115,C0116,C0301,C0302,C0411,C0413,C1802,R0401,R0801,R0902,R0903,R0911,R0912,R0913,R0914,R0915,R0917,R1720,W0105,W0123,W0201,W0511,W0613,W1113,W1514,W4904,E0401,E1121,C0103,C0209,R0402,R1705,R1710,R1725,R1730,R1735,W0102,W0212,W0221,W0223,W0231,W0237,W0612,W0621,W0622,W0703,W1309,E1102,E1136 --const-rgx='[a-z_][a-z0-9_]{2,30}' qlib --init-hook=\"import astroid; astroid.context.InferenceContext.max_inferred = 500; import sys; sys.setrecursionlimit(2000)\"\n\tpylint --disable=C0104,C0114,C0115,C0116,C0301,C0302,C0411,C0413,C1802,R0401,R0801,R0902,R0903,R0911,R0912,R0913,R0914,R0915,R0917,R1720,W0105,W0123,W0201,W0511,W0613,W1113,W1514,E0401,E1121,E1123,C0103,C0209,R0402,R1705,R1710,R1725,R1735,W0102,W0212,W0221,W0223,W0231,W0237,W0246,W0612,W0621,W0622,W0703,W1309,E1102,E1136 --const-rgx='[a-z_][a-z0-9_]{2,30}' scripts --init-hook=\"import astroid; astroid.context.InferenceContext.max_inferred = 500; import sys; sys.setrecursionlimit(2000)\"\n\n# Check code with flake8.\n# The following flake8 error codes were ignored:\n# E501 line too long\n# \tDescription: We have used black to limit the length of each line to 120.\n# F541 f-string is missing placeholders\n# \tDescription: The same thing is done when using pylint for detection.\n# E266 too many leading '#' for block comment\n# \tDescription: To make the code more readable, a lot of \"#\" is used.\n#         This error code appears centrally in:\n# \t\t\tqlib/backtest/executor.py\n# \t\t\tqlib/data/ops.py\n# \t\t\tqlib/utils/__init__.py\n# E402 module level import not at top of file\n# \tDescription: There are times when module level import is not available at the top of the file.\n# W503 line break before binary operator\n# \tDescription: Since black formats the length of each line of code, it has to perform a line break when a line of arithmetic is too long.\n# E731 do not assign a lambda expression, use a def\n# \tDescription: Restricts the use of lambda expressions, but at some point lambda expressions are required.\n# E203 whitespace before ':'\n# \tDescription: If there is whitespace before \":\", it cannot pass the black check.\nflake8:\n\tflake8 --ignore=E501,F541,E266,E402,W503,E731,E203 --per-file-ignores=\"__init__.py:F401,F403\" qlib\n\n# Check code with mypy.\n# https://github.com/python/mypy/issues/10600\nmypy:\n\tmypy qlib --install-types --non-interactive\n\tmypy qlib --verbose\n\n# Check ipynb with nbqa.\nnbqa:\n\tnbqa black . -l 120 --check --diff\n\tnbqa pylint . --disable=C0104,C0114,C0115,C0116,C0301,C0302,C0411,C0413,C1802,R0401,R0801,R0902,R0903,R0911,R0912,R0913,R0914,R0915,R1720,W0105,W0123,W0201,W0511,W0613,W1113,W1514,E0401,E1121,C0103,C0209,R0402,R1705,R1710,R1725,R1735,W0102,W0212,W0221,W0223,W0231,W0237,W0612,W0621,W0622,W0703,W1309,E1102,E1136,W0719,W0104,W0404,C0412,W0611,C0410 --const-rgx='[a-z_][a-z0-9_]{2,30}'\n\n# Check ipynb with nbconvert.(Run after data downloads)\n# TODO: Add more ipynb files in future\nnbconvert:\n\tjupyter nbconvert --to notebook --execute examples/workflow_by_code.ipynb\n\nlint: black pylint flake8 mypy nbqa\n\n########################################################################################\n# Package\n########################################################################################\n\n# Build the package.\nbuild:\n\tpython -m build --wheel\n\n# Upload the package.\nupload:\n\tpython -m twine upload dist/*\n\n########################################################################################\n# Documentation\n########################################################################################\n\ndocs-gen:\n\tpython -m sphinx.cmd.build -W docs $(PUBLIC_DIR)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 40.8701171875,
          "content": "[![Python Versions](https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&logoColor=white)](https://pypi.org/project/pyqlib/#files)\n[![Platform](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey)](https://pypi.org/project/pyqlib/#files)\n[![PypI Versions](https://img.shields.io/pypi/v/pyqlib)](https://pypi.org/project/pyqlib/#history)\n[![Upload Python Package](https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg)](https://pypi.org/project/pyqlib/)\n[![Github Actions Test Status](https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main)](https://github.com/microsoft/qlib/actions)\n[![Documentation Status](https://readthedocs.org/projects/qlib/badge/?version=latest)](https://qlib.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/pypi/l/pyqlib)](LICENSE)\n[![Join the chat at https://gitter.im/Microsoft/qlib](https://badges.gitter.im/Microsoft/qlib.svg)](https://gitter.im/Microsoft/qlib?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n## :newspaper: **What's NEW!** &nbsp;   :sparkling_heart: \n\nRecent released features\n\n### Introducing <a href=\"https://github.com/microsoft/RD-Agent\"><img src=\"docs/_static/img/rdagent_logo.png\" alt=\"RD_Agent\" style=\"height: 2em\"></a>: LLM-Based Autonomous Evolving Agents for Industrial Data-Driven R&D\n\nWe are excited to announce the release of **RD-Agent**📢, a powerful tool that supports automated factor mining and model optimization in quant investment R&D.\n\nRD-Agent is now available on [GitHub](https://github.com/microsoft/RD-Agent), and we welcome your star🌟!\n\nTo learn more, please visit our [♾️Demo page](https://rdagent.azurewebsites.net/). Here, you will find demo videos in both English and Chinese to help you better understand the scenario and usage of RD-Agent.\n\nWe have prepared several demo videos for you:\n| Scenario | Demo video (English) | Demo video (中文) |\n| --                      | ------    | ------    |\n| Quant Factor Mining | [Link](https://rdagent.azurewebsites.net/factor_loop?lang=en) | [Link](https://rdagent.azurewebsites.net/factor_loop?lang=zh) |\n| Quant Factor Mining from reports | [Link](https://rdagent.azurewebsites.net/report_factor?lang=en) | [Link](https://rdagent.azurewebsites.net/report_factor?lang=zh) |\n| Quant Model Optimization | [Link](https://rdagent.azurewebsites.net/model_loop?lang=en) | [Link](https://rdagent.azurewebsites.net/model_loop?lang=zh) |\n\n***\n\n| Feature | Status |\n| --                      | ------    |\n| BPQP for End-to-end learning | 📈Coming soon!([Under review](https://github.com/microsoft/qlib/pull/1863)) |\n| 🔥LLM-driven Auto Quant Factory🔥 | 🚀 Released in [♾️RD-Agent](https://github.com/microsoft/RD-Agent) on Aug 8, 2024 |\n| KRNN and Sandwich models | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/1414/) on May 26, 2023 |\n| Release Qlib v0.9.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.9.0) on Dec 9, 2022 |\n| RL Learning Framework | :hammer: :chart_with_upwards_trend: Released on Nov 10, 2022. [#1332](https://github.com/microsoft/qlib/pull/1332), [#1322](https://github.com/microsoft/qlib/pull/1322), [#1316](https://github.com/microsoft/qlib/pull/1316),[#1299](https://github.com/microsoft/qlib/pull/1299),[#1263](https://github.com/microsoft/qlib/pull/1263), [#1244](https://github.com/microsoft/qlib/pull/1244), [#1169](https://github.com/microsoft/qlib/pull/1169), [#1125](https://github.com/microsoft/qlib/pull/1125), [#1076](https://github.com/microsoft/qlib/pull/1076)|\n| HIST and IGMTF models | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/1040) on Apr 10, 2022 |\n| Qlib [notebook tutorial](https://github.com/microsoft/qlib/tree/main/examples/tutorial) | 📖 [Released](https://github.com/microsoft/qlib/pull/1037) on Apr 7, 2022 | \n| Ibovespa index data | :rice: [Released](https://github.com/microsoft/qlib/pull/990) on Apr 6, 2022 |\n| Point-in-Time database | :hammer: [Released](https://github.com/microsoft/qlib/pull/343) on Mar 10, 2022 |\n| Arctic Provider Backend & Orderbook data example | :hammer: [Released](https://github.com/microsoft/qlib/pull/744) on Jan 17, 2022 |\n| Meta-Learning-based framework & DDG-DA  | :chart_with_upwards_trend:  :hammer: [Released](https://github.com/microsoft/qlib/pull/743) on Jan 10, 2022 | \n| Planning-based portfolio optimization | :hammer: [Released](https://github.com/microsoft/qlib/pull/754) on Dec 28, 2021 | \n| Release Qlib v0.8.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.8.0) on Dec 8, 2021 |\n| ADD model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/704) on Nov 22, 2021 |\n| ADARNN  model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/689) on Nov 14, 2021 |\n| TCN  model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/668) on Nov 4, 2021 |\n| Nested Decision Framework | :hammer: [Released](https://github.com/microsoft/qlib/pull/438) on Oct 1, 2021. [Example](https://github.com/microsoft/qlib/blob/main/examples/nested_decision_execution/workflow.py) and [Doc](https://qlib.readthedocs.io/en/latest/component/highfreq.html) |\n| Temporal Routing Adaptor (TRA) | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/531) on July 30, 2021 |\n| Transformer & Localformer | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/508) on July 22, 2021 |\n| Release Qlib v0.7.0 | :octocat: [Released](https://github.com/microsoft/qlib/releases/tag/v0.7.0) on July 12, 2021 |\n| TCTS Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/491) on July 1, 2021 |\n| Online serving and automatic model rolling | :hammer:  [Released](https://github.com/microsoft/qlib/pull/290) on May 17, 2021 | \n| DoubleEnsemble Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/286) on Mar 2, 2021 | \n| High-frequency data processing example | :hammer: [Released](https://github.com/microsoft/qlib/pull/257) on Feb 5, 2021  |\n| High-frequency trading example | :chart_with_upwards_trend: [Part of code released](https://github.com/microsoft/qlib/pull/227) on Jan 28, 2021  | \n| High-frequency data(1min) | :rice: [Released](https://github.com/microsoft/qlib/pull/221) on Jan 27, 2021 |\n| Tabnet Model | :chart_with_upwards_trend: [Released](https://github.com/microsoft/qlib/pull/205) on Jan 22, 2021 |\n\nFeatures released before 2021 are not listed here.\n\n<p align=\"center\">\n  <img src=\"docs/_static/img/logo/1.png\" />\n</p>\n\nQlib is an open-source, AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning.\n\nAn increasing number of SOTA Quant research works/papers in diverse paradigms are being released in Qlib to collaboratively solve key challenges in quantitative investment. For example, 1) using supervised learning to mine the market's complex non-linear patterns from rich and heterogeneous financial data, 2) modeling the dynamic nature of the financial market using adaptive concept drift technology, and 3) using reinforcement learning to model continuous investment decisions and assist investors in optimizing their trading strategies.\n\nIt contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. \nFor more details, please refer to our paper [\"Qlib: An AI-oriented Quantitative Investment Platform\"](https://arxiv.org/abs/2009.11189).\n\n\n<table>\n  <tbody>\n    <tr>\n      <th>Frameworks, Tutorial, Data & DevOps</th>\n      <th>Main Challenges & Solutions in Quant Research</th>\n    </tr>\n    <tr>\n      <td>\n        <li><a href=\"#plans\"><strong>Plans</strong></a></li>\n        <li><a href=\"#framework-of-qlib\">Framework of Qlib</a></li>\n        <li><a href=\"#quick-start\">Quick Start</a></li>\n          <ul dir=\"auto\">\n            <li type=\"circle\"><a href=\"#installation\">Installation</a> </li>\n            <li type=\"circle\"><a href=\"#data-preparation\">Data Preparation</a></li>\n            <li type=\"circle\"><a href=\"#auto-quant-research-workflow\">Auto Quant Research Workflow</a></li>\n            <li type=\"circle\"><a href=\"#building-customized-quant-research-workflow-by-code\">Building Customized Quant Research Workflow by Code</a></li></ul>\n        <li><a href=\"#quant-dataset-zoo\"><strong>Quant Dataset Zoo</strong></a></li>\n        <li><a href=\"#learning-framework\">Learning Framework</a></li>\n        <li><a href=\"#more-about-qlib\">More About Qlib</a></li>\n        <li><a href=\"#offline-mode-and-online-mode\">Offline Mode and Online Mode</a>\n        <ul>\n          <li type=\"circle\"><a href=\"#performance-of-qlib-data-server\">Performance of Qlib Data Server</a></li></ul>\n        <li><a href=\"#related-reports\">Related Reports</a></li>\n        <li><a href=\"#contact-us\">Contact Us</a></li>\n        <li><a href=\"#contributing\">Contributing</a></li>\n      </td>\n      <td valign=\"baseline\">\n        <li><a href=\"#main-challenges--solutions-in-quant-research\">Main Challenges &amp; Solutions in Quant Research</a>\n          <ul>\n            <li type=\"circle\"><a href=\"#forecasting-finding-valuable-signalspatterns\">Forecasting: Finding Valuable Signals/Patterns</a>\n              <ul>\n                <li type=\"disc\"><a href=\"#quant-model-paper-zoo\"><strong>Quant Model (Paper) Zoo</strong></a>\n                  <ul>\n                    <li type=\"circle\"><a href=\"#run-a-single-model\">Run a Single Model</a></li>\n                    <li type=\"circle\"><a href=\"#run-multiple-models\">Run Multiple Models</a></li>\n                  </ul>\n                </li>\n              </ul>\n            </li>\n          <li type=\"circle\"><a href=\"#adapting-to-market-dynamics\">Adapting to Market Dynamics</a></li>\n          <li type=\"circle\"><a href=\"#reinforcement-learning-modeling-continuous-decisions\">Reinforcement Learning: modeling continuous decisions</a></li>\n          </ul>\n        </li>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n# Plans\nNew features under development(order by estimated release time).\nYour feedbacks about the features are very important.\n<!-- | Feature                        | Status      | -->\n<!-- | --                      | ------    | -->\n\n# Framework of Qlib\n\n<div style=\"align: center\">\n<img src=\"docs/_static/img/framework-abstract.jpg\" />\n</div>\n\nThe high-level framework of Qlib can be found above(users can find the [detailed framework](https://qlib.readthedocs.io/en/latest/introduction/introduction.html#framework) of Qlib's design when getting into nitty gritty).\nThe components are designed as loose-coupled modules, and each component could be used stand-alone.\n\nQlib provides a strong infrastructure to support Quant research. [Data](https://qlib.readthedocs.io/en/latest/component/data.html) is always an important part.\nA strong learning framework is designed to support diverse learning paradigms (e.g. [reinforcement learning](https://qlib.readthedocs.io/en/latest/component/rl.html), [supervised learning](https://qlib.readthedocs.io/en/latest/component/workflow.html#model-section)) and patterns at different levels(e.g. [market dynamic modeling](https://qlib.readthedocs.io/en/latest/component/meta.html)).\nBy modeling the market, [trading strategies](https://qlib.readthedocs.io/en/latest/component/strategy.html) will generate trade decisions that will be executed. Multiple trading strategies and executors in different levels or granularities can be [nested to be optimized and run together](https://qlib.readthedocs.io/en/latest/component/highfreq.html).\nAt last, a comprehensive [analysis](https://qlib.readthedocs.io/en/latest/component/report.html) will be provided and the model can be [served online](https://qlib.readthedocs.io/en/latest/component/online.html) in a low cost.\n\n\n# Quick Start\n\nThis quick start guide tries to demonstrate\n1. It's very easy to build a complete Quant research workflow and try your ideas with _Qlib_.\n2. Though with *public data* and *simple models*, machine learning technologies **work very well** in practical Quant investment.\n\nHere is a quick **[demo](https://terminalizer.com/view/3f24561a4470)** shows how to install ``Qlib``, and run LightGBM with ``qrun``. **But**, please make sure you have already prepared the data following the [instruction](#data-preparation).\n\n\n## Installation\n\nThis table demonstrates the supported Python version of `Qlib`:\n|               | install with pip      | install from source  |        plot        |\n| ------------- |:---------------------:|:--------------------:|:------------------:|\n| Python 3.8    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.9    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.10   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.11   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.12   | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n\n**Note**: \n1. **Conda** is suggested for managing your Python environment. In some cases, using Python outside of a `conda` environment may result in missing header files, causing the installation failure of certain packages.\n2. Please pay attention that installing cython in Python 3.6 will raise some error when installing ``Qlib`` from source. If users use Python 3.6 on their machines, it is recommended to *upgrade* Python to version 3.8 or higher, or use `conda`'s Python to install ``Qlib`` from source.\n\n### Install with pip\nUsers can easily install ``Qlib`` by pip according to the following command.\n\n```bash\n  pip install pyqlib\n```\n\n**Note**: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.\n\n### Install from source\nAlso, users can install the latest dev version ``Qlib`` by the source code according to the following steps:\n\n* Before installing ``Qlib`` from source, users need to install some dependencies:\n\n  ```bash\n  pip install numpy\n  pip install --upgrade cython\n  ```\n\n* Clone the repository and install ``Qlib`` as follows.\n    ```bash\n    git clone https://github.com/microsoft/qlib.git && cd qlib\n    pip install .  # `pip install -e .[dev]` is recommended for development. check details in docs/developer/code_standard_and_dev_guide.rst\n    ```\n\n**Tips**: If you fail to install `Qlib` or run the examples in your environment,  comparing your steps and the [CI workflow](.github/workflows/test_qlib_from_source.yml) may help you find the problem.\n\n**Tips for Mac**: If you are using Mac with M1, you might encounter issues in building the wheel for LightGBM, which is due to missing dependencies from OpenMP. To solve the problem, install openmp first with ``brew install libomp`` and then run ``pip install .`` to build it successfully. \n\n## Data Preparation\n❗ Due to more restrict data security policy. The offical dataset is disabled temporarily. You can try [this data source](https://github.com/chenditc/investment_data/releases) contributed by the community.\nHere is an example to download the latest data.\n```bash\nwget https://github.com/chenditc/investment_data/releases/latest/download/qlib_bin.tar.gz\nmkdir -p ~/.qlib/qlib_data/cn_data\ntar -zxvf qlib_bin.tar.gz -C ~/.qlib/qlib_data/cn_data --strip-components=2\nrm -f qlib_bin.tar.gz\n```\n\nThe official dataset below will resume in short future.\n\n\n----\n\nLoad and prepare data by running the following code:\n\n### Get with module\n  ```bash\n  # get 1d data\n  python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n  # get 1min data\n  python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n\n  ```\n\n### Get from source\n\n  ```bash\n  # get 1d data\n  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n  # get 1min data\n  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n\n  ```\n\nThis dataset is created by public data collected by [crawler scripts](scripts/data_collector/), which have been released in\nthe same repository.\nUsers could create the same dataset with it. [Description of dataset](https://github.com/microsoft/qlib/tree/main/scripts/data_collector#description-of-dataset)\n\n*Please pay **ATTENTION** that the data is collected from [Yahoo Finance](https://finance.yahoo.com/lookup), and the data might not be perfect.\nWe recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the [related document](https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format)*.\n\n### Automatic update of daily frequency data (from yahoo finance)\n  > This step is *Optional* if users only want to try their models and strategies on history data.\n  > \n  > It is recommended that users update the data manually once (--trading_date 2021-05-25) and then set it to update automatically.\n  >\n  > **NOTE**: Users can't incrementally  update data based on the offline data provided by Qlib(some fields are removed to reduce the data size). Users should use [yahoo collector](https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance) to download Yahoo data from scratch and then incrementally update it.\n  > \n  > For more information, please refer to: [yahoo collector](https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo#automatic-update-of-daily-frequency-datafrom-yahoo-finance)\n\n  * Automatic update of data to the \"qlib\" directory each trading day(Linux)\n      * use *crontab*: `crontab -e`\n      * set up timed tasks:\n\n        ```\n        * * * * 1-5 python <script path> update_data_to_bin --qlib_data_1d_dir <user data dir>\n        ```\n        * **script path**: *scripts/data_collector/yahoo/collector.py*\n\n  * Manual update of data\n      ```\n      python scripts/data_collector/yahoo/collector.py update_data_to_bin --qlib_data_1d_dir <user data dir> --trading_date <start date> --end_date <end date>\n      ```\n      * *trading_date*: start of trading day\n      * *end_date*: end of trading day(not included)\n\n### Checking the health of the data\n  * We provide a script to check the health of the data, you can run the following commands to check whether the data is healthy or not.\n    ```\n    python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data\n    ```\n  * Of course, you can also add some parameters to adjust the test results, such as this.\n    ```\n    python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data --missing_data_num 30055 --large_step_threshold_volume 94485 --large_step_threshold_price 20\n    ```\n  * If you want more information about `check_data_health`, please refer to the [documentation](https://qlib.readthedocs.io/en/latest/component/data.html#checking-the-health-of-the-data).\n\n<!-- \n- Run the initialization code and get stock data:\n\n  ```python\n  import qlib\n  from qlib.data import D\n  from qlib.constant import REG_CN\n\n  # Initialization\n  mount_path = \"~/.qlib/qlib_data/cn_data\"  # target_dir\n  qlib.init(mount_path=mount_path, region=REG_CN)\n\n  # Get stock data by Qlib\n  # Load trading calendar with the given time range and frequency\n  print(D.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2])\n\n  # Parse a given market name into a stockpool config\n  instruments = D.instruments('csi500')\n  print(D.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6])\n\n  # Load features of certain instruments in given time range\n  instruments = ['SH600000']\n  fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']\n  print(D.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head())\n  ```\n -->\n\n## Docker images\n1. Pulling a docker image from a docker hub repository\n    ```bash\n    docker pull pyqlib/qlib_image_stable:stable\n    ```\n2. Start a new Docker container\n    ```bash\n    docker run -it --name <container name> -v <Mounted local directory>:/app qlib_image_stable\n    ```\n3. At this point you are in the docker environment and can run the qlib scripts. An example:\n    ```bash\n    >>> python scripts/get_data.py qlib_data --name qlib_data_simple --target_dir ~/.qlib/qlib_data/cn_data --interval 1d --region cn\n    >>> python qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n    ```\n4. Exit the container\n    ```bash\n    >>> exit\n    ```\n5. Restart the container\n    ```bash\n    docker start -i -a <container name>\n    ```\n6. Stop the container\n    ```bash\n    docker stop <container name>\n    ```\n7. Delete the container\n    ```bash\n    docker rm <container name>\n    ```\n8. If you want to know more information, please refer to the [documentation](https://qlib.readthedocs.io/en/latest/developer/how_to_build_image.html).\n\n## Auto Quant Research Workflow\nQlib provides a tool named `qrun` to run the whole workflow automatically (including building dataset, training models, backtest and evaluation). You can start an auto quant research workflow and have a graphical reports analysis according to the following steps: \n\n1. Quant Research Workflow: Run  `qrun` with lightgbm workflow config ([workflow_config_lightgbm_Alpha158.yaml](examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml) as following.\n    ```bash\n      cd examples  # Avoid running program under the directory contains `qlib`\n      qrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n    ```\n    If users want to use `qrun` under debug mode, please use the following command:\n    ```bash\n    python -m pdb qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n    ```\n    The result of `qrun` is as follows, please refer to [Intraday Trading](https://qlib.readthedocs.io/en/latest/component/backtest.html) for more details about the result. \n\n    ```bash\n\n    'The following are analysis results of the excess return without cost.'\n                           risk\n    mean               0.000708\n    std                0.005626\n    annualized_return  0.178316\n    information_ratio  1.996555\n    max_drawdown      -0.081806\n    'The following are analysis results of the excess return with cost.'\n                           risk\n    mean               0.000512\n    std                0.005626\n    annualized_return  0.128982\n    information_ratio  1.444287\n    max_drawdown      -0.091078\n    ```\n    Here are detailed documents for `qrun` and [workflow](https://qlib.readthedocs.io/en/latest/component/workflow.html).\n\n2. Graphical Reports Analysis: First, run `python -m pip install .[analysis]` to install the required dependencies. Then run `examples/workflow_by_code.ipynb` with `jupyter notebook` to get graphical reports. \n    - Forecasting signal (model prediction) analysis\n      - Cumulative Return of groups\n      ![Cumulative Return](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_cumulative_return.png)\n      - Return distribution\n      ![long_short](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_long_short.png)\n      - Information Coefficient (IC)\n      ![Information Coefficient](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_IC.png)\n      ![Monthly IC](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_monthly_IC.png)\n      ![IC](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_NDQ.png)\n      - Auto Correlation of forecasting signal (model prediction)\n      ![Auto Correlation](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/analysis_model_auto_correlation.png)\n\n    - Portfolio analysis\n      - Backtest return\n      ![Report](https://github.com/microsoft/qlib/blob/main/docs/_static/img/analysis/report.png)\n      <!-- \n      - Score IC\n      ![Score IC](docs/_static/img/score_ic.png)\n      - Cumulative Return\n      ![Cumulative Return](docs/_static/img/cumulative_return.png)\n      - Risk Analysis\n      ![Risk Analysis](docs/_static/img/risk_analysis.png)\n      - Rank Label\n      ![Rank Label](docs/_static/img/rank_label.png)\n      -->\n   - [Explanation](https://qlib.readthedocs.io/en/latest/component/report.html) of above results\n\n## Building Customized Quant Research Workflow by Code\nThe automatic workflow may not suit the research workflow of all Quant researchers. To support a flexible Quant research workflow, Qlib also provides a modularized interface to allow researchers to build their own workflow by code. [Here](examples/workflow_by_code.ipynb) is a demo for customized Quant research workflow by code.\n\n# Main Challenges & Solutions in Quant Research\nQuant investment is a very unique scenario with lots of key challenges to be solved.\nCurrently, Qlib provides some solutions for several of them.\n\n## Forecasting: Finding Valuable Signals/Patterns\nAccurate forecasting of the stock price trend is a very important part to construct profitable portfolios.\nHowever, huge amount of data with various formats in the financial market which make it challenging to build forecasting models.\n\nAn increasing number of SOTA Quant research works/papers, which focus on building forecasting models to mine valuable signals/patterns in complex financial data, are released in `Qlib`\n\n\n### [Quant Model (Paper) Zoo](examples/benchmarks)\n\nHere is a list of models built on `Qlib`.\n- [GBDT based on XGBoost (Tianqi Chen, et al. KDD 2016)](examples/benchmarks/XGBoost/)\n- [GBDT based on LightGBM (Guolin Ke, et al. NIPS 2017)](examples/benchmarks/LightGBM/)\n- [GBDT based on Catboost (Liudmila Prokhorenkova, et al. NIPS 2018)](examples/benchmarks/CatBoost/)\n- [MLP based on pytorch](examples/benchmarks/MLP/)\n- [LSTM based on pytorch (Sepp Hochreiter, et al. Neural computation 1997)](examples/benchmarks/LSTM/)\n- [GRU based on pytorch (Kyunghyun Cho, et al. 2014)](examples/benchmarks/GRU/)\n- [ALSTM based on pytorch (Yao Qin, et al. IJCAI 2017)](examples/benchmarks/ALSTM)\n- [GATs based on pytorch (Petar Velickovic, et al. 2017)](examples/benchmarks/GATs/)\n- [SFM based on pytorch (Liheng Zhang, et al. KDD 2017)](examples/benchmarks/SFM/)\n- [TFT based on tensorflow (Bryan Lim, et al. International Journal of Forecasting 2019)](examples/benchmarks/TFT/)\n- [TabNet based on pytorch (Sercan O. Arik, et al. AAAI 2019)](examples/benchmarks/TabNet/)\n- [DoubleEnsemble based on LightGBM (Chuheng Zhang, et al. ICDM 2020)](examples/benchmarks/DoubleEnsemble/)\n- [TCTS based on pytorch (Xueqing Wu, et al. ICML 2021)](examples/benchmarks/TCTS/)\n- [Transformer based on pytorch (Ashish Vaswani, et al. NeurIPS 2017)](examples/benchmarks/Transformer/)\n- [Localformer based on pytorch (Juyong Jiang, et al.)](examples/benchmarks/Localformer/)\n- [TRA based on pytorch (Hengxu, Dong, et al. KDD 2021)](examples/benchmarks/TRA/)\n- [TCN based on pytorch (Shaojie Bai, et al. 2018)](examples/benchmarks/TCN/)\n- [ADARNN based on pytorch (YunTao Du, et al. 2021)](examples/benchmarks/ADARNN/)\n- [ADD based on pytorch (Hongshun Tang, et al.2020)](examples/benchmarks/ADD/)\n- [IGMTF based on pytorch (Wentao Xu, et al.2021)](examples/benchmarks/IGMTF/)\n- [HIST based on pytorch (Wentao Xu, et al.2021)](examples/benchmarks/HIST/)\n- [KRNN based on pytorch](examples/benchmarks/KRNN/)\n- [Sandwich based on pytorch](examples/benchmarks/Sandwich/)\n\nYour PR of new Quant models is highly welcomed.\n\nThe performance of each model on the `Alpha158` and `Alpha360` datasets can be found [here](examples/benchmarks/README.md).\n\n### Run a single model\nAll the models listed above are runnable with ``Qlib``. Users can find the config files we provide and some details about the model through the [benchmarks](examples/benchmarks) folder. More information can be retrieved at the model files listed above.\n\n`Qlib` provides three different ways to run a single model, users can pick the one that fits their cases best:\n- Users can use the tool `qrun` mentioned above to run a model's workflow based from a config file.\n- Users can create a `workflow_by_code` python script based on the [one](examples/workflow_by_code.py) listed in the `examples` folder.\n\n- Users can use the script [`run_all_model.py`](examples/run_all_model.py) listed in the `examples` folder to run a model. Here is an example of the specific shell command to be used: `python run_all_model.py run --models=lightgbm`, where the `--models` arguments can take any number of models listed above(the available models can be found  in [benchmarks](examples/benchmarks/)). For more use cases, please refer to the file's [docstrings](examples/run_all_model.py).\n    - **NOTE**: Each baseline has different environment dependencies, please make sure that your python version aligns with the requirements(e.g. TFT only supports Python 3.6~3.7 due to the limitation of `tensorflow==1.15.0`)\n\n### Run multiple models\n`Qlib` also provides a script [`run_all_model.py`](examples/run_all_model.py) which can run multiple models for several iterations. (**Note**: the script only support *Linux* for now. Other OS will be supported in the future. Besides, it doesn't support parallel running the same model for multiple times as well, and this will be fixed in the future development too.)\n\nThe script will create a unique virtual environment for each model, and delete the environments after training. Thus, only experiment results such as `IC` and `backtest` results will be generated and stored.\n\nHere is an example of running all the models for 10 iterations:\n```python\npython run_all_model.py run 10\n```\n\nIt also provides the API to run specific models at once. For more use cases, please refer to the file's [docstrings](examples/run_all_model.py). \n\n## [Adapting to Market Dynamics](examples/benchmarks_dynamic)\n\nDue to the non-stationary nature of the environment of the financial market, the data distribution may change in different periods, which makes the performance of models build on training data decays in the future test data.\nSo adapting the forecasting models/strategies to market dynamics is very important to the model/strategies' performance.\n\nHere is a list of solutions built on `Qlib`.\n- [Rolling Retraining](examples/benchmarks_dynamic/baseline/)\n- [DDG-DA on pytorch (Wendi, et al. AAAI 2022)](examples/benchmarks_dynamic/DDG-DA/)\n\n##  Reinforcement Learning: modeling continuous decisions\nQlib now supports reinforcement learning, a feature designed to model continuous investment decisions. This functionality assists investors in optimizing their trading strategies by learning from interactions with the environment to maximize some notion of cumulative reward.\n\nHere is a list of solutions built on `Qlib` categorized by scenarios.\n\n### [RL for order execution](examples/rl_order_execution)\n[Here](https://qlib.readthedocs.io/en/latest/component/rl/overall.html#order-execution) is the introduction of this scenario.  All the methods below are compared [here](examples/rl_order_execution).\n- [TWAP](examples/rl_order_execution/exp_configs/backtest_twap.yml)\n- [PPO: \"An End-to-End Optimal Trade Execution Framework based on Proximal Policy Optimization\", IJCAL 2020](examples/rl_order_execution/exp_configs/backtest_ppo.yml)\n- [OPDS: \"Universal Trading for Order Execution with Oracle Policy Distillation\", AAAI 2021](examples/rl_order_execution/exp_configs/backtest_opds.yml)\n\n# Quant Dataset Zoo\nDataset plays a very important role in Quant. Here is a list of the datasets built on `Qlib`:\n\n| Dataset                                    | US Market | China Market |\n| --                                         | --        | --           |\n| [Alpha360](./qlib/contrib/data/handler.py) |  √        |  √           |\n| [Alpha158](./qlib/contrib/data/handler.py) |  √        |  √           |\n\n[Here](https://qlib.readthedocs.io/en/latest/advanced/alpha.html) is a tutorial to build dataset with `Qlib`.\nYour PR to build new Quant dataset is highly welcomed.\n\n\n# Learning Framework\nQlib is high customizable and a lot of its components are learnable.\nThe learnable components are instances of `Forecast Model` and `Trading Agent`. They are learned based on the `Learning Framework` layer and then applied to multiple scenarios in `Workflow` layer.\nThe learning framework leverages the `Workflow` layer as well(e.g. sharing `Information Extractor`, creating environments based on `Execution Env`).\n\nBased on learning paradigms, they can be categorized into reinforcement learning and supervised learning.\n- For supervised learning, the detailed docs can be found [here](https://qlib.readthedocs.io/en/latest/component/model.html).\n- For reinforcement learning, the detailed docs can be found [here](https://qlib.readthedocs.io/en/latest/component/rl.html). Qlib's RL learning framework leverages `Execution Env` in `Workflow` layer to create environments.  It's worth noting that `NestedExecutor` is supported as well. This empowers users to optimize different level of strategies/models/agents together (e.g. optimizing an order execution strategy for a specific portfolio management strategy).\n\n\n# More About Qlib\nIf you want to have a quick glance at the most frequently used components of qlib, you can try notebooks [here](examples/tutorial/).\n\nThe detailed documents are organized in [docs](docs/).\n[Sphinx](http://www.sphinx-doc.org) and the readthedocs theme is required to build the documentation in html formats. \n```bash\ncd docs/\nconda install sphinx sphinx_rtd_theme -y\n# Otherwise, you can install them with pip\n# pip install sphinx sphinx_rtd_theme\nmake html\n```\nYou can also view the [latest document](http://qlib.readthedocs.io/) online directly.\n\nQlib is in active and continuing development. Our plan is in the roadmap, which is managed as a [github project](https://github.com/microsoft/qlib/projects/1).\n\n\n\n# Offline Mode and Online Mode\nThe data server of Qlib can either deployed as `Offline` mode or `Online` mode. The default mode is offline mode.\n\nUnder `Offline` mode, the data will be deployed locally. \n\nUnder `Online` mode, the data will be deployed as a shared data service. The data and their cache will be shared by all the clients. The data retrieval performance is expected to be improved due to a higher rate of cache hits. It will consume less disk space, too. The documents of the online mode can be found in [Qlib-Server](https://qlib-server.readthedocs.io/). The online mode can be deployed automatically with [Azure CLI based scripts](https://qlib-server.readthedocs.io/en/latest/build.html#one-click-deployment-in-azure). The source code of online data server can be found in [Qlib-Server repository](https://github.com/microsoft/qlib-server).\n\n## Performance of Qlib Data Server\nThe performance of data processing is important to data-driven methods like AI technologies. As an AI-oriented platform, Qlib provides a solution for data storage and data processing. To demonstrate the performance of Qlib data server, we\ncompare it with several other data storage solutions. \n\nWe evaluate the performance of several storage solutions by finishing the same task,\nwhich creates a dataset (14 features/factors) from the basic OHLCV daily data of a stock market (800 stocks each day from 2007 to 2020). The task involves data queries and processing.\n\n|                         | HDF5      | MySQL     | MongoDB   | InfluxDB  | Qlib -E -D  | Qlib +E -D   | Qlib +E +D  |\n| --                      | ------    | ------    | --------  | --------- | ----------- | ------------ | ----------- |\n| Total (1CPU) (seconds)  | 184.4±3.7 | 365.3±7.5 | 253.6±6.7 | 368.2±3.6 | 147.0±8.8   | 47.6±1.0     | **7.4±0.3** |\n| Total (64CPU) (seconds) |           |           |           |           | 8.8±0.6     | **4.2±0.2**  |             |\n* `+(-)E` indicates with (out) `ExpressionCache`\n* `+(-)D` indicates with (out) `DatasetCache`\n\nMost general-purpose databases take too much time to load data. After looking into the underlying implementation, we find that data go through too many layers of interfaces and unnecessary format transformations in general-purpose database solutions.\nSuch overheads greatly slow down the data loading process.\nQlib data are stored in a compact format, which is efficient to be combined into arrays for scientific computation.\n\n# Related Reports\n- [Guide To Qlib: Microsoft’s AI Investment Platform](https://analyticsindiamag.com/qlib/)\n- [微软也搞AI量化平台？还是开源的！](https://mp.weixin.qq.com/s/47bP5YwxfTp2uTHjUBzJQQ)\n- [微矿Qlib：业内首个AI量化投资开源平台](https://mp.weixin.qq.com/s/vsJv7lsgjEi-ALYUz4CvtQ)\n\n# Contact Us\n- If you have any issues, please create issue [here](https://github.com/microsoft/qlib/issues/new/choose) or send messages in [gitter](https://gitter.im/Microsoft/qlib).\n- If you want to make contributions to `Qlib`, please [create pull requests](https://github.com/microsoft/qlib/compare). \n- For other reasons, you are welcome to contact us by email([qlib@microsoft.com](mailto:qlib@microsoft.com)).\n  - We are recruiting new members(both FTEs and interns), your resumes are welcome!\n\nJoin IM discussion groups:\n|[Gitter](https://gitter.im/Microsoft/qlib)|\n|----|\n|![image](https://github.com/microsoft/qlib/blob/main/docs/_static/img/qrcode/gitter_qr.png)|\n\n# Contributing\nWe appreciate all contributions and thank all the contributors!\n<a href=\"https://github.com/microsoft/qlib/graphs/contributors\"><img src=\"https://contrib.rocks/image?repo=microsoft/qlib\" /></a>\n\nBefore we released Qlib as an open-source project on Github in Sep 2020, Qlib is an internal project in our group. Unfortunately, the internal commit history is not kept. A lot of members in our group have also contributed a lot to Qlib, which includes Ruihua Wang, Yinda Zhang, Haisu Yu, Shuyu Wang, Bochen Pang, and [Dong Zhou](https://github.com/evanzd/evanzd). Especially thanks to [Dong Zhou](https://github.com/evanzd/evanzd) due to his initial version of Qlib.\n\n## Guidance\n\nThis project welcomes contributions and suggestions.  \n**Here are some \n[code standards and development guidance](docs/developer/code_standard_and_dev_guide.rst) for submiting a pull request.**\n\nMaking contributions is not a hard thing. Solving an issue(maybe just answering a question raised in [issues list](https://github.com/microsoft/qlib/issues) or [gitter](https://gitter.im/Microsoft/qlib)), fixing/issuing a bug, improving the documents and even fixing a typo are important contributions to Qlib.\n\nFor example, if you want to contribute to Qlib's document/code, you can follow the steps in the figure below.\n<p align=\"center\">\n  <img src=\"https://github.com/demon143/qlib/blob/main/docs/_static/img/change%20doc.gif\" />\n</p>\n\nIf you don't know how to start to contribute, you can refer to the following examples.\n| Type | Examples |\n| -- | -- |\n| Solving issues | [Answer a question](https://github.com/microsoft/qlib/issues/749);  [issuing](https://github.com/microsoft/qlib/issues/765) or [fixing](https://github.com/microsoft/qlib/pull/792) a bug |\n| Docs | [Improve docs quality](https://github.com/microsoft/qlib/pull/797/files) ;  [Fix a typo](https://github.com/microsoft/qlib/pull/774) | \n| Feature |  Implement a [requested feature](https://github.com/microsoft/qlib/projects) like [this](https://github.com/microsoft/qlib/pull/754); [Refactor interfaces](https://github.com/microsoft/qlib/pull/539/files) |\n| Dataset | [Add a dataset](https://github.com/microsoft/qlib/pull/733) | \n| Models |  [Implement a new model](https://github.com/microsoft/qlib/pull/689), [some instructions to contribute models](https://github.com/microsoft/qlib/tree/main/examples/benchmarks#contributing) |\n\n[Good first issues](https://github.com/microsoft/qlib/labels/good%20first%20issue) are labelled to indicate that they are easy to start your contributions.\n\nYou can find some impefect implementation in Qlib by  `rg 'TODO|FIXME' qlib`\n \nIf you would like to become one of Qlib's maintainers to contribute more (e.g. help merge PR, triage issues), please contact us by email([qlib@microsoft.com](mailto:qlib@microsoft.com)).  We are glad to help to upgrade your permission.\n\n## Licence\nMost contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe right to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.71484375,
          "content": "<!-- BEGIN MICROSOFT SECURITY.MD V0.0.5 BLOCK -->\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc751383(v=technet.10)), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://msrc.microsoft.com/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://www.microsoft.com/en-us/msrc/pgp-key-msrc).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc). \n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://microsoft.com/msrc/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://www.microsoft.com/en-us/msrc/cvd).\n\n<!-- END MICROSOFT SECURITY.MD BLOCK -->"
        },
        {
          "name": "build_docker_image.sh",
          "type": "blob",
          "size": 1.0439453125,
          "content": "#!/bin/bash\n\ndocker_user=\"your_dockerhub_username\"\n\nread -p \"Do you want to build the nightly version of the qlib image? (default is stable) (yes/no): \" answer;\nanswer=$(echo \"$answer\" | tr '[:upper:]' '[:lower:]')\n\nif [ \"$answer\" = \"yes\" ]; then\n    # Build the nightly version of the qlib image\n    docker build --build-arg IS_STABLE=no -t qlib_image -f ./Dockerfile .\n    image_tag=\"nightly\"\nelse\n    # Build the stable version of the qlib image\n    docker build -t qlib_image -f ./Dockerfile .\n    image_tag=\"stable\"\nfi\n\nread -p \"Is it uploaded to docker hub? (default is no) (yes/no): \" answer;\nanswer=$(echo \"$answer\" | tr '[:upper:]' '[:lower:]')\n\nif [ \"$answer\" = \"yes\" ]; then\n    # Log in to Docker Hub\n    # If you are a new docker hub user, please verify your email address before proceeding with this step.\n    docker login\n    # Tag the Docker image\n    docker tag qlib_image \"$docker_user/qlib_image:$image_tag\"\n    # Push the Docker image to Docker Hub\n    docker push \"$docker_user/qlib_image:$image_tag\"\nelse\n    echo \"Not uploaded to docker hub.\"\nfi\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.78515625,
          "content": "[build-system]\nrequires = [\"setuptools\", \"cython\", \"numpy>=1.24.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nclassifiers = [\n  \"Operating System :: POSIX :: Linux\",\n  \"Operating System :: Microsoft :: Windows\",\n  \"Operating System :: MacOS\",\n  \"License :: OSI Approved :: MIT License\",\n  \"Development Status :: 3 - Alpha\",\n  \"Programming Language :: Python\",\n  \"Programming Language :: Python :: 3\",\n  \"Programming Language :: Python :: 3.8\",\n  \"Programming Language :: Python :: 3.9\",\n  \"Programming Language :: Python :: 3.10\",\n  \"Programming Language :: Python :: 3.11\",\n  \"Programming Language :: Python :: 3.12\",\n]\nname = \"pyqlib\"\ndynamic = [\"version\"]\ndescription = \"A Quantitative-research Platform\"\nrequires-python = \">=3.8.0\"\nreadme = {file = \"README.md\", content-type = \"text/markdown\"}\n\ndependencies = [\n  \"pyyaml\",\n  \"numpy\",\n  \"pandas\",\n  \"mlflow\",\n  \"filelock>=3.16.0\",\n  \"redis\",\n  \"dill\",\n  \"fire\",\n  \"ruamel.yaml>=0.17.38\",\n  \"python-redis-lock\",\n  \"tqdm\",\n  \"pymongo\",\n  \"loguru\",\n  \"lightgbm\",\n  \"gym\",\n  \"cvxpy\",\n  \"joblib\",\n  \"matplotlib\",\n  \"jupyter\",\n  \"nbconvert\",\n]\n\n[project.optional-dependencies]\ndev = [\n  \"pytest\",\n  \"statsmodels\",\n]\n# On macos-13 system, when using python version greater than or equal to 3.10,\n# pytorch can't fully support Numpy version above 2.0, so, when you want to install torch,\n# it will limit the version of Numpy less than 2.0.\nrl = [\n  \"tianshou<=0.4.10\",\n  \"torch\",\n  \"numpy<2.0.0\",\n]\nlint = [\n  \"black\",\n  \"pylint\",\n  \"mypy<1.5.0\",\n  \"flake8\",\n  \"nbqa\",\n]\ndocs = [\n  \"sphinx\",\n  \"sphinx_rtd_theme\",\n  \"readthedocs_sphinx_ext\",\n]\npackage = [\n  \"twine\",\n  \"build\",\n]\n# test_pit dependency packages\ntest = [\n  \"yahooquery\",\n  \"baostock\",\n]\nanalysis = [\n  \"plotly\",\n]\n\n[tool.setuptools]\npackages = [\n  \"qlib\",\n]\n\n[project.scripts]\nqrun = \"qlib.workflow.cli:run\"\n"
        },
        {
          "name": "qlib",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.0048828125,
          "content": "from setuptools import setup, Extension\nimport numpy\nimport os\n\n\ndef read(rel_path: str) -> str:\n    here = os.path.abspath(os.path.dirname(__file__))\n    with open(os.path.join(here, rel_path), encoding=\"utf-8\") as fp:\n        return fp.read()\n\n\ndef get_version(rel_path: str) -> str:\n    for line in read(rel_path).splitlines():\n        if line.startswith(\"__version__\"):\n            delim = '\"' if '\"' in line else \"'\"\n            return line.split(delim)[1]\n    raise RuntimeError(\"Unable to find version string.\")\n\n\nNUMPY_INCLUDE = numpy.get_include()\n\nVERSION = get_version(\"qlib/__init__.py\")\n\n\nsetup(\n    version=VERSION,\n    ext_modules=[\n        Extension(\n            \"qlib.data._libs.rolling\",\n            [\"qlib/data/_libs/rolling.pyx\"],\n            language=\"c++\",\n            include_dirs=[NUMPY_INCLUDE],\n        ),\n        Extension(\n            \"qlib.data._libs.expanding\",\n            [\"qlib/data/_libs/expanding.pyx\"],\n            language=\"c++\",\n            include_dirs=[NUMPY_INCLUDE],\n        ),\n    ],\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}