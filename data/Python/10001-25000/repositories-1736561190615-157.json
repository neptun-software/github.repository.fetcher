{
  "metadata": {
    "timestamp": 1736561190615,
    "page": 157,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "TransformerOptimus/SuperAGI",
      "stars": 15701,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".do",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.25,
          "content": "# Ignore everything\n**\n\n# Allow files and directories\n!/migrations\n!/nginx\n!/superagi\n!/tgwui\n!/tools\n!/workspace\n!/main.py\n!/requirements.txt\n!/entrypoint.sh\n!/entrypoint_celery.sh\n!/wait-for-it.sh\n!/tools.json\n!/install_tool_dependencies.sh\n!/alembic.ini"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0166015625,
          "content": "*.sh text eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.388671875,
          "content": ".idea\n**/.env\n**/.venv\nconfig.yaml\n__pycache__\nsuperagi/models/__pycache__\nsuperagi/controllers/__pycache__\n**agent_dictvenv\n**/__gitpycache__/\ngui/node_modules\nnode_modules\ngui/.next\n.DS_Store\n.DS_Store?\nvenv\nworkspace/output\nworkspace/input\ncelerybeat-schedule\n../bfg-report*\nsuperagi/tools/marketplace_tools/\nsuperagi/tools/external_tools/\ntests/unit_tests/resource_manager/test_path\n/tools.json"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.1640625,
          "content": "repos:\n  -   repo: local\n      hooks:\n        -   id: pylint\n            name: pylint\n            entry: pylint\n            language: system\n            types: [python]"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.080078125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\n.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.23046875,
          "content": "#  ‚ö° Contributing to SuperAGI\n<p align=\"center\">\n  <a href=\"https://superagi.com//#gh-light-mode-only\">\n    <img src=\"https://superagi.com/wp-content/uploads/2023/05/Logo-dark.svg\" width=\"318px\" alt=\"SuperAGI logo\" />\n  </a>\n  <a href=\"https://superagi.com//#gh-dark-mode-only\">\n    <img src=\"https://superagi.com/wp-content/uploads/2023/05/Logo-light.svg\" width=\"318px\" alt=\"SuperAGI logo\" />\n  </a>\n</p>\n\nFirst of all, thank you for taking the time to contribute to this project. We truly appreciate your contributions, whether it's bug reports, feature suggestions, or pull requests. Your time and effort are highly valued in this project. üöÄ\n\nThis document provides guidelines and best practices to help you to contribute effectively. These are meant to serve as guidelines, not strict rules. We encourage you to use your best judgment and feel comfortable proposing changes to this document through a pull request.\n\nFor all contributions, a CLA (Contributor License Agreement) needs to be signed\n[here](https://cla-assistant.io/TransformerOptimus/SuperAGI) before (or after) the pull request has been submitted.\n\n**********************************Table of Content:********************************** \n1. [Code of conduct](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#code-of-conduct) \n2. [Quick Start](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#quick-start)\n3. [Contributing Guidelines](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#contributing-guidelines)\n    1. [Reporting Bugs](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#reporting-bugs)\n    2. [New Feature or Suggesting Enhancements](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#new-feature-or-suggesting-enhancements)\n4. [Testing](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#testing-changes)\n5. [Pull Requests](https://github.com/TransformerOptimus/SuperAGI/blob/CONTRIBUTING.md#pull-requests)\n\n## ‚úîÔ∏è Code of Conduct:\n\nPlease read our [Code of Conduct](https://github.com/TransformerOptimus/SuperAGI/blob/main/CODE_OF_CONDUCT.md) to understand the expectations we have for all contributors participating in this project. By participating, you agree to abide by our Code of Conduct.\n\n## üöÄ Quick Start\n\nYou can quickly get started with contributing by searching for issues with the labels **\"Good First Issue\"** or **\"Help Needed\"** in the [Issues Section](https://github.com/TransformerOptimus/SuperAGI/Issues). If you think you can contribute, comment on the issue and we will assign it to you.  \n\nTo set up your development environment, please follow the steps mentioned below : \n\n1. Fork the repository and create a clone of the fork\n2. Create a branch for a feature or a bug you are working on in your fork\n3. Once you've created your branch, follow the instructions in the [README.MD](https://github.com/TransformerOptimus/SuperAGI/README.MD)\n\n## Contributing Guidelines \n \n### üîç Reporting Bugs\n\nYou can start working on an existing bug that has been reported and labeled as **\"Bug\"** in the Issues Section, and you can report your bugs in the following manner :\n\n1. Title describing the issue clearly and concisely with relevant labels\n2. Provide a detailed description of the problem and the necessary steps to reproduce the issue.\n3. Include any relevant logs, screenshots, or other helpful information supporting the issue.\n\n### :bulb: New Feature or Suggesting Enhancements\n\nThis section guides you through working on an enhancement **Including a completely New Feature** & **Enhancements to an existing functionality**. \n\nBefore getting started, Perform a search on Issues to see if the enhancement or feature has already been suggested and picked up. If the feature or enhancement is suggested and not picked up, comment on the issue and assign yourself to it. \n\nIf the feature or enhancement is not in the issues, find out whether your idea fits with the scope and aims of the project by looking at the [Roadmap](https://github.com/users/TransformerOptimus/projects/5/). If yes, raise an issue with the label **\"Feature Request\"** in the following manner: \n\n1. Title describing the feature or enhancement in a clear and concise manner\n2. Clearly describe the proposed enhancement, highlighting its benefits and potential drawbacks.\n3. Provide examples and supporting information.\n\nOnce you have raised the issue and have gotten yourself assigned, you can start working on the feature or enhancement. Please make sure the feature or enhancement you're working on is placed on the Roadmap.\n\n## Testing your Changes\n\nEach method or the function of the code should have a unit test with the maximum coverage possible and on each Pull Request, we have GitHub Actions triggered, which\nruns all the unit tests where all the tests should pass for merging the Pull Request. \n\n## Pull Request\n\nNow that you have worked on your code and tested it thoroughly, you can now go ahead and raise the pull request. Please make sure that the Pull Request adheres to the following guidelines: \n\n1.  The pull request is atomic and focuses on a single change.\n2.  You have read the contributing guide and your code conforms to the guidelines.\n3.  You have documented your changes clearly and comprehensively.\n4.  You have added the required tests.\n\n\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.0458984375,
          "content": "# Stage 1: Compile image\nFROM python:3.10-slim-bullseye AS compile-image\nWORKDIR /app\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y wget libpq-dev gcc g++ && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN python -m venv /opt/venv\nENV PATH=\"/opt/venv/bin:$PATH\"\n\nCOPY requirements.txt .\nRUN pip install --upgrade pip && \\\n    pip install --no-cache-dir -r requirements.txt\n\nRUN python3.10 -c \"import nltk; nltk.download('punkt')\" && \\\n  python3.10 -c \"import nltk; nltk.download('averaged_perceptron_tagger')\"\n\nCOPY . .\n\nRUN chmod +x ./entrypoint.sh ./wait-for-it.sh ./install_tool_dependencies.sh ./entrypoint_celery.sh\n\n# Stage 2: Build image\nFROM python:3.10-slim-bullseye AS build-image\nWORKDIR /app\n\nRUN apt-get update && \\\n    apt-get install --no-install-recommends -y libpq-dev && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nCOPY --from=compile-image /opt/venv /opt/venv\nCOPY --from=compile-image /app /app\nCOPY --from=compile-image /root/nltk_data /root/nltk_data\n\nENV PATH=\"/opt/venv/bin:$PATH\"\n\nEXPOSE 8001"
        },
        {
          "name": "Dockerfile-gpu",
          "type": "blob",
          "size": 1.3984375,
          "content": "# Define the CUDA SDK version you need\nARG CUDA_IMAGE=\"12.1.1-devel-ubuntu22.04\"\nFROM nvidia/cuda:${CUDA_IMAGE}\n\nENV DEBIAN_FRONTEND=noninteractive\n\nWORKDIR /app\n\nRUN apt-get update && apt-get upgrade -y \\\n    && apt-get install -y git build-essential \\\n    python3 python3-pip python3.10-venv  libpq-dev gcc wget \\\n    ocl-icd-opencl-dev opencl-headers clinfo \\\n    libclblast-dev libopenblas-dev \\\n    && mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n\n# Create a virtual environment and activate it\nRUN python3 -m venv /opt/venv\nENV PATH=\"/opt/venv/bin:$PATH\"\n\n# Install Python dependencies from requirements.txt\nCOPY requirements.txt .\nRUN pip install --upgrade pip && \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Running nltk setup as you mentioned\nRUN python3.10 -c \"import nltk; nltk.download('punkt')\" && \\\n    python3.10 -c \"import nltk; nltk.download('averaged_perceptron_tagger')\"\n\n# Copy the application code\nCOPY . .\n\nENV CUDA_DOCKER_ARCH=all\nENV LLAMA_CUBLAS=1\n\nRUN CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.7 --force-reinstall --upgrade --no-cache-dir\n\n# Make necessary scripts executable\nRUN chmod +x ./entrypoint.sh ./wait-for-it.sh ./install_tool_dependencies.sh ./entrypoint_celery.sh\n\n# Set environment variable to point to the custom libllama.so\n# ENV LLAMA_CPP_LIB=/app/llama.cpp/libllama.so\n\nEXPOSE 8001\n\nCMD [\"./entrypoint.sh\"]"
        },
        {
          "name": "DockerfileCelery",
          "type": "blob",
          "size": 0.779296875,
          "content": "FROM python:3.9\n\nWORKDIR /app\n\n#RUN apt-get update && apt-get install --no-install-recommends -y git wget libpq-dev gcc python3-dev && pip install psycopg2\nRUN pip install --upgrade pip\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\n# Downloads the tools\nRUN python superagi/tool_manager.py\n\n# Set executable permissions for install_tool_dependencies.sh\nRUN chmod +x install_tool_dependencies.sh\n\n# Install dependencies\nRUN ./install_tool_dependencies.sh\n\n# Downloads the tools\nRUN python superagi/tool_manager.py\n\n# Set executable permissions for install_tool_dependencies.sh\nRUN chmod +x install_tool_dependencies.sh\n\n# Install dependencies\nRUN ./install_tool_dependencies.sh\n\n\nCMD [\"celery\", \"-A\", \"superagi.worker\", \"worker\", \"--beat\",\"--loglevel=info\"]\n"
        },
        {
          "name": "DockerfileRedis",
          "type": "blob",
          "size": 0.03515625,
          "content": "FROM redis/redis-stack-server:latest"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "MIT License\n\nCopyright (c) 2023 TransformerOptimus\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.MD",
          "type": "blob",
          "size": 22.3642578125,
          "content": "<p align=\"center\">\n  <a href=\"https://superagi.com//#gh-light-mode-only\">\n    <img src=\"https://superagi.com/wp-content/uploads/2023/05/Logo-dark.svg\" width=\"318px\" alt=\"SuperAGI logo\" />\n  </a>\n  <a href=\"https://superagi.com//#gh-dark-mode-only\">\n    <img src=\"https://superagi.com/wp-content/uploads/2023/05/Logo-light.svg\" width=\"318px\" alt=\"SuperAGI logo\" />\n  </a>\n\n</p>\n\n<p align=\"center\"><i>Open-source framework to build, manage and run useful Autonomous AI Agents</i></p>\n    \n\n<p align=\"center\">\n<a href=\"https://superagi.com\"> <img src=\"https://superagi.com/wp-content/uploads/2023/08/Website.svg\"></a>\n<a href=\"https://app.superagi.com\"> <img src=\"https://superagi.com/wp-content/uploads/2023/07/Cloud.svg\"></a>\n<a href=\"https://marketplace.superagi.com/\"> <img src=\"https://superagi.com/wp-content/uploads/2023/08/Marketplace.svg\"></a>\n<a href=\"https://superagi.com/docs/\"> <img src=\"https://superagi.com/wp-content/uploads/2023/08/Docs.svg\"></a>\n<a href=\"https://documenter.getpostman.com/view/28438662/2s9Xy6rqP5\"> <img src=\"https://superagi.com/wp-content/uploads/2023/08/APIs.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://github.com/TransformerOptimus/SuperAGI/fork\" target=\"blank\">\n<img src=\"https://img.shields.io/github/forks/TransformerOptimus/SuperAGI?style=for-the-badge\" alt=\"SuperAGI forks\"/>\n</a>\n\n<a href=\"https://github.com/TransformerOptimus/SuperAGI/stargazers\" target=\"blank\">\n<img src=\"https://img.shields.io/github/stars/TransformerOptimus/SuperAGI?style=for-the-badge\" alt=\"SuperAGI stars\"/>\n</a>\n<a href='https://github.com/TransformerOptimus/SuperAGI/releases'>\n<img src='https://img.shields.io/github/release/TransformerOptimus/SuperAGI?&label=Latest&style=for-the-badge'>\n</a>\n\n<a href=\"https://github.com/TransformerOptimus/SuperAGI/commits\" target=\"blank\">\n<img src=\"https://img.shields.io/github/commits-since/TransformerOptimus/SuperAGI/v0.0.11.svg?style=for-the-badge\" alt=\"SuperAGI Commits\"/>\n</a>\n</p>\n\n<p align=\"center\"><b>Follow SuperAGI </b></p>\n\n<p align=\"center\">\n<a href=\"https://twitter.com/_superAGI\" target=\"blank\">\n<img src=\"https://img.shields.io/twitter/follow/_superAGI?label=Follow: _superAGI&style=social\" alt=\"Follow _superAGI\"/>\n</a>\n<a href=\"https://www.reddit.com/r/Super_AGI\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/url?label=/r/Super_AGI&logo=reddit&style=social&url=https://github.com/TransformerOptimus/SuperAGI\"/></a>\n\n<a href=\"https://discord.gg/dXbRe5BHJC\" target=\"blank\">\n<img src=\"https://img.shields.io/discord/1107593006032355359?label=Join%20SuperAGI&logo=discord&style=social\" alt=\"Join SuperAGI Discord Community\"/>\n</a>\n<a href=\"https://www.youtube.com/@_superagi\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/url?label=Youtube&logo=youtube&style=social&url=https://github.com/TransformerOptimus/SuperAGI\"/></a>\n</p>\n\n<p align=\"center\"><b>Connect with the Creator </b></p>\n\n<p align=\"center\">\n<a href=\"https://twitter.com/ishaanbhola\" target=\"blank\">\n<img src=\"https://img.shields.io/twitter/follow/ishaanbhola?label=Follow: ishaanbhola&style=social\" alt=\"Follow ishaanbhola\"/>\n</a>\n</p>\n\n<p align=\"center\"><b>Share SuperAGI Repository</b></p>\n\n<p align=\"center\">\n\n<a href=\"https://twitter.com/intent/tweet?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.&url=https://github.com/TransformerOptimus/SuperAGI&hashtags=SuperAGI,AGI,Autonomics,future\" target=\"blank\">\n<img src=\"https://img.shields.io/twitter/follow/_superAGI?label=Share Repo on Twitter&style=social\" alt=\"Follow _superAGI\"/></a> \n<a href=\"https://t.me/share/url?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.&url=https://github.com/TransformerOptimus/SuperAGI\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/url?label=Telegram&logo=Telegram&style=social&url=https://github.com/TransformerOptimus/SuperAGI\" alt=\"Share on Telegram\"/></a>\n<a href=\"https://api.whatsapp.com/send?text=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let's%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.%20https://github.com/TransformerOptimus/SuperAGI\"><img src=\"https://img.shields.io/twitter/url?label=whatsapp&logo=whatsapp&style=social&url=https://github.com/TransformerOptimus/SuperAGI\" /></a> <a href=\"https://www.reddit.com/submit?url=https://github.com/TransformerOptimus/SuperAGI&title=Check%20this%20GitHub%20repository%20out.%20SuperAGI%20-%20Let's%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.\n\" target=\"blank\">\n<img src=\"https://img.shields.io/twitter/url?label=Reddit&logo=Reddit&style=social&url=https://github.com/TransformerOptimus/SuperAGI\" alt=\"Share on Reddit\"/>\n</a> <a href=\"mailto:?subject=Check%20this%20GitHub%20repository%20out.&body=SuperAGI%20-%20Let%27s%20you%20easily%20build,%20manage%20and%20run%20useful%20autonomous%20AI%20agents.%3A%0Ahttps://github.com/TransformerOptimus/SuperAGI\" target=\"_blank\"><img src=\"https://img.shields.io/twitter/url?label=Gmail&logo=Gmail&style=social&url=https://github.com/TransformerOptimus/SuperAGI\"/></a> <a href=\"https://www.buymeacoffee.com/superagi\" target=\"_blank\"><img src=\"https://cdn.buymeacoffee.com/buttons/default-orange.png\" alt=\"Buy Me A Coffee\" height=\"23\" width=\"100\" style=\"border-radius:1px\"></a>\n\n</p>\n\n<hr>\n\n## What are we ?\n\nA dev-first open source autonomous AI agent framework enabling developers to build, manage & run useful autonomous agents. You can run concurrent agents seamlessly, extend agent capabilities with tools. The agents efficiently perform a variety of tasks and continually improve their performance with each subsequent run.\n\n\n### üí° Features\n\n- <b>Provision, Spawn & Deploy Autonomous AI Agents</b> - Create production-ready & scalable autonomous agents.\n- <b>Extend Agent Capabilities with Toolkits</b> - Add Toolkits from our marketplace to your agent workflows.\n- <b>Graphical User Interface</b> - Access your agents through a graphical user interface.\n- <b>Action Console</b> - Interact with agents by giving them input and permissions.\n- <b>Multiple Vector DBs</b> - Connect to multiple Vector DBs to enhance your agent‚Äôs performance.\n- <b>Performance Telemetry</b> - Get insights into your agent‚Äôs performance and optimize accordingly.\n- <b>Optimized Token Usage</b> - Control token usage to manage costs effectively.\n- <b>Agent Memory Storage</b> - Enable your agents to learn and adapt by storing their memory.\n- <b>Models</b> - Custom fine tuned models for business specific usecases.\n- <b>Workflows</b> - Automate tasks with ease using ReAct LLM's predefined steps.\n\n### üõ† Toolkits\nToolkits allow SuperAGI Agents to interact with external systems and third-party plugins.\n\n<a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Twitter.png height=50px width=50px alt=\"Twitter\" valign=\"middle\" title=\"Twitter\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Coding.png height=50px width=50px alt=\"Coding Tool\" valign=\"middle\" title=\"Coding Tool\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Insta.png height=50px width=50px alt=\"Instagram\" valign=\"middle\" title=\"Instagram\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Knowledge_tool.png height=50px width=50px alt=\"Knowledge Search\" valign=\"middle\" title=\"Knowledge Search\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113612.png height=50px width=50px alt=\"Email\"  valign=\"middle\" title=\"Email\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113610.png height=50px width=50px alt=\"Jira\" valign=\"middle\" title=\"Jira\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113611.png height=50px width=50px alt=\"File Manager\" valign=\"middle\" title=\"File Manager\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113613.png height=50px width=50px alt=\"Google Search\" valign=\"middle\" title=\"Google Search\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113615.png height=50px width=50px alt=\"Dall-E\" valign=\"middle\" title=\"Dall-E\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113614.png height=50px width=50px alt=\"Github\" valign=\"middle\" title=\"Github\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113616.png height=50px width=50px alt=\"Web Interaction\" valign=\"middle\" title=\"Web Interaction\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/05/Group-113622.png height=50px width=50px alt=\"Duckduckgo\" valign=\"middle\" title=\"Duckduckgo\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Calendar_tool.png height=50px width=50px alt=\"Google Calendar\" valign=\"middle\" title=\"Google Calendar\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Search_tool.png height=50px width=50px alt=\"Google Calendar\" valign=\"middle\" title=\"Google Search\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Serp.png height=50px width=50px alt=\"Serp API\" valign=\"middle\" title=\"Serp API\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Searx.png height=50px width=50px alt=\"Searx\" valign=\"middle\" title=\"Searx \"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Web_scraper_logo.png height=50px width=50px alt=\"Web Scraper\" valign=\"middle\" title=\"Web Scraper\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Notion_logo.png height=50px width=50px alt=\"Notion\" valign=\"middle\" title=\"Notion\"></a> <a href=\"https://marketplace.superagi.com/\" target=\"_blank\"><img src=https://superagi.com/wp-content/uploads/2023/08/Apollo_logo.png height=50px width=50px alt=\"Apollo\" valign=\"middle\" title=\"Apollo\"></a>\n\n### ‚öôÔ∏è Installation\n\nYou can install superAGI using one of the following three approaches.\n\n#### ‚òÅÔ∏è SuperAGI cloud\n\nTo quickly start experimenting with agents without the hassle of setting up the system, try [Superagi Cloud](https://app.superagi.com/)\n\n1. Visit [Superagi Cloud](https://app.superagi.com/) and log in using your github account.\n\n2. In your account settings, go to \"Model Providers\" and add your API key.\n\nYou're all set! Start running your agents effortlessly.\n\n#### üñ•Ô∏è Local\n\n1. Open your terminal and clone the SuperAGI repository.\n```\ngit clone https://github.com/TransformerOptimus/SuperAGI.git \n```\n\n2. Navigate to the cloned repository directory using the command:\n```\ncd SuperAGI\n```\n3. Create a copy of config_template.yaml, and name it config.yaml.\n\n4. Ensure that Docker is installed on your system. You can download and install it from [here](https://docs.docker.com/get-docker/).\n\n5. Once you have Docker Desktop running, run the following command in the SuperAGI directory:\n\n   a. For regular usage:\n      ```\n      docker compose -f docker-compose.yaml up --build\n      ```\n\n   b. If you want to use SuperAGI with Local LLMs and have GPU, run the following command:\n      ```\n      docker compose -f docker-compose-gpu.yml up --build\n      ```\n\n\n6. Open your web browser and navigate to http://localhost:3000 to access SuperAGI.\n\n#### üåÄ Digital Ocean\n\n<p align=\"left\">\n<a href=\"https://cloud.digitalocean.com/apps/new?repo=https://github.com/TransformerOptimus/SuperAGI/tree/main\"> <img src=\"https://www.deploytodo.com/do-btn-blue.svg\"></a><br>Deploy SuperAGI to DigitalOcean with one click.\n</p>\n\n<a id=\"architecture\">\n\n### üåê Architecture\n</a>\n<details>\n<summary>SuperAGI Architecture</summary>\n\n![SuperAGI Architecture](https://superagi.com/wp-content/uploads/2023/09/SuperAGI-Architecture.png)\n</details>\n\n<details>\n<summary>Agent Architecture</summary>\n\n![Agent Architecture](https://superagi.com/wp-content/uploads/2023/06/Agent-Architecture.png)\n</details>\n\n<details>\n<summary>Agent Workflow Architecture</summary>\n\n![Agent Workflow Architecture](https://superagi.com/wp-content/uploads/2023/09/Workflow-Architecture.png)\n</details>\n\n<details>\n<summary>Tools Architecture</summary>\n\n![Tools Architecture](https://superagi.com/wp-content/uploads/2023/09/Tools-Architecture.png)\n</details>\n\n<details>\n<summary>ER Diagram</summary>\n\n![ER Diagram](https://superagi.com/wp-content/uploads/2023/09/ER-Diagram.png)\n</details>\n\n### üìö Resources\n\n* [Documentation](https://superagi.com/docs/)\n* [YouTube Channel](https://www.youtube.com/@_SuperAGI/videos)\n\n\n### üìñ Need Help?\n\nJoin our [Discord community](https://discord.gg/dXbRe5BHJC) for support and discussions.\n\n[![Join us on Discord](https://invidget.switchblade.xyz/uJ3XUGsY2R)](https://discord.gg/uJ3XUGsY2R)\n\nIf you have questions or encounter issues, please don't hesitate to [create a new issue](https://github.com/TransformerOptimus/SuperAGI/issues/new/choose) to get support.\n\n### üíª Contribution\nWe ‚ù§Ô∏è our contributors. We‚Äôre committed to fostering an open, welcoming, and safe environment in the community.\n\nIf you'd like to contribute, start by reading our [Contribution Guide](https://github.com/TransformerOptimus/SuperAGI/blob/main/CONTRIBUTING.md).\n\nWe expect everyone participating in the community to abide by our [Code of Conduct](https://github.com/TransformerOptimus/SuperAGI/blob/main/CODE_OF_CONDUCT.md).\n\nTo get more idea on where we are heading, checkout our roadmap [here](https://github.com/users/TransformerOptimus/projects/5/views/1).\n\nExplore some [good first issues](https://github.com/TransformerOptimus/SuperAGI/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) to start contributing.\n\n### üë©‚Äçüíª Contributors\n[![TransformerOptimus](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133493246?v=4&w=50&h=50&mask=circle)](https://github.com/TransformerOptimus) [![Cptsnowcrasher](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133322218?v=4&w=50&h=50&mask=circle)](https://github.com/Cptsnowcrasher) [![vectorcrow](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/133646556?v=4&w=50&h=50&mask=circle)](https://github.com/vectorcrow) [![Akki-jain](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/92881074?v=4&w=50&h=50&mask=circle)](https://github.com/Akki-jain) [![Autocop-Agent](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/129729746?v=4&w=50&h=50&mask=circle)](https://github.com/Autocop-Agent)[![COLONAYUSH](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/60507126?v=4&w=50&h=50&mask=circle)](https://github.com/COLONAYUSH)[![luciferlinx101](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/129729795?v=4&w=50&h=50&mask=circle)](https://github.com/luciferlinx101)[![mukundans89](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/101278493?v=4&w=50&h=50&mask=circle)](https://github.com/mukundans89)[![Fluder-Paradyne](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/121793617?v=4&w=50&h=50&mask=circle)](https://github.com/Fluder-Paradyne)[![nborthy](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/101320057?v=4&w=50&h=50&mask=circle)](https://github.com/nborthy)[![nihirr](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/122777244?v=4&w=50&h=50&mask=circle)](https://github.com/nihirr)[![Tarraann](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/97586318?v=4&w=50&h=50&mask=circle)](https://github.com/Tarraann)[![neelayan7](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/43145646?v=4&w=50&h=50&mask=circle)](https://github.com/neelayan7)[![Arkajit-Datta](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/61142632?v=4&w=50&h=50&mask=circle)](https://github.com/Arkajit-Datta)[![guangchen811](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/103159823?v=4&w=50&h=50&mask=circle)](https://github.com/guangchen811)[![juanfpo96](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/14787156?v=4&w=50&h=50&mask=circle)](https://github.com/juanfpo96)[![iskandarreza](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/32027019?v=4&w=50&h=50&mask=circle)](https://github.com/iskandarreza)[![jpenalbae](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/8380459?v=4&w=50&h=50&mask=circle)](https://github.com/jpenalbae)[![pallasite99](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/26508636?v=4&w=50&h=50&mask=circle)](https://github.com/pallasite99)[![xutpuu](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/11964505?v=4&w=50&h=50&mask=circle)](https://github.com/xutpuu)[![alexkreidler](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/11166947?v=4&w=50&h=50&mask=circle)](https://github.com/alexkreidler)[![hanhyalex123](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/100895608?v=4&w=50&h=50&mask=circle)](https://github.com/hanhyalex123)[![ps4vs](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/91535358?v=4&w=50&h=50&mask=circle)](https://github.com/ps4vs)[![eltociear](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/22633385?v=4&w=50&h=50&mask=circle)](https://github.com/eltociear)\n[![shaiss](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/113060?v=4&w=50&h=50&mask=circle)](https://github.com/shaiss)\n[![AdityaRajSingh1992](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/105219157?v=4&w=50&h=50&mask=circle)](https://github.com/AdityaRajSingh1992)\n[![namansleeps2](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/134390870?v=4&w=50&h=50&mask=circle)](https://github.com/namansleeps22)\n[![sirajperson](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/396941?v=4&w=50&h=50&mask=circle)](https://github.com/sirajperson)\n[![hsm207](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/2398765?v=4&w=50&h=50&mask=circle)](https://github.com/hsm207)\n[![unkn-wn](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/43097991?v=4&w=50&h=50&mask=circle)](https://github.com/unkn-wn)\n[![DMTarmey](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/590474?v=4&w=50&h=50&mask=circle)](https://github.com/DMTarmey)\n[![Parth2506](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/122429822?v=4&w=50&h=50&mask=circle)](https://github.com/Parth2506)\n[![platinaCoder](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/47349795?v=4&w=50&h=50&mask=circle)](https://github.com/platinaCoder)\n[![anisha1607](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/60440541?v=4&w=50&h=50&mask=circle)](https://github.com/anisha1607)\n[![jorgectf](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/46056498?v=4&w=50&h=50&mask=circle)](https://github.com/jorgectf)\n[![PaulRBerg](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/8782666?v=4&w=50&h=50&mask=circle)](https://github.com/PaulRBerg)\n[![boundless-asura](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/122777244?v=4&w=50&h=50&mask=circle)](https://github.com/boundless-asura)\n[![JPDucky](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/34105363?v=4&w=50&h=50&mask=circle)](https://github.com/JPDucky)\n[![Vibhusha22](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/128478691?v=4&w=50&h=50&mask=circle)](https://github.com/Vibhusha22)\n[![ai-akuma](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/7444521?v=4&w=50&h=50&mask=circle)](https://github.com/ai-akuma)\n[![rounak610](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/81288115?v=4&w=50&h=50&mask=circle)](https://github.com/rounak610)\n[![AdarshJha619](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/53672264?v=4&w=50&h=50&mask=circle)](https://github.com/AdarshJha619)\n[![ResoluteStoic](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/105219157?v=4&w=50&h=50&mask=circle)](https://github.com/ResoluteStoic)\n[![JohnHunt999](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/137149331?v=4&w=50&h=50&mask=circle)](https://github.com/JohnHunt999)\n[![Maverick-F35](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/138012351?v=4&w=50&h=50&mask=circle)](https://github.com/Maverick-F359)\n[![jorgectf](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/46056498?v=4&w=50&h=50&mask=circle)](https://github.com/jorgectf)\n[![AdityaSharma13064](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/138581531?v=4&w=50&h=50&mask=circle)](https://github.com/AdityaSharma13064)\n[![lalitlj](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/138583454?v=4&w=50&h=50&mask=circle)](https://github.com/lalitlj)\n[![andrew-kelly-neutralaiz](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/128111428?v=4&w=50&h=50&mask=circle)](https://github.com/andrew-kelly-neutralaiz)\n[![sayan1101](https://images.weserv.nl/?url=https://avatars.githubusercontent.com/u/139119661?v=4&w=50&h=50&mask=circle)](https://github.com/sayan1101)\n\n\n<p align=\"center\"><a href=\"https://github.com/TransformerOptimus/SuperAGI#\"><img src=\"https://superagi.com/wp-content/uploads/2023/05/backToTopButton.png\" alt=\"Back to top\" height=\"29\"/></a></p>\n\n### ‚ö†Ô∏è Under Development!\nThis project is under active development and may still have issues. We appreciate your understanding and patience. If you encounter any problems, please check the open issues first. If your issue is not listed, kindly create a new issue detailing the error or problem you experienced. Thank you for your support!\n"
        },
        {
          "name": "alembic.ini",
          "type": "blob",
          "size": 3.33203125,
          "content": "# A generic, single database configuration.\n\n[alembic]\n# path to migration scripts\nscript_location = migrations\n\n# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s\n# Uncomment the line below if you want the files to be prepended with date and time\n# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file\n# for all available tokens\n# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s\n\n# sys.path path, will be prepended to sys.path if present.\n# defaults to the current working directory.\nprepend_sys_path = .\n\n# timezone to use when rendering the date within the migration file\n# as well as the filename.\n# If specified, requires the python-dateutil library that can be\n# installed by adding `alembic[tz]` to the pip requirements\n# string value is passed to dateutil.tz.gettz()\n# leave blank for localtime\n# timezone =\n\n# max length of characters to apply to the\n# \"slug\" field\n# truncate_slug_length = 40\n\n# set to 'true' to run the environment during\n# the 'revision' command, regardless of autogenerate\n# revision_environment = false\n\n# set to 'true' to allow .pyc and .pyo files without\n# a source .py file to be detected as revisions in the\n# versions/ directory\n# sourceless = false\n\n# version location specification; This defaults\n# to migrations/versions.  When using multiple version\n# directories, initial revisions must be specified with --version-path.\n# The path separator used here should be the separator specified by \"version_path_separator\" below.\n# version_locations = %(here)s/bar:%(here)s/bat:migrations/versions\n\n# version path separator; As mentioned above, this is the character used to split\n# version_locations. The default within new alembic.ini files is \"os\", which uses os.pathsep.\n# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.\n# Valid values for version_path_separator are:\n#\n# version_path_separator = :\n# version_path_separator = ;\n# version_path_separator = space\nversion_path_separator = os  # Use os.pathsep. Default configuration used for new projects.\n\n# set to 'true' to search source files recursively\n# in each \"version_locations\" directory\n# new in Alembic version 1.10\n# recursive_version_locations = false\n\n# the output encoding used when revision files\n# are written from script.py.mako\n# output_encoding = utf-8\n\nsqlalchemy.url = postgresql://superagi:password@super__postgres:5432/super_agi_main\n\n[post_write_hooks]\n# post_write_hooks defines scripts or Python functions that are run\n# on newly generated revision scripts.  See the documentation for further\n# detail and examples\n\n# format using \"black\" - use the console_scripts runner, against the \"black\" entrypoint\n# hooks = black\n# black.type = console_scripts\n# black.entrypoint = black\n# black.options = -l 79 REVISION_SCRIPT_FILENAME\n\n# Logging configuration\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n"
        },
        {
          "name": "cli2.py",
          "type": "blob",
          "size": 2.748046875,
          "content": "import os\r\nimport sys\r\nimport subprocess\r\nfrom time import sleep\r\nimport shutil\r\nfrom sys import platform\r\nfrom multiprocessing import Process\r\nfrom superagi.lib.logger import logger\r\n\r\n\r\ndef check_command(command, message):\r\n    if not shutil.which(command):\r\n        logger.info(message)\r\n        sys.exit(1)\r\n\r\n\r\ndef run_npm_commands(shell=False):\r\n    os.chdir(\"gui\")\r\n    try:\r\n        subprocess.run([\"npm\", \"install\"], check=True, shell=shell)\r\n    except subprocess.CalledProcessError:\r\n        logger.error(f\"Error during '{' '.join(sys.exc_info()[1].cmd)}'. Exiting.\")\r\n        sys.exit(1)\r\n    os.chdir(\"..\")\r\n\r\n\r\ndef run_server(shell=False,a_name=None,a_description=None,goals=None):\r\n    tgwui_process = Process(target=subprocess.run, args=([\"python\", \"test.py\",\"--name\",a_name,\"--description\",a_description,\"--goals\"]+goals,), kwargs={\"shell\": shell})\r\n    api_process = Process(target=subprocess.run, args=([\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"],), kwargs={\"shell\": shell})\r\n    celery_process = Process(target=subprocess.run, args=([\"celery\", \"-A\", \"celery_app\", \"worker\", \"--loglevel=info\"],), kwargs={\"shell\": shell})\r\n    ui_process = Process(target=subprocess.run, args=([\"python\", \"test.py\",\"--name\",a_name,\"--description\",a_description,\"--goals\"]+goals,), kwargs={\"shell\": shell})\r\n    api_process.start()\r\n    celery_process.start()\r\n    ui_process.start()\r\n\r\n    return api_process, ui_process, celery_process\r\n\r\n\r\ndef cleanup(api_process, ui_process, celery_process):\r\n    logger.info(\"Shutting down processes...\")\r\n    api_process.terminate()\r\n    ui_process.terminate()\r\n    celery_process.terminate()\r\n    logger.info(\"Processes terminated. Exiting.\")\r\n    sys.exit(1)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    check_command(\"node\", \"Node.js is not installed. Please install it and try again.\")\r\n    check_command(\"npm\", \"npm is not installed. Please install npm to proceed.\")\r\n    check_command(\"uvicorn\", \"uvicorn is not installed. Please install uvicorn to proceed.\")\r\n\r\n    agent_name = input(\"Enter an agent name: \")\r\n    agent_description = input(\"Enter an agent description: \")\r\n    goals = []\r\n    while True:\r\n        goal = input(\"Enter a goal (or 'q' to quit): \")\r\n        if goal == 'q':\r\n            break\r\n        goals.append(goal)\r\n    isWindows = False\r\n    if platform == \"win32\" or platform == \"cygwin\":\r\n        isWindows = True\r\n    run_npm_commands(shell=isWindows)\r\n\r\n    try:\r\n        api_process, ui_process, celery_process = run_server(isWindows, agent_name, agent_description, goals)\r\n        while True:\r\n            try:\r\n                sleep(30)\r\n            except KeyboardInterrupt:\r\n                cleanup(api_process, ui_process, celery_process)\r\n    except Exception as e:\r\n        cleanup(api_process, ui_process, celery_process)"
        },
        {
          "name": "config_template.yaml",
          "type": "blob",
          "size": 4.6708984375,
          "content": "#####################------------------SYSTEM KEYS-------------------------########################\nPINECONE_API_KEY: YOUR_PINECONE_API_KEY\nPINECONE_ENVIRONMENT: YOUR_PINECONE_ENVIRONMENT\n\nOPENAI_API_KEY: YOUR_OPEN_API_KEY\nPALM_API_KEY: YOUR_PALM_API_KEY\nREPLICATE_API_TOKEN: YOUR_REPLICATE_API_TOKEN\nHUGGING_API_TOKEN: YOUR_HUGGING_FACE_API_TOKEN\n\n# For locally hosted LLMs comment out the next line and uncomment the one after\n# to configure a local llm point your browser to 127.0.0.1:7860 and click on the model tab in text generation web ui.\nOPENAI_API_BASE: https://api.openai.com/v1\n#OPENAI_API_BASE: \"http://super__tgwui:5001/v1\"\n\n# \"gpt-3.5-turbo-0301\": 4032, \"gpt-4-0314\": 8092, \"gpt-3.5-turbo\": 4032, \"gpt-4\": 8092, \"gpt-4-32k\": 32768, \"gpt-4-32k-0314\": 32768, \"llama\":2048, \"mpt-7b-storywriter\":45000\nMODEL_NAME: \"gpt-3.5-turbo-0301\"\n# \"gpt-3.5-turbo\", , \"gpt-4\", \"models/chat-bison-001\"\nRESOURCES_SUMMARY_MODEL_NAME: \"gpt-3.5-turbo\"\nMAX_TOOL_TOKEN_LIMIT: 800\nMAX_MODEL_TOKEN_LIMIT: 4032 # set to 2048 for llama\n\n#DATABASE INFO\n# redis details\nDB_NAME: super_agi_main\nDB_HOST: super__postgres\nDB_USERNAME: superagi\nDB_PASSWORD: password\nDB_URL: postgresql://superagi:password@super__postgres:5432/super_agi_main\nREDIS_URL: \"super__redis:6379\"\n\n#STORAGE TYPE (\"FILE\" or \"S3\")\nSTORAGE_TYPE: \"FILE\"\n\n#TOOLS\nTOOLS_DIR: \"superagi/tools\"\n\n#STORAGE INFO FOR FILES\nRESOURCES_INPUT_ROOT_DIR: workspace/input/{agent_id}\nRESOURCES_OUTPUT_ROOT_DIR: workspace/output/{agent_id}/{agent_execution_id} # For keeping resources at agent execution level\n#RESOURCES_OUTPUT_ROOT_DIR: workspace/output/{agent_id}  # For keeping resources at agent level\n\n#S3 RELATED DETAILS ONLY WHEN STORAGE_TYPE IS \"S3\"\nBUCKET_NAME:\nINSTAGRAM_TOOL_BUCKET_NAME:                                   #Public read bucket, Images generated by stable diffusion are put in this bucket and the public url of the same is generated.\nAWS_ACCESS_KEY_ID:\nAWS_SECRET_ACCESS_KEY:\n\n#AUTH\nENV: 'DEV' #DEV,PROD, to use GITHUB OAUTH set to PROD\nJWT_SECRET_KEY: 'secret'\nexpiry_time_hours: 1\n\n#GITHUB OAUTH:\nGITHUB_CLIENT_ID:\nGITHUB_CLIENT_SECRET:\nFRONTEND_URL: \"http://localhost:3000\"\n\n#ENCRYPTION KEY, Replace this with your own key for production\nENCRYPTION_KEY: abcdefghijklmnopqrstuvwxyz123456\n\n#WEAVIATE\n\n# If you are using docker or web hosted uncomment the next two lines and comment the third one\n# WEAVIATE_URL: YOUR_WEAVIATE_URL\n# WEAVIATE_API_KEY: YOUR_WEAVIATE_API_KEY\nWEAVIATE_USE_EMBEDDED: true\n\n\n#####################------------------TOOLS KEY-------------------------########################\n#If you have google api key and CSE key, use this\nGOOGLE_API_KEY: YOUR_GOOGLE_API_KEY\nSEARCH_ENGINE_ID: YOUR_SEARCH_ENIGNE_ID\n\n# IF YOU DONT HAVE GOOGLE SEARCH KEY, YOU CAN USE SERPER.DEV KEYS\nSERP_API_KEY: YOUR_SERPER_API_KEY\n\n#ENTER YOUR EMAIL CREDENTIALS TO ACCESS EMAIL TOOL\nEMAIL_ADDRESS: YOUR_EMAIL_ADDRESS\nEMAIL_PASSWORD: YOUR_EMAIL_APP_PASSWORD #get the app password from (https://myaccount.google.com/apppasswords)\nEMAIL_SMTP_HOST: smtp.gmail.com #Change the SMTP host if not using Gmail\nEMAIL_SMTP_PORT: 587 #Change the SMTP port if not using Gmail\nEMAIL_IMAP_SERVER: imap.gmail.com #Change the IMAP Host if not using Gmail\nEMAIL_SIGNATURE: Email sent by SuperAGI\nEMAIL_DRAFT_MODE_WITH_FOLDER: YOUR_DRAFTS_FOLDER\nEMAIL_ATTACHMENT_BASE_PATH: YOUR_DIRECTORY_FOR_EMAIL_ATTACHMENTS\n\n# GITHUB\nGITHUB_USERNAME: YOUR_GITHUB_USERNAME\nGITHUB_ACCESS_TOKEN: YOUR_GITHUB_ACCESS_TOKEN\n\n#JIRA\nJIRA_INSTANCE_URL: YOUR_JIRA_INSTANCE_URL\nJIRA_USERNAME: YOUR_JIRA_EMAIL\nJIRA_API_TOKEN: YOUR_JIRA_API_TOKEN\n\n#SLACK\nSLACK_BOT_TOKEN: YOUR_SLACK_BOT_TOKEN\n\n# For running stable diffusion\nSTABILITY_API_KEY: YOUR_STABILITY_API_KEY\n#Engine IDs that can be used: 'stable-diffusion-v1', 'stable-diffusion-v1-5','stable-diffusion-512-v2-0', 'stable-diffusion-768-v2-0','stable-diffusion-512-v2-1','stable-diffusion-768-v2-1','stable-diffusion-xl-beta-v2-2-2'\nENGINE_ID: \"stable-diffusion-xl-beta-v2-2-2\"\n\n## To config a vector store for resources manager uncomment config below\n## based on the vector store you want to use\n\n## RESOURCE_VECTOR_STORE can be REDIS, PINECONE, CHROMA, QDRANT\n#RESOURCE_VECTOR_STORE: YOUR_RESOURCE_VECTOR_STORE\n#RESOURCE_VECTOR_STORE_INDEX_NAME: YOUR_RESOURCE_VECTOR_STORE_INDEX_NAME\n\n## To use a custom redis\n#REDIS_VECTOR_STORE_URL: YOUR_REDIS_VECTOR_STORE_URL\n\n## To use qdrant for vector store in resources manager\n#QDRANT_PORT: YOUR_QDRANT_PORT\n#QDRANT_HOST_NAME: YOUR_QDRANT_HOST_NAME\n\n## To use chroma for vector store in resources manager\n#CHROMA_HOST_NAME: YOUR_CHROMA_HOST_NAME\n#CHROMA_PORT: YOUR_CHROMA_PORT\n\n## To use Qdrant for vector store\n#QDRANT_HOST_NAME: YOUR_QDRANT_HOST_NAME\n#QDRANT_PORT: YOUR_QDRANT_PORT\n#GPU_LAYERS: GPU LAYERS THAT YOU WANT TO OFFLOAD TO THE GPU WHILE USING LOCAL LLMS\n"
        },
        {
          "name": "docker-compose-dev.yaml",
          "type": "blob",
          "size": 1.599609375,
          "content": "version: '3.8'\nservices:\n  backend:\n    volumes:\n      - \"./:/app\"\n    build: .\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/wait-for-it.sh\", \"super__postgres:5432\",\"-t\",\"60\",\"--\",\"/app/entrypoint.sh\"]\n  celery:\n    volumes:\n      - \"./:/app\"\n      - \"${EXTERNAL_RESOURCE_DIR:-./workspace}:/app/ext\"\n    build: .\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/entrypoint_celery.sh\"]\n  gui:\n    build:\n      context: ./gui\n      args:\n        NEXT_PUBLIC_API_BASE_URL: \"/api\"\n    networks:\n      - super_network\n#    volumes:\n#      - ./gui:/app\n#      - /app/node_modules/\n#      - /app/.next/\n  super__redis:\n    image: \"redis/redis-stack-server:latest\"\n    networks:\n      - super_network\n#    uncomment to expose redis port to host\n#    ports:\n#      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n\n  super__postgres:\n    image: \"docker.io/library/postgres:latest\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n#    uncomment to expose postgres port to host\n#    ports:\n#      - \"5432:5432\"\n\n  proxy:\n    image: nginx:stable-alpine\n    ports:\n      - \"3000:80\"\n    networks:\n      - super_network\n    depends_on:\n      - backend\n      - gui\n    volumes:\n      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf\n\nnetworks:\n  super_network:\n    driver: bridge\nvolumes:\n  superagi_postgres_data:\n  redis_data:\n"
        },
        {
          "name": "docker-compose-gpu.yml",
          "type": "blob",
          "size": 2.0009765625,
          "content": "version: '3.8'\nservices:\n  backend:\n    volumes:\n      - \"./:/app\"\n    build:\n      context: .\n      dockerfile: Dockerfile-gpu \n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/wait-for-it.sh\", \"super__postgres:5432\",\"-t\",\"60\",\"--\",\"/app/entrypoint.sh\"]\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n\n  celery:\n    volumes:\n      - \"./:/app\"\n      - \"${EXTERNAL_RESOURCE_DIR:-./workspace}:/app/ext\"\n    build:\n      context: .\n      dockerfile: Dockerfile-gpu \n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/entrypoint_celery.sh\"]\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: all\n              capabilities: [gpu]\n  gui:\n    build:\n      context: ./gui\n      args:\n        NEXT_PUBLIC_API_BASE_URL: \"/api\"\n    networks:\n      - super_network\n#    volumes:\n#      - ./gui:/app\n#      - /app/node_modules/\n#      - /app/.next/\n  super__redis:\n    image: \"redis/redis-stack-server:latest\"\n    networks:\n      - super_network\n#    uncomment to expose redis port to host\n#    ports:\n#      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n\n  super__postgres:\n    image: \"docker.io/library/postgres:15\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n#    uncomment to expose postgres port to host\n#    ports:\n#      - \"5432:5432\"\n\n  proxy:\n    image: nginx:stable-alpine\n    ports:\n      - \"3000:80\"\n    networks:\n      - super_network\n    depends_on:\n      - backend\n      - gui\n    volumes:\n      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf\n\nnetworks:\n  super_network:\n    driver: bridge\nvolumes:\n  superagi_postgres_data:\n  redis_data:\n"
        },
        {
          "name": "docker-compose.image.example.yaml",
          "type": "blob",
          "size": 1.5888671875,
          "content": "version: '3.8'\nservices:\n  backend:\n    image: \"superagidev/superagi:main\"\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    env_file:\n      - config.yaml\n    command: [\"/app/wait-for-it.sh\", \"super__postgres:5432\",\"-t\",\"60\",\"--\",\"/app/entrypoint.sh\"]\n\n  celery:\n    image: \"superagidev/superagi:main\"\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    env_file:\n      - config.yaml\n    command: [\"/app/entrypoint_celery.sh\"]\n    volumes:\n      - \"./workspace:/app/workspace\"\n\n  gui:\n    image: \"superagidev/superagi-frontend:main\"\n    environment:\n      - NEXT_PUBLIC_API_BASE_URL=/api\n    networks:\n      - super_network\n\n  super__redis:\n    image: \"redis/redis-stack-server:latest\"\n    networks:\n      - super_network\n#    uncomment to expose redis port to host\n#    ports:\n#      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n\n  super__postgres:\n    image: \"docker.io/library/postgres:latest\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n#    uncomment to expose postgres port to host\n#    ports:\n#      - \"5432:5432\"\n\n  proxy:\n    image: nginx:stable-alpine\n    ports:\n      - \"3000:80\"\n    networks:\n      - super_network\n    depends_on:\n      - backend\n      - gui\n    volumes:\n      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf\n\nnetworks:\n  super_network:\n    driver: bridge\nvolumes:\n  superagi_postgres_data:\n  redis_data:\n"
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 1.5947265625,
          "content": "version: '3.8'\nservices:\n  backend:\n    volumes:\n      - \"./:/app\"\n    build: .\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/wait-for-it.sh\", \"super__postgres:5432\",\"-t\",\"60\",\"--\",\"/app/entrypoint.sh\"]\n  celery:\n    volumes:\n      - \"./:/app\"\n      - \"${EXTERNAL_RESOURCE_DIR:-./workspace}:/app/ext\"\n    build: .\n    depends_on:\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    command: [\"/app/entrypoint_celery.sh\"]\n  gui:\n    build:\n      context: ./gui\n      args:\n        NEXT_PUBLIC_API_BASE_URL: \"/api\"\n    networks:\n      - super_network\n#    volumes:\n#      - ./gui:/app\n#      - /app/node_modules/\n#      - /app/.next/\n  super__redis:\n    image: \"redis/redis-stack-server:latest\"\n    networks:\n      - super_network\n#    uncomment to expose redis port to host\n#    ports:\n#      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n\n  super__postgres:\n    image: \"docker.io/library/postgres:15\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n#    uncomment to expose postgres port to host\n#    ports:\n#      - \"5432:5432\"\n\n  proxy:\n    image: nginx:stable-alpine\n    ports:\n      - \"3000:80\"\n    networks:\n      - super_network\n    depends_on:\n      - backend\n      - gui\n    volumes:\n      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf\n\nnetworks:\n  super_network:\n    driver: bridge\nvolumes:\n  superagi_postgres_data:\n  redis_data:"
        },
        {
          "name": "entrypoint.sh",
          "type": "blob",
          "size": 0.28515625,
          "content": "#!/bin/bash\n\n# Downloads the tools from marketplace and external tool repositories\npython superagi/tool_manager.py\n\n# Install dependencies\n./install_tool_dependencies.sh\n\n# Run Alembic migrations\nalembic upgrade head\n\n# Start the app\nexec uvicorn main:app --host 0.0.0.0 --port 8001 --reload\n"
        },
        {
          "name": "entrypoint_celery.sh",
          "type": "blob",
          "size": 0.1787109375,
          "content": "#!/bin/bash\n\n# Downloads the tools\npython superagi/tool_manager.py\n\n# Install dependencies\n./install_tool_dependencies.sh\n\nexec celery -A superagi.worker worker --beat --loglevel=info"
        },
        {
          "name": "gui",
          "type": "tree",
          "content": null
        },
        {
          "name": "install_tool_dependencies.sh",
          "type": "blob",
          "size": 0.861328125,
          "content": "#!/bin/bash\n\n# Update and upgrade apt settings and apps\napt update && apt upgrade -y\nxargs apt install -y < /app/requirements_apt.txt\n\n# Run the project's main requirements.txt\npip install -r /app/requirements.txt\n\nfor tool in /app/superagi/tools/* /app/superagi/tools/external_tools/* /app/superagi/tools/marketplace_tools/* ; do\n# Loop through the tools directories and install their apt_requirements.txt if they exist\n  if [ -d \"$tool\" ] && [ -f \"$tool/requirements_apt.txt\" ]; then\n    echo \"Installing apt requirements for tool: $(basename \"$tool\")\"\n    xargs apt install -y < \"$tool/requirements_apt.txt\"\n  fi\n# Loop through the tools directories and install their requirements.txt if they exist\n  if [ -d \"$tool\" ] && [ -f \"$tool/requirements.txt\" ]; then\n    echo \"Installing requirements for tool: $(basename \"$tool\")\"\n    pip install -r \"$tool/requirements.txt\"\n  fi\ndone\n"
        },
        {
          "name": "local-llm",
          "type": "blob",
          "size": 2.0166015625,
          "content": "version: '3.8'\n\nservices:\n  backend:\n    volumes:\n      - \"./:/app\"\n    build: .\n    ports:\n      - \"8001:8001\"\n    depends_on:\n      - super__tgwui\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n\n  celery:\n    volumes:\n      - \"./:/app\"\n    build:\n      context: .\n      dockerfile: DockerfileCelery\n    depends_on:\n      - super__tgwui\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    \n  gui:\n    build: ./gui\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NEXT_PUBLIC_API_BASE_URL=http://localhost:8001\n    networks:\n      - super_network\n    volumes:\n      - ./gui:/app\n      - /app/node_modules\n      - /app/.next\n\n  super__tgwui:\n    build:\n      context: .\n      dockerfile: ./tgwui/DockerfileTGWUI\n    container_name: super__tgwui\n    environment:\n      - EXTRA_LAUNCH_ARGS=\"--listen --verbose --extensions openai --threads 4 --n_ctx 1600\"\n    ports:\n      - 7860:7860  # Default web port\n      - 5000:5000  # Default API port\n      - 5005:5005  # Default streaming port\n      - 5001:5001  # Default OpenAI API extension port\n    volumes:\n      - ./tgwui/config/loras:/app/loras\n      - ./tgwui/config/models:/app/models\n      - ./tgwui/config/presets:/app/presets\n      - ./tgwui/config/prompts:/app/prompts\n      - ./tgwui/config/softprompts:/app/softprompts\n      - ./tgwui/config/training:/app/training\n    logging:\n      driver:  json-file\n      options:\n        max-file: \"3\"   # number of files or file count\n        max-size: '10m'\n    networks:\n      - super_network\n\n  super__redis:\n    image: \"docker.io/library/redis:latest\"\n    networks:\n      - super_network\n\n  super__postgres:\n    image: \"docker.io/library/postgres:latest\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n    ports:\n      - \"5432:5432\"\n\nnetworks:\n  super_network:\n    driver: bridge\n\nvolumes:\n  superagi_postgres_data:\n"
        },
        {
          "name": "local-llm-gpu",
          "type": "blob",
          "size": 2.7333984375,
          "content": "version: '3.8'\n\nservices:\n  backend:\n    volumes:\n      - \"./:/app\"\n    build: .\n    ports:\n      - \"8001:8001\"\n    depends_on:\n      - super__tgwui\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n\n  celery:\n    volumes:\n      - \"./:/app\"\n    build:\n      context: .\n      dockerfile: DockerfileCelery\n    depends_on:\n      - super__tgwui\n      - super__redis\n      - super__postgres\n    networks:\n      - super_network\n    \n  gui:\n    build: ./gui\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NEXT_PUBLIC_API_BASE_URL=http://localhost:8001\n    networks:\n      - super_network\n    volumes:\n      - ./gui:/app\n      - /app/node_modules\n      - /app/.next\n\n  super__tgwui:\n    build:\n      context: ./tgwui/\n      target: llama-cublas\n      dockerfile: DockerfileTGWUI\n#      args:\n#        - LCL_SRC_DIR=text-generation-webui  # Developers - see Dockerfile app_base\n    image: atinoda/text-generation-webui:llama-cublas # Specify variant as the :tag\n    container_name: super__tgwui\n    environment:\n      - EXTRA_LAUNCH_ARGS=\"--no-mmap --verbose --extensions openai --auto-devices --n_ctx 2000 --gpu-memory 22 22 --n-gpu-layers 128 --threads 8\"\n#      - BUILD_EXTENSIONS_LIVE=\"silero_tts whisper_stt\" # Install named extensions during every container launch. THIS WILL SIGNIFICANLTLY SLOW LAUNCH TIME.\n    ports:\n      - 7860:7860  # Default web port\n      - 5000:5000  # Default API port\n      - 5005:5005  # Default streaming port\n      - 5001:5001  # Default OpenAI API extension port\n    volumes:\n      - ./tgwui/config/loras:/app/loras\n      - ./tgwui/config/models:/app/models\n      - ./tgwui/config/presets:/app/presets\n      - ./tgwui/config/prompts:/app/prompts\n      - ./tgwui/config/softprompts:/app/softprompts\n      - ./tgwui/config/training:/app/training\n#      - ./config/extensions:/app/extensions\n    logging:\n      driver:  json-file\n      options:\n        max-file: \"3\"   # number of files or file count\n        max-size: '10m'\n    networks:\n      - super_network\n    deploy:\n        resources:\n          reservations:\n            devices:\n              - driver: nvidia\n#                count: \"all\"\n                device_ids: ['0', '1'] # must comment the above line if this line is uncommented.\n                capabilities: [gpu]\n  super__redis:\n    image: \"docker.io/library/redis:latest\"\n    networks:\n      - super_network\n\n  super__postgres:\n    image: \"docker.io/library/postgres:latest\"\n    environment:\n      - POSTGRES_USER=superagi\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=super_agi_main\n    volumes:\n      - superagi_postgres_data:/var/lib/postgresql/data/\n    networks:\n      - super_network\n    ports:\n      - \"5432:5432\"\n\nnetworks:\n  super_network:\n    driver: bridge\n\nvolumes:\n  superagi_postgres_data:\n"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 16.966796875,
          "content": "import requests\nfrom fastapi import FastAPI, HTTPException, Depends, Request, status, Query\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import JSONResponse\nfrom fastapi.responses import RedirectResponse\nfrom fastapi_jwt_auth import AuthJWT\nfrom fastapi_jwt_auth.exceptions import AuthJWTException\nfrom fastapi_sqlalchemy import DBSessionMiddleware, db\nfrom pydantic import BaseModel\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nimport superagi\nfrom datetime import timedelta, datetime\nfrom superagi.agent.workflow_seed import IterationWorkflowSeed, AgentWorkflowSeed\nfrom superagi.config.config import get_config\nfrom superagi.controllers.agent import router as agent_router\nfrom superagi.controllers.agent_execution import router as agent_execution_router\nfrom superagi.controllers.agent_execution_feed import router as agent_execution_feed_router\nfrom superagi.controllers.agent_execution_permission import router as agent_execution_permission_router\nfrom superagi.controllers.agent_template import router as agent_template_router\nfrom superagi.controllers.agent_workflow import router as agent_workflow_router\nfrom superagi.controllers.budget import router as budget_router\nfrom superagi.controllers.config import router as config_router\nfrom superagi.controllers.organisation import router as organisation_router\nfrom superagi.controllers.project import router as project_router\nfrom superagi.controllers.twitter_oauth import router as twitter_oauth_router\nfrom superagi.controllers.google_oauth import router as google_oauth_router\nfrom superagi.controllers.resources import router as resources_router\nfrom superagi.controllers.tool import router as tool_router\nfrom superagi.controllers.tool_config import router as tool_config_router\nfrom superagi.controllers.toolkit import router as toolkit_router\nfrom superagi.controllers.user import router as user_router\nfrom superagi.controllers.agent_execution_config import router as agent_execution_config\nfrom superagi.controllers.analytics import router as analytics_router\nfrom superagi.controllers.models_controller import router as models_controller_router\nfrom superagi.controllers.knowledges import router as knowledges_router\nfrom superagi.controllers.knowledge_configs import router as knowledge_configs_router\nfrom superagi.controllers.vector_dbs import router as vector_dbs_router\nfrom superagi.controllers.vector_db_indices import router as vector_db_indices_router\nfrom superagi.controllers.marketplace_stats import router as marketplace_stats_router\nfrom superagi.controllers.api_key import router as api_key_router\nfrom superagi.controllers.api.agent import router as api_agent_router\nfrom superagi.controllers.webhook import router as web_hook_router\nfrom superagi.helper.tool_helper import register_toolkits, register_marketplace_toolkits\nfrom superagi.lib.logger import logger\nfrom superagi.llms.google_palm import GooglePalm\nfrom superagi.llms.llm_model_factory import build_model_with_api_key\nfrom superagi.llms.openai import OpenAi\nfrom superagi.llms.replicate import Replicate\nfrom superagi.llms.hugging_face import HuggingFace\nfrom superagi.models.agent_template import AgentTemplate\nfrom superagi.models.models_config import ModelsConfig\nfrom superagi.models.organisation import Organisation\nfrom superagi.models.types.login_request import LoginRequest\nfrom superagi.models.types.validate_llm_api_key_request import ValidateAPIKeyRequest\nfrom superagi.models.user import User\nfrom superagi.models.workflows.agent_workflow import AgentWorkflow\nfrom superagi.models.workflows.iteration_workflow import IterationWorkflow\nfrom superagi.models.workflows.iteration_workflow_step import IterationWorkflowStep\nfrom urllib.parse import urlparse\napp = FastAPI()\n\ndb_host = get_config('DB_HOST', 'super__postgres')\ndb_url = get_config('DB_URL', None)\ndb_username = get_config('DB_USERNAME')\ndb_password = get_config('DB_PASSWORD')\ndb_name = get_config('DB_NAME')\nenv = get_config('ENV', \"DEV\")\n\nif db_url is None:\n    if db_username is None:\n        db_url = f'postgresql://{db_host}/{db_name}'\n    else:\n        db_url = f'postgresql://{db_username}:{db_password}@{db_host}/{db_name}'\nelse:\n    db_url = urlparse(db_url)\n    db_url = db_url.scheme + \"://\" + db_url.netloc + db_url.path\n\nengine = create_engine(db_url,\n                       pool_size=20,  # Maximum number of database connections in the pool\n                       max_overflow=50,  # Maximum number of connections that can be created beyond the pool_size\n                       pool_timeout=30,  # Timeout value in seconds for acquiring a connection from the pool\n                       pool_recycle=1800,  # Recycle connections after this number of seconds (optional)\n                       pool_pre_ping=False,  # Enable connection health checks (optional)\n                       )\n\n# app.add_middleware(DBSessionMiddleware, db_url=f'postgresql://{db_username}:{db_password}@localhost/{db_name}')\napp.add_middleware(DBSessionMiddleware, db_url=db_url)\n\n# Configure CORS middleware\norigins = [\n    # Add more origins if needed\n    \"*\",  # Allow all origins\n]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Creating requrired tables -- Now handled using migrations\n# DBBaseModel.metadata.create_all(bind=engine, checkfirst=True)\n# DBBaseModel.metadata.drop_all(bind=engine,checkfirst=True)\n\n\napp.include_router(user_router, prefix=\"/users\")\napp.include_router(tool_router, prefix=\"/tools\")\napp.include_router(organisation_router, prefix=\"/organisations\")\napp.include_router(project_router, prefix=\"/projects\")\napp.include_router(budget_router, prefix=\"/budgets\")\napp.include_router(agent_router, prefix=\"/agents\")\napp.include_router(agent_execution_router, prefix=\"/agentexecutions\")\napp.include_router(agent_execution_feed_router, prefix=\"/agentexecutionfeeds\")\napp.include_router(agent_execution_permission_router, prefix=\"/agentexecutionpermissions\")\napp.include_router(resources_router, prefix=\"/resources\")\napp.include_router(config_router, prefix=\"/configs\")\napp.include_router(toolkit_router, prefix=\"/toolkits\")\napp.include_router(tool_config_router, prefix=\"/tool_configs\")\napp.include_router(config_router, prefix=\"/configs\")\napp.include_router(agent_template_router, prefix=\"/agent_templates\")\napp.include_router(agent_workflow_router, prefix=\"/agent_workflows\")\napp.include_router(twitter_oauth_router, prefix=\"/twitter\")\napp.include_router(agent_execution_config, prefix=\"/agent_executions_configs\")\napp.include_router(analytics_router, prefix=\"/analytics\")\napp.include_router(models_controller_router, prefix=\"/models_controller\")\napp.include_router(google_oauth_router, prefix=\"/google\")\napp.include_router(knowledges_router, prefix=\"/knowledges\")\napp.include_router(knowledge_configs_router, prefix=\"/knowledge_configs\")\napp.include_router(vector_dbs_router, prefix=\"/vector_dbs\")\napp.include_router(vector_db_indices_router, prefix=\"/vector_db_indices\")\napp.include_router(marketplace_stats_router, prefix=\"/marketplace\")\napp.include_router(api_key_router, prefix=\"/api-keys\")\napp.include_router(api_agent_router,prefix=\"/v1/agent\")\napp.include_router(web_hook_router,prefix=\"/webhook\")\n\n# in production you can use Settings management\n# from pydantic to get secret key from .env\nclass Settings(BaseModel):\n    # jwt_secret = get_config(\"JWT_SECRET_KEY\")\n    authjwt_secret_key: str = superagi.config.config.get_config(\"JWT_SECRET_KEY\")\n\n\ndef create_access_token(email, Authorize: AuthJWT = Depends()):\n    expiry_time_hours = superagi.config.config.get_config(\"JWT_EXPIRY\")\n    if type(expiry_time_hours) == str:\n        expiry_time_hours = int(expiry_time_hours)\n    if expiry_time_hours is None:\n        expiry_time_hours = 200\n    expires = timedelta(hours=expiry_time_hours)\n    access_token = Authorize.create_access_token(subject=email, expires_time=expires)\n    return access_token\n\n\n# callback to get your configuration\n@AuthJWT.load_config\ndef get_config():\n    return Settings()\n\n\n# exception handler for authjwt\n# in production, you can tweak performance using orjson response\n@app.exception_handler(AuthJWTException)\ndef authjwt_exception_handler(request: Request, exc: AuthJWTException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\"detail\": exc.message}\n    )\n\n\ndef replace_old_iteration_workflows(session):\n    templates = session.query(AgentTemplate).all()\n    for template in templates:\n        iter_workflow = IterationWorkflow.find_by_id(session, template.agent_workflow_id)\n        if not iter_workflow:\n            continue\n        if iter_workflow.name == \"Fixed Task Queue\":\n            agent_workflow = AgentWorkflow.find_by_name(session, \"Fixed Task Workflow\")\n            template.agent_workflow_id = agent_workflow.id\n            session.commit()\n\n        if iter_workflow.name == \"Maintain Task Queue\":\n            agent_workflow = AgentWorkflow.find_by_name(session, \"Dynamic Task Workflow\")\n            template.agent_workflow_id = agent_workflow.id\n            session.commit()\n\n        if iter_workflow.name == \"Don't Maintain Task Queue\" or iter_workflow.name == \"Goal Based Agent\":\n            agent_workflow = AgentWorkflow.find_by_name(session, \"Goal Based Workflow\")\n            template.agent_workflow_id = agent_workflow.id\n            session.commit()\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    # Perform startup tasks here\n    logger.info(\"Running Startup tasks\")\n    Session = sessionmaker(bind=engine)\n    session = Session()\n    default_user = session.query(User).filter(User.email == \"super6@agi.com\").first()\n    logger.info(default_user)\n    if default_user is not None:\n        organisation = session.query(Organisation).filter_by(id=default_user.organisation_id).first()\n        logger.info(organisation)\n        register_toolkits(session, organisation)\n\n    def register_toolkit_for_all_organisation():\n        organizations = session.query(Organisation).all()\n        for organization in organizations:\n            register_toolkits(session, organization)\n        logger.info(\"Successfully registered local toolkits for all Organisations!\")\n\n    def register_toolkit_for_master_organisation():\n        marketplace_organisation_id = superagi.config.config.get_config(\"MARKETPLACE_ORGANISATION_ID\")\n        marketplace_organisation = session.query(Organisation).filter(\n            Organisation.id == marketplace_organisation_id).first()\n        if marketplace_organisation is not None:\n            register_marketplace_toolkits(session, marketplace_organisation)\n\n    IterationWorkflowSeed.build_single_step_agent(session)\n    IterationWorkflowSeed.build_task_based_agents(session)\n    IterationWorkflowSeed.build_action_based_agents(session)\n    IterationWorkflowSeed.build_initialize_task_workflow(session)\n\n    AgentWorkflowSeed.build_goal_based_agent(session)\n    AgentWorkflowSeed.build_task_based_agent(session)\n    AgentWorkflowSeed.build_fixed_task_based_agent(session)\n    AgentWorkflowSeed.build_sales_workflow(session)\n    AgentWorkflowSeed.build_recruitment_workflow(session)\n    AgentWorkflowSeed.build_coding_workflow(session)\n\n    # NOTE: remove old workflows. Need to remove this changes later\n    workflows = [\"Sales Engagement Workflow\", \"Recruitment Workflow\", \"SuperCoder\", \"Goal Based Workflow\",\n     \"Dynamic Task Workflow\", \"Fixed Task Workflow\"]\n    workflows = session.query(AgentWorkflow).filter(AgentWorkflow.name.not_in(workflows))\n    for workflow in workflows:\n        session.delete(workflow)\n\n    # AgentWorkflowSeed.doc_search_and_code(session)\n    # AgentWorkflowSeed.build_research_email_workflow(session)\n    replace_old_iteration_workflows(session)\n\n    if env != \"PROD\":\n        register_toolkit_for_all_organisation()\n    else:\n        register_toolkit_for_master_organisation()\n    session.close()\n\n\n@app.post('/login')\ndef login(request: LoginRequest, Authorize: AuthJWT = Depends()):\n    \"\"\"Login API for email and password based login\"\"\"\n\n    email_to_find = request.email\n    user: User = db.session.query(User).filter(User.email == email_to_find).first()\n\n    if user == None or request.email != user.email or request.password != user.password:\n        raise HTTPException(status_code=401, detail=\"Bad username or password\")\n\n    # subject identifier for who this token is for example id or username from database\n    access_token = create_access_token(user.email, Authorize)\n    return {\"access_token\": access_token}\n\n\n# def get_jwt_from_payload(user_email: str,Authorize: AuthJWT = Depends()):\n#     access_token = Authorize.create_access_token(subject=user_email)\n#     return access_token\n\n@app.get('/github-login')\ndef github_login():\n    \"\"\"GitHub login\"\"\"\n\n    github_client_id = \"\"\n    return RedirectResponse(f'https://github.com/login/oauth/authorize?scope=user:email&client_id={github_client_id}')\n\n\n@app.get('/github-auth')\ndef github_auth_handler(code: str = Query(...), Authorize: AuthJWT = Depends()):\n    \"\"\"GitHub login callback\"\"\"\n\n    github_token_url = 'https://github.com/login/oauth/access_token'\n    github_client_id = superagi.config.config.get_config(\"GITHUB_CLIENT_ID\")\n    github_client_secret = superagi.config.config.get_config(\"GITHUB_CLIENT_SECRET\")\n\n    frontend_url = superagi.config.config.get_config(\"FRONTEND_URL\", \"http://localhost:3000\")\n    params = {\n        'client_id': github_client_id,\n        'client_secret': github_client_secret,\n        'code': code\n    }\n    headers = {\n        'Accept': 'application/json'\n    }\n    response = requests.post(github_token_url, params=params, headers=headers)\n    if response.ok:\n        data = response.json()\n        access_token = data.get('access_token')\n        github_api_url = 'https://api.github.com/user'\n        headers = {\n            'Authorization': f'Bearer {access_token}'\n        }\n        response = requests.get(github_api_url, headers=headers)\n        if response.ok:\n            user_data = response.json()\n            user_email = user_data[\"email\"]\n            if user_email is None:\n                user_email = user_data[\"login\"] + \"@github.com\"\n            db_user: User = db.session.query(User).filter(User.email == user_email).first()\n            if db_user is not None:\n                jwt_token = create_access_token(user_email, Authorize)\n                redirect_url_success = f\"{frontend_url}?access_token={jwt_token}&first_time_login={False}\"\n                return RedirectResponse(url=redirect_url_success)\n\n            user = User(name=user_data[\"name\"], email=user_email)\n            db.session.add(user)\n            db.session.commit()\n            jwt_token = create_access_token(user_email, Authorize)\n            redirect_url_success = f\"{frontend_url}?access_token={jwt_token}&first_time_login={True}\"\n            return RedirectResponse(url=redirect_url_success)\n        else:\n            redirect_url_failure = \"https://superagi.com/\"\n            return RedirectResponse(url=redirect_url_failure)\n    else:\n        redirect_url_failure = \"https://superagi.com/\"\n        return RedirectResponse(url=redirect_url_failure)\n\n\n@app.get('/user')\ndef user(Authorize: AuthJWT = Depends()):\n    \"\"\"API to get current logged in User\"\"\"\n\n    Authorize.jwt_required()\n    current_user = Authorize.get_jwt_subject()\n    return {\"user\": current_user}\n\n\n@app.get(\"/validate-access-token\")\nasync def root(Authorize: AuthJWT = Depends()):\n    \"\"\"API to validate access token\"\"\"\n\n    try:\n        Authorize.jwt_required()\n        current_user_email = Authorize.get_jwt_subject()\n        current_user = db.session.query(User).filter(User.email == current_user_email).first()\n        return current_user\n    except:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid token\")\n\n\n@app.post(\"/validate-llm-api-key\")\nasync def validate_llm_api_key(request: ValidateAPIKeyRequest, Authorize: AuthJWT = Depends()):\n    \"\"\"API to validate LLM API Key\"\"\"\n    source = request.model_source\n    api_key = request.model_api_key\n    model = build_model_with_api_key(source, api_key)\n    valid_api_key = model.verify_access_key() if model is not None else False\n    if valid_api_key:\n        return {\"message\": \"Valid API Key\", \"status\": \"success\"}\n    else:\n        return {\"message\": \"Invalid API Key\", \"status\": \"failed\"}\n\n\n@app.get(\"/validate-open-ai-key/{open_ai_key}\")\nasync def root(open_ai_key: str, Authorize: AuthJWT = Depends()):\n    \"\"\"API to validate Open AI Key\"\"\"\n\n    try:\n        llm = OpenAi(api_key=open_ai_key)\n        response = llm.chat_completion([{\"role\": \"system\", \"content\": \"Hey!\"}])\n    except:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid API Key\")\n\n\n# #Unprotected route\n@app.get(\"/hello/{name}\")\nasync def say_hello(name: str, Authorize: AuthJWT = Depends()):\n    Authorize.jwt_required()\n    return {\"message\": f\"Hello {name}\"}\n\n@app.get('/get/github_client_id')\ndef github_client_id():\n    \"\"\"Get GitHub Client ID\"\"\"\n\n    git_hub_client_id = superagi.config.config.get_config(\"GITHUB_CLIENT_ID\")\n    if git_hub_client_id:\n        git_hub_client_id = git_hub_client_id.strip()\n    return {\"github_client_id\": git_hub_client_id}\n\n# # __________________TO RUN____________________________\n# # uvicorn main:app --host 0.0.0.0 --port 8001 --reload\n\n"
        },
        {
          "name": "migrations",
          "type": "tree",
          "content": null
        },
        {
          "name": "nginx",
          "type": "tree",
          "content": null
        },
        {
          "name": "package.json",
          "type": "blob",
          "size": 0.080078125,
          "content": "{\n  \"dependencies\": {\n    \"axios\": \"^1.4.0\",\n    \"react-toastify\": \"^9.1.3\"\n  }\n}\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 2.8310546875,
          "content": "aiohttp==3.8.4\naiosignal==1.3.1\nalembic==1.11.1\namqp==5.1.1\nanyio==3.7.0\napiclient==1.0.4\nappdirs==1.4.4\nasync-timeout==4.0.2\nattrs==23.1.0\nbeautifulsoup4==4.12.2\nbilliard==3.6.4.0\nboto3==1.26.146\nbotocore==1.29.146\nbs4==0.0.1\ncelery==5.2.7\ncertifi==2023.5.7\ncffi==1.15.1\ncharset-normalizer==3.1.0\nclick==8.1.3\nclick-didyoumean==0.3.0\nclick-plugins==1.1.1\nclick-repl==0.2.0\ncolorama==0.4.6\nconfluent-kafka==2.1.1\ncryptography==41.0.1\ncssselect==1.2.0\nchromadb==0.3.26\ndataclasses-json==0.5.7\ndefusedxml==0.7.1\ndocx2txt==0.8\ndnspython==2.3.0\nemail-validator==2.0.0.post2\nexceptiongroup==1.1.1\nfake-useragent==1.1.3\nfastapi==0.95.2\nfastapi-jwt-auth==0.5.0\nFastAPI-SQLAlchemy==0.2.1\nfeedfinder2==0.0.4\nfeedparser==6.0.10\nfilelock==3.12.0\nfrozenlist==1.3.3\ngoogle-search-results==2.4.2\ngoogle-serp-api==1.0.3\ngoogle-api-core==2.11.0\ngoogle-api-python-client==2.88.0\ngoogle-auth==2.19.1\ngoogle-auth-httplib2==0.1.0\ngoogle-auth-oauthlib==1.0.0\ngreenlet==2.0.2\nh11==0.14.0\nhalo==0.0.31\nhttpcore==0.17.2\nhttptools==0.5.0\nhttpx==0.24.1\nidna==3.4\nimportlib-metadata==6.6.0\nimportlib-resources==5.12.0\nitsdangerous==2.1.2\njieba3k==0.35.1\nJinja2==3.1.2\njira==3.5.0\njmespath==1.0.1\njoblib==1.2.0\njson5==0.9.14\njsonmerge==1.9.0\njsonschema==4.17.3\nkombu==5.2.4\nllama-index==0.6.35\nlog-symbols==0.0.14\nloguru==0.7.0\nlxml==4.9.2\nMako==1.2.4\nMarkupSafe==2.1.2\nmarshmallow==3.19.0\nmarshmallow-enum==1.5.1\nmultidict==6.0.4\nmypy-extensions==1.0.0\nnewspaper3k==0.2.8\nnltk==3.8.1\nnumexpr==2.8.4\nnumpy==1.24.3\noauthlib==3.2.2\noauth2client==4.1.3\nopenai==0.27.7\nopenapi-schema-pydantic==1.2.4\norjson==3.8.14\npackaging==23.1\nparse==1.19.0\nPillow==9.5.0\npinecone-client==2.2.1\nprompt-toolkit==3.0.38\npsycopg2==2.9.6\npycparser==2.21\npydantic==1.10.8\nPyJWT==1.7.1\nPyPDF2==3.0.1\npyquery==2.0.0\npyrsistent==0.19.3\npytest==7.3.2\npython-dateutil==2.8.2\npython-dotenv==1.0.0\npython-multipart==0.0.6\npytz==2023.3\nPyYAML==6.0\nqdrant-client==1.3.1\nredis==4.5.5\nregex==2023.5.5\nreplicate==0.8.4\nrequests==2.31.0\nrequests-file==1.5.1\nrequests-html==0.10.0\nrequests-oauthlib==1.3.1\nrequests-toolbelt==1.0.0\ns3transfer==0.6.1\nsafetensors==0.3.2\nsgmllib3k==1.0.0\nsix==1.16.0\nsniffio==1.3.0\nsoupsieve==2.4.1\nspinners==0.0.24\nstarlette==0.27.0\nSQLAlchemy==2.0.16\ntenacity==8.2.2\ntermcolor==2.3.0\ntiktoken==0.4.0\ntinysegmenter==0.3\ntldextract==3.4.4\ntqdm==4.65.0\ntweepy==4.14.0\ntyping-inspect==0.8.0\nujson==5.7.0\nurllib3==1.26.16\nuvicorn==0.22.0\nvine==5.0.0\nw3lib==2.1.1\nwatchfiles==0.19.0\nwcwidth==0.2.6\nweaviate-client==3.20.1\nwebsockets==10.4\nyarl==1.9.2\nzipp==3.15.0\ntiktoken==0.4.0\npsycopg2==2.9.6\nslack-sdk==3.21.3\npytest==7.3.2\npylint==2.17.4\npre-commit==3.3.3\npytest-cov==4.1.0\npytest-mock==3.11.1\ntransformers==4.30.2\npypdf==3.11.0\npython-pptx==0.6.21\nPillow==9.5.0\nEbookLib==0.18\nhtml2text==2020.1.16\nduckduckgo-search==3.8.3 \ngoogle-generativeai==0.1.0\nunstructured==0.8.1\nai21==1.2.6\ntyping-extensions==4.5.0\nllama_cpp_python==0.2.7"
        },
        {
          "name": "run.bat",
          "type": "blob",
          "size": 0.90625,
          "content": "@echo off\necho Checking if config.yaml file exists...\nif not exist config.yaml (\n    echo ERROR: config.yaml file not found. Please create the config.yaml file.\n    exit /b 1\n)\necho Checking if virtual environment is activated...\nif not defined VIRTUAL_ENV (\n    echo Virtual environment not activated. Creating and activating virtual environment...\n    python3 -m venv venv\n    if errorlevel 1 (\n      echo Error: Failed to create virtual environment.\n      exit /b 1\n    )\n    call venv\\Scripts\\activate.bat\n) else (\n    echo Virtual environment is already activated.\n)\necho Checking requirements...\npip show -r requirements.txt >nul 2>&1\nif errorlevel 1 (\n    echo Installing requirements...\n    pip install -r requirements.txt >nul 2>&1\n) else (\n    echo All packages are already installed.\n)\necho Running test.py with python...\npython test.py\nif errorlevel 1 (\n    echo Running test.py with python3...\n    python3 test.py\n)"
        },
        {
          "name": "run.sh",
          "type": "blob",
          "size": 1.9599609375,
          "content": "#!/bin/bash\n\n# Check if config.yaml file exists\nif [ ! -f \"config.yaml\" ]; then\n    echo \"ERROR: config.yaml file not found. Please create the config.yaml file.\"\n    exit 1\nfi\n\nif [ ! -f \"tgwui/text-generation-webui\" ]; then\n    echo \"Downloading tgwui src\"\n    git clone https://github.com/oobabooga/text-generation-webui\n    mv text-generation-webui tgwui\nfi\n\n# Function to check if virtual environment is activated\nis_venv_activated() {\n    [[ -n \"$VIRTUAL_ENV\" ]]\n}\n\n# Check if virtual environment is activated\nif ! is_venv_activated; then\n    echo \"Virtual environment not activated. Creating and activating virtual environment...\"\n\n    # Create virtual environment\n    python3 -m venv venv\n\n    # Activate virtual environment based on the operating system\n    if [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n        source venv/bin/activate\n    else\n        source venv/bin/activate\n    fi\nelse\n    echo \"Virtual environment is already activated.\"\nfi\n\n# Activate virtual environment\nif ! is_venv_activated; then\n    echo \"Activating virtual environment...\"\n    source venv/bin/activate\nfi\n\n# Check if requirements are already installed\necho \"Checking requirements...\"\nif ! pip show -r requirements.txt >/dev/null 2>&1; then\n    echo \"Installing requirements...\"\n    pip install -r requirements.txt >/dev/null 2>&1\nelse\n    echo \"All packages are already installed.\"\nfi\n\n# Run test.py using python\n#echo \"Running test.py with python...\"\n#python test.py\n#\n## If the above command fails, run test.py using python3\n#if [ $? -ne 0 ]; then\n#    echo \"Running test.py with python3...\"\n#    python3 test.py\n#fi\n\n\nif [ \"$1\" = \"ui\" ]; then\n    echo \"Running UI...\"\n    python ui.py\n    if [ $? -ne 0 ]; then\n        echo \"Running UI with python3...\"\n        python3 ui.py\n    fi\nfi\nif [ \"$1\" = \"cli\" ]; then\n    echo \"Running superagi cli...\"\n    python cli2.py\n\n    # If the above command fails, run test.py using python3\n    if [ $? -ne 0 ]; then\n        echo \"Running superagi cli...\"\n        python3 cli2.py\n    fi\nfi"
        },
        {
          "name": "run_gui.py",
          "type": "blob",
          "size": 1.5166015625,
          "content": "import os\nimport sys\nimport subprocess\nfrom time import sleep\nimport shutil\nfrom superagi.lib.logger import logger\n\ndef check_command(command, message):\n    if not shutil.which(command):\n        logger.info(message)\n        sys.exit(1)\n\ndef run_npm_commands():\n    os.chdir(\"gui\")\n    try:\n        subprocess.run([\"npm\", \"install\"], check=True)\n    except subprocess.CalledProcessError:\n        logger.error(f\"Error during '{' '.join(sys.exc_info()[1].cmd)}'. Exiting.\")\n        sys.exit(1)\n    os.chdir(\"..\")\n\ndef run_server():\n    api_process = subprocess.Popen([\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"])\n    os.chdir(\"gui\")\n    ui_process = subprocess.Popen([\"npm\", \"run\", \"dev\"])\n    os.chdir(\"..\")\n    return api_process, ui_process\n\ndef cleanup(api_process, ui_process):\n    logger.info(\"Shutting down processes...\")\n    api_process.terminate()\n    ui_process.terminate()\n    logger.info(\"Processes terminated. Exiting.\")\n    sys.exit(1)\n\nif __name__ == \"__main__\":\n    check_command(\"node\", \"Node.js is not installed. Please install it and try again.\")\n    check_command(\"npm\", \"npm is not installed. Please install npm to proceed.\")\n    check_command(\"uvicorn\", \"uvicorn is not installed. Please install uvicorn to proceed.\")\n\n    run_npm_commands()\n\n    try:\n        api_process, ui_process = run_server()\n        while True:\n            try:\n                sleep(30)\n            except KeyboardInterrupt:\n                cleanup(api_process, ui_process)\n    except Exception as e:\n        cleanup(api_process, ui_process)"
        },
        {
          "name": "run_gui.sh",
          "type": "blob",
          "size": 0.86328125,
          "content": "#!/bin/bash\n\napi_process=\"\"\nui_process=\"\"\n\nfunction check_command() {\n  command -v \"$1\" >/dev/null 2>&1\n  if [ $? -ne 0 ]; then\n    echo \"$1 is not installed. Please install $1 to proceed.\"\n    exit 1\n  fi\n}\n\nfunction run_npm_commands() {\n  cd gui\n  npm install\n  if [ $? -ne 0 ]; then\n    echo \"Error during 'npm install'. Exiting.\"\n    exit 1\n  fi\n\n  npm run build\n  if [ $? -ne 0 ]; then\n    echo \"Error during 'npm run build'. Exiting.\"\n    exit 1\n  fi\n\n  cd ..\n}\n\nfunction run_server() {\n  uvicorn main:app --host 0.0.0.0 --port 8000 &\n  api_process=$!\n  cd gui && npm run dev &\n  ui_process=$!\n}\n\nfunction cleanup() {\n  echo \"Shutting down processes...\"\n  kill $api_process\n  kill $ui_process\n  echo \"Processes terminated. Exiting.\"\n  exit 1\n}\n\ntrap cleanup SIGINT\n\ncheck_command \"node\"\ncheck_command \"npm\"\ncheck_command \"uvicorn\"\n\nrun_npm_commands\nrun_server\n\nwait $api_process"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "superagi",
          "type": "tree",
          "content": null
        },
        {
          "name": "test.py",
          "type": "blob",
          "size": 3.876953125,
          "content": "import argparse\nfrom datetime import datetime\nfrom time import time\nfrom superagi.lib.logger import logger\n\nfrom sqlalchemy.orm import sessionmaker\n\nfrom superagi.worker import execute_agent\nfrom superagi.models.agent import Agent\nfrom superagi.models.agent_config import AgentConfiguration\nfrom superagi.models.agent_execution import AgentExecution\nfrom superagi.models.db import connect_db\nfrom superagi.models.organisation import Organisation\nfrom superagi.models.project import Project\n\nparser = argparse.ArgumentParser(description='Create a new agent.')\nparser.add_argument('--name', type=str, help='Agent name for the script.')\nparser.add_argument('--description', type=str, help='Agent description for the script.')\nparser.add_argument('--goals', type=str, nargs='+', help='Agent goals for the script.')\nargs = parser.parse_args()\n\nagent_name = args.name\nagent_description = args.description\nagent_goals = args.goals\n\nengine = connect_db()\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n\ndef ask_user_for_goals():\n    goals = []\n    while True:\n        goal = input(\"Enter a goal (or 'q' to quit): \")\n        if goal == 'q':\n            break\n        goals.append(goal)\n    return goals\n\n\ndef run_superagi_cli(agent_name=None, agent_description=None, agent_goals=None):\n    # Create default organization\n    organization = Organisation(name='Default Organization', description='Default organization description')\n    session.add(organization)\n    session.flush()  # Flush pending changes to generate the agent's ID\n    session.commit()\n    logger.info(organization)\n\n    # Create default project associated with the organization\n    project = Project(name='Default Project', description='Default project description',\n                      organisation_id=organization.id)\n    session.add(project)\n    session.flush()  # Flush pending changes to generate the agent's ID\n    session.commit()\n    logger.info(project)\n\n    # Agent\n    if agent_name is None:\n        agent_name = input(\"Enter agent name: \")\n    if agent_description is None:\n        agent_description = input(\"Enter agent description: \")\n    agent = Agent(name=agent_name, description=agent_description, project_id=project.id)\n    session.add(agent)\n    session.flush()\n    session.commit()\n    logger.info(agent)\n\n    # Agent Config\n    # Create Agent Configuration\n    agent_config_values = {\n        \"goal\": ask_user_for_goals() if agent_goals is None else agent_goals,\n        \"agent_type\": \"Type Non-Queue\",\n        \"constraints\": [\"~4000 word limit for short term memory. \",\n                        \"Your short term memory is short, so immediately save important information to files.\",\n                        \"If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\",\n                        \"No user assistance\",\n                        \"Exclusively use the commands listed in double quotes e.g. \\\"command name\\\"\"\n                        ],\n        \"tools\": [],\n        \"exit\": \"Default\",\n        \"iteration_interval\": 0,\n        \"model\": \"gpt-4\",\n        \"permission_type\": \"Default\",\n        \"LTM_DB\": \"Pinecone\",\n        \"memory_window\": 10\n    }\n\n    agent_configurations = [\n        AgentConfiguration(agent_id=agent.id, key=key, value=str(value))\n        for key, value in agent_config_values.items()\n    ]\n\n    session.add_all(agent_configurations)\n    session.commit()\n    logger.info(\"Agent Config : \")\n    logger.info(agent_configurations)\n\n    # Create agent execution in RUNNING state associated with the agent\n    execution = AgentExecution(status='RUNNING', agent_id=agent.id, last_execution_time=datetime.utcnow())\n    session.add(execution)\n    session.commit()\n\n    logger.info(\"Final Execution\")\n    logger.info(execution)\n\n    execute_agent.delay(execution.id, datetime.now())\n\n\nrun_superagi_cli(agent_name=agent_name, agent_description=agent_description, agent_goals=agent_goals)\n"
        },
        {
          "name": "test_main.http",
          "type": "blob",
          "size": 0.15234375,
          "content": "# Test your FastAPI endpoints\n\nGET http://127.0.0.1:8000/\nAccept: application/json\n\n###\n\nGET http://127.0.0.1:8000/hello/User\nAccept: application/json\n\n###\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tgwui",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools.json",
          "type": "blob",
          "size": 0.01953125,
          "content": "{\n  \"tools\": {\n  }\n}"
        },
        {
          "name": "ui.py",
          "type": "blob",
          "size": 2.0341796875,
          "content": "import os\r\nimport sys\r\nimport subprocess\r\nfrom time import sleep\r\nimport shutil\r\nfrom sys import platform\r\nfrom superagi.lib.logger import logger\r\n\r\ndef check_command(command, message):\r\n    if not shutil.which(command):\r\n        logger.info(message)\r\n        sys.exit(1)\r\n\r\n\r\ndef run_npm_commands(shell=False):\r\n    os.chdir(\"gui\")\r\n    try:\r\n        subprocess.run([\"npm\", \"install\"], check=True,shell=shell)\r\n    except subprocess.CalledProcessError:\r\n        logger.error(f\"Error during '{' '.join(sys.exc_info()[1].cmd)}'. Exiting.\")\r\n        sys.exit(1)\r\n    os.chdir(\"..\")\r\n\r\n\r\ndef run_server(shell=False):\r\n    api_process = subprocess.Popen([\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"], shell=shell)\r\n    # celery_process = None\r\n    celery_process = subprocess.Popen([\"celery\", \"-A\", \"superagi.worker\", \"worker\", \"--loglevel=info\"], shell=shell)\r\n    os.chdir(\"gui\")\r\n    ui_process = subprocess.Popen([\"npm\", \"run\", \"dev\"], shell=shell)\r\n    os.chdir(\"..\")\r\n    return api_process, ui_process , celery_process\r\n\r\n\r\ndef cleanup(api_process, ui_process, celery_process):\r\n    logger.info(\"Shutting down processes...\")\r\n    api_process.terminate()\r\n    ui_process.terminate()\r\n    celery_process.terminate()\r\n    logger.info(\"Processes terminated. Exiting.\")\r\n    sys.exit(1)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    check_command(\"node\", \"Node.js is not installed. Please install it and try again.\")\r\n    check_command(\"npm\", \"npm is not installed. Please install npm to proceed.\")\r\n    check_command(\"uvicorn\", \"uvicorn is not installed. Please install uvicorn to proceed.\")\r\n\r\n    isWindows = False\r\n    if platform == \"win32\" or platform == \"cygwin\":\r\n        isWindows = True\r\n    run_npm_commands(shell=isWindows)\r\n\r\n    try:\r\n        api_process, ui_process, celery_process = run_server(isWindows)\r\n        while True:\r\n            try:\r\n                sleep(30)\r\n            except KeyboardInterrupt:\r\n                cleanup(api_process, ui_process, celery_process)\r\n    except Exception as e:\r\n        cleanup(api_process, ui_process, celery_process)"
        },
        {
          "name": "wait-for-it.sh",
          "type": "blob",
          "size": 5.1044921875,
          "content": "#!/usr/bin/env bash\n# Use this script to test if a given TCP host/port are available\n\nWAITFORIT_cmdname=${0##*/}\n\nechoerr() { if [[ $WAITFORIT_QUIET -ne 1 ]]; then echo \"$@\" 1>&2; fi }\n\nusage()\n{\n    cat << USAGE >&2\nUsage:\n    $WAITFORIT_cmdname host:port [-s] [-t timeout] [-- command args]\n    -h HOST | --host=HOST       Host or IP under test\n    -p PORT | --port=PORT       TCP port under test\n                                Alternatively, you specify the host and port as host:port\n    -s | --strict               Only execute subcommand if the test succeeds\n    -q | --quiet                Don't output any status messages\n    -t TIMEOUT | --timeout=TIMEOUT\n                                Timeout in seconds, zero for no timeout\n    -- COMMAND ARGS             Execute command with args after the test finishes\nUSAGE\n    exit 1\n}\n\nwait_for()\n{\n    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then\n        echoerr \"$WAITFORIT_cmdname: waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT\"\n    else\n        echoerr \"$WAITFORIT_cmdname: waiting for $WAITFORIT_HOST:$WAITFORIT_PORT without a timeout\"\n    fi\n    WAITFORIT_start_ts=$(date +%s)\n    while :\n    do\n        if [[ $WAITFORIT_ISBUSY -eq 1 ]]; then\n            nc -z $WAITFORIT_HOST $WAITFORIT_PORT\n            WAITFORIT_result=$?\n        else\n            (echo -n > /dev/tcp/$WAITFORIT_HOST/$WAITFORIT_PORT) >/dev/null 2>&1\n            WAITFORIT_result=$?\n        fi\n        if [[ $WAITFORIT_result -eq 0 ]]; then\n            WAITFORIT_end_ts=$(date +%s)\n            echoerr \"$WAITFORIT_cmdname: $WAITFORIT_HOST:$WAITFORIT_PORT is available after $((WAITFORIT_end_ts - WAITFORIT_start_ts)) seconds\"\n            break\n        fi\n        sleep 1\n    done\n    return $WAITFORIT_result\n}\n\nwait_for_wrapper()\n{\n    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692\n    if [[ $WAITFORIT_QUIET -eq 1 ]]; then\n        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --quiet --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &\n    else\n        timeout $WAITFORIT_BUSYTIMEFLAG $WAITFORIT_TIMEOUT $0 --child --host=$WAITFORIT_HOST --port=$WAITFORIT_PORT --timeout=$WAITFORIT_TIMEOUT &\n    fi\n    WAITFORIT_PID=$!\n    trap \"kill -INT -$WAITFORIT_PID\" INT\n    wait $WAITFORIT_PID\n    WAITFORIT_RESULT=$?\n    if [[ $WAITFORIT_RESULT -ne 0 ]]; then\n        echoerr \"$WAITFORIT_cmdname: timeout occurred after waiting $WAITFORIT_TIMEOUT seconds for $WAITFORIT_HOST:$WAITFORIT_PORT\"\n    fi\n    return $WAITFORIT_RESULT\n}\n\n# process arguments\nwhile [[ $# -gt 0 ]]\ndo\n    case \"$1\" in\n        *:* )\n        WAITFORIT_hostport=(${1//:/ })\n        WAITFORIT_HOST=${WAITFORIT_hostport[0]}\n        WAITFORIT_PORT=${WAITFORIT_hostport[1]}\n        shift 1\n        ;;\n        --child)\n        WAITFORIT_CHILD=1\n        shift 1\n        ;;\n        -q | --quiet)\n        WAITFORIT_QUIET=1\n        shift 1\n        ;;\n        -s | --strict)\n        WAITFORIT_STRICT=1\n        shift 1\n        ;;\n        -h)\n        WAITFORIT_HOST=\"$2\"\n        if [[ $WAITFORIT_HOST == \"\" ]]; then break; fi\n        shift 2\n        ;;\n        --host=*)\n        WAITFORIT_HOST=\"${1#*=}\"\n        shift 1\n        ;;\n        -p)\n        WAITFORIT_PORT=\"$2\"\n        if [[ $WAITFORIT_PORT == \"\" ]]; then break; fi\n        shift 2\n        ;;\n        --port=*)\n        WAITFORIT_PORT=\"${1#*=}\"\n        shift 1\n        ;;\n        -t)\n        WAITFORIT_TIMEOUT=\"$2\"\n        if [[ $WAITFORIT_TIMEOUT == \"\" ]]; then break; fi\n        shift 2\n        ;;\n        --timeout=*)\n        WAITFORIT_TIMEOUT=\"${1#*=}\"\n        shift 1\n        ;;\n        --)\n        shift\n        WAITFORIT_CLI=(\"$@\")\n        break\n        ;;\n        --help)\n        usage\n        ;;\n        *)\n        echoerr \"Unknown argument: $1\"\n        usage\n        ;;\n    esac\ndone\n\nif [[ \"$WAITFORIT_HOST\" == \"\" || \"$WAITFORIT_PORT\" == \"\" ]]; then\n    echoerr \"Error: you need to provide a host and port to test.\"\n    usage\nfi\n\nWAITFORIT_TIMEOUT=${WAITFORIT_TIMEOUT:-15}\nWAITFORIT_STRICT=${WAITFORIT_STRICT:-0}\nWAITFORIT_CHILD=${WAITFORIT_CHILD:-0}\nWAITFORIT_QUIET=${WAITFORIT_QUIET:-0}\n\n# Check to see if timeout is from busybox?\nWAITFORIT_TIMEOUT_PATH=$(type -p timeout)\nWAITFORIT_TIMEOUT_PATH=$(realpath $WAITFORIT_TIMEOUT_PATH 2>/dev/null || readlink -f $WAITFORIT_TIMEOUT_PATH)\n\nWAITFORIT_BUSYTIMEFLAG=\"\"\nif [[ $WAITFORIT_TIMEOUT_PATH =~ \"busybox\" ]]; then\n    WAITFORIT_ISBUSY=1\n    # Check if busybox timeout uses -t flag\n    # (recent Alpine versions don't support -t anymore)\n    if timeout &>/dev/stdout | grep -q -e '-t '; then\n        WAITFORIT_BUSYTIMEFLAG=\"-t\"\n    fi\nelse\n    WAITFORIT_ISBUSY=0\nfi\n\nif [[ $WAITFORIT_CHILD -gt 0 ]]; then\n    wait_for\n    WAITFORIT_RESULT=$?\n    exit $WAITFORIT_RESULT\nelse\n    if [[ $WAITFORIT_TIMEOUT -gt 0 ]]; then\n        wait_for_wrapper\n        WAITFORIT_RESULT=$?\n    else\n        wait_for\n        WAITFORIT_RESULT=$?\n    fi\nfi\n\nif [[ $WAITFORIT_CLI != \"\" ]]; then\n    if [[ $WAITFORIT_RESULT -ne 0 && $WAITFORIT_STRICT -eq 1 ]]; then\n        echoerr \"$WAITFORIT_cmdname: strict mode, refusing to execute subprocess\"\n        exit $WAITFORIT_RESULT\n    fi\n    exec \"${WAITFORIT_CLI[@]}\"\nelse\n    exit $WAITFORIT_RESULT\nfi\n"
        },
        {
          "name": "workspace",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}