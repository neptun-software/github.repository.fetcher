{
  "metadata": {
    "timestamp": 1736561085280,
    "page": 13,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "AtsushiSakai/PythonRobotics",
      "stars": 23967,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.830078125,
          "content": "*.csv\n*.gif\n*.g2o\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n_build/\n.idea/\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n.DS_Store\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n#Ipython Notebook\n.ipynb_checkpoints\n\nmatplotrecorder/*\n.vscode/settings.json\n"
        },
        {
          "name": "AerialNavigation",
          "type": "tree",
          "content": null
        },
        {
          "name": "ArmNavigation",
          "type": "tree",
          "content": null
        },
        {
          "name": "Bipedal",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2705078125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at asakaig@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.7685546875,
          "content": "# Contributing to Python\n\n:+1::tada: First of off, thanks very much for taking the time to contribute! :tada::+1:\n\nThe following is a set of guidelines for contributing to PythonRobotics. \n\nThese are mostly guidelines, not rules. \n\nUse your best judgment, and feel free to propose changes to this document in a pull request.\n\n# Before contributing\n\n## Taking a look at the paper.\n\nPlease check this paper to understand the philosophy of this project.\n\n- [\\[1808\\.10703\\] PythonRobotics: a Python code collection of robotics algorithms](https://arxiv.org/abs/1808.10703) ([BibTeX](https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib))\n\n## Check your Python version.\n\nWe only accept a PR for Python 3.8.x or higher.\n\nWe will not accept a PR for Python 2.x.\n"
        },
        {
          "name": "Control",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.1435546875,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2016 - 2022 Atsushi Sakai and other contributors:\nhttps://github.com/AtsushiSakai/PythonRobotics/contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Localization",
          "type": "tree",
          "content": null
        },
        {
          "name": "Mapping",
          "type": "tree",
          "content": null
        },
        {
          "name": "PathPlanning",
          "type": "tree",
          "content": null
        },
        {
          "name": "PathTracking",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.685546875,
          "content": "<img src=\"https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true\" align=\"right\" width=\"300\" alt=\"header pic\"/>\n\n# PythonRobotics\n![GitHub_Action_Linux_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg)\n![GitHub_Action_MacOS_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg)\n![GitHub_Action_Windows_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg)\n[![Build status](https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true)](https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics)\n[![codecov](https://codecov.io/gh/AtsushiSakai/PythonRobotics/branch/master/graph/badge.svg)](https://codecov.io/gh/AtsushiSakai/PythonRobotics)\n\nPython codes for robotics algorithm.\n\n\n# Table of Contents\n   * [What is this?](#what-is-this)\n   * [Requirements](#requirements)\n   * [Documentation](#documentation)\n   * [How to use](#how-to-use)\n   * [Localization](#localization)\n      * [Extended Kalman Filter localization](#extended-kalman-filter-localization)\n      * [Particle filter localization](#particle-filter-localization)\n      * [Histogram filter localization](#histogram-filter-localization)\n   * [Mapping](#mapping)\n      * [Gaussian grid map](#gaussian-grid-map)\n      * [Ray casting grid map](#ray-casting-grid-map)\n      * [Lidar to grid map](#lidar-to-grid-map)\n      * [k-means object clustering](#k-means-object-clustering)\n      * [Rectangle fitting](#rectangle-fitting)\n   * [SLAM](#slam)\n      * [Iterative Closest Point (ICP) Matching](#iterative-closest-point-icp-matching)\n      * [FastSLAM 1.0](#fastslam-10)\n   * [Path Planning](#path-planning)\n      * [Dynamic Window Approach](#dynamic-window-approach)\n      * [Grid based search](#grid-based-search)\n         * [Dijkstra algorithm](#dijkstra-algorithm)\n         * [A* algorithm](#a-algorithm)\n         * [D* algorithm](#d-algorithm)\n         * [D* Lite algorithm](#d-lite-algorithm)\n         * [Potential Field algorithm](#potential-field-algorithm)\n         * [Grid based coverage path planning](#grid-based-coverage-path-planning)\n      * [State Lattice Planning](#state-lattice-planning)\n         * [Biased polar sampling](#biased-polar-sampling)\n         * [Lane sampling](#lane-sampling)\n      * [Probabilistic Road-Map (PRM) planning](#probabilistic-road-map-prm-planning)\n      * [Rapidly-Exploring Random Trees (RRT)](#rapidly-exploring-random-trees-rrt)\n         * [RRT*](#rrt)\n         * [RRT* with reeds-shepp path](#rrt-with-reeds-shepp-path)\n         * [LQR-RRT*](#lqr-rrt)\n      * [Quintic polynomials planning](#quintic-polynomials-planning)\n      * [Reeds Shepp planning](#reeds-shepp-planning)\n      * [LQR based path planning](#lqr-based-path-planning)\n      * [Optimal Trajectory in a Frenet Frame](#optimal-trajectory-in-a-frenet-frame)\n   * [Path Tracking](#path-tracking)\n      * [move to a pose control](#move-to-a-pose-control)\n      * [Stanley control](#stanley-control)\n      * [Rear wheel feedback control](#rear-wheel-feedback-control)\n      * [Linear–quadratic regulator (LQR) speed and steering control](#linearquadratic-regulator-lqr-speed-and-steering-control)\n      * [Model predictive speed and steering control](#model-predictive-speed-and-steering-control)\n      * [Nonlinear Model predictive control with C-GMRES](#nonlinear-model-predictive-control-with-c-gmres)\n   * [Arm Navigation](#arm-navigation)\n      * [N joint arm to point control](#n-joint-arm-to-point-control)\n      * [Arm navigation with obstacle avoidance](#arm-navigation-with-obstacle-avoidance)\n   * [Aerial Navigation](#aerial-navigation)\n      * [drone 3d trajectory following](#drone-3d-trajectory-following)\n      * [rocket powered landing](#rocket-powered-landing)\n   * [Bipedal](#bipedal)\n      * [bipedal planner with inverted pendulum](#bipedal-planner-with-inverted-pendulum)\n   * [License](#license)\n   * [Use-case](#use-case)\n   * [Contribution](#contribution)\n   * [Citing](#citing)\n   * [Support](#support)\n   * [Sponsors](#sponsors)\n      * [JetBrains](#JetBrains)\n      * [1Password](#1password)\n   * [Authors](#authors)\n\n# What is this?\n\nThis is a Python code collection of robotics algorithms.\n\nFeatures:\n\n1. Easy to read for understanding each algorithm's basic idea.\n\n2. Widely used and practical algorithms are selected.\n\n3. Minimum dependency.\n\nSee this paper for more details:\n\n- [\\[1808\\.10703\\] PythonRobotics: a Python code collection of robotics algorithms](https://arxiv.org/abs/1808.10703) ([BibTeX](https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib))\n\n\n# Requirements\n\nFor running each sample code:\n\n- [Python 3.12.x](https://www.python.org/)\n \n- [NumPy](https://numpy.org/)\n \n- [SciPy](https://scipy.org/)\n \n- [Matplotlib](https://matplotlib.org/)\n \n- [cvxpy](https://www.cvxpy.org/) \n\nFor development:\n  \n- [pytest](https://pytest.org/) (for unit tests)\n  \n- [pytest-xdist](https://pypi.org/project/pytest-xdist/) (for parallel unit tests)\n  \n- [mypy](http://mypy-lang.org/) (for type check)\n  \n- [sphinx](https://www.sphinx-doc.org/) (for document generation)\n  \n- [pycodestyle](https://pypi.org/project/pycodestyle/) (for code style check)\n\n# Documentation\n\nThis README only shows some examples of this project. \n\nIf you are interested in other examples or mathematical backgrounds of each algorithm, \n\nYou can check the full documentation online: [Welcome to PythonRobotics’s documentation\\! — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/index.html)\n\nAll animation gifs are stored here: [AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs)\n\n# How to use\n\n1. Clone this repo.\n\n   ```terminal\n   git clone https://github.com/AtsushiSakai/PythonRobotics.git\n   ```\n\n\n2. Install the required libraries.\n\n- using conda :\n\n  ```terminal\n  conda env create -f requirements/environment.yml\n  ```\n \n- using pip :\n\n  ```terminal\n  pip install -r requirements/requirements.txt\n  ```\n\n\n3. Execute python script in each directory.\n\n4. Add star to this repo if you like it :smiley:. \n\n# Localization\n\n## Extended Kalman Filter localization\n\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif\" width=\"640\" alt=\"EKF pic\">\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html)\n\n## Particle filter localization\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif)\n\nThis is a sensor fusion localization with Particle Filter(PF).\n\nThe blue line is true trajectory, the black line is dead reckoning trajectory,\n\nand the red line is an estimated trajectory with PF.\n\nIt is assumed that the robot can measure a distance from landmarks (RFID).\n\nThese measurements are used for PF localization.\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n\n## Histogram filter localization\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif)\n\nThis is a 2D localization example with Histogram filter.\n\nThe red cross is true position, black points are RFID positions.\n\nThe blue grid shows a position probability of histogram filter.  \n\nIn this simulation, x,y are unknown, yaw is known.\n\nThe filter integrates speed input and range observations from RFID for localization.\n\nInitial position is not needed.\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n# Mapping\n\n## Gaussian grid map\n\nThis is a 2D Gaussian grid mapping example.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif)\n\n## Ray casting grid map\n\nThis is a 2D ray casting grid mapping example.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif)\n\n## Lidar to grid map\n\nThis example shows how to convert a 2D range measurement to a grid map.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif)\n\n## k-means object clustering\n\nThis is a 2D object clustering with k-means algorithm.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif)\n\n## Rectangle fitting\n\nThis is a 2D rectangle fitting for vehicle detection.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif)\n\n\n# SLAM\n\nSimultaneous Localization and Mapping(SLAM) examples\n\n## Iterative Closest Point (ICP) Matching\n\nThis is a 2D ICP matching example with singular value decomposition.\n\nIt can calculate a rotation matrix, and a translation vector between points and points.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif)\n\nRef:\n\n- [Introduction to Mobile Robotics: Iterative Closest Point Algorithm](https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf)\n\n\n## FastSLAM 1.0\n\nThis is a feature based SLAM example using FastSLAM 1.0.\n\nThe blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.\n\nThe red points are particles of FastSLAM.\n\nBlack points are landmarks, blue crosses are estimated landmark positions by FastSLAM.\n\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif)\n\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n- [SLAM simulations by Tim Bailey](http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm)\n\n\n# Path Planning\n\n## Dynamic Window Approach\n\nThis is a 2D navigation sample code with Dynamic Window Approach.\n\n- [The Dynamic Window Approach to Collision Avoidance](https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf)\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif)\n\n\n## Grid based search\n\n### Dijkstra algorithm\n\nThis is a 2D grid based the shortest path planning with Dijkstra's algorithm.\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif)\n\nIn the animation, cyan points are searched nodes.\n\n### A\\* algorithm\n\nThis is a 2D grid based the shortest path planning with A star algorithm.\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif)\n\nIn the animation, cyan points are searched nodes.\n\nIts heuristic is 2D Euclid distance.\n\n### D\\* algorithm\n\nThis is a 2D grid based the shortest path planning with D star algorithm.\n\n![figure at master · nirnayroy/intelligentrobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif)\n\nThe animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.\n\nRef:\n\n- [D* Algorithm Wikipedia](https://en.wikipedia.org/wiki/D*)\n\n### D\\* Lite algorithm\n\nThis algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.\n\n![D* Lite](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif)\n\nThe animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.\n\nRefs:\n\n- [D* Lite](http://idm-lab.org/bib/abstracts/papers/aaai02b.pd)\n- [Improved Fast Replanning for Robot Navigation in Unknown Terrain](http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf)\n\n### Potential Field algorithm\n\nThis is a 2D grid based path planning with Potential Field algorithm.\n\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif)\n\nIn the animation, the blue heat map shows potential value on each grid.\n\nRef:\n\n- [Robotic Motion Planning:Potential Functions](https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf)\n\n### Grid based coverage path planning\n\nThis is a 2D grid based coverage path planning simulation.\n\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif)\n\n## State Lattice Planning\n\nThis script is a path planning code with state lattice planning.\n\nThis code uses the model predictive trajectory generator to solve boundary problem.\n\nRef: \n\n- [Optimal rough terrain trajectory generation for wheeled mobile robots](http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328)\n\n- [State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf)\n\n\n### Biased polar sampling\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif)\n\n\n### Lane sampling\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif)\n\n## Probabilistic Road-Map (PRM) planning \n\n![PRM](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif)\n\nThis PRM planner uses Dijkstra method for graph search.\n\nIn the animation, blue points are sampled points,\n\nCyan crosses means searched points with Dijkstra method,\n\nThe red line is the final path of PRM.\n\nRef:\n\n- [Probabilistic roadmap \\- Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_roadmap)\n\n　　\n\n## Rapidly-Exploring Random Trees (RRT)\n\n### RRT\\*\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif)\n\nThis is a path planning code with RRT\\*\n\nBlack circles are obstacles, green line is a searched tree, red crosses are start and goal positions.\n\nRef:\n\n- [Incremental Sampling-based Algorithms for Optimal Motion Planning](https://arxiv.org/abs/1005.0416)\n\n- [Sampling-based Algorithms for Optimal Motion Planning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&rep=rep1&type=pdf)\n\n### RRT\\* with reeds-shepp path\n\n![Robotics/animation.gif at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif)\n\nPath planning for a car robot with RRT\\* and reeds shepp path planner.\n\n### LQR-RRT\\*\n\nThis is a path planning simulation with LQR-RRT\\*.\n\nA double integrator motion model is used for LQR local planner.\n\n![LQR_RRT](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif)\n\nRef:\n\n- [LQR\\-RRT\\*: Optimal Sampling\\-Based Motion Planning with Automatically Derived Extension Heuristics](http://lis.csail.mit.edu/pubs/perez-icra12.pdf)\n\n- [MahanFathi/LQR\\-RRTstar: LQR\\-RRT\\* method is used for random motion planning of a simple pendulum in its phase plot](https://github.com/MahanFathi/LQR-RRTstar)\n\n\n## Quintic polynomials planning\n\nMotion planning with quintic polynomials.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif)\n\nIt can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.\n\nRef:\n\n- [Local Path Planning And Motion Control For Agv In Positioning](http://ieeexplore.ieee.org/document/637936/)\n\n## Reeds Shepp planning\n\nA sample code with Reeds Shepp path planning.\n\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true)\n\nRef:\n\n- [15.3.2 Reeds\\-Shepp Curves](http://planning.cs.uiuc.edu/node822.html) \n\n- [optimal paths for a car that goes both forwards and backwards](https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf)\n\n- [ghliu/pyReedsShepp: Implementation of Reeds Shepp curve\\.](https://github.com/ghliu/pyReedsShepp)\n\n\n## LQR based path planning\n\nA sample code using LQR based path planning for double integrator model.\n\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true)\n\n\n## Optimal Trajectory in a Frenet Frame \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif)\n\nThis is optimal trajectory generation in a Frenet Frame.\n\nThe cyan line is the target course and black crosses are obstacles.\n\nThe red line is the predicted path.\n\nRef:\n\n- [Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf)\n\n- [Optimal trajectory generation for dynamic street scenarios in a Frenet Frame](https://www.youtube.com/watch?v=Cj6tAQe7UCY)\n\n\n# Path Tracking\n\n## move to a pose control\n\nThis is a simulation of moving to a pose control\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif)\n\nRef:\n\n- [P. I. Corke, \"Robotics, Vision and Control\" \\| SpringerLink p102](https://link.springer.com/book/10.1007/978-3-642-20144-8)\n\n\n## Stanley control\n\nPath tracking simulation with Stanley steering control and PID speed control.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif)\n\nRef:\n\n- [Stanley: The robot that won the DARPA grand challenge](http://robots.stanford.edu/papers/thrun.stanley05.pdf)\n\n- [Automatic Steering Methods for Autonomous Automobile Path Tracking](https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf)\n\n\n\n## Rear wheel feedback control\n\nPath tracking simulation with rear wheel feedback steering control and PID speed control.\n\n![PythonRobotics/figure_1.png at master · AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif)\n\nRef:\n\n- [A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles](https://arxiv.org/abs/1604.07446)\n\n\n## Linear–quadratic regulator (LQR) speed and steering control\n\nPath tracking simulation with LQR speed and steering control.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif)\n\nRef:\n\n- [Towards fully autonomous driving: Systems and algorithms \\- IEEE Conference Publication](http://ieeexplore.ieee.org/document/5940562/)\n\n\n## Model predictive speed and steering control\n\nPath tracking simulation with iterative linear model predictive speed and steering control.\n\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif\" width=\"640\" alt=\"MPC pic\">\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html)\n\n- [Real\\-time Model Predictive Control \\(MPC\\), ACADO, Python \\| Work\\-is\\-Playing](http://grauonline.de/wordpress/?page_id=3244)\n\n## Nonlinear Model predictive control with C-GMRES\n\nA motion planning and path tracking simulation with NMPC of C-GMRES \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif)\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/cgmres_nmpc/cgmres_nmpc.html)\n\n\n# Arm Navigation\n\n## N joint arm to point control\n\nN joint arm to a point control simulation.\n\nThis is an interactive simulation.\n\nYou can set the goal position of the end effector with left-click on the plotting area. \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif)\n\nIn this simulation N = 10, however, you can change it.\n\n## Arm navigation with obstacle avoidance \n\nArm navigation with obstacle avoidance simulation.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif)\n\n\n# Aerial Navigation\n\n## drone 3d trajectory following \n\nThis is a 3d trajectory following simulation for a quadrotor.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif)\n\n## rocket powered landing\n\nThis is a 3d trajectory generation simulation for a rocket powered landing.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif)\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/aerial_navigation/rocket_powered_landing/rocket_powered_landing.html)\n\n# Bipedal\n\n## bipedal planner with inverted pendulum\n\nThis is a bipedal planner for modifying footsteps for an inverted pendulum.\n\nYou can set the footsteps, and the planner will modify those automatically.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif)\n\n# License \n\nMIT\n\n# Use-case\n\nIf this project helps your robotics project, please let me know with creating an issue.\n\nYour robot's video, which is using PythonRobotics, is very welcome!!\n\nThis is a list of user's comment and references:[users\\_comments](https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md)\n\n# Contribution\n\nAny contribution is welcome!! \n\nPlease check this document:[How To Contribute — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/how_to_contribute.html)\n\n# Citing\n\nIf you use this project's code for your academic work, we encourage you to cite [our papers](https://arxiv.org/abs/1808.10703) \n\nIf you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.\n\n# <a id=\"support\"></a>Supporting this project\n\nIf you or your company would like to support this project, please consider:\n\n- [Sponsor @AtsushiSakai on GitHub Sponsors](https://github.com/sponsors/AtsushiSakai)\n\n- [Become a backer or sponsor on Patreon](https://www.patreon.com/myenigma)\n\n- [One-time donation via PayPal](https://www.paypal.me/myenigmapay/)\n\nIf you would like to support us in some other way, please contact with creating an issue.\n\n## <a id=\"sponsors\"></a>Sponsors\n\n### <a id=\"JetBrains\"></a>[JetBrains](https://www.jetbrains.com/)\n\nThey are providing a free license of their IDEs for this OSS development.   \n\n### [1Password](https://github.com/1Password/1password-teams-open-source)\n\nThey are providing a free license of their 1Password team license for this OSS project.   \n\n\n# Authors\n\n- [Contributors to AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors)\n\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.3017578125,
          "content": "# Security Policy\n\n## Supported Versions\n\nIn this project, we are only support latest code.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| latest   | :white_check_mark: |\n\n## Reporting a Vulnerability\n\nIf you find any security related problem, let us know by creating an issue about it.\n"
        },
        {
          "name": "SLAM",
          "type": "tree",
          "content": null
        },
        {
          "name": "__init__.py",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.0458984375,
          "content": "theme: jekyll-theme-slate\nshow_downloads: true\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 1.943359375,
          "content": "os: Visual Studio 2022\n\nenvironment:\n  global:\n    # SDK v7.0 MSVC Express 2008's SetEnv.cmd script will fail if the\n    # /E:ON and /V:ON options are not enabled in the batch script intepreter\n    # See: http://stackoverflow.com/a/13751649/163740\n    CMD_IN_ENV: \"cmd /E:ON /V:ON /C .\\\\appveyor\\\\run_with_env.cmd\"\n\n  matrix:\n     - PYTHON_DIR: C:\\Python310-x64\n\nbranches:\n  only:\n    - master\n\ninit:\n  - \"ECHO %PYTHON_DIR%\"\n\ninstall:\n  # If there is a newer build queued for the same PR, cancel this one.\n  # The AppVeyor 'rollout builds' option is supposed to serve the same\n  # purpose but it is problematic because it tends to cancel builds pushed\n  # directly to master instead of just PR builds (or the converse).\n  # credits: JuliaLang developers.\n  - ps: if ($env:APPVEYOR_PULL_REQUEST_NUMBER -and $env:APPVEYOR_BUILD_NUMBER -ne ((Invoke-RestMethod `\n        https://ci.appveyor.com/api/projects/$env:APPVEYOR_ACCOUNT_NAME/$env:APPVEYOR_PROJECT_SLUG/history?recordsNumber=50).builds | `\n        Where-Object pullRequestId -eq $env:APPVEYOR_PULL_REQUEST_NUMBER)[0].buildNumber) { `\n          throw \"There are newer queued builds for this pull request, failing early.\" }\n  - ECHO \"Filesystem root:\"\n  - ps: \"ls \\\"C:/\\\"\"\n\n  # Prepend newly installed Python to the PATH of this build (this cannot be\n  # done from inside the powershell script as it would require to restart\n  # the parent CMD process).\n  - SET PATH=%PYTHON_DIR%;%PYTHON_DIR%\\\\Scripts;%PATH%\n  - SET PATH=%PYTHON%;%PYTHON%\\Scripts;%PYTHON%\\Library\\bin;%PATH%\n  - SET PATH=%PATH%;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\n  - \"python -m pip install --upgrade pip\"\n  - \"python -m pip install -r requirements/requirements.txt\"\n  - \"python -m pip install pytest-xdist\"\n\n  # Check that we have the expected version and architecture for Python\n  - \"python --version\"\n  - \"python -c \\\"import struct; print(struct.calcsize('P') * 8)\\\"\"\n\nbuild: off\n\ntest_script:\n  - \"pytest tests -n auto -Werror --durations=0\"\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "icon.png",
          "type": "blob",
          "size": 528.474609375,
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.03515625,
          "content": "[mypy]\nignore_missing_imports = True"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "ruff.toml",
          "type": "blob",
          "size": 0.2763671875,
          "content": "line-length = 88\n\nselect = [\"F\", \"E\", \"W\", \"UP\"]\nignore = [\"E501\", \"E741\", \"E402\"]\nexclude = [\n]\n\n# Assume Python 3.11\ntarget-version = \"py312\"\n\n[per-file-ignores]\n\n[mccabe]\n# Unlike Flake8, default to a complexity level of 10.\nmax-complexity = 10\n\n[pydocstyle]\nconvention = \"numpy\"\n"
        },
        {
          "name": "runtests.sh",
          "type": "blob",
          "size": 0.248046875,
          "content": "#!/usr/bin/env bash\necho \"Run test suites! \"\n\n# === pytest based test runner ===\n# -Werror: warning as error\n# --durations=0: show ranking of test durations\n# -l (--showlocals); show local variables when test failed\npytest tests -l -Werror --durations=0\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "users_comments.md",
          "type": "blob",
          "size": 12.8876953125,
          "content": "# User's demos\n\n## WHILL MODEL CR with move to a pose control\n\nThis is an electric wheelchair control demo by [Katsushun89](https://github.com/Katsushun89).\n\n[WHILL Model CR](https://whill.jp/model-cr) is the control target, [M5Stack](https://m5stack.com/) is used for the controller, and [toio](https://toio.io/) is used for the control input device.\n\n[Move to a Pose Control — PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/modules/control/move_to_a_pose_control/move_to_a_pose_control.html) is used for its control algorithm ([code link](https://github.com/AtsushiSakai/PythonRobotics/blob/master/PathTracking/move_to_pose/move_to_pose.py)).\n\n![1](https://github.com/AtsushiSakai/PythonRoboticsGifs/blob/master/Users/WHILL_Model_CR_with_move_to_a_pose/WHLL_Model_CR_with_move_to_a_pose.gif)\n\nRef:\n\n- [toioと同じように動くWHILL Model CR (in Japanese)](https://qiita.com/KatsuShun89/items/68fde7544ecfe36096d2)\n\n\n# Educational users\n\nThis is a list of users who are using PythonRobotics for education.\n\nIf you found other users, please make an issue to let me know.\n\n- [CSCI/ARTI 4530/6530: Introduction to Robotics (Fall 2018),  University of Georgia ](http://cobweb.cs.uga.edu/~ramviyas/csci_x530.html)\n\n- [CIT Modules & Programmes \\- COMP9073 \\- Automation with Python](https://courses.cit.ie/index.cfm/page/module/moduleId/14416)\n\n# Stargazers location map\n\nYou can check stargazer's locations of this project from:\n\n- [Stargazers location map](https://drive.google.com/open?id=1bBXS9IQmZ3Tfe1wNGvJbObRt9Htt4PGC&usp=sharing)\n\n\n# Related projects\n\nThis is a list of related projects. \n\n- [onlytailei/CppRobotics: cpp implementation of robotics algorithms including localization, mapping, SLAM, path planning and control](https://github.com/onlytailei/CppRobotics)\n\n# Individual users comments\n\n---\n\nDear AtsushiSakai, <br>thank you for building this cool repo for robotics. <br>I am still learning robotics and this will give me a good starting point. <br>I hope this note gets to you. <br> <br>\n\n--David Senicic\n\n---\n\nDear AtsushiSakai, <br>WE found your project from google when first searching for a rosbag to csv converter. We are a small team in MCity working on Connected (and Automated) vehicles. We are working with an opensource platform that serve as the AI to control the vehicle. Your code and documentation helped us a lot! <br> <br>Thank you! Have a nice day!\n\n--Hanlin(Julia) Chen, MCity Apollo team\n\n---\n\nDear Atsushi Sakai, <br> <br>With your simplistic descriptions in text and as gifs, i was able to help my students understand easily and effectively, I would be honored to help, in anyway towards this, As a hobbyist have been developing lidar based slam navigation systems from 2011 and its only right to acknowledge and thank you for your contributions.\n\n--Shiva\n\n---\n\nDear Atsushi Sakai <br>I first came across your Matlab repository on ICP and SLAM. The repository for both python and Matlab helped me in understanding the essential concepts of robotics.I am really grateful to you for helping me develop my understanding of the concepts of robotics.\n\n--Sparsh Garg\n\n---\n\nDear AtsushiSakai, <br>Thank you very much for all the example programs related to Robotics\n\n--Kalyan\n\n---\nDear AtsushiSakai, <br> <br>Thanks for Python Robotics\n\n--Rebecca Li\n\n---\n\nThanks alot.\n\n--Zain\n\n--- \n\nDear AtsushiSakai,<br> <br>thank you for you code!\n\n—- Anonymous\n\n--- \n\nThanks!\n\n--a friend\n\n--- \n\nThanks for the awesome collection of codes!\n\n--Qi\n\n---\n\nThank you!\n\n--huang pingzhong\n\n---\n\nDear AtsushiSakai, <br>Thanks a lot for the wonderful collection of projects.It was really useful. I really appreciate your time in maintaing and building this repository.It will be really great if I get a chance to meet you in person sometime.I got really inspired looking at your work. <br>All the very best for all your future endeavors! <br> Thanks once again, <br>\n\n---Ezhil Bharathi \n\n---\n\nDear Atsushi Sakai, <br>Thank you so much for gathering all the useful stuff and good examples of robotics things ! :) <br>I am very new in this area and want to know more about robotics and SLAM things.  <br>and again, thank you so much :) <br>\n\n--Tutorgaming\n\n---\n\nDear AtsushiSakai, <br>Very excellent work. Thank you for your share.\n\n--Thomas Yang\n\n---\n\nDear Atsushi Saka Arigato 🤗🤗\n\n--Badal Kumar\n\n---\n\nDear AtsushiSakai, <br>Thanks for teaching how to implement path planning algorithms in robotics. <br>\n\n---\n\nYour Github page is very useful. I will apply it with cooperative robot.\n\n--Soloist\n\n---\n\nhelp me very much thankyou\n\n--sanchuan\n\n---\n\nDear AtsushiSakai, <br>U R so niubility!\n\n--FangKD\n\n---\n\nthankyou AtsushiSakai!\n\n--ou minghua\n\n---\n\nDear AtsushiSakai <br>Thank You\n\n--Dogukan Altay\n\n---\n\nso kind of you can you make videos of it.\n\n---\n\nDear AtshshiSakai, <br>You are very wise and smart that you created this library for students wanting to learn Probabilistic Robotics and actually perform robot control. <br>Hats off to you and your work. <br>I am also reading your book titled : Python Robotics\n\n--Himanshu\n\n---\n\nDear AtsushiSakai, <br>Hello! YOUR CODE IS SUPER SUPER HELPFUL AND GIVES ME CLEAR INSTRUCTIONs as well as STRONG SUPPORT!! <br>Thank you so much !\n\n--Lee\n\n---\n\nHi AtsushiSakai, <br> <br>Thanks for creating the pythonrobotics repo! It's an awesome repo that has been of great help to me. I've referenced your extended kalman filter algorithm while creating my own for localization using a 2D lidar, camera, and IMU. Our robot is destined to compete soon, so fingers crossed that all works out! Thanks again.\n\n---\n\nYou rock!\n\n--Matt\n\n---\n\nDear AtsushiSakai, <br>You are the best. This is by far the best tutorial for learning and implementing robotics. <br>Thanks a lot for your time and efforts to do this!\n\n--Adi B\n\n---\n\nDear Atushi, thank you for this amazing repository. It is a pleasure to have access to python algorithms without the burden of ROS. While I'm no longer working on such robotics projects, it's wonderful to know its available when I need it and it was amazing to see all the beautiful animations for each algorithm.\n\n--Shreeyak Sajjan\n\n---\n\nDear AtsushiSakai <br>Thank you for your contributions!\n\n--Luo\n\n---\n\nDear AtsushiSakai, Your visualizations are awesome, and I am going to have this link bookmarked for future references. Thank you!\n\n--Srinivasa Varadhan Agaram Chakravarthy\n\n---\n\nDear AtsushiSakai, <br>Thank you for this great resource! I very much appreciate all your hard work and effort.\n\n--Mridul Aanjaneya\n\n---\n\nThank you for the python robotics sample code and visualizations!! This is my new favorite thing on the internet.\n\n--selamg@mit.edu\n\n---\n\nMr AtsushiSakai .. <br>Your work and teaching is light for me <br>thank you very much for giving time and effort to make it public for us\n\n--Karim Anass\n\n---\n\nThank You\n\n--Anonymous\n\n---\n\nI've learned the robotics from the traditional way of solving problem through finding packages and reading papers. This amazing project is unbelievably helpful for new-comers to learn and get familiar with the algorithms. Gods know how many hours you've taken to sort all the materials and written everything into one single coherent project. I'm truly amazed and deepest appreciation.\n\n--Ewing Kang\n\n---\n\nHey, I'm a student and I just recently got into robotics, and visited your repository multiple times. Today I was super happy to find the link to Patreon! I am impressed by didactic quality of the repo, keep up the good work!\n\n--Carolina Bianchi\n\n---\n\nDear AtsushiSakai, thanks a lot for the PythonRobotics git repository. I'm a college student who is trying to make a mini autonomous robot for my final project submission, I still haven't started using your code but by the look of it I'm sure it will be of greater use. Will let you know how my project is coming up.\n\n--Pragdheesh\n\n---\n\nHello AtsushiSakai, <br> <br>Thank you very much for sharing your work!\n\n--Uma K\n\n---\n\nHey Atsushi <br>We are working on a multiagent simulation game and this project gave us really good insights. <br>In future, I would like to contribute to this project with our multiagent task allocation among robots and multi robot map merging( Which is a big hurdle as we found). <br>Thanks for what you are doing for open source. <br>\n\n--Mayank\n\n---\n\nThanks a lot for this amazing set of very useful librarires!\n\n--Razvan Viorel Mihai\n\n---\n\nDear Atsushi Sakai, <br> <br>This is probably one of the best open-source robotics based Algorithms I have seen so far. Thank you for posting this knowledge with other engineers. It will definitely help soon to become engineers like myself.\n\n--Don\n\n---\n\nhanks frnd, for ur contibusion\n\n—--\n\nThank you for python robotics!!\n\n--Manuel Miguez\n\n---\n\nGreat job\n\n--Anonymous\n\n---\n\nDear Atsushi Sakai <br>Thank you for the Python Robotics\n\n--Alex Liberzon\n\n---\n\nThanks for your robotics repo!\n\n--Mithi\n\n---\n\nYou made such a nice work. Congratulations :)\n\n--ATroya\n\n---\n\nthank you for python path finding repo\n\n--fengzongbao\n\n---\n\nDear AtsushiSakai, <br> <br>Thank you so much for making the concept of robotics approachable for the general mass. Keep up the good work :)\n\n--Harsh Munshi\n\n---\n\nBenefit a lot for your GitHub repository of PythonRobotics. Thanks so much.\n\n--Haoran\n\n---\n\nThanks!\n\n--Reinzor\n\n---\n\nThanks for writing these algorithms. They are very helpful for learning robotics.\n\n--Arihant Lunawat\n\n---\n\nDear AtsushiSakai, <br>Thank you for providing us this great repository for playing and look around:)!\n\n--Hsin-Wen\n\n---\n\nThanks for PythonRobotics!\n\n--Nick V\n\n---\n\nDear AtsushiSakai, thank you so much for this material, it's so useful to me, i'm really glad with it =D\n\n--Juanda\n\n---\n\nDear Atsushi Thanks for compiling such a vast resource for robotics motion planning.\n\n--Kartik Prakash\n\n---\n\nThanks for your job! <br>I have learned a lot from it!\n\n--ZhongyiShen\n\n---\n\nDear Atsushi Sakai, <br>Thank you so much for creating PythonRobotics and documenting it so well. I am a senior in high school trying to learn and better myself in these concepts.\n\n--Rohan Mathur\n\n\n\n# Citations\n\n1. B. Blaga, M. Deac, R. W. Y. Al-doori, M. Negru and R. Dǎnescu, \"Miniature Autonomous Vehicle Development on Raspberry Pi,\" 2018 IEEE 14th International Conference on Intelligent Computer Communication and Processing (ICCP), Cluj-Napoca, Romania, 2018, pp. 229-236.\ndoi: 10.1109/ICCP.2018.8516589\nkeywords: {Automobiles;Task analysis;Autonomous vehicles;Path planning;Global Positioning System;Cameras;miniature autonomous vehicle;path planning;navigation;parking assist;lane detection and tracking;traffic sign recognition},\nURL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8516589&isnumber=8516425\n\n2. Peggy (Yuchun) Wang and Caitlin Hogan, \"Path Planning with Dynamic Obstacle Avoidance for a Jumping-Enabled Robot\", AA228/CS238 class report, Department of Computer Science, Stanford University, URL: https://web.stanford.edu/class/aa228/reports/2018/final113.pdf\n\n3. Welburn, E, Hakim Khalili, H, Gupta, A, Watson, S & Carrasco, J 2019, A Navigational System for Quadcopter Remote Inspection of Offshore Substations. in The Fifteenth International Conference on Autonomic and Autonomous Systems 2019. URL:https://www.research.manchester.ac.uk/portal/files/107169964/ICAS19_A_Navigational_System_for_Quadcopter_Remote_Inspection_of_Offshore_Substations.pdf\n\n4. E. Horváth, C. Hajdu, C. Radu and Á. Ballagi, \"Range Sensor-based Occupancy Grid Mapping with Signatures,\" 2019 20th International Carpathian Control Conference (ICCC), Krakow-Wieliczka, Poland, 2019, pp. 1-5.\nURL: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8765684&isnumber=8765679\n\n5. Josie Hughes, Masaru Shimizu, and Arnoud Visser, \"A Review of Robot Rescue Simulation Platforms for Robotics Education\"\nURL: https://2019.robocup.org/downloads/program/HughesEtAl2019.pdf\n\n6. Hughes, Josie, Masaru Shimizu, and Arnoud Visser. \"A review of robot rescue simulation platforms for robotics education.\" (2019).\nURL: https://www.semanticscholar.org/paper/A-Review-of-Robot-Rescue-Simulation-Platforms-for-Hughes-Shimizu/318a4bcb97a44661422ae1430d950efc408097da\n\n7. Ghosh, Ritwika, et al. \"CyPhyHouse: A Programming, Simulation, and Deployment Toolchain for Heterogeneous Distributed Coordination.\" arXiv preprint arXiv:1910.01557 (2019).\nURL: https://arxiv.org/abs/1910.01557\n\n8. Hahn, Carsten, et al. \"Dynamic Path Planning with Stable Growing Neural Gas.\" (2019).\nURL: https://pdfs.semanticscholar.org/5c06/f3cb9542a51e1bf1a32523c1bc7fea6cecc5.pdf\n\n9. Brijen Thananjeyan, et al. \"ABC-LMPC: Safe Sample-Based Learning MPC for Stochastic Nonlinear Dynamical Systems with Adjustable Boundary Conditions\"\nURL: https://arxiv.org/pdf/2003.01410.pdf\n\n# Others\n\n- Autonomous Vehicle Readings https://richardkelley.io/readings\n\n- 36 Amazing Python Open Source Projects (v.2019) – Mybridge for Professionals https://medium.mybridge.co/36-amazing-python-open-source-projects-v-2019-2fe058d79450\n\n- Real-time Model Predictive Control (MPC), ACADO, Python | Work-is-Playing http://grauonline.de/wordpress/?page_id=3244\n\n- 💡 Greatest of GitHub - Python Robotics (Amazing!) - YouTube https://www.youtube.com/watch?v=f_pPaYx6Gu0&feature=emb_logo\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}