{
  "metadata": {
    "timestamp": 1736561302059,
    "page": 304,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "zalandoresearch/fashion-mnist",
      "stars": 12055,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".catwatch.yaml",
          "type": "blob",
          "size": 0.130859375,
          "content": "# this file will be read by Catwatch\n# see https://github.com/zalando/catwatch/issues/32\ntitle: A MNIST-like fashion product database."
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.1064453125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*,cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# IPython Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# dotenv\n.env\n\n# virtualenv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n\n# Rope project settings\n.ropeproject\n\n.idea\n/data/fashion/holdout-labels-idx1-ubyte.gz\n/data/fashion/holdout-images-idx3-ubyte.gz\n"
        },
        {
          "name": ".zappr.yaml",
          "type": "blob",
          "size": 0.1455078125,
          "content": "approvals:\n  groups:\n    zalando:\n      minimum: 2\n      from:\n        orgs:\n          - \"zalando\"\n\nX-Zalando-Team: deepthought\nX-Zalando-Type: tools"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.5224609375,
          "content": "# Contributing to Fashion-MNIST\n\nWe are happy to accept your contributions to make `Fashion-MNIST` better and more awesome! To avoid unnecessary work on either side, please stick to the following process:\n\n1. Check if there is already [an issue](https://github.com/zalando/fashion-mnist/issues) for your concern.\n2. If there is not, open a new one to start a discussion. We hate to close finished PRs!\n3. If we decide your concern needs code changes, we would be happy to accept a pull request. Please consider the commit guidelines below.\n\nIn case you just want to help out and don't know where to start, [issues with \"help wanted\" label](https://github.com/zalandoresearch/fashion-mnist/labels/help%20wanted) are good for first-time contributors. \n\n## Git Commit Guidelines\n\nIf there is already a ticket, use this number at the start of your commit message. \n\nUse [semantic commit messages](http://seesparkbox.com/foundry/semantic_commit_messages):\n\n* citation (submitting papers/applications that used this dataset)\n* visualization (submitting interesting visualization)\n* quality (improving the quality of the data (images/labels))\n* benchmark (submitting new benchmark)\n* feat (new feature)\n* fix (bug fix)\n* docs (changes to documentation)\n* style (formatting, missing semi colons, etc; no code change)\n* refactor (refactoring production code)\n* test (adding missing tests, refactoring tests; no production code change)\n* chore (updating grunt tasks etc; no production code change)\n\n**Example:** `#42 citation: I used it in my paper, here is my bibtex` "
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.3916015625,
          "content": "FROM tensorflow/tensorflow:latest-gpu-py3\n\nMAINTAINER han.xiao@zalando.de\n\nWORKDIR /\n\n# Install necessary packages.\nRUN apt-get -y update && \\\n    apt-get -y install jq awscli && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nCOPY requirements.txt /\nRUN pip install --no-cache-dir -r requirements.txt\n\nADD . /\n\nENTRYPOINT python ./app.py $ARGUMENTS\n#ENTRYPOINT python ./benchmark/convnet.py"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0830078125,
          "content": "The MIT License (MIT) Copyright © 2017 Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "MAINTAINERS",
          "type": "blob",
          "size": 0.0693359375,
          "content": "Han Xiao <hanhxiao@tencent.com>\nKashif Rasul <kashif.rasul@zalando.de>\n"
        },
        {
          "name": "README.ja.md",
          "type": "blob",
          "size": 23.4912109375,
          "content": "# Fashion-MNIST\n\n[![GitHub stars](https://img.shields.io/github/stars/zalandoresearch/fashion-mnist.svg?style=flat&label=Star)](https://github.com/zalandoresearch/fashion-mnist/)\n[![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link)\n[![Readme-EN](https://img.shields.io/badge/README-English-green.svg)](README.md)\n[![Readme-CN](https://img.shields.io/badge/README-中文-green.svg)](README.zh-CN.md)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Year-In-Review](https://img.shields.io/badge/%F0%9F%8E%82-%E3%83%AC%E3%83%93%E3%83%A5%E3%83%BC%E3%81%AE%E5%B9%B4-orange.svg)](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n\n翻訳 : [(株)クラスキャット セールスインフォメーション](http://tensorflow.classcat.com/2017/08/28/tensorflow-fashion-mnist/)\n\n<details><summary>目次</summary><p>\n\n  * [何故でしょう？](#何故でしょう？)\n  * [データを取得する](#データを取得する)\n  * [使い方](#使い方)\n  * [ベンチマーク](#ベンチマーク)\n  * [可視化](#可視化)\n  * [貢献する](#貢献する)\n  * [接触](#接触)\n  * [引用Fashion-MNIST](#引用Fashion-MNIST)\n  * [License](#license)\n</p></details><p></p>\n\n\n60,000 サンプルの訓練セットと 10,000 サンプルのテストセットから成る、[Zalando](https://jobs.zalando.com/tech/) の記事の画像のデータセットです。各サンプルは 28×28 グレースケール画像で、10 クラスからのラベルと関連付けられています。`Fashion-MNIST` は、機械学習アルゴリズムのベンチマークのためのオリジナルの MNIST データセット の 直接的な差し込み式の (= drop-in) 置き換え としてサーブすることを意図しています。\n\nここにどのようにデータが見えるかのサンプルがあります (各クラスは３行取ります) :\n\n![](doc/img/fashion-mnist-sprite.png)\n\n<img src=\"doc/img/embedding.gif\" width=\"100%\">\n\n## 何故でしょう？\n   \nオリジナルの [MNIST](http://yann.lecun.com/exdb/mnist/) データセットは沢山の手書き数字を含みます。AI/ML/データサイエンス・コミュニティの人々はこのデータセットを好みそして彼らのアルゴリズムを検証するためのベンチマークとしてそれを使用します。実際に、MNIST はしばしば試してみる最初のデータセットです。「もしそれが MNIST で動作しなければ、まったく動作しないだろう」と彼らは言いました。「そうですね～、もし MNIST で動作するとしても、他の上では依然として失敗するかもしれませんが。」\n   \nFashion-MNIST は、機械学習アルゴリズムのベンチマークのためのオリジナルの MNIST データセットの直接的な差し込み式の (= drop-in) 置き換えとしてサーブすることを意図しています、というのはそれは同じ画像サイズでそして訓練及びテスト分割の構造を共有しているからです。\n\n### 真面目な機械学習研究者へ\n\n真面目な話し、MNIST を置き換えることについて話しをしています。幾つかの良い理由がここにあります :\n\n- **MNIST は簡単過ぎます。** [私たちの比較ベンチマーク](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/) と “[Most pairs of MNIST digits can be distinguished pretty well by just one pixel](https://gist.github.com/dgrtwo/aaef94ecc6a60cd50322c0054cc04478)” を確かめてください。\n- **MNIST は使用され過ぎています。** “[Ian Goodfellow wants people to move away from mnist.](https://twitter.com/goodfellow_ian/status/852591106655043584)”を確かめてください。\n- **MNIST はモダンな CV タスクを表現できません。** “[François Cholle: Ideas on MNIST do not transfer to real CV.](https://twitter.com/fchollet/status/852594987527045120)” を確かめてください。\n\n## データを取得する\n[多くのMLライブラリ](#他の機械学習ライブラリを使用する)には既にFashion-MNISTデータ/ APIが含まれています。試してみてください！\n\nデータセットをダウンロードするためには直接リンクを使用することができます。データはオリジナルの [MNIST](http://yann.lecun.com/exdb/mnist/) データと同じフォーマットでストアされています。\n\n| 名前  | 内容 | サンプル | サイズ | リンク | MD5チェックサム|\n| --- | --- |--- | --- |--- |--- |\n| `train-images-idx3-ubyte.gz`  | 訓練セット画像\t  | 60,000|26 MBytes | [ダウンロード](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz)|`8d4fb7e6c68d591d4c3dfef9ec88bf0d`|\n| `train-labels-idx1-ubyte.gz`  | 訓練セット・ラベル |60,000|29 KBytes | [ダウンロード](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz)|`25c81989df183df01b3e8a0aad5dffbe`|\n| `t10k-images-idx3-ubyte.gz`  | テストセット画像  | 10,000|4.3 MBytes | [ダウンロード](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz)|`bef4ecab320f06d8554ea6380940ec79`|\n| `t10k-labels-idx1-ubyte.gz`  | テストセット・ラベル  | 10,000| 5.1 KBytes | [ダウンロード](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz)|`bb300cfdad3c16e7a12a480ee83cd310`|\n\nあるいはこのレポジトリを clone することもできます、データセットは `data/fashion` の下です。この repo はベンチーマークと可視化のための幾つかのスクリプトを含みます。\n   \n```bash\ngit clone git@github.com:zalandoresearch/fashion-mnist.git\n```\n\n### ラベル\n各訓練とテスト・サンプルは以下のラベル群の一つに割り当てられています :\n\n| ラベル | 記述 |\n| --- | --- |\n| 0 | T-shirt/top |\n| 1 | Trouser |\n| 2 | Pullover |\n| 3 | Dress |\n| 4 | Coat |\n| 5 | Sandal |\n| 6 | Shirt |\n| 7 | Sneaker |\n| 8 | Bag |\n| 9 | Ankle boot |\n\n## 使い方\n\n### Python ([NumPy](http://www.numpy.org/)が必要)でデータをロードする\n\nこの repo の `utils/mnist_reader` を使用する :\n```python\nimport mnist_reader\nX_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\nX_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n```\n\n### でデータをロードする\n\n[私たちのデータセットをダウンロードしてください](#データを取得する)ことを確認し、それを `data/fashion`の下に置きます。それ以外の場合、* Tensorflowは自動的に元のMNISTをダウンロードして使用します。 *\n\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('data/fashion')\n\ndata.train.next_batch(BATCH_SIZE)\n```\n\nFashion-MNISTを訓練するための高レベルのAPIである`tf.keras`の使用に関する公式のTensorflow[チュートリアルがここにあります](https://www.tensorflow.org/tutorials/keras/classification)。\n\n### 他の機械学習ライブラリを使用する\n\n今日まで、以下のライブラリは、組み込みデータセットとして `Fashion-MNIST`を含んでいます。 したがって、自分で`Fashion-MNIST`をダウンロードする必要はありません。 そのAPIに従うだけで、あなたは準備が整いました。\n\n- [Apache MXNet Gluon](https://mxnet.apache.org/api/python/docs/api/gluon/data/vision/datasets/index.html#mxnet.gluon.data.vision.datasets.FashionMNIST)\n- [TensorFlow.js](https://github.com/tensorflow/tfjs-examples/blob/master/fashion-mnist-vae/data.js)\n- [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist)\n- [Pytorch](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)\n- [Keras](https://keras.io/api/datasets/fashion_mnist/)\n- [Edward](http://edwardlib.org/api/observations/fashion_mnist)\n- [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist)\n- [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/fashion_mnist)\n- [Torch](https://github.com/mingloo/fashion-mnist)\n- [JuliaML](https://juliaml.github.io/MLDatasets.jl/latest/datasets/FashionMNIST/)\n- [Chainer](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.get_fashion_mnist.html)\n- [HuggingFace Datasets](https://huggingface.co/datasets/fashion_mnist)\n- \nようこそ私たちに参加して、各機械学習ライブラリ用の`Fashion-MNIST`のサポートを追加してください。\n\n\n### 他の言語でデータをロードする\n\n機械学習コミュニティでもっとも人気のあるデータセットの一つですので、人々は多くの言語で MNIST loader を実装してきています。それらは `Fashion-MNIST` データセットをロードするためにも使用できるでしょう (最初に decompress する必要があるかもしれません)。それらは私たちによってテストはされていないことには注意してください。\n\n- [C](https://stackoverflow.com/a/10409376)\n- [C++](https://github.com/wichtounet/mnist)\n- [Java](https://stackoverflow.com/a/8301949)\n- [Python](https://pypi.python.org/pypi/python-mnist) and [this](https://pypi.python.org/pypi/mnist) \n- [Scala](http://mxnet.io/tutorials/scala/mnist.html)\n- [Go](https://github.com/schuyler/neural-go/blob/master/mnist/mnist.go)\n- [C#](https://jamesmccaffrey.wordpress.com/2013/11/23/reading-the-mnist-data-set-with-c/)\n- [NodeJS](https://github.com/ApelSYN/mnist_dl) and [this](https://github.com/cazala/mnist)\n- [Swift](https://github.com/simonlee2/MNISTKit)\n- [R](https://gist.github.com/brendano/39760) and [this](https://github.com/maddin79/darch)\n- [Matlab](http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset)\n- [Ruby](https://github.com/gbuesing/mnist-ruby-test/blob/master/train/mnist_loader.rb)\n- [Rust](https://github.com/AtheMathmo/vision-rs/blob/master/src/fashion_mnist.rs)\n\n\n## ベンチマーク\nscikit-learn ベースの自動ベンチマーキング・システムを構築しました、これは異なるパラメータの 129 の (深層学習ではない) 分類器をカバーします。 [結果はここで見つかります。](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/).\n\n<img src=\"doc/img/benchmark.gif\" width=\"100%\">\n\n結果は benchmark/runner.py を実行することで再現できます。推奨方法はこの docker コンテナをビルドして deploy することです (訳注 : リンク欠落)。[this Dockerfile](Dockerfile). \n\n貴方のベンチマークを submit することを歓迎します。新しい issue を作成してください、貴方の結果はここでリストされます。詳細は [contributor guidelines](https://github.com/zalandoresearch/fashion-mnist#contributing) セクションを確認してください。ベンチマークを submit する前に、このリストにリストされていなことを必ず確認してください。\n\n| 分類器 | 前処理\t | Fashion テスト精度| MNIST テスト精度 | Submitter| コード |\n| --- | --- | --- | --- | --- |--- |\n|2 Conv+pooling | None | 0.876 | - | [Kashif Rasul](https://twitter.com/krasul) | [:link:](https://gist.github.com/kashif/76792939dd6f473b7404474989cb62a8) |\n|2 Conv+pooling | None | 0.916| - |[Tensorflow's doc](https://www.tensorflow.org/tutorials/layers) | [:link:](/benchmark/convnet.py)|\n|2 Conv+pooling+ELU activation (PyTorch)| None| 0.903| - | [@AbhirajHinge](https://github.com/AbhirajHinge) | [:link:](https://github.com/AbhirajHinge/CNN-with-Fashion-MNIST-dataset)|\n|2 Conv | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.919 |0.971 | [Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|2 Conv <100K parameters | None | 0.925 | 0.992 |[@hardmaru](https://twitter.com/hardmaru) | [:link:](https://github.com/hardmaru/pytorch_notebooks/blob/master/pytorch_tiny_custom_mnist_adam.ipynb)|\n|2 Conv ~113K parameters | Normalization | 0.922| 0.993 |[Abel G.](https://github.com/abelusha) | [:link:](https://github.com/abelusha/MNIST-Fashion-CNN/blob/master/Fashon_MNIST_CNN_using_Keras_10_Runs.ipynb)|\n|2 Conv+3 FC ~1.8M parameters| Normalization | 0.932 | 0.994 | [@Xfan1025](https://github.com/Xfan1025) |[:link:](https://github.com/Xfan1025/Fashion-MNIST/blob/master/fashion-mnist.ipynb) |\n|2 Conv+3 FC ~500K parameters | Augmentation, batch normalization | 0.934 | 0.994 | [@cmasch](https://github.com/cmasch) |[:link:](https://github.com/cmasch/zalando-fashion-mnist) |\n|2 Conv+pooling+BN | None | 0.934 | - | [@khanguyen1207](https://github.com/khanguyen1207) | [:link:](https://github.com/khanguyen1207/My-Machine-Learning-Corner/blob/master/Zalando%20MNIST/fashion.ipynb)|\n|2 Conv+2 FC| Random Horizontal Flips|  0.939| -| [@ashmeet13](https://github.com/ashmeet13)|[:link:](https://github.com/ashmeet13/FashionMNIST-CNN)|\n|3 Conv+2 FC | None | 0.907 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|3 Conv+pooling+BN | None | 0.903 | 0.994 | [@meghanabhange](https://github.com/meghanabhange) | [:link:](https://github.com/meghanabhange/FashionMNIST-3-Layer-CNN) |\n|3 Conv+pooling+2 FC+dropout | None | 0.926 | - | [@Umberto Griffo](https://github.com/umbertogriffo) | [:link:](https://github.com/umbertogriffo/Fashion-mnist-cnn-keras)|\n|3 Conv+BN+pooling|None|0.921|0.992|[@gchhablani](https://github.com/gchhablani)|[:link:](https://github.com/gchhablani/CNN-with-FashionMNIST)| \n|5 Conv+BN+pooling|None|0.931|-|[@Noumanmufc1](https://github.com/Noumanmufc1)|[:link:](https://gist.github.com/Noumanmufc1/60f00e434f0ce42b6f4826029737490a)| \n|CNN with optional shortcuts, dense-like connectivity| standardization+augmentation+random erasing | 0.947 |-| [@kennivich](https://github.com/Dezhic) | [:link:](https://github.com/Dezhic/fashion-classifier)|\n|GRU+SVM | None| 0.888 | 0.965 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/828fbda0e466dacb1fad66549e0e3022e1c7263a/gru_svm_zalando.py)|\n|GRU+SVM with dropout | None| 0.897 | 0.988 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/58dbe7cd8b0d83e4386cd6896766113b1a9af096/gru_svm_zalando_dropout.py)|\n|WRN40-4 8.9M params | standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips)| 0.967 | - |[@ajbrock](https://github.com/ajbrock) | [:link:](https://github.com/xternalz/WideResNet-pytorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|DenseNet-BC 768K params| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.954 | - |[@ajbrock](https://github.com/ajbrock)  | [:link:](https://github.com/bamos/densenet.pytorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|MobileNet | augmentation (horizontal flips)| 0.950|- | [@苏剑林](https://github.com/bojone)| [:link:](http://kexue.fm/archives/4556/)|\n|ResNet18 | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.949 | 0.979 |[Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|GoogleNet with cross-entropy loss | None | 0.937 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|AlexNet with Triplet loss| None | 0.899 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|SqueezeNet with cyclical learning rate 200 epochs| None| 0.900| - | [@snakers4](https://github.com/snakers4) | [:link:](https://github.com/zalandoresearch/fashion-mnist/files/1263340/squeeze_net_mnist.zip)|\n|Dual path network with wide resnet 28-10|standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) |0.957|-|[@Queequeg](https://github.com/Queequeg92)|[:link:](https://github.com/Queequeg92/DualPathNet)|\n|MLP 256-128-100| None | 0.8833| - | [@heitorrapela](https://github.com/heitorrapela)| [:link:](https://github.com/heitorrapela/fashion-mnist-mlp)|\n|VGG16 26M parameters | None | 0.935| - | [@QuantumLiu](https://github.com/QuantumLiu)|[:link:](https://github.com/QuantumLiu/fashion-mnist-demo-by-Keras) [:link:](https://zhuanlan.zhihu.com/p/28968219)|\n|WRN-28-10| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.959 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|WRN-28-10 + Random Erasing| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.963 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|Human Performance| Crowd-sourced evaluation of human (with no fashion expertise) performance. 1000 randomly sampled test images, 3 labels per image, majority labelling. | 0.835 | - | Leo  | - \n|Capsule Network 8M parameters| Normalization and shift at most 2 pixel and horizontal flip | 0.936 | - | [@XifengGuo](https://github.com/XifengGuo)  | [:link:](https://github.com/XifengGuo/CapsNet-Fashion-MNIST)|\n|HOG+SVM| HOG | 0.926 | - | [@subalde](https://github.com/subalde) | [:link:](https://github.com/subalde/fashion-mnist)|\n|XgBoost| scaling the pixel values to mean=0.0 and var=1.0| 0.898| 0.958| [@anktplwl91](https://github.com/anktplwl91)| [:link:](https://github.com/anktplwl91/fashion_mnist.git)|\n|DENSER| - | 0.953| 0.997| [@fillassuncao](https://github.com/fillassuncao)| [:link:](https://github.com/fillassuncao/denser-models) [:link:](https://arxiv.org/pdf/1801.01563.pdf)|\n|Dyra-Net| Rescale to unit interval | 0.906| -| [@Dirk Schäfer](https://github.com/disc5)| [:link:](https://github.com/disc5/dyra-net) [:link:](https://dl.acm.org/citation.cfm?id=3204176.3204200)|\n|Google AutoML|24 compute hours (higher quality)| 0.939|-| [@Sebastian Heinz](https://github.com/sebastianheinz) |[:link:](https://www.statworx.com/de/blog/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist/)|\n|Fastai| Resnet50+Fine-tuning+Softmax on last layer's activations| 0.9312| - | [@Sayak](https://github.com/sayakpaul) | [:link:](https://github.com/sayakpaul/Experiments-on-Fashion-MNIST/)|\n\n### 他の探求\n\n#### [Fashion-MNIST: Year in Review](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n#### [Fashion-MNIST on Google Scholar](https://scholar.google.de/scholar?hl=en&as_sdt=0%2C5&q=fashion-mnist&btnG=&oq=fas) \n\n#### Generative adversarial networks (GANs) \n- [Tensorflow implementation of various GANs and VAEs.](https://github.com/hwalsuklee/tensorflow-generative-model-collections) (**Recommend to read!** Note how various GANs generate different results on Fashion-MNIST, which can not be easily observed on the original MNIST.)\n- [Make a ghost wardrobe using DCGAN](https://twitter.com/spaceLenny/status/901488938023403520)\n- [fashion-mnist的gan玩具](http://kexue.fm/archives/4540/)\n- [CGAN output after 5000 steps](https://github.com/a7b23/Conditional-GAN-using-tensorflow-slim)\n- [GAN Playground - Explore Generative Adversarial Nets in your Browser](https://reiinakano.github.io/gan-playground/)\n\n#### クラスタリング\n- [Xifeng Guo's implementation](https://github.com/XifengGuo/DEC-keras) of [Unsupervised Deep Embedding for Clustering Analysis (DEC)](http://proceedings.mlr.press/v48/xieb16.pdf)\n- [Leland McInnes's](https://github.com/lmcinnes) [Uniform Manifold Approximation and Projection (UMAP)](https://github.com/lmcinnes/umap)\n\n\n#### ビデオチュートリアル\n*Machine Learning Meets Fashion* by Yufeng G @ Google Cloud\n\n[![Machine Learning Meets Fashion](doc/img/ae143b2d.png)](https://youtu.be/RJudqel8DVA)\n\n*Introduction to Kaggle Kernels* by [Yufeng G](https://twitter.com/yufengg) @ Google Cloud\n\n[![Introduction to Kaggle Kernels](doc/img/853c717e.png)](https://youtu.be/FloMHMOU5Bs)\n\n*动手学深度学习* by Mu Li @ Amazon AI\n\n[![MXNet/Gluon中文频道](doc/img/e9514ab1.png)](https://youtu.be/kGktiYF5upk)\n\nApache MXNet으로 배워보는 딥러닝(Deep Learning) - 김무현 (AWS 솔루션즈아키텍트)\n\n[![Apache MXNet으로 배워보는 딥러닝(Deep Learning)](doc/img/dd83f448.png)](https://youtu.be/H66GDuLsGl4)\n\n\n\n## 可視化\n\n### t-SNE on Fashion-MNIST (左) とオリジナルの MNIST (右)\n<img src=\"doc/img/34d72c08.png\" width=\"50%\"><img src=\"doc/img/01e0c4be.png\" width=\"50%\">\n\n### PCA on Fashion-MNIST (左) とオリジナルの MNIST (右)\n<img src=\"doc/img/f04ba662.png\" width=\"50%\"><img src=\"doc/img/4433f0e1.png\" width=\"50%\">\n\n### [UMAP](https://github.com/lmcinnes/umap) Fashion-MNIST (左) とオリジナルの MNIST (右) \n<img src=\"doc/img/umap_example_fashion_mnist1.png\" width=\"50%\"><img src=\"doc/img/umap_example_mnist1.png\" width=\"50%\">\n\n### [PyMDE](https://github.com/cvxgrp/pymde) Fashion-MNIST (左) とオリジナルの MNIST (右) \n<img src=\"doc/img/pymde_example_fashion_mnist.png\" width=\"50%\"><img src=\"doc/img/pymde_example_mnist.png\" width=\"50%\">\n\n## 貢献する\n\nThanks for your interest in contributing! There are many ways to get involved; start with our [contributor guidelines](/CONTRIBUTING.md) and then check these [open issues](https://github.com/zalandoresearch/fashion-mnist/issues) for specific tasks.\n\n## 接触\nTo discuss the dataset, please use [![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link).\n\n## 引用Fashion-MNIST\nIf you use Fashion-MNIST in a scientific publication, we would appreciate references to the following paper:\n\n**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](http://arxiv.org/abs/1708.07747)**\n\nBiblatex entry:\n```latex\n@online{xiao2017/online,\n  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},\n  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},\n  date         = {2017-08-28},\n  year         = {2017},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1708.07747},\n}\n```\n\n[誰がFashion-MNISTを引用していますか？](https://scholar.google.com/scholar?scisbd=2&q=%22fashion-mnist%22&hl=en&as_sdt=0,5) \n\n\n## License\n\nThe MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.1787109375,
          "content": "# Fashion-MNIST\n\n[![GitHub stars](https://img.shields.io/github/stars/zalandoresearch/fashion-mnist.svg?style=flat&label=Star)](https://github.com/zalandoresearch/fashion-mnist/)\n[![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link)\n[![Readme-CN](https://img.shields.io/badge/README-中文-green.svg)](README.zh-CN.md)\n[![Readme-JA](https://img.shields.io/badge/README-日本語-green.svg)](README.ja.md)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Year-In-Review](https://img.shields.io/badge/%F0%9F%8E%82-Year%20in%20Review-orange.svg)](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n\n<details><summary>Table of Contents</summary><p>\n\n* [Why we made Fashion-MNIST](#why-we-made-fashion-mnist)\n* [Get the Data](#get-the-data)\n* [Usage](#usage)\n* [Benchmark](#benchmark)\n* [Visualization](#visualization)\n* [Contributing](#contributing)\n* [Contact](#contact)\n* [Citing Fashion-MNIST](#citing-fashion-mnist)\n* [License](#license)\n</p></details><p></p>\n\n\n`Fashion-MNIST` is a dataset of [Zalando](https://jobs.zalando.com/tech/)'s article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend `Fashion-MNIST` to serve as a direct **drop-in replacement** for the original [MNIST dataset](http://yann.lecun.com/exdb/mnist/) for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\nHere's an example of how the data looks (*each class takes three-rows*):\n\n![](doc/img/fashion-mnist-sprite.png)\n\n<img src=\"doc/img/embedding.gif\" width=\"100%\">\n\n## Why we made Fashion-MNIST\n\nThe original [MNIST dataset](http://yann.lecun.com/exdb/mnist/) contains a lot of handwritten digits. Members of the AI/ML/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. *\"If it doesn't work on MNIST, it **won't work** at all\"*, they said. *\"Well, if it does work on MNIST, it may still fail on others.\"* \n\n### To Serious Machine Learning Researchers\n\nSeriously, we are talking about replacing MNIST. Here are some good reasons:\n\n- **MNIST is too easy.** Convolutional nets can achieve 99.7% on MNIST. Classic machine learning algorithms can also achieve 97% easily. Check out [our side-by-side benchmark for Fashion-MNIST vs. MNIST](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/), and read \"[Most pairs of MNIST digits can be distinguished pretty well by just one pixel](https://gist.github.com/dgrtwo/aaef94ecc6a60cd50322c0054cc04478).\"\n- **MNIST is overused.** In [this April 2017 Twitter thread](https://twitter.com/goodfellow_ian/status/852591106655043584), Google Brain research scientist and deep learning expert Ian Goodfellow calls for people to move away from MNIST.\n- **MNIST can not represent modern CV tasks**, as noted in [this April 2017 Twitter thread](https://twitter.com/fchollet/status/852594987527045120), deep learning expert/Keras author François Chollet.\n\n## Get the Data\n\n[Many ML libraries](#loading-data-with-other-machine-learning-libraries) already include Fashion-MNIST data/API, give it a try!\n\nYou can use direct links to download the dataset. The data is stored in the **same** format as the original [MNIST data](http://yann.lecun.com/exdb/mnist/).\n\n| Name  | Content | Examples | Size | Link | MD5 Checksum|\n| --- | --- |--- | --- |--- |--- |\n| `train-images-idx3-ubyte.gz`  | training set images  | 60,000|26 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz)|`8d4fb7e6c68d591d4c3dfef9ec88bf0d`|\n| `train-labels-idx1-ubyte.gz`  | training set labels  |60,000|29 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz)|`25c81989df183df01b3e8a0aad5dffbe`|\n| `t10k-images-idx3-ubyte.gz`  | test set images  | 10,000|4.3 MBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz)|`bef4ecab320f06d8554ea6380940ec79`|\n| `t10k-labels-idx1-ubyte.gz`  | test set labels  | 10,000| 5.1 KBytes | [Download](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz)|`bb300cfdad3c16e7a12a480ee83cd310`|\n\nAlternatively, you can clone this GitHub repository; the dataset appears under `data/fashion`. This repo also contains some scripts for benchmark and visualization.\n   \n```bash\ngit clone git@github.com:zalandoresearch/fashion-mnist.git\n```\n\n### Labels\nEach training and test example is assigned to one of the following labels:\n\n| Label | Description |\n| --- | --- |\n| 0 | T-shirt/top |\n| 1 | Trouser |\n| 2 | Pullover |\n| 3 | Dress |\n| 4 | Coat |\n| 5 | Sandal |\n| 6 | Shirt |\n| 7 | Sneaker |\n| 8 | Bag |\n| 9 | Ankle boot |\n\n## Usage\n\n### Loading data with Python (requires [NumPy](http://www.numpy.org/))\n\nUse `utils/mnist_reader` in this repo:\n```python\nimport mnist_reader\nX_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\nX_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n```\n\n### Loading data with Tensorflow\nMake sure you have [downloaded the data](#get-the-data) and placed it in `data/fashion`. Otherwise, *Tensorflow will download and use the original MNIST.*\n\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('data/fashion')\n\ndata.train.next_batch(BATCH_SIZE)\n```\n\nNote, Tensorflow supports passing in a source url to the `read_data_sets`. You may use: \n```python\ndata = input_data.read_data_sets('data/fashion', source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n```\n\nAlso, an official Tensorflow tutorial of using `tf.keras`, a high-level API to train Fashion-MNIST [can be found here](https://www.tensorflow.org/tutorials/keras/classification).\n\n### Loading data with other machine learning libraries \nTo date, the following libraries have included `Fashion-MNIST` as a built-in dataset. Therefore, you don't need to download `Fashion-MNIST` by yourself. Just follow their API and you are ready to go.\n\n- [Activeloop Hub](https://docs.activeloop.ai/datasets/fashion-mnist-dataset)\n- [Apache MXNet Gluon](https://mxnet.apache.org/api/python/docs/api/gluon/data/vision/datasets/index.html#mxnet.gluon.data.vision.datasets.FashionMNIST)\n- [TensorFlow.js](https://github.com/tensorflow/tfjs-examples/blob/master/fashion-mnist-vae/data.js)\n- [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist)\n- [Pytorch](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)\n- [Keras](https://keras.io/api/datasets/fashion_mnist/)\n- [Edward](http://edwardlib.org/api/observations/fashion_mnist)\n- [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist)\n- [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/fashion_mnist)\n- [Torch](https://github.com/mingloo/fashion-mnist)\n- [JuliaML](https://juliaml.github.io/MLDatasets.jl/latest/datasets/FashionMNIST/)\n- [Chainer](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.get_fashion_mnist.html)\n- [HuggingFace Datasets](https://huggingface.co/datasets/fashion_mnist)\n \nYou are welcome to make pull requests to other open-source machine learning packages, improving their support to `Fashion-MNIST` dataset.\n\n### Loading data with other languages\n\nAs one of the Machine Learning community's most popular datasets, MNIST has inspired people to implement loaders in many different languages. You can use these loaders with the `Fashion-MNIST` dataset as well. (Note: may require decompressing first.) To date, we haven't yet tested all of these loaders with Fashion-MNIST.\n\n- [C](https://stackoverflow.com/a/10409376)\n- [C++](https://github.com/wichtounet/mnist)\n- [Java](https://stackoverflow.com/a/8301949)\n- [Python](https://pypi.python.org/pypi/python-mnist) and [this](https://pypi.python.org/pypi/mnist)\n- [Scala](http://mxnet.io/tutorials/scala/mnist.html)\n- [Go](https://github.com/schuyler/neural-go/blob/master/mnist/mnist.go)\n- [C#](https://jamesmccaffrey.wordpress.com/2013/11/23/reading-the-mnist-data-set-with-c/)\n- [NodeJS](https://github.com/ApelSYN/mnist_dl) and [this](https://github.com/cazala/mnist)\n- [Swift](https://github.com/simonlee2/MNISTKit)\n- [R](https://gist.github.com/brendano/39760) and [this](https://github.com/maddin79/darch)\n- [Matlab](http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset)\n- [Ruby](https://github.com/gbuesing/mnist-ruby-test/blob/master/train/mnist_loader.rb)\n- [Rust](https://github.com/AtheMathmo/vision-rs/blob/master/src/fashion_mnist.rs)\n\n\n## Benchmark\nWe built an automatic benchmarking system based on `scikit-learn` that covers 129 classifiers (but no deep learning) with different parameters. [Find the results here](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/).\n\n<img src=\"doc/img/benchmark.gif\" width=\"100%\">\n\nYou can reproduce the results by running `benchmark/runner.py`. We recommend building and deploying [this Dockerfile](Dockerfile). \n\nYou are welcome to submit your benchmark; simply create a new issue and we'll list your results here. Before doing that, please make sure it does not already appear [in this list](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/). Visit our [contributor guidelines](https://github.com/zalandoresearch/fashion-mnist#contributing) for additional details.\n\nThe table below collects the submitted benchmarks. Note that **we haven't yet tested these results**. You are welcome to validate the results using the code provided by the submitter. Test accuracy may differ due to the number of epoch, batch size, etc. To correct this table, please create a new issue.\n\n| Classifier | Preprocessing | Fashion test accuracy | MNIST test accuracy | Submitter| Code |\n| --- | --- | --- | --- | --- |--- |\n|2 Conv+pooling | None | 0.876 | - | [Kashif Rasul](https://twitter.com/krasul) | [:link:](https://gist.github.com/kashif/76792939dd6f473b7404474989cb62a8) |\n|2 Conv+pooling | None | 0.916| - |[Tensorflow's doc](https://www.tensorflow.org/tutorials/layers) | [:link:](/benchmark/convnet.py)|\n|2 Conv+pooling+ELU activation (PyTorch)| None| 0.903| - | [@AbhirajHinge](https://github.com/AbhirajHinge) | [:link:](https://github.com/AbhirajHinge/CNN-with-Fashion-MNIST-dataset)|\n|2 Conv | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.919 |0.971 | [Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|2 Conv <100K parameters | None | 0.925 | 0.992 |[@hardmaru](https://twitter.com/hardmaru) | [:link:](https://github.com/hardmaru/pytorch_notebooks/blob/master/pytorch_tiny_custom_mnist_adam.ipynb)|\n|2 Conv ~113K parameters | Normalization | 0.922| 0.993 |[Abel G.](https://github.com/abelusha) | [:link:](https://github.com/abelusha/MNIST-Fashion-CNN/blob/master/Fashon_MNIST_CNN_using_Keras_10_Runs.ipynb)|\n|2 Conv+3 FC ~1.8M parameters| Normalization | 0.932 | 0.994 | [@Xfan1025](https://github.com/Xfan1025) |[:link:](https://github.com/Xfan1025/Fashion-MNIST/blob/master/fashion-mnist.ipynb) |\n|2 Conv+3 FC ~500K parameters | Augmentation, batch normalization | 0.934 | 0.994 | [@cmasch](https://github.com/cmasch) |[:link:](https://github.com/cmasch/zalando-fashion-mnist) |\n|2 Conv+pooling+BN | None | 0.934 | - | [@khanguyen1207](https://github.com/khanguyen1207) | [:link:](https://github.com/khanguyen1207/My-Machine-Learning-Corner/blob/master/Zalando%20MNIST/fashion.ipynb)|\n|2 Conv+2 FC| Random Horizontal Flips|  0.939| -| [@ashmeet13](https://github.com/ashmeet13)|[:link:](https://github.com/ashmeet13/FashionMNIST-CNN)|\n|3 Conv+2 FC | None | 0.907 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|3 Conv+pooling+BN | None | 0.903 | 0.994 | [@meghanabhange](https://github.com/meghanabhange) | [:link:](https://github.com/meghanabhange/FashionMNIST-3-Layer-CNN) |\n|3 Conv+pooling+2 FC+dropout | None | 0.926 | - | [@Umberto Griffo](https://github.com/umbertogriffo) | [:link:](https://github.com/umbertogriffo/Fashion-mnist-cnn-keras)|\n|3 Conv+BN+pooling|None|0.921|0.992|[@gchhablani](https://github.com/gchhablani)|[:link:](https://github.com/gchhablani/CNN-with-FashionMNIST)| \n|5 Conv+BN+pooling|None|0.931|-|[@Noumanmufc1](https://github.com/Noumanmufc1)|[:link:](https://gist.github.com/Noumanmufc1/60f00e434f0ce42b6f4826029737490a)| \n|CNN with optional shortcuts, dense-like connectivity| standardization+augmentation+random erasing | 0.947 |-| [@kennivich](https://github.com/Dezhic) | [:link:](https://github.com/Dezhic/fashion-classifier)|\n|GRU+SVM | None| 0.888 | 0.965 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/828fbda0e466dacb1fad66549e0e3022e1c7263a/gru_svm_zalando.py)|\n|GRU+SVM with dropout | None| 0.897 | 0.988 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/58dbe7cd8b0d83e4386cd6896766113b1a9af096/gru_svm_zalando_dropout.py)|\n|WRN40-4 8.9M params | standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips)| 0.967 | - |[@ajbrock](https://github.com/ajbrock) | [:link:](https://github.com/xternalz/WideResNet-pytorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|DenseNet-BC 768K params| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.954 | - |[@ajbrock](https://github.com/ajbrock)  | [:link:](https://github.com/bamos/densenet.pytorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|MobileNet | augmentation (horizontal flips)| 0.950|- | [@苏剑林](https://github.com/bojone)| [:link:](http://kexue.fm/archives/4556/)|\n|ResNet18 | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.949 | 0.979 |[Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|GoogleNet with cross-entropy loss | None | 0.937 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|AlexNet with Triplet loss| None | 0.899 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|SqueezeNet with cyclical learning rate 200 epochs| None| 0.900| - | [@snakers4](https://github.com/snakers4) | [:link:](https://github.com/zalandoresearch/fashion-mnist/files/1263340/squeeze_net_mnist.zip)|\n|Dual path network with wide resnet 28-10|standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) |0.957|-|[@Queequeg](https://github.com/Queequeg92)|[:link:](https://github.com/Queequeg92/DualPathNet)|\n|MLP 256-128-100| None | 0.8833| - | [@heitorrapela](https://github.com/heitorrapela)| [:link:](https://github.com/heitorrapela/fashion-mnist-mlp)| \n|VGG16 26M parameters | None | 0.935| - | [@QuantumLiu](https://github.com/QuantumLiu)|[:link:](https://github.com/QuantumLiu/fashion-mnist-demo-by-Keras) [:link:](https://zhuanlan.zhihu.com/p/28968219)|\n|WRN-28-10| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.959 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|WRN-28-10 + Random Erasing| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.963 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|Human Performance| Crowd-sourced evaluation of human (with no fashion expertise) performance. 1000 randomly sampled test images, 3 labels per image, majority labelling. | 0.835 | - | Leo  | - |\n|Capsule Network 8M parameters| Normalization and shift at most 2 pixel and horizontal flip | 0.936 | - | [@XifengGuo](https://github.com/XifengGuo)  | [:link:](https://github.com/XifengGuo/CapsNet-Fashion-MNIST)|\n|HOG+SVM| HOG | 0.926 | - | [@subalde](https://github.com/subalde) | [:link:](https://github.com/subalde/fashion-mnist)|\n|XgBoost| scaling the pixel values to mean=0.0 and var=1.0| 0.898| 0.958| [@anktplwl91](https://github.com/anktplwl91)| [:link:](https://github.com/anktplwl91/fashion_mnist.git)|\n|DENSER| - | 0.953| 0.997| [@fillassuncao](https://github.com/fillassuncao)| [:link:](https://github.com/fillassuncao/denser-models) [:link:](https://arxiv.org/pdf/1801.01563.pdf)|\n|Dyra-Net| Rescale to unit interval | 0.906| -| [@Dirk Schäfer](https://github.com/disc5)| [:link:](https://github.com/disc5/dyra-net) [:link:](https://dl.acm.org/citation.cfm?id=3204176.3204200)|\n|Google AutoML|24 compute hours (higher quality)| 0.939|-| [@Sebastian Heinz](https://github.com/sebastianheinz) |[:link:](https://www.statworx.com/de/blog/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist/)|\n|Fastai| Resnet50+Fine-tuning+Softmax on last layer's activations| 0.9312| - | [@Sayak](https://github.com/sayakpaul) | [:link:](https://github.com/sayakpaul/Experiments-on-Fashion-MNIST/)|\n\n\n### Other Explorations of Fashion-MNIST\n\n#### [Fashion-MNIST: Year in Review](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n#### [Fashion-MNIST on Google Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=fashion-mnist&btnG=&oq=fas) \n\n#### Generative adversarial networks (GANs) \n- [Tensorflow implementation of various GANs and VAEs.](https://github.com/hwalsuklee/tensorflow-generative-model-collections) (**Recommend to read!** Note how various GANs generate different results on Fashion-MNIST, which can not be easily observed on the original MNIST.)\n- [Make a ghost wardrobe using DCGAN](https://twitter.com/spaceLenny/status/901488938023403520)\n- [fashion-mnist的gan玩具](http://kexue.fm/archives/4540/)\n- [CGAN output after 5000 steps](https://github.com/a7b23/Conditional-GAN-using-tensorflow-slim)\n- [GAN Playground - Explore Generative Adversarial Nets in your Browser](https://reiinakano.github.io/gan-playground/)\n\n#### Clustering\n- [Xifeng Guo's implementation](https://github.com/XifengGuo/DEC-keras) of [Unsupervised Deep Embedding for Clustering Analysis (DEC)](http://proceedings.mlr.press/v48/xieb16.pdf)\n- [Leland McInnes's](https://github.com/lmcinnes) [Uniform Manifold Approximation and Projection (UMAP)](https://github.com/lmcinnes/umap)\n\n#### Video Tutorial\n*Machine Learning Meets Fashion* by Yufeng G @ Google Cloud\n\n[![Machine Learning Meets Fashion](doc/img/ae143b2d.png)](https://youtu.be/RJudqel8DVA)\n\n*Introduction to Kaggle Kernels* by [Yufeng G](https://twitter.com/yufengg) @ Google Cloud\n\n[![Introduction to Kaggle Kernels](doc/img/853c717e.png)](https://youtu.be/FloMHMOU5Bs)\n\n*动手学深度学习* by Mu Li @ Amazon AI\n\n[![MXNet/Gluon中文频道](doc/img/e9514ab1.png)](https://youtu.be/kGktiYF5upk)\n\nApache MXNet으로 배워보는 딥러닝(Deep Learning) - 김무현 (AWS 솔루션즈아키텍트)\n\n[![Apache MXNet으로 배워보는 딥러닝(Deep Learning)](doc/img/dd83f448.png)](https://youtu.be/H66GDuLsGl4)\n\n\n\n## Visualization\n\n### t-SNE on Fashion-MNIST (left) and original MNIST (right) \n<img src=\"doc/img/34d72c08.png\" width=\"50%\"><img src=\"doc/img/01e0c4be.png\" width=\"50%\">\n\n### PCA on Fashion-MNIST (left) and original MNIST (right) \n<img src=\"doc/img/f04ba662.png\" width=\"50%\"><img src=\"doc/img/4433f0e1.png\" width=\"50%\">\n\n### [UMAP](https://github.com/lmcinnes/umap) on Fashion-MNIST (left) and original MNIST (right) \n<img src=\"doc/img/umap_example_fashion_mnist1.png\" width=\"50%\"><img src=\"doc/img/umap_example_mnist1.png\" width=\"50%\">\n\n### [PyMDE](https://github.com/cvxgrp/pymde) on Fashion-MNIST (left) and original MNIST (right) \n<img src=\"doc/img/pymde_example_fashion_mnist.png\" width=\"50%\"><img src=\"doc/img/pymde_example_mnist.png\" width=\"50%\">\n\n\n## Contributing\n\nThanks for your interest in contributing! There are many ways to get involved; start with our [contributor guidelines](/CONTRIBUTING.md) and then check these [open issues](https://github.com/zalandoresearch/fashion-mnist/issues) for specific tasks.\n\n## Contact\nTo discuss the dataset, please use [![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link).\n\n## Citing Fashion-MNIST\nIf you use Fashion-MNIST in a scientific publication, we would appreciate references to the following paper:\n\n**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](http://arxiv.org/abs/1708.07747)**\n\nBiblatex entry:\n```latex\n@online{xiao2017/online,\n  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},\n  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},\n  date         = {2017-08-28},\n  year         = {2017},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1708.07747},\n}\n```\n\n[Who is citing Fashion-MNIST?](https://scholar.google.com/scholar?scisbd=2&q=%22fashion-mnist%22&hl=en&as_sdt=0,5) \n\n## License\n\nThe MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.zh-CN.md",
          "type": "blob",
          "size": 22.994140625,
          "content": "# Fashion-MNIST\n\n[![GitHub stars](https://img.shields.io/github/stars/zalandoresearch/fashion-mnist.svg?style=flat&label=Star)](https://github.com/zalandoresearch/fashion-mnist/)\n[![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link)\n[![Readme-EN](https://img.shields.io/badge/README-English-green.svg)](README.md)\n[![Readme-JA](https://img.shields.io/badge/README-日本語-green.svg)](README.ja.md)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Year-In-Review](https://img.shields.io/badge/%F0%9F%8E%82-%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93-orange.svg)](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n\n<details><summary>目录</summary><p>\n\n* [为什么要做这个数据集？](#为什么要做这个数据集？)\n* [获取数据](#获取数据)\n* [如何载入数据？](#如何载入数据？)\n* [基准测试](#基准测试)\n* [数据可视化](#数据可视化)\n* [参与贡献](#参与贡献)\n* [联系](#联系)\n* [在论文中引用Fashion-MNIST](#在论文中引用Fashion-MNIST)\n* [License](#license)\n\n</p></details><p></p>\n\n\n`Fashion-MNIST`是一个替代[MNIST手写数字集](http://yann.lecun.com/exdb/mnist/)的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的[研究部门](https://research.zalando.com/)提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28x28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且**不需要**改动任何的代码。\n\n这个数据集的样子大致如下（每个类别占三行）：\n\n![](doc/img/fashion-mnist-sprite.png)\n\n<img src=\"doc/img/embedding.gif\" width=\"100%\">\n\n## 为什么要做这个数据集？\n\n[经典的MNIST数据集](http://yann.lecun.com/exdb/mnist/)包含了大量的手写数字。十几年来，来自机器学习、机器视觉、人工智能、深度学习领域的研究员们把这个数据集作为衡量算法的基准之一。你会在很多的会议，期刊的论文中发现这个数据集的身影。实际上，MNIST数据集已经成为算法作者的必测的数据集之一。有人曾调侃道：*\"如果一个算法在MNIST不work, 那么它就根本没法用；而如果它在MNIST上work, 它在其他数据上也可能不work！\"*\n \n\n`Fashion-MNIST`的目的是要成为MNIST数据集的一个直接替代品。作为算法作者，你不需要修改任何的代码，就可以直接使用这个数据集。`Fashion-MNIST`的图片大小，训练、测试样本数及类别数与经典MNIST**完全相同**。\n\n### 写给专业的机器学习研究者\n\n我们是认真的。取代MNIST数据集的原因由如下几个：\n\n- **MNIST太简单了。** 很多深度学习算法在测试集上的准确率已经达到99.6%！不妨看看[我们基于scikit-learn上对经典机器学习算法的评测](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/) 和这段代码： [\"Most pairs of MNIST digits can be distinguished pretty well by just one pixel\"（翻译：大多数MNIST只需要一个像素就可以区分开！）](https://gist.github.com/dgrtwo/aaef94ecc6a60cd50322c0054cc04478)\n- **MNIST被用烂了。** 参考：[\"Ian Goodfellow wants people to move away from mnist\"（翻译：Ian Goodfellow希望人们不要再用MNIST了。）](https://twitter.com/goodfellow_ian/status/852591106655043584)\n- **MNIST数字识别的任务不代表现代机器学习。** 参考：[\"François Cholle: Ideas on MNIST do not transfer to real CV\" （翻译：在MNIST上看似有效的想法没法迁移到真正的机器视觉问题上。）](https://twitter.com/fchollet/status/852592598128615424)\n\n## 获取数据\n\n[很多的机器学习库](#使用其它机器学习库)已经内置了Fashion-MNIST数据或接口，方便你直接使用。\n\n\n你可以使用以下链接下载这个数据集。`Fashion-MNIST`的数据集的存储方式和命名与[经典MNIST数据集](http://yann.lecun.com/exdb/mnist/)完全一致。\n\n| 名称  | 描述 | 样本数量 | 文件大小 | 链接 | MD5校验和|\n| --- | --- |--- | --- |--- |--- |\n| `train-images-idx3-ubyte.gz`  | 训练集的图像  | 60,000|26 MBytes | [下载](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz)|`8d4fb7e6c68d591d4c3dfef9ec88bf0d`|\n| `train-labels-idx1-ubyte.gz`  | 训练集的类别标签  |60,000|29 KBytes | [下载](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz)|`25c81989df183df01b3e8a0aad5dffbe`|\n| `t10k-images-idx3-ubyte.gz`  | 测试集的图像  | 10,000|4.3 MBytes | [下载](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz)|`bef4ecab320f06d8554ea6380940ec79`|\n| `t10k-labels-idx1-ubyte.gz`  | 测试集的类别标签  | 10,000| 5.1 KBytes | [下载](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz)|`bb300cfdad3c16e7a12a480ee83cd310`|\n\n或者，你可以直接克隆这个代码库。数据集就放在`data/fashion`下。这个代码库还包含了一些用于评测和可视化的脚本。\n   \n```bash\ngit clone git@github.com:zalandoresearch/fashion-mnist.git\n```\n\n### 类别标注\n每个训练和测试样本都按照以下类别进行了标注：\n\n| 标注编号 | 描述 |\n| --- | --- |\n| 0 | T-shirt/top（T恤）|\n| 1 | Trouser（裤子）|\n| 2 | Pullover（套衫）|\n| 3 | Dress（裙子）|\n| 4 | Coat（外套）|\n| 5 | Sandal（凉鞋）|\n| 6 | Shirt（汗衫）|\n| 7 | Sneaker（运动鞋）|\n| 8 | Bag（包）|\n| 9 | Ankle boot（踝靴）|\n\n## 如何载入数据？\n\n### 使用Python (需要安装`numpy`)\n- 你可以直接使用`utils/mnist_reader`：\n```python\nimport mnist_reader\nX_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\nX_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n```\n\n### 使用Tensorflow\n请确保你已经[下载了我们的数据集](#获取数据)并把它放到了`data/fashion`下。不然， *Tensorflow会自动下载并使用原始的MNIST。*\n\n```python\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('data/fashion')\n\ndata.train.next_batch(BATCH_SIZE)\n```\n\n注意，Tensorflow (master ver.) 支持向`read_data_sets`函数传入MNIST数据集的地址。你可以使用： \n```python\ndata = input_data.read_data_sets('data/fashion', source_url='http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/')\n```\n\nTensorflow的官网也提供了一份使用高级API`tf.keras`训练Fashion-MNIST的详细教程，[你可以在这里查看它](https://www.tensorflow.org/tutorials/keras/classification)。\n\n### 使用其它机器学习库\n截止今日，以下软件库中已内置了对`Fashion-MNIST`的支持。你只需要按照他们的文档载入`Fashion-MNIST`即可使用此数据集。\n- [Apache MXNet Gluon](https://mxnet.apache.org/api/python/docs/api/gluon/data/vision/datasets/index.html#mxnet.gluon.data.vision.datasets.FashionMNIST)\n- [TensorFlow.js](https://github.com/tensorflow/tfjs-examples/blob/master/fashion-mnist-vae/data.js)\n- [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist)\n- [Pytorch](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)\n- [Keras](https://keras.io/api/datasets/fashion_mnist/)\n- [Edward](http://edwardlib.org/api/observations/fashion_mnist)\n- [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist)\n- [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/fashion_mnist)\n- [Torch](https://github.com/mingloo/fashion-mnist)\n- [JuliaML](https://juliaml.github.io/MLDatasets.jl/latest/datasets/FashionMNIST/)\n- [Chainer](https://docs.chainer.org/en/stable/reference/generated/chainer.datasets.get_fashion_mnist.html)\n- [HuggingFace Datasets](https://huggingface.co/datasets/fashion_mnist)\n- \n欢迎你同我们一起，为各个机器学习库增加对`Fashion-MNIST`的支持。\n\n\n### 使用其它的语言\n\n作为机器学习领域里最常使用的数据集，人们用各种语言为MNIST开发了很多载入工具。有一些方法需要先解压数据文件。注意，我们并没有测试过所有的载入方法。\n\n- [C](https://stackoverflow.com/a/10409376)\n- [C++](https://github.com/wichtounet/mnist)\n- [Java](https://stackoverflow.com/a/8301949)\n- [Python](https://pypi.python.org/pypi/python-mnist) and [this](https://pypi.python.org/pypi/mnist)\n- [Scala](http://mxnet.io/tutorials/scala/mnist.html)\n- [Go](https://github.com/schuyler/neural-go/blob/master/mnist/mnist.go)\n- [C#](https://jamesmccaffrey.wordpress.com/2013/11/23/reading-the-mnist-data-set-with-c/)\n- [NodeJS](https://github.com/ApelSYN/mnist_dl)和[这里](https://github.com/cazala/mnist)\n- [Swift](https://github.com/simonlee2/MNISTKit)\n- [R](https://gist.github.com/brendano/39760)和[这里](https://github.com/maddin79/darch)\n- [Matlab](http://ufldl.stanford.edu/wiki/index.php/Using_the_MNIST_Dataset)\n- [Ruby](https://github.com/gbuesing/mnist-ruby-test/blob/master/train/mnist_loader.rb)\n- [Rust](https://github.com/AtheMathmo/vision-rs/blob/master/src/fashion_mnist.rs)\n\n\n## 基准测试\n我们使用`scikit-learn`做了一套自动评测系统。它涵盖了除深度学习之外的129种经典机器学习模型（包含不同的参数）。[你可以在这里以互动的方式查看结果。](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/)\n\n<img src=\"doc/img/benchmark.gif\" width=\"100%\">\n\n你可以运行`benchmark/runner.py`对结果进行重现。而我们更推荐的方法是使用Dockerfile打包部署后以Container的方式运行。\n\n我们欢迎你提交自己的模型评测。请使用Github新建一个Issue。不妨先看看[如何贡献](https://github.com/zalandoresearch/fashion-mnist#参与贡献)。如果你提交自己的模型，请先确保这个模型没有[在这个列表中](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/)被测试过。\n\n下面这个表格总结了提交的一些测试结果。注意，**我们并没有对这些结果的准确性进行验证**。你可以通过提交者附带的代码尝试对结果进行重现。当然，测试准确率最终取决于Epoch的多少，Batch的大小等因素。如果你发现了下表中的不妥，欢迎提交新的Issue。\n\n| 算法  | 预处理 | Fashion测试集准确率| 经典MNIST测试集准确率| 提交者| 代码|\n| --- | --- | --- | --- | --- |--- |\n|2 Conv+pooling | None | 0.876 | - | [Kashif Rasul](https://twitter.com/krasul) | [:link:](https://gist.github.com/kashif/76792939dd6f473b7404474989cb62a8) |\n|2 Conv+pooling | None | 0.916| - |[Tensorflow's doc](https://www.tensorflow.org/tutorials/layers) | [:link:](/benchmark/convnet.py)|\n|2 Conv+pooling+ELU activation (PyTorch)| None| 0.903| - | [@AbhirajHinge](https://github.com/AbhirajHinge) | [:link:](https://github.com/AbhirajHinge/CNN-with-Fashion-MNIST-dataset)|\n|2 Conv | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.919 |0.971 | [Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|2 Conv <100K parameters | None | 0.925 | 0.992 |[@hardmaru](https://twitter.com/hardmaru) | [:link:](https://github.com/hardmaru/pytorch_notebooks/blob/master/pytorch_tiny_custom_mnist_adam.ipynb)|\n|2 Conv ~113K parameters | Normalization | 0.922| 0.993 |[Abel G.](https://github.com/abelusha) | [:link:](https://github.com/abelusha/MNIST-Fashion-CNN/blob/master/Fashon_MNIST_CNN_using_Keras_10_Runs.ipynb)|\n|2 Conv+3 FC ~1.8M parameters| Normalization | 0.932 | 0.994 | [@Xfan1025](https://github.com/Xfan1025) |[:link:](https://github.com/Xfan1025/Fashion-MNIST/blob/master/fashion-mnist.ipynb) |\n|2 Conv+3 FC ~500K parameters | Augmentation, batch normalization | 0.934 | 0.994 | [@cmasch](https://github.com/cmasch) |[:link:](https://github.com/cmasch/zalando-fashion-mnist) |\n|2 Conv+pooling+BN | None | 0.934 | - | [@khanguyen1207](https://github.com/khanguyen1207) | [:link:](https://github.com/khanguyen1207/My-Machine-Learning-Corner/blob/master/Zalando%20MNIST/fashion.ipynb)|\n|2 Conv+2 FC| Random Horizontal Flips|  0.939| -| [@ashmeet13](https://github.com/ashmeet13)|[:link:](https://github.com/ashmeet13/FashionMNIST-CNN)|\n|3 Conv+2 FC | None | 0.907 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|3 Conv+pooling+BN | None | 0.903 | 0.994 | [@meghanabhange](https://github.com/meghanabhange) | [:link:](https://github.com/meghanabhange/FashionMNIST-3-Layer-CNN) |\n|3 Conv+pooling+2 FC+dropout | None | 0.926 | - | [@Umberto Griffo](https://github.com/umbertogriffo) | [:link:](https://github.com/umbertogriffo/Fashion-mnist-cnn-keras)|\n|3 Conv+BN+pooling|None|0.921|0.992|[@gchhablani](https://github.com/gchhablani)|[:link:](https://github.com/gchhablani/CNN-with-FashionMNIST)| \n|5 Conv+BN+pooling|None|0.931|-|[@Noumanmufc1](https://github.com/Noumanmufc1)|[:link:](https://gist.github.com/Noumanmufc1/60f00e434f0ce42b6f4826029737490a)| \n|CNN with optional shortcuts, dense-like connectivity| standardization+augmentation+random erasing | 0.947 |-| [@kennivich](https://github.com/Dezhic) | [:link:](https://github.com/Dezhic/fashion-classifier)|\n|GRU+SVM | None| 0.888 | 0.965 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/828fbda0e466dacb1fad66549e0e3022e1c7263a/gru_svm_zalando.py)|\n|GRU+SVM with dropout | None| 0.897 | 0.988 | [@AFAgarap](https://github.com/AFAgarap) | [:link:](https://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/58dbe7cd8b0d83e4386cd6896766113b1a9af096/gru_svm_zalando_dropout.py)|\n|WRN40-4 8.9M params | standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips)| 0.967 | - |[@ajbrock](https://github.com/ajbrock) | [:link:](https://github.com/xternalz/WideResNet-pythttps://gist.githubusercontent.com/AFAgarap/92c1c4a5dd771999b0201ec0e7edfee0/raw/58dbe7cd8b0d83e4386cd6896766113b1a9af096/gru_svm_zalando_dropout.pyorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|DenseNet-BC 768K params| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.954 | - |[@ajbrock](https://github.com/ajbrock)  | [:link:](https://github.com/bamos/densenet.pytorch)  [:link:](https://github.com/ajbrock/FreezeOut) |\n|MobileNet | augmentation (horizontal flips)| 0.950|- | [@苏剑林](https://github.com/bojone)| [:link:](http://kexue.fm/archives/4556/)|\n|ResNet18 | Normalization, random horizontal flip, random vertical flip, random translation, random rotation. | 0.949 | 0.979 |[Kyriakos Efthymiadis](https://github.com/kefth)| [:link:](https://github.com/kefth/fashion-mnist)|\n|GoogleNet with cross-entropy loss | None | 0.937 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|AlexNet with Triplet loss| None | 0.899 | - | [@Cenk Bircanoğlu](https://github.com/cenkbircanoglu) | [:link:](https://github.com/cenkbircanoglu/openface/tree/master/fashion_mnist)|\n|SqueezeNet with cyclical learning rate 200 epochs| None| 0.900| - | [@snakers4](https://github.com/snakers4) | [:link:](https://github.com/zalandoresearch/fashion-mnist/files/1263340/squeeze_net_mnist.zip)|\n|Dual path network with wide resnet 28-10|standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) |0.957|-|[@Queequeg](https://github.com/Queequeg92)|[:link:](https://github.com/Queequeg92/DualPathNet)|\n|MLP 256-128-100| None | 0.8833| - | [@heitorrapela](https://github.com/heitorrapela)| [:link:](https://github.com/heitorrapela/fashion-mnist-mlp)|\n|VGG16 26M parameters | None | 0.935| - | [@QuantumLiu](https://github.com/QuantumLiu)|[:link:](https://github.com/QuantumLiu/fashion-mnist-demo-by-Keras) [:link:](https://zhuanlan.zhihu.com/p/28968219)|\n|WRN-28-10| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.959 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|WRN-28-10 + Random Erasing| standard preprocessing (mean/std subtraction/division) and augmentation (random crops/horizontal flips) | 0.963 | -| [@zhunzhong07](https://github.com/zhunzhong07)|[:link:](https://github.com/zhunzhong07/Random-Erasing)|\n|Human Performance| Crowd-sourced evaluation of human (with no fashion expertise) performance. 1000 randomly sampled test images, 3 labels per image, majority labelling. | 0.835 | - | Leo  | - \n|Capsule Network 8M parameters| Normalization and shift at most 2 pixel and horizontal flip | 0.936 | - | [@XifengGuo](https://github.com/XifengGuo)  | [:link:](https://github.com/XifengGuo/CapsNet-Fashion-MNIST)|\n|HOG+SVM| HOG | 0.926 | - | [@subalde](https://github.com/subalde) | [:link:](https://github.com/subalde/fashion-mnist)|\n|XgBoost| scaling the pixel values to mean=0.0 and var=1.0| 0.898| 0.958| [@anktplwl91](https://github.com/anktplwl91)| [:link:](https://github.com/anktplwl91/fashion_mnist.git)|\n|DENSER| - | 0.953| 0.997| [@fillassuncao](https://github.com/fillassuncao)| [:link:](https://github.com/fillassuncao/denser-models) [:link:](https://arxiv.org/pdf/1801.01563.pdf)|\n|Dyra-Net| Rescale to unit interval | 0.906| -| [@Dirk Schäfer](https://github.com/disc5)| [:link:](https://github.com/disc5/dyra-net) [:link:](https://dl.acm.org/citation.cfm?id=3204176.3204200)|\n|Google AutoML|24 compute hours (higher quality)| 0.939|-| [@Sebastian Heinz](https://github.com/sebastianheinz) |[:link:](https://www.statworx.com/de/blog/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist/)|\n|Fastai| Resnet50+Fine-tuning+Softmax on last layer's activations| 0.9312| - | [@Sayak](https://github.com/sayakpaul) | [:link:](https://github.com/sayakpaul/Experiments-on-Fashion-MNIST/)|\n### 更多在Fashion-MNIST上的探索和尝试\n\n#### [Fashion-MNIST: 年度总结](https://hanxiao.github.io/2018/09/28/Fashion-MNIST-Year-In-Review/)\n#### [在Google Scholar中查看引用Fashion-MNIST的论文](https://scholar.google.de/scholar?hl=en&as_sdt=0%2C5&q=fashion-mnist&btnG=&oq=fas) \n\n#### 生成对抗网络 (GANs) \n- [Tensorflow implementation of various GANs and VAEs.](https://github.com/hwalsuklee/tensorflow-generative-model-collections) (**推荐阅读！** 注意不同GANs的算法在Fashion-MNIST上生成的样本明显不同，而这点在经典的MNIST数据集上是观察不到的。)\n- [Make a ghost wardrobe using DCGAN](https://twitter.com/spaceLenny/status/901488938023403520)\n- [fashion-mnist的gan玩具](http://kexue.fm/archives/4540/)\n- [CGAN output after 5000 steps](https://github.com/a7b23/Conditional-GAN-using-tensorflow-slim)\n- [GAN Playground - Explore Generative Adversarial Nets in your Browser](https://reiinakano.github.io/gan-playground/)\n\n#### 聚类\n- [Xifeng Guo's implementation](https://github.com/XifengGuo/DEC-keras) of [Unsupervised Deep Embedding for Clustering Analysis (DEC)](http://proceedings.mlr.press/v48/xieb16.pdf)\n- [Leland McInnes's](https://github.com/lmcinnes) [Uniform Manifold Approximation and Projection (UMAP)](https://github.com/lmcinnes/umap)\n\n\n#### 视频教程\n*Machine Learning Meets Fashion* by [Yufeng G](https://twitter.com/yufengg) @ Google Cloud\n\n[![Machine Learning Meets Fashion](doc/img/ae143b2d.png)](https://youtu.be/RJudqel8DVA)\n\n*Introduction to Kaggle Kernels* by [Yufeng G](https://twitter.com/yufengg) @ Google Cloud\n\n[![Introduction to Kaggle Kernels](doc/img/853c717e.png)](https://youtu.be/FloMHMOU5Bs)\n\n*动手学深度学习* by Mu Li @ Amazon AI\n\n[![MXNet/Gluon中文频道](doc/img/e9514ab1.png)](https://youtu.be/kGktiYF5upk)\n\nApache MXNet으로 배워보는 딥러닝(Deep Learning) - 김무현 (AWS 솔루션즈아키텍트)\n\n[![Apache MXNet으로 배워보는 딥러닝(Deep Learning)](doc/img/dd83f448.png)](https://youtu.be/H66GDuLsGl4)\n\n\n\n## 数据可视化\n\n### t-SNE在Fashion-MNIST(左侧)和经典MNIST上的可视化(右侧) \n<img src=\"doc/img/34d72c08.png\" width=\"50%\"><img src=\"doc/img/01e0c4be.png\" width=\"50%\">\n\n### PCA在Fashion-MNIST(左侧)和经典MNIST上的可视化(右侧) \n<img src=\"doc/img/f04ba662.png\" width=\"50%\"><img src=\"doc/img/4433f0e1.png\" width=\"50%\">\n\n### [UMAP](https://github.com/lmcinnes/umap)在Fashion-MNIST(左侧)和经典MNIST上的可视化(右侧)  \n<img src=\"doc/img/umap_example_fashion_mnist1.png\" width=\"50%\"><img src=\"doc/img/umap_example_mnist1.png\" width=\"50%\">\n\n### [PyMDE](https://github.com/cvxgrp/pymde)在Fashion-MNIST(左侧)和经典MNIST上的可视化(右侧)  \n<img src=\"doc/img/pymde_example_fashion_mnist.png\" width=\"50%\"><img src=\"doc/img/pymde_example_mnist.png\" width=\"50%\">\n\n## 参与贡献\n我们热烈欢迎您参与贡献这个项目。[请先阅读这里！](/CONTRIBUTING.md) 并查看有什么[open issues](https://github.com/zalandoresearch/fashion-mnist/issues)可以帮助解决。\n\n## 联系\n若要讨论这个数据集上的应用和评测，请使用这个聊天室[![Gitter](https://badges.gitter.im/zalandoresearch/fashion-mnist.svg)](https://gitter.im/fashion-mnist/Lobby?utm_source=share-link&utm_medium=link&utm_campaign=share-link)\n\n\n## 在论文中引用Fashion-MNIST\n如果你在你的研究工作中使用了这个数据集，欢迎你引用这篇论文：\n\n**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](http://arxiv.org/abs/1708.07747)**\n\n亦可使用Biblatex:\n```latex\n@online{xiao2017/online,\n  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},\n  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},\n  date         = {2017-08-28},\n  year         = {2017},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1708.07747},\n}\n```\n\n[有谁引用了Fashion-MNIST?](https://scholar.google.com/scholar?scisbd=2&q=%22fashion-mnist%22&hl=en&as_sdt=0,5) \n\n\n## License\n\nThe MIT License (MIT) Copyright © [2017] Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 0.4736328125,
          "content": "import threading\n\nfrom benchmark.runner import JobManager\nfrom configs import LOGGER\nfrom utils.argparser import get_args_cli\nfrom utils.helper import UploadS3Thread\n\n\ndef start_s3_sync():\n    stop_flag = threading.Event()\n    upload_s3_thread = UploadS3Thread(stop_flag)\n    upload_s3_thread.start()\n\n\nif __name__ == \"__main__\":\n    arg_dict = get_args_cli()\n    LOGGER.info('received task with args: %s' % arg_dict)\n    start_s3_sync()\n    jm = JobManager(**arg_dict)\n    jm.start()\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "configs.py",
          "type": "blob",
          "size": 2.6416015625,
          "content": "import os\nfrom random import randint\n\nAPP_NAME = '%s-%d' % ('fashion-mnist', randint(0, 100))\nLOG_FORMAT = '%(asctime)-15s %(filename)s:%(funcName)s:[%(levelname)s] %(message)s'\nJSON_FORMAT = '%(message)s'\n\nRUN_LOCALLY = False\nROOT_DIR = os.path.dirname(os.path.abspath(__file__)) + '/'\nTEST_DIR = ROOT_DIR + 'test/'\nDATA_DIR = ROOT_DIR + 'data/fashion'\nVIS_DIR = ROOT_DIR + 'visualization/'\nMODEL_SAVE_DIR = ROOT_DIR + 'save/'\nMULTI_TASK_MODEL = '20170814-153653'\nTEST_DATA_DIR = TEST_DIR + 'data/'\nLOG_DIR = ROOT_DIR + 'log/'\nRESULT_DIR = ROOT_DIR + 'result/'\nTEMPLATE_DIR = ROOT_DIR + 'templates/'\nSTATIC_DIR = ROOT_DIR + 'static/'\nSCRIPT_DIR = ROOT_DIR + 'script/'\nBASELINE_PATH = ROOT_DIR + 'benchmark/baselines.json'\n\nQ2A_SUFFIX = '-merged-ad1-20170501+36D+20170605.json.gz'\n\nSYNC_SCRIPT_PATH = SCRIPT_DIR + 'sync_s3.sh'\nDOWNLOAD_SCRIPT_PATH = SCRIPT_DIR + 'load_s3_json.sh'\nLOG_PATH = LOG_DIR + APP_NAME + '.log'\nRESULT_PATH = RESULT_DIR + APP_NAME + '.json'\n\nQ2A_PATH = DATA_DIR + \"query2brand-train.tfr\"\nQ2A_INFO = DATA_DIR + \"query2brand.json\"\nMAX_ITEM_PER_ATTRIBUTE = 20\n\nLOSS_JITTER = 1e-4\nSYNC_INTERVAL = 300.0  # sync every 5 minutes\nSYNC_TIMEOUT = 600\nFIRST_SYNC_DELAY = 300.0  # do the first task only after 5 minutes.\n\nRNN_ARGS_JSON = ROOT_DIR + 'nn/queryclf/config.json'\n\nQ2A_JSON_AKEY1 = 'attributes'\nQ2A_JSON_AKEY2 = 'value'\n\n\ndef touch(fname: str, times=None, create_dirs: bool = False):\n    if create_dirs:\n        base_dir = os.path.dirname(fname)\n        if not os.path.exists(base_dir):\n            os.makedirs(base_dir)\n    with open(fname, 'a'):\n        os.utime(fname, times)\n\n\ndef touch_dir(base_dir: str) -> None:\n    if not os.path.exists(base_dir):\n        os.makedirs(base_dir)\n\n\ndef _get_logger(name: str):\n    import logging.handlers\n    touch(LOG_PATH, create_dirs=True)\n    touch_dir(MODEL_SAVE_DIR)\n    l = logging.getLogger(name)\n    l.setLevel(logging.DEBUG)\n    fh = logging.FileHandler(LOG_PATH)\n    fh.setLevel(logging.INFO)\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.INFO)\n    fh.setFormatter(logging.Formatter(LOG_FORMAT))\n    ch.setFormatter(logging.Formatter(LOG_FORMAT))\n    l.addHandler(fh)\n    l.addHandler(ch)\n    return l\n\n\ndef get_json_logger(name: str):\n    import logging.handlers\n    touch(RESULT_PATH, create_dirs=True)\n    l = logging.getLogger(__name__ + name)\n    l.setLevel(logging.INFO)\n    # add rotator to the logger. it's lazy in the sense that it wont rotate unless there are new logs\n    fh = logging.FileHandler(RESULT_PATH)\n    fh.setLevel(logging.INFO)\n    fh.setFormatter(logging.Formatter(JSON_FORMAT))\n    l.addHandler(fh)\n    return l\n\n\nLOGGER = _get_logger(__name__)\nJSON_LOGGER = get_json_logger('json' + __name__)\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0341796875,
          "content": "scikit-learn>=0.19.0\npsutil>=5.2.2\n"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        },
        {
          "name": "visualization",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}