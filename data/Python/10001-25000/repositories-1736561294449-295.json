{
  "metadata": {
    "timestamp": 1736561294449,
    "page": 295,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "netease-youdao/QAnything",
      "stars": 12268,
      "defaultBranch": "qanything-v2",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3798828125,
          "content": ".venv\n.vscode\n.idea\n.env\n.DS_Store\nuser.config\nvenv\ncustom_models\nfile_images\n__pycache__\nQANY_DB\nqanything_logs\ndebug_logs\nqa_logs\n*.lock\napi.log\nfront_end/dist\nnode_modules\nmodels\nvolumes\n*.log\nfront_end/yarn.lock\nfront_end/package-lock.json\nfront_end/.eslintrc-auto-import.json\nfront_end/auto-imports.d.ts\nfront_end/components.d.ts\nfront_end/stats.html\nfront_end/version.txt\ntmp_files/\n"
        },
        {
          "name": "FAQ_zh.md",
          "type": "blob",
          "size": 2.6328125,
          "content": "## 运行时报错，比如大模型不回答问题，或上传文件报错，或多个文件解析失败\n- 请查看内存使用情况，目前出错大概率是因为内存不足导致的，可以先尝试释放其他程序占用内存，再尝试运行\n  - 如果还是不行，可以尝试关闭部分依赖服务，比如ocr服务（只用于jpg，jpeg，png格式解析），再尝试运行\n- 请查看README中的[DEBUG](https://github.com/netease-youdao/QAnything/blob/qanything-v2/README_zh.md#debug)，日志中会有详细的报错信息，可以根据报错信息进行调试\n\n## 使用ollama本地服务时报错：Connection error.\n- 原因有2:\n  - ollama默认运行在127.0.0.1:11434端口上，而在容器内是无法访问到宿主机的127.0.0.1端口的，所以需要将ollama服务绑定到0.0.0.0:11434端口上，详情可以参考[ollama issue 3581](https://github.com/ollama/ollama/issues/3581)以及[ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server)\n  - docker-compose-xxx.yaml使用yaml内创建的子网QAnything来连接mysql等各个容器，未配置network_mode: host，因此无法访问到宿主机的localhost（0.0.0.0）服务\n- 解决方式：（更新最新代码即可，无需任何手动修改）\n  - 在macos和windows下，我不再使用子网QAnything，将mysql，milvus，es等端口直接映射到宿主机中，并使用host.docker.internal来自动替换api_base中的localhost，它允许容器访问宿主机的本地服务\n  - 在Linux下，host.docker.internal并不是一个内置的功能，因此我在docker-compose-xxx.yaml中添加了network_mode: host，这样容器内部可以直接访问宿主机的localhost服务\n\n## 使用ollama本地服务时问答效果不佳：\n- 原因：ollama服务内置上下文长度为2048，且无法通过传参的方式修改（因此使用ollama时，总Token数量设置无法生效），导致相关信息被截断，从而影响问答效果，详情可参考[ollama issue 5902](https://github.com/ollama/ollama/issues/5902)以及[ollama FAQ](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-specify-the-context-window-size)\n- 解决方式：（需手动修改）\n  - 举例：如果想把qwen2:72b-instruct的上下文从2048修改32000，需要执行如下操作：\n```bash\nollama pull qwen2:72b-instruct\n\nollama show --modelfile qwen2:72b-instruct > Modelfile\n\nvim Modelfile  // 加一行：PARAMETER num_ctx 32000\n\nollama create -f Modelfile qwen2:72b_ctx32k\n```\n  - 修改完成后，重启ollama本地服务，并在前端模型配置中将ollama服务的【模型名称】修改为【qwen2:72b_ctx32k】，即可生效"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 33.7138671875,
          "content": "                    GNU AFFERO GENERAL PUBLIC LICENSE\n                       Version 3, 19 November 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU Affero General Public License is a free, copyleft license for\nsoftware and other kinds of works, specifically designed to ensure\ncooperation with the community in the case of network server software.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nour General Public Licenses are intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  Developers that use our General Public Licenses protect your rights\nwith two steps: (1) assert copyright on the software, and (2) offer\nyou this License which gives you legal permission to copy, distribute\nand/or modify the software.\n\n  A secondary benefit of defending all users' freedom is that\nimprovements made in alternate versions of the program, if they\nreceive widespread use, become available for other developers to\nincorporate.  Many developers of free software are heartened and\nencouraged by the resulting cooperation.  However, in the case of\nsoftware used on network servers, this result may fail to come about.\nThe GNU General Public License permits making a modified version and\nletting the public access it on a server without ever releasing its\nsource code to the public.\n\n  The GNU Affero General Public License is designed specifically to\nensure that, in such cases, the modified source code becomes available\nto the community.  It requires the operator of a network server to\nprovide the source code of the modified version running there to the\nusers of that server.  Therefore, public use of a modified version, on\na publicly accessible server, gives the public access to the source\ncode of the modified version.\n\n  An older license, called the Affero General Public License and\npublished by Affero, was designed to accomplish similar goals.  This is\na different license, not a version of the Affero GPL, but Affero has\nreleased a new version of the Affero GPL which permits relicensing under\nthis license.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU Affero General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Remote Network Interaction; Use with the GNU General Public License.\n\n  Notwithstanding any other provision of this License, if you modify the\nProgram, your modified version must prominently offer all users\ninteracting with it remotely through a computer network (if your version\nsupports such interaction) an opportunity to receive the Corresponding\nSource of your version by providing access to the Corresponding Source\nfrom a network server at no charge, through some standard or customary\nmeans of facilitating copying of software.  This Corresponding Source\nshall include the Corresponding Source for any work covered by version 3\nof the GNU General Public License that is incorporated pursuant to the\nfollowing paragraph.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the work with which it is combined will remain governed by version\n3 of the GNU General Public License.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU Affero General Public License from time to time.  Such new versions\nwill be similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU Affero General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU Affero General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU Affero General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU Affero General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU Affero General Public License for more details.\n\n    You should have received a copy of the GNU Affero General Public License\n    along with this program.  If not, see <https://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If your software can interact with users remotely through a computer\nnetwork, you should also make sure that it provides a way for users to\nget its source.  For example, if your program is a web application, its\ninterface could display a \"Source\" link that leads users to an archive\nof the code.  There are many ways you could offer source, and different\nsolutions will be better for different programs; see section 13 for the\nspecific requirements.\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU AGPL, see\n<https://www.gnu.org/licenses/>.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 41.04296875,
          "content": "<div align=\"center\">\n\n  <a href=\"https://github.com/netease-youdao/QAnything\">\n    <!-- Please provide path to your logo here -->\n    <img src=\"docs/images/qanything_logo.png\" alt=\"Logo\" width=\"800\">\n  </a>\n\n# **Q**uestion and **A**nswer based on **Anything**\n\n<p align=\"center\">\n  <a href=\"./README.md\">English</a> |\n  <a href=\"./README_zh.md\">简体中文</a>\n</p>\n\n</div>\n\n<div align=\"center\">\n\n<a href=\"https://qanything.ai\"><img src=\"https://img.shields.io/badge/try%20online-qanything.ai-purple\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://read.youdao.com#/home\"><img src=\"https://img.shields.io/badge/try%20online-read.youdao.com-purple\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n\n<a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPL--3.0-yellow\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://github.com/netease-youdao/QAnything/pulls\"><img src=\"https://img.shields.io/badge/PRs-welcome-red\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://twitter.com/YDopensource\"><img src=\"https://img.shields.io/badge/follow-%40YDOpenSource-1DA1F2?logo=twitter&style={style}\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n\n<a href=\"https://discord.gg/5uNpPsEJz8\"><img src=\"https://img.shields.io/discord/1197874288963895436?style=social&logo=discord\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n\n\n\n</div>\n\n<details open=\"open\">\n<summary>Table of Contents</summary>\n\n- [What is QAnything](#what-is-qanything)\n  - [Key features](#key-features)\n  - [Architecture](#architecture)\n- [Latest Updates](#-latest-updates)\n- [Before You Start](#before-you-start)\n- [Getting Started](#getting-started)\n  - [Latest Features Table](#latest-features-table)\n  - [Version 2.0.0 adds detailed optimizations:](#version-200-adds-detailed-optimizations)\n    - [Display of data at each stage:](#display-of-data-at-each-stage)\n    - [Problem fixed](#problem-fixed)\n  - [Comparison of New and Old Parsing Effects](#comparison-of-new-and-old-parsing-effects)\n  - [Installation](#installation)\n    - [Prerequisites](#prerequisites)\n    - [step1: pull qanything repository](#step1-pull-qanything-repository)\n    - [step2: Enter the project root directory and execute the startup command.](#step2-enter-the-project-root-directory-and-execute-the-startup-command)\n    - [step3: start to experience](#step3-start-to-experience)\n    - [API](#api)\n    - [DEBUG](#debug)\n    - [Close service](#close-service)\n  - [Offline Use](#offline-use)\n  - [FAQ](#faq)\n  - [Contributing](#contributing)\n    - [Thanks to all contributors for their efforts](#thanks-to-all-contributors-for-their-efforts)\n    - [Special thanks!](#special-thanks)\n  - [Business contact information：](#business-contact-information)\n- [Roadmap & Feedback](#-roadmap--feedback)\n- [Community & Support](#community--support)\n- [License](#license)\n- [Acknowledgements](#acknowledgments)\n\n</details>\n\n# 🚀 Important Updates \n<h1><span style=\"color:red;\">Important things should be said three times.</span></h1>\n\n# [2024-08-23: QAnything updated to version 2.0.] \n# [2024-08-23: QAnything updated to version 2.0.]\n# [2024-08-23: QAnything updated to version 2.0.]\n\n<h2>\n\n* <span style=\"color:green\">This update brings improvements in various aspects such as usability, resource consumption, search results, question and answer results, parsing results, front-end effects, service architecture, and usage methods.</span>\n* <span style=\"color:green\">At the same time, the old Docker version and Python version have been merged into a new unified version, using a single-line command with Docker Compose for one-click startup, ready to use out of the box.</span>\n\n</h2>\n\n\n## Contributing\nWe appreciate your interest in contributing to our project. Whether you're fixing a bug, improving an existing feature, or adding something completely new, your contributions are welcome!\n### Thanks to all contributors for their efforts\n<a href=\"https://github.com/netease-youdao/QAnything/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=netease-youdao/QAnything\" />\n</a>\n\n### Special thanks!\n<h2><span style=\"color:red;\">Please note: Our list of contributors is automatically updated, so your contributions may not appear immediately on this list.</span></h2>\n<h2><span style=\"color:red;\">Special thanks!：@ikun-moxiaofei</span></h2>\n<h2><span style=\"color:red;\">Special thanks!：@Ianarua</span></h2>\n\n\n## Business contact information：\n### 010-82558901\n![](docs/images/business.jpeg)\n\n# What is QAnything?\n`QAnything`(**Q**uestion and **A**nswer based on **Anything**) is a local knowledge base question-answering system designed to support a wide range of file formats and databases, allowing for offline installation and use.\n\nWith `QAnything`, you can simply drop any locally stored file of any format and receive accurate, fast, and reliable answers.\n\nCurrently supported formats include: **PDF(pdf)**,**Word(docx)**,**PPT(pptx)**,**XLS(xlsx)**,**Markdown(md)**,**Email(eml)**,**TXT(txt)**,**Image(jpg，jpeg，png)**,**CSV(csv)**,**Web links(html)** and more formats coming soon…\n\n\n## Key features\n\n- Data security, supports installation and use by unplugging the network cable throughout the process. \n- Supports multiple file types, high parsing success rate, supports cross-language question and answer, freely switches between Chinese and English question and answer, regardless of the language of the file.\n- Supports massive data question and answer, two-stage vector sorting, solves the problem of degradation of large-scale data retrieval, the more data, the better the effect, no limit on the number of uploaded files, fast retrieval speed. \n- Hardware friendly, defaults to running in a pure CPU environment, and supports multiple platforms such as Windows, Mac, and Linux, with no dependencies other than Docker. \n- User-friendly, no need for cumbersome configuration, one-click installation and deployment, ready to use, each dependent component (PDF parsing, OCR, embed, rerank, etc.) is completely independent, supports free replacement. \n- Supports a quick start mode similar to Kimi, fileless chat mode, retrieval mode only, custom Bot mode.\n\n\n\n\n## Architecture\n<div align=\"center\">\n<img src=\"docs/images/qanything_arch.png\" width = \"700\" alt=\"qanything_system\" align=center />\n</div>\n\n### Why 2 stage retrieval?\nIn scenarios with a large volume of knowledge base data, the advantages of a two-stage approach are very clear. If only a first-stage embedding retrieval is used, there will be a problem of retrieval degradation as the data volume increases, as indicated by the green line in the following graph. However, after the second-stage reranking, there can be a stable increase in accuracy, **the more data, the better the performance**.\n<div align=\"center\">\n<img src=\"docs/images/two_stage_retrieval.jpg\" width = \"500\" alt=\"two stage retrievaal\" align=center />\n</div>\n\nQAnything uses the retrieval component [BCEmbedding](https://github.com/netease-youdao/BCEmbedding), which is distinguished for its bilingual and crosslingual proficiency. BCEmbedding excels in bridging Chinese and English linguistic gaps, which achieves\n- **A high performance on <a href=\"https://github.com/netease-youdao/BCEmbedding/tree/master?tab=readme-ov-file#evaluate-semantic-representation-by-mteb\" target=\"_Self\">Semantic Representation Evaluations in MTEB</a>**;\n- **A new benchmark in the realm of <a href=\"https://github.com/netease-youdao/BCEmbedding/tree/master?tab=readme-ov-file#evaluate-rag-by-llamaindex\" target=\"_Self\">RAG Evaluations in LlamaIndex</a>**.\n\n\n### 1st Retrieval（embedding）\n| Model | Retrieval | STS | PairClassification | Classification | Reranking | Clustering | Avg |  \n|:-------------------------------|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|  \n| bge-base-en-v1.5 | 37.14 | 55.06 | 75.45 | 59.73 | 43.05 | 37.74 | 47.20 |  \n| bge-base-zh-v1.5 | 47.60 | 63.72 | 77.40 | 63.38 | 54.85 | 32.56 | 53.60 |  \n| bge-large-en-v1.5 | 37.15 | 54.09 | 75.00 | 59.24 | 42.68 | 37.32 | 46.82 |  \n| bge-large-zh-v1.5 | 47.54 | 64.73 | **79.14** | 64.19 | 55.88 | 33.26 | 54.21 |  \n| jina-embeddings-v2-base-en | 31.58 | 54.28 | 74.84 | 58.42 | 41.16 | 34.67 | 44.29 |  \n| m3e-base | 46.29 | 63.93 | 71.84 | 64.08 | 52.38 | 37.84 | 53.54 |  \n| m3e-large | 34.85 | 59.74 | 67.69 | 60.07 | 48.99 | 31.62 | 46.78 |  \n| ***bce-embedding-base_v1*** | **57.60** | **65.73** | 74.96 | **69.00** | **57.29** | **38.95** | ***59.43*** |  \n\n- More evaluation details please check [Embedding Models Evaluation Summary](https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/embedding_eval_summary.md)。\n\n### 2nd Retrieval（rerank）\n| Model | Reranking | Avg |  \n|:-------------------------------|:--------:|:--------:|  \n| bge-reranker-base | 57.78 | 57.78 |  \n| bge-reranker-large | 59.69 | 59.69 |  \n| ***bce-reranker-base_v1*** | **60.06** | ***60.06*** |  \n\n- More evaluation details please check [Reranker Models Evaluation Summary](https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/reranker_eval_summary.md)\n\n### RAG Evaluations in LlamaIndex（embedding and rerank）\n\n<img src=\"https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/assets/rag_eval_multiple_domains_summary.jpg\">\n\n***NOTE:***\n\n- In `WithoutReranker` setting, our `bce-embedding-base_v1` outperforms all the other embedding models.\n- With fixing the embedding model, our `bce-reranker-base_v1` achieves the best performance.\n- **The combination of `bce-embedding-base_v1` and `bce-reranker-base_v1` is SOTA**.\n- If you want to use embedding and rerank separately, please refer to [BCEmbedding](https://github.com/netease-youdao/BCEmbedding)\n\n### LLM\n\nThe open source version of QAnything is based on QwenLM and has been fine-tuned on a large number of professional question-answering datasets. It greatly enhances the ability of question-answering.\nIf you need to use it for commercial purposes, please follow the license of QwenLM. For more details, please refer to: [QwenLM](https://github.com/QwenLM/Qwen)\n\n# 🚀 Latest Updates\n\n- ***2024-08-23***: **Support quick start, front-end configuration parameters, online preview and editing of chunk blocks, greatly optimize project architecture and startup mode, greatly optimize parsing and retrieval effects.** - See More👉 [v2.0.0](https://github.com/netease-youdao/QAnything/releases/tag/v2.0.0) \n- ***2024-05-20***: **Support other large model services compatible with OpenAI API, and provide an optimized powerful PDF parser.** - See More👉 [v1.4.1](https://github.com/netease-youdao/QAnything/releases/tag/v1.4.1)\n- ***2024-04-26***: **Support web search, FAQ, custom bot, file traceability preview etc.** - See More👉 [v1.4.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.4.0-python)\n- ***2024-04-03***: **Support installation in a pure Python environment.Support hybrid search.** - See More👉 [v1.3.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.3.0)\n- ***2024-01-29***: **Support for custom large models, including OpenAI API and other open-source large models, with a minimum GPU requirement of GTX 1050Ti, greatly improving deployment, debugging, and user experience.** - See More👉 [v1.2.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.2.0)\n- ***2024-01-23***: **Enable rerank by default and fix various issues when starting on Windows.** - See More👉 [v1.1.1](https://github.com/netease-youdao/QAnything/releases/tag/v1.1.1)\n- ***2024-01-18***: **Support one-click startup, support Windows deployment, improve PDF, XLSX, HTML parsing efficiency.** - See More👉 [v1.1.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.1.0)\n\n# Before You Start\n**Star us on GitHub, and be instantly notified for new release!**\n![star_us](https://github.com/netease-youdao/QAnything/assets/29041332/fd5e5926-b9b2-4675-9f60-6cdcaca18e14)\n* [🏄 Try QAnything Online](https://qanything.ai)\n* [📚 Try read.youdao.com | 有道速读](https://read.youdao.com)\n* [🛠️ Only use our BCEmbedding(embedding & rerank)](https://github.com/netease-youdao/BCEmbedding)\n* [📖 FAQ](FAQ_zh.md)\n* [👂️Let me hear your voice](https://qanything.canny.io/feature-requests)\n\n\n# Getting Started\n## Latest Features Table\n\n\n| features                                                             | python （v1.4.2） | docker （v1.2.2） | QAnything v2.0.0 | Explanation                                                                                                                                                                                                     |\n|----------------------------------------------------------------------|-----------------|-----------------|------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Detailed installation document                                       | ✅               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support API                                                          | ✅               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support production environment                                       | ❌               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support offline use                                                  | ❌               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support multiple concurrency                                         | ❌               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support multi-card inference                                         | ❌               | ✅               | ❌                | Version 2.0.0 no longer provides default local LLM. All access is through the openai interface, and users can deploy local LLM through tools such as ollama.                                                    |\n| Support Mac (M series chips)                                         | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support Linux                                                        | ✅               | ✅               | ✅                | The old version of Python defaults to using onnxruntime-gpu for cuda12 on Linux, and automatically switches to onnxruntime when glibc<2.28.                                                                     |\n| Support windows                                                      | ❌               | ❌               | ✅                | Both old versions of Python and Docker require WSL environment. Version 2.0.0 can be started directly in a non-WSL environment.                                                                                 |\n| Support CPU only                                                     | ✅               | ❌               | ✅                | Version 2.0.0 Mac, Linux, Win unified no longer use GPU, completely migrated to CPU.                                                                                                                            |\n| Support hybrid search (BM25+embedding)                               | ❌               | ✅               | ✅                |                                                                                                                                                                                                                 |\n| Support web search (need VPN)                                        | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support FAQ                                                          | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support BOT                                                          | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support Traceability                                                 | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support Log retrieval                                                | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support audio file                                                   | ✅               | ❌               | ❌                | Relying on whisper, slow speed and high resource consumption, temporarily removed.                                                                                                                              |\n| Support OpenCloudOS                                                  | ✅               | ❌               | ✅                |                                                                                                                                                                                                                 |\n| Support interfaces compatible with Openaiapi (including ollama)      | ✅               | ✅               | ✅                | Old versions of Python and Docker require manual modification of parameters such as api_key, base_url, model, etc. In version 2.0.0, these are all changed to be automatically saved in the front end settings. |\n| PDF parsing performance improvement (including tables)               | ✅               | ❌               | ✅                | Version 1.4.2 requires manual settings, version 2.0.0 does not require manual settings, and both the PDF parsing effect and performance have been improved.                                                     |\n| User-defined configuration (Experimental: Improve speed)             | ✅               | ❌               | ✅                | v1.4.2 needs to be set manually, v2.0.0 uses the best configuration by default.                                                                                                                                 |\n| Improvement in parsing performance of other file types               | ❌               | ❌               | ✅                | Version 2.0.0 improves the parsing effect of URLs, Markdown, XLSX, DOCX, etc.                                                                                                                                   |\n| Support independent service invocation                               | ❌               | ❌               | ✅                | Version 2.0.0 independent dependent services, including embed, rerank, ocr, pdf parsing services, can be called independently (http)                                                                            |\n| Support quick start mode                                             | ❌               | ❌               | ✅                | Quick Start: No need to create a knowledge base, support for file upload and instant questioning, support for fileless Q&A.                                                                                     |\n| Support only retrieval mode                                          | ❌               | ❌               | ✅                | Only return search results, do not call the large model for question answering.                                                                                                                                 |\n| Support parsing result chunks content visualization, manual editing. | ❌               | ❌               | ✅                | Version 2.0.0 supports manually editing the contents of chunks, which take effect in real time.                                                                                                                 |\n| PDF parsing supports images, supports answering with images.         | ❌               | ❌               | ✅                |                                                                                                                                                                                                                 |\n\n\n## Version 2.0.0 adds detailed optimizations:\n\n* Support front-end configuration API_BASE, API_KEY, text chunk size, output token quantity, context message quantity, etc.\n* Optimize the instruction compliance of Bot role settings, each Bot can configure model parameters separately.\n* Support creating multiple dialogue windows and saving multiple sets of historical Q&A records at the same time.\n* Support saving question and answer records as images\n* Optimize the logic of uploading files, parse files and question-and-answer requests independently, uploading files will no longer affect question-and-answer.\n* Optimize image size, the compressed size of the old version image is 18.94GB -> the compressed size of the new version image is 4.88GB, reduced to 1/4 of the original size, providing a complete Dockerfile.\n* Search optimization, chunks add fragment fusion and sorting, aggregate single document or double document.\n* Both the retrieval stage and the question-answering stage embed metadata information to improve the retrieval and question-answering effectiveness. \n\n### Display of data at each stage:\n* Display the upload progress of all files in the knowledge base.\n* Display the progress of uploading a single file in the knowledge base, and the time consumed in each stage of the upload.\n* Question and answer information statistics, including time consumption at each stage of question and answer, token consumption, model information, etc.\n* User information statistics, including total number of uploaded files, total time consumed, question and answer history records, etc.\n\n### Problem fixed\n* The xlsx file format supports parsing multiple sheets.\n* Optimize the problem of missing recognition of PDF tables.\n* Fix some parsing errors in DOCX files.\n* Optimize FAQ matching logic.\n* Support for non-UTF-8 encoded txt files. \n\n## Comparison of New and Old Parsing Effects\n* First, with regard to the parsing of large tables in documents, especially tables that span multiple pages, version 2.0 has made significant improvements. The new version's parsing logic can analyze the structure of the table, including the layout of rows and columns, and can automatically identify the table headers, placing them at the top of each table segment that is split. This improvement prevents interruptions in meaning caused by logical segmentation when parsing long tables.\n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170060.png) | ![image.png](docs/assets/17244247170067.png) | ![image.png](docs/assets/17244247170074.png) |\n\n* In addition, version 2.0 has also been optimized for handling text columnation and cross-page layout. It can recognize double-column or multi-column layouts of text and correctly divide text blocks in accordance with human reading habits. At the same time, this version can also save images in documents to ensure the integrity of content is not lost during file parsing. As shown in the figure below, the correct arrangement should be to group the text arranged in sequence as 1, 2, 3 into a large paragraph and then segment it, rather than segmenting 1, 2, 3 separately.\n  * In version 1.4 parsing results, the cross-page text \"higher\" was chunked into the next text block, which is detrimental to large model semantic understanding. In version 2.0 parsing results, it is correctly divided, and images interspersed in text paragraphs are also parsed into corresponding chunk statements. Non-main text such as \"Figure 1 Identification and Authorization and Their Support Relationship 37\" and \"Cover Story Cover Feature\" were successfully filtered out.\n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170088.png) | ![image.png](docs/assets/17244247170101.png)<br/>![image.png](docs/assets/17244247170115.png) | ![image.png](docs/assets/17244247170129.png) |\n\n* Version 2.0 has also made corresponding optimizations for parsing tables interspersed between text columns or text blocks. The parsing of the original version could not recognize tables and would only parse them in the format of text paragraphs. This not only destroys the logical structure of the tables but also adds a section of messy and useless text for large models, which would affect the accuracy of large model responses. Version 2.0 can recognize and parse these tables embedded in the text, thereby improving the quality of parsing and the accuracy of responses from large models.\n  * In version 1.4 parsing results, tables interspersed in text blocks are parsed as normal text blocks. In version 2.0, this type of table can be parsed \"elegantly\", which not only improves the quality of parsing but also increases the accuracy of large model answers.\n  * In addition, in version 2.0, when processing text under specific subheadings, priority is given to ensuring that these texts are segmented into the same chunk block to maintain logical coherence. When the text is too long and needs to be split, the parsing logic of version 2.0 will repeat the same subheading before each split text block to indicate ownership. For example, in the example, the same subheading \"European Conference: Legal Status of Robots\" was added to all three text blocks (due to the length of the text, this title was not displayed in the original file screenshot). This processing method effectively avoids the problem of incoherent semantic logic in split text blocks caused by excessively long text. \n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170148.png) | ![image.png](docs/assets/17244247170166.png) | ![image.png](docs/assets/17244247171267.png) |\n\n* For Excel (.xlsx) documents with complex formatting, version 2.0 has undergone a series of optimization measures to accurately identify and process row and column data, including optimized handling of merged cells and text spanning across rows or columns. Specific examples can be seen below.\n  * In version 1.4, there may be some limitations when parsing Excel documents, especially for documents with special structures or formats. The parsing results may not be satisfactory, mainly recognizing only the plain text part. This may lead to information loss or format disorder when dealing with complex data and formats. In contrast, version 2.0 has significantly improved parsing capabilities, able to better handle various complex formats of Excel documents. Although it may not be perfect yet, it can already solve the vast majority of complex situations. \n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170188.png) | ![image.png](docs/assets/17244247170208.png) | ![image.png](docs/assets/17244247170228.png) |\n\n* Similarly, for simple formatted xlsx documents, version 2.0 of the parser has been optimized.\n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170272.png) | ![image.png](docs/assets/17244247170298.png) | ![image.png](docs/assets/17244247170323.png) |\n\n* In the latest version, we have also made significant improvements to the URL parsing function. Taking the following page as an example, the old version may miss a large amount of page information during the parsing process and cannot effectively handle more complex page elements such as tables and lists. However, the new version has been optimized for these issues and can parse these contents more accurately.\n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170443.png) | ![image.png](docs/assets/17244247170478.png)<br/>![image.png](docs/assets/17244247170512.png) | ![image.png](docs/assets/17244247170546.png) |\n\n* In addition, for the vast majority of files, version 2.0 has also made corresponding optimizations, including but not limited to the following points.\n  * Improved the cutting logic of chunk blocks, avoiding semantic blocks being too short or logic interruption due to blank lines or paragraphs in the document, ensuring the coherence and integrity of text blocks. \n  * The new version can more accurately identify the subheadings in the document, and locate and organize the corresponding text blocks based on these subheadings, which helps optimize the parsing effect, making the parsing structure clearer and the information hierarchy more distinct.\n  * The comparison of the analysis results is as follows: In version 1.4, the parsing logic divides the document into 10 chunks, while in version 2.0, after parsing, there are only 4 chunks. The more reasonable and fewer chunk blocks greatly improve the coherence and integrity of the content, helping to reduce semantic breaks or logical confusion caused by improper segmentation, thereby improving the overall parsing and model answering effects. \n\n| Original image | Old version parsing effect | New version parsing effect |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170352.png) | ![image.png](docs/assets/17244247170380.png) | ![image.png](docs/assets/17244247170406.png) |\n\n### In summary, version 2.0 parsing has optimized many aspects compared to version 1.4 parsing, including but not limited to\n1. By using more reasonable chunk lengths, the semantic and logical losses caused by paragraphs being too small or incomplete are reduced. \n2. Improved recognition ability for columned text, able to intelligently determine reading order, even correctly handling paragraphs that span across pages. \n3. The new version can recognize and save images and tables within text paragraphs, ensuring that no important text information is missed. \n4. Optimized table parsing, including parsing and storage of long tables exceeding chunk limits and complex structured xlsx files. \n5. Based on the identified subheadings in the document, locate and organize corresponding text blocks to make the parsing structure clearer and the information hierarchy more distinct. \n6. Optimized parsing results for webpage URLs, converted to .md format. \n7. Support for more encoding formats of txt files and docx files.\n\n## Installation\n### Prerequisites\n| **System** | **Required item**       | **Minimum Requirement** | **Note**                                                                               |\n|------------|-------------------------|-------------------------|----------------------------------------------------------------------------------------|\n|            | RAM Memory              | >= 20GB                 |                                                                                        |\n| Linux/Mac  | Docker version          | >= 20.10.5              | [Docker install](https://docs.docker.com/engine/install/)                              |\n| Linux/Mac  | docker compose  version | >= 2.23.3               | [docker compose install](https://docs.docker.com/compose/install/)                     |\n| Windows    | Docker Desktop          | >= 4.26.1（131620）       | [Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/) |\n\n### step1: pull qanything repository\n```shell\ngit clone https://github.com/netease-youdao/QAnything.git\n```\n### step2: Enter the project root directory and execute the startup command.\n* Execute the docker compose start command\n* **The startup process takes about 30 seconds. When the log outputs \"qanything backend service is ready!\", the startup is complete!** \n```shell\ncd QAnything\n# Start on Linux\ndocker compose -f docker-compose-linux.yaml up\n# Start on Mac\ndocker compose -f docker-compose-mac.yaml up\n# Start on Windows\ndocker compose -f docker-compose-win.yaml up\n```\n\n(Note) If the startup fails, you can try changing `docker compose` to `docker-compose`.\n\n### step3: start to experience\n#### Front end\nAfter successful installation, you can experience the application by entering the following addresses in your web browser.\n\n- Front end address: http://localhost:8777/qanything/\n\n### API\nIf you want to visit API, please refer to the following address:\n- API address: http://localhost:8777/qanything/\n- For detailed API documentation, please refer to [QAnything API documentation](docs/API.md)\n\n### DEBUG\nIf you want to view the relevant logs, please check the log files in the `QAnything/logs/debug_logs` directory.\n- **debug.log**\n  - User request processing log\n- **sanic_api.log**\n  - Backend service running log\n- **llm_embed_rerank_tritonserver.log**(Single card deployment)\n  - LLM embedding and rerank tritonserver service startup log\n- **llm_tritonserver.log**(Multi-card deployment)\n  - LLM tritonserver service startup log\n- **embed_rerank_tritonserver.log**(Multi-card deployment or use of the OpenAI interface.)\n  - Embedding and rerank tritonserver service startup log\n- rerank_server.log\n  - Rerank service running log\n- ocr_server.log\n  - OCR service running log\n- npm_server.log\n  - Front-end service running log \n- llm_server_entrypoint.log\n  - LLM intermediate server running log\n- fastchat_logs/*.log\n  - FastChat service running log\n\n### Close service\n```shell\n# Front desk service startup mode like:\ndocker compose -f docker-compose-xxx.yaml up  # To close the service, please press Ctrl+C.\n# Backend service startup mode like: \ndocker compose -f docker-compose-xxx.yaml up -d # To close the service, please execute the following command.\ndocker compose -f docker-compose-xxx.yaml down\n```\n\n## Offline Use\nIf you want to use QAnything offline, you need to deploy the local large model (recommended to use ollama) on the offline machine in advance, and then you can start the service using the following command.\n### Install offline for windows \n```shell\n# Download the docker image on a networked machine\ndocker pull quay.io/coreos/etcd:v3.5.5\ndocker pull minio/minio:RELEASE.2023-03-20T20-16-18Z\ndocker pull milvusdb/milvus:v2.4.8\ndocker pull mysql:8.4\ndocker pull xixihahaliu01/qanything-win:v1.5.1  # From [https://github.com/netease-youdao/QAnything/blob/master/docker-compose-windows.yaml#L103] Get the latest version number.\n\n# pack image\ndocker save quay.io/coreos/etcd:v3.5.5 minio/minio:RELEASE.2023-03-20T20-16-18Z milvusdb/milvus:v2.4.8 mysql:8.4 xixihahaliu01/qanything-win:v1.5.1 -o qanything_offline.tar\n\n# download QAnything code\nwget https://github.com/netease-youdao/QAnything/archive/refs/heads/master.zip\n\n# Copy the image qanything_offline.tar and the code qany-master.zip to the offline machine \ncp QAnything-master.zip qanything_offline.tar /path/to/your/offline/machine\n\n# Load image on offline machine \ndocker load -i qanything_offline.tar\n\n# Unzip the code and run it\nunzip QAnything-master.zip\ncd QAnything-master\ndocker compose -f docker-compose-win.yaml up\n``` \nSimilarly for other systems, just replace the corresponding image of the system, such as replacing mac with docker-compose-mac.yaml, and linux with docker-compose-linux.yaml.\n\n\n## FAQ\n### The most common issue at present is that the local service of Ollama has poor question and answer effects, and you can refer to the solutions in the FAQ.\n[FAQ](FAQ_zh.md)\n\n\n## Contributing\nWe appreciate your interest in contributing to our project. Whether you're fixing a bug, improving an existing feature, or adding something completely new, your contributions are welcome!\n### Thanks to all contributors for their efforts\n<a href=\"https://github.com/netease-youdao/QAnything/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=netease-youdao/QAnything\" />\n</a>\n\n\n# 🛣️ Roadmap & Feedback\n🔎 To learn about QAnything's future plans and progress, please see here: [QAnything Roadmap](https://qanything.canny.io/)\n\n🤬To provide feedback to QAnything, please see here: [QAnything Feedbak](https://qanything.canny.io/feature-requests)\n\n# Community & Support\n\n## Discord <a href=\"https://discord.gg/5uNpPsEJz8\"><img src=\"https://img.shields.io/discord/1197874288963895436?style=social&logo=discord\"></a>\nWelcome to the QAnything [Discord](https://discord.gg/5uNpPsEJz8) community\n\n\n## WeChat\n\nWelcome to follow QAnything WeChat Official Account to get the latest information.\n\n<img src=\"docs/images/qrcode_for_qanything.jpg\" width=\"30%\" height=\"auto\">\n\n\nWelcome to scan the code to join the QAnything discussion group.\n\n<img src=\"docs/images/Wechat.jpg\" width=\"30%\" height=\"auto\">\n\n\n## Email\nIf you need to contact our team privately, please reach out to us via the following email:\n\nqanything@rd.netease.com\n\n## GitHub issues & discussions\nReach out to the maintainer at one of the following places:\n\n- [Github issues](https://github.com/netease-youdao/QAnything/issues)\n- [Github discussions](https://github.com/netease-youdao/QAnything/discussions)\n- Contact options listed on [this GitHub profile](https://github.com/netease-youdao)\n\n<a href=\"https://github.com/netease-youdao/QAnything/discussions\">\n  <!-- Please provide path to your logo here -->\n  <img src=\"https://github.com/netease-youdao/QAnything/assets/29041332/ad027ec5-0bbc-4ea0-92eb-81b30c5359a1\" alt=\"Logo\" width=\"600\">\n</a>\n\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=netease-youdao/QAnything,netease-youdao/BCEmbedding&type=Date)](https://star-history.com/#netease-youdao/QAnything&netease-youdao/BCEmbedding&Date)\n\n\n\n# License\n\n`QAnything` is licensed under [AGPL-3.0 License](./LICENSE)\n\n# Acknowledgments\n`QAnything` adopts dependencies from the following:\n- Thanks to our [BCEmbedding](https://github.com/netease-youdao/BCEmbedding) for the excellent embedding and rerank model. \n- Thanks to [Qwen](https://github.com/QwenLM/Qwen) for strong base language models.\n- Thanks to [Triton Inference Server](https://github.com/triton-inference-server/server) for providing great open source inference serving.\n- Thanks to [FastChat](https://github.com/lm-sys/FastChat) for providing a fully OpenAI-compatible API server.\n- Thanks to [FasterTransformer](https://github.com/NVIDIA/FasterTransformer) and [vllm](https://github.com/vllm-project/vllm) for highly optimized LLM inference backend.\n- Thanks to [Langchain](https://github.com/langchain-ai/langchain) for the wonderful llm application framework. \n- Thanks to [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat) for the inspiration provided on local knowledge base Q&A.\n- Thanks to [Milvus](https://github.com/milvus-io/milvus) for the excellent semantic search library.\n- Thanks to [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) for its ease-to-use OCR library.\n- Thanks to [Sanic](https://github.com/sanic-org/sanic) for the powerful web service framework.\n- Thanks to [RAGFlow](https://github.com/infiniflow/ragflow) for providing some ideas for document parsing.\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 34.1025390625,
          "content": "<div align=\"center\">\n\n  <a href=\"https://github.com/netease-youdao/QAnything\">\n    <!-- Please provide path to your logo here -->\n    <img src=\"docs/images/qanything_logo.png\" alt=\"Logo\" width=\"911\" height=\"175\">\n  </a>\n\n# **Q**uestion and **A**nswer based on **Anything**\n\n<p align=\"center\">\n  <a href=\"./README.md\">English</a> |\n  <a href=\"./README_zh.md\">简体中文</a>\n</p>\n\n</div>\n\n<div align=\"center\">\n\n<a href=\"https://qanything.ai\"><img src=\"https://img.shields.io/badge/%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C-QAnything-purple\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://read.youdao.com#/home\"><img src=\"https://img.shields.io/badge/%E5%9C%A8%E7%BA%BF%E4%BD%93%E9%AA%8C-有道速读-purple\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n\n<a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-AGPL--3.0-yellow\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://github.com/netease-youdao/QAnything/pulls\"><img src=\"https://img.shields.io/badge/PRs-welcome-red\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n<a href=\"https://twitter.com/YDopensource\"><img src=\"https://img.shields.io/badge/follow-%40YDOpenSource-1DA1F2?logo=twitter&style={style}\"></a>\n&nbsp;&nbsp;&nbsp;&nbsp;\n\n</div>\n\n<details open=\"open\">\n<summary>目 录</summary>\n\n- [重要更新](#-重要更新)\n- [什么是QAnything](#什么是qanything)\n  - [特点](#特点)\n  - [架构](#架构)\n- [最近更新 ](#-最近更新)\n- [开始之前](#开始之前)\n- [开始](#开始)\n  - [最新特性表](#最新特性表)\n  - [V2.0.0版本新增细节优化：](#v200版本新增细节优化)\n  - [新旧解析效果对比](#新旧解析效果对比)\n  - [安装](#安装)\n    - [必要条件](#必要条件)\n    - [step1: 下载本项目](#step1-下载本项目)\n    - [step2: 进入项目根目录执行启动命令](#step2-进入项目根目录执行启动命令)\n    - [step3: 开始体验](#step3-开始体验)\n    - [API](#API)\n    - [DEBUG](#DEBUG)\n    - [关闭服务](#关闭服务)\n  - [离线使用](#离线使用)\n  - [常见问题](#常见问题)\n  - [贡献代码](#贡献代码)\n    - [感谢以下所有贡献者](#感谢以下所有贡献者)\n    - [特别鸣谢](#特别鸣谢)\n  - [商务问题联系方式：](#商务问题联系方式)\n- [路线图&反馈](#-路线图--反馈)\n- [交流&支持](#交流--支持)\n  - [微信](#微信)\n  - [邮箱](#邮箱)\n- [协议](#协议)\n- [Acknowledgements](#acknowledgements)\n\n</details>\n\n# 🚀 重要更新\n<h1><span style=\"color:red;\">重要的事情说三遍！</span></h1>\n\n# [2024-08-23: QAnything更新V2.0版本]\n# [2024-08-23: QAnything更新V2.0版本]\n# [2024-08-23: QAnything更新V2.0版本]\n\n<h2>\n\n* <span style=\"color:green\">此次更新带来了使用门槛，资源占用，检索效果，问答效果，解析效果，前端效果，服务架构，使用方式等多方面的改进。</span>\n* <span style=\"color:green\">同时合并了旧有的docker版和python版两个版本，改为全新的统一版本，采用docker compose单行命令一键启动，开箱即用。</span>\n\n</h2>\n\n\n## 欢迎贡献代码\n我们感谢您对贡献到我们项目的兴趣。无论您是修复错误、改进现有功能还是添加全新内容，我们都欢迎您的贡献！\n\n### 感谢以下所有贡献者\n<a href=\"https://github.com/netease-youdao/QAnything/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=netease-youdao/QAnything\" />\n</a>\n\n### 特别鸣谢！\n<h2><span style=\"color:red;\">请注意：我们的贡献者名单是自动更新的，因此您的贡献可能不会立即显示在此列表中。</span></h2>\n<h2><span style=\"color:red;\">特别鸣谢！：@ikun-moxiaofei</span></h2>\n<h2><span style=\"color:red;\">特别鸣谢！：@Ianarua</span></h2>\n\n\n## 商务问题联系方式：\n### 010-82558901\n![](docs/images/business.jpeg)\n\n# 什么是QAnything？\n**QAnything** (**Q**uestion and **A**nswer based on **Anything**) 是致力于支持任意格式文件或数据库的本地知识库问答系统，可断网安装使用。\n\n您的任何格式的本地文件都可以往里扔，即可获得准确、快速、靠谱的问答体验。\n\n目前已支持格式: **PDF(pdf)**，**Word(docx)**，**PPT(pptx)**，**XLS(xlsx)**，**Markdown(md)**，**电子邮件(eml)**，**TXT(txt)**，**图片(jpg，jpeg，png)**，**CSV(csv)**，**网页链接(html)**，更多格式，敬请期待...\n\n## 特点\n- 数据安全，支持全程拔网线安装使用。\n- 支持文件类型多，解析成功率高，支持跨语种问答，中英文问答随意切换，无所谓文件是什么语种。\n- 支持海量数据问答，两阶段向量排序，解决了大规模数据检索退化的问题，数据越多，效果越好，不限制上传文件数量，检索速度快。\n- 硬件友好，默认在纯CPU环境下运行，且win，mac，linux多端支持，除docker外无依赖项。\n- 易用性，无需繁琐的配置，一键安装部署，开箱即用，各依赖组件（pdf解析，ocr，embed，rerank等）完全独立，支持自由替换。\n- 支持类似Kimi的快速开始模式，无文件聊天模式，仅检索模式，自定义Bot模式。\n\n## 架构\n<div align=\"center\">\n<img src=\"docs/images/qanything_arch.png\" width = \"700\" alt=\"qanything_system\" align=center />\n</div>\n\n### 为什么是两阶段检索?\n知识库数据量大的场景下两阶段优势非常明显，如果只用一阶段embedding检索，随着数据量增大会出现检索退化的问题，如下图中绿线所示，二阶段rerank重排后能实现准确率稳定增长，即**数据越多，效果越好**。\n\n<div align=\"center\">\n<img src=\"docs/images/two_stage_retrieval.jpg\" width = \"500\" alt=\"two stage retrievaal\" align=center />\n</div>\n\nQAnything使用的检索组件[BCEmbedding](https://github.com/netease-youdao/BCEmbedding)有非常强悍的双语和跨语种能力，能消除语义检索里面的中英语言之间的差异，从而实现：\n- **强大的双语和跨语种语义表征能力【<a href=\"https://github.com/netease-youdao/BCEmbedding/tree/master?tab=readme-ov-file#semantic-representation-evaluations-in-mteb\" target=\"_Self\">基于MTEB的语义表征评测指标</a>】。**\n- **基于LlamaIndex的RAG评测，表现SOTA【<a href=\"https://github.com/netease-youdao/BCEmbedding/tree/master?tab=readme-ov-file#rag-evaluations-in-llamaindex\" target=\"_Self\">基于LlamaIndex的RAG评测指标</a>】。**\n\n\n### 一阶段检索（embedding）\n| 模型名称 | Retrieval | STS | PairClassification | Classification | Reranking | Clustering | 平均 |  \n|:-------------------------------|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|  \n| bge-base-en-v1.5 | 37.14 | 55.06 | 75.45 | 59.73 | 43.05 | 37.74 | 47.20 |  \n| bge-base-zh-v1.5 | 47.60 | 63.72 | 77.40 | 63.38 | 54.85 | 32.56 | 53.60 |  \n| bge-large-en-v1.5 | 37.15 | 54.09 | 75.00 | 59.24 | 42.68 | 37.32 | 46.82 |  \n| bge-large-zh-v1.5 | 47.54 | 64.73 | **79.14** | 64.19 | 55.88 | 33.26 | 54.21 |  \n| jina-embeddings-v2-base-en | 31.58 | 54.28 | 74.84 | 58.42 | 41.16 | 34.67 | 44.29 |  \n| m3e-base | 46.29 | 63.93 | 71.84 | 64.08 | 52.38 | 37.84 | 53.54 |  \n| m3e-large | 34.85 | 59.74 | 67.69 | 60.07 | 48.99 | 31.62 | 46.78 |  \n| ***bce-embedding-base_v1*** | **57.60** | **65.73** | 74.96 | **69.00** | **57.29** | **38.95** | ***59.43*** |  \n\n- 更详细的评测结果详见[Embedding模型指标汇总](https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/embedding_eval_summary.md)。\n\n### 二阶段检索（rerank）\n| 模型名称 | Reranking | 平均 |  \n|:-------------------------------|:--------:|:--------:|  \n| bge-reranker-base | 57.78 | 57.78 |  \n| bge-reranker-large | 59.69 | 59.69 |  \n| ***bce-reranker-base_v1*** | **60.06** | ***60.06*** |  \n\n- 更详细的评测结果详见[Reranker模型指标汇总](https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/EvaluationSummary/reranker_eval_summary.md)\n\n### 基于LlamaIndex的RAG评测（embedding and rerank）\n\n<img src=\"https://github.com/netease-youdao/BCEmbedding/blob/master/Docs/assets/rag_eval_multiple_domains_summary.jpg\">\n\n***NOTE:***\n\n- 在WithoutReranker列中，我们的bce-embedding-base_v1模型优于所有其他embedding模型。\n- 在固定embedding模型的情况下，我们的bce-reranker-base_v1模型达到了最佳表现。\n- **bce-embedding-base_v1和bce-reranker-base_v1的组合是SOTA。**\n- 如果想单独使用embedding和rerank请参阅：[BCEmbedding](https://github.com/netease-youdao/BCEmbedding)\n\n### LLM\n\nv2.0版本QAnything不再提供本地大模型，用户可自行接入OpenAI接口兼容的其他开源大模型服务，如ollama, DashScope等。\n\n# 🚀 最近更新\n- ***2024-08-23***: **支持快速开始、前端配置参数、在线预览和编辑chunk块，极大优化项目架构和启动方式，极大优化解析和检索效果。** - 详见👉 [v2.0.0](https://github.com/netease-youdao/QAnything/releases/tag/v2.0.0)\n- ***2024-05-20***: **支持与OpenAI API兼容的其他LLM服务，并提供优化后的PDF解析器。** - 详见👉 [v1.4.1](https://github.com/netease-youdao/QAnything/releases/tag/v1.4.1)\n- ***2024-04-26***: **支持联网检索、FAQ、自定义BOT、文件溯源等。** - 详见👉 [v1.4.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.4.0-python)\n- ***2024-04-03***: **支持在纯Python环境中安装；支持混合检索。** - 详见👉 [v1.3.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.3.0)\n- ***2024-01-29***: **支持自定义大模型，包括OpenAI API和其他开源大模型，GPU需求最低降至GTX 1050Ti，极大提升部署，调试等方面的用户体验** - 详见👉 [v1.2.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.2.0)\n- ***2024-01-23***: **默认开启rerank，修复在windows上启动时存在的各类问题** - 详见👉 [v1.1.1](https://github.com/netease-youdao/QAnything/releases/tag/v1.1.1)\n- ***2024-01-18***: **支持一键启动，支持windows部署，提升pdf，xlsx，html解析效果** - 详见👉 [v1.1.0](https://github.com/netease-youdao/QAnything/releases/tag/v1.1.0)\n\n# 开始之前\n**在GitHub上加星，即可立即收到新版本的通知！**\n![star_us](https://github.com/netease-youdao/QAnything/assets/29041332/fd5e5926-b9b2-4675-9f60-6cdcaca18e14)\n* [🏄 在线试用QAnything](https://qanything.ai)\n* [📚 在线试用有道速读](https://read.youdao.com)\n* [🛠️ 想只使用BCEmbedding(embedding & rerank)](https://github.com/netease-youdao/BCEmbedding)\n* [📖 FAQ](FAQ_zh.md)\n* [👂️需求反馈 | 让我听见你的声音](https://qanything.canny.io/feature-requests)\n\n\n# 开始\n## 最新特性表\n\n| 特性                              | python （v1.4.2） | docker （v1.2.2） | 全新QAnything v2.0.0 | 说明                                                                        |\n|---------------------------------|-----------------|-----------------| ---------------- |---------------------------------------------------------------------------|\n| 详细安装文档                          | ✅               | ✅               | ✅                |                                                                           |\n| API支持                           | ✅               | ✅               | ✅                |                                                                           |\n| 生产环境（小型生产环境）                    | ❌               | ✅               | ✅                |                                                                           |\n| 离线使用                            | ❌               | ✅               | ✅                |                                                                           |\n| 支持多并发                           | ❌               | ✅               | ✅                |                                                                           |\n| 支持多卡推理                          | ❌               | ✅               | ❌                | v2.0.0版本不再提供默认本地LLM，一律通过openai接口接入，用户可自行通过ollama等工具部署本地LLM                |\n| 支持Mac（M系列芯片）                    | ✅               | ❌               | ✅                |                                                                           |\n| 支持Linux                         | ✅               | ✅               | ✅                | python旧版本Linux下默认使用onnxruntime-gpu for cuda12，glibc<2.28时自动切换为onnxruntime |\n| 支持windows （**无需WSL**）               | ❌               | ❌               | ✅                | python和docker旧版本均要求WSL环境，v2.0.0可直接在非WSL环境下启动                              |\n| 支持纯CPU环境                        | ✅               | ❌               | ✅                | v2.0.0版本Mac，Linux，Win统一不再使用GPU，完全迁移至CPU                                   |\n| 支持混合检索（BM25+embedding）          | ❌               | ✅               | ✅                |                                                                           |\n| 支持联网检索（**需外网VPN**）                  | ✅               | ❌               | ✅                |                                                                           |\n| 支持FAQ问答                         | ✅               | ❌               | ✅                |                                                                           |\n| 支持自定义机器人（可绑定知识库，可分享）            | ✅               | ❌               | ✅                |                                                                           |\n| 支持文件溯源（数据来源可直接点击打开）             | ✅               | ❌               | ✅                |                                                                           |\n| 支持问答日志检索             | ✅               | ❌               | ✅                | python和docker旧版本均只能通过API检索，v2.0.0可直接在前端检索                                 |\n| 支持解析语音文件（依赖faster_whisper，解析速度慢） | ✅               | ❌               | ❌                | 依赖whisper，速度慢且占用资源大，暂时去除                                                  |\n| 支持OpenCloudOS                   | ✅               | ❌               | ✅                |                                                                           |\n| 支持与OpenAI接口兼容的其他开源大模型服务(包括ollama) | ✅               | ✅               | ✅                | python和docker旧版本需手动修改api_key，base_url，model等参数，v2.0.0版本均改为前端设置自动保存        |\n| pdf（包含表格）解析效果+++                | ✅               | ❌               | ✅                | v1.4.2版本需手动设置，v2.0.0无需手动设置，pdf解析效果和性能均有提升                                 |\n| 用户自定义embed，rerank配置（实验性：提升速度）   | ✅               | ❌               | ✅                | v1.4.2需手动设置，v2.0.0默认使用最佳配置                                                |\n| 其他文件类型解析效果+++                   | ❌               | ❌               | ✅                | v2.0.0版本提升url，md，xlsx，docx等解析效果                                           |\n| 支持独立服务调用                        | ❌               | ❌               | ✅                | v2.0.0版本独立依赖服务，包括embed，rerank，ocr，pdf解析服务等，可独立调用（http）                    |\n| 支持快速开始模式                        | ❌               | ❌               | ✅                | 快速开始：无需创建知识库，支持文件即传即问，支持无文件问答                                             |\n| 支持仅检索模式                         | ❌               | ❌               | ✅                | 仅返回检索结果，不调用大模型进行问答                                                        |\n| 支持解析结果chunks内容可视化，手动编辑          | ❌               | ❌               | ✅                | v2.0.0版本支持手动编辑chunks内容，实时生效                                               |\n| pdf解析支持图片,支持回答带图                | ❌               | ❌               | ✅                |                                                                           |\n\n## V2.0.0版本新增细节优化：\n\n* 支持前端配置API_BASE，API_KEY，文本分片大小，输出token数量，上下文消息数量等参数\n* 优化Bot角色设定的指令遵循效果，每个Bot可单独配置模型参数\n* 支持创建多个对话窗口，同时保存多份历史问答记录\n* 支持问答记录保存成图片\n* 优化上传文件逻辑，解析文件与问答请求独立，上传文件不再影响问答\n* 优化镜像大小，旧版本镜像压缩后大小为18.94GB->新版镜像压缩后大小为4.88GB，降为原有的1/4，提供完整Dockerfile\n* 检索优化，chunks新增片段融合与排序，聚合单文档或双文档\n* 检索阶段和问答阶段均嵌入metadata信息，提升检索和问答效果\n  \n### 各阶段数据展示：\n* 知识库所有文件上传进度展示\n* 知识库单个文件上传进度展示，上传各阶段耗时\n* 问答信息统计，包含问答各阶段耗时，tokens消耗，模型信息等\n* 用户信息统计，包含上传文件总数量，总耗时，问答历史记录等\n  \n### 问题修复\n* xlsx表格支持多sheet解析\n* 优化PDF表格漏识别问题\n* 修复部分DOCX文件解析出错问题\n* 优化FAQ匹配逻辑\n* 支持非utf-8编码的txt文件\n\n\n## 新旧解析效果对比\n* 针对PDF文档：首先针对在文档中大段表格，尤其是跨页表格的解析方面，2.0版本进行了显著的改进，新版本解析逻辑能够分析表格的结构，包括行和列的布局，并且能够自动识别出表头，将其置于每个切片分割出的表格的顶部。这样的改进防止了在解析长表格时，由于逻辑上的切割而导致的意义上的中断\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170060.png) | ![image.png](docs/assets/17244247170067.png) | ![image.png](docs/assets/17244247170074.png) |\n\n* 此外，2.0版本在处理文本分栏和跨页布局的情况下也做了优化。它能够识别文本的双栏或多栏布局，并根据人类的阅读习惯来正确划分文本块的顺序。同时，该版本还能够保存文档中的图片，确保在文件解析过程中内容的完整性不会丢失。如在下图中，正确的排列顺序应该为一次排列编号1，2，3的文本为一大段并进行切块，而不是将1，2，3分别切块。\n  * 在1.4版本解析结果中，跨页文本 “更高一些” 被分块到了下一文本块中，这对大模型语义理解是不利的，而在2.0版本解析结果中是正确划分的，并且也将穿插在文本段落中的图片解析到对应的chunk语句块中，非正文本文 “图1  鉴别与授权及其支持关系  37” 和 “Cover Story 封面专题” 也成功被过滤\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170088.png) | ![image.png](docs/assets/17244247170101.png)<br/>![image.png](docs/assets/17244247170115.png) | ![image.png](docs/assets/17244247170129.png) |\n\n\n* 2.0版本在针对穿插在文本栏或文本块之间的表格解析也做了相应的优化，原先版本的解析无法识别表格，只会将其以文本段落的格式进行解析，这样不仅会破坏表格的逻辑结构，对大模型而言也是多了一段杂乱无用的文本，会影响大模型回答的准确度；而2.0版本能够识别并解析这些嵌入文本中的表格，从而提高了解析的质量和大模型回答的准确性。\n  * 在1.4版本解析结果中，穿插在文本块中的表格被当做普通文本块解析，2.0版本这可以将这种表格“优雅地”解析，不仅提高了解析的质量也增加大模型回答的准确性；\n  * 此外，2.0版本在处理特定小标题下的文本时，会优先确保这些文本被分割到同一个chunk块中，以维持逻辑上的连贯性。当文本过长，需要进行分割时，2.0版本的解析逻辑会在每个分割后的文本块前重复相同的小标题，以示归属。例如，在示例中，三个文本块都加上了相同的小标题“欧洲会议：机器人的法律地位”（由于文本过长，在原文件截图时未能显示该标题）。这种处理方式有效避免了因文本过长而导致的分割后文本块语义逻辑不连贯的问题。\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170148.png) | ![image.png](docs/assets/17244247170166.png) | ![image.png](docs/assets/17244247171267.png) |\n\n* 对于包含复杂格式的Excel（.xlsx）文档，2.0版本进行了一系列的优化措施，可以准确地识别和处理行列数据，包括合并单元格和跨行或跨列的文本等优化，具体可以看以下示例。\n  * 在1.4版本中，解析Excel文档时可能存在一些限制，特别是对于包含特殊结构或格式的文档，解析结果可能不尽如人意，主要只能识别纯文本部分。这在处理复杂数据和格式时可能导致信息丢失或格式错乱。相比之下，2.0版本在解析能力上有了显著提升，能够更好地处理各种复杂格式的Excel文档，尽管可能还未达到完美，但已经能够解决绝大多数复杂情况。\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170188.png) | ![image.png](docs/assets/17244247170208.png) | ![image.png](docs/assets/17244247170228.png) |\n\n* 同样，对于简单格式的xlsx文档，2.0版本的解析也做了优化。\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170272.png) | ![image.png](docs/assets/17244247170298.png) | ![image.png](docs/assets/17244247170323.png) |\n\n* 在最新版本中，我们对URL解析功能也进行了显著改进。以下面的页面为例，旧版本在解析过程中可能会遗漏大量页面信息，并且无法有效处理表格、列表等较为复杂的页面元素。然而，新版本已经针对这些问题进行了优化，能够更准确地解析这些内容。\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170443.png) | ![image.png](docs/assets/17244247170478.png)<br/>![image.png](docs/assets/17244247170512.png) | ![image.png](docs/assets/17244247170546.png) |\n\n* 除此之外，对于绝大多数的文件，2.0版本也做了对应的优化，包括但不限于以下几点 \n  * 改进了chunk块的切割逻辑，避免了由于文档中的空白行或段落导致的语义块过短或逻辑中断，确保了文本块的连贯性和完整性\n  * 新版本能够更准确地识别文档中的小标题，并根据这些小标题来定位和组织对应的文本块，有助于优化解析效果，使得解析的结构更加清晰，信息层次更加分明\n  * 解析结果对比如下，1.4版本解析逻辑将文档分为了10个chunk块，而2.0版本解析后只有4个chunk块，更加合理且较少的chunk块极大的提高了内容的连贯性和完整性，有助于减少因切割不当而导致的语义断裂或逻辑混乱，从而提高了整体的解析效果和模型回答的效果\n\n| 原图 | 旧版本解析效果 | 新版本解析效果 |\n|:----:|:--------------------------------------------:|:---------------------------------------------------------------------------------------------:|\n| ![image.png](docs/assets/17244247170352.png) | ![image.png](docs/assets/17244247170380.png) | ![image.png](docs/assets/17244247170406.png) |\n\n### 综上所述，2.0版本解析相较于1.4版本的解析优化了很多方面，包括但不限于\n\n1. 通过更合理的分块长度，减少了因段落过小或段落不完整而导致的语义和逻辑上的丢失。\n2. 改进了对分栏文本的识别能力，能够智能判断阅读顺序，即使是跨页的段落也能做出正确处理。\n3. 新版本能够识别并保存文本段落中的图片和表格，确保不会遗漏任何重要的文本信息。\n4. 优化表格解析，包括超出chunk块限制的长表格和复杂结构的xlsx文件的解析和存储\n5. 根据识别文档中的小标题，定位和组织对应的文本块，使得解析的结构更加清晰，信息层次更加分明\n6. 优化对于网页url的解析结果，转为.md格式\n7. 支持更多编码格式的txt文件和docx文件\n\n\n## 安装\n### 必要条件\n| **系统**    | **依赖**                  | **要求**            | **说明**                                                                                 |\n|-----------|-------------------------|-------------------|----------------------------------------------------------------------------------------|\n|           | RAM Memory              | >= 20GB           |                                                                                        |\n| Linux/Mac | Docker version          | >= 20.10.5        | [Docker install](https://docs.docker.com/engine/install/)                              |\n| Linux/Mac | docker compose  version | >= 2.23.3         | [docker compose install](https://docs.docker.com/compose/install/)                     |\n| Windows   | Docker Desktop          | >= 4.26.1（131620） | [Docker Desktop for Windows](https://docs.docker.com/desktop/install/windows-install/) |\n\n\n### step1: 下载本项目\n```shell\ngit clone https://github.com/netease-youdao/QAnything.git\n```\n### step2: 进入项目根目录执行启动命令\n* 执行 docker compose 启动命令\n* **启动过程大约需要30秒左右，当日志输出\"qanything后端服务已就绪!\"后，启动完毕！** \n```shell\ncd QAnything\n# 在 Linux 上启动\ndocker compose -f docker-compose-linux.yaml up\n# 在 Mac 上启动\ndocker compose -f docker-compose-mac.yaml up\n# 在 Windows 上启动\ndocker compose -f docker-compose-win.yaml up\n```\n\n（注意）如果启动失败，可以尝试将 `docker compose`改为 `docker-compose`。\n（注意）镜像手动下载地址：\n- [win](https://pan.baidu.com/s/1tVZ7J-3dwblvRGv1-N6J5A?pwd=bfna)\n- [mac](https://pan.baidu.com/s/1lxUq0ZOIzVCa3RXTp6Uozg?pwd=5w4i)\n- [linux](https://pan.baidu.com/s/1kqyGhBOUjBfk8zAeaVddzg?pwd=j72b)\n加载方式：\n```shell\ndocker load -i qanything_xxx.tar\n```\n\n### step3: 开始体验\n\n#### 前端页面\n运行成功后，即可在浏览器输入以下地址进行体验。\n\n- 前端地址: http://localhost:8777/qanything/\n\n### API\n如果想要访问API接口，请参考下面的地址:\n- API address: http://localhost:8777/api/\n- For detailed API documentation, please refer to [QAnything API 文档](docs/API.md)\n\n### DEBUG\n##### 如果想要查看服务启动相关日志，请查看`QAnything/logs/debug_logs`目录下的日志文件。\n- **debug.log**\n  - 用户请求处理日志\n- **main_server.log**\n  - 后端服务运行日志\n- **rerank_server.log**\n  - rerank服务运行日志\n- **ocr_server.log**\n  - OCR服务运行日志\n- **embedding_server.log**\n  - 向量化服务运行日志\n- **rerank_server.log**\n  - 检索增强服务运行日志\n- **insert_files_server.log**\n  - 文件上传服务运行日志\n- **pdf_parser_server.log**\n  - pdf解析服务运行日志\n##### 详细上传文件日志请查看`QAnything/logs/insert_logs`目录下的日志文件。\n##### 详细问答日志请查看`QAnything/logs/qa_logs`目录下的日志文件。\n##### 详细embedding日志请查看`QAnything/logs/embed_logs`目录下的日志文件。\n##### 详细rerank日志请查看`QAnything/logs/rerank_logs`目录下的日志文件。\n\n### 关闭服务\n```shell\n# 前台启动服务方式如下：\ndocker compose -f docker-compose-xxx.yaml up # 关闭服务请按Ctrl+C\n# 后台启动服务方式如下：\ndocker compose -f docker-compose-xxx.yaml up -d  # 关闭服务请执行以下命令\ndocker compose -f docker-compose-xxx.yaml down\n```\n\n## 离线使用\n如果您想要离线使用QAnything，需要在断网机器提前部署本地的大模型（推荐使用ollama），随后可以使用以下命令启动服务。\n### windows离线使用\n```shell \n# 先在联网机器上下载docker镜像\ndocker pull quay.io/coreos/etcd:v3.5.5\ndocker pull minio/minio:RELEASE.2023-03-20T20-16-18Z\ndocker pull milvusdb/milvus:v2.4.8\ndocker pull mysql:8.4\ndocker pull docker.elastic.co/elasticsearch/elasticsearch:8.13.2\ndocker pull xixihahaliu01/qanything-win:v1.5.1  # 从 [https://github.com/netease-youdao/QAnything/blob/master/docker-compose-windows.yaml#L103] 中获取最新镜像版本号。\n\n# 打包镜像\ndocker save quay.io/coreos/etcd:v3.5.5 minio/minio:RELEASE.2023-03-20T20-16-18Z milvusdb/milvus:v2.4.8 mysql:8.4 docker.elastic.co/elasticsearch/elasticsearch:8.13.2 xixihahaliu01/qanything-win:v1.5.1 -o qanything_offline.tar\n\n# 下载QAnything代码\nwget https://github.com/netease-youdao/QAnything/archive/refs/heads/master.zip\n\n# 把镜像qanything_offline.tar和代码QAnything-master.zip拷贝到断网机器上\ncp QAnything-master.zip qanything_offline.tar /path/to/your/offline/machine\n\n# 在断网机器上加载镜像\ndocker load -i qanything_offline.tar\n\n# 解压代码，运行\nunzip QAnything-master.zip\ncd QAnything-master\ndocker compose -f docker-compose-win.yaml up\n```\n\n### Linux离线使用\n```shell \n# 先在联网机器上下载docker镜像\ndocker pull quay.io/coreos/etcd:v3.5.5\ndocker pull minio/minio:RELEASE.2023-03-20T20-16-18Z\ndocker pull milvusdb/milvus:v2.4.8\ndocker pull mysql:8.4\ndocker pull docker.elastic.co/elasticsearch/elasticsearch:8.13.2\ndocker pull xixihahaliu01/qanything-linux:v1.5.1  # 从 [https://github.com/netease-youdao/qanything/blob/master/docker-compose-linux.yaml#L104] 中获取最新镜像版本号。\n\n# 打包镜像\ndocker save quay.io/coreos/etcd:v3.5.5 minio/minio:RELEASE.2023-03-20T20-16-18Z milvusdb/milvus:v2.4.8 mysql:8.4 docker.elastic.co/elasticsearch/elasticsearch:8.13.2 xixihahaliu01/qanything-linux:v1.5.1 -o qanything_offline.tar\n\n# 下载QAnything代码\nwget https://github.com/netease-youdao/QAnything/archive/refs/heads/master.zip\n\n# 把镜像qanything_offline.tar和代码QAnything-master.zip拷贝到断网机器上\ncp QAnything-master.zip qanything_offline.tar /path/to/your/offline/machine\n\n# 在断网机器上加载镜像\ndocker load -i qanything_offline.tar\n\n# 解压代码，运行\nunzip QAnything-master.zip\ncd QAnything-master\ndocker compose -f docker-compose-linux.yaml up\n```\n\n## 常见问题\n### 目前最常见的问题是ollama本地服务问答效果不佳，可以参考faq中的解决方案\n[常见问题](FAQ_zh.md)\n\n## 贡献代码\n我们感谢您对贡献到我们项目的兴趣。无论您是修复错误、改进现有功能还是添加全新内容，我们都欢迎您的贡献！\n\n### 感谢以下所有贡献者\n<a href=\"https://github.com/netease-youdao/QAnything/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=netease-youdao/QAnything\" />\n</a>\n\n# 🛣️ 路线图 & 反馈\n🔎 想了解QAnything的未来规划和进展，请看这里： [QAnything Roadmap](https://qanything.canny.io/)\n\n🤬 想要给QAnything提交反馈，请看这里(可以给每个功能需求投票哦): [QAnything Feedbak](https://qanything.canny.io/feature-requests)\n\n# 交流 & 支持\n\n## Discord <a href=\"https://discord.gg/5uNpPsEJz8\"><img src=\"https://img.shields.io/discord/1197874288963895436?style=social&logo=discord\"></a>\n欢迎加入QAnything [Discord](https://discord.gg/5uNpPsEJz8) 社区！\n\n\n\n## 微信\n欢迎关注微信公众号，获取最新QAnything信息\n\n<img src=\"docs/images/qrcode_for_qanything.jpg\" width=\"30%\" height=\"auto\">\n\n欢迎扫码进入QAnything交流群\n\n<img src=\"docs/images/Wechat.jpg\" width=\"30%\" height=\"auto\">\n\n## 邮箱\n如果你需要私信我们团队，请通过下面的邮箱联系我们：\n\nqanything@rd.netease.com\n\n## GitHub issues & discussions\n有任何公开的问题，欢迎提交issues，或者在discussions区讨论\n- [Github issues](https://github.com/netease-youdao/QAnything/issues)\n- [Github discussions](https://github.com/netease-youdao/QAnything/discussions)\n\n<a href=\"https://github.com/netease-youdao/QAnything/discussions\">\n  <!-- Please provide path to your logo here -->\n  <img src=\"https://github.com/netease-youdao/QAnything/assets/29041332/ad027ec5-0bbc-4ea0-92eb-81b30c5359a1\" alt=\"Logo\" width=\"600\">\n</a>\n\n# Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=netease-youdao/QAnything,netease-youdao/BCEmbedding&type=Date)](https://star-history.com/#netease-youdao/QAnything&netease-youdao/BCEmbedding&Date)\n\n# 协议\n\n`QAnything` 依照 [AGPL-3.0](./LICENSE)开源。\n\n# Acknowledgements\n- [BCEmbedding](https://github.com/netease-youdao/BCEmbedding)\n- [Qwen](https://github.com/QwenLM/Qwen)\n- [Triton Inference Server](https://github.com/triton-inference-server/server)\n- [vllm](https://github.com/vllm-project/vllm)\n- [FastChat](https://github.com/lm-sys/FastChat)\n- [FasterTransformer](https://github.com/NVIDIA/FasterTransformer)\n- [Langchain](https://github.com/langchain-ai/langchain)\n- [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat)\n- [Milvus](https://github.com/milvus-io/milvus)\n- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) \n- [Sanic](https://github.com/sanic-org/sanic)\n- [RAGFlow](https://github.com/infiniflow/ragflow)\n"
        },
        {
          "name": "build_images",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose-linux.yaml",
          "type": "blob",
          "size": 3.7548828125,
          "content": "services:\n  elasticsearch:\n    container_name: es-container-local\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.2\n    user: root\n    privileged: true\n    ports:\n      - \"9210:9200\"\n    restart: on-failure\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n      - \"ES_JAVA_OPTS=-Xms1024m -Xmx1024m\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/third_party/es/plugins:/usr/share/elasticsearch/plugins\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/es/data:/usr/share/elasticsearch/data\n    command: >\n      /bin/bash -c \"\n        mkdir -p /usr/share/elasticsearch/data /usr/share/elasticsearch/plugins &&\n        chown -R elasticsearch:elasticsearch /usr/share/elasticsearch &&\n        su elasticsearch -c '/usr/share/elasticsearch/bin/elasticsearch'\n      \"\n    healthcheck:\n      test: curl --fail http://localhost:9200/_cat/health || exit 1\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  etcd:\n    container_name: milvus-etcd-local\n    image: quay.io/coreos/etcd:v3.5.5\n    environment:\n      - ETCD_AUTO_COMPACTION_MODE=revision\n      - ETCD_AUTO_COMPACTION_RETENTION=1000\n      - ETCD_QUOTA_BACKEND_BYTES=4294967296\n      - ETCD_SNAPSHOT_COUNT=50000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd\n    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd\n    healthcheck:\n      test: [\"CMD\", \"etcdctl\", \"endpoint\", \"health\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  minio:\n    container_name: milvus-minio-local\n    image: minio/minio:RELEASE.2023-03-20T20-16-18Z\n    environment:\n      MINIO_ACCESS_KEY: minioadmin\n      MINIO_SECRET_KEY: minioadmin\n    # ports:\n    #   - \"9001:9001\"\n    #       - \"9000:9000\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data\n    command: minio server /minio_data --console-address \":9001\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  standalone:\n    container_name: milvus-standalone-local\n    image: milvusdb/milvus:v2.4.8\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"100m\"\n        max-file: \"3\"\n    command: [\"milvus\", \"run\", \"standalone\"]\n    security_opt:\n    - seccomp:unconfined\n    environment:\n      ETCD_ENDPOINTS: etcd:2379\n      MINIO_ADDRESS: minio:9000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9091/healthz\"]\n      interval: 10s\n      start_period: 90s\n      timeout: 20s\n      retries: 3\n    ports:\n      - \"19540:19530\"\n    depends_on:\n      - \"etcd\"\n      - \"minio\"\n\n  mysql:\n    container_name: mysql-container-local\n    privileged: true\n    image: mysql:8.4\n    ports:\n      - \"3316:3306\"\n    command: --max-connections=10000\n    environment:\n      - MYSQL_ROOT_PASSWORD=123456\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/mysql:/var/lib/mysql\n\n\n  qanything_local:\n    container_name: qanything-container-local\n    image: xixihahaliu01/qanything-linux:v1.5.1\n    command: /bin/bash -c \"cd /workspace/QAnything && bash scripts/entrypoint.sh\"\n    privileged: true\n    shm_size: '8gb'\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/:/workspace/QAnything/\n    # ports:\n    #   - \"8777:8777\"\n    network_mode: \"host\"\n    environment:\n      - NCCL_LAUNCH_MODE=PARALLEL\n      - GPUID=${GPUID:-0}\n      - USER_IP=${USER_IP:-0.0.0.0}\n      - Gateway_IP=${Gateway_IP:-0.0.0.0}\n    depends_on:\n      standalone:\n        condition: service_healthy\n      mysql:\n        condition: service_started\n      elasticsearch:\n        condition: service_healthy\n    tty: true\n    stdin_open: true\n\n#networks:\n#  default:\n#    name: QAnything\n\n"
        },
        {
          "name": "docker-compose-mac.yaml",
          "type": "blob",
          "size": 3.68359375,
          "content": "#networks:\n#  default:\n#    name: QAnything\n\nservices:\n  elasticsearch:\n    container_name: es-container-local\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.2\n    user: root\n    privileged: true\n    ports:\n      - \"9210:9200\"\n    restart: on-failure\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n      - \"ES_JAVA_OPTS=-Xms1024m -Xmx1024m\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/third_party/es/plugins:/usr/share/elasticsearch/plugins\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/es/data:/usr/share/elasticsearch/data\n    command: >\n      /bin/bash -c \"\n        mkdir -p /usr/share/elasticsearch/data /usr/share/elasticsearch/plugins &&\n        chown -R elasticsearch:elasticsearch /usr/share/elasticsearch &&\n        su elasticsearch -c '/usr/share/elasticsearch/bin/elasticsearch'\n      \"\n    healthcheck:\n      test: curl --fail http://localhost:9200/_cat/health || exit 1\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  etcd:\n    container_name: milvus-etcd-local\n    image: quay.io/coreos/etcd:v3.5.5\n    environment:\n      - ETCD_AUTO_COMPACTION_MODE=revision\n      - ETCD_AUTO_COMPACTION_RETENTION=1000\n      - ETCD_QUOTA_BACKEND_BYTES=4294967296\n      - ETCD_SNAPSHOT_COUNT=50000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd\n    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd\n    healthcheck:\n      test: [\"CMD\", \"etcdctl\", \"endpoint\", \"health\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  minio:\n    container_name: milvus-minio-local\n    image: minio/minio:RELEASE.2023-03-20T20-16-18Z\n    environment:\n      MINIO_ACCESS_KEY: minioadmin\n      MINIO_SECRET_KEY: minioadmin\n    # ports:\n    #   - \"9001:9001\"\n    #       - \"9000:9000\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data\n    command: minio server /minio_data --console-address \":9001\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  standalone:\n    container_name: milvus-standalone-local\n    image: milvusdb/milvus:v2.4.8\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"100m\"\n        max-file: \"3\"\n    command: [\"milvus\", \"run\", \"standalone\"]\n    security_opt:\n    - seccomp:unconfined\n    environment:\n      ETCD_ENDPOINTS: etcd:2379\n      MINIO_ADDRESS: minio:9000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9091/healthz\"]\n      interval: 10s\n      start_period: 90s\n      timeout: 20s\n      retries: 3\n    ports:\n      - \"19540:19530\"\n    depends_on:\n      - \"etcd\"\n      - \"minio\"\n\n  mysql:\n    container_name: mysql-container-local\n    privileged: true\n    image: docker.io/library/mysql:8.4\n    ports:\n      - \"3316:3306\"\n    command: --max-connections=10000\n    environment:\n      - MYSQL_ROOT_PASSWORD=123456\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/mysql:/var/lib/mysql\n\n\n  qanything_local:\n    container_name: qanything-container-local\n    image: xixihahaliu01/qanything-mac:v1.5.1\n    command: /bin/bash -c \"cd /workspace/QAnything && bash scripts/entrypoint.sh\"\n    privileged: true\n    shm_size: '8gb'\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/:/workspace/QAnything/\n    ports:\n      - \"8777:8777\"\n    environment:\n      - USER_IP=${USER_IP:-0.0.0.0}\n      - GATEWAY_IP=host.docker.internal\n    depends_on:\n      standalone:\n        condition: service_healthy\n      mysql:\n        condition: service_started\n      elasticsearch:\n        condition: service_healthy\n    tty: true\n    stdin_open: true\n\n\n\n"
        },
        {
          "name": "docker-compose-win.yaml",
          "type": "blob",
          "size": 3.728515625,
          "content": "services:\n  elasticsearch:\n    container_name: es-container-local\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.2\n    user: root\n    privileged: true\n    ports:\n      - \"9210:9200\"\n    restart: on-failure\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n      - \"ES_JAVA_OPTS=-Xms1024m -Xmx1024m\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/third_party/es/plugins:/usr/share/elasticsearch/plugins\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/es/data:/usr/share/elasticsearch/data\n    command: >\n      /bin/bash -c \"\n          mkdir -p /usr/share/elasticsearch/data /usr/share/elasticsearch/plugins &&\n          chown -R elasticsearch:elasticsearch /usr/share/elasticsearch &&\n          su elasticsearch -c '/usr/share/elasticsearch/bin/elasticsearch'\n      \"\n    healthcheck:\n      test: curl --fail http://localhost:9200/_cat/health || exit 1\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  etcd:\n    container_name: milvus-etcd-local\n    image: quay.io/coreos/etcd:v3.5.5\n    environment:\n      - ETCD_AUTO_COMPACTION_MODE=revision\n      - ETCD_AUTO_COMPACTION_RETENTION=1000\n      - ETCD_QUOTA_BACKEND_BYTES=4294967296\n      - ETCD_SNAPSHOT_COUNT=50000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd\n    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd\n    healthcheck:\n      test: [\"CMD\", \"etcdctl\", \"endpoint\", \"health\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  minio:\n    container_name: milvus-minio-local\n    image: minio/minio:RELEASE.2023-03-20T20-16-18Z\n    environment:\n      MINIO_ACCESS_KEY: minioadmin\n      MINIO_SECRET_KEY: minioadmin\n    # ports:\n    #   - \"9001:9001\"\n    #       - \"9000:9000\"\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data\n    command: minio server /minio_data --console-address \":9001\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n      interval: 10s\n      timeout: 20s\n      retries: 3\n\n  standalone:\n    container_name: milvus-standalone-local\n    image: milvusdb/milvus:v2.4.8\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"100m\"\n        max-file: \"3\"\n    command: [\"milvus\", \"run\", \"standalone\"]\n    security_opt:\n    - seccomp:unconfined\n    environment:\n      ETCD_ENDPOINTS: etcd:2379\n      MINIO_ADDRESS: minio:9000\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9091/healthz\"]\n      interval: 10s\n      start_period: 90s\n      timeout: 20s\n      retries: 3\n    ports:\n      - \"19540:19530\"\n    depends_on:\n      - \"etcd\"\n      - \"minio\"\n\n  mysql:\n    container_name: mysql-container-local\n    privileged: true\n    image: mysql:8.4\n    ports:\n      - \"3316:3306\"\n    command: --max-connections=10000\n    environment:\n      - MYSQL_ROOT_PASSWORD=123456\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/mysql:/var/lib/mysql\n\n\n  qanything_local:\n    container_name: qanything-container-local\n    image: xixihahaliu01/qanything-win:v1.5.1\n    command: /bin/bash -c \"cd /workspace/QAnything && bash scripts/entrypoint.sh\"\n    privileged: true\n    shm_size: '8gb'\n    volumes:\n      - ${DOCKER_VOLUME_DIRECTORY:-.}/:/workspace/QAnything/\n    ports:\n      - \"8777:8777\"\n    environment:\n      - NCCL_LAUNCH_MODE=PARALLEL\n      - GPUID=${GPUID:-0}\n      - USER_IP=${USER_IP:-0.0.0.0}\n      - GATEWAY_IP=host.docker.internal\n    depends_on:\n      standalone:\n        condition: service_healthy\n      mysql:\n        condition: service_started\n      elasticsearch:\n        condition: service_healthy\n    tty: true\n    stdin_open: true\n\n#networks:\n#  default:\n#    name: QAnything\n\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "qanything_kernel",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 1.1396484375,
          "content": "concurrent-log-handler==0.9.25\nboto3==1.34.79\nsanic==23.6.0\nsanic_ext==23.6.0\nlangchain-core==0.1.50\nlangchain==0.1.9\nunstructured==0.12.4\nunstructured[pptx]==0.12.4\nunstructured[md]==0.12.4\nopencv-python-headless==4.9.0.80\npython-dotenv==1.0.1\nmysql-connector-python==8.2.0\npymilvus==2.3.6\nlangchain-openai==0.0.8\naiomysql==0.2.0\n# PyMuPDFb==1.24.3  #\nPyMuPDF==1.24.4  #\nopenpyxl==3.1.2\nnetworkx==3.2.1\npython-docx==1.1.0\nnewspaper4k==0.9.3.1\nnewspaper4k[zh]\nduckduckgo-search==5.3.0b4\nhtml2text==2024.2.26\nfsspec==2024.3.1\nmistune==3.0.2\nflair==0.13.0\nnltk==3.8.1\ntransformers==4.36.2\n# dspy-ai==2.1.1\npandas==2.1.1\nscikit-learn==1.3.2\nchardet==5.2.0\nsentence-transformers==2.2.2\nscipy==1.10.1\nfastchat==0.1.0\nwikipedia==1.4.0\nWikipedia-API==0.6.0\nrouge-score==0.1.2\ntoml==0.10.2\ntqdm==4.66.1\nanthropic==0.25.7\nstreamlit==1.34.0\nopenai==1.13.4\nzhipuai==2.0.1.20240429\nlangchain_elasticsearch==0.2.2\ntiktoken==0.7.0\nmodelscope==1.13.0\nonnxruntime==1.17.1\ncryptography==42.0.8\nshapely==2.0.4\npyclipper==1.3.0.post5\nxgboost==2.0.3\npdfplumber==0.11.0\nmarkdownify==0.12.1\ndatrie==0.8.2\nhanziconv==0.3.2\nPyPDF2==3.0.1\nlxml_html_clean==0.1.1\ndocx2txt==0.8\nipython==8.26.0\n"
        },
        {
          "name": "run.sh",
          "type": "blob",
          "size": 5.0458984375,
          "content": "#!/bin/bash\n\n# 函数：更新或追加键值对到.env文件\nupdate_or_append_to_env() {\n  local key=$1\n  local value=$2\n  local env_file=\".env\"\n\n  # 如果不存在.env文件，则创建\n  if [ ! -f \"$env_file\" ]; then\n    touch \"$env_file\"\n  fi\n\n  # 确保文件以换行符结束\n  sed -i'' -e '$a\\' \"$env_file\"\n\n  # 检查键是否存在于.env文件中\n  if grep -q \"^${key}=\" \"$env_file\"; then\n    # 如果键存在，则更新它的值\n    if [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n      # macOS (BSD sed)\n      sed -i '' \"/^${key}=/c\\\\\n${key}=${value}\" \"$env_file\"\n    else\n      # Linux (GNU sed)\n      sed -i \"/^${key}=/c\\\\${key}=${value}\" \"$env_file\"\n    fi\n  else\n    # 如果键不存在，则追加键值对到文件\n    echo \"${key}=${value}\" >> \"$env_file\"\n  fi\n\n  # 再次确保文件以换行符结束\n  sed -i'' -e '$a\\' \"$env_file\"\n}\n\n\n\n# 检测支持的 Docker Compose 命令\nif docker compose version &>/dev/null; then\n  DOCKER_COMPOSE_CMD=\"docker compose\"\nelif docker-compose version &>/dev/null; then\n  DOCKER_COMPOSE_CMD=\"docker-compose\"\nelse\n  echo \"无法找到 'docker compose' 或 'docker-compose' 命令。\"\n  exit 1\nfi\n\n# 检查master分支是否有新代码\n# 定义颜色\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\n\n# 默认 device_id\ndevice_id=\"-1\"\n\nusage() {\n    echo \"Usage: $0 [-i <device_id>]\"\n    echo \" -i <device_id>: Specify GPU device_id\"\n    exit 1\n}\n\nwhile getopts \"i:\" opt; do\n    case $opt in\n        i) device_id=$OPTARG ;;\n        *) usage ;;\n    esac\ndone\n\n\n# 检查device_id是否是0-9或-1\nif [[ ! $device_id =~ ^[0-9]|-1$ ]]; then\n    echo \"device_id 必须是0-9或-1\"\n    exit 1\nfi\n\n\necho \"device_id=${device_id}\"\n\n# if device_id是-1，则提示在cpu上启动\nif [[ $device_id == \"-1\" ]]; then\n    echo \"将在CPU上启动服务\"\nelse\n    echo \"将在GPU $device_id 上启动服务\"\nfi\n\nupdate_or_append_to_env \"GPUID\" \"$device_id\"\n\n# 读取环境变量中的用户信息\nsource .env\n\n# 检查是否存在USER_IP\nif [ -z \"${USER_IP}\" ]; then\n    # 如果USER_IP不存在，询问用户并保存配置\n    read -p \"Are you running the code on a remote server or on your local machine? (remote/local) 您是在云服务器上还是本地机器上启动代码？(remote/local) \" answer\n    if [[ $answer == \"local\" || $answer == \"本地\" ]]; then\n        ip=\"localhost\"\n    else\n        read -p \"Please enter the server IP address 请输入服务器公网IP地址(示例：10.234.10.144): \" ip\n        echo \"当前设置的远程服务器IP地址为 $ip, QAnything启动后，本地前端服务位于（浏览器打开[http://$ip:8777/qanything/]），请知悉！\"\n        sleep 5\n    fi\n\n    # 保存配置\n    update_or_append_to_env \"USER_IP\" \"$ip\"\n\nelse\n    # 读取上次的配置\n    ip=$USER_IP\n    read -p \"Do you want to use the previous ip: $ip? (yes/no) 是否使用上次的ip: $ip ？(yes/no) 回车默认选yes，请输入:\" use_previous\n    use_previous=${use_previous:-yes}\n    if [[ $use_previous != \"yes\" && $use_previous != \"是\" ]]; then\n        read -p \"Are you running the code on a remote server or on your local machine? (remote/local) 您是在远程服务器上还是本地机器上启动代码？(remote/local) \" answer\n        if [[ $answer == \"local\" || $answer == \"本地\" ]]; then\n            ip=\"localhost\"\n        else\n            read -p \"Please enter the server IP address 请输入服务器公网IP地址(示例：10.234.10.144): \" ip\n            echo \"当前设置的远程服务器IP地址为 $ip, QAnything启动后，本地前端服务位于（浏览器打开[http://$ip:8777/qanything/]），请知悉！\"\n            sleep 5\n        fi\n        # 保存新的配置\n        update_or_append_to_env \"USER_IP\" \"$ip\"\n    fi\nfi\n\nif [ -e /proc/version ]; then\n  if grep -qi microsoft /proc/version || grep -qi MINGW /proc/version; then\n    # 不支持Windows\n    echo \"当前版本不支持Windows，请在Linux环境下运行此脚本\"\n  else\n    echo \"Running under native Linux\"\n  if $DOCKER_COMPOSE_CMD -f docker-compose-linux.yaml down 2>&1 | tee /dev/tty | grep -q \"services.qanything_local.deploy.resources.reservations value 'devices' does not match any of the regexes\"; then\n    echo \"检测到 Docker Compose 版本过低，请升级到v2.23.3或更高版本。执行docker-compose -v查看版本。\"\n  fi\n\n    # 如果不存在volumes，则创建\n    if [ ! -d \"volumes/es/data\" ]; then\n        mkdir -p volumes/es/data\n        chmod 777 -R volumes/es/data\n    fi\n\n    $DOCKER_COMPOSE_CMD -f docker-compose-linux.yaml up -d\n    $DOCKER_COMPOSE_CMD -f docker-compose-linux.yaml logs -f qanything_local\n    # 检查日志输出\n  fi\nelse\n  echo \"Running under Macos\"\n  if $DOCKER_COMPOSE_CMD -f docker-compose-mac.yaml down 2>&1 | tee /dev/tty | grep -q \"services.qanything_local.deploy.resources.reservations value 'devices' does not match any of the regexes\"; then\n    echo \"检测到 Docker Compose 版本过低，请升级到v2.23.3或更高版本。执行docker-compose -v查看版本。\"\n  fi\n\n  $DOCKER_COMPOSE_CMD -f docker-compose-mac.yaml up -d\n  $DOCKER_COMPOSE_CMD -f docker-compose-mac.yaml logs -f qanything_local\nfi\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}