{
  "metadata": {
    "timestamp": 1736561249862,
    "page": 240,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "smicallef/spiderfoot",
      "stars": 13483,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.1259765625,
          "content": ".git/\n\nbuild\ndist\n*.egg-info\n*.egg/\n*.pyc\n*.swp\n\nvenv/\ncache/\nlog/\nspiderfoot.db*\nspiderfoot.test.db\n\n__pycache__\nhtmlcov/\ndocs/\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 4.3037109375,
          "content": "# SpiderFoot specific #\n#######################\n/cache/\n/log/\n/spiderfoot.db*\npasswd\nspiderfoot.crt\nspiderfoot.key\n\nspiderfoot/static/node_modules/*\n\nspiderfoot/static/node_modules/alertifyjs/*\nspiderfoot/static/node_modules/alertifyjs/build/*\nspiderfoot/static/node_modules/alertifyjs/build/css/*\n\n!spiderfoot/static/node_modules/alertifyjs/\n!spiderfoot/static/node_modules/alertifyjs/build/\n!spiderfoot/static/node_modules/alertifyjs/build/alertify.min.js\n!spiderfoot/static/node_modules/alertifyjs/build/css/\n!spiderfoot/static/node_modules/alertifyjs/build/css/alertify.min.css\n\nspiderfoot/static/node_modules/bootstrap/*\nspiderfoot/static/node_modules/bootstrap/dist/*\nspiderfoot/static/node_modules/bootstrap/dist/js/*\nspiderfoot/static/node_modules/bootstrap/dist/css/*\nspiderfoot/static/node_modules/bootstrap/dist/fonts/*\n\n!spiderfoot/static/node_modules/bootstrap/\n!spiderfoot/static/node_modules/bootstrap/dist/\n!spiderfoot/static/node_modules/bootstrap/dist/js/\n!spiderfoot/static/node_modules/bootstrap/dist/js/bootstrap.min.js\n!spiderfoot/static/node_modules/bootstrap/dist/css/\n!spiderfoot/static/node_modules/bootstrap/dist/css/bootstrap.min.css\n!spiderfoot/static/node_modules/bootstrap/dist/fonts/\n!spiderfoot/static/node_modules/bootstrap/dist/fonts/glyphicons-halflings-regular.woff\n!spiderfoot/static/node_modules/bootstrap/dist/fonts/glyphicons-halflings-regular.woff2\n\nspiderfoot/static/node_modules/jquery/*\nspiderfoot/static/node_modules/jquery/dist/*\n\n!spiderfoot/static/node_modules/jquery/\n!spiderfoot/static/node_modules/jquery/dist/\n!spiderfoot/static/node_modules/jquery/dist/jquery.min.js\n\nspiderfoot/static/node_modules/sigma/*\nspiderfoot/static/node_modules/sigma/build/*\nspiderfoot/static/node_modules/sigma/build/plugins/*\n\n!spiderfoot/static/node_modules/sigma/\n!spiderfoot/static/node_modules/sigma/build/\n!spiderfoot/static/node_modules/sigma/build/sigma.min.js\n!spiderfoot/static/node_modules/sigma/build/plugins/\n!spiderfoot/static/node_modules/sigma/build/plugins/sigma.parsers.json.min.js\n!spiderfoot/static/node_modules/sigma/build/plugins/sigma.plugins.dragNodes.min.js\n!spiderfoot/static/node_modules/sigma/build/plugins/sigma.layout.forceAtlas2.min.js\n!spiderfoot/static/node_modules/sigma/build/plugins/sigma.renderers.snapshot.min.js\n\nspiderfoot/static/node_modules/tablesorter/*\nspiderfoot/static/node_modules/tablesorter/dist/*\nspiderfoot/static/node_modules/tablesorter/dist/js/*\nspiderfoot/static/node_modules/tablesorter/dist/css/*\nspiderfoot/static/node_modules/tablesorter/dist/js/extras/*\n\n!spiderfoot/static/node_modules/tablesorter/\n!spiderfoot/static/node_modules/tablesorter/dist/\n!spiderfoot/static/node_modules/tablesorter/dist/css/\n!spiderfoot/static/node_modules/tablesorter/dist/css/jquery.tablesorter.pager.min.css\n!spiderfoot/static/node_modules/tablesorter/dist/css/theme.default.min.css\n!spiderfoot/static/node_modules/tablesorter/dist/js/\n!spiderfoot/static/node_modules/tablesorter/dist/js/jquery.tablesorter.min.js\n!spiderfoot/static/node_modules/tablesorter/dist/js/jquery.tablesorter.widgets.min.js\n!spiderfoot/static/node_modules/tablesorter/dist/js/extras/\n!spiderfoot/static/node_modules/tablesorter/dist/js/extras/jquery.tablesorter.pager.min.js\n\nspiderfoot/static/node_modules/d3/*\n\n!spiderfoot/static/node_modules/d3/\n!spiderfoot/static/node_modules/d3/d3.min.js\n\n# Compiled source #\n###################\n__pycache__/\n*.com\n*.class\n*.dll\n*.exe\n*.o\n*.so\n*.py[cod]\n*$py.class\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# Packages #\n############\n# it's better to unpack these files and commit the raw source\n# git has its own built in compression methods\n*.7z\n*.dmg\n*.gz\n*.iso\n*.jar\n*.rar\n*.tar\n*.zip\n\n# Logs and databases #\n######################\n*.log\n*.sqlite\n*.db\n\n# OS generated files #\n######################\n.DS_Store\n.DS_Store?\n._*\n.Spotlight-V100\n.Trashes\n.*~\nIcon?\nehthumbs.db\nThumbs.db\n\n# Virtual environments #\n########################\nvenv/\nvenv3/\n\n# IDE #\n#######\n.idea\n.vscode\n\n# Test & Coverage Reports #\n###########################\n.coverage\ncoverage/\ntest/acceptance/results/\nhtmlcov/\nreport/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Documentation #\n#################\ndocs/_build/\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 14.4208984375,
          "content": "[MASTER]\n\n# A comma-separated list of package or module names from where C extensions may\n# be loaded. Extensions are loading into the active Python interpreter and may\n# run arbitrary code\nextension-pkg-whitelist=\n\n# Add files or directories to the blacklist. They should be base names, not\n# paths.\nignore=CVS\n\n# Add files or directories matching the regex patterns to the blacklist. The\n# regex matches against base names, not paths.\nignore-patterns=\n\n# Python code to execute, usually for sys.path manipulation such as\n# pygtk.require().\n#init-hook=\n\n# Use multiple processes to speed up Pylint.\njobs=4\n\n# List of plugins (as comma separated values of python modules names) to load,\n# usually to register additional checkers.\nload-plugins=\n\n# Pickle collected data for later comparisons.\npersistent=yes\n\n# Specify a configuration file.\n#rcfile=\n\n# When enabled, pylint would attempt to guess common misconfiguration and emit\n# user-friendly hints instead of false-positive error messages\nsuggestion-mode=yes\n\n# Allow loading of arbitrary C extensions. Extensions are imported into the\n# active Python interpreter and may run arbitrary code.\nunsafe-load-any-extension=no\n\n\n[MESSAGES CONTROL]\n\n# Only show warnings with the listed confidence levels. Leave empty to show\n# all. Valid levels: HIGH, INFERENCE, INFERENCE_FAILURE, UNDEFINED\nconfidence=\n\n# Disable the message, report, category or checker with the given id(s). You\n# can either give multiple identifiers separated by comma (,) or put this\n# option multiple times (only on the command line, not in the configuration\n# file where it should appear only once).You can also use \"--disable=all\" to\n# disable everything first and then reenable specific checks. For example, if\n# you want to run only the similarities checker, you can use \"--disable=all\n# --enable=similarities\". If you want to run only the classes checker, but have\n# no Warning level messages displayed, use\"--disable=all --enable=classes\n# --disable=W\"\ndisable=invalid-name,\n        no-self-use,\n        too-few-public-methods,\n        too-many-ancestors,\n        too-many-arguments,\n        too-many-boolean-expressions,\n        too-many-branches,\n        too-many-instance-attributes,\n        too-many-locals,\n        too-many-nested-blocks,\n        too-many-public-methods,\n        too-many-return-statements,\n        too-many-statements,\n\n# Enable the message, report, category or checker with the given id(s). You can\n# either give multiple identifier separated by comma (,) or put this option\n# multiple time (only on the command line, not in the configuration file where\n# it should appear only once). See also the \"--disable\" option for examples.\nenable=c-extension-no-member\n\n\n[REPORTS]\n\n# Python expression which should return a note less than 10 (10 is the highest\n# note). You have access to the variables errors warning, statement which\n# respectively contain the number of errors / warnings messages and the total\n# number of statements analyzed. This is used by the global evaluation report\n# (RP0004).\nevaluation=10.0 - ((float(5 * error + warning + refactor + convention) / statement) * 10)\n\n# Template used to display messages. This is a python new-style format string\n# used to format the message information. See doc for all details\n#msg-template=\n\n# Set the output format. Available formats are text, parseable, colorized, json\n# and msvs (visual studio).You can also give a reporter class, eg\n# mypackage.mymodule.MyReporterClass.\n#output-format=text\noutput-format=parseable\n\n# Tells whether to display a full report or only the messages\nreports=no\n\n# Activate the evaluation score.\nscore=yes\n\n\n[REFACTORING]\n\n# Maximum number of nested blocks for function / method body\nmax-nested-blocks=5\n\n# Complete name of functions that never returns. When checking for\n# inconsistent-return-statements if a never returning function is called then\n# it will be considered as an explicit return statement and no message will be\n# printed.\nnever-returning-functions=optparse.Values,sys.exit\n\n\n[BASIC]\n\n# Regular expression matching correct argument names. Overrides argument-\n# naming-style\nargument-rgx=^[a-z][a-z0-9_]*$\n\n# Regular expression matching correct attribute names. Overrides attr-naming-\n# style\nattr-rgx=^_{0,2}[a-z][a-z0-9_]*$\n\n# Bad variable names which should always be refused, separated by a comma\nbad-names=\n\n# Regular expression matching correct class attribute names. Overrides class-\n# attribute-naming-style\nclass-attribute-rgx=^(_?[A-Z][A-Z0-9_]*|__[a-z0-9_]+__|_?[a-z][a-z0-9_]*)$\n\n# Regular expression matching correct class names. Overrides class-naming-style\nclass-rgx=^_?[A-Z][a-zA-Z0-9]*$\n\n# Naming style matching correct constant names\nconst-naming-style=UPPER_CASE\n\n# Minimum line length for functions/classes that require docstrings, shorter\n# ones are exempt.\ndocstring-min-length=-1\n\n# Regular expression matching correct function names. Overrides function-\n# naming-style\nfunction-rgx=^(?:(?P<exempt>setUp|tearDown|setUpModule|tearDownModule)|(?P<camel_case>_?[A-Z][a-zA-Z0-9]*)|(?P<snake_case>_?[a-z][a-z0-9_]*))$\n\n\n# Good variable names which should always be accepted, separated by a comma\ngood-names=main,\n           sf,\n           _\n\n# Include a hint for the correct naming format with invalid-name\ninclude-naming-hint=no\n\n# Regular expression matching correct inline iteration names. Overrides\n# inlinevar-naming-style\ninlinevar-rgx=^[a-z][a-z0-9_]*$\n\n# Regular expression matching correct method names. Overrides method-naming-\n# style\nmethod-rgx=(?x)^(?:(?P<exempt>_[a-z0-9_]+__|runTest|setUp|tearDown|setUpTestCase|tearDownTestCase|setupSelf|tearDownClass|setUpClass|(test|assert)_*[A-Z0-9][a-zA-Z0-9_]*|next)|(?P<camel_case>_{0,2}[A-Z][a-zA-Z0-9_]*)|(?P<snake_case>_{0,2}[a-z][a-z0-9_]*))$\n\n# Regular expression matching correct module names. Overrides module-naming-\n# style\nmodule-rgx=^(_?[a-z][a-z0-9_]*|__init__)$\n\n# Colon-delimited sets of names that determine each other's naming style when\n# the name regexes allow several styles.\nname-group=\n\n# Regular expression which should only match function or class names that do\n# not require a docstring.\nno-docstring-rgx=^_\n\n# List of decorators that produce properties, such as abc.abstractproperty. Add\n# to this list to register other decorators that produce valid properties.\nproperty-classes=abc.abstractproperty,cached_property.cached_property,cached_property.threaded_cached_property,cached_property.cached_property_with_ttl,cached_property.threaded_cached_property_with_ttl\n\n# Regular expression matching correct variable names. Overrides variable-\n# naming-style\nvariable-rgx=^[a-z][a-z0-9_]*$\n\n\n[SIMILARITIES]\n\n# Ignore comments when computing similarities.\nignore-comments=yes\n\n# Ignore docstrings when computing similarities.\nignore-docstrings=yes\n\n# Ignore imports when computing similarities.\nignore-imports=no\n\n# Minimum lines number of a similarity.\nmin-similarity-lines=4\n\n\n[SPELLING]\n\n# Limits count of emitted suggestions for spelling mistakes\nmax-spelling-suggestions=4\n\n# Spelling dictionary name. Available dictionaries: en_US (myspell), en\n# (aspell), en_AU (aspell), en_CA (aspell), en_GB (aspell).\nspelling-dict=\n\n# List of comma separated words that should not be checked.\nspelling-ignore-words=\n\n# A path to a file that contains private dictionary; one word per line.\nspelling-private-dict-file=\n\n# Tells whether to store unknown words to indicated private dictionary in\n# --spelling-private-dict-file option instead of raising a message.\nspelling-store-unknown-words=no\n\n\n[LOGGING]\n\n# Logging modules to check that the string format arguments are in logging\n# function parameter format\nlogging-modules=logging\n\n\n[FORMAT]\n\n# Expected format of line ending, e.g. empty (any line ending), LF or CRLF.\nexpected-line-ending-format=\n\n# Regexp for a line that is allowed to be longer than the limit.\nignore-long-lines=(?x)(\n  ^\\s*(\\#\\ )?<?https?://\\S+>?$|\n  ^\\s*(from\\s+\\S+\\s+)?import\\s+.+$)\n\n# Number of spaces of indent required inside a hanging  or continued line.\nindent-after-paren=4\n\n# String used as indentation unit. This is usually \"    \" (4 spaces) or \"\\t\" (1\n# tab).\nindent-string='    '\n\n# Maximum number of characters on a single line.\nmax-line-length=120\n\n# Maximum number of lines in a module\nmax-module-lines=1000\n\n# List of optional constructs for which whitespace checking is disabled. `dict-\n# separator` is used to allow tabulation in dicts, etc.: {1  : 1,\\n222: 2}.\n# `trailing-comma` allows a space between comma and closing bracket: (a, ).\n# `empty-line` allows space-only lines.\nno-space-check=trailing-comma\n\n# Allow the body of a class to be on the same line as the declaration if body\n# contains single statement.\nsingle-line-class-stmt=no\n\n# Allow the body of an if to be on the same line as the test if there is no\n# else.\nsingle-line-if-stmt=no\n\n\n[MISCELLANEOUS]\n\n# List of note tags to take in consideration, separated by a comma.\nnotes=FIXME,\n      XXX,\n      TODO\n\n\n[TYPECHECK]\n\n# List of decorators that produce context managers, such as\n# contextlib.contextmanager. Add to this list to register other decorators that\n# produce valid context managers.\ncontextmanager-decorators=contextlib.contextmanager\n\n# List of members which are set dynamically and missed by pylint inference\n# system, and so shouldn't trigger E1101 when accessed. Python regular\n# expressions are accepted.\ngenerated-members=\n\n# Tells whether missing members accessed in mixin class should be ignored. A\n# mixin class is detected if its name ends with \"mixin\" (case insensitive).\nignore-mixin-members=yes\n\n# This flag controls whether pylint should warn about no-member and similar\n# checks whenever an opaque object is returned when inferring. The inference\n# can return multiple potential results while evaluating a Python object, but\n# some branches might not be evaluated, which results in partial inference. In\n# that case, it might be useful to still emit no-member and other checks for\n# the rest of the inferred objects.\nignore-on-opaque-inference=yes\n\n# List of class names for which member attributes should not be checked (useful\n# for classes with dynamically set attributes). This supports the use of\n# qualified names.\nignored-classes=optparse.Values,thread._local,_thread._local\n\n# List of module names for which member attributes should not be checked\n# (useful for modules/projects where namespaces are manipulated during runtime\n# and thus existing member attributes cannot be deduced by static analysis. It\n# supports qualified module names, as well as Unix pattern matching.\nignored-modules=\n\n# Show a hint with possible names when a member name was not found. The aspect\n# of finding the hint is based on edit distance.\nmissing-member-hint=yes\n\n# The minimum edit distance a name should have in order to be considered a\n# similar match for a missing member name.\nmissing-member-hint-distance=1\n\n# The total number of similar names that should be taken in consideration when\n# showing a hint for a missing member.\nmissing-member-max-choices=1\n\n\n[VARIABLES]\n\n# List of additional names supposed to be defined in builtins. Remember that\n# you should avoid to define new builtins when possible.\nadditional-builtins=\n\n# Tells whether unused global variables should be treated as a violation.\nallow-global-unused-variables=yes\n\n# List of strings which can identify a callback function by name. A callback\n# name must start or end with one of those strings.\ncallbacks=cb_,\n          _cb\n\n# A regular expression matching the name of dummy variables (i.e. expectedly\n# not used).\ndummy-variables-rgx=_+$|(_[a-zA-Z0-9_]*[a-zA-Z0-9]+?$)|dummy|^ignored_|^unused_\n\n# Argument names that match this expression will be ignored. Default to name\n# with leading underscore\nignored-argument-names=_.*|^ignored_|^unused_\n\n# Tells whether we should check for unused import in __init__ files.\ninit-import=no\n\n# List of qualified module names which can have objects that can redefine\n# builtins.\nredefining-builtins-modules=six.moves,past.builtins,future.builtins,io,builtins\n\n\n[DESIGN]\n\n# Maximum number of arguments for function / method\nmax-args=5\n\n# Maximum number of attributes for a class (see R0902).\nmax-attributes=7\n\n# Maximum number of boolean expressions in a if statement\nmax-bool-expr=5\n\n# Maximum number of branch for function / method body\nmax-branches=12\n\n# Maximum number of locals for function / method body\nmax-locals=15\n\n# Maximum number of parents for a class (see R0901).\nmax-parents=7\n\n# Maximum number of public methods for a class (see R0904).\nmax-public-methods=20\n\n# Maximum number of return / yield for function / method body\nmax-returns=6\n\n# Maximum number of statements in function / method body\nmax-statements=50\n\n# Minimum number of public methods for a class (see R0903).\nmin-public-methods=2\n\n\n[CLASSES]\n\n# List of method names used to declare (i.e. assign) instance attributes.\ndefining-attr-methods=__init__,\n                      __new__,\n                      setUp\n\n# List of member names, which should be excluded from the protected access\n# warning.\nexclude-protected=_asdict,\n                  _fields,\n                  _replace,\n                  _source,\n                  _make\n\n# List of valid names for the first argument in a class method.\nvalid-classmethod-first-arg=cls,\n                            class_\n\n# List of valid names for the first argument in a metaclass class method.\nvalid-metaclass-classmethod-first-arg=mcs\n\n\n[IMPORTS]\n\n# Allow wildcard imports from modules that define __all__.\nallow-wildcard-with-all=no\n\n# Analyse import fallback blocks. This can be used to support both Python 2 and\n# 3 compatible code, which means that the block might have code that exists\n# only in one or another interpreter, leading to false positives when analysed.\nanalyse-fallback-blocks=no\n\n# Deprecated modules which should not be used, separated by a comma\ndeprecated-modules=regsub,\n                   TERMIOS,\n                   Bastion,\n                   rexec,\n                   sets\n\n# Create a graph of external dependencies in the given file (report RP0402 must\n# not be disabled)\next-import-graph=\n\n# Create a graph of every (i.e. internal and external) dependencies in the\n# given file (report RP0402 must not be disabled)\nimport-graph=\n\n# Create a graph of internal dependencies in the given file (report RP0402 must\n# not be disabled)\nint-import-graph=\n\n# Force import order to recognize a module as part of the standard\n# compatibility libraries.\nknown-standard-library=\n\n# Force import order to recognize a module as part of a third party library.\nknown-third-party=enchant\n\n\n[EXCEPTIONS]\n\n# Exceptions that will emit a warning when being caught. Defaults to\n# \"Exception\"\novergeneral-exceptions=Exception,\n                       BaseException,\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.7138671875,
          "content": "#\n# Spiderfoot Dockerfile\n#\n# http://www.spiderfoot.net\n#\n# Written by: Michael Pellon <m@pellon.io>\n# Updated by: Chandrapal <bnchandrapal@protonmail.com>\n# Updated by: Steve Micallef <steve@binarypool.com>\n# Updated by: Steve Bate <svc-spiderfoot@stevebate.net>\n#    -> Inspired by https://github.com/combro2k/dockerfiles/tree/master/alpine-spiderfoot\n#\n# Usage:\n#\n#   sudo docker build -t spiderfoot .\n#   sudo docker run -p 5001:5001 --security-opt no-new-privileges spiderfoot\n#\n# Using Docker volume for spiderfoot data\n#\n#   sudo docker run -p 5001:5001 -v /mydir/spiderfoot:/var/lib/spiderfoot spiderfoot\n#\n# Using SpiderFoot remote command line with web server\n#\n#   docker run --rm -it spiderfoot sfcli.py -s http://my.spiderfoot.host:5001/\n#\n# Running spiderfoot commands without web server (can optionally specify volume)\n#\n#   sudo docker run --rm spiderfoot sf.py -h\n#\n# Running a shell in the container for maintenance\n#   sudo docker run -it --entrypoint /bin/sh spiderfoot\n#\n# Running spiderfoot unit tests in container\n#\n#   sudo docker build -t spiderfoot-test --build-arg REQUIREMENTS=test/requirements.txt .\n#   sudo docker run --rm spiderfoot-test -m pytest --flake8 .\n\nFROM alpine:3.12.4 AS build\nARG REQUIREMENTS=requirements.txt\nRUN apk add --no-cache gcc git curl python3 python3-dev py3-pip swig tinyxml-dev \\\n python3-dev musl-dev openssl-dev libffi-dev libxslt-dev libxml2-dev jpeg-dev \\\n openjpeg-dev zlib-dev cargo rust\nRUN python3 -m venv /opt/venv\nENV PATH=\"/opt/venv/bin\":$PATH\nCOPY $REQUIREMENTS requirements.txt ./\nRUN ls\nRUN echo \"$REQUIREMENTS\"\nRUN pip3 install -U pip\nRUN pip3 install -r \"$REQUIREMENTS\"\n\n\n\nFROM alpine:3.13.0\nWORKDIR /home/spiderfoot\n\n# Place database and logs outside installation directory\nENV SPIDERFOOT_DATA /var/lib/spiderfoot\nENV SPIDERFOOT_LOGS /var/lib/spiderfoot/log\nENV SPIDERFOOT_CACHE /var/lib/spiderfoot/cache\n\n# Run everything as one command so that only one layer is created\nRUN apk --update --no-cache add python3 musl openssl libxslt tinyxml libxml2 jpeg zlib openjpeg \\\n    && addgroup spiderfoot \\\n    && adduser -G spiderfoot -h /home/spiderfoot -s /sbin/nologin \\\n               -g \"SpiderFoot User\" -D spiderfoot \\\n    && rm -rf /var/cache/apk/* \\\n    && rm -rf /lib/apk/db \\\n    && rm -rf /root/.cache \\\n    && mkdir -p $SPIDERFOOT_DATA || true \\\n    && mkdir -p $SPIDERFOOT_LOGS || true \\\n    && mkdir -p $SPIDERFOOT_CACHE || true \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_DATA \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_LOGS \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_CACHE\n\nCOPY . .\nCOPY --from=build /opt/venv /opt/venv\nENV PATH=\"/opt/venv/bin:$PATH\"\n\nUSER spiderfoot\n\nEXPOSE 5001\n\n# Run the application.\nENTRYPOINT [\"/opt/venv/bin/python\"]\nCMD [\"sf.py\", \"-l\", \"0.0.0.0:5001\"]\n"
        },
        {
          "name": "Dockerfile.full",
          "type": "blob",
          "size": 4.787109375,
          "content": "#\n# Spiderfoot Dockerfile (Full - includes all CLI tools, etc.)\n#\n# http://www.spiderfoot.net\n#\n# Written by: TheTechromancer\n#\n\nFROM python:3\n\n# Install tools/dependencies from apt\nRUN apt-get -y update && apt-get -y install nbtscan onesixtyone nmap\n\n# Compile other tools from source\nRUN mkdir /tools || true\nWORKDIR /tools\n\n# Install Golang tools\nRUN apt-get -y update && apt-get -y install golang\nENV GOPATH=\"/go\"\nENV PATH=\"$GOPATH/bin:$PATH\"\nRUN mkdir -p \"$GOPATH/src\" \"$GOPATH/bin\"\n\n# Install Ruby tools for WhatWeb\nRUN apt-get -y update && apt-get -y install ruby ruby-dev bundler\n# Install WhatWeb\nRUN git clone https://github.com/urbanadventurer/WhatWeb \\\n    && gem install rchardet mongo json && cd /tools/WhatWeb \\\n    && bundle install && cd /tools\n\nRUN groupadd spiderfoot \\\n    && useradd -m -g spiderfoot -d /home/spiderfoot -s /sbin/nologin \\\n    -c \"SpiderFoot User\" spiderfoot\n\n# Install RetireJS\nRUN apt remove -y cmdtest \\\n    && apt remove -y yarn \\\n    && curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add - \\\n    && echo 'deb https://dl.yarnpkg.com/debian/ stable main' |tee /etc/apt/sources.list.d/yarn.list \\\n    && apt-get update \\\n    && apt-get install yarn -y \\\n    && yarn install \\\n    && curl -fsSL https://deb.nodesource.com/setup_17.x | bash - \\\n    && apt-get install -y nodejs \\\n    && npm install -g retire\n\n# Install Google Chrome the New Way (Not via apt-key)\nRUN wget -qO - https://dl.google.com/linux/linux_signing_key.pub | gpg --dearmor -o /usr/share/keyrings/googlechrome-linux-keyring.gpg \\\n    && echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/googlechrome-linux-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main\" | tee /etc/apt/sources.list.d/google-chrome.list \\\n    && apt -y update && apt install --allow-unauthenticated -y google-chrome-stable\n\n# Install Wappalyzer\nRUN git clone https://github.com/AliasIO/wappalyzer.git \\\n    && cd wappalyzer \\\n    && yarn install && yarn run link\n\n# Install Nuclei\nRUN wget https://github.com/projectdiscovery/nuclei/releases/download/v2.6.5/nuclei_2.6.5_linux_amd64.zip \\\n    && unzip nuclei_2.6.5_linux_amd64.zip \\\n    && git clone https://github.com/projectdiscovery/nuclei-templates.git\n\n# Install testssl.sh\nRUN apt-get install -y bsdmainutils dnsutils coreutils\nRUN git clone https://github.com/drwetter/testssl.sh.git\n\n# Install Snallygaster and TruffleHog\nRUN pip3 install snallygaster trufflehog\n\n# Place database and logs outside installation directory\nENV SPIDERFOOT_DATA /var/lib/spiderfoot\nENV SPIDERFOOT_LOGS /var/lib/spiderfoot/log\nENV SPIDERFOOT_CACHE /var/lib/spiderfoot/cache\n\nRUN mkdir -p $SPIDERFOOT_DATA || true \\\n    && mkdir -p $SPIDERFOOT_LOGS || true \\\n    && mkdir -p $SPIDERFOOT_CACHE || true \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_DATA \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_LOGS \\\n    && chown spiderfoot:spiderfoot $SPIDERFOOT_CACHE\n\nWORKDIR /home/spiderfoot\nCOPY . .\n\nENV VIRTUAL_ENV=/opt/venv\nRUN mkdir -p \"$VIRTUAL_ENV\" || true\nENV PATH=\"$VIRTUAL_ENV/bin:$PATH\"\nRUN python -m venv \"$VIRTUAL_ENV\"\n\nARG REQUIREMENTS=requirements.txt\nCOPY \"$REQUIREMENTS\" requirements.txt\n\nRUN chown -R spiderfoot:spiderfoot /tools\nRUN chown -R spiderfoot:spiderfoot \"$VIRTUAL_ENV\"\nRUN chown -R spiderfoot:spiderfoot \"/home/spiderfoot\"\n\nUSER spiderfoot\n\nRUN pip install -U pip\nRUN pip install -r \"$REQUIREMENTS\"\n\n# Install Python tools\nRUN pip install dnstwist\n# CMSeeK\nWORKDIR /tools\nRUN git clone https://github.com/Tuhinshubhra/CMSeeK && cd CMSeeK \\\n    && pip install -r requirements.txt && mkdir Results\n\n# Install wafw00f\nRUN git clone https://github.com/EnableSecurity/wafw00f \\\n    && cd wafw00f \\\n    && python3 setup.py install\nWORKDIR /home/spiderfoot\n\nEXPOSE 5001\n\n# Run the application\nCMD python -c 'from spiderfoot import SpiderFootDb; \\\ndb = SpiderFootDb({\"__database\": \"/var/lib/spiderfoot/spiderfoot.db\"}); \\\ndb.configSet({ \\\n    \"sfp_tool_dnstwist:dnstwistpath\": \"/opt/venv/bin/dnstwist\", \\\n    \"sfp_tool_cmseek:cmseekpath\": \"/tools/CMSeeK/cmseek.py\", \\\n    \"sfp_tool_whatweb:whatweb_path\": \"/tools/WhatWeb/whatweb\", \\\n    \"sfp_tool_wafw00f:wafw00f_path\": \"/opt/venv/bin/wafw00f\", \\\n    \"sfp_tool_onesixtyone:onesixtyone_path\": \"/usr/bin/onesixtyone\", \\\n    \"sfp_tool_retirejs:retirejs_path\": \"/usr/bin/retire\", \\\n    \"sfp_tool_testsslsh:testsslsh_path\": \"/tools/testssl.sh/testssl.sh\", \\\n    \"sfp_tool_snallygaster:snallygaster_path\": \"/usr/local/bin/snallygaster\", \\\n    \"sfp_tool_trufflehog:trufflehog_path\": \"/usr/local/bin/trufflehog\", \\\n    \"sfp_tool_nuclei:nuclei_path\": \"/tools/nuclei\", \\\n    \"sfp_tool_nuclei:template_path\": \"/tools/nuclei-templates\", \\\n    \"sfp_tool_wappalyzer:wappalyzer_path\": \"/tools/wappalyzer/src/drivers/npm/cli.js\", \\\n    \"sfp_tool_nbtscan:nbtscan_path\": \"/usr/bin/nbtscan\", \\\n    \"sfp_tool_nmap:nmappath\": \"DISABLED_BECAUSE_NMAP_REQUIRES_ROOT_TO_WORK\" \\\n})' || true && ./sf.py -l 0.0.0.0:5001\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0517578125,
          "content": "Copyright 2022 Steve Micallef <steve@binarypool.com>\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 33.185546875,
          "content": "<a href=\"https://www.spiderfoot.net/r.php?u=aHR0cHM6Ly93d3cuc3BpZGVyZm9vdC5uZXQv&s=os_gh\"><img src=\"https://www.spiderfoot.net/wp-content/themes/spiderfoot/img/spiderfoot-wide.png\"></a>\n\n\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/smicallef/spiderfoot/master/LICENSE)\n[![Python Version](https://img.shields.io/badge/python-3.7+-green)](https://www.python.org)\n[![Stable Release](https://img.shields.io/badge/version-4.0-blue.svg)](https://github.com/smicallef/spiderfoot/releases/tag/v4.0)\n[![CI status](https://github.com/smicallef/spiderfoot/workflows/Tests/badge.svg)](https://github.com/smicallef/spiderfoot/actions?query=workflow%3A\"Tests\")\n[![Last Commit](https://img.shields.io/github/last-commit/smicallef/spiderfoot)](https://github.com/smicallef/spiderfoot/commits/master)\n[![Codecov](https://codecov.io/github/smicallef/spiderfoot/coverage.svg)](https://codecov.io/github/smicallef/spiderfoot)\n[![Twitter Follow](https://img.shields.io/twitter/follow/spiderfoot?label=follow&style=social)](https://twitter.com/spiderfoot)\n[![Discord](https://img.shields.io/discord/770524432464216074)](https://discord.gg/vyvztrG)\n\n**SpiderFoot** is an open source intelligence (OSINT) automation tool. It integrates with just about every data source available and utilises a range of methods for data analysis, making that data easy to navigate. \n\nSpiderFoot has an embedded web-server for providing a clean and intuitive web-based interface but can also be used completely via the command-line.  It's written in **Python 3** and **MIT-licensed**.\n\n<img src=\"https://www.spiderfoot.net/wp-content/uploads/2022/04/opensource-screenshot-v4.png\" />\n\n### FEATURES\n\n- Web based UI or CLI\n- Over 200 modules (see below)\n- Python 3.7+\n- YAML-configurable [correlation engine](/correlations/README.md) with [37 pre-defined rules](/correlations)\n- CSV/JSON/GEXF export\n- API key export/import\n- SQLite back-end for custom querying\n- Highly configurable\n- Fully documented\n- Visualisations\n- TOR integration for dark web searching\n- Dockerfile for Docker-based deployments\n- Can call other tools like DNSTwist, Whatweb, Nmap and CMSeeK\n- [Actively developed since 2012!](https://medium.com/@micallst/lessons-learned-from-my-10-year-open-source-project-4a4c8c2b4f64)\n\n### WANT MORE?\n\nNeed more from SpiderFoot? Check out [SpiderFoot HX](https://www.spiderfoot.net/hx) for:\n- 100% Cloud-based and managed for you\n- Attack Surface Monitoring with change notifications by email, REST and Slack\n- Multiple targets per scan\n- Multi-user collaboration\n- Authenticated and 2FA\n- Investigations\n- Customer support\n- Third party tools pre-installed & configured\n- Drive it with a fully RESTful API\n- TOR integration built-in\n- Screenshotting\n- Bring your own Python SpiderFoot modules\n- Feed scan data to Splunk, ElasticSearch and REST endpoints\n\nSee the full set of differences between SpiderFoot HX and the open source version [here](https://www.spiderfoot.net/open-source-vs-hx/).\n\n### USES\n\nSpiderFoot can be used offensively (e.g. in a red team exercise or penetration test) for reconnaissance of your target or defensively to gather information about what you or your organisation might have exposed over the Internet.\n\nYou can target the following entities in a SpiderFoot scan:\n\n - IP address\n - Domain/sub-domain name\n - Hostname\n - Network subnet (CIDR)\n - ASN\n - E-mail address\n - Phone number\n - Username\n - Person's name\n - Bitcoin address\n \nSpiderFoot's 200+ modules feed each other in a publisher/subscriber model to ensure maximum data extraction to do things like:\n\n- [Host/sub-domain/TLD enumeration/extraction](https://asciinema.org/a/295912)\n- [Email address, phone number and human name extraction](https://asciinema.org/a/295947)\n- [Bitcoin and Ethereum address extraction](https://asciinema.org/a/295957)\n- [Check for susceptibility to sub-domain hijacking](https://asciinema.org/a/344377)\n- DNS zone transfers\n- [Threat intelligence and Blacklist queries](https://asciinema.org/a/295949)\n- API integration with [SHODAN](https://asciinema.org/a/127601), [HaveIBeenPwned](https://asciinema.org/a/128731), [GreyNoise](https://asciinema.org/a/295943), AlienVault, SecurityTrails, etc.\n- [Social media account enumeration](https://asciinema.org/a/295923)\n- [S3/Azure/Digitalocean bucket enumeration/scraping](https://asciinema.org/a/295941)\n- IP geo-location\n- Web scraping, web content analysis\n- [Image, document and binary file meta data analysis](https://asciinema.org/a/296274)\n- Dark web searches\n- [Port scanning and banner grabbing](https://asciinema.org/a/295939)\n- [Data breach searches](https://asciinema.org/a/296145)\n- So much more...\n\n### INSTALLING & RUNNING\n\nTo install and run SpiderFoot, you need at least Python 3.7 and a number of Python libraries which you can install with `pip`. We recommend you install a packaged release since master will often have bleeding edge features and modules that aren't fully tested.\n\n#### Stable build (packaged release):\n\n```\n wget https://github.com/smicallef/spiderfoot/archive/v4.0.tar.gz\n tar zxvf v4.0.tar.gz\n cd spiderfoot-4.0\n pip3 install -r requirements.txt\n python3 ./sf.py -l 127.0.0.1:5001\n```\n\n#### Development build (cloning git master branch):\n\n```\n git clone https://github.com/smicallef/spiderfoot.git\n cd spiderfoot\n pip3 install -r requirements.txt\n python3 ./sf.py -l 127.0.0.1:5001\n```\n\nCheck out the [documentation](https://www.spiderfoot.net/documentation) and our [asciinema videos](https://asciinema.org/~spiderfoot) for more tutorials.\n\n### COMMUNITY\n\nWhether you're a contributor, user or just curious about SpiderFoot and OSINT in general, we'd love to have you join our community! SpiderFoot now has a [Discord server](https://discord.gg/vyvztrG) for seeking help from the community, requesting features or just general OSINT chit-chat.\n\n### WRITING CORRELATION RULES\n\nWe have a comprehensive write-up and reference of the correlation rule-set introduced in SpiderFoot 4.0 [here](/correlations/README.md).\n\nAlso take a look at the [template.yaml](/correlations/template.yaml) file for a walk through. The existing [37 rules](/correlations) are also quite readable and good as starting points for additional rules.\n\n### MODULES / INTEGRATIONS\n\nSpiderFoot has over 200 modules, most of which *don't require API keys*, and many of those that do require API keys *have a free tier*.\n\n| Name     | Description | Type   |\n|:---------| :-----------|:-------|\n[AbstractAPI](https://app.abstractapi.com/)|Look up domain, phone and IP address information from AbstractAPI.|Tiered API\n[abuse.ch](https://www.abuse.ch)|Check if a host/domain, IP address or netblock is malicious according to Abuse.ch.|Free API\n[AbuseIPDB](https://www.abuseipdb.com)|Check if an IP address is malicious according to AbuseIPDB.com blacklist.|Tiered API\n[Abusix Mail Intelligence](https://abusix.org/)|Check if a netblock or IP address is in the Abusix Mail Intelligence blacklist.|Tiered API\nAccount Finder|Look for possible associated accounts on over 500 social and other websites such as Instagram, Reddit, etc.|Internal\n[AdBlock Check](https://adblockplus.org/)|Check if linked pages would be blocked by AdBlock Plus.|Tiered API\n[AdGuard DNS](https://adguard.com/)|Check if a host would be blocked by AdGuard DNS.|Free API\n[Ahmia](https://ahmia.fi/)|Search Tor 'Ahmia' search engine for mentions of the target.|Free API\n[AlienVault IP Reputation](https://cybersecurity.att.com/)|Check if an IP or netblock is malicious according to the AlienVault IP Reputation database.|Free API\n[AlienVault OTX](https://otx.alienvault.com/)|Obtain information from AlienVault Open Threat Exchange (OTX)|Tiered API\n[Amazon S3 Bucket Finder](https://aws.amazon.com/s3/)|Search for potential Amazon S3 buckets associated with the target and attempt to list their contents.|Free API\n[Apple iTunes](https://itunes.apple.com/)|Search Apple iTunes for mobile apps.|Free API\n[Archive.org](https://archive.org/)|Identifies historic versions of interesting files/pages from the Wayback Machine.|Free API\n[ARIN](https://www.arin.net/)|Queries ARIN registry for contact information.|Free API\n[Azure Blob Finder](https://azure.microsoft.com/en-in/services/storage/blobs/)|Search for potential Azure blobs associated with the target and attempt to list their contents.|Free API\nBase64 Decoder|Identify Base64-encoded strings in URLs, often revealing interesting hidden information.|Internal\n[BGPView](https://bgpview.io/)|Obtain network information from BGPView API.|Free API\nBinary String Extractor|Attempt to identify strings in binary content.|Internal\n[BinaryEdge](https://www.binaryedge.io/)|Obtain information from BinaryEdge.io Internet scanning systems, including breaches, vulnerabilities, torrents and passive DNS.|Tiered API\n[Bing (Shared IPs)](https://www.bing.com/)|Search Bing for hosts sharing the same IP.|Tiered API\n[Bing](https://www.bing.com/)|Obtain information from bing to identify sub-domains and links.|Tiered API\nBitcoin Finder|Identify bitcoin addresses in scraped webpages.|Internal\n[Bitcoin Who's Who](https://bitcoinwhoswho.com/)|Check for Bitcoin addresses against the Bitcoin Who's Who database of suspect/malicious addresses.|Tiered API\n[BitcoinAbuse](https://www.bitcoinabuse.com/)|Check Bitcoin addresses against the bitcoinabuse.com database of suspect/malicious addresses.|Free API\n[Blockchain](https://www.blockchain.com/)|Queries blockchain.info to find the balance of identified bitcoin wallet addresses.|Free API\n[blocklist.de](http://www.blocklist.de/en/index.html)|Check if a netblock or IP is malicious according to blocklist.de.|Free API\n[BotScout](https://botscout.com/)|Searches BotScout.com's database of spam-bot IP addresses and e-mail addresses.|Tiered API\n[botvrij.eu](https://botvrij.eu/)|Check if a domain is malicious according to botvrij.eu.|Free API\n[BuiltWith](https://builtwith.com/)|Query BuiltWith.com's Domain API for information about your target's web technology stack, e-mail addresses and more.|Tiered API\n[C99](https://api.c99.nl/)|Queries the C99 API which offers various data (geo location, proxy detection, phone lookup, etc).|Commercial API\n[CallerName](http://callername.com/)|Lookup US phone number location and reputation information.|Free API\n[Censys](https://censys.io/)|Obtain host information from Censys.io.|Tiered API\n[Certificate Transparency](https://crt.sh/)|Gather hostnames from historical certificates in crt.sh.|Free API\n[CertSpotter](https://sslmate.com/certspotter/)|Gather information about SSL certificates from SSLMate CertSpotter API.|Tiered API\n[CINS Army List](https://cinsscore.com/)|Check if a netblock or IP address is malicious according to Collective Intelligence Network Security (CINS) Army list.|Free API\n[CIRCL.LU](https://www.circl.lu/)|Obtain information from CIRCL.LU's Passive DNS and Passive SSL databases.|Free API\n[CleanBrowsing.org](https://cleanbrowsing.org/)|Check if a host would be blocked by CleanBrowsing.org DNS content filters.|Free API\n[CleanTalk Spam List](https://cleantalk.org)|Check if a netblock or IP address is on CleanTalk.org's spam IP list.|Free API\n[Clearbit](https://clearbit.com/)|Check for names, addresses, domains and more based on lookups of e-mail addresses on clearbit.com.|Tiered API\n[CloudFlare DNS](https://www.cloudflare.com/)|Check if a host would be blocked by CloudFlare DNS.|Free API\n[CoinBlocker Lists](https://zerodot1.gitlab.io/CoinBlockerListsWeb/)|Check if a domain appears on CoinBlocker lists.|Free API\n[CommonCrawl](http://commoncrawl.org/)|Searches for URLs found through CommonCrawl.org.|Free API\n[Comodo Secure DNS](https://www.comodo.com/secure-dns/)|Check if a host would be blocked by Comodo Secure DNS.|Tiered API\nCompany Name Extractor|Identify company names in any obtained data.|Internal\nCookie Extractor|Extract Cookies from HTTP headers.|Internal\nCountry Name Extractor|Identify country names in any obtained data.|Internal\nCredit Card Number Extractor|Identify Credit Card Numbers in any data|Internal\n[Crobat API](https://sonar.omnisint.io/)|Search Crobat API for subdomains.|Free API\nCross-Referencer|Identify whether other domains are associated ('Affiliates') of the target by looking for links back to the target site(s).|Internal\n[CRXcavator](https://crxcavator.io/)|Search CRXcavator for Chrome extensions.|Free API\nCustom Threat Feed|Check if a host/domain, netblock, ASN or IP is malicious according to your custom feed.|Internal\n[CyberCrime-Tracker.net](https://cybercrime-tracker.net/)|Check if a host/domain or IP address is malicious according to CyberCrime-Tracker.net.|Free API\n[Debounce](https://debounce.io/)|Check whether an email is disposable|Free API\n[Dehashed](https://www.dehashed.com/)|Gather breach data from Dehashed API.|Commercial API\n[Digital Ocean Space Finder](https://www.digitalocean.com/products/spaces/)|Search for potential Digital Ocean Spaces associated with the target and attempt to list their contents.|Free API\nDNS Brute-forcer|Attempts to identify hostnames through brute-forcing common names and iterations.|Internal\nDNS Common SRV|Attempts to identify hostnames through brute-forcing common DNS SRV records.|Internal\n[DNS for Family](https://dnsforfamily.com/)|Check if a host would be blocked by DNS for Family.|Free API\nDNS Look-aside|Attempt to reverse-resolve the IP addresses next to your target to see if they are related.|Internal\nDNS Raw Records|Retrieves raw DNS records such as MX, TXT and others.|Internal\nDNS Resolver|Resolves hosts and IP addresses identified, also extracted from raw content.|Internal\nDNS Zone Transfer|Attempts to perform a full DNS zone transfer.|Internal\n[DNSDB](https://www.farsightsecurity.com)|Query FarSight's DNSDB for historical and passive DNS data.|Tiered API\n[DNSDumpster](https://dnsdumpster.com/)|Passive subdomain enumeration using HackerTarget's DNSDumpster|Free API\n[DNSGrep](https://opendata.rapid7.com/)|Obtain Passive DNS information from Rapid7 Sonar Project using DNSGrep API.|Free API\n[DroneBL](https://dronebl.org/)|Query the DroneBL database for open relays, open proxies, vulnerable servers, etc.|Free API\n[DuckDuckGo](https://duckduckgo.com/)|Query DuckDuckGo's API for descriptive information about your target.|Free API\nE-Mail Address Extractor|Identify e-mail addresses in any obtained data.|Internal\n[EmailCrawlr](https://emailcrawlr.com/)|Search EmailCrawlr for email addresses and phone numbers associated with a domain.|Tiered API\n[EmailFormat](https://www.email-format.com/)|Look up e-mail addresses on email-format.com.|Free API\n[EmailRep](https://emailrep.io/)|Search EmailRep.io for email address reputation.|Tiered API\n[Emerging Threats](https://rules.emergingthreats.net/)|Check if a netblock or IP address is malicious according to EmergingThreats.net.|Free API\nError String Extractor|Identify common error messages in content like SQL errors, etc.|Internal\nEthereum Address Extractor|Identify ethereum addresses in scraped webpages.|Internal\n[Etherscan](https://etherscan.io)|Queries etherscan.io to find the balance of identified ethereum wallet addresses.|Free API\nFile Metadata Extractor|Extracts meta data from documents and images.|Internal\n[Flickr](https://www.flickr.com/)|Search Flickr for domains, URLs and emails related to the specified domain.|Free API\n[Focsec](https://focsec.com/)|Look up IP address information from Focsec.|Tiered API\n[FortiGuard Antispam](https://www.fortiguard.com/)|Check if an IP address is malicious according to FortiGuard Antispam.|Free API\n[Fraudguard](https://fraudguard.io/)|Obtain threat information from Fraudguard.io|Tiered API\n[F-Secure Riddler.io](https://riddler.io/)|Obtain network information from F-Secure Riddler.io API.|Commercial API\n[FullContact](https://www.fullcontact.com)|Gather domain and e-mail information from FullContact.com API.|Tiered API\n[FullHunt](https://fullhunt.io/)|Identify domain attack surface using FullHunt API.|Tiered API\n[Github](https://github.com/)|Identify associated public code repositories on Github.|Free API\n[GLEIF](https://search.gleif.org/)|Look up company information from Global Legal Entity Identifier Foundation (GLEIF).|Tiered API\n[Google Maps](https://cloud.google.com/maps-platform/)|Identifies potential physical addresses and latitude/longitude coordinates.|Tiered API\n[Google Object Storage Finder](https://cloud.google.com/storage)|Search for potential Google Object Storage buckets associated with the target and attempt to list their contents.|Free API\n[Google SafeBrowsing](https://developers.google.com/safe-browsing/v4/lookup-api)|Check if the URL is included on any of the Safe Browsing lists.|Free API\n[Google](https://developers.google.com/custom-search)|Obtain information from the Google Custom Search API to identify sub-domains and links.|Tiered API\n[Gravatar](https://secure.gravatar.com/)|Retrieve user information from Gravatar API.|Free API\n[Grayhat Warfare](https://buckets.grayhatwarfare.com/)|Find bucket names matching the keyword extracted from a domain from Grayhat API.|Tiered API\n[Greensnow](https://greensnow.co/)|Check if a netblock or IP address is malicious according to greensnow.co.|Free API\n[grep.app](https://grep.app/)|Search grep.app API for links and emails related to the specified domain.|Free API\n[GreyNoise Community](https://greynoise.io/)|Obtain IP enrichment data from GreyNoise Community API|Tiered API\n[GreyNoise](https://greynoise.io/)|Obtain IP enrichment data from GreyNoise|Tiered API\n[HackerOne (Unofficial)](http://www.nobbd.de/)|Check external vulnerability scanning/reporting service h1.nobbd.de to see if the target is listed.|Free API\n[HackerTarget](https://hackertarget.com/)|Search HackerTarget.com for hosts sharing the same IP.|Free API\nHash Extractor|Identify MD5 and SHA hashes in web content, files and more.|Internal\n[HaveIBeenPwned](https://haveibeenpwned.com/)|Check HaveIBeenPwned.com for hacked e-mail addresses identified in breaches.|Commercial API\nHosting Provider Identifier|Find out if any IP addresses identified fall within known 3rd party hosting ranges, e.g. Amazon, Azure, etc.|Internal\n[Host.io](https://host.io)|Obtain information about domain names from host.io.|Tiered API\nHuman Name Extractor|Attempt to identify human names in fetched content.|Internal\n[Hunter.io](https://hunter.io/)|Check for e-mail addresses and names on hunter.io.|Tiered API\n[Hybrid Analysis](https://www.hybrid-analysis.com)|Search Hybrid Analysis for domains and URLs related to the target.|Free API\nIBAN Number Extractor|Identify International Bank Account Numbers (IBANs) in any data.|Internal\n[Iknowwhatyoudownload.com](https://iknowwhatyoudownload.com/en/peer/)|Check iknowwhatyoudownload.com for IP addresses that have been using torrents.|Tiered API\n[IntelligenceX](https://intelx.io/)|Obtain information from IntelligenceX about identified IP addresses, domains, e-mail addresses and phone numbers.|Tiered API\nInteresting File Finder|Identifies potential files of interest, e.g. office documents, zip files.|Internal\n[Internet Storm Center](https://isc.sans.edu)|Check if an IP address is malicious according to SANS ISC.|Free API\n[ipapi.co](https://ipapi.co/)|Queries ipapi.co to identify geolocation of IP Addresses using ipapi.co API|Tiered API\n[ipapi.com](https://ipapi.com/)|Queries ipapi.com to identify geolocation of IP Addresses using ipapi.com API|Tiered API\n[IPInfo.io](https://ipinfo.io)|Identifies the physical location of IP addresses identified using ipinfo.io.|Tiered API\n[IPQualityScore](https://www.ipqualityscore.com/)|Determine if target is malicious using IPQualityScore API|Tiered API\n[ipregistry](https://ipregistry.co/)|Query the ipregistry.co database for reputation and geo-location.|Tiered API\n[ipstack](https://ipstack.com/)|Identifies the physical location of IP addresses identified using ipstack.com.|Tiered API\n[JsonWHOIS.com](https://jsonwhois.com)|Search JsonWHOIS.com for WHOIS records associated with a domain.|Tiered API\nJunk File Finder|Looks for old/temporary and other similar files.|Internal\n[Keybase](https://keybase.io/)|Obtain additional information about domain names and identified usernames.|Free API\n[Koodous](https://koodous.com/apks/)|Search Koodous for mobile apps.|Tiered API\n[LeakIX](https://leakix.net/)|Search LeakIX for host data leaks, open ports, software and geoip.|Free API\n[Leak-Lookup](https://leak-lookup.com/)|Searches Leak-Lookup.com's database of breaches.|Free API\n[Maltiverse](https://maltiverse.com)|Obtain information about any malicious activities involving IP addresses|Free API\n[MalwarePatrol](https://www.malwarepatrol.net/)|Searches malwarepatrol.net's database of malicious URLs/IPs.|Tiered API\n[MetaDefender](https://metadefender.opswat.com/)|Search MetaDefender API for IP address and domain IP reputation.|Tiered API\n[Mnemonic PassiveDNS](https://www.mnemonic.no)|Obtain Passive DNS information from PassiveDNS.mnemonic.no.|Free API\n[multiproxy.org Open Proxies](https://multiproxy.org/)|Check if an IP address is an open proxy according to multiproxy.org open proxy list.|Free API\n[MySpace](https://myspace.com/)|Gather username and location from MySpace.com profiles.|Free API\n[NameAPI](https://www.nameapi.org/)|Check whether an email is disposable|Tiered API\n[NetworksDB](https://networksdb.io/)|Search NetworksDB.io API for IP address and domain information.|Tiered API\n[NeutrinoAPI](https://www.neutrinoapi.com/)|Search NeutrinoAPI for phone location information, IP address information, and host reputation.|Tiered API\n[numverify](http://numverify.com/)|Lookup phone number location and carrier information from numverify.com.|Tiered API\n[Onion.link](https://onion.link/)|Search Tor 'Onion City' search engine for mentions of the target domain using Google Custom Search.|Free API\n[Onionsearchengine.com](https://as.onionsearchengine.com)|Search Tor onionsearchengine.com for mentions of the target domain.|Free API\n[Onyphe](https://www.onyphe.io)|Check Onyphe data (threat list, geo-location, pastries, vulnerabilities)  about a given IP.|Tiered API\n[Open Bug Bounty](https://www.openbugbounty.org/)|Check external vulnerability scanning/reporting service openbugbounty.org to see if the target is listed.|Free API\n[OpenCorporates](https://opencorporates.com)|Look up company information from OpenCorporates.|Tiered API\n[OpenDNS](https://www.opendns.com/)|Check if a host would be blocked by OpenDNS.|Free API\n[OpenNIC DNS](https://www.opennic.org/)|Resolves host names in the OpenNIC alternative DNS system.|Free API\n[OpenPhish](https://openphish.com/)|Check if a host/domain is malicious according to OpenPhish.com.|Free API\n[OpenStreetMap](https://www.openstreetmap.org/)|Retrieves latitude/longitude coordinates for physical addresses from OpenStreetMap API.|Free API\nPage Information|Obtain information about web pages (do they take passwords, do they contain forms, etc.)|Internal\n[PasteBin](https://pastebin.com/)|PasteBin search (via Google Search API) to identify related content.|Tiered API\nPGP Key Servers|Look up domains and e-mail addresses in PGP public key servers.|Internal\n[PhishStats](https://phishstats.info/)|Check if a netblock or IP address is malicious according to PhishStats.|Free API\n[PhishTank](https://phishtank.com/)|Check if a host/domain is malicious according to PhishTank.|Free API\nPhone Number Extractor|Identify phone numbers in scraped webpages.|Internal\nPort Scanner - TCP|Scans for commonly open TCP ports on Internet-facing systems.|Internal\n[Project Honey Pot](https://www.projecthoneypot.org/)|Query the Project Honey Pot database for IP addresses.|Free API\n[ProjectDiscovery Chaos](https://chaos.projectdiscovery.io)|Search for hosts/subdomains using chaos.projectdiscovery.io|Commercial API\n[Psbdmp](https://psbdmp.cc/)|Check psbdmp.cc (PasteBin Dump) for potentially hacked e-mails and domains.|Free API\n[Pulsedive](https://pulsedive.com/)|Obtain information from Pulsedive's API.|Tiered API\n[PunkSpider](https://punkspider.io/)|Check the QOMPLX punkspider.io service to see if the target is listed as vulnerable.|Free API\n[Quad9](https://quad9.net/)|Check if a host would be blocked by Quad9 DNS.|Free API\n[ReverseWhois](https://www.reversewhois.io/)|Reverse Whois lookups using reversewhois.io.|Free API\n[RIPE](https://www.ripe.net/)|Queries the RIPE registry (includes ARIN data) to identify netblocks and other info.|Free API\n[RiskIQ](https://community.riskiq.com/)|Obtain information from RiskIQ's (formerly PassiveTotal) Passive DNS and Passive SSL databases.|Tiered API\n[Robtex](https://www.robtex.com/)|Search Robtex.com for hosts sharing the same IP.|Free API\n[searchcode](https://searchcode.com/)|Search searchcode for code repositories mentioning the target domain.|Free API\n[SecurityTrails](https://securitytrails.com/)|Obtain Passive DNS and other information from SecurityTrails|Tiered API\n[Seon](https://seon.io/)|Queries seon.io to gather intelligence about IP Addresses, email addresses, and phone numbers|Commercial API\n[SHODAN](https://www.shodan.io/)|Obtain information from SHODAN about identified IP addresses.|Tiered API\nSimilar Domain Finder|Search various sources to identify similar looking domain names, for instance squatted domains.|Internal\n[Skymem](http://www.skymem.info/)|Look up e-mail addresses on Skymem.|Free API\n[SlideShare](https://www.slideshare.net)|Gather name and location from SlideShare profiles.|Free API\n[Snov](https://snov.io/)|Gather available email IDs from identified domains|Tiered API\n[Social Links](https://sociallinks.io/)|Queries SocialLinks.io to gather intelligence from social media platforms and dark web.|Commercial API\n[Social Media Profile Finder](https://developers.google.com/custom-search)|Tries to discover the social media profiles for human names identified.|Tiered API\nSocial Network Identifier|Identify presence on social media networks such as LinkedIn, Twitter and others.|Internal\n[SORBS](http://www.sorbs.net/)|Query the SORBS database for open relays, open proxies, vulnerable servers, etc.|Free API\n[SpamCop](https://www.spamcop.net/)|Check if a netblock or IP address is in the SpamCop database.|Free API\n[Spamhaus Zen](https://www.spamhaus.org/)|Check if a netblock or IP address is in the Spamhaus Zen database.|Free API\n[spur.us](https://spur.us/)|Obtain information about any malicious activities involving IP addresses found|Commercial API\n[SpyOnWeb](http://spyonweb.com/)|Search SpyOnWeb for hosts sharing the same IP address, Google Analytics code, or Google Adsense code.|Tiered API\nSSL Certificate Analyzer|Gather information about SSL certificates used by the target's HTTPS sites.|Internal\n[StackOverflow](https://www.stackexchange.com)|Search StackOverflow for any mentions of a target domain. Returns potentially related information.|Tiered API\n[Steven Black Hosts](https://github.com/StevenBlack/hosts)|Check if a domain is malicious (malware or adware) according to Steven Black Hosts list.|Free API\nStrange Header Identifier|Obtain non-standard HTTP headers returned by web servers.|Internal\nSubdomain Takeover Checker|Check if affiliated subdomains are vulnerable to takeover.|Internal\n[Sublist3r PassiveDNS](https://api.sublist3r.com)|Passive subdomain enumeration using Sublist3r's API|Free API\n[SURBL](http://www.surbl.org/)|Check if a netblock, IP address or domain is in the SURBL blacklist.|Free API\n[Talos Intelligence](https://talosintelligence.com/)|Check if a netblock or IP address is malicious according to TalosIntelligence.|Free API\n[TextMagic](https://www.textmagic.com/)|Obtain phone number type from TextMagic API|Tiered API\n[Threat Jammer](https://threatjammer.com)|Check if an IP address is malicious according to ThreatJammer.com|Tiered API\n[ThreatCrowd](https://www.threatcrowd.org)|Obtain information from ThreatCrowd about identified IP addresses, domains and e-mail addresses.|Free API\n[ThreatFox](https://threatfox.abuse.ch)|Check if an IP address is malicious according to ThreatFox.|Free API\n[ThreatMiner](https://www.threatminer.org/)|Obtain information from ThreatMiner's database for passive DNS and threat intelligence.|Free API\nTLD Searcher|Search all Internet TLDs for domains with the same name as the target (this can be very slow.)|Internal\n[Tool - CMSeeK]([https://github.com/Tuhinshubhra/CMSeeK](https://github.com/Tuhinshubhra/CMSeeK))|Identify what Content Management System (CMS) might be used.|Tool\n[Tool - DNSTwist]([https://github.com/elceef/dnstwist](https://github.com/elceef/dnstwist))|Identify bit-squatting, typo and other similar domains to the target using a local DNSTwist installation.|Tool\n[Tool - nbtscan]([http://www.unixwiz.net/tools/nbtscan.html](http://www.unixwiz.net/tools/nbtscan.html))|Scans for open NETBIOS nameservers on your target's network.|Tool\n[Tool - Nmap]([https://nmap.org/](https://nmap.org/))|Identify what Operating System might be used.|Tool\n[Tool - Nuclei]([https://nuclei.projectdiscovery.io/](https://nuclei.projectdiscovery.io/))|Fast and customisable vulnerability scanner.|Tool\n[Tool - onesixtyone]([https://github.com/trailofbits/onesixtyone](https://github.com/trailofbits/onesixtyone))|Fast scanner to find publicly exposed SNMP services.|Tool\n[Tool - Retire.js]([http://retirejs.github.io/retire.js/](http://retirejs.github.io/retire.js/))|Scanner detecting the use of JavaScript libraries with known vulnerabilities|Tool\n[Tool - snallygaster]([https://github.com/hannob/snallygaster](https://github.com/hannob/snallygaster))|Finds file leaks and other security problems on HTTP servers.|Tool\n[Tool - testssl.sh]([https://testssl.sh](https://testssl.sh))|Identify various TLS/SSL weaknesses, including Heartbleed, CRIME and ROBOT.|Tool\n[Tool - TruffleHog]([https://github.com/trufflesecurity/truffleHog](https://github.com/trufflesecurity/truffleHog))|Searches through git repositories for high entropy strings and secrets, digging deep into commit history.|Tool\n[Tool - WAFW00F]([https://github.com/EnableSecurity/wafw00f](https://github.com/EnableSecurity/wafw00f))|Identify what web application firewall (WAF) is in use on the specified website.|Tool\n[Tool - Wappalyzer]([https://www.wappalyzer.com/](https://www.wappalyzer.com/))|Wappalyzer indentifies technologies on websites.|Tool\n[Tool - WhatWeb]([https://github.com/urbanadventurer/whatweb](https://github.com/urbanadventurer/whatweb))|Identify what software is in use on the specified website.|Tool\n[TOR Exit Nodes](https://metrics.torproject.org/)|Check if an IP adddress or netblock appears on the Tor Metrics exit node list.|Free API\n[TORCH](https://torchsearch.wordpress.com/)|Search Tor 'TORCH' search engine for mentions of the target domain.|Free API\n[Trashpanda](https://got-hacked.wtf)|Queries Trashpanda to gather intelligence about mentions of target in pastesites|Tiered API\n[Trumail](https://trumail.io/)|Check whether an email is disposable|Free API\n[Twilio](https://www.twilio.com/)|Obtain information from Twilio about phone numbers. Ensure you have the Caller Name add-on installed in Twilio.|Tiered API\n[Twitter](https://twitter.com/)|Gather name and location from Twitter profiles.|Free API\n[UCEPROTECT](http://www.uceprotect.net/)|Check if a netblock or IP address is in the UCEPROTECT database.|Free API\n[URLScan.io](https://urlscan.io/)|Search URLScan.io cache for domain information.|Free API\n[Venmo](https://venmo.com/)|Gather user information from Venmo API.|Free API\n[ViewDNS.info](https://viewdns.info/)|Identify co-hosted websites and perform reverse Whois lookups using ViewDNS.info.|Tiered API\n[VirusTotal](https://www.virustotal.com/)|Obtain information from VirusTotal about identified IP addresses.|Tiered API\n[VoIP Blacklist (VoIPBL)](https://voipbl.org/)|Check if an IP address or netblock is malicious according to VoIP Blacklist (VoIPBL).|Free API\n[VXVault.net](http://vxvault.net/)|Check if a domain or IP address is malicious according to VXVault.net.|Free API\nWeb Analytics Extractor|Identify web analytics IDs in scraped webpages and DNS TXT records.|Internal\nWeb Framework Identifier|Identify the usage of popular web frameworks like jQuery, YUI and others.|Internal\nWeb Server Identifier|Obtain web server banners to identify versions of web servers being used.|Internal\nWeb Spider|Spidering of web-pages to extract content for searching.|Internal\n[WhatCMS](https://whatcms.org/)|Check web technology using WhatCMS.org API.|Tiered API\n[Whoisology](https://whoisology.com/)|Reverse Whois lookups using Whoisology.com.|Commercial API\nWhois|Perform a WHOIS look-up on domain names and owned netblocks.|Internal\n[Whoxy](https://www.whoxy.com/)|Reverse Whois lookups using Whoxy.com.|Commercial API\n[WiGLE](https://wigle.net/)|Query WiGLE to identify nearby WiFi access points.|Free API\n[Wikileaks](https://wikileaks.org/)|Search Wikileaks for mentions of domain names and e-mail addresses.|Free API\n[Wikipedia Edits](https://www.wikipedia.org/)|Identify edits to Wikipedia articles made from a given IP address or username.|Free API\n[XForce Exchange](https://exchange.xforce.ibmcloud.com/)|Obtain IP reputation and passive DNS information from IBM X-Force Exchange.|Tiered API\n[Yandex DNS](https://yandex.com/)|Check if a host would be blocked by Yandex DNS.|Free API\n[Zetalytics](https://zetalytics.com/)|Query the Zetalytics database for hosts on your target domain(s).|Tiered API\n[ZoneFile.io](https://zonefiles.io)|Search ZoneFiles.io Domain query API for domain information.|Tiered API\n[Zone-H Defacement Check](https://zone-h.org/)|Check if a hostname/domain appears on the zone-h.org 'special defacements' RSS feed.|Free API\n\n### DOCUMENTATION\n\nRead more at the [project website](https://www.spiderfoot.net/r.php?u=aHR0cHM6Ly93d3cuc3BpZGVyZm9vdC5uZXQv&s=os_gh), including more complete documentation, blog posts with tutorials/guides, plus information about [SpiderFoot HX](https://www.spiderfoot.net/r.php?u=aHR0cHM6Ly93d3cuc3BpZGVyZm9vdC5uZXQvaHgvCg==&s=os_gh).\n\nLatest updates announced on [Twitter](https://twitter.com/spiderfoot).\n"
        },
        {
          "name": "THANKYOU",
          "type": "blob",
          "size": 2.1552734375,
          "content": "These people are owed some credit for their contributions to SpiderFoot, be it\nbug fixes or new functionality. Thank you!\n\n- Brendan Coles (https://github.com/bcoles)\n    - Second highest contributor to the project\n    - Tons of modules, fixes and established the whole testing framework\n    - Too many contributions to list here, see https://github.com/smicallef/spiderfoot/pulls?q=is%3Apr+author%3Abcoles+is%3Aclosed\n\n- Krishnasis Mandal (https://github.com/krishnasism)\n    - Many modules, see https://github.com/smicallef/spiderfoot/pulls?q=is%3Apr+author%3Akrishnasism+is%3Aclosed\n\n- Steve Bate (https://github.com/steve-bate)\n    - Multiple bug fixes, performance and quality improvements\n\n- fallingcubes (https://github.com/fallingcubes)\n    - Use of multiprocessing instead of threading for running multiple scans simultaneously\n\n- Counter Intrusive Technologies (https://github.com/counterintrusive)\n    - sfp_citadel updates\n\n- Dhiraj Mishra (https://github.com/RootUp)\n    - Created the sfp_h1nobbdde module\n\n- Chris Weber (http://www.casaba.com/blog/author/chris/)\n    - Many recommendations for improvement\n\n- Henri Salo (https://github.com/fgeek)\n    - Identified XSS issues (issue #29)\n\n- MarioVilas (https://github.com/MarioVilas)\n    - Contributed a fix for CSV exports (issue #35)\n\n- johnnykv (https://github.com/johnnykv)\n    - Contributed improved pip instructions\n\n- Russ McRee (@holisticinfosec)\n    - Identified XSS/CSRF issues\n\n- Andrea De Pasquale (https://github.com/adepasquale)\n    - Cache directory fix\n\n- Viyat Bhalodia (https://github.com/delta24)\n    - Prettied up README.md\n\n- Gormogon (https://github.com/Gormogon)\n    - Huge code clean up for PEP 8 compliance\n\n- Lin Zhemin (https://github.com/miaoski)\n    - Added the ability to use a configurable document root\n\n- Micah Hoffman (https://github.com/WebBreacher)\n    - Comprehensive list of URLs for identifying account usage in modules/sfp_accounts.py\n\n- Michael Pellon (https://github.com/mpellon)\n    - Providing a Dockerfile\n\n- HackershubNL (https://github.com/HackershubNL)\n    - Contributions towards authentication functionality\n\n- Mathew Woodyard (https://github.com/woodrad)\n    - Bad Packets module improvements\n"
        },
        {
          "name": "VERSION",
          "type": "blob",
          "size": 0.0166015625,
          "content": "SpiderFoot 4.0.0\n"
        },
        {
          "name": "correlations",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose-dev.yml",
          "type": "blob",
          "size": 0.076171875,
          "content": "version: \"3\"\n\nservices:\n  spiderfoot:\n    volumes:\n      - .:/home/spiderfoot\n"
        },
        {
          "name": "docker-compose-full.yml",
          "type": "blob",
          "size": 0.1005859375,
          "content": "version: \"3\"\n\nservices:\n  spiderfoot:\n    build:\n      context: ./\n      dockerfile: ./Dockerfile.full\n"
        },
        {
          "name": "docker-compose.yml",
          "type": "blob",
          "size": 0.796875,
          "content": "version: \"3\"\n\n# Basic usage:\n#     $ docker-compose up\n#\n# Dev environment (code directory mapped into container):\n#     $ docker-compose -f docker-compose.yml -f docker-compose-dev.yml up\n#\n# Full image (all CLI tools installed):\n#     $ docker-compose -f docker-compose.yml -f docker-compose-full.yml up\n#\n# Spiderfoot data resides in a Docker volume\n#\n#     $ ls -lh /var/lib/docker/volumes/spiderfoot_spiderfoot-data/_data\n#       total 104K\n#       drwxr-xr-x 2 user user 4.0K Sep 22 09:51 cache\n#       -rw-r--r-- 1 user user 100K Sep 22 15:19 spiderfoot.db\n\nservices:\n  spiderfoot:\n    build:\n      context: ./\n    volumes:\n      - spiderfoot-data:/var/lib/spiderfoot\n    image: spiderfoot\n    container_name: spiderfoot\n    ports:\n      - \"5001:5001\"\n    restart: unless-stopped\n\nvolumes:\n  spiderfoot-data:\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "generate-certificate",
          "type": "blob",
          "size": 0.4775390625,
          "content": "#!/bin/sh\nif ! command -v openssl >/dev/null 2>&1 ; then\n  echo \"Error: Could not find openssl in \\$PATH: $PATH\"\n  exit 1\nfi\n\nif test -f spiderfoot.key; then\n  echo \"Error: spiderfoot.key already exists\"\n  exit 1\nfi\n\nif test -f spiderfoot.crt; then\n  echo \"Error: spiderfoot.crt already exists\"\n  exit 1\nfi\n\nopenssl req -new -newkey rsa:4096 -sha256 -x509 -days 365 -nodes -out spiderfoot.crt -keyout spiderfoot.key -subj \"/CN=localhost\"\n\nchmod 600 spiderfoot.crt\nchmod 600 spiderfoot.key\n"
        },
        {
          "name": "modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.53125,
          "content": "adblockparser>=0.7,<1\ndnspython>=2.3.0,<3\nExifRead>=2.3.2,<3\nCherryPy>=18.8.0,<19\ncherrypy-cors>=1.6,<2\nMako>=1.2.4,<2\nbeautifulsoup4>=4.11.2,<5\nlxml>=4.9.2,<5\nnetaddr>=0.8.0,<1\npysocks>=1.7.1,<2\nrequests>=2.28.2,<3\nipwhois>=1.1.0,<1.2.0\nipaddr>=2.2.0,<3\nphonenumbers>=8.13.6,<9\npygexf>=0.2.2,<0.3\nPyPDF2>=1.28.6,<2\npython-whois>=0.7.3,<0.8\nsecure>=0.3.0,<0.4.0\npyOpenSSL>=21.0.0,<22\npython-docx>=0.8.11,<0.9\npython-pptx>=0.6.21,<0.7\nnetworkx>=2.6.3,<2.7\ncryptography>=3.4.8,<4\npublicsuffixlist>=0.9.3,<0.10\nopenpyxl>=3.1.1,<4\npyyaml>=6.0.0,<7\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.7080078125,
          "content": "[flake8]\nflake8-max-line-length = 120\nmax-complexity = 60\ndocstring-convention = google\nignore-decorators = property\nselect = C,E,F,W,B,B9,DAR,DUO,R,A,S,Q0,SIM,SFS\n# Note: B902, B907 and ANN should be fixed instead of ignored\nextend-ignore = E501 W503 B006 B950 SFS301 SF01 Q000 B902 B907 ANN\n# Note: most of these should be fixed instead of ignored\nper-file-ignores =\n    spiderfoot/event.py:A003\n    spiderfoot/db.py:SFS101\n    modules/*:SIM102,SIM113,SIM114\n    modules/sfp_alienvault.py:C901\n    modules/sfp_binaryedge.py:C901\n    modules/sfp_bitcoin.py:SFS101\n    spiderfoot/__init__.py:F401\n    sfcli.py:DAR\n    sfwebui.py:A001,A002,B905\n    test/*:SIM117,B904,ANN\n    docs/conf.py:A\n\n[darglint]\ndocstring_style=google\n"
        },
        {
          "name": "sf.py",
          "type": "blob",
          "size": 24.0224609375,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# -------------------------------------------------------------------------------\n# Name:         sf\n# Purpose:      Main wrapper for calling all SpiderFoot modules\n#\n# Author:      Steve Micallef <steve@binarypool.com>\n#\n# Created:     03/04/2012\n# Copyright:   (c) Steve Micallef 2012\n# Licence:     MIT\n# -------------------------------------------------------------------------------\n\nimport argparse\nimport logging\nimport multiprocessing as mp\nimport os\nimport os.path\nimport random\nimport signal\nimport sys\nimport time\nfrom copy import deepcopy\n\nimport cherrypy\nimport cherrypy_cors\nfrom cherrypy.lib import auth_digest\n\nfrom sflib import SpiderFoot\nfrom sfscan import startSpiderFootScanner\nfrom sfwebui import SpiderFootWebUi\nfrom spiderfoot import SpiderFootHelpers\nfrom spiderfoot import SpiderFootDb\nfrom spiderfoot import SpiderFootCorrelator\nfrom spiderfoot.logger import logListenerSetup, logWorkerSetup\nfrom spiderfoot import __version__\n\nscanId = None\ndbh = None\n\n\ndef main() -> None:\n    # web server config\n    sfWebUiConfig = {\n        'host': '127.0.0.1',\n        'port': 5001,\n        'root': '/',\n        'cors_origins': [],\n    }\n\n    # 'Global' configuration options\n    # These can be overriden on a per-module basis, and some will\n    # be overridden from saved configuration settings stored in the DB.\n    sfConfig = {\n        '_debug': False,  # Debug\n        '_maxthreads': 3,  # Number of modules to run concurrently\n        '__logging': True,  # Logging in general\n        '__outputfilter': None,  # Event types to filter from modules' output\n        '_useragent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0',  # User-Agent to use for HTTP requests\n        '_dnsserver': '',  # Override the default resolver\n        '_fetchtimeout': 5,  # number of seconds before giving up on a fetch\n        '_internettlds': 'https://publicsuffix.org/list/effective_tld_names.dat',\n        '_internettlds_cache': 72,\n        '_genericusers': \",\".join(SpiderFootHelpers.usernamesFromWordlists(['generic-usernames'])),\n        '__database': f\"{SpiderFootHelpers.dataPath()}/spiderfoot.db\",\n        '__modules__': None,  # List of modules. Will be set after start-up.\n        '__correlationrules__': None,  # List of correlation rules. Will be set after start-up.\n        '_socks1type': '',\n        '_socks2addr': '',\n        '_socks3port': '',\n        '_socks4user': '',\n        '_socks5pwd': '',\n    }\n\n    sfOptdescs = {\n        '_debug': \"Enable debugging?\",\n        '_maxthreads': \"Max number of modules to run concurrently\",\n        '_useragent': \"User-Agent string to use for HTTP requests. Prefix with an '@' to randomly select the User Agent from a file containing user agent strings for each request, e.g. @C:\\\\useragents.txt or @/home/bob/useragents.txt. Or supply a URL to load the list from there.\",\n        '_dnsserver': \"Override the default resolver with another DNS server. For example, 8.8.8.8 is Google's open DNS server.\",\n        '_fetchtimeout': \"Number of seconds before giving up on a HTTP request.\",\n        '_internettlds': \"List of Internet TLDs.\",\n        '_internettlds_cache': \"Hours to cache the Internet TLD list. This can safely be quite a long time given that the list doesn't change too often.\",\n        '_genericusers': \"List of usernames that if found as usernames or as part of e-mail addresses, should be treated differently to non-generics.\",\n        '_socks1type': \"SOCKS Server Type. Can be '4', '5', 'HTTP' or 'TOR'\",\n        '_socks2addr': 'SOCKS Server IP Address.',\n        '_socks3port': 'SOCKS Server TCP Port. Usually 1080 for 4/5, 8080 for HTTP and 9050 for TOR.',\n        '_socks4user': 'SOCKS Username. Valid only for SOCKS4 and SOCKS5 servers.',\n        '_socks5pwd': \"SOCKS Password. Valid only for SOCKS5 servers.\",\n        '_modulesenabled': \"Modules enabled for the scan.\"  # This is a hack to get a description for an option not actually available.\n    }\n\n    # Legacy way to run the server\n    args = None\n    p = argparse.ArgumentParser(description=f\"SpiderFoot {__version__}: Open Source Intelligence Automation.\")\n    p.add_argument(\"-d\", \"--debug\", action='store_true', help=\"Enable debug output.\")\n    p.add_argument(\"-l\", metavar=\"IP:port\", help=\"IP and port to listen on.\")\n    p.add_argument(\"-m\", metavar=\"mod1,mod2,...\", type=str, help=\"Modules to enable.\")\n    p.add_argument(\"-M\", \"--modules\", action='store_true', help=\"List available modules.\")\n    p.add_argument(\"-C\", \"--correlate\", metavar=\"scanID\", help=\"Run correlation rules against a scan ID.\")\n    p.add_argument(\"-s\", metavar=\"TARGET\", help=\"Target for the scan.\")\n    p.add_argument(\"-t\", metavar=\"type1,type2,...\", type=str, help=\"Event types to collect (modules selected automatically).\")\n    p.add_argument(\"-u\", choices=[\"all\", \"footprint\", \"investigate\", \"passive\"], type=str, help=\"Select modules automatically by use case\")\n    p.add_argument(\"-T\", \"--types\", action='store_true', help=\"List available event types.\")\n    p.add_argument(\"-o\", choices=[\"tab\", \"csv\", \"json\"], type=str, help=\"Output format. Tab is default.\")\n    p.add_argument(\"-H\", action='store_true', help=\"Don't print field headers, just data.\")\n    p.add_argument(\"-n\", action='store_true', help=\"Strip newlines from data.\")\n    p.add_argument(\"-r\", action='store_true', help=\"Include the source data field in tab/csv output.\")\n    p.add_argument(\"-S\", metavar=\"LENGTH\", type=int, help=\"Maximum data length to display. By default, all data is shown.\")\n    p.add_argument(\"-D\", metavar='DELIMITER', type=str, help=\"Delimiter to use for CSV output. Default is ,.\")\n    p.add_argument(\"-f\", action='store_true', help=\"Filter out other event types that weren't requested with -t.\")\n    p.add_argument(\"-F\", metavar=\"type1,type2,...\", type=str, help=\"Show only a set of event types, comma-separated.\")\n    p.add_argument(\"-x\", action='store_true', help=\"STRICT MODE. Will only enable modules that can directly consume your target, and if -t was specified only those events will be consumed by modules. This overrides -t and -m options.\")\n    p.add_argument(\"-q\", action='store_true', help=\"Disable logging. This will also hide errors!\")\n    p.add_argument(\"-V\", \"--version\", action='store_true', help=\"Display the version of SpiderFoot and exit.\")\n    p.add_argument(\"-max-threads\", type=int, help=\"Max number of modules to run concurrently.\")\n    args = p.parse_args()\n\n    if args.version:\n        print(f\"SpiderFoot {__version__}: Open Source Intelligence Automation.\")\n        sys.exit(0)\n\n    if args.max_threads:\n        sfConfig['_maxthreads'] = args.max_threads\n\n    if args.debug:\n        sfConfig['_debug'] = True\n    else:\n        sfConfig['_debug'] = False\n\n    if args.q:\n        sfConfig['__logging'] = False\n\n    loggingQueue = mp.Queue()\n    logListenerSetup(loggingQueue, sfConfig)\n    logWorkerSetup(loggingQueue)\n    log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n    # Add descriptions of the global config options\n    sfConfig['__globaloptdescs__'] = sfOptdescs\n\n    # Load each module in the modules directory with a .py extension\n    try:\n        mod_dir = os.path.dirname(os.path.abspath(__file__)) + '/modules/'\n        sfModules = SpiderFootHelpers.loadModulesAsDict(mod_dir, ['sfp_template.py'])\n    except BaseException as e:\n        log.critical(f\"Failed to load modules: {e}\", exc_info=True)\n        sys.exit(-1)\n\n    if not sfModules:\n        log.critical(f\"No modules found in modules directory: {mod_dir}\")\n        sys.exit(-1)\n\n    # Load each correlation rule in the correlations directory with\n    # a .yaml extension\n    try:\n        correlations_dir = os.path.dirname(os.path.abspath(__file__)) + '/correlations/'\n        correlationRulesRaw = SpiderFootHelpers.loadCorrelationRulesRaw(correlations_dir, ['template.yaml'])\n    except BaseException as e:\n        log.critical(f\"Failed to load correlation rules: {e}\", exc_info=True)\n        sys.exit(-1)\n\n    # Initialize database handle\n    try:\n        dbh = SpiderFootDb(sfConfig)\n    except Exception as e:\n        log.critical(f\"Failed to initialize database: {e}\", exc_info=True)\n        sys.exit(-1)\n\n    # Sanity-check the rules and parse them\n    sfCorrelationRules = list()\n    if not correlationRulesRaw:\n        log.error(f\"No correlation rules found in correlations directory: {correlations_dir}\")\n    else:\n        try:\n            correlator = SpiderFootCorrelator(dbh, correlationRulesRaw)\n            sfCorrelationRules = correlator.get_ruleset()\n        except Exception as e:\n            log.critical(f\"Failure initializing correlation rules: {e}\", exc_info=True)\n            sys.exit(-1)\n\n    # Add modules and correlation rules to sfConfig so they can be used elsewhere\n    sfConfig['__modules__'] = sfModules\n    sfConfig['__correlationrules__'] = sfCorrelationRules\n\n    if args.correlate:\n        if not correlationRulesRaw:\n            log.error(\"Unable to perform correlations as no correlation rules were found.\")\n            sys.exit(-1)\n\n        try:\n            log.info(f\"Running {len(correlationRulesRaw)} correlation rules against scan, {args.correlate}.\")\n            corr = SpiderFootCorrelator(dbh, correlationRulesRaw, args.correlate)\n            corr.run_correlations()\n        except Exception as e:\n            log.critical(f\"Unable to run correlation rules: {e}\", exc_info=True)\n            sys.exit(-1)\n        sys.exit(0)\n\n    if args.modules:\n        log.info(\"Modules available:\")\n        for m in sorted(sfModules.keys()):\n            if \"__\" in m:\n                continue\n            print(f\"{m.ljust(25)}  {sfModules[m]['descr']}\")\n        sys.exit(0)\n\n    if args.types:\n        dbh = SpiderFootDb(sfConfig, init=True)\n        log.info(\"Types available:\")\n        typedata = dbh.eventTypes()\n        types = dict()\n        for r in typedata:\n            types[r[1]] = r[0]\n\n        for t in sorted(types.keys()):\n            print(f\"{t.ljust(45)}  {types[t]}\")\n        sys.exit(0)\n\n    if args.l:\n        try:\n            (host, port) = args.l.split(\":\")\n        except BaseException:\n            log.critical(\"Invalid ip:port format.\")\n            sys.exit(-1)\n\n        sfWebUiConfig['host'] = host\n        sfWebUiConfig['port'] = port\n\n        start_web_server(sfWebUiConfig, sfConfig, loggingQueue)\n        sys.exit(0)\n\n    start_scan(sfConfig, sfModules, args, loggingQueue)\n\n\ndef start_scan(sfConfig: dict, sfModules: dict, args, loggingQueue) -> None:\n    \"\"\"Start scan\n\n    Args:\n        sfConfig (dict): SpiderFoot config options\n        sfModules (dict): modules\n        args (argparse.Namespace): command line args\n        loggingQueue (Queue): main SpiderFoot logging queue\n    \"\"\"\n    log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n    global dbh\n    global scanId\n\n    dbh = SpiderFootDb(sfConfig, init=True)\n    sf = SpiderFoot(sfConfig)\n\n    if not args.s:\n        log.error(\"You must specify a target when running in scan mode. Try --help for guidance.\")\n        sys.exit(-1)\n\n    if args.x and not args.t:\n        log.error(\"-x can only be used with -t. Use --help for guidance.\")\n        sys.exit(-1)\n\n    if args.x and args.m:\n        log.error(\"-x can only be used with -t and not with -m. Use --help for guidance.\")\n        sys.exit(-1)\n\n    if args.r and (args.o and args.o not in [\"tab\", \"csv\"]):\n        log.error(\"-r can only be used when your output format is tab or csv.\")\n        sys.exit(-1)\n\n    if args.H and (args.o and args.o not in [\"tab\", \"csv\"]):\n        log.error(\"-H can only be used when your output format is tab or csv.\")\n        sys.exit(-1)\n\n    if args.D and args.o != \"csv\":\n        log.error(\"-D can only be used when using the csv output format.\")\n        sys.exit(-1)\n\n    target = args.s\n    # Usernames and names - quoted on the commandline - won't have quotes,\n    # so add them.\n    if \" \" in target:\n        target = f\"\\\"{target}\\\"\"\n    if \".\" not in target and not target.startswith(\"+\") and '\"' not in target:\n        target = f\"\\\"{target}\\\"\"\n    targetType = SpiderFootHelpers.targetTypeFromString(target)\n\n    if not targetType:\n        log.error(f\"Could not determine target type. Invalid target: {target}\")\n        sys.exit(-1)\n\n    target = target.strip('\"')\n\n    modlist = list()\n    if not args.t and not args.m and not args.u:\n        log.warning(\"You didn't specify any modules, types or use case, so all modules will be enabled.\")\n        for m in list(sfModules.keys()):\n            if \"__\" in m:\n                continue\n            modlist.append(m)\n\n    signal.signal(signal.SIGINT, handle_abort)\n    # If the user is scanning by type..\n    # 1. Find modules producing that type\n    if args.t:\n        types = args.t\n        modlist = sf.modulesProducing(types)\n        newmods = deepcopy(modlist)\n        newmodcpy = deepcopy(newmods)\n\n        # 2. For each type those modules consume, get modules producing\n        while len(newmodcpy) > 0:\n            for etype in sf.eventsToModules(newmodcpy):\n                xmods = sf.modulesProducing([etype])\n                for mod in xmods:\n                    if mod not in modlist:\n                        modlist.append(mod)\n                        newmods.append(mod)\n            newmodcpy = deepcopy(newmods)\n            newmods = list()\n\n    # Easier if scanning by module\n    if args.m:\n        modlist = list(filter(None, args.m.split(\",\")))\n\n    # Select modules if the user selected usercase\n    if args.u:\n        usecase = args.u[0].upper() + args.u[1:]  # Make the first Letter Uppercase\n        for mod in sfConfig['__modules__']:\n            if usecase == 'All' or usecase in sfConfig['__modules__'][mod]['group']:\n                modlist.append(mod)\n\n    # Add sfp__stor_stdout to the module list\n    typedata = dbh.eventTypes()\n    types = dict()\n    for r in typedata:\n        types[r[1]] = r[0]\n\n    sfp__stor_stdout_opts = sfConfig['__modules__']['sfp__stor_stdout']['opts']\n    sfp__stor_stdout_opts['_eventtypes'] = types\n    if args.f:\n        if args.f and not args.t:\n            log.error(\"You can only use -f with -t. Use --help for guidance.\")\n            sys.exit(-1)\n        sfp__stor_stdout_opts['_showonlyrequested'] = True\n    if args.F:\n        sfp__stor_stdout_opts['_requested'] = args.F.split(\",\")\n        sfp__stor_stdout_opts['_showonlyrequested'] = True\n    if args.o:\n        if args.o not in [\"tab\", \"csv\", \"json\"]:\n            log.error(\"Invalid output format selected. Must be 'tab', 'csv' or 'json'.\")\n            sys.exit(-1)\n        sfp__stor_stdout_opts['_format'] = args.o\n    if args.t:\n        sfp__stor_stdout_opts['_requested'] = args.t.split(\",\")\n    if args.n:\n        sfp__stor_stdout_opts['_stripnewline'] = True\n    if args.r:\n        sfp__stor_stdout_opts['_showsource'] = True\n    if args.S:\n        sfp__stor_stdout_opts['_maxlength'] = args.S\n    if args.D:\n        sfp__stor_stdout_opts['_csvdelim'] = args.D\n    if args.x:\n        tmodlist = list()\n        modlist = list()\n        xmods = sf.modulesConsuming([targetType])\n        for mod in xmods:\n            if mod not in modlist:\n                tmodlist.append(mod)\n\n        # Remove any modules not producing the type requested\n        rtypes = args.t.split(\",\")\n        for mod in tmodlist:\n            for r in rtypes:\n                if not sfModules[mod]['provides']:\n                    continue\n                if r in sfModules[mod].get('provides', []) and mod not in modlist:\n                    modlist.append(mod)\n\n    if len(modlist) == 0:\n        log.error(\"Based on your criteria, no modules were enabled.\")\n        sys.exit(-1)\n\n    modlist += [\"sfp__stor_db\", \"sfp__stor_stdout\"]\n\n    if sfConfig['__logging']:\n        log.info(f\"Modules enabled ({len(modlist)}): {','.join(modlist)}\")\n\n    cfg = sf.configUnserialize(dbh.configGet(), sfConfig)\n\n    # Debug mode is a variable that gets stored to the DB, so re-apply it\n    if args.debug:\n        cfg['_debug'] = True\n    else:\n        cfg['_debug'] = False\n\n    # If strict mode is enabled, filter the output from modules.\n    if args.x and args.t:\n        cfg['__outputfilter'] = args.t.split(\",\")\n\n    # Prepare scan output headers\n    if args.o == \"json\":\n        print(\"[\", end='')\n    elif not args.H:\n        delim = \"\\t\"\n\n        if args.o == \"tab\":\n            delim = \"\\t\"\n\n        if args.o == \"csv\":\n            if args.D:\n                delim = args.D\n            else:\n                delim = \",\"\n\n        if args.r:\n            if delim == \"\\t\":\n                headers = delim.join([\"Source\".ljust(30), \"Type\".ljust(45), \"Source Data\", \"Data\"])\n            else:\n                headers = delim.join([\"Source\", \"Type\", \"Source Data\", \"Data\"])\n        else:\n            if delim == \"\\t\":\n                headers = delim.join([\"Source\".ljust(30), \"Type\".ljust(45), \"Data\"])\n            else:\n                headers = delim.join([\"Source\", \"Type\", \"Data\"])\n\n        print(headers)\n\n    # Start running a new scan\n    scanName = target\n    scanId = SpiderFootHelpers.genScanInstanceId()\n    try:\n        p = mp.Process(target=startSpiderFootScanner, args=(loggingQueue, scanName, scanId, target, targetType, modlist, cfg))\n        p.daemon = True\n        p.start()\n    except BaseException as e:\n        log.error(f\"Scan [{scanId}] failed: {e}\")\n        sys.exit(-1)\n\n    # Poll for scan status until completion\n    while True:\n        time.sleep(1)\n        info = dbh.scanInstanceGet(scanId)\n        if not info:\n            continue\n        if info[5] in [\"ERROR-FAILED\", \"ABORT-REQUESTED\", \"ABORTED\", \"FINISHED\"]:\n            # allow 60 seconds for post-scan correlations to complete\n            timeout = 60\n            p.join(timeout=timeout)\n            if (p.is_alive()):\n                log.error(f\"Timeout reached ({timeout}s) waiting for scan {scanId} post-processing to complete.\")\n                sys.exit(-1)\n\n            if sfConfig['__logging']:\n                log.info(f\"Scan completed with status {info[5]}\")\n            if args.o == \"json\":\n                print(\"]\")\n            sys.exit(0)\n\n    return\n\n\ndef start_web_server(sfWebUiConfig: dict, sfConfig: dict, loggingQueue=None) -> None:\n    \"\"\"Start the web server so you can start looking at results\n\n    Args:\n        sfWebUiConfig (dict): web server options\n        sfConfig (dict): SpiderFoot config options\n        loggingQueue (Queue): main SpiderFoot logging queue\n    \"\"\"\n    log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n    web_host = sfWebUiConfig.get('host', '127.0.0.1')\n    web_port = sfWebUiConfig.get('port', 5001)\n    web_root = sfWebUiConfig.get('root', '/')\n    cors_origins = sfWebUiConfig.get('cors_origins', [])\n\n    cherrypy.config.update({\n        'log.screen': False,\n        'server.socket_host': web_host,\n        'server.socket_port': int(web_port)\n    })\n\n    log.info(f\"Starting web server at {web_host}:{web_port} ...\")\n\n    # Enable access to static files via the web directory\n    conf = {\n        '/query': {\n            'tools.encode.text_only': False,\n            'tools.encode.add_charset': True,\n        },\n        '/static': {\n            'tools.staticdir.on': True,\n            'tools.staticdir.dir': 'static',\n            'tools.staticdir.root': f\"{os.path.dirname(os.path.abspath(__file__))}/spiderfoot\"\n        }\n    }\n\n    secrets = dict()\n    passwd_file = SpiderFootHelpers.dataPath() + '/passwd'\n    if os.path.isfile(passwd_file):\n        if not os.access(passwd_file, os.R_OK):\n            log.error(\"Could not read passwd file. Permission denied.\")\n            sys.exit(-1)\n\n        with open(passwd_file, 'r') as f:\n            passwd_data = f.readlines()\n\n        for line in passwd_data:\n            if line.strip() == '':\n                continue\n\n            if ':' not in line:\n                log.error(\"Incorrect format of passwd file, must be username:password on each line.\")\n                sys.exit(-1)\n\n            u = line.strip().split(\":\")[0]\n            p = ':'.join(line.strip().split(\":\")[1:])\n\n            if not u or not p:\n                log.error(\"Incorrect format of passwd file, must be username:password on each line.\")\n                sys.exit(-1)\n\n            secrets[u] = p\n\n    if secrets:\n        log.info(\"Enabling authentication based on supplied passwd file.\")\n        conf['/'] = {\n            'tools.auth_digest.on': True,\n            'tools.auth_digest.realm': web_host,\n            'tools.auth_digest.get_ha1': auth_digest.get_ha1_dict_plain(secrets),\n            'tools.auth_digest.key': random.SystemRandom().randint(0, 99999999)\n        }\n    else:\n        warn_msg = \"\\n********************************************************************\\n\"\n        warn_msg += \"Warning: passwd file contains no passwords. Authentication disabled.\\n\"\n        warn_msg += \"Please consider adding authentication to protect this instance!\\n\"\n        warn_msg += \"Refer to https://www.spiderfoot.net/documentation/#security.\\n\"\n        warn_msg += \"********************************************************************\\n\"\n        log.warning(warn_msg)\n\n    using_ssl = False\n    key_path = SpiderFootHelpers.dataPath() + '/spiderfoot.key'\n    crt_path = SpiderFootHelpers.dataPath() + '/spiderfoot.crt'\n    if os.path.isfile(key_path) and os.path.isfile(crt_path):\n        if not os.access(crt_path, os.R_OK):\n            log.critical(f\"Could not read {crt_path} file. Permission denied.\")\n            sys.exit(-1)\n\n        if not os.access(key_path, os.R_OK):\n            log.critical(f\"Could not read {key_path} file. Permission denied.\")\n            sys.exit(-1)\n\n        log.info(\"Enabling SSL based on supplied key and certificate file.\")\n        cherrypy.server.ssl_module = 'builtin'\n        cherrypy.server.ssl_certificate = crt_path\n        cherrypy.server.ssl_private_key = key_path\n        using_ssl = True\n\n    if using_ssl:\n        url = \"https://\"\n    else:\n        url = \"http://\"\n\n    if web_host == \"0.0.0.0\":  # nosec\n        url = f\"{url}127.0.0.1:{web_port}\"\n    else:\n        url = f\"{url}{web_host}:{web_port}{web_root}\"\n        cors_origins.append(url)\n\n    cherrypy_cors.install()\n    cherrypy.config.update({\n        'cors.expose.on': True,\n        'cors.expose.origins': cors_origins,\n        'cors.preflight.origins': cors_origins\n    })\n\n    print(\"\")\n    print(\"*************************************************************\")\n    print(\" Use SpiderFoot by starting your web browser of choice and \")\n    print(f\" browse to {url}\")\n    print(\"*************************************************************\")\n    print(\"\")\n\n    # Disable auto-reloading of content\n    cherrypy.engine.autoreload.unsubscribe()\n\n    cherrypy.quickstart(SpiderFootWebUi(sfWebUiConfig, sfConfig, loggingQueue), script_name=web_root, config=conf)\n\n\ndef handle_abort(signal, frame) -> None:\n    \"\"\"Handle interrupt and abort scan.\n\n    Args:\n        signal: TBD\n        frame: TBD\n    \"\"\"\n    log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n    global dbh\n    global scanId\n\n    if scanId and dbh:\n        log.info(f\"Aborting scan [{scanId}] ...\")\n        dbh.scanInstanceSet(scanId, None, None, \"ABORTED\")\n    sys.exit(-1)\n\n\nif __name__ == '__main__':\n    if sys.version_info < (3, 7):\n        print(\"SpiderFoot requires Python 3.7 or higher.\")\n        sys.exit(-1)\n\n    if len(sys.argv) <= 1:\n        print(\"SpiderFoot requires -l <ip>:<port> to start the web server. Try --help for guidance.\")\n        sys.exit(-1)\n\n    # TODO: remove this after a few releases (added in 3.5 pre-release 2021-09-05)\n    from pathlib import Path\n    if os.path.exists('spiderfoot.db'):\n        print(f\"ERROR: spiderfoot.db file exists in {os.path.dirname(__file__)}\")\n        print(\"SpiderFoot no longer supports loading the spiderfoot.db database from the application directory.\")\n        print(f\"The database is now loaded from your home directory: {Path.home()}/.spiderfoot/spiderfoot.db\")\n        print(f\"This message will go away once you move or remove spiderfoot.db from {os.path.dirname(__file__)}\")\n        sys.exit(-1)\n\n    # TODO: remove this after a few releases (added in 3.5 pre-release 2021-09-05)\n    from pathlib import Path\n    if os.path.exists('passwd'):\n        print(f\"ERROR: passwd file exists in {os.path.dirname(__file__)}\")\n        print(\"SpiderFoot no longer supports loading credentials from the application directory.\")\n        print(f\"The passwd file is now loaded from your home directory: {Path.home()}/.spiderfoot/passwd\")\n        print(f\"This message will go away once you move or remove passwd from {os.path.dirname(__file__)}\")\n        sys.exit(-1)\n\n    main()\n"
        },
        {
          "name": "sfcli.py",
          "type": "blob",
          "size": 44.7763671875,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# -------------------------------------------------------------------------------\n# Name:        sfcli\n# Purpose:     Command Line Interface for SpiderFoot.\n#\n# Author:      Steve Micallef <steve@binarypool.com>\n#\n# Created:     03/05/2017\n# Copyright:   (c) Steve Micallef 2017\n# Licence:     MIT\n# -------------------------------------------------------------------------------\n\nimport argparse\nimport cmd\nimport codecs\nimport io\nimport json\nimport os\nimport re\nimport shlex\nimport sys\nimport time\nfrom os.path import expanduser\n\nimport requests\n\n\nASCII_LOGO = r\"\"\"\n  _________      .__    .___          ___________            __\n /   _____/_____ |__| __| _/__________\\_   _____/___   _____/  |_\n \\_____  \\\\____ \\|  |/ __ |/ __ \\_  __ \\    __)/  _ \\ /  _ \\   __\\\n /        \\  |_> >  / /_/ \\  ___/|  | \\/     \\(  <_> |  <_> )  |\n/_______  /   __/|__\\____ |\\___  >__|  \\___  / \\____/ \\____/|__|\n        \\/|__|           \\/    \\/          \\/\n                Open Source Intelligence Automation.\"\"\"\nCOPYRIGHT_INFO = \"               by Steve Micallef | @spiderfoot\\n\"\n\ntry:\n    import readline\nexcept ImportError:\n    import pyreadline as readline\n\n\n# Colors to make things purty\nclass bcolors:\n    GREYBLUE = '\\x1b[38;5;25m'\n    GREY = '\\x1b[38;5;243m'\n    DARKRED = '\\x1b[38;5;124m'\n    DARKGREEN = '\\x1b[38;5;30m'\n    BOLD = '\\033[1m'\n    ENDC = '\\033[0m'\n    GREYBLUE_DARK = '\\x1b[38;5;24m'\n\n\nclass SpiderFootCli(cmd.Cmd):\n    version = \"4.0.0\"\n    pipecmd = None\n    output = None\n    modules = []\n    types = []\n    correlationrules = []\n    prompt = \"sf> \"\n    nohelp = \"[!] Unknown command '%s'.\"\n    knownscans = []\n    ownopts = {\n        \"cli.debug\": False,\n        \"cli.silent\": False,\n        \"cli.color\": True,\n        \"cli.output\": \"pretty\",\n        \"cli.history\": True,\n        \"cli.history_file\": \"\",\n        \"cli.spool\": False,\n        \"cli.spool_file\": \"\",\n        \"cli.ssl_verify\": True,\n        \"cli.username\": \"\",\n        \"cli.password\": \"\",\n        \"cli.server_baseurl\": \"http://127.0.0.1:5001\"\n    }\n\n    def default(self, line):\n        if line.startswith('#'):\n            return\n\n        self.edprint(\"Unknown command\")\n\n    # Auto-complete for these commands\n    def complete_start(self, text, line, startidx, endidx):\n        return self.complete_default(text, line, startidx, endidx)\n\n    def complete_find(self, text, line, startidx, endidx):\n        return self.complete_default(text, line, startidx, endidx)\n\n    def complete_data(self, text, line, startidx, endidx):\n        return self.complete_default(text, line, startidx, endidx)\n\n    # Command completion for arguments\n    def complete_default(self, text, line, startidx, endidx):\n        ret = list()\n\n        if not isinstance(text, str):\n            return ret\n\n        if not isinstance(line, str):\n            return ret\n\n        if \"-m\" in line and line.find(\"-m\") > line.find(\"-t\"):\n            for m in self.modules:\n                if m.startswith(text):\n                    ret.append(m)\n\n        if \"-t\" in line and line.find(\"-t\") > line.find(\"-m\"):\n            for t in self.types:\n                if t.startswith(text):\n                    ret.append(t)\n        return ret\n\n    def dprint(self, msg, err=False, deb=False, plain=False, color=None):\n        cout = \"\"\n        sout = \"\"\n        pfx = \"\"\n        col = \"\"\n        if err:\n            pfx = \"[!]\"\n            if self.ownopts['cli.color']:\n                col = bcolors.DARKRED\n        else:\n            pfx = \"[*]\"\n            if self.ownopts['cli.color']:\n                col = bcolors.DARKGREEN\n        if deb:\n            if not self.ownopts[\"cli.debug\"]:\n                return\n            pfx = \"[+]\"\n            if self.ownopts['cli.color']:\n                col = bcolors.GREY\n\n        if color:\n            pfx = \"\"\n            col = color\n\n        if err or not self.ownopts[\"cli.silent\"]:\n            if not plain or color:\n                cout = col + bcolors.BOLD + pfx + \" \" + bcolors.ENDC + col + msg + bcolors.ENDC\n                # Never include color in the spool\n                sout = pfx + \" \" + msg\n            else:\n                cout = msg\n                sout = msg\n\n            print(cout)\n\n        if self.ownopts['cli.spool']:\n            f = codecs.open(self.ownopts['cli.spool_file'], \"a\", encoding=\"utf-8\")\n            f.write(sout)\n            f.write('\\n')\n            f.close()\n\n    # Shortcut commands\n    def do_debug(self, line):\n        \"\"\"debug\n        Short-cut command for set cli.debug = 1\"\"\"\n        if self.ownopts['cli.debug']:\n            val = \"0\"\n        else:\n            val = \"1\"\n        return self.do_set(\"cli.debug = \" + val)\n\n    def do_spool(self, line):\n        \"\"\"spool\n        Short-cut command for set cli.spool = 1/0\"\"\"\n        if self.ownopts['cli.spool']:\n            val = \"0\"\n        else:\n            val = \"1\"\n\n        if self.ownopts['cli.spool_file']:\n            return self.do_set(\"cli.spool = \" + val)\n\n        self.edprint(\"You haven't set cli.spool_file. Set that before enabling spooling.\")\n\n        return None\n\n    def do_history(self, line):\n        \"\"\"history [-l]\n        Short-cut command for set cli.history = 1/0.\n        Add -l to just list the history.\"\"\"\n        c = self.myparseline(line)\n\n        if '-l' in c[0]:\n            i = 0\n            while i < readline.get_current_history_length():\n                self.dprint(readline.get_history_item(i), plain=True)\n                i += 1\n            return None\n\n        if self.ownopts['cli.history']:\n            val = \"0\"\n        else:\n            val = \"1\"\n\n        return self.do_set(\"cli.history = \" + val)\n\n    # Run before all commands to handle history and spooling\n    def precmd(self, line):\n        if self.ownopts['cli.history'] and line != \"EOF\":\n            f = codecs.open(self.ownopts[\"cli.history_file\"], \"a\", encoding=\"utf-8\")\n            f.write(line)\n            f.write('\\n')\n            f.close()\n        if self.ownopts['cli.spool']:\n            f = codecs.open(self.ownopts[\"cli.spool_file\"], \"a\", encoding=\"utf-8\")\n            f.write(self.prompt + line)\n            f.write('\\n')\n            f.close()\n\n        return line\n\n    # Debug print\n    def ddprint(self, msg):\n        self.dprint(msg, deb=True)\n\n    # Error print\n    def edprint(self, msg):\n        self.dprint(msg, err=True)\n\n    # Print nice tables.\n    def pretty(self, data, titlemap=None):\n        if not data:\n            return \"\"\n\n        out = list()\n        # Get the column titles\n        maxsize = dict()\n        if type(data[0]) == dict:\n            cols = list(data[0].keys())\n        else:\n            # for lists, use the index numbers as titles\n            cols = list(map(str, list(range(0, len(data[0])))))\n\n        # Strip out columns that don't have titles\n        if titlemap:\n            nc = list()\n            for c in cols:\n                if c in titlemap:\n                    nc.append(c)\n            cols = nc\n\n        spaces = 2\n        # Find the maximum column sizes\n        for r in data:\n            for i, c in enumerate(r):\n                if type(r) == list:\n                    # we have  list index\n                    cn = str(i)\n                    if type(c) == int:\n                        v = str(c)\n                    if type(c) == str:\n                        v = c\n                else:\n                    # we have a dict key\n                    cn = c\n                    v = str(r[c])\n                # print(str(cn) + \", \" + str(c) + \", \" + str(v))\n                if len(v) > maxsize.get(cn, 0):\n                    maxsize[cn] = len(v)\n\n        # Adjust for long titles\n        if titlemap:\n            for c in maxsize:\n                if len(titlemap.get(c, c)) > maxsize[c]:\n                    maxsize[c] = len(titlemap.get(c, c))\n\n        # Display the column titles\n        for i, c in enumerate(cols):\n            if titlemap:\n                t = titlemap.get(c, c)\n            else:\n                t = c\n            # out += t\n            out.append(t)\n            sdiff = maxsize[c] - len(t) + 1\n            # out += \" \" * spaces\n            out.append(\" \" * spaces)\n            if sdiff > 0 and i < len(cols) - 1:\n                # out += \" \" * sdiff\n                out.append(\" \" * sdiff)\n        # out += \"\\n\"\n        out.append('\\n')\n\n        # Then the separator\n        for i, c in enumerate(cols):\n            # out += \"-\" * ((maxsize[c]+spaces))\n            out.append(\"-\" * ((maxsize[c] + spaces)))\n            if i < len(cols) - 1:\n                # out += \"+\"\n                out.append(\"+\")\n        # out += \"\\n\"\n        out.append(\"\\n\")\n\n        # Then the actual data\n        # ts = time.time()\n        for r in data:\n            i = 0\n            di = 0\n            tr = type(r)\n            for c in r:\n                if tr == list:\n                    # we have  list index\n                    cn = str(i)\n                    tc = type(c)\n                    if tc == int:\n                        v = str(c)\n                    if tc == str:\n                        v = c\n                else:\n                    # we have a dict key\n                    cn = c\n                    v = str(r[c])\n                if cn not in cols:\n                    i += 1\n                    continue\n\n                out.append(v)\n                lv = len(v)\n                # there is a preceeding space if this is after the\n                # first column\n                # sdiff = number of spaces between end of word and |\n                if di == 0:\n                    sdiff = (maxsize[cn] - lv) + spaces\n                else:\n                    sdiff = (maxsize[cn] - lv) + spaces - 1\n                if di < len(cols) - 1:\n                    # out += \" \" * sdiff\n                    out.append(\" \" * sdiff)\n                if di < len(cols) - 1:\n                    # out += \"| \"\n                    out.append(\"| \")\n                di += 1\n                i += 1\n            # out += \"\\n\"\n            out.append(\"\\n\")\n\n        # print(\"time: \" + str(time.time() - ts))\n        return ''.join(out)\n\n    # Make a request to the SpiderFoot server\n    def request(self, url, post=None):\n        if not url:\n            self.edprint(\"Invalid request URL\")\n            return None\n\n        if not isinstance(url, str):\n            self.edprint(f\"Invalid request URL: {url}\")\n            return None\n\n        # logging.basicConfig()\n        # logging.getLogger().setLevel(logging.DEBUG)\n        # requests_log = logging.getLogger(\"requests.packages.urllib3\")\n        # requests_log.setLevel(logging.DEBUG)\n        # requests_log.propagate = True\n        headers = {\n            \"User-agent\": \"SpiderFoot-CLI/\" + self.version,\n            \"Accept\": \"application/json\"\n        }\n\n        try:\n            self.ddprint(f\"Fetching: {url}\")\n            if not post:\n                r = requests.get(\n                    url,\n                    headers=headers,\n                    verify=self.ownopts['cli.ssl_verify'],\n                    auth=requests.auth.HTTPDigestAuth(\n                        self.ownopts['cli.username'],\n                        self.ownopts['cli.password']\n                    )\n                )\n            else:\n                self.ddprint(f\"Posting: {post}\")\n                r = requests.post(\n                    url,\n                    headers=headers,\n                    verify=self.ownopts['cli.ssl_verify'],\n                    auth=requests.auth.HTTPDigestAuth(\n                        self.ownopts['cli.username'],\n                        self.ownopts['cli.password']\n                    ),\n                    data=post\n                )\n            self.ddprint(f\"Response: {r}\")\n            if r.status_code == requests.codes.ok:  # pylint: disable=no-member\n                return r.text\n            r.raise_for_status()\n        except BaseException as e:\n            self.edprint(f\"Failed communicating with server: {e}\")\n            return None\n\n    def emptyline(self):\n        return\n\n    def completedefault(self, text, line, begidx, endidx):\n        return []\n\n    # Parse the command line, returns a list of lists:\n    # sf> scans \"blahblah test\" | top 10 | grep foo ->\n    # [[ 'blahblah test' ], [[ 'top', '10' ], [ 'grep', 'foo']]]\n    def myparseline(self, cmdline, replace=True):\n        ret = [list(), list()]\n\n        if not cmdline:\n            return ret\n\n        try:\n            s = shlex.split(cmdline)\n        except Exception as e:\n            self.edprint(f\"Error parsing command: {e}\")\n            return ret\n\n        for c in s:\n            if c == '|':\n                break\n            if replace and c.startswith(\"$\") and c in self.ownopts:\n                ret[0].append(self.ownopts[c])\n            else:\n                ret[0].append(c)\n\n        if s.count('|') == 0:\n            return ret\n\n        # Handle any pipe commands at the end\n        ret[1] = list()\n        i = 0\n        ret[1].append(list())\n        for t in s[(s.index('|') + 1):]:\n            if t == '|':\n                i += 1\n                ret[1].append(list())\n            # Replace variables\n            elif t.startswith(\"$\") and t in self.ownopts:\n                ret[1][i].append(self.ownopts[t])\n            else:\n                ret[1][i].append(t)\n\n        return ret\n\n    # Send the command output to the user, processing the pipes\n    # that may have been used.\n    def send_output(self, data, cmd, titles=None, total=True, raw=False):\n        out = None\n        try:\n            if raw:\n                j = data\n                totalrec = 0\n            else:\n                j = json.loads(data)\n                totalrec = len(j)\n        except BaseException as e:\n            self.edprint(f\"Unable to parse data from server: {e}\")\n            return\n\n        if raw:\n            out = data\n        else:\n            if self.ownopts['cli.output'] == \"json\":\n                out = json.dumps(j, indent=4, separators=(',', ': '))\n\n            if self.ownopts['cli.output'] == \"pretty\":\n                out = self.pretty(j, titlemap=titles)\n\n            if not out:\n                self.edprint(f\"Unknown output format '{self.ownopts['cli.output']}'.\")\n                return\n\n        c = self.myparseline(cmd)\n\n        # If no pipes, just disply the output\n        if len(c[1]) == 0:\n            self.dprint(out, plain=True)\n            if total:\n                self.dprint(f\"Total records: {totalrec}\")\n            return\n\n        for pc in c[1]:\n            newout = \"\"\n            if len(pc) == 0:\n                self.edprint(\"Invalid syntax.\")\n                return\n            pipecmd = pc[0]\n            pipeargs = \" \".join(pc[1:])\n            if pipecmd not in [\"str\", \"regex\", \"file\", \"grep\", \"top\", \"last\"]:\n                self.edprint(\"Unrecognised pipe command.\")\n                return\n\n            if pipecmd == \"regex\":\n                p = re.compile(pipeargs, re.IGNORECASE)\n                for r in out.split(\"\\n\"):\n                    if re.match(p, r.strip()):\n                        newout += r + \"\\n\"\n\n            if pipecmd in ['str', 'grep']:\n                for r in out.split(\"\\n\"):\n                    if pipeargs.lower() in r.strip().lower():\n                        newout += r + \"\\n\"\n\n            if pipecmd == \"top\":\n                if not pipeargs.isdigit():\n                    self.edprint(\"Invalid syntax.\")\n                    return\n                newout = \"\\n\".join(out.split(\"\\n\")[0:int(pipeargs)])\n\n            if pipecmd == \"last\":\n                if not pipeargs.isdigit():\n                    self.edprint(\"Invalid syntax.\")\n                    return\n                tot = len(out.split(\"\\n\"))\n                i = tot - int(pipeargs)\n                newout = \"\\n\".join(out.split(\"\\n\")[i:])\n\n            if pipecmd == \"file\":\n                try:\n                    f = codecs.open(pipeargs, \"w\", encoding=\"utf-8\")\n                    f.write(out)\n                    f.close()\n                except BaseException as e:\n                    self.edprint(f\"Unable to write to file: {e}\")\n                    return\n                self.dprint(f\"Successfully wrote to file '{pipeargs}'.\")\n                return\n\n            out = newout\n\n        self.dprint(newout, plain=True)\n\n    # Run SQL against the DB.\n    def do_query(self, line):\n        \"\"\"query <SQL query>\n        Run an <SQL query> against the database.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n        query = ' '.join(c[0])\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/query\",\n                         post={\"query\": query})\n        if not d:\n            return\n        j = json.loads(d)\n        if j[0] == \"ERROR\":\n            self.edprint(f\"Error running your query: {j[1]}\")\n            return\n        self.send_output(d, line)\n\n    # Ping the server.\n    def do_ping(self, line):\n        \"\"\"ping\n        Ping the SpiderFoot server to ensure it's responding.\"\"\"\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/ping\")\n        if not d:\n            return\n\n        s = json.loads(d)\n        if s[0] == \"SUCCESS\":\n            self.dprint(f\"Server {self.ownopts['cli.server_baseurl']} responding.\")\n            self.do_modules(\"\", cacheonly=True)\n            self.do_types(\"\", cacheonly=True)\n        else:\n            self.dprint(f\"Something odd happened: {d}\")\n\n        if s[1] != self.version:\n            self.edprint(f\"Server and CLI version are not the same ({s[1]} / {self.version}). This could lead to unpredictable results!\")\n\n    # List all SpiderFoot modules.\n    def do_modules(self, line, cacheonly=False):\n        \"\"\"modules\n        List all available modules and their descriptions.\"\"\"\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/modules\")\n        if not d:\n            return\n\n        if cacheonly:\n            j = json.loads(d)\n            for m in j:\n                self.modules.append(m['name'])\n            return\n\n        self.send_output(d, line, titles={\"name\": \"Module name\",\n                                          \"descr\": \"Description\"})\n\n    # List all SpiderFoot correlation rules\n    def do_correlationrules(self, line, cacheonly=False):\n        \"\"\"correlations\n        List all available correlation rules and their descriptions.\"\"\"\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/correlationrules\")\n        if not d:\n            return\n\n        if cacheonly:\n            j = json.loads(d)\n            for m in j:\n                self.correlationrules.append(m['name'])\n            return\n\n        self.send_output(d, line, titles={\"id\": \"Correlation rule ID\",\n                                          \"name\": \"Name\",\n                                          \"risk\": \"Risk\"})\n\n    # List all SpiderFoot data element types.\n    def do_types(self, line, cacheonly=False):\n        \"\"\"types\n        List all available element types and their descriptions.\"\"\"\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/eventtypes\")\n\n        if not d:\n            return\n\n        if cacheonly:\n            j = json.loads(d)\n            for t in j:\n                self.types.append(t[0])\n            return\n\n        self.send_output(\n            d,\n            line,\n            titles={\n                \"1\": \"Element description\",\n                \"0\": \"Element name\"\n            }\n        )\n\n    # Load commands from a file.\n    def do_load(self, line):\n        \"\"\"load <file>\n        Execute SpiderFoot CLI commands found in <file>.\"\"\"\n        pass\n\n    # Get scan info and config.\n    def do_scaninfo(self, line):\n        \"\"\"scaninfo <sid> [-c]\n        Get status information for scan ID <sid>, optionally also its\n        configuration if -c is supplied.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        sid = c[0][0]\n        d = self.request(self.ownopts['cli.server_baseurl'] + f\"/scanopts?id={sid}\")\n        if not d:\n            return\n        j = json.loads(d)\n        if len(j) == 0:\n            self.dprint(\"No such scan exists.\")\n            return\n\n        out = list()\n        out.append(f\"Name: {j['meta'][0]}\")\n        out.append(f\"ID: {sid}\")\n        out.append(f\"Target: {j['meta'][1]}\")\n        out.append(f\"Started: {j['meta'][3]}\")\n        out.append(f\"Completed: {j['meta'][4]}\")\n        out.append(f\"Status: {j['meta'][5]}\")\n\n        if \"-c\" in c[0]:\n            out.append(\"Configuration:\")\n            for k in sorted(j['config']):\n                out.append(f\"  {k} = {j['config'][k]}\")\n\n        self.send_output(\"\\n\".join(out), line, total=False, raw=True)\n\n    # List scans.\n    def do_scans(self, line):\n        \"\"\"scans [-x]\n        List all scans, past and present. -x for extended view.\"\"\"\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/scanlist\")\n        if not d:\n            return\n        j = json.loads(d)\n        if len(j) == 0:\n            self.dprint(\"No scans exist.\")\n            return\n\n        c = self.myparseline(line)\n        titles = dict()\n        if \"-x\" in c[0]:\n            titles = {\n                \"0\": \"ID\",\n                \"1\": \"Name\",\n                \"2\": \"Target\",\n                \"4\": \"Started\",\n                \"5\": \"Finished\",\n                \"6\": \"Status\",\n                \"7\": \"Total Elements\"\n            }\n        else:\n            titles = {\n                \"0\": \"ID\",\n                \"2\": \"Target\",\n                \"6\": \"Status\",\n                \"7\": \"Total Elements\"\n            }\n\n        self.send_output(d, line, titles=titles)\n\n    # Show the correlation results from a scan.\n    def do_correlations(self, line):\n        \"\"\"correlations <sid> [-c correlation_id]\n        Get the correlation results for scan ID <sid> and optionally the\n        events associated with a correlation result [correlation_id] to\n        get the results for a particular correlation.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        post = {\"id\": c[0][0]}\n\n        if \"-c\" in c[0]:\n            post['correlationId'] = c[0][c[0].index(\"-c\") + 1]\n            url = self.ownopts['cli.server_baseurl'] + \"/scaneventresults\"\n            titles = {\n                \"10\": \"Type\",\n                \"1\": \"Data\"\n            }\n        else:\n            url = self.ownopts['cli.server_baseurl'] + \"/scancorrelations\"\n            titles = {\n                \"0\": \"ID\",\n                \"1\": \"Title\",\n                \"3\": \"Risk\",\n                \"7\": \"Data Elements\"\n            }\n\n        d = self.request(url, post=post)\n        if not d:\n            return\n        j = json.loads(d)\n        if len(j) < 1:\n            self.dprint(\"No results.\")\n            return\n\n        self.send_output(d, line, titles=titles)\n\n    # Show the data from a scan.\n    def do_data(self, line):\n        \"\"\"data <sid> [-t type] [-x] [-u]\n        Get the scan data for scan ID <sid> and optionally the element\n        type [type] (e.g. EMAILADDR), [type]. Use -x for extended format.\n        Use -u for a unique set of results.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        post = {\"id\": c[0][0]}\n\n        if \"-t\" in c[0]:\n            post[\"eventType\"] = c[0][c[0].index(\"-t\") + 1]\n        else:\n            post[\"eventType\"] = \"ALL\"\n\n        if \"-u\" in c[0]:\n            url = self.ownopts['cli.server_baseurl'] + \"/scaneventresultsunique\"\n            titles = {\n                \"0\": \"Data\"\n            }\n        else:\n            url = self.ownopts['cli.server_baseurl'] + \"/scaneventresults\"\n            titles = {\n                \"10\": \"Type\",\n                \"1\": \"Data\"\n            }\n\n        d = self.request(url, post=post)\n        if not d:\n            return\n        j = json.loads(d)\n        if len(j) < 1:\n            self.dprint(\"No results.\")\n            return\n\n        if \"-x\" in c[0]:\n            titles[\"0\"] = \"Last Seen\"\n            titles[\"3\"] = \"Module\"\n            titles[\"2\"] = \"Source Data\"\n\n        d = d.replace(\"&lt;/SFURL&gt;\", \"\").replace(\"&lt;SFURL&gt;\", \"\")\n        self.send_output(d, line, titles=titles)\n\n    # Export data from a scan.\n    def do_export(self, line):\n        \"\"\"export <sid> [-t type] [-f file]\n        Export the scan data for scan ID <sid> as type [type] to file [file].\n        Valid types: csv, json, gexf (default: json).\"\"\"\n        c = self.myparseline(line)\n\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        export_format = 'json'\n        if '-t' in c[0]:\n            export_format = c[0][c[0].index(\"-t\") + 1]\n\n        file = None\n        if '-f' in c[0]:\n            file = c[0][c[0].index(\"-f\") + 1]\n\n        base_url = self.ownopts['cli.server_baseurl']\n        post = {\"ids\": c[0][0]}\n\n        if export_format not in ['json', 'csv', 'gexf']:\n            self.edprint(f\"Invalid export format: {export_format}\")\n            return\n\n        data = None\n        if export_format == 'json':\n            res = self.request(base_url + '/scanexportjsonmulti', post=post)\n\n            if not res:\n                self.dprint(\"No results.\")\n                return\n\n            j = json.loads(res)\n\n            if len(j) < 1:\n                self.dprint(\"No results.\")\n                return\n\n            data = json.dumps(j)\n\n        elif export_format == 'csv':\n            data = self.request(base_url + '/scaneventresultexportmulti', post=post)\n\n        elif export_format == 'gexf':\n            data = self.request(base_url + '/scanvizmulti', post=post)\n\n        if not data:\n            self.dprint(\"No results.\")\n            return\n\n        self.send_output(data, line, titles=None, total=False, raw=True)\n\n        if file:\n            try:\n                with io.open(file, \"w\", encoding=\"utf-8\", errors=\"ignore\") as fp:\n                    fp.write(data)\n                self.dprint(f\"Wrote scan {c[0][0]} data to {file}\")\n            except Exception as e:\n                self.edprint(f\"Could not write scan {c[0][0]} data to file '{file}': {e}\")\n\n    # Show logs.\n    def do_logs(self, line):\n        \"\"\"logs <sid> [-l count] [-w]\n        Show the most recent [count] logs for a given scan ID, <sid>.\n        If no count is supplied, all logs are given.\n        If -w is supplied, logs will be streamed to the console until\n        Ctrl-C is entered.\"\"\"\n        c = self.myparseline(line)\n\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        sid = c[0][0]\n        limit = None\n        if \"-l\" in c[0]:\n            limit = c[0][c[0].index(\"-l\") + 1]\n\n            if not limit.isdigit():\n                self.edprint(f\"Invalid result count: {limit}\")\n                return\n\n            limit = int(limit)\n\n        if \"-w\" not in c[0]:\n            d = self.request(\n                self.ownopts['cli.server_baseurl'] + \"/scanlog\",\n                post={'id': sid, 'limit': limit}\n            )\n            if not d:\n                return\n            j = json.loads(d)\n            if len(j) < 1:\n                self.dprint(\"No results.\")\n                return\n\n            self.send_output(\n                d,\n                line,\n                titles={\n                    \"0\": \"Generated\",\n                    \"1\": \"Type\",\n                    \"2\": \"Source\",\n                    \"3\": \"Message\"\n                }\n            )\n            return\n\n        # Get the rowid of the latest log message\n        d = self.request(\n            self.ownopts['cli.server_baseurl'] + \"/scanlog\",\n            post={'id': sid, 'limit': '1'}\n        )\n        if not d:\n            return\n\n        j = json.loads(d)\n        if len(j) < 1:\n            self.dprint(\"No logs (yet?).\")\n            return\n\n        rowid = j[0][4]\n\n        if not limit:\n            limit = 10\n\n        d = self.request(\n            self.ownopts['cli.server_baseurl'] + \"/scanlog\",\n            post={'id': sid, 'reverse': '1', 'rowId': rowid - limit}\n        )\n        if not d:\n            return\n\n        j = json.loads(d)\n        for r in j:\n            # self.send_output(str(r), line, total=False, raw=True)\n            if r[2] == \"ERROR\":\n                self.edprint(f\"{r[1]}: {r[3]}\")\n            else:\n                self.dprint(f\"{r[1]}: {r[3]}\")\n\n        try:\n            while True:\n                d = self.request(\n                    self.ownopts['cli.server_baseurl'] + \"/scanlog\",\n                    post={'id': sid, 'reverse': '1', 'rowId': rowid}\n                )\n                if not d:\n                    return\n                j = json.loads(d)\n                for r in j:\n                    if r[2] == \"ERROR\":\n                        self.edprint(f\"{r[1]}: {r[3]}\")\n                    else:\n                        self.dprint(f\"{r[1]}: {r[3]}\")\n                    rowid = str(r[4])\n                time.sleep(0.5)\n        except KeyboardInterrupt:\n            return\n\n    # Start a new scan.\n    def do_start(self, line):\n        \"\"\"start <target> (-m m1,... | -t t1,... | -u case) [-n name] [-w]\n        Start a scan against <target> using modules m1,... OR looking\n        for types t1,...\n        OR by use case (\"all\", \"investigate\", \"passive\" and \"footprint\").\n\n        Scan be be optionally named [name], without a name the target\n        will be used.\n        Use -w to watch the logs from the scan. Ctrl-C to abort the\n        logging (but will not abort the scan).\n        \"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 3:\n            self.edprint(\"Invalid syntax.\")\n            return None\n\n        mods = \"\"\n        types = \"\"\n        usecase = \"\"\n\n        if \"-m\" in c[0]:\n            mods = c[0][c[0].index(\"-m\") + 1]\n\n        if \"-t\" in c[0]:\n            # Scan by type\n            types = c[0][c[0].index(\"-t\") + 1]\n\n        if \"-u\" in c[0]:\n            # Scan by use case\n            usecase = c[0][c[0].index(\"-u\") + 1]\n\n        if not mods and not types and not usecase:\n            self.edprint(\"Invalid syntax.\")\n            return None\n\n        target = c[0][0]\n        if \"-n\" in c[0]:\n            title = c[0][c[0].index(\"-n\") + 1]\n        else:\n            title = target\n\n        post = {\n            \"scanname\": title,\n            \"scantarget\": target,\n            \"modulelist\": mods,\n            \"typelist\": types,\n            \"usecase\": usecase\n        }\n        d = self.request(\n            self.ownopts['cli.server_baseurl'] + \"/startscan\",\n            post=post\n        )\n        if not d:\n            return None\n\n        s = json.loads(d)\n        if s[0] == \"SUCCESS\":\n            self.dprint(\"Successfully initiated scan.\")\n            self.dprint(f\"Scan ID: {s[1]}\")\n        else:\n            self.dprint(f\"Unable to start scan: {s[1]}\")\n\n        if \"-w\" in c[0]:\n            return self.do_logs(f\"{s[1]} -w\")\n\n        return None\n\n    # Stop a running scan.\n    def do_stop(self, line):\n        \"\"\"stop <sid>\n        Abort the running scan with scan ID, <sid>.\"\"\"\n        c = self.myparseline(line)\n        try:\n            scan_id = c[0][0]\n        except BaseException:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        self.request(self.ownopts['cli.server_baseurl'] + f\"/stopscan?id={scan_id}\")\n        self.dprint(f\"Successfully requested scan {id} to stop. This could take some minutes to complete.\")\n\n    # Search for data, alias to find\n    def do_search(self, line):\n        \"\"\"search (look up 'find')\n        \"\"\"\n        return self.do_find(line)\n\n    # Search for data\n    def do_find(self, line):\n        \"\"\"find \"<string|/regex/>\" <[-s sid]|[-t type]> [-x]\n        Search for string/regex, limited to the scope of either a scan ID or\n        event type. -x for extended format.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        val = c[0][0]\n        sid = None\n        etype = None\n\n        if \"-t\" in c[0]:\n            etype = c[0][c[0].index(\"-t\") + 1]\n        if \"-s\" in c[0]:\n            sid = c[0][c[0].index(\"-s\") + 1]\n\n        titles = {\n            \"0\": \"Last Seen\",\n            \"1\": \"Data\",\n            \"3\": \"Module\"\n        }\n        if \"-x\" in c[0]:\n            titles[\"2\"] = \"Source Data\"\n\n        d = self.request(\n            self.ownopts['cli.server_baseurl'] + \"/search\",\n            post={'value': val, 'id': sid, 'eventType': etype}\n        )\n        if not d:\n            return\n        j = json.loads(d)\n\n        if not j:\n            self.dprint(\"No results found.\")\n            return\n        if len(j) < 1:\n            self.dprint(\"No results found.\")\n            return\n\n        self.send_output(d, line, titles)\n\n    # Summary of a scan\n    def do_summary(self, line):\n        \"\"\"summary <sid> [-t]\n        Summarise the results for a scan ID, <sid>. -t to only show\n        the element types.\"\"\"\n        c = self.myparseline(line)\n        if len(c[0]) < 1:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        sid = c[0][0]\n\n        if \"-t\" in c[0]:\n            titles = {\"0\": \"Element Type\"}\n        else:\n            titles = {\n                \"0\": \"Element Type\",\n                \"1\": \"Element Description\",\n                \"3\": \"Total\",\n                \"4\": \"Unique\"\n            }\n\n        d = self.request(self.ownopts['cli.server_baseurl'] + f\"/scansummary?id={sid}&by=type\")\n        if not d:\n            return\n\n        j = json.loads(d)\n\n        if not j:\n            self.dprint(\"No results found.\")\n            return\n        if len(j) < 1:\n            self.dprint(\"No results found.\")\n            return\n\n        self.send_output(d, line, titles, total=False)\n\n    # Delete a scan\n    def do_delete(self, line):\n        \"\"\"delete <sid>\n        Delete a scan with scan ID, <sid>.\"\"\"\n        c = self.myparseline(line)\n        try:\n            scan_id = c[0][0]\n        except BaseException:\n            self.edprint(\"Invalid syntax.\")\n            return\n\n        self.request(self.ownopts['cli.server_baseurl'] + f\"/scandelete?id={scan_id}\")\n        self.dprint(f\"Successfully deleted scan {scan_id}.\")\n\n    # Override the default help\n    def print_topics(self, header, cmds, cmdlen, maxcol):\n        if not cmds:\n            return\n\n        helpmap = [\n            [\"help [command]\", \"This help output.\"],\n            [\"debug\", \"Enable/Disable debug output.\"],\n            [\"clear\", \"Clear the screen.\"],\n            [\"history\", \"Enable/Disable/List command history.\"],\n            [\"spool\", \"Enable/Disable spooling output.\"],\n            [\"shell\", \"Execute a shell command.\"],\n            [\"exit\", \"Exit the SpiderFoot CLI (won't impact running scans).\"],\n            [\"ping\", \"Test connectivity to the SpiderFoot server.\"],\n            [\"modules\", \"List available modules.\"],\n            [\"types\", \"List available data types.\"],\n            [\"correlationrules\", \"List available correlation rules.\"],\n            [\"set\", \"Set variables and configuration settings.\"],\n            [\"scans\", \"List all scans that have been run or are running.\"],\n            [\"start\", \"Start a new scan.\"],\n            [\"stop\", \"Stop a scan.\"],\n            [\"delete\", \"Delete a scan.\"],\n            [\"scaninfo\", \"Scan information.\"],\n            [\"data\", \"Show data from a scan's results.\"],\n            [\"export\", \"Export scan results to file.\"],\n            [\"correlations\", \"Show correlation results from a scan.\"],\n            [\"summary\", \"Scan result summary.\"],\n            [\"find\", \"Search for data within scan results.\"],\n            [\"query\", \"Run SQL against the SpiderFoot SQLite database.\"],\n            [\"logs\", \"View/watch logs from a scan.\"]\n        ]\n\n        self.send_output(\n            json.dumps(helpmap),\n            \"\",\n            titles={\"0\": \"Command\", \"1\": \"Description\"},\n            total=False\n        )\n\n    # Get/Set configuration\n    def do_set(self, line):\n        \"\"\"set [opt [= <val>]]\n        Set a configuration variable in SpiderFoot.\"\"\"\n\n        c = self.myparseline(line, replace=False)\n        cfg = None\n        val = None\n\n        if len(c[0]) > 0:\n            cfg = c[0][0]\n\n        if len(c[0]) > 2:\n            try:\n                val = c[0][2]\n            except BaseException:\n                self.edprint(\"Invalid syntax.\")\n                return\n\n        # Local CLI config\n        if cfg and val:\n            if cfg.startswith('$'):\n                self.ownopts[cfg] = val\n                self.dprint(f\"{cfg} set to {val}\")\n                return\n\n            if cfg in self.ownopts:\n                if isinstance(self.ownopts[cfg], bool):\n                    if val.lower() == \"false\" or val == \"0\":\n                        val = False\n                    else:\n                        val = True\n\n                self.ownopts[cfg] = val\n                self.dprint(f\"{cfg} set to {val}\")\n                return\n\n        # Get the server-side config\n        d = self.request(self.ownopts['cli.server_baseurl'] + \"/optsraw\")\n        if not d:\n            self.edprint(\"Unable to obtain SpiderFoot server-side config.\")\n            return\n\n        j = list()\n        serverconfig = dict()\n        token = \"\"  # nosec\n        j = json.loads(d)\n        if j[0] == \"ERROR\":\n            self.edprint(\"Error fetching SpiderFoot server-side config.\")\n            return\n\n        serverconfig = j[1]['data']\n        token = j[1]['token']\n\n        self.ddprint(str(serverconfig))\n\n        # Printing current config, not setting a value\n        if not cfg or not val:\n            ks = list(self.ownopts.keys())\n            ks.sort()\n            output = list()\n            for k in ks:\n                c = self.ownopts[k]\n                if isinstance(c, bool):\n                    c = str(c)\n\n                if not cfg:\n                    output.append({'opt': k, 'val': c})\n                    continue\n\n                if cfg == k:\n                    self.dprint(f\"{k} = {c}\", plain=True)\n\n            for k in sorted(serverconfig.keys()):\n                if type(serverconfig[k]) == list:\n                    serverconfig[k] = ','.join(serverconfig[k])\n                if not cfg:\n                    output.append({'opt': k, 'val': str(serverconfig[k])})\n                    continue\n                if cfg == k:\n                    self.dprint(f\"{k} = {serverconfig[k]}\", plain=True)\n\n            if len(output) > 0:\n                self.send_output(\n                    json.dumps(output),\n                    line,\n                    {'opt': \"Option\", 'val': \"Value\"},\n                    total=False\n                )\n            return\n\n        if val:\n            # submit all non-CLI vars to the SF server\n            confdata = dict()\n            found = False\n            for k in serverconfig:\n                if k == cfg:\n                    serverconfig[k] = val\n                    if type(val) == str:\n                        if val.lower() == \"true\":\n                            serverconfig[k] = \"1\"\n                        if val.lower() == \"false\":\n                            serverconfig[k] = \"0\"\n                    found = True\n\n            if not found:\n                self.edprint(\"Variable not found, so not set.\")\n                return\n\n            # Sanitize the data before sending it to the server\n            for k in serverconfig:\n                optstr = \":\".join(k.split(\".\")[1:])\n                if type(serverconfig[k]) == bool:\n                    if serverconfig[k]:\n                        confdata[optstr] = \"1\"\n                    else:\n                        confdata[optstr] = \"0\"\n                if type(serverconfig[k]) == list:\n                    # If set by the user, it must already be a\n                    # string, not a list\n                    confdata[optstr] = ','.join(serverconfig[k])\n                if type(serverconfig[k]) == int:\n                    confdata[optstr] = str(serverconfig[k])\n                if type(serverconfig[k]) == str:\n                    confdata[optstr] = serverconfig[k]\n\n            self.ddprint(str(confdata))\n            d = self.request(\n                self.ownopts['cli.server_baseurl'] + \"/savesettingsraw\",\n                post={'token': token, 'allopts': json.dumps(confdata)}\n            )\n            j = list()\n\n            if not d:\n                self.edprint(\"Unable to set SpiderFoot server-side config.\")\n                return\n\n            j = json.loads(d)\n            if j[0] == \"ERROR\":\n                self.edprint(f\"Error setting SpiderFoot server-side config: {j[1]}\")\n                return\n\n            self.dprint(f\"{cfg} set to {val}\")\n            return\n\n        if cfg not in self.ownopts:\n            self.edprint(\"Variable not found, so not set. Did you mean to use a $ variable?\")\n            return\n\n    # Execute a shell command locally and return the output\n    def do_shell(self, line):\n        \"\"\"shell\n        Run a shell command locally.\"\"\"\n        self.dprint(\"Running shell command:\" + str(line))\n        self.dprint(os.popen(line).read(), plain=True)  # noqa: DUO106\n\n    def do_clear(self, line):\n        \"\"\"clear\n        Clear the screen.\"\"\"\n        sys.stderr.write(\"\\x1b[2J\\x1b[H\")\n\n    # Exit the CLI\n    def do_exit(self, line):\n        \"\"\"exit\n        Exit the SpiderFoot CLI.\"\"\"\n        return True\n\n    # Ctrl-D\n    def do_EOF(self, line):\n        \"\"\"EOF (Ctrl-D)\n        Exit the SpiderFoot CLI.\"\"\"\n        print(\"\\n\")\n        return True\n\n\nif __name__ == \"__main__\":\n    p = argparse.ArgumentParser(description='SpiderFoot: Open Source Intelligence Automation.')\n    p.add_argument(\"-d\", \"--debug\", help=\"Enable debug output.\", action='store_true')\n    p.add_argument(\"-s\", metavar=\"URL\", type=str, help=\"Connect to SpiderFoot server on URL. By default, a connection to http://127.0.0.1:5001 will be attempted.\")\n    p.add_argument(\"-u\", metavar=\"USER\", type=str, help=\"Username to authenticate to SpiderFoot server.\")\n    p.add_argument(\"-p\", metavar=\"PASS\", type=str, help=\"Password to authenticate to SpiderFoot server. Consider using -P PASSFILE instead so that your password isn't visible in your shell history or in process lists!\")\n    p.add_argument(\"-P\", metavar=\"PASSFILE\", type=str, help=\"File containing password to authenticate to SpiderFoot server. Ensure permissions on the file are set appropriately!\")\n    p.add_argument(\"-e\", metavar=\"FILE\", type=str, help=\"Execute commands from FILE.\")\n    p.add_argument(\"-l\", metavar=\"FILE\", type=str, help=\"Log command history to FILE. By default, history is stored to ~/.spiderfoot_history unless disabled with -n.\")\n    p.add_argument(\"-n\", action='store_true', help=\"Disable history logging.\")\n    p.add_argument(\"-o\", metavar=\"FILE\", type=str, help=\"Spool commands and output to FILE.\")\n    p.add_argument(\"-i\", help=\"Allow insecure server connections when using SSL\", action='store_true')\n    p.add_argument(\"-q\", help=\"Silent output, only errors reported.\", action='store_true')\n    p.add_argument(\"-k\", help=\"Turn off color-coded output.\", action='store_true')\n    p.add_argument(\"-b\", \"-v\", help=\"Print the banner w/ version and exit.\", action='store_true')\n\n    args = p.parse_args()\n\n    # Load commands from a file\n    if args.e:\n        try:\n            with open(args.e, 'r') as f:\n                cin = f.read()\n        except BaseException as e:\n            print(f\"Unable to open {args.e}: ({e})\")\n            sys.exit(-1)\n    else:\n        cin = sys.stdin\n    s = SpiderFootCli(stdin=cin)\n    s.identchars += \"$\"\n\n    # Map command-line to config\n    if args.u:\n        s.ownopts['cli.username'] = args.u\n    if args.p:\n        s.ownopts['cli.password'] = args.p\n    if args.P:\n        try:\n            with open(args.P, 'r') as f:\n                s.ownopts['cli.password'] = f.readlines()[0].strip('\\n')\n        except BaseException as e:\n            print(f\"Unable to open {args.P}: ({e})\")\n            sys.exit(-1)\n    if args.i:\n        s.ownopts['cli.ssl_verify'] = False\n    if args.k:\n        s.ownopts['cli.color'] = False\n    if args.s:\n        s.ownopts['cli.server_baseurl'] = args.s\n    if args.debug:\n        s.ownopts['cli.debug'] = True\n    if args.q:\n        s.ownopts['cli.silent'] = True\n    if args.n:\n        s.ownopts['cli.history'] = False\n    if args.l:\n        s.ownopts['cli.history_file'] = args.l\n    else:\n        try:\n            s.ownopts['cli.history_file'] = expanduser(\"~\") + \"/.spiderfoot_history\"\n        except BaseException as e:\n            s.dprint(f\"Failed to set 'cli.history_file': {e}\")\n            s.dprint(\"Using '.spiderfoot_history' in working directory\")\n            s.ownopts['cli.history_file'] = \".spiderfoot_history\"\n    if args.o:\n        s.ownopts['cli.spool'] = True\n        s.ownopts['cli.spool_file'] = args.o\n\n    if args.e or not os.isatty(0):\n        try:\n            s.use_rawinput = False\n            s.prompt = \"\"\n            s.cmdloop()\n        finally:\n            cin.close()\n        sys.exit(0)\n\n    if not args.q:\n        s = SpiderFootCli()\n        s.dprint(ASCII_LOGO, plain=True, color=bcolors.GREYBLUE)\n        s.dprint(COPYRIGHT_INFO, plain=True,\n                 color=bcolors.GREYBLUE_DARK)\n        s.dprint(f\"Version {s.version}.\")\n        if args.b:\n            sys.exit(0)\n\n    # Test connectivity to the server\n    s.do_ping(\"\")\n\n    if not args.n:\n        try:\n            f = codecs.open(s.ownopts['cli.history_file'], \"r\", encoding=\"utf-8\")\n            for line in f.readlines():\n                readline.add_history(line.strip())\n            s.dprint(\"Loaded previous command history.\")\n        except BaseException:\n            pass\n\n    try:\n        s.dprint(\"Type 'help' or '?'.\")\n        s.cmdloop()\n    except KeyboardInterrupt:\n        print(\"\\n\")\n        sys.exit(0)\n"
        },
        {
          "name": "sflib.py",
          "type": "blob",
          "size": 51.9345703125,
          "content": "#  -*- coding: utf-8 -*-\n# -------------------------------------------------------------------------------\n# Name:         sflib\n# Purpose:      Common functions used by SpiderFoot modules.\n#\n# Author:      Steve Micallef <steve@binarypool.com>\n#\n# Created:     26/03/2012\n# Copyright:   (c) Steve Micallef 2012\n# Licence:     MIT\n# -------------------------------------------------------------------------------\n\nimport hashlib\nimport inspect\nimport io\nimport json\nimport logging\nimport os\nimport random\nimport re\nimport socket\nimport ssl\nimport sys\nimport time\nimport urllib.error\nimport urllib.parse\nimport urllib.request\nfrom copy import deepcopy\nfrom datetime import datetime\n\nimport cryptography\nimport dns.resolver\nimport netaddr\nimport OpenSSL\nimport requests\nimport urllib3\nfrom publicsuffixlist import PublicSuffixList\nfrom spiderfoot import SpiderFootHelpers\n\n# For hiding the SSL warnings coming from the requests lib\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)  # noqa: DUO131\n\n\nclass SpiderFoot:\n    \"\"\"SpiderFoot\n\n    Attributes:\n        dbh (SpiderFootDb): database handle\n        scanId (str): scan ID this instance of SpiderFoot is being used in\n        socksProxy (str): SOCKS proxy\n        opts (dict): configuration options\n    \"\"\"\n    _dbh = None\n    _scanId = None\n    _socksProxy = None\n    opts = dict()\n\n    def __init__(self, options: dict) -> None:\n        \"\"\"Initialize SpiderFoot object.\n\n        Args:\n            options (dict): dictionary of configuration options.\n\n        Raises:\n            TypeError: options argument was invalid type\n        \"\"\"\n        if not isinstance(options, dict):\n            raise TypeError(f\"options is {type(options)}; expected dict()\")\n\n        self.opts = deepcopy(options)\n        self.log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n        # This is ugly but we don't want any fetches to fail - we expect\n        # to encounter unverified SSL certs!\n        ssl._create_default_https_context = ssl._create_unverified_context  # noqa: DUO122\n\n        if self.opts.get('_dnsserver', \"\") != \"\":\n            res = dns.resolver.Resolver()\n            res.nameservers = [self.opts['_dnsserver']]\n            dns.resolver.override_system_resolver(res)\n\n    @property\n    def dbh(self):\n        \"\"\"Database handle\n\n        Returns:\n            SpiderFootDb: database handle\n        \"\"\"\n        return self._dbh\n\n    @property\n    def scanId(self) -> str:\n        \"\"\"Scan instance ID\n\n        Returns:\n            str: scan instance ID\n        \"\"\"\n        return self._scanId\n\n    @property\n    def socksProxy(self) -> str:\n        \"\"\"SOCKS proxy\n\n        Returns:\n            str: socks proxy\n        \"\"\"\n        return self._socksProxy\n\n    @dbh.setter\n    def dbh(self, dbh):\n        \"\"\"Called usually some time after instantiation\n        to set up a database handle and scan ID, used\n        for logging events to the database about a scan.\n\n        Args:\n            dbh (SpiderFootDb): database handle\n        \"\"\"\n        self._dbh = dbh\n\n    @scanId.setter\n    def scanId(self, scanId: str) -> str:\n        \"\"\"Set the scan ID this instance of SpiderFoot is being used in.\n\n        Args:\n            scanId (str): scan instance ID\n        \"\"\"\n        self._scanId = scanId\n\n    @socksProxy.setter\n    def socksProxy(self, socksProxy: str) -> str:\n        \"\"\"SOCKS proxy\n\n        Bit of a hack to support SOCKS because of the loading order of\n        modules. sfscan will call this to update the socket reference\n        to the SOCKS one.\n\n        Args:\n            socksProxy (str): SOCKS proxy\n        \"\"\"\n        self._socksProxy = socksProxy\n\n    def optValueToData(self, val: str) -> str:\n        \"\"\"Supplied an option value, return the data based on what the\n        value is. If val is a URL, you'll get back the fetched content,\n        if val is a file path it will be loaded and get back the contents,\n        and if a string it will simply be returned back.\n\n        Args:\n            val (str): option name\n\n        Returns:\n            str: option data\n        \"\"\"\n        if not isinstance(val, str):\n            self.error(f\"Invalid option value {val}\")\n            return None\n\n        if val.startswith('@'):\n            fname = val.split('@')[1]\n            self.info(f\"Loading configuration data from: {fname}\")\n\n            try:\n                with open(fname, \"r\") as f:\n                    return f.read()\n            except Exception as e:\n                self.error(f\"Unable to open option file, {fname}: {e}\")\n                return None\n\n        if val.lower().startswith('http://') or val.lower().startswith('https://'):\n            try:\n                self.info(f\"Downloading configuration data from: {val}\")\n                session = self.getSession()\n                res = session.get(val)\n\n                return res.content.decode('utf-8')\n            except BaseException as e:\n                self.error(f\"Unable to open option URL, {val}: {e}\")\n                return None\n\n        return val\n\n    def error(self, message: str) -> None:\n        \"\"\"Print and log an error message\n\n        Args:\n            message (str): error message\n        \"\"\"\n        if not self.opts['__logging']:\n            return\n\n        self.log.error(message, extra={'scanId': self._scanId})\n\n    def fatal(self, error: str) -> None:\n        \"\"\"Print an error message and stacktrace then exit.\n\n        Args:\n            error (str): error message\n        \"\"\"\n        self.log.critical(error, extra={'scanId': self._scanId})\n\n        print(str(inspect.stack()))\n\n        sys.exit(-1)\n\n    def status(self, message: str) -> None:\n        \"\"\"Log and print a status message.\n\n        Args:\n            message (str): status message\n        \"\"\"\n        if not self.opts['__logging']:\n            return\n\n        self.log.info(message, extra={'scanId': self._scanId})\n\n    def info(self, message: str) -> None:\n        \"\"\"Log and print an info message.\n\n        Args:\n            message (str): info message\n        \"\"\"\n        if not self.opts['__logging']:\n            return\n\n        self.log.info(f\"{message}\", extra={'scanId': self._scanId})\n\n    def debug(self, message: str) -> None:\n        \"\"\"Log and print a debug message.\n\n        Args:\n            message (str): debug message\n        \"\"\"\n        if not self.opts['_debug']:\n            return\n        if not self.opts['__logging']:\n            return\n\n        self.log.debug(f\"{message}\", extra={'scanId': self._scanId})\n\n    def hashstring(self, string: str) -> str:\n        \"\"\"Returns a SHA256 hash of the specified input.\n\n        Args:\n            string (str): data to be hashed\n\n        Returns:\n            str: SHA256 hash\n        \"\"\"\n        s = string\n        if type(string) in [list, dict]:\n            s = str(string)\n        return hashlib.sha256(s.encode('raw_unicode_escape')).hexdigest()\n\n    def cachePut(self, label: str, data: str) -> None:\n        \"\"\"Store data to the cache.\n\n        Args:\n            label (str): Name of the cached data to be used when retrieving the cached data.\n            data (str): Data to cache\n        \"\"\"\n        pathLabel = hashlib.sha224(label.encode('utf-8')).hexdigest()\n        cacheFile = SpiderFootHelpers.cachePath() + \"/\" + pathLabel\n        with io.open(cacheFile, \"w\", encoding=\"utf-8\", errors=\"ignore\") as fp:\n            if isinstance(data, list):\n                for line in data:\n                    if isinstance(line, str):\n                        fp.write(line)\n                        fp.write(\"\\n\")\n                    else:\n                        fp.write(line.decode('utf-8') + '\\n')\n            elif isinstance(data, bytes):\n                fp.write(data.decode('utf-8'))\n            else:\n                fp.write(data)\n\n    def cacheGet(self, label: str, timeoutHrs: int) -> str:\n        \"\"\"Retreive data from the cache.\n\n        Args:\n            label (str): Name of the cached data to retrieve\n            timeoutHrs (int): Age of the cached data (in hours)\n                              for which the data is considered to be too old and ignored.\n\n        Returns:\n            str: cached data\n        \"\"\"\n        if not label:\n            return None\n\n        pathLabel = hashlib.sha224(label.encode('utf-8')).hexdigest()\n        cacheFile = SpiderFootHelpers.cachePath() + \"/\" + pathLabel\n        try:\n            cache_stat = os.stat(cacheFile)\n        except OSError:\n            return None\n\n        if cache_stat.st_size == 0:\n            return None\n\n        if cache_stat.st_mtime > time.time() - timeoutHrs * 3600 or timeoutHrs == 0:\n            with open(cacheFile, \"r\", encoding='utf-8') as fp:\n                return fp.read()\n\n        return None\n\n    def configSerialize(self, opts: dict, filterSystem: bool = True):\n        \"\"\"Convert a Python dictionary to something storable in the database.\n\n        Args:\n            opts (dict): Dictionary of SpiderFoot configuration options\n            filterSystem (bool): TBD\n\n        Returns:\n            dict: config options\n\n        Raises:\n            TypeError: arg type was invalid\n        \"\"\"\n        if not isinstance(opts, dict):\n            raise TypeError(f\"opts is {type(opts)}; expected dict()\")\n\n        storeopts = dict()\n\n        if not opts:\n            return storeopts\n\n        for opt in list(opts.keys()):\n            # Filter out system temporary variables like GUID and others\n            if opt.startswith('__') and filterSystem:\n                continue\n\n            if isinstance(opts[opt], (int, str)):\n                storeopts[opt] = opts[opt]\n\n            if isinstance(opts[opt], bool):\n                if opts[opt]:\n                    storeopts[opt] = 1\n                else:\n                    storeopts[opt] = 0\n            if isinstance(opts[opt], list):\n                storeopts[opt] = ','.join(opts[opt])\n\n        if '__modules__' not in opts:\n            return storeopts\n\n        if not isinstance(opts['__modules__'], dict):\n            raise TypeError(f\"opts['__modules__'] is {type(opts['__modules__'])}; expected dict()\")\n\n        for mod in opts['__modules__']:\n            for opt in opts['__modules__'][mod]['opts']:\n                if opt.startswith('_') and filterSystem:\n                    continue\n\n                mod_opt = f\"{mod}:{opt}\"\n                mod_opt_val = opts['__modules__'][mod]['opts'][opt]\n\n                if isinstance(mod_opt_val, (int, str)):\n                    storeopts[mod_opt] = mod_opt_val\n\n                if isinstance(mod_opt_val, bool):\n                    if mod_opt_val:\n                        storeopts[mod_opt] = 1\n                    else:\n                        storeopts[mod_opt] = 0\n                if isinstance(mod_opt_val, list):\n                    storeopts[mod_opt] = ','.join(str(x) for x in mod_opt_val)\n\n        return storeopts\n\n    def configUnserialize(self, opts: dict, referencePoint: dict, filterSystem: bool = True):\n        \"\"\"Take strings, etc. from the database or UI and convert them\n        to a dictionary for Python to process.\n\n        Args:\n            opts (dict): SpiderFoot configuration options\n            referencePoint (dict): needed to know the actual types the options are supposed to be.\n            filterSystem (bool): Ignore global \"system\" configuration options\n\n        Returns:\n            dict: TBD\n\n        Raises:\n            TypeError: arg type was invalid\n        \"\"\"\n\n        if not isinstance(opts, dict):\n            raise TypeError(f\"opts is {type(opts)}; expected dict()\")\n        if not isinstance(referencePoint, dict):\n            raise TypeError(f\"referencePoint is {type(referencePoint)}; expected dict()\")\n\n        returnOpts = referencePoint\n\n        # Global options\n        for opt in list(referencePoint.keys()):\n            if opt.startswith('__') and filterSystem:\n                # Leave out system variables\n                continue\n\n            if opt not in opts:\n                continue\n\n            if isinstance(referencePoint[opt], bool):\n                if opts[opt] == \"1\":\n                    returnOpts[opt] = True\n                else:\n                    returnOpts[opt] = False\n                continue\n\n            if isinstance(referencePoint[opt], str):\n                returnOpts[opt] = str(opts[opt])\n                continue\n\n            if isinstance(referencePoint[opt], int):\n                returnOpts[opt] = int(opts[opt])\n                continue\n\n            if isinstance(referencePoint[opt], list):\n                if isinstance(referencePoint[opt][0], int):\n                    returnOpts[opt] = list()\n                    for x in str(opts[opt]).split(\",\"):\n                        returnOpts[opt].append(int(x))\n                else:\n                    returnOpts[opt] = str(opts[opt]).split(\",\")\n\n        if '__modules__' not in referencePoint:\n            return returnOpts\n\n        if not isinstance(referencePoint['__modules__'], dict):\n            raise TypeError(f\"referencePoint['__modules__'] is {type(referencePoint['__modules__'])}; expected dict()\")\n\n        # Module options\n        # A lot of mess to handle typing..\n        for modName in referencePoint['__modules__']:\n            for opt in referencePoint['__modules__'][modName]['opts']:\n                if opt.startswith('_') and filterSystem:\n                    continue\n\n                if modName + \":\" + opt in opts:\n                    ref_mod = referencePoint['__modules__'][modName]['opts'][opt]\n                    if isinstance(ref_mod, bool):\n                        if opts[modName + \":\" + opt] == \"1\":\n                            returnOpts['__modules__'][modName]['opts'][opt] = True\n                        else:\n                            returnOpts['__modules__'][modName]['opts'][opt] = False\n                        continue\n\n                    if isinstance(ref_mod, str):\n                        returnOpts['__modules__'][modName]['opts'][opt] = str(opts[modName + \":\" + opt])\n                        continue\n\n                    if isinstance(ref_mod, int):\n                        returnOpts['__modules__'][modName]['opts'][opt] = int(opts[modName + \":\" + opt])\n                        continue\n\n                    if isinstance(ref_mod, list):\n                        if isinstance(ref_mod[0], int):\n                            returnOpts['__modules__'][modName]['opts'][opt] = list()\n                            for x in str(opts[modName + \":\" + opt]).split(\",\"):\n                                returnOpts['__modules__'][modName]['opts'][opt].append(int(x))\n                        else:\n                            returnOpts['__modules__'][modName]['opts'][opt] = str(opts[modName + \":\" + opt]).split(\",\")\n\n        return returnOpts\n\n    def modulesProducing(self, events: list) -> list:\n        \"\"\"Return an array of modules that produce the list of types supplied.\n\n        Args:\n            events (list): list of event types\n\n        Returns:\n            list: list of modules\n        \"\"\"\n        modlist = list()\n\n        if not events:\n            return modlist\n\n        loaded_modules = self.opts.get('__modules__')\n\n        if not loaded_modules:\n            return modlist\n\n        for mod in list(loaded_modules.keys()):\n            provides = loaded_modules[mod].get('provides')\n\n            if not provides:\n                continue\n\n            if \"*\" in events:\n                modlist.append(mod)\n\n            for evtype in provides:\n                if evtype in events:\n                    modlist.append(mod)\n\n        return list(set(modlist))\n\n    def modulesConsuming(self, events: list) -> list:\n        \"\"\"Return an array of modules that consume the list of types supplied.\n\n        Args:\n            events (list): list of event types\n\n        Returns:\n            list: list of modules\n        \"\"\"\n        modlist = list()\n\n        if not events:\n            return modlist\n\n        loaded_modules = self.opts.get('__modules__')\n\n        if not loaded_modules:\n            return modlist\n\n        for mod in list(loaded_modules.keys()):\n            consumes = loaded_modules[mod].get('consumes')\n\n            if not consumes:\n                continue\n\n            if \"*\" in consumes:\n                modlist.append(mod)\n                continue\n\n            for evtype in consumes:\n                if evtype in events:\n                    modlist.append(mod)\n\n        return list(set(modlist))\n\n    def eventsFromModules(self, modules: list) -> list:\n        \"\"\"Return an array of types that are produced by the list of modules supplied.\n\n        Args:\n            modules (list): list of modules\n\n        Returns:\n            list: list of types\n        \"\"\"\n        evtlist = list()\n\n        if not modules:\n            return evtlist\n\n        loaded_modules = self.opts.get('__modules__')\n\n        if not loaded_modules:\n            return evtlist\n\n        for mod in modules:\n            if mod in list(loaded_modules.keys()):\n                provides = loaded_modules[mod].get('provides')\n                if provides:\n                    for evt in provides:\n                        evtlist.append(evt)\n\n        return evtlist\n\n    def eventsToModules(self, modules: list) -> list:\n        \"\"\"Return an array of types that are consumed by the list of modules supplied.\n\n        Args:\n            modules (list): list of modules\n\n        Returns:\n            list: list of types\n        \"\"\"\n        evtlist = list()\n\n        if not modules:\n            return evtlist\n\n        loaded_modules = self.opts.get('__modules__')\n\n        if not loaded_modules:\n            return evtlist\n\n        for mod in modules:\n            if mod in list(loaded_modules.keys()):\n                consumes = loaded_modules[mod].get('consumes')\n                if consumes:\n                    for evt in consumes:\n                        evtlist.append(evt)\n\n        return evtlist\n\n    def urlFQDN(self, url: str) -> str:\n        \"\"\"Extract the FQDN from a URL.\n\n        Args:\n            url (str): URL\n\n        Returns:\n            str: FQDN\n        \"\"\"\n        if not url:\n            self.error(f\"Invalid URL: {url}\")\n            return None\n\n        baseurl = SpiderFootHelpers.urlBaseUrl(url)\n        if '://' in baseurl:\n            count = 2\n        else:\n            count = 0\n\n        # http://abc.com will split to ['http:', '', 'abc.com']\n        return baseurl.split('/')[count].lower()\n\n    def domainKeyword(self, domain: str, tldList: list) -> str:\n        \"\"\"Extract the keyword (the domain without the TLD or any subdomains) from a domain.\n\n        Args:\n            domain (str): The domain to check.\n            tldList (list): The list of TLDs based on the Mozilla public list.\n\n        Returns:\n            str: The keyword\n        \"\"\"\n        if not domain:\n            self.error(f\"Invalid domain: {domain}\")\n            return None\n\n        # Strip off the TLD\n        dom = self.hostDomain(domain.lower(), tldList)\n        if not dom:\n            return None\n\n        tld = '.'.join(dom.split('.')[1:])\n        ret = domain.lower().replace('.' + tld, '')\n\n        # If the user supplied a domain with a sub-domain, return the second part\n        if '.' in ret:\n            return ret.split('.')[-1]\n\n        return ret\n\n    def domainKeywords(self, domainList: list, tldList: list) -> set:\n        \"\"\"Extract the keywords (the domains without the TLD or any subdomains) from a list of domains.\n\n        Args:\n            domainList (list): The list of domains to check.\n            tldList (list): The list of TLDs based on the Mozilla public list.\n\n        Returns:\n            set: List of keywords\n        \"\"\"\n        if not domainList:\n            self.error(f\"Invalid domain list: {domainList}\")\n            return set()\n\n        keywords = list()\n        for domain in domainList:\n            keywords.append(self.domainKeyword(domain, tldList))\n\n        self.debug(f\"Keywords: {keywords}\")\n        return set([k for k in keywords if k])\n\n    def hostDomain(self, hostname: str, tldList: list) -> str:\n        \"\"\"Obtain the domain name for a supplied hostname.\n\n        Args:\n            hostname (str): The hostname to check.\n            tldList (list): The list of TLDs based on the Mozilla public list.\n\n        Returns:\n            str: The domain name.\n        \"\"\"\n        if not tldList:\n            return None\n        if not hostname:\n            return None\n\n        ps = PublicSuffixList(tldList, only_icann=True)\n        return ps.privatesuffix(hostname)\n\n    def validHost(self, hostname: str, tldList: str) -> bool:\n        \"\"\"Check if the provided string is a valid hostname with a valid public suffix TLD.\n\n        Args:\n            hostname (str): The hostname to check.\n            tldList (str): The list of TLDs based on the Mozilla public list.\n\n        Returns:\n            bool\n        \"\"\"\n        if not tldList:\n            return False\n        if not hostname:\n            return False\n\n        if \".\" not in hostname:\n            return False\n\n        if not re.match(r\"^[a-z0-9-\\.]*$\", hostname, re.IGNORECASE):\n            return False\n\n        ps = PublicSuffixList(tldList, only_icann=True, accept_unknown=False)\n        sfx = ps.privatesuffix(hostname)\n        return sfx is not None\n\n    def isDomain(self, hostname: str, tldList: list) -> bool:\n        \"\"\"Check if the provided hostname string is a valid domain name.\n\n        Given a possible hostname, check if it's a domain name\n        By checking whether it rests atop a valid TLD.\n        e.g. www.example.com = False because tld of hostname is com,\n        and www.example has a . in it.\n\n        Args:\n            hostname (str): The hostname to check.\n            tldList (list): The list of TLDs based on the Mozilla public list.\n\n        Returns:\n            bool\n        \"\"\"\n        if not tldList:\n            return False\n        if not hostname:\n            return False\n\n        ps = PublicSuffixList(tldList, only_icann=True, accept_unknown=False)\n        sfx = ps.privatesuffix(hostname)\n        return sfx == hostname\n\n    def validIP(self, address: str) -> bool:\n        \"\"\"Check if the provided string is a valid IPv4 address.\n\n        Args:\n            address (str): The IPv4 address to check.\n\n        Returns:\n            bool\n        \"\"\"\n        if not address:\n            return False\n        return netaddr.valid_ipv4(address)\n\n    def validIP6(self, address: str) -> bool:\n        \"\"\"Check if the provided string is a valid IPv6 address.\n\n        Args:\n            address (str): The IPv6 address to check.\n\n        Returns:\n            bool: string is a valid IPv6 address\n        \"\"\"\n        if not address:\n            return False\n        return netaddr.valid_ipv6(address)\n\n    def validIpNetwork(self, cidr: str) -> bool:\n        \"\"\"Check if the provided string is a valid CIDR netblock.\n\n        Args:\n            cidr (str): The netblock to check.\n\n        Returns:\n            bool: string is a valid CIDR netblock\n        \"\"\"\n        if not isinstance(cidr, str):\n            return False\n\n        if '/' not in cidr:\n            return False\n\n        try:\n            return netaddr.IPNetwork(str(cidr)).size > 0\n        except BaseException:\n            return False\n\n    def isPublicIpAddress(self, ip: str) -> bool:\n        \"\"\"Check if an IP address is public.\n\n        Args:\n            ip (str): IP address\n\n        Returns:\n            bool: IP address is public\n        \"\"\"\n        if not isinstance(ip, (str, netaddr.IPAddress)):\n            return False\n        if not self.validIP(ip) and not self.validIP6(ip):\n            return False\n\n        if not netaddr.IPAddress(ip).is_unicast():\n            return False\n\n        if netaddr.IPAddress(ip).is_loopback():\n            return False\n        if netaddr.IPAddress(ip).is_reserved():\n            return False\n        if netaddr.IPAddress(ip).is_multicast():\n            return False\n        if netaddr.IPAddress(ip).is_private():\n            return False\n        return True\n\n    def normalizeDNS(self, res: list) -> list:\n        \"\"\"Clean DNS results to be a simple list\n\n        Args:\n            res (list): List of DNS names\n\n        Returns:\n            list: list of domains\n        \"\"\"\n        ret = list()\n\n        if not res:\n            return ret\n\n        for addr in res:\n            if isinstance(addr, list):\n                for host in addr:\n                    host = str(host).rstrip(\".\")\n                    if host:\n                        ret.append(host)\n            else:\n                host = str(addr).rstrip(\".\")\n                if host:\n                    ret.append(host)\n        return ret\n\n    def resolveHost(self, host: str) -> list:\n        \"\"\"Return a normalised IPv4 resolution of a hostname.\n\n        Args:\n            host (str): host to resolve\n\n        Returns:\n            list: IP addresses\n        \"\"\"\n        if not host:\n            self.error(f\"Unable to resolve host: {host} (Invalid host)\")\n            return list()\n\n        addrs = list()\n        try:\n            addrs = self.normalizeDNS(socket.gethostbyname_ex(host))\n        except BaseException as e:\n            self.debug(f\"Unable to resolve host: {host} ({e})\")\n            return addrs\n\n        if not addrs:\n            self.debug(f\"Unable to resolve host: {host}\")\n            return addrs\n\n        self.debug(f\"Resolved {host} to IPv4: {addrs}\")\n\n        return list(set(addrs))\n\n    def resolveIP(self, ipaddr: str) -> list:\n        \"\"\"Return a normalised resolution of an IPv4 or IPv6 address.\n\n        Args:\n            ipaddr (str): IP address to reverse resolve\n\n        Returns:\n            list: list of domain names\n        \"\"\"\n\n        if not self.validIP(ipaddr) and not self.validIP6(ipaddr):\n            self.error(f\"Unable to reverse resolve {ipaddr} (Invalid IP address)\")\n            return list()\n\n        self.debug(f\"Performing reverse resolve of {ipaddr}\")\n\n        try:\n            addrs = self.normalizeDNS(socket.gethostbyaddr(ipaddr))\n        except BaseException as e:\n            self.debug(f\"Unable to reverse resolve IP address: {ipaddr} ({e})\")\n            return list()\n\n        if not addrs:\n            self.debug(f\"Unable to reverse resolve IP address: {ipaddr}\")\n            return list()\n\n        self.debug(f\"Reverse resolved {ipaddr} to: {addrs}\")\n\n        return list(set(addrs))\n\n    def resolveHost6(self, hostname: str) -> list:\n        \"\"\"Return a normalised IPv6 resolution of a hostname.\n\n        Args:\n            hostname (str): hostname to resolve\n\n        Returns:\n            list\n        \"\"\"\n        if not hostname:\n            self.error(f\"Unable to resolve host: {hostname} (Invalid host)\")\n            return list()\n\n        addrs = list()\n        try:\n            res = socket.getaddrinfo(hostname, None, socket.AF_INET6)\n            for addr in res:\n                if addr[4][0] not in addrs:\n                    addrs.append(addr[4][0])\n        except BaseException as e:\n            self.debug(f\"Unable to resolve host: {hostname} ({e})\")\n            return addrs\n\n        if not addrs:\n            self.debug(f\"Unable to resolve host: {hostname}\")\n            return addrs\n\n        self.debug(f\"Resolved {hostname} to IPv6: {addrs}\")\n\n        return list(set(addrs))\n\n    def validateIP(self, host: str, ip: str) -> bool:\n        \"\"\"Verify a host resolves to a given IP.\n\n        Args:\n            host (str): host\n            ip (str): IP address\n\n        Returns:\n            bool: host resolves to the given IP address\n        \"\"\"\n        if not host:\n            self.error(f\"Unable to resolve host: {host} (Invalid host)\")\n            return False\n\n        if self.validIP(ip):\n            addrs = self.resolveHost(host)\n        elif self.validIP6(ip):\n            addrs = self.resolveHost6(host)\n        else:\n            self.error(f\"Unable to verify hostname {host} resolves to {ip} (Invalid IP address)\")\n            return False\n\n        if not addrs:\n            return False\n\n        return any(str(addr) == ip for addr in addrs)\n\n    def safeSocket(self, host: str, port: int, timeout: int) -> 'ssl.SSLSocket':\n        \"\"\"Create a safe socket that's using SOCKS/TOR if it was enabled.\n\n        Args:\n            host (str): host\n            port (int): port\n            timeout (int): timeout\n\n        Returns:\n            sock\n        \"\"\"\n        sock = socket.create_connection((host, int(port)), int(timeout))\n        sock.settimeout(int(timeout))\n        return sock\n\n    def safeSSLSocket(self, host: str, port: int, timeout: int) -> 'ssl.SSLSocket':\n        \"\"\"Create a safe SSL connection that's using SOCKs/TOR if it was enabled.\n\n        Args:\n            host (str): host\n            port (int): port\n            timeout (int): timeout\n\n        Returns:\n            sock\n        \"\"\"\n        s = socket.socket()\n        s.settimeout(int(timeout))\n        s.connect((host, int(port)))\n        sock = ssl.wrap_socket(s)\n        sock.do_handshake()\n        return sock\n\n    def parseCert(self, rawcert: str, fqdn: str = None, expiringdays: int = 30) -> dict:\n        \"\"\"Parse a PEM-format SSL certificate.\n\n        Args:\n            rawcert (str): PEM-format SSL certificate\n            fqdn (str): expected FQDN for certificate\n            expiringdays (int): The certificate will be considered as \"expiring\" if within this number of days of expiry.\n\n        Returns:\n            dict: certificate details\n        \"\"\"\n        if not rawcert:\n            self.error(f\"Invalid certificate: {rawcert}\")\n            return None\n\n        ret = dict()\n        if '\\r' in rawcert:\n            rawcert = rawcert.replace('\\r', '')\n        if isinstance(rawcert, str):\n            rawcert = rawcert.encode('utf-8')\n\n        from cryptography.hazmat.backends.openssl import backend\n        cert = cryptography.x509.load_pem_x509_certificate(rawcert, backend)\n        sslcert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, rawcert)\n        sslcert_dump = OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_TEXT, sslcert)\n\n        ret['text'] = sslcert_dump.decode('utf-8', errors='replace')\n        ret['issuer'] = str(cert.issuer)\n        ret['altnames'] = list()\n        ret['expired'] = False\n        ret['expiring'] = False\n        ret['mismatch'] = False\n        ret['certerror'] = False\n        ret['issued'] = str(cert.subject)\n\n        # Expiry info\n        try:\n            notafter = datetime.strptime(sslcert.get_notAfter().decode('utf-8'), \"%Y%m%d%H%M%SZ\")\n            ret['expiry'] = int(notafter.strftime(\"%s\"))\n            ret['expirystr'] = notafter.strftime(\"%Y-%m-%d %H:%M:%S\")\n            now = int(time.time())\n            warnexp = now + (expiringdays * 86400)\n            if ret['expiry'] <= warnexp:\n                ret['expiring'] = True\n            if ret['expiry'] <= now:\n                ret['expired'] = True\n        except BaseException as e:\n            self.error(f\"Error processing date in certificate: {e}\")\n            ret['certerror'] = True\n            return ret\n\n        # SANs\n        try:\n            ext = cert.extensions.get_extension_for_class(cryptography.x509.SubjectAlternativeName)\n            for x in ext.value:\n                if isinstance(x, cryptography.x509.DNSName):\n                    ret['altnames'].append(x.value.lower().encode('raw_unicode_escape').decode(\"ascii\", errors='replace'))\n        except BaseException as e:\n            self.debug(f\"Problem processing certificate: {e}\")\n\n        certhosts = list()\n        try:\n            attrs = cert.subject.get_attributes_for_oid(cryptography.x509.oid.NameOID.COMMON_NAME)\n\n            if len(attrs) == 1:\n                name = attrs[0].value.lower()\n                # CN often duplicates one of the SANs, don't add it then\n                if name not in ret['altnames']:\n                    certhosts.append(name)\n        except BaseException as e:\n            self.debug(f\"Problem processing certificate: {e}\")\n\n        # Check for mismatch\n        if fqdn and ret['issued']:\n            fqdn = fqdn.lower()\n\n            try:\n                # Extract the CN from the issued section\n                if \"cn=\" + fqdn in ret['issued'].lower():\n                    certhosts.append(fqdn)\n\n                # Extract subject alternative names\n                for host in ret['altnames']:\n                    certhosts.append(host.replace(\"dns:\", \"\"))\n\n                ret['hosts'] = certhosts\n\n                self.debug(f\"Checking for {fqdn} in certificate subject\")\n                fqdn_tld = \".\".join(fqdn.split(\".\")[1:]).lower()\n\n                found = False\n                for chost in certhosts:\n                    if chost == fqdn:\n                        found = True\n                    if chost == \"*.\" + fqdn_tld:\n                        found = True\n                    if chost == fqdn_tld:\n                        found = True\n\n                if not found:\n                    ret['mismatch'] = True\n            except BaseException as e:\n                self.error(f\"Error processing certificate: {e}\")\n                ret['certerror'] = True\n\n        return ret\n\n    def getSession(self) -> 'requests.sessions.Session':\n        \"\"\"Return requests session object.\n\n        Returns:\n            requests.sessions.Session: requests session\n        \"\"\"\n        session = requests.session()\n        if self.socksProxy:\n            session.proxies = {\n                'http': self.socksProxy,\n                'https': self.socksProxy,\n            }\n        return session\n\n    def removeUrlCreds(self, url: str) -> str:\n        \"\"\"Remove potentially sensitive strings (such as \"key=...\" and \"password=...\") from a string.\n\n        Used to remove potential credentials from URLs prior during logging.\n\n        Args:\n            url (str): URL\n\n        Returns:\n            str: Sanitized URL\n        \"\"\"\n        pats = {\n            r'key=\\S+': \"key=XXX\",\n            r'pass=\\S+': \"pass=XXX\",\n            r'user=\\S+': \"user=XXX\",\n            r'password=\\S+': \"password=XXX\"\n        }\n\n        ret = url\n        for pat in pats:\n            ret = re.sub(pat, pats[pat], ret, re.IGNORECASE)\n\n        return ret\n\n    def isValidLocalOrLoopbackIp(self, ip: str) -> bool:\n        \"\"\"Check if the specified IPv4 or IPv6 address is a loopback or local network IP address (IPv4 RFC1918 / IPv6 RFC4192 ULA).\n\n        Args:\n            ip (str): IPv4 or IPv6 address\n\n        Returns:\n            bool: IP address is local or loopback\n        \"\"\"\n        if not self.validIP(ip) and not self.validIP6(ip):\n            return False\n\n        if netaddr.IPAddress(ip).is_private():\n            return True\n\n        if netaddr.IPAddress(ip).is_loopback():\n            return True\n\n        return False\n\n    def useProxyForUrl(self, url: str) -> bool:\n        \"\"\"Check if the configured proxy should be used to connect to a specified URL.\n\n        Args:\n            url (str): The URL to check\n\n        Returns:\n            bool: should the configured proxy be used?\n\n        Todo:\n            Allow using TOR only for .onion addresses\n        \"\"\"\n        host = self.urlFQDN(url).lower()\n\n        if not self.opts['_socks1type']:\n            return False\n\n        proxy_host = self.opts['_socks2addr']\n\n        if not proxy_host:\n            return False\n\n        proxy_port = self.opts['_socks3port']\n\n        if not proxy_port:\n            return False\n\n        # Never proxy requests to the proxy host\n        if host == proxy_host.lower():\n            return False\n\n        # Never proxy RFC1918 addresses on the LAN or the local network interface\n        if self.validIP(host):\n            if netaddr.IPAddress(host).is_private():\n                return False\n            if netaddr.IPAddress(host).is_loopback():\n                return False\n\n        # Never proxy local hostnames\n        else:\n            neverProxyNames = ['local', 'localhost']\n            if host in neverProxyNames:\n                return False\n\n            for s in neverProxyNames:\n                if host.endswith(s):\n                    return False\n\n        return True\n\n    def fetchUrl(\n        self,\n        url: str,\n        cookies: str = None,\n        timeout: int = 30,\n        useragent: str = \"SpiderFoot\",\n        headers: dict = None,\n        noLog: bool = False,\n        postData: str = None,\n        disableContentEncoding: bool = False,\n        sizeLimit: int = None,\n        headOnly: bool = False,\n        verify: bool = True\n    ) -> dict:\n        \"\"\"Fetch a URL and return the HTTP response as a dictionary.\n\n        Args:\n            url (str): URL to fetch\n            cookies (str): cookies\n            timeout (int): timeout\n            useragent (str): user agent header\n            headers (dict): headers\n            noLog (bool): do not log request\n            postData (str): HTTP POST data\n            disableContentEncoding (bool): do not UTF-8 encode response body\n            sizeLimit (int): size threshold\n            headOnly (bool): use HTTP HEAD method\n            verify (bool): use HTTPS SSL/TLS verification\n\n        Returns:\n            dict: HTTP response\n        \"\"\"\n        if not url:\n            return None\n\n        result = {\n            'code': None,\n            'status': None,\n            'content': None,\n            'headers': None,\n            'realurl': url\n        }\n\n        url = url.strip()\n\n        try:\n            parsed_url = urllib.parse.urlparse(url)\n        except Exception:\n            self.debug(f\"Could not parse URL: {url}\")\n            return None\n\n        if parsed_url.scheme != 'http' and parsed_url.scheme != 'https':\n            self.debug(f\"Invalid URL scheme for URL: {url}\")\n            return None\n\n        request_log = []\n\n        proxies = dict()\n        if self.useProxyForUrl(url):\n            proxies = {\n                'http': self.socksProxy,\n                'https': self.socksProxy,\n            }\n\n        header = dict()\n        btime = time.time()\n\n        if isinstance(useragent, list):\n            header['User-Agent'] = random.SystemRandom().choice(useragent)\n        else:\n            header['User-Agent'] = useragent\n\n        # Add custom headers\n        if isinstance(headers, dict):\n            for k in list(headers.keys()):\n                header[k] = str(headers[k])\n\n        request_log.append(f\"proxy={self.socksProxy}\")\n        request_log.append(f\"user-agent={header['User-Agent']}\")\n        request_log.append(f\"timeout={timeout}\")\n        request_log.append(f\"cookies={cookies}\")\n\n        if sizeLimit or headOnly:\n            if noLog:\n                self.debug(f\"Fetching (HEAD): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n            else:\n                self.info(f\"Fetching (HEAD): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n\n            try:\n                hdr = self.getSession().head(\n                    url,\n                    headers=header,\n                    proxies=proxies,\n                    verify=verify,\n                    timeout=timeout\n                )\n            except Exception as e:\n                if noLog:\n                    self.debug(f\"Unexpected exception ({e}) occurred fetching (HEAD only) URL: {url}\", exc_info=True)\n                else:\n                    self.error(f\"Unexpected exception ({e}) occurred fetching (HEAD only) URL: {url}\", exc_info=True)\n\n                return result\n\n            size = int(hdr.headers.get('content-length', 0))\n            newloc = hdr.headers.get('location', url).strip()\n\n            # Relative re-direct\n            if newloc.startswith(\"/\") or newloc.startswith(\"../\"):\n                newloc = SpiderFootHelpers.urlBaseUrl(url) + newloc\n            result['realurl'] = newloc\n            result['code'] = str(hdr.status_code)\n\n            if headOnly:\n                return result\n\n            if size > sizeLimit:\n                return result\n\n            if result['realurl'] != url:\n                if noLog:\n                    self.debug(f\"Fetching (HEAD): {self.removeUrlCreds(result['realurl'])} ({', '.join(request_log)})\")\n                else:\n                    self.info(f\"Fetching (HEAD): {self.removeUrlCreds(result['realurl'])} ({', '.join(request_log)})\")\n\n                try:\n                    hdr = self.getSession().head(\n                        result['realurl'],\n                        headers=header,\n                        proxies=proxies,\n                        verify=verify,\n                        timeout=timeout\n                    )\n                    size = int(hdr.headers.get('content-length', 0))\n                    result['realurl'] = hdr.headers.get('location', result['realurl'])\n                    result['code'] = str(hdr.status_code)\n\n                    if size > sizeLimit:\n                        return result\n\n                except Exception as e:\n                    if noLog:\n                        self.debug(f\"Unexpected exception ({e}) occurred fetching (HEAD only) URL: {result['realurl']}\", exc_info=True)\n                    else:\n                        self.error(f\"Unexpected exception ({e}) occurred fetching (HEAD only) URL: {result['realurl']}\", exc_info=True)\n\n                    return result\n\n        try:\n            if postData:\n                if noLog:\n                    self.debug(f\"Fetching (POST): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n                else:\n                    self.info(f\"Fetching (POST): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n                res = self.getSession().post(\n                    url,\n                    data=postData,\n                    headers=header,\n                    proxies=proxies,\n                    allow_redirects=True,\n                    cookies=cookies,\n                    timeout=timeout,\n                    verify=verify\n                )\n            else:\n                if noLog:\n                    self.debug(f\"Fetching (GET): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n                else:\n                    self.info(f\"Fetching (GET): {self.removeUrlCreds(url)} ({', '.join(request_log)})\")\n                res = self.getSession().get(\n                    url,\n                    headers=header,\n                    proxies=proxies,\n                    allow_redirects=True,\n                    cookies=cookies,\n                    timeout=timeout,\n                    verify=verify\n                )\n        except requests.exceptions.RequestException as e:\n            self.error(f\"Failed to connect to {url}: {e}\")\n            return result\n        except Exception as e:\n            if noLog:\n                self.debug(f\"Unexpected exception ({e}) occurred fetching URL: {url}\", exc_info=True)\n            else:\n                self.error(f\"Unexpected exception ({e}) occurred fetching URL: {url}\", exc_info=True)\n\n            return result\n\n        try:\n            result['headers'] = dict()\n            result['realurl'] = res.url\n            result['code'] = str(res.status_code)\n\n            for header, value in res.headers.items():\n                result['headers'][str(header).lower()] = str(value)\n\n            # Sometimes content exceeds the size limit after decompression\n            if sizeLimit and len(res.content) > sizeLimit:\n                self.debug(f\"Content exceeded size limit ({sizeLimit}), so returning no data just headers\")\n                return result\n\n            refresh_header = result['headers'].get('refresh')\n            if refresh_header:\n                try:\n                    newurl = refresh_header.split(\";url=\")[1]\n                except Exception as e:\n                    self.debug(f\"Refresh header '{refresh_header}' found, but not parsable: {e}\")\n                    return result\n\n                self.debug(f\"Refresh header '{refresh_header}' found, re-directing to {self.removeUrlCreds(newurl)}\")\n\n                return self.fetchUrl(\n                    newurl,\n                    cookies,\n                    timeout,\n                    useragent,\n                    headers,\n                    noLog,\n                    postData,\n                    disableContentEncoding,\n                    sizeLimit,\n                    headOnly\n                )\n\n            if disableContentEncoding:\n                result['content'] = res.content\n            else:\n                for encoding in (\"utf-8\", \"ascii\"):\n                    try:\n                        result[\"content\"] = res.content.decode(encoding)\n                    except UnicodeDecodeError:\n                        pass\n                    else:\n                        break\n                else:\n                    result[\"content\"] = res.content\n\n        except Exception as e:\n            self.error(f\"Unexpected exception ({e}) occurred parsing response for URL: {url}\", exc_info=True)\n            result['content'] = None\n            result['status'] = str(e)\n\n        atime = time.time()\n        t = str(atime - btime)\n        self.info(f\"Fetched {self.removeUrlCreds(url)} ({len(result['content'] or '')} bytes in {t}s)\")\n        return result\n\n    def checkDnsWildcard(self, target: str) -> bool:\n        \"\"\"Check if wildcard DNS is enabled for a domain by looking up a random subdomain.\n\n        Args:\n            target (str): domain\n\n        Returns:\n            bool: Domain returns DNS records for any subdomains\n        \"\"\"\n        if not target:\n            return False\n\n        randpool = 'bcdfghjklmnpqrstvwxyz3456789'\n        randhost = ''.join([random.SystemRandom().choice(randpool) for x in range(10)])\n\n        if not self.resolveHost(randhost + \".\" + target):\n            return False\n\n        return True\n\n    def cveInfo(self, cveId: str, sources: str = \"circl,nist\") -> (str, str):\n        \"\"\"Look up a CVE ID for more information in the first available source.\n\n        Args:\n            cveId (str): CVE ID, e.g. CVE-2018-15473\n            sources (str): Comma-separated list of sources to query. Options available are circl and nist\n\n        Returns:\n            (str, str): Appropriate event type and descriptive text\n        \"\"\"\n        sources = sources.split(\",\")\n        # VULNERABILITY_GENERAL is the generic type in case we don't have\n        # a real/mappable CVE.\n        eventType = \"VULNERABILITY_GENERAL\"\n\n        def cveRating(score: int) -> str:\n            if score == \"Unknown\":\n                return None\n            if score >= 0 and score <= 3.9:\n                return \"LOW\"\n            if score >= 4.0 and score <= 6.9:\n                return \"MEDIUM\"\n            if score >= 7.0 and score <= 8.9:\n                return \"HIGH\"\n            if score >= 9.0:\n                return \"CRITICAL\"\n            return None\n\n        for source in sources:\n            jsondata = self.cacheGet(f\"{source}-{cveId}\", 86400)\n\n            if not jsondata:\n                # Fetch data from source\n                if source == \"nist\":\n                    ret = self.fetchUrl(f\"https://services.nvd.nist.gov/rest/json/cve/1.0/{cveId}\", timeout=5)\n                if source == \"circl\":\n                    ret = self.fetchUrl(f\"https://cve.circl.lu/api/cve/{cveId}\", timeout=5)\n\n                if not ret:\n                    continue\n\n                if not ret['content']:\n                    continue\n\n                self.cachePut(f\"{source}-{cveId}\", ret['content'])\n                jsondata = ret['content']\n\n            try:\n                data = json.loads(jsondata)\n\n                if source == \"circl\":\n                    score = data.get('cvss', 'Unknown')\n                    rating = cveRating(score)\n                    if rating:\n                        eventType = f\"VULNERABILITY_CVE_{rating}\"\n                        return (eventType, f\"{cveId}\\n<SFURL>https://nvd.nist.gov/vuln/detail/{cveId}</SFURL>\\n\"\n                                f\"Score: {score}\\nDescription: {data.get('summary', 'Unknown')}\")\n\n                if source == \"nist\":\n                    try:\n                        if data['result']['CVE_Items'][0]['impact'].get('baseMetricV3'):\n                            score = data['result']['CVE_Items'][0]['impact']['baseMetricV3']['cvssV3']['baseScore']\n                        else:\n                            score = data['result']['CVE_Items'][0]['impact']['baseMetricV2']['cvssV2']['baseScore']\n                        rating = cveRating(score)\n                        if rating:\n                            eventType = f\"VULNERABILITY_CVE_{rating}\"\n                    except Exception:\n                        score = \"Unknown\"\n\n                    try:\n                        descr = data['result']['CVE_Items'][0]['cve']['description']['description_data'][0]['value']\n                    except Exception:\n                        descr = \"Unknown\"\n\n                    return (eventType, f\"{cveId}\\n<SFURL>https://nvd.nist.gov/vuln/detail/{cveId}</SFURL>\\n\"\n                            f\"Score: {score}\\nDescription: {descr}\")\n            except BaseException as e:\n                self.debug(f\"Unable to parse CVE response from {source.upper()}: {e}\")\n                continue\n\n        return (eventType, f\"{cveId}\\nScore: Unknown\\nDescription: Unknown\")\n\n    def googleIterate(self, searchString: str, opts: dict = None) -> dict:\n        \"\"\"Request search results from the Google API.\n\n        Will return a dict:\n        {\n          \"urls\": a list of urls that match the query string,\n          \"webSearchUrl\": url for Google results page,\n        }\n\n        Options accepted:\n            useragent: User-Agent string to use\n            timeout: API call timeout\n\n        Args:\n            searchString (str): Google search query\n            opts (dict): TBD\n\n        Returns:\n            dict: Search results as {\"webSearchUrl\": \"URL\", \"urls\": [results]}\n        \"\"\"\n        if not searchString:\n            return None\n\n        if opts is None:\n            opts = {}\n\n        search_string = searchString.replace(\" \", \"%20\")\n        params = urllib.parse.urlencode({\n            \"cx\": opts[\"cse_id\"],\n            \"key\": opts[\"api_key\"],\n        })\n\n        response = self.fetchUrl(\n            f\"https://www.googleapis.com/customsearch/v1?q={search_string}&{params}\",\n            timeout=opts[\"timeout\"],\n        )\n\n        if response['code'] != '200':\n            self.error(\"Failed to get a valid response from the Google API\")\n            return None\n\n        try:\n            response_json = json.loads(response['content'])\n        except ValueError:\n            self.error(\"The key 'content' in the Google API response doesn't contain valid JSON.\")\n            return None\n\n        if \"items\" not in response_json:\n            return None\n\n        # We attempt to make the URL params look as authentically human as possible\n        params = urllib.parse.urlencode({\n            \"ie\": \"utf-8\",\n            \"oe\": \"utf-8\",\n            \"aq\": \"t\",\n            \"rls\": \"org.mozilla:en-US:official\",\n            \"client\": \"firefox-a\",\n        })\n\n        return {\n            \"urls\": [str(k['link']) for k in response_json['items']],\n            \"webSearchUrl\": f\"https://www.google.com/search?q={search_string}&{params}\"\n        }\n\n    def bingIterate(self, searchString: str, opts: dict = None) -> dict:\n        \"\"\"Request search results from the Bing API.\n\n        Will return a dict:\n        {\n          \"urls\": a list of urls that match the query string,\n          \"webSearchUrl\": url for bing results page,\n        }\n\n        Options accepted:\n            count: number of search results to request from the API\n            useragent: User-Agent string to use\n            timeout: API call timeout\n\n        Args:\n            searchString (str): Bing search query\n            opts (dict): TBD\n\n        Returns:\n            dict: Search results as {\"webSearchUrl\": \"URL\", \"urls\": [results]}\n        \"\"\"\n        if not searchString:\n            return None\n\n        if opts is None:\n            opts = {}\n\n        search_string = searchString.replace(\" \", \"%20\")\n        params = urllib.parse.urlencode({\n            \"responseFilter\": \"Webpages\",\n            \"count\": opts[\"count\"],\n        })\n\n        response = self.fetchUrl(\n            f\"https://api.cognitive.microsoft.com/bing/v7.0/search?q={search_string}&{params}\",\n            timeout=opts[\"timeout\"],\n            useragent=opts[\"useragent\"],\n            headers={\"Ocp-Apim-Subscription-Key\": opts[\"api_key\"]},\n        )\n\n        if response['code'] != '200':\n            self.error(\"Failed to get a valid response from the Bing API\")\n            return None\n\n        try:\n            response_json = json.loads(response['content'])\n        except ValueError:\n            self.error(\"The key 'content' in the bing API response doesn't contain valid JSON.\")\n            return None\n\n        if (\"webPages\" in response_json and \"value\" in response_json[\"webPages\"] and \"webSearchUrl\" in response_json[\"webPages\"]):\n            return {\n                \"urls\": [result[\"url\"] for result in response_json[\"webPages\"][\"value\"]],\n                \"webSearchUrl\": response_json[\"webPages\"][\"webSearchUrl\"],\n            }\n\n        return None\n\n# end of SpiderFoot class\n"
        },
        {
          "name": "sfscan.py",
          "type": "blob",
          "size": 22.8974609375,
          "content": "# -*- coding: utf-8 -*-\n# -----------------------------------------------------------------\n# Name:         sfscan\n# Purpose:      Scanning control functionality\n#\n# Author:       Steve Micallef <steve@binarypool.com>\n#\n# Created:      11/03/2013\n# Copyright:    (c) Steve Micallef 2013\n# License:      MIT\n# -----------------------------------------------------------------\nimport socket\nimport time\nimport queue\nfrom time import sleep\nfrom copy import deepcopy\nfrom contextlib import suppress\nfrom collections import OrderedDict\n\nimport dns.resolver\n\nfrom sflib import SpiderFoot\nfrom spiderfoot import SpiderFootDb, SpiderFootEvent, SpiderFootPlugin, SpiderFootTarget, SpiderFootHelpers, SpiderFootThreadPool, SpiderFootCorrelator, logger\n\n\ndef startSpiderFootScanner(loggingQueue, *args, **kwargs):\n    logger.logWorkerSetup(loggingQueue)\n    return SpiderFootScanner(*args, **kwargs)\n\n\nclass SpiderFootScanner():\n    \"\"\"SpiderFootScanner object.\n\n    Attributes:\n        scanId (str): unique ID of the scan\n        status (str): status of the scan\n    \"\"\"\n\n    __scanId = None\n    __status = None\n    __config = None\n    __sf = None\n    __dbh = None\n    __targetValue = None\n    __targetType = None\n    __moduleList = list()\n    __target = None\n    __moduleInstances = dict()\n    __modconfig = dict()\n    __scanName = None\n\n    def __init__(self, scanName: str, scanId: str, targetValue: str, targetType: str, moduleList: list, globalOpts: dict, start: bool = True) -> None:\n        \"\"\"Initialize SpiderFootScanner object.\n\n        Args:\n            scanName (str): name of the scan\n            scanId (str): unique ID of the scan\n            targetValue (str): scan target\n            targetType (str): scan target type\n            moduleList (list): list of modules to run\n            globalOpts (dict): scan options\n            start (bool): start the scan immediately\n\n        Raises:\n            TypeError: arg type was invalid\n            ValueError: arg value was invalid\n\n        Todo:\n             Eventually change this to be able to control multiple scan instances\n        \"\"\"\n        if not isinstance(globalOpts, dict):\n            raise TypeError(f\"globalOpts is {type(globalOpts)}; expected dict()\")\n        if not globalOpts:\n            raise ValueError(\"globalOpts is empty\")\n\n        self.__config = deepcopy(globalOpts)\n        self.__dbh = SpiderFootDb(self.__config)\n\n        if not isinstance(scanName, str):\n            raise TypeError(f\"scanName is {type(scanName)}; expected str()\")\n        if not scanName:\n            raise ValueError(\"scanName value is blank\")\n\n        self.__scanName = scanName\n\n        if not isinstance(scanId, str):\n            raise TypeError(f\"scanId is {type(scanId)}; expected str()\")\n        if not scanId:\n            raise ValueError(\"scanId value is blank\")\n\n        if not isinstance(targetValue, str):\n            raise TypeError(f\"targetValue is {type(targetValue)}; expected str()\")\n        if not targetValue:\n            raise ValueError(\"targetValue value is blank\")\n\n        self.__targetValue = targetValue\n\n        if not isinstance(targetType, str):\n            raise TypeError(f\"targetType is {type(targetType)}; expected str()\")\n        if not targetType:\n            raise ValueError(\"targetType value is blank\")\n\n        self.__targetType = targetType\n\n        if not isinstance(moduleList, list):\n            raise TypeError(f\"moduleList is {type(moduleList)}; expected list()\")\n        if not moduleList:\n            raise ValueError(\"moduleList is empty\")\n\n        self.__moduleList = moduleList\n        self.__sf = SpiderFoot(self.__config)\n        self.__sf.dbh = self.__dbh\n\n        # Create a unique ID for this scan in the back-end DB.\n        if scanId:\n            self.__scanId = scanId\n        else:\n            self.__scanId = SpiderFootHelpers.genScanInstanceId()\n\n        self.__sf.scanId = self.__scanId\n        self.__dbh.scanInstanceCreate(self.__scanId, self.__scanName, self.__targetValue)\n\n        # Create our target\n        try:\n            self.__target = SpiderFootTarget(self.__targetValue, self.__targetType)\n        except (TypeError, ValueError) as e:\n            self.__sf.status(f\"Scan [{self.__scanId}] failed: {e}\")\n            self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n            raise ValueError(f\"Invalid target: {e}\") from None\n\n        # Save the config current set for this scan\n        self.__config['_modulesenabled'] = self.__moduleList\n        self.__dbh.scanConfigSet(self.__scanId, self.__sf.configSerialize(deepcopy(self.__config)))\n\n        # Process global options that point to other places for data\n\n        # If a proxy server was specified, set it up\n        proxy_type = self.__config.get('_socks1type')\n        if proxy_type:\n            # TODO: allow DNS lookup to be configurable when using a proxy\n            # - proxy DNS lookup: socks5h:// and socks4a://\n            # - local DNS lookup: socks5:// and socks4://\n            if proxy_type == '4':\n                proxy_proto = 'socks4://'\n            elif proxy_type == '5':\n                proxy_proto = 'socks5://'\n            elif proxy_type == 'HTTP':\n                proxy_proto = 'http://'\n            elif proxy_type == 'TOR':\n                proxy_proto = 'socks5h://'\n            else:\n                self.__sf.status(f\"Scan [{self.__scanId}] failed: Invalid proxy type: {proxy_type}\")\n                self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n                raise ValueError(f\"Invalid proxy type: {proxy_type}\")\n\n            proxy_host = self.__config.get('_socks2addr', '')\n\n            if not proxy_host:\n                self.__sf.status(f\"Scan [{self.__scanId}] failed: Proxy type is set ({proxy_type}) but proxy address value is blank\")\n                self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n                raise ValueError(f\"Proxy type is set ({proxy_type}) but proxy address value is blank\")\n\n            proxy_port = int(self.__config.get('_socks3port') or 0)\n\n            if not proxy_port:\n                if proxy_type in ['4', '5']:\n                    proxy_port = 1080\n                elif proxy_type.upper() == 'HTTP':\n                    proxy_port = 8080\n                elif proxy_type.upper() == 'TOR':\n                    proxy_port = 9050\n\n            proxy_username = self.__config.get('_socks4user', '')\n            proxy_password = self.__config.get('_socks5pwd', '')\n\n            if proxy_username or proxy_password:\n                proxy_auth = f\"{proxy_username}:{proxy_password}\"\n                proxy = f\"{proxy_proto}{proxy_auth}@{proxy_host}:{proxy_port}\"\n            else:\n                proxy = f\"{proxy_proto}{proxy_host}:{proxy_port}\"\n\n            self.__sf.debug(f\"Using proxy: {proxy}\")\n            self.__sf.socksProxy = proxy\n        else:\n            self.__sf.socksProxy = None\n\n        # Override the default DNS server\n        if self.__config['_dnsserver']:\n            res = dns.resolver.Resolver()\n            res.nameservers = [self.__config['_dnsserver']]\n            dns.resolver.override_system_resolver(res)\n        else:\n            dns.resolver.restore_system_resolver()\n\n        # Set the user agent\n        self.__config['_useragent'] = self.__sf.optValueToData(self.__config['_useragent'])\n\n        # Set up the Internet TLD list.\n        # If the cached does not exist or has expired, reload it from scratch.\n        tld_data = self.__sf.cacheGet(\"internet_tlds\", self.__config['_internettlds_cache'])\n        if tld_data is None:\n            tld_data = self.__sf.optValueToData(self.__config['_internettlds'])\n            if tld_data is None:\n                self.__sf.status(f\"Scan [{self.__scanId}] failed: Could not update TLD list\")\n                self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n                raise ValueError(\"Could not update TLD list\")\n            self.__sf.cachePut(\"internet_tlds\", tld_data)\n\n        self.__config['_internettlds'] = tld_data.splitlines()\n\n        self.__setStatus(\"INITIALIZING\", time.time() * 1000, None)\n\n        self.__sharedThreadPool = SpiderFootThreadPool(threads=self.__config.get(\"_maxthreads\", 3), name='sharedThreadPool')\n\n        # Used when module threading is enabled\n        self.eventQueue = None\n\n        if start:\n            self.__startScan()\n\n    @property\n    def scanId(self) -> str:\n        return self.__scanId\n\n    @property\n    def status(self) -> str:\n        return self.__status\n\n    def __setStatus(self, status: str, started: float = None, ended: float = None) -> None:\n        \"\"\"Set the status of the currently running scan (if any).\n\n        Args:\n            status (str): scan status\n            started (float): timestamp at start of scan\n            ended (float): timestamp at end of scan\n\n        Raises:\n            TypeError: arg type was invalid\n            ValueError: arg value was invalid\n        \"\"\"\n        if not isinstance(status, str):\n            raise TypeError(f\"status is {type(status)}; expected str()\")\n\n        if status not in [\n            \"INITIALIZING\",\n            \"STARTING\",\n            \"STARTED\",\n            \"RUNNING\",\n            \"ABORT-REQUESTED\",\n            \"ABORTED\",\n            \"ABORTING\",\n            \"FINISHED\",\n            \"ERROR-FAILED\"\n        ]:\n            raise ValueError(f\"Invalid scan status {status}\")\n\n        self.__status = status\n        self.__dbh.scanInstanceSet(self.__scanId, started, ended, status)\n\n    def __startScan(self) -> None:\n        \"\"\"Start running a scan.\n\n        Raises:\n            AssertionError: Never actually raised.\n        \"\"\"\n        failed = True\n\n        try:\n            self.__setStatus(\"STARTING\", time.time() * 1000, None)\n            self.__sf.status(f\"Scan [{self.__scanId}] for '{self.__target.targetValue}' initiated.\")\n\n            self.eventQueue = queue.Queue()\n\n            self.__sharedThreadPool.start()\n\n            # moduleList = list of modules the user wants to run\n            self.__sf.debug(f\"Loading {len(self.__moduleList)} modules ...\")\n            for modName in self.__moduleList:\n                if not modName:\n                    continue\n\n                # Module may have been renamed or removed\n                if modName not in self.__config['__modules__']:\n                    self.__sf.error(f\"Failed to load module: {modName}\")\n                    continue\n\n                try:\n                    module = __import__('modules.' + modName, globals(), locals(), [modName])\n                except ImportError:\n                    self.__sf.error(f\"Failed to load module: {modName}\")\n                    continue\n\n                try:\n                    mod = getattr(module, modName)()\n                    mod.__name__ = modName\n                except Exception:\n                    self.__sf.error(f\"Module {modName} initialization failed\", exc_info=True)\n                    continue\n\n                # Set up the module options, scan ID, database handle and listeners\n                try:\n                    # Configuration is a combined global config with module-specific options\n                    self.__modconfig[modName] = deepcopy(self.__config['__modules__'][modName]['opts'])\n                    for opt in list(self.__config.keys()):\n                        self.__modconfig[modName][opt] = deepcopy(self.__config[opt])\n\n                    # clear any listener relationships from the past\n                    mod.clearListeners()\n                    mod.setScanId(self.__scanId)\n                    mod.setSharedThreadPool(self.__sharedThreadPool)\n                    mod.setDbh(self.__dbh)\n                    mod.setup(self.__sf, self.__modconfig[modName])\n                except Exception:\n                    self.__sf.error(f\"Module {modName} initialization failed\", exc_info=True)\n                    mod.errorState = True\n                    continue\n\n                # Override the module's local socket module to be the SOCKS one.\n                if self.__config['_socks1type'] != '':\n                    try:\n                        mod._updateSocket(socket)\n                    except Exception as e:\n                        self.__sf.error(f\"Module {modName} socket setup failed: {e}\")\n                        continue\n\n                # Set up event output filters if requested\n                if self.__config['__outputfilter']:\n                    try:\n                        mod.setOutputFilter(self.__config['__outputfilter'])\n                    except Exception as e:\n                        self.__sf.error(f\"Module {modName} output filter setup failed: {e}\")\n                        continue\n\n                # Give modules a chance to 'enrich' the original target with aliases of that target.\n                try:\n                    newTarget = mod.enrichTarget(self.__target)\n                    if newTarget is not None:\n                        self.__target = newTarget\n                except Exception as e:\n                    self.__sf.error(f\"Module {modName} target enrichment failed: {e}\")\n                    continue\n\n                # Register the target with the module\n                try:\n                    mod.setTarget(self.__target)\n                except Exception as e:\n                    self.__sf.error(f\"Module {modName} failed to set target '{self.__target}': {e}\")\n                    continue\n\n                # Set up the outgoing event queue\n                try:\n                    mod.outgoingEventQueue = self.eventQueue\n                    mod.incomingEventQueue = queue.Queue()\n                except Exception as e:\n                    self.__sf.error(f\"Module {modName} event queue setup failed: {e}\")\n                    continue\n\n                self.__moduleInstances[modName] = mod\n                self.__sf.status(f\"{modName} module loaded.\")\n\n            self.__sf.debug(f\"Scan [{self.__scanId}] loaded {len(self.__moduleInstances)} modules.\")\n\n            if not self.__moduleInstances:\n                self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n                self.__dbh.close()\n                return\n\n            # sort modules by priority\n            self.__moduleInstances = OrderedDict(sorted(self.__moduleInstances.items(), key=lambda m: m[-1]._priority))\n\n            # Now we are ready to roll..\n            self.__setStatus(\"RUNNING\")\n\n            # Create a pseudo module for the root event to originate from\n            psMod = SpiderFootPlugin()\n            psMod.__name__ = \"SpiderFoot UI\"\n            psMod.setTarget(self.__target)\n            psMod.setDbh(self.__dbh)\n            psMod.clearListeners()\n            psMod.outgoingEventQueue = self.eventQueue\n            psMod.incomingEventQueue = queue.Queue()\n\n            # Create the \"ROOT\" event which un-triggered modules will link events to\n            rootEvent = SpiderFootEvent(\"ROOT\", self.__targetValue, \"\", None)\n            psMod.notifyListeners(rootEvent)\n            firstEvent = SpiderFootEvent(self.__targetType, self.__targetValue,\n                                         \"SpiderFoot UI\", rootEvent)\n            psMod.notifyListeners(firstEvent)\n\n            # Special case.. check if an INTERNET_NAME is also a domain\n            if self.__targetType == 'INTERNET_NAME' and self.__sf.isDomain(self.__targetValue, self.__config['_internettlds']):\n                firstEvent = SpiderFootEvent('DOMAIN_NAME', self.__targetValue, \"SpiderFoot UI\", rootEvent)\n                psMod.notifyListeners(firstEvent)\n\n            # If in interactive mode, loop through this shared global variable\n            # waiting for inputs, and process them until my status is set to\n            # FINISHED.\n\n            # Check in case the user requested to stop the scan between modules\n            # initializing\n            scanstatus = self.__dbh.scanInstanceGet(self.__scanId)\n            if scanstatus and scanstatus[5] == \"ABORT-REQUESTED\":\n                raise AssertionError(\"ABORT-REQUESTED\")\n\n            # start threads\n            self.waitForThreads()\n            failed = False\n\n        except (KeyboardInterrupt, AssertionError):\n            self.__sf.status(f\"Scan [{self.__scanId}] aborted.\")\n            self.__setStatus(\"ABORTED\", None, time.time() * 1000)\n\n        except BaseException as e:\n            self.__sf.error(\n                f\"Unhandled exception ({e.__class__.__name__}) encountered during scan. Please report this as a bug\",\n                exc_info=True\n            )\n            self.__sf.status(f\"Scan [{self.__scanId}] failed: {e}\")\n            self.__setStatus(\"ERROR-FAILED\", None, time.time() * 1000)\n\n        finally:\n            if not failed:\n                self.__setStatus(\"FINISHED\", None, time.time() * 1000)\n                self.runCorrelations()\n                self.__sf.status(f\"Scan [{self.__scanId}] completed.\")\n            self.__dbh.close()\n\n    def runCorrelations(self) -> None:\n        \"\"\"Run correlation rules.\"\"\"\n\n        self.__sf.status(f\"Running {len(self.__config['__correlationrules__'])} correlation rules on scan {self.__scanId}.\")\n        ruleset = dict()\n        for rule in self.__config['__correlationrules__']:\n            ruleset[rule['id']] = rule['rawYaml']\n        corr = SpiderFootCorrelator(self.__dbh, ruleset, self.__scanId)\n        corr.run_correlations()\n\n    def waitForThreads(self) -> None:\n        \"\"\"Wait for threads.\n\n        Raises:\n            TypeError: queue tried to process a malformed event\n            AssertionError: scan halted for some reason\n        \"\"\"\n        if not self.eventQueue:\n            return\n\n        counter = 0\n\n        try:\n            # start one thread for each module\n            for mod in self.__moduleInstances.values():\n                mod.start()\n            final_passes = 3\n\n            # watch for newly-generated events\n            while True:\n\n                # log status of threads every 10 iterations\n                log_status = counter % 10 == 0\n                counter += 1\n\n                if log_status:\n                    scanstatus = self.__dbh.scanInstanceGet(self.__scanId)\n                    if scanstatus and scanstatus[5] == \"ABORT-REQUESTED\":\n                        raise AssertionError(\"ABORT-REQUESTED\")\n\n                try:\n                    sfEvent = self.eventQueue.get_nowait()\n                    self.__sf.debug(f\"waitForThreads() got event, {sfEvent.eventType}, from eventQueue.\")\n                except queue.Empty:\n                    # check if we're finished\n                    if self.threadsFinished(log_status):\n                        sleep(.1)\n                        # but are we really?\n                        if self.threadsFinished(log_status):\n                            if final_passes < 1:\n                                break\n                            # Trigger module.finished()\n                            for mod in self.__moduleInstances.values():\n                                if not mod.errorState and mod.incomingEventQueue is not None:\n                                    mod.incomingEventQueue.put('FINISHED')\n                            sleep(.1)\n                            while not self.threadsFinished(log_status):\n                                log_status = counter % 100 == 0\n                                counter += 1\n                                sleep(.01)\n                            final_passes -= 1\n\n                    else:\n                        # save on CPU\n                        sleep(.1)\n                    continue\n\n                if not isinstance(sfEvent, SpiderFootEvent):\n                    raise TypeError(f\"sfEvent is {type(sfEvent)}; expected SpiderFootEvent\")\n\n                # for every module\n                for mod in self.__moduleInstances.values():\n                    # if it's been aborted\n                    if mod._stopScanning:\n                        # break out of the while loop\n                        raise AssertionError(f\"{mod.__name__} requested stop\")\n\n                    # send it the new event if applicable\n                    if not mod.errorState and mod.incomingEventQueue is not None:\n                        watchedEvents = mod.watchedEvents()\n                        if sfEvent.eventType in watchedEvents or \"*\" in watchedEvents:\n                            mod.incomingEventQueue.put(deepcopy(sfEvent))\n\n        finally:\n            # tell the modules to stop\n            for mod in self.__moduleInstances.values():\n                mod._stopScanning = True\n            self.__sharedThreadPool.shutdown(wait=True)\n\n    def threadsFinished(self, log_status: bool = False) -> bool:\n        \"\"\"Check if all threads are complete.\n\n        Args:\n            log_status (bool): print thread queue status to debug log\n\n        Returns:\n            bool: True if all threads are finished\n        \"\"\"\n        if self.eventQueue is None:\n            return True\n\n        modules_waiting = dict()\n        for m in self.__moduleInstances.values():\n            try:\n                if m.incomingEventQueue is not None:\n                    modules_waiting[m.__name__] = m.incomingEventQueue.qsize()\n            except Exception:\n                with suppress(Exception):\n                    m.errorState = True\n        modules_waiting = sorted(modules_waiting.items(), key=lambda x: x[-1], reverse=True)\n\n        modules_running = []\n        for m in self.__moduleInstances.values():\n            try:\n                if m.running:\n                    modules_running.append(m.__name__)\n            except Exception:\n                with suppress(Exception):\n                    m.errorState = True\n\n        modules_errored = []\n        for m in self.__moduleInstances.values():\n            try:\n                if m.errorState:\n                    modules_errored.append(m.__name__)\n            except Exception:\n                with suppress(Exception):\n                    m.errorState = True\n\n        queues_empty = [qsize == 0 for m, qsize in modules_waiting]\n\n        for mod in self.__moduleInstances.values():\n            if mod.errorState and mod.incomingEventQueue is not None:\n                self.__sf.debug(f\"Clearing and unsetting incomingEventQueue for errored module {mod.__name__}.\")\n                with suppress(Exception):\n                    while 1:\n                        mod.incomingEventQueue.get_nowait()\n                mod.incomingEventQueue = None\n\n        if not modules_running and not queues_empty:\n            self.__sf.debug(\"Clearing queues for stalled/aborted modules.\")\n            for mod in self.__moduleInstances.values():\n                with suppress(Exception):\n                    while True:\n                        mod.incomingEventQueue.get_nowait()\n\n        if log_status:\n            events_queued = \", \".join([f\"{mod}: {qsize:,}\" for mod, qsize in modules_waiting[:5] if qsize > 0])\n            if not events_queued:\n                events_queued = 'None'\n            self.__sf.debug(f\"Events queued: {sum([m[-1] for m in modules_waiting]):,} ({events_queued})\")\n            if modules_running:\n                self.__sf.debug(f\"Modules running: {len(modules_running):,} ({', '.join(modules_running)})\")\n            if modules_errored:\n                self.__sf.debug(f\"Modules errored: {len(modules_errored):,} ({', '.join(modules_errored)})\")\n\n        if all(queues_empty) and not modules_running:\n            return True\n        return False\n"
        },
        {
          "name": "sfwebui.py",
          "type": "blob",
          "size": 64.0615234375,
          "content": "# -*- coding: utf-8 -*-\n# -----------------------------------------------------------------\n# Name:         sfwebui\n# Purpose:      User interface class for use with a web browser\n#\n# Author:       Steve Micallef <steve@binarypool.com>\n#\n# Created:      30/09/2012\n# Copyright:    (c) Steve Micallef 2012\n# License:      MIT\n# -----------------------------------------------------------------\nimport csv\nimport html\nimport json\nimport logging\nimport multiprocessing as mp\nimport random\nimport string\nimport time\nfrom copy import deepcopy\nfrom io import BytesIO, StringIO\nfrom operator import itemgetter\n\nimport cherrypy\nfrom cherrypy import _cperror\n\nfrom mako.lookup import TemplateLookup\nfrom mako.template import Template\n\nimport openpyxl\n\nimport secure\n\nfrom sflib import SpiderFoot\n\nfrom sfscan import startSpiderFootScanner\n\nfrom spiderfoot import SpiderFootDb\nfrom spiderfoot import SpiderFootHelpers\nfrom spiderfoot import __version__\nfrom spiderfoot.logger import logListenerSetup, logWorkerSetup\n\nmp.set_start_method(\"spawn\", force=True)\n\n\nclass SpiderFootWebUi:\n    \"\"\"SpiderFoot web interface.\"\"\"\n\n    lookup = TemplateLookup(directories=[''])\n    defaultConfig = dict()\n    config = dict()\n    token = None\n    docroot = ''\n\n    def __init__(self: 'SpiderFootWebUi', web_config: dict, config: dict, loggingQueue: 'logging.handlers.QueueListener' = None) -> None:\n        \"\"\"Initialize web server.\n\n        Args:\n            web_config (dict): config settings for web interface (interface, port, root path)\n            config (dict): SpiderFoot config\n            loggingQueue: TBD\n\n        Raises:\n            TypeError: arg type is invalid\n            ValueError: arg value is invalid\n        \"\"\"\n        if not isinstance(config, dict):\n            raise TypeError(f\"config is {type(config)}; expected dict()\")\n        if not config:\n            raise ValueError(\"config is empty\")\n\n        if not isinstance(web_config, dict):\n            raise TypeError(f\"web_config is {type(web_config)}; expected dict()\")\n        if not config:\n            raise ValueError(\"web_config is empty\")\n\n        self.docroot = web_config.get('root', '/').rstrip('/')\n\n        # 'config' supplied will be the defaults, let's supplement them\n        # now with any configuration which may have previously been saved.\n        self.defaultConfig = deepcopy(config)\n        dbh = SpiderFootDb(self.defaultConfig, init=True)\n        sf = SpiderFoot(self.defaultConfig)\n        self.config = sf.configUnserialize(dbh.configGet(), self.defaultConfig)\n\n        # Set up logging\n        if loggingQueue is None:\n            self.loggingQueue = mp.Queue()\n            logListenerSetup(self.loggingQueue, self.config)\n        else:\n            self.loggingQueue = loggingQueue\n        logWorkerSetup(self.loggingQueue)\n        self.log = logging.getLogger(f\"spiderfoot.{__name__}\")\n\n        cherrypy.config.update({\n            'error_page.401': self.error_page_401,\n            'error_page.404': self.error_page_404,\n            'request.error_response': self.error_page\n        })\n\n        csp = (\n            secure.ContentSecurityPolicy()\n            .default_src(\"'self'\")\n            .script_src(\"'self'\", \"'unsafe-inline'\", \"blob:\")\n            .style_src(\"'self'\", \"'unsafe-inline'\")\n            .base_uri(\"'self'\")\n            .connect_src(\"'self'\", \"data:\")\n            .frame_src(\"'self'\", 'data:')\n            .img_src(\"'self'\", \"data:\")\n        )\n\n        secure_headers = secure.Secure(\n            server=secure.Server().set(\"server\"),\n            cache=secure.CacheControl().must_revalidate(),\n            csp=csp,\n            referrer=secure.ReferrerPolicy().no_referrer(),\n        )\n\n        cherrypy.config.update({\n            \"tools.response_headers.on\": True,\n            \"tools.response_headers.headers\": secure_headers.framework.cherrypy()\n        })\n\n    def error_page(self: 'SpiderFootWebUi') -> None:\n        \"\"\"Error page.\"\"\"\n        cherrypy.response.status = 500\n\n        if self.config.get('_debug'):\n            cherrypy.response.body = _cperror.get_error_page(status=500, traceback=_cperror.format_exc())\n        else:\n            cherrypy.response.body = b\"<html><body>Error</body></html>\"\n\n    def error_page_401(self: 'SpiderFootWebUi', status: str, message: str, traceback: str, version: str) -> str:\n        \"\"\"Unauthorized access HTTP 401 error page.\n\n        Args:\n            status (str): HTTP response status code and message\n            message (str): Error message\n            traceback (str): Error stack trace\n            version (str): CherryPy version\n\n        Returns:\n            str: HTML response\n        \"\"\"\n        return \"\"\n\n    def error_page_404(self: 'SpiderFootWebUi', status: str, message: str, traceback: str, version: str) -> str:\n        \"\"\"Not found error page 404.\n\n        Args:\n            status (str): HTTP response status code and message\n            message (str): Error message\n            traceback (str): Error stack trace\n            version (str): CherryPy version\n\n        Returns:\n            str: HTTP response template\n        \"\"\"\n        templ = Template(filename='spiderfoot/templates/error.tmpl', lookup=self.lookup)\n        return templ.render(message='Not Found', docroot=self.docroot, status=status, version=__version__)\n\n    def jsonify_error(self: 'SpiderFootWebUi', status: str, message: str) -> dict:\n        \"\"\"Jsonify error response.\n\n        Args:\n            status (str): HTTP response status code and message\n            message (str): Error message\n\n        Returns:\n            dict: HTTP error response template\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = 'application/json'\n        cherrypy.response.status = status\n        return {\n            'error': {\n                'http_status': status,\n                'message': message,\n            }\n        }\n\n    def error(self: 'SpiderFootWebUi', message: str) -> None:\n        \"\"\"Show generic error page with error message.\n\n        Args:\n            message (str): error message\n\n        Returns:\n            None\n        \"\"\"\n        templ = Template(filename='spiderfoot/templates/error.tmpl', lookup=self.lookup)\n        return templ.render(message=message, docroot=self.docroot, version=__version__)\n\n    def cleanUserInput(self: 'SpiderFootWebUi', inputList: list) -> list:\n        \"\"\"Convert data to HTML entities; except quotes and ampersands.\n\n        Args:\n            inputList (list): list of strings to sanitize\n\n        Returns:\n            list: sanitized input\n\n        Raises:\n            TypeError: inputList type was invalid\n\n        Todo:\n            Review all uses of this function, then remove it.\n            Use of this function is overloaded.\n        \"\"\"\n        if not isinstance(inputList, list):\n            raise TypeError(f\"inputList is {type(inputList)}; expected list()\")\n\n        ret = list()\n\n        for item in inputList:\n            if not item:\n                ret.append('')\n                continue\n            c = html.escape(item, True)\n\n            # Decode '&' and '\"' HTML entities\n            c = c.replace(\"&amp;\", \"&\").replace(\"&quot;\", \"\\\"\")\n            ret.append(c)\n\n        return ret\n\n    def searchBase(self: 'SpiderFootWebUi', id: str = None, eventType: str = None, value: str = None) -> list:\n        \"\"\"Search.\n\n        Args:\n            id (str): scan ID\n            eventType (str): TBD\n            value (str): TBD\n\n        Returns:\n            list: search results\n        \"\"\"\n        retdata = []\n\n        if not id and not eventType and not value:\n            return retdata\n\n        if not value:\n            value = ''\n\n        regex = \"\"\n        if value.startswith(\"/\") and value.endswith(\"/\"):\n            regex = value[1:len(value) - 1]\n            value = \"\"\n\n        value = value.replace('*', '%')\n        if value in [None, \"\"] and regex in [None, \"\"]:\n            value = \"%\"\n            regex = \"\"\n\n        dbh = SpiderFootDb(self.config)\n        criteria = {\n            'scan_id': id or '',\n            'type': eventType or '',\n            'value': value or '',\n            'regex': regex or '',\n        }\n\n        try:\n            data = dbh.search(criteria)\n        except Exception:\n            return retdata\n\n        for row in data:\n            lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n            escapeddata = html.escape(row[1])\n            escapedsrc = html.escape(row[2])\n            retdata.append([lastseen, escapeddata, escapedsrc,\n                            row[3], row[5], row[6], row[7], row[8], row[10],\n                            row[11], row[4], row[13], row[14]])\n\n        return retdata\n\n    def buildExcel(self: 'SpiderFootWebUi', data: list, columnNames: list, sheetNameIndex: int = 0) -> str:\n        \"\"\"Convert supplied raw data into GEXF (Graph Exchange XML Format) format (e.g. for Gephi).\n\n        Args:\n            data (list): Scan result as list\n            columnNames (list): column names\n            sheetNameIndex (int): TBD\n\n        Returns:\n            str: Excel workbook\n        \"\"\"\n        rowNums = dict()\n        workbook = openpyxl.Workbook()\n        defaultSheet = workbook.active\n        columnNames.pop(sheetNameIndex)\n        allowed_sheet_chars = string.ascii_uppercase + string.digits + '_'\n        for row in data:\n            sheetName = \"\".join([c for c in str(row.pop(sheetNameIndex)) if c.upper() in allowed_sheet_chars])\n            try:\n                sheet = workbook[sheetName]\n            except KeyError:\n                # Create sheet\n                workbook.create_sheet(sheetName)\n                sheet = workbook[sheetName]\n                # Write headers\n                for col_num, column_title in enumerate(columnNames, 1):\n                    cell = sheet.cell(row=1, column=col_num)\n                    cell.value = column_title\n                rowNums[sheetName] = 2\n\n            # Write row\n            for col_num, cell_value in enumerate(row, 1):\n                cell = sheet.cell(row=rowNums[sheetName], column=col_num)\n                cell.value = cell_value\n\n            rowNums[sheetName] += 1\n\n        if rowNums:\n            workbook.remove(defaultSheet)\n\n        # Sort sheets alphabetically\n        workbook._sheets.sort(key=lambda ws: ws.title)\n\n        # Save workbook\n        with BytesIO() as f:\n            workbook.save(f)\n            f.seek(0)\n            return f.read()\n\n    #\n    # USER INTERFACE PAGES\n    #\n\n    @cherrypy.expose\n    def scanexportlogs(self: 'SpiderFootWebUi', id: str, dialect: str = \"excel\") -> bytes:\n        \"\"\"Get scan log\n\n        Args:\n            id (str): scan ID\n            dialect (str): CSV dialect (default: excel)\n\n        Returns:\n            bytes: scan logs in CSV format\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n\n        try:\n            data = dbh.scanLogs(id, None, None, True)\n        except Exception:\n            return self.error(\"Scan ID not found.\")\n\n        if not data:\n            return self.error(\"Scan ID not found.\")\n\n        fileobj = StringIO()\n        parser = csv.writer(fileobj, dialect=dialect)\n        parser.writerow([\"Date\", \"Component\", \"Type\", \"Event\", \"Event ID\"])\n        for row in data:\n            parser.writerow([\n                time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0] / 1000)),\n                str(row[1]),\n                str(row[2]),\n                str(row[3]),\n                row[4]\n            ])\n\n        cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename=SpiderFoot-{id}.log.csv\"\n        cherrypy.response.headers['Content-Type'] = \"application/csv\"\n        cherrypy.response.headers['Pragma'] = \"no-cache\"\n        return fileobj.getvalue().encode('utf-8')\n\n    @cherrypy.expose\n    def scancorrelationsexport(self: 'SpiderFootWebUi', id: str, filetype: str = \"csv\", dialect: str = \"excel\") -> str:\n        \"\"\"Get scan correlation data in CSV or Excel format.\n\n        Args:\n            id (str): scan ID\n            filetype (str): type of file (\"xlsx|excel\" or \"csv\")\n            dialect (str): CSV dialect (default: excel)\n\n        Returns:\n            str: results in CSV or Excel format\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n\n        try:\n            scaninfo = dbh.scanInstanceGet(id)\n            scan_name = scaninfo[0]\n        except Exception:\n            return json.dumps([\"ERROR\", \"Could not retrieve info for scan.\"]).encode('utf-8')\n\n        try:\n            correlations = dbh.scanCorrelationList(id)\n        except Exception:\n            return json.dumps([\"ERROR\", \"Could not retrieve correlations for scan.\"]).encode('utf-8')\n\n        headings = [\"Rule Name\", \"Correlation\", \"Risk\", \"Description\"]\n\n        if filetype.lower() in [\"xlsx\", \"excel\"]:\n            rows = []\n            for row in correlations:\n                correlation = row[1]\n                rule_name = row[2]\n                rule_risk = row[3]\n                rule_description = row[5]\n                rows.append([rule_name, correlation, rule_risk, rule_description])\n\n            if scan_name:\n                fname = f\"{scan_name}-SpiderFoot-correlations.xlxs\"\n            else:\n                fname = \"SpiderFoot-correlations.xlxs\"\n\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return self.buildExcel(rows, headings, sheetNameIndex=0)\n\n        if filetype.lower() == 'csv':\n            fileobj = StringIO()\n            parser = csv.writer(fileobj, dialect=dialect)\n            parser.writerow(headings)\n\n            for row in correlations:\n                correlation = row[1]\n                rule_name = row[2]\n                rule_risk = row[3]\n                rule_description = row[5]\n                parser.writerow([rule_name, correlation, rule_risk, rule_description])\n\n            if scan_name:\n                fname = f\"{scan_name}-SpiderFoot-correlations.csv\"\n            else:\n                fname = \"SpiderFoot-correlations.csv\"\n\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/csv\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return fileobj.getvalue().encode('utf-8')\n\n        return self.error(\"Invalid export filetype.\")\n\n    @cherrypy.expose\n    def scaneventresultexport(self: 'SpiderFootWebUi', id: str, type: str, filetype: str = \"csv\", dialect: str = \"excel\") -> str:\n        \"\"\"Get scan event result data in CSV or Excel format\n\n        Args:\n            id (str): scan ID\n            type (str): TBD\n            filetype (str): type of file (\"xlsx|excel\" or \"csv\")\n            dialect (str): CSV dialect (default: excel)\n\n        Returns:\n            str: results in CSV or Excel format\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        data = dbh.scanResultEvent(id, type)\n\n        if filetype.lower() in [\"xlsx\", \"excel\"]:\n            rows = []\n            for row in data:\n                if row[4] == \"ROOT\":\n                    continue\n                lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                rows.append([lastseen, str(row[4]), str(row[3]), str(row[2]), row[13], datafield])\n\n            fname = \"SpiderFoot.xlsx\"\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return self.buildExcel(rows, [\"Updated\", \"Type\", \"Module\", \"Source\",\n                                   \"F/P\", \"Data\"], sheetNameIndex=1)\n\n        if filetype.lower() == 'csv':\n            fileobj = StringIO()\n            parser = csv.writer(fileobj, dialect=dialect)\n            parser.writerow([\"Updated\", \"Type\", \"Module\", \"Source\", \"F/P\", \"Data\"])\n            for row in data:\n                if row[4] == \"ROOT\":\n                    continue\n                lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                parser.writerow([lastseen, str(row[4]), str(row[3]), str(row[2]), row[13], datafield])\n\n            fname = \"SpiderFoot.csv\"\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/csv\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return fileobj.getvalue().encode('utf-8')\n\n        return self.error(\"Invalid export filetype.\")\n\n    @cherrypy.expose\n    def scaneventresultexportmulti(self: 'SpiderFootWebUi', ids: str, filetype: str = \"csv\", dialect: str = \"excel\") -> str:\n        \"\"\"Get scan event result data in CSV or Excel format for multiple scans\n\n        Args:\n            ids (str): comma separated list of scan IDs\n            filetype (str): type of file (\"xlsx|excel\" or \"csv\")\n            dialect (str): CSV dialect (default: excel)\n\n        Returns:\n            str: results in CSV or Excel format\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        scaninfo = dict()\n        data = list()\n        scan_name = \"\"\n\n        for id in ids.split(','):\n            scaninfo[id] = dbh.scanInstanceGet(id)\n            if scaninfo[id] is None:\n                continue\n            scan_name = scaninfo[id][0]\n            data = data + dbh.scanResultEvent(id)\n\n        if not data:\n            return None\n\n        if filetype.lower() in [\"xlsx\", \"excel\"]:\n            rows = []\n            for row in data:\n                if row[4] == \"ROOT\":\n                    continue\n                lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                rows.append([scaninfo[row[12]][0], lastseen, str(row[4]), str(row[3]),\n                            str(row[2]), row[13], datafield])\n\n            if len(ids.split(',')) > 1 or scan_name == \"\":\n                fname = \"SpiderFoot.xlsx\"\n            else:\n                fname = scan_name + \"-SpiderFoot.xlsx\"\n\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return self.buildExcel(rows, [\"Scan Name\", \"Updated\", \"Type\", \"Module\",\n                                   \"Source\", \"F/P\", \"Data\"], sheetNameIndex=2)\n\n        if filetype.lower() == 'csv':\n            fileobj = StringIO()\n            parser = csv.writer(fileobj, dialect=dialect)\n            parser.writerow([\"Scan Name\", \"Updated\", \"Type\", \"Module\", \"Source\", \"F/P\", \"Data\"])\n            for row in data:\n                if row[4] == \"ROOT\":\n                    continue\n                lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                parser.writerow([scaninfo[row[12]][0], lastseen, str(row[4]), str(row[3]),\n                                str(row[2]), row[13], datafield])\n\n            if len(ids.split(',')) > 1 or scan_name == \"\":\n                fname = \"SpiderFoot.csv\"\n            else:\n                fname = scan_name + \"-SpiderFoot.csv\"\n\n            cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n            cherrypy.response.headers['Content-Type'] = \"application/csv\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return fileobj.getvalue().encode('utf-8')\n\n        return self.error(\"Invalid export filetype.\")\n\n    @cherrypy.expose\n    def scansearchresultexport(self: 'SpiderFootWebUi', id: str, eventType: str = None, value: str = None, filetype: str = \"csv\", dialect: str = \"excel\") -> str:\n        \"\"\"Get search result data in CSV or Excel format\n\n        Args:\n            id (str): scan ID\n            eventType (str): TBD\n            value (str): TBD\n            filetype (str): type of file (\"xlsx|excel\" or \"csv\")\n            dialect (str): CSV dialect (default: excel)\n\n        Returns:\n            str: results in CSV or Excel format\n        \"\"\"\n        data = self.searchBase(id, eventType, value)\n\n        if not data:\n            return None\n\n        if filetype.lower() in [\"xlsx\", \"excel\"]:\n            rows = []\n            for row in data:\n                if row[10] == \"ROOT\":\n                    continue\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                rows.append([row[0], str(row[10]), str(row[3]), str(row[2]), row[11], datafield])\n            cherrypy.response.headers['Content-Disposition'] = \"attachment; filename=SpiderFoot.xlsx\"\n            cherrypy.response.headers['Content-Type'] = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return self.buildExcel(rows, [\"Updated\", \"Type\", \"Module\", \"Source\",\n                                   \"F/P\", \"Data\"], sheetNameIndex=1)\n\n        if filetype.lower() == 'csv':\n            fileobj = StringIO()\n            parser = csv.writer(fileobj, dialect=dialect)\n            parser.writerow([\"Updated\", \"Type\", \"Module\", \"Source\", \"F/P\", \"Data\"])\n            for row in data:\n                if row[10] == \"ROOT\":\n                    continue\n                datafield = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                parser.writerow([row[0], str(row[10]), str(row[3]), str(row[2]), row[11], datafield])\n            cherrypy.response.headers['Content-Disposition'] = \"attachment; filename=SpiderFoot.csv\"\n            cherrypy.response.headers['Content-Type'] = \"application/csv\"\n            cherrypy.response.headers['Pragma'] = \"no-cache\"\n            return fileobj.getvalue().encode('utf-8')\n\n        return self.error(\"Invalid export filetype.\")\n\n    @cherrypy.expose\n    def scanexportjsonmulti(self: 'SpiderFootWebUi', ids: str) -> str:\n        \"\"\"Get scan event result data in JSON format for multiple scans.\n\n        Args:\n            ids (str): comma separated list of scan IDs\n\n        Returns:\n            str: results in JSON format\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        scaninfo = list()\n        scan_name = \"\"\n\n        for id in ids.split(','):\n            scan = dbh.scanInstanceGet(id)\n\n            if scan is None:\n                continue\n\n            scan_name = scan[0]\n\n            for row in dbh.scanResultEvent(id):\n                lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n                event_data = str(row[1]).replace(\"<SFURL>\", \"\").replace(\"</SFURL>\", \"\")\n                source_data = str(row[2])\n                source_module = str(row[3])\n                event_type = row[4]\n                false_positive = row[13]\n\n                if event_type == \"ROOT\":\n                    continue\n\n                scaninfo.append({\n                    \"data\": event_data,\n                    \"event_type\": event_type,\n                    \"module\": source_module,\n                    \"source_data\": source_data,\n                    \"false_positive\": false_positive,\n                    \"last_seen\": lastseen,\n                    \"scan_name\": scan_name,\n                    \"scan_target\": scan[1]\n                })\n\n        if len(ids.split(',')) > 1 or scan_name == \"\":\n            fname = \"SpiderFoot.json\"\n        else:\n            fname = scan_name + \"-SpiderFoot.json\"\n\n        cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n        cherrypy.response.headers['Pragma'] = \"no-cache\"\n        return json.dumps(scaninfo).encode('utf-8')\n\n    @cherrypy.expose\n    def scanviz(self: 'SpiderFootWebUi', id: str, gexf: str = \"0\") -> str:\n        \"\"\"Export entities from scan results for visualising.\n\n        Args:\n            id (str): scan ID\n            gexf (str): TBD\n\n        Returns:\n            str: GEXF data\n        \"\"\"\n        if not id:\n            return None\n\n        dbh = SpiderFootDb(self.config)\n        data = dbh.scanResultEvent(id, filterFp=True)\n        scan = dbh.scanInstanceGet(id)\n\n        if not scan:\n            return None\n\n        scan_name = scan[0]\n\n        root = scan[1]\n\n        if gexf == \"0\":\n            return SpiderFootHelpers.buildGraphJson([root], data)\n\n        if not scan_name:\n            fname = \"SpiderFoot.gexf\"\n        else:\n            fname = scan_name + \"SpiderFoot.gexf\"\n\n        cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n        cherrypy.response.headers['Content-Type'] = \"application/gexf\"\n        cherrypy.response.headers['Pragma'] = \"no-cache\"\n        return SpiderFootHelpers.buildGraphGexf([root], \"SpiderFoot Export\", data)\n\n    @cherrypy.expose\n    def scanvizmulti(self: 'SpiderFootWebUi', ids: str, gexf: str = \"1\") -> str:\n        \"\"\"Export entities results from multiple scans in GEXF format.\n\n        Args:\n            ids (str): scan IDs\n            gexf (str): TBD\n\n        Returns:\n            str: GEXF data\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        data = list()\n        roots = list()\n        scan_name = \"\"\n\n        if not ids:\n            return None\n\n        for id in ids.split(','):\n            scan = dbh.scanInstanceGet(id)\n            if not scan:\n                continue\n            data = data + dbh.scanResultEvent(id, filterFp=True)\n            roots.append(scan[1])\n            scan_name = scan[0]\n\n        if not data:\n            return None\n\n        if gexf == \"0\":\n            # Not implemented yet\n            return None\n\n        if len(ids.split(',')) > 1 or scan_name == \"\":\n            fname = \"SpiderFoot.gexf\"\n        else:\n            fname = scan_name + \"-SpiderFoot.gexf\"\n\n        cherrypy.response.headers['Content-Disposition'] = f\"attachment; filename={fname}\"\n        cherrypy.response.headers['Content-Type'] = \"application/gexf\"\n        cherrypy.response.headers['Pragma'] = \"no-cache\"\n        return SpiderFootHelpers.buildGraphGexf(roots, \"SpiderFoot Export\", data)\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanopts(self: 'SpiderFootWebUi', id: str) -> dict:\n        \"\"\"Return configuration used for the specified scan as JSON.\n\n        Args:\n            id: scan ID\n\n        Returns:\n            dict: scan options for the specified scan\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        ret = dict()\n\n        meta = dbh.scanInstanceGet(id)\n        if not meta:\n            return ret\n\n        if meta[3] != 0:\n            started = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(meta[3]))\n        else:\n            started = \"Not yet\"\n\n        if meta[4] != 0:\n            finished = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(meta[4]))\n        else:\n            finished = \"Not yet\"\n\n        ret['meta'] = [meta[0], meta[1], meta[2], started, finished, meta[5]]\n        ret['config'] = dbh.scanConfigGet(id)\n        ret['configdesc'] = dict()\n        for key in list(ret['config'].keys()):\n            if ':' not in key:\n                globaloptdescs = self.config['__globaloptdescs__']\n                if globaloptdescs:\n                    ret['configdesc'][key] = globaloptdescs.get(key, f\"{key} (legacy)\")\n            else:\n                [modName, modOpt] = key.split(':')\n                if modName not in list(self.config['__modules__'].keys()):\n                    continue\n\n                if modOpt not in list(self.config['__modules__'][modName]['optdescs'].keys()):\n                    continue\n\n                ret['configdesc'][key] = self.config['__modules__'][modName]['optdescs'][modOpt]\n\n        return ret\n\n    @cherrypy.expose\n    def rerunscan(self: 'SpiderFootWebUi', id: str) -> None:\n        \"\"\"Rerun a scan.\n\n        Args:\n            id (str): scan ID\n\n        Returns:\n            None\n\n        Raises:\n            HTTPRedirect: redirect to info page for new scan\n        \"\"\"\n        # Snapshot the current configuration to be used by the scan\n        cfg = deepcopy(self.config)\n        modlist = list()\n        dbh = SpiderFootDb(cfg)\n        info = dbh.scanInstanceGet(id)\n\n        if not info:\n            return self.error(\"Invalid scan ID.\")\n\n        scanname = info[0]\n        scantarget = info[1]\n\n        scanconfig = dbh.scanConfigGet(id)\n        if not scanconfig:\n            return self.error(f\"Error loading config from scan: {id}\")\n\n        modlist = scanconfig['_modulesenabled'].split(',')\n        if \"sfp__stor_stdout\" in modlist:\n            modlist.remove(\"sfp__stor_stdout\")\n\n        targetType = SpiderFootHelpers.targetTypeFromString(scantarget)\n        if not targetType:\n            # It must then be a name, as a re-run scan should always have a clean\n            # target. Put quotes around the target value and try to determine the\n            # target type again.\n            targetType = SpiderFootHelpers.targetTypeFromString(f'\"{scantarget}\"')\n\n        if targetType not in [\"HUMAN_NAME\", \"BITCOIN_ADDRESS\"]:\n            scantarget = scantarget.lower()\n\n        # Start running a new scan\n        scanId = SpiderFootHelpers.genScanInstanceId()\n        try:\n            p = mp.Process(target=startSpiderFootScanner, args=(self.loggingQueue, scanname, scanId, scantarget, targetType, modlist, cfg))\n            p.daemon = True\n            p.start()\n        except Exception as e:\n            self.log.error(f\"[-] Scan [{scanId}] failed: {e}\")\n            return self.error(f\"[-] Scan [{scanId}] failed: {e}\")\n\n        # Wait until the scan has initialized\n        while dbh.scanInstanceGet(scanId) is None:\n            self.log.info(\"Waiting for the scan to initialize...\")\n            time.sleep(1)\n\n        raise cherrypy.HTTPRedirect(f\"{self.docroot}/scaninfo?id={scanId}\", status=302)\n\n    @cherrypy.expose\n    def rerunscanmulti(self: 'SpiderFootWebUi', ids: str) -> str:\n        \"\"\"Rerun scans.\n\n        Args:\n            ids (str): comma separated list of scan IDs\n\n        Returns:\n            str: Scan list page HTML\n        \"\"\"\n        # Snapshot the current configuration to be used by the scan\n        cfg = deepcopy(self.config)\n        modlist = list()\n        dbh = SpiderFootDb(cfg)\n\n        for id in ids.split(\",\"):\n            info = dbh.scanInstanceGet(id)\n            if not info:\n                return self.error(\"Invalid scan ID.\")\n\n            scanconfig = dbh.scanConfigGet(id)\n            scanname = info[0]\n            scantarget = info[1]\n            targetType = None\n\n            if len(scanconfig) == 0:\n                return self.error(\"Something went wrong internally.\")\n\n            modlist = scanconfig['_modulesenabled'].split(',')\n            if \"sfp__stor_stdout\" in modlist:\n                modlist.remove(\"sfp__stor_stdout\")\n\n            targetType = SpiderFootHelpers.targetTypeFromString(scantarget)\n            if targetType is None:\n                # Should never be triggered for a re-run scan..\n                return self.error(\"Invalid target type. Could not recognize it as a target SpiderFoot supports.\")\n\n            # Start running a new scan\n            scanId = SpiderFootHelpers.genScanInstanceId()\n            try:\n                p = mp.Process(target=startSpiderFootScanner, args=(self.loggingQueue, scanname, scanId, scantarget, targetType, modlist, cfg))\n                p.daemon = True\n                p.start()\n            except Exception as e:\n                self.log.error(f\"[-] Scan [{scanId}] failed: {e}\")\n                return self.error(f\"[-] Scan [{scanId}] failed: {e}\")\n\n            # Wait until the scan has initialized\n            while dbh.scanInstanceGet(scanId) is None:\n                self.log.info(\"Waiting for the scan to initialize...\")\n                time.sleep(1)\n\n        templ = Template(filename='spiderfoot/templates/scanlist.tmpl', lookup=self.lookup)\n        return templ.render(rerunscans=True, docroot=self.docroot, pageid=\"SCANLIST\", version=__version__)\n\n    @cherrypy.expose\n    def newscan(self: 'SpiderFootWebUi') -> str:\n        \"\"\"Configure a new scan.\n\n        Returns:\n            str: New scan page HTML\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        types = dbh.eventTypes()\n        templ = Template(filename='spiderfoot/templates/newscan.tmpl', lookup=self.lookup)\n        return templ.render(pageid='NEWSCAN', types=types, docroot=self.docroot,\n                            modules=self.config['__modules__'], scanname=\"\",\n                            selectedmods=\"\", scantarget=\"\", version=__version__)\n\n    @cherrypy.expose\n    def clonescan(self: 'SpiderFootWebUi', id: str) -> str:\n        \"\"\"Clone an existing scan (pre-selected options in the newscan page).\n\n        Args:\n            id (str): scan ID to clone\n\n        Returns:\n            str: New scan page HTML pre-populated with options from cloned scan.\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        types = dbh.eventTypes()\n        info = dbh.scanInstanceGet(id)\n\n        if not info:\n            return self.error(\"Invalid scan ID.\")\n\n        scanconfig = dbh.scanConfigGet(id)\n        scanname = info[0]\n        scantarget = info[1]\n        targetType = None\n\n        if scanname == \"\" or scantarget == \"\" or len(scanconfig) == 0:\n            return self.error(\"Something went wrong internally.\")\n\n        targetType = SpiderFootHelpers.targetTypeFromString(scantarget)\n        if targetType is None:\n            # It must be a name, so wrap quotes around it\n            scantarget = \"&quot;\" + scantarget + \"&quot;\"\n\n        modlist = scanconfig['_modulesenabled'].split(',')\n\n        templ = Template(filename='spiderfoot/templates/newscan.tmpl', lookup=self.lookup)\n        return templ.render(pageid='NEWSCAN', types=types, docroot=self.docroot,\n                            modules=self.config['__modules__'], selectedmods=modlist,\n                            scanname=str(scanname),\n                            scantarget=str(scantarget), version=__version__)\n\n    @cherrypy.expose\n    def index(self: 'SpiderFootWebUi') -> str:\n        \"\"\"Show scan list page.\n\n        Returns:\n            str: Scan list page HTML\n        \"\"\"\n        templ = Template(filename='spiderfoot/templates/scanlist.tmpl', lookup=self.lookup)\n        return templ.render(pageid='SCANLIST', docroot=self.docroot, version=__version__)\n\n    @cherrypy.expose\n    def scaninfo(self: 'SpiderFootWebUi', id: str) -> str:\n        \"\"\"Information about a selected scan.\n\n        Args:\n            id (str): scan id\n\n        Returns:\n            str: scan info page HTML\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        res = dbh.scanInstanceGet(id)\n        if res is None:\n            return self.error(\"Scan ID not found.\")\n\n        templ = Template(filename='spiderfoot/templates/scaninfo.tmpl', lookup=self.lookup, input_encoding='utf-8')\n        return templ.render(id=id, name=html.escape(res[0]), status=res[5], docroot=self.docroot, version=__version__,\n                            pageid=\"SCANLIST\")\n\n    @cherrypy.expose\n    def opts(self: 'SpiderFootWebUi', updated: str = None) -> str:\n        \"\"\"Show module and global settings page.\n\n        Args:\n            updated (str): scan options were updated successfully\n\n        Returns:\n            str: scan options page HTML\n        \"\"\"\n        templ = Template(filename='spiderfoot/templates/opts.tmpl', lookup=self.lookup)\n        self.token = random.SystemRandom().randint(0, 99999999)\n        return templ.render(opts=self.config, pageid='SETTINGS', token=self.token, version=__version__,\n                            updated=updated, docroot=self.docroot)\n\n    @cherrypy.expose\n    def optsexport(self: 'SpiderFootWebUi', pattern: str = None) -> str:\n        \"\"\"Export configuration.\n\n        Args:\n            pattern (str): TBD\n\n        Returns:\n            str: Configuration settings\n        \"\"\"\n        sf = SpiderFoot(self.config)\n        conf = sf.configSerialize(self.config)\n        content = \"\"\n\n        for opt in sorted(conf):\n            if \":_\" in opt or opt.startswith(\"_\"):\n                continue\n\n            if pattern:\n                if pattern in opt:\n                    content += f\"{opt}={conf[opt]}\\n\"\n            else:\n                content += f\"{opt}={conf[opt]}\\n\"\n\n        cherrypy.response.headers['Content-Disposition'] = 'attachment; filename=\"SpiderFoot.cfg\"'\n        cherrypy.response.headers['Content-Type'] = \"text/plain\"\n        return content\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def optsraw(self: 'SpiderFootWebUi') -> str:\n        \"\"\"Return global and module settings as json.\n\n        Returns:\n            str: settings as JSON\n        \"\"\"\n        ret = dict()\n        self.token = random.SystemRandom().randint(0, 99999999)\n        for opt in self.config:\n            if not opt.startswith('__'):\n                ret[\"global.\" + opt] = self.config[opt]\n                continue\n\n            if opt == '__modules__':\n                for mod in sorted(self.config['__modules__'].keys()):\n                    for mo in sorted(self.config['__modules__'][mod]['opts'].keys()):\n                        if mo.startswith(\"_\"):\n                            continue\n                        ret[\"module.\" + mod + \".\" + mo] = self.config['__modules__'][mod]['opts'][mo]\n\n        return ['SUCCESS', {'token': self.token, 'data': ret}]\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scandelete(self: 'SpiderFootWebUi', id: str) -> str:\n        \"\"\"Delete scan(s).\n\n        Args:\n            id (str): comma separated list of scan IDs\n\n        Returns:\n            str: JSON response\n        \"\"\"\n        if not id:\n            return self.jsonify_error('404', \"No scan specified\")\n\n        dbh = SpiderFootDb(self.config)\n        ids = id.split(',')\n\n        for scan_id in ids:\n            res = dbh.scanInstanceGet(scan_id)\n            if not res:\n                return self.jsonify_error('404', f\"Scan {scan_id} does not exist\")\n\n            if res[5] in [\"RUNNING\", \"STARTING\", \"STARTED\"]:\n                return self.jsonify_error('400', f\"Scan {scan_id} is {res[5]}. You cannot delete running scans.\")\n\n        for scan_id in ids:\n            dbh.scanInstanceDelete(scan_id)\n\n        return \"\"\n\n    @cherrypy.expose\n    def savesettings(self: 'SpiderFootWebUi', allopts: str, token: str, configFile: 'cherrypy._cpreqbody.Part' = None) -> None:\n        \"\"\"Save settings, also used to completely reset them to default.\n\n        Args:\n            allopts: TBD\n            token (str): CSRF token\n            configFile (cherrypy._cpreqbody.Part): TBD\n\n        Returns:\n            None\n\n        Raises:\n            HTTPRedirect: redirect to scan settings\n        \"\"\"\n        if str(token) != str(self.token):\n            return self.error(f\"Invalid token ({token})\")\n\n        # configFile seems to get set even if a file isn't uploaded\n        if configFile and configFile.file:\n            try:\n                contents = configFile.file.read()\n\n                if isinstance(contents, bytes):\n                    contents = contents.decode('utf-8')\n\n                tmp = dict()\n                for line in contents.split(\"\\n\"):\n                    if \"=\" not in line:\n                        continue\n\n                    opt_array = line.strip().split(\"=\")\n                    if len(opt_array) == 1:\n                        opt_array[1] = \"\"\n\n                    tmp[opt_array[0]] = '='.join(opt_array[1:])\n\n                allopts = json.dumps(tmp).encode('utf-8')\n            except Exception as e:\n                return self.error(f\"Failed to parse input file. Was it generated from SpiderFoot? ({e})\")\n\n        # Reset config to default\n        if allopts == \"RESET\":\n            if self.reset_settings():\n                raise cherrypy.HTTPRedirect(f\"{self.docroot}/opts?updated=1\")\n            return self.error(\"Failed to reset settings\")\n\n        # Save settings\n        try:\n            dbh = SpiderFootDb(self.config)\n            useropts = json.loads(allopts)\n            cleanopts = dict()\n            for opt in list(useropts.keys()):\n                cleanopts[opt] = self.cleanUserInput([useropts[opt]])[0]\n\n            currentopts = deepcopy(self.config)\n\n            # Make a new config where the user options override\n            # the current system config.\n            sf = SpiderFoot(self.config)\n            self.config = sf.configUnserialize(cleanopts, currentopts)\n            dbh.configSet(sf.configSerialize(self.config))\n        except Exception as e:\n            return self.error(f\"Processing one or more of your inputs failed: {e}\")\n\n        raise cherrypy.HTTPRedirect(f\"{self.docroot}/opts?updated=1\")\n\n    @cherrypy.expose\n    def savesettingsraw(self: 'SpiderFootWebUi', allopts: str, token: str) -> str:\n        \"\"\"Save settings, also used to completely reset them to default.\n\n        Args:\n            allopts: TBD\n            token (str): CSRF token\n\n        Returns:\n            str: save success as JSON\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n\n        if str(token) != str(self.token):\n            return json.dumps([\"ERROR\", f\"Invalid token ({token}).\"]).encode('utf-8')\n\n        # Reset config to default\n        if allopts == \"RESET\":\n            if self.reset_settings():\n                return json.dumps([\"SUCCESS\", \"\"]).encode('utf-8')\n            return json.dumps([\"ERROR\", \"Failed to reset settings\"]).encode('utf-8')\n\n        # Save settings\n        try:\n            dbh = SpiderFootDb(self.config)\n            useropts = json.loads(allopts)\n            cleanopts = dict()\n            for opt in list(useropts.keys()):\n                cleanopts[opt] = self.cleanUserInput([useropts[opt]])[0]\n\n            currentopts = deepcopy(self.config)\n\n            # Make a new config where the user options override\n            # the current system config.\n            sf = SpiderFoot(self.config)\n            self.config = sf.configUnserialize(cleanopts, currentopts)\n            dbh.configSet(sf.configSerialize(self.config))\n        except Exception as e:\n            return json.dumps([\"ERROR\", f\"Processing one or more of your inputs failed: {e}\"]).encode('utf-8')\n\n        return json.dumps([\"SUCCESS\", \"\"]).encode('utf-8')\n\n    def reset_settings(self: 'SpiderFootWebUi') -> bool:\n        \"\"\"Reset settings to default.\n\n        Returns:\n            bool: success\n        \"\"\"\n        try:\n            dbh = SpiderFootDb(self.config)\n            dbh.configClear()  # Clear it in the DB\n            self.config = deepcopy(self.defaultConfig)  # Clear in memory\n        except Exception:\n            return False\n\n        return True\n\n    @cherrypy.expose\n    def resultsetfp(self: 'SpiderFootWebUi', id: str, resultids: str, fp: str) -> str:\n        \"\"\"Set a bunch of results (hashes) as false positive.\n\n        Args:\n            id (str): scan ID\n            resultids (str): comma separated list of result IDs\n            fp (str): 0 or 1\n\n        Returns:\n            str: set false positive status as JSON\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n\n        dbh = SpiderFootDb(self.config)\n\n        if fp not in [\"0\", \"1\"]:\n            return json.dumps([\"ERROR\", \"No FP flag set or not set correctly.\"]).encode('utf-8')\n\n        try:\n            ids = json.loads(resultids)\n        except Exception:\n            return json.dumps([\"ERROR\", \"No IDs supplied.\"]).encode('utf-8')\n\n        # Cannot set FPs if a scan is not completed\n        status = dbh.scanInstanceGet(id)\n        if not status:\n            return self.error(f\"Invalid scan ID: {id}\")\n\n        if status[5] not in [\"ABORTED\", \"FINISHED\", \"ERROR-FAILED\"]:\n            return json.dumps([\n                \"WARNING\",\n                \"Scan must be in a finished state when setting False Positives.\"\n            ]).encode('utf-8')\n\n        # Make sure the user doesn't set something as non-FP when the\n        # parent is set as an FP.\n        if fp == \"0\":\n            data = dbh.scanElementSourcesDirect(id, ids)\n            for row in data:\n                if str(row[14]) == \"1\":\n                    return json.dumps([\n                        \"WARNING\",\n                        f\"Cannot unset element {id} as False Positive if a parent element is still False Positive.\"\n                    ]).encode('utf-8')\n\n        # Set all the children as FPs too.. it's only logical afterall, right?\n        childs = dbh.scanElementChildrenAll(id, ids)\n        allIds = ids + childs\n\n        ret = dbh.scanResultsUpdateFP(id, allIds, fp)\n        if ret:\n            return json.dumps([\"SUCCESS\", \"\"]).encode('utf-8')\n\n        return json.dumps([\"ERROR\", \"Exception encountered.\"]).encode('utf-8')\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def eventtypes(self: 'SpiderFootWebUi') -> list:\n        \"\"\"List all event types.\n\n        Returns:\n            list: list of event types\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n\n        dbh = SpiderFootDb(self.config)\n        types = dbh.eventTypes()\n        ret = list()\n\n        for r in types:\n            ret.append([r[1], r[0]])\n\n        return sorted(ret, key=itemgetter(0))\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def modules(self: 'SpiderFootWebUi') -> list:\n        \"\"\"List all modules.\n\n        Returns:\n            list: list of modules\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n\n        ret = list()\n\n        modinfo = list(self.config['__modules__'].keys())\n        if not modinfo:\n            return ret\n\n        modinfo.sort()\n\n        for m in modinfo:\n            if \"__\" in m:\n                continue\n            ret.append({'name': m, 'descr': self.config['__modules__'][m]['descr']})\n\n        return ret\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def correlationrules(self: 'SpiderFootWebUi') -> list:\n        \"\"\"List all correlation rules.\n\n        Returns:\n            list: list of correlation rules\n        \"\"\"\n        cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n\n        ret = list()\n\n        rules = self.config['__correlationrules__']\n        if not rules:\n            return ret\n\n        for r in rules:\n            ret.append({\n                'id': r['id'],\n                'name': r['meta']['name'],\n                'descr': r['meta']['description'],\n                'risk': r['meta']['risk'],\n            })\n\n        return ret\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def ping(self: 'SpiderFootWebUi') -> list:\n        \"\"\"For the CLI to test connectivity to this server.\n\n        Returns:\n            list: SpiderFoot version as JSON\n        \"\"\"\n        return [\"SUCCESS\", __version__]\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def query(self: 'SpiderFootWebUi', query: str) -> str:\n        \"\"\"For the CLI to run queries against the database.\n\n        Args:\n            query (str): SQL query\n\n        Returns:\n            str: query results as JSON\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n\n        if not query:\n            return self.jsonify_error('400', \"Invalid query.\")\n\n        if not query.lower().startswith(\"select\"):\n            return self.jsonify_error('400', \"Non-SELECTs are unpredictable and not recommended.\")\n\n        try:\n            ret = dbh.dbh.execute(query)\n            data = ret.fetchall()\n            columnNames = [c[0] for c in dbh.dbh.description]\n            return [dict(zip(columnNames, row)) for row in data]\n        except Exception as e:\n            return self.jsonify_error('500', str(e))\n\n    @cherrypy.expose\n    def startscan(self: 'SpiderFootWebUi', scanname: str, scantarget: str, modulelist: str, typelist: str, usecase: str) -> str:\n        \"\"\"Initiate a scan.\n\n        Args:\n            scanname (str): scan name\n            scantarget (str): scan target\n            modulelist (str): comma separated list of modules to use\n            typelist (str): selected modules based on produced event data types\n            usecase (str): selected module group (passive, investigate, footprint, all)\n\n        Returns:\n            str: start scan status as JSON\n\n        Raises:\n            HTTPRedirect: redirect to new scan info page\n        \"\"\"\n        scanname = self.cleanUserInput([scanname])[0]\n        scantarget = self.cleanUserInput([scantarget])[0]\n\n        if not scanname:\n            if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n                cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n                return json.dumps([\"ERROR\", \"Incorrect usage: scan name was not specified.\"]).encode('utf-8')\n\n            return self.error(\"Invalid request: scan name was not specified.\")\n\n        if not scantarget:\n            if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n                cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n                return json.dumps([\"ERROR\", \"Incorrect usage: scan target was not specified.\"]).encode('utf-8')\n\n            return self.error(\"Invalid request: scan target was not specified.\")\n\n        if not typelist and not modulelist and not usecase:\n            if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n                cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n                return json.dumps([\"ERROR\", \"Incorrect usage: no modules specified for scan.\"]).encode('utf-8')\n\n            return self.error(\"Invalid request: no modules specified for scan.\")\n\n        targetType = SpiderFootHelpers.targetTypeFromString(scantarget)\n        if targetType is None:\n            if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n                cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n                return json.dumps([\"ERROR\", \"Unrecognised target type.\"]).encode('utf-8')\n\n            return self.error(\"Invalid target type. Could not recognize it as a target SpiderFoot supports.\")\n\n        # Swap the globalscantable for the database handler\n        dbh = SpiderFootDb(self.config)\n\n        # Snapshot the current configuration to be used by the scan\n        cfg = deepcopy(self.config)\n        sf = SpiderFoot(cfg)\n\n        modlist = list()\n\n        # User selected modules\n        if modulelist:\n            modlist = modulelist.replace('module_', '').split(',')\n\n        # User selected types\n        if len(modlist) == 0 and typelist:\n            typesx = typelist.replace('type_', '').split(',')\n\n            # 1. Find all modules that produce the requested types\n            modlist = sf.modulesProducing(typesx)\n            newmods = deepcopy(modlist)\n            newmodcpy = deepcopy(newmods)\n\n            # 2. For each type those modules consume, get modules producing\n            while len(newmodcpy) > 0:\n                for etype in sf.eventsToModules(newmodcpy):\n                    xmods = sf.modulesProducing([etype])\n                    for mod in xmods:\n                        if mod not in modlist:\n                            modlist.append(mod)\n                            newmods.append(mod)\n                newmodcpy = deepcopy(newmods)\n                newmods = list()\n\n        # User selected a use case\n        if len(modlist) == 0 and usecase:\n            for mod in self.config['__modules__']:\n                if usecase == 'all' or usecase in self.config['__modules__'][mod]['group']:\n                    modlist.append(mod)\n\n        # If we somehow got all the way through to here and still don't have any modules selected\n        if not modlist:\n            if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n                cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n                return json.dumps([\"ERROR\", \"Incorrect usage: no modules specified for scan.\"]).encode('utf-8')\n\n            return self.error(\"Invalid request: no modules specified for scan.\")\n\n        # Add our mandatory storage module\n        if \"sfp__stor_db\" not in modlist:\n            modlist.append(\"sfp__stor_db\")\n        modlist.sort()\n\n        # Delete the stdout module in case it crept in\n        if \"sfp__stor_stdout\" in modlist:\n            modlist.remove(\"sfp__stor_stdout\")\n\n        # Start running a new scan\n        if targetType in [\"HUMAN_NAME\", \"USERNAME\", \"BITCOIN_ADDRESS\"]:\n            scantarget = scantarget.replace(\"\\\"\", \"\")\n        else:\n            scantarget = scantarget.lower()\n\n        # Start running a new scan\n        scanId = SpiderFootHelpers.genScanInstanceId()\n        try:\n            p = mp.Process(target=startSpiderFootScanner, args=(self.loggingQueue, scanname, scanId, scantarget, targetType, modlist, cfg))\n            p.daemon = True\n            p.start()\n        except Exception as e:\n            self.log.error(f\"[-] Scan [{scanId}] failed: {e}\")\n            return self.error(f\"[-] Scan [{scanId}] failed: {e}\")\n\n        # Wait until the scan has initialized\n        # Check the database for the scan status results\n        while dbh.scanInstanceGet(scanId) is None:\n            self.log.info(\"Waiting for the scan to initialize...\")\n            time.sleep(1)\n\n        if cherrypy.request.headers.get('Accept') and 'application/json' in cherrypy.request.headers.get('Accept'):\n            cherrypy.response.headers['Content-Type'] = \"application/json; charset=utf-8\"\n            return json.dumps([\"SUCCESS\", scanId]).encode('utf-8')\n\n        raise cherrypy.HTTPRedirect(f\"{self.docroot}/scaninfo?id={scanId}\")\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def stopscan(self: 'SpiderFootWebUi', id: str) -> str:\n        \"\"\"Stop a scan.\n\n        Args:\n            id (str): comma separated list of scan IDs\n\n        Returns:\n            str: JSON response\n        \"\"\"\n        if not id:\n            return self.jsonify_error('404', \"No scan specified\")\n\n        dbh = SpiderFootDb(self.config)\n        ids = id.split(',')\n\n        for scan_id in ids:\n            res = dbh.scanInstanceGet(scan_id)\n            if not res:\n                return self.jsonify_error('404', f\"Scan {scan_id} does not exist\")\n\n            scan_status = res[5]\n\n            if scan_status == \"FINISHED\":\n                return self.jsonify_error('400', f\"Scan {scan_id} has already finished.\")\n\n            if scan_status == \"ABORTED\":\n                return self.jsonify_error('400', f\"Scan {scan_id} has already aborted.\")\n\n            if scan_status != \"RUNNING\" and scan_status != \"STARTING\":\n                return self.jsonify_error('400', f\"The running scan is currently in the state '{scan_status}', please try again later or restart SpiderFoot.\")\n\n        for scan_id in ids:\n            dbh.scanInstanceSet(scan_id, status=\"ABORT-REQUESTED\")\n\n        return \"\"\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def vacuum(self):\n        dbh = SpiderFootDb(self.config)\n        try:\n            if dbh.vacuumDB():\n                return json.dumps([\"SUCCESS\", \"\"]).encode('utf-8')\n            return json.dumps([\"ERROR\", \"Vacuuming the database failed\"]).encode('utf-8')\n        except Exception as e:\n            return json.dumps([\"ERROR\", f\"Vacuuming the database failed: {e}\"]).encode('utf-8')\n\n    #\n    # DATA PROVIDERS\n    #\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanlog(self: 'SpiderFootWebUi', id: str, limit: str = None, rowId: str = None, reverse: str = None) -> list:\n        \"\"\"Scan log data.\n\n        Args:\n            id (str): scan ID\n            limit (str): TBD\n            rowId (str): TBD\n            reverse (str): TBD\n\n        Returns:\n            list: scan log\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        retdata = []\n\n        try:\n            data = dbh.scanLogs(id, limit, rowId, reverse)\n        except Exception:\n            return retdata\n\n        for row in data:\n            generated = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0] / 1000))\n            retdata.append([generated, row[1], row[2], html.escape(row[3]), row[4]])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanerrors(self: 'SpiderFootWebUi', id: str, limit: str = None) -> list:\n        \"\"\"Scan error data.\n\n        Args:\n            id (str): scan ID\n            limit (str): limit number of results\n\n        Returns:\n            list: scan errors\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        retdata = []\n\n        try:\n            data = dbh.scanErrors(id, limit)\n        except Exception:\n            return retdata\n\n        for row in data:\n            generated = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0] / 1000))\n            retdata.append([generated, row[1], html.escape(str(row[2]))])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanlist(self: 'SpiderFootWebUi') -> list:\n        \"\"\"Produce a list of scans.\n\n        Returns:\n            list: scan list\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        data = dbh.scanInstanceList()\n        retdata = []\n\n        for row in data:\n            created = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[3]))\n            riskmatrix = {\n                \"HIGH\": 0,\n                \"MEDIUM\": 0,\n                \"LOW\": 0,\n                \"INFO\": 0\n            }\n            correlations = dbh.scanCorrelationSummary(row[0], by=\"risk\")\n            if correlations:\n                for c in correlations:\n                    riskmatrix[c[0]] = c[1]\n\n            if row[4] == 0:\n                started = \"Not yet\"\n            else:\n                started = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[4]))\n\n            if row[5] == 0:\n                finished = \"Not yet\"\n            else:\n                finished = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[5]))\n\n            retdata.append([row[0], row[1], row[2], created, started, finished, row[6], row[7], riskmatrix])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanstatus(self: 'SpiderFootWebUi', id: str) -> list:\n        \"\"\"Show basic information about a scan, including status and number of each event type.\n\n        Args:\n            id (str): scan ID\n\n        Returns:\n            list: scan status\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        data = dbh.scanInstanceGet(id)\n\n        if not data:\n            return []\n\n        created = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(data[2]))\n        started = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(data[3]))\n        ended = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(data[4]))\n        riskmatrix = {\n            \"HIGH\": 0,\n            \"MEDIUM\": 0,\n            \"LOW\": 0,\n            \"INFO\": 0\n        }\n        correlations = dbh.scanCorrelationSummary(id, by=\"risk\")\n        if correlations:\n            for c in correlations:\n                riskmatrix[c[0]] = c[1]\n\n        return [data[0], data[1], created, started, ended, data[5], riskmatrix]\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scansummary(self: 'SpiderFootWebUi', id: str, by: str) -> list:\n        \"\"\"Summary of scan results.\n\n        Args:\n            id (str): scan ID\n            by (str): filter by type\n\n        Returns:\n            list: scan summary\n        \"\"\"\n        retdata = []\n\n        dbh = SpiderFootDb(self.config)\n\n        try:\n            scandata = dbh.scanResultSummary(id, by)\n        except Exception:\n            return retdata\n\n        try:\n            statusdata = dbh.scanInstanceGet(id)\n        except Exception:\n            return retdata\n\n        for row in scandata:\n            if row[0] == \"ROOT\":\n                continue\n            lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[2]))\n            retdata.append([row[0], row[1], lastseen, row[3], row[4], statusdata[5]])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scancorrelations(self: 'SpiderFootWebUi', id: str) -> list:\n        \"\"\"Correlation results from a scan.\n\n        Args:\n            id (str): scan ID\n\n        Returns:\n            list: correlation result list\n        \"\"\"\n        retdata = []\n\n        dbh = SpiderFootDb(self.config)\n\n        try:\n            corrdata = dbh.scanCorrelationList(id)\n        except Exception:\n            return retdata\n\n        for row in corrdata:\n            retdata.append([row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7]])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scaneventresults(self: 'SpiderFootWebUi', id: str, eventType: str = None, filterfp: bool = False, correlationId: str = None) -> list:\n        \"\"\"Return all event results for a scan as JSON.\n\n        Args:\n            id (str): scan ID\n            eventType (str): filter by event type\n            filterfp (bool): remove false positives from search results\n            correlationId (str): filter by events associated with a correlation\n\n        Returns:\n            list: scan results\n        \"\"\"\n        retdata = []\n\n        dbh = SpiderFootDb(self.config)\n\n        if not eventType:\n            eventType = 'ALL'\n\n        try:\n            data = dbh.scanResultEvent(id, eventType, filterfp, correlationId=correlationId)\n        except Exception:\n            return retdata\n\n        for row in data:\n            lastseen = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(row[0]))\n            retdata.append([\n                lastseen,\n                html.escape(row[1]),\n                html.escape(row[2]),\n                row[3],\n                row[5],\n                row[6],\n                row[7],\n                row[8],\n                row[13],\n                row[14],\n                row[4]\n            ])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scaneventresultsunique(self: 'SpiderFootWebUi', id: str, eventType: str, filterfp: bool = False) -> list:\n        \"\"\"Return unique event results for a scan as JSON.\n\n        Args:\n            id (str): filter search results by scan ID\n            eventType (str): filter search results by event type\n            filterfp (bool): remove false positives from search results\n\n        Returns:\n            list: unique search results\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        retdata = []\n\n        try:\n            data = dbh.scanResultEventUnique(id, eventType, filterfp)\n        except Exception:\n            return retdata\n\n        for row in data:\n            escaped = html.escape(row[0])\n            retdata.append([escaped, row[1], row[2]])\n\n        return retdata\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def search(self: 'SpiderFootWebUi', id: str = None, eventType: str = None, value: str = None) -> list:\n        \"\"\"Search scans.\n\n        Args:\n            id (str): filter search results by scan ID\n            eventType (str): filter search results by event type\n            value (str): filter search results by event value\n\n        Returns:\n            list: search results\n        \"\"\"\n        try:\n            return self.searchBase(id, eventType, value)\n        except Exception:\n            return []\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanhistory(self: 'SpiderFootWebUi', id: str) -> list:\n        \"\"\"Historical data for a scan.\n\n        Args:\n            id (str): scan ID\n\n        Returns:\n            list: scan history\n        \"\"\"\n        if not id:\n            return self.jsonify_error('404', \"No scan specified\")\n\n        dbh = SpiderFootDb(self.config)\n\n        try:\n            return dbh.scanResultHistory(id)\n        except Exception:\n            return []\n\n    @cherrypy.expose\n    @cherrypy.tools.json_out()\n    def scanelementtypediscovery(self: 'SpiderFootWebUi', id: str, eventType: str) -> dict:\n        \"\"\"Scan element type discovery.\n\n        Args:\n            id (str): scan ID\n            eventType (str): filter by event type\n\n        Returns:\n            dict\n        \"\"\"\n        dbh = SpiderFootDb(self.config)\n        pc = dict()\n        datamap = dict()\n        retdata = dict()\n\n        # Get the events we will be tracing back from\n        try:\n            leafSet = dbh.scanResultEvent(id, eventType)\n            [datamap, pc] = dbh.scanElementSourcesAll(id, leafSet)\n        except Exception:\n            return retdata\n\n        # Delete the ROOT key as it adds no value from a viz perspective\n        del pc['ROOT']\n        retdata['tree'] = SpiderFootHelpers.dataParentChildToTree(pc)\n        retdata['data'] = datamap\n\n        return retdata\n"
        },
        {
          "name": "spiderfoot",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}