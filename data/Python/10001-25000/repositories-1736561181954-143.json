{
  "metadata": {
    "timestamp": 1736561181954,
    "page": 143,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Kr1s77/awesome-python-login-model",
      "stars": 15972,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.099609375,
          "content": "   *.js linguist-language=python\n   *.css linguist-language=python\n   *.html linguist-language=python\n"
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.2294921875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# Mac os\n.DS_Store \n*/.DS_Store \n\n# pycharm\n.idea\n.env\n"
        },
        {
          "name": "126email",
          "type": "tree",
          "content": null
        },
        {
          "name": "163email",
          "type": "tree",
          "content": null
        },
        {
          "name": "163youdao",
          "type": "tree",
          "content": null
        },
        {
          "name": "Github",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.09765625,
          "content": "The MIT License\n\nCopyright (c) 2018 CriseLYJ.\nhttps://github.com/CriseLYJ/awesome-python-login-model\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "NeteaseCloudMusicDownload",
          "type": "tree",
          "content": null
        },
        {
          "name": "README-Test.md",
          "type": "blob",
          "size": 1.794921875,
          "content": "## Test\n\n### Bilibili自动登录测试正常，成功率98%\n\n![](./images/bilibili.gif)\n\n![](./images/bilibili.jpg)\n\n### web微信\n\n![](./images/weixin.gif)\n\n![Alt text](./images/weixin.jpg)\n\n### 图虫Spider\n\n![](./images/tuchong.gif)\n\n![](./images/tuchong.jpg)\n\n### 淘宝web\n- taobao.py为模拟登录\n- 剩下的文件为爬虫\n\n### Github\n\n![](./images/github.jpg)\n\n### 新增链家Spider\n\n![](./images/lianjia.gif)\n\n```\n1. 爬取淘宝各子标签，按销量排名商品信息，按分类保存至MongoDB\n2. 通过pandas进行数据分析\n3 .将商品在各省分布、销量排行、地图分布等通过matplotlib绘图显示\n```\n\n### guoke.spider使用需谨慎，下载的比较快！10秒能下载一堆，截图我就不展示了，已经删除,东西太多了😝\n\n### 微博\n- sina.py为模拟登录\n- spider文件夹中为爬虫\n\n```\n1. 输入要爬取的博主ID，获取ajax请求\n2. 解析json数据，爬取博主所有微博，保存至MySQL\n\n```\n\n### 网易云音乐\n- 新增网易云音乐下载，之前的一个小demo应该还可以用，Crypto包应该挺难搞的，安装之后还是导入不了，推荐去百度一下，百度上的这个解决方法有很多，我就不多赘述了嘿嘿！\n\n### 知乎\n- 知乎登录没有问题，不过要手动输入验证码\n\n- 知乎登录遇到“execjs._exceptions.ProgramError: TypeError: 'exports' 未定义”\n- 原因以及解决办法：\n```\n1. 由于是你本地的JScript引擎只有一个默认的JScript，所以会造成json未定义的错误。\n2. execjs会自动使用当前电脑上的运行时环境\n3. 解决办法：安装一个nodejs的V8引擎就可以了\n```\n\n![](./images/zhihu.jpg)\n\n\n### 糗事百科\n\n![](./images/qiushibaike.gif)\n\n![](./images/qiushibaike.jpg)\n\n### 百度翻译\n- 输入英语自动翻译\n\n![](./images/baidu_translate.gif)"
        },
        {
          "name": "README-en-us.md",
          "type": "blob",
          "size": 4.8046875,
          "content": "<h2 align=\"center\"><code>🐍Website_login_mode</code></h2>\n\n<br>\n<p align=\"center\">\n    <img src=\"https://github.com/CriseLYJ/flask-video-streaming-recorder/blob/master/img/main.jpg?raw=true\" \n        alt=\"Master\">\n</p>\n\n<br>\n\n<p align=\"center\">\"<i>Did you know all your doors were locked?</i>\" - Riddick (The Chronicles of Riddick)</p>\n\n<br>\n<div align=\"center\">\n  <sub>Created by\n  <a href=\"https://criselyj.github.io/\">CriseLYJ</a>\n</div>\n\n<br>\n\n****\n\n# 🌟Website_login_mode\nI collected some major website login methods, and some website crawling programs, some are registered through selenium, some are directly simulated login by capturing packets, some are using scrapy, I hope to help Xiaobai, this project is used for research and sharing The simulated landing mode of the big website, and the crawler program, I will continue to update. . .\n\n## Simulate login to some common websites and crawl corresponding information\n\n\n## About\n\nThe basic login is based on direct login or using selenium+webdriver. Some websites are very difficult to log in directly. For example, qq space, bilibili, etc. if you use selenium, it is relatively easy.\n\nAlthough it is selenium when logging in, for efficiency, we can maintain the cookie obtained after login, and then call requests or scrapy for data collection, so the speed of data collection can be guaranteed.\n\n\n## Completed\n\n- [x] [Facebook](https://www.facebook.com/)\n- [x] [无需身份验证即可抓取Twitter前端API](https://twitter.com/)\n- [x] [微博网页版](http://weibo.com)\n- [x] [知乎](http://zhihu.com)\n- [x] [QQZone](https://qzone.qq.com/)\n- [x] [CSDN](https://www.csdn.net/)\n- [x] [淘宝](www.taobao.com)\n- [x] [Baidu](www.baidu.com)\n- [x] [果壳](https://www.guokr.com/)\n- [x] [JingDong 模拟登录和自动申请京东试用](https://www.jd.com/)\n- [x] [163mail](https://mail.163.com/)\n- [x] [拉钩](https://www.lagou.com/)\n- [x] [Bilibili](https://www.bilibili.com/)\n- [x] [豆瓣](https://www.douban.com/)\n- [x] [Baidu2](www.baidu.com)\n- [x] [猎聘网](https://www.liepin.com/)\n- [x] [微信网页版登录并获取好友列表](https://wx.qq.com/)\n- [x] [Github](https://github.com/)\n- [x] [爬取图虫相应的图片](https://tuchong.com/)\n\n## show\n\n### Bilibili automatic login test is normal, the success rate is 98%\n\n![](./images/bilibili.jpg)\n\n### web Weichat\n\n\n![Alt text](./images/weixin.jpg)\n\n### 图虫spider\n\n![](./images/Jietu20190306-232224.jpg)\n\n![](./images/Jietu20190306-232303.jpg)\n\n### TaoBaoweb\n- taobao.py为模拟登录\n- 剩下的文件为爬虫\n\n### Github\n\n![](./images/github.jpg)\n\n```\n1. Climb the sub-labels of Taobao, rank the product information by sales, and save to MongoDB by category.\n2. Data analysis by pandas\n3. Display the distribution of goods in each province, sales ranking, map distribution, etc. through matplotlib\n```\n\n### Guoke.spider use caution, download faster! 10 seconds to download a bunch, screenshots I will not show, has been deleted, too many things 😝\n\n### Sina\n- sina.py: Log in for the simulation\n- spider: Folder in the crawler\n\n```\n1. Enter the blogger ID to crawl and get an ajax request\n2. Parse the json data, crawl all the bloggers of the blogger, save to MySQL\n\n```\n\n\n## tips of pull request \n\n- Welcome everyone to come pull request 💗\n\n## Problems\n\n- About the verification code: The method used in this project does not process the verification code. The difficulty of identifying the complex verification code is still relatively large at present. In my opinion, the best way to do reptiles is to try to avoid the verification code.\n- Code invalidation: Due to website policy or style change, the code is invalid, please give me an issue. If you have already solved it, you can mention PR, thank you!\n\n## Another\n- If you have any website that is difficult to log in, such as a website that uses selenium+webdriver and can't log in, please feel free to give me an issue.\n- If the repo is helpful to everyone, give a star encouragement.\n\n## something to add\n\n1. After writing the project for a period of time, I found that the style of the code and the ease of use of the program, scalability, and readability of the code all have certain problems, so the next most important thing is to refactor the code so that everyone can It's easier to make some small features of your own.\n2. If you feel that the login of a website is very representative, please feel free to ask in the issue\n3. If the login to the site is very interesting, I will add it in a later update.\n4. The login mechanism of the website may change frequently, so when the current simulated login rule cannot be used, please submit it in the issue.\n- If you have a lot of attention, I will continue to maintain this repository to bring more things and refactor the code.\n\n## Acknowledgments\n- Thanks for all!\n\n## Written at the end\n- I need your support.\n- And I think you can give me a 🌟``star``!s"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.2568359375,
          "content": "<h2 align=\"center\"><code>🎉Life is fantastic🥳!~</code></h2>\n\n<br>\n<p align=\"center\">\n    <img src=\"https://github.com/CriseLYJ/flask-video-streaming-recorder/blob/master/img/main.jpg?raw=true\" \n        alt=\"Master\">\n</p>\n\n<br>\n\n<p align=\"center\">\"<i>Did you know all your doors were locked?</i>\" - Riddick (The Chronicles of Riddick)</p>\n\n<br>\n\n<p align=\"center\">\n  <a href=\"https://github.com/CriseLYJ/awesome-python-login-model/tree/master\">\n    <img src=\"https://img.shields.io/badge/Branch-master-green.svg?longCache=true\"\n        alt=\"Branch\">\n  </a>\n  <a href=\"https://github.com/CriseLYJ/awesome-python-login-model/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/CriseLYJ/awesome-python-login-model.svg?label=Stars&style=social\"\n        alt=\"Stars\">\n  </a>\n    <a href=\"https://github.com/CriseLYJ/awesome-python-login-model/network/members\">\n    <img src=\"https://img.shields.io/github/forks/CriseLYJ/awesome-python-login-model.svg?label=Forks&style=social\"\n        alt=\"Forks\">\n  </a>\n  <a href=\"http://www.gnu.org/licenses/\">\n    <img src=\"https://img.shields.io/badge/License-GNU-blue.svg?longCache=true\"\n        alt=\"License\">\n  </a>\n   <a href=\"https://github.com/sindresorhus/awesome\">\n   <img src=\"https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg\"\n        alt=\"Awesome\">\n  </a>\n</p>\n<br>\n<div align=\"center\">\n  <sub>Created by\n  <a href=\"https://Kr1s77.github.io/\">@kris</a>\n</div>\n\n<br>\n\n****\n\n## 传送门\n- [x] [4G 代理](https://github.com/Kr1s77/FgSurfing)\n- [x] [异常处理回调，直接 hook 所有函数，和类](https://github.com/Kr1s77/abnormalities)\n给个 🌟 再走吧...\n    \n## 💕Website login model\n一些爬虫示例程序，以及模拟登陆程序,模拟登陆基于 selenium，有些模拟登录基于 js 逆向，持续更新，有问题可以直接提交 Issues，欢迎提交 PR, 测试通过可以直接 merge，文中所有程序都是使用 ``python3`` 编写 :-)\n\n## About\n\n模拟登陆基本采用的是直接登录或者使用selenium+webdriver的方式，有的网站直接登录难度很大，比如qq空间，bilibili等如果采用selenium就相对轻松一些。\n\n虽然在登录的时候采用的是selenium,为了效率，我们可以在登录过后得到的cookie维护起来，然后调用requests或者scrapy等进行数据采集，这样数据采集的速度可以得到保证。\n\n## WebDriver\n[Chrome](https://chromedriver.chromium.org/)\n[FireFox](https://github.com/mozilla/geckodriver/releases/)\n\n## Completed\n\n- [x] [虾米音乐](https://www.xiami.com/)\n- [x] [Facebook](https://www.facebook.com/)\n- [x] [微博网页版](http://weibo.com)\n- [x] [知乎](http://zhihu.com)\n- [x] [QQZone](https://qzone.qq.com/)\n- [x] [CSDN](https://www.csdn.net/)\n- [x] [淘宝-接口修复完成-可用](https://login.taobao.com/member/login.jhtml)\n- [x] [CSDN--已重构](https://www.csdn.net/)\n- [x] [Baidu](www.baidu.com)\n- [x] [果壳](https://www.guokr.com/)\n- [x] [JingDong 模拟登录和自动申请京东试用](https://www.jd.com/)\n- [x] [163mail](https://mail.163.com/)\n- [x] [拉钩](https://www.lagou.com/)\n- [x] [Bilibili](https://www.bilibili.com/)\n- [x] [豆瓣](https://www.douban.com/)\n- [x] [豆瓣spider](https://www.douban.com/)\n- [x] [Baidu](www.baidu.com)\n- [x] [猎聘网](https://www.liepin.com/)\n- [x] [微信网页版登录并获取好友列表](https://wx.qq.com/)\n- [x] [Github](https://github.com/)\n- [x] [爬取图虫相应的图片](https://tuchong.com/)\n- [x] [网易云音乐](https://music.163.com/)\n- [x] [糗事百科--改为协程版](https://www.qiushibaike.com/)\n- [x] [百度贴吧spider](https://tieba.baidu.com/)\n- [x] [百度翻译](https://fanyi.baidu.com/)\n\n## catalogue\n- [x] [虾米音乐](https://github.com/Kr1s77/awesome-python-login-model/tree/master/xiamiMusic)\n- [x] [Facebook模拟登录](https://github.com/Kr1s77/awesome-python-login-model/blob/master/facebook)\n- [x] [微博网页版模拟登录](https://github.com/Kr1s77/awesome-python-login-model/blob/master/sina)\n- [x] [QQZone模拟登录](https://github.com/Kr1s77/awesome-python-login-model/blob/master/qqzone)\n- [x] [CSDN模拟登录--已恢复](https://github.com/Kr1s77/awesome-python-login-model/blob/master/csdn)\n- [x] [淘宝爬虫--重构中](https://github.com/Kr1s77/awesome-python-login-model/tree/master/taobao)\n- [x] [Baidu模拟登录一](https://github.com/Kr1s77/awesome-python-login-model/tree/master/baidu)\n- [x] [果壳爬虫程序](https://github.com/Kr1s77/awesome-python-login-model/tree/master/guoke)\n- [x] [JingDong 模拟登录和自动申请京东试用](https://github.com/Kr1s77/awesome-python-login-model/tree/master/jd_login)\n- [x] [163mail--已恢复](https://github.com/Kr1s77/awesome-python-login-model/blob/master/163email/163email.py)\n- [x] [拉钩模拟登录--已失效](https://github.com/Kr1s77/awesome-python-login-model/blob/master/lagou/Lagou.py)\n- [x] [Bilibili模拟登录](https://github.com/Kr1s77/awesome-python-login-model/blob/master/bilibili/bilibili.py)\n- [x] [豆瓣](https://github.com/Kr1s77/awesome-python-login-model/blob/master/douban/douban.py)\n- [x] [Baidu2模拟登录](https://github.com/Kr1s77/awesome-python-login-model/blob/master/baidu2/baidu.py)\n- [x] [猎聘网模拟登录](https://github.com/Kr1s77/awesome-python-login-model/tree/master/liepin)\n- [x] [微信网页版登录并获取好友列表](https://github.com/Kr1s77/awesome-python-login-model/blob/master/webWeixin/webWeixin.py)\n- [x] [Github模拟登录两种解决方案都可行](https://github.com/Kr1s77/awesome-python-login-model/tree/master/Github)\n- [x] [爬取图虫想要的图片](https://github.com/Kr1s77/awesome-python-login-model/blob/master/tuchong/tuchong.py)\n- [x] [网易云音乐downloader](https://github.com/Kr1s77/awesome-python-login-model/blob/master/NeteaseCloudMusicDownload/wangyiyun_spider.py)\n- [x] [糗事百科爬虫](https://github.com/Kr1s77/awesome-python-login-model/blob/master/qsbk/qiushibaike.py)\n- [x] [淘宝登陆-访问](https://login.taobao.com/member/login.jhtml)\n\n\n# Test\n\n> [Please touch here to view test images](./README-Test.md)\n\n## Informations\n- 为感谢你们的支持，准备写一套免费爬虫的教程，保证你学会以后可以爬取市面上大部分的网站，[教程地址](https://github.com/CriseLYJ/-Python-crawler-starts-from-zero)\n\n## tips of pull request \n\n- 欢迎大家一起来 pull request 💗\n\n## Problems\n\n- 关于验证码：本项目所用的方法都没有处理验证码，识别复杂验证码的难度就目前来说，还是比较大的。以我的心得来说，做爬虫最好的方式就是尽量规避验证码。\n- 代码失效：由于网站策略或者样式改变，导致代码失效，请给我提issue，如果你已经解决，可以提PR，谢谢！\n- 正在对部分代码进行优化。。。\n- 如果该repo对大家有帮助，记得 star 哦。\n\n\n## Acknowledgments\n\n> [@deepforce](https://github.com/deepforce) | [@cclauss](https://github.com/cclauss) | [ksoeasyxiaosi](https://github.com/ksoeasyxiaosi) | [JasonJunJun](https://github.com/JasonJunJun) | [MediocrityXT](https://github.com/MediocrityXT)\n\n- 感谢以上开发者的支持和贡献。\n\n## 联系我\n- 欢迎反馈！\n- Email : criselyj@163.com\n\n## 注意：\n- 本项目仅用于学习和交流\n> 欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远\n"
        },
        {
          "name": "baidu",
          "type": "tree",
          "content": null
        },
        {
          "name": "baidu_translate",
          "type": "tree",
          "content": null
        },
        {
          "name": "bilibili",
          "type": "tree",
          "content": null
        },
        {
          "name": "csdn",
          "type": "tree",
          "content": null
        },
        {
          "name": "douban",
          "type": "tree",
          "content": null
        },
        {
          "name": "facebook",
          "type": "tree",
          "content": null
        },
        {
          "name": "guoke",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "jd_login",
          "type": "tree",
          "content": null
        },
        {
          "name": "lagou",
          "type": "tree",
          "content": null
        },
        {
          "name": "liepin",
          "type": "tree",
          "content": null
        },
        {
          "name": "qqmusic",
          "type": "tree",
          "content": null
        },
        {
          "name": "qqzone",
          "type": "tree",
          "content": null
        },
        {
          "name": "qsbk",
          "type": "tree",
          "content": null
        },
        {
          "name": "sina",
          "type": "tree",
          "content": null
        },
        {
          "name": "taobao",
          "type": "tree",
          "content": null
        },
        {
          "name": "tieba",
          "type": "tree",
          "content": null
        },
        {
          "name": "tuchong",
          "type": "tree",
          "content": null
        },
        {
          "name": "webWeixin",
          "type": "tree",
          "content": null
        },
        {
          "name": "xiamiMusic",
          "type": "tree",
          "content": null
        },
        {
          "name": "zhaopingou",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}