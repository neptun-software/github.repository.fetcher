{
  "metadata": {
    "timestamp": 1736561097697,
    "page": 30,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sebastianruder/NLP-progress",
      "stars": 22761,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0419921875,
          "content": "_site/\nGemfile*\nvenv\n.idea\nstructured.json\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.2548828125,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Ruder\"\n  given-names: \"Sebastian\"\ntitle: \"NLP-progress\"\nversion: 1.0.0\ndoi: 10.5281/zenodo.1234\ndate-released: 2022-02-06\nurl: \"https://nlpprogress.com/\"\n"
        },
        {
          "name": "CNAME",
          "type": "blob",
          "size": 0.0146484375,
          "content": "nlpprogress.com"
        },
        {
          "name": "Gemfile",
          "type": "blob",
          "size": 0.0703125,
          "content": "source 'https://rubygems.org'\ngem 'github-pages', group: :jekyll_plugins"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.046875,
          "content": "MIT License\n\nCopyright (c) 2018 Sebastian Ruder\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.6748046875,
          "content": "# Tracking Progress in Natural Language Processing\n\n## Table of contents\n\n### English\n\n- [Automatic speech recognition](english/automatic_speech_recognition.md)\n- [CCG](english/ccg.md)\n- [Common sense](english/common_sense.md)\n- [Constituency parsing](english/constituency_parsing.md)\n- [Coreference resolution](english/coreference_resolution.md)\n- [Data-to-Text Generation](english/data_to_text_generation.md)\n- [Dependency parsing](english/dependency_parsing.md)\n- [Dialogue](english/dialogue.md)\n- [Domain adaptation](english/domain_adaptation.md)\n- [Entity linking](english/entity_linking.md)\n- [Grammatical error correction](english/grammatical_error_correction.md)\n- [Information extraction](english/information_extraction.md)\n- [Intent Detection and Slot Filling](english/intent_detection_slot_filling.md) \n- [Keyphrase Extraction and Generation](english/keyphrase_extraction_generation.md)\n- [Language modeling](english/language_modeling.md)\n- [Lexical normalization](english/lexical_normalization.md)\n- [Machine translation](english/machine_translation.md)\n- [Missing elements](english/missing_elements.md)\n- [Multi-task learning](english/multi-task_learning.md)\n- [Multi-modal](english/multimodal.md)\n- [Named entity recognition](english/named_entity_recognition.md)\n- [Natural language inference](english/natural_language_inference.md)\n- [Part-of-speech tagging](english/part-of-speech_tagging.md)\n- [Paraphrase Generation](english/paraphrase-generation.md)\n- [Question answering](english/question_answering.md)\n- [Relation prediction](english/relation_prediction.md)\n- [Relationship extraction](english/relationship_extraction.md)\n- [Semantic textual similarity](english/semantic_textual_similarity.md)\n- [Semantic parsing](english/semantic_parsing.md)\n- [Semantic role labeling](english/semantic_role_labeling.md)\n- [Sentiment analysis](english/sentiment_analysis.md)\n- [Shallow syntax](english/shallow_syntax.md)\n- [Simplification](english/simplification.md)\n- [Stance detection](english/stance_detection.md)\n- [Summarization](english/summarization.md)\n- [Taxonomy learning](english/taxonomy_learning.md)\n- [Temporal processing](english/temporal_processing.md)\n- [Text classification](english/text_classification.md)\n- [Word sense disambiguation](english/word_sense_disambiguation.md)\n\n### Vietnamese\n\n- [Dependency parsing](vietnamese/vietnamese.md#dependency-parsing)\n- [Intent detection and Slot filling](vietnamese/vietnamese.md#intent-detection-and-slot-filling)\n- [Machine translation](vietnamese/vietnamese.md#machine-translation)\n- [Named entity recognition](vietnamese/vietnamese.md#named-entity-recognition)\n- [Part-of-speech tagging](vietnamese/vietnamese.md#part-of-speech-tagging)\n- [Semantic parsing](vietnamese/vietnamese.md#semantic-parsing)\n- [Word segmentation](vietnamese/vietnamese.md#word-segmentation)\n\n### Hindi\n\n- [Chunking](hindi/hindi.md#chunking)\n- [Part-of-speech tagging](hindi/hindi.md#part-of-speech-tagging)\n- [Machine Translation](hindi/hindi.md#machine-translation)\n\n### Chinese\n\n- [Entity linking](chinese/chinese.md#entity-linking)\n- [Chinese word segmentation](chinese/chinese_word_segmentation.md)\n- [Question answering](chinese/question_answering.md)\n\nFor more tasks, datasets and results in Chinese, check out the [Chinese NLP](https://chinesenlp.xyz/#/) website.\n\n### French\n\n- [Question answering](french/question_answering.md)\n- [Summarization](french/summarization.md)\n\n### Russian\n\n- [Question answering](russian/question_answering.md)\n- [Sentiment Analysis](russian/sentiment-analysis.md)\n- [Summarization](russian/summarization.md)\n\n### Spanish\n\n- [Named Entity Recognition](spanish/named_entity_recognition.md)\n- [Entity linking](spanish/entity_linking.md#entity-linking)\n- [Summarization](spanish/summarization.md)\n\n### Portuguese\n\n- [Question Answering](portuguese/question_answering.md)\n\n### Korean\n\n- [Question Answering](korean/question_answering.md)\n\n### Nepali\n\n- [Machine Translation](nepali/nepali.md#machine-translation)\n\n### Bengali\n- [Part-of-speech Tagging](bengali/part_of_speech_tagging.md)\n- [Emotion Detection](bengali/emotion_detection.md)\n- [Sentiment Analysis](bengali/sentiment_analysis.md)\n\n### Persian\n- [Named entity recognition](persian/named_entity_recognition.md)\n- [Natural language inference](persian/natural_language_inference.md)\n- [Summarization](persian/summarization.md)\n\n### Turkish\n\n- [Summarization](turkish/summarization.md)\n\n### German\n\n- [Question Answering](german/question_answering.md)\n- [Summarization](german/summarization.md)\n\n### Arabic\n- [Language modeling](arabic/language_modeling.md)\n\n\nThis document aims to track the progress in Natural Language Processing (NLP) and give an overview\nof the state-of-the-art (SOTA) across the most common NLP tasks and their corresponding datasets.\n\nIt aims to cover both traditional and core NLP tasks such as dependency parsing and part-of-speech tagging\nas well as more recent ones such as reading comprehension and natural language inference. The main objective\nis to provide the reader with a quick overview of benchmark datasets and the state-of-the-art for their\ntask of interest, which serves as a stepping stone for further research. To this end, if there is a \nplace where results for a task are already published and regularly maintained, such as a public leaderboard,\nthe reader will be pointed there.\n\nIf you want to find this document again in the future, just go to [`nlpprogress.com`](https://nlpprogress.com/)\nor [`nlpsota.com`](http://nlpsota.com/) in your browser.\n\n### Contributing\n\n#### Guidelines\n\n**Results** &nbsp; Results reported in published papers are preferred; an exception may be made for influential preprints.\n\n**Datasets** &nbsp; Datasets should have been used for evaluation in at least one published paper besides \nthe one that introduced the dataset.\n\n**Code** &nbsp; We recommend to add a link to an implementation \nif available. You can add a `Code` column (see below) to the table if it does not exist.\nIn the `Code` column, indicate an official implementation with [Official](http://link_to_implementation).\nIf an unofficial implementation is available, use [Link](http://link_to_implementation) (see below).\nIf no implementation is available, you can leave the cell empty.\n\n#### Adding a new result\n\nIf you would like to add a new result, you can just click on the small edit button in the top-right\ncorner of the file for the respective task (see below).\n\n![Click on the edit button to add a file](img/edit_file.png)\n\nThis allows you to edit the file in Markdown. Simply add a row to the corresponding table in the\nsame format. Make sure that the table stays sorted (with the best result on top). \nAfter you've made your change, make sure that the table still looks ok by clicking on the\n\"Preview changes\" tab at the top of the page. If everything looks good, go to the bottom of the page,\nwhere you see the below form. \n\n![Fill out the file change information](img/propose_file_change.png)\n\nAdd a name for your proposed change, an optional description, indicate that you would like to\n\"Create a new branch for this commit and start a pull request\", and click on \"Propose file change\".\n\n#### Adding a new dataset or task\n\nFor adding a new dataset or task, you can also follow the steps above. Alternatively, you can fork the repository.\nIn both cases, follow the steps below:\n\n1. If your task is completely new, create a new file and link to it in the table of contents above.\n2. If not, add your task or dataset to the respective section of the corresponding file (in alphabetical order).\n3. Briefly describe the dataset/task and include relevant references. \n4. Describe the evaluation setting and evaluation metric.\n5. Show how an annotated example of the dataset/task looks like.\n6. Add a download link if available.\n7. Copy the below table and fill in at least two results (including the state-of-the-art)\n  for your dataset/task (change Score to the metric of your dataset). If your dataset/task\n  has multiple metrics, add them to the right of `Score`.\n1. Submit your change as a pull request.\n  \n| Model           | Score  |  Paper / Source | Code |\n| ------------- | :-----:| --- | --- |\n|  |  |  | |\n\n\n### Wish list\n\nThese are tasks and datasets that are still missing:\n\n- Bilingual dictionary induction\n- Discourse parsing\n- Keyphrase extraction\n- Knowledge base population (KBP)\n- More dialogue tasks\n- Semi-supervised learning\n- Frame-semantic parsing (FrameNet full-sentence analysis)\n\n### Exporting into a structured format\n\nYou can extract all the data into a structured, machine-readable JSON format with parsed tasks, descriptions and SOTA tables. \n\nThe instructions are in [structured/README.md](structured/README.md).\n\n### Instructions for building the site locally\n\nInstructions for building the website locally using Jekyll can be found [here](jekyll_instructions.md).\n\n\n"
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.0244140625,
          "content": "theme: jekyll-theme-slate"
        },
        {
          "name": "_includes",
          "type": "tree",
          "content": null
        },
        {
          "name": "arabic",
          "type": "tree",
          "content": null
        },
        {
          "name": "bengali",
          "type": "tree",
          "content": null
        },
        {
          "name": "chinese",
          "type": "tree",
          "content": null
        },
        {
          "name": "english",
          "type": "tree",
          "content": null
        },
        {
          "name": "french",
          "type": "tree",
          "content": null
        },
        {
          "name": "german",
          "type": "tree",
          "content": null
        },
        {
          "name": "hindi",
          "type": "tree",
          "content": null
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "jekyll_instructions.md",
          "type": "blob",
          "size": 1.0517578125,
          "content": "# Instructions for building the site locally\n\nYou can build the site locally using Jekyll by following the steps detailed\n[here](https://help.github.com/articles/setting-up-your-github-pages-site-locally-with-jekyll/#requirements):\n\n1. Check whether you have Ruby 2.1.0 or higher installed with `ruby --version`, otherwise [install it](https://www.ruby-lang.org/en/downloads/).\nOn OS X for instance, this can be done with `brew install ruby`. Make sure you also have `ruby-dev` and `zlib1g-dev` installed.\n1. Install Bundler `gem install bundler`. If you run into issues with installing bundler on OS X, have a look\n[here](https://bundler.io/v1.16/guides/rubygems_tls_ssl_troubleshooting_guide.html) for troubleshooting tips. Also try refreshing\nthe terminal.\n1. Clone the repo locally: `git clone https://github.com/sebastianruder/NLP-progress`\n1. Navigate to the repo with `cd NLP-progress`\n1. Install Jekyll: `bundle install`\n1. Run the Jekyll site locally: `bundle exec jekyll serve`\n1. You can now preview the local Jekyll site in your browser at `http://localhost:4000`.\n"
        },
        {
          "name": "korean",
          "type": "tree",
          "content": null
        },
        {
          "name": "nepali",
          "type": "tree",
          "content": null
        },
        {
          "name": "persian",
          "type": "tree",
          "content": null
        },
        {
          "name": "portuguese",
          "type": "tree",
          "content": null
        },
        {
          "name": "russian",
          "type": "tree",
          "content": null
        },
        {
          "name": "spanish",
          "type": "tree",
          "content": null
        },
        {
          "name": "structured",
          "type": "tree",
          "content": null
        },
        {
          "name": "turkish",
          "type": "tree",
          "content": null
        },
        {
          "name": "vietnamese",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}