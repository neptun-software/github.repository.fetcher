{
  "metadata": {
    "timestamp": 1736561227186,
    "page": 209,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "flairNLP/flair",
      "stars": 14009,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.25,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n.idea/\n.vscode/\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\nresources/taggers/\nregression_train/\n/doc_build/\n\nscripts/\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.142578125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at opensource@zalando.de. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.1484375,
          "content": "# Contributing to Flair\n\nWe are happy to accept your contributions to make `flair` better and more awesome! To avoid unnecessary work on either\nside, please stick to the following process:\n\n1. Check if there is already [an issue](https://github.com/flairNLP/flair/issues) for your concern.\n2. If there is not, open a new one to start a discussion. We hate to close finished PRs!\n3. If we decide your concern needs code changes, we would be happy to accept a pull request. Please consider the\n   commit guidelines below.\n\n\n## Git Commit Guidelines\n\nIf there is already a ticket, use this number at the start of your commit message.\nUse meaningful commit messages that described what you did.\n\n**Example:** `GH-42: Added new type of embeddings: DocumentEmbedding.`\n\n## Developing locally\n\nFor contributors looking to get deeper into the API we suggest cloning the repository and checking out the unit\ntests for examples of how to call methods. Nearly all classes and methods are documented, so finding your way around\nthe code should hopefully be easy.\n\n### Setup\n\nFlair requires python-3.9 or higher. To make sure your code also runs on the oldest supported\npython version, it is recommended to use python-3.9.x for flair development.\n\nCreate a python environment of your preference and run:\n```bash\npip install -r requirements-dev.txt\npip install -e .\n```\n\n### Tests\n\nTo only run typechecks and check the code formatting execute:\n\n```bash\npytest flair\n```\n\nTo run all basic tests execute:\n\n```bash\npytest\n```\n\nTo run integration tests execute:\n\n```bash\npytest --runintegration\n```\n\nThe integration tests will train small models and therefore take more time.\nIn general, it is recommended to ensure all basic tests are running through before testing the integration tests\n\n### Code Formatting\n\nTo ensure a standardized code style we use the formatter [black](https://github.com/ambv/black) and for standardizing imports we use [ruff](https://github.com/charliermarsh/ruff).\nIf your code is not formatted properly, the tests will fail.\n\nWe recommend configuring your IDE to run these formatters for you, but you can also always run them manually via\n`black . && ruff --fix .` in the flair root folder.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.138671875,
          "content": "The MIT License (MIT)\n\nFlair is licensed under the following MIT License (MIT) Copyright © 2018 Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.046875,
          "content": "include flair/py.typed\ninclude requirements.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.2216796875,
          "content": "![alt text](resources/docs/flair_logo_2020_FINAL_day_dpi72.png#gh-light-mode-only)\n![alt text](resources/docs/flair_logo_2020_FINAL_night_dpi72.png#gh-dark-mode-only)\n\n[![PyPI version](https://badge.fury.io/py/flair.svg)](https://badge.fury.io/py/flair)\n[![GitHub Issues](https://img.shields.io/github/issues/flairNLP/flair.svg)](https://github.com/flairNLP/flair/issues)\n[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)\n\nA very simple framework for **state-of-the-art NLP**. Developed by [Humboldt University of Berlin](https://www.informatik.hu-berlin.de/en/forschung-en/gebiete/ml-en/) and friends.\n\n---\n\nFlair is:\n\n* **A powerful NLP library.** Flair allows you to apply our state-of-the-art natural language processing (NLP)\nmodels to your text, such as named entity recognition (NER), sentiment analysis, part-of-speech tagging (PoS),\n  special support for [biomedical texts](/resources/docs/HUNFLAIR2.md),\n sense disambiguation and classification, with support for a rapidly growing number of languages.\n\n* **A text embedding library.** Flair has simple interfaces that allow you to use and combine different word and\ndocument embeddings, including our proposed [Flair embeddings](https://www.aclweb.org/anthology/C18-1139/) and various transformers.\n\n* **A PyTorch NLP framework.** Our framework builds directly on [PyTorch](https://pytorch.org/), making it easy to\ntrain your own models and experiment with new approaches using Flair embeddings and classes.\n\nNow at [version 0.15.0](https://github.com/flairNLP/flair/releases)!\n\n\n## State-of-the-Art Models\n\nFlair ships with state-of-the-art models for a range of NLP tasks. For instance, check out our latest NER models:\n\n| Language | Dataset | Flair | Best published | Model card & demo\n|  ---  | ----------- | ---------------- | ------------- | ------------- |\n| English | Conll-03 (4-class)   |  **94.09**  | *94.3 [(Yamada et al., 2020)](https://doi.org/10.18653/v1/2020.emnlp-main.523)* | [Flair English 4-class NER demo](https://huggingface.co/flair/ner-english-large)  |\n| English | Ontonotes (18-class)  |  **90.93**  | *91.3 [(Yu et al., 2020)](https://www.aclweb.org/anthology/2020.acl-main.577.pdf)* | [Flair English 18-class NER demo](https://huggingface.co/flair/ner-english-ontonotes-large) |\n| German  | Conll-03 (4-class)   |  **92.31**  | *90.3 [(Yu et al., 2020)](https://www.aclweb.org/anthology/2020.acl-main.577.pdf)* | [Flair German 4-class NER demo](https://huggingface.co/flair/ner-german-large)  |\n| Dutch  | Conll-03  (4-class)  |  **95.25**  | *93.7 [(Yu et al., 2020)](https://www.aclweb.org/anthology/2020.acl-main.577.pdf)* | [Flair Dutch 4-class NER demo](https://huggingface.co/flair/ner-dutch-large)  |\n| Spanish  | Conll-03 (4-class)   |  **90.54** | *90.3 [(Yu et al., 2020)](https://www.aclweb.org/anthology/2020.acl-main.577.pdf)* | [Flair Spanish 4-class NER demo](https://huggingface.co/flair/ner-spanish-large)  |\n\nMany Flair sequence tagging models (named entity recognition, part-of-speech tagging etc.) are also hosted\non the [__🤗 Hugging Face model hub__](https://huggingface.co/models?library=flair&sort=downloads)! You can browse models, check detailed information on how they were trained, and even try each model out online!\n\n\n## Quick Start\n\n### Requirements and Installation\n\nIn your favorite virtual environment, simply do:\n\n```\npip install flair\n```\n\nFlair requires Python 3.9+. \n\n### Example 1: Tag Entities in Text\n\nLet's run **named entity recognition** (NER) over an example sentence. All you need to do is make a `Sentence`, load\na pre-trained model and use it to predict tags for the sentence:\n\n```python\nfrom flair.data import Sentence\nfrom flair.nn import Classifier\n\n# make a sentence\nsentence = Sentence('I love Berlin .')\n\n# load the NER tagger\ntagger = Classifier.load('ner')\n\n# run NER over sentence\ntagger.predict(sentence)\n\n# print the sentence with all annotations\nprint(sentence)\n```\n\nThis should print:\n\n```console\nSentence: \"I love Berlin .\" → [\"Berlin\"/LOC]\n```\n\nThis means that \"Berlin\" was tagged as a **location entity** in this sentence. \n\n   * *to learn more about NER tagging in Flair, check out our [NER tutorial](https://flairnlp.github.io/docs/tutorial-basics/tagging-entities)!*\n\n\n### Example 2: Detect Sentiment \n\nLet's run **sentiment analysis** over an example sentence to determine whether it is POSITIVE or NEGATIVE.\nSame code as above, just a different model: \n\n```python\nfrom flair.data import Sentence\nfrom flair.nn import Classifier\n\n# make a sentence\nsentence = Sentence('I love Berlin .')\n\n# load the NER tagger\ntagger = Classifier.load('sentiment')\n\n# run NER over sentence\ntagger.predict(sentence)\n\n# print the sentence with all annotations\nprint(sentence)\n```\n\nThis should print:\n\n```console\nSentence[4]: \"I love Berlin .\" → POSITIVE (0.9983)\n```\n\nThis means that the sentence \"I love Berlin\" was tagged as having **POSITIVE** sentiment. \n\n   * *to learn more about sentiment analysis in Flair, check out our [sentiment analysis tutorial](https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment)!*\n\n## Tutorials\n\nOn our new :fire: [**Flair documentation page**](https://flairnlp.github.io/docs/intro) you will find many tutorials to get you started!\n\nIn particular: \n- [Tutorial 1: Basic tagging](https://flairnlp.github.io/docs/category/tutorial-1-basic-tagging) → how to tag your text \n- [Tutorial 2: Training models](https://flairnlp.github.io/docs/category/tutorial-2-training-models) → how to train your own state-of-the-art NLP models \n- [Tutorial 3: Embeddings](https://flairnlp.github.io/docs/category/tutorial-3-embeddings) → how to produce embeddings for words and documents\n- [Tutorial 4: Biomedical text](https://flairnlp.github.io/docs/category/tutorial-4-biomedical-text) → how to analyse biomedical text data\n\nThere is also a dedicated landing page for our [biomedical NER and datasets](/resources/docs/HUNFLAIR.md) with\ninstallation instructions and tutorials.\n\n\n## More Documentation\n\nAnother great place to start is the book [Natural Language Processing with Flair](https://www.amazon.com/Natural-Language-Processing-Flair-understanding/dp/1801072310)\nand its accompanying [code repository](https://github.com/PacktPublishing/Natural-Language-Processing-with-Flair), though it was\nwritten for an older version of Flair and some examples may no longer work.\n\nThere are also good third-party articles and posts that illustrate how to use Flair:\n* [Training an NER model with Flair](https://medium.com/thecyphy/training-custom-ner-model-using-flair-df1f9ea9c762)\n* [Training a text classifier with Flair](https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f)\n* [Zero and few-shot learning](https://towardsdatascience.com/zero-and-few-shot-learning-c08e145dc4ed) \n* [Visualisation tool for highlighting the extracted entities](https://github.com/lunayach/visNER)\n* [Flair functionality and how to use in Colab](https://www.analyticsvidhya.com/blog/2019/02/flair-nlp-library-python/)\n* [Benchmarking NER algorithms](https://towardsdatascience.com/benchmark-ner-algorithm-d4ab01b2d4c3)\n* [Clinical NLP](https://towardsdatascience.com/clinical-natural-language-processing-5c7b3d17e137)\n* [How to build a microservice with Flair and Flask](https://shekhargulati.com/2019/01/04/building-a-sentiment-analysis-python-microservice-with-flair-and-flask/)\n* [A docker image for Flair](https://towardsdatascience.com/docker-image-for-nlp-5402c9a9069e)\n* [Practical approach of State-of-the-Art Flair in Named Entity Recognition](https://medium.com/analytics-vidhya/practical-approach-of-state-of-the-art-flair-in-named-entity-recognition-46a837e25e6b)\n* [Training a Flair text classifier on Google Cloud Platform (GCP) and serving predictions on GCP](https://github.com/robinvanschaik/flair-on-gcp)\n* [Model Interpretability for transformer-based Flair models](https://github.com/robinvanschaik/interpret-flair)\n\n## Citing Flair\n\nPlease cite [the following paper](https://www.aclweb.org/anthology/C18-1139/) when using Flair embeddings:\n\n```\n@inproceedings{akbik2018coling,\n  title={Contextual String Embeddings for Sequence Labeling},\n  author={Akbik, Alan and Blythe, Duncan and Vollgraf, Roland},\n  booktitle = {{COLING} 2018, 27th International Conference on Computational Linguistics},\n  pages     = {1638--1649},\n  year      = {2018}\n}\n```\n\nIf you use the Flair framework for your experiments, please cite [this paper](https://www.aclweb.org/anthology/papers/N/N19/N19-4010/):\n\n```\n@inproceedings{akbik2019flair,\n  title={{FLAIR}: An easy-to-use framework for state-of-the-art {NLP}},\n  author={Akbik, Alan and Bergmann, Tanja and Blythe, Duncan and Rasul, Kashif and Schweter, Stefan and Vollgraf, Roland},\n  booktitle={{NAACL} 2019, 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)},\n  pages={54--59},\n  year={2019}\n}\n```\n\nIf you use our new \"FLERT\" models or approach, please cite [this paper](https://arxiv.org/abs/2011.06993):\n\n```\n@misc{schweter2020flert,\n    title={{FLERT}: Document-Level Features for Named Entity Recognition},\n    author={Stefan Schweter and Alan Akbik},\n    year={2020},\n    eprint={2011.06993},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n```\n\nIf you use our TARS approach for few-shot and zero-shot learning, please cite [this paper](https://aclanthology.org/2020.coling-main.285/):\n\n```\n@inproceedings{halder2020coling,\n  title={Task Aware Representation of Sentences for Generic Text Classification},\n  author={Halder, Kishaloy and Akbik, Alan and Krapac, Josip and Vollgraf, Roland},\n  booktitle = {{COLING} 2020, 28th International Conference on Computational Linguistics},\n  year      = {2020}\n}\n```\n\n## Contact\n\nPlease email your questions or comments to [Alan Akbik](http://alanakbik.github.io/).\n\n## Contributing\n\nThanks for your interest in contributing! There are many ways to get involved;\nstart with our [contributor guidelines](CONTRIBUTING.md) and then\ncheck these [open issues](https://github.com/flairNLP/flair/issues) for specific tasks.\n\n\n## [License](/LICENSE)\n\nThe MIT License (MIT)\n\nFlair is licensed under the following MIT license: The MIT License (MIT) Copyright © 2018 Zalando SE, https://tech.zalando.com\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.24609375,
          "content": "We acknowledge that every line of code that we write may potentially contain security issues.\nWe are trying to deal with it responsibly and provide patches as quickly as possible.\n\nPlease report any issues to [Alan Akbik](http://alanakbik.github.io/).\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "collect_env.py",
          "type": "blob",
          "size": 0.330078125,
          "content": "import torch\nimport transformers\n\nimport flair\n\n\ndef main():\n    print(\"#### Versions:\")\n    print(f\"##### Flair\\n{flair.__version__}\")\n    print(f\"##### Pytorch\\n{torch.__version__}\")\n    print(f\"##### Transformers\\n{transformers.__version__}\")\n    print(f\"#### GPU\\n{torch.cuda.is_available()}\")\n\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flair",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.93359375,
          "content": "[tool.black]\nline-length = 120\ntarget-version = ['py39']\nexclude = '''\n(\n  /(\n      \\.eggs\n    | \\.git\n    | \\.pytest_cache\n    | build\n    | dist\n    | venv\n  )/\n)\n'''\n[tool.pytest.ini_options]\naddopts = \"--black --mypy --ruff\"\nfilterwarnings = [\n    \"error\",  # Convert all warnings to errors\n    'ignore:torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables',  # Distilbert warning\n    'ignore:TorchScript will treat type annotations of Tensor:UserWarning',  # Torch onnx export warns about it ignoring types, however we still like types.\n    'ignore:Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.',  # ignore gensim using deprecated scipy\n    'ignore:bilinear is deprecated and will be removed in Pillow 10',  # huggingface layoutlmv2 has deprecated calls.\n    'ignore:nearest is deprecated and will be removed in Pillow 10',  # huggingface layoutlmv2 has deprecated calls.\n    'ignore:The `device` argument is deprecated and will be removed in v5 of Transformers.',  # hf layoutlmv3 calls deprecated hf.\n    \"ignore:the imp module is deprecated:DeprecationWarning:past\",  # ignore DeprecationWarning from hyperopt dependency\n    \"ignore:.*imp module.*:DeprecationWarning\",  # ignore DeprecationWarnings that involve imp module\n    \"ignore:The class LayoutLMv3FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv3ImageProcessor instead.\",  # huggingface layoutlmv3 has deprecated calls.\n    \"ignore:pkg_resources\",  # huggingface has deprecated calls.\n    'ignore:Deprecated call to `pkg_resources',  # huggingface has deprecated calls.\n    'ignore:distutils Version classes are deprecated.',  # faiss uses deprecated distutils.\n    'ignore:`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.',  # transformers calls deprecated hf_hub\n    \"ignore:`torch.cuda.amp.GradScaler\",  # GradScaler changes in torch 2.3.0 but we want to be backwards compatible.\n    \"ignore:`clean_up_tokenization_spaces` was not set\",  # Default behavior changes in transformers v4.45, raising irrelevant FutureWarning for serialized models.\n    \"ignore:1Torch was not compiled with flash attention\",  # You might want to install flash attention, but you don't have to.\n]\nmarkers = [\n    \"integration\",\n]\ntestpaths = [\"flair\", \"tests\"]\n[tool.mypy]\nignore_missing_imports = true\ndisable_error_code = [\"annotation-unchecked\"]\nexclude = [\".git/\", \".venv/\", \"__pycache__\", \"build\", \"venv\"]\nwarn_unused_ignores = true\n\n[[tool.mypy.overrides]]\nmodule=\"flair.embeddings.legacy\"\nignore_errors = true\n\n[tool.ruff]\nline-length = 120\ntarget-version = \"py39\"\n\n[tool.ruff.lint]\n#select = [\"ALL\"]    # Uncommit to autofix all the things\nselect = [\n  \"C4\",\n  \"COM\",\n  \"D\",\n  \"E\",\n  \"EXE\",\n  \"F\",\n  \"I\",\n  \"INP\",\n  \"ISC\",\n  \"NPY\",\n  \"PD\",\n  \"PGH\",\n  \"PIE\",\n  \"PLE\",\n  \"PYI\",\n  \"Q\",\n  \"RSE\",\n  \"RUF\",\n  \"SIM\",\n  \"T10\",\n  \"TID\",\n  \"UP\",\n  \"W\",\n  \"YTT\",\n]\n\nignore = [\n  \"COM812\", # Do not force trailing commas for function argument lists\n  \"D100\",   # Don't force presence of docstrings (D100-D107)\n  \"D101\",\n  \"D102\",\n  \"D103\",\n  \"D104\",\n  \"D105\",\n  \"D107\",\n  \"E501\",   # Ignore line too long\n  \"RUF012\",\n]\n\nunfixable = [\n  \"ERA\",    # Do not delete commented code\n  \"EXE001\", # Do not check python files for executability, doesn't work well on windows\n  \"EXE002\", # Do not check python files for executability, doesn't work well on windows\n  \"F841\",   # Do not remove unused variables automatically\n]\n\n[tool.ruff.lint.per-file-ignores]\n\"flair/embeddings/legacy.py\" = [\"D205\"]\n\"scripts/*\" = [\"INP001\"]  #  no need for __ini__ for scripts\n\"flair/datasets/*\" = [\"D417\"]  # need to fix datasets in a unified way later.\n\n[tool.ruff.lint.pydocstyle]\nconvention = \"google\"\n\n[tool.pydocstyle]\nmatch = \"^(?!legacy).*\\\\.py$\"\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.3212890625,
          "content": "black[jupyter]==24.2.*\nkonoha[janome]<6.0.0\nmypy>=1.2.0\npytest>=7.3.1\npytest-black-ng==0.4.*\npytest-github-actions-annotate-failures>=0.1.8\npytest-mypy>=0.10.3\npytest-ruff==0.3.*\nruff==0.7.*\ntypes-dataclasses>=0.6.6\ntypes-Deprecated>=1.2.9.2\ntypes-requests>=2.28.11.17\ntypes-tabulate>=0.9.0.2\npyab3p\ntransformers!=4.40.1,!=4.40.0"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.474609375,
          "content": "boto3>=1.20.27\nconllu>=4.0,<5.0.0\ndeprecated>=1.2.13\nftfy>=6.1.0\ngdown>=4.4.0\nhuggingface-hub>=0.10.0\nlangdetect>=1.0.9\nlxml>=4.8.0\nmatplotlib>=2.2.3\nmore-itertools>=8.13.0\nmpld3>=0.3\npptree>=3.1\npython-dateutil>=2.8.2\npytorch_revgrad>=0.2.0\nregex>=2022.1.18\nscikit-learn>=1.0.2\nsegtok>=1.5.11\nsqlitedict>=2.0.0\ntabulate>=0.8.10\ntorch>=1.5.0,!=1.8\ntqdm>=4.63.0\ntransformer-smaller-training-vocab>=0.2.3\ntransformers[sentencepiece]>=4.25.0,<5.0.0\nwikipedia-api>=0.5.7\nbioc<3.0.0,>=2.0.0\n"
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.7509765625,
          "content": "from pathlib import Path\n\nfrom setuptools import find_packages, setup\n\nrequired = Path(\"requirements.txt\").read_text(encoding=\"utf-8\").split(\"\\n\")\n\nsetup(\n    name=\"flair\",\n    version=\"0.15.0\",\n    description=\"A very simple framework for state-of-the-art NLP\",\n    long_description=Path(\"README.md\").read_text(encoding=\"utf-8\"),\n    long_description_content_type=\"text/markdown\",\n    author=\"Alan Akbik\",\n    author_email=\"alan.akbik@gmail.com\",\n    url=\"https://github.com/flairNLP/flair\",\n    packages=find_packages(exclude=[\"tests\", \"tests.*\"]),  # same as name\n    license=\"MIT\",\n    install_requires=required,\n    extras_require={\n        \"word-embeddings\": [\"gensim>=4.2.0\", \"bpemb>=0.3.5\"],\n    },\n    include_package_data=True,\n    python_requires=\">=3.9\",\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}