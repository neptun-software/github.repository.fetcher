{
  "metadata": {
    "timestamp": 1736561476049,
    "page": 23,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "keras-team/keras",
      "stars": 62346,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".devcontainer",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2509765625,
          "content": ".DS_Store\n*.pyc\n.vscode-test\n__pycache__\n**/.vscode-test/**\n**/.vscode test/**\n**/.vscode-smoke/**\n**/.venv*/\nbin/**\nbuild/**\nobj/**\n.pytest_cache\ntmp/**\n.vs/\ndist/**\n*.egg-info/*\n.vscode\nexamples/**/*.jpg\n.python-version\n.coverage\n*coverage.xml\n.ruff_cache"
        },
        {
          "name": ".kokoro",
          "type": "tree",
          "content": null
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 6.8056640625,
          "content": "Keras 3 is a high-velocity open-source project. We welcome contributions!\n\nContributions can be made in a variety of ways, including coding, enriching documentation, refining docstrings, and providing code examples.\n\n\n## Current items open for contributions\nAt [this link](https://github.com/keras-team/keras/issues/18442), you'll find a list of items where you help is needed!\n\n\n## How to contribute code\n\nFollow these steps to submit your code contribution.\n\n### Step 1. Open an issue\n\nBefore making any changes, we recommend opening an issue (if one doesn't already\nexist) and discussing your proposed changes. This way, we can give you feedback\nand validate the proposed changes.\n\nIf the changes are minor (simple bug fix or documentation fix), then feel free\nto open a Pull Request (PR) without discussion.\n\n### Step 2. Make code changes\n\nTo make code changes, you need to fork the repository. You will need to setup a\ndevelopment environment and run the unit tests. This is covered in the section\n\"Setup environment\".\n\n### Step 3. Create a pull request\n\nOnce the change is ready, open a pull request from your branch in your fork to\nthe master branch in [keras-team/keras](https://github.com/keras-team/keras).\n\n### Step 4. Sign the Contributor License Agreement\n\nAfter creating the pull request, the `cla/google` check will be performed and,\nif you haven't signed the Contributor License Agreement (CLA), it will fail with\ninstructions on how to do so. Please follow the instructions to sign the CLA and\nthe check will pass.\n\n![CLA signed](https://github.com/keras-team/keras/assets/1091026/71c26353-e3b5-4135-8bae-64693c717775)\n\n\n### Step 5. Code review\n\nIf the tests fail, look into the error messages and try to fix them.\n\n![CI tests](https://github.com/keras-team/keras/assets/1091026/6f6c17ef-6bd7-4e95-9fbc-1906cde37380)\n\nA reviewer will review the pull request and provide comments. There may be\nseveral rounds of comments and code changes before the pull request gets\napproved by the reviewer.\n\n![Approval from reviewer](https://github.com/keras-team/keras/assets/1091026/8d28f74c-21e9-4146-b0ff-62d649a552a8)\n\n### Step 6. Merging\n\nOnce the pull request is approved, a `ready to pull` tag will be added to the\npull request. A team member will take care of the merging.\n\n![Ready to pull and merged](https://github.com/keras-team/keras/assets/1091026/c3908345-d7ae-44ee-a428-01f3b448b46b)\n\nHere is an [example pull request](https://github.com/keras-team/keras/pull/18848)\nfor your reference.\n\n## Setup environment\n\nWe provide two ways of setting up a development environment. One is to use a\ndev container, and the other one is to set up a local environment by installing\nthe dev tools needed.\n\n### Option 1: GitHub Codespace or dev container\n\nWe support GitHub Codespaces, Visual Studio Code dev containers and JetBrain dev\ncontainers. Please see the\n[Dev container documentation](https://github.com/keras-team/keras/tree/master/.devcontainer).\n\n### Option 2: Set up a local environment\n\nTo set up your local dev environment, you will need the following tools.\n\n1.  [git](https://github.com/) for code repository management.\n2.  [python](https://www.python.org/) to build and code in Keras.\n\nThe following commands check the tools above are successfully installed. Note\nthat Keras requires at least Python 3.9 to run.\n\n```shell\ngit --version\npython --version\n```\n\nClone your forked repo to your local machine. Go to the cloned directory to\ninstall the dependencies.\n\n```shell\ngit clone https://github.com/YOUR_GITHUB_USERNAME/keras.git\ncd keras\npip install -r requirements.txt\n```\n\nYou then need to configure the backend to use, see the\n[Configuring your backend](https://github.com/keras-team/keras/blob/master/README.md#configuring-your-backend)\nsection of the README.\n\nYou can also add GPU support to your environment, see the\n[Adding GPU support](https://github.com/keras-team/keras/blob/master/README.md#adding-gpu-support)\nsection of the README.\n\n## Code style\n\nKeras uses [Ruff](https://docs.astral.sh/ruff/) to format the code. Please refer to\n[requirements-common.txt](https://github.com/keras-team/keras/blob/master/requirements-common.txt)\nfor the required versions. Run the following command **at the root directory of\nthe repo** to format your code.\n\n```\nsh shell/format.sh\n```\n\nIt will also display the errors that cannot be resolved by autoformatting. You\nneed to follow the output of the command to resolve them manually.\n\nIf you do not want to auto format the code but only show the lint errors, you\ncan run `sh shell/lint.sh` **at the root directory of the repo**.\n\n### Docstrings\n\nWe do not have an automated way to check docstring style, so if you write\nor edit any docstring, please make sure to check them manually.\nKeras docstrings follow the conventions below:\n\nA **class docstring** may contain the following items:\n\n* A one-line description of the class.\n* Paragraph(s) of more detailed information.\n* Optional `Examples` section.\n* `Args` section for arguments in `__init__()`.\n* If it's a layer:\n    * `Call arguments` section for arguments in `Layer.call()`.\n    * `Returns` section for the return values of `Layer.call()`.\n    * Optional `Raises` section for possible errors.\n\nYou can check out `MultiHeadAttention` as an example\n[(link)](https://github.com/keras-team/keras/blob/v3.0.0/keras/layers/attention/multi_head_attention.py#L20).\n\nA **function docstring** may contain the following items:\n\n* One-line description of the function.\n* Paragraph(s) of more detailed information.\n* Optional `Examples` section.\n* `Args` section for the function arguments.\n* `Returns` section for the return values.\n* Optional `Raises` section for possible errors.\n\nYou can check out `text_dataset_from_directory` as an example\n[(link)](https://github.com/keras-team/keras/blob/v3.0.0/keras/utils/text_dataset_utils.py#L27).\n\n## Run tests\n\nWe use [pytest](https://pytest.org/) to run the tests.\n\n### Run a test file\n\nTo run the tests in `keras/src/losses/losses_test.py`, use the following command\nat the root directory of the repo.\n\n```shell\npytest keras/src/losses/losses_test.py\n```\n\n### Run a single test case\n\nYou can specify a single test class to run within a file.\n\n```shell\npytest keras/src/losses/losses_test.py::MeanSquaredErrorTest\n```\n\nYou can also specify a single test method to run within a class.\n\n```shell\npytest keras/src/losses/losses_test.py::MeanSquaredErrorTest::test_sample_weighted\n```\n\n### Run all tests\n\nYou can run all the tests locally by running the following command in the repo\nroot directory.\n\n```shell\npytest keras\n```\n\nNote that you can skip the Keras applications tests using the\n`SKIP_APPLICATIONS_TESTS` environment variable. This will cut down the testing\ntime significantly.\n\n```shell\nSKIP_APPLICATIONS_TESTS=True pytest keras\n```\n\nTo run all tests using a different backend, you can simply specify it on the\ncommand line.\n\n```shell\nKERAS_BACKEND=jax SKIP_APPLICATIONS_TESTS=True pytest keras\n```\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.08984375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.970703125,
          "content": "# Keras 3: Deep Learning for Humans\n\nKeras 3 is a multi-backend deep learning framework, with support for JAX, TensorFlow, PyTorch, and OpenVINO (for inference-only).\nEffortlessly build and train models for computer vision, natural language processing, audio processing,\ntimeseries forecasting, recommender systems, etc.\n\n- **Accelerated model development**: Ship deep learning solutions faster thanks to the high-level UX of Keras\nand the availability of easy-to-debug runtimes like PyTorch or JAX eager execution.\n- **State-of-the-art performance**: By picking the backend that is the fastest for your model architecture (often JAX!),\nleverage speedups ranging from 20% to 350% compared to other frameworks. [Benchmark here](https://keras.io/getting_started/benchmarks/).\n- **Datacenter-scale training**: Scale confidently from your laptop to large clusters of GPUs or TPUs.\n\nJoin nearly three million developers, from burgeoning startups to global enterprises, in harnessing the power of Keras 3.\n\n\n## Installation\n\n### Install with pip\n\nKeras 3 is available on PyPI as `keras`. Note that Keras 2 remains available as the `tf-keras` package.\n\n1. Install `keras`:\n\n```\npip install keras --upgrade\n```\n\n2. Install backend package(s).\n\nTo use `keras`, you should also install the backend of choice: `tensorflow`, `jax`, or `torch`.\nNote that `tensorflow` is required for using certain Keras 3 features: certain preprocessing layers\nas well as `tf.data` pipelines.\n\n### Local installation\n\n#### Minimal installation\n\nKeras 3 is compatible with Linux and MacOS systems. For Windows users, we recommend using WSL2 to run Keras.\nTo install a local development version:\n\n1. Install dependencies:\n\n```\npip install -r requirements.txt\n```\n\n2. Run installation command from the root directory.\n\n```\npython pip_build.py --install\n```\n\n3. Run API generation script when creating PRs that update `keras_export` public APIs:\n\n```\n./shell/api_gen.sh\n```\n\n#### Adding GPU support\n\nThe `requirements.txt` file will install a CPU-only version of TensorFlow, JAX, and PyTorch. For GPU support, we also\nprovide a separate `requirements-{backend}-cuda.txt` for TensorFlow, JAX, and PyTorch. These install all CUDA\ndependencies via `pip` and expect a NVIDIA driver to be pre-installed. We recommend a clean python environment for each\nbackend to avoid CUDA version mismatches. As an example, here is how to create a Jax GPU environment with `conda`:\n\n```shell\nconda create -y -n keras-jax python=3.10\nconda activate keras-jax\npip install -r requirements-jax-cuda.txt\npython pip_build.py --install\n```\n\n## Configuring your backend\n\nYou can export the environment variable `KERAS_BACKEND` or you can edit your local config file at `~/.keras/keras.json`\nto configure your backend. Available backend options are: `\"tensorflow\"`, `\"jax\"`, `\"torch\"`, `\"openvino\"`. Example:\n\n```\nexport KERAS_BACKEND=\"jax\"\n```\n\nIn Colab, you can do:\n\n```python\nimport os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n\nimport keras\n```\n\n**Note:** The backend must be configured before importing `keras`, and the backend cannot be changed after \nthe package has been imported.\n\n**Note:** The OpenVINO backend is an inference-only backend, meaning it is designed only for running model\npredictions using `model.predict()` method.\nTo use `openvino` backend, install the required dependencies from the `requirements-openvino.txt` file.\n\n## Backwards compatibility\n\nKeras 3 is intended to work as a drop-in replacement for `tf.keras` (when using the TensorFlow backend). Just take your\nexisting `tf.keras` code, make sure that your calls to `model.save()` are using the up-to-date `.keras` format, and you're\ndone.\n\nIf your `tf.keras` model does not include custom components, you can start running it on top of JAX or PyTorch immediately.\n\nIf it does include custom components (e.g. custom layers or a custom `train_step()`), it is usually possible to convert it\nto a backend-agnostic implementation in just a few minutes.\n\nIn addition, Keras models can consume datasets in any format, regardless of the backend you're using:\nyou can train your models with your existing `tf.data.Dataset` pipelines or PyTorch `DataLoaders`.\n\n## Why use Keras 3?\n\n- Run your high-level Keras workflows on top of any framework -- benefiting at will from the advantages of each framework,\ne.g. the scalability and performance of JAX or the production ecosystem options of TensorFlow.\n- Write custom components (e.g. layers, models, metrics) that you can use in low-level workflows in any framework.\n    - You can take a Keras model and train it in a training loop written from scratch in native TF, JAX, or PyTorch.\n    - You can take a Keras model and use it as part of a PyTorch-native `Module` or as part of a JAX-native model function.\n- Make your ML code future-proof by avoiding framework lock-in.\n- As a PyTorch user: get access to power and usability of Keras, at last!\n- As a JAX user: get access to a fully-featured, battle-tested, well-documented modeling and training library.\n\n\nRead more in the [Keras 3 release announcement](https://keras.io/keras_3/).\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 5.033203125,
          "content": "# Security Policy\n\n - [**Using Keras Securely**](#using-keras-securely)\n   - [Untrusted inputs](#untrusted-inputs)\n   - [Data privacy](#data-privacy)\n   - [Untrusted environments or networks](#untrusted-environments-or-networks)\n   - [Multi-Tenant environments](#multi-tenant-environments)\n - [**Reporting a Vulnerability**](#reporting-a-vulnerability)\n\n## Using Keras Securely\n\n### Untrusted inputs\n\nSome models accept various input formats (text, images, audio, etc.). The libraries converting these inputs have varying security levels, so it's crucial to isolate the model and carefully pre-process inputs to mitigate script injection risks.\n\nFor maximum security when handling untrusted inputs, you may need to employ the following:\n\n* Sandboxing: Isolate the model process.\n* Pre-analysis: check how the model performs by default when exposed to prompt injection (e.g. using [fuzzing for prompt injection](https://github.com/FonduAI/awesome-prompt-injection?tab=readme-ov-file#tools)). This will give you leads on how hard you will have to work on the next topics.\n* Updates: Keep your model and libraries updated with the latest security patches.\n* Input Sanitation: Before feeding data to the model, sanitize inputs rigorously. This involves techniques such as:\n    * Validation: Enforce strict rules on allowed characters and data types.\n    * Filtering: Remove potentially malicious scripts or code fragments.\n    * Encoding: Convert special characters into safe representations.\n    * Verification: Run tooling that identifies potential script injections (e.g. [models that detect prompt injection attempts](https://python.langchain.com/docs/guides/safety/hugging_face_prompt_injection)). \n\n### Data privacy\nTo protect sensitive data from potential leaks or unauthorized access, it is essential to sandbox the model execution. This means running the model in a secure, isolated environment, which helps mitigate many attack vectors.\n\nWhen training the model with sensitive data, expose your newly-trained model to tests to identify potential sensitive data leaks.\n\n### Untrusted environments or networks\n\nIf you can't run your models in a secure and isolated environment or if it must be exposed to an untrusted network, make sure to take the following security precautions:\n* Confirm the hash of  any downloaded artifact (i.e. pre-trained model weights) matches a known-good value\n* Encrypt your data while sending it over the network.\n\n### Multi-Tenant environments\n\nIf you intend to run multiple models in parallel with shared memory, it is your responsibility to ensure the models do not interact or access each other's data. The primary areas of concern are tenant isolation, resource allocation, model sharing and hardware attacks.\n\n#### Tenant Isolation\n\nYou must make sure that models run separately. Since models can run code, it's important to use strong isolation methods to prevent unwanted access to the data from other tenants.\n\nSeparating networks is also a big part of isolation. If you keep model network traffic separate, you not only prevent unauthorized access to data or models, but also prevent malicious users or tenants sending graphs to execute under another tenantâ€™s identity.\n\n#### Resource Allocation\n\nA denial of service caused by one model can impact the overall system health. Implement safeguards like rate limits, access controls, and health monitoring.\n\n#### Model Sharing\n\nIn a multitenant design that allows sharing models, make sure that tenants and users fully understand the potential security risks involved. They must be aware that they will essentially be running code provided by other users. Unfortunately, there are no reliable methods available to detect malicious models, graphs, or checkpoints. To mitigate this risk, the recommended approach is to sandbox the model execution, effectively isolating it from the rest of the system.\n\n#### Hardware Attacks\n\nBesides the virtual environment, the hardware (GPUs or TPUs) can also be attacked. [Research](https://scholar.google.com/scholar?q=gpu+side+channel) has shown that side channel attacks on GPUs are possible, which can make data leak from other models or processes running on the same system at the same time.\n\n## Reporting a Vulnerability\n\nBeware that none of the topics under [Using Keras Securely](#using-keras-securely) are considered vulnerabilities of Keras.\n\nIf you have discovered a security vulnerability in this project, please report it\nprivately. **Do not disclose it as a public issue.** This gives us time to work with you\nto fix the issue before public exposure, reducing the chance that the exploit will be\nused before a patch is released.\n\nYou may submit the report in the following ways:\n\n- send an email to fchollet@google.com; and/or\n- send a [private vulnerability report](https://github.com/keras-team/keras/security/advisories/new)\n\nPlease provide the following information in your report:\n\n- A description of the vulnerability and its impact\n- How to reproduce the issue\n\nThis project is maintained by volunteers on a reasonable-effort basis. As such,\nplease give us 90 days to work on a fix before public exposure.\n"
        },
        {
          "name": "api_gen.py",
          "type": "blob",
          "size": 8.09375,
          "content": "\"\"\"Script to generate keras public API in `keras/api` directory.\n\nUsage:\n\nRun via `./shell/api_gen.sh`.\nIt generates API and formats user and generated APIs.\n\"\"\"\n\nimport importlib\nimport os\nimport re\nimport shutil\n\nimport namex\n\nPACKAGE = \"keras\"\nBUILD_DIR_NAME = \"tmp_build_dir\"\n\n\ndef ignore_files(_, filenames):\n    return [f for f in filenames if f.endswith(\"_test.py\")]\n\n\ndef copy_source_to_build_directory(root_path):\n    # Copy sources (`keras/` directory and setup files) to build dir\n    build_dir = os.path.join(root_path, BUILD_DIR_NAME)\n    if os.path.exists(build_dir):\n        shutil.rmtree(build_dir)\n    os.mkdir(build_dir)\n    shutil.copytree(\n        PACKAGE, os.path.join(build_dir, PACKAGE), ignore=ignore_files\n    )\n    return build_dir\n\n\ndef create_legacy_directory(package_dir):\n    src_dir = os.path.join(package_dir, \"src\")\n    api_dir = os.path.join(package_dir, \"api\")\n    # Make keras/_tf_keras/ by copying keras/\n    tf_keras_dirpath_parent = os.path.join(api_dir, \"_tf_keras\")\n    tf_keras_dirpath = os.path.join(tf_keras_dirpath_parent, \"keras\")\n    os.makedirs(tf_keras_dirpath, exist_ok=True)\n    with open(os.path.join(tf_keras_dirpath_parent, \"__init__.py\"), \"w\") as f:\n        f.write(\"from keras.api._tf_keras import keras\\n\")\n    with open(os.path.join(api_dir, \"__init__.py\")) as f:\n        init_file = f.read()\n        init_file = init_file.replace(\n            \"from keras.api import _legacy\",\n            \"from keras.api import _tf_keras\",\n        )\n    with open(os.path.join(api_dir, \"__init__.py\"), \"w\") as f:\n        f.write(init_file)\n    # Remove the import of `_tf_keras` in `keras/_tf_keras/keras/__init__.py`\n    init_file = init_file.replace(\"from keras.api import _tf_keras\\n\", \"\\n\")\n    with open(os.path.join(tf_keras_dirpath, \"__init__.py\"), \"w\") as f:\n        f.write(init_file)\n    for dirname in os.listdir(api_dir):\n        dirpath = os.path.join(api_dir, dirname)\n        if os.path.isdir(dirpath) and dirname not in (\n            \"_legacy\",\n            \"_tf_keras\",\n            \"src\",\n        ):\n            destpath = os.path.join(tf_keras_dirpath, dirname)\n            if os.path.exists(destpath):\n                shutil.rmtree(destpath)\n            shutil.copytree(\n                dirpath,\n                destpath,\n                ignore=ignore_files,\n            )\n\n    # Copy keras/_legacy/ file contents to keras/_tf_keras/keras\n    legacy_submodules = [\n        path[:-3]\n        for path in os.listdir(os.path.join(src_dir, \"legacy\"))\n        if path.endswith(\".py\")\n    ]\n    legacy_submodules += [\n        path\n        for path in os.listdir(os.path.join(src_dir, \"legacy\"))\n        if os.path.isdir(os.path.join(src_dir, \"legacy\", path))\n    ]\n    for root, _, fnames in os.walk(os.path.join(api_dir, \"_legacy\")):\n        for fname in fnames:\n            if fname.endswith(\".py\"):\n                legacy_fpath = os.path.join(root, fname)\n                tf_keras_root = root.replace(\"/_legacy\", \"/_tf_keras/keras\")\n                core_api_fpath = os.path.join(\n                    root.replace(\"/_legacy\", \"\"), fname\n                )\n                if not os.path.exists(tf_keras_root):\n                    os.makedirs(tf_keras_root)\n                tf_keras_fpath = os.path.join(tf_keras_root, fname)\n                with open(legacy_fpath) as f:\n                    legacy_contents = f.read()\n                    legacy_contents = legacy_contents.replace(\n                        \"keras.api._legacy\", \"keras.api._tf_keras.keras\"\n                    )\n                if os.path.exists(core_api_fpath):\n                    with open(core_api_fpath) as f:\n                        core_api_contents = f.read()\n                    core_api_contents = core_api_contents.replace(\n                        \"from keras.api import _tf_keras\\n\", \"\"\n                    )\n                    for legacy_submodule in legacy_submodules:\n                        core_api_contents = core_api_contents.replace(\n                            f\"from keras.api import {legacy_submodule}\\n\",\n                            \"\",\n                        )\n                        core_api_contents = core_api_contents.replace(\n                            f\"keras.api.{legacy_submodule}\",\n                            f\"keras.api._tf_keras.keras.{legacy_submodule}\",\n                        )\n                    # Remove duplicate generated comments string.\n                    legacy_contents = re.sub(r\"\\n\", r\"\\\\n\", legacy_contents)\n                    legacy_contents = re.sub('\"\"\".*\"\"\"', \"\", legacy_contents)\n                    legacy_contents = re.sub(r\"\\\\n\", r\"\\n\", legacy_contents)\n                    # If the same module is in legacy and core_api, use legacy\n                    legacy_imports = re.findall(\n                        r\"import (\\w+)\", legacy_contents\n                    )\n                    for import_name in legacy_imports:\n                        core_api_contents = re.sub(\n                            f\"\\n.* import {import_name}\\n\",\n                            r\"\\n\",\n                            core_api_contents,\n                        )\n                    legacy_contents = core_api_contents + \"\\n\" + legacy_contents\n                with open(tf_keras_fpath, \"w\") as f:\n                    f.write(legacy_contents)\n\n    # Delete keras/api/_legacy/\n    shutil.rmtree(os.path.join(api_dir, \"_legacy\"))\n\n\ndef export_version_string(api_init_fname):\n    with open(api_init_fname) as f:\n        contents = f.read()\n    with open(api_init_fname, \"w\") as f:\n        contents += \"from keras.src.version import __version__\\n\"\n        f.write(contents)\n\n\ndef update_package_init(template_fname, dest_fname, api_module):\n    with open(template_fname) as template_file:\n        with open(dest_fname, \"w\") as dest_file:\n            for line in template_file:\n                if \"# DO NOT EDIT.\" in line:\n                    dest_file.write(line)\n                    # Import all public symbols from `api/` and `__version__`.\n                    for symbol in api_module.__dict__.keys():\n                        if symbol.startswith(\"_\") and symbol != \"__version__\":\n                            continue\n                        dest_file.write(f\"from keras.api import {symbol}\\n\")\n                    # Skip the previous autogenerated block.\n                    for line in template_file:\n                        if \"# END DO NOT EDIT.\" in line:\n                            break\n                dest_file.write(line)\n\n\ndef build():\n    # Backup the `keras/__init__.py` and restore it on error in api gen.\n    root_path = os.path.dirname(os.path.abspath(__file__))\n    code_api_dir = os.path.join(root_path, PACKAGE, \"api\")\n    code_init_fname = os.path.join(root_path, PACKAGE, \"__init__.py\")\n    # Create temp build dir\n    build_dir = copy_source_to_build_directory(root_path)\n    build_api_dir = os.path.join(build_dir, PACKAGE, \"api\")\n    build_init_fname = os.path.join(build_dir, PACKAGE, \"__init__.py\")\n    build_api_init_fname = os.path.join(build_api_dir, \"__init__.py\")\n    try:\n        os.chdir(build_dir)\n        # Generates `keras/api` directory.\n        if os.path.exists(build_api_dir):\n            shutil.rmtree(build_api_dir)\n        if os.path.exists(build_init_fname):\n            os.remove(build_init_fname)\n        os.makedirs(build_api_dir)\n        namex.generate_api_files(\n            \"keras\", code_directory=\"src\", target_directory=\"api\"\n        )\n        # Add __version__ to `api/`.\n        export_version_string(build_api_init_fname)\n        # Creates `_tf_keras` with full keras API\n        create_legacy_directory(package_dir=os.path.join(build_dir, PACKAGE))\n        # Update toplevel init with all `api/` imports.\n        api_module = importlib.import_module(f\"{BUILD_DIR_NAME}.keras.api\")\n        update_package_init(code_init_fname, build_init_fname, api_module)\n        # Copy back the keras/api and keras/__init__.py from build directory\n        if os.path.exists(code_api_dir):\n            shutil.rmtree(code_api_dir)\n        shutil.copytree(build_api_dir, code_api_dir)\n        shutil.copy(build_init_fname, code_init_fname)\n    finally:\n        # Clean up: remove the build directory (no longer needed)\n        shutil.rmtree(build_dir)\n\n\nif __name__ == \"__main__\":\n    build()\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.646484375,
          "content": "coverage:\n  status:\n    project:\n      default:\n        # `auto` compares coverage with the base-commit\n        target: auto\n\n    patch:\n      default:\n        target:auto\n\ncomment:\n  layout: \"header, reach, diff, flags, files\"\n  behavior: default\n  require_changes: no\n  require_base: no\n  require_head: yes\n  show_carryforward_flags: yes\n\nflag_management:\n  default_rules:\n    carryforward: false\n    statuses:\n      - type: project\n        target: auto\n      - type: patch\n        target: auto\n  individual_flags:\n    - name: keras\n      paths:\n        - keras\n    - name: keras.applications\n      paths:\n        - keras/applications\n      carryforward: true\n"
        },
        {
          "name": "conftest.py",
          "type": "blob",
          "size": 1.1650390625,
          "content": "import os\n\n# When using jax.experimental.enable_x64 in unit test, we want to keep the\n# default dtype with 32 bits, aligning it with Keras's default.\nos.environ[\"JAX_DEFAULT_DTYPE_BITS\"] = \"32\"\n\ntry:\n    # When using torch and tensorflow, torch needs to be imported first,\n    # otherwise it will segfault upon import. This should force the torch\n    # import to happen first for all tests.\n    import torch  # noqa: F401\nexcept ImportError:\n    pass\n\nimport pytest  # noqa: E402\n\nfrom keras.src.backend import backend  # noqa: E402\n\n\ndef pytest_configure(config):\n    config.addinivalue_line(\n        \"markers\",\n        \"requires_trainable_backend: mark test for trainable backend only\",\n    )\n\n\ndef pytest_collection_modifyitems(config, items):\n    requires_trainable_backend = pytest.mark.skipif(\n        backend() == \"numpy\" or backend() == \"openvino\",\n        reason=\"Trainer not implemented for NumPy and OpenVINO backend.\",\n    )\n    for item in items:\n        if \"requires_trainable_backend\" in item.keywords:\n            item.add_marker(requires_trainable_backend)\n\n\ndef skip_if_backend(given_backend, reason):\n    return pytest.mark.skipif(backend() == given_backend, reason=reason)\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "guides",
          "type": "tree",
          "content": null
        },
        {
          "name": "integration_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "keras",
          "type": "tree",
          "content": null
        },
        {
          "name": "pip_build.py",
          "type": "blob",
          "size": 5.10546875,
          "content": "\"\"\"Script to create (and optionally install) a `.whl` archive for Keras 3.\n\nUsage:\n\n1. Create a `.whl` file in `dist/`:\n\n```\npython3 pip_build.py\n```\n\n2. Also install the new package immediately after:\n\n```\npython3 pip_build.py --install\n```\n\"\"\"\n\nimport argparse\nimport datetime\nimport glob\nimport os\nimport pathlib\nimport re\nimport shutil\n\n# Needed because importing torch after TF causes the runtime to crash\nimport torch  # noqa: F401\n\npackage = \"keras\"\nbuild_directory = \"tmp_build_dir\"\ndist_directory = \"dist\"\nto_copy = [\"pyproject.toml\", \"README.md\"]\n\n\ndef export_version_string(version, is_nightly=False, rc_index=None):\n    \"\"\"Export Version and Package Name.\"\"\"\n    if is_nightly:\n        date = datetime.datetime.now()\n        version += f\".dev{date:%Y%m%d%H}\"\n        # Update `name = \"keras\"` with \"keras-nightly\"\n        pyproj_pth = pathlib.Path(\"pyproject.toml\")\n        pyproj_str = pyproj_pth.read_text().replace(\n            'name = \"keras\"', 'name = \"keras-nightly\"'\n        )\n        pyproj_pth.write_text(pyproj_str)\n    elif rc_index is not None:\n        version += \"rc\" + str(rc_index)\n\n    # Make sure to export the __version__ string\n    with open(os.path.join(package, \"src\", \"version.py\")) as f:\n        init_contents = f.read()\n    with open(os.path.join(package, \"src\", \"version.py\"), \"w\") as f:\n        init_contents = re.sub(\n            \"\\n__version__ = .*\\n\",\n            f'\\n__version__ = \"{version}\"\\n',\n            init_contents,\n        )\n        f.write(init_contents)\n\n\ndef ignore_files(_, filenames):\n    return [f for f in filenames if f.endswith(\"_test.py\")]\n\n\ndef copy_source_to_build_directory(root_path):\n    # Copy sources (`keras/` directory and setup files) to build\n    # directory\n    os.chdir(root_path)\n    os.mkdir(build_directory)\n    shutil.copytree(\n        package, os.path.join(build_directory, package), ignore=ignore_files\n    )\n    for fname in to_copy:\n        shutil.copy(fname, os.path.join(f\"{build_directory}\", fname))\n    os.chdir(build_directory)\n\n\ndef build(root_path, is_nightly=False, rc_index=None):\n    if os.path.exists(build_directory):\n        raise ValueError(f\"Directory already exists: {build_directory}\")\n\n    try:\n        copy_source_to_build_directory(root_path)\n        move_tf_keras_directory()\n\n        from keras.src.version import __version__  # noqa: E402\n\n        export_version_string(__version__, is_nightly, rc_index)\n        return build_and_save_output(root_path, __version__)\n    finally:\n        # Clean up: remove the build directory (no longer needed)\n        shutil.rmtree(build_directory)\n\n\ndef move_tf_keras_directory():\n    \"\"\"Move `keras/api/_tf_keras` to `keras/_tf_keras`, update references.\"\"\"\n    shutil.move(os.path.join(package, \"api\", \"_tf_keras\"), \"keras\")\n    with open(os.path.join(package, \"api\", \"__init__.py\")) as f:\n        contents = f.read()\n        contents = contents.replace(\"from keras.api import _tf_keras\", \"\")\n    with open(os.path.join(package, \"api\", \"__init__.py\"), \"w\") as f:\n        f.write(contents)\n    # Replace `keras.api._tf_keras` with `keras._tf_keras`.\n    for root, _, fnames in os.walk(os.path.join(package, \"_tf_keras\")):\n        for fname in fnames:\n            if fname.endswith(\".py\"):\n                tf_keras_fpath = os.path.join(root, fname)\n                with open(tf_keras_fpath) as f:\n                    contents = f.read()\n                    contents = contents.replace(\n                        \"keras.api._tf_keras\", \"keras._tf_keras\"\n                    )\n                with open(tf_keras_fpath, \"w\") as f:\n                    f.write(contents)\n\n\ndef build_and_save_output(root_path, __version__):\n    # Build the package\n    os.system(\"python3 -m build\")\n\n    # Save the dist files generated by the build process\n    os.chdir(root_path)\n    if not os.path.exists(dist_directory):\n        os.mkdir(dist_directory)\n    for fpath in glob.glob(\n        os.path.join(build_directory, dist_directory, \"*.*\")\n    ):\n        shutil.copy(fpath, dist_directory)\n\n    # Find the .whl file path\n    whl_path = None\n    for fname in os.listdir(dist_directory):\n        if __version__ in fname and fname.endswith(\".whl\"):\n            whl_path = os.path.abspath(os.path.join(dist_directory, fname))\n    if whl_path:\n        print(f\"Build successful. Wheel file available at {whl_path}\")\n    else:\n        print(\"Build failed.\")\n    return whl_path\n\n\ndef install_whl(whl_fpath):\n    print(f\"Installing wheel file: {whl_fpath}\")\n    os.system(f\"pip3 install {whl_fpath} --force-reinstall --no-dependencies\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--install\",\n        action=\"store_true\",\n        help=\"Whether to install the generated wheel file.\",\n    )\n    parser.add_argument(\n        \"--nightly\",\n        action=\"store_true\",\n        help=\"Whether to generate nightly wheel file.\",\n    )\n    parser.add_argument(\n        \"--rc\",\n        type=int,\n        help=\"Specify `[0-9] when generating RC wheels.\",\n    )\n    args = parser.parse_args()\n    root_path = pathlib.Path(__file__).parent.resolve()\n    whl_path = build(root_path, args.nightly, args.rc)\n    if whl_path and args.install:\n        install_whl(whl_path)\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 2.4736328125,
          "content": "[build-system]\nrequires = [\"setuptools >=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"keras\"\nauthors = [\n    {name = \"Keras team\", email = \"keras-users@googlegroups.com\"},\n]\ndescription = \"Multi-backend Keras\"\nreadme = \"README.md\"\nrequires-python = \">=3.9\"\nlicense = {text = \"Apache License 2.0\"}\ndynamic = [\"version\"]\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Operating System :: Unix\",\n    \"Operating System :: MacOS\",\n    \"Intended Audience :: Science/Research\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Software Development\",\n]\ndependencies = [\n    \"absl-py\",\n    \"numpy\",\n    \"rich\",\n    \"namex\",\n    \"h5py\",\n    \"optree\",\n    \"ml-dtypes\",\n    \"packaging\",\n]\n# Run also: pip install -r requirements.txt\n\n[project.urls]\nHome = \"https://keras.io/\"\nRepository = \"https://github.com/keras-team/keras\"\n\n[tool.setuptools.dynamic]\nversion = {attr = \"keras.src.version.__version__\"}\n\n[tool.setuptools.packages.find]\ninclude = [\"keras\", \"keras.*\"]\n\n[tool.ruff]\nline-length = 80\n\n[tool.ruff.lint]\nselect = [\n    \"E\",  # pycodestyle error\n    \"F\",  # Pyflakes\n    \"I\",  # isort\n]\nignore = [\n    \"E722\",  # do not use bare 'except'\n    \"E741\",  # ambiguous variable name\n    \"E731\",  # do not assign a `lambda` expression, use a `def`\n]\n\n[tool.ruff.lint.per-file-ignores]\n\"**/__init__.py\" = [\"E501\", \"F401\"]  # lines too long; imported but unused\n\"**/random.py\" = [\"F401\"]  # imported but unused\n\"examples/*\" = [\"I\", \"E\"]\n\"guides/*\" = [\"I\", \"E\", \"F\"]\n\n[tool.ruff.lint.isort]\nforce-single-line = true\nknown-first-party = [\"keras\"]\n\n[tool.pytest.ini_options]\nfilterwarnings = [\n    \"error\",\n    \"ignore::DeprecationWarning\",\n    \"ignore::ImportWarning\",\n    \"ignore::RuntimeWarning\",\n    \"ignore::PendingDeprecationWarning\",\n    \"ignore::FutureWarning\",\n    \"ignore::UserWarning\",\n    # Ignore a spurious warning on tf-nightly related to save model changes.\n    \"ignore:Custom mask layers require a config\",\n]\naddopts = \"-vv\"\n\n# Do not run tests in the `build` folders\nnorecursedirs = [\"build\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"@abstract\",\n    \"raise NotImplementedError\",\n]\nomit = [\n    \"*/*_test.py\",\n    \"keras/src/legacy/*\",\n]\n\n[tool.coverage.run]\nbranch = true\nomit = [\n    \"*/*_test.py\",\n    \"keras/src/legacy/*\",\n]\n\n"
        },
        {
          "name": "requirements-common.txt",
          "type": "blob",
          "size": 0.2578125,
          "content": "namex>=0.0.8\nruff\npytest\nnumpy\nscipy\nscikit-learn\npandas\nabsl-py\nrequests\nh5py\nml-dtypes\nprotobuf\ngoogle\ntensorboard-plugin-profile\nrich\nbuild\noptree\npytest-cov\npackaging\n# for tree_test.py\ndm_tree\ncoverage!=7.6.5  # 7.6.5 breaks CI\n# for onnx_test.py\nonnxruntime\n"
        },
        {
          "name": "requirements-jax-cuda.txt",
          "type": "blob",
          "size": 0.412109375,
          "content": "# Tensorflow cpu-only version (needed for testing).\ntensorflow-cpu~=2.18.0\ntf2onnx\n\n# Torch cpu-only version (needed for testing).\n--extra-index-url https://download.pytorch.org/whl/cpu\ntorch>=2.1.0\ntorchvision>=0.16.0\ntorch-xla\n\n# Jax with cuda support.\n# TODO: Higher version breaks CI.\n--find-links https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\njax[cuda12]==0.4.28\nflax\n\n-r requirements-common.txt\n"
        },
        {
          "name": "requirements-openvino.txt",
          "type": "blob",
          "size": 0.0595703125,
          "content": "# OpenVINO\nopenvino\n\n# All testing deps.\n-r requirements.txt\n"
        },
        {
          "name": "requirements-tensorflow-cuda.txt",
          "type": "blob",
          "size": 0.291015625,
          "content": "# Tensorflow with cuda support.\ntensorflow[and-cuda]~=2.18.0\ntf2onnx\n\n# Torch cpu-only version (needed for testing).\n--extra-index-url https://download.pytorch.org/whl/cpu\ntorch>=2.1.0\ntorchvision>=0.16.0\ntorch-xla\n\n# Jax cpu-only version (needed for testing).\njax[cpu]\n\n-r requirements-common.txt\n"
        },
        {
          "name": "requirements-torch-cuda.txt",
          "type": "blob",
          "size": 0.298828125,
          "content": "# Tensorflow cpu-only version (needed for testing).\ntensorflow-cpu~=2.18.0\ntf2onnx\n\n# Torch with cuda support.\n--extra-index-url https://download.pytorch.org/whl/cu121\ntorch==2.5.1+cu121\ntorchvision==0.20.1+cu121\ntorch-xla\n\n# Jax cpu-only version (needed for testing).\njax[cpu]\n\n-r requirements-common.txt\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3330078125,
          "content": "# Tensorflow.\ntensorflow-cpu~=2.18.0;sys_platform != 'darwin'\ntensorflow~=2.18.0;sys_platform == 'darwin'\ntf_keras\ntf2onnx\n\n# Torch.\n# TODO: Pin to < 2.3.0 (GitHub issue #19602)\n--extra-index-url https://download.pytorch.org/whl/cpu\ntorch>=2.1.0\ntorchvision>=0.16.0\ntorch-xla\n\n# Jax.\njax[cpu]\nflax\n\n# Common deps.\n-r requirements-common.txt\n"
        },
        {
          "name": "shell",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}