{
  "metadata": {
    "timestamp": 1736559702135,
    "page": 386,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Kwai-Kolors/Kolors",
      "stars": 4085,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0361328125,
          "content": "weights\n*.egg-info\n__pycache__\n*.pyc\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MODEL_LICENSE",
          "type": "blob",
          "size": 15.2138671875,
          "content": "ä¸­æ–‡ç‰ˆ\næ¨¡å‹è®¸å¯åè®®\næ¨¡å‹å‘å¸ƒæ—¥æœŸï¼š2024/7/6\n\né€šè¿‡ç‚¹å‡»åŒæ„æˆ–ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆ†å‘ã€è¡¨æ¼”æˆ–å±•ç¤ºæ¨¡å‹ä½œå“çš„ä»»ä½•éƒ¨åˆ†æˆ–å…ƒç´ ï¼Œæ‚¨å°†è¢«è§†ä¸ºå·²æ‰¿è®¤å¹¶æ¥å—æœ¬åè®®çš„å†…å®¹ï¼Œæœ¬åè®®ç«‹å³ç”Ÿæ•ˆã€‚\n\n1.å®šä¹‰ã€‚\na. â€œåè®®â€æŒ‡æœ¬åè®®ä¸­æ‰€è§„å®šçš„ä½¿ç”¨ã€å¤åˆ¶ã€åˆ†å‘ã€ä¿®æ”¹ã€è¡¨æ¼”å’Œå±•ç¤ºæ¨¡å‹ä½œå“æˆ–å…¶ä»»ä½•éƒ¨åˆ†æˆ–å…ƒç´ çš„æ¡æ¬¾å’Œæ¡ä»¶ã€‚\nb. â€œææ–™â€æ˜¯æŒ‡æ ¹æ®æœ¬åè®®æä¾›çš„ä¸“æœ‰çš„æ¨¡å‹å’Œæ–‡æ¡£ï¼ˆåŠå…¶ä»»ä½•éƒ¨åˆ†ï¼‰çš„ç»Ÿç§°ã€‚\nc. â€œæ¨¡å‹â€æŒ‡å¤§å‹è¯­è¨€æ¨¡å‹ã€å›¾åƒ/è§†é¢‘/éŸ³é¢‘/3D ç”Ÿæˆæ¨¡å‹ã€å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åŠå…¶è½¯ä»¶å’Œç®—æ³•ï¼ŒåŒ…æ‹¬è®­ç»ƒåçš„æ¨¡å‹æƒé‡ã€å‚æ•°ï¼ˆåŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ã€æœºå™¨å­¦ä¹ æ¨¡å‹ä»£ç ã€æ¨ç†æ”¯æŒä»£ç ã€è®­ç»ƒæ”¯æŒä»£ç ã€å¾®è°ƒæ”¯æŒä»£ç ä»¥åŠæˆ‘ä»¬å…¬å¼€æä¾›çš„å‰è¿°å…¶ä»–å…ƒç´ ã€‚\nd.  â€œè¾“å‡ºâ€æ˜¯æŒ‡é€šè¿‡æ“ä½œæˆ–ä»¥å…¶ä»–æ–¹å¼ä½¿ç”¨æ¨¡å‹æˆ–æ¨¡å‹è¡ç”Ÿå“è€Œäº§ç”Ÿçš„æ¨¡å‹æˆ–æ¨¡å‹è¡ç”Ÿå“çš„ä¿¡æ¯å’Œ/æˆ–å†…å®¹è¾“å‡ºã€‚\ne.  â€œæ¨¡å‹è¡ç”Ÿå“â€åŒ…æ‹¬ï¼š(i)å¯¹æ¨¡å‹æˆ–ä»»ä½•æ¨¡å‹è¡ç”Ÿç‰©çš„ä¿®æ”¹ï¼›(ii)åŸºäºæ¨¡å‹çš„ä»»ä½•æ¨¡å‹è¡ç”Ÿç‰©çš„ä½œå“ï¼›æˆ–(iii)é€šè¿‡å°†æ¨¡å‹æˆ–æ¨¡å‹çš„ä»»ä½•æ¨¡å‹è¡ç”Ÿç‰©çš„æƒé‡ã€å‚æ•°ã€æ“ä½œæˆ–è¾“å‡ºçš„æ¨¡å¼è½¬ç§»åˆ°è¯¥æ¨¡å‹è€Œåˆ›å»ºçš„ä»»ä½•å…¶ä»–æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä»¥ä½¿è¯¥æ¨¡å‹çš„æ€§èƒ½ç±»ä¼¼äºæ¨¡å‹æˆ–æ¨¡å‹è¡ç”Ÿç‰©ã€‚ä¸ºæ¸…æ¥šèµ·è§ï¼Œè¾“å‡ºæœ¬èº«ä¸è¢«è§†ä¸ºæ¨¡å‹è¡ç”Ÿç‰©ã€‚\nf. â€œæ¨¡å‹ä½œå“â€åŒ…æ‹¬ï¼š(i)ææ–™ï¼›(ii)æ¨¡å‹è¡ç”Ÿå“ï¼›åŠ(iii)å…¶æ‰€æœ‰è¡ç”Ÿä½œå“ã€‚\ng. â€œè®¸å¯äººâ€æˆ–â€œæˆ‘ä»¬â€æŒ‡ä½œå“æ‰€æœ‰è€…æˆ–ä½œå“æ‰€æœ‰è€…æˆæƒçš„æˆäºˆè®¸å¯çš„å®ä½“ï¼ŒåŒ…æ‹¬å¯èƒ½å¯¹æ¨¡å‹å’Œ/æˆ–åˆ†å‘æ¨¡å‹æ‹¥æœ‰æƒåˆ©çš„ä¸ªäººæˆ–å®ä½“ã€‚\nh.â€œè¢«è®¸å¯äººâ€ã€â€œæ‚¨â€æˆ–â€œæ‚¨çš„â€æ˜¯æŒ‡è¡Œä½¿æœ¬åè®®æˆäºˆçš„æƒåˆ©å’Œ/æˆ–ä¸ºä»»ä½•ç›®çš„å’Œåœ¨ä»»ä½•ä½¿ç”¨é¢†åŸŸä½¿ç”¨æ¨¡å‹ä½œå“çš„è‡ªç„¶äººæˆ–æ³•äººå®ä½“ã€‚\ni.â€œç¬¬ä¸‰æ–¹â€æ˜¯æŒ‡ä¸å—æˆ‘ä»¬æˆ–æ‚¨å…±åŒæ§åˆ¶çš„ä¸ªäººæˆ–æ³•äººå®ä½“ã€‚\n\n2. è®¸å¯å†…å®¹ã€‚\na.æˆ‘ä»¬æˆäºˆæ‚¨éæ’ä»–æ€§çš„ã€å…¨çƒæ€§çš„ã€ä¸å¯è½¬è®©çš„ã€å…ç‰ˆç¨çš„è®¸å¯ï¼ˆåœ¨æˆ‘ä»¬çš„çŸ¥è¯†äº§æƒæˆ–æˆ‘ä»¬æ‹¥æœ‰çš„ä½“ç°åœ¨ææ–™ä¸­æˆ–åˆ©ç”¨ææ–™çš„å…¶ä»–æƒåˆ©çš„èŒƒå›´å†…ï¼‰ï¼Œå…è®¸æ‚¨ä»…æ ¹æ®æœ¬åè®®çš„æ¡æ¬¾ä½¿ç”¨ã€å¤åˆ¶ã€åˆ†å‘ã€åˆ›ä½œè¡ç”Ÿä½œå“ï¼ˆåŒ…æ‹¬æ¨¡å‹è¡ç”Ÿå“ï¼‰å’Œå¯¹ææ–™è¿›è¡Œä¿®æ”¹ï¼Œå¹¶ä¸”æ‚¨ä¸å¾—è¿åï¼ˆæˆ–é¼“åŠ±ã€æˆ–å…è®¸ä»»ä½•å…¶ä»–äººè¿åï¼‰æœ¬åè®®çš„ä»»ä½•æ¡æ¬¾ã€‚\nb.åœ¨éµå®ˆæœ¬åè®®çš„å‰æä¸‹ï¼Œæ‚¨å¯ä»¥åˆ†å‘æˆ–å‘ç¬¬ä¸‰æ–¹æä¾›æ¨¡å‹ä½œå“ï¼Œæ‚¨é¡»æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š\nï¼ˆiï¼‰æ‚¨å¿…é¡»å‘æ‰€æœ‰è¯¥æ¨¡å‹ä½œå“æˆ–ä½¿ç”¨è¯¥ä½œå“çš„äº§å“æˆ–æœåŠ¡çš„ä»»ä½•ç¬¬ä¸‰æ–¹æ¥æ”¶è€…æä¾›æ¨¡å‹ä½œå“çš„æ¥æºå’Œæœ¬åè®®çš„å‰¯æœ¬ï¼›\nï¼ˆiiï¼‰æ‚¨å¿…é¡»åœ¨ä»»ä½•ä¿®æ”¹è¿‡çš„æ–‡æ¡£ä¸Šé™„åŠ æ˜æ˜¾çš„å£°æ˜ï¼Œè¯´æ˜æ‚¨æ›´æ”¹äº†è¿™äº›æ–‡æ¡£ï¼›\nï¼ˆiiiï¼‰æ‚¨å¯ä»¥åœ¨æ‚¨çš„ä¿®æ”¹ä¸­æ·»åŠ æ‚¨è‡ªå·±çš„ç‰ˆæƒå£°æ˜ï¼Œå¹¶ä¸”ï¼Œåœ¨æ‚¨å¯¹è¯¥ä½œå“çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆ†å‘ã€è¡¨æ¼”å’Œå±•ç¤ºç¬¦åˆæœ¬åè®®çš„æ¡æ¬¾å’Œæ¡ä»¶çš„å‰æä¸‹ï¼Œæ‚¨å¯ä»¥ä¸ºæ‚¨çš„ä¿®æ”¹æˆ–ä»»ä½•æ­¤ç±»æ¨¡å‹è¡ç”Ÿå“çš„ä½¿ç”¨ã€å¤åˆ¶æˆ–åˆ†å‘æä¾›é¢å¤–æˆ–ä¸åŒçš„è®¸å¯æ¡æ¬¾å’Œæ¡ä»¶ã€‚\nc. é™„åŠ å•†ä¸šæ¡æ¬¾ï¼šè‹¥æ‚¨æˆ–å…¶å…³è”æ–¹æä¾›çš„æ‰€æœ‰äº§å“æˆ–æœåŠ¡çš„æœˆæ´»è·ƒç”¨æˆ·æ•°åœ¨å‰ä¸€ä¸ªè‡ªç„¶æœˆæœªè¶…è¿‡3äº¿æœˆæ´»è·ƒç”¨æˆ·æ•°ï¼Œåˆ™æ‚¨å‘è®¸å¯æ–¹è¿›è¡Œç™»è®°ï¼Œå°†è¢«è§†ä¸ºè·å¾—ç›¸åº”çš„å•†ä¸šè®¸å¯ï¼›è‹¥æ‚¨æˆ–å…¶å…³è”æ–¹æä¾›çš„æ‰€æœ‰äº§å“æˆ–æœåŠ¡çš„æœˆæ´»è·ƒç”¨æˆ·æ•°åœ¨å‰ä¸€ä¸ªè‡ªç„¶æœˆè¶…è¿‡3äº¿æœˆæ´»è·ƒç”¨æˆ·æ•°ï¼Œåˆ™æ‚¨å¿…é¡»å‘è®¸å¯äººç”³è¯·è®¸å¯ï¼Œè®¸å¯äººå¯è‡ªè¡Œå†³å®šå‘æ‚¨æˆäºˆè®¸å¯ã€‚é™¤éè®¸å¯äººå¦è¡Œæ˜ç¡®æˆäºˆæ‚¨è¯¥ç­‰æƒåˆ©ï¼Œå¦åˆ™æ‚¨æ— æƒè¡Œä½¿æœ¬åè®®é¡¹ä¸‹çš„ä»»ä½•æƒåˆ©ã€‚\n\n3.ä½¿ç”¨é™åˆ¶ã€‚\na. æ‚¨å¯¹æœ¬æ¨¡å‹ä½œå“çš„ä½¿ç”¨å¿…é¡»éµå®ˆé€‚ç”¨æ³•å¾‹æ³•è§„ï¼ˆåŒ…æ‹¬è´¸æ˜“åˆè§„æ³•å¾‹æ³•è§„ï¼‰ï¼Œå¹¶éµå®ˆã€ŠæœåŠ¡åè®®ã€‹(https://kolors.kuaishou.com/agreement)ã€‚æ‚¨å¿…é¡»å°†æœ¬ç¬¬ 3(a) å’Œ 3(b) æ¡ä¸­æåŠçš„ä½¿ç”¨é™åˆ¶ä½œä¸ºå¯æ‰§è¡Œæ¡æ¬¾çº³å…¥ä»»ä½•è§„èŒƒæœ¬æ¨¡å‹ä½œå“ä½¿ç”¨å’Œ/æˆ–åˆ†å‘çš„åè®®ï¼ˆä¾‹å¦‚è®¸å¯åè®®ã€ä½¿ç”¨æ¡æ¬¾ç­‰ï¼‰ï¼Œå¹¶ä¸”æ‚¨å¿…é¡»å‘æ‚¨åˆ†å‘çš„åç»­ç”¨æˆ·å‘å‡ºé€šçŸ¥ï¼Œå‘ŠçŸ¥å…¶æœ¬æ¨¡å‹ä½œå“å—æœ¬ç¬¬ 3(a) å’Œ 3(b) æ¡ä¸­çš„ä½¿ç”¨é™åˆ¶çº¦æŸã€‚\nb. æ‚¨ä¸å¾—ä½¿ç”¨æœ¬æ¨¡å‹ä½œå“æˆ–æœ¬æ¨¡å‹ä½œå“çš„ä»»ä½•è¾“å‡ºæˆ–æˆæœæ¥æ”¹è¿›ä»»ä½•å…¶ä»–æ¨¡å‹ï¼ˆæœ¬æ¨¡å‹æˆ–å…¶æ¨¡å‹è¡ç”Ÿå“é™¤å¤–ï¼‰ã€‚\n\n4.çŸ¥è¯†äº§æƒã€‚\na. æˆ‘ä»¬ä¿ç•™ææ–™çš„æ‰€æœ‰æƒåŠå…¶ç›¸å…³çŸ¥è¯†äº§æƒã€‚åœ¨éµå®ˆæœ¬åè®®æ¡æ¬¾å’Œæ¡ä»¶çš„å‰æä¸‹ï¼Œå¯¹äºæ‚¨åˆ¶ä½œçš„ææ–™çš„ä»»ä½•è¡ç”Ÿä½œå“å’Œä¿®æ”¹ï¼Œæ‚¨æ˜¯ä¸”å°†æ˜¯æ­¤ç±»è¡ç”Ÿä½œå“å’Œä¿®æ”¹çš„æ‰€æœ‰è€…ã€‚\nb.  æœ¬åè®®ä¸æˆäºˆä»»ä½•å•†æ ‡ã€å•†å·ã€æœåŠ¡æ ‡è®°æˆ–äº§å“åç§°çš„æ ‡è¯†è®¸å¯ï¼Œé™¤éå‡ºäºæè¿°å’Œåˆ†å‘æœ¬æ¨¡å‹ä½œå“çš„åˆç†å’Œæƒ¯å¸¸ç”¨é€”ã€‚\nc. å¦‚æœæ‚¨å¯¹æˆ‘ä»¬æˆ–ä»»ä½•ä¸ªäººæˆ–å®ä½“æèµ·è¯‰è®¼æˆ–å…¶ä»–ç¨‹åºï¼ˆåŒ…æ‹¬è¯‰è®¼ä¸­çš„äº¤å‰ç´¢èµ”æˆ–åç´¢èµ”ï¼‰ï¼Œå£°ç§°ææ–™æˆ–ä»»ä½•è¾“å‡ºæˆ–ä»»ä½•ä¸Šè¿°å†…å®¹çš„ä»»ä½•éƒ¨åˆ†ä¾µçŠ¯æ‚¨æ‹¥æœ‰æˆ–å¯è®¸å¯çš„ä»»ä½•çŸ¥è¯†äº§æƒæˆ–å…¶ä»–æƒåˆ©ï¼Œåˆ™æ ¹æ®æœ¬åè®®æˆäºˆæ‚¨çš„æ‰€æœ‰è®¸å¯åº”äºæèµ·æ­¤ç±»è¯‰è®¼æˆ–å…¶ä»–ç¨‹åºä¹‹æ—¥èµ·ç»ˆæ­¢ã€‚\n\n5. å…è´£å£°æ˜å’Œè´£ä»»é™åˆ¶ã€‚\na.  æœ¬æ¨¡å‹ä½œå“åŠå…¶ä»»ä½•è¾“å‡ºå’Œç»“æœæŒ‰â€œåŸæ ·â€æä¾›ï¼Œä¸ä½œä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯ï¼ŒåŒ…æ‹¬é€‚é”€æ€§ã€éä¾µæƒæ€§æˆ–é€‚ç”¨äºç‰¹å®šç”¨é€”çš„ä¿è¯ã€‚æˆ‘ä»¬ä¸å¯¹ææ–™åŠå…¶ä»»ä½•è¾“å‡ºçš„å®‰å…¨æ€§æˆ–ç¨³å®šæ€§ä½œä»»ä½•ä¿è¯ï¼Œä¹Ÿä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚\nb. åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å‡ä¸å¯¹æ‚¨æ‰¿æ‹…ä»»ä½•æŸå®³èµ”å¿è´£ä»»ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå› æ‚¨ä½¿ç”¨æˆ–æ— æ³•ä½¿ç”¨ææ–™æˆ–å…¶ä»»ä½•è¾“å‡ºè€Œé€ æˆçš„ä»»ä½•ç›´æ¥ã€é—´æ¥ã€ç‰¹æ®Šæˆ–åæœæ€§æŸå®³èµ”å¿è´£ä»»ï¼Œæ— è®ºè¯¥æŸå®³èµ”å¿è´£ä»»æ˜¯å¦‚ä½•é€ æˆçš„ã€‚\nc. å¯¹äºå› æ‚¨ä½¿ç”¨æˆ–åˆ†å‘æ¨¡å‹çš„è¡ç”Ÿç‰©è€Œå¼•èµ·çš„æˆ–ä¸ä¹‹ç›¸å…³çš„ä»»ä½•ç¬¬ä¸‰æ–¹ç´¢èµ”ï¼Œæ‚¨åº”æä¾›è¾©æŠ¤ï¼Œèµ”å¿ï¼Œå¹¶ä½¿æˆ‘æ–¹å…å—æŸå®³ã€‚\n\n6. å­˜ç»­å’Œç»ˆæ­¢ã€‚\na. æœ¬åè®®æœŸé™è‡ªæ‚¨æ¥å—æœ¬åè®®æˆ–è®¿é—®ææ–™ä¹‹æ—¥èµ·å¼€å§‹ï¼Œå¹¶å°†æŒç»­å®Œå…¨æœ‰æ•ˆï¼Œç›´è‡³æ ¹æ®æœ¬åè®®æ¡æ¬¾å’Œæ¡ä»¶ç»ˆæ­¢ã€‚\nb. å¦‚æœæ‚¨è¿åæœ¬åè®®çš„ä»»ä½•æ¡æ¬¾æˆ–æ¡ä»¶ï¼Œæˆ‘ä»¬å¯ç»ˆæ­¢æœ¬åè®®ã€‚æœ¬åè®®ç»ˆæ­¢åï¼Œæ‚¨å¿…é¡»ç«‹å³åˆ é™¤å¹¶åœæ­¢ä½¿ç”¨æœ¬æ¨¡å‹ä½œå“ã€‚ç¬¬ 4(a)ã€4(c)ã€5å’Œ 7 æ¡åœ¨æœ¬åè®®ç»ˆæ­¢åä»ç„¶æœ‰æ•ˆã€‚\n\n7. é€‚ç”¨æ³•å¾‹å’Œç®¡è¾–æƒã€‚\na. æœ¬åè®®åŠç”±æœ¬åè®®å¼•èµ·çš„æˆ–ä¸æœ¬åè®®æœ‰å…³çš„ä»»ä½•äº‰è®®å‡å—ä¸­åäººæ°‘å…±å’Œå›½å¤§é™†åœ°åŒºï¼ˆä»…ä¸ºæœ¬åè®®ç›®çš„ï¼Œä¸åŒ…æ‹¬é¦™æ¸¯ã€æ¾³é—¨å’Œå°æ¹¾ï¼‰æ³•å¾‹ç®¡è¾–ï¼Œå¹¶æ’é™¤å†²çªæ³•çš„é€‚ç”¨ï¼Œä¸”ã€Šè”åˆå›½å›½é™…è´§ç‰©é”€å”®åˆåŒå…¬çº¦ã€‹ä¸é€‚ç”¨äºæœ¬åè®®ã€‚\nb. å› æœ¬åè®®å¼•èµ·æˆ–ä¸æœ¬åè®®æœ‰å…³çš„ä»»ä½•äº‰è®®ï¼Œç”±è®¸å¯äººä½æ‰€åœ°äººæ°‘æ³•é™¢ç®¡è¾–ã€‚\n\nè¯·æ³¨æ„ï¼Œè®¸å¯è¯å¯èƒ½ä¼šæ›´æ–°åˆ°æ›´å…¨é¢çš„ç‰ˆæœ¬ã€‚ æœ‰å…³è®¸å¯å’Œç‰ˆæƒçš„ä»»ä½•é—®é¢˜ï¼Œè¯·é€šè¿‡ kwai-kolors@kuaishou.com ä¸æˆ‘ä»¬è”ç³»ã€‚\nâ€ƒ\n \nè‹±æ–‡ç‰ˆ\n\nMODEL LICENSE AGREEMENT\nRelease Date: 2024/7/6\nBy clicking to agree or by using, reproducing, modifying, distributing, performing or displaying any portion or element of the Model Works, You will be deemed to have recognized and accepted the content of this Agreement, which is effective immediately.\n1.   \tDEFINITIONS.\na.    \tâ€œAgreementâ€ shall mean the terms and conditions for use, reproduction, distribution, modification, performance and displaying of the Model Works or any portion or element thereof set forth herein.\nb.   \tâ€œMaterialsâ€ shall mean, collectively, Us proprietary the Model and Documentation (and any portion thereof) as made available by Us under this Agreement.\nc.  \tâ€œModelâ€ shall mean the large language models, image/video/audio/3D generation models, and multimodal large language models and their software and algorithms, including trained model weights, parameters (including optimizer states), machine-learning model code, inference-enabling code, training-enabling code, fine-tuning enabling code and other elements of the foregoing made publicly available by Us .\nd.   \tâ€œOutputâ€ shall mean the information and/or content output of Model or a Model Derivative that results from operating or otherwise using Model or a Model Derivative.\ne.    \tâ€œModel Derivativesâ€ shall mean all: (i) modifications to the Model or any Model Derivative; (ii) works based on the Model or any Model Derivative; or (iii) any other machine learning model which is created by transfer of patterns of the weights, parameters, operations, or Output of the Model or any Model Derivative, to that model in order to cause that model to perform similarly to the Model or a Model Derivative, including distillation methods, methods that use intermediate data representations, or methods based on the generation of synthetic data Outputs or a Model Derivative for training that model. For clarity, Outputs by themselves are not deemed Model Derivatives.\nf.    \tâ€œModel Worksâ€ shall mean: (i) the Materials; (ii) Model Derivatives; and (iii) all derivative works thereof.\ng.   \tâ€œLicensorâ€ , â€œWeâ€ or â€œUsâ€ shall mean the copyright owner or entity authorized by the copyright owner that is granting the License, including the persons or entities that may have rights in the Model and/or distributing the Model.\nh.   \tâ€œLicenseeâ€,  â€œYouâ€ or â€œYourâ€ shall mean a natural person or legal entity exercising the rights granted by this Agreement and/or using the Model Works for any purpose and in any field of use.\ni.    \tâ€œThird Partyâ€ or â€œThird Partiesâ€ shall mean individuals or legal entities that are not under common control with Us or You.\n\n2.   \tLICENSE CONTENT.\na.    \tWe grant You a non-exclusive, worldwide, non-transferable and royalty-free limited license under the intellectual property or other rights owned by Us embodied in or utilized by the Materials to use, reproduce, distribute, create derivative works of (including Model Derivatives), and make modifications to the Materials, only in accordance with the terms of this Agreement and the Acceptable Use Policy, and You must not violate (or encourage or permit anyone else to violate) any term of this Agreement or the Acceptable Use Policy.\nb.   \tYou may, subject to Your compliance with this Agreement, distribute or make available to Third Parties the Model Works, provided that You meet all of the following conditions:\n (i)\tYou must provide all such Third Party recipients of the Model Works or products or services using them the source of the Model and a copy of this Agreement;\n(ii)    You must cause any modified documents to carry prominent notices stating that You changed the documents;\n(iii)\tYou may add Your own copyright statement to Your modifications and, may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Model Derivatives as a whole, provided Your use, reproduction, modification, distribution, performance and display of the work otherwise complies with the terms and conditions of this Agreement.\nc.    \tadditional commercial terms: If, the monthly active users of all products or services made available by or for You, or Your affiliates, does not exceed 300 million monthly active users in the preceding calendar month, Your registration with the Licensor will be deemed to have obtained the corresponding business license; If, the monthly active users of all products or services made available by or for You, or Your affiliates,  is greater than 300 million monthly active users in the preceding calendar month, You must request a license from Licensor, which the Licensor may grant to You in its sole discretion, and You are not authorized to exercise any of the rights under this Agreement unless or until We otherwise expressly grants You such rights.\n\n3.   \tLICENSE RESTRICITIONS.\na.    \tYour use of the Model Works must comply with applicable laws and regulations (including trade compliance laws and regulations) and adhere to the Service Agreement. You must include the use restrictions referenced in these Sections 3(a) and 3(b) as an enforceable provision in any agreement (e.g., license agreement, terms of use, etc.) governing the use and/or distribution of Model Works and You must provide notice to subsequent users to whom You distribute that Model Works are subject to the use restrictions in these Sections 3(a) and 3(b).\nb.   \tYou must not use the Model Works or any Output or results of the Model Works to improve any other large  model (other than Model or Model Derivatives thereof).\n4.   \tINTELLECTUAL PROPERTY.\na.    \tWe retain ownership of all intellectual property rights in and to the Model and derivatives. Conditioned upon compliance with the terms and conditions of this Agreement, with respect to any derivative works and modifications of the Materials that are made by You, You are and will be the owner of such derivative works and modifications.\nb.  \tNo trademark license is granted to use the trade names, trademarks, service marks, or product names of Us, except as required to fulfill notice requirements under this Agreement or as required for reasonable and customary use in describing and redistributing the Materials.\nc.    \tIf You commence a lawsuit or other proceedings (including a cross-claim or counterclaim in a lawsuit) against Us or any person or entity alleging that the Materials or any Output, or any portion of any of the foregoing, infringe any intellectual property or other right owned or licensable by You, then all licenses granted to You under this Agreement shall terminate as of the date such lawsuit or other proceeding is filed. \n5.   \tDISCLAIMERS OF WARRANTY AND LIMITATIONS OF LIABILITY.\na. THE MODEL WORKS AND ANY OUTPUT AND RESULTS THERE FROM ARE PROVIDED  \"AS IS\" WITHOUT ANY EXPRESS OR IMPLIED WARRANTY OF ANY KIND INCLUDING WARRANTIES OF MERCHANTABILITY, NONINFRINGEMENT, OR FITNESS FOR A PARTICULAR PURPOSE. WE MAKE NO WARRANTY AND ASSUME NO RESPONSIBILITY FOR THE SAFETY OR STABILITY OF THE MATERIALS AND ANY OUTPUT THEREFROM.\nb.   IN NO EVENT SHALL WE BE LIABLE TO YOU FOR ANY DAMAGES, INCLUDING, BUT NOT LIMITED TO ANY DIRECT, OR INDIRECT, SPECIAL OR CONSEQUENTIAL DAMAGES ARISING FROM YOUR USE OR INABILITY TO USE THE MATERIALS OR ANY OUTPUT OF IT, NO MATTER HOW ITâ€™S CAUSED.\nc. You will defend, indemnify and hold harmless Us from and against any claim by any third party arising out of or related to Your use or distribution of the Materials.\n\n6.   \tSURVIVAL AND TERMINATION.\na.  The term of this Agreement shall commence upon Your acceptance of this Agreement or access to the Materials and will continue in full force and effect until terminated in accordance with the terms and conditions herein.\nb.  We may terminate this Agreement if You breach any of the terms or conditions of this Agreement. Upon termination of this Agreement, You must promptly delete and cease use of the Model Works. Sections 4(a), 4(c), 5 and 7 shall survive the termination of this Agreement.\n7.   \tGOVERNING LAW AND JURISDICTION.\na.   This Agreement and any dispute arising out of or relating to it will be governed by the laws of China (for the purpose of this agreement only, excluding Hong Kong, Macau, and Taiwan), without regard to conflict of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement.\nb.   Any disputes arising from or related to this Agreement shall be under the jurisdiction of the People's Court where the Licensor is located. \n\nNote that the license is subject to update to a more comprehensive version.  For any questions related to the license and copyright, please contact us at kwai-kolors@kuaishou.com.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 18.7822265625,
          "content": "<p align=\"left\">\n    English</a>&nbsp ï½œ &nbsp<a href=\"README_CN.md\">ä¸­æ–‡</a>&nbsp\n</p>\n<br><br>\n\n<p align=\"center\">\n    <img src=\"imgs/logo.png\" width=\"400\"/>\n<p>\n<br>\n\n\n<div align=\"center\">\n  <a href='https://huggingface.co/Kwai-Kolors/Kolors'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-HF-yellow'></a> &ensp;\n  <a href=\"https://github.com/Kwai-Kolors/Kolors\"><img src=\"https://img.shields.io/static/v1?label=Kolors Code&message=Github&color=blue&logo=github-pages\"></a> &ensp;\n  <a href=\"https://kwai-kolors.github.io/\"><img src=\"https://img.shields.io/static/v1?label=Team%20Page&message=Page&color=green\"></a> &ensp;\n\n<a href='https://huggingface.co/spaces/Kwai-Kolors/Kolors '><img src='https://img.shields.io/badge/%F0%9F%A4%97%20HF Space-HF-yellow'></a> &ensp;\n  <a href=\"https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf\"><img src=\"https://img.shields.io/static/v1?label=Tech Report&message=Arxiv:Kolors&color=red&logo=arxiv\"></a> &ensp;\n  <a href=\"https://kolors.kuaishou.com/\"><img src=\"https://img.shields.io/static/v1?label=Official Website&message=Page&color=green\"></a> &ensp;\n</div>\n\n\n\n# Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis\n<figure>\n  <img src=\"imgs/head_final3.png\">\n</figure>\n<br><br>\n\n## Contents\n\n- [ğŸ‰ News](#News)\n- [ğŸ“‘ Open-source Plan](#open-source-plan)\n- [ğŸ“– Introduction](#Introduction)\n- [ğŸ“Š Evaluation ğŸ¥‡ğŸ¥‡ğŸ”¥ğŸ”¥](#Evaluation)\n- [ğŸ¥ Visualization](#Visualization)\n- [ğŸ› ï¸ Usage](#Usage)\n- [ğŸ“œ License & Citation & Acknowledgments](#License)\n<br><br>\n\n\n## <a name=\"News\"></a>ğŸ‰ News\n* 2024.11.13 ğŸ”¥ [Kolors-Portrait-with-Flux](https://huggingface.co/spaces/Kwai-Kolors/Kolors-Portrait-with-Flux) and [Kolors-Character-With-Flux](https://huggingface.co/spaces/Kwai-Kolors/Kolors-Character-With-Flux), which enable to preserve identity, are available on HuggingFace Space for free trials! Hope you enjoy it!\n* 2024.09.01 ğŸ”¥ Kolors-Virtual-Try-On, a virtual try-on demo based on Kolors is released! Enjoy trying on [Kolors-Virtual-Try-On](https://huggingface.co/spaces/Kwai-Kolors/Kolors-Virtual-Try-On), [WeChat post](https://mp.weixin.qq.com/s/Wk_Eq7OAywlrPqNC6zWZJQ).\n\n* 2024.08.06 ğŸ”¥ Pose ControlNet is released! Please check [ControlNet(Pose)](./controlnet/) for more details.\n\n* 2024.08.01 ğŸ”¥ The Kolors-Dreambooth-LoRA training and inference code is released! Please check [Dreambooth-LoRA](./dreambooth/) for more details.\n  \n* 2024.07.31 ğŸ”¥ The Kolors-IP-Adapter-FaceID-Plus weights and inference code is released! Please check [IP-Adapter-FaceID-Plus](./ipadapter_FaceID/) for more details.\n\n* 2024.07.26 ğŸ”¥ ControlNet and Inpainting Model are released! Please check [ControlNet(Canny, Depth)](./controlnet/) and [Inpainting Model](./inpainting/) for more details.\n\n\n* 2024.07.17 ğŸ”¥ The Kolors-IP-Adapter-Plus weights and infernce code is released! Please check [IP-Adapter-Plus](./ipadapter/) for more details.\n\n* 2024.07.12 ğŸ¤— Kolors is now available in **Diffusers**! Please check [kolors-diffusers](https://huggingface.co/Kwai-Kolors/Kolors-diffusers) or the [example](#using-with-diffusers) below for detail! Thanks to the Diffusers team for their technical support.\n* 2024.07.10 ğŸ¤– Kolors supports [ModelScope](https://modelscope.cn/models/Kwai-Kolors/Kolors).\n* 2024.07.09 ğŸ’¥ Kolors supports [ComfyUI](https://github.com/comfyanonymous/ComfyUI#manual-install-windows-linux). Thanks to [@kijai](https://github.com/kijai/ComfyUI-KwaiKolorsWrapper) with his great work.\n* 2024.07.06 ğŸ”¥ğŸ”¥ğŸ”¥ We release **Kolors**, a large text-to-image model trained on billions of text-image pairs. This model is bilingual in both Chinese and English, and supports a context length of 256 tokens. For more technical details, please refer to [technical report](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf).\n* 2024.07.03 ğŸ“Š Kolors won the second place on [FlagEval Multimodal Text-to-Image Leaderboard](https://flageval.baai.ac.cn/#/leaderboard/multimodal?kind=t2i), excelling particularly in the Chinese and English subjective quality assessment where Kolors took the first place.\n* 2024.07.02 ğŸ‰ Congratulations! Our paper on controllable video generation, [DragAnything: Motion Control for Anything using Entity Representation](https://arxiv.org/abs/2403.07420), have been accepted by ECCV 2024.\n* 2024.02.08 ğŸ‰ Congratulations! Our paper on generative model evaluation, [Learning Multi-dimensional Human Preference for Text-to-Image Generation](https://wangbohan97.github.io/MPS/), have been accepted by CVPR 2024.\n<br><br>\n\n## <a name=\"open-source-plan\"></a>ğŸ“‘ Open-source Plan\n\n- Kolors (Text-to-Image Model)\n  - [x] Inference \n  - [x] Checkpoints \n  - [x] IP-Adapter\n  - [x] ControlNet (Canny, Depth)\n  - [x] Inpainting\n  - [x] IP-Adapter-FaceID\n  - [x] LoRA\n  - [x] ControlNet (Pose)\n- [x] ComfyUI\n- [x] Gradio\n- [x] Diffusers\n<br><br>\n\n## \n## <a name=\"Introduction\"></a>ğŸ“– Introduction\n\nKolors is a large-scale text-to-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. Trained on billions of text-image pairs, Kolors exhibits significant advantages over both open-source and closed-source models in visual quality, complex semantic accuracy, and text rendering for both Chinese and English characters. Furthermore, Kolors supports both Chinese and English inputs, demonstrating strong performance in understanding and generating Chinese-specific content. For more details, please refer to this <a href=\"https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf\">technical report</a></b>.\n<br><br>\n\n## <a name=\"Evaluation\"></a>ğŸ“Š Evaluation\nWe have collected a comprehensive text-to-image evaluation dataset named KolorsPrompts to compare Kolors with other state-of-the-art open models and closed-source models. KolorsPrompts includes over 1,000 prompts across 14 catagories and 12 evaluation dimensions. The evaluation process incorporates both human and machine assessments. In relevant benchmark evaluations, Kolors demonstrated highly competitive performance, achieving industry-leading standards.\n\n<br><br>\n\n### Human Assessment\n\nFor the human evaluation, we invited 50 imagery experts to conduct comparative evaluations of the results generated by different models. The experts rated the generated images based on three criteria: visual appeal, text faithfulness, and overall satisfaction. In the evaluation, Kolors achieved the highest overall satisfaction score and significantly led in visual appeal compared to other models.\n\n|       Model       | Average Overall Satisfaction | Average Visual Appeal | Average Text Faithfulness |\n| :--------------: | :--------: | :--------: | :--------: |\n|  Adobe-Firefly   |    3.03    |    3.46    |    3.84    |\n| Stable Diffusion 3 |    3.26    |    3.50    |    4.20    |\n|     DALL-E 3      |    3.32    |    3.54    |    4.22    |\n|  Midjourney-v5   |    3.32    |    3.68    |    4.02    |\n| Playground-v2.5  |    3.37    |    3.73    |    4.04    |\n|  Midjourney-v6   |    3.58    |    3.92    |    4.18    |\n|    **Kolors**    |    **3.59**    |    **3.99**    |    **4.17**    |\n\n------\n\n<div style=\"color: gray; font-size: small;\">\n\n**All model results are tested with the April 2024 product versions**\n\n</div>\n<br>\n\n### Machine Assessment\nWe used [MPS](https://arxiv.org/abs/2405.14705) (Multi-dimensional Human Preference Score) on KolorsPrompts as the evaluation metric for machine assessment. Kolors achieved the highest MPS score, which is consistent with the results of the human evaluations.\n\n<div style=\"text-align:center\">\n\n| Models            | Overall MPS |\n|:-------------------:|:-------------:|\n| Adobe-Firefly     | 8.5     |\n| Stable Diffusion 3  | 8.9      |\n| DALL-E 3           |   9.0    |\n| Midjourney-v5     | 9.4      |\n| Playground-v2.5   | 9.8      |\n| Midjourney-v6     | 10.2      |\n| **Kolors**        | **10.3**      |\n</div>\n\n\n<br>\n\nFor more experimental results and details, please refer to our [technical report](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf).\n\n<br><br>\n\n\n## <a name=\"Visualization\"></a>ğŸ¥ Visualization\n\n* **High-quality Portrait**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/zl8.png\" />\n</div>\n<br>\n\n* **Chinese Elements Generation**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/cn_all.png\"/>\n</div>\n<br>\n\n* **Complex Semantic Understanding**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/fz_all.png\"/>\n</div>\n<br>\n\n* **Text Rendering**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/wz_all.png\" />\n</div>\n<br>\n</div>\n\nThe visualized case prompts mentioned above can be accessed [here](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/prompt_vis.txt). \n<br><br>\n\n## <a name=\"Usage\"></a>ğŸ› ï¸ Usage\n\n### Requirements\n\n* Python 3.8 or later\n* PyTorch 1.13.1 or later\n* Transformers 4.26.1 or later\n* Recommended: CUDA 11.7 or later\n<br>\n\n1. Repository Cloning and Dependency Installation\n\n```bash\napt-get install git-lfs\ngit clone https://github.com/Kwai-Kolors/Kolors\ncd Kolors\nconda create --name kolors python=3.8\nconda activate kolors\npip install -r requirements.txt\npython3 setup.py install\n```\n2. Weights downloadï¼ˆ[link](https://huggingface.co/Kwai-Kolors/Kolors)ï¼‰ï¼š\n```bash\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors --local-dir weights/Kolors\n```\nor\n```bash\ngit lfs clone https://huggingface.co/Kwai-Kolors/Kolors weights/Kolors\n```\n3. Inferenceï¼š\n```bash\npython3 scripts/sample.py \"ä¸€å¼ ç“¢è™«çš„ç…§ç‰‡ï¼Œå¾®è·ï¼Œå˜ç„¦ï¼Œé«˜è´¨é‡ï¼Œç”µå½±ï¼Œæ‹¿ç€ä¸€ä¸ªç‰Œå­ï¼Œå†™ç€â€œå¯å›¾â€\"\n# The image will be saved to \"scripts/outputs/sample_text.jpg\"\n```\n4. Web demoï¼š\n```bash\npython3 scripts/sampleui.py\n```\n\n### Using with Diffusers\nMake sure you upgrade to the latest version(0.30.0.dev0) of diffusers: \n```\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npython3 setup.py install\n```\n**Notes:**\n- The pipeline uses the `EulerDiscreteScheduler` by default. We recommend using this scheduler with `guidance scale=5.0` and `num_inference_steps=50`.\n- The pipeline also supports the `EDMDPMSolverMultistepScheduler`. `guidance scale=5.0` and `num_inference_steps=25` is a good default for this scheduler.\n- In addition to Text-to-Image, `KolorsImg2ImgPipeline` also supports Image-to-Image.\n\nAnd then you can run:\n```python\nimport torch\nfrom diffusers import KolorsPipeline\npipe = KolorsPipeline.from_pretrained(\n    \"Kwai-Kolors/Kolors-diffusers\", \n    torch_dtype=torch.float16, \n    variant=\"fp16\"\n).to(\"cuda\")\nprompt = 'ä¸€å¼ ç“¢è™«çš„ç…§ç‰‡ï¼Œå¾®è·ï¼Œå˜ç„¦ï¼Œé«˜è´¨é‡ï¼Œç”µå½±ï¼Œæ‹¿ç€ä¸€ä¸ªç‰Œå­ï¼Œå†™ç€\"å¯å›¾\"'\nimage = pipe(\n    prompt=prompt,\n    negative_prompt=\"\",\n    guidance_scale=5.0,\n    num_inference_steps=50,\n    generator=torch.Generator(pipe.device).manual_seed(66),\n).images[0]\nimage.show()\n```\n\n### IP-Adapter-Plus\n\nWe provide IP-Adapter-Plus weights and inference code, detailed in the [ipadapter](./ipadapter/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-IP-Adapter-Plus --local-dir weights/Kolors-IP-Adapter-Plus\n```\n\n```bash\n# Inferenceï¼š\npython3 ipadapter/sample_ipadapter_plus.py ./ipadapter/asset/test_ip.jpg \"ç©¿ç€é»‘è‰²Tæ¤è¡«ï¼Œä¸Šé¢ä¸­æ–‡ç»¿è‰²å¤§å­—å†™ç€â€œå¯å›¾â€\"\n\npython3 ipadapter/sample_ipadapter_plus.py ./ipadapter/asset/test_ip2.png \"ä¸€åªå¯çˆ±çš„å°ç‹—åœ¨å¥”è·‘\"\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n### ControlNet\n\nWe provide three ControlNet weights and inference code, detailed in the [controlnet](./controlnet/README.md).\n\n```bash\n# Weights download\n\n# Canny - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Canny --local-dir weights/Kolors-ControlNet-Canny\n\n# Depth - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Depth --local-dir weights/Kolors-ControlNet-Depth\n\n# Pose - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Pose --local-dir weights/Kolors-ControlNet-Pose\n```\n\nIf you intend to utilize the depth estimation network, please make sure to download its corresponding model weights.\n```\nhuggingface-cli download lllyasviel/Annotators ./dpt_hybrid-midas-501f0c75.pt --local-dir ./controlnet/annotator/ckpts\n```\n\nThanks to [DWPose](https://github.com/IDEA-Research/DWPose/tree/onnx?tab=readme-ov-file), you can utilize the pose estimation network. Please download the Pose model dw-ll_ucoco_384.onnx ([baidu](https://pan.baidu.com/s/1nuBjw-KKSxD_BkpmwXUJiw?pwd=28d7), [google](https://drive.google.com/file/d/12L8E2oAgZy4VACGSK9RaZBZrfgx7VTA2/view?usp=sharing)) and Det model yolox_l.onnx ([baidu](https://pan.baidu.com/s/1fpfIVpv5ypo4c1bUlzkMYQ?pwd=mjdn), [google](https://drive.google.com/file/d/1w9pXC8tT0p9ndMN-CArp1__b2GbzewWI/view?usp=sharing)). Then please put them into `controlnet/annotator/ckpts/`.\n\n\n```bash\n# Inferenceï¼š\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_1.png ä¸€ä¸ªæ¼‚äº®çš„å¥³å­©ï¼Œé«˜å“è´¨ï¼Œè¶…æ¸…æ™°ï¼Œè‰²å½©é²œè‰³ï¼Œè¶…é«˜åˆ†è¾¨ç‡ï¼Œæœ€ä½³å“è´¨ï¼Œ8kï¼Œé«˜æ¸…ï¼Œ4K Canny\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_2.png æ–°æµ·è¯šé£æ ¼ï¼Œä¸°å¯Œçš„è‰²å½©ï¼Œç©¿ç€ç»¿è‰²è¡¬è¡«çš„å¥³äººç«™åœ¨ç”°é‡é‡Œï¼Œå”¯ç¾é£æ™¯ï¼Œæ¸…æ–°æ˜äº®ï¼Œæ–‘é©³çš„å…‰å½±ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…ç»†èŠ‚ï¼Œ8Kç”»è´¨ Depth\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_3.png ä¸€ä½ç©¿ç€ç´«è‰²æ³¡æ³¡è¢–è¿è¡£è£™ã€æˆ´ç€çš‡å† å’Œç™½è‰²è•¾ä¸æ‰‹å¥—çš„å¥³å­©åŒæ‰‹æ‰˜è„¸ï¼Œé«˜å“è´¨ï¼Œè¶…æ¸…æ™°ï¼Œè‰²å½©é²œè‰³ï¼Œè¶…é«˜åˆ†è¾¨ç‡ï¼Œæœ€ä½³å“è´¨ï¼Œ8kï¼Œé«˜æ¸…ï¼Œ4K Pose\n\n# The image will be saved to \"controlnet/outputs/\"\n```\n\n\n### Inpainting\n\nWe provide Inpainting weights and inference code, detailed in the [inpainting](./inpainting/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-Inpainting --local-dir weights/Kolors-Inpainting\n```\n\n```bash\n# Inferenceï¼š\npython3 inpainting/sample_inpainting.py ./inpainting/asset/3.png ./inpainting/asset/3_mask.png ç©¿ç€ç¾å°‘å¥³æˆ˜å£«çš„è¡£æœï¼Œä¸€ä»¶ç±»ä¼¼äºæ°´æ‰‹æœé£æ ¼çš„è¡£æœï¼ŒåŒ…æ‹¬ä¸€ä¸ªç™½è‰²ç´§èº«ä¸Šè¡£ï¼Œå‰èƒ¸æ­é…ä¸€ä¸ªå¤§å¤§çš„çº¢è‰²è´è¶ç»“ã€‚è¡£æœçš„é¢†å­éƒ¨åˆ†å‘ˆè“è‰²ï¼Œå¹¶ä¸”æœ‰ç™½è‰²æ¡çº¹ã€‚å¥¹è¿˜ç©¿ç€ä¸€æ¡è“è‰²ç™¾è¤¶è£™ï¼Œè¶…é«˜æ¸…ï¼Œè¾›çƒ·æ¸²æŸ“ï¼Œé«˜çº§è´¨æ„Ÿï¼Œ32kï¼Œé«˜åˆ†è¾¨ç‡ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…çº§ç»†èŠ‚ï¼Œæ™¯æ·±\n\npython3 inpainting/sample_inpainting.py ./inpainting/asset/4.png ./inpainting/asset/4_mask.png ç©¿ç€é’¢é“ä¾ çš„è¡£æœï¼Œé«˜ç§‘æŠ€ç›”ç”²ï¼Œä¸»è¦é¢œè‰²ä¸ºçº¢è‰²å’Œé‡‘è‰²ï¼Œå¹¶ä¸”æœ‰ä¸€äº›é“¶è‰²è£…é¥°ã€‚èƒ¸å‰æœ‰ä¸€ä¸ªäº®èµ·çš„åœ†å½¢ååº”å †è£…ç½®ï¼Œå……æ»¡äº†æœªæ¥ç§‘æŠ€æ„Ÿã€‚è¶…æ¸…æ™°ï¼Œé«˜è´¨é‡ï¼Œè¶…é€¼çœŸï¼Œé«˜åˆ†è¾¨ç‡ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…çº§ç»†èŠ‚ï¼Œæ™¯æ·±\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n### IP-Adapter-FaceID-Plus\n\nWe provide IP-Adapter-FaceID-Plus weights and inference code, detailed in the [ipadapter_FaceID](./ipadapter_FaceID/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus --local-dir weights/Kolors-IP-Adapter-FaceID-Plus\n```\n\n```bash\n# Inferenceï¼š\npython ipadapter_FaceID/sample_ipadapter_faceid_plus.py ./ipadapter_FaceID/assets/image1.png \"ç©¿ç€æ™šç¤¼æœï¼Œåœ¨æ˜Ÿå…‰ä¸‹çš„æ™šå®´åœºæ™¯ä¸­ï¼Œçƒ›å…‰é—ªé—ªï¼Œæ•´ä¸ªåœºæ™¯æ´‹æº¢ç€æµªæ¼«è€Œå¥¢åçš„æ°›å›´\"\n\npython ipadapter_FaceID/sample_ipadapter_faceid_plus.py ./ipadapter_FaceID/assets/image2.png \"è¥¿éƒ¨ç‰›ä»”ï¼Œç‰›ä»”å¸½ï¼Œè’é‡å¤§é•–å®¢ï¼ŒèƒŒæ™¯æ˜¯è¥¿éƒ¨å°é•‡ï¼Œä»™äººæŒï¼Œ,æ—¥è½ä½™æ™–, æš–è‰²è°ƒ, ä½¿ç”¨XT4èƒ¶ç‰‡æ‹æ‘„, å™ªç‚¹, æ™•å½±, æŸ¯è¾¾èƒ¶å·ï¼Œå¤å¤\"\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n### Dreambooth-LoRA\n\nWe provide LoRA training and inference code, detailed in the [Dreambooth-LoRA](./dreambooth/README.md).\n\n```bash\n# Training:\nsh train.sh\n```\n\n```bash\n# Inferenceï¼š\npython infer_dreambooth.py \"ktxlç‹—åœ¨è‰åœ°ä¸Šè·‘\"\n```\n\n<br><br>\n\n## <a name=\"License\"></a>ğŸ“œ License & Citation & Acknowledgments\n\n### License\n\nKolors weights are fully open for academic research. If you intend to use the Kolors model or its derivatives for commercial purposes under the licensing terms and conditions, please send the [questionnaire](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/å¯å›¾KOLORSæ¨¡å‹å•†ä¸šæˆæƒç”³è¯·ä¹¦.docx) to kwai-kolors@kuaishou.com to register with the licensor. If the monthly active users of all products or services made available by or for Licensee does not exceed 300 million monthly active users in the preceding calendar month, Your registration with the Licensor will be deemed to have obtained the corresponding business license; If, the monthly active users of all products or services made available by or for Licensee is greater than 300 million monthly active users in the preceding calendar month, You must request a license from Licensor, which the Licensor may grant to You in its sole discretion, and You are not authorized to exercise any of the rights under this Agreement unless or until We otherwise expressly grants You such rights.\n\n \nWe open-source Kolors to promote the development of large text-to-image models in collaboration with the open-source community. The code of this project is open-sourced under the Apache-2.0 license. We sincerely urge all developers and users to strictly adhere to the [open-source license](MODEL_LICENSE), avoiding the use of the open-source model, code, and its derivatives for any purposes that may harm the country and society or for any services not evaluated and registered for safety. Note that despite our best efforts to ensure the compliance, accuracy, and safety of the data during training, due to the diversity and combinability of generated content and the probabilistic randomness affecting the model, we cannot guarantee the accuracy and safety of the output content, and the model is susceptible to misleading. This project does not assume any legal responsibility for any data security issues, public opinion risks, or risks and liabilities arising from the model being misled, abused, misused, or improperly utilized due to the use of the open-source model and code.\n\n### Citation\nIf you find our work helpful, please cite it!\n\n```\n@article{kolors,\n  title={Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis},\n  author={Kolors Team},\n  journal={arXiv preprint},\n  year={2024}\n}\n```\n\n### Acknowledgments\n- Thanks to [Diffusers](https://github.com/huggingface/diffusers) for providing the codebase.\n- Thanks to [ChatGLM3](https://github.com/THUDM/ChatGLM3) for providing the powerful Chinese language model.\n<br>\n\n### Contact Us\n\nIf you want to leave a message for our R&D team and product team, feel free to join our [WeChat group](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/wechat.png). You can also contact us via email (kwai-kolors@kuaishou.com).\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Kwai-Kolors/Kolors&type=Date)](https://star-history.com/#Kwai-Kolors/Kolors&Date)\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 18.0400390625,
          "content": "<p align=\"left\">\n    ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href=\"README.md\">English</a>&nbsp\n</p>\n<!-- <br><br> -->\n\n<p align=\"center\">\n    <img src=\"imgs/logo.png\" width=\"400\"/>\n<p>\n<br>\n\n<!-- <div align=\"center\">\n\n<a href='https://kwai-kolors.github.io/'><img src='https://img.shields.io/badge/Team-Page-green'></a> <a href=''><img src='https://img.shields.io/badge/Technique-Report-red'></a> [![Teampage](https://img.shields.io/badge/Website-Page-blue)](https://kolors.kuaishou.com/)\n\n</div> -->\n\n<div align=\"center\">\n  <a href='https://huggingface.co/Kwai-Kolors/Kolors'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-HF-yellow'></a> &ensp;\n  <a href=\"https://github.com/Kwai-Kolors/Kolors\"><img src=\"https://img.shields.io/static/v1?label=Kolors Code&message=Github&color=blue&logo=github-pages\"></a> &ensp;\n  <a href=\"https://kwai-kolors.github.io/\"><img src=\"https://img.shields.io/static/v1?label=Team%20Page&message=Page&color=green\"></a> &ensp;\n\n<a href='https://huggingface.co/spaces/Kwai-Kolors/Kolors '><img src='https://img.shields.io/badge/%F0%9F%A4%97%20HF Space-HF-yellow'></a> &ensp;\n  <a href=\"https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf\"><img src=\"https://img.shields.io/static/v1?label=Tech Report&message=Arxiv:Kolors&color=red&logo=arxiv\"></a> &ensp;\n  <a href=\"https://kolors.kuaishou.com/\"><img src=\"https://img.shields.io/static/v1?label=Official Website&message=Page&color=green\"></a> &ensp;\n</div>\n\n\n\n\n</p>\n\n# Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis\n<figure>\n  <img src=\"imgs/head_final3.png\">\n</figure>\n<br><br>\n\n##  ç›®å½•\n\n- [ğŸ‰ æ–°é—»](#æ–°é—»)\n- [ğŸ“‘ å¼€æºè®¡åˆ’](#å¼€æºè®¡åˆ’)\n- [ğŸ“– æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)\n- [ğŸ“Š è¯„æµ‹è¡¨ç° ğŸ¥‡ğŸ¥‡ğŸ”¥ğŸ”¥](#è¯„æµ‹è¡¨ç°)\n- [ğŸ¥ å¯è§†åŒ–](#å¯è§†åŒ–)\n- [ğŸ› ï¸ å¿«é€Ÿä½¿ç”¨](#å¿«é€Ÿä½¿ç”¨)\n- [ğŸ“œ åè®®ã€å¼•ç”¨ã€è‡´è°¢](#åè®®å¼•ç”¨)\n<br><br>\n\n## <a name=\"æ–°é—»\"></a>ğŸ‰ æ–°é—»\n* 2024.09.01 ğŸ”¥ Kolors-Virtual-Try-On å¯å›¾è™šæ‹Ÿè¯•è¡£é¡¹ç›®ä½“éªŒdemoå·²å‘å¸ƒï¼æ¬¢è¿ä½“éªŒ [Kolors-Virtual-Try-On](https://huggingface.co/spaces/Kwai-Kolors/Kolors-Virtual-Try-On)ï¼Œ [å¯å›¾å…¬ä¼—å·](https://mp.weixin.qq.com/s/Wk_Eq7OAywlrPqNC6zWZJQ)ã€‚\n  \n* 2024.08.06 ğŸ”¥ Pose ControlNet å·²å‘å¸ƒ! è¯·æŸ¥çœ‹ [ControlNet(Pose)](./controlnet/) è·å–è¯¦ç»†ä¿¡æ¯ã€‚\n\n* 2024.08.01 ğŸ”¥ Kolors-Dreambooth-LoRA çš„è®­ç»ƒå’Œæ¨ç†ä»£ç å·²å‘å¸ƒï¼è¯·æŸ¥çœ‹ [Dreambooth-LoRA](./dreambooth/) è·å–è¯¦ç»†ä¿¡æ¯ã€‚\n\n* 2024.07.31 ğŸ”¥ Kolors-IP-Adapter-FaceID-Plus çš„æƒé‡å’Œæ¨ç†ä»£ç å·²å‘å¸ƒï¼è¯·æŸ¥çœ‹ [IP-Adapter-FaceID-Plus](./ipadapter_FaceID/) è·å–è¯¦ç»†ä¿¡æ¯ã€‚\n\n* 2024.07.26 ğŸ”¥ Kolorså‘å¸ƒäº†ControlNetå’ŒInpainting Model! è¯·æŸ¥çœ‹ [ControlNet(Canny, Depth)](./controlnet/) å’Œ[Inpainting Model](./inpainting/) è·å–è¯¦ç»†ä¿¡æ¯ã€‚\n\n* 2024.07.17 ğŸ”¥ Kolors-IP-Adapter-Plus çš„æƒé‡å’Œæ¨ç†ä»£ç å·²å‘å¸ƒï¼è¯·æŸ¥çœ‹ [IP-Adapter-Plus](./ipadapter/) è·å–è¯¦ç»†ä¿¡æ¯ã€‚\n\n* 2024.07.12 ğŸ¤— Kolors å·²æ”¯æŒ **Diffusers**! ä½¿ç”¨æ–¹å¼å¯å‚è€ƒ [kolors-diffusers](https://huggingface.co/Kwai-Kolors/Kolors-diffusers)æˆ–[ä¸‹é¢çš„ä¾‹å­](#using-with-diffusers) ! æ„Ÿè°¢ Diffusers å®˜æ–¹æä¾›çš„æŠ€æœ¯æ”¯æŒã€‚\n* 2024.07.10 ğŸ¤– Kolors æ”¯æŒäº† [ModelScope](https://modelscope.cn/models/Kwai-Kolors/Kolors).\n* 2024.07.09 ğŸ’¥ Kolors æ”¯æŒäº† [ComfyUI](https://github.com/comfyanonymous/ComfyUI#manual-install-windows-linux)ï¼Œæ„Ÿè°¢ [@kijai](https://github.com/kijai/ComfyUI-KwaiKolorsWrapper) çš„å·¥ä½œã€‚\n* 2024.07.06 ğŸ”¥ğŸ”¥ğŸ”¥ æˆ‘ä»¬å¼€æºäº†åŸºäºéšç©ºé—´æ‰©æ•£çš„æ–‡ç”Ÿå›¾å¤§æ¨¡å‹ **Kolors** ï¼Œè¯¥æ¨¡å‹åŸºäºæ•°åäº¿å›¾æ–‡å¯¹è¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒ256çš„ä¸Šä¸‹æ–‡tokenæ•°ï¼Œæ”¯æŒä¸­è‹±åŒè¯­ï¼ŒæŠ€æœ¯ç»†èŠ‚å‚è€ƒ[æŠ€æœ¯æŠ¥å‘Š](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf)ã€‚\n* 2024.07.03 ğŸ“Š Kolors åœ¨æ™ºæºç ”ç©¶é™¢ [FlagEval å¤šæ¨¡æ€æ–‡ç”Ÿå›¾](https://flageval.baai.ac.cn/#/leaderboard/multimodal?kind=t2i)è¯„æµ‹ä¸­å–å¾—ç¬¬äºŒåï¼Œå…¶ä¸­ä¸­æ–‡ä¸»è§‚è´¨é‡ã€è‹±æ–‡ä¸»è§‚è´¨é‡ä¸¤ä¸ªå•é¡¹æ’åç¬¬ä¸€ã€‚\n* 2024.07.02 ğŸ‰ ç¥è´ºï¼Œå¯å›¾é¡¹ç›®ç»„æå‡ºçš„å¯æ§è§†é¢‘ç”Ÿæˆæ–¹æ³• [DragAnything: Motion Control for Anything using Entity Representation](https://arxiv.org/abs/2403.07420)  è¢« ECCV 2024 æ¥æ”¶ã€‚\n* 2024.02.08 ğŸ‰ ç¥è´ºï¼Œå¯å›¾é¡¹ç›®ç»„æå‡ºçš„ç”Ÿæˆæ¨¡å‹è¯„ä¼°æ–¹æ³• [Learning Multi-dimensional Human Preference for Text-to-Image Generation](https://wangbohan97.github.io/MPS/)  è¢« CVPR 2024 æ¥æ”¶ã€‚\n<br><br>\n\n## <a name=\"å¼€æºè®¡åˆ’\"></a>ğŸ“‘ å¼€æºè®¡åˆ’\n\n- Kolors (Text-to-Image Model)\n  - [x] Inference \n  - [x] Checkpoints \n  - [x] IP-Adapter\n  - [x] ControlNet (Canny, Depth)\n  - [x] Inpainting\n  - [x] IP-Adapter-FaceID\n  - [x] LoRA\n  - [x] ControlNet (Pose)\n- [x] ComfyUI\n- [x] Gradio\n- [x] Diffusers\n<br><br>\n\n## <a name=\"æ¨¡å‹ä»‹ç»\"></a>ğŸ“– æ¨¡å‹ä»‹ç»\nå¯å›¾å¤§æ¨¡å‹æ˜¯ç”±å¿«æ‰‹å¯å›¾å›¢é˜Ÿå¼€å‘çš„åŸºäºæ½œåœ¨æ‰©æ•£çš„å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚Kolors åœ¨æ•°åäº¿å›¾æ–‡å¯¹ä¸‹è¿›è¡Œè®­ç»ƒï¼Œåœ¨è§†è§‰è´¨é‡ã€å¤æ‚è¯­ä¹‰ç†è§£ã€æ–‡å­—ç”Ÿæˆï¼ˆä¸­è‹±æ–‡å­—ç¬¦ï¼‰ç­‰æ–¹é¢ï¼Œç›¸æ¯”äºå¼€æº/é—­æºæ¨¡å‹ï¼Œéƒ½å±•ç¤ºå‡ºäº†å·¨å¤§çš„ä¼˜åŠ¿ã€‚åŒæ—¶ï¼ŒKolors æ”¯æŒä¸­è‹±åŒè¯­ï¼Œåœ¨ä¸­æ–‡ç‰¹è‰²å†…å®¹ç†è§£æ–¹é¢æ›´å…·ç«äº‰åŠ›ã€‚æ›´å¤šçš„å®éªŒç»“æœå’Œç»†èŠ‚è¯·æŸ¥çœ‹æˆ‘ä»¬çš„<a href=\"https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf\">æŠ€æœ¯æŠ¥å‘Š</a></b>ã€‚\n<br><br>\n\n## <a name=\"è¯„æµ‹è¡¨ç°\"></a>ğŸ“Š è¯„æµ‹è¡¨ç°\nä¸ºäº†å…¨é¢æ¯”è¾ƒ Kolors ä¸å…¶ä»–æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œæˆ‘ä»¬æ„å»ºäº†åŒ…å«äººå·¥è¯„ä¼°ã€æœºå™¨è¯„ä¼°çš„å…¨é¢è¯„æµ‹å†…å®¹ã€‚\nåœ¨ç›¸å…³åŸºå‡†è¯„æµ‹ä¸­ï¼ŒKolors å…·æœ‰éå¸¸æœ‰ç«äº‰åŠ›çš„è¡¨ç°ï¼Œè¾¾åˆ°ä¸šç•Œé¢†å…ˆæ°´å¹³ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«14ç§å‚ç±»ï¼Œ12ä¸ªæŒ‘æˆ˜é¡¹ï¼Œæ€»æ•°é‡ä¸ºä¸€åƒå¤šä¸ª prompt çš„æ–‡ç”Ÿå›¾è¯„ä¼°é›† KolorsPromptsã€‚åœ¨ KolorsPrompts ä¸Šï¼Œæˆ‘ä»¬æ”¶é›†äº† Kolors ä¸å¸‚é¢ä¸Šå¸¸è§çš„ SOTA çº§åˆ«çš„å¼€æº/é—­æºç³»ç»Ÿçš„æ–‡ç”Ÿå›¾ç»“æœï¼Œå¹¶è¿›è¡Œäº†äººå·¥è¯„æµ‹å’Œæœºå™¨è¯„æµ‹ã€‚\n<br><br>\n\n### äººå·¥è¯„æµ‹\n\næˆ‘ä»¬é‚€è¯·äº†50ä¸ªå…·æœ‰å›¾åƒé¢†åŸŸçŸ¥è¯†çš„ä¸“ä¸šè¯„ä¼°äººå‘˜å¯¹ä¸åŒæ¨¡å‹çš„ç”Ÿæˆç»“æœè¿›è¡Œå¯¹æ¯”è¯„ä¼°ï¼Œä¸ºç”Ÿæˆå›¾åƒæ‰“åˆ†ï¼Œè¡¡é‡ç»´åº¦ä¸ºï¼šç”»é¢è´¨é‡ã€å›¾æ–‡ç›¸å…³æ€§ã€æ•´ä½“æ»¡æ„åº¦ä¸‰ä¸ªæ–¹é¢ã€‚\nKolors åœ¨æ•´ä½“æ»¡æ„åº¦æ–¹é¢å¤„äºæœ€ä¼˜æ°´å¹³ï¼Œå…¶ä¸­ç”»é¢è´¨é‡æ˜¾è‘—é¢†å…ˆå…¶ä»–æ¨¡å‹ã€‚\n<div style=\"text-align: center;\">\n\n|       æ¨¡å‹       | æ•´ä½“æ»¡æ„åº¦å¹³å‡åˆ† | ç”»é¢è´¨é‡å¹³å‡åˆ† | å›¾æ–‡ç›¸å…³æ€§å¹³å‡åˆ† |\n| :--------------: | :--------: | :--------: | :--------: |\n|  Adobe-Firefly   |    3.03    |    3.46    |    3.84    |\n| Stable Diffusion 3 |    3.26    |    3.50    |    4.20    |\n|     DALL-E 3      |    3.32    |    3.54    |    4.22    |\n|  Midjourney-v5   |    3.32    |    3.68    |    4.02    |\n| Playground-v2.5  |    3.37    |    3.73    |    4.04    |\n|  Midjourney-v6   |    3.58    |    3.92    |    4.18    |\n|    **Kolors**    |    **3.59**    |    **3.99**    |    **4.17**    |\n\n</div>\n\n\n<div style=\"color: gray; font-size: small;\">\n\n**æ‰€æœ‰æ¨¡å‹ç»“æœå–è‡ª 2024.04 çš„äº§å“ç‰ˆæœ¬**\n\n</div>\n<br>\n\n### æœºå™¨è¯„æµ‹\næˆ‘ä»¬é‡‡ç”¨ [MPS](https://arxiv.org/abs/2405.14705) (Multi-dimensional Human preference Score) æ¥è¯„ä¼°ä¸Šè¿°æ¨¡å‹ã€‚\næˆ‘ä»¬ä»¥ KolorsPrompts ä½œä¸ºåŸºç¡€è¯„ä¼°æ•°æ®é›†ï¼Œè®¡ç®—å¤šä¸ªæ¨¡å‹çš„ MPS æŒ‡æ ‡ã€‚Kolors å®ç°äº†æœ€é«˜çš„MPS æŒ‡æ ‡ï¼Œè¿™ä¸äººå·¥è¯„ä¼°çš„æŒ‡æ ‡ä¸€è‡´ã€‚\n\n<div style=\"text-align:center\">\n\n| æ¨¡å‹            | MPSç»¼åˆå¾—åˆ† |\n|-------------------|-------------|\n| Adobe-Firefly     | 8.5     |\n| Stable Diffusion 3  | 8.9      |\n| DALL-E 3           |   9.0    |\n| Midjourney-v5     | 9.4      |\n| Playground-v2.5   | 9.8      |\n| Midjourney-v6     | 10.2      |\n| **Kolors**            | **10.3**      |\n</div>\n\n\n<br>\n\næ›´å¤šçš„å®éªŒç»“æœå’Œç»†èŠ‚è¯·æŸ¥çœ‹æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šã€‚ç‚¹å‡»[æŠ€æœ¯æŠ¥å‘Š](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf)ã€‚\n<br><br>\n\n## <a name=\"å¯è§†åŒ–\"></a>ğŸ¥ å¯è§†åŒ–\n\n* **é«˜è´¨é‡äººåƒ**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/zl8.png\" />\n</div>\n<br>\n\n* **ä¸­å›½å…ƒç´ **\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/cn_all.png\"/>\n</div>\n<br>\n\n* **å¤æ‚è¯­ä¹‰ç†è§£**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/fz_all.png\"/>\n</div>\n<br>\n\n* **æ–‡å­—ç»˜åˆ¶**\n<div style=\"display: flex; justify-content: space-between;\">\n  <img src=\"imgs/wz_all.png\" />\n</div>\n<br>\n</div>\n\nä¸Šè¿°å¯è§†åŒ– caseï¼Œå¯ä»¥ç‚¹å‡»[å¯è§†åŒ–prompts](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/prompt_vis.txt) è·å–\n<br><br>\n\n## <a name=\"å¿«é€Ÿä½¿ç”¨\"></a>ğŸ› ï¸ å¿«é€Ÿä½¿ç”¨\n\n### è¦æ±‚\n\n* python 3.8åŠä»¥ä¸Šç‰ˆæœ¬\n* pytorch 1.13.1åŠä»¥ä¸Šç‰ˆæœ¬\n* transformers 4.26.1åŠä»¥ä¸Šç‰ˆæœ¬\n* å»ºè®®ä½¿ç”¨CUDA 11.7åŠä»¥ä¸Š\n<br>\n\n1ã€ä»“åº“å…‹éš†åŠä¾èµ–å®‰è£…\n```bash\napt-get install git-lfs\ngit clone https://github.com/Kwai-Kolors/Kolors\ncd Kolors\nconda create --name kolors python=3.8\nconda activate kolors\npip install -r requirements.txt\npython3 setup.py install\n```\n2ã€æ¨¡å‹æƒé‡ä¸‹è½½ï¼ˆ[é“¾æ¥](https://huggingface.co/Kwai-Kolors/Kolors)ï¼‰ï¼š\n```bash\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors --local-dir weights/Kolors\n```\næˆ–è€…\n```bash\ngit lfs clone https://huggingface.co/Kwai-Kolors/Kolors weights/Kolors\n```\n3ã€æ¨¡å‹æ¨ç†ï¼š\n```bash\npython3 scripts/sample.py \"ä¸€å¼ ç“¢è™«çš„ç…§ç‰‡ï¼Œå¾®è·ï¼Œå˜ç„¦ï¼Œé«˜è´¨é‡ï¼Œç”µå½±ï¼Œæ‹¿ç€ä¸€ä¸ªç‰Œå­ï¼Œå†™ç€â€œå¯å›¾â€\"\n# The image will be saved to \"scripts/outputs/sample_text.jpg\"\n```\n4ã€ Web demoï¼š\n```bash\npython3 scripts/sampleui.py\n```\n\n### åœ¨ Diffusers ä¸­ä½¿ç”¨\nç¡®ä¿æ‚¨å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬çš„ `diffusers`(0.30.0.dev0): \n```\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npython3 setup.py install\n```\n**æ³¨æ„:**\n- KolorsPipeline é»˜è®¤ä½¿ç”¨`EulerDiscreteScheduler` ä½œä¸ºå™ªå£°è°ƒåº¦å™¨ã€‚æˆ‘ä»¬æ¨èä½¿ç”¨è¯¥è°ƒåº¦å™¨æ—¶æ­é… `guidance scale=5.0` åŠ `num_inference_steps=50`ã€‚\n- KolorsPipeline åŒæ—¶æ”¯æŒ `EDMDPMSolverMultistepScheduler`ã€‚åœ¨ä½¿ç”¨è¯¥å™ªå£°è°ƒåº¦å™¨æ—¶ï¼Œæ¨èä½¿ç”¨å‚æ•° `guidance scale=5.0`åŠ`num_inference_steps=25`ã€‚\n- é™¤äº†æ–‡ç”Ÿå›¾èƒ½åŠ›ï¼Œ`KolorsImg2ImgPipeline` åŒæ—¶ä¹Ÿæ”¯æŒå›¾æ–‡ç”Ÿå›¾åŠŸèƒ½ã€‚\n\nè¿è¡Œä»¥ä¸‹æŒ‡ä»¤è¿›è¡Œå›¾åƒç”Ÿæˆ:\n```python\nimport torch\nfrom diffusers import KolorsPipeline\npipe = KolorsPipeline.from_pretrained(\n    \"Kwai-Kolors/Kolors-diffusers\", \n    torch_dtype=torch.float16, \n    variant=\"fp16\"\n).to(\"cuda\")\nprompt = 'ä¸€å¼ ç“¢è™«çš„ç…§ç‰‡ï¼Œå¾®è·ï¼Œå˜ç„¦ï¼Œé«˜è´¨é‡ï¼Œç”µå½±ï¼Œæ‹¿ç€ä¸€ä¸ªç‰Œå­ï¼Œå†™ç€\"å¯å›¾\"'\nimage = pipe(\n    prompt=prompt,\n    negative_prompt=\"\",\n    guidance_scale=5.0,\n    num_inference_steps=50,\n    generator=torch.Generator(pipe.device).manual_seed(66),\n).images[0]\nimage.show()\n```\n### IP-Adapter-Plus\n\næˆ‘ä»¬æä¾›äº† IP-Adapter-Plus çš„å‚æ•°å’Œä»£ç , è¯¦ç»†ä¿¡æ¯è§ [ipadapter](./ipadapter/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-IP-Adapter-Plus --local-dir weights/Kolors-IP-Adapter-Plus\n```\n\n```bash\n# Inferenceï¼š\npython3 ipadapter/sample_ipadapter_plus.py ./ipadapter/asset/test_ip.jpg \"ç©¿ç€é»‘è‰²Tæ¤è¡«ï¼Œä¸Šé¢ä¸­æ–‡ç»¿è‰²å¤§å­—å†™ç€â€œå¯å›¾â€\"\n\npython3 ipadapter/sample_ipadapter_plus.py ./ipadapter/asset/test_ip2.png \"ä¸€åªå¯çˆ±çš„å°ç‹—åœ¨å¥”è·‘\"\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n\n### ControlNet\n\næˆ‘ä»¬æä¾›äº†ä¸‰ä¸ªç±»å‹çš„ControlNetå‚æ•°å’Œä»£ç ï¼Œè¯¦ç»†ä¿¡æ¯è§[controlnet](./controlnet/README.md)ã€‚\n\n```bash\n# Weights download\n\n# Canny - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Canny --local-dir weights/Kolors-ControlNet-Canny\n\n# Depth - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Depth --local-dir weights/Kolors-ControlNet-Depth\n\n# Pose - ControlNet\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-ControlNet-Pose --local-dir weights/Kolors-ControlNet-Pose\n```\nå¦‚æœä½ æ‰“ç®—ä½¿ç”¨æ·±åº¦ä¼°è®¡ç½‘ç»œï¼Œè¯·ç¡®ä¿ä¸‹è½½å…¶ç›¸åº”çš„æ¨¡å‹æƒé‡ã€‚\n```\nhuggingface-cli download lllyasviel/Annotators ./dpt_hybrid-midas-501f0c75.pt --local-dir ./controlnet/annotator/ckpts  \n```\n\næ„Ÿè°¢[DWPose](https://github.com/IDEA-Research/DWPose/tree/onnx?tab=readme-ov-file)ï¼Œä½ å¯ä»¥ä½¿ç”¨å§¿æ€é¢„æµ‹ç½‘ç»œã€‚ è¯·ä¸‹è½½å§¿æ€æ¨¡å‹ dw-ll_ucoco_384.onnx ([baidu](https://pan.baidu.com/s/1nuBjw-KKSxD_BkpmwXUJiw?pwd=28d7), [google](https://drive.google.com/file/d/12L8E2oAgZy4VACGSK9RaZBZrfgx7VTA2/view?usp=sharing)) å’Œæ£€æµ‹æ¨¡å‹ yolox_l.onnx ([baidu](https://pan.baidu.com/s/1fpfIVpv5ypo4c1bUlzkMYQ?pwd=mjdn), [google](https://drive.google.com/file/d/1w9pXC8tT0p9ndMN-CArp1__b2GbzewWI/view?usp=sharing))ã€‚ç„¶åè¯·å°†å®ƒä»¬æ”¾å…¥ `controlnet/annotator/ckpts/`ã€‚\n\n\n```bash\n# Inferenceï¼š\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_1.png ä¸€ä¸ªæ¼‚äº®çš„å¥³å­©ï¼Œé«˜å“è´¨ï¼Œè¶…æ¸…æ™°ï¼Œè‰²å½©é²œè‰³ï¼Œè¶…é«˜åˆ†è¾¨ç‡ï¼Œæœ€ä½³å“è´¨ï¼Œ8kï¼Œé«˜æ¸…ï¼Œ4K Canny\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_2.png æ–°æµ·è¯šé£æ ¼ï¼Œä¸°å¯Œçš„è‰²å½©ï¼Œç©¿ç€ç»¿è‰²è¡¬è¡«çš„å¥³äººç«™åœ¨ç”°é‡é‡Œï¼Œå”¯ç¾é£æ™¯ï¼Œæ¸…æ–°æ˜äº®ï¼Œæ–‘é©³çš„å…‰å½±ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…ç»†èŠ‚ï¼Œ8Kç”»è´¨ Depth\n\npython ./controlnet/sample_controlNet.py ./controlnet/assets/woman_3.png ä¸€ä½ç©¿ç€ç´«è‰²æ³¡æ³¡è¢–è¿è¡£è£™ã€æˆ´ç€çš‡å† å’Œç™½è‰²è•¾ä¸æ‰‹å¥—çš„å¥³å­©åŒæ‰‹æ‰˜è„¸ï¼Œé«˜å“è´¨ï¼Œè¶…æ¸…æ™°ï¼Œè‰²å½©é²œè‰³ï¼Œè¶…é«˜åˆ†è¾¨ç‡ï¼Œæœ€ä½³å“è´¨ï¼Œ8kï¼Œé«˜æ¸…ï¼Œ4K Pose\n\n# The image will be saved to \"controlnet/outputs/\"\n```\n\n\n### Inpainting\n\næˆ‘ä»¬æä¾›äº† Inpainting çš„å‚æ•°å’Œä»£ç , è¯¦ç»†ä¿¡æ¯è§ [inpainting](./inpainting/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-Inpainting --local-dir weights/Kolors-Inpainting\n```\n\n```bash\n# Inferenceï¼š\npython3 inpainting/sample_inpainting.py ./inpainting/asset/3.png ./inpainting/asset/3_mask.png ç©¿ç€ç¾å°‘å¥³æˆ˜å£«çš„è¡£æœï¼Œä¸€ä»¶ç±»ä¼¼äºæ°´æ‰‹æœé£æ ¼çš„è¡£æœï¼ŒåŒ…æ‹¬ä¸€ä¸ªç™½è‰²ç´§èº«ä¸Šè¡£ï¼Œå‰èƒ¸æ­é…ä¸€ä¸ªå¤§å¤§çš„çº¢è‰²è´è¶ç»“ã€‚è¡£æœçš„é¢†å­éƒ¨åˆ†å‘ˆè“è‰²ï¼Œå¹¶ä¸”æœ‰ç™½è‰²æ¡çº¹ã€‚å¥¹è¿˜ç©¿ç€ä¸€æ¡è“è‰²ç™¾è¤¶è£™ï¼Œè¶…é«˜æ¸…ï¼Œè¾›çƒ·æ¸²æŸ“ï¼Œé«˜çº§è´¨æ„Ÿï¼Œ32kï¼Œé«˜åˆ†è¾¨ç‡ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…çº§ç»†èŠ‚ï¼Œæ™¯æ·±\n\npython3 inpainting/sample_inpainting.py ./inpainting/asset/4.png ./inpainting/asset/4_mask.png ç©¿ç€é’¢é“ä¾ çš„è¡£æœï¼Œé«˜ç§‘æŠ€ç›”ç”²ï¼Œä¸»è¦é¢œè‰²ä¸ºçº¢è‰²å’Œé‡‘è‰²ï¼Œå¹¶ä¸”æœ‰ä¸€äº›é“¶è‰²è£…é¥°ã€‚èƒ¸å‰æœ‰ä¸€ä¸ªäº®èµ·çš„åœ†å½¢ååº”å †è£…ç½®ï¼Œå……æ»¡äº†æœªæ¥ç§‘æŠ€æ„Ÿã€‚è¶…æ¸…æ™°ï¼Œé«˜è´¨é‡ï¼Œè¶…é€¼çœŸï¼Œé«˜åˆ†è¾¨ç‡ï¼Œæœ€å¥½çš„è´¨é‡ï¼Œè¶…çº§ç»†èŠ‚ï¼Œæ™¯æ·±\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n### IP-Adapter-FaceID-Plus\n\næˆ‘ä»¬æä¾›äº† IP-Adapter-FaceID-Plus çš„å‚æ•°å’Œä»£ç , è¯¦ç»†ä¿¡æ¯è§ [ipadapter_FaceID](./ipadapter_FaceID/README.md).\n\n```bash\n# Weights download\nhuggingface-cli download --resume-download Kwai-Kolors/Kolors-IP-Adapter-FaceID-Plus --local-dir weights/Kolors-IP-Adapter-FaceID-Plus\n```\n\n```bash\n# Inferenceï¼š\npython ipadapter_FaceID/sample_ipadapter_faceid_plus.py ./ipadapter_FaceID/assets/image1.png \"ç©¿ç€æ™šç¤¼æœï¼Œåœ¨æ˜Ÿå…‰ä¸‹çš„æ™šå®´åœºæ™¯ä¸­ï¼Œçƒ›å…‰é—ªé—ªï¼Œæ•´ä¸ªåœºæ™¯æ´‹æº¢ç€æµªæ¼«è€Œå¥¢åçš„æ°›å›´\"\n\npython ipadapter_FaceID/sample_ipadapter_faceid_plus.py ./ipadapter_FaceID/assets/image2.png \"è¥¿éƒ¨ç‰›ä»”ï¼Œç‰›ä»”å¸½ï¼Œè’é‡å¤§é•–å®¢ï¼ŒèƒŒæ™¯æ˜¯è¥¿éƒ¨å°é•‡ï¼Œä»™äººæŒï¼Œ,æ—¥è½ä½™æ™–, æš–è‰²è°ƒ, ä½¿ç”¨XT4èƒ¶ç‰‡æ‹æ‘„, å™ªç‚¹, æ™•å½±, æŸ¯è¾¾èƒ¶å·ï¼Œå¤å¤\"\n\n# The image will be saved to \"scripts/outputs/\"\n```\n\n### Dreambooth-LoRA\n\næˆ‘ä»¬æä¾›äº†Dreambooth-LoRA çš„è®­ç»ƒå’Œæ¨ç†ä»£ç ï¼Œè¯¦ç»†ä¿¡æ¯è§ [Dreambooth-LoRA](./dreambooth/README.md).\n\n```bash\n# Training:\nsh train.sh\n```\n\n```bash\n# Inferenceï¼š\npython infer_dreambooth.py \"ktxlç‹—åœ¨è‰åœ°ä¸Šè·‘\"\n```\n\n<br><br>\n\n## <a name=\"åè®®å¼•ç”¨\"></a>ğŸ“œåè®®ã€å¼•ç”¨ã€è‡´è°¢\n\n\n### åè®®\n**Kolors**ï¼ˆå¯å›¾ï¼‰æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œè‹¥æ‚¨æœŸæœ›åŸºäºæœ¬æ¨¡å‹åè®®çš„è®¸å¯æ¡ä»¶ä¸é™åˆ¶ï¼Œå°†å¯å›¾KOLORSæ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨ä½œå•†ä¸šç›®çš„ï¼Œè¯·æ‚¨å°†[é—®å·](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/å¯å›¾KOLORSæ¨¡å‹å•†ä¸šæˆæƒç”³è¯·ä¹¦.docx)å‘é€è‡³é‚®ç®±kwai-kolors@kuaishou.comï¼Œä»¥å‘è®¸å¯æ–¹ç™»è®°ã€‚è‹¥æ‚¨æä¾›çš„æ‰€æœ‰äº§å“æˆ–æœåŠ¡çš„æœˆæ´»è·ƒç”¨æˆ·æ•°åœ¨å‰ä¸€ä¸ªè‡ªç„¶æœˆæœªè¶…è¿‡3äº¿æœˆæ´»è·ƒç”¨æˆ·æ•°ï¼Œåˆ™æ‚¨å‘è®¸å¯æ–¹è¿›è¡Œç™»è®°ï¼Œå°†è¢«è§†ä¸ºè·å¾—ç›¸åº”çš„å•†ä¸šè®¸å¯ï¼›è‹¥æ‚¨æä¾›çš„æ‰€æœ‰äº§å“æˆ–æœåŠ¡çš„æœˆæ´»è·ƒç”¨æˆ·æ•°åœ¨å‰ä¸€ä¸ªè‡ªç„¶æœˆè¶…è¿‡3äº¿æœˆæ´»è·ƒç”¨æˆ·æ•°ï¼Œåˆ™æ‚¨å¿…é¡»å‘è®¸å¯äººç”³è¯·è®¸å¯ï¼Œè®¸å¯äººå¯è‡ªè¡Œå†³å®šå‘æ‚¨æˆäºˆè®¸å¯ã€‚\n\næœ¬å¼€æºæ¨¡å‹æ—¨åœ¨ä¸å¼€æºç¤¾åŒºå…±åŒæ¨è¿›æ–‡ç”Ÿå›¾å¤§æ¨¡å‹æŠ€æœ¯çš„å‘å±•ã€‚æœ¬é¡¹ç›®ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æºï¼Œæ¨¡å‹æƒé‡éœ€è¦éµå¾ªæœ¬ã€Šæ¨¡å‹è®¸å¯åè®®ã€‹ï¼Œæˆ‘ä»¬æ³è¯·æ‰€æœ‰å¼€å‘è€…å’Œç”¨æˆ·ä¸¥æ ¼éµå®ˆ[å¼€æºåè®®](MODEL_LICENSE)ï¼Œé¿å…å°†å¼€æºæ¨¡å‹ã€ä»£ç åŠå…¶è¡ç”Ÿç‰©ç”¨äºä»»ä½•å¯èƒ½å¯¹å›½å®¶å’Œç¤¾ä¼šé€ æˆå±å®³çš„ç”¨é€”ï¼Œæˆ–ç”¨äºä»»ä½•æœªç»å®‰å…¨è¯„ä¼°å’Œå¤‡æ¡ˆçš„æœåŠ¡ã€‚éœ€è¦æ³¨æ„ï¼Œå°½ç®¡æ¨¡å‹åœ¨è®­ç»ƒä¸­æˆ‘ä»¬å°½åŠ›ç¡®ä¿æ•°æ®çš„åˆè§„æ€§ã€å‡†ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œä½†ç”±äºè§†è§‰ç”Ÿæˆæ¨¡å‹å­˜åœ¨ç”Ÿæˆå¤šæ ·æ€§å’Œå¯ç»„åˆæ€§ç­‰ç‰¹ç‚¹ï¼Œä»¥åŠç”Ÿæˆæ¨¡å‹å—æ¦‚ç‡éšæœºæ€§å› ç´ çš„å½±å“ï¼Œæ¨¡å‹æ— æ³•ä¿è¯è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§å’Œå®‰å…¨æ€§ï¼Œä¸”æ¨¡å‹æ˜“è¢«è¯¯å¯¼ã€‚æœ¬é¡¹ç›®ä¸å¯¹å› ä½¿ç”¨å¼€æºæ¨¡å‹å’Œä»£ç è€Œå¯¼è‡´çš„ä»»ä½•æ•°æ®å®‰å…¨é—®é¢˜ã€èˆ†æƒ…é£é™©æˆ–å› æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­ã€ä¸å½“åˆ©ç”¨è€Œäº§ç”Ÿçš„é£é™©å’Œè´£ä»»æ‰¿æ‹…ä»»ä½•æ³•å¾‹è´£ä»»ã€‚\n\n<br>\n\n### å¼•ç”¨\nå¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ï¼\n\n```\n@article{kolors,\n  title={Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis},\n  author={Kolors Team},\n  journal={arXiv preprint},\n  year={2024}\n}\n```\n<br>\n\n### è‡´è°¢\n- æ„Ÿè°¢ [Diffusers](https://github.com/huggingface/diffusers) æä¾›çš„codebase\n- æ„Ÿè°¢ [ChatGLM3](https://github.com/THUDM/ChatGLM3) æä¾›çš„å¼ºå¤§ä¸­æ–‡è¯­è¨€æ¨¡å‹\n<br>\n\n### è”ç³»æˆ‘ä»¬\n\nå¦‚æœä½ æƒ³ç»™æˆ‘ä»¬çš„ç ”å‘å›¢é˜Ÿå’Œäº§å“å›¢é˜Ÿç•™è¨€ï¼Œæ¬¢è¿åŠ å…¥æˆ‘ä»¬çš„[å¾®ä¿¡ç¾¤](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/wechat.png)ã€‚å½“ç„¶ä¹Ÿå¯ä»¥é€šè¿‡é‚®ä»¶ï¼ˆkwai-kolors@kuaishou.comï¼‰è”ç³»æˆ‘ä»¬ã€‚\n\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Kwai-Kolors/Kolors&type=Date)](https://star-history.com/#Kwai-Kolors/Kolors&Date)\n"
        },
        {
          "name": "controlnet",
          "type": "tree",
          "content": null
        },
        {
          "name": "dreambooth",
          "type": "tree",
          "content": null
        },
        {
          "name": "imgs",
          "type": "tree",
          "content": null
        },
        {
          "name": "inpainting",
          "type": "tree",
          "content": null
        },
        {
          "name": "ipadapter",
          "type": "tree",
          "content": null
        },
        {
          "name": "ipadapter_FaceID",
          "type": "tree",
          "content": null
        },
        {
          "name": "kolors",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.357421875,
          "content": "fire\ntriton\npydantic==2.8.2\naccelerate==0.27.2\ndeepspeed==0.8.1\nhuggingface-hub==0.23.4\nimageio==2.25.1\nnumpy==1.21.6\nomegaconf==2.3.0\npandas==1.3.5\nPillow==9.4.0\ntokenizers==0.13.2\ntorch==1.13.1\ntorchvision==0.14.1\ntransformers==4.42.4\nxformers==0.0.16\nsafetensors==0.3.3\ndiffusers==0.28.2\nsentencepiece==0.1.99\ngradio==4.37.2\nopencv-python\neinops\ntimm\nonnxruntime\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.2568359375,
          "content": "from setuptools import setup, find_packages\n\nsetup(\n    name=\"kolors\",\n    version=\"0.1\",\n    author=\"Kolors\",\n    description=\"The training and inference code for Kolors models.\",\n    packages=find_packages(),\n    install_requires=[],\n    dependency_links=[],\n)\n"
        }
      ]
    }
  ]
}