{
  "metadata": {
    "timestamp": 1736559600415,
    "page": 236,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "NVIDIA/warp",
      "stars": 4421,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 1.0029296875,
          "content": "# Normalize text files on commit to LF endings by default\n* text=auto\n# Make sure Windows batch files preserve CR/LF line endings, otherwise they may not be able to execute.  Windows\n# batch files require a CR/LF for labels to work properly, otherwise they may fail when labels straddle 512-byte\n# block boundaries.  This is important when files are downloaded through a zip archive that was authored on a\n# Linux machine (the default behavior on GitHub)\n*.bat text eol=crlf\n*.cmd text eol=crlf\n# Make sure shell scripts have LF line endings, even when checked out on a Windows client with autocrlf=true\n*.sh text eol=lf\n*.nvdb.grid filter=lfs diff=lfs merge=lfs -text\n*.usd filter=lfs diff=lfs merge=lfs -text\n*.grid filter=lfs diff=lfs merge=lfs -text\n*.nvdb filter=lfs diff=lfs merge=lfs -text\n*.gif filter=lfs diff=lfs merge=lfs -text\n*.png filter=lfs diff=lfs merge=lfs -text\n\n# Exclude vendored code from project language stats\nwarp/native/cutlass/** linguist-vendored\ntools/** linguist-vendored\n\nCHANGELOG.md merge=union"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.677734375,
          "content": "__pycache__\n.idea\n.history\n*.net\n*.prof\nwarp/kernels\nwarp.egg-info\n.[v]env\n.vscode\narchive\n*.o\n*.exp\n*.dll\n*.lib\n*.cpp.obj\n*.pdb\n/_build\n/_repo\n/_conan\n/_deps\n/docs/_build\n/warp_lang.egg-info\nexts/omni.warp/omni/warp/ogn/tests/usd\n.vs/\noutputs/\nbuild/lib/\n.venv/\n.usd_cache/\nexts/omni.warp/config/extension.gen.toml\n/external/llvm-project\n/build\n/dist\n.coverage\n.cache\nwarp/tests/outputs\n\n# CUTLASS repo directories we don't want to track\nwarp/native/cutlass/.github\nwarp/native/cutlass/cmake\nwarp/native/cutlass/docs\nwarp/native/cutlass/examples\nwarp/native/cutlass/media\nwarp/native/cutlass/python\nwarp/native/cutlass/test\nwarp/native/cutlass/tools/profiler\nwarp/native/cutlass/tools/library\n"
        },
        {
          "name": ".gitlab-ci.yml",
          "type": "blob",
          "size": 34.8115234375,
          "content": "# Copyright (c) 2023 NVIDIA CORPORATION.  All rights reserved.\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\n# ==============================================================================\n# CI/CD Pipeline Configuration\n# ==============================================================================\n\ninclude:\n  - local: /.gitlab/ci/common.yml\n  - project: \"omniverse/devplat/gitlab/templates/common/compliance\"\n    file: \"modules/omniverse-repo-compliance.gitlab-ci.yml\"\n    ref: v1_latest\n\nworkflow:\n  rules:\n    - if: $CI_PROJECT_ROOT_NAMESPACE != \"omniverse\" # Prevent pipelines that can't access the runners\n      when: never\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n    - if: $CI_MERGE_REQUEST_TARGET_BRANCH_SHA\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n      auto_cancel:\n        on_new_commit: none\n        on_job_failure: none\n    - if: $CI_COMMIT_TAG # Run for tagged releases\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - if: $CI_PIPELINE_SOURCE == \"web\" # Run if triggered from the UI\n\nvariables:\n  PM_PACKAGES_ROOT: '$CI_PROJECT_DIR/packman-repo'\n  PIP_CACHE_DIR: '$CI_PROJECT_DIR/.cache/pip'\n  CUDA_BIN: '$CI_PROJECT_DIR/_build/target-deps/cuda/bin'\n  CUDA: '$CI_PROJECT_DIR/_build/target-deps/cuda'\n  CUDA_HOME: '$CI_PROJECT_DIR/_build/target-deps/cuda'\n  PYTHON: '$CI_PROJECT_DIR/_build/target-deps/python/python'\n  LINBUILD: '$CI_PROJECT_DIR/_build/host-deps/linbuild/linbuild.sh'\n  WARP_CACHE_ROOT: '$CI_PROJECT_DIR/.cache/warp' # Used by the parallel test runner\n  GIT_DEPTH: 1\n  DEFAULT_PYTHON:\n    value: \"3.9.18+nv1\"\n    options:\n      - \"3.11.8+nv1\"\n      - \"3.10.13+nv3\"\n      - \"3.9.18+nv1\"\n      - \"3.8.18+nv1\"\n    description: \"The default Python version used in the main testing jobs.\"\n\nstages:\n  - build\n  - test\n  - child pipelines\n  - package\n  - deploy\n\n# ==============================================================================\n# Build Jobs (Release)\n# ==============================================================================\n\nlinux-aarch64 build:\n  stage: build\n  image: ubuntu:20.04\n  extends:\n    - .save_warp_bin_artifact\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - apt-get update && apt-get install build-essential curl --no-install-recommends -y\n    - >\n      curl -k -H \"Authorization: Bearer $ARTIFACTORY_ACCESS_TOKEN\"\n      $ARTIFACTORY_BASE_URL/sw-cuda-math-mathdx-generic-local/cicd/libmathdx/sandbox/PostMerge/15/libmathdx_build_aarch64_rockylinux8_cuda12.0.0_release.tar.gz\n      -o libmathdx.tar.gz\n    - mkdir -p _build/target-deps\n    - tar -xzf libmathdx.tar.gz -C _build/target-deps\n    - export LIBMATHDX_HOME=\"$CI_PROJECT_DIR/_build/target-deps/libmathdx-0.1.0-Linux\"\n    - gcc --version\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - ./tools/ci/building/build-linux-aarch64/build.sh --no-docker\n    - mkdir -p warp/bin/linux-aarch64\n    - mv warp/bin/warp.so warp/bin/linux-aarch64\n    - mv warp/bin/warp-clang.so warp/bin/linux-aarch64\n  tags:\n    - arch/arm\n\nlinux-x86_64 build:\n  stage: build\n  image: ubuntu:20.04\n  extends:\n    - .save_warp_bin_artifact\n    - .runner-build-linux-x86_64\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - apt-get update && apt-get install build-essential curl --no-install-recommends -y\n    - >\n      curl -k -H \"Authorization: Bearer $ARTIFACTORY_ACCESS_TOKEN\"\n      $ARTIFACTORY_BASE_URL/sw-cuda-math-mathdx-generic-local/cicd/libmathdx/sandbox/PostMerge/15/libmathdx_build_x86_64_rockylinux8_cuda12.0.0_release.tar.gz\n      -o libmathdx.tar.gz\n    - mkdir -p _build/target-deps\n    - tar -xzf libmathdx.tar.gz -C _build/target-deps\n    - export LIBMATHDX_HOME=\"$CI_PROJECT_DIR/_build/target-deps/libmathdx-0.1.0-Linux\"\n    - gcc --version\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - ./tools/ci/building/build-linux-x86_64/build.sh --no-docker\n    - mkdir -p warp/bin/linux-x86_64\n    - mv warp/bin/warp.so warp/bin/linux-x86_64\n    - mv warp/bin/warp-clang.so warp/bin/linux-x86_64\n\nwindows-x86_64 build:\n  stage: build\n  extends:\n    - .save_warp_bin_artifact\n    - .runner-build-windows-x86_64\n  before_script:\n    - powershell -command \"Get-Volume | Format-Table -AutoSize\"\n    - |\n      $headers = @{\n          \"Authorization\" = \"Basic $([Convert]::ToBase64String([Text.Encoding]::ASCII.GetBytes(\"warp-cicd:${env:LIBMATHDX_REGISTRY_TOKEN}\")))\"\n      }\n      $url = \"${CI_API_V4_URL}/projects/141992/packages/generic/libmathdx/0-1-0-2/libmathdx-0.1.0-win64.zip\"\n      $output = \"libmathdx.zip\"\n      Invoke-WebRequest -Uri $url -Headers $headers -OutFile $output -ErrorAction Stop\n    - Expand-Archive -Path libmathdx.zip -DestinationPath _build/target-deps -Force\n    - Get-ChildItem -Path \"${env:CI_PROJECT_DIR}\\_build\\target-deps\"\n    - $env:LIBMATHDX_HOME = \"${env:CI_PROJECT_DIR}\\_build\\target-deps\\libmathdx-0.1.0-win64\"\n  script:\n    - ./tools/ci/building/build-windows-x86_64/build.bat\n\nmac-x86_64 build:\n  stage: build\n  extends:\n    - .save_warp_bin_artifact\n    - .runner-build-macos-universal\n    - .macos_warp_tags\n  script:\n    - ./tools/ci/building/build-linux-x86_64/build.sh\n\n# ==============================================================================\n# Linting Jobs\n#\n# The jobs here are meant to assist with code quality analysis.\n# They can run immediately without waiting for the build jobs to complete.\n# ==============================================================================\n\nruff lint:\n  stage: test\n  image: python:3.11-slim\n  needs: []\n  extends:\n    - .runner-utility-linux-x86_64\n  before_script:\n    - python -m pip install --upgrade pip\n    - pip install ruff --constraint docs/requirements.txt\n  script:\n    - ruff check --output-format full  --exit-zero # Just to get something in the log\n    - ruff check --output-format gitlab > gl-code-quality-report.json\n  artifacts:\n    reports:\n      codequality: gl-code-quality-report.json\n\nruff format:\n  stage: test\n  image: python:3.11-slim\n  needs: []\n  extends:\n    - .runner-utility-linux-x86_64\n  before_script:\n    - python -m pip install --upgrade pip\n    - pip install ruff --constraint docs/requirements.txt\n  script:\n    - ruff format --diff\n\nosec:sonarqube:\n  variables:\n    # Disable C/C++ analyzer until project specific work is done to enable it.\n    # See: https://confluence.nvidia.com/display/OMNIVERSE/SonarQube+Gitlab+CI+Integration#C+Project+Enablement+Additions\n    SONAR_EXTRA_ARGS: \"-Dsonar.c.file.suffixes=- -Dsonar.cpp.file.suffixes=- -Dsonar.objc.file.suffixes=-\"\n\n# ==============================================================================\n# Main Unit Testing Jobs\n#\n# The jobs here will always be run when the pipeline is triggered. The jobs that\n# compute code coverage run slower than jobs that do not. The minimal jobs were\n# added to test the user experience without any optional Python packages.\n# ==============================================================================\n\n.test_common_main:\n  stage: test\n  coverage: '/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/'\n  artifacts:\n    when: always\n    paths:\n      - rspec.xml\n      - coverage.xml\n    reports:\n      junit: rspec.xml\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - if: $CI_PIPELINE_SOURCE == \"web\"\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n      changes:\n        - .gitlab/ci/*\n        - warp/**/*\n        - pyproject.toml\n        - tools/**/*\n        - deps/*\n        - build_lib.py\n        - build_llvm.py\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n      allow_failure: true\n\nlinux-aarch64 test:\n  image: ubuntu:22.04\n  needs: [linux-aarch64 build]\n  extends:\n    - .test_common_main\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - !reference [.snippets, install-python+warp-aarch64]\n    - python -m pip install coverage[toml]\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml --coverage --coverage-xml coverage.xml -s autodetect --failfast\n  tags:\n    - arch/arm\n\nlinux-aarch64 test jetson:\n  image: ubuntu:22.04\n  needs: [linux-aarch64 build]\n  extends:\n    - .test_common_main\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n  allow_failure: true # Unsure of stability of Jetson runner for now\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - !reference [.snippets, install-python+warp-aarch64]\n    - python -m pip install coverage[toml]\n    - python -m pip install -U \"jax[cuda12]\"\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml --coverage --coverage-xml coverage.xml -s autodetect --failfast\n  tags:\n    - gpu/orin\n\nlinux-x86_64 test:\n  needs: [linux-x86_64 build]\n  extends:\n    - .omni_nvks_gpu_2x\n    - .test_common_main\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - df -h\n    # Move compiled binaries out of platform-specific directory\n    - mv warp/bin/linux-x86_64/warp.so warp/bin/\n    - mv warp/bin/linux-x86_64/warp-clang.so warp/bin/\n    - tools/packman/packman install -l _build/target-deps/python python ${DEFAULT_PYTHON}-linux-x86_64\n    - export PATH=\"$CUDA_BIN:$PATH\"\n    - $PYTHON -m venv _venv\n    - source _venv/bin/activate\n    - python -m pip install --upgrade pip\n    - python -m pip install --upgrade usd-core coverage[toml] blosc\n    - python -m pip install --upgrade torch --extra-index-url https://download.pytorch.org/whl/cu121\n    - python -m pip install -U \"jax[cuda12]\"\n    - python -m pip install -e .\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n    # HACK: disable P2P tests due to misbehaving agents\n    - export WARP_DISABLE_P2P_TESTS=1\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml --coverage --coverage-xml coverage.xml -s autodetect --failfast\n\n# Note that for throughput reasons this runs on a single-GPU runner\nwindows-x86_64 test:\n  stage: test\n  needs: [windows-x86_64 build]\n  extends:\n    - .runner-test-windows-x86_64-gpu\n    - .test_common_main\n  before_script:\n    - !reference [.snippets, define-powershell-GetTime]\n    - Write-Output \"$([char]27)[0Ksection_start:$(GetTime):install_dependencies[collapsed=true]$([char]13)$([char]27)[0KInstalling dependencies\"\n    - powershell -command \"Get-Volume | Format-Table -AutoSize\"\n    - $python_name = $DEFAULT_PYTHON + \"-windows-x86_64\"\n    - tools/packman/packman.cmd install -l _build/target-deps/python python $python_name\n    - '& $env:CI_PROJECT_DIR\\_build\\target-deps\\python\\python.exe -m venv _venv'\n    - .\\_venv\\Scripts\\Activate.ps1\n    - python -m pip install --upgrade pip\n    - python -m pip install --upgrade usd-core coverage[toml] numpy blosc\n    - python -m pip install --upgrade torch --extra-index-url https://download.pytorch.org/whl/cu121\n    - python -m pip install -e .\n    - Write-Output \"$([char]27)[0Ksection_end:$(GetTime):install_dependencies$([char]13)$([char]27)[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml --coverage --coverage-xml coverage.xml -s autodetect --failfast\n\nmac-x86_64 test:\n  stage: test\n  needs: [mac-x86_64 build]\n  extends:\n    - .runner-test-macos-universal\n    - .test_common_main\n    - .macos_warp_tags\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - !reference [.snippets, install-python+warp-macos]\n    - python -m pip install --upgrade usd-core coverage[toml]\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml --coverage --coverage-xml coverage.xml -s autodetect --failfast\n\n# Test the Linux release build in an environment with minimal Python dependencies installed\nlinux-x86_64 test minimal:\n  stage: test\n  needs: [linux-x86_64 build]\n  extends:\n    - .omni_nvks_gpu_2x\n    - .save_test_report_artifact\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - if: $CI_PIPELINE_SOURCE == \"web\"\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n      changes:\n        - .gitlab/ci/*\n        - warp/**/*\n        - pyproject.toml\n        - tools/**/*\n        - deps/*\n        - build_lib.py\n        - build_llvm.py\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n      allow_failure: true\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - df -h\n    # Move compiled binaries out of platform-specific directory\n    - mv warp/bin/linux-x86_64/warp.so warp/bin/\n    - mv warp/bin/linux-x86_64/warp-clang.so warp/bin/\n    - tools/packman/packman install -l _build/target-deps/python python ${DEFAULT_PYTHON}-linux-x86_64\n    - $PYTHON -m venv _venv\n    - source _venv/bin/activate\n    - python -m pip install --upgrade pip\n    - python -m pip install -e .\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n    # HACK: disable P2P tests due to misbehaving agents\n    - export WARP_DISABLE_P2P_TESTS=1\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml -s autodetect --failfast\n\n# Optional multi-GPU Windows job (likely longer queue time)\nwindows-x86_64 test mgpu:\n  stage: test\n  needs: [windows-x86_64 build]\n  extends:\n    - .save_test_report_artifact\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n    - if: $CI_COMMIT_TAG\n    - when: manual # Can be triggered in all other scenarios\n      allow_failure: true\n  before_script:\n    - !reference [.snippets, define-powershell-GetTime]\n    - Write-Output \"$([char]27)[0Ksection_start:$(GetTime):install_dependencies[collapsed=true]$([char]13)$([char]27)[0KInstalling dependencies\"\n    - powershell -command \"Get-Volume | Format-Table -AutoSize\"\n    - $python_name = $DEFAULT_PYTHON + \"-windows-x86_64\"\n    - tools/packman/packman.cmd install -l _build/target-deps/python python $python_name\n    - '& $env:CI_PROJECT_DIR\\_build\\target-deps\\python\\python.exe -m venv _venv'\n    - .\\_venv\\Scripts\\Activate.ps1\n    - python -m pip install --upgrade pip\n    - python -m pip install --upgrade usd-core numpy\n    - python -m pip install --upgrade torch --extra-index-url https://download.pytorch.org/whl/cu121\n    - python -m pip install -e .\n    - Write-Output \"$([char]27)[0Ksection_end:$(GetTime):install_dependencies$([char]13)$([char]27)[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml -s autodetect --failfast\n  tags:\n    - os/windows\n    - gpu/2x-A5000\n\n# Note: This will no longer be needed once Warp auto-initializes upon import\nlinux-x86_64 test warp-init:\n  stage: test\n  needs: [linux-x86_64 build]\n  extends:\n    - .omni_nvks_gpu\n    - .save_test_report_artifact\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH \n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - if: $CI_PIPELINE_SOURCE == \"web\"\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n      changes:\n        - .gitlab/ci/*\n        - warp/**/*\n        - pyproject.toml\n        - tools/**/*\n        - deps/*\n        - build_lib.py\n        - build_llvm.py\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n      allow_failure: true\n  timeout: 10m\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KInstalling dependencies\"\n    - df -h\n    # Move compiled binaries out of platform-specific directory\n    - mv warp/bin/linux-x86_64/warp.so warp/bin/\n    - mv warp/bin/linux-x86_64/warp-clang.so warp/bin/\n    - tools/packman/packman install -l _build/target-deps/python python ${DEFAULT_PYTHON}-linux-x86_64\n    - $PYTHON -m venv _venv\n    - source _venv/bin/activate\n    - python -m pip install --upgrade pip\n    - python -m pip install -e .\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - python -m warp.tests --junit-report-xml rspec.xml -s autodetect --disable-process-pooling --disable-concurrent-futures --level test -p 'test_implicit_init.py'\n\n# The only purpose of this job is to make sure documentation can be built on Windows.\n# The output does not get published anywhere, but the website can be viewed in the\n# artifacts.\nwindows-x86_64 docs:\n  stage: test\n  needs: [windows-x86_64 build]\n  extends:\n    - .runner-utility-windows-x86_64\n  artifacts:\n    paths:\n      - public\n  before_script:\n    - !reference [.snippets, define-powershell-GetTime]\n    - Write-Output \"$([char]27)[0Ksection_start:$(GetTime):install_dependencies[collapsed=true]$([char]13)$([char]27)[0KInstalling dependencies\"\n    - powershell -command \"Get-Volume | Format-Table -AutoSize\"\n    - $python_name = \"3.12.6+nv1-windows-x86_64\"\n    - tools/packman/packman.cmd install -l _build/target-deps/python python $python_name\n    - '& $env:CI_PROJECT_DIR\\_build\\target-deps\\python\\python.exe -m venv _venv'\n    - .\\_venv\\Scripts\\Activate.ps1\n    - python -m pip install --upgrade pip\n    - python -m pip install -r docs/requirements.txt\n    - Write-Output \"$([char]27)[0Ksection_end:$(GetTime):install_dependencies$([char]13)$([char]27)[0K\"\n  script:\n    - python build_docs.py --no_doctest\n    - mv docs/_build/html/ ./public/\n  after_script:\n    - echo \"View the website at https://$CI_PROJECT_ROOT_NAMESPACE.$CI_PAGES_DOMAIN/-/$CI_PROJECT_NAME/-/jobs/$CI_JOB_ID/artifacts/public/index.html\"\n\n# This job tests code snippets in the documentation\ndoctest:\n  stage: test\n  image: python:3.11-slim\n  needs: [linux-x86_64 build]\n  extends:\n    - .omni_nvks_gpu\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KSet up docs environment\"\n    - df -h\n    - apt-get update && apt-get install make --no-install-recommends -y\n    # Move compiled binaries out of platform-specific directory\n    - mv warp/bin/linux-x86_64/warp.so warp/bin/\n    - mv warp/bin/linux-x86_64/warp-clang.so warp/bin/\n    - python -m pip install --upgrade pip\n    - python -m pip install -r docs/requirements.txt\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - sphinx-build -b doctest docs docs/_build/doctest\n\n# ==============================================================================\n# Child pipelines\n#\n# The child pipelines defined here are only run in specific\n# circumstances. Most developers don't need to worry about the\n# jobs in this section.\n# ==============================================================================\n\n# Trigger additional (no code coverage) pipelines testing more Python versions\n# Workaround from https://gitlab.com/gitlab-org/gitlab/-/issues/284086\ntrigger python 3.X test pipelines:\n  stage: test\n  image: busybox\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - when: manual # Can be triggered in all other scenarios\n      allow_failure: true\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo \"Run this job to test additional Python versions.\"\n\npython 3.8 test:\n  stage: child pipelines\n  needs: [trigger python 3.X test pipelines]\n  trigger:\n    include: /.gitlab/ci/additional-tests.yml\n  extends:\n    - .trigger_common\n  variables:\n    DEFAULT_PYTHON: \"3.8.18+nv1\"\n\n# Trigger debug build and test (no code coverage) pipelines\n# Workaround from https://gitlab.com/gitlab-org/gitlab/-/issues/284086\ntrigger debug build and test pipeline:\n  stage: test\n  image: busybox\n  extends:\n    - .runner-utility-linux-x86_64\n  needs: []\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - when: manual # Can be triggered in all other scenarios\n      allow_failure: true\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo \"Run this job to test Warp compiled in debug mode.\"\n\n# Uses the same Python version as the main pipeline.\ndebug build and test:\n  stage: child pipelines\n  needs: [trigger debug build and test pipeline]\n  trigger:\n    include: /.gitlab/ci/debug-build-and-test.yml\n  extends:\n    - .trigger_common\n\n# Trigger CUDA 11 pipelines\n# Workaround from https://gitlab.com/gitlab-org/gitlab/-/issues/284086\ntrigger cuda 11 pipeline:\n  stage: test\n  image: busybox\n  extends:\n    - .runner-utility-linux-x86_64\n  needs: []\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - when: manual # Can be triggered in all other scenarios\n      allow_failure: true\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - echo \"Run this job to test Warp compiled with CUDA 11.\"\n\n# Uses the same Python version as the main pipeline.\ncuda 11 build and test:\n  stage: child pipelines\n  needs: [trigger cuda 11 pipeline]\n  trigger:\n    include: /.gitlab/ci/cuda-11-build-and-test.yml\n  extends:\n    - .trigger_common\n\n# ==============================================================================\n# Packaging Jobs\n#\n# Kit and PyPI jobs produce deployment artifacts and are not run in MRs unless\n# manually started.\n# ==============================================================================\n\n# Creates wheel files for PyPI\ncreate pypi wheels:\n  stage: package\n  needs:\n    - linux-aarch64 build\n    - linux-x86_64 build\n    - windows-x86_64 build\n    - mac-x86_64 build\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n      changes:\n        - pyproject.toml\n        - setup.py\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n      allow_failure: true\n  before_script:\n    # Move binaries into platform-specific folders. Already done in the build jobs for Linux.\n    - mkdir -p warp/bin/windows-x86_64\n    - mv warp/bin/warp.dll warp/bin/windows-x86_64/\n    - mv warp/bin/warp-clang.dll warp/bin/windows-x86_64/\n    - mkdir -p warp/bin/macos-universal\n    - mv warp/bin/libwarp.dylib warp/bin/macos-universal/\n    - mv warp/bin/libwarp-clang.dylib warp/bin/macos-universal/\n    - python3 -m pip install --upgrade pip\n    - python3 -m pip install build\n  script:\n    - sed -i \"s/^\\(.*\\)$/\\1+cu12/\" VERSION.md  # Modify VERSION.md with +cu12\n    - python3 -m build --wheel -C--build-option=-Pwindows-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-aarch64\n    - sed -i \"s/^\\(.*\\)+cu12$/\\1+cpu/\" VERSION.md  # Modify VERSION.md with +cu12 replaced by +cpu\n    - python3 -m build --wheel -C--build-option=-Pmacos-universal\n    - sed -i \"s/^\\(.*\\)+cpu$/\\1/\" VERSION.md  # Revert VERSION.md changes\n    - mv dist dist-github\n    # Now make the wheels meant for PyPI publishing\n    - python3 -m build --wheel -C--build-option=-Pwindows-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-aarch64\n    - python3 -m build --wheel -C--build-option=-Pmacos-universal\n    - find . -type f -exec chmod 664 {} +\n    - find . -type d -exec chmod 775 {} +\n  artifacts:\n    name: $CI_COMMIT_REF_SLUG-$CI_COMMIT_SHORT_SHA\n    expose_as: \"Python Wheels\"\n    paths:\n      - \"dist/\"\n      - \"dist-github/\"\n    when: always\n\ncreate dev wheels:\n  stage: package\n  needs:\n    - linux-aarch64 build\n    - linux-x86_64 build\n    - windows-x86_64 build\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n    - when: never\n  before_script:\n    # Move binaries into platform-specific folders. Already done in the build jobs for Linux.\n    - mkdir -p warp/bin/windows-x86_64\n    - mv warp/bin/warp.dll warp/bin/windows-x86_64/\n    - mv warp/bin/warp-clang.dll warp/bin/windows-x86_64/\n    - python3 -m pip install --upgrade pip\n    - python3 -m pip install build\n  script:\n    - python3 tools/ci/publishing/set_nightly_version.py  # Modify VERSION.md with dev version\n    - python3 -m build --wheel -C--build-option=-Pwindows-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-x86_64\n    - python3 -m build --wheel -C--build-option=-Plinux-aarch64\n    - find . -type f -exec chmod 664 {} +\n    - find . -type d -exec chmod 775 {} +\n    - cp VERSION.md dist/\n  artifacts:\n    name: $CI_COMMIT_REF_SLUG-$CI_COMMIT_SHORT_SHA-dev\n    paths:\n      - \"dist/\"\n\n# ==============================================================================\n# Deployment Jobs\n#\n# This section currently contains jobs that publish files to the internal\n# GitLab service.\n# ==============================================================================\n\npublish wheels to testpypi registry:\n  stage: deploy\n  image: python:3.11-slim\n  needs: [\"create pypi wheels\"]\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_COMMIT_BRANCH =~ /release-.*/ || $CI_COMMIT_TAG\n      when: manual\n      allow_failure: true\n  environment:\n    name: staging\n    url: https://test.pypi.org/project/warp-lang/\n  before_script:\n    - python3 -m pip install --upgrade pip\n    - python3 -m pip install --upgrade build twine\n  script:\n    - python3 -m twine upload --verbose --skip-existing --non-interactive --repository testpypi dist/* -u __token__ -p $TESTPYPI_DEPLOY_KEY\n\npublish wheels to pypi registry:\n  stage: deploy\n  image: python:3.11-slim\n  needs: [\"create pypi wheels\"]\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_COMMIT_TAG\n      when: manual\n      allow_failure: true\n  environment:\n    name: production\n    url: https://pypi.org/project/warp-lang/\n  before_script:\n    - python3 -m pip install --upgrade pip\n    - python3 -m pip install --upgrade build twine\n  script:\n    - python3 -m twine upload --verbose --skip-existing --non-interactive dist/* -u __token__ -p $PYPI_DEPLOY_KEY\n\npublish wheels to gitlab pypi registry:\n  stage: deploy\n  image: python:3.11-slim\n  needs: [\"create pypi wheels\"]\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/ || $CI_COMMIT_TAG\n      when: manual\n      allow_failure: true\n  before_script:\n    - python3 -m pip install --upgrade pip\n    - python3 -m pip install --upgrade build twine\n  script:\n    - TWINE_PASSWORD=${CI_JOB_TOKEN} TWINE_USERNAME=gitlab-ci-token python3 -m twine upload --verbose --skip-existing --non-interactive --repository-url ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi dist-github/*\n\n# Uploads the wheels to the internal GitLab package registry in the Warp project\n# Generated files will be in a branch/tag-specific folder\npublish wheels to gitlab package registry:\n  stage: deploy\n  needs: [\"create pypi wheels\"]\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_COMMIT_TAG\n    - if: $CI_COMMIT_BRANCH =~ /^release-.*/\n    - when: manual # If not auto-triggered, allow any pipeline to run this job manually\n      allow_failure: true\n  before_script:\n    - apt-get update && apt-get install curl --no-install-recommends -y\n  script:\n    - |\n      for file in $(find . -name '*.whl'); do\n          filename=$(basename -- \"$file\")\n          curl --header \"JOB-TOKEN: $CI_JOB_TOKEN\" --upload-file \"$file\" \"${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/warp/${CI_COMMIT_REF_SLUG}/${filename}\"\n      done\n    - echo \"See the published files at $CI_PROJECT_URL/-/packages\"\n\npublish dev wheels to artifactory:\n  stage: deploy\n  image: releases-docker.jfrog.io/jfrog/jfrog-cli-v2-jf\n  needs:\n    - job: create dev wheels\n      optional: true\n  extends:\n    - .runner-utility-linux-x86_64\n  rules: # Should be consistent with create dev wheels\n    - if: $CI_PIPELINE_SOURCE == \"schedule\" && $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  allow_failure: true\n  before_script:\n    - export VERSION=$(head -n 1 dist/VERSION.md)\n  script:\n    - cd dist\n    - >\n      jf rt u --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      --target-props 'component_name=warp-lang;release_approver=ershi;release_status=ready'\n      '*.whl' sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/\n    # Set build-specific properties on individual artifacts\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-win_amd64.whl\n      'arch=x86_64;os=windows'\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-manylinux2014_aarch64.whl\n      'arch=aarch64;os=linux'\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-manylinux2014_x86_64.whl\n      'arch=x86_64;os=linux'\n    # Set additional common properties on all artifacts\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*.whl\n      version=$VERSION\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*.whl\n      branch=$CI_COMMIT_REF_NAME\n\npublish tag wheels to artifactory:\n  stage: deploy\n  image: releases-docker.jfrog.io/jfrog/jfrog-cli-v2-jf\n  needs: [\"create pypi wheels\"]\n  extends:\n    - .runner-utility-linux-x86_64\n  rules:\n    - if: $CI_COMMIT_TAG\n  allow_failure: true\n  before_script:\n    - export VERSION=$(head -n 1 VERSION.md)\n  script:\n    - cd dist\n    - >\n      jf rt u --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      --target-props 'component_name=warp-lang;release_approver=ershi;release_status=ready'\n      '*.whl' sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/\n    # Set build-specific properties on individual artifacts\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-win_amd64.whl\n      'arch=x86_64;os=windows'\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-manylinux2014_aarch64.whl\n      'arch=aarch64;os=linux'\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-manylinux2014_x86_64.whl\n      'arch=x86_64;os=linux'\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*-macosx_*_universal2.whl\n      'arch=universal;os=macosx'\n    # Set additional common properties on all artifacts\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*.whl\n      version=$VERSION\n    - >\n      jf rt sp --fail-no-op --url=$ARTIFACTORY_BASE_URL --access-token $ARTIFACTORY_SVC_ACCESS_TOKEN\n      sw-warp-pypi-local/warp/$CI_COMMIT_REF_NAME/$VERSION/*.whl\n      branch=$CI_COMMIT_REF_NAME\n\n.build-docs-common:\n  stage: deploy\n  image: python:3.11-slim\n  needs: [linux-x86_64 build]\n  extends:\n    - .runner-utility-linux-x86_64\n  artifacts:\n    paths:\n      - public\n  before_script:\n    - echo -e \"\\\\e[0Ksection_start:`date +%s`:install_dependencies[collapsed=true]\\\\r\\\\e[0KSet up docs environment\"\n    - df -h\n    - apt-get update && apt-get install make --no-install-recommends -y\n    # Move compiled binaries out of platform-specific directory\n    - mv warp/bin/linux-x86_64/warp.so warp/bin/\n    - mv warp/bin/linux-x86_64/warp-clang.so warp/bin/\n    - python -m pip install --upgrade pip\n    - python -m pip install -r docs/requirements.txt\n    - echo -e \"\\\\e[0Ksection_end:`date +%s`:install_dependencies\\\\r\\\\e[0K\"\n  script:\n    - python build_docs.py --no_doctest\n    - mv docs/_build/html/ ./public/\n\n# Merge requests: Build documentation and save as an artifact\n# A link to the generated documentation is added to the merge request.\nmerge request docs:\n  extends:\n    - .build-docs-common\n  artifacts:\n    paths:\n      - warp/stubs.py\n      - docs/modules/functions.rst\n      - public\n  rules:\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n  timeout: 10m\n  environment:\n    name: review/$CI_MERGE_REQUEST_IID\n    url: https://$CI_PROJECT_ROOT_NAMESPACE.$CI_PAGES_DOMAIN/-/$CI_PROJECT_NAME/-/jobs/$CI_JOB_ID/artifacts/public/index.html\n  after_script:\n    - echo \"View the website at https://$CI_PROJECT_ROOT_NAMESPACE.$CI_PAGES_DOMAIN/-/$CI_PROJECT_NAME/-/jobs/$CI_JOB_ID/artifacts/public/index.html\"\n\n\n# Merge requests: Ensure that exports.h, stubs.py, functions.rst have been\n# manually added to the MR if they are changed\ncheck generated files:\n  needs:\n    - job: linux-x86_64 build\n    - job: merge request docs\n      optional: true\n  stage: deploy\n  artifacts:\n    when: on_failure\n    expose_as: 'Generated source files'\n    paths:\n      - warp/native/exports.h\n      - warp/stubs.py\n      - docs/modules/functions.rst\n  rules:\n    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'\n  timeout: 10m\n  extends:\n    - .runner-utility-linux-x86_64\n  script:\n    - >\n      git diff --exit-code warp/stubs.py docs/modules/functions.rst ||\n      (echo \"Please run build_docs.py (or download from $CI_JOB_URL/artifacts/browse) and add modified files to your merge request.\" && false)\n    - >\n      git diff --exit-code warp/native/exports.h ||\n      (echo \"Please run build_lib.py  (or download from $CI_JOB_URL/artifacts/browse) and add warp/native/exports.h to your merge request.\" && false)\n\n# Build documentation and publish on gitlab-master\n# This only runs in the default branch pipeline. The \"pages\" name is special for GitLab.\npages:\n  extends:\n    - .build-docs-common\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n  timeout: 10m\n  environment:\n    name: GitLab Pages\n    deployment_tier: staging\n    url: $CI_PAGES_URL\n"
        },
        {
          "name": ".gitlab",
          "type": "tree",
          "content": null
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.599609375,
          "content": "ci:\n  autofix_commit_msg: |\n    [pre-commit.ci] auto code formatting\n  autofix_prs: false\n  autoupdate_branch: \"\"\n  autoupdate_commit_msg: \"[pre-commit.ci] pre-commit autoupdate\"\n  autoupdate_schedule: quarterly\n  skip: []\n  submodules: false\n\n# See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    # Ruff version.\n    rev: v0.9.0\n    hooks:\n      # Run the linter.\n      - id: ruff\n        args: [--fix] # Apply fixes to resolve lint violations.\n      # Run the formatter.\n      - id: ruff-format\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 77.3173828125,
          "content": "# Changelog\n\n## [Unreleased] - 2025-??\n\n### Added\n\n- Support `assert` statements in kernels ([docs](https://nvidia.github.io/warp/debugging.html#assertions)).\n  Assertions can only be triggered in `\"debug\"` mode ([GH-366](https://github.com/NVIDIA/warp/issues/336)).\n- Add optimization example for soft-body properties ([GH-419](https://github.com/NVIDIA/warp/pull/419)).\n- Add per-module option to disable fused floating point operations, use `wp.set_module_options({\"fuse_fp\": False})`\n  ([GH-379](https://github.com/NVIDIA/warp/issues/379)).\n\n### Changed\n\n### Fixed\n\n- Fix errors during graph capture caused by module unloading ([GH-401](https://github.com/NVIDIA/warp/issues/401)).\n- Fix allocating arrays with strides ([GH-404](https://github.com/NVIDIA/warp/issues/404)).\n- Fix `ImportError` exception being thrown during `OpenGLRenderer` interpreter shutdown on Windows\n  ([GH-412](https://github.com/NVIDIA/warp/issues/412)).\n- Fix scale and rotation issues with the rock geometry used in the granular collision SDF example\n  ([GH-409](https://github.com/NVIDIA/warp/issues/409)).\n- Fix so that `wp.Tape.zero()` zeroes gradients passed via the 'grads' parameter in `wp.Tape.backward()` ([GH-407](https://github.com/NVIDIA/warp/issues/407)).\n- Fix the OpenGL renderer not working when multiple instances exist at the same time ([GH-385](https://github.com/NVIDIA/warp/issues/385)).\n- Negative constants evaluate to compile-time constants (fixes [GH-403](https://github.com/NVIDIA/warp/issues/403))\n\n## [1.5.1] - 2025-01-02\n\n### Added\n\n- Add PyTorch basics and custom operators notebooks to the `notebooks` directory.\n- Update PyTorch interop docs to include section on custom operators\n  ([docs](https://nvidia.github.io/warp/modules/interoperability.html#pytorch-custom-ops-example)).\n\n### Fixed\n\n- warp.sim: Fix a bug in which the color-balancing algorithm was not updating the colorings.\n- Fix custom colors being not being updated when rendering meshes with static topology in OpenGL\n  ([GH-343](https://github.com/NVIDIA/warp/issues/343)).\n- Fix `wp.launch_tiled()` not returning a `Launch` object when passed `record_cmd=True`.\n- Fix default arguments not being resolved for `wp.func` when called from Python's runtime\n  ([GH-386](https://github.com/NVIDIA/warp/issues/386)).\n- Array overwrite tracking: Fix issue with not marking arrays passed to `wp.atomic_add()`, `wp.atomic_sub()`,\n  `wp.atomic_max()`, or `wp.atomic_min()` as being written to ([GH-378](https://github.com/NVIDIA/warp/issues/378)).\n- Fix for occasional failure to update `.meta` files into Warp kernel cache on Windows.\n- Fix the OpenGL renderer not being able to run without a CUDA device available\n  ([GH-344](https://github.com/NVIDIA/warp/issues/344)).\n- Fix incorrect CUDA driver function versions ([GH-402](https://github.com/NVIDIA/warp/issues/402)).\n\n## [1.5.0] - 2024-12-02\n\n### Added\n\n- Support for cooperative tile-based primitives using cuBLASDx and cuFFTDx, please see the tile\n  [documentation](https://nvidia.github.io/warp/modules/tiles.html) for details.\n- Expose a `reversed()` built-in for iterators ([GH-311](https://github.com/NVIDIA/warp/issues/311)).\n- Support for saving Volumes into `.nvdb` files with the `save_to_nvdb` method.\n- warp.fem: Add `wp.fem.Trimesh3D` and `wp.fem.Quadmesh3D` geometry types for 3D surfaces with new `example_distortion_energy` example.\n- warp.fem: Add `\"add\"` option to `wp.fem.integrate()` for accumulating integration result to existing output.\n- warp.fem: Add `\"assembly\"` option to `wp.fem.integrate()` for selecting between more memory-efficient or more\n  computationally efficient integration algorithms.\n- warp.fem: Add Nédélec (first kind) and Raviart-Thomas vector-valued function spaces\n  providing conforming discretization of `curl` and `div` operators, respectively.\n- warp.sim: Add a graph coloring module that supports converting trimesh into a vertex graph and applying coloring.\n  The `wp.sim.ModelBuilder` now includes methods to color particles for use with `wp.sim.VBDIntegrator()`,\n  users should call `builder.color()` before finalizing assets.\n- warp.sim: Add support for a per-particle radius for soft-body triangle contact using the `wp.sim.Model.particle_radius`\n  array ([docs](https://nvidia.github.io/warp/modules/sim.html#warp.sim.Model.particle_radius)), replacing the previous\n  hard-coded value of 0.01 ([GH-329](https://github.com/NVIDIA/warp/issues/329)).\n- Add a `particle_radius` parameter to `wp.sim.ModelBuilder.add_cloth_mesh()` and `wp.sim.ModelBuilder.add_cloth_grid()`\n  to set a uniform radius for the added particles.\n- Document `wp.array` attributes ([GH-364](https://github.com/NVIDIA/warp/issues/364)).\n- Document time-to-compile tradeoffs when using vector component assignment statements in kernels.\n- Add introductory Jupyter notebooks to the `notebooks` directory.\n\n### Changed\n\n- Drop support for Python 3.7; Python 3.8 is now the minimum-supported version.\n- Promote the `wp.Int`, `wp.Float`, and `wp.Scalar` generic annotation types to the public API.\n- warp.fem: Simplify querying neighboring cell quantities when integrating on sides using new\n  `wp.fem.cells()`, `wp.fem.to_inner_cell()`, `wp.fem.to_outer_cell()` operators.\n- Show an error message when the type returned by a function differs from its annotation, which would have led to the compilation stage failing.\n- Clarify that `wp.randn()` samples a normal distribution of mean 0 and variance 1.\n- Raise error when passing more than 32 variadic argument to the `wp.printf()` built-in.\n\n### Fixed\n\n- Fix `place` setting of paddle backend.\n- warp.fem: Fix tri-cubic shape functions on quadrilateral meshes.\n- warp.fem: Fix caching of integrand kernels when changing code-generation options.\n- Fix `wp.expect_neq()` overloads missing for scalar types.\n- Fix an error when a `wp.kernel` or a `wp.func` object is annotated to return a `None` value.\n- Fix error when reading multi-volume, BLOSC-compressed `.nvdb` files.\n- Fix `wp.printf()` erroring out when no variadic arguments are passed ([GH-333](https://github.com/NVIDIA/warp/issues/333)).\n- Fix memory access issues in soft-rigid contact collisions ([GH-362](https://github.com/NVIDIA/warp/issues/362)).\n- Fix gradient propagation for in-place addition/subtraction operations on custom vector-type arrays.\n- Fix the OpenGL renderer's window not closing when clicking the X button.\n- Fix the OpenGL renderer's camera snapping to a different direction from the initial camera's orientation when first looking around.\n- Fix custom colors being ignored when rendering meshes in OpenGL ([GH-343](https://github.com/NVIDIA/warp/issues/343)).\n- Fix topology updates not being supported by the the OpenGL renderer.\n\n## [1.4.2] - 2024-11-13\n\n### Changed\n\n- Make the output of `wp.print()` in backward kernels consistent for all supported data types.\n\n### Fixed\n\n- Fix to relax the integer types expected when indexing arrays (regression in `1.3.0`).\n- Fix printing vector and matrix adjoints in backward kernels.\n- Fix kernel compile error when printing structs.\n- Fix an incorrect user function being sometimes resolved when multiple overloads are available with array parameters with different `dtype` values.\n- Fix error being raised when static and dynamic for-loops are written in sequence with the same iteration variable names ([GH-331](https://github.com/NVIDIA/warp/issues/331)).\n- Fix an issue with the `Texture Write` node, used in the Mandelbrot Omniverse sample, sometimes erroring out in multi-GPU environments.\n- Code generation of in-place multiplication and division operations (regression introduced in a69d061)([GH-342](https://github.com/NVIDIA/warp/issues/342)).\n\n## [1.4.1] - 2024-10-15\n\n### Fixed\n\n- Fix `iter_reverse()` not working as expected for ranges with steps other than 1 ([GH-311](https://github.com/NVIDIA/warp/issues/311)).\n- Fix potential out-of-bounds memory access when a `wp.sparse.BsrMatrix` object is reused for storing matrices of different shapes.\n- Fix robustness to very low desired tolerance in `wp.fem.utils.symmetric_eigenvalues_qr`.\n- Fix invalid code generation error messages when nesting dynamic and static for-loops.\n- Fix caching of kernels with static expressions.\n- Fix `ModelBuilder.add_builder(builder)` to correctly update `articulation_start` and thereby `articulation_count` when `builder` contains more than one articulation.\n- Re-introduced the `wp.rand*()`, `wp.sample*()`, and `wp.poisson()` onto the Python scope to revert a breaking change.\n\n## [1.4.0] - 2024-10-01\n\n### Added\n\n- Support for a new `wp.static(expr)` function that allows arbitrary Python expressions to be evaluated at the time of\n  function/kernel definition ([docs](https://nvidia.github.io/warp/codegen.html#static-expressions)).\n- Support for stream priorities to hint to the device that it should process pending work\n  in high-priority streams over pending work in low-priority streams when possible\n  ([docs](https://nvidia.github.io/warp/modules/concurrency.html#stream-priorities)).\n- Adaptive sparse grid geometry to `warp.fem` ([docs](https://nvidia.github.io/warp/modules/fem.html#adaptivity)).\n- Support for defining `wp.kernel` and `wp.func` objects from within closures.\n- Support for defining multiple versions of kernels, functions, and structs without manually assigning unique keys.\n- Support for default argument values for user functions decorated with `wp.func`.\n- Allow passing custom launch dimensions to `jax_kernel()` ([GH-310](https://github.com/NVIDIA/warp/pull/310)).\n- JAX interoperability examples for sharding and matrix multiplication ([docs](https://nvidia.github.io/warp/modules/interoperability.html#using-shardmap-for-distributed-computation)).\n- Interoperability support for the PaddlePaddle ML framework ([GH-318](https://github.com/NVIDIA/warp/pull/318)).\n- Support `wp.mod()` for vector types ([GH-282](https://github.com/NVIDIA/warp/issues/282)).\n- Expose the modulo operator `%` to Python's runtime scalar and vector types.\n- Support for fp64 `atomic_add`, `atomic_max`, and `atomic_min` ([GH-284](https://github.com/NVIDIA/warp/issues/284)).\n- Support for quaternion indexing (e.g. `q.w`).\n- Support shadowing builtin functions ([GH-308](https://github.com/NVIDIA/warp/issues/308)).\n- Support for redefining function overloads.\n- Add an ocean sample to the `omni.warp` extension.\n- `warp.sim.VBDIntegrator` now supports body-particle collision.\n- Add a [contributing guide](https://nvidia.github.io/warp/modules/contribution_guide.html) to the Sphinx docs .\n- Add documentation for dynamic code generation ([docs](https://nvidia.github.io/warp/codegen.html#dynamic-kernel-creation)).\n\n### Changed\n\n- `wp.sim.Model.edge_indices` now includes boundary edges.\n- Unexposed `wp.rand*()`, `wp.sample*()`, and `wp.poisson()` from the Python scope.\n- Skip unused functions in module code generation, improving performance.\n- Avoid reloading modules if their content does not change, improving performance.\n- `wp.Mesh.points` is now a property instead of a raw data member, its reference can be changed after the mesh is initialized.\n- Improve error message when invalid objects are referenced in a Warp kernel.\n- `if`/`else`/`elif` statements with constant conditions are resolved at compile time with no branches being inserted in the generated code.\n- Include all non-hidden builtins in the stub file.\n- Improve accuracy of symmetric eigenvalues routine in `warp.fem`.\n\n### Fixed\n\n- Fix for `wp.func` erroring out when defining a `Tuple` as a return type hint ([GH-302](https://github.com/NVIDIA/warp/issues/302)).\n- Fix array in-place op (`+=`, `-=`) adjoints to compute gradients correctly in the backwards pass\n- Fix vector, matrix in-place assignment adjoints to compute gradients correctly in the backwards pass, e.g.: `v[1] = x`\n- Fix a bug in which Python docstrings would be created as local function variables in generated code.\n- Fix a bug with autograd array access validation in functions from different modules.\n- Fix a rare crash during error reporting on some systems due to glibc mismatches.\n- Handle `--num_tiles 1` in `example_render_opengl.py` ([GH-306](https://github.com/NVIDIA/warp/issues/306)).\n- Fix the computation of body contact forces in `FeatherstoneIntegrator` when bodies and particles collide.\n- Fix bug in `FeatherstoneIntegrator` where `eval_rigid_jacobian` could give incorrect results or reach an infinite\n  loop when the body and joint indices were not in the same order. Added `Model.joint_ancestor` to fix the indexing\n  from a joint to its parent joint in the articulation.\n- Fix wrong vertex index passed to `add_edges()` called from `ModelBuilder.add_cloth_mesh()` ([GH-319](https://github.com/NVIDIA/warp/issues/319)).\n- Add a workaround for uninitialized memory read warning in the `compute-sanitizer` initcheck tool when using `wp.Mesh`.\n- Fix name clashes when Warp functions and structs are returned from Python functions multiple times.\n- Fix name clashes between Warp functions and structs defined in different modules.\n- Fix code generation errors when overloading generic kernels defined in a Python function.\n- Fix issues with unrelated functions being treated as overloads (e.g., closures).\n- Fix handling of `stream` argument in `array.__dlpack__()`.\n- Fix a bug related to reloading CPU modules.\n- Fix a crash when kernel functions are not found in CPU modules.\n- Fix conditions not being evaluated as expected in `while` statements.\n- Fix printing Boolean and 8-bit integer values.\n- Fix array interface type strings used for Boolean and 8-bit integer values.\n- Fix initialization error when setting struct members.\n- Fix Warp not being initialized upon entering a `wp.Tape` context.\n- Use `kDLBool` instead of `kDLUInt` for DLPack interop of Booleans.\n\n## [1.3.3] - 2024-09-04\n\n- Bug fixes\n  - Fix an aliasing issue with zero-copy array initialization from NumPy introduced in Warp 1.3.0.\n  - Fix `wp.Volume.load_from_numpy()` behavior when `bg_value` is a sequence of values ([GH-312](https://github.com/NVIDIA/warp/pull/312)).\n\n## [1.3.2] - 2024-08-30\n\n- Bug fixes\n  - Fix accuracy of 3x3 SVD ``wp.svd3`` with fp64 numbers ([GH-281](https://github.com/NVIDIA/warp/issues/281)).\n  - Fix module hashing when a kernel argument contained a struct array ([GH-287](https://github.com/NVIDIA/warp/issues/287)).\n  - Fix a bug in `wp.bvh_query_ray()` where the direction instead of the reciprocal direction was used ([GH-288](https://github.com/NVIDIA/warp/issues/288)).\n  - Fix errors when launching a CUDA graph after a module is reloaded. Modules that were used during graph capture\n    will no longer be unloaded before the graph is released.\n  - Fix a bug in `wp.sim.collide.triangle_closest_point_barycentric()` where the returned barycentric coordinates may be\n    incorrect when the closest point lies on an edge.\n  - Fix 32-bit overflow when array shape is specified using `np.int32`.\n  - Fix handling of integer indices in the `input_output_mask` argument to `autograd.jacobian` and\n    `autograd.jacobian_fd` ([GH-289](https://github.com/NVIDIA/warp/issues/289)).\n  - Fix `ModelBuilder.collapse_fixed_joints()` to correctly update the body centers of mass and the\n    `ModelBuilder.articulation_start` array.\n  - Fix precedence of closure constants over global constants.\n  - Fix quadrature point indexing in `wp.fem.ExplicitQuadrature` (regression from 1.3.0).\n- Documentation improvements\n  - Add missing return types for built-in functions.\n  - Clarify that atomic operations also return the previous value.\n  - Clarify that `wp.bvh_query_aabb()` returns parts that overlap the bounding volume.\n\n## [1.3.1] - 2024-07-27\n\n- Remove `wp.synchronize()` from PyTorch autograd function example\n- `Tape.check_kernel_array_access()` and `Tape.reset_array_read_flags()` are now private methods.\n- Fix reporting unmatched argument types\n\n## [1.3.0] - 2024-07-25\n\n- Warp Core improvements\n  - Update to CUDA 12.x by default (requires NVIDIA driver 525 or newer), please see [README.md](https://github.com/nvidia/warp?tab=readme-ov-file#installing) for commands to install CUDA 11.x binaries for older drivers\n  - Add information to the module load print outs to indicate whether a module was\n  compiled `(compiled)`, loaded from the cache `(cached)`, or was unable to be\n  loaded `(error)`.\n  - `wp.config.verbose = True` now also prints out a message upon the entry to a `wp.ScopedTimer`.\n  - Add `wp.clear_kernel_cache()` to the public API. This is equivalent to `wp.build.clear_kernel_cache()`.\n  - Add code-completion support for `wp.config` variables.\n  - Remove usage of a static task (thread) index for CPU kernels to address multithreading concerns ([GH-224](https://github.com/NVIDIA/warp/issues/224))\n  - Improve error messages for unsupported Python operations such as sequence construction in kernels\n  - Update `wp.matmul()` CPU fallback to use dtype explicitly in `np.matmul()` call\n  - Add support for PEP 563's `from __future__ import annotations` ([GH-256](https://github.com/NVIDIA/warp/issues/256)).\n  - Allow passing external arrays/tensors to `wp.launch()` directly via `__cuda_array_interface__` and `__array_interface__`, up to 2.5x faster conversion from PyTorch\n  - Add faster Torch interop path using `return_ctype` argument to `wp.from_torch()`\n  - Handle incompatible CUDA driver versions gracefully\n  - Add `wp.abs()` and `wp.sign()` for vector types\n  - Expose scalar arithmetic operators to Python's runtime (e.g.: `wp.float16(1.23) * wp.float16(2.34)`)\n  - Add support for creating volumes with anisotropic transforms\n  - Allow users to pass function arguments by keyword in a kernel using standard Python calling semantics\n  - Add additional documentation and examples demonstrating `wp.copy()`, `wp.clone()`, and `array.assign()` differentiability\n  - Add `__new__()` methods for all class `__del__()` methods to handle when a class instance is created but not instantiated before garbage collection\n  - Implement the assignment operator for `wp.quat`\n  - Make the geometry-related built-ins available only from within kernels\n  - Rename the API-facing query types to remove their `_t` suffix: `wp.BVHQuery`, `wp.HashGridQuery`, `wp.MeshQueryAABB`, `wp.MeshQueryPoint`, and `wp.MeshQueryRay`\n  - Add `wp.array(ptr=...)` to allow initializing arrays from pointer addresses inside of kernels ([GH-206](https://github.com/NVIDIA/warp/issues/206))\n\n- `warp.autograd` improvements:\n  - New `warp.autograd` module with utility functions `gradcheck()`, `jacobian()`, and `jacobian_fd()` for debugging kernel Jacobians ([docs](https://nvidia.github.io/warp/modules/differentiability.html#measuring-gradient-accuracy))\n  - Add array overwrite detection, if `wp.config.verify_autograd_array_access` is true in-place operations on arrays on the Tape that could break gradient computation will be detected ([docs](https://nvidia.github.io/warp/modules/differentiability.html#array-overwrite-tracking))\n  - Fix bug where modification of `@wp.func_replay` functions and native snippets would not trigger module recompilation\n  - Add documentation for dynamic loop autograd limitations\n\n- `warp.sim` improvements:\n  - Improve memory usage and performance for rigid body contact handling when `self.rigid_mesh_contact_max` is zero (default behavior).\n  - The `mask` argument to `wp.sim.eval_fk()` now accepts both integer and boolean arrays to mask articulations.\n  - Fix handling of `ModelBuilder.joint_act` in `ModelBuilder.collapse_fixed_joints()` (affected floating-base systems)\n  - Fix and improve implementation of `ModelBuilder.plot_articulation()` to visualize the articulation tree of a rigid-body mechanism\n  - Fix ShapeInstancer `__new__()` method (missing instance return and `*args` parameter)\n  - Fix handling of `upaxis` variable in `ModelBuilder` and the rendering thereof in `OpenGLRenderer`\n\n- `warp.sparse` improvements:\n  - Sparse matrix allocations (from `bsr_from_triplets()`, `bsr_axpy()`, etc.) can now be captured in CUDA graphs; exact number of non-zeros can be optionally requested asynchronously.\n  - `bsr_assign()` now supports changing block shape (including CSR/BSR conversions)\n  - Add Python operator overloads for common sparse matrix operations, e.g `A += 0.5 * B`, `y = x @ C`\n\n- `warp.fem` new features and fixes:\n  - Support for variable number of nodes per element\n  - Global `wp.fem.lookup()` operator now supports `wp.fem.Tetmesh` and `wp.fem.Trimesh2D` geometries\n  - Simplified defining custom subdomains (`wp.fem.Subdomain`), free-slip boundary conditions\n  - New field types: `wp.fem.UniformField`, `wp.fem.ImplicitField` and `wp.fem.NonconformingField`\n  - New `streamlines`, `magnetostatics` and `nonconforming_contact` examples, updated `mixed_elasticity` to use a nonlinear model\n  - Function spaces can now export VTK-compatible cells for visualization\n  - Fixed edge cases with NanoVDB function spaces\n  - Fixed differentiability of `wp.fem.PicQuadrature` w.r.t. positions and measures\n\n## [1.2.2] - 2024-07-04\n\n- Fix hashing of replay functions and snippets\n- Add additional documentation and examples demonstrating `wp.copy()`, `wp.clone()`, and `array.assign()` differentiability\n- Add `__new__()` methods for all class `__del__()` methods to\n  handle when a class instance is created but not instantiated before garbage collection.\n- Add documentation for dynamic loop autograd limitations\n- Allow users to pass function arguments by keyword in a kernel using standard Python calling semantics\n- Implement the assignment operator for `wp.quat`\n\n## [1.2.2] - 2024-07-04\n\n- Support for NumPy >= 2.0\n\n## [1.2.1] - 2024-06-14\n\n- Fix generic function caching\n- Fix Warp not being initialized when constructing arrays with `wp.array()`\n- Fix `wp.is_mempool_access_supported()` not resolving the provided device arguments to `wp.context.Device`\n\n## [1.2.0] - 2024-06-06\n\n- Add a not-a-number floating-point constant that can be used as `wp.NAN` or `wp.nan`.\n- Add `wp.isnan()`, `wp.isinf()`, and `wp.isfinite()` for scalars, vectors, matrices, etc.\n- Improve kernel cache reuse by hashing just the local module constants. Previously, a\n  module's hash was affected by all `wp.constant()` variables declared in a Warp program.\n- Revised module compilation process to allow multiple processes to use the same kernel cache directory.\n  Cached kernels will now be stored in hash-specific subdirectory.\n- Add runtime checks for `wp.MarchingCubes` on field dimensions and size\n- Fix memory leak in `wp.Mesh` BVH ([GH-225](https://github.com/NVIDIA/warp/issues/225))\n- Use C++17 when building the Warp library and user kernels\n- Increase PTX target architecture up to `sm_75` (from `sm_70`), enabling Turing ISA features\n- Extended NanoVDB support (see `warp.Volume`):\n  - Add support for data-agnostic index grids, allocation at voxel granularity\n  - New `wp.volume_lookup_index()`, `wp.volume_sample_index()` and generic `wp.volume_sample()`/`wp.volume_lookup()`/`wp.volume_store()` kernel-level functions\n  - Zero-copy aliasing of in-memory grids, support for multi-grid buffers\n  - Grid introspection and blind data access capabilities\n  - `warp.fem` can now work directly on NanoVDB grids using `warp.fem.Nanogrid`\n  - Fixed `wp.volume_sample_v()` and `wp.volume_store_*()` adjoints\n  - Prevent `wp.volume_store()` from overwriting grid background values\n- Improve validation of user-provided fields and values in `warp.fem`\n- Support headless rendering of `wp.render.OpenGLRenderer` via `pyglet.options[\"headless\"] = True`\n- `wp.render.RegisteredGLBuffer` can fall back to CPU-bound copying if CUDA/OpenGL interop is not available\n- Clarify terms for external contributions, please see CONTRIBUTING.md for details\n- Improve performance of `wp.sparse.bsr_mm()` by ~5x on benchmark problems\n- Fix for XPBD incorrectly indexing into of joint actuations `joint_act` arrays\n- Fix for mass matrix gradients computation in `wp.sim.FeatherstoneIntegrator()`\n- Fix for handling of `--msvc_path` in build scripts\n- Fix for `wp.copy()` params to record dest and src offset parameters on `wp.Tape()`\n- Fix for `wp.randn()` to ensure return values are finite\n- Fix for slicing of arrays with gradients in kernels\n- Fix for function overload caching, ensure module is rebuilt if any function overloads are modified\n- Fix for handling of `bool` types in generic kernels\n- Publish CUDA 12.5 binaries for Hopper support, see https://github.com/nvidia/warp?tab=readme-ov-file#installing for details\n\n## 1.1.1 - 2024-05-24\n\n- `wp.init()` is no longer required to be called explicitly and will be performed on first call to the API\n- Speed up `omni.warp.core`'s startup time\n\n## [1.1.0] - 2024-05-09\n\n- Support returning a value from `@wp.func_native` CUDA functions using type hints\n- Improved differentiability of the `wp.sim.FeatherstoneIntegrator`\n- Fix gradient propagation for rigid body contacts in `wp.sim.collide()`\n- Added support for event-based timing, see `wp.ScopedTimer()`\n- Added Tape visualization and debugging functions, see `wp.Tape.visualize()`\n- Support constructing Warp arrays from objects that define the `__cuda_array_interface__` attribute\n- Support copying a struct to another device, use `struct.to(device)` to migrate struct arrays\n- Allow rigid shapes to not have any collisions with other shapes in `wp.sim.Model`\n- Change default test behavior to test redundant GPUs (up to 2x)\n- Test each example in an individual subprocess\n- Polish and optimize various examples and tests\n- Allow non-contiguous point arrays to be passed to `wp.HashGrid.build()`\n- Upgrade LLVM to 18.1.3 for from-source builds and Linux x86-64 builds\n- Build DLL source code as C++17 and require GCC 9.4 as a minimum\n- Array clone, assign, and copy are now differentiable\n- Use `Ruff` for formatting and linting\n- Various documentation improvements (infinity, math constants, etc.)\n- Improve URDF importer, handle joint armature\n- Allow builtins.bool to be used in Warp data structures\n- Use external gradient arrays in backward passes when passed to `wp.launch()`\n- Add Conjugate Residual linear solver, see `wp.optim.linear.cr()`\n- Fix propagation of gradients on aliased copy of variables in kernels\n- Facilitate debugging and speed up `import warp` by eliminating raising any exceptions\n- Improve support for nested vec/mat assignments in structs\n- Recommend Python 3.9 or higher, which is required for JAX and soon PyTorch.\n- Support gradient propagation for indexing sliced multi-dimensional arrays, i.e. `a[i][j]` vs. `a[i, j]`\n- Provide an informative message if setting DLL C-types failed, instructing to try rebuilding the library\n\n## 1.0.3 - 2024-04-17\n\n- Add a `support_level` entry to the configuration file of the extensions\n\n## [1.0.2] - 2024-03-22\n\n- Make examples runnable from any location\n- Fix the examples not running directly from their Python file\n- Add the example gallery to the documentation\n- Update `README.md` examples USD location\n- Update `example_graph_capture.py` description\n\n## [1.0.1] - 2024-03-15\n\n- Document Device `total_memory` and `free_memory`\n- Documentation for allocators, streams, peer access, and generics\n- Changed example output directory to current working directory\n- Added `python -m warp.examples.browse` for browsing the examples folder\n- Print where the USD stage file is being saved\n- Added `examples/optim/example_walker.py` sample\n- Make the drone example not specific to USD\n- Reduce the time taken to run some examples\n- Optimise rendering points with a single colour\n- Clarify an error message around needing USD\n- Raise exception when module is unloaded during graph capture\n- Added `wp.synchronize_event()` for blocking the host thread until a recorded event completes\n- Flush C print buffers when ending `stdout` capture\n- Remove more unneeded CUTLASS files\n- Allow setting mempool release threshold as a fractional value\n\n## [1.0.0] - 2024-03-07\n\n- Add `FeatherstoneIntegrator` which provides more stable simulation of articulated rigid body dynamics in generalized coordinates (`State.joint_q` and `State.joint_qd`)\n- Introduce `warp.sim.Control` struct to store control inputs for simulations (optional, by default the `Model` control inputs are used as before); integrators now have a different simulation signature: `integrator.simulate(model: Model, state_in: State, state_out: State, dt: float, control: Control)`\n- `joint_act` can now behave in 3 modes: with `joint_axis_mode` set to `JOINT_MODE_FORCE` it behaves as a force/torque, with `JOINT_MODE_VELOCITY` it behaves as a velocity target, and with `JOINT_MODE_POSITION` it behaves as a position target; `joint_target` has been removed\n- Add adhesive contact to Euler integrators via `Model.shape_materials.ka` which controls the contact distance at which the adhesive force is applied\n- Improve handling of visual/collision shapes in URDF importer so visual shapes are not involved in contact dynamics\n- Experimental JAX kernel callback support\n- Improve module load exception message\n- Add `wp.ScopedCapture`\n- Removing `enable_backward` warning for callables\n- Copy docstrings and annotations from wrapped kernels, functions, structs\n\n## [0.15.1] - 2024-03-05\n\n- Add examples assets to the wheel packages\n- Fix broken image link in documentation\n- Fix codegen for custom grad functions calling their respective forward functions\n- Fix custom grad function handling for functions that have no outputs\n- Fix issues when `wp.config.quiet = True`\n\n## [0.15.0] - 2024-03-04\n\n- Add thumbnails to examples gallery\n- Apply colored lighting to examples\n- Moved `examples` directory under `warp/`\n- Add example usage to `python -m warp.tests --help`\n- Adding `torch.autograd.function` example + docs\n- Add error-checking to array shapes during creation\n- Adding `example_graph_capture`\n- Add a Diffsim Example of a Drone\n- Fix `verify_fp` causing compiler errors and support CPU kernels\n- Fix to enable `matmul` to be called in CUDA graph capture\n- Enable mempools by default\n- Update `wp.launch` to support tuple args\n- Fix BiCGSTAB and GMRES producing NaNs when converging early\n- Fix warning about backward codegen being disabled in `test_fem`\n- Fix `assert_np_equal` when NaN's and tolerance are involved\n- Improve error message to discern between CUDA being disabled or not supported\n- Support cross-module functions with user-defined gradients\n- Suppress superfluous CUDA error when ending capture after errors\n- Make output during initialization atomic\n- Add `warp.config.max_unroll`, fix custom gradient unrolling\n- Support native replay snippets using `@wp.func_native(snippet, replay_snippet=replay_snippet)`\n- Look for the CUDA Toolkit in default locations if the `CUDA_PATH` environment variable or `--cuda_path` build option are not used\n- Added `wp.ones()` to efficiently create one-initialized arrays\n- Rename `wp.config.graph_capture_module_load_default` to `wp.config.enable_graph_capture_module_load_by_default`\n\n## 0.14.0 - 2024-02-19\n\n- Add support for CUDA pooled (stream-ordered) allocators\n  - Support memory allocation during graph capture\n  - Support copying non-contiguous CUDA arrays during graph capture\n  - Improved memory allocation/deallocation performance with pooled allocators\n  - Use `wp.config.enable_mempools_at_init` to enable pooled allocators during Warp initialization (if supported)\n  - `wp.is_mempool_supported()` - check if a device supports pooled allocators\n  - `wp.is_mempool_enabled()`, `wp.set_mempool_enabled()` - enable or disable pooled allocators per device\n  - `wp.set_mempool_release_threshold()`, `wp.get_mempool_release_threshold()` - configure memory pool release threshold\n- Add support for direct memory access between devices\n  - Improved peer-to-peer memory transfer performance if access is enabled\n  - Caveat: enabling peer access may impact memory allocation/deallocation performance and increase memory consumption\n  - `wp.is_peer_access_supported()` - check if the memory of a device can be accessed by a peer device\n  - `wp.is_peer_access_enabled()`, `wp.set_peer_access_enabled()` - manage peer access for memory allocated using default CUDA allocators\n  - `wp.is_mempool_access_supported()` - check if the memory pool of a device can be accessed by a peer device\n  - `wp.is_mempool_access_enabled()`, `wp.set_mempool_access_enabled()` - manage access for memory allocated using pooled CUDA allocators\n- Refined stream synchronization semantics\n  - `wp.ScopedStream` can synchronize with the previous stream on entry and/or exit (only sync on entry by default)\n  - Functions taking an optional stream argument do no implicit synchronization for max performance (e.g., `wp.copy()`, `wp.launch()`, `wp.capture_launch()`)\n- Support for passing a custom `deleter` argument when constructing arrays\n  - Deprecation of `owner` argument - use `deleter` to transfer ownership\n- Optimizations for various core API functions (e.g., `wp.zeros()`, `wp.full()`, and more)\n- Fix `wp.matmul()` to always use the correct CUDA context\n- Fix memory leak in BSR transpose\n- Fix stream synchronization issues when copying non-contiguous arrays\n- API change: `wp.matmul()` no longer accepts a device as a parameter; instead, it infers the correct device from the arrays being multiplied\n- Updated DLPack utilities to the latest published standard\n  - External arrays can be imported into Warp directly, e.g., `wp.from_dlpack(external_array)`\n  - Warp arrays can be exported to consumer frameworks directly, e.g., `jax.dlpack.from_dlpack(warp_array)`\n  - Added CUDA stream synchronization for CUDA arrays\n  - The original DLPack protocol can still be used for better performance when stream synchronization is not required, see interoperability docs for details\n  - `warp.to_dlpack()` is about 3-4x faster in common cases\n  - `warp.from_dlpack()` is about 2x faster when called with a DLPack capsule\n  - Fixed a small CPU memory leak related to DLPack interop\n- Improved performance of creating arrays\n\n## 0.13.1 - 2024-02-22\n\n- Ensure that the results from the `Noise Deform` are deterministic across different Kit sessions\n\n## [0.13.0] - 2024-02-16\n\n- Update the license to *NVIDIA Software License*, allowing commercial use (see `LICENSE.md`)\n- Add `CONTRIBUTING.md` guidelines (for NVIDIA employees)\n- Hash CUDA `snippet` and `adj_snippet` strings to fix caching\n- Fix `build_docs.py` on Windows\n- Add missing `.py` extension to `warp/tests/walkthrough_debug`\n- Allow `wp.bool` usage in vector and matrix types\n\n## 0.12.0 - 2024-02-05\n\n- Add a warning when the `enable_backward` setting is set to `False` upon calling `wp.Tape.backward()`\n- Fix kernels not being recompiled as expected when defined using a closure\n- Change the kernel cache appauthor subdirectory to just \"NVIDIA\"\n- Ensure that gradients attached to PyTorch tensors have compatible strides when calling `wp.from_torch()`\n- Add a `Noise Deform` node for OmniGraph that deforms points using a perlin/curl noise\n\n## [0.11.0] - 2024-01-23\n\n- Re-release 1.0.0-beta.7 as a non-pre-release 0.11.0 version so it gets selected by `pip install warp-lang`.\n- Introducing a new versioning and release process, detailed in `PACKAGING.md` and resembling that of [Python itself](https://devguide.python.org/developer-workflow/development-cycle/#devcycle):\n  - The 0.11 release(s) can be found on the `release-0.11` branch.\n  - Point releases (if any) go on the same minor release branch and only contain bug fixes, not new features.\n  - The `public` branch, previously used to merge releases into and corresponding with the GitHub `main` branch, is retired.\n\n## 1.0.0-beta.7 - 2024-01-23\n\n- Ensure captures are always enclosed in `try`/`finally`\n- Only include .py files from the warp subdirectory into wheel packages\n- Fix an extension's sample node failing at parsing some version numbers\n- Allow examples to run without USD when possible\n- Add a setting to disable the main Warp menu in Kit\n- Add iterative linear solvers, see `wp.optim.linear.cg`, `wp.optim.linear.bicgstab`, `wp.optim.linear.gmres`, and `wp.optim.linear.LinearOperator`\n- Improve error messages around global variables\n- Improve error messages around mat/vec assignments\n- Support conversion of scalars to native/ctypes, e.g.: `float(wp.float32(1.23))` or `ctypes.c_float(wp.float32(1.23))`\n- Add a constant for infinity, see `wp.inf`\n- Add a FAQ entry about array assignments\n- Add a mass spring cage diff simulation example, see `examples/example_diffsim_mass_spring_cage.py`\n- Add `-s`, `--suite` option for only running tests belonging to the given suites\n- Fix common spelling mistakes\n- Fix indentation of generated code\n- Show deprecation warnings only once\n- Improve `wp.render.OpenGLRenderer`\n- Create the extension's symlink to the *core library* at runtime\n- Fix some built-ins failing to compile the backward pass when nested inside if/else blocks\n- Update examples with the new variants of the mesh query built-ins\n- Fix type members that weren't zero-initialized\n- Fix missing adjoint function for `wp.mesh_query_ray()`\n\n## [1.0.0-beta.6] - 2024-01-10\n\n- Do not create CPU copy of grad array when calling `array.numpy()`\n- Fix `assert_np_equal()` bug\n- Support Linux AArch64 platforms, including Jetson/Tegra devices\n- Add parallel testing runner (invoke with `python -m warp.tests`, use `warp/tests/unittest_serial.py` for serial testing)\n- Fix support for function calls in `range()`\n- `wp.matmul()` adjoints now accumulate\n- Expand available operators (e.g. vector @ matrix, scalar as dividend) and improve support for calling native built-ins\n- Fix multi-gpu synchronization issue in `sparse.py`\n- Add depth rendering to `wp.render.OpenGLRenderer`, document `wp.render`\n- Make `wp.atomic_min()`, `wp.atomic_max()` differentiable\n- Fix error reporting using the exact source segment\n- Add user-friendly mesh query overloads, returning a struct instead of overwriting parameters\n- Address multiple differentiability issues\n- Fix backpropagation for returning array element references\n- Support passing the return value to adjoints\n- Add point basis space and explicit point-based quadrature for `wp.fem`\n- Support overriding the LLVM project source directory path using `build_lib.py --build_llvm --llvm_source_path=`\n- Fix the error message for accessing non-existing attributes\n- Flatten faces array for Mesh constructor in URDF parser\n\n## [1.0.0-beta.5] - 2023-11-22\n\n- Fix for kernel caching when function argument types change\n- Fix code-gen ordering of dependent structs\n- Fix for `wp.Mesh` build on MGPU systems\n- Fix for name clash bug with adjoint code: https://github.com/NVIDIA/warp/issues/154\n- Add `wp.frac()` for returning the fractional part of a floating point value\n- Add support for custom native CUDA snippets using `@wp.func_native` decorator\n- Add support for batched matmul with batch size > 2^16-1\n- Add support for transposed CUTLASS `wp.matmul()` and additional error checking\n- Add support for quad and hex meshes in `wp.fem`\n- Detect and warn when C++ runtime doesn't match compiler during build, e.g.: ``libstdc++.so.6: version `GLIBCXX_3.4.30' not found``\n- Documentation update for `wp.BVH`\n- Documentation and simplified API for runtime kernel specialization `wp.Kernel`\n\n## 1.0.0-beta.4 - 2023-11-01\n\n- Add `wp.cbrt()` for cube root calculation\n- Add `wp.mesh_furthest_point_no_sign()` to compute furthest point on a surface from a query point\n- Add support for GPU BVH builds, 10-100x faster than CPU builds for large meshes\n- Add support for chained comparisons, i.e.: `0 < x < 2`\n- Add support for running `wp.fem` examples headless\n- Fix for unit test determinism\n- Fix for possible GC collection of array during graph capture\n- Fix for `wp.utils.array_sum()` output initialization when used with vector types\n- Coverage and documentation updates\n\n## 1.0.0-beta.3 - 2023-10-19\n\n- Add support for code coverage scans (test_coverage.py), coverage at 85% in `omni.warp.core`\n- Add support for named component access for vector types, e.g.: `a = v.x`\n- Add support for lvalue expressions, e.g.: `array[i] += b`\n- Add casting constructors for matrix and vector types\n- Add support for `type()` operator that can be used to return type inside kernels\n- Add support for grid-stride kernels to support kernels with > 2^31-1 thread blocks\n- Fix for multi-process initialization warnings\n- Fix alignment issues with empty `wp.struct`\n- Fix for return statement warning with tuple-returning functions\n- Fix for `wp.batched_matmul()` registering the wrong function in the Tape\n- Fix and document for `wp.sim` forward + inverse kinematics\n- Fix for `wp.func` to return a default value if function does not return on all control paths\n- Refactor `wp.fem` support for new basis functions, decoupled function spaces\n- Optimizations for `wp.noise` functions, up to 10x faster in most cases\n- Optimizations for `type_size_in_bytes()` used in array construction'\n\n### Breaking Changes\n\n- To support grid-stride kernels, `wp.tid()` can no longer be called inside `wp.func` functions.\n\n## 1.0.0-beta.2 - 2023-09-01\n\n- Fix for passing bool into `wp.func` functions\n- Fix for deprecation warnings appearing on `stderr`, now redirected to `stdout`\n- Fix for using `for i in wp.hash_grid_query(..)` syntax\n\n## 1.0.0-beta.1 - 2023-08-29\n\n- Fix for `wp.float16` being passed as kernel arguments\n- Fix for compile errors with kernels using structs in backward pass\n- Fix for `wp.Mesh.refit()` not being CUDA graph capturable due to synchronous temp. allocs\n- Fix for dynamic texture example flickering / MGPU crashes demo in Kit by reusing `ui.DynamicImageProvider` instances\n- Fix for a regression that disabled bundle change tracking in samples\n- Fix for incorrect surface velocities when meshes are deforming in `OgnClothSimulate`\n- Fix for incorrect lower-case when setting USD stage \"up_axis\" in examples\n- Fix for incompatible gradient types when wrapping PyTorch tensor as a vector or matrix type\n- Fix for adding open edges when building cloth constraints from meshes in `wp.sim.ModelBuilder.add_cloth_mesh()`\n- Add support for `wp.fabricarray` to directly access Fabric data from Warp kernels, see https://docs.omniverse.nvidia.com/kit/docs/usdrt/latest/docs/usdrt_prim_selection.html for examples\n- Add support for user defined gradient functions, see `@wp.func_replay`, and `@wp.func_grad` decorators\n- Add support for more OG attribute types in `omni.warp.from_omni_graph()`\n- Add support for creating NanoVDB `wp.Volume` objects from dense NumPy arrays\n- Add support for `wp.volume_sample_grad_f()` which returns the value + gradient efficiently from an NVDB volume\n- Add support for LLVM fp16 intrinsics for half-precision arithmetic\n- Add implementation of stochastic gradient descent, see `wp.optim.SGD`\n- Add `wp.fem` framework for solving weak-form PDE problems (see https://nvidia.github.io/warp/modules/fem.html)\n- Optimizations for `omni.warp` extension load time (2.2s to 625ms cold start)\n- Make all `omni.ui` dependencies optional so that Warp unit tests can run headless\n- Deprecation of `wp.tid()` outside of kernel functions, users should pass `tid()` values to `wp.func` functions explicitly\n- Deprecation of `wp.sim.Model.flatten()` for returning all contained tensors from the model\n- Add support for clamping particle max velocity in `wp.sim.Model.particle_max_velocity`\n- Remove dependency on `urdfpy` package, improve MJCF parser handling of default values\n\n## [0.10.1] - 2023-07-25\n\n- Fix for large multidimensional kernel launches (> 2^32 threads)\n- Fix for module hashing with generics\n- Fix for unrolling loops with break or continue statements (will skip unrolling)\n- Fix for passing boolean arguments to build_lib.py (previously ignored)\n- Fix build warnings on Linux\n- Fix for creating array of structs from NumPy structured array\n- Fix for regression on kernel load times in Kit when using `wp.sim`\n- Update `wp.array.reshape()` to handle `-1` dimensions\n- Update margin used by for mesh queries when using `wp.sim.create_soft_body_contacts()`\n- Improvements to gradient handling with `wp.from_torch()`, `wp.to_torch()` plus documentation\n\n## 0.10.0 - 2023-07-05\n\n- Add support for macOS universal binaries (x86 + aarch64) for M1+ support\n- Add additional methods for SDF generation please see the following new methods:\n  - `wp.mesh_query_point_nosign()` - closest point query with no sign determination\n  - `wp.mesh_query_point_sign_normal()` - closest point query with sign from angle-weighted normal\n  - `wp.mesh_query_point_sign_winding_number()` - closest point query with fast winding number sign determination\n- Add CSR/BSR sparse matrix support, see `wp.sparse` module:\n  - `wp.sparse.BsrMatrix`\n  - `wp.sparse.bsr_zeros()`, `wp.sparse.bsr_set_from_triplets()` for construction\n  - `wp.sparse.bsr_mm()`, `wp.sparse_bsr_mv()` for matrix-matrix and matrix-vector products respectively\n- Add array-wide utilities:\n  - `wp.utils.array_scan()` - prefix sum (inclusive or exclusive)\n  - `wp.utils.array_sum()` - sum across array\n  - `wp.utils.radix_sort_pairs()` - in-place radix sort (key,value) pairs\n- Add support for calling `@wp.func` functions from Python (outside of kernel scope)\n- Add support for recording kernel launches using a `wp.Launch` object that can be replayed with low overhead, use `wp.launch(..., record_cmd=True)` to generate a command object\n- Optimizations for `wp.struct` kernel arguments, up to 20x faster launches for kernels with large structs or number of params\n- Refresh USD samples to use bundle based workflow + change tracking\n- Add Python API for manipulating mesh and point bundle data in OmniGraph, see `omni.warp.nodes` module, see `omni.warp.nodes.mesh_create_bundle()`, `omni.warp.nodes.mesh_get_points()`, etc\n- Improvements to `wp.array`:\n  - Fix a number of array methods misbehaving with empty arrays\n  - Fix a number of bugs and memory leaks related to gradient arrays\n  - Fix array construction when creating arrays in pinned memory from a data source in pageable memory\n  - `wp.empty()` no longer zeroes-out memory and returns an uninitialized array, as intended\n  - `array.zero_()` and `array.fill_()` work with non-contiguous arrays\n  - Support wrapping non-contiguous NumPy arrays without a copy\n  - Support preserving the outer dimensions of NumPy arrays when wrapping them as Warp arrays of vector or matrix types\n  - Improve PyTorch and DLPack interop with Warp arrays of arbitrary vectors and matrices\n  - `array.fill_()` can now take lists or other sequences when filling arrays of vectors or matrices, e.g. `arr.fill_([[1, 2], [3, 4]])`\n  - `array.fill_()` now works with arrays of structs (pass a struct instance)\n  - `wp.copy()` gracefully handles copying between non-contiguous arrays on different devices\n  - Add `wp.full()` and `wp.full_like()`, e.g., `a = wp.full(shape, value)`\n  - Add optional `device` argument to `wp.empty_like()`, `wp.zeros_like()`, `wp.full_like()`, and `wp.clone()`\n  - Add `indexedarray` methods `.zero_()`, `.fill_()`, and `.assign()`\n  - Fix `indexedarray` methods `.numpy()` and `.list()`\n  - Fix `array.list()` to work with arrays of any Warp data type\n  - Fix `array.list()` synchronization issue with CUDA arrays\n  - `array.numpy()` called on an array of structs returns a structured NumPy array with named fields\n  - Improve the performance of creating arrays\n- Fix for `Error: No module named 'omni.warp.core'` when running some Kit configurations (e.g.: stubgen)\n- Fix for `wp.struct` instance address being included in module content hash\n- Fix codegen with overridden function names\n- Fix for kernel hashing so it occurs after code generation and before loading to fix a bug with stale kernel cache\n- Fix for `wp.BVH.refit()` when executed on the CPU\n- Fix adjoint of `wp.struct` constructor\n- Fix element accessors for `wp.float16` vectors and matrices in Python\n- Fix `wp.float16` members in structs\n- Remove deprecated `wp.ScopedCudaGuard()`, please use `wp.ScopedDevice()` instead\n\n## [0.9.0] - 2023-06-01\n\n- Add support for in-place modifications to vector, matrix, and struct types inside kernels (will warn during backward pass with `wp.verbose` if using gradients)\n- Add support for step-through VSCode debugging of kernel code with standalone LLVM compiler, see `wp.breakpoint()`, and `walkthrough_debug.py`\n- Add support for default values on built-in functions\n- Add support for multi-valued `@wp.func` functions\n- Add support for `pass`, `continue`, and `break` statements\n- Add missing `__sincos_stret` symbol for macOS\n- Add support for gradient propagation through `wp.Mesh.points`, and other cases where arrays are passed to native functions\n- Add support for Python `@` operator as an alias for `wp.matmul()`\n- Add XPBD support for particle-particle collision\n- Add support for individual particle radii: `ModelBuilder.add_particle` has a new `radius` argument, `Model.particle_radius` is now a Warp array\n- Add per-particle flags as a `Model.particle_flags` Warp array, introduce `PARTICLE_FLAG_ACTIVE` to define whether a particle is being simulated and participates in contact dynamics\n- Add support for Python bitwise operators `&`, `|`, `~`, `<<`, `>>`\n- Switch to using standalone LLVM compiler by default for `cpu` devices\n- Split `omni.warp` into `omni.warp.core` for Omniverse applications that want to use the Warp Python module with minimal additional dependencies\n- Disable kernel gradient generation by default inside Omniverse for improved compile times\n- Fix for bounds checking on element access of vector/matrix types\n- Fix for stream initialization when a custom (non-primary) external CUDA context has been set on the calling thread\n- Fix for duplicate `@wp.struct` registration during hot reload\n- Fix for array `unot()` operator so kernel writers can use `if not array:` syntax\n- Fix for case where dynamic loops are nested within unrolled loops\n- Change `wp.hash_grid_point_id()` now returns -1 if the `wp.HashGrid` has not been reserved before\n- Deprecate `wp.Model.soft_contact_distance` which is now replaced by `wp.Model.particle_radius`\n- Deprecate single scalar particle radius (should be a per-particle array)\n\n## 0.8.2 - 2023-04-21\n\n- Add `ModelBuilder.soft_contact_max` to control the maximum number of soft contacts that can be registered. Use `Model.allocate_soft_contacts(new_count)` to change count on existing `Model` objects.\n- Add support for `bool` parameters\n- Add support for logical boolean operators with `int` types\n- Fix for `wp.quat()` default constructor\n- Fix conditional reassignments\n- Add sign determination using angle weighted normal version of `wp.mesh_query_point()` as `wp.mesh_query_sign_normal()`\n- Add sign determination using winding number of `wp.mesh_query_point()` as `wp.mesh_query_sign_winding_number()`\n- Add query point without sign determination `wp.mesh_query_no_sign()`\n\n## 0.8.1 - 2023-04-13\n\n- Fix for regression when passing flattened numeric lists as matrix arguments to kernels\n- Fix for regressions when passing `wp.struct` types with uninitialized (`None`) member attributes\n\n## 0.8.0 - 2023-04-05\n\n- Add `Texture Write` node for updating dynamic RTX textures from Warp kernels / nodes\n- Add multi-dimensional kernel support to Warp Kernel Node\n- Add `wp.load_module()` to pre-load specific modules (pass `recursive=True` to load recursively)\n- Add `wp.poisson()` for sampling Poisson distributions\n- Add support for UsdPhysics schema see `wp.sim.parse_usd()`\n- Add XPBD rigid body implementation plus diff. simulation examples\n- Add support for standalone CPU compilation (no host-compiler) with LLVM backed, enable with `--standalone` build option\n- Add support for per-timer color in `wp.ScopedTimer()`\n- Add support for row-based construction of matrix types outside of kernels\n- Add support for setting and getting row vectors for Python matrices, see `matrix.get_row()`, `matrix.set_row()`\n- Add support for instantiating `wp.struct` types within kernels\n- Add support for indexed arrays, `slice = array[indices]` will now generate a sparse slice of array data\n- Add support for generic kernel params, use `def compute(param: Any):`\n- Add support for `with wp.ScopedDevice(\"cuda\") as device:` syntax (same for `wp.ScopedStream()`, `wp.Tape()`)\n- Add support for creating custom length vector/matrices inside kernels, see `wp.vector()`, and `wp.matrix()`\n- Add support for creating identity matrices in kernels with, e.g.: `I = wp.identity(n=3, dtype=float)`\n- Add support for unary plus operator (`wp.pos()`)\n- Add support for `wp.constant` variables to be used directly in Python without having to use `.val` member\n- Add support for nested `wp.struct` types\n- Add support for returning `wp.struct` from functions\n- Add `--quick` build for faster local dev. iteration (uses a reduced set of SASS arches)\n- Add optional `requires_grad` parameter to `wp.from_torch()` to override gradient allocation\n- Add type hints for generic vector / matrix types in Python stubs\n- Add support for custom user function recording in `wp.Tape()`\n- Add support for registering CUTLASS `wp.matmul()` with tape backward pass\n- Add support for grids with > 2^31 threads (each dimension may be up to INT_MAX in length)\n- Add CPU fallback for `wp.matmul()`\n- Optimizations for `wp.launch()`, up to 3x faster launches in common cases\n- Fix `wp.randf()` conversion to float to reduce bias for uniform sampling\n- Fix capture of `wp.func` and `wp.constant` types from inside Python closures\n- Fix for CUDA on WSL\n- Fix for matrices in structs\n- Fix for transpose indexing for some non-square matrices\n- Enable Python faulthandler by default\n- Update to VS2019\n\n### Breaking Changes\n\n- `wp.constant` variables can now be treated as their true type, accessing the underlying value through `constant.val` is no longer supported\n- `wp.sim.model.ground_plane` is now a `wp.array` to support gradient, users should call `builder.set_ground_plane()` to create the ground \n- `wp.sim` capsule, cones, and cylinders are now aligned with the default USD up-axis\n\n## 0.7.2 - 2023-02-15\n\n- Reduce test time for vec/math types\n- Clean-up CUDA disabled build pipeline\n- Remove extension.gen.toml to make Kit packages Python version independent\n- Handle additional cases for array indexing inside Python\n\n## 0.7.1 - 2023-02-14\n\n- Disabling some slow tests for Kit\n- Make unit tests run on first GPU only by default\n\n## [0.7.0] - 2023-02-13\n\n- Add support for arbitrary length / type vector and matrices e.g.: `wp.vec(length=7, dtype=wp.float16)`, see `wp.vec()`, and `wp.mat()`\n- Add support for `array.flatten()`, `array.reshape()`, and `array.view()` with NumPy semantics\n- Add support for slicing `wp.array` types in Python\n- Add `wp.from_ptr()` helper to construct arrays from an existing allocation\n- Add support for `break` statements in ranged-for and while loops (backward pass support currently not implemented)\n- Add built-in mathematic constants, see `wp.pi`, `wp.e`, `wp.log2e`, etc.\n- Add built-in conversion between degrees and radians, see `wp.degrees()`, `wp.radians()`\n- Add security pop-up for Kernel Node\n- Improve error handling for kernel return values\n\n## 0.6.3 - 2023-01-31\n\n- Add DLPack utilities, see `wp.from_dlpack()`, `wp.to_dlpack()`\n- Add Jax utilities, see `wp.from_jax()`, `wp.to_jax()`, `wp.device_from_jax()`, `wp.device_to_jax()`\n- Fix for Linux Kit extensions OM-80132, OM-80133\n\n## 0.6.2 - 2023-01-19\n\n- Updated `wp.from_torch()` to support more data types\n- Updated `wp.from_torch()` to automatically determine the target Warp data type if not specified\n- Updated `wp.from_torch()` to support non-contiguous tensors with arbitrary strides\n- Add CUTLASS integration for dense GEMMs, see `wp.matmul()` and `wp.matmul_batched()`\n- Add QR and Eigen decompositions for `mat33` types, see `wp.qr3()`, and `wp.eig3()`\n- Add default (zero) constructors for matrix types\n- Add a flag to suppress all output except errors and warnings (set `wp.config.quiet = True`)\n- Skip recompilation when Kernel Node attributes are edited\n- Allow optional attributes for Kernel Node\n- Allow disabling backward pass code-gen on a per-kernel basis, use `@wp.kernel(enable_backward=False)`\n- Replace Python `imp` package with `importlib`\n- Fix for quaternion slerp gradients (`wp.quat_slerp()`)\n\n## 0.6.1 - 2022-12-05\n\n- Fix for non-CUDA builds\n- Fix strides computation in array_t constructor, fixes a bug with accessing mesh indices through mesh.indices[]\n- Disable backward pass code generation for kernel node (4-6x faster compilation)\n- Switch to linbuild for universal Linux binaries (affects TeamCity builds only)\n\n## 0.6.0 - 2022-11-28\n\n- Add support for CUDA streams, see `wp.Stream`, `wp.get_stream()`, `wp.set_stream()`, `wp.synchronize_stream()`, `wp.ScopedStream`\n- Add support for CUDA events, see `wp.Event`, `wp.record_event()`, `wp.wait_event()`, `wp.wait_stream()`, `wp.Stream.record_event()`, `wp.Stream.wait_event()`, `wp.Stream.wait_stream()`\n- Add support for PyTorch stream interop, see `wp.stream_from_torch()`, `wp.stream_to_torch()`\n- Add support for allocating host arrays in pinned memory for asynchronous data transfers, use `wp.array(..., pinned=True)` (default is non-pinned)\n- Add support for direct conversions between all scalar types, e.g.: `x = wp.uint8(wp.float64(3.0))`\n- Add per-module option to enable fast math, use `wp.set_module_options({\"fast_math\": True})`, fast math is now *disabled* by default\n- Add support for generating CUBIN kernels instead of PTX on systems with older drivers\n- Add user preference options for CUDA kernel output (\"ptx\" or \"cubin\", e.g.: `wp.config.cuda_output = \"ptx\"` or per-module `wp.set_module_options({\"cuda_output\": \"ptx\"})`)\n- Add kernel node for OmniGraph\n- Add `wp.quat_slerp()`, `wp.quat_to_axis_angle()`, `wp.rotate_rodriquez()` and adjoints for all remaining quaternion operations\n- Add support for unrolling for-loops when range is a `wp.constant`\n- Add support for arithmetic operators on built-in vector / matrix types outside of `wp.kernel`\n- Add support for multiple solution variables in `wp.optim` Adam optimization\n- Add nested attribute support for `wp.struct` attributes\n- Add missing adjoint implementations for spatial math types, and document all functions with missing adjoints\n- Add support for retrieving NanoVDB tiles and voxel size, see `wp.Volume.get_tiles()`, and `wp.Volume.get_voxel_size()`\n- Add support for store operations on integer NanoVDB volumes, see `wp.volume_store_i()`\n- Expose `wp.Mesh` points, indices, as arrays inside kernels, see `wp.mesh_get()`\n- Optimizations for `wp.array` construction, 2-3x faster on average\n- Optimizations for URDF import\n- Fix various deployment issues by statically linking with all CUDA libs\n- Update warp.so/warp.dll to CUDA Toolkit 11.5\n\n## 0.5.1 - 2022-11-01\n\n- Fix for unit tests in Kit\n\n## [0.5.0] - 2022-10-31\n\n- Add smoothed particle hydrodynamics (SPH) example, see `example_sph.py`\n- Add support for accessing `array.shape` inside kernels, e.g.: `width = arr.shape[0]`\n- Add dependency tracking to hot-reload modules if dependencies were modified\n- Add lazy acquisition of CUDA kernel contexts (save ~300Mb of GPU memory in MGPU environments)\n- Add BVH object, see `wp.Bvh` and `bvh_query_ray()`, `bvh_query_aabb()` functions\n- Add component index operations for `spatial_vector`, `spatial_matrix` types\n- Add `wp.lerp()` and `wp.smoothstep()` builtins\n- Add `wp.optim` module with implementation of the Adam optimizer for float and vector types\n- Add support for transient Python modules (fix for Houdini integration)\n- Add `wp.length_sq()`, `wp.trace()` for vector / matrix types respectively\n- Add missing adjoints for `wp.quat_rpy()`, `wp.determinant()`\n- Add `wp.atomic_min()`, `wp.atomic_max()` operators\n- Add vectorized version of `wp.sim.model.add_cloth_mesh()`\n- Add NVDB volume allocation API, see `wp.Volume.allocate()`, and `wp.Volume.allocate_by_tiles()`\n- Add NVDB volume write methods, see `wp.volume_store_i()`, `wp.volume_store_f()`, `wp.volume_store_v()`\n- Add MGPU documentation\n- Add example showing how to compute Jacobian of multiple environments in parallel, see `example_jacobian_ik.py`\n- Add `wp.Tape.zero()` support for `wp.struct` types\n- Make SampleBrowser an optional dependency for Kit extension\n- Make `wp.Mesh` object accept both 1d and 2d arrays of face vertex indices\n- Fix for reloading of class member kernel / function definitions using `importlib.reload()`\n- Fix for hashing of `wp.constants()` not invalidating kernels\n- Fix for reload when multiple `.ptx` versions are present\n- Improved error reporting during code-gen\n\n## [0.4.3] - 2022-09-20\n\n- Update all samples to use GPU interop path by default\n- Fix for arrays > 2GB in length\n- Add support for per-vertex USD mesh colors with `wp.render` class\n\n## 0.4.2 - 2022-09-07\n\n- Register Warp samples to the sample browser in Kit\n- Add NDEBUG flag to release mode kernel builds\n- Fix for particle solver node when using a large number of particles\n- Fix for broken cameras in Warp sample scenes\n\n## 0.4.1 - 2022-08-30\n\n- Add geometry sampling methods, see `wp.sample_unit_cube()`, `wp.sample_unit_disk()`, etc\n- Add `wp.lower_bound()` for searching sorted arrays\n- Add an option for disabling code-gen of backward pass to improve compilation times, see `wp.set_module_options({\"enable_backward\": False})`, True by default\n- Fix for using Warp from Script Editor or when module does not have a `__file__` attribute\n- Fix for hot reload of modules containing `wp.func()` definitions\n- Fix for debug flags not being set correctly on CUDA when `wp.config.mode == \"debug\"`, this enables bounds checking on CUDA kernels in debug mode\n- Fix for code gen of functions that do not return a value\n\n## 0.4.0 - 2022-08-09\n\n- Fix for FP16 conversions on GPUs without hardware support\n- Fix for `runtime = None` errors when reloading the Warp module\n- Fix for PTX architecture version when running with older drivers, see `wp.config.ptx_target_arch`\n- Fix for USD imports from `__init__.py`, defer them to individual functions that need them\n- Fix for robustness issues with sign determination for `wp.mesh_query_point()`\n- Fix for `wp.HashGrid` memory leak when creating/destroying grids\n- Add CUDA version checks for toolkit and driver\n- Add support for cross-module `@wp.struct` references\n- Support running even if CUDA initialization failed, use `wp.is_cuda_available()` to check availability\n- Statically linking with the CUDA runtime library to avoid deployment issues\n\n### Breaking Changes\n\n- Removed `wp.runtime` reference from the top-level module, as it should be considered private\n\n## 0.3.2 - 2022-07-19\n\n- Remove Torch import from `__init__.py`, defer import to `wp.from_torch()`, `wp.to_torch()`\n\n## [0.3.1] - 2022-07-12\n\n- Fix for marching cubes reallocation after initialization\n- Add support for closest point between line segment tests, see `wp.closest_point_edge_edge()` builtin\n- Add support for per-triangle elasticity coefficients in simulation, see `wp.sim.ModelBuilder.add_cloth_mesh()`\n- Add support for specifying default device, see `wp.set_device()`, `wp.get_device()`, `wp.ScopedDevice`\n- Add support for multiple GPUs (e.g., `\"cuda:0\"`, `\"cuda:1\"`), see `wp.get_cuda_devices()`, `wp.get_cuda_device_count()`, `wp.get_cuda_device()`\n- Add support for explicitly targeting the current CUDA context using device alias `\"cuda\"`\n- Add support for using arbitrary external CUDA contexts, see `wp.map_cuda_device()`, `wp.unmap_cuda_device()`\n- Add PyTorch device aliasing functions, see `wp.device_from_torch()`, `wp.device_to_torch()`\n\n### Breaking Changes\n\n- A CUDA device is used by default, if available (aligned with `wp.get_preferred_device()`)\n- `wp.ScopedCudaGuard` is deprecated, use `wp.ScopedDevice` instead\n- `wp.synchronize()` now synchronizes all devices; for finer-grained control, use `wp.synchronize_device()`\n- Device alias `\"cuda\"` now refers to the current CUDA context, rather than a specific device like `\"cuda:0\"` or `\"cuda:1\"`\n\n## 0.3.0 - 2022-07-08\n\n- Add support for FP16 storage type, see `wp.float16`\n- Add support for per-dimension byte strides, see `wp.array.strides`\n- Add support for passing Python classes as kernel arguments, see `@wp.struct` decorator\n- Add additional bounds checks for builtin matrix types\n- Add additional floating point checks, see `wp.config.verify_fp`\n- Add interleaved user source with generated code to aid debugging\n- Add generalized GPU marching cubes implementation, see `wp.MarchingCubes` class\n- Add additional scalar*matrix vector operators\n- Add support for retrieving a single row from builtin types, e.g.: `r = m33[i]`\n- Add  `wp.log2()` and `wp.log10()` builtins\n- Add support for quickly instancing `wp.sim.ModelBuilder` objects to improve env. creation performance for RL\n- Remove custom CUB version and improve compatibility with CUDA 11.7\n- Fix to preserve external user-gradients when calling `wp.Tape.zero()`\n- Fix to only allocate gradient of a Torch tensor if `requires_grad=True`\n- Fix for missing `wp.mat22` constructor adjoint\n- Fix for ray-cast precision in edge case on GPU (watertightness issue)\n- Fix for kernel hot-reload when definition changes\n- Fix for NVCC warnings on Linux\n- Fix for generated function names when kernels are defined as class functions\n- Fix for reload of generated CPU kernel code on Linux\n- Fix for example scripts to output USD at 60 timecodes per-second (better Kit compatibility)\n\n## [0.2.3] - 2022-06-13\n\n- Fix for incorrect 4d array bounds checking\n- Fix for `wp.constant` changes not updating module hash\n- Fix for stale CUDA kernel cache when CPU kernels launched first\n- Array gradients are now allocated along with the arrays and accessible as `wp.array.grad`, users should take care to always call `wp.Tape.zero()` to clear gradients between different invocations of `wp.Tape.backward()`\n- Added `wp.array.fill_()` to set all entries to a scalar value (4-byte values only currently)\n\n### Breaking Changes\n\n- Tape `capture` option has been removed, users can now capture tapes inside existing CUDA graphs (e.g.: inside Torch)\n- Scalar loss arrays should now explicitly set `requires_grad=True` at creation time\n\n## 0.2.2 - 2022-05-30\n\n- Fix for `from import *` inside Warp initialization\n- Fix for body space velocity when using deforming Mesh objects with scale\n- Fix for noise gradient discontinuities affecting `wp.curlnoise()`\n- Fix for `wp.from_torch()` to correctly preserve shape\n- Fix for URDF parser incorrectly passing density to scale parameter\n- Optimizations for startup time from 3s -> 0.3s\n- Add support for custom kernel cache location, Warp will now store generated binaries in the user's application directory\n- Add support for cross-module function references, e.g.: call another modules @wp.func functions\n- Add support for overloading `@wp.func` functions based on argument type\n- Add support for calling built-in functions directly from Python interpreter outside kernels (experimental)\n- Add support for auto-complete and docstring lookup for builtins in IDEs like VSCode, PyCharm, etc\n- Add support for doing partial array copies, see `wp.copy()` for details\n- Add support for accessing mesh data directly in kernels, see `wp.mesh_get_point()`, `wp.mesh_get_index()`, `wp.mesh_eval_face_normal()`\n- Change to only compile for targets where kernel is launched (e.g.: will not compile CPU unless explicitly requested)\n\n### Breaking Changes\n\n- Builtin methods such as `wp.quat_identity()` now call the Warp native implementation directly and will return a `wp.quat` object instead of NumPy array\n- NumPy implementations of many builtin methods have been moved to `wp.utils` and will be deprecated\n- Local `@wp.func` functions should not be namespaced when called, e.g.: previously `wp.myfunc()` would work even if `myfunc()` was not a builtin\n- Removed `wp.rpy2quat()`, please use `wp.quat_rpy()` instead\n\n## 0.2.1 - 2022-05-11\n\n- Fix for unit tests in Kit\n\n## [0.2.0] - 2022-05-02\n\n### Warp Core\n\n- Fix for unrolling loops with negative bounds\n- Fix for unresolved symbol `hash_grid_build_device()` not found when lib is compiled without CUDA support\n- Fix for failure to load nvrtc-builtins64_113.dll when user has a newer CUDA toolkit installed on their machine\n- Fix for conversion of Torch tensors to `wp.array` with a vector dtype (incorrect row count)\n- Fix for `warp.dll` not found on some Windows installations\n- Fix for macOS builds on Clang 13.x\n- Fix for step-through debugging of kernels on Linux\n- Add argument type checking for user defined `@wp.func` functions\n- Add support for custom iterable types, supports ranges, hash grid, and mesh query objects\n- Add support for multi-dimensional arrays, for example use `x = array[i,j,k]` syntax to address a 3-dimensional array\n- Add support for multi-dimensional kernel launches, use `launch(kernel, dim=(i,j,k), ...` and `i,j,k = wp.tid()` to obtain thread indices\n- Add support for bounds-checking array memory accesses in debug mode, use `wp.config.mode = \"debug\"` to enable\n- Add support for differentiating through dynamic and nested for-loops\n- Add support for evaluating MLP neural network layers inside kernels with custom activation functions, see `wp.mlp()`\n- Add additional NVDB sampling methods and adjoints, see `wp.volume_sample_i()`, `wp.volume_sample_f()`, and `wp.volume_sample_vec()`\n- Add support for loading zlib compressed NVDB volumes, see `wp.Volume.load_from_nvdb()`\n- Add support for triangle intersection testing, see `wp.intersect_tri_tri()`\n- Add support for NVTX profile zones in `wp.ScopedTimer()`\n- Add support for additional transform and quaternion math operations, see `wp.inverse()`, `wp.quat_to_matrix()`, `wp.quat_from_matrix()`\n- Add fast math (`--fast-math`) to kernel compilation by default\n- Add `wp.torch` import by default (if PyTorch is installed)\n\n### Warp Kit\n\n- Add Kit menu for browsing Warp documentation and example scenes under 'Window->Warp'\n- Fix for OgnParticleSolver.py example when collider is coming from Read Prim into Bundle node\n\n### Warp Sim\n\n- Fix for joint attachment forces\n- Fix for URDF importer and floating base support\n- Add examples showing how to use differentiable forward kinematics to solve inverse kinematics\n- Add examples for URDF cartpole and quadruped simulation\n\n### Breaking Changes\n\n- `wp.volume_sample_world()` is now replaced by `wp.volume_sample_f/i/vec()` which operate in index (local) space. Users should use `wp.volume_world_to_index()` to transform points from world space to index space before sampling.\n- `wp.mlp()` expects multi-dimensional arrays instead of one-dimensional arrays for inference, all other semantics remain the same as earlier versions of this API.\n- `wp.array.length` member has been removed, please use `wp.array.shape` to access array dimensions, or use `wp.array.size` to get total element count\n- Marking `dense_gemm()`, `dense_chol()`, etc methods as experimental until we revisit them\n\n## 0.1.25 - 2022-03-20\n\n- Add support for class methods to be Warp kernels\n- Add HashGrid reserve() so it can be used with CUDA graphs\n- Add support for CUDA graph capture of tape forward/backward passes\n- Add support for Python 3.8.x and 3.9.x\n- Add hyperbolic trigonometric functions, see `wp.tanh()`, `wp.sinh()`, `wp.cosh()`\n- Add support for floored division on integer types\n- Move tests into core library so they can be run in Kit environment\n\n## 0.1.24 - 2022-03-03\n\n### Warp Core\n\n- Add NanoVDB support, see `wp.volume_sample*()` methods\n- Add support for reading compile-time constants in kernels, see `wp.constant()`\n- Add support for __cuda_array_interface__ protocol for zero-copy interop with PyTorch, see `wp.torch.to_torch()`\n- Add support for additional numeric types, i8, u8, i16, u16, etc\n- Add better checks for device strings during allocation / launch\n- Add support for sampling random numbers with a normal distribution, see `wp.randn()`\n- Upgrade to CUDA 11.3\n- Update example scenes to Kit 103.1\n- Deduce array dtype from np.array when one is not provided\n- Fix for ranged for loops with negative step sizes\n- Fix for 3d and 4d spherical gradient distributions\n\n## 0.1.23 - 2022-02-17\n\n### Warp Core\n\n- Fix for generated code folder being removed during Showroom installation\n- Fix for macOS support\n- Fix for dynamic for-loop code gen edge case\n- Add procedural noise primitives, see `wp.noise()`, `wp.pnoise()`, `wp.curlnoise()`\n- Move simulation helpers our of test into `wp.sim` module\n\n## 0.1.22 - 2022-02-14\n\n### Warp Core\n\n- Fix for .so reloading on Linux\n- Fix for while loop code-gen in some edge cases\n- Add rounding functions `wp.round()`, `wp.rint()`, `wp.trunc()`, `wp.floor()`, `wp.ceil()`\n- Add support for printing strings and formatted strings from kernels\n- Add MSVC compiler version detection and require minimum\n\n### Warp Sim\n\n- Add support for universal and compound joint types\n\n## 0.1.21 - 2022-01-19\n\n### Warp Core\n\n- Fix for exception on shutdown in empty `wp.array` objects\n- Fix for hot reload of CPU kernels in Kit\n- Add hash grid primitive for point-based spatial queries, see `wp.hash_grid_query()`, `wp.hash_grid_query_next()`\n- Add new PRNG methods using PCG-based generators, see `wp.rand_init()`, `wp.randf()`, `wp.randi()`\n- Add support for AABB mesh queries, see `wp.mesh_query_aabb()`, `wp.mesh_query_aabb_next()`\n- Add support for all Python `range()` loop variants\n- Add builtin vec2 type and additional math operators, `wp.pow()`, `wp.tan()`, `wp.atan()`, `wp.atan2()`\n- Remove dependency on CUDA driver library at build time\n- Remove unused NVRTC binary dependencies (50mb smaller Linux distribution)\n\n### Warp Sim\n\n- Bundle import of multiple shapes for simulation nodes\n- New OgnParticleVolume node for sampling shapes -> particles\n- New OgnParticleSolver node for DEM style granular materials\n\n## 0.1.20 - 2021-11-02\n\n- Updates to the ripple solver for GTC (support for multiple colliders, buoyancy, etc)\n\n## 0.1.19 - 2021-10-15\n\n- Publish from 2021.3 to avoid omni.graph database incompatibilities\n\n## 0.1.18 - 2021-10-08\n\n- Enable Linux support (tested on 20.04)\n\n## 0.1.17 - 2021-09-30\n\n- Fix for 3x3 SVD adjoint\n- Fix for A6000 GPU (bump compute model to sm_52 minimum)\n- Fix for .dll unload on rebuild\n- Fix for possible array destruction warnings on shutdown\n- Rename spatial_transform -> transform\n- Documentation update\n\n## 0.1.16 - 2021-09-06\n\n- Fix for case where simple assignments (a = b) incorrectly generated reference rather than value copy\n- Handle passing zero-length (empty) arrays to kernels\n\n## 0.1.15 - 2021-09-03\n\n- Add additional math library functions (asin, etc)\n- Add builtin 3x3 SVD support\n- Add support for named constants (True, False, None)\n- Add support for if/else statements (differentiable)\n- Add custom memset kernel to avoid CPU overhead of cudaMemset()\n- Add rigid body joint model to `wp.sim` (based on Brax)\n- Add Linux, MacOS support in core library\n- Fix for incorrectly treating pure assignment as reference instead of value copy\n- Removes the need to transfer array to CPU before numpy conversion (will be done implicitly)\n- Update the example OgnRipple wave equation solver to use bundles\n\n## 0.1.14 - 2021-08-09\n\n- Fix for out-of-bounds memory access in CUDA BVH\n- Better error checking after kernel launches (use `wp.config.verify_cuda=True`)\n- Fix for vec3 normalize adjoint code\n\n## 0.1.13 - 2021-07-29\n\n- Remove OgnShrinkWrap.py test node\n\n## 0.1.12 - 2021-07-29\n\n- Switch to Woop et al.'s watertight ray-tri intersection test\n- Disable --fast-math in CUDA compilation step for improved precision\n\n## 0.1.11 - 2021-07-28\n\n- Fix for `wp.mesh_query_ray()` returning incorrect t-value\n\n## 0.1.10 - 2021-07-28\n\n- Fix for OV extension fwatcher filters to avoid hot-reload loop due to OGN regeneration\n\n## 0.1.9 - 2021-07-21\n\n- Fix for loading sibling DLL paths\n- Better type checking for built-in function arguments\n- Added runtime docs, can now list all builtins using `wp.print_builtins()`\n\n## 0.1.8 - 2021-07-14\n\n- Fix for hot-reload of CUDA kernels\n- Add Tape object for replaying differentiable kernels\n- Add helpers for Torch interop (convert `torch.Tensor` to `wp.Array`)\n\n## 0.1.7 - 2021-07-05\n\n- Switch to NVRTC for CUDA runtime\n- Allow running without host compiler\n- Disable asserts in kernel release mode (small perf. improvement)\n\n## 0.1.6 - 2021-06-14\n\n- Look for CUDA toolchain in target-deps\n\n## 0.1.5 - 2021-06-14\n\n- Rename OgLang -> Warp\n- Improve CUDA environment error checking\n- Clean-up some logging, add verbose mode (`wp.config.verbose`)\n\n## 0.1.4 - 2021-06-10\n\n- Add support for mesh raycast\n\n## 0.1.3 - 2021-06-09\n\n- Add support for unary negation operator\n- Add support for mutating variables during dynamic loops (non-differentiable)\n- Add support for in-place operators\n- Improve kernel cache start up times (avoids adjointing before cache check)\n- Update README.md with requirements / examples\n\n## 0.1.2 - 2021-06-03\n\n- Add support for querying mesh velocities\n- Add CUDA graph support, see `wp.capture_begin()`, `wp.capture_end()`, `wp.capture_launch()`\n- Add explicit initialization phase, `wp.init()`\n- Add variational Euler solver (sim)\n- Add contact caching, switch to nonlinear friction model (sim)\n\n- Fix for Linux/macOS support\n\n## 0.1.1 - 2021-05-18\n\n- Fix bug with conflicting CUDA contexts\n\n## 0.1.0 - 2021-05-17\n\n- Initial publish for alpha testing\n\n[Unreleased]: https://github.com/NVIDIA/warp/compare/v1.5.1...HEAD\n[1.5.1]: https://github.com/NVIDIA/warp/releases/tag/v1.5.1\n[1.5.0]: https://github.com/NVIDIA/warp/releases/tag/v1.5.0\n[1.4.2]: https://github.com/NVIDIA/warp/releases/tag/v1.4.2\n[1.4.1]: https://github.com/NVIDIA/warp/releases/tag/v1.4.1\n[1.4.0]: https://github.com/NVIDIA/warp/releases/tag/v1.4.0\n[1.3.3]: https://github.com/NVIDIA/warp/releases/tag/v1.3.3\n[1.3.2]: https://github.com/NVIDIA/warp/releases/tag/v1.3.2\n[1.3.1]: https://github.com/NVIDIA/warp/releases/tag/v1.3.1\n[1.3.0]: https://github.com/NVIDIA/warp/releases/tag/v1.3.0\n[1.2.2]: https://github.com/NVIDIA/warp/releases/tag/v1.2.2\n[1.2.1]: https://github.com/NVIDIA/warp/releases/tag/v1.2.1\n[1.2.0]: https://github.com/NVIDIA/warp/releases/tag/v1.2.0\n[1.1.0]: https://github.com/NVIDIA/warp/releases/tag/v1.1.0\n[1.0.2]: https://github.com/NVIDIA/warp/releases/tag/v1.0.2\n[1.0.1]: https://github.com/NVIDIA/warp/releases/tag/v1.0.1\n[1.0.0]: https://github.com/NVIDIA/warp/releases/tag/v1.0.0\n[0.15.1]: https://github.com/NVIDIA/warp/releases/tag/v0.15.1\n[0.15.0]: https://github.com/NVIDIA/warp/releases/tag/v0.15.0\n[0.13.0]: https://github.com/NVIDIA/warp/releases/tag/v0.13.0\n[0.11.0]: https://github.com/NVIDIA/warp/releases/tag/v0.11.0\n[1.0.0-beta.6]: https://github.com/NVIDIA/warp/releases/tag/v1.0.0-beta.6\n[1.0.0-beta.5]: https://github.com/NVIDIA/warp/releases/tag/v1.0.0-beta.5\n[0.10.1]: https://github.com/NVIDIA/warp/releases/tag/v0.10.1\n[0.9.0]: https://github.com/NVIDIA/warp/releases/tag/v0.9.0\n[0.7.0]: https://github.com/NVIDIA/warp/releases/tag/v0.7.0\n[0.5.0]: https://github.com/NVIDIA/warp/releases/tag/v0.5.0\n[0.4.3]: https://github.com/NVIDIA/warp/releases/tag/v0.4.3\n[0.3.1]: https://github.com/NVIDIA/warp/releases/tag/v0.3.1\n[0.2.3]: https://github.com/NVIDIA/warp/releases/tag/v0.2.3\n[0.2.0]: https://github.com/NVIDIA/warp/releases/tag/v0.2.0\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.79296875,
          "content": "# Contributing to NVIDIA Warp\n\nContributions and PRs from the community are welcome and are taken under the\nterms described in the **9. Feedback** section of the [license](LICENSE.md).\n\n## Forking and Branch Naming\n\nThe first step in developing for Warp is to create a fork of the Warp repository.\n\n- GitHub community developers can fork the [GitHub Warp repository](https://github.com/NVIDIA/warp).\n- NVIDIA developers can fork the [GitLab Warp repository](https://gitlab-master.nvidia.com/omniverse/warp).\n\nFeatures should be developed on a branch with the following naming scheme:\n\n    user/feature-name\n\nFor example:\n\n    mmacklin/cuda-bvh-optimizations\n\n## Opening a Merge Request\n\nThe following guidelines were originally written for NVIDIA developers\nworking on Warp using the internal GitLab repository. Developers working\non GitHub should generally follow this process, replacing the GitLab-specific\ncomponents with their GitHub counterparts.\n\nWhen you're ready to submit your changes, please follow these steps to create a Merge Request (MR):\n\n1. **Create MR**: Submit your MR against the Warp repo.\nEnsure your MR has a descriptive title that clearly states the purpose of the changes.\n\n2. **Add a Detailed Description**: Your MR should include a brief description covering:\n   - Summary of changes.\n   - Areas affected by the changes.\n   - The problem being solved.\n   - Any limitations or non-handled areas in the changes.\n   - A link to the JIRA Or GitHub issue it is addressing.\n\n3. **Pre-Review Checklist**: The following should be checked before assigning reviews:\n   - Unit / regression tests are written.\n   - Docs have been updated.\n   - Use `ruff check` and `ruff format --check` to check for code quality issues.\n     The GitLab pipeline will fail if there are issues.\n     Exclusions may be used as appropriate, e.g. `# noqa: F841` or `#fmt: skip`.\n   - The GitLab CI/CD pipeline for the merge request is successful.\n\n4. **Assign Reviewers**: Select one or more reviewers from the owners list below to review your changes.\nUse the **Assignees** field to indicate reviewers who must _all_ approve the MR before it can be merged.\nAdditional reviewers whose approvals are not required can be listed in the **Reviewers** field.\n\n5. **Address Reviewer Comments**: Respond to all reviewer feedback. Be open to revising your approach based on their suggestions.\nOnce you have addressed a comment then reply to notify reviewers.\n_Do not_ resolve the thread yourself, this makes it harder for the reviewer to verify what has been changed.\nIf a reviewer has already approved the MR, you may self-resolve any of their outstanding threads in the interest of convenience.\n\n6. **Final Steps for Merging**: Before your MR can be merged, ensure that:\n   - All reviewer comments are resolved.\n   - All mandatory reviewers (in the **Assignees** field) have approved the MR.\n\n## Reviewer Guidelines\n\nAs a reviewer, your role is crucial in maintaining the quality of the NVIDIA Warp library. Here's what to look for in an MR:\n\n1. **Bug and Regression Checks**: If the MR addresses any bugs or regressions, verify that new unit tests are added to prevent future regressions.\n\n2. **Code Style and Conventions**: The code should generally adhere to PEP8 standards. However, if the surrounding code deviates from these standards, prioritize existing conventions. Avoid introducing new styles, layouts, or terminology for existing concepts.\n\n3. **Documentation**: Check for appropriate documentation of new features. This includes docstrings and updates to the User Manual. Note that documentation is auto-generated for each MR, so contributors should not submit built documentation files.\n\n4. **Review Thoroughly**: Take your time with the review.\n   - Consider if there's a simpler or better solution, ask clarifying questions or add comments if the intention is not clear.\n   - Consider the impact on the user experience, ease of use, intuitiveness, and consistency.\n   - Beware of breaking changes, even if the API does not change, does it break semantics existing users may be relying on?\n\n   Once you are satisfied with a thread resolution you should mark it as resolved. All threads must be resolved for the MR to be merged.\n\n## Feature Owners\n\nIf you're contributing to a specific area of NVIDIA Warp, please consult the relevant feature owners:\n\n- **Public API**: MilesM + relevant area owner from below\n  \n- **Code Generation**: NicolasC, MilesM\n\n- **Platform Support (macOS, Tegra)**: NicolasC\n- **CI/CD**: EricS, NicolasC, ZachC\n- **CUDA, MGPU**: LukaszW, EricS\n- **Kit Extensions**: ChristopherC\n- **Torch/dlpack Interop**: LukaszW, ZachC\n- **warp.sim**: EricH, MilesM\n- **warp.fem**: GillesD\n- **warp.optim**: GillesD, JonathanL\n- **NanoVDB**: GregK\n- **Testing/Packaging/Deployment**: EricS, NicolasC, LukaszW\n\nThank you for your contributions to making NVIDIA Warp a great tool for developers!\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 18.8134765625,
          "content": "# NVIDIA Software License Agreement\n\nIMPORTANT NOTICE – PLEASE READ AND AGREE BEFORE USING THE SOFTWARE.\n\nThis license agreement (“Agreement”) is a legal agreement between you, whether an individual or entity (“you”) and NVIDIA Corporation (“NVIDIA”) and governs the use of the NVIDIA Warp and any additional software and materials provided under this Agreement (“Software”). \n\nThis Agreement can be accepted only by an adult of legal age of majority in the country in which the Software is used. \nIf you don’t have the required age or authority to accept this Agreement, or if you don’t accept all the terms and conditions of this Agreement, do not use the Software. \nYou agree to use the Software only for purposes that are permitted by this Agreement and any applicable law or regulation in the relevant jurisdictions. \n\n## 1. License Grant\n\nSubject to the terms of this Agreement, NVIDIA grants you a non-exclusive, revocable, non-transferable, non-sublicensable (except as expressly granted in this Agreement), license to:\n\n1.1\tinstall and use copies of the Software,\n\n1.2\tmodify and create derivative works of sample or example Software provided by NVIDIA in source code format, and\n\n1.3\tdistribute the Software as incorporated into a software application subject to the following distribution requirements:\n\n(a)\tYour application must have material additional functionality, beyond the included portions of the Software.\n\n(b)\tThe distributable portions of the Software shall only be accessed by your application.\n\n(c)\tThe following notice shall be included in modifications and derivative works of sample source code distributed: “This software contains source code provided by NVIDIA Corporation.”\n\n(d)\tUnless a developer tool is identified in this Agreement as distributable, it is delivered for your internal use only.\n\n(e)\tThe terms under which you distribute your application must be consistent with the terms of this Agreement, including (without limitation) terms relating to the license grant and license restrictions and protection of \nNVIDIA’s intellectual property rights. Additionally, you agree that you will protect the privacy, security and legal rights of your application users.\n\n(f)\tYou agree to notify NVIDIA in writing of any known or suspected distribution or use of the Software not in compliance with the requirements of this Agreement, and to enforce the terms of your agreements with respect to distributed Software.\n\n## 2. Limitations\n\nYour license to use the Software is restricted as follows:\n\n2.1\tThe Software is licensed for you to develop applications only for use in systems with NVIDIA GPUs, NVIDIA CPUs or other CPUs.\n\n2.2\tYou may not reverse engineer, decompile or disassemble the Software components provided in binary form, nor attempt in any other manner to obtain source code of the Software.\n\n2.3\tYou may not change or remove copyright or other proprietary notices in the Software.\n\n2.4\tExcept as expressly granted in this Agreement, you may not copy, sell, rent, sublicense, transfer, distribute, modify or create derivative works of the Software, or make its functionality available to others. \n\n2.5\tYou may not bypass, disable or circumvent any technical limitation, encryption, security, digital rights management or authentication mechanism in the Software.\n\n2.6\tYou may not use the Software in any manner that would cause it to become subject to an open source software license; subject to the terms in the “Components Under Other Licenses” section below.\n\n2.7\tYou may not use the Software for the purpose of developing competing products or technologies or assist a third party in such activities. \n\n2.8\tYou may not indicate that a product or service developed with the Software is sponsored or endorsed by NVIDIA.\n\n2.9\tYou may not replace any NVIDIA software components in the Software that are governed by this Agreement with other software that implements NVIDIA APIs.\n\n2.10\tYou may not reverse engineer, decompile or disassemble any portion of the output generated using Software elements for the purpose of translating such output artifacts to target a non-NVIDIA platform.\n\n2.11\tYou acknowledge that the Software provided under this Agreement is not designed or tested by NVIDIA for use in any system or application where the use or failure of such system or application developed with NVIDIA’s Software could result in injury, death or catastrophic damage (each, a “Mission Critical Application”). Examples of Mission Critical Applications include use in avionics, navigation, autonomous vehicle applications, AI solutions for automotive products, military, medical, life support or other mission-critical or life-critical applications. NVIDIA will not be liable to you or any third party, in whole or in part, for any claims or damages arising from these uses. You are solely responsible for ensuring that systems and applications developed with the Software include sufficient safety and redundancy features and comply with all applicable legal and regulatory standards and requirements.\n\n2.12\tYou agree to defend, indemnify and hold harmless NVIDIA and its affiliates, and their respective employees, contractors, agents, officers and directors, from and against any and all claims, damages, obligations, losses, liabilities, costs or debt, fines, restitutions and expenses (including but not limited to attorney’s fees and costs incident to establishing the right of indemnification) arising out of or related to (i) products or services that have been developed or deployed with or use the Software, or claims that they violate laws, or infringe, violate, or misappropriate any third party right; or (ii) a violation of the terms and conditions of this Agreement. \n\n## 3. Authorized Users\n\nYou may allow employees and contractors of your entity or of your subsidiary(ies) to access and use the Software from your secure network to perform the work authorized by this Agreement on your behalf. If you are an academic institution, you may allow users enrolled or employed by the academic institution to access and use the Software as authorized by this Agreement from your secure network. You are responsible for the compliance with the terms of this Agreement by your authorized users. Any act or omission that if committed by you would constitute a breach of this Agreement will be deemed to constitute a breach of this Agreement if committed by your authorized users.\n\n## 4. Pre-Release Versions\n\nSoftware versions or specific features identified as alpha, beta, preview, early access or otherwise as pre-release may not be fully functional, may contain errors or design flaws, and may have reduced or different security, privacy, availability and reliability standards relative to commercial versions of NVIDIA offerings. You may use pre-release Software at your own risk, understanding that such versions are not intended for use in production or business-critical systems. NVIDIA may choose not to make available a commercial version of any pre-release Software. NVIDIA may also choose to abandon development and terminate the availability of pre-release Software at any time without liability.\n\n## 5. Updates\n\nNVIDIA may, at its option, make available patches, workarounds or other updates to the Software. Unless the updates are provided with their separate governing terms, they are deemed part of the Software licensed to you as provided in this Agreement.\n\n## 6. Components Under Other Licenses\n\nThe Software may include or be distributed with components provided with separate legal notices or terms that accompany the components, such as open source software licenses and other license. The components are subject to the applicable other licenses, including any proprietary notices, disclaimers, requirements and extended use rights; except that this Agreement will prevail regarding the use of third-party open source software, unless a third-party open source software license requires its license terms to prevail. Open source software license means any software, data or documentation subject to any license identified as an open source license by the Open Source Initiative (http://opensource.org), Free Software Foundation (http://www.fsf.org) or other similar open source organization or listed by the Software Package Data Exchange (SPDX) Workgroup under the Linux Foundation (http://www.spdx.org).\n\n## 7. Termination\n\nThis Agreement will automatically terminate without notice from NVIDIA if you fail to comply with any of the terms in this Agreement or if you commence or participate in any legal proceeding against NVIDIA with respect to the Software. Additionally, NVIDIA may terminate this Agreement with prior written notice to you if, in NVIDIA’s sole discretion, the continued use of the Software is no longer commercially viable or creates liabilities for NVIDIA. You agree to cooperate with NVIDIA and provide reasonably requested information to verify your compliance with this Agreement. Upon any termination, you must stop using and destroy all copies of the Software. Upon written request, you will certify in writing that you have complied with your commitments under this section. All provisions will survive termination, except for the licenses granted to you.\n\n## 8. Ownership\n\n8.1\tNVIDIA Ownership. The Software, including all intellectual property rights, is and will remain the sole and exclusive property of NVIDIA or its licensors. Except as expressly granted in this Agreement, (i) NVIDIA reserves all rights, interests and remedies in connection with the Software and (ii) no other license or right is granted to you by implication, estoppel or otherwise. \n\n8.2\tYour Ownership. Subject to the rights of NVIDIA and its suppliers in the Software, you hold all rights, title and interest in and to your services, applications and derivative works of samples or examples you develop as permitted in this Agreement including their respective intellectual property rights.\n\n8.3\tNon-Assert. You agree that you will not, and will not assist or enable any other party to, assert or threaten to assert any intellectual property rights against NVIDIA or its affiliates with respect to new software samples or examples that NVIDIA or its affiliates may develop and make available in the future.\n\n## 9. Feedback\n\nYou may, but are not obligated to, provide suggestions, requests, fixes, modifications, enhancements or other feedback regarding or in connection with your use of the Software (collectively, “Feedback”). Feedback, even if designated as confidential by you, will not create any confidentiality obligation for NVIDIA or its affiliates. If you provide Feedback, you hereby grant NVIDIA, its affiliates and its designees a non-exclusive, perpetual, irrevocable, sublicensable, worldwide, royalty-free, fully paid-up and transferable license, under your intellectual property rights, to publicly perform, publicly display, reproduce, use, make, have made, sell, offer for sale, distribute (through multiple tiers of distribution), import, create derivative works of and otherwise commercialize and exploit the Feedback at NVIDIA’s discretion. You will not give Feedback (i) that you have reason to believe is subject to any restriction that impairs the exercise of the grant stated in this section, such as third-party intellectual property rights or (ii) subject to license terms which seek to require any product incorporating or developed using such Feedback, or other intellectual property of NVIDIA or its affiliates, to be licensed to or otherwise shared with any third party. \n\n## 10. Disclaimer of Warranties.\n\nTHE SOFTWARE IS PROVIDED BY NVIDIA AS-IS AND WITH ALL FAULTS. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, NVIDIA DISCLAIMS ALL WARRANTIES AND REPRESENTATIONS OF ANY KIND, WHETHER EXPRESS, IMPLIED OR STATUTORY, RELATING TO OR ARISING UNDER THIS AGREEMENT, INCLUDING, WITHOUT LIMITATION, THE WARRANTIES OF TITLE, NONINFRINGEMENT, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, USAGE OF TRADE AND COURSE OF DEALING. WITHOUT LIMITING THE FOREGOING, NVIDIA DOES NOT WARRANT THAT THE SOFTWARE WILL MEET YOUR REQUIREMENTS; THAT ANY DEFECTS OR ERRORS WILL BE CORRECTED; THAT ANY CERTAIN CONTENT WILL BE AVAILABLE; OR THAT THE SOFTWARE IS FREE OF VIRUSES OR OTHER HARMFUL COMPONENTS.  NO INFORMATION OR ADVICE GIVEN BY NVIDIA WILL IN ANY WAY INCREASE THE SCOPE OF ANY WARRANTY EXPRESSLY PROVIDED IN THIS AGREEMENT. NVIDIA does not warrant or assume responsibility for the accuracy or completeness of any third-party information, text, graphics or links contained in the Software.\n\n## 11. Limitations of Liability\n\n11.1\tDISCLAIMERS. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY (I) INDIRECT, PUNITIVE, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES, OR (II) DAMAGES FOR THE (A) COST OF PROCURING SUBSTITUTE GOODS OR (B) LOSS OF PROFITS, REVENUES, USE, DATA OR GOODWILL ARISING OUT OF OR RELATED TO THIS AGREEMENT, WHETHER BASED ON BREACH OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY, OR OTHERWISE, AND EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES AND EVEN IF A PARTY’S REMEDIES FAIL THEIR ESSENTIAL PURPOSE.\n\n11.2\tDAMAGES CAP. ADDITIONALLY, TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, NVIDIA’S TOTAL CUMULATIVE AGGREGATE LIABILITY FOR ANY AND ALL LIABILITIES, OBLIGATIONS OR CLAIMS ARISING OUT OF OR RELATED TO THIS AGREEMENT WILL NOT EXCEED FIVE U.S. DOLLARS (US$5).\n\n## 12. Governing Law and Jurisdiction\n\nThis Agreement will be governed in all respects by the laws of the United States and the laws of the State of Delaware, without regard to conflict of laws principles or the United Nations Convention on Contracts for the International Sale of Goods. The state and federal courts residing in Santa Clara County, California will have exclusive jurisdiction over any dispute or claim arising out of or related to this Agreement, and the parties irrevocably consent to personal jurisdiction and venue in those courts; except that either party may apply for injunctive remedies or an equivalent type of urgent legal relief in any jurisdiction.\n\n## 13. General\n\n13.1\tNo Assignment. NVIDIA may assign, delegate or transfer its rights or obligations under this Agreement by any means or operation of law. You may not, without NVIDIA’s prior written consent, assign, delegate or transfer any of your rights or obligations under this Agreement by any means or operation of law, and any attempt to do so is null and void.\n\n13.2\tNo Waiver. No waiver of any term of the Agreement will be deemed a further or continuing waiver of such term or any other term, and NVIDIA’s failure to assert any right or provision under the Agreement will not constitute a waiver of such right or provision.\n\n13.3\tTrade and Compliance. You agree to comply with all applicable export, import, trade and economic sanctions laws and regulations, including U.S. Export Administration Regulations and Office of Foreign Assets Control regulations. You confirm that you will not export or reexport any products or technology, directly or indirectly, without first obtaining any required license or other approval from appropriate authorities, (i) to any countries that are subject to any U.S. or local export restrictions (currently including, but not necessarily limited to, Cuba, Iran, North Korea, Syria, the Region of Crimea, Donetsk People’s Republic Region and Luhansk People’s Republic Region); (ii) to any end user who you know or have reason to know will utilize them in the design, development or production of nuclear, chemical or biological weapons, missiles, rocket systems, unmanned air vehicles, or any weapons of mass destruction; (iii) to any end-user who has been prohibited from participating in the U.S. or local export transactions by any governing authority; or (iv) to any known military or military-intelligence end-user or for any known military or military-intelligence end-use in accordance with U.S. trade compliance laws and regulations. Use of the Software under this Agreement must be consistent with NVIDIA’s HumanRightsPolicy.pdf (nvidia.com).\n\n13.4\tGovernment Rights. The Software, documentation and technology (“Protected Items”) are “Commercial products” as this term is defined at 48 C.F.R. 2.101, consisting of “commercial computer software” and “commercial computer software documentation” as such terms are used in, respectively, 48 C.F.R. 12.212 and 48 C.F.R. 227.7202 & 252.227-7014(a)(1). Before any Protected Items are supplied to the U.S. Government, you will (i) inform the U.S. Government in writing that the Protected Items are and must be treated as commercial computer software and commercial computer software documentation developed at private expense; (ii) inform the U.S. Government that the Protected Items are provided subject to the terms of the Agreement; and (iii) mark the Protected Items as commercial computer software and commercial computer software documentation developed at private expense. In no event will you permit the U.S. Government to acquire rights in Protected Items beyond those specified in 48 C.F.R. 52.227-19(b)(1)-(2) or 252.227-7013(c) except as expressly approved by NVIDIA in writing.\n\n13.5\tNotices. Please direct your legal notices or other correspondence to NVIDIA Corporation, 2788 San Tomas Expressway, Santa Clara, California 95051, United States of America, Attention: Legal Department, with a copy emailed to legalnotices@nvidia.com. If NVIDIA needs to contact you about the Software, you consent to receive the notices by email and agree that such notices will satisfy any legal communication requirements.\n\n13.6\tForce Majeure. Neither party will be liable during any period where an event or circumstance prevents or delays that party from performing its obligations under this Agreement and that event or circumstance: (i) is not within the reasonable control of that party and is not the result of that party’s negligence, and (ii) cannot be overcome or avoided by that party using reasonably diligent efforts.\n\n13.7\tSeverability and Amendment. If a court of competent jurisdiction rules that a provision of this Agreement is unenforceable, that provision will be deemed modified to the extent necessary to make it enforceable and the remainder of this Agreement will continue in full force and effect. Any amendment to this Agreement must be in writing and signed by authorized representatives of both parties. \n\n13.8\tConstruction. The headings in the Agreement are included solely for convenience and are not intended to affect the meaning or interpretation of the Agreement. As required by the context of the Agreement, the singular of a term includes the plural and vice versa.\n\n13.9\tEntire Agreement. Regarding the subject matter of this Agreement, the parties agree that (i) this Agreement constitutes the entire and exclusive agreement between the parties and supersedes all prior and contemporaneous communications and (ii) any additional or different terms or conditions, whether contained in purchase orders, order acknowledgments, invoices or otherwise, will not be binding and are null and void. \n"
        },
        {
          "name": "PACKAGING.md",
          "type": "blob",
          "size": 7.6513671875,
          "content": "# Release Instructions\n\n## Versioning\n\nVersions take the format X.Y.Z, similar to [Python itself](https://devguide.python.org/developer-workflow/development-cycle/#devcycle):\n\n- Increments in X are reserved for major reworks of the project causing disruptive incompatibility (or reaching the 1.0 milestone).\n- Increments in Y are for regular releases with a new set of features.\n- Increments in Z are for bug fixes. In principle there are no new features. Can be omitted if 0 or not relevant.\n\nThis is similar to [Semantic Versioning](https://semver.org/) but less strict around backward compatibility.\nLike with Python, some breaking changes can be present between minor versions if well documented and gradually introduced.\n\nNote that prior to 0.11.0 this schema was not strictly adhered to.\n\n## Repositories\n\nDevelopment happens internally on a GitLab repository (part of the Omniverse group), while releases are made public on GitHub.\n\nThis document uses the following Git remote names:\n\n- **omniverse**: `git remote add omniverse https://gitlab-master.nvidia.com/omniverse/warp.git`\n- **github**: `git remote add github https://github.com/NVIDIA/warp.git`\n\nCurrently, all feature branches get merged into the `main` branch of the **omniverse** repo and then GitLab push-mirrors\nthe changes over to GitHub (nominally within five minutes). This mirroring process also pushes all tags\n(only tags beginning with `v` are allowed to be created) and branches beginning with `release-`.\n\nThe status of push mirroring can be checked under **Settings** :arrow_right: **Repository** on GitLab.\n\n## GitLab Release Branch\n\n1) Create a branch in your fork repository from which a merge-request will be opened to bump the version string\n   and create the public-facing changelogs for the release.\n\n2) Search & replace the current version string from `VERSION.md`.\n\n   We want to keep the Omniverse extensions' version in sync with the library so update the strings found in the `exts` folder as well.\n\n   The version string currently appears in the following two files, but there could be more in the future:\n\n   - `omni.warp/config/extension.toml`\n   - `omni.warp.core/config/extension.toml`\n\n   Be sure *not* to update previous strings in `CHANGELOG.md`.\n\n3) Update `CHANGELOG.md` from Git history (since the last release branch). Only list user-facing changes.\n\n   The entire development team should all be helping to keep this file up-to-date, so verify that all changes users\n   should know about are included.\n\n   The changelogs from the Omniverse extensions found in `exts` are kept in sync with the one from the library, so update them all at the same time and list any change made to the extensions.\n\n4) Open a MR on GitLab to merge this branch into `main`. Send a message in `#omni-warp-dev` to the `@warp-team`\n   asking for a review of the merge request's changes.\n\n5) Merge the branch into `main` after waiting a reasonable amount of time for the team to review and approve the MR.\n\n6) For new `X.Y` versions, create a release branch (note `.Z` maintenance versions remain on the same branch):\n\n   `git checkout -b release-X.Y [<start-point>]`\n\n   If branching from an older revision or reusing a branch, make sure to cherry-pick the version and changelog update.\n\n7) Make any release-specific changes (e.g. disable/remove features not ready yet).\n\n8) :warning: Keep in mind that branches pushed to the **omniverse** repository beginning with `release-` are\n   automatically mirrored to GitLab. :warning:\n\n   Push the new release branch to **omniverse** when it is in a state ready for CI testing.\n\n9) Check that the last revision on the release branch passes GitLab CI tests. A pipeline should have been automatically\n   created after pushing the branch in the previous step:\n\n   <https://gitlab-master.nvidia.com/omniverse/warp/-/pipelines>\n\n   Fix issues until all tests pass. Cherry-pick fixes for `main` where applicable.\n\n## Creating a GitHub Release Package\n\n1) Wait for the (latest) packages to appear in:\n\n   <https://gitlab-master.nvidia.com/omniverse/warp/-/packages/>\n\n2) Download the `.whl` files for each supported platform and move them into an empty folder.\n\n3) Run tests for at least one platform:\n\n    - Run `python -m pip install warp_lang-<version>-<platform-tag>.whl`\n    - Run `python -m warp.tests`\n\n    Check that the correct version number gets printed.\n\n4) If tests fail, make fixes on `release-X.Y` and where necessary cherry-pick to `main` before repeating from step (1).\n\n5) Tag the release with `vX.Y.Z` on `release-X.Y` and push to `omniverse`.\n   Both the tag and the release branch will be automatically mirrored to GitLab.\n\n   It is safest to push *just* the new tag using `git push omniverse vX.Y.Z`.\n\n   In case of a mistake, a tag already pushed to `omniverse` can be deleted from the GitLab UI.\n   The bad tag must also be deleted from the GitHub UI if it was mirrored there.\n\n6) Create a new release on [GitHub](https://github.com/NVIDIA/warp) with a tag and title of `vX.Y.Z` and\n   upload the `.whl` artifacts as attachments. Use the changelog updates as the description.\n\n## Upload a PyPI Release\n\nFirst time:\n\n- Create a [PyPI](https://pypi.org/) account.\n- [Create a Token](https://pypi.org/manage/account/#api-tokens) for uploading to the `warp-lang` project (store it somewhere safe).\n- Get an admin (<mmacklin@nvidia.com>) to give you write access to the project.\n\nPer release:\n\nRemove any `.whl` files from the upload folder that contain a `+cpu` or `+cu` (local) tag.\n\nRun `python -m twine upload *` from the `.whl` packages folder (on Windows make sure to use `cmd` shell; Git Bash doesn't work).\n\n- username: `__token__`\n- password: `(your token string from PyPI)`\n\n## Publishing the Omniverse Extensions\n\n1) Ensure that the version strings and `CHANGELOG.md` files in the `exts` folder are in sync with the ones from the library.\n\n2) Wait for the (latest) packages to appear in:\n\n   <https://gitlab-master.nvidia.com/omniverse/warp/-/packages/>\n\n3) Download `kit-extensions.zip` to your computer.\n\n4) Extract it to a clean folder and check the extensions inside of Kit:\n\n    - Run `omni.create.sh --ext-folder /path/to/artifacts/exts --enable omni.warp-X.Y.Z --enable omni.warp.core-X.Y.Z`\n    - Ensure that the example scenes are working as expected\n    - Run test suites for both extensions\n\n5) If tests fail, make fixes on `release-X.Y` and where necessary cherry-pick to `main` before repeating from step (2).\n\n6) If all tests passed:\n\n   - `kit --ext-folder /path/to/artifacts/exts --publish omni-warp.core-X.Y.Z`\n   - `kit --ext-folder /path/to/artifacts/exts --publish omni-warp-X.Y.Z`\n\n7) Ensure that the release is tagged with `vX.Y.Z` on both `omniverse/release-X.Y` and `github/release-X.Y`.\n\n## Automated processes\n\nThe following is just for your information. These steps should run automatically by CI/CD pipelines, but can be replicated manually if needed:\n\n### Building the documentation\n\nThe contents of <https://nvidia.github.io/warp/> is generated by a GitHub pipeline which runs `python build_docs.py` (prerequisites: `pip install docs/requirements.txt`).\n\n### Building pip wheels\n\nThe GitLab pipeline's `create pypi wheels` Job (part of the `package` Stage) combines artifacts from each platform build, moving the contents of `warp/bin` to platform- and architecture-specific\nsubfolders; e.g. `warp/bin/linux-x86_64` and `warp/bin/linux-aarch64` both contain `warp.so` and `warp-clang.so` files.\n\nPip wheels are then built using:\n\n```bash\npython -m build --wheel -C--build-option=-Pwindows-x86_64\npython -m build --wheel -C--build-option=-Plinux-x86_64\npython -m build --wheel -C--build-option=-Plinux-aarch64\npython -m build --wheel -C--build-option=-Pmacos-universal\n```\n\nSelecting the correct library files for each wheel happens in [`setup.py`](setup.py).\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 24.064453125,
          "content": "[![PyPI version](https://badge.fury.io/py/warp-lang.svg)](https://badge.fury.io/py/warp-lang)\n![GitHub commit activity](https://img.shields.io/github/commit-activity/m/NVIDIA/warp?link=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fwarp%2Fcommits%2Fmain)\n[![Downloads](https://static.pepy.tech/badge/warp-lang/month)](https://pepy.tech/project/warp-lang)\n[![codecov](https://codecov.io/github/NVIDIA/warp/graph/badge.svg?token=7O1KSM79FG)](https://codecov.io/github/NVIDIA/warp)\n![GitHub - CI](https://github.com/NVIDIA/warp/actions/workflows/ci.yml/badge.svg)\n[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&logoColor=white)](https://discord.com/invite/nvidiaomniverse)\n\n# NVIDIA Warp\n\nWarp is a Python framework for writing high-performance simulation and graphics code. Warp takes\nregular Python functions and JIT compiles them to efficient kernel code that can run on the CPU or GPU.\n\nWarp is designed for [spatial computing](https://en.wikipedia.org/wiki/Spatial_computing)\nand comes with a rich set of primitives that make it easy to write\nprograms for physics simulation, perception, robotics, and geometry processing. In addition, Warp kernels\nare differentiable and can be used as part of machine-learning pipelines with frameworks such as PyTorch, JAX and Paddle.\n\nPlease refer to the project [Documentation](https://nvidia.github.io/warp/) for API and language reference and [CHANGELOG.md](./CHANGELOG.md) for release history.\n\n<div align=\"center\">\n    <img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/header.jpg\">\n    <p><i>A selection of physical simulations computed with Warp</i></p>\n</div>\n\n## Installing\n\nPython version 3.9 or newer is recommended. Warp can run on x86-64 and ARMv8 CPUs on Windows, Linux, and macOS.\nGPU support requires a CUDA-capable NVIDIA GPU and driver (minimum GeForce GTX 9xx).\n\nThe easiest way to install Warp is from [PyPI](https://pypi.org/project/warp-lang/):\n\n```text\npip install warp-lang\n```\n\nYou can also use `pip install warp-lang[extras]` to install additional dependencies for running examples and USD-related features.\n\nThe binaries hosted on PyPI are currently built with the CUDA 12 runtime and therefore\nrequire a minimum version of the CUDA driver of 525.60.13 (Linux x86-64) or 528.33 (Windows x86-64).\n\nIf you require GPU support on a system with an older CUDA driver, you can build Warp from source or\ninstall wheels built with the CUDA 11.8 runtime from the [GitHub Releases](https://github.com/NVIDIA/warp/releases) page.\nCopy the URL of the appropriate wheel file (`warp-lang-{ver}+cu12-py3-none-{platform}.whl`) and pass it to\nthe `pip install` command, e.g.\n\n| Platform        | Install Command                                                                                                               |\n| --------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n| Linux aarch64   | `pip install https://github.com/NVIDIA/warp/releases/download/v1.5.1/warp_lang-1.5.1+cu11-py3-none-manylinux2014_aarch64.whl` |\n| Linux x86-64    | `pip install https://github.com/NVIDIA/warp/releases/download/v1.5.1/warp_lang-1.5.1+cu11-py3-none-manylinux2014_x86_64.whl`  |\n| Windows x86-64  | `pip install https://github.com/NVIDIA/warp/releases/download/v1.5.1/warp_lang-1.5.1+cu11-py3-none-win_amd64.whl`             |\n\nThe `--force-reinstall` option may need to be used to overwrite a previous installation.\n\n### CUDA Requirements\n\n* Warp packages built with CUDA Toolkit 11.x require NVIDIA driver 470 or newer.\n* Warp packages built with CUDA Toolkit 12.x require NVIDIA driver 525 or newer.\n\nThis applies to pre-built packages distributed on PyPI and GitHub and also when building Warp from source.\n\nNote that building Warp with the `--quick` flag changes the driver requirements.  The quick build skips CUDA backward compatibility, so the minimum required driver is determined by the CUDA Toolkit version.  Refer to the [latest CUDA Toolkit release notes](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html) to find the minimum required driver for different CUDA Toolkit versions (e.g., [this table from CUDA Toolkit 12.6](https://docs.nvidia.com/cuda/archive/12.6.0/cuda-toolkit-release-notes/index.html#id5)).\n\nWarp checks the installed driver during initialization and will report a warning if the driver is not suitable, e.g.:\n\n```text\nWarp UserWarning:\n   Insufficient CUDA driver version.\n   The minimum required CUDA driver version is 12.0, but the installed CUDA driver version is 11.8.\n   Visit https://github.com/NVIDIA/warp/blob/main/README.md#installing for guidance.\n```\n\nThis will make CUDA devices unavailable, but the CPU can still be used.\n\nTo remedy the situation there are a few options:\n\n* Update the driver.\n* Install a compatible pre-built Warp package.\n* Build Warp from source using a CUDA Toolkit that's compatible with the installed driver.\n\n## Getting Started\n\nAn example first program that computes the lengths of random 3D vectors is given below:\n\n```python\nimport warp as wp\nimport numpy as np\n\nnum_points = 1024\n\n@wp.kernel\ndef length(points: wp.array(dtype=wp.vec3),\n           lengths: wp.array(dtype=float)):\n\n    # thread index\n    tid = wp.tid()\n    \n    # compute distance of each point from origin\n    lengths[tid] = wp.length(points[tid])\n\n\n# allocate an array of 3d points\npoints = wp.array(np.random.rand(num_points, 3), dtype=wp.vec3)\nlengths = wp.zeros(num_points, dtype=float)\n\n# launch kernel\nwp.launch(kernel=length,\n          dim=len(points),\n          inputs=[points, lengths])\n\nprint(lengths)\n```\n\n## Running Notebooks\n\nA few notebooks are available in the [notebooks](./notebooks/) directory to provide an overview over the key features available in Warp.\n\nTo run these notebooks, ``jupyterlab`` is required to be installed using:\n\n```text\npip install jupyterlab\n```\n\nFrom there, opening the notebooks can be done with the following command:\n\n```text\njupyter lab ./notebooks\n```\n\n* [Warp Core Tutorial: Basics](./notebooks/core_01_basics.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/core_01_basics.ipynb)\n* [Warp Core Tutorial: Generics](./notebooks/core_02_generics.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/core_02_generics.ipynb)\n* [Warp Core Tutorial: Points](./notebooks/core_03_points.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/core_03_points.ipynb)\n* [Warp Core Tutorial: Meshes](./notebooks/core_04_meshes.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/core_04_meshes.ipynb)\n* [Warp Core Tutorial: Volumes](./notebooks/core_05_volumes.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/core_05_volumes.ipynb)\n* [Warp PyTorch Tutorial: Basics](./notebooks/pytorch_01_basics.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/pytorch_01_basics.ipynb)\n* [Warp PyTorch Tutorial: Custom Operators](./notebooks/pytorch_02_custom_operators.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/warp/blob/main/notebooks/pytorch_02_custom_operators.ipynb)\n\n## Running Examples\n\nThe [warp/examples](./warp/examples/) directory contains a number of scripts categorized under subdirectories\nthat show how to implement various simulation methods using the Warp API.\nMost examples will generate USD files containing time-sampled animations in the current working directory.\nBefore running examples, users should ensure that the ``usd-core``, ``matplotlib``, and ``pyglet`` packages are installed using:\n\n```text\npip install warp-lang[extras]\n```\n\nThese dependencies can also be manually installed using:\n\n```text\npip install usd-core matplotlib pyglet\n```\n\nExamples can be run from the command-line as follows:\n\n```text\npython -m warp.examples.<example_subdir>.<example>\n```\n\nTo browse the example source code, you can open the directory where the files are located like this:\n\n```text\npython -m warp.examples.browse\n```\n\nMost examples can be run on either the CPU or a CUDA-capable device, but a handful require a CUDA-capable device. These are marked at the top of the example script.\n\nUSD files can be viewed or rendered inside [NVIDIA Omniverse](https://developer.nvidia.com/omniverse), Pixar's UsdView, and Blender. Note that Preview in macOS is not recommended as it has limited support for time-sampled animations.\n\nBuilt-in unit tests can be run from the command-line as follows:\n\n```text\npython -m warp.tests\n```\n\n### warp/examples/core\n\n<table>\n    <tbody>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_dem.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_dem.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_fluid.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_fluid.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_graph_capture.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_graph_capture.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_marching_cubes.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_marching_cubes.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">dem</td>\n            <td align=\"center\">fluid</td>\n            <td align=\"center\">graph capture</td>\n            <td align=\"center\">marching cubes</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_mesh.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_mesh.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_nvdb.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_nvdb.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_raycast.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_raycast.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_raymarch.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_raymarch.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">mesh</td>\n            <td align=\"center\">nvdb</td>\n            <td align=\"center\">raycast</td>\n            <td align=\"center\">raymarch</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_sph.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_sph.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_torch.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_torch.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/core/example_wave.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/core_wave.png\"></a></td>\n            <td></td>\n        </tr>\n        <tr>\n            <td align=\"center\">sph</td>\n            <td align=\"center\">torch</td>\n            <td align=\"center\">wave</td>\n            <td align=\"center\"></td>\n        </tr>\n    </tbody>\n</table>\n\n### warp/examples/fem\n\n<table>\n    <tbody>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_diffusion_3d.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_diffusion_3d.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_mixed_elasticity.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_mixed_elasticity.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_apic_fluid.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_apic_fluid.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_streamlines.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_streamlines.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">diffusion 3d</td>\n            <td align=\"center\">mixed elasticity</td>\n            <td align=\"center\">apic fluid</td>\n            <td align=\"center\">streamlines</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_convection_diffusion.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_convection_diffusion.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_navier_stokes.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_navier_stokes.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_burgers.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_burgers.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/fem/example_magnetostatics.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/fem_magnetostatics.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">convection diffusion</td>\n            <td align=\"center\">navier stokes</td>\n            <td align=\"center\">burgers</td>\n            <td align=\"center\">magnetostatics</td>\n        </tr>\n    </tbody>\n</table>\n\n### warp/examples/optim\n\n<table>\n    <tbody>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_bounce.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_bounce.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_cloth_throw.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_cloth_throw.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_diffray.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_diffray.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_drone.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_drone.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">bounce</td>\n            <td align=\"center\">cloth throw</td>\n            <td align=\"center\">diffray</td>\n            <td align=\"center\">drone</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_inverse_kinematics.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_inverse_kinematics.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_spring_cage.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_spring_cage.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_trajectory.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_trajectory.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_walker.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/optim_walker.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">inverse kinematics</td>\n            <td align=\"center\">spring cage</td>\n            <td align=\"center\">trajectory</td>\n            <td align=\"center\">walker</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/optim/example_softbody_properties.py\"><img src=\"https://media.githubusercontent.com/media/NVIDIA/warp/refs/heads/main/docs/img/examples/optim_softbody_properties.png\"></a></td>\n            <td></td>\n            <td></td>\n            <td></td>\n        </tr>\n        <tr>\n            <td align=\"center\">soft body properties</td>\n            <td align=\"center\"></td>\n            <td align=\"center\"></td>\n            <td align=\"center\"></td>\n        </tr>\n    </tbody>\n</table>\n\n### warp/examples/sim\n\n<table>\n    <tbody>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_cartpole.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_cartpole.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_cloth.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_cloth.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_granular.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_granular.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_granular_collision_sdf.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_granular_collision_sdf.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">cartpole</td>\n            <td align=\"center\">cloth</td>\n            <td align=\"center\">granular</td>\n            <td align=\"center\">granular collision sdf</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_jacobian_ik.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_jacobian_ik.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_quadruped.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_quadruped.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_rigid_chain.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_rigid_chain.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_rigid_contact.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_rigid_contact.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">jacobian ik</td>\n            <td align=\"center\">quadruped</td>\n            <td align=\"center\">rigid chain</td>\n            <td align=\"center\">rigid contact</td>\n        </tr>\n        <tr>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_rigid_force.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_rigid_force.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_rigid_gyroscopic.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_rigid_gyroscopic.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_rigid_soft_contact.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_rigid_soft_contact.png\"></a></td>\n            <td><a href=\"https://github.com/NVIDIA/warp/tree/main/warp/examples/sim/example_soft_body.py\"><img src=\"https://github.com/NVIDIA/warp/raw/main/docs/img/examples/sim_soft_body.png\"></a></td>\n        </tr>\n        <tr>\n            <td align=\"center\">rigid force</td>\n            <td align=\"center\">rigid gyroscopic</td>\n            <td align=\"center\">rigid soft contact</td>\n            <td align=\"center\">soft body</td>\n        </tr>\n    </tbody>\n</table>\n\n## Building\n\nFor developers who want to build the library themselves, the following tools are required:\n\n* Microsoft Visual Studio 2019 upwards (Windows)\n* GCC 9.4 upwards (Linux)\n* CUDA Toolkit 11.5 or higher\n* [Git LFS](https://git-lfs.github.com/) installed\n\nAfter cloning the repository, users should run:\n\n```text\npython build_lib.py\n```\n\nUpon success, the script will output platform-specific binary files in `warp/bin/`.\nThe build script will look for the CUDA Toolkit in its default installation path.\nThis path can be overridden by setting the `CUDA_PATH` environment variable. Alternatively,\nthe path to the CUDA Toolkit can be passed to the build command as\n`--cuda_path=\"...\"`. After building, the Warp package should be installed using:\n\n```text\npip install -e .\n```\n\nThis ensures that subsequent modifications to the library will be reflected in the Python package.\n\n## Learn More\n\nPlease see the following resources for additional background on Warp:\n\n* [Product Page](https://developer.nvidia.com/warp-python)\n* [SIGGRAPH 2024 Course Slides](https://dl.acm.org/doi/10.1145/3664475.3664543)\n* [GTC 2024 Presentation](https://www.nvidia.com/en-us/on-demand/session/gtc24-s63345/)\n* [GTC 2022 Presentation](https://www.nvidia.com/en-us/on-demand/session/gtcspring22-s41599)\n* [GTC 2021 Presentation](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31838)\n* [SIGGRAPH Asia 2021 Differentiable Simulation Course](https://dl.acm.org/doi/abs/10.1145/3476117.3483433)\n\nThe underlying technology in Warp has been used in a number of research projects at NVIDIA including the following publications:\n\n* Accelerated Policy Learning with Parallel Differentiable Simulation - Xu, J., Makoviychuk, V., Narang, Y., Ramos, F., Matusik, W., Garg, A., & Macklin, M. [(2022)](https://short-horizon-actor-critic.github.io)\n* DiSECt: Differentiable Simulator for Robotic Cutting - Heiden, E., Macklin, M., Narang, Y., Fox, D., Garg, A., & Ramos, F [(2021)](https://github.com/NVlabs/DiSECt)\n* gradSim: Differentiable Simulation for System Identification and Visuomotor Control - Murthy, J. Krishna, Miles Macklin, Florian Golemo, Vikram Voleti, Linda Petrini, Martin Weiss, Breandan Considine et al. [(2021)](https://gradsim.github.io)\n\n## Frequently Asked Questions\n\nSee the [FAQ](https://nvidia.github.io/warp/faq.html) in the Warp documentation.\n\n## Support\n\nProblems, questions, and feature requests can be opened on [GitHub Issues](https://github.com/NVIDIA/warp/issues).\n\nThe Warp team also monitors the **#warp** forum on the public [Omniverse Discord](https://discord.com/invite/nvidiaomniverse) server, come chat with us!\n\n## Versioning\n\nVersions take the format X.Y.Z, similar to [Python itself](https://devguide.python.org/developer-workflow/development-cycle/#devcycle):\n\n* Increments in X are reserved for major reworks of the project causing disruptive incompatibility (or reaching the 1.0 milestone).\n* Increments in Y are for regular releases with a new set of features.\n* Increments in Z are for bug fixes. In principle, there are no new features. Can be omitted if 0 or not relevant.\n\nThis is similar to [Semantic Versioning](https://semver.org/) but is less strict regarding backward compatibility.\nLike with Python, some breaking changes can be present between minor versions if well-documented and gradually introduced.\n\nNote that prior to 0.11.0, this schema was not strictly adhered to.\n\n## License\n\nWarp is provided under the NVIDIA Software License, please see [LICENSE.md](./LICENSE.md) for full license text.\n\n## Contributing\n\nContributions and pull requests from the community are welcome and are taken under the\nterms described in the **Feedback** section of [LICENSE.md](LICENSE.md#9-feedback).\nPlease see the [Contribution Guide](https://nvidia.github.io/warp/modules/contribution_guide.html) for more\ninformation on contributing to the development of Warp.\n\n## Citing\n\nIf you use Warp in your research, please use the following citation:\n\n```bibtex\n@misc{warp2022,\ntitle= {Warp: A High-performance Python Framework for GPU Simulation and Graphics},\nauthor = {Miles Macklin},\nmonth = {March},\nyear = {2022},\nnote= {NVIDIA GPU Technology Conference (GTC)},\nhowpublished = {\\url{https://github.com/nvidia/warp}}\n}\n```\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.6572265625,
          "content": "# Security\n\nNVIDIA is dedicated to the security and trust of our software products and services, including all source code repositories managed through our organization.\n\nIf you need to report a security issue, please use the appropriate contact points outlined below. **Please do not report security vulnerabilities through GitHub.**\n\n## Reporting Potential Security Vulnerability in an NVIDIA Product\n\nTo report a potential security vulnerability in any NVIDIA product:\n\n- Web: [Security Vulnerability Submission Form](https://www.nvidia.com/object/submit-security-vulnerability.html)\n- E-Mail: <psirt@nvidia.com>\n- We encourage you to use the following PGP key for secure email communication: [NVIDIA public PGP Key for communication](https://www.nvidia.com/en-us/security/pgp-key)\n  - Please include the following information:\n    - Product/Driver name and version/branch that contains the vulnerability\n    - Type of vulnerability (code execution, denial of service, buffer overflow, etc.)\n    - Instructions to reproduce the vulnerability\n    - Proof-of-concept or exploit code\n    - Potential impact of the vulnerability, including how an attacker could exploit the vulnerability\n\nWhile NVIDIA currently does not have a bug bounty program, we do offer acknowledgement when an externally reported security issue is addressed under our coordinated vulnerability disclosure policy. Please visit our [Product Security Incident Response Team (PSIRT)](https://www.nvidia.com/en-us/security/psirt-policies/) policies page for more information.\n\n## NVIDIA Product Security\n\nFor all security-related concerns, please visit NVIDIA's Product Security portal at <https://www.nvidia.com/en-us/security>\n"
        },
        {
          "name": "VERSION.md",
          "type": "blob",
          "size": 0.005859375,
          "content": "1.5.1\n"
        },
        {
          "name": "build_docs.py",
          "type": "blob",
          "size": 2.0625,
          "content": "# Copyright (c) 2022 NVIDIA CORPORATION.  All rights reserved.\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\nimport argparse\nimport os\nimport shutil\nimport subprocess\n\nfrom warp.context import export_functions_rst, export_stubs\n\nparser = argparse.ArgumentParser(description=\"Warp Sphinx Documentation Builder\")\n# Note argparse.BooleanOptionalAction can be used here when Python 3.9+ becomes the minimum supported version\nparser.add_argument(\"--doctest\", action=\"store_true\", help=\"Also run doctest on code snippets, default enabled\")\nparser.add_argument(\"--no_doctest\", dest=\"doctest\", action=\"store_false\")\nparser.set_defaults(doctest=True)\n\nargs = parser.parse_args()\n\nbase_path = os.path.dirname(os.path.realpath(__file__))\n\n# generate stubs for autocomplete\nwith open(os.path.join(base_path, \"warp\", \"stubs.py\"), \"w\") as stub_file:\n    export_stubs(stub_file)\n\n# code formatting of stubs.py\nsubprocess.run([\"ruff\", \"format\", \"--verbose\", os.path.join(base_path, \"warp\", \"stubs.py\")], check=True)\n\nwith open(os.path.join(base_path, \"docs\", \"modules\", \"functions.rst\"), \"w\") as function_ref:\n    export_functions_rst(function_ref)\n\nsource_dir = os.path.join(base_path, \"docs\")\noutput_dir = os.path.join(base_path, \"docs\", \"_build\", \"html\")\n\n# Clean previous HTML output\nif os.path.exists(output_dir):\n    shutil.rmtree(output_dir)\n\ncommand = [\"sphinx-build\", \"-W\", \"-b\", \"html\", source_dir, output_dir]\n\nsubprocess.run(command, check=True)\n\nif args.doctest:\n    print(\"Running doctest... (skip with --no_doctest)\")\n\n    output_dir = os.path.join(base_path, \"docs\", \"_build\", \"doctest\")\n\n    if os.path.exists(output_dir):\n        shutil.rmtree(output_dir)\n\n    command = [\"sphinx-build\", \"-W\", \"-b\", \"doctest\", source_dir, output_dir]\n\n    subprocess.run(command, check=True)\n\nprint(\"Finished\")\n"
        },
        {
          "name": "build_lib.py",
          "type": "blob",
          "size": 10.58203125,
          "content": "# Copyright (c) 2022 NVIDIA CORPORATION.  All rights reserved.\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\n\n# This script is an 'offline' build of the core warp runtime libraries\n# designed to be executed as part of CI / developer workflows, not\n# as part of the user runtime (since it requires CUDA toolkit, etc)\n\nimport sys\n\nif sys.version_info < (3, 8):\n    raise Exception(\"Warp requires Python 3.8 minimum\")\n\nimport argparse\nimport glob\nimport os\nimport platform\nimport shutil\n\nfrom warp.build_dll import build_dll, find_host_compiler, machine_architecture, set_msvc_env, verbose_cmd\nfrom warp.context import export_builtins\n\nparser = argparse.ArgumentParser(description=\"Warp build script\")\nparser.add_argument(\"--msvc_path\", type=str, help=\"Path to MSVC compiler (optional if already on PATH)\")\nparser.add_argument(\"--sdk_path\", type=str, help=\"Path to WinSDK (optional if already on PATH)\")\nparser.add_argument(\"--cuda_path\", type=str, help=\"Path to CUDA SDK\")\nparser.add_argument(\"--libmathdx_path\", type=str, help=\"Path to libmathdx (optional if LIBMATHDX_HOME is defined)\")\nparser.add_argument(\n    \"--mode\",\n    type=str,\n    default=\"release\",\n    help=\"Build configuration, default 'release'\",\n    choices=[\"release\", \"debug\"],\n)\n\n# Note argparse.BooleanOptionalAction can be used here when Python 3.9+ becomes the minimum supported version\nparser.add_argument(\"--verbose\", action=\"store_true\", help=\"Verbose building output, default enabled\")\nparser.add_argument(\"--no_verbose\", dest=\"verbose\", action=\"store_false\")\nparser.set_defaults(verbose=True)\n\nparser.add_argument(\n    \"--verify_fp\",\n    action=\"store_true\",\n    help=\"Verify kernel inputs and outputs are finite after each launch, default disabled\",\n)\nparser.add_argument(\"--no_verify_fp\", dest=\"verify_fp\", action=\"store_false\")\nparser.set_defaults(verify_fp=False)\n\nparser.add_argument(\"--fast_math\", action=\"store_true\", help=\"Enable fast math on library, default disabled\")\nparser.add_argument(\"--no_fast_math\", dest=\"fast_math\", action=\"store_false\")\nparser.set_defaults(fast_math=False)\n\nparser.add_argument(\"--quick\", action=\"store_true\", help=\"Only generate PTX code, disable CUTLASS ops\")\nparser.set_defaults(quick=False)\n\nparser.add_argument(\"--build_llvm\", action=\"store_true\", help=\"Build Clang/LLVM compiler from source, default disabled\")\nparser.add_argument(\"--no_build_llvm\", dest=\"build_llvm\", action=\"store_false\")\nparser.set_defaults(build_llvm=False)\n\nparser.add_argument(\n    \"--llvm_source_path\", type=str, help=\"Path to the LLVM project source code (optional, repo cloned if not set)\"\n)\n\nparser.add_argument(\"--debug_llvm\", action=\"store_true\", help=\"Enable LLVM compiler code debugging, default disabled\")\nparser.add_argument(\"--no_debug_llvm\", dest=\"debug_llvm\", action=\"store_false\")\nparser.set_defaults(debug_llvm=False)\n\nparser.add_argument(\"--standalone\", action=\"store_true\", help=\"Use standalone LLVM-based JIT compiler, default enabled\")\nparser.add_argument(\"--no_standalone\", dest=\"standalone\", action=\"store_false\")\nparser.set_defaults(standalone=True)\n\n\nargs = parser.parse_args()\n\n# set build output path off this file\nbase_path = os.path.dirname(os.path.realpath(__file__))\nbuild_path = os.path.join(base_path, \"warp\")\n\nprint(args)\n\nverbose_cmd = args.verbose\n\n\ndef find_cuda_sdk():\n    # check environment variables\n    for env in [\"WARP_CUDA_PATH\", \"CUDA_HOME\", \"CUDA_PATH\"]:\n        cuda_sdk = os.environ.get(env)\n        if cuda_sdk is not None:\n            print(f\"Using CUDA Toolkit path '{cuda_sdk}' provided through the '{env}' environment variable\")\n            return cuda_sdk\n\n    # use which/where to locate the nvcc compiler program\n    nvcc = shutil.which(\"nvcc\")\n    if nvcc is not None:\n        cuda_sdk = os.path.dirname(os.path.dirname(nvcc))  # strip the executable name and bin folder\n        print(f\"Using CUDA Toolkit path '{cuda_sdk}' found through 'which nvcc'\")\n        return cuda_sdk\n\n    # check default paths\n    if platform.system() == \"Windows\":\n        cuda_paths = glob.glob(\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v*.*\")\n        if len(cuda_paths) >= 1:\n            cuda_sdk = cuda_paths[0]\n            print(f\"Using CUDA Toolkit path '{cuda_sdk}' found at default path\")\n            return cuda_sdk\n\n    else:\n        usr_local_cuda = \"/usr/local/cuda\"\n        if os.path.exists(usr_local_cuda):\n            cuda_sdk = usr_local_cuda\n            print(f\"Using CUDA Toolkit path '{cuda_sdk}' found at default path\")\n            return cuda_sdk\n\n    return None\n\n\ndef find_libmathdx():\n    libmathdx_path = os.environ.get(\"LIBMATHDX_HOME\")\n\n    if libmathdx_path:\n        print(f\"Using libmathdx path '{libmathdx_path}' provided through the 'LIBMATHDX_HOME' environment variable\")\n        return libmathdx_path\n    else:\n        # First check if a libmathdx folder exists in the target location\n        extract_dir_base = os.path.join(\".\", \"_build\", \"target-deps\")\n        extract_dir = os.path.join(extract_dir_base, \"libmathdx\")\n\n        if os.path.isdir(extract_dir) and os.listdir(extract_dir):\n            # Directory is not empty, so let's try to use it\n            print(f\"Using existing libmathdx at path '{os.path.abspath(extract_dir)}'\")\n            return os.path.abspath(extract_dir)\n\n        base_url = \"https://developer.nvidia.com/downloads/compute/cublasdx/redist/cublasdx\"\n        libmathdx_ver = \"0.1.0\"\n\n        if platform.system() == \"Windows\":\n            source_url = f\"{base_url}/libmathdx-{libmathdx_ver}-win64.zip\"\n        elif platform.system() == \"Linux\":\n            source_url = f\"{base_url}/libmathdx-Linux-{machine_architecture()}-{libmathdx_ver}.tar.gz\"\n        else:\n            return None\n\n        import urllib.request\n\n        try:\n            local_filename, _ = urllib.request.urlretrieve(source_url)\n        except Exception as e:\n            print(f\"Unable to download libmathdx from {source_url}, skipping: {e}\")\n            return None\n\n        if platform.system() == \"Windows\":\n            import zipfile\n\n            try:\n                with zipfile.ZipFile(local_filename, \"r\") as zip_file:\n                    zip_file.extractall(extract_dir_base)\n\n            except Exception as e:\n                print(f\"Unable to extract libmathdx to {extract_dir_base}, skipping: {e}\")\n                return None\n\n            try:\n                os.rename(os.path.join(extract_dir_base, f\"libmathdx-{libmathdx_ver}-win64\"), extract_dir)\n            except Exception:\n                # Unable to rename to preferred directory name, return the intermediate one\n                return os.path.abspath(os.path.join(extract_dir_base, f\"libmathdx-{libmathdx_ver}-win64\"))\n        else:\n            import tarfile\n\n            try:\n                with tarfile.open(local_filename, \"r:gz\") as tar_file:\n                    tar_file.extractall(extract_dir_base, filter=\"data\")\n            except Exception as e:\n                print(f\"Unable to extract libmathdx to {extract_dir_base}, skipping: {e}\")\n                return None\n\n        # Success\n        return os.path.abspath(extract_dir)\n\n\n# setup CUDA Toolkit path\nif platform.system() == \"Darwin\":\n    args.cuda_path = None\nelse:\n    if not args.cuda_path:\n        args.cuda_path = find_cuda_sdk()\n\n    # libmathdx needs to be used with a build of Warp that supports CUDA\n    if not args.libmathdx_path and args.cuda_path:\n        args.libmathdx_path = find_libmathdx()\n\n# setup MSVC and WinSDK paths\nif platform.system() == \"Windows\":\n    if args.msvc_path or args.sdk_path:\n        # user provided MSVC and Windows SDK\n        assert args.msvc_path and args.sdk_path, \"--msvc_path and --sdk_path must be used together.\"\n\n        args.host_compiler = set_msvc_env(msvc_path=args.msvc_path, sdk_path=args.sdk_path)\n    else:\n        # attempt to find MSVC in environment (will set vcvars)\n        args.host_compiler = find_host_compiler()\n\n        if not args.host_compiler:\n            print(\"Warp build error: Could not find MSVC compiler\")\n            sys.exit(1)\n\n\n# return platform specific shared library name\ndef lib_name(name):\n    if platform.system() == \"Windows\":\n        return f\"{name}.dll\"\n    elif platform.system() == \"Darwin\":\n        return f\"lib{name}.dylib\"\n    else:\n        return f\"{name}.so\"\n\n\ndef generate_exports_header_file():\n    \"\"\"Generates warp/native/exports.h, which lets built-in functions be callable from outside kernels\"\"\"\n\n    # set build output path off this file\n    export_path = os.path.join(base_path, \"warp\", \"native\", \"exports.h\")\n\n    try:\n        with open(export_path, \"w\") as f:\n            export_builtins(f)\n\n        print(f\"Finished writing {export_path}\")\n    except FileNotFoundError:\n        print(f\"Error: The file '{export_path}' was not found.\")\n    except PermissionError:\n        print(f\"Error: Permission denied. Unable to write to '{export_path}'.\")\n    except OSError as e:\n        print(f\"Error: An OS-related error occurred: {e}\")\n    except Exception as e:\n        print(f\"An unexpected error occurred: {e}\")\n\n\ntry:\n    # Generate warp/native/export.h\n    generate_exports_header_file()\n\n    # build warp.dll\n    cpp_sources = [\n        \"native/warp.cpp\",\n        \"native/crt.cpp\",\n        \"native/error.cpp\",\n        \"native/cuda_util.cpp\",\n        \"native/mesh.cpp\",\n        \"native/hashgrid.cpp\",\n        \"native/reduce.cpp\",\n        \"native/runlength_encode.cpp\",\n        \"native/sort.cpp\",\n        \"native/sparse.cpp\",\n        \"native/volume.cpp\",\n        \"native/marching.cpp\",\n        \"native/cutlass_gemm.cpp\",\n        \"native/mathdx.cpp\",\n        \"native/coloring.cpp\",\n    ]\n    warp_cpp_paths = [os.path.join(build_path, cpp) for cpp in cpp_sources]\n\n    if args.cuda_path is None:\n        print(\"Warning: CUDA toolchain not found, building without CUDA support\")\n        warp_cu_path = None\n    else:\n        warp_cu_path = os.path.join(build_path, \"native/warp.cu\")\n\n    if args.libmathdx_path is None:\n        print(\"Warning: libmathdx not found, building without MathDx support\")\n\n    warp_dll_path = os.path.join(build_path, f\"bin/{lib_name('warp')}\")\n\n    build_dll(args, dll_path=warp_dll_path, cpp_paths=warp_cpp_paths, cu_path=warp_cu_path)\n\n    # build warp-clang.dll\n    if args.standalone:\n        import build_llvm\n\n        if args.build_llvm:\n            build_llvm.build_from_source(args)\n\n        build_llvm.build_warp_clang(args, lib_name(\"warp-clang\"))\n\nexcept Exception as e:\n    # output build error\n    print(f\"Warp build error: {e}\")\n\n    # report error\n    sys.exit(1)\n"
        },
        {
          "name": "build_llvm.py",
          "type": "blob",
          "size": 15.8994140625,
          "content": "import os\nimport subprocess\nimport sys\n\nfrom warp.build_dll import *\n\n# set build output path off this file\nbase_path = os.path.dirname(os.path.realpath(__file__))\nbuild_path = os.path.join(base_path, \"warp\")\n\nllvm_project_path = os.path.join(base_path, \"external/llvm-project\")\nllvm_build_path = os.path.join(llvm_project_path, \"out/build/\")\nllvm_install_path = os.path.join(llvm_project_path, \"out/install/\")\n\n\n# Fetch prebuilt Clang/LLVM libraries\ndef fetch_prebuilt_libraries(arch):\n    if os.name == \"nt\":\n        packman = \"tools\\\\packman\\\\packman.cmd\"\n        packages = {\"x86_64\": \"15.0.7-windows-x86_64-ptx-vs142\"}\n    else:\n        packman = \"./tools/packman/packman\"\n        if sys.platform == \"darwin\":\n            packages = {\n                \"aarch64\": \"15.0.7-darwin-aarch64-macos11\",\n                \"x86_64\": \"15.0.7-darwin-x86_64-macos11\",\n            }\n        else:\n            packages = {\n                \"aarch64\": \"15.0.7-linux-aarch64-gcc7.5\",\n                \"x86_64\": \"18.1.3-linux-x86_64-gcc9.4\",\n            }\n\n    try:\n        subprocess.check_output(\n            [\n                packman,\n                \"install\",\n                \"-l\",\n                f\"./_build/host-deps/llvm-project/release-{arch}\",\n                \"clang+llvm-warp\",\n                packages[arch],\n            ],\n            stderr=subprocess.STDOUT,\n            text=True,\n        )\n    except subprocess.CalledProcessError as e:\n        print(e.output)\n        raise e\n\n\ndef build_from_source_for_arch(args, arch, llvm_source):\n    # Check out the LLVM project Git repository, unless it already exists\n    if not os.path.exists(llvm_source):\n        # Install dependencies\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"gitpython\"])\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"cmake\"])\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ninja\"])\n\n        from git import Repo\n\n        repo_url = \"https://github.com/llvm/llvm-project.git\"\n        print(f\"Cloning LLVM project from {repo_url}...\")\n\n        shallow_clone = True  # https://github.blog/2020-12-21-get-up-to-speed-with-partial-clone-and-shallow-clone/\n        version = \"18.1.3\"\n        if shallow_clone:\n            repo = Repo.clone_from(\n                repo_url,\n                to_path=llvm_source,\n                single_branch=True,\n                branch=f\"llvmorg-{version}\",\n                depth=1,\n            )\n        else:\n            repo = Repo.clone_from(repo_url, to_path=llvm_source)\n            repo.git.checkout(f\"tags/llvmorg-{version}\", \"-b\", f\"llvm-{version}\")\n\n    print(f\"Using LLVM project source from {llvm_source}\")\n\n    # CMake supports Debug, Release, RelWithDebInfo, and MinSizeRel builds\n    if args.mode == \"release\":\n        msvc_runtime = \"MultiThreaded\"\n        # prefer smaller size over aggressive speed\n        cmake_build_type = \"MinSizeRel\"\n    else:\n        msvc_runtime = \"MultiThreadedDebug\"\n        # When args.mode == \"debug\" we build a Debug version of warp.dll but\n        # we generally don't want warp-clang.dll to be a slow Debug version.\n        if args.debug_llvm:\n            cmake_build_type = \"Debug\"\n        else:\n            # The GDB/LLDB debugger observes the __jit_debug_register_code symbol\n            # defined by the LLVM JIT, for which it needs debug info.\n            cmake_build_type = \"RelWithDebInfo\"\n\n    # Location of cmake and ninja installed through pip (see build.bat / build.sh)\n    python_bin = \"python/Scripts\" if sys.platform == \"win32\" else \"python/bin\"\n    os.environ[\"PATH\"] = os.path.join(base_path, \"_build/target-deps/\" + python_bin) + os.pathsep + os.environ[\"PATH\"]\n\n    if arch == \"aarch64\":\n        target_backend = \"AArch64\"\n    else:\n        target_backend = \"X86\"\n\n    if sys.platform == \"darwin\":\n        host_triple = f\"{arch}-apple-macos11\"\n        osx_architectures = arch  # build one architecture only\n        abi_version = \"\"\n    elif os.name == \"nt\":\n        host_triple = f\"{arch}-pc-windows\"\n        osx_architectures = \"\"\n        abi_version = \"\"\n    else:\n        host_triple = f\"{arch}-pc-linux\"\n        osx_architectures = \"\"\n        abi_version = \"-fabi-version=13\"  # GCC 8.2+\n\n    llvm_path = os.path.join(llvm_source, \"llvm\")\n    build_path = os.path.join(llvm_build_path, f\"{args.mode}-{arch}\")\n    install_path = os.path.join(llvm_install_path, f\"{args.mode}-{arch}\")\n\n    # Build LLVM and Clang\n    # fmt: off\n    cmake_gen = [\n        \"cmake\",\n        \"-S\", llvm_path,\n        \"-B\", build_path,\n        \"-G\", \"Ninja\",\n        \"-D\", f\"CMAKE_BUILD_TYPE={cmake_build_type}\",\n        \"-D\", f\"CMAKE_MSVC_RUNTIME_LIBRARY={msvc_runtime}\",\n        \"-D\", f\"LLVM_TARGETS_TO_BUILD={target_backend};NVPTX\",\n        \"-D\", \"LLVM_ENABLE_PROJECTS=clang\",\n        \"-D\", \"LLVM_ENABLE_ZLIB=FALSE\",\n        \"-D\", \"LLVM_ENABLE_ZSTD=FALSE\",\n        \"-D\", \"LLVM_ENABLE_TERMINFO=FALSE\",\n        \"-D\", \"LLVM_BUILD_LLVM_C_DYLIB=FALSE\",\n        \"-D\", \"LLVM_BUILD_RUNTIME=FALSE\",\n        \"-D\", \"LLVM_BUILD_RUNTIMES=FALSE\",\n        \"-D\", \"LLVM_BUILD_TOOLS=FALSE\",\n        \"-D\", \"LLVM_BUILD_UTILS=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_BENCHMARKS=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_DOCS=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_EXAMPLES=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_RUNTIMES=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_TESTS=FALSE\",\n        \"-D\", \"LLVM_INCLUDE_TOOLS=TRUE\",  # Needed by Clang\n        \"-D\", \"LLVM_INCLUDE_UTILS=FALSE\",\n        \"-D\", f\"CMAKE_CXX_FLAGS=-D_GLIBCXX_USE_CXX11_ABI=0 {abi_version}\",  # The pre-C++11 ABI is still the default on the CentOS 7 toolchain\n        \"-D\", f\"CMAKE_INSTALL_PREFIX={install_path}\",\n        \"-D\", f\"LLVM_HOST_TRIPLE={host_triple}\",\n        \"-D\", f\"CMAKE_OSX_ARCHITECTURES={osx_architectures}\",\n\n        # Disable unused tools and features\n        \"-D\", \"CLANG_BUILD_TOOLS=FALSE\",\n        \"-D\", \"LLVM_ENABLE_PLUGINS=FALSE\",\n        \"-D\", \"CLANG_PLUGIN_SUPPORT=FALSE\",\n        \"-D\", \"CLANG_ENABLE_ARCMT=FALSE\",\n        \"-D\", \"CLANG_ENABLE_STATIC_ANALYZER=FALSE\",\n        \"-D\", \"CLANG_TOOLING_BUILD_AST_INTROSPECTION=FALSE\",\n        \"-D\", \"CLANG_TOOL_AMDGPU_ARCH_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_APINOTES_TEST_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_ARCMT_TEST_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_CHECK_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_DIFF_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_EXTDEF_MAPPING_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_FORMAT_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_FORMAT_VS_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_FUZZER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_IMPORT_TEST_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_LINKER_WRAPPER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_NVLINK_WRAPPER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_OFFLOAD_PACKAGER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_OFFLOAD_WRAPPER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_REFACTOR_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_RENAME_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_REPL_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_SCAN_DEPS_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_SHLIB_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_C_ARCMT_TEST_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_C_INDEX_TEST_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_DIAGTOOL_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_DRIVER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_LIBCLANG_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_SCAN_BUILD_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_SCAN_BUILD_PY_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=FALSE\",\n        \"-D\", \"CLANG_TOOL_SCAN_VIEW_BUILD=FALSE\",\n        \"-D\", \"LLVM_ENABLE_BINDINGS=FALSE\",\n        \"-D\", \"LLVM_ENABLE_OCAMLDOC=FALSE\",\n        \"-D\", \"LLVM_TOOL_BUGPOINT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_BUGPOINT_PASSES_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_CLANG_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_DSYMUTIL_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_DXIL_DIS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_GOLD_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLC_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLDB_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLI_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_AR_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_AS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_AS_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_BCANALYZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CAT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CFI_VERIFY_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CONFIG_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_COV_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CVTRES_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CXXDUMP_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CXXFILT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_CXXMAP_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_C_TEST_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DEBUGINFOD_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DEBUGINFOD_FIND_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DIFF_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DIS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DIS_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DLANG_DEMANGLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DWARFDUMP_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DWARFUTIL_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_DWP_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_EXEGESIS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_EXTRACT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_GO_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_GSYMUTIL_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_IFS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_ISEL_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_ITANIUM_DEMANGLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_JITLINK_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_JITLISTENER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_LIBTOOL_DARWIN_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_LINK_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_LIPO_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_LTO2_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_LTO_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MCA_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MC_ASSEMBLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MC_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MC_DISASSEMBLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MICROSOFT_DEMANGLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_ML_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MODEXTRACT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_MT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_NM_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_OBJCOPY_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_OBJDUMP_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_OPT_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_OPT_REPORT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_PDBUTIL_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_PROFDATA_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_PROFGEN_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_RC_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_READOBJ_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_REDUCE_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_REMARK_SIZE_DIFF_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_RTDYLD_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_RUST_DEMANGLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SHLIB_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SIM_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SIZE_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SPECIAL_CASE_LIST_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SPLIT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_STRESS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_STRINGS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_SYMBOLIZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_TAPI_DIFF_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_TLI_CHECKER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_UNDNAME_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_XRAY_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_YAML_NUMERIC_PARSER_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LLVM_YAML_PARSER_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_LTO_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_OBJ2YAML_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_OPT_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_OPT_VIEWER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_REMARKS_SHLIB_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_SANCOV_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_SANSTATS_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_SPLIT_FILE_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_VERIFY_USELISTORDER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_VFABI_DEMANGLE_FUZZER_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_XCODE_TOOLCHAIN_BUILD=FALSE\",\n        \"-D\", \"LLVM_TOOL_YAML2OBJ_BUILD=FALSE\",\n    ]\n    # fmt: on\n    subprocess.check_call(cmake_gen, stderr=subprocess.STDOUT)\n\n    cmake_build = [\"cmake\", \"--build\", build_path]\n    subprocess.check_call(cmake_build, stderr=subprocess.STDOUT)\n\n    cmake_install = [\"cmake\", \"--install\", build_path]\n    subprocess.check_call(cmake_install, stderr=subprocess.STDOUT)\n\n\ndef build_from_source(args):\n    print(\"Building Clang/LLVM from source...\")\n\n    if args.llvm_source_path is not None:\n        llvm_source = args.llvm_source_path\n    else:\n        llvm_source = llvm_project_path\n\n    # build for the machine's architecture\n    build_from_source_for_arch(args, machine_architecture(), llvm_source)\n\n    # for Apple systems also cross-compile for building a universal binary\n    if sys.platform == \"darwin\":\n        if machine_architecture() == \"x86_64\":\n            build_from_source_for_arch(args, \"aarch64\", llvm_source)\n        else:\n            build_from_source_for_arch(args, \"x86_64\", llvm_source)\n\n\n# build warp-clang.dll\ndef build_warp_clang_for_arch(args, lib_name, arch):\n    try:\n        cpp_sources = [\n            \"native/clang/clang.cpp\",\n            \"native/crt.cpp\",\n        ]\n        clang_cpp_paths = [os.path.join(build_path, cpp) for cpp in cpp_sources]\n\n        clang_dll_path = os.path.join(build_path, f\"bin/{lib_name}\")\n\n        if args.build_llvm:\n            # obtain Clang and LLVM libraries from the local build\n            install_path = os.path.join(llvm_install_path, f\"{args.mode}-{arch}\")\n            libpath = os.path.join(install_path, \"lib\")\n        else:\n            # obtain Clang and LLVM libraries from packman\n            fetch_prebuilt_libraries(arch)\n            libpath = os.path.join(base_path, f\"_build/host-deps/llvm-project/release-{arch}/lib\")\n\n        libs = []\n\n        for _, _, libraries in os.walk(libpath):\n            libs.extend(libraries)\n            break  # just the top level contains library files\n\n        if os.name == \"nt\":\n            libs.append(\"Version.lib\")\n            libs.append(\"Ws2_32.lib\")\n            libs.append(f'/LIBPATH:\"{libpath}\"')\n        else:\n            libs = [f\"-l{lib[3:-2]}\" for lib in libs if os.path.splitext(lib)[1] == \".a\"]\n            if sys.platform == \"darwin\":\n                libs += libs  # prevents unresolved symbols due to link order\n            else:\n                libs.insert(0, \"-Wl,--start-group\")\n                libs.append(\"-Wl,--end-group\")\n            libs.append(f\"-L{libpath}\")\n            libs.append(\"-lpthread\")\n            libs.append(\"-ldl\")\n            if sys.platform != \"darwin\":\n                libs.append(\"-lrt\")\n\n        build_dll_for_arch(\n            args,\n            dll_path=clang_dll_path,\n            cpp_paths=clang_cpp_paths,\n            cu_path=None,\n            libs=libs,\n            arch=arch,\n            mode=args.mode if args.build_llvm else \"release\",\n        )\n\n    except Exception as e:\n        # output build error\n        print(f\"Warp Clang/LLVM build error: {e}\")\n\n        # report error\n        sys.exit(1)\n\n\ndef build_warp_clang(args, lib_name):\n    if sys.platform == \"darwin\":\n        # create a universal binary by combining x86-64 and AArch64 builds\n        build_warp_clang_for_arch(args, lib_name + \"-x86_64\", \"x86_64\")\n        build_warp_clang_for_arch(args, lib_name + \"-aarch64\", \"aarch64\")\n\n        dylib_path = os.path.join(build_path, f\"bin/{lib_name}\")\n        run_cmd(f\"lipo -create -output {dylib_path} {dylib_path}-x86_64 {dylib_path}-aarch64\")\n        os.remove(f\"{dylib_path}-x86_64\")\n        os.remove(f\"{dylib_path}-aarch64\")\n\n    else:\n        build_warp_clang_for_arch(args, lib_name, machine_architecture())\n"
        },
        {
          "name": "deps",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "exts",
          "type": "tree",
          "content": null
        },
        {
          "name": "licenses",
          "type": "tree",
          "content": null
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.044921875,
          "content": "[build-system]\nrequires = [\"setuptools>=61\", \"build\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"warp-lang\"\nrequires-python = \">=3.8\" # 3.9 recommended\nauthors = [{ name = \"NVIDIA Corporation\", email = \"mmacklin@nvidia.com\" }]\ndescription = \"A Python framework for high-performance simulation and graphics programming\"\nlicense = { text = \"NVIDIA Software License\" }\nclassifiers = [\n    \"Programming Language :: Python :: 3.8\",  # Deprecated\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"License :: Other/Proprietary License\",\n    \"Operating System :: OS Independent\",\n]\ndependencies = [\"numpy\"]\ndynamic = [\"version\", \"readme\"]\n\n[project.urls]\nGitHub = \"https://github.com/NVIDIA/warp\"\nDocumentation = \"https://nvidia.github.io/warp\"\nChangelog = \"https://github.com/NVIDIA/warp/blob/main/CHANGELOG.md\"\n\n[project.optional-dependencies]\ndev = [\"pre-commit\", \"ruff\", \"nvtx\", \"nvidia-sphinx-theme\", \"sphinx-copybutton\", \"coverage[toml]\"]\nextras = ['usd-core', 'matplotlib', 'pyglet']\n\n[tool.setuptools.packages.find]\ninclude = [\"warp*\"]\n\n[tool.setuptools.dynamic]\nversion = { file = [\"VERSION.md\"] }\nreadme = { file = [\"README.md\"], content-type = \"text/markdown\" }\n\n[tool.ruff]\ncache-dir = \".cache/ruff\"\nline-length = 120\nindent-width = 4\nextend-exclude = [\n    \"notebooks\",\n    \"warp/native/cutlass/\",\n    \"warp/thirdparty/appdirs.py\",\n    \"warp/thirdparty/dlpack.py\",\n    \"tools\",\n    \"stubs.py\",\n]\n\n[tool.ruff.lint]\nselect = [\n    \"E\",  # pycodestyle errors\n    \"I\",  # isort\n    \"F\", # pyflakes\n    \"W\",  # pycodestyle warnings\n    \"B\",  # flake8-bugbear\n    \"C4\",  # flake8-comprehensions\n    \"NPY\",  # NumPy-specific rules\n    \"PLC\",  # pylint convention\n    \"PLE\",  # pylint error\n    \"PLW\"  # pylint warning\n]\nignore = [\n    \"E501\", # Many lines are over 120 characters already\n    \"E741\", # Warp often uses l as a variable name\n    \"F403\", # Allow wildcard imports\n    \"F405\", # Related to use of wildcard imports\n    \"F811\", # Warp often uses overloads\n    \"E721\", # Warp often uses == in float and int type comparisons\n    \"PLW0603\" # Allow assignments to global variables\n]\n\n[tool.ruff.lint.per-file-ignores]\n\"__init__.py\" = [\"F401\"]\n\"warp/tests/*.py\" = [\"F841\"]\n\n[tool.ruff.lint.pydocstyle]\nconvention = \"google\"\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\nskip-magic-trailing-comma = false\nline-ending = \"auto\"\ndocstring-code-format = true\n\n[tool.coverage.run]\nsource = [\"warp\", \"warp.sim\", \"warp.render\"]\ndisable_warnings = [\n    \"module-not-measured\",\n    \"module-not-imported\",\n    \"no-data-collected\",\n    \"couldnt-parse\",\n]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"@wp\",\n    \"@warp\",\n    \"if 0:\",\n    \"if __name__ == .__main__.:\",\n]\nomit = [\n    \"*/warp/thirdparty/*\",\n    \"*/warp/examples/*\",\n    \"*/warp/tests/*\",\n    \"*/warp/fem/*\",\n    \"appdirs.py\",\n    \"render_opengl.py\",\n    \"build_dll.py\",\n    \"config.py\",\n    \"stubs.py\",\n]\n"
        },
        {
          "name": "repo.toml",
          "type": "blob",
          "size": 1.5625,
          "content": "########################################################################################################################\n# Repo tool base settings\n########################################################################################################################\n\n[repo]\n\n# Repository Name\nname = \"warp\"\n\nextra_tool_paths = [\n    \"${root}/_build/kit-deps/kit-kernel/dev\",\n]\n\nimport_configs = [\n    \"${root}/_repo/deps/repo_kit_tools/kit-template/repo.toml\",\n]\n\n\n########################################################################################################################\n# Build tool setup\n########################################################################################################################\n\n[repo_build]\n\n# List of packman projects to pull (in order)\nfetch.packman_host_files_to_pull = [\n    \"${root}/deps/host-deps.packman.xml\",\n]\n\nfetch.packman_target_files_to_pull = [\n    \"${root}/deps/target-deps.packman.xml\",\n]\n\n# Extensions precache\nfetch.after_pull_commands = [\n]\n\n[repo_build_number]\nenabled = true\n\n########################################################################################################################\n# Extensions publisher\n########################################################################################################################\n\n[repo_publish_exts]\n\nkit_path = \"${root}/_build/kit-deps/kit-kernel/kit${exe_ext}\"\n\next_folders = [\n    \"${root}/_build/${platform_target}/${config}/exts\"\n]\n\nexts.include = [\n    \"omni.warp\",\n    \"omni.warp.core\",\n]\n\nconfigs = [\"release\"]\nplatforms = [\"windows-x86_64\", \"linux-x86_64\"]\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.05859375,
          "content": "import argparse\nimport os\nimport pathlib\nimport platform\nimport shutil\nimport sys\nfrom typing import NamedTuple\n\nimport setuptools\nfrom wheel.bdist_wheel import bdist_wheel\n\n# Parse --build-option arguments meant for the bdist_wheel command. We have to parse these\n# ourselves because when bdist_wheel runs it's too late to select a subset of libraries for package_data.\nparser = argparse.ArgumentParser()\nparser.add_argument(\"command\")\nparser.add_argument(\n    \"--platform\", \"-P\", type=str, default=\"\", help=\"Wheel platform: windows|linux|macos-x86_64|aarch64|universal\"\n)\nargs = parser.parse_known_args()[0]\n\n\n# returns a canonical machine architecture string\n# - \"x86_64\" for x86-64, aka. AMD64, aka. x64\n# - \"aarch64\" for AArch64, aka. ARM64\ndef machine_architecture() -> str:\n    machine = platform.machine()\n    if machine == \"x86_64\" or machine == \"AMD64\":\n        return \"x86_64\"\n    if machine == \"aarch64\" or machine == \"arm64\":\n        return \"aarch64\"\n    raise RuntimeError(f\"Unrecognized machine architecture {machine}\")\n\n\ndef machine_os() -> str:\n    if sys.platform == \"win32\":\n        return \"windows\"\n    if sys.platform == \"linux\":\n        return \"linux\"\n    if sys.platform == \"darwin\":\n        return \"macos\"\n    raise RuntimeError(f\"Unrecognized system platform {sys.platform}\")\n\n\nclass Platform(NamedTuple):\n    os: str\n    arch: str\n    fancy_name: str\n    extension: str\n    tag: str\n\n    def name(self) -> str:\n        return self.os + \"-\" + self.arch\n\n\nplatforms = [\n    Platform(\"windows\", \"x86_64\", \"Windows x86-64\", \".dll\", \"win_amd64\"),\n    Platform(\"linux\", \"x86_64\", \"Linux x86-64\", \".so\", \"manylinux2014_x86_64\"),\n    Platform(\"linux\", \"aarch64\", \"Linux AArch64\", \".so\", \"manylinux2014_aarch64\"),\n    Platform(\"macos\", \"universal\", \"macOS universal\", \".dylib\", \"macosx_10_13_universal2\"),\n]\n\n\nclass Library(NamedTuple):\n    file: str\n    directory: str\n    platform: Platform\n\n\n# Enumerate warp/bin libraries\ndef detect_warp_libraries():\n    detected_libraries = set()\n    warp_bin = pathlib.Path(\"warp/bin\")\n    for file in warp_bin.rglob(\"*.*\"):\n        for p in platforms:\n            if os.path.splitext(file.name)[1] == p.extension:\n                # If this is a local build, assume we want a wheel for this machine's architecture\n                if file.parent.name == \"bin\" and (p.arch == machine_architecture() or p.arch == \"universal\"):\n                    detected_libraries.add(Library(file.name, \"bin/\", p))\n                else:\n                    # Expect libraries to be in a subdirectory named after the wheel platform\n                    platform_name = p.name()\n                    if file.parent.name == platform_name:\n                        detected_libraries.add(Library(file.name, \"bin/\" + platform_name + \"/\", p))\n\n    if len(detected_libraries) == 0:\n        raise Exception(\"No libraries found in warp/bin. Please run build_lib.py first.\")\n\n    return detected_libraries\n\n\ndetected_libraries = detect_warp_libraries()\ndetected_platforms = {lib.platform for lib in detected_libraries}\n\nwheel_platform = None  # The one platform for which we're building a wheel\n\nif args.command == \"bdist_wheel\":\n    if args.platform != \"\":\n        for p in platforms:\n            if args.platform == p.name():\n                wheel_platform = p\n                print(f\"Platform argument specified for building {p.fancy_name} wheel\")\n                break\n\n        if wheel_platform is None:\n            print(f\"Platform argument '{args.platform}' not recognized\")\n        elif wheel_platform not in detected_platforms:\n            print(f\"No libraries found for {wheel_platform.fancy_name}\")\n            print(\"Falling back to auto-detection\")\n            wheel_platform = None\n\n    if wheel_platform is None:\n        if len(detected_platforms) > 1:\n            print(\"Libraries for multiple platforms were detected.\")\n            print(\n                \"Run `python -m build --wheel -C--build-option=-P[windows|linux|macos]-[x86_64|aarch64|universal]` to select a specific one.\"\n            )\n            # Select the libraries corresponding with the this machine's platform\n            for p in platforms:\n                if p.os == machine_os() and p.arch == machine_architecture():\n                    wheel_platform = p\n                    break\n\n        if wheel_platform is None:\n            # Just pick the first one\n            wheel_platform = next(iter(detected_platforms))\n\n    print(\"Creating Warp wheel for \" + wheel_platform.fancy_name)\n\n\n# Binary wheel distribution builds assume that the platform you're building on will be the platform\n# of the package. This class overrides the platform tag.\n# https://packaging.python.org/en/latest/specifications/platform-compatibility-tags\nclass WarpBDistWheel(bdist_wheel):\n    # Even though we parse the platform argument ourselves, we need to declare it here as well so\n    # setuptools.Command can validate the command line options.\n    user_options = bdist_wheel.user_options + [\n        (\"platform=\", \"P\", \"Wheel platform: windows|linux|macos-x86_64|aarch64|universal\"),\n    ]\n\n    def initialize_options(self):\n        super().initialize_options()\n        self.platform = \"\"\n\n    def get_tag(self):\n        if wheel_platform is not None:\n            # The wheel's complete tag format is {python tag}-{abi tag}-{platform tag}.\n            return \"py3\", \"none\", wheel_platform.tag\n        else:\n            # The target platform was not overridden. Fall back to base class behavior.\n            return bdist_wheel.get_tag(self)\n\n    def run(self):\n        super().run()\n\n        # Clean up so we can re-invoke `py -m build --wheel -C--build-option=--platform=...`\n        # See https://github.com/pypa/setuptools/issues/1871 for details.\n        shutil.rmtree(\"./build\", ignore_errors=True)\n        shutil.rmtree(\"./warp_lang.egg-info\", ignore_errors=True)\n\n\n# Distributions are identified as non-pure (i.e. containing non-Python code, or binaries) if the\n# setuptools.setup() `ext_modules` parameter is not empty, but this assumes building extension\n# modules from source through the Python build. This class provides an override for prebuilt binaries:\nclass BinaryDistribution(setuptools.Distribution):\n    def has_ext_modules(self):\n        return True\n\n\ndef get_warp_libraries(platform):\n    libraries = []\n    for library in detected_libraries:\n        if library.platform == platform:\n            src = \"warp/\" + library.directory + library.file\n            dst = \"warp/bin/\" + library.file\n            if src != dst:\n                shutil.copyfile(src, dst)\n\n            libraries.append(\"bin/\" + library.file)\n\n    return libraries\n\n\nif wheel_platform is not None:\n    warp_binary_libraries = get_warp_libraries(wheel_platform)\nelse:\n    warp_binary_libraries = []  # Not needed during egg_info command\n\nsetuptools.setup(\n    package_data={\n        \"\": [\n            \"native/*.cpp\",\n            \"native/*.cu\",\n            \"native/*.h\",\n            \"native/clang/*.cpp\",\n            \"native/nanovdb/*.h\",\n            \"tests/assets/*\",\n            \"examples/assets/*\",\n        ]\n        + warp_binary_libraries,\n    },\n    distclass=BinaryDistribution,\n    cmdclass={\n        \"bdist_wheel\": WarpBDistWheel,\n    },\n)\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "warp",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}