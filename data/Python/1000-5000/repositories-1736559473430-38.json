{
  "metadata": {
    "timestamp": 1736559473430,
    "page": 38,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "charlesq34/pointnet",
      "stars": 4904,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.2021484375,
          "content": "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation.\n\nCopyright (c) 2017, Geometric Computation Group of Stanford University\n\nThe MIT License (MIT)\n\nCopyright (c) 2017 Charles R. Qi\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.96484375,
          "content": "## PointNet: *Deep Learning on Point Sets for 3D Classification and Segmentation*\nCreated by <a href=\"http://charlesrqi.com\" target=\"_blank\">Charles R. Qi</a>, <a href=\"http://ai.stanford.edu/~haosu/\" target=\"_blank\">Hao Su</a>, <a href=\"http://cs.stanford.edu/~kaichun/\" target=\"_blank\">Kaichun Mo</a>, <a href=\"http://geometry.stanford.edu/member/guibas/\" target=\"_blank\">Leonidas J. Guibas</a> from Stanford University.\n\n![prediction example](https://github.com/charlesq34/pointnet/blob/master/doc/teaser.png)\n\n### Introduction\nThis work is based on our [arXiv tech report](https://arxiv.org/abs/1612.00593), which is going to appear in CVPR 2017. We proposed a novel deep net architecture for point clouds (as unordered point sets). You can also check our [project webpage](http://stanford.edu/~rqi/pointnet) for a deeper introduction.\n\nPoint cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input.  Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective.\n\nIn this repository, we release code and data for training a PointNet classification network on point clouds sampled from 3D shapes, as well as for training a part segmentation network on ShapeNet Part dataset.\n\n### Citation\nIf you find our work useful in your research, please consider citing:\n\n\t@article{qi2016pointnet,\n\t  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},\n\t  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},\n\t  journal={arXiv preprint arXiv:1612.00593},\n\t  year={2016}\n\t}\n   \n### Installation\n\nInstall <a href=\"https://www.tensorflow.org/get_started/os_setup\" target=\"_blank\">TensorFlow</a>. You may also need to install h5py. The code has been tested with Python 2.7, TensorFlow 1.0.1, CUDA 8.0 and cuDNN 5.1 on Ubuntu 14.04. \n\nIf you are using PyTorch, you can find a third-party pytorch implementation <a href=\"https://github.com/fxia22/pointnet.pytorch\" target=\"_blank\">here</a>.\n\nTo install h5py for Python:\n```bash\nsudo apt-get install libhdf5-dev\nsudo pip install h5py\n```\n\n### Usage\nTo train a model to classify point clouds sampled from 3D shapes:\n\n    python train.py\n\nLog files and network parameters will be saved to `log` folder in default. Point clouds of <a href=\"http://modelnet.cs.princeton.edu/\" target=\"_blank\">ModelNet40</a> models in HDF5 files will be automatically downloaded (416MB) to the data folder. Each point cloud contains 2048 points uniformly sampled from a shape surface. Each cloud is zero-mean and normalized into an unit sphere. There are also text files in `data/modelnet40_ply_hdf5_2048` specifying the ids of shapes in h5 files.\n\nTo see HELP for the training script:\n\n    python train.py -h\n\nWe can use TensorBoard to view the network architecture and monitor the training progress.\n\n    tensorboard --logdir log\n\nAfter the above training, we can evaluate the model and output some visualizations of the error cases.\n\n    python evaluate.py --visu\n\nPoint clouds that are wrongly classified will be saved to `dump` folder in default. We visualize the point cloud by rendering it into three-view images.\n\nIf you'd like to prepare your own data, you can refer to some helper functions in `utils/data_prep_util.py` for saving and loading HDF5 files.\n\n### Part Segmentation\nTo train a model for object part segmentation, firstly download the data:\n\n    cd part_seg\n    sh download_data.sh\n\nThe downloading script will download <a href=\"http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html\" target=\"_blank\">ShapeNetPart</a> dataset (around 1.08GB) and our prepared HDF5 files (around 346MB).\n\nThen you can run `train.py` and `test.py` in the `part_seg` folder for training and testing (computing mIoU for evaluation).\n\n### License\nOur code is released under MIT License (see LICENSE file for details).\n\n### Selected Projects that Use PointNet\n\n* <a href=\"http://stanford.edu/~rqi/pointnet2/\" target=\"_blank\">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</a> by Qi et al. (NIPS 2017) A hierarchical feature learning framework on point clouds. The PointNet++ architecture applies PointNet recursively on a nested partitioning of the input point set. It also proposes novel layers for point clouds with non-uniform densities.\n* <a href=\"http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w13/Engelmann_Exploring_Spatial_Context_ICCV_2017_paper.pdf\" target=\"_blank\">Exploring Spatial Context for 3D Semantic Segmentation of Point Clouds</a> by Engelmann et al. (ICCV 2017 workshop). This work extends PointNet for large-scale scene segmentation.\n* <a href=\"https://arxiv.org/abs/1710.04954\" target=\"_blank\">PCPNET: Learning Local Shape Properties from Raw Point Clouds</a> by Guerrero et al. (arXiv). The work adapts PointNet for local geometric properties (e.g. normal and curvature) estimation in noisy point clouds.\n* <a href=\"https://arxiv.org/abs/1711.06396\" target=\"_blank\">VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection</a> by Zhou et al. from Apple (arXiv) This work studies 3D object detection using LiDAR point clouds. It splits space into voxels, use PointNet to learn local voxel features and then use 3D CNN for region proposal, object classification and 3D bounding box estimation.\n* <a href=\"https://arxiv.org/abs/1711.08488\" target=\"_blank\">Frustum PointNets for 3D Object Detection from RGB-D Data</a> by Qi et al. (arXiv) A novel framework for 3D object detection with RGB-D data. The method proposed has achieved first place on KITTI 3D object detection benchmark on all categories (last checked on 11/30/2017).\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "evaluate.py",
          "type": "blob",
          "size": 7.02734375,
          "content": "import tensorflow as tf\nimport numpy as np\nimport argparse\nimport socket\nimport importlib\nimport time\nimport os\nimport scipy.misc\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, 'models'))\nsys.path.append(os.path.join(BASE_DIR, 'utils'))\nimport provider\nimport pc_util\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')\nparser.add_argument('--model', default='pointnet_cls', help='Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]')\nparser.add_argument('--batch_size', type=int, default=4, help='Batch Size during training [default: 1]')\nparser.add_argument('--num_point', type=int, default=1024, help='Point Number [256/512/1024/2048] [default: 1024]')\nparser.add_argument('--model_path', default='log/model.ckpt', help='model checkpoint file path [default: log/model.ckpt]')\nparser.add_argument('--dump_dir', default='dump', help='dump folder path [dump]')\nparser.add_argument('--visu', action='store_true', help='Whether to dump image for error case [default: False]')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMODEL_PATH = FLAGS.model_path\nGPU_INDEX = FLAGS.gpu\nMODEL = importlib.import_module(FLAGS.model) # import network module\nDUMP_DIR = FLAGS.dump_dir\nif not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\nLOG_FOUT = open(os.path.join(DUMP_DIR, 'log_evaluate.txt'), 'w')\nLOG_FOUT.write(str(FLAGS)+'\\n')\n\nNUM_CLASSES = 40\nSHAPE_NAMES = [line.rstrip() for line in \\\n    open(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/shape_names.txt'))] \n\nHOSTNAME = socket.gethostname()\n\n# ModelNet40 official train/test split\nTRAIN_FILES = provider.getDataFiles( \\\n    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'))\nTEST_FILES = provider.getDataFiles(\\\n    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'))\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+'\\n')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef evaluate(num_votes):\n    is_training = False\n     \n    with tf.device('/gpu:'+str(GPU_INDEX)):\n        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n        is_training_pl = tf.placeholder(tf.bool, shape=())\n\n        # simple model\n        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n        loss = MODEL.get_loss(pred, labels_pl, end_points)\n        \n        # Add ops to save and restore all the variables.\n        saver = tf.train.Saver()\n        \n    # Create a session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n    config.log_device_placement = True\n    sess = tf.Session(config=config)\n\n    # Restore variables from disk.\n    saver.restore(sess, MODEL_PATH)\n    log_string(\"Model restored.\")\n\n    ops = {'pointclouds_pl': pointclouds_pl,\n           'labels_pl': labels_pl,\n           'is_training_pl': is_training_pl,\n           'pred': pred,\n           'loss': loss}\n\n    eval_one_epoch(sess, ops, num_votes)\n\n   \ndef eval_one_epoch(sess, ops, num_votes=1, topk=1):\n    error_cnt = 0\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    fout = open(os.path.join(DUMP_DIR, 'pred_label.txt'), 'w')\n    for fn in range(len(TEST_FILES)):\n        log_string('----'+str(fn)+'----')\n        current_data, current_label = provider.loadDataFile(TEST_FILES[fn])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_label = np.squeeze(current_label)\n        print(current_data.shape)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        print(file_size)\n        \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n            cur_batch_size = end_idx - start_idx\n            \n            # Aggregating BEG\n            batch_loss_sum = 0 # sum of losses for the batch\n            batch_pred_sum = np.zeros((cur_batch_size, NUM_CLASSES)) # score for classes\n            batch_pred_classes = np.zeros((cur_batch_size, NUM_CLASSES)) # 0/1 for classes\n            for vote_idx in range(num_votes):\n                rotated_data = provider.rotate_point_cloud_by_angle(current_data[start_idx:end_idx, :, :],\n                                                  vote_idx/float(num_votes) * np.pi * 2)\n                feed_dict = {ops['pointclouds_pl']: rotated_data,\n                             ops['labels_pl']: current_label[start_idx:end_idx],\n                             ops['is_training_pl']: is_training}\n                loss_val, pred_val = sess.run([ops['loss'], ops['pred']],\n                                          feed_dict=feed_dict)\n                batch_pred_sum += pred_val\n                batch_pred_val = np.argmax(pred_val, 1)\n                for el_idx in range(cur_batch_size):\n                    batch_pred_classes[el_idx, batch_pred_val[el_idx]] += 1\n                batch_loss_sum += (loss_val * cur_batch_size / float(num_votes))\n            # pred_val_topk = np.argsort(batch_pred_sum, axis=-1)[:,-1*np.array(range(topk))-1]\n            # pred_val = np.argmax(batch_pred_classes, 1)\n            pred_val = np.argmax(batch_pred_sum, 1)\n            # Aggregating END\n            \n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            # correct = np.sum(pred_val_topk[:,0:topk] == label_val)\n            total_correct += correct\n            total_seen += cur_batch_size\n            loss_sum += batch_loss_sum\n\n            for i in range(start_idx, end_idx):\n                l = current_label[i]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx] == l)\n                fout.write('%d, %d\\n' % (pred_val[i-start_idx], l))\n                \n                if pred_val[i-start_idx] != l and FLAGS.visu: # ERROR CASE, DUMP!\n                    img_filename = '%d_label_%s_pred_%s.jpg' % (error_cnt, SHAPE_NAMES[l],\n                                                           SHAPE_NAMES[pred_val[i-start_idx]])\n                    img_filename = os.path.join(DUMP_DIR, img_filename)\n                    output_img = pc_util.point_cloud_three_views(np.squeeze(current_data[i, :, :]))\n                    scipy.misc.imsave(img_filename, output_img)\n                    error_cnt += 1\n                \n    log_string('eval mean loss: %f' % (loss_sum / float(total_seen)))\n    log_string('eval accuracy: %f' % (total_correct / float(total_seen)))\n    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n    \n    class_accuracies = np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float)\n    for i, name in enumerate(SHAPE_NAMES):\n        log_string('%10s:\\t%0.3f' % (name, class_accuracies[i]))\n    \n\n\nif __name__=='__main__':\n    with tf.Graph().as_default():\n        evaluate(num_votes=1)\n    LOG_FOUT.close()\n"
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "part_seg",
          "type": "tree",
          "content": null
        },
        {
          "name": "provider.py",
          "type": "blob",
          "size": 3.533203125,
          "content": "import os\nimport sys\nimport numpy as np\nimport h5py\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\n# Download dataset for point cloud classification\nDATA_DIR = os.path.join(BASE_DIR, 'data')\nif not os.path.exists(DATA_DIR):\n    os.mkdir(DATA_DIR)\nif not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n    www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n    zipfile = os.path.basename(www)\n    os.system('wget %s; unzip %s' % (www, zipfile))\n    os.system('mv %s %s' % (zipfile[:-4], DATA_DIR))\n    os.system('rm %s' % (zipfile))\n\n\ndef shuffle_data(data, labels):\n    \"\"\" Shuffle data and labels.\n        Input:\n          data: B,N,... numpy array\n          label: B,... numpy array\n        Return:\n          shuffled data, label and shuffle indices\n    \"\"\"\n    idx = np.arange(len(labels))\n    np.random.shuffle(idx)\n    return data[idx, ...], labels[idx], idx\n\n\ndef rotate_point_cloud(batch_data):\n    \"\"\" Randomly rotate the point clouds to augument the dataset\n        rotation is per shape based along up direction\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    \"\"\"\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef rotate_point_cloud_by_angle(batch_data, rotation_angle):\n    \"\"\" Rotate the point cloud along up direction with certain angle.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, rotated batch of point clouds\n    \"\"\"\n    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n    for k in range(batch_data.shape[0]):\n        #rotation_angle = np.random.uniform() * 2 * np.pi\n        cosval = np.cos(rotation_angle)\n        sinval = np.sin(rotation_angle)\n        rotation_matrix = np.array([[cosval, 0, sinval],\n                                    [0, 1, 0],\n                                    [-sinval, 0, cosval]])\n        shape_pc = batch_data[k, ...]\n        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n    return rotated_data\n\n\ndef jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n    \"\"\" Randomly jitter points. jittering is per point.\n        Input:\n          BxNx3 array, original batch of point clouds\n        Return:\n          BxNx3 array, jittered batch of point clouds\n    \"\"\"\n    B, N, C = batch_data.shape\n    assert(clip > 0)\n    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1*clip, clip)\n    jittered_data += batch_data\n    return jittered_data\n\ndef getDataFiles(list_filename):\n    return [line.rstrip() for line in open(list_filename)]\n\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    return (data, label)\n\ndef loadDataFile(filename):\n    return load_h5(filename)\n\ndef load_h5_data_label_seg(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    seg = f['pid'][:]\n    return (data, label, seg)\n\n\ndef loadDataFile_with_seg(filename):\n    return load_h5_data_label_seg(filename)\n"
        },
        {
          "name": "sem_seg",
          "type": "tree",
          "content": null
        },
        {
          "name": "train.py",
          "type": "blob",
          "size": 10.671875,
          "content": "import argparse\nimport math\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(BASE_DIR, 'models'))\nsys.path.append(os.path.join(BASE_DIR, 'utils'))\nimport provider\nimport tf_util\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')\nparser.add_argument('--model', default='pointnet_cls', help='Model name: pointnet_cls or pointnet_cls_basic [default: pointnet_cls]')\nparser.add_argument('--log_dir', default='log', help='Log dir [default: log]')\nparser.add_argument('--num_point', type=int, default=1024, help='Point Number [256/512/1024/2048] [default: 1024]')\nparser.add_argument('--max_epoch', type=int, default=250, help='Epoch to run [default: 250]')\nparser.add_argument('--batch_size', type=int, default=32, help='Batch Size during training [default: 32]')\nparser.add_argument('--learning_rate', type=float, default=0.001, help='Initial learning rate [default: 0.001]')\nparser.add_argument('--momentum', type=float, default=0.9, help='Initial learning rate [default: 0.9]')\nparser.add_argument('--optimizer', default='adam', help='adam or momentum [default: adam]')\nparser.add_argument('--decay_step', type=int, default=200000, help='Decay step for lr decay [default: 200000]')\nparser.add_argument('--decay_rate', type=float, default=0.7, help='Decay rate for lr decay [default: 0.8]')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(BASE_DIR, 'models', FLAGS.model+'.py')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system('cp %s %s' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\nLOG_FOUT.write(str(FLAGS)+'\\n')\n\nMAX_NUM_POINT = 2048\nNUM_CLASSES = 40\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\n# ModelNet40 official train/test split\nTRAIN_FILES = provider.getDataFiles( \\\n    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'))\nTEST_FILES = provider.getDataFiles(\\\n    os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'))\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+'\\n')\n    LOG_FOUT.flush()\n    print(out_str)\n\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device('/gpu:'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            print(is_training_pl)\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n            batch = tf.Variable(0)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar('bn_decay', bn_decay)\n\n            # Get model and loss \n            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n            loss = MODEL.get_loss(pred, labels_pl, end_points)\n            tf.summary.scalar('loss', loss)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar('accuracy', accuracy)\n\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar('learning_rate', learning_rate)\n            if OPTIMIZER == 'momentum':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == 'adam':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            train_op = optimizer.minimize(loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n            \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        #merged = tf.merge_all_summaries()\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'),\n                                  sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        # To fix the bug introduced in TF 0.12.1 as in\n        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n        #sess.run(init)\n        sess.run(init, {is_training_pl: True})\n\n        ops = {'pointclouds_pl': pointclouds_pl,\n               'labels_pl': labels_pl,\n               'is_training_pl': is_training_pl,\n               'pred': pred,\n               'loss': loss,\n               'train_op': train_op,\n               'merged': merged,\n               'step': batch}\n\n        for epoch in range(MAX_EPOCH):\n            log_string('**** EPOCH %03d ****' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n            \n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n                log_string(\"Model saved in file: %s\" % save_path)\n\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    is_training = True\n    \n    # Shuffle train files\n    train_file_idxs = np.arange(0, len(TRAIN_FILES))\n    np.random.shuffle(train_file_idxs)\n    \n    for fn in range(len(TRAIN_FILES)):\n        log_string('----' + str(fn) + '-----')\n        current_data, current_label = provider.loadDataFile(TRAIN_FILES[train_file_idxs[fn]])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_data, current_label, _ = provider.shuffle_data(current_data, np.squeeze(current_label))            \n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        total_correct = 0\n        total_seen = 0\n        loss_sum = 0\n       \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n            \n            # Augment batched point clouds by rotation and jittering\n            rotated_data = provider.rotate_point_cloud(current_data[start_idx:end_idx, :, :])\n            jittered_data = provider.jitter_point_cloud(rotated_data)\n            feed_dict = {ops['pointclouds_pl']: jittered_data,\n                         ops['labels_pl']: current_label[start_idx:end_idx],\n                         ops['is_training_pl']: is_training,}\n            summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n                ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n            train_writer.add_summary(summary, step)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += loss_val\n        \n        log_string('mean loss: %f' % (loss_sum / float(num_batches)))\n        log_string('accuracy: %f' % (total_correct / float(total_seen)))\n\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    is_training = False\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    for fn in range(len(TEST_FILES)):\n        log_string('----' + str(fn) + '-----')\n        current_data, current_label = provider.loadDataFile(TEST_FILES[fn])\n        current_data = current_data[:,0:NUM_POINT,:]\n        current_label = np.squeeze(current_label)\n        \n        file_size = current_data.shape[0]\n        num_batches = file_size // BATCH_SIZE\n        \n        for batch_idx in range(num_batches):\n            start_idx = batch_idx * BATCH_SIZE\n            end_idx = (batch_idx+1) * BATCH_SIZE\n\n            feed_dict = {ops['pointclouds_pl']: current_data[start_idx:end_idx, :, :],\n                         ops['labels_pl']: current_label[start_idx:end_idx],\n                         ops['is_training_pl']: is_training}\n            summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n                ops['loss'], ops['pred']], feed_dict=feed_dict)\n            pred_val = np.argmax(pred_val, 1)\n            correct = np.sum(pred_val == current_label[start_idx:end_idx])\n            total_correct += correct\n            total_seen += BATCH_SIZE\n            loss_sum += (loss_val*BATCH_SIZE)\n            for i in range(start_idx, end_idx):\n                l = current_label[i]\n                total_seen_class[l] += 1\n                total_correct_class[l] += (pred_val[i-start_idx] == l)\n            \n    log_string('eval mean loss: %f' % (loss_sum / float(total_seen)))\n    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n         \n\n\nif __name__ == \"__main__\":\n    train()\n    LOG_FOUT.close()\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}