{
  "metadata": {
    "timestamp": 1736559689965,
    "page": 368,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "huawei-noah/Efficient-AI-Backbones",
      "stars": 4114,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.03125,
          "content": ".DS_Store\n.*/__pycache__\n.*pyc\n\n"
        },
        {
          "name": "augvit_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "cmt_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "fig",
          "type": "tree",
          "content": null
        },
        {
          "name": "g_ghost_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "ghostnet_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "ghostnet_tensorflow",
          "type": "tree",
          "content": null
        },
        {
          "name": "ghostnetv2_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "ghostnetv3_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "hubconf.py",
          "type": "blob",
          "size": 2.4677734375,
          "content": "# 2022.09.16-GhostNet & SNN-MLP definition for pytorch hub\n#            Huawei Technologies Co., Ltd. <foss@huawei.com>\ndependencies = ['torch']\nimport torch\nfrom ghostnet_pytorch.ghostnet import ghostnet\nfrom snnmlp_pytorch.models.snn_mlp import SNNMLP\n\n\nstate_dict_url = 'https://github.com/huawei-noah/ghostnet/raw/master/ghostnet_pytorch/models/state_dict_73.98.pth'\nstate_dict_url_snnmlp_t = 'https://github.com/huawei-noah/Efficient-AI-Backbones/releases/download/snnmlp/snnmlp_tiny_81.88.pt'\nstate_dict_url_snnmlp_s = 'https://github.com/huawei-noah/Efficient-AI-Backbones/releases/download/snnmlp/snnmlp_small_83.30.pt'\nstate_dict_url_snnmlp_b = 'https://github.com/huawei-noah/Efficient-AI-Backbones/releases/download/snnmlp/snnmlp_base_83.59.pt'\n\n\ndef ghostnet_1x(pretrained=False, **kwargs):\n\t  \"\"\" # This docstring shows up in hub.help()\n    GhostNet 1.0x model\n    pretrained (bool): kwargs, load pretrained weights into the model\n    \"\"\"\n\t  model = ghostnet(num_classes=1000, width=1.0, dropout=0.2)\n\t  if pretrained:\n\t  \t  state_dict = torch.hub.load_state_dict_from_url(state_dict_url, progress=True)\n\t  \t  model.load_state_dict(state_dict)\n\t  return model\n\ndef snnmlp_t(pretrained=False, **kwargs):\n\t  \"\"\" # This docstring shows up in hub.help()\n    SNN-MLP tiny model\n    pretrained (bool): kwargs, load pretrained weights into the model\n    \"\"\"\n\t  model = SNNMLP(num_classes=1000, embed_dim=96, depths=[2, 2, 6, 2], drop_path_rate=0.2)\n\t  if pretrained:\n\t  \t  state_dict = torch.hub.load_state_dict_from_url(state_dict_url_snnmlp_t, progress=True)\n\t  \t  model.load_state_dict(state_dict)\n\t  return model\n\ndef snnmlp_s(pretrained=False, **kwargs):\n\t  \"\"\" # This docstring shows up in hub.help()\n    SNN-MLP small model\n    pretrained (bool): kwargs, load pretrained weights into the model\n    \"\"\"\n\t  model = SNNMLP(num_classes=1000, embed_dim=96, depths=[2, 2, 18, 2], drop_path_rate=0.3)\n\t  if pretrained:\n\t  \t  state_dict = torch.hub.load_state_dict_from_url(state_dict_url_snnmlp_s, progress=True)\n\t  \t  model.load_state_dict(state_dict)\n\t  return model\n\ndef snnmlp_b(pretrained=False, **kwargs):\n\t  \"\"\" # This docstring shows up in hub.help()\n    SNN-MLP base model\n    pretrained (bool): kwargs, load pretrained weights into the model\n    \"\"\"\n\t  model = SNNMLP(num_classes=1000, embed_dim=128, depths=[2, 2, 18, 2], drop_path_rate=0.5)\n\t  if pretrained:\n\t  \t  state_dict = torch.hub.load_state_dict_from_url(state_dict_url_snnmlp_b, progress=True)\n\t  \t  model.load_state_dict(state_dict)\n\t  return model\n"
        },
        {
          "name": "legonet_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "parameternet_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "readme.md",
          "type": "blob",
          "size": 5.7548828125,
          "content": "# Efficient AI Backbones \r\nincluding GhostNet, TNT (Transformer in Transformer), AugViT, WaveMLP and ViG developed by Huawei Noah's Ark Lab.\r\n- [News](#news)\r\n- [Model zoo](#model-zoo)\r\n\r\n## News\r\n\r\n2024/02/27 The paper of ParameterNet is accepted by [CVPR 2024](https://arxiv.org/abs/2306.14525).\r\n\r\n2022/12/01 The code of NeurIPS 2022 (Spotlight) [GhostNetV2](https://arxiv.org/abs/2211.12905) is released at [./ghostnetv2_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnetv2_pytorch).\r\n\r\n2022/11/13 The code of IJCV 2022 [G-Ghost RegNet](https://arxiv.org/abs/2201.03297) is released at [./g_ghost_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/g_ghost_pytorch). \r\n\r\n2022/06/17 The code of NeurIPS 2022 [Vision GNN (ViG)](https://arxiv.org/abs/2206.00272) is released at [./vig_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/vig_pytorch). \r\n\r\n2022/02/06 Transformer in Transformer (TNT) is selected as the **[Most Influential NeurIPS 2021 Papers](https://www.paperdigest.org/2022/02/most-influential-nips-papers-2022-02/)**.\r\n\r\n2021/09/18 The extended version of [Versatile Filters](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/versatile_filters) is accepted by T-PAMI.\r\n\r\n2021/08/30 GhostNet paper is selected as the **[Most Influential CVPR 2020 Papers](https://www.paperdigest.org/2021/08/most-influential-cvpr-papers-2021-08/)**.\r\n\r\n\r\n## Model zoo\r\n\r\n| Model | Paper | Pytorch code | MindSpore code |\r\n| - | - | - | - |\r\n| GhostNet | GhostNet: More Features from Cheap Operations. [[CVPR 2020]](https://arxiv.org/abs/1911.11907) | [./ghostnet_pytorch](https://github.com/huawei-noah/CV-backbones/tree/master/ghostnet_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet) |\r\n| GhostNetV2 | GhostNetV2: Enhance Cheap Operation with Long-Range Attention. [[NeurIPS 2022 Spotlight]](https://arxiv.org/abs/2211.12905) | [./ghostnetv2_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnetv2_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/ghostnetv2) |\r\n| G-GhostNet | GhostNets on Heterogeneous Devices via Cheap Operations. [[IJCV 2022]](https://arxiv.org/abs/2201.03297) | [./g_ghost_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/g_ghost_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet_d) |\r\n| TinyNet | Model Rubikâ€™s Cube: Twisting Resolution, Depth and Width for TinyNets. [[NeurIPS 2020]](https://arxiv.org/abs/2010.14819) | [./tinynet_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tinynet_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/tinynet) |\r\n| TNT | Transformer in Transformer. [[NeurIPS 2021]](https://arxiv.org/abs/2103.00112) | [./tnt_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tnt_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/TNT) |\r\n| PyramidTNT | PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture. [[CVPR 2022 Workshop]](https://arxiv.org/abs/2201.00978)| [./tnt_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/tnt_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/TNT) |\r\n| CMT | CMT: Convolutional Neural Networks Meet Vision Transformers. [[CVPR 2022]](https://arxiv.org/pdf/2107.06263.pdf) | [./cmt_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/cmt_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/CMT) |\r\n| AugViT | Augmented Shortcuts for Vision Transformers. [[NeurIPS 2021]](https://proceedings.neurips.cc/paper/2021/file/818f4654ed39a1c147d1e51a00ffb4cb-Paper.pdf) | [./augvit_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/augvit_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/augvit) |\r\n| SNN-MLP | Brain-inspired Multilayer Perceptron with Spiking Neurons. [[CVPR 2022]](https://arxiv.org/pdf/2203.14679.pdf) | [./snnmlp_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/snnmlp_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/snn_mlp) |\r\n| WaveMLP | An Image Patch is a Wave: Quantum Inspired Vision MLP. [[CVPR 2022]](https://arxiv.org/pdf/2111.12294.pdf) | [./wavemlp_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/wavemlp_pytorch) | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/wave_mlp) |\r\n| ViG | Vision GNN: An Image is Worth Graph of Nodes. [[NeurIPS 2022]](https://arxiv.org/abs/2206.00272) | [./vig_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/vig_pytorch) | - | [MindSpore Model Zoo](https://gitee.com/mindspore/models/tree/master/research/cv/ViG) |\r\n| LegoNet | LegoNet: Efficient Convolutional Neural Networks with Lego Filters. [[ICML 2019]](http://proceedings.mlr.press/v97/yang19c/yang19c.pdf) | [./legonet_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/legonet_pytorch) | - |\r\n| Versatile Filters | Learning Versatile Filters for Efficient Convolutional Neural Networks. [[NeurIPS 2018]](https://papers.nips.cc/paper/7433-learning-versatile-filters-for-efficient-convolutional-neural-networks) | [./versatile_filters](https://github.com/huawei-noah/CV-backbones/tree/master/versatile_filters) | - |\r\n| ParameterNet | ParameterNet: Parameters Are All You Need. [[CVPR 2024]](https://arxiv.org/abs/2306.14525). | [./parameternet_pytorch](https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/parameternet_pytorch) | - |\r\n\r\n\r\n\r\n"
        },
        {
          "name": "snnmlp_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "tinynet_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "tnt_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "versatile_filters",
          "type": "tree",
          "content": null
        },
        {
          "name": "vig_pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "wavemlp_pytorch",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}