{
  "metadata": {
    "timestamp": 1736559719463,
    "page": 412,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "CLUEbenchmark/CLUE",
      "stars": 4048,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.294921875,
          "content": "*.pkl\n*.npy\n*.log\n*.bin\n*.gz\ntemp\nmodel\nmodel_files\ndata\nlogs\nglue\nprev_trained_model\n.DS_Store\n.ipynb_checkpoints\n.idea\n.idea/CLUE.iml\n.idea/misc.iml\nbaselines/models_pytorch/classifier_pytorch/CLUEdatasets\nbaselines/models_pytorch/classifier_pytorch/*output\nbaselines/models/bert/*output\n__pycache__\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 5.30859375,
          "content": "# Contributing guidelines\n\n[中文版本](https://github.com/CLUEbenchmark/CLUE/tree/master/CONTRIBUTING_ZH.md)\n\n## Pull Request Rules\n\nBefore sending your pull requests, make sure you followed this list.\n\n- Read contributing guidelines.\n- Check if my changes are consistent with the guidelines.\n- Changes are consistent with the [Coding Style].\n- Run Unit Tests.\n\n## How to become a contributor and submit your own code\n\nWelcome any contribution and whatever it is, even just a typo. Please raise your question via issue or email us privately. We take care both the documents and codes equally. So, just do it as long as you follow our rules.\n\n### Where shall I start\n\n----\n\nIf this is your first time to touch CLUE, then we suggest you start from solving issues or our minimal tasks. \n\nIf you are already familiar with this project and you are definitely feel comfortable with NLP related problems, please raise what you want to do via issue or email, and follow the workflow below. \n\nWELCOME!\n\n### **Github WorkFLOW**\n\n---\nWe take branch \"master\" as our main branch, which means it is not wise to develop new feature directly on it. We encourage you to create your own branch and create a PR for your contribution, after you complete it.\n\nHere's the workflow：\n\n1. fort it into you github\n2. clone it into your local machine. \n3. create a new branch and code on it\n4. push you code into YOUR git\n5. create a PR\n\nIf you have huge modification, please make sure there is a coressbonding issue on our main res.\n\n\n```\nDescribe what this PR does / why we need it\nDoes this pull request fix one issue?\nDescribe how you did it\nDescribe how to verify it\nSpecial notes for reviews \n[copied from https://github.com/alibaba/Sentinel/blob/master/.github/PULL_REQUEST_TEMPLATE.md]\n```\nAfter you create you PR, we will assign one or two reviewer for you PR.\n\n\n### Create Issue/PR\n\n---\nWe use Github Issue and Pull Request to manage/track problems.\n\nIf you find any little bug or typo, or you have new ideas about this project, you could create an issue. \n\nIf you want to contribute code, please the workflow above. If you have big modification about this project or you want to reconstruct this project ,PLEASE create an issue or email us (chineseGLUE@163.com) firstly.\n\n\n## Security Problems\n\nIf you find there is any serious bug about security, please contact us via chineseGLUE@163.com privately. PLEASE DO NOT publish any security problem via ANY public way, including issue. Thank you very much.\n\n### Contribution guidelines and standards\n\nBefore sending your pull request for [review](https://github.com/tensorflow/tensorflow/pulls), make sure your changes are consistent with the guidelines and follow the TensorFlow coding style.\n\n#### General guidelines and philosophy for contribution\n\n- Include unit tests when you contribute new features, as they help to a) prove that your code works correctly, and b) guard against future breaking changes to lower the maintenance cost.\n- Bug fixes also generally require unit tests, because the presence of bugs usually indicates insufficient test coverage.\n- Keep API compatibility in mind when you change code. Reviewers of your pull request will comment on any API compatibility issues.\n- When you contribute a new feature to CLUE, the maintenance burden is (by default) transferred to the CLUE team. This means that the benefit of the contribution must be compared against the cost of maintaining the feature.\n- As every PR requires several CPU/GPU hours of CI testing, we discourage submitting PRs to fix one typo, one warning,etc. We recommend fixing the same issue at the file level at least (e.g.: fix all typos in a file, fix all compiler warning in a file, etc.)\n\n### Code review\n\nAll the code will need to be reviewed.\n\n#### License\n\nInclude a license at the top of new files.\n\nPython Liscense:\n\n```\n# Copyright 2020 The CLUE Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================\n```\n\n#### Python coding style\n\nUse `pylint` to check your Python changes. To install `pylint` and check a file with `pylint` against TensorFlow's custom style definition:\n\nWe encourage PEP-8.\n\n```\npip install pylint\npylint myfile.py\n```\n\nNote `pylint ` should run from the top level directory.\n\n#### Running unit tests\n\nWe encourage you to send your PR with your test case. Then, the review process will be quick.\n\n# Community\n\n## Contact\n\n### Email\n\nPlease contact us via [chineseGLUE@163.com](mailto:chineseGLUE@163.com).\n\n### Gitter\n\nGitter room: https://github.com/CLUEbenchmark\n\n\n\nAll the things above, we refer to：[Sentinel]([https://github.com/alibaba/Sentinel/wiki/%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97](https://github.com/alibaba/Sentinel/wiki/开源贡献指南)) and [Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md). Thanks for their wisdom."
        },
        {
          "name": "CONTRIBUTING_ZH.md",
          "type": "blob",
          "size": 6.17578125,
          "content": "# 开源贡献指南\n\n# CLUE 开源贡献指南\n\n欢迎您对CLUE的相关工作感兴趣。本文档作为基本指南来指引您如何向CLUE进行贡献。如果您发现文档中有错误或者又缺失的内容，请及时与我们联系\n\n# 贡献流程\n\n## 行为准则\n\n- 阅读贡献指南（This one）\n- 检查您的修改是否与我们的guidelines一致\n- 您的贡献与我们的代码风格一致\n- 运行单元测试\n\n# 如何贡献\n\n我们随时都欢迎任何贡献，无论是简单的错别字修正，BUG 修复还是增加新功能。请踊跃提出问题或发起 PR。我们同样重视文档以及与其它开源项目的整合，欢迎在这方面做出贡献。\n\n## 从哪里入手？\n\n如果您是初次贡献，可以先从issue或者我们的小任务中开始快速参与社区贡献。\n\n如果您已经对NLP相关的任务很熟悉了，那么欢迎您来与我们一起建设NLP社区。\n\n您可以直接在相应 issue 中回复参与意愿，或者提出您想要做的工作，参照下面的 GitHub 工作流指引解决 issue 并按照规范提交 PR，通过 review 后就会被 merge 到 master 分支。\n\n## GitHub 工作流\n\n我们使用 `master` 分支作为我们的主，最好不要在上面直接开发。每个版本区间（如 0.1.x）都会创建一个 release 分支（如 `release-0.1`）作为稳定的发布分支。每发布一个新版本都会将其合并到对应的 release 分支并打上对应的 tag。\n\n下面是开源贡献者常用的工作流（workflow）：\n\n1. 将仓库 fork 到自己的 GitHub 下\n2. 将 fork 后的仓库 clone 到本地\n3. 创建新的分支，在新的分支上进行开发操作（**通常情况下，请确保对应的变更都有测试用例或 demo 进行验证**）\n4. 保持分支与远程 master 分支一致（通过 `fetch` 和 `rebase` 操作）\n5. 在本地提交变更（**注意 commit log 保持简练、规范**），**注意提交的 email 需要和 GitHub 的 email 保持一致**\n6. 将提交 push 到 fork 的仓库下\n7. 创建一个 pull request (PR)\n\n提交 PR 的时候请参考。在进行较大的变更的时候请确保 PR 有一个对应的 Issue。\n\n```\nDescribe what this PR does / why we need it\nDoes this pull request fix one issue?\nDescribe how you did it\nDescribe how to verify it\nSpecial notes for reviews \n[copied from https://github.com/alibaba/Sentinel/blob/master/.github/PULL_REQUEST_TEMPLATE.md]\n```\n\n在提交 PR 后，系统会自动运行持续集成，请确保所有的 CI 均为 pass 状态。一切就绪后，我们会为 PR 分配一个或多个 reviewer。Reviewer 会对提交的代码进行 review。\n\n在合并 PR 的时候，请把多余的提交记录都 squash 成一个。最终的提交信息需要保证简练、规范。\n\n## 创建 Issue / PR\n\n我们使用 GitHub Issues 以及 Pull Requests 来管理/追踪问题。\n\n如果您发现了文档中有表述错误，或者代码发现了 BUG，或者希望开发新的特性，或者希望提建议，可以创建一个 Issue。请参考 Issue 模板中对应的指导信息来完善 Issue 的内容，来帮助我们更好地理解您的 Issue。\n\n如果您想要贡献代码，您可以参考上面的 [GitHub 工作流]，提交对应的 PR。若是对当前开发版本进行提交，则目标分支为 `master`。如果您的 PR 包含非常大的变更，比如模块的重构或者添加新的组件，请**务必先提出相关 issue，发起详细讨论，达成一致后再进行变更**，并为其编写详细的文档来阐述其设计、解决的问题和用途。注意一个 PR 尽量不要过于大。如果的确需要有大的变更，可以将其按功能拆分成多个单独的 PR。\n\n## 报告安全问题\n\n特别地，若您发现 CLUE 及其生态项目中有任何的安全漏洞（或潜在的安全问题），请第一时间通过邮箱[chineseGLUE@163.com私下联系我们。在对应代码修复之前，**请不要将对应安全问题对外披露，也不鼓励公开提 issue 报告安全问题**。\n\n## Contribution guidelines and standards\n\n在你提交你的PR之前，麻烦请确定你的改变符合我们的规范\n\n#### General guidelines and philosophy for contribution\n\n- 如果你贡献了一个新的特性，请尽量包含你的单元测试以保证你的代码可以使用，并且降低未来的维护成本。\n- 修复了bug也需要写单元测试\n- 请维持API的兼容性\n- 当您为CLUE贡献一个新特性时，维护责任(默认情况下)会转移到CLUE团队。这意味着必须将贡献的收益与维护特性的成本进行trade off。\n- \n- 由于每个PR都需要几个CPU/GPU小时的CI测试，我们不鼓励提交PRs来修复一个错误，一个警告等等。我们建议至少在文件级别修复相同的问题(例如:修复文件中的所有拼写错误，修复文件中的所有编译器警告，等等)。如果有小的错误，可以通过issue来提出。感谢配合。\n\n### Code review\n\n所有的代码都需要经过 committer 进行 review。以下是我们推荐的一些原则：\n\n- 可读性：代码遵循我们的开发规约，重要代码需要有详细注释和文档\n- 优雅性：代码简练、复用度高，有着完善的设计\n- 测试：重要的代码需要有完善的测试用例（单元测试、集成测试），对应的衡量标准是测试覆盖率\n\n#### Python coding style\n\nUse `pylint` to check your Python changes. To install `pylint` and check a file with `pylint` against TensorFlow's custom style definition:\n\nWe encourage PEP-8.\n\n```\npip install pylint\npylint myfile.py\n```\n\nNote `pylint ` should run from the top level directory.\n\n#### Running unit tests\n\nWe encourage you to send your PR with your test case. Then, the review process will be quick.\n\n# 社区\n\n## 联系我们\n\n### 邮件组\n\n如果您有任何问题与建议，请通过邮箱[chineseGLUE@163.com](mailto:chineseGLUE@163.com)联系我们。\n\n### Gitter\n\n我们的 Gitter room: https://github.com/CLUEbenchmark\n\n\n\n以上贡献者模版参考自：[Sentinel]([https://github.com/alibaba/Sentinel/wiki/%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97](https://github.com/alibaba/Sentinel/wiki/开源贡献指南)) and [Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md)。感谢他们的智慧。\n\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 49.7578125,
          "content": "# CLUE benchmark \ndatasets, baselines, pre-trained models, corpus and leaderboard\n\n中文语言理解测评基准，包括代表性的数据集、基准(预训练)模型、语料库、排行榜。  \n\n我们会选择一系列有一定代表性的任务对应的数据集，做为我们测试基准的数据集。这些数据集会覆盖不同的任务、数据量、任务难度。\n\nUpdate:\n\n<a href='https://www.langyb.com'>【琅琊榜】-中文大模型专用竞技场，你关心的领先模型都在这里</a>\n\n<a href='https://www.SuperCLUEAI.com'>中文大模型最新榜单</a>\n\n<a href=\"https://github.com/CLUEbenchmark/SuperCLUE\">SuperCLUE: 中文通用大模型综合性测评基准</a>\n\n优秀的国产深度学习框架PaddlePaddle中的NLP核心项目：<a href=\"https://github.com/CLUEbenchmark/CLUE/tree/master/baselines/paddlenlp\" target=\"_\" style=\"color:red\">PaddleNLP现以全面支持CLUE基准</a>\n\n<a href='https://mp.weixin.qq.com/s/LtkKuKdpg8Lg3XCEMWpaMw'> CLUE论文被计算语言学国际会议 COLING2020高分录用</a>\n\n中文任务测评基准(CLUE benchmark)-排行榜 Leaderboard\n---------------------------------------------------------------------\n#####  排行榜会定期更新           数据来源: www.CLUEbenchmarks.com                <a href='https://arxiv.org/abs/2004.05986'>论文</a>\n\n#### 分类任务(v1版本,正式版)\n\n| 模型   | Score  | 参数    | AFQMC  | TNEWS'  | IFLYTEK'   | CMNLI   | CLUEWSC2020 | CSL  |\n| :----:| :----: | :----: | :----: |:----: |:----: |:----: |:----: |:----: |\n| <a href=\"https://github.com/google-research/bert\">BERT-base</a>        | 68.77 | 108M |  73.70 | 56.58  | 60.29 | 79.69 |  62.0 | 80.36 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">BERT-wwm-ext</a>      | 68.75 | 108M  | 74.07 | 56.84  | 59.43 | 80.42 | 61.1  | 80.63 |\n| <a href=\"https://github.com/PaddlePaddle/ERNIE\">ERNIE-base</a>         | 68.55 | 108M  | 73.83 | 58.33 | 58.96 | 80.29 | 60.8  | 79.1 |\n| <a href=\"https://github.com/brightmart/roberta_zh\">RoBERTa-large</a>      | 71.70 | 334M  | 74.02 | 57.86 | 62.55 | 81.70 | 72.7  | 81.36 |\n| <a href=\"https://github.com/ymcui/Chinese-PreTrained-XLNet\">XLNet-mid</a>  | 68.58 | 200M | 70.50 | 56.24 | 57.85 | 81.25 |  64.4   | 81.26  |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-xxlarge</a>      | 71.04 | 235M   | 75.6 | **59.46** | 62.89 | **83.14** |  61.54  | **83.63**  |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-xlarge</a>      | 68.92 | 60M   | 69.96 | 57.36 | 59.50 | 81.13 |  64.34   | 81.20  |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-large</a>      | 67.91 | 18M   | 74  | 55.16 | 57.00 | 78.77 |  62.24   | 80.30  |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-base</a>      | 67.44 | 12M   | 72.55  | 55.06 | 56.58 | 77.58 |  64.34   | 78.5  |\n| <a href=\"https://github.com/brightmart/albert_zh\">ALBERT-tiny</a>        | 62.61 | **4M** | 69.92 | 53.35 | 48.71 | 70.61 |  58.5  | 74.56 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">RoBERTa-wwm-ext</a>   | 70.10 | 108M  | 74.04 | 56.94 | 60.31 | 80.51 | 67.8 | 81.0 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">RoBERTa-wwm-large</a> | **72.83** | 330M | **76.55** | 58.61 | **62.98** | 82.12 |  **74.6** | 82.13 |\n\n\n    注：AFQMC:蚂蚁语义相似度(Acc)；TNEWS:文本分类(Acc)；IFLYTEK:长文本分类(Acc); CMNLI: 自然语言推理中文版; \n       COPA: 因果推断; WSC:CLUEWSC2020,即Winograd模式挑战中文版; CSL: 中国科学文献数据集; Score总分是通过计算6个数据集得分平均值获得；\n      '代表对原数据集使用albert_tiny模型筛选后获得，数据集与原数据集不同,从而可能导致在这些数据集上albert_tiny表现略低.\n\n#### 阅读理解任务\n\n| 模型 | Score | 参数 | CMRC2018 | CHID | C<sup>3</sup> |\n| :----:| :----: | :----: | :----: |:----: |:----: |\n| <a href=\"https://github.com/google-research/bert\">BERT-base</a>\t| 72.71 | 108M | 71.60 | 82.04 | 64.50 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">BERT-wwm-ext</a> | 75.12 | 108M | 73.95 | 82.90 | 68.50 |\n| <a href=\"https://github.com/PaddlePaddle/ERNIE\">ERNIE-base</a>\t| 73.69 | 108M | 74.7 | 82.28 | 64.10 |\n| <a href=\"https://github.com/brightmart/roberta_zh\">RoBERTa-large</a> | 76.85 | 334M | ***78.50*** | 84.50 | 67.55 |\n| <a href=\"https://github.com/ymcui/Chinese-PreTrained-XLNet\">XLNet-mid</a>\t| 72.70 | 209M | 66.95 | 83.47 | 67.68 |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-base</a> | 68.08 | 10M | 72.90 | 71.77 | 59.58 |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-large</a> | 71.51 | 16.5M | 75.95 | 74.18 | 64.41 |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-xlarge</a> | 75.73 | 57.5M | 76.30 | 80.57 | 70.32 |\n| <a href=\"https://github.com/google-research/albert\">ALBERT-xxlarge</a> | 77.19 | 221M | 75.15 | 83.15 | 73.28 |\n| <a href=\"https://github.com/brightmart/albert_zh\">ALBERT-tiny</a> | 49.05 | 1.8M | 53.35 | 43.53 | 50.26 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">RoBERTa-wwm-ext</a>  | 75.11 | 108M | 75.20 | 83.62 | 66.50 |\n| <a href=\"https://github.com/ymcui/Chinese-BERT-wwm\">RoBERTa-wwm-large</a> | ***79.05*** | 330M | 77.95 | ***85.37*** | ***73.82*** |\n\nDRCD、CMRC2018: 繁体、简体抽取式阅读理解(F1, EM)；CHID: 成语多分类阅读理解(Acc)；C<sup>3</sup>: 多选中文阅读理解(Acc)；Score总分是通过计算3个数据集得分平均值获得。\n\n注：阅读理解上述指标中F1和EM共存的情况下，取EM为最终指标。CMRC2018结果为CLUE专用独立测试集。\n\n一键运行.基线模型与代码 Baseline with codes\n---------------------------------------------------------------------\n    使用方式：\n    1、克隆项目 \n       git clone https://github.com/CLUEbenchmark/CLUE.git\n    2、进入到相应的目录\n       分类任务  \n           例如：\n           cd CLUE/baselines/models/bert\n           cd CLUE/baselines/models_pytorch/classifier_pytorch\n       或阅读理解任务：\n           cd CLUE/baselines/models_pytorch/mrc_pytorch\n    3、运行对应任务的脚本(GPU方式): 会自动下载模型和任务数据并开始运行。\n       bash run_classifier_xxx.sh\n       如运行 bash run_classifier_iflytek.sh 会开始iflytek任务的训练  \n    4、tpu使用方式(可选)  \n        cd CLUE/baselines/models/bert/tpu  \n        bash run_classifier_tnews.sh即可测试tnews任务（注意更换里面的gs路径和tpu ip）。数据和模型会自动下载和上传。\n        \n        cd CLUE/baselines/models/roberta/tpu  \n        bash run_classifier_tiny.sh即可运行所有分类任务（注意更换里面的路径,模型地址和tpu ip）  \n\n### 生成提交文件\n\n    分类任务: \n        在CLUE/baselines/models/bert目录下执行\n        bash run_classifier_xxx.sh predict \n        即可在output_dir下得到相应的提交文件json格式结果xxx_prdict.json\n\n   或见<a href=\"https://github.com/CLUEbenchmark/CLUE/blob/master/baselines/models/bert/run_classifier.py#L932-L951\">代码实现</a>\n\n    阅读理解任务:\n         在CLUE/baselines/models_pytorch/mrc_pytorch目录下执行\n         test_mrc.py\n         具体参数和使用方法可见对应的run_mrc_xxx.sh\n    ​    \n <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/clue_submit_examples.zip\">提交样例下载</a>\n \n \n### 运行环境\ntensorflow 1.12 /cuda 9.0 /cudnn7.0\n### 工具包 Toolkit\n\n运行方式：\n\n    pip install PyCLUE \n    cd PyCLUE/examples/classifications\n    python3 run_clue_task.py\n\n支持10个任务、9大模型、自定义任务，见 <a href=\"https://github.com/CLUEbenchmark/PyCLUE\">PyCLUE toolkit</a>\n\n测评系统 Leaderboard\n---------------------------------------------------------------------\n测评入口：<a href=\"http://www.CLUEbenchmarks.com\">我要提交</a>\n<img src=\"https://github.com/CLUEbenchmark/CLUE/blob/master/resources/img/CLUEbenchmark.jpg\"  width=\"90%\" height=\"45%\" />\n\n语料库(CLUECorpus2020)：语言建模、预训练或生成型任务\n---------------------------------------------------------------------\nCorpus for Langauge Modelling, Pre-training, Generating tasks\n\n可用于语言建模、预训练或生成型任务等，数据量超过14G，近4000个定义良好的txt文件、50亿个字。主要部分来自于<a href=\"https://github.com/brightmart/nlp_chinese_corpus\">nlp_chinese_corpus项目</a>\n\n当前语料库按照【预训练格式】处理，内含有多个文件夹；每个文件夹有许多不超过4M大小的小文件，文件格式符合预训练格式：每句话一行，文档间空行隔开。\n\n包含如下子语料库（总共14G语料）：\n\n1、<a href=\"https://pan.baidu.com/s/1MLLM-CdM6BhJkj8D0u3atA\">新闻语料 news2016zh_corpus</a>: 8G语料，分成两个上下两部分，总共有2000个小文件。 \n\n2、<a href=\"https://drive.google.com/open?id=1u2yW_XohbYL2YAK6Bzc5XrngHstQTf0v\">社区互动-语料 webText2019zh_corpus</a>：3G语料，包含3G文本，总共有900多个小文件。\n\n3、<a href=\"https://pan.baidu.com/s/1uPMlIY3vhusdnhAge318TA\">维基百科-语料 wiki2019zh_corpus</a>：1.1G左右文本，包含300左右小文件。  \n\n4、<a href=\"https://pan.baidu.com/s/18-ufaJJtf7ullzHMWXvhFw\">评论数据-语料 comments2019zh_corpus</a>：2.3G左右文本，共784个小文件，包括点评评论547个、亚马逊评论227个，合并<a href=\"https://github.com/InsaneLife/ChineseNLPCorpus\">ChineseNLPCorpus</a>的多个评论数据，清洗、格式转换、拆分成小文件。  \n\n这些语料，你可以通过上面这两个项目，清洗数据并做格式转换获得；\n\n你也可以通过邮件申请（chineseGLUE#163.com）获得单个项目的语料，告知单位或学校、姓名、语料用途；\n\n如需获得ChineseGLUE项目下的所有语料，需成为ChineseGLUE组织成员，并完成一个（小）任务。\n\n\nCLUE benchmark的定位 Vision\n---------------------------------------------------------------------\n为更好的服务中文语言理解、任务和产业界，做为通用语言模型测评的补充，通过完善中文语言理解基础设施的方式来促进中文语言模型的发展\n\n\n数据集介绍与下载 Introduction of datasets \n--------------------------------------------------------------------\n\n <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/clue_submit_examples.zip\">提交样例下载</a>\n\n##### 1. AFQMC 蚂蚁金融语义相似度 Ant Financial  Question Matching Corpus\n```\n     数据量：训练集（34334）验证集（4316）测试集（3861）\n     例子：\n     {\"sentence1\": \"双十一花呗提额在哪\", \"sentence2\": \"里可以提花呗额度\", \"label\": \"0\"}\n     每一条数据有三个属性，从前往后分别是 句子1，句子2，句子相似度标签。其中label标签，1 表示sentence1和sentence2的含义类似，0表示两个句子的含义不同。\n```\n  <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/afqmc_public.zip\" > AFQMC'数据集下载</a>\n\n##### 2.TNEWS' 今日头条中文新闻（短文本）分类 Short Text Classificaiton for News\n该数据集来自今日头条的新闻版块，共提取了15个类别的新闻，包括旅游，教育，金融，军事等。\n```\n     数据量：训练集(53,360)，验证集(10,000)，测试集(10,000)\n     例子：\n     {\"label\": \"102\", \"label_des\": \"news_entertainment\", \"sentence\": \"江疏影甜甜圈自拍，迷之角度竟这么好看，美吸引一切事物\"}\n     每一条数据有三个属性，从前往后分别是 分类ID，分类名称，新闻字符串（仅含标题）。\n```\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/tnews_public.zip\" > TNEWS'数据集下载</a>\n           \n##### 3.IFLYTEK' 长文本分类 Long Text classification\n该数据集共有1.7万多条关于app应用描述的长文本标注数据，包含和日常生活相关的各类应用主题，共119个类别：\"打车\":0,\"地图导航\":1,\"免费WIFI\":2,\"租车\":3,….,\"女性\":115,\"经营\":116,\"收款\":117,\"其他\":118(分别用0-118表示)。\n```\n    数据量：训练集(12,133)，验证集(2,599)，测试集(2,600)\n    例子：\n    {\"label\": \"110\", \"label_des\": \"社区超市\", \"sentence\": \"朴朴快送超市创立于2016年，专注于打造移动端30分钟即时配送一站式购物平台，商品品类包含水果、蔬菜、肉禽蛋奶、海鲜水产、粮油调味、酒水饮料、休闲食品、日用品、外卖等。朴朴公司希望能以全新的商业模式，更高效快捷的仓储配送模式，致力于成为更快、更好、更多、更省的在线零售平台，带给消费者更好的消费体验，同时推动中国食品安全进程，成为一家让社会尊敬的互联网公司。,朴朴一下，又好又快,1.配送时间提示更加清晰友好2.保障用户隐私的一些优化3.其他提高使用体验的调整4.修复了一些已知bug\"}\n    每一条数据有三个属性，从前往后分别是 类别ID，类别名称，文本内容。\n```\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/iflytek_public.zip\" > IFLYTEK'数据集下载</a>\n\n##### 4.<a href='https://github.com/cluebenchmark/OCNLI'>OCNLI 中文原版自然语言推理</a> Original Chinese Natural Language Inference\nOCNLI，即原生中文自然语言推理数据集，是第一个非翻译的、使用原生汉语的大型中文自然语言推理数据集。\n\n```\n   数据量：train: 50k， dev(3k), test(3k) \n    例子：\n     {\n\t\"level\": \"medium\",\n\t\"sentence1\": \"身上裹一件工厂发的棉大衣,手插在袖筒里\",\n\t\"sentence2\": \"身上至少一件衣服\",\n\t\"label\": \"entailment\",\n\t\"genre\": \"lit\",\n\t\"prem_id\": \"lit_635\",\n\t\"id\": 0\n} {\n\t\"level\": \"easy\",\n\t\"sentence1\": \"东、中、西部地区要加强多种形式的合作,在协调发展中逐步实现共同富裕\",\n\t\"sentence2\": \"东、中、西部地区发展存在不协调\",\n\t\"label\": \"entailment\",\n\t\"genre\": \"gov\",\n\t\"prem_id\": \"gov_1260\",\n\t\"id\": 1\n} {\n\t\"level\": \"hard\",\n\t\"sentence1\": \"外贸经营权进一步放开\",\n\t\"sentence2\": \"外贸经营权经历了先收缩再放开的过程。\",\n\t\"label\": \"neutral\",\n\t\"genre\": \"gov\",\n\t\"prem_id\": \"gov_755\",\n\t\"id\": 2\n} \n\n```\n<a href=\"https://storage.googleapis.com/cluebenchmark/tasks/ocnli_public.zip\" > OCNLI数据集下载</a>\n\n\n##### --4.CMNLI 语言推理任务 Chinese Multi-Genre NLI (该任务在排行榜中被中文原版OCNLI替代)\n\nCMNLI数据由两部分组成：XNLI和MNLI。数据来自于fiction，telephone，travel，government，slate等，对原始MNLI数据和XNLI数据进行了中英文转化，保留原始训练集，合并XNLI中的dev和MNLI中的matched作为CMNLI的dev，合并XNLI中的test和MNLI中的mismatched作为CMNLI的test，并打乱顺序。该数据集可用于判断给定的两个句子之间属于蕴涵、中立、矛盾关系。\n\n```\n    数据量：train(391,782)，dev(12,426)，test(13,880)\n    例子：\n    {\"sentence1\": \"新的权利已经足够好了\", \"sentence2\": \"每个人都很喜欢最新的福利\", \"label\": \"neutral\"}\n    每一条数据有三个属性，从前往后分别是 句子1，句子2，蕴含关系标签。其中label标签有三种：neutral，entailment，contradiction。\n```\n<a href=\"https://storage.googleapis.com/cluebenchmark/tasks/cmnli_public.zip\" > CMNLI数据集下载</a>\n\n\n\n##### 5. CLUEWSC2020: WSC Winograd模式挑战中文版，新版2020-03-25发布  \n\n<a href=\"https://github.com/CLUEbenchmark/CLUEWSC2020\">git项目地址</a>\n\nWinograd Scheme Challenge（WSC）是一类代词消歧的任务。新版与原CLUE项目WSC内容不同\n\n即判断句子中的代词指代的是哪个名词。题目以真假判别的方式出现，如：\n\n句子：这时候放在床上枕头旁边的手机响了，我感到奇怪，因为欠费已被停机两个月，现在它突然响了。需要判断“它”指代的是“床”、“枕头”，还是“手机”？\n\n数据来源：数据有CLUE benchmark提供，从中国现当代作家文学作品中抽取，再经语言专家人工挑选、标注。\n\n数据形式：\n\n     {\"target\": \n         {\"span2_index\": 37, \n         \"span1_index\": 5, \n         \"span1_text\": \"床\", \n         \"span2_text\": \"它\"}, \n     \"idx\": 261, \n     \"label\": \"false\", \n     \"text\": \"这时候放在床上枕头旁边的手机响了，我感到奇怪，因为欠费已被停机两个月，现在它突然响了。\"}\n     \"true\"表示代词确实是指代span1_text中的名词的，\"false\"代表不是。\n\n数据集大小：\n- 训练集：1244\n- 开发集：304\n\n  <a href='https://storage.googleapis.com/cluebenchmark/tasks/cluewsc2020_public.zip'>CLUEWSC2020数据集下载</a>\n\n\n##### 6. CSL 论文关键词识别 Keyword Recognition\n[中文科技文献数据集(CSL)](https://github.com/P01son6415/chinese-scientific-literature-dataset)取自中文论文摘要及其关键词，论文选自部分中文社会科学和自然科学核心期刊。\n使用tf-idf生成伪造关键词与论文真实关键词混合，构造摘要-关键词对，任务目标是根据摘要判断关键词是否全部为真实关键词。\n```\n    数据量：训练集(20,000)，验证集(3,000)，测试集(3,000)\n    例子： \n    {\"id\": 1, \"abst\": \"为解决传统均匀FFT波束形成算法引起的3维声呐成像分辨率降低的问题,该文提出分区域FFT波束形成算法.远场条件下,以保证成像分辨率为约束条件,以划分数量最少为目标,采用遗传算法作为优化手段将成像区域划分为多个区域.在每个区域内选取一个波束方向,获得每一个接收阵元收到该方向回波时的解调输出,以此为原始数据在该区域内进行传统均匀FFT波束形成.对FFT计算过程进行优化,降低新算法的计算量,使其满足3维成像声呐实时性的要求.仿真与实验结果表明,采用分区域FFT波束形成算法的成像分辨率较传统均匀FFT波束形成算法有显著提高,且满足实时性要求.\", \"keyword\": [\"水声学\", \"FFT\", \"波束形成\", \"3维成像声呐\"], \"label\": \"1\"}\n    每一条数据有四个属性，从前往后分别是 数据ID，论文摘要，关键词，真假标签。\n    \n```\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/csl_public.zip\" > CSL数据集下载</a>\n\n##### 7.CMRC2018 简体中文阅读理解任务 Reading Comprehension for Simplified Chinese\nhttps://hfl-rc.github.io/cmrc2018/\n```\n数据量：训练集(短文数2,403，问题数10,142)，试验集(短文数256，问题数1,002)，开发集(短文数848，问题数3,219)  \n例子：\n{\n  \"version\": \"1.0\",\n  \"data\": [\n    {\n        \"title\": \"傻钱策略\",\n        \"context_id\": \"TRIAL_0\",\n        \"context_text\": \"工商协进会报告，12月消费者信心上升到78.1，明显高于11月的72。另据《华尔街日报》报道，2013年是1995年以来美国股市表现最好的一年。这一年里，投资美国股市的明智做法是追着“傻钱”跑。所谓的“傻钱”策略，其实就是买入并持有美国股票这样的普通组合。这个策略要比对冲基金和其它专业投资者使用的更为复杂的投资方法效果好得多。\",\n        \"qas\":[\n                {\n                \"query_id\": \"TRIAL_0_QUERY_0\",\n                \"query_text\": \"什么是傻钱策略？\",\n                \"answers\": [\n                     \"所谓的“傻钱”策略，其实就是买入并持有美国股票这样的普通组合\",\n                     \"其实就是买入并持有美国股票这样的普通组合\",\n                     \"买入并持有美国股票这样的普通组合\"\n                    ]\n                },\n                {\n                \"query_id\": \"TRIAL_0_QUERY_1\",\n                \"query_text\": \"12月的消费者信心指数是多少？\",\n                \"answers\": [\n                    \"78.1\",\n                    \"78.1\",\n                    \"78.1\"\n                    ]\n                },\n                {\n                \"query_id\": \"TRIAL_0_QUERY_2\",\n                \"query_text\": \"消费者信心指数由什么机构发布？\",\n                \"answers\": [\n                    \"工商协进会\",\n                    \"工商协进会\",\n                    \"工商协进会\"\n                    ]\n                }\n            ]\n        }\n    ]\n}\n```\n\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/cmrc2018_public.zip\" > CMRC2018数据集下载</a>\n\n\n##### 8.DRCD 繁体阅读理解任务 Reading Comprehension for Traditional Chinese\n台達閱讀理解資料集 Delta Reading Comprehension Dataset (DRCD)(https://github.com/DRCKnowledgeTeam/DRCD) 屬於通用領域繁體中文機器閱讀理解資料集。 本資料集期望成為適用於遷移學習之標準中文閱讀理解資料集。  \n```\n数据量：训练集(8,016个段落，26,936个问题)，验证集(1,000个段落，3,524个问题)，测试集(1,000个段落，3,493个问题)  \n例子：\n{\n  \"version\": \"1.3\",\n  \"data\": [\n    {\n      \"title\": \"基督新教\",\n      \"id\": \"2128\",\n      \"paragraphs\": [\n        {\n          \"context\": \"基督新教與天主教均繼承普世教會歷史上許多傳統教義，如三位一體、聖經作為上帝的啟示、原罪、認罪、最後審判等等，但有別於天主教和東正教，新教在行政上沒有單一組織架構或領導，而且在教義上強調因信稱義、信徒皆祭司， 以聖經作為最高權威，亦因此否定以教宗為首的聖統制、拒絕天主教教條中關於聖傳與聖經具同等地位的教導。新教各宗派間教義不盡相同，但一致認同五個唯獨：唯獨恩典：人的靈魂得拯救唯獨是神的恩典，是上帝送給人的禮物。唯獨信心：人唯獨藉信心接受神的赦罪、拯救。唯獨基督：作為人類的代罪羔羊，耶穌基督是人與上帝之間唯一的調解者。唯獨聖經：唯有聖經是信仰的終極權威。唯獨上帝的榮耀：唯獨上帝配得讚美、榮耀\",\n          \"id\": \"2128-2\",\n          \"qas\": [\n            {\n              \"id\": \"2128-2-1\",\n              \"question\": \"新教在教義上強調信徒皆祭司以及什麼樣的理念?\",\n              \"answers\": [\n                {\n                  \"id\": \"1\",\n                  \"text\": \"因信稱義\",\n                  \"answer_start\": 92\n                }\n              ]\n            },\n            {\n              \"id\": \"2128-2-2\",\n              \"question\": \"哪本經典為新教的最高權威?\",\n              \"answers\": [\n                {\n                  \"id\": \"1\",\n                  \"text\": \"聖經\",\n                  \"answer_start\": 105\n                }\n              ]\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n```\n数据格式和squad相同，如果使用简体中文模型进行评测的时候可以将其繁转简(本项目已提供)\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/drcd_public.zip\" > DRCD2018数据集下载</a>\n\n##### 9.ChID 成语阅读理解填空 Chinese IDiom Dataset for Cloze Test\nhttps://arxiv.org/abs/1906.01265  \n成语完形填空，文中多处成语被mask，候选项中包含了近义的成语。\n```\n    数据量：训练集(84,709)，验证集(3,218)，测试集(3,231)\n    例子：\n    {\n      \"content\": [\n        # 文段0\n        \"……在热火22年的历史中，他们已经100次让对手得分在80以下，他们在这100次中都取得了胜利，今天他们希望能#idiom000378#再进一步。\", \n        # 文段1\n        \"在轻舟发展过程之中，是和业内众多企业那样走相似的发展模式，去#idiom000379#？还是迎难而上，另走一条与众不同之路。诚然，#idiom000380#远比随大流更辛苦，更磨难，更充满风险。但是有一条道理却是显而易见的：那就是水往低处流，随波逐流，永远都只会越走越低。只有创新，只有发展科技，才能强大自己。\", \n        # 文段2\n        \"最近十年间，虚拟货币的发展可谓#idiom000381#。美国著名经济学家林顿·拉鲁什曾预言：到2050年，基于网络的虚拟货币将在某种程度上得到官方承认，成为能够流通的货币。现在看来，这一断言似乎还嫌过于保守……\", \n        # 文段3\n        \"“平时很少能看到这么多老照片，这次图片展把新旧照片对比展示，令人印象深刻。”现场一位参观者对笔者表示，大多数生活在北京的人都能感受到这个城市#idiom000382#的变化，但很少有人能具体说出这些变化，这次的图片展按照区域发展划分，展示了丰富的信息，让人形象感受到了60年来北京的变化和发展。\", \n        # 文段4\n        \"从今天大盘的走势看，市场的热点在反复的炒作之中，概念股的炒作#idiom000383#，权重股走势较为稳健，大盘今日早盘的震荡可以看作是多头关前的蓄势行为。对于后市，大盘今日蓄势震荡后，明日将会在权重和题材股的带领下亮剑冲关。再创反弹新高无悬念。\", \n        # 文段5\n        \"……其中，更有某纸媒借尤小刚之口指出“根据广电总局的这项要求，2009年的荧屏将很难出现#idiom000384#的情况，很多已经制作好的非主旋律题材电视剧想在卫视的黄金时段播出，只能等到2010年了……\"],\n      \"candidates\": [\n        \"百尺竿头\", \n        \"随波逐流\", \n        \"方兴未艾\", \n        \"身体力行\", \n        \"一日千里\", \n        \"三十而立\", \n        \"逆水行舟\", \n        \"日新月异\", \n        \"百花齐放\", \n        \"沧海一粟\"\n      ]\n    }\n```\n\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/chid_public.zip\" > CHID数据集下载</a>\n   \n##### 10.C<sup>3</sup> 中文多选阅读理解 Multiple-Choice Chinese Machine Reading Comprehension  \nhttps://arxiv.org/abs/1904.09679  \n中文多选阅读理解数据集，包含对话和长文等混合类型数据集。训练和验证集中的d,m分别代表对话、多种文本类型混合。  \n```\n    数据量：训练集(11,869)，验证集(3,816)，测试集(3,892)\n    例子：\n    [\n      [\n        \"男：你今天晚上有时间吗?我们一起去看电影吧?\",\n        \"女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……\"\n      ],\n      [\n       {\n        \"question\": \"女的最喜欢哪种电影?\",\n        \"choice\": [\n         \"恐怖片\",\n         \"爱情片\",\n         \"喜剧片\",\n         \"科幻片\"\n        ],\n        \"answer\": \"喜剧片\"\n       }\n      ],\n    \"25-35\"\n    ],\n    [\n      [\n       \"男：足球比赛是明天上午八点开始吧?\",\n       \"女：因为天气不好，比赛改到后天下午三点了。\"\n      ],\n      [\n       {\n        \"question\": \"根据对话，可以知道什么?\",\n        \"choice\": [\n         \"今天天气不好\",\n         \"比赛时间变了\",\n         \"校长忘了时间\"\n        ],\n        \"answer\": \"比赛时间变了\"\n       }\n      ],\n    \"31-109\"\n    ]\n```\n   <a href=\"https://storage.googleapis.com/cluebenchmark/tasks/c3_public.zip\" > C3数据集下载</a>\n\n##### 11. 诊断集 CLUE_diagnostics test_set\n\n诊断集，用于评估不同模型在9种语言学家总结的中文语言现象上的表现\n\n使用在CMNLI上训练过的模型，直接预测在这个诊断集上的结果，提交格式和CMNLI一致，在排行榜详情页可以看到结果\n\n<a href='https://storage.googleapis.com/cluebenchmark/tasks/clue_diagnostics_public.zip'>diagnostics数据集下载</a>\n\n##### 更多数据集添加中，Comming soon!\n如果你有定义良好的数据集并愿意为社区做贡献，请与我们取得联系 ChineseGLUE#163.com\n\n##### 数据集整体下载 \n\n<a href=\"#\">整体下载 Comining Soon</a>最近几天，会添加中\n\n或使用命令：wget <url>\n\nData filter method\n\n## 难样本数据集筛选方法\n\n为了增加模型区分度和增大数据集难度，我们采用**k折交叉验证**的方式对v0版本的数据集进行过滤，最终得到v1版本。\n\n```\n具体步骤：\n1.将特定任务的数据集集中在一起，同时选择一个基准测试模型（如AlbertTiny）\n2.将数据集均匀分成k份；每次选择其中1份当验证集，剩下的都作为训练集，训练基准模型并在验证集上测试、保留预测结果\n3.重复步骤二k次，让每一份数据都有机会当验证集，过完整个数据集\n4.将k份验证集的预测结果合并；保留其中预测错误的样本（可以认为是较难的数据），并删除一部分预测正确的样本。最后重新划分出训练集、验证集、测试集\n5.如果希望进一步筛选难样本，重复步骤2-4即可\n```\n\nNotes：\n\n```\n1.k一般选择4-6\n2.难样本，是指在交叉验证过程中模型预测错误的样本，也是我们希望尽可能保留的样本。模型预测正确的样本最终会被优先排除一部分\n```\n\n内容体系 Contents\n--------------------------------------------------------------------\nLanguage Understanding Evaluation benchmark for Chinese(ChineseGLUE) got ideas from GLUE, which is a collection of \n\nresources for training, evaluating, and analyzing natural language understanding systems. ChineseGLUE consists of: \n\n##### 1）中文任务的基准测试，覆盖多个不同程度的语言任务 \n\nA benchmark of several sentence or sentence pair language understanding tasks. \nCurrently the datasets used in these tasks are come from public. We will include datasets with private test set before the end of 2019.\n\n##### 2）公开的排行榜 Leaderboard \n\nA public leaderboard for tracking performance. You will able to submit your prediction files on these tasks, each task will be evaluated and scored, a final score will also be available.\n\n##### 3）基线模型，包含开始的代码、预训练模型  Baselines with code\n\nbaselines for ChineseGLUE tasks. baselines will be available in TensorFlow,PyTorch,Keras and PaddlePaddle.\n\n##### 4）语料库，用于语言建模、预训练或生成型任务  Corpus\n\nA huge amount of raw corpus for pre-train or language modeling research purpose. It will contains around 10G raw corpus in 2019; \n\nIn the first half year of 2020, it will include at least 30G raw corpus; By the end of 2020, we will include enough raw corpus, such as 100G, so big enough that you will need no more raw corpus for general purpose language modeling.\nYou can use it for general purpose or domain adaption, or even for text generating. when you use for domain adaption, you will able to select corpus you are interested in.\n\n##### 5）工具包 toolkit\n\nAn easy to use toolkit that can run specific task or model with one line of code. You can easily change configuration, task or model.\n\n##### 6) 技术报告\n\nTechical report with details\n\nWhy do we need a benchmark for Chinese lanague understand evaluation?\n\n为什么我们需要一个中文任务的基准测试？ \n---------------------------------------------------------------------\n首先，中文是一个大语种，有其自身的特定、大量的应用。\n\n    如中文使用人数近14亿，是联合国官方语言之一，产业界有大量的的朋友在做中文的任务。\n    中文是象形文字，有文字图形；字与字之间没有分隔符，不同的分词(分字或词)会影响下游任务。\n\n其次，相对于英文的数据集，中文的公开可用的数据集还比较少。\n\n     很多数据集是非公开的或缺失基准测评的；多数的论文描述的模型是在英文数据集上做的测试和评估，那么对于中文效果如何？不得而知。\n\n再次，语言理解发展到当前阶段，预训练模型极大的促进了自然语言理解。\n\n     不同的预训练模型相继产生，但不少最先进(state of the art)的模型，并没有官方的中文的版本，也没有对这些预训练模型在不同任务上的公开测试，\n     导致技术的发展和应用还有不少距离，或者说技术应用上的滞后。\n\n那么，如果有一个中文任务的基准测试，包含一批大众能广泛使用和测评的数据集、适用中文任务的特点、能紧跟当前世界技术的发展，\n\n     能缓解当前中文任务的一些问题，并促进相关应用的发展。\n\n\n各任务详细对比\n---------------------------------------------------------------------\n Evaluation of Dataset for Different Models\n\n#### AFQMC 蚂蚁语义相似度 Ant Semantic Similarity (Accuracy)：\n|         模型          | 开发集（dev) | 测试集（test) |              训练参数              |\n| :-------------------: | :----------: | :-----------: | :--------------------------------: |\n|     ALBERT-xxlarge     |    -     |     -   |  -  |\n|      ALBERT-tiny      |    69.13%     |    69.92%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n|       BERT-base       |    74.16%     |     73.70%   | batch_size=16, length=128, epoch=3 lr=2e-5|\n|   BERT-wwm-ext-base   |    73.74%     |     74.07%   | batch_size=16, length=128, epoch=3 lr=2e-5|\n|      ERNIE-base       |        74.88% |    73.83%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n|     RoBERTa-large     |     73.32%    |     74.02%   | batch_size=16, length=128, epoch=3 lr=2e-5|\n|       XLNet-mid       |     70.73%    |   70.50%     | batch_size=16, length=128, epoch=3 lr=2e-5|\n|    RoBERTa-wwm-ext    |   74.30%      |    74.04%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n| RoBERTa-wwm-large-ext |     74.92%    |    76.55%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n\n#### TNEWS' 头条新闻分类 Toutiao News Classification (Accuracy)：\n|         模型          | 开发集（dev) | 测试集（test) |              训练参数              |\n| :-------------------: | :----------: | :-----------: | :--------------------------------: |\n|     ALBERT-xxlarge     |    -     |     -    |     -  |\n|      ALBERT-tiny      |    53.55%     |       53.35%   | batch_size=16, length=128, epoch=3 lr=2e-5|\n|       BERT-base       |    56.09%     |     56.58%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n|   BERT-wwm-ext-base   |     56.77%    |    56.86%      | batch_size=16, length=128, epoch=3 lr=2e-5|\n|      ERNIE-base       |     58.24%    |     58.33%     | batch_size=16, length=128, epoch=3 lr=2e-5|\n|     RoBERTa-large     |     57.95%    |      57.84%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n|       XLNet-mid       |    56.09%     |      56.24%    | batch_size=16, length=128, epoch=3 lr=2e-5|\n|    RoBERTa-wwm-ext    |   57.51%      |      56.94%       | batch_size=16, length=128, epoch=3 lr=2e-5|\n| RoBERTa-wwm-large-ext |  58.32% | 58.61%  | batch_size=16, length=128, epoch=3 lr=2e-5|\n\n#### IFLYTEK' 长文本分类 Long Text Classification (Accuracy)：\n|         模型          | 开发集（dev) | 测试集（test) |              训练参数              |\n| :-------------------: | :----------: | :-----------: | :--------------------------------: |\n|     ALBERT-xlarge     |    -     |     -     | batch=32, length=128, epoch=3 lr=2e-5 |\n|      ALBERT-tiny      |    48.76    |     48.71     | batch=32, length=128, epoch=10 lr=2e-5 |\n|       BERT-base       |    60.37    |     60.29     | batch=32, length=128, epoch=3 lr=2e-5 |\n|   BERT-wwm-ext-base   |    59.88    |     59.43     | batch=32, length=128, epoch=3 lr=2e-5 |\n|      ERNIE-base       |    59.52    |     58.96     | batch=32, length=128, epoch=3 lr=2e-5  |\n|     RoBERTa-large     |    62.6    |     62.55     | batch=24, length=128, epoch=3 lr=2e-5  |\n|       XLNet-mid       |    57.72    |     57.85     | batch=32, length=128, epoch=3 lr=2e-5  |\n|    RoBERTa-wwm-ext    |    60.8    |       60.31       | batch=32, length=128, epoch=3 lr=2e-5  |\n| RoBERTa-wwm-large-ext | **62.75** |  **62.98**  | batch=24, length=128, epoch=3 lr=2e-5 |\n\n#### CMNLI 中文自然语言推理 Chinese Multi-Genre NLI (Accuracy)：\n| 模型 | 开发集 (dev %) | 测试集（test %) |  训练参数 |\n| :----:| :----: | :----: | :----: |\n| BERT-base\t| 79.47 | 79.69 | batch=64, length=128, epoch=2 lr=3e-5 |\n| BERT-wwm-ext-base\t| 80.92 |80.42|\tbatch=64, length=128, epoch=2 lr=3e-5 |\n| ERNIE-base\t| 80.37 | 80.29 | batch=64, length=128, epoch=2 lr=3e-5 |\n| ALBERT-xxlarge\t|- | - | - |\n| ALBERT-tiny\t| 70.26 | 70.61 | batch=64, length=128, epoch=2 lr=3e-5 |\n| RoBERTa-large\t| 82.40 | 81.70 | batch=64, length=128, epoch=2 lr=3e-5 |\n| xlnet-mid\t| 82.21 | 81.25 | batch=64, length=128, epoch=2 lr=3e-5 |\n| RoBERTa-wwm-ext\t| 80.70 | 80.51 | batch=64, length=128, epoch=2 lr=3e-5  |\n| RoBERTa-wwm-large-ext\t|***83.20*** | ***82.12*** | batch=64, length=128, epoch=2 lr=3e-5  |\n\n注：ALBERT-xlarge，在XNLI任务上训练暂时还存在有问题\n\n#### WSC Winograd模式挑战中文版  The Winograd Schema Challenge,Chinese Version：\n| 模型 | 开发集（dev) | 测试集（test) | 训练参数 |\n| :----:| :----: | :----: | :----: |\n| ALBERT-xxlarge |  -  |  -  |  -    |\n| ALBERT-tiny |  57.7(52.9)  |  58.5(52.1)  | lr=1e-4, batch_size=8, length=128, epoch=50   |\n| BERT-base | 59.6（56.7)  | 62.0（57.9）  |  lr=2e-5, batch_size=8, length=128, epoch=50 |\n| BERT-wwm-ext-base | 59.4(56.7) |  61.1(56.2) | lr=2e-5, batch_size=8, length=128, epoch=50   |\n| ERNIE-base  | 58.1(54.9)| 60.8(55.9) | lr=2e-5, batch_size=8, length=128, epoch=50   |\n| RoBERTa-large | 68.6(58.7)  | 72.7(63.6)  | lr=2e-5, batch_size=8, length=128, epoch=50   |\n| XLNet-mid | 60.9(56.8）  |  64.4(57.3） | lr=2e-5, batch_size=8, length=128, epoch=50   |\n| RoBERTa-wwm-ext | 67.2(57.7)  | 67.8(63.5)  | lr=2e-5, batch_size=8, length=128, epoch=50   |\n| RoBERTa-wwm-large-ext |69.7(64.5) |  74.6(69.4) | lr=2e-5, batch_size=8, length=128, epoch=50   |\n\n#### CSL 关键词识别  Keyword Recognition (Accuracy)：\n\n|         模型          | 开发集（dev) | 测试集（test) |              训练参数              |\n| :-------------------: | :----------: | :-----------: | :--------------------------------: |\n|     ALBERT-xlarge     |    80.23     |     80.29     | batch_size=16, length=128, epoch=2, lr=5e-6  |\n|     ALBERT-tiny       |    74.36     |     74.56     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n|       BERT-base       |    79.63     |     80.23     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n|   BERT-wwm-ext-base   |    80.60     |     81.00     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n|      ERNIE-base       |    79.43     |     79.10     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n|     RoBERTa-large     |    81.87     |     81.36     | batch_size=4, length=256, epoch=5, lr=5e-6 |\n|       XLNet-mid       |    82.06     |     81.26     | batch_size=4, length=256, epoch=3, lr=1e-5 |\n|    RoBERTa-wwm-ext    |    80.67     |     80.63     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n| RoBERTa-wwm-large-ext |    82.17     |     82.13     | batch_size=4, length=256, epoch=5, lr=1e-5 |\n\n#### DRCD 繁体阅读理解 Reading Comprehension for Traditional Chinese (F1, EM)：\n| 模型 | 开发集（dev) | 测试集（test) | 训练参数 |\n| :----:| :----: | :----: | :----: |\n| BERT-base |F1:92.30 EM:86.60 | F1:91.46 EM:85.49 |  batch=32, length=512, epoch=2, lr=3e-5, warmup=0.1 |\n| BERT-wwm-ext-base |F1:93.27 EM:88.00 | F1:92.63 EM:87.15 |  batch=32, length=512, epoch=2, lr=3e-5, warmup=0.1 |\n| ERNIE-base  |F1:92.78 EM:86.85 | F1:92.01 EM:86.03 |  batch=32, length=512, epoch=2, lr=3e-5, warmup=0.1 |\n| ALBERT-large  |F1:93.90 EM:88.88 | F1:93.06 EM:87.52 |  batch=32, length=512, epoch=3, lr=2e-5, warmup=0.05 |\n| ALBERT-xlarge |F1:94.63 EM:89.68 | F1:94.70 EM:89.78 |  batch_size=32, length=512, epoch=3, lr=2.5e-5, warmup=0.06 |\n| ALBERT-xxlarge |F1:93.69 EM:89.97 | F1:94.62 EM:89.67 |  batch_size=32, length=512, epoch=2, lr=3e-5, warmup=0.1 |\n| ALBERT-tiny |F1:81.51 EM:71.61 | F1:80.67 EM:70.08 |  batch=32, length=512, epoch=3, lr=2e-4, warmup=0.1 |\n| RoBERTa-large |F1:94.93 EM:90.11 | F1:94.25 EM:89.35 |  batch=32, length=256, epoch=2, lr=3e-5, warmup=0.1|\n| xlnet-mid |F1:92.08 EM:84.40 | F1:91.44 EM:83.28 | batch=32, length=512, epoch=2, lr=3e-5, warmup=0.1 |\n| RoBERTa-wwm-ext |F1:94.26 EM:89.29 | F1:93.53 EM:88.12 |  batch=32, length=512, epoch=2, lr=3e-5, warmup=0.1|\n| RoBERTa-wwm-large-ext |***F1:95.32 EM:90.54*** | ***F1:95.06 EM:90.70*** | batch=32, length=512, epoch=2, lr=2.5e-5, warmup=0.1 |\n\n#### CMRC2018 阅读理解 Reading Comprehension for Simplified Chinese (F1, EM)：\n| 模型 | 开发集（dev) | 测试集（test) |  训练参数 |\n| :----:| :----: | :----: | :----: |\n| BERT-base\t|F1:85.48 EM:64.77 | F1:88.10 EM:71.60 | batch=32, length=512, epoch=2 lr=3e-5 warmup=0.1 |\n| BERT-wwm-ext-base\t|F1:86.68 EM:66.96 |F1:89.62 EM:73.95|\tbatch=32, length=512, epoch=2 lr=3e-5 warmup=0.1 |\n| ERNIE-base\t|F1:87.30 EM:66.89 | F1:90.57 EM:74.70 | batch=32, length=512, epoch=2 lr=3e-5 warmup=0.1 |\n| ALBERT-base\t| F1:85.86 EM:64.76 |F1:89.66 EM:72.90| batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| ALBERT-large\t| F1:87.36 EM:67.31 |F1:90.81 EM:75.95| batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| ALBERT-xlarge\t| F1:88.99 EM:69.08 |F1:92.09 EM:76.30| batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| ALBERT-xxlarge\t| F1:87.47 EM:66.43 |F1:90.77 EM:75.15| batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| ALBERT-tiny\t| F1:73.95 EM:48.31 |F1:76.21 EM:53.35| batch=32, epoch3, length=512, lr=2e-4, warmup=0.1 |\n| RoBERTa-large\t| F1:88.61 EM:69.94 |***F1:92.04 EM:78.50***| batch=32, epoch2, length=256, lr=3e-5, warmup=0.1 |\n| xlnet-mid\t|F1:85.63 EM:65.31 | F1:86.11 EM:66.95 | batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| RoBERTa-wwm-ext\t|F1:87.28 EM:67.89 | F1:90.41 EM:75.20 | batch=32, epoch2, length=512, lr=3e-5, warmup=0.1 |\n| RoBERTa-wwm-large-ext\t|***F1:89.42 EM:70.59*** | F1:92.11 EM:77.95 | batch=32, epoch2, length=512, lr=2.5e-5, warmup=0.1 |\n\n注: 现在榜上数据为cmrc2018的2k测试集子集作为测试，而并非cmrc2018官方完整测试集。如需完整测试cmrc2018阅读理解数据集仍需通过cmrc2018平台提交(https://worksheets.codalab.org/worksheets/0x96f61ee5e9914aee8b54bd11e66ec647)。\n\n#### CHID 成语阅读理解填空 Chinese IDiom Dataset for Cloze Test (Accuracy)：\n| 模型 | 开发集（dev) | 测试集（test) |  训练参数 |\n| :----:| :----: | :----: | :----: |\n| BERT-base\t|82.20 | 82.04 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| BERT-wwm-ext-base\t|83.36 |82.9 |\tbatch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ERNIE-base\t|82.46 | 82.28 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ALBERT-base\t| 70.99 |71.77 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ALBERT-large\t| 75.10 |74.18 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ALBERT-xlarge\t| 81.20 | 80.57 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ALBERT-xxlarge | 83.61 | 83.15 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| ALBERT-tiny\t| 43.47 |43.53 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| RoBERTa-large\t| 85.31 |84.50 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| xlnet-mid\t|83.76 | 83.47 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| RoBERTa-wwm-ext\t|83.78 | 83.62 | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n| RoBERTa-wwm-large-ext\t|***85.81*** | ***85.37*** | batch=24, length=64, epoch=3, lr=2e-5, warmup=0.06 |\n\n#### C<sup>3</sup> 成语阅读理解填空 中文多选阅读理解 Multiple-Choice Chinese Machine Reading Comprehension (Accuracy)：\n| 模型 | 开发集（dev) | 测试集（test) |  训练参数 |\n| :----:| :----: | :----: | :----: |\n| BERT-base\t| 65.70 | 64.50 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| BERT-wwm-ext-base\t| 67.80 | 68.50 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ERNIE-base\t| 65.50 | 64.10 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ALBERT-base | 60.43 | 59.58 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ALBERT-large | 64.07 | 64.41 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ALBERT-xlarge | 69.75 | 70.32 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ALBERT-xxlarge | 73.66 | 73.28 | batch=16, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| ALBERT-tiny\t| 50.58 | 50.26 | batch=32, length=512, epoch=8, lr=5e-5, warmup=0.1 |\n| RoBERTa-large\t| 67.79 | 67.55 | batch=24, length=256, epoch=8, lr=2e-5, warmup=0.1 |\n| xlnet-mid\t| 66.17 | 67.68 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| RoBERTa-wwm-ext\t| 67.06 | 66.50 | batch=24, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n| RoBERTa-wwm-large-ext\t|***74.48*** | ***73.82*** | batch=16, length=512, epoch=8, lr=2e-5, warmup=0.1 |\n\n\n成为ChineseGLUE组织的创始成员 Members\n---------------------------------------------------------------------\n##### 你将可以 Benefits：\n\n1、成为中国第一个中文任务基准测评的创始会员\n\n2、能与其他专业人士共同贡献力量，促进中文自然语言处理事业的发展\n\n3、参与部分工作后，获得已经清洗并预训练的后的、与英文wiki & bookCorpus同等量级、大规模的预训练语料，用于研究目的。\n\n4、优先使用state of the art的中文预训练模型，包括各种体验版或未公开版本\n\n##### 如何参与 How to join with us：\n\n发送邮件 chineseGLUE#163.com，简要介绍你自己、背景、工作或研究方向、你的组织、在哪方面可以为社区贡献力量，我们评估后会与你取得联系你。\n\n任务清单 TODO LIST\n---------------------------------------------------------------------\n1、搜集、挖掘1个有代表性的数据集，一般为分类或句子对任务 (需要额外5个数据集)\n\n2、阅读理解任务转化成句子对任务（如线索与问题或答案），并做测评，数据应拆分成训练、验证和测试集。\n\n3、基线模型baselises在特定任务模型的训练、预测的方法和脚本(支持PyTorch、Keras)；\n\n4、对当前主流模型（如bert/bert_wwm_ext/roberta/albert/ernie/ernie2.0等），结合ChineseGLUE的数据集，做准确率测试。\n\n   如： XLNet-mid在LCQMC数据集上做测试\n\n5、是否还有没有参与测评的模型？\n\n##### 其他\n6、排行榜landing页\n\n7、介绍中文语言理解测评基准(ChineseGLUE)\n\n8、测评系统主要功能开发\n\nTimeline 时间计划:\n---------------------------------------------------------------------\n2019-10-20 to 2019-12-31: beta version of ChineseGLUE\n\n2020.1.1 to 2020-12-31: official version of ChineseGLUE\n\n2021.1.1 to 2021-12-31: super version of ChineseGLUE\n\nContribution 贡献你的力量，从今天开始\n---------------------------------------------------------------------\n\nShare your data set with community or make a contribution today! Just send email to chineseGLUE#163.com, \n\nor join QQ group: 836811304\n\n\n#### Research supported with Cloud TPUs from Google's TensorFlow Research Cloud (TFRC)\n---------------------------------------------------------------------\n\t\nCite Us:\n\n    @inproceedings {xu-etal-2020-clue,\n     title = \"{CLUE}: A {C}hinese Language Understanding Evaluation Benchmark\",\n     author = \"Xu, Liang  and\n        Hu, Hai and\n        Zhang, Xuanwei and\n        Li, Lu and\n        Cao, Chenjie and\n        Li, Yudong and\n        Xu, Yechen and\n        Sun, Kai and\n        Yu, Dian and\n        Yu, Cong and\n        Tian, Yin and\n        Dong, Qianqian and\n        Liu, Weitang and\n        Shi, Bo and\n        Cui, Yiming and\n        Li, Junyi and\n        Zeng, Jun and\n        Wang, Rongzhao and\n        Xie, Weijian and\n        Li, Yanting and\n        Patterson, Yina and\n        Tian, Zuoyu and\n        Zhang, Yiwen and\n        Zhou, He and\n        Liu, Shaoweihua and\n        Zhao, Zhe and\n        Zhao, Qipeng and\n        Yue, Cong and\n        Zhang, Xinrui and\n        Yang, Zhengliang and\n        Richardson, Kyle and\n        Lan, Zhenzhong \",\n     booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\",\n     month = dec,\n     year = \"2020\",\n     address = \"Barcelona, Spain (Online)\",\n     publisher = \"International Committee on Computational Linguistics\",\n     url = \"https://aclanthology.org/2020.coling-main.419\",\n     doi = \"10.18653/v1/2020.coling-main.419\",\n     pages = \"4762--4772\",\n     abstract = \"The advent of natural language understanding (NLU) benchmarks for English, such as GLUE and SuperGLUE allows new NLU models to be evaluated across a diverse set of tasks. These comprehensive benchmarks have facilitated a broad range of research and applications in natural language processing (NLP). The problem, however, is that most such benchmarks are limited to English, which has made it difficult to replicate many of the successes in English NLU for other languages. To help remedy this issue, we introduce the first large-scale Chinese Language Understanding Evaluation (CLUE) benchmark. CLUE is an open-ended, community-driven project that brings together 9 tasks spanning several well-established single-sentence/sentence-pair classification tasks, as well as machine reading comprehension, all on original Chinese text. To establish results on these tasks, we report scores using an exhaustive set of current state-of-the-art pre-trained Chinese models (9 in total). We also introduce a number of supplementary datasets and additional tools to help facilitate further progress on Chinese NLU. Our benchmark is released at https://www.cluebenchmarks.com\",\n    }\n\n\n你可以查看这里：：https://aclanthology.org/2020.coling-main.419.bib\n\n\t\nReference:\n---------------------------------------------------------------------\n1、<a href=\"https://openreview.net/pdf?id=rJ4km2R5t7\">GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</a>\n\n2、<a href=\"https://w4ngatang.github.io/static/papers/superglue.pdf\">SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems</a>\n\n4、<a href=\"https://arxiv.org/pdf/1809.05053.pdf\">XNLI: Evaluating Cross-lingual Sentence Representations</a>\n\n5、<a href=\"https://github.com/brightmart/nlp_chinese_corpus\">nlp_chinese_corpus: 大规模中文自然语言处理语料 Large Scale Chinese Corpus for NLP</a>\n\n6、<a href=\"https://github.com/InsaneLife/ChineseNLPCorpus\">ChineseNLPCorpus</a>\n\n7、<a href=\"https://arxiv.org/abs/1909.11942\">ALBERT: A Lite BERT For Self-Supervised Learning Of Language Representations</a>\n\n8、<a href=\"https://arxiv.org/pdf/1810.04805.pdf\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>\n\n9、<a href=\"https://arxiv.org/pdf/1907.11692.pdf\">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a>\n\t\n10、CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark <a href=\"https://github.com/CBLUEbenchmark/CBLUE\">[git]</a>  <a href=\"https://arxiv.org/abs/2106.08087\">[pdf]</a> <a href=\"https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&lang=en-us\">[web]</a>\n"
        },
        {
          "name": "baselines",
          "type": "tree",
          "content": null
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}