{
  "metadata": {
    "timestamp": 1736559985942,
    "page": 779,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dongrixinyu/JioNLP",
      "stars": 3448,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.076171875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n.idea/\n*.py[cod]\n*$py.class\nmath_question/\n\nchina_location.txt\nchinese_char_dictionary.txt\nchinese_idiom.txt\nchinese_word_dictionary.txt\nidf.txt\npinyin_phrase.txt\ntopic_word_weight.json\nword_topic_weight.json\nphone_location.txt\npornography.txt\nsentiment_words.txt\nword_distribution.json\nchar_distribution.json\nxiehouyu.txt\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# cuichengyu\nnohup.out\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1064453125,
          "content": "include jionlp/dictionary/*\ninclude jionlp/dictionary/jionlp_LLM_test/*\ninclude jionlp/algorithm/keyphrase/*\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.8037109375,
          "content": "<p align=\"center\">\n    <a alt=\"jionlp logo\">\n        <img src=\"../../blob/master/image/jionlp_logo.jpg\" style=\"width:300px;height:100px\">\n    </a>\n</p>\n<p align=\"center\">\n    <a alt=\"License\">\n        <img src=\"https://img.shields.io/github/license/dongrixinyu/JioNLP?color=crimson\" /></a>\n    <a alt=\"Size\">\n        <img src=\"https://img.shields.io/badge/size-19.3m-orange\" /></a>\n    <a alt=\"Downloads\">\n        <img src=\"https://pepy.tech/badge/jionlp/month\" /></a>\n    <a alt=\"Version\">\n        <img src=\"https://img.shields.io/badge/version-1.5.19-green\" /></a>\n    <a href=\"https://github.com/dongrixinyu/JioNLP/pulse\" alt=\"Activity\">\n        <img src=\"https://img.shields.io/github/commit-activity/m/dongrixinyu/JioNLP?color=blue\" /></a>\n</p>\n\n#### &emsp;&emsp; JioNLP：中文 NLP 预处理、解析工具包 A Python Lib for Chinese NLP Preprocessing & Parsing\n#### &emsp;&emsp; 安装：```pip install jionlp```\n- JioNLP 是一个面向 **NLP 开发者**的工具包，提供 NLP 任务预处理、解析功能，准确、高效、零使用门槛。请下拉本网页，查阅具体功能信息，并按 **Ctrl+F** 进行搜索。[**JioNLP在线版**](https://www.jionlp.com/jionlp_online) 可快速试用部分功能。关注同名**微信公众号 JioNLP** 可获取最新的 AI 资讯，数据资源。\n\n  - [**AI发展方向——从pipeline到end2end**](https://mp.weixin.qq.com/s/ZpEn_vZGjY2dqpE_62721w)\n  - [**你为什么不相信 LLM 模型评测：深入评测 LLM 接口**](https://mp.weixin.qq.com/s/8PoFz6mUD1AzKthGyO4cyA)\n  - [**AI似乎在向着奇怪的方向飞奔**](https://mp.weixin.qq.com/s/cXktu3BDUee-s2L8Z0wXYA)\n  - [**ChatGPT这么强，会影响NLPer的就业环境吗？**](https://zhuanlan.zhihu.com/p/605673596)\n  - [**一文读懂ChatGPT模型原理**](https://zhuanlan.zhihu.com/p/589621442)\n  - [**花了三周，我又更新了一版开源软件 ffio**](https://zhuanlan.zhihu.com/p/678141936) => [**FFIO链接**](https://github.com/dongrixinyu/ffio)\n\n\n### 2025-01-10 更新某些功能\n\n- `jio.chinese_idiom_loader`\n该函数是成语加载函数，**目前**返回成语的 释义、出处、示例、整个中文语料中的出现频率。\n\n由于该函数占据了 2.9M 硬盘空间，且使用人数应该非常少，所以会对该词典进行精简，**计划**仅保留成语以及其文本频率，删除释义、出处、示例。\n这样做会压缩 jionlp 工具包大小。\n\n如果有任何意见，都可以提 issue 反馈。\n\n\n### 2023-12-12 Add [MELLM](https://zhuanlan.zhihu.com/p/666001842)\n\n- **MELLM**, short for **Mutual Evaluation of Large Language Models**, is an automatic evaluation algorithm of LLMs without human supervision. MELLM has been tested effectively on several LLMs and datasets [test results and analysis](https://zhuanlan.zhihu.com/p/671636095). You can use the example code below to take a try. \n- before running this code, you should download `norm_score.json` and `max_score.json` from [test data](https://pan.baidu.com/s/18Ufx51v05gyVkBoCo8fupw) with password `jmbo`.\n- If you encounter any error, read the [test_mellm.py](https://github.com/dongrixinyu/JioNLP/blob/master/test/test_mellm.py) to download `*.json` file.\n```\n$ git clone https://github.com/dongrixinyu/JioNLP\n$ cd JioNLP/test/\n$ python test_mellm.py\n```\n\n\n### 2023-06-22 添加[大语言模型 LLM 评测数据集](https://github.com/dongrixinyu/JioNLP/wiki/LLM%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86)\n- JioNLP 提供了一套 LLM 的测试数据集，并应用 MELLM 算法完成了自动评测。\n- **评测结果**可关注**公众号JioNLP**，查阅具体各家评测截图pdf。\n```\n>>> import jionlp as jio\n>>> llm_test = jio.llm_test_dataset_loader(version='1.1')\n>>> print(llm_test[15])\n>>> llm_test = jio.llm_test_dataset_loader(field='math')\n>>> print(llm_test[5])\n```\n\n\n## 安装 Installation\n\n- python>=3.6 **github 版本略领先于 pip**\n```\n$ git clone https://github.com/dongrixinyu/JioNLP\n$ cd ./JioNLP\n$ pip install .\n```\n- pip 安装\n```\n$ pip install jionlp\n```\n\n\n## 使用 Features\n\n- 导入工具包，查看工具包的主要功能与函数注释\n```\n>>> import jionlp as jio\n>>> print(jio.__version__)  # 查看 jionlp 的版本\n>>> dir(jio)\n>>> print(jio.extract_parentheses.__doc__)\n```\n\n\n- **星级⭐**代表优质特色功能\n### 1.小工具集 Gadgets\n\n| 功能   | 函数   |描述   |星级   |\n|--------|-------|-------|-------|\n|[**查找帮助**](../../wiki/Gadget-说明文档#user-content-查找帮助) |help|若不知道 JioNLP 有哪些功能，可根据命令行提示键入若干关键词做搜索 | |\n|[**车牌号**解析](../../wiki/Gadget-说明文档#user-content-解析车牌号) |parse_motor_vehicle_licence_plate|给定一个车牌号，对其进行解析 |⭐|\n|[**时间语义解析**](../../wiki/时间语义解析-说明文档#user-content-时间语义解析) |parse_time|给定时间文本，解析其时间语义（时间戳、时长）等 |⭐|\n|[**关键短语抽取**](../../wiki/Gadget-说明文档#user-content-关键短语抽取) |extract_keyphrase|给定一篇文本，抽取其对应关键短语 |⭐|\n|[抽取式**文本摘要**](../../wiki/Gadget-说明文档#user-content-抽取式文本摘要) |extract_summary|给定一篇文本，抽取其对应文摘 | |\n|[**停用词过滤**](../../wiki/Gadget-说明文档#user-content-去除停用词) |remove_stopwords|给定一个文本被分词后的词 list，去除其中的停用词 |⭐|\n|[**分句**](../../wiki/Gadget-说明文档#user-content-文本分句) |split_sentence|对文本按标点分句 |⭐|\n|[**地址解析**](../../wiki/Gadget-说明文档#user-content-地址解析) |parse_location|给定一个包含国内地址字符串，识别其中的**省、市、县区、乡镇街道、村社**等信息 |⭐|\n|[电话号码**归属地**、<br>**运营商**解析](../../wiki/Gadget-说明文档#user-content-电话号码归属地运营商解析) |phone_location<br>cell_phone_location<br>landline_phone_location |给定一个电话号码（手机号、座机号）字符串，识别其中的**省、市、运营商** ||\n|[新闻**地名识别**](../../wiki/Gadget-说明文档#user-content-新闻地名识别) |recognize_location|给定新闻文本，识别其中的**国内省、市、县，国外国家、城市**等信息 |⭐|\n|[**公历农历**日期互转](../../wiki/Gadget-说明文档#user-content-公历农历日期互转)|lunar2solar<br>solar2lunar |给定某公（农）历日期，将其转换为农（公）历 ||\n|[**身份证号**解析](../../wiki/Gadget-说明文档#user-content-身份证号码解析) |parse_id_card|给定一个身份证号，识别对应的**省、市、县、出生年月、**<br>**性别、校验码**等信息 |⭐|\n|[**成语接龙**](../../wiki/Gadget-说明文档#user-content-成语接龙) |idiom_solitaire|成语接龙，即前一成语的尾字和后一成语的首字（读音）相同 ||\n|[**色情**数据过滤](../../wiki/一些说明#user-content-色情数据过滤) |- |- |\n|[**反动**数据过滤](../../wiki/一些说明#user-content-反动数据过滤) |- |- |\n|[**繁**体转**简**体](../../wiki/Gadget-说明文档#user-content-繁体转简体字) |tra2sim|繁体转简体，支持**逐字转**与**最大匹配**两种模式 | |\n|[**简**体转**繁**体](../../wiki/Gadget-说明文档#user-content-简体转繁体字) |sim2tra|简体转繁体，支持**逐字转**与**最大匹配**两种模式 | |\n|[汉字转**拼音**](../../wiki/Gadget-说明文档#user-content-汉字转拼音) |pinyin| 找出中文文本对应的汉语拼音，并可返回**声母**、**韵母**、**声调** |⭐ |\n|[汉字转**偏旁与字形**](../../wiki/Gadget-说明文档#user-content-汉字转偏旁与字形) |char_radical| 找出中文文本对应的汉字字形结构信息，<br>包括**偏旁部首**(“河”氵)、**字形结构**(“河”左右结构)、<br>**四角编码**(“河”31120)、**汉字拆解**(“河”水可)、<br>**五笔编码**(“河”ISKG) |⭐ |\n|[金额**数字转汉字**](../../wiki/正则抽取与解析-说明文档#user-content-金额数字转汉字)|money_num2char| 给定一条数字金额，返回其**汉字**大写结果 | |\n|[**新词发现**](../../wiki/Gadget-说明文档#user-content-新词发现)|new_word_discovery| 给定一语料文本文件，统计其中高可能成词 | |\n\n\n### 2.数据增强\n\n- [**文本数据增强各方法说明**](../../wiki/数据增强-说明文档#user-content-数据增强方法对比)\n\n| 功能   | 函数   |描述   |星级  |\n|--------|--------|-------|------|\n|[**回译**](../../wiki/数据增强-说明文档#user-content-回译数据增强) |BackTranslation|给定一篇文本，采用各大厂云平台的机器翻译接口，<br>实现数据增强 |⭐ |\n|[**邻近汉字换位**](../../wiki/数据增强-说明文档#user-content-邻近汉字换位) |swap_char_position|随机交换相近字符的位置，实现数据增强 | |\n|[**同音词替换**](../../wiki/数据增强-说明文档#user-content-同音词替换) |homophone_substitution|相同读音词汇替换，实现数据增强 |⭐ |\n|[随机**增删字符**](../../wiki/数据增强-说明文档#user-content-随机增删字符) |random_add_delete|随机在文本中增加、删除某个字符，对语义不造成影响 | |\n|[NER**实体替换**](../../wiki/数据增强-说明文档#user-content-ner实体替换) |replace_entity|根据实体词典，随机在文本中替换某个实体，对语义不<br>造成影响，也广泛适用于序列标注、文本分类 |⭐ |\n\n\n### 3.正则抽取与解析\n\n| 功能   | 函数   |描述   |星级    |\n|--------|--------|-------|-------|\n|[**清洗文本**](../../wiki/正则抽取与解析-说明文档#user-content-清洗文本) |clean_text|去除文本中的**异常字符、冗余字符、HTML标签、括号信息、**<br>**URL、E-mail、电话号码，全角字母数字转换为半角** |⭐ |\n|[抽取 **E-mail**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-e-mail) |extract_email|抽取文本中的 E-mail，返回**位置**与**域名** | |\n|[解析 **货币金额**](../../wiki/正则抽取与解析-说明文档#user-content-货币金额解析) |extract_money|解析货币金额字符串 |⭐ |\n|[抽取**微信号**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-微信号) |extract_wechat_id| 抽取微信号，返回**位置** | |\n|[抽取**电话号码**](../../wiki/正则抽取与解析-说明文档#user-content-抽取电话号码) |extract_phone_number| 抽取电话号码(含**手机号**、**座机号**)，返回**域名**、**类型**与**位置** | |\n|[抽取中国**身份证** ID](../../wiki/正则抽取与解析-说明文档#user-content-抽取身份证号) |extract_id_card|抽取身份证 ID，配合 **jio.parse_id_card** 返回身份证的<br>详细信息(**省市县**、**出生日期**、**性别**、**校验码**)| |\n|[抽取 **QQ** 号](../../wiki/正则抽取与解析-说明文档#user-content-抽取-qq) |extract_qq|抽取 QQ 号，分为严格规则和宽松规则 | |\n|[抽取 **URL**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-url-超链接) |extract_url|抽取 URL 超链接 | |\n|[抽取 **IP**地址](../../wiki/正则抽取与解析-说明文档#user-content-抽取-ip-地址) |extract_ip_address|抽取 IP 地址| |\n|[抽取**括号**中的内容](../../wiki/正则抽取与解析-说明文档#user-content-抽取文本括号信息) |extract_parentheses|抽取括号内容，包括 **{}「」[]【】()（）<>《》** |⭐ |\n|[抽取**车牌号**](../../wiki/正则抽取与解析-说明文档#user-content-抽取车牌号) |extract_motor_vehicle_licence_plate|抽取大陆车牌号信息 | |\n|[删除 **E-mail**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-e-mail) |remove_email|删除文本中的 E-mail 信息 | |\n|[删除 **URL**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-url) |remove_url |删除文本中的 URL 信息| |\n|[删除 **电话号码**](../../wiki/正则抽取与解析-说明文档#user-content-删除电话号码) |remove_phone_number|删除文本中的电话号码 | |\n|[删除 **IP地址**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-ip-地址)|remove_ip_address|删除文本中的 IP 地址 | |\n|[删除 **身份证号**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的身份证号) |remove_id_card|删除文本中的身份证信息 | |\n|[删除 **QQ**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-qq-号) |remove_qq|删除文本中的 qq 号| |\n|[删除 **HTML**标签](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-html-标签) |remove_html_tag|删除文本中残留的 HTML 标签 | |\n|[删除**括号**中的内容](../../wiki/正则抽取与解析-说明文档#user-content-删除文本括号信息) |remove_parentheses|删除括号内容，包括 **{}「」[]【】()（）<>《》** | |\n|[删除**异常**字符](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的异常字符) |remove_exception_char|删除文本中异常字符，主要保留汉字、常用的标点，<br>单位计算符号，字母数字等 | |\n|[删除**冗余**字符](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的冗余字符) |remove_redundant_char|删除文本中冗余重复字符 | |\n|[归一化 **E-mail**](../../wiki/正则抽取与解析-说明文档#user-content-归一化文本中的-e-mail) |replace_email|归一化文本中的 E-mail 信息为\\<email\\> | |\n|[归一化 **URL**](../../wiki/正则抽取与解析-说明文档#user-content-归一化文本中的-url) |replace_url |归一化文本中的 URL 信息为\\<url\\> | |\n|[归一化 **电话号码**](../../wiki/正则抽取与解析-说明文档#user-content-归一化电话号码) |replace_phone_number|归一化文本中的电话号码为\\<tel\\> | |\n|[归一化 **IP地址**](../../wiki/正则抽取与解析-说明文档#user-content-归一化文本中的-ip-地址)|replace_ip_address|归一化文本中的 IP 地址为\\<ip\\> | |\n|[归一化 **身份证号**](../../wiki/正则抽取与解析-说明文档#user-content-归一化文本中的身份证号) |replace_id_card|归一化文本中的身份证信息为\\<id\\> | |\n|[归一化 **QQ**](../../wiki/正则抽取与解析-说明文档#user-content-归一化文本中的-qq-号) |replace_qq|归一化文本中的 qq 号为\\<qq\\> | |\n|[判断文本是否**包含**中文字符](../../wiki/正则判断类说明文档#user-content-判断字符串中是否包含中文字符) | check_any_chinese_char | 检查文本中是否包含中文字符，若至少包含一个，则返回 True | |\n|[判断文本是否**全部是**中文字符](../../wiki/正则判断类说明文档#user-content-判断字符串中是否全部为中文字符) | check_all_chinese_char | 检查文本中是否全部是中文字符，若全部都是，则返回 True | |\n|[判断文本是否**包含**阿拉伯数字](../../wiki/正则判断类说明文档#user-content-判断字符串中是否包含阿拉伯数字) | check_any_arabic_num | 检查文本中是否包含阿拉伯数字，若至少包含一个，则返回 True | |\n|[判断文本是否**全部是**阿拉伯数字](../../wiki/正则判断类说明文档#user-content-判断字符串中是否全部为阿拉伯数字) | check_all_arabic_num | 检查文本中是否全部是阿拉伯数字，若全部都是，则返回 True | |\n\n### 4.文件读写工具\n\n| 功能   | 函数   |描述   |星级   |\n|--------|--------|-------|-------|\n|[**按行读取文件**](../../wiki/文件读写-说明文档#user-content-文件读取iter) |read_file_by_iter |以迭代器形式方便按行读取文件，节省内存，<br>支持指定**行数**，**跳过空行** ||\n|[**按行读取文件**](../../wiki/文件读写-说明文档#user-content-文件读取list) |read_file_by_line |按行读取文件，支持指定**行数**，**跳过空行** |⭐ |\n|[将 list 中元素按行写入文件](../../wiki/文件读写-说明文档#user-content-文件写入) |write_file_by_line| 将 list 中元素按行写入文件 |⭐ |\n|[计时工具](../../wiki/文件读写-说明文档#user-content-计时器) |TimeIt | 统计某一代码段的耗时 | |\n|[日志工具](../../wiki/文件读写-说明文档#user-content-日志处理设置函数) |set_logger |调整工具包日志输出形式 | |\n\n### 5.词典加载与使用\n\n| 功能 | 函数 | 描述 |星级  |\n|-----|-----|------|------|\n|[大语言模型 LLM 评测数据集](https://github.com/dongrixinyu/JioNLP/wiki/LLM%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86)|jio.llm_test_dataset_loader | LLM 评测数据集 |⭐|\n|[**Byte-level BPE**](../../wiki/BPE算法说明文档) | jio.bpe.byte_level_bpe |Byte-level-BPE 算法|⭐|\n|**停用词词典** | jio.stopwords_loader() | 综合了百度、jieba、讯飞等的停用词词典 |  |\n|[**成语**词典](../../wiki/词典加载-说明文档#user-content-加载成语词典) |chinese_idiom_loader|加载成语词典 |⭐|\n|[**歇后语**词典](../../wiki/词典加载-说明文档#user-content-加载歇后语词典) |xiehouyu_loader|加载歇后语词典 |⭐|\n|[**中国地名**词典](../../wiki/词典加载-说明文档#user-content-加载中国省市县地名词典) |china_location_loader|加载中国**省、市、县**三级词典 |⭐|\n|[**中国区划调整**词典](../../wiki/词典加载-说明文档#user-content-加载中国区划调整词典) |china_location_change_loader|加载 2018 年以来中国**县级**以上区划调整更名记录 |⭐|\n|[**世界地名**词典](../../wiki/词典加载-说明文档#user-content-加载世界国家城市地名词典) |world_location_loader|加载世界**大洲、国家、城市**词典 | |\n|[新华**字**典](../../wiki/词典加载-说明文档#user-content-加载新华字典) |chinese_char_dictionary_loader|加载新华字典 | |\n|[新华**词**典](../../wiki/词典加载-说明文档#user-content-加载新华词典) |chinese_word_dictionary_loader|加载新华词典 | |\n\n### 6.实体识别(NER)算法辅助工具集\n\n- [工具包 NER 数据规定说明](../../wiki/NER-说明文档#user-content-前言)\n\n| 功能   | 函数   |描述   |星级   |\n|--------|--------|-------|-------|\n|[抽取**货币金额实体**](../../wiki/NER-说明文档#user-content-货币金额实体抽取) |extract_money |从文本中抽取出货币金额实体 |⭐ |\n|[抽取**时间实体**](../../wiki/NER-说明文档#user-content-时间实体抽取) |extract_time |从文本中抽取出时间实体 |⭐ |\n|[基于**词典NER**](../../wiki/NER-说明文档#user-content-基于词典-ner) |LexiconNER|依据指定的实体词典，前向最大匹配实体 |⭐ |\n|[**entity 转 tag**](../../wiki/NER-说明文档#user-content-entity-转-tag) |entity2tag|将 json 格式实体转换为模型处理的 tag 序列 | |\n|[**tag 转 entity**](../../wiki/NER-说明文档#user-content-tag-转-entity) |tag2entity|将模型处理的 tag 序列转换为 json 格式实体 | |\n|[**字** token 转**词** token](../../wiki/NER-说明文档#user-content-字-token-转词-token) |char2word|将字符级别 token 转换为词汇级别 token | |\n|[**词** token 转**字** token](../../wiki/NER-说明文档#user-content-词-token-转字-token) |word2char|将词汇级别 token 转换为字符级别 token | |\n|[比较标注与模型预测的**实体差异**](../../wiki/NER-说明文档#user-content-比较-ner-标注实体与模型预测实体之间的差异) |entity_compare|针对人工标注的实体，与模型预测出的实体结果<br>，做差异比对 |⭐ |\n|[NER模型**预测加速**](../../wiki/NER-说明文档#user-content-ner-模型预测加速) |TokenSplitSentence<br>TokenBreakLongSentence<br>TokenBatchBucket|对 NER 模型预测并行加速的方法  |⭐ |\n|[**分割数据集**](../../wiki/NER-说明文档#user-content-分割数据集) |analyse_dataset|对 NER 标注语料，分为训练集、验证集、测试集，并给出各个子集的实体类型分布统计 |⭐ |\n|[实体**收集**](../../wiki/NER-说明文档#user-content-实体收集) |collect_dataset_entities|将标注语料中的实体收集起来，形成词典 | |\n\n\n### 7.文本分类\n\n| 功能   | 函数   |描述   |星级   |\n|--------|--------|-------|------|\n|[朴素贝叶斯**分析类别词汇**](../../wiki/文本分类-说明文档#user-content-朴素贝叶斯分析类别词汇) |analyse_freq_words|对文本分类的标注语料，做朴素贝叶斯词频分析，返回各类<br>文本的高条件概率词汇 |⭐ |\n|[**分割数据集**](../../wiki/文本分类-说明文档#user-content-分割数据集) |analyse_dataset|对文本分类的标注语料，切分为训练集、验证集、测试集，<br>并给出各个子集的分类分布统计 |⭐ |\n\n\n### 8.情感分析\n\n| 功能   | 函数   |描述   |星级   |\n|--------|--------|-------|-------|\n|[基于**词典情感分析**](../../wiki/情感分析-说明文档#user-content-基于词典的情感分析) |LexiconSentiment|依据人工构建的情感词典，计算文本的情感值，介于0~1之间 | |\n\n### 9.分词\n| 功能   | 函数   |描述   |星级   |\n|--------|--------|-------|-------|\n|[**word 转 tag**](../../wiki/分词-说明文档#user-content-word-转-tag) |cws.word2tag|将 json 格式分词序列转换为模型处理的 tag 序列 | |\n|[**tag 转 word**](../../wiki/分词-说明文档#user-content-tag-转-word) |cws.tag2word|将模型处理的 tag 序列转换为 json 格式分词 | |\n|[**统计F1值**](../../wiki/分词-说明文档#user-content-统计-f1-值) |cws.f1|比对分词标注标签于模型预测标签的F1值 | |\n|[**分词数据矫正-标准词典**](../../wiki/分词-说明文档#user-content-分词数据矫正-标准词典) |cws.CWSDCWithStandardWords |使用标准词典对分词标注数据进行矫正和修复 | |\n\n### 文献引用\n\n- 若论文需要进行引用，可复制以下引用：\n\n> Chengyu Cui, JioNLP, (2020), GitHub repository, https://github.com/dongrixinyu/JioNLP\n\n### 初衷\n\n- NLP 预处理与解析至关重要，且非常耗时。本 lib 能快速辅助完成各种琐碎的预处理、解析操作，加速开发进度，把有限的精力用在思考而非 code 上。\n- 如有功能建议、bug，可通过 issue 按模板提出。\n- 非常欢迎各位 NLP 开发者和研究者 **合作完善本工具包，添加新功能** 。\n\n### 如本工具对您有帮助，请点一下右上角 star ⭐\n### 或者扫码请作者喝杯咖啡 (●'◡'●)，开源项目完全用爱发电，谢谢啦！推荐优先使用【支付宝】 ~~\n- 感谢[致谢](../../wiki/致谢篇)名单中赞助的小伙伴们，你们的打赏让我更有动力\n\n<p align=\"center\">\n    <a alt=\"jionlp logo\">\n        <img src=\"../../blob/master/image/payment_code.jpg\" style=\"width:500px;height:380px\">\n    </a>\n</p>\n\n### 做 NLP不易，欢迎加入自然语言处理 Wechat 交流群\n### 请扫以下码，或wx搜索公众号JioNLP”，关注并回复【进群】\n<p align=\"center\">\n    <a alt=\"jionlp logo\">\n        <img src=\"../../blob/master/image/qrcode_for_gh.jpg\" style=\"width:200px;height:200px\">\n    </a>\n</p>\n\n\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 19.2138671875,
          "content": "<p align=\"center\">\n    <a alt=\"jionlp logo\">\n        <img src=\"../../blob/master/image/jionlp_logo.jpg\" / style=\"width:300px;height:100px\">\n    </a>\n</p>\n<p align=\"center\">\n    <a alt=\"License\">\n        <img src=\"https://img.shields.io/github/license/dongrixinyu/JioNLP?color=crimson\" /></a>\n    <a alt=\"Size\">\n        <img src=\"https://img.shields.io/badge/size-19.3m-orange\" /></a>\n    <a alt=\"Downloads\">\n        <img src=\"https://pepy.tech/badge/jionlp/month\" /></a>\n    <a alt=\"Version\">\n        <img src=\"https://img.shields.io/badge/version-1.5.2-green\" /></a>\n    <a href=\"https://github.com/dongrixinyu/JioNLP/pulse\" alt=\"Activity\">\n        <img src=\"https://img.shields.io/github/commit-activity/m/dongrixinyu/JioNLP?color=blue\" /></a>\n</p>\n\n### &emsp;&emsp; ——JioNLP：A Python Lib for Chinese NLP Preprocessing & Parsing\n### &emsp;&emsp; ——installation method：```pip install jionlp```\n### &emsp;&emsp; ——[JioNLP online](http://www.jionlp.com/) is provided for a quick trial of some functions\n### &emsp;&emsp; ——[中文版 README.md](https://github.com/dongrixinyu/JioNLP)\n\n- Doing NLP tasks, need to clean and filter the corpus? Use JioNLP\n- Doing NLP tasks, need to extract key info? Use JioNLP\n- Doing NLP tasks, need to do text augmentation? Use JioNLP\n- Doing NLP tasks, need to get radical, pinyin, traditional info of Chinese character? Use JioNLP\n\n#### In short, JioNLP offers a bundle of NLP task preprocessing and parsing tools, which is accurate, efficient, easy to use.\n#### Main functions include: clean text, delete HTML tags, exceptional chars, redundent chars, convert full-angle chars to half-angle, extract email, qq, phone-num, parenthesis info, id cards, ip, url, money and case, nums, parse time text, extract keyphrase, load Chinese dictionaries, do Chinese text augmentation\n \n\n#### Updata 2022-05-26\n## Update [**Keyphrase extraction**](../../wiki/Gadget-说明文档#user-content-关键短语抽取) \n\n#### jio.keyphrase.extract_keyphrase: extract keyphrases from a Chinese text\n```\n>>> import jionlp as jio\n>>> text = '浑水创始人：七月开始调查贝壳，因为“好得难以置信” 2021年12月16日，做空机构浑水在社交媒体上公开表示，正在做空美股上市公司贝壳...'\n\n>>> keyphrases = jio.keyphrase.extract_keyphrase(text)\n>>> print(keyphrases)\n>>> print(jio.keyphrase.extract_keyphrase.__doc__)\n\n# ['浑水创始人', '开始调查贝壳', '做空机构浑水', '美股上市公司贝壳', '美国证监会']\n\n```\n\n\n#### Update 2021-10-25\n## Update [money text parser](../../wiki/正则抽取与解析-说明文档#user-content-货币金额解析)\n\n#### jio.parse_money: parse a given money text to get a number, money case and definition of the money\n\n```python\nimport jionlp as jio\ntext_list = ['约4.287亿美元', '两个亿卢布', '六十四万零一百四十三元一角七分', '3000多欧元', '三五佰块钱', '七百到九百亿泰铢'] \nmoneys = [jio.parse_money(text) for text in text_list]\n\n# 约4.287亿美元: {'num': '428700000.00', 'case': '美元', 'definition': 'blur'}\n# 两个亿卢布: {'num': '200000000.00', 'case': '卢布', 'definition': 'accurate'}\n# 六十四万零一百四十三元一角七分: {'num': '640143.17', 'case': '元', 'definition': 'accurate'}\n# 3000多欧元: {'num': ['3000.00', '4000.00'], 'case': '欧元', 'definition': 'blur'}\n# 三五百块钱: {'num': ['300.00', '500.00'], 'case': '元', 'definition': 'blur'}\n# 七百到九百亿泰铢: {'num': ['70000000000.00', '90000000000.00'], 'case': '泰铢', 'definition': 'blur'}\n\n```\n\n#### Update 2022-03-07\n## Update [Time sementic parser](../../wiki/时间语义解析-说明文档#user-content-时间语义解析)\n\n#### jio.parse_time: parse a given time string\n\n``` python\nimport time\nimport jionlp as jio\nres = jio.parse_time('今年9月', time_base={'year': 2021})\nres = jio.parse_time('零三年元宵节晚上8点半', time_base=time.time())\nres = jio.parse_time('一万个小时')\nres = jio.parse_time('100天之后', time.time())\nres = jio.parse_time('四月十三', lunar_date=False)\nres = jio.parse_time('每周五下午4点', time.time(), period_results_num=2)\nprint(res)\n\n# {'type': 'time_span', 'definition': 'accurate', 'time': ['2021-09-01 00:00:00', '2021-09-30 23:59:59']}\n# {'type': 'time_point', 'definition': 'accurate', 'time': ['2003-02-15 20:30:00', '2003-02-15 20:30:59']}\n# {'type': 'time_delta', 'definition': 'accurate', 'time': {'hour': 10000.0}}\n# {'type': 'time_span', 'definition': 'blur', 'time': ['2021-10-22 00:00:00', 'inf']}\n# {'type': 'time_period', 'definition': 'accurate', 'time': {'delta': {'day': 7}, \n# {'type': 'time_point', 'definition': 'accurate', 'time': ['2022-04-13 00:00:00', '2022-04-13 23:59:59']}\n#  'point': {'time': [['2021-07-16 16:00:00', '2021-07-16 16:59:59'],\n#                     ['2021-07-23 16:00:00', '2021-07-23 16:59:59']], 'string': '周五下午4点'}}}\n\n```\n\n- [About**time sementic parser**](../../wiki/时间语义解析-说明文档)\n- [All test cases](../../blob/master/test/test_time_parser.py)\n\n\n## Installation\n\n- python>=3.6 and github\n```\n$ git clone https://github.com/dongrixinyu/JioNLP\n$ cd ./JioNLP\n$ pip install .\n```\n- pip\n```\n$ pip install jionlp\n```\n\n\n## Features\n\n- import jionlp and check the main funcs and annotatiosn\n```\n>>> import jionlp as jio\n>>> jio.help()  # input the keywords, such as “回译”, which means back translation\n>>> dir(jio)\n>>> print(jio.extract_parentheses.__doc__)\n```\n- If in Linux, the following command is a replacement of `jio.help()`.\n```\n$ jio_help\n```\n\n- **Star⭐** represents excellent features\n### 1.Gadgets\n\n| Features   | Function name   |Description   |Star   |\n|--------|-------|-------|-------|\n|[**help search tool**](../../wiki/Gadget-说明文档#user-content-查找帮助) |help|if you have no idea of JioNLP features, this tool can help you to scan with keywords | |\n|[**time sementic parser**](../../wiki/时间语义解析-说明文档#user-content-时间语义解析) |parse_time|get the timestamp and span of a given time text |⭐|\n|[**keyphrase extraction**](../../wiki/Gadget-说明文档#user-content-关键短语抽取) |extract_keyphrase|extract the keyphrases of a given text |⭐|\n|[extractive **summary**](../../wiki/Gadget-说明文档#user-content-抽取式文本摘要) |extract_summary|extract the summary of a given text | |\n|[**stopwords filter**](../../wiki/Gadget-说明文档#user-content-去除停用词) |remove_stopwords|delete the stopwords of a given words list generated from a text |⭐|\n|[**sentence spliter**](../../wiki/Gadget-说明文档#user-content-文本分句) |split_sentence|split a text to sentences |⭐|\n|[**location parser**](../../wiki/Gadget-说明文档#user-content-地址解析) |parse_location|get the **province, city, county, town and countryside** name of a location text |⭐|\n|[telephone number parser](../../wiki/Gadget-说明文档#user-content-电话号码归属地运营商解析) |phone_location<br>cell_phone_location<br>landline_phone_location |get the **province, city, communication operators** of a telephone number ||\n|[news **location recognizer**](../../wiki/Gadget-说明文档#user-content-新闻地名识别) |recognize_location|get the **country, province, city, county** name of a news text |⭐|\n|[**solar lunar**date conversion](../../wiki/Gadget-说明文档#user-content-公历农历日期互转)|lunar2solar<br>solar2lunar |translate a lunar (solar) date to the solar (lunar) date ||\n|[**ID cards** parser](../../wiki/Gadget-说明文档#user-content-身份证号码解析) |parse_id_card|get the **province, city, conty, birthday, gender, checking code** of a given Chinese ID card number |⭐|\n|[**idiom solitaire**](../../wiki/Gadget-说明文档#user-content-成语接龙) |idiom_solitaire|a word game that a list of Chinese idioms which the first char of the latter idiom has the same pronunciation with the last char of the former idiom ||\n|[**tranditional** chars to **simplified** chars](../../wiki/Gadget-说明文档#user-content-繁体转简体字) |tra2sim|translate traditional characters to simplified version | |\n|[**simplified** chars to **traditional** chars](../../wiki/Gadget-说明文档#user-content-简体转繁体字) |sim2tra|translate simplified characters to traditional version | |\n|[characters to **pinyin**](../../wiki/Gadget-说明文档#user-content-汉字转拼音) |pinyin|get the pinyin of chinese chars to add pronunciation info to the NLP model input |⭐ |\n|[characters to **radical**](../../wiki/Gadget-说明文档#user-content-汉字转偏旁与字形) |char_radical|get the radical info of Chinese chars to add to the NLP model input |⭐ |\n|[money **numbers to chars**](../../wiki/正则抽取与解析-说明文档#user-content-金额数字转汉字)|money_num2char|get the character of a given money number | |\n\n### 2.Text Augmentation\n\n- [**Description of all text augmentation methods**](../../wiki/数据增强-说明文档#user-content-数据增强方法对比)\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|------|\n|[**back translation**](../../wiki/数据增强-说明文档#user-content-回译数据增强) |BackTranslation|get augmented text via back translation |⭐ |\n|[**swap char position**](../../wiki/数据增强-说明文档#user-content-邻近汉字换位) |swap_char_position|get augmented text via swapping the position of adjacent chars | |\n|[**homophone substitution**](../../wiki/数据增强-说明文档#user-content-同音词替换) |homophone_substitution|replace chars with the same pronunciation to get augmented text |⭐ |\n|[randomly **add & delete chars**](../../wiki/数据增强-说明文档#user-content-随机增删字符) |random_add_delete|add and delete chars randomly in the text to get augmented text | |\n|[NER **entity replacement**](../../wiki/数据增强-说明文档#user-content-ner实体替换) |replace_entity|replace the entity of the text via dictionary to get augmented text |⭐ |\n\n\n### 3.Key info extraction and parsing with regular expression\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|-------|\n|[**clean text**](../../wiki/正则抽取与解析-说明文档#user-content-清洗文本) |clean_text|delete exceptional, redundent chars, HTML tags, parenthesis, url, email, phone nums |⭐ |\n|[extract **E-mail**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-e-mail) |extract_email|extract email info from text | |\n|[parse **money text**](../../wiki/正则抽取与解析-说明文档#user-content-货币金额解析) |extract_money|parse money text |⭐ |\n|[extract **phone number**](../../wiki/正则抽取与解析-说明文档#user-content-抽取电话号码) |extract_phone_number| extract landline and telephone number | |\n|[extract Chinese **ID card** ](../../wiki/正则抽取与解析-说明文档#user-content-抽取身份证号) |extract_id_card|extract Chinese ID card info and parse it with **jio.parse_id_card**| |\n|[extract **QQ**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-qq) |extract_qq|extract tencent QQ number | |\n|[extract **URL**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-url-超链接) |extract_url|extract URL info | |\n|[extract **IP**](../../wiki/正则抽取与解析-说明文档#user-content-抽取-ip-地址) |extract_ip_address|extract IPv4 address| |\n|[extract **parenthesis** info](../../wiki/正则抽取与解析-说明文档#user-content-抽取文本括号信息) |extract_parentheses|extract parenthesis info wrapped by **{}「」[]【】()（）<>《》** |⭐ |\n|[delete **E-mail**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-e-mail) |remove_email|delete E-mail info from the given text | |\n|[delete **URL**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-url) |remove_url |delete URL info| |\n|[delete **phone num**](../../wiki/正则抽取与解析-说明文档#user-content-删除电话号码) |remove_phone_number|delete telephone numbers | |\n|[delete **IP**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-ip-地址)|remove_ip_address|delete IP address | |\n|[delete **Chinese ID card**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的身份证号) |remove_id_card|delete Chinese ID card info | |\n|[delete **QQ**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-qq-号) |remove_qq|delete qq numbers| |\n|[delete **HTML tags**](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的-html-标签) |remove_html_tag|delete HTML tags | |\n|[delete **parenthesis** info](../../wiki/正则抽取与解析-说明文档#user-content-删除文本括号信息) |remove_parentheses|delete parenthesis info wrapped by **{}「」[]【】()（）<>《》** | |\n|[delete exceptional chars](../../wiki/正则抽取与解析-说明文档#user-content-删除文本中的异常字符) |remove_exception_char|delete exceptional chars | |\n\n### 4.file reader and writer\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|-------|\n|[**read file by iteration**](../../wiki/文件读写-说明文档#user-content-文件读取iter) |read_file_by_iter |read file by iteration to get a json list ||\n|[**read file by line**](../../wiki/文件读写-说明文档#user-content-文件读取list) |read_file_by_line |read file to get a json list |⭐ |\n|[write file by line](../../wiki/文件读写-说明文档#user-content-文件写入) |write_file_by_line| write a list of text to the file |⭐ |\n|[get the time consumption](../../wiki/文件读写-说明文档#user-content-计时器) |TimeIt | get the seconds of a given programming consuming | |\n|[jionlp logger](../../wiki/文件读写-说明文档#user-content-日志处理设置函数) |set_logger |the logger used by jionlp | |\n\n### 5.dictionaries\n\n| Features   | Function name   |Description   |Star   |\n|-----|-----|------|------|\n|[**Chinese idiom** dict](../../wiki/词典加载-说明文档#user-content-加载成语词典) |chinese_idiom_loader|load Chinese idiom dictionary |⭐|\n|[**xiehouyu** dict](../../wiki/词典加载-说明文档#user-content-加载歇后语词典) |xiehouyu_loader|load xiehouyu dictionary |⭐|\n|[**Chinese location** dict](../../wiki/词典加载-说明文档#user-content-加载中国省市县地名词典) |china_location_loader|load Chinese location dictionary including province, city, county |⭐|\n|[**Chinese location replacement** dict](../../wiki/词典加载-说明文档#user-content-加载中国区划调整词典) |china_location_change_loader|load replacement info of Chinese location dictionary from 2018 |⭐|\n|[**world wide location** dict](../../wiki/词典加载-说明文档#user-content-加载世界国家城市地名词典) |world_location_loader|load world wide location | |\n|[**Chinese character** dict](../../wiki/词典加载-说明文档#user-content-加载新华字典) |chinese_char_dictionary_loader|load Chinese character dictionary | |\n|[**Chinese word** dict](../../wiki/词典加载-说明文档#user-content-加载新华词典) |chinese_word_dictionary_loader|load Chinese word dictionary | |\n\n### 6.Named Entity Recognition(NER) auxiliary tools\n\n- [NER dateset format description](../../wiki/NER-说明文档#user-content-前言)\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|-------|\n|[extract **money entity**](../../wiki/NER-说明文档#user-content-货币金额实体抽取) |extract_money |extract money entity text from the given text |⭐ |\n|[extract **time entity**](../../wiki/NER-说明文档#user-content-时间实体抽取) |extract_time |extract time entity text from the given text |⭐ |\n|[**Lexicon NER**](../../wiki/NER-说明文档#user-content-基于词典-ner) |LexiconNER|get entities from the text via dictionary |⭐ |\n|[**entity to tag**](../../wiki/NER-说明文档#user-content-entity-转-tag) |entity2tag|convert the entities info to tags for sequence labeling | |\n|[**tag to entity**](../../wiki/NER-说明文档#user-content-tag-转-entity) |tag2entity|convert the tags of sequence labeling to entities | |\n|[**char** token to **word** token](../../wiki/NER-说明文档#user-content-字-token-转词-token) |char2word|convert char token data to word token data | |\n|[**word** token to **char** token](../../wiki/NER-说明文档#user-content-词-token-转字-token) |word2char|convert word token data to char token data | |\n|[**entity compare**](../../wiki/NER-说明文档#user-content-比较-ner-标注实体与模型预测实体之间的差异) |entity_compare|compare the predicted entities with the golden entities |⭐ |\n|[NER **acceleration of prediction**](../../wiki/NER-说明文档#user-content-ner-模型预测加速) |TokenSplitSentence<br>TokenBreakLongSentence<br>TokenBatchBucket|acceleration of NER prediction |⭐ |\n|[**split dataset**](../../wiki/NER-说明文档#user-content-分割数据集) |analyse_dataset|split dataset info training, valid, test part and analyse the KL divergence info  |⭐ |\n|[entity **collector**](../../wiki/NER-说明文档#user-content-实体收集) |collect_dataset_entities|collect all entities from labeled dataset to get a dictionary | |\n\n\n### 7.Text Classification\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|------|\n|[Naive bayes **words analysis**](../../wiki/文本分类-说明文档#user-content-朴素贝叶斯分析类别词汇) |analyse_freq_words|analyse the words frequency of different classes by naive bayes |⭐ |\n|[**split dataset**](../../wiki/文本分类-说明文档#user-content-分割数据集) |analyse_dataset|split dataset info training, valid, test part and analyse the KL divergence info |⭐ |\n\n\n### 8.Sentiment Analysis\n\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|-------|\n|[**sentiment analysis** based on dictionary](../../wiki/情感分析-说明文档#user-content-基于词典的情感分析) |LexiconSentiment|compute the sentiment value(0~1) of a given text | |\n\n### 9.Chinese Word Segmentation(CWS)\n| Features   | Function name   |Description   |Star   |\n|--------|--------|-------|-------|\n|[**word to tag**](../../wiki/分词-说明文档#user-content-word-转-tag) |cws.word2tag|convert the words list to a list of tags for CWS | |\n|[**tag to word**](../../wiki/分词-说明文档#user-content-tag-转-word) |cws.tag2word|convert the list of tags to a words list for CWS | |\n|[**compute F1**](../../wiki/分词-说明文档#user-content-统计-f1-值) |cws.f1|compute F1 value of the CWS models | |\n|[**CWS dataset corrector**](../../wiki/分词-说明文档#user-content-分词数据矫正-标准词典) |cws.CWSDCWithStandardWords |correct the CWS datasets with dictionaries | |\n\n### My Initial Intention\n\n- NLP preprocessing and parsing is significant and time-consuming, especially for Chinese. This library offers a bundle of features to tackle these nasty jobs and you can focus more on training models. \n- If having any suggestions or problems with bugs, you can raise an issue via github.\n\n### Welcome to join the wechat group of NLP technics\n### Please scan the qr code below and send 【进群】\n![image](../../blob/master/image/qrcode_for_gh.jpg)\n### If this tool is useful to your development, please click the github star ⭐\n### Or scan the Paypal or Wechat QR code to donate money (●'◡'●) Thanks ~~\n- [Thanks](../../wiki/致谢篇) for your donation!\n\n![image](../../blob/master/image/payment_code.jpg)\n\\"
        },
        {
          "name": "TODO.txt",
          "type": "blob",
          "size": 1.017578125,
          "content": "- 数据增强 - 其他\n- 其他开放性自然语言文本解析工具\n- simhash 工具\n- 利用各情感分析数据集训练可解释情感分析器\n- 歇后语检索及同义替换\n- 语料信息统计\n- 新词发现\n\n项目的问题与缺点：\n    - 若干模块内部耦合度太高，如“时间语义解析”，原因在于自然语言表达的复杂性，\n      用规则复现自然带来大量的规则判断，而代码在初期是没有摸索好采用什么结构\n      来完成代码工作的，导致后期大量的罕见语言表达会对代码产生众多补丁，从而\n      代码变得难以维护。\n      目前采用的方式即加入大量注释来弥补代码结构的高耦合，在未来应当重新设计\n      代码结构组织代码，对代码进行多层抽象。\n      规则解析自然语言，很大程度上，比较像编译器、解释器中的词法、句法分析器，\n      有相同的地方。可以相互借鉴。\n    - 词典、字典的更新。期待更多的用户提交词典的更新\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "image",
          "type": "tree",
          "content": null
        },
        {
          "name": "jionlp",
          "type": "tree",
          "content": null
        },
        {
          "name": "py_installer.sh",
          "type": "blob",
          "size": 1.25390625,
          "content": "#!/bin/bash\n\n# make sure your python path is like the below ones.\n# python: /home/ubuntu/anaconda3/bin/python\n# working in the directory with `setup.py` file.\n\n# get the latest jionlp version\ncurrent_dir_path=$(pwd)\necho \"Current directory: $current_dir_path\"\n\njionlp_version=`cat ${current_dir_path}/jionlp/__init__.py | grep -iPo \"(?<=(__version__ = \\'))([0-9]{1,2}.[0-9]{1,2}.[0-9]{1,2})\"`\necho \"jionlp version: ${jionlp_version}\"\n\n\n# clean redundant dirs\nif [ -d build ]; then\n    rm -rf build\nfi\nif [ -d jionlp.egg-info ]; then\n    rm -rf jionlp.egg-info\nfi\n\nto_be_deleted=(\n  char_distribution.json\n  china_location.txt\n  chinese_char_dictionary.txt\n  chinese_idiom.txt\n  chinese_word_dictionary.txt\n  idf.txt\n  phone_location.txt\n  pinyin_phrase.txt\n  pornography.txt\n  sentiment_words.txt\n  topic_word_weight.json\n  word_distribution.json\n  word_topic_weight.json\n  xiehouyu.txt)\nfor item in ${to_be_deleted[*]};\ndo\n    if [ -f ./jionlp/dictionary/$item ]; then\n        echo \"deleting redundant file: \" $item\n        rm -rf ./jionlp/dictionary/$item\nfi\ndone\n\n# char_distribution.json\npython3 setup.py bdist_wheel --universal\n\nls -lth ./dist/ | grep ${jionlp_version}\npip install twine\ntwine upload ./dist/jionlp-${jionlp_version}-py2.py3-none-any.whl\n\necho \"finished!\"\nexit 0\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0302734375,
          "content": "numpy\njiojio\nrequests\nzipfile36"
        },
        {
          "name": "run_test.sh",
          "type": "blob",
          "size": 0.0390625,
          "content": "#!/bin/bash\ncd test\npython test_main.py\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.2841796875,
          "content": "# -*- coding=utf-8 -*-\n\"\"\"\n# library: jionlp\n# author: dongrixinyu\n# license: Apache License 2.0\n# Email: dongrixinyu.89@163.com\n# github: https://github.com/dongrixinyu/JioNLP\n# description: Preprocessing & Parsing tool for Chinese NLP\n\"\"\"\n\nimport os\nimport re\nfrom setuptools import setup, find_packages\n\n\nDIR_PATH = os.path.dirname(os.path.abspath(__file__))\nLONG_DOC = '''\n==================================== JioNLP ====================================\n\n中文 NLP 文本预处理与解析工具包，完成 NLP 模型训练前后的预处理与解析，如文本数据增强、\n文本清洗、特定信息抽取、数据集概况分析、模型加速、相关模型任务 baseline、各类词典等。\n\n# 安装：\n    $ pip install jionlp\n\n# 导入：\n    >>> import jionlp as jio\n\n'''\n__version__ = ''\n\nwith open(os.path.join(DIR_PATH, 'README.md'),\n          'r', encoding='utf-8') as f:\n    readme_lines = f.readlines()\n    version_pattern = re.compile('badge/version-(\\d\\.\\d+\\.\\d+)-')\n    for line in readme_lines:\n        result = version_pattern.search(line)\n        if result is not None:\n            __version__ = result.group(1)\n\n    LONG_DOC = '\\n'.join(readme_lines)\n\n__name__ = 'jionlp'\n__author__ = \"dongrixinyu\"\n__copyright__ = \"Copyright 2020, dongrixinyu\"\n__credits__ = list()\n__license__ = \"Apache License 2.0\"\n__maintainer__ = \"dongrixinyu\"\n__email__ = \"dongrixinyu.89@163.com\"\n__url__ = 'https://github.com/dongrixinyu/JioNLP'\n__description__ = 'Chinese NLP Preprocessing & Parsing'\n\n\nwith open(os.path.join(DIR_PATH, 'requirements.txt'),\n          'r', encoding='utf-8') as f:\n    requirements = f.readlines()\n\n# delete test module\njionlp_packages = find_packages()\nif 'test' in jionlp_packages:\n    jionlp_packages.remove('test')\n\nsetup(name=__name__,\n      version=__version__,\n      url=__url__,\n      author=__author__,\n      author_email=__email__,\n      description=__description__,\n      long_description=LONG_DOC,\n      long_description_content_type='text/markdown',\n      license=__license__,\n      py_modules=list(),\n      packages=jionlp_packages,\n      include_package_data=True,\n      install_requires=requirements,\n      entry_points={\n          'console_scripts': [\n              'jio_help = jionlp.util:help',\n          ]\n      },\n      test_suite='nose.collector',\n      tests_require=['nose'])\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}