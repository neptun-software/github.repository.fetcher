{
  "metadata": {
    "timestamp": 1736559929300,
    "page": 698,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "mukulpatnaik/researchgpt",
      "stars": 3558,
      "defaultBranch": "main",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.044921875,
          "content": "MIT License\n\nCopyright (c) 2023 Mukul Patnaik\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.0498046875,
          "content": "## **This repository is no longer actively maintained. A more advanced version of this project is available at [chat.portal.so](https://chat.portal.so) for free and will be open sourced soon.**\n\n# ResearchGPT\n\nThis is a simple fastapi app that provides a clean interface to enable a conversation with any pdf. You can enter a link to a pdf hosted online or upload your own pdf. The app will then extract the text from the pdf, create embeddings from the text and use them with the openai api to generate a response to a question you ask. It will also return a source for the part of the text it used to generate the response and the page number. \n\nTry the demo at: https://www.dara.chat\n\n## Example \n(this video shows some features available on the [live demo](https://www.dara.chat) only )\n\nhttps://user-images.githubusercontent.com/36257370/230793133-ecb579d3-47d9-4200-916a-9c5978a40b09.mp4\n\n## Installation\n\n```bash\ngit clone https://github.com/mukulpatnaik/researchgpt.git\ncd researchgpt\npip install -r requirements.txt\n```\n\nYou also need redis for storing the embeddings locally on your machine. You can find installation instructions here: https://redis.io/docs/getting-started/installation/. To start the db, run the following command in your terminal.\n\nOn MacOS:\n\n```bash\nredis-server\n```\n\nOn Windows:\n\n```bash\nsudo service redis-server start\n```\n\n## Usage\n\nYou need to have an openai api key and set it as the environment variable 'OPENAI_API_KEY'.\n\nYou can get the OpenAI API key here - https://platform.openai.com/account/api-keys\n\nTo set your environment variable open your .bashrc or .zshrc and add the line `export OPENAI_API_KEY=\"your-key`, make sure to put your actual key instead of \"your-key\".\n\n```bash\nuvicorn main:app --reload\n```\n\n## Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n## License\n\n[MIT](https://choosealicense.com/licenses/mit/)\n\nIf you would like to collaborate on this project, please reach out to me at mukulpatnaik@gmail.com or find me on [twitter](https://twitter.com/mukul0x)\n"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 7.73828125,
          "content": "from fastapi import FastAPI, Request\nfrom fastapi.responses import HTMLResponse, JSONResponse\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.templating import Jinja2Templates\nfrom fastapi.staticfiles import StaticFiles\nfrom io import BytesIO\nfrom PyPDF2 import PdfReader\nimport pandas as pd\nfrom openai.embeddings_utils import get_embedding, cosine_similarity\nimport openai\nimport os\nimport requests\nimport redis\nfrom _md5 import md5\n\napp = FastAPI()\n\norigins = [\n    \"http://localhost\",\n    \"http://localhost:3000\",\n]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\ntemplates = Jinja2Templates(directory=\"templates\")\n\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n\ndb = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n\nclass Chatbot():\n\n    def extraxt_txt(self, txt):\n        with open(txt, \"r\") as f:\n            text = f.read()\n        return str(text)\n\n    def extract_pdf(self, pdf):\n        print(\"Parsing paper\")\n        number_of_pages = len(pdf.pages)\n        print(f\"Total number of pages: {number_of_pages}\")\n        paper_text = []\n        for i in range(number_of_pages):\n            page = pdf.pages[i]\n            page_text = []\n\n            def visitor_body(text, cm, tm, fontDict, fontSize):\n                x = tm[4]\n                y = tm[5]\n                # ignore header/footer\n                if (y > 50 and y < 720) and (len(text.strip()) > 1):\n                    page_text.append({\"fontsize\": fontSize, \"text\": text.strip().replace(\"\\x03\", \"\"), \"x\": x, \"y\": y})\n\n            _ = page.extract_text(visitor_text=visitor_body)\n\n            blob_font_size = None\n            blob_text = \"\"\n            processed_text = []\n\n            for t in page_text:\n                if t[\"fontsize\"] == blob_font_size:\n                    blob_text += f\" {t['text']}\"\n                    if len(blob_text) >= 200:\n                        processed_text.append({\"fontsize\": blob_font_size, \"text\": blob_text, \"page\": i})\n                        blob_font_size = None\n                        blob_text = \"\"\n                else:\n                    if blob_font_size is not None and len(blob_text) >= 1:\n                        processed_text.append({\"fontsize\": blob_font_size, \"text\": blob_text, \"page\": i})\n                    blob_font_size = t[\"fontsize\"]\n                    blob_text = t[\"text\"]\n            paper_text += processed_text\n        print(\"Done parsing paper\")\n        return paper_text\n\n    def create_df(self, data):\n\n        if type(data) == list:\n            print(\"Extracting text from pdf\")\n            print(\"Creating dataframe\")\n            filtered_pdf = []\n            # print(pdf.pages[0].extract_text())\n            for row in data:\n                if len(row[\"text\"]) < 30:\n                    continue\n                filtered_pdf.append(row)\n            df = pd.DataFrame(filtered_pdf)\n            # remove elements with identical df[text] and df[page] values\n            df = df.drop_duplicates(subset=[\"text\", \"page\"], keep=\"first\")\n            # df['length'] = df['text'].apply(lambda x: len(x))\n            print(\"Done creating dataframe\")\n\n        elif type(data) == str:\n            print(\"Extracting text from txt\")\n            print(\"Creating dataframe\")\n            # Parse the text and add each paragraph to a column 'text' in a dataframe\n            df = pd.DataFrame(data.split(\"\\n\"), columns=[\"text\"])\n\n        return df\n\n    def embeddings(self, df):\n        print(\"Calculating embeddings\")\n        # openai.api_key = os.getenv('OPENAI_API_KEY')\n        embedding_model = \"text-embedding-ada-002\"\n        embeddings = df.text.apply([lambda x: get_embedding(x, engine=embedding_model)])\n        df[\"embeddings\"] = embeddings\n        print(\"Done calculating embeddings\")\n        return df\n\n    def search(self, df, query, n=3, pprint=True):\n        query_embedding = get_embedding(query, engine=\"text-embedding-ada-002\")\n        df[\"similarity\"] = df.embeddings.apply(lambda x: cosine_similarity(x, query_embedding))\n\n        results = df.sort_values(\"similarity\", ascending=False, ignore_index=True)\n        # make a dictionary of the the first three results with the page number as the key and the text as the value. The page number is a column in the dataframe.\n        results = results.head(n)\n        sources = []\n        for i in range(n):\n            # append the page number and the text as a dict to the sources list\n            sources.append({\"Page \" + str(results.iloc[i][\"page\"]): results.iloc[i][\"text\"][:150] + \"...\"})\n        return {\"results\": results, \"sources\": sources}\n\n    def create_prompt(self, df, user_input):\n        print('Creating prompt')\n        print(user_input)\n\n        result = self.search(df, user_input, n=3)\n        data = result['results']\n        sources = result['sources']\n        system_role = \"\"\"You are a AI assistant whose expertise is reading and summarizing scientific papers. You are given a query, \n        a series of text embeddings and the title from a paper in order of their cosine similarity to the query. \n        You must take the given embeddings and return a very detailed summary of the paper in the languange of the query:\n        \"\"\"\n\n        user_input = user_input + \"\"\"\n        Here are the embeddings:\n\n        1.\"\"\" + str(data.iloc[0]['text']) + \"\"\"\n        2.\"\"\" + str(data.iloc[1]['text']) + \"\"\"\n        3.\"\"\" + str(data.iloc[2]['text']) + \"\"\"\n        \"\"\"\n\n        history = [\n        {\"role\": \"system\", \"content\": system_role},\n        {\"role\": \"user\", \"content\": str(user_input)}]\n\n        print('Done creating prompt')\n        return {'messages': history, 'sources': sources}\n\n    def gpt(self, context, source):\n        print('Sending request to OpenAI')\n        openai.api_key = os.getenv('OPENAI_API_KEY')\n        r = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=context)\n        answer = r.choices[0][\"message\"][\"content\"]\n        print('Done sending request to OpenAI')\n        response = {'answer': answer, 'sources': source}\n        return response\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def index(request: Request):\n    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n@app.post(\"/process_pdf\")\nasync def process_pdf(request: Request):\n    print(\"Processing pdf\")\n    body = await request.body()\n    key = md5(body).hexdigest()\n    print(key)\n\n    if db.get(key) is not None:\n        print(\"Already processed pdf\")\n        return JSONResponse({\"key\": key})\n    \n    file = body\n    pdf = PdfReader(BytesIO(file))\n\n    chatbot = Chatbot()\n    paper_text = chatbot.extract_pdf(pdf)\n    df = chatbot.create_df(paper_text)\n    df = chatbot.embeddings(df)\n\n    if db.get(key) is None:\n        db.set(key, df.to_json())\n\n    print(\"Done processing pdf\")\n    return JSONResponse({\"key\": key})\n\n@app.post(\"/download_pdf\")\nasync def download_pdf(url: str):\n    chatbot = Chatbot()\n    r = requests.get(str(url))\n    key = md5(r.content).hexdigest()\n    if db.get(key) is not None:\n        return JSONResponse({\"key\": key})\n    pdf = PdfReader(BytesIO(r.content))\n    paper_text = chatbot.extract_pdf(pdf)\n    df = chatbot.create_df(paper_text)\n    df = chatbot.embeddings(df)\n    if db.get(key) is None:\n        db.set(key, df.to_json())\n    print(\"Done processing pdf\")\n    return JSONResponse({\"key\": key})\n\n@app.post(\"/reply\")\nasync def reply(request: Request):\n    data = await request.json()\n    key = data.get('key')\n    query = data.get('query')\n    \n    chatbot = Chatbot()\n    query = str(query)\n    df = pd.read_json(BytesIO(db.get(key)))\n    print(df.head(5))\n    prompt = chatbot.create_prompt(df, query)\n\n    chat = []\n    chat.extend(prompt['messages'])\n\n    response = chatbot.gpt(chat, prompt['sources'])\n    print(response)\n    return JSONResponse(content=response, status_code=200)\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.109375,
          "content": "fastapi\nPyPDF2\npandas\nopenai\nrequests\nmatplotlib\nscipy\nplotly\ngunicorn==20.1.0\nscikit-learn==0.24.1\nredis\njinja2"
        },
        {
          "name": "static",
          "type": "tree",
          "content": null
        },
        {
          "name": "templates",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}