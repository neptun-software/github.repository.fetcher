{
  "metadata": {
    "timestamp": 1736559526605,
    "page": 117,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "snakers4/silero-vad",
      "stars": 4700,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2705078125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event. Representation of a project may be\nfurther defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at aveysov@gmail.com. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0498046875,
          "content": "MIT License\n\nCopyright (c) 2020-present Silero Team\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.2265625,
          "content": "[![Mailing list : test](http://img.shields.io/badge/Email-gray.svg?style=for-the-badge&logo=gmail)](mailto:hello@silero.ai) [![Mailing list : test](http://img.shields.io/badge/Telegram-blue.svg?style=for-the-badge&logo=telegram)](https://t.me/silero_speech) [![License: CC BY-NC 4.0](https://img.shields.io/badge/License-MIT-lightgrey.svg?style=for-the-badge)](https://github.com/snakers4/silero-vad/blob/master/LICENSE) [![downloads](https://img.shields.io/pypi/dm/silero-vad?style=for-the-badge)](https://pypi.org/project/silero-vad/)\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/snakers4/silero-vad/blob/master/silero-vad.ipynb)\n\n![header](https://user-images.githubusercontent.com/12515440/89997349-b3523080-dc94-11ea-9906-ca2e8bc50535.png)\n\n<br/>\n<h1 align=\"center\">Silero VAD</h1>\n<br/>\n\n**Silero VAD** - pre-trained enterprise-grade [Voice Activity Detector](https://en.wikipedia.org/wiki/Voice_activity_detection) (also see our [STT models](https://github.com/snakers4/silero-models)).\n\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://github.com/snakers4/silero-vad/assets/36505480/300bd062-4da5-4f19-9736-9c144a45d7a7\" />\n</p>\n\n\n<details>\n<summary>Real Time Example</summary>\n\nhttps://user-images.githubusercontent.com/36505480/144874384-95f80f6d-a4f1-42cc-9be7-004c891dd481.mp4\n\nPlease note, that video loads only if you are logged in your GitHub account. \n\n</details>\n\n<br/>\n\n<h2 align=\"center\">Fast start</h2>\n<br/>\n\n<details>\n<summary>Dependencies</summary>\n\n  System requirements to run python examples on `x86-64` systems:\n  \n  - `python 3.8+`;\n  - 1G+ RAM;\n  - A modern CPU with AVX, AVX2, AVX-512 or AMX instruction sets.\n\n  Dependencies:\n  \n  - `torch>=1.12.0`;\n  - `torchaudio>=0.12.0` (for I/O only);\n  - `onnxruntime>=1.16.1` (for ONNX model usage).\n  \n  Silero VAD uses torchaudio library for audio I/O (`torchaudio.info`, `torchaudio.load`, and `torchaudio.save`), so a proper audio backend is required:\n  \n  - Option №1 - [**FFmpeg**](https://www.ffmpeg.org/) backend. `conda install -c conda-forge 'ffmpeg<7'`;\n  - Option №2 - [**sox_io**](https://pypi.org/project/sox/) backend. `apt-get install sox`, TorchAudio is tested on libsox 14.4.2;\n  - Option №3 - [**soundfile**](https://pypi.org/project/soundfile/) backend. `pip install soundfile`.\n\nIf you are planning to run the VAD using solely the `onnx-runtime`, it will run on any other system architectures where onnx-runtume is [supported](https://onnxruntime.ai/getting-started). In this case please note that:\n\n- You will have to implement the I/O;\n- You will have to adapt the existing wrappers / examples / post-processing for your use-case.\n\n</details>\n\n**Using pip**:\n`pip install silero-vad`\n\n```python3\nfrom silero_vad import load_silero_vad, read_audio, get_speech_timestamps\nmodel = load_silero_vad()\nwav = read_audio('path_to_audio_file')\nspeech_timestamps = get_speech_timestamps(\n  wav,\n  model,\n  return_seconds=True,  # Return speech timestamps in seconds (default is samples)\n)\n```\n\n**Using torch.hub**:\n```python3\nimport torch\ntorch.set_num_threads(1)\n\nmodel, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')\n(get_speech_timestamps, _, read_audio, _, _) = utils\n\nwav = read_audio('path_to_audio_file')\nspeech_timestamps = get_speech_timestamps(\n  wav,\n  model,\n  return_seconds=True,  # Return speech timestamps in seconds (default is samples)\n)\n```\n\n<br/>\n\n<h2 align=\"center\">Key Features</h2>\n<br/>\n\n- **Stellar accuracy**\n\n  Silero VAD has [excellent results](https://github.com/snakers4/silero-vad/wiki/Quality-Metrics#vs-other-available-solutions) on speech detection tasks.\n  \n- **Fast**\n\n  One audio chunk (30+ ms) [takes](https://github.com/snakers4/silero-vad/wiki/Performance-Metrics#silero-vad-performance-metrics) less than **1ms** to be processed on a single CPU thread. Using batching or GPU can also improve performance considerably. Under certain conditions ONNX may even run up to 4-5x faster. \n\n- **Lightweight**\n\n  JIT model is around two megabytes in size.\n\n- **General**\n\n  Silero VAD was trained on huge corpora that include over **6000** languages and it performs well on audios from different domains with various background noise and quality levels.\n\n- **Flexible sampling rate**\n\n  Silero VAD [supports](https://github.com/snakers4/silero-vad/wiki/Quality-Metrics#sample-rate-comparison)  **8000 Hz** and **16000 Hz** [sampling rates](https://en.wikipedia.org/wiki/Sampling_(signal_processing)#Sampling_rate).\n\n- **Highly Portable**\n\n  Silero VAD reaps benefits from the rich ecosystems built around **PyTorch** and **ONNX** running everywhere where these runtimes are available.\n\n- **No Strings Attached**\n\n   Published under permissive license (MIT) Silero VAD has zero strings attached - no telemetry, no keys, no registration, no built-in expiration, no keys or vendor lock.\n\n<br/>\n\n<h2 align=\"center\">Typical Use Cases</h2>\n<br/>\n\n- Voice activity detection for IOT / edge / mobile use cases\n- Data cleaning and preparation, voice detection in general\n- Telephony and call-center automation, voice bots\n- Voice interfaces\n\n<br/>\n<h2 align=\"center\">Links</h2>\n<br/>\n\n\n- [Examples and Dependencies](https://github.com/snakers4/silero-vad/wiki/Examples-and-Dependencies#dependencies)\n- [Quality Metrics](https://github.com/snakers4/silero-vad/wiki/Quality-Metrics)\n- [Performance Metrics](https://github.com/snakers4/silero-vad/wiki/Performance-Metrics)\n- [Versions and Available Models](https://github.com/snakers4/silero-vad/wiki/Version-history-and-Available-Models)\n- [Further reading](https://github.com/snakers4/silero-models#further-reading)\n- [FAQ](https://github.com/snakers4/silero-vad/wiki/FAQ)\n\n<br/>\n<h2 align=\"center\">Get In Touch</h2>\n<br/>\n\nTry our models, create an [issue](https://github.com/snakers4/silero-vad/issues/new), start a [discussion](https://github.com/snakers4/silero-vad/discussions/new), join our telegram [chat](https://t.me/silero_speech), [email](mailto:hello@silero.ai) us, read our [news](https://t.me/silero_news).\n\nPlease see our [wiki](https://github.com/snakers4/silero-models/wiki) for relevant information and [email](mailto:hello@silero.ai) us directly.\n\n**Citations**\n\n```\n@misc{Silero VAD,\n  author = {Silero Team},\n  title = {Silero VAD: pre-trained enterprise-grade Voice Activity Detector (VAD), Number Detector and Language Classifier},\n  year = {2024},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/snakers4/silero-vad}},\n  commit = {insert_some_commit_here},\n  email = {hello@silero.ai}\n}\n```\n\n<br/>\n<h2 align=\"center\">Examples and VAD-based Community Apps</h2>\n<br/>\n\n- Example of VAD ONNX Runtime model usage in [C++](https://github.com/snakers4/silero-vad/tree/master/examples/cpp) \n\n- Voice activity detection for the [browser](https://github.com/ricky0123/vad) using ONNX Runtime Web\n\n- [Rust](https://github.com/snakers4/silero-vad/tree/master/examples/rust-example), [Go](https://github.com/snakers4/silero-vad/tree/master/examples/go), [Java](https://github.com/snakers4/silero-vad/tree/master/examples/java-example), [C++](https://github.com/snakers4/silero-vad/tree/master/examples/cpp), [C#](https://github.com/snakers4/silero-vad/tree/master/examples/csharp) and [other](https://github.com/snakers4/silero-vad/tree/master/examples) community examples\n"
        },
        {
          "name": "datasets",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "files",
          "type": "tree",
          "content": null
        },
        {
          "name": "hubconf.py",
          "type": "blob",
          "size": 1.9453125,
          "content": "dependencies = ['torch', 'torchaudio']\nimport torch\nimport os\nimport sys\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))\nfrom silero_vad.utils_vad import (init_jit_model,\n                                  get_speech_timestamps,\n                                  save_audio,\n                                  read_audio,\n                                  VADIterator,\n                                  collect_chunks,\n                                  OnnxWrapper)\n\n\ndef versiontuple(v):\n    splitted = v.split('+')[0].split(\".\")\n    version_list = []\n    for i in splitted:\n        try:\n            version_list.append(int(i))\n        except:\n            version_list.append(0)\n    return tuple(version_list)\n\n\ndef silero_vad(onnx=False, force_onnx_cpu=False, opset_version=16):\n    \"\"\"Silero Voice Activity Detector\n    Returns a model with a set of utils\n    Please see https://github.com/snakers4/silero-vad for usage examples\n    \"\"\"\n    available_ops = [15, 16]\n    if onnx and opset_version not in available_ops:\n        raise Exception(f'Available ONNX opset_version: {available_ops}')\n\n    if not onnx:\n        installed_version = torch.__version__\n        supported_version = '1.12.0'\n        if versiontuple(installed_version) < versiontuple(supported_version):\n            raise Exception(f'Please install torch {supported_version} or greater ({installed_version} installed)')\n\n    model_dir = os.path.join(os.path.dirname(__file__), 'src', 'silero_vad', 'data')\n    if onnx:\n        if opset_version == 16:\n            model_name = 'silero_vad.onnx'\n        else:\n            model_name = f'silero_vad_16k_op{opset_version}.onnx'\n        model = OnnxWrapper(os.path.join(model_dir, model_name), force_onnx_cpu)\n    else:\n        model = init_jit_model(os.path.join(model_dir, 'silero_vad.jit'))\n    utils = (get_speech_timestamps,\n             save_audio,\n             read_audio,\n             VADIterator,\n             collect_chunks)\n\n    return model, utils\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.048828125,
          "content": "[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n[project]\nname = \"silero-vad\"\nversion = \"5.1.2\"\nauthors = [\n  {name=\"Silero Team\", email=\"hello@silero.ai\"},\n]\ndescription = \"Voice Activity Detector (VAD) by Silero\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n    \"Intended Audience :: Science/Research\",\n    \"Intended Audience :: Developers\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    \"Topic :: Scientific/Engineering\",\n]\ndependencies = [\n  \"torch>=1.12.0\",\n  \"torchaudio>=0.12.0\",\n  \"onnxruntime>=1.16.1\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/snakers4/silero-vad\"\nIssues = \"https://github.com/snakers4/silero-vad/issues\"\n"
        },
        {
          "name": "silero-vad.ipynb",
          "type": "blob",
          "size": 5.8994140625,
          "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"heading_collapsed\": true,\n    \"id\": \"62A6F_072Fwq\"\n   },\n   \"source\": [\n    \"## Install Dependencies\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"hidden\": true,\n    \"id\": \"5w5AkskZ2Fwr\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"#@title Install and Import Dependencies\\n\",\n    \"\\n\",\n    \"# this assumes that you have a relevant version of PyTorch installed\\n\",\n    \"!pip install -q torchaudio\\n\",\n    \"\\n\",\n    \"SAMPLING_RATE = 16000\\n\",\n    \"\\n\",\n    \"import torch\\n\",\n    \"torch.set_num_threads(1)\\n\",\n    \"\\n\",\n    \"from IPython.display import Audio\\n\",\n    \"from pprint import pprint\\n\",\n    \"# download example\\n\",\n    \"torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"pSifus5IilRp\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"USE_PIP = True # download model using pip package or torch.hub\\n\",\n    \"USE_ONNX = False # change this to True if you want to test onnx model\\n\",\n    \"if USE_ONNX:\\n\",\n    \"    !pip install -q onnxruntime\\n\",\n    \"if USE_PIP:\\n\",\n    \"  !pip install -q silero-vad\\n\",\n    \"  from silero_vad import (load_silero_vad,\\n\",\n    \"                          read_audio,\\n\",\n    \"                          get_speech_timestamps,\\n\",\n    \"                          save_audio,\\n\",\n    \"                          VADIterator,\\n\",\n    \"                          collect_chunks)\\n\",\n    \"  model = load_silero_vad(onnx=USE_ONNX)\\n\",\n    \"else:\\n\",\n    \"  model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\\n\",\n    \"                                model='silero_vad',\\n\",\n    \"                                force_reload=True,\\n\",\n    \"                                onnx=USE_ONNX)\\n\",\n    \"\\n\",\n    \"  (get_speech_timestamps,\\n\",\n    \"  save_audio,\\n\",\n    \"  read_audio,\\n\",\n    \"  VADIterator,\\n\",\n    \"  collect_chunks) = utils\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"fXbbaUO3jsrw\"\n   },\n   \"source\": [\n    \"## Speech timestapms from full audio\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"aI_eydBPjsrx\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"wav = read_audio('en_example.wav', sampling_rate=SAMPLING_RATE)\\n\",\n    \"# get speech timestamps from full audio file\\n\",\n    \"speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=SAMPLING_RATE)\\n\",\n    \"pprint(speech_timestamps)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"OuEobLchjsry\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"# merge all speech chunks to one audio\\n\",\n    \"save_audio('only_speech.wav',\\n\",\n    \"           collect_chunks(speech_timestamps, wav), sampling_rate=SAMPLING_RATE)\\n\",\n    \"Audio('only_speech.wav')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"zeO1xCqxUC6w\"\n   },\n   \"source\": [\n    \"## Entire audio inference\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"LjZBcsaTT7Mk\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"wav = read_audio('en_example.wav', sampling_rate=SAMPLING_RATE)\\n\",\n    \"# audio is being splitted into 31.25 ms long pieces\\n\",\n    \"# so output length equals ceil(input_length * 31.25 / SAMPLING_RATE)\\n\",\n    \"predicts = model.audio_forward(wav, sr=SAMPLING_RATE)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"id\": \"iDKQbVr8jsry\"\n   },\n   \"source\": [\n    \"## Stream imitation example\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"q-lql_2Wjsry\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"## using VADIterator class\\n\",\n    \"\\n\",\n    \"vad_iterator = VADIterator(model, sampling_rate=SAMPLING_RATE)\\n\",\n    \"wav = read_audio(f'en_example.wav', sampling_rate=SAMPLING_RATE)\\n\",\n    \"\\n\",\n    \"window_size_samples = 512 if SAMPLING_RATE == 16000 else 256\\n\",\n    \"for i in range(0, len(wav), window_size_samples):\\n\",\n    \"    chunk = wav[i: i+ window_size_samples]\\n\",\n    \"    if len(chunk) < window_size_samples:\\n\",\n    \"      break\\n\",\n    \"    speech_dict = vad_iterator(chunk, return_seconds=True)\\n\",\n    \"    if speech_dict:\\n\",\n    \"        print(speech_dict, end=' ')\\n\",\n    \"vad_iterator.reset_states() # reset model states after each audio\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {\n    \"id\": \"BX3UgwwB2Fwv\"\n   },\n   \"outputs\": [],\n   \"source\": [\n    \"## just probabilities\\n\",\n    \"\\n\",\n    \"wav = read_audio('en_example.wav', sampling_rate=SAMPLING_RATE)\\n\",\n    \"speech_probs = []\\n\",\n    \"window_size_samples = 512 if SAMPLING_RATE == 16000 else 256\\n\",\n    \"for i in range(0, len(wav), window_size_samples):\\n\",\n    \"    chunk = wav[i: i+ window_size_samples]\\n\",\n    \"    if len(chunk) < window_size_samples:\\n\",\n    \"      break\\n\",\n    \"    speech_prob = model(chunk, SAMPLING_RATE).item()\\n\",\n    \"    speech_probs.append(speech_prob)\\n\",\n    \"vad_iterator.reset_states() # reset model states after each audio\\n\",\n    \"\\n\",\n    \"print(speech_probs[:10]) # first 10 chunks predicts\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"colab\": {\n   \"name\": \"silero-vad.ipynb\",\n   \"provenance\": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.8\"\n  },\n  \"toc\": {\n   \"base_numbering\": 1,\n   \"nav_menu\": {},\n   \"number_sections\": true,\n   \"sideBar\": true,\n   \"skip_h1_title\": false,\n   \"title_cell\": \"Table of Contents\",\n   \"title_sidebar\": \"Contents\",\n   \"toc_cell\": false,\n   \"toc_position\": {},\n   \"toc_section_display\": true,\n   \"toc_window_display\": false\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 0\n}\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tuning",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}