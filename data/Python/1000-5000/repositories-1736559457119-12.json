{
  "metadata": {
    "timestamp": 1736559457119,
    "page": 12,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "elceef/dnstwist",
      "stars": 4975,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.05078125,
          "content": "venv/\n# PyCharm project directory\n.idea\n*.pyc\n*.swp\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.7001953125,
          "content": "# docker build -t dnstwist .\n# docker build -t dnstwist:phash --build-arg phash=1 .\n\nFROM debian:stable-slim\nMAINTAINER elceef@gmail.com\n\nWORKDIR /opt/dnstwist\n\nARG phash\n\nRUN apt-get update && \\\nexport DEBIAN_FRONTEND=noninteractive && \\\napt-get install -y --no-install-recommends python3-dnspython python3-tld python3-geoip python3-idna ca-certificates && \\\napt-get install -y python3-ssdeep python3-tlsh && \\\nif [ -n \"$phash\" ]; then apt-get install -y --no-install-recommends python3-pil python3-selenium chromium-driver; fi && \\\napt-get autoremove -y && \\\napt-get clean && \\\nrm -rf /var/lib/apt/lists/*\n\nCOPY dnstwist.py /opt/dnstwist/\nCOPY dictionaries /opt/dnstwist/dictionaries/\n\nENTRYPOINT [\"./dnstwist.py\"]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0859375,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2015-2023 Marcin Ulikowski\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 0.013671875,
          "content": "docs/README.md"
        },
        {
          "name": "dictionaries",
          "type": "tree",
          "content": null
        },
        {
          "name": "dnstwist.py",
          "type": "blob",
          "size": 50.7314453125,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nr'''\n     _           _            _     _\n  __| |_ __  ___| |___      _(_)___| |_\n / _` | '_ \\/ __| __\\ \\ /\\ / / / __| __|\n| (_| | | | \\__ \\ |_ \\ V  V /| \\__ \\ |_\n \\__,_|_| |_|___/\\__| \\_/\\_/ |_|___/\\__|\n\nGenerate and resolve domain variations to detect typo squatting,\nphishing and corporate espionage.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n'''\n\n__author__ = 'Marcin Ulikowski'\n__version__ = '20240812'\n__email__ = 'marcin@ulikowski.pl'\n\nimport re\nimport sys\nimport socket\nsocket.setdefaulttimeout(12.0)\nimport signal\nimport time\nimport argparse\nimport threading\nimport os\nimport json\nimport queue\nimport urllib.request\nimport urllib.parse\nimport gzip\nfrom io import BytesIO\nfrom datetime import datetime\n\ndef _debug(msg):\n\tif 'DEBUG' in os.environ:\n\t\tif isinstance(msg, Exception):\n\t\t\tprint('{}:{} {}'.format(__file__, msg.__traceback__.tb_lineno, str(msg)), file=sys.stderr, flush=True)\n\t\telse:\n\t\t\tprint(str(msg), file=sys.stderr, flush=True)\n\ntry:\n\tfrom PIL import Image\n\tMODULE_PIL = True\nexcept ImportError as e:\n\t_debug(e)\n\tMODULE_PIL = False\n\ntry:\n\tfrom selenium import webdriver\n\tMODULE_SELENIUM = True\nexcept ImportError as e:\n\t_debug(e)\n\tMODULE_SELENIUM = False\n\ntry:\n\tfrom dns.resolver import Resolver, NXDOMAIN, NoNameservers\n\timport dns.rdatatype\n\tfrom dns.exception import DNSException\n\tMODULE_DNSPYTHON = True\nexcept ImportError as e:\n\t_debug(e)\n\tMODULE_DNSPYTHON = False\n\nGEOLITE2_MMDB = os.environ.get('GEOLITE2_MMDB' , os.path.join(os.path.dirname(__file__), 'GeoLite2-Country.mmdb'))\ntry:\n\timport geoip2.database\n\t_ = geoip2.database.Reader(GEOLITE2_MMDB)\nexcept Exception as e:\n\t_debug(e)\n\ttry:\n\t\timport GeoIP\n\t\t_ = GeoIP.new(-1)\n\texcept Exception as e:\n\t\t_debug(e)\n\t\tMODULE_GEOIP = False\n\telse:\n\t\tMODULE_GEOIP = True\n\t\tclass geoip:\n\t\t\tdef __init__(self):\n\t\t\t\tself.reader = GeoIP.new(GeoIP.GEOIP_MEMORY_CACHE)\n\t\t\tdef country_by_addr(self, ipaddr):\n\t\t\t\treturn self.reader.country_name_by_addr(ipaddr)\nelse:\n\tMODULE_GEOIP = True\n\tclass geoip:\n\t\tdef __init__(self):\n\t\t\tself.reader = geoip2.database.Reader(GEOLITE2_MMDB)\n\t\tdef country_by_addr(self, ipaddr):\n\t\t\treturn self.reader.country(ipaddr).country.name\n\ntry:\n\timport ssdeep\n\tMODULE_SSDEEP = True\nexcept ImportError as e:\n\t_debug(e)\n\ttry:\n\t\timport ppdeep as ssdeep\n\t\tMODULE_SSDEEP = True\n\texcept ImportError as e:\n\t\t_debug(e)\n\t\tMODULE_SSDEEP = False\n\ntry:\n\timport tlsh\n\tMODULE_TLSH = True\nexcept ImportError as e:\n\t_debug(e)\n\tMODULE_TLSH = False\n\ntry:\n\timport idna\nexcept ImportError as e:\n\t_debug(e)\n\tclass idna:\n\t\t@staticmethod\n\t\tdef decode(domain):\n\t\t\treturn domain.encode().decode('idna')\n\t\t@staticmethod\n\t\tdef encode(domain):\n\t\t\treturn domain.encode('idna')\n\n\nVALID_FQDN_REGEX = re.compile(r'(?=^.{4,253}$)(^((?!-)[a-z0-9-]{1,63}(?<!-)\\.)+[a-z0-9-]{2,63}$)', re.IGNORECASE)\nUSER_AGENT_STRING = 'Mozilla/5.0 ({} {}-bit) dnstwist/{}'.format(sys.platform, sys.maxsize.bit_length() + 1, __version__)\n\nREQUEST_TIMEOUT_DNS = 2.5\nREQUEST_RETRIES_DNS = 2\nREQUEST_TIMEOUT_HTTP = 5\nREQUEST_TIMEOUT_SMTP = 5\nTHREAD_COUNT_DEFAULT = min(32, os.cpu_count() + 4)\n\nif sys.platform != 'win32' and sys.stdout.isatty():\n\tFG_RND = '\\x1b[3{}m'.format(int(time.time())%8+1)\n\tFG_YEL = '\\x1b[33m'\n\tFG_CYA = '\\x1b[36m'\n\tFG_BLU = '\\x1b[34m'\n\tFG_RST = '\\x1b[39m'\n\tST_BRI = '\\x1b[1m'\n\tST_CLR = '\\x1b[1K'\n\tST_RST = '\\x1b[0m'\nelse:\n\tFG_RND = FG_YEL = FG_CYA = FG_BLU = FG_RST = ST_BRI = ST_CLR = ST_RST = ''\n\ndevnull = os.devnull\n\n\ndef domain_tld(domain):\n\ttry:\n\t\tfrom tld import parse_tld\n\texcept ImportError:\n\t\tctld = ['org', 'com', 'net', 'gov', 'edu', 'co', 'mil', 'nom', 'ac', 'info', 'biz']\n\t\td = domain.rsplit('.', 3)\n\t\tif len(d) < 2:\n\t\t\treturn '', d[0], ''\n\t\tif len(d) == 2:\n\t\t\treturn '', d[0], d[1]\n\t\tif len(d) > 2:\n\t\t\tif d[-2] in ctld:\n\t\t\t\treturn '.'.join(d[:-3]), d[-3], '.'.join(d[-2:])\n\t\t\telse:\n\t\t\t\treturn '.'.join(d[:-2]), d[-2], d[-1]\n\telse:\n\t\td = parse_tld(domain, fix_protocol=True)[::-1]\n\t\tif d[1:] == d[:-1] and None in d:\n\t\t\td = tuple(domain.rsplit('.', 2))\n\t\t\td = ('',) * (3-len(d)) + d\n\t\treturn d\n\n\nclass Whois():\n\tWHOIS_IANA = 'whois.iana.org'\n\tTIMEOUT = 2.0\n\tWHOIS_TLD = {\n\t\t'com': 'whois.verisign-grs.com',\n\t\t'net': 'whois.verisign-grs.com',\n\t\t'org': 'whois.pir.org',\n\t\t'info': 'whois.afilias.net',\n\t\t'pl': 'whois.dns.pl',\n\t\t'us': 'whois.nic.us',\n\t\t'co': 'whois.nic.co',\n\t\t'cn': 'whois.cnnic.cn',\n\t\t'ru': 'whois.tcinet.ru',\n\t\t'in': 'whois.registry.in',\n\t\t'eu': 'whois.eu',\n\t\t'uk': 'whois.nic.uk',\n\t\t'de': 'whois.denic.de',\n\t\t'nl': 'whois.domain-registry.nl',\n\t\t'br': 'whois.registro.br',\n\t\t'jp': 'whois.jprs.jp',\n\t}\n\n\tdef __init__(self):\n\t\tself.whois_tld = self.WHOIS_TLD\n\n\tdef _brute_datetime(self, s):\n\t\tformats = ('%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%d %H:%M:%S%z', '%Y-%m-%d %H:%M', '%Y.%m.%d %H:%M',\n\t\t\t'%Y.%m.%d %H:%M:%S', '%d.%m.%Y %H:%M:%S', '%a %b %d %Y', '%d-%b-%Y', '%Y-%m-%d')\n\t\tfor f in formats:\n\t\t\ttry:\n\t\t\t\tdt = datetime.strptime(s, f)\n\t\t\t\treturn dt\n\t\t\texcept ValueError:\n\t\t\t\tpass\n\t\treturn None\n\n\tdef _extract(self, response):\n\t\tfields = {\n\t\t\t'registrar': (r'[\\r\\n]registrar[ .]*:\\s+(?:name:\\s)?(?P<registrar>[^\\r\\n]+)', str),\n\t\t\t'creation_date': (r'[\\r\\n](?:created(?: on)?|creation date|registered(?: on)?)[ .]*:\\s+(?P<creation_date>[^\\r\\n]+)', self._brute_datetime),\n\t\t}\n\t\tresult = {'text': response}\n\t\tresponse_reduced = '\\r\\n'.join([x.strip() for x in response.splitlines() if not x.startswith('%')])\n\t\tfor field, (pattern, func) in fields.items():\n\t\t\tmatch = re.search(pattern, response_reduced, re.IGNORECASE | re.MULTILINE)\n\t\t\tif match:\n\t\t\t\tresult[field] = func(match.group(1))\n\t\t\telse:\n\t\t\t\tresult[field] = None\n\t\treturn result\n\n\tdef query(self, query, server=None):\n\t\t_, _, tld = domain_tld(query)\n\t\tserver = server or self.whois_tld.get(tld, self.WHOIS_IANA)\n\t\tsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\t\tsock.settimeout(self.TIMEOUT)\n\t\tresponse = b''\n\t\ttry:\n\t\t\tsock.connect((server, 43))\n\t\t\tsock.send(query.encode() + b'\\r\\n')\n\t\t\twhile True:\n\t\t\t\tbuf = sock.recv(4096)\n\t\t\t\tif not buf:\n\t\t\t\t\tbreak\n\t\t\t\tresponse += buf\n\t\t\tif server and server != self.WHOIS_IANA and tld not in self.whois_tld:\n\t\t\t\tself.whois_tld[tld] = server\n\t\texcept (socket.timeout, socket.gaierror):\n\t\t\treturn ''\n\t\tfinally:\n\t\t\tsock.close()\n\t\tresponse = response.decode('utf-8', errors='ignore')\n\t\trefer = re.search(r'refer:\\s+(?P<server>[-.a-z0-9]+)', response, re.IGNORECASE | re.MULTILINE)\n\t\tif refer:\n\t\t\treturn self.query(query, refer.group('server'))\n\t\treturn response\n\n\tdef whois(self, domain, server=None):\n\t\treturn self._extract(self.query(domain, server))\n\n\nclass UrlOpener():\n\tdef __init__(self, url, timeout=REQUEST_TIMEOUT_HTTP, headers={}, verify=True):\n\t\thttp_headers = {'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9',\n\t\t\t'accept-encoding': 'gzip,identity',\n\t\t\t'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8'}\n\t\tfor h, v in headers.items():\n\t\t\t# do not override accepted encoding - only gzip,identity is supported\n\t\t\tif h.lower() != 'accept-encoding':\n\t\t\t\thttp_headers[h.lower()] = v\n\t\tif verify:\n\t\t\tctx = urllib.request.ssl.create_default_context()\n\t\telse:\n\t\t\tctx = urllib.request.ssl._create_unverified_context()\n\t\trequest = urllib.request.Request(url, headers=http_headers)\n\t\twith urllib.request.urlopen(request, timeout=timeout, context=ctx) as r:\n\t\t\tself.headers = r.headers\n\t\t\tself.code = r.code\n\t\t\tself.reason = r.reason\n\t\t\tself.url = r.url\n\t\t\tself.content = r.read()\n\t\tif self.content[:3] == b'\\x1f\\x8b\\x08':\n\t\t\tself.content = gzip.decompress(self.content)\n\t\tif 64 < len(self.content) < 1024:\n\t\t\ttry:\n\t\t\t\tmeta_url = re.search(r'<meta[^>]*?url=(https?://[\\w.,?!:;/*#@$&+=[\\]()%~-]*?)\"', self.content.decode(), re.IGNORECASE)\n\t\t\texcept Exception:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tif meta_url:\n\t\t\t\t\tself.__init__(meta_url.group(1), timeout=timeout, headers=http_headers, verify=verify)\n\t\tself.normalized_content = self._normalize()\n\n\tdef _normalize(self):\n\t\tcontent = b' '.join(self.content.split())\n\t\tmapping = dict({\n\t\t\tb'(action|src|href)=\".+\"': lambda m: m.group(0).split(b'=')[0] + b'=\"\"',\n\t\t\tb'url(.+)': b'url()',\n\t\t\t})\n\t\tfor pattern, repl in mapping.items():\n\t\t\tcontent = re.sub(pattern, repl, content, flags=re.IGNORECASE)\n\t\treturn content\n\n\nclass UrlParser():\n\tdef __init__(self, url):\n\t\tif not url:\n\t\t\traise TypeError('argument has to be non-empty string')\n\t\tu = urllib.parse.urlparse(url if '://' in url else '//' + url, scheme='http')\n\t\tself.scheme = u.scheme.lower()\n\t\tif self.scheme not in ('http', 'https'):\n\t\t\traise ValueError('invalid scheme') from None\n\t\tself.domain = u.hostname.lower()\n\t\ttry:\n\t\t\tself.domain = idna.encode(self.domain).decode()\n\t\texcept Exception:\n\t\t\traise ValueError('invalid domain name') from None\n\t\tif not self._validate_domain(self.domain):\n\t\t\traise ValueError('invalid domain name') from None\n\t\tself.username = u.username\n\t\tself.password = u.password\n\t\tself.port = u.port\n\t\tself.path = u.path\n\t\tself.query = u.query\n\t\tself.fragment = u.fragment\n\n\tdef _validate_domain(self, domain):\n\t\tif len(domain) < 1 or len(domain) > 253:\n\t\t\treturn False\n\t\tif VALID_FQDN_REGEX.match(domain):\n\t\t\ttry:\n\t\t\t\t_ = idna.decode(domain)\n\t\t\texcept Exception:\n\t\t\t\treturn False\n\t\t\telse:\n\t\t\t\treturn True\n\t\treturn False\n\n\tdef full_uri(self, domain=None):\n\t\turi = '{}://'.format(self.scheme)\n\t\tif self.username:\n\t\t\turi += self.username\n\t\t\tif self.password:\n\t\t\t\turi += ':{}'.format(self.password)\n\t\t\turi += '@'\n\t\turi += self.domain if not domain else domain\n\t\tif self.port:\n\t\t\turi += ':{}'.format(self.port)\n\t\tif self.path:\n\t\t\turi += self.path\n\t\tif self.query:\n\t\t\turi += '?{}'.format(self.query)\n\t\tif self.fragment:\n\t\t\turi += '#{}'.format(self.fragment)\n\t\treturn uri\n\n\nclass Permutation(dict):\n\tdef __getattr__(self, item):\n\t\tif item in self:\n\t\t\treturn self[item]\n\t\traise AttributeError(\"object has no attribute '{}'\".format(item)) from None\n\n\t__setattr__ = dict.__setitem__\n\n\tdef __init__(self, **kwargs):\n\t\tsuper(dict, self).__init__()\n\t\tself['fuzzer'] = kwargs.pop('fuzzer', '')\n\t\tself['domain'] = kwargs.pop('domain', '')\n\t\tfor k, v in kwargs.items():\n\t\t\tself[k] = v\n\n\tdef __hash__(self):\n\t\treturn hash(self['domain'])\n\n\tdef __eq__(self, other):\n\t\treturn self['domain'] == other['domain']\n\n\tdef __lt__(self, other):\n\t\tif self['fuzzer'] == other['fuzzer']:\n\t\t\tif len(self) > 2 and len(other) > 2:\n\t\t\t\treturn self.get('dns_a', [''])[0] + self['domain'] < other.get('dns_a', [''])[0] + other['domain']\n\t\t\telse:\n\t\t\t\treturn self['domain'] < other['domain']\n\t\treturn self['fuzzer'] < other['fuzzer']\n\n\tdef is_registered(self):\n\t\treturn len(self) > 2\n\n\tdef copy(self):\n\t\treturn Permutation(**self)\n\n\nclass pHash():\n\tdef __init__(self, image, hsize=8):\n\t\timg = Image.open(image).convert('L').resize((hsize, hsize), Image.LANCZOS)\n\t\tpixels = list(img.getdata())\n\t\tavg = sum(pixels) / len(pixels)\n\t\tself.hash = ''.join('1' if p > avg else '0' for p in pixels)\n\n\tdef __sub__(self, other):\n\t\tbc = len(self.hash)\n\t\tham = sum(x != y for x, y in list(zip(self.hash, other.hash)))\n\t\te = 2.718281828459045\n\t\tsub = int((1 + e**((bc - ham) / bc) - e) * 100)\n\t\treturn sub if sub > 0 else 0\n\n\tdef __repr__(self):\n\t\treturn '{:x}'.format(int(self.hash, base=2))\n\n\tdef __int__(self):\n\t\treturn int(self.hash, base=2)\n\n\nclass HeadlessBrowser():\n\tWEBDRIVER_TIMEOUT = 12\n\tWEBDRIVER_ARGUMENTS = (\n\t\t'--disable-dev-shm-usage',\n\t\t'--ignore-certificate-errors',\n\t\t'--headless',\n\t\t'--incognito',\n\t\t'--no-sandbox',\n\t\t'--disable-gpu',\n\t\t'--disable-extensions',\n\t\t'--disk-cache-size=0',\n\t\t'--aggressive-cache-discard',\n\t\t'--disable-notifications',\n\t\t'--disable-remote-fonts',\n\t\t'--disable-sync',\n\t\t'--window-size=1366,768',\n\t\t'--hide-scrollbars',\n\t\t'--disable-audio-output',\n\t\t'--dns-prefetch-disable',\n\t\t'--no-default-browser-check',\n\t\t'--disable-background-networking',\n\t\t'--enable-features=NetworkService,NetworkServiceInProcess',\n\t\t'--disable-background-timer-throttling',\n\t\t'--disable-backgrounding-occluded-windows',\n\t\t'--disable-breakpad',\n\t\t'--disable-client-side-phishing-detection',\n\t\t'--disable-component-extensions-with-background-pages',\n\t\t'--disable-default-apps',\n\t\t'--disable-features=TranslateUI',\n\t\t'--disable-hang-monitor',\n\t\t'--disable-ipc-flooding-protection',\n\t\t'--disable-prompt-on-repost',\n\t\t'--disable-renderer-backgrounding',\n\t\t'--force-color-profile=srgb',\n\t\t'--metrics-recording-only',\n\t\t'--no-first-run',\n\t\t'--password-store=basic',\n\t\t'--use-mock-keychain',\n\t\t'--disable-blink-features=AutomationControlled',\n\t\t)\n\n\tdef __init__(self, useragent=None):\n\t\tchrome_options = webdriver.ChromeOptions()\n\t\tfor opt in self.WEBDRIVER_ARGUMENTS:\n\t\t\tchrome_options.add_argument(opt)\n\t\tproxies = urllib.request.getproxies()\n\t\tif proxies:\n\t\t\tproxy_string = ';'.join(['{}={}'.format(scheme, url) for scheme, url in proxies.items()])\n\t\t\tchrome_options.add_argument('--proxy-server={}'.format(proxy_string))\n\t\tchrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])\n\t\tchrome_options.add_experimental_option('useAutomationExtension', False)\n\t\tself.driver = webdriver.Chrome(options=chrome_options)\n\t\tself.driver.set_page_load_timeout(self.WEBDRIVER_TIMEOUT)\n\t\tself.driver.execute_cdp_cmd('Network.setUserAgentOverride', {'userAgent':\n\t\t\tuseragent or self.driver.execute_script('return navigator.userAgent').replace('Headless', '')\n\t\t\t})\n\t\tself.get = self.driver.get\n\t\tself.screenshot = self.driver.get_screenshot_as_png\n\n\tdef stop(self):\n\t\ttry:\n\t\t\tself.driver.close()\n\t\t\tself.driver.quit()\n\t\texcept Exception:\n\t\t\tpass\n\t\ttry:\n\t\t\tpid = True\n\t\t\twhile pid:\n\t\t\t\tpid, status = os.waitpid(-1, os.WNOHANG)\n\t\texcept ChildProcessError:\n\t\t\tpass\n\n\tdef __del__(self):\n\t\tself.stop()\n\n\nclass Fuzzer():\n\tglyphs_idn_by_tld = {\n\t\t**dict.fromkeys(['ad', 'cz', 'sk', 'uk', 'co.uk', 'nl', 'edu', 'us'], {\n\t\t\t# IDN not supported by the corresponding registry\n\t\t}),\n\t\t**dict.fromkeys(['jp', 'co.jp', 'ad.jp', 'ne.jp'], {\n\t\t}),\n\t\t**dict.fromkeys(['cn', 'com.cn', 'tw', 'com.tw', 'net.tw'], {\n\t\t}),\n\t\t**dict.fromkeys(['info'], {\n\t\t\t'a': ('á', 'ä', 'å', 'ą'),\n\t\t\t'c': ('ć', 'č'),\n\t\t\t'e': ('é', 'ė', 'ę'),\n\t\t\t'i': ('í', 'į'),\n\t\t\t'l': ('ł',),\n\t\t\t'n': ('ñ', 'ń'),\n\t\t\t'o': ('ó', 'ö', 'ø', 'ő'),\n\t\t\t's': ('ś', 'š'),\n\t\t\t'u': ('ú', 'ü', 'ū', 'ű', 'ų'),\n\t\t\t'z': ('ź', 'ż', 'ž'),\n\t\t\t'ae': ('æ',),\n\t\t}),\n\t\t**dict.fromkeys(['br', 'com.br'], {\n\t\t\t'a': ('à', 'á', 'â', 'ã'),\n\t\t\t'c': ('ç',),\n\t\t\t'e': ('é', 'ê'),\n\t\t\t'i': ('í',),\n\t\t\t'o': ('ó', 'ô', 'õ'),\n\t\t\t'u': ('ú', 'ü'),\n\t\t\t'y': ('ý', 'ÿ'),\n\t\t}),\n\t\t**dict.fromkeys(['dk'], {\n\t\t\t'a': ('ä', 'å'),\n\t\t\t'e': ('é',),\n\t\t\t'o': ('ö', 'ø'),\n\t\t\t'u': ('ü',),\n\t\t\t'ae': ('æ',),\n\t\t}),\n\t\t**dict.fromkeys(['eu', 'de', 'pl'], {\n\t\t\t'a': ('á', 'à', 'ă', 'â', 'å', 'ä', 'ã', 'ą', 'ā'),\n\t\t\t'c': ('ć', 'ĉ', 'č', 'ċ', 'ç'),\n\t\t\t'd': ('ď', 'đ'),\n\t\t\t'e': ('é', 'è', 'ĕ', 'ê', 'ě', 'ë', 'ė', 'ę', 'ē'),\n\t\t\t'g': ('ğ', 'ĝ', 'ġ', 'ģ'),\n\t\t\t'h': ('ĥ', 'ħ'),\n\t\t\t'i': ('í', 'ì', 'ĭ', 'î', 'ï', 'ĩ', 'į', 'ī'),\n\t\t\t'j': ('ĵ',),\n\t\t\t'k': ('ķ', 'ĸ'),\n\t\t\t'l': ('ĺ', 'ľ', 'ļ', 'ł'),\n\t\t\t'n': ('ń', 'ň', 'ñ', 'ņ'),\n\t\t\t'o': ('ó', 'ò', 'ŏ', 'ô', 'ö', 'ő', 'õ', 'ø', 'ō'),\n\t\t\t'r': ('ŕ', 'ř', 'ŗ'),\n\t\t\t's': ('ś', 'ŝ', 'š', 'ş'),\n\t\t\t't': ('ť', 'ţ', 'ŧ'),\n\t\t\t'u': ('ú', 'ù', 'ŭ', 'û', 'ů', 'ü', 'ű', 'ũ', 'ų', 'ū'),\n\t\t\t'w': ('ŵ',),\n\t\t\t'y': ('ý', 'ŷ', 'ÿ'),\n\t\t\t'z': ('ź', 'ž', 'ż'),\n\t\t\t'ae': ('æ',),\n\t\t\t'oe': ('œ',),\n\t\t}),\n\t\t**dict.fromkeys(['fi'], {\n\t\t\t'3': ('ʒ',),\n\t\t\t'a': ('á', 'ä', 'å', 'â'),\n\t\t\t'c': ('č',),\n\t\t\t'd': ('đ',),\n\t\t\t'g': ('ǧ', 'ǥ'),\n\t\t\t'k': ('ǩ',),\n\t\t\t'n': ('ŋ',),\n\t\t\t'o': ('õ', 'ö'),\n\t\t\t's': ('š',),\n\t\t\t't': ('ŧ',),\n\t\t\t'z': ('ž',),\n\t\t}),\n\t\t**dict.fromkeys(['no'], {\n\t\t\t'a': ('á', 'à', 'ä', 'å'),\n\t\t\t'c': ('č', 'ç'),\n\t\t\t'e': ('é', 'è', 'ê'),\n\t\t\t'i': ('ï',),\n\t\t\t'n': ('ŋ', 'ń', 'ñ'),\n\t\t\t'o': ('ó', 'ò', 'ô', 'ö', 'ø'),\n\t\t\t's': ('š',),\n\t\t\t't': ('ŧ',),\n\t\t\t'u': ('ü',),\n\t\t\t'z': ('ž',),\n\t\t\t'ae': ('æ',),\n\t\t}),\n\t\t**dict.fromkeys(['be', 'fr', 're', 'yt', 'pm', 'wf', 'tf', 'ch', 'li'], {\n\t\t\t'a': ('à', 'á', 'â', 'ã', 'ä', 'å'),\n\t\t\t'c': ('ç',),\n\t\t\t'e': ('è', 'é', 'ê', 'ë'),\n\t\t\t'i': ('ì', 'í', 'î', 'ï'),\n\t\t\t'n': ('ñ',),\n\t\t\t'o': ('ò', 'ó', 'ô', 'õ', 'ö'),\n\t\t\t'u': ('ù', 'ú', 'û', 'ü'),\n\t\t\t'y': ('ý', 'ÿ'),\n\t\t\t'ae': ('æ',),\n\t\t\t'oe': ('œ',),\n\t\t}),\n\t\t**dict.fromkeys(['ca'], {\n\t\t\t'a': ('à', 'â'),\n\t\t\t'c': ('ç',),\n\t\t\t'e': ('è', 'é', 'ê', 'ë'),\n\t\t\t'i': ('î', 'ï'),\n\t\t\t'o': ('ô',),\n\t\t\t'u': ('ù', 'û', 'ü'),\n\t\t\t'y': ('ÿ',),\n\t\t\t'ae': ('æ',),\n\t\t\t'oe': ('œ',),\n\t\t}),\n\t}\n\n\tglyphs_unicode = {\n\t\t'2': ('ƻ',),\n\t\t'3': ('ʒ',),\n\t\t'5': ('ƽ',),\n\t\t'a': ('ạ', 'ă', 'ȧ', 'ɑ', 'å', 'ą', 'â', 'ǎ', 'á', 'ə', 'ä', 'ã', 'ā', 'à'),\n\t\t'b': ('ḃ', 'ḅ', 'ƅ', 'ʙ', 'ḇ', 'ɓ'),\n\t\t'c': ('č', 'ᴄ', 'ċ', 'ç', 'ć', 'ĉ', 'ƈ'),\n\t\t'd': ('ď', 'ḍ', 'ḋ', 'ɖ', 'ḏ', 'ɗ', 'ḓ', 'ḑ', 'đ'),\n\t\t'e': ('ê', 'ẹ', 'ę', 'è', 'ḛ', 'ě', 'ɇ', 'ė', 'ĕ', 'é', 'ë', 'ē', 'ȩ'),\n\t\t'f': ('ḟ', 'ƒ'),\n\t\t'g': ('ǧ', 'ġ', 'ǵ', 'ğ', 'ɡ', 'ǥ', 'ĝ', 'ģ', 'ɢ'),\n\t\t'h': ('ȟ', 'ḫ', 'ḩ', 'ḣ', 'ɦ', 'ḥ', 'ḧ', 'ħ', 'ẖ', 'ⱨ', 'ĥ'),\n\t\t'i': ('ɩ', 'ǐ', 'í', 'ɪ', 'ỉ', 'ȋ', 'ɨ', 'ï', 'ī', 'ĩ', 'ị', 'î', 'ı', 'ĭ', 'į', 'ì'),\n\t\t'j': ('ǰ', 'ĵ', 'ʝ', 'ɉ'),\n\t\t'k': ('ĸ', 'ǩ', 'ⱪ', 'ḵ', 'ķ', 'ᴋ', 'ḳ'),\n\t\t'l': ('ĺ', 'ł', 'ɫ', 'ļ', 'ľ'),\n\t\t'm': ('ᴍ', 'ṁ', 'ḿ', 'ṃ', 'ɱ'),\n\t\t'n': ('ņ', 'ǹ', 'ń', 'ň', 'ṅ', 'ṉ', 'ṇ', 'ꞑ', 'ñ', 'ŋ'),\n\t\t'o': ('ö', 'ó', 'ȯ', 'ỏ', 'ô', 'ᴏ', 'ō', 'ò', 'ŏ', 'ơ', 'ő', 'õ', 'ọ', 'ø'),\n\t\t'p': ('ṗ', 'ƿ', 'ƥ', 'ṕ'),\n\t\t'q': ('ʠ',),\n\t\t'r': ('ʀ', 'ȓ', 'ɍ', 'ɾ', 'ř', 'ṛ', 'ɽ', 'ȑ', 'ṙ', 'ŗ', 'ŕ', 'ɼ', 'ṟ'),\n\t\t's': ('ṡ', 'ș', 'ŝ', 'ꜱ', 'ʂ', 'š', 'ś', 'ṣ', 'ş'),\n\t\t't': ('ť', 'ƫ', 'ţ', 'ṭ', 'ṫ', 'ț', 'ŧ'),\n\t\t'u': ('ᴜ', 'ų', 'ŭ', 'ū', 'ű', 'ǔ', 'ȕ', 'ư', 'ù', 'ů', 'ʉ', 'ú', 'ȗ', 'ü', 'û', 'ũ', 'ụ'),\n\t\t'v': ('ᶌ', 'ṿ', 'ᴠ', 'ⱴ', 'ⱱ', 'ṽ'),\n\t\t'w': ('ᴡ', 'ẇ', 'ẅ', 'ẃ', 'ẘ', 'ẉ', 'ⱳ', 'ŵ', 'ẁ'),\n\t\t'x': ('ẋ', 'ẍ'),\n\t\t'y': ('ŷ', 'ÿ', 'ʏ', 'ẏ', 'ɏ', 'ƴ', 'ȳ', 'ý', 'ỿ', 'ỵ'),\n\t\t'z': ('ž', 'ƶ', 'ẓ', 'ẕ', 'ⱬ', 'ᴢ', 'ż', 'ź', 'ʐ'),\n\t\t'ae': ('æ',),\n\t\t'oe': ('œ',),\n\t}\n\n\tglyphs_ascii = {\n\t\t'0': ('o',),\n\t\t'1': ('l', 'i'),\n\t\t'3': ('8',),\n\t\t'6': ('9',),\n\t\t'8': ('3',),\n\t\t'9': ('6',),\n\t\t'b': ('d', 'lb'),\n\t\t'c': ('e',),\n\t\t'd': ('b', 'cl', 'dl'),\n\t\t'e': ('c',),\n\t\t'g': ('q',),\n\t\t'h': ('lh',),\n\t\t'i': ('1', 'l'),\n\t\t'k': ('lc',),\n\t\t'l': ('1', 'i'),\n\t\t'm': ('n', 'nn', 'rn'),\n\t\t'n': ('m', 'r'),\n\t\t'o': ('0',),\n\t\t'q': ('g',),\n\t\t'u': ('v',),\n\t\t'v': ('u',),\n\t\t'w': ('vv',),\n\t\t'rn': ('m',),\n\t\t'cl': ('d',),\n\t}\n\n\tlatin_to_cyrillic = {\n\t\t'a': 'а', 'b': 'ь', 'c': 'с', 'd': 'ԁ', 'e': 'е', 'g': 'ԍ', 'h': 'һ',\n\t\t'i': 'і', 'j': 'ј', 'k': 'к', 'l': 'ӏ', 'm': 'м', 'o': 'о', 'p': 'р',\n\t\t'q': 'ԛ', 's': 'ѕ', 't': 'т', 'v': 'ѵ', 'w': 'ԝ', 'x': 'х', 'y': 'у',\n\t}\n\n\tqwerty = {\n\t\t'1': '2q', '2': '3wq1', '3': '4ew2', '4': '5re3', '5': '6tr4', '6': '7yt5', '7': '8uy6', '8': '9iu7', '9': '0oi8', '0': 'po9',\n\t\t'q': '12wa', 'w': '3esaq2', 'e': '4rdsw3', 'r': '5tfde4', 't': '6ygfr5', 'y': '7uhgt6', 'u': '8ijhy7', 'i': '9okju8', 'o': '0plki9', 'p': 'lo0',\n\t\t'a': 'qwsz', 's': 'edxzaw', 'd': 'rfcxse', 'f': 'tgvcdr', 'g': 'yhbvft', 'h': 'ujnbgy', 'j': 'ikmnhu', 'k': 'olmji', 'l': 'kop',\n\t\t'z': 'asx', 'x': 'zsdc', 'c': 'xdfv', 'v': 'cfgb', 'b': 'vghn', 'n': 'bhjm', 'm': 'njk'\n\t}\n\tqwertz = {\n\t\t'1': '2q', '2': '3wq1', '3': '4ew2', '4': '5re3', '5': '6tr4', '6': '7zt5', '7': '8uz6', '8': '9iu7', '9': '0oi8', '0': 'po9',\n\t\t'q': '12wa', 'w': '3esaq2', 'e': '4rdsw3', 'r': '5tfde4', 't': '6zgfr5', 'z': '7uhgt6', 'u': '8ijhz7', 'i': '9okju8', 'o': '0plki9', 'p': 'lo0',\n\t\t'a': 'qwsy', 's': 'edxyaw', 'd': 'rfcxse', 'f': 'tgvcdr', 'g': 'zhbvft', 'h': 'ujnbgz', 'j': 'ikmnhu', 'k': 'olmji', 'l': 'kop',\n\t\t'y': 'asx', 'x': 'ysdc', 'c': 'xdfv', 'v': 'cfgb', 'b': 'vghn', 'n': 'bhjm', 'm': 'njk'\n\t}\n\tazerty = {\n\t\t'1': '2a', '2': '3za1', '3': '4ez2', '4': '5re3', '5': '6tr4', '6': '7yt5', '7': '8uy6', '8': '9iu7', '9': '0oi8', '0': 'po9',\n\t\t'a': '2zq1', 'z': '3esqa2', 'e': '4rdsz3', 'r': '5tfde4', 't': '6ygfr5', 'y': '7uhgt6', 'u': '8ijhy7', 'i': '9okju8', 'o': '0plki9', 'p': 'lo0m',\n\t\t'q': 'zswa', 's': 'edxwqz', 'd': 'rfcxse', 'f': 'tgvcdr', 'g': 'yhbvft', 'h': 'ujnbgy', 'j': 'iknhu', 'k': 'olji', 'l': 'kopm', 'm': 'lp',\n\t\t'w': 'sxq', 'x': 'wsdc', 'c': 'xdfv', 'v': 'cfgb', 'b': 'vghn', 'n': 'bhj'\n\t}\n\tkeyboards = [qwerty, qwertz, azerty]\n\n\tdef __init__(self, domain, dictionary=[], tld_dictionary=[]):\n\t\tself.subdomain, self.domain, self.tld = domain_tld(domain)\n\t\tself.domain = idna.decode(self.domain)\n\t\tself.dictionary = list(dictionary)\n\t\tself.tld_dictionary = list(tld_dictionary)\n\t\tself.domains = set()\n\n\tdef __enter__(self):\n\t\treturn self\n\n\tdef __exit__(self, exc_type, exc_val, exc_tb):\n\t\treturn\n\n\tdef _bitsquatting(self):\n\t\tmasks = [1, 2, 4, 8, 16, 32, 64, 128]\n\t\tchars = set('abcdefghijklmnopqrstuvwxyz0123456789-')\n\t\tfor i, c in enumerate(self.domain):\n\t\t\tfor mask in masks:\n\t\t\t\tb = chr(ord(c) ^ mask)\n\t\t\t\tif b in chars:\n\t\t\t\t\tyield self.domain[:i] + b + self.domain[i+1:]\n\n\tdef _cyrillic(self):\n\t\tcdomain = self.domain\n\t\tfor l, c in self.latin_to_cyrillic.items():\n\t\t\tcdomain = cdomain.replace(l, c)\n\t\tfor c, l in zip(cdomain, self.domain):\n\t\t\tif c == l:\n\t\t\t\treturn []\n\t\treturn [cdomain]\n\n\tdef _homoglyph(self):\n\t\tmd = lambda a, b: {k: set(a.get(k, [])) | set(b.get(k, [])) for k in set(a.keys()) | set(b.keys())}\n\t\tglyphs = md(self.glyphs_ascii, self.glyphs_idn_by_tld.get(self.tld, self.glyphs_unicode))\n\t\tdef mix(domain):\n\t\t\tfor i, c in enumerate(domain):\n\t\t\t\tfor g in glyphs.get(c, []):\n\t\t\t\t\tyield domain[:i] + g + domain[i+1:]\n\t\t\tfor i in range(len(domain)-1):\n\t\t\t\twin = domain[i:i+2]\n\t\t\t\tfor c in {win[0], win[1], win}:\n\t\t\t\t\tfor g in glyphs.get(c, []):\n\t\t\t\t\t\tyield domain[:i] + win.replace(c, g) + domain[i+2:]\n\t\tresult1 = set(mix(self.domain))\n\t\tresult2 = set()\n\t\tfor r in result1:\n\t\t\tresult2.update(set(mix(r)))\n\t\treturn result1 | result2\n\n\tdef _hyphenation(self):\n\t\treturn {self.domain[:i] + '-' + self.domain[i:] for i in range(1, len(self.domain))}\n\n\tdef _insertion(self):\n\t\tresult = set()\n\t\tfor i in range(0, len(self.domain)-1):\n\t\t\tprefix, orig_c, suffix = self.domain[:i], self.domain[i], self.domain[i+1:]\n\t\t\tfor c in (c for keys in self.keyboards for c in keys.get(orig_c, [])):\n\t\t\t\tresult.update({\n\t\t\t\t\tprefix + c + orig_c + suffix,\n\t\t\t\t\tprefix + orig_c + c + suffix\n\t\t\t\t})\n\t\treturn result\n\n\tdef _omission(self):\n\t\treturn {self.domain[:i] + self.domain[i+1:] for i in range(len(self.domain))}\n\n\tdef _repetition(self):\n\t\treturn {self.domain[:i] + c + self.domain[i:] for i, c in enumerate(self.domain)}\n\n\tdef _replacement(self):\n\t\tfor i, c in enumerate(self.domain):\n\t\t\tpre = self.domain[:i]\n\t\t\tsuf = self.domain[i+1:]\n\t\t\tfor layout in self.keyboards:\n\t\t\t\tfor r in layout.get(c, ''):\n\t\t\t\t\tyield pre + r + suf\n\n\tdef _subdomain(self):\n\t\tfor i in range(1, len(self.domain)-1):\n\t\t\tif self.domain[i] not in ['-', '.'] and self.domain[i-1] not in ['-', '.']:\n\t\t\t\tyield self.domain[:i] + '.' + self.domain[i:]\n\n\tdef _transposition(self):\n\t\treturn {self.domain[:i] + self.domain[i+1] + self.domain[i] + self.domain[i+2:] for i in range(len(self.domain)-1)}\n\n\tdef _vowel_swap(self):\n\t\tvowels = 'aeiou'\n\t\tfor i in range(0, len(self.domain)):\n\t\t\tfor vowel in vowels:\n\t\t\t\tif self.domain[i] in vowels:\n\t\t\t\t\tyield self.domain[:i] + vowel + self.domain[i+1:]\n\n\tdef _plural(self):\n\t\tfor i in range(2, len(self.domain)-2):\n\t\t\tyield self.domain[:i+1] + ('es' if self.domain[i] in ('s', 'x', 'z') else 's') + self.domain[i+1:]\n\n\n\tdef _addition(self):\n\t\tresult = set()\n\t\tif '-' in self.domain:\n\t\t\tparts = self.domain.split('-')\n\t\t\tresult = {'-'.join(parts[:p]) + chr(i) + '-' + '-'.join(parts[p:]) for i in (*range(48, 58), *range(97, 123)) for p in range(1, len(parts))}\n\t\tresult.update({self.domain + chr(i) for i in (*range(48, 58), *range(97, 123))})\n\t\treturn result\n\n\n\tdef _dictionary(self):\n\t\tresult = set()\n\t\tfor word in self.dictionary:\n\t\t\tif not (self.domain.startswith(word) and self.domain.endswith(word)):\n\t\t\t\tresult.update({\n\t\t\t\t\tself.domain + '-' + word,\n\t\t\t\t\tself.domain + word,\n\t\t\t\t\tword + '-' + self.domain,\n\t\t\t\t\tword + self.domain\n\t\t\t\t})\n\t\tif '-' in self.domain:\n\t\t\tparts = self.domain.split('-')\n\t\t\tfor word in self.dictionary:\n\t\t\t\tresult.update({\n\t\t\t\t\t'-'.join(parts[:-1]) + '-' + word,\n\t\t\t\t\tword + '-' + '-'.join(parts[1:])\n\t\t\t\t})\n\t\treturn result\n\n\tdef _tld(self):\n\t\tif self.tld in self.tld_dictionary:\n\t\t\tself.tld_dictionary.remove(self.tld)\n\t\treturn set(self.tld_dictionary)\n\n\tdef generate(self, fuzzers=[]):\n\t\tself.domains = set()\n\t\tif not fuzzers or '*original' in fuzzers:\n\t\t\tself.domains.add(Permutation(fuzzer='*original', domain='.'.join(filter(None, [self.subdomain, self.domain, self.tld]))))\n\t\tfor f_name in fuzzers or [\n\t\t\t'addition', 'bitsquatting', 'cyrillic', 'homoglyph', 'hyphenation',\n\t\t\t'insertion', 'omission', 'plural', 'repetition', 'replacement',\n\t\t\t'subdomain', 'transposition', 'vowel-swap', 'dictionary',\n\t\t]:\n\t\t\ttry:\n\t\t\t\tf = getattr(self, '_' + f_name.replace('-', '_'))\n\t\t\texcept AttributeError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tfor domain in f():\n\t\t\t\t\tself.domains.add(Permutation(fuzzer=f_name, domain='.'.join(filter(None, [self.subdomain, domain, self.tld]))))\n\t\tif not fuzzers or 'tld-swap' in fuzzers:\n\t\t\tfor tld in self._tld():\n\t\t\t\tself.domains.add(Permutation(fuzzer='tld-swap', domain='.'.join(filter(None, [self.subdomain, self.domain, tld]))))\n\t\tif not fuzzers or 'various' in fuzzers:\n\t\t\tif '.' in self.tld:\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join(filter(None, [self.subdomain, self.domain, self.tld.split('.')[-1]]))))\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join(filter(None, [self.subdomain, self.domain + self.tld]))))\n\t\t\tif '.' not in self.tld:\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join(filter(None, [self.subdomain, self.domain + self.tld, self.tld]))))\n\t\t\tif self.tld != 'com' and '.' not in self.tld:\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join(filter(None, [self.subdomain, self.domain + '-' + self.tld, 'com']))))\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join(filter(None, [self.subdomain, self.domain + self.tld, 'com']))))\n\t\t\tif self.subdomain:\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join([self.subdomain + self.domain, self.tld])))\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join([self.subdomain.replace('.', '') + self.domain, self.tld])))\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join([self.subdomain + '-' + self.domain, self.tld])))\n\t\t\t\tself.domains.add(Permutation(fuzzer='various', domain='.'.join([self.subdomain.replace('.', '-') + '-' + self.domain, self.tld])))\n\t\tdef _punycode(domain):\n\t\t\ttry:\n\t\t\t\tdomain['domain'] = idna.encode(domain['domain']).decode()\n\t\t\texcept Exception:\n\t\t\t\tdomain['domain'] = ''\n\t\t\treturn domain\n\t\tself.domains = set(map(_punycode, self.domains))\n\t\tfor domain in self.domains.copy():\n\t\t\tif not VALID_FQDN_REGEX.match(domain.get('domain')):\n\t\t\t\tself.domains.discard(domain)\n\n\tdef permutations(self, registered=False, unregistered=False, dns_all=False, unicode=False):\n\t\tif (registered and not unregistered):\n\t\t\tdomains = [x.copy() for x in self.domains if x.is_registered()]\n\t\telif (unregistered and not registered):\n\t\t\tdomains = [x.copy() for x in self.domains if not x.is_registered()]\n\t\telse:\n\t\t\tdomains = [x.copy() for x in self.domains]\n\t\tif not dns_all:\n\t\t\tdef _cutdns(x):\n\t\t\t\tif x.is_registered():\n\t\t\t\t\tfor k in ('dns_ns', 'dns_a', 'dns_aaaa', 'dns_mx'):\n\t\t\t\t\t\tif k in x:\n\t\t\t\t\t\t\tx[k] = x[k][:1]\n\t\t\t\treturn x\n\t\t\tdomains = map(_cutdns, domains)\n\t\tif unicode:\n\t\t\tdef _punydecode(x):\n\t\t\t\tx.domain = idna.decode(x.domain)\n\t\t\t\treturn x\n\t\t\tdomains = map(_punydecode, domains)\n\t\treturn sorted(domains)\n\n\nclass Scanner(threading.Thread):\n\tdef __init__(self, queue):\n\t\tthreading.Thread.__init__(self)\n\t\tself._stop_event = threading.Event()\n\t\tself.daemon = True\n\t\tself.id = 0\n\t\tself.jobs = queue\n\t\tself.lsh_init = ''\n\t\tself.lsh_effective_url = ''\n\t\tself.phash_init = None\n\t\tself.screenshot_dir = None\n\t\tself.url = None\n\t\tself.option_extdns = False\n\t\tself.option_geoip = False\n\t\tself.option_lsh = None\n\t\tself.option_phash = False\n\t\tself.option_banners = False\n\t\tself.option_mxcheck = False\n\t\tself.nameservers = []\n\t\tself.useragent = ''\n\n\t@staticmethod\n\tdef _send_recv_tcp(host, port, data=b'', timeout=2.0, recv_bytes=1024):\n\t\tsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\t\tsock.settimeout(timeout)\n\t\tresp = b''\n\t\ttry:\n\t\t\tsock.connect((host, port))\n\t\t\tif data:\n\t\t\t\tsock.send(data)\n\t\t\tresp = sock.recv(recv_bytes)\n\t\texcept Exception as e:\n\t\t\t_debug(e)\n\t\tfinally:\n\t\t\tsock.close()\n\t\treturn resp.decode('utf-8', errors='ignore')\n\n\tdef _banner_http(self, ip, vhost):\n\t\tresponse = self._send_recv_tcp(ip, 80,\n\t\t\t'HEAD / HTTP/1.1\\r\\nHost: {}\\r\\nUser-Agent: {}\\r\\n\\r\\n'.format(vhost, self.useragent).encode())\n\t\tif not response:\n\t\t\treturn ''\n\t\theaders = response.splitlines()\n\t\tfor field in headers:\n\t\t\tif field.lower().startswith('server: '):\n\t\t\t\treturn field[8:]\n\t\treturn ''\n\n\tdef _banner_smtp(self, mx):\n\t\tresponse = self._send_recv_tcp(mx, 25)\n\t\tif not response:\n\t\t\treturn ''\n\t\thello = response.splitlines()[0]\n\t\tif hello.startswith('220'):\n\t\t\treturn hello[4:].strip()\n\t\treturn ''\n\n\tdef _mxcheck(self, mxhost, domain_from, domain_rcpt):\n\t\tr'''\n\t\tDetects potential email honey pots waiting for mistyped emails to arrive.\n\t\tNote: Some mail servers only pretend to accept incorrectly addressed\n\t\temails - this technique is used to prevent \"directory harvesting attack\".\n\t\t'''\n\t\ttry:\n\t\t\tsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\t\t\tsock.settimeout(REQUEST_TIMEOUT_SMTP)\n\t\t\tsock.connect((mxhost, 25))\n\t\texcept Exception:\n\t\t\treturn False\n\t\tfor cmd in [\n\t\t\t'EHLO {}\\r\\n'.format(mxhost),\n\t\t\t'MAIL FROM: randombob1986@{}\\r\\n'.format(domain_from),\n\t\t\t'RCPT TO: randomalice1986@{}\\r\\n'.format(domain_rcpt),\n\t\t\t# And that's how the cookie crumbles\n\t\t]:\n\t\t\ttry:\n\t\t\t\tresp = sock.recv(512)\n\t\t\texcept Exception:\n\t\t\t\tbreak\n\t\t\tif not resp:\n\t\t\t\tbreak\n\t\t\tif resp[0] != 0x32: # status code != 2xx\n\t\t\t\tbreak\n\t\t\tsock.send(cmd.encode())\n\t\telse:\n\t\t\tsock.close()\n\t\t\treturn True\n\t\tsock.close()\n\t\treturn False\n\n\tdef stop(self):\n\t\tself._stop_event.set()\n\n\tdef is_stopped(self):\n\t\treturn self._stop_event.is_set()\n\n\tdef run(self):\n\t\tif self.option_extdns:\n\t\t\tif self.nameservers:\n\t\t\t\tresolv = Resolver(configure=False)\n\t\t\t\tresolv.nameservers = self.nameservers\n\t\t\telse:\n\t\t\t\tresolv = Resolver()\n\t\t\t\tresolv.search = []\n\n\t\t\tresolv.lifetime = REQUEST_TIMEOUT_DNS * REQUEST_RETRIES_DNS\n\t\t\tresolv.timeout = REQUEST_TIMEOUT_DNS\n\t\t\tEDNS_PAYLOAD = 1232\n\t\t\tresolv.use_edns(edns=True, ednsflags=0, payload=EDNS_PAYLOAD)\n\t\t\tresolv.rotate = True\n\n\t\t\tif hasattr(resolv, 'resolve'):\n\t\t\t\tresolve = resolv.resolve\n\t\t\telse:\n\t\t\t\tresolve = resolv.query\n\n\t\tif self.option_geoip:\n\t\t\tgeo = geoip()\n\n\t\tif self.option_phash:\n\t\t\tbrowser = HeadlessBrowser(useragent=self.useragent)\n\n\t\t_answer_to_list = lambda ans: sorted([str(x).split(' ')[-1].rstrip('.') for x in ans])\n\n\t\twhile not self.is_stopped():\n\t\t\ttry:\n\t\t\t\ttask = self.jobs.get(block=False)\n\t\t\texcept queue.Empty:\n\t\t\t\tself.stop()\n\t\t\t\treturn\n\n\t\t\tdomain = task.get('domain')\n\n\t\t\tdns_a = False\n\t\t\tdns_aaaa = False\n\t\t\tif self.option_extdns:\n\t\t\t\tnxdomain = False\n\t\t\t\tdns_ns = False\n\t\t\t\tdns_mx = False\n\n\t\t\t\ttry:\n\t\t\t\t\ttask['dns_ns'] = _answer_to_list(resolve(domain, rdtype=dns.rdatatype.NS))\n\t\t\t\t\tdns_ns = True\n\t\t\t\texcept NXDOMAIN:\n\t\t\t\t\tnxdomain = True\n\t\t\t\texcept NoNameservers:\n\t\t\t\t\ttask['dns_ns'] = ['!ServFail']\n\t\t\t\texcept DNSException as e:\n\t\t\t\t\t_debug(e)\n\n\t\t\t\tif nxdomain is False:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttask['dns_a'] = _answer_to_list(resolve(domain, rdtype=dns.rdatatype.A))\n\t\t\t\t\t\tdns_a = True\n\t\t\t\t\texcept NoNameservers:\n\t\t\t\t\t\ttask['dns_a'] = ['!ServFail']\n\t\t\t\t\texcept DNSException as e:\n\t\t\t\t\t\t_debug(e)\n\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttask['dns_aaaa'] = _answer_to_list(resolve(domain, rdtype=dns.rdatatype.AAAA))\n\t\t\t\t\t\tdns_aaaa = True\n\t\t\t\t\texcept NoNameservers:\n\t\t\t\t\t\ttask['dns_aaaa'] = ['!ServFail']\n\t\t\t\t\texcept DNSException as e:\n\t\t\t\t\t\t_debug(e)\n\n\t\t\t\tif nxdomain is False and dns_ns is True:\n\t\t\t\t\ttry:\n\t\t\t\t\t\ttask['dns_mx'] = _answer_to_list(resolve(domain, rdtype=dns.rdatatype.MX))\n\t\t\t\t\t\tdns_mx = True\n\t\t\t\t\texcept NoNameservers:\n\t\t\t\t\t\ttask['dns_mx'] = ['!ServFail']\n\t\t\t\t\texcept DNSException as e:\n\t\t\t\t\t\t_debug(e)\n\t\t\telse:\n\t\t\t\ttry:\n\t\t\t\t\taddrinfo = socket.getaddrinfo(domain, None, proto=socket.IPPROTO_TCP)\n\t\t\t\texcept socket.gaierror as e:\n\t\t\t\t\tif e.errno == -3:\n\t\t\t\t\t\ttask['dns_a'] = ['!ServFail']\n\t\t\t\texcept Exception as e:\n\t\t\t\t\t_debug(e)\n\t\t\t\telse:\n\t\t\t\t\tfor _, _, _, _, sa in addrinfo:\n\t\t\t\t\t\tip = sa[0]\n\t\t\t\t\t\tif '.' in ip:\n\t\t\t\t\t\t\tif 'dns_a' not in task:\n\t\t\t\t\t\t\t\ttask['dns_a'] = set()\n\t\t\t\t\t\t\t\tdns_a = True\n\t\t\t\t\t\t\ttask['dns_a'].add(ip)\n\t\t\t\t\t\tif ':' in ip:\n\t\t\t\t\t\t\tif 'dns_aaaa' not in task:\n\t\t\t\t\t\t\t\ttask['dns_aaaa'] = set()\n\t\t\t\t\t\t\t\tdns_aaaa = True\n\t\t\t\t\t\t\ttask['dns_aaaa'].add(ip)\n\t\t\t\t\tif 'dns_a' in task:\n\t\t\t\t\t\ttask['dns_a'] = list(task['dns_a'])\n\t\t\t\t\tif 'dns_aaaa' in task:\n\t\t\t\t\t\ttask['dns_aaaa'] = list(task['dns_aaaa'])\n\n\t\t\tif self.option_mxcheck:\n\t\t\t\tif dns_mx is True:\n\t\t\t\t\tif domain != self.url.domain:\n\t\t\t\t\t\tif self._mxcheck(task['dns_mx'][0], self.url.domain, domain):\n\t\t\t\t\t\t\ttask['mx_spy'] = True\n\n\t\t\tif self.option_geoip:\n\t\t\t\tif dns_a is True:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tcountry = geo.country_by_addr(task['dns_a'][0])\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\t_debug(e)\n\t\t\t\t\t\tpass\n\t\t\t\t\telse:\n\t\t\t\t\t\tif country:\n\t\t\t\t\t\t\ttask['geoip'] = country.split(',')[0]\n\n\t\t\tif self.option_banners:\n\t\t\t\tif dns_a is True:\n\t\t\t\t\tbanner = self._banner_http(task['dns_a'][0], domain)\n\t\t\t\t\tif banner:\n\t\t\t\t\t\ttask['banner_http'] = banner\n\t\t\t\tif dns_mx is True:\n\t\t\t\t\tbanner = self._banner_smtp(task['dns_mx'][0])\n\t\t\t\t\tif banner:\n\t\t\t\t\t\ttask['banner_smtp'] = banner\n\n\t\t\tif self.option_phash or self.screenshot_dir:\n\t\t\t\tif dns_a or dns_aaaa:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tbrowser.get(self.url.full_uri(domain))\n\t\t\t\t\t\tscreenshot = browser.screenshot()\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\t_debug(e)\n\t\t\t\t\telse:\n\t\t\t\t\t\tif self.option_phash:\n\t\t\t\t\t\t\tphash = pHash(BytesIO(screenshot))\n\t\t\t\t\t\t\ttask['phash'] = self.phash_init - phash\n\t\t\t\t\t\tif self.screenshot_dir:\n\t\t\t\t\t\t\tfilename = os.path.join(self.screenshot_dir, '{:08x}_{}.png'.format(self.id, domain))\n\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\twith open(filename, 'wb') as f:\n\t\t\t\t\t\t\t\t\tf.write(screenshot)\n\t\t\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\t\t\t_debug(e)\n\n\t\t\tif self.option_lsh:\n\t\t\t\tif dns_a is True or dns_aaaa is True:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tr = UrlOpener(self.url.full_uri(domain),\n\t\t\t\t\t\t\ttimeout=REQUEST_TIMEOUT_HTTP,\n\t\t\t\t\t\t\theaders={'user-agent': self.useragent},\n\t\t\t\t\t\t\tverify=False)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\t_debug(e)\n\t\t\t\t\telse:\n\t\t\t\t\t\tif r.url.split('?')[0] != self.lsh_effective_url:\n\t\t\t\t\t\t\tif self.option_lsh == 'ssdeep':\n\t\t\t\t\t\t\t\tlsh_curr = ssdeep.hash(r.normalized_content)\n\t\t\t\t\t\t\t\tif lsh_curr not in (None, '3::'):\n\t\t\t\t\t\t\t\t\ttask['ssdeep'] = ssdeep.compare(self.lsh_init, lsh_curr)\n\t\t\t\t\t\t\telif self.option_lsh == 'tlsh':\n\t\t\t\t\t\t\t\tlsh_curr = tlsh.hash(r.normalized_content)\n\t\t\t\t\t\t\t\tif lsh_curr not in (None, '', 'TNULL'):\n\t\t\t\t\t\t\t\t\ttask['tlsh'] = int(100 - (min(tlsh.diff(self.lsh_init, lsh_curr), 300)/3))\n\n\t\t\tself.jobs.task_done()\n\n\nclass Format():\n\tdef __init__(self, domains=[]):\n\t\tself.domains = domains\n\n\tdef json(self, indent=4, sort_keys=True):\n\t\treturn json.dumps(self.domains, indent=indent, sort_keys=sort_keys)\n\n\tdef csv(self):\n\t\tcols = ['fuzzer', 'domain']\n\t\tfor domain in self.domains:\n\t\t\tfor k in domain.keys() - cols:\n\t\t\t\tcols.append(k)\n\t\tcols = cols[:2] + sorted(cols[2:])\n\t\tcsv = [','.join(cols)]\n\t\tfor domain in self.domains:\n\t\t\trow = []\n\t\t\tfor val in [domain.get(c, '') for c in cols]:\n\t\t\t\tif isinstance(val, str):\n\t\t\t\t\tif ',' in val:\n\t\t\t\t\t\trow.append('\"{}\"'.format(val))\n\t\t\t\t\telse:\n\t\t\t\t\t\trow.append(val)\n\t\t\t\telif isinstance(val, list):\n\t\t\t\t\trow.append(';'.join(val))\n\t\t\t\telif isinstance(val, int):\n\t\t\t\t\trow.append(str(val))\n\t\t\tcsv.append(','.join(row))\n\t\treturn '\\n'.join(csv)\n\n\tdef list(self):\n\t\treturn '\\n'.join([x.get('domain') for x in sorted(self.domains)])\n\n\tdef cli(self):\n\t\tcli = []\n\t\tdomains = list(self.domains)\n\t\tif sys.stdout.encoding.lower() == 'utf-8':\n\t\t\tfor domain in domains:\n\t\t\t\tdomain.update(domain=idna.decode(domain.get('domain')))\n\t\twfuz = max([len(x.get('fuzzer', '')) for x in domains]) + 1\n\t\twdom = max([len(x.get('domain', '')) for x in domains]) + 1\n\t\tkv = lambda k, v: FG_YEL + k + FG_CYA + v + FG_RST if k else FG_CYA + v + FG_RST\n\t\tfor domain in domains:\n\t\t\tinf = []\n\t\t\tif 'dns_a' in domain:\n\t\t\t\tinf.append(';'.join(domain['dns_a']) + (kv('/', domain['geoip'].replace(' ', '')) if 'geoip' in domain else ''))\n\t\t\tif 'dns_aaaa' in domain:\n\t\t\t\tinf.append(';'.join(domain['dns_aaaa']))\n\t\t\tif 'dns_ns' in domain:\n\t\t\t\tinf.append(kv('NS:', ';'.join(domain['dns_ns'])))\n\t\t\tif 'dns_mx' in domain:\n\t\t\t\tinf.append(kv('SPYING-MX:' if domain.get('mx_spy') else 'MX:', ';'.join(domain['dns_mx'])))\n\t\t\tif 'banner_http' in domain:\n\t\t\t\tinf.append(kv('HTTP:', domain['banner_http']))\n\t\t\tif 'banner_smtp' in domain:\n\t\t\t\tinf.append(kv('SMTP:', domain['banner_smtp']))\n\t\t\tif 'whois_registrar' in domain:\n\t\t\t\tinf.append(kv('REGISTRAR:', domain['whois_registrar']))\n\t\t\tif 'whois_created' in domain:\n\t\t\t\tinf.append(kv('CREATED:', domain['whois_created']))\n\t\t\tif domain.get('ssdeep', 0) > 0:\n\t\t\t\tinf.append(kv('SSDEEP:', '{}%'.format(domain['ssdeep'])))\n\t\t\tif domain.get('tlsh', 0) > 0:\n\t\t\t\tinf.append(kv('TLSH:', '{}%'.format(domain['tlsh'])))\n\t\t\tif domain.get('phash', 0) > 0:\n\t\t\t\tinf.append(kv('PHASH:', '{}%'.format(domain['phash'])))\n\t\t\tcli.append('{}{[fuzzer]:<{}}{} {[domain]:<{}} {}'.format(FG_BLU, domain, wfuz, FG_RST, domain, wdom, ' '.join(inf or ['-'])))\n\t\treturn '\\n'.join(cli)\n\n\ndef cleaner(func):\n\tdef wrapper(*args, **kwargs):\n\t\tresult = func(*args, **kwargs)\n\t\tif threading.current_thread() is threading.main_thread():\n\t\t\tfor sig in (signal.SIGINT, signal.SIGTERM):\n\t\t\t\tsignal.signal(sig, signal.default_int_handler)\n\t\tsys.argv = sys.argv[0:1]\n\t\treturn result\n\treturn wrapper\n\n\n@cleaner\ndef run(**kwargs):\n\tparser = argparse.ArgumentParser(\n\t\tusage='%s [OPTION]... DOMAIN' % sys.argv[0],\n\t\tadd_help=False,\n\t\tdescription=\n\t\t'''Domain name permutation engine for detecting homograph phishing attacks, '''\n\t\t'''typosquatting, fraud and brand impersonation.''',\n\t\tformatter_class=lambda prog: argparse.HelpFormatter(prog,max_help_position=30)\n\t\t)\n\n\tparser.add_argument('domain', help='Domain name or URL to scan')\n\tparser.add_argument('-a', '--all', action='store_true', help='Print all DNS records instead of the first ones')\n\tparser.add_argument('-b', '--banners', action='store_true', help='Determine HTTP and SMTP service banners')\n\tparser.add_argument('-d', '--dictionary', type=str, metavar='FILE', help='Generate more domains using dictionary FILE')\n\tparser.add_argument('-f', '--format', type=str, default='cli', help='Output format: cli, csv, json, list (default: cli)')\n\tparser.add_argument('--fuzzers', type=str, metavar='LIST', help='Use only selected fuzzing algorithms (separated with commas)')\n\tparser.add_argument('-g', '--geoip', action='store_true', help='Lookup for GeoIP location')\n\tparser.add_argument('--lsh', type=str, metavar='LSH', nargs='?', const='ssdeep',\n\t\thelp='Evaluate web page similarity with LSH algorithm: ssdeep, tlsh (default: ssdeep)')\n\tparser.add_argument('--lsh-url', metavar='URL', help='Override URL to fetch the original web page from')\n\tparser.add_argument('-m', '--mxcheck', action='store_true', help='Check if MX host can be used to intercept emails')\n\tparser.add_argument('-o', '--output', type=str, metavar='FILE', help='Save output to FILE')\n\tparser.add_argument('-r', '--registered', action='store_true', help='Show only registered domain names')\n\tparser.add_argument('-u', '--unregistered', action='store_true', help='Show only unregistered domain names')\n\tparser.add_argument('-p', '--phash', action='store_true', help='Render web pages and evaluate visual similarity')\n\tparser.add_argument('--phash-url', metavar='URL', help='Override URL to render the original web page from')\n\tparser.add_argument('--screenshots', metavar='DIR', help='Save web page screenshots into DIR')\n\tparser.add_argument('-s', '--ssdeep', action='store_true', help=argparse.SUPPRESS)\n\tparser.add_argument('--ssdeep-url', help=argparse.SUPPRESS)\n\tparser.add_argument('-t', '--threads', type=int, metavar='NUM', default=THREAD_COUNT_DEFAULT,\n\t\thelp='Start specified NUM of threads (default: %s)' % THREAD_COUNT_DEFAULT)\n\tparser.add_argument('-w', '--whois', action='store_true', help='Lookup WHOIS database for creation date and registrar')\n\tparser.add_argument('--tld', type=str, metavar='FILE', help='Swap TLD for the original domain from FILE')\n\tparser.add_argument('--nameservers', type=str, metavar='LIST', help='DNS or DoH servers to query (separated with commas)')\n\tparser.add_argument('--useragent', type=str, metavar='STRING', default=USER_AGENT_STRING,\n\t\thelp='Set User-Agent STRING (default: %s)' % USER_AGENT_STRING)\n\tparser.add_argument('--version', action='version', version='dnstwist {}'.format(__version__), help=argparse.SUPPRESS)\n\n\tif kwargs:\n\t\tsys.argv = ['']\n\t\tfor k, v in kwargs.items():\n\t\t\tif k in ('domain',):\n\t\t\t\tsys.argv.append(v)\n\t\t\telse:\n\t\t\t\tif v is not False:\n\t\t\t\t\tsys.argv.append('--' + k.replace('_', '-'))\n\t\t\t\tif not isinstance(v, bool):\n\t\t\t\t\tsys.argv.append(str(v))\n\t\tdef _parser_error(msg):\n\t\t\traise Exception(msg) from None\n\t\tparser.error = _parser_error\n\n\tif not sys.argv[1:] or '-h' in sys.argv or '--help' in sys.argv:\n\t\tprint('{}dnstwist {} by <{}>{}\\n'.format(ST_BRI, __version__, __email__, ST_RST))\n\t\tparser.print_help()\n\t\treturn\n\n\targs = parser.parse_args()\n\n\tthreads = []\n\tjobs = queue.Queue()\n\n\tdef p_cli(text):\n\t\tif args.format == 'cli' and sys.stdout.isatty(): print(text, end='', flush=True)\n\tdef p_err(text):\n\t\tprint(str(text), file=sys.stderr, flush=True)\n\n\tdef signal_handler(signal, frame):\n\t\tif threads:\n\t\t\tprint('\\nstopping threads... ', file=sys.stderr, flush=True)\n\t\t\tjobs.queue.clear()\n\t\t\tfor worker in threads:\n\t\t\t\tworker.stop()\n\t\t\tthreads.clear()\n\t\tsys.tracebacklimit = 0\n\t\traise KeyboardInterrupt\n\n\tif args.registered and args.unregistered:\n\t\tparser.error('arguments --registered and --unregistered are mutually exclusive')\n\n\tif args.ssdeep:\n\t\tp_err('WARNING: argument --ssdeep is deprecated, use --lsh ssdeep instead')\n\t\targs.lsh = 'ssdeep'\n\tif args.ssdeep_url:\n\t\tp_err('WARNING: argument --ssdeep-url is deprecated, use --lsh-url instead')\n\t\targs.lsh_url = args.ssdeep_url\n\n\tif not args.lsh and args.lsh_url:\n\t\tparser.error('argument --lsh-url requires --lsh')\n\n\tif args.lsh and args.lsh not in ('ssdeep', 'tlsh'):\n\t\tparser.error('invalid LSH algorithm (choose ssdeep or tlsh)')\n\n\tif not args.phash:\n\t\tif args.phash_url:\n\t\t\tparser.error('argument --phash-url requires --phash')\n\t\tif args.screenshots:\n\t\t\tparser.error('argument --screenshots requires --phash')\n\n\tif not kwargs and args.format not in ('cli', 'csv', 'json', 'list'):\n\t\tparser.error('invalid output format (choose from cli, csv, json, list)')\n\n\tif args.threads < 1:\n\t\tparser.error('number of threads must be greater than zero')\n\n\tfuzzers = []\n\tif args.fuzzers:\n\t\tfuzzers = [x.strip().lower() for x in set(args.fuzzers.split(','))]\n\t\tif args.dictionary and 'dictionary' not in fuzzers:\n\t\t\tparser.error('argument --dictionary cannot be used with selected fuzzing algorithms (consider enabling fuzzer: dictionary)')\n\t\tif args.tld and 'tld-swap' not in fuzzers:\n\t\t\tparser.error('argument --tld cannot be used with selected fuzzing algorithms (consider enabling fuzzer: tld-swap)')\n\t\t# important: this should enable all available fuzzers\n\t\twith Fuzzer('example.domain', ['foo'], ['bar']) as fuzz:\n\t\t\tfuzz.generate()\n\t\t\tall_fuzzers = sorted({x.get('fuzzer') for x in fuzz.permutations()})\n\t\t\tif not set(fuzzers).issubset(all_fuzzers):\n\t\t\t\tparser.error('argument --fuzzers takes a comma-separated list with at least one of the following: {}'.format(' '.join(all_fuzzers)))\n\t\t\tdel all_fuzzers\n\n\tnameservers = []\n\tif args.nameservers:\n\t\tif not MODULE_DNSPYTHON:\n\t\t\tparser.error('missing DNSPython library')\n\t\tnameservers = args.nameservers.split(',')\n\t\tfor addr in nameservers:\n\t\t\tif re.match(r'^https://[a-z0-9.-]{4,253}/dns-query$', addr):\n\t\t\t\ttry:\n\t\t\t\t\tfrom dns.query import https\n\t\t\t\texcept ImportError:\n\t\t\t\t\tparser.error('DNS-over-HTTPS requires DNSPython 2.x or newer')\n\t\t\t\telse:\n\t\t\t\t\tdel https\n\t\t\t\tcontinue\n\t\t\tif re.match(r'^((25[0-5]|(2[0-4]|1\\d|[1-9]|)\\d)(\\.(?!$)|$)){4}$', addr):\n\t\t\t\tcontinue\n\t\t\tparser.error('invalid nameserver: {}'.format(addr))\n\n\tdictionary = []\n\tif args.dictionary:\n\t\tre_subd = re.compile(r'^(?:(?:xn--)[a-z0-9-]{3,59}|[a-z0-9-]{1,63})$')\n\t\ttry:\n\t\t\twith open(args.dictionary, encoding='utf-8') as f:\n\t\t\t\tdictionary = [x for x in set(f.read().lower().splitlines()) if re_subd.match(x)]\n\t\texcept UnicodeDecodeError:\n\t\t\tparser.error('UTF-8 decode error when reading: {}'.format(args.dictionary))\n\t\texcept OSError as err:\n\t\t\tparser.error('unable to open {} ({})'.format(args.dictionary, err.strerror.lower()))\n\n\ttld = []\n\tif args.tld:\n\t\tre_tld = re.compile(r'^[a-z0-9-]{2,63}(?:\\.[a-z0-9-]{2,63})?$')\n\t\ttry:\n\t\t\twith open(args.tld, encoding='utf-8') as f:\n\t\t\t\ttld = [x for x in set(f.read().lower().splitlines()) if re_tld.match(x)]\n\t\texcept UnicodeDecodeError:\n\t\t\tparser.error('UTF-8 decode error when reading: {}'.format(args.tld))\n\t\texcept OSError as err:\n\t\t\tparser.error('unable to open {} ({})'.format(args.tld, err.strerror.lower()))\n\n\tif args.output:\n\t\tsys._stdout = sys.stdout\n\t\ttry:\n\t\t\tsys.stdout = open(args.output, 'w' if args.output == os.devnull else 'x')\n\t\texcept OSError as err:\n\t\t\tparser.error('unable to open {} ({})'.format(args.output, err.strerror.lower()))\n\n\n\tlsh_url = None\n\tif args.lsh:\n\t\tif args.lsh == 'ssdeep' and not MODULE_SSDEEP:\n\t\t\tparser.error('missing ssdeep library')\n\t\tif args.lsh == 'tlsh' and not MODULE_TLSH:\n\t\t\tparser.error('missing py-tlsh library')\n\t\tif args.lsh_url:\n\t\t\ttry:\n\t\t\t\tlsh_url = UrlParser(args.lsh_url)\n\t\t\texcept ValueError:\n\t\t\t\tparser.error('invalid domain name: ' + args.lsh_url)\n\n\tphash_url = None\n\tif args.phash or args.screenshots:\n\t\tif not MODULE_PIL:\n\t\t\tparser.error('missing Python Imaging Library (PIL)')\n\t\tif not MODULE_SELENIUM:\n\t\t\tparser.error('missing Selenium Webdriver')\n\t\ttry:\n\t\t\t_ = HeadlessBrowser()\n\t\texcept Exception as e:\n\t\t\tparser.error(str(e))\n\t\tif args.screenshots:\n\t\t\tif not os.access(args.screenshots, os.W_OK | os.X_OK):\n\t\t\t\tparser.error('insufficient access permissions: %s' % args.screenshots)\n\t\tif args.phash_url:\n\t\t\ttry:\n\t\t\t\tphash_url = UrlParser(args.phash_url)\n\t\t\texcept ValueError:\n\t\t\t\tparser.error('invalid domain name: ' + args.phash_url)\n\n\tif args.geoip:\n\t\tif not MODULE_GEOIP:\n\t\t\tparser.error('missing geoip2 library or database file (check $GEOLITE2_MMDB environment variable)')\n\n\ttry:\n\t\turl = UrlParser(args.domain)\n\texcept Exception:\n\t\tparser.error('invalid domain name: ' + args.domain)\n\n\tif threading.current_thread() is threading.main_thread():\n\t\tfor sig in (signal.SIGINT, signal.SIGTERM):\n\t\t\tsignal.signal(sig, signal_handler)\n\n\tfuzz = Fuzzer(url.domain, dictionary=dictionary, tld_dictionary=tld)\n\tfuzz.generate(fuzzers=fuzzers)\n\tdomains = fuzz.domains\n\n\tif not domains:\n\t\tparser.error('selected fuzzing algorithms do not generate any permutations for provided input domain')\n\n\tif args.format == 'list':\n\t\tprint(Format(domains).list())\n\t\tif hasattr(sys, '_stdout'):\n\t\t\tsys.stdout = sys._stdout\n\t\treturn list(map(dict, domains)) if kwargs else None\n\n\tif not MODULE_DNSPYTHON:\n\t\tp_err('WARNING: DNS features are limited due to lack of DNSPython library')\n\n\tp_cli(FG_RND + ST_BRI +\nr'''     _           _            _     _\n  __| |_ __  ___| |___      _(_)___| |_\n / _` | '_ \\/ __| __\\ \\ /\\ / / / __| __|\n| (_| | | | \\__ \\ |_ \\ V  V /| \\__ \\ |_\n \\__,_|_| |_|___/\\__| \\_/\\_/ |_|___/\\__| {%s}\n\n''' % __version__ + FG_RST + ST_RST)\n\n\tif args.lsh or args.phash:\n\t\tproxies = urllib.request.getproxies()\n\t\tif proxies:\n\t\t\tp_cli('using proxy: {}\\n'.format(' '.join(set(proxies.values()))))\n\n\tlsh_init = str()\n\tlsh_effective_url = str()\n\tif args.lsh:\n\t\trequest_url = lsh_url.full_uri() if lsh_url else url.full_uri()\n\t\tp_cli('fetching content from: {} '.format(request_url))\n\t\ttry:\n\t\t\tr = UrlOpener(request_url,\n\t\t\t\ttimeout=REQUEST_TIMEOUT_HTTP,\n\t\t\t\theaders={'User-Agent': args.useragent},\n\t\t\t\tverify=True)\n\t\texcept Exception as e:\n\t\t\tif kwargs:\n\t\t\t\traise\n\t\t\tp_err(e)\n\t\t\tsys.exit(1)\n\t\telse:\n\t\t\tp_cli('> {} [{:.1f} KB]\\n'.format(r.url.split('?')[0], len(r.content)/1024))\n\t\t\tif args.lsh == 'ssdeep':\n\t\t\t\tlsh_init = ssdeep.hash(r.normalized_content)\n\t\t\telif args.lsh == 'tlsh':\n\t\t\t\tlsh_init = tlsh.hash(r.normalized_content)\n\t\t\tlsh_effective_url = r.url.split('?')[0]\n\t\t\t# hash blank if content too short or insufficient entropy\n\t\t\tif lsh_init in (None, '', 'TNULL', '3::'):\n\t\t\t\targs.lsh = None\n\n\tif args.phash:\n\t\trequest_url = phash_url.full_uri() if phash_url else url.full_uri()\n\t\tp_cli('rendering web page: {}\\n'.format(request_url))\n\t\tbrowser = HeadlessBrowser(useragent=args.useragent)\n\t\ttry:\n\t\t\tbrowser.get(request_url)\n\t\t\tscreenshot = browser.screenshot()\n\t\texcept Exception as e:\n\t\t\tif kwargs:\n\t\t\t\traise\n\t\t\tp_err(e)\n\t\t\tsys.exit(1)\n\t\telse:\n\t\t\tphash = pHash(BytesIO(screenshot))\n\t\t\tbrowser.stop()\n\n\tfor task in domains:\n\t\tjobs.put(task)\n\n\tsid = int.from_bytes(os.urandom(4), sys.byteorder)\n\tfor _ in range(args.threads):\n\t\tworker = Scanner(jobs)\n\t\tworker.id = sid\n\t\tworker.url = url\n\t\tworker.option_extdns = MODULE_DNSPYTHON\n\t\tif args.geoip:\n\t\t\tworker.option_geoip = True\n\t\tif args.banners:\n\t\t\tworker.option_banners = True\n\t\tif args.lsh and lsh_init:\n\t\t\tworker.option_lsh = args.lsh\n\t\t\tworker.lsh_init = lsh_init\n\t\t\tworker.lsh_effective_url = lsh_effective_url\n\t\tif args.phash:\n\t\t\tworker.option_phash = True\n\t\t\tworker.phash_init = phash\n\t\t\tworker.screenshot_dir = args.screenshots\n\t\tif args.mxcheck:\n\t\t\tworker.option_mxcheck = True\n\t\tif args.nameservers:\n\t\t\tworker.nameservers = nameservers\n\t\tworker.useragent = args.useragent\n\t\tworker.start()\n\t\tthreads.append(worker)\n\n\tp_cli('started {} scanner threads\\n'.format(args.threads))\n\n\tttime = 0\n\tival = 0.2\n\twhile True:\n\t\ttime.sleep(ival)\n\t\tttime += ival\n\t\tdlen = len(domains)\n\t\tcomp = dlen - jobs.qsize()\n\t\tif not comp:\n\t\t\tcontinue\n\t\trate = int(comp / ttime) + 1\n\t\teta = jobs.qsize() // rate\n\t\tfound = sum([1 for x in domains if x.is_registered()])\n\t\tp_cli(ST_CLR + '\\rpermutations: {:.2%} of {} | found: {} | eta: {:d}m {:02d}s | speed: {:d} qps'.format(comp/dlen,\n\t\t\tdlen, found, eta//60, eta%60, rate))\n\t\tif jobs.empty():\n\t\t\tbreak\n\t\tif sum([1 for x in threads if x.is_alive()]) == 0:\n\t\t\tbreak\n\tp_cli('\\n')\n\n\tfor worker in threads:\n\t\tworker.stop()\n\tfor worker in threads:\n\t\tworker.join()\n\n\tdomains = fuzz.permutations(registered=args.registered, unregistered=args.unregistered, dns_all=args.all)\n\n\tif args.whois:\n\t\ttotal = sum([1 for x in domains if x.is_registered()])\n\t\twhois = Whois()\n\t\tfor i, domain in enumerate([x for x in domains if x.is_registered()]):\n\t\t\tp_cli(ST_CLR + '\\rWHOIS: {} ({:.2%})'.format(domain['domain'], (i+1)/total))\n\t\t\ttry:\n\t\t\t\twreply = whois.whois('.'.join(domain_tld(domain['domain'])[1:]))\n\t\t\texcept Exception as e:\n\t\t\t\t_debug(e)\n\t\t\telse:\n\t\t\t\tif wreply.get('creation_date'):\n\t\t\t\t\tdomain['whois_created'] = wreply.get('creation_date').strftime('%Y-%m-%d')\n\t\t\t\tif wreply.get('registrar'):\n\t\t\t\t\tdomain['whois_registrar'] = wreply.get('registrar')\n\t\tp_cli('\\n')\n\n\tp_cli('\\n')\n\n\tif domains:\n\t\tif args.format == 'csv':\n\t\t\tprint(Format(domains).csv())\n\t\telif args.format == 'json':\n\t\t\tprint(Format(domains).json())\n\t\telif args.format == 'cli':\n\t\t\tprint(Format(domains).cli())\n\n\tif hasattr(sys, '_stdout'):\n\t\tsys.stdout = sys._stdout\n\n\tif kwargs:\n\t\treturn list(map(dict, domains))\n\n\nif __name__ == '__main__':\n\ttry:\n\t\trun()\n\texcept BrokenPipeError:\n\t\tpass\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.140625,
          "content": "#GeoIP>=1.3.2\ngeoip2>=4.0.0\ndnspython>=1.16.0\n#ssdeep>=3.1\nppdeep>=20200505\npy-tlsh>=4.5.0\ntld>=0.9.1\nidna>=2.8\n#Pillow>=7.0.0\n#selenium>=4.0.0\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.1357421875,
          "content": "from setuptools import setup\n\ndef get_extras(rel_path):\n\twith open(rel_path) as f:\n\t\textras = [line for line in f.read().splitlines() if not line.startswith('#')]\n\treturn extras\n\ndef get_version(rel_path):\n\twith open(rel_path) as f:\n\t\tfor line in f.read().splitlines():\n\t\t\tif line.startswith('__version__'):\n\t\t\t\tdelim = '\"' if '\"' in line else \"'\"\n\t\t\t\treturn line.split(delim)[1]\n\traise RuntimeError('Unable to find version string')\n\nsetup(\n\tname='dnstwist',\n\tversion=get_version('dnstwist.py'),\n\tauthor='Marcin Ulikowski',\n\tauthor_email='marcin@ulikowski.pl',\n\tdescription='Domain name permutation engine for detecting homograph phishing attacks, typo squatting, and brand impersonation',\n\tlong_description='Project website: https://github.com/elceef/dnstwist',\n\turl='https://github.com/elceef/dnstwist',\n\tlicense='ASL 2.0',\n\tpy_modules=['dnstwist'],\n\tentry_points={\n\t\t'console_scripts': ['dnstwist=dnstwist:run']\n\t},\n\tinstall_requires=[],\n\textras_require={\n\t\t'full': get_extras('requirements.txt'),\n\t},\n\tclassifiers=[\n\t\t'Programming Language :: Python :: 3',\n\t\t'License :: OSI Approved :: Apache Software License',\n\t\t'Operating System :: OS Independent',\n\t],\n)\n"
        },
        {
          "name": "webapp",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}