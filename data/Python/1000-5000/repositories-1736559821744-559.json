{
  "metadata": {
    "timestamp": 1736559821744,
    "page": 559,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "NVlabs/ffhq-dataset",
      "stars": 3802,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.572265625,
          "content": "Flickr-Faces-HQ (FFHQ) is a high-quality image dataset of human faces,\r\noriginally created as a benchmark for generative adversarial networks (GAN):\r\n\r\n    A Style-Based Generator Architecture for Generative Adversarial Networks\r\n    Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)\r\n    http://stylegan.xyz/paper\r\n\r\nThe individual images were published in Flickr by their respective authors\r\nunder either Creative Commons BY 2.0, Creative Commons BY-NC 2.0,\r\nPublic Domain Mark 1.0, Public Domain CC0 1.0, or U.S. Government Works\r\nlicense. All of these licenses allow free use, redistribution, and adaptation\r\nfor non-commercial purposes. However, some of them require giving appropriate\r\ncredit to the original author, as well as indicating any changes that were\r\nmade to the images. The license and original author of each image are\r\nindicated in the metadata.\r\n\r\n    https://creativecommons.org/licenses/by/2.0/\r\n    https://creativecommons.org/licenses/by-nc/2.0/\r\n    https://creativecommons.org/publicdomain/mark/1.0/\r\n    https://creativecommons.org/publicdomain/zero/1.0/\r\n    http://www.usa.gov/copyright.shtml\r\n\r\nThe dataset itself (including JSON metadata, download script, and\r\ndocumentation) is made available under Creative Commons BY-NC-SA 4.0 license\r\nby NVIDIA Corporation. You can use, redistribute, and adapt it for\r\nnon-commercial purposes, as long as you (a) give appropriate credit by\r\nciting our paper, (b) indicate any changes that you've made, and\r\n(c) distribute any derivative works under the same license.\r\n\r\n    https://creativecommons.org/licenses/by-nc-sa/4.0/\r\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 13.6318359375,
          "content": "## Flickr-Faces-HQ Dataset (FFHQ)\n![Python 3.6](https://img.shields.io/badge/python-3.6-green.svg?style=plastic)\n![License CC](https://img.shields.io/badge/license-CC-green.svg?style=plastic)\n![Format PNG](https://img.shields.io/badge/format-PNG-green.svg?style=plastic)\n![Resolution 1024&times;1024](https://img.shields.io/badge/resolution-1024&times;1024-green.svg?style=plastic)\n![Images 70000](https://img.shields.io/badge/images-70,000-green.svg?style=plastic)\n\n![Teaser image](./ffhq-teaser.png)\n\nFlickr-Faces-HQ (FFHQ) is a high-quality image dataset of human faces, originally created as a benchmark for generative adversarial networks (GAN):\n\n> **A Style-Based Generator Architecture for Generative Adversarial Networks**<br>\n> Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)<br>\n> https://arxiv.org/abs/1812.04948\n\nThe dataset consists of 70,000 high-quality PNG images at 1024&times;1024 resolution and contains considerable variation in terms of age, ethnicity and image background. It also has good coverage of accessories such as eyeglasses, sunglasses, hats, etc. The images were crawled from [Flickr](https://www.flickr.com/), thus inheriting all the biases of that website, and automatically aligned and cropped using [dlib](http://dlib.net/). Only images under permissive licenses were collected. Various automatic filters were used to prune the set, and finally [Amazon Mechanical Turk](https://www.mturk.com/) was used to remove the occasional statues, paintings, or photos of photos.\n\nPlease note that this dataset is not intended for, and should not be used for, development or improvement of facial recognition technologies.  For business inquiries, please visit our website and submit the form: [NVIDIA Research Licensing](https://www.nvidia.com/en-us/research/inquiries/)\n\n## Licenses\n\nThe individual images were published in Flickr by their respective authors under either [Creative Commons BY 2.0](https://creativecommons.org/licenses/by/2.0/), [Creative Commons BY-NC 2.0](https://creativecommons.org/licenses/by-nc/2.0/), [Public Domain Mark 1.0](https://creativecommons.org/publicdomain/mark/1.0/), [Public Domain CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/), or [U.S. Government Works](http://www.usa.gov/copyright.shtml) license. All of these licenses allow **free use, redistribution, and adaptation for non-commercial purposes**. However, some of them require giving **appropriate credit** to the original author, as well as **indicating any changes** that were made to the images. The license and original author of each image are indicated in the metadata.\n\n* [https://creativecommons.org/licenses/by/2.0/](https://creativecommons.org/licenses/by/2.0/)\n* [https://creativecommons.org/licenses/by-nc/2.0/](https://creativecommons.org/licenses/by-nc/2.0/)\n* [https://creativecommons.org/publicdomain/mark/1.0/](https://creativecommons.org/publicdomain/mark/1.0/)\n* [https://creativecommons.org/publicdomain/zero/1.0/](https://creativecommons.org/publicdomain/zero/1.0/)\n* [http://www.usa.gov/copyright.shtml](http://www.usa.gov/copyright.shtml)\n\nThe dataset itself (including JSON metadata, download script, and documentation) is made available under [Creative Commons BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license by NVIDIA Corporation. You can **use, redistribute, and adapt it for non-commercial purposes**, as long as you (a) give appropriate credit by **citing our paper**, (b) **indicate any changes** that you've made, and (c) distribute any derivative works **under the same license**.\n\n* [https://creativecommons.org/licenses/by-nc-sa/4.0/](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n\n## Overview\n\nAll data is hosted on Google Drive:\n\n| Path | Size | Files | Format | Description\n| :--- | :--: | ----: | :----: | :----------\n| [ffhq-dataset](https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP) | 2.56 TB | 210,014 | | Main folder\n| &boxvr;&nbsp; [ffhq-dataset-v2.json](https://drive.google.com/open?id=16N0RV4fHI6joBuKbQAoG34V_cQk7vxSA) | 255 MB | 1 | JSON | Metadata including copyright info, URLs, etc.\n| &boxvr;&nbsp; [images1024x1024](https://drive.google.com/open?id=1tZUcXDBeOibC6jcMCtgRRz67pzrAHeHL) | 89.1 GB | 70,000 | PNG | Aligned and cropped images at 1024&times;1024\n| &boxvr;&nbsp; [thumbnails128x128](https://drive.google.com/open?id=1tg-Ur7d4vk1T8Bn0pPpUSQPxlPGBlGfv) | 1.95 GB | 70,000 | PNG | Thumbnails at 128&times;128\n| &boxvr;&nbsp; [in-the-wild-images](https://drive.google.com/open?id=1ZX7QOy6LZuTLTnsOtQk-kmKq2-69l5hu) | 955 GB | 70,000 | PNG | Original images from Flickr\n| &boxvr;&nbsp; [tfrecords](https://drive.google.com/open?id=1LTBpJ0W_WLjqza3zdayligS8Dh1V1gA6) | 273 GB | 9 | tfrecords | Multi-resolution data for [StyleGAN](https://github.com/NVlabs/stylegan) and [StyleGAN2](https://github.com/NVlabs/stylegan2)\n| &boxur;&nbsp; [zips](https://drive.google.com/open?id=1WocxvZ4GEZ1DI8dOz30aSj2zT6pkATYS) | 1.28 TB | 4 | ZIP | Contents of each folder as a ZIP archive.\n\nHigh-level statistics:\n\n![Pie charts](./ffhq-piecharts.png)\n\nFor use cases that require separate training and validation sets, we have appointed the first 60,000 images to be used for training and the remaining 10,000 for validation. In the [StyleGAN paper](https://arxiv.org/abs/1812.04948), however, we used all 70,000 images for training.\n\nWe have explicitly made sure that there are no duplicate images in the dataset itself. However, please note that the `in-the-wild` folder may contain multiple copies of the same image in cases where we extracted several different faces from the same image.\n\n## Download script\n\nYou can either grab the data directly from Google Drive or use the provided [download script](./download_ffhq.py). The script makes things considerably easier by automatically downloading all the requested files, verifying their checksums, retrying each file several times on error, and employing multiple concurrent connections to maximize bandwidth.\n\n```\n> python download_ffhq.py -h\nusage: download_ffhq.py [-h] [-j] [-s] [-i] [-t] [-w] [-r] [-a]\n                        [--num_threads NUM] [--status_delay SEC]\n                        [--timing_window LEN] [--chunk_size KB]\n                        [--num_attempts NUM]\n\nDownload Flickr-Face-HQ (FFHQ) dataset to current working directory.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -j, --json            download metadata as JSON (254 MB)\n  -s, --stats           print statistics about the dataset\n  -i, --images          download 1024x1024 images as PNG (89.1 GB)\n  -t, --thumbs          download 128x128 thumbnails as PNG (1.95 GB)\n  -w, --wilds           download in-the-wild images as PNG (955 GB)\n  -r, --tfrecords       download multi-resolution TFRecords (273 GB)\n  -a, --align           recreate 1024x1024 images from in-the-wild images\n  --num_threads NUM     number of concurrent download threads (default: 32)\n  --status_delay SEC    time between download status prints (default: 0.2)\n  --timing_window LEN   samples for estimating download eta (default: 50)\n  --chunk_size KB       chunk size for each download thread (default: 128)\n  --num_attempts NUM    number of download attempts per file (default: 10)\n  --random-shift SHIFT  standard deviation of random crop rectangle jitter\n  --retry-crops         retry random shift if crop rectangle falls outside image (up to 1000\n                        times)\n  --no-rotation         keep the original orientation of images\n  --no-padding          do not apply blur-padding outside and near the image borders\n  --source-dir DIR      where to find already downloaded FFHQ source data\n```\n\n```\n> python ..\\download_ffhq.py --json --images\nDownloading JSON metadata...\n\\ 100.00% done  2/2 files  0.25/0.25 GB   43.21 MB/s  ETA: done\nParsing JSON metadata...\nDownloading 70000 files...\n| 100.00% done  70001/70001 files  89.19 GB/89.19 GB  59.87 MB/s  ETA: done\n```\n\nThe script also serves as a reference implementation of the automated scheme that we used to align and crop the images. Once you have downloaded the in-the-wild images with `python download_ffhq.py --wilds`, you can run `python download_ffhq.py --align` to reproduce exact replicas of the aligned 1024&times;1024 images using the facial landmark locations included in the metadata.\n\n### Reproducing the unaligned FFHQ\n\nTo reproduce the \"unaligned FFHQ\" dataset as used in the [Alias-Free Generative Adversarial Networks](https://arxiv.org/abs/2106.12423) paper, use the following options:\n\n```\npython download_ffhq.py \\\n    --source-dir <path/to/downloaded/ffhq> \\\n    --align --no-rotation --random-shift 0.2 --no-padding --retry-crops\n```\n\n\n## Metadata\n\nThe `ffhq-dataset-v2.json` file contains the following information for each image in a machine-readable format:\n\n```\n{\n  \"0\": {                                                 # Image index\n    \"category\": \"training\",                              # Training or validation\n    \"metadata\": {                                        # Info about the original Flickr photo:\n      \"photo_url\": \"https://www.flickr.com/photos/...\",  # - Flickr URL\n      \"photo_title\": \"DSCF0899.JPG\",                     # - File name\n      \"author\": \"Jeremy Frumkin\",                        # - Author\n      \"country\": \"\",                                     # - Country where the photo was taken\n      \"license\": \"Attribution-NonCommercial License\",    # - License name\n      \"license_url\": \"https://creativecommons.org/...\",  # - License detail URL\n      \"date_uploaded\": \"2007-08-16\",                     # - Date when the photo was uploaded to Flickr\n      \"date_crawled\": \"2018-10-10\"                       # - Date when the photo was crawled from Flickr\n    },\n    \"image\": {                                           # Info about the aligned 1024x1024 image:\n      \"file_url\": \"https://drive.google.com/...\",        # - Google Drive URL\n      \"file_path\": \"images1024x1024/00000/00000.png\",    # - Google Drive path\n      \"file_size\": 1488194,                              # - Size of the PNG file in bytes\n      \"file_md5\": \"ddeaeea6ce59569643715759d537fd1b\",    # - MD5 checksum of the PNG file\n      \"pixel_size\": [1024, 1024],                        # - Image dimensions\n      \"pixel_md5\": \"47238b44dfb87644460cbdcc4607e289\",   # - MD5 checksum of the raw pixel data\n      \"face_landmarks\": [...]                            # - 68 face landmarks reported by dlib\n    },\n    \"thumbnail\": {                                       # Info about the 128x128 thumbnail:\n      \"file_url\": \"https://drive.google.com/...\",        # - Google Drive URL\n      \"file_path\": \"thumbnails128x128/00000/00000.png\",  # - Google Drive path\n      \"file_size\": 29050,                                # - Size of the PNG file in bytes\n      \"file_md5\": \"bd3e40b2ba20f76b55dc282907b89cd1\",    # - MD5 checksum of the PNG file\n      \"pixel_size\": [128, 128],                          # - Image dimensions\n      \"pixel_md5\": \"38d7e93eb9a796d0e65f8c64de8ba161\"    # - MD5 checksum of the raw pixel data\n    },\n    \"in_the_wild\": {                                     # Info about the in-the-wild image:\n      \"file_url\": \"https://drive.google.com/...\",        # - Google Drive URL\n      \"file_path\": \"in-the-wild-images/00000/00000.png\", # - Google Drive path\n      \"file_size\": 3991569,                              # - Size of the PNG file in bytes\n      \"file_md5\": \"1dc0287e73e485efb0516a80ce9d42b4\",    # - MD5 checksum of the PNG file\n      \"pixel_size\": [2016, 1512],                        # - Image dimensions\n      \"pixel_md5\": \"86b3470c42e33235d76b979161fb2327\",   # - MD5 checksum of the raw pixel data\n      \"face_rect\": [667, 410, 1438, 1181],               # - Axis-aligned rectangle of the face region\n      \"face_landmarks\": [...],                           # - 68 face landmarks reported by dlib\n      \"face_quad\": [...]                                 # - Aligned quad of the face region\n    }\n  },\n  ...\n}\n```\n\n## Acknowledgements\n\nWe thank Jaakko Lehtinen, David Luebke, and Tuomas Kynk&auml;&auml;nniemi for in-depth discussions and helpful comments; Janne Hellsten, Tero Kuosmanen, and Pekka J&auml;nis for compute infrastructure and help with the code release.\n\nWe also thank Vahid Kazemi and Josephine Sullivan for their work on automatic face detection and alignment that enabled us to collect the data in the first place:\n\n> **One Millisecond Face Alignment with an Ensemble of Regression Trees**<br>\n> Vahid Kazemi, Josephine Sullivan<br>\n> Proc. CVPR 2014<br>\n> https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Kazemi_One_Millisecond_Face_2014_CVPR_paper.pdf\n\n## Privacy\n\nWhen collecting the data, we were careful to only include photos that &ndash; to the best of our knowledge &ndash; were intended for free use and redistribution by their respective authors. That said, we are committed to protecting the privacy of individuals who do not wish their photos to be included.\n\nTo find out whether your photo is included in the Flickr-Faces-HQ dataset, please [click this link](https://nvlabs.github.io/ffhq-dataset/search/) to search the dataset with your Flickr username.\n\nTo get your photo removed from the Flickr-Faces-HQ dataset:\n\n1. Go to Flickr and do one of the following:\n    - Tag the photo with `no_cv` to indicate that you do not wish it to be used for computer vision research.\n    - Change the license of the photo to `None` (All rights reserved) or any Creative Commons license with `NoDerivs` to indicate that you do not want it to be redistributed.\n    - Make the photo private, i.e., only visible to you and your friends/family.\n    - Get the photo removed from Flickr altogether.\n2. Contact [researchinquiries@nvidia.com](mailto:researchinquiries@nvidia.com). Please include your Flickr username in the email.\n3. We will check the status of all photos from the particular user and update the dataset accordingly.\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "download_ffhq.py",
          "type": "blob",
          "size": 23.2705078125,
          "content": "# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n#\n# This work is licensed under the Creative Commons\n# Attribution-NonCommercial-ShareAlike 4.0 International License.\n# To view a copy of this license, visit\n# http://creativecommons.org/licenses/by-nc-sa/4.0/ or send a letter to\n# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n\n\"\"\"Download Flickr-Faces-HQ (FFHQ) dataset to current working directory.\"\"\"\n\nimport os\nimport sys\nimport requests\nimport html\nimport hashlib\nimport PIL.Image\nimport PIL.ImageFile\nimport numpy as np\nimport scipy.ndimage\nimport threading\nimport queue\nimport time\nimport json\nimport uuid\nimport glob\nimport argparse\nimport itertools\nimport shutil\nfrom collections import OrderedDict, defaultdict\n\nPIL.ImageFile.LOAD_TRUNCATED_IMAGES = True # avoid \"Decompressed Data Too Large\" error\n\n#----------------------------------------------------------------------------\n\njson_spec = dict(file_url='https://drive.google.com/uc?id=16N0RV4fHI6joBuKbQAoG34V_cQk7vxSA', file_path='ffhq-dataset-v2.json', file_size=267793842, file_md5='425ae20f06a4da1d4dc0f46d40ba5fd6')\n\ntfrecords_specs = [\n    dict(file_url='https://drive.google.com/uc?id=1LnhoytWihRRJ7CfhLQ76F8YxwxRDlZN3', file_path='tfrecords/ffhq/ffhq-r02.tfrecords', file_size=6860000,      file_md5='63e062160f1ef9079d4f51206a95ba39'),\n    dict(file_url='https://drive.google.com/uc?id=1LWeKZGZ_x2rNlTenqsaTk8s7Cpadzjbh', file_path='tfrecords/ffhq/ffhq-r03.tfrecords', file_size=17290000,     file_md5='54fb32a11ebaf1b86807cc0446dd4ec5'),\n    dict(file_url='https://drive.google.com/uc?id=1Lr7Tiufr1Za85HQ18yg3XnJXstiI2BAC', file_path='tfrecords/ffhq/ffhq-r04.tfrecords', file_size=57610000,     file_md5='7164cc5531f6828bf9c578bdc3320e49'),\n    dict(file_url='https://drive.google.com/uc?id=1LnyiayZ-XJFtatxGFgYePcs9bdxuIJO_', file_path='tfrecords/ffhq/ffhq-r05.tfrecords', file_size=218890000,    file_md5='050cc7e5fd07a1508eaa2558dafbd9ed'),\n    dict(file_url='https://drive.google.com/uc?id=1Lt6UP201zHnpH8zLNcKyCIkbC-aMb5V_', file_path='tfrecords/ffhq/ffhq-r06.tfrecords', file_size=864010000,    file_md5='90bedc9cc07007cd66615b2b1255aab8'),\n    dict(file_url='https://drive.google.com/uc?id=1LwOP25fJ4xN56YpNCKJZM-3mSMauTxeb', file_path='tfrecords/ffhq/ffhq-r07.tfrecords', file_size=3444980000,   file_md5='bff839e0dda771732495541b1aff7047'),\n    dict(file_url='https://drive.google.com/uc?id=1LxxgVBHWgyN8jzf8bQssgVOrTLE8Gv2v', file_path='tfrecords/ffhq/ffhq-r08.tfrecords', file_size=13766900000,  file_md5='74de4f07dc7bfb07c0ad4471fdac5e67'),\n    dict(file_url='https://drive.google.com/uc?id=1M-ulhD5h-J7sqSy5Y1njUY_80LPcrv3V', file_path='tfrecords/ffhq/ffhq-r09.tfrecords', file_size=55054580000,  file_md5='05355aa457a4bd72709f74a81841b46d'),\n    dict(file_url='https://drive.google.com/uc?id=1M11BIdIpFCiapUqV658biPlaXsTRvYfM', file_path='tfrecords/ffhq/ffhq-r10.tfrecords', file_size=220205650000, file_md5='bf43cab9609ab2a27892fb6c2415c11b'),\n]\n\nlicense_specs = {\n    'json':      dict(file_url='https://drive.google.com/uc?id=1SHafCugkpMZzYhbgOz0zCuYiy-hb9lYX', file_path='LICENSE.txt',                    file_size=1610, file_md5='724f3831aaecd61a84fe98500079abc2'),\n    'images':    dict(file_url='https://drive.google.com/uc?id=1sP2qz8TzLkzG2gjwAa4chtdB31THska4', file_path='images1024x1024/LICENSE.txt',    file_size=1610, file_md5='724f3831aaecd61a84fe98500079abc2'),\n    'thumbs':    dict(file_url='https://drive.google.com/uc?id=1iaL1S381LS10VVtqu-b2WfF9TiY75Kmj', file_path='thumbnails128x128/LICENSE.txt',  file_size=1610, file_md5='724f3831aaecd61a84fe98500079abc2'),\n    'wilds':     dict(file_url='https://drive.google.com/uc?id=1rsfFOEQvkd6_Z547qhpq5LhDl2McJEzw', file_path='in-the-wild-images/LICENSE.txt', file_size=1610, file_md5='724f3831aaecd61a84fe98500079abc2'),\n    'tfrecords': dict(file_url='https://drive.google.com/uc?id=1SYUmqKdLoTYq-kqsnPsniLScMhspvl5v', file_path='tfrecords/ffhq/LICENSE.txt',     file_size=1610, file_md5='724f3831aaecd61a84fe98500079abc2'),\n}\n\n#----------------------------------------------------------------------------\n\ndef download_file(session, file_spec, stats, chunk_size=128, num_attempts=10, **kwargs):\n    file_path = file_spec['file_path']\n    file_url = file_spec['file_url']\n    file_dir = os.path.dirname(file_path)\n    tmp_path = file_path + '.tmp.' + uuid.uuid4().hex\n    if file_dir:\n        os.makedirs(file_dir, exist_ok=True)\n\n    for attempts_left in reversed(range(num_attempts)):\n        data_size = 0\n        try:\n            # Download.\n            data_md5 = hashlib.md5()\n            with session.get(file_url, stream=True) as res:\n                res.raise_for_status()\n                with open(tmp_path, 'wb') as f:\n                    for chunk in res.iter_content(chunk_size=chunk_size<<10):\n                        f.write(chunk)\n                        data_size += len(chunk)\n                        data_md5.update(chunk)\n                        with stats['lock']:\n                            stats['bytes_done'] += len(chunk)\n\n            # Validate.\n            if 'file_size' in file_spec and data_size != file_spec['file_size']:\n                raise IOError('Incorrect file size', file_path)\n            if 'file_md5' in file_spec and data_md5.hexdigest() != file_spec['file_md5']:\n                raise IOError('Incorrect file MD5', file_path)\n            if 'pixel_size' in file_spec or 'pixel_md5' in file_spec:\n                with PIL.Image.open(tmp_path) as image:\n                    if 'pixel_size' in file_spec and list(image.size) != file_spec['pixel_size']:\n                        raise IOError('Incorrect pixel size', file_path)\n                    if 'pixel_md5' in file_spec and hashlib.md5(np.array(image)).hexdigest() != file_spec['pixel_md5']:\n                        raise IOError('Incorrect pixel MD5', file_path)\n            break\n\n        except:\n            with stats['lock']:\n                stats['bytes_done'] -= data_size\n\n            # Handle known failure cases.\n            if data_size > 0 and data_size < 8192:\n                with open(tmp_path, 'rb') as f:\n                    data = f.read()\n                data_str = data.decode('utf-8')\n\n                # Google Drive virus checker nag.\n                links = [html.unescape(link) for link in data_str.split('\"') if 'export=download' in link]\n                if len(links) == 1:\n                    if attempts_left:\n                        file_url = requests.compat.urljoin(file_url, links[0])\n                        continue\n\n                # Google Drive quota exceeded.\n                if 'Google Drive - Quota exceeded' in data_str:\n                    if not attempts_left:\n                        raise IOError(\"Google Drive download quota exceeded -- please try again later\")\n\n            # Last attempt => raise error.\n            if not attempts_left:\n                raise\n\n    # Rename temp file to the correct name.\n    os.replace(tmp_path, file_path) # atomic\n    with stats['lock']:\n        stats['files_done'] += 1\n\n    # Attempt to clean up any leftover temps.\n    for filename in glob.glob(file_path + '.tmp.*'):\n        try:\n            os.remove(filename)\n        except:\n            pass\n\n#----------------------------------------------------------------------------\n\ndef choose_bytes_unit(num_bytes):\n    b = int(np.rint(num_bytes))\n    if b < (100 << 0): return 'B', (1 << 0)\n    if b < (100 << 10): return 'kB', (1 << 10)\n    if b < (100 << 20): return 'MB', (1 << 20)\n    if b < (100 << 30): return 'GB', (1 << 30)\n    return 'TB', (1 << 40)\n\n#----------------------------------------------------------------------------\n\ndef format_time(seconds):\n    s = int(np.rint(seconds))\n    if s < 60: return '%ds' % s\n    if s < 60 * 60: return '%dm %02ds' % (s // 60, s % 60)\n    if s < 24 * 60 * 60: return '%dh %02dm' % (s // (60 * 60), (s // 60) % 60)\n    if s < 100 * 24 * 60 * 60: return '%dd %02dh' % (s // (24 * 60 * 60), (s // (60 * 60)) % 24)\n    return '>100d'\n\n#----------------------------------------------------------------------------\n\ndef download_files(file_specs, num_threads=32, status_delay=0.2, timing_window=50, **download_kwargs):\n\n    # Determine which files to download.\n    done_specs = {spec['file_path']: spec for spec in file_specs if os.path.isfile(spec['file_path'])}\n    missing_specs = [spec for spec in file_specs if spec['file_path'] not in done_specs]\n    files_total = len(file_specs)\n    bytes_total = sum(spec['file_size'] for spec in file_specs)\n    stats = dict(files_done=len(done_specs), bytes_done=sum(spec['file_size'] for spec in done_specs.values()), lock=threading.Lock())\n    if len(done_specs) == files_total:\n        print('All files already downloaded -- skipping.')\n        return\n\n    # Launch worker threads.\n    spec_queue = queue.Queue()\n    exception_queue = queue.Queue()\n    for spec in missing_specs:\n        spec_queue.put(spec)\n    thread_kwargs = dict(spec_queue=spec_queue, exception_queue=exception_queue, stats=stats, download_kwargs=download_kwargs)\n    for _thread_idx in range(min(num_threads, len(missing_specs))):\n        threading.Thread(target=_download_thread, kwargs=thread_kwargs, daemon=True).start()\n\n    # Monitor status until done.\n    bytes_unit, bytes_div = choose_bytes_unit(bytes_total)\n    spinner = '/-\\\\|'\n    timing = []\n    while True:\n        with stats['lock']:\n            files_done = stats['files_done']\n            bytes_done = stats['bytes_done']\n        spinner = spinner[1:] + spinner[:1]\n        timing = timing[max(len(timing) - timing_window + 1, 0):] + [(time.time(), bytes_done)]\n        bandwidth = max((timing[-1][1] - timing[0][1]) / max(timing[-1][0] - timing[0][0], 1e-8), 0)\n        bandwidth_unit, bandwidth_div = choose_bytes_unit(bandwidth)\n        eta = format_time((bytes_total - bytes_done) / max(bandwidth, 1))\n\n        print('\\r%s %6.2f%% done  %d/%d files  %-13s  %-10s  ETA: %-7s ' % (\n            spinner[0],\n            bytes_done / bytes_total * 100,\n            files_done, files_total,\n            '%.2f/%.2f %s' % (bytes_done / bytes_div, bytes_total / bytes_div, bytes_unit),\n            '%.2f %s/s' % (bandwidth / bandwidth_div, bandwidth_unit),\n            'done' if bytes_total == bytes_done else '...' if len(timing) < timing_window or bandwidth == 0 else eta,\n        ), end='', flush=True)\n\n        if files_done == files_total:\n            print()\n            break\n\n        try:\n            exc_info = exception_queue.get(timeout=status_delay)\n            raise exc_info[1].with_traceback(exc_info[2])\n        except queue.Empty:\n            pass\n\ndef _download_thread(spec_queue, exception_queue, stats, download_kwargs):\n    with requests.Session() as session:\n        while not spec_queue.empty():\n            spec = spec_queue.get()\n            try:\n                download_file(session, spec, stats, **download_kwargs)\n            except:\n                exception_queue.put(sys.exc_info())\n\n#----------------------------------------------------------------------------\n\ndef print_statistics(json_data):\n    categories = defaultdict(int)\n    licenses = defaultdict(int)\n    countries = defaultdict(int)\n    for item in json_data.values():\n        categories[item['category']] += 1\n        licenses[item['metadata']['license']] += 1\n        country = item['metadata']['country']\n        countries[country if country else '<Unknown>'] += 1\n\n    for name in [name for name, num in countries.items() if num / len(json_data) < 1e-3]:\n        countries['<Other>'] += countries.pop(name)\n\n    rows = [[]] * 2\n    rows += [['Category', 'Images', '% of all']]\n    rows += [['---'] * 3]\n    for name, num in sorted(categories.items(), key=lambda x: -x[1]):\n        rows += [[name, '%d' % num, '%.2f' % (100.0 * num / len(json_data))]]\n\n    rows += [[]] * 2\n    rows += [['License', 'Images', '% of all']]\n    rows += [['---'] * 3]\n    for name, num in sorted(licenses.items(), key=lambda x: -x[1]):\n        rows += [[name, '%d' % num, '%.2f' % (100.0 * num / len(json_data))]]\n\n    rows += [[]] * 2\n    rows += [['Country', 'Images', '% of all', '% of known']]\n    rows += [['---'] * 4]\n    for name, num in sorted(countries.items(), key=lambda x: -x[1] if x[0] != '<Other>' else 0):\n        rows += [[name, '%d' % num, '%.2f' % (100.0 * num / len(json_data)),\n            '%.2f' % (0 if name == '<Unknown>' else 100.0 * num / (len(json_data) - countries['<Unknown>']))]]\n\n    rows += [[]] * 2\n    widths = [max(len(cell) for cell in column if cell is not None) for column in itertools.zip_longest(*rows)]\n    for row in rows:\n        print(\"  \".join(cell + \" \" * (width - len(cell)) for cell, width in zip(row, widths)))\n\n#----------------------------------------------------------------------------\n\ndef recreate_aligned_images(json_data, source_dir, dst_dir='realign1024x1024', output_size=1024, transform_size=4096, enable_padding=True, rotate_level=True, random_shift=0.0, retry_crops=False):\n    print('Recreating aligned images...')\n\n    # Fix random seed for reproducibility\n    np.random.seed(12345)\n    # The following random numbers are unused in present implementation, but we consume them for reproducibility\n    _ = np.random.normal(0, 1, (len(json_data.values()), 2))\n\n    if dst_dir:\n        os.makedirs(dst_dir, exist_ok=True)\n        shutil.copyfile('LICENSE.txt', os.path.join(dst_dir, 'LICENSE.txt'))\n\n    for item_idx, item in enumerate(json_data.values()):\n        print('\\r%d / %d ... ' % (item_idx, len(json_data)), end='', flush=True)\n\n        # Parse landmarks.\n        # pylint: disable=unused-variable\n        lm = np.array(item['in_the_wild']['face_landmarks'])\n        lm_chin          = lm[0  : 17]  # left-right\n        lm_eyebrow_left  = lm[17 : 22]  # left-right\n        lm_eyebrow_right = lm[22 : 27]  # left-right\n        lm_nose          = lm[27 : 31]  # top-down\n        lm_nostrils      = lm[31 : 36]  # top-down\n        lm_eye_left      = lm[36 : 42]  # left-clockwise\n        lm_eye_right     = lm[42 : 48]  # left-clockwise\n        lm_mouth_outer   = lm[48 : 60]  # left-clockwise\n        lm_mouth_inner   = lm[60 : 68]  # left-clockwise\n\n        # Calculate auxiliary vectors.\n        eye_left     = np.mean(lm_eye_left, axis=0)\n        eye_right    = np.mean(lm_eye_right, axis=0)\n        eye_avg      = (eye_left + eye_right) * 0.5\n        eye_to_eye   = eye_right - eye_left\n        mouth_left   = lm_mouth_outer[0]\n        mouth_right  = lm_mouth_outer[6]\n        mouth_avg    = (mouth_left + mouth_right) * 0.5\n        eye_to_mouth = mouth_avg - eye_avg\n\n        # Choose oriented crop rectangle.\n        if rotate_level:\n            x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n            x /= np.hypot(*x)\n            x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n            y = np.flipud(x) * [-1, 1]\n            c0 = eye_avg + eye_to_mouth * 0.1\n        else:\n            x = np.array([1, 0], dtype=np.float64)\n            x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n            y = np.flipud(x) * [-1, 1]\n            c0 = eye_avg + eye_to_mouth * 0.1\n\n        # Load in-the-wild image.\n        src_file = os.path.join(source_dir, item['in_the_wild']['file_path'])\n        if not os.path.isfile(src_file):\n            print('\\nCannot find source image. Please run \"--wilds\" before \"--align\".')\n            return\n        img = PIL.Image.open(src_file)\n\n        quad = np.stack([c0 - x - y, c0 - x + y, c0 + x + y, c0 + x - y])\n        qsize = np.hypot(*x) * 2\n\n        # Keep drawing new random crop offsets until we find one that is contained in the image\n        # and does not require padding\n        if random_shift != 0:\n            for _ in range(1000):\n                # Offset the crop rectange center by a random shift proportional to image dimension\n                # and the requested standard deviation\n                c = (c0 + np.hypot(*x)*2 * random_shift * np.random.normal(0, 1, c0.shape))\n                quad = np.stack([c - x - y, c - x + y, c + x + y, c + x - y])\n                crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n                if not retry_crops or not (crop[0] < 0 or crop[1] < 0 or crop[2] >= img.width or crop[3] >= img.height):\n                    # We're happy with this crop (either it fits within the image, or retries are disabled)\n                    break\n            else:\n                # rejected N times, give up and move to next image\n                # (does not happen in practice with the FFHQ data)\n                print('rejected image')\n                return\n\n        # Shrink.\n        shrink = int(np.floor(qsize / output_size * 0.5))\n        if shrink > 1:\n            rsize = (int(np.rint(float(img.size[0]) / shrink)), int(np.rint(float(img.size[1]) / shrink)))\n            img = img.resize(rsize, PIL.Image.ANTIALIAS)\n            quad /= shrink\n            qsize /= shrink\n\n        # Crop.\n        border = max(int(np.rint(qsize * 0.1)), 3)\n        crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n        crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n        if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n            img = img.crop(crop)\n            quad -= crop[0:2]\n\n        # Pad.\n        pad = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n        pad = (max(-pad[0] + border, 0), max(-pad[1] + border, 0), max(pad[2] - img.size[0] + border, 0), max(pad[3] - img.size[1] + border, 0))\n        if enable_padding and max(pad) > border - 4:\n            pad = np.maximum(pad, int(np.rint(qsize * 0.3)))\n            img = np.pad(np.float32(img), ((pad[1], pad[3]), (pad[0], pad[2]), (0, 0)), 'reflect')\n            h, w, _ = img.shape\n            y, x, _ = np.ogrid[:h, :w, :1]\n            mask = np.maximum(1.0 - np.minimum(np.float32(x) / pad[0], np.float32(w-1-x) / pad[2]), 1.0 - np.minimum(np.float32(y) / pad[1], np.float32(h-1-y) / pad[3]))\n            blur = qsize * 0.02\n            img += (scipy.ndimage.gaussian_filter(img, [blur, blur, 0]) - img) * np.clip(mask * 3.0 + 1.0, 0.0, 1.0)\n            img += (np.median(img, axis=(0,1)) - img) * np.clip(mask, 0.0, 1.0)\n            img = PIL.Image.fromarray(np.uint8(np.clip(np.rint(img), 0, 255)), 'RGB')\n            quad += pad[:2]\n\n        # Transform.\n        img = img.transform((transform_size, transform_size), PIL.Image.QUAD, (quad + 0.5).flatten(), PIL.Image.BILINEAR)\n        if output_size < transform_size:\n            img = img.resize((output_size, output_size), PIL.Image.ANTIALIAS)\n\n        # Save aligned image.\n        dst_subdir = os.path.join(dst_dir, '%05d' % (item_idx - item_idx % 1000))\n        os.makedirs(dst_subdir, exist_ok=True)\n        img.save(os.path.join(dst_subdir, '%05d.png' % item_idx))\n\n    # All done.\n    print('\\r%d / %d ... done' % (len(json_data), len(json_data)))\n\n#----------------------------------------------------------------------------\n\ndef run(tasks, **download_kwargs):\n    if not os.path.isfile(json_spec['file_path']) or not os.path.isfile('LICENSE.txt'):\n        print('Downloading JSON metadata...')\n        download_files([json_spec, license_specs['json']], **download_kwargs)\n\n    print('Parsing JSON metadata...')\n    with open(json_spec['file_path'], 'rb') as f:\n        json_data = json.load(f, object_pairs_hook=OrderedDict)\n\n    if 'stats' in tasks:\n        print_statistics(json_data)\n\n    specs = []\n    if 'images' in tasks:\n        specs += [item['image'] for item in json_data.values()] + [license_specs['images']]\n    if 'thumbs' in tasks:\n        specs += [item['thumbnail'] for item in json_data.values()] + [license_specs['thumbs']]\n    if 'wilds' in tasks:\n        specs += [item['in_the_wild'] for item in json_data.values()] + [license_specs['wilds']]\n    if 'tfrecords' in tasks:\n        specs += tfrecords_specs + [license_specs['tfrecords']]\n\n    if len(specs):\n        print('Downloading %d files...' % len(specs))\n        np.random.shuffle(specs) # to make the workload more homogeneous\n        download_files(specs, **download_kwargs)\n\n    if 'align' in tasks:\n        recreate_aligned_images(json_data, source_dir=download_kwargs['source_dir'], rotate_level=not download_kwargs['no_rotation'], random_shift=download_kwargs['random_shift'], enable_padding=not download_kwargs['no_padding'], retry_crops=download_kwargs['retry_crops'])\n\n#----------------------------------------------------------------------------\n\ndef run_cmdline(argv):\n    parser = argparse.ArgumentParser(prog=argv[0], description='Download Flickr-Face-HQ (FFHQ) dataset to current working directory.')\n    parser.add_argument('-j', '--json',         help='download metadata as JSON (254 MB)', dest='tasks', action='append_const', const='json')\n    parser.add_argument('-s', '--stats',        help='print statistics about the dataset', dest='tasks', action='append_const', const='stats')\n    parser.add_argument('-i', '--images',       help='download 1024x1024 images as PNG (89.1 GB)', dest='tasks', action='append_const', const='images')\n    parser.add_argument('-t', '--thumbs',       help='download 128x128 thumbnails as PNG (1.95 GB)', dest='tasks', action='append_const', const='thumbs')\n    parser.add_argument('-w', '--wilds',        help='download in-the-wild images as PNG (955 GB)', dest='tasks', action='append_const', const='wilds')\n    parser.add_argument('-r', '--tfrecords',    help='download multi-resolution TFRecords (273 GB)', dest='tasks', action='append_const', const='tfrecords')\n    parser.add_argument('-a', '--align',        help='recreate 1024x1024 images from in-the-wild images', dest='tasks', action='append_const', const='align')\n    parser.add_argument('--num_threads',        help='number of concurrent download threads (default: 32)', type=int, default=32, metavar='NUM')\n    parser.add_argument('--status_delay',       help='time between download status prints (default: 0.2)', type=float, default=0.2, metavar='SEC')\n    parser.add_argument('--timing_window',      help='samples for estimating download eta (default: 50)', type=int, default=50, metavar='LEN')\n    parser.add_argument('--chunk_size',         help='chunk size for each download thread (default: 128)', type=int, default=128, metavar='KB')\n    parser.add_argument('--num_attempts',       help='number of download attempts per file (default: 10)', type=int, default=10, metavar='NUM')\n    parser.add_argument('--random-shift',       help='standard deviation of random crop rectangle jitter', type=float, default=0.0, metavar='SHIFT')\n    parser.add_argument('--retry-crops',        help='retry random shift if crop rectangle falls outside image (up to 1000 times)', dest='retry_crops', default=False, action='store_true')\n    parser.add_argument('--no-rotation',        help='keep the original orientation of images', dest='no_rotation', default=False, action='store_true')\n    parser.add_argument('--no-padding',         help='do not apply blur-padding outside and near the image borders', dest='no_padding', default=False, action='store_true')\n    parser.add_argument('--source-dir',         help='where to find already downloaded FFHQ source data', default='', metavar='DIR')\n\n    args = parser.parse_args()\n    if not args.tasks:\n        print('No tasks specified. Please see \"-h\" for help.')\n        exit(1)\n    run(**vars(args))\n\n#----------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    run_cmdline(sys.argv)\n\n#----------------------------------------------------------------------------\n"
        },
        {
          "name": "ffhq-piecharts.png",
          "type": "blob",
          "size": 73.0595703125,
          "content": null
        },
        {
          "name": "ffhq-teaser.png",
          "type": "blob",
          "size": 928.7685546875,
          "content": null
        }
      ]
    }
  ]
}