{
  "metadata": {
    "timestamp": 1736559487703,
    "page": 59,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjYw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "DropsDevopsOrg/ECommerceCrawlers",
      "stars": 4838,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".DS_Store",
          "type": "blob",
          "size": 10.00390625,
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0595703125,
          "content": "*.html linguist-language=python\n*.js linguist-language=python"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.19921875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# idea\n.idea\n*.iml\n*.xml\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 6.15625,
          "content": "# Citizen Code of Conduct\n\n## 1. Purpose\n\nA primary goal of E Commerce Crawlers is to be inclusive to the largest number of contributors, with the most varied and diverse backgrounds possible. As such, we are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, ability, ethnicity, socioeconomic status, and religion (or lack thereof).\n\nThis code of conduct outlines our expectations for all those who participate in our community, as well as the consequences for unacceptable behavior.\n\nWe invite all those who participate in E Commerce Crawlers to help us create safe and positive experiences for everyone.\n\n## 2. Open [Source/Culture/Tech] Citizenship\n\nA supplemental goal of this Code of Conduct is to increase open [source/culture/tech] citizenship by encouraging participants to recognize and strengthen the relationships between our actions and their effects on our community.\n\nCommunities mirror the societies in which they exist and positive action is essential to counteract the many forms of inequality and abuses of power that exist in society.\n\nIf you see someone who is making an extra effort to ensure our community is welcoming, friendly, and encourages all participants to contribute to the fullest extent, we want to know.\n\n## 3. Expected Behavior\n\nThe following behaviors are expected and requested of all community members:\n\n * Participate in an authentic and active way. In doing so, you contribute to the health and longevity of this community.\n * Exercise consideration and respect in your speech and actions.\n * Attempt collaboration before conflict.\n * Refrain from demeaning, discriminatory, or harassing behavior and speech.\n * Be mindful of your surroundings and of your fellow participants. Alert community leaders if you notice a dangerous situation, someone in distress, or violations of this Code of Conduct, even if they seem inconsequential.\n * Remember that community event venues may be shared with members of the public; please be respectful to all patrons of these locations.\n\n## 4. Unacceptable Behavior\n\nThe following behaviors are considered harassment and are unacceptable within our community:\n\n * Violence, threats of violence or violent language directed against another person.\n * Sexist, racist, homophobic, transphobic, ableist or otherwise discriminatory jokes and language.\n * Posting or displaying sexually explicit or violent material.\n * Posting or threatening to post other people's personally identifying information (\"doxing\").\n * Personal insults, particularly those related to gender, sexual orientation, race, religion, or disability.\n * Inappropriate photography or recording.\n * Inappropriate physical contact. You should have someone's consent before touching them.\n * Unwelcome sexual attention. This includes, sexualized comments or jokes; inappropriate touching, groping, and unwelcomed sexual advances.\n * Deliberate intimidation, stalking or following (online or in person).\n * Advocating for, or encouraging, any of the above behavior.\n * Sustained disruption of community events, including talks and presentations.\n\n## 5. Weapons Policy\n\nNo weapons will be allowed at E Commerce Crawlers events, community spaces, or in other spaces covered by the scope of this Code of Conduct. Weapons include but are not limited to guns, explosives (including fireworks), and large knives such as those used for hunting or display, as well as any other item used for the purpose of causing injury or harm to others. Anyone seen in possession of one of these items will be asked to leave immediately, and will only be allowed to return without the weapon. Community members are further expected to comply with all state and local laws on this matter.\n\n## 6. Consequences of Unacceptable Behavior\n\nUnacceptable behavior from any community member, including sponsors and those with decision-making authority, will not be tolerated.\n\nAnyone asked to stop unacceptable behavior is expected to comply immediately.\n\nIf a community member engages in unacceptable behavior, the community organizers may take any action they deem appropriate, up to and including a temporary ban or permanent expulsion from the community without warning (and without refund in the case of a paid event).\n\n## 7. Reporting Guidelines\n\nIf you are subject to or witness unacceptable behavior, or have any other concerns, please notify a community organizer as soon as possible. .\n\n\n\nAdditionally, community organizers are available to help community members engage with local law enforcement or to otherwise help those experiencing unacceptable behavior feel safe. In the context of in-person events, organizers will also provide escorts as desired by the person experiencing distress.\n\n## 8. Addressing Grievances\n\nIf you feel you have been falsely or unfairly accused of violating this Code of Conduct, you should notify DropsDevopsOrg with a concise description of your grievance. Your grievance will be handled in accordance with our existing governing policies. \n\n\n\n## 9. Scope\n\nWe expect all community participants (contributors, paid or otherwise; sponsors; and other guests) to abide by this Code of Conduct in all community venues--online and in-person--as well as in all one-on-one communications pertaining to community business.\n\nThis code of conduct and its related procedures also applies to unacceptable behavior occurring outside the scope of community activities when such behavior has the potential to adversely affect the safety and well-being of community members.\n\n## 10. Contact info\n\n\n\n## 11. License and attribution\n\nThe Citizen Code of Conduct is distributed by [Stumptown Syndicate](http://stumptownsyndicate.org) under a [Creative Commons Attribution-ShareAlike license](http://creativecommons.org/licenses/by-sa/3.0/). \n\nPortions of text derived from the [Django Code of Conduct](https://www.djangoproject.com/conduct/) and the [Geek Feminism Anti-Harassment Policy](http://geekfeminism.wikia.com/wiki/Conference_anti-harassment/Policy).\n\n_Revision 2.3. Posted 6 March 2017._\n\n_Revision 2.2. Posted 4 February 2016._\n\n_Revision 2.1. Posted 23 June 2014._\n\n_Revision 2.0, adopted by the [Stumptown Syndicate](http://stumptownsyndicate.org) board on 10 January 2013. Posted 17 March 2013._\n"
        },
        {
          "name": "DianpingCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "East_money",
          "type": "tree",
          "content": null
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0458984375,
          "content": "MIT License\n\nCopyright (c) 2019 DropsDevopsOrg\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "OthertCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "QiChaCha",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.744140625,
          "content": "[![](https://img.shields.io/badge/language-Python35-green.svg)]() [![](https://img.shields.io/badge/Branch-master-green.svg?longCache=true)]() [![](https://img.shields.io/github/followers/DropsDevopsOrg.svg?label=Follow)]() ![GitHub contributors](https://img.shields.io/github/contributors/DropsDevopsOrg/ECommerceCrawlers.svg) [![](https://img.shields.io/github/forks/DropsDevopsOrg/ECommerceCrawlers.svg?label=Fork&style=social)]() [![](https://img.shields.io/github/stars/DropsDevopsOrg/ECommerceCrawlers.svg?style=social)]() [![](https://img.shields.io/github/watchers/DropsDevopsOrg/ECommerceCrawlers.svg?label=Watch&style=social)]()\n\n## ECommerceCrawlers\n\n多种电商商品数据 🐍 爬虫，整理收集爬虫练习。每个项目都是成员写的。通过实战项目练习解决一般爬虫中遇到的问题。\n\n通过每个项目的 readme，了解爬取过程分析。\n\n对于精通爬虫的 pyer，这将是一个很好的例子减少重复收集轮子的过程。项目经常更新维护，确保即下即用，减少爬取的时间。\n\n对于小白通过 ✍️ 实战项目，了解爬虫的从无到有。爬虫知识构建可以移步[项目 wiki](https://github.com/DropsDevopsOrg/ECommerceCrawlers/wiki/%E7%88%AC%E8%99%AB%E5%88%B0%E5%BA%95%E8%BF%9D%E6%B3%95%E5%90%97%3F)。爬虫可能是一件非常复杂、技术门槛很高的事情，但掌握正确的方法，在短时间内做到能够爬取主流网站的数据，其实非常容易实现，但建议从一开始就要有一个具体的目标。\n\n在目标的驱动下，你的学习才会更加精准和高效。那些所有你认为必须的前置知识，都是可以在完成目标的过程中学到的 😁😁😁。\n\n需要进阶学习爬虫技巧，推荐王平大师傅的[猿人学·爬虫逆向高阶课](https://j.youzan.com/zF-n-2)，报AJay13推荐，可享受内部优惠价格。\n\n欢迎大家对本项目的不足加以指正，⭕️Issues 或者 🔔Pr\n\n> 在之前上传的大文件贯穿了 3/4 的 commits，发现每次 clone 达到 100M，这与我们最初的想法违背，我们不能很有效的删除每一个文件（太懒），将重新进行初始化仓库的 commit。并在今后不上传爬虫数据，优化仓库结构。\n\n## About\n\n- 码云仓库链接:[AJay13/ECommerceCrawlers](https://gitee.com/AJay13/ECommerceCrawlers)\n- Github 仓库链接:[DropsDevopsOrg/ECommerceCrawlers](https://github.com/DropsDevopsOrg/ECommerceCrawlers)\n- 项目展示平台链接:[http://wechat.doonsec.com](http://wechat.doonsec.com)\n\n## Income\n\n几乎 80%的项目都是帮客户写的爬虫，在添加到仓库之前已经经过客户同意可开源原则。\n\n\n\n## CrawlerDemo\n\n- [x] [DianpingCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/DianpingCrawler)：大众点评爬取\n- [x] [East_money](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/East_money)：scrapy 爬取东方财富网\n- [x] [📛TaobaoCrawler(new)](<https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/TaobaoCrawler(new)>)：阿里系全自主平台(淘宝、天猫、咸鱼、菜鸟裹裹、飞猪等)信息爬取 免 cookie, 理论上不被反爬虫机制(只提供淘宝，其他思路一样，加密方式一样)，\n- [x] [📛SIPO 专利审查](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/SIPO专利审查)：SIPO 专利审查 自动化客户端\n- [x] [📛QiChaCha](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/QiChaCha)：企查查 全国工业园区及企业信息\n- [x] [TaobaoCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/TaobaoCrawler)：淘宝商品爬取\n- [x] [📛ZhaopinCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/ZhaopinCrawler)：各大招聘网站爬取\n- [x] [ShicimingjuCrawleAndDisplayr](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/ShicimingjuCrawleAndDisplay)：诗词名家句网站爬取展示\n- [x] [XianyuCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/XianyuCrawler)：闲鱼商品爬取\n- [x] [SohuNewCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/SohuNewCrawler)：新闻网爬取\n- [x] [WechatCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/WechatCrawler)：微信公众号爬取\n- [x] [cnblog](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/cnblog)：scrapy 博客园爬取\n- [x] [WeiboCrawler](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/WeiboCrawler)：微博数据爬取免 cookie\n- [x] [OtherCrawlers](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler)：一些有趣的爬虫例子\n  - [x] [0x01 百度贴吧](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x01baidutieba)\n  - [x] [0x02 豆瓣电影](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x02doubanmovie)\n  - [x] [0x03 阿里任务](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x03alitask)\n  - [x] [0x04 包图网视频](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x04baotu)\n  - [x] [0x05 全景网图片](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x05quanjing)\n  - [x] [0x06 豆瓣音乐](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x06douban_music)\n  - [x] [0x07 某省药监局](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x07gdfda_pharmacy)\n  - [x] [0x08 fofa](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x08fofa)\n  - [ ] [0x09 汽车之家](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler#0x09autohome)\n  - [ ] [0x010 国家统计局]()\n  - [x] [0x10 baidu](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x10baidu)\n  - [x] [0x11 蜘蛛泛目录](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x11zzc)\n  - [x] [0x12 今日头条](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x12toutiao)\n  - [x] [0x13 豆瓣影评分析](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x13douban_yingping)\n  - [x] [0x14 协程评论爬取](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x14ctrip_crawler)\n  - [x] [0x15 小米应用商店爬取](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x15xiaomiappshop)\n  - [x] [0x16 酷安app信息采集](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x16kuanappshop)\n  - [ ] [0x17 知乎信息采集](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x17zhihu)\n  - [x] [0x18 必应图片采集](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x18bing_img)\n  - [x] [0x19 安居客信息采集](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x19anjuke)\n  - [x] [0x20 途家民宿信息采集](https://github.com/DropsDevopsOrg/ECommerceCrawlers/tree/master/OthertCrawler/0x20tujiaminsu)\n## Contribution👏\n\n| <a  href=\"https://gitee.com/joseph31\"><img class=\"avatar\" src=\"https://avatars3.githubusercontent.com/u/47005658?s=460&v=4\" width=\"48\" height=\"48\" alt=\"@joseph31\"></a> | <a  href=\"https://github.com/Joynice\"><img class=\"avatar\" src=\"https://avatars0.githubusercontent.com/u/22851022?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@Joynice\"></a> | <a href=\"https://github.com/liangweiyang\"><img class=\"avatar\" src=\"https://avatars0.githubusercontent.com/u/37971213?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@liangweiyang\"></a> | <a href=\"https://github.com/Hatcat123\"><img class=\"avatar\" src=\"https://avatars0.githubusercontent.com/u/28727970?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@Hatcat123\"></a> | <a href=\"https://github.com/jihu9\"><img class=\"avatar\" src=\"https://avatars0.githubusercontent.com/u/17663102?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@jihu9\"></a> | <a href=\"https://github.com/ctycode\"><img class=\"avatar\" src=\"https://avatars3.githubusercontent.com/u/56985178?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@ctycode\"></a> |<a href=\"https://github.com/sparkyuyuanyuan\"><img class=\"avatar\" src=\"https://avatars3.githubusercontent.com/u/50583631?s=96&amp;v=4\" width=\"48\" height=\"48\" alt=\"@sparkyuyuanyuan\"></a> |\n| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------: |:------------------------------:|\n|    [joseph31](https://gitee.com/joseph31)                                                                  |        [Joynice](https://github.com/Joynice)  |    [liangweiyang](https://github.com/liangweiyang)    |         [Hatcat123](https://github.com/Hatcat123)                                                                   |                                                                  [jihu9](https://github.com/jihu9)                                                                   |                                                                  [ctycode](https://github.com/ctycode)                                                                   |                                                                  [sparkyuyuanyuan](https://github.com/sparkyuyuanyuan)                                                                   |\n\n\n> wait for you\n\n## What You Learn ?\n\n本项目使用了哪些有用的技术\n\n- 数据分析\n  - [x] chrome Devtools\n  - [x] Fiddler\n  - [x] Firefox\n  - [ ] appnium\n  - [x] anyproxy\n  - [x] mitmproxy\n- 数据采集\n  - [x] [urllib]()\n  - [x] [requests](https://2.python-requests.org//zh_CN/latest/user/quickstart.html)\n  - [x] scrapy\n  - [x] selenium\n  - [ ] pypputeer\n- 数据解析\n  - [x] re\n  - [x] beautifulsoup\n  - [x] xpath\n  - [x] pyquery\n  - [x] css\n- 数据保存\n  - [x] txt 文本\n  - [x] csv\n  - [x] excel\n  - [x] mysql\n  - [x] redis\n  - [x] mongodb\n- 反爬验证\n  - [x] mitmproxy 绕过淘宝检测\n  - [x] js 数据解密\n  - [x] js 数据生成对应指纹库\n  - [x] 文字混淆\n  - [ ] 穿插脏数据\n- 效率爬虫\n  - [x] 单线程\n  - [x] 多线程\n  - [x] 多进程\n  - [x] 异步协成\n  - [x] 生产者消费者多线程\n  - [x] 分布式爬虫系统\n\n> _链接标识官方文档或推荐例子_\n\n## What`s Spider 🕷？\n\n**[ECommerceCrawlerswiki](https://github.com/DropsDevopsOrg/ECommerceCrawlers/wiki)**\n\n### 🙋0x01 爬虫简介\n\n**爬虫**\n\n爬虫是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。\n\n**[爬虫到底违法吗？](https://github.com/DropsDevopsOrg/ECommerceCrawlers/wiki/%E7%88%AC%E8%99%AB%E5%88%B0%E5%BA%95%E8%BF%9D%E6%B3%95%E5%90%97%3F)**\n\n**爬虫作用**\n\n- 市场分析：电商分析、商圈分析、一二级市场分析等\n- 市场监控：电商、新闻、房源监控等\n- 商机发现：招投标情报发现、客户资料发掘、企业客户发现等\n\n**网页介绍**\n\n- url\n- html\n- css\n- js\n\n**Roobots 协议**\n\n无规矩不成方圆，Robots 协议就是爬虫中的规矩，它告诉爬虫和搜索引擎哪些页面可以抓取，哪些不可以抓取。\n通常是一个叫作 robots.txt 的文本文件，放在网站的根目录下。\n\n### 🙋0x02 爬取过程\n\n**获取数据**\n\n**模拟获取数据**\n\n### 🙋0x03 解析数据\n\n**re**\n\n**beautifulsoup**\n\n**xpath**\n\n**pyquery**\n\n**css**\n\n### 🙋0x04 存储数据\n\n小规模数据存储（文本）\n\n- txt 文本\n- csv\n- excel\n\n大规模数据存储（数据库）\n\n- mysql\n- redis\n- mongodb\n\n### 🙋0x05 反爬措施\n\n反爬\n\n反反爬\n\n### 🙋0x06 效率爬虫\n\n多线程\n\n多进程\n\n异步协程\n\nscrapy 框架\n\n### 🙋0x07 可视化处理\n\nflask Web\n\ndjango Web\n\ntkinter\n\necharts\n\nelectron\n\n## Padding\n\n…………\n\n## Awesome-Example😍:\n\n- [CriseLYJ/awesome-python-login-model](https://github.com/CriseLYJ/awesome-python-login-model)\n\n- [lb2281075105/Python-Spider](https://github.com/lb2281075105/Python-Spider)\n\n- [SpiderCrackDemo](https://github.com/wkunzhi/SpiderCrackDemo)\n\n\n"
        },
        {
          "name": "SIPO专利审查",
          "type": "tree",
          "content": null
        },
        {
          "name": "ShicimingjuCrawleAndDisplay",
          "type": "tree",
          "content": null
        },
        {
          "name": "SohuNewCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "TaobaoCrawler(new)",
          "type": "tree",
          "content": null
        },
        {
          "name": "TaobaoCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "TouTiao",
          "type": "tree",
          "content": null
        },
        {
          "name": "WechatCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "WeiboCookieAutoGet",
          "type": "tree",
          "content": null
        },
        {
          "name": "WeiboCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "XianyuCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "ZhaopinCrawler",
          "type": "tree",
          "content": null
        },
        {
          "name": "cnblog",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}