{
  "metadata": {
    "timestamp": 1736559469775,
    "page": 32,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "OpenBMB/ToolBench",
      "stars": 4925,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0673828125,
          "content": "data/\ndata.zip\n*.DS_store\n\n__MACOSX/\n\nrun.bash\n\n*.pyc\n**/__pycache__\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 32.1025390625,
          "content": "<div align= \"center\">\n    <h1> ğŸ› ï¸ToolBenchğŸ¤–</h1>\n</div>\n\n<div align=\"center\">\n\n![Dialogues](https://img.shields.io/badge/Tool\\_Num-3451-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/API\\_Num-16464-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Current\\_Dataset\\_Size-126K-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Total\\_API\\_Call-469K-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Average\\_Reasoning\\_Traces-4.0-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Tool\\_LLaMA-Released-green?style=flat-square)\n\n</div>\n\n<p align=\"center\">\n  <a href=\"#model\">Model</a> â€¢\n  <a href=\"#data\">Data Release</a> â€¢\n  <a href=\"#web-ui\">Web Demo</a> â€¢\n  <a href=\"#tooleval\">Tool Eval</a> â€¢\n  <a href=\"https://arxiv.org/pdf/2307.16789.pdf\">Paper</a> â€¢\n  <a href=\"#citation\">Citation</a>\n\n</p>\n\n</div>\n\n<div align=\"center\">\n<img src=\"assets/ToolLLaMA-logo.png\" width=\"350px\">\n</div>\n\nğŸ”¨This project (ToolLLM) aims to construct **open-source, large-scale, high-quality** instruction tuning SFT data to facilitate the construction of powerful LLMs with general **tool-use** capability. We aim to empower open-source LLMs to master thousands of diverse real-world APIs. We achieve this by collecting a high-quality instruction-tuning dataset. It is constructed automatically using the latest ChatGPT (gpt-3.5-turbo-16k), which is upgraded with enhanced [function call](https://openai.com/blog/function-calling-and-other-api-updates) capabilities. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.\n\n**2024.8 Update** We have updated the RapidAPI server with a new IP, please make sure you get the latest code. You can also build it locally using codes [here](https://drive.google.com/file/d/1JdbHkL2D8as1docfHyfLWhrhlSP9rZhf/view?usp=sharing).\n\n**ğŸ’â€â™‚ï¸ğŸ’ğŸ’â€â™€ï¸ Join Us on [Discord](https://discord.gg/NScFnpMuRQ)!**\n\n*Read this in [ä¸­æ–‡](README_ZH.md).*\n\n## What's New\n- **[2024/3/17]** Welcome to **[StableToolBench](https://github.com/zhichengg/StableToolBench)**:\nA **stable and reliable** local toolbench server based on API response simulation. Dive deeper into the tech behind StableToolBench with [paper here](https://arxiv.org/pdf/2403.07714.pdf) and explore more on the [project homepage](https://zhichengg.github.io/stb.github.io/). Codes are available [here](https://github.com/zhichengg/StableToolBench).\n\n- **[2023/9/29]** A new version ToolEval which is more stable and covers more models including GPT4! Please refer to [**ToolEval**](https://github.com/OpenBMB/ToolBench/tree/master/toolbench/tooleval) for more details. Besides, [**ToolLLaMA-2-7b-v2**](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v2) is released with stronger tool-use capabilities. Please use the ToolLLaMA-2-7b-v2 model to reproduce our latest experimental results with the new version ToolEval.\n\n- **[2023/8/30]** Data updation, with more than **120,000** solution path annotations and **intact reasoning thoughts**! Please find `data.zip` on [Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J).\n\n- **[2023/8/8]** No more hallucination! [**ToolLLaMA-2-7b-v1**](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v1) (fine-tuned from LLaMA-2-7b) is released with lower API hallucination than ChatGPT.\n\n- **[2023/8/4]** We provide **RapidAPI backend service** to free you from using your own RapidAPI key and subscribing the APIs. Please fill out our [form](https://forms.gle/S4hqVLtnqeXcNTCJA). We will review it as soon as possible and send you the ToolBench key to get start on it! \n\n- **[2023/8/1]** Our [**paper**](https://arxiv.org/abs/2307.16789) is released.\n\n- **[2023/7/27]** **New version** ToolBench is released.\n\nâœ¨Here is an overview of the dataset construction, training, and evaluation.\n\n<br>\n<div align=\"center\">\n<img src=\"assets/overview.png\" width=\"800px\">\n</div>\n<br>\n\nâœ¨âœ¨Features:\n - **API Collection**: we gather **16464** representational state transfer (REST) APIs from [RapidAPI](https://rapidapi.com/hub), a platform that hosts massive real-world APIs provided by developers.\n - **Instruction Generation**: we curate instructions that involve both **single-tool** and **multi-tool** scenarios.\n - **Answer Annotation**: we develop a novel **depth-first search based decision tree** (DFSDT) to bolster the planning and reasoning ability of LLMs, which significantly improves the annotation efficiency and successfully annotates those complex instructions that cannot be answered with CoT or ReACT. We provide responses that not only include the final answer but also incorporate the model's **reasoning process, tool execution, and tool execution results**. \n - **API Retriver**: we incorporate API retrieval to equip ToolLLaMA with open-domain tool-using abilities.\n - All the data is automatically generated by OpenAI API and filtered by us, the whole data creation process is easy to scale up.\n\n<br>\n<div align=\"center\">\n<img src=\"assets/comparison.png\" width=\"800px\">\n</div>\n<br>\n\nWe also provide **A demo of using ToolLLaMA**\n\n<div align=\"center\">\n\nhttps://github.com/OpenBMB/ToolBench/assets/25274507/f1151d85-747b-4fac-92ff-6c790d8d9a31\n\n</div>\n\nCurrently, our ToolLLaMA has reached the performance of ChatGPT (turbo-16k) in tool use, in the future, *we will continually improve the data quality and increase the coverage of real-world tools.*\n\n<div align=\"center\">\n<img src=\"assets/performance.png\" width=\"300px\">\n</div>\n\nHere is the *[Old version](https://github.com/OpenBMB/ToolBench/tree/legacy)* of ToolBench.\n\n## Data\n\nğŸ‘ToolBench is intended solely for research and educational purposes and should not be construed as reflecting the opinions or views of the creators, owners, or contributors of this dataset. It is distributed under Apache License 2.0. Below is the statistics of the data :\n\n| Tool Nums | API Nums | Instance Nums | Real API Call | Reasoning Traces |\n|-----------|----------|---------------|---------------|------------------|\n| 3451      | 16464    | 126486         | 469585         | 4.0              |\n\nWe crawl 16000+ real-world APIs from [RapidAPI](https://rapidapi.com/hub), and curate realistic human instructions that involve them. Below we present a hierarchy of RapidAPI and our instruction generation process.\n\n<br>\n<div align=\"center\">\n<img src=\"assets/instructiongeneration.png\" width=\"800px\">\n</div>\n<br>\n\nToolBench contains both single-tool and multi-tool scenarios. The multi-tool scenarios can be further categorized into intra-category multi-tool and intra-collection multi-tool. We utilize DFSDT method for all scenarios to our data creation. Here is an illustration for the data creation process using DFSDT method:\n\n<div align=\"center\">\n\n<img src=\"assets/answer_anno.png\" width=\"800px\">\n\n</div>\n\n### Data Release\n\n Please download our dataset using the following link: [Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J) or [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/c9e50625743b40bfbe10/). *Notice that `data_0801` is the old version data.*\nThe file structure is as follows:\n```\nâ”œâ”€â”€ /data/\nâ”‚  â”œâ”€â”€ /instruction/\nâ”‚  â”œâ”€â”€ /answer/\nâ”‚  â”œâ”€â”€ /toolenv/\nâ”‚  â”œâ”€â”€ /retrieval/\nâ”‚  â”œâ”€â”€ /test_instruction/\nâ”‚  â”œâ”€â”€ /test_query_ids/\nâ”‚  â”œâ”€â”€ /retrieval_test_query_ids/\nâ”‚  â”œâ”€â”€ toolllama_G123_dfs_train.json\nâ”‚  â””â”€â”€ toolllama_G123_dfs_eval.json\nâ”œâ”€â”€ /reproduction_data/\nâ”‚  â”œâ”€â”€ /chatgpt_cot/\nâ”‚  â”œâ”€â”€ /chatgpt_dfs/\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â””â”€â”€ /toolllama_dfs/\n```\nHere are some descriptions for the `data` directory:\n- `instruction` and `answer`: The instruction data and solution path annotation data. `G1`,`G2`, `G3` refers to single-tool, intra-category multi-tool and intra-collection multi-tool data respectively. We also have an [Atlas Explorer](https://atlas.nomic.ai/map/58aca169-c29a-447a-8f01-0d418fc4d341/030ddad7-5305-461c-ba86-27e1ca79d899) for visualization.\n- `toolenv`: The tool environment related data, containing API jsons, API codes and API example responses.\n- `retrieval`: The data used for tool retrieval is included in this directory.\n- `test_instruction` and `test_query_ids`: We sample 200 instances from every test set. The `test_instruction` directory contains test queries for each test set, and the `test_query_ids` contains query ids of the test instances in each test set.\n- `retrieval_test_query_ids`: This directory contains query ids of the test instances for retriever.\n- `toolllama_G123_dfs_train.json` and `toolllama_G123_dfs_eval.json`: Preprocessed data that can be used to train toolllama directly and reproduce our results. For preprocessing details, we split the G1, G2 and G3 data into train, eval and test parts respectively and combine the train data for training in our main experiments.\n\n*Please make sure you have downloaded the necessary data and put the directory (e.g. `data/`) under `ToolBench/`, so that the following bash scripts can navigate to the related data.*\n\n## ğŸ¤–Model\n\nWe release the [ToolLLaMA-2-7b-v2](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v2) which is trained on the latest version data, and [ToolLLaMA-7b-v1](https://huggingface.co/ToolBench/ToolLLaMA-7b-v1), [ToolLLaMA-7b-LoRA-v1](https://huggingface.co/ToolBench/ToolLLaMA-7b-LoRA-v1) which are trained on the 0801 version data. All models are trained on the released dataset in a multi-task fashion. We also release the [tool retriever](https://huggingface.co/ToolBench/ToolBench_IR_bert_based_uncased) trained under our experimental setting.\n\n## ğŸš€Fine-tuning\n### Install\nClone this repository and navigate to the ToolBench folder.\n```bash\ngit clone git@github.com:OpenBMB/ToolBench.git\ncd ToolBench\n```\nInstall Package (python>=3.9)\n```bash\npip install -r requirements.txt\n```\nor for ToolEval only\n```bash\npip install -r toolbench/tooleval/requirements.txt\n```\n\nPrepare the data and tool environment:\n```bash\nwget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1XFjDxVZdUY7TXYF2yvzx3pJlS2fy78jk&confirm=yes' -O data.zip\nunzip data.zip\n```\nhttps://drive.google.com/file/d/1XFjDxVZdUY7TXYF2yvzx3pJlS2fy78jk/view?usp=drive_link\n\n### Training Retriever\n- Data preprocessing:\n```bash\nexport PYTHONPATH=./\npython preprocess/preprocess_retriever_data.py \\\n    --query_file data/instruction/G1_query.json \\\n    --index_file data/test_query_ids/G1_instruction_test_query_ids.json \\\n    --dataset_name G1 \\\n    --output_dir data/retrieval/G1\n```\n- Then run the following command to train the tool retriever:\n```bash\nexport PYTHONPATH=./\npython toolbench/retrieval/train.py \\\n    --data_path data/retrieval/G1/ \\\n    --model_name bert-base-uncased \\\n    --output_path retrieval_model \\\n    --num_epochs 5 \\\n    --train_batch_size 32 \\\n    --learning_rate 2e-5 \\\n    --warmup_steps 500 \\\n    --max_seq_length 256\n```\n\n### Training ToolLLaMA\n- Data preprocessing, for G1_answer as an example:\n```bash\nexport PYTHONPATH=./\npython preprocess/preprocess_toolllama_data.py \\\n    --tool_data_dir data/answer/G1_answer \\\n    --method DFS_woFilter_w2 \\\n    --output_file data/answer/toolllama_G1_dfs.json\n```\n- Our training code is based on [FastChat](https://github.com/lm-sys/FastChat). You can use the following command to train ToolLLaMA-7b with 2 x A100 (80GB), with our preprocessed data `data/toolllama_G123_dfs_train.json`. For preprocessing details, we split the G1, G2 and G3 data into train, eval and test parts respectively and combine the train data for training in our main experiments:\n```bash\nexport PYTHONPATH=./\ntorchrun --nproc_per_node=2 --master_port=20001 toolbench/train/train_mem.py \\\n    --model_name_or_path huggyllama/llama-7b  \\\n    --data_path  data/toolllama_G123_dfs_train.json \\\n    --eval_data_path  data/toolllama_G123_dfs_eval.json \\\n    --conv_template tool-llama-single-round \\\n    --bf16 True \\\n    --output_dir toolllama \\\n    --num_train_epochs 2 \\\n    --per_device_train_batch_size 2 \\\n    --per_device_eval_batch_size 2 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"epoch\" \\\n    --prediction_loss_only \\\n    --save_strategy \"epoch\" \\\n    --save_total_limit 8 \\\n    --learning_rate 5e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.04 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\" \\\n    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n    --tf32 True \\\n    --source_model_max_length 2048 \\\n    --model_max_length 8192 \\\n    --gradient_checkpointing True \\\n    --lazy_preprocess True \\\n    --report_to none\n```\n\nTo train lora version:\n```bash\nexport PYTHONPATH=./\ndeepspeed --master_port=20001 toolbench/train/train_lora.py \\\n    --model_name_or_path huggyllama/llama-7b  \\\n    --data_path  data/toolllama_G123_dfs_train.json \\\n    --eval_data_path  data/toolllama_G123_dfs_eval.json \\\n    --conv_template tool-llama-single-round \\\n    --bf16 True \\\n    --output_dir toolllama_lora \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 4 \\\n    --per_device_eval_batch_size 2 \\\n    --gradient_accumulation_steps 2 \\\n    --evaluation_strategy \"epoch\" \\\n    --prediction_loss_only \\\n    --save_strategy \"epoch\" \\\n    --save_total_limit 8 \\\n    --learning_rate 5e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.04 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --source_model_max_length 2048 \\\n    --model_max_length 8192 \\\n    --gradient_checkpointing True \\\n    --lazy_preprocess True \\\n    --deepspeed ds_configs/stage2.json \\\n    --report_to none\n```\n\n\n## Inference With Our RapidAPI Server\nPlease fill out the [form](https://forms.gle/S4hqVLtnqeXcNTCJA) first and after reviewing we will send you the toolbench key. Then prepare your toolbench key by:\n```bash\nexport TOOLBENCH_KEY=\"your_toolbench_key\"\n```\n\n### For ToolLLaMA\n\nTo inference with ToolLLaMA, run the following commands:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path ToolBench/ToolLLaMA-7b \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\nFor **ToolLLaMA-LoRA**:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/downloaded/ToolLLaMA-7b-LoRA \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_lora_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\nFor ToolLLaMA-LoRA under **open-domain** setting, run:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline_open_domain.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --corpus_tsv_path data/retrieval/G1/corpus.tsv \\\n    --retrieval_model_path /path/to/your/retrival_model \\\n    --retrieved_api_nums 5 \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/toolllama_lora \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_lora_dfs_open_domain_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\n### For OpenAI Models\nTo use ChatGPT, run:\n```bash\nexport TOOLBENCH_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model chatgpt_function \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file chatgpt_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\nTo use Text-Davinci-003, run:\n```bash\nexport TOOLBENCH_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model davinci \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file davinci_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\n## Inference With Your Own RapidAPI Account\nTo do inference with customized RapidAPI account, pass your **rapidapi key** through `rapidapi_key` and specify the `use_rapidapi_key` argument in the script:\n```bash\nexport RAPIDAPI_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model chatgpt_function \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file chatgpt_dfs_inference_result \\\n    --rapidapi_key $RAPIDAPI_KEY \\\n    --use_rapidapi_key\n```\n\n## API Customization\nTo do inference with customized API(s), you should prepare the API documentation and code, then modify your query. For example, to add an API **hello_world** which returns a \"hello world\" string:\n- API documentation: First generate the API documentation `hello_world.json`, which should follow this format:\n```\n{\n    \"tool_description\": \"Return hello world.\",\n    \"tool_name\": \"hello world\",\n    \"title\": \"hello world\",\n    \"api_list\": [\n        {\n            \"name\": \"get_hello_world\",\n            \"url\": \"\",\n            \"description\": \"To get 'hello world'.\",\n            \"method\": \"GET\",\n            \"required_parameters\": [],\n            \"optional_parameters\": []\n        }\n    ],\n    \"standardized_name\": \"hello_world\"\n}\n```\nThen put it under a specific category in `data/toolenv/tools/`, either one of the 49 existing categories or a new category, e.g. `Customized`. \n- API code: Create a directory naming the `hello_world` under `Customized` directory. Then write a code `api.py` to realize the function of the API and put it under `Customized/hello_world/`. The API code can be written in this format:\n```python\ndef get_hello_world():\n    \"\"\"\n    To get hello world \n    \"\"\"\n    observation = \"hello world\"\n    return observation\n```\nNow the file structure under `data/toolenv/` should be:\n```\nâ”œâ”€â”€ /tools/\nâ”‚  â”œâ”€â”€ /Sports/\nâ”‚  â”‚  â”œâ”€â”€ basketball.json\nâ”‚  â”‚  â”œâ”€â”€ /basketball/\nâ”‚  â”‚  â”‚  â””â”€â”€ api.py\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â”œâ”€â”€ /Customized/\nâ”‚  â”‚  â”œâ”€â”€ hello_world.json\nâ”‚  â”‚  â”œâ”€â”€ /hello_world/\nâ”‚  â”‚  â”‚  â””â”€â”€ api.py\nâ””â”€â”€ response_examples\n```\n- Modify your query file, and the query file should follow the following format:\n```\n[\n    {\n        \"query\": \"I want to get a 'hello world' string.\",\n        \"query_id\": 200001,\n        \"api_list\": [\n            {\n                \"category_name\": \"Customized\",\n                \"tool_name\": \"hello world\",\n                \"api_name\": \"get_hello_world\"\n            }\n        ]\n    }\n]\n```\n- Finally we are free to inference with the **hello_world** API by running the following commands:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path ToolBench/ToolLLaMA-7b \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file /path/to/your/query/file \\\n    --output_answer_file /path/to/your/output/file \\\n    --api_customization\n```\n*Currently we only support customized API usage under close-domain setting. We plan to support open-domain soon.*\n\n\n## Setting up and running the interface\nToolBench contains a Web UI based on [Chatbot UI](https://github.com/mckaywrigley/chatbot-ui), forked to include the use of tools in the interface. It comes in two parts: the backend server, and [chatbot-ui-toolllama](https://github.com/lilbillybiscuit/chatbot-ui-toolllama). Here is a [video demo](assets/toolbench-demo.mp4).\n\n\n### Web UI\n```bash\ngit clone https://github.com/lilbillybiscuit/chatbot-ui-toolllama\ncd chatbot-ui-toolllama\nnpm install\nnpm run dev\n```\n\nThe app will be available on `http://localhost:3000/`\n\n### Backend server\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/toolbench_server.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --corpus_tsv_path data/retrieval/G1/corpus.tsv \\\n    --retrieval_model_path /path/to/your/retrival_model \\\n    --retrieved_api_nums 5 \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/toolllama_lora \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_lora_dfs_open_domain_result \\\n    --rapidapi_key $RAPIDAPIKEY\n```\n\nThis server will be available on `http://localhost:5000/`. To start a request, call `http://localhost:5000/stream` with a GET or POST request containing a JSON object with the following fields:\n```json\n{\n    \"text\": \"What is the weather in New York today?\",\n    \"top_k\": 5,\n    \"method\": \"DFS_woFilter_w2\"\n}\n```\n\n## ToolEval\n\nBy fine-tuning LLaMA on ToolBench, we obtain **ToolLLaMA**. Considering that human evaluation can be time-consuming, we follow [AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/) to develop an efficient machine evaluator **ToolEval**, which incorporates two evaluation metrics:\n - **Pass Rate**: Calculates the proportion of successfully completing an instruction within limited OpenAI API calls. \n - **Preference**: Measured by comparing two answers (action sequences) for a given instruction. We pre-define a set of criteria for a better answer, which are organized as prompts for ChatGPT. We provide the test instruction and two candidate answers to the evaluator and obtain its preference. We evaluate each answer pair multiple times to improve the reliability of our system. Then we calculate the **Win Rate** (percentage of being preferred by the evaluator). More details can be found in our paper.\n\nTo validate the reliability of ChatGPT evaluator in both pass rate and win rate, we sample among four different methods (ChatGPT+ReACT, ChatGPT+DFSDT, ToolLLaMA+DFSDT and GPT4+DFSDT) to obtain solution pairs for 300 test instructions for each method. Then we engage humans to annotate the pass rate for ChatGPT+DFSDT, ToolLLaMA+DFSDT and GPT4+DFSDT, and the win rate among ChatGPT+ReACT and ChatGPT+DFSDT.\nOur ChatGPT evaluator demonstrates a high agreement of **87.1%** in pass rate and **80.3%** in win rate with human annotators. This result shows that our evaluator generates highly similar evaluation results to humans and can be viewed as a credible evaluator who simulates human evaluation on pass rate and win rate.\n\nMore details about ToolEval can be found in our paper.\n\n### Evaluation with ToolEval\n#### Install\nInstall Package (python>=3.9)\n```bash\npip install -r requirements.txt\n```\n\n#### Evaluation\n*If you want to reproduce the official results, download the reproduction data `reproduction_data.zip` through [Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J), unzip it and put the `reproduction_data` under `ToolBench/data/`, and skip the data preparation process.*\n- Data preparation. To evaluate your own model and method using ToolEval, first you need to prepare all the model predictions for the six test subsets. Create a directory naming with your model and method, e.g. `chatgpt_cot` then put each test set's predictions under the directory. The file sturcture of the directory should be:\n```\nâ”œâ”€â”€ /chatgpt_cot/\nâ”‚  â”œâ”€â”€ /G1_instruction/\nâ”‚  â”‚  â”œâ”€â”€ /10160_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ /G1_tool/\nâ”‚  â”‚  â”œâ”€â”€ /10221_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â”œâ”€â”€ /G3_instruction/\nâ”‚  â”‚  â”œâ”€â”€ /10221_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\n```\n\nThen preprocess the predictions by running the following commands:\n```bash\nexport RAW_ANSWER_PATH=../../data/reproduction_data/model_predictions/\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport MODEL_NAME=chatgpt_cot\nexport METHOD=CoT\nmkdir ${CONVERTED_ANSWER_PATH}/${MODEL_NAME}\nfor test_set in G1_instruction G1_category G1_tool G2_category G2_instruction G3_instruction\ndo\n    answer_dir=${RAW_ANSWER_PATH}/${MODEL_NAME}/${test_set}\n    output_file=${CONVERTED_ANSWER_PATH}/${MODEL_NAME}/${test_set}.json\n    python convert_to_answer_format.py\\\n        --answer_dir ${answer_dir} \\\n        --method ${METHOD} \\\n        --output ${output_file}\ndone\n```\nAfter that, check if there are preprocessed json files for the test sets under `${CONVERTED_ANSWER_PATH}/${MODEL_NAME}`. If so, you're ready to run the following evaluate process. If not, check if there is anything wrong with the model's predictions.\n\n- OpenAI Key. Prepare your openai key to use our evaluator. The key(s) should be stored in a json file, e.g. `path/to/your/openai_key_json_file.json`:\n```bash\n[\n    {\n        \"username\": \"your_user_name\",\n        \"passwd\": \"your_password\",\n        \"api_key\": \"your_openai_key\",\n        \"organization\": \"your_organization\"\n    },\n    ...\n]\n```\n\n- Pass rate:\n```bash\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport SAVE_PATH=pass_rate_results\nexport CANDIDATE_MODEL=chatgpt_cot\nexport API_POOL_FILE=path/to/your/openai_key_json_file.json\n\npython eval_pass_rate.py \\\n    --converted_answer_path ${CONVERTED_ANSWER_PATH} \\\n    --save_path ${SAVE_PATH} \\\n    --reference_model ${CANDIDATE_MODEL} \\\n    --test_ids ../../data/test_ids/ \\\n    --max_eval_threads 20 \\\n    --evaluate_times 7\n\n```\nThe result files will be stored under the ${SAVE_PATH}.\n\n- Win rate. The below example take ChatGPT-ReACT as reference model and GPT4-ReACT as candidate model. Notice that you need to get both model's pass rate results first, then run the following commands to evaluate the preference result of GPT4-ReACT:\n```bash\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport SAVE_PATH=preference_results\nexport PASS_TARE_PATH=pass_rate_results\nexport REFERENCE_MODEL=chatgpt_cot\nexport CANDIDATE_MODEL=gpt-4-0613_cot\nexport API_POOL_FILE=path/to/your/openai_key_json_file.json\n\npython eval_preference.py \\\n    --converted_answer_path ${CONVERTED_ANSWER_PATH} \\\n    --reference_model ${REFERENCE_MODEL} \\\n    --output_model ${CANDIDATE_MODEL} \\\n    --test_ids ../../data/test_ids/ \\\n    --save_path ${SAVE_PATH} \\\n    --pass_rate_result_path ${PASS_TARE_PATH} \\\n    --max_eval_threads 20 \\\n    --use_pass_rate true \\\n    --evaluate_times 7\n```\nThe result files will be stored under the ${SAVE_PATH}.\n\nPlease refer to [ToolEval](https://github.com/OpenBMB/ToolBench/tree/master/toolbench/tooleval) for more details.\n\n### ğŸ“Š Model Experiments Results\n\n\nIn our main experiments, ToolLLaMA(v2) demonstrates a compelling capability to handle both single-tool and complex multi-tool instructions, which on a par with ChatGPT.\nBelow are the main results. Win rate for each model is compared with ChatGPT-ReACT.\n\n\n**Pass Rate:**\n| Method | Model               | I1-Inst. | I1-Tool | I1-Cate. | I2-Inst. | I2-Cate. | I3-Inst. | Average |\n|--------|---------------------|----------|---------|----------|----------|----------|----------|---------|\n| ReACT  | Claude-2            | 5.5      | 3.5     | 5.5      | 6        | 6        | 14       | 6.8     |\n|        | Text-Davinci-003    | 12       | 20      | 20       | 8.5      | 14.5     | 24       | 16.5    |\n|        | ChatGPT             | 41.5     | 44      | 44.5     | 42.5     | 46.5     | 22       | 40.2    |\n|        | ToolLLaMA           | 25       | 29      | 33       | 30.5     | 31.5     | 25       | 29      |\n|        | GPT4                | 53.5       | 50.0    | 53.5       | 67.0     | 72.0     | 47.0       | 57.2    |\n| DFSDT  | Claude-2            | 20.5     | 31      | 18.5     | 17       | 20.5     | 28       | 22.6    |\n|        | Text-Davinci-003    | 43.5     | 44      | 46       | 37       | 42       | 46       | 43.1    |\n|        | ChatGPT             | 54.5     | 65      | 60.5     | 75       | 71.5     | 62       | 64.8    |\n|        | ToolLLaMA           | 57       | 61      | 62       | 77       | 77       | 66       | 66.7    |\n|        | ToolLLaMA-Retreiver | **64**       | 64      | 60.5     | **81.5**     | 68.5     | 65       | 67.3    |\n|        | GPT4                | 60       | **71.5**    | **67**       | 79.5     | **77.5**     | **71**       | **71.1**    |\n\n\n**Win Rate:** (Reference model: ChatGPT-ReACT)\n| Method | Model               | I1-Inst. | I1-Tool | I1-Cate. | I2-Inst. | I2-Cate. | I3-Inst. | Average |\n|--------|---------------------|----------|---------|----------|----------|----------|----------|---------|\n| ReACT  | Claude-2            | 31       | 27.8    | 33.8     | 35       | 31.5     | 47.5     | 34.4    |\n|        | Text-Davinci-003    | 28.5     | 35.3    | 31       | 29.8     | 29.8     | 45       | 33.2    |\n|        | ToolLLaMA           | 45       | 42      | 47.5     | 50.8     | 41.8     | 55       | 47      |\n|        | GPT4                | 60       | 58.8    | 63.5     | 65.8     | 60.3     | 78       | 64.4    |\n| DFSDT  | Claude-2            | 38       | 44.3    | 43.3     | 36.8     | 33.5     | 65       | 43.5    |\n|        | Text-Davinci-003    | 40.3     | 43.8    | 46.8     | 40.5     | 43.3     | 63       | 46.3    |\n|        | ChatGPT             | 60.5     | 62      | 57.3     | 72       | **64.8**     | 69       | 64.3    |\n|        | ToolLLaMA           | 55       | 55.3    | 54.5     | 68.5     | 58       | 69       | 60      |\n|        | ToolLLaMA-Retreiver | 62.3     | 59      | 55       | 68.5     | 60.8     | 73       | 63.1    |\n|        | GPT4                | **67.5**     | **67.8**    | **66.5**     | **73.3**     | 63.3     | **84**       | **70.4**    |\n\n\n## TODO\n- [ ] ToolLLaMA will reach GPT-4's tool-use capability.\n\n## Resources of Tool Learning\n\nWith the powerful capabilities of foundation models, we are eager to see their applications in manipulating various tools. For more resources, please refer to the following:\n\n- **BMTools**. [[Project](https://github.com/OpenBMB/BMTools)]\n\n- **Tool Learning Survey**. [[Paper](https://arxiv.org/abs/2304.08354)]\n  \n- **Tool Learning Paper List**. [[Project](https://github.com/thunlp/ToolLearningPapers)]\n\n- **WebCPM**. [[Paper](https://github.com/thunlp/WebCPM)]\n\n\n## Citation\nFeel free to cite us if you like ToolBench.\n```bibtex\n@misc{qin2023toolllm,\n      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, \n      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},\n      year={2023},\n      eprint={2307.16789},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}\n```\n\n```bibtex\n@misc{qin2023tool,\n      title={Tool Learning with Foundation Models}, \n      author={Yujia Qin and Shengding Hu and Yankai Lin and Weize Chen and Ning Ding and Ganqu Cui and Zheni Zeng and Yufei Huang and Chaojun Xiao and Chi Han and Yi Ren Fung and Yusheng Su and Huadong Wang and Cheng Qian and Runchu Tian and Kunlun Zhu and Shihao Liang and Xingyu Shen and Bokai Xu and Zhen Zhang and Yining Ye and Bowen Li and Ziwei Tang and Jing Yi and Yuzhang Zhu and Zhenning Dai and Lan Yan and Xin Cong and Yaxi Lu and Weilin Zhao and Yuxiang Huang and Junxi Yan and Xu Han and Xian Sun and Dahai Li and Jason Phang and Cheng Yang and Tongshuang Wu and Heng Ji and Zhiyuan Liu and Maosong Sun},\n      year={2023},\n      eprint={2304.08354},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n\n```bibtex\n@misc{guo2024stabletoolbench,\n      title={StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models},\n      author={Guo, Zhicheng and Cheng, Sijie and Wang, Hao and Liang, Shihao and Qin, Yujia and Li, Peng and Liu, Zhiyuan and Sun, Maosong and Liu, Yang},\n      year={2024},\n      eprint={2403.07714},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n"
        },
        {
          "name": "README_ZH.md",
          "type": "blob",
          "size": 30.0947265625,
          "content": "<div align= \"center\">\n    <h1> ğŸ› ï¸ToolBenchğŸ¤–</h1>\n</div>\n\n<div align=\"center\">\n\n![Dialogues](https://img.shields.io/badge/Tool\\_Num-3451-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/API\\_Num-16464-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Current\\_Dataset\\_Size-126K-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Total\\_API\\_Call-469K-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Average\\_Reasoning\\_Traces-4.0-red?style=flat-square)\n![Dialogues](https://img.shields.io/badge/Tool\\_LLaMA-Released-green?style=flat-square)\n\n</div>\n\n<p align=\"center\">\n  <a href=\"#model\">Model</a> â€¢\n  <a href=\"#data\">Data Release</a> â€¢\n  <a href=\"#web-ui\">Web Demo</a> â€¢\n  <a href=\"#tool-eval\">Tool Eval</a> â€¢\n  <a href=\"assets/paper.pdf\">Paper</a> â€¢\n  <a href=\"#citation\">Citation</a>\n\n</p>\n\n</div>\n\n<div align=\"center\">\n<img src=\"https://cdn.discordapp.com/attachments/941582479117127680/1111543600879259749/20230526075532.png\" width=\"350px\">\n</div>\n\nğŸ”¨è¿™ä¸ªé¡¹ç›®(ToolLLM)æ—¨åœ¨æ„å»º**å¼€æºã€å¤§è§„æ¨¡ã€é«˜è´¨é‡**çš„æŒ‡ä»¤è°ƒæ•´ SFT æ•°æ®ï¼Œä»¥ä¿ƒè¿›æ„å»ºå…·æœ‰é€šç”¨å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„å¼ºå¤§LLMsã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èµ‹äºˆå¼€æº LLMs æŒæ¡æˆåƒä¸Šä¸‡å¤šæ ·çš„çœŸå®ä¸–ç•ŒAPIèƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡æ”¶é›†é«˜è´¨é‡çš„æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚è¯¥æ•°æ®é›†ä½¿ç”¨æœ€æ–°çš„ChatGPTï¼ˆgpt-3.5-turbo-16kï¼‰è‡ªåŠ¨æ„å»ºï¼Œè¯¥ç‰ˆæœ¬å‡çº§äº†å¢å¼ºçš„å‡½æ•°è°ƒç”¨åŠŸèƒ½ã€‚æˆ‘ä»¬æä¾›æ•°æ®é›†ã€ç›¸åº”çš„è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬ï¼Œä»¥åŠåœ¨ToolBenchä¸Šç»è¿‡å¾®è°ƒçš„å¼ºå¤§æ¨¡å‹ToolLLaMAã€‚\n\n**ğŸ’â€â™‚ï¸ğŸ’ğŸ’â€â™€ï¸åœ¨ [Discord](https://discord.gg/NScFnpMuRQ) åŠ å…¥æˆ‘ä»¬!**\n\n*è‹±æ–‡[README](README.md)é“¾æ¥.*\n\n## æœ€æ–°æ”¯æŒ\n- **[2023/9/29]** æ›´ç¨³å®šçš„æ›´æ–°ç‰ˆæœ¬**ToolEval**ï¼Œ åŠ ä¸Šæ›´å¤šæ¨¡å‹æ¯”å¦‚GPT4çš„ç»“æœï¼æ›´å¤šç»†èŠ‚è¯·å‚è€ƒ[ToolEval](https://github.com/OpenBMB/ToolBench/tree/master/toolbench/tooleval). é™¤æ­¤ä¹‹å¤–ï¼Œå·¥å…·ä½¿ç”¨èƒ½åŠ›æ›´å¼ºçš„[**ToolLLaMA-2-7b-v2**](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v2)æ¨¡å‹å·²ç»å¼€æ”¾ï¼Œè¯·ä½¿ç”¨è¿™ç‰ˆæ¨¡å‹å’Œæ›´æ–°çš„toolevalæ¥å¤ç°æœ€æ–°çš„å®éªŒç»“æœã€‚\n\n- **[2023/8/30]** æ•°æ®æ›´æ–°ï¼Œæ‹¥æœ‰è¶…è¿‡**12ä¸‡**è§£è·¯å¾„æ ‡æ³¨å’Œ**å®Œæ•´çš„æ¨ç†thoughts**ï¼è¯·åœ¨ [Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J) ä¸Šæ‰¾åˆ°`data.zip`ã€‚\n\n- **[2023/8/8]** å‘Šåˆ«å¹»è§‰ï¼[**ToolLLaMA-2-7b-v1**](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v1) (ä»LLaMA-2-7bå¾®è°ƒè€Œæ¥)æ¨¡å‹å·²å‘å¸ƒï¼Œæ¯”ChatGPTæœ‰ç€æ›´å°‘çš„APIå¹»è§‰ç°è±¡.\n\n- **[2023/8/4]** æˆ‘ä»¬æä¾›RapidAPIåç«¯æœåŠ¡ï¼Œä»¥å…æ‚¨ä½¿ç”¨è‡ªå·±çš„RapidAPIç§é’¥å»è®¢é˜…APIã€‚å¡«å†™[è¡¨å•](https://forms.gle/S4hqVLtnqeXcNTCJA)åï¼Œæˆ‘ä»¬ä¼šå°½å¿«å®¡æ ¸å¹¶ç»™æ‚¨å‘é€ToolBench keyå»è¯·æ±‚è¯¥åç«¯æœåŠ¡! \n\n- **[2023/8/1]** æˆ‘ä»¬çš„[è®ºæ–‡](https://arxiv.org/abs/2307.16789)æ­£å¼å‘å¸ƒ.\n\n- **[2023/7/27]** æ–°ç‰ˆæœ¬ToolBenchæ›´æ–°.\n\nâœ¨ä»¥ä¸‹æ˜¯æ•°æ®é›†æ„å»ºæ–¹æ³•ã€æ¨¡å‹è®­ç»ƒã€è¯„æµ‹çš„æ•´ä½“æ¦‚è§ˆ\n\n<br>\n<div align=\"center\">\n<img src=\"assets/overview.png\" width=\"800px\">\n</div>\n<br>\n\nâœ¨âœ¨ç‰¹ç‚¹:\n - APIæ”¶é›†: æˆ‘ä»¬ä» RapidAPI æ”¶é›†äº† 16464 ä¸ªAPIã€‚RapidAPI æ˜¯ä¸€ä¸ªæ‰˜ç®¡å¼€å‘è€…æä¾›çš„å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒAPIçš„å¹³å°ã€‚\n\n - æŒ‡ä»¤ç”Ÿæˆ: æˆ‘ä»¬ç”Ÿæˆäº†æ¶‰åŠå•å·¥å…·å’Œå¤šå·¥å…·åœºæ™¯çš„æŒ‡ä»¤ã€‚\n\n - ç­”æ¡ˆæ ‡æ³¨: æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„æ·±åº¦ä¼˜å…ˆæœç´¢å†³ç­–æ ‘æ–¹æ³•ï¼ˆDFSDTï¼‰ï¼Œä»¥å¢å¼ºLLMsçš„è§„åˆ’å’Œæ¨ç†èƒ½åŠ›ã€‚è¿™æ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡ï¼Œå¹¶æˆåŠŸåœ°å¯¹é‚£äº›ä¸èƒ½ç”¨CoTæˆ–ReACTå›ç­”çš„å¤æ‚æŒ‡ä»¤è¿›è¡Œäº†æ ‡æ³¨ã€‚æˆ‘ä»¬æä¾›çš„å›ç­”ä¸ä»…åŒ…æ‹¬æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜åŒ…æ‹¬æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€å·¥å…·æ‰§è¡Œå’Œå·¥å…·æ‰§è¡Œç»“æœã€‚\n\n - API Retriever: æˆ‘ä»¬æ•´åˆäº†APIæ£€ç´¢æ¨¡å—ï¼Œä¸ºToolLLaMAæä¾›äº†å¼€æ”¾åŸŸçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚\n\n - æ‰€æœ‰æ•°æ®å‡ç”±OpenAI APIè‡ªåŠ¨ç”Ÿæˆå¹¶ç”±æˆ‘ä»¬ç­›é€‰ï¼Œæ•´ä¸ªæ•°æ®åˆ›å»ºè¿‡ç¨‹æ˜“äºæ‰©å±•ã€‚\n\n<br>\n<div align=\"center\">\n<img src=\"assets/comparison.png\" width=\"800px\">\n</div>\n<br>\n\nä»¥ä¸‹æ˜¯**ToolLLaMAçš„demoå±•ç¤º**\n\n<div align=\"center\">\n\nhttps://github.com/OpenBMB/ToolBench/assets/25274507/f1151d85-747b-4fac-92ff-6c790d8d9a31\n\n</div>\n\nç›®å‰ï¼Œæˆ‘ä»¬çš„ToolLLaMAå·²ç»è¾¾åˆ°äº†å’ŒChatGPTï¼ˆturbo-16kï¼‰æ¥è¿‘çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œæœªæ¥*æˆ‘ä»¬å°†ä¸æ–­è¿›è¡Œæ•°æ®çš„åå¤„ç†ä¸æ¸…æ´—ï¼Œä»¥æé«˜æ•°æ®è´¨é‡å¹¶å¢åŠ çœŸå®ä¸–ç•Œå·¥å…·çš„è¦†ç›–èŒƒå›´ã€‚*\n\n<div align=\"center\">\n<img src=\"assets/performance.png\" width=\"300px\">\n</div>\n\nè¿™æ˜¯*[è€ç‰ˆæœ¬](https://github.com/OpenBMB/ToolBench/tree/legacy)*çš„ToolBenchã€‚\n<!-- ğŸ’â€â™‚ï¸ğŸ’ğŸ’â€â™€ï¸**We need your help!** Curating large-scale real-world APIs and their corresponding tool-use SFT data is not easy, we sincerely invite you to join us in building and refining ToolBench. We will list all participants as co-authors in the final paper. Please contact and join [us](mailto:yujiaqin16@gmail.com) if you're interested. -->\n\n## ğŸ—’ï¸æ•°æ®\n\nğŸ‘ToolBenchä»…ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„ï¼Œä¸åº”è¢«è§†ä¸ºåæ˜ æ­¤æ•°æ®é›†çš„åˆ›ä½œè€…ã€æ‰€æœ‰è€…æˆ–è´¡çŒ®è€…çš„è§‚ç‚¹æˆ–æ„è§ã€‚è¯¥æ•°æ®é›†ä»¥ Apache License 2.0 è®¸å¯è¯ è¿›è¡Œåˆ†å‘ã€‚ä»¥ä¸‹æ˜¯æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯:\n\n| å·¥å…·æ•°é‡ | APIæ•°é‡ | å®ä¾‹æ•°é‡ | çœŸå®APIè°ƒç”¨æ•°é‡ | å¹³å‡Reasoningæ­¥æ•° |\n|-----------|----------|---------------|---------------|------------------|\n| 3451      | 16464    | 126486         | 469585         | 4.0              |\n\næˆ‘ä»¬ä»[RapidAPI](https://rapidapi.com/hub)çˆ¬å–äº†è¶…è¿‡16000ä¸ªAPIï¼Œå¹¶ä¸”ä¸ºä¹‹æ„é€ äº†çœŸå®çš„äººç±»æŒ‡ä»¤ã€‚ä»¥ä¸‹æ˜¯RapidAPIçš„æ¶æ„ä¿¡æ¯ä¸æŒ‡ä»¤æ„é€ çš„æ–¹å¼ã€‚\n\n<br>\n<div align=\"center\">\n<img src=\"assets/instructiongeneration.png\" width=\"800px\">\n</div>\n<br>\n\n\nToolBenchåŒ…å«å•å·¥å…·å’Œå¤šå·¥å…·åœºæ™¯ã€‚å¤šå·¥å…·åœºæ™¯å¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºç±»åˆ«å†…å¤šå·¥å…·å’Œé›†åˆå†…å¤šå·¥å…·ã€‚æˆ‘ä»¬åœ¨æ•°æ®åˆ›å»ºè¿‡ç¨‹ä¸­ä½¿ç”¨DFSDTæ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨DFSDTæ–¹æ³•è¿›è¡Œæ•°æ®åˆ›å»ºçš„è¯´æ˜ï¼š\n\n<div align=\"center\">\n\n<img src=\"assets/answer_anno.png\" width=\"800px\">\n\n</div>\n\n### æ•°æ®å‘å¸ƒ\n\n è¯·ä½¿ç”¨ä»¥ä¸‹é“¾æ¥ä¸‹è½½æˆ‘ä»¬çš„æ•°æ®é›†ï¼š[Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J)æˆ–è€…[æ¸…åäº‘ç›˜](https://cloud.tsinghua.edu.cn/f/c9e50625743b40bfbe10/).*è¯·æ³¨æ„ï¼š`data_0801.zip`æ˜¯è€ç‰ˆæœ¬æ•°æ®ã€‚*\næ–‡ä»¶ç»“æ„å¦‚ä¸‹:\n```\nâ”œâ”€â”€ /data/\nâ”‚  â”œâ”€â”€ /instruction/\nâ”‚  â”œâ”€â”€ /answer/\nâ”‚  â”œâ”€â”€ /toolenv/\nâ”‚  â”œâ”€â”€ /retrieval/\nâ”‚  â”œâ”€â”€ /test_instruction/\nâ”‚  â”œâ”€â”€ /test_query_ids/\nâ”‚  â”œâ”€â”€ /retrieval_test_query_ids/\nâ”‚  â”œâ”€â”€ toolllama_G123_dfs_train.json\nâ”‚  â””â”€â”€ toolllama_G123_dfs_eval.json\nâ”œâ”€â”€ /reproduction_data/\nâ”‚  â”œâ”€â”€ /chatgpt_cot/\nâ”‚  â”œâ”€â”€ /chatgpt_dfs/\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â””â”€â”€ /toolllama_dfs/\n```\nä»¥ä¸‹æ˜¯`data`ç›®å½•çš„ä¸€äº›æè¿°ï¼š\n- `instruction` å’Œ `answer`ï¼šæŒ‡ä»¤æ•°æ®å’Œè§£å†³æ–¹æ¡ˆè·¯å¾„æ ‡æ³¨æ•°æ®ã€‚ `G1`ã€`G2`ã€`G3`åˆ†åˆ«æŒ‡å•å·¥å…·ã€ç±»å†…å¤šå·¥å…·å’Œé›†åˆå†…å¤šå·¥å…·æ•°æ®ã€‚æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªç”¨äºå¯è§†åŒ–çš„ [Atlas Explorer](https://atlas.nomic.ai/map/58aca169-c29a-447a-8f01-0d418fc4d341/030ddad7-5305-461c-ba86-27e1ca79d899)ã€‚\n- `toolenv`ï¼šå·¥å…·ç¯å¢ƒç›¸å…³æ•°æ®ï¼ŒåŒ…å«API jsonã€APIä»£ç å’ŒAPIç¤ºä¾‹è¿”å›ã€‚\n- `retrieval`ï¼šç”¨äºå·¥å…·æ£€ç´¢çš„æ•°æ®åŒ…å«åœ¨æ­¤ç›®å½•ä¸­ã€‚\n- `test_instruction` and `test_query_ids`ï¼šæˆ‘ä»¬ä»æ¯ä¸ªæµ‹è¯•é›†ä¸­æŠ½å– 200 ä¸ªå®ä¾‹ã€‚è¯¥ç›®å½•åŒ…å«æ¯ä¸ªæµ‹è¯•é›†ä¸­æµ‹è¯•å®ä¾‹çš„querieså’Œquery idã€‚\n- `retrieval_test_query_ids`ï¼šè¯¥ç›®å½•åŒ…å«æ£€ç´¢å™¨æµ‹è¯•å®ä¾‹çš„query idã€‚\n- `toolllama_G123_dfs_train.json` å’Œ `toolllama_G123_dfs_eval.json`ï¼šé¢„å¤„ç†æ•°æ®ï¼Œå¯ç”¨äºç›´æ¥è®­ç»ƒ toolllama å¹¶å¤ç°æˆ‘ä»¬çš„ç»“æœã€‚å¯¹äºé¢„å¤„ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬å°† G1ã€G2 å’Œ G3 æ•°æ®åˆ†åˆ«åˆ†ä¸ºè®­ç»ƒã€è¯„ä¼°å’Œæµ‹è¯•éƒ¨åˆ†ï¼Œåˆå¹¶å„æ•°æ®é›†çš„è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒã€‚\n\n## ğŸ¤–æ¨¡å‹\næˆ‘ä»¬å‘å¸ƒäº†åœ¨æœ€æ–°æ•°æ®ä¸Šå…¨å‚æ•°å¾®è°ƒçš„[ToolLLaMA-2-7b-v2](https://huggingface.co/ToolBench/ToolLLaMA-2-7b-v2)ï¼Œè¿˜æœ‰åœ¨0801ç‰ˆæœ¬æ•°æ®ä¸Šå…¨å‚æ•°å¾®è°ƒçš„[ToolLLaMA-7b-v1](https://huggingface.co/ToolBench/ToolLLaMA-7b-v1)å’Œloraç‰ˆæœ¬[ToolLLaMA-7b-LoRA-v1](https://huggingface.co/ToolBench/ToolLLaMA-7b-LoRA-v1)ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ä»¥å¤šä»»åŠ¡æ–¹å¼è®­ç»ƒçš„ã€‚æˆ‘ä»¬ä¹Ÿå‘å¸ƒåœ¨å®éªŒè®¾ç½®ä¸‹è®­ç»ƒçš„[tool retriever](https://huggingface.co/ToolBench/ToolBench_IR_bert_based_uncased).\n## ğŸš€ç²¾è°ƒ\n### å®‰è£…\nå…‹éš†è¿™ä¸ªä»“åº“å¹¶è¿›å…¥ToolBenchæ–‡ä»¶å¤¹ã€‚\n```bash\ngit clone git@github.com:OpenBMB/ToolBench.git\ncd ToolBench\n```\nå®‰è£…åŒ… (python>=3.9)\n```bash\npip install -r requirements.txt\n```\næˆ–è€…ä»…å®‰è£…ToolEvaléœ€è¦çš„åŒ…\n```bash\npip install -r toolbench/tooleval/requirements.txt\n```\n\nå‡†å¤‡æ•°æ®å’Œå·¥å…·ç¯å¢ƒ:\n```bash\nwget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1XFjDxVZdUY7TXYF2yvzx3pJlS2fy78jk&confirm=yes' -O data.zip\nunzip data.zip\n```\n\n\n### è®­ç»ƒRetriever\n- æ•°æ®é¢„å¤„ç†:\n```bash\nexport PYTHONPATH=./\npython preprocess/preprocess_retriever_data.py \\\n    --query_file data/instruction/G1_query.json \\\n    --index_file data/test_query_ids/G1_instruction_test_query_ids.json \\\n    --dataset_name G1 \\\n    --output_dir data/retrieval/G1\n```\n- ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒRetriever:\n```bash\nexport PYTHONPATH=./\npython toolbench/retrieval/train.py \\\n    --data_path data/retrieval/G1/ \\\n    --model_name bert-base-uncased \\\n    --output_path retrieval_model \\\n    --num_epochs 5 \\\n    --train_batch_size 32 \\\n    --learning_rate 2e-5 \\\n    --warmup_steps 500 \\\n    --max_seq_length 256\n```\n\n### è®­ç»ƒToolLLaMA\n- æ•°æ®é¢„å¤„ç†ï¼ˆG1_answerä¸ºä¾‹å­ï¼‰:\n```bash\nexport PYTHONPATH=./\npython preprocess/preprocess_toolllama_data.py \\\n    --tool_data_dir data/answer/G1_answer \\\n    --method DFS_woFilter_w2 \\\n    --output_file data/answer/toolllama_G1_dfs.json\n```\n- æˆ‘ä»¬çš„è®­ç»ƒä»£ç åŸºäº[FastChat](https://github.com/lm-sys/FastChat)å¼€å‘.æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨ä¸¤å¼ A100ï¼ˆ80Gï¼‰ä»¥åŠæˆ‘ä»¬é¢„å¤„ç†å¥½çš„æ•°æ®`data/toolllama_G123_dfs_train.json`æˆ–data_0830ç‰ˆæœ¬`data_0830/toolllama_G123_dfs_train_0830.json`æ¥è®­ç»ƒ ToolLLaMA-7bã€‚å¯¹äºé¢„å¤„ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬å°† G1ã€G2 å’Œ G3 æ•°æ®åˆ†åˆ«åˆ†ä¸ºè®­ç»ƒã€è¯„ä¼°å’Œæµ‹è¯•éƒ¨åˆ†ï¼Œåˆå¹¶å„æ•°æ®é›†ä¸­çš„è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒ:\n```bash\nexport PYTHONPATH=./\ntorchrun --nproc_per_node=2 --master_port=20001 toolbench/train/train_mem.py \\\n    --model_name_or_path huggyllama/llama-7b  \\\n    --data_path  data/toolllama_G123_dfs_train.json \\\n    --eval_data_path  data/toolllama_G123_dfs_eval.json \\\n    --conv_template tool-llama-single-round \\\n    --bf16 True \\\n    --output_dir toolllama \\\n    --num_train_epochs 2 \\\n    --per_device_train_batch_size 2 \\\n    --per_device_eval_batch_size 2 \\\n    --gradient_accumulation_steps 8 \\\n    --evaluation_strategy \"epoch\" \\\n    --prediction_loss_only \\\n    --save_strategy \"epoch\" \\\n    --save_total_limit 8 \\\n    --learning_rate 5e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.04 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --fsdp \"full_shard auto_wrap\" \\\n    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \\\n    --tf32 True \\\n    --source_model_max_length 2048 \\\n    --model_max_length 8192 \\\n    --gradient_checkpointing True \\\n    --lazy_preprocess True \\\n    --report_to none\n```\n\næ‚¨ä¹Ÿå¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨æ‚¨è‡ªå·±çš„æ–¹å¼å»é¢„å¤„ç†å¹¶åˆ’åˆ†æ•°æ®:\n```bash\nexport PYTHONPATH=./\npython preprocess/preprocess_toolllama_data.py \\\n    --tool_data_dir data/answer/G1_answer \\\n    --method DFS_woFilter_w2 \\\n    --output_file data/answer/toolllama_G1_dfs.json\n```\n\n\nè®­ç»ƒloraç‰ˆæœ¬:\n```bash\nexport PYTHONPATH=./\ndeepspeed --master_port=20001 toolbench/train/train_lora.py \\\n    --model_name_or_path huggyllama/llama-7b  \\\n    --data_path  data/toolllama_G123_dfs_train.json \\\n    --eval_data_path  data/toolllama_G123_dfs_eval.json \\\n    --conv_template tool-llama-single-round \\\n    --bf16 True \\\n    --output_dir toolllama_lora \\\n    --num_train_epochs 5 \\\n    --per_device_train_batch_size 4 \\\n    --per_device_eval_batch_size 2 \\\n    --gradient_accumulation_steps 2 \\\n    --evaluation_strategy \"epoch\" \\\n    --prediction_loss_only \\\n    --save_strategy \"epoch\" \\\n    --save_total_limit 8 \\\n    --learning_rate 5e-5 \\\n    --weight_decay 0. \\\n    --warmup_ratio 0.04 \\\n    --lr_scheduler_type \"cosine\" \\\n    --logging_steps 1 \\\n    --source_model_max_length 2048 \\\n    --model_max_length 8192 \\\n    --gradient_checkpointing True \\\n    --lazy_preprocess True \\\n    --deepspeed ds_configs/stage2.json \\\n    --report_to none\n```\n\n\n## ç”¨æˆ‘ä»¬çš„RapidAPIæœåŠ¡è¿›è¡Œæ¨ç†\nè¯·å…ˆå¡«å†™[é—®å·](https://forms.gle/S4hqVLtnqeXcNTCJA)ï¼Œæˆ‘ä»¬ä¼šå°½å¿«å®¡æ ¸ç„¶åç»™æ‚¨å‘é€toolbench keyã€‚ç„¶ååˆå§‹åŒ–æ‚¨çš„toolbench key:\n```bash\nexport TOOLBENCH_KEY=\"your_toolbench_key\"\n```\n### ToolLLaMA\nç”¨ä»¥ä¸‹å‘½ä»¤ç”¨ToolLLaMAåšæ¨ç†:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path /path/to/your/toolllama \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\n**lora**ç‰ˆæœ¬çš„inference:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/toolllama_lora \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_lora_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\nloraç‰ˆæœ¬çš„**å¼€æ”¾åŸŸ**, ç”¨ä»¥ä¸‹å‘½ä»¤:\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline_open_domain.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --corpus_tsv_path data/retrieval/G1/corpus.tsv \\\n    --retrieval_model_path /path/to/your/retrival_model \\\n    --retrieved_api_nums 5 \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/toolllama_lora \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file toolllama_lora_dfs_open_domain_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n### OpenAIæ¨¡å‹\nç”¨ChatGPT:\n```bash\nexport TOOLBENCH_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model chatgpt_function \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file chatgpt_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\nç”¨Text-Davinci-003:\n```bash\nexport TOOLBENCH_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model davinci \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file davinci_dfs_inference_result \\\n    --toolbench_key $TOOLBENCH_KEY\n```\n\n## ç”¨æ‚¨è‡ªå·±çš„RapidAPIè´¦å·åšæ¨ç†\nè¦ç”¨å®šåˆ¶åŒ–çš„RapidAPIè´¦å·è¿›è¡Œæ¨ç†ï¼Œè¯·åœ¨è„šæœ¬ä¸­ä¼ å…¥æ‚¨çš„**rapidapi key**å¹¶æŒ‡å®š`use_rapidapi_key`å‚æ•°:\n```bash\nexport RAPIDAPI_KEY=\"\"\nexport OPENAI_KEY=\"\"\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model chatgpt_function \\\n    --openai_key $OPENAI_KEY \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file chatgpt_dfs_inference_result \\\n    --rapidapi_key $RAPIDAPI_KEY \\\n    --use_rapidapi_key\n```\n\n\n## è‡ªå®šä¹‰APIåšæ¨ç†\nè¦ä½¿ç”¨è‡ªå®šä¹‰APIè¿›è¡Œæ¨ç†ï¼Œæ‚¨éœ€è¦å‡†å¤‡APIæ–‡æ¡£å’Œä»£ç ï¼Œç„¶åä¿®æ”¹æ‚¨çš„queryæ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œè¦æ·»åŠ **hello_world** APIï¼Œè¯¥APIçš„åŠŸèƒ½ä¸ºè¿”å›â€œhello worldâ€å­—ç¬¦ä¸²ï¼š\n- APIæ–‡æ¡£ï¼šé¦–å…ˆç”ŸæˆAPIæ–‡æ¡£jsonæ–‡ä»¶ï¼ˆ`hello_world.json`ï¼‰ï¼Œè¯¥æ–‡ä»¶åº”éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š\n```\n{\n    \"tool_description\": \"Return hello world.\",\n    \"tool_name\": \"hello world\",\n    \"title\": \"hello world\",\n    \"api_list\": [\n        {\n            \"name\": \"get_hello_world\",\n            \"url\": \"\",\n            \"description\": \"To get 'hello world'.\",\n            \"method\": \"GET\",\n            \"required_parameters\": [],\n            \"optional_parameters\": []\n        }\n    ],\n    \"standardized_name\": \"hello_world\"\n}\n```\nç„¶åå°†å…¶æ”¾åœ¨â€œdata/toolenv/tools/â€ä¸­çš„æŸä¸ªcategoryä¸‹ï¼Œå¯ä»¥æ˜¯å·²æœ‰çš„49ä¸ªç°æœ‰ç±»åˆ«ä¹‹ä¸€ï¼Œä¹Ÿå¯ä»¥æ–°åˆ›å»ºä¸€ä¸ªç±»åˆ«ï¼Œä¾‹å¦‚`Customized`ã€‚\n- APIä»£ç ï¼šåœ¨`Customized`æ–‡ä»¶å¤¹ä¸‹åˆ›å»ºä¸€ä¸ªåä¸º`hello_world`çš„æ–‡ä»¶å¤¹ï¼Œç„¶åç¼–å†™å®ç°APIåŠŸèƒ½çš„ä»£ç `api.py`å¹¶å°†å…¶æ”¾åœ¨`Customized/hello_world/`ä¸‹ã€‚ APIä»£ç å¯ä»¥å†™æˆè¿™æ ·çš„æ ¼å¼ï¼š\n```python\ndef get_hello_world():\n    \"\"\"\n    To get hello world \n    \"\"\"\n    observation = \"hello world\"\n    return observation\n```\nç°åœ¨ `data/toolenv/` ä¸‹çš„æ–‡ä»¶ç»“æ„åº”è¯¥æ˜¯ï¼š\n```\nâ”œâ”€â”€ /tools/\nâ”‚  â”œâ”€â”€ /Sports/\nâ”‚  â”‚  â”œâ”€â”€ basketball.json\nâ”‚  â”‚  â”œâ”€â”€ /basketball/\nâ”‚  â”‚  â”‚  â””â”€â”€ api.py\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â”œâ”€â”€ /Customized/\nâ”‚  â”‚  â”œâ”€â”€ hello_world.json\nâ”‚  â”‚  â”œâ”€â”€ /hello_world/\nâ”‚  â”‚  â”‚  â””â”€â”€ api.py\nâ””â”€â”€ response_examples\n```\n- ä¿®æ”¹æ‚¨çš„queryæ–‡ä»¶ï¼ŒæŸ¥è¯¢æ–‡ä»¶åº”éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š\n```\n[\n    {\n        \"query\": \"I want to get a 'hello world' string.\",\n        \"query_id\": 200001,\n        \"api_list\": [\n            {\n                \"category_name\": \"Customized\",\n                \"tool_name\": \"hello world\",\n                \"api_name\": \"get_hello_world\"\n            }\n        ]\n    }\n]\n```\n- æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ä½¿ç”¨è‡ªå®šä¹‰çš„**hello_world**APIè¿›è¡Œæ¨ç†ï¼š\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/qa_pipeline.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --backbone_model toolllama \\\n    --model_path ToolBench/ToolLLaMA-7b \\\n    --max_observation_length 1024 \\\n    --observ_compress_method truncate \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file /path/to/your/query/file \\\n    --output_answer_file /path/to/your/output/file \\\n    --api_customization\n```\n*Currently we only support customized API usage under close-domain setting. We plan to support open-domain soon.*\n\n## Setting up and running the interface\n\nToolBenchåŒ…å«ä¸€ä¸ªåŸºäº[Chatbot UI](https://github.com/mckaywrigley/chatbot-ui)çš„Web UIï¼Œç»è¿‡ä¿®æ”¹ä»¥åŒ…å«åœ¨ç•Œé¢ä¸­ä½¿ç”¨å·¥å…·çš„åŠŸèƒ½ã€‚å®ƒåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šåç«¯æœåŠ¡å™¨å’Œ[chatbot-ui-toolllama](https://github.com/lilbillybiscuit/chatbot-ui-toolllama)ã€‚è¿™æ˜¯ä¸€ä¸ª[è§†é¢‘æ¼”ç¤º](assets/toolbench-demo.mp4)ã€‚\n\n### Web UI\n```bash\ngit clone https://github.com/lilbillybiscuit/chatbot-ui-toolllama\ncd chatbot-ui-toolllama\nnpm install\nnpm run dev\n```\n\nåº”ç”¨å°†åœ¨ http://localhost:3000/ ä¸Šå¯ç”¨\n\n### Backend server\n```bash\nexport PYTHONPATH=./\npython toolbench/inference/toolbench_server.py \\\n    --tool_root_dir data/toolenv/tools/ \\\n    --corpus_tsv_path data/retrieval/G1/corpus.tsv \\\n    --retrieval_model_path /path/to/your/retrival_model \\\n    --retrieved_api_nums 5 \\\n    --backbone_model toolllama \\\n    --model_path huggyllama/llama-7b \\\n    --lora \\\n    --lora_path /path/to/your/toolllama_lora \\\n    --max_observation_length 1024 \\\n    --method DFS_woFilter_w2 \\\n    --input_query_file data/test_instruction/G1_instruction.json \\\n    --output_answer_file data/answer/toolllama_lora_dfs_open_domain \\\n    --rapidapi_key $RAPIDAPIKEY\n```\n\nThis server will be available on `http://localhost:5000/`. To start a request, call `http://localhost:5000/stream` with a GET or POST request containing a JSON object with the following fields:\n```json\n{\n    \"text\": \"What is the weather in New York today?\",\n    \"top_k\": 5,\n    \"method\": \"DFS_woFilter_w2\"\n}\n```\n\n\n## ToolEval\n\né€šè¿‡åœ¨ToolBenchä¸Šå¯¹LLaMAè¿›è¡Œå¾®è°ƒï¼Œæˆ‘ä»¬å¾—åˆ°äº†**ToolLLaMA**ã€‚è€ƒè™‘åˆ°äººå·¥è¯„ä¼°éå¸¸è€—æ—¶ï¼Œæˆ‘ä»¬å€Ÿé‰´[AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/)å¼€å‘äº†ä¸€ä¸ªé«˜æ•ˆçš„æœºå™¨è‡ªåŠ¨è¯„ä¼°**ToolEval**ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼š\n\n- **é€šè¿‡ç‡**ï¼šè®¡ç®—åœ¨æœ‰é™çš„OpenAI APIè°ƒç”¨æ¬¡æ•°å†…æˆåŠŸå®ŒæˆæŒ‡ä»¤çš„æ¯”ä¾‹ã€‚\n\n- **åå¥½**ï¼šé€šè¿‡æ¯”è¾ƒç»™å®šæŒ‡ä»¤çš„ä¸¤ä¸ªç­”æ¡ˆï¼ˆåŠ¨ä½œåºåˆ—ï¼‰æ¥è¡¡é‡ã€‚æˆ‘ä»¬é¢„å…ˆå®šä¹‰äº†ä¸€ç»„æ›´å¥½ç­”æ¡ˆçš„æ ‡å‡†ï¼Œè¿™äº›æ ‡å‡†è¢«ç»„ç»‡æˆChatGPTçš„æç¤ºã€‚æˆ‘ä»¬å‘è¯„ä¼°å™¨æä¾›æµ‹è¯•æŒ‡ä»¤å’Œä¸¤ä¸ªå€™é€‰ç­”æ¡ˆï¼Œå¹¶è·å¾—å…¶åå¥½ã€‚æˆ‘ä»¬å¯¹æ¯ä¸ªç­”æ¡ˆå¯¹è¿›è¡Œå¤šæ¬¡è¯„ä¼°ä»¥æé«˜ç³»ç»Ÿçš„å¯é æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¡ç®—**ä¼˜èƒœç‡**ï¼ˆè¢«è¯„ä¼°å™¨é€‰æ‹©ä¸ºæ›´ä¼˜çš„ç™¾åˆ†æ¯”ï¼‰ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è®ºæ–‡ã€‚\n\nä¸ºäº†éªŒè¯ChatGPTè¯„ä¼°å™¨åœ¨é€šè¿‡ç‡å’Œèƒœç‡æ–¹é¢çš„å¯é æ€§ï¼Œæˆ‘ä»¬ä»å››ç§ä¸åŒçš„æ–¹æ³•ï¼ˆChatGPT+ReACTï¼ŒChatGPT+DFSDTï¼ŒToolLLaMA+DFSDTå’ŒGPT4+DFSDTï¼‰ä¸­è¿›è¡Œé‡‡æ ·ï¼Œä¸ºæ¯ç§æ–¹æ³•çš„300ä¸ªæµ‹è¯•æŒ‡ä»¤è·å–è§£å†³æ–¹æ¡ˆå¯¹ã€‚ç„¶åï¼Œæˆ‘ä»¬è¯·äººç±»æ ‡æ³¨ChatGPT+DFSDTï¼ŒToolLLaMA+DFSDTå’ŒGPT4+DFSDTçš„é€šè¿‡ç‡ï¼Œä»¥åŠChatGPT+ReACTå’ŒChatGPT+DFSDTä¹‹é—´çš„èƒœç‡ã€‚\n\næˆ‘ä»¬çš„ChatGPTè¯„ä¼°å™¨åœ¨é€šè¿‡ç‡æ–¹é¢ä¸äººç±»æ ‡æ³¨è€…å…·æœ‰é«˜è¾¾**87.1%**çš„ä¸€è‡´æ€§ï¼Œåœ¨èƒœç‡æ–¹é¢å…·æœ‰**80.3%**çš„ä¸€è‡´æ€§ã€‚è¿™ä¸ªç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„è¯„ä¼°å™¨ç”Ÿæˆçš„è¯„ä¼°ç»“æœä¸äººç±»éå¸¸ç›¸ä¼¼ï¼Œå¹¶ä¸”å¯ä»¥è§†ä¸ºåœ¨é€šè¿‡ç‡å’Œèƒœç‡ä¸Šæ¨¡æ‹Ÿäººç±»è¯„ä¼°çš„å¯é è¯„ä¼°å™¨ã€‚\n\næœ‰å…³ToolEvalçš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è®ºæ–‡ã€‚\n\n\n### Evaluation with ToolEval\n*è‹¥è¦å¤ç°ç»“æœï¼Œç›´æ¥é€šè¿‡[Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J)ä¸‹è½½æˆ‘ä»¬çš„`reproduction_data.zip`ï¼Œè§£å‹åç½®`reproduction_data`äº`ToolBench/data/`ä¸‹å³å¯ï¼Œå¯ä»¥è·³è¿‡æ•°æ®å‡†å¤‡æµç¨‹ã€‚*\n- æ•°æ®å‡†å¤‡ã€‚è‹¥è¦ä½¿ç”¨ ToolEval è¯„ä¼°æ‚¨è‡ªå·±çš„æ¨¡å‹å’Œæ–¹æ³•ï¼Œé¦–å…ˆéœ€è¦ä¸ºå…­ä¸ªæµ‹è¯•å­é›†å‡†å¤‡æ‰€æœ‰çš„æ¨¡å‹é¢„æµ‹ã€‚åˆ›å»ºä¸€ä¸ªä»¥æ‚¨çš„æ¨¡å‹å’Œæ–¹æ³•å‘½åçš„ç›®å½•ï¼Œä¾‹å¦‚ `chatgpt_cot`ï¼Œç„¶åå°†æ¯ä¸ªæµ‹è¯•é›†çš„é¢„æµ‹æ”¾åœ¨è¯¥ç›®å½•ä¸‹ã€‚ç›®å½•çš„æ–‡ä»¶ç»“æ„åº”å¦‚ä¸‹ï¼š\n```\nâ”œâ”€â”€ /chatgpt_cot/\nâ”‚  â”œâ”€â”€ /G1_instruction/\nâ”‚  â”‚  â”œâ”€â”€ /10160_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ /G1_tool/\nâ”‚  â”‚  â”œâ”€â”€ /10221_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\nâ”‚  â”œâ”€â”€ ...\nâ”‚  â”œâ”€â”€ /G3_instruction/\nâ”‚  â”‚  â”œâ”€â”€ /10221_CoT@1.json\nâ”‚  â”‚  â””â”€â”€ ...\n```\n\nç„¶åå¯¹æ¨¡å‹é¢„æµ‹è¿›è¡Œé¢„å¤„ç†:\n\n```bash\nexport RAW_ANSWER_PATH=../../data/reproduction_data/model_predictions/\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport MODEL_NAME=chatgpt_cot\nexport METHOD=CoT\nmkdir ${CONVERTED_ANSWER_PATH}/${MODEL_NAME}\nfor test_set in G1_instruction G1_category G1_tool G2_category G2_instruction G3_instruction\ndo\n    answer_dir=${RAW_ANSWER_PATH}/${MODEL_NAME}/${test_set}\n    output_file=${CONVERTED_ANSWER_PATH}/${MODEL_NAME}/${test_set}.json\n    python convert_to_answer_format.py\\\n        --answer_dir ${answer_dir} \\\n        --method ${METHOD} \\\n        --output ${output_file}\ndone\n```\nä¹‹åï¼Œæ£€æŸ¥`${CONVERTED_ANSWER_PATH}/${MODEL_NAME}`ä¸‹æ˜¯å¦æœ‰æµ‹è¯•é›†çš„é¢„å¤„ç†JSONæ–‡ä»¶ã€‚å¦‚æœæœ‰ï¼Œä½ å°±å¯ä»¥å‡†å¤‡è¿è¡Œä»¥ä¸‹è¯„ä¼°è¿‡ç¨‹äº†ã€‚å¦‚æœæ²¡æœ‰ï¼Œè¯·æ£€æŸ¥æ¨¡å‹çš„é¢„æµ‹æ˜¯å¦æœ‰é—®é¢˜ã€‚\n\n- OpenAI Key\nå‡†å¤‡æ‚¨çš„OpenAI Keyæ¥æ­å»ºæˆ‘ä»¬çš„evaluatorã€‚Keyéœ€è¦è¢«å­˜å‚¨åˆ°ä¸€ä¸ªjson fileä¸­ï¼Œå¦‚`path/to/your/openai_key_json_file.json`ï¼š\n```bash\n[\n    {\n        \"username\": \"your_user_name\",\n        \"passwd\": \"your_password\",\n        \"api_key\": \"your_openai_key\",\n        \"organization\": \"your_organization\"\n    },\n    ...\n]\n```\n- Pass rate.\n```bash\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport SAVE_PATH=pass_rate_results\nexport CANDIDATE_MODEL=chatgpt_cot\nexport API_POOL_FILE=path/to/your/openai_key_json_file.json\n\npython eval_pass_rate.py \\\n    --converted_answer_path ${CONVERTED_ANSWER_PATH} \\\n    --save_path ${SAVE_PATH} \\\n    --reference_model ${CANDIDATE_MODEL} \\\n    --test_ids ../../data/test_query_ids/ \\\n    --max_eval_threads 20 \\\n    --evaluate_times 7\n\n```\n\nç»“æœæ–‡ä»¶ä¼šè¢«å­˜å‚¨è‡³${SAVE_PATH}ä¸­ã€‚\n\n- Win rate. ä»¥ä¸‹ç¤ºä¾‹ä»¥ChatGPT-ReACTä½œä¸ºå‚è€ƒæ¨¡å‹ï¼ŒGPT4-ReACTä½œä¸ºå€™é€‰æ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œæ‚¨é¦–å…ˆéœ€è¦è·å–ä¸¤ä¸ªæ¨¡å‹çš„pass rateç»“æœï¼Œç„¶åè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥è¯„ä¼°GPT4-ReACTçš„win rateç»“æœ:\n```bash\nexport CONVERTED_ANSWER_PATH=../../data/reproduction_data/model_predictions_converted/\nexport SAVE_PATH=preference_results\nexport PASS_TARE_PATH=pass_rate_results\nexport REFERENCE_MODEL=chatgpt_cot\nexport CANDIDATE_MODEL=gpt-4-0613_cot\nexport API_POOL_FILE=path/to/your/openai_key_json_file.json\n\npython eval_preference.py \\\n    --converted_answer_path ${CONVERTED_ANSWER_PATH} \\\n    --reference_model ${REFERENCE_MODEL} \\\n    --output_model ${CANDIDATE_MODEL} \\\n    --test_ids ../../data/test_query_ids/ \\\n    --save_path ${SAVE_PATH} \\\n    --pass_rate_result_path ${PASS_TARE_PATH} \\\n    --max_eval_threads 20 \\\n    --use_pass_rate true \\\n    --evaluate_times 7\n```\n\nç»“æœæ–‡ä»¶ä¼šè¢«å­˜å‚¨è‡³${SAVE_PATH}ä¸­ã€‚\n\næ›´å¤šç»†èŠ‚è¯·å‚è€ƒ [ToolEval](https://github.com/OpenBMB/ToolBench/blob/master/toolbench/tooleval/README_ZH.md).\n\n\n### Model Experiment\n\nåœ¨æˆ‘ä»¬çš„ä¸»è¦å®éªŒä¸­ï¼ŒToolLLaMAå±•ç°äº†å¤„ç†å•ä¸€å·¥å…·å’Œå¤æ‚å¤šå·¥å…·æŒ‡ä»¤çš„å¼•äººæ³¨ç›®çš„èƒ½åŠ›ï¼Œä¸ChatGPTçš„èƒ½åŠ›ç›¸å½“ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦çš„å®éªŒç»“æœï¼Œå…¶ä¸­win rateçš„å‚è€ƒæ¨¡å‹æ˜¯ChatGPT-ReACT.\n\n**Pass Rate:**\n| Method | Model               | I1-Inst. | I1-Tool | I1-Cate. | I2-Inst. | I2-Cate. | I3-Inst. | Average |\n|--------|---------------------|----------|---------|----------|----------|----------|----------|---------|\n| ReACT  | Claude-2            | 5.5      | 3.5     | 5.5      | 6        | 6        | 14       | 6.8     |\n|        | Text-Davinci-003    | 12       | 20      | 20       | 8.5      | 14.5     | 24       | 16.5    |\n|        | ChatGPT             | 41.5     | 44      | 44.5     | 42.5     | 46.5     | 22       | 40.2    |\n|        | ToolLLaMA           | 25       | 29      | 33       | 30.5     | 31.5     | 25       | 29      |\n|        | GPT4                | 53.5       | 50.0    | 53.5       | 67.0     | 72.0     | 47.0       | 57.2    |\n| DFSDT  | Claude-2            | 20.5     | 31      | 18.5     | 17       | 20.5     | 28       | 22.6    |\n|        | Text-Davinci-003    | 43.5     | 44      | 46       | 37       | 42       | 46       | 43.1    |\n|        | ChatGPT             | 54.5     | 65      | 60.5     | 75       | 71.5     | 62       | 64.8    |\n|        | ToolLLaMA           | 57       | 61      | 62       | 77       | 77       | 66       | 66.7    |\n|        | ToolLLaMA-Retreiver | **64**       | 64      | 60.5     | **81.5**     | 68.5     | 65       | 67.3    |\n|        | GPT4                | 60       | **71.5**    | **67**       | 79.5     | **77.5**     | **71**       | **71.1**    |\n\n\n**Win Rate:** (Reference model: ChatGPT-ReACT)\n| Method | Model               | I1-Inst. | I1-Tool | I1-Cate. | I2-Inst. | I2-Cate. | I3-Inst. | Average |\n|--------|---------------------|----------|---------|----------|----------|----------|----------|---------|\n| ReACT  | Claude-2            | 31       | 27.8    | 33.8     | 35       | 31.5     | 47.5     | 34.4    |\n|        | Text-Davinci-003    | 28.5     | 35.3    | 31       | 29.8     | 29.8     | 45       | 33.2    |\n|        | ToolLLaMA           | 45       | 42      | 47.5     | 50.8     | 41.8     | 55       | 47      |\n|        | GPT4                | 60       | 58.8    | 63.5     | 65.8     | 60.3     | 78       | 64.4    |\n| DFSDT  | Claude-2            | 38       | 44.3    | 43.3     | 36.8     | 33.5     | 65       | 43.5    |\n|        | Text-Davinci-003    | 40.3     | 43.8    | 46.8     | 40.5     | 43.3     | 63       | 46.3    |\n|        | ChatGPT             | 60.5     | 62      | 57.3     | 72       | **64.8**     | 69       | 64.3    |\n|        | ToolLLaMA           | 55       | 55.3    | 54.5     | 68.5     | 58       | 69       | 60      |\n|        | ToolLLaMA-Retreiver | 62.3     | 59      | 55       | 68.5     | 60.8     | 73       | 63.1    |\n|        | GPT4                | **67.5**     | **67.8**    | **66.5**     | **73.3**     | 63.3     | **84**       | **70.4**    |\n\n## TODO\n- [ ] æ›´æ–°ä½¿ç”¨æ›´æ–°æ•°æ®ï¼ˆdata-0830 ç‰ˆæœ¬ï¼‰è®­ç»ƒçš„ ToolLLaMA ç»“æœã€‚\n- [ ] ToolLLaMAå°†è¾¾åˆ°GPT-4çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚\n\n## å·¥å…·å­¦ä¹ ç›¸å…³é“¾æ¥\n\né‰´äºåŸºç¡€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆ‘ä»¬æœŸå¾…çœ‹åˆ°å®ƒä»¬åœ¨æ“çºµå„ç§å·¥å…·ä¸­çš„åº”ç”¨ã€‚æ›´å¤šçš„èµ„æºï¼Œè¯·å‚è€ƒä»¥ä¸‹å†…å®¹ï¼š\n\n- **BMTools**. [[Project](https://github.com/OpenBMB/BMTools)]\n\n- **Tool Learning Survey**. [[Paper](https://arxiv.org/abs/2304.08354)]\n  \n- **Tool Learning Paper List**. [[Project](https://github.com/thunlp/ToolLearningPapers)]\n\n- **WebCPM**. [[Paper](https://github.com/thunlp/WebCPM)]\n\n## Citation\nå¦‚æœæ‚¨å¯¹ToolBenchæ„Ÿå…´è¶£ï¼Œæ¬¢è¿å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œã€‚\n```bibtex\n@misc{qin2023toolllm,\n      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, \n      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},\n      year={2023},\n      eprint={2307.16789},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}\n```\n\n```bibtex\n@misc{qin2023tool,\n      title={Tool Learning with Foundation Models}, \n      author={Yujia Qin and Shengding Hu and Yankai Lin and Weize Chen and Ning Ding and Ganqu Cui and Zheni Zeng and Yufei Huang and Chaojun Xiao and Chi Han and Yi Ren Fung and Yusheng Su and Huadong Wang and Cheng Qian and Runchu Tian and Kunlun Zhu and Shihao Liang and Xingyu Shen and Bokai Xu and Zhen Zhang and Yining Ye and Bowen Li and Ziwei Tang and Jing Yi and Yuzhang Zhu and Zhenning Dai and Lan Yan and Xin Cong and Yaxi Lu and Weilin Zhao and Yuxiang Huang and Junxi Yan and Xu Han and Xian Sun and Dahai Li and Jason Phang and Cheng Yang and Tongshuang Wu and Heng Ji and Zhiyuan Liu and Maosong Sun},\n      year={2023},\n      eprint={2304.08354},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "data_example",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "ds_configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "preprocess",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.46875,
          "content": "accelerate==0.20.3\nfastapi==0.95.1\ngradio==3.23.0\nhttpx==0.24.0\nmarkdown-it-py==2.2.0\nnumpy==1.24.3\nprompt-toolkit==3.0.38\npydantic==1.10.7\nrequests==2.30.0\nrich==13.3.5\nrouge==1.0.1\nsentencepiece==0.1.99\nshortuuid==1.0.11\ntiktoken==0.4.0\ntokenizers==0.13.3\ntorch>=1.12.0\ntransformers==4.28.1\nuvicorn==0.22.0\nbitsandbytes==0.38.1\npeft==0.3.0\nlangchain==0.0.229\ndeepspeed==0.9.2\nsentence_transformers==2.2.2\ntensorboard\nopenai\nscipy\ntermcolor\nflask\nflask_cors\nsentence_transformers"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "toolbench",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}