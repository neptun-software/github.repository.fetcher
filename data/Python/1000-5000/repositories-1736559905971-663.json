{
  "metadata": {
    "timestamp": 1736559905971,
    "page": 663,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjY3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ethereum/consensus-specs",
      "stars": 3611,
      "defaultBranch": "dev",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".codespell-whitelist",
          "type": "blob",
          "size": 0.0205078125,
          "content": "uint\nbyteorder\nether\n"
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.015625,
          "content": "**/venv\n**/.venv"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0322265625,
          "content": "*.sol linguist-language=Solidity\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.8427734375,
          "content": "*.pyc\n/__pycache__\nvenv\n.venvs\n.venv\n/.pytest_cache\n*.swp\n.eth2spec\n\nbuild/\noutput/\ndist/\n\nconsensus-spec-tests/\n\n.pytest_cache\n.mypy_cache\n\n# Dynamically built from Markdown spec\ntests/core/pyspec/eth2spec/phase0/\ntests/core/pyspec/eth2spec/altair/\ntests/core/pyspec/eth2spec/bellatrix/\ntests/core/pyspec/eth2spec/capella/\ntests/core/pyspec/eth2spec/deneb/\ntests/core/pyspec/eth2spec/electra/\ntests/core/pyspec/eth2spec/fulu/\ntests/core/pyspec/eth2spec/whisk/\ntests/core/pyspec/eth2spec/eip6800/\ntests/core/pyspec/eth2spec/eip7732/\n\n# coverage reports\n.htmlcov\n.coverage\n.coverage.*\n\n# local CI testing output\ntests/core/pyspec/test-reports\ntests/core/pyspec/eth2spec/test_results.xml\n\n*.egg-info\n\n# TOC tool outputs temporary files\n*.tmp\n\n# docs reader build\ndocs/specs\ndocs/sync\ndocs/ssz\ndocs/fork_choice\ndocs/README.md\nsite\n\n# docker test results\ntestResults\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.111328125,
          "content": "[submodule \"lib/ds-test\"]\n\tpath = solidity_deposit_contract/lib/ds-test\n\turl = https://github.com/dapphub/ds-test\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 6.4013671875,
          "content": "CC0 1.0 Universal\n\nStatement of Purpose\n\nThe laws of most jurisdictions throughout the world automatically confer\nexclusive Copyright and Related Rights (defined below) upon the creator and\nsubsequent owner(s) (each and all, an \"owner\") of an original work of\nauthorship and/or a database (each, a \"Work\").\n\nCertain owners wish to permanently relinquish those rights to a Work for the\npurpose of contributing to a commons of creative, cultural and scientific\nworks (\"Commons\") that the public can reliably and without fear of later\nclaims of infringement build upon, modify, incorporate in other works, reuse\nand redistribute as freely as possible in any form whatsoever and for any\npurposes, including without limitation commercial purposes. These owners may\ncontribute to the Commons to promote the ideal of a free culture and the\nfurther production of creative, cultural and scientific works, or to gain\nreputation or greater distribution for their Work in part through the use and\nefforts of others.\n\nFor these and/or other purposes and motivations, and without any expectation\nof additional consideration or compensation, the person associating CC0 with a\nWork (the \"Affirmer\"), to the extent that he or she is an owner of Copyright\nand Related Rights in the Work, voluntarily elects to apply CC0 to the Work\nand publicly distribute the Work under its terms, with knowledge of his or her\nCopyright and Related Rights in the Work and the meaning and intended legal\neffect of CC0 on those rights.\n\n1. Copyright and Related Rights. A Work made available under CC0 may be\nprotected by copyright and related or neighboring rights (\"Copyright and\nRelated Rights\"). Copyright and Related Rights include, but are not limited\nto, the following:\n\n  i. the right to reproduce, adapt, distribute, perform, display, communicate,\n  and translate a Work;\n\n  ii. moral rights retained by the original author(s) and/or performer(s);\n\n  iii. publicity and privacy rights pertaining to a person's image or likeness\n  depicted in a Work;\n\n  iv. rights protecting against unfair competition in regards to a Work,\n  subject to the limitations in paragraph 4(a), below;\n\n  v. rights protecting the extraction, dissemination, use and reuse of data in\n  a Work;\n\n  vi. database rights (such as those arising under Directive 96/9/EC of the\n  European Parliament and of the Council of 11 March 1996 on the legal\n  protection of databases, and under any national implementation thereof,\n  including any amended or successor version of such directive); and\n\n  vii. other similar, equivalent or corresponding rights throughout the world\n  based on applicable law or treaty, and any national implementations thereof.\n\n2. Waiver. To the greatest extent permitted by, but not in contravention of,\napplicable law, Affirmer hereby overtly, fully, permanently, irrevocably and\nunconditionally waives, abandons, and surrenders all of Affirmer's Copyright\nand Related Rights and associated claims and causes of action, whether now\nknown or unknown (including existing as well as future claims and causes of\naction), in the Work (i) in all territories worldwide, (ii) for the maximum\nduration provided by applicable law or treaty (including future time\nextensions), (iii) in any current or future medium and for any number of\ncopies, and (iv) for any purpose whatsoever, including without limitation\ncommercial, advertising or promotional purposes (the \"Waiver\"). Affirmer makes\nthe Waiver for the benefit of each member of the public at large and to the\ndetriment of Affirmer's heirs and successors, fully intending that such Waiver\nshall not be subject to revocation, rescission, cancellation, termination, or\nany other legal or equitable action to disrupt the quiet enjoyment of the Work\nby the public as contemplated by Affirmer's express Statement of Purpose.\n\n3. Public License Fallback. Should any part of the Waiver for any reason be\njudged legally invalid or ineffective under applicable law, then the Waiver\nshall be preserved to the maximum extent permitted taking into account\nAffirmer's express Statement of Purpose. In addition, to the extent the Waiver\nis so judged Affirmer hereby grants to each affected person a royalty-free,\nnon transferable, non sublicensable, non exclusive, irrevocable and\nunconditional license to exercise Affirmer's Copyright and Related Rights in\nthe Work (i) in all territories worldwide, (ii) for the maximum duration\nprovided by applicable law or treaty (including future time extensions), (iii)\nin any current or future medium and for any number of copies, and (iv) for any\npurpose whatsoever, including without limitation commercial, advertising or\npromotional purposes (the \"License\"). The License shall be deemed effective as\nof the date CC0 was applied by Affirmer to the Work. Should any part of the\nLicense for any reason be judged legally invalid or ineffective under\napplicable law, such partial invalidity or ineffectiveness shall not\ninvalidate the remainder of the License, and in such case Affirmer hereby\naffirms that he or she will not (i) exercise any of his or her remaining\nCopyright and Related Rights in the Work or (ii) assert any associated claims\nand causes of action with respect to the Work, in either case contrary to\nAffirmer's express Statement of Purpose.\n\n4. Limitations and Disclaimers.\n\n  a. No trademark or patent rights held by Affirmer are waived, abandoned,\n  surrendered, licensed or otherwise affected by this document.\n\n  b. Affirmer offers the Work as-is and makes no representations or warranties\n  of any kind concerning the Work, express, implied, statutory or otherwise,\n  including without limitation warranties of title, merchantability, fitness\n  for a particular purpose, non infringement, or the absence of latent or\n  other defects, accuracy, or the present or absence of errors, whether or not\n  discoverable, all to the greatest extent permissible under applicable law.\n\n  c. Affirmer disclaims responsibility for clearing rights of other persons\n  that may apply to the Work or any use thereof, including without limitation\n  any person's Copyright and Related Rights in the Work. Further, Affirmer\n  disclaims responsibility for obtaining any necessary consents, permissions\n  or other rights required for any use of the Work.\n\n  d. Affirmer understands and acknowledges that Creative Commons is not a\n  party to this document and has no duty or obligation with respect to this\n  CC0 or use of the Work.\n\nFor more information, please see\n<http://creativecommons.org/publicdomain/zero/1.0/>\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 9.09375,
          "content": "all: help\n\n# A list of executable specifications.\n# These must pass a strict linter.\nALL_EXECUTABLE_SPEC_NAMES = \\\n\tphase0    \\\n\taltair    \\\n\tbellatrix \\\n\tcapella   \\\n\tdeneb     \\\n\telectra   \\\n\tfulu      \\\n\twhisk     \\\n\teip6800   \\\n\teip7732\n\n# A list of fake targets.\n.PHONY: \\\n\tclean         \\\n\tcoverage      \\\n\tdetect_errors \\\n\teth2spec      \\\n\tgen_all       \\\n\tgen_list      \\\n\thelp          \\\n\tkzg_setups    \\\n\tlint          \\\n\tpyspec        \\\n\tserve_docs    \\\n\ttest\n\n###############################################################################\n# Help\n###############################################################################\n\nBOLD = $(shell tput bold)\nNORM = $(shell tput sgr0)\n\n# Print target descriptions.\nhelp:\n\t@echo \"make $(BOLD)clean$(NORM)         -- delete all untracked files\"\n\t@echo \"make $(BOLD)coverage$(NORM)      -- run pyspec tests with coverage\"\n\t@echo \"make $(BOLD)detect_errors$(NORM) -- detect generator errors\"\n\t@echo \"make $(BOLD)eth2spec$(NORM)      -- force rebuild eth2spec package\"\n\t@echo \"make $(BOLD)gen_<gen>$(NORM)     -- run a single generator\"\n\t@echo \"make $(BOLD)gen_all$(NORM)       -- run all generators\"\n\t@echo \"make $(BOLD)gen_list$(NORM)      -- list all generator targets\"\n\t@echo \"make $(BOLD)kzg_setups$(NORM)    -- generate trusted setups\"\n\t@echo \"make $(BOLD)lint$(NORM)          -- run the linters\"\n\t@echo \"make $(BOLD)pyspec$(NORM)        -- generate python specifications\"\n\t@echo \"make $(BOLD)serve_docs$(NORM)    -- start a local docs web server\"\n\t@echo \"make $(BOLD)test$(NORM)          -- run pyspec tests\"\n\n###############################################################################\n# Virtual Environment\n###############################################################################\n\nVENV = venv\nPYTHON_VENV = $(VENV)/bin/python3\nPIP_VENV = $(VENV)/bin/pip3\nCODESPELL_VENV = $(VENV)/bin/codespell\n\n# Make a virtual environment will all of the necessary dependencies.\n$(VENV): requirements_preinstallation.txt\n\t@echo \"Creating virtual environment\"\n\t@python3 -m venv $(VENV)\n\t@$(PIP_VENV) install -r requirements_preinstallation.txt\n\n###############################################################################\n# Specification\n###############################################################################\n\nTEST_LIBS_DIR = $(CURDIR)/tests/core\nPYSPEC_DIR = $(TEST_LIBS_DIR)/pyspec\nSITE_PACKAGES := $(wildcard $(VENV)/lib/python*/site-packages)\nETH2SPEC := $(SITE_PACKAGES)/eth2spec\n\n# Install the eth2spec package.\n# The pipe indicates that venv is an order-only prerequisite.\n# When restoring venv cache, its timestamp is newer than eth2spec.\n$(ETH2SPEC): setup.py | $(VENV)\n\t@$(PIP_VENV) install .[docs,lint,test,generator]\n\n# Force rebuild/install the eth2spec package.\neth2spec:\n\t@$(MAKE) --always-make $(ETH2SPEC)\n\n# Create the pyspec for all phases.\npyspec: $(VENV) setup.py\n\t@echo \"Building all pyspecs\"\n\t@$(PYTHON_VENV) setup.py pyspecdev\n\n###############################################################################\n# Testing\n###############################################################################\n\nTEST_REPORT_DIR = $(PYSPEC_DIR)/test-reports\n\n# Run pyspec tests.\n# Note: for debugging output to show, print to stderr.\n#\n# To run a specific test, append k=<test>, eg:\n#   make test k=test_verify_kzg_proof\n# To run tests for a specific fork, append fork=<fork>, eg:\n#   make test fork=deneb\n# To run tests for a specific preset, append preset=<preset>, eg:\n#   make test preset=mainnet\n# Or all at the same time, eg:\n#   make test preset=mainnet fork=deneb k=test_verify_kzg_proof\n# To run tests with a specific bls library, append bls=<bls>, eg:\n#   make test bls=arkworks\ntest: MAYBE_TEST := $(if $(k),-k=$(k))\ntest: MAYBE_FORK := $(if $(fork),--fork=$(fork))\ntest: PRESET := --preset=$(if $(preset),$(preset),minimal)\ntest: BLS := --bls-type=$(if $(bls),$(bls),fastest)\ntest: $(ETH2SPEC) pyspec\n\t@mkdir -p $(TEST_REPORT_DIR)\n\t@$(PYTHON_VENV) -m pytest \\\n\t\t-n auto \\\n\t\t--capture=no \\\n\t\t$(MAYBE_TEST) \\\n\t\t$(MAYBE_FORK) \\\n\t\t$(PRESET) \\\n\t\t$(BLS) \\\n\t\t--junitxml=$(TEST_REPORT_DIR)/test_results.xml \\\n\t\t$(PYSPEC_DIR)/eth2spec\n\n###############################################################################\n# Coverage\n###############################################################################\n\nTEST_PRESET_TYPE ?= minimal\nCOV_HTML_OUT=$(PYSPEC_DIR)/.htmlcov\nCOV_INDEX_FILE=$(COV_HTML_OUT)/index.html\nCOVERAGE_SCOPE := $(foreach S,$(ALL_EXECUTABLE_SPEC_NAMES), --cov=eth2spec.$S.$(TEST_PRESET_TYPE))\n\n# Run pytest with coverage tracking\n_test_with_coverage: MAYBE_TEST := $(if $(k),-k=$(k))\n_test_with_coverage: MAYBE_FORK := $(if $(fork),--fork=$(fork))\n_test_with_coverage: $(ETH2SPEC) pyspec\n\t@$(PYTHON_VENV) -m pytest \\\n\t\t-n auto \\\n\t\t$(MAYBE_TEST) \\\n\t\t$(MAYBE_FORK) \\\n\t\t--disable-bls \\\n\t\t$(COVERAGE_SCOPE) \\\n\t\t--cov-report=\"html:$(COV_HTML_OUT)\" \\\n\t\t--cov-branch \\\n\t\t$(PYSPEC_DIR)/eth2spec\n\n# Run tests with coverage then open the coverage report.\n# See `make test` for a list of options.\ncoverage: _test_with_coverage\n\t@echo \"Opening result: $(COV_INDEX_FILE)\"\n\t@((open \"$(COV_INDEX_FILE)\" || xdg-open \"$(COV_INDEX_FILE)\") &> /dev/null) &\n\n###############################################################################\n# Documentation\n###############################################################################\n\nDOCS_DIR = ./docs\nFORK_CHOICE_DIR = ./fork_choice\nSPEC_DIR = ./specs\nSSZ_DIR = ./ssz\nSYNC_DIR = ./sync\n\n# Copy files to the docs directory.\n_copy_docs:\n\t@cp -r $(SPEC_DIR) $(DOCS_DIR)\n\t@cp -r $(SYNC_DIR) $(DOCS_DIR)\n\t@cp -r $(SSZ_DIR) $(DOCS_DIR)\n\t@cp -r $(FORK_CHOICE_DIR) $(DOCS_DIR)\n\t@cp $(CURDIR)/README.md $(DOCS_DIR)/README.md\n\n# Start a local documentation server.\nserve_docs: _copy_docs\n\t@mkdocs build\n\t@mkdocs serve\n\n###############################################################################\n# Checks\n###############################################################################\n\nFLAKE8_CONFIG = $(CURDIR)/flake8.ini\nMYPY_CONFIG = $(CURDIR)/mypy.ini\nPYLINT_CONFIG = $(CURDIR)/pylint.ini\n\nPYLINT_SCOPE := $(foreach S,$(ALL_EXECUTABLE_SPEC_NAMES), $(PYSPEC_DIR)/eth2spec/$S)\nMYPY_SCOPE := $(foreach S,$(ALL_EXECUTABLE_SPEC_NAMES), -p eth2spec.$S)\nTEST_GENERATORS_DIR = ./tests/generators\nMARKDOWN_FILES = $(wildcard $(SPEC_DIR)/*/*.md) \\\n                 $(wildcard $(SPEC_DIR)/*/*/*.md) \\\n                 $(wildcard $(SPEC_DIR)/_features/*/*.md) \\\n                 $(wildcard $(SPEC_DIR)/_features/*/*/*.md) \\\n                 $(wildcard $(SSZ_DIR)/*.md)\n\n# Generate ToC sections & save copy of original if modified.\n%.toc:\n\t@cp $* $*.tmp; \\\n\tdoctoc $* > /dev/null; \\\n\tif diff -q $* $*.tmp > /dev/null; then \\\n\t\techo \"Good $*\"; \\\n\t\trm $*.tmp; \\\n\telse \\\n\t\techo \"\\033[1;33m Bad $*\\033[0m\"; \\\n\t\techo \"\\033[1;34m See $*.tmp\\033[0m\"; \\\n\tfi\n\n# Check all files and error if any ToC were modified.\n_check_toc: $(MARKDOWN_FILES:=.toc)\n\t@[ \"$$(find . -name '*.md.tmp' -print -quit)\" ] && exit 1 || exit 0\n\n# Check for mistakes.\nlint: $(ETH2SPEC) pyspec _check_toc\n\t@$(CODESPELL_VENV) . --skip \"./.git,$(VENV),$(PYSPEC_DIR)/.mypy_cache\" -I .codespell-whitelist\n\t@$(PYTHON_VENV) -m flake8 --config $(FLAKE8_CONFIG) $(PYSPEC_DIR)/eth2spec\n\t@$(PYTHON_VENV) -m flake8 --config $(FLAKE8_CONFIG) $(TEST_GENERATORS_DIR)\n\t@$(PYTHON_VENV) -m pylint --rcfile $(PYLINT_CONFIG) $(PYLINT_SCOPE)\n\t@$(PYTHON_VENV) -m mypy --config-file $(MYPY_CONFIG) $(MYPY_SCOPE)\n\n###############################################################################\n# Generators\n###############################################################################\n\nTEST_VECTOR_DIR = $(CURDIR)/../consensus-spec-tests/tests\nGENERATOR_DIR = $(CURDIR)/tests/generators\nSCRIPTS_DIR = $(CURDIR)/scripts\nGENERATOR_ERROR_LOG_FILE = $(TEST_VECTOR_DIR)/testgen_error_log.txt\nGENERATORS = $(sort $(dir $(wildcard $(GENERATOR_DIR)/*/.)))\nGENERATOR_TARGETS = $(patsubst $(GENERATOR_DIR)/%/, gen_%, $(GENERATORS))\n\n# List available generators.\ngen_list:\n\t@for target in $(shell echo $(GENERATOR_TARGETS) | tr ' ' '\\n' | sort -n); do \\\n\t\techo $$target; \\\n\tdone\n\n# Run one generator.\n# This will forcibly rebuild eth2spec just in case.\n# To check modules for a generator, append modcheck=true, eg:\n#   make gen_genesis modcheck=true\ngen_%: MAYBE_MODCHECK := $(if $(filter true,$(modcheck)),--modcheck)\ngen_%: eth2spec\n\t@mkdir -p $(TEST_VECTOR_DIR)\n\t@$(PYTHON_VENV) $(GENERATOR_DIR)/$*/main.py \\\n\t\t--output $(TEST_VECTOR_DIR) \\\n\t\t$(MAYBE_MODCHECK)\n\n# Run all generators then check for errors.\ngen_all: $(GENERATOR_TARGETS)\n\t@$(MAKE) detect_errors\n\n# Detect errors in generators.\ndetect_errors: $(TEST_VECTOR_DIR)\n\t@find $(TEST_VECTOR_DIR) -name \"INCOMPLETE\"\n\t@if [ -f $(GENERATOR_ERROR_LOG_FILE) ]; then \\\n\t\techo \"[ERROR] $(GENERATOR_ERROR_LOG_FILE) file exists\"; \\\n\telse \\\n\t\techo \"[PASSED] error log file does not exist\"; \\\n\tfi\n\n# Generate KZG trusted setups for testing.\nkzg_setups: $(ETH2SPEC)\n\t@for preset in minimal mainnet; do \\\n\t\t$(PYTHON_VENV) $(SCRIPTS_DIR)/gen_kzg_trusted_setups.py \\\n\t\t\t--secret=1337 \\\n\t\t\t--g1-length=4096 \\\n\t\t\t--g2-length=65 \\\n\t\t\t--output-dir $(CURDIR)/presets/$$preset/trusted_setups; \\\n\tdone\n\n###############################################################################\n# Cleaning\n###############################################################################\n\n# Delete all untracked files.\nclean:\n\t@git clean -fdx"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.998046875,
          "content": "# Ethereum Proof-of-Stake Consensus Specifications\n\n[![Join the chat at https://discord.gg/qGpsxSA](https://img.shields.io/badge/chat-on%20discord-blue.svg)](https://discord.gg/qGpsxSA)\n\nTo learn more about proof-of-stake and sharding, see the [PoS documentation](https://ethereum.org/en/developers/docs/consensus-mechanisms/pos/), [sharding documentation](https://ethereum.org/en/upgrades/sharding/) and the [research compendium](https://notes.ethereum.org/s/H1PGqDhpm).\n\nThis repository hosts the current Ethereum proof-of-stake specifications. Discussions about design rationale and proposed changes can be brought up and discussed as issues. Solidified, agreed-upon changes to the spec can be made through pull requests.\n\n## Specs\n\n[![GitHub release](https://img.shields.io/github/v/release/ethereum/consensus-specs)](https://github.com/ethereum/consensus-specs/releases/) [![PyPI version](https://badge.fury.io/py/eth2spec.svg)](https://badge.fury.io/py/eth2spec) [![testgen](https://github.com/ethereum/consensus-specs/actions/workflows/generate_vectors.yml/badge.svg?branch=dev&event=schedule)](https://github.com/ethereum/consensus-specs/actions/workflows/generate_vectors.yml)\n\nCore specifications for Ethereum proof-of-stake clients can be found in [specs](./specs). These are divided into features.\nFeatures are researched and developed in parallel, and then consolidated into sequential upgrades when ready.\n\n### Stable Specifications\n\n| Seq. | Code Name | Fork Epoch | Specs |\n| - | - | - | - |\n| 0 | **Phase0** |`0` | <ul><li>Core</li><ul><li>[The beacon chain](specs/phase0/beacon-chain.md)</li><li>[Deposit contract](specs/phase0/deposit-contract.md)</li><li>[Beacon chain fork choice](specs/phase0/fork-choice.md)</li></ul><li>Additions</li><ul><li>[Honest validator guide](specs/phase0/validator.md)</li><li>[P2P networking](specs/phase0/p2p-interface.md)</li><li>[Weak subjectivity](specs/phase0/weak-subjectivity.md)</li></ul></ul> |\n| 1 |  **Altair** | `74240` | <ul><li>Core</li><ul><li>[Beacon chain changes](specs/altair/beacon-chain.md)</li><li>[Altair fork](specs/altair/fork.md)</li></ul><li>Additions</li><ul><li>[Light client sync protocol](specs/altair/light-client/sync-protocol.md) ([full node](specs/altair/light-client/full-node.md), [light client](specs/altair/light-client/light-client.md), [networking](specs/altair/light-client/p2p-interface.md))</li><li>[Honest validator guide changes](specs/altair/validator.md)</li><li>[P2P networking](specs/altair/p2p-interface.md)</li></ul></ul> |\n| 2 | **Bellatrix** <br/> ([\"The Merge\"](https://ethereum.org/en/upgrades/merge/)) | `144896` | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/bellatrix/beacon-chain.md)</li><li>[Bellatrix fork](specs/bellatrix/fork.md)</li><li>[Fork choice changes](specs/bellatrix/fork-choice.md)</li></ul><li>Additions</li><ul><li>[Honest validator guide changes](specs/bellatrix/validator.md)</li><li>[P2P networking](specs/bellatrix/p2p-interface.md)</li></ul></ul> |\n| 3 | **Capella** | `194048` | <ul><li>Core</li><ul><li>[Beacon chain changes](specs/capella/beacon-chain.md)</li><li>[Capella fork](specs/capella/fork.md)</li></ul><li>Additions</li><ul><li>[Light client sync protocol changes](specs/capella/light-client/sync-protocol.md) ([fork](specs/capella/light-client/fork.md), [full node](specs/capella/light-client/full-node.md), [networking](specs/capella/light-client/p2p-interface.md))</li><li>[Validator additions](specs/capella/validator.md)</li><li>[P2P networking](specs/capella/p2p-interface.md)</li></ul></ul> |\n| 4 | **Deneb** | `269568` | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/deneb/beacon-chain.md)</li><li>[Deneb fork](specs/deneb/fork.md)</li><li>[Polynomial commitments](specs/deneb/polynomial-commitments.md)</li><li>[Fork choice changes](specs/deneb/fork-choice.md)</li></ul><li>Additions</li><ul><li>[Light client sync protocol changes](specs/deneb/light-client/sync-protocol.md) ([fork](specs/deneb/light-client/fork.md), [full node](specs/deneb/light-client/full-node.md), [networking](specs/deneb/light-client/p2p-interface.md))</li><li>[Honest validator guide changes](specs/deneb/validator.md)</li><li>[P2P networking](specs/deneb/p2p-interface.md)</li></ul></ul> |\n\n### In-development Specifications\n\n| Seq. | Code Name | Fork Epoch | Specs |\n| - | - | - | - |\n| 5 | **Electra** | TBD | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/electra/beacon-chain.md)</li><li>[Electra fork](specs/electra/fork.md)</li></ul><li>Additions</li><ul><li>[Light client sync protocol changes](specs/electra/light-client/sync-protocol.md) ([fork](specs/electra/light-client/fork.md), [networking](specs/electra/light-client/p2p-interface.md))</li><li>[Honest validator guide changes](specs/electra/validator.md)</li><li>[P2P networking](specs/electra/p2p-interface.md)</li></ul></ul> |\n| 6 | **Fulu** | TBD | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/fulu/beacon-chain.md)</li><li>[Fulu fork](specs/fulu/fork.md)</li><li>[Data availability sampling core](specs/fulu/das-core.md)</li><li>[Polynomial commitments sampling](specs/fulu/polynomial-commitments-sampling.md)</li><li>[Fork choice changes](specs/fulu/fork-choice.md)</li></ul><li>Additions</li><ul><li>[P2P networking](specs/fulu/p2p-interface.md)</li><li>[Peer sampling](specs/fulu/peer-sampling.md)</li></ul></ul> |\n\n### Outdated Specifications\n\n| Code Name or Topic | Specs | Notes |\n| - | - | - |\n| Sharding | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/_features/sharding/beacon-chain.md)</li></ul><li>Additions</li><ul><li>[P2P networking](specs/_features/sharding/p2p-interface.md)</li></ul></ul> |\n| Custody Game | <ul><li>Core</li><ul><li>[Beacon Chain changes](specs/_features/custody_game/beacon-chain.md)</li></ul><li>Additions</li><ul><li>[Honest validator guide changes](specs/_features/custody_game/validator.md)</li></ul></ul> | Dependent on sharding |\n| Data Availability Sampling | <ul><li>Core</li><ul><li>[Core types and functions](specs/_features/das/das-core.md)</li><li>[Fork choice changes](specs/_features/das/fork-choice.md)</li></ul><li>Additions</li><ul><li>[P2P Networking](specs/_features/das/p2p-interface.md)</li><li>[Sampling process](specs/_features/das/sampling.md)</li></ul></ul> | <ul><li> Dependent on sharding</li><li>[Technical explainer](https://hackmd.io/@HWeNw8hNRimMm2m2GH56Cw/B1YJPGkpD)</li></ul> |\n\n### Accompanying documents can be found in [specs](specs) and include:\n\n* [SimpleSerialize (SSZ) spec](ssz/simple-serialize.md)\n* [Merkle proof formats](ssz/merkle-proofs.md)\n* [General test format](tests/formats/README.md)\n\n## Additional specifications for client implementers\n\nAdditional specifications and standards outside of requisite client functionality can be found in the following repos:\n\n* [Beacon APIs](https://github.com/ethereum/beacon-apis)\n* [Engine APIs](https://github.com/ethereum/execution-apis/tree/main/src/engine)\n* [Beacon Metrics](https://github.com/ethereum/beacon-metrics/)\n\n## Design goals\n\nThe following are the broad design goals for the Ethereum proof-of-stake consensus specifications:\n* to minimize complexity, even at the cost of some losses in efficiency\n* to remain live through major network partitions and when very large portions of nodes go offline\n* to select all components such that they are either quantum secure or can be easily swapped out for quantum secure counterparts when available\n* to utilize crypto and design techniques that allow for a large participation of validators in total and per unit time\n* to allow for a typical consumer laptop with `O(C)` resources to process/validate `O(1)` shards (including any system level validation such as the beacon chain)\n\n## Useful external resources\n\n* [Design Rationale](https://notes.ethereum.org/s/rkhCgQteN#)\n* [Phase 0 Onboarding Document](https://notes.ethereum.org/s/Bkn3zpwxB)\n* [Combining GHOST and Casper paper](https://arxiv.org/abs/2003.03052)\n\n## For spec contributors\n\nDocumentation on the different components used during spec writing can be found here:\n* [YAML Test Generators](tests/generators/README.md)\n* [Executable Python Spec, with Py-tests](tests/core/pyspec/README.md)\n\n## Online viewer of the latest release (latest `master` branch)\n\n[Ethereum Consensus Specs](https://ethereum.github.io/consensus-specs/)\n\n## Consensus spec tests\n\nConformance tests built from the executable python spec are available in the [Ethereum Proof-of-Stake Consensus Spec Tests](https://github.com/ethereum/consensus-spec-tests) repo. Compressed tarballs are available in [releases](https://github.com/ethereum/consensus-spec-tests/releases).\n\n\n## Installation and Usage\nThe consensus-specs repo can be used by running the tests locally or inside a docker container.\n\nTo run the tests locally:\n- Clone the repository with `git clone https://github.com/ethereum/consensus-specs.git`\n- Switch to the directory `cd consensus-specs`\n- Run the tests with `make test`\n\nTo run the tests inside a docker container:\n- Switch to the directory with `cd scripts`\n- Run the script `./build_run_docker_tests.sh`\n- Find the results in a folder called `./testResults`\n- Find more ways to customize the script with `./build_run_docker_tests.sh --h`"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.6416015625,
          "content": "# Security Policy\n\n## Supported Versions\n\nPlease see [Releases](https://github.com/ethereum/consensus-specs/releases/). We recommend using the [most recently released version](https://github.com/ethereum/consensus-specs/releases/latest).\n\n## Reporting a Vulnerability\n\n**Please do not file a public ticket** mentioning the vulnerability.\n\nTo find out how to disclose a vulnerability in the Ethereum Consensus Layer visit [https://ethereum.org/bug-bounty](https://ethereum.org/bug-bounty) or email bounty@ethereum.org. Please read the [disclosure page](https://ethereum.org/bug-bounty) for more information about publicly disclosed security vulnerabilities.\n"
        },
        {
          "name": "configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "flake8.ini",
          "type": "blob",
          "size": 0.052734375,
          "content": "[flake8]\nignore = E252,W504,W503\nmax-line-length = 120"
        },
        {
          "name": "fork_choice",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 0.9013671875,
          "content": "site_name: Ethereum Consensus Specs\nsite_url: https://ethereum.github.io/consensus-specs/\nrepo_name: ethereum/consensus-specs\ntheme:\n  name: material\n  palette:\n    - scheme: default\n      primary: black\n      toggle:\n        icon: material/brightness-7\n        name: Switch to dark mode\n    - scheme: slate\n      primary: black\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n  features:\n    - navigation.tabs\n    - search\nmarkdown_extensions:\n  - toc:\n      permalink: true\n  - pymdownx.superfences\n  - pymdownx.highlight:\n      use_pygments: true\n      noclasses: true\n      pygments_style: monokai\n      linenums: true\n      anchor_linenums: true\n  - mdx_truly_sane_lists:\n      nested_indent: 4\nplugins:\n  - search\n  - awesome-pages\nextra_css:\n  - stylesheets/extra.css\nextra:\n  social:\n    - icon: fontawesome/brands/github\n      link: https://github.com/ethereum/consensus-specs\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.1748046875,
          "content": "[mypy]\ndisallow_incomplete_defs = True\ndisallow_untyped_defs = True\nwarn_unused_ignores = True\nwarn_unused_configs = True\nwarn_redundant_casts = True\nignore_missing_imports = True"
        },
        {
          "name": "presets",
          "type": "tree",
          "content": null
        },
        {
          "name": "pylint.ini",
          "type": "blob",
          "size": 0.0556640625,
          "content": "[MESSAGES CONTROL]\ndisable = all\nenable = unused-argument"
        },
        {
          "name": "pysetup",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements_preinstallation.txt",
          "type": "blob",
          "size": 0.0693359375,
          "content": "pip>=24.0.0\nwheel>=0.44.0\nsetuptools>=72.0.0\npylint>=3.2.0\nbuild>=1.2.2"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 22.2177734375,
          "content": "from setuptools import setup, find_packages, Command\nfrom setuptools.command.build_py import build_py\nfrom distutils import dir_util\nfrom distutils.util import convert_path\nfrom pathlib import Path\nimport os\nimport string\nfrom typing import Dict, List, Sequence, Optional, Tuple\nimport ast\nimport subprocess\nimport sys\nimport copy\nfrom collections import OrderedDict\nimport json\nfrom functools import lru_cache\n\nfrom pysetup.constants import (\n    # code names\n    PHASE0,\n    # misc\n    ETH2_SPEC_COMMENT_PREFIX,\n)\nfrom pysetup.spec_builders import spec_builders\nfrom pysetup.typing import (\n    BuildTarget,\n    ProtocolDefinition,\n    SpecObject,\n    VariableDefinition,\n)\nfrom pysetup.helpers import (\n    combine_spec_objects,\n    dependency_order_class_objects,\n    objects_to_spec,\n    parse_config_vars,\n)\nfrom pysetup.md_doc_paths import get_md_doc_paths\n\n# Ignore '1.5.0-alpha.*' to '1.5.0a*' messages.\nimport warnings\nwarnings.filterwarnings('ignore', message='Normalizing .* to .*')\n\n# Ignore 'running' and 'creating' messages\nimport logging\nclass PyspecFilter(logging.Filter):\n    def filter(self, record):\n        return not record.getMessage().startswith(('running ', 'creating '))\nlogging.getLogger().addFilter(PyspecFilter())\n\n# NOTE: have to programmatically include third-party dependencies in `setup.py`.\ndef installPackage(package: str):\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n\nRUAMEL_YAML_VERSION = \"ruamel.yaml==0.17.21\"\ntry:\n    import ruamel.yaml\nexcept ImportError:\n    installPackage(RUAMEL_YAML_VERSION)\n\nfrom ruamel.yaml import YAML\n\nMARKO_VERSION = \"marko==1.0.2\"\ntry:\n    import marko\nexcept ImportError:\n    installPackage(MARKO_VERSION)\n\nfrom marko.block import Heading, FencedCode, LinkRefDef, BlankLine\nfrom marko.inline import CodeSpan\nfrom marko.ext.gfm import gfm\nfrom marko.ext.gfm.elements import Table\n\n\n@lru_cache(maxsize=None)\ndef _get_name_from_heading(heading: Heading) -> Optional[str]:\n    last_child = heading.children[-1]\n    if isinstance(last_child, CodeSpan):\n        return last_child.children\n    return None\n\n\n@lru_cache(maxsize=None)\ndef _get_source_from_code_block(block: FencedCode) -> str:\n    return block.children[0].children.strip()\n\n\n@lru_cache(maxsize=None)\ndef _get_function_name_from_source(source: str) -> str:\n    fn = ast.parse(source).body[0]\n    return fn.name\n\n\n@lru_cache(maxsize=None)\ndef _get_self_type_from_source(source: str) -> Optional[str]:\n    fn = ast.parse(source).body[0]\n    args = fn.args.args\n    if len(args) == 0:\n        return None\n    if args[0].arg != 'self':\n        return None\n    if args[0].annotation is None:\n        return None\n    return args[0].annotation.id\n\n\n@lru_cache(maxsize=None)\ndef _get_class_info_from_source(source: str) -> Tuple[str, Optional[str]]:\n    class_def = ast.parse(source).body[0]\n    base = class_def.bases[0]\n    if isinstance(base, ast.Name):\n        parent_class = base.id\n    elif isinstance(base, ast.Subscript):\n        parent_class = base.value.id\n    else:\n        # NOTE: SSZ definition derives from earlier phase...\n        # e.g. `phase0.SignedBeaconBlock`\n        # TODO: check for consistency with other phases\n        parent_class = None\n    return class_def.name, parent_class\n\n\n@lru_cache(maxsize=None)\ndef _is_constant_id(name: str) -> bool:\n    if name[0] not in string.ascii_uppercase + '_':\n        return False\n    return all(map(lambda c: c in string.ascii_uppercase + '_' + string.digits, name[1:]))\n\n\n@lru_cache(maxsize=None)\ndef _load_kzg_trusted_setups(preset_name):\n    trusted_setups_file_path = str(Path(__file__).parent) + '/presets/' + preset_name + '/trusted_setups/trusted_setup_4096.json'\n\n    with open(trusted_setups_file_path, 'r') as f:\n        json_data = json.load(f)\n        trusted_setup_G1_monomial = json_data['g1_monomial']\n        trusted_setup_G1_lagrange = json_data['g1_lagrange']\n        trusted_setup_G2_monomial = json_data['g2_monomial']\n\n    return trusted_setup_G1_monomial, trusted_setup_G1_lagrange, trusted_setup_G2_monomial\n\n@lru_cache(maxsize=None)\ndef _load_curdleproofs_crs(preset_name):\n    \"\"\"\n    NOTE: File generated from https://github.com/asn-d6/curdleproofs/blob/8e8bf6d4191fb6a844002f75666fb7009716319b/tests/crs.rs#L53-L67\n    \"\"\"\n    file_path = str(Path(__file__).parent) + '/presets/' + preset_name + '/trusted_setups/curdleproofs_crs.json'\n\n    with open(file_path, 'r') as f:\n        json_data = json.load(f)\n\n    return json_data\n\n\nALL_KZG_SETUPS = {\n    'minimal': _load_kzg_trusted_setups('minimal'),\n    'mainnet': _load_kzg_trusted_setups('mainnet')\n}\n\nALL_CURDLEPROOFS_CRS = {\n    'minimal': _load_curdleproofs_crs('minimal'),\n    'mainnet': _load_curdleproofs_crs('mainnet'),\n}\n\n\n@lru_cache(maxsize=None)\ndef _get_eth2_spec_comment(child: LinkRefDef) -> Optional[str]:\n    _, _, title = child._parse_info\n    if not (title[0] == \"(\" and title[len(title)-1] == \")\"):\n        return None\n    title = title[1:len(title)-1]\n    if not title.startswith(ETH2_SPEC_COMMENT_PREFIX):\n        return None\n    return title[len(ETH2_SPEC_COMMENT_PREFIX):].strip()\n\n\n@lru_cache(maxsize=None)\ndef _parse_value(name: str, typed_value: str, type_hint: Optional[str] = None) -> VariableDefinition:\n    comment = None\n    if name in (\"ROOT_OF_UNITY_EXTENDED\", \"ROOTS_OF_UNITY_EXTENDED\", \"ROOTS_OF_UNITY_REDUCED\"):\n        comment = \"noqa: E501\"\n\n    typed_value = typed_value.strip()\n    if '(' not in typed_value:\n        return VariableDefinition(type_name=None, value=typed_value, comment=comment, type_hint=type_hint)\n    i = typed_value.index('(')\n    type_name = typed_value[:i]\n\n    return VariableDefinition(type_name=type_name, value=typed_value[i+1:-1], comment=comment, type_hint=type_hint)\n\n\ndef _update_constant_vars_with_kzg_setups(constant_vars, preset_name):\n    comment = \"noqa: E501\"\n    kzg_setups = ALL_KZG_SETUPS[preset_name]\n    constant_vars['KZG_SETUP_G1_MONOMIAL'] = VariableDefinition(constant_vars['KZG_SETUP_G1_MONOMIAL'].value, str(kzg_setups[0]), comment, None)\n    constant_vars['KZG_SETUP_G1_LAGRANGE'] = VariableDefinition(constant_vars['KZG_SETUP_G1_LAGRANGE'].value, str(kzg_setups[1]), comment, None)\n    constant_vars['KZG_SETUP_G2_MONOMIAL'] = VariableDefinition(constant_vars['KZG_SETUP_G2_MONOMIAL'].value, str(kzg_setups[2]), comment, None)\n\n\n@lru_cache(maxsize=None)\ndef parse_markdown(content: str):\n    return gfm.parse(content)\n\n\ndef get_spec(file_name: Path, preset: Dict[str, str], config: Dict[str, str], preset_name=str) -> SpecObject:\n    functions: Dict[str, str] = {}\n    protocols: Dict[str, ProtocolDefinition] = {}\n    constant_vars: Dict[str, VariableDefinition] = {}\n    preset_vars: Dict[str, VariableDefinition] = {}\n    config_vars: Dict[str, VariableDefinition] = {}\n    ssz_dep_constants: Dict[str, str] = {}\n    func_dep_presets: Dict[str, str] = {}\n    ssz_objects: Dict[str, str] = {}\n    dataclasses: Dict[str, str] = {}\n    custom_types: Dict[str, str] = {}\n\n    with open(file_name) as source_file:\n        document = parse_markdown(source_file.read())\n\n    current_name = None\n    should_skip = False\n    for child in document.children:\n        if isinstance(child, BlankLine):\n            continue\n        if should_skip:\n            should_skip = False\n            continue\n        if isinstance(child, Heading):\n            current_name = _get_name_from_heading(child)\n        elif isinstance(child, FencedCode):\n            if child.lang != \"python\":\n                continue\n            source = _get_source_from_code_block(child)\n            if source.startswith(\"def\"):\n                current_name = _get_function_name_from_source(source)\n                self_type_name = _get_self_type_from_source(source)\n                function_def = \"\\n\".join(line.rstrip() for line in source.splitlines())\n                if self_type_name is None:\n                    functions[current_name] = function_def\n                else:\n                    if self_type_name not in protocols:\n                        protocols[self_type_name] = ProtocolDefinition(functions={})\n                    protocols[self_type_name].functions[current_name] = function_def\n            elif source.startswith(\"@dataclass\"):\n                dataclasses[current_name] = \"\\n\".join(line.rstrip() for line in source.splitlines())\n            elif source.startswith(\"class\"):\n                class_name, parent_class = _get_class_info_from_source(source)\n                # check consistency with spec\n                try:\n                    assert class_name == current_name\n                except Exception:\n                    print('class_name', class_name)\n                    print('current_name', current_name)\n                    raise\n\n                if parent_class:\n                    assert parent_class == \"Container\"\n                # NOTE: trim whitespace from spec\n                ssz_objects[current_name] = \"\\n\".join(line.rstrip() for line in source.splitlines())\n            else:\n                raise Exception(\"unrecognized python code element: \" + source)\n        elif isinstance(child, Table):\n            for row in child.children:\n                cells = row.children\n                if len(cells) >= 2:\n                    name_cell = cells[0]\n                    name = name_cell.children[0].children\n\n                    value_cell = cells[1]\n                    value = value_cell.children[0].children\n\n                    description = None\n                    if len(cells) >= 3:\n                        description_cell = cells[2]\n                        if len(description_cell.children) > 0:\n                            description = description_cell.children[0].children\n                            if isinstance(description, list):\n                                # marko parses `**X**` as a list containing a X\n                                description = description[0].children\n\n                    if isinstance(name, list):\n                        # marko parses `[X]()` as a list containing a X\n                        name = name[0].children\n                    if isinstance(value, list):\n                        # marko parses `**X**` as a list containing a X\n                        value = value[0].children\n\n                    # Skip types that have been defined elsewhere\n                    if description is not None and description.startswith(\"<!-- predefined-type -->\"):\n                        continue\n\n                    if not _is_constant_id(name):\n                        # Check for short type declarations\n                        if value.startswith((\"uint\", \"Bytes\", \"ByteList\", \"Union\", \"Vector\", \"List\", \"ByteVector\")):\n                            custom_types[name] = value\n                        continue\n\n                    if value.startswith(\"get_generalized_index\"):\n                        ssz_dep_constants[name] = value\n                        continue\n\n                    if description is not None and description.startswith(\"<!-- predefined -->\"):\n                        func_dep_presets[name] = value\n\n                    value_def = _parse_value(name, value)\n                    if name in preset:\n                        preset_vars[name] = VariableDefinition(value_def.type_name, preset[name], value_def.comment, None)\n                    elif name in config:\n                        config_vars[name] = VariableDefinition(value_def.type_name, config[name], value_def.comment, None)\n                    else:\n                        if name in ('ENDIANNESS', 'KZG_ENDIANNESS'):\n                            # Deal with mypy Literal typing check\n                            value_def = _parse_value(name, value, type_hint='Final')\n                        constant_vars[name] = value_def\n\n        elif isinstance(child, LinkRefDef):\n            comment = _get_eth2_spec_comment(child)\n            if comment == \"skip\":\n                should_skip = True\n\n    # Load KZG trusted setup from files\n    if any('KZG_SETUP' in name for name in constant_vars):\n        _update_constant_vars_with_kzg_setups(constant_vars, preset_name)\n\n    if any('CURDLEPROOFS_CRS' in name for name in constant_vars):\n        constant_vars['CURDLEPROOFS_CRS'] = VariableDefinition(\n            None,\n            'curdleproofs.CurdleproofsCrs.from_json(json.dumps(' + str(ALL_CURDLEPROOFS_CRS[str(preset_name)]).replace('0x', '') + '))',\n            \"noqa: E501\", None\n        )\n\n    return SpecObject(\n        functions=functions,\n        protocols=protocols,\n        custom_types=custom_types,\n        constant_vars=constant_vars,\n        preset_vars=preset_vars,\n        config_vars=config_vars,\n        ssz_dep_constants=ssz_dep_constants,\n        func_dep_presets=func_dep_presets,\n        ssz_objects=ssz_objects,\n        dataclasses=dataclasses,\n    )\n\n\n@lru_cache(maxsize=None)\ndef load_preset(preset_files: Sequence[Path]) -> Dict[str, str]:\n    \"\"\"\n    Loads the a directory of preset files, merges the result into one preset.\n    \"\"\"\n    preset = {}\n    for fork_file in preset_files:\n        yaml = YAML(typ='base')\n        fork_preset: dict = yaml.load(fork_file)\n        if fork_preset is None:  # for empty YAML files\n            continue\n        if not set(fork_preset.keys()).isdisjoint(preset.keys()):\n            duplicates = set(fork_preset.keys()).intersection(set(preset.keys()))\n            raise Exception(f\"duplicate config var(s) in preset files: {', '.join(duplicates)}\")\n        preset.update(fork_preset)\n    assert preset != {}\n    return parse_config_vars(preset)\n\n\n@lru_cache(maxsize=None)\ndef load_config(config_path: Path) -> Dict[str, str]:\n    \"\"\"\n    Loads the given configuration file.\n    \"\"\"\n    yaml = YAML(typ='base')\n    config_data = yaml.load(config_path)\n    return parse_config_vars(config_data)\n\n\ndef build_spec(fork: str,\n               preset_name: str,\n               source_files: Sequence[Path],\n               preset_files: Sequence[Path],\n               config_file: Path) -> str:\n    preset = load_preset(tuple(preset_files))\n    config = load_config(config_file)\n    all_specs = [get_spec(spec, preset, config, preset_name) for spec in source_files]\n\n    spec_object = all_specs[0]\n    for value in all_specs[1:]:\n        spec_object = combine_spec_objects(spec_object, value)\n\n    class_objects = {**spec_object.ssz_objects, **spec_object.dataclasses}\n\n    # Ensure it's ordered after multiple forks\n    new_objects = {}\n    while OrderedDict(new_objects) != OrderedDict(class_objects):\n        new_objects = copy.deepcopy(class_objects)\n        dependency_order_class_objects(class_objects, spec_object.custom_types)\n\n    return objects_to_spec(preset_name, spec_object, fork, class_objects)\n\n\nclass PySpecCommand(Command):\n    \"\"\"Convert spec markdown files to a spec python file\"\"\"\n\n    description = \"Convert spec markdown files to a spec python file\"\n\n    spec_fork: str\n    md_doc_paths: str\n    parsed_md_doc_paths: List[str]\n    build_targets: str\n    parsed_build_targets: List[BuildTarget]\n    out_dir: str\n\n    # The format is (long option, short option, description).\n    user_options = [\n        ('spec-fork=', None, \"Spec fork to tag build with. Used to select md-docs defaults.\"),\n        ('md-doc-paths=', None, \"List of paths of markdown files to build spec with\"),\n        ('build-targets=', None, \"Names, directory paths of compile-time presets, and default config paths.\"),\n        ('out-dir=', None, \"Output directory to write spec package to\")\n    ]\n\n    def initialize_options(self):\n        \"\"\"Set default values for options.\"\"\"\n        # Each user option must be listed here with their default value.\n        self.spec_fork = PHASE0\n        self.md_doc_paths = ''\n        self.out_dir = 'pyspec_output'\n        self.build_targets = \"\"\"\n                minimal:presets/minimal:configs/minimal.yaml\n                mainnet:presets/mainnet:configs/mainnet.yaml\n        \"\"\"\n\n    def finalize_options(self):\n        \"\"\"Post-process options.\"\"\"\n        if len(self.md_doc_paths) == 0:\n            self.md_doc_paths = get_md_doc_paths(self.spec_fork)\n            if len(self.md_doc_paths) == 0:\n                raise Exception('no markdown files specified, and spec fork \"%s\" is unknown', self.spec_fork)\n\n        self.parsed_md_doc_paths = self.md_doc_paths.split()\n\n        for filename in self.parsed_md_doc_paths:\n            if not os.path.exists(filename):\n                raise Exception('Pyspec markdown input file \"%s\" does not exist.' % filename)\n\n        self.parsed_build_targets = []\n        for target in self.build_targets.split():\n            target = target.strip()\n            data = target.split(':')\n            if len(data) != 3:\n                raise Exception('invalid target, expected \"name:preset_dir:config_file\" format, but got: %s' % target)\n            name, preset_dir_path, config_path = data\n            if any((c not in string.digits + string.ascii_letters) for c in name):\n                raise Exception('invalid target name: \"%s\"' % name)\n            if not os.path.exists(preset_dir_path):\n                raise Exception('Preset dir \"%s\" does not exist' % preset_dir_path)\n            _, _, preset_file_names = next(os.walk(preset_dir_path))\n            preset_paths = [(Path(preset_dir_path) / name) for name in preset_file_names]\n\n            if not os.path.exists(config_path):\n                raise Exception('Config file \"%s\" does not exist' % config_path)\n            self.parsed_build_targets.append(BuildTarget(name, preset_paths, Path(config_path)))\n\n    def run(self):\n        if not self.dry_run:\n            dir_util.mkpath(self.out_dir)\n\n        print(f'Building pyspec: {self.spec_fork}')\n        for (name, preset_paths, config_path) in self.parsed_build_targets:\n            spec_str = build_spec(\n                spec_builders[self.spec_fork].fork,\n                name,\n                self.parsed_md_doc_paths,\n                preset_paths,\n                config_path,\n            )\n            if self.dry_run:\n                self.announce('dry run successfully prepared contents for spec.'\n                              f' out dir: \"{self.out_dir}\", spec fork: \"{self.spec_fork}\", build target: \"{name}\"')\n                self.debug_print(spec_str)\n            else:\n                with open(os.path.join(self.out_dir, name+'.py'), 'w') as out:\n                    out.write(spec_str)\n\n        if not self.dry_run:\n            with open(os.path.join(self.out_dir, '__init__.py'), 'w') as out:\n                # `mainnet` is the default spec.\n                out.write(\"from . import mainnet as spec  # noqa:F401\\n\")\n\n\nclass BuildPyCommand(build_py):\n    \"\"\"Customize the build command to run the spec-builder on setup.py build\"\"\"\n\n    def initialize_options(self):\n        super(BuildPyCommand, self).initialize_options()\n\n    def run_pyspec_cmd(self, spec_fork: str, **opts):\n        cmd_obj: PySpecCommand = self.distribution.reinitialize_command(\"pyspec\")\n        cmd_obj.spec_fork = spec_fork\n        cmd_obj.out_dir = os.path.join(self.build_lib, 'eth2spec', spec_fork)\n        for k, v in opts.items():\n            setattr(cmd_obj, k, v)\n        self.run_command('pyspec')\n\n    def run(self):\n        for spec_fork in spec_builders:\n            self.run_pyspec_cmd(spec_fork=spec_fork)\n\n        super(BuildPyCommand, self).run()\n\n\nclass PyspecDevCommand(Command):\n    \"\"\"Build the markdown files in-place to their source location for testing.\"\"\"\n    description = \"Build the markdown files in-place to their source location for testing.\"\n    user_options = []\n\n    def initialize_options(self):\n        pass\n\n    def finalize_options(self):\n        pass\n\n    def run_pyspec_cmd(self, spec_fork: str, **opts):\n        cmd_obj: PySpecCommand = self.distribution.reinitialize_command(\"pyspec\")\n        cmd_obj.spec_fork = spec_fork\n        eth2spec_dir = convert_path(self.distribution.package_dir['eth2spec'])\n        cmd_obj.out_dir = os.path.join(eth2spec_dir, spec_fork)\n        for k, v in opts.items():\n            setattr(cmd_obj, k, v)\n        self.run_command('pyspec')\n\n    def run(self):\n        for spec_fork in spec_builders:\n            self.run_pyspec_cmd(spec_fork=spec_fork)\n\n\ncommands = {\n    'pyspec': PySpecCommand,\n    'build_py': BuildPyCommand,\n    'pyspecdev': PyspecDevCommand,\n}\n\nwith open(\"README.md\", \"rt\", encoding=\"utf8\") as f:\n    readme = f.read()\n\n# How to use \"VERSION.txt\" file:\n# - dev branch contains \"X.Y.Z.dev\", where \"X.Y.Z\" is the target version to release dev into.\n#    -> Changed as part of 'master' backport to 'dev'\n# - master branch contains \"X.Y.Z\", where \"X.Y.Z\" is the current version.\n#    -> Changed as part of 'dev' release (or other branch) into 'master'\n#    -> In case of a commit on master without git tag, target the next version\n#        with \".postN\" (release candidate, numbered) suffixed.\n# See https://www.python.org/dev/peps/pep-0440/#public-version-identifiers\nwith open(os.path.join('tests', 'core', 'pyspec', 'eth2spec', 'VERSION.txt')) as f:\n    spec_version = f.read().strip()\n\nsetup(\n    name='eth2spec',\n    version=spec_version,\n    description=\"Eth2 spec, provided as Python package for tooling and testing\",\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=\"ethereum\",\n    url=\"https://github.com/ethereum/consensus-specs\",\n    include_package_data=False,\n    package_data={\n        'configs': ['*.yaml'],\n        'eth2spec': ['VERSION.txt'],\n        'presets': ['**/*.yaml', '**/*.json'],\n        'specs': ['**/*.md'],\n        'sync': ['optimistic.md'],\n    },\n    package_dir={\n        \"configs\": \"configs\",\n        \"eth2spec\": \"tests/core/pyspec/eth2spec\",\n        \"presets\": \"presets\",\n        \"specs\": \"specs\",\n        \"sync\": \"sync\",\n    },\n    packages=find_packages(where='tests/core/pyspec') + ['configs', 'presets', 'specs', 'presets', 'sync'],\n    py_modules=[\"eth2spec\"],\n    cmdclass=commands,\n    python_requires=\">=3.9, <4\",\n    extras_require={\n        \"test\": [\"pytest>=4.4\", \"pytest-cov\", \"pytest-xdist\"],\n        \"lint\": [\"flake8==5.0.4\", \"mypy==0.981\", \"pylint==3.3.1\", \"codespell<3.0.0,>=2.0.0\"],\n        \"generator\": [\"setuptools>=72.0.0\", \"pytest>4.4\", \"python-snappy==0.7.3\", \"filelock\", \"pathos==0.3.0\"],\n        \"docs\": [\"mkdocs==1.4.2\", \"mkdocs-material==9.1.5\", \"mdx-truly-sane-lists==1.3\",  \"mkdocs-awesome-pages-plugin==2.8.0\"]\n    },\n    install_requires=[\n        \"eth-utils>=2.0.0,<3\",\n        \"eth-typing>=3.2.0,<4.0.0\",\n        \"pycryptodome>=3.19.1\",\n        \"py_ecc==6.0.0\",\n        \"milagro_bls_binding==1.9.0\",\n        \"remerkleable==0.1.28\",\n        \"trie>=3,<4\",\n        RUAMEL_YAML_VERSION,\n        \"lru-dict==1.2.0\",\n        MARKO_VERSION,\n        \"py_arkworks_bls12381==0.3.8\",\n        \"curdleproofs==0.1.2\",\n    ]\n)\n"
        },
        {
          "name": "solidity_deposit_contract",
          "type": "tree",
          "content": null
        },
        {
          "name": "specs",
          "type": "tree",
          "content": null
        },
        {
          "name": "ssz",
          "type": "tree",
          "content": null
        },
        {
          "name": "sync",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}