{
  "metadata": {
    "timestamp": 1736560000082,
    "page": 800,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjgxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "abhiTronix/vidgear",
      "stars": 3421,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.8125,
          "content": "# Basic .gitattributes for a vidgear repo.\n\n# Set the default behavior, in case people don't have core.autocrlf set.\n* text=auto\n\n# Binary data types\n*.gif binary\n*.ico binary\n*.jpg binary\n*.bmp binary\n*.webp binary\n*.svg binary\n*.png binary\n*.whl binary\n*.zip binary\n\n# Language aware diff headers\n*.css   diff=css\n*.html  diff=html\n*.py    diff=python\n*.md    diff=markdown\n\n# Linguist language overrides\n*.py linguist-language=Python\n*.md linguist-language=Markdown\n*.js linguist-language=JavaScript\n*.sh linguist-language=Shell\n*.css linguist-language=CSS\n*.html linguist-language=HTML\n*.yml linguist-language=YAML\n\n# Override LF on some files\n*.js    text eol=lf\n*.md    text eol=lf\n*.css   text eol=lf\n*.html  text eol=lf\n*.cfg   text eol=lf\n*.json  text eol=lf\n*.sh    text eol=lf\n*.yml   text eol=lf\n*.manifest   text eol=lf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1923828125,
          "content": "__pycache__\n.pytest_cache\n.ipynb_checkpoints\n.mypy_cache\n.vscode\nvenv\nPipfile.lock\nenv3.*\nenv\n.cache\n.coverage\ncoverage.xml\n.netlify\n.idea\nbuild/*\n*.egg-info/\n*.egg\n\n# vim temporary files\n*~\n.*.sw?"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.314453125,
          "content": "                                 Apache License\r\n                           Version 2.0, January 2004\r\n                        http://www.apache.org/licenses/\r\n\r\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\r\n\r\n   1. Definitions.\r\n\r\n      \"License\" shall mean the terms and conditions for use, reproduction,\r\n      and distribution as defined by Sections 1 through 9 of this document.\r\n\r\n      \"Licensor\" shall mean the copyright owner or entity authorized by\r\n      the copyright owner that is granting the License.\r\n\r\n      \"Legal Entity\" shall mean the union of the acting entity and all\r\n      other entities that control, are controlled by, or are under common\r\n      control with that entity. For the purposes of this definition,\r\n      \"control\" means (i) the power, direct or indirect, to cause the\r\n      direction or management of such entity, whether by contract or\r\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\r\n      outstanding shares, or (iii) beneficial ownership of such entity.\r\n\r\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\r\n      exercising permissions granted by this License.\r\n\r\n      \"Source\" form shall mean the preferred form for making modifications,\r\n      including but not limited to software source code, documentation\r\n      source, and configuration files.\r\n\r\n      \"Object\" form shall mean any form resulting from mechanical\r\n      transformation or translation of a Source form, including but\r\n      not limited to compiled object code, generated documentation,\r\n      and conversions to other media types.\r\n\r\n      \"Work\" shall mean the work of authorship, whether in Source or\r\n      Object form, made available under the License, as indicated by a\r\n      copyright notice that is included in or attached to the work\r\n      (an example is provided in the Appendix below).\r\n\r\n      \"Derivative Works\" shall mean any work, whether in Source or Object\r\n      form, that is based on (or derived from) the Work and for which the\r\n      editorial revisions, annotations, elaborations, or other modifications\r\n      represent, as a whole, an original work of authorship. For the purposes\r\n      of this License, Derivative Works shall not include works that remain\r\n      separable from, or merely link (or bind by name) to the interfaces of,\r\n      the Work and Derivative Works thereof.\r\n\r\n      \"Contribution\" shall mean any work of authorship, including\r\n      the original version of the Work and any modifications or additions\r\n      to that Work or Derivative Works thereof, that is intentionally\r\n      submitted to Licensor for inclusion in the Work by the copyright owner\r\n      or by an individual or Legal Entity authorized to submit on behalf of\r\n      the copyright owner. For the purposes of this definition, \"submitted\"\r\n      means any form of electronic, verbal, or written communication sent\r\n      to the Licensor or its representatives, including but not limited to\r\n      communication on electronic mailing lists, source code control systems,\r\n      and issue tracking systems that are managed by, or on behalf of, the\r\n      Licensor for the purpose of discussing and improving the Work, but\r\n      excluding communication that is conspicuously marked or otherwise\r\n      designated in writing by the copyright owner as \"Not a Contribution.\"\r\n\r\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\r\n      on behalf of whom a Contribution has been received by Licensor and\r\n      subsequently incorporated within the Work.\r\n\r\n   2. Grant of Copyright License. Subject to the terms and conditions of\r\n      this License, each Contributor hereby grants to You a perpetual,\r\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\r\n      copyright license to reproduce, prepare Derivative Works of,\r\n      publicly display, publicly perform, sublicense, and distribute the\r\n      Work and such Derivative Works in Source or Object form.\r\n\r\n   3. Grant of Patent License. Subject to the terms and conditions of\r\n      this License, each Contributor hereby grants to You a perpetual,\r\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\r\n      (except as stated in this section) patent license to make, have made,\r\n      use, offer to sell, sell, import, and otherwise transfer the Work,\r\n      where such license applies only to those patent claims licensable\r\n      by such Contributor that are necessarily infringed by their\r\n      Contribution(s) alone or by combination of their Contribution(s)\r\n      with the Work to which such Contribution(s) was submitted. If You\r\n      institute patent litigation against any entity (including a\r\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\r\n      or a Contribution incorporated within the Work constitutes direct\r\n      or contributory patent infringement, then any patent licenses\r\n      granted to You under this License for that Work shall terminate\r\n      as of the date such litigation is filed.\r\n\r\n   4. Redistribution. You may reproduce and distribute copies of the\r\n      Work or Derivative Works thereof in any medium, with or without\r\n      modifications, and in Source or Object form, provided that You\r\n      meet the following conditions:\r\n\r\n      (a) You must give any other recipients of the Work or\r\n          Derivative Works a copy of this License; and\r\n\r\n      (b) You must cause any modified files to carry prominent notices\r\n          stating that You changed the files; and\r\n\r\n      (c) You must retain, in the Source form of any Derivative Works\r\n          that You distribute, all copyright, patent, trademark, and\r\n          attribution notices from the Source form of the Work,\r\n          excluding those notices that do not pertain to any part of\r\n          the Derivative Works; and\r\n\r\n      (d) If the Work includes a \"NOTICE\" text file as part of its\r\n          distribution, then any Derivative Works that You distribute must\r\n          include a readable copy of the attribution notices contained\r\n          within such NOTICE file, excluding those notices that do not\r\n          pertain to any part of the Derivative Works, in at least one\r\n          of the following places: within a NOTICE text file distributed\r\n          as part of the Derivative Works; within the Source form or\r\n          documentation, if provided along with the Derivative Works; or,\r\n          within a display generated by the Derivative Works, if and\r\n          wherever such third-party notices normally appear. The contents\r\n          of the NOTICE file are for informational purposes only and\r\n          do not modify the License. You may add Your own attribution\r\n          notices within Derivative Works that You distribute, alongside\r\n          or as an addendum to the NOTICE text from the Work, provided\r\n          that such additional attribution notices cannot be construed\r\n          as modifying the License.\r\n\r\n      You may add Your own copyright statement to Your modifications and\r\n      may provide additional or different license terms and conditions\r\n      for use, reproduction, or distribution of Your modifications, or\r\n      for any such Derivative Works as a whole, provided Your use,\r\n      reproduction, and distribution of the Work otherwise complies with\r\n      the conditions stated in this License.\r\n\r\n   5. Submission of Contributions. Unless You explicitly state otherwise,\r\n      any Contribution intentionally submitted for inclusion in the Work\r\n      by You to the Licensor shall be under the terms and conditions of\r\n      this License, without any additional terms or conditions.\r\n      Notwithstanding the above, nothing herein shall supersede or modify\r\n      the terms of any separate license agreement you may have executed\r\n      with Licensor regarding such Contributions.\r\n\r\n   6. Trademarks. This License does not grant permission to use the trade\r\n      names, trademarks, service marks, or product names of the Licensor,\r\n      except as required for reasonable and customary use in describing the\r\n      origin of the Work and reproducing the content of the NOTICE file.\r\n\r\n   7. Disclaimer of Warranty. Unless required by applicable law or\r\n      agreed to in writing, Licensor provides the Work (and each\r\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\r\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\r\n      implied, including, without limitation, any warranties or conditions\r\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\r\n      PARTICULAR PURPOSE. You are solely responsible for determining the\r\n      appropriateness of using or redistributing the Work and assume any\r\n      risks associated with Your exercise of permissions under this License.\r\n\r\n   8. Limitation of Liability. In no event and under no legal theory,\r\n      whether in tort (including negligence), contract, or otherwise,\r\n      unless required by applicable law (such as deliberate and grossly\r\n      negligent acts) or agreed to in writing, shall any Contributor be\r\n      liable to You for damages, including any direct, indirect, special,\r\n      incidental, or consequential damages of any character arising as a\r\n      result of this License or out of the use or inability to use the\r\n      Work (including but not limited to damages for loss of goodwill,\r\n      work stoppage, computer failure or malfunction, or any and all\r\n      other commercial damages or losses), even if such Contributor\r\n      has been advised of the possibility of such damages.\r\n\r\n   9. Accepting Warranty or Additional Liability. While redistributing\r\n      the Work or Derivative Works thereof, You may choose to offer,\r\n      and charge a fee for, acceptance of support, warranty, indemnity,\r\n      or other liability obligations and/or rights consistent with this\r\n      License. However, in accepting such obligations, You may act only\r\n      on Your own behalf and on Your sole responsibility, not on behalf\r\n      of any other Contributor, and only if You agree to indemnify,\r\n      defend, and hold each Contributor harmless for any liability\r\n      incurred by, or claims asserted against, such Contributor by reason\r\n      of your accepting any such warranty or additional liability.\r\n\r\n   END OF TERMS AND CONDITIONS\r\n\r\n   APPENDIX: How to apply the Apache License to your work.\r\n\r\n      To apply the Apache License to your work, attach the following\r\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\r\n      replaced with your own identifying information. (Don't include\r\n      the brackets!)  The text should be enclosed in the appropriate\r\n      comment syntax for the file format. We also recommend that a\r\n      file or class name and description of purpose be included on the\r\n      same \"printed page\" as the copyright notice for easier\r\n      identification within third-party archives.\r\n\r\n   Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\r\n\r\n   Licensed under the Apache License, Version 2.0 (the \"License\");\r\n   you may not use this file except in compliance with the License.\r\n   You may obtain a copy of the License at\r\n\r\n       http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n   Unless required by applicable law or agreed to in writing, software\r\n   distributed under the License is distributed on an \"AS IS\" BASIS,\r\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n   See the License for the specific language governing permissions and\r\n   limitations under the License.\r\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 45.3203125,
          "content": "<!--\n===============================================\nvidgear library source-code is deployed under the Apache 2.0 License:\n\nCopyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n===============================================\n-->\n\n<h1 align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/vidgear.png\" alt=\"VidGear\" title=\"Logo designed by Abhishek Thakur(@abhiTronix), under CC-BY-NC-SA 4.0 License\" width=\"80%\"/>\n</h1>\n<h2 align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/tagline.svg\" alt=\"VidGear tagline\" width=\"40%\"/>\n</h2>\n\n<div align=\"center\">\n\n[Releases][release]&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[Gears][gears]&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[Documentation][docs]&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[Installation][installation]&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;[License](#copyright)\n\n[![Build Status][github-cli]][github-flow] [![Codecov branch][codecov]][code] [![Azure DevOps builds (branch)][azure-badge]][azure-pipeline]\n\n[![Glitter chat][gitter-bagde]][gitter] [![Build Status][appveyor]][app] [![PyPi version][pypi-badge]][pypi]\n\n[![Code Style][black-badge]][black]\n\n</div>\n\n&nbsp;\n\nVidGear is a **High-Performance Video Processing Python Library** that provides an easy-to-use, highly extensible, thoroughly optimised **Multi-Threaded + Asyncio API Framework** on top of many state-of-the-art specialized libraries like _[OpenCV][opencv], [FFmpeg][ffmpeg], [ZeroMQ][zmq], [picamera2][picamera2], [starlette][starlette], [yt_dlp][yt_dlp], [pyscreenshot][pyscreenshot], [dxcam][dxcam], [aiortc][aiortc] and [python-mss][mss]_ serving at its backend, and enable us to flexibly exploit their internal parameters and methods, while silently delivering **robust error-handling and real-time performance 🔥**\n\nVidGear primarily focuses on simplicity, and thereby lets programmers and software developers to easily integrate and perform Complex Video Processing Tasks, in just a few lines of code.\n\n&nbsp;\n\nThe following **functional block diagram** clearly depicts the generalized functioning of VidGear APIs:\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/gears_fbd.png\" alt=\"@Vidgear Functional Block Diagram\" />\n</p>\n\n&nbsp;\n\n# Table of Contents\n\n- [**TL;DR**](#tldr)\n- [**Getting Started**](#getting-started)\n- [**Gears: What are these?**](#gears-what-are-these)\n  - [**CamGear**](#camgear)\n  - [**PiGear**](#pigear)\n  - [**VideoGear**](#videogear)\n  - [**ScreenGear**](#screengear)\n  - [**WriteGear**](#writegear)\n  - [**StreamGear**](#streamgear)\n  - [**NetGear**](#netgear)\n  - [**WebGear**](#webgear)\n  - [**WebGear_RTC**](#webgear_rtc)\n  - [**NetGear_Async**](#netgear_async)\n- [**Contributions**](#contributions)\n- [**Donations**](#donations)\n- [**Citation**](#citation)\n- [**Copyright**](#copyright)\n\n&nbsp;\n\n&nbsp;\n\n## TL;DR\n\n#### What is vidgear?\n\n> _\"VidGear is a cross-platform High-Performance Framework that provides an one-stop **Video-Processing** solution for building complex real-time media applications in python.\"_\n\n#### What does it do?\n\n> _\"VidGear can read, write, process, send & receive video files/frames/streams from/to various devices in real-time, and [**faster**][tqm-doc] than underline libraries.\"_\n\n#### What is its purpose?\n\n> _\"Write Less and Accomplish More\"_ — **VidGear's Motto**\n\n> _\"Built with simplicity in mind, VidGear lets programmers and software developers to easily integrate and perform **Complex Video-Processing Tasks** in their existing or newer applications without going through hefty documentation and in just a [**few lines of code**][switch_from_cv]. Beneficial for both, if you're new to programming with Python language or already a pro at it.\"_\n\n&nbsp;\n\n&nbsp;\n\n## Getting Started\n\nIf this is your first time using VidGear, head straight to the [Installation ➶][installation] to install VidGear.\n\nOnce you have VidGear installed, **Checkout its Well-Documented [Function-Specific Gears ➶][gears]**\n\nAlso, if you're already familiar with [OpenCV][opencv] library, then see [Switching from OpenCV Library ➶][switch_from_cv]\n\nOr, if you're just getting started with OpenCV-Python programming, then refer this [FAQ ➶](https://abhitronix.github.io/vidgear/latest/help/general_faqs/#im-new-to-python-programming-or-its-usage-in-opencv-library-how-to-use-vidgear-in-my-projects)\n\n&nbsp;\n\n&nbsp;\n\n## Gears: What are these?\n\n> **VidGear is built with multiple APIs a.k.a [Gears][gears], each with some unique functionality.**\n\nEach API is designed exclusively to handle/control/process different data-specific & device-specific video streams, network streams, and media encoders/decoders. These APIs provides the user an easy-to-use, dynamic, extensible, and exposed Multi-Threaded + Asyncio optimized internal layer above state-of-the-art libraries to work with, while silently delivering robust error-handling.\n\n**These Gears can be classified as follows:**\n\n**A. Video-Capture Gears:**\n\n- [**CamGear:**](#camgear) Multi-Threaded API targeting various IP-USB-Cameras/Network-Streams/Streaming-Sites-URLs.\n- [**PiGear:**](#pigear) Multi-Threaded API targeting various Camera Modules and _(limited)_ USB cameras on Raspberry Pis :grapes:.\n- [**ScreenGear:**](#screengear) High-performance API targeting rapid Screencasting Capabilities.\n- [**VideoGear:**](#videogear) Common Video-Capture API with internal [Video Stabilizer](https://abhitronix.github.io/vidgear/latest/gears/stabilizer/overview/) wrapper.\n\n**B. Video-Writer Gears:**\n\n- [**WriteGear:**](#writegear) Handles Lossless Video-Writer for file/stream/frames Encoding and Compression.\n\n**C. Streaming Gears:**\n\n- [**StreamGear**](#streamgear): Handles Transcoding of High-Quality, Dynamic & Adaptive Streaming Formats.\n\n- **Asynchronous I/O Streaming Gear:**\n\n  - [**WebGear:**](#webgear) ASGI Video-Server that broadcasts Live MJPEG-Frames to any web-browser on the network.\n  - [**WebGear_RTC:**](#webgear_rtc) Real-time Asyncio WebRTC media server for streaming directly to peer clients over the network.\n\n**D. Network Gears:**\n\n- [**NetGear:**](#netgear) Handles High-Performance Video-Frames & Data Transfer between interconnecting systems over the network.\n\n- **Asynchronous I/O Network Gear:**\n\n  - [**NetGear_Async:**](#netgear_async) Immensely Memory-Efficient Asyncio Video-Frames Network Messaging Framework.\n\n&nbsp;\n\n&nbsp;\n\n## CamGear\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/camgear.png\" alt=\"CamGear Functional Block Diagram\" width=\"45%\"/>\n</p>\n\n> _CamGear can grab ultra-fast frames from a diverse range of file-formats/devices/streams, which includes almost any IP-USB Cameras, multimedia video file-formats ([*upto 4k tested*][test-4k]), various network stream protocols such as `http(s), rtp, rtsp, rtmp, mms, etc.`, and GStreamer's pipelines, plus direct support for live video streaming sites like YouTube, Twitch, LiveStream, Dailymotion etc._\n\nCamGear provides a flexible, high-level, multi-threaded framework around OpenCV's [VideoCapture class][opencv-vc] with access almost all of its available parameters. CamGear internally implements [`yt_dlp`][yt_dlp] backend class for seamlessly pipelining live video-frames and metadata from various streaming services like [YouTube][youtube-doc], [Twitch][piping-live-videos], and [many more ➶](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md#supported-sites). Furthermore, its framework relies exclusively on [**Threaded Queue mode**][tqm-doc] for ultra-fast, error-free, and synchronized video-frame handling.\n\n### CamGear API Guide:\n\n[**>>> Usage Guide**][camgear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## VideoGear\n\n> _VideoGear API provides a special internal wrapper around VidGear's exclusive [**Video Stabilizer**][stabilizer-doc] class._\n\nVideoGear also acts as a Common Video-Capture API that provides internal access for both [CamGear](#camgear) and [PiGear](#pigear) APIs and their parameters with an exclusive `enablePiCamera` boolean flag.\n\nVideoGear is ideal when you need to switch to different video sources without changing your code much. Also, it enables easy stabilization for various video-streams _(real-time or not)_ with minimum effort and writing way fewer lines of code.\n\n**Below is a snapshot of a VideoGear Stabilizer in action (_See its detailed usage [here][stabilizer-doc-ex]_):**\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/34266896/211500670-b3aaf4db-a52a-4836-a03c-c2c17b971feb.gif\" alt=\"VideoGear Stabilizer in action!\"/>\n  <br>\n  <sub><i>Original Video Courtesy <a href=\"http://liushuaicheng.org/SIGGRAPH2013/database.html\" title=\"opensourced video samples database\">@SIGGRAPH2013</a></i></sub>\n</p>\n\n**Code to generate above result:**\n\n```python\n# import required libraries\nfrom vidgear.gears import VideoGear\nimport numpy as np\nimport cv2\n\n# open any valid video stream with stabilization enabled(`stabilize = True`)\nstream_stab = VideoGear(source=\"test.mp4\", stabilize=True).start()\n\n# open same stream without stabilization for comparison\nstream_org = VideoGear(source=\"test.mp4\").start()\n\n# loop over\nwhile True:\n\n    # read stabilized frames\n    frame_stab = stream_stab.read()\n\n    # check for stabilized frame if Nonetype\n    if frame_stab is None:\n        break\n\n    # read un-stabilized frame\n    frame_org = stream_org.read()\n\n    # concatenate both frames\n    output_frame = np.concatenate((frame_org, frame_stab), axis=1)\n\n    # put text over concatenated frame\n    cv2.putText(\n        output_frame,\n        \"Before\",\n        (10, output_frame.shape[0] - 10),\n        cv2.FONT_HERSHEY_SIMPLEX,\n        0.6,\n        (0, 255, 0),\n        2,\n    )\n    cv2.putText(\n        output_frame,\n        \"After\",\n        (output_frame.shape[1] // 2 + 10, output_frame.shape[0] - 10),\n        cv2.FONT_HERSHEY_SIMPLEX,\n        0.6,\n        (0, 255, 0),\n        2,\n    )\n\n    # Show output window\n    cv2.imshow(\"Stabilized Frame\", output_frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) & 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close both video streams\nstream_org.stop()\nstream_stab.stop()\n```\n\n### VideoGear API Guide:\n\n[**>>> Usage Guide**][videogear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## PiGear\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/picam2.webp\" alt=\"PiGear\" width=\"50%\" />\n</p>\n\n> _PiGear is a specialized API similar to the [CamGear API](#camgear) but optimized for **Raspberry Pi :grapes: Boards**, offering comprehensive **support for camera modules** _(e.g., [OmniVision OV5647 Camera Module][ov5647-picam], [Sony IMX219 Camera Module][imx219-picam])_, along with **limited compatibility for USB cameras**._\n\nPiGear implements a seamless and robust wrapper around the [picamera2][picamera2] python library, simplifying integration with minimal code changes and ensuring a smooth transition for developers already familiar with the Picamera2 API. PiGear leverages the `libcamera` API under the hood with multi-threading, providing high-performance :fire:, enhanced control and functionality for Raspberry Pi camera modules. \n\nPiGear handles common configuration parameters and non-standard settings for various camera types, simplifying the integration process. PiGear currently supports PiCamera2 API parameters such as `sensor`, `controls`, `transform`, and `format` etc., with internal type and sanity checks for robust performance.\n\nWhile primarily focused on Raspberry Pi camera modules, PiGear also provides **basic functionality for USB webcams** only with Picamera2 API, along with the ability to accurately differentiate between USB and Raspberry Pi cameras using metadata. \n\nPiGear seamlessly switches to the legacy [picamera][picamera] library if the `picamera2` library is unavailable, ensuring seamless backward compatibility. For this, PiGear also provides a flexible multi-threaded framework around complete `picamera` API, allowing developers to effortlessly exploit a wide range of parameters, such as `brightness`, `saturation`, `sensor_mode`, `iso`, `exposure`, and more. \n\nFurthermore, PiGear supports the use of multiple camera modules, including those found on Raspberry Pi Compute Module IO boards and USB cameras _(only with Picamera2 API)_.\n\nBest of all, PiGear contains **Threaded Internal Timer** - that silently keeps active track of any frozen-threads/hardware-failures and exit safely, if any does occur. That means that if you're running PiGear API in your script and someone accidentally pulls the Camera-Module cable out, instead of going into possible kernel panic, API will exit safely to save resources.\n\n**Code to open picamera2 stream with variable parameters in PiGear API:**\n\n```python\n# import required libraries\nfrom vidgear.gears import PiGear\nfrom libcamera import Transform\nimport cv2\n\n# formulate various Picamera2 API \n# configurational parameters\noptions = {\n    \"controls\": {\"Brightness\": 0.5, \"ExposureValue\": 2.0},\n    \"transform\": Transform(hflip=1),\n    \"sensor\": {\"output_size\": (480, 320)},  # will override `resolution`\n    \"format\": \"RGB888\", # 8-bit BGR\n}\n\n# open pi video stream with defined parameters\nstream = PiGear(resolution=(640, 480), framerate=60, logging=True, **options).start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) & 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n```\n\n### PiGear API Guide:\n\n[**>>> Usage Guide**][pigear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## ScreenGear\n\n> _ScreenGear is designed exclusively for targeting rapid Screencasting Capabilities, which means it can grab frames from your monitor in real-time, either by defining an area on the computer screen or full-screen, at the expense of inconsiderable latency. ScreenGear also seamlessly support frame capturing from multiple monitors as well as supports multiple backends._\n\nScreenGear implements a Lightning-Fast API wrapper around [**dxcam**][dxcam], [**pyscreenshot**][pyscreenshot] & [**python-mss**][mss] python libraries and also supports an easy and flexible direct internal parameters manipulation.\n\n**Below is a snapshot of a ScreenGear API in action:**\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/gifs/screengear.gif\" alt=\"ScreenGear in action!\"/>\n</p>\n\n**Code to generate the above results:**\n\n```python\n# import required libraries\nfrom vidgear.gears import ScreenGear\nimport cv2\n\n# open video stream with default parameters\nstream = ScreenGear().start()\n\n# loop over\nwhile True:\n\n    # read frames from stream\n    frame = stream.read()\n\n    # check for frame if Nonetype\n    if frame is None:\n        break\n\n    # {do something with the frame here}\n\n    # Show output window\n    cv2.imshow(\"Output Frame\", frame)\n\n    # check for 'q' key if pressed\n    key = cv2.waitKey(1) & 0xFF\n    if key == ord(\"q\"):\n        break\n\n# close output window\ncv2.destroyAllWindows()\n\n# safely close video stream\nstream.stop()\n```\n\n### ScreenGear API Guide:\n\n[**>>> Usage Guide**][screengear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## WriteGear\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/writegear.png\" alt=\"WriteGear Functional Block Diagram\" width=\"70%\" />\n</p>\n\n> _WriteGear handles various powerful Video-Writer Tools that provide us the freedom to do almost anything imaginable with multimedia data._\n\nWriteGear API provides a complete, flexible, and robust wrapper around [**FFmpeg**][ffmpeg], a leading multimedia framework. WriteGear can process real-time frames into a lossless compressed video-file with any suitable specifications _(such as`bitrate, codec, framerate, resolution, subtitles,  etc.`)_.\n\nWriteGear also supports streaming with traditional protocols such as [RTSP/RTP][rtsp-ex], RTMP. It is powerful enough to perform complex tasks such as [Live-Streaming][live-stream] _(such as for Twitch, YouTube etc.)_ and [Multiplexing Video-Audio][live-audio-doc] with real-time frames in just few lines of code.\n\nBest of all, WriteGear grants users the complete freedom to play with any FFmpeg parameter with its exclusive **Custom Commands function** _(see this [doc][custom-command-doc])_ without relying on any third-party API.\n\nIn addition to this, WriteGear also provides flexible access to [**OpenCV's VideoWriter API**][opencv-writer] tools for video-frames encoding without compression.\n\n**WriteGear primarily operates in the following two modes:**\n\n- **Compression Mode:** In this mode, WriteGear utilizes powerful [**FFmpeg**][ffmpeg] inbuilt encoders to encode lossless multimedia files. This mode provides us the ability to exploit almost any parameter available within FFmpeg, effortlessly and flexibly, and while doing that it robustly handles all errors/warnings quietly. **You can find more about this mode [here ➶][cm-writegear-doc]**\n\n- **Non-Compression Mode:** In this mode, WriteGear utilizes basic [**OpenCV's inbuilt VideoWriter API**][opencv-vw] tools. This mode also supports all parameter transformations available within OpenCV's VideoWriter API, but it lacks the ability to manipulate encoding parameters and other important features like video compression, audio encoding, etc. **You can learn about this mode [here ➶][ncm-writegear-doc]**\n\n### WriteGear API Guide:\n\n[**>>> Usage Guide**][writegear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## StreamGear\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/streamgear_flow.webp\" alt=\"NetGear API\" width=80%/>\n</p>\n\n> _StreamGear streamlines and simplifies the transcoding workflow to generate Ultra-Low Latency, High-Quality, Dynamic & Adaptive Streaming Formats like MPEG-DASH and Apple HLS with just a few lines of Python code, allowing developers to focus on their application logic rather than dealing with the complexities of transcoding and chunking media files._\n\nStreamGear API provides a standalone, highly extensible, and flexible wrapper around the [**FFmpeg**](https://ffmpeg.org/) multimedia framework for generating chunk-encoded media segments from your multimedia content effortlessly.\n\nWith StreamGear, you can transcode source video/audio files and real-time video frames into a sequence of multiple smaller chunks/segments of suitable lengths. These segments facilitate streaming at different quality levels _(bitrates or spatial resolutions)_ and allow for seamless switching between quality levels during playback based on available bandwidth. You can serve these segments on a web server, making them easily accessible via standard **HTTP GET** requests.\n\nSteamGear currently supports both [**MPEG-DASH**](https://www.encoding.com/mpeg-dash/) _(Dynamic Adaptive Streaming over HTTP, ISO/IEC 23009-1)_  and [**Apple HLS**](https://developer.apple.com/documentation/http_live_streaming) _(HTTP Live Streaming)_. \n\nAdditionally, StreamGear generates a manifest file _(such as MPD for DASH)_ or a master playlist _(such as M3U8 for Apple HLS)_ alongside the segments. These files contain essential segment information, _including timing, URLs, and media characteristics like video resolution and adaptive bitrates_. They are provided to the client before the streaming session begins.\n\n**StreamGear primarily works in two Independent Modes for transcoding which serves different purposes:**\n\n- **Single-Source Mode 💿 :** In this mode, StreamGear **transcodes entire video file** _(as opposed to frame-by-frame)_ into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you're transcoding long-duration lossless videos(with audio) for streaming that required no interruptions. But on the downside, the provided source cannot be flexibly manipulated or transformed before sending onto FFmpeg Pipeline for processing. **_Learn more about this mode [here ➶][ss-mode-doc]_**\n\n- **Real-time Frames Mode 🎞️ :** In this mode, StreamGear directly **transcodes frame-by-frame** _(as opposed to a entire video file)_, into a sequence of multiple smaller chunks/segments for streaming. This mode works exceptionally well when you desire to flexibility manipulate or transform [`numpy.ndarray`](https://numpy.org/doc/1.18/reference/generated/numpy.ndarray.html#numpy-ndarray) frames in real-time before sending them onto FFmpeg Pipeline for processing. But on the downside, audio has to added manually _(as separate source)_ for streams. **_Learn more about this mode [here ➶][rtf-mode-doc]_**\n\n### StreamGear API Guide:\n\n[**>>> Usage Guide**][streamgear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## NetGear\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/netgear.png\" alt=\"NetGear API\" width=65%/>\n</p>\n\n> _NetGear is exclusively designed to transfer video-frames & data synchronously between interconnecting systems over the network in real-time._\n\nNetGear implements a high-level wrapper around [**PyZmQ**][pyzmq] python library that contains python bindings for [**ZeroMQ**][zmq] - a high-performance asynchronous distributed messaging library.\n\nNetGear seamlessly supports additional [**bidirectional data transmission**][netgear_bidata_doc] between receiver(client) and sender(server) while transferring video-frames all in real-time.\n\nNetGear can also robustly handle [**Multiple Server-Systems**][netgear_multi_server_doc] and [**Multiple Client-Systems**][netgear_multi_client_doc] and at once, thereby providing access to a seamless exchange of video-frames & data between multiple devices across the network at the same time.\n\nNetGear allows remote connection over [**SSH Tunnel**][netgear_sshtunnel_doc] that allows us to connect NetGear client and server via secure SSH connection over the untrusted network and access its intranet services across firewalls.\n\nNetGear also enables real-time [**JPEG Frame Compression**][netgear_compression_doc] capabilities for boosting performance significantly while sending video-frames over the network in real-time.\n\nFor security, NetGear implements easy access to ZeroMQ's powerful, smart & secure Security Layers that enable [**Strong encryption on data**][netgear_security_doc] and unbreakable authentication between the Server and the Client with the help of custom certificates.\n\n**NetGear as of now seamlessly supports three ZeroMQ messaging patterns:**\n\n- [**`zmq.PAIR`**][zmq-pair] _(ZMQ Pair Pattern)_\n- [**`zmq.REQ/zmq.REP`**][zmq-req-rep] _(ZMQ Request/Reply Pattern)_\n- [**`zmq.PUB/zmq.SUB`**][zmq-pub-sub] _(ZMQ Publish/Subscribe Pattern)_\n\nWhereas supported protocol are: `tcp` and `ipc`.\n\n### NetGear API Guide:\n\n[**>>> Usage Guide**][netgear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## WebGear\n\n> _WebGear is a powerful [ASGI](https://asgi.readthedocs.io/en/latest/) Video-Broadcaster API ideal for transmitting [Motion-JPEG](https://en.wikipedia.org/wiki/Motion_JPEG)-frames from a single source to multiple recipients via the browser._\n\nWebGear API works on [**Starlette**](https://www.starlette.io/)'s ASGI application and provides a highly extensible and flexible async wrapper around its complete framework. WebGear can flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, [Response classes](https://www.starlette.io/responses/), [Routing tables](https://www.starlette.io/routing/), [Static Files](https://www.starlette.io/staticfiles/), [Templating engine(with Jinja2)](https://www.starlette.io/templates/), etc.\n\nWebGear API uses an intraframe-only compression scheme under the hood where the sequence of video-frames are first encoded as JPEG-DIB (JPEG with Device-Independent Bit compression) and then streamed over HTTP using Starlette's Multipart [Streaming Response](https://www.starlette.io/responses/#streamingresponse) and a [Uvicorn](https://www.uvicorn.org/#quickstart) ASGI Server. This method imposes lower processing and memory requirements, but the quality is not the best, since JPEG compression is not very efficient for motion video.\n\nIn layman's terms, WebGear acts as a powerful **Video Broadcaster** that transmits live video-frames to any web-browser in the network. Additionally, WebGear API also provides a special internal wrapper around [VideoGear](#videogear), which itself provides internal access to both [CamGear](#camgear) and [PiGear](#pigear) APIs, thereby granting it exclusive power of broadcasting frames from any incoming stream. It also allows us to define our custom Server as source to transform frames easily before sending them across the network(see this [doc][webgear-cs] example).\n\n**Below is a snapshot of a WebGear Video Server in action on Chrome browser:**\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/34266896/211500287-0c12bfdf-2cbb-417a-9f3c-7a8b03ca5b6a.gif\" alt=\"WebGear in action!\" width=\"80%\" />\n  <br>\n  <sub><i>WebGear Video Server at <a href=\"http://localhost:8000/\" title=\"default address\">http://localhost:8000/</a> address.</i></sub>\n</p>\n\n**Code to generate the above result:**\n\n```python\n# import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 40,\n    \"jpeg_compression_quality\": 80,\n    \"jpeg_compression_fastdct\": True,\n    \"jpeg_compression_fastupsample\": False,\n}\n\n# initialize WebGear app\nweb = WebGear(source=\"foo.mp4\", logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n```\n\n### WebGear API Guide:\n\n[**>>> Usage Guide**][webgear-doc]\n\n&nbsp;\n\n&nbsp;\n\n## WebGear_RTC\n\n> _WebGear_RTC is similar to [WeGear API](#webgear) in many aspects but utilizes [WebRTC][webrtc] technology under the hood instead of Motion JPEG, which makes it suitable for building powerful video-streaming solutions for all modern browsers as well as native clients available on all major platforms._\n\nWebGear_RTC is implemented with the help of [**aiortc**][aiortc] library which is built on top of asynchronous I/O framework for Web Real-Time Communication (WebRTC) and Object Real-Time Communication (ORTC) and supports many features like SDP generation/parsing, Interactive Connectivity Establishment with half-trickle and mDNS support, DTLS key and certificate generation, DTLS handshake, etc.\n\nWebGear_RTC can handle [multiple consumers][webgear_rtc-mc] seamlessly and provides native support for ICE _(Interactive Connectivity Establishment)_ protocol, STUN _(Session Traversal Utilities for NAT)_, and TURN _(Traversal Using Relays around NAT)_ servers that help us to seamlessly establish direct media connection with the remote peers for uninterrupted data flow. It also allows us to define our custom streaming class with suitable source to transform frames easily before sending them across the network(see this [doc][webgear_rtc-cs] example).\n\nWebGear_RTC API works in conjunction with [**Starlette**][starlette]'s ASGI application and provides easy access to its complete framework. WebGear_RTC can also flexibly interact with Starlette's ecosystem of shared middleware, mountable applications, [Response classes](https://www.starlette.io/responses/), [Routing tables](https://www.starlette.io/routing/), [Static Files](https://www.starlette.io/staticfiles/), [Templating engine(with Jinja2)](https://www.starlette.io/templates/), etc.\n\nAdditionally, WebGear_RTC API also provides a special internal wrapper around [VideoGear](#videogear), which itself provides internal access to both [CamGear](#camgear) and [PiGear](#pigear) APIs.\n\n**Below is a snapshot of a WebGear_RTC Media Server in action on Chrome browser:**\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/34266896/211502451-6dc1fb24-2472-4e95-b38e-cab252071cc7.gif\" alt=\"WebGear_RTC in action!\" width=\"80%\" />\n  <br>\n  <sub><i>WebGear_RTC Video Server at <a href=\"http://localhost:8000/\" title=\"default address\">http://localhost:8000/</a> address.</i></sub>\n</p>\n\n**Code to generate the above result:**\n\n```python\n# import required libraries\nimport uvicorn\nfrom vidgear.gears.asyncio import WebGear_RTC\n\n# various performance tweaks\noptions = {\n    \"frame_size_reduction\": 30,\n}\n\n# initialize WebGear_RTC app\nweb = WebGear_RTC(source=\"foo.mp4\", logging=True, **options)\n\n# run this app on Uvicorn server at address http://localhost:8000/\nuvicorn.run(web(), host=\"localhost\", port=8000)\n\n# close app safely\nweb.shutdown()\n```\n\n### WebGear_RTC API Guide:\n\n[**>>> Usage Guide**][webgear_rtc-doc]\n\n&nbsp;\n\n&nbsp;\n\n## NetGear_Async\n\n<p align=\"center\">\n  <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/zmq_asyncio.png\" alt=\"WebGear in action!\" width=\"70%\"/>\n</p>\n.\n\n> _NetGear_Async can generate the same performance as [NetGear API](#netgear) at about one-third the memory consumption, and also provide complete server-client handling with various options to use variable protocols/patterns similar to NetGear, but lacks in term of flexibility as it supports only a few [NetGear's Exclusive Modes][netgear-exm]._\n\nNetGear_Async is built on [`zmq.asyncio`][asyncio-zmq], and powered by a high-performance asyncio event loop called [**`uvloop`**][uvloop] to achieve unmatchable high-speed and lag-free video streaming over the network with minimal resource constraints. NetGear_Async can transfer thousands of frames in just a few seconds without causing any significant load on your system.\n\nNetGear_Async provides complete server-client handling and options to use variable protocols/patterns similar to [NetGear API](#netgear). Furthermore, NetGear_Async allows us to define our custom Server as source to transform frames easily before sending them across the network(see this [doc][netgear_async-cs] example).\n\nNetGear_Async now supports additional [**bidirectional data transmission**][btm_netgear_async] between receiver(client) and sender(server) while transferring video-frames. Users can easily build complex applications such as like [Real-Time Video Chat][rtvc] in just few lines of code.\n\nNetGear_Async as of now supports all four ZeroMQ messaging patterns:\n\n- [**`zmq.PAIR`**][zmq-pair] _(ZMQ Pair Pattern)_\n- [**`zmq.REQ/zmq.REP`**][zmq-req-rep] _(ZMQ Request/Reply Pattern)_\n- [**`zmq.PUB/zmq.SUB`**][zmq-pub-sub] _(ZMQ Publish/Subscribe Pattern)_\n- [**`zmq.PUSH/zmq.PULL`**][zmq-pull-push] _(ZMQ Push/Pull Pattern)_\n\nWhereas supported protocol are: `tcp` and `ipc`.\n\n### NetGear_Async API Guide:\n\n[**>>> Usage Guide**][netgear_async-doc]\n\n&nbsp;\n\n&nbsp;\n\n# Contributions\n\n<div align=\"center\">\n   <h3>👑 Contributor Hall of Fame 👑</h3><br>\n   <a href=\"https://github.com/abhiTronix/vidgear/graphs/contributors\">\n    <img src=\"https://contributors-img.web.app/image?repo=abhiTronix/vidgear\"/><br><br>\n  </a>\n  <p><i>We're happy to meet new contributors💗</i></p><br>\n</div>\n\nWe welcome your contributions to help us improve and extend this project. If you want to get involved with VidGear development, checkout the **[Contribution Guidelines ▶️][contribute]**\n\nWe're offering support for VidGear on [**Gitter Community Channel**](https://gitter.im/vidgear/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge). Come and join the conversation over there!\n\n&nbsp;\n\n&nbsp;\n\n# Donations\n\n<div align=\"center\">\n   <img src=\"https://abhitronix.github.io/vidgear/latest/assets/images/help_us.png\" alt=\"PiGear\" width=\"50%\" />\n   <p><i>VidGear is free and open source and will always remain so. ❤️</i></p>\n</div>\n\nIt is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference 🙂\n\n<a href='https://ko-fi.com/W7W8WTYO' target='_blank'><img height='36' style='border:0px;height:36px;' src='https://cdn.ko-fi.com/cdn/kofi1.png?v=3' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>\n\n&nbsp;\n\n&nbsp;\n\n# Citation\n\nHere is a Bibtex entry you can use to cite this project in a publication:\n\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.8332548.svg)](https://doi.org/10.5281/zenodo.8332548)\n\n```BibTeX\n@software{vidgear,\n  author       = {Abhishek Thakur and\n                  Zoe Papakipos and\n                  Christian Clauss and\n                  Christian Hollinger and\n                  Ian Max Andolina and\n                  Vincent Boivin and\n                  Kyle Ahn and\n                  freol35241 and\n                  Benjamin Lowe and\n                  Mickaël Schoentgen and\n                  Renaud Bouckenooghe and\n                  Ibtsam Ahmad},\n  title        = {abhiTronix/vidgear: VidGear Stable v0.3.2},\n  month        = sep,\n  year         = 2023,\n  publisher    = {Zenodo},\n  version      = {vidgear-0.3.2},\n  doi          = {10.5281/zenodo.8332548},\n  url          = {https://doi.org/10.5281/zenodo.8332548}\n}\n```\n\n&nbsp;\n\n&nbsp;\n\n# Copyright\n\n**Copyright © abhiTronix 2019**\n\nThis library is released under the **[Apache 2.0 License][license]**.\n\n<!--\nBadges\n-->\n\n[appveyor]: https://img.shields.io/appveyor/ci/abhitronix/vidgear.svg?style=for-the-badge&logo=appveyor\n[codecov]: https://img.shields.io/codecov/c/github/abhiTronix/vidgear/testing?logo=codecov&style=for-the-badge\n[github-cli]: https://img.shields.io/github/actions/workflow/status/abhiTronix/vidgear/.github/workflows/ci_linux.yml?style=for-the-badge&logo=data:image/svg%2bxml;base64,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\n[prs-badge]: https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=for-the-badge&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAABC0lEQVRYhdWVPQoCMRCFX6HY2ghaiZUXsLW0EDyBrbWtN/EUHsHTWFnYyCL4gxibVZZlZzKTnWz0QZpk5r0vIdkF/kBPAMOKeddE+CQPKoc5Yt5cTjBMdQSwDQToWgBJAn3jmhqgltapAV6E6b5U17MGGAUaUj07TficMfIBZDV6vxowBm1BP9WbSQE4o5h9IjPJmy73TEPDDxVmoZdQrQ5jRhly9Q8tgMUXkIIWn0oG4GYQfAXQzz1PGoCiQndM7b4RgJay/h7zBLT3hASgoKjamQJMreKf0gfuAGyYtXEIAKcL/Dss15iq6ohXghozLYiAMxPuACwtIT4yeQUxAaLrZwAoqGRKGk7qDSYTfYQ8LuYnAAAAAElFTkSuQmCC\n[twitter-badge]: https://img.shields.io/badge/Tweet-Now-blue.svg?style=for-the-badge&logo=twitter\n[azure-badge]: https://img.shields.io/azure-devops/build/abhiuna12/942b3b13-d745-49e9-8d7d-b3918ff43ac2/2/testing?logo=azure-pipelines&style=for-the-badge\n[pypi-badge]: https://img.shields.io/pypi/v/vidgear.svg?style=for-the-badge&logo=pypi\n[gitter-bagde]: https://img.shields.io/badge/Chat-Gitter-blueviolet.svg?style=for-the-badge&logo=gitter\n[coffee-badge]: https://abhitronix.github.io/img/vidgear/orange_img.png\n[kofi-badge]: https://www.ko-fi.com/img/githubbutton_sm.svg\n[black-badge]: https://img.shields.io/badge/code%20style-black-000000.svg?style=for-the-badge&logo=github\n\n<!--\nInternal URLs\n-->\n\n[release]: https://github.com/abhiTronix/vidgear/releases/latest\n[pypi]: https://pypi.org/project/vidgear/\n[gitter]: https://gitter.im/vidgear/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge\n[twitter-intent]: https://twitter.com/intent/tweet?url=https%3A%2F%2Fabhitronix.github.io%2Fvidgear&via%20%40abhi_una12&text=Checkout%20VidGear%20-%20A%20High-Performance%20Video-Processing%20Python%20Framework.&hashtags=vidgear%20%23videoprocessing%20%23python%20%23threaded%20%23asyncio\n[coffee]: https://www.buymeacoffee.com/2twOXFvlA\n[kofi]: https://ko-fi.com/W7W8WTYO\n[license]: https://github.com/abhiTronix/vidgear/blob/master/LICENSE\n[github-flow]: https://github.com/abhiTronix/vidgear/actions?query=workflow%3A%22Run+Linux+CI-Tests+for+vidgear%22\n[azure-pipeline]: https://dev.azure.com/abhiuna12/public/_build?definitionId=2\n[app]: https://ci.appveyor.com/project/abhiTronix/vidgear\n[code]: https://codecov.io/gh/abhiTronix/vidgear\n[btm_netgear_async]: https://abhitronix.github.io/vidgear/latest/gears/netgear_async/advanced/bidirectional_mode/\n[rtvc]: https://abhitronix.github.io/vidgear/latest/gears/netgear_async/advanced/bidirectional_mode/#using-bidirectional-mode-for-video-frames-transfer\n[test-4k]: https://github.com/abhiTronix/vidgear/blob/e0843720202b0921d1c26e2ce5b11fadefbec892/vidgear/tests/benchmark_tests/test_benchmark_playback.py#L65\n[bs_script_dataset]: https://github.com/abhiTronix/vidgear/blob/testing/scripts/bash/prepare_dataset.sh\n[faq]: https://abhitronix.github.io/vidgear/latest/help/get_help/#frequently-asked-questions\n[contribute]: https://abhitronix.github.io/vidgear/latest/contribution\n[rtsp-ex]: https://abhitronix.github.io/vidgear/latest/help/writegear_ex/#using-writegears-compression-mode-for-rtsprtp-live-streaming\n[doc-vidgear-purpose]: https://abhitronix.github.io/vidgear/latest/help/motivation/#why-is-vidgear-a-thing\n[live-stream]: https://abhitronix.github.io/vidgear/latest/gears/writegear/compression/usage/#using-compression-mode-for-live-streaming\n[live-audio-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/compression/usage/#using-compression-mode-with-live-audio-input\n[piping-live-videos]: https://abhitronix.github.io/vidgear/latest/gears/camgear/usage/#using-camgear-with-streaming-websites\n[ffmpeg-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/compression/advanced/ffmpeg_install/\n[youtube-doc]: https://abhitronix.github.io/vidgear/latest/gears/camgear/usage/#using-camgear-with-youtube-videos\n[tqm-doc]: https://abhitronix.github.io/vidgear/latest/bonus/TQM/#threaded-queue-mode\n[camgear-doc]: https://abhitronix.github.io/vidgear/latest/gears/camgear/overview/\n[stabilizer-doc]: https://abhitronix.github.io/vidgear/latest/gears/stabilizer/overview/\n[stabilizer-doc-ex]: https://abhitronix.github.io/vidgear/latest/gears/videogear/usage/#using-videogear-with-video-stabilizer-backend\n[videogear-doc]: https://abhitronix.github.io/vidgear/latest/gears/videogear/overview/\n[pigear-doc]: https://abhitronix.github.io/vidgear/latest/gears/pigear/overview/\n[cm-writegear-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/compression/overview/\n[ncm-writegear-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/non_compression/overview/\n[screengear-doc]: https://abhitronix.github.io/vidgear/latest/gears/screengear/overview/\n[streamgear-doc]: https://abhitronix.github.io/vidgear/latest/gears/streamgear/introduction/\n[writegear-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/introduction/\n[netgear-doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/overview/\n[webgear-doc]: https://abhitronix.github.io/vidgear/latest/gears/webgear/overview/\n[webgear_rtc-doc]: https://abhitronix.github.io/vidgear/latest/gears/webgear_rtc/overview/\n[netgear_async-doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear_async/overview/\n[drop35]: https://github.com/abhiTronix/vidgear/issues/99\n[custom-command-doc]: https://abhitronix.github.io/vidgear/latest/gears/writegear/compression/advanced/cciw/\n[advanced-webgear-doc]: https://abhitronix.github.io/vidgear/latest/gears/webgear/advanced/\n[netgear_bidata_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/bidirectional_mode/\n[netgear_compression_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/compression/\n[netgear_security_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/secure_mode/\n[netgear_multi_server_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/multi_server/\n[netgear_multi_client_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/multi_client/\n[netgear_sshtunnel_doc]: https://abhitronix.github.io/vidgear/latest/gears/netgear/advanced/ssh_tunnel/\n[netgear-exm]: https://abhitronix.github.io/vidgear/latest/gears/netgear/overview/#modes-of-operation\n[stabilize_webgear_doc]: https://abhitronix.github.io/vidgear/latest/gears/webgear/advanced/#using-webgear-with-real-time-video-stabilization-enabled\n[netgear_async-cs]: https://abhitronix.github.io/vidgear/latest/gears/netgear_async/usage/#using-netgear_async-with-a-custom-sourceopencv\n[installation]: https://abhitronix.github.io/vidgear/latest/installation/\n[gears]: https://abhitronix.github.io/vidgear/latest/gears\n[switch_from_cv]: https://abhitronix.github.io/vidgear/latest/switch_from_cv/\n[ss-mode-doc]: https://abhitronix.github.io/vidgear/latest/gears/streamgear/ssm/#overview\n[rtf-mode-doc]: https://abhitronix.github.io/vidgear/latest/gears/streamgear/rtfm/#overview\n[webgear-cs]: https://abhitronix.github.io/vidgear/latest/gears/webgear/advanced/#using-webgear-with-a-custom-sourceopencv\n[webgear_rtc-cs]: https://abhitronix.github.io/vidgear/latest/gears/webgear_rtc/advanced/#using-webgear_rtc-with-a-custom-sourceopencv\n[webgear_rtc-mc]: https://abhitronix.github.io/vidgear/latest/gears/webgear_rtc/advanced/#using-webgear_rtc-as-real-time-broadcaster\n[docs]: https://abhitronix.github.io/vidgear\n\n<!--\nExternal URLs\n-->\n\n[asyncio-zmq]: https://pyzmq.readthedocs.io/en/latest/api/zmq.asyncio.html\n[uvloop]: https://github.com/MagicStack/uvloop\n[streamlink]: https://streamlink.github.io/\n[aiortc]: https://aiortc.readthedocs.io/en/latest/\n[pyscreenshot]: https://github.com/ponty/pyscreenshot\n[uvloop-ns]: https://github.com/MagicStack/uvloop/issues/14\n[ffmpeg]: https://www.ffmpeg.org/\n[flake8]: https://flake8.pycqa.org/en/latest/\n[dxcam]: https://github.com/ra1nty/DXcam\n[black]: https://github.com/psf/black\n[pytest]: https://docs.pytest.org/en/latest/\n[opencv-writer]: https://docs.opencv.org/master/dd/d9e/classcv_1_1VideoWriter.html#ad59c61d8881ba2b2da22cff5487465b5\n[opencv-windows]: https://www.learnopencv.com/install-opencv3-on-windows/\n[opencv-linux]: https://www.pyimagesearch.com/2018/05/28/ubuntu-18-04-how-to-install-opencv/\n[opencv-pi]: https://www.pyimagesearch.com/2018/09/26/install-opencv-4-on-your-raspberry-pi/\n[starlette]: https://www.starlette.io/\n[uvicorn]: http://www.uvicorn.org/\n[daphne]: https://github.com/django/daphne/\n[hypercorn]: https://pgjones.gitlab.io/hypercorn/\n[prs]: http://makeapullrequest.com\n[opencv]: https://github.com/opencv/opencv\n[picamera]: https://github.com/waveform80/picamera\n[pafy]: https://github.com/mps-youtube/pafy\n[pyzmq]: https://github.com/zeromq/pyzmq\n[zmq]: https://zeromq.org/\n[mss]: https://github.com/BoboTiG/python-mss\n[pip]: https://pip.pypa.io/en/stable/installing/\n[opencv-vc]: https://docs.opencv.org/master/d8/dfe/classcv_1_1VideoCapture.html#a57c0e81e83e60f36c83027dc2a188e80\n[ov5647-picam]: https://github.com/techyian/MMALSharp/doc/OmniVision-OV5647-Camera-Module\n[imx219-picam]: https://github.com/techyian/MMALSharp/doc/Sony-IMX219-Camera-Module\n[opencv-vw]: https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html\n[yt_dlp]: https://github.com/yt-dlp/yt-dlp\n[numpy]: https://github.com/numpy/numpy\n[zmq-pair]: https://learning-0mq-with-pyzmq.readthedocs.io/en/latest/pyzmq/patterns/pair.html\n[zmq-req-rep]: https://learning-0mq-with-pyzmq.readthedocs.io/en/latest/pyzmq/patterns/client_server.html\n[zmq-pub-sub]: https://learning-0mq-with-pyzmq.readthedocs.io/en/latest/pyzmq/patterns/pubsub.html\n[zmq-pull-push]: https://learning-0mq-with-pyzmq.readthedocs.io/en/latest/pyzmq/patterns/pushpull.html#push-pull\n[picamera2]:https://github.com/raspberrypi/picamera2\n[picamera-setting]: https://picamera.readthedocs.io/en/release-1.13/quickstart.html\n[webrtc]: https://webrtc.org/\n"
        },
        {
          "name": "appveyor.yml",
          "type": "blob",
          "size": 2.0576171875,
          "content": "# Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#    http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimage: Visual Studio 2019\n\nenvironment:\n  matrix:\n    - PYTHON: \"C:\\\\Python38-x64\"\n      PYTHON_VERSION: \"3.8.x\"\n      PYTHON_ARCH: \"64\"\n\n    - PYTHON: \"C:\\\\Python39-x64\"\n      PYTHON_VERSION: \"3.9.x\"\n      PYTHON_ARCH: \"64\"\n\n    - PYTHON: \"C:\\\\Python310-x64\"\n      PYTHON_VERSION: \"3.10.x\"\n      PYTHON_ARCH: \"64\"\n\n    - PYTHON: \"C:\\\\Python311-x64\"\n      PYTHON_VERSION: \"3.11.x\"\n      PYTHON_ARCH: \"64\"\n\nbuild: off\n\nversion: \"{branch}-{build}\"\n\ncache:\n  - '%LOCALAPPDATA%\\pip\\Cache'\n\nbranches:\n  only:\n    - testing\n\nskip_commits:\n  files:\n    - \"**/*.md\"\n    - \"**/*.html\"\n    - \"**/*.js\"\n    - \"**/*.css\"\n    - docs/**/*\n    - mkdocs.yml\n    - README.md\n\nmatrix:\n  fast_finish: true\n\ninstall:\n  - \"SET PATH=%PYTHON%;%PYTHON%\\\\Scripts;%PATH%\"\n  - \"python --version\"\n  - \"python -m pip install --upgrade pip wheel\"\n  - cmd: python -m pip install \"numpy<2.0.0\"\n  - \"python -m pip install --upgrade .[asyncio] six httpx yt_dlp aiortc\"\n  - \"python -m pip install --upgrade pytest codecov pytest-cov pytest-asyncio m3u8 async-asgi-testclient paramiko\"\n  - \"python -m pip install --upgrade deffcode\"\n  - \"python -m pip install https://github.com/abhiTronix/python-mpegdash/releases/download/0.3.0-dev2/mpegdash-0.3.0.dev2-py3-none-any.whl\"\n  - cmd: chmod +x scripts/bash/prepare_dataset.sh\n  - cmd: bash scripts/bash/prepare_dataset.sh\n\ntest_script:\n  - cmd: python -m pytest --verbose --capture=no --cov-report term-missing --cov=vidgear vidgear/tests/\n\nafter_test:\n  - cmd: python -m codecov\n"
        },
        {
          "name": "azure-pipelines.yml",
          "type": "blob",
          "size": 3.0390625,
          "content": "# Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#    http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# specific path build\ntrigger:\n  branches:\n    include:\n      - testing\n  paths:\n    exclude:\n      - docs/**/*\n      - README.md\n      - mkdocs.yml\n      - \"**/*.md\"\n      - \"**/*.html\"\n      - \"**/*.js\"\n      - \"**/*.css\"\n\npr:\n  - testing\n\npool:\n  vmImage: \"macOS-latest\"\n\nstrategy:\n  matrix:\n    Python38:\n      python.version: \"3.8\"\n    Python39:\n      python.version: \"3.9\"\n    Python310:\n      python.version: \"3.10\"\n    Python311:\n      python.version: \"3.11\"\n\nsteps:\n  - task: UsePythonVersion@0\n    inputs:\n      versionSpec: \"$(python.version)\"\n    displayName: \"Using Python $(python.version)\"\n\n  - bash: |\n      brew install swig\n      brew install ffmpeg\n      brew reinstall openssl\n      brew install unzip\n      brew install dos2unix\n      brew install coreutils\n      dos2unix scripts/bash/prepare_dataset.sh\n      chmod +x scripts/bash/prepare_dataset.sh\n    displayName: \"Install brew dependencies\"\n\n  - bash: |\n      bash scripts/bash/prepare_dataset.sh\n    displayName: \"Prepare dataset\"\n\n  - script: |\n      python -m pip install -U pip wheel \n      python -m pip install \"numpy<2.0.0\"\n      python -m pip install -U .[asyncio] yt_dlp httpx six paramiko\n      python -m pip install -U codecov pytest pytest-asyncio pytest-cov mpegdash m3u8 async-asgi-testclient\n      python -m pip install -U deffcode\n    displayName: \"Install pip dependencies\"\n\n  - script: |\n      timeout 1500 pytest --verbose --cov=vidgear --cov-report=xml --cov-report=html --cov-report term-missing vidgear/tests/ || code=$?; if [[ $code -ne 124 && $code -ne 0 ]]; then exit $code; else echo \"##vso[task.setvariable variable=exit_code]$code\"; fi\n    displayName: \"pytest\"\n\n  - bash: |\n      echo \"Exit Code was: $(exit_code)\"\n      curl https://keybase.io/codecovsecurity/pgp_keys.asc | gpg --no-default-keyring --keyring trustedkeys.gpg --import\n      curl -Os https://uploader.codecov.io/latest/macos/codecov\n      curl -Os https://uploader.codecov.io/latest/macos/codecov.SHA256SUM\n      curl -Os https://uploader.codecov.io/latest/macos/codecov.SHA256SUM.sig\n      gpgv codecov.SHA256SUM.sig codecov.SHA256SUM\n      shasum -a 256 -c codecov.SHA256SUM\n      chmod +x codecov\n      if [ \"$(exit_code)\" != \"124\" ]; then\n        ./codecov -t $CODECOV_TOKEN -f coverage.xml -C $(Build.SourceVersion) -B $(Build.SourceBranch) -b $(Build.BuildNumber);\n      else\n        echo \"Timeout test - Skipped Codecov!\"; \n      fi\n    env:\n      CODECOV_TOKEN: $(TOKEN)\n    displayName: Upload coverage to CodeCov\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 1.0546875,
          "content": "# Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#    http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\ncodecov:\n  require_ci_to_pass: yes\n  branch: testing\n\ncoverage:\n  status:\n    patch: off\n    project:\n      default:\n        threshold: 5%\n        branches: \n          - testing\n        if_ci_failed: error\n        \nignore:\n  - \"vidgear/tests\"\n  - \"dir/**/*\"\n  - \"scripts\"\n  - \"vidgear/gears/__init__.py\" #trivial\n  - \"vidgear/gears/asyncio/__main__.py\" #trivial\n  - \"vidgear/gears/pigear.py\" #HW limits\n  - \"setup.py\"\n  - \"**/*.md\"\n  - \"**/*.html\"\n  - \"mkdocs.yml\""
        },
        {
          "name": "contributing.md",
          "type": "blob",
          "size": 4.71484375,
          "content": "<!--\n===============================================\nvidgear library source-code is deployed under the Apache 2.0 License:\n\nCopyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n===============================================\n-->\n\n<img src=\"docs/overrides/assets/images/contribute.webp\" alt=\"VidGear Contribution\" loading=\"lazy\" class=\"center\" />\n\n\n# Contribution Overview\n\n\nContributions are welcome, We'd love your contribution to VidGear in order to fix bugs or to implement new features!\n\n> 💡 If you're looking for something to work on, check for the [PR WELCOMED :mailbox_with_mail:](https://github.com/abhiTronix/vidgear/issues?q=is%3Aissue+is%3Aopen+label%3A%22PR+WELCOMED+%3Amailbox_with_mail%3A%22) labeled issues on our GitHub Repository.\n\n&thinsp;\n\n## Submission Contexts\n\n### Got a question or problem?\n\nFor quick questions, please refrain from opening an issue, instead read our [FAQ & Troubleshooting](https://abhitronix.github.io/vidgear/latest/help/get_help/#frequently-asked-questions) section or you can reach us on [Gitter](https://gitter.im/vidgear/community) community channel.\n\n\n### Found a typo?\n\nThere's no need to contribute for some typos. Just reach us on [Gitter ➶](https://gitter.im/vidgear/community) community channel, We will correct them in (less than) no time. \n\n\n### Found a bug?\n\nIf you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the [guidelines ➶](#submission-guidelines).\n\n\n### Request for a feature/improvement?\n\n> 💡 You can [subscribe our GitHub Repository](https://github.com/abhiTronix/vidgear/watchers) to receive notifications through email for new pull requests, commits and issues that are created in VidGear. _Learn more about it [here ➶](https://help.github.com/en/github/managing-subscriptions-and-notifications-on-github/viewing-your-subscriptions)_\n\nYou can request our GitHub Repository for a new feature/improvement based on the type of request:\n\n> Please [submit an issue with a proposal template](https://github.com/abhiTronix/vidgear/issues/new?labels=issue%3A+proposal&template=proposal.md) for your request to explain how it benefits everyone in the community.\n\n* **Major Feature Requests:** If you require a major feature for VidGear, then first [open an issue](https://abhitronix.github.io/vidgear/latest/contribution/issue/) and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! \n\n* **Minor Feature Requests:**  Small features and bugs resolved on priority. You just have to [submit an issue](https://abhitronix.github.io/vidgear/latest/contribution/issue/) to our GitHub Repository.\n\n&thinsp;\n\n## Submission Guidelines\n\n- [Submitting an Issue Guidelines](https://abhitronix.github.io/vidgear/latest/contribution/issue/)\n- [Submitting Pull Request(PR) Guidelines](https://abhitronix.github.io/vidgear/latest/contribution/PR/)\n\n\n&thinsp;\n\n## Community Channel\n\nIf you've come up with some new idea, or looking for the fastest way troubleshoot your problems, then please **join our [Gitter community channel][gitter]**.\n\n&thinsp;\n\n## Become a Stargazer\n\nYou can be a [**Stargazer 🌟**][stargazer] by starring this framework, it helps us a lot and **you're making it easier for others to find & trust this library.** Thanks!\n\n&thinsp;\n \n\n## Love using VidGear? \n\n> VidGear relies on your support :heart:\n\nDonations help keep VidGear's Development alive. Giving a little means a lot, even the smallest contribution can make a huge difference.\n\n\n[![ko-fi][kofi-badge]][kofi]\n\n\n<!--\nInternal URLs\n-->\n[Coffee-badge]:https://abhitronix.github.io/img/vidgear/orange_img.png\n[coffee]:https://www.buymeacoffee.com/2twOXFvlA\n[kofi-badge]:https://www.ko-fi.com/img/githubbutton_sm.svg\n[kofi]: https://ko-fi.com/W7W8WTYO\n[gitter]:https://gitter.im/vidgear/community\n[stargazer]: https://github.com/abhiTronix/vidgear/stargazers"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "mkdocs.yml",
          "type": "blob",
          "size": 13.8798828125,
          "content": "# Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#    http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Project information\nsite_name: VidGear\nsite_url: https://abhitronix.github.io/vidgear/\nsite_author: Abhishek Thakur\nsite_description: >-\n  A High-Performance Video-Processing Python Framework for building complex real-time media applications. 🔥\n\n# Repository\nrepo_name: abhiTronix/vidgear\nrepo_url: https://github.com/abhiTronix/vidgear\nedit_uri: edit/testing/docs/\n\n# Copyright\ncopyright: Copyright &copy; 2019 Abhishek Thakur(@abhiTronix)\n\n# Configuration\ntheme:\n  name: material\n  custom_dir: docs/overrides\n\n  # Default values, taken from mkdocs_theme.yml\n  features:\n    - announce.dismiss\n    - navigation.tabs\n    - navigation.tabs.sticky\n    - navigation.top\n    - navigation.tracking\n    - navigation.instant\n    - navigation.instant.progress\n    - search.suggest\n    - search.highlight\n    - search.share\n    - content.code.annotate\n    - content.code.copy\n    - content.tabs.link\n    - content.footnote.tooltips\n    - content.action.view\n    - content.action.edit\n    - content.tooltips\n    - toc.follow\n  palette:\n    - media: \"(prefers-color-scheme)\"\n      toggle:\n        icon: material/weather-hazy\n        name: Switch to light mode\n    # Light mode\n    - media: \"(prefers-color-scheme: light)\"\n      scheme: default\n      primary: purple\n      accent: dark purple\n      toggle:\n        icon: material/weather-sunny\n        name: Switch to dark mode\n    # Dark mode\n    - media: \"(prefers-color-scheme: dark)\"\n      scheme: slate\n      primary: deep orange\n      accent: orange\n      toggle:\n        icon: material/weather-night\n        name: Switch to system mode\n  font:\n    text: Source Sans 3\n    code: Fira Code\n  icon:\n    admonition:\n      note: octicons/tag-16\n      abstract: octicons/checklist-16\n      info: octicons/info-16\n      tip: octicons/light-bulb-16\n      success: octicons/check-16\n      question: octicons/question-16\n      warning: octicons/alert-16\n      failure: octicons/x-circle-16\n      danger: octicons/zap-16\n      bug: octicons/bug-16\n      example: octicons/beaker-16\n      quote: octicons/quote-16\n  logo: assets/images/logo.svg\n  favicon: assets/images/favicon-32.png\n  static_templates:\n    - 404.html\n\n# Plugins\nplugins:\n  - search\n  - git-revision-date-localized:\n      enable_creation_date: true\n      fallback_to_build_date: true\n  - minify:\n      minify_html: true\n  - mkdocstrings:\n      handlers:\n        python:\n          options:\n            show_root_heading: false\n            show_root_toc_entry: false\n            show_source: true\n            heading_level: 3\n  - exclude:\n      glob:\n        - overrides/assets/README.md\n\n# Hooks\nhooks:\n  - docs/overrides/hooks/js_hook.py\n\n# Logging\nvalidation:\n  unrecognized_links: ignore\n\n# Customization\nextra:\n  social:\n    - icon: fontawesome/brands/github\n      link: https://github.com/abhiTronix\n    - icon: fontawesome/brands/gitter\n      link: https://gitter.im/vidgear/community\n    - icon: fontawesome/brands/linkedin\n      link: https://www.linkedin.com/in/abhishek-singh-thakur-a37845a5\n    - icon: fontawesome/brands/dev\n      link: https://dev.to/abhitronix\n  version:\n    provider: mike\n    default: latest\n  analytics: # Google analytics\n    provider: google\n    property: G-XMZCQ3KBNJ\n    feedback:\n      title: Was this page helpful?\n      ratings:\n        - icon: material/emoticon-happy-outline\n          name: This page was helpful\n          data: 1\n          note: >-\n            Thanks for your feedback!\n        - icon: material/emoticon-sad-outline\n          name: This page could be improved\n          data: 0\n          note: >- \n            Thanks for your feedback! Help us improve this page by\n            using our <a href=\"...\" target=\"_blank\" rel=\"noopener\">feedback form</a>.\n\nextra_css:\n  - assets/stylesheets/custom.css\n\nextra_javascript:\n  - assets/javascripts/extra.js\n\n# Extensions\nmarkdown_extensions:\n  - admonition\n  - abbr\n  - tables\n  - attr_list\n  - def_list\n  - footnotes\n  - md_in_html\n  - meta\n  - toc:\n      permalink: true\n\n  # Python Markdown Extensions\n  - pymdownx.arithmatex:\n      generic: true\n  - pymdownx.betterem:\n      smart_enable: all\n  - pymdownx.caret\n  - pymdownx.details\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  - pymdownx.highlight:\n      anchor_linenums: true\n      line_spans: __span\n      pygments_lang_class: true\n  - pymdownx.inlinehilite\n  - pymdownx.keys\n  - pymdownx.mark\n  - pymdownx.smartsymbols\n  - pymdownx.magiclink:\n      normalize_issue_symbols: true\n      repo_url_shorthand: true\n      user: abhiTronix\n      repo: vidgear\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n  - pymdownx.tabbed:\n      alternate_style: true\n  - pymdownx.tasklist:\n      custom_checkbox: true\n  - pymdownx.tilde\n\n# Page tree\nnav:\n  - Home:\n      - Overview: index.md\n      - Installation:\n          - Installation Overview: installation.md\n          - Install using pip: installation/pip_install.md\n          - Install from source: installation/source_install.md\n      - Switching from OpenCV: switch_from_cv.md\n      - Contribution Guidelines:\n          - Contribution Overview: contribution.md\n          - Submitting an Issue Guidelines: contribution/issue.md\n          - Submitting Pull Request(PR) Guidelines: contribution/PR.md\n      - Release Notes: changelog.md\n      - License: license.md\n  - Gears:\n      - Introduction: gears.md\n      - CamGear:\n          - Overview: gears/camgear/overview.md\n          - Usage Examples: gears/camgear/usage.md\n          - Parameters: gears/camgear/params.md\n          - Bonus:\n              - Source Tweak Parameters: gears/camgear/advanced/source_params.md\n              - CamGear API References: bonus/reference/camgear.md\n              - Bonus Examples: help/camgear_ex.md\n              - FAQs: help/camgear_faqs.md\n      - PiGear:\n          - Overview: gears/pigear/overview.md\n          - Usage Examples: gears/pigear/usage.md\n          - Parameters: gears/pigear/params.md\n          - Bonus:\n              - PiGear API References: bonus/reference/pigear.md\n              - Bonus Examples: help/pigear_ex.md\n              - FAQs: help/pigear_faqs.md\n      - VideoGear:\n          - Overview: gears/videogear/overview.md\n          - Usage Examples: gears/videogear/usage.md\n          - Parameters: gears/videogear/params.md\n          - Bonus:\n              - VideoGear API References: bonus/reference/videogear.md\n              - Bonus Examples: help/videogear_ex.md\n              - FAQs: help/videogear_faqs.md\n      - ScreenGear:\n          - Overview: gears/screengear/overview.md\n          - Usage Examples: gears/screengear/usage.md\n          - Parameters: gears/screengear/params.md\n          - Bonus:\n              - ScreenGear API References: bonus/reference/screengear.md\n              - Bonus Examples: help/screengear_ex.md\n              - FAQs: help/screengear_faqs.md\n      - WriteGear:\n          - Introduction: gears/writegear/introduction.md\n          - Compression Mode:\n              - Overview: gears/writegear/compression/overview.md\n              - Usage Examples: gears/writegear/compression/usage.md\n              - Advanced:\n                  - Custom FFmpeg Commands: gears/writegear/compression/advanced/cciw.md\n                  - FFmpeg Installation: gears/writegear/compression/advanced/ffmpeg_install.md\n              - Parameters: gears/writegear/compression/params.md\n          - Non-Compression Mode:\n              - Overview: gears/writegear/non_compression/overview.md\n              - Usage Examples: gears/writegear/non_compression/usage.md\n              - Parameters: gears/writegear/non_compression/params.md\n          - Bonus:\n              - WriteGear API References: bonus/reference/writegear.md\n              - Bonus Examples: help/writegear_ex.md\n              - FAQs: help/writegear_faqs.md\n      - StreamGear:\n          - Introduction: gears/streamgear/introduction.md\n          - Single-Source Mode:\n              - Overview: gears/streamgear/ssm/overview.md\n              - Usage Examples: gears/streamgear/ssm/usage.md\n          - Real-time Frames Mode:\n              - Overview: gears/streamgear/rtfm/overview.md\n              - Usage Examples: gears/streamgear/rtfm/usage.md\n          - Parameters: gears/streamgear/params.md\n          - Bonus:\n              - StreamGear API References: bonus/reference/streamgear.md\n              - FFmpeg Installation: gears/streamgear/ffmpeg_install.md\n              - Bonus Examples: help/streamgear_ex.md\n              - FAQs: help/streamgear_faqs.md\n      - NetGear:\n          - Overview: gears/netgear/overview.md\n          - Usage Examples: gears/netgear/usage.md\n          - Advanced Usages:\n              - Multi-Servers Mode: gears/netgear/advanced/multi_server.md\n              - Multi-Clients Mode: gears/netgear/advanced/multi_client.md\n              - Bidirectional Mode: gears/netgear/advanced/bidirectional_mode.md\n              - SSH Tunneling Mode: gears/netgear/advanced/ssh_tunnel.md\n              - Secure Mode: gears/netgear/advanced/secure_mode.md\n              - Frame Compression: gears/netgear/advanced/compression.md\n          - Parameters: gears/netgear/params.md\n          - Bonus:\n              - NetGear API References: bonus/reference/netgear.md\n              - Bonus Examples: help/netgear_ex.md\n              - FAQs: help/netgear_faqs.md\n      - WebGear:\n          - Overview: gears/webgear/overview.md\n          - Usage Examples: gears/webgear/usage.md\n          - Advanced Usages: gears/webgear/advanced.md\n          - Parameters: gears/webgear/params.md\n          - Bonus:\n              - WebGear API References: bonus/reference/webgear.md\n              - Bonus Examples: help/webgear_ex.md\n              - FAQs: help/webgear_faqs.md\n      - WebGear_RTC:\n          - Overview: gears/webgear_rtc/overview.md\n          - Usage Examples: gears/webgear_rtc/usage.md\n          - Advanced Usages: gears/webgear_rtc/advanced.md\n          - Parameters: gears/webgear_rtc/params.md\n          - Bonus:\n              - WebGear_RTC API References: bonus/reference/webgear_rtc.md\n              - Bonus Examples: help/webgear_rtc_ex.md\n              - FAQs: help/webgear_rtc_faqs.md\n      - NetGear_Async:\n          - Overview: gears/netgear_async/overview.md\n          - Usage Examples: gears/netgear_async/usage.md\n          - Advanced Usages:\n              - Bidirectional Mode: gears/netgear_async/advanced/bidirectional_mode.md\n          - Parameters: gears/netgear_async/params.md\n          - Bonus:\n              - NetGear_Async API References: bonus/reference/netgear_async.md\n              - Bonus Examples: help/netgear_async_ex.md\n              - FAQs: help/netgear_async_faqs.md\n      - Stabilizer Class:\n          - Overview: gears/stabilizer/overview.md\n          - Usage Examples: gears/stabilizer/usage.md\n          - Parameters: gears/stabilizer/params.md\n          - Bonus:\n              - API References: bonus/reference/stabilizer.md\n              - Bonus Examples: help/stabilizer_ex.md\n              - FAQs: help/stabilizer_faqs.md\n  - References:\n      - API References:\n          - vidgear.gears:\n              - CamGear API: bonus/reference/camgear.md\n              - PiGear API: bonus/reference/pigear.md\n              - VideoGear API: bonus/reference/videogear.md\n              - ScreenGear API: bonus/reference/screengear.md\n              - WriteGear API: bonus/reference/writegear.md\n              - StreamGear API: bonus/reference/streamgear.md\n              - NetGear API: bonus/reference/netgear.md\n              - Stabilizer Class: bonus/reference/stabilizer.md\n              - Helper Methods: bonus/reference/helper.md\n          - vidgear.gears.asyncio:\n              - WebGear API: bonus/reference/webgear.md\n              - WebGear_RTC API: bonus/reference/webgear_rtc.md\n              - NetGear_Async API: bonus/reference/netgear_async.md\n              - Helper Methods: bonus/reference/helper_async.md\n      - Colorspace Manipulation: bonus/colorspace_manipulation.md\n      - Threaded Queue Mode: bonus/TQM.md\n  - Help:\n      - Help VidGear 'n' Get Help:\n          - Helping VidGear: help.md\n          - Getting Help: help/get_help.md\n      - Frequently Asked Questions:\n          - General FAQs: help/general_faqs.md\n          - CamGear FAQs: help/camgear_faqs.md\n          - PiGear FAQs: help/pigear_faqs.md\n          - VideoGear FAQs: help/videogear_faqs.md\n          - ScreenGear FAQs: help/screengear_faqs.md\n          - WriteGear FAQs: help/writegear_faqs.md\n          - StreamGear FAQs: help/streamgear_faqs.md\n          - NetGear FAQs: help/netgear_faqs.md\n          - WebGear FAQs: help/webgear_faqs.md\n          - WebGear_RTC FAQs: help/webgear_rtc_faqs.md\n          - NetGear_Async FAQs: help/netgear_async_faqs.md\n          - Stabilizer Class FAQs: help/stabilizer_faqs.md\n      - Bonus Examples:\n          - CamGear Examples: help/camgear_ex.md\n          - PiGear Examples: help/pigear_ex.md\n          - VideoGear Examples: help/videogear_ex.md\n          - ScreenGear Examples: help/screengear_ex.md\n          - WriteGear Examples: help/writegear_ex.md\n          - StreamGear Examples: help/streamgear_ex.md\n          - NetGear Examples: help/netgear_ex.md\n          - WebGear Examples: help/webgear_ex.md\n          - WebGear_RTC Examples: help/webgear_rtc_ex.md\n          - NetGear_Async Examples: help/netgear_async_ex.md\n          - Stabilizer Class Examples: help/stabilizer_ex.md\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.72265625,
          "content": "# Copyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n\n#    http://www.apache.org/licenses/LICENSE-2.0\n\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n \n[pytest]\n\nfilterwarnings =\n    ignore:the imp module is deprecated.*:DeprecationWarning\n    ignore:tostring.*is deprecated\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.6728515625,
          "content": "[metadata]\n# This includes the license file(s) in the wheel.\n# https://wheel.readthedocs.io/en/stable/user_guide.html#including-license-files-in-the-generated-wheel-file\nlicense_files = LICENSE\ndescription_file = README.md\n\n[bdist_wheel]\n# This flag says to generate wheels that support both Python 2 and Python\n# 3. If your code will not run unchanged on both Python 2 and 3, you will\n# need to generate separate wheels for each Python version that you\n# support. Removing this line (or setting universal to 0) will prevent\n# bdist_wheel from trying to make a universal wheel. For more see:\n# https://packaging.python.org/guides/distributing-packages-using-setuptools/#wheels\nuniversal=0\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.5205078125,
          "content": "\"\"\"\n===============================================\nvidgear library source-code is deployed under the Apache 2.0 License:\n\nCopyright (c) 2019 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com>\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n===============================================\n\"\"\"\n\n# import the necessary packages\nimport json\nimport platform\nimport urllib.request\n\nfrom pkg_resources import parse_version\nfrom distutils.util import convert_path\nfrom setuptools import setup\n\n\ndef test_opencv():\n    \"\"\"\n    This function is workaround to\n    test if correct OpenCV Library version has already been installed\n    on the machine or not. Returns True if previously not installed.\n    \"\"\"\n    try:\n        # import OpenCV Binaries\n        import cv2\n\n        # check whether OpenCV Binaries are 3.x+\n        if parse_version(cv2.__version__) < parse_version(\"3\"):\n            raise ImportError(\n                \"Incompatible (< 3.0) OpenCV version-{} Installation found on this machine!\".format(\n                    parse_version(cv2.__version__)\n                )\n            )\n    except ImportError:\n        return True\n    return False\n\n\ndef latest_version(package_name):\n    \"\"\"\n    Get latest package version from pypi (Hack)\n    \"\"\"\n    url = \"https://pypi.python.org/pypi/%s/json\" % (package_name,)\n    versions = []\n    try:\n        response = urllib.request.urlopen(\n            urllib.request.Request(url),\n            timeout=1,\n        )\n        data = json.load(response)\n        versions = list(data[\"releases\"].keys())\n        versions.sort(key=parse_version)\n        return \">={}\".format(versions[-1])\n    except Exception as e:\n        if versions:\n            return \">={}\".format(versions[-1])\n        else:\n            print(str(e))\n    return \"\"\n\n\npkg_version = {}\nver_path = convert_path(\"vidgear/version.py\")\nwith open(ver_path) as ver_file:\n    exec(ver_file.read(), pkg_version)\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n    long_description = fh.read()\n    long_description = long_description.replace(\n        \"(#\", \"(https://github.com/abhiTronix/vidgear#\"\n    )\n    # patch for unicodes\n    long_description = long_description.replace(\"➶\", \">>\")\n    long_description = long_description.replace(\"©\", \"(c)\")\n\nsetup(\n    name=\"vidgear\",\n    packages=[\"vidgear\", \"vidgear.gears\", \"vidgear.gears.asyncio\"],\n    version=pkg_version[\"__version__\"],\n    description=\"High-performance cross-platform Video Processing Python framework powerpacked with unique trailblazing features.\",\n    license=\"Apache License 2.0\",\n    author=\"Abhishek Thakur\",\n    install_requires=[\n        \"cython\",  # helper for numpy install\n        \"numpy\",\n        \"requests\",\n        \"colorlog\",\n        \"tqdm\",\n    ]\n    + ([\"opencv-python\"] if test_opencv() else []),\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    author_email=\"abhi.una12@gmail.com\",\n    url=\"https://abhitronix.github.io/vidgear\",\n    extras_require={\n        # API specific deps\n        \"core\": [\n            \"yt_dlp{}\".format(latest_version(\"yt_dlp\")),\n            \"pyzmq{}\".format(latest_version(\"pyzmq\")),\n            \"Pillow\",\n            \"simplejpeg>=1.7.3\", # Requires-Python >=3.9 for v1.7.4\n            \"mss{}\".format(latest_version(\"mss\")),\n            \"pyscreenshot{}\".format(latest_version(\"pyscreenshot\")),\n        ]\n        + (\n            [\"dxcam{}\".format(latest_version(\"dxcam\"))]\n            if (platform.system() == \"Windows\")  # windows is only supported\n            else []\n        ),\n        # API specific + Asyncio deps\n        \"asyncio\": [\n            \"yt_dlp{}\".format(latest_version(\"yt_dlp\")),\n            \"pyzmq{}\".format(latest_version(\"pyzmq\")),\n            \"simplejpeg>=1.7.3\", # Requires-Python >=3.9 for v1.7.4\n            \"mss{}\".format(latest_version(\"mss\")),\n            \"Pillow\",\n            \"pyscreenshot{}\".format(latest_version(\"pyscreenshot\")),\n            \"starlette{}\".format(latest_version(\"starlette\")),\n            \"jinja2\",\n            \"msgpack{}\".format(latest_version(\"msgpack\")),\n            \"msgpack_numpy{}\".format(latest_version(\"msgpack_numpy\")),\n            \"aiortc{}\".format(latest_version(\"aiortc\")),\n            \"uvicorn{}\".format(latest_version(\"uvicorn\")),\n        ]\n        + (\n            [\"dxcam{}\".format(latest_version(\"dxcam\"))]\n            if (platform.system() == \"Windows\")  # windows is only supported\n            else []\n        )\n        + (\n            [\"uvloop{}\".format(latest_version(\"uvloop\"))]\n            if (platform.system() != \"Windows\")  # windows not supported\n            else []\n        ),\n    },\n    keywords=[\n        \"OpenCV\",\n        \"multithreading\",\n        \"FFmpeg\",\n        \"picamera\",\n        \"starlette\",\n        \"mss\",\n        \"pyzmq\",\n        \"dxcam\",\n        \"aiortc\",\n        \"uvicorn\",\n        \"uvloop\",\n        \"yt-dlp\",\n        \"asyncio\",\n        \"dash\",\n        \"hls\",\n        \"Video Processing\",\n        \"Video Stabilization\",\n        \"Computer Vision\",\n        \"Video Streaming\",\n        \"raspberrypi\",\n        \"YouTube\",\n        \"Twitch\",\n        \"WebRTC\",\n    ],\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Operating System :: POSIX\",\n        \"Operating System :: MacOS :: MacOS X\",\n        \"Operating System :: Microsoft :: Windows\",\n        \"Topic :: Multimedia :: Video\",\n        \"Topic :: Scientific/Engineering\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Science/Research\",\n        \"Intended Audience :: Education\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n    ],\n    python_requires=\">=3.8\",\n    scripts=[],\n    project_urls={\n        \"Bug Reports\": \"https://github.com/abhiTronix/vidgear/issues\",\n        \"Funding\": \"https://ko-fi.com/W7W8WTYO\",\n        \"Source\": \"https://github.com/abhiTronix/vidgear\",\n        \"Documentation\": \"https://abhitronix.github.io/vidgear\",\n        \"Changelog\": \"https://abhitronix.github.io/vidgear/latest/changelog/\",\n    },\n)\n"
        },
        {
          "name": "vidgear",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}