{
  "metadata": {
    "timestamp": 1736559651671,
    "page": 311,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "obss/sahi",
      "stars": 4245,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0732421875,
          "content": "# this drop notebooks from GitHub language stats\n*.ipynb linguist-vendored\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.3056640625,
          "content": "*.pyc\n*.swp\n*.pkl\n*.pth\n*.pt\n*.onnx\nweights*\n.vscode\n.idea\nruns\n\n# outputs\noutputs\nsliced_prediction_data\n\n# mmdetection\nmmdetection/build\nmmdetection/demo\nmmdetection/experiments\n\n# mac\n.DS_Store\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# Elastic Beanstalk Files\n.elasticbeanstalk/*\n!.elasticbeanstalk/*.cfg.yml\n!.elasticbeanstalk/*.global.yml\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.9931640625,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this package, please consider citing it.\"\nauthors:\n- family-names: \"Akyon\"\n  given-names: \"Fatih Cagatay\"\n- family-names: \"Cengiz\"\n  given-names: \"Cemil\"\n- family-names: \"Altinuc\"\n  given-names: \"Sinan Onur\"\n- family-names: \"Cavusoglu\"\n  given-names: \"Devrim\"\n- family-names: \"Sahin\"\n  given-names: \"Kadir\"\n- family-names: \"Eryuksel\"\n  given-names: \"Ogulcan\"\ntitle: \"SAHI: A lightweight vision library for performing large scale object detection and instance segmentation\"\npreferred-citation:\n  type: article\n  title: \"Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection\"\n  doi: 10.1109/ICIP46576.2022.9897990\n  url: https://ieeexplore.ieee.org/document/9897990\n  journal: 2022 IEEE International Conference on Image Processing (ICIP)\n  authors:\n  - family-names: \"Akyon\"\n    given-names: \"Fatih Cagatay\"\n  - family-names: \"Altinuc\"\n    given-names: \"Sinan Onur\"\n  - family-names: \"Temizel\"\n    given-names: \"Alptekin\"\n  year: 2022\n  start: 966\n  end: 970\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0361328125,
          "content": "MIT License\n\nCopyright (c) 2020 obss\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0244140625,
          "content": "include requirements.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.8037109375,
          "content": "<div align=\"center\">\n<h1>\n  SAHI: Slicing Aided Hyper Inference\n</h1>\n\n<h4>\n  A lightweight vision library for performing large scale object detection & instance segmentation\n</h4>\n\n<h4>\n    <img width=\"700\" alt=\"teaser\" src=\"https://raw.githubusercontent.com/obss/sahi/main/resources/sliced_inference.gif\">\n</h4>\n\n<div>\n    <a href=\"https://pepy.tech/project/sahi\"><img src=\"https://pepy.tech/badge/sahi\" alt=\"downloads\"></a>\n    <a href=\"https://pepy.tech/project/sahi\"><img src=\"https://pepy.tech/badge/sahi/month\" alt=\"downloads\"></a>\n    <br>\n    <a href=\"https://badge.fury.io/py/sahi\"><img src=\"https://badge.fury.io/py/sahi.svg\" alt=\"pypi version\"></a>\n    <a href=\"https://anaconda.org/conda-forge/sahi\"><img src=\"https://anaconda.org/conda-forge/sahi/badges/version.svg\" alt=\"conda version\"></a>\n    <a href=\"https://github.com/obss/sahi/actions/workflows/package_testing.yml\"><img src=\"https://github.com/obss/sahi/actions/workflows/package_testing.yml/badge.svg\" alt=\"package testing\"></a>\n  <br>\n    <a href=\"https://ieeexplore.ieee.org/document/9897990\"><img src=\"https://img.shields.io/badge/DOI-10.1109%2FICIP46576.2022.9897990-orange.svg\" alt=\"ci\"></a>\n  <br>\n    <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_yolov5.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n    <a href=\"https://huggingface.co/spaces/fcakyon/sahi-yolox\"><img src=\"https://raw.githubusercontent.com/obss/sahi/main/resources/hf_spaces_badge.svg\" alt=\"HuggingFace Spaces\"></a>\n\n​    \n</div>\n</div>\n\n## <div align=\"center\">Overview</div>\n\nObject detection and instance segmentation are by far the most important applications in Computer Vision. However, the detection of small objects and inference on large images still need to be improved in practical usage. Here comes the SAHI to help developers overcome these real-world problems with many vision utilities.\n\n| Command  | Description  |\n|---|---|\n| [predict](https://github.com/obss/sahi/blob/main/docs/cli.md#predict-command-usage)  | perform sliced/standard video/image prediction using any [ultralytics](https://github.com/ultralytics/ultralytics)/[mmdet](https://github.com/open-mmlab/mmdetection)/[detectron2](https://github.com/facebookresearch/detectron2)/[huggingface](https://huggingface.co/models?pipeline_tag=object-detection&sort=downloads)/[torchvision](https://pytorch.org/vision/stable/models.html#object-detection) model |\n| [predict-fiftyone](https://github.com/obss/sahi/blob/main/docs/cli.md#predict-fiftyone-command-usage)  | perform sliced/standard prediction using any [ultralytics](https://github.com/ultralytics/ultralytics)/[mmdet](https://github.com/open-mmlab/mmdetection)/[detectron2](https://github.com/facebookresearch/detectron2)/[huggingface](https://huggingface.co/models?pipeline_tag=object-detection&sort=downloads)/[torchvision](https://pytorch.org/vision/stable/models.html#object-detection) model and explore results in [fiftyone app](https://github.com/voxel51/fiftyone) |\n| [coco slice](https://github.com/obss/sahi/blob/main/docs/cli.md#coco-slice-command-usage)  | automatically slice COCO annotation and image files |\n| [coco fiftyone](https://github.com/obss/sahi/blob/main/docs/cli.md#coco-fiftyone-command-usage)  | explore multiple prediction results on your COCO dataset with [fiftyone ui](https://github.com/voxel51/fiftyone) ordered by number of misdetections |\n| [coco evaluate](https://github.com/obss/sahi/blob/main/docs/cli.md#coco-evaluate-command-usage)  | evaluate classwise COCO AP and AR for given predictions and ground truth |\n| [coco analyse](https://github.com/obss/sahi/blob/main/docs/cli.md#coco-analyse-command-usage)  | calculate and export many error analysis plots |\n| [coco yolov5](https://github.com/obss/sahi/blob/main/docs/cli.md#coco-yolov5-command-usage)  | automatically convert any COCO dataset to [ultralytics](https://github.com/ultralytics/ultralytics) format |\n\n## <div align=\"center\">Quick Start Examples</div>\n\n[📜 List of publications that cite SAHI (currently 200+)](https://scholar.google.com/scholar?hl=en&as_sdt=2005&sciodt=0,5&cites=14065474760484865747&scipsc=&q=&scisbd=1)\n\n[🏆 List of competition winners that used SAHI](https://github.com/obss/sahi/discussions/688)\n\n### Tutorials\n\n- [Introduction to SAHI](https://medium.com/codable/sahi-a-vision-library-for-performing-sliced-inference-on-large-images-small-objects-c8b086af3b80)\n\n- [Official paper](https://ieeexplore.ieee.org/document/9897990) (ICIP 2022 oral)\n\n- [Pretrained weights and ICIP 2022 paper files](https://github.com/fcakyon/small-object-detection-benchmark)\n\n- [Visualizing and Evaluating SAHI predictions with FiftyOne](https://voxel51.com/blog/how-to-detect-small-objects/) (2024) (NEW)\n\n- ['Exploring SAHI' Research Article from 'learnopencv.com'](https://learnopencv.com/slicing-aided-hyper-inference/)\n\n- ['VIDEO TUTORIAL: Slicing Aided Hyper Inference for Small Object Detection - SAHI'](https://www.youtube.com/watch?v=UuOjJKxn-M8&t=270s) (RECOMMENDED)\n\n- [Video inference support is live](https://github.com/obss/sahi/discussions/626)\n\n- [Kaggle notebook](https://www.kaggle.com/remekkinas/sahi-slicing-aided-hyper-inference-yv5-and-yx)\n\n- [Satellite object detection](https://blog.ml6.eu/how-to-detect-small-objects-in-very-large-images-70234bab0f98)\n\n- [Error analysis plots & evaluation](https://github.com/obss/sahi/discussions/622) (RECOMMENDED)\n\n- [Interactive result visualization and inspection](https://github.com/obss/sahi/discussions/624) (RECOMMENDED)\n\n- [COCO dataset conversion](https://medium.com/codable/convert-any-dataset-to-coco-object-detection-format-with-sahi-95349e1fe2b7)\n\n- [Slicing operation notebook](demo/slicing.ipynb)\n\n- `YOLOX` + `SAHI` demo: <a href=\"https://huggingface.co/spaces/fcakyon/sahi-yolox\"><img src=\"https://raw.githubusercontent.com/obss/sahi/main/resources/hf_spaces_badge.svg\" alt=\"sahi-yolox\"></a>\n\n- `YOLO11` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_ultralytics.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-yolov8\"></a> (NEW)\n\n- `RT-DETR` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_rtdetr.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-rtdetr\"></a> (NEW)\n\n- `YOLOv8` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_ultralytics.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-yolov8\"></a>\n\n- `DeepSparse` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_sparse_yolov5.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-deepsparse\"></a>\n\n- `HuggingFace` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_huggingface.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-huggingface\"></a>\n\n- `YOLOv5` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_yolov5.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-yolov5\"></a>\n\n- `MMDetection` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_mmdetection.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-mmdetection\"></a>\n\n- `Detectron2` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_detectron2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-detectron2\"></a>\n\n- `TorchVision` + `SAHI` walkthrough: <a href=\"https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_torchvision.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"sahi-torchvision\"></a>\n\n\n<a href=\"https://huggingface.co/spaces/fcakyon/sahi-yolox\"><img width=\"600\" src=\"https://user-images.githubusercontent.com/34196005/144092739-c1d9bade-a128-4346-947f-424ce00e5c4f.gif\" alt=\"sahi-yolox\"></a> \n\n\n</details>\n\n### Installation\n\n<img width=\"700\" alt=\"sahi-installation\" src=\"https://user-images.githubusercontent.com/34196005/149311602-b44e6fe1-f496-40f2-a7ae-5ea1f66e1550.gif\">\n\n\n<details closed>\n<summary>\n<big><b>Installation details:</b></big>\n</summary>\n\n- Install `sahi` using pip:\n\n```console\npip install sahi\n```\n\n- On Windows, `Shapely` needs to be installed via Conda:\n\n```console\nconda install -c conda-forge shapely\n```\n\n- Install your desired version of pytorch and torchvision (cuda 11.3 for detectron2, cuda 11.7 for rest):\n\n```console\nconda install pytorch=1.10.2 torchvision=0.11.3 cudatoolkit=11.3 -c pytorch\n```\n\n```console\nconda install pytorch=1.13.1 torchvision=0.14.1 pytorch-cuda=11.7 -c pytorch -c nvidia\n```\n\n- Install your desired detection framework (yolov5):\n\n```console\npip install yolov5==7.0.13\n```\n\n- Install your desired detection framework (ultralytics):\n\n```console\npip install ultralytics==8.3.50\n```\n\n- Install your desired detection framework (mmdet):\n\n```console\npip install mim\nmim install mmdet==3.0.0\n```\n\n- Install your desired detection framework (detectron2):\n\n```console\npip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n```\n\n- Install your desired detection framework (huggingface):\n\n```console\npip install transformers timm\n```\n\n- Install your desired detection framework (super-gradients):\n\n```console\npip install super-gradients==3.3.1\n```\n\n</details>\n\n### Framework Agnostic Sliced/Standard Prediction\n\n<img width=\"700\" alt=\"sahi-predict\" src=\"https://user-images.githubusercontent.com/34196005/149310540-e32f504c-6c9e-4691-8afd-59f3a1a457f0.gif\">\n\nFind detailed info on `sahi predict` command at [cli.md](docs/cli.md#predict-command-usage).\n\nFind detailed info on video inference at [video inference tutorial](https://github.com/obss/sahi/discussions/626).\n\nFind detailed info on image/dataset slicing utilities at [slicing.md](docs/slicing.md).\n\n### Error Analysis Plots & Evaluation\n\n<img width=\"700\" alt=\"sahi-analyse\" src=\"https://user-images.githubusercontent.com/34196005/149537858-22b2e274-04e8-4e10-8139-6bdcea32feab.gif\">\n\nFind detailed info at [Error Analysis Plots & Evaluation](https://github.com/obss/sahi/discussions/622).\n\n### Interactive Visualization & Inspection\n\n<img width=\"700\" alt=\"sahi-fiftyone\" src=\"https://user-images.githubusercontent.com/34196005/149321540-e6ddd5f3-36dc-4267-8574-a985dd0c6578.gif\">\n\nFind detailed info at [Interactive Result Visualization and Inspection](https://github.com/obss/sahi/discussions/624).\n\n### Other utilities\n\nFind detailed info on COCO utilities (yolov5 conversion, slicing, subsampling, filtering, merging, splitting) at [coco.md](docs/coco.md).\n\nFind detailed info on MOT utilities (ground truth dataset creation, exporting tracker metrics in mot challenge format) at [mot.md](docs/mot.md).\n\n## <div align=\"center\">Citation</div>\n\nIf you use this package in your work, please cite it as:\n\n```\n@article{akyon2022sahi,\n  title={Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection},\n  author={Akyon, Fatih Cagatay and Altinuc, Sinan Onur and Temizel, Alptekin},\n  journal={2022 IEEE International Conference on Image Processing (ICIP)},\n  doi={10.1109/ICIP46576.2022.9897990},\n  pages={966-970},\n  year={2022}\n}\n```\n\n```\n@software{obss2021sahi,\n  author       = {Akyon, Fatih Cagatay and Cengiz, Cemil and Altinuc, Sinan Onur and Cavusoglu, Devrim and Sahin, Kadir and Eryuksel, Ogulcan},\n  title        = {{SAHI: A lightweight vision library for performing large scale object detection and instance segmentation}},\n  month        = nov,\n  year         = 2021,\n  publisher    = {Zenodo},\n  doi          = {10.5281/zenodo.5718950},\n  url          = {https://doi.org/10.5281/zenodo.5718950}\n}\n```\n\n## <div align=\"center\">Contributing</div>\n\n`sahi` library currently supports all [Ultralytics (YOLOv8/v10/v11/RTDETR) models](https://github.com/ultralytics/ultralytics), [MMDetection models](https://github.com/open-mmlab/mmdetection/blob/master/docs/en/model_zoo.md), [Detectron2 models](https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md), and [HuggingFace object detection models](https://huggingface.co/models?pipeline_tag=object-detection&sort=downloads). Moreover, it is easy to add new frameworks.\n\nAll you need to do is, create a new .py file under [sahi/models/](https://github.com/obss/sahi/tree/main/sahi/models) folder and create a new class in that .py file that implements [DetectionModel class](https://github.com/obss/sahi/blob/aaeb57c39780a5a32c4de2848e54df9a874df58b/sahi/models/base.py#L12). You can take the [MMDetection wrapper](https://github.com/obss/sahi/blob/aaeb57c39780a5a32c4de2848e54df9a874df58b/sahi/models/mmdet.py#L91) or [YOLOv5 wrapper](https://github.com/obss/sahi/blob/7e48bdb6afda26f977b763abdd7d8c9c170636bd/sahi/models/yolov5.py#L17) as a reference.\n\nBefore opening a PR:\n\n- Install required development packages:\n\n```bash\npip install -e .\"[dev]\"\n```\n\n- Reformat with black and isort:\n\n```bash\npython -m scripts.run_code_style format\n```\n\n## <div align=\"center\">Contributors</div>\n\n<div align=\"center\">\n\n<a align=\"left\" href=\"https://github.com/fcakyon\" target=\"_blank\">Fatih Cagatay Akyon</a>\n\n<a align=\"left\" href=\"https://github.com/sinanonur\" target=\"_blank\">Sinan Onur Altinuc</a>\n\n<a align=\"left\" href=\"https://github.com/devrimcavusoglu\" target=\"_blank\">Devrim Cavusoglu</a>\n\n<a align=\"left\" href=\"https://github.com/cemilcengiz\" target=\"_blank\">Cemil Cengiz</a>\n\n<a align=\"left\" href=\"https://github.com/oulcan\" target=\"_blank\">Ogulcan Eryuksel</a>\n\n<a align=\"left\" href=\"https://github.com/kadirnar\" target=\"_blank\">Kadir Nar</a>\n\n<a align=\"left\" href=\"https://github.com/madenburak\" target=\"_blank\">Burak Maden</a>\n\n<a align=\"left\" href=\"https://github.com/PushpakBhoge\" target=\"_blank\">Pushpak Bhoge</a>\n\n<a align=\"left\" href=\"https://github.com/mcvarer\" target=\"_blank\">M. Can V.</a>\n\n<a align=\"left\" href=\"https://github.com/ChristofferEdlund\" target=\"_blank\">Christoffer Edlund</a>\n\n<a align=\"left\" href=\"https://github.com/ishworii\" target=\"_blank\">Ishwor</a>\n\n<a align=\"left\" href=\"https://github.com/mecevit\" target=\"_blank\">Mehmet Ecevit</a>\n\n<a align=\"left\" href=\"https://github.com/ssahinnkadir\" target=\"_blank\">Kadir Sahin</a>\n\n<a align=\"left\" href=\"https://github.com/weypro\" target=\"_blank\">Wey</a>\n\n<a align=\"left\" href=\"https://github.com/youngjae-avikus\" target=\"_blank\">Youngjae</a>\n\n<a align=\"left\" href=\"https://github.com/tureckova\" target=\"_blank\">Alzbeta Tureckova</a>\n\n<a align=\"left\" href=\"https://github.com/s-aiueo32\" target=\"_blank\">So Uchida</a>\n\n<a align=\"left\" href=\"https://github.com/developer0hye\" target=\"_blank\">Yonghye Kwon</a>\n\n<a align=\"left\" href=\"https://github.com/aphilas\" target=\"_blank\">Neville</a>\n\n<a align=\"left\" href=\"https://github.com/mayrajeo\" target=\"_blank\">Janne Mäyrä</a>\n\n<a align=\"left\" href=\"https://github.com/christofferedlund\" target=\"_blank\">Christoffer Edlund</a>\n\n<a align=\"left\" href=\"https://github.com/ilkermanap\" target=\"_blank\">Ilker Manap</a>\n\n<a align=\"left\" href=\"https://github.com/nguyenthean\" target=\"_blank\">Nguyễn Thế An</a>\n\n<a align=\"left\" href=\"https://github.com/weiji14\" target=\"_blank\">Wei Ji</a>\n\n<a align=\"left\" href=\"https://github.com/aynursusuz\" target=\"_blank\">Aynur Susuz</a>\n\n<a align=\"left\" href=\"https://github.com/pranavdurai10\" target=\"_blank\">Pranav Durai</a>\n\n<a align=\"left\" href=\"https://github.com/lakshaymehra\" target=\"_blank\">Lakshay Mehra</a>\n\n<a align=\"left\" href=\"https://github.com/karl-joan\" target=\"_blank\">Karl-Joan Alesma</a>\n\n<a align=\"left\" href=\"https://github.com/jacobmarks\" target=\"_blank\">Jacob Marks</a>\n\n<a align=\"left\" href=\"https://github.com/williamlung\" target=\"_blank\">William Lung</a>\n\n<a align=\"left\" href=\"https://github.com/amoghdhaliwal\" target=\"_blank\">Amogh Dhaliwal</a>\n\n</div>\n\n"
        },
        {
          "name": "demo",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.0791015625,
          "content": "[tool.black]\nline-length = 120\n\n[tool.isort]\nline_length = 120\nprofile = \"black\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1220703125,
          "content": "opencv-python<=4.10.0.84\nshapely>=2.0.0\ntqdm>=4.48.2\npillow>=8.2.0\npybboxes==0.1.6\npyyaml\nfire\nterminaltables\nrequests\nclick\n"
        },
        {
          "name": "resources",
          "type": "tree",
          "content": null
        },
        {
          "name": "sahi",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.3115234375,
          "content": "[flake8]\nmax-line-length = 119\nmax-complexity = 18\nexclude =.git,__pycache__,docs/source/conf.py,build,dist\nignore = I101,I201,F401,F403,S001,D100,D101,D102,D103,D104,D105,D106,D107,D200,D205,D400,W504,D202,E203,E501,E722,W503,B006\ninline-quotes = \"\nstatistics = true\ncount = true\n\n[mypy]\nignore_missing_imports = True\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.091796875,
          "content": "import io\nimport os\nimport re\n\nimport setuptools\n\n\ndef get_long_description():\n    base_dir = os.path.abspath(os.path.dirname(__file__))\n    with io.open(os.path.join(base_dir, \"README.md\"), encoding=\"utf-8\") as f:\n        return f.read()\n\n\ndef get_requirements():\n    with open(\"requirements.txt\", encoding=\"utf8\") as f:\n        return f.read().splitlines()\n\n\ndef get_version():\n    current_dir = os.path.abspath(os.path.dirname(__file__))\n    version_file = os.path.join(current_dir, \"sahi\", \"__init__.py\")\n    with io.open(version_file, encoding=\"utf-8\") as f:\n        return re.search(r'^__version__ = [\\'\"]([^\\'\"]*)[\\'\"]', f.read(), re.M).group(1)\n\n\nsetuptools.setup(\n    name=\"sahi\",\n    version=get_version(),\n    author=\"OBSS\",\n    license=\"MIT\",\n    description=\"A vision library for performing sliced inference on large images/small objects\",\n    long_description=get_long_description(),\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/obss/sahi\",\n    packages=setuptools.find_packages(exclude=[\"demo\", \"docs\", \"resources\", \"tests\", \"scripts\"]),\n    python_requires=\">=3.6\",\n    install_requires=get_requirements(),\n    extras_require={\n        \"tests\": [\"mmdet==3.0.0\", \"pycocotools==2.0.6\"],\n        \"dev\": [\n            \"black==22.3.0\",\n            \"flake8==3.9.2\",\n            \"importlib-metadata>=1.1.0,<4.3;python_version<'3.8'\",\n            \"isort==5.9.2\",\n            \"jupyterlab==3.0.14\",\n        ],\n    },\n    classifiers=[\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Science/Research\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Topic :: Software Development :: Libraries\",\n        \"Topic :: Software Development :: Libraries :: Python Modules\",\n    ],\n    entry_points={\n        \"console_scripts\": [\n            \"sahi=sahi.cli:app\",\n        ],\n    },\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}