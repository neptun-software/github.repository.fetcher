{
  "metadata": {
    "timestamp": 1736559804344,
    "page": 532,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "FlagAI-Open/FlagAI",
      "stars": 3849,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5498046875,
          "content": "__pycache__\n.idea/\nlogs/\ntest_tokenizer.py\nsamples_text2image/\ngenerate_contexts/\nvenv/\n*__pycache__\n.DS_Store\n.vscode\n*.swo\n*.swp\n*log\nbuild\ndist\neazybigmodel.egg-info\nflagai.egg-info\ntest_report\n/data/\n/tests/*/data\ncheckpoints\ncheckpoints_in\ncheckpoints_out\nstate_dict\ncheckpoints*\nvocabs\ntensorboard*\ndatasets\nqqp\nglm_large_qqp_pytorch\nwandb\nclip_benchmark_datasets\nexamples/AltCLIP/clip_benchmark_datasets\nexamples/glm_pretrain/data.lazy\nexamples/glm_pretrain/examples/glm_pretrain/data.lazy\nexamples/vit_cifar100/cifar100\nexamples/vit_cifar100/data\noutput/\n"
        },
        {
          "name": "BAAI_Aquila_Model_License.pdf",
          "type": "blob",
          "size": 220.0595703125,
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.318359375,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n### Added\nCPM-1 model examples\n### Changed\n\n### Removed\n"
        },
        {
          "name": "CLA.md",
          "type": "blob",
          "size": 4.1025390625,
          "content": "# The Contributor License Agreement\n\nThe [Cloud Native Computing Foundation](https://www.cncf.io) (CNCF) defines\nthe legal status of the contributed code in two different types of _Contributor License Agreements_\n(CLAs), [individual contributors](https://github.com/cncf/cla/blob/master/individual-cla.pdf) and [corporations](https://github.com/cncf/cla/blob/master/corporate-cla.pdf).\n\nFlagAI can only accept original source code from CLA signatories.\n\n\nIt is important to read and understand this legal agreement.\n\n## How do I sign?\n\nAfter creating your first Pull Request the linux-foundation-easycla bot will respond with information regarding your CLA status along with a link to sign the CLA.\n\n<img width=\"1065\" alt=\"EasyCLA bot\" src=\"https://user-images.githubusercontent.com/69111235/152226443-f6fe61ee-0e92-46c5-b6ea-c0deb718a585.png\">\n\n#### 1. Authorize EasyCLA to read some of your GitHub information\n\n<img width=\"554\" alt=\"GitHub EasyCLA Authorization\" src=\"https://user-images.githubusercontent.com/69111235/152228712-7d22f9d0-9f3c-4226-9ee0-bacba4b47725.png\">\n\nClick on the \"Please click here to be authorized\" link to navigate to the GitHub Authorize Linux Foundation: EasyCLA page. Then click Authorize LF-Engineering to give the Linux Foundation read-only access to list the email addresses associated with your GitHub account.\n\n#### 2. Select from the two types of contributor\n\n<img width=\"1407\" alt=\"EasyCLA\" src=\"https://user-images.githubusercontent.com/69111235/152224818-1246453a-b086-4a57-9d14-c10d62ad438f.png\">\n\n\nAfter authorizing EasyCLA, you will be redirected to a page to identify which type of contributor you are. \nSelect the most appropriate option:\n  * Individual Contributor: You are contributing as yourself, and not as part of another organization.\n  * Corporate Contributor: You are contributing on behalf of your employer or other organization.\n\n#### 3. Sign the CLA\n\nOnce you select the type of contributor, proceed to Sign the CLA and follow the instructions to complete the signing process through DocuSign.\n\n**Ensure your GitHub e-mail address matches e-mail address used to sign CLA**\n\nAfter you have filled out  the information, Click \"Finish\" and you will be redirected back to your Pull Request.\n\n#### 4. Look for an email indicating successful signup.\n\n> Hello,\n> \n> This is a notification email from EasyCLA regarding the project Cloud Native Computing > Foundation (CNCF).\n> \n> The CLA has now been signed. You can download the signed CLA as a PDF here.\n> \n> If you need help or have questions about EasyCLA, you can read the documentation or reach out to us for support.\n> \n> Thanks,\n> EasyCLA Support Team\n\n\n\n#### 5. Validate your CLA\n\nOnce you are redirected back to your GitHub Pull Request, reply with a comment `/easycla` to update the CLA status of your PR.\n\n\n## Changing your Affiliation\n\nIf you've changed employers and still contribute to Kubernetes, your affiliation\nneeds to be updated. The Cloud Native Computing Foundation uses [gitdm](https://github.com/cncf/gitdm)\nto track who is contributing and from where. Create a pull request on the [gitdm](https://github.com/cncf/gitdm)\nrepository with a change to the corresponding developer affiliation text file.\nYour entry should look similar to this:\n\n```\nJorge O. Castro*: jorge!heptio.com, jorge!ubuntu.com, jorge.castro!gmail.com\nHeptio\nCanonical until 2017-03-31\n```\n\n## Troubleshooting\n\nIf you encounter any problems signing the CLA and need further assistance, log a ticket by clicking on the link [please submit a support request ticket](https://jira.linuxfoundation.org/plugins/servlet/theme/portal/4) from the EasyCLA bot's response. Someone from the CNCF will respond to your ticket to help.\n\nShould you have any issues using the LF Support Site, send a message to the\nbackup e-mail support address <login-issues@jira.linuxfoundation.org>\n\n## Setting up the CNCF CLA check\n\nIf you are a Kubernetes GitHub organization or repo owner and would like to setup\nthe Linux Foundation CNCF CLA check for your repositories, [read the docs on setting up the CNCF CLA check](/github-management/setting-up-cla-check.md)\n\n\n[Linux Foundation Support Site]: https://support.linuxfoundation.org/"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1943359375,
          "content": "All\tparticipants agree to abide by the Code of Conduct available at https://lfprojects.org/policies/code-of-conduct/. Please contact conduct@lfaidata.foundation to report any violations or concerns.\n"
        },
        {
          "name": "COMMITTERS.csv",
          "type": "blob",
          "size": 0.0634765625,
          "content": "Name, Email, Github ID\nGuang Liu, marscrazy_90@163.com, marcrazy\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.681640625,
          "content": "# Contributing to FlagAI\n\nWe are happy to accept your contributions to make `FlagAI` better and more awesome! To avoid unnecessary work on either\nside, please stick to the following process:\n\n1. Check if there is already [an issue](https://github.com/FlagAI-Open/FlagAI/issues) for your concern.\n2. If there is not, open a new one to start a discussion. We hate to close finished PRs!\n3. If we decide your concern needs code changes, we would be happy to accept a pull request. Please consider the\ncommit guidelines below.\n\n## Sign the CLA\n\nBefore you can contribute to FlagAI, you will need to sign the [Contributor License Agreement](CLA.md).\n\n## Git Commit Guidelines\n\nIf there is already a ticket, use this number at the start of your commit message.\nUse meaningful commit messages that described what you did.\n\n**Example:** `GH-42: Added new type of embeddings: DocumentEmbedding.`\n**Example:** `ISSUE#123: Fix typo in README.`\n\n\n## Developing locally\n\nFor contributors looking to get deeper into the API we suggest cloning the repository and checking out the unit\ntests for examples of how to call methods. Nearly all classes and methods are documented, so finding your way around\nthe code should hopefully be easy.\n\n### setup\n\nYou can either use [Pipenv](https://pipenv.readthedocs.io/) for this:\n\nor create a python environment of your preference and run\n```bash\npython setup.py install\n```\n\n### tests\nInstall `pytest` for testing\n```\npip install pytest\n```\nTo run all basic tests execute:\n```bash\npytest\n```\n\n### code formatting\n\nTo ensure a standardized code style we use the formatter [yapf](https://github.com/google/yapf).\nYou can automatically format the code via `yapf flagai/ -i` in the flair root folder.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.1337890625,
          "content": "FROM nvcr.io/nvidia/cuda:11.7.0-devel-ubuntu20.04\n\nLABEL zhanglu0704\n\nENV TZ=Asia/Shanghai\n\nVOLUME /etc/localtime\n\nENV WORK_DID=/workspace\n\nWORKDIR ${WORK_DID}\n\nRUN apt update && \\\n    apt install -y g++ gcc cmake curl wget vim unzip git openssh-server net-tools python3-packaging && \\\n    apt install -y python3.9 python3.9-dev python3-pip && \\\n    apt clean -y && \\\n    rm -rf /var/cache/apt/archives \n\nRUN rm /usr/bin/python3 && \\\n    ln -s /usr/bin/python3.9 /usr/bin/python3 && \\\n    ln -s /usr/bin/python3 /usr/bin/python && \\\n    python -m pip install --upgrade pip\n\nRUN pip install torch==1.13.0+cu117 torchvision==0.14.0+cu117 torchaudio==0.13.0 \\\n    --extra-index-url https://download.pytorch.org/whl/cu117\n\nCOPY requirements.txt  ${WORK_DID}/\n\nRUN python -m pip install -r ${WORK_DID}/requirements.txt\n\nRUN git clone https://github.com/NVIDIA/apex && \\\n    cd apex && \\\n    # git checkout -f 23.05 && \\\n    # pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" . && \\\n    pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" . && \\\n    cd ../ && rm -rf apex\n\nRUN git clone https://github.com/OpenBMB/BMTrain && \\\n    cd BMTrain && \\\n    git checkout -f 0.2.2 && \\\n    # python setup.py install --prefix=/usr/local/\n    pip install -v . && \\\n    cd ../ && rm -rf BMTrain\n\nRUN git clone https://github.com/FlagAI-Open/FlagAI.git && \\\n    cd FlagAI && \\\n    pip install -v . && \\\n    cd ../ && rm -rf FlagAI\n\nRUN echo \"ClientAliveInterval 30\" >> /etc/ssh/sshd_config && \\\n    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config && \\\n    echo \"StrictHostKeyChecking no\" >> /etc/ssh/ssh_config && \\\n    echo \"UserKnownHostsFile /dev/null\" >> /etc/ssh/ssh_config\n\nRUN ssh-keygen -t rsa -f /root/.ssh/id_rsa -N \"\" && \\\n    cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys && \\\n    chmod og-wx /root/.ssh/authorized_keys\n\nCMD service ssh start && tail -f /dev/null\n\n# sudo docker build -f Dockerfile --shm-size='120g' -t flagai:dev-ubuntu20-cuda11.7-py39 .\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 4.0390625,
          "content": "*NOTE: This document is intended to provide an example governance structure for any LF AI and Data Foundation project to consider as a starting point. All projects hosted by LF AI and Data Foundation are not bound by these governance polices, but in absence of any prior governance structure should consider this as a recommended structure*\n\n# Overview\n\nThis project aims to be governed in a transparent, accessible way for the benefit of the community. All participation in this project is open and not bound to corporate affilation. Participants are bound to the project's [Code of Conduct](./CODE_OF_CONDUCT.md).\n\n# Project roles\n\n## Contributor\n\nThe contributor role is the starting role for anyone participating in the project and wishing to contribute code.\n\n# Process for becoming a contributor\n\n* Review the [Contribution Guidelines](./CONTRIBUTING.md) to ensure your contribution is inline with the project's coding and styling guidelines.\n* Submit your code as a PR with the appropriate DCO signoff\n* Have your submission approved by the committer(s) and merged into the codebase.\n\n## Committer\n\nThe committer role enables the contributor to commit code directly to the repository, but also comes with the responsibility of being a responsible leader in the community.\n\n### Process for becoming a committer\n\n* Show your experience with the codebase through contributions and engagement on the community channels.\n* Request to become a committer. To do this, create a new pull request that adds your name and details to the [Committers File](./COMMITTERS.csv) file and request existing committers to approve.\n* After the majority of committers approve you, merge in the PR. Be sure to tag the whomever is managing the GitHub permissions to update the committers team in GitHub.\n\n### Committer responsibilities\n\n* Monitor email aliases (if any).\n* Monitor Slack (delayed response is perfectly acceptable).\n* Triage GitHub issues and perform pull request reviews for other committers and the community.\n* Make sure that ongoing PRs are moving forward at the right pace or closing them.\n* In general continue to be willing to spend at least 25% of ones time working on the project (~1.25 business days per week).\n\n### When does a committer lose committer status\n\nIf a committer is no longer interested or cannot perform the committer duties listed above, they\nshould volunteer to be moved to emeritus status. In extreme cases this can also occur by a vote of\nthe committers per the voting process below.\n\n## Lead\n\nThe project committers will elect a lead ( and optionally a co-lead ) which will be the primary point of contact for the project and representative to the TAC upon becoming an Active stage project. The lead(s) will be responsible for the overall project health and direction, coordination of activities, and working with other projects and committees as needed for the continuted growth of the project.\n\n# Release Process\n\nProject releases will occur on a scheduled basis as agreed to by the committers.\n\n# Conflict resolution and voting\n\nIn general, we prefer that technical issues and committer membership are amicably worked out\nbetween the persons involved. If a dispute cannot be decided independently, the committers can be\ncalled in to decide an issue. If the committers themselves cannot decide an issue, the issue will\nbe resolved by voting. The voting process is a simple majority in which each committer receives one vote.\n\n# Communication\n\nThis project, just like all of open source, is a global community. In addition to the [Code of Conduct](./CODE_OF_CONDUCT.md), this project will:\n\n* Keep all communucation on open channels ( mailing list, forums, chat ).\n* Be respectful of time and language differences between community members ( such as scheduling meetings, email/issue responsiveness, etc ).\n* Ensure tools are able to be used by community members regardless of their region.\n\nIf you have concerns about communication challenges for this project, please contact the committers.\n\n[Code of Conduct]: CODE_OF_CONDUCT.md\n[Committers File]: COMMITTERS.csv\n[Contribution Guidelines]: CONTRIBUTING.md\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.9794921875,
          "content": "Copyright Â© 2022 BAAI. All rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 19.626953125,
          "content": "[<img src=\"flagopen.jpeg\">](https://flagopen.baai.ac.cn/)\n![FlagAI](logo.png)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6052/badge)](https://bestpractices.coreinfrastructure.org/projects/6052)\n[![Python application](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg)](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml)\n![GitHub release (release name instead of tag name)](https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&style=social)\n\n[ç®€ä½“ä¸­æ–‡](README_zh.md)\n\n--------------------------------------------------------------------------------\n\n\nFlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.\n\n\n\n## Why should I use FlagAI?\n\n\n1. **Quickly Download Models via API**\n\n    FlagAI provides an API that allows you to quickly download pre-trained models and fine-tune them on a wide range of datasets collected from [SuperGLUE](https://super.gluebenchmark.com/) and [CLUE](https://github.com/CLUEbenchmark/CLUE) benchmarks for both Chinese and English text.\n\n    FlagAI now supports over 30 mainstream models, including Language Model [**Aquila**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila), multilingual text and image representation model [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP), text-to-image generation model [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) [![Huggingface space](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Space-cyan.svg)](https://huggingface.co/spaces/BAAI/bilingual_stable_diffusion), [**WuDao GLM**](/docs/GLM.md) (with a maximum of 10 billion parameters), [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP), **OPT**, **BERT**, **RoBERTa**, **GPT2**, **T5**, **ALM**, and models from **Huggingface Transformers**, etc.\n    \n\n2. **Parallel train with fewer than 10 lines of code**\n\n\tBacked by the four most popular data/model parallel libraries -- [PyTorch](https://pytorch.org/), [Deepspeed](https://www.deepspeed.ai/), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [BMTrain](https://github.com/OpenBMB/BMTrain) -- FlagAI allows for seamless integration between them, enabling users to parallel their training/testing process with fewer than ten lines of code.\n\n\n3. **Conveniently use the few-shot learning toolkits**\n   \n    FlagAI also provides [prompt-learning](/docs/TUTORIAL_7_PROMPT_LEARNING.md) toolkit for few-shot tasks.\n\n4. **Particularly good at Chinese tasks**\n\n    These models can be applied to (Chinese/English) Text, for tasks like text classification, information extraction, question answering, summarization, and text generation, with a particular focus on Chinese tasks.\n\n\n## Toolkits and Pre-trained Models \n\n> The code is partially based on [GLM](https://github.com/THUDM/GLM), [Transformers](https://github.com/huggingface/transformers)ï¼Œ[timm](https://github.com/rwightman/pytorch-image-models) and [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM).\n\n\n### Toolkits\n\n\n| Name       | Description       | Examples            |\n|:-------------- |:---------- |:------------------------------------------------------ |\n| \t`GLM_custom_pvp` | Customizing PET templates   | [README.md](http:///examples/glm_custom_pvp/README.md) |\n| `GLM_ptuning`    | p-tuning tool | â€”â€”                                                     |\n| `BMInf-generate` | Accelerating generation | [README.md](http:///examples/bminf_generate/README.md) | \n\n\n### Pre-trained Models \n\n\n|   Model          |  Task    | Train | Finetune | Inference/Generate | Examples       |                                                         \n| :---------------- | :------- | :-- |:-- | :-- | :--------------------------------------------- |\n| Aquila      | Natural Language Processing  | âœ…  | âœ…  | âœ…  | [README.md](examples/Aquila/README.md) \n| ALM          | Arabic Text Generation  |  âœ…  | âŒ  | âœ…  | [README.md](/examples/ALM/README.md)  |                         \n| AltCLIP       | Image-Text Matching  | âœ…  | âœ…  | âœ…  | [README.md](/examples/AltCLIP/README.md)   |  \n| AltCLIP-m18      | Image-Text Matching  | âœ…  | âœ…  | âœ…  | [README.md](examples/AltCLIP-m18/README.md)   |                             \n| AltDiffusion    | Text-to-Image Generation    | âŒ  | âŒ  | âœ…  | [README.md](/examples/AltDiffusion/README.md)    |\n| AltDiffusion-m18    | Text-to-Image Generation,supporting 18 languages    | âŒ  | âŒ  | âœ…  |[README.md](/examples/AltDiffusion-m18/README.md)   |\n| BERT-title-generation-english     | English Title Generation | âœ…  | âŒ  | âœ…  | [README.md](/examples/bert_title_generation_english/README.md) |\n| CLIP           | Image-Text Matching    | âœ…  | âŒ  | âœ…  | â€”â€”   |                                                                 \n| CPM3-finetune       | Text Continuation   | âŒ  | âœ…  | âŒ  | â€”â€”    |                                                                \n| CPM3-generate    | Text Continuation  | âŒ  | âŒ  | âœ…  | â€”â€”   |                                                                 \n| CPM3_pretrain    | Text Continuation  | âœ…  | âŒ  | âŒ  | â€”â€”        |\n| CPM_1     | Text Continuation   | âŒ  | âŒ  | âœ…  | [README.md](/examples/cpm_1/README.md)      |\n| EVA-CLIP                          | Image-Text Matching  | âœ…  | âœ…  | âœ…  | [README.md](/examples/EVA_CLIP/README.md)                             |\n| Galactica       | Text Continuation    | âŒ  | âŒ  | âœ…  | â€”â€”      |                                                              \n| GLM-large-ch-blank-filling        | Blank Filling     | âŒ  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_11_GLM_BLANK_FILLING_QA.md)               |\n| GLM-large-ch-poetry-generation    | Poetry Generation     | âœ…  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md)       |\n| GLM-large-ch-title-generation     | Title Generation   | âœ…  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md)        |\n| GLM-pretrain         | Pre-Train    | âœ…  | âŒ  | âŒ  | â€”â€”   |                                                                 \n| GLM-seq2seq        | Generation    | âœ…  | âŒ  | âœ…  | â€”â€”     |                                                               \n| GLM-superglue      | Classification  | âœ…  | âŒ  | âŒ  | â€”â€”     |                                                               \n| GPT-2-text-writting      | Text Continuation   | âŒ  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_18_GPT2_WRITING.md)        |\n| GPT2-text-writting                | Text Continuation   | âŒ  | âŒ  | âœ…  | â€”â€” |                                                                   \n| GPT2-title-generation             | Title Generation   | âŒ  | âŒ  | âœ…  | â€”â€”  |                                                                  \n| OPT                               | Text Continuation   | âŒ  | âŒ  | âœ…  | [README.md](/examples/opt/README.md) |                                  \n| RoBERTa-base-ch-ner               | Named Entity Recognition| âœ…  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_17_BERT_EXAMPLE_NER.md)     |\n| RoBERTa-base-ch-semantic-matching |Semantic Similarity Matching | âœ…  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md)      |\n| RoBERTa-base-ch-title-generation  | Title Generation     | âœ…  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md)       |\n| RoBERTa-faq      |   Question-Answer   | âŒ  | âŒ  | âœ…  | [README.md](/examples/roberta_faq/README.md) |         \n| Swinv1                            | Image Classification | âœ…  | âŒ  | âœ…  | â€”â€”  |                                                                  \n| Swinv2                            | Image Classification   | âœ…  | âŒ  | âœ…  | â€”â€”     |                                                               \n| T5-huggingface-11b                | Train   | âœ…  | âŒ  | âŒ  | [TUTORIAL](/docs/TUTORIAL_14_HUGGINGFACE_T5.md)                      |\n| T5-title-generation               | Title Generation     | âŒ  | âŒ  | âœ…  | [TUTORIAL](/docs/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md)                |\n| T5-flagai-11b                     | Pre-Train  | âœ…  | âŒ  | âŒ  | â€”â€”    |                                                                \n| ViT-cifar100                      |  Pre-Train  | âœ…  | âŒ  | âŒ  | â€”â€” |\n\n\n> * More excamples in  [./examples](https://github.com/FlagAI-Open/FlagAI/tree/master/examples) \n> * More tutorials in [./docs](https://github.com/FlagAI-Open/FlagAI/tree/master/doc) \n\n\n\n\n## Contributing\n\nThanks for your interest in contributing! There are many ways to get involved;\nstart with our [contributor guidelines](CONTRIBUTING.md) and then\ncheck these [open issues](https://github.com/FlagAI-Open/FlagAI/issues) for specific tasks.\n\n\n## Contact us\n\nWelcome to raise your questions or feature requests on [GitHub Issues](https://github.com/FlagAI-Open/FlagAI/issues) , and share your experience on the  [Discussions](https://github.com/FlagAI-Open/FlagAI/discussions) board.\n\n* Official email: open.platform@baai.ac.cn.\n* Zhihu: [FlagAI](https://www.zhihu.com/people/95-22-20-18)\n* Scan the qrcode to join the WeChat group for communication:\n\n<img src=\"./wechat-qrcode.jpg\" width = \"200\" height = \"200\"  align=center />\n\n\n## Quick Start\nWe provide many models which are trained to perform different tasks. You can load these models by AutoLoader to make prediction. See more in `FlagAI/quickstart`.\n\n### Requirements and Installation\n* Python version >= 3.8\n* PyTorch version >= 1.8.0\n* [Optional] For training/testing models on GPUs, you'll also need to install CUDA and NCCL\n\n- To install FlagAI with pip:\n```shell\npip install -U flagai\n```\n\n- [Optional] To install FlagAI and develop locally:\n\n```shell\ngit clone https://github.com/FlagAI-Open/FlagAI.git\npython setup.py install\n```\n\n- [Optional] For faster training, install NVIDIA's [apex](https://github.com/NVIDIA/apex)\n```\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n- [Optional] For ZeRO optimizers, install [DEEPSPEED](https://github.com/microsoft/DeepSpeed) (>= 0.7.7)\n```\ngit clone https://github.com/microsoft/DeepSpeed\ncd DeepSpeed\nDS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .\nds_report # check the deespeed status\n```\n- [Optional] For BMTrain training, install [BMTrain](https://github.com/OpenBMB/BMTrain) (>= 0.2.2)\n```\ngit clone https://github.com/OpenBMB/BMTrain\ncd BMTrain\npython setup.py install\n```\n- [Optional] For BMInf low-resource inference, install [BMInf](https://github.com/OpenBMB/BMInf)\n```\npip install bminf\n\n```\n- [Optional] For Flash Attention, install [Flash-attention](https://github.com/HazyResearch/flash-attention) (>=1.0.2)\n```\npip install flash-attn\n```\n\n- [Tips] For single-node docker environments, we need to set up ports for your ssh. e.g., root@127.0.0.1 with port 711\n```\n>>> vim ~/.ssh/config\nHost 127.0.0.1\n    Hostname 127.0.0.1\n    Port 7110\n    User root\n```\n- [Tips] For multi-node docker environments, generate ssh keys and copy the public key to all nodes (in `~/.ssh/`)\n```\n>>> ssh-keygen -t rsa -C \"xxx@xxx.com\"\n```\n\n\n### Load model and tokenizer\nWe provide the AutoLoad class to load the model and tokenizer quickly, for example:\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\n\nauto_loader = AutoLoader(\n    task_name=\"title-generation\",\n    model_name=\"BERT-base-en\"\n)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n```\nThis example is for the `title_generation` task, and you can also model other tasks by modifying the `task_name`.\nThen you can use the model and tokenizer to fine-tune or test.\n\n### Examples\n\n#### 1. Predictor \n\nWe provide the `Predictor` class to predict for different tasks, for example:\n\n```python\nfrom flagai.model.predictor.predictor import Predictor\npredictor = Predictor(model, tokenizer)\ntest_data = [\n    \"Four minutes after the red card, Emerson Royal nodded a corner into the path of the unmarked Kane at the far post, who nudged the ball in for his 12th goal in 17 North London derby appearances. Arteta's misery was compounded two minutes after half-time when Kane held the ball up in front of goal and teed up Son to smash a shot beyond a crowd of defenders to make it 3-0.The goal moved the South Korea talisman a goal behind Premier League top scorer Mohamed Salah on 21 for the season, and he looked perturbed when he was hauled off with 18 minutes remaining, receiving words of consolation from Pierre-Emile Hojbjerg.Once his frustrations have eased, Son and Spurs will look ahead to two final games in which they only need a point more than Arsenal to finish fourth.\",\n]\n\nfor text in test_data:\n    print(\n        predictor.predict_generate_beamsearch(text,\n                                              out_max_length=50,\n                                              beam_size=3))\n```\nThis example is for the `seq2seq` task, where we can get `beam-search` results by calling the `predict_generate_beamsearch` function. In addition, we also support prediction for tasks such as `NER` and `title generate`.\n\n\n#### 2. NER \n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\ntask_name = \"ner\"\nmodel_name = \"RoBERTa-base-ch\"\ntarget = [\"O\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\", \"B-PER\", \"I-PER\"]\nmaxlen = 256\n\nauto_loader = AutoLoader(task_name,\n                         model_name=model_name,\n                         load_pretrain_params=True,\n                         class_num=len(target))\n\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [\n    \"6æœˆ15æ—¥ï¼Œæ²³å—çœæ–‡ç‰©è€ƒå¤ç ”ç©¶æ‰€æ›¹æ“é«˜é™µæ–‡ç‰©é˜Ÿå…¬å¼€å‘è¡¨å£°æ˜æ‰¿è®¤ï¼šâ€œä»æ¥æ²¡æœ‰è¯´è¿‡å‡ºåœŸçš„ç å­æ˜¯å¢“ä¸»äººçš„\",\n    \"4æœˆ8æ—¥ï¼ŒåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šæ€»ç»“è¡¨å½°å¤§ä¼šåœ¨äººæ°‘å¤§ä¼šå ‚éš†é‡ä¸¾è¡Œã€‚ä¹ è¿‘å¹³æ€»ä¹¦è®°å‡ºå¸­å¤§ä¼šå¹¶å‘è¡¨é‡è¦è®²è¯ã€‚åœ¨è®²è¯ä¸­ï¼Œæ€»ä¹¦è®°å……åˆ†è‚¯å®šäº†åŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šå–å¾—çš„ä¼˜å¼‚æˆç»©ï¼Œå…¨é¢å›é¡¾äº†7å¹´ç­¹åŠå¤‡èµ›çš„ä¸å‡¡å†ç¨‹ï¼Œæ·±å…¥æ€»ç»“äº†ç­¹å¤‡ä¸¾åŠåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šçš„å®è´µç»éªŒï¼Œæ·±åˆ»é˜é‡Šäº†åŒ—äº¬å†¬å¥¥ç²¾ç¥ï¼Œå¯¹è¿ç”¨å¥½å†¬å¥¥é—äº§æ¨åŠ¨é«˜è´¨é‡å‘å±•æå‡ºæ˜ç¡®è¦æ±‚ã€‚\",\n    \"å½“åœ°æ—¶é—´8æ—¥ï¼Œæ¬§ç›Ÿå§”å‘˜ä¼šè¡¨ç¤ºï¼Œæ¬§ç›Ÿå„æˆå‘˜å›½æ”¿åºœç°å·²å†»ç»“å…±è®¡çº¦300äº¿æ¬§å…ƒä¸ä¿„ç½—æ–¯å¯¡å¤´åŠå…¶ä»–è¢«åˆ¶è£çš„ä¿„æ–¹äººå‘˜æœ‰å…³çš„èµ„äº§ã€‚\",\n    \"è¿™ä¸€ç›˜å£çŠ¶æ€ä¸‹è‹±å›½å¿…å‘å…¬å¸äºšæ´²ç›˜äº¤æ˜“æ•°æ®æ˜¾ç¤ºåšæ´›å°¼äºšçƒ­ã€‚è€Œä»æ¬§èµ”æŠ•æ³¨çœ‹ï¼Œä¹Ÿæ˜¯ä¸»é˜Ÿçƒ­ã€‚å·´å‹’è«ä¸¤è¿è´¥ï¼Œ\",\n]\n\nfor t in test_data:\n    entities = predictor.predict_ner(t, target, maxlen=maxlen)\n    result = {}\n    for e in entities:\n        if e[2] not in result:\n            result[e[2]] = [t[e[0]:e[1] + 1]]\n        else:\n            result[e[2]].append(t[e[0]:e[1] + 1])\n    print(f\"result is {result}\")\n```\n\n#### 3. Semantic Matching example\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\nmaxlen = 256\n\nauto_loader = AutoLoader(\"semantic-matching\",\n                         model_name=\"RoBERTa-base-ch\",\n                         load_pretrain_params=True,\n                         class_num=2)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [[\"åæ‚”äº†å—\", \"ä½ æœ‰æ²¡æœ‰åæ‚”\"], [\"æ‰“å¼€è‡ªåŠ¨æ¨ªå±\", \"å¼€å¯ç§»åŠ¨æ•°æ®\"],\n             [\"æˆ‘è§‰å¾—ä½ å¾ˆèªæ˜\", \"ä½ èªæ˜æˆ‘æ˜¯è¿™ä¹ˆè§‰å¾—\"]]\n\nfor text_pair in test_data:\n    print(predictor.predict_cls_classifier(text_pair))\n\n```\n\n\n\n## LICENSE\n\nThe majority of FlagAI is licensed under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0), however portions of the project are available under separate license terms:\n\n* Megatron-LM is licensed under the [Megatron-LM license](https://github.com/NVIDIA/Megatron-LM/blob/main/LICENSE)\n* GLM is licensed under the [MIT license](https://github.com/THUDM/GLM/blob/main/LICENSE)\n* AltDiffusion is licensed under the [CreativeML Open RAIL-M license](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n\n\n\n## News\n- [9 June 2023] release v1.7.0, Support Aquila [#324](https://github.com/FlagAI-Open/FlagAI/pull/324);\n- [31 Mar 2023] release v1.6.3, Support AltCLIP-m18 [#303](https://github.com/FlagAI-Open/FlagAI/pull/303) and AltDiffusion-m18 [#302](https://github.com/FlagAI-Open/FlagAI/pull/302); \n- [17 Mar 2023] release v1.6.2, Support application of new optimizers [#266](https://github.com/FlagAI-Open/FlagAI/pull/266), and added a new gpt model name 'GPT2-base-en' for English; \n- [2 Mar 2023] release v1.6.1, Support Galactica model [#234](https://github.com/FlagAI-Open/FlagAI/pull/234); BMInf, a low-resource inference package [#238](https://github.com/FlagAI-Open/FlagAI/pull/238), and examples for p-tuning [#227](https://github.com/FlagAI-Open/FlagAI/pull/238)\n- [12 Jan 2023] release v1.6.0, support a new parallel lib called [**BMTrain**](https://github.com/OpenBMB/BMTrain) and integate [**Flash Attention**](https://github.com/HazyResearch/flash-attention) to speedup training of BERT and ViT models, examples in [FlashAttentionBERT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/bert_title_generation_english/train_flash_atten.py) and [FlashAttentionViT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/vit_cifar100/train_single_gpu_flash_atten.py). Also add the contrastive search based text generation method [**SimCTG**](https://github.com/yxuansu/SimCTG) and DreamBooth finetuning based on AltDiffusion, examples in [AltDiffusionNaruto](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/AltDiffusion/dreambooth.py). \n- [28 Nov 2022] release v1.5.0, support 1.1B [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP) and [ALM: A large Arabic Language Model based on GLM], examples in [**ALM**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/ALM)\n- [10 Nov 2022] release v1.4.0, support [AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities](https://arxiv.org/abs/2211.06679v1), examples in [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP) and [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)\n- [29 Aug 2022] release v1.3.0, Added CLIP module and redesigned tokenizer APIs in [#81](https://github.com/FlagAI-Open/FlagAI/pull/81)\n- [21 Jul 2022] release v1.2.0, ViTs are supported in [#71](https://github.com/FlagAI-Open/FlagAI/pull/71)\n- [29 Jun 2022] release v1.1.0, support OPTs downloading and inference/fine-tuning [#63](https://github.com/FlagAI-Open/FlagAI/pull/63)\n- [17 May 2022] made our first contribution in [#1](https://github.com/FlagAI-Open/FlagAI/pull/1)\n\n## Platforms supported\n\n<div  align=\"center\">    \n<img src=\"./examples/Aquila/img/merged_platform.jpg\" height = \"100\" align=center />\n</div>\n\n\n\n## Misc\n\n### &#8627; Stargazers, thank you for your support!\n[![Stargazers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/stars/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/stargazers)\n\n### &#8627; Forkers, thank you for your support!\n[![Forkers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/forks/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/network/members)\n\n### &#8627; Star History\n<div align=\"center\">\n\n![Star History Chart](https://api.star-history.com/svg?repos=FlagAI-Open/FlagAI&type=Date)]\n\n</div>\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 19.20703125,
          "content": "[<img src=\"flagopen.jpeg\">](https://flagopen.baai.ac.cn/)\n![FlagAI](logo.png)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6052/badge)](https://bestpractices.coreinfrastructure.org/projects/6052)\n[![Python application](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg)](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml)\n![GitHub release (release name instead of tag name)](https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&style=social)\n\n[English](README.md)\n\n--------------------------------------------------------------------------------\n\n\n**FlagAIé£æ™º**æ˜¯ä¸€ä¸ªå¿«é€Ÿã€æ˜“äºä½¿ç”¨å’Œå¯æ‰©å±•çš„å¤§æ¨¡å‹å·¥å…·åŒ…ã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ”¯æŒåœ¨å¤šæ¨¡æ€çš„å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šè®­ç»ƒã€å¾®è°ƒå’Œéƒ¨ç½²å¤§è§„æ¨¡æ¨¡å‹ã€‚\n<br><br>\n\n## ä¸ºä»€ä¹ˆä½ éœ€è¦ FlagAI?\n\n1. **å¯é€šè¿‡ API å¿«é€Ÿä¸‹è½½æ¨¡å‹**\n      \n    æä¾› API æ–¹ä¾¿ä½ å¿«é€Ÿä¸‹è½½æ¨¡å‹ï¼Œå¹¶åœ¨ç»™å®šï¼ˆä¸­/è‹±æ–‡ï¼‰æ–‡æœ¬ä¸Šä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ï¼Œåœ¨ä»[SuperGLUE](https://super.gluebenchmark.com/)å’Œ[CLUE](https://github.com/CLUEbenchmark/CLUE) benchmarksæ”¶é›†çš„å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šå¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒã€‚\n     \n      FlagAI ç°å·²æ”¯æŒ 30+ ä¸»æµæ¨¡å‹ï¼ŒåŒ…æ‹¬è¯­è¨€æ¨¡å‹[**Aquila**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila), å¤šæ¨¡æ€æ¨¡å‹ [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP) ã€æ–‡ç”Ÿå›¾æ¨¡å‹ [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) [![Huggingface space](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Space-cyan.svg)](https://huggingface.co/spaces/BAAI/bilingual_stable_diffusion)ã€æœ€é«˜ç™¾äº¿å‚æ•°çš„ **[æ‚Ÿé“GLM](/doc_zh/GLM.md)**ï¼Œ[**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP)ã€**[Galactica](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/galactica)**ã€**OPT**ã€**BERT**ã€**RoBERTa**ã€**GPT2**ã€**T5**ã€**ALM**ã€**Huggingface Transformers** ç­‰ã€‚\n      \n2.  **ä»…ç”¨åè¡Œä»£ç å³å¯è¿›è¡Œå¹¶è¡Œè®­ç»ƒ**\n\n    é£æ™ºç”±å››ä¸ªæœ€æµè¡Œçš„æ•°æ®/æ¨¡å‹å¹¶è¡Œåº“ï¼ˆ[PyTorch](https://pytorch.org/)/[Deepspeed](https://www.deepspeed.ai/)/[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)/[BMTrain](https://github.com/OpenBMB/BMTrain)ï¼‰æä¾›æ”¯æŒï¼Œå®ƒä»¬ä¹‹é—´å®ç°äº†æ— ç¼é›†æˆã€‚ ä½ å¯ä»¥ç”¨ä¸åˆ°åè¡Œä»£ç æ¥å¹¶è¡Œä½ çš„è®­ç»ƒ/æµ‹è¯•è¿‡ç¨‹ã€‚\n   \n3.  **æä¾›æç¤ºå­¦ä¹ å·¥å…·åŒ…**\n\n    FlagAI æä¾›äº†æç¤ºå­¦ä¹ ï¼ˆ[prompt-learning](https://github.com/FlagAI-Open/FlagAI/blob/master/docs/TUTORIAL_7_PROMPT_LEARNING.md)ï¼‰çš„å·¥å…·åŒ…ï¼Œç”¨äºå°‘æ ·æœ¬å­¦ä¹ (few-shot learning)ä»»åŠ¡ã€‚\n   \n4.  **å°¤å…¶æ“…é•¿ä¸­æ–‡ä»»åŠ¡**\n\n    FlagAI ç›®å‰æ”¯æŒçš„æ¨¡å‹å¯ä»¥åº”ç”¨äºæ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æå–ã€é—®ç­”ã€æ‘˜è¦ã€æ–‡æœ¬ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œå°¤å…¶æ“…é•¿ä¸­æ–‡ä»»åŠ¡ã€‚\n\n\n\n## å·¥å…·åŒ…åŠå·²æ”¯æŒçš„æ¨¡å‹\n\n> æœ¬é¡¹ç›®çš„éƒ¨åˆ†ä»£ç åŸºäº [GLM](https://github.com/THUDM/GLM)ï¼Œ[Transformers](https://github.com/huggingface/transformers)ï¼Œ[timm](https://github.com/rwightman/pytorch-image-models) å’Œ [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM).\n\n\n### å·¥å…·\n\n| å·¥å…·åç§°           | æè¿°         | æ ·ä¾‹                |\n|:-------------- |:---------- |:------------------------------------------------------ |\n| \t`GLM_custom_pvp` | è‡ªå®šä¹‰ PET æ¨¡æ¿   | [README.md](./examples/glm_custom_pvp/README.md) |\n| `GLM_ptuning`    | p-tuning å·¥å…· | â€”â€”                                                     |\n| `BMInf-generate` | æ¨ç†åŠ é€Ÿ    | [README.md](./examples/bminf_generate/README.md) |\n\n### æ¨¡å‹\n\n|    æ¨¡å‹åç§°            | ä»»åŠ¡      | è®­ç»ƒ | å¾®è°ƒ | æ¨ç† | æ ·ä¾‹           |                                                         \n| :---------------- | :------- | :-- |:-- | :-- | :--------------------------------------------- |\n| Aquila      | è‡ªç„¶è¯­è¨€å¤„ç†  | âœ…  | âœ…  | âœ…  | [README.md](examples/Aquila/README.md) \n| ALM          | é˜¿æ‹‰ä¼¯è¯­æ–‡æœ¬ç”Ÿæˆ   |  âœ…  | âŒ  | âœ…  | [README.md](/examples/ALM/README.md)  |                         \n| AltCLIP       | æ–‡å›¾åŒ¹é… | âœ…  | âœ…  | âœ…  | [README.md](/examples/AltCLIP/README.md)   |  \n| AltCLIP-m18      | æ–‡å›¾åŒ¹é…  | âœ…  | âœ…  | âœ…  | [README.md](examples/AltCLIP-m18/README.md)   |                             \n| AltDiffusion    | æ–‡ç”Ÿå›¾  | âŒ  | âŒ  | âœ…  | [README.md](/examples/AltDiffusion/README.md)    |\n| AltDiffusion-m18    | æ–‡ç”Ÿå›¾ï¼Œæ”¯æŒ 18 ç§è¯­è¨€   | âŒ  | âŒ  | âœ…  | [README.md](/examples/AltDiffusion-m18/README.md)   |\n| BERT-title-generation-english     | è‹±æ–‡æ ‡é¢˜ç”Ÿæˆ  | âœ…  | âŒ  | âœ…  | [README.md](/examples/bert_title_generation_english/README.md) |\n| CLIP           | å›¾æ–‡åŒ¹é…    | âœ…  | âŒ  | âœ…  | â€”â€”   |                                                                 \n| CPM3-finetune       | æ–‡æœ¬ç»­å†™    | âŒ  | âœ…  | âŒ  | â€”â€”    |                                                                \n| CPM3-generate    | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | â€”â€”   |                                                                 \n| CPM3_pretrain    | æ–‡æœ¬ç»­å†™    | âœ…  | âŒ  | âŒ  | â€”â€”        |\n| CPM_1     | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | [README.md](/examples/cpm_1/README.md)      |\n| EVA-CLIP                          | å›¾æ–‡åŒ¹é…    | âœ…  | âœ…  | âœ…  | [README.md](/examples/EVA_CLIP/README.md)                             |\n| Galactica       | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | â€”â€”      |                                                              \n| GLM-large-ch-blank-filling        | å®Œå½¢å¡«ç©ºé—®ç­”  | âŒ  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_11_GLM_BLANK_FILLING_QA.md)               |\n| GLM-large-ch-poetry-generation    | è¯—æ­Œç”Ÿæˆ    | âœ…  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md)       |\n| GLM-large-ch-title-generation     | æ ‡é¢˜ç”Ÿæˆ    | âœ…  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md)        |\n| GLM-pretrain         | é¢„è®­ç»ƒ     | âœ…  | âŒ  | âŒ  | â€”â€”   |                                                                 \n| GLM-seq2seq        | ç”Ÿæˆä»»åŠ¡    | âœ…  | âŒ  | âœ…  | â€”â€”     |                                                               \n| GLM-superglue      | åˆ¤åˆ«ä»»åŠ¡    | âœ…  | âŒ  | âŒ  | â€”â€”     |                                                               \n| GPT-2-text-writting      | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_18_GPT2_WRITING.md)        |\n| GPT2-text-writting                | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | â€”â€” |                                                                   \n| GPT2-title-generation             | æ ‡é¢˜ç”Ÿæˆ    | âŒ  | âŒ  | âœ…  | â€”â€”  |                                                                  \n| OPT                               | æ–‡æœ¬ç»­å†™    | âŒ  | âŒ  | âœ…  | [README.md](/examples/opt/README.md) |                                  \n| RoBERTa-base-ch-ner               | å‘½åå®ä½“è¯†åˆ«  | âœ…  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_17_BERT_EXAMPLE_NER.md)     |\n| RoBERTa-base-ch-semantic-matching | è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é… | âœ…  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md)      |\n| RoBERTa-base-ch-title-generation  | æ ‡é¢˜ç”Ÿæˆ    | âœ…  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md)       |\n| RoBERTa-faq      | é—®ç­”      | âŒ  | âŒ  | âœ…  | [README.md](/examples/roberta_faq/README.md) |         \n| Swinv1                            | å›¾ç‰‡åˆ†ç±»    | âœ…  | âŒ  | âœ…  | â€”â€”  |                                                                  \n| Swinv2                            | å›¾ç‰‡åˆ†ç±»    | âœ…  | âŒ  | âœ…  | â€”â€”     |                                                               \n| T5-huggingface-11b                | è®­ç»ƒ      | âœ…  | âŒ  | âŒ  | [TUTORIAL](/doc_zh/TUTORIAL_14_HUGGINGFACE_T5.md)                      |\n| T5-title-generation               | æ ‡é¢˜ç”Ÿæˆ    | âŒ  | âŒ  | âœ…  | [TUTORIAL](/doc_zh/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md)                |\n| T5-flagai-11b                     | é¢„è®­ç»ƒ     | âœ…  | âŒ  | âŒ  | â€”â€”    |                                                                \n| ViT-cifar100                      | é¢„è®­ç»ƒ     | âœ…  | âŒ  | âŒ  | â€”â€” |\n\n\n> æ›´å¤šæ ·ä¾‹è§ [./examples](https://github.com/FlagAI-Open/FlagAI/tree/master/examples) ç›®å½•ï¼Œæ›´å¤šä¸­æ–‡æ•™ç¨‹è§ [./docs_zh](https://github.com/FlagAI-Open/FlagAI/tree/master/doc_zh) ç›®å½•ã€‚\n\n\n## è´¡çŒ®ä»£ç \n\næ„Ÿè°¢æ‚¨å¯¹è´¡çŒ®çš„å…´è¶£ï¼è¯·å…ˆé˜…è¯» [è´¡çŒ®è€…æŒ‡å—](CONTRIBUTING.md)ï¼Œç„¶åä» [æœªè§£å†³çš„é—®é¢˜](https://github.com/FlagAI-Open/FlagAI/issues) å¯»æ‰¾ä½ æ„Ÿå…´è¶£çš„ä»»åŠ¡å¼€å¯è´¡çŒ®ä¹‹æ—…ï¼\n\n## è”ç³»æˆ‘ä»¬\n\næ¬¢è¿åœ¨ [GitHub Issues](https://github.com/FlagAI-Open/FlagAI/issues) ä¸­æå‡ºä½ çš„é—®é¢˜ï¼Œæˆ–åœ¨ [Discussions ](https://github.com/FlagAI-Open/FlagAI/discussions) æ¿å—äº¤æµä½¿ç”¨ç»éªŒã€‚\n\n* å®˜æ–¹é‚®ç®±ï¼šopen.platform@baai.ac.cnã€‚\n* çŸ¥ä¹ï¼š[FlagAIé£æ™º](https://www.zhihu.com/people/95-22-20-18)\n* æ‰«ç æ·»åŠ å°åŠ©æ‰‹åŠ å…¥**å¾®ä¿¡äº¤æµç¾¤**ï¼š\n\n<img src=\"./wechat-qrcode.jpg\" width = \"200\" height = \"200\"  align=center />\n\n\n\n## Quick Start\n\n### å®‰è£…ç¯å¢ƒ\n\n* Python ç‰ˆæœ¬ >= 3.8\n* PyTorch ç‰ˆæœ¬ >= 1.8.0\n* [å¯é€‰] ä½¿ç”¨GPUsè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•, ä½ éœ€è¦å®‰è£…CUDA å’Œ NCCL\n\n- é€šè¿‡`pip`å®‰è£…:\n```shell\npip install -U flagai\n```\n\n- [å¯é€‰] ä¸‹è½½æºç å®‰è£…:\n\n```shell\ngit clone https://github.com/FlagAI-Open/FlagAI.git\npython setup.py install\n```\n\n- [å¯é€‰] å¼€å¯è®­ç»ƒåŠ é€Ÿéœ€è¦å®‰è£… NVIDIAçš„ [apex](https://github.com/NVIDIA/apex)\n```\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n- [å¯é€‰] ä½¿ç”¨ ZeRO ä¼˜åŒ–å™¨ï¼Œéœ€è¦å®‰è£… [DEEPSPEED](https://github.com/microsoft/DeepSpeed) (>= 0.7.7)\n```\ngit clone https://github.com/microsoft/DeepSpeed\ncd DeepSpeed\nDS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .\nds_report # æ£€æŸ¥deepspeedçš„çŠ¶æ€\n```\n- [å¯é€‰] å¼€å¯BMTrainè®­ç»ƒï¼Œéœ€è¦å®‰è£… [BMTrain](https://github.com/OpenBMB/BMTrain) ((>= 0.2.2))\n```\ngit clone https://github.com/OpenBMB/BMTrain\ncd BMTrain\npython setup.py install \n```\n\n- [å¯é€‰] å¼€å¯BMInfä½èµ„æºæ¨ç†, éœ€è¦å®‰è£…[BMInf](https://github.com/OpenBMB/BMInf)\n```\npip install bminf\n\n```\n- [å¯é€‰] å¯¹äºFlashAttention, éœ€è¦å®‰è£…[Flash-attention](https://github.com/HazyResearch/flash-attention) ï¼ˆ>=1.0.2ï¼‰\n```\npip install flash-attn\n```\n\n- [å¯é€‰] é•œåƒæ„å»ºï¼Œè¯·å‚ç…§ [Dockerfile](https://github.com/FlagAI-Open/FlagAI/blob/master/Dockerfile)\n- [æç¤º] å•èŠ‚ç‚¹dockerç¯å¢ƒä¸‹ï¼Œè¿è¡Œå¤šå¡æ•°æ®å¹¶è¡Œéœ€è¦è®¾ç½®hostã€‚ ä¾‹å¦‚ï¼ŒdockerèŠ‚ç‚¹ root@127.0.0.1ï¼Œå…¶ç«¯å£ 7110ã€‚\n```\n>>> vim ~/.ssh/config\nHost 127.0.0.1\n    Hostname 127.0.0.1\n    Port 7110\n    User root\n```\n- [æç¤º] å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œ éœ€è¦ç”Ÿæˆ ssh keys å¹¶æ‹·è´å…¬é’¥åˆ°æ‰€æœ‰èŠ‚ç‚¹ (in `~/.ssh/`)\n```\n>>> ssh-keygen -t rsa -C \"xxx@xxx.com\"\n```\n\n### åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨\næˆ‘ä»¬æä¾› `AutoLoad` ç±»æ¥å¿«é€ŸåŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œä¾‹å¦‚ï¼š\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nauto_loader = AutoLoader(\n      task_name=\"title-generation\",\n      model_name=\"RoBERTa-base-ch\"  \n)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n```\n\nè¿™ä¸ªä¾‹å­æ˜¯é’ˆå¯¹`title-generation`(æ–‡æœ¬æ‘˜è¦ï¼‰ä»»åŠ¡çš„ï¼Œä½ ä¹Ÿå¯ä»¥é€šè¿‡ä¿®æ”¹`task_name`æ¥ä¸ºå…¶ä»–ä»»åŠ¡å»ºæ¨¡ã€‚ ç„¶åæ‚¨å¯ä»¥ä½¿ç”¨æ¨¡å‹å’Œæ ‡è®°å™¨è¿›è¡Œå¾®è°ƒæˆ–æµ‹è¯•ã€‚\n\n### ä½¿ç”¨é¢„æµ‹å™¨\næˆ‘ä»¬æä¾› `Predictor` ç±»æ¥é¢„æµ‹ä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š\n\n```python\nfrom flagai.model.predictor.predictor import Predictor\npredictor = Predictor(model, tokenizer)\ntest_data = [\n    \"æœ¬æ–‡æ€»ç»“äº†åä¸ªå¯ç©¿æˆ´äº§å“çš„è®¾è®¡åŸåˆ™è€Œè¿™äº›åŸåˆ™åŒæ ·ä¹Ÿæ˜¯ç¬”è€…è®¤ä¸ºæ˜¯è¿™ä¸ªè¡Œä¸šæœ€å¸å¼•äººçš„åœ°æ–¹1ä¸ºäººä»¬è§£å†³é‡å¤æ€§é—®é¢˜2ä»äººå¼€å§‹è€Œä¸æ˜¯ä»æœºå™¨å¼€å§‹3è¦å¼•èµ·æ³¨æ„ä½†ä¸è¦åˆ»æ„4æå‡ç”¨æˆ·èƒ½åŠ›è€Œä¸æ˜¯å–ä»£äºº\",\n    \"2007å¹´ä¹”å¸ƒæ–¯å‘äººä»¬å±•ç¤ºiPhoneå¹¶å®£ç§°å®ƒå°†ä¼šæ”¹å˜ä¸–ç•Œè¿˜æœ‰äººè®¤ä¸ºä»–åœ¨å¤¸å¤§å…¶è¯ç„¶è€Œåœ¨8å¹´åä»¥iPhoneä¸ºä»£è¡¨çš„è§¦å±æ™ºèƒ½æ‰‹æœºå·²ç»å¸­å·å…¨çƒå„ä¸ªè§’è½æœªæ¥æ™ºèƒ½æ‰‹æœºå°†ä¼šæˆä¸ºçœŸæ­£çš„ä¸ªäººç”µè„‘ä¸ºäººç±»å‘å±•åšå‡ºæ›´å¤§çš„è´¡çŒ®\",\n    \"é›…è™å‘å¸ƒ2014å¹´ç¬¬å››å­£åº¦è´¢æŠ¥å¹¶æ¨å‡ºäº†å…ç¨æ–¹å¼å‰¥ç¦»å…¶æŒæœ‰çš„é˜¿é‡Œå·´å·´é›†å›¢15ï¼…è‚¡æƒçš„è®¡åˆ’æ‰“ç®—å°†è¿™ä¸€ä»·å€¼çº¦400äº¿ç¾å…ƒçš„å®è´µæŠ•èµ„åˆ†é…ç»™è‚¡ä¸œæˆªæ­¢å‘ç¨¿å‰é›…è™è‚¡ä»·ä¸Šæ¶¨äº†å¤§çº¦7ï¼…è‡³5145ç¾å…ƒ\"\n]\nfor text in test_data:\n    print(\n        predictor.predict_generate_beamsearch(text,\n                                              out_max_length=50,\n                                              beam_size=3))\n```\n\nè¿™ä¸ªä¾‹å­æ˜¯é’ˆå¯¹ `seq2seq` ä»»åŠ¡çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨`predict_generate_beamsearch`å‡½æ•°å¾—åˆ°`beam-search`ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒ`NER`å’Œ`title generate`ç­‰ä»»åŠ¡çš„é¢„æµ‹ã€‚\n\n\n### å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ç¤ºä¾‹\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\ntask_name = \"ner\"\nmodel_name = \"RoBERTa-base-ch\"\ntarget = [\"O\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\", \"B-PER\", \"I-PER\"]\nmaxlen = 256\n\nauto_loader = AutoLoader(task_name,\n                         model_name=model_name,\n                         load_pretrain_params=True,\n                         class_num=len(target))\n\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [\n    \"6æœˆ15æ—¥ï¼Œæ²³å—çœæ–‡ç‰©è€ƒå¤ç ”ç©¶æ‰€æ›¹æ“é«˜é™µæ–‡ç‰©é˜Ÿå…¬å¼€å‘è¡¨å£°æ˜æ‰¿è®¤ï¼šâ€œä»æ¥æ²¡æœ‰è¯´è¿‡å‡ºåœŸçš„ç å­æ˜¯å¢“ä¸»äººçš„\",\n    \"4æœˆ8æ—¥ï¼ŒåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šæ€»ç»“è¡¨å½°å¤§ä¼šåœ¨äººæ°‘å¤§ä¼šå ‚éš†é‡ä¸¾è¡Œã€‚ä¹ è¿‘å¹³æ€»ä¹¦è®°å‡ºå¸­å¤§ä¼šå¹¶å‘è¡¨é‡è¦è®²è¯ã€‚åœ¨è®²è¯ä¸­ï¼Œæ€»ä¹¦è®°å……åˆ†è‚¯å®šäº†åŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šå–å¾—çš„ä¼˜å¼‚æˆç»©ï¼Œå…¨é¢å›é¡¾äº†7å¹´ç­¹åŠå¤‡èµ›çš„ä¸å‡¡å†ç¨‹ï¼Œæ·±å…¥æ€»ç»“äº†ç­¹å¤‡ä¸¾åŠåŒ—äº¬å†¬å¥¥ä¼šã€å†¬æ®‹å¥¥ä¼šçš„å®è´µç»éªŒï¼Œæ·±åˆ»é˜é‡Šäº†åŒ—äº¬å†¬å¥¥ç²¾ç¥ï¼Œå¯¹è¿ç”¨å¥½å†¬å¥¥é—äº§æ¨åŠ¨é«˜è´¨é‡å‘å±•æå‡ºæ˜ç¡®è¦æ±‚ã€‚\",\n    \"å½“åœ°æ—¶é—´8æ—¥ï¼Œæ¬§ç›Ÿå§”å‘˜ä¼šè¡¨ç¤ºï¼Œæ¬§ç›Ÿå„æˆå‘˜å›½æ”¿åºœç°å·²å†»ç»“å…±è®¡çº¦300äº¿æ¬§å…ƒä¸ä¿„ç½—æ–¯å¯¡å¤´åŠå…¶ä»–è¢«åˆ¶è£çš„ä¿„æ–¹äººå‘˜æœ‰å…³çš„èµ„äº§ã€‚\",\n    \"è¿™ä¸€ç›˜å£çŠ¶æ€ä¸‹è‹±å›½å¿…å‘å…¬å¸äºšæ´²ç›˜äº¤æ˜“æ•°æ®æ˜¾ç¤ºåšæ´›å°¼äºšçƒ­ã€‚è€Œä»æ¬§èµ”æŠ•æ³¨çœ‹ï¼Œä¹Ÿæ˜¯ä¸»é˜Ÿçƒ­ã€‚å·´å‹’è«ä¸¤è¿è´¥ï¼Œ\",\n]\n\nfor t in test_data:\n    entities = predictor.predict_ner(t, target, maxlen=maxlen)\n    result = {}\n    for e in entities:\n        if e[2] not in result:\n            result[e[2]] = [t[e[0]:e[1] + 1]]\n        else:\n            result[e[2]].append(t[e[0]:e[1] + 1])\n    print(f\"result is {result}\")\n```\n\n\n### è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ä»»åŠ¡ç¤ºä¾‹\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\nmaxlen = 256\n\nauto_loader = AutoLoader(\"semantic-matching\",\n                         model_name=\"RoBERTa-base-ch\",\n                         load_pretrain_params=True,\n                         class_num=2)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [[\"åæ‚”äº†å—\", \"ä½ æœ‰æ²¡æœ‰åæ‚”\"], [\"æ‰“å¼€è‡ªåŠ¨æ¨ªå±\", \"å¼€å¯ç§»åŠ¨æ•°æ®\"],\n             [\"æˆ‘è§‰å¾—ä½ å¾ˆèªæ˜\", \"ä½ èªæ˜æˆ‘æ˜¯è¿™ä¹ˆè§‰å¾—\"]]\n\nfor text_pair in test_data:\n    print(predictor.predict_cls_classifier(text_pair))\n\n```\n\n\n## åŠ¨æ€\n- [9 June 2023] æ”¯æŒ v1.7.0ç‰ˆæœ¬, å¢åŠ Aquila [#324](https://github.com/FlagAI-Open/FlagAI/pull/324);\n- [31 Mar 2023] æ”¯æŒv1.6.3ç‰ˆæœ¬, å¢åŠ AltCLIP-m18æ¨¡å‹ [#303](https://github.com/FlagAI-Open/FlagAI/pull/303) ä»¥åŠ AltDiffusion-m18æ¨¡å‹ [#302](https://github.com/FlagAI-Open/FlagAI/pull/302); \n- [17 Mar 2023] æ”¯æŒv1.6.2ç‰ˆæœ¬, å¯ä»¥ä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨ [#266](https://github.com/FlagAI-Open/FlagAI/pull/266), å¹¶å¢åŠ äº†è‹±æ–‡gptæ¨¡å‹GPT2-base-en; \n- [2 Mar 2023] æ”¯æŒv1.6.1ç‰ˆæœ¬, å¢åŠ Galacticaæ¨¡å‹ [#234](https://github.com/FlagAI-Open/FlagAI/pull/234), å¤§æ¨¡å‹æ¨ç†çš„ä½èµ„æºå·¥å…·åŒ…BMInf [#238](https://github.com/FlagAI-Open/FlagAI/pull/238), ä»¥åŠP-tuningæ ·ä¾‹ [#227](https://github.com/FlagAI-Open/FlagAI/pull/238)\n- [12 Jan 2023] å‘å¸ƒv1.6.0ç‰ˆæœ¬, æ–°å¢æ”¯æŒå¹¶è¡Œè®­ç»ƒåº“ [**BMTrain**](https://github.com/OpenBMB/BMTrain) ä»¥åŠé›†æˆ [**Flash Attention**](https://github.com/HazyResearch/flash-attention) åˆ° Bert å’Œ Vit æ¨¡å‹æé€Ÿç«¯åˆ°ç«¯è®­ç»ƒ, ç¤ºä¾‹è§ [FlashAttentionBERT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/bert_title_generation_english/train_flash_atten.py)å’Œ [FlashAttentionViT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/vit_cifar100/train_single_gpu_flash_atten.py). åŒæ—¶å¢åŠ äº†åŸºäºå¯¹æ¯”æœç´¢çš„æ–‡æœ¬ç”Ÿæˆæ–¹æ³• [**SimCTG**](https://github.com/yxuansu/SimCTG) ä»¥åŠåŸºäº AltDiffusion è¿›è¡Œ DreamBooth ä¸ªæ€§åŒ–å¾®è°ƒ, ç¤ºä¾‹è§ [AltDiffusionNaruto](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/AltDiffusion/dreambooth.py). \n- [28 Nov 2022] å‘å¸ƒv1.5.0ç‰ˆæœ¬, æ”¯æŒ1.1Bå‚æ•°çš„ [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP) ä»¥åŠ[ALM: åŸºäºGLMçš„é˜¿æ‹‰ä¼¯è¯­å¤§æ¨¡å‹], ç¤ºä¾‹è§[**ALM**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/ALM)\n- [10 Nov 2022] å‘å¸ƒv1.4.0ç‰ˆæœ¬, æ”¯æŒ[AltCLIP: æ›´æ”¹CLIPä¸­çš„è¯­è¨€ç¼–ç å™¨ä»¥æ‰©å±•è¯­è¨€åŠŸèƒ½](https://arxiv.org/abs/2211.06679v1), ç¤ºä¾‹è§[**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP)ä»¥åŠ[**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)\n- [29 Aug 2022] æ”¯æŒv1.3.0ç‰ˆæœ¬, å¢åŠ CLIPæ¨¡å—ä»¥åŠé‡æ–°è®¾è®¡äº†tokenizerçš„API: [#81](https://github.com/FlagAI-Open/FlagAI/pull/81)\n- [21 Jul 2022] æ”¯æŒv1.2.0ç‰ˆæœ¬, æ”¯æŒViTç³»åˆ—æ¨¡å‹: [#71](https://github.com/FlagAI-Open/FlagAI/pull/71)\n- [29 Jun 2022] æ”¯æŒv1.1.0ç‰ˆæœ¬, æ”¯æŒOPTçš„åŠ è½½ï¼Œå¾®è°ƒå’Œæ¨ç†[#63](https://github.com/FlagAI-Open/FlagAI/pull/63)\n- [17 May 2022] åšå‡ºäº†æˆ‘ä»¬çš„ç¬¬ä¸€ä»½è´¡çŒ®[#1](https://github.com/FlagAI-Open/FlagAI/pull/1)\n\n## è®¸å¯ LICENSE \n\n\nFlagAIé£æ™ºå¤§éƒ¨åˆ†é¡¹ç›®åŸºäº [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0)ï¼Œä½†æ˜¯è¯·æ³¨æ„éƒ¨åˆ†é¡¹ç›®ä»£ç åŸºäºå…¶ä»–åè®®ï¼š\n\n* Megatron-LM æ˜¯åŸºäºåè®® [Megatron-LM license](https://github.com/NVIDIA/Megatron-LM/blob/main/LICENSE)\n* GLM æ˜¯åŸºäºåè®® [MIT license](https://github.com/THUDM/GLM/blob/main/LICENSE)\n* AltDiffusion æ˜¯åŸºäºåè®® [CreativeML Open RAIL-M license](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n\n## å¹³å°æ”¯æŒ\n\n<div  align=\"center\">    \n<img src=\"./examples/Aquila/img/merged_platform.jpg\" height = \"100\" align=center />\n</div>\n\n\n## Misc\n\n### &#8627; Stargazers, thank you for your support!\n[![Stargazers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/stars/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/stargazers)\n\n### &#8627; Forkers, thank you for your support!\n[![Forkers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/forks/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/network/members)\n\n### &#8627; Star History\n\n<div align=\"center\">\n\n![Star History Chart](https://api.star-history.com/svg?repos=FlagAI-Open/FlagAI&type=Date)]\n\n</div>\n"
        },
        {
          "name": "SUPPORT.md",
          "type": "blob",
          "size": 1.064453125,
          "content": "_Use this file to detail how to make get support forthe project. The structure below is generally recommended, but can be changed to meet the needs of the project_\n\n# Getting Help\n\nThere are a few ways to connect with the PROJECT NAME project:\n* https://github.com/FlagAI-Open/FlagAI/issues\n\n## How to Ask for Help\n\nIf you have trouble installing, building, or using PROJECT NAME, but there's not yet reason to suspect you've encountered a genuine bug,\nstart by posting a question to the mailing list or Slack channel. This is the place for question such has \"How do I...\".\n\n## How to report a bug or request an enhancement\n\nPROJECT NAME manages bug and enhancement using it's [issue tracker](https://github.com/FlagAI-Open/FlagAI/issues). The issue template will guide you on making an effective report.\n\n## How to report a security vulnerability\n\nIf you think you've found a potential vulnerability in PROJECT NAME, please\nemail security@PROJECT DOMAIN to responsibly disclose it.\n\n## Contributing a fix\n\nPlease refer to [CONTRIBUTING.md](CONTRIBUTING.md) to make a project contribution.\n"
        },
        {
          "name": "doc_zh",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flagai",
          "type": "tree",
          "content": null
        },
        {
          "name": "flagopen.jpeg",
          "type": "blob",
          "size": 450.912109375,
          "content": null
        },
        {
          "name": "logo.png",
          "type": "blob",
          "size": 75.48046875,
          "content": null
        },
        {
          "name": "prepare_test.sh",
          "type": "blob",
          "size": 0.1533203125,
          "content": "git clone https://github.com/BAAI-OpenPlatform/checkpoints.git\ncd checkpoints\nunzip checkpoints.zip\nmv checkpoints/* .\nrm checkpoints -r\nrm checkpoints.zip\n\n"
        },
        {
          "name": "quickstart",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0634765625,
          "content": "packaging\nPyYAML==5.4.1\ndeepspeed==0.6.5\nflash-attn==1.0.2\nbminf\n"
        },
        {
          "name": "script",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.06640625,
          "content": "[easy_install]\n\nindex_url = https://mirrors.aliyun.com/pypi/simple/\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.3544921875,
          "content": "# Copyright Â© 2022 BAAI. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\")\nfrom setuptools import find_packages, setup\n\nsetup(\n    name=\"flagai\",\n    version=\"v1.8.5\",\n    description=\"FlagAI aims to help researchers and developers to freely train and test large-scale models for NLP/CV/VL tasks.\",\n    long_description=open(\"README.md\", encoding=\"utf-8\").read(),\n    long_description_content_type=\"text/markdown\",\n    author=\"FlagAI-Open\",\n    author_email=\"open@baai.ac.cn\",\n    url=\"https://github.com/FlagAI-Open/FlagAI\",\n    packages=find_packages(exclude=\"tests\"),  # same as name\n    license=\"Apache 2.0\",\n    include_package_data=True,\n    python_requires=\">=3.8\",\n    install_requires=[\n        'nltk>=3.6.7',\n        'sentencepiece>=0.1.96',\n        'boto3>=1.17.32',\n        'pandas>=1.3.5',\n        'jieba>=0.42.1',\n        'scikit-learn>=1.0.2',\n        'tensorboard>=2.9.0',\n        'transformers>=4.31.0',\n        'datasets>=2.0.0',\n        'setuptools>=66.0.0',\n        'protobuf>=3.19.6',\n        'ftfy',\n        'Pillow>=9.3.0',\n        'einops>=0.3.0',\n        'diffusers>=0.7.2',\n        'pytorch-lightning>=1.6.5',\n        'taming-transformers-rom1504==0.0.6',\n        'rouge-score',\n        'sacrebleu>=2.3.1',\n        'jsonlines',\n        'accelerate',\n        'PyYAML>=5.4.1',\n        'safetensors',\n        'timm',\n    ]\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "wechat-qrcode.jpg",
          "type": "blob",
          "size": 79.1474609375,
          "content": null
        }
      ]
    }
  ]
}