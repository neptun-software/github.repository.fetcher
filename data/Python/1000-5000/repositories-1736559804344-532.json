{
  "metadata": {
    "timestamp": 1736559804344,
    "page": 532,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "FlagAI-Open/FlagAI",
      "stars": 3849,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5498046875,
          "content": "__pycache__\n.idea/\nlogs/\ntest_tokenizer.py\nsamples_text2image/\ngenerate_contexts/\nvenv/\n*__pycache__\n.DS_Store\n.vscode\n*.swo\n*.swp\n*log\nbuild\ndist\neazybigmodel.egg-info\nflagai.egg-info\ntest_report\n/data/\n/tests/*/data\ncheckpoints\ncheckpoints_in\ncheckpoints_out\nstate_dict\ncheckpoints*\nvocabs\ntensorboard*\ndatasets\nqqp\nglm_large_qqp_pytorch\nwandb\nclip_benchmark_datasets\nexamples/AltCLIP/clip_benchmark_datasets\nexamples/glm_pretrain/data.lazy\nexamples/glm_pretrain/examples/glm_pretrain/data.lazy\nexamples/vit_cifar100/cifar100\nexamples/vit_cifar100/data\noutput/\n"
        },
        {
          "name": "BAAI_Aquila_Model_License.pdf",
          "type": "blob",
          "size": 220.0595703125,
          "content": null
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.318359375,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [Unreleased]\n\n### Added\nCPM-1 model examples\n### Changed\n\n### Removed\n"
        },
        {
          "name": "CLA.md",
          "type": "blob",
          "size": 4.1025390625,
          "content": "# The Contributor License Agreement\n\nThe [Cloud Native Computing Foundation](https://www.cncf.io) (CNCF) defines\nthe legal status of the contributed code in two different types of _Contributor License Agreements_\n(CLAs), [individual contributors](https://github.com/cncf/cla/blob/master/individual-cla.pdf) and [corporations](https://github.com/cncf/cla/blob/master/corporate-cla.pdf).\n\nFlagAI can only accept original source code from CLA signatories.\n\n\nIt is important to read and understand this legal agreement.\n\n## How do I sign?\n\nAfter creating your first Pull Request the linux-foundation-easycla bot will respond with information regarding your CLA status along with a link to sign the CLA.\n\n<img width=\"1065\" alt=\"EasyCLA bot\" src=\"https://user-images.githubusercontent.com/69111235/152226443-f6fe61ee-0e92-46c5-b6ea-c0deb718a585.png\">\n\n#### 1. Authorize EasyCLA to read some of your GitHub information\n\n<img width=\"554\" alt=\"GitHub EasyCLA Authorization\" src=\"https://user-images.githubusercontent.com/69111235/152228712-7d22f9d0-9f3c-4226-9ee0-bacba4b47725.png\">\n\nClick on the \"Please click here to be authorized\" link to navigate to the GitHub Authorize Linux Foundation: EasyCLA page. Then click Authorize LF-Engineering to give the Linux Foundation read-only access to list the email addresses associated with your GitHub account.\n\n#### 2. Select from the two types of contributor\n\n<img width=\"1407\" alt=\"EasyCLA\" src=\"https://user-images.githubusercontent.com/69111235/152224818-1246453a-b086-4a57-9d14-c10d62ad438f.png\">\n\n\nAfter authorizing EasyCLA, you will be redirected to a page to identify which type of contributor you are. \nSelect the most appropriate option:\n  * Individual Contributor: You are contributing as yourself, and not as part of another organization.\n  * Corporate Contributor: You are contributing on behalf of your employer or other organization.\n\n#### 3. Sign the CLA\n\nOnce you select the type of contributor, proceed to Sign the CLA and follow the instructions to complete the signing process through DocuSign.\n\n**Ensure your GitHub e-mail address matches e-mail address used to sign CLA**\n\nAfter you have filled out  the information, Click \"Finish\" and you will be redirected back to your Pull Request.\n\n#### 4. Look for an email indicating successful signup.\n\n> Hello,\n> \n> This is a notification email from EasyCLA regarding the project Cloud Native Computing > Foundation (CNCF).\n> \n> The CLA has now been signed. You can download the signed CLA as a PDF here.\n> \n> If you need help or have questions about EasyCLA, you can read the documentation or reach out to us for support.\n> \n> Thanks,\n> EasyCLA Support Team\n\n\n\n#### 5. Validate your CLA\n\nOnce you are redirected back to your GitHub Pull Request, reply with a comment `/easycla` to update the CLA status of your PR.\n\n\n## Changing your Affiliation\n\nIf you've changed employers and still contribute to Kubernetes, your affiliation\nneeds to be updated. The Cloud Native Computing Foundation uses [gitdm](https://github.com/cncf/gitdm)\nto track who is contributing and from where. Create a pull request on the [gitdm](https://github.com/cncf/gitdm)\nrepository with a change to the corresponding developer affiliation text file.\nYour entry should look similar to this:\n\n```\nJorge O. Castro*: jorge!heptio.com, jorge!ubuntu.com, jorge.castro!gmail.com\nHeptio\nCanonical until 2017-03-31\n```\n\n## Troubleshooting\n\nIf you encounter any problems signing the CLA and need further assistance, log a ticket by clicking on the link [please submit a support request ticket](https://jira.linuxfoundation.org/plugins/servlet/theme/portal/4) from the EasyCLA bot's response. Someone from the CNCF will respond to your ticket to help.\n\nShould you have any issues using the LF Support Site, send a message to the\nbackup e-mail support address <login-issues@jira.linuxfoundation.org>\n\n## Setting up the CNCF CLA check\n\nIf you are a Kubernetes GitHub organization or repo owner and would like to setup\nthe Linux Foundation CNCF CLA check for your repositories, [read the docs on setting up the CNCF CLA check](/github-management/setting-up-cla-check.md)\n\n\n[Linux Foundation Support Site]: https://support.linuxfoundation.org/"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1943359375,
          "content": "All\tparticipants agree to abide by the Code of Conduct available at https://lfprojects.org/policies/code-of-conduct/. Please contact conduct@lfaidata.foundation to report any violations or concerns.\n"
        },
        {
          "name": "COMMITTERS.csv",
          "type": "blob",
          "size": 0.0634765625,
          "content": "Name, Email, Github ID\nGuang Liu, marscrazy_90@163.com, marcrazy\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.681640625,
          "content": "# Contributing to FlagAI\n\nWe are happy to accept your contributions to make `FlagAI` better and more awesome! To avoid unnecessary work on either\nside, please stick to the following process:\n\n1. Check if there is already [an issue](https://github.com/FlagAI-Open/FlagAI/issues) for your concern.\n2. If there is not, open a new one to start a discussion. We hate to close finished PRs!\n3. If we decide your concern needs code changes, we would be happy to accept a pull request. Please consider the\ncommit guidelines below.\n\n## Sign the CLA\n\nBefore you can contribute to FlagAI, you will need to sign the [Contributor License Agreement](CLA.md).\n\n## Git Commit Guidelines\n\nIf there is already a ticket, use this number at the start of your commit message.\nUse meaningful commit messages that described what you did.\n\n**Example:** `GH-42: Added new type of embeddings: DocumentEmbedding.`\n**Example:** `ISSUE#123: Fix typo in README.`\n\n\n## Developing locally\n\nFor contributors looking to get deeper into the API we suggest cloning the repository and checking out the unit\ntests for examples of how to call methods. Nearly all classes and methods are documented, so finding your way around\nthe code should hopefully be easy.\n\n### setup\n\nYou can either use [Pipenv](https://pipenv.readthedocs.io/) for this:\n\nor create a python environment of your preference and run\n```bash\npython setup.py install\n```\n\n### tests\nInstall `pytest` for testing\n```\npip install pytest\n```\nTo run all basic tests execute:\n```bash\npytest\n```\n\n### code formatting\n\nTo ensure a standardized code style we use the formatter [yapf](https://github.com/google/yapf).\nYou can automatically format the code via `yapf flagai/ -i` in the flair root folder.\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.1337890625,
          "content": "FROM nvcr.io/nvidia/cuda:11.7.0-devel-ubuntu20.04\n\nLABEL zhanglu0704\n\nENV TZ=Asia/Shanghai\n\nVOLUME /etc/localtime\n\nENV WORK_DID=/workspace\n\nWORKDIR ${WORK_DID}\n\nRUN apt update && \\\n    apt install -y g++ gcc cmake curl wget vim unzip git openssh-server net-tools python3-packaging && \\\n    apt install -y python3.9 python3.9-dev python3-pip && \\\n    apt clean -y && \\\n    rm -rf /var/cache/apt/archives \n\nRUN rm /usr/bin/python3 && \\\n    ln -s /usr/bin/python3.9 /usr/bin/python3 && \\\n    ln -s /usr/bin/python3 /usr/bin/python && \\\n    python -m pip install --upgrade pip\n\nRUN pip install torch==1.13.0+cu117 torchvision==0.14.0+cu117 torchaudio==0.13.0 \\\n    --extra-index-url https://download.pytorch.org/whl/cu117\n\nCOPY requirements.txt  ${WORK_DID}/\n\nRUN python -m pip install -r ${WORK_DID}/requirements.txt\n\nRUN git clone https://github.com/NVIDIA/apex && \\\n    cd apex && \\\n    # git checkout -f 23.05 && \\\n    # pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" . && \\\n    pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" . && \\\n    cd ../ && rm -rf apex\n\nRUN git clone https://github.com/OpenBMB/BMTrain && \\\n    cd BMTrain && \\\n    git checkout -f 0.2.2 && \\\n    # python setup.py install --prefix=/usr/local/\n    pip install -v . && \\\n    cd ../ && rm -rf BMTrain\n\nRUN git clone https://github.com/FlagAI-Open/FlagAI.git && \\\n    cd FlagAI && \\\n    pip install -v . && \\\n    cd ../ && rm -rf FlagAI\n\nRUN echo \"ClientAliveInterval 30\" >> /etc/ssh/sshd_config && \\\n    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config && \\\n    echo \"StrictHostKeyChecking no\" >> /etc/ssh/ssh_config && \\\n    echo \"UserKnownHostsFile /dev/null\" >> /etc/ssh/ssh_config\n\nRUN ssh-keygen -t rsa -f /root/.ssh/id_rsa -N \"\" && \\\n    cat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys && \\\n    chmod og-wx /root/.ssh/authorized_keys\n\nCMD service ssh start && tail -f /dev/null\n\n# sudo docker build -f Dockerfile --shm-size='120g' -t flagai:dev-ubuntu20-cuda11.7-py39 .\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 4.0390625,
          "content": "*NOTE: This document is intended to provide an example governance structure for any LF AI and Data Foundation project to consider as a starting point. All projects hosted by LF AI and Data Foundation are not bound by these governance polices, but in absence of any prior governance structure should consider this as a recommended structure*\n\n# Overview\n\nThis project aims to be governed in a transparent, accessible way for the benefit of the community. All participation in this project is open and not bound to corporate affilation. Participants are bound to the project's [Code of Conduct](./CODE_OF_CONDUCT.md).\n\n# Project roles\n\n## Contributor\n\nThe contributor role is the starting role for anyone participating in the project and wishing to contribute code.\n\n# Process for becoming a contributor\n\n* Review the [Contribution Guidelines](./CONTRIBUTING.md) to ensure your contribution is inline with the project's coding and styling guidelines.\n* Submit your code as a PR with the appropriate DCO signoff\n* Have your submission approved by the committer(s) and merged into the codebase.\n\n## Committer\n\nThe committer role enables the contributor to commit code directly to the repository, but also comes with the responsibility of being a responsible leader in the community.\n\n### Process for becoming a committer\n\n* Show your experience with the codebase through contributions and engagement on the community channels.\n* Request to become a committer. To do this, create a new pull request that adds your name and details to the [Committers File](./COMMITTERS.csv) file and request existing committers to approve.\n* After the majority of committers approve you, merge in the PR. Be sure to tag the whomever is managing the GitHub permissions to update the committers team in GitHub.\n\n### Committer responsibilities\n\n* Monitor email aliases (if any).\n* Monitor Slack (delayed response is perfectly acceptable).\n* Triage GitHub issues and perform pull request reviews for other committers and the community.\n* Make sure that ongoing PRs are moving forward at the right pace or closing them.\n* In general continue to be willing to spend at least 25% of ones time working on the project (~1.25 business days per week).\n\n### When does a committer lose committer status\n\nIf a committer is no longer interested or cannot perform the committer duties listed above, they\nshould volunteer to be moved to emeritus status. In extreme cases this can also occur by a vote of\nthe committers per the voting process below.\n\n## Lead\n\nThe project committers will elect a lead ( and optionally a co-lead ) which will be the primary point of contact for the project and representative to the TAC upon becoming an Active stage project. The lead(s) will be responsible for the overall project health and direction, coordination of activities, and working with other projects and committees as needed for the continuted growth of the project.\n\n# Release Process\n\nProject releases will occur on a scheduled basis as agreed to by the committers.\n\n# Conflict resolution and voting\n\nIn general, we prefer that technical issues and committer membership are amicably worked out\nbetween the persons involved. If a dispute cannot be decided independently, the committers can be\ncalled in to decide an issue. If the committers themselves cannot decide an issue, the issue will\nbe resolved by voting. The voting process is a simple majority in which each committer receives one vote.\n\n# Communication\n\nThis project, just like all of open source, is a global community. In addition to the [Code of Conduct](./CODE_OF_CONDUCT.md), this project will:\n\n* Keep all communucation on open channels ( mailing list, forums, chat ).\n* Be respectful of time and language differences between community members ( such as scheduling meetings, email/issue responsiveness, etc ).\n* Ensure tools are able to be used by community members regardless of their region.\n\nIf you have concerns about communication challenges for this project, please contact the committers.\n\n[Code of Conduct]: CODE_OF_CONDUCT.md\n[Committers File]: COMMITTERS.csv\n[Contribution Guidelines]: CONTRIBUTING.md\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.9794921875,
          "content": "Copyright © 2022 BAAI. All rights reserved.\n\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 19.626953125,
          "content": "[<img src=\"flagopen.jpeg\">](https://flagopen.baai.ac.cn/)\n![FlagAI](logo.png)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6052/badge)](https://bestpractices.coreinfrastructure.org/projects/6052)\n[![Python application](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg)](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml)\n![GitHub release (release name instead of tag name)](https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&style=social)\n\n[简体中文](README_zh.md)\n\n--------------------------------------------------------------------------------\n\n\nFlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.\n\n\n\n## Why should I use FlagAI?\n\n\n1. **Quickly Download Models via API**\n\n    FlagAI provides an API that allows you to quickly download pre-trained models and fine-tune them on a wide range of datasets collected from [SuperGLUE](https://super.gluebenchmark.com/) and [CLUE](https://github.com/CLUEbenchmark/CLUE) benchmarks for both Chinese and English text.\n\n    FlagAI now supports over 30 mainstream models, including Language Model [**Aquila**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila), multilingual text and image representation model [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP), text-to-image generation model [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) [![Huggingface space](https://img.shields.io/badge/🤗-Huggingface%20Space-cyan.svg)](https://huggingface.co/spaces/BAAI/bilingual_stable_diffusion), [**WuDao GLM**](/docs/GLM.md) (with a maximum of 10 billion parameters), [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP), **OPT**, **BERT**, **RoBERTa**, **GPT2**, **T5**, **ALM**, and models from **Huggingface Transformers**, etc.\n    \n\n2. **Parallel train with fewer than 10 lines of code**\n\n\tBacked by the four most popular data/model parallel libraries -- [PyTorch](https://pytorch.org/), [Deepspeed](https://www.deepspeed.ai/), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [BMTrain](https://github.com/OpenBMB/BMTrain) -- FlagAI allows for seamless integration between them, enabling users to parallel their training/testing process with fewer than ten lines of code.\n\n\n3. **Conveniently use the few-shot learning toolkits**\n   \n    FlagAI also provides [prompt-learning](/docs/TUTORIAL_7_PROMPT_LEARNING.md) toolkit for few-shot tasks.\n\n4. **Particularly good at Chinese tasks**\n\n    These models can be applied to (Chinese/English) Text, for tasks like text classification, information extraction, question answering, summarization, and text generation, with a particular focus on Chinese tasks.\n\n\n## Toolkits and Pre-trained Models \n\n> The code is partially based on [GLM](https://github.com/THUDM/GLM), [Transformers](https://github.com/huggingface/transformers)，[timm](https://github.com/rwightman/pytorch-image-models) and [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM).\n\n\n### Toolkits\n\n\n| Name       | Description       | Examples            |\n|:-------------- |:---------- |:------------------------------------------------------ |\n| \t`GLM_custom_pvp` | Customizing PET templates   | [README.md](http:///examples/glm_custom_pvp/README.md) |\n| `GLM_ptuning`    | p-tuning tool | ——                                                     |\n| `BMInf-generate` | Accelerating generation | [README.md](http:///examples/bminf_generate/README.md) | \n\n\n### Pre-trained Models \n\n\n|   Model          |  Task    | Train | Finetune | Inference/Generate | Examples       |                                                         \n| :---------------- | :------- | :-- |:-- | :-- | :--------------------------------------------- |\n| Aquila      | Natural Language Processing  | ✅  | ✅  | ✅  | [README.md](examples/Aquila/README.md) \n| ALM          | Arabic Text Generation  |  ✅  | ❌  | ✅  | [README.md](/examples/ALM/README.md)  |                         \n| AltCLIP       | Image-Text Matching  | ✅  | ✅  | ✅  | [README.md](/examples/AltCLIP/README.md)   |  \n| AltCLIP-m18      | Image-Text Matching  | ✅  | ✅  | ✅  | [README.md](examples/AltCLIP-m18/README.md)   |                             \n| AltDiffusion    | Text-to-Image Generation    | ❌  | ❌  | ✅  | [README.md](/examples/AltDiffusion/README.md)    |\n| AltDiffusion-m18    | Text-to-Image Generation,supporting 18 languages    | ❌  | ❌  | ✅  |[README.md](/examples/AltDiffusion-m18/README.md)   |\n| BERT-title-generation-english     | English Title Generation | ✅  | ❌  | ✅  | [README.md](/examples/bert_title_generation_english/README.md) |\n| CLIP           | Image-Text Matching    | ✅  | ❌  | ✅  | ——   |                                                                 \n| CPM3-finetune       | Text Continuation   | ❌  | ✅  | ❌  | ——    |                                                                \n| CPM3-generate    | Text Continuation  | ❌  | ❌  | ✅  | ——   |                                                                 \n| CPM3_pretrain    | Text Continuation  | ✅  | ❌  | ❌  | ——        |\n| CPM_1     | Text Continuation   | ❌  | ❌  | ✅  | [README.md](/examples/cpm_1/README.md)      |\n| EVA-CLIP                          | Image-Text Matching  | ✅  | ✅  | ✅  | [README.md](/examples/EVA_CLIP/README.md)                             |\n| Galactica       | Text Continuation    | ❌  | ❌  | ✅  | ——      |                                                              \n| GLM-large-ch-blank-filling        | Blank Filling     | ❌  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_11_GLM_BLANK_FILLING_QA.md)               |\n| GLM-large-ch-poetry-generation    | Poetry Generation     | ✅  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md)       |\n| GLM-large-ch-title-generation     | Title Generation   | ✅  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md)        |\n| GLM-pretrain         | Pre-Train    | ✅  | ❌  | ❌  | ——   |                                                                 \n| GLM-seq2seq        | Generation    | ✅  | ❌  | ✅  | ——     |                                                               \n| GLM-superglue      | Classification  | ✅  | ❌  | ❌  | ——     |                                                               \n| GPT-2-text-writting      | Text Continuation   | ❌  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_18_GPT2_WRITING.md)        |\n| GPT2-text-writting                | Text Continuation   | ❌  | ❌  | ✅  | —— |                                                                   \n| GPT2-title-generation             | Title Generation   | ❌  | ❌  | ✅  | ——  |                                                                  \n| OPT                               | Text Continuation   | ❌  | ❌  | ✅  | [README.md](/examples/opt/README.md) |                                  \n| RoBERTa-base-ch-ner               | Named Entity Recognition| ✅  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_17_BERT_EXAMPLE_NER.md)     |\n| RoBERTa-base-ch-semantic-matching |Semantic Similarity Matching | ✅  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md)      |\n| RoBERTa-base-ch-title-generation  | Title Generation     | ✅  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md)       |\n| RoBERTa-faq      |   Question-Answer   | ❌  | ❌  | ✅  | [README.md](/examples/roberta_faq/README.md) |         \n| Swinv1                            | Image Classification | ✅  | ❌  | ✅  | ——  |                                                                  \n| Swinv2                            | Image Classification   | ✅  | ❌  | ✅  | ——     |                                                               \n| T5-huggingface-11b                | Train   | ✅  | ❌  | ❌  | [TUTORIAL](/docs/TUTORIAL_14_HUGGINGFACE_T5.md)                      |\n| T5-title-generation               | Title Generation     | ❌  | ❌  | ✅  | [TUTORIAL](/docs/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md)                |\n| T5-flagai-11b                     | Pre-Train  | ✅  | ❌  | ❌  | ——    |                                                                \n| ViT-cifar100                      |  Pre-Train  | ✅  | ❌  | ❌  | —— |\n\n\n> * More excamples in  [./examples](https://github.com/FlagAI-Open/FlagAI/tree/master/examples) \n> * More tutorials in [./docs](https://github.com/FlagAI-Open/FlagAI/tree/master/doc) \n\n\n\n\n## Contributing\n\nThanks for your interest in contributing! There are many ways to get involved;\nstart with our [contributor guidelines](CONTRIBUTING.md) and then\ncheck these [open issues](https://github.com/FlagAI-Open/FlagAI/issues) for specific tasks.\n\n\n## Contact us\n\nWelcome to raise your questions or feature requests on [GitHub Issues](https://github.com/FlagAI-Open/FlagAI/issues) , and share your experience on the  [Discussions](https://github.com/FlagAI-Open/FlagAI/discussions) board.\n\n* Official email: open.platform@baai.ac.cn.\n* Zhihu: [FlagAI](https://www.zhihu.com/people/95-22-20-18)\n* Scan the qrcode to join the WeChat group for communication:\n\n<img src=\"./wechat-qrcode.jpg\" width = \"200\" height = \"200\"  align=center />\n\n\n## Quick Start\nWe provide many models which are trained to perform different tasks. You can load these models by AutoLoader to make prediction. See more in `FlagAI/quickstart`.\n\n### Requirements and Installation\n* Python version >= 3.8\n* PyTorch version >= 1.8.0\n* [Optional] For training/testing models on GPUs, you'll also need to install CUDA and NCCL\n\n- To install FlagAI with pip:\n```shell\npip install -U flagai\n```\n\n- [Optional] To install FlagAI and develop locally:\n\n```shell\ngit clone https://github.com/FlagAI-Open/FlagAI.git\npython setup.py install\n```\n\n- [Optional] For faster training, install NVIDIA's [apex](https://github.com/NVIDIA/apex)\n```\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n- [Optional] For ZeRO optimizers, install [DEEPSPEED](https://github.com/microsoft/DeepSpeed) (>= 0.7.7)\n```\ngit clone https://github.com/microsoft/DeepSpeed\ncd DeepSpeed\nDS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .\nds_report # check the deespeed status\n```\n- [Optional] For BMTrain training, install [BMTrain](https://github.com/OpenBMB/BMTrain) (>= 0.2.2)\n```\ngit clone https://github.com/OpenBMB/BMTrain\ncd BMTrain\npython setup.py install\n```\n- [Optional] For BMInf low-resource inference, install [BMInf](https://github.com/OpenBMB/BMInf)\n```\npip install bminf\n\n```\n- [Optional] For Flash Attention, install [Flash-attention](https://github.com/HazyResearch/flash-attention) (>=1.0.2)\n```\npip install flash-attn\n```\n\n- [Tips] For single-node docker environments, we need to set up ports for your ssh. e.g., root@127.0.0.1 with port 711\n```\n>>> vim ~/.ssh/config\nHost 127.0.0.1\n    Hostname 127.0.0.1\n    Port 7110\n    User root\n```\n- [Tips] For multi-node docker environments, generate ssh keys and copy the public key to all nodes (in `~/.ssh/`)\n```\n>>> ssh-keygen -t rsa -C \"xxx@xxx.com\"\n```\n\n\n### Load model and tokenizer\nWe provide the AutoLoad class to load the model and tokenizer quickly, for example:\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\n\nauto_loader = AutoLoader(\n    task_name=\"title-generation\",\n    model_name=\"BERT-base-en\"\n)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n```\nThis example is for the `title_generation` task, and you can also model other tasks by modifying the `task_name`.\nThen you can use the model and tokenizer to fine-tune or test.\n\n### Examples\n\n#### 1. Predictor \n\nWe provide the `Predictor` class to predict for different tasks, for example:\n\n```python\nfrom flagai.model.predictor.predictor import Predictor\npredictor = Predictor(model, tokenizer)\ntest_data = [\n    \"Four minutes after the red card, Emerson Royal nodded a corner into the path of the unmarked Kane at the far post, who nudged the ball in for his 12th goal in 17 North London derby appearances. Arteta's misery was compounded two minutes after half-time when Kane held the ball up in front of goal and teed up Son to smash a shot beyond a crowd of defenders to make it 3-0.The goal moved the South Korea talisman a goal behind Premier League top scorer Mohamed Salah on 21 for the season, and he looked perturbed when he was hauled off with 18 minutes remaining, receiving words of consolation from Pierre-Emile Hojbjerg.Once his frustrations have eased, Son and Spurs will look ahead to two final games in which they only need a point more than Arsenal to finish fourth.\",\n]\n\nfor text in test_data:\n    print(\n        predictor.predict_generate_beamsearch(text,\n                                              out_max_length=50,\n                                              beam_size=3))\n```\nThis example is for the `seq2seq` task, where we can get `beam-search` results by calling the `predict_generate_beamsearch` function. In addition, we also support prediction for tasks such as `NER` and `title generate`.\n\n\n#### 2. NER \n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\ntask_name = \"ner\"\nmodel_name = \"RoBERTa-base-ch\"\ntarget = [\"O\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\", \"B-PER\", \"I-PER\"]\nmaxlen = 256\n\nauto_loader = AutoLoader(task_name,\n                         model_name=model_name,\n                         load_pretrain_params=True,\n                         class_num=len(target))\n\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [\n    \"6月15日，河南省文物考古研究所曹操高陵文物队公开发表声明承认：“从来没有说过出土的珠子是墓主人的\",\n    \"4月8日，北京冬奥会、冬残奥会总结表彰大会在人民大会堂隆重举行。习近平总书记出席大会并发表重要讲话。在讲话中，总书记充分肯定了北京冬奥会、冬残奥会取得的优异成绩，全面回顾了7年筹办备赛的不凡历程，深入总结了筹备举办北京冬奥会、冬残奥会的宝贵经验，深刻阐释了北京冬奥精神，对运用好冬奥遗产推动高质量发展提出明确要求。\",\n    \"当地时间8日，欧盟委员会表示，欧盟各成员国政府现已冻结共计约300亿欧元与俄罗斯寡头及其他被制裁的俄方人员有关的资产。\",\n    \"这一盘口状态下英国必发公司亚洲盘交易数据显示博洛尼亚热。而从欧赔投注看，也是主队热。巴勒莫两连败，\",\n]\n\nfor t in test_data:\n    entities = predictor.predict_ner(t, target, maxlen=maxlen)\n    result = {}\n    for e in entities:\n        if e[2] not in result:\n            result[e[2]] = [t[e[0]:e[1] + 1]]\n        else:\n            result[e[2]].append(t[e[0]:e[1] + 1])\n    print(f\"result is {result}\")\n```\n\n#### 3. Semantic Matching example\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\nmaxlen = 256\n\nauto_loader = AutoLoader(\"semantic-matching\",\n                         model_name=\"RoBERTa-base-ch\",\n                         load_pretrain_params=True,\n                         class_num=2)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [[\"后悔了吗\", \"你有没有后悔\"], [\"打开自动横屏\", \"开启移动数据\"],\n             [\"我觉得你很聪明\", \"你聪明我是这么觉得\"]]\n\nfor text_pair in test_data:\n    print(predictor.predict_cls_classifier(text_pair))\n\n```\n\n\n\n## LICENSE\n\nThe majority of FlagAI is licensed under the [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0), however portions of the project are available under separate license terms:\n\n* Megatron-LM is licensed under the [Megatron-LM license](https://github.com/NVIDIA/Megatron-LM/blob/main/LICENSE)\n* GLM is licensed under the [MIT license](https://github.com/THUDM/GLM/blob/main/LICENSE)\n* AltDiffusion is licensed under the [CreativeML Open RAIL-M license](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n\n\n\n## News\n- [9 June 2023] release v1.7.0, Support Aquila [#324](https://github.com/FlagAI-Open/FlagAI/pull/324);\n- [31 Mar 2023] release v1.6.3, Support AltCLIP-m18 [#303](https://github.com/FlagAI-Open/FlagAI/pull/303) and AltDiffusion-m18 [#302](https://github.com/FlagAI-Open/FlagAI/pull/302); \n- [17 Mar 2023] release v1.6.2, Support application of new optimizers [#266](https://github.com/FlagAI-Open/FlagAI/pull/266), and added a new gpt model name 'GPT2-base-en' for English; \n- [2 Mar 2023] release v1.6.1, Support Galactica model [#234](https://github.com/FlagAI-Open/FlagAI/pull/234); BMInf, a low-resource inference package [#238](https://github.com/FlagAI-Open/FlagAI/pull/238), and examples for p-tuning [#227](https://github.com/FlagAI-Open/FlagAI/pull/238)\n- [12 Jan 2023] release v1.6.0, support a new parallel lib called [**BMTrain**](https://github.com/OpenBMB/BMTrain) and integate [**Flash Attention**](https://github.com/HazyResearch/flash-attention) to speedup training of BERT and ViT models, examples in [FlashAttentionBERT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/bert_title_generation_english/train_flash_atten.py) and [FlashAttentionViT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/vit_cifar100/train_single_gpu_flash_atten.py). Also add the contrastive search based text generation method [**SimCTG**](https://github.com/yxuansu/SimCTG) and DreamBooth finetuning based on AltDiffusion, examples in [AltDiffusionNaruto](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/AltDiffusion/dreambooth.py). \n- [28 Nov 2022] release v1.5.0, support 1.1B [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP) and [ALM: A large Arabic Language Model based on GLM], examples in [**ALM**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/ALM)\n- [10 Nov 2022] release v1.4.0, support [AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities](https://arxiv.org/abs/2211.06679v1), examples in [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP) and [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)\n- [29 Aug 2022] release v1.3.0, Added CLIP module and redesigned tokenizer APIs in [#81](https://github.com/FlagAI-Open/FlagAI/pull/81)\n- [21 Jul 2022] release v1.2.0, ViTs are supported in [#71](https://github.com/FlagAI-Open/FlagAI/pull/71)\n- [29 Jun 2022] release v1.1.0, support OPTs downloading and inference/fine-tuning [#63](https://github.com/FlagAI-Open/FlagAI/pull/63)\n- [17 May 2022] made our first contribution in [#1](https://github.com/FlagAI-Open/FlagAI/pull/1)\n\n## Platforms supported\n\n<div  align=\"center\">    \n<img src=\"./examples/Aquila/img/merged_platform.jpg\" height = \"100\" align=center />\n</div>\n\n\n\n## Misc\n\n### &#8627; Stargazers, thank you for your support!\n[![Stargazers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/stars/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/stargazers)\n\n### &#8627; Forkers, thank you for your support!\n[![Forkers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/forks/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/network/members)\n\n### &#8627; Star History\n<div align=\"center\">\n\n![Star History Chart](https://api.star-history.com/svg?repos=FlagAI-Open/FlagAI&type=Date)]\n\n</div>\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 19.20703125,
          "content": "[<img src=\"flagopen.jpeg\">](https://flagopen.baai.ac.cn/)\n![FlagAI](logo.png)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6052/badge)](https://bestpractices.coreinfrastructure.org/projects/6052)\n[![Python application](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml/badge.svg)](https://github.com/FlagAI-Open/FlagAI/actions/workflows/python-app.yml)\n![GitHub release (release name instead of tag name)](https://img.shields.io/github/v/release/FlagAI-Open/FlagAI?include_prereleases&style=social)\n\n[English](README.md)\n\n--------------------------------------------------------------------------------\n\n\n**FlagAI飞智**是一个快速、易于使用和可扩展的大模型工具包。 我们的目标是支持在多模态的各种下游任务上训练、微调和部署大规模模型。\n<br><br>\n\n## 为什么你需要 FlagAI?\n\n1. **可通过 API 快速下载模型**\n      \n    提供 API 方便你快速下载模型，并在给定（中/英文）文本上使用这些预训练模型，在从[SuperGLUE](https://super.gluebenchmark.com/)和[CLUE](https://github.com/CLUEbenchmark/CLUE) benchmarks收集的广泛使用的数据集上对它们进行微调。\n     \n      FlagAI 现已支持 30+ 主流模型，包括语言模型[**Aquila**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila), 多模态模型 [**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP) 、文生图模型 [**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion) [![Huggingface space](https://img.shields.io/badge/🤗-Huggingface%20Space-cyan.svg)](https://huggingface.co/spaces/BAAI/bilingual_stable_diffusion)、最高百亿参数的 **[悟道GLM](/doc_zh/GLM.md)**，[**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP)、**[Galactica](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/galactica)**、**OPT**、**BERT**、**RoBERTa**、**GPT2**、**T5**、**ALM**、**Huggingface Transformers** 等。\n      \n2.  **仅用十行代码即可进行并行训练**\n\n    飞智由四个最流行的数据/模型并行库（[PyTorch](https://pytorch.org/)/[Deepspeed](https://www.deepspeed.ai/)/[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)/[BMTrain](https://github.com/OpenBMB/BMTrain)）提供支持，它们之间实现了无缝集成。 你可以用不到十行代码来并行你的训练/测试过程。\n   \n3.  **提供提示学习工具包**\n\n    FlagAI 提供了提示学习（[prompt-learning](https://github.com/FlagAI-Open/FlagAI/blob/master/docs/TUTORIAL_7_PROMPT_LEARNING.md)）的工具包，用于少样本学习(few-shot learning)任务。\n   \n4.  **尤其擅长中文任务**\n\n    FlagAI 目前支持的模型可以应用于文本分类、信息提取、问答、摘要、文本生成等任务，尤其擅长中文任务。\n\n\n\n## 工具包及已支持的模型\n\n> 本项目的部分代码基于 [GLM](https://github.com/THUDM/GLM)，[Transformers](https://github.com/huggingface/transformers)，[timm](https://github.com/rwightman/pytorch-image-models) 和 [DeepSpeedExamples](https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM).\n\n\n### 工具\n\n| 工具名称           | 描述         | 样例                |\n|:-------------- |:---------- |:------------------------------------------------------ |\n| \t`GLM_custom_pvp` | 自定义 PET 模板   | [README.md](./examples/glm_custom_pvp/README.md) |\n| `GLM_ptuning`    | p-tuning 工具 | ——                                                     |\n| `BMInf-generate` | 推理加速    | [README.md](./examples/bminf_generate/README.md) |\n\n### 模型\n\n|    模型名称            | 任务      | 训练 | 微调 | 推理 | 样例           |                                                         \n| :---------------- | :------- | :-- |:-- | :-- | :--------------------------------------------- |\n| Aquila      | 自然语言处理  | ✅  | ✅  | ✅  | [README.md](examples/Aquila/README.md) \n| ALM          | 阿拉伯语文本生成   |  ✅  | ❌  | ✅  | [README.md](/examples/ALM/README.md)  |                         \n| AltCLIP       | 文图匹配 | ✅  | ✅  | ✅  | [README.md](/examples/AltCLIP/README.md)   |  \n| AltCLIP-m18      | 文图匹配  | ✅  | ✅  | ✅  | [README.md](examples/AltCLIP-m18/README.md)   |                             \n| AltDiffusion    | 文生图  | ❌  | ❌  | ✅  | [README.md](/examples/AltDiffusion/README.md)    |\n| AltDiffusion-m18    | 文生图，支持 18 种语言   | ❌  | ❌  | ✅  | [README.md](/examples/AltDiffusion-m18/README.md)   |\n| BERT-title-generation-english     | 英文标题生成  | ✅  | ❌  | ✅  | [README.md](/examples/bert_title_generation_english/README.md) |\n| CLIP           | 图文匹配    | ✅  | ❌  | ✅  | ——   |                                                                 \n| CPM3-finetune       | 文本续写    | ❌  | ✅  | ❌  | ——    |                                                                \n| CPM3-generate    | 文本续写    | ❌  | ❌  | ✅  | ——   |                                                                 \n| CPM3_pretrain    | 文本续写    | ✅  | ❌  | ❌  | ——        |\n| CPM_1     | 文本续写    | ❌  | ❌  | ✅  | [README.md](/examples/cpm_1/README.md)      |\n| EVA-CLIP                          | 图文匹配    | ✅  | ✅  | ✅  | [README.md](/examples/EVA_CLIP/README.md)                             |\n| Galactica       | 文本续写    | ❌  | ❌  | ✅  | ——      |                                                              \n| GLM-large-ch-blank-filling        | 完形填空问答  | ❌  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_11_GLM_BLANK_FILLING_QA.md)               |\n| GLM-large-ch-poetry-generation    | 诗歌生成    | ✅  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_13_GLM_EXAMPLE_PEOTRY_GENERATION.md)       |\n| GLM-large-ch-title-generation     | 标题生成    | ✅  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_12_GLM_EXAMPLE_TITLE_GENERATION.md)        |\n| GLM-pretrain         | 预训练     | ✅  | ❌  | ❌  | ——   |                                                                 \n| GLM-seq2seq        | 生成任务    | ✅  | ❌  | ✅  | ——     |                                                               \n| GLM-superglue      | 判别任务    | ✅  | ❌  | ❌  | ——     |                                                               \n| GPT-2-text-writting      | 文本续写    | ❌  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_18_GPT2_WRITING.md)        |\n| GPT2-text-writting                | 文本续写    | ❌  | ❌  | ✅  | —— |                                                                   \n| GPT2-title-generation             | 标题生成    | ❌  | ❌  | ✅  | ——  |                                                                  \n| OPT                               | 文本续写    | ❌  | ❌  | ✅  | [README.md](/examples/opt/README.md) |                                  \n| RoBERTa-base-ch-ner               | 命名实体识别  | ✅  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_17_BERT_EXAMPLE_NER.md)     |\n| RoBERTa-base-ch-semantic-matching | 语义相似度匹配 | ✅  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_16_BERT_EXAMPLE_SEMANTIC_MATCHING.md)      |\n| RoBERTa-base-ch-title-generation  | 标题生成    | ✅  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_15_BERT_EXAMPLE_TITLE_GENERATION.md)       |\n| RoBERTa-faq      | 问答      | ❌  | ❌  | ✅  | [README.md](/examples/roberta_faq/README.md) |         \n| Swinv1                            | 图片分类    | ✅  | ❌  | ✅  | ——  |                                                                  \n| Swinv2                            | 图片分类    | ✅  | ❌  | ✅  | ——     |                                                               \n| T5-huggingface-11b                | 训练      | ✅  | ❌  | ❌  | [TUTORIAL](/doc_zh/TUTORIAL_14_HUGGINGFACE_T5.md)                      |\n| T5-title-generation               | 标题生成    | ❌  | ❌  | ✅  | [TUTORIAL](/doc_zh/TUTORIAL_19_T5_EXAMPLE_TITLE_GENERATION.md)                |\n| T5-flagai-11b                     | 预训练     | ✅  | ❌  | ❌  | ——    |                                                                \n| ViT-cifar100                      | 预训练     | ✅  | ❌  | ❌  | —— |\n\n\n> 更多样例见 [./examples](https://github.com/FlagAI-Open/FlagAI/tree/master/examples) 目录，更多中文教程见 [./docs_zh](https://github.com/FlagAI-Open/FlagAI/tree/master/doc_zh) 目录。\n\n\n## 贡献代码\n\n感谢您对贡献的兴趣！请先阅读 [贡献者指南](CONTRIBUTING.md)，然后从 [未解决的问题](https://github.com/FlagAI-Open/FlagAI/issues) 寻找你感兴趣的任务开启贡献之旅！\n\n## 联系我们\n\n欢迎在 [GitHub Issues](https://github.com/FlagAI-Open/FlagAI/issues) 中提出你的问题，或在 [Discussions ](https://github.com/FlagAI-Open/FlagAI/discussions) 板块交流使用经验。\n\n* 官方邮箱：open.platform@baai.ac.cn。\n* 知乎：[FlagAI飞智](https://www.zhihu.com/people/95-22-20-18)\n* 扫码添加小助手加入**微信交流群**：\n\n<img src=\"./wechat-qrcode.jpg\" width = \"200\" height = \"200\"  align=center />\n\n\n\n## Quick Start\n\n### 安装环境\n\n* Python 版本 >= 3.8\n* PyTorch 版本 >= 1.8.0\n* [可选] 使用GPUs进行训练和测试, 你需要安装CUDA 和 NCCL\n\n- 通过`pip`安装:\n```shell\npip install -U flagai\n```\n\n- [可选] 下载源码安装:\n\n```shell\ngit clone https://github.com/FlagAI-Open/FlagAI.git\npython setup.py install\n```\n\n- [可选] 开启训练加速需要安装 NVIDIA的 [apex](https://github.com/NVIDIA/apex)\n```\ngit clone https://github.com/NVIDIA/apex\ncd apex\npip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n```\n- [可选] 使用 ZeRO 优化器，需要安装 [DEEPSPEED](https://github.com/microsoft/DeepSpeed) (>= 0.7.7)\n```\ngit clone https://github.com/microsoft/DeepSpeed\ncd DeepSpeed\nDS_BUILD_CPU_ADAM=1 DS_BUILD_AIO=1 DS_BUILD_UTILS=1 pip install -e .\nds_report # 检查deepspeed的状态\n```\n- [可选] 开启BMTrain训练，需要安装 [BMTrain](https://github.com/OpenBMB/BMTrain) ((>= 0.2.2))\n```\ngit clone https://github.com/OpenBMB/BMTrain\ncd BMTrain\npython setup.py install \n```\n\n- [可选] 开启BMInf低资源推理, 需要安装[BMInf](https://github.com/OpenBMB/BMInf)\n```\npip install bminf\n\n```\n- [可选] 对于FlashAttention, 需要安装[Flash-attention](https://github.com/HazyResearch/flash-attention) （>=1.0.2）\n```\npip install flash-attn\n```\n\n- [可选] 镜像构建，请参照 [Dockerfile](https://github.com/FlagAI-Open/FlagAI/blob/master/Dockerfile)\n- [提示] 单节点docker环境下，运行多卡数据并行需要设置host。 例如，docker节点 root@127.0.0.1，其端口 7110。\n```\n>>> vim ~/.ssh/config\nHost 127.0.0.1\n    Hostname 127.0.0.1\n    Port 7110\n    User root\n```\n- [提示] 多节点环境， 需要生成 ssh keys 并拷贝公钥到所有节点 (in `~/.ssh/`)\n```\n>>> ssh-keygen -t rsa -C \"xxx@xxx.com\"\n```\n\n### 加载模型和分词器\n我们提供 `AutoLoad` 类来快速加载模型和分词器，例如：\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nauto_loader = AutoLoader(\n      task_name=\"title-generation\",\n      model_name=\"RoBERTa-base-ch\"  \n)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n```\n\n这个例子是针对`title-generation`(文本摘要）任务的，你也可以通过修改`task_name`来为其他任务建模。 然后您可以使用模型和标记器进行微调或测试。\n\n### 使用预测器\n我们提供 `Predictor` 类来预测不同的任务，例如：\n\n```python\nfrom flagai.model.predictor.predictor import Predictor\npredictor = Predictor(model, tokenizer)\ntest_data = [\n    \"本文总结了十个可穿戴产品的设计原则而这些原则同样也是笔者认为是这个行业最吸引人的地方1为人们解决重复性问题2从人开始而不是从机器开始3要引起注意但不要刻意4提升用户能力而不是取代人\",\n    \"2007年乔布斯向人们展示iPhone并宣称它将会改变世界还有人认为他在夸大其词然而在8年后以iPhone为代表的触屏智能手机已经席卷全球各个角落未来智能手机将会成为真正的个人电脑为人类发展做出更大的贡献\",\n    \"雅虎发布2014年第四季度财报并推出了免税方式剥离其持有的阿里巴巴集团15％股权的计划打算将这一价值约400亿美元的宝贵投资分配给股东截止发稿前雅虎股价上涨了大约7％至5145美元\"\n]\nfor text in test_data:\n    print(\n        predictor.predict_generate_beamsearch(text,\n                                              out_max_length=50,\n                                              beam_size=3))\n```\n\n这个例子是针对 `seq2seq` 任务的，我们可以通过调用`predict_generate_beamsearch`函数得到`beam-search`结果。此外，我们还支持`NER`和`title generate`等任务的预测。\n\n\n### 命名实体识别任务示例\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\ntask_name = \"ner\"\nmodel_name = \"RoBERTa-base-ch\"\ntarget = [\"O\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\", \"B-PER\", \"I-PER\"]\nmaxlen = 256\n\nauto_loader = AutoLoader(task_name,\n                         model_name=model_name,\n                         load_pretrain_params=True,\n                         class_num=len(target))\n\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [\n    \"6月15日，河南省文物考古研究所曹操高陵文物队公开发表声明承认：“从来没有说过出土的珠子是墓主人的\",\n    \"4月8日，北京冬奥会、冬残奥会总结表彰大会在人民大会堂隆重举行。习近平总书记出席大会并发表重要讲话。在讲话中，总书记充分肯定了北京冬奥会、冬残奥会取得的优异成绩，全面回顾了7年筹办备赛的不凡历程，深入总结了筹备举办北京冬奥会、冬残奥会的宝贵经验，深刻阐释了北京冬奥精神，对运用好冬奥遗产推动高质量发展提出明确要求。\",\n    \"当地时间8日，欧盟委员会表示，欧盟各成员国政府现已冻结共计约300亿欧元与俄罗斯寡头及其他被制裁的俄方人员有关的资产。\",\n    \"这一盘口状态下英国必发公司亚洲盘交易数据显示博洛尼亚热。而从欧赔投注看，也是主队热。巴勒莫两连败，\",\n]\n\nfor t in test_data:\n    entities = predictor.predict_ner(t, target, maxlen=maxlen)\n    result = {}\n    for e in entities:\n        if e[2] not in result:\n            result[e[2]] = [t[e[0]:e[1] + 1]]\n        else:\n            result[e[2]].append(t[e[0]:e[1] + 1])\n    print(f\"result is {result}\")\n```\n\n\n### 语义相似度匹配任务示例\n\n```python\nfrom flagai.auto_model.auto_loader import AutoLoader\nfrom flagai.model.predictor.predictor import Predictor\n\nmaxlen = 256\n\nauto_loader = AutoLoader(\"semantic-matching\",\n                         model_name=\"RoBERTa-base-ch\",\n                         load_pretrain_params=True,\n                         class_num=2)\nmodel = auto_loader.get_model()\ntokenizer = auto_loader.get_tokenizer()\n\npredictor = Predictor(model, tokenizer)\n\ntest_data = [[\"后悔了吗\", \"你有没有后悔\"], [\"打开自动横屏\", \"开启移动数据\"],\n             [\"我觉得你很聪明\", \"你聪明我是这么觉得\"]]\n\nfor text_pair in test_data:\n    print(predictor.predict_cls_classifier(text_pair))\n\n```\n\n\n## 动态\n- [9 June 2023] 支持 v1.7.0版本, 增加Aquila [#324](https://github.com/FlagAI-Open/FlagAI/pull/324);\n- [31 Mar 2023] 支持v1.6.3版本, 增加AltCLIP-m18模型 [#303](https://github.com/FlagAI-Open/FlagAI/pull/303) 以及 AltDiffusion-m18模型 [#302](https://github.com/FlagAI-Open/FlagAI/pull/302); \n- [17 Mar 2023] 支持v1.6.2版本, 可以使用新的优化器 [#266](https://github.com/FlagAI-Open/FlagAI/pull/266), 并增加了英文gpt模型GPT2-base-en; \n- [2 Mar 2023] 支持v1.6.1版本, 增加Galactica模型 [#234](https://github.com/FlagAI-Open/FlagAI/pull/234), 大模型推理的低资源工具包BMInf [#238](https://github.com/FlagAI-Open/FlagAI/pull/238), 以及P-tuning样例 [#227](https://github.com/FlagAI-Open/FlagAI/pull/238)\n- [12 Jan 2023] 发布v1.6.0版本, 新增支持并行训练库 [**BMTrain**](https://github.com/OpenBMB/BMTrain) 以及集成 [**Flash Attention**](https://github.com/HazyResearch/flash-attention) 到 Bert 和 Vit 模型提速端到端训练, 示例见 [FlashAttentionBERT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/bert_title_generation_english/train_flash_atten.py)和 [FlashAttentionViT](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/vit_cifar100/train_single_gpu_flash_atten.py). 同时增加了基于对比搜索的文本生成方法 [**SimCTG**](https://github.com/yxuansu/SimCTG) 以及基于 AltDiffusion 进行 DreamBooth 个性化微调, 示例见 [AltDiffusionNaruto](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/AltDiffusion/dreambooth.py). \n- [28 Nov 2022] 发布v1.5.0版本, 支持1.1B参数的 [**EVA-CLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/EVA_CLIP) 以及[ALM: 基于GLM的阿拉伯语大模型], 示例见[**ALM**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/ALM)\n- [10 Nov 2022] 发布v1.4.0版本, 支持[AltCLIP: 更改CLIP中的语言编码器以扩展语言功能](https://arxiv.org/abs/2211.06679v1), 示例见[**AltCLIP**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltCLIP)以及[**AltDiffusion**](https://github.com/FlagAI-Open/FlagAI/tree/master/examples/AltDiffusion)\n- [29 Aug 2022] 支持v1.3.0版本, 增加CLIP模块以及重新设计了tokenizer的API: [#81](https://github.com/FlagAI-Open/FlagAI/pull/81)\n- [21 Jul 2022] 支持v1.2.0版本, 支持ViT系列模型: [#71](https://github.com/FlagAI-Open/FlagAI/pull/71)\n- [29 Jun 2022] 支持v1.1.0版本, 支持OPT的加载，微调和推理[#63](https://github.com/FlagAI-Open/FlagAI/pull/63)\n- [17 May 2022] 做出了我们的第一份贡献[#1](https://github.com/FlagAI-Open/FlagAI/pull/1)\n\n## 许可 LICENSE \n\n\nFlagAI飞智大部分项目基于 [Apache 2.0 license](https://www.apache.org/licenses/LICENSE-2.0)，但是请注意部分项目代码基于其他协议：\n\n* Megatron-LM 是基于协议 [Megatron-LM license](https://github.com/NVIDIA/Megatron-LM/blob/main/LICENSE)\n* GLM 是基于协议 [MIT license](https://github.com/THUDM/GLM/blob/main/LICENSE)\n* AltDiffusion 是基于协议 [CreativeML Open RAIL-M license](https://huggingface.co/spaces/CompVis/stable-diffusion-license)\n\n## 平台支持\n\n<div  align=\"center\">    \n<img src=\"./examples/Aquila/img/merged_platform.jpg\" height = \"100\" align=center />\n</div>\n\n\n## Misc\n\n### &#8627; Stargazers, thank you for your support!\n[![Stargazers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/stars/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/stargazers)\n\n### &#8627; Forkers, thank you for your support!\n[![Forkers repo roster for @FlagAI-Open/FlagAI](https://reporoster.com/forks/FlagAI-Open/FlagAI)](https://github.com/FlagAI-Open/FlagAI/network/members)\n\n### &#8627; Star History\n\n<div align=\"center\">\n\n![Star History Chart](https://api.star-history.com/svg?repos=FlagAI-Open/FlagAI&type=Date)]\n\n</div>\n"
        },
        {
          "name": "SUPPORT.md",
          "type": "blob",
          "size": 1.064453125,
          "content": "_Use this file to detail how to make get support forthe project. The structure below is generally recommended, but can be changed to meet the needs of the project_\n\n# Getting Help\n\nThere are a few ways to connect with the PROJECT NAME project:\n* https://github.com/FlagAI-Open/FlagAI/issues\n\n## How to Ask for Help\n\nIf you have trouble installing, building, or using PROJECT NAME, but there's not yet reason to suspect you've encountered a genuine bug,\nstart by posting a question to the mailing list or Slack channel. This is the place for question such has \"How do I...\".\n\n## How to report a bug or request an enhancement\n\nPROJECT NAME manages bug and enhancement using it's [issue tracker](https://github.com/FlagAI-Open/FlagAI/issues). The issue template will guide you on making an effective report.\n\n## How to report a security vulnerability\n\nIf you think you've found a potential vulnerability in PROJECT NAME, please\nemail security@PROJECT DOMAIN to responsibly disclose it.\n\n## Contributing a fix\n\nPlease refer to [CONTRIBUTING.md](CONTRIBUTING.md) to make a project contribution.\n"
        },
        {
          "name": "doc_zh",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "flagai",
          "type": "tree",
          "content": null
        },
        {
          "name": "flagopen.jpeg",
          "type": "blob",
          "size": 450.912109375,
          "content": null
        },
        {
          "name": "logo.png",
          "type": "blob",
          "size": 75.48046875,
          "content": null
        },
        {
          "name": "prepare_test.sh",
          "type": "blob",
          "size": 0.1533203125,
          "content": "git clone https://github.com/BAAI-OpenPlatform/checkpoints.git\ncd checkpoints\nunzip checkpoints.zip\nmv checkpoints/* .\nrm checkpoints -r\nrm checkpoints.zip\n\n"
        },
        {
          "name": "quickstart",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.0634765625,
          "content": "packaging\nPyYAML==5.4.1\ndeepspeed==0.6.5\nflash-attn==1.0.2\nbminf\n"
        },
        {
          "name": "script",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.06640625,
          "content": "[easy_install]\n\nindex_url = https://mirrors.aliyun.com/pypi/simple/\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.3544921875,
          "content": "# Copyright © 2022 BAAI. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\")\nfrom setuptools import find_packages, setup\n\nsetup(\n    name=\"flagai\",\n    version=\"v1.8.5\",\n    description=\"FlagAI aims to help researchers and developers to freely train and test large-scale models for NLP/CV/VL tasks.\",\n    long_description=open(\"README.md\", encoding=\"utf-8\").read(),\n    long_description_content_type=\"text/markdown\",\n    author=\"FlagAI-Open\",\n    author_email=\"open@baai.ac.cn\",\n    url=\"https://github.com/FlagAI-Open/FlagAI\",\n    packages=find_packages(exclude=\"tests\"),  # same as name\n    license=\"Apache 2.0\",\n    include_package_data=True,\n    python_requires=\">=3.8\",\n    install_requires=[\n        'nltk>=3.6.7',\n        'sentencepiece>=0.1.96',\n        'boto3>=1.17.32',\n        'pandas>=1.3.5',\n        'jieba>=0.42.1',\n        'scikit-learn>=1.0.2',\n        'tensorboard>=2.9.0',\n        'transformers>=4.31.0',\n        'datasets>=2.0.0',\n        'setuptools>=66.0.0',\n        'protobuf>=3.19.6',\n        'ftfy',\n        'Pillow>=9.3.0',\n        'einops>=0.3.0',\n        'diffusers>=0.7.2',\n        'pytorch-lightning>=1.6.5',\n        'taming-transformers-rom1504==0.0.6',\n        'rouge-score',\n        'sacrebleu>=2.3.1',\n        'jsonlines',\n        'accelerate',\n        'PyYAML>=5.4.1',\n        'safetensors',\n        'timm',\n    ]\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "wechat-qrcode.jpg",
          "type": "blob",
          "size": 79.1474609375,
          "content": null
        }
      ]
    }
  ]
}