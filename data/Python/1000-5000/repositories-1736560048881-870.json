{
  "metadata": {
    "timestamp": 1736560048881,
    "page": 870,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ownthink/Jiagu",
      "stars": 3344,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.15234375,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# self define\n.idea\n\n\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.8828125,
          "content": "# Jiagu自然语言处理工具\n>>> Jiagu使用大规模语料训练而成。将提供中文分词、词性标注、命名实体识别、情感分析、知识图谱关系抽取、关键词抽取、文本摘要、新词发现、情感分析、文本聚类等常用自然语言处理功能。参考了各大工具优缺点制作，将Jiagu回馈给大家。\n\n## 目录\n* [安装方式](#安装方式)\n* [使用方式](#使用方式)\n* [评价标准](#评价标准)\n* [附录说明](#附录)\n\n---\n\n提供的功能有：\n* 中文分词\n* 词性标注\n* 命名实体识别\n* 知识图谱关系抽取\n* 关键词提取\n* 文本摘要\n* 新词发现\n* 情感分析\n* 文本聚类\n* 等等。。。。\n\n---\n\n## 安装方式\npip安装\n```shell\npip install -U jiagu\n```\n如果比较慢，可以使用清华的pip源：`pip install -U jiagu -i https://pypi.tuna.tsinghua.edu.cn/simple`\n\n源码安装\n```shell\ngit clone https://github.com/ownthink/Jiagu\ncd Jiagu\npython3 setup.py install\n```\n\n## 使用方式\n1. 快速上手：分词、词性标注、命名实体识别\n```python3\nimport jiagu\n\n#jiagu.init() # 可手动初始化，也可以动态初始化\n\ntext = '厦门明天会不会下雨'\n\nwords = jiagu.seg(text) # 分词\nprint(words)\n\npos = jiagu.pos(words) # 词性标注\nprint(pos)\n\nner = jiagu.ner(words) # 命名实体识别\nprint(ner)\n```\n\n2. 中文分词\n```python3\nimport jiagu\n\ntext = '汉服和服装、维基图谱'\n\nwords = jiagu.seg(text)\nprint(words)\n\n# jiagu.load_userdict('dict/user.dict') # 加载自定义字典，支持字典路径、字典列表形式。\njiagu.load_userdict(['汉服和服装'])\n\nwords = jiagu.seg(text) # 自定义分词，字典分词模式有效\nprint(words)\n```\n\n3. 知识图谱关系抽取\n\n仅用于测试用，可以pip3 install jiagu==0.1.8，只能使用百科的描述进行测试。效果更佳的后期将会开放api。\n```python3\nimport jiagu\n\n# 吻别是由张学友演唱的一首歌曲。\n# 《盗墓笔记》是2014年欢瑞世纪影视传媒股份有限公司出品的一部网络季播剧，改编自南派三叔所著的同名小说，由郑保瑞和罗永昌联合导演，李易峰、杨洋、唐嫣、刘天佐、张智尧、魏巍等主演。\n\ntext = '姚明1980年9月12日出生于上海市徐汇区，祖籍江苏省苏州市吴江区震泽镇，前中国职业篮球运动员，司职中锋，现任中职联公司董事长兼总经理。'\nknowledge = jiagu.knowledge(text)\nprint(knowledge)\n```\n训练数据：https://github.com/ownthink/KnowledgeGraphData\n\n4. 关键词提取\n```python3\nimport jiagu\n\ntext = '''\n该研究主持者之一、波士顿大学地球与环境科学系博士陈池（音）表示，“尽管中国和印度国土面积仅占全球陆地的9%，但两国为这一绿化过程贡献超过三分之一。考虑到人口过多的国家一般存在对土地过度利用的问题，这个发现令人吃惊。”\nNASA埃姆斯研究中心的科学家拉玛·内曼尼（Rama Nemani）说，“这一长期数据能让我们深入分析地表绿化背后的影响因素。我们一开始以为，植被增加是由于更多二氧化碳排放，导致气候更加温暖、潮湿，适宜生长。”\n“MODIS的数据让我们能在非常小的尺度上理解这一现象，我们发现人类活动也作出了贡献。”\nNASA文章介绍，在中国为全球绿化进程做出的贡献中，有42%来源于植树造林工程，对于减少土壤侵蚀、空气污染与气候变化发挥了作用。\n据观察者网过往报道，2017年我国全国共完成造林736.2万公顷、森林抚育830.2万公顷。其中，天然林资源保护工程完成造林26万公顷，退耕还林工程完成造林91.2万公顷。京津风沙源治理工程完成造林18.5万公顷。三北及长江流域等重点防护林体系工程完成造林99.1万公顷。完成国家储备林建设任务68万公顷。\n'''\t\t\t\t\n\nkeywords = jiagu.keywords(text, 5) # 关键词\nprint(keywords)\n```\n\n5. 文本摘要\n```python3\nimport jiagu\n\nfin = open('input.txt', 'r')\ntext = fin.read()\nfin.close()\n\nsummarize = jiagu.summarize(text, 3) # 摘要\nprint(summarize)\n```\n\n6. 新词发现\n```python3\nimport jiagu\n\njiagu.findword('input.txt', 'output.txt') # 根据文本，利用信息熵做新词发现。\n```\n\n7. 情感分析\n```python3\nimport jiagu\n\ntext = '很讨厌还是个懒鬼'\nsentiment = jiagu.sentiment(text)\nprint(sentiment)\n```\n\n8. 文本聚类\n```python3\nimport jiagu\n\ndocs = [\n        \"百度深度学习中文情感分析工具Senta试用及在线测试\",\n        \"情感分析是自然语言处理里面一个热门话题\",\n        \"AI Challenger 2018 文本挖掘类竞赛相关解决方案及代码汇总\",\n        \"深度学习实践：从零开始做电影评论文本情感分析\",\n        \"BERT相关论文、文章和代码资源汇总\",\n        \"将不同长度的句子用BERT预训练模型编码，映射到一个固定长度的向量上\",\n        \"自然语言处理工具包spaCy介绍\",\n        \"现在可以快速测试一下spaCy的相关功能，我们以英文数据为例，spaCy目前主要支持英文和德文\"\n    ]\ncluster = jiagu.text_cluster(docs)\t\nprint(cluster)\n```\n\n## 评价标准\n1. msr测试结果（旧版本）\n\n![msr](https://github.com/ownthink/evaluation/blob/master/images/2.png)\n\n\n## 附录\n1. 词性标注说明\n```text\nn　　　普通名词\nnt　 　时间名词\nnd　 　方位名词\nnl　 　处所名词\nnh　 　人名\nnhf　　姓\nnhs　　名\nns　 　地名\nnn 　　族名\nni 　　机构名\nnz 　　其他专名\nv　　 动词\nvd　　趋向动词\nvl　　联系动词\nvu　　能愿动词\na　 　形容词\nf　 　区别词\nm　 　数词　　\nq　 　量词\nd　 　副词\nr　 　代词\np　　 介词\nc　 　连词\nu　　 助词\ne　 　叹词\no　 　拟声词\ni　 　习用语\nj　　 缩略语\nh　　 前接成分\nk　　 后接成分\ng　 　语素字\nx　 　非语素字\nw　 　标点符号\nws　　非汉字字符串\nwu　　其他未知的符号\n```\n\n2. 命名实体说明（采用BIO标记方式）\n```text\nB-PER、I-PER   人名\nB-LOC、I-LOC   地名\nB-ORG、I-ORG   机构名\n```\n\n## 加入我们\n```text\n人工智能qq群1：90780053(满)\n人工智能qq群2：956936481（满）\n人工智能qq群3：1160292084（满）\n人工智能qq群4：1019825236（满）\n人工智能qq群5：535614287\n知识图谱qq群1：55152968\n知识图谱qq群2：740104333（满）\n知识图谱qq群3：586457987（满）\n知识图谱qq群4：858829119\n\n微信群可联系作者微信：MrYener，作者邮箱联系方式：help@ownthink.com\n```\n<p>捐赠作者(您的鼓励是作者开源最大的动力！！！)：<a href=\"https://github.com/ownthink/Jiagu/wiki/donation\"target=\"_blank\">捐赠致谢</a> </p>\n\n![收款码](https://github.com/ownthink/KnowledgeGraph/raw/master/img/%E6%94%B6%E6%AC%BE%E7%A0%81.jpg)\n\n\n## 贡献者：\n1. [Yener](https://github.com/ownthink)\n2. [zengbin93](https://github.com/zengbin93)\n3. [dirtdust](https://github.com/dirtdust)\n4. [frankchen7788](https://github.com/frankchen7788)\n\n\n\n"
        },
        {
          "name": "demo.py",
          "type": "blob",
          "size": 3.2412109375,
          "content": "import jiagu\n\n# jiagu.init() # 可手动初始化，也可以动态初始化\n\n\ntext = '苏州的天气不错'\n\nwords = jiagu.seg(text)  # 分词\nprint(words)\n\nwords = jiagu.cut(text)  # 分词\nprint(words)\n\npos = jiagu.pos(words)  # 词性标注\nprint(pos)\n\nner = jiagu.ner(words)  # 命名实体识别\nprint(ner)\n\n\n# 字典模式分词\ntext = '思知机器人挺好用的'\nwords = jiagu.seg(text)\nprint(words)\n\n# jiagu.load_userdict('dict/user.dict') # 加载自定义字典，支持字典路径、字典列表形式。\njiagu.load_userdict(['思知机器人'])\n\nwords = jiagu.seg(text)\nprint(words)\n\n\n\ntext = '''\n该研究主持者之一、波士顿大学地球与环境科学系博士陈池（音）表示，“尽管中国和印度国土面积仅占全球陆地的9%，但两国为这一绿化过程贡献超过三分之一。考虑到人口过多的国家一般存在对土地过度利用的问题，这个发现令人吃惊。”\nNASA埃姆斯研究中心的科学家拉玛·内曼尼（Rama Nemani）说，“这一长期数据能让我们深入分析地表绿化背后的影响因素。我们一开始以为，植被增加是由于更多二氧化碳排放，导致气候更加温暖、潮湿，适宜生长。”\n“MODIS的数据让我们能在非常小的尺度上理解这一现象，我们发现人类活动也作出了贡献。”\nNASA文章介绍，在中国为全球绿化进程做出的贡献中，有42%来源于植树造林工程，对于减少土壤侵蚀、空气污染与气候变化发挥了作用。\n据观察者网过往报道，2017年我国全国共完成造林736.2万公顷、森林抚育830.2万公顷。其中，天然林资源保护工程完成造林26万公顷，退耕还林工程完成造林91.2万公顷。京津风沙源治理工程完成造林18.5万公顷。三北及长江流域等重点防护林体系工程完成造林99.1万公顷。完成国家储备林建设任务68万公顷。\n'''\t\t\t\t\n\nkeywords = jiagu.keywords(text, 5)  # 关键词抽取\nprint(keywords)\n\nsummarize = jiagu.summarize(text, 3)  # 文本摘要\nprint(summarize)\n\n\n# jiagu.findword('input.txt', 'output.txt') # 根据大规模语料，利用信息熵做新词发现。\n\n\n# 知识图谱关系抽取\ntext = '姚明1980年9月12日出生于上海市徐汇区，祖籍江苏省苏州市吴江区震泽镇，前中国职业篮球运动员，司职中锋，现任中职联公司董事长兼总经理。'\nknowledge = jiagu.knowledge(text)\nprint(knowledge)\n\n\n# 情感分析\ntext = '很讨厌还是个懒鬼'\nsentiment = jiagu.sentiment(text)\nprint(sentiment)\n\n\n# 文本聚类（需要调参）\ndocs = [\n        \"百度深度学习中文情感分析工具Senta试用及在线测试\",\n        \"情感分析是自然语言处理里面一个热门话题\",\n        \"AI Challenger 2018 文本挖掘类竞赛相关解决方案及代码汇总\",\n        \"深度学习实践：从零开始做电影评论文本情感分析\",\n        \"BERT相关论文、文章和代码资源汇总\",\n        \"将不同长度的句子用BERT预训练模型编码，映射到一个固定长度的向量上\",\n        \"自然语言处理工具包spaCy介绍\",\n        \"现在可以快速测试一下spaCy的相关功能，我们以英文数据为例，spaCy目前主要支持英文和德文\"\n    ]\ncluster = jiagu.text_cluster(docs)\t\nprint(cluster)\n"
        },
        {
          "name": "jiagu",
          "type": "tree",
          "content": null
        },
        {
          "name": "license",
          "type": "blob",
          "size": 1.0498046875,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2018 OwnThink\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.55859375,
          "content": "#!/usr/bin/env python\n# -*- coding:utf-8 -*-\nfrom setuptools import setup\n\nsetup(name='jiagu',\n      version='0.2.3',\n      description='Jiagu Natural Language Processing',\n      author='Yener(Zheng Wenyu)',\n      author_email='help@ownthink.com',\n      url='https://github.com/ownthink/Jiagu',\n      license='MIT',\n      packages=['jiagu'],\n      package_dir={'jiagu': 'jiagu'},\n      package_data={'jiagu': ['*.*', 'cluster/*', 'data/*', 'model/*',\n\t\t'normal/*', 'segment/*', 'segment/dict/*','segment/model/*',\n\t\t'sentiment/*', 'sentiment/model/*', 'topic/*']}\n      )\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "train",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}