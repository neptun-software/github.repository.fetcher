{
  "metadata": {
    "timestamp": 1736559736535,
    "page": 437,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "modelscope/FunClip",
      "stars": 3997,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0712890625,
          "content": "*.pyc\n.DS_Store\n*.DS_Store\nClipVideo/clipvideo/output\n*__pycache__\n*.spec"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0390625,
          "content": "MIT License\n\nCopyright (c) 2023 Alibaba\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.9443359375,
          "content": "[![SVG Banners](https://svg-banners.vercel.app/api?type=rainbow&text1=FunClip%20%20ğŸ¥’&width=800&height=210)](https://github.com/Akshay090/svg-banners)\n\n### <p align=\"center\">ã€Œ[ç®€ä½“ä¸­æ–‡](./README_zh.md) | Englishã€</p>\n\n**<p align=\"center\"> âš¡ Open-source, accurate and easy-to-use video clipping tool </p>**\n**<p align=\"center\"> ğŸ§  Explore LLM based video clipping with FunClip </p>**\n\n<p align=\"center\"> <img src=\"docs/images/interface.jpg\" width=444/></p>\n\n<p align=\"center\" class=\"trendshift\">\n<a href=\"https://trendshift.io/repositories/10126\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/10126\" alt=\"alibaba-damo-academy%2FFunClip | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"300\" height=\"55\"/></a>\n</p>\n\n<div align=\"center\">  \n<h4>\n<a href=\"#What's New\"> What's New </a>\nï½œ<a href=\"#On Going\"> On Going </a>\nï½œ<a href=\"#Install\"> Install </a>\nï½œ<a href=\"#Usage\"> Usage </a>\nï½œ<a href=\"#Community\"> Community </a>\n</h4>\n</div>\n\n**FunClip** is a fully open-source, locally deployed automated video clipping tool. It leverages Alibaba TONGYI speech lab's open-source [FunASR](https://github.com/alibaba-damo-academy/FunASR) Paraformer series models to perform speech recognition on videos. Then, users can freely choose text segments or speakers from the recognition results and click the clip button to obtain the video clip corresponding to the selected segments (Quick Experience [Modelscopeâ­](https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary) [HuggingFaceğŸ¤—](https://huggingface.co/spaces/R1ckShi/FunClip)).\n\n## HighlightsğŸ¨\n\n- ğŸ”¥Try AI clipping using LLM in FunClip now.\n- FunClip integrates Alibaba's open-source industrial-grade model [Paraformer-Large](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary), which is one of the best-performing open-source Chinese ASR models available, with over 13 million downloads on Modelscope. It can also accurately predict timestamps in an integrated manner.\n- FunClip incorporates the hotword customization feature of [SeACo-Paraformer](https://modelscope.cn/models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary), allowing users to specify certain entity words, names, etc., as hotwords during the ASR process to enhance recognition results.\n- FunClip integrates the [CAM++](https://modelscope.cn/models/iic/speech_campplus_sv_zh-cn_16k-common/summary) speaker recognition model, enabling users to use the auto-recognized speaker ID as the target for trimming, to clip segments from a specific speaker.\n- The functionalities are realized through Gradio interaction, offering simple installation and ease of use. It can also be deployed on a server and accessed via a browser.\n- FunClip supports multi-segment free clipping and automatically returns full video SRT subtitles and target segment SRT subtitles, offering a simple and convenient user experience.\n\n<a name=\"What's New\"></a>\n## What's NewğŸš€\n- 2024/06/12 FunClip supports recognize and clip English audio files now. Run `python funclip/launch.py -l en` to try.\n- ğŸ”¥2024/05/13 FunClip v2.0.0 now supports smart clipping with large language models, integrating models from the qwen series, GPT series, etc., providing default prompts. You can also explore and share tips for setting prompts, the usage is as follows:\n  1. After the recognition, select the name of the large model and configure your own apikey;\n  2. Click on the 'LLM Inference' button, and FunClip will automatically combine two prompts with the video's srt subtitles;\n  3. Click on the 'AI Clip' button, and based on the output results of the large language model from the previous step, FunClip will extract the timestamps for clipping;\n  4. You can try changing the prompt to leverage the capabilities of the large language models to get the results you want;\n- 2024/05/09 FunClip updated to v1.1.0, including the following updates and fixes:\n  - Support configuration of output file directory, saving ASR intermediate results and video clipping intermediate files;\n  - UI upgrade (see guide picture below), video and audio cropping function are on the same page now, button position adjustment;\n  - Fixed a bug introduced due to FunASR interface upgrade, which has caused some serious clipping errors;\n  - Support configuring different start and end time offsets for each paragraph;\n  - Code update, etc;\n- 2024/03/06 Fix bugs in using FunClip with command line.\n- 2024/02/28 [FunASR](https://github.com/alibaba-damo-academy/FunASR) is updated to 1.0 version, use FunASR1.0 and SeACo-Paraformer to conduct ASR with hotword customization.\n- 2023/10/17 Fix bugs in multiple periods chosen, used to return video with wrong length.\n- 2023/10/10 FunClipper now supports recognizing with speaker diarization ability, choose 'yes' button in 'Recognize Speakers' and you will get recognition results with speaker id for each sentence. And then you can clip out the periods of one or some speakers (e.g. 'spk0' or 'spk0#spk3') using FunClipper.\n\n<a name=\"On Going\"></a>\n## On GoingğŸŒµ\n\n- [x] FunClip will support Whisper model for English users, coming soon (ASR using Whisper with timestamp requires massive GPU memory, we support timestamp prediction for vanilla Paraformer in FunASR to achieving this).\n- [x] FunClip will further explore the abilities of large langage model based AI clipping, welcome to discuss about prompt setting and clipping, etc.\n- [ ] Reverse periods choosing while clipping.\n- [ ] Removing silence periods.\n\n<a name=\"Install\"></a>\n## InstallğŸ”¨\n\n### Python env install\n\nFunClip basic functions rely on a python environment only.\n```shell\n# clone funclip repo\ngit clone https://github.com/alibaba-damo-academy/FunClip.git\ncd FunClip\n# install Python requirments\npip install -r ./requirements.txt\n```\n\n### imagemagick install (Optional)\n\nIf you want to clip video file with embedded subtitles\n\n1. ffmpeg and imagemagick is required\n\n- On Ubuntu\n```shell\napt-get -y update && apt-get -y install ffmpeg imagemagick\nsed -i 's/none/read,write/g' /etc/ImageMagick-6/policy.xml\n```\n- On MacOS\n```shell\nbrew install imagemagick\nsed -i 's/none/read,write/g' /usr/local/Cellar/imagemagick/7.1.1-8_1/etc/ImageMagick-7/policy.xml \n```\n- On Windows\n\nDownload and install imagemagick https://imagemagick.org/script/download.php#windows\n\nFind your python install path and change the `IMAGEMAGICK_BINARY` to your imagemagick install path in file `site-packages\\moviepy\\config_defaults.py`\n\n2. Download font file to funclip/font\n\n```shell\nwget https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ClipVideo/STHeitiMedium.ttc -O font/STHeitiMedium.ttc\n```\n<a name=\"Usage\"></a>\n## Use FunClip\n\n### A. Use FunClip as local Gradio Service\nYou can establish your own FunClip service which is same as [Modelscope Space](https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary) as follow:\n```shell\npython funclip/launch.py\n# '-l en' for English audio recognize\n# '-p xxx' for setting port number\n# '-s True' for establishing service for public accessing\n```\nthen visit ```localhost:7860``` you will get a Gradio service like below and you can use FunClip following the steps:\n\n- Step1: Upload your video file (or try the example videos below)\n- Step2: Copy the text segments you need to 'Text to Clip'\n- Step3: Adjust subtitle settings (if needed)\n- Step4: Click 'Clip' or 'Clip and Generate Subtitles'\n\n<img src=\"docs/images/guide.jpg\"/>\n\nFollow the guide below to explore LLM based clipping:\n\n<img src=\"docs/images/LLM_guide.png\" width=360/>\n\n### B. Experience FunClip in Modelscope\n\n[FunClip@Modelscope Spaceâ­](https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary)\n\n[FunClip@HuggingFace SpaceğŸ¤—](https://huggingface.co/spaces/R1ckShi/FunClip)\n\n### C. Use FunClip in command line\n\nFunClip supports you to recognize and clip with commands:\n```shell\n# step1: Recognize\npython funclip/videoclipper.py --stage 1 \\\n                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \\\n                       --output_dir ./output\n# now you can find recognition results and entire SRT file in ./output/\n# step2: Clip\npython funclip/videoclipper.py --stage 2 \\\n                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \\\n                       --output_dir ./output \\\n                       --dest_text 'æˆ‘ä»¬æŠŠå®ƒè·Ÿä¹¡æ‘æŒ¯å…´å»ç»“åˆèµ·æ¥ï¼Œåˆ©ç”¨æˆ‘ä»¬çš„è®¾è®¡çš„èƒ½åŠ›' \\\n                       --start_ost 0 \\\n                       --end_ost 100 \\\n                       --output_file './output/res.mp4'\n```\n\n<a name=\"Community\"></a>\n## Community CommunicationğŸŸ\n\nFunClip is firstly open-sourced bu FunASR team, any useful PR is welcomed.\n\nYou can also scan the following DingTalk group or WeChat group QR code to join the community group for communication.\n\n|                           DingTalk group                            |                     WeChat group                      |\n|:-------------------------------------------------------------------:|:-----------------------------------------------------:|\n| <div align=\"left\"><img src=\"docs/images/dingding.png\" width=\"250\"/> | <img src=\"docs/images/wechat.png\" width=\"215\"/></div> |\n\n## Find Speech Models in FunASR\n\n[FunASR](https://github.com/alibaba-damo-academy/FunASR) hopes to build a bridge between academic research and industrial applications on speech recognition. By supporting the training & finetuning of the industrial-grade speech recognition model released on ModelScope, researchers and developers can conduct research and production of speech recognition models more conveniently, and promote the development of speech recognition ecology. ASR for Funï¼\n\nğŸ“šFunASR Paper: <a href=\"https://arxiv.org/abs/2305.11013\"><img src=\"https://img.shields.io/badge/Arxiv-2305.11013-orange\"></a> \n\nğŸ“šSeACo-Paraformer Paper: <a href=\"https://arxiv.org/abs/2308.03266\"><img src=\"https://img.shields.io/badge/Arxiv-2308.03266-orange\"></a>\n\nğŸŒŸSupport FunASR: <a href='https://github.com/alibaba-damo-academy/FunASR/stargazers'><img src='https://img.shields.io/github/stars/alibaba-damo-academy/FunASR.svg?style=social'></a>\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 9.244140625,
          "content": "[![SVG Banners](https://svg-banners.vercel.app/api?type=rainbow&text1=FunClip%20%20ğŸ¥’&width=800&height=210)](https://github.com/Akshay090/svg-banners)\n\n### <p align=\"center\">ã€Œç®€ä½“ä¸­æ–‡ | [English](./README.md)ã€</p>\n\n**<p align=\"center\"> âš¡ å¼€æºã€ç²¾å‡†ã€æ–¹ä¾¿çš„è§†é¢‘åˆ‡ç‰‡å·¥å…· </p>**\n**<p align=\"center\"> ğŸ§  é€šè¿‡FunClipæ¢ç´¢åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è§†é¢‘å‰ªè¾‘ </p>**\n\n<p align=\"center\"> <img src=\"docs/images/interface.jpg\" width=444/></p>\n\n<p align=\"center\" class=\"trendshift\">\n<a href=\"https://trendshift.io/repositories/10126\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/10126\" alt=\"alibaba-damo-academy%2FFunClip | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<div align=\"center\">  \n<h4><a href=\"#è¿‘æœŸæ›´æ–°\"> è¿‘æœŸæ›´æ–° </a>\nï½œ<a href=\"#æ–½å·¥ä¸­\"> æ–½å·¥ä¸­ </a>\nï½œ<a href=\"#å®‰è£…ç¯å¢ƒ\"> å®‰è£…ç¯å¢ƒ </a>\nï½œ<a href=\"#ä½¿ç”¨æ–¹æ³•\"> ä½¿ç”¨æ–¹æ³• </a>\nï½œ<a href=\"#ç¤¾åŒºäº¤æµ\"> ç¤¾åŒºäº¤æµ </a>\n</h4>\n</div>\n\n**FunClip**æ˜¯ä¸€æ¬¾å®Œå…¨å¼€æºã€æœ¬åœ°éƒ¨ç½²çš„è‡ªåŠ¨åŒ–è§†é¢‘å‰ªè¾‘å·¥å…·ï¼Œé€šè¿‡è°ƒç”¨é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤å¼€æºçš„[FunASR](https://github.com/alibaba-damo-academy/FunASR) Paraformerç³»åˆ—æ¨¡å‹è¿›è¡Œè§†é¢‘çš„è¯­éŸ³è¯†åˆ«ï¼Œéšåç”¨æˆ·å¯ä»¥è‡ªç”±é€‰æ‹©è¯†åˆ«ç»“æœä¸­çš„æ–‡æœ¬ç‰‡æ®µæˆ–è¯´è¯äººï¼Œç‚¹å‡»è£å‰ªæŒ‰é’®å³å¯è·å–å¯¹åº”ç‰‡æ®µçš„è§†é¢‘ï¼ˆå¿«é€Ÿä½“éªŒ [Modelscopeâ­](https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary)  [HuggingFaceğŸ¤—](https://huggingface.co/spaces/R1ckShi/FunClip)ï¼‰ã€‚\n\n## çƒ­ç‚¹&ç‰¹æ€§ğŸ¨\n\n- ğŸ”¥FunClipé›†æˆäº†å¤šç§å¤§è¯­è¨€æ¨¡å‹è°ƒç”¨æ–¹å¼å¹¶æä¾›äº†prompté…ç½®æ¥å£ï¼Œå°è¯•é€šè¿‡å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè§†é¢‘è£å‰ª~\n- FunClipé›†æˆäº†é˜¿é‡Œå·´å·´å¼€æºçš„å·¥ä¸šçº§æ¨¡å‹[Paraformer-Large](https://modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)ï¼Œæ˜¯å½“å‰è¯†åˆ«æ•ˆæœæœ€ä¼˜çš„å¼€æºä¸­æ–‡ASRæ¨¡å‹ä¹‹ä¸€ï¼ŒModelscopeä¸‹è½½é‡1300w+æ¬¡ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸€ä½“åŒ–çš„å‡†ç¡®é¢„æµ‹æ—¶é—´æˆ³ã€‚\n- FunClipé›†æˆäº†[SeACo-Paraformer](https://modelscope.cn/models/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)çš„çƒ­è¯å®šåˆ¶åŒ–åŠŸèƒ½ï¼Œåœ¨ASRè¿‡ç¨‹ä¸­å¯ä»¥æŒ‡å®šä¸€äº›å®ä½“è¯ã€äººåç­‰ä½œä¸ºçƒ­è¯ï¼Œæå‡è¯†åˆ«æ•ˆæœã€‚\n- FunClipé›†æˆäº†[CAM++](https://modelscope.cn/models/iic/speech_campplus_sv_zh-cn_16k-common/summary)è¯´è¯äººè¯†åˆ«æ¨¡å‹ï¼Œç”¨æˆ·å¯ä»¥å°†è‡ªåŠ¨è¯†åˆ«å‡ºçš„è¯´è¯äººIDä½œä¸ºè£å‰ªç›®æ ‡ï¼Œå°†æŸä¸€è¯´è¯äººçš„æ®µè½è£å‰ªå‡ºæ¥ã€‚\n- é€šè¿‡Gradioäº¤äº’å®ç°ä¸Šè¿°åŠŸèƒ½ï¼Œå®‰è£…ç®€å•ä½¿ç”¨æ–¹ä¾¿ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æœåŠ¡ç«¯æ­å»ºæœåŠ¡é€šè¿‡æµè§ˆå™¨ä½¿ç”¨ã€‚\n- FunClipæ”¯æŒå¤šæ®µè‡ªç”±å‰ªè¾‘ï¼Œå¹¶ä¸”ä¼šè‡ªåŠ¨è¿”å›å…¨è§†é¢‘SRTå­—å¹•ã€ç›®æ ‡æ®µè½SRTå­—å¹•ï¼Œä½¿ç”¨ç®€å•æ–¹ä¾¿ã€‚\n\næ¬¢è¿ä½“éªŒä½¿ç”¨ï¼Œæ¬¢è¿æå‡ºå…³äºå­—å¹•ç”Ÿæˆæˆ–è¯­éŸ³è¯†åˆ«çš„éœ€æ±‚ä¸å®è´µå»ºè®®~\n\n<a name=\"è¿‘æœŸæ›´æ–°\"></a>\n## è¿‘æœŸæ›´æ–°ğŸš€\n\n- 2024/06/12 FunClipç°åœ¨æ”¯æŒè¯†åˆ«ä¸è£å‰ªè‹±æ–‡è§†é¢‘ï¼Œé€šè¿‡`python funclip/launch.py -l en`æ¥å¯åŠ¨è‹±æ–‡ç‰ˆæœ¬æœåŠ¡ã€‚\n- ğŸ”¥2024/05/13 FunClip v2.0.0åŠ å…¥å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½è£å‰ªåŠŸèƒ½ï¼Œé›†æˆqwenç³»åˆ—ï¼Œgptç³»åˆ—ç­‰æ¨¡å‹ï¼Œæä¾›é»˜è®¤promptï¼Œæ‚¨ä¹Ÿå¯ä»¥æ¢ç´¢å¹¶åˆ†äº«promptçš„è®¾ç½®æŠ€å·§ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š\n  1. åœ¨è¿›è¡Œè¯†åˆ«ä¹‹åï¼Œé€‰æ‹©å¤§æ¨¡å‹åç§°ï¼Œé…ç½®ä½ è‡ªå·±çš„apikeyï¼›\n  2. ç‚¹å‡»'LLMæ™ºèƒ½æ®µè½é€‰æ‹©'æŒ‰é’®ï¼ŒFunClipå°†è‡ªåŠ¨ç»„åˆä¸¤ä¸ªpromptä¸è§†é¢‘çš„srtå­—å¹•ï¼›\n  3. ç‚¹å‡»'LLMæ™ºèƒ½è£å‰ª'æŒ‰é’®ï¼ŒåŸºäºå‰ä¸€æ­¥çš„å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºç»“æœï¼ŒFunClipå°†æå–å…¶ä¸­çš„æ—¶é—´æˆ³è¿›è¡Œè£å‰ªï¼›\n  4. æ‚¨å¯ä»¥å°è¯•æ”¹å˜promptæ¥å€ŸåŠ©å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›æ¥è·å–æ‚¨æƒ³è¦çš„ç»“æœï¼›\n- 2024/05/09 FunClipæ›´æ–°è‡³v1.1.0ï¼ŒåŒ…å«å¦‚ä¸‹æ›´æ–°ä¸ä¿®å¤ï¼š\n  - æ”¯æŒé…ç½®è¾“å‡ºæ–‡ä»¶ç›®å½•ï¼Œä¿å­˜ASRä¸­é—´ç»“æœä¸è§†é¢‘è£å‰ªä¸­é—´æ–‡ä»¶ï¼›\n  - UIå‡çº§ï¼ˆè§ä¸‹æ–¹æ¼”ç¤ºå›¾ä¾‹ï¼‰ï¼Œè§†é¢‘ä¸éŸ³é¢‘è£å‰ªåŠŸèƒ½åœ¨åŒä¸€é¡µï¼ŒæŒ‰é’®ä½ç½®è°ƒæ•´ï¼›\n  - ä¿®å¤äº†ç”±äºFunASRæ¥å£å‡çº§å¼•å…¥çš„bugï¼Œè¯¥bugæ›¾å¯¼è‡´ä¸€äº›ä¸¥é‡çš„å‰ªè¾‘é”™è¯¯ï¼›\n  - æ”¯æŒä¸ºæ¯ä¸€ä¸ªæ®µè½é…ç½®ä¸åŒçš„èµ·æ­¢æ—¶é—´åç§»ï¼›\n  - ä»£ç ä¼˜åŒ–ç­‰ï¼›\n- 2024/03/06 å‘½ä»¤è¡Œè°ƒç”¨æ–¹å¼æ›´æ–°ä¸é—®é¢˜ä¿®å¤ï¼Œç›¸å…³åŠŸèƒ½å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚\n- 2024/02/28 FunClipå‡çº§åˆ°FunASR1.0æ¨¡å‹è°ƒç”¨æ–¹å¼ï¼Œé€šè¿‡FunASRå¼€æºçš„SeACo-Paraformeræ¨¡å‹åœ¨è§†é¢‘å‰ªè¾‘ä¸­è¿›ä¸€æ­¥æ”¯æŒçƒ­è¯å®šåˆ¶åŒ–åŠŸèƒ½ã€‚\n- 2024/02/28 åŸFunASR-APP/ClipVideoæ›´åä¸ºFunClipã€‚\n\n<a name=\"æ–½å·¥ä¸­\"></a>\n## æ–½å·¥ä¸­ğŸŒµ\n\n- [x] FunClipå°†ä¼šé›†æˆWhisperæ¨¡å‹ï¼Œä»¥æä¾›è‹±æ–‡è§†é¢‘å‰ªè¾‘èƒ½åŠ›(Whisperæ¨¡å‹çš„æ—¶é—´æˆ³é¢„æµ‹åŠŸèƒ½éœ€è¦æ˜¾å­˜è¾ƒå¤§ï¼Œæˆ‘ä»¬åœ¨FunASRä¸­æ·»åŠ äº†Paraformerè‹±æ–‡æ¨¡å‹çš„æ—¶é—´æˆ³é¢„æµ‹æ”¯æŒä»¥å…è®¸FunClipæ”¯æŒè‹±æ–‡è¯†åˆ«è£å‰ª)ã€‚\n- [x] é›†æˆå¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œæä¾›æ™ºèƒ½è§†é¢‘å‰ªè¾‘ç›¸å…³åŠŸèƒ½ã€‚å¤§å®¶å¯ä»¥åŸºäºFunClipæ¢ç´¢ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è§†é¢‘å‰ªè¾‘~\n- [ ] ç»™å®šæ–‡æœ¬æ®µè½ï¼Œåå‘é€‰å–å…¶ä»–æ®µè½ã€‚\n- [ ] åˆ é™¤è§†é¢‘ä¸­æ— äººè¯´è¯çš„ç‰‡æ®µã€‚\n\n<a name=\"å®‰è£…ç¯å¢ƒ\"></a>\n## å®‰è£…ğŸ”¨\n\n### Pythonç¯å¢ƒå®‰è£…\n\nFunClipçš„è¿è¡Œä»…ä¾èµ–äºä¸€ä¸ªPythonç¯å¢ƒï¼Œè‹¥æ‚¨æ˜¯ä¸€ä¸ªå°ç™½å¼€å‘è€…ï¼Œå¯ä»¥å…ˆäº†è§£ä¸‹å¦‚ä½•ä½¿ç”¨Pythonï¼Œpipç­‰~\n```shell\n# å…‹éš†funclipä»“åº“\ngit clone https://github.com/alibaba-damo-academy/FunClip.git\ncd FunClip\n# å®‰è£…ç›¸å…³Pythonä¾èµ–\npip install -r ./requirements.txt\n```\n\n### å®‰è£…imagemagickï¼ˆå¯é€‰ï¼‰\n\n1. å¦‚æœä½ å¸Œæœ›ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆå­—å¹•çš„è§†é¢‘è£å‰ªåŠŸèƒ½ï¼Œéœ€è¦å®‰è£…imagemagick\n\n- Ubuntu\n```shell\napt-get -y update && apt-get -y install ffmpeg imagemagick\nsed -i 's/none/read,write/g' /etc/ImageMagick-6/policy.xml\n```\n- MacOS\n```shell\nbrew install imagemagick\nsed -i 's/none/read,write/g' /usr/local/Cellar/imagemagick/7.1.1-8_1/etc/ImageMagick-7/policy.xml \n```\n- Windows\n\né¦–å…ˆä¸‹è½½å¹¶å®‰è£…imagemagick https://imagemagick.org/script/download.php#windows\n\nç„¶åç¡®å®šæ‚¨çš„Pythonå®‰è£…ä½ç½®ï¼Œåœ¨å…¶ä¸­çš„`site-packages\\moviepy\\config_defaults.py`æ–‡ä»¶ä¸­ä¿®æ”¹`IMAGEMAGICK_BINARY`ä¸ºimagemagickçš„exeè·¯å¾„\n\n2. ä¸‹è½½ä½ éœ€è¦çš„å­—ä½“æ–‡ä»¶ï¼Œè¿™é‡Œæˆ‘ä»¬æä¾›ä¸€ä¸ªé»˜è®¤çš„é»‘ä½“å­—ä½“æ–‡ä»¶\n\n```shell\nwget https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ClipVideo/STHeitiMedium.ttc -O font/STHeitiMedium.ttc\n```\n\n<a name=\"ä½¿ç”¨æ–¹æ³•\"></a>\n## ä½¿ç”¨FunClip\n\n### A.åœ¨æœ¬åœ°å¯åŠ¨GradioæœåŠ¡\n\n```shell\npython funclip/launch.py\n# '-l en' for English audio recognize\n# '-p xxx' for setting port number\n# '-s True' for establishing service for public accessing\n```\néšååœ¨æµè§ˆå™¨ä¸­è®¿é—®```localhost:7860```å³å¯çœ‹åˆ°å¦‚ä¸‹å›¾æ‰€ç¤ºçš„ç•Œé¢ï¼ŒæŒ‰å¦‚ä¸‹æ­¥éª¤å³å¯è¿›è¡Œè§†é¢‘å‰ªè¾‘\n1. ä¸Šä¼ ä½ çš„è§†é¢‘ï¼ˆæˆ–ä½¿ç”¨ä¸‹æ–¹çš„è§†é¢‘ç”¨ä¾‹ï¼‰\n2. ï¼ˆå¯é€‰ï¼‰è®¾ç½®çƒ­è¯ï¼Œè®¾ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„ï¼ˆä¿å­˜è¯†åˆ«ç»“æœã€è§†é¢‘ç­‰ï¼‰\n3. ç‚¹å‡»è¯†åˆ«æŒ‰é’®è·å–è¯†åˆ«ç»“æœï¼Œæˆ–ç‚¹å‡»è¯†åˆ«+åŒºåˆ†è¯´è¯äººåœ¨è¯­éŸ³è¯†åˆ«åŸºç¡€ä¸Šè¯†åˆ«è¯´è¯äººID\n4. å°†è¯†åˆ«ç»“æœä¸­çš„é€‰æ®µå¤åˆ¶åˆ°å¯¹åº”ä½ç½®ï¼Œæˆ–è€…å°†è¯´è¯äººIDè¾“å…¥åˆ°å¯¹åº”ä¸ºæ­¢\n5. ï¼ˆå¯é€‰ï¼‰é…ç½®å‰ªè¾‘å‚æ•°ï¼Œåç§»é‡ä¸å­—å¹•è®¾ç½®ç­‰\n6. ç‚¹å‡»â€œè£å‰ªâ€æˆ–â€œè£å‰ª+å­—å¹•â€æŒ‰é’®\n\n<img src=\"docs/images/guide.jpg\"/>\n\nä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è£å‰ªè¯·å‚è€ƒå¦‚ä¸‹æ•™ç¨‹\n\n<img src=\"docs/images/LLM_guide.png\" width=360/>\n\n### B.é€šè¿‡å‘½ä»¤è¡Œè°ƒç”¨ä½¿ç”¨FunClipçš„ç›¸å…³åŠŸèƒ½\n```shell\n# æ­¥éª¤ä¸€ï¼šè¯†åˆ«\npython funclip/videoclipper.py --stage 1 \\\n                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \\\n                       --output_dir ./output\n# ./outputä¸­ç”Ÿæˆäº†è¯†åˆ«ç»“æœä¸srtå­—å¹•ç­‰\n# æ­¥éª¤äºŒï¼šè£å‰ª\npython funclip/videoclipper.py --stage 2 \\\n                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \\\n                       --output_dir ./output \\\n                       --dest_text 'æˆ‘ä»¬æŠŠå®ƒè·Ÿä¹¡æ‘æŒ¯å…´å»ç»“åˆèµ·æ¥ï¼Œåˆ©ç”¨æˆ‘ä»¬çš„è®¾è®¡çš„èƒ½åŠ›' \\\n                       --start_ost 0 \\\n                       --end_ost 100 \\\n                       --output_file './output/res.mp4'\n```\n\n### C.é€šè¿‡åˆ›ç©ºé—´ä¸Spaceä½“éªŒFunClip\n\n[FunClip@Modelscopeåˆ›ç©ºé—´â­](https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary)\n\n[FunClip@HuggingFace SpaceğŸ¤—](https://huggingface.co/spaces/R1ckShi/FunClip)\n\n\n<a name=\"ç¤¾åŒºäº¤æµ\"></a>\n## ç¤¾åŒºäº¤æµğŸŸ\n\nFunClipå¼€æºé¡¹ç›®ç”±FunASRç¤¾åŒºç»´æŠ¤ï¼Œæ¬¢è¿åŠ å…¥ç¤¾åŒºï¼Œäº¤æµä¸è®¨è®ºï¼Œä»¥åŠåˆä½œå¼€å‘ç­‰ã€‚\n\n|                              é’‰é’‰ç¾¤                                |                     å¾®ä¿¡ç¾¤                      |\n|:-------------------------------------------------------------------:|:-----------------------------------------------------:|\n| <div align=\"left\"><img src=\"docs/images/dingding.png\" width=\"250\"/> | <img src=\"docs/images/wechat.png\" width=\"215\"/></div> |\n\n## é€šè¿‡FunASRäº†è§£è¯­éŸ³è¯†åˆ«ç›¸å…³æŠ€æœ¯\n\n[FunASR](https://github.com/alibaba-damo-academy/FunASR)æ˜¯é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤å¼€æºçš„ç«¯åˆ°ç«¯è¯­éŸ³è¯†åˆ«å·¥å…·åŒ…ï¼Œç›®å‰å·²ç»æˆä¸ºä¸»æµASRå·¥å…·åŒ…ä¹‹ä¸€ã€‚å…¶ä¸»è¦åŒ…æ‹¬Python pipelineï¼ŒSDKéƒ¨ç½²ä¸æµ·é‡å¼€æºå·¥ä¸šASRæ¨¡å‹ç­‰ã€‚\n\nğŸ“šFunASRè®ºæ–‡: <a href=\"https://arxiv.org/abs/2305.11013\"><img src=\"https://img.shields.io/badge/Arxiv-2305.11013-orange\"></a> \n\nğŸ“šSeACo-Paraformerè®ºæ–‡ï¼š<a href=\"https://arxiv.org/abs/2308.03266\"><img src=\"https://img.shields.io/badge/Arxiv-2308.03266-orange\"></a> \n\nâ­æ”¯æŒFunASR: <a href='https://github.com/alibaba-damo-academy/FunASR.stargazers'><img src='https://img.shields.io/github/stars/alibaba-damo-academy/FunASR.svg?style=social'></a>\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "font",
          "type": "tree",
          "content": null
        },
        {
          "name": "funclip",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.142578125,
          "content": "librosa\nsoundfile\nscikit-learn>=1.3.2\nfunasr>=1.1.2\nmoviepy\nnumpy==1.26.4\ngradio\nmodelscope\ntorch>=1.13\ntorchaudio\nopenai\ng4f\ndashscope\ncurl_cffi\n"
        }
      ]
    }
  ]
}