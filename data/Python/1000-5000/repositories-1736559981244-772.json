{
  "metadata": {
    "timestamp": 1736559981244,
    "page": 772,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "wal-e/wal-e",
      "stars": 3460,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.771484375,
          "content": "# Python common gitignores\n#\n# https://github.com/github/gitignore/blob/e1f0a713c47dada10b2f818a6650198816badd7c/Python.gitignore\n\n*.py[co]\n\n# Packages\n*.egg\n*.egg-info\ndist\nbuild\neggs\nparts\nbin\nvar\nsdist\ndevelop-eggs\n.installed.cfg\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.tox\n.cache\nhtmlcov/\n\n#Translations\n*.mo\n\n#Mr Developer\n.mr.developer.cfg\n\n\n# emacs gitignores\n#\n# https://github.com/github/gitignore/blob/4c9fba7b1e942141a3bf5345a8c3b91b3d77d241/Global/Emacs.gitignore\n\n*~\n\\#*\\#\n/.emacs.desktop\n/.emacs.desktop.lock\n.elc\nauto-save-list\ntramp\n.\\#*\n\n\n# vim gitignores\n#\n# https://github.com/github/gitignore/blob/4c9fba7b1e942141a3bf5345a8c3b91b3d77d241/Global/vim.gitignore\n.*.sw[a-z]\n*.un~\nSession.vim\n\n# Virtualenv\n.env\n\n# rope ignores\n.ropeproject\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.4150390625,
          "content": "language: python\ndist: trusty\nenv:\n    # do not load /etc/boto.cfg with Python 3 incompatible plugin\n    # https://github.com/travis-ci/travis-ci/issues/5246#issuecomment-166460882\n    - BOTO_CONFIG=/doesnotexist\npython:\n  - \"3.4\"\n  - \"3.5\"\n  - \"3.6\"\nbefore_install:\n  - sudo apt-get update -qq\n  - sudo apt-get install -qq libevent-dev lzop pv gnupg\ninstall: pip install tox-travis\nscript: tox\nnotifications:\n  email: false\n"
        },
        {
          "name": "CONTRIBUTORS",
          "type": "blob",
          "size": 2.5185546875,
          "content": "Alex Gaynor <alex.gaynor@gmail.com>\nAlexander Kukushkin <alexander.kukushkin@zalando.de>\nAnatolii Mihailenco <anmic.webdev@gmail.com>\nAndrew Marks <amarks@gmail.com>\nAndrew Williams <awilliams@intoxitrack.net>\nAndy Freeland <andy@andyfreeland.net>\nAyush Goyal <ayush@helpshift.com>\nBartek Jarocki <bartek@smatly.com>\nBo Shi <bs@alum.mit.edu>\nBrian Oldfield <brian@oldfield.io>\nBrian Rosner <brosner@gmail.com>\nCarlo Cabanilla <carlo.cabanilla@gmail.com>\nCharles Duffy <charles@dyfis.net>\nChris Armstrong <chris@opdemand.com>\nChristian Pedersen <chripede@gmail.com>\nChristophe Pettus <cpettus@pgexperts.com>\nChristopher Weibel <christopher.weibel@gmail.com>\nColm Aengus Murphy <colmaengus@gmail.com>\nDan Milstein <milstein.dan@gmail.com>\nDan Robinson <dan@heapanalytics.com>\nDaniel Farina <daniel@heroku.com>\nDavid Dever <david.dever@virtustream.com>\nDerrick Petzold <dpetzold@clearcareonline.com>\nDikang Gu <dikang85@gmail.com>\nDr Nic Williams <drnicwilliams@gmail.com>\nEdward Muller <edward@heroku.com>\nFeike Steenbergen <feikesteenbergen@gmail.com>\nGreg Burek <greg.burek@gmail.com>\nGreg Stark <stark@heroku.com>\nHunter Blanks <hunter@napofearth.com>\nIgor Katson <igor.katson@gmail.com>\nJamal Boukaffal <boukaffal@lemonde.fr>\nJason Drapala <evilplankton@gmail.com>\nJason Yan <tailofthesun@gmail.com>\nJeff Frost <jeff@pgexperts.com>\nJeffrey Paul <sneak@datavibe.net>\nJoe Healy <joehealy@gmail.com>\nJoel E. Svensson <joeles_93@hotmail.com>\nJoshua Gross <joshuaagross@gmail.com>\nKenneth Shelton <kshelton@defensative.com>\nKenny Johansson <wirehell@gmail.com>\nKirill Klenov <horneds@gmail.com>\nLéo Cavaillé <leo@datadoghq.com>\nMaciek Sakrejda <maciek@heroku.com>\nManuel Alejandro de Brito Fontes <aledbf@gmail.com>\nMasaki Muranaka <monaka@monami-ya.com>\nMatt Wright <matt@nobien.net>\nMatthew Hooker <mwhooker@gmail.com>\nMichael Hale <mikehale@heroku.com>\nMike Krieger <mikeyk@instagram.com>\nNick Jalbert <nickj@captricity.com>\nNicolas Goy <kuon@goyman.com>\nNoah Yetter <noah@sympoz.com>\nNorbert Tretkowski <norbert@tretkowski.de>\nPaul Paradise <paulpar@gmail.com>\nPetar Radosevic <petar@wunki.org>\nRaanan Raz <raanan.raz@gmail.com>\nRodolphe Quiédeville <rodolphe@quiedeville.org>\nRuss Garrett <russ@garrett.co.uk>\nRyan P. Kelly <rpkelly@cpan.org>\nSamuel Kohonen <deverant@spotify.com>\nSean Linsley <xovatdev@gmail.com>\nSeth Rosenblum <seth.t.rosenblum@gmail.com>\nTimothée Peignier <tim@heroku.com>\nToby Collier <tobycollier@gmail.com>\nTuomas Silen <tuomas.silen@nodeta.fi>\nhttps://github.com/earsdown\nhttps://github.com/secwall\nhttps://github.com/tvarsis <tvarsis@hotmail.com>\n"
        },
        {
          "name": "HISTORY.rst",
          "type": "blob",
          "size": 2.4775390625,
          "content": "WAL-E's History\n===============\n\nWAL-E's development began Heroku in early 2011, commissioned by the\nDepartment of Data with the intent of ensuring that appreciable data\nloss on Heroku would have to be accompanied by spectacularly obscure\nmechanisms: it was not acceptable to lose a lot of data in common\ncases of media failure or operator error.  The subsequent\nreplication-related \"fork\" and \"follow\" features did not exist.  The\n\"Heroku Postgres\" product was not yet a concept.\n\nWithin one month after the first commit of WAL-E, the very earliest\nversions were deployed to Heroku production, v0.2.0.  At this point,\nit was somewhat unclear that WAL-E even worked, which was to be\ndetermined at leisure following deployment.  However, within two\nweeks, the large April 30th, 2011 AWS crash took place, and this was\nthe first of several large-scale disaster recoveries that took place\nunder similar circumstances at Heroku.  This fortuitous timing of\nevents — including WAL-E happening to work on the first try — exhibits\na rare circumstance where cutting the corners of engineering practice\nto deploy slightly earlier prevented enormous heartache for Heroku\nstaff and its customers.\n\nAt the time, WAL-E was little more than a shell-script-esque Python\nprogram wrapping around ``s3cmd``.  It had terrible error messages,\nblunt error handling — sometimes none, with hazardous results, and\nlacked parallelism.  However, by this time, the critical four\noperators and one critical concept of WAL-E had gelled and been shown\nto work well:\n\n* wal-push\n* wal-fetch\n* backup-push\n* backup-fetch\n* WALE_S3_PREFIX\n\nAlso in April of 2011, the v0.5 series was released.  Notably, this\nwas the first version possessing a stable version of the storage\nformat in S3, version '005'.\n\nBy May of 2011, it became clear that a lot more control over error\nhandling and exceptions would be necessary to make WAL-E an ergonomic\ntool not hated by all its operators.  It was also desirable to use\nless aggregate virtual memory, as tended to occur when ``fork()``-ing\nsubprocesses.  The was the cause of major re-positioning to use\n``boto`` and ``gevent`` in WAL-E.  Although started in May of 2011,\nthe bulk of development took place in September and October of 2011,\nculminating in v0.5.8.  This version is the first that is looks\nrecognizably like WAL-E would for quite some time to come.\n\nIn January of 2013, WAL-E inducted its first committers beyond the\nprincipal author at Heroku, and its project development gained a\ndistinct identity from Heroku.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.478515625,
          "content": "Copyright (c) 2011-2015, WAL-E Contributors\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n    * Redistributions of source code must retain the above copyright\n      notice, this list of conditions and the following disclaimer.\n    * Redistributions in binary form must reproduce the above copyright\n      notice, this list of conditions and the following disclaimer in the\n      documentation and/or other materials provided with the distribution.\n    * Neither the name of the WAL-E project nor the\n      names of its contributors may be used to endorse or promote products\n      derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE WAL-E CONTRIBUTORS BE LIABLE FOR ANY\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\nON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1875,
          "content": "include LICENSE\ninclude README.rst\ninclude VERSION\ninclude requirements.txt\n\nrecursive-exclude * __pycache__\nrecursive-exclude * *.py[co]\nrecursive-exclude * *.orig\n\nrecursive-include wal_e *\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.962890625,
          "content": "ALLSPHINXOPTS= -d $(BUILDDIR)/doctrees $(PAPEROPT_$(PAPER)) $(SPHINXOPTS) .\nMODULE=wal_e\nVIRTUALENV=$(shell echo \"$${VDIR:-'.env'}\")\nPYTHON=$(VIRTUALENV)/bin/python\n\nall: $(VIRTUALENV)\n\n$(VIRTUALENV): requirements.txt\n\t@virtualenv --no-site-packages $(VIRTUALENV)\n\t@$(VIRTUALENV)/bin/pip install -r requirements.txt\n\t$(PYTHON) setup.py develop\n\ttouch $(VIRTUALENV)\n\n.PHONY: help\n# target: help - Display callable targets\nhelp:\n\t@egrep \"^# target:\" [Mm]akefile | sed -e 's/^# target: //g'\n\n.PHONY: clean\n# target: clean - Clean repo\nclean:\n\t@rm -rf build dist docs/_build\n\t@rm -f *.py[co]\n\t@rm -f *.orig\n\t@rm -f */*.py[co]\n\t@rm -f */*.orig\n\n.PHONY: register\n# target: register - Register module on PyPi\nregister:\n\t$(PYTHON) setup.py register\n\n.PHONY: upload\n# target: upload - Upload module on PyPi\nupload: clean\n\t$(PYTHON) setup.py sdist upload || echo 'Upload already'\n\n.PHONY: test\n# target: test - Run module tests\ntest: clean\n\tPATH=$(VIRTUALENV)/bin:$(PATH) $(PYTHON) setup.py test\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 26.2353515625,
          "content": "WAL-E\n=====\n---------------------------------\nContinuous archiving for Postgres\n---------------------------------\n\nWAL-E is a program designed to perform continuous archiving of\nPostgreSQL WAL files and base backups.\n\nObsolescence Notice\n-------------------\n\nWAL-E is obsolete. Though it has been used recently, nobody routinely\nreviews patches or fixes regressions that are occasionally introduced\nby changing libraries and Python versions.  It is also not fast as\nmore modern archivers.\n\nSome alternatives for you to consider:\n\n`WAL-G <https://github.com/wal-g/wal-g>`_ is one alternative that uses\na similar model as WAL-E, but is also a much more expansive piece of\nsoftware, supporting many databases and compression formats.  WAL-G\nhas the capability to read, but not write, WAL-E archives.  Like\nWAL-E, it is piece of software that tends to be developed from the\ncloud service provider set of priorities.\n\n`pgBackRest <https://pgbackrest.org>`_ has a more traditional model\n(by standards of Postgres archives predating cloud blob storage) and a\nnarrower focus on Postgres.  In general, it makes more concessions to\nand implements more polished features for what independent system\noperators might encounter.\n\nTo correspond on using WAL-E or to collaborate on its development, do\nnot hesitate to send mail to the mailing list at\nwal-e@googlegroups.com (`archives and subscription settings`_).\nGithub issues are also currently being used to track known problems,\nso please feel free to submit those.\n\n.. contents:: Table of Contents\n\n.. _archives and subscription settings:\n   https://groups.google.com/forum/#!forum/wal-e\n\n\nInstallation\n------------\n\nIf no up-to-date packages are available to you via a package manager,\nthis command can work on most operating systems::\n\n  sudo python3 -m pip install wal-e[aws,azure,google,swift]\n\nYou can omit storage services you do not wish to use from the above\nlist.\n\n\nPrimary Commands\n----------------\n\nWAL-E has these key commands:\n\n* backup-fetch\n* backup-push\n* wal-fetch\n* wal-push\n* `delete`_\n\nAll of these operators work in a context of several environment\nvariables that WAL-E reads.  The variables set depend on the storage\nprovider being used, and are detailed below.\n\nWAL-E's organizing concept is the `PREFIX`.  Prefixes must be set\nuniquely for each *writing* database, and prefix all objects stored\nfor a given database.  For example: ``s3://bucket/databasename``.\n\nOf these, the \"push\" operators send backup data to storage and \"fetch\"\noperators get backup data from storage.\n\n``wal`` commands are called by Postgres's ``archive_command`` and\n``restore_command`` to fetch or pull write ahead log, and ``backup``\ncommands are used to fetch or push a hot backup of the base database\nthat WAL segments can be applied to.  Finally, the ``delete`` command\nis used to prune the archives as to retain a finite number of backups.\n\nAWS S3 and Work-alikes\n''''''''''''''''''''''\n\n* WALE_S3_PREFIX (e.g. ``s3://bucket/path/optionallymorepath``)\n* AWS_ACCESS_KEY_ID\n* AWS_SECRET_ACCESS_KEY\n* AWS_REGION (e.g. ``us-east-1``)\n\nOptional:\n\n* WALE_S3_ENDPOINT: See `Manually specifying the S3 Endpoint`_\n* WALE_S3_STORAGE_CLASS: One of: STANDARD (default), REDUCED_REDUNDANCY,\n  GLACIER, STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, DEEP_ARCHIVE\n* AWS_SECURITY_TOKEN: When using AWS STS\n* Pass ``--aws-instance-profile`` to gather credentials from the\n  Instance Profile.  See `Using AWS IAM Instance Profiles`.\n\n\nAzure Blob Store\n''''''''''''''''\nExample below is based on the following blob storage in Azure in the\nresource group ``resgroup`` :\nhttps://store1.blob.core.windows.net/container1/nextpath\n\n* WALE_WABS_PREFIX (e.g. ``wabs://container1/nextpath``)\n* WABS_ACCOUNT_NAME (e.g. ``store1``)\n* WABS_ACCESS_KEY (Use key1 from running ``azure storage account keys\n  list store1 --resource-group resgroup`` You will need to have the\n  Azure CLI installed for this to work.)\n* WABS_SAS_TOKEN (You only need this if you have not provided an\n  WABS_ACCESS_KEY)\n\n\nGoogle Storage\n''''''''''''''\n\n* WALE_GS_PREFIX (e.g. ``gs://bucket/path/optionallymorepath``)\n* GOOGLE_APPLICATION_CREDENTIALS\n\nSwift\n'''''\n\n* WALE_SWIFT_PREFIX (e.g. ``swift://container/path/optionallymorepath``)\n* SWIFT_AUTHURL\n* SWIFT_TENANT\n* SWIFT_USER\n* SWIFT_PASSWORD\n\nOptional Variables:\n\n* SWIFT_AUTH_VERSION which defaults to ``2``. Some object stores such as\n  Softlayer require version ``1``.\n* SWIFT_ENDPOINT_TYPE defaults to ``publicURL``, this may be set to\n  ``internalURL`` on object stores like Rackspace Cloud Files in order\n  to use the internal network.\n\nFile System\n'''''''''''\n\n* WALE_FILE_PREFIX (e.g. ``file://localhost/backups/pg``)\n\n.. IMPORTANT::\n   Ensure that all writing servers have different _PREFIXes set.\n   Reuse of a value between two, writing databases will likely cause\n   unrecoverable backups.\n\n\nDependencies\n------------\n\n* python (>= 3.4)\n* lzop\n* psql (>= 8.4)\n* pv\n\nThis software also has Python dependencies: installing with ``pip``\nwill attempt to resolve them:\n\n* gevent>=1.1.1\n* boto>=2.40.0\n* azure==3.0.0\n* google-cloud-storage>=1.4.0\n* python-swiftclient>=3.0.0\n* python-keystoneclient>=3.0.0\n\nIt is possible to use WAL-E without the dependencies of back-end\nstorage one does not use installed: the imports for those are only\nperformed if the storage configuration demands their use.\n\nExamples\n--------\n\nPushing a base backup to S3::\n\n  $ AWS_SECRET_ACCESS_KEY=... wal-e                     \\\n    -k AWS_ACCESS_KEY_ID                                \\\n    --s3-prefix=s3://some-bucket/directory/or/whatever  \\\n    backup-push /var/lib/my/database\n\nSending a WAL segment to WABS::\n\n  $ WABS_ACCESS_KEY=... wal-e                                   \\\n    -a WABS_ACCOUNT_NAME                                        \\\n    --wabs-prefix=wabs://some-bucket/directory/or/whatever      \\\n    wal-push /var/lib/my/database/pg_xlog/WAL_SEGMENT_LONG_HEX\n\nPush a base backup to Swift::\n\n  $ WALE_SWIFT_PREFIX=\"swift://my_container_name\"              \\\n    SWIFT_AUTHURL=\"http://my_keystone_url/v2.0/\"               \\\n    SWIFT_TENANT=\"my_tennant\"                                  \\\n    SWIFT_USER=\"my_user\"                                       \\\n    SWIFT_PASSWORD=\"my_password\" wal-e                         \\\n    backup-push /var/lib/my/database\n\nPush a base backup to Google Cloud Storage::\n\n  $ WALE_GS_PREFIX=\"gs://some-bucket/directory-or-whatever\"     \\\n    GOOGLE_APPLICATION_CREDENTIALS=...                          \\\n    wal-e backup-push /var/lib/my/database\n\nIt is generally recommended that one use some sort of environment\nvariable management with WAL-E: working with it this way is less verbose,\nless prone to error, and less likely to expose secret information in\nlogs.\n\n.. _archive_command: http://www.postgresql.org/docs/8.3/static/runtime-config-wal.html#GUC-ARCHIVE-COMMAND>\n\nenvdir_, part of the daemontools_ package is one recommended approach\nto setting environment variables.  One can prepare an\nenvdir-compatible directory like so::\n\n  # Assumption: the group is trusted to read secret information\n  # S3 Setup\n  $ umask u=rwx,g=rx,o=\n  $ mkdir -p /etc/wal-e.d/env\n  $ echo \"secret-key-content\" > /etc/wal-e.d/env/AWS_SECRET_ACCESS_KEY\n  $ echo \"access-key\" > /etc/wal-e.d/env/AWS_ACCESS_KEY_ID\n  $ echo 's3://some-bucket/directory/or/whatever' > \\\n    /etc/wal-e.d/env/WALE_S3_PREFIX\n  $ chown -R root:postgres /etc/wal-e.d\n\n\n  # Assumption: the group is trusted to read secret information\n  # WABS Setup\n  $ umask u=rwx,g=rx,o=\n  $ mkdir -p /etc/wal-e.d/env\n  $ echo \"secret-key-content\" > /etc/wal-e.d/env/WABS_ACCESS_KEY\n  $ echo \"access-key\" > /etc/wal-e.d/env/WABS_ACCOUNT_NAME\n  $ echo 'wabs://some-container/directory/or/whatever' > \\\n    /etc/wal-e.d/env/WALE_WABS_PREFIX\n  $ chown -R root:postgres /etc/wal-e.d\n\nAfter having done this preparation, it is possible to run WAL-E\ncommands much more simply, with less risk of accidentally using\nincorrect values::\n\n  $ envdir /etc/wal-e.d/env wal-e backup-push ...\n  $ envdir /etc/wal-e.d/env wal-e wal-push ...\n\nenvdir is conveniently combined with the archive_command functionality\nused by PostgreSQL to enable continuous archiving.  To enable\ncontinuous archiving, one needs to edit ``postgresql.conf`` and\nrestart the server.  The important settings to enable continuous\narchiving are related here::\n\n  wal_level = archive # hot_standby and logical in 9.x is also acceptable\n  archive_mode = on\n  archive_command = 'envdir /etc/wal-e.d/env wal-e wal-push %p'\n  archive_timeout = 60\n\nEvery segment archived will be noted in the PostgreSQL log.\n\n.. WARNING::\n   PostgreSQL users can check the pg_settings table and see the\n   archive_command employed.  Do not put secret information into\n   postgresql.conf for that reason, and use envdir instead.\n\nA base backup (via ``backup-push``) can be uploaded at any time, but\nthis must be done at least once in order to perform a restoration.  It\nmust be done again if you decided to skip archiving any WAL segments:\nreplication will not be able to continue if there are any gaps in the\nstored WAL segments.\n\n.. _envdir: http://cr.yp.to/daemontools/envdir.html\n.. _daemontools: http://cr.yp.to/daemontools.html\n\n\nPrimary Commands\n----------------\n``backup-push``, ``backup-fetch``, ``wal-push``, ``wal-fetch`` represent\nthe primary functionality of WAL-E and must reside on the database machine.\nUnlike ``wal-push`` and ``wal-fetch`` commands, which function as described\nabove, the ``backup-push`` and ``backup-fetch`` require a little additional\nexplanation.\n\nbackup-push\n'''''''''''\n\nBy default ``backup-push`` will include all user defined tablespaces in\nthe database backup. please see the ``backup-fetch`` section below for\nWAL-E's tablespace restoration behavior.\n\nbackup-fetch\n''''''''''''\n\nUse ``backup-fetch`` to restore a base backup from storage.\n\nThis command makes use of the ``LATEST`` pseudo-backup-name to find a\nbackup to download::\n\n    $ envdir /etc/wal-e.d/fetch-env wal-e               \\\n    --s3-prefix=s3://some-bucket/directory/or/whatever  \\\n    backup-fetch /var/lib/my/database LATEST\n\nAlso allowed is naming a backup specifically as seen in\n``backup-list``, which can be useful for restoring older backups for\nthe purposes of point in time recovery::\n\n    $ envdir /etc/wal-e.d/fetch-env wal-e               \\\n    --s3-prefix=s3://some-bucket/directory/or/whatever  \\\n    backup-fetch                                        \\\n    /var/lib/my/database base_LONGWALNUMBER_POSITION_NUMBER\n\nOne will need to provide a `recovery.conf`_ file to recover WAL\nsegments associated with the backup.  In short, `recovery.conf`_ needs\nto be created in the Postgres's data directory with content like::\n\n    restore_command = 'envdir /etc/wal-e.d/env wal-e wal-fetch %f %p'\n    standby_mode = on\n\n.. _recovery.conf: https://www.postgresql.org/docs/current/static/recovery-config.html\n\nA database with such a `recovery.conf` set will poll WAL-E storage for\nWAL indefinitely.  You can exit recovery by running `pg_ctl promote`_.\n\nIf you wish to perform Point In Time Recovery (PITR) can add `recovery\ntargets`_ to `recovery.conf`_, looking like this::\n\n    recovery_target_time = '2017-02-01 19:58:55'\n\nThere are several other ways to specify recovery target,\ne.g. transaction id.\n\nRegardless of recovery target, the result by default is Postgres will\npause recovery at this time, allowing inspection before promotion.\nSee `recovery targets`_ for details on how to customize what happens\nwhen the target criterion is reached.\n\n.. _pg_ctl promote: https://www.postgresql.org/docs/current/static/app-pg-ctl.html\n.. _recovery targets: https://www.postgresql.org/docs/current/static/recovery-target-settings.html\n\nTablespace Support\n******************\n\nIf and only if you are using Tablespaces, you will need to consider\nadditional issues on how run ``backup-fetch``.  The options are:\n\n* User-directed Restore\n\n  WAL-E expects that tablespace symlinks will be in place prior to a\n  ``backup-fetch`` run. This means prepare your target path by\n  insuring ``${PG_CLUSTER_DIRECTORY}/pg_tblspc`` contains all required\n  symlinks before restoration time. If any expected symlink does not\n  exist ``backup-fetch`` will fail.\n\n* Blind Restore\n\n  If you are unable to reproduce tablespace storage structures prior\n  to running ``backup-fetch`` you can set the option flag\n  ``--blind-restore``.  This will direct WAL-E to skip the symlink\n  verification process and place all data directly in the\n  ``${PG_CLUSTER_DIRECTORY}/pg_tblspc`` path.\n\n* Restoration Specification\n\n  You can provide a restoration specification file to WAL-E using the\n  ``backup-fetch`` ``--restore-spec RESTORE_SPEC`` option.  This spec\n  must be valid JSON and contain all contained tablespaces as well as\n  the target storage path they require, and the symlink postgres\n  expects for the tablespace. Here is an example for a cluster with a\n  single tablespace::\n\n    {\n        \"12345\": {\n            \"loc\": \"/data/postgres/tablespaces/tblspc001/\",\n            \"link\": \"pg_tblspc/12345\"\n        },\n        \"tablespaces\": [\n            \"12345\"\n        ],\n    }\n\n  Given this information WAL-E will create the data storage directory\n  and symlink it appropriately in\n  ``${PG_CLUSTER_DIRECTORY}/pg_tblspc``.\n\n.. WARNING::\n   ``\"link\"`` properties of tablespaces in the restore specification\n   must contain the ``pg_tblspc`` prefix, it will not be added for you.\n\nAuxiliary Commands\n------------------\n\nThese are commands that are not used expressly for backup or WAL\npushing and fetching, but are important to the monitoring or\nmaintenance of WAL-E archived databases.  Unlike the critical four\noperators for taking and restoring backups (``backup-push``,\n``backup-fetch``, ``wal-push``, ``wal-fetch``) that must reside on the\ndatabase machine, these commands can be productively run from any\ncomputer with the appropriate _PREFIX set and the necessary credentials to\nmanipulate or read data there.\n\n\nbackup-list\n'''''''''''\n\nbackup-list is useful for listing base backups that are complete for a\ngiven WAL-E context.  Some fields are only filled in when the\n``--detail`` option is passed to ``backup-list`` [#why-detail-flag]_.\n\n.. NOTE::\n   Some ``--detail`` only fields are not strictly to the right of\n   fields that do not require ``--detail`` be passed.  This is not a\n   problem if one uses any CSV parsing library (as two tab-delimiters\n   will be emitted) to signify the empty column, but if one is hoping\n   to use string mangling to extract fields, exhibit care.\n\nFirstly, the fields that are filled in regardless of if ``--detail``\nis passed or not:\n\n================================  ====================================\n        Header in CSV                           Meaning\n================================  ====================================\nname                              The name of the backup, which can be\n                                  passed to the ``delete`` and\n                                  ``backup-fetch`` commands.\n\nlast_modified                     The date and time the backup was\n                                  completed and uploaded, rendered in\n                                  an ISO-compatible format with\n                                  timezone information.\n\nwal_segment_backup_start          The wal segment number.  It is a\n                                  24-character hexadecimal number.\n                                  This information identifies the\n                                  timeline and relative ordering of\n                                  various backups.\n\nwal_segment_offset_backup_start   The offset in the WAL segment that\n                                  this backup starts at.  This is\n                                  mostly to avoid ambiguity in event\n                                  of backups that may start in the\n                                  same WAL segment.\n================================  ====================================\n\nSecondly, the fields that are filled in only when ``--detail`` is\npassed:\n\n================================  ====================================\n        Header in CSV                           Meaning\n================================  ====================================\nexpanded_size_bytes               The decompressed size of the backup\n                                  in bytes.\n\nwal_segment_backup_stop           The last WAL segment file required\n                                  to bring this backup into a\n                                  consistent state, and thus available\n                                  for hot-standby.\n\nwal_segment_offset_backup_stop    The offset in the last WAL segment\n                                  file required to bring this backup\n                                  into a consistent state.\n================================  ====================================\n\n.. [#why-detail-flag] ``backup-list --detail`` is slower (one web\n   request per backup, rather than one web request per thousand\n   backups or so) than ``backup-list``, and often (but not always) the\n   information in the regular ``backup-list`` is all one needs.\n\ndelete\n''''''\n\n``delete`` contains additional subcommands that are used for deleting\ndata from storage for various reasons.  These commands are organized\nseparately because the ``delete`` subcommand itself takes options that\napply to any subcommand that does deletion, such as ``--confirm``.\n\nAll deletions are designed to be reentrant and idempotent: there are\nno negative consequences if one runs several deletions at once or if\none resubmits the same deletion command several times, with or without\ncanceling other deletions that may be concurrent.\n\nThese commands have a ``dry-run`` mode that is the default.  The\ncommand is basically optimized for not deleting data except in a very\nspecific circumstance to avoid operator error.  Should a dry-run be\nperformed, ``wal-e`` will instead simply report every key it would\notherwise delete if it was not running in dry-run mode, along with\nprominent HINT-lines for every key noting that nothing was actually\ndeleted from the blob store.\n\nTo *actually* delete any data, one must pass ``--confirm`` to ``wal-e\ndelete``.  If one passes both ``--dry-run`` and ``--confirm``, a dry\nrun will be performed, regardless of the order of options passed.\n\nCurrently, these kinds of deletions are supported.  Examples omit\nenvironment variable configuration for clarity:\n\n* ``before``: Delete all backups and wal segment files before the\n  given base-backup name.  This does not include the base backup\n  passed: it will remain a viable backup.\n\n  Example::\n\n    $ wal-e delete [--confirm] before base_00000004000002DF000000A6_03626144\n\n* ``retain``: Leave the given number of backups in place, and delete\n  all base backups and wal segment files older than them.\n\n  Example::\n\n    $ wal-e delete [--confirm] retain 5\n\n* ``old-versions``: Delete all backups and wal file segments with an\n  older format.  This is only intended to be run after a major WAL-E\n  version upgrade and the subsequent base-backup.  If no base backup\n  is successfully performed first, one is more exposed to data loss\n  until one does perform a base backup.\n\n  Example::\n\n    $ wal-e delete [--confirm] old-versions\n\n* ``everything``: Delete all backups and wal file segments in the\n  context.  This is appropriate if one is decommissioning a database\n  and has no need for its archives.\n\n  Example::\n\n    $ wal-e delete [--confirm] everything\n\n\nCompression and Temporary Files\n-------------------------------\n\nAll assets pushed to storage are run through the program \"lzop\" which\ncompresses the object using the very fast lzo compression algorithm.\nIt takes roughly 2 CPU seconds to compress a gigabyte, which when\nsending things to storage at about 25MB/s occupies about 5% CPU time.\nCompression ratios are expected to make file sizes 50% or less of the\noriginal file size in most cases, making backups and restorations\nconsiderably faster.\n\nBecause storage services generally require the Content-Length header\nof a stored object to be set up-front, it is necessary to completely\nfinish compressing an entire input file and storing the compressed\noutput in a temporary file.  Thus, the temporary file directory needs\nto be big enough and fast enough to support this, although this tool\nis designed to avoid calling fsync(), so some memory can be leveraged.\n\nBase backups first have their files consolidated into disjoint tar\nfiles of limited length to avoid the relatively large per-file transfer\noverhead.  This has the effect of making base backups and restores\nmuch faster when many small relations and ancillary files are\ninvolved.\n\n\nOther Options\n-------------\n\nEncryption\n''''''''''\n\nTo encrypt backups as well as compress them, first generate a key pair\nusing ``gpg --gen-key``. You don't need the private key on the machine\nto back up, but you will need it to restore. The private key may have\na password, but to restore, the password should be present in GPG\nagent. WAL-E does not support entering GPG passwords via a tty device.\n\nOnce this is done, set the ``WALE_GPG_KEY_ID`` environment variable or\nthe ``--gpg-key-id`` command line option to the ID of the secret key\nfor backup and restore commands.\n\nHere's an example of how you can restore with a private key that has a\npassword, by forcing decryption of an arbitrary file with the correct\nkey to unlock the GPG keychain::\n\n  # This assumes you have \"keychain\" gpg-agent installed.\n  eval $( keychain --eval --agents gpg )\n\n  # If you want default gpg-agent, use this instead\n  # eval $( gpg-agent --daemon )\n\n  # Force storing the private key password in the agent.  Here you\n  # will need to enter the key password.\n  export TEMPFILE=`tempfile`\n  gpg --recipient \"$WALE_GPG_KEY_ID\" --encrypt \"$TEMPFILE\"\n  gpg --decrypt \"$TEMPFILE\".gpg || exit 1\n\n  rm \"$TEMPFILE\" \"$TEMPFILE\".gpg\n  unset TEMPFILE\n\n  # Now use wal-e to fetch the backup.\n  wal-e backup-fetch [...]\n\n  # If you have WAL segments encrypted, don't forget to add\n  # restore_command to recovery.conf, e.g.\n  #\n  # restore_command = 'wal-e wal-fetch \"%f\" \"%p\"'\n\n  # Start the restoration postgres server in a context where you have\n  # gpg-agent's environment variables initialized, such as the current\n  # shell.\n  pg_ctl -D [...] start\n\n\nControlling the I/O of a Base Backup\n''''''''''''''''''''''''''''''''''''\n\nTo reduce the read load on base backups, they are sent through the\ntool ``pv`` first.  To use this rate-limited-read mode, use the option\n``--cluster-read-rate-limit`` as seen in ``wal-e backup-push``.\n\nLogging\n'''''''\n\nWAL-E supports logging configuration with following environment\nvariables:\n\n* ``WALE_LOG_DESTINATION`` comma separated values, **syslog** and\n  **stderr** are supported.  The default is equivalent to:\n  ``syslog,stderr``.\n\n* ``WALE_SYSLOG_FACILITY`` from ``LOCAL0`` to ``LOCAL7`` and ``USER``.\n\nTo restrict log statements to warnings and errors, use the ``--terse``\noption.\n\nIncreasing throughput of wal-push\n'''''''''''''''''''''''''''''''''\n\nIn certain situations, the ``wal-push`` process can take long enough\nthat it can't keep up with WAL segments being produced by Postgres,\nwhich can lead to unbounded disk usage and an eventual crash of the\ndatabase.\n\nOne can instruct WAL-E to pool WAL segments together and send them in\ngroups by passing the ``--pool-size`` parameter to ``wal-push``.  This\ncan increase throughput significantly.\n\nAs of version 1.x, ``--pool-size`` defaults to 32.\n\nNote: You can also use this parameter when calling ``backup-fetch``\nand ``backup-push`` (it defaults to 4).\n\nUsing AWS IAM Instance Profiles\n'''''''''''''''''''''''''''''''\n\nStoring credentials on AWS EC2 instances has usability and security\ndrawbacks.  When using WAL-E with AWS S3 and AWS EC2, most uses of\nWAL-E would benefit from use with the `AWS Instance Profile feature`_,\nwhich automatically generates and rotates credentials on behalf of an\ninstance.\n\nTo instruct WAL-E to use these credentials for access to S3, pass the\n``--aws-instance-profile`` flag.\n\n.. _AWS Instance Profile feature:\n   http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AESDG-chapter-instancedata.html\n\nInstance profiles may *not* be preferred in more complex scenarios\nwhen one has multiple AWS IAM policies written for multiple programs\nrun on an instance, or an existing key management infrastructure.\n\nManually specifying the S3 Endpoint\n'''''''''''''''''''''''''''''''''''\n\nIf one wishes to target WAL-E against an alternate S3 endpoint\n(e.g. Ceph RADOS), one can set the ``WALE_S3_ENDPOINT`` environment\nvariable.  This can also be used take fine-grained control over\nendpoints and calling conventions with AWS.\n\nThe format is that of::\n\n  protocol+convention://hostname:port\n\nWhere valid protocols are ``http`` and ``https``, and conventions are\n``path``, ``virtualhost``, and ``subdomain``.\n\nExample::\n\n  # Turns off encryption and specifies us-west-1 endpoint.\n  WALE_S3_ENDPOINT=http+path://s3-us-west-1.amazonaws.com:80\n\n  # For radosgw.\n  WALE_S3_ENDPOINT=http+path://hostname\n\n  # As seen when using Deis, which uses radosgw.\n  WALE_S3_ENDPOINT=http+path://deis-store-gateway:8888\n\nDevelopment\n-----------\n\nDevelopment is heavily reliant on the tool tox_ being existent within\nthe development environment.  All additional dependencies of WAL-E are\nmanaged by tox_.  In addition, the coding conventions are checked by\nthe tox_ configuration included with WAL-E.\n\nTo run the tests, run::\n\n  $ tox -e py35\n\nTo run a somewhat more lengthy suite of integration tests that\ncommunicate with a real blob store account, one might run tox_ like\nthis::\n\n  $ WALE_S3_INTEGRATION_TESTS=TRUE      \\\n    AWS_ACCESS_KEY_ID=[AKIA...]         \\\n    AWS_SECRET_ACCESS_KEY=[...]         \\\n    WALE_WABS_INTEGRATION_TESTS=TRUE    \\\n    WABS_ACCOUNT_NAME=[...]             \\\n    WABS_ACCESS_KEY=[...]               \\\n    WALE_GS_INTEGRATION_TESTS=TRUE      \\\n    GOOGLE_APPLICATION_CREDENTIALS=[~/my-credentials.json] \\\n    tox -e py35 -- -n 8\n\nLooking carefully at the above, notice the ``-n 8`` added the tox_\ninvocation.  This ``-n 8`` is after a ``--`` that indicates to tox_\nthat the subsequent arguments are for the underlying test program\npytest_.\n\nThis is to enable parallel test execution, which makes the integration\ntests complete a small fraction of the time it would take otherwise.\nIt is a design requirement of new tests that parallel execution not be\nsacrificed.\n\nCoverage testing can be used by combining any of these using\npytest-cov_, e.g.: ``tox -- --cov wal_e`` and\n``tox -- --cov wal_e --cov-report html; see htmlcov/index.html``.\n\n.. _tox: https://pypi.python.org/pypi/tox\n.. _pytest: https://pypi.python.org/pypi/pytest\n.. _unittest: http://docs.python.org/2/library/unittest.html\n.. _pytest-cov: https://pypi.python.org/pypi/pytest-cov\n"
        },
        {
          "name": "RELEASES.rst",
          "type": "blob",
          "size": 5.169921875,
          "content": "Releases\n========\n\nv1.1.0\n------\n\nRelease v1.1.0 is compatible with older versions, and has one\nnoteworthy detailed behavioral change:\n\nWAL-E now ignores backing up the directories ``pg_log``,\n``pg_replslot``, and ``pg_wal``, all of which could cause spurious\nproblems in backup or restore.\n\nOther changes include:\n\n* It also switches to a more modern driver for Google Storage. (Samuel\n  Kohonen)\n\n* Python 3.6 is now a tested (Dr. Nic Williams)\n\n* A counter-productive infinite retry with expired STS tokens has been\n  fixed (Timothée Peignier)\n\n* The README has been expanded (tvarsis, Daniel Farina)\n\n\nv1.0.3\n------\n\nRelease v1.0.3 adds support for Keystone v3 (Joel E. Svensson).\n\n\nv1.0.2\n------\n\nRelease v1.0.2 fixes a defect in WABS storage, the offline backup\nfeature, and documentation.\n\nThanks goes to: Ayush Goyal, for fixing an infinite-retry in WABS\ndeletion.  Jamal Boukaffal for a crash fix to offline backups. Norbert\nTretkowski for documentation fixes.\n\n\nv1.0.1\n------\n\nRelease v1.0.1 fixes defects in WABS and Swift storage.  Both were\nencoding errors that resulted from Python 3 conversion.\n\nThanks goes to: Ayush Goyal, for the fix for WABS. Joe Healy, for the\nfix for Swift. Derrick Petzold fixed an old reference to Python 2 in\nthe README.\n\n\nv1.0.0\n------\n\nRelease v1.0.0 contains the conversion WAL-E from a Python 2.7 to a\nPython 3.4 and Python 3.5 project.  It also adds support for Google\nCloud Storage (Matt Wright, Daniel Farina, Samuel Kohonen).\n\nIn addition, all WAL-E storage backends have been made optional. Thus,\nrunning ``pip install wal-e`` does not install any backends by\ndefault.  One must instead write a command akin to ``pip install\nwal-e[aws]``.  The valid options are:\n\n* aws\n* azure\n* google\n* swift\n\nFinally, there are some detailed adjustments:\n\n* Default parallelism for ``wal-push`` has been increased to 32.\n\n* 404 messages have been demoted to \"INFO\" rather than \"WARNING\"\n  because they can happen routinely and continuously, particularly\n  with ``standby_mode=on`` (earsdown).\n\n* Top-level backups in Azure no longer create a nameless \"directory\"\n  (Andrew Marks).\n\n* WAL-E start-up log message has been suppressed in some noisy cases:\n  ``wal-fetch``, ``wal-push``, ``wal-prefetch``.\n\n* WABS's `Content-Type` header is being set correctly.  Previously\n  this header was confused with `Content-Encoding` (David Dever).\n\nv0.9.2\n------\n\nRelease v0.9.2 fixes environment variable clobbering caused by the\nupdated statement_timeout suppression patch that can break use of\nwrapper scripts ``psql``.  By Kenneth Shelton.\n\nv0.9.1\n------\n\nRelease v0.9.1 adds support for Azure SAS Tokens (by Kenny Johansson)\nand fixes several bugs.  It is backwards and forwards compatible with\nv0.9.0.\n\nThe bugs fixed are:\n\n* Customized .psqlrc files no longer break WAL-E (Feike Steenbergen)\n* ``statement_timeout`` suppression should work now (Anatolii Mihailenco)\n* Files unlinked during backup no longer cause a crash (Léo Cavaillé)\n\nv0.9.0\n------\n\nRelease v0.9.0 requires use of (and adds support for) AWS SigV4. As\nsuch, a new environment variable is **required**, ``AWS_REGION``,\nbecause it is part of the signature format.  **This is not a backwards\ncompatible change**.\n\nNewer S3 features are often gated behind use of SigV4, and the region\n``eu-central-1`` relies on them.  Because of this change,\n``eu-central-1`` is now supported.\n\nSecondly, compatibility has been added with new versions of the Azure\nSDK v1.0.\n\nv0.8.1\n------\n\nRelease v0.8.1 drops Python 2.6 support and has minor bug fixes from\nv0.8.0:\n\n* Python 2.6 support dropped.  This is on account of the Azure driver\n  having dropped support for it.\n\n* Busybox compatability\n\n  \"lzop\" on busybox does not have the \"--stdout\" flag, instead the\n  shorthand \"-c\" must be used.\n\n  There is an investigation of backwards compatability by Manuel\n  Alejandro de Brito Fontes at\n  https://github.com/wal-e/wal-e/pull/171.\n\n* Delete files when there is an error in their creation.  Such partial\n  files could cause confusion for Postgres, particularly when\n  ``standby_mode=off`` is in ``recovery.conf``.\n\n  Ivan Evtuhovich reported the issue, tested solutions, and wrote a\n  proof of concept of a fix: https://github.com/wal-e/wal-e/pull/169\n\n* Avoid annoying error message \"invalid facility\" when stderr is set\n  as the log target.  Report and fixed by Noah Yetter.\n\nv0.8.0\n------\n\nRelease v0.8.0 is deemed backwards and forwards compatible with WAL-E\nv0.7 in terms of archival format and interface.  Upgrading and\ndowngrading require no special steps.\n\nChanges and enhancements from the v0.7 series:\n\n* Addition of parallel and pipelined WAL recovery\n\n  Enabled by default, WAL-E will now perform speculative and parallel\n  prefetching of WAL when recovering.  This is an often a significant\n  speedup in recovering or catching up databases.\n\n* The S3 Server Side Encryption is always set\n\n  Because the feature is transparent outside sending a header, this is\n  not thought to impose any changes.\n\n* Support an optinally specified S3 endpoint\n\n  This allows use of alternate S3 implementations, such as \"radosgw\".\n\n* Support an optionally specified log destination\n\n  Configuring for emitting logs on only stderr is now supported.  Also\n  supported is customizing the syslog facility logged to.\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.115234375,
          "content": "[pytest]\nflake8-ignore =\n    *.py E122 E125 E126 E127 E128 E129 E402 W503\n    wal_e/subprocess.py ALL\n    *.egg/* ALL\n"
        },
        {
          "name": "runtests.py",
          "type": "blob",
          "size": 0.3134765625,
          "content": "#!/usr/bin/env python\nimport sys\n\nfrom wal_e.cmd import external_program_check\nfrom wal_e.pipeline import PV_BIN\n\n\ndef runtests(args=None):\n    import pytest\n\n    external_program_check([PV_BIN])\n\n    if args is None:\n        args = []\n\n    sys.exit(pytest.main(args))\n\n\nif __name__ == '__main__':\n    runtests(sys.argv)\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.94921875,
          "content": "#!/usr/bin/env python\nimport os.path\nimport sys\n\n# Version file managment scheme and graceful degredation for\n# setuptools borrowed and adapted from GitPython.\ntry:\n    from setuptools import setup, find_packages\n\n    # Silence pyflakes\n    assert setup\n    assert find_packages\nexcept ImportError:\n    from ez_setup import use_setuptools\n    use_setuptools()\n    from setuptools import setup, find_packages\n\nif sys.version_info < (3, 4):\n    raise RuntimeError('Python versions < 3.4 are not supported.')\n\n\n# Utility function to read the contents of short files.\ndef read(fname):\n    with open(os.path.join(os.path.dirname(__file__), fname)) as f:\n        return f.read()\n\n\nVERSION = read(os.path.join('wal_e', 'VERSION')).strip()\n\nsetup(\n    name=\"wal-e\",\n    version=VERSION,\n    packages=find_packages(),\n\n    install_requires=['gevent>=1.1.1'],\n    extras_require={\n        'aws': ['boto>=2.40.0'],\n        'azure': ['azure==3.0.0'],\n        'google': ['google-cloud-storage>=1.4.0'],\n        'swift': ['python-swiftclient>=3.0.0',\n                  'python-keystoneclient>=3.0.0']\n    },\n\n    # metadata for upload to PyPI\n    author=\"The WAL-E Contributors\",\n    author_email=\"wal-e@googlegroups.com\",\n    maintainer=\"Daniel Farina\",\n    maintainer_email=\"daniel@fdr.io\",\n    description=\"Continuous Archiving for Postgres\",\n    long_description=read('README.rst'),\n    classifiers=[\n        'Topic :: Database',\n        'Topic :: System :: Archiving',\n        'Topic :: System :: Recovery Tools',\n        'Programming Language :: Python :: 3.4',\n        'Programming Language :: Python :: 3.5'\n    ],\n    platforms=['any'],\n    license=\"BSD\",\n    keywords=(\"postgres postgresql database backup archive archiving s3 aws \"\n              \"openstack swift wabs azure google gce gcs wal shipping\"),\n    url=\"https://github.com/wal-e/wal-e\",\n\n    # Include the VERSION file\n    package_data={'wal_e': ['VERSION']},\n\n    # install\n    entry_points={'console_scripts': ['wal-e=wal_e.cmd:main']})\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 1.1630859375,
          "content": "[tox]\nskipsdist=True\n\n# Oldest sensitive dependencies supported with WAL-E 1.0.\n[testenv:v1.0-oldest]\nbasepython = python3.4\ndeps =\n     azure-storage-blob==1.1.0\n     azure==3.0.0\n     boto==2.40.0\n     google-cloud-storage==1.4.0\n     gevent==1.1.1\n     python-keystoneclient==3.0.0\n     python-swiftclient==3.0.0\n     {[base]deps}\n\n[testenv:py34]\ndeps =\n    # All optional cloud dependencies.\n    boto\n    azure\n    google-cloud-storage\n    python-keystoneclient\n    python-swiftclient\n    {[base]deps}\n\n[testenv:py35]\ndeps =\n    # All optional cloud dependencies.\n    boto\n    azure\n    google-cloud-storage\n    python-keystoneclient\n    python-swiftclient\n    {[base]deps}\n\n[testenv:py36]\ndeps =\n    # All optional cloud dependencies.\n    boto\n    azure\n    google-cloud-storage\n    python-keystoneclient\n    python-swiftclient\n    {[base]deps}\n\n[base]\ndeps =\n    pytest\n    pytest-cov\n    pytest-flake8\n    pytest-xdist\n\n[testenv]\npassenv = BOTO_CONFIG WALE_* AWS_* WABS_* GOOGLE_* SWIFT_*\ndeps = {[base]deps}\ncommands =\n    pip install -e .\n    py.test                     \\\n    --flake8                    \\\n    --basetemp={envtmpdir}      \\\n    --confcutdir=..             \\\n    []\n"
        },
        {
          "name": "wal_e",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}