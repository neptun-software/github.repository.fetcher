{
  "metadata": {
    "timestamp": 1736559816589,
    "page": 551,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "0x727/ShuiZe_0x727",
      "stars": 3813,
      "defaultBranch": "master",
      "files": [
        {
          "name": "Plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 15.271484375,
          "content": "# 水泽-信息收集自动化工具\n\n[![GitHub release](https://img.shields.io/github/release/0x727/ShuiZe_0x727.svg)](https://github.com/0x727/ShuiZe_0x727/releases)\n\n郑重声明：文中所涉及的技术、思路和工具仅供以安全为目的的学习交流使用，任何人不得将其用于非法用途以及盈利等目的，否则后果自行承担。\n\n## 0x01 介绍\n\n作者：[Ske](https://github.com/SkewwG)\n\n团队：[0x727](https://github.com/0x727)，未来一段时间将陆续开源工具，地址：https://github.com/0x727\n\n定位：协助红队人员快速的信息收集，测绘目标资产，寻找薄弱点\n\n语言：python3开发\n\n功能：一条龙服务，只需要输入根域名即可全方位收集相关资产，并检测漏洞。也可以输入多个域名、C段IP等，具体案例见下文。\n\n调用：脚本借用了ksubdomain爆破子域名和theHarvester收集邮箱，感谢ksubdomain和theHarvester作者\n\n## 0x02 安装\n\n为了避免踩坑,建议安装在如下环境中\n\n* 当前用户对该目录有写权限，不然扫描结果无法生成。root权限即可\n* Python环境必须是3.7以上，因为使用了异步。建议VPS环境是ubuntu20，默认是python3.8。安装模块的时候切记不要走豆瓣的源\n* 在配置文件iniFile/config.ini里加入api（fofa、shodan、github、virustotal）\n\n```\nchmod 777 build.sh\n./build.sh\n```\n\n![image-20210728153419131](imgs/image-20210728153419131.png)\n\n`python3 ShuiZe.py -h`\n\n![image-20210728154929084](imgs/image-20210728154929084.png)\n\n\n### docker运行ShuiZe\n\n较多人反馈安装的时候会出现各种报错，新增通过docker运行ShuiZe\n\n通过下面的命令安装docker，然后拉取python3.8的容器，再git clone水泽后，运行docker_build.sh即可。\n\n```\napt install docker.io\ndocker pull yankovg/python3.8.2-ubuntu18.04\ndocker run -itd yankovg/python3.8.2-ubuntu18.04 bash\ndocker exec -it docker的ID /bin/bash\napt-get update\napt install git --fix-missing\napt install vim\nrm /usr/bin/python3\nln -s /usr/local/bin/python3.8 /usr/bin/python3\npython3 -m pip install --upgrade pip\ngit clone https://github.com/0x727/ShuiZe_0x727.git\nchmod 777 docker_build.sh\n./docker_build.sh\n```\n\n也可参考 [@1itt1eB0y](https://github.com/1itt1eB0y) 提供的Dockerfile和docker-compose.yml构建镜像并运行\n\n链接：https://github.com/1itt1eB0y/MyCollection/tree/master/docker/shuize\n\n**请自行评估安全性**\n\n**脚本自带Linux版本的Nuclei和ksubdomain，如果是windows或者mac，需要自行更换版本。**\n\n## 0x03 效果展示\n\n备案反查顶级域名\n\n![image-20210728155358378](imgs/image-20210728155358378.png)\n\n不是泛解析，调用ksubdomain爆破子域名\n\n![image-20210728155541501](imgs/image-20210728155541501-7458943.png)\n\ntheHarvest获取邮箱\n\n![image-20210728161507035](imgs/image-20210728161507035.png)\n\n![image-20210728163216047](imgs/image-20210728163216047.png)\n\n第三方数据接口 -> 获取子域名\n\n![image-20210728160705706](imgs/image-20210728160705706.png)\n\ngithub -> 从github获取子域名，并把查询结果保存到txt，并匹配关键字获取敏感信息\n\n![image-20210728161022348](imgs/image-20210728161022348.png)\n\n百度和必应爬虫\n\n![image-20210728161117459](imgs/image-20210728161117459.png)\n\n证书\n\n![image-20210728161711534](imgs/image-20210728161711534.png)\n\n子域名友链\n\n![image-20210728161339208](imgs/image-20210728161339208.png)\n\n解析子域名A记录,检测是否CDN和整理C段的IP\n\n![image-20210728162655684](imgs/image-20210728162655684.png)\n\n![image-20210728162049962](imgs/image-20210728162049962.png)\n\n网络空间搜索引擎：Fofa和Shodan\n\n![image-20210728162119531](imgs/image-20210728162119531.png)\n\nIP反查域名\n\n![image-20210728162303312](imgs/image-20210728162303312.png)\n\n存活探测\n\n![image-20210728162441132](imgs/image-20210728162441132.png)\n\n漏洞检测\n\n![image-20210728165612314](imgs/image-20210728165612314.png)\n\n扫描结果保存在excel文件里\n\n![image-20210728170303756](imgs/image-20210728170303756.png)\n\nexcel的内容如下\n\n备案反查顶级域名\n\n![image-20210728163926763](imgs/image-20210728163926763.png)\n\n![image-20210728163940918](imgs/image-20210728163940918.png)\n\n邮箱\n\n![image-20210728164010063](imgs/image-20210728164010063.png)\n\n\n\nGithub敏感信息\n\n![image-20210728164040649](imgs/image-20210728164040649.png)\n\n爬虫\n\n![image-20210728164146630](imgs/image-20210728164146630.png)\n\n证书\n\n![image-20210728164211552](imgs/image-20210728164211552.png)\n\n子域名A记录和CDN\n\n![image-20210728164316747](imgs/image-20210728164316747.png)\n\n动态链接和后台地址\n\n![image-20210728164555141](imgs/image-20210728164555141.png)\n\n网络空间搜索引擎\n\n![image-20210728164745820](imgs/image-20210728164745820.png)\n\nip反查域名\n\n![image-20210728164811422](imgs/image-20210728164811422.png)\n\n存活网站标题\n\n![image-20210728164933353](imgs/image-20210728164933353.png)\n\n指纹和漏洞\n\n![image-20210728165004202](imgs/image-20210728165004202.png)\n\n相关域名和C段\n\n![image-20210728165052361](imgs/image-20210728165052361.png)\n\n## 0x04 POC编写\n\nPOC的模板文件例子：`Plugins/Vul/Web/__template__.py`\n\n只需要在run_detect方法里调用POC的利用方法即可。\n\n## 0x05 使用方法 \n\n| 语法                                                     | 功能                                          |\n| :------------------------------------------------------- | :-------------------------------------------- |\n| python3 ShuiZe.py -d domain.com                          | 收集单一的根域名资产                          |\n| python3 ShuiZe.py --domainFile domain.txt                | 批量跑根域名列表                              |\n| python3 ShuiZe.py -c 192.168.1.0,192.168.2.0,192.168.3.0 | 收集C段资产                                   |\n| python3 ShuiZe.py -f url.txt                             | 对url里的网站漏洞检测                         |\n| python3 ShuiZe.py --fofaTitle XXX大学                    | 从fofa里收集标题为XXX大学的资产，然后漏洞检测 |\n| python3 ShuiZe.py -d domain.com --justInfoGather 1       | 仅信息收集，不检测漏洞                        |\n| python3 ShuiZe.py -d domain.com --ksubdomain 0           | 不调用ksubdomain爆破子域名                    |\n\n## 0x06 实现原理\n\n* 备案反查顶级域名 -> 获取目标域名相关的其他根域名 -> 接口:http://icp.chinaz.com\n* 判断是否是泛解析\n  * 泛解析-> 不爆破子域名\n  * 不是泛解析 -> 调用ksubdomain爆破子域名(脚本里我用的是linux版本的ksubdomain，文件地址:./Plugins/infoGather/subdomain/ksubdomain/ksubdomain_linux，如果是其他系统请自行替换)\n* 调用theHarvester -> 获取子域名和邮箱列表\n* 第三方数据接口 -> 获取子域名\n  * virustotal -> https://www.virustotal.com -> 需要api\n  * ce.baidu.com -> http://ce.baidu.com\n  * url.fht.im -> https://url.fht.im/\n  * qianxun -> https://www.dnsscan.cn/\n  * sublist3r -> https://api.sublist3r.com\n  * crt.sh -> https://crt.sh\n  * certspotter -> https://api.certspotter.com\n  * bufferover -> http://dns.bufferover.run\t\n  * threatcrowd -> https://threatcrowd.org\n  * hackertarget -> https://api.hackertarget.com\n  * chaziyu -> https://chaziyu.com/hbu.cn/\n  * rapiddns -> https://rapiddns.io\n  * sitedossier -> http://www.sitedossier.com\n  * ximcx -> http://sbd.ximcx.cn\t\t\n* github -> 从github获取子域名，并把查询结果保存到txt-获取敏感信息\n  * 敏感信息关键字匹配，可在iniFile/config.ini自定义关键字内容，内置如下关键字('jdbc:', 'password', 'username', 'database', 'smtp', 'vpn', 'pwd', 'passwd', 'connect')\n* 百度和必应爬虫 -> 获取目标后台等地址('inurl:admin', 'inurl:login', 'inurl:system', 'inurl:register', 'inurl:upload', '后台', '系统', '登录')\n* 证书 -> 获取目标关联域名\n* 子域名友链 -> 获取未爆破出的子域名，未被收录的深层域名\n\n![image-20210728132752381](imgs/image-20210728132752381.png)\n\n整理上面所有的子域名\n\n* 对所有子域名判断是否是CDN并解析出A记录\n\n* 统计每个c段出现IP的个数\n\n* 调用网络空间搜索引擎\n  * fofa -> 需要API\n  * shodan -> 需要API\n\n* 前面获得的ip反查域名得到相关资产的子域名，整理出所有的子域名和IP\n\n\n![image-20210728133047590](imgs/image-20210728133047590.png)\n\n* 整理所有资产探测漏洞\n\n  * Web -> 存活探测 \n\n    * 获取标题 \n      * 自动跑后台路径(['admin', 'login', 'system', 'manager', 'admin.jsp', 'login.jsp', 'admin.php', 'login.php','admin.aspx', 'login.aspx', 'admin.asp', 'login.asp'])\n      * 如果URL是IP则查询IP的归属地\n    * 漏洞检测 -> Plugins/Vul/Web\n\n    ![image-20210728134051049](imgs/image-20210728134051049.png)\n\n    ![image-20210728134115608](imgs/image-20210728134115608.png)\n\n    ![image-20210728134131076](imgs/image-20210728134131076.png)\n\n  * 非Web服务 --> 未授权和弱口令\n\n  ![image-20210728134212279](imgs/image-20210728134212279.png)\n\n\n其他功能\n\n![image-20210728134304533](imgs/image-20210728134304533.png)\n\n结果展示：\n\n![image-20210728132105833](imgs/image-20210728132105833.png)\n\n完整流程图:\n\n![](imgs/xmind.png)\n\n\n## 0x07 新增功能\n\n2021.7.31 增加了Censys接口，需要在iniFile/config.ini的[censys api]中填入API。 功能是获取域名的所有解析IP记录，一是为了Host碰撞，二是更加准确的得到C段IP\n\n需要censys的api，免费的账户一个月只有250次查询，所以后期需要注意，用完了要更新api\n\n2021.7.31 增加了Host碰撞访问内网系统漏洞，感谢 **横戈安全团队-小洲** 提交的建议\n\n![](imgs/hostCollide.png)\n\n2021.8.1 修复了CDN判断的bug，感谢 **leveryd 师傅** 提交的bug。\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/3 \n\n2021.8.3 修复了chinazApi接口请求超时太长的bug，设置默认时间10秒，感谢 **k0njac 师傅**提交的bug。\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/11 \n\n2021.8.13 增加了获取Github敏感信息地址的作者邮箱，帮助判断是否是目标员工的项目\n\n2021.8.17 更新了ksubdomain版本，自动选择网卡，不需要重新手动输入网卡\n\nksubdomain项目地址：https://github.com/knownsec/ksubdomain\n\n![](./imgs/github_auther.png)\n\n2021.9.1 增加了从fofa中爬去socks代理功能，后续可以手动配合proxychains进行漏洞探测，防止因为被封IP导致漏报。\n\n感谢 **安恒水滴实验室-1amfine2333师傅** 提供的思路。\n\n![](./imgs/socksProxy.png)\n\n2021.9.2 增加了Confluence指纹识别，漏洞利用地址：https://github.com/h3v0x/CVE-2021-26084_Confluence\n\n2021.9.4 增加了某查接口，对目标的整个架构分析，涵盖【对外投资、控股公司、分支机构、联系方式、邮箱】等信息。\n\n感谢 **pykiller师傅** 提交的建议，同时参考了 **吐司师傅gubeiya** 的脚本\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/25\n\n![](./imgs/aiqicha.png)\n\n\n2021.9.26 增加了夸克的api接口,-d -c --fofaTitle中都会调用\n\n限定了每次最大查询数量1000条，不然一个月5w条数据也用不了多少次\n\n在config.ini配置文件的quake_nums值\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/33\n\n![](./imgs/quakeApi.png)\n\n![](./imgs/quakeApi2.png)\n\n\n2021.11.30 增加了奇安信hunter的api接口,-d -c --fofaTitle中都会调用\n\n限定了每次最大查询数量200条，不然一天的几千条数据也用不了多少次\n\n在config.ini配置文件的qianxin_nums值\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/48\n\n![](./imgs/qianxinApi2.png)\n\n![](./imgs/qianxinApi.png)\n\n2022.1.17 修复了certspotter接口获取子域名过滤不严谨的问题\n\n感谢 **union-cmd师傅** 提交的建议\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/57\n\n2022.3.21 更新了fofa api的域名\n\n2022.3.21 更新了域名备案反查的问题\n\n2022.3.23 增加了securitytrails接口获取子域名，该接口很强大，建议在config.ini里添加你的api keys\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/48\n\n注册地址: https://docs.securitytrails.com/\n\n![](./imgs/securitytrails.png)\n\n感谢 **郭师傅** 提交的建议\n\n2022.3.23 修复了爱企查无法获取数据的问题\n\n感谢 **横戈安全团队-chhyx（逗逗）** 的技术支持\n\n2022.4.13 修复了奇安信测绘语法使用错误的问题\n\nissues地址：https://github.com/0x727/ShuiZe_0x727/issues/74\n\n感谢 **cwkiller** 反馈的问题\n\n2022.4.16 增加了调用Nuclei检测漏洞\n\nnuclei的参数在iniFile/config.ini配置，默认为`nuclei_config = -rl 300 -c 50 -timeout 5 -stats -silent -severity critical,high` 根据需求自行修改\n\n![](./imgs/nuclei_1.png)\n\n2022.7.5 Nuclei默认参数配置增加-as\n\nissues地址: https://github.com/0x727/ShuiZe_0x727/issues/104\n\n-as 参数，先使用 wappalyzer 进行指纹识别，在进行扫描。\n\n感谢 **anquanbiji** 反馈的建议\n\n2022.8.12 ShuiZe增加Dockerfile安装方式\n\nissues地址: https://github.com/0x727/ShuiZe_0x727/issues/99\n\n感谢 [@1itt1eB0y](https://github.com/1itt1eB0y) 提供的脚本。**安全性自行评估**\n\n\n2022.8.12 修复了大量反馈aiqicha脚本报错的问题，初步排查是被封IP的原因。\n\n2022.8.12 修复了quakeApi没有title导致报错的情况\n\nissues地址: https://github.com/0x727/ShuiZe_0x727/issues/120\n\n感谢 **Zimba5880** 反馈的建议\n\n2022.8.20 增加了快代理配置，漏洞检测时会使用快代理的代理池，这样可以避免当前IP被封后导致后续的扫描出现遗漏。\n\n购买快代理的隧道代理，地址：https://www.kuaidaili.com/cart?t=tps_c\n\n根据自己的需求选择包年包月或者按量付费，更换IP的频率。这里注意并发请求数的，并发数量越高，在配置文件里iniFile/config.ini的thread_num就可以设置的更高。\n\n假设并发数为5，那么thread_num不要设置超过10，具体的值自己测试。\n\n![](./imgs/kuaidaili1.png)\n\n购买后查看host、port、username、password，然后填入到配置文件里\n\n![](./imgs/kuaidaili2.png)\n\n![](./imgs/kuaidaili3.png)\n\n默认关闭快代理代理池功能，如果要开启，把switch设置为on，使用快代理代理池时会先验证是否配置正确\n\n![](./imgs/kuaidaili4.png)\n\n2022.8.27 集成了ObserverWard扫描指纹\n\n项目地址：https://github.com/0x727/ObserverWard\n\n指纹地址：https://github.com/0x727/FingerprintHub\n\n![](./imgs/ObserverWard1.png)\n\n\n## 0x08 反馈\n\nShuiZe（水泽） 是一个免费且开源的项目，我们欢迎任何人为其开发和进步贡献力量。\n\n* 在使用过程中出现任何问题，可以通过 issues 来反馈。\n* Bug 的修复可以直接提交 Pull Request 到 dev 分支。\n* 如果是增加新的功能特性，请先创建一个 issue 并做简单描述以及大致的实现方法，提议被采纳后，就可以创建一个实现新特性的 Pull Request。\n* 欢迎对说明文档做出改善，帮助更多的人使用 ShuiZe。\n* 贡献代码请提交 PR 至 dev 分支，master 分支仅用于发布稳定可用版本。\n\n*提醒：和项目相关的问题最好在 issues 中反馈，这样方便其他有类似问题的人可以快速查找解决方法，并且也避免了我们重复回答一些问题。*\n\n## Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/0x727/ShuiZe_0x727.svg)](https://starchart.cc/0x727/ShuiZe_0x727)\n\n<img align='right' src=\"https://profile-counter.glitch.me/ShuiZe_0x727/count.svg\" width=\"200\">"
        },
        {
          "name": "ShuiZe.py",
          "type": "blob",
          "size": 70.578125,
          "content": "# 调用各类插件获取子域名信息\r\n\r\n# -*- coding:utf-8 -*-\r\n\r\n\r\nimport sys\r\nimport os\r\n# from gevent import monkey\r\n# monkey.patch_all()\r\nimport urllib3\r\nimport openpyxl\r\n\r\nfrom Plugins.infoGather.subdomain.subdomainInterface.subdomainInterface import run_subdomainInterface\r\n\r\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\r\nfrom uuid import uuid4\r\nimport dns.resolver\r\nimport re\r\nfrom threading import Thread\r\nfrom IPy import IP\r\nfrom collections import Counter\r\nfrom queue import Queue\r\nfrom urllib.parse import urlparse\r\nfrom termcolor import cprint\r\nfrom optparse import OptionParser\r\nimport os\r\nimport platform\r\nfrom Plugins.saveToExcel import saveToExcel\r\nfrom uuid import uuid4\r\nimport socket\r\nimport socks\r\nimport configparser\r\nfrom tqdm import *\r\nfrom colorama import Fore\r\nimport requests\r\n\r\n## 调用lijiejie的子域名收集脚本\r\n# def lijiejieSubdomain():\r\n#     Subdomains_ips = {}             # 字典，key为子域名，value为子域名的A记录IP值\r\n#     Subdomains_ips[domain] = []     # 主域名\r\n#     ips_L = []\r\n#     subdomains = ''\r\n#     lijiejie_folder = './Plugins/infoGather/subdomain/lijiejie'\r\n#     cprint('-' * 50 + 'Load lijiejie Subdomain ...' + '-' * 50, 'green')  # 启动lijiejie脚本\r\n#     from Plugins.infoGather.subdomain.lijiejie.subDomainsBrute import lijiejieRun\r\n#     # print('cd {} && python3 ./subDomainsBrute.py {}'.format(lijiejie_folder, domain))\r\n#     # p1 = Popen('cd {} && python3 ./subDomainsBrute.py {}'.format(lijiejie_folder, domain), shell=True, stdin=PIPE, stdout=PIPE)\r\n#     # print(p1.stdout.read().decode('gb2312'))\r\n#     lijiejieRun(domain)\r\n#     lijiejie_domain_file = '{}/{}.txt'.format(lijiejie_folder, domain)\r\n#     with open(lijiejie_domain_file, 'rt') as f:\r\n#         for each_line in f.readlines():\r\n#             each_line_split = each_line.split('\\t')\r\n#             subdomain = each_line_split[0].strip()                  # 子域名\r\n#             ips = each_line_split[1].strip('\\n')                    # 子域名的dns解析A记录IP\r\n#             # print(subdomain, ips)\r\n#             for ip in ips.split(','):\r\n#                 ips_L.append(ip.strip())\r\n#             # print(subdomain, ips_L)\r\n#             Subdomains_ips[subdomain] = ips_L\r\n#             ips_L = []\r\n#\r\n#     os.remove(lijiejie_domain_file)                         # 删除临时文件\r\n#\r\n#     lijiejie_tmp = lijiejie_folder + '/tmp'                 # 删除tmp目录\r\n#     if os.path.isdir(lijiejie_tmp):\r\n#         shutil.rmtree(lijiejie_tmp, True)\r\n#\r\n#     return Subdomains_ips\r\n\r\n# 进度条\r\n\r\n\r\n# 判断是否是IP\r\ndef isIP(str):\r\n    p = re.compile('^((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$')\r\n    if p.match(str):\r\n        return True\r\n    else:\r\n        return False\r\n\r\n# 获取github敏感信息\r\ndef get_GitSensitiveInfo(github_txt, raw_url_emails):\r\n    cf = configparser.ConfigParser()\r\n    cf.read(\"./iniFile/config.ini\")\r\n    secs = cf.sections()\r\n    github_keywords = eval(cf.get('github keywords', 'github_keywords'))\r\n\r\n    line_urls = {}\r\n    gitSensitiveInfo = []\r\n\r\n    with open(github_txt, 'rt', encoding=\"utf-8\", errors='ignore') as f:\r\n        content = f.readlines()\r\n        for line, each in enumerate(content):\r\n            if '[------------------] ' in each:\r\n                line_urls[str(line + 1)] = each.split('[------------------] ')[1]\r\n\r\n    lines = list(line_urls.keys())\r\n\r\n    # print(line_urls)\r\n    def get_githubAddr(line):\r\n        for i, num in enumerate(lines):\r\n            # print(line)\r\n            if i < len(lines) - 1:\r\n                # print(line, int(num), int(lines[i + 1]))\r\n                if int(num) <= line <= int(lines[i + 1]):\r\n                    return int(num)\r\n            elif line > int(lines[-1]):\r\n                return int(lines[-1])\r\n\r\n    for keyword in github_keywords:\r\n        for line, each in enumerate(content):\r\n            if line < len(content) - 1:\r\n                if keyword in each:\r\n                    # print(line)\r\n                    githubAddr = get_githubAddr(line)\r\n                    # print(githubAddr)\r\n                    if githubAddr:\r\n                        raw_url = content[int(githubAddr) - 1].replace('[------------------]', '').strip()\r\n                        try:\r\n                            emails = str(raw_url_emails[raw_url])\r\n                            print('github address: [line:{}] {}'.format(githubAddr, raw_url))\r\n                            print('[emails] : {}'.format(emails))\r\n                            print('[{}] [line:{}] {}'.format(keyword, line, content[line - 1].strip()))\r\n                            print('[{}] [line:{}] {}'.format(keyword, line + 1, content[line].strip()))\r\n                            print('[{}] [line:{}] {}'.format(keyword, line + 2, content[line + 1].strip()))\r\n                            gitSensitiveInfo.append(['gitAddress', githubAddr, raw_url, emails])\r\n                            gitSensitiveInfo.append([keyword, line, content[line - 1].strip(), emails])\r\n                            gitSensitiveInfo.append([keyword, line + 1, content[line].strip(), emails])\r\n                            gitSensitiveInfo.append([keyword, line + 2, content[line + 1].strip(), emails])\r\n                            gitSensitiveInfo.append(['-' * 50, '-' * 50, '-' * 50, '-' * 50])\r\n                        except Exception as e:\r\n                            pass\r\n\r\n    return gitSensitiveInfo\r\n\r\n# 打印脚本跑出了几个新的子域名，并返回最新最全的子域名列表  传递两个列表，old是前面收集好的子域名，new是刚跑完的脚本收集的子域名，进行比较.\r\ndef printGetNewSubdomains(old_subdomains, new_subdomains):\r\n    if len(old_subdomains) > 0:\r\n        newSubdomains = list(set(new_subdomains) - set(old_subdomains))\r\n        print('[new :{}] {}'.format(len(newSubdomains), newSubdomains))\r\n    return list(set(new_subdomains + old_subdomains))\r\n\r\n\r\n# subdomains3脚本调用\r\ndef subdomains3():\r\n    cprint('-' * 50 + 'Load subdomains3 ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.subdomain3.brutedns import run_subdomains\r\n    Subdomains_ips = run_subdomains(domain)\r\n    return Subdomains_ips\r\n\r\n\r\n# dns域传送漏洞\r\ndef dnsZoneTransfer():\r\n    pass\r\n\r\n\r\n# 从fofa收集代理\r\ndef getSocksProxy():\r\n    cprint('-' * 50 + 'Load getSocksProxy ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.SocksProxy.getSocksProxy import run_getSocksProxy\r\n    socksProxysDict = run_getSocksProxy()\r\n\r\n    # 保存到excel\r\n    # socksProxysSheet = saveToExcel(excelSavePath, excel, '代理')\r\n    # socksProxysSheet.saveSocksProxys(socksProxysDict)\r\n\r\n# 备案反查顶级域名\r\ndef beian2NewDomain():\r\n    cprint('-' * 50 + 'Load beian2NewDomain ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.beian2NewDomain.beian2domain import run_beian2domain\r\n    beianNewDomains, companyName = run_beian2domain(domain)\r\n\r\n    for _ in beianNewDomains:\r\n        newDomains.append(_[2])\r\n\r\n    # 保存到excel\r\n    beianNewDomainsSheet = saveToExcel(excelSavePath, excel, '备案反查顶级域名')\r\n    beianNewDomainsSheet.saveBeianNewDomains(beianNewDomains)\r\n    return companyName\r\n\r\n\r\n# 从爱企查获取目标相关信息\r\ndef Aiqicha(companyName):\r\n    cprint('-' * 50 + 'Load Aiqicha ...' + '-' * 50, 'green')\r\n    if not companyName:\r\n        return\r\n\r\n    cprint(\"查询【{}】公司架构\".format(companyName), 'red')\r\n\r\n    from Plugins.infoGather.subdomain.Aiqicha.Aiqicha import run_aiqicha\r\n    selfIcpinfo_infos, invest_infos, holds_infos, branch_infos = run_aiqicha(companyName)\r\n\r\n    # 保存到excel\r\n    aiqichaSheet = saveToExcel(excelSavePath, excel, '爱企查')\r\n    aiqichaSheet.saveAiqicha(selfIcpinfo_infos, invest_infos, holds_infos, branch_infos)\r\n\r\n\r\n\r\n# 判断是否是泛解析\r\ndef checkPanAnalysis():\r\n    cprint('-' * 50 + 'check Pan-Analysis ...' + '-' * 50, 'green')\r\n    panDomain = 'sadfsadnxzjlkcxjvlkasdfasdf.{}'.format(domain)\r\n    try:\r\n        dns_A_ips = [j for i in dns.resolver.query(panDomain, 'A').response.answer for j in i.items]\r\n        print(dns_A_ips)\r\n        cprint('[泛解析] {} -> {}'.format(panDomain, dns_A_ips), 'red')\r\n        return True\r\n    except Exception as e:\r\n        cprint('[不是泛解析] :{}'.format(e.args), 'red')\r\n        return False\r\n\r\n\r\n\r\n# 调用kSubdomain脚本\r\ndef callKsubdomain():\r\n    cprint('-' * 50 + 'Load ksubdomain ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.ksubdomain.ksubdomain import run_ksubdomain\r\n    ksubdomains = run_ksubdomain(domain)\r\n    return ksubdomains\r\n\r\n\r\n\r\n\r\n# theHarvest脚本调用\r\ndef theHarvester():\r\n    cprint('-' * 50 + 'Load theHarvest ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.theHarvester.theHarvester import run_theHarvester\r\n    theHarvesterIp, emails, hosts = run_theHarvester(domain)\r\n    print(hosts)\r\n    theHarvesterSubdomains = []\r\n    subdomain = None\r\n    for host in list(set(hosts)):\r\n        if '/' not in host and ' ' not in host:\r\n            domain_ip = host.strip().split(':')\r\n            if len(domain_ip) == 2:\r\n                subdomain, ip = [domain_ip[0]], domain_ip[1]\r\n            elif len(domain_ip) == 1:\r\n                subdomain, ip = domain_ip, None\r\n        if subdomain:\r\n            theHarvesterSubdomains.extend(subdomain)\r\n\r\n    # 测试\r\n\r\n    # 检测邮箱的真实性\r\n    cprint('-' * 50 + 'Load verifyEmails ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.verifyEmails.VerifyEmails import run_verifyEmails\r\n    aliveEmails = run_verifyEmails(emails)\r\n\r\n    # 保存到excel\r\n    theHarvesterIpSheet = saveToExcel(excelSavePath, excel, 'theHarvester—IP')\r\n    theHarvesterIpSheet.saveTheHarvesterIp(theHarvesterIp)\r\n\r\n    emailsSheet = saveToExcel(excelSavePath, excel, '邮箱')\r\n    emailsSheet.saveEmails(emails, aliveEmails)\r\n    return list(set(theHarvesterSubdomains))\r\n\r\n\r\n# 调用virustotal|ce.baidu.com|www.threatcrowd.org|url.fht.im|的子域名收集脚本\r\ndef othersApiSubdomain():\r\n    cprint('-' * 50 + 'Load VirusTotal threatcrowd url.fht.im ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.othersApiSubdomains.othersApiSubdomains import othersApiRun\r\n    othersApiTotalSubdomains = othersApiRun(domain)          # 列表，存放子域名\r\n    return othersApiTotalSubdomains\r\n\r\ndef interfaceSubdomain():\r\n    cprint('-' * 50 + 'Load VirusTotal threatcrowd url.fht.im ...' + '-' * 50, 'green')\r\n    # from Plugins.infoGather.subdomain.othersApiSubdomains.othersApiSubdomains import othersApiRun\r\n    othersApiTotalSubdomains = run_subdomainInterface(domain)          # 列表，存放子域名\r\n    return othersApiTotalSubdomains\r\n\r\n# 调用github api的子域名收集脚本\r\ndef githubApiSubdomain():\r\n    cprint('-' * 50 + 'Load Github Api Subdomain ...' + '-' * 50, 'green')\r\n    from Plugins.infoGather.subdomain.githubSubdomains.githubSubdomains import githubApiRun\r\n    githubApiSubdomains, raw_url_emails = githubApiRun(domain, save_fold_path)          # 列表，存放子域名\r\n\r\n    # 保存到excel\r\n    githubSheet = saveToExcel(excelSavePath, excel, 'Github敏感信息')\r\n    github_txt = r'{}/{}_github.txt'.format(save_fold_path, domain)\r\n    if os.path.exists(github_txt):\r\n        gitSensitiveInfo = get_GitSensitiveInfo(github_txt, raw_url_emails)\r\n        githubSheet.saveGithub(gitSensitiveInfo)\r\n\r\n    return githubApiSubdomains\r\n\r\n\r\n# 调用Sublist3r子域名收集脚本\r\ndef Sublist3r():\r\n    print('[+] Load Sublist3r Subdomain ...')\r\n    from Plugins.infoGather.subdomain.Sublist3r.sublist3r import sublist3rRun\r\n    sublist3rSubdomains = sublist3rRun(domain)\r\n    return sublist3rSubdomains\r\n\r\n# 调用爬虫\r\ndef SpiderSubdomain():\r\n    cprint('-' * 50 + 'Load Spider ...' + '-' * 50, 'green')  # 启动百度爬虫\r\n    spiderSheet = saveToExcel(excelSavePath, excel, '爬虫')\r\n\r\n    # 百度爬虫\r\n    def BaiduSubdomain():\r\n        cprint('Load BaiduSpider ...', 'green')  # 启动百度爬虫\r\n        from Plugins.infoGather.subdomain.Spider.Baidu.baidu import BaiduSpider\r\n        bdSubdomains, links = BaiduSpider().run_subdomain(domain)\r\n        # 保存到excel\r\n        spiderSheet.saveSpider('百度', links)\r\n        return bdSubdomains\r\n\r\n    # 必应爬虫\r\n    def BingSubdomain():\r\n        cprint('Load BingSpider ...', 'green')  # 启动必应爬虫\r\n        from Plugins.infoGather.subdomain.Spider.Bing.bing import BingSpider\r\n        bingSubdomains, links = BingSpider().run_subdomain(domain)\r\n        # 保存到excel\r\n        spiderSheet.saveSpider('必应', links)\r\n        return bingSubdomains\r\n\r\n    bdSubdomains = BaiduSubdomain()\r\n    bingSubdomains = BingSubdomain()\r\n    spiderSubdomains = list(set(bdSubdomains + bingSubdomains))\r\n\r\n    return spiderSubdomains\r\n\r\n# 抓取https域名的证书dns信息\r\ndef crawlCerts(subdomains):\r\n    cprint('-' * 50 + 'Load crawlCerts ...' + '-' * 50, 'green')  # 启动证书爬虫\r\n    from Plugins.infoGather.subdomain.Certs.crawlCerts import crawlCerts\r\n    certsSubdomains, trustedDomainDict, _newDomains = crawlCerts(domain, subdomains).run()\r\n\r\n    newDomains.extend(_newDomains)\r\n    # 保存到excel\r\n    certSheet = saveToExcel(excelSavePath, excel, '证书')\r\n    certSheet.saveCert(trustedDomainDict)\r\n\r\n    return certsSubdomains\r\n\r\n# 调用友链爬虫\r\ndef FriendChinsSubdomain(temp_subdomains):\r\n    cprint('-' * 50 + 'Load FriendChins ...' + '-' * 50, 'green')  # 启动友链爬虫\r\n    from Plugins.infoGather.subdomain.FriendChins.crawlFriendChins import FriendChins\r\n    fcSubdomains = FriendChins(domain, temp_subdomains).run()\r\n    return fcSubdomains\r\n\r\n\r\n# 整合子域名，对所有子域名解析A记录\r\ndef checkCDN_queryA_subdomains(Subdomains_ips, subdomains):\r\n    cprint('-' * 50 + 'check subdomains CDN and query ip ...' + '-' * 50, 'green')  # 整合所有子域名\r\n    tmp_subdomains = []\r\n    for subdomain in subdomains:\r\n        if '.{}'.format(domain) in subdomain:\r\n            tmp_subdomains.append(subdomain)\r\n    subdomains = list(set(tmp_subdomains))\r\n\r\n\r\n    print('Check CDN [{}] subdomains'.format(len(subdomains)))\r\n    from Plugins.infoGather.subdomain.CDN import checkCDN\r\n    notCDNSubdomains, CDNSubdomainsDict = checkCDN.run_checkCDN(subdomains)\r\n\r\n    print('Query the A record of [{}] subdomains'.format(len(subdomains)))\r\n    from Plugins.infoGather.subdomain.queryA import queryA\r\n    Subdomains_ips = queryA.run_queryA(Subdomains_ips, subdomains)\r\n\r\n    # 保存到excel\r\n    queryASheet = saveToExcel(excelSavePath, excel, '子域名A记录')\r\n    queryASheet.saveQueryA(Subdomains_ips, CDNSubdomainsDict)\r\n\r\n    return Subdomains_ips, CDNSubdomainsDict, notCDNSubdomains\r\n\r\n# host碰撞\r\ndef hostCollide(Subdomains_ips):\r\n    cprint('-' * 50 + 'run_hostCollide ...' + '-' * 50, 'green')  # 启动网络空间引擎\r\n    from Plugins.infoGather.subdomain.hostCollide import hostCollide\r\n    hostCollideResult, censysIPS = hostCollide.run_hostCollide(domain, Subdomains_ips)\r\n\r\n    # 保存到excel\r\n    queryASheet = saveToExcel(excelSavePath, excel, 'HOST碰撞')\r\n    queryASheet.saveHostCollide(hostCollideResult)\r\n\r\n    return censysIPS\r\n\r\n# 获取所有子域名的参数链接和后台链接（存活）\r\ndef run_ParamLinks():\r\n    cprint('-' * 50 + 'run_ParamLinks ...' + '-' * 50, 'green')  # 启动网络空间引擎\r\n    from Plugins.infoGather.ParamSpider.paramSpider import getParamLinks\r\n    paramLinks, htLinks = getParamLinks(domain)\r\n\r\n    # 保存到excel\r\n    paramHtLinksSheet = saveToExcel(excelSavePath, excel, '动态链接和后台地址')\r\n    paramHtLinksSheet.saveparamHtLinks(paramLinks, htLinks)\r\n\r\n    # 如果动态链接的个数大于1000，\r\n    if len(paramLinks) > 1000:\r\n        paramLinks = []\r\n\r\n    return paramLinks\r\n\r\n# 整理IP，获取C段IP\r\ndef get_CIP(Subdomains_ips, CDNSubdomainsDict, censysIPS):\r\n    cprint('-' * 50 + 'get_CIP ...' + '-' * 50, 'green')  # 整理C段IP\r\n    # 过滤内网IP\r\n    def is_internal_ip(ip_subnet):\r\n        ip_subnet_list = ip_subnet.split('.')\r\n        if ip_subnet_list[0] == '10' or ip_subnet_list[0] == '127':\r\n            return True\r\n        elif ip_subnet_list[0] == '172' and 15 < int(ip_subnet_list[1]) < 32:\r\n            return True\r\n        elif ip_subnet_list[0] == '192' and ip_subnet_list[1] == '168':\r\n            return True\r\n        else:\r\n            return False\r\n\r\n    ips = []\r\n    CIP_List = []\r\n    CIP_List_all = []\r\n\r\n    for subdomain in Subdomains_ips:\r\n        if CDNSubdomainsDict[subdomain] == 'NOT':           # 如果该子域名没有CDN，则开始统计解析出来的IP\r\n            ip_List = Subdomains_ips[subdomain]\r\n            for ip in ip_List:\r\n                if not is_internal_ip(ip):\r\n                    ips.append(ip)\r\n\r\n    ips.extend(censysIPS)\r\n\r\n    for ip in list(set(ips)):\r\n        c_subnet = str(IP(ip).make_net('255.255.255.0')).rsplit('.', 1)[0] + '.0'\r\n        CIP_List_all.append(c_subnet)\r\n\r\n    global ip_count\r\n    ip_count = Counter(CIP_List_all)\r\n    cprint(ip_count, 'red')\r\n    import configparser\r\n    cf = configparser.ConfigParser()\r\n    cf.read(\"./iniFile/config.ini\")\r\n    c_nums = cf.get('C nums', 'c_nums')\r\n\r\n    for ip in ip_count:\r\n        if ip_count[ip] > int(c_nums):\r\n            CIP_List.append(ip)\r\n\r\n    return CIP_List\r\n    # return list(set(CIP_List))\r\n\r\n\r\n# 调用网络空间引擎,查询根域名和C段IP的资产\r\ndef run_webSpace(domain, SubdomainAndNotCDNIPs, CIP_List, fofaTitle):\r\n    cprint('-' * 50 + 'run_webSpace ...' + '-' * 50, 'green')  # 启动网络空间引擎\r\n    from Plugins.infoGather.WebspaceSearchEngine import fofaApi, shodanApi, quakeApi, qianxinApi\r\n    webSpaceSheet = saveToExcel(excelSavePath, excel, '网络空间搜索引擎')\r\n    serviceSheet = saveToExcel(excelSavePath, excel, '服务')\r\n\r\n    webSpace_web_host_port = []         # 存放开放web服务\r\n    webSpace_service_host_port = []     # 存放除了Web的其他服务\r\n\r\n    # fofa搜索引擎信息收集\r\n    def run_fofa():\r\n        # 查询域名\r\n        if domain:\r\n            query_str = 'domain=\"{}\"'.format(domain)\r\n            fofa_Results, fofa_web_host_port, fofa_service_host_port = fofaApi.query_domain(query_str)\r\n            if fofa_Results:\r\n                webSpaceSheet.saveWebSpace('fofa', fofa_Results, query_str) # 将网络空间搜索引擎的结果保存到webSpace项里\r\n                # save_webSpace(fofa_Results, 'fofa', query_str)\r\n                webSpace_web_host_port.extend(fofa_web_host_port)\r\n                webSpace_service_host_port.extend(fofa_service_host_port)\r\n\r\n        # 查询C段IP\r\n        if CIP_List:\r\n            for c_subnet in CIP_List:\r\n                query_str = 'ip=\"{}/24\"'.format(c_subnet)\r\n                fofa_Results, fofa_web_host_port, fofa_service_host_port = fofaApi.query_ip(query_str)\r\n                if fofa_Results:\r\n                    webSpaceSheet.saveWebSpace('fofa', fofa_Results, query_str)\r\n                    webSpace_web_host_port.extend(fofa_web_host_port)\r\n                    webSpace_service_host_port.extend(fofa_service_host_port)\r\n\r\n        if fofaTitle:\r\n            query_str = 'title=\"{}\" && country=\"CN\"'.format(fofaTitle)\r\n            fofa_Results, fofa_web_host_port, fofa_service_host_port = fofaApi.query_domain(query_str)\r\n            if fofa_Results:\r\n                webSpaceSheet.saveWebSpace('fofa', fofa_Results, query_str) # 将网络空间搜索引擎的结果保存到webSpace项里\r\n                # save_webSpace(fofa_Results, 'fofa', query_str)\r\n                webSpace_web_host_port.extend(fofa_web_host_port)\r\n                webSpace_service_host_port.extend(fofa_service_host_port)\r\n\r\n\r\n\r\n    # shodan搜索引擎信息收集\r\n    def run_shodan():\r\n        # 查询域名\r\n        if domain:\r\n            query_str = 'hostname:\"{}\"'.format(domain)\r\n            shodan_Results, shodan_web_host_port, shodan_service_host_port = shodanApi.query_domain(query_str)\r\n            if shodan_Results:\r\n                webSpaceSheet.saveWebSpace('shodan', shodan_Results, query_str)\r\n                webSpace_web_host_port.extend(shodan_web_host_port)\r\n                webSpace_service_host_port.extend(shodan_service_host_port)\r\n\r\n        # 查询C段IP\r\n        if CIP_List:\r\n            for c_subnet in CIP_List:\r\n                query_str = 'net:\"{}/24\"'.format(c_subnet)\r\n                shodan_Results, shodan_web_host_port, shodan_service_host_port = shodanApi.query_ip(query_str)\r\n                if shodan_Results:\r\n                    webSpaceSheet.saveWebSpace('shodan', shodan_Results, query_str)\r\n                    webSpace_web_host_port.extend(shodan_web_host_port)\r\n                    webSpace_service_host_port.extend(shodan_service_host_port)\r\n\r\n    # quake搜索引擎信息收集\r\n    def run_quake():\r\n        # 查询域名\r\n        if domain:\r\n            query_str = 'domain:\"{}\" AND country:\"China\"'.format(domain)\r\n            quake_Results, quake_web_host_port, quake_service_host_port = quakeApi.query_domain(query_str)\r\n            if quake_Results:\r\n                webSpaceSheet.saveWebSpace('quake', quake_Results, query_str)\r\n                webSpace_web_host_port.extend(quake_web_host_port)\r\n                webSpace_service_host_port.extend(quake_service_host_port)\r\n\r\n        # 查询C段IP\r\n        if CIP_List:\r\n            for c_subnet in CIP_List:\r\n                query_str = 'ip:\"{}/24\"'.format(c_subnet)\r\n                quake_Results, quake_web_host_port, quake_service_host_port = quakeApi.query_ip(query_str)\r\n                if quake_Results:\r\n                    webSpaceSheet.saveWebSpace('quake', quake_Results, query_str)\r\n                    webSpace_web_host_port.extend(quake_web_host_port)\r\n                    webSpace_service_host_port.extend(quake_service_host_port)\r\n\r\n        if fofaTitle:\r\n            query_str = 'title:\"{}\" AND country:\"China\"'.format(fofaTitle)\r\n            quake_Results, quake_web_host_port, quake_service_host_port = quakeApi.query_ip(query_str)\r\n            if quake_Results:\r\n                webSpaceSheet.saveWebSpace('quake', quake_Results, query_str)\r\n                webSpace_web_host_port.extend(quake_web_host_port)\r\n                webSpace_service_host_port.extend(quake_service_host_port)\r\n\r\n    # qianxin搜索引擎信息收集\r\n    def run_qianxin():\r\n        # 查询域名\r\n        if domain:\r\n            query_str = '(domain.suffix=\"{}\")&&(country==\"中国\")'.format(domain)\r\n            qianxin_Results, qianxin_web_host_port, qianxin_service_host_port = qianxinApi.query_domain(query_str)\r\n            if qianxin_Results:\r\n                webSpaceSheet.saveWebSpace('qianxin', qianxin_Results, query_str)\r\n                webSpace_web_host_port.extend(qianxin_web_host_port)\r\n                webSpace_service_host_port.extend(qianxin_service_host_port)\r\n\r\n        # 查询C段IP\r\n        if CIP_List:\r\n            for c_subnet in CIP_List:\r\n                query_str = 'ip=\"{}/24\"'.format(c_subnet)\r\n                qianxin_Results, qianxin_web_host_port, qianxin_service_host_port = qianxinApi.query_ip(query_str)\r\n                if qianxin_Results:\r\n                    webSpaceSheet.saveWebSpace('qianxin', qianxin_Results, query_str)\r\n                    webSpace_web_host_port.extend(qianxin_web_host_port)\r\n                    webSpace_service_host_port.extend(qianxin_service_host_port)\r\n\r\n        if fofaTitle:\r\n            query_str = '(title=\"{}\")&&(country==\"中国\")'.format(fofaTitle)\r\n            qianxin_Results, qianxin_web_host_port, qianxin_service_host_port = qianxinApi.query_ip(query_str)\r\n            if qianxin_Results:\r\n                webSpaceSheet.saveWebSpace('qianxin', qianxin_Results, query_str)\r\n                webSpace_web_host_port.extend(qianxin_web_host_port)\r\n                webSpace_service_host_port.extend(qianxin_service_host_port)\r\n\r\n\r\n    # 对子域名和非CDN的IP进行fofa查询\r\n    def run_fofaOne(subdomainAndIP_Q):\r\n        while not subdomainAndIP_Q.empty():\r\n            subdomainOrIp = subdomainAndIP_Q.get()\r\n            if isIP(subdomainOrIp):\r\n                query_str = 'ip=\"{}\"'.format(subdomainOrIp)\r\n            else:\r\n                query_str = 'domain=\"{}\"'.format(subdomainOrIp)\r\n            fofa_Results, fofa_web_host_port, fofa_service_host_port = fofaApi.query_ip(query_str)\r\n            if fofa_Results:\r\n                webSpaceSheet.saveWebSpace('fofa', fofa_Results, query_str)  # 将网络空间搜索引擎的结果保存到webSpace项里\r\n                # save_webSpace(fofa_Results, 'fofa', query_str)\r\n                webSpace_web_host_port.extend(fofa_web_host_port)\r\n                webSpace_service_host_port.extend(fofa_service_host_port)\r\n\r\n    run_fofa()\r\n    run_shodan()\r\n    run_quake()\r\n    run_qianxin()\r\n\r\n\r\n    # fofa跑所有子域名解析出来的IP\r\n    if SubdomainAndNotCDNIPs:\r\n        subdomainAndIP_Q = Queue(-1)\r\n        for subdomainAndIP in SubdomainAndNotCDNIPs:\r\n            subdomainAndIP_Q.put(subdomainAndIP)\r\n        threads = []\r\n        for t_id in range(5):\r\n            t = Thread(target=run_fofaOne, args=(subdomainAndIP_Q, ))\r\n            threads.append(t)\r\n            t.start()\r\n        for t in threads:\r\n            t.join()\r\n\r\n    serviceResult = []\r\n    for _ in webSpace_service_host_port:            # 去重\r\n        if _ not in serviceResult:\r\n            serviceResult.append(_)\r\n\r\n    webSpace_service_host_port = serviceResult\r\n    # 将非Web服务的结果保存到service项里\r\n    serviceSheet.saveService(webSpace_service_host_port)\r\n\r\n\r\n    return webSpace_web_host_port, webSpace_service_host_port\r\n\r\n\r\n# 整理fofaTitle结果的域名和IP\r\ndef collation_fofaDomainIP(webSpace_web_host_port):\r\n    ips = []\r\n    fofaTitle_IPs = []\r\n    fofaTitle_newDomains = []\r\n\r\n    for _ in webSpace_web_host_port:\r\n        a = urlparse(_)\r\n        if a.scheme:\r\n            newdomain_ip = a.netloc.split(':')[0]\r\n        else:\r\n            newdomain_ip = a.path.split(':')[0]\r\n        if isIP(newdomain_ip):\r\n            ips.append(newdomain_ip)\r\n        else:\r\n            fofaTitle_newDomains.append(newdomain_ip)\r\n\r\n    for ip in list(set(ips)):\r\n        ip_C = str(IP(ip).make_net('255.255.255.0')).rsplit('.', 1)[0] + '.0'\r\n        fofaTitle_IPs.append(ip_C)\r\n\r\n    global ip_count\r\n    ip_count = Counter(fofaTitle_IPs)\r\n    newDomains.extend(fofaTitle_newDomains)\r\n\r\n# ip反查域名，并将域名结果保存到Subdomains_ips列表里，并且存放到ip2domain_dict里\r\ndef get_ip2domain():\r\n    cprint('-' * 50 + 'ip to domain ...' + '-' * 50, 'green')  # 对IP进行域名反查\r\n    from Plugins.infoGather.subdomain.ip2domain import getIp2Domain\r\n\r\n    ip2domain_dict, _newDomains = getIp2Domain.run_ip2domain(domain, allTargets_Queue)  # ip2domain_dict字典，key为IP，value为反查的域名\r\n\r\n    # 和目标关联的相关域名\r\n    newDomains.extend(_newDomains)\r\n\r\n    # 去重\r\n    ip2domainSubdomains = []                        # 反查出来的子域名列表    ['ca.hbu.edu.cn', 'jwjcc.bdu.edu.cn', 'yzuuc.hbu.cn']\r\n    for subdomains in ip2domain_dict.values():\r\n        for subdomain in subdomains:\r\n            if domain:\r\n                if domain in subdomain:\r\n                    ip2domainSubdomains.append(subdomain)\r\n            else:\r\n                ip2domainSubdomains.append(subdomain)\r\n    ip2domainSubdomains = list(set(ip2domainSubdomains))\r\n\r\n    ip2domainSheet = saveToExcel(excelSavePath, excel, 'ip反查域名')    # 创建一个ip反查域名页\r\n    ip2domainSheet.saveIp2Domain(ip2domain_dict)\r\n\r\n    return ip2domainSubdomains      # 返回ip反查得到的域名列表\r\n\r\n\r\n# 对IP进行归属地查询\r\ndef get_ip_address(web_ip_list):\r\n    cprint('-' * 50 + 'get ip address ...' + '-' * 50, 'green')  # 对IP进行归属地查询\r\n    from Plugins.infoGather.subdomain.ipAddress import getIpAddress\r\n    ip_address_dict = getIpAddress.run_getIpAddress(web_ip_list)            # 字典，key为IP，value为归属地\r\n    return ip_address_dict\r\n\r\n\r\n# 整理开放web服务的host\r\ndef collation_web_host(Subdomains_ips, webSpace_web_host_port, ip2domainSubdomains):\r\n    cprint('-' * 50 + 'collation_web_host ...' + '-' * 50, 'green')  # 启动web服务收集\r\n    web_host_port = []                      # 存放最终的开放web服务的host\r\n    web_host_port_temp = []                 # web_host_port临时列表\r\n    web_ip_list = []                        # 存放开放web服务的IP\r\n\r\n\r\n    for subdomain in list(set(list(Subdomains_ips.keys()) + ip2domainSubdomains)):\r\n        if ':' in subdomain:                        # ip2domainSubdomains的结果里有些类似于221.192.236.146:999这种结果，所以不加80端口\r\n            web_host_port_temp.append(subdomain)\r\n        else:\r\n            web_host_port_temp.append('{}:80'.format(subdomain))\r\n\r\n    web_host_port_temp.extend(webSpace_web_host_port)\r\n    # print('[{}] {}'.format(len(web_host_port), web_host_port))\r\n    web_host_port_temp = list(set(web_host_port_temp))\r\n    # print('[{}] {}'.format(len(web_host_port), web_host_port))\r\n\r\n    # 整合url，格式规范。全部是http(s)://www.domain.com:xxxx\r\n    for host_port in web_host_port_temp:\r\n        host_port_urlparse = urlparse(host_port)\r\n        if not host_port_urlparse.scheme:           # 如果没有http（https）， 则加上。如果是443端口，则加https，其他端口加http\r\n            if ':' in host_port:\r\n                try:\r\n                    host, port = host_port.split(':')\r\n                    if isIP(host):\r\n                        web_ip_list.append(host)\r\n                    if port == '443':\r\n                        host_port = 'https://{}'.format(host)\r\n                    elif port == '80':\r\n                        host_port = 'http://{}'.format(host)\r\n                    else:\r\n                        host_port = 'http://{}'.format(host_port)\r\n                except Exception as e:\r\n                    pass\r\n            else:\r\n                host_port = 'http://{}'.format(host_port)\r\n        else:   # 如果有https或者http，则不加\r\n            host_port = host_port\r\n        web_host_port.append(host_port)\r\n\r\n    web_host_port = list(set(web_host_port))    # 去重\r\n    web_ip_list = list(set(web_ip_list))\r\n\r\n    return web_host_port, web_ip_list\r\n\r\n\r\n# 内网端口扫描\r\ndef scan_IntranetPorts():\r\n\r\n\r\n    from Plugins.infoGather.Intranet.scanPort import scanPort\r\n    from Plugins.infoGather.Intranet import getMoreIp\r\n\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'scan_IntranetPorts ...' + '-' * 50)\r\n    web_host_port, service_host_port, alive_host_List = scanPort.run_ScanPort(allTargets_Queue, proxy)\r\n\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'get_IntranetHostName and IP ...' + '-' * 50)\r\n    alive_hostname_ips = getMoreIp.run_getMoreIp(alive_host_List)        # 通过oxid获取主机名和更多的内网IP\r\n\r\n    # 写入表格里\r\n    intranetServiceSheet = saveToExcel(excelSavePath, excel, '内网服务')\r\n    intranetServiceSheet.saveService(service_host_port)\r\n\r\n    intranetHostNameIpsSheet = saveToExcel(excelSavePath, excel, '内网主机名和IP')\r\n    intranetHostNameIpsSheet.saveHostNameAndIps(alive_hostname_ips)\r\n\r\n    return web_host_port, alive_host_List\r\n\r\n# 筛选存活并获取标题\r\ndef run_getWebTitle(web_host_port, ip_address_dict):\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'run_getWebTitle ...' + '-' * 50)  # 筛选存活并获取标题\r\n    from Plugins.infoGather.webInfo import getWebTitle\r\n    if isIntranet == 1:\r\n        threadNum = 10        # 如果是扫内网，则线程为5\r\n    else:\r\n        threadNum = 300      # 扫外网则线程为300\r\n\r\n    # title不需要使用快代理\r\n    requests_proxies = None\r\n    web_Titles = getWebTitle.run_getWebTitle(web_host_port, ip_address_dict, requests_proxies, threadNum)\r\n    # print(web_Titles)\r\n    alive_Web = []  # 存活的web服务\r\n    for each in web_Titles:\r\n        if each[1] != 65535:\r\n            alive_Web.append(each[0])\r\n\r\n    # 写入表格里\r\n    webTitileSheet = saveToExcel(excelSavePath, excel, '存活网站标题')  # 创建一个ip反查域名页\r\n    webTitileSheet.saveWebTitle(web_Titles)\r\n\r\n    return web_Titles, alive_Web\r\n\r\n\r\n# Web漏洞检测\r\ndef detect_webVul(alive_Web):\r\n\r\n    # 跑自己的漏洞脚本\r\n    def runSelfVul():\r\n        vul_path = os.getcwd() + '/Plugins/Vul/Web/'\r\n        sys.path.append(vul_path)  # 添加环境变量\r\n        vulList = filter(lambda x: (True, False)[x[-3:] == 'pyc' or x[-5:] == '__.py' or x[:2] == '__'],\r\n                         os.listdir(vul_path))  # 获取漏洞脚本\r\n\r\n        # 内网跑的漏洞\r\n        intPassVul = ['Jboss.py', 'phpstudy.py', 'weblogic.py', 'cms.py', 'yongyou.py', 'easyConnect.py', 'shiro.py']\r\n\r\n        for vulName in vulList:\r\n            tqdm.write(Fore.BLACK + '-' * 50 + 'detect ' + vulName[:-3] + '-' * 50)  # 探测各种漏洞\r\n            md = __import__(vulName[:-3])  # 导入类\r\n            try:\r\n                if hasattr(md, 'Detect'):\r\n                    detect = getattr(md, 'Detect')  # 获取类\r\n\r\n                    alive_Web_queue = Queue(-1)  # 将存活的web存入队列里\r\n                    for _ in alive_Web:\r\n                        alive_Web_queue.put(_)\r\n\r\n                    threads = []\r\n                    if isIntranet == 1:\r\n                        threadNum = 30  # 如果是扫内网，则线程为5\r\n                        if vulName in intPassVul:\r\n                            pass\r\n                        else:\r\n                            tqdm.write(Fore.BLACK + '内网不跑{}漏洞'.format(vulName))\r\n                            continue\r\n                    else:\r\n                        threadNum = 100  # 扫外网则线程为300\r\n\r\n                    # 使用快代理时，线程调整\r\n                    if kuaidaili_thread_num:\r\n                        threadNum = int(kuaidaili_thread_num)\r\n\r\n                    pbar = tqdm(total=alive_Web_queue.qsize(), desc=\"检测Web漏洞\", ncols=150)  # total是总数\r\n\r\n                    for num in range(1, threadNum + 1):\r\n                        t = detect(alive_Web_queue, pbar, webVul_list, requests_proxies)  # 实例化漏洞类，传递参数：存活web的队列，  存储漏洞的列表\r\n                        threads.append(t)\r\n                        t.start()\r\n                    for t in threads:\r\n                        t.join()\r\n\r\n                    pbar.close()\r\n            except Exception as e:\r\n                tqdm.write(Fore.BLACK + r'[-] Load Vul [{}] Error: {}'.format(vulName, e.args))\r\n                continue\r\n\r\n    # 调用ObserverWard跑指纹\r\n    def runObserverWard():\r\n        cprint('-' * 50 + 'Load ObserverWard ...' + '-' * 50, 'green')\r\n        from Plugins.Vul.ObserverWard.ObserverWardApi import run_observerWard\r\n        observerWardVul_list = run_observerWard(alive_Web)\r\n        webVul_list.extend(observerWardVul_list)\r\n\r\n    # 调用Nuclei跑漏洞\r\n    def runNucleiVul():\r\n        cprint('-' * 50 + 'Load Nuclei ...' + '-' * 50, 'green')\r\n        from Plugins.Vul.Nuclei.NucleiApi import run_nuclei\r\n        nucleiVul_list = run_nuclei(alive_Web)\r\n        webVul_list.extend(nucleiVul_list)\r\n\r\n\r\n\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'detect Web vul' + '-' * 50)  # 探测各种漏洞\r\n    webVul_list = []  # 存储Web漏洞，每个元素都是一个列表。[['shiro', 'http://127.0.0.1'], ['weblogic', 'http://127.0.0.1'], ['phpstudy', 'http://127.0.0.1']]\r\n\r\n    runObserverWard()\r\n    runSelfVul()\r\n    runNucleiVul()\r\n    # print(webVul_list)\r\n    return webVul_list\r\n\r\n# 参数漏洞检测\r\ndef detect_paramVul(param_Links):\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'detect param vul' + '-' * 50)  # 探测各种参数漏洞-注入\r\n    paramVul_list = []  # 存储参数漏洞，每个元素都是一个列表。[['SQL', 'http://127.0.0.1/a.php?id=1'], ['SQL', 'http://127.0.0.1/a.php?id=2']]\r\n\r\n    vul_path = os.getcwd() + '/Plugins/Vul/Param/'\r\n    sys.path.append(vul_path)  # 添加环境变量\r\n    vulList = filter(lambda x: (True, False)[x[-3:] == 'pyc' or x[-5:] == '__.py' or x[:2] == '__'],\r\n                     os.listdir(vul_path))  # 获取漏洞脚本\r\n\r\n\r\n    for vulName in vulList:\r\n        tqdm.write(Fore.BLACK + '-' * 50 + 'detect ' + vulName[:-3] + '-' * 50)  # 探测各种漏洞\r\n        md = __import__(vulName[:-3])  # 导入类\r\n        try:\r\n            paramVul_list = md.detect(param_Links)\r\n        except Exception as e:\r\n            tqdm.write(Fore.BLACK + r'[-] Load Vul [{}] Error: {}'.format(vulName, e.args))\r\n            continue\r\n\r\n    return paramVul_list\r\n\r\n\r\n\r\n# 未授权漏洞检测\r\ndef detect_unauthWeakVul(service_host_port):\r\n    tqdm.write(Fore.BLACK + '-' * 50 + 'detect unauth vul' + '-' * 50)  # 探测各种漏洞\r\n    tqdm.write(Fore.BLACK + 'service_host_port : {}'.format(service_host_port))\r\n\r\n    service_host_port_queue = Queue(-1)            # 队列\r\n    for _ in service_host_port:\r\n        service_host_port_queue.put((_))\r\n\r\n    # 键值队，key为漏洞的名字，value为漏洞插件名\r\n    serviceVulName = {'redis': 'unAuthRedis', 'elastic': 'unAuthElastic', 'mongodb': 'unAuthMongodb', 'ldaps': 'unAuthLdaps',\r\n                      'zookeeper': 'unAuthZookeeper', 'ftp': 'weakFTP', 'ssh': 'weakSSH', 'mssql': 'weakMSSQL',\r\n                      'mysql': 'weakMYSQL', 'rdp': 'weakRDP'}\r\n\r\n    # 弱口令漏洞-密码字典文件地址\r\n    weakTxtDict = {'ftp': 'dic_password_ftp.txt', 'ssh': 'dic_password_ssh.txt', 'mssql': 'dic_password_sqlserver.txt',\r\n                      'mysql': 'dic_password_mysql.txt', 'rdp': 'dic_password_rdp.txt'}\r\n\r\n    # 存放弱口令密码\r\n    serviceWeakPwds = {}\r\n    # 读取密码字典\r\n    for protocol in weakTxtDict.keys():\r\n        weakPwdTxt = './iniFile/PwdTxt/{}'.format(weakTxtDict[protocol])\r\n        with open(weakPwdTxt, 'rt') as f:\r\n            serviceWeakPwds[protocol] = f.readlines()\r\n\r\n    unauthWeakVul_list = []  # 存储未授权漏洞，每个元素都是一个列表。[['redis', 'http://127.0.0.1'], ['elastic', 'http://127.0.0.1']]\r\n\r\n    unauthVul_path = os.getcwd() + '/Plugins/Vul/Service/'\r\n    sys.path.append(unauthVul_path)  # 添加环境变量\r\n\r\n    # 多线程探测未授权-弱口令漏洞\r\n    def detect_unauthWeak(protocol, ip, port):\r\n        if protocol in serviceVulName.keys():\r\n            vulName = serviceVulName[protocol]\r\n            # 跑域名和C段的时候默认要跑弱口令\r\n            # if not domain and not cSubnet:\r\n            if not weak and protocol in weakTxtDict.keys():\r\n                return\r\n            if protocol in serviceWeakPwds.keys():\r\n                weakPwdsList = serviceWeakPwds[protocol]        # 弱口令密码列表\r\n            else:\r\n                weakPwdsList = []\r\n\r\n            tqdm.write(Fore.BLACK + 'test [{}] : {} {}'.format(vulName, ip, port))\r\n\r\n            try:\r\n                md = __import__(vulName)  # 导入类\r\n                if hasattr(md, 'Detect'):\r\n                    detect = getattr(md, 'Detect')  # 获取类\r\n                    detect(ip, port, unauthWeakVul_list).run_detect(weakPwdsList)\r\n            except Exception as e:\r\n                tqdm.write(Fore.BLACK + r'[-] Load Vul [{}] Error: {}'.format(vulName, e.args))\r\n\r\n    pbar = tqdm(total=len(service_host_port), desc=\"检测未授权漏洞\", ncols=150)  # total是总数\r\n    for _ in service_host_port:\r\n        protocol, ip, port = _\r\n        detect_unauthWeak(protocol, ip, port)\r\n        pbar.update(1)\r\n    pbar.close()  # 关闭进度条\r\n\r\n\r\n\r\n    return unauthWeakVul_list\r\n\r\n\r\n\r\n# Windows漏洞检测\r\ndef detect_winVul(alive_host_List):\r\n    cprint('-' * 50 + 'detect Windows vul' + '-' * 50, 'green')  # 探测Windows漏洞\r\n    winVul_list = []  # 存储Windows漏洞，每个元素都是一个列表。[['CVE-2020-0796', '127.0.0.1'], ['MS17010', '127.0.0.1']]\r\n\r\n    vul_path = os.getcwd() + '/Plugins/Vul/Win/'\r\n    sys.path.append(vul_path)  # 添加环境变量\r\n    vulList = filter(lambda x: (True, False)[x[-3:] == 'pyc' or x[-5:] == '__.py' or x[:2] == '__'],\r\n                     os.listdir(vul_path))  # 获取漏洞脚本\r\n\r\n    for vulName in vulList:\r\n        cprint('-' * 50 + 'detect ' + vulName[:-3] + '-' * 50, 'green')  # 探测各种漏洞\r\n        md = __import__(vulName[:-3])  # 导入类\r\n        try:\r\n            if hasattr(md, 'Detect'):\r\n                detect = getattr(md, 'Detect')  # 获取类\r\n\r\n                alive_host_queue = Queue(-1)  # 将存活的主机存入队列里\r\n                for _ in alive_host_List:\r\n                    alive_host_queue.put(_)\r\n\r\n                threads = []\r\n                if isIntranet == 1:\r\n                    threadNum = 5  # 如果是扫内网，则线程为5\r\n                else:\r\n                    threadNum = 200  # 扫外网则线程为300\r\n\r\n                for num in range(1, threadNum + 1):\r\n                    t = detect(alive_host_queue, winVul_list, proxy)  # 实例化漏洞类，传递参数：存活主机的队列，  存储漏洞的列表\r\n                    threads.append(t)\r\n                    t.start()\r\n                for t in threads:\r\n                    t.join()\r\n\r\n        except Exception as e:\r\n            print(r'[-] Load Vul [{}] Error: {}'.format(vulName, e.args))\r\n            continue\r\n\r\n    return winVul_list\r\n\r\n\r\n\r\n# 打印漏洞并保存\r\ndef printSave_Vul(Vul_list):\r\n    if Vul_list:        # 如果探测出漏洞\r\n        tqdm.write(Fore.BLACK + '-' * 50 + 'Vulnerabilities exist ' + '-' * 50)  # 探测各种漏洞\r\n        for vul in Vul_list:\r\n            Vul_Name, Vul_url, Vul_exist = vul\r\n            tqdm.write(Fore.BLACK + '[{}] {} {}'.format(Vul_Name, Vul_url, Vul_exist))\r\n\r\n        # 写入表格里\r\n        vulSheet = saveToExcel(excelSavePath, excel, '漏洞')  # 创建一个ip反查域名页\r\n        vulSheet.saveVul(Vul_list)\r\n\r\n    else:\r\n        tqdm.write(Fore.BLACK + '-' * 50 + 'Non-existent vulnerabilities' + '-' * 50)\r\n\r\n# 15. 保存相关信息：新的域名和C段IP信息\r\ndef saveRelatedInfo(newDomains, ip_count):\r\n    ip2domainSheet = saveToExcel(excelSavePath, excel, '相关域名和C段')    # 创建一个ip反查域名页\r\n    ip2domainSheet.saveNewDomainAndCSubnet(newDomains, ip_count)\r\n\r\n\r\n# 获取子域名\r\ndef run_subdomain():\r\n    # 弃用 1. lijiji\r\n    # Subdomains_ips = lijiejieSubdomain()  # 字典，key为子域名，value为子域名的A记录IP值\r\n    # print(Subdomains_ips)\r\n\r\n    # 弃用 2. sublist3r\r\n    # sublist3rSubdomains = []     # Sublist3r()\r\n    # print('sublist3rSubdomains: {}'.format(sublist3rSubdomains))\r\n    # sublist3rSubdomains = []\r\n\r\n    # 启用 2. subdomains\r\n    # Subdomains_ips = subdomains3()  # 字典，key为子域名，value为子域名的A记录IP值\r\n    # print('[total: {}] Subdomains3: {}'.format(len(Subdomains_ips), Subdomains_ips))\r\n\r\n    # 0. beian2NewDomain\r\n    # companyName = beian2NewDomain()\r\n    #\r\n    # # 爱企查\r\n    # Aiqicha(companyName)\r\n\r\n    Subdomains_ips = {}\r\n\r\n    # dns域传送\r\n    # subdomains = dnsZoneTransfer()\r\n\r\n\r\n    # 判断是否是泛解析\r\n    isPanAnalysis = checkPanAnalysis()\r\n\r\n    if not isPanAnalysis and ksubdomain:\r\n        # 0. 调用kSubdomain脚本\r\n        ksubdomains = callKsubdomain()\r\n    else:\r\n        ksubdomains = []\r\n\r\n    print('[total: {}] ksubdomain: {}'.format(len(ksubdomains), ksubdomains))\r\n    subdomains = printGetNewSubdomains([], ksubdomains)\r\n    print('len [{}]'.format(len(subdomains)))\r\n\r\n    # 1. theHarvester\r\n    theHarvesterSubdomains = [] # theHarvester()\r\n    print('[total: {}] theHarvester: {}'.format(len(theHarvesterSubdomains), theHarvesterSubdomains))\r\n    subdomains = printGetNewSubdomains(subdomains, theHarvesterSubdomains)\r\n    print('len [{}]'.format(len(subdomains)))\r\n\r\n    # 2. virustotal|ce.baidu.com|www.threatcrowd.org|url.fht.im|qianxun\r\n    subdomainInterface_context_list = interfaceSubdomain()\r\n    subdomainInterface_subdomains_list = []\r\n    for _ in subdomainInterface_context_list:\r\n        subdomainInterface_subdomains_list.extend(_['subdomains'])\r\n    subdomains = printGetNewSubdomains(subdomains, subdomainInterface_subdomains_list)\r\n\r\n    # 3. github\r\n    githubApiSubdomains = githubApiSubdomain()\r\n    print('[total: {}] Github: {}'.format(len(githubApiSubdomains), githubApiSubdomains))\r\n    subdomains = printGetNewSubdomains(subdomains, githubApiSubdomains)\r\n\r\n    # 4. 爬虫(百度｜必应)\r\n    spiderSubdomains = SpiderSubdomain()\r\n    print('[total: {}] Spider: {}'.format(len(spiderSubdomains), spiderSubdomains))\r\n    subdomains = printGetNewSubdomains(subdomains, spiderSubdomains)\r\n\r\n    # 防止程序奔溃后重新跑耗费大量时间，所以在当前目录创建文本保存子域名\r\n    with open('{}.txt'.format(domain), 'at') as f:\r\n        for subdomain in subdomains:\r\n            f.writelines('{}\\n'.format(subdomain))\r\n\r\n    # 测试\r\n    '''\r\n    Subdomains_ips = {}\r\n'''\r\n\r\n    # 5. 爬证书\r\n    certsSubdomains = crawlCerts(subdomains)\r\n    print('[total: {}] Certs: {}'.format(len(certsSubdomains), certsSubdomains))\r\n    subdomains = printGetNewSubdomains(subdomains, certsSubdomains)\r\n\r\n    # 6. 爬友链\r\n    fcSubdomains = FriendChinsSubdomain(subdomains)\r\n    print('[total: {}] Friends: {}'.format(len(fcSubdomains), fcSubdomains))\r\n    subdomains = printGetNewSubdomains(subdomains, fcSubdomains)\r\n\r\n    # 防止程序奔溃后重新跑耗费大量时间，所以在当前目录创建文本保存子域名\r\n    with open('{}.txt'.format(domain), 'at') as f:\r\n        for subdomain in subdomains:\r\n            f.writelines('{}\\n'.format(subdomain))\r\n\r\n\r\n    # 7. 整合子域名，对所有子域名判断是否是CDN,解析A记录，并将所有子域名结果保存到excel里\r\n    Subdomains_ips, CDNSubdomainsDict, notCDNSubdomains = checkCDN_queryA_subdomains(Subdomains_ips, subdomains)\r\n\r\n    # host碰撞,censysIPS是censys api得到的解析的IP\r\n    censysIPS = hostCollide(Subdomains_ips)\r\n\r\n    # 8. 获取所有子域名的参数链接（存活）\r\n    param_Links = [] # run_ParamLinks()\r\n\r\n    # 获取C段的IP\r\n    CIP_List = get_CIP(Subdomains_ips, CDNSubdomainsDict, censysIPS)\r\n    print('C段的IP:{}'.format(CIP_List))\r\n\r\n    # 8. 跑C段\r\n    run_cSubnet(CIP_List, Subdomains_ips, notCDNSubdomains, param_Links)\r\n\r\n# 获取C段资产\r\ndef run_cSubnet(CIP_List, Subdomains_ips, notCDNSubdomains, param_Links):\r\n    print(CIP_List)\r\n    print(Subdomains_ips)\r\n    print(notCDNSubdomains)\r\n\r\n    SubdomainAndNotCDNIPs = []  # 子域名和非CDN的IP\r\n\r\n    for subdomain in notCDNSubdomains:\r\n        for ip in Subdomains_ips[subdomain]:\r\n            SubdomainAndNotCDNIPs.append(ip)\r\n    SubdomainAndNotCDNIPs = list(set(SubdomainAndNotCDNIPs))\r\n    # 防止IP太多，导致查询次数过多被fofa封\r\n    if len(SubdomainAndNotCDNIPs) > 10:\r\n        SubdomainAndNotCDNIPs = []\r\n\r\n    # print(notCDNSubdomainIPs)\r\n    # 8. 调用网络空间引擎,查询根域名和C段IP的资产         webSpace_web_host_port 是Web服务             webSpace_service_host_port  是其他服务\r\n    if domain:            # 跑域名的时候，不跑C段\r\n        webSpace_web_host_port, webSpace_service_host_port = run_webSpace(domain, SubdomainAndNotCDNIPs, [], '')\r\n    else:\r\n        webSpace_web_host_port, webSpace_service_host_port = run_webSpace(domain, [], CIP_List, '')           # 网络空间引擎（fofa、shodan）获取的开放web服务的host（IP/domain）\r\n    # print('webSpace_web_host_port: {}'.format(webSpace_web_host_port))\r\n    # print('webSpace_service_host_port: {}'.format(webSpace_service_host_port))\r\n\r\n    for subdomain in Subdomains_ips.keys():\r\n        for ip in Subdomains_ips[subdomain]:\r\n            allTargets_Queue.put(ip)\r\n            allTargets_List.append(ip)\r\n\r\n\r\n    # ip反查的子域名列表\r\n    ip2domainSubdomains = get_ip2domain()\r\n    print('[total: {}] ip2domainSubdomains: {}'.format(len(ip2domainSubdomains), ip2domainSubdomains))\r\n    print('[ip2domain get new subdomains] [{}]'.format(len(list(set(ip2domainSubdomains)-set(list(Subdomains_ips.keys()))))))\r\n\r\n    # 9. 整理开放web服务的host, 存放开放web服务器的ip/domain和port，用来后面的cms识别\r\n    web_host_port, web_ip_list = collation_web_host(Subdomains_ips, webSpace_web_host_port, ip2domainSubdomains)\r\n    print('[total: {}] web_host_port'.format(len(web_host_port)))\r\n\r\n    # 10. 对IP进行归属地查询\r\n    ip_address_dict = get_ip_address(web_ip_list)\r\n\r\n\r\n\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, ip_address_dict)  # 获取C段资产\r\n\r\n    # 不仅仅只信息收集-即跑漏洞\r\n    if justInfoGather == 0:\r\n        webVul_list = detect_webVul(alive_Web)  # 获取C段资产\r\n\r\n\r\n        if domain:\r\n            # paramVul_list = detect_paramVul(param_Links)      不跑注入\r\n            paramVul_list = []\r\n        else:\r\n            paramVul_list = []\r\n\r\n        # 13. 未授权漏洞检测\r\n        unauthWeakVul_list = detect_unauthWeakVul(webSpace_service_host_port)       # 获取C段资产\r\n        # unauthWeakVul_list = []\r\n        # 14. 打印并保存漏洞\r\n        Vul_list = webVul_list + unauthWeakVul_list + paramVul_list\r\n        printSave_Vul(Vul_list)\r\n\r\n\r\n\r\n    # 15. 保存相关信息：新的域名和C段IP信息\r\n    saveRelatedInfo(newDomains, ip_count)\r\n\r\n    cprint(r'新的域名：{}'.format(newDomains), 'green')\r\n    cprint(r'C段IP：{}'.format(CIP_List), 'green')\r\n    cprint(r'资产信息保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n    cprint(r'Github信息保存路径：{}/{}_github.txt'.format(save_fold_path, domain), 'green')\r\n\r\n    if domain:\r\n        ret = \"\"\r\n        for cip in CIP_List:\r\n            ret += cip\r\n            ret += \",\"\r\n        cprint(r\"请使用-c功能跑C段资产\", 'green')\r\n        cprint(r\"python3 ShuiZe.py -c {}\".format(ret[:-1]), 'red')\r\n\r\n# 跑fofa Title漏洞\r\ndef run_fofaTitle():\r\n    webSpace_web_host_port, webSpace_service_host_port = run_webSpace(domain, [], [], fofaTitle)\r\n    # print('webSpace_web_host_port: {}'.format(webSpace_web_host_port))\r\n    # print('webSpace_service_host_port: {}'.format(webSpace_service_host_port))\r\n\r\n    # 整理fofaTitle结果的域名和IP\r\n    collation_fofaDomainIP(webSpace_web_host_port)\r\n\r\n    # 9. 整理开放web服务的host, 存放开放web服务器的ip/domain和port，用来后面的cms识别\r\n    web_host_port, web_ip_list = collation_web_host({}, webSpace_web_host_port, [])\r\n    print('[total: {}] web_host_port'.format(len(web_host_port)))\r\n\r\n    # 10. 对IP进行归属地查询\r\n    ip_address_dict = get_ip_address(web_ip_list)\r\n\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, ip_address_dict)\r\n\r\n    # 12. Web漏洞检测\r\n    webVul_list = detect_webVul(alive_Web)\r\n\r\n    # 13. 检测未授权，弱口令漏洞\r\n    unauthWeakVul_list = detect_unauthWeakVul(webSpace_service_host_port)       # 跑fofa Title漏洞\r\n\r\n    # 14. 打印并保存漏洞\r\n    Vul_list = webVul_list + unauthWeakVul_list\r\n    printSave_Vul(Vul_list)\r\n\r\n    # 15. 保存相关信息：新的域名和C段IP信息\r\n    saveRelatedInfo(newDomains, ip_count)\r\n\r\n    cprint(r'新的域名：{}'.format(newDomains), 'green')\r\n    cprint(r'C段IP：{}'.format(CIP_List), 'green')\r\n    cprint(r'资产信息保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n    cprint(r'Github信息保存路径：{}/{}_github.txt'.format(save_fold_path, domain), 'green')\r\n\r\n# 扫描内网Web漏洞\r\ndef run_intranetWeb():\r\n    # 9. 整理开放web服务的host, 存放开放web服务器的ip/domain和port，用来后面的cms识别\r\n    web_host_port, web_ip_list = collation_web_host({}, [], allTargets_List)\r\n    print('[total: {}] web_host_port'.format(len(web_host_port)))\r\n\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, {})\r\n\r\n    # 12. Web漏洞检测\r\n    webVul_list = detect_webVul(alive_Web)\r\n\r\n    # 14. 打印并保存漏洞\r\n    Vul_list = webVul_list + []\r\n    printSave_Vul(Vul_list)\r\n\r\n    cprint(r'保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n\r\n# 读取文件扫描，文件是每行一个url\r\ndef run_file():\r\n    # 9. 整理开放web服务的host, 存放开放web服务器的ip/domain和port，用来后面的cms识别\r\n    web_host_port, web_ip_list = collation_web_host({}, [], allTargets_List)\r\n    print('[total: {}] web_host_port'.format(len(web_host_port)))\r\n\r\n    # 10. 对IP进行归属地查询\r\n    ip_address_dict = get_ip_address(web_ip_list)\r\n\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, ip_address_dict)\r\n\r\n    # 12. Web漏洞检测\r\n    webVul_list = detect_webVul(alive_Web)              # # 读取文件扫描\r\n\r\n    # 13. 检测未授权，弱口令漏洞\r\n    # webVul_list = []\r\n    # webSpace_service_host_port = []\r\n    unauthWeakVul_list = detect_unauthWeakVul([])       # 读取文件扫描\r\n\r\n    # 14. 打印并保存漏洞\r\n    Vul_list = webVul_list + unauthWeakVul_list\r\n    printSave_Vul(Vul_list)\r\n\r\n    cprint(r'保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n\r\n\r\n# 内网C段扫描， web端口，未授权服务端口，弱口令端口\r\ndef run_intranet_cSubnet():\r\n    # 10. 内网端口扫描, 返回存活IP和开放web端口的ip\r\n    web_host_port, alive_host_List = scan_IntranetPorts()\r\n    # web_host_port, alive_host_List = ['http://192.168.168.139:80'], ['192.168.168.139']\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, {})\r\n\r\n    # 12. Web漏洞检测\r\n    webVul_list = detect_webVul(alive_Web)\r\n\r\n    # 13. 不检测未授权，弱口令漏洞，因为需要用proxychains，不能用代理\r\n\r\n    # 14. 检测windows漏洞: CVE-2020-0796\r\n    # webVul_list = []\r\n    # alive_host_List = ['192.168.168.148']\r\n    winVul_list = detect_winVul(alive_host_List)\r\n\r\n    # 15. 打印并保存漏洞\r\n    printSave_Vul(webVul_list+winVul_list)\r\n\r\n    cprint(r'保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n\r\n\r\n\r\n\r\n# 内网服务漏洞检测\r\ndef run_intranet_ServiceVul():\r\n    # 从表格里读取《内网服务》的数据，并保存到service_host_port列表里\r\n    intranetServiceSheet = xlsxFileWB.get_sheet_by_name(r'内网服务')\r\n    service_host_port = []\r\n    for i in range(2, intranetServiceSheet.max_row + 1):  # 遍历每行\r\n        eachline = []\r\n        for j in range(1, intranetServiceSheet.max_column + 1):  # 遍历每列\r\n            eachValue = intranetServiceSheet.cell(row=i, column=j).value\r\n            if j == 3:\r\n                eachValue = int(eachValue)\r\n            eachline.append(eachValue)\r\n        service_host_port.append(eachline)      # []\r\n\r\n\r\n    # 13. 检测未授权，弱口令漏洞\r\n    unauthWeakVul_list = detect_unauthWeakVul(service_host_port)\r\n\r\n    # 14. 打印并保存漏洞\r\n    printSave_Vul(unauthWeakVul_list)\r\n\r\n    cprint(r'保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n\r\n# 读取masNmap.xlsx文件扫描web漏洞和未授权漏洞\r\ndef run_masNmap():\r\n    xlsxFile = openpyxl.load_workbook(masNmapFile)  # 打开文件\r\n    masNmapSheet = xlsxFile.get_sheet_by_name(r'masNmap')\r\n    service_host_port = []\r\n    web_host_port = []\r\n    for i in range(2, masNmapSheet.max_row + 1):  # 遍历每行\r\n        eachline = []\r\n        for j in range(1, masNmapSheet.max_column + 1):  # 遍历每列\r\n            eachValue = masNmapSheet.cell(row=i, column=j).value\r\n            if j == 3:\r\n                eachValue = int(eachValue)\r\n            eachline.append(eachValue)\r\n\r\n        if 'http' in eachline[0]:\r\n            url = '{}://{}:{}'.format(eachline[0], eachline[1], eachline[2])\r\n        else:\r\n            url = 'http://{}:{}'.format(eachline[1], eachline[2])\r\n        web_host_port.append(url)\r\n        service_host_port.append(eachline)\r\n        # if 'http' in eachline[0]:\r\n        #     url = '{}://{}:{}'.format(eachline[0], eachline[1], eachline[2])\r\n        #     web_host_port.append(url)\r\n        # else:\r\n        #     service_host_port.append(eachline)\r\n\r\n    # 11. 获取标题, 以及存活的web\r\n    web_Title, alive_Web = run_getWebTitle(web_host_port, {})\r\n\r\n    # 12. Web漏洞检测\r\n    webVul_list = detect_webVul(alive_Web)\r\n\r\n    # 13. 检测未授权，弱口令漏洞\r\n    unauthWeakVul_list = detect_unauthWeakVul(service_host_port)\r\n\r\n    # 14. 打印并保存漏洞\r\n    Vul_list = webVul_list + unauthWeakVul_list\r\n    printSave_Vul(Vul_list)\r\n\r\n    cprint(r'保存路径：{}'.format('{}/{}.xlsx'.format(save_fold_path, excel_name)), 'green')\r\n\r\ndef banner():\r\n    banner = '''    __             ____    ___     ____  \r\n   /  \\   __ __   |__  |  |_  )   |__  | \r\n  | () |  \\ \\ /     / /    / /      / /  \r\n   \\__/   /_\\_\\    /_/    /___|    /_/       author:ske\r\n   \r\n   脚本自带Linux版本的Nuclei和ksubdomain，如果是windows或者mac，需要自行更换版本。\r\n   Plugins/infoGather/subdomain/ksubdomain/ksubdomain.py\r\n   Plugins/Vul/Nuclei/NucleiApi.py\r\n   最好在配置文件里填入fofa、shodan、github、censys的API，这样效果最佳。\r\n   请一定要配置fofa的api～～～最好是高级会员\r\n   配置文件地址：iniFile/config.ini\r\n'''\r\n    print(banner)\r\n\r\n# 判断是否是最新版本\r\ndef checkVersion():\r\n    with open(\"versionFlag.txt\", \"rt\", encoding=\"utf-8\") as f:\r\n        now_version = f.read().strip()\r\n    # print(\"目前版本: \\n{}\".format(now_version))\r\n    version_url = \"https://raw.githubusercontent.com/0x727/ShuiZe_0x727/master/versionFlag.txt\"\r\n    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\r\n    try:\r\n        res = requests.get(url=version_url, headers=headers, timeout=10, verify=False)\r\n        new_version = res.text.strip()\r\n        # print(\"最新版本: \\n{}\".format(new_version))\r\n        if now_version == new_version:\r\n            cprint(\"目前版本最新\", 'red')\r\n        else:\r\n            add_version = new_version.replace(now_version, \"\")\r\n            # cprint(\"更新内容如下:{}\\n\".format(add_version), \"red\")\r\n            cprint(\"目前版本非最新，建议及时更新...\\n地址: https://github.com/0x727/ShuiZe_0x727/\", 'red')\r\n\r\n    except Exception as e:\r\n        print('获取版本信息失败...')\r\n\r\n# 初始配置\r\ndef _init():\r\n    global domain, cSubnet, save_fold_path, excel, excel_name, excelSavePath, proxy, \\\r\n        requests_proxies, isIntranet, xlsxFileWB, weak, CIP_List, allTargets_List, \\\r\n        allTargets_Queue, masNmapFile, newDomains, ip_count, fofaTitle, ksubdomain, justInfoGather, socksProxysDict, kuaidaili_thread_num\r\n\r\n    # python3 %prog -n 1 -c 192.168.1.0,192.168.2.0 -p 1.1.1.1:1111                 内网：使用代理扫描内网C段资产：web标题和漏洞\r\n    # proxychains4 python3 %prog -n 1 -f /result/2ddcaa3ebbd0/172.18.82.0.xlsx      内网：使用proxychains4代理扫描C段的服务漏洞：弱口令和未授权\r\n    # python3 %prog --mn masNmap.xlsx                                               外网：扫描masscan和nmap的结果\r\n    # python3 %prog -n 1 -c 192.168.1.0,192.168.2.0 -v 1                            内网：使用wifi或者vpn的情况下扫web标题和漏洞\r\n\r\n    banner()\r\n    checkVersion()\r\n\r\n    usage = '\\n\\t' \\\r\n            'python3 %prog -d domain.com\\n\\t' \\\r\n            'python3 %prog -d domain.com --justInfoGather 1\\n\\t' \\\r\n            'python3 %prog -d domain.com --ksubdomain 0\\n\\t' \\\r\n            'python3 %prog -c 192.168.1.0,192.168.2.0,192.168.3.0\\n\\t' \\\r\n            'python3 %prog -f url.txt\\n\\t' \\\r\n            'python3 %prog -n 1 -c 192.168.1.0,192.168.2.0 -p 1.1.1.1:1111\\n\\t' \\\r\n            'python3 %prog -n 1 -f url.txt -p 1.1.1.1:1111 --web 1\\n\\t' \\\r\n            'python3 %prog -n 1 -c 192.168.1.0,192.168.2.0 -v 1\\n\\t' \\\r\n            'proxychains4 python3 %prog -n 1 -f /result/2ddcaa3ebbd0/172.18.82.0.xlsx\\n\\t' \\\r\n            'proxychains4 python3 %prog -n 1 -w 1 -f /result/2ddcaa3ebbd0/172.18.82.0.xlsx\\n\\t' \\\r\n            'python3 %prog --mn masNmap.xlsx\\n\\t' \\\r\n            'python3 %prog --mn masNmap.xlsx -w 1\\n\\t' \\\r\n            'python3 %prog --fofaTitle 大学\\n\\t' \\\r\n            'python3 %prog --domainFile domain.txt\\n\\t'\r\n    parse = OptionParser(usage=usage)\r\n    parse.add_option('-d', '--domain', dest='domain', type='string', help='target domain')\r\n    parse.add_option('-c', '--cSubnet', dest='cSubnet', type='string', help='target cSubnet')\r\n    # parse.add_option('--proxyFlag', dest='proxyFlag', type='int', default=0, help='0:No,1:kuaidaili,2:tencentcs')  # 0不使用代理扫描，1使用快代理扫描，2使用腾讯云函数扫描\r\n    parse.add_option('-n', '--intranet', dest='isIntranet', type='int', default=0, help='Scan intranet value set to 1')        # 扫描内网, 值为1扫内网， 默认为0\r\n    parse.add_option('-p', '--proxy', dest='proxy', type='string', default=None, help='Intranet proxy socks5 socks4')           # 代理，socks5和socks4, 默认为None，可用于外网扫描，也可以用于内网扫描\r\n    parse.add_option('-f', '--file', dest='File', type='string', default=None, help='/result/2ddcaa3ebbd0/172.18.82.0.xlsx')  # 扫描内网的服务漏洞-未授权和弱口令\r\n    parse.add_option('-w', '--weak', dest='weak', type='int', default=None, help='run weak password script')                    # 内网弱口令是否要跑\r\n    parse.add_option('-v', '--vpn', dest='vpn', type='int', default=None, help='Run in the case of vpn')            # 在vpn的情况下跑\r\n    parse.add_option('--web', dest='web', type='int', default=None, help='detect web in Intranet')  # 跑内网的web漏洞\r\n    parse.add_option('--mn', dest='masNmapFile', type='str', default=None, help='run masscan nmap result')          # 跑masscan和nmap的结果\r\n    parse.add_option('--fofaTitle', dest='fofaTitle', type='str', default=None, help='run fofa title')  # 跑fofa的title\r\n    parse.add_option('--domainFile', dest='domainFile', type='str', default=None, help='run domain title')  # 跑多个域名\r\n    parse.add_option('--ksubdomain', dest='ksubdomain', type='int', default=1, help='not run ksubdomain')  # 不使用ksubdomain跑子域名\r\n    parse.add_option('--test', dest='testDemo', type='int', default=0, help='if test=1 then run testDemo')  # 测试某个功能\r\n    parse.add_option('--justInfoGather', dest='justInfoGather', type='int', default=0, help='just infoGather, not detect vul')  # 只信息收集，不跑漏洞\r\n    parse.add_option('--getSocks', dest='getSocks', type='int', default=0, help='get socks')  # 获取socks代理\r\n\r\n\r\n    options, args = parse.parse_args()\r\n    domain, cSubnet, isIntranet, proxy, File, weak, vpn, masNmapFile, fofaTitle, domainFile, web, ksubdomain, justInfoGather, testDemo, getSocks = options.domain, options.cSubnet, options.isIntranet, options.proxy, options.File, options.weak, options.vpn, options.masNmapFile, options.fofaTitle, options.domainFile, options.web, options.ksubdomain, options.justInfoGather, options.testDemo, options.getSocks\r\n\r\n    # 所有目标\r\n    allTargets_List = []\r\n    allTargets_Queue = Queue(-1)\r\n\r\n    # C段IP列表\r\n    CIP_List = []\r\n\r\n    # C段出现的IP个数\r\n    ip_count = Counter()\r\n\r\n    # 和目标资产相关联的新的根域名\r\n    newDomains = []\r\n\r\n    # 代理\r\n    socksProxysDict = {\"baidu\": [], \"google\": []}\r\n\r\n    print(domain, cSubnet, isIntranet, proxy, File)\r\n\r\n    # requests代理\r\n    # 内网代理\r\n    if proxy:\r\n        requests_proxies = {\"http\": \"socks5://{}\".format(proxy), \"https\": \"socks5://{}\".format(proxy)}\r\n    # 外网代理\r\n    else:\r\n        cf = configparser.ConfigParser()\r\n        cf.read(\"./iniFile/config.ini\")\r\n\r\n        # 快代理配置\r\n        kuaidaili_tunnel = cf.get('kuaidaili', 'tunnel')\r\n        kuaidaili_username = cf.get('kuaidaili', 'username')\r\n        kuaidaili_password = cf.get('kuaidaili', 'password')\r\n        kuaidaili_thread_num = cf.get('kuaidaili', 'thread_num')\r\n        kuaidaili_switch = cf.get('kuaidaili', 'switch')\r\n        if kuaidaili_switch == \"on\":\r\n            requests_proxies = {\r\n                \"http\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": kuaidaili_username, \"pwd\": kuaidaili_password, \"proxy\": kuaidaili_tunnel},\r\n                \"https\": \"http://%(user)s:%(pwd)s@%(proxy)s/\" % {\"user\": kuaidaili_username, \"pwd\": kuaidaili_password, \"proxy\": kuaidaili_tunnel}\r\n            }\r\n\r\n            cprint('-' * 50 + 'Detect kuaidaili Config'.format(domain) + '-' * 50, 'green') # 验证代理是否有效\r\n            try:\r\n                kuaidaili_ips = []\r\n                for i in range(3):\r\n                    res = requests.get(url='https://www.taobao.com/help/getip.php', proxies=requests_proxies, timeout=10, verify=False)\r\n                    print(res.text)\r\n                    ip = re.findall(r'ip:\"([\\d\\.]+)\"', res.text)[0]\r\n                    print(\"此次请求IP: {}\".format(ip))\r\n                    kuaidaili_ips.append(ip)\r\n                if len(kuaidaili_ips) == 3:\r\n                    cprint(\"快代理配置验证通过\", 'red')\r\n                else:\r\n                    cprint(\"快代理配置验证失败\", 'red')\r\n                    exit()\r\n            except Exception as OSError:\r\n                print(\"快代理配置错误或者快代理请求超时，请检查 {}\".format(OSError.args))\r\n                exit()\r\n\r\n        else:\r\n            requests_proxies = None\r\n\r\n\r\n    # 分割C段，获取ip\r\n    if cSubnet:\r\n        CIP_List = cSubnet.split(',')\r\n        for CIP in CIP_List:\r\n            for ip in IP('{}/24'.format(CIP)):\r\n                allTargets_Queue.put(str(ip))\r\n                allTargets_List.append(str(ip))\r\n\r\n    # 扫描外网时加载文件扫描\r\n    if File and not isIntranet:\r\n        with open(File, 'rt') as f:\r\n            for each in f.readlines():\r\n                allTargets_Queue.put(each.strip())\r\n                allTargets_List.append(each.strip())\r\n\r\n    # 创建目录\r\n    # 扫描内网漏洞（Web或者服务）\r\n    if File and isIntranet:\r\n        if not web:     # 扫描内网服务漏洞\r\n            save_fold_path, _excel_name = File.rsplit('/', 1)\r\n            excel_name = _excel_name.rsplit('.', 1)[0] + '_ServiceVul'\r\n            xlsxFileWB = openpyxl.load_workbook(File)  # 打开文件\r\n        else:           # 扫描内网web漏洞\r\n            save_fold_path = os.getcwd() + '/result/' + str(uuid4()).split('-')[-1]  # 保存路径\r\n            os.makedirs(save_fold_path)\r\n            with open(File, 'rt') as f:\r\n                for each in f.readlines():\r\n                    allTargets_Queue.put(each.strip())\r\n                    allTargets_List.append(each.strip())\r\n\r\n    # 扫描外网或者外网读取file.txt或者读取masNmap.xlsx时\r\n    else:\r\n        try:\r\n            save_fold_path = os.getcwd() + '/result/' + str(uuid4()).split('-')[-1] # 保存路径\r\n            os.makedirs(save_fold_path)\r\n        except Exception:\r\n            pass\r\n\r\n\r\n\r\n    excel = openpyxl.Workbook()\r\n    excel.remove(excel[excel.sheetnames[0]])  # 删除第一个默认的表\r\n\r\n\r\n\r\n\r\n\r\n    if domain and cSubnet:\r\n        cprint('Error： domain and cSubnet can only pass one', 'red')\r\n        exit(0)\r\n    elif domain and not cSubnet:        # 跑域名\r\n        cprint('-' * 50 + 'Start {} information collection'.format(domain) + '-' * 50, 'green')\r\n        excel_name = domain\r\n        excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n        run_subdomain()\r\n    elif not domain and cSubnet:        # 跑C段\r\n        if isIntranet == 0:             # 外网C段\r\n            cprint('-' * 50 + 'Start {} cSubnet collection'.format(cSubnet) + '-' * 50, 'green')\r\n            excel_name = cSubnet\r\n            excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n            print('C Subnet: {}'.format(CIP_List))\r\n            run_cSubnet(CIP_List, {}, [], [])\r\n        elif isIntranet == 1:\r\n            if proxy or vpn:            # 内网C段的扫描\r\n                cprint('-' * 50 + 'Start {} cSubnet intranet scan'.format(cSubnet) + '-' * 50, 'green')\r\n                excel_name = cSubnet\r\n                excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n                print('C Subnet: {}'.format(CIP_List))\r\n                run_intranet_cSubnet()\r\n            else:\r\n                cprint('Error： Please pass in the agent when scanning the intranet', 'red')\r\n\r\n    elif File:\r\n        if isIntranet and not web:              # 扫描内网的服务漏洞\r\n            cprint('-' * 50 + 'Open {} Scanning for service vulnerabilities on the intranet'.format(File) + '-' * 50, 'green')\r\n            excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n            print('xlsxFile: {}'.format(File))\r\n            run_intranet_ServiceVul()\r\n        elif isIntranet and web:                   # 扫描内网Web漏洞\r\n            cprint('-' * 50 + 'Open {} Scanning for intranet Web vulnerabilities'.format(File) + '-' * 50, 'green')\r\n            excel_name = str(uuid4()).split('-')[0]\r\n            excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n            run_intranetWeb()\r\n        else:                       # 扫描外网漏洞\r\n            cprint('-' * 50 + 'Open {} Scanning'.format(File) + '-' * 50, 'green')\r\n            excel_name = str(uuid4()).split('-')[0]\r\n            excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n            print('open File: {}'.format(File))\r\n            run_file()\r\n\r\n    elif masNmapFile:   # 跑masscan和nmap的结果\r\n        cprint('-' * 50 + 'Open masNmap File {} to Scanning'.format(masNmapFile) + '-' * 50, 'green')\r\n        excel_name = str(uuid4()).split('-')[0]\r\n        excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n        run_masNmap()\r\n    elif fofaTitle:             # 跑fofa Title漏洞\r\n        cprint('-' * 50 + 'Run Fofa Search Title {} to Scanning'.format(fofaTitle) + '-' * 50, 'green')\r\n        excel_name = str(uuid4()).split('-')[0]\r\n        excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n        run_fofaTitle()\r\n    elif domainFile:        #  跑域名文件\r\n        cprint('-' * 50 + 'Run Domain File {} to information collection'.format(domainFile) + '-' * 50, 'green')\r\n        with open(domainFile, 'rt') as f:\r\n            for each in f.readlines():\r\n                # C段IP列表\r\n                CIP_List = []\r\n                # C段出现的IP个数\r\n                ip_count = Counter()\r\n                # 和目标资产相关联的新的根域名\r\n                newDomains = []\r\n\r\n                domain = each.strip()\r\n                cprint('-' * 50 + 'Start {} information collection'.format(domain) + '-' * 50, 'green')\r\n                excel_name = domain\r\n                excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n                excel = openpyxl.Workbook()\r\n                excel.remove(excel[excel.sheetnames[0]])  # 删除第一个默认的表\r\n                run_subdomain()\r\n    elif testDemo == 1:\r\n        # 测试代码\r\n        # domain = ''\r\n        # save_fold_path = os.getcwd() + '/result/' + str(uuid4()).split('-')[-1]  # 保存路径\r\n        # os.makedirs(save_fold_path)\r\n        # excel_name = domain\r\n        # excelSavePath = '{}/{}.xlsx'.format(save_fold_path, excel_name)\r\n        #\r\n        # CIP_List = []\r\n        # Subdomains_ips = {}\r\n        # notCDNSubdomains = []\r\n        # param_Links = []\r\n        # run_cSubnet(CIP_List, Subdomains_ips, notCDNSubdomains, param_Links)\r\n\r\n        alive_Web = ['']\r\n        detect_webVul(alive_Web)\r\n\r\n\r\n    elif getSocks == 1:\r\n        # 从fofa收集代理\r\n        getSocksProxy()\r\n\r\nif __name__ == '__main__':\r\n    _init()\r\n\r\n\r\n"
        },
        {
          "name": "__init__.py",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "build.sh",
          "type": "blob",
          "size": 0.33984375,
          "content": "#!/bin/bash\napt install python3 -y\napt install python3-pip --fix-missing -y\napt install python3-setuptools -y\napt install tmux -y\npython3 -m pip install --upgrade pip\npython3 -m pip install openpyxl==2.6.4\npython3 -m pip install Cython\npython3 -m pip install -r requirements.txt\nchmod 777 ./Plugins/infoGather/subdomain/ksubdomain/ksubdomain_linux\n"
        },
        {
          "name": "docker_build.sh",
          "type": "blob",
          "size": 0.1533203125,
          "content": "#!/bin/bash\napt install python3-setuptools -y\npython3 -m pip install -r requirements.txt\nchmod 777 ./Plugins/infoGather/subdomain/ksubdomain/ksubdomain_linux"
        },
        {
          "name": "imgs",
          "type": "tree",
          "content": null
        },
        {
          "name": "iniFile",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.626953125,
          "content": "openpyxl\naiodns\naiohttp\naiosqlite\naltgraph\nasync-timeout\nattrs\nbcrypt\nbeautifulsoup4\nbs4\ncertifi\ncffi\nchardet\nClick\nclick-plugins\ncloudscraper\ncolorama\ncryptography\nCython\ndnslib\ndnspython\nelasticsearch\net-xmlfile\nFlask\nFOFA\ngeoip2\ngevent\ngoogle\nidna\nIPy\nitsdangerous\njdcal\nJinja2\nkazoo\nldap3\nlxml\nmacholib\nMarkupSafe\nmaxminddb\nmultidict\nnetaddr\nopenpyxl\nparamiko\nplotly\npyasn1\npycares\npycparser\npycryptodome\nPyInstaller\npymongo\nPyMySQL\nPyNaCl\npyparsing\nPySocks\nPythonDNS\nredis\nrequests\nrequests-file\nrequests-toolbelt\nretrying\nscapy\nshodan\nsix\nsoupsieve\ntermcolor\ntexttable\ntldextract\nurllib3\nuvloop\nWerkzeug\nXlsxWriter\nxlwt\nyarl\nPyYAML\ntqdm"
        },
        {
          "name": "requirements2.txt",
          "type": "blob",
          "size": 1.138671875,
          "content": "openpyxl==2.6.4\naiodns==2.0.0\naiohttp==3.6.2\naiosqlite==0.13.0\naltgraph==0.16.1\nasync-timeout==3.0.1\nattrs==20.1.0\nbcrypt==3.1.7\nbeautifulsoup4==4.8.1\nbs4==0.0.1\ncertifi==2019.9.11\ncffi==1.13.1\nchardet==3.0.4\nClick==7.0\nclick-plugins==1.1.1\ncloudscraper==1.2.46\ncolorama==0.4.1\ncryptography==2.8\nCython==0.29.15\ndnslib==0.9.10\ndnspython==1.16.0\nelasticsearch==7.1.0\net-xmlfile==1.0.1\nFlask==1.1.1\nFOFA==1.0.1\ngeoip2==4.0.2\ngevent\ngoogle==2.0.3\nidna==2.8\nIPy==1.0\nitsdangerous==1.1.0\njdcal==1.4.1\nJinja2==2.11.1\nkazoo==2.6.1\nldap3==2.6.1\nlxml==4.5.1\nmacholib==1.11\nMarkupSafe==1.1.1\nmaxminddb==2.0.2\nmultidict==4.7.6\nnetaddr==0.7.19\nopenpyxl==2.6.4\nparamiko==2.7.1\nplotly==4.7.1\npyasn1==0.4.8\npycares==3.1.1\npycparser==2.19\npycryptodome==3.9.2\nPyInstaller==3.5\npymongo==3.2\nPyMySQL==0.9.3\nPyNaCl==1.3.0\npyparsing==2.4.7\nPySocks==1.7.1\nPythonDNS==0.1\nredis==3.3.11\nrequests==2.24.0\nrequests-file==1.4.3\nrequests-toolbelt==0.9.1\nretrying==1.3.3\nscapy==2.4.3\nshodan==1.7.5\nsix==1.13.0\nsoupsieve==1.9.5\ntermcolor==1.1.0\ntexttable==1.6.2\ntldextract==2.2.2\nurllib3==1.25.8\nuvloop==0.14.0\nWerkzeug==1.0.0\nXlsxWriter==1.2.5\nxlwt==1.3.0\nyarl==1.5.1\nPyYAML==5.3.1\ntqdm==4.51.0\n"
        },
        {
          "name": "versionFlag.txt",
          "type": "blob",
          "size": 0.990234375,
          "content": "2021.9.3 增加了confluence指纹\n2021.9.4 更新了爱企查获取目标架构信息，包含【备案信息、对外投资企业、控股公司、分支机构、联系方式、邮箱地址等信息】\n2021.9.5 增加了夸克的api接口：-d -c --fofaTitle中都会调用\n2021.11.30 增加了奇安信hunter的api接口：-d -c --fofaTitle中都会调用\n2022.1.17 修复了certspotter接口获取子域名过滤不严谨的问题\n2022.3.21 更新了fofa api的域名\n2022.3.21 更新了域名备案反查的问题\n2022.3.23 增加了securitytrails接口获取子域名，该接口很强大，建议在config.ini里添加你的api keys\n2022.3.23 修复了爱企查无法获取数据的问题\n2022.7.5 增加Nuclei默认参数配置-as,先进行wappalyzer指纹识别\n2022.8.12 ShuiZe增加Dockerfile安装方式\n2022.8.12 修复了大量反馈aiqicha脚本报错的问题，初步排查是被封IP的原因\n2022.8.12 修复了quakeApi没有title导致报错的情况\n2022.8.20 集成了ObserverWard扫描指纹"
        }
      ]
    }
  ]
}