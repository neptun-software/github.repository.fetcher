{
  "metadata": {
    "timestamp": 1736559454570,
    "page": 8,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/AugLy",
      "stars": 4981,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.47265625,
          "content": "# compilation and distribution\n__pycache__\n_ext\n*.pyc\n*.so\n\n# pytorch/python/numpy formats\n*.pth\n*.npy\n\n# ipython/jupyter notebooks\n**/.ipynb_checkpoints/\n\n# Editor temporaries\n*.swn\n*.swo\n*.swp\n*~\n\n# Pycharm editor settings\n.idea\n\n# project dirs\n/datasets\n/models\n/old_models\n\nslurm-*\nlog.txt\n\n# OSX-specific\n.DS_Store\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.8193359375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-20.04\n  apt_packages:\n    - libsndfile1\n    - ffmpeg\n  tools:\n    python: \"3.9\"\n    # You can also specify other tool versions:\n    # nodejs: \"16\"\n    # rust: \"1.55\"\n    # golang: \"1.17\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/source/conf.py\n\n# If using Sphinx, optionally build your docs in additional formats such as PDF\n# formats:\n#    - pdf\n\n# Optionally declare the Python requirements required to build your docs\npython:\n  install:\n    - requirements: requirements.txt\n    - requirements: av_requirements.txt\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.4521484375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\naddress, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\nprofessional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\nThis Code of Conduct also applies outside the project spaces when there is a\nreasonable belief that an individual's behavior may have a negative impact on\nthe project or its community.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 10.3212890625,
          "content": "# Contributing to AugLy\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Pull Requests\nWe actively welcome your pull requests.\n\n1. Fork the repo and create your branch from `main`.\n2. If you've added code that should be tested, add tests.\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. Make sure your code lints.\n6. Run `black` formatting.\n7. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n## Adding a New Augmentation\n\nBefore adding a new augmentation, please open an associated issue such that we could ensure that (a) this functionality doesn't already exist in the library (b) it is in line with the kinds of augmentations we'd like to support.\n\nPlease implement your new augmentation using AugLy's existing dependencies (i.e. `PIL`, `numpy`, `nlpaug`, `librosa`, etc.) if possible, and **avoid adding new dependencies** as these will make AugLy heavier and slower to download. However, if you feel it's necessary in order to implement your new augmentation and that the new augmentation is really worth having, it may be fine; in this case, add your new dependency to `requirements.txt`, and then make sure you can install `augly` in a fresh conda environment and the new unit tests pass.\n\nBefore submitting a PR with your new augmentation, please ensure that you have made all the necessary changes in the listed files below for the corresponding module where you're adding the augmentation. Whenever adding a new function, class, etc please make sure to insert it in **alphabetical order** in the file!\n\n### Audio\n- `augly/audio/functional.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/audio/functional.py#L929-L981) for `pitch_shift`)\n- `augly/audio/transforms.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/audio/transforms.py#L687-L716) for `pitch_shift`)\n- `augly/audio/intensity.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/audio/intensity.py#L142-L145) for `pitch_shift`)\n- `augly/audio/__init__.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/audio/__init__.py#L24) for `pitch_shift`)\n- `augly/tests/audio_tests/functional_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/audio_tests/functional_unit_test.py#L61-L62) for `pitch_shift`)\n- `augly/tests/audio_tests/transforms_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/audio_tests/transforms_unit_test.py#L125-L126) for `pitch_shift`)\n- `augly/utils/expected_output/audio/expected_metadata.json` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/utils/expected_output/audio_tests/expected_metadata.json#L515-L540) for `pitch_shift`)\n- `augly/assets/tests/audio/speech_commands_expected_output/{mono, stereo}/test_<aug_name>.wav` (e.g. [mono](https://github.com/facebookresearch/AugLy/blob/main/augly/assets/tests/audio/speech_commands_expected_output/mono/test_pitch_shift.wav) & [stereo](https://github.com/facebookresearch/AugLy/blob/main/augly/assets/tests/audio/speech_commands_expected_output/stereo/test_pitch_shift.wav) files for `pitch_shift`)\n  - These test files should be the result of running the new augmentation with the args as specified in the new unit tests. The two new unit tests should specify the same args for the new augmentation so they can use the same output file.\n\n### Image\n- `augly/image/functional.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/image/functional.py#L568-L638) for `crop`)\n- `augly/image/transforms.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/image/transforms.py#L666-L729) for `crop`)\n- `augly/image/intensity.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/image/intensity.py#L103-L104) for `crop`)\n- `augly/image/__init__.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/image/__init__.py#L19) for `crop`)\n- `augly/tests/image_tests/functional_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/image_tests/functional_unit_test.py#L44-L45) for `crop`)\n- `augly/tests/image_tests/transforms_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/image_tests/transforms_unit_test.py#L81-L82) for `crop`)\n- `augly/utils/expected_output/image/expected_metadata.json` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/utils/expected_output/image_tests/expected_metadata.json#L192-L209) for `crop`)\n- `augly/assets/tests/image/dfdc_expected_output/test_<aug_name>.png` (e.g. [test file](https://github.com/facebookresearch/AugLy/blob/main/augly/assets/tests/image/dfdc_expected_output/test_crop.png) for `crop`)\n  - This test file should be the result of running the new augmentation with the args as specified in the new unit tests. The two new unit tests should specify the same args for the new augmentation so they can use the same output file.\n- `augly/image/utils/bboxes.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/image/utils/bboxes.py#L16-L31) for `crop`)\n  - You should ensure that bounding boxes will be correctly transformed with the images for your new augmentation by either (1) adding a new helper function to `bboxes.py` which computes how a given bounding box will be changed by your augmentation (see the one for [`crop`](https://github.com/facebookresearch/AugLy/blob/main/augly/image/utils/bboxes.py#L16-L31) as an example); (2) using the `spatial_bbox_helper` if your augmentation is spatial and does not cause any color changes or overlay non-black content (see [`skew`](https://github.com/facebookresearch/AugLy/blob/main/augly/image/functional.py#L2430) call it as an example); or (3) doing nothing if your new augmentation does not move or occlude pixels at all from the original image content (e.g. [`color_jitter`](https://github.com/facebookresearch/AugLy/blob/main/augly/image/functional.py#L374) or [`sharpen`](https://github.com/facebookresearch/AugLy/blob/main/augly/image/functional.py#L2246)).\n\n### Text\n- `augly/text/functional.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/text/functional.py#L819-L867) for `split_words`)\n- `augly/text/transforms.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/text/transforms.py#L972-L1027) for `split_words`)\n- `augly/text/intensity.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/text/intensity.py#L103-L104) for `split_words`)\n- `augly/text/__init__.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/text/__init__.py#L25) for `split_words`)\n- `augly/tests/text_tests/functional_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/text_tests/functional_unit_test.py#L445-L463) for `split_words`)\n- `augly/tests/text_tests/transforms_unit_test.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/text_tests/transforms_unit_test.py#L324-L335) for `split_words`)\n- `augly/utils/expected_output/text/expected_metadata.json` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/utils/expected_output/text_tests/expected_metadata.json#L262-L276) for `split_words`)\n\n### Video\n- `augly/video/functional.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/functional.py#L1111-L1179) for `overlay`)\n- `augly/video/transforms.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/transforms.py#L1071-L1137) for `overlay`)\n- `augly/video/__init__.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/__init__.py#L31) for `overlay`)\n- `augly/video/helpers/intensity.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/helpers/intensity.py#L177-L193) for `overlay`)\n- `augly/video/helpers/__init__.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/helpers/__init__.py#L40) for `overlay`)\n- `augly/tests/video_tests/transforms/<aug_type>.py` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/tests/video_tests/transforms/ffmpeg_test.py#L96-L98) for `overlay`)\n  - Instead of `functional_unit_test.py` or `transforms_unit_test.py`, you should choose which test file to add the unit test for your new augmentation to based on which category it best fits in to. If the augmentation is implemented using `cv2` or `ffmpeg`, you should add the unit test to `cv2_test.py` or `ffmpeg_test.py` respectively. If the augmentation is implemented by applying a function to each frame of the video, you should add the unit test to `image_based_test.py`. If the augmentation is a combination of multiple video augmentations, you should add the unit test to `composite_test.py`.\n- `augly/utils/expected_output/image/expected_metadata.json` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/utils/expected_output/video_tests/expected_metadata.json#L691-L721) for `overlay`\n- You may also need to add an augmenter file in `augly/video/augmenters/` if your augmentation uses `cv2` or `ffmpeg` (e.g. [changes](https://github.com/facebookresearch/AugLy/blob/main/augly/video/augmenters/ffmpeg/overlay.py) for `overlay`)\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Facebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## Coding Style\n* 4 spaces for indentation rather than tabs\n* 90 character line length\n* 2 newlines before a function or class definition. For functions within classes, use a single newline\n* Add typing to your function parameters and add a return type\n* Add a newline after an if/else block\n\n## License\nBy contributing to AugLy, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.197265625,
          "content": "MIT License\n\nCopyright (c) Meta Platforms, Inc. and affiliates.\nAll rights reserved.\n\nThis source code is licensed under the license found in the\nLICENSE file in the root directory of this source tree.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.2255859375,
          "content": "include augly/assets/audio/*\ninclude augly/assets/fonts/*\ninclude augly/assets/masks/*\ninclude augly/assets/screenshot_templates/*\ninclude augly/assets/text/*\ninclude augly/assets/tests/*/inputs/*\ninclude augly/assets/twemojis/*/*\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.849609375,
          "content": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/facebookresearch/AugLy/main/logo.svg\" alt=\"logo\" width=\"70%\" />\n</p>\n\n<div align=\"center\">\n  <a href=\"https://github.com/facebookresearch/AugLy/actions\">\n    <img alt=\"Github Actions\" src=\"https://github.com/facebookresearch/AugLy/actions/workflows/test_python.yml/badge.svg\"/>\n  </a>\n  <a href=\"https://pypi.python.org/pypi/augly/\">\n    <img alt=\"PyPI downloads per month\" src=\"https://img.shields.io/pypi/dm/augly.svg\"/>\n  </a>\n  <a href=\"https://pypi.python.org/pypi/augly\">\n    <img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/augly\"/>\n  </a>\n  <a href=\"https://colab.research.google.com/github/facebookresearch/AugLy/blob/main/examples/AugLy_image.ipynb\">\n    <img alt=\"Image Colab notebook\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\n  </a>\n  <a href=\"https://doi.org/10.5281/zenodo.5014032\">\n    <img  alt=\"DOI\" src=\"https://zenodo.org/badge/DOI/10.5281/zenodo.5014032.svg\">\n  </a>\n  <a href=\"https://github.com/facebookresearch/AugLy/blob/main/CONTRIBUTING.md\">\n    <img alt=\"PRs Welcome\" src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg\"/>\n  </a>\n</div>\n\n----------------------\n\nAugLy is a data augmentations library that currently supports four modalities ([audio](augly/audio), [image](augly/image), [text](augly/text) & [video](augly/video)) and over 100 augmentations. Each modality’s augmentations are contained within its own sub-library. These sub-libraries include both function-based and class-based transforms, composition operators, and have the option to provide metadata about the transform applied, including its intensity.\n\nAugLy is a great library to utilize for augmenting your data in model training, or to evaluate the robustness gaps of your model! We designed AugLy to include many specific data augmentations that users perform in real life on internet platforms like Facebook's -- for example making an image into a meme, overlaying text/emojis on images/videos, reposting a screenshot from social media. While AugLy contains more generic data augmentations as well, it will be particularly useful to you if you're working on a problem like copy detection, hate speech detection, or copyright infringement where these \"internet user\" types of data augmentations are prevalent.\n\n![Visual](https://raw.githubusercontent.com/facebookresearch/AugLy/main/image_visual.png)\n\nTo see more examples of augmentations, open the Colab notebooks in the README for each modality! (e.g. image [README](augly/image) & [Colab](https://colab.research.google.com/github/facebookresearch/AugLy/blob/main/examples/AugLy_image.ipynb))\n\nThe library is Python-based and requires at least Python 3.6, as we use dataclasses.\n\n## Authors\n\n[**Joanna Bitton**](https://www.linkedin.com/in/joanna-bitton/) — Software Engineer at Meta AI\n\n[**Zoe Papakipos**](https://www.linkedin.com/in/zoe-papakipos-8637155b/) — Software Engineer at Meta AI\n\n## Installation\n\n`AugLy` is a Python 3.6+ library. It can be installed with:\n\n```bash\npip install augly[all]\n```\n\nIf you want to only install the dependencies needed for one sub-library e.g. audio, you can install like so:\n\n```bash\npip install augly[audio]\n```\n\nOr clone AugLy if you want to be able to run our unit tests, contribute a pull request, etc:\n```bash\ngit clone git@github.com:facebookresearch/AugLy.git && cd AugLy\n[Optional, but recommended] conda create -n augly && conda activate augly && conda install pip\npip install -e .[all]\n```\n\n**Backwards compatibility note**: In versions `augly<=0.2.1` we did not separate the dependencies by modality. For those versions to install most dependencies you could use `pip install augly`, and if you want to use the audio or video modalities you would install with `pip install augly[av]`.\n\nIn some environments, `pip` doesn't install `python-magic` as expected. In that case, you will need to additionally run:\n```bash\nconda install -c conda-forge python-magic\n```\n\nOr if you aren't using conda:\n```bash\nsudo apt-get install python3-magic\n```\n\n## Documentation\n\nCheck out our [documentation](https://augly.readthedocs.io/en/latest/) on ReadtheDocs!\n\nFor more details about how to use each sub-library, how to run the tests, and links to colab notebooks with runnable examples, please see the READMEs in each respective directory ([audio](augly/audio/), [image](augly/image/), [text](augly/text/), & [video](augly/video/)).\n\n## Assets\n\nWe provide various media assets to use with some of our augmentations. These assets include:\n1. [Emojis](augly/assets/twemojis/) ([Twemoji](https://twemoji.twitter.com/)) - Copyright 2020 Twitter, Inc and other contributors. Code licensed under the MIT License. Graphics licensed under CC-BY 4.0.\n2. [Fonts](augly/assets/fonts/) ([Noto fonts](https://www.google.com/get/noto/)) - Noto is a trademark of Google Inc. Noto fonts are open source. All Noto fonts are published under the SIL Open Font License, Version 1.1.\n3. [Screenshot Templates](augly/assets/screenshot_templates/) - Images created by a designer at Facebook specifically to use with AugLy. You can use these with the `overlay_onto_screenshot` augmentation in both the image and video libraries to make it look like your source image/video was screenshotted in a social media feed similar to Facebook or Instagram.\n\n## Links\n\n1. Facebook AI blog post: https://ai.facebook.com/blog/augly-a-new-data-augmentation-library-to-help-build-more-robust-ai-models/\n2. PyPi package: https://pypi.org/project/augly/\n3. Arxiv paper: https://arxiv.org/abs/2201.06494\n4. Examples: https://github.com/facebookresearch/AugLy/tree/main/examples\n\n## Uses of AugLy in the wild\n1. [Image Similarity Challenge](https://ai.facebook.com/blog/the-image-similarity-challenge-and-data-set-for-detecting-image-manipulation) - a NeurIPS 2021 competition run by Facebook AI with $200k in prizes, currently open for sign ups; also produced the DISC21 dataset, which will be made publicly available after the challenge concludes!\n2. [DeepFake Detection Challenge](https://ai.facebook.com/datasets/dfdc/) - a Kaggle competition run by Facebook AI in 2020 with $1 million in prizes; also produced the [DFDC dataset](https://dfdc.ai)\n3. [SimSearchNet](https://ai.facebook.com/blog/using-ai-to-detect-covid-19-misinformation-and-exploitative-content/) - a near-duplicate detection model developed at Facebook AI to identify infringing content on our platforms\n\n## Citation\n\nIf you use AugLy in your work, please cite our [Arxiv paper](https://arxiv.org/abs/2201.06494) using the citation below:\n\n```bibtex\n@misc{papakipos2022augly,\n  author        = {Zoe Papakipos and Joanna Bitton},\n  title         = {AugLy: Data Augmentations for Robustness},\n  year          = {2022},\n  eprint        = {2201.06494},\n  archivePrefix = {arXiv},\n  primaryClass  = {cs.AI}}\n}\n```\n\n## License\n\nAugLy is MIT licensed, as found in the [LICENSE](LICENSE) file. Please note that some of the dependencies AugLy uses may be licensed under different terms.\n"
        },
        {
          "name": "augly",
          "type": "tree",
          "content": null
        },
        {
          "name": "browser-extension.json",
          "type": "blob",
          "size": 0.0966796875,
          "content": "{\n  \"allowDirectMerges\": false,\n  \"allowBotCommands\": false,\n  \"internalRepository\": \"fbsource\"\n}\n\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "image_visual.png",
          "type": "blob",
          "size": 869.943359375,
          "content": null
        },
        {
          "name": "logo.svg",
          "type": "blob",
          "size": 3.671875,
          "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 395.49 200.65\"><defs><style>.cls-1{fill:#19646e;}.cls-2{fill:#199696;}.cls-3{fill:#5cb8b8;}</style></defs><g id=\"Layer_2\" data-name=\"Layer 2\"><path class=\"cls-1\" d=\"M180,127.08q2.09-7.24,4.78-15t5.7-15.25q3-7.53,6.1-14.27h8.58q3.11,6.74,6.13,14.27t5.7,15.25q2.69,7.72,4.75,15H214.1q-1.28-5-3-10.34t-3.61-10.83q-1.92-5.44-4-10.66t-4.07-9.82h2.58q-2,4.6-4.07,9.82t-4,10.66q-1.92,5.45-3.6,10.83t-3,10.34Zm8.35-12V109.1h25.07V115Z\"/><path class=\"cls-1\" d=\"M236,127.84h-.73q-5.47,0-8.34-3.66t-2.88-10.38V95.22h6.74V113c0,3,.52,5.31,1.57,6.86a5.4,5.4,0,0,0,4.81,2.32h.67a7.73,7.73,0,0,0,6-2.72,13.71,13.71,0,0,0,3.19-6.75h2.38a25.55,25.55,0,0,1-2.41,8,13.77,13.77,0,0,1-4.5,5.29A11.21,11.21,0,0,1,236,127.84Zm10.42-.76v-8.83l-.1-1.46V95.22h6.74v31.86Z\"/><path class=\"cls-1\" d=\"M272,127.21h-.73a12.76,12.76,0,0,1-7.24-2.07,13.66,13.66,0,0,1-4.86-5.76,21.86,21.86,0,0,1,0-17.14,13.69,13.69,0,0,1,4.86-5.75,12.76,12.76,0,0,1,7.24-2.07H272a12,12,0,0,1,10.63,6,17.29,17.29,0,0,1,2.21,7.33h-2.26a11.61,11.61,0,0,0-3.38-5.56,8.1,8.1,0,0,0-5.55-2.1h-.6a7.78,7.78,0,0,0-6.31,2.8q-2.32,2.79-2.33,7.91c0,3.41.78,6,2.33,7.91a7.8,7.8,0,0,0,6.31,2.79h.6a8.07,8.07,0,0,0,5.53-2.08,11.73,11.73,0,0,0,3.4-5.57h2c-.42,4.34-1.8,7.65-4.11,9.92A11.61,11.61,0,0,1,272,127.21Zm1.21,14h-.73a17.59,17.59,0,0,1-7.72-1.67,14.42,14.42,0,0,1-5.66-4.81l4.55-3.72a10.28,10.28,0,0,0,3.68,3.41,10.74,10.74,0,0,0,5.18,1.16q4.54,0,7-2.59c1.64-1.72,2.47-4.36,2.47-7.92V103.16l.12-1.33V95.34h6.48v29.07a19.92,19.92,0,0,1-2,9.41,12.86,12.86,0,0,1-5.43,5.54A16.79,16.79,0,0,1,273.24,141.19Z\"/><path class=\"cls-1\" d=\"M294.39,127.08V82.6h7.21v41.08L298.55,121H325v6.13Z\"/><path class=\"cls-1\" d=\"M335.16,129.15q-3.92-8.18-7.41-16.71t-6.6-17.22h7.59q2.28,7.62,5.07,15.29t5.95,15.21Zm-8.45,12a15,15,0,0,1-2.83-.26v-5.46l1,.11c.35,0,.7,0,1.07,0a8.25,8.25,0,0,0,4.54-1.19,10.06,10.06,0,0,0,3.18-3.5,35.54,35.54,0,0,0,2.51-5.57l.92-1.5,9.4-28.65h7.21L341.51,128.1a27.13,27.13,0,0,1-5.73,9.69A12.26,12.26,0,0,1,326.71,141.19Z\"/><path class=\"cls-1\" d=\"M155.87,97.76H45.28a3.29,3.29,0,0,1,0-6.58H155.87a3.29,3.29,0,1,1,0,6.58Z\"/><path class=\"cls-2\" d=\"M117.27,47.5c-9.36,0-10.15,8.51-16.69,8.51-6.35,0-7.33-8.51-16.7-8.51-5.86,0-19.74.81-28.54,46.89h90.47C137,48.31,123.13,47.5,117.27,47.5Z\"/><path class=\"cls-1\" d=\"M149.78,97.68H51.37l.74-3.9c9.46-49.57,25.67-49.57,31.77-49.57,6.48,0,9.91,3.36,12.42,5.81,1.81,1.78,2.82,2.7,4.28,2.7S103.1,51.83,105,50c2.47-2.43,5.85-5.77,12.3-5.77,6.1,0,22.31,0,31.77,49.57ZM59.35,91.11H141.8c-8.42-40.32-20.49-40.32-24.53-40.32-3.75,0-5.48,1.71-7.67,3.87s-4.7,4.64-9,4.64-6.8-2.54-8.88-4.58c-2.25-2.2-4-3.93-7.82-3.93C79.84,50.79,67.77,50.79,59.35,91.11Z\"/><rect class=\"cls-1\" x=\"88.98\" y=\"128.72\" width=\"20.11\" height=\"6.58\"/><circle class=\"cls-2\" cx=\"131.77\" cy=\"129.93\" r=\"22.12\"/><path class=\"cls-1\" d=\"M131.77,155.33a25.41,25.41,0,1,1,25.4-25.4A25.44,25.44,0,0,1,131.77,155.33Zm0-44.23a18.83,18.83,0,1,0,18.83,18.83A18.85,18.85,0,0,0,131.77,111.1Z\"/><circle class=\"cls-2\" cx=\"69.38\" cy=\"129.93\" r=\"22.12\"/><path class=\"cls-1\" d=\"M69.38,155.33a25.41,25.41,0,1,1,25.41-25.4A25.43,25.43,0,0,1,69.38,155.33Zm0-44.23a18.83,18.83,0,1,0,18.83,18.83A18.85,18.85,0,0,0,69.38,111.1Z\"/><path class=\"cls-3\" d=\"M69.5,148.88a18.79,18.79,0,0,0,15-30.17c-7.08,7.54-18,19.15-25.65,26.86A18.7,18.7,0,0,0,69.5,148.88Z\"/><path class=\"cls-3\" d=\"M131.72,148.73a18.79,18.79,0,0,0,15-30.16c-7.08,7.54-18,19.14-25.63,26.85A18.74,18.74,0,0,0,131.72,148.73Z\"/><path class=\"cls-2\" d=\"M66.09,139.83a3.29,3.29,0,0,0,6.58,0v-6.49h6.48a3.29,3.29,0,1,0,0-6.57H76.89c-3.5,3.7-7.25,7.64-10.8,11.34Z\"/><path class=\"cls-1\" d=\"M66.09,138.11c3.56-3.7,7.31-7.64,10.81-11.34H72.67v-6.49a3.29,3.29,0,1,0-6.58,0v6.49H59.61a3.29,3.29,0,1,0,0,6.57h6.48Z\"/></g></svg>"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.091796875,
          "content": "dataclasses-json>=0.5.2\niopath>=0.1.8\npython-magic>=0.4.22\nregex>=2021.4.4\nsetuptools>=65.5.1\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.6435546875,
          "content": "#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nfrom pathlib import Path\n\nimport setuptools\n\n\nrequirements = [\n    r for r in Path(\"requirements.txt\").read_text().splitlines() if \"@\" not in r\n]\n\nextra_requirements = {\n    module: [\n        r\n        for r in Path(os.path.join(\"augly\", module, \"requirements.txt\"))\n        .read_text()\n        .splitlines()\n        if \"@\" not in r\n    ]\n    for module in [\"audio\", \"image\", \"text\", \"video\"]\n}\n\nextra_requirements[\"video\"].extend(\n    extra_requirements[\"audio\"] + extra_requirements[\"image\"]\n)\nextra_requirements[\"all\"] = list(\n    {r for reqs in extra_requirements.values() for r in reqs}\n)\n\nwith open(\"README.md\", encoding=\"utf8\") as f:\n    readme = f.read()\n\nwith open(\"version.txt\", \"r\") as f:\n    version = f.read().strip()\n\n\nsetuptools.setup(\n    name=\"augly\",\n    version=version,\n    description=\"A data augmentations library for audio, image, text, & video.\",\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/facebookresearch/AugLy\",\n    author=\"Zoe Papakipos and Joanna Bitton\",\n    author_email=\"zoep@fb.com\",\n    packages=setuptools.find_packages(exclude=[\"augly.tests\"]),\n    include_package_data=True,\n    install_requires=requirements,\n    extras_require=extra_requirements,\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    python_requires=\">=3.6\",\n)\n"
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.005859375,
          "content": "1.0.0\n"
        }
      ]
    }
  ]
}