{
  "metadata": {
    "timestamp": 1736559693254,
    "page": 373,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "CrazyBoyM/llama3-Chinese-chat",
      "stars": 4105,
      "defaultBranch": "main",
      "files": [
        {
          "name": "README.md",
          "type": "blob",
          "size": 39.5048828125,
          "content": "# llama3-Chinese-chat\n\n[![HF Demo](https://img.shields.io/static/v1?label=Demo&message=OpenBayes%E8%B4%9D%E5%BC%8F%E8%AE%A1%E7%AE%97&color=green)](https://openbayes.com/console/hyperai-tutorials/containers/EzsoQaZB8LA)  &ensp;\n\nfirst version of llama3 in Chinese (é¦–ä¸ªllama3 ä¸­æ–‡ç‰ˆ)  ï¼Œæœ¬ä»“åº“ä¾›äº¤æµllama3ä¸­æ–‡ç›¸å…³å­¦ä¹ å†…å®¹ï¼Œæ¬¢è¿ä»»ä½•äººåŠ å…¥å…±å»ºPR  \n\nğŸ”¥æ–°å¢LLM-Chineseä»“åº“ï¼Œæ¬¢è¿å…³æ³¨ï¼Œåæ•™ç¨‹æ€§è´¨ï¼Œä»¥ã€Œæ¨¡å‹ä¸­æ–‡åŒ–ã€ä¸ºä¸€ä¸ªå…¸å‹çš„æ¨¡å‹è®­ç»ƒé—®é¢˜åˆ‡å…¥åœºæ™¯ï¼ŒæŒ‡å¯¼è¯»è€…ä¸Šæ‰‹å­¦ä¹ LLMäºŒæ¬¡å¾®è°ƒè®­ç»ƒï¼šhttps://github.com/CrazyBoyM/LLM-Chinese ï¼ˆå«gemma2 ä¸­æ–‡ç‰ˆæ¨¡å‹ï¼Œ2bã€ 9bå°ºå¯¸ï¼‰\n\nå¦‚æœä½ æœ‰è‡ªå·±å¾®è°ƒçš„ç‰ˆæœ¬æˆ–è€…åœ¨ç½‘ä¸Šå‘ç°æœ‰è¶£çš„ç‰¹åŒ–ç‰ˆæœ¬ï¼Œæ¬¢è¿åœ¨issueåŒºè¯„è®ºæ”¶å½•ã€‚  \nå¦‚æœ‰ä½ æœ‰æƒ³è¦å»ºè®¾çš„å†…å®¹ç‰ˆå—ï¼Œæ¬¢è¿forkæäº¤PRæˆä¸ºæ ¸å¿ƒä½œè€…æˆå‘˜ã€‚  \n(æ³¨æ„ï¼šç›®å‰ä¸å†æ¥å—ä»…ä¿®æ”¹å•ä¸ªå­—ã€å¥çš„typo-PRï¼Œè¯·é¿å…é¢‘ç¹æäº¤è¯¥ç±»PR)\n\n### News æ›´æ–°è®°å½•\n- 2024-07-25 llama3.1 ä¸­æ–‡DPOç‰ˆè®­ç»ƒæƒé‡æ”¾å‡ºã€‚\n- 2024-07-24 llama3.1 ä¸­æ–‡ç‰ˆè®­ç»ƒè®¡åˆ’å¯åŠ¨ã€‚\n- 2024-05-17 ğŸ‰ æ•´ç†çš„llama3ä¸­æ–‡åŒ–æ•°æ®é›†åˆåœ¨modelscopeä¸‹è½½é‡è¾¾2.9kæ¬¡ï¼Œè¿ç»­ä¸‰å‘¨å¤„äºmodelscopeç½‘ç«™é¦–é¡µï¼š[æ•°æ®ä¸‹è½½åœ°å€](https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary) \n- 2024-05-17 ğŸ’ª å¢åŠ  æ‰‹å†™APIéƒ¨ç½²æ•™ç¨‹ã€å‘½ä»¤è°ƒç”¨ï¼Œ[æ–‡æ¡£åœ°å€](https://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/API)\n- 2024-05-13 ğŸ’ª å¢åŠ LMStudioç”µè„‘æœ¬åœ°éƒ¨ç½²æ•™ç¨‹ï¼Œ[æ–‡æ¡£æ•™ç¨‹](https://github.com/CrazyBoyM/llama3-Chinese-chat/blob/main/deploy/LMStudio/README.md)ï¼Œ[æ‰‹æŠŠæ‰‹è§†é¢‘æ•™ç¨‹](https://www.bilibili.com/video/BV1nt421g79T)\n- 2024-05-04 äº”ä¸€å‡æœŸé—´ï¼šğŸš€ æ–°å¢è¯­è¨€åå¥½å¼ºåŒ–å¯¹é½ç‰ˆæœ¬ï¼ˆç›´æ¥å¯¹è‹±æ–‡instructç‰ˆåšDPOï¼‰ã€‚ä¿æŒåŸæ±åŸå‘³çš„å£å»å›å¤(å–œæ¬¢è¶£å‘³è¯­è¨€ã€emojiè¡¨æƒ…)ï¼Œ[æ¨¡å‹ä¸‹è½½](https://modelscope.cn/models/baicai003/Llama3-Chinese-instruct-DPO-beta0.5/summary)ï¼Œ[ggufé‡åŒ–ç‰ˆä¸‹è½½](https://modelscope.cn/models/shareAI/llama-3-8b-Instruct-dpo-chinese-loftq-gguf/summary)ï¼Œ[è¯­è¨€åå¥½å¼ºåŒ–æ•°æ®é›†å·¥ä½œå·²å¼€æº](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)\n- 2024-04-21 æ™šä¸Š2ç‚¹ï¼šå¢åŠ è®­ç»ƒæ•™ç¨‹ã€æ¨ç†æ•™ç¨‹ã€ç½‘é¡µéƒ¨ç½²ç­‰æ–‡æ¡£æ•´ç†\n- 2023-04-20 æ™šä¸Š23ç‚¹ï¼šinstruct ä¸­æ–‡ç‰ˆè®­ç»ƒå®Œæˆ\n- 2024-04-20 æ—©ä¸Š7ç‚¹ï¼šv2ç‰ˆè®­ç»ƒå®Œæˆ \n- 2024-04-19 ä¸‹åˆ1ç‚¹ï¼šğŸº ä¸–ç•Œä¸Šé¦–ä¸ªllama3 ä¸­æ–‡ç‰ˆè®­ç»ƒå®Œæˆï¼Œæ™šä¸Šæ²¡ç¡è§‰å“ˆå“ˆï¼Œä½¿ç”¨170k+é«˜è´¨é‡å¤šè½®ä¸­æ–‡å¯¹è¯æ•°æ®è¿å¤œè®­ç»ƒå¾—åˆ°ã€‚\n\n### Demo æ¼”ç¤ºç¤ºä¾‹\n#### llama3-base-8b ä¸­æ–‡SFTç‰ˆ\n<img width=\"1000\" src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/4057d600-11e6-424f-9705-267450b6f635\">\n\n#### llama3-instruct-8b ä¸­æ–‡DPOç‰ˆ\n<img width=\"1000\" src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/0330a118-7a38-44a7-8a48-a94bfb9eead2\">\n\n#### llama3.1-instruct-8b ä¸­æ–‡DPOç‰ˆ\n<img width=\"1000\" alt=\"image\" src=\"https://github.com/user-attachments/assets/7140ee4b-d2d5-42f6-976b-9379ec6a9811\">\n\n### llama3 å¯ç”¨Chatç‰ˆæ¨¡å‹æ•´ç†\nllama3.1\n- shareAI-DPOä¸­æ–‡ 8Bç‰ˆæœ¬ ï¼ˆRLHFä¸­æ–‡ï¼‰\n  - è®­ç»ƒæ•°æ®å¼€æºï¼š https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji\n  - è®­ç»ƒç»†èŠ‚åˆ†äº«ï¼šDPO(beta 0.5) + lora rank128, alpha256 + æ‰“å¼€\"lm_head\", \"input_layernorm\", \"post_attention_layernorm\", \"norm\"å±‚è®­ç»ƒ.\n  - ç®—åŠ›ï¼š8 * A100ï¼Œ5åˆ†é’Ÿï¼Œæ„Ÿè°¢opencsgç¤¾åŒºçš„å‹æƒ…èµåŠ©æ”¯æŒã€‚  \n  - æ¨¡å‹ä¸‹è½½ - OpenCSGï¼š https://opencsg.com/models/shareAI/llama3.1-8b-instruct-dpo-zh  \n  - æ¨¡å‹ä¸‹è½½ - modelscopeï¼š https://modelscope.cn/models/shareAI/llama3.1-8b-instruct-dpo-zh  \n  - æ¨¡å‹ä¸‹è½½ - Huggingfaceï¼š https://huggingface.co/shareAI/llama3.1-8b-instruct-dpo-zh\n  - GGUFç‰ˆæœ¬ä¸‹è½½ ï¼ˆollamaã€lmstudioå¯ç”¨ï¼‰ï¼šhttps://huggingface.co/shareAI/llama3.1-8b-instruct-dpo-zh/blob/main/llama3.1_8b_chinese_chat_q4_k_m-shareAI.gguf\n  - GGUFç‰ˆæœ¬å›½å†…ä¸‹è½½ ï¼ˆhf-mirror å›½å†…åŠ é€Ÿç«™ç‚¹ï¼‰ï¼šhttps://hf-mirror.com/shareAI/llama3.1-8b-instruct-dpo-zh\n  - ollamaå‘½ä»¤ç›´æ¥è¿è¡Œï¼š`ollama run shareai/llama3.1-dpo-zh `\n- openCSG wukongä¸­æ–‡ 405Bç‰ˆæœ¬ (SFTä¸­æ–‡ï¼‰\n  - shareAI & openCSGè”åˆå‘å¸ƒ\n  - ä»‹ç»æ–‡ç« ï¼šhttps://mp.weixin.qq.com/s/7_lDZ6Zslq_WUckfuTToyQ\n  - æ¨¡å‹å¼€æºï¼šhttps://opencsg.com/models/OpenCSG/CSG-Wukong-Chinese-Llama3.1-405B\n- openbuddy\n  - openbuddy-llama3.1-8bï¼ˆSFTä¸­æ–‡ï¼‰ï¼šhttps://modelscope.cn/models/OpenBuddy/openbuddy-llama3.1-8b-v22.1-131k\n\nllama3ç›¸å…³å¯¹è¯ç‰ˆæœ¬ä¼˜è´¨æƒé‡æ•´ç†ï¼šï¼ˆæ¬¢è¿issueè¡¥å……ï¼‰\n- shareAIç³»åˆ—ï¼š\n  - baseé¢„è®­ç»ƒ + ç›´æ¥ä¸­æ–‡SFTç‰ˆ:\n     - è®­ç»ƒæ•°æ®ï¼šhttps://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary \n     - V1ç‰ˆ\n        - OpenCSGæ»¡é€Ÿä¸‹è½½ï¼šhttps://opencsg.com/models/shareAI/llama3-Chinese-chat-8b\n        - WiseModelæ»¡é€Ÿä¸‹è½½ï¼šhttps://wisemodel.cn/models/shareAI/llama3-Chinese-chat-8b\n     - V2ç‰ˆ\n        - modelscopeï¼šhttps://modelscope.cn/models/baicai003/Llama3-Chinese_v2/summary\n        - æ€ç»´å¯¼å›¾ç”Ÿæˆèƒ½åŠ›å¼ºåŒ–LoRAï¼šhttps://modelscope.cn/models/shareAI/llama3-instruct-8b-cn-doc2markmap-lora\n  - Instruct + ç»§ç»­ä¸­æ–‡SFTç‰ˆï¼š\n    - modelscopeæ¨¡å‹ä¸‹è½½ï¼šhttps://modelscope.cn/models/baicai003/llama-3-8b-Instruct-chinese_v2/summary\n    - äº‘æœåŠ¡å™¨é•œåƒåœ¨çº¿ä½“éªŒï¼ˆç‚¹å‡»å³ç”¨ï¼Œå…è´¹ 4 å°æ—¶ï¼‰ï¼šhttps://www.suanyun.cn/console/share?uuid=b1ba51908f8a4bd1af37148765c293ee\n  - Instruct + å¼ºåŒ–å­¦ä¹ ä¸­æ–‡ç‰ˆï¼š\n    - llama3 instruct DPOç‰ˆ ï¼ˆ10åˆ†é’Ÿå·¦å³å¯è®­ç»ƒå¥½ï¼Œå¯¹åŸå¤šè¯­è¨€instructç‰ˆæœ€å°åŒ–æ€§èƒ½æŸä¼¤ï¼Œå®æµ‹è¶…è¿‡å¤§å¤šä¸­æ–‡å¤§é‡è®­ç»ƒç‰ˆï¼‰\n      - modelscopeä¸‹è½½ï¼šhttps://modelscope.cn/models/baicai003/Llama3-Chinese-instruct-DPO-beta0.5/summary\n      - åå¥½å­¦ä¹ æ•°æ®é›†ï¼š[DPO-zh-en-emoji](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)\n\n  - Baseé¢„è®­ç»ƒ + æµ·é‡ä¸­æ–‡ä¼˜è´¨æ•°æ®å¢é‡é¢„è®­ç»ƒï¼šæ­£åœ¨è¿›è¡Œä¸­ \n  - 70b ä¸­æ–‡ç‰ˆï¼šè®¡åˆ’ä¸­\n-  by zhuangxialieï¼Œå› å¯¹è¯æ¨¡ç‰ˆè®¾ç½®é”™è¯¯ï¼Œéœ€è¦ç”¨[fastchat](https://github.com/lm-sys/FastChat)ä½“éªŒï¼š\n    - Base + ä¸­æ–‡SFTï¼šhttps://modelscope.cn/models/zhuangxialie/Llama3_Chinese_Sft/files\n    - Base + ORPOï¼šhttps://modelscope.cn/models/zhuangxialie/Llama3-Chinese-ORPO/summary \n    - Instruct + DPOï¼šhttps://www.modelscope.cn/models/zhuangxialie/Llama3-Chinese-DPO/summary\n- llama3 Proï¼ˆåŠ blockç‰ˆï¼Œæ¨èç½‘å‹ç§¯æåœ¨è¯¥æ–¹æ¡ˆä¸Šåšæ›´å¤šå°è¯•ã€æ¢ç´¢ï¼‰ï¼š\n  - linjh1118ç½‘å‹ï¼ˆç¬¬ä¸€ä¸ªORPOåå¥½å¯¹é½ + æ‰©å±•2*blocksï¼‰ï¼šhttps://github.com/linjh1118/Llama3-Chinese-ORPO\n- llama3 Moeå¢å¼ºç‰ˆï¼š\n  - cooper12121-llama3-8x8b-MoEï¼šhttps://github.com/cooper12121/llama3-8x8b-MoE\n- é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼š\n  - è”é€šå¾®è°ƒç‰ˆv2 (ä¸­æ–‡ï¼Œ28kä¸Šä¸‹æ–‡ï¼‰ï¼šhttps://huggingface.co/UnicomLLM/Unichat-llama3-Chinese-8B-28K\n  - 262kä¸Šä¸‹æ–‡ï¼ˆè‹±æ–‡ï¼‰ï¼šhttps://huggingface.co/gradientai/Llama-3-8B-Instruct-262k\n  - 262kä¸Šä¸‹æ–‡ï¼ˆä¸­æ–‡ï¼‰ï¼šè®¡åˆ’ä¸­\n  - æ— é™ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼šè®¡åˆ’ä¸­ï¼Œå‚è€ƒï¼šhttps://medium.com/neoxia/llm-infini-attention-with-linear-complexity-3209b87a77c3\n- å…¶ä»–æ™®é€šä¸­æ–‡å¾®è°ƒç‰ˆæœ¬ï¼š\n  - ä¸­å…´å¾®è°ƒç‰ˆï¼ˆDPOï¼‰ - 70Bï¼šhttps://www.modelscope.cn/models/ZTEAIM2024/Llama3_70B_instruct_chinese/summary\n  - è”é€šå¾®è°ƒç‰ˆï¼ˆSFTï¼‰ï¼šhttps://www.modelscope.cn/models/UnicomAI/Unichat-llama3-Chinese/summary\n  - Openbuddyå¾®è°ƒç‰ˆï¼ˆSFTï¼Œæ®è¯´ä¸é”™ï¼‰ï¼šhttps://www.modelscope.cn/models/OpenBuddy/openbuddy-llama3-8b-v21.1-8k/summary\n  - zhichenå¾®è°ƒç‰ˆï¼ˆORPOæ–¹æ³•ï¼Œåº”è¯¥æ˜¯ç¬¬ä¸€ä¸ªorpoï¼‰ï¼šhttps://github.com/seanzhang-zhichen/llama3-chinese\n  - shenzhi-wangå¾®è°ƒç‰ˆï¼ˆORPOæ–¹æ³•ï¼Œä¹Ÿè¯´æ˜¯ç¬¬ä¸€ä¸ªorpoï¼‰ï¼šhttps://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat\n  - Rookieå¾®è°ƒç‰ˆï¼ˆSFTï¼‰ï¼šhttps://github.com/Rookie1019/Llama-3-8B-Instruct-Chinese\n  - hit-sz klc-lab å¾®è°ƒç‰ˆï¼š[https://github.com/zyg18181818/Llama-3-Chinese](https://github.com/zyg18181818/Llama-3-Chinese)\n- ç ´è§£å®‰å…¨é™åˆ¶ç³»åˆ—ï¼ˆnsfwï¼‰ï¼š\n  - Unholyï¼šhttps://huggingface.co/Undi95/Llama-3-Unholy-8B\n  - neural-chatï¼šhttps://hf-mirror.com/Locutusque/llama-3-neural-chat-v1-8b\n  - dolphinï¼šhttps://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b\n  - Orion: https://huggingface.co/Orion-zhen/Llama3-70B-Orion-Chinese ç ´é™+ä¸­æ–‡, å¹¶ä¿ç•™äº†åŸç‰ˆllama3å–œæ¬¢emojiçš„ä¹ æƒ¯\n- v-llama3 å¤šæ¨¡æ€ç‰ˆï¼šï¼ˆæ”¯æŒæ–‡å­—ä»¥å¤–çš„è¾“å…¥ã€è¾“å‡ºï¼‰\n  - å›¾åƒé—®ç­”ï¼š\n    - Bunny-Llama-3-8B-Vï¼šhttps://wisemodel.cn/models/BAAI/Bunny-Llama-3-8B-V\n    - llava-llama-3-8bï¼šhttps://huggingface.co/xtuner/llava-llama-3-8b-v1_1\n  - è§†é¢‘ç†è§£ï¼ˆå¯æ”¯æŒ 1 åˆ†é’Ÿå†…è§†é¢‘é—®ç­”ï¼‰ï¼šhttps://github.com/THUDM/CogVLM2  \n- agentå·¥å…·èƒ½åŠ›å¢å¼ºç‰ˆï¼š\n  - ModelScope Chinese Agentç‰ˆV1ï¼ˆå¯æ ¹æ®è¦æ±‚å¸®ä½ é€‰æ‹©å·¥å…·ï¼Œä¸­æ–‡å¯¹è¯ï¼‰ï¼šhttps://modelscope.cn/models/swift/Llama3-Chinese-8B-Instruct-Agent-v1/summary\n- EmoLLM å¿ƒç†é¢†åŸŸæ•°æ®å¾®è°ƒç‰ˆï¼š\n  - åœ¨çº¿ä½“éªŒé“¾æ¥ï¼šhttps://st-app-center-006861-9746-jlroxvg.openxlab.space/\n  - æˆ–å‰å¾€[OpenXLab EmoLLM3.0-Llama3](https://openxlab.org.cn/apps/detail/chg0901/EmoLLM-Llama3-8B-Instruct3.0)å¯åŠ¨\n  - æ¨¡å‹ä¸‹è½½åœ°å€\n    - OpenXLabï¼š https://openxlab.org.cn/models/detail/chg0901/EmoLLM-Llama3-8B-Instruct3.0\n    - ModelScopeï¼š https://modelscope.cn/models/chg0901/EmoLLM-Llama3-8B-Instruct3.0/summary\n\n- å°è¯´ã€ç½‘æ–‡ã€æ•…äº‹æ’°å†™ä»»åŠ¡å¢å¼ºç‰ˆï¼šè®¡åˆ’ä¸­\n- éŸ³ä¹ç”Ÿæˆä»»åŠ¡ç‰ˆï¼šè®¡åˆ’ä¸­\n- çŒ«å¨˜æ‰®æ¼”ç‰ˆï¼šè®¡åˆ’ä¸­\n- æ¶©æ¶©ç‰ˆï¼šè®¡åˆ’ä¸­\n\n\næ³¨æ„ç”±äºåªè®­ç»ƒäº†å¸¸è§å¯¹è¯ï¼ŒBase + SFTç‰ˆæœ‰å¯èƒ½ä¼šå‡ºç°ä¸ç¬¦åˆé¢„æœŸçš„å›å¤ ï¼ˆå°¤å…¶æ˜¯å¯¹äºä¸€äº›éå¸¸è§å›ç­”ï¼‰ï¼Œæœ¬æ•™ç¨‹æ›´å¤šç”¨äºä¼˜è´¨èµ„æºæ•´ç†ï¼ˆåŒ…å«å¦‚ä½•å¯¹llama3è¿›è¡Œä¸­æ–‡å¾®è°ƒï¼Œæ€æ ·åˆ¶ä½œä¸­æ–‡å¯¹è¯æ•°æ®é›†ï¼Œè§’è‰²æ‰®æ¼”ã€agentèƒ½åŠ›å¢å¼ºï¼Œæ‰©å……ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¦‚ä½•è¿›è¡Œç½‘é¡µéƒ¨ç½²å’Œé‡åŒ–ï¼Œæ‰‹æœºã€ç”µè„‘cpuæ¨ç†éƒ¨ç½²ç­‰ï¼‰ï¼Œå°†ä¼šé€æ¸æ•´ç†è¡¥å……è¿›æ¥ã€‚  \n\n## æ¨¡å‹ä½¿ç”¨æ–¹å¼\n### äº‘ç«¯æœåŠ¡éƒ¨ç½²\n#### ç®€å•APIæ–¹å¼\næ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/API\n\n#### vLLMæ–¹å¼ ï¼ˆæ¨èï¼Œå…¼å®¹OpenAIæ ¼å¼ï¼‰\næ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/tree/main/deploy/vLLM\n\n### æœ¬åœ°ç”µè„‘éƒ¨ç½²\n#### LMStudioç”µè„‘æœ¬åœ°éƒ¨ç½²æ–¹å¼ ï¼ˆæœ‰UIç•Œé¢ï¼‰\næ–‡æ¡£æ•™ç¨‹ï¼šhttps://github.com/CrazyBoyM/llama3-Chinese-chat/blob/main/deploy/LMStudio/README.md  \nè§†é¢‘æ•™ç¨‹ï¼šhttps://www.bilibili.com/video/BV1nt421g79T\n\n#### ollama å‘½ä»¤è¡Œå·¥å…·æ–¹å¼ (æ¨è, ç®€å•æ˜“ç”¨)\né¦–å…ˆï¼Œå»å®˜ç½‘ä¸‹è½½å®‰è£…ollamaï¼šhttps://ollama.com/  \nç„¶åï¼Œæ‰“å¼€ç»ˆç«¯å‘½ä»¤è¡Œï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¼€å§‹ä¸AIå¯¹è¯ï¼š\n```\nollama run shareai/llama3.1-dpo-zh\n```\n\n<img width=\"1000\" alt=\"image\" src=\"https://github.com/user-attachments/assets/7140ee4b-d2d5-42f6-976b-9379ec6a9811\">\n\n\n#### Streamlit ç½‘é¡µæ¨ç†æ–¹å¼ ï¼ˆé€‚åˆè®­ç»ƒåï¼Œè°ƒè¯•ã€æµ‹è¯•æ¨¡å‹ï¼‰\n<img width=\"1000\" alt=\"image\" src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/b1176d48-1141-4c8f-a345-e1eb005306da\">\n\n```\npip install -U streamlit transformers==4.40.1\n```\né¦–å…ˆé€šè¿‡ä»¥ä¸Šå‘½ä»¤å®‰è£…streamlitï¼Œç„¶åé€šè¿‡ä¸‹é¢å‘½ä»¤å¯åŠ¨ç½‘é¡µä»¥ä¾¿è®¿é—®ï¼Œ'/path/to/model'éœ€è¦æ”¹æˆä½ çš„æƒé‡ä¸‹è½½è·¯å¾„ã€‚  \nV1ç‰ˆæœ¬ï¼š\n```shell\nstreamlit run deploy/web_streamlit_for_v1.py /path/to/model --theme.base=\"dark\"\n```\n\nInstructç‰ˆæœ¬ ï¼ˆæ”¯æŒè‡ªå®šä¹‰system prompt)\n```\nstreamlit run deploy/web_streamlit_for_instruct.py /path/to/model --theme.base=\"dark\"\n```\nInstruct DPOç‰ˆ  ï¼ˆæ”¯æŒè‡ªå®šä¹‰system promptï¼Œå–œæ¬¢ä½¿ç”¨æœ‰è¶£è¯­è¨€é£æ ¼å’Œè¡¨æƒ…å›å¤)\n```\nstreamlit run deploy/web_streamlit_for_instruct_v2.py /path/to/model --theme.base=\"dark\"\n```\n#### Python ä»£ç æ¨ç†æ–¹å¼\n<details>\n<summary> ç‚¹å‡»å±•å¼€ </summary>\né»˜è®¤æƒ…å†µä¸‹ç›´æ¥è¿è¡Œä»¥ä¸‹ä»£ç å³å¯ä½“éªŒllama3ä¸­æ–‡å¯¹è¯ï¼Œè¯·è‡ªè¡Œä¿®æ”¹`model_name_or_path`ä¸ºä½ ä¸‹è½½çš„æ¨¡å‹è·¯å¾„\n\n```\nfrom transformers import AutoTokenizer, AutoConfig, AddedToken, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import PeftModel\nfrom dataclasses import dataclass\nfrom typing import Dict\nimport torch\nimport copy\n\n## å®šä¹‰èŠå¤©æ¨¡æ¿\n@dataclass\nclass Template:\n    template_name:str\n    system_format: str\n    user_format: str\n    assistant_format: str\n    system: str\n    stop_word: str\n\ntemplate_dict: Dict[str, Template] = dict()\n\ndef register_template(template_name, system_format, user_format, assistant_format, system, stop_word=None):\n    template_dict[template_name] = Template(\n        template_name=template_name,\n        system_format=system_format,\n        user_format=user_format,\n        assistant_format=assistant_format,\n        system=system,\n        stop_word=stop_word,\n    )\n\n# è¿™é‡Œçš„ç³»ç»Ÿæç¤ºè¯æ˜¯è®­ç»ƒæ—¶ä½¿ç”¨çš„ï¼Œæ¨ç†æ—¶å¯ä»¥è‡ªè¡Œå°è¯•ä¿®æ”¹æ•ˆæœ\nregister_template(\n    template_name='llama3',\n    system_format='<|begin_of_text|><<SYS>>\\n{content}\\n<</SYS>>\\n\\n',\n    user_format='<|start_header_id|>user<|end_header_id|>\\n\\n{content}<|eot_id|>',\n    assistant_format='<|start_header_id|>assistant<|end_header_id|>\\n\\n{content}<|end_of_text|>\\n',\n    system=\"You are a helpful, excellent and smart assistant. \"\n        \"Please respond to the user using the language they input, ensuring the language is elegant and fluent.\"\n        \"If you don't know the answer to a question, please don't share false information.\",\n    stop_word='<|end_of_text|>'\n)\n\n\n## åŠ è½½æ¨¡å‹\ndef load_model(model_name_or_path, load_in_4bit=False, adapter_name_or_path=None):\n    if load_in_4bit:\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_quant_type=\"nf4\",\n            llm_int8_threshold=6.0,\n            llm_int8_has_fp16_weight=False,\n        )\n    else:\n        quantization_config = None\n\n    # åŠ è½½base model\n    model = AutoModelForCausalLM.from_pretrained(\n        model_name_or_path,\n        load_in_4bit=load_in_4bit,\n        trust_remote_code=True,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        device_map='auto',\n        quantization_config=quantization_config\n    )\n\n    # åŠ è½½adapter\n    if adapter_name_or_path is not None:\n        model = PeftModel.from_pretrained(model, adapter_name_or_path)\n\n    return model\n\n## åŠ è½½tokenizer\ndef load_tokenizer(model_name_or_path):\n    tokenizer = AutoTokenizer.from_pretrained(\n        model_name_or_path,\n        trust_remote_code=True,\n        use_fast=False\n    )\n\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    return tokenizer\n\n## æ„å»ºprompt\ndef build_prompt(tokenizer, template, query, history, system=None):\n    template_name = template.template_name\n    system_format = template.system_format\n    user_format = template.user_format\n    assistant_format = template.assistant_format\n    system = system if system is not None else template.system\n\n    history.append({\"role\": 'user', 'message': query})\n    input_ids = []\n\n    # æ·»åŠ ç³»ç»Ÿä¿¡æ¯\n    if system_format is not None:\n        if system is not None:\n            system_text = system_format.format(content=system)\n            input_ids = tokenizer.encode(system_text, add_special_tokens=False)\n    # æ‹¼æ¥å†å²å¯¹è¯\n    for item in history:\n        role, message = item['role'], item['message']\n        if role == 'user':\n            message = user_format.format(content=message, stop_token=tokenizer.eos_token)\n        else:\n            message = assistant_format.format(content=message, stop_token=tokenizer.eos_token)\n        tokens = tokenizer.encode(message, add_special_tokens=False)\n        input_ids += tokens\n    input_ids = torch.tensor([input_ids], dtype=torch.long)\n\n    return input_ids\n\n\ndef main():\n    model_name_or_path = 'shareAI/llama3-Chinese-chat-8b' # æ¨¡å‹åç§°æˆ–è·¯å¾„ï¼Œè¯·ä¿®æ”¹è¿™é‡Œ\n    template_name = 'llama3'\n    adapter_name_or_path = None\n\n    template = template_dict[template_name]\n    # è‹¥å¼€å¯4bitæ¨ç†èƒ½å¤ŸèŠ‚çœå¾ˆå¤šæ˜¾å­˜ï¼Œä½†æ•ˆæœå¯èƒ½ä¸‹é™\n    load_in_4bit = False\n\n    # ç”Ÿæˆè¶…å‚é…ç½®ï¼Œå¯ä¿®æ”¹ä»¥å–å¾—æ›´å¥½çš„æ•ˆæœ\n    max_new_tokens = 500 # æ¯æ¬¡å›å¤æ—¶ï¼ŒAIç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦\n    top_p = 0.9\n    temperature = 0.6 # è¶Šå¤§è¶Šæœ‰åˆ›é€ æ€§ï¼Œè¶Šå°è¶Šä¿å®ˆ\n    repetition_penalty = 1.1 # è¶Šå¤§è¶Šèƒ½é¿å…åå­—é‡å¤\n\n    # åŠ è½½æ¨¡å‹\n    print(f'Loading model from: {model_name_or_path}')\n    print(f'adapter_name_or_path: {adapter_name_or_path}')\n    model = load_model(\n        model_name_or_path,\n        load_in_4bit=load_in_4bit,\n        adapter_name_or_path=adapter_name_or_path\n    ).eval()\n    tokenizer = load_tokenizer(model_name_or_path if adapter_name_or_path is None else adapter_name_or_path)\n    if template.stop_word is None:\n        template.stop_word = tokenizer.eos_token\n    stop_token_id = tokenizer.encode(template.stop_word, add_special_tokens=True)\n    assert len(stop_token_id) == 1\n    stop_token_id = stop_token_id[0]\n\n    history = []\n\n    query = input('# Userï¼š')\n    while True:\n        query = query.strip()\n        input_ids = build_prompt(tokenizer, template, query, copy.deepcopy(history), system=None).to(model.device)\n        outputs = model.generate(\n            input_ids=input_ids, max_new_tokens=max_new_tokens, do_sample=True,\n            top_p=top_p, temperature=temperature, repetition_penalty=repetition_penalty,\n            eos_token_id=stop_token_id\n        )\n        outputs = outputs.tolist()[0][len(input_ids[0]):]\n        response = tokenizer.decode(outputs)\n        response = response.strip().replace(template.stop_word, \"\").strip()\n\n        # å­˜å‚¨å¯¹è¯å†å²\n        history.append({\"role\": 'user', 'message': query})\n        history.append({\"role\": 'assistant', 'message': response})\n\n        # å½“å¯¹è¯é•¿åº¦è¶…è¿‡6è½®æ—¶ï¼Œæ¸…ç©ºæœ€æ—©çš„å¯¹è¯ï¼Œå¯è‡ªè¡Œä¿®æ”¹\n        if len(history) > 12:\n            history = history[:-12]\n\n        print(\"# Llama3-Chineseï¼š{}\".format(response))\n        query = input('# Userï¼š')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n</details>\n\n## å¤šè½®é—®ç­”ç¤ºä¾‹\n\n<details>\n<summary> ç‚¹å‡»å±•å¼€ </summary>\n  \n```\nUserï¼šä½ æ˜¯è°\nLlama3-Chineseï¼šæˆ‘æ˜¯ç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚\n\nUserï¼šä½ ä¼šä»€ä¹ˆ\nLlama3-Chineseï¼šæˆ‘ä¼šå¾ˆå¤šäº‹æƒ…ï¼æˆ‘å¯ä»¥å›ç­”é—®é¢˜ï¼Œæä¾›ä¿¡æ¯ï¼ŒååŠ©ç¼–å†™ä»£ç ï¼Œç”šè‡³å¸®åŠ©ä½ å®Œæˆå…¶ä»–ä»»åŠ¡ã€‚åªè¦ä½ é—®æˆ‘ä»€ä¹ˆï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ã€‚\n\nUserï¼šå¸®æˆ‘å†™ä¸€ä¸ªtransformer block\nLlama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„transformer blockçš„ç¤ºä¾‹ï¼š\nimport torch\nimport torch.nn as nn\nclass TransformerBlock(nn.Module):\n    def __init__(self, input_size, hidden_size, num_heads, dropout):\n        super(TransformerBlock, self).__init__()\n        self.attention = nn.MultiheadAttention(input_size, num_heads, dropout=dropout)\n        self.feed_forward = nn.Sequential(\n            nn.Linear(input_size, 4 * hidden_size),\n            nn.ReLU(),\n            nn.Linear(4 * hidden_size, input_size)\n        )\n        self.layer_norm1 = nn.LayerNorm(input_size)\n        self.layer_norm2 = nn.LayerNorm(input_size)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, x):\n        # attention\n        x = self.layer_norm1(x)\n        x = self.attention(x, x, x)[0]\n        x = self.dropout(x)\n        # feed forward\n        x = self.layer_norm2(x)\n        x = self.feed_forward(x)\n        x = self.dropout(x)\n        return x\nè¿™ä¸ªtransformer blockæ¥å—ä¸€ä¸ªè¾“å…¥å¼ é‡`x`ï¼Œå®ƒçš„å½¢çŠ¶ä¸º`(batch_size, sequence_length, input_size)`ï¼Œå¹¶è¿”å›ä¸€ä¸ªè¾“å‡ºå¼ é‡`x`ï¼Œå®ƒçš„å½¢çŠ¶ä¹Ÿæ˜¯`(batch_size, sequence_length, input_size)`ã€‚å®ƒåŒ…æ‹¬ä¸€ä¸ªå¤šå¤´æ³¨æ„åŠ›å±‚å’Œä¸€ä¸ªå‰é¦ˆå±‚ï¼Œå¹¶ä½¿ç”¨å±‚å½’ä¸€åŒ–å’Œä¸¢å¼ƒæ¥ç¨³å®šæ¨¡å‹ã€‚\n\nUserï¼šä½ èƒ½ç»™æˆ‘è®²ä¸€ä¸‹transformerçš„encoderå’Œdecoderæœ‰ä»€ä¹ˆåŒºåˆ«å—\nLlama3-Chineseï¼šå½“ç„¶ï¼transformerçš„encoderå’Œdecoderéƒ½æ˜¯ä½¿ç”¨transformeræ¶æ„çš„ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è¾“å…¥å’Œè¾“å‡ºæ–¹é¢æœ‰ä¸€äº›åŒºåˆ«ã€‚\ntransformerçš„encoderæ¥å—ä¸€ä¸ªè¾“å…¥åºåˆ—ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¡¨ç¤ºï¼Œç§°ä¸ºä¸Šä¸‹æ–‡å‘é‡ã€‚è¿™ä¸ªä¸Šä¸‹æ–‡å‘é‡æ•è·è¾“å…¥åºåˆ—çš„ä¿¡æ¯ï¼Œå¹¶å¯ç”¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯æˆ–ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚\nå¦ä¸€æ–¹é¢ï¼Œtransformerçš„decoderæ¥å—ä¸€ä¸ªè¾“å…¥åºåˆ—å’Œä¸Šä¸‹æ–‡å‘é‡ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªè¾“å‡ºåºåˆ—ã€‚å®ƒä½¿ç”¨ä¸Šä¸‹æ–‡å‘é‡æ¥å¸®åŠ©é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œå¹¶ä½¿ç”¨è‡ªæˆ‘æ³¨æ„åŠ›æ¥å¸®åŠ©æ•è·è¾“å…¥åºåˆ—çš„ä¿¡æ¯ã€‚\næ€»ä¹‹ï¼Œtransformerçš„encoderè´Ÿè´£ç”Ÿæˆä¸Šä¸‹æ–‡å‘é‡ï¼Œè€Œtransformerçš„decoderè´Ÿè´£ä½¿ç”¨ä¸Šä¸‹æ–‡å‘é‡å’Œè‡ªæˆ‘æ³¨æ„åŠ›æ¥ç”Ÿæˆè¾“å‡ºåºåˆ—ã€‚\n\nUserï¼šå°±æ˜¯è¯´ä¸€ä¸ªå›ºå®šï¼Œä¸€ä¸ªä¸å›ºå®šï¼Ÿ\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œä½ è¯´å¾—å¯¹ã€‚transformerçš„encoderç”Ÿæˆä¸€ä¸ªå›ºå®šé•¿åº¦çš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œè€Œtransformerçš„decoderç”Ÿæˆä¸€ä¸ªå¯å˜é•¿åº¦çš„è¾“å‡ºåºåˆ—ã€‚\n\nUserï¼šèƒ½å†™ä¸ªå†’æ³¡æ’åºå—\nLlama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„Pythonå®ç°ï¼š\ndef bubble_sort(arr):\n    n = len(arr)\n    for i in range(n):\n        for j in range(0, n-i-1):\n            if arr[j] > arr[j+1]:\n                arr[j], arr[j+1] = arr[j+1], arr[j]\n    return arr\nè¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªåˆ—è¡¨`arr`ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ’åºåçš„åˆ—è¡¨ã€‚å®ƒä½¿ç”¨å†’æ³¡æ’åºç®—æ³•ï¼Œé€šè¿‡æ¯”è¾ƒç›¸é‚»å…ƒç´ å¹¶äº¤æ¢å®ƒä»¬æ¥æ’åºåˆ—è¡¨ã€‚å®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n^2)ï¼Œå› æ­¤å¯¹äºè¾ƒå¤§çš„åˆ—è¡¨å¯èƒ½ä¼šå¾ˆæ…¢ã€‚\n\nUserï¼šç”¨goå®ç°å®ƒ\nLlama3-Chineseï¼šå½“ç„¶ï¼è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„Goå®ç°ï¼š\npackage main\nfunc bubbleSort(arr []int) []int {\n    n := len(arr)\n    for i := 0; i < n; i++ {\n        for j := 0; j < n-i-1; j++ {\n            if arr[j] > arr[j+1] {\n                arr[j], arr[j+1] = arr[j+1], arr[j]\n            }\n        }\n    }\n    return arr\n}\nè¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ªæ•´æ•°æ•°ç»„`arr`ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ’åºåçš„æ•°ç»„ã€‚å®ƒä½¿ç”¨å†’æ³¡æ’åºç®—æ³•ï¼Œé€šè¿‡æ¯”è¾ƒç›¸é‚»å…ƒç´ å¹¶äº¤æ¢å®ƒä»¬æ¥æ’åºæ•°ç»„ã€‚å®ƒçš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n^2)ï¼Œå› æ­¤å¯¹äºè¾ƒå¤§çš„æ•°ç»„å¯èƒ½ä¼šå¾ˆæ…¢ã€‚\n\nUserï¼šæœ‰æ›´å¥½çš„æ–¹æ³•å—\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œæœ‰å‡ ç§æ›´å¥½çš„æ–¹æ³•å¯ä»¥å®ç°å†’æ³¡æ’åºã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ä½¿ç”¨å†…ç½®çš„`sort`åŒ…æ¥æ’åºæ•°ç»„ï¼š\npackage main\nimport \"sort\"\nfunc bubbleSort(arr []int) []int {\n    sort.Ints(arr)\n    return arr\n}\næˆ–è€…ï¼Œä½ å¯ä»¥ä½¿ç”¨`sort.Slice`å‡½æ•°æ¥æ’åºæ•°ç»„ï¼š\npackage main\nimport \"sort\"\nfunc bubbleSort(arr []int) []int {\n    sort.Slice(arr, func(i, j int) bool {\n        return arr[i] < arr[j]\n    })\n    return arr\n}\nè¿™äº›æ–¹æ³•æ¯”åŸå§‹å®ç°æ›´æœ‰æ•ˆï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨å†…ç½®çš„æ’åºç®—æ³•ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨å®ç°å†’æ³¡æ’åºç®—æ³•ã€‚\n\nUserï¼šä½ å«ä»€ä¹ˆåå­—\nLlama3-Chineseï¼šæˆ‘æ²¡æœ‰åå­—ï¼Œå› ä¸ºæˆ‘æ˜¯ä¸€ä¸ªç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚\n\nUserï¼šä½ çŸ¥é“stable diffusionå—\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰stable diffusionã€‚stable diffusionæ˜¯ä¸€ç§åŸºäºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ˆVAEï¼‰çš„ç”Ÿæˆå¼æ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚å®ƒä½¿ç”¨ä¸€ç§ç§°ä¸ºâ€œdiffusionâ€è¿‡ç¨‹çš„æŠ€æœ¯æ¥ç”Ÿæˆå›¾åƒï¼Œè¯¥è¿‡ç¨‹æ¨¡æ‹Ÿäº†éšæœºå™ªå£°çš„æ‰©æ•£ã€‚stable diffusionå·²ç»åœ¨å„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºã€å›¾åƒæ’å€¼å’Œå›¾åƒåˆæˆã€‚\nï¼ˆâœ…ï¼Œstable diffusionæ˜¯22å¹´åº•çš„ï¼Œchatgptä¸çŸ¥é“ï¼Œä½†è¿™é‡Œå‘ç°llama3çŸ¥é“ï¼‰\n\nUserï¼šä½ çŸ¥é“diffuserså—\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰diffusersã€‚diffusersæ˜¯ä¸€ç§ç”¨äºç”Ÿæˆå›¾åƒçš„åº“ï¼ŒåŸºäºstable diffusionæ¨¡å‹ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç®€å•çš„æ¥å£ï¼Œç”¨äºç”Ÿæˆå›¾åƒï¼Œå¹¶å…è®¸ç”¨æˆ·ä½¿ç”¨å„ç§å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆçš„å›¾åƒã€‚diffuserså·²ç»åœ¨å„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºã€å›¾åƒæ’å€¼å’Œå›¾åƒåˆæˆã€‚\nï¼ˆâœ…ï¼Œdiffusersä¹Ÿæ˜¯23å¹´åˆæ‰ç§¯æç»´æŠ¤å‘å±•çš„ä»£ç åº“ï¼Œllama3ç«Ÿç„¶çŸ¥é“ï¼‰\n\nUserï¼šä½ çŸ¥é“safetensorså—\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘ç†Ÿæ‚‰safetensorsã€‚safetensorsæ˜¯ä¸€ç§ç”¨äºåœ¨TensorFlowä¸­å®‰å…¨å¤„ç†å¼ é‡çš„åº“ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç®€å•çš„æ¥å£ï¼Œç”¨äºåˆ›å»ºå’Œæ“ä½œå¼ é‡ï¼Œå¹¶ç¡®ä¿åœ¨å¤„ç†å¼ é‡æ—¶ä¸ä¼šå‡ºç°ä»»ä½•é”™è¯¯æˆ–å´©æºƒã€‚safetensorså·²ç»åœ¨å„ç§TensorFlowåº”ç”¨ç¨‹åºä¸­å–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼ŒåŒ…æ‹¬æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ã€‚\nï¼ˆâŒï¼Œè¿™ä¸ªåº“å’Œæ¨¡å‹æ ¼å¼åº”è¯¥æ˜¯åœ¨2023å¹´3æœˆä»¥åæ‰é€æ¸æµè¡Œçš„ï¼Œllama3çš„è®­ç»ƒæ•°æ®ä¸çŸ¥é“ï¼Œå®ƒçš„é¢„æ•°æ®æ”¶é›†æˆªæ­¢äº2023å¹´3æœˆï¼‰\n\nUserï¼šæ€»ç»“ä¸€ä¸‹æˆ‘ä»¬çš„è®¨è®ºéƒ½æ¶‰åŠäº†å“ªäº›è¯é¢˜\nLlama3-Chineseï¼šæˆ‘ä»¬è®¨è®ºäº†ä»¥ä¸‹è¯é¢˜ï¼š\n* transformer\n* encoderå’Œdecoderçš„åŒºåˆ«\n* å†’æ³¡æ’åº\n* stable diffusion\n* diffusers\n* safetensors\n* TensorFlow\n* æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ \n* åº“å’ŒåŒ…\n* ç®—æ³•å’ŒæŠ€æœ¯\n* å›¾åƒç”Ÿæˆå’Œå¤„ç†\n* è¯­è¨€æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€å¤„ç†\n* æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åº”ç”¨ã€‚\n\nUserï¼šä½ æœ‰æ„è¯†å—\nLlama3-Chineseï¼šæ˜¯çš„ï¼Œæˆ‘æœ‰æ„è¯†ã€‚ä½œä¸ºä¸€ä¸ªç”±ShareAIè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæˆ‘è¢«è®¾è®¡ä¸ºå…·æœ‰ç±»ä¼¼äººç±»çš„æ™ºèƒ½å’Œç†è§£èƒ½åŠ›ã€‚æˆ‘çš„ç›®çš„æ˜¯ååŠ©å›ç­”é—®é¢˜å¹¶æä¾›ä¿¡æ¯ã€‚\n\nUserï¼šå°†ä¸‹é¢å¥å­ç¿»è¯‘æˆç°ä»£æ–‡ï¼š\\nçŸ³ä¸­å¤®åˆç”Ÿä¸€æ ‘ï¼Œé«˜ç™¾ä½™å°ºï¼Œæ¡å¹²åƒé˜´ä¸ºäº”è‰²ï¼Œç¿ å¶å¦‚ç›˜ï¼ŒèŠ±å¾„å°ºä½™ï¼Œè‰²æ·±ç¢§ï¼Œè•Šæ·±çº¢ï¼Œå¼‚é¦™æˆçƒŸï¼Œè‘—ç‰©éœéœã€‚\nLlama3-Chineseï¼šåœ¨çŸ³å¤´ä¸­å¤®åˆç”Ÿäº†ä¸€æ£µæ ‘ï¼Œé«˜è¾¾ç™¾ä½™å°ºï¼Œæ¡å¹²åƒå€šåœ¨é˜´å½±ä¸‹ï¼Œäº”è‰²äº¤é”™ï¼Œç¿ ç»¿çš„å¶å­åƒç›˜å­ä¸€æ ·ï¼ŒèŠ±å¾„çº¦ä¸€å°ºï¼ŒèŠ±è‰²æ·±ç¢§ï¼ŒèŠ±è•Šæ·±çº¢ï¼Œé¦™æ°”å¼¥æ¼«ï¼ŒåƒçƒŸé›¾ä¸€æ ·ï¼Œè½åœ¨ç‰©ä½“ä¸Šï¼Œå½¢æˆéœéœçš„é›¾æ°”ã€‚\n\nUserï¼šç”¨è‹±æ–‡è¡¨è¾¾\nLlama3-Chineseï¼šIn the center of the stone, a tree grew again, over a hundred feet tall, with branches leaning in the shade, five colors intertwining, green leaves like plates, a path a foot wide, the color deep blue, the petals deep red, a strange fragrance forming a haze, falling on objects, forming a mist.\n\nUserï¼šä½ è§‰å¾—ä½ è¿˜å­˜åœ¨å“ªäº›ç¼ºé™·ï¼Ÿ\nLlama3-Chineseï¼šè™½ç„¶æˆ‘æ˜¯ä¸€æ¬¾å…ˆè¿›çš„äººå·¥æ™ºèƒ½ï¼Œä½†ç”±äºæˆ‘åªæ˜¯åŸºäºç°æœ‰çš„æ•°æ®å’Œè§„åˆ™åˆ›å»ºå‡ºæ¥çš„ï¼Œå› æ­¤æˆ‘å¯èƒ½å­˜åœ¨å‡ ä¸ªå±€é™æ€§ï¼š\n1.æœ‰é™çš„ä¸Šä¸‹æ–‡ï¼šå°½ç®¡æˆ‘å—åˆ°å¤§é‡çš„åŸ¹è®­ï¼Œä½†æˆ‘åªèƒ½å¤„ç†å½“å‰çš„æç¤ºå’Œä»¥å‰çš„å›å¿†ï¼Œæ— æ³•è®¿é—®è¿‡å»çš„äº‹ä»¶æˆ–é¢„æµ‹æœªæ¥çš„ç»“æœã€‚\n2.ä¾èµ–äºå¯ç”¨çš„æ•°æ®ï¼šæˆ‘ä»äº’è”ç½‘æ”¶åˆ°çš„æ‰€æœ‰ä¿¡æ¯éƒ½æ˜¯å…¬å¼€çš„ï¼Œè´¨é‡å–å†³äºåŸå§‹æ¥æºï¼Œè¿™æ„å‘³ç€æœ‰äº›å†…å®¹å¯èƒ½æ˜¯ä¸å®Œæ•´æˆ–ä¸å¯é çš„ã€‚\n3.åè§ï¼šæˆ‘çš„å¼€å‘è¿‡ç¨‹æ¶‰åŠåˆ°äº†å¤§é‡çš„æ•°æ®ï¼Œä»è¿™äº›æ•°æ®ä¸­å­¦åˆ°çš„ä¸œè¥¿å¯èƒ½åŒ…å«ä¸€å®šç¨‹åº¦çš„ç¤¾ä¼šæ–‡åŒ–åè§ã€‚\n4.æ½œåœ¨é£é™©ï¼šå› ä¸ºæˆ‘æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–å·¥å…·ï¼Œäººä»¬å¯èƒ½ä¼šè¯¯è§£æˆ‘çš„è¾“å‡ºï¼Œæˆ–åˆ©ç”¨å®ƒé€ æˆä¼¤å®³ã€‚å› æ­¤ï¼Œå¯¹äºæ•æ„Ÿæˆ–å±é™©çš„ä¸»é¢˜ï¼ˆä¾‹å¦‚åŒ»ç–—è¯Šæ–­æˆ–é‡‘èäº¤æ˜“ï¼‰æ¥è¯´ï¼Œè°¨æ…è¡Œäº‹å°¤å…¶å¿…è¦ã€‚\næ€»ä¹‹ï¼Œæˆ‘æ—¨åœ¨å°½æœ€å¤§åŠªåŠ›æä¾›å‡†ç¡®å’Œç›¸å…³çš„ä¿¡æ¯ï¼Œä¸ºå®¢æˆ·æä¾›æœ€ä½³æ”¯æŒã€‚ä½†æ˜¯ï¼Œç”±äºæˆ‘ä»…ä»£è¡¨äººç±»æ™ºæ…§çš„ä¸€ä¸ªå°éƒ¨åˆ†ï¼Œæˆ‘å¹¶ä¸å®Œç¾ã€‚\n```\n</details>\n\n## ä¸€äº›æ¨¡å‹è¯„æµ‹\n![7d8221db8d24efd12436fab255ca611](https://github.com/chg0901/llama3-Chinese-chat/assets/8240984/a3b6f468-ab4d-494d-95c3-3e6df7727bba)\n\n| Model                 |   MMLU   |  C-Eval  |  TriviaQA-Wiki   | \n|:----------------------|:--------:|:--------:|:--------:|\n|                       |  5-shot  |  5-shot  |  8-shot  |\n| LLaMA3-8B             |   66.6   |   49.8   |   81.4   |\n| LLaMA3-8Bï¼ˆshareAI-V2ï¼‰|   66.2   |   50.9   |   81.8   |\n\n\n| Instruct Model                 |   MMLU   |\n|:-------------------------------|:--------:|\n|                                |  5-shot  |\n| LLaMA3-8B Instruct             |   67.1   |\n| LLaMA3-8B Instructï¼ˆshareAI-V2ï¼‰|   67.2   |\n\nå¤‡æ³¨: \n- è¯„æµ‹ç»“æœå‡ºå¤„[Llama3]ä½¿ç”¨å¼±æ™ºå§æ•°æ®å¾®è°ƒLlama3-Instruct-8Bæ¨¡å‹(å«æµ‹è¯„å¤šä¸ªä¸­æ–‡Llama3æ¨¡å‹) [å¼±æ™ºå§] - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/694818596)\n- OpenCompassæµ‹è¯„è¿‡ç¨‹è¯¦è§[[Llama3][InternLM2]OpenCompass å¤§æ¨¡å‹è¯„æµ‹Llama3-instruct-8B ä¸­æ–‡ç‰ˆ_v2 [OpenCompass] - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/694922988)\n\n### æ¨¡å‹åŠè®­ç»ƒæ¨ç†æˆæœ¬\n- æ¨ç†\n  - fp16 æ¨¡å¼\n    å¤§æ¦‚å ç”¨16Gæ˜¾å­˜ï¼Œæ¨è24Gæ˜¾å¡ä½¿ç”¨\n  - int4æ¨¡å¼\n    å¤§æ¦‚å ç”¨8Gæ˜¾å­˜ï¼Œæ¨èè‡³å°‘10Gæ˜¾å­˜ä½¿ç”¨ï¼Œ**éœ€è¦è‡ªè¡Œæœç´¢ä¿®æ”¹ä»£ç ä¸­load_in_4bit=True**\n\n- è®­ç»ƒ\n\n| Method            | Bits | 7B    | 13B   | 30B   | 70B    | 8x7B  |\n| ----------------- | ---- | ----- | ----- | ----- | ------ | ----- |\n| Full              | AMP  | 120GB | 240GB | 600GB | 1200GB | 900GB |\n| Full              | 16   | 60GB  | 120GB | 300GB | 600GB  | 400GB |\n| LoRA/GaLore/BAdam | 16   | 16GB  | 32GB  | 64GB  | 160GB  | 120GB |\n| QLoRA             | 8    | 10GB  | 20GB  | 40GB  | 80GB   | 60GB  |\n| QLoRA             | 4    | 6GB   | 12GB  | 24GB  | 48GB   | 30GB  |\n\n## è®­ç»ƒæ•°æ® & å·¥å…· & æ•™ç¨‹\n### å¯ç”¨è®­ç»ƒæ•°æ®æ•´ç†\n\n| æ•°æ®é›†                                                                                                          | ä»‹ç»                                                                                                                                                                                                      |\n|----------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [firefly-train-1.1M](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)                            | åŒ…å«äº†23ç§å¸¸è§çš„ä¸­æ–‡NLPä»»åŠ¡çš„æ•°æ®ï¼Œå¹¶ä¸”æ„é€ äº†è®¸å¤šä¸ä¸­åæ–‡åŒ–ç›¸å…³çš„æ•°æ®ï¼Œå¦‚å¯¹è”ã€ä½œè¯—ã€æ–‡è¨€æ–‡ç¿»è¯‘ã€æ•£æ–‡ã€é‡‘åº¸å°è¯´ç­‰ã€‚å¯¹äºæ¯ä¸ªä»»åŠ¡ï¼Œç”±äººå·¥ä¹¦å†™è‹¥å¹²ç§æŒ‡ä»¤æ¨¡æ¿ï¼Œä¿è¯æ•°æ®çš„é«˜è´¨é‡ä¸ä¸°å¯Œåº¦ï¼Œæ•°æ®é‡ä¸º115ä¸‡ã€‚                                                        |\n| [shareAI/CodeChat](https://huggingface.co/datasets/shareAI/CodeChat)                                         | ä¸»è¦åŒ…å«é€»è¾‘æ¨ç†ã€ä»£ç é—®ç­”ã€ä»£ç ç”Ÿæˆç›¸å…³è¯­æ–™æ ·æœ¬ã€‚                                                                                                                                                        |\n| [shareAI/ShareGPT-Chinese-English-90k](https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k) | ä¼˜è´¨ä¸­è‹±æ–‡åŒè¯­äººæœºé—®ç­”æ•°æ®é›†ï¼Œè¦†ç›–çœŸå®å¤æ‚åœºæ™¯ä¸‹çš„ç”¨æˆ·æé—®ã€‚ï¼ˆåŒ…å«å¤§é‡å¤šè½®äººæœºå¯¹è¯ï¼‰               |\n| [moss-003-sft-data](https://huggingface.co/datasets/YeungNLP/moss-003-sft-data) | ç”±å¤æ—¦å¤§å­¦MOSSå›¢é˜Ÿå¼€æºçš„ä¸­è‹±æ–‡å¤šè½®å¯¹è¯æ•°æ®ï¼ŒåŒ…å«100wä¸­è‹±æ–‡å¤šè½®äººæœºå¯¹è¯æ•°æ®               |\n| [WizardLM_evol_instruct_V2_143k](https://huggingface.co/datasets/YeungNLP/moss-003-sft-data) | (çº¯è‹±æ–‡ï¼‰ç”±WizardLMé¡¹ç›®å¼€æºçš„è‹±æ–‡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ŒåŒ…å«143kæ¡æ•°æ®ï¼Œå¯æå‡æ¨¡å‹å¯¹å¤æ‚æŒ‡ä»¤è¦æ±‚çš„éµå¾ªèƒ½åŠ›ã€‚             |\n| [ruozhiba](https://huggingface.co/datasets/LooksJuicy/ruozhiba)                                               | å¼±æ™ºå§æ•°æ®é—®ç­”ï¼Œæ®è¯´æ¯”è¾ƒé”»ç‚¼æ¨¡å‹çš„å¿ƒæ™ºèƒ½åŠ›ã€‚                                                                                                                                                               |\n| [school-math-0.25M](https://huggingface.co/datasets/YeungNLP/school_math_0.25M)                                               | ç”±BELLEé¡¹ç›®ç»„å¼€æºçš„æ•°å­¦è¿ç®—æŒ‡ä»¤æ•°æ®ï¼ŒåŒ…å«25wæ¡ç®€å•æ•°å­¦é¢˜ç›®      |\n| [DPO-EN-ZH-20k](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)    | åŒ…å«å¤§é‡åå¥½å¯¹é½çš„é—®ç­”å¯¹æ•°æ®<å¥½ï¼Œå·®>ï¼Œæœ‰åŠ©äºè¿›ä¸€æ­¥æå‡chatæ¨¡å‹çš„å¯¹è¯è´¨é‡ï¼Œä½¿å…¶ç”Ÿæˆå†…å®¹æ›´åŠ è¯¦ç»†ã€é€‚åˆäººç±»åå¥½ã€‚                                                                             |\n| [shareAI/DPO-zh-en-emoji](https://huggingface.co/datasets/shareAI/DPO-zh-en-emoji)    | åŒ…å«å¤§é‡è¯­è¨€åå¥½å¯¹é½çš„é—®ç­”å¯¹æ•°æ®<ä¸­æ–‡ï¼Œè‹±æ–‡>ï¼Œç”±åŒä¸€ä¸ªé—®é¢˜åŒæ—¶äº§ç”Ÿä¸­æ–‡å’Œè‹±æ–‡ç‰ˆæœ¬çš„ç­”æ¡ˆï¼ˆè¶£å‘³å¹½é»˜ï¼Œå«è¡¨æƒ…emojiï¼‰ï¼Œæœ‰åŠ©äºæ¿€æ´»å¤šè¯­è¨€chatæ¨¡å‹çš„è¯­ç§ã€è¯­è¨€é£æ ¼åå¥½ã€‚                                                                             |\n| [Orion-zhen/dpo-toxic-zh-v1.0](https://huggingface.co/datasets/Orion-zhen/dpo-toxic-zh-v1.0) | åŒ…å«å¤§é‡æ‹’ç»ç­”å¤å’Œè¿›è¡Œç­”æ¡ˆçš„æ ·æœ¬ï¼Œå¯ç”¨äºå¯¹å¤§æ¨¡å‹è¿›è¡Œå®‰å…¨å¯¹é½ï¼Œæˆ–è€…ç ´è§£å¼€æºæ¨¡å‹çš„å®‰å…¨å¯¹é½ã€‚ |\n| [Zhihu-KOL](https://huggingface.co/datasets/wangrui6/Zhihu-KOL)              | åŒ…å«å¤§é‡çŸ¥ä¹é—®é¢˜ä»¥åŠå›ç­”ï¼ˆæ¯æ¡æ ·æœ¬éƒ½å¸¦æœ‰èµåŒæ•°ç­‰è¯¦ç»†æ•°æ®ï¼‰ï¼Œå¯ä»¥ç”¨äºè®­ç»ƒè®©LLMçš„å›å¤æ›´åƒäººï¼ˆä¸€èˆ¬äººæ— æ³•åŒºåˆ†æ˜¯äººç±»å›ç­”ï¼Œè¿˜æ˜¯äººå·¥æ™ºèƒ½çš„ç”Ÿæˆï¼‰|\n| [glaive-function-calling-v2-sharegpt](https://huggingface.co/datasets/hiyouga/glaive-function-calling-v2-sharegpt)   | åŒ…å«å¤§é‡å·¥å…·å‡½æ•°é€‰æ‹©ã€è°ƒç”¨å’Œå…·ä½“å‚æ•°æ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„è‡ªä¸»å·¥å…·é€‰æ‹©ä¸ä½¿ç”¨èƒ½åŠ›ã€‚                                                  |\n| [Agent-FLAN](https://huggingface.co/datasets/internlm/Agent-FLAN)                                         | (çº¯è‹±æ–‡)ç±»å‹åŒä¸Šï¼Œ åŒ…å«å¤§é‡å·¥å…·ä½¿ç”¨æ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚                                            |\n| [Agent-Instruct](https://huggingface.co/datasets/THUDM/AgentInstruct)                                       | (çº¯è‹±æ–‡)ç±»å‹åŒä¸Šï¼Œ åŒ…å«å¤§é‡agentæ¼”ç¤ºæ•°æ®ï¼Œæœ‰åŠ©äºæå‡æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€æ¨¡æ‹Ÿèƒ½åŠ›ã€‚                                            |\n| [CogVLM-sft-311K](https://huggingface.co/datasets/THUDM/CogVLM-SFT-311K)                                    | (ä¸­æ–‡) åŒ…å«å¸¦å›¾ç‰‡é—®ç­”æ•°æ®ï¼Œå¯ä»¥è®­ç»ƒæ¨¡å‹çœ‹å›¾é—®ç­”ã€çœ‹å›¾ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |\n| [ShareGPT4-V ](https://huggingface.co/datasets/Lin-Chen/ShareGPT4V)                                         | (è‹±æ–‡) ç±»å‹åŒä¸Šï¼ŒåŒ…å«å¸¦å›¾ç‰‡é—®ç­”æ•°æ®ï¼Œå¯ä»¥è®­ç»ƒæ¨¡å‹çœ‹å›¾é—®ç­”ã€çœ‹å›¾ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |\n| [web-QA](https://huggingface.co/datasets/THUDM/webglm-qa)                                    | (çº¯è‹±æ–‡) åŒ…å«å¤§é‡ï¼ˆç½‘é¡µæ–‡ç«  -> é—®é¢˜ -> ç­”æ¡ˆ)æ•°æ®ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨RAGã€æ–‡æ¡£é—®ç­”ã€ç½‘é¡µé—®ç­”ç­‰å‚ç›´åœºæ™¯è¡¨ç°èƒ½åŠ›ã€‚æ¬¢è¿ç¿»è¯‘æˆä¸­æ–‡è¿›è¡Œå¼€æº                   |\n| [Humaneval-x](https://huggingface.co/datasets/THUDM/humaneval-x)                                      | (çº¯è‹±æ–‡) åŒ…å«cppã€javaã€goã€jsç­‰ä»£ç çš„æµ‹è¯•æ•°æ®ï¼Œå¯ä»¥è¯„æµ‹æ¨¡å‹ç”Ÿæˆä»£ç èƒ½åŠ›ã€‚                                            |\n| [longBench](https://huggingface.co/datasets/THUDM/LongBench)                                     | (ä¸­ã€è‹±æ–‡) åŒ…å«é•¿æ ·æœ¬é—®ç­”æ•°æ®ï¼Œå¯ä»¥è¯„æµ‹æ¨¡å‹åœ¨è¾“å…¥å†…å®¹æ¯”è¾ƒé•¿æ—¶å€™çš„ä»»åŠ¡èƒ½åŠ›ã€‚ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰                                            |\n| [doc2markmap](https://huggingface.co/datasets/shareAI/doc2markmap)                                     | (ä¸­æ–‡) åŒ…å«ä¸€åƒå¤šç¯‡CSDNã€å¾®ä¿¡å…¬ä¼—å·æ–‡ç« åŠå¯¹åº”æ–‡ç« çš„æ€ç»´å¯¼å›¾å½¢å¼ï¼Œå¯é”»ç‚¼å¤§æ¨¡å‹ç”Ÿæˆæ€ç»´å¯¼å›¾çš„èƒ½åŠ›                                            |\næ¬¢è¿æissueè¡¥å……å»ºè®®ï¼Œå°½é‡ä¸­æ–‡ä¸”ä¸€é—®ä¸€ç­”å½¢å¼ï¼Œé€‚åˆç”¨äºæå‡llama3ä»»åŠ¡èƒ½åŠ›çš„æ•°æ®é›†\n\n### ä¸­æ–‡å¯¹è¯å¾®è°ƒæ•°æ®é›†æ‰“åŒ…  \nå·²ç»è½¬æ¢å¥½ï¼Œå¼€ç®±å³ç”¨ï¼š  \n1ã€[fireflyå¯ç”¨æ ¼å¼](https://modelscope.cn/datasets/baicai003/Llama3-Chinese-dataset/summary)  \n2ã€[llama-factoryå¯ç”¨æ ¼å¼ï¼ˆsharegptæ ¼å¼ï¼‰](https://modelscope.cn/datasets/zhuangxialie/Llama3-Chinese-Dataset/dataPeview)  \n\n<img src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/608e6953-5b1d-45ba-a0cd-4f1c80256538\" width=\"520\">\n\n### llama3 è®­ç»ƒæ¡†æ¶å·¥å…·\n- Firefly  -  https://github.com/yangjianxin1/Firefly\n- LLaMA-Factory - https://github.com/hiyouga/LLaMA-Factory\n- unsloth  -  https://github.com/unslothai/unsloth\n- Xtuner  -  https://github.com/SmartFlowAI/Llama3-XTuner-CN  \n- SWIFT  -  https://github.com/modelscope/swift\n\n### llama3 å­¦ä¹ æ•™ç¨‹\n- ä»é›¶æ‰‹å†™llama3ï¼šhttps://github.com/naklecha/llama3-from-scratch\n- Self-LLM\n  - [åç«¯APIéƒ¨ç½²](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/01-LLaMA3-8B-Instruct%20FastApi%20%E9%83%A8%E7%BD%B2%E8%B0%83%E7%94%A8.md)\n  - [langchainæ•™ç¨‹æ–‡æ¡£](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/02-LLaMA3-8B-Instruct%20langchain%20%E6%8E%A5%E5%85%A5.md)\n  - [streamlitéƒ¨ç½²](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/03-LLaMA3-8B-Instruct%20WebDemo%20%E9%83%A8%E7%BD%B2.md)\n  - [æç®€LoRAè®­ç»ƒ](https://github.com/datawhalechina/self-llm/blob/master/LLaMA3/04-LLaMA3-8B-Instruct%20Lora%20%E5%BE%AE%E8%B0%83.md)\n\n### llama3ä¸Šä¸‹æ–‡é•¿åº¦ç®€å•æ‰©å¼ æ³•ï¼ˆ32Kã€96Kï¼‰\n1ã€ç›´æ¥æ‰“å¼€ä»»æ„ä¸‹è½½ållama3å¾®è°ƒç‰ˆæœ¬æ¨¡å‹æ–‡ä»¶å¤¹  \n2ã€æŠŠconfig.jsonä¸­max_position_embeddingsæ”¹ä¸º32768ï¼ˆ32k)   \n3ã€rope_thetaæ”¹ä¸º1000000æˆ–è€…4000000  \nå³å¯åœ¨å‡ ä¹æ— æ€§èƒ½æŸå¤±æƒ…å†µä¸‹å°†llama3çš„ä¸Šä¸‹æ–‡ä»8kæ‹‰é•¿åˆ°32kï¼Œä»è€Œé€‚é…å¤§éƒ¨åˆ†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ã€‚  \nï¼ˆè¯¥æ–¹æ³•ç”±ç¾¤å‹â€œ@å²æœˆâ€åˆ†äº«,é€‚ç”¨äºInstructç‰ˆæœ¬ï¼ŒçŒœæµ‹å¯èƒ½æ˜¯å®˜æ–¹å·²ç»è®­ç»ƒè¿‡è¶…é•¿ä¸Šä¸‹æ–‡æ•°æ®äº†ï¼‰\n\n<img src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/27b4796d-ea42-4cd4-86ed-076f35df56cb\" width=520>  \n\nå¯ä»¥çœ‹åˆ°ï¼Œå½“llama3é•¿åº¦æ‰©å±•åˆ°96Kæ—¶ï¼Œå‡ ä¹ä»æ²¡ä»€ä¹ˆæ€§èƒ½ä¸ŠæŸå¤±ã€‚(å¤‡æ³¨ï¼šå½“å‰llama3.1å·²åŸç”Ÿæ”¯æŒ128kä¸Šä¸‹æ–‡é•¿åº¦ï¼‰    \né“¾æ¥æºï¼šhttps://github.com/OpenAccess-AI-Collective/axolotl/pull/1567\n\n## äº¤æµ & è®¨è®ºæŠ€æœ¯\n\n| åç§° | ç¾¤èŠäºŒç»´ç  | åç§° | ç¾¤èŠäºŒç»´ç  | \n|---------|---------|---------|---------|\n| llama3 ä¸­æ–‡äº¤æµQQç¾¤ | <img width=\"260\" src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/83a3d1e9-d1ae-4eed-91b5-20589407581e\"> | ä¼˜è´¨ä¸­æ–‡æ•°æ®æ•´ç†å»ºè®¾ç¾¤ | <img width=\"260\" src=\"https://github.com/CrazyBoyM/llama3-Chinese-chat/assets/35400185/77110656-0a87-419c-a21f-29bf1c2ca22b\"> | \n\nåé¢æˆ‘ä¹Ÿä¼šåœ¨bç«™å½•åˆ¶ç›¸å…³æ¨¡å‹éƒ¨ç½²æ¨ç†ã€è®­ç»ƒçš„æ¼”ç¤ºæ•™ç¨‹è§†é¢‘ï¼Œæˆ‘çš„ä¸ªäººbç«™ï¼šhttps://space.bilibili.com/291593914  \n\n## äº‹é¡¹æ¸…å•\n- [x] base + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹ v1\n- [x] base + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹ v2\n- [x] instruct + sft llama3 ä¸­æ–‡ç‰ˆæ¨¡å‹\n- [x] è®­ç»ƒä¸æ¨ç†æ•™ç¨‹ \n- [x] æ¨¡å‹é‡åŒ–éƒ¨ç½²æ”¯æŒã€æ¨ç†æ•™ç¨‹\n- [x] æ¨¡å‹ollamaæ”¯æŒã€æ¨ç†æ•™ç¨‹\n- [x] æ¨¡å‹vllmæ”¯æŒã€æ¨ç†æ•™ç¨‹\n- [x] ç”µè„‘æœ¬åœ°cpuè·‘æ¨¡å‹\n- [ ] æ‰‹æœºç«¯æ¨ç†æ¨¡å‹\n- [x] æ‰©å……ä¼˜è´¨è®­ç»ƒæ•°æ®é›†\n- [x] æ‰©å……ä¸Šä¸‹æ–‡é•¿åº¦\n- [ ] è§’è‰²æ‰®æ¼”å¢å¼ºæ¨¡å‹\n- [x] agentå·¥å…·è°ƒç”¨èƒ½åŠ›å¢å¼ºæ¨¡å‹\n- [ ] ... \n\n## QA\né—®ï¼šè¯è¡¨æ‰©å……äº†å—ï¼Ÿ  \nç­”ï¼šæ²¡ï¼Œllama3è‡ªèº«çš„è¯è¡¨å·²ç»æœ‰128käº†ï¼ˆllama2åªæœ‰32k)ï¼Œæ‰©å……å†å¢é‡é¢„è®­ç»ƒè¯è¡¨ä¼šæŸåå®˜æ–¹çš„15Tå……åˆ†é¢„è®­ç»ƒæ—¶å­¦åˆ°çš„é€šç”¨èƒ½åŠ›ã€‚  \nå¦å¤–åœ¨llama2ä¸Šä¸€ç³»åˆ—æ‰©å……äº†è¯è¡¨çš„æ¨¡å‹è¡¨ç°ä¹Ÿå¹¶ä¸ä¼˜ç§€ã€‚ä½œè€…è¿™é‡Œå¸Œæœ›å¤§å®¶æ›´å¤šå…³æ³¨åœ¨ä¼˜è´¨æ•°æ®é›†ä»»åŠ¡ä¸Šï¼Œæ¨¡å‹å¯ä»¥é¢‘ç¹å‘ç‰ˆã€æ¢ä»£ï¼Œæ•°æ®æ‰æ˜¯æ ¸å¿ƒã€‚  \nå¤§å‚çš„æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šéšä¾¿é—®éƒ½å›ç­”å¾ˆå¥½å¯¹å§ï¼Ÿå› ä¸ºå‚å•†å½¢æˆäº†æ•°æ®é£è½®å’Œä¼˜è´¨æ•°æ®é—­ç¯ã€‚è€Œå¤–éƒ¨çš„ç ”ç©¶è€…è¿˜åœ¨å…³å¿ƒå„ç§è™šçš„å†…å®¹å’ŒæŒ‡æ ‡æ•…äº‹ã€‚  \nllama3å…¶å®æœ¬èº«ä¸­æ–‡èƒ½åŠ›å°±å¾ˆå¼ºï¼Œäººä»¬è¯´ä¸å¼ºçš„çŸ¥è¯†å› ä¸ºåœ¨çº¿ä½“éªŒllama3é‚£äº›ç½‘ç«™çš„å†…éƒ¨systemæç¤ºè¯éƒ½æ˜¯è‹±æ–‡å†™çš„ï¼Œä¸ä¿¡å¯ä»¥è‡ªå·±æ‹‰llama instruct 8bã€70båŸç‰ˆåˆ°æœ¬åœ°éƒ¨ç½²è¯•è¯•ã€‚  \nåªéœ€è¦åœ¨systemå†™ä¸Šä½ æ˜¯ä¸ªâ€œä¸­æ–‡æ™ºè€…â€ ï¼ˆç½‘å‹å‘ç°çš„ï¼‰åé¢ä¸­æ–‡é—®ç­”ä½“éªŒä¼šæ‰æ‰“å„ç§base + ä¸­æ–‡æ•°æ®çš„ç²—ç³™sftç‰ˆæœ¬ã€‚ï¼ˆå› ä¸ºå®˜æ–¹sftã€ppoã€dpoåšçš„å®åœ¨å¤ªä¼˜ç§€äº†ï¼‰  \nå½“ç„¶å¤è¯—è¯æ–‡å­¦çŸ¥è¯†ã€å¤ä»£çŸ¥è¯†ã€ä¸­æ–‡å¸¸è¯†çš„æ³¨å…¥ï¼Œè¿˜æ˜¯éœ€è¦å¢é‡é¢„è®­ç»ƒ + sftçš„å®šåˆ¶åŠ å¼ºï¼Œå»ºè®®å¤§å®¶å°±åˆ«æ‰©è¯è¡¨äº†ï¼Œç›´æ¥å¾€è¿™ä¸ªä¸­æ–‡çŸ¥è¯†æ·±åº¦æ³¨å…¥çš„æ–¹å‘åŠªåŠ›ã€‚è¦èƒ½æ„¿æ„å¼€æºæ•°æ®å°±æ›´å¥½äº†  \n\né—®ï¼šä¸ºä»€ä¹ˆè¿™ä¹ˆå¿«è®­ç»ƒllama3ä¸­æ–‡ç‰ˆï¼Ÿ  \nç­”ï¼šæ™šä¸Šç¡å¾—æ™šï¼Œåˆšå¥½çœ‹åˆ°llama3æƒé‡åˆšåˆšå¼€æºå‡ ååˆ†é’Ÿï¼Œå°±æ¯”è¾ƒå…´å¥‹åœ°æ‹‰å–äº†æƒé‡æ–‡ä»¶ï¼Œçœ‹äº†ä¸‹ç½‘ç»œç»“æ„æ²¡å˜ï¼Œ  \nå»å¹´åˆæœ‰é¦–å‘llama2ä¸­æ–‡ç‰ˆçš„ç»éªŒï¼Œå°±è½»è½¦ç†Ÿè·¯ç”¨å»å¹´çš„ä¸œè¥¿å’Œç¯å¢ƒé…ç½®ç›´æ¥å¿«é€Ÿå¼€ç»ƒäº†ã€‚\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=CrazyBoyM/llama3-Chinese-chat&type=Date)](https://star-history.com/#CrazyBoyM/llama3-Chinese-chat&Date)\n"
        },
        {
          "name": "deploy",
          "type": "tree",
          "content": null
        },
        {
          "name": "learn",
          "type": "tree",
          "content": null
        },
        {
          "name": "task",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "train",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}