{
  "metadata": {
    "timestamp": 1736559951262,
    "page": 727,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjczMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pytorch/text",
      "stars": 3524,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 2.3740234375,
          "content": "---\nAccessModifierOffset: -1\nAlignAfterOpenBracket: AlwaysBreak\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlinesLeft: true\nAlignOperands: false\nAlignTrailingComments: false\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Empty\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: false\nBinPackParameters: false\nBraceWrapping:\n  AfterClass: false\n  AfterControlStatement: false\n  AfterEnum: false\n  AfterFunction: false\n  AfterNamespace: false\n  AfterObjCDeclaration: false\n  AfterStruct: false\n  AfterUnion: false\n  BeforeCatch: false\n  BeforeElse: false\n  IndentBraces: false\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: false\nColumnLimit: 80\nCommentPragmas: \"^ IWYU pragma:\"\nCompactNamespaces: false\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat: false\nForEachMacros: [FOR_EACH_RANGE, FOR_EACH]\nIncludeCategories:\n  - Regex: '^<.*\\.h(pp)?>'\n    Priority: 1\n  - Regex: \"^<.*\"\n    Priority: 2\n  - Regex: \".*\"\n    Priority: 3\nIndentCaseLabels: true\nIndentWidth: 2\nIndentWrappedFunctionNames: false\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: \"\"\nMacroBlockEnd: \"\"\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: false\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 2000000\nPointerAlignment: Left\nReflowComments: true\nSortIncludes: true\nSpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles: false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard: Cpp11\nTabWidth: 8\nUseTab: Never\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.318359375,
          "content": "[flake8]\nignore =\n    E401,E402,E501,E722,W503,W504,F821,B006,B007,B008,B009,\n    # https://github.com/PyCQA/pycodestyle/issues/373\n    E203\nselect =\n    B,C,E,F,P,T4,W,B9,\n    # Missing argument descriptions in the docstring\n    D417,\n    # TorchFix\n    TOR0,TOR1,TOR2\nmax-line-length = 120\nexclude = docs/source,third_party\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.09375,
          "content": "# To exclude autogenerated files from code reviews\n.circleci/config.yml linguist-generated=true\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.609375,
          "content": "*.txt\n*.zip\n*~\n.vector_cache\n.idea/\n\n# Documentation\ndocs/build\n\n# Download folder\n.data\n\n# Created by https://www.gitignore.io/api/python\n\n### Python ###\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\ndocs/src/\ndocs/source/tutorials\ndocs/source/gen_modules\n\n# PyBuilder\ntarget/\n\n# computed checksum files\ntorchtext/experimental/asset/.checksums/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule.*\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# VSCode project settings\n.vscode\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# End of https://www.gitignore.io/api/python\n\n# vim\n*.swp\n*.swo\n\ntorchtext/version.py\n\n# Thirdparty directories\nthird_party/*/\n\n# Mac OS .DS_Store files\n.DS_Store\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.4931640625,
          "content": "[submodule \"third_party/sentencepiece\"]\n\tpath = third_party/sentencepiece\n\turl = https://github.com/google/sentencepiece\n\tignore = dirty\n[submodule \"third_party/re2\"]\n\tpath = third_party/re2\n\turl = https://github.com/google/re2\n\tignore = dirty\n[submodule \"third_party/double-conversion\"]\n\tpath = third_party/double-conversion\n\turl = https://github.com/google/double-conversion\n\tignore = dirty\n[submodule \"third_party/utf8proc\"]\n\tpath = third_party/utf8proc\n\turl = https://github.com/JuliaStrings/utf8proc\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.828125,
          "content": "default_language_version:\n  node: 16.14.2\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.0.1\n    hooks:\n      - id: trailing-whitespace\n      - id: mixed-line-ending\n        args:\n          - --fix=lf\n      - id: end-of-file-fixer\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v2.5.1\n    hooks:\n      - id: prettier\n        types_or:\n          - markdown\n          - toml\n          - yaml\n\n  - repo: https://github.com/omnilib/ufmt\n    rev: v1.3.1\n    hooks:\n      - id: ufmt\n        additional_dependencies:\n          - black == 21.4b2\n          - usort == 0.6.4\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 4.0.1\n    hooks:\n      - id: flake8\n        additional_dependencies:\n          - flake8-docstrings == 1.6.0\n          - torchfix == 0.0.2\n        args:\n          - --config=.flake8\n"
        },
        {
          "name": ".prettierignore",
          "type": "blob",
          "size": 0.0322265625,
          "content": "packaging/*\n.circleci/config.yml\n"
        },
        {
          "name": ".prettierrc.yaml",
          "type": "blob",
          "size": 0.033203125,
          "content": "proseWrap: always\nprintWidth: 120\n"
        },
        {
          "name": ".python3",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "CMakeLists.txt",
          "type": "blob",
          "size": 2.453125,
          "content": "cmake_minimum_required(VERSION 3.18 FATAL_ERROR)\n\n# Most of the configurations are taken from PyTorch\n# https://github.com/pytorch/pytorch/blob/0c9fb4aff0d60eaadb04e4d5d099fb1e1d5701a9/CMakeLists.txt\n\n# Use compiler ID \"AppleClang\" instead of \"Clang\" for XCode.\n# Not setting this sometimes makes XCode C compiler gets detected as \"Clang\",\n# even when the C++ one is detected as \"AppleClang\".\ncmake_policy(SET CMP0010 NEW)\ncmake_policy(SET CMP0025 NEW)\n\n# Suppress warning flags in default MSVC configuration.  It's not\n# mandatory that we do this (and we don't if cmake is old), but it's\n# nice when it's possible, and it's possible on our Windows configs.\nif(NOT CMAKE_VERSION VERSION_LESS 3.15.0)\n  cmake_policy(SET CMP0092 NEW)\nendif()\n\nproject(torchtext)\n\n\n# check and set CMAKE_CXX_STANDARD\nstring(FIND \"${CMAKE_CXX_FLAGS}\" \"-std=c++\" env_cxx_standard)\nif(env_cxx_standard GREATER -1)\n  message(\n      WARNING \"C++ standard version definition detected in environment variable.\"\n      \"PyTorch requires -std=c++17. Please remove -std=c++ settings in your environment.\")\nendif()\n\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_C_STANDARD 11)\n\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n\n# Apple specific\nif(APPLE)\n  # Get clang version on macOS\n  execute_process( COMMAND ${CMAKE_CXX_COMPILER} --version OUTPUT_VARIABLE clang_full_version_string )\n  string(REGEX REPLACE \"Apple LLVM version ([0-9]+\\\\.[0-9]+).*\" \"\\\\1\" CLANG_VERSION_STRING ${clang_full_version_string})\n  message( STATUS \"CLANG_VERSION_STRING:         \" ${CLANG_VERSION_STRING} )\n\n  # RPATH stuff\n  set(CMAKE_MACOSX_RPATH ON)\n\n  set(CMAKE_SHARED_LIBRARY_SUFFIX \".so\")\nendif()\n\n# Options\noption(BUILD_TORCHTEXT_PYTHON_EXTENSION \"Build Python extension\" OFF)\n\nset(CMAKE_MODULE_PATH \"${CMAKE_MODULE_PATH};${CMAKE_CURRENT_SOURCE_DIR}/cmake\")\nset(TORCH_INSTALL_PREFIX \"${CMAKE_PREFIX_PATH}/../..\" CACHE STRING \"Install path for torch\")\nset(TORCH_COMPILED_WITH_CXX_ABI \"-D_GLIBCXX_USE_CXX11_ABI=0\" CACHE STRING \"Compile torchtext with cxx11_abi\")\n\nfind_library(TORCH_C10_LIBRARY c10 PATHS \"${TORCH_INSTALL_PREFIX}/lib\")\nfind_library(TORCH_LIBRARY torch PATHS \"${TORCH_INSTALL_PREFIX}/lib\")\nfind_library(TORCH_CPU_LIBRARY torch_cpu PATHS \"${TORCH_INSTALL_PREFIX}/lib\")\n\nif(MSVC)\n  set(CMAKE_MSVC_RUNTIME_LIBRARY \"MultiThreaded$<$<CONFIG:Debug>:Debug>\")\nendif()\n\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} ${TORCH_COMPILED_WITH_CXX_ABI} -Wall ${TORCH_CXX_FLAGS}\")\n\nadd_subdirectory(third_party)\nadd_subdirectory(torchtext/csrc)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2646484375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make\nparticipation in our project and our community a harassment-free experience for everyone, regardless of age, body size,\ndisability, ethnicity, sex characteristics, gender identity and expression, level of experience, education,\nsocio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or electronic address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take\nappropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits,\nissues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any\ncontributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when an individual is representing the\nproject or its community in public spaces. Examples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting as an appointed representative at an\nonline or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at\n<conduct@pytorch.org>. All complaints will be reviewed and investigated and will result in a response that is deemed\nnecessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to\nthe reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent\nrepercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at\nhttps://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 6.0478515625,
          "content": "# Contributing to text\n\nWe want to make contributing to this project as easy and transparent as possible.\n\n## Pull Requests\n\nWe actively welcome your pull requests.\n\n1. Fork the repo and create your branch from `main`.\n2. If you've added code that should be tested, add tests.\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n### Code style\n\n`torchtext` enforces a fairly strict code format for Python, text, and configuration files through\n[`pre-commit`](https://pre-commit.com). You can install it with\n\n```shell\npip install pre-commit\n```\n\nor\n\n```shell\nconda install -c conda-forge pre-commit\n```\n\nTo check and in most cases fix the code format, stage all your changes (`git add`) and execute `pre-commit run`. To\nperform the checks automatically before every `git commit`, you can install the checks as hooks with\n`pre-commit install`.\n\nIn addition, `torchtext` also enforces a fairly strict code format for C++ files through a custom version of\n[`clang-format`](https://clang.llvm.org/docs/ClangFormat.html). You can download it from\n\n- https://oss-clang-format.s3.us-east-2.amazonaws.com/mac/clang-format-mojave\n- https://oss-clang-format.s3.us-east-2.amazonaws.com/linux64/clang-format-linux64\n\ndepending on your platform. To run the formatter, make the binary executable (`chmod +x`) and execute\n\n```shell\npython run-clang-format.py \\\n    --recursive \\\n    --clang-format-executable=$CLANG_FORMAT \\\n    torchtext/csrc\n```\n\nwhere `$CLANG_FORMAT` denotes the path to the downloaded binary.\n\n## Adding Third Party Libraries\n\nThe following steps outline how to add third party libraries to torchtext. We assume that the third party library has\ncorrectly setup their `CMakeLists.txt` file for other libraries to take a dependency on.\n\n1. Add the third party library as a submodule. Here is a great\n   [tutorial](https://www.atlassian.com/git/tutorials/git-submodule) on working with submodules in git.\n   - Navigate to `third_party/` folder and run `git submodule add <repo-URL>`\n   - Verify the newly added module is present in the\n     [`.gitmodules`](https://github.com/pytorch/text/blob/main/.gitmodules) file\n2. Update\n   [`third_party/CMakeLists.txt`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/third_party/CMakeLists.txt#L8)\n   to add the following line: `add_subdirectory(<name-of-submodule-folder> EXCLUDE_FROM_ALL)`\n3. (Optional) If any of the files within the `csrc/` folder make use of the newly added third party library then\n   - Add the new submodule folder to\n     [`​​LIBTORCHTEXT_INCLUDE_DIRS`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/CMakeLists.txt#L24)\n     and to\n     [`EXTENSION_INCLUDE_DIRS`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/CMakeLists.txt#L119)\n   - Add the \"targets\" name defined by the third party library's `CMakeLists.txt` file to\n     [`LIBTORCHTEXT_LINK_LIBRARIES`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/CMakeLists.txt#L33)\n   - Note that the third party libraries are linked statically with torchtext\n4. Verify the torchtext build works by running `python setup.py develop`\n\n## Adding a Custom C++ Operator\n\nCustom C++ operators can be implemented and registered in torchtext for several reasons including to make an existing\nPython component more efficient, and to get around the limitations when working with multithreading in Python (due to\nthe Global Interpreter Lock). These custom kernels (or “ops”) can be embedded into a TorchScripted model and can be\nexecuted both in Python and in their serialized form directly in C++. You can learn more in this\n[tutorial on writing custom C++ operators](https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html)\n\nSteps to register an operator:\n\n1. Add the new custom operator to the [`torchtext/csrc`](https://github.com/pytorch/text/tree/main/torchtext/csrc)\n   folder. This entails writing the header and the source file for the custom op.\n2. Add the new source files to the\n   [`LIBTORCHTEXT_SOURCES`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/CMakeLists.txt#L11)\n   list.\n3. Register the operators with torchbind and pybind\n   - Torchbind registration happens in the\n     [`register_torchbindings.cpp`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/register_torchbindings.cpp#L14)\n     file\n   - Pybind registration happens in the\n     [`register_pybindings.cpp`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/csrc/register_pybindings.cpp#L34)\n     file.\n4. Write a Python wrapper class that is responsible for exposing the torchbind/pybind registered operators via Python.\n   You can find some examples of this in the\n   [`torchtext/transforms.py`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/torchtext/transforms.py#L274)\n   file.\n5. Write a unit test that tests the functionality of the operator through the Python wrapper class. You can find some\n   examples in the\n   [`test/test_transforms.py`](https://github.com/pytorch/text/blob/70fc1040ee40faf129604557107cc59fd51c4fe2/test/test_transforms.py#L317)\n   file.\n\n## Contributor License Agreement (\"CLA\")\n\nIn order to accept your pull request, we need you to submit a CLA. You only need to do this once to work on any of\nFacebook's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\n\nWe use GitHub issues to track public bugs. Please ensure your description is clear and has sufficient instructions to be\nable to reproduce the issue.\n\nFacebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe disclosure of security bugs. In those\ncases, please go through the process outlined on that page and do not file a public issue.\n\n## License\n\nBy contributing to text, you agree that your contributions will be licensed under the LICENSE file in the root directory\nof this source tree.\n"
        },
        {
          "name": "CONTRIBUTING_DATASETS.md",
          "type": "blob",
          "size": 8.75,
          "content": "# Guidelines for adding new dataset\n\n## Background\n\nTorchtext datasets are based on and are built using composition of TorchData’s DataPipes.\n[TorchData](https://github.com/pytorch/data) is a library that provides modular/composable primitives, allowing users to\nload and transform data in performant data pipelines. With DataPipes, users can easily do data manipulation and\npreprocessing using user-defined functions and transformations in a functional style programming. Datasets backed by\nDataPipes also enable standard flow-control like batching, collation, shuffling and bucketizing. Collectively, DataPipes\nprovides a comprehensive experience for data preprocessing and tensorization needs in a Pythonic and flexible way for\nmodel training.\n\nFor reference, datasets have been migrated from older-style Iterable Datasets to TorchData’s DataPipes in version 0.12.\nYou can follow more details in this [github issue](https://github.com/pytorch/text/issues/1494)\n\n## Developers guide\n\n### Before you begin\n\nIt’s great that you would like to contribute a new dataset to the repository, we love contributions! But there are few\nthings to take into account.\n\n- `Dataset Hosting:` Please note that torchtext does not host or provide any hosting services for datasets. It simply\n  provides a Dataset API contract to make it easy for end users to consume the dataset from its original source.\n- `Dataset Relevance:` Although there are no strict guidelines on what can and cannot be part of the library, we think\n  that it is very important to take the dataset relevance into account before adding it to the repository. Some of the\n  reference points may include:\n  - Whether the dataset provide a good reference benchmarks for any given NLP/Multi-Modal related tasks\n  - Number of citations received by the dataset\n  - Community needs\n- `Licensing concerns:` Last, but not least, make sure there are no licensing concerns over providing access to the\n  dataset through torchtext’s datasets API. We have a disclaimer\n  [here](https://github.com/pytorch/text#disclaimer-on-datasets) on this too.\n\nIf you have any questions or concerns, do not hesitate to open a github issue for seeking feedback from community and\ntorchtext’s library maintainers.\n\n### Let’s get started!\n\n#### Functional API\n\nTorchText’s datasets API are all functional. To write a new dataset, create the file for the corresponding dataset in\nthe datasets directory and create the function with `root` as the first argument. The `root` directory is the one used\nto cache the dataset. If the dataset consists of splits (`train`, `test`, `val`, `dev` etc), follow `root` by another\nkeyword argument called `split`. Provide any additional keyword arguments necessary to implement the dataset. Add\nfollowing decorators to your function:\n\n- `@_create_dataset_directory:` This decorator will create an appropriate directory in the `root` directory to download\n  and cache the dataset.\n- `@_wrap_split_argument:` If the dataset consists of split arguments, add this decorator. It will allow the users to\n  pass a split argument either as `tuple` or `str`.\n\nSample code to add function definition:\n\n```python\nDATASET_NAME = \"MyDataName\"\n\n@_create_dataset_directory(dataset_name=DATASET_NAME)\n@_wrap_split_argument((\"train\", “dev”,\"test\"))\ndef MyDataName(root: str, split: Union[Tuple[str], str], …):\n    …\n```\n\nTo make the dataset importable through the torchtext’s datasets package, add it to the datasets `__init__.py` file.\n\n### Dataset Implementation\n\nBuilding datasets using DataPipes is fun! One just needs to think in terms of various primitive components and\nabstractions that are necessary to compose the stack. A typical workflow may look like this:\n\nData download (+Caching) -> Hash check -> Extraction (+Caching) ->File parsing -> Data organization -> Dataset samples.\n\nWe already have a healthy collection of dataset implementations based on DataPipes. It provides a great starter guide to\nimplement new dataset since they share many of the components. For reference, it is highly recommended to look at some\nof these existing datasets implementations. Furthermore, please refer to official torchdata\n[documentation](https://pytorch.org/data/beta/index.html) to learn more about available\n[Iterable Style DataPipes](https://pytorch.org/data/beta/torchdata.datapipes.iter.html).\n\nBelow we provide a bit more details on what each of these components are and how to realize them using DataPipes.\n\n#### Download from source\n\nTypically the first step is to download the dataset from the host to the local machine. The dataset may be present on\ndifferent stores like Google Drive, AWS S3 etc and may require different reading mechanisms. TorchData implements a\nnumber of commonly downloading mechanisms like HTTPReader and GDriveReader and can be used for data download. Refer to\nthe [IO Data Pipes](https://pytorch.org/data/beta/torchdata.datapipes.iter.html#io-datapipes) section for more details.\n\n#### Dataset cache\n\nDownloading data is expensive! Hence it is important to cache the data on disk (unless it is implemented as a streaming\nDataset). TorchData provides\n[OnDiskCashHolder](https://pytorch.org/data/beta/generated/torchdata.datapipes.iter.OnDiskCacheHolder.html#torchdata.datapipes.iter.OnDiskCacheHolder)\nand\n[EndofDiskCashHolder](https://pytorch.org/data/beta/generated/torchdata.datapipes.iter.EndOnDiskCacheHolder.html#torchdata.datapipes.iter.EndOnDiskCacheHolder)\nDataPipes to facilitate caching. In short, the datapipe checks whether the file is already available on the local\nfilesystem and shall trigger download only when it is not present. It is quite important to use caching, otherwise the\ndata will be downloaded at every epoch. The Datapipe also facilitates data integrity check via hash checking. It is\nrecommended to do this to ensure that we do not silently ignore changes made in the hosted dataset.\n\n#### Unarchiving and caching compressed files\n\nTypically, the dataset is often stored in archived (zip, tar etc) form. TorchData provides a number of utility datapipe\nto uncompress the datasets. Check the available\n[archive DataPipes](https://pytorch.org/data/beta/torchdata.datapipes.iter.html#archive-datapipes) to use them in your\ndataset implementation. Furthermore, it is also highly recommended to use a caching mechanism (similar to caching\ndownloaded files) to ensure that data is not decompressed at every epoch. Note that it is not necessary to use hash\ncheck for caching decompressed file(s), since it is already done for compressed file(s).\n\n#### Reading from files\n\nData is often saved in text files with different structures/formatting like CSV, JSON etc. TorchData provides a number\nof standard [text file reading utilities](https://pytorch.org/data/beta/torchdata.datapipes.iter.html#text-datapipes)\nthat can be conveniently stacked on top of previous IO Stream pipes like\n[FileOpener](https://pytorch.org/data/beta/generated/torchdata.datapipes.iter.FileOpener.html#torchdata.datapipes.iter.FileOpener)\nthat yield data streams.\n\n#### Data organization and returning dataset samples as tuples\n\nIn torchtext we follow the convention that samples are returned as tuples. For instance, the samples from classification\ndatasets are returned as tuples of (int, str) that store labels and text respectively. Similarly for translation dataset\nthey are tuples of (str, str) that store source and target sentences.\n\n#### Add support for data shuffle and sharding\n\nFinally add support data shuffling and sharding across ranks during distributed training and multi-processing. Follow\nthis [issue](https://github.com/pytorch/text/issues/1727) for additional details.\n\n### Testing\n\nWe use mocking to implement end-2-end testing for the implemented dataset. We avoid testing using a real dataset since\nit is expensive to download and/or cache the dataset for testing purposes.\n\nTo implement the dataset test, create the corresponding testing file `test_<datasetname>.py` under `tests/datasets`\ndirectory. Do the following:\n\n- Create a function `_get_mock_dataset` that writes a replica of the dataset (albeit with a much smaller number of\n  samples, typically 10) in a temporary directory and returns the dataset samples for comparison during testing\n- Create the dataset test class `Test<DataSetName>` that tests implementation on following two accounts:\n  - Samples returned on iterating over the dataset\n  - Dataset returned by passing split argument as `tuple` and as `str`\n\nFor detailed examples on how to write the test, please follow the existing test suite under `tests/datasets` directory.\n\nFor additional reference, you may also refer to [github issue #1493](https://github.com/pytorch/text/issues/1493) where\nwe migrated testing of all the datasets from real datasets (that were cached) to mocked one.\n\n### Contribute\n\nSimply create the PR and the torchtext team will help with reviews and get it landed on to the main branch!\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4990234375,
          "content": "BSD 3-Clause License\n\nCopyright (c) James Bradbury and Soumith Chintala 2016,\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 7.041015625,
          "content": ".. image:: docs/source/_static/img/torchtext_logo.png\n\n.. image:: https://circleci.com/gh/pytorch/text.svg?style=svg\n    :target: https://circleci.com/gh/pytorch/text\n\n.. image:: https://codecov.io/gh/pytorch/text/branch/main/graph/badge.svg\n    :target: https://codecov.io/gh/pytorch/text\n\n.. image:: https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Ftorchtext%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v\n    :target: https://pytorch.org/text/\n\ntorchtext\n+++++++++\n\n**WARNING**: TorchText development is stopped and the `0.18` release (April 2024) will be the last stable release of the library.\n\nThis repository consists of:\n\n* `torchtext.datasets <https://github.com/pytorch/text/tree/main/torchtext/datasets>`_: The raw text iterators for common NLP datasets\n* `torchtext.data <https://github.com/pytorch/text/tree/main/torchtext/data>`_: Some basic NLP building blocks\n* `torchtext.transforms <https://github.com/pytorch/text/tree/main/torchtext/transforms.py>`_: Basic text-processing transformations\n* `torchtext.models <https://github.com/pytorch/text/tree/main/torchtext/models>`_: Pre-trained models\n* `torchtext.vocab <https://github.com/pytorch/text/tree/main/torchtext/vocab>`_: Vocab and Vectors related classes and factory functions\n* `examples <https://github.com/pytorch/text/tree/main/examples>`_: Example NLP workflows with PyTorch and torchtext library.\n\n\nInstallation\n============\n\nWe recommend Anaconda as a Python package management system. Please refer to `pytorch.org <https://pytorch.org/>`_ for the details of PyTorch installation. The following are the corresponding ``torchtext`` versions and supported Python versions.\n\n.. csv-table:: Version Compatibility\n   :header: \"PyTorch version\", \"torchtext version\", \"Supported Python version\"\n   :widths: 10, 10, 10\n\n   nightly build, main, \">=3.8, <=3.11\"\n   2.3.0, 0.18.0, \">=3.8, <=3.11\"\n   2.2.0, 0.17.0, \">=3.8, <=3.11\"\n   2.1.0, 0.16.0, \">=3.8, <=3.11\"\n   2.0.0, 0.15.0, \">=3.8, <=3.11\"\n   1.13.0, 0.14.0, \">=3.7, <=3.10\"\n   1.12.0, 0.13.0, \">=3.7, <=3.10\"\n   1.11.0, 0.12.0, \">=3.6, <=3.9\"\n   1.10.0, 0.11.0, \">=3.6, <=3.9\"\n   1.9.1, 0.10.1, \">=3.6, <=3.9\"\n   1.9, 0.10, \">=3.6, <=3.9\"\n   1.8.1, 0.9.1, \">=3.6, <=3.9\"\n   1.8, 0.9, \">=3.6, <=3.9\"\n   1.7.1, 0.8.1, \">=3.6, <=3.9\"\n   1.7, 0.8, \">=3.6, <=3.8\"\n   1.6, 0.7, \">=3.6, <=3.8\"\n   1.5, 0.6, \">=3.5, <=3.8\"\n   1.4, 0.5, \"2.7, >=3.5, <=3.8\"\n   0.4 and below, 0.2.3, \"2.7, >=3.5, <=3.8\"\n\nUsing conda::\n\n    conda install -c pytorch torchtext\n\nUsing pip::\n\n    pip install torchtext\n\nOptional requirements\n---------------------\n\nIf you want to use English tokenizer from `SpaCy <http://spacy.io/>`_, you need to install SpaCy and download its English model::\n\n    pip install spacy\n    python -m spacy download en_core_web_sm\n\nAlternatively, you might want to use the `Moses <http://www.statmt.org/moses/>`_ tokenizer port in `SacreMoses <https://github.com/alvations/sacremoses>`_ (split from `NLTK <http://nltk.org/>`_). You have to install SacreMoses::\n\n    pip install sacremoses\n\nFor torchtext 0.5 and below, ``sentencepiece``::\n\n    conda install -c powerai sentencepiece\n\nBuilding from source\n--------------------\n\nTo build torchtext from source, you need ``git``, ``CMake`` and C++11 compiler such as ``g++``.::\n\n    git clone https://github.com/pytorch/text torchtext\n    cd torchtext\n    git submodule update --init --recursive\n\n    # Linux\n    python setup.py clean install\n\n    # OSX\n    CC=clang CXX=clang++ python setup.py clean install\n\n    # or ``python setup.py develop`` if you are making modifications.\n\n**Note**\n\nWhen building from source, make sure that you have the same C++ compiler as the one used to build PyTorch. A simple way is to build PyTorch from source and use the same environment to build torchtext.\nIf you are using the nightly build of PyTorch, checkout the environment it was built with `conda (here) <https://github.com/pytorch/builder/tree/main/conda>`_ and `pip (here) <https://github.com/pytorch/builder/tree/main/manywheel>`_.\n\nAdditionally, datasets in torchtext are implemented using the torchdata library. Please take a look at the\n`installation instructions <https://github.com/pytorch/data#installation>`_ to download the latest nightlies or install from source.\n\nDocumentation\n=============\n\nFind the documentation `here <https://pytorch.org/text/>`_.\n\nDatasets\n========\n\nThe datasets module currently contains:\n\n* Language modeling: WikiText2, WikiText103, PennTreebank, EnWik9\n* Machine translation: IWSLT2016, IWSLT2017, Multi30k\n* Sequence tagging (e.g. POS/NER): UDPOS, CoNLL2000Chunking\n* Question answering: SQuAD1, SQuAD2\n* Text classification: SST2, AG_NEWS, SogouNews, DBpedia, YelpReviewPolarity, YelpReviewFull, YahooAnswers, AmazonReviewPolarity, AmazonReviewFull, IMDB\n* Model pre-training: CC-100\n\nModels\n======\n\nThe library currently consist of following pre-trained models:\n\n* RoBERTa: `Base and Large Architecture <https://github.com/pytorch/fairseq/tree/main/examples/roberta#pre-trained-models>`_\n* `DistilRoBERTa <https://github.com/huggingface/transformers/blob/main/examples/research_projects/distillation/README.md>`_\n* XLM-RoBERTa: `Base and Large Architure <https://github.com/pytorch/fairseq/tree/main/examples/xlmr#pre-trained-models>`_\n* T5: `Small, Base, Large, 3B, and 11B Architecture <https://github.com/google-research/text-to-text-transfer-transformer>`_\n* Flan-T5: `Base, Large, XL, and XXL Architecture <https://github.com/google-research/t5x>`_\n\nTokenizers\n==========\n\nThe transforms module currently support following scriptable tokenizers:\n\n* `SentencePiece <https://github.com/google/sentencepiece>`_\n* `GPT-2 BPE <https://github.com/openai/gpt-2/blob/master/src/encoder.py>`_\n* `CLIP <https://github.com/openai/CLIP/blob/main/clip/simple_tokenizer.py>`_\n* `RE2 <https://github.com/google/re2>`_\n* `BERT <https://arxiv.org/pdf/1810.04805.pdf>`_\n\nTutorials\n=========\n\nTo get started with torchtext, users may refer to the following tutorial available on PyTorch website.\n\n* `SST-2 binary text classification using XLM-R pre-trained model <https://pytorch.org/text/stable/tutorials/sst2_classification_non_distributed.html>`_\n* `Text classification with AG_NEWS dataset <https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html>`_\n* `Translation trained with Multi30k dataset using transformers and torchtext <https://pytorch.org/tutorials/beginner/translation_transformer.html>`_\n* `Language modeling using transforms and torchtext <https://pytorch.org/tutorials/beginner/transformer_tutorial.html>`_\n\n\nDisclaimer on Datasets\n======================\n\nThis is a utility library that downloads and prepares public datasets. We do not host or distribute these datasets, vouch for their quality or fairness, or claim that you have license to use the dataset. It is your responsibility to determine whether you have permission to use the dataset under the dataset's license.\n\nIf you're a dataset owner and wish to update any part of it (description, citation, etc.), or do not want your dataset to be included in this library, please get in touch through a GitHub issue. Thanks for your contribution to the ML community!\n"
        },
        {
          "name": "benchmark",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "notebooks",
          "type": "tree",
          "content": null
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.1005859375,
          "content": "[tool.usort]\n\nfirst_party_detection = false\n\n[tool.black]\n\nline-length = 120\ntarget-version = [\"py37\"]\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.1416015625,
          "content": "[pytest]\naddopts = --ignore-glob=test/torchtext_unittest/datasets/*\ntestpaths = test/\npython_paths = ./\nmarkers =\n    gpu_test: marks cuda tests\n"
        },
        {
          "name": "readthedocs.yml",
          "type": "blob",
          "size": 0.1552734375,
          "content": "build:\n  image: latest\n\npython:\n  version: 3.5\n  setup_py_install: true\n\n# Don't build any extra formats\nformats: []\n\nrequirements_file: docs/requirements.txt\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.4296875,
          "content": "# Progress bars on iterators\ntqdm\n\n# Downloading data and other files\nrequests\n\n# Optional NLP tools\nnltk\nspacy\nsacremoses\ngit+https://github.com/jekbradbury/revtok.git\n\n# Documentation\nSphinx\n\n# Required for tests only:\n\n# Run unit tests\npytest\nexpecttest\nparameterized\n\n# Lets pytest find our code by automatically modifying PYTHONPATH\npytest-pythonpath\n\n# Coverage statistics\npytest-cov\ncodecov\n\n# To parse untrusted XML data\ndefusedxml\n"
        },
        {
          "name": "run-clang-format.py",
          "type": "blob",
          "size": 10.4169921875,
          "content": "#!/usr/bin/env python\n\"\"\"\nMIT License\n\nCopyright (c) 2017 Guillaume Papin\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\nA wrapper script around clang-format, suitable for linting multiple files\nand to use for continuous integration.\n\nThis is an alternative API for the clang-format command line.\nIt runs over multiple files and directories in parallel.\nA diff output is produced and a sensible exit code is returned.\n\n\"\"\"\n\nimport argparse\nimport difflib\nimport fnmatch\nimport multiprocessing\nimport os\nimport signal\nimport subprocess\nimport sys\nimport traceback\nfrom functools import partial\n\ntry:\n    from subprocess import DEVNULL  # py3k\nexcept ImportError:\n    DEVNULL = open(os.devnull, \"wb\")\n\n\nDEFAULT_EXTENSIONS = \"c,h,C,H,cpp,hpp,cc,hh,c++,h++,cxx,hxx,cu\"\n\n\nclass ExitStatus:\n    SUCCESS = 0\n    DIFF = 1\n    TROUBLE = 2\n\n\ndef list_files(files, recursive=False, extensions=None, exclude=None):\n    if extensions is None:\n        extensions = []\n    if exclude is None:\n        exclude = []\n\n    out = []\n    for file in files:\n        if recursive and os.path.isdir(file):\n            for dirpath, dnames, fnames in os.walk(file):\n                fpaths = [os.path.join(dirpath, fname) for fname in fnames]\n                for pattern in exclude:\n                    # os.walk() supports trimming down the dnames list\n                    # by modifying it in-place,\n                    # to avoid unnecessary directory listings.\n                    dnames[:] = [x for x in dnames if not fnmatch.fnmatch(os.path.join(dirpath, x), pattern)]\n                    fpaths = [x for x in fpaths if not fnmatch.fnmatch(x, pattern)]\n                for f in fpaths:\n                    ext = os.path.splitext(f)[1][1:]\n                    if ext in extensions:\n                        out.append(f)\n        else:\n            out.append(file)\n    return out\n\n\ndef make_diff(file, original, reformatted):\n    return list(\n        difflib.unified_diff(\n            original, reformatted, fromfile=f\"{file}\\t(original)\", tofile=f\"{file}\\t(reformatted)\", n=3\n        )\n    )\n\n\nclass DiffError(Exception):\n    def __init__(self, message, errs=None):\n        super().__init__(message)\n        self.errs = errs or []\n\n\nclass UnexpectedError(Exception):\n    def __init__(self, message, exc=None):\n        super().__init__(message)\n        self.formatted_traceback = traceback.format_exc()\n        self.exc = exc\n\n\ndef run_clang_format_diff_wrapper(args, file):\n    try:\n        ret = run_clang_format_diff(args, file)\n        return ret\n    except DiffError:\n        raise\n    except Exception as e:\n        raise UnexpectedError(f\"{file}: {e.__class__.__name__}: {e}\", e)\n\n\ndef run_clang_format_diff(args, file):\n    try:\n        with open(file, encoding=\"utf-8\") as f:\n            original = f.readlines()\n    except OSError as exc:\n        raise DiffError(str(exc))\n    invocation = [args.clang_format_executable, file]\n\n    # Use of utf-8 to decode the process output.\n    #\n    # Hopefully, this is the correct thing to do.\n    #\n    # It's done due to the following assumptions (which may be incorrect):\n    # - clang-format will returns the bytes read from the files as-is,\n    #   without conversion, and it is already assumed that the files use utf-8.\n    # - if the diagnostics were internationalized, they would use utf-8:\n    #   > Adding Translations to Clang\n    #   >\n    #   > Not possible yet!\n    #   > Diagnostic strings should be written in UTF-8,\n    #   > the client can translate to the relevant code page if needed.\n    #   > Each translation completely replaces the format string\n    #   > for the diagnostic.\n    #   > -- http://clang.llvm.org/docs/InternalsManual.html#internals-diag-translation\n\n    try:\n        proc = subprocess.Popen(\n            invocation, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, encoding=\"utf-8\"\n        )\n    except OSError as exc:\n        raise DiffError(f\"Command '{subprocess.list2cmdline(invocation)}' failed to start: {exc}\")\n    proc_stdout = proc.stdout\n    proc_stderr = proc.stderr\n\n    # hopefully the stderr pipe won't get full and block the process\n    outs = list(proc_stdout.readlines())\n    errs = list(proc_stderr.readlines())\n    proc.wait()\n    if proc.returncode:\n        raise DiffError(\n            \"Command '{}' returned non-zero exit status {}\".format(\n                subprocess.list2cmdline(invocation), proc.returncode\n            ),\n            errs,\n        )\n    return make_diff(file, original, outs), errs\n\n\ndef bold_red(s):\n    return \"\\x1b[1m\\x1b[31m\" + s + \"\\x1b[0m\"\n\n\ndef colorize(diff_lines):\n    def bold(s):\n        return \"\\x1b[1m\" + s + \"\\x1b[0m\"\n\n    def cyan(s):\n        return \"\\x1b[36m\" + s + \"\\x1b[0m\"\n\n    def green(s):\n        return \"\\x1b[32m\" + s + \"\\x1b[0m\"\n\n    def red(s):\n        return \"\\x1b[31m\" + s + \"\\x1b[0m\"\n\n    for line in diff_lines:\n        if line[:4] in [\"--- \", \"+++ \"]:\n            yield bold(line)\n        elif line.startswith(\"@@ \"):\n            yield cyan(line)\n        elif line.startswith(\"+\"):\n            yield green(line)\n        elif line.startswith(\"-\"):\n            yield red(line)\n        else:\n            yield line\n\n\ndef print_diff(diff_lines, use_color):\n    if use_color:\n        diff_lines = colorize(diff_lines)\n    sys.stdout.writelines(diff_lines)\n\n\ndef print_trouble(prog, message, use_colors):\n    error_text = \"error:\"\n    if use_colors:\n        error_text = bold_red(error_text)\n    print(f\"{prog}: {error_text} {message}\", file=sys.stderr)\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"--clang-format-executable\",\n        metavar=\"EXECUTABLE\",\n        help=\"path to the clang-format executable\",\n        default=\"clang-format\",\n    )\n    parser.add_argument(\n        \"--extensions\",\n        help=f\"comma separated list of file extensions (default: {DEFAULT_EXTENSIONS})\",\n        default=DEFAULT_EXTENSIONS,\n    )\n    parser.add_argument(\"-r\", \"--recursive\", action=\"store_true\", help=\"run recursively over directories\")\n    parser.add_argument(\"files\", metavar=\"file\", nargs=\"+\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\")\n    parser.add_argument(\n        \"-j\",\n        metavar=\"N\",\n        type=int,\n        default=0,\n        help=\"run N clang-format jobs in parallel (default number of cpus + 1)\",\n    )\n    parser.add_argument(\n        \"--color\", default=\"auto\", choices=[\"auto\", \"always\", \"never\"], help=\"show colored diff (default: auto)\"\n    )\n    parser.add_argument(\n        \"-e\",\n        \"--exclude\",\n        metavar=\"PATTERN\",\n        action=\"append\",\n        default=[],\n        help=\"exclude paths matching the given glob-like pattern(s) from recursive search\",\n    )\n\n    args = parser.parse_args()\n\n    # use default signal handling, like diff return SIGINT value on ^C\n    # https://bugs.python.org/issue14229#msg156446\n    signal.signal(signal.SIGINT, signal.SIG_DFL)\n    try:\n        signal.SIGPIPE\n    except AttributeError:\n        # compatibility, SIGPIPE does not exist on Windows\n        pass\n    else:\n        signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n\n    colored_stdout = False\n    colored_stderr = False\n    if args.color == \"always\":\n        colored_stdout = True\n        colored_stderr = True\n    elif args.color == \"auto\":\n        colored_stdout = sys.stdout.isatty()\n        colored_stderr = sys.stderr.isatty()\n\n    version_invocation = [args.clang_format_executable, \"--version\"]\n    try:\n        subprocess.check_call(version_invocation, stdout=DEVNULL)\n    except subprocess.CalledProcessError as e:\n        print_trouble(parser.prog, str(e), use_colors=colored_stderr)\n        return ExitStatus.TROUBLE\n    except OSError as e:\n        print_trouble(\n            parser.prog,\n            f\"Command '{subprocess.list2cmdline(version_invocation)}' failed to start: {e}\",\n            use_colors=colored_stderr,\n        )\n        return ExitStatus.TROUBLE\n\n    retcode = ExitStatus.SUCCESS\n    files = list_files(\n        args.files, recursive=args.recursive, exclude=args.exclude, extensions=args.extensions.split(\",\")\n    )\n\n    if not files:\n        return\n\n    njobs = args.j\n    if njobs == 0:\n        njobs = multiprocessing.cpu_count() + 1\n    njobs = min(len(files), njobs)\n\n    if njobs == 1:\n        # execute directly instead of in a pool,\n        # less overhead, simpler stacktraces\n        it = (run_clang_format_diff_wrapper(args, file) for file in files)\n        pool = None\n    else:\n        pool = multiprocessing.Pool(njobs)\n        it = pool.imap_unordered(partial(run_clang_format_diff_wrapper, args), files)\n    while True:\n        try:\n            outs, errs = next(it)\n        except StopIteration:\n            break\n        except DiffError as e:\n            print_trouble(parser.prog, str(e), use_colors=colored_stderr)\n            retcode = ExitStatus.TROUBLE\n            sys.stderr.writelines(e.errs)\n        except UnexpectedError as e:\n            print_trouble(parser.prog, str(e), use_colors=colored_stderr)\n            sys.stderr.write(e.formatted_traceback)\n            retcode = ExitStatus.TROUBLE\n            # stop at the first unexpected error,\n            # something could be very wrong,\n            # don't process all files unnecessarily\n            if pool:\n                pool.terminate()\n            break\n        else:\n            sys.stderr.writelines(errs)\n            if outs == []:\n                continue\n            if not args.quiet:\n                print_diff(outs, use_color=colored_stdout)\n            if retcode == ExitStatus.SUCCESS:\n                retcode = ExitStatus.DIFF\n    return retcode\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.5205078125,
          "content": "#!/usr/bin/env python\nimport distutils.command.clean\nimport io\nimport os\nimport shutil\nimport subprocess\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\nfrom tools import setup_helpers\n\nROOT_DIR = Path(__file__).parent.resolve()\n\n\ndef read(*names, **kwargs):\n    with io.open(ROOT_DIR.joinpath(*names), encoding=kwargs.get(\"encoding\", \"utf8\")) as fp:\n        return fp.read()\n\n\ndef _get_version():\n    try:\n        cmd = [\"git\", \"rev-parse\", \"HEAD\"]\n        sha = subprocess.check_output(cmd, cwd=str(ROOT_DIR)).decode(\"ascii\").strip()\n    except Exception:\n        sha = None\n\n    if \"BUILD_VERSION\" in os.environ:\n        version = os.environ[\"BUILD_VERSION\"]\n    else:\n        with open(os.path.join(ROOT_DIR, \"version.txt\"), \"r\") as f:\n            version = f.readline().strip()\n        if sha is not None:\n            version += \"+\" + sha[:7]\n\n    if sha is None:\n        sha = \"Unknown\"\n    return version, sha\n\n\ndef _export_version(version, sha):\n    version_path = ROOT_DIR / \"torchtext\" / \"version.py\"\n    with open(version_path, \"w\") as fileobj:\n        fileobj.write(\"__version__ = '{}'\\n\".format(version))\n        fileobj.write(\"git_version = {}\\n\".format(repr(sha)))\n\n\ndef _init_submodule():\n    print(\" --- Initializing submodules\")\n    try:\n        subprocess.check_call([\"git\", \"submodule\", \"init\"])\n        subprocess.check_call([\"git\", \"submodule\", \"update\"])\n    except Exception:\n        print(\" --- Submodule initalization failed\")\n        print(\"Please run:\\n\\tgit submodule update --init --recursive\")\n        sys.exit(1)\n    print(\" --- Initialized submodule\")\n\n\nVERSION, SHA = _get_version()\n_export_version(VERSION, SHA)\n\nprint(\"-- Building version \" + VERSION)\n\npytorch_package_version = os.getenv(\"PYTORCH_VERSION\")\n\npytorch_package_dep = \"torch\"\nif pytorch_package_version is not None:\n    pytorch_package_dep += \">=\" + pytorch_package_version\n\n\nclass clean(distutils.command.clean.clean):\n    def run(self):\n        # Run default behavior first\n        distutils.command.clean.clean.run(self)\n\n        # Remove torchtext extension\n        for path in (ROOT_DIR / \"torchtext\").glob(\"**/*.so\"):\n            print(f\"removing '{path}'\")\n            path.unlink()\n        # Remove build directory\n        build_dirs = [\n            ROOT_DIR / \"build\",\n            ROOT_DIR / \"third_party\" / \"build\",\n        ]\n        for path in build_dirs:\n            if path.exists():\n                print(f\"removing '{path}' (and everything under it)\")\n                shutil.rmtree(str(path), ignore_errors=True)\n\n\n_init_submodule()\nsetup_info = dict(\n    # Metadata\n    name=\"torchtext\",\n    version=VERSION,\n    author=\"PyTorch Text Team\",\n    author_email=\"packages@pytorch.org\",\n    url=\"https://github.com/pytorch/text\",\n    description=\"Text utilities, models, transforms, and datasets for PyTorch.\",\n    long_description=read(\"README.rst\"),\n    license=\"BSD\",\n    install_requires=[\"tqdm\", \"requests\", pytorch_package_dep, \"numpy\"],\n    python_requires=\">=3.8\",\n    classifiers=[\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n    ],\n    # Package info\n    packages=find_packages(exclude=(\"test*\", \"tools*\")),\n    zip_safe=False,\n    # Extension info\n    # If you are trying to use torchtext.so and see no registered op.\n    # See here: https://github.com/pytorch/vision/issues/2134\"\n    ext_modules=setup_helpers.get_ext_modules(),\n    cmdclass={\n        \"build_ext\": setup_helpers.CMakeBuild,\n        \"clean\": clean,\n    },\n)\n\nsetup(**setup_info)\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "third_party",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "torchtext",
          "type": "tree",
          "content": null
        },
        {
          "name": "version.txt",
          "type": "blob",
          "size": 0.0087890625,
          "content": "0.17.0a0\n"
        }
      ]
    }
  ]
}