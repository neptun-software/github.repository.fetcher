{
  "metadata": {
    "timestamp": 1736559728648,
    "page": 426,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "sksq96/pytorch-summary",
      "stars": 4024,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.025390625,
          "content": "__pycache__\n*.pyc\n.vscode/"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.046875,
          "content": "MIT License\n\nCopyright (c) 2020 Shubham Chandel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.4638671875,
          "content": "## Use the new and updated [torchinfo](https://github.com/TylerYep/torchinfo).\n\n## Keras style `model.summary()` in PyTorch\n[![PyPI version](https://badge.fury.io/py/torchsummary.svg)](https://badge.fury.io/py/torchsummary)\n\nKeras has a neat API to view the visualization of the model which is very helpful while debugging your network. Here is a barebone code to try and mimic the same in PyTorch. The aim is to provide information complementary to, what is not provided by `print(your_model)` in PyTorch.\n\n### Usage\n\n- `pip install torchsummary` or \n- `git clone https://github.com/sksq96/pytorch-summary`\n\n```python\nfrom torchsummary import summary\nsummary(your_model, input_size=(channels, H, W))\n```\n\n- Note that the `input_size` is required to make a forward pass through the network.\n\n### Examples\n\n#### CNN for MNIST\n\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import summary\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\nmodel = Net().to(device)\n\nsummary(model, (1, 28, 28))\n```\n\n\n```\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 10, 24, 24]             260\n            Conv2d-2             [-1, 20, 8, 8]           5,020\n         Dropout2d-3             [-1, 20, 8, 8]               0\n            Linear-4                   [-1, 50]          16,050\n            Linear-5                   [-1, 10]             510\n================================================================\nTotal params: 21,840\nTrainable params: 21,840\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.06\nParams size (MB): 0.08\nEstimated Total Size (MB): 0.15\n----------------------------------------------------------------\n```\n\n\n#### VGG16\n\n\n```python\nimport torch\nfrom torchvision import models\nfrom torchsummary import summary\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nvgg = models.vgg16().to(device)\n\nsummary(vgg, (3, 224, 224))\n```\n\n\n```\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 224, 224]           1,792\n              ReLU-2         [-1, 64, 224, 224]               0\n            Conv2d-3         [-1, 64, 224, 224]          36,928\n              ReLU-4         [-1, 64, 224, 224]               0\n         MaxPool2d-5         [-1, 64, 112, 112]               0\n            Conv2d-6        [-1, 128, 112, 112]          73,856\n              ReLU-7        [-1, 128, 112, 112]               0\n            Conv2d-8        [-1, 128, 112, 112]         147,584\n              ReLU-9        [-1, 128, 112, 112]               0\n        MaxPool2d-10          [-1, 128, 56, 56]               0\n           Conv2d-11          [-1, 256, 56, 56]         295,168\n             ReLU-12          [-1, 256, 56, 56]               0\n           Conv2d-13          [-1, 256, 56, 56]         590,080\n             ReLU-14          [-1, 256, 56, 56]               0\n           Conv2d-15          [-1, 256, 56, 56]         590,080\n             ReLU-16          [-1, 256, 56, 56]               0\n        MaxPool2d-17          [-1, 256, 28, 28]               0\n           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n             ReLU-19          [-1, 512, 28, 28]               0\n           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n             ReLU-21          [-1, 512, 28, 28]               0\n           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n             ReLU-23          [-1, 512, 28, 28]               0\n        MaxPool2d-24          [-1, 512, 14, 14]               0\n           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n             ReLU-26          [-1, 512, 14, 14]               0\n           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n             ReLU-28          [-1, 512, 14, 14]               0\n           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n             ReLU-30          [-1, 512, 14, 14]               0\n        MaxPool2d-31            [-1, 512, 7, 7]               0\n           Linear-32                 [-1, 4096]     102,764,544\n             ReLU-33                 [-1, 4096]               0\n          Dropout-34                 [-1, 4096]               0\n           Linear-35                 [-1, 4096]      16,781,312\n             ReLU-36                 [-1, 4096]               0\n          Dropout-37                 [-1, 4096]               0\n           Linear-38                 [-1, 1000]       4,097,000\n================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 218.59\nParams size (MB): 527.79\nEstimated Total Size (MB): 746.96\n----------------------------------------------------------------\n```\n\n\n#### Multiple Inputs\n\n\n```python\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\n\nclass SimpleConv(nn.Module):\n    def __init__(self):\n        super(SimpleConv, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n        )\n\n    def forward(self, x, y):\n        x1 = self.features(x)\n        x2 = self.features(y)\n        return x1, x2\n    \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SimpleConv().to(device)\n\nsummary(model, [(1, 16, 16), (1, 28, 28)])\n```\n\n\n```\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 1, 16, 16]              10\n              ReLU-2            [-1, 1, 16, 16]               0\n            Conv2d-3            [-1, 1, 28, 28]              10\n              ReLU-4            [-1, 1, 28, 28]               0\n================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.77\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.78\n----------------------------------------------------------------\n```\n\n\n\n### References\n\n- The idea for this package sparked from [this PyTorch issue](https://github.com/pytorch/pytorch/issues/2001).\n- Thanks to @ncullen93 and @HTLife. \n- For Model Size Estimation @jacobkimmel ([details here](https://github.com/sksq96/pytorch-summary/pull/21))\n\n### License\n\n`pytorch-summary` is MIT-licensed.\n\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.3388671875,
          "content": "from setuptools import setup, find_packages\n\nsetup(\n    name=\"torchsummary\",\n    version=\"1.5.1\",\n    description=\"Model summary in PyTorch similar to `model.summary()` in Keras\",\n    url=\"https://github.com/sksq96/pytorch-summary\",\n    author=\"Shubham Chandel @sksq96\",\n    author_email=\"shubham.zeez@gmail.com\",\n    packages=[\"torchsummary\"],\n)\n"
        },
        {
          "name": "torchsummary",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}