{
  "metadata": {
    "timestamp": 1736559928206,
    "page": 696,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/encodec",
      "stars": 3560,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.478515625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# macOS dir files\n.DS_Store\n\n# Distribution / packaging\n.Python\ndocs/\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# personal notebooks & scripts\n/notebooks\n/local_scripts\n/notes\n/tmp\n\n# script outputs\n/processed\n/experiments\n\n/test_*.ecdc\n/test_*_decompressed.wav\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.701171875,
          "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [0.1.2a1] - TBD\n\nAdding balancer for reference.\n\nConvert Paths to str before giving to torchaudio due to [some compat issue with Windows](https://github.com/facebookresearch/encodec/issues/13).\nInstalling is another way to solve the issue.\n\nFix bug in convert audio that would not work properly with shapes [*, C, T].\n\nFixing incorrect order of operations when evaluating the number of frames (thanks @chenjiasheng  for the report).\n\n## [0.1.1] - 2022-10-25\n\nRemoved useless warning when using `-r` option.\n\n## [0.1.0] - 2022-10-25\n\nInitial release.\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.4521484375,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\nadvances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\naddress, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\nprofessional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\nThis Code of Conduct also applies outside the project spaces when there is a\nreasonable belief that an individual's behavior may have a negative impact on\nthe project or its community.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 1.3369140625,
          "content": "# Contributing to encodec\nWe want to make contributing to this project as easy and transparent as\npossible.\n\n## Pull Requests\nencodec is the implementation of a research paper.\nTherefore, we do not plan on accepting many pull requests for new features.\nWe certainly welcome them for bug fixes.\n\n1. Fork the repo and create your branch from `main`.\n2. If you've added code that should be tested, add tests.\n3. If you've changed APIs, update the documentation.\n4. Ensure the test suite passes.\n5. Make sure your code lints.\n6. If you haven't already, complete the Contributor License Agreement (\"CLA\").\n\n## Contributor License Agreement (\"CLA\")\nIn order to accept your pull request, we need you to submit a CLA. You only need\nto do this once to work on any of Meta's open source projects.\n\nComplete your CLA here: <https://code.facebook.com/cla>\n\n## Issues\nWe use GitHub issues to track public bugs. Please ensure your description is\nclear and has sufficient instructions to be able to reproduce the issue.\n\nMeta has a [bounty program](https://www.facebook.com/whitehat/) for the safe\ndisclosure of security bugs. In those cases, please go through the process\noutlined on that page and do not file a public issue.\n\n## License\nBy contributing to encodec, you agree that your contributions will be licensed\nunder the LICENSE file in the root directory of this source tree.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0615234375,
          "content": "MIT License\n\nCopyright (c) Meta Platforms, Inc. and affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.158203125,
          "content": "include *.md\ninclude LICENSE\ninclude setup.cfg\ninclude Makefile\ninclude mypy.ini\ninclude encodec/py.typed\nexclude *.wav\ninclude test_24k.wav\ninclude test_48k.wav\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.8544921875,
          "content": "default: linter tests\n\nall: linter tests docs dist\n\nlinter:\n\tflake8 encodec && mypy encodec\n\ntests:\n\tpython3 -m encodec.binary\n\tpython3 -m encodec.compress\n\tpython3 -m encodec.model\n\tpython3 -m encodec.modules.seanet\n\tpython3 -m encodec.msstftd\n\tpython3 -m encodec.quantization.ac\n\tpython3 -m encodec.balancer\n\ttest ! -f test_24k_decompressed.wav || rm test_24k_decompressed.wav; \\\n\t\tpython3 -m encodec test_24k.wav test_24k.ecdc -f && \\\n\t\tpython3 -m encodec test_24k.ecdc test_24k_decompressed.wav -f\n\ttest ! -f test_48k_decompressed.wav || rm test_48k_decompressed.wav; \\\n\t\tpython3 -m encodec test_48k.wav test_48k.ecdc -f -q && \\\n\t\tpython3 -m encodec test_48k.ecdc test_48k_decompressed.wav -f -q\n\ndocs:\n\tpdoc3 --html -o docs -f encodec\n\ndist: docs\n\tpython3 setup.py sdist\n\nclean:\n\trm -r docs dist *.egg-info\n\nlive:\n\tpdoc3 --http : encodec\n\n.PHONY: linter tests docs dist\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.9326171875,
          "content": "# EnCodec: High Fidelity Neural Audio Compression\n![linter badge](https://github.com/facebookresearch/encodec/workflows/linter/badge.svg)\n![tests badge](https://github.com/facebookresearch/encodec/workflows/tests/badge.svg)\n\nThis is the code for the EnCodec neural codec presented in the [High Fidelity Neural Audio Compression](https://arxiv.org/pdf/2210.13438.pdf) [[abs]](https://arxiv.org/abs/2210.13438).\npaper. We provide our two multi-bandwidth models:\n* A causal model operating at 24 kHz on monophonic audio trained on a variety of audio data.\n* A non-causal model operating at 48 kHz on stereophonic audio trained on music-only data.\n\nThe 24 kHz model can compress to 1.5, 3, 6, 12 or 24 kbps, while the 48 kHz model\nsupport 3, 6, 12 and 24 kbps. We also provide a pre-trained language model for each\nof the models, that can further compress the representation by up to 40% without\nany further loss of quality.\n\nFor reference, we also provide the code for our novel [MS-STFT discriminator](encodec/msstftd.py) and the [balancer](encodec/balancer.py).\n\n<p align=\"center\">\n<img src=\"./architecture.png\" alt=\"Schema representing the structure of Encodec,\n    with a convolutional+LSTM encoder, a Residual Vector Quantization in the middle,\n    followed by a convolutional+LSTM decoder. A multiscale complex spectrogram discriminator is applied to the output, along with objective reconstruction losses.\n    A small transformer model is trained to predict the RVQ output.\"\nwidth=\"800px\"></p>\n\n\n## Samples\n\nSamples including baselines are provided on [our sample page](https://ai.honu.io/papers/encodec/samples.html).\nYou can also have a quick demo of what we achieve for 48 kHz music with EnCodec, along with\nentropy coding, by clicking the thumbnail (original tracks provided by [Lucille Crew](https://open.spotify.com/artist/5eLv7rNfrf3IjMnK311ByP?si=X_zD9ackRRGjFP5Y6Q7Zng) and [Voyageur I](https://open.spotify.com/artist/21HymveeIhDcM4KDKeNLz0?si=4zXF8VpeQpeKR9QUIuck9Q)).\n\n<p align=\"center\">\n<a href=\"https://ai.honu.io/papers/encodec/final.mp4\">\n<img src=\"./thumbnail.png\" alt=\"Thumbnail for the sample video.\n\tYou will first here the ground truth, then ~3kbps, then 12kbps, for two songs.\"></a></p>\n\n## ü§ó Transformers\n\nEncodec has now been added to Transformers. For more information, please refer to [Transformers' Encodec docs](https://huggingface.co/docs/transformers/main/en/model_doc/encodec).\n\nYou can find both the [24KHz](https://huggingface.co/facebook/encodec_24khz) and [48KHz](https://huggingface.co/facebook/encodec_48khz) checkpoints on the ü§ó Hub.\n\nUsing ü§ó Transformers, you can leverage Encodec at scale along with all the other supported models and datasets. ‚ö°Ô∏è\nAlternatively you can also directly use the encodec package, as detailed in the Usage section. \n\nTo use first you'd need to set up your development environment!\n```\npip install -U datasets \npip install git+https://github.com/huggingface/transformers.git@main\n```\n\nThen, start embedding your audio datasets at scale!\n```python\nfrom datasets import load_dataset, Audio\nfrom transformers import EncodecModel, AutoProcessor\n\n# dummy dataset, however you can swap this with an dataset on the ü§ó hub or bring your own\nlibrispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n\n# load the model + processor (for pre-processing the audio)\nmodel = EncodecModel.from_pretrained(\"facebook/encodec_24khz\")\nprocessor = AutoProcessor.from_pretrained(\"facebook/encodec_24khz\")\n\n# cast the audio data to the correct sampling rate for the model\nlibrispeech_dummy = librispeech_dummy.cast_column(\"audio\", Audio(sampling_rate=processor.sampling_rate))\naudio_sample = librispeech_dummy[0][\"audio\"][\"array\"]\n\n# pre-process the inputs\ninputs = processor(raw_audio=audio_sample, sampling_rate=processor.sampling_rate, return_tensors=\"pt\")\n\n# explicitly encode then decode the audio inputs\nencoder_outputs = model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"])\naudio_values = model.decode(encoder_outputs.audio_codes, encoder_outputs.audio_scales, inputs[\"padding_mask\"])[0]\n\n# or the equivalent with a forward pass\naudio_values = model(inputs[\"input_values\"], inputs[\"padding_mask\"]).audio_values\n\n# you can also extract the discrete codebook representation for LM tasks\n# output: concatenated tensor of all the representations\naudio_codes = model(inputs[\"input_values\"], inputs[\"padding_mask\"]).audio_codes\n\n```\n\n## What's up?\n\nSee [the changelog](CHANGELOG.md) for details on releases.\n\n## Installation\n\nEnCodec requires Python 3.8, and a reasonably recent version of PyTorch (1.11.0 ideally).\nTo install EnCodec, you can run from this repository:\n```bash\npip install -U encodec  # stable release\npip install -U git+https://git@github.com/facebookresearch/encodec#egg=encodec  # bleeding edge\n# of if you cloned the repo locally\npip install .\n```\n\n**Supported platforms:** we officially support only Mac OS X (you might need XCode installed if running on a non Intel Mac), and recent versions of mainstream Linux distributions. We will try to help out on Windows but cannot provide strong support. Any other platform (iOS / Android / onboard ARM) are not supported.\n\n## Usage\n\nYou can then use the EnCodec command, either as\n```bash\npython3 -m encodec [...]\n# or\nencodec [...]\n```\n\nIf you want to directly use the compression API, checkout `encodec.compress`\nand `encodec.model`. See hereafter for instructions on how to extract the discrete\nrepresentation.\n\n### Model storage\n\nThe models will be automatically downloaded on first use using Torch Hub.\nFor more information on where those models are stored, or how to customize\nthe storage location, [checkout their documentation.](https://pytorch.org/docs/stable/hub.html#where-are-my-downloaded-models-saved)\n\n### Compression\n\n```bash\nencodec [-b TARGET_BANDWIDTH] [-f] [--hq] [--lm] INPUT_FILE [OUTPUT_FILE]\n```\nGiven any audio file supported by torchaudio on your platform, compresses\nit with EnCodec to the target bandwidth (default is 6 kbps, can be either 1.5, 3, 6, 12 or 24).\nOUTPUT_FILE must end in `.ecdc`. If not provided it will be the same as `INPUT_FILE`,\nreplacing the extension with `.ecdc`.\nIn order to use the model operating at 48 kHz on stereophonic audio, use the `--hq` flag.\nThe `-f` flag is used to force overwrite an existing output file.\nUse the `--lm` flag to use the pretrained language model with entropy coding (expect it to\nbe much slower).\n\nIf the sample rate or number of channels of the input doesn't match that of the model,\nthe command will automatically resample / reduce channels as needed.\n\n### Decompression\n```bash\nencodec [-f] [-r] ENCODEC_FILE [OUTPUT_WAV_FILE]\n```\nGiven a `.ecdc` file previously generated, this will decode it to the given output wav file.\nIf not provided, the output will default to the input with the `.wav` extension.\nUse the `-f` file to force overwrite the output file (be carefull if compress then decompress,\nnot to overwrite your original file !). Use the `-r` flag if you experience clipping, this will\nrescale the output file to avoid it.\n\n### Compression + Decompression\n```bash\nencodec [-r] [-b TARGET_BANDWIDTH] [-f] [--hq] [--lm] INPUT_FILE OUTPUT_WAV_FILE\n```\nWhen `OUTPUT_WAV_FILE` has the `.wav` extension (as opposed to `.ecdc`), the `encodec`\ncommand will instead compress and immediately decompress without storing the intermediate\n`.ecdc` file.\n\n### Extracting discrete representations\n\nThe EnCodec model can also be used to extract discrete representations from the audio waveform.\n\n```python\nfrom encodec import EncodecModel\nfrom encodec.utils import convert_audio\n\nimport torchaudio\nimport torch\n\n# Instantiate a pretrained EnCodec model\nmodel = EncodecModel.encodec_model_24khz()\n# The number of codebooks used will be determined bythe bandwidth selected.\n# E.g. for a bandwidth of 6kbps, `n_q = 8` codebooks are used.\n# Supported bandwidths are 1.5kbps (n_q = 2), 3 kbps (n_q = 4), 6 kbps (n_q = 8) and 12 kbps (n_q =16) and 24kbps (n_q=32).\n# For the 48 kHz model, only 3, 6, 12, and 24 kbps are supported. The number\n# of codebooks for each is half that of the 24 kHz model as the frame rate is twice as much.\nmodel.set_target_bandwidth(6.0)\n\n# Load and pre-process the audio waveform\nwav, sr = torchaudio.load(\"<PATH_TO_AUDIO_FILE>\")\nwav = convert_audio(wav, sr, model.sample_rate, model.channels)\nwav = wav.unsqueeze(0)\n\n# Extract discrete codes from EnCodec\nwith torch.no_grad():\n    encoded_frames = model.encode(wav)\ncodes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # [B, n_q, T]\n```\n\nNote that the 48 kHz model processes the audio by chunks of 1 seconds, with an overlap of 1%,\nand renormalizes the audio to have unit scale. For this model, the output of `model.encode(wav)`\nwould a list (for each frame of 1 second) of a tuple `(codes, scale)` with `scale` a scalar tensor.\n\n## Installation for development\n\nThis will install the dependencies and a `encodec` in developer mode (changes to the files\nwill directly reflect), along with the dependencies to run unit tests.\n```\npip install -e '.[dev]'\n```\n\n### Test\n\nYou can run the unit tests with\n```\nmake tests\n```\n\n## FAQ\n\nPlease check this section before opening an issue.\n\n### Out of memory errors with long files\n\nWe do not try to be smart about long files, and we apply the model at once on the entire file. This can lead to a large memory usage\nand result in the process being killed. At the moment we will not support this use case.\n\n### Bad interactions between DistributedDataParallel and the RVQ code\n\nWe do not use DDP, instead we recommend using the routines in `encodec/distrib.py`, in particular `encodec.distrib.sync_buffer` and `encodec.distrib.sync_grad`.\n\n## Citation\n\nIf you use this code or results in your paper, please cite our work as:\n\n```\n@article{defossez2022highfi,\n  title={High Fidelity Neural Audio Compression},\n  author={D√©fossez, Alexandre and Copet, Jade and Synnaeve, Gabriel and Adi, Yossi},\n  journal={arXiv preprint arXiv:2210.13438},\n  year={2022}\n}\n```\n\n## License\n\nThe code in this repository is released under the MIT license as found in the\n[LICENSE](LICENSE) file.\n"
        },
        {
          "name": "architecture.png",
          "type": "blob",
          "size": 553.84375,
          "content": null
        },
        {
          "name": "benchmark.py",
          "type": "blob",
          "size": 2.447265625,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n\"\"\"Benchmark script.\"\"\"\n\n\nimport io\nimport time\nimport torch\nimport torchaudio\n\nfrom encodec.model import EncodecModel\nfrom encodec.quantization.ac import ArithmeticCoder, ArithmeticDecoder, build_stable_quantized_cdf\n\n\ndef _timer():\n    last = time.perf_counter()\n\n    def _measure():\n        nonlocal last\n        result = time.perf_counter() - last\n        last += result\n        return result\n\n    return _measure\n\n\ndef main():\n    torch.set_num_threads(1)\n    model_lq = EncodecModel.encodec_model_24khz()\n    model_hq = EncodecModel.encodec_model_48khz()\n\n    for model in [model_lq, model_hq]:\n        sr = model.sample_rate // 1000\n        x, _ = torchaudio.load(f'test_{sr}k.wav')\n        x = x[None, :, :model.sample_rate * 10]\n        model.set_target_bandwidth(12)\n        lm = model.get_lm_model()\n\n        timer = _timer()\n        with torch.no_grad():\n            frames = model.encode(x)\n        print(\"Time to encode: \", timer())\n        codes = torch.cat([f for f, _ in frames], dim=-1)\n\n        _, K, T = codes.shape\n        offset = 0\n        input_ = torch.zeros(1, K, 1, dtype=torch.long, device=x.device)\n        probas = torch.zeros(1, lm.card, K, T)\n        offset = 0\n        states = None\n        for t in range(T):\n            with torch.no_grad():\n                probas[:, :, :, t: t + 1], states, offset = lm(input_, states, offset)\n            input_ = codes[:, :, t: t + 1] + 1\n        print(\"Time to eval LM:\", timer())\n        fo = io.BytesIO()\n        coder = ArithmeticCoder(fo)\n        for t in range(T):\n            for k, value in enumerate(codes[0, :, t].tolist()):\n                q_cdf = build_stable_quantized_cdf(\n                    probas[0, :, k, t], coder.total_range_bits, check=False)\n                coder.push(value, q_cdf)\n        print(\"Time to AC enc.:\", timer())\n        decoder = ArithmeticDecoder(fo)\n        for t in range(T):\n            for k, value in enumerate(codes[0, :, t].tolist()):\n                q_cdf = build_stable_quantized_cdf(\n                    probas[0, :, k, t], coder.total_range_bits, check=False)\n                decoder.pull(q_cdf)\n        print(\"Time to AC dec.:\", timer())\n        with torch.no_grad():\n            _ = model.decode(frames)\n        print(\"Time to decode:\", timer())\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "encodec",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.095703125,
          "content": "[mypy]\n\n[mypy-treetable,torchaudio.*,scipy,soundfile,tqdm,einops.*]\nignore_missing_imports = True\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.0595703125,
          "content": "[pep8]\nmax-line-length = 120\n\n[flake8]\nmax-line-length = 120\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.8251953125,
          "content": "#!/usr/bin/env python3\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n#\n# Inspired from https://github.com/kennethreitz/setup.py\nfrom pathlib import Path\n\nfrom setuptools import setup\n\n\nNAME = 'encodec'\nDESCRIPTION = 'High fidelity neural audio codec'\nURL = 'https://github.com/facebookresearch/encodec'\nEMAIL = 'defossez@fb.com'\nAUTHOR = 'Alexandre D√©fossez, Jade Copet, Yossi Adi, Gabriel Synnaeve'\nREQUIRES_PYTHON = '>=3.8.0'\n\nfor line in open('encodec/__init__.py'):\n    line = line.strip()\n    if '__version__' in line:\n        context = {}\n        exec(line, context)\n        VERSION = context['__version__']\n\nHERE = Path(__file__).parent\n\ntry:\n    with open(HERE / \"README.md\", encoding='utf-8') as f:\n        long_description = '\\n' + f.read()\nexcept FileNotFoundError:\n    long_description = DESCRIPTION\n\nsetup(\n    name=NAME,\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    author=AUTHOR,\n    author_email=EMAIL,\n    python_requires=REQUIRES_PYTHON,\n    url=URL,\n    packages=['encodec', 'encodec.quantization', 'encodec.modules'],\n    extras_require={\n        'dev': ['flake8', 'mypy', 'pdoc3'],\n    },\n    install_requires=['numpy', 'torch', 'torchaudio', 'einops'],\n    include_package_data=True,\n    entry_points={\n        'console_scripts': ['encodec=encodec.__main__:main'],\n    },\n    license='MIT License',\n    classifiers=[\n        # Trove classifiers\n        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n        'Topic :: Multimedia :: Sound/Audio',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n        'License :: OSI Approved :: MIT License',\n    ])\n"
        },
        {
          "name": "test_24k.wav",
          "type": "blob",
          "size": 937.576171875,
          "content": null
        },
        {
          "name": "test_48k.wav",
          "type": "blob",
          "size": 2812.6171875,
          "content": null
        },
        {
          "name": "thumbnail.png",
          "type": "blob",
          "size": 34.5966796875,
          "content": null
        }
      ]
    }
  ]
}