{
  "metadata": {
    "timestamp": 1736559455250,
    "page": 9,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "modelscope/ms-swift",
      "stars": 4981,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dev_scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.5517578125,
          "content": "# Byte-compiled / optimized / DLL files\ntmp\n*.ttf\n__pycache__/\n*.py[cod]\n*$py.class\ntest.py\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n/package\n/temp\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n.vscode\n.idea\n.run\n\n# custom\n*.pkl\n*.pkl.json\n*.log.json\n*.whl\n*.tar.gz\n*.swp\n*.log\n*.tar.gz\nsource.sh\ntensorboard.sh\n.DS_Store\nreplace.sh\nresult.png\nresult.jpg\nresult.mp4\noutput/\noutputs/\n*.out\nbenchmarks/\neval_output/\neval_outputs/\ntransformers/\nvlmeval/\nmy_model/\n/data\nresult/\nimages\n/custom/\n\n# Pytorch\n*.pth\n*.pt\n\n# ast template\nast_index_file.py\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.373046875,
          "content": "repos:\n  - repo: https://github.com/pycqa/flake8.git\n    rev: 4.0.0\n    hooks:\n      - id: flake8\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/PyCQA/isort.git\n    rev: 4.3.21\n    hooks:\n      - id: isort\n        exclude: |\n            (?x)^(\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/pre-commit/mirrors-yapf.git\n    rev: v0.30.0\n    hooks:\n      - id: yapf\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/pre-commit/pre-commit-hooks.git\n    rev: v3.1.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: thirdparty/|tests/run.py\n      - id: check-yaml\n        exclude: thirdparty/|tests/run.py\n      - id: end-of-file-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: requirements-txt-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: double-quote-string-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: check-merge-conflict\n        exclude: thirdparty/|tests/run.py\n      - id: fix-encoding-pragma\n        exclude: thirdparty/|tests/run.py\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        exclude: thirdparty/|tests/run.py\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": ".pre-commit-config_local.yaml",
          "type": "blob",
          "size": 1.3271484375,
          "content": "repos:\n  - repo: /home/admin/pre-commit/flake8\n    rev: 4.0.0\n    hooks:\n      - id: flake8\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/isort\n    rev: 4.3.21\n    hooks:\n      - id: isort\n        exclude: |\n            (?x)^(\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/mirrors-yapf\n    rev: v0.30.0\n    hooks:\n      - id: yapf\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/pre-commit-hooks\n    rev: v3.1.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: thirdparty/|tests/run.py\n      - id: check-yaml\n        exclude: thirdparty/|tests/run.py\n      - id: end-of-file-fixer\n        exclude: thirdparty/\n      - id: requirements-txt-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: double-quote-string-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: check-merge-conflict\n        exclude: thirdparty/|tests/run.py\n      - id: fix-encoding-pragma\n        exclude: thirdparty/|tests/run.py\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        exclude: thirdparty/|tests/run.py\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.357421875,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\ncontact@modelscope.cn.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.7099609375,
          "content": "# Contributor Guide\n\n_Welcome to offer PRs, bug reports, documentation supplements or other types of contributions to SWIFT!_\n\n## Table of Contents\n- [Code of Conduct](#-code-of-conduct)\n- [Contribution Process](#-contribution-process)\n- [Hardware support](#-Hardware-support)\n\n## 📖 Code of Conduct\nPlease refer to our [Code of Conduct documentation](./CODE_OF_CONDUCT.md).\n\n## 🔁 Contribution Process\n### What We Need\n- ROADMAP: We provide a [ROADMAP](./ROADMAP.md) for each iteration of SWIFT, contributors can check our ROADMAP to understand our development progress and plans. Features in **To be Assigned** is available for all developers.\n- New Technologies and New Models: SWIFT needs to support more open-source models and datasets, or new technologies that we have not paid attention to. If you are interested please submit a PR to us.\n- Technical Propagation: If you are interested in technical propagation, you are welcome to help us write tutorials, documents or videos on any website, and send us the link.\n- Community Contribution: You can write technical articles related to SWIFT, and submit them to us. After review and approval, we will publish them on the official ModelScope accounts (Zhihu, WeChat, etc.), with your name assigned.\n\n### Incentives\n- we will issue electronic certificates to contributors on behalf of the ModelScope community, to encourage your selfless contributions.\n- We will offer small souvenirs related to the ModelScope Community.\n- We will provide free A10 computing power during the development period. For more details, please refer to [Hardware-support](#-Hardware-support) section.\n\n### Submitting PR (Pull Requests)\n\nAny feature development is carried out in the form of Fork and then PR on GitHub.\n1. Fork: Go to the [SWIFT](https://github.com/modelscope/swift) page and click the **Fork button**. After completion, a SWIFT code repository will be cloned under your personal organization.\n2. Clone: Clone the code repository generated in the first step to your local machine and **create a new branch** for development. During development, please click the **Sync Fork button** in time to synchronize with the `main` branch to prevent code expiration and conflicts.\n3. Submit PR: After development and testing, push the code to the remote branch. On GitHub, go to the **Pull Requests page**, create a new PR, select your code branch as the source branch, and the `modelscope/swift:main` branch as the target branch.\n\n4. Write Description: It is necessary to provide a good feature description in the PR, so that the reviewers know the content of your modification.\n5. Review: We hope that the code to be merged is concise and efficient, so we may raise some questions and discuss them. Please note that any issues raised in the review are aimed at the code itself, not at you personally. Once all issues are discussed and resolved, your code will be approved.\n\n### Code Standards and Development Approach\nSWIFT has conventional variable naming conventions and development approaches. Please follow these approaches as much as possible during development.\n1. Variable names are separated by underscores, and class names are named with the first letter of each word capitalized.\n2. All Python indentation uses four spaces instead of a tab.\n3. Choose well-known open-source libraries, avoid using closed-source libraries or unstable open-source libraries, and avoid repeating the existing code.\n\nAfter the PR is submitted, SWIFT will perform two types of tests:\n- Code Lint Test: A static code compliance check test. please make sure that you have performed code lint locally in advance.\n```shell\npip install pre-commit # In the swift folder\npre-commit run --all-files # Fix the errors reported by pre-commit until all checks are successful\n```\n- CI Tests: Smoke tests and unit tests, please refer to the next section.\n\n### Running CI Tests\nBefore submitting the PR, please ensure that your development code is protected by test cases, such as smoke tests for new features, or unit tests for various edge cases. Reviewers will also pay attention to this during code review. At the same time, there will be dedicated services running CI Tests, running all test cases, and the code can only be merged after the test cases pass.\n\nAdditionally, since some important tests have been skipped due to long running time, to ensure that your logic is correct, you can run the test locally:\n```shell\npython tests/llm/test_run.py\n```\nPlease make sure this test can pass normally.\n\n## ✅ Hardware support\n\nSWIFT will provide hardware support for developers, including free GPUs. If needed, please email us ([contact@modelscope.cn](mailto:contact@modelscope.cn)) or join our WeChat group:\n\n<p align=\"left\">\n<img src=\"asset/wechat.png\" width=\"250\" style=\"display: inline-block;\">\n</p>\n"
        },
        {
          "name": "CONTRIBUTING_CN.md",
          "type": "blob",
          "size": 3.9990234375,
          "content": "# 贡献者指引\n\n*欢迎帮SWIFT提供Feature PR、Bug反馈、文档补充或其他类型的贡献！*\n\n## 目录\n\n- [代码规约](#-代码规约)\n- [贡献流程](#-贡献流程)\n- [资源支持](#-资源支持)\n\n## 📖 代码规约\n\n请查看我们的[代码规约文档](./CODE_OF_CONDUCT.md).\n\n## 🔁 贡献流程\n\n### 我们需要什么\n\n- ROADMAP：我们为SWIFT提供了每个迭代的[ROADMAP](./ROADMAP.md)，贡献者可以查看我们的ROADMAP来了解我们的开发进度和规划。在**待分配**中的feature可以认领并开发。\n\n- 新技术和新模型：SWIFT需要支持更多的开源模型和数据集，或我们没有关注到的新技术，如果您对此有兴趣，可以提交PR给我们。\n- 技术布道：如果您对技术布道有兴趣，欢迎在任何网站上帮我们撰写教程文档或视频等，并将链接发给我们。\n- 社区供稿：您可以撰写和SWIFT有关的技术文章，并供稿给我们，我们审核通过后会在魔搭官方账号（知乎、公众号等）上进行发布，并属上您的名字。\n\n### 激励\n\n- 我们会以魔搭社区的身份给贡献者颁发电子证书，以鼓励您的无私贡献。\n- 我们会赠送相关魔搭社区相关周边小礼品。\n- 我们会赠送开发期间的免费A10算力，具体可以查看[资源支持](#-资源支持)章节。\n\n### 提交PR（Pull Requests）\n\n任何feature开发都在github上以先Fork后PR的形式进行。\n\n1. Fork：进入[SWIFT](https://github.com/modelscope/swift)页面后，点击**Fork按钮**执行。完成后会在您的个人组织下克隆出一个SWIFT代码库\n\n2. Clone：将第一步产生的代码库clone到本地并**拉新分支**进行开发，开发中请及时点击**Sync Fork按钮**同步`main`分支，防止代码过期并冲突\n\n3. 提交PR：开发、测试完成后将代码推送到远程分支。在github上点击**Pull Requests页面**，新建一个PR，源分支选择您提交的代码分支，目标分支选择`modelscope/swift:main`分支\n\n4. 撰写描述：在PR中填写良好的feature描述是必要的，让Reviewers知道您的修改内容\n\n5. Review：我们希望合入的代码简洁高效，因此可能会提出一些问题并讨论。请注意，任何review中提出的问题是针对代码本身，而非您个人。在所有问题讨论通过后，您的代码会被通过\n\n### 代码规范和开发方式\n\nSWIFT有约定俗成的变量命名方式和开发方式。在开发中请尽量遵循这些方式。\n\n1. 变量命名以下划线分割，类名以所有单词首字母大写方式命名\n2. 所有的python缩进都是四个空格取代一个tab\n3. 选用知名的开源库，避免使用闭源库或不稳定的开源库，避免重复造轮子\n\nSWIFT在PR提交后会进行两类测试：\n\n- Code Lint测试 对代码进行静态规范走查的测试，为保证改测试通过，请保证本地预先进行了Code lint。方法是：\n\n  ```shell\n  pip install pre-commit\n  # 在swift文件夹内\n  pre-commit run --all-files\n  # 对pre-commit报的错误进行修改，直到所有的检查都是成功状态\n  ```\n\n- CI Tests 冒烟测试和单元测试，请查看下一章节\n\n### Running CI Tests\n\n在提交PR前，请保证您的开发代码已经受到了测试用例的保护。例如，对新功能的冒烟测试，或者各种边缘case的单元测试等。在代码review时Reviewers也会关注这一点。同时，也会有服务专门运行CI Tests，运行所有的测试用例，测试用例通过后代码才可以合并。\n\n另外，由于运行时间过长，我们跳过了部分重要测试，为保证您的逻辑是正确的，可以在本地执行该测试：\n\n```shell\npython tests/llm/test_run.py\n```\n\n请保证该测试可以正常通过。\n\n## ✅ 资源支持\n\nSWIFT会为开发者提供资源支持，包括免费的GPU算力。如果需要请邮件联系我们（[contact@modelscope.cn](mailto:contact@modelscope.cn)）或加入我们的微信群：\n\n<p align=\"left\">\n<img src=\"asset/wechat.png\" width=\"250\" style=\"display: inline-block;\">\n</p>\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.201171875,
          "content": "recursive-include swift/utils *.py\nrecursive-include swift/llm/dataset/data *.*\nrecursive-include swift/llm/ds_config *.json\nrecursive-include requirements *.txt\nrecursive-include swift/plugin/agent *.json\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.3505859375,
          "content": "WHL_BUILD_DIR :=package\nDOC_BUILD_DIR :=docs/build/\n\n# default rule\ndefault: whl docs\n\n.PHONY: docs\ndocs:\n\tbash .dev_scripts/build_docs.sh\n\n.PHONY: linter\nlinter:\n\tbash .dev_scripts/linter.sh\n\n.PHONY: test\ntest:\n\tbash .dev_scripts/citest.sh\n\n.PHONY: whl\nwhl:\n\tpython setup.py sdist bdist_wheel\n\n.PHONY: clean\nclean:\n\trm -rf  $(WHL_BUILD_DIR) $(DOC_BUILD_DIR)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.046875,
          "content": "# SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning)\n\n<p align=\"center\">\n    <br>\n    <img src=\"asset/banner.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n<a href=\"https://modelscope.cn/home\">ModelScope Community Website</a>\n<br>\n        <a href=\"README_CN.md\">中文</a> &nbsp ｜ &nbsp English &nbsp\n</p>\n\n<p align=\"center\">\n<img src=\"https://img.shields.io/badge/python-3.10-5be.svg\">\n<img src=\"https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg\">\n<a href=\"https://github.com/modelscope/modelscope/\"><img src=\"https://img.shields.io/badge/modelscope-%E2%89%A51.19-5D91D4.svg\"></a>\n<a href=\"https://pypi.org/project/ms-swift/\"><img src=\"https://badge.fury.io/py/ms-swift.svg\"></a>\n<a href=\"https://github.com/modelscope/swift/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/modelscope/swift\"></a>\n<a href=\"https://pepy.tech/project/ms-swift\"><img src=\"https://pepy.tech/badge/ms-swift\"></a>\n<a href=\"https://github.com/modelscope/swift/pulls\"><img src=\"https://img.shields.io/badge/PR-welcome-55EB99.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/6427\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/6427\" alt=\"modelscope%2Fswift | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n        <a href=\"https://arxiv.org/abs/2408.05517\">Paper</a> &nbsp ｜ <a href=\"https://swift.readthedocs.io/en/latest/\">English Documentation</a> &nbsp ｜ &nbsp <a href=\"https://swift.readthedocs.io/zh-cn/latest/\">中文文档</a> &nbsp\n</p>\n<p align=\"center\">\n        <a href=\"https://swift2x-en.readthedocs.io/en/latest/\">Swift2.x En Doc</a> &nbsp ｜ &nbsp <a href=\"https://swift2x.readthedocs.io/zh-cn/latest/\">Swift2.x中文文档</a> &nbsp\n</p>\n\n\n## 📖 Table of Contents\n- [Groups](#-Groups)\n- [Introduction](#-introduction)\n- [News](#-news)\n- [Installation](#%EF%B8%8F-installation)\n- [Quick Start](#-quick-Start)\n- [Usage](#-Usage)\n- [License](#-License)\n- [Citation](#-citation)\n\n\n## ☎ Groups\n\nYou can contact us and communicate with us by adding our group:\n\n\n[Discord Group](https://discord.com/invite/D27yfEFVz5)              |  WeChat Group\n:-------------------------:|:-------------------------:\n<img src=\"asset/discord_qr.jpg\" width=\"200\" height=\"200\">  |  <img src=\"asset/wechat.png\" width=\"200\" height=\"200\">\n\n\n## 📝 Introduction\n🍲 ms-swift is an official framework provided by the ModelScope community for fine-tuning and deploying large language models and multi-modal large models. It currently supports the training (pre-training, fine-tuning, human alignment), inference, evaluation, quantization, and deployment of 400+ large models and 150+ multi-modal large models. These large language models (LLMs) include models such as Qwen2.5, Llama3.3, GLM4, Internlm2.5, Yi1.5, Mistral, DeepSeek2.5, Baichuan2, Gemma2, and TeleChat2. The multi-modal LLMs include models such as Qwen2-VL, Qwen2-Audio, Llama3.2-Vision, Llava, InternVL2.5, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, Yi-VL, DeepSeek-VL2, Phi3.5-Vision, and GOT-OCR2.\n\n🍔 In addition, ms-swift gathers the latest training technologies, including LoRA, QLoRA, Llama-Pro, LongLoRA, GaLore, Q-GaLore, LoRA+, LISA, DoRA, FourierFt, ReFT, UnSloth, and Liger. ms-swift supports acceleration of inference, evaluation, and deployment modules using vLLM and LMDeploy, and supports the quantization of large models and multi-modal large models using technologies such as GPTQ, AWQ, and BNB. To help researchers and developers fine-tune and apply large models more easily, ms-swift also provides a Gradio-based Web-UI interface and a wealth of best practices.\n\n**Why choose ms-swift?**\n\n- 🍎 **Model Types**: Supports 400+ large language models and **150+ multi-modal large models** and all-to-all models, **providing a comprehensive solution from training to deployment**.\n- **Dataset Types**: Comes with 150+ pre-training, fine-tuning, human alignment, multi-modal datasets, and supports custom datasets.\n- **Hardware Support**: Compatible with CPU, RTX series, T4/V100, A10/A100/H100, Ascend NPU, etc.\n- 🍊 **Lightweight Training**: Supports lightweight fine-tuning methods like LoRA, QLoRA, DoRA, LoRA+, ReFT, RS-LoRA, LLaMAPro, Adapter, GaLore, Q-Galore, LISA, UnSloth, Liger-Kernel.\n- **Distributed Training**: Supports distributed data parallel (DDP), device_map simple model parallelism, DeepSpeed ZeRO2/ZeRO3, FSDP, and other distributed training techniques.\n- **Quantization Training**: Supports training quantized models like BNB, AWQ, GPTQ, AQLM, HQQ, EETQ.\n- **RLHF Training**: Supports human alignment training methods such as DPO, CPO, SimPO, ORPO, KTO, RM, PPO for both pure text and multi-modal large models.\n- 🍓 **Multi-Modal Training**: Supports training on different modalities like images, videos, and audio, for tasks like VQA, captioning, OCR, and grounding.\n- **Interface Training**: Provides capabilities for training, inference, evaluation, quantization through an interface, completing the whole large model pipeline.\n- **Plugin and Extension**: Supports custom model and dataset extensions, as well as customization of components like loss, metric, trainer, loss-scale, callback, optimizer.\n- 🍉 **Toolbox Capabilities**: Offers not only training support for large models and multi-modal large models but also covers the entire process of inference, evaluation, quantization, and deployment.\n- **Inference Acceleration**: Supports inference acceleration engines like PyTorch, vLLM, LmDeploy, and provides OpenAI API for accelerating inference, deployment, and evaluation modules.\n- **Model Evaluation**: Uses EvalScope as the evaluation backend and supports evaluation on 100+ datasets for both pure text and multi-modal models.\n- **Model Quantization**: Supports AWQ, GPTQ, and BNB quantized exports, with models that can use vLLM/LmDeploy for inference acceleration and continue training.\n\n\n## 🎉 News\n\n- 🎁 2024.12.04: **SWIFT3.0** major version update. Please check the [Release Notes and Changes](https://swift.readthedocs.io/en/latest/Instruction/ReleaseNote3.0.html).\n- 🎉 2024.08.12: The SWIFT paper has been published on arXiv, and you can read it [here](https://arxiv.org/abs/2408.05517).\n- 🔥 2024.08.05: Support for using [evalscope](https://github.com/modelscope/evalscope/) as a backend for evaluating large models and multimodal models.\n- 🔥 2024.07.29: Support for using [vllm](https://github.com/vllm-project/vllm) and [lmdeploy](https://github.com/InternLM/lmdeploy) to accelerate inference for large models and multimodal models. When performing infer/deploy/eval, you can specify `--infer_backend vllm/lmdeploy`.\n- 🔥 2024.07.24: Support for human preference alignment training for multimodal large models, including DPO/ORPO/SimPO/CPO/KTO/RM/PPO.\n- 🔥 2024.02.01: Support for Agent training! The training algorithm is derived from [this paper](https://arxiv.org/pdf/2309.00986.pdf).\n\n\n## 🛠️ Installation\nTo install using pip:\n```shell\npip install ms-swift -U\n```\n\nTo install from source:\n```shell\n# pip install git+https://github.com/modelscope/ms-swift.git\n\ngit clone https://github.com/modelscope/ms-swift.git\ncd ms-swift\npip install -e .\n```\n\n## 🚀 Quick Start\n\n10 minutes of self-cognition fine-tuning of Qwen2.5-7B-Instruct on a single 3090 GPU:\n\n### Command Line Interface\n\n```shell\n# 22GB\nCUDA_VISIBLE_DEVICES=0 \\\nswift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \\\n              'AI-ModelScope/alpaca-gpt4-data-en#500' \\\n              'swift/self-cognition#500' \\\n    --torch_dtype bfloat16 \\\n    --num_train_epochs 1 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 5 \\\n    --max_length 2048 \\\n    --output_dir output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-robot\n```\n\nAfter training is complete, use the following command to perform inference with the trained weights. The `--adapters` option should be replaced with the last checkpoint folder generated from the training. Since the adapters folder contains the parameter files from the training, there is no need to specify `--model` or `--system` separately.\n\n```shell\n# Using an interactive command line for inference.\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n\n# merge-lora and use vLLM for inference acceleration\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --merge_lora true \\\n    --infer_backend vllm \\\n    --max_model_len 8192 \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Web-UI\nThe Web-UI is a **zero-threshold** training and deployment interface solution based on Gradio interface technology. For more details, you can check [here](https://swift.readthedocs.io/en/latest/GetStarted/Web-UI.html).\n\n```shell\nSWIFT_UI_LANG=en swift web-ui\n```\n\n![image.png](./docs/resources/web-ui-en.jpg)\n\n### Using Python\n\nms-swift also supports training and inference using Python. Below is pseudocode for training and inference. For more details, you can refer to [here](https://github.com/modelscope/ms-swift/tree/main/examples/notebook).\n\nTraining:\n\n```python\n# Retrieve the model and template, and add a trainable LoRA module\nmodel, tokenizer = get_model_tokenizer(model_id_or_path, ...)\ntemplate = get_template(model.model_meta.template, tokenizer, ...)\nmodel = Swift.prepare_model(model, lora_config)\n\n# Download and load the dataset, and encode the text into tokens\ntrain_dataset, val_dataset = load_dataset(dataset_id_or_path, ...)\ntrain_dataset = EncodePreprocessor(template=template)(train_dataset, num_proc=num_proc)\nval_dataset = EncodePreprocessor(template=template)(val_dataset, num_proc=num_proc)\n\n# Train the model\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=template.data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    template=template,\n)\ntrainer.train()\n```\nInference:\n\n```python\n# Perform inference using the native PyTorch engine\nengine = PtEngine(model_id_or_path, adapters=[lora_checkpoint])\ninfer_request = InferRequest(messages=[{'role': 'user', 'content': 'who are you?'}])\nrequest_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature)\n\nresp_list = engine.infer([infer_request], request_config)\nprint(f'response: {resp_list[0].choices[0].message.content}')\n```\n\n## ✨ Usage\nHere is the simplest example of training to deployment using ms-swift. For more details, you can check the [examples](https://github.com/modelscope/ms-swift/tree/main/examples).\n\n|   Useful Links |\n| ------ |\n|   [Command Line Parameters](https://swift.readthedocs.io/en/latest/Instruction/Command-line-parameters.html)   |\n|   [Supported Models and Datasets](https://swift.readthedocs.io/en/latest/Instruction/Supported-models-and-datasets.html)   |\n|   [Custom Models](https://swift.readthedocs.io/en/latest/Customization/Custom-model.html), [Custom Datasets](https://swift.readthedocs.io/en/latest/Customization/Custom-dataset.html)   |\n|   [LLM Tutorial](https://github.com/modelscope/modelscope-classroom/tree/main/LLM-tutorial)   |\n\n### Training\n\nPre-training:\n```shell\n# 8*A100\nNPROC_PER_NODE=8 \\\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\nswift pt \\\n    --model Qwen/Qwen2.5-7B \\\n    --dataset swift/chinese-c4 \\\n    --streaming true \\\n    --train_type full \\\n    --deepspeed zero2 \\\n    --output_dir output \\\n    --max_steps 100000 \\\n    ...\n```\n\nFine-tuning:\n```shell\nCUDA_VISIBLE_DEVICES=0 swift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-en \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\nRLHF:\n```shell\nCUDA_VISIBLE_DEVICES=0 swift rlhf \\\n    --rlhf_type dpo \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset hjh0119/shareAI-Llama3-DPO-zh-en-emoji \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\n\n### Inference\n```shell\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n\n# LoRA\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --adapters swift/test_lora \\\n    --stream true \\\n    --infer_backend pt \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Interface Inference\n```shell\nCUDA_VISIBLE_DEVICES=0 swift app \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n```\n\n### Deployment\n```shell\nCUDA_VISIBLE_DEVICES=0 swift deploy \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend vllm\n```\n\n### Evaluation\n```shell\nCUDA_VISIBLE_DEVICES=0 swift eval \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend lmdeploy \\\n    --eval_dataset ARC_c\n```\n\n### Quantization\n```shell\nCUDA_VISIBLE_DEVICES=0 swift export \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --quant_bits 4 --quant_method awq \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --output_dir Qwen2.5-7B-Instruct-AWQ\n```\n\n## 🏛 License\n\nThis framework is licensed under the [Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE). For models and datasets, please refer to the original resource page and follow the corresponding License.\n\n## 📎 Citation\n\n```bibtex\n@misc{zhao2024swiftascalablelightweightinfrastructure,\n      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},\n      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},\n      year={2024},\n      eprint={2408.05517},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2408.05517},\n}\n```\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=modelscope/swift&type=Date)](https://star-history.com/#modelscope/ms-swift&Date)\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 13.2275390625,
          "content": "# SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning)\n\n<p align=\"center\">\n    <br>\n    <img src=\"asset/banner.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n<a href=\"https://modelscope.cn/home\">魔搭社区官网</a>\n<br>\n        中文&nbsp ｜ &nbsp<a href=\"README.md\">English</a>&nbsp\n</p>\n\n\n<p align=\"center\">\n<img src=\"https://img.shields.io/badge/python-3.10-5be.svg\">\n<img src=\"https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg\">\n<a href=\"https://github.com/modelscope/modelscope/\"><img src=\"https://img.shields.io/badge/modelscope-%E2%89%A51.19-5D91D4.svg\"></a>\n<a href=\"https://pypi.org/project/ms-swift/\"><img src=\"https://badge.fury.io/py/ms-swift.svg\"></a>\n<a href=\"https://github.com/modelscope/swift/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/modelscope/swift\"></a>\n<a href=\"https://pepy.tech/project/ms-swift\"><img src=\"https://pepy.tech/badge/ms-swift\"></a>\n<a href=\"https://github.com/modelscope/swift/pulls\"><img src=\"https://img.shields.io/badge/PR-welcome-55EB99.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/6427\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/6427\" alt=\"modelscope%2Fswift | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n        <a href=\"https://arxiv.org/abs/2408.05517\">论文</a> &nbsp ｜ <a href=\"https://swift.readthedocs.io/en/latest/\">English Documentation</a> &nbsp ｜ &nbsp <a href=\"https://swift.readthedocs.io/zh-cn/latest/\">中文文档</a> &nbsp\n</p>\n<p align=\"center\">\n        <a href=\"https://swift2x-en.readthedocs.io/en/latest/\">Swift2.x En Doc</a> &nbsp ｜ &nbsp <a href=\"https://swift2x.readthedocs.io/zh-cn/latest/\">Swift2.x中文文档</a> &nbsp\n</p>\n\n\n##  📖 目录\n- [用户群](#-用户群)\n- [简介](#-简介)\n- [新闻](#-新闻)\n- [安装](#%EF%B8%8F-安装)\n- [快速开始](#-快速开始)\n- [如何使用](#-如何使用)\n- [License](#-license)\n- [引用](#-引用)\n\n## ☎ 用户群\n\n请扫描下面的二维码来加入我们的交流群：\n\n[Discord Group](https://discord.com/invite/D27yfEFVz5)              |  微信群\n:-------------------------:|:-------------------------:\n<img src=\"asset/discord_qr.jpg\" width=\"200\" height=\"200\">  |  <img src=\"asset/wechat.png\" width=\"200\" height=\"200\">\n\n## 📝 简介\n🍲 ms-swift是魔搭社区提供的大模型与多模态大模型微调部署框架，现已支持450+大模型与150+多模态大模型的训练（预训练、微调、人类对齐）、推理、评测、量化与部署。其中大模型包括：Qwen2.5、Llama3.3、GLM4、Internlm2.5、Yi1.5、Mistral、DeepSeek2.5、Baichuan2、Gemma2、TeleChat2等模型，多模态大模型包括：Qwen2-VL、Qwen2-Audio、Llama3.2-Vision、Llava、InternVL2.5、MiniCPM-V-2.6、GLM4v、Xcomposer2.5、Yi-VL、DeepSeek-VL2、Phi3.5-Vision、GOT-OCR2等模型。\n\n🍔 除此之外，ms-swift汇集了最新的训练技术，包括LoRA、QLoRA、Llama-Pro、LongLoRA、GaLore、Q-GaLore、LoRA+、LISA、DoRA、FourierFt、ReFT、UnSloth、和Liger等。ms-swift支持使用vLLM和LMDeploy对推理、评测和部署模块进行加速，并支持使用GPTQ、AWQ、BNB等技术对大模型和多模态大模型进行量化。为了帮助研究者和开发者更轻松地微调和应用大模型，ms-swift还提供了基于Gradio的Web-UI界面及丰富的最佳实践。\n\n**为什么选择ms-swift？**\n- 🍎 **模型类型**：支持400+纯文本大模型、**150+多模态大模型**，All-to-All全模态模型的**训练到部署全流程**。\n- **数据集类型**：内置150+预训练、微调、人类对齐、多模态等各种类型的数据集，并支持自定义数据集。\n- **硬件支持**：CPU、RTX系列、T4/V100、A10/A100/H100、Ascend NPU等。\n- 🍊 **轻量训练**：支持了LoRA、QLoRA、DoRA、LoRA+、ReFT、RS-LoRA、LLaMAPro、Adapter、GaLore、Q-Galore、LISA、UnSloth、Liger-Kernel等轻量微调方式。\n- **分布式训练**：支持分布式数据并行（DDP）、device_map简易模型并行、DeepSpeed ZeRO2 ZeRO3、FSDP等分布式训练技术。\n- **量化训练**：支持对BNB、AWQ、GPTQ、AQLM、HQQ、EETQ量化模型进行训练。\n- **RLHF训练**：支持纯文本大模型和多模态大模型的DPO、CPO、SimPO、ORPO、KTO、RM、PPO等人类对齐训练方法。\n- 🍓 **多模态训练**：支持对图像、视频和语音不同模态模型进行训练，支持VQA、Caption、OCR、Grounding任务的训练。\n- **界面训练**：以界面的方式提供训练、推理、评测、量化的能力，完成大模型的全链路。\n- **插件化与拓展**：支持自定义模型和数据集拓展，支持对loss、metric、trainer、loss-scale、callback、optimizer等组件进行自定义。\n- 🍉 **工具箱能力**：不仅提供大模型和多模态大模型的训练支持，还涵盖其推理、评测、量化和部署全流程。\n- **推理加速**：支持PyTorch、vLLM、LmDeploy推理加速引擎，并提供OpenAI接口，为推理、部署和评测模块提供加速。\n- **模型评测**：以EvalScope作为评测后端，支持100+评测数据集对纯文本和多模态模型进行评测。\n- **模型量化**：支持AWQ、GPTQ和BNB的量化导出，导出的模型支持使用vLLM/LmDeploy推理加速，并支持继续训练。\n\n## 🎉 新闻\n- 🎁 2024.12.04: **SWIFT3.0**大版本更新. 请查看[发布说明和更改](https://swift.readthedocs.io/zh-cn/latest/Instruction/ReleaseNote3.0.html)。\n- 🎉 2024.08.12: SWIFT论文已经发布到arXiv上，可以点击[这里](https://arxiv.org/abs/2408.05517)阅读。\n- 🔥 2024.08.05: 支持使用[evalscope](https://github.com/modelscope/evalscope/)作为后端进行大模型和多模态模型的评测。\n- 🔥 2024.07.29: 支持使用[vllm](https://github.com/vllm-project/vllm), [lmdeploy](https://github.com/InternLM/lmdeploy)对大模型和多模态大模型进行推理加速，在infer/deploy/eval时额外指定`--infer_backend vllm/lmdeploy`即可。\n- 🔥 2024.07.24: 支持对多模态大模型进行人类偏好对齐训练，包括DPO/ORPO/SimPO/CPO/KTO/RM/PPO。\n- 🔥 2024.02.01: 支持Agent训练！训练算法源自这篇[论文](https://arxiv.org/pdf/2309.00986.pdf)。\n\n## 🛠️ 安装\n使用pip进行安装：\n```shell\npip install ms-swift -U\n```\n\n从源代码安装：\n```shell\n# pip install git+https://github.com/modelscope/ms-swift.git\n\ngit clone https://github.com/modelscope/ms-swift.git\ncd ms-swift\npip install -e .\n```\n\n## 🚀 快速开始\n\n**10分钟**在单卡3090上对Qwen2.5-7B-Instruct进行自我认知微调：\n\n### 命令行\n```shell\n# 22GB\nCUDA_VISIBLE_DEVICES=0 \\\nswift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \\\n              'AI-ModelScope/alpaca-gpt4-data-en#500' \\\n              'swift/self-cognition#500' \\\n    --torch_dtype bfloat16 \\\n    --num_train_epochs 1 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 5 \\\n    --max_length 2048 \\\n    --output_dir output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-robot\n```\n\n训练完成后，使用以下命令对训练后的权重进行推理，这里的`--adapters`替换成训练生成的last checkpoint文件夹. 由于adapters文件夹中包含了训练的参数文件，因此不需要额外指定`--model`, `--system`.\n\n```shell\n# 使用交互式命令行进行推理\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n\n# merge-lora并使用vLLM进行推理加速\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --merge_lora true \\\n    --infer_backend vllm \\\n    --max_model_len 8192 \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Web-UI\n\nWeb-UI是基于gradio界面技术的**零门槛**训练、部署界面方案，具体可以查看[这里](https://swift.readthedocs.io/zh-cn/latest/GetStarted/Web-UI.html)。\n\n```shell\nswift web-ui\n```\n![image.png](./docs/resources/web-ui.png)\n\n### 使用Python\nms-swift也支持使用python的方式进行训练和推理。下面给出训练和推理的**伪代码**，具体可以查看[这里](https://github.com/modelscope/ms-swift/tree/main/examples/notebook)。\n\n训练：\n```python\n# 获取模型和template，并加入可训练的LoRA模块\nmodel, tokenizer = get_model_tokenizer(model_id_or_path, ...)\ntemplate = get_template(model.model_meta.template, tokenizer, ...)\nmodel = Swift.prepare_model(model, lora_config)\n\n# 下载并载入数据集，并将文本encode成tokens\ntrain_dataset, val_dataset = load_dataset(dataset_id_or_path, ...)\ntrain_dataset = EncodePreprocessor(template=template)(train_dataset, num_proc=num_proc)\nval_dataset = EncodePreprocessor(template=template)(val_dataset, num_proc=num_proc)\n\n# 进行训练\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=template.data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    template=template,\n)\ntrainer.train()\n```\n\n推理：\n```python\n# 使用原生pytorch引擎进行推理\nengine = PtEngine(model_id_or_path, adapters=[lora_checkpoint])\ninfer_request = InferRequest(messages=[{'role': 'user', 'content': 'who are you?'}])\nrequest_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature)\n\nresp_list = engine.infer([infer_request], request_config)\nprint(f'response: {resp_list[0].choices[0].message.content}')\n```\n\n## ✨ 如何使用\n\n这里给出使用ms-swift进行训练到部署到最简示例，具体可以查看[examples](https://github.com/modelscope/ms-swift/tree/main/examples).\n\n|   常用链接 |\n| ------ |\n|   [命令行参数](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0.html)   |\n|   [支持的模型和数据集](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86.html)   |\n|   [自定义模型](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B.html), [自定义数据集](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86.html)   |\n|   [大模型教程](https://github.com/modelscope/modelscope-classroom/tree/main/LLM-tutorial)   |\n\n### 训练\n\n预训练：\n```shell\n# 8*A100\nNPROC_PER_NODE=8 \\\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\nswift pt \\\n    --model Qwen/Qwen2.5-7B \\\n    --dataset swift/chinese-c4 \\\n    --streaming true \\\n    --train_type full \\\n    --deepspeed zero2 \\\n    --output_dir output \\\n    --max_steps 100000 \\\n    ...\n```\n\n微调：\n```shell\nCUDA_VISIBLE_DEVICES=0 swift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\nRLHF：\n```shell\nCUDA_VISIBLE_DEVICES=0 swift rlhf \\\n    --rlhf_type dpo \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset hjh0119/shareAI-Llama3-DPO-zh-en-emoji \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\n\n### 推理\n```shell\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n\n# LoRA\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --adapters swift/test_lora \\\n    --stream true \\\n    --infer_backend pt \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### 界面推理\n```shell\nCUDA_VISIBLE_DEVICES=0 swift app \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048 \\\n    --lang zh\n```\n\n### 部署\n```shell\nCUDA_VISIBLE_DEVICES=0 swift deploy \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend vllm\n```\n\n### 评测\n```shell\nCUDA_VISIBLE_DEVICES=0 swift eval \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend lmdeploy \\\n    --eval_dataset ARC_c\n```\n\n### 量化\n```shell\nCUDA_VISIBLE_DEVICES=0 swift export \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --quant_bits 4 --quant_method awq \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --output_dir Qwen2.5-7B-Instruct-AWQ\n```\n\n\n## 🏛 License\n\n本框架使用[Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE)进行许可。模型和数据集请查看原资源页面并遵守对应License。\n\n## 📎 引用\n\n```bibtex\n@misc{zhao2024swiftascalablelightweightinfrastructure,\n      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},\n      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},\n      year={2024},\n      eprint={2408.05517},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2408.05517},\n}\n```\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=modelscope/swift&type=Date)](https://star-history.com/#modelscope/ms-swift&Date)\n"
        },
        {
          "name": "asset",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.029296875,
          "content": "-r requirements/framework.txt\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.736328125,
          "content": "[isort]\nline_length = 120\nmulti_line_output = 0\nknown_standard_library = setuptools\nknown_first_party = swift\nknown_third_party = json,yaml\nno_lines_before = STDLIB,LOCALFOLDER\ndefault_section = THIRDPARTY\n\n[yapf]\nBASED_ON_STYLE = pep8\nCOLUMN_LIMIT = 120\nBLANK_LINE_BEFORE_NESTED_CLASS_OR_DEF = true\nSPLIT_BEFORE_EXPRESSION_AFTER_OPENING_PAREN = true\nSPLIT_BEFORE_ARITHMETIC_OPERATOR = true\n\n[codespell]\nskip = *.ipynb\nquiet-level = 3\nignore-words-list = patten,nd,ty,mot,hist,formating,winn,gool,datas,wan,confids\n\n[flake8]\nmax-line-length = 120\nselect = B,C,E,F,P,T4,W,B9\nignore = F401,F403,F405,F821,W503,E251,W504,E126\nexclude = docs/src,*.pyi,.git,peft.py\n\n[darglint]\nignore=DAR101\n\n[easy_install]\nindex-url=https://pypi.tuna.tsinghua.edu.cn/simple\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.0048828125,
          "content": "# Copyright (c) Alibaba, Inc. and its affiliates.\n# !/usr/bin/env python\nimport os\nfrom setuptools import find_packages, setup\nfrom typing import List\n\n\ndef readme():\n    with open('README.md', encoding='utf-8') as f:\n        content = f.read()\n    return content\n\n\nversion_file = 'swift/version.py'\n\n\ndef get_version():\n    with open(version_file, 'r', encoding='utf-8') as f:\n        exec(compile(f.read(), version_file, 'exec'))\n    return locals()['__version__']\n\n\ndef parse_requirements(fname='requirements.txt', with_version=True):\n    \"\"\"\n    Parse the package dependencies listed in a requirements file but strips\n    specific versioning information.\n\n    Args:\n        fname (str): path to requirements file\n        with_version (bool, default=False): if True include version specs\n\n    Returns:\n        List[str]: list of requirements items\n\n    CommandLine:\n        python -c \"import setup; print(setup.parse_requirements())\"\n    \"\"\"\n    import re\n    import sys\n    from os.path import exists\n    require_fpath = fname\n\n    def parse_line(line):\n        \"\"\"\n        Parse information from a line in a requirements text file\n        \"\"\"\n        if line.startswith('-r '):\n            # Allow specifying requirements in other files\n            target = line.split(' ')[1]\n            relative_base = os.path.dirname(fname)\n            absolute_target = os.path.join(relative_base, target)\n            for info in parse_require_file(absolute_target):\n                yield info\n        else:\n            info = {'line': line}\n            if line.startswith('-e '):\n                info['package'] = line.split('#egg=')[1]\n            else:\n                # Remove versioning from the package\n                pat = '(' + '|'.join(['>=', '==', '>']) + ')'\n                parts = re.split(pat, line, maxsplit=1)\n                parts = [p.strip() for p in parts]\n\n                info['package'] = parts[0]\n                if len(parts) > 1:\n                    op, rest = parts[1:]\n                    if ';' in rest:\n                        # Handle platform specific dependencies\n                        # http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies\n                        version, platform_deps = map(str.strip, rest.split(';'))\n                        info['platform_deps'] = platform_deps\n                    else:\n                        version = rest  # NOQA\n                    info['version'] = (op, version)\n            yield info\n\n    def parse_require_file(fpath):\n        with open(fpath, 'r', encoding='utf-8') as f:\n            for line in f.readlines():\n                line = line.strip()\n                if line.startswith('http'):\n                    print('skip http requirements %s' % line)\n                    continue\n                if line and not line.startswith('#') and not line.startswith('--'):\n                    for info in parse_line(line):\n                        yield info\n                elif line and line.startswith('--find-links'):\n                    eles = line.split()\n                    for e in eles:\n                        e = e.strip()\n                        if 'http' in e:\n                            info = dict(dependency_links=e)\n                            yield info\n\n    def gen_packages_items():\n        items = []\n        deps_link = []\n        if exists(require_fpath):\n            for info in parse_require_file(require_fpath):\n                if 'dependency_links' not in info:\n                    parts = [info['package']]\n                    if with_version and 'version' in info:\n                        parts.extend(info['version'])\n                    if not sys.version.startswith('3.4'):\n                        # apparently package_deps are broken in 3.4\n                        platform_deps = info.get('platform_deps')\n                        if platform_deps is not None:\n                            parts.append(';' + platform_deps)\n                    item = ''.join(parts)\n                    items.append(item)\n                else:\n                    deps_link.append(info['dependency_links'])\n        return items, deps_link\n\n    return gen_packages_items()\n\n\nif __name__ == '__main__':\n    install_requires, deps_link = parse_requirements('requirements.txt')\n    extra_requires = {}\n    all_requires = []\n    extra_requires['eval'], _ = parse_requirements('requirements/eval.txt')\n    extra_requires['seq_parallel'], _ = parse_requirements('requirements/seq_parallel.txt')\n    all_requires.extend(install_requires)\n    all_requires.extend(extra_requires['eval'])\n    all_requires.extend(extra_requires['seq_parallel'])\n    extra_requires['all'] = all_requires\n\n    setup(\n        name='ms-swift',\n        version=get_version(),\n        description='Swift: Scalable lightWeight Infrastructure for Fine-Tuning',\n        long_description=readme(),\n        long_description_content_type='text/markdown',\n        author='DAMO ModelScope teams',\n        author_email='contact@modelscope.cn',\n        keywords='python, petl, efficient tuners',\n        url='https://github.com/modelscope/swift',\n        packages=find_packages(exclude=('configs', 'demo')),\n        include_package_data=True,\n        package_data={\n            '': ['*.h', '*.cpp', '*.cu'],\n        },\n        classifiers=[\n            'Development Status :: 4 - Beta',\n            'License :: OSI Approved :: Apache Software License',\n            'Operating System :: OS Independent',\n            'Programming Language :: Python :: 3',\n            'Programming Language :: Python :: 3.8',\n            'Programming Language :: Python :: 3.9',\n            'Programming Language :: Python :: 3.10',\n            'Programming Language :: Python :: 3.11',\n            'Programming Language :: Python :: 3.12',\n        ],\n        license='Apache License 2.0',\n        tests_require=parse_requirements('requirements/tests.txt'),\n        install_requires=install_requires,\n        extras_require=extra_requires,\n        entry_points={'console_scripts': ['swift=swift.cli.main:cli_main']},\n        dependency_links=deps_link,\n        zip_safe=False)\n"
        },
        {
          "name": "swift",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}