{
  "metadata": {
    "timestamp": 1736559455250,
    "page": 9,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "modelscope/ms-swift",
      "stars": 4981,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".dev_scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.5517578125,
          "content": "# Byte-compiled / optimized / DLL files\ntmp\n*.ttf\n__pycache__/\n*.py[cod]\n*$py.class\ntest.py\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n/package\n/temp\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n.vscode\n.idea\n.run\n\n# custom\n*.pkl\n*.pkl.json\n*.log.json\n*.whl\n*.tar.gz\n*.swp\n*.log\n*.tar.gz\nsource.sh\ntensorboard.sh\n.DS_Store\nreplace.sh\nresult.png\nresult.jpg\nresult.mp4\noutput/\noutputs/\n*.out\nbenchmarks/\neval_output/\neval_outputs/\ntransformers/\nvlmeval/\nmy_model/\n/data\nresult/\nimages\n/custom/\n\n# Pytorch\n*.pth\n*.pt\n\n# ast template\nast_index_file.py\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.373046875,
          "content": "repos:\n  - repo: https://github.com/pycqa/flake8.git\n    rev: 4.0.0\n    hooks:\n      - id: flake8\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/PyCQA/isort.git\n    rev: 4.3.21\n    hooks:\n      - id: isort\n        exclude: |\n            (?x)^(\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/pre-commit/mirrors-yapf.git\n    rev: v0.30.0\n    hooks:\n      - id: yapf\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: https://github.com/pre-commit/pre-commit-hooks.git\n    rev: v3.1.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: thirdparty/|tests/run.py\n      - id: check-yaml\n        exclude: thirdparty/|tests/run.py\n      - id: end-of-file-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: requirements-txt-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: double-quote-string-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: check-merge-conflict\n        exclude: thirdparty/|tests/run.py\n      - id: fix-encoding-pragma\n        exclude: thirdparty/|tests/run.py\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        exclude: thirdparty/|tests/run.py\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": ".pre-commit-config_local.yaml",
          "type": "blob",
          "size": 1.3271484375,
          "content": "repos:\n  - repo: /home/admin/pre-commit/flake8\n    rev: 4.0.0\n    hooks:\n      - id: flake8\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/isort\n    rev: 4.3.21\n    hooks:\n      - id: isort\n        exclude: |\n            (?x)^(\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/mirrors-yapf\n    rev: v0.30.0\n    hooks:\n      - id: yapf\n        exclude: |\n            (?x)^(\n                thirdparty/|\n                examples/|\n                tests/run.py\n            )$\n  - repo: /home/admin/pre-commit/pre-commit-hooks\n    rev: v3.1.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: thirdparty/|tests/run.py\n      - id: check-yaml\n        exclude: thirdparty/|tests/run.py\n      - id: end-of-file-fixer\n        exclude: thirdparty/\n      - id: requirements-txt-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: double-quote-string-fixer\n        exclude: thirdparty/|tests/run.py\n      - id: check-merge-conflict\n        exclude: thirdparty/|tests/run.py\n      - id: fix-encoding-pragma\n        exclude: thirdparty/|tests/run.py\n        args: [\"--remove\"]\n      - id: mixed-line-ending\n        exclude: thirdparty/|tests/run.py\n        args: [\"--fix=lf\"]\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 5.357421875,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\ncontact@modelscope.cn.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.7099609375,
          "content": "# Contributor Guide\n\n_Welcome to offer PRs, bug reports, documentation supplements or other types of contributions to SWIFT!_\n\n## Table of Contents\n- [Code of Conduct](#-code-of-conduct)\n- [Contribution Process](#-contribution-process)\n- [Hardware support](#-Hardware-support)\n\n## ğŸ“– Code of Conduct\nPlease refer to our [Code of Conduct documentation](./CODE_OF_CONDUCT.md).\n\n## ğŸ” Contribution Process\n### What We Need\n- ROADMAP: We provide a [ROADMAP](./ROADMAP.md) for each iteration of SWIFT, contributors can check our ROADMAP to understand our development progress and plans. Features in **To be Assigned** is available for all developers.\n- New Technologies and New Models: SWIFT needs to support more open-source models and datasets, or new technologies that we have not paid attention to. If you are interested please submit a PR to us.\n- Technical Propagation: If you are interested in technical propagation, you are welcome to help us write tutorials, documents or videos on any website, and send us the link.\n- Community Contribution: You can write technical articles related to SWIFT, and submit them to us. After review and approval, we will publish them on the official ModelScope accounts (Zhihu, WeChat, etc.), with your name assigned.\n\n### Incentives\n- we will issue electronic certificates to contributors on behalf of the ModelScope community, to encourage your selfless contributions.\n- We will offer small souvenirs related to the ModelScope Community.\n- We will provide free A10 computing power during the development period. For more details, please refer to [Hardware-support](#-Hardware-support) section.\n\n### Submitting PR (Pull Requests)\n\nAny feature development is carried out in the form of Fork and then PR on GitHub.\n1. Fork: Go to the [SWIFT](https://github.com/modelscope/swift) page and click the **Fork button**. After completion, a SWIFT code repository will be cloned under your personal organization.\n2. Clone: Clone the code repository generated in the first step to your local machine and **create a new branch** for development. During development, please click the **Sync Fork button** in time to synchronize with the `main` branch to prevent code expiration and conflicts.\n3. Submit PR: After development and testing, push the code to the remote branch. On GitHub, go to the **Pull Requests page**, create a new PR, select your code branch as the source branch, and the `modelscope/swift:main` branch as the target branch.\n\n4. Write Description: It is necessary to provide a good feature description in the PR, so that the reviewers know the content of your modification.\n5. Review: We hope that the code to be merged is concise and efficient, so we may raise some questions and discuss them. Please note that any issues raised in the review are aimed at the code itself, not at you personally. Once all issues are discussed and resolved, your code will be approved.\n\n### Code Standards and Development Approach\nSWIFT has conventional variable naming conventions and development approaches. Please follow these approaches as much as possible during development.\n1. Variable names are separated by underscores, and class names are named with the first letter of each word capitalized.\n2. All Python indentation uses four spaces instead of a tab.\n3. Choose well-known open-source libraries, avoid using closed-source libraries or unstable open-source libraries, and avoid repeating the existing code.\n\nAfter the PR is submitted, SWIFT will perform two types of tests:\n- Code Lint Test: A static code compliance check test. please make sure that you have performed code lint locally in advance.\n```shell\npip install pre-commit # In the swift folder\npre-commit run --all-files # Fix the errors reported by pre-commit until all checks are successful\n```\n- CI Tests: Smoke tests and unit tests, please refer to the next section.\n\n### Running CI Tests\nBefore submitting the PR, please ensure that your development code is protected by test cases, such as smoke tests for new features, or unit tests for various edge cases. Reviewers will also pay attention to this during code review. At the same time, there will be dedicated services running CI Tests, running all test cases, and the code can only be merged after the test cases pass.\n\nAdditionally, since some important tests have been skipped due to long running time, to ensure that your logic is correct, you can run the test locally:\n```shell\npython tests/llm/test_run.py\n```\nPlease make sure this test can pass normally.\n\n## âœ… Hardware support\n\nSWIFT will provide hardware support for developers, including free GPUs. If needed, please email us ([contact@modelscope.cn](mailto:contact@modelscope.cn)) or join our WeChat group:\n\n<p align=\"left\">\n<img src=\"asset/wechat.png\" width=\"250\" style=\"display: inline-block;\">\n</p>\n"
        },
        {
          "name": "CONTRIBUTING_CN.md",
          "type": "blob",
          "size": 3.9990234375,
          "content": "# è´¡çŒ®è€…æŒ‡å¼•\n\n*æ¬¢è¿å¸®SWIFTæä¾›Feature PRã€Bugåé¦ˆã€æ–‡æ¡£è¡¥å……æˆ–å…¶ä»–ç±»å‹çš„è´¡çŒ®ï¼*\n\n## ç›®å½•\n\n- [ä»£ç è§„çº¦](#-ä»£ç è§„çº¦)\n- [è´¡çŒ®æµç¨‹](#-è´¡çŒ®æµç¨‹)\n- [èµ„æºæ”¯æŒ](#-èµ„æºæ”¯æŒ)\n\n## ğŸ“– ä»£ç è§„çº¦\n\nè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[ä»£ç è§„çº¦æ–‡æ¡£](./CODE_OF_CONDUCT.md).\n\n## ğŸ” è´¡çŒ®æµç¨‹\n\n### æˆ‘ä»¬éœ€è¦ä»€ä¹ˆ\n\n- ROADMAPï¼šæˆ‘ä»¬ä¸ºSWIFTæä¾›äº†æ¯ä¸ªè¿­ä»£çš„[ROADMAP](./ROADMAP.md)ï¼Œè´¡çŒ®è€…å¯ä»¥æŸ¥çœ‹æˆ‘ä»¬çš„ROADMAPæ¥äº†è§£æˆ‘ä»¬çš„å¼€å‘è¿›åº¦å’Œè§„åˆ’ã€‚åœ¨**å¾…åˆ†é…**ä¸­çš„featureå¯ä»¥è®¤é¢†å¹¶å¼€å‘ã€‚\n\n- æ–°æŠ€æœ¯å’Œæ–°æ¨¡å‹ï¼šSWIFTéœ€è¦æ”¯æŒæ›´å¤šçš„å¼€æºæ¨¡å‹å’Œæ•°æ®é›†ï¼Œæˆ–æˆ‘ä»¬æ²¡æœ‰å…³æ³¨åˆ°çš„æ–°æŠ€æœ¯ï¼Œå¦‚æœæ‚¨å¯¹æ­¤æœ‰å…´è¶£ï¼Œå¯ä»¥æäº¤PRç»™æˆ‘ä»¬ã€‚\n- æŠ€æœ¯å¸ƒé“ï¼šå¦‚æœæ‚¨å¯¹æŠ€æœ¯å¸ƒé“æœ‰å…´è¶£ï¼Œæ¬¢è¿åœ¨ä»»ä½•ç½‘ç«™ä¸Šå¸®æˆ‘ä»¬æ’°å†™æ•™ç¨‹æ–‡æ¡£æˆ–è§†é¢‘ç­‰ï¼Œå¹¶å°†é“¾æ¥å‘ç»™æˆ‘ä»¬ã€‚\n- ç¤¾åŒºä¾›ç¨¿ï¼šæ‚¨å¯ä»¥æ’°å†™å’ŒSWIFTæœ‰å…³çš„æŠ€æœ¯æ–‡ç« ï¼Œå¹¶ä¾›ç¨¿ç»™æˆ‘ä»¬ï¼Œæˆ‘ä»¬å®¡æ ¸é€šè¿‡åä¼šåœ¨é­”æ­å®˜æ–¹è´¦å·ï¼ˆçŸ¥ä¹ã€å…¬ä¼—å·ç­‰ï¼‰ä¸Šè¿›è¡Œå‘å¸ƒï¼Œå¹¶å±ä¸Šæ‚¨çš„åå­—ã€‚\n\n### æ¿€åŠ±\n\n- æˆ‘ä»¬ä¼šä»¥é­”æ­ç¤¾åŒºçš„èº«ä»½ç»™è´¡çŒ®è€…é¢å‘ç”µå­è¯ä¹¦ï¼Œä»¥é¼“åŠ±æ‚¨çš„æ— ç§è´¡çŒ®ã€‚\n- æˆ‘ä»¬ä¼šèµ é€ç›¸å…³é­”æ­ç¤¾åŒºç›¸å…³å‘¨è¾¹å°ç¤¼å“ã€‚\n- æˆ‘ä»¬ä¼šèµ é€å¼€å‘æœŸé—´çš„å…è´¹A10ç®—åŠ›ï¼Œå…·ä½“å¯ä»¥æŸ¥çœ‹[èµ„æºæ”¯æŒ](#-èµ„æºæ”¯æŒ)ç« èŠ‚ã€‚\n\n### æäº¤PRï¼ˆPull Requestsï¼‰\n\nä»»ä½•featureå¼€å‘éƒ½åœ¨githubä¸Šä»¥å…ˆForkåPRçš„å½¢å¼è¿›è¡Œã€‚\n\n1. Forkï¼šè¿›å…¥[SWIFT](https://github.com/modelscope/swift)é¡µé¢åï¼Œç‚¹å‡»**ForkæŒ‰é’®**æ‰§è¡Œã€‚å®Œæˆåä¼šåœ¨æ‚¨çš„ä¸ªäººç»„ç»‡ä¸‹å…‹éš†å‡ºä¸€ä¸ªSWIFTä»£ç åº“\n\n2. Cloneï¼šå°†ç¬¬ä¸€æ­¥äº§ç”Ÿçš„ä»£ç åº“cloneåˆ°æœ¬åœ°å¹¶**æ‹‰æ–°åˆ†æ”¯**è¿›è¡Œå¼€å‘ï¼Œå¼€å‘ä¸­è¯·åŠæ—¶ç‚¹å‡»**Sync ForkæŒ‰é’®**åŒæ­¥`main`åˆ†æ”¯ï¼Œé˜²æ­¢ä»£ç è¿‡æœŸå¹¶å†²çª\n\n3. æäº¤PRï¼šå¼€å‘ã€æµ‹è¯•å®Œæˆåå°†ä»£ç æ¨é€åˆ°è¿œç¨‹åˆ†æ”¯ã€‚åœ¨githubä¸Šç‚¹å‡»**Pull Requestsé¡µé¢**ï¼Œæ–°å»ºä¸€ä¸ªPRï¼Œæºåˆ†æ”¯é€‰æ‹©æ‚¨æäº¤çš„ä»£ç åˆ†æ”¯ï¼Œç›®æ ‡åˆ†æ”¯é€‰æ‹©`modelscope/swift:main`åˆ†æ”¯\n\n4. æ’°å†™æè¿°ï¼šåœ¨PRä¸­å¡«å†™è‰¯å¥½çš„featureæè¿°æ˜¯å¿…è¦çš„ï¼Œè®©ReviewersçŸ¥é“æ‚¨çš„ä¿®æ”¹å†…å®¹\n\n5. Reviewï¼šæˆ‘ä»¬å¸Œæœ›åˆå…¥çš„ä»£ç ç®€æ´é«˜æ•ˆï¼Œå› æ­¤å¯èƒ½ä¼šæå‡ºä¸€äº›é—®é¢˜å¹¶è®¨è®ºã€‚è¯·æ³¨æ„ï¼Œä»»ä½•reviewä¸­æå‡ºçš„é—®é¢˜æ˜¯é’ˆå¯¹ä»£ç æœ¬èº«ï¼Œè€Œéæ‚¨ä¸ªäººã€‚åœ¨æ‰€æœ‰é—®é¢˜è®¨è®ºé€šè¿‡åï¼Œæ‚¨çš„ä»£ç ä¼šè¢«é€šè¿‡\n\n### ä»£ç è§„èŒƒå’Œå¼€å‘æ–¹å¼\n\nSWIFTæœ‰çº¦å®šä¿—æˆçš„å˜é‡å‘½åæ–¹å¼å’Œå¼€å‘æ–¹å¼ã€‚åœ¨å¼€å‘ä¸­è¯·å°½é‡éµå¾ªè¿™äº›æ–¹å¼ã€‚\n\n1. å˜é‡å‘½åä»¥ä¸‹åˆ’çº¿åˆ†å‰²ï¼Œç±»åä»¥æ‰€æœ‰å•è¯é¦–å­—æ¯å¤§å†™æ–¹å¼å‘½å\n2. æ‰€æœ‰çš„pythonç¼©è¿›éƒ½æ˜¯å››ä¸ªç©ºæ ¼å–ä»£ä¸€ä¸ªtab\n3. é€‰ç”¨çŸ¥åçš„å¼€æºåº“ï¼Œé¿å…ä½¿ç”¨é—­æºåº“æˆ–ä¸ç¨³å®šçš„å¼€æºåº“ï¼Œé¿å…é‡å¤é€ è½®å­\n\nSWIFTåœ¨PRæäº¤åä¼šè¿›è¡Œä¸¤ç±»æµ‹è¯•ï¼š\n\n- Code Lintæµ‹è¯• å¯¹ä»£ç è¿›è¡Œé™æ€è§„èŒƒèµ°æŸ¥çš„æµ‹è¯•ï¼Œä¸ºä¿è¯æ”¹æµ‹è¯•é€šè¿‡ï¼Œè¯·ä¿è¯æœ¬åœ°é¢„å…ˆè¿›è¡Œäº†Code lintã€‚æ–¹æ³•æ˜¯ï¼š\n\n  ```shell\n  pip install pre-commit\n  # åœ¨swiftæ–‡ä»¶å¤¹å†…\n  pre-commit run --all-files\n  # å¯¹pre-commitæŠ¥çš„é”™è¯¯è¿›è¡Œä¿®æ”¹ï¼Œç›´åˆ°æ‰€æœ‰çš„æ£€æŸ¥éƒ½æ˜¯æˆåŠŸçŠ¶æ€\n  ```\n\n- CI Tests å†’çƒŸæµ‹è¯•å’Œå•å…ƒæµ‹è¯•ï¼Œè¯·æŸ¥çœ‹ä¸‹ä¸€ç« èŠ‚\n\n### Running CI Tests\n\nåœ¨æäº¤PRå‰ï¼Œè¯·ä¿è¯æ‚¨çš„å¼€å‘ä»£ç å·²ç»å—åˆ°äº†æµ‹è¯•ç”¨ä¾‹çš„ä¿æŠ¤ã€‚ä¾‹å¦‚ï¼Œå¯¹æ–°åŠŸèƒ½çš„å†’çƒŸæµ‹è¯•ï¼Œæˆ–è€…å„ç§è¾¹ç¼˜caseçš„å•å…ƒæµ‹è¯•ç­‰ã€‚åœ¨ä»£ç reviewæ—¶Reviewersä¹Ÿä¼šå…³æ³¨è¿™ä¸€ç‚¹ã€‚åŒæ—¶ï¼Œä¹Ÿä¼šæœ‰æœåŠ¡ä¸“é—¨è¿è¡ŒCI Testsï¼Œè¿è¡Œæ‰€æœ‰çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæµ‹è¯•ç”¨ä¾‹é€šè¿‡åä»£ç æ‰å¯ä»¥åˆå¹¶ã€‚\n\nå¦å¤–ï¼Œç”±äºè¿è¡Œæ—¶é—´è¿‡é•¿ï¼Œæˆ‘ä»¬è·³è¿‡äº†éƒ¨åˆ†é‡è¦æµ‹è¯•ï¼Œä¸ºä¿è¯æ‚¨çš„é€»è¾‘æ˜¯æ­£ç¡®çš„ï¼Œå¯ä»¥åœ¨æœ¬åœ°æ‰§è¡Œè¯¥æµ‹è¯•ï¼š\n\n```shell\npython tests/llm/test_run.py\n```\n\nè¯·ä¿è¯è¯¥æµ‹è¯•å¯ä»¥æ­£å¸¸é€šè¿‡ã€‚\n\n## âœ… èµ„æºæ”¯æŒ\n\nSWIFTä¼šä¸ºå¼€å‘è€…æä¾›èµ„æºæ”¯æŒï¼ŒåŒ…æ‹¬å…è´¹çš„GPUç®—åŠ›ã€‚å¦‚æœéœ€è¦è¯·é‚®ä»¶è”ç³»æˆ‘ä»¬ï¼ˆ[contact@modelscope.cn](mailto:contact@modelscope.cn)ï¼‰æˆ–åŠ å…¥æˆ‘ä»¬çš„å¾®ä¿¡ç¾¤ï¼š\n\n<p align=\"left\">\n<img src=\"asset/wechat.png\" width=\"250\" style=\"display: inline-block;\">\n</p>\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.201171875,
          "content": "recursive-include swift/utils *.py\nrecursive-include swift/llm/dataset/data *.*\nrecursive-include swift/llm/ds_config *.json\nrecursive-include requirements *.txt\nrecursive-include swift/plugin/agent *.json\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.3505859375,
          "content": "WHL_BUILD_DIR :=package\nDOC_BUILD_DIR :=docs/build/\n\n# default rule\ndefault: whl docs\n\n.PHONY: docs\ndocs:\n\tbash .dev_scripts/build_docs.sh\n\n.PHONY: linter\nlinter:\n\tbash .dev_scripts/linter.sh\n\n.PHONY: test\ntest:\n\tbash .dev_scripts/citest.sh\n\n.PHONY: whl\nwhl:\n\tpython setup.py sdist bdist_wheel\n\n.PHONY: clean\nclean:\n\trm -rf  $(WHL_BUILD_DIR) $(DOC_BUILD_DIR)\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 14.046875,
          "content": "# SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning)\n\n<p align=\"center\">\n    <br>\n    <img src=\"asset/banner.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n<a href=\"https://modelscope.cn/home\">ModelScope Community Website</a>\n<br>\n        <a href=\"README_CN.md\">ä¸­æ–‡</a> &nbsp ï½œ &nbsp English &nbsp\n</p>\n\n<p align=\"center\">\n<img src=\"https://img.shields.io/badge/python-3.10-5be.svg\">\n<img src=\"https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg\">\n<a href=\"https://github.com/modelscope/modelscope/\"><img src=\"https://img.shields.io/badge/modelscope-%E2%89%A51.19-5D91D4.svg\"></a>\n<a href=\"https://pypi.org/project/ms-swift/\"><img src=\"https://badge.fury.io/py/ms-swift.svg\"></a>\n<a href=\"https://github.com/modelscope/swift/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/modelscope/swift\"></a>\n<a href=\"https://pepy.tech/project/ms-swift\"><img src=\"https://pepy.tech/badge/ms-swift\"></a>\n<a href=\"https://github.com/modelscope/swift/pulls\"><img src=\"https://img.shields.io/badge/PR-welcome-55EB99.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/6427\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/6427\" alt=\"modelscope%2Fswift | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n        <a href=\"https://arxiv.org/abs/2408.05517\">Paper</a> &nbsp ï½œ <a href=\"https://swift.readthedocs.io/en/latest/\">English Documentation</a> &nbsp ï½œ &nbsp <a href=\"https://swift.readthedocs.io/zh-cn/latest/\">ä¸­æ–‡æ–‡æ¡£</a> &nbsp\n</p>\n<p align=\"center\">\n        <a href=\"https://swift2x-en.readthedocs.io/en/latest/\">Swift2.x En Doc</a> &nbsp ï½œ &nbsp <a href=\"https://swift2x.readthedocs.io/zh-cn/latest/\">Swift2.xä¸­æ–‡æ–‡æ¡£</a> &nbsp\n</p>\n\n\n## ğŸ“– Table of Contents\n- [Groups](#-Groups)\n- [Introduction](#-introduction)\n- [News](#-news)\n- [Installation](#%EF%B8%8F-installation)\n- [Quick Start](#-quick-Start)\n- [Usage](#-Usage)\n- [License](#-License)\n- [Citation](#-citation)\n\n\n## â˜ Groups\n\nYou can contact us and communicate with us by adding our group:\n\n\n[Discord Group](https://discord.com/invite/D27yfEFVz5)              |  WeChat Group\n:-------------------------:|:-------------------------:\n<img src=\"asset/discord_qr.jpg\" width=\"200\" height=\"200\">  |  <img src=\"asset/wechat.png\" width=\"200\" height=\"200\">\n\n\n## ğŸ“ Introduction\nğŸ² ms-swift is an official framework provided by the ModelScope community for fine-tuning and deploying large language models and multi-modal large models. It currently supports the training (pre-training, fine-tuning, human alignment), inference, evaluation, quantization, and deployment of 400+ large models and 150+ multi-modal large models. These large language models (LLMs) include models such as Qwen2.5, Llama3.3, GLM4, Internlm2.5, Yi1.5, Mistral, DeepSeek2.5, Baichuan2, Gemma2, and TeleChat2. The multi-modal LLMs include models such as Qwen2-VL, Qwen2-Audio, Llama3.2-Vision, Llava, InternVL2.5, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, Yi-VL, DeepSeek-VL2, Phi3.5-Vision, and GOT-OCR2.\n\nğŸ” In addition, ms-swift gathers the latest training technologies, including LoRA, QLoRA, Llama-Pro, LongLoRA, GaLore, Q-GaLore, LoRA+, LISA, DoRA, FourierFt, ReFT, UnSloth, and Liger. ms-swift supports acceleration of inference, evaluation, and deployment modules using vLLM and LMDeploy, and supports the quantization of large models and multi-modal large models using technologies such as GPTQ, AWQ, and BNB. To help researchers and developers fine-tune and apply large models more easily, ms-swift also provides a Gradio-based Web-UI interface and a wealth of best practices.\n\n**Why choose ms-swift?**\n\n- ğŸ **Model Types**: Supports 400+ large language models and **150+ multi-modal large models** and all-to-all models, **providing a comprehensive solution from training to deployment**.\n- **Dataset Types**: Comes with 150+ pre-training, fine-tuning, human alignment, multi-modal datasets, and supports custom datasets.\n- **Hardware Support**: Compatible with CPU, RTX series, T4/V100, A10/A100/H100, Ascend NPU, etc.\n- ğŸŠ **Lightweight Training**: Supports lightweight fine-tuning methods like LoRA, QLoRA, DoRA, LoRA+, ReFT, RS-LoRA, LLaMAPro, Adapter, GaLore, Q-Galore, LISA, UnSloth, Liger-Kernel.\n- **Distributed Training**: Supports distributed data parallel (DDP), device_map simple model parallelism, DeepSpeed ZeRO2/ZeRO3, FSDP, and other distributed training techniques.\n- **Quantization Training**: Supports training quantized models like BNB, AWQ, GPTQ, AQLM, HQQ, EETQ.\n- **RLHF Training**: Supports human alignment training methods such as DPO, CPO, SimPO, ORPO, KTO, RM, PPO for both pure text and multi-modal large models.\n- ğŸ“ **Multi-Modal Training**: Supports training on different modalities like images, videos, and audio, for tasks like VQA, captioning, OCR, and grounding.\n- **Interface Training**: Provides capabilities for training, inference, evaluation, quantization through an interface, completing the whole large model pipeline.\n- **Plugin and Extension**: Supports custom model and dataset extensions, as well as customization of components like loss, metric, trainer, loss-scale, callback, optimizer.\n- ğŸ‰ **Toolbox Capabilities**: Offers not only training support for large models and multi-modal large models but also covers the entire process of inference, evaluation, quantization, and deployment.\n- **Inference Acceleration**: Supports inference acceleration engines like PyTorch, vLLM, LmDeploy, and provides OpenAI API for accelerating inference, deployment, and evaluation modules.\n- **Model Evaluation**: Uses EvalScope as the evaluation backend and supports evaluation on 100+ datasets for both pure text and multi-modal models.\n- **Model Quantization**: Supports AWQ, GPTQ, and BNB quantized exports, with models that can use vLLM/LmDeploy for inference acceleration and continue training.\n\n\n## ğŸ‰ News\n\n- ğŸ 2024.12.04: **SWIFT3.0** major version update. Please check the [Release Notes and Changes](https://swift.readthedocs.io/en/latest/Instruction/ReleaseNote3.0.html).\n- ğŸ‰ 2024.08.12: The SWIFT paper has been published on arXiv, and you can read it [here](https://arxiv.org/abs/2408.05517).\n- ğŸ”¥ 2024.08.05: Support for using [evalscope](https://github.com/modelscope/evalscope/) as a backend for evaluating large models and multimodal models.\n- ğŸ”¥ 2024.07.29: Support for using [vllm](https://github.com/vllm-project/vllm) and [lmdeploy](https://github.com/InternLM/lmdeploy) to accelerate inference for large models and multimodal models. When performing infer/deploy/eval, you can specify `--infer_backend vllm/lmdeploy`.\n- ğŸ”¥ 2024.07.24: Support for human preference alignment training for multimodal large models, including DPO/ORPO/SimPO/CPO/KTO/RM/PPO.\n- ğŸ”¥ 2024.02.01: Support for Agent training! The training algorithm is derived from [this paper](https://arxiv.org/pdf/2309.00986.pdf).\n\n\n## ğŸ› ï¸ Installation\nTo install using pip:\n```shell\npip install ms-swift -U\n```\n\nTo install from source:\n```shell\n# pip install git+https://github.com/modelscope/ms-swift.git\n\ngit clone https://github.com/modelscope/ms-swift.git\ncd ms-swift\npip install -e .\n```\n\n## ğŸš€ Quick Start\n\n10 minutes of self-cognition fine-tuning of Qwen2.5-7B-Instruct on a single 3090 GPU:\n\n### Command Line Interface\n\n```shell\n# 22GB\nCUDA_VISIBLE_DEVICES=0 \\\nswift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \\\n              'AI-ModelScope/alpaca-gpt4-data-en#500' \\\n              'swift/self-cognition#500' \\\n    --torch_dtype bfloat16 \\\n    --num_train_epochs 1 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 5 \\\n    --max_length 2048 \\\n    --output_dir output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-robot\n```\n\nAfter training is complete, use the following command to perform inference with the trained weights. The `--adapters` option should be replaced with the last checkpoint folder generated from the training. Since the adapters folder contains the parameter files from the training, there is no need to specify `--model` or `--system` separately.\n\n```shell\n# Using an interactive command line for inference.\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n\n# merge-lora and use vLLM for inference acceleration\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --merge_lora true \\\n    --infer_backend vllm \\\n    --max_model_len 8192 \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Web-UI\nThe Web-UI is a **zero-threshold** training and deployment interface solution based on Gradio interface technology. For more details, you can check [here](https://swift.readthedocs.io/en/latest/GetStarted/Web-UI.html).\n\n```shell\nSWIFT_UI_LANG=en swift web-ui\n```\n\n![image.png](./docs/resources/web-ui-en.jpg)\n\n### Using Python\n\nms-swift also supports training and inference using Python. Below is pseudocode for training and inference. For more details, you can refer to [here](https://github.com/modelscope/ms-swift/tree/main/examples/notebook).\n\nTraining:\n\n```python\n# Retrieve the model and template, and add a trainable LoRA module\nmodel, tokenizer = get_model_tokenizer(model_id_or_path, ...)\ntemplate = get_template(model.model_meta.template, tokenizer, ...)\nmodel = Swift.prepare_model(model, lora_config)\n\n# Download and load the dataset, and encode the text into tokens\ntrain_dataset, val_dataset = load_dataset(dataset_id_or_path, ...)\ntrain_dataset = EncodePreprocessor(template=template)(train_dataset, num_proc=num_proc)\nval_dataset = EncodePreprocessor(template=template)(val_dataset, num_proc=num_proc)\n\n# Train the model\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=template.data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    template=template,\n)\ntrainer.train()\n```\nInference:\n\n```python\n# Perform inference using the native PyTorch engine\nengine = PtEngine(model_id_or_path, adapters=[lora_checkpoint])\ninfer_request = InferRequest(messages=[{'role': 'user', 'content': 'who are you?'}])\nrequest_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature)\n\nresp_list = engine.infer([infer_request], request_config)\nprint(f'response: {resp_list[0].choices[0].message.content}')\n```\n\n## âœ¨ Usage\nHere is the simplest example of training to deployment using ms-swift. For more details, you can check the [examples](https://github.com/modelscope/ms-swift/tree/main/examples).\n\n|   Useful Links |\n| ------ |\n|   [Command Line Parameters](https://swift.readthedocs.io/en/latest/Instruction/Command-line-parameters.html)   |\n|   [Supported Models and Datasets](https://swift.readthedocs.io/en/latest/Instruction/Supported-models-and-datasets.html)   |\n|   [Custom Models](https://swift.readthedocs.io/en/latest/Customization/Custom-model.html), [Custom Datasets](https://swift.readthedocs.io/en/latest/Customization/Custom-dataset.html)   |\n|   [LLM Tutorial](https://github.com/modelscope/modelscope-classroom/tree/main/LLM-tutorial)   |\n\n### Training\n\nPre-training:\n```shell\n# 8*A100\nNPROC_PER_NODE=8 \\\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\nswift pt \\\n    --model Qwen/Qwen2.5-7B \\\n    --dataset swift/chinese-c4 \\\n    --streaming true \\\n    --train_type full \\\n    --deepspeed zero2 \\\n    --output_dir output \\\n    --max_steps 100000 \\\n    ...\n```\n\nFine-tuning:\n```shell\nCUDA_VISIBLE_DEVICES=0 swift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-en \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\nRLHF:\n```shell\nCUDA_VISIBLE_DEVICES=0 swift rlhf \\\n    --rlhf_type dpo \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset hjh0119/shareAI-Llama3-DPO-zh-en-emoji \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\n\n### Inference\n```shell\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n\n# LoRA\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --adapters swift/test_lora \\\n    --stream true \\\n    --infer_backend pt \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Interface Inference\n```shell\nCUDA_VISIBLE_DEVICES=0 swift app \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n```\n\n### Deployment\n```shell\nCUDA_VISIBLE_DEVICES=0 swift deploy \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend vllm\n```\n\n### Evaluation\n```shell\nCUDA_VISIBLE_DEVICES=0 swift eval \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend lmdeploy \\\n    --eval_dataset ARC_c\n```\n\n### Quantization\n```shell\nCUDA_VISIBLE_DEVICES=0 swift export \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --quant_bits 4 --quant_method awq \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --output_dir Qwen2.5-7B-Instruct-AWQ\n```\n\n## ğŸ› License\n\nThis framework is licensed under the [Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE). For models and datasets, please refer to the original resource page and follow the corresponding License.\n\n## ğŸ“ Citation\n\n```bibtex\n@misc{zhao2024swiftascalablelightweightinfrastructure,\n      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},\n      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},\n      year={2024},\n      eprint={2408.05517},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2408.05517},\n}\n```\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=modelscope/swift&type=Date)](https://star-history.com/#modelscope/ms-swift&Date)\n"
        },
        {
          "name": "README_CN.md",
          "type": "blob",
          "size": 13.2275390625,
          "content": "# SWIFT (Scalable lightWeight Infrastructure for Fine-Tuning)\n\n<p align=\"center\">\n    <br>\n    <img src=\"asset/banner.png\"/>\n    <br>\n<p>\n<p align=\"center\">\n<a href=\"https://modelscope.cn/home\">é­”æ­ç¤¾åŒºå®˜ç½‘</a>\n<br>\n        ä¸­æ–‡&nbsp ï½œ &nbsp<a href=\"README.md\">English</a>&nbsp\n</p>\n\n\n<p align=\"center\">\n<img src=\"https://img.shields.io/badge/python-3.10-5be.svg\">\n<img src=\"https://img.shields.io/badge/pytorch-%E2%89%A52.0-orange.svg\">\n<a href=\"https://github.com/modelscope/modelscope/\"><img src=\"https://img.shields.io/badge/modelscope-%E2%89%A51.19-5D91D4.svg\"></a>\n<a href=\"https://pypi.org/project/ms-swift/\"><img src=\"https://badge.fury.io/py/ms-swift.svg\"></a>\n<a href=\"https://github.com/modelscope/swift/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/modelscope/swift\"></a>\n<a href=\"https://pepy.tech/project/ms-swift\"><img src=\"https://pepy.tech/badge/ms-swift\"></a>\n<a href=\"https://github.com/modelscope/swift/pulls\"><img src=\"https://img.shields.io/badge/PR-welcome-55EB99.svg\"></a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/6427\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/6427\" alt=\"modelscope%2Fswift | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n\n<p align=\"center\">\n        <a href=\"https://arxiv.org/abs/2408.05517\">è®ºæ–‡</a> &nbsp ï½œ <a href=\"https://swift.readthedocs.io/en/latest/\">English Documentation</a> &nbsp ï½œ &nbsp <a href=\"https://swift.readthedocs.io/zh-cn/latest/\">ä¸­æ–‡æ–‡æ¡£</a> &nbsp\n</p>\n<p align=\"center\">\n        <a href=\"https://swift2x-en.readthedocs.io/en/latest/\">Swift2.x En Doc</a> &nbsp ï½œ &nbsp <a href=\"https://swift2x.readthedocs.io/zh-cn/latest/\">Swift2.xä¸­æ–‡æ–‡æ¡£</a> &nbsp\n</p>\n\n\n##  ğŸ“– ç›®å½•\n- [ç”¨æˆ·ç¾¤](#-ç”¨æˆ·ç¾¤)\n- [ç®€ä»‹](#-ç®€ä»‹)\n- [æ–°é—»](#-æ–°é—»)\n- [å®‰è£…](#%EF%B8%8F-å®‰è£…)\n- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)\n- [å¦‚ä½•ä½¿ç”¨](#-å¦‚ä½•ä½¿ç”¨)\n- [License](#-license)\n- [å¼•ç”¨](#-å¼•ç”¨)\n\n## â˜ ç”¨æˆ·ç¾¤\n\nè¯·æ‰«æä¸‹é¢çš„äºŒç»´ç æ¥åŠ å…¥æˆ‘ä»¬çš„äº¤æµç¾¤ï¼š\n\n[Discord Group](https://discord.com/invite/D27yfEFVz5)              |  å¾®ä¿¡ç¾¤\n:-------------------------:|:-------------------------:\n<img src=\"asset/discord_qr.jpg\" width=\"200\" height=\"200\">  |  <img src=\"asset/wechat.png\" width=\"200\" height=\"200\">\n\n## ğŸ“ ç®€ä»‹\nğŸ² ms-swiftæ˜¯é­”æ­ç¤¾åŒºæä¾›çš„å¤§æ¨¡å‹ä¸å¤šæ¨¡æ€å¤§æ¨¡å‹å¾®è°ƒéƒ¨ç½²æ¡†æ¶ï¼Œç°å·²æ”¯æŒ450+å¤§æ¨¡å‹ä¸150+å¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒï¼ˆé¢„è®­ç»ƒã€å¾®è°ƒã€äººç±»å¯¹é½ï¼‰ã€æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–ä¸éƒ¨ç½²ã€‚å…¶ä¸­å¤§æ¨¡å‹åŒ…æ‹¬ï¼šQwen2.5ã€Llama3.3ã€GLM4ã€Internlm2.5ã€Yi1.5ã€Mistralã€DeepSeek2.5ã€Baichuan2ã€Gemma2ã€TeleChat2ç­‰æ¨¡å‹ï¼Œå¤šæ¨¡æ€å¤§æ¨¡å‹åŒ…æ‹¬ï¼šQwen2-VLã€Qwen2-Audioã€Llama3.2-Visionã€Llavaã€InternVL2.5ã€MiniCPM-V-2.6ã€GLM4vã€Xcomposer2.5ã€Yi-VLã€DeepSeek-VL2ã€Phi3.5-Visionã€GOT-OCR2ç­‰æ¨¡å‹ã€‚\n\nğŸ” é™¤æ­¤ä¹‹å¤–ï¼Œms-swiftæ±‡é›†äº†æœ€æ–°çš„è®­ç»ƒæŠ€æœ¯ï¼ŒåŒ…æ‹¬LoRAã€QLoRAã€Llama-Proã€LongLoRAã€GaLoreã€Q-GaLoreã€LoRA+ã€LISAã€DoRAã€FourierFtã€ReFTã€UnSlothã€å’ŒLigerç­‰ã€‚ms-swiftæ”¯æŒä½¿ç”¨vLLMå’ŒLMDeployå¯¹æ¨ç†ã€è¯„æµ‹å’Œéƒ¨ç½²æ¨¡å—è¿›è¡ŒåŠ é€Ÿï¼Œå¹¶æ”¯æŒä½¿ç”¨GPTQã€AWQã€BNBç­‰æŠ€æœ¯å¯¹å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹è¿›è¡Œé‡åŒ–ã€‚ä¸ºäº†å¸®åŠ©ç ”ç©¶è€…å’Œå¼€å‘è€…æ›´è½»æ¾åœ°å¾®è°ƒå’Œåº”ç”¨å¤§æ¨¡å‹ï¼Œms-swiftè¿˜æä¾›äº†åŸºäºGradioçš„Web-UIç•Œé¢åŠä¸°å¯Œçš„æœ€ä½³å®è·µã€‚\n\n**ä¸ºä»€ä¹ˆé€‰æ‹©ms-swiftï¼Ÿ**\n- ğŸ **æ¨¡å‹ç±»å‹**ï¼šæ”¯æŒ400+çº¯æ–‡æœ¬å¤§æ¨¡å‹ã€**150+å¤šæ¨¡æ€å¤§æ¨¡å‹**ï¼ŒAll-to-Allå…¨æ¨¡æ€æ¨¡å‹çš„**è®­ç»ƒåˆ°éƒ¨ç½²å…¨æµç¨‹**ã€‚\n- **æ•°æ®é›†ç±»å‹**ï¼šå†…ç½®150+é¢„è®­ç»ƒã€å¾®è°ƒã€äººç±»å¯¹é½ã€å¤šæ¨¡æ€ç­‰å„ç§ç±»å‹çš„æ•°æ®é›†ï¼Œå¹¶æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†ã€‚\n- **ç¡¬ä»¶æ”¯æŒ**ï¼šCPUã€RTXç³»åˆ—ã€T4/V100ã€A10/A100/H100ã€Ascend NPUç­‰ã€‚\n- ğŸŠ **è½»é‡è®­ç»ƒ**ï¼šæ”¯æŒäº†LoRAã€QLoRAã€DoRAã€LoRA+ã€ReFTã€RS-LoRAã€LLaMAProã€Adapterã€GaLoreã€Q-Galoreã€LISAã€UnSlothã€Liger-Kernelç­‰è½»é‡å¾®è°ƒæ–¹å¼ã€‚\n- **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šæ”¯æŒåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œï¼ˆDDPï¼‰ã€device_mapç®€æ˜“æ¨¡å‹å¹¶è¡Œã€DeepSpeed ZeRO2 ZeRO3ã€FSDPç­‰åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯ã€‚\n- **é‡åŒ–è®­ç»ƒ**ï¼šæ”¯æŒå¯¹BNBã€AWQã€GPTQã€AQLMã€HQQã€EETQé‡åŒ–æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚\n- **RLHFè®­ç»ƒ**ï¼šæ”¯æŒçº¯æ–‡æœ¬å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„DPOã€CPOã€SimPOã€ORPOã€KTOã€RMã€PPOç­‰äººç±»å¯¹é½è®­ç»ƒæ–¹æ³•ã€‚\n- ğŸ“ **å¤šæ¨¡æ€è®­ç»ƒ**ï¼šæ”¯æŒå¯¹å›¾åƒã€è§†é¢‘å’Œè¯­éŸ³ä¸åŒæ¨¡æ€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒVQAã€Captionã€OCRã€Groundingä»»åŠ¡çš„è®­ç»ƒã€‚\n- **ç•Œé¢è®­ç»ƒ**ï¼šä»¥ç•Œé¢çš„æ–¹å¼æä¾›è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–çš„èƒ½åŠ›ï¼Œå®Œæˆå¤§æ¨¡å‹çš„å…¨é“¾è·¯ã€‚\n- **æ’ä»¶åŒ–ä¸æ‹“å±•**ï¼šæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹å’Œæ•°æ®é›†æ‹“å±•ï¼Œæ”¯æŒå¯¹lossã€metricã€trainerã€loss-scaleã€callbackã€optimizerç­‰ç»„ä»¶è¿›è¡Œè‡ªå®šä¹‰ã€‚\n- ğŸ‰ **å·¥å…·ç®±èƒ½åŠ›**ï¼šä¸ä»…æä¾›å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹çš„è®­ç»ƒæ”¯æŒï¼Œè¿˜æ¶µç›–å…¶æ¨ç†ã€è¯„æµ‹ã€é‡åŒ–å’Œéƒ¨ç½²å…¨æµç¨‹ã€‚\n- **æ¨ç†åŠ é€Ÿ**ï¼šæ”¯æŒPyTorchã€vLLMã€LmDeployæ¨ç†åŠ é€Ÿå¼•æ“ï¼Œå¹¶æä¾›OpenAIæ¥å£ï¼Œä¸ºæ¨ç†ã€éƒ¨ç½²å’Œè¯„æµ‹æ¨¡å—æä¾›åŠ é€Ÿã€‚\n- **æ¨¡å‹è¯„æµ‹**ï¼šä»¥EvalScopeä½œä¸ºè¯„æµ‹åç«¯ï¼Œæ”¯æŒ100+è¯„æµ‹æ•°æ®é›†å¯¹çº¯æ–‡æœ¬å’Œå¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œè¯„æµ‹ã€‚\n- **æ¨¡å‹é‡åŒ–**ï¼šæ”¯æŒAWQã€GPTQå’ŒBNBçš„é‡åŒ–å¯¼å‡ºï¼Œå¯¼å‡ºçš„æ¨¡å‹æ”¯æŒä½¿ç”¨vLLM/LmDeployæ¨ç†åŠ é€Ÿï¼Œå¹¶æ”¯æŒç»§ç»­è®­ç»ƒã€‚\n\n## ğŸ‰ æ–°é—»\n- ğŸ 2024.12.04: **SWIFT3.0**å¤§ç‰ˆæœ¬æ›´æ–°. è¯·æŸ¥çœ‹[å‘å¸ƒè¯´æ˜å’Œæ›´æ”¹](https://swift.readthedocs.io/zh-cn/latest/Instruction/ReleaseNote3.0.html)ã€‚\n- ğŸ‰ 2024.08.12: SWIFTè®ºæ–‡å·²ç»å‘å¸ƒåˆ°arXivä¸Šï¼Œå¯ä»¥ç‚¹å‡»[è¿™é‡Œ](https://arxiv.org/abs/2408.05517)é˜…è¯»ã€‚\n- ğŸ”¥ 2024.08.05: æ”¯æŒä½¿ç”¨[evalscope](https://github.com/modelscope/evalscope/)ä½œä¸ºåç«¯è¿›è¡Œå¤§æ¨¡å‹å’Œå¤šæ¨¡æ€æ¨¡å‹çš„è¯„æµ‹ã€‚\n- ğŸ”¥ 2024.07.29: æ”¯æŒä½¿ç”¨[vllm](https://github.com/vllm-project/vllm), [lmdeploy](https://github.com/InternLM/lmdeploy)å¯¹å¤§æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹è¿›è¡Œæ¨ç†åŠ é€Ÿï¼Œåœ¨infer/deploy/evalæ—¶é¢å¤–æŒ‡å®š`--infer_backend vllm/lmdeploy`å³å¯ã€‚\n- ğŸ”¥ 2024.07.24: æ”¯æŒå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹è¿›è¡Œäººç±»åå¥½å¯¹é½è®­ç»ƒï¼ŒåŒ…æ‹¬DPO/ORPO/SimPO/CPO/KTO/RM/PPOã€‚\n- ğŸ”¥ 2024.02.01: æ”¯æŒAgentè®­ç»ƒï¼è®­ç»ƒç®—æ³•æºè‡ªè¿™ç¯‡[è®ºæ–‡](https://arxiv.org/pdf/2309.00986.pdf)ã€‚\n\n## ğŸ› ï¸ å®‰è£…\nä½¿ç”¨pipè¿›è¡Œå®‰è£…ï¼š\n```shell\npip install ms-swift -U\n```\n\nä»æºä»£ç å®‰è£…ï¼š\n```shell\n# pip install git+https://github.com/modelscope/ms-swift.git\n\ngit clone https://github.com/modelscope/ms-swift.git\ncd ms-swift\npip install -e .\n```\n\n## ğŸš€ å¿«é€Ÿå¼€å§‹\n\n**10åˆ†é’Ÿ**åœ¨å•å¡3090ä¸Šå¯¹Qwen2.5-7B-Instructè¿›è¡Œè‡ªæˆ‘è®¤çŸ¥å¾®è°ƒï¼š\n\n### å‘½ä»¤è¡Œ\n```shell\n# 22GB\nCUDA_VISIBLE_DEVICES=0 \\\nswift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --train_type lora \\\n    --dataset 'AI-ModelScope/alpaca-gpt4-data-zh#500' \\\n              'AI-ModelScope/alpaca-gpt4-data-en#500' \\\n              'swift/self-cognition#500' \\\n    --torch_dtype bfloat16 \\\n    --num_train_epochs 1 \\\n    --per_device_train_batch_size 1 \\\n    --per_device_eval_batch_size 1 \\\n    --learning_rate 1e-4 \\\n    --lora_rank 8 \\\n    --lora_alpha 32 \\\n    --target_modules all-linear \\\n    --gradient_accumulation_steps 16 \\\n    --eval_steps 50 \\\n    --save_steps 50 \\\n    --save_total_limit 5 \\\n    --logging_steps 5 \\\n    --max_length 2048 \\\n    --output_dir output \\\n    --system 'You are a helpful assistant.' \\\n    --warmup_ratio 0.05 \\\n    --dataloader_num_workers 4 \\\n    --model_author swift \\\n    --model_name swift-robot\n```\n\nè®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯¹è®­ç»ƒåçš„æƒé‡è¿›è¡Œæ¨ç†ï¼Œè¿™é‡Œçš„`--adapters`æ›¿æ¢æˆè®­ç»ƒç”Ÿæˆçš„last checkpointæ–‡ä»¶å¤¹. ç”±äºadaptersæ–‡ä»¶å¤¹ä¸­åŒ…å«äº†è®­ç»ƒçš„å‚æ•°æ–‡ä»¶ï¼Œå› æ­¤ä¸éœ€è¦é¢å¤–æŒ‡å®š`--model`, `--system`.\n\n```shell\n# ä½¿ç”¨äº¤äº’å¼å‘½ä»¤è¡Œè¿›è¡Œæ¨ç†\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n\n# merge-loraå¹¶ä½¿ç”¨vLLMè¿›è¡Œæ¨ç†åŠ é€Ÿ\nCUDA_VISIBLE_DEVICES=0 \\\nswift infer \\\n    --adapters output/vx-xxx/checkpoint-xxx \\\n    --stream true \\\n    --merge_lora true \\\n    --infer_backend vllm \\\n    --max_model_len 8192 \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### Web-UI\n\nWeb-UIæ˜¯åŸºäºgradioç•Œé¢æŠ€æœ¯çš„**é›¶é—¨æ§›**è®­ç»ƒã€éƒ¨ç½²ç•Œé¢æ–¹æ¡ˆï¼Œå…·ä½“å¯ä»¥æŸ¥çœ‹[è¿™é‡Œ](https://swift.readthedocs.io/zh-cn/latest/GetStarted/Web-UI.html)ã€‚\n\n```shell\nswift web-ui\n```\n![image.png](./docs/resources/web-ui.png)\n\n### ä½¿ç”¨Python\nms-swiftä¹Ÿæ”¯æŒä½¿ç”¨pythonçš„æ–¹å¼è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚ä¸‹é¢ç»™å‡ºè®­ç»ƒå’Œæ¨ç†çš„**ä¼ªä»£ç **ï¼Œå…·ä½“å¯ä»¥æŸ¥çœ‹[è¿™é‡Œ](https://github.com/modelscope/ms-swift/tree/main/examples/notebook)ã€‚\n\nè®­ç»ƒï¼š\n```python\n# è·å–æ¨¡å‹å’Œtemplateï¼Œå¹¶åŠ å…¥å¯è®­ç»ƒçš„LoRAæ¨¡å—\nmodel, tokenizer = get_model_tokenizer(model_id_or_path, ...)\ntemplate = get_template(model.model_meta.template, tokenizer, ...)\nmodel = Swift.prepare_model(model, lora_config)\n\n# ä¸‹è½½å¹¶è½½å…¥æ•°æ®é›†ï¼Œå¹¶å°†æ–‡æœ¬encodeæˆtokens\ntrain_dataset, val_dataset = load_dataset(dataset_id_or_path, ...)\ntrain_dataset = EncodePreprocessor(template=template)(train_dataset, num_proc=num_proc)\nval_dataset = EncodePreprocessor(template=template)(val_dataset, num_proc=num_proc)\n\n# è¿›è¡Œè®­ç»ƒ\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=template.data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    template=template,\n)\ntrainer.train()\n```\n\næ¨ç†ï¼š\n```python\n# ä½¿ç”¨åŸç”Ÿpytorchå¼•æ“è¿›è¡Œæ¨ç†\nengine = PtEngine(model_id_or_path, adapters=[lora_checkpoint])\ninfer_request = InferRequest(messages=[{'role': 'user', 'content': 'who are you?'}])\nrequest_config = RequestConfig(max_tokens=max_new_tokens, temperature=temperature)\n\nresp_list = engine.infer([infer_request], request_config)\nprint(f'response: {resp_list[0].choices[0].message.content}')\n```\n\n## âœ¨ å¦‚ä½•ä½¿ç”¨\n\nè¿™é‡Œç»™å‡ºä½¿ç”¨ms-swiftè¿›è¡Œè®­ç»ƒåˆ°éƒ¨ç½²åˆ°æœ€ç®€ç¤ºä¾‹ï¼Œå…·ä½“å¯ä»¥æŸ¥çœ‹[examples](https://github.com/modelscope/ms-swift/tree/main/examples).\n\n|   å¸¸ç”¨é“¾æ¥ |\n| ------ |\n|   [å‘½ä»¤è¡Œå‚æ•°](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0.html)   |\n|   [æ”¯æŒçš„æ¨¡å‹å’Œæ•°æ®é›†](https://swift.readthedocs.io/zh-cn/latest/Instruction/%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86.html)   |\n|   [è‡ªå®šä¹‰æ¨¡å‹](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B.html), [è‡ªå®šä¹‰æ•°æ®é›†](https://swift.readthedocs.io/zh-cn/latest/Customization/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86.html)   |\n|   [å¤§æ¨¡å‹æ•™ç¨‹](https://github.com/modelscope/modelscope-classroom/tree/main/LLM-tutorial)   |\n\n### è®­ç»ƒ\n\né¢„è®­ç»ƒï¼š\n```shell\n# 8*A100\nNPROC_PER_NODE=8 \\\nCUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \\\nswift pt \\\n    --model Qwen/Qwen2.5-7B \\\n    --dataset swift/chinese-c4 \\\n    --streaming true \\\n    --train_type full \\\n    --deepspeed zero2 \\\n    --output_dir output \\\n    --max_steps 100000 \\\n    ...\n```\n\nå¾®è°ƒï¼š\n```shell\nCUDA_VISIBLE_DEVICES=0 swift sft \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\nRLHFï¼š\n```shell\nCUDA_VISIBLE_DEVICES=0 swift rlhf \\\n    --rlhf_type dpo \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --dataset hjh0119/shareAI-Llama3-DPO-zh-en-emoji \\\n    --train_type lora \\\n    --output_dir output \\\n    ...\n```\n\n\n### æ¨ç†\n```shell\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048\n\n# LoRA\nCUDA_VISIBLE_DEVICES=0 swift infer \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --adapters swift/test_lora \\\n    --stream true \\\n    --infer_backend pt \\\n    --temperature 0 \\\n    --max_new_tokens 2048\n```\n\n### ç•Œé¢æ¨ç†\n```shell\nCUDA_VISIBLE_DEVICES=0 swift app \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --stream true \\\n    --infer_backend pt \\\n    --max_new_tokens 2048 \\\n    --lang zh\n```\n\n### éƒ¨ç½²\n```shell\nCUDA_VISIBLE_DEVICES=0 swift deploy \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend vllm\n```\n\n### è¯„æµ‹\n```shell\nCUDA_VISIBLE_DEVICES=0 swift eval \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --infer_backend lmdeploy \\\n    --eval_dataset ARC_c\n```\n\n### é‡åŒ–\n```shell\nCUDA_VISIBLE_DEVICES=0 swift export \\\n    --model Qwen/Qwen2.5-7B-Instruct \\\n    --quant_bits 4 --quant_method awq \\\n    --dataset AI-ModelScope/alpaca-gpt4-data-zh \\\n    --output_dir Qwen2.5-7B-Instruct-AWQ\n```\n\n\n## ğŸ› License\n\næœ¬æ¡†æ¶ä½¿ç”¨[Apache License (Version 2.0)](https://github.com/modelscope/modelscope/blob/master/LICENSE)è¿›è¡Œè®¸å¯ã€‚æ¨¡å‹å’Œæ•°æ®é›†è¯·æŸ¥çœ‹åŸèµ„æºé¡µé¢å¹¶éµå®ˆå¯¹åº”Licenseã€‚\n\n## ğŸ“ å¼•ç”¨\n\n```bibtex\n@misc{zhao2024swiftascalablelightweightinfrastructure,\n      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},\n      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},\n      year={2024},\n      eprint={2408.05517},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2408.05517},\n}\n```\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=modelscope/swift&type=Date)](https://star-history.com/#modelscope/ms-swift&Date)\n"
        },
        {
          "name": "asset",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.029296875,
          "content": "-r requirements/framework.txt\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.736328125,
          "content": "[isort]\nline_length = 120\nmulti_line_output = 0\nknown_standard_library = setuptools\nknown_first_party = swift\nknown_third_party = json,yaml\nno_lines_before = STDLIB,LOCALFOLDER\ndefault_section = THIRDPARTY\n\n[yapf]\nBASED_ON_STYLE = pep8\nCOLUMN_LIMIT = 120\nBLANK_LINE_BEFORE_NESTED_CLASS_OR_DEF = true\nSPLIT_BEFORE_EXPRESSION_AFTER_OPENING_PAREN = true\nSPLIT_BEFORE_ARITHMETIC_OPERATOR = true\n\n[codespell]\nskip = *.ipynb\nquiet-level = 3\nignore-words-list = patten,nd,ty,mot,hist,formating,winn,gool,datas,wan,confids\n\n[flake8]\nmax-line-length = 120\nselect = B,C,E,F,P,T4,W,B9\nignore = F401,F403,F405,F821,W503,E251,W504,E126\nexclude = docs/src,*.pyi,.git,peft.py\n\n[darglint]\nignore=DAR101\n\n[easy_install]\nindex-url=https://pypi.tuna.tsinghua.edu.cn/simple\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.0048828125,
          "content": "# Copyright (c) Alibaba, Inc. and its affiliates.\n# !/usr/bin/env python\nimport os\nfrom setuptools import find_packages, setup\nfrom typing import List\n\n\ndef readme():\n    with open('README.md', encoding='utf-8') as f:\n        content = f.read()\n    return content\n\n\nversion_file = 'swift/version.py'\n\n\ndef get_version():\n    with open(version_file, 'r', encoding='utf-8') as f:\n        exec(compile(f.read(), version_file, 'exec'))\n    return locals()['__version__']\n\n\ndef parse_requirements(fname='requirements.txt', with_version=True):\n    \"\"\"\n    Parse the package dependencies listed in a requirements file but strips\n    specific versioning information.\n\n    Args:\n        fname (str): path to requirements file\n        with_version (bool, default=False): if True include version specs\n\n    Returns:\n        List[str]: list of requirements items\n\n    CommandLine:\n        python -c \"import setup; print(setup.parse_requirements())\"\n    \"\"\"\n    import re\n    import sys\n    from os.path import exists\n    require_fpath = fname\n\n    def parse_line(line):\n        \"\"\"\n        Parse information from a line in a requirements text file\n        \"\"\"\n        if line.startswith('-r '):\n            # Allow specifying requirements in other files\n            target = line.split(' ')[1]\n            relative_base = os.path.dirname(fname)\n            absolute_target = os.path.join(relative_base, target)\n            for info in parse_require_file(absolute_target):\n                yield info\n        else:\n            info = {'line': line}\n            if line.startswith('-e '):\n                info['package'] = line.split('#egg=')[1]\n            else:\n                # Remove versioning from the package\n                pat = '(' + '|'.join(['>=', '==', '>']) + ')'\n                parts = re.split(pat, line, maxsplit=1)\n                parts = [p.strip() for p in parts]\n\n                info['package'] = parts[0]\n                if len(parts) > 1:\n                    op, rest = parts[1:]\n                    if ';' in rest:\n                        # Handle platform specific dependencies\n                        # http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies\n                        version, platform_deps = map(str.strip, rest.split(';'))\n                        info['platform_deps'] = platform_deps\n                    else:\n                        version = rest  # NOQA\n                    info['version'] = (op, version)\n            yield info\n\n    def parse_require_file(fpath):\n        with open(fpath, 'r', encoding='utf-8') as f:\n            for line in f.readlines():\n                line = line.strip()\n                if line.startswith('http'):\n                    print('skip http requirements %s' % line)\n                    continue\n                if line and not line.startswith('#') and not line.startswith('--'):\n                    for info in parse_line(line):\n                        yield info\n                elif line and line.startswith('--find-links'):\n                    eles = line.split()\n                    for e in eles:\n                        e = e.strip()\n                        if 'http' in e:\n                            info = dict(dependency_links=e)\n                            yield info\n\n    def gen_packages_items():\n        items = []\n        deps_link = []\n        if exists(require_fpath):\n            for info in parse_require_file(require_fpath):\n                if 'dependency_links' not in info:\n                    parts = [info['package']]\n                    if with_version and 'version' in info:\n                        parts.extend(info['version'])\n                    if not sys.version.startswith('3.4'):\n                        # apparently package_deps are broken in 3.4\n                        platform_deps = info.get('platform_deps')\n                        if platform_deps is not None:\n                            parts.append(';' + platform_deps)\n                    item = ''.join(parts)\n                    items.append(item)\n                else:\n                    deps_link.append(info['dependency_links'])\n        return items, deps_link\n\n    return gen_packages_items()\n\n\nif __name__ == '__main__':\n    install_requires, deps_link = parse_requirements('requirements.txt')\n    extra_requires = {}\n    all_requires = []\n    extra_requires['eval'], _ = parse_requirements('requirements/eval.txt')\n    extra_requires['seq_parallel'], _ = parse_requirements('requirements/seq_parallel.txt')\n    all_requires.extend(install_requires)\n    all_requires.extend(extra_requires['eval'])\n    all_requires.extend(extra_requires['seq_parallel'])\n    extra_requires['all'] = all_requires\n\n    setup(\n        name='ms-swift',\n        version=get_version(),\n        description='Swift: Scalable lightWeight Infrastructure for Fine-Tuning',\n        long_description=readme(),\n        long_description_content_type='text/markdown',\n        author='DAMO ModelScope teams',\n        author_email='contact@modelscope.cn',\n        keywords='python, petl, efficient tuners',\n        url='https://github.com/modelscope/swift',\n        packages=find_packages(exclude=('configs', 'demo')),\n        include_package_data=True,\n        package_data={\n            '': ['*.h', '*.cpp', '*.cu'],\n        },\n        classifiers=[\n            'Development Status :: 4 - Beta',\n            'License :: OSI Approved :: Apache Software License',\n            'Operating System :: OS Independent',\n            'Programming Language :: Python :: 3',\n            'Programming Language :: Python :: 3.8',\n            'Programming Language :: Python :: 3.9',\n            'Programming Language :: Python :: 3.10',\n            'Programming Language :: Python :: 3.11',\n            'Programming Language :: Python :: 3.12',\n        ],\n        license='Apache License 2.0',\n        tests_require=parse_requirements('requirements/tests.txt'),\n        install_requires=install_requires,\n        extras_require=extra_requires,\n        entry_points={'console_scripts': ['swift=swift.cli.main:cli_main']},\n        dependency_links=deps_link,\n        zip_safe=False)\n"
        },
        {
          "name": "swift",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}