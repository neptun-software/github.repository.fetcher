{
  "metadata": {
    "timestamp": 1736559710133,
    "page": 398,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "IDEA-CCNL/Fengshenbang-LM",
      "stars": 4068,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.869140625,
          "content": "# Byte-compiled / optimized / DLL files\n*torch_extendsions/\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Log\n*.log\n*.err\n*logs/\n*ds_config.json\n\n# ckpt\n*ckpt/\n*.bin\n*.ckpt\n\n# test files\n*predict.py"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.1201171875,
          "content": "[submodule \"fengshen/data/fs_datasets\"]\n\tpath = fengshen/data/fs_datasets\n\turl = git@github.com:IDEA-CCNL/fs_datasets.git \n"
        },
        {
          "name": ".pep8speaks.yml",
          "type": "blob",
          "size": 1.8388671875,
          "content": "# File : .pep8speaks.yml\n\nscanner:\n    diff_only: True  # If False, the entire file touched by the Pull Request is scanned for errors. If True, only the diff is scanned.\n    linter: flake8  # Other option is flake8\n\npycodestyle:  # Same as scanner.linter value. Other option is flake8\n    max-line-length: 150  # Default is 79 in PEP 8\n    ignore:  # Errors and warnings to ignore\n        - W504  # line break after binary operator\n        - E402  # module level import not at top of file\n        - E731  # do not assign a lambda expression, use a def\n        - C406  # Unnecessary list literal - rewrite as a dict literal.\n        - E741  # ambiguous variable name\n        \nflake8:  # Valid if scanner.linter is flake8\n    max-line-length: 150\n    ignore: [E203,E266,E501,W503,F403,F401,E402,F841,E741,F821,E226,W504,E731,C406]\n    exclude: []\n    count: False\n    show-source: False\n    statistics: False\n    hang-closing: False\n    filename: []\n    select: [] \n\nno_blank_comment: True  # If True, no comment is made on PR without any errors.\ndescending_issues_order: False  # If True, PEP 8 issues in message will be displayed in descending order of line numbers in the file\n\nmessage:  # Customize the comment made by the bot\n    opened:  # Messages when a new PR is submitted\n        header: \"Hello @{name}! Thanks for opening this PR. \"\n                # The keyword {name} is converted into the author's username\n        footer: \"Do see the [Hitchhiker's guide to code style](https://goo.gl/hqbW4r)\"\n                # The messages can be written as they would over GitHub\n    updated:  # Messages when new commits are added to the PR\n        header: \"Hello @{name}! Thanks for updating this PR. \"\n        footer: \"\"  # Why to comment the link to the style guide everytime? :)\n    no_errors: \"There are currently no PEP 8 issues detected in this Pull Request. Cheers! :beers: \"\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.4765625,
          "content": "default_stages: [commit]\nrepos:\n  - repo: https://github.com/yingzi113/pre-commit-hooks\n    rev: 5863e162f1bed1f63eeb716e77d622ff8e3d9af9\n    hooks:\n    - id: check-case-conflict\n  - repo: https://github.com/pre-commit/mirrors-autopep8\n    rev: v1.4.4\n    hooks:\n    - id: autopep8\n      args: [-i, --global-config=.flake8, -v, --max-line-length=300]\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.4.0\n    hooks:\n    - id: flake8\n      args: [--max-line-length=300]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.1474609375,
          "content": "Copyright 2021 The IDEA-CCNL Authors. All rights reserved.\n                                Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 20.6337890625,
          "content": "[**中文**](./README.md) | [**English**](./README_en.md)\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n</p>\n\n\n<h4 align=\"center\">\n  <a href=#安装> 环境安装 </a> |\n  <a href=https://huggingface.co/IDEA-CCNL> 模型下载 </a> |\n  <a href=https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples> 代码示例 </a> |\n  <a href=https://fengshenbang-doc.readthedocs.io/zh/latest> 模型文档 </a> |\n  <a href=https://fengshenbang-lm.com> 封神榜官网 </a> |\n  <a href=https://fengshenbang-lm.com/open-api> 封神API </a>\n</h4>\n\n------------------------------------------------------------------------------------------\n\n# 封神榜科技成果\n> [**Fengshenbang 1.0**](https://arxiv.org/abs/2209.02970): 封神榜开源计划1.0中英双语总论文，旨在成为中文认知智能的基础设施。\n \n> [**BioBART**](https://arxiv.org/abs/2204.03905): 由清华大学和IDEA研究院一起提供的生物医疗领域的生成语言模型。(```BioNLP 2022```)\n\n> [**UniMC**](https://arxiv.org/abs/2210.08590): 针对zero-shot场景下基于标签数据集的统一模型。(```EMNLP 2022```)\n\n> [**FMIT**](https://arxiv.org/abs/2208.11039): 基于相对位置编码的单塔多模态命名实体识别模型。(```COLING 2022```)\n\n> [**UniEX**](https://arxiv.org/abs/2305.10306): 统一抽取任务的自然语言理解模型。(```ACL 2023```)\n\n> [**Solving Math Word Problems via Cooperative Reasoning induced Language Models**](https://2023.aclweb.org/program/accepted_main_conference/): 使用语言模型的协同推理框架解决数学问题。(```ACL 2023```)\n\n> [**MVP-Tuning**](https://2023.aclweb.org/program/accepted_main_conference/): 基于多视角知识检索的参数高效常识问答系统。(```ACL 2023```)\n\n\n# 封神榜大事件\n\n- [多模态Ziya上线！姜子牙通用模型垂直能力系列 Vol.1发布](https://mp.weixin.qq.com/s/-gv9tG5-Vqo2iN_ETO84KQ) 2023.06.05\n- [IDEA研究院封神榜团队再次出击， 推出开源通用大模型系列“姜子牙”](https://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA) 2023.05.17\n- [首个中文Stable Diffusion模型开源，IDEA研究院封神榜团队开启中文AI艺术时代](https://mp.weixin.qq.com/s/WrzkiJOxqNcFpdU24BKbMA) 2022.11.2\n- [打破不可能三角、比肩5400亿模型，IDEA封神榜团队仅2亿级模型达到零样本学习SOTA](https://mp.weixin.qq.com/s/m0_W31mP4xKKla8jIwUXkw) 2022.10.25\n- [AIWIN大赛冠军，封神榜提出多任务学习方案Ubert](https://mp.weixin.qq.com/s/A9G0YLbIPShKgm98DnD2jA) 2022.07.21\n- [Finetune一下，“封神榜”预训练语言模型“二郎神”获SimCLUE榜一](https://mp.weixin.qq.com/s/KXQtCgxZlCnv0HqSyQAteQ) 2022.07.14\n- [封神框架正式开源，帮你轻松预训练和微调“封神榜”各大模型](https://mp.weixin.qq.com/s/NtaEVMdTxzTJfVr-uQ419Q) 2022.06.30\n- [GTS模型生产平台开放公测，用AI自动化生产AI模型](https://mp.weixin.qq.com/s/AFp22hzElkBmJD_VHW0njQ) 2022.05.23\n- [数据集发布！IDEA研究院CCNL×NLPCC 2022 任务挑战赛开始了，优胜队伍将获IDEA实习机会](https://mp.weixin.qq.com/s/AikMy6ygfnRagOw3iWuArA) 2022.04.07\n- [又刷新了！IDEA CCNL预训练语言模型“二郎神”，这次拿下了ZeroCLUE](https://mp.weixin.qq.com/s/Ukp0JOUwAZJiegdX_4ox2Q) 2022.01.24\n- [IDEA Friends | CCNL Team“封神榜”，他们为什么选择IDEA？](https://mp.weixin.qq.com/s/eCmMtopG9DGvZ0qWM3C6Sg) 2022.01.12\n- [IDEA大会发布｜“封神榜”大模型开源计划](https://mp.weixin.qq.com/s/Ct06-vLEKoYMyJQPBV2n0w) 2021.11.25\n- [IDEA研究院中文预训练模型二郎神登顶FewCLUE榜单](https://mp.weixin.qq.com/s/bA_9n_TlBE9P-UzCn7mKoA) 2021.11.11\n\n# 导航\n- [封神榜科技成果](#封神榜科技成果)\n- [封神榜大事件](#封神榜大事件)\n- [导航](#导航)\n- [模型系列简介](#模型系列简介)\n- [Fengshenbang-LM](#fengshenbang-lm)\n- [封神榜模型](#封神榜模型)\n  - [姜子牙系列](#姜子牙系列)\n  - [二郎神系列](#二郎神系列)\n  - [太乙系列](#太乙系列)\n- [封神框架](#封神框架)\n  - [安装](#安装)\n  - [Pipelines](#pipelines)\n- [封神榜系列文章](#封神榜系列文章)\n- [引用](#引用)\n- [联系我们](#联系我们)\n- [版权许可](#版权许可)\n\n# 模型系列简介\n\n|系列名称|需求|适用任务|参数规模|备注|\n|:---:|:---:|:---:|:---:|---|\n|[姜子牙](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)|通用|通用大模型|>70亿参数|通用大模型“姜子牙”系列，具备翻译，编程，文本分类，信息抽取，摘要，文案生成，常识问答和数学计算等能力|\n|[太乙](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E5%A4%AA%E4%B9%99%E7%B3%BB%E5%88%97/index.html)|特定|多模态|8千万-10亿参数|应用于跨模态场景，包括文本图像生成，蛋白质结构预测, 语音-文本表示等|\n|[二郎神](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E4%BA%8C%E9%83%8E%E7%A5%9E%E7%B3%BB%E5%88%97/index.html)|通用|语言理解|9千万-39亿参数|处理理解任务，拥有开源时最大的中文bert模型，2021登顶FewCLUE和ZeroCLUE|\n|[闻仲](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E9%97%BB%E4%BB%B2%E7%B3%BB%E5%88%97/index.html)|通用|语言生成|1亿-35亿参数|专注于生成任务，提供了多个不同参数量的生成模型，例如GPT2等|\n|[燃灯](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E7%87%83%E7%81%AF%E7%B3%BB%E5%88%97/index.html)|通用|语言转换|7千万-50亿参数|处理各种从源文本转换到目标文本类型的任务，例如机器翻译，文本摘要等|  \n|[余元](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E4%BD%99%E5%85%83%E7%B3%BB%E5%88%97/index.html)|特定|领域|1亿-35亿参数|应用于领域，如医疗，金融，法律，编程等。拥有目前最大的开源GPT2医疗模型|\n|-待定-|特定|探索|-未知-|我们希望与各技术公司和大学一起开发NLP相关的实验模型。目前已有：[周文王](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E5%91%A8%E6%96%87%E7%8E%8B%E7%B3%BB%E5%88%97/index.html)|\n\n[封神榜模型下载链接](https://huggingface.co/IDEA-CCNL)\n\n[封神榜模型训练和微调代码脚本](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples)\n\n[封神榜模型训练手册](https://fengshenbang-doc.readthedocs.io/zh/latest/index.html)\n\n# Fengshenbang-LM\n\n人工智能的显著进步产生了许多伟大的模型，特别是基于预训练的基础模型成为了一种新兴的范式。传统的AI模型必须要在专门的巨大的数据集上为一个或几个有限的场景进行训练，相比之下，基础模型可以适应广泛的下游任务。基础模型造就了AI在低资源的场景下落地的可能。  \n我们观察到这些模型的参数量正在以每年10倍的速度增长。2018年的BERT，在参数量仅有1亿量级，但是到了2020年，GPT-3的参数量就已达到百亿的量级。由于这一鼓舞人心的趋势，人工智能中的许多前沿挑战，尤其是强大的泛化能力，逐渐变得可以被实现。\n\n如今的基础模型，尤其是语言模型，正在被英文社区主导着。与此同时，中文作为这个世界上最大的口语语种（母语者中），却缺乏系统性的研究资源支撑，这使得中文领域的研究进展相较于英文来说有些滞后。\n\n这个世界需要一个答案。\n\n为了解决中文领域研究进展滞后和研究资源严重不足的问题，2021年11月22日，IDEA研究院创院理事长沈向洋在IDEA大会上正式宣布，开启 “封神榜”开源体系——一个以中文驱动的基础生态系统，其中包括了预训练大模型，特定任务的微调应用，基准和数据集等。我们的目标是构建一个全面的，标准化的，以用户为中心的生态系统。\n![avatar](pics/start_opensource.png)\n\n# 封神榜模型\n\n“封神榜模型”将全方面的开源一系列NLP相关的预训练大模型。NLP社区中有着广泛的研究任务，这些任务可以被分为两类：通用任务和特殊任务。前者包括了自然语言理解(NLU)，自然语言生成(NLG)和自然语言转换(NLT)任务。后者涵盖了多模态，特定领域等任务。我们考虑了所有的这些任务，并且提供了在下游任务上微调好的相关模型，这使得计算资源有限的用户也可以轻松使用我们的基础模型。而且我们承诺，将对这些模型做持续的升级，不断融合最新的数据和最新的训练算法。通过IDEA研究院的努力，打造中文认知智能的通用基础设施，避免重复建设，为全社会节省算力。\n\n![avatar](pics/all_models.png)\n\n同时，“封神榜”也希望各个公司、高校、机构加入到这个开源计划中，一起共建大模型开源体系。未来，当我们需要一个新的预训练模型，都应该是首先从这些开源大模型中选取一个最接近的，做继续训练，然后再把新的模型开源回这个体系。这样，每个人用最少的算力，就能得到自己的模型，同时这个开源大模型体系也能越来越大。\n\n![avatar](pics/model_pic2.png)\n\n为了更好的体验，拥抱开源社区，封神榜的所有模型都转化并同步到了Huggingface社区，你可以通过几行代码就能轻松使用封神榜的所有模型，欢迎来[IDEA-CCNL的huggingface社区](https://huggingface.co/IDEA-CCNL)下载。\n\n## 姜子牙系列\n\n通用大模型“姜子牙”系列，具备翻译，编程，文本分类，信息抽取，摘要，文案生成，常识问答和数学计算等能力。目前姜子牙通用大模型(v1/v1.1)已完成大规模预训练、多任务有监督微调和人类反馈学习三阶段的训练过程。姜子牙系列模型包含以下模型：\n- [Ziya-LLaMA-13B-v1.1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)\n- [Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)\n- [Ziya-LLaMA-7B-Reward](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-7B-Reward)\n- [Ziya-LLaMA-13B-Pretrain-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1)\n- [Ziya-BLIP2-14B-Visual-v1](https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1)\n\n### 模型使用\n\n参考 [Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)\n\n### 线上体验\n\n- [Huggingface Ziya Space](https://huggingface.co/spaces/IDEA-CCNL/Ziya-v1)\n- [Huggingface Ziya-visual Space](https://huggingface.co/spaces/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1-Demo)\n- [ModelScope Ziya Space](https://modelscope.cn/studios/Fengshenbang/Ziya_LLaMA_13B_v1_online/summary)\n\n\n### 微调示例\n\n参考 [ziya_finetune](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/ziya_llama)\n\n### 推理量化示例\n\n参考 [ziya_inference](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/ziya_inference)\n\n\n\n## 二郎神系列\n\nEncoder结构为主的双向语言模型，专注于解决各种自然语言理解任务。\n13亿参数的二郎神-1.3B大模型，采用280G数据，32张A100训练14天，是最大的开源中文Bert大模型。2021年11月10日在中文语言理解权威评测基准FewCLUE 榜单上登顶。其中，CHID(成语填空)、TNEWS(新闻分类)超过人类，CHID(成语填空)、CSLDCP(学科文献分类)、OCNLI(自然语言推理)单任务第一，刷新小样本学习记录。二郎神系列会持续在模型规模、知识融入、监督任务辅助等方向不断优化。\n\n![image](https://user-images.githubusercontent.com/4384420/141752311-d15c2a7f-cd83-4e9e-99a5-cb931088845e.png)\n\n2022年1月24日，二郎神-MRC在中文语言理解评测零样本ZeroCLUE榜单上登顶。其中，CSLDCP(学科文献分类)、TNEWS(新闻分类)，IFLYTEK(应用描述分类)、CSL(摘要关键字识别)、CLUEWSC(指代消解)单任务均为第一。\n![image](https://user-images.githubusercontent.com/4384420/151319156-e20ba252-b531-4779-8099-ef60c7954f76.png)\n\n### 模型下载地址\n\n[Huggingface 二郎神-1.3B](https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B)\n\n### 模型加载\n\n``` python\nfrom transformers import MegatronBertConfig, MegatronBertModel\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\nconfig = MegatronBertConfig.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\nmodel = MegatronBertModel.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\n```\n\n### 使用示例\n\n为了便于开发者快速使用我们的开源模型，这里提供了一个下游任务的[finetune示例脚本](https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/classification/finetune_classification.sh)，使用的[CLUE](https://github.com/CLUEbenchmark/CLUE)上的tnews新闻分类任务数据，运行脚本如下。其中DATA_PATH为数据路径，tnews任务数据的[下载地址](https://github.com/CLUEbenchmark/CLUE).\n\n1、首先修改finetune示例脚本[finetune_classification.sh](https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/classification/finetune_classification.sh)中的model_type和pretrained_model_path参数。其他如batch_size、data_dir等参数可根据自己的设备修改。\n\n``` sh\nMODEL_TYPE=huggingface-megatron_bert\nPRETRAINED_MODEL_PATH=IDEA-CCNL/Erlangshen-MegatronBert-1.3B\n```\n\n2、然后运行：\n\n``` sh\nsh finetune_classification.sh\n```\n\n### 下游效果\n\n|     模型   | afqmc    |  tnews  | iflytek    |  ocnli  |  cmnli  | wsc  | csl  |\n| :--------:    | :-----:  | :----:  | :-----:   | :----: | :----: | :----: | :----: |\n| roberta-wwm-ext-large | 0.7514      |   0.5872    | 0.6152      |   0.777    | 0.814    | 0.8914    | 0.86    |\n| Erlangshen-MegatronBert-1.3B | 0.7608      |   0.5996    | 0.6234      |   0.7917    | 0.81    | 0.9243    | 0.872    |\n\n## 太乙系列\n\n太乙系列模型主要应用于跨模态场景，包括文本图像生成，蛋白质结构预测, 语音-文本表示等。2022年11月1日，封神榜开源了第一个中文版本的 stable diffusion 模型“太乙 Stable Diffusion”。\n\n### 模型下载地址\n[太乙 Stable Diffusion 纯中文版本](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1)\n\n[太乙 Stable Diffusion 中英双语版本](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1)\n\n### 模型使用\n\n``` python\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1\").to(\"cuda\")\n\nprompt = '飞流直下三千尺，油画'\nimage = pipe(prompt, guidance_scale=7.5).images[0]  \nimage.save(\"飞流.png\")\n```\n\n### 生成效果\n\n|  铁马冰河入梦来，3D绘画。   |  飞流直下三千尺，油画。 | 女孩背影，日落，唯美插画。  |\n|  ----  | ----  | ----  |\n| ![](fengshen/examples/stable_diffusion_chinese/result_examples/tiema.png)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/feiliu.png)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/nvhai.jpg) |\n\nAdvanced Prompt\n\n| 铁马冰河入梦来，概念画，科幻，玄幻，3D  | 中国海边城市，科幻，未来感，唯美，插画。 | 那人却在灯火阑珊处，色彩艳丽，古风，资深插画师作品，桌面高清壁纸。 |\n|  ----  | ----  | ----  |\n| ![](fengshen/examples/stable_diffusion_chinese/result_examples/tiema2.jpg)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/chengshi.jpg) | ![](fengshen/examples/stable_diffusion_chinese/result_examples/naren.jpg) |\n\n### 使用手册 Handbook for Taiyi\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/stable_diffusion_chinese/taiyi_handbook.md\n\n### 怎样微调(How to finetune)\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/finetune_taiyi_stable_diffusion\n\n### 配置webui(Configure webui)\n\nhttps://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/README.md\n\n### DreamBooth\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/stable_diffusion_dreambooth\n\n# 封神框架\n\n为了让大家用好封神榜大模型，参与大模型的继续训练和下游应用，我们同步开源了以用户为中心的FengShen(封神)框架。详情请见：[FengShen(封神)框架](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen)。\n\n我们参考了[HuggingFace](https://github.com/huggingface/transformers), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [Pytorch-Lightning](https://github.com/PyTorchLightning/pytorch-lightning), [DeepSpeed](https://github.com/microsoft/DeepSpeed)等优秀的开源框架，结合NLP领域的特点, 以Pytorch为基础框架，Pytorch-Lightning为Pipeline重新设计了FengShen。 FengShen可以应用在基于海量数据(TB级别数据)的大模型(百亿级别参数)预训练以及各种下游任务的微调，用户可以通过配置的方式很方便地进行分布式训练和节省显存的技术，更加聚焦在模型实现和创新。同时FengShen也能直接使用[HuggingFace](https://github.com/huggingface/transformers)中的模型结构进行继续训练，方便用户进行领域模型迁移。FengShen针对封神榜开源的模型和模型的应用，提供丰富、真实的源代码和示例。随着封神榜模型的训练和应用，我们也会不断优化FengShen框架，敬请期待。\n\n## 安装\n\n### 使用自己的环境安装\n\n```shell\ngit clone https://github.com/IDEA-CCNL/Fengshenbang-LM.git\ncd Fengshenbang-LM\ngit submodule init\ngit submodule update\n# submodule是我们用来管理数据集的fs_datasets，通过ssh的方式拉取，如果用户没有在机器上配置ssh-key的话可能会拉取失败。\n# 如果拉取失败，需要到.gitmodules文件中把ssh地址改为https地址即可。\npip install --editable .\n```\n\n### 使用Docker\n\n我们提供一个简单的包含torch、cuda环境的docker来运行我们的框架。\n\n```shell\nsudo docker run --runtime=nvidia --rm -itd --ipc=host --name fengshen fengshenbang/pytorch:1.10-cuda11.1-cudann8-devel\nsudo docker exec -it fengshen bash\ncd Fengshenbang-LM\n# 更新代码 docker内的代码可能不是最新的\ngit pull\ngit submodule foreach 'git pull origin master' \n# 即可快速的在docker中使用我们的框架啦\n```\n\n## Pipelines\n\n封神框架目前在适配各种下游任务的Pipeline，支持命令行一键启动Predict、Finetuning。\n以Text Classification为例\n\n```python\n# predict\n❯ fengshen-pipeline text_classification predict --model='IDEA-CCNL/Erlangshen-Roberta-110M-Similarity' --text='今天心情不好[SEP]今天很开心'\n[{'label': 'not similar', 'score': 0.9988130331039429}]\n\n# train\nfengshen-pipeline text_classification train --model='IDEA-CCNL/Erlangshen-Roberta-110M-Similarity' --datasets='IDEA-CCNL/AFQMC' --gpus=0 --texta_name=sentence1 --strategy=ddp\n```\n\n[三分钟上手封神](fengshen/README.md)\n\n\n# 封神榜系列文章\n\n[封神榜系列之从数据并行开始大模型训练](https://zhuanlan.zhihu.com/p/512194216)\n\n[封神榜系列之是时候给你的训练提提速了](https://zhuanlan.zhihu.com/p/485369778)\n\n[封神榜系列之中文pegasus模型预训练](https://zhuanlan.zhihu.com/p/528716336)\n\n[封神榜系列：finetune一下二郎神就不小心拿下了第一](https://zhuanlan.zhihu.com/p/539870077)\n\n[封神榜系列之快速搭建你的算法demo](https://zhuanlan.zhihu.com/p/528077249)\n\n[2022AIWIN世界人工智能创新大赛：小样本多任务赛道冠军方案](https://zhuanlan.zhihu.com/p/539958182)\n\n# 引用\n\n```\n@article{fengshenbang,\n  author    = {Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen and Ruyi Gan and Jiaxing Zhang},\n  title     = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},\n  journal   = {CoRR},\n  volume    = {abs/2209.02970},\n  year      = {2022}\n}\n\n也可以引用我们的网站:\n\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2021},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```\n\n# 联系我们\n\nIDEA研究院CCNL技术团队已创建封神榜开源讨论群，我们将在讨论群中不定期更新发布封神榜新模型与系列文章。请扫描下面二维码或者微信搜索“fengshenbang-lm”，添加封神空间小助手进群交流！\n\n![avartar](pics/wechat_icon.png)\n\n我们也在持续招人，欢迎投递简历！\n\n![avartar](pics/contactus.png)\n\n# 版权许可\n\n[Apache License 2.0](LICENSE)\n"
        },
        {
          "name": "README_en.md",
          "type": "blob",
          "size": 22.693359375,
          "content": "[**中文**](./README.md) | [**English**](./README_en.md)\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n</p>\n\n\n<h4 align=\"center\">\n  <a href=#Installation> Installation </a> |\n  <a href=https://huggingface.co/IDEA-CCNL> Model Downloads </a> |\n  <a href=https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples> Code Example </a> |\n  <a href=https://fengshenbang-doc.readthedocs.io/zh/latest> Docs </a> |\n  <a href=https://fengshenbang-lm.com> Fengshenbang Website </a> |\n  <a href=https://fengshenbang-lm.com/open-api> API </a>\n</h4>\n\n------------------------------------------------------------------------------------------\n\n\n# Fengshenbang Achievements\n\n> [**Fengshenbang 1.0**](https://arxiv.org/abs/2209.02970): Fengshenbang1.0 bilingual general paper, aims to be the Foundation of Chinese Cognitive Intelligence.\n\n> [**BioBART**](https://arxiv.org/abs/2204.03905): A generative language model for biomedical domain provided by Tsinghua University together with IDEA Institute.(```BioNLP 2022```)\n\n> [**UniMC**](https://arxiv.org/abs/2210.08590): A unified model for zero-shot scenarios based on labeled datasets.(```EMNLP 2022```)\n\n> [**FMIT**](https://arxiv.org/abs/2208.11039): A single-tower multimodal named entity recognition model based on relative position encoding.(```COLING 2022```)\n\n> [**UniEX**](https://arxiv.org/abs/2305.10306): A Natural Language Understanding Model for Unified Extraction Tasks.(```ACL 2023```)\n\n> [**Solving Math Word Problems via Cooperative Reasoning induced Language Models**](https://2023.aclweb.org/program/accepted_main_conference/): Solving Math Word Problems via Cooperative Reasoning induced Language Models.(```ACL 2023```)\n\n> [**MVP-Tuning**](https://2023.aclweb.org/program/accepted_main_conference/): 基Multi-View Knowledge Retrieval with Prompt Tuning\nfor Commonsense Reasoning.(```ACL 2023```)\n\n\n# Fengshenbang Big Event\n- [Fengshenbang team open-sources the \"Ziya-Visual\"](https://mp.weixin.qq.com/s/-gv9tG5-Vqo2iN_ETO84KQ) 2023.06.05\n- [Fengshenbang team open-sources the general large-scale model series \"Ziya\"](https://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA) 2023.05.17\n- [First Chinese stable diffusion model is open-sourced，IDEA Fengshenbang team opens the era of Chinese AI art](https://mp.weixin.qq.com/s/WrzkiJOxqNcFpdU24BKbMA) 2022.11.2\n- [Breaking the impossible triangle, comparable to 540B models, IDEA Fengshenbang team only has 200B models to achieve zero-shot SOTA](https://mp.weixin.qq.com/s/m0_W31mP4xKKla8jIwUXkw) 2022.10.25\n- [AIWIN champion solution, Fengshenbang proposed multi-task learning model Ubert](https://mp.weixin.qq.com/s/A9G0YLbIPShKgm98DnD2jA) 2022.07.21\n- [Just a simple Finetune, \"Fengshenbang\" pre-trained language model \"Erlangshen\" won the first place in SimCLUE benchmark](https://mp.weixin.qq.com/s/KXQtCgxZlCnv0HqSyQAteQ) 2022.07.14\n- [Fengshen Framework is officially open-sourced, helping you easily pre-train and fine-tune major models in \"Fengshenbang\"](https://mp.weixin.qq.com/s/NtaEVMdTxzTJfVr-uQ419Q) 2022.06.30\n- [GTS model production platform is open to public beta, automatically produces AI models using AI](https://mp.weixin.qq.com/s/AFp22hzElkBmJD_VHW0njQ) 2022.05.23\n- [Dataset released！IDEA-CCNL × NLPCC 2022 Mission Challenge has begun, and the winning teams will receive IDEA internship opportunities](https://mp.weixin.qq.com/s/AikMy6ygfnRagOw3iWuArA) 2022.04.07\n- [A new record! IDEA-CCNL pretrained language model \"Erlangshen\", this time won ZeroCLUE](https://mp.weixin.qq.com/s/Ukp0JOUwAZJiegdX_4ox2Q) 2022.01.24\n- [IDEA Friends | CCNL Team \"Fengshenbang\", why did they choose IDEA?](https://mp.weixin.qq.com/s/eCmMtopG9DGvZ0qWM3C6Sg) 2022.01.12\n- [IDEA Meeting Release｜\"Fengshenbang\" Open Source Project](https://mp.weixin.qq.com/s/Ct06-vLEKoYMyJQPBV2n0w) 2021.11.25\n- [IDEA Chinese pre-trained language model Erlangshen tops the FewCLUE benchmark](https://mp.weixin.qq.com/s/bA_9n_TlBE9P-UzCn7mKoA) 2021.11.11\n\n# Navigation\n- [Fengshenbang Achievements](#fengshenbang-achievements)\n- [Fengshenbang Big Event](#fengshenbang-big-event)\n- [Navigation](#navigation)\n- [Model Infofrmation](#model-infofrmation)\n- [Fengshenbang-LM](#fengshenbang-lm)\n- [Fengshenbang Model](#fengshenbang-model)\n  - [Ziya](#Ziya)\n  - [Erlangshen](#erlangshen)\n  - [Taiyi](#Taiyi)\n- [Fengshen Framework](#fengshen-framework)\n  - [Installation](#installation)\n  - [Pipelines](#pipelines)\n- [Fengshen Benchmark](#fengshen-benchmark)\n- [Fegnshenbang Series Articles](#fegnshenbang-series-articles)\n- [Citation](#citation)\n- [Contact](#contact)\n- [License](#license)\n\n# Model Infofrmation\n|Series|Demand|Task|Parameter Scale|Extra|\n|:---:|:---:|:---:|:---:|---|\n|[Ziya](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)|General|AGI|>7B|Ziya has the capabilities of translation, programming, text classification, information extraction, summarization, copy generation, common sense question and answer, and mathematical calculation.|\n|[Erlangshen](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E4%BA%8C%E9%83%8E%E7%A5%9E%E7%B3%BB%E5%88%97/index.html)|General|NLU|97M-3.9B|Erlangshen was designed to solve NLU tasks; The largest BERT when publicly released; SOTA on FewCLUE and ZeroCLUE in 2021.|\n|[Wenzhong](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E9%97%BB%E4%BB%B2%E7%B3%BB%E5%88%97/index.html)|General|NLG|1B-3.5B|Wenzhong focuses on NLG tasks; Provides several generative models with different scales, such as GPT2, etc.|\n|[Randeng](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E7%87%83%E7%81%AF%E7%B3%BB%E5%88%97/index.html)|General|NLT|770M-5B|Randeng handles natural language transformation (NLT) type tasks that convert from source text to target text, such as machine translation, text summarization, etc.|\n|[Taiyi](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E5%A4%AA%E4%B9%99%E7%B3%BB%E5%88%97/index.html)|Speical|MultiModal|87M-1B|Taiyi was applied to cross-modality scenarios, including text image generation, protein structure prediction, speech-text representation, etc.|\n|[Yuyuan](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E4%BD%99%E5%85%83%E7%B3%BB%E5%88%97/index.html)|Speical|Domain|0.1B-3.5B|Yuyuan was applied to specific domains such as healthcare, finance, law, programming, etc; The largest open-source GPT2 medical model|\n|-TBD-|Special|Exploration|-Unknown-|This series hopes to develop experimental models on NLP with various technology companies and universities. Currently there are:[Zhouwenwang](https://fengshenbang-doc.readthedocs.io/zh/latest/docs/%E5%91%A8%E6%96%87%E7%8E%8B%E7%B3%BB%E5%88%97/index.html)|\n\n\n[Download url of Fengshenbang](https://huggingface.co/IDEA-CCNL)\n\n[Fengshenbang Model training and fine-tuning code script](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples)\n\n[Handbook of Fengshenbang](https://fengshenbang-doc.readthedocs.io/zh/latest/index.html)\n\n\n# Fengshenbang-LM\nRemarkable advances in Artificial Intelligence (AI) have produced great models, in particular, pre-trained based foundation models become an emerging paradigm. In contrast to traditional AI models that must be trained on vast datasets for one or a few scenarios, foundation models can be adapted to a wide range of downstream tasks, therefore, limiting the amount of resource demanded to acquire an AI venture off the ground. \nMoreover, we observe that these models grow rapidly within a short period, around 10 times each year. For instance, BERT has 100 million parameters and GTP-3 has over 100 billion parameters. Many of the forefront challenges in AI, especially generalization ability, are becoming achievable due to this inspiring trend.\n\nFoundation models, most notably language models, are dominated by the English-language community. \nThe Chinese language as the world's largest spoken language (native speakers), however, has no systematic research resources to support it, making the progress in the Chinese language domain lag behind others.\n\nAnd the world needs an answer for this.\n\nOn November 22nd, 2021, Harry Shum, the Founder and Chairman of the IDEA (International Digital Economy Academy) officially announces the launch of \"Fengshenbang\" open source project.  —— a Chinese language driven foundation ecosystem, incorporates pre-trained models, task-specific fine-tune applications, benchmarks, and datasets. \n![avatar](pics/start_opensource.png)\n\n\n# Fengshenbang Model\n\n\"Fengshenbang Model\" will open-source a series of NLP-related pre-trained models in all aspects. There are a wide range of research tasks in the NLP community, which can be divided into two categories: general demands and special demands. In general demands, there are common NLP tasks, which are classified into Natural Language Understanding (NLU), Natural Language Generation (NLG), and Natural Language Transformation (NLT). \nDue to the fast development, NLP community brings special demands to the entire AI community, which are often assigned to MultiModal (MM), Domains and Exploration. We consider all of these tasks and provide models that are fine tuning for downstream tasks, making our base model easy to use for users with limited computing resources. We consider all of these demands and provide models that are fine-tuned for downstream tasks, making our base model easy to use for users with limited computing resources. Moreover, we guarantee that we will optimize the models continuously with new datasets and latest algorithms. We aim to build universal infrastructure for Chinese cognitive intelligence and prevent duplicative construction, and hence save computing resources for the community.\n\n![avatar](pics/all_models.png)\n\nWe also call for businesses, universities and institutions to join us with the project and build the sytem of large-scale open-source models collaboratively. We envision that, in the near future, the first choice when in need of a new pretrained model should be selecting one in closest proximity to the desired scale,architecture and domain from the series, followed by further training. After obtaining a trained new model, we shall add it back to the series of open-source models for future usage. In this way we build the open-source system iteratively and collaboratively while individuals could get desired models using minimal computing resources. \n\nFor better open source experience, all models of the Fengshenbang series are synchronized within the Huggingface community, and can be obtained for use within few lines of code. Welcome to download and use our models from our repo at [IDEA-CCNL at HuggingFace](https://huggingface.co/IDEA-CCNL).\n\n## Ziya\n\nThe general large-scale model \"Ziya\" series has the capabilities of translation, programming, text classification, information extraction, summarization, copy generation, common sense question and answer, and mathematical calculation. At present, Ziya's general-purpose large model (v1/v1.1) has completed a three-stage training process of large-scale pre-training, multi-task supervised fine-tuning, and human feedback learning. Ziya series models include the following models:\n- [Ziya-LLaMA-13B-v1.1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)\n- [Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)\n- [Ziya-LLaMA-7B-Reward](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-7B-Reward)\n- [Ziya-LLaMA-13B-Pretrain-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-Pretrain-v1)\n- [Ziya-BLIP2-14B-Visual-v1](https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1)\n\n### Example of Usage\n\nRefer to [Ziya-LLaMA-13B-v1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1)\n\n### Online Demo\n\n- [Huggingface Ziya Space](https://huggingface.co/spaces/IDEA-CCNL/Ziya-v1)\n- [Huggingface Ziya-visual Space](https://huggingface.co/spaces/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1-Demo)\n- [ModelScope Ziya Space](https://modelscope.cn/studios/Fengshenbang/Ziya_LLaMA_13B_v1_online/summary)\n\n\n### Finetune Example\n\nRefer to [ziya_finetune](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/ziya_llama)\n\n### Inference & Quantization Example\n\nRefer to [ziya_inference](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/ziya_inference)\n \n## Erlangshen\n\nThis series focuses on using bidirectional language models with encoders to solve multiple natural language understanding tasks. \nErlangshen-MegatronBert-1.3B is the largest Chinese open source model with the structure of Bert. It contains 13 billion parameters, and was trained with 280G datasets on 32 A100 GPUs for 14 days. It achieved the top on the Chinese natural language understanding benchmark FewCLUE on Nov 10th, 2021. Among the tasks of FewCLUE, Erlangshen-1.3 beat human performance on the task of CHID(Chinese idioms cloze test) and TNEWS(News Classification), and achieved SOTA on tasks of CHID, CSLDCP（academic literature classification) and OCNLI(Natural language Inference), refreshing the records of few-shot learning. We will continue to optimize the Erlangshen series with respect to model scale, knowledge fusion, auxiliary supervision tasks, etc. \n\n![image](https://user-images.githubusercontent.com/4384420/141752311-d15c2a7f-cd83-4e9e-99a5-cb931088845e.png)\n\nErlangshen-MRC achieved the Chinese language comprehension evaluations benchmark ZeroCLUE on Jan 24th, 2022. Among the tasks of ZeroCLUE, CSLDCP (discipline literature classification), TNEWS (news classification), IFLYTEK (application description classification), CSL (abstract keyword recognition), CLUEWSC (reference resolution) achieved SOTA.\n\n![image](https://user-images.githubusercontent.com/4384420/151319156-e20ba252-b531-4779-8099-ef60c7954f76.png)\n\n### Download the Models\n[Huggingface Erlangshen-MegatronBert-1.3B](https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B)\n\n### Load the Models \n``` python\nfrom transformers import MegatronBertConfig, MegatronBertModel\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\nconfig = MegatronBertConfig.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\nmodel = MegatronBertModel.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\n\n```\n### Example of Usage\nFor the convenience of developers, we offer an example [script](https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/classification/finetune_classification.sh) for downstream finetuning. The script uses the tnews dataset from [CLUE](https://github.com/CLUEbenchmark/CLUE). \n\n1、Fisrt, modify the MODEL_TYPE and PRETRAINING_MODEL_PATH parameters of [finetune script](https://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/classification/finetune_classification.sh), and other parameters can be modified according to your specific device.\n\n``` sh\nMODEL_TYPE=huggingface-megatron_bert\nPRETRAINED_MODEL_PATH=IDEA-CCNL/Erlangshen-MegatronBert-1.3B\n```\n2、Then, run\n\n``` sh\nsh finetune_classification.sh\n```\n\n### Performance on Downstream Tasks \n|     Model   | afqmc    |  tnews  | iflytek    |  ocnli  |  cmnli  | wsc  | csl  |\n| :--------:    | :-----:  | :----:  | :-----:   | :----: | :----: | :----: | :----: |\n| roberta-wwm-ext-large | 0.7514      |   0.5872    | 0.6152      |   0.777    | 0.814    | 0.8914    | 0.86    |\n| Erlangshen-MegatronBert-1.3B | 0.7608      |   0.5996    | 0.6234      |   0.7917    | 0.81    | 0.9243    | 0.872    |\n\n## Taiyi\n\nTaiyi series models are mainly used in cross-modal scenarios, including text image generation, protein structure prediction, speech-text representation, etc. On November 1, 2022, Fengshenbang released the first Chinese version of the stable diffusion model \"Taiyi Stable Diffusion\".\n\n### Download the Models\n[Taiyi Stable Diffusion Chinese](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1)\n\n[Taiyi Stable Diffusion Chinese&English Bilingual](https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1)\n\n### Example of Usage\n\n``` python\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\"IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1\").to(\"cuda\")\n\nprompt = '飞流直下三千尺，油画'\nimage = pipe(prompt, guidance_scale=7.5).images[0]  \nimage.save(\"飞流.png\")\n```\n\n### Performance\n\n|  铁马冰河入梦来，3D绘画。   |  飞流直下三千尺，油画。 | 女孩背影，日落，唯美插画。  |\n|  ----  | ----  | ----  |\n| ![](fengshen/examples/stable_diffusion_chinese/result_examples/tiema.png)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/feiliu.png)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/nvhai.jpg) |\n\nAdvanced Prompt\n\n| 铁马冰河入梦来，概念画，科幻，玄幻，3D  | 中国海边城市，科幻，未来感，唯美，插画。 | 那人却在灯火阑珊处，色彩艳丽，古风，资深插画师作品，桌面高清壁纸。 |\n|  ----  | ----  | ----  |\n| ![](fengshen/examples/stable_diffusion_chinese/result_examples/tiema2.jpg)  | ![](fengshen/examples/stable_diffusion_chinese/result_examples/chengshi.jpg) | ![](fengshen/examples/stable_diffusion_chinese/result_examples/naren.jpg) |\n\n### Handbook for Taiyi\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/blob/main/fengshen/examples/stable_diffusion_chinese/taiyi_handbook.md\n\n### How to finetune\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/finetune_taiyi_stable_diffusion\n\n### Configure webui\n\nhttps://github.com/IDEA-CCNL/stable-diffusion-webui/blob/master/README.md\n\n### DreamBooth\n\nhttps://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/stable_diffusion_dreambooth\n\n# Fengshen Framework\n\nTo make it easy for everyone to use the FengShenbang model, participate in the continuous training and downstream applications of the large-scale model, we We simultaneously open-source the user-centered FengShen framework. For details, please also see: [Fengshen Framework](https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen).\n\nReferring to other excellent open source frameworks (including [HuggingFace](https://github.com/huggingface/transformers), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [Pytorch-Lightning](https://github.com/PyTorchLightning/pytorch-lightning), [DeepSpeed](https://github.com/microsoft/DeepSpeed)) and combining the characteristics of NLP field, we redesign FengShen with Pytorch as the base framework and Pytorch-Lightning as the Pipeline. FengShen can be applied to pre-training of large models (tens of billions of parameters) based on massive data (terabytes of data) and fine-tuning on various downstream tasks. Users can easily perform distributed training and memory-saving techniques with configuration, thus focusing more on model implementation and innovation. Also, FengShen can directly use the model structure in [HuggingFace](https://github.com/huggingface/transformers) for continued training, which facilitates domain transfer for users. FengShen provides rich and realistic source code and examples. We will continue to optimize the FengShen framework as the models of Fengshenbang are trained and applied. Stay tuned. \n\n## Installation\n\n### Installing in an existing environment\n\n```shell\ngit clone https://github.com/IDEA-CCNL/Fengshenbang-LM.git\ncd Fengshenbang-LM\ngit submodule init\ngit submodule update\n# ubmodule is the fs_datasets we use to manage the datasets, pulled by ssh, which may fail if the user does not have ssh-key configured on the machine.\n# If the pull fails, you need to go to the .gitmodules file and change the ssh address to an https address.\npip install --editable .\n```\n\n### Using Docker\n\nWe provide a simple docker, which contains torch and cuda environment to run our framework.\n\n```shell\nsudo docker run --runtime=nvidia --rm -itd --ipc=host --name fengshen fengshenbang/pytorch:1.10-cuda11.1-cudann8-devel\nsudo docker exec -it fengshen bash\ncd Fengshenbang-LM\n# Update the code. The code in docker may not be up to date\ngit pull\ngit submodule foreach 'git pull origin master' \n# Now you're ready to use our framework in docker\n```\n\n## Pipelines\n\nFenghen framework is currently adapting various downstream tasks in Pipeline, support Predict, Finetuning by one-click in command line.\nTake Text Classification as an example\n\n```python\n# predict\n❯ fengshen-pipeline text_classification predict --model='IDEA-CCNL/Erlangshen-Roberta-110M-Similarity' --text='今天心情不好[SEP]今天很开心'\n[{'label': 'not similar', 'score': 0.9988130331039429}]\n\n# train\nfengshen-pipeline text_classification train --model='IDEA-CCNL/Erlangshen-Roberta-110M-Similarity' --datasets='IDEA-CCNL/AFQMC' --gpus=0 --texta_name=sentence1 --strategy=ddp\n```\n\n[Get Started with Fengshen in 3 Minutes](fengshen/README.md)\n\n\n# Fengshenbang Series Articles\n\n[Fengshen Series: Getting Started on Training Large Model with Data Parallelism](https://zhuanlan.zhihu.com/p/512194216)\n\n[Fengshen Series: It is Time to Accelerate your Training Process!](https://zhuanlan.zhihu.com/p/485369778)\n\n[Fengshen Series: Chinese PEGASUS Model Pre-training](https://zhuanlan.zhihu.com/p/528716336)\n\n[Fengshen Series: Just a Simple Finetune, Erlangshen Accidentally Took the First Place](https://zhuanlan.zhihu.com/p/539870077)\n\n[Fengshen Series: Quickly Build Your Algorithm Demo](https://zhuanlan.zhihu.com/p/528077249)\n\n[2022 AIWIN World Artificial Intelligence Innovation Competition: Small Sample Multi-Task Track Winner Solution](https://zhuanlan.zhihu.com/p/539958182)\n\n# Citation\nIf you are using the resource for your work, please cite the our [paper](https://arxiv.org/abs/2209.02970):\n```\n@article{fengshenbang,\n  author    = {Junjie Wang and Yuxiang Zhang and Lin Zhang and Ping Yang and Xinyu Gao and Ziwei Wu and Xiaoqun Dong and Junqing He and Jianheng Zhuo and Qi Yang and Yongfeng Huang and Xiayu Li and Yanghan Wu and Junyu Lu and Xinyu Zhu and Weifeng Chen and Ting Han and Kunhao Pan and Rui Wang and Hao Wang and Xiaojun Wu and Zhongshen Zeng and Chongpei Chen and Ruyi Gan and Jiaxing Zhang},\n  title     = {Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence},\n  journal   = {CoRR},\n  volume    = {abs/2209.02970},\n  year      = {2022}\n}\n```\nYou can also cite our [website](https://github.com/IDEA-CCNL/Fengshenbang-LM/):\n```\n@misc{Fengshenbang-LM,\n  title={Fengshenbang-LM},\n  author={IDEA-CCNL},\n  year={2021},\n  howpublished={\\url{https://github.com/IDEA-CCNL/Fengshenbang-LM}},\n}\n```\n# Contact\n\nIDEA-CCNL team has created the Fengshebang open source discussion group, we will update and release new models and articles of Fengshenbang in the discussion group from time to time. Please scan the QR code below or search \"fengshenbang-lm\" on WeChat to add the Fengshen space assistant into the group!\n\n![avartar](pics/wechat_icon.png)\n\nWe are also continuously recruiting, so feel free to send in your resume!\n\n![avartar](pics/contactus.png)\n\n# License \n\n[Apache License 2.0](LICENSE)\n"
        },
        {
          "name": "fengshen",
          "type": "tree",
          "content": null
        },
        {
          "name": "pics",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.7158203125,
          "content": "from setuptools import setup, find_packages\n\nsetup(\n    name=\"fengshen\",\n    version=\"0.0.1\",\n    description=\"fengshen\",\n    long_description=\"fengshen\",\n    license=\"MIT Licence\",\n    url=\"https://idea.edu.cn\",\n    author=\"gaoxinyu\",\n    author_email=\"gaoxinyu@idea.edu.cn\",\n\n    packages=find_packages(),\n    include_package_data=True,\n    platforms=\"any\",\n    install_requires=[\n        'transformers >= 4.17.0',\n        'datasets >= 2.0.0',\n        'pytorch_lightning >= 1.5.10',\n        'deepspeed >= 0.5.10',\n        'jieba-fast >= 0.53',\n        'jieba >= 0.40.0',\n    ],\n\n    scripts=[],\n    entry_points={\n        'console_scripts': [\n            'fengshen-pipeline = fengshen.cli.fengshen_pipeline:main'\n        ]\n    }\n)\n"
        }
      ]
    }
  ]
}