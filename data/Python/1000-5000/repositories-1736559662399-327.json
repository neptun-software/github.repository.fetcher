{
  "metadata": {
    "timestamp": 1736559662399,
    "page": 327,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMzMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dedupeio/dedupe",
      "stars": 4194,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.0478515625,
          "content": "[flake8]\nmax-line-length=160\nextend-ignore = E203"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.154296875,
          "content": "# .git-blame-ignore-revs\n# Blacken\nc28cd1363f9fcf3bb9c7769615e02bfc08ba45b1\n9e01ccf2e7eacabe0cd1ee16c5158ba417104897\n442edec76a27f7d76f01c89de7327c35cbb898d7\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.40625,
          "content": ".env\n.coverage*\nhtmlcov\ncpredicates.c\n*.code-workspace\nlibdistance-0.2.1\nbuild\n_build\n*.pyc\nlogfile\n*.*~\n*.o\n*.so\n*.py.*\n*.*gz\n*.html\n.#*\n*.*#\n*.json\nexamples/output/*.*\nexamples/csv_example/csv_example_output.csv\n*output.csv\nexamples/mysql_example/*.txt*\n*.db\nkernprof.py\npossible_classifiers\n.DS_Store\nmysql.cnf\n*settings\n*.egg-info\nENV\ndist\nsrc/*.c\n\n.coverage\nhtmlcov\n\n!benchmarks/asv.conf.json\nbenchmarks/.asv/*\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.3193359375,
          "content": "repos:\n  - repo: https://github.com/psf/black\n    rev: 24.4.2 \n    hooks:\n    - id: black\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        name: isort (python)\n  - repo: https://github.com/pycqa/flake8\n    rev: \"7.1.0\"\n    hooks:\n      - id: flake8\n        args: [--config=.flake8]\n"
        },
        {
          "name": ".readthedocs.yml",
          "type": "blob",
          "size": 0.6318359375,
          "content": "# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the OS, Python version and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n\n# Build documentation with MkDocs\n#mkdocs:\n#  configuration: mkdocs.yml\n\n# Optionally build your docs in additional formats such as PDF and ePub\nformats: all\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  install:\n    - requirements: docs/requirements.txt\n    - method: pip\n      path: .\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 7.1611328125,
          "content": "# 3.0.2\n- Fixed regression in Exists predicate\n\n# 3.0.1\n- Fixed regression in Exists predicate\n\n\n# 3.0.0\n- Development in python packaging made supporting the previous namespace approach for\n  variable plugins untenable. Since we had to redo the way we defined the data model, \n  we took the opportunity to explicity instantiate variable objects. \n\n# 2.0.6\n- fixed bug that was preventing learning of index predicates in Dedupe mode\n\n# 2.0.3\n- Improved memory performance of connected components\n\n\n# 2.0\n\n- Python 3 only\n- Static typing and type Hints\n- Incorporate sqlite to extend normal API to millions of records\n- Multiprocessing enabled for Windows\n- Multiprocessing mode changed to spawn for Mac OS X\n- Moved from CamelCase to lowercase_with_underscore for method names.\n- Dropped ability to save indices in save settings.\n- Moved from Deduper.match -> Dedupe.partition, RecordLink.match -> RecordLink.join, Gazetteer.match -> Gazetteer.search\n- Renamed Matching.blocker -> Matching.fingerprinter\n- Moved to autodoc for documentation\n- Dropped threshold methods\n- matchBlocks has been replaced by score, which takes pairs of records not blocks\n\n# 1.10.0\n- Dropped python 2.7 support\n\n# 1.9.4\n- Cleaned up block learning\n\n# 1.9.3\n- Improved performance of connected components algorithm with very large components\n- Fixed pickling unpickling bug of Index predicate classes\n\n# 1.9.0\n- Implemented a disagreement based active labeler to improve blocking recall\n\n# 1.8.2\n- removed shelve-backed persistence in blocking data in favor of an improved in-memory implementation\n\n# 1.8.0\n- matchBlocks is not a generator; match is now optionally a generator. If the\n  generator option is turned of for the Gazette match is lazy\n\n# 1.7.8\n- Speed up blocking, on our way to 3-predicates\n\n# 1.7.5\n- Significantly reduced memory footprint during connected_components\n\n# 1.7.3\n- Significantly reduced memory footprint during scoreDuplicates\n\n# 1.7.2\n- Improper release\n\n# 1.7.1\n- TempShelve class that addresses various bugs related to cleaning up tempoary shelves\n\n# 1.7.0\n- Added `target` argument to blocker and predicates for changing the behavior\n  of the predicates for the target and source dataset if we are linking.\n\n# 1.6.8\n- Use file-backed blocking with dbm, dramatically increases size of data that can be handled without special programming\n\n# 1.6.7\n- Reduce memory footprint of matching\n\n# 1.6.0\n- Simplify .train method\n\n# 1.5.5\n- Levenshtein search based index predicates thanks to @mattandahalfew\n\n# 1.5.0\n- simplified the sample API, this might be a breaking change for some\n- the active learner interface is now more modular to allow for a different learner\n- random sampling of pairs has been improved for linking case and\n  dedupe case, h/t to @MarkusShepherd\n\n## 1.4.15\n- frozendicts have finally been removed\n- first N char predicates return their entire length if length is less\n  than N, instead of nothing\n- crossvalidation is skipped in active learning if using default rlr learner\n\n## 1.4.5\n- Block indexes can now be persisted by using the index=True argument\n  in the writeSettings method\n\n## 1.4.1\n- Now uses C version of double metaphone for speed\n- Much faster compounding of blocks in block learning\n\n## 1.4.0\n- Block learning now tries to minimize the total number of comparisons\n  not just the comparisons of distinct records. This decouples makes\n  block learning from learning classifier learning. This change has\n  requires new, different arguments to the train method.\n\n## 1.3.8\n- Console labeler now shows fields in the order they are defined in\n  the data model. The labeler also reports number of labeled examples\n- `pud` argument added to the `train` method. Proportion of uncovered\n  dupes. This deprecates `uncovered_dupes` argument\n\n## 1.3.0\n- If we have enough training data, consider Compound predicates of length 3 in addition to predicates of length 2\n\n## 1.1.1\n- None now treated as missing data indicator. Warnings for deprecations of older types of missing data indicators\n\n## 1.1.0\nFeatures\n- Handle FuzzyCategoricalType in datamodel\n\n## 1.0.0\nFeatures\n- Speed up learning\n- Parallelize sampling\n- Optional [CRF Edit Distance](https://dedupe.readthedocs.io/en/latest/Variable-definition.html#optional-edit-distance)\n\n## 0.8.0\nSupport for Python 3.4 added. Support for Python 2.6 dropped.\n\nFeatures\n- Windows OS supported\n- train method has argument for not considering index predicates\n- TfIDFNGram Index Predicate added (for shorter string)\n- SuffixArray Predicate\n- Double Metaphone Predicates\n- Predicates for numbers, OrderOfMagnitude, Round\n- Set Predicate OrderOfCardinality\n- Final, learned predicates list will now often be smaller without\n  loss of coverage\n- Variables refactored to support external extensions like\n  https://github.com/datamade/dedupe-variable-address\n- Categorical distance, regularized logistic regression, affine gap\n  distance, canonicalization have been turned into separate libraries.\n- Simplejson is now dependency\n\n## 0.7.5\nFeatures\n- Individual record cluster membership scores\n- New predicates\n- New Exists Variable Type\n\nBug Fixes\n- Latlong predicate fixed\n- Set TFIDF canopy working properly\n\n## 0.7.4\nFeatures\n- Sampling methods now use blocked sampling\n\n## 0.7.0\nVersion 0.7.0 is backwards compatible, except for the match method of Gazetteer class\n\nFeatures\n- new index, unindex, and match methods in Gazetter Matching. Useful for\n  streaming matching\n\n## 0.6.0\nVersion 0.6.0 is *not* backwards compatible.\n\nFeatures :\n- new Text, ShortString, and exact string types\n- multiple variables can be defined on same field\n- new Gazette linker for matching dirty records against a master list\n- performance improvements, particularly in memory usage\n- canonicalize function in dedupe.convenience for creating a canonical representation of a cluster of records\n- tons of bugfixes\n\nAPI breaks\n- when initializing an ActiveMatching object, `variable_definition` replaces `field_definition` and is a list of    dictionaries instead of a dictionary. See the documentation for details\n- also when initializing a Matching object, `num_processes` has been replaced by `num_cores`, which now defaults to the\nnumber of cpus on the machine\n- when initializing a StaticMatching object, `settings_file` is now expected to be a file object not a string. The `readTraining`, `writeTraining`, `writeSettings` methods also all now expect file objects\n\n\n## 0.5\nVersion 0.5 is *not* backwards compatible.\n\nFeatures :\n\n- Special case code for linking two datasets that, individually are unique\n- Parallel processing using python standard library multiprocessing\n- Much faster canopy creation using zope.index\n- Asynchronous active learning methods\n\nAPI breaks :\n- `duplicateClusters` has been removed, it has been replaced by\n  `match` and `matchBlocks`\n- `goodThreshold` has been removed, it has been replaced by\n  `threshold` and `thresholdBlocks`\n- the meaning of `train` has changed. To train from training file use `readTraining`. To use console labeling, pass a dedupe instance to the `consoleLabel` function\n- The convenience function dataSample has been removed. It has been replaced by\nthe `sample` methods\n- It is no longer necessary to pass `frozendicts` to `Matching` classes\n- `blockingFunction` has been removed and been replaced by the `blocker` method\n"
        },
        {
          "name": "CITATION.cff",
          "type": "blob",
          "size": 0.27734375,
          "content": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Gregg\"\n  given-names: \"Forest\"\n- family-names: \"Eder\"\n  given-names: \"Derek\"\ntitle: \"dedupe\"\nversion: 2.0.11\ndate-released: 2022-01-27\nurl: \"https://github.com/dedupeio/dedupe\"\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1376953125,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info@datamade.us. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.359375,
          "content": "## Reporting issues\n\nWhen reporting issues please include as much detail as possible about your\noperating system, dedupe version and python version. Whenever possible, please\nalso include a brief, self-contained code example that demonstrates the problem.\n\nIf dedupe is raising an exception, please paste a [full traceback](https://en.wikipedia.org/wiki/Stack_trace).\n"
        },
        {
          "name": "CONTRIBUTORS.md",
          "type": "blob",
          "size": 0.0556640625,
          "content": "* Forest Gregg\n* Derek Eder\n* Nikit Saraf\n* Mark Huberty\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.091796875,
          "content": "The MIT License (MIT)\n\nCopyright (c) 2014 Forest Gregg, Derek Eder, DataMade and Contributors\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.029296875,
          "content": "include dedupe/cpredicates.pyx"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.3076171875,
          "content": "# Dedupe Python Library\n\n[![Tests Passing](https://github.com/dedupeio/dedupe/workflows/tests/badge.svg)](https://github.com/dedupeio/dedupe/actions?query=workflow%3Atests)[![codecov](https://codecov.io/gh/dedupeio/dedupe/branch/main/graph/badge.svg?token=aauKUrTEgh)](https://codecov.io/gh/dedupeio/dedupe)\n\n_dedupe is a python library that uses machine learning to perform fuzzy matching, deduplication and entity resolution quickly on structured data._\n\n__dedupe__ will help you: \n\n* __remove duplicate entries__ from a spreadsheet of names and addresses\n* __link a list__ with customer information to another with order history, even without unique customer IDs\n* take a database of campaign contributions and __figure out which ones were made by the same person__, even if the names were entered slightly differently for each record\n\ndedupe takes in human training data and comes up with the best rules for your dataset to quickly and automatically find similar records, even with very large databases.\n\n## Important links\n* Documentation: https://docs.dedupe.io/\n* Repository: https://github.com/dedupeio/dedupe\n* Issues: https://github.com/dedupeio/dedupe/issues\n* Mailing list: https://groups.google.com/forum/#!forum/open-source-deduplication\n* Examples: https://github.com/dedupeio/dedupe-examples\n\n## dedupe library consulting\n\nIf you or your organization would like professional assistance in working with the dedupe library, Dedupe.io LLC offers consulting services. [Read more about pricing and available services here](https://dedupe.io/pricing/#consulting).\n\n## Tools built with dedupe\n\n### [Dedupe.io](https://dedupe.io/)\nA cloud service powered by the dedupe library for de-duplicating and finding matches in your data. It provides a step-by-step wizard for uploading your data, setting up a model, training, clustering and reviewing the results.\n\n[Dedupe.io](https://dedupe.io/) also supports record linkage across data sources and continuous matching and training through an [API](https://apidocs.dedupe.io/en/latest/).\n\nFor more, see the [Dedupe.io product site](https://dedupe.io/), [tutorials on how to use it](https://dedupe.io/tutorial/intro-to-dedupe-io.html), and [differences between it and the dedupe library](https://dedupe.io/documentation/should-i-use-dedupeio-or-the-dedupe-python-library.html).\n\nDedupe is well adopted by the Python community. Check out this [blogpost](https://medium.com/district-data-labs/basics-of-entity-resolution-with-python-and-dedupe-bc87440b64d4),\na YouTube video on how to use [Dedupe with Python](https://youtu.be/McsTWXeURhA) and a Youtube video on how to apply [Dedupe at scale using Spark](https://youtu.be/q9HPUYmiwjE?t=2704).\n\n\n### [csvdedupe](https://github.com/dedupeio/csvdedupe)\nCommand line tool for de-duplicating and [linking](https://github.com/dedupeio/csvdedupe#csvlink-usage) CSV files. Read about it on [Source Knight-Mozilla OpenNews](https://source.opennews.org/en-US/articles/introducing-cvsdedupe/).\n\n## Installation\n\n### Using dedupe\n\nIf you only want to use dedupe, install it this way:\n\n```bash\npip install dedupe\n```\n\nFamiliarize yourself with [dedupe's API](https://docs.dedupe.io/en/latest/API-documentation.html), and get started on your project. Need inspiration? Have a look at [some examples](https://github.com/dedupeio/dedupe-examples).\n\n### Developing dedupe\n\nWe recommend using [virtualenv](http://virtualenv.readthedocs.org/en/latest/virtualenv.html) and [virtualenvwrapper](http://virtualenvwrapper.readthedocs.org/en/latest/install.html) for working in a virtualized development environment. [Read how to set up virtualenv](http://docs.python-guide.org/en/latest/dev/virtualenvs/).\n\nOnce you have virtualenvwrapper set up,\n\n```bash\nmkvirtualenv dedupe\ngit clone https://github.com/dedupeio/dedupe.git\ncd dedupe\npip install -e . --config-settings editable_mode=compat\npip install -r requirements.txt\n```\n\nIf these tests pass, then everything should have been installed correctly!\n\n```bash\npytest\n```\n\nAfterwards, whenever you want to work on dedupe,\n\n```bash\nworkon dedupe\n```\n\n## Testing\nUnit tests of core dedupe functions\n```bash\npytest\n```\n\n#### Test using canonical dataset from Bilenko's research\n  \nUsing Deduplication\n```bash\npython -m pip install -e ./benchmarks\npython benchmarks/benchmarks/canonical.py\n```\n\nUsing Record Linkage\n```bash\npython -m pip install -e ./benchmarks\npython benchmarks/benchmarks/canonical_matching.py\n```\n\n\n## Team\n\n* Forest Gregg, DataMade\n* Derek Eder, DataMade\n\n## Credits\n\nDedupe is based on Mikhail Yuryevich Bilenko's Ph.D. dissertation: [*Learnable Similarity Functions and their Application to Record Linkage and Clustering*](http://www.cs.utexas.edu/~ml/papers/marlin-dissertation-06.pdf).\n\n## Errors / Bugs\n\nIf something is not behaving intuitively, it is a bug, and should be reported.\n[Report it here](https://github.com/dedupeio/dedupe/issues)\n\n\n## Note on Patches/Pull Requests\n \n* Fork the project.\n* Make your feature addition or bug fix.\n* Send us a pull request. Bonus points for topic branches.\n\n## Copyright\n\nCopyright (c) 2022 Forest Gregg and Derek Eder. Released under the [MIT License](https://github.com/dedupeio/dedupe/blob/main/LICENSE).\n\nThird-party copyright in this distribution is noted where applicable.\n\n## Citing Dedupe\nIf you use Dedupe in an academic work, please give this citation:\n\nForest Gregg and Derek Eder. 2022. Dedupe. https://github.com/dedupeio/dedupe.\n"
        },
        {
          "name": "THANKS.md",
          "type": "blob",
          "size": 0.375,
          "content": "# Thanks To\n\n* Jon Markel for the Illinois campaign contributions data used in the mysql_example, which he got from \n  the [Illinois State Board of Elections](http://www.elections.il.gov/)\n\n* [Daniel Müllner](http://math.stanford.edu/~muellner/) for his wonderful [fastcluster](http://math.stanford.edu/~muellner/fastcluster.html) library and the many changes he made at our request\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "dedupe",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 2.2373046875,
          "content": "[project]\nname = \"dedupe\"\ndescription = \"A python library for accurate and scaleable data deduplication and entity-resolution\"\nversion = \"3.0.3\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\nlicense = {file = \"LICENSE\"}\nkeywords = []\nauthors = [\n  { name = \"Forest Gregg\", email = \"fgregg@datamade.us\" },\n]\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"Intended Audience :: Science/Research\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Natural Language :: English\",\n    \"Operating System :: MacOS :: MacOS X\",\n    \"Operating System :: Microsoft :: Windows\",\n    \"Operating System :: POSIX\",\n    \"Programming Language :: Cython\",\n    \"Programming Language :: Python :: 3\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Scientific/Engineering :: Information Analysis\",\n]\ndependencies = [\n    \"scikit-learn\",\n    \"affinegap>=1.3\",\n    \"categorical-distance>=1.9\",\n    \"numpy>=1.20\",\n    \"doublemetaphone\",\n    \"highered>=0.2.0\",\n    \"simplecosine>=1.2\",\n    \"haversine>=0.4.1\",\n    \"BTrees>=4.1.4\",\n    \"zope.index\",\n    \"dedupe_Levenshtein_search\",\n]\n\n[project.urls]\nHomepage = \"https://github.com/dedupeio/dedupe\"\nIssues = \"https://github.com/dedupeio/dedupe/issues\"\nDocumentation = \"https://docs.dedupe.io/en/latest/\"\nExamples = \"https://github.com/dedupeio/dedupe-examples\"\nTwitter = \"https://twitter.com/DedupeIo\"\nChangelog = \"https://github.com/dedupeio/dedupe/blob/main/CHANGELOG.md\"\nMailingList = \"https://groups.google.com/forum/#!forum/open-source-deduplication\"\n\n\n[build-system]\nrequires = [\"setuptools\",\n            \"wheel\",\n            \"cython\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.setuptools]\npackages = [\"dedupe\", \"dedupe.variables\"]\n\n[tool.setuptools.package-data]\ndedupe = [\"py.typed\"]\n\n[tool.mypy]\nplugins = \"numpy.typing.mypy_plugin\"\nfiles = [\"dedupe\"]\nshow_error_codes = true\nignore_missing_imports = true\ncheck_untyped_defs = true\nimplicit_reexport = false\n\n[tool.pytest.ini_options]\nminversion = \"7.1\"\naddopts = \"--cov dedupe --cov-report xml\"\ntestpaths = [\"tests\", \"dedupe\"]\n\n[tool.isort]\nprofile = \"black\"\nsrc_paths = [\"dedupe\", \"tests\", \"benchmarks\"]\n\n[tool.coverage.run]\nomit = [\"dedupe/backport.py\"]\nsource = [\"dedupe\"]\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.095703125,
          "content": "asv\nblack\ncoverage[toml]\ncoveralls\nflake8\nmock\nmypy\npytest\npytest-cov\nvirtualenv\nisort\npre-commit\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.369140625,
          "content": "try:\n    from setuptools import Extension, setup\nexcept ImportError:\n    raise ImportError(\n        \"setuptools module required, please go to https://pypi.python.org/pypi/setuptools and follow the instructions for installing setuptools\"\n    )\n\nfrom Cython.Build import cythonize\n\nsetup(\n    ext_modules=cythonize([Extension(\"dedupe.cpredicates\", [\"dedupe/cpredicates.pyx\"])])\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}