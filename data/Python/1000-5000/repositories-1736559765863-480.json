{
  "metadata": {
    "timestamp": 1736559765863,
    "page": 480,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "goodfeli/adversarial",
      "stars": 3917,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.53125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbin/\nbuild/\ndevelop-eggs/\ndist/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n\n# Mr Developer\n.mr.developer.cfg\n.project\n.pydevproject\n\n# Rope\n.ropeproject\n\n# Django stuff:\n*.log\n*.pot\n\n# Sphinx documentation\ndocs/_build/\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4541015625,
          "content": "Copyright (c) 2014, Ian Goodfellow\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the {organization} nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 1.9794921875,
          "content": "Generative Adversarial Networks\n===============================\n\nThis repository contains the code and hyperparameters for the paper:\n\n\"Generative Adversarial Networks.\" Ian J. Goodfellow, Jean Pouget-Abadie,\nMehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville,\nYoshua Bengio. ArXiv 2014.\n\nPlease cite this paper if you use the code in this repository as part of\na published research project.\n\nWe are an academic lab, not a software company, and have no personnel\ndevoted to documenting and maintaing this research code.\nTherefore this code is offered with absolutely no support.\nExact reproduction of the numbers in the paper depends on exact\nreproduction of many factors,\nincluding the version of all software dependencies and the choice of\nunderlying hardware (GPU model, etc). We used NVIDA Ge-Force GTX-580\ngraphics cards; other hardware will use different tree structures for\nsummation and incur different rounding error. If you do not reproduce our\nsetup exactly you should expect to need to re-tune your hyperparameters\nslight for your new setup.\n\nMoreover, we have not integrated any unit tests for this code into Theano\nor Pylearn2 so subsequent changes to those libraries may break the code\nin this repository. If you encounter problems with this code, you should\nmake sure that you are using the development branch of Pylearn2 and Theano,\nand use \"git checkout\" to go to a commit from approximately June 9, 2014.\n\nThis code itself requires no installation besides making sure that the\n\"adversarial\" directory is in a directory in your PYTHONPATH. If\ninstalled correctly, 'python -c \"import adversarial\"' will work. You\nmust also install Pylearn2 and Pylearn2's dependencies (Theano, numpy,\netc.)\n\nparzen_ll.py is the script used to estimate the log likelihood of the\nmodel using the Parzen density technique.\n\nCall pylearn2/scripts/train.py on the various yaml files in this repository\nto train the model for each dataset reported in the paper. The names of\n*.yaml are fairly self-explanatory.\n"
        },
        {
          "name": "__init__.py",
          "type": "blob",
          "size": 49.005859375,
          "content": "\"\"\"\nCode for \"Generative Adversarial Networks\". Please cite the ArXiv paper in\nany published research work making use of this code.\n\"\"\"\nimport functools\nwraps = functools.wraps\nimport itertools\nimport numpy\nnp = numpy\nimport theano\nimport warnings\n\nfrom theano.compat import OrderedDict\nfrom theano.sandbox.rng_mrg import MRG_RandomStreams\nfrom theano import tensor as T\n\nfrom pylearn2.space import VectorSpace\nfrom pylearn2.costs.cost import Cost\nfrom pylearn2.costs.cost import DefaultDataSpecsMixin\nfrom pylearn2.models.mlp import Layer\nfrom pylearn2.models.mlp import Linear\nfrom pylearn2.models import Model\nfrom pylearn2.space import CompositeSpace\nfrom pylearn2.train_extensions import TrainExtension\nfrom pylearn2.utils import block_gradient\nfrom pylearn2.utils import safe_zip\nfrom pylearn2.utils import serial\nfrom pylearn2.utils import sharedX\n\nclass AdversaryPair(Model):\n\n    def __init__(self, generator, discriminator, inferer=None,\n                 inference_monitoring_batch_size=128,\n                 monitor_generator=True,\n                 monitor_discriminator=True,\n                 monitor_inference=True,\n                 shrink_d = 0.):\n        Model.__init__(self)\n        self.__dict__.update(locals())\n        del self.self\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        if 'inferer' not in state:\n            self.inferer = None\n        if 'inference_monitoring_batch_size' not in state:\n            self.inference_monitoring_batch_size = 128  # TODO: HACK\n        if 'monitor_generator' not in state:\n            self.monitor_generator = True\n        if 'monitor_discriminator' not in state:\n            self.monitor_discriminator = True\n        if 'monitor_inference' not in state:\n            self.monitor_inference = True\n\n    def get_params(self):\n        p = self.generator.get_params() + self.discriminator.get_params()\n        if hasattr(self, 'inferer') and self.inferer is not None:\n            p += self.inferer.get_params()\n        return p\n\n    def get_input_space(self):\n        return self.discriminator.get_input_space()\n\n    def get_weights_topo(self):\n        return self.discriminator.get_weights_topo()\n\n    def get_weights(self):\n        return self.discriminator.get_weights()\n\n    def get_weights_format(self):\n        return self.discriminator.get_weights_format()\n\n    def get_weights_view_shape(self):\n        return self.discriminator.get_weights_view_shape()\n\n    def get_monitoring_channels(self, data):\n        rval = OrderedDict()\n\n        g_ch = self.generator.get_monitoring_channels(data)\n        d_ch = self.discriminator.get_monitoring_channels((data, None))\n        samples = self.generator.sample(100)\n        d_samp_ch = self.discriminator.get_monitoring_channels((samples, None))\n\n        i_ch = OrderedDict()\n        if self.inferer is not None:\n            batch_size = self.inference_monitoring_batch_size\n            sample, noise, _ = self.generator.sample_and_noise(batch_size)\n            i_ch.update(self.inferer.get_monitoring_channels((sample, noise)))\n\n        if self.monitor_generator:\n            for key in g_ch:\n                rval['gen_' + key] = g_ch[key]\n        if self.monitor_discriminator:\n            for key in d_ch:\n                rval['dis_on_data_' + key] = d_samp_ch[key]\n            for key in d_ch:\n                rval['dis_on_samp_' + key] = d_ch[key]\n        if self.monitor_inference:\n            for key in i_ch:\n                rval['inf_' + key] = i_ch[key]\n        return rval\n\n    def get_monitoring_data_specs(self):\n\n        space = self.discriminator.get_input_space()\n        source = self.discriminator.get_input_source()\n        return (space, source)\n\n    def _modify_updates(self, updates):\n        self.generator.modify_updates(updates)\n        self.discriminator.modify_updates(updates)\n        if self.shrink_d != 0.:\n            for param in self.discriminator.get_params():\n                if param in updates:\n                    updates[param] = self.shrink_d * updates[param]\n        if self.inferer is not None:\n            self.inferer.modify_updates(updates)\n\n    def get_lr_scalers(self):\n\n        rval = self.generator.get_lr_scalers()\n        rval.update(self.discriminator.get_lr_scalers())\n        return rval\n\ndef add_layers(mlp, pretrained, start_layer=0):\n    model = serial.load(pretrained)\n    pretrained_layers = model.generator.mlp.layers\n    assert pretrained_layers[start_layer].get_input_space() == mlp.layers[-1].get_output_space()\n    mlp.layers.extend(pretrained_layers[start_layer:])\n    return mlp\n\n\n\nclass Generator(Model):\n\n    def __init__(self, mlp, noise = \"gaussian\", monitor_ll = False, ll_n_samples = 100, ll_sigma = 0.2):\n        Model.__init__(self)\n        self.__dict__.update(locals())\n        del self.self\n        self.theano_rng = MRG_RandomStreams(2014 * 5 + 27)\n\n    def get_input_space(self):\n        return self.mlp.get_input_space()\n\n    def sample_and_noise(self, num_samples, default_input_include_prob=1., default_input_scale=1., all_g_layers=False):\n        n = self.mlp.get_input_space().get_total_dimension()\n        noise = self.get_noise((num_samples, n))\n        formatted_noise = VectorSpace(n).format_as(noise, self.mlp.get_input_space())\n        if all_g_layers:\n            rval = self.mlp.dropout_fprop(formatted_noise, default_input_include_prob=default_input_include_prob, default_input_scale=default_input_scale, return_all=all_g_layers)\n            other_layers, rval = rval[:-1], rval[-1]\n        else:\n            rval = self.mlp.dropout_fprop(formatted_noise, default_input_include_prob=default_input_include_prob, default_input_scale=default_input_scale)\n            other_layers = None\n        return rval, formatted_noise, other_layers\n\n    def sample(self, num_samples, default_input_include_prob=1., default_input_scale=1.):\n        sample, _, _ = self.sample_and_noise(num_samples, default_input_include_prob, default_input_scale)\n        return sample\n\n    def inpainting_sample_and_noise(self, X, default_input_include_prob=1., default_input_scale=1.):\n        # Very hacky! Specifically for inpainting right half of CIFAR-10 given left half\n        # assumes X is b01c\n        assert X.ndim == 4\n        input_space = self.mlp.get_input_space()\n        n = input_space.get_total_dimension()\n        image_size = input_space.shape[0]\n        half_image = int(image_size / 2)\n        data_shape = (X.shape[0], image_size, half_image, input_space.num_channels)\n\n        noise = self.theano_rng.normal(size=data_shape, dtype='float32')\n        Xg = T.set_subtensor(X[:,:,half_image:,:], noise)\n        sampled_part, noise =  self.mlp.dropout_fprop(Xg, default_input_include_prob=default_input_include_prob, default_input_scale=default_input_scale), noise\n        sampled_part = sampled_part.reshape(data_shape)\n        rval = T.set_subtensor(X[:, :, half_image:, :], sampled_part)\n        return rval, noise\n\n\n    def get_monitoring_channels(self, data):\n        if data is None:\n            m = 100\n        else:\n            m = data.shape[0]\n        n = self.mlp.get_input_space().get_total_dimension()\n        noise = self.get_noise((m, n))\n        rval = OrderedDict()\n\n        try:\n            rval.update(self.mlp.get_monitoring_channels((noise, None)))\n        except Exception:\n            warnings.warn(\"something went wrong with generator.mlp's monitoring channels\")\n\n        if  self.monitor_ll:\n            rval['ll'] = T.cast(self.ll(data, self.ll_n_samples, self.ll_sigma),\n                                        theano.config.floatX).mean()\n            rval['nll'] = -rval['ll']\n        return rval\n\n    def get_noise(self, size):\n\n        # Allow just requesting batch size\n        if isinstance(size, int):\n            size = (size, self.get_input_space().get_total_dimension())\n\n        if not hasattr(self, 'noise'):\n            self.noise = \"gaussian\"\n        if self.noise == \"uniform\":\n            return self.theano_rng.uniform(low=-np.sqrt(3), high=np.sqrt(3), size=size, dtype='float32')\n        elif self.noise == \"gaussian\":\n            return self.theano_rng.normal(size=size, dtype='float32')\n        elif self.noise == \"spherical\":\n            noise = self.theano_rng.normal(size=size, dtype='float32')\n            noise = noise / T.maximum(1e-7, T.sqrt(T.sqr(noise).sum(axis=1))).dimshuffle(0, 'x')\n            return noise\n        else:\n            raise NotImplementedError(self.noise)\n\n    def get_params(self):\n        return self.mlp.get_params()\n\n    def get_output_space(self):\n        return self.mlp.get_output_space()\n\n    def ll(self, data, n_samples, sigma):\n\n        samples = self.sample(n_samples)\n        output_space = self.mlp.get_output_space()\n        if 'Conv2D' in str(output_space):\n            samples = output_space.convert(samples, output_space.axes, ('b', 0, 1, 'c'))\n            samples = samples.flatten(2)\n            data = output_space.convert(data, output_space.axes, ('b', 0, 1, 'c'))\n            data = data.flatten(2)\n        parzen = theano_parzen(data, samples, sigma)\n        return parzen\n\n    def _modify_updates(self, updates):\n        self.mlp.modify_updates(updates)\n\n    def get_lr_scalers(self):\n        return self.mlp.get_lr_scalers()\n\n    def __setstate__(self, state):\n        self.__dict__.update(state)\n        if 'monitor_ll' not in state:\n            self.monitor_ll = False\n\n\nclass IntrinsicDropoutGenerator(Generator):\n    def __init__(self, default_input_include_prob, default_input_scale,\n                        input_include_probs=None, input_scales=None, **kwargs):\n        super(IntrinsicDropoutGenerator, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        del self.self\n\n    def sample_and_noise(self, num_samples, default_input_include_prob=1., default_input_scale=1., all_g_layers=False):\n        if all_g_layers:\n            raise NotImplementedError()\n        n = self.mlp.get_input_space().get_total_dimension()\n        noise = self.theano_rng.normal(size=(num_samples, n), dtype='float32')\n        formatted_noise = VectorSpace(n).format_as(noise, self.mlp.get_input_space())\n        # ignores dropout args\n        default_input_include_prob = self.default_input_include_prob\n        default_input_scale = self.default_input_scale\n        input_include_probs = self.input_include_probs\n        input_scales = self.input_scales\n        return self.mlp.dropout_fprop(formatted_noise,\n                                      default_input_include_prob=default_input_include_prob,\n                                      default_input_scale=default_input_scale,\n                                      input_include_probs=input_include_probs,\n                                      input_scales=input_scales), formatted_noise, None\n\nclass AdversaryCost2(DefaultDataSpecsMixin, Cost):\n    \"\"\"\n    \"\"\"\n\n    # Supplies own labels, don't get them from the dataset\n    supervised = False\n\n    def __init__(self, scale_grads=1, target_scale=.1,\n            discriminator_default_input_include_prob = 1.,\n            discriminator_input_include_probs=None,\n            discriminator_default_input_scale=1.,\n            discriminator_input_scales=None,\n            generator_default_input_include_prob = 1.,\n            generator_default_input_scale=1.,\n            inference_default_input_include_prob=None,\n            inference_input_include_probs=None,\n            inference_default_input_scale=1.,\n            inference_input_scales=None,\n            init_now_train_generator=True,\n            ever_train_discriminator=True,\n            ever_train_generator=True,\n            ever_train_inference=True,\n            no_drop_in_d_for_g=False,\n            alternate_g = False,\n            infer_layer=None,\n            noise_both = 0.,\n            blend_obj = False,\n            minimax_coeff = 1.,\n            zurich_coeff = 1.):\n        self.__dict__.update(locals())\n        del self.self\n        # These allow you to dynamically switch off training parts.\n        # If the corresponding ever_train_* is False, these have\n        # no effect.\n        self.now_train_generator = sharedX(init_now_train_generator)\n        self.now_train_discriminator = sharedX(numpy.array(1., dtype='float32'))\n        self.now_train_inference = sharedX(numpy.array(1., dtype='float32'))\n\n    def expr(self, model, data, **kwargs):\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        l = []\n        # This stops stuff from ever getting computed if we're not training\n        # it.\n        if self.ever_train_discriminator:\n            l.append(d_obj)\n        if self.ever_train_generator:\n            l.append(g_obj)\n        if self.ever_train_inference:\n            l.append(i_obj)\n        return sum(l)\n\n    def get_samples_and_objectives(self, model, data):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        # Note: this assumes data is design matrix\n        X = data\n        m = data.shape[space.get_batch_axis()]\n        y1 = T.alloc(1, m, 1)\n        y0 = T.alloc(0, m, 1)\n        # NOTE: if this changes to optionally use dropout, change the inference\n        # code below to use a non-dropped-out version.\n        S, z, other_layers = g.sample_and_noise(m, default_input_include_prob=self.generator_default_input_include_prob, default_input_scale=self.generator_default_input_scale, all_g_layers=(self.infer_layer is not None))\n\n        if self.noise_both != 0.:\n            rng = MRG_RandomStreams(2014 / 6 + 2)\n            S = S + rng.normal(size=S.shape, dtype=S.dtype) * self.noise_both\n            X = X + rng.normal(size=X.shape, dtype=S.dtype) * self.noise_both\n\n        y_hat1 = d.dropout_fprop(X, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n        y_hat0 = d.dropout_fprop(S, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n\n        d_obj =  0.5 * (d.layers[-1].cost(y1, y_hat1) + d.layers[-1].cost(y0, y_hat0))\n\n        if self.no_drop_in_d_for_g:\n            y_hat0_no_drop = d.dropout_fprop(S)\n            g_obj = d.layers[-1].cost(y1, y_hat0_no_drop)\n        else:\n            g_obj = d.layers[-1].cost(y1, y_hat0)\n\n        if self.blend_obj:\n            g_obj = (self.zurich_coeff * g_obj - self.minimax_coeff * d_obj) / (self.zurich_coeff + self.minimax_coeff)\n\n        if model.inferer is not None:\n            # Change this if we ever switch to using dropout in the\n            # construction of S.\n            S_nograd = block_gradient(S)  # Redundant as long as we have custom get_gradients\n            pred = model.inferer.dropout_fprop(S_nograd, self.inference_default_input_include_prob,\n                                                self.inference_input_include_probs,\n                                                self.inference_default_input_scale,\n                                                self.inference_input_scales)\n            if self.infer_layer is None:\n                target = z\n            else:\n                target = other_layers[self.infer_layer]\n            i_obj = model.inferer.layers[-1].cost(target, pred)\n        else:\n            i_obj = 0\n\n        return S, d_obj, g_obj, i_obj\n\n    def get_gradients(self, model, data, **kwargs):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n\n        g_params = g.get_params()\n        d_params = d.get_params()\n        for param in g_params:\n            assert param not in d_params\n        for param in d_params:\n            assert param not in g_params\n        d_grads = T.grad(d_obj, d_params)\n        g_grads = T.grad(g_obj, g_params)\n\n        if self.scale_grads:\n            S_grad = T.grad(g_obj, S)\n            scale = T.maximum(1., self.target_scale / T.sqrt(T.sqr(S_grad).sum()))\n            g_grads = [g_grad * scale for g_grad in g_grads]\n\n        rval = OrderedDict()\n        zeros = itertools.repeat(theano.tensor.constant(0., dtype='float32'))\n        if self.ever_train_discriminator:\n            rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\n        else:\n            rval.update(OrderedDict(zip(d_params, zeros)))\n        if self.ever_train_generator:\n            rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n        else:\n            rval.update(OrderedDict(zip(g_params, zeros)))\n        if self.ever_train_inference and model.inferer is not None:\n            i_params = model.inferer.get_params()\n            i_grads = T.grad(i_obj, i_params)\n            rval.update(OrderedDict(safe_zip(i_params, [self.now_train_inference * ig for ig in i_grads])))\n        elif model.inferer is not None:\n            rval.update(OrderedDict(model.inferer.get_params(), zeros))\n\n        updates = OrderedDict()\n\n        # Two d steps for every g step\n        if self.alternate_g:\n            updates[self.now_train_generator] = 1. - self.now_train_generator\n\n        return rval, updates\n\n    def get_monitoring_channels(self, model, data, **kwargs):\n\n        rval = OrderedDict()\n\n        m = data.shape[0]\n\n        g = model.generator\n        d = model.discriminator\n\n        y_hat = d.fprop(data)\n\n        rval['false_negatives'] = T.cast((y_hat < 0.5).mean(), 'float32')\n\n        samples = g.sample(m)\n        y_hat = d.fprop(samples)\n        rval['false_positives'] = T.cast((y_hat > 0.5).mean(), 'float32')\n        # y = T.alloc(0., m, 1)\n        cost = d.cost_from_X((samples, y_hat))\n        sample_grad = T.grad(-cost, samples)\n        rval['sample_grad_norm'] = T.sqrt(T.sqr(sample_grad).sum())\n        _S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        if model.monitor_inference and i_obj != 0:\n            rval['objective_i'] = i_obj\n        if model.monitor_discriminator:\n            rval['objective_d'] = d_obj\n        if model.monitor_generator:\n            rval['objective_g'] = g_obj\n\n        rval['now_train_generator'] = self.now_train_generator\n        return rval\n\ndef recapitate_discriminator(pair_path, new_head):\n    pair = serial.load(pair_path)\n    d = pair.discriminator\n    del d.layers[-1]\n    d.add_layers([new_head])\n    return d\n\ndef theano_parzen(data, mu, sigma):\n    \"\"\"\n    Credit: Yann N. Dauphin\n    \"\"\"\n    x = data\n\n    a = ( x.dimshuffle(0, 'x', 1) - mu.dimshuffle('x', 0, 1) ) / sigma\n\n    E = log_mean_exp(-0.5*(a**2).sum(2))\n\n    Z = mu.shape[1] * T.log(sigma * numpy.sqrt(numpy.pi * 2))\n\n    #return theano.function([x], E - Z)\n    return E - Z\n\n\ndef log_mean_exp(a):\n    \"\"\"\n    Credit: Yann N. Dauphin\n    \"\"\"\n\n    max_ = a.max(1)\n\n    return max_ + T.log(T.exp(a - max_.dimshuffle(0, 'x')).mean(1))\n\nclass Sum(Layer):\n    \"\"\"\n    Monitoring channels are hardcoded for C01B batches\n    \"\"\"\n\n    def __init__(self, layer_name):\n        Model.__init__(self)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        self.input_space = space\n        assert isinstance(space, CompositeSpace)\n        self.output_space = space.components[0]\n\n    def fprop(self, state_below):\n        rval = state_below[0]\n        for i in xrange(1, len(state_below)):\n            rval = rval + state_below[i]\n        rval.came_from_sum = True\n        return rval\n\n    @functools.wraps(Layer.get_layer_monitoring_channels)\n    def get_layer_monitoring_channels(self, state_below=None,\n                                    state=None, targets=None):\n        rval = OrderedDict()\n\n        if state is None:\n                state = self.fprop(state_below)\n        vars_and_prefixes = [(state, '')]\n\n        for var, prefix in vars_and_prefixes:\n            if not hasattr(var, 'ndim') or var.ndim != 4:\n                print \"expected 4D tensor, got \"\n                print var\n                print type(var)\n                if isinstance(var, tuple):\n                    print \"tuple length: \", len(var)\n                assert False\n            v_max = var.max(axis=(1, 2, 3))\n            v_min = var.min(axis=(1, 2, 3))\n            v_mean = var.mean(axis=(1, 2, 3))\n            v_range = v_max - v_min\n\n            # max_x.mean_u is \"the mean over *u*nits of the max over\n            # e*x*amples\" The x and u are included in the name because\n            # otherwise its hard to remember which axis is which when reading\n            # the monitor I use inner.outer rather than outer_of_inner or\n            # something like that because I want mean_x.* to appear next to\n            # each other in the alphabetical list, as these are commonly\n            # plotted together\n            for key, val in [('max_x.max_u',    v_max.max()),\n                             ('max_x.mean_u',   v_max.mean()),\n                             ('max_x.min_u',    v_max.min()),\n                             ('min_x.max_u',    v_min.max()),\n                             ('min_x.mean_u',   v_min.mean()),\n                             ('min_x.min_u',    v_min.min()),\n                             ('range_x.max_u',  v_range.max()),\n                             ('range_x.mean_u', v_range.mean()),\n                             ('range_x.min_u',  v_range.min()),\n                             ('mean_x.max_u',   v_mean.max()),\n                             ('mean_x.mean_u',  v_mean.mean()),\n                             ('mean_x.min_u',   v_mean.min())]:\n                rval[prefix+key] = val\n\n        return rval\n\ndef marginals(dataset):\n    return dataset.X.mean(axis=0)\n\nclass ActivateGenerator(TrainExtension):\n    def __init__(self, active_after, value=1.):\n        self.__dict__.update(locals())\n        del self.self\n        self.cur_epoch = 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        if self.cur_epoch == self.active_after:\n            algorithm.cost.now_train_generator.set_value(np.array(self.value, dtype='float32'))\n        self.cur_epoch += 1\n\nclass InpaintingAdversaryCost(DefaultDataSpecsMixin, Cost):\n    \"\"\"\n    \"\"\"\n\n    # Supplies own labels, don't get them from the dataset\n    supervised = False\n\n    def __init__(self, scale_grads=1, target_scale=.1,\n            discriminator_default_input_include_prob = 1.,\n            discriminator_input_include_probs=None,\n            discriminator_default_input_scale=1.,\n            discriminator_input_scales=None,\n            generator_default_input_include_prob = 1.,\n            generator_default_input_scale=1.,\n            inference_default_input_include_prob=None,\n            inference_input_include_probs=None,\n            inference_default_input_scale=1.,\n            inference_input_scales=None,\n            init_now_train_generator=True,\n            ever_train_discriminator=True,\n            ever_train_generator=True,\n            ever_train_inference=True,\n            no_drop_in_d_for_g=False,\n            alternate_g = False):\n        self.__dict__.update(locals())\n        del self.self\n        # These allow you to dynamically switch off training parts.\n        # If the corresponding ever_train_* is False, these have\n        # no effect.\n        self.now_train_generator = sharedX(init_now_train_generator)\n        self.now_train_discriminator = sharedX(numpy.array(1., dtype='float32'))\n        self.now_train_inference = sharedX(numpy.array(1., dtype='float32'))\n\n    def expr(self, model, data, **kwargs):\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        return d_obj + g_obj + i_obj\n\n    def get_samples_and_objectives(self, model, data):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        # Note: this assumes data is b01c\n        X = data\n        assert X.ndim == 4\n        m = data.shape[space.get_batch_axis()]\n        y1 = T.alloc(1, m, 1)\n        y0 = T.alloc(0, m, 1)\n        # NOTE: if this changes to optionally use dropout, change the inference\n        # code below to use a non-dropped-out version.\n        S, z = g.inpainting_sample_and_noise(X, default_input_include_prob=self.generator_default_input_include_prob, default_input_scale=self.generator_default_input_scale)\n        y_hat1 = d.dropout_fprop(X, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n        y_hat0 = d.dropout_fprop(S, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n\n        d_obj =  0.5 * (d.layers[-1].cost(y1, y_hat1) + d.layers[-1].cost(y0, y_hat0))\n\n        if self.no_drop_in_d_for_g:\n            y_hat0_no_drop = d.dropout_fprop(S)\n            g_obj = d.layers[-1].cost(y1, y_hat0)\n        else:\n            g_obj = d.layers[-1].cost(y1, y_hat0)\n\n        if model.inferer is not None:\n            # Change this if we ever switch to using dropout in the\n            # construction of S.\n            S_nograd = block_gradient(S)  # Redundant as long as we have custom get_gradients\n            z_hat = model.inferer.dropout_fprop(S_nograd, self.inference_default_input_include_prob,\n                                                self.inference_input_include_probs,\n                                                self.inference_default_input_scale,\n                                                self.inference_input_scales)\n            i_obj = model.inferer.layers[-1].cost(z, z_hat)\n        else:\n            i_obj = 0\n\n        return S, d_obj, g_obj, i_obj\n\n    def get_gradients(self, model, data, **kwargs):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n\n        g_params = g.get_params()\n        d_params = d.get_params()\n        for param in g_params:\n            assert param not in d_params\n        for param in d_params:\n            assert param not in g_params\n        d_grads = T.grad(d_obj, d_params)\n        g_grads = T.grad(g_obj, g_params)\n\n        if self.scale_grads:\n            S_grad = T.grad(g_obj, S)\n            scale = T.maximum(1., self.target_scale / T.sqrt(T.sqr(S_grad).sum()))\n            g_grads = [g_grad * scale for g_grad in g_grads]\n\n        rval = OrderedDict()\n        if self.ever_train_discriminator:\n            rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\n        else:\n            rval.update(OrderedDict(zip(d_params, itertools.repeat(theano.tensor.constant(0., dtype='float32')))))\n\n        if self.ever_train_generator:\n            rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n        else:\n            rval.update(OrderedDict(zip(g_params, itertools.repeat(theano.tensor.constant(0., dtype='float32')))))\n\n        if self.ever_train_inference and model.inferer is not None:\n            i_params = model.inferer.get_params()\n            i_grads = T.grad(i_obj, i_params)\n            rval.update(OrderedDict(safe_zip(i_params, [self.now_train_inference * ig for ig in i_grads])))\n\n        updates = OrderedDict()\n\n        # Two d steps for every g step\n        if self.alternate_g:\n            updates[self.now_train_generator] = 1. - self.now_train_generator\n\n        return rval, updates\n\n    def get_monitoring_channels(self, model, data, **kwargs):\n\n        rval = OrderedDict()\n\n        m = data.shape[0]\n\n        g = model.generator\n        d = model.discriminator\n\n        y_hat = d.fprop(data)\n\n        rval['false_negatives'] = T.cast((y_hat < 0.5).mean(), 'float32')\n\n        samples, noise = g.inpainting_sample_and_noise(data)\n        y_hat = d.fprop(samples)\n        rval['false_positives'] = T.cast((y_hat > 0.5).mean(), 'float32')\n        # y = T.alloc(0., m, 1)\n        cost = d.cost_from_X((samples, y_hat))\n        sample_grad = T.grad(-cost, samples)\n        rval['sample_grad_norm'] = T.sqrt(T.sqr(sample_grad).sum())\n        _S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        if i_obj != 0:\n            rval['objective_i'] = i_obj\n        rval['objective_d'] = d_obj\n        rval['objective_g'] = g_obj\n\n        rval['now_train_generator'] = self.now_train_generator\n        return rval\n\nclass Cycler(object):\n\n    def __init__(self, k):\n        self.__dict__.update(locals())\n        del self.self\n        self.i = 0\n\n    def __call__(self, sgd):\n        self.i = (self.i + 1) % self.k\n        sgd.cost.now_train_generator.set_value(np.cast['float32'](self.i == 0))\n\nclass NoiseCat(Layer):\n\n    def __init__(self, new_dim, std, layer_name):\n        Layer.__init__(self)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        assert isinstance(space, VectorSpace)\n        self.input_space = space\n        self.output_space = VectorSpace(space.dim + self.new_dim)\n        self.theano_rng = MRG_RandomStreams(self.mlp.rng.randint(2 ** 16))\n\n    def fprop(self, state):\n        noise = self.theano_rng.normal(std=self.std, avg=0., size=(state.shape[0], self.new_dim),\n                dtype=state.dtype)\n        return T.concatenate((state, noise), axis=1)\n\nclass RectifiedLinear(Layer):\n\n    def __init__(self, layer_name, left_slope=0.0, **kwargs):\n        super(RectifiedLinear, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        self.input_space = space\n        self.output_space = space\n\n    def fprop(self, state_below):\n        p = state_below\n        p = T.switch(p > 0., p, self.left_slope * p)\n        return p\n\nclass Sigmoid(Layer):\n\n    def __init__(self, layer_name, left_slope=0.0, **kwargs):\n        super(Sigmoid, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        self.input_space = space\n        self.output_space = space\n\n    def fprop(self, state_below):\n        p = T.nnet.sigmoid(state_below)\n        return p\n\nclass SubtractHalf(Layer):\n\n    def __init__(self, layer_name, left_slope=0.0, **kwargs):\n        super(SubtractHalf, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        self.input_space = space\n        self.output_space = space\n\n    def fprop(self, state_below):\n        return state_below - 0.5\n\n    def get_weights(self):\n        return self.mlp.layers[1].get_weights()\n\n    def get_weights_format(self):\n        return self.mlp.layers[1].get_weights_format()\n\n    def get_weights_view_shape(self):\n        return self.mlp.layers[1].get_weights_view_shape()\n\nclass SubtractRealMean(Layer):\n\n    def __init__(self, layer_name, dataset, also_sd = False, **kwargs):\n        super(SubtractRealMean, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n        self.mean = sharedX(dataset.X.mean(axis=0))\n        if also_sd:\n            self.sd = sharedX(dataset.X.std(axis=0))\n        del self.dataset\n\n    def set_input_space(self, space):\n        self.input_space = space\n        self.output_space = space\n\n    def fprop(self, state_below):\n        return (state_below - self.mean) / self.sd\n\n    def get_weights(self):\n        return self.mlp.layers[1].get_weights()\n\n    def get_weights_format(self):\n        return self.mlp.layers[1].get_weights_format()\n\n    def get_weights_view_shape(self):\n        return self.mlp.layers[1].get_weights_view_shape()\n\n\nclass Clusterize(Layer):\n\n    def __init__(self, scale, layer_name):\n        Layer.__init__(self)\n        self.__dict__.update(locals())\n        del self.self\n        self._params = []\n\n    def set_input_space(self, space):\n        assert isinstance(space, VectorSpace)\n        self.input_space = space\n        self.output_space = space\n        self.theano_rng = MRG_RandomStreams(self.mlp.rng.randint(2 ** 16))\n\n    def fprop(self, state):\n        noise = self.theano_rng.binomial(size=state.shape, p=0.5,\n                dtype=state.dtype) * 2. - 1.\n        return state + self.scale * noise\n\n\n\nclass ThresholdedAdversaryCost(DefaultDataSpecsMixin, Cost):\n    \"\"\"\n    \"\"\"\n\n    # Supplies own labels, don't get them from the dataset\n    supervised = False\n\n    def __init__(self, scale_grads=1, target_scale=.1,\n            discriminator_default_input_include_prob = 1.,\n            discriminator_input_include_probs=None,\n            discriminator_default_input_scale=1.,\n            discriminator_input_scales=None,\n            generator_default_input_include_prob = 1.,\n            generator_default_input_scale=1.,\n            inference_default_input_include_prob=None,\n            inference_input_include_probs=None,\n            inference_default_input_scale=1.,\n            inference_input_scales=None,\n            init_now_train_generator=True,\n            ever_train_discriminator=True,\n            ever_train_generator=True,\n            ever_train_inference=True,\n            no_drop_in_d_for_g=False,\n            alternate_g = False,\n            infer_layer=None,\n            noise_both = 0.):\n        self.__dict__.update(locals())\n        del self.self\n        # These allow you to dynamically switch off training parts.\n        # If the corresponding ever_train_* is False, these have\n        # no effect.\n        self.now_train_generator = sharedX(init_now_train_generator)\n        self.now_train_discriminator = sharedX(numpy.array(1., dtype='float32'))\n        self.now_train_inference = sharedX(numpy.array(1., dtype='float32'))\n\n    def expr(self, model, data, **kwargs):\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        l = []\n        # This stops stuff from ever getting computed if we're not training\n        # it.\n        if self.ever_train_discriminator:\n            l.append(d_obj)\n        if self.ever_train_generator:\n            l.append(g_obj)\n        if self.ever_train_inference:\n            l.append(i_obj)\n        return sum(l)\n\n    def get_samples_and_objectives(self, model, data):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        # Note: this assumes data is design matrix\n        X = data\n        m = data.shape[space.get_batch_axis()]\n        y1 = T.alloc(1, m, 1)\n        y0 = T.alloc(0, m, 1)\n        # NOTE: if this changes to optionally use dropout, change the inference\n        # code below to use a non-dropped-out version.\n        S, z, other_layers = g.sample_and_noise(m, default_input_include_prob=self.generator_default_input_include_prob, default_input_scale=self.generator_default_input_scale, all_g_layers=(self.infer_layer is not None))\n\n        if self.noise_both != 0.:\n            rng = MRG_RandomStreams(2014 / 6 + 2)\n            S = S + rng.normal(size=S.shape, dtype=S.dtype) * self.noise_both\n            X = X + rng.normal(size=X.shape, dtype=S.dtype) * self.noise_both\n\n        y_hat1 = d.dropout_fprop(X, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n        y_hat0 = d.dropout_fprop(S, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n\n        d_obj =  0.5 * (d.layers[-1].cost(y1, y_hat1) + d.layers[-1].cost(y0, y_hat0))\n\n        if self.no_drop_in_d_for_g:\n            y_hat0_no_drop = d.dropout_fprop(S)\n            g_cost_mat = d.layers[-1].cost_matrix(y1, y_hat0_no_drop)\n        else:\n            g_cost_mat = d.layers[-1].cost_matrix(y1, y_hat0)\n        assert g_cost_mat.ndim == 2\n        assert y_hat0.ndim == 2\n\n        mask = y_hat0 < 0.5\n        masked_cost = g_cost_mat * mask\n        g_obj = masked_cost.mean()\n\n\n        if model.inferer is not None:\n            # Change this if we ever switch to using dropout in the\n            # construction of S.\n            S_nograd = block_gradient(S)  # Redundant as long as we have custom get_gradients\n            pred = model.inferer.dropout_fprop(S_nograd, self.inference_default_input_include_prob,\n                                                self.inference_input_include_probs,\n                                                self.inference_default_input_scale,\n                                                self.inference_input_scales)\n            if self.infer_layer is None:\n                target = z\n            else:\n                target = other_layers[self.infer_layer]\n            i_obj = model.inferer.layers[-1].cost(target, pred)\n        else:\n            i_obj = 0\n\n        return S, d_obj, g_obj, i_obj\n\n    def get_gradients(self, model, data, **kwargs):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n\n        g_params = g.get_params()\n        d_params = d.get_params()\n        for param in g_params:\n            assert param not in d_params\n        for param in d_params:\n            assert param not in g_params\n        d_grads = T.grad(d_obj, d_params)\n        g_grads = T.grad(g_obj, g_params)\n\n        if self.scale_grads:\n            S_grad = T.grad(g_obj, S)\n            scale = T.maximum(1., self.target_scale / T.sqrt(T.sqr(S_grad).sum()))\n            g_grads = [g_grad * scale for g_grad in g_grads]\n\n        rval = OrderedDict()\n        zeros = itertools.repeat(theano.tensor.constant(0., dtype='float32'))\n        if self.ever_train_discriminator:\n            rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\n        else:\n            rval.update(OrderedDict(zip(d_params, zeros)))\n        if self.ever_train_generator:\n            rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n        else:\n            rval.update(OrderedDict(zip(g_params, zeros)))\n        if self.ever_train_inference and model.inferer is not None:\n            i_params = model.inferer.get_params()\n            i_grads = T.grad(i_obj, i_params)\n            rval.update(OrderedDict(safe_zip(i_params, [self.now_train_inference * ig for ig in i_grads])))\n        elif model.inferer is not None:\n            rval.update(OrderedDict(model.inferer.get_params(), zeros))\n\n        updates = OrderedDict()\n\n        # Two d steps for every g step\n        if self.alternate_g:\n            updates[self.now_train_generator] = 1. - self.now_train_generator\n\n        return rval, updates\n\n    def get_monitoring_channels(self, model, data, **kwargs):\n\n        rval = OrderedDict()\n\n        m = data.shape[0]\n\n        g = model.generator\n        d = model.discriminator\n\n        y_hat = d.fprop(data)\n\n        rval['false_negatives'] = T.cast((y_hat < 0.5).mean(), 'float32')\n\n        samples = g.sample(m)\n        y_hat = d.fprop(samples)\n        rval['false_positives'] = T.cast((y_hat > 0.5).mean(), 'float32')\n        # y = T.alloc(0., m, 1)\n        cost = d.cost_from_X((samples, y_hat))\n        sample_grad = T.grad(-cost, samples)\n        rval['sample_grad_norm'] = T.sqrt(T.sqr(sample_grad).sum())\n        _S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        if model.monitor_inference and i_obj != 0:\n            rval['objective_i'] = i_obj\n        if model.monitor_discriminator:\n            rval['objective_d'] = d_obj\n        if model.monitor_generator:\n            rval['objective_g'] = g_obj\n\n        rval['now_train_generator'] = self.now_train_generator\n        return rval\n\n\nclass HardSigmoid(Linear):\n    \"\"\"\n    Hard \"sigmoid\" (note: shifted along the x axis)\n    \"\"\"\n\n    def __init__(self, left_slope=0.0, **kwargs):\n        super(HardSigmoid, self).__init__(**kwargs)\n        self.left_slope = left_slope\n\n    @wraps(Layer.fprop)\n    def fprop(self, state_below):\n\n        p = self._linear_part(state_below)\n        # Original: p = p * (p > 0.) + self.left_slope * p * (p < 0.)\n        # T.switch is faster.\n        # For details, see benchmarks in\n        # pylearn2/scripts/benchmark/time_relu.py\n        p = T.clip(p, 0., 1.)\n        return p\n\n    @wraps(Layer.cost)\n    def cost(self, *args, **kwargs):\n\n        raise NotImplementedError()\n\n\nclass LazyAdversaryCost(DefaultDataSpecsMixin, Cost):\n    \"\"\"\n    \"\"\"\n\n    # Supplies own labels, don't get them from the dataset\n    supervised = False\n\n    def __init__(self, scale_grads=1, target_scale=.1,\n            discriminator_default_input_include_prob = 1.,\n            discriminator_input_include_probs=None,\n            discriminator_default_input_scale=1.,\n            discriminator_input_scales=None,\n            generator_default_input_include_prob = 1.,\n            generator_default_input_scale=1.,\n            inference_default_input_include_prob=None,\n            inference_input_include_probs=None,\n            inference_default_input_scale=1.,\n            inference_input_scales=None,\n            init_now_train_generator=True,\n            ever_train_discriminator=True,\n            ever_train_generator=True,\n            ever_train_inference=True,\n            no_drop_in_d_for_g=False,\n            alternate_g = False,\n            infer_layer=None,\n            noise_both = 0.,\n            g_eps = 0.,\n            d_eps =0.):\n        self.__dict__.update(locals())\n        del self.self\n        # These allow you to dynamically switch off training parts.\n        # If the corresponding ever_train_* is False, these have\n        # no effect.\n        self.now_train_generator = sharedX(init_now_train_generator)\n        self.now_train_discriminator = sharedX(numpy.array(1., dtype='float32'))\n        self.now_train_inference = sharedX(numpy.array(1., dtype='float32'))\n\n    def expr(self, model, data, **kwargs):\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        l = []\n        # This stops stuff from ever getting computed if we're not training\n        # it.\n        if self.ever_train_discriminator:\n            l.append(d_obj)\n        if self.ever_train_generator:\n            l.append(g_obj)\n        if self.ever_train_inference:\n            l.append(i_obj)\n        return sum(l)\n\n    def get_samples_and_objectives(self, model, data):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        # Note: this assumes data is design matrix\n        X = data\n        m = data.shape[space.get_batch_axis()]\n        y1 = T.alloc(1, m, 1)\n        y0 = T.alloc(0, m, 1)\n        # NOTE: if this changes to optionally use dropout, change the inference\n        # code below to use a non-dropped-out version.\n        S, z, other_layers = g.sample_and_noise(m, default_input_include_prob=self.generator_default_input_include_prob, default_input_scale=self.generator_default_input_scale, all_g_layers=(self.infer_layer is not None))\n\n        if self.noise_both != 0.:\n            rng = MRG_RandomStreams(2014 / 6 + 2)\n            S = S + rng.normal(size=S.shape, dtype=S.dtype) * self.noise_both\n            X = X + rng.normal(size=X.shape, dtype=S.dtype) * self.noise_both\n\n        y_hat1 = d.dropout_fprop(X, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n        y_hat0 = d.dropout_fprop(S, self.discriminator_default_input_include_prob,\n                                     self.discriminator_input_include_probs,\n                                     self.discriminator_default_input_scale,\n                                     self.discriminator_input_scales)\n\n        # d_obj =  0.5 * (d.layers[-1].cost(y1, y_hat1) + d.layers[-1].cost(y0, y_hat0))\n\n        pos_mask = y_hat1 < .5 + self.d_eps\n        neg_mask = y_hat0 > .5 - self.d_eps\n\n        pos_cost_matrix = d.layers[-1].cost_matrix(y1, y_hat1)\n        neg_cost_matrix = d.layers[-1].cost_matrix(y0, y_hat0)\n\n        pos_cost = (pos_mask * pos_cost_matrix).mean()\n        neg_cost = (neg_mask * neg_cost_matrix).mean()\n\n        d_obj = 0.5 * (pos_cost + neg_cost)\n\n        if self.no_drop_in_d_for_g:\n            y_hat0_no_drop = d.dropout_fprop(S)\n            g_cost_mat = d.layers[-1].cost_matrix(y1, y_hat0_no_drop)\n        else:\n            g_cost_mat = d.layers[-1].cost_matrix(y1, y_hat0)\n        assert g_cost_mat.ndim == 2\n        assert y_hat0.ndim == 2\n\n        mask = y_hat0 < 0.5 + self.g_eps\n        masked_cost = g_cost_mat * mask\n        g_obj = masked_cost.mean()\n\n\n        if model.inferer is not None:\n            # Change this if we ever switch to using dropout in the\n            # construction of S.\n            S_nograd = block_gradient(S)  # Redundant as long as we have custom get_gradients\n            pred = model.inferer.dropout_fprop(S_nograd, self.inference_default_input_include_prob,\n                                                self.inference_input_include_probs,\n                                                self.inference_default_input_scale,\n                                                self.inference_input_scales)\n            if self.infer_layer is None:\n                target = z\n            else:\n                target = other_layers[self.infer_layer]\n            i_obj = model.inferer.layers[-1].cost(target, pred)\n        else:\n            i_obj = 0\n\n        return S, d_obj, g_obj, i_obj\n\n    def get_gradients(self, model, data, **kwargs):\n        space, sources = self.get_data_specs(model)\n        space.validate(data)\n        assert isinstance(model, AdversaryPair)\n        g = model.generator\n        d = model.discriminator\n\n        S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n\n        g_params = g.get_params()\n        d_params = d.get_params()\n        for param in g_params:\n            assert param not in d_params\n        for param in d_params:\n            assert param not in g_params\n        d_grads = T.grad(d_obj, d_params)\n        g_grads = T.grad(g_obj, g_params)\n\n        if self.scale_grads:\n            S_grad = T.grad(g_obj, S)\n            scale = T.maximum(1., self.target_scale / T.sqrt(T.sqr(S_grad).sum()))\n            g_grads = [g_grad * scale for g_grad in g_grads]\n\n        rval = OrderedDict()\n        zeros = itertools.repeat(theano.tensor.constant(0., dtype='float32'))\n        if self.ever_train_discriminator:\n            rval.update(OrderedDict(safe_zip(d_params, [self.now_train_discriminator * dg for dg in d_grads])))\n        else:\n            rval.update(OrderedDict(zip(d_params, zeros)))\n        if self.ever_train_generator:\n            rval.update(OrderedDict(safe_zip(g_params, [self.now_train_generator * gg for gg in g_grads])))\n        else:\n            rval.update(OrderedDict(zip(g_params, zeros)))\n        if self.ever_train_inference and model.inferer is not None:\n            i_params = model.inferer.get_params()\n            i_grads = T.grad(i_obj, i_params)\n            rval.update(OrderedDict(safe_zip(i_params, [self.now_train_inference * ig for ig in i_grads])))\n        elif model.inferer is not None:\n            rval.update(OrderedDict(model.inferer.get_params(), zeros))\n\n        updates = OrderedDict()\n\n        # Two d steps for every g step\n        if self.alternate_g:\n            updates[self.now_train_generator] = 1. - self.now_train_generator\n\n        return rval, updates\n\n    def get_monitoring_channels(self, model, data, **kwargs):\n\n        rval = OrderedDict()\n\n        m = data.shape[0]\n\n        g = model.generator\n        d = model.discriminator\n\n        y_hat = d.fprop(data)\n\n        rval['false_negatives'] = T.cast((y_hat < 0.5).mean(), 'float32')\n\n        samples = g.sample(m)\n        y_hat = d.fprop(samples)\n        rval['false_positives'] = T.cast((y_hat > 0.5).mean(), 'float32')\n        # y = T.alloc(0., m, 1)\n        cost = d.cost_from_X((samples, y_hat))\n        sample_grad = T.grad(-cost, samples)\n        rval['sample_grad_norm'] = T.sqrt(T.sqr(sample_grad).sum())\n        _S, d_obj, g_obj, i_obj = self.get_samples_and_objectives(model, data)\n        if model.monitor_inference and i_obj != 0:\n            rval['objective_i'] = i_obj\n        if model.monitor_discriminator:\n            rval['objective_d'] = d_obj\n        if model.monitor_generator:\n            rval['objective_g'] = g_obj\n\n        rval['now_train_generator'] = self.now_train_generator\n        return rval\n"
        },
        {
          "name": "cifar10_convolutional.yaml",
          "type": "blob",
          "size": 6.40625,
          "content": "!obj:pylearn2.train.Train {\n    dataset: &train !obj:pylearn2.datasets.cifar10.CIFAR10 {\n        axes: ['c', 0, 1, 'b'],\n        gcn: 55.,\n        which_set: 'train',\n        start: 0,\n        stop: 40000\n    },\n    model: !obj:adversarial.AdversaryPair {\n        generator: !obj:adversarial.Generator {\n            mlp: !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.mlp.RectifiedLinear {\n                         layer_name: 'gh0',\n                         dim: 8000,\n                         irange: .05,\n                         #max_col_norm: 1.9365,\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'h1',\n                         dim: 8000,\n                         irange: .05,\n                         #max_col_norm: 1.9365,\n                     },\n                     !obj:pylearn2.models.mlp.SpaceConverter {\n                         layer_name: 'converter',\n                         output_space: !obj:pylearn2.space.Conv2DSpace {\n                        shape: [10, 10],\n                        num_channels: 80,\n                        axes: ['c', 0, 1, 'b'],\n                    }},\n                     !obj:adversarial.deconv.Deconv {\n                     #W_lr_scale: .05,\n                     #b_lr_scale: .05,\n                         num_channels: 3,\n                         output_stride: [3, 3],\n                         kernel_shape: [5, 5],\n                         pad_out: 0,\n                         #max_kernel_norm: 1.9365,\n                         # init_bias: !obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals { dataset: *train},\n                         layer_name: 'y',\n                         irange: .05,\n                         tied_b: 0\n                     },\n                    ],\n            nvis: 100,\n        }},\n        discriminator: \n            !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                 !obj:pylearn2.models.maxout.MaxoutConvC01B {\n                     layer_name: 'dh0',\n                     pad: 4,\n                     tied_b: 1,\n                     #W_lr_scale: .05,\n                     #b_lr_scale: .05,\n                     num_channels: 32,\n                     num_pieces: 2,\n                     kernel_shape: [8, 8],\n                     pool_shape: [4, 4],\n                     pool_stride: [2, 2],\n                     irange: .005,\n                     #max_kernel_norm: .9,\n                     partial_sum: 33,\n                 },\n                 !obj:pylearn2.models.maxout.MaxoutConvC01B {\n                     layer_name: 'h1',\n                     pad: 3,\n                     tied_b: 1,\n                     #W_lr_scale: .05,\n                     #b_lr_scale: .05,\n                     num_channels: 32, # 192 ran out of memory\n                     num_pieces: 2,\n                     kernel_shape: [8, 8],\n                     pool_shape: [4, 4],\n                     pool_stride: [2, 2],\n                     irange: .005,\n                     #max_kernel_norm: 1.9365,\n                     partial_sum: 15,\n                 },\n                 !obj:pylearn2.models.maxout.MaxoutConvC01B {\n                     pad: 3,\n                     layer_name: 'h2',\n                     tied_b: 1,\n                     #W_lr_scale: .05,\n                     #b_lr_scale: .05,\n                     num_channels: 192,\n                     num_pieces: 2,\n                     kernel_shape: [5, 5],\n                     pool_shape: [2, 2],\n                     pool_stride: [2, 2],\n                     irange: .005,\n                     #max_kernel_norm: 1.9365,\n                 },\n                 !obj:pylearn2.models.maxout.Maxout {\n                    layer_name: 'h3',\n                    irange: .005,\n                    num_units: 500,\n                    num_pieces: 5,\n                    #max_col_norm: 1.9\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         #W_lr_scale: .1,\n                         #b_lr_scale: .1,\n                         #max_col_norm: 1.9365,\n                         layer_name: 'y',\n                         dim: 1,\n                         irange: .005\n                     }\n                    ],\n        input_space: !obj:pylearn2.space.Conv2DSpace {\n            shape: [32, 32],\n            num_channels: 3,\n            axes: ['c', 0, 1, 'b'],\n        }\n        },\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n        batch_size: 128,\n        learning_rate: .004,\n        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n            init_momentum: .5,\n        },\n        monitoring_dataset:\n            {\n                #'train' : *train,\n                'valid' : !obj:pylearn2.datasets.cifar10.CIFAR10 {\n                            axes: ['c', 0, 1, 'b'],\n                              gcn: 55., \n                              which_set: 'train',\n                              start: 40000,\n                              stop:  50000\n                          },\n                #'test'  : !obj:pylearn2.datasets.cifar10.CIFAR10 {\n                #              which_set: 'test',\n                #              gcn: 55.,\n                #          }\n            },\n        cost: !obj:adversarial.AdversaryCost2 {\n            scale_grads: 0,\n            #target_scale: .1,\n            discriminator_default_input_include_prob: .5,\n            discriminator_input_include_probs: {\n                'dh0': .8\n            },\n            discriminator_default_input_scale: 2.,\n            discriminator_input_scales: {\n                'dh0': 1.25   \n            }\n            },\n        #termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n        #    channel_name: \"valid_y_misclass\",\n        #    prop_decrease: 0.,\n        #    N: 100\n        #},\n        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {\n            decay_factor: 1.000004,\n            min_lr: .000001\n        }\n    },\n    extensions: [\n        #!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n        #     channel_name: 'valid_y_misclass',\n        #     save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl\"\n        #},\n        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n            start: 1,\n            saturate: 250,\n            final_momentum: .7\n        }\n    ],\n    save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl\",\n    save_freq: 1\n}\n"
        },
        {
          "name": "cifar10_fully_connected.yaml",
          "type": "blob",
          "size": 4.029296875,
          "content": "!obj:pylearn2.train.Train {\n    dataset: &train !obj:pylearn2.datasets.cifar10.CIFAR10 {\n        gcn: 55.,\n        which_set: 'train',\n        start: 0,\n        stop: 40000\n    },\n    model: !obj:adversarial.AdversaryPair {\n        generator: !obj:adversarial.Generator {\n            mlp: !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.mlp.RectifiedLinear {\n                         layer_name: 'gh0',\n                         dim: 8000,\n                         irange: .05,\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'h1',\n                         dim: 8000,\n                         irange: .05,\n                     },\n                     !obj:pylearn2.models.mlp.Linear {\n                         # init_bias: !obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals { dataset: *train},\n                         layer_name: 'y',\n                         irange: .5,\n                         dim: 3072\n                     }\n                    ],\n            nvis: 100,\n        }},\n        discriminator: \n            !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.maxout.Maxout {\n                         layer_name: 'dh0',\n                         num_units: 1600,\n                         num_pieces: 5,\n                         irange: .005,\n                     },\n                     !obj:pylearn2.models.maxout.Maxout {\n                         layer_name: 'h1',\n                         num_units: 1600,\n                         num_pieces: 5,\n                         irange: .005,\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'y',\n                         dim: 1,\n                         irange: .005\n                     }\n                    ],\n            nvis: 3072,\n        },\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n        batch_size: 100,\n        learning_rate: .025,\n        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n            init_momentum: .5,\n        },\n        monitoring_dataset:\n            {\n                #'train' : *train,\n                'valid' : !obj:pylearn2.datasets.cifar10.CIFAR10 {\n                              gcn: 55., \n                              which_set: 'train',\n                              start: 40000,\n                              stop:  50000\n                          },\n                #'test'  : !obj:pylearn2.datasets.cifar10.CIFAR10 {\n                #              which_set: 'test',\n                #              gcn: 55.,\n                #          }\n            },\n        cost: !obj:adversarial.AdversaryCost2 {\n            scale_grads: 0,\n            #target_scale: .1,\n            discriminator_default_input_include_prob: .5,\n            discriminator_input_include_probs: {\n                'dh0': .8\n            },\n            discriminator_default_input_scale: 2.,\n            discriminator_input_scales: {\n                'dh0': 1.25   \n            }\n            },\n        #!obj:pylearn2.costs.mlp.dropout.Dropout {\n        #    input_include_probs: { 'h0' : .8 },\n        #    input_scales: { 'h0': 1. }\n        #},\n        #termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n        #    channel_name: \"valid_y_misclass\",\n        #    prop_decrease: 0.,\n        #    N: 100\n        #},\n        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {\n            decay_factor: 1.000004,\n            min_lr: .000001\n        }\n    },\n    extensions: [\n        #!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n        #     channel_name: 'valid_y_misclass',\n        #     save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl\"\n        #},\n        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n            start: 1,\n            saturate: 250,\n            final_momentum: .7\n        }\n    ],\n    save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl\",\n    save_freq: 1\n}\n"
        },
        {
          "name": "deconv.py",
          "type": "blob",
          "size": 13.7919921875,
          "content": "import functools\nimport logging\nimport numpy as np\n\nfrom theano.compat import OrderedDict\nfrom theano import tensor as T\n\nfrom pylearn2.linear.conv2d_c01b import make_random_conv2D\nfrom pylearn2.models import Model\nfrom pylearn2.models.maxout import check_cuda # TODO: import from original path\nfrom pylearn2.models.mlp import Layer\n#from pylearn2.models.maxout import py_integer_types # TODO: import from orig path\nfrom pylearn2.space import Conv2DSpace\nfrom pylearn2.utils import sharedX\n\nlogger = logging.getLogger(__name__)\n\nclass Deconv(Layer):\n    def __init__(self,\n                 num_channels,\n                 kernel_shape,\n                 layer_name,\n                 irange=None,\n                 init_bias=0.,\n                 W_lr_scale=None,\n                 b_lr_scale=None,\n                 pad_out=0,\n                 fix_kernel_shape=False,\n                 partial_sum=1,\n                 tied_b=False,\n                 max_kernel_norm=None,\n                 output_stride=(1, 1)):\n        check_cuda(str(type(self)))\n        super(Deconv, self).__init__()\n\n        detector_channels = num_channels\n\n        self.__dict__.update(locals())\n        del self.self\n\n    @functools.wraps(Model.get_lr_scalers)\n    def get_lr_scalers(self):\n\n        if not hasattr(self, 'W_lr_scale'):\n            self.W_lr_scale = None\n\n        if not hasattr(self, 'b_lr_scale'):\n            self.b_lr_scale = None\n\n        rval = OrderedDict()\n\n        if self.W_lr_scale is not None:\n            W, = self.transformer.get_params()\n            rval[W] = self.W_lr_scale\n\n        if self.b_lr_scale is not None:\n            rval[self.b] = self.b_lr_scale\n\n        return rval\n\n    def set_input_space(self, space):\n        \"\"\"\n        Tells the layer to use the specified input space.\n\n        This resets parameters! The kernel tensor is initialized with the\n        size needed to receive input from this space.\n\n        Parameters\n        ----------\n        space : Space\n            The Space that the input will lie in.\n        \"\"\"\n\n        setup_deconv_detector_layer_c01b(layer=self,\n                                  input_space=space,\n                                  rng=self.mlp.rng)\n\n        rng = self.mlp.rng\n\n        detector_shape = self.detector_space.shape\n\n\n        self.output_space = self.detector_space\n\n        logger.info('Output space: {0}'.format(self.output_space.shape))\n\n    def _modify_updates(self, updates):\n        \"\"\"\n        Replaces the values in `updates` if needed to enforce the options set\n        in the __init__ method, including `max_kernel_norm`.\n\n        Parameters\n        ----------\n        updates : OrderedDict\n            A dictionary mapping parameters (including parameters not\n            belonging to this model) to updated values of those parameters.\n            The dictionary passed in contains the updates proposed by the\n            learning algorithm. This function modifies the dictionary\n            directly. The modified version will be compiled and executed\n            by the learning algorithm.\n        \"\"\"\n\n        if self.max_kernel_norm is not None:\n            W, = self.transformer.get_params()\n            if W in updates:\n                updated_W = updates[W]\n                row_norms = T.sqrt(T.sum(T.sqr(updated_W), axis=(0, 1, 2)))\n                desired_norms = T.clip(row_norms, 0, self.max_kernel_norm)\n                scales = desired_norms / (1e-7 + row_norms)\n                updates[W] = (updated_W * scales.dimshuffle('x', 'x', 'x', 0))\n\n    @functools.wraps(Model.get_params)\n    def get_params(self):\n        assert self.b.name is not None\n        W, = self.transformer.get_params()\n        assert W.name is not None\n        rval = self.transformer.get_params()\n        assert not isinstance(rval, set)\n        rval = list(rval)\n        assert self.b not in rval\n        rval.append(self.b)\n        return rval\n\n    @functools.wraps(Layer.get_weight_decay)\n    def get_weight_decay(self, coeff):\n        if isinstance(coeff, str):\n            coeff = float(coeff)\n        assert isinstance(coeff, float) or hasattr(coeff, 'dtype')\n        W, = self.transformer.get_params()\n        return coeff * T.sqr(W).sum()\n\n    @functools.wraps(Layer.set_weights)\n    def set_weights(self, weights):\n        W, = self.transformer.get_params()\n        W.set_value(weights)\n\n    @functools.wraps(Layer.set_biases)\n    def set_biases(self, biases):\n        self.b.set_value(biases)\n\n    @functools.wraps(Layer.get_biases)\n    def get_biases(self):\n        return self.b.get_value()\n\n    @functools.wraps(Model.get_weights_topo)\n    def get_weights_topo(self):\n        return self.transformer.get_weights_topo()\n\n    @functools.wraps(Layer.get_monitoring_channels)\n    def get_layer_monitoring_channels(self, state_below=None, state=None, targets=None):\n\n        W, = self.transformer.get_params()\n\n        assert W.ndim == 4\n\n        sq_W = T.sqr(W)\n\n        row_norms = T.sqrt(sq_W.sum(axis=(0, 1, 2)))\n\n        P = state\n\n        rval = OrderedDict()\n\n        vars_and_prefixes = [(P, '')]\n\n        for var, prefix in vars_and_prefixes:\n            if not hasattr(var, 'ndim') or var.ndim != 4:\n                print \"expected 4D tensor, got \"\n                print var\n                print type(var)\n                if isinstance(var, tuple):\n                    print \"tuple length: \", len(var)\n                assert False\n            v_max = var.max(axis=(1, 2, 3))\n            v_min = var.min(axis=(1, 2, 3))\n            v_mean = var.mean(axis=(1, 2, 3))\n            v_range = v_max - v_min\n\n            # max_x.mean_u is \"the mean over *u*nits of the max over\n            # e*x*amples\" The x and u are included in the name because\n            # otherwise its hard to remember which axis is which when reading\n            # the monitor I use inner.outer rather than outer_of_inner or\n            # something like that because I want mean_x.* to appear next to\n            # each other in the alphabetical list, as these are commonly\n            # plotted together\n            for key, val in [('max_x.max_u',    v_max.max()),\n                             ('max_x.mean_u',   v_max.mean()),\n                             ('max_x.min_u',    v_max.min()),\n                             ('min_x.max_u',    v_min.max()),\n                             ('min_x.mean_u',   v_min.mean()),\n                             ('min_x.min_u',    v_min.min()),\n                             ('range_x.max_u',  v_range.max()),\n                             ('range_x.mean_u', v_range.mean()),\n                             ('range_x.min_u',  v_range.min()),\n                             ('mean_x.max_u',   v_mean.max()),\n                             ('mean_x.mean_u',  v_mean.mean()),\n                             ('mean_x.min_u',   v_mean.min())]:\n                rval[prefix+key] = val\n\n        rval.update(OrderedDict([('kernel_norms_min',  row_norms.min()),\n                            ('kernel_norms_mean', row_norms.mean()),\n                            ('kernel_norms_max',  row_norms.max()), ]))\n\n        return rval\n\n    @functools.wraps(Layer.fprop)\n    def fprop(self, state_below):\n        check_cuda(str(type(self)))\n\n        self.input_space.validate(state_below)\n\n        z = self.transformer.lmul_T(state_below)\n\n        self.output_space.validate(z)\n\n        if not hasattr(self, 'tied_b'):\n            self.tied_b = False\n        if self.tied_b:\n            b = self.b.dimshuffle(0, 'x', 'x', 'x')\n        else:\n            b = self.b.dimshuffle(0, 1, 2, 'x')\n\n        return z + b\n\n\n\ndef setup_deconv_detector_layer_c01b(layer, input_space, rng, irange=\"not specified\"):\n    \"\"\"\n    layer. This function sets up only the detector layer.\n\n    Does the following:\n\n    * raises a RuntimeError if cuda is not available\n    * sets layer.input_space to input_space\n    * sets up addition of dummy channels for compatibility with cuda-convnet:\n\n      - layer.dummy_channels: # of dummy channels that need to be added\n        (You might want to check this and raise an Exception if it's not 0)\n      - layer.dummy_space: The Conv2DSpace representing the input with dummy\n        channels added\n\n    * sets layer.detector_space to the space for the detector layer\n    * sets layer.transformer to be a Conv2D instance\n    * sets layer.b to the right value\n\n    Parameters\n    ----------\n    layer : object\n        Any python object that allows the modifications described below and\n        has the following attributes:\n\n          * pad : int describing amount of zero padding to add\n          * kernel_shape : 2-element tuple or list describing spatial shape of\n            kernel\n          * fix_kernel_shape : bool, if true, will shrink the kernel shape to\n            make it feasible, as needed (useful for hyperparameter searchers)\n          * detector_channels : The number of channels in the detector layer\n          * init_bias : numeric constant added to a tensor of zeros to\n            initialize the bias\n          * tied_b : If true, biases are shared across all spatial locations\n    input_space : WRITEME\n        A Conv2DSpace to be used as input to the layer\n    rng : WRITEME\n        A numpy RandomState or equivalent\n    \"\"\"\n\n    if irange != \"not specified\":\n        raise AssertionError(\n            \"There was a bug in setup_detector_layer_c01b.\"\n            \"It uses layer.irange instead of the irange parameter to the \"\n            \"function. The irange parameter is now disabled by this \"\n            \"AssertionError, so that this error message can alert you that \"\n            \"the bug affected your code and explain why the interface is \"\n            \"changing. The irange parameter to the function and this \"\n            \"error message may be removed after April 21, 2014.\"\n        )\n\n    # Use \"self\" to refer to layer from now on, so we can pretend we're\n    # just running in the set_input_space method of the layer\n    self = layer\n\n    # Make sure cuda is available\n    check_cuda(str(type(self)))\n\n    # Validate input\n    if not isinstance(input_space, Conv2DSpace):\n        raise TypeError(\"The input to a convolutional layer should be a \"\n                        \"Conv2DSpace, but layer \" + self.layer_name + \" got \" +\n                        str(type(self.input_space)))\n\n    if not hasattr(self, 'detector_channels'):\n        raise ValueError(\"layer argument must have a 'detector_channels' \"\n                         \"attribute specifying how many channels to put in \"\n                         \"the convolution kernel stack.\")\n\n    # Store the input space\n    self.input_space = input_space\n\n    # Make sure number of channels is supported by cuda-convnet\n    # (multiple of 4 or <= 3)\n    # If not supported, pad the input with dummy channels\n    ch = self.detector_channels\n    rem = ch % 4\n    if ch > 3 and rem != 0:\n        raise NotImplementedError(\"Need to do dummy channels on the output\")\n    #    self.dummy_channels = 4 - rem\n    #else:\n    #    self.dummy_channels = 0\n    #self.dummy_space = Conv2DSpace(\n    #    shape=input_space.shape,\n    #    channels=input_space.num_channels + self.dummy_channels,\n    #    axes=('c', 0, 1, 'b')\n    #)\n\n    if hasattr(self, 'output_stride'):\n        kernel_stride = self.output_stride\n    else:\n        assert False # not sure if I got the name right, remove this assert if I did\n        kernel_stride = [1, 1]\n\n\n    #o_sh = int(np.ceil((i_sh + 2. * self.pad - k_sh) / float(k_st))) + 1\n    #o_sh -1 = np.ceil((i_sh + 2. * self.pad - k_sh) / float(k_st))\n    #inv_ceil(o_sh -1) = (i_sh + 2. * self.pad - k_sh) / float(k_st)\n    #float(k_st) inv_cel(o_sh -1) = (i_sh + 2 * self.pad -k_sh)\n    # i_sh = k_st inv_ceil(o_sh-1) - 2 * self.pad + k_sh\n\n    output_shape = \\\n        [k_st * (i_sh - 1) - 2 * self.pad_out + k_sh\n         for i_sh, k_sh, k_st in zip(self.input_space.shape,\n                                     self.kernel_shape, kernel_stride)]\n\n\n    if self.input_space.num_channels < 16:\n        raise ValueError(\"Cuda-convnet requires the input to lmul_T to have \"\n                         \"at least 16 channels.\")\n\n    self.detector_space = Conv2DSpace(shape=output_shape,\n                                      num_channels=self.detector_channels,\n                                      axes=('c', 0, 1, 'b'))\n\n    if hasattr(self, 'partial_sum'):\n        partial_sum = self.partial_sum\n    else:\n        partial_sum = 1\n\n    if hasattr(self, 'sparse_init') and self.sparse_init is not None:\n        self.transformer = \\\n            checked_call(make_sparse_random_conv2D,\n                         OrderedDict([('num_nonzero', self.sparse_init),\n                                      ('input_space', self.detector_space),\n                                      ('output_space', self.input_space),\n                                      ('kernel_shape', self.kernel_shape),\n                                      ('pad', self.pad),\n                                      ('partial_sum', partial_sum),\n                                      ('kernel_stride', kernel_stride),\n                                      ('rng', rng)]))\n    else:\n        self.transformer = make_random_conv2D(\n            irange=self.irange,\n            input_axes=self.detector_space.axes,\n            output_axes=self.input_space.axes,\n            input_channels=self.detector_space.num_channels,\n            output_channels=self.input_space.num_channels,\n            kernel_shape=self.kernel_shape,\n            pad=self.pad_out,\n            partial_sum=partial_sum,\n            kernel_stride=kernel_stride,\n            rng=rng,\n            input_shape=self.detector_space.shape\n        )\n\n    W, = self.transformer.get_params()\n    W.name = self.layer_name + '_W'\n\n    if self.tied_b:\n        self.b = sharedX(np.zeros(self.detector_space.num_channels) +\n                         self.init_bias)\n    else:\n        self.b = sharedX(self.detector_space.get_origin() + self.init_bias)\n    self.b.name = self.layer_name + '_b'\n\n    logger.info('Input shape: {0}'.format(self.input_space.shape))\n    print layer.layer_name + ' detector space: {0}'.format(self.detector_space.shape)\n"
        },
        {
          "name": "ll.py",
          "type": "blob",
          "size": 2.5439453125,
          "content": "import numpy as np\nimport sys\n\nfrom theano import function\nfrom theano import tensor as T\n\n_, model_path, sigma = sys.argv\nfrom pylearn2.utils import serial\nmodel = serial.load(model_path)\nfrom pylearn2.config import yaml_parse\ndataset = yaml_parse.load(model.dataset_yaml_src)\ndataset = dataset.get_test_set()\nfrom pylearn2.utils import sharedX\ng = model.generator\nn = g.get_input_space().get_total_dimension()\nX = sharedX(dataset.X)\nm = dataset.X.shape[0]\naccumulator = sharedX(np.zeros((m,)))\nz_samples = g.get_noise(1)\nx_samples = g.mlp.fprop(z_samples)\nfrom theano.compat import OrderedDict\nupdates = OrderedDict()\nfrom theano import shared\nnum_samples = shared(1)\nsigma = sharedX(float(sigma))\nprev = accumulator\ncur = -0.5 * T.sqr(X - x_samples).sum(axis=1) / T.sqr(sigma)\nofs = T.maximum(prev, cur)\nnum_samples_f = T.cast(num_samples, 'float32')\nupdates[accumulator] = ofs + T.log(num_samples_f * T.exp(prev - ofs) + T.exp(cur - ofs)) - T.log(num_samples_f + 1.)\nupdates[num_samples] = num_samples + 1\nf = function([], updates=updates)\nupdates[accumulator] = cur\ndel updates[num_samples]\nfirst = function([], updates=updates)\navg_ll = accumulator.mean() - 0.5 * X.shape[1] * T.log(2 * np.pi * T.sqr(sigma))\n\nimport time\nprev_t = time.time()\nfirst()\nwhile True:\n    v = avg_ll.eval()\n    i = num_samples.get_value()\n    if i == 1 or i % 1000 == 0:\n        now_t = time.time()\n        print i, v, now_t - prev_t\n        prev_t = now_t\n    if np.isnan(v) or np.isinf(v):\n        break\n    f()\n\n# log p(x)\n# = log int p(z, x) dz\n# = log int p(z) p(x |z) dz\n# = log E_z p(x|z)\n# = log (1/m) sum_z p(x|z)\n# = log (1/m) sum_z prod_i sqrt(1/(2 pi sigma^2)) exp( -0.5 (x_i-g(z)_i)^2 / sigma^2)\n# = log  sqrt(1/(2 pi sigma^2))^d (1/m) sum_z prod_iexp( -0.5 (x_i-g(z)_i)^2 / sigma^2)\n# = log  sqrt(1/(2 pi sigma^2))^d (1/m) sum_z exp( sum_i -0.5 (x_i-g(z)_i)^2 / sigma^2)\n# = log  sqrt(1/(2 pi sigma^2))^d + log (1/m) sum_z exp( sum_i -0.5 (x_i-g(z)_i)^2 / sigma^2)\n# = 0.5 d log  1/(2 pi sigma^2) + log (1/m) sum_z exp( sum_i -0.5 (x_i-g(z)_i)^2 / sigma^2)\n# = -0.5 d log  (2 pi sigma^2) + log (1/m) sum_z exp( sum_i -0.5 (x_i-g(z)_i)^2 / sigma^2)\n\n# log (1/m) sum_j exp(v_j)\n# = log (1/m) [exp(v_m) + sum_{j=1}^{m-1} exp(v_j)]\n# = log (1/m) [exp(v_m) + (m-1) exp( prev )]\n# = log (1/m) [exp(v_m) exp(ofs-ofs) + (m-1) exp( prev ) exp(ofs -ofs)]\n# = log (1/m) [exp(v_m- ofs) exp(ofs) + (m-1) exp( prev -ofs) exp(ofs)]\n# = log exp(ofs) (1/m) [exp(v_m- ofs) + (m-1) exp( prev -ofs) ]\n# = ofs + log  (1/m) [exp(v_m- ofs) + (m-1) exp( prev -ofs) ]\n# = ofs + log  [exp(v_m- ofs) + (m-1) exp( prev -ofs) ] - log m\n"
        },
        {
          "name": "ll_mnist.py",
          "type": "blob",
          "size": 2.37109375,
          "content": "import numpy as np\nimport sys\n\nfrom theano import function\nfrom theano import tensor as T\n\n_, model_path, sigma = sys.argv\nfrom pylearn2.utils import serial\nmodel = serial.load(model_path)\nfrom pylearn2.config import yaml_parse\ndataset = yaml_parse.load(model.dataset_yaml_src)\ndataset = dataset.get_test_set()\nfrom pylearn2.utils import sharedX\ng = model.generator\nn = g.get_input_space().get_total_dimension()\nX = sharedX(dataset.X)\nfrom theano.sandbox.rng_mrg import MRG_RandomStreams\ntheano_rng = MRG_RandomStreams(2014 + 6 * 24)\nassert False # Aaron says to do valid comparison we need to download the standard binarization,\n# and the model should also have been trained on the standard binarization\nf = function([], updates=[(X, theano_rng.binomial(p=X, size=X.shape, dtype=X.dtype))])\nf()\nm = dataset.X.shape[0]\naccumulator = sharedX(np.zeros((m,)))\nz_samples = g.get_noise(1)\nx_samples = g.mlp.fprop(z_samples)\n# x_samples = X\nfrom theano.compat import OrderedDict\nupdates = OrderedDict()\nfrom theano import shared\nnum_samples = shared(1)\nsigma = sharedX(float(sigma))\nprev = accumulator\nfrom theano.printing import Print\n#prev = Print('prev',attrs=['min','max'])(prev)\n# E_x log E_z exp(- sum_i softplus( (1 - 2 x_i) A(z)_i) )\nfrom pylearn2.expr.nnet import arg_of_sigmoid\nA = arg_of_sigmoid(x_samples)\ncur = - T.nnet.softplus((1. - 2. * X) * A).sum(axis=1)\n#cur = Print('cur',attrs=['min','max'])(cur)\nofs = T.maximum(prev, cur)\nnum_samples_f = T.cast(num_samples, 'float32')\nupdates[accumulator] = ofs + T.log((num_samples_f * T.exp(prev - ofs) + T.exp(cur - ofs)) / (num_samples_f + 1.))\nupdates[num_samples] = num_samples + 1\nf = function([], updates=updates)\nupdates[accumulator] = cur\ndel updates[num_samples]\nfirst = function([], updates=updates)\navg_ll = accumulator.mean()\n\nimport time\nprev_t = time.time()\nfirst()\nwhile True:\n    v = avg_ll.eval()\n    i = num_samples.get_value()\n    if i == 1 or i % 1000 == 0:\n        now_t = time.time()\n        print i, v, now_t - prev_t\n        prev_t = now_t\n    if np.isnan(v) or np.isinf(v):\n        break\n    f()\n\n# E_x log p(x)\n# E_x log int p(x, z) dz\n# E_x log int p(z) p(x | z) dz\n# E_x log E_z p(x | z)\n# E_x log E_z prod_i p(x_i | z)\n# E_x log E_z prod_i sigmoid( (2 x_i - 1) A(z)_i)\n# E_x log E_z exp(log prod_i sigmoid( (2 x_i - 1) A(z)_i) )\n# E_x log E_z exp(sum_i log sigmoid( (2 x_i - 1) A(z)_i) )\n# E_x log E_z exp(- sum_i softplus( (1 - 2 x_i) A(z)_i) )\n"
        },
        {
          "name": "mnist.yaml",
          "type": "blob",
          "size": 3.7998046875,
          "content": "!obj:pylearn2.train.Train {\n    dataset: &train !obj:pylearn2.datasets.mnist.MNIST {\n        which_set: 'train',\n        start: 0,\n        stop: 50000\n    },\n    model: !obj:adversarial.AdversaryPair {\n        generator: !obj:adversarial.Generator {\n            noise: 'uniform',\n            monitor_ll: 1,\n            mlp: !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.mlp.RectifiedLinear {\n                         layer_name: 'h0',\n                         dim: 1200,\n                         irange: .05,\n                     },\n                     !obj:pylearn2.models.mlp.RectifiedLinear {\n                         layer_name: 'h1',\n                         dim: 1200,\n                         irange: .05,\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         init_bias: !obj:pylearn2.models.dbm.init_sigmoid_bias_from_marginals { dataset: *train},\n                         layer_name: 'y',\n                         irange: .05,\n                         dim: 784\n                     }\n                    ],\n            nvis: 100,\n        }},\n        discriminator: \n            !obj:pylearn2.models.mlp.MLP {\n            layers: [\n                     !obj:pylearn2.models.maxout.Maxout {\n                         layer_name: 'h0',\n                         num_units: 240,\n                         num_pieces: 5,\n                         irange: .005,\n                     },\n                     !obj:pylearn2.models.maxout.Maxout {\n                         layer_name: 'h1',\n                         num_units: 240,\n                         num_pieces: 5,\n                         irange: .005,\n                     },\n                     !obj:pylearn2.models.mlp.Sigmoid {\n                         layer_name: 'y',\n                         dim: 1,\n                         irange: .005\n                     }\n                    ],\n            nvis: 784,\n        },\n    },\n    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {\n        batch_size: 100,\n        learning_rate: .1,\n        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.Momentum {\n            init_momentum: .5,\n        },\n        monitoring_dataset:\n            {\n                'valid' : !obj:pylearn2.datasets.mnist.MNIST {\n                              which_set: 'train',\n                              start: 50000,\n                              stop:  60000\n                          },\n            },\n        cost: !obj:adversarial.AdversaryCost2 {\n            scale_grads: 0,\n            #target_scale: 1.,\n            discriminator_default_input_include_prob: .5,\n            discriminator_input_include_probs: {\n                'h0': .8\n            },\n            discriminator_default_input_scale: 2.,\n            discriminator_input_scales: {\n                'h0': 1.25   \n            }\n            },\n        #!obj:pylearn2.costs.mlp.dropout.Dropout {\n        #    input_include_probs: { 'h0' : .8 },\n        #    input_scales: { 'h0': 1. }\n        #},\n        #termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {\n        #    channel_name: \"valid_y_misclass\",\n        #    prop_decrease: 0.,\n        #    N: 100\n        #},\n        update_callbacks: !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {\n            decay_factor: 1.000004,\n            min_lr: .000001\n        }\n    },\n    extensions: [\n        #!obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {\n        #     channel_name: 'valid_y_misclass',\n        #     save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}_best.pkl\"\n        #},\n        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {\n            start: 1,\n            saturate: 250,\n            final_momentum: .7\n        }\n    ],\n    save_path: \"${PYLEARN2_TRAIN_FILE_FULL_STEM}.pkl\",\n    save_freq: 1\n}\n"
        },
        {
          "name": "parzen_ll.py",
          "type": "blob",
          "size": 4.62109375,
          "content": "import argparse\nimport time\nimport gc\nimport numpy\nimport theano\nimport theano.tensor as T\nfrom pylearn2.utils import serial\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.datasets.mnist import MNIST\nfrom pylearn2.datasets.tfd import TFD\n\n\n\ndef get_nll(x, parzen, batch_size=10):\n    \"\"\"\n    Credit: Yann N. Dauphin\n    \"\"\"\n\n    inds = range(x.shape[0])\n    n_batches = int(numpy.ceil(float(len(inds)) / batch_size))\n\n    times = []\n    nlls = []\n    for i in range(n_batches):\n        begin = time.time()\n        nll = parzen(x[inds[i::n_batches]])\n        end = time.time()\n        times.append(end-begin)\n        nlls.extend(nll)\n\n        if i % 10 == 0:\n            print i, numpy.mean(times), numpy.mean(nlls)\n\n    return numpy.array(nlls)\n\n\ndef log_mean_exp(a):\n    \"\"\"\n    Credit: Yann N. Dauphin\n    \"\"\"\n\n    max_ = a.max(1)\n\n    return max_ + T.log(T.exp(a - max_.dimshuffle(0, 'x')).mean(1))\n\n\ndef theano_parzen(mu, sigma):\n    \"\"\"\n    Credit: Yann N. Dauphin\n    \"\"\"\n\n    x = T.matrix()\n    mu = theano.shared(mu)\n    a = ( x.dimshuffle(0, 'x', 1) - mu.dimshuffle('x', 0, 1) ) / sigma\n    E = log_mean_exp(-0.5*(a**2).sum(2))\n    Z = mu.shape[1] * T.log(sigma * numpy.sqrt(numpy.pi * 2))\n\n    return theano.function([x], E - Z)\n\n\ndef cross_validate_sigma(samples, data, sigmas, batch_size):\n\n    lls = []\n    for sigma in sigmas:\n        print sigma\n        parzen = theano_parzen(samples, sigma)\n        tmp = get_nll(data, parzen, batch_size = batch_size)\n        lls.append(numpy.asarray(tmp).mean())\n        del parzen\n        gc.collect()\n\n    ind = numpy.argmax(lls)\n    return sigmas[ind]\n\n\ndef get_valid(ds, limit_size = -1, fold = 0):\n    if ds == 'mnist':\n        data = MNIST('train', start=50000, stop=60000)\n        return data.X[:limit_size]\n    elif ds == 'tfd':\n        data = TFD('valid', fold = fold, scale=True)\n        return data.X\n    else:\n         raise ValueError(\"Unknow dataset: {}\".format(args.dataet))\n\n\ndef get_test(ds, test, fold=0):\n    if ds == 'mnist':\n        return test.get_test_set()\n    elif ds == 'tfd':\n        return test.get_test_set(fold=fold)\n    else:\n        raise ValueError(\"Unknow dataset: {}\".format(args.dataet))\n\n\ndef main():\n    parser = argparse.ArgumentParser(description = 'Parzen window, log-likelihood estimator')\n    parser.add_argument('-p', '--path', help='model path')\n    parser.add_argument('-s', '--sigma', default = None)\n    parser.add_argument('-d', '--dataset', choices=['mnist', 'tfd'])\n    parser.add_argument('-f', '--fold', default = 0, type=int)\n    parser.add_argument('-v', '--valid', default = False, action='store_true')\n    parser.add_argument('-n', '--num_samples', default=10000, type=int)\n    parser.add_argument('-l', '--limit_size', default=1000, type=int)\n    parser.add_argument('-b', '--batch_size', default=100, type=int)\n    parser.add_argument('-c', '--cross_val', default=10, type=int,\n                            help=\"Number of cross valiation folds\")\n    parser.add_argument('--sigma_start', default=-1, type=float)\n    parser.add_argument('--sigma_end', default=0., type=float)\n    args = parser.parse_args()\n\n    # load model\n    model = serial.load(args.path)\n    src = model.dataset_yaml_src\n    batch_size = args.batch_size\n    model.set_batch_size(batch_size)\n\n    # load test set\n    test = yaml_parse.load(src)\n    test = get_test(args.dataset, test, args.fold)\n\n    # generate samples\n    samples = model.generator.sample(args.num_samples).eval()\n    output_space = model.generator.mlp.get_output_space()\n    if 'Conv2D' in str(output_space):\n        samples = output_space.convert(samples, output_space.axes, ('b', 0, 1, 'c'))\n        samples = samples.reshape((samples.shape[0], numpy.prod(samples.shape[1:])))\n    del model\n    gc.collect()\n\n    # cross validate sigma\n    if args.sigma is None:\n        valid = get_valid(args.dataset, limit_size = args.limit_size, fold = args.fold)\n        sigma_range = numpy.logspace(args.sigma_start, args.sigma_end, num=args.cross_val)\n        sigma = cross_validate_sigma(samples, valid, sigma_range, batch_size)\n    else:\n        sigma = float(args.sigma)\n\n    print \"Using Sigma: {}\".format(sigma)\n    gc.collect()\n\n    # fit and evaulate\n    parzen = theano_parzen(samples, sigma)\n    ll = get_nll(test.X, parzen, batch_size = batch_size)\n    se = ll.std() / numpy.sqrt(test.X.shape[0])\n\n    print \"Log-Likelihood of test set = {}, se: {}\".format(ll.mean(), se)\n\n    # valid\n    if args.valid:\n        valid = get_valid(args.dataset)\n        ll = get_nll(valid, parzen, batch_size = batch_size)\n        se = ll.std() / numpy.sqrt(valid.shape[0])\n        print \"Log-Likelihood of valid set = {}, se: {}\".format(ll.mean(), se)\n\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "name": "sgd.py",
          "type": "blob",
          "size": 45.6865234375,
          "content": "\"\"\"\nCopy of pylearn2's sgd.py, hacked to support doing steps on\ndiscriminator separately from the generator. Ideally this would\nbe accomplished using pylearn2's FixedVarDescr implementation,\nbut it is currently not very well supported.\n\"\"\"\nfrom __future__ import division\n\n__authors__ = \"Ian Goodfellow\"\n__copyright__ = \"Copyright 2010-2012, Universite de Montreal\"\n__credits__ = [\"Ian Goodfellow, David Warde-Farley\"]\n__license__ = \"3-clause BSD\"\n__maintainer__ = \"David Warde-Farley\"\n__email__ = \"pylearn-dev@googlegroups\"\n\nimport logging\nimport warnings\nimport numpy as np\n\nfrom theano import config\nfrom theano import function\nfrom theano.compat.python2x import OrderedDict\nfrom theano.gof.op import get_debug_values\n\nfrom pylearn2.monitor import Monitor\nfrom pylearn2.space import CompositeSpace, NullSpace\nfrom pylearn2.train_extensions import TrainExtension\nfrom pylearn2.training_algorithms.training_algorithm import TrainingAlgorithm\nfrom pylearn2.training_algorithms.learning_rule import Momentum\nfrom pylearn2.training_algorithms.learning_rule import MomentumAdjustor \\\n        as LRMomentumAdjustor\nfrom pylearn2.utils.iteration import is_stochastic, has_uniform_batch_size\nfrom pylearn2.utils import py_integer_types, py_float_types\nfrom pylearn2.utils import safe_zip\nfrom pylearn2.utils import serial\nfrom pylearn2.utils import sharedX\nfrom pylearn2.utils.data_specs import DataSpecsMapping\nfrom pylearn2.utils.timing import log_timing\nfrom pylearn2.utils.rng import make_np_rng\n\n\nlog = logging.getLogger(__name__)\n\n\nclass SGD(TrainingAlgorithm):\n    \"\"\"\n    SGD = (Minibatch) Stochastic Gradient Descent.\n    A TrainingAlgorithm that does stochastic gradient descent on minibatches\n    of training examples.\n\n    For theoretical background on this algorithm, see Yoshua Bengio's machine\n    learning course notes on the subject:\n\n    http://www.iro.umontreal.ca/~pift6266/H10/notes/gradient.html\n\n    Parameters\n    ----------\n    learning_rate : float\n        The learning rate to use. Train object callbacks can change the\n        learning rate after each epoch. SGD update_callbacks can change\n        it after each minibatch.\n    cost : pylearn2.costs.cost.Cost, optional\n        Cost object specifying the objective function to be minimized.\n        Optionally, may be None. In this case, SGD will call the model's\n        get_default_cost method to obtain the objective function.\n    batch_size : int, optional\n        The size of the batch to be used.\n        If not specified, the model will be asked for the batch size, so\n        you must have specified the batch size there.\n        (Some models are rigidly defined to only work with one batch size)\n    monitoring_batch_size : int, optional\n        The size of the monitoring batches.\n    monitoring_batches : int, optional\n        At the start of each epoch, we run \"monitoring\", to evaluate\n        quantities such as the validation set error.\n        monitoring_batches, if specified, determines the number of batches\n        to draw from the iterator for each monitoring dataset.\n        Unnecessary if not using monitoring or if `monitor_iteration_mode`\n        is 'sequential' and `batch_size` is specified (number of\n        batches will be calculated based on full dataset size).\n        TODO: make it possible to specify different monitoring_batches\n        for each monitoring dataset. The Monitor itself already supports\n        this.\n    monitoring_dataset : Dataset or dictionary, optional\n        If not specified, no monitoring is used.\n        If specified to be a Dataset, monitor on that Dataset.\n        If specified to be dictionary, the keys should be string names\n        of datasets, and the values should be Datasets. All monitoring\n        channels will be computed for all monitoring Datasets and will\n        have the dataset name and an underscore prepended to them.\n    monitor_iteration_mode : str, optional\n        The iteration mode used to iterate over the examples in all\n        monitoring datasets. If not specified, defaults to 'sequential'.\n        TODO: make it possible to specify different modes for different\n        datasets.\n    termination_criterion : instance of \\\n        pylearn2.termination_criteria.TerminationCriterion, optional\n\n        Used to determine when the algorithm should stop running.\n        If not specified, runs forever--or more realistically, until\n        external factors halt the python process (Kansas 1977).\n    update_callbacks : list, optional\n        If specified, each member of the list should be a callable that\n        accepts an SGD instance as its only argument.\n        All callbacks will be called with this SGD instance after each\n        SGD step.\n    learning_rule : training_algorithms.learning_rule.LearningRule, optional\n        A learning rule computes the new parameter values given old\n        parameters and first-order gradients. If learning_rule is None,\n        sgd.SGD will update parameters according to the standard SGD\n        learning rule:\n\n        .. code-block:: none\n\n            param := param - learning_rate * d cost / d param\n\n        This argument allows more sophisticated learning rules, such\n        as SGD with momentum.\n    init_momentum : float, **DEPRECATED** option\n        Use learning_rule instead.\n        If None, does not use momentum otherwise, use momentum and\n        initialize the momentum coefficient to init_momentum. Callbacks\n        can change this over time just like the learning rate. If the\n        gradient is the same on every step, then the update taken by the\n        SGD algorithm is scaled by a factor of 1/(1-momentum). See\n        section 9 of Geoffrey Hinton's \"A Practical Guide to Training\n        Restricted Boltzmann Machines\" for details.\n    set_batch_size : bool, optional\n        Defaults to False.\n        If True, and batch_size conflicts with model.force_batch_size,\n        will call model.set_batch_size(batch_size) in an attempt to\n        change model.force_batch_size\n    train_iteration_mode : str, optional\n        Defaults to 'shuffled_sequential'.\n        The iteration mode to use for iterating through training examples.\n    batches_per_iter : int, optional\n        The number of batches to draw from the iterator over training\n        examples.\n        If iteration mode is 'sequential' or 'shuffled_sequential', this\n        is unnecessary; when unspecified we will iterate over all examples.\n    theano_function_mode : a valid argument to theano.function's \\\n        'mode' parameter, optional\n\n        The theano mode to compile the updates function with. Note that\n        pylearn2 includes some wraplinker modes that are not bundled with\n        theano. See pylearn2.devtools. These extra modes let you do\n        things like check for NaNs at every step, or record md5 digests\n        of all computations performed by the update function to help\n        isolate problems with nondeterminism.\n    monitoring_costs : list, optional\n        a list of Cost instances. The Monitor will also include all\n        channels defined by these Costs, even though we don't train\n        using them.\n    seed : valid argument to np.random.RandomState, optional\n        The seed used for the random number generate to be passed to the\n        training dataset iterator (if any)\n    \"\"\"\n    def __init__(self, learning_rate, cost=None, batch_size=None,\n                 monitoring_batch_size=None, monitoring_batches=None,\n                 monitoring_dataset=None, monitor_iteration_mode='sequential',\n                 termination_criterion=None, update_callbacks=None,\n                 learning_rule = None, init_momentum = None,\n                 set_batch_size = False,\n                 train_iteration_mode = None, batches_per_iter=None,\n                 theano_function_mode = None, monitoring_costs=None,\n                 seed=[2012, 10, 5], discriminator_steps=1):\n        self.discriminator_steps = discriminator_steps\n\n        if isinstance(cost, (list, tuple, set)):\n            raise TypeError(\"SGD no longer supports using collections of \" +\n                            \"Costs to represent a sum of Costs. Use \" +\n                            \"pylearn2.costs.cost.SumOfCosts instead.\")\n\n        if init_momentum:\n            warnings.warn(\"init_momentum interface is deprecated and will \"\n            \"become officially unsuported as of May 9, 2014. Please use the \"\n            \"`learning_rule` parameter instead, providing an object of type \"\n            \"`pylearn2.training_algorithms.learning_rule.Momentum` instead\")\n            # Convert to new interface under the hood.\n            self.learning_rule = Momentum(init_momentum)\n        else:\n            self.learning_rule = learning_rule\n\n        self.learning_rate = sharedX(learning_rate, 'learning_rate')\n        self.cost = cost\n        self.batch_size = batch_size\n        self.set_batch_size = set_batch_size\n        self.batches_per_iter = batches_per_iter\n        self._set_monitoring_dataset(monitoring_dataset)\n        self.monitoring_batch_size = monitoring_batch_size\n        self.monitoring_batches = monitoring_batches\n        self.monitor_iteration_mode = monitor_iteration_mode\n        if monitoring_dataset is None:\n            if monitoring_batch_size is not None:\n                raise ValueError(\"Specified a monitoring batch size \" +\n                                 \"but not a monitoring dataset.\")\n            if monitoring_batches is not None:\n                raise ValueError(\"Specified an amount of monitoring batches \" +\n                                 \"but not a monitoring dataset.\")\n        self.termination_criterion = termination_criterion\n        self._register_update_callbacks(update_callbacks)\n        if train_iteration_mode is None:\n            train_iteration_mode = 'shuffled_sequential'\n        self.train_iteration_mode = train_iteration_mode\n        self.first = True\n        self.rng = make_np_rng(seed, which_method=[\"randn\",\"randint\"])\n        self.theano_function_mode = theano_function_mode\n        self.monitoring_costs = monitoring_costs\n\n    def setup(self, model, dataset):\n        \"\"\"\n        Compiles the theano functions needed for the train method.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        \"\"\"\n        self.i = 0\n        if self.cost is None:\n            self.cost = model.get_default_cost()\n\n        inf_params = [param for param in model.get_params()\n                      if np.any(np.isinf(param.get_value()))]\n        if len(inf_params) > 0:\n            raise ValueError(\"These params are Inf: \"+str(inf_params))\n        if any([np.any(np.isnan(param.get_value()))\n                for param in model.get_params()]):\n            nan_params = [param for param in model.get_params()\n                          if np.any(np.isnan(param.get_value()))]\n            raise ValueError(\"These params are NaN: \"+str(nan_params))\n        self.model = model\n\n        self._synchronize_batch_size(model)\n        model._test_batch_size = self.batch_size\n        self.monitor = Monitor.get_monitor(model)\n        self.monitor._sanity_check()\n\n        # test if force batch size and batch size\n        if getattr(model, \"force_batch_size\", False) and \\\n           any(dataset.get_design_matrix().shape[0] % self.batch_size != 0 for\n               dataset in self.monitoring_dataset.values()) and \\\n           not has_uniform_batch_size(self.monitor_iteration_mode):\n\n            raise ValueError(\"Dataset size is not a multiple of batch size.\"\n                             \"You should set monitor_iteration_mode to \"\n                             \"even_sequential, even_shuffled_sequential or \"\n                             \"even_batchwise_shuffled_sequential\")\n\n        data_specs = self.cost.get_data_specs(self.model)\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n\n        # Build a flat tuple of Theano Variables, one for each space.\n        # We want that so that if the same space/source is specified\n        # more than once in data_specs, only one Theano Variable\n        # is generated for it, and the corresponding value is passed\n        # only once to the compiled Theano function.\n        theano_args = []\n        for space, source in safe_zip(space_tuple, source_tuple):\n            name = '%s[%s]' % (self.__class__.__name__, source)\n            arg = space.make_theano_batch(name=name,\n                                          batch_size=self.batch_size)\n            theano_args.append(arg)\n        theano_args = tuple(theano_args)\n\n        # Methods of `self.cost` need args to be passed in a format compatible\n        # with data_specs\n        nested_args = mapping.nest(theano_args)\n        fixed_var_descr = self.cost.get_fixed_var_descr(model, nested_args)\n        self.on_load_batch = fixed_var_descr.on_load_batch\n\n        cost_value = self.cost.expr(model, nested_args,\n                                    ** fixed_var_descr.fixed_vars)\n\n        if cost_value is not None and cost_value.name is None:\n            # Concatenate the name of all tensors in theano_args !?\n            cost_value.name = 'objective'\n\n        # Set up monitor to model the objective value, learning rate,\n        # momentum (if applicable), and extra channels defined by\n        # the cost\n        learning_rate = self.learning_rate\n        if self.monitoring_dataset is not None:\n            if (self.monitoring_batch_size is None and\n                    self.monitoring_batches is None):\n                self.monitoring_batch_size = self.batch_size\n                self.monitoring_batches = self.batches_per_iter\n            self.monitor.setup(dataset=self.monitoring_dataset,\n                               cost=self.cost,\n                               batch_size=self.monitoring_batch_size,\n                               num_batches=self.monitoring_batches,\n                               extra_costs=self.monitoring_costs,\n                               mode=self.monitor_iteration_mode)\n            dataset_name = self.monitoring_dataset.keys()[0]\n            monitoring_dataset = self.monitoring_dataset[dataset_name]\n            #TODO: have Monitor support non-data-dependent channels\n            self.monitor.add_channel(name='learning_rate',\n                                     ipt=None,\n                                     val=learning_rate,\n                                     data_specs=(NullSpace(), ''),\n                                     dataset=monitoring_dataset)\n\n            if self.learning_rule:\n                self.learning_rule.add_channels_to_monitor(\n                        self.monitor,\n                        monitoring_dataset)\n\n        params = list(model.get_params())\n        assert len(params) > 0\n        for i, param in enumerate(params):\n            if param.name is None:\n                param.name = 'sgd_params[%d]' % i\n        self.params = params\n\n\n        grads, updates = self.cost.get_gradients(model, nested_args,\n                                                 ** fixed_var_descr.fixed_vars)\n        if not isinstance(grads, OrderedDict):\n            raise TypeError(str(type(self.cost)) + \".get_gradients returned \" +\n                            \"something with\" + str(type(grads)) + \"as its \" +\n                            \"first member. Expected OrderedDict.\")\n\n        for param in grads:\n            assert param in params\n        for param in params:\n            assert param in grads\n\n        lr_scalers = model.get_lr_scalers()\n\n        for key in lr_scalers:\n            if key not in params:\n                raise ValueError(\"Tried to scale the learning rate on \" +\\\n                        str(key)+\" which is not an optimization parameter.\")\n\n        assert len(updates.keys()) == 0\n\n        def get_func(learn_discriminator, learn_generator):\n\n            updates = OrderedDict()\n\n            assert (learn_discriminator or learn_generator) and not (learn_discriminator and learn_generator)\n\n            if learn_discriminator:\n                cur_params = model.discriminator.get_params()\n            else:\n                cur_params = model.generator.get_params()\n\n            cur_grads = OrderedDict()\n            for param in cur_params:\n                cur_grads[param] = grads[param]\n\n            for param in grads:\n                if grads[param].name is None and cost_value is not None:\n                    grads[param].name = ('grad(%(costname)s, %(paramname)s)' %\n                                         {'costname': cost_value.name,\n                                          'paramname': param.name})\n                assert grads[param].dtype == param.dtype\n\n            cur_lr_scalers = OrderedDict()\n            for param in cur_params:\n                if param in lr_scalers:\n                    lr_scaler = lr_scalers[param]\n                    cur_lr_scalers[param] = lr_scaler\n\n            log.info('Parameter and initial learning rate summary:')\n            for param in cur_params:\n                param_name = param.name\n                if param_name is None:\n                    param_name = 'anon_param'\n                lr = learning_rate.get_value() * cur_lr_scalers.get(param,1.)\n                log.info('\\t' + param_name + ': ' + str(lr))\n\n            if self.learning_rule:\n                updates.update(self.learning_rule.get_updates(\n                    learning_rate, cur_grads, cur_lr_scalers))\n            else:\n                # Use standard SGD updates with fixed learning rate.\n                updates.update( dict(safe_zip(params, [param - learning_rate * \\\n                    lr_scalers.get(param, 1.) * grads[param]\n                                        for param in params])))\n\n            for param in cur_params:\n                if updates[param].name is None:\n                    updates[param].name = 'sgd_update(' + param.name + ')'\n            model.modify_updates(updates)\n            for param in cur_params:\n                update = updates[param]\n                if update.name is None:\n                    update.name = 'censor(sgd_update(' + param.name + '))'\n                for update_val in get_debug_values(update):\n                    if np.any(np.isinf(update_val)):\n                        raise ValueError(\"debug value of %s contains infs\" %\n                                update.name)\n                    if np.any(np.isnan(update_val)):\n                        raise ValueError(\"debug value of %s contains nans\" %\n                                update.name)\n\n\n            with log_timing(log, 'Compiling sgd_update'):\n                return function(theano_args,\n                                           updates=updates,\n                                           name='sgd_update',\n                                           on_unused_input='ignore',\n                                           mode=self.theano_function_mode)\n        self.d_func = get_func(1, 0)\n        self.g_func = get_func(0, 1)\n\n    def train(self, dataset):\n        \"\"\"\n        Runs one epoch of SGD training on the specified dataset.\n\n        Parameters\n        ----------\n        dataset : Dataset\n        \"\"\"\n        if not hasattr(self, 'd_func'):\n            raise Exception(\"train called without first calling setup\")\n\n        # Make sure none of the parameters have bad values\n        for param in self.params:\n            value = param.get_value(borrow=True)\n            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n                raise Exception(\"NaN in \" + param.name)\n\n        self.first = False\n        rng = self.rng\n        if not is_stochastic(self.train_iteration_mode):\n            rng = None\n\n        data_specs = self.cost.get_data_specs(self.model)\n\n        # The iterator should be built from flat data specs, so it returns\n        # flat, non-redundent tuples of data.\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n        if len(space_tuple) == 0:\n            # No data will be returned by the iterator, and it is impossible\n            # to know the size of the actual batch.\n            # It is not decided yet what the right thing to do should be.\n            raise NotImplementedError(\"Unable to train with SGD, because \"\n                    \"the cost does not actually use data from the data set. \"\n                    \"data_specs: %s\" % str(data_specs))\n        flat_data_specs = (CompositeSpace(space_tuple), source_tuple)\n\n        iterator = dataset.iterator(mode=self.train_iteration_mode,\n                batch_size=self.batch_size,\n                data_specs=flat_data_specs, return_tuple=True,\n                rng = rng, num_batches = self.batches_per_iter)\n\n        on_load_batch = self.on_load_batch\n        i = self.i\n        for batch in iterator:\n            for callback in on_load_batch:\n                callback(*batch)\n            self.d_func(*batch)\n            i += 1\n            if i == self.discriminator_steps:\n                # Generator doesn't actually use the data so we want to\n                # re-use this batch. Could save memory by making the\n                # code not expect data in the interface.\n                self.g_func(*batch)\n                i = 0\n            # iterator might return a smaller batch if dataset size\n            # isn't divisible by batch_size\n            # Note: if data_specs[0] is a NullSpace, there is no way to know\n            # how many examples would actually have been in the batch,\n            # since it was empty, so actual_batch_size would be reported as 0.\n            actual_batch_size = flat_data_specs[0].np_batch_size(batch)\n            self.monitor.report_batch(actual_batch_size)\n            for callback in self.update_callbacks:\n                callback(self)\n\n        # Make sure none of the parameters have bad values\n        for param in self.params:\n            value = param.get_value(borrow=True)\n            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n                raise Exception(\"NaN in \" + param.name)\n        self.i = i\n\n    def continue_learning(self, model):\n        \"\"\"\n        Returns True if the algorithm should continue running, or False\n        if it has reached convergence / started overfitting and should\n        stop.\n\n        Parameters\n        ----------\n        model : a Model instance\n        \"\"\"\n        if self.termination_criterion is None:\n            return True\n        else:\n            return self.termination_criterion.continue_learning(self.model)\n\nclass MonitorBasedLRAdjuster(TrainExtension):\n    \"\"\"\n    A TrainExtension that uses the on_monitor callback to adjust\n    the learning rate on each epoch. It pulls out a channel\n    from the model's monitor and adjusts the learning rate\n    based on what happened to the monitoring channel on the last\n    epoch. If the channel is greater than high_trigger times\n    its previous value, the learning rate will be scaled by\n    shrink_amt (which should be < 1 for this scheme to make\n    sense). The idea is that in this case the learning algorithm\n    is overshooting the bottom of the objective function.\n\n    If the objective is less than high_trigger but\n    greater than low_trigger times its previous value, the\n    learning rate will be scaled by grow_amt (which should be > 1\n    for this scheme to make sense). The idea is that the learning\n    algorithm is making progress but at too slow of a rate.\n\n    Parameters\n    ----------\n    high_trigger : float, optional\n        See class-level docstring\n    low_trigger : float, optional\n        See class-level docstring\n    grow_amt : float, optional\n        See class-level docstring\n    min_lr : float, optional\n        All updates to the learning rate are clipped to be at least\n        this value.\n    max_lr : float, optional\n        All updates to the learning rate are clipped to be at most\n        this value.\n    dataset_name : str, optional\n        If specified, use dataset_name + \"_objective\" as the channel\n        to guide the learning rate adaptation.\n    channel_name : str, optional\n        If specified, use channel_name as the channel to guide the\n        learning rate adaptation. Conflicts with dataset_name.\n        If neither dataset_name nor channel_name is specified, uses\n        \"objective\"\n    \"\"\"\n\n    def __init__(self, high_trigger=1., shrink_amt=.99,\n                 low_trigger=.99, grow_amt=1.01,\n                 min_lr = 1e-7, max_lr = 1.,\n                 dataset_name=None, channel_name=None):\n        self.high_trigger = high_trigger\n        self.shrink_amt = shrink_amt\n        self.low_trigger = low_trigger\n        self.grow_amt = grow_amt\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.dataset_name = None\n        if channel_name is not None:\n            self.channel_name = channel_name\n        else:\n            if dataset_name is not None:\n                self.channel_name = dataset_name + '_objective'\n                self.dataset_name = dataset_name\n            else:\n                self.channel_name = None\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate based on the contents of model.monitor\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        model = algorithm.model\n        lr = algorithm.learning_rate\n        current_learning_rate = lr.get_value()\n        assert hasattr(model, 'monitor'), (\"no monitor associated with \"\n                + str(model))\n        monitor = model.monitor\n        monitor_channel_specified = True\n\n        if self.channel_name is None:\n            monitor_channel_specified = False\n            channels = [elem for elem in monitor.channels\n                    if elem.endswith(\"objective\")]\n            if len(channels) < 1:\n                raise ValueError(\"There are no monitoring channels that end \"\n                        \"with \\\"objective\\\". Please specify either \"\n                        \"channel_name or dataset_name.\")\n            elif len(channels) > 1:\n                datasets = algorithm.monitoring_dataset.keys()\n                raise ValueError(\"There are multiple monitoring channels that\"\n                        \"end with \\\"_objective\\\". The list of available \"\n                        \"datasets are: \" +\n                                str(datasets) + \" . Please specify either \"\n                                \"channel_name or dataset_name in the \"\n                                \"MonitorBasedLRAdjuster constructor to \"\n                                'disambiguate.')\n            else:\n                self.channel_name = channels[0]\n                warnings.warn('The channel that has been chosen for '\n                        'monitoring is: ' +\n                              str(self.channel_name) + '.')\n\n        try:\n            v = monitor.channels[self.channel_name].val_record\n        except KeyError:\n            err_input = ''\n            if monitor_channel_specified:\n                if self.dataset_name:\n                    err_input = 'The dataset_name \\'' + str(\n                            self.dataset_name) + '\\' is not valid.'\n                else:\n                    err_input = 'The channel_name \\'' + str(\n                            self.channel_name) + '\\' is not valid.'\n            err_message = 'There is no monitoring channel named \\'' + \\\n                    str(self.channel_name) + '\\'. You probably need to ' + \\\n                    'specify a valid monitoring channel by using either ' + \\\n                    'dataset_name or channel_name in the ' + \\\n                    'MonitorBasedLRAdjuster constructor. ' + err_input\n            raise ValueError(err_message)\n\n        if len(v) < 1:\n            if monitor.dataset is None:\n                assert len(v) == 0\n                raise ValueError(\"You're trying to use a monitor-based \"\n                        \"learning rate adjustor but the monitor has no \"\n                        \"entries because you didn't specify a \"\n                        \"monitoring dataset.\")\n\n            raise ValueError(\"For some reason there are no monitor entries\"\n                                 \"yet the MonitorBasedLRAdjuster has been \"\n                                 \"called. This should never happen. The Train\"\n                                 \" object should call the monitor once on \"\n                                 \"initialization, then call the callbacks. \"\n                                 \"It seems you are either calling the \"\n                                 \"callback manually rather than as part of a \"\n                                 \"training algorithm, or there is a problem \"\n                                \"with the Train object.\")\n        if len(v) == 1:\n            #only the initial monitoring has happened\n            #no learning has happened, so we can't adjust the learning rate yet\n            #just do nothing\n            return\n\n        rval = current_learning_rate\n\n        log.info(\"monitoring channel is {0}\".format(self.channel_name))\n\n        if v[-1] > self.high_trigger * v[-2]:\n            rval *= self.shrink_amt\n            log.info(\"shrinking learning rate to %f\" % rval)\n        elif v[-1] > self.low_trigger * v[-2]:\n            rval *= self.grow_amt\n            log.info(\"growing learning rate to %f\" % rval)\n\n        rval = max(self.min_lr, rval)\n        rval = min(self.max_lr, rval)\n\n        lr.set_value(np.cast[lr.dtype](rval))\n\n\nclass PatienceBasedTermCrit(object):\n    \"\"\"\n    A monitor-based termination criterion using a geometrically increasing\n    amount of patience. If the selected channel has decreased by a certain\n    proportion when comparing to the lowest value seen yet, the patience is\n    set to a factor of the number of examples seen, which by default\n    (patience_increase=2.) ensures the model has seen as many examples as the\n    number of examples that lead to the lowest value before concluding a local\n    optima has been reached.\n\n    Note: Technically, the patience corresponds to a number of epochs to be\n    independent of the size of the dataset, so be aware of that when choosing\n    initial_patience.\n\n    Parameters\n    ----------\n    prop_decrease : float\n        The factor X in the (1 - X) * best_value threshold\n    initial_patience : int\n        Minimal number of epochs the model has to run before it can stop\n    patience_increase : float, optional\n        The factor X in the patience = X * n_iter update.\n    channel_name : string, optional\n        Name of the channel to examine. If None and the monitor\n        has only one channel, this channel will be used; otherwise, an\n        error will be raised.\n    \"\"\"\n    def __init__(self, prop_decrease, initial_patience,\n                 patience_increase=2., channel_name=None):\n        self._channel_name = channel_name\n        self.prop_decrease = prop_decrease\n        self.patience = initial_patience\n        self.best_value = np.inf\n        self.patience_increase = patience_increase\n\n    def __call__(self, model):\n        \"\"\"\n        Returns True or False depending on whether the optimization should\n        stop or not. The optimization should stop if it has run for a number\n        of epochs superior to the patience without any improvement.\n\n        Parameters\n        ----------\n        model : Model\n            The model used in the experiment and from which the monitor used\n            in the termination criterion will be extracted.\n\n        Returns\n        -------\n        bool\n            True or False, indicating if the optimization should stop or not.\n        \"\"\"\n        monitor = model.monitor\n        # In the case the monitor has only one channel, the channel_name can\n        # be omitted and the criterion will examine the only channel\n        # available. However, if the monitor has multiple channels, leaving\n        # the channel_name unspecified will raise an error.\n        if self._channel_name is None:\n            if len(monitor.channels) != 1:\n                raise ValueError(\"Only single-channel monitors are supported \"\n                                 \"for channel_name == None\")\n            v = monitor.channels.values()[0].val_record\n        else:\n            v = monitor.channels[self._channel_name].val_record\n        # If the channel value decrease is higher than the threshold, we\n        # update the best value to this value and we update the patience.\n        if v[-1] < self.best_value * (1. - self.prop_decrease):\n            # Using the max between actual patience and updated patience\n            # ensures that the model will run for at least the initial\n            # patience and that it would behave correctly if the user\n            # chooses a dumb value (i.e. less than 1)\n            self.patience = max(self.patience, len(v) * self.patience_increase)\n            self.best_value = v[-1]\n\n        return len(v) < self.patience\n\n\nclass AnnealedLearningRate(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decrease as 1/t where t is the number\n    of gradient descent updates done so far. Use OneOverEpoch as Train object\n    callback if you would prefer 1/t where t is epochs.\n\n    Parameters\n    ----------\n    anneal_start : int\n        The epoch on which to begin annealing\n    \"\"\"\n    def __init__(self, anneal_start):\n        self._initialized = False\n        self._count = 0\n        self._anneal_start = anneal_start\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the annealing schedule.\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._base = algorithm.learning_rate.get_value()\n        self._count += 1\n        algorithm.learning_rate.set_value(self.current_learning_rate())\n\n    def current_learning_rate(self):\n        \"\"\"\n        Returns the current desired learning rate according to the\n        annealing schedule.\n        \"\"\"\n        return self._base * min(1, self._anneal_start / self._count)\n\nclass ExponentialDecay(object):\n    \"\"\"\n    This is a callback for the `SGD` algorithm rather than the `Train` object.\n    This anneals the learning rate by dividing by decay_factor after each\n    gradient descent step. It will not shrink the learning rate beyond\n    `min_lr`.\n\n    Parameters\n    ----------\n    decay_factor : float\n        The learning rate at step t is given by\n        `init_learning_rate / (decay_factor ** t)`\n    min_lr : float\n        The learning rate will be clipped to be at least this value\n    \"\"\"\n\n    def __init__(self, decay_factor, min_lr):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(min_lr, str):\n            min_lr = float(min_lr)\n        assert isinstance(decay_factor, float)\n        assert isinstance(min_lr, float)\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        self._min_reached = False\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the exponential decay schedule.\n\n        Parameters\n        ----------\n        algorithm : SGD\n            The SGD instance whose `learning_rate` field should be modified.\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n        self._count += 1\n\n        if not self._min_reached:\n            # If we keep on executing the exponentiation on each mini-batch,\n            # we will eventually get an OverflowError. So make sure we\n            # only do the computation until min_lr is reached.\n            new_lr = self._base_lr / (self.decay_factor ** self._count)\n            if new_lr <= self.min_lr:\n                self._min_reached = True\n                new_lr = self.min_lr\n        else:\n            new_lr = self.min_lr\n\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\nclass LinearDecay(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decay_factor times of the initial value\n    during time start till saturate.\n\n    Parameters\n    ----------\n    start : int\n        The step at which to start decreasing the learning rate\n    saturate : int\n        The step at which to stop decreating the learning rate\n    decay_factor : float\n        `final learning rate = decay_factor * initial learning rate`\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(start, str):\n            start = float(start)\n        if isinstance(saturate, str):\n            saturate = float(saturate)\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start > 0\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the linear decay schedule\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._base_lr - self._base_lr * self.decay_factor) /\n                          (self.saturate - self.start + 1))\n        self._count += 1\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._base_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._base_lr * self.decay_factor\n        else:\n            new_lr = self._base_lr\n        assert new_lr > 0\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\n\ndef MomentumAdjustor(final_momentum, start, saturate):\n    \"\"\"\n    Deprecated class used with the deprecated init_momentum argument.\n    Use learning_rule.MomentumAdjustor instead.\n\n    Parameters\n    ----------\n    final_momentum : WRITEME\n    start : WRITEME\n    saturate : WRITEME\n    \"\"\"\n    warnings.warn(\"sgd.MomentumAdjustor interface is deprecated and will \"\n    \"become officially unsupported as of May 9, 2014. Please use \"\n    \"`learning_rule.MomentumAdjustor` instead.\")\n    return LRMomentumAdjustor(final_momentum, start, saturate)\n\n\nclass OneOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate like one over # epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    half_life : int, optional\n        How many epochs after start it will take for the learning rate to lose\n        half its value for the first time (to lose the next half of its value\n        will take twice as long)\n    min_lr : float, optional\n        The minimum value the learning rate can take on\n    \"\"\"\n    def __init__(self, start, half_life = None, min_lr = 1e-6):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert start >= 0\n        if half_life is None:\n            self.half_life = start + 1\n        else:\n            assert half_life > 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            if self._init_lr < self.min_lr:\n                raise ValueError(\"The initial learning rate is smaller than \" +\n                                 \"the minimum allowed learning rate.\")\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count < self.start:\n            scale = 1\n        else:\n            scale = float(self.half_life) / float(self._count - self.start\n                    + self.half_life)\n        lr = self._init_lr * scale\n        clipped = max(self.min_lr, lr)\n        return clipped\n\nclass LinearDecayOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate linearly on each epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    saturate : int\n        The epoch to saturate the shrinkage\n    decay_factor : float\n        The final value would be initial learning rate times decay_factor\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start >= 0\n        assert saturate >= start\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Updates the learning rate based on the linear decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._init_lr - self._init_lr * self.decay_factor) /\n                          (self.saturate - self.start + 1))\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._init_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._init_lr * self.decay_factor\n        else:\n            new_lr = self._init_lr\n        assert new_lr > 0\n        return new_lr\n\nclass _PolyakWorker(object):\n    \"\"\"\n    Only to be used by the PolyakAveraging TrainingCallback below.\n    Do not use directly.\n    A callback for the SGD class.\n\n    Parameters\n    ----------\n    model : a Model\n        The model whose parameters we want to train with Polyak averaging\n    \"\"\"\n\n    def __init__(self, model):\n        avg_updates = OrderedDict()\n        t = sharedX(1.)\n        self.param_to_mean = OrderedDict()\n        for param in model.get_params():\n            mean = sharedX(param.get_value())\n            assert type(mean) == type(param)\n            self.param_to_mean[param] = mean\n            avg_updates[mean] = mean - (mean - param) / t\n            avg_updates[t] = t + 1.\n        self.avg = function([], updates = avg_updates)\n\n    def __call__(self, algorithm):\n        \"\"\"\n        To be called after each SGD step.\n        Updates the Polyak averaged-parameters for this model\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        self.avg()\n\nclass PolyakAveraging(TrainExtension):\n    \"\"\"\n    See \"A Tutorial on Stochastic Approximation Algorithms\n        for Training Restricted Boltzmann Machines and\n        Deep Belief Nets\" by Kevin Swersky et al\n\n    This functionality is still a work in progress. Currently,\n    your model needs to implement \"add_polyak_channels\" to\n    use it.\n\n    The problem is that Polyak averaging shouldn't modify\n    the model parameters. It should keep a second copy\n    that it averages in the background. This second copy\n    doesn't get to come back in and affect the learning process\n    though.\n\n    (IG tried having the second copy get pushed back into\n    the model once per epoch, but this turned out to be\n    harmful, at least in limited tests)\n\n    So we need a cleaner interface for monitoring the\n    averaged copy of the parameters, and we need to make\n    sure the saved model at the end uses the averaged\n    parameters, not the parameters used for computing\n    the gradients during training.\n\n    TODO: make use of the new on_save callback instead\n        of duplicating Train's save_freq flag\n\n    Parameters\n    ----------\n    start : int\n        The epoch after which to start averaging (0 = start averaging\n        immediately)\n    save_path : str, optional\n        WRITEME\n    save_freq : int, optional\n        WRITEME\n\n    Notes\n    -----\n    This is usually used with a fixed, rather than annealed learning\n    rate. It may be used in conjunction with momentum.\n    \"\"\"\n\n    def __init__(self, start, save_path=None, save_freq=1):\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        assert isinstance(start, py_integer_types)\n        assert start >= 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Make sure Polyak-averaged model gets monitored.\n        Save the model if necessary.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == self.start:\n            self._worker = _PolyakWorker(model)\n            algorithm.update_callbacks.append(self._worker)\n            #HACK\n            try:\n                model.add_polyak_channels(self._worker.param_to_mean,\n                                          algorithm.monitoring_dataset)\n            except AttributeError:\n                pass\n        elif self.save_path is not None and self._count > self.start and \\\n                self._count % self.save_freq == 0:\n            saved_params = OrderedDict()\n            for param in model.get_params():\n                saved_params[param] = param.get_value()\n                param.set_value(self._worker.param_to_mean[param].get_value())\n            serial.save(self.save_path, model)\n            for param in model.get_params():\n                param.set_value(saved_params[param])\n        self._count += 1\n"
        },
        {
          "name": "sgd_alt.py",
          "type": "blob",
          "size": 45.8212890625,
          "content": "\"\"\"\nCopy of pylearn2's sgd.py, hacked to support alternating between\nepochs of updating only the discriminator and epochs of updating\nboth discriminator and generator. Ideally this would\nbe accomplished using pylearn2's FixedVarDescr implementation,\nbut it is currently not very well supported.\n\"\"\"\nfrom __future__ import division\n\n__authors__ = \"Ian Goodfellow\"\n__copyright__ = \"Copyright 2010-2012, Universite de Montreal\"\n__credits__ = [\"Ian Goodfellow, David Warde-Farley\"]\n__license__ = \"3-clause BSD\"\n__maintainer__ = \"David Warde-Farley\"\n__email__ = \"pylearn-dev@googlegroups\"\n\nimport logging\nimport warnings\nimport numpy as np\n\nfrom theano import config\nfrom theano import function\nfrom theano.compat.python2x import OrderedDict\nfrom theano.gof.op import get_debug_values\n\nfrom pylearn2.monitor import Monitor\nfrom pylearn2.space import CompositeSpace, NullSpace\nfrom pylearn2.train_extensions import TrainExtension\nfrom pylearn2.training_algorithms.training_algorithm import TrainingAlgorithm\nfrom pylearn2.training_algorithms.learning_rule import Momentum\nfrom pylearn2.training_algorithms.learning_rule import MomentumAdjustor \\\n        as LRMomentumAdjustor\nfrom pylearn2.utils.iteration import is_stochastic, has_uniform_batch_size\nfrom pylearn2.utils import py_integer_types, py_float_types\nfrom pylearn2.utils import safe_zip\nfrom pylearn2.utils import serial\nfrom pylearn2.utils import sharedX\nfrom pylearn2.utils.data_specs import DataSpecsMapping\nfrom pylearn2.utils.timing import log_timing\nfrom pylearn2.utils.rng import make_np_rng\n\n\nlog = logging.getLogger(__name__)\n\n\nclass SGD(TrainingAlgorithm):\n    \"\"\"\n    SGD = (Minibatch) Stochastic Gradient Descent.\n    A TrainingAlgorithm that does stochastic gradient descent on minibatches\n    of training examples.\n\n    For theoretical background on this algorithm, see Yoshua Bengio's machine\n    learning course notes on the subject:\n\n    http://www.iro.umontreal.ca/~pift6266/H10/notes/gradient.html\n\n    Parameters\n    ----------\n    learning_rate : float\n        The learning rate to use. Train object callbacks can change the\n        learning rate after each epoch. SGD update_callbacks can change\n        it after each minibatch.\n    cost : pylearn2.costs.cost.Cost, optional\n        Cost object specifying the objective function to be minimized.\n        Optionally, may be None. In this case, SGD will call the model's\n        get_default_cost method to obtain the objective function.\n    batch_size : int, optional\n        The size of the batch to be used.\n        If not specified, the model will be asked for the batch size, so\n        you must have specified the batch size there.\n        (Some models are rigidly defined to only work with one batch size)\n    monitoring_batch_size : int, optional\n        The size of the monitoring batches.\n    monitoring_batches : int, optional\n        At the start of each epoch, we run \"monitoring\", to evaluate\n        quantities such as the validation set error.\n        monitoring_batches, if specified, determines the number of batches\n        to draw from the iterator for each monitoring dataset.\n        Unnecessary if not using monitoring or if `monitor_iteration_mode`\n        is 'sequential' and `batch_size` is specified (number of\n        batches will be calculated based on full dataset size).\n        TODO: make it possible to specify different monitoring_batches\n        for each monitoring dataset. The Monitor itself already supports\n        this.\n    monitoring_dataset : Dataset or dictionary, optional\n        If not specified, no monitoring is used.\n        If specified to be a Dataset, monitor on that Dataset.\n        If specified to be dictionary, the keys should be string names\n        of datasets, and the values should be Datasets. All monitoring\n        channels will be computed for all monitoring Datasets and will\n        have the dataset name and an underscore prepended to them.\n    monitor_iteration_mode : str, optional\n        The iteration mode used to iterate over the examples in all\n        monitoring datasets. If not specified, defaults to 'sequential'.\n        TODO: make it possible to specify different modes for different\n        datasets.\n    termination_criterion : instance of \\\n        pylearn2.termination_criteria.TerminationCriterion, optional\n\n        Used to determine when the algorithm should stop running.\n        If not specified, runs forever--or more realistically, until\n        external factors halt the python process (Kansas 1977).\n    update_callbacks : list, optional\n        If specified, each member of the list should be a callable that\n        accepts an SGD instance as its only argument.\n        All callbacks will be called with this SGD instance after each\n        SGD step.\n    learning_rule : training_algorithms.learning_rule.LearningRule, optional\n        A learning rule computes the new parameter values given old\n        parameters and first-order gradients. If learning_rule is None,\n        sgd.SGD will update parameters according to the standard SGD\n        learning rule:\n\n        .. code-block:: none\n\n            param := param - learning_rate * d cost / d param\n\n        This argument allows more sophisticated learning rules, such\n        as SGD with momentum.\n    init_momentum : float, **DEPRECATED** option\n        Use learning_rule instead.\n        If None, does not use momentum otherwise, use momentum and\n        initialize the momentum coefficient to init_momentum. Callbacks\n        can change this over time just like the learning rate. If the\n        gradient is the same on every step, then the update taken by the\n        SGD algorithm is scaled by a factor of 1/(1-momentum). See\n        section 9 of Geoffrey Hinton's \"A Practical Guide to Training\n        Restricted Boltzmann Machines\" for details.\n    set_batch_size : bool, optional\n        Defaults to False.\n        If True, and batch_size conflicts with model.force_batch_size,\n        will call model.set_batch_size(batch_size) in an attempt to\n        change model.force_batch_size\n    train_iteration_mode : str, optional\n        Defaults to 'shuffled_sequential'.\n        The iteration mode to use for iterating through training examples.\n    batches_per_iter : int, optional\n        The number of batches to draw from the iterator over training\n        examples.\n        If iteration mode is 'sequential' or 'shuffled_sequential', this\n        is unnecessary; when unspecified we will iterate over all examples.\n    theano_function_mode : a valid argument to theano.function's \\\n        'mode' parameter, optional\n\n        The theano mode to compile the updates function with. Note that\n        pylearn2 includes some wraplinker modes that are not bundled with\n        theano. See pylearn2.devtools. These extra modes let you do\n        things like check for NaNs at every step, or record md5 digests\n        of all computations performed by the update function to help\n        isolate problems with nondeterminism.\n    monitoring_costs : list, optional\n        a list of Cost instances. The Monitor will also include all\n        channels defined by these Costs, even though we don't train\n        using them.\n    seed : valid argument to np.random.RandomState, optional\n        The seed used for the random number generate to be passed to the\n        training dataset iterator (if any)\n    \"\"\"\n    def __init__(self, learning_rate, cost=None, batch_size=None,\n                 monitoring_batch_size=None, monitoring_batches=None,\n                 monitoring_dataset=None, monitor_iteration_mode='sequential',\n                 termination_criterion=None, update_callbacks=None,\n                 learning_rule = None, init_momentum = None,\n                 set_batch_size = False,\n                 train_iteration_mode = None, batches_per_iter=None,\n                 theano_function_mode = None, monitoring_costs=None,\n                 seed=[2012, 10, 5], discriminator_steps=1):\n\n        self.discriminator_steps = discriminator_steps\n        self.train_generator = 0\n\n        if isinstance(cost, (list, tuple, set)):\n            raise TypeError(\"SGD no longer supports using collections of \" +\n                            \"Costs to represent a sum of Costs. Use \" +\n                            \"pylearn2.costs.cost.SumOfCosts instead.\")\n\n        if init_momentum:\n            warnings.warn(\"init_momentum interface is deprecated and will \"\n            \"become officially unsuported as of May 9, 2014. Please use the \"\n            \"`learning_rule` parameter instead, providing an object of type \"\n            \"`pylearn2.training_algorithms.learning_rule.Momentum` instead\")\n            # Convert to new interface under the hood.\n            self.learning_rule = Momentum(init_momentum)\n        else:\n            self.learning_rule = learning_rule\n\n        self.learning_rate = sharedX(learning_rate, 'learning_rate')\n        self.cost = cost\n        self.batch_size = batch_size\n        self.set_batch_size = set_batch_size\n        self.batches_per_iter = batches_per_iter\n        self._set_monitoring_dataset(monitoring_dataset)\n        self.monitoring_batch_size = monitoring_batch_size\n        self.monitoring_batches = monitoring_batches\n        self.monitor_iteration_mode = monitor_iteration_mode\n        if monitoring_dataset is None:\n            if monitoring_batch_size is not None:\n                raise ValueError(\"Specified a monitoring batch size \" +\n                                 \"but not a monitoring dataset.\")\n            if monitoring_batches is not None:\n                raise ValueError(\"Specified an amount of monitoring batches \" +\n                                 \"but not a monitoring dataset.\")\n        self.termination_criterion = termination_criterion\n        self._register_update_callbacks(update_callbacks)\n        if train_iteration_mode is None:\n            train_iteration_mode = 'shuffled_sequential'\n        self.train_iteration_mode = train_iteration_mode\n        self.first = True\n        self.rng = make_np_rng(seed, which_method=[\"randn\",\"randint\"])\n        self.theano_function_mode = theano_function_mode\n        self.monitoring_costs = monitoring_costs\n\n    def setup(self, model, dataset):\n        \"\"\"\n        Compiles the theano functions needed for the train method.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        \"\"\"\n        if self.cost is None:\n            self.cost = model.get_default_cost()\n\n        inf_params = [param for param in model.get_params()\n                      if np.any(np.isinf(param.get_value()))]\n        if len(inf_params) > 0:\n            raise ValueError(\"These params are Inf: \"+str(inf_params))\n        if any([np.any(np.isnan(param.get_value()))\n                for param in model.get_params()]):\n            nan_params = [param for param in model.get_params()\n                          if np.any(np.isnan(param.get_value()))]\n            raise ValueError(\"These params are NaN: \"+str(nan_params))\n        self.model = model\n\n        self._synchronize_batch_size(model)\n        model._test_batch_size = self.batch_size\n        self.monitor = Monitor.get_monitor(model)\n        self.monitor._sanity_check()\n\n        # test if force batch size and batch size\n        if getattr(model, \"force_batch_size\", False) and \\\n           any(dataset.get_design_matrix().shape[0] % self.batch_size != 0 for\n               dataset in self.monitoring_dataset.values()) and \\\n           not has_uniform_batch_size(self.monitor_iteration_mode):\n\n            raise ValueError(\"Dataset size is not a multiple of batch size.\"\n                             \"You should set monitor_iteration_mode to \"\n                             \"even_sequential, even_shuffled_sequential or \"\n                             \"even_batchwise_shuffled_sequential\")\n\n        data_specs = self.cost.get_data_specs(self.model)\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n\n        # Build a flat tuple of Theano Variables, one for each space.\n        # We want that so that if the same space/source is specified\n        # more than once in data_specs, only one Theano Variable\n        # is generated for it, and the corresponding value is passed\n        # only once to the compiled Theano function.\n        theano_args = []\n        for space, source in safe_zip(space_tuple, source_tuple):\n            name = '%s[%s]' % (self.__class__.__name__, source)\n            arg = space.make_theano_batch(name=name,\n                                          batch_size=self.batch_size)\n            theano_args.append(arg)\n        theano_args = tuple(theano_args)\n\n        # Methods of `self.cost` need args to be passed in a format compatible\n        # with data_specs\n        nested_args = mapping.nest(theano_args)\n        fixed_var_descr = self.cost.get_fixed_var_descr(model, nested_args)\n        self.on_load_batch = fixed_var_descr.on_load_batch\n\n        cost_value = self.cost.expr(model, nested_args,\n                                    ** fixed_var_descr.fixed_vars)\n\n        if cost_value is not None and cost_value.name is None:\n            # Concatenate the name of all tensors in theano_args !?\n            cost_value.name = 'objective'\n\n        # Set up monitor to model the objective value, learning rate,\n        # momentum (if applicable), and extra channels defined by\n        # the cost\n        learning_rate = self.learning_rate\n        if self.monitoring_dataset is not None:\n            if (self.monitoring_batch_size is None and\n                    self.monitoring_batches is None):\n                self.monitoring_batch_size = self.batch_size\n                self.monitoring_batches = self.batches_per_iter\n            self.monitor.setup(dataset=self.monitoring_dataset,\n                               cost=self.cost,\n                               batch_size=self.monitoring_batch_size,\n                               num_batches=self.monitoring_batches,\n                               extra_costs=self.monitoring_costs,\n                               mode=self.monitor_iteration_mode)\n            dataset_name = self.monitoring_dataset.keys()[0]\n            monitoring_dataset = self.monitoring_dataset[dataset_name]\n            #TODO: have Monitor support non-data-dependent channels\n            self.monitor.add_channel(name='learning_rate',\n                                     ipt=None,\n                                     val=learning_rate,\n                                     data_specs=(NullSpace(), ''),\n                                     dataset=monitoring_dataset)\n\n            if self.learning_rule:\n                self.learning_rule.add_channels_to_monitor(\n                        self.monitor,\n                        monitoring_dataset)\n\n        params = list(model.get_params())\n        assert len(params) > 0\n        for i, param in enumerate(params):\n            if param.name is None:\n                param.name = 'sgd_params[%d]' % i\n        self.params = params\n\n\n        grads, updates = self.cost.get_gradients(model, nested_args,\n                                                 ** fixed_var_descr.fixed_vars)\n        if not isinstance(grads, OrderedDict):\n            raise TypeError(str(type(self.cost)) + \".get_gradients returned \" +\n                            \"something with\" + str(type(grads)) + \"as its \" +\n                            \"first member. Expected OrderedDict.\")\n\n        for param in grads:\n            assert param in params\n        for param in params:\n            assert param in grads\n\n        lr_scalers = model.get_lr_scalers()\n\n        for key in lr_scalers:\n            if key not in params:\n                raise ValueError(\"Tried to scale the learning rate on \" +\\\n                        str(key)+\" which is not an optimization parameter.\")\n\n        assert len(updates.keys()) == 0\n\n        def get_func(learn_discriminator, learn_generator, dont_you_fucking_dare_touch_the_generator=False):\n\n            updates = OrderedDict()\n\n            assert (learn_discriminator or learn_generator) and not (learn_discriminator and learn_generator)\n\n            if learn_discriminator:\n                cur_params = model.discriminator.get_params()\n            else:\n                cur_params = model.generator.get_params()\n\n            def check():\n                for param in params:\n                    if param not in cur_params:\n                        assert param not in updates\n\n            cur_grads = OrderedDict()\n            for param in cur_params:\n                cur_grads[param] = grads[param]\n\n            for param in grads:\n                if grads[param].name is None and cost_value is not None:\n                    grads[param].name = ('grad(%(costname)s, %(paramname)s)' %\n                                         {'costname': cost_value.name,\n                                          'paramname': param.name})\n                assert grads[param].dtype == param.dtype\n\n            cur_lr_scalers = OrderedDict()\n            for param in cur_params:\n                if param in lr_scalers:\n                    lr_scaler = lr_scalers[param]\n                    cur_lr_scalers[param] = lr_scaler\n\n            log.info('Parameter and initial learning rate summary:')\n            for param in cur_params:\n                param_name = param.name\n                if param_name is None:\n                    param_name = 'anon_param'\n                lr = learning_rate.get_value() * cur_lr_scalers.get(param,1.)\n                log.info('\\t' + param_name + ': ' + str(lr))\n\n            updates.update(self.learning_rule.get_updates(\n                    learning_rate, cur_grads, cur_lr_scalers))\n            check()\n\n            for param in cur_params:\n                if updates[param].name is None:\n                    updates[param].name = 'sgd_update(' + param.name + ')'\n            check()\n            model.modify_updates(updates)\n            check()\n            for param in cur_params:\n                update = updates[param]\n                if update.name is None:\n                    update.name = 'censor(sgd_update(' + param.name + '))'\n                for update_val in get_debug_values(update):\n                    if np.any(np.isinf(update_val)):\n                        raise ValueError(\"debug value of %s contains infs\" %\n                                update.name)\n                    if np.any(np.isnan(update_val)):\n                        raise ValueError(\"debug value of %s contains nans\" %\n                                update.name)\n\n            check()\n\n            if dont_you_fucking_dare_touch_the_generator:\n                for param in model.generator.get_params():\n                    assert param not in updates\n\n            with log_timing(log, 'Compiling sgd_update'):\n                return function(theano_args,\n                                           updates=updates,\n                                           name='sgd_update',\n                                           on_unused_input='ignore',\n                                           mode=self.theano_function_mode)\n        self.d_func = get_func(1, 0, dont_you_fucking_dare_touch_the_generator=True)\n        self.g_func = get_func(0, 1)\n\n    def train(self, dataset):\n        \"\"\"\n        Runs one epoch of SGD training on the specified dataset.\n\n        Parameters\n        ----------\n        dataset : Dataset\n        \"\"\"\n\n\n        if not hasattr(self, 'd_func'):\n            raise Exception(\"train called without first calling setup\")\n\n        # Make sure none of the parameters have bad values\n        for param in self.params:\n            value = param.get_value(borrow=True)\n            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n                raise Exception(\"NaN in \" + param.name)\n\n        self.first = False\n        rng = self.rng\n        if not is_stochastic(self.train_iteration_mode):\n            rng = None\n\n        data_specs = self.cost.get_data_specs(self.model)\n\n        # The iterator should be built from flat data specs, so it returns\n        # flat, non-redundent tuples of data.\n        mapping = DataSpecsMapping(data_specs)\n        space_tuple = mapping.flatten(data_specs[0], return_tuple=True)\n        source_tuple = mapping.flatten(data_specs[1], return_tuple=True)\n        if len(space_tuple) == 0:\n            # No data will be returned by the iterator, and it is impossible\n            # to know the size of the actual batch.\n            # It is not decided yet what the right thing to do should be.\n            raise NotImplementedError(\"Unable to train with SGD, because \"\n                    \"the cost does not actually use data from the data set. \"\n                    \"data_specs: %s\" % str(data_specs))\n        flat_data_specs = (CompositeSpace(space_tuple), source_tuple)\n\n        iterator = dataset.iterator(mode=self.train_iteration_mode,\n                batch_size=self.batch_size,\n                data_specs=flat_data_specs, return_tuple=True,\n                rng = rng, num_batches = self.batches_per_iter)\n\n\n        on_load_batch = self.on_load_batch\n        i = 0\n        for batch in iterator:\n            for callback in on_load_batch:\n                callback(*batch)\n            if self.train_generator and i == self.discriminator_steps:\n                self.g_func(*batch)\n                i = 0\n            else:\n                self.d_func(*batch)\n                i += 1\n            # iterator might return a smaller batch if dataset size\n            # isn't divisible by batch_size\n            # Note: if data_specs[0] is a NullSpace, there is no way to know\n            # how many examples would actually have been in the batch,\n            # since it was empty, so actual_batch_size would be reported as 0.\n            actual_batch_size = flat_data_specs[0].np_batch_size(batch)\n            self.monitor.report_batch(actual_batch_size)\n            for callback in self.update_callbacks:\n                callback(self)\n\n\n        # Make sure none of the parameters have bad values\n        for param in self.params:\n            value = param.get_value(borrow=True)\n            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n                raise Exception(\"NaN in \" + param.name)\n\n        self.train_generator = not self.train_generator\n\n    def continue_learning(self, model):\n        \"\"\"\n        Returns True if the algorithm should continue running, or False\n        if it has reached convergence / started overfitting and should\n        stop.\n\n        Parameters\n        ----------\n        model : a Model instance\n        \"\"\"\n        if self.termination_criterion is None:\n            return True\n        else:\n            return self.termination_criterion.continue_learning(self.model)\n\nclass MonitorBasedLRAdjuster(TrainExtension):\n    \"\"\"\n    A TrainExtension that uses the on_monitor callback to adjust\n    the learning rate on each epoch. It pulls out a channel\n    from the model's monitor and adjusts the learning rate\n    based on what happened to the monitoring channel on the last\n    epoch. If the channel is greater than high_trigger times\n    its previous value, the learning rate will be scaled by\n    shrink_amt (which should be < 1 for this scheme to make\n    sense). The idea is that in this case the learning algorithm\n    is overshooting the bottom of the objective function.\n\n    If the objective is less than high_trigger but\n    greater than low_trigger times its previous value, the\n    learning rate will be scaled by grow_amt (which should be > 1\n    for this scheme to make sense). The idea is that the learning\n    algorithm is making progress but at too slow of a rate.\n\n    Parameters\n    ----------\n    high_trigger : float, optional\n        See class-level docstring\n    low_trigger : float, optional\n        See class-level docstring\n    grow_amt : float, optional\n        See class-level docstring\n    min_lr : float, optional\n        All updates to the learning rate are clipped to be at least\n        this value.\n    max_lr : float, optional\n        All updates to the learning rate are clipped to be at most\n        this value.\n    dataset_name : str, optional\n        If specified, use dataset_name + \"_objective\" as the channel\n        to guide the learning rate adaptation.\n    channel_name : str, optional\n        If specified, use channel_name as the channel to guide the\n        learning rate adaptation. Conflicts with dataset_name.\n        If neither dataset_name nor channel_name is specified, uses\n        \"objective\"\n    \"\"\"\n\n    def __init__(self, high_trigger=1., shrink_amt=.99,\n                 low_trigger=.99, grow_amt=1.01,\n                 min_lr = 1e-7, max_lr = 1.,\n                 dataset_name=None, channel_name=None):\n        self.high_trigger = high_trigger\n        self.shrink_amt = shrink_amt\n        self.low_trigger = low_trigger\n        self.grow_amt = grow_amt\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.dataset_name = None\n        if channel_name is not None:\n            self.channel_name = channel_name\n        else:\n            if dataset_name is not None:\n                self.channel_name = dataset_name + '_objective'\n                self.dataset_name = dataset_name\n            else:\n                self.channel_name = None\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate based on the contents of model.monitor\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        model = algorithm.model\n        lr = algorithm.learning_rate\n        current_learning_rate = lr.get_value()\n        assert hasattr(model, 'monitor'), (\"no monitor associated with \"\n                + str(model))\n        monitor = model.monitor\n        monitor_channel_specified = True\n\n        if self.channel_name is None:\n            monitor_channel_specified = False\n            channels = [elem for elem in monitor.channels\n                    if elem.endswith(\"objective\")]\n            if len(channels) < 1:\n                raise ValueError(\"There are no monitoring channels that end \"\n                        \"with \\\"objective\\\". Please specify either \"\n                        \"channel_name or dataset_name.\")\n            elif len(channels) > 1:\n                datasets = algorithm.monitoring_dataset.keys()\n                raise ValueError(\"There are multiple monitoring channels that\"\n                        \"end with \\\"_objective\\\". The list of available \"\n                        \"datasets are: \" +\n                                str(datasets) + \" . Please specify either \"\n                                \"channel_name or dataset_name in the \"\n                                \"MonitorBasedLRAdjuster constructor to \"\n                                'disambiguate.')\n            else:\n                self.channel_name = channels[0]\n                warnings.warn('The channel that has been chosen for '\n                        'monitoring is: ' +\n                              str(self.channel_name) + '.')\n\n        try:\n            v = monitor.channels[self.channel_name].val_record\n        except KeyError:\n            err_input = ''\n            if monitor_channel_specified:\n                if self.dataset_name:\n                    err_input = 'The dataset_name \\'' + str(\n                            self.dataset_name) + '\\' is not valid.'\n                else:\n                    err_input = 'The channel_name \\'' + str(\n                            self.channel_name) + '\\' is not valid.'\n            err_message = 'There is no monitoring channel named \\'' + \\\n                    str(self.channel_name) + '\\'. You probably need to ' + \\\n                    'specify a valid monitoring channel by using either ' + \\\n                    'dataset_name or channel_name in the ' + \\\n                    'MonitorBasedLRAdjuster constructor. ' + err_input\n            raise ValueError(err_message)\n\n        if len(v) < 1:\n            if monitor.dataset is None:\n                assert len(v) == 0\n                raise ValueError(\"You're trying to use a monitor-based \"\n                        \"learning rate adjustor but the monitor has no \"\n                        \"entries because you didn't specify a \"\n                        \"monitoring dataset.\")\n\n            raise ValueError(\"For some reason there are no monitor entries\"\n                                 \"yet the MonitorBasedLRAdjuster has been \"\n                                 \"called. This should never happen. The Train\"\n                                 \" object should call the monitor once on \"\n                                 \"initialization, then call the callbacks. \"\n                                 \"It seems you are either calling the \"\n                                 \"callback manually rather than as part of a \"\n                                 \"training algorithm, or there is a problem \"\n                                \"with the Train object.\")\n        if len(v) == 1:\n            #only the initial monitoring has happened\n            #no learning has happened, so we can't adjust the learning rate yet\n            #just do nothing\n            return\n\n        rval = current_learning_rate\n\n        log.info(\"monitoring channel is {0}\".format(self.channel_name))\n\n        if v[-1] > self.high_trigger * v[-2]:\n            rval *= self.shrink_amt\n            log.info(\"shrinking learning rate to %f\" % rval)\n        elif v[-1] > self.low_trigger * v[-2]:\n            rval *= self.grow_amt\n            log.info(\"growing learning rate to %f\" % rval)\n\n        rval = max(self.min_lr, rval)\n        rval = min(self.max_lr, rval)\n\n        lr.set_value(np.cast[lr.dtype](rval))\n\n\nclass PatienceBasedTermCrit(object):\n    \"\"\"\n    A monitor-based termination criterion using a geometrically increasing\n    amount of patience. If the selected channel has decreased by a certain\n    proportion when comparing to the lowest value seen yet, the patience is\n    set to a factor of the number of examples seen, which by default\n    (patience_increase=2.) ensures the model has seen as many examples as the\n    number of examples that lead to the lowest value before concluding a local\n    optima has been reached.\n\n    Note: Technically, the patience corresponds to a number of epochs to be\n    independent of the size of the dataset, so be aware of that when choosing\n    initial_patience.\n\n    Parameters\n    ----------\n    prop_decrease : float\n        The factor X in the (1 - X) * best_value threshold\n    initial_patience : int\n        Minimal number of epochs the model has to run before it can stop\n    patience_increase : float, optional\n        The factor X in the patience = X * n_iter update.\n    channel_name : string, optional\n        Name of the channel to examine. If None and the monitor\n        has only one channel, this channel will be used; otherwise, an\n        error will be raised.\n    \"\"\"\n    def __init__(self, prop_decrease, initial_patience,\n                 patience_increase=2., channel_name=None):\n        self._channel_name = channel_name\n        self.prop_decrease = prop_decrease\n        self.patience = initial_patience\n        self.best_value = np.inf\n        self.patience_increase = patience_increase\n\n    def __call__(self, model):\n        \"\"\"\n        Returns True or False depending on whether the optimization should\n        stop or not. The optimization should stop if it has run for a number\n        of epochs superior to the patience without any improvement.\n\n        Parameters\n        ----------\n        model : Model\n            The model used in the experiment and from which the monitor used\n            in the termination criterion will be extracted.\n\n        Returns\n        -------\n        bool\n            True or False, indicating if the optimization should stop or not.\n        \"\"\"\n        monitor = model.monitor\n        # In the case the monitor has only one channel, the channel_name can\n        # be omitted and the criterion will examine the only channel\n        # available. However, if the monitor has multiple channels, leaving\n        # the channel_name unspecified will raise an error.\n        if self._channel_name is None:\n            if len(monitor.channels) != 1:\n                raise ValueError(\"Only single-channel monitors are supported \"\n                                 \"for channel_name == None\")\n            v = monitor.channels.values()[0].val_record\n        else:\n            v = monitor.channels[self._channel_name].val_record\n        # If the channel value decrease is higher than the threshold, we\n        # update the best value to this value and we update the patience.\n        if v[-1] < self.best_value * (1. - self.prop_decrease):\n            # Using the max between actual patience and updated patience\n            # ensures that the model will run for at least the initial\n            # patience and that it would behave correctly if the user\n            # chooses a dumb value (i.e. less than 1)\n            self.patience = max(self.patience, len(v) * self.patience_increase)\n            self.best_value = v[-1]\n\n        return len(v) < self.patience\n\n\nclass AnnealedLearningRate(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decrease as 1/t where t is the number\n    of gradient descent updates done so far. Use OneOverEpoch as Train object\n    callback if you would prefer 1/t where t is epochs.\n\n    Parameters\n    ----------\n    anneal_start : int\n        The epoch on which to begin annealing\n    \"\"\"\n    def __init__(self, anneal_start):\n        self._initialized = False\n        self._count = 0\n        self._anneal_start = anneal_start\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the annealing schedule.\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._base = algorithm.learning_rate.get_value()\n        self._count += 1\n        algorithm.learning_rate.set_value(self.current_learning_rate())\n\n    def current_learning_rate(self):\n        \"\"\"\n        Returns the current desired learning rate according to the\n        annealing schedule.\n        \"\"\"\n        return self._base * min(1, self._anneal_start / self._count)\n\nclass ExponentialDecay(object):\n    \"\"\"\n    This is a callback for the `SGD` algorithm rather than the `Train` object.\n    This anneals the learning rate by dividing by decay_factor after each\n    gradient descent step. It will not shrink the learning rate beyond\n    `min_lr`.\n\n    Parameters\n    ----------\n    decay_factor : float\n        The learning rate at step t is given by\n        `init_learning_rate / (decay_factor ** t)`\n    min_lr : float\n        The learning rate will be clipped to be at least this value\n    \"\"\"\n\n    def __init__(self, decay_factor, min_lr):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(min_lr, str):\n            min_lr = float(min_lr)\n        assert isinstance(decay_factor, float)\n        assert isinstance(min_lr, float)\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        self._min_reached = False\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Updates the learning rate according to the exponential decay schedule.\n\n        Parameters\n        ----------\n        algorithm : SGD\n            The SGD instance whose `learning_rate` field should be modified.\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n        self._count += 1\n\n        if not self._min_reached:\n            # If we keep on executing the exponentiation on each mini-batch,\n            # we will eventually get an OverflowError. So make sure we\n            # only do the computation until min_lr is reached.\n            new_lr = self._base_lr / (self.decay_factor ** self._count)\n            if new_lr <= self.min_lr:\n                self._min_reached = True\n                new_lr = self.min_lr\n        else:\n            new_lr = self.min_lr\n\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\nclass LinearDecay(object):\n    \"\"\"\n    This is a callback for the SGD algorithm rather than the Train object.\n    This anneals the learning rate to decay_factor times of the initial value\n    during time start till saturate.\n\n    Parameters\n    ----------\n    start : int\n        The step at which to start decreasing the learning rate\n    saturate : int\n        The step at which to stop decreating the learning rate\n    decay_factor : float\n        `final learning rate = decay_factor * initial learning rate`\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        if isinstance(decay_factor, str):\n            decay_factor = float(decay_factor)\n        if isinstance(start, str):\n            start = float(start)\n        if isinstance(saturate, str):\n            saturate = float(saturate)\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start > 0\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n\n    def __call__(self, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the linear decay schedule\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == 0:\n            self._base_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._base_lr - self._base_lr * self.decay_factor) /\n                          (self.saturate - self.start + 1))\n        self._count += 1\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._base_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._base_lr * self.decay_factor\n        else:\n            new_lr = self._base_lr\n        assert new_lr > 0\n        new_lr = np.cast[config.floatX](new_lr)\n        algorithm.learning_rate.set_value(new_lr)\n\n\ndef MomentumAdjustor(final_momentum, start, saturate):\n    \"\"\"\n    Deprecated class used with the deprecated init_momentum argument.\n    Use learning_rule.MomentumAdjustor instead.\n\n    Parameters\n    ----------\n    final_momentum : WRITEME\n    start : WRITEME\n    saturate : WRITEME\n    \"\"\"\n    warnings.warn(\"sgd.MomentumAdjustor interface is deprecated and will \"\n    \"become officially unsupported as of May 9, 2014. Please use \"\n    \"`learning_rule.MomentumAdjustor` instead.\")\n    return LRMomentumAdjustor(final_momentum, start, saturate)\n\n\nclass OneOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate like one over # epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    half_life : int, optional\n        How many epochs after start it will take for the learning rate to lose\n        half its value for the first time (to lose the next half of its value\n        will take twice as long)\n    min_lr : float, optional\n        The minimum value the learning rate can take on\n    \"\"\"\n    def __init__(self, start, half_life = None, min_lr = 1e-6):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert start >= 0\n        if half_life is None:\n            self.half_life = start + 1\n        else:\n            assert half_life > 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Adjusts the learning rate according to the decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            if self._init_lr < self.min_lr:\n                raise ValueError(\"The initial learning rate is smaller than \" +\n                                 \"the minimum allowed learning rate.\")\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count < self.start:\n            scale = 1\n        else:\n            scale = float(self.half_life) / float(self._count - self.start\n                    + self.half_life)\n        lr = self._init_lr * scale\n        clipped = max(self.min_lr, lr)\n        return clipped\n\nclass LinearDecayOverEpoch(TrainExtension):\n    \"\"\"\n    Scales the learning rate linearly on each epochs\n\n    Parameters\n    ----------\n    start : int\n        The epoch on which to start shrinking the learning rate\n    saturate : int\n        The epoch to saturate the shrinkage\n    decay_factor : float\n        The final value would be initial learning rate times decay_factor\n    \"\"\"\n\n    def __init__(self, start, saturate, decay_factor):\n        self.__dict__.update(locals())\n        del self.self\n        self._initialized = False\n        self._count = 0\n        assert isinstance(decay_factor, float)\n        assert isinstance(start, (py_integer_types, py_float_types))\n        assert isinstance(saturate, (py_integer_types, py_float_types))\n        assert saturate > start\n        assert start >= 0\n        assert saturate >= start\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Updates the learning rate based on the linear decay schedule.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if not self._initialized:\n            self._init_lr = algorithm.learning_rate.get_value()\n            self._step = ((self._init_lr - self._init_lr * self.decay_factor) /\n                          (self.saturate - self.start + 1))\n            self._initialized = True\n        self._count += 1\n        algorithm.learning_rate.set_value(np.cast[config.floatX](\n            self.current_lr()))\n\n    def current_lr(self):\n        \"\"\"\n        Returns the learning rate currently desired by the decay schedule.\n        \"\"\"\n        if self._count >= self.start:\n            if self._count < self.saturate:\n                new_lr = self._init_lr - self._step * (self._count\n                        - self.start + 1)\n            else:\n                new_lr = self._init_lr * self.decay_factor\n        else:\n            new_lr = self._init_lr\n        assert new_lr > 0\n        return new_lr\n\nclass _PolyakWorker(object):\n    \"\"\"\n    Only to be used by the PolyakAveraging TrainingCallback below.\n    Do not use directly.\n    A callback for the SGD class.\n\n    Parameters\n    ----------\n    model : a Model\n        The model whose parameters we want to train with Polyak averaging\n    \"\"\"\n\n    def __init__(self, model):\n        avg_updates = OrderedDict()\n        t = sharedX(1.)\n        self.param_to_mean = OrderedDict()\n        for param in model.get_params():\n            mean = sharedX(param.get_value())\n            assert type(mean) == type(param)\n            self.param_to_mean[param] = mean\n            avg_updates[mean] = mean - (mean - param) / t\n            avg_updates[t] = t + 1.\n        self.avg = function([], updates = avg_updates)\n\n    def __call__(self, algorithm):\n        \"\"\"\n        To be called after each SGD step.\n        Updates the Polyak averaged-parameters for this model\n\n        Parameters\n        ----------\n        algorithm : WRITEME\n        \"\"\"\n        self.avg()\n\nclass PolyakAveraging(TrainExtension):\n    \"\"\"\n    See \"A Tutorial on Stochastic Approximation Algorithms\n        for Training Restricted Boltzmann Machines and\n        Deep Belief Nets\" by Kevin Swersky et al\n\n    This functionality is still a work in progress. Currently,\n    your model needs to implement \"add_polyak_channels\" to\n    use it.\n\n    The problem is that Polyak averaging shouldn't modify\n    the model parameters. It should keep a second copy\n    that it averages in the background. This second copy\n    doesn't get to come back in and affect the learning process\n    though.\n\n    (IG tried having the second copy get pushed back into\n    the model once per epoch, but this turned out to be\n    harmful, at least in limited tests)\n\n    So we need a cleaner interface for monitoring the\n    averaged copy of the parameters, and we need to make\n    sure the saved model at the end uses the averaged\n    parameters, not the parameters used for computing\n    the gradients during training.\n\n    TODO: make use of the new on_save callback instead\n        of duplicating Train's save_freq flag\n\n    Parameters\n    ----------\n    start : int\n        The epoch after which to start averaging (0 = start averaging\n        immediately)\n    save_path : str, optional\n        WRITEME\n    save_freq : int, optional\n        WRITEME\n\n    Notes\n    -----\n    This is usually used with a fixed, rather than annealed learning\n    rate. It may be used in conjunction with momentum.\n    \"\"\"\n\n    def __init__(self, start, save_path=None, save_freq=1):\n        self.__dict__.update(locals())\n        del self.self\n        self._count = 0\n        assert isinstance(start, py_integer_types)\n        assert start >= 0\n\n    def on_monitor(self, model, dataset, algorithm):\n        \"\"\"\n        Make sure Polyak-averaged model gets monitored.\n        Save the model if necessary.\n\n        Parameters\n        ----------\n        model : a Model instance\n        dataset : Dataset\n        algorithm : WRITEME\n        \"\"\"\n        if self._count == self.start:\n            self._worker = _PolyakWorker(model)\n            algorithm.update_callbacks.append(self._worker)\n            #HACK\n            try:\n                model.add_polyak_channels(self._worker.param_to_mean,\n                                          algorithm.monitoring_dataset)\n            except AttributeError:\n                pass\n        elif self.save_path is not None and self._count > self.start and \\\n                self._count % self.save_freq == 0:\n            saved_params = OrderedDict()\n            for param in model.get_params():\n                saved_params[param] = param.get_value()\n                param.set_value(self._worker.param_to_mean[param].get_value())\n            serial.save(self.save_path, model)\n            for param in model.get_params():\n                param.set_value(saved_params[param])\n        self._count += 1\n"
        },
        {
          "name": "show_gen_weights.py",
          "type": "blob",
          "size": 1.392578125,
          "content": "import sys\nfrom pylearn2.gui.patch_viewer import make_viewer\nfrom pylearn2.utils import serial\nmodel = serial.load(sys.argv[1])\ngenerator = model.generator\n\nfinal = generator.mlp.layers[-1]\nsuccess = False\n\ni = -1\nsuccess = False\nto_search = generator.mlp\nwhile not success:\n    print \"while loop \", i\n    final = to_search.layers[i]\n    if 'Composite' in str(type(final)):\n        i = input(\"which\")\n        elem = final.layers[i]\n        if hasattr(elem, 'layers'):\n            print \"stepping into inner MLP\"\n            i = -1\n            to_search = elem\n            continue\n        else:\n            print \"examining this element\"\n            final = elem\n\n    try:\n        print \"Trying get_weights topo\"\n        topo = final.get_weights_topo()\n        print \"It worked\"\n        success = True\n    except Exception:\n        pass\n\n    if success:\n        print \"Making the viewer and showing\"\n        make_viewer(topo).show()\n        quit()\n\n    try:\n        print \"Trying get_weights\"\n        weights = final.get_weights()\n        print \"It worked\"\n        success = True\n    except NotImplementedError:\n        i -= 1 # skip over SpaceConverter, etc.\nprint \"Out of the while loop\"\n\n\nprint \"weights shape \", weights.shape\nviewer = make_viewer(weights, is_color=weights.shape[1] % 3 == 0 and weights.shape[1] != 48*48)\nprint \"image shape \", viewer.image.shape\n\nprint \"made viewer\"\n\nviewer.show()\n\nprint \"executed show\"\n"
        },
        {
          "name": "show_inpaint_samples.py",
          "type": "blob",
          "size": 1.0849609375,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\ndataset = dataset.get_test_set()\n\ngrid_shape = None\n\nfrom pylearn2.utils import sharedX\nX = sharedX(dataset.get_batch_topo(100))\nsamples, ignore = model.generator.inpainting_sample_and_noise(X)\nsamples = samples.eval()\ntotal_dimension = space.get_total_dimension()\nnum_colors = 1\nif total_dimension % 3 == 0:\n    num_colors = 3\nw = int(np.sqrt(total_dimension / num_colors))\nfrom pylearn2.space import Conv2DSpace\ndesired_space = Conv2DSpace(shape=[w, w], num_channels=num_colors, axes=('b',0,1,'c'))\nis_color = samples.shape[-1] == 3\nprint (samples.min(), samples.mean(), samples.max())\n# Hack for detecting MNIST [0, 1] values. Otherwise we assume centered images\nif samples.min() >0:\n    samples = samples * 2.0 - 1.0\nviewer = make_viewer(samples, grid_shape=grid_shape, is_color=is_color)\nviewer.show()\n"
        },
        {
          "name": "show_samples.py",
          "type": "blob",
          "size": 1.74609375,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.space import VectorSpace\nfrom pylearn2.config import yaml_parse\nimport numpy as np\n\nmatch_train = True\nif match_train:\n    dataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nif isinstance(space, VectorSpace):\n    # For some reason format_as from VectorSpace is not working right\n    samples = model.generator.sample(100).eval()\n\n    if match_train:\n        grid_shape = (10, 20)\n        matched = np.zeros((samples.shape[0] * 2, samples.shape[1]))\n        X = dataset.X\n        for i in xrange(samples.shape[0]):\n            matched[2 * i, :] = samples[i, :].copy()\n            dists = np.square(X - samples[i, :]).sum(axis=1)\n            j = np.argmin(dists)\n            matched[2 * i + 1, :] = X[j, :]\n        samples = matched\n\n    is_color = samples.shape[-1] % 3 == 0 and samples.shape[-1] != 48 * 48\nelse:\n    total_dimension = space.get_total_dimension()\n    import numpy as np\n    num_colors = 1\n    if total_dimension % 3 == 0:\n        num_colors = 3\n    w = int(np.sqrt(total_dimension / num_colors))\n    from pylearn2.space import Conv2DSpace\n    desired_space = Conv2DSpace(shape=[w, w], num_channels=num_colors, axes=('b',0,1,'c'))\n    samples = space.format_as(batch=model.generator.sample(100),\n            space=desired_space).eval()\n    is_color = samples.shape[-1] == 3\nprint (samples.min(), samples.mean(), samples.max())\n# Hack for detecting MNIST [0, 1] values. Otherwise we assume centered images\nif samples.min() >0:\n    samples = samples * 2.0 - 1.0\nviewer = make_viewer(samples, grid_shape=grid_shape, is_color=is_color)\nviewer.show()\n"
        },
        {
          "name": "show_samples_cifar_conv_paper.py",
          "type": "blob",
          "size": 1.2880859375,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.gui.patch_viewer import PatchViewer\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nrows = 4\nsample_cols = 5\n\n# For some reason format_as from VectorSpace is not working right\ntopo_samples = model.generator.sample(rows * sample_cols).eval()\nsamples = dataset.get_design_matrix(topo_samples)\ndataset.axes = ['b', 0, 1, 'c']\ndataset.view_converter.axes = ['b', 0, 1, 'c']\ntopo_samples = dataset.get_topological_view(samples)\n\npv = PatchViewer(grid_shape=(rows, sample_cols + 1), patch_shape=(32,32),\n        is_color=True)\nscale = np.abs(samples).max()\n\nX = dataset.X\ntopo = dataset.get_topological_view()\nindex = 0\nfor i in xrange(samples.shape[0]):\n    topo_sample = topo_samples[i, :, :, :]\n    print topo_sample.min(), topo_sample.max()\n    pv.add_patch(topo_sample / scale, rescale=False)\n\n    if (i +1) % sample_cols == 0:\n        sample = samples[i, :]\n        dists = np.square(X - sample).sum(axis=1)\n        j = np.argmin(dists)\n        match = topo[j, :]\n        print match.min(), match.max()\n        pv.add_patch(match / scale, rescale=False, activation=1)\n\npv.show()\n"
        },
        {
          "name": "show_samples_cifar_full_paper.py",
          "type": "blob",
          "size": 1.1572265625,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.gui.patch_viewer import PatchViewer\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nrows = 4\nsample_cols = 5\n\n# For some reason format_as from VectorSpace is not working right\nsamples = model.generator.sample(rows * sample_cols).eval()\ntopo_samples = dataset.get_topological_view(samples)\n\npv = PatchViewer(grid_shape=(rows, sample_cols + 1), patch_shape=(32,32),\n        is_color=True)\nscale = np.abs(samples).max()\n\nX = dataset.X\ntopo = dataset.get_topological_view()\nindex = 0\nfor i in xrange(samples.shape[0]):\n    topo_sample = topo_samples[i, :, :, :]\n    print topo_sample.min(), topo_sample.max()\n    pv.add_patch(topo_sample / scale, rescale=False)\n\n    if (i +1) % sample_cols == 0:\n        sample = samples[i, :]\n        dists = np.square(X - sample).sum(axis=1)\n        j = np.argmin(dists)\n        match = topo[j, :]\n        print match.min(), match.max()\n        pv.add_patch(match / scale, rescale=False, activation=1)\n\npv.show()\n"
        },
        {
          "name": "show_samples_inpaint.py",
          "type": "blob",
          "size": 1.4306640625,
          "content": "import theano\nfrom pylearn2.utils import serial\nimport sys\nfrom pylearn2.gui.patch_viewer import make_viewer\nfrom pylearn2.space import VectorSpace\nfrom pylearn2.config import yaml_parse\nimport numpy as np\nimport ipdb\n\n\n# TODO, only works for CIFAR10 for now\n\ngrid_shape = None\nrepeat_samples = 1\nnum_samples = 5\n\n\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nrng = np.random.RandomState(20232)\n\ndef get_data_samples(dataset, n = num_samples):\n    unique_y = np.unique(dataset.y)\n    rval = []\n    for y in np.unique(dataset.y):\n        ind = np.where(dataset.y == y)[0]\n        ind = ind[rng.randint(0, len(ind), n)]\n        rval.append(dataset.get_topological_view()[ind])\n\n    return np.concatenate(rval)\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\ndataset = dataset.get_test_set()\ndata = get_data_samples(dataset)\n\noutput_space = model.generator.get_output_space()\ninput_space = model.generator.mlp.input_space\n\nX = input_space.get_theano_batch()\nsamples, _ = model.generator.inpainting_sample_and_noise(X)\nf = theano.function([X], samples)\n\nsamples = []\nfor i in xrange(repeat_samples):\n    samples.append(f(data))\n\nsamples = np.concatenate(samples)\n\nis_color = True\n\n\nprint (samples.min(), samples.mean(), samples.max())\n# Hack for detecting MNIST [0, 1] values. Otherwise we assume centered images\nif samples.min() >0:\n    samples = samples * 2.0 - 1.0\nviewer = make_viewer(samples, grid_shape=grid_shape, is_color=is_color)\nviewer.show()\n"
        },
        {
          "name": "show_samples_mnist_paper.py",
          "type": "blob",
          "size": 1.0947265625,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.gui.patch_viewer import PatchViewer\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nrows = 4\nsample_cols = 5\n\n# For some reason format_as from VectorSpace is not working right\nsamples = model.generator.sample(rows * sample_cols).eval()\ntopo_samples = dataset.get_topological_view(samples)\n\npv = PatchViewer(grid_shape=(rows, sample_cols + 1), patch_shape=(28,28),\n        is_color=False)\n\nX = dataset.X\ntopo = dataset.get_topological_view()\nindex = 0\nfor i in xrange(samples.shape[0]):\n    topo_sample = topo_samples[i, :, :, :]\n    pv.add_patch(topo_sample * 2. - 1., rescale=False)\n\n    if (i +1) % sample_cols == 0:\n        sample = samples[i, :]\n        dists = np.square(X - sample).sum(axis=1)\n        j = np.argmin(dists)\n        match = topo[j, :]\n        pv.add_patch(match * 2 -1, rescale=False, activation=1)\n\npv.show()\n"
        },
        {
          "name": "show_samples_tfd.py",
          "type": "blob",
          "size": 0.6875,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\ntotal_dimension = space.get_total_dimension()\nimport numpy as np\nnum_colors = 1\n#if total_dimension % 3 == 0:\n#    num_colors = 3\nw = int(np.sqrt(total_dimension / num_colors))\nfrom pylearn2.space import Conv2DSpace\ndesired_space = Conv2DSpace(shape=[w, w], num_channels=num_colors, axes=('b',0,1,'c'))\nsamples = space.format_as(batch=model.generator.sample(100),\n        space=desired_space).eval()\nprint (samples.min(), samples.mean(), samples.max())\nviewer = make_viewer(samples * 2.0 - 1.0)\nviewer.show()\n"
        },
        {
          "name": "show_samples_tfd_paper.py",
          "type": "blob",
          "size": 1.0947265625,
          "content": "from pylearn2.utils import serial\nimport sys\n_, model_path = sys.argv\nmodel = serial.load(model_path)\nfrom pylearn2.gui.patch_viewer import make_viewer\nspace = model.generator.get_output_space()\nfrom pylearn2.config import yaml_parse\nfrom pylearn2.gui.patch_viewer import PatchViewer\nimport numpy as np\n\ndataset = yaml_parse.load(model.dataset_yaml_src)\n\ngrid_shape = None\n\nrows = 4\nsample_cols = 5\n\n# For some reason format_as from VectorSpace is not working right\nsamples = model.generator.sample(rows * sample_cols).eval()\ntopo_samples = dataset.get_topological_view(samples)\n\npv = PatchViewer(grid_shape=(rows, sample_cols + 1), patch_shape=(48,48),\n        is_color=False)\n\nX = dataset.X\ntopo = dataset.get_topological_view()\nindex = 0\nfor i in xrange(samples.shape[0]):\n    topo_sample = topo_samples[i, :, :, :]\n    pv.add_patch(topo_sample * 2. - 1., rescale=False)\n\n    if (i +1) % sample_cols == 0:\n        sample = samples[i, :]\n        dists = np.square(X - sample).sum(axis=1)\n        j = np.argmin(dists)\n        match = topo[j, :]\n        pv.add_patch(match * 2 -1, rescale=False, activation=1)\n\npv.show()\n"
        },
        {
          "name": "test_deconv.py",
          "type": "blob",
          "size": 1.556640625,
          "content": "\"\"\"\nThis script visually test the deconv layer.\nConstruct an MLP with conv ,and deconv layer,\nset their W to same values and show the original\ninput and the output of the mlp side by side.\nThey are supposed to look same.\n\"\"\"\n\n\nimport theano\nfrom adversarial.deconv import Deconv\nfrom pylearn2.datasets.mnist import MNIST\nfrom pylearn2.space import Conv2DSpace\nfrom pylearn2.models.mlp import MLP\nfrom pylearn2.models.maxout import MaxoutConvC01B\nfrom pylearn2.gui import patch_viewer\nimport ipdb\n\n\ninput_space = Conv2DSpace(shape = (28, 28), num_channels=1, axes = ('c', 0, 1, 'b'))\nconv = MaxoutConvC01B(layer_name = 'conv',\n                        num_channels = 16,\n                        num_pieces = 1,\n                        kernel_shape = (4, 4),\n                        pool_shape = (1, 1),\n                        pool_stride=(1, 1),\n                        irange = 0.05)\ndeconv = Deconv(layer_name = 'deconv',\n                num_channels = 1,\n                kernel_shape = (4, 4),\n                irange = 0.05)\n\nmlp = MLP(input_space =input_space,\n        layers = [conv, deconv])\n\nmlp.layers[1].transformer._filters.set_value(mlp.layers[0].transformer._filters.get_value())\n\nx = input_space.get_theano_batch()\nout = mlp.fprop(x)\nf = theano.function([x], out)\n\ndata = MNIST('test')\ndata_specs = (input_space, 'features')\niter = data.iterator(mode = 'sequential', batch_size = 2, data_specs = data_specs)\npv = patch_viewer.PatchViewer((10, 10), (28, 28))\nfor item in iter:\n    res = f(item)\n    pv.add_patch(item[0,:,:,0])\n    pv.add_patch(res[0,:,:,0])\n    pv.show()\n    break\n\n"
        },
        {
          "name": "tfd_pretrain",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}