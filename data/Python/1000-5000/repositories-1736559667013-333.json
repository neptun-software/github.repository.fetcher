{
  "metadata": {
    "timestamp": 1736559667013,
    "page": 333,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjM0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "Doriandarko/maestro",
      "stars": 4189,
      "defaultBranch": "main",
      "files": [
        {
          "name": "README.md",
          "type": "blob",
          "size": 6.765625,
          "content": "# Maestro - A Framework for Claude Opus, GPT and local LLMs to Orchestrate Subagents\n\n\nThis Python script demonstrates an AI-assisted task breakdown and execution workflow using the Anthropic API. It utilizes two AI models, Opus and Haiku, to break down an objective into sub-tasks, execute each sub-task, and refine the results into a cohesive final output.\n\n## New: \n# Updated the original Maestro to support Claude 3.5 Sonnet\n```bash\npython maestro.py\n```\n\n\n# Use Maestro with any APIs, Anthropic, Gemini, OpenAI, Cohere, etc.\nThanks to a rewrite of the codebase using LiteLLM, it's now much easier to select the model you want.\n\nSimply\n#### Set environment variables for API keys for the services you are using\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\" \n\nos.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR KEY\"\n\nos.environ[\"GEMINI_API_KEY\"] = \"YOUR KEY\"\n\n#### Define the models to be used for each stage\nORCHESTRATOR_MODEL = \"gemini/gemini-1.5-flash-latest\"\n\nSUB_AGENT_MODEL = \"gemini/gemini-1.5-flash-latest\"\n\nREFINER_MODEL = \"gemini/gemini-1.5-flash-latest\"\n\nOr gpt-3.5-turbo, etc.\n\nFirst install litellm\n```bash\npip install litellm\n```\n\nAfeter installing dependecies run\n\n```bash\npython maestro-anyapi.py\n```\n\n\n## GPT-4o\n\nThe GPT script has been updated from the ground up to support the code capabilities of GPT-4o\n\nAfeter installing dependecies run\n\n```bash\npython maestro-gpt4o.py\n```\n\n## Run locally with LMStudio or Ollama\n\n### Lmstudio\n\nFirst download the app here\nhttps://lmstudio.ai/\n\nThen run the local server using your preferred method. I also recommend removing any system prompt for the app (leave your prompt field empty so it can take advantage of the script prompts).\n\nThen\n```bash\npython maestro-lmstudio.py\n```\n\n\n### Ollama\nMestro now runs locally thanks to the Ollama platform. Experience the power of Llama 3 locally! \n\nBefore running the script\n\nInstall Ollama client from here\nhttps://ollama.com/download\n\nthen\n\n```bash\npip install ollama\n```\nAnd \n\n```bash\nollama.pull('llama3:70b')\n```\nThis will depend on the model you want to use it, you only need to do it once or if you want to update the model when a new version it's out.\nIn the script I am using both versions but you can customize the model you want to use\n\nollama.pull('llama3:70b')\nollama.pull('llama3:8b')\n\nThen\n\n```bash\npython maestro-ollama.py\n```\n\n## Highly requested features\n- GROQ SUPPORT\nExperience the power of maestro thanks to Groq super fast api responses.\n```bash\npip install groq\n```\nThen\n\n```bash\npython maestro-groq.py\n```\n\n\n- SEARCH üîç\n\nNow, when it's creating a task for its subagent, Claude Opus will perform a search and get the best answer to help the subagent solve that task even better.\n\nMake sure you replace your Tavil API for search to work\n\nGet one here https://tavily.com/\n  \n- GPT4 SUPPORT\n\nAdd support for GPT-4 as an orchestrator in maestro-gpt.py\nSimply\n```bash\npython maestro-gpt.py\n```\n\nAfter you complete your installs.\n\n\n## Features\n\n- Breaks down an objective into manageable sub-tasks using the Opus model\n- Executes each sub-task using the Haiku model\n- Provides the Haiku model with memory of previous sub-tasks for context\n- Refines the sub-task results into a final output using the Opus model\n- Generates a detailed exchange log capturing the entire task breakdown and execution process\n- Saves the exchange log to a Markdown file for easy reference\n- Utilizes an improved prompt for the Opus model to better assess task completion\n- Creates code files and folders when working on code projects.\n\n## Prerequisites\n\nTo run this script, you need to have the following:\n\n- Python installed\n- Anthropic API key\n- Required Python packages: `anthropic` and `rich`\n\n## Installation\n\n1. Clone the repository or download the script file.\n2. Install the required Python packages by running the following command:\n\n```bash\npip install -r requirements.txt\n```\n\n3. Replace the placeholder API key in the script with your actual Anthropic API key:\n\n```python\nclient = Anthropic(api_key=\"YOUR_API_KEY_HERE\")\n```\n\nIf using search, replace your Tavil API\n```python\ntavily = TavilyClient(api_key=\"YOUR API KEY HERE\")\n```\n\n## Usage\n\n1. Open a terminal or command prompt and navigate to the directory containing the script.\n2. Run the script using the following command:\n\n```bash\npython maestro.py\n```\n\n3. Enter your objective when prompted:\n\n```bash\nPlease enter your objective: Your objective here\n```\n\nThe script will start the task breakdown and execution process. It will display the progress and results in the console using formatted panels.\n\nOnce the process is complete, the script will display the refined final output and save the full exchange log to a Markdown file with a filename based on the objective.\n\n## Code Structure\n\nThe script consists of the following main functions:\n\n- `opus_orchestrator(objective, previous_results=None)`: Calls the Opus model to break down the objective into sub-tasks or provide the final output. It uses an improved prompt to assess task completion and includes the phrase \"The task is complete:\" when the objective is fully achieved.\n- `haiku_sub_agent(prompt, previous_haiku_tasks=None)`: Calls the Haiku model to execute a sub-task prompt, providing it with the memory of previous sub-tasks.\n- `opus_refine(objective, sub_task_results)`: Calls the Opus model to review and refine the sub-task results into a cohesive final output.\n\nThe script follows an iterative process, repeatedly calling the opus_orchestrator function to break down the objective into sub-tasks until the final output is provided. Each sub-task is then executed by the haiku_sub_agent function, and the results are stored in the task_exchanges and haiku_tasks lists.\n\nThe loop terminates when the Opus model includes the phrase \"The task is complete:\" in its response, indicating that the objective has been fully achieved.\n\nFinally, the opus_refine function is called to review and refine the sub-task results into a final output. The entire exchange log, including the objective, task breakdown, and refined final output, is saved to a Markdown file.\n\n## Customization\n\nYou can customize the script according to your needs:\n\n- Adjust the max_tokens parameter in the client.messages.create() function calls to control the maximum number of tokens generated by the AI models.\n- Change the models to what you prefer, like replacing Haiku with Sonnet or Opus.\n- Modify the console output formatting by updating the rich library's Panel and Console configurations.\n- Customize the exchange log formatting and file extension by modifying the relevant code sections.\n\n## License\n\nThis script is released under the MIT License.\n\n## Acknowledgements\n\n- Anthropic for providing the AI models and API.\n- Rich for the beautiful console formatting.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Doriandarko/maestro&type=Date)](https://star-history.com/#Doriandarko/maestro&Date)\n"
        },
        {
          "name": "flask_app",
          "type": "tree",
          "content": null
        },
        {
          "name": "maestro-anyapi.py",
          "type": "blob",
          "size": 14.4248046875,
          "content": "import os\nimport re\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom datetime import datetime\nimport json\nfrom litellm import completion\nfrom tavily import TavilyClient\n\n# Set environment variables for API keys for the services you are using\nos.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR ANTHROPIC API KEY\"\nos.environ[\"GEMINI_API_KEY\"] = \"YOUR GEMINI API KEY\"\n\n# Define the models to be used for each stage\nORCHESTRATOR_MODEL = \"gemini/gemini-1.5-flash-latest\"\nSUB_AGENT_MODEL = \"gemini/gemini-1.5-flash-latest\"\nREFINER_MODEL = \"gemini/gemini-1.5-flash-latest\"\n\n# Initialize the Rich Console\nconsole = Console()\n\ndef gpt_orchestrator(objective, file_content=None, previous_results=None, use_search=False):\n    console.print(f\"\\n[bold]Calling Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    \n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a detailed and meticulous assistant. Your primary goal is to break down complex objectives into manageable sub-tasks, provide thorough reasoning, and ensure code correctness. Always explain your thought process step-by-step and validate any code for errors, improvements, and adherence to best practices.\"},\n        {\"role\": \"user\", \"content\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. IMPORTANT!!! when dealing with code tasks make sure you check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt. Please assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.:\\n\\nObjective: {objective}\" + ('\\nFile content:\\n' + file_content if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"}\n    ]\n\n    if use_search:\n        messages.append({\"role\": \"user\", \"content\": \"Please also generate a JSON object containing a single 'search_query' key, which represents a question that, when asked online, would yield important information for solving the subtask. The question should be specific and targeted to elicit the most relevant and helpful resources. Format your JSON like this, with no additional text before or after:\\n{\\\"search_query\\\": \\\"<question>\\\"}\\n\"})\n\n    response = completion(model=ORCHESTRATOR_MODEL, messages=messages)\n\n    response_text = response['choices'][0]['message']['content']\n\n    console.print(Panel(response_text, title=f\"[bold green]Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to sub-agent üëá\"))\n\n    search_query = None\n    if use_search:\n        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n        if json_match:\n            json_string = json_match.group()\n            try:\n                search_query = json.loads(json_string)[\"search_query\"]\n                console.print(Panel(f\"Search Query: {search_query}\", title=\"[bold blue]Search Query[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                response_text = response_text.replace(json_string, \"\").strip()\n            except json.JSONDecodeError as e:\n                console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n                console.print(Panel(f\"Skipping search query extraction.\", title=\"[bold yellow]Search Query Extraction Skipped[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n        else:\n            search_query = None\n\n    return response_text, file_content, search_query\n\ndef gpt_sub_agent(prompt, search_query=None, previous_gpt_tasks=None, use_search=False, continuation=False):\n    if previous_gpt_tasks is None:\n        previous_gpt_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    system_message = (\n        \"You are an expert assistant. Your goal is to execute tasks accurately, provide detailed explanations of your reasoning, \"\n        \"and ensure the correctness and quality of any code. Always explain your thought process and validate your output thoroughly.\\n\\n\"\n        \"Previous tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_gpt_tasks)\n    )\n    if continuation:\n        prompt = continuation_prompt\n\n    qna_response = None\n    if search_query and use_search:\n        tavily = TavilyClient(api_key=\"your-tavily-key\")\n        qna_response = tavily.qna_search(query=search_query)\n        console.print(f\"QnA response: {qna_response}\", style=\"yellow\")\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_message},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    if qna_response:\n        messages.append({\"role\": \"user\", \"content\": f\"\\nSearch Results:\\n{qna_response}\"})\n\n    response = completion(model=SUB_AGENT_MODEL, messages=messages)\n\n    response_text = response['choices'][0]['message']['content']\n\n    console.print(Panel(response_text, title=\"[bold blue]Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to Orchestrator üëá\"))\n\n    if len(response_text) >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = gpt_sub_agent(prompt, search_query, previous_gpt_tasks, use_search, continuation=True)\n        response_text += continuation_response_text\n\n    return response_text\n\ndef anthropic_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    console.print(\"\\nCalling Opus to provide the refined final output for your objective:\")\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed. When working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE please provide the following:\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary.\\nWrap the JSON object in <folder_structure> tags.\\n3. Code Files: For each code file, include ONLY the file name NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\n```python\\n<code>\\n```\"}\n            ]\n        }\n    ]\n\n    response = completion(model=REFINER_MODEL, messages=messages)\n\n    response_text = response['choices'][0]['message']['content']\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n\n    if len(response_text) >= 4000 and not continuation:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = anthropic_refine(objective, sub_task_results + [response_text], filename, projectname, continuation=True)\n        response_text += \"\\n\" + continuation_response_text\n\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold green]Project Folder[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        return\n\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\ndef read_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n    return content\n\n# Get the objective from user input\nobjective = input(\"Please enter your objective: \")\n\n# Ask the user if they want to provide a file path\nprovide_file = input(\"Do you want to provide a file path? (y/n): \").lower() == 'y'\n\nif provide_file:\n    file_path = input(\"Please enter the file path: \")\n    if os.path.exists(file_path):\n        file_content = read_file(file_path)\n    else:\n        print(f\"File not found: {file_path}\")\n        file_content = None\nelse:\n    file_content = None\n\n# Ask the user if they want to use search\nuse_search = input(\"Do you want to use search? (y/n): \").lower() == 'y'\n\ntask_exchanges = []\ngpt_tasks = []\n\nwhile True:\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        gpt_result, file_content_for_gpt, search_query = gpt_orchestrator(objective, file_content, previous_results, use_search)\n    else:\n        gpt_result, _, search_query = gpt_orchestrator(objective, previous_results=previous_results, use_search=use_search)\n\n    if \"The task is complete:\" in gpt_result:\n        final_output = gpt_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = gpt_result\n        if file_content_for_gpt and not gpt_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_gpt}\"\n        sub_task_result = gpt_sub_agent(sub_task_prompt, search_query, gpt_tasks, use_search)\n        gpt_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        file_content_for_gpt = None\n\n# Include both orchestrator prompts and sub-agent results in sub-task results\nsub_task_results = [f\"Orchestrator Prompt: {prompt}\\nSub-agent Result: {result}\" for prompt, result in task_exchanges]\n\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\nrefined_output = anthropic_refine(objective, sub_task_results, timestamp, sanitized_objective)\n\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Ensure proper extraction of filenames and code contents\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")\n\n"
        },
        {
          "name": "maestro-gpt4o.py",
          "type": "blob",
          "size": 15.1103515625,
          "content": "import os\nimport re\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom datetime import datetime\nimport json\nfrom openai import OpenAI\nfrom anthropic import Anthropic\nfrom tavily import TavilyClient\n\n# Initialize OpenAI and Anthropic API clients\nopenai_client = OpenAI(api_key=\"YOUR API KEY\")\nanthropic_client = Anthropic(api_key=\"YOUR API KEY\")\n\n# Available OpenAI models\nORCHESTRATOR_MODEL = \"gpt-4o\"\nSUB_AGENT_MODEL = \"gpt-4o\"\n\n# Available Claude models for Anthropic API\nREFINER_MODEL = \"claude-3-opus-20240229\"\n\n# Initialize the Rich Console\nconsole = Console()\n\ndef calculate_subagent_cost(model, input_tokens, output_tokens):\n    # Pricing information per model\n    pricing = {\n        \"claude-3-opus-20240229\": {\"input_cost_per_mtok\": 15.00, \"output_cost_per_mtok\": 75.00},\n        \"claude-3-haiku-20240307\": {\"input_cost_per_mtok\": 0.25, \"output_cost_per_mtok\": 1.25},\n        \"claude-3-sonnet-20240229\": {\"input_cost_per_mtok\": 3.00, \"output_cost_per_mtok\": 15.00},\n    }\n\n    # Calculate cost\n    input_cost = (input_tokens / 1_000_000) * pricing[model][\"input_cost_per_mtok\"]\n    output_cost = (output_tokens / 1_000_000) * pricing[model][\"output_cost_per_mtok\"]\n    total_cost = input_cost + output_cost\n\n    return total_cost\n\ndef gpt_orchestrator(objective, file_content=None, previous_results=None, use_search=False):\n    console.print(f\"\\n[bold]Calling Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    \n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. IMPORTANT!!! when dealing with code tasks make sure you check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt. Please assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.:\\n\\nObjective: {objective}\" + ('\\nFile content:\\n' + file_content if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"}\n    ]\n\n    if use_search:\n        messages.append({\"role\": \"user\", \"content\": \"Please also generate a JSON object containing a single 'search_query' key, which represents a question that, when asked online, would yield important information for solving the subtask. The question should be specific and targeted to elicit the most relevant and helpful resources. Format your JSON like this, with no additional text before or after:\\n{\\\"search_query\\\": \\\"<question>\\\"}\\n\"})\n\n    gpt_response = openai_client.chat.completions.create(\n        model=ORCHESTRATOR_MODEL,\n        messages=messages,\n        max_tokens=4096\n    )\n\n    response_text = gpt_response.choices[0].message.content\n    usage = gpt_response.usage\n\n    console.print(Panel(response_text, title=f\"[bold green]gpt Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to gpt üëá\"))\n    console.print(f\"Input Tokens: {usage.prompt_tokens}, Output Tokens: {usage.completion_tokens}, Total Tokens: {usage.total_tokens}\")\n\n    search_query = None\n    if use_search:\n        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n        if json_match:\n            json_string = json_match.group()\n            try:\n                search_query = json.loads(json_string)[\"search_query\"]\n                console.print(Panel(f\"Search Query: {search_query}\", title=\"[bold blue]Search Query[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                response_text = response_text.replace(json_string, \"\").strip()\n            except json.JSONDecodeError as e:\n                console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n                console.print(Panel(f\"Skipping search query extraction.\", title=\"[bold yellow]Search Query Extraction Skipped[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n        else:\n            search_query = None\n\n    return response_text, file_content, search_query\n\ndef gpt_sub_agent(prompt, search_query=None, previous_gpt_tasks=None, use_search=False, continuation=False):\n    if previous_gpt_tasks is None:\n        previous_gpt_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    system_message = \"Previous gpt tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_gpt_tasks)\n    if continuation:\n        prompt = continuation_prompt\n\n    qna_response = None\n    if search_query and use_search:\n        tavily = TavilyClient(api_key=\"YOUR_API_KEY\")\n        qna_response = tavily.qna_search(query=search_query)\n        console.print(f\"QnA response: {qna_response}\", style=\"yellow\")\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_message},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    if qna_response:\n        messages.append({\"role\": \"user\", \"content\": f\"\\nSearch Results:\\n{qna_response}\"})\n\n    gpt_response = openai_client.chat.completions.create(\n        model=SUB_AGENT_MODEL,\n        messages=messages,\n        max_tokens=4096\n    )\n\n    response_text = gpt_response.choices[0].message.content\n    usage = gpt_response.usage\n\n    console.print(Panel(response_text, title=\"[bold blue]gpt Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to gpt üëá\"))\n    console.print(f\"Input Tokens: {usage.prompt_tokens}, Output Tokens: {usage.completion_tokens}, Total Tokens: {usage.total_tokens}\")\n\n    if usage.completion_tokens >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = gpt_sub_agent(prompt, search_query, previous_gpt_tasks, use_search, continuation=True)\n        response_text += continuation_response_text\n\n    return response_text\n\ndef anthropic_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    console.print(\"\\nCalling Opus to provide the refined final output for your objective:\")\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed. When working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE please provide the following:\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary.\\nWrap the JSON object in <folder_structure> tags.\\n3. Code Files: For each code file, include ONLY the file name NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\n```python\\n<code>\\n```\"}\n            ]\n        }\n    ]\n\n    opus_response = anthropic_client.messages.create(\n        model=REFINER_MODEL,\n        max_tokens=4096,\n        messages=messages\n    )\n\n    response_text = opus_response.content[0].text.strip()\n    console.print(f\"Input Tokens: {opus_response.usage.input_tokens}, Output Tokens: {opus_response.usage.output_tokens}\")\n    total_cost = calculate_subagent_cost(REFINER_MODEL, opus_response.usage.input_tokens, opus_response.usage.output_tokens)\n    console.print(f\"Refine Cost: ${total_cost:.4f}\")\n\n    if opus_response.usage.output_tokens >= 4000 and not continuation:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = anthropic_refine(objective, sub_task_results + [response_text], filename, projectname, continuation=True)\n        response_text += \"\\n\" + continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold green]Project Folder[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        return\n\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\ndef read_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n    return content\n\n# Get the objective from user input\nobjective = input(\"Please enter your objective: \")\n\n# Ask the user if they want to provide a file path\nprovide_file = input(\"Do you want to provide a file path? (y/n): \").lower() == 'y'\n\nif provide_file:\n    file_path = input(\"Please enter the file path: \")\n    if os.path.exists(file_path):\n        file_content = read_file(file_path)\n    else:\n        print(f\"File not found: {file_path}\")\n        file_content = None\nelse:\n    file_content = None\n\n# Ask the user if they want to use search\nuse_search = input(\"Do you want to use search? (y/n): \").lower() == 'y'\n\ntask_exchanges = []\ngpt_tasks = []\n\nwhile True:\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        gpt_result, file_content_for_gpt, search_query = gpt_orchestrator(objective, file_content, previous_results, use_search)\n    else:\n        gpt_result, _, search_query = gpt_orchestrator(objective, previous_results=previous_results, use_search=use_search)\n\n    \n\n    if \"The task is complete:\" in gpt_result:\n        final_output = gpt_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = gpt_result\n        if file_content_for_gpt and not gpt_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_gpt}\"\n        sub_task_result = gpt_sub_agent(sub_task_prompt, search_query, gpt_tasks, use_search)\n        gpt_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        file_content_for_gpt = None\n\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\nrefined_output = anthropic_refine(objective, [result for _, result in task_exchanges], timestamp, sanitized_objective)\n\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Ensure proper extraction of filenames and code contents\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")\n\n"
        },
        {
          "name": "maestro-groq.py",
          "type": "blob",
          "size": 12.3984375,
          "content": "import os\nimport re\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom datetime import datetime\nimport json\n\n# Set up the Groq API client\nfrom groq import Groq\nimport os\n\nclient = Groq(api_key=\"YOUR API KEY\")\n\n# Define the models to use for each agent\nORCHESTRATOR_MODEL = \"mixtral-8x7b-32768\"\nSUB_AGENT_MODEL = \"mixtral-8x7b-32768\"\nREFINER_MODEL = \"llama3-70b-8192\"\n\n# Initialize the Rich Console\nconsole = Console()\n\ndef opus_orchestrator(objective, file_content=None, previous_results=None):\n    console.print(f\"\\n[bold]Calling Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an AI orchestrator that breaks down objectives into sub-tasks.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. IMPORTANT!!! when dealing with code tasks make sure you check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt. Please assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.:\\n\\nObjective: {objective}\" + ('\\\\nFile content:\\\\n' + file_content if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"\n        }\n    ]\n\n    opus_response = client.chat.completions.create(\n        model=ORCHESTRATOR_MODEL,\n        messages=messages,\n        max_tokens=8000\n    )\n\n    response_text = opus_response.choices[0].message.content\n    console.print(Panel(response_text, title=f\"[bold green]Groq Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to Subagent üëá\"))\n    return response_text, file_content\n\ndef haiku_sub_agent(prompt, previous_haiku_tasks=None, continuation=False):\n    if previous_haiku_tasks is None:\n        previous_haiku_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    system_message = \"Previous Haiku tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_haiku_tasks)\n    if continuation:\n        prompt = continuation_prompt\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": system_message\n        },\n        {\n            \"role\": \"user\",\n            \"content\": prompt\n        }\n    ]\n\n    haiku_response = client.chat.completions.create(\n        model=SUB_AGENT_MODEL,\n        messages=messages,\n        max_tokens=8000\n    )\n\n    response_text = haiku_response.choices[0].message.content\n    console.print(Panel(response_text, title=\"[bold blue]Groq Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to Orchestrator üëá\"))\n    return response_text\n\ndef opus_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    console.print(\"\\nCalling Opus to provide the refined final output for your objective:\")\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an AI assistant that refines sub-task results into a cohesive final output.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed. Make sure the code files are completed. When working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE please provide the following:\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary.\\nWrap the JSON object in <folder_structure> tags.\\n3. Code Files: For each code file, include ONLY the file name in this format 'Filename: <filename>' NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\n‚Äãpython\\n<code>\\n‚Äã\"\n        }\n    ]\n\n    opus_response = client.chat.completions.create(\n        model=REFINER_MODEL,\n        messages=messages,\n        max_tokens=8000\n    )\n\n    response_text = opus_response.choices[0].message.content\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    # Create the project folder\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold green]Project Folder[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        return\n\n    # Recursively create the folder structure and files\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\ndef read_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n    return content\n\n# Get the objective from user input\nobjective = input(\"Please enter your objective with or without a text file path: \")\n\n# Check if the input contains a file path\nif \"./\" in objective or \"/\" in objective:\n    # Extract the file path from the objective\n    file_path = re.findall(r'[./\\w]+\\.[\\w]+', objective)[0]\n    # Read the file content\n    with open(file_path, 'r') as file:\n        file_content = file.read()\n    # Update the objective string to remove the file path\n    objective = objective.split(file_path)[0].strip()\nelse:\n    file_content = None\n\ntask_exchanges = []\nhaiku_tasks = []\n\nwhile True:\n    # Call Orchestrator to break down the objective into the next sub-task or provide the final output\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        # Pass the file content only in the first iteration if available\n        opus_result, file_content_for_haiku = opus_orchestrator(objective, file_content, previous_results)\n    else:\n        opus_result, _ = opus_orchestrator(objective, previous_results=previous_results)\n\n    if \"The task is complete:\" in opus_result:\n        # If Opus indicates the task is complete, exit the loop\n        final_output = opus_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = opus_result\n        # Append file content to the prompt for the initial call to haiku_sub_agent, if applicable\n        if file_content_for_haiku and not haiku_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_haiku}\"\n        # Call haiku_sub_agent with the prepared prompt and record the result\n        sub_task_result = haiku_sub_agent(sub_task_prompt, haiku_tasks)\n        # Log the task and its result for future reference\n        haiku_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        # Record the exchange for processing and output generation\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        # Prevent file content from being included in future haiku_sub_agent calls\n        file_content_for_haiku = None\n\n# Create the .md filename\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\n\n# Call Opus to review and refine the sub-task results\nrefined_output = opus_refine(objective, [result for _, result in task_exchanges], timestamp, sanitized_objective)\n\n# Extract the project name from the refined output\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\n# Extract the folder structure from the refined output\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Extract code files from the refined output\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\n\n# Create the folder structure and code files\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\n# Truncate the sanitized_objective to a maximum of 50 characters\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\n# Update the filename to include the project name\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\n# Prepare the full exchange log\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")"
        },
        {
          "name": "maestro-lmstudio.py",
          "type": "blob",
          "size": 15.205078125,
          "content": "import os\nimport re\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom datetime import datetime\nimport json\nfrom tavily import TavilyClient\nfrom openai import OpenAI\n\n# Set up the LM Studio API client\nclient = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n\n# Available models (replace with your own model names)\nORCHESTRATOR_MODEL = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\nSUB_AGENT_MODEL = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\nREFINER_MODEL = \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\"\n\n# Initialize the Rich Console\nconsole = Console()\n\ndef opus_orchestrator(objective, file_content=None, previous_results=None, use_search=False):\n    console.print(f\"\\n[bold]Calling Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    \n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an orchestrator responsible for breaking down complex tasks into smaller sub-tasks.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. IMPORTANT!!! when dealing with code tasks make sure you check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt. Please assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.:\\n\\nObjective: {objective}\" + ('\\\\nFile content:\\\\n' + file_content if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"\n        }\n    ]\n    if use_search:\n        messages.append({\n            \"role\": \"user\",\n            \"content\": \"Please also generate a JSON object containing a single 'search_query' key, which represents a question that, when asked online, would yield important information for solving the subtask. The question should be specific and targeted to elicit the most relevant and helpful resources. Format your JSON like this, with no additional text before or after:\\n{\\\"search_query\\\": \\\"<question>\\\"}\\n\"\n        })\n\n    opus_response = client.chat.completions.create(\n        model=ORCHESTRATOR_MODEL,\n        messages=messages,\n        temperature=0.7,\n    )\n\n    response_text = opus_response.choices[0].message.content\n\n    search_query = None\n    if use_search:\n        # Extract the JSON from the response\n        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n        if json_match:\n            json_string = json_match.group()\n            try:\n                search_query = json.loads(json_string)[\"search_query\"]\n                console.print(Panel(f\"Search Query: {search_query}\", title=\"[bold blue]Search Query[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                response_text = response_text.replace(json_string, \"\").strip()\n            except json.JSONDecodeError as e:\n                console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n                console.print(Panel(f\"Skipping search query extraction.\", title=\"[bold yellow]Search Query Extraction Skipped[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n        else:\n            search_query = None\n\n    console.print(Panel(response_text, title=f\"[bold green]Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to Haiku üëá\"))\n    return response_text, file_content, search_query\n\n\ndef haiku_sub_agent(prompt, search_query=None, previous_haiku_tasks=None, use_search=False, continuation=False):\n    if previous_haiku_tasks is None:\n        previous_haiku_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    system_message = \"Previous Haiku tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_haiku_tasks)\n    if continuation:\n        prompt = continuation_prompt\n\n    qna_response = None\n    if search_query and use_search:\n        # Initialize the Tavily client\n        tavily = TavilyClient(api_key=\"YOUR API KEY HERE\")\n        # Perform a QnA search based on the search query\n        qna_response = tavily.qna_search(query=search_query)\n        console.print(f\"QnA response: {qna_response}\", style=\"yellow\")\n\n    # Prepare the messages array with only the prompt initially\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": system_message\n        },\n        {\n            \"role\": \"user\",\n            \"content\": prompt\n        }\n    ]\n\n    # Add search results to the messages if there are any\n    if qna_response:\n        messages.append({\n            \"role\": \"user\",\n            \"content\": f\"\\nSearch Results:\\n{qna_response}\"\n        })\n\n    haiku_response = client.chat.completions.create(\n        model=SUB_AGENT_MODEL,\n        messages=messages,\n        temperature=0.7,\n    )\n\n    response_text = haiku_response.choices[0].message.content\n\n    console.print(Panel(response_text, title=\"[bold blue]Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to Opus üëá\"))\n    return response_text\n\ndef opus_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    print(\"\\nCalling Opus to provide the refined final output for your objective:\")\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are responsible for refining the sub-task results into a cohesive final output.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed. When working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE please provide the following:\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary.\\nWrap the JSON object in <folder_structure> tags.\\n3. Code Files: For each code file, include ONLY the file name NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\n‚Äãpython\\n<code>\\n‚Äã\"\n        }\n    ]\n\n    opus_response = client.chat.completions.create(\n        model=REFINER_MODEL,\n        messages=messages,\n        temperature=0.7,\n    )\n\n    response_text = opus_response.choices[0].message.content.strip()\n\n    if opus_response.usage.total_tokens >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = opus_refine(objective, sub_task_results, filename, projectname, continuation=True)\n        response_text += continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    # Create the project folder\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold green]Project Folder[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        return\n\n    # Recursively create the folder structure and files\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\ndef read_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n    return content\n\n# Get the objective from user input\nobjective = input(\"Please enter your objective with or without a text file path: \")\n\n# Check if the input contains a file path\nif \"./\" in objective or \"/\" in objective:\n    # Extract the file path from the objective\n    file_path = re.findall(r'[./\\w]+\\.[\\w]+', objective)[0]\n    # Read the file content\n    with open(file_path, 'r') as file:\n        file_content = file.read()\n    # Update the objective string to remove the file path\n    objective = objective.split(file_path)[0].strip()\nelse:\n    file_content = None\n\n# Ask the user if they want to use search\nuse_search = input(\"Do you want to use search? (y/n): \").lower() == 'y'\n\ntask_exchanges = []\nhaiku_tasks = []\n\nwhile True:\n    # Call Orchestrator to break down the objective into the next sub-task or provide the final output\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        # Pass the file content only in the first iteration if available\n        opus_result, file_content_for_haiku, search_query = opus_orchestrator(objective, file_content, previous_results, use_search)\n    else:\n        opus_result, _, search_query = opus_orchestrator(objective, previous_results=previous_results, use_search=use_search)\n\n    if \"The task is complete:\" in opus_result:\n        # If Opus indicates the task is complete, exit the loop\n        final_output = opus_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = opus_result\n        # Append file content to the prompt for the initial call to haiku_sub_agent, if applicable\n        if file_content_for_haiku and not haiku_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_haiku}\"\n        # Call haiku_sub_agent with the prepared prompt, search query, and record the result\n        sub_task_result = haiku_sub_agent(sub_task_prompt, search_query, haiku_tasks, use_search)\n        # Log the task and its result for future reference\n        haiku_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        # Record the exchange for processing and output generation\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        # Prevent file content from being included in future haiku_sub_agent calls\n        file_content_for_haiku = None\n\n# Create the .md filename\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\n\n# Call Opus to review and refine the sub-task results\nrefined_output = opus_refine(objective, [result for _, result in task_exchanges], timestamp, sanitized_objective)\n\n# Extract the project name from the refined output\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\n# Extract the folder structure from the refined output\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Extract code files from the refined output\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\n\n# Create the folder structure and code files\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\n# Truncate the sanitized_objective to a maximum of 50 characters\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\n# Update the filename to include the project name\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\n# Prepare the full exchange log\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")"
        },
        {
          "name": "maestro-ollama.py",
          "type": "blob",
          "size": 14.9296875,
          "content": "import os\nimport re\nfrom datetime import datetime\nimport json\nfrom rich.console import Console\nfrom rich.panel import Panel\nimport ollama\nfrom ollama import Client  # Import the Ollama client\nimport argparse\n\n# Only for the first time run based on the model you want to use\n# ollama.pull('llama3:70b')\n# ollama.pull('llama3:8b')\n# ollama.pull('llama3:8b')\n# ollama.pull('llama3:70b-instruct')\n# ollama.pull('llama3:instruct')\n\n# Define model identifiers as variables at the top of the script\nORCHESTRATOR_MODEL = 'llama3:70b-instruct'\nSUBAGENT_MODEL = 'llama3:instruct'\nREFINER_MODEL = 'llama3:70b-instruct'\n\n# check and pull models if they don't exist yet\nfor model in [ORCHESTRATOR_MODEL, SUBAGENT_MODEL, REFINER_MODEL]:\n    try:\n        print(f\"Checking for model: {model}\")\n        m = ollama.show(model)\n    except ollama._types.ResponseError as e:\n        print(f\"Pulling model from ollama: {model}\")\n        ollama.pull(model)\n\n# Initialize the Ollama client\nclient = Client(host='http://localhost:11434')\n\nconsole = Console()\n\ndef opus_orchestrator(objective, file_content=None, previous_results=None):\n    console.print(f\"\\n[bold]Calling Ollama Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    \n    response = client.chat(\n        model=ORCHESTRATOR_MODEL,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. Focus solely on the objective and avoid engaging in casual conversation with the subagent.\\n\\nWhen dealing with code tasks, make sure to check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt.\\n\\nPlease assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.\\n\\nObjective: {objective}\" + (f'\\nFile content:\\n{file_content}' if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"\n            }\n        ]\n    )\n    \n    response_text = response['message']['content']\n    console.print(Panel(response_text, title=\"[bold green]Ollama Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to Ollama sub-agent üëá\"))\n    return response_text, file_content\n\ndef haiku_sub_agent(prompt, previous_haiku_tasks=None, continuation=False):\n    if previous_haiku_tasks is None:\n        previous_haiku_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    if continuation:\n        prompt = continuation_prompt\n\n    # Compile previous tasks into a readable format\n    previous_tasks_summary = \"Previous Sub-agent tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_haiku_tasks)\n    \n    # Append previous tasks summary to the prompt\n    full_prompt = f\"{previous_tasks_summary}\\n\\n{prompt}\"\n\n    # Ensure prompt is not empty\n    if not full_prompt.strip():\n        raise ValueError(\"Prompt cannot be empty\")\n\n    response = client.chat(\n        model=SUBAGENT_MODEL, \n        messages=[{\"role\": \"user\", \"content\": full_prompt}]\n    )\n    \n    response_text = response['message']['content']\n    \n    if len(response_text) >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = haiku_sub_agent(continuation_prompt, previous_haiku_tasks, continuation=True)\n        response_text += continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold blue]Ollama Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to Ollama Orchestrator üëá\"))\n    return response_text\n\ndef opus_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    console.print(\"\\nCalling Ollama to provide the refined final output for your objective:\")\n    \n    response = client.chat(\n        model=REFINER_MODEL,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed.\\n\\nWhen working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE, please provide the following:\\n\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary. Wrap the JSON object in <folder_structure> tags.\\n\\n3. Code Files: For each code file, include ONLY the file name, NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING. YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\npython\\n<code>\\n\\n\\nFocus solely on the objective and avoid engaging in casual conversation. Ensure the final output is clear, concise, and addresses all aspects of the objective.‚Äã\"\n            }\n        ]\n    )\n    \n    response_text = response['message']['content']\n    \n    if len(response_text) >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = opus_refine(objective, sub_task_results, filename, projectname, continuation=True)\n        response_text += continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold blue]Project Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\ndef read_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n    return content\n   \ndef has_task_data():\n    return os.path.exists('task_data.json')\n\ndef read_task_data():\n    with open('task_data.json', 'r') as file:\n        task_data = json.load(file)\n    return task_data\n\n\ndef write_task_data(task_data):\n    with open('task_data.json', 'w') as file:\n        json.dump(task_data, file)\n\n\ncontinue_from_last_task = False\ntmp_task_data = {}\n\n# parse args\nparser = argparse.ArgumentParser()\nparser.add_argument('-p', '--prompt', type=str, help='Please enter your objective with or without a text file path')\nargs = parser.parse_args()\n\nif args.prompt is not None:\n    objective = args.prompt\nelse:\n    # Check if there is a task data file\n    if has_task_data():\n        continue_from_last_task = input(\"Do you want to continue from the last task? (y/n): \").lower() == 'y'\n\n    if continue_from_last_task:\n        tmp_task_data = read_task_data()\n        objective = tmp_task_data['objective']\n        task_exchanges = tmp_task_data['task_exchanges']\n        console.print(Panel(f\"Resuming from last task: {objective}\", title=\"[bold blue]Resuming from last task[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    else:\n        # Get the objective from user input\n        objective = input(\"Please enter your objective with or without a text file path: \")\n        tmp_task_data['objective'] = objective\n        tmp_task_data['task_exchanges'] = []\n\n# Check if the input contains a file path\nif \"./\" in objective or \"/\" in objective:\n    # Extract the file path from the objective\n    file_path = re.findall(r'[./\\w]+\\.[\\w]+', objective)[0]\n    # Read the file content\n    with open(file_path, 'r') as file:\n        file_content = file.read()\n    # Update the objective string to remove the file path\n    objective = objective.split(file_path)[0].strip()\nelse:\n    file_content = None\n\ntask_exchanges = []\nhaiku_tasks = []\n\nwhile True:\n    # Call Orchestrator to break down the objective into the next sub-task or provide the final output\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        # Pass the file content only in the first iteration if available\n        opus_result, file_content_for_haiku = opus_orchestrator(objective, file_content, previous_results)\n    else:\n        opus_result, _ = opus_orchestrator(objective, previous_results=previous_results)\n\n    if \"The task is complete:\" in opus_result:\n        # If Opus indicates the task is complete, exit the loop\n        final_output = opus_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = opus_result\n        # Append file content to the prompt for the initial call to haiku_sub_agent, if applicable\n        if file_content_for_haiku and not haiku_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_haiku}\"\n        # Call haiku_sub_agent with the prepared prompt and record the result\n        sub_task_result = haiku_sub_agent(sub_task_prompt, haiku_tasks)\n        # Log the task and its result for future reference\n        haiku_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        # Record the exchange for processing and output generation\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        # Update the task data with the new task exchanges\n        tmp_task_data['task_exchanges'] = task_exchanges\n        # Save the task data to a JSON file for resuming later\n        write_task_data(tmp_task_data)\n        # Prevent file content from being included in future haiku_sub_agent calls\n        file_content_for_haiku = None\n\n# Create the .md filename\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\n\n# Call Opus to review and refine the sub-task results\nrefined_output = opus_refine(objective, [result for _, result in task_exchanges], timestamp, sanitized_objective)\n\n# Extract the project name from the refined output\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\n# Extract the folder structure from the refined output\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Extract code files from the refined output\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\n\n# Create the folder structure and code files\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\n# Truncate the sanitized_objective to a maximum of 50 characters\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\n# Update the filename to include the project name\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\n# Prepare the full exchange log\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")\n"
        },
        {
          "name": "maestro.py",
          "type": "blob",
          "size": 17.2509765625,
          "content": "import os\nfrom anthropic import Anthropic\nimport re\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom datetime import datetime\nimport json\nfrom tavily import TavilyClient\n\n# Set up the Anthropic API client\nclient = Anthropic(api_key=\"YOUR KEY\")\n\n# Available Claude models:\n# Claude 3 Opus     claude-3-opus-20240229\n# Claude 3 Sonnet   claude-3-sonnet-20240229\n# Claude 3 Haiku    claude-3-haiku-20240307\n# Claude 3.5 Sonnet claude-3-5-sonnet-20240620\n\nORCHESTRATOR_MODEL = \"claude-3-5-sonnet-20240620\"\nSUB_AGENT_MODEL = \"claude-3-5-sonnet-20240620\"\nREFINER_MODEL = \"claude-3-5-sonnet-20240620\"\n\ndef calculate_subagent_cost(model, input_tokens, output_tokens):\n    # Pricing information per model\n    pricing = {\n        \"claude-3-opus-20240229\": {\"input_cost_per_mtok\": 15.00, \"output_cost_per_mtok\": 75.00},\n        \"claude-3-haiku-20240307\": {\"input_cost_per_mtok\": 0.25, \"output_cost_per_mtok\": 1.25},\n        \"claude-3-sonnet-20240229\": {\"input_cost_per_mtok\": 3.00, \"output_cost_per_mtok\": 15.00},\n        \"claude-3-5-sonnet-20240620\": {\"input_cost_per_mtok\": 3.00, \"output_cost_per_mtok\": 15.00},\n    }\n\n    # Calculate cost\n    input_cost = (input_tokens / 1_000_000) * pricing[model][\"input_cost_per_mtok\"]\n    output_cost = (output_tokens / 1_000_000) * pricing[model][\"output_cost_per_mtok\"]\n    total_cost = input_cost + output_cost\n\n    return total_cost\n\n# Initialize the Rich Console\nconsole = Console()\n\ndef opus_orchestrator(objective, file_content=None, previous_results=None, use_search=False):\n    console.print(f\"\\n[bold]Calling Orchestrator for your objective[/bold]\")\n    previous_results_text = \"\\n\".join(previous_results) if previous_results else \"None\"\n    if file_content:\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    \n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": f\"Based on the following objective{' and file content' if file_content else ''}, and the previous sub-task results (if any), please break down the objective into the next sub-task, and create a concise and detailed prompt for a subagent so it can execute that task. IMPORTANT!!! when dealing with code tasks make sure you check the code for errors and provide fixes and support as part of the next sub-task. If you find any bugs or have suggestions for better code, please include them in the next sub-task prompt. Please assess if the objective has been fully achieved. If the previous sub-task results comprehensively address all aspects of the objective, include the phrase 'The task is complete:' at the beginning of your response. If the objective is not yet fully achieved, break it down into the next sub-task and create a concise and detailed prompt for a subagent to execute that task.:\\n\\nObjective: {objective}\" + ('\\\\nFile content:\\\\n' + file_content if file_content else '') + f\"\\n\\nPrevious sub-task results:\\n{previous_results_text}\"}\n            ]\n        }\n    ]\n    if use_search:\n        messages[0][\"content\"].append({\"type\": \"text\", \"text\": \"Please also generate a JSON object containing a single 'search_query' key, which represents a question that, when asked online, would yield important information for solving the subtask. The question should be specific and targeted to elicit the most relevant and helpful resources. Format your JSON like this, with no additional text before or after:\\n{\\\"search_query\\\": \\\"<question>\\\"}\\n\"})\n\n    opus_response = client.messages.create(\n        model=ORCHESTRATOR_MODEL,\n        max_tokens=4096,\n        messages=messages\n    )\n\n    response_text = opus_response.content[0].text\n    console.print(f\"Input Tokens: {opus_response.usage.input_tokens}, Output Tokens: {opus_response.usage.output_tokens}\")\n    total_cost = calculate_subagent_cost(ORCHESTRATOR_MODEL, opus_response.usage.input_tokens, opus_response.usage.output_tokens)\n    console.print(f\"Orchestrator Cost: ${total_cost:.4f}\")\n\n    search_query = None\n    if use_search:\n        # Extract the JSON from the response\n        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n        if json_match:\n            json_string = json_match.group()\n            try:\n                search_query = json.loads(json_string)[\"search_query\"]\n                console.print(Panel(f\"Search Query: {search_query}\", title=\"[bold blue]Search Query[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                response_text = response_text.replace(json_string, \"\").strip()\n            except json.JSONDecodeError as e:\n                console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n                console.print(Panel(f\"Skipping search query extraction.\", title=\"[bold yellow]Search Query Extraction Skipped[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n        else:\n            search_query = None\n\n    console.print(Panel(response_text, title=f\"[bold green]Opus Orchestrator[/bold green]\", title_align=\"left\", border_style=\"green\", subtitle=\"Sending task to Haiku üëá\"))\n    return response_text, file_content, search_query\n\ndef haiku_sub_agent(prompt, search_query=None, previous_haiku_tasks=None, use_search=False, continuation=False):\n    if previous_haiku_tasks is None:\n        previous_haiku_tasks = []\n\n    continuation_prompt = \"Continuing from the previous answer, please complete the response.\"\n    system_message = \"Previous Haiku tasks:\\n\" + \"\\n\".join(f\"Task: {task['task']}\\nResult: {task['result']}\" for task in previous_haiku_tasks)\n    if continuation:\n        prompt = continuation_prompt\n\n    qna_response = None\n    if search_query and use_search:\n        # Initialize the Tavily client\n        tavily = TavilyClient(api_key=\"YOUR API KEY HERE\")\n        # Perform a QnA search based on the search query\n        qna_response = tavily.qna_search(query=search_query)\n        console.print(f\"QnA response: {qna_response}\", style=\"yellow\")\n\n    # Prepare the messages array with only the prompt initially\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [{\"type\": \"text\", \"text\": prompt}]\n        }\n    ]\n\n    # Add search results to the messages if there are any\n    if qna_response:\n        messages[0][\"content\"].append({\"type\": \"text\", \"text\": f\"\\nSearch Results:\\n{qna_response}\"})\n\n    haiku_response = client.messages.create(\n        model=SUB_AGENT_MODEL,\n        max_tokens=4096,\n        messages=messages,\n        system=system_message\n    )\n\n    response_text = haiku_response.content[0].text\n    console.print(f\"Input Tokens: {haiku_response.usage.input_tokens}, Output Tokens: {haiku_response.usage.output_tokens}\")\n    total_cost = calculate_subagent_cost(SUB_AGENT_MODEL, haiku_response.usage.input_tokens, haiku_response.usage.output_tokens)\n    console.print(f\"Sub-agent Cost: ${total_cost:.4f}\")\n\n    if haiku_response.usage.output_tokens >= 4000:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = haiku_sub_agent(prompt, search_query, previous_haiku_tasks, use_search, continuation=True)\n        response_text += continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold blue]Haiku Sub-agent Result[/bold blue]\", title_align=\"left\", border_style=\"blue\", subtitle=\"Task completed, sending result to Opus üëá\"))\n    return response_text\n\ndef opus_refine(objective, sub_task_results, filename, projectname, continuation=False):\n    print(\"\\nCalling Opus to provide the refined final output for your objective:\")\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"Objective: \" + objective + \"\\n\\nSub-task results:\\n\" + \"\\n\".join(sub_task_results) + \"\\n\\nPlease review and refine the sub-task results into a cohesive final output. Add any missing information or details as needed. When working on code projects, ONLY AND ONLY IF THE PROJECT IS CLEARLY A CODING ONE please provide the following:\\n1. Project Name: Create a concise and appropriate project name that fits the project based on what it's creating. The project name should be no more than 20 characters long.\\n2. Folder Structure: Provide the folder structure as a valid JSON object, where each key represents a folder or file, and nested keys represent subfolders. Use null values for files. Ensure the JSON is properly formatted without any syntax errors. Please make sure all keys are enclosed in double quotes, and ensure objects are correctly encapsulated with braces, separating items with commas as necessary.\\nWrap the JSON object in <folder_structure> tags.\\n3. Code Files: For each code file, include ONLY the file name NEVER EVER USE THE FILE PATH OR ANY OTHER FORMATTING YOU ONLY USE THE FOLLOWING format 'Filename: <filename>' followed by the code block enclosed in triple backticks, with the language identifier after the opening backticks, like this:\\n\\n‚Äãpython\\n<code>\\n‚Äã\"}\n            ]\n        }\n    ]\n\n    opus_response = client.messages.create(\n        model=REFINER_MODEL,\n        max_tokens=4096,\n        messages=messages\n    )\n\n    response_text = opus_response.content[0].text.strip()\n    console.print(f\"Input Tokens: {opus_response.usage.input_tokens}, Output Tokens: {opus_response.usage.output_tokens}\")\n    total_cost = calculate_subagent_cost(REFINER_MODEL, opus_response.usage.input_tokens, opus_response.usage.output_tokens)\n    console.print(f\"Refine Cost: ${total_cost:.4f}\")\n\n    if opus_response.usage.output_tokens >= 4000 and not continuation:  # Threshold set to 4000 as a precaution\n        console.print(\"[bold yellow]Warning:[/bold yellow] Output may be truncated. Attempting to continue the response.\")\n        continuation_response_text = opus_refine(objective, sub_task_results + [response_text], filename, projectname, continuation=True)\n        response_text += \"\\n\" + continuation_response_text\n\n    console.print(Panel(response_text, title=\"[bold green]Final Output[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    return response_text\n\ndef create_folder_structure(project_name, folder_structure, code_blocks):\n    # Create the project folder\n    try:\n        os.makedirs(project_name, exist_ok=True)\n        console.print(Panel(f\"Created project folder: [bold]{project_name}[/bold]\", title=\"[bold green]Project Folder[/bold green]\", title_align=\"left\", border_style=\"green\"))\n    except OSError as e:\n        console.print(Panel(f\"Error creating project folder: [bold]{project_name}[/bold]\\nError: {e}\", title=\"[bold red]Project Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        return\n\n    # Recursively create the folder structure and files\n    create_folders_and_files(project_name, folder_structure, code_blocks)\n\ndef create_folders_and_files(current_path, structure, code_blocks):\n    for key, value in structure.items():\n        path = os.path.join(current_path, key)\n        if isinstance(value, dict):\n            try:\n                os.makedirs(path, exist_ok=True)\n                console.print(Panel(f\"Created folder: [bold]{path}[/bold]\", title=\"[bold blue]Folder Creation[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n                create_folders_and_files(path, value, code_blocks)\n            except OSError as e:\n                console.print(Panel(f\"Error creating folder: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]Folder Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        else:\n            code_content = next((code for file, code in code_blocks if file == key), None)\n            if code_content:\n                try:\n                    with open(path, 'w') as file:\n                        file.write(code_content)\n                    console.print(Panel(f\"Created file: [bold]{path}[/bold]\", title=\"[bold green]File Creation[/bold green]\", title_align=\"left\", border_style=\"green\"))\n                except IOError as e:\n                    console.print(Panel(f\"Error creating file: [bold]{path}[/bold]\\nError: {e}\", title=\"[bold red]File Creation Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n            else:\n                console.print(Panel(f\"Code content not found for file: [bold]{key}[/bold]\", title=\"[bold yellow]Missing Code Content[/bold yellow]\", title_align=\"left\", border_style=\"yellow\"))\n\n# Get the objective from user input\nobjective = input(\"Please enter your objective: \")\n\n# Ask if the user wants to add a file\nadd_file = input(\"Do you want to add a text file? (y/n): \").lower() == 'y'\n\nfile_content = None\nif add_file:\n    file_path = input(\"Please enter the file path: \")\n    try:\n        with open(file_path, 'r') as file:\n            file_content = file.read()\n        console.print(Panel(f\"File content:\\n{file_content}\", title=\"[bold blue]File Content[/bold blue]\", title_align=\"left\", border_style=\"blue\"))\n    except FileNotFoundError:\n        console.print(Panel(\"File not found. Proceeding without file content.\", title=\"[bold red]File Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n    except IOError:\n        console.print(Panel(\"Error reading file. Proceeding without file content.\", title=\"[bold red]File Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Ask the user if they want to use search\nuse_search = input(\"Do you want to use search? (y/n): \").lower() == 'y'\n\ntask_exchanges = []\nhaiku_tasks = []\n\nwhile True:\n    # Call Orchestrator to break down the objective into the next sub-task or provide the final output\n    previous_results = [result for _, result in task_exchanges]\n    if not task_exchanges:\n        # Pass the file content only in the first iteration if available\n        opus_result, file_content_for_haiku, search_query = opus_orchestrator(objective, file_content, previous_results, use_search)\n    else:\n        opus_result, _, search_query = opus_orchestrator(objective, previous_results=previous_results, use_search=use_search)\n\n    if \"The task is complete:\" in opus_result:\n        # If Opus indicates the task is complete, exit the loop\n        final_output = opus_result.replace(\"The task is complete:\", \"\").strip()\n        break\n    else:\n        sub_task_prompt = opus_result\n        # Append file content to the prompt for the initial call to haiku_sub_agent, if applicable\n        if file_content_for_haiku and not haiku_tasks:\n            sub_task_prompt = f\"{sub_task_prompt}\\n\\nFile content:\\n{file_content_for_haiku}\"\n        # Call haiku_sub_agent with the prepared prompt, search query, and record the result\n        sub_task_result = haiku_sub_agent(sub_task_prompt, search_query, haiku_tasks, use_search)\n        # Log the task and its result for future reference\n        haiku_tasks.append({\"task\": sub_task_prompt, \"result\": sub_task_result})\n        # Record the exchange for processing and output generation\n        task_exchanges.append((sub_task_prompt, sub_task_result))\n        # Prevent file content from being included in future haiku_sub_agent calls\n        file_content_for_haiku = None\n\n# Create the .md filename\nsanitized_objective = re.sub(r'\\W+', '_', objective)\ntimestamp = datetime.now().strftime(\"%H-%M-%S\")\n\n# Call Opus to review and refine the sub-task results\nrefined_output = opus_refine(objective, [result for _, result in task_exchanges], timestamp, sanitized_objective)\n\n# Extract the project name from the refined output\nproject_name_match = re.search(r'Project Name: (.*)', refined_output)\nproject_name = project_name_match.group(1).strip() if project_name_match else sanitized_objective\n\n# Extract the folder structure from the refined output\nfolder_structure_match = re.search(r'<folder_structure>(.*?)</folder_structure>', refined_output, re.DOTALL)\nfolder_structure = {}\nif folder_structure_match:\n    json_string = folder_structure_match.group(1).strip()\n    try:\n        folder_structure = json.loads(json_string)\n    except json.JSONDecodeError as e:\n        console.print(Panel(f\"Error parsing JSON: {e}\", title=\"[bold red]JSON Parsing Error[/bold red]\", title_align=\"left\", border_style=\"red\"))\n        console.print(Panel(f\"Invalid JSON string: [bold]{json_string}[/bold]\", title=\"[bold red]Invalid JSON String[/bold red]\", title_align=\"left\", border_style=\"red\"))\n\n# Extract code files from the refined output\ncode_blocks = re.findall(r'Filename: (\\S+)\\s*```[\\w]*\\n(.*?)\\n```', refined_output, re.DOTALL)\n\n# Create the folder structure and code files\ncreate_folder_structure(project_name, folder_structure, code_blocks)\n\n# Truncate the sanitized_objective to a maximum of 50 characters\nmax_length = 25\ntruncated_objective = sanitized_objective[:max_length] if len(sanitized_objective) > max_length else sanitized_objective\n\n# Update the filename to include the project name\nfilename = f\"{timestamp}_{truncated_objective}.md\"\n\n# Prepare the full exchange log\nexchange_log = f\"Objective: {objective}\\n\\n\"\nexchange_log += \"=\" * 40 + \" Task Breakdown \" + \"=\" * 40 + \"\\n\\n\"\nfor i, (prompt, result) in enumerate(task_exchanges, start=1):\n    exchange_log += f\"Task {i}:\\n\"\n    exchange_log += f\"Prompt: {prompt}\\n\"\n    exchange_log += f\"Result: {result}\\n\\n\"\n\nexchange_log += \"=\" * 40 + \" Refined Final Output \" + \"=\" * 40 + \"\\n\\n\"\nexchange_log += refined_output\n\nconsole.print(f\"\\n[bold]Refined Final output:[/bold]\\n{refined_output}\")\n\nwith open(filename, 'w') as file:\n    file.write(exchange_log)\nprint(f\"\\nFull exchange log saved to {filename}\")\n"
        }
      ]
    }
  ]
}