{
  "metadata": {
    "timestamp": 1736559472237,
    "page": 36,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "superduper-io/superduper",
      "stars": 4907,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.05859375,
          "content": "requirements/* linguist-vendored\nMakefile linguist-vendored\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.5546875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n.ruff_cache\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n.virtual_documents\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n/.env\n.venv\n/env/\n/venv/\n/ENV/\n/env.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Data\n/data\n\n# Presentation material\n/img/*.monopic\n\n# PyCharm\n.idea\n\n# Supervisord logs\n/logs\n\n# Config file (maybe sensitive)\n/config.json\n/examples/*/config.json\n\n# Annoying Mac thingies\n.DS_Store\n\n# Common IDE files\n.vscode\n\n# links\n/architectures\n/superduperdb/server/static\n/superduperdb/snowflake\n/converters\n/models\n\n# Meta\n/.jd\n/.syncignore\n/supervisord.conf\n/cloudformation\n/*jd*\n/notebooks/data\n/custom_requirements.txt\n/notebooks/*.json\n/notebooks/*.bson\n\n# direnv\n.direnv/\n.envrc\n\nlightning_logs/\n.cdc.tokens\n.lancedb\n.ipynb_checkpoints\n\n# docs\n/apidocs/source/\n/docs/source\n/docs/node_modules\n/docs/.docusaurus\n\nmonkeytype.sqlite3\n\ntest/sleep.json\n\n# editors\n.vscode\n\n/tmp\n/.superduperdb\n/output/\n/deploy/testenv/requirements.txt\n/superduper/rest/superdupertmp\n/example*\n.cache\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 16.5458984375,
          "content": "# superduper.io Changelog\n\nAll notable changes to this project will be documented in this file\n\nThe format is inspired by (but not strictly follows) [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n**Before you create a Pull Request, remember to update the Changelog with your changes.**\n\n## Changes Since Last Release\n\n#### Changed defaults / behaviours\n\n- Deprecate vanilla `DataType`\n- Remove `_Encodable` from project\n- Connect to Snowflake using the incluster oauth token\n- Add postprocess in apibase model.\n- Fallback for ibis drop table\n- Add create events waiting on db apply.\n- Refactor secrets loading method.\n- Add db.load in db wait\n- Add model component cleanup\n\n#### New Features & Functionality\n\n- Streamlit component and server\n- Graceful updates when making incremental changes\n- Include templates remotely\n- Remove duplicate jobs\n- Add template information to regular component\n- Add diff when re-applying component\n- Add schema to `Template`\n- Low-code form builder for frontend\n- Add snowflake vector search engine\n- Add a meta-datatype `Vector` to handle different databackend requirements\n- Support `<var:template_staged_file>` in Template to enable apps to use files/folders included in the template\n- Add Data Component for storing data directly in the template\n- Add a standalone flag in Streamlit to mark the page as independent.\n- Add secrets directory mount for loading secret env vars.\n- Remove components recursively\n- Add metadata batched db updates\n\n#### Bug Fixes\n\n- Catch exceptions in updates vs. breakign\n- Fix the issue where the trigger fails in custom components.\n- Fix serialization between vector-search client and vector-search backend with `to_dict`\n- Fix the bug in the update diff check that replaces uuids\n- Fix snowflake vector search issues.\n- Fix crontab drop method.\n- Fix job status update.\n- Fix a random bug caused by queue thread-safety issues when OSS used crontab.\n- Fix the bug in the update mechanism that fails when the parent references an existing child.\n- Fix minor bug in openai plugin init method\n- Fix the frontend rendering issue related to choices when it is set to /describe_tables.\n- Fix the error when using batch apply with dataset.\n- Fix the bug of mismatched data types in the diff within the update mechanism.\n- Fix a small bug in sqlachmey reconnect\n\n## [0.4.0](https://github.com/superduper-io/superduper/compare/0.4.0...0.3.0])    (2024-Nov-02)\n\n#### Changed defaults / behaviours\n\n- Change images docker superduper/<image> to superduperio/<image>\n- Change the image's user from `/home/superduperdb` to `/home/superduper`\n- Add message broker service config\n- Add helper dict method in Event.\n- Use declare_component from base class.\n- Use different colors to distinguish logs\n- Change all the `_outputs.` to `_outputs__`\n- Disable cdc on output tables.\n- Remove `-` from the uuid of the component.\n- Add _execute_select and filter in the Query class.\n- Optimize the logic of ready_ids in trigger_ids.\n- Move all plugins superduperdb/ext/* to /plugins\n- Optimize the logic for file saving and retrieval in the artifact_store.\n- Add backfill on load of vector index\n- Add startup event to initialize db.apply jobs\n- Update job_id after job submission\n- Fixed default event.uuid\n- Fixed atlas vector search\n- Fix the bug where shared artifacts are deleted when removing a component.\n- Fix compatibility issues with the latest version of pymongo.\n- Fix the query parser incompatibility with '.' symbol.\n- Fix the post like in the service vector_search.\n- Fix the conflict of the same identifier during encoding.\n- Fix the issue where MongoDB did not create the output table.\n- Fix the bug in the CI where plugins are skipping tests.\n- Updated CONTRIBUTING.md\n- Add README.md files for the plugins.\n- Add templates to project\n- Add frontend to project\n- Change compute init order in cluster initialize\n- Add table error exception and sql table length fallback.\n- Permissions of artifacts increased\n- Make JSON-able a configuration depending on the databackend\n- Restore some training test cases\n- Simple querying shell\n- Fix existing templates\n- Add optional data insert to `Table`\n- Make Lance vector searcher as plugin.\n- Remove job dependencies from job metadata\n\n#### New Features & Functionality\n\n- Modify the field name output to _outputs.predict_id in the model results of Ibis.\n- Remove the document_embed function.\n- Support MongoDB outputs query\n- Make \"create a table\" compulsory\n- All datatypes should be wrapped with a Schema\n- Support eager mode\n- Add CSN env var\n- Make tests configurable against backend\n- Make the prefix of the output string configurable\n- Add testing utils for plugins\n- Add `cache` field in Component\n- Add predict_id in Listener\n- Add serve in Model\n- Added templates directory with OSS templates\n- Qdrant vector search support\n- Add placeholder for web app link in Application\n- Add support for remote artifacts\n- Add basic rest server\n- Add `@trigger` decorator to improve developer experience\n- `ModelRouter` to enable easy toggles\n- Simple interactive shell\n- Add pdf rag template\n- Updated llm_finetuning template\n- Add sql table length exceed limit and uuid truncation.\n- Add ci workflow to test templates\n- Add deploy flag in model.\n- Modify the apply endpoint in the REST API to an asynchronous interface.\n- Add db apply wait on create events.\n\n#### Bug Fixes\n\n- Vector-search vector-loading bug fixed\n- Bugs related to new queuing paradigm\n- Remove --user from make install_devkit as it supposed to run on a virtualenv.\n- component info support list\n- Trigger downstream vector indices.\n- Fix vector_index function job.\n- Fix verbosity in component info\n- Change default encoding to sqlvector\n- Fix some links in documentation\n- Change `__dataclass_params__` to `_dataclass_params`\n- Make component reload after caching in apply\n- Fix a minor bug in schedule_jobs\n- Fix vector index cleanup\n- Fix the condition of the CDC job.\n- Fix form_template\n- Fix the duplicate children in the component.\n- Fix datatype for graph models\n- Fix bug in variables\n- Fix Qdrant collection name\n- Fix the ordering and sequencing of jobs initiated on `db.apply`\n- Fix rest routes with db injection and prefix.\n- Fix cluster db setter.\n- Fix decode function\n\n## [0.3.0](https://github.com/superduper-io/superduper/compare/0.3.0...0.2.0])    (2024-Jun-21)\n\n#### Changed defaults / behaviours\n\n- Renamed superduper -> superduper\n- Added data_pipeline_deps test case\n\n#### New Features & Functionality\n\n- Add plugin component.\n- QueryTemplate component\n- Support for packaging application from the database.\n- Added DataInit component\n- Refactor ray jobs\n\n#### Bug Fixes\n\n- Fix templates\n- Fix the issue of the filter in select not working in the listener.\n- Fix exports\n- Fix model query\n- Fix doc-strings\n- Fix support for keys in new queue handler.\n- Fix the bug where the query itself changes after encoding\n- Fix the dependency error in copy_vectors within vector_index.\n- Fix Template substitutions\n- Fix remove un_use_import function\n- Fix some linting and small refactors.\n\n## [0.2.0](https://github.com/superduper-io/superduper/compare/0.1.3...0.2.0])    (2024-Jun-21)\n\n#### Changed defaults / behaviours\n\n- Run Tests from within container\n- Add model dict output indexing in graph\n- Make lance upsert for added vectors\n- Make vectors normalized in inmemory vector database for cosine measure\n- Add local cluster as tmux session\n- At the end of the test, drop the collection instead of the database\n- Force load vector indices during backfill\n- Fix pandas database (in-memory)\n- Add and update docstrings in component classes and methods\n- Changed the rest implementation to use new serialization\n- Remove unused deadcode from the project\n- Auto wrap insert documents as Document instances\n- Changed the rest implementation to use the new serialization\n- Mask special character keys in mongodb queries\n- Fix listener cleanup after removal\n- Don't require `@dc.dataclass` or `@merge_docstrings` decorator\n- Make output of `Document.encode()` more minimalistic\n- Increment minimum supported ibis version to 9.0.0\n- Make database connections reconnection on token expiry\n- Prototype the cron job services\n- Simplified Taskworkflow\n\n#### New Features & Functionality\n\n- Add nightly image for pre-release testing in the cloud environment\n- Fix  torch model fit and make schedule_jobs at db add\n- Add requires functionality for all extension modules\n- CI fails if CHANGELOG.md is not updated on PRs\n- Update Menu structure and renamed use-cases\n- Change and simplify the contract for writing new `_Predictor` descendants (`.predict_one`, `.predict`)\n- Add file datatype type to support saving and reading files/folders in artifact_store\n- Create models directly by importing package from auto and with decorator `@objectmodel`, `@torchmodel`\n- Support Schema option for MongoDB\n- Optimize LLM fine-tuning\n- Sort out the llm directory structure\n- Add cache support in inmemory vector searcher\n- Add compute_kwargs option for model\n- Add BulkWrite mongodb query\n- Rename `_Predictor` to `Model`\n- Allow developers to write `Listeners` and `Graph` in a single formalism\n- Change unittesting framework to pure configuration (no patching configs)\n- Add a simple REST server implementation\n- Add reusable snippets that are reused across the docs\n- Added snippet for connecting to superduper in docs\n- Added support to serialize documents in a flat way \"_leaves\"\n- Added `lazy_file` datatype\n- Show the DataLayer configuration\n- Optimized LLM finetuning usage experience\n- Auto-infer Schema from data\n- Lazy-creation of output tables for ibis to enable auto-inference of output schema\n- Add database packages that improve deployment and connection testing\n- Enable dependency injection on image builders\n- Add database package for oracle\n- Reconstruct data serialization and database queries\n- Auto-create tables and schemas\n- Add `Application` and `Template` support to build reusable apps\n- Add pretty-print to `Component.info`\n- `Model`\n- 'Add pluggable compute backend via config'\n\n#### Bug Fixes\n\n- Fixed cross platfrom issue in cli command\n- Separate nightly release from sandbox\n- Fixed a bug in refresh_after_insert for listeners with select None\n- Refactor graph internal with input mapping\n- Fixed a bug in Component init\n- Fixed a bug in predict in db for missing ouptuts\n- Fixed a bug in variable set\n- Fixed the bug where select in listener is modified in schedule_jobs.\n- LLM CI random errors\n- VectorIndex schedule_jobs missing function\n- Fixed some bugs of the cdc RAG application\n- Fixed open source RAG Pipeline\n- Fixed vllm real-time task concurrency bug\n- Fixed Post-Like feature\n- Added CORS Policy regarding REST server implementation\n- Fixed some bugs in multimodal usecase\n- Fixed File datatype\n- Fixed a bug in artifact store to skip duplicate artifacts\n- Fixed database permission issues when connecting to mongodb\n- Handle ProgrammingError of SnowFlake for non-existing objects\n- Updated the use cases.\n- Update references to components and artifacts.\n- Fix Ray compute async with job submission api.\n- Refactor document encode\n- Change '_leaves' to '_builds'\n- Fixed empty identifier of Code.from_object.\n- Fixed Native encodable.\n- Fix ibis cdc and cdc config\n- Fixed 'objectmodel' and 'predict_one' in doc.\n- Fixed ray dependencies bug.\n- Fixed listener dependencies bug.\n- Fixed cluster bug.\n\n## [0.1.3](https://github.com/superduper-io/superduper/compare/0.1.1...0.1.3])    (2024-Jun-20)\n\nTest release before v0.2\n\n## [0.1.1](https://github.com/superduper-io/superduper/compare/0.1.0...0.1.1])    (2024-Feb-09)\n\n#### Changed defaults / behaviours\n\n- Test suite takes config from external .env file\n- Added support for multi key in model predict\n- Support 3.10+ due to `dataclass` supported features\n- Updated the table creation method in MetaDataStore to improve compatibility across various databases\n- Replaced JSON data with String format before storage in SQLAlchemy\n- Implemented storage of byte data in base64 format\n- Migrated MongoDB Atlas vector search as a standalone searcher like lance\n- Deprecated Demo Image. Now Notebooks run in Colab\n- Replace dask with ray compute backend\n- All training and validation parameters to be configured in `_Predictor` attributes (`.trainer`, `.train_X`, etc.)\n- Docker build can include optional custom `requirements.txt` path\n\n#### New Features & Functionality\n\n- Add Llama cpp model in extensions.\n- Basic Ray server support to server models on ray cluster\n- Add Graph mode support to chain models\n- Simplify the testing of SQL databases using containerized databases\n- Integrate Monitoring(cadvisor/Prometheus) and Logging (promtail/Loki) with Grafana, in the `testenv`\n- Add `QueryModel` and `SequentialModel` to make chaining searches and models easier\n- Add `insert_to=<table-or-collection>` to `.predict` to allow single predictions to be saved.\n- Support vLLM (running locally or remotely on a ray cluster)\n- Support LLM service in OpenAI format\n- Add lazy loading of artifacts by default\n\n#### Bug Fixes\n\n- Update connection uris in `sql_examples.ipynb` to include snippets for Embedded, Cloud, and Distributed databases\n- Fixed a bug related to using Clickhouse as both databackend and metastore\n\n## [0.1.0](https://github.com/superduper-io/superduper/compare/0.0.20...0.1.0])    (2023-Dec-05)\n\n#### New Features & Functionality\n\n- Introduced Chinese version of README\n\n#### Bug Fixes\n\n- Updated paths for docker-compose.\n\n## [0.0.20](https://github.com/superduper-io/superduper/compare/0.0.10...0.0.20])    (2023-Dec-04)\n\n#### Changed defaults / behaviours\n\n- Chop down large files from the history to reduce the size of the repo\n\n## [0.0.19](https://github.com/superduper-io/superduper/compare/0.0.15...0.0.19])    (2023-Dec-04)  \n\n#### Changed defaults / behaviours\n\n- Add Changelog for tracking changes on the repo. It must be filled before any PR\n- Remove ci-pinned-dependencies and replaced them with actions with better cache management\n- Change logging mechanism from the default to loguru\n- Update icons on the README.\n- Reboot test-suite, with modular approach to toggling between SQL and MongoDB tests\n- Add model-versioning of model-outputs\n- Refactor OpenAI code to use the new features of the OpenAI API\n- Fixes for dask worker compute delegation\n- Wrap compute with abstraction as component of datalayer\n- Simplify approach to project configuration\n- Add services for vector-search and CDC for more comprehensive cluster mode\n- Add a `Component.post_create` hook to enable logic to incorporate model versions\n- Fix multiple issues with `ibis`/ SQL code\n\n#### New Features & Functionality\n\n- Add support for selecting whether logs will be redirected to the system output or directly to Loki\n\n#### Bug Fixes\n\n- Added libgl libraries in Dockerfile to correctly render the video in notebooks\n\n## [0.0.15](https://github.com/superduper-io/superduper/compare/0.0.14...0.0.15])    (2023-Nov-01)\n\n#### Changed defaults / behaviors\n\n- Updated readme by @fnikolai in #1196.\n- Removed unused import by @jieguangzhou in #1205.\n- Updated README.md with contributors by @thejumpman2323 in #1201.\n- Added conditional builders in Dockerfile by @fnikolai in #1213.\n- Optimized unit tests by @jieguangzhou in #1204.\n\n#### New Features & Functionality\n\n- Updated README.md with announcement emoji by @thejumpman2323 in #1222.\n- Launched announcement by @fnikolai in #1208.\n- Added raw SQL in ibis by @thejumpman2323 in #1220.\n- Added experimental keyword by @fnikolai in #1218.\n- Added query table by @thejumpman2323 in #1212.\n- Merged Ashishpatel26 main by @blythed in #1224.\n- Bumped Version to 0.0.15 by @fnikolai in #1225.\n\n#### Bug Fixes\n\n- Fixed dependencies and makefile by @fnikolai in #1209.\n- Fixed demo release by @fnikolai in #1210.\n\n## [0.0.14](https://github.com/superduper-io/superduper/compare/0.0.13...0.0.14])    (2023-Oct-27)\n\n## [0.0.13](https://github.com/superduper-io/superduper/compare/0.0.12...0.0.13])    (2023-Oct-19)\n\n## [0.0.12](https://github.com/superduper-io/superduper/compare/0.0.11...0.0.12])    (2023-Oct-12)\n\n## [0.0.11](https://github.com/superduper-io/superduper/compare/0.0.10...0.0.11])    (2023-Oct-10)\n\n## [0.0.10](https://github.com/superduper-io/superduper/compare/0.0.9...0.0.10])    (2023-Oct-09)\n\n## [0.0.9](https://github.com/superduper-io/superduper/compare/0.0.8...0.0.9])      (2023-Oct-06)\n\n## [0.0.8](https://github.com/superduper-io/superduper/compare/0.0.7...0.0.8])      (2023-Sep-29)\n\n## [0.0.7](https://github.com/superduper-io/superduper/compare/0.0.6...0.0.7])      (2023-Sep-14)\n\n## [0.0.6](https://github.com/superduper-io/superduper/compare/0.0.5...0.0.6])      (2023-Aug-29)\n\n## [0.0.5](https://github.com/superduper-io/superduper/compare/0.0.5...0.0.4])      (2023-Aug-15)\n\n## 0.0.4      (2023-Aug-03)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.64453125,
          "content": "# superduper Code of Conduct\n\n## Conduct\n\nWe are dedicated to fostering a friendly, safe, and inclusive environment for everyone, irrespective of their experience level, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, nationality, or any other similar characteristic.\n\n- Please refrain from using overtly sexual aliases or nicknames that might compromise the friendly and welcoming atmosphere.\n- Be kind and courteous; there's no place for mean or rude behavior.\n- Respect diverse opinions and acknowledge that every design or implementation choice involves trade-offs and costs. There is seldom a single right answer.\n- Keep unstructured critique to a minimum. If you have concrete ideas to experiment with, consider creating a fork and testing them out.\n- Insults, demeaning language, or harassment of any kind will result in exclusion from interaction. We do not tolerate behavior that marginalizes individuals in socially marginalized groups.\n- Private harassment is also unacceptable. If you feel harassed or uncomfortable, please contact one of the channel ops or any member of the Superduper moderation team immediately. We care about creating a safe community and will support you, whether you're a regular contributor or a newcomer.\n- Spamming, trolling, flaming, baiting, or any other attention-seeking behavior is not welcome.\n\n**Contact the Moderation Team: [EMAIL THE MODERATION TEAM](mailto:hello@superduperdb.com)**\n\n## Moderation\n\nThese policies outline how we uphold the standards of conduct in our community:\n\n- Remarks that violate the Superduper standards of conduct, including hateful, hurtful, oppressive, or exclusionary remarks, are strictly prohibited.\n- Moderators will respond to such remarks with a warning.\n- If the warning is disregarded, the user will be \"kicked\" from the communication channel to cool off.\n- Continued disruptive behavior may result in a ban, i.e., indefinite exclusion.\n- Moderators may, at their discretion, unban a user for a first offense if a genuine apology is offered to the offended party.\n- If you believe a ban was unjustified, address the issue with the responsible moderator in private. Complaints about bans in-channel are not allowed.\n- Moderators are held to a higher standard than other community members. In case a moderator creates an inappropriate situation, they should expect less leeway than others.\n\nIn the Superduper community, we go the extra step to look out for each other. Strive not only to be technically proficient but also to be your best self. Avoid flirting with offensive or sensitive issues, especially if they're off-topic, to prevent unnecessary conflicts, hurt feelings, and damaged trust.\n\nIf someone raises concerns about something you said or did, resist the urge to be defensive. Stop the behavior in question and apologize. Even if you believe you were misunderstood or unfairly accused, consider that there might be room for better communication. Remember, it's your responsibility to make your fellow Superduper community members comfortable.\n\nThe enforcement policies mentioned above apply to all official Superduper venues, including [Slack channels](https://join.slack.com/t/superduper-public/shared_invite/zt-1yodhtx8y-KxzECued5QBtT6JFnsSNrQ), GitHub repositories under the Superduper organization, and all forums under Superduper, Inc.\n\nAdapted with inspiration from the [Rust Code of Conduct](https://github.com/rust-lang/rust/blob/master/CODE_OF_CONDUCT.md), the [Node.js Policy on Trolling](https://blog.izs.me/2012/08/policy-on-trolling/), and the [Contributor Covenant v1.3.0](https://www.contributor-covenant.org/version/1/3/0/code-of-conduct/).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 8.7705078125,
          "content": "## How To Contribute :rocket:\n\n\nHello! :wave: \n\nThank you for considering contributing to `superduper`. There are many ways to contribute, and they are not limited to writing code. We welcome all contributions such as:\n\n- bug reports\n- documentation improvements\n- enhancement suggestions\n- expanding the reusable-snippets and use-cases\n\nThis project is intended to be a community effort, and it won't be possible without your support and enthusiasm.\n\n## Where to Start? \n\nIf you're new to open-source development, we recommend going through the [GitHub ‚Äúissues‚Äù tab](https://github.com/superduper-io/superduper/issues) to find items that interest you. Once you‚Äôve found something interesting, the next step is to create your development environment.\n\n## Installation and setup\n\nOnce you've 'forked' and 'cloned' the code to your local machine, please follow these steps:\n\nGet the code on your local:\n\n```shell\n# Clone and change location directory of the superduper repository, change the `<FORKED_NAME>` to your GitHub id\ngit clone git@github.com:<FORKED_NAME>/superduper.git\ncd superduper\n```\n\nSet up your python environment:\n\n\n```shell\n# Create your Python virtual environment\npython3 -m venv .venv\n\n# Activate the Python virtual environment\n. .venv/bin/activate  \n```\n\nInstall the dependencies:\n\n```shell\n# Install pip-tools and latest version of pip\npip install --upgrade pip-tools\n\n# Install the SuperDuper project in editable mode, along with the necessary developer tools.\npip install -e '.[test]'\n```\n\nInstall the required plugins for your development environment.\n```shell\n# The mongodb plugin is required for the tests (nosql)\npip install -e 'plugins/mongodb[test]'\n# The ibis and sqlalchemy plugins are required for the tests (sql)\npip install -e 'plugins/ibis[test]'\npip install -e 'plugins/sqlalchemy[test]'\n```\n\nYou can install any additional plugins needed for your development environment.\n\n## Branch workflow\n\nWe follow something called a \"fork and pull request\" workflow for collaborating on our project. See [here](https://gist.github.com/Chaser324/ce0505fbed06b947d962) for a great overview on what some of these mysterious terms mean! \n\n## Running the tests\n\n### Unittests\n\nThese tests check that there are no basic programming errors in how \nclasses and functions work internally.\n\n```shell\nmake unit_testing\n```\n\n### Extension integration tests\n\nWe use specific use cases to test the entire system.\n\n```shell\nmake usecase_testing\n```\n\n### Plugin tests\n\nWe maintain a set of plugins that are tested independently.. If you change the plugin code, you can run the tests for that plugin.\n\n```shell\nexport PYTHONPATH=./\n# Install the plugin you want to test\npip install -e 'plugins/<PLUGIN_NAME>[test]'\n# Run the tests\npytest plugins/<PLUGIN_NAME>/plugin_test\n```\n\n\n## Lint and type-check the code\n\nWe use `black` for code formatting, `run` for linting, and `mypy` for type-checking.\n\nYou can run the following commands to check the code:\n\n```\nmake lint-and-type-check\n```\n\nIf you want to format the code, you can run the following command:\n```\nmake fix-and-check\n```\n\n## Contributing to new plugins and templates\n\nThe `superduper` project is designed to be extensible and customizable. You can create new plugins and templates to extend the functionality of the project.\n\n### Create a new plugin\n\nPlugins are Python packages that extend the functionality of the SuperDuper project.\nMore details about the plugins can be found in the documentation:\n\n- [Data plugins](https://docs.superduper.io/docs/data_plugins/intro)\n- [AI plugins](https://docs.superduper.io/docs/category/ai-plugins)\n\nIf you want to create a new plugin, you can follow the steps below:\n\n1. Copy `plugins/template` to `plugins/<PLUGIN_NAME>`\n2. Modify the name of the plugin in the following names:\n   - Plugin name in `pyproject.toml`\n   - Package name `superduper_<PLUGIN_NAME>`\n3. Write the code for the plugin\n4. Create the tests directory `plugin_test/` and write the tests\n5. Modify the `__version__` in the `superduper_<PLUGIN_NAME>/__init__.py` file. We use this version for releasing the plugin.\n\nWe follow x.y.z versioning for the plugins, where the x.y version matches the superduper x.y version.\n\nWe increment the z version for new releases and increment the x.y version for major releases.\n\n### Create a new template\n\nTemplates are reusable components that facilitate the quick and easy building of AI applications.\nMore details about the templates can be found in the documentation:\n\n- [Templates](https://docs.superduper.io/docs/category/templates)\n\nIf you want to create a new template, you can follow the steps below:\n\n1. Create a new directory in `templates/<TEMPLATE_NAME>`\n2. Create a `build.ipynb` file with the code to build the template\n   1. Present the build process in a Jupyter notebook\n   2. Package all the components into the application\n   3. Build a template from the application\n   4. Export the template using `template.export('.')`, and then you can get `component.json` in the directory\n\n## Contributing to the documentation\nWe maintain the documentation in the [superduper-docs](https://github.com/superduper-io/superduper-docs) repository.\n\n\nPlease go to the repository and create a pull request with the changes you want to make.\n\n### Fork and clone the repository\n\n```\ngit clone git@github.com:<FORKED_NAME>/superduper-docs.git\ncd superduper-docs\n```\n\n### Updating the documentation\n\nFor most document updates and additions, you can directly modify the files under `superduper-docs/content`.\n\nBut there are some special cases:\n\n- Plugin documentation\n- Template documentation\n\n**Creating of updating documentation for a plugin**\n\nAfter you create or update a plugin, you need to update the documentation.\n\n1. Update the `README.md` file in the plugin directory.\n2. Copy the file to the `superduper-docs/content/plugins` directory and change the file name to `<PLUGIN_NAME>.md`.\n\n**Creating of updating documentation for a template**\n\nAfter you create or update a template, you need to update the documentation.\n\nWe can use the `to_docusaurus_markdown.py` script to convert the Jupyter notebook to the markdown file.\n\n```\npython3 to_docusaurus_markdown.py <Your superduper project path>/templates/<TEMPLATE_NAME>/build.ipynb\n```\n\nThen a new markdown file `<Your superduper project path>/templates/<TEMPLATE_NAME>/build.md`.\n\nYou can copy the file to the `superduper-docs/content/templates` directory and change the file name to `<TEMPLATE_NAME>.md`.\n\n\n\n\n## Create an issue\n\nIf you have an unsolvable problem or find a bug with the code, we\nwould love it if you could create a useful [issue on GitHub](https://github.com/superduper-io/superduper-stealth/issues).\n\nCreating a useful issue, is itself a useful skill. Think about following these pointers:\n\n- Add the \"bug label\" to flag the issue as a bug\n- Make sure the issue contains the ***minimal code*** needed to create the issue:\n  - Remove padding code, unnecessary setup etc. \n  - Make it as easy as possible to recreate the problem.\n- Always include the traceback in the issue\n- To flag the issue to the team, escalate this in the Slack channels\n- Tag relevant people who have worked on that issue, or know the feature\n\n## CI workflow\n\nWe have two ci workflows that run on the pull requests:\n\n- Code Testing: Unittests, Extension Integration Tests. The code testing is run on every pull request.\n- Plugin Testing: Plugin tests. The plugin testing only runs on the pull requests that change the plugin code.\n\nAdditionally, we have a plugin release workflow that runs on the main branch. The plugin release workflow will release the plugins to the PyPI.\n\n### Code Testing\n\n1. Lint and type-check\n2. Unit Testing, will run the unittests with mongodb and sqlite\n3. Usecase Testing, will run the usecases with mongodb and sqlite\n\n### Plugin Testing\n\nThe plugin use matrix testing to test the plugins which are changed in the pull request.\n\n1. Lint and type-check\n2. Run `plugins/<PLUGIN_NAME>/plugin_test`\n3. Run the base testing(Optional): If the config file `plugins/<PLUGIN_NAME>/plugin_test/config.yaml` exists, the unittests and usecases will be run with the plugin.\n\n### Release plugins on PyPI\n\nThe workflow detects commit messages like `[PLUGINS] Bump Version [plugin_1 | plugin_2]` and releases the corresponding plugins to PyPI.\n\n## Getting Help üôã\n\n[![Slack](https://img.shields.io/badge/Slack-superduper-8A2BE2?logo=slack)](https://join.slack.com/t/superduper-public/shared_invite/zt-1yodhtx8y-KxzECued5QBtT6JFnsSNrQ)\n[![Issues](https://img.shields.io/badge/Issues-superduper-8A2BE2?logo=github)](https://github.com/superduper-io/superduper/issues)\n[![Wiki](https://img.shields.io/badge/Project%20Wiki-superduper-8A2BE2?logo=github)](https://github.com/superduper-io/superduper/wiki)\n\nIf you have any problems please contact a maintainer or community volunteer. The GitHub issues or the Slack channel are a great place to start. We look forward to seeing you there! :purple_heart:\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0869140625,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [2023] [SuperDuperDB, Inc.]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0791015625,
          "content": "recursive-include superduper/templates *\nrecursive-include superduper/rest/out *\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 2.853515625,
          "content": "DIRECTORIES ?= superduper test\nSUPERDUPER_CONFIG ?= test/configs/default.yaml\nPYTEST_ARGUMENTS ?=\nPLUGIN_NAME ?=\n\n# Export directories for data and artifacts\nexport SUPERDUPER_DATA_DIR ?= ~/.cache/superduper/test_data\nexport SUPERDUPER_ARTIFACTS_DIR ?= ~/.cache/superduper/artifacts\n\n\n##@ General\n\n# Display help message with available targets\n.DEFAULT_GOAL := help\n\nhelp: ## Display this help\n\t@awk 'BEGIN {FS = \":.*##\"; printf \"\\nUsage:\\n  make \\033[36m<target>\\033[0m\\n\"} /^[a-zA-Z_0-9-]+:.*?##/ { printf \"  \\033[36m%-15s\\033[0m %s\\n\", $$1, $$2 } /^##@/ { printf \"\\n\\033[1m%s\\033[0m\\n\", substr($$0, 5) } ' $(MAKEFILE_LIST)\n\nTEMPLATES ?= '*'\n\nbuild_templates:  # build the templates with APPLY=False TEMPLATES='*'\n\tif [ \"$(TEMPLATES)\" = \"*\" ]; then \\\n\t\ttemplates_to_build=$$(ls -d templates/*/); \\\n\telse \\\n\t\ttemplates_to_build=$$(echo $(TEMPLATES) | tr ',' ' '); \\\n\tfi; \\\n\tfor template in $$templates_to_build; do \\\n\t\techo $$template; \\\n\t\trm -rf templates/$$template/blobs; \\\n\t\trm -rf templates/$$template/files; \\\n\t\trm -rf templates/$$template/.ipynb_checkpoints; \\\n\t\t(cd templates/$$template && papermill build.ipynb /tmp/papermill_output.ipynb -p APPLY False); \\\n\t\tjupyter nbconvert templates/$$template/build.ipynb --clear-output; \\\n\tdone;\n\n##@ Code Quality\n\ngen_docs: ## Generate Docs and API\n\t@echo \"===> Generate docusaurus docs and blog-posts <===\"\n\tcd docs && npm i --legacy-peer-deps && npm run build\n\tcd ..\n\t@echo \"Build finished. The HTML pages are in docs/hr/build\"\n\nlint-and-type-check: ## Lint and type-check the code\n\t@echo \"===> Code Formatting <===\"\n\tblack --check $(DIRECTORIES)\n\truff check $(DIRECTORIES)\n\n\t@echo \"===> Static Typing Check <===\"\n\n\t@if [ -d .mypy_cache ]; then rm -rf .mypy_cache; fi\n\tmypy superduper\n\t# Check for missing docstrings\n\t# interrogate superduper\n\t# Check for unused dependencies\n\t# deptry ./\n\t# Check for deadcode\n\t# vulture ./\n\ninstall_all_plugins:\n\t@plugins=\"\"; \\\n\tfor plugin in $$(ls plugins); do \\\n\t\tif [ \"$$plugin\" != \"template\" -a -d \"plugins/$$plugin\" -a -f \"plugins/$$plugin/pyproject.toml\" ]; then \\\n\t\t\tplugins=\"$$plugins $$plugin\"; \\\n\t\tfi \\\n\tdone; \\\n\techo \"Found plugins:$$plugins\"; \\\n\tfor plugin in $$plugins; do \\\n\t\techo \"Installing $$plugin...\"; \\\n\t\tpython -m pip install -e \"plugins/$$plugin[test]\"; \\\n\tdone\n%:\n\t@:\n\nfix-and-check: ##  Lint the code before testing\n\t# Code formatting\n\tblack $(DIRECTORIES)\n\t# Linter and code formatting\n\truff check --fix $(DIRECTORIES)\n\t# Linting\n\n\t@if [ -d .mypy_cache ]; then rm -rf .mypy_cache; fi\n\tmypy superduper\n\n##@ CI Testing Functions\n\nrest_testing: ## Execute rest unit tests\n\tSUPERDUPER_CONFIG=$(SUPERDUPER_CONFIG) pytest $(PYTEST_ARGUMENTS) ./test/rest\n\nunit_testing: ## Execute unit testing\n\tSUPERDUPER_CONFIG=$(SUPERDUPER_CONFIG) pytest $(PYTEST_ARGUMENTS)  test/unittest/\n\nusecase_testing: ## Execute usecase testing\n\tSUPERDUPER_CONFIG=$(SUPERDUPER_CONFIG) pytest $(PYTEST_ARGUMENTS) ./test/integration/usecase\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 12.69140625,
          "content": "<div align=\"center\">\n  <a href=\"https://www.superduper.io\">\n    <picture>\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/superduper-io/superduper-docs/main/static/img/SuperDuperDB_logo_white.svg\">\n      <source media=\"(prefers-color-scheme: light)\" srcset=\"https://raw.githubusercontent.com/superduper-io/superduper-docs/main/static/img/SuperDuperDB_logo_color.svg\">\n      <img width=\"50%\" alt=\"SuperDuper logo\" src=\"https://raw.githubusercontent.com/superduper-io/superduper-docs/main/static/img/SuperDuperDB_logo_color.svg\">\n    </picture>\n  </a>\n</div>\n<div align=\"center\">\n  <h1>Build end-to-end AI-data workflows and applications with your favourite tools</h1>\n</div>\n\n\n<div align=\"center\">\n  <h2>\n    <a href=\"https://docs.superduper.io\"><strong>Docs</strong></a> |\n    <a href=\"https://blog.superduper.io\"><strong>Blog</strong></a> |\n    <a href=\"https://superduper.io\"><strong>Website</strong></a> |\n    <a href=\"https://docs.superduper.io/docs/category/templates\"><strong>Templates</strong></a> |\n    <a href=\"https://join.slack.com/t/superduper-public/shared_invite/zt-1yodhtx8y-KxzECued5QBtT6JFnsSNrQ\"><strong>Slack</strong></a> |\n    <a href=\"https://www.youtube.com/channel/UC-clq9x8EGtQc6MHW0GF73g\"><strong>Youtube</strong></a> |\n    <a href=\"https://www.linkedin.com/company/superduper-io\"><strong>LinkedIn</strong></a>\n  </h2>\n</div>\n\n<div align=\"center\">\n  <h2>\n    <a href=\"https://pypi.org/project/superduper-framework\"><img src=\"https://img.shields.io/pypi/v/superduper-framework?color=%23007ec6&label=pypi%20package\" alt=\"Package version\"></a>\n    <a href=\"https://pypi.org/project/superduper-framework\"><img src=\"https://img.shields.io/pypi/pyversions/superduper-framework\" alt=\"Supported Python versions\"></a>    \n    <a href=\"https://github.com/superduper-io/superduper/actions/workflows/ci_code.yml\"><img src=\"https://github.com/superduper-io/superduper/actions/workflows/ci_code.yml/badge.svg?branch=main\" /></a>\n    <a href=\"https://github.com/superduper-io/superduper/blob/main/LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache_2.0-green\" alt=\"License - Apache 2.0\"></a>  \n  </h2>\n</div>\n\n\n## What is Superduper?\n\nSuperduper is a Python based framework for building **end-2-end AI-data workflows and applications** on your own data, integrating with major databases. It supports the latest technologies and techniques, including LLMs, vector-search, RAG, multimodality as well as classical AI and ML paradigms.\n\nDevelopers may leverage Superduper by building **compositional and declarative objects** which out-source the details of deployment, orchestration and versioning, and more to the Superduper engine. This allows developers to completely avoid implementing MLOps, ETL pipelines, model deployment, data migration and synchronization.\n\nUsing Superduper is simply \"**CAPE**\": **Connect** to your data, **apply** arbitrary AI to that data, **package** and reuse the application on arbitrary data, and **execute** AI-database queries and predictions on the resulting AI outputs and data.\n\n- **Connect**\n- **Apply**\n- **Package**\n- **Execute**\n\n<img src=\"https://github.com/superduper-io/superduper/blob/main/img/apply.gif\" alt=\"Alt text for the image\" style=\"width: 100%;\">\n\n**Connect**\n\n```python\ndb = superduper('mongodb|postgres|mysql|sqlite|duckdb|snowflake://<your-db-uri>')\n```\n\n**Apply**\n\n```python\nlistener = MyLLM('self_hosted_llm', architecture='llama-3.2', postprocess=my_postprocess).to_listener('documents', key='txt')\ndb.apply(listener)\n```\n\n**Package**\n\n```python\napplication = Application('my-analysis-app', components=[listener, vector_index])\ntemplate = Template('my-analysis', component=app, substitutions={'documents': 'table'})\ntemplate.export('my-analysis')\n```\n\n**Execute**\n\n```python\nquery = db['documents'].like({'txt', 'Tell me about Superduper'}, vector_index='my-index').select()\nquery.execute()\n```\n\nSuperduper may be run anywhere; you can also [contact us](https://superduper.io/contact) to learn more about the enterprise platform for bringing your Superduper workflows to production at scale. \n\n## What does Superduper support?\n\nSuperduper is flexible enough to support a huge range of AI techniques and paradigms. We have a range of pre-built functionality in the `plugins` and `templates` directories. In particular, Superduper excels when AI and data need to interact in a continuous and tightly integrated fashion. Here are some illustrative examples, which you may try out from our templates:\n\n- Semantic multimodal vector search ([images](https://github.com/superduper-io/superduper/tree/main/templates/multimodal_image_search), [text](https://github.com/superduper-io/superduper/tree/main/templates/text_vector_search), [video](https://github.com/superduper-io/superduper/tree/main/templates/multimodal_video_search))\n- [Retrieval augmented generation](https://github.com/superduper-io/superduper/tree/main/templates/retrieval_augmented_generation) with specialized requirements (data fetching involves semantic search as well as business rules and pre-processing)\n- [LLM finetuning on database hosted data](https://github.com/superduper-io/superduper/tree/main/templates/llm_finetuning)\n- [Transfer learning using multimodal data](https://github.com/superduper-io/superduper/tree/main/templates/transfer_learning)\n\nWe're looking to connect with enthusiastic developers to contribute to the repertoire of amazing pre-built templates and workflows available in Superduper open-source. Please join the discussion, by contributing issues and pull requests!\n\n## Core features\n\n- Create a Superduper data-AI connection/ datalayer consisting of your own\n  - databackend (database/ datalake/ datawarehouse)\n  - metadata store (same or other as databackend)\n  - artifact store (to store big objects)\n  - compute implementation\n- Build complex units of functionality (`Component`) using a declarative programming model, which integrate closely with data in your databackend, using a simple set of primitives and base classes.\n- Build larger units of functionality wrapping several interrelated `Component` instances into an AI-data `Application`\n- Reuse battle-tested `Component`, `Model` and `Application` instances using `Template`, giving developers an easy point to start with difficult AI implementations\n- A transparent, human-readable, web-friendly and highly portable serialization protocol, \"Superduper-protocol\", to communicate results of experimentation, make `Application` lineage and versioning easy to follow, and create an elegant segway from the AI world to the databasing/ typed-data worlds.\n- Execute queries using a combination of outputs of `Model` instances as well as primary databackend data, to enable the latest generation of AI-data applications, including all flavours of vector-search, RAG, and much, much more.\n\n## Key benefits\n\n**Massive flexibility**\n\nCombine any Python based AI model, API from the ecosystem with the most established, battle tested databases and warehouses;  Snowflake, MongoDB, Postgres, MySQL, SQL Server, SQLite, BigQuery, and Clickhouse are all supported.\n\n**Seamless integration avoiding MLOps**\n\nRemove the need to implement MLOps, using the declarative and compositional Superduper components, which specify the end state that the models and data should reach.\n\n**Promote code reusability and portability**\n\nPackage components as templates, exposing the key parameters required to reuse and communicate AI applications in your community and organization.\n\n**Cost savings**\n\nImplement vector search and embedding generation without requiring a dedicated vector database. Effortlessly toggle between self hosted models and API hosted models, without major code changes.\n\n**Move to production without any additional effort**\n\nSuperduper's REST API, allows installed models to be served without additional development work. For enterprise grade scalability, fail safes, security and logging, applications and workflows created with Superduper, may be deployed in one click on [Superduper enterprise](https://superduper.io/contact).\n\n\n## What's new in the `main` branch?\n\nWe are working on an upcoming release of `0.5.0`. In this release we will have:\n\n### A graceful update schema to update already applied components\n\nThis means that changing a prompt or parameter deep in your `Component` wont' mean \nstarting all components from scratch. This also lays the groundwork for rollbacks \nand version pins.\n\n### A smart form builder leveraging the `Template` class\n\nThis will allow developers to expose their applications as no-code interfaces.\n\n### Serialization based on Python native type annotations\n\n```python\nfrom superduper import typing as t\n\nclass MyPDF:\n    path: t.File\n    my_func: t.Blob\n    my_other_func: t.Pickle\n```\n\n## Getting started\n\n**Installation**:\n\n```bash\npip install superduper-framework\n```\n\n**View** available pre-built templates:\n\n```bash\nsuperduper ls\n```\n\n**Connect** and **apply** a pre-built template:\n\n(***Note:*** *the pre-built templates are only supported by Python 3.10; you may use all of the other features in Python 3.11+.*)\n\n```bash\n# e.g. 'mongodb://localhost:27017/test_db'\nSUPERDUPER_DATA_BACKEND=<your-db-uri> superduper apply simple_rag\n```\n\n**Execute** a query or prediction on the results:\n\n```python\nfrom superduper import superduper\ndb = superduper('<your-db-uri>')  # e.g. 'mongodb://localhost:27017/test_db'\ndb['rag'].predict('Tell me about superduper')\n```\n\n**View** and **monitor** everything in the Superduper interface. From the command line:\n\n```bash\nsuperduper start\n```\n\n***After doing this you are ready to build your own components, applications and templates!***\n\n**Get started** by copying an existing template, to your own development environment:\n\n```bash\nsuperduper bootstrap <template_name> --destination templates/my-template\n```\n\n**Edit** the `build.ipynb` notebook, to build your own functionality.\n\n## Currently supported datastores\n\n- [MongoDB](https://www.mongodb.com)\n- [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)\n- [Snowflake](https://www.snowflake.com)\n- [PostgreSQL](https://www.postgresql.org)\n- [MySQL](https://www.mysql.com)\n- [SQLite](https://www.sqlite.org)\n- [DuckDB](https://duckdb.org)\n- [Google BigQuery](https://cloud.google.com/bigquery)\n- [Microsoft SQL Server (MSSQL)](https://www.microsoft.com/en-us/sql-server)\n- [ClickHouse](https://clickhouse.com)\n\n## Community & getting help \n\nIf you have any problems, questions, comments, or ideas:\n- Join <a href=\"https://join.slack.com/t/superduper-public/shared_invite/zt-1yodhtx8y-KxzECued5QBtT6JFnsSNrQ\">our Slack</a> (we look forward to seeing you there).\n- Search through <a href=\"https://github.com/superduper-io/superduper/discussions\">our GitHub Discussions</a>, or <a href=\"https://github.com/superduper-io/superduper/discussions/new/choose\">add a new question</a>.\n- Comment <a href=\"https://github.com/superduper-io/superduper/issues/\">an existing issue</a> or create <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">a new one</a>.\n- Help us to improve Superduper by providing your valuable feedback <a href=\"https://github.com/superduper-io/superduper/discussions/new/choose\">here</a>!\n- Email us at `gethelp@superduper.io`.\n- Visit our [YouTube channel](https://www.youtube.com/@superduper-io).\n- Follow us on [Twitter (now X)](https://twitter.com/superduperdb).\n- Connect with us on [LinkedIn](https://www.linkedin.com/company/superduper-io).\n- Feel free to contact a maintainer or community volunteer directly! \n\n\n## Contributing  \nThere are many ways to contribute, and they are not limited to writing code. We welcome all contributions such as:\n\n- <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">Bug reports</a>\n- <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">Documentation improvements</a>\n- <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">Enhancement suggestions</a>\n- <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">Feature requests</a>\n- <a href=\"https://github.com/superduper-io/superduper/issues/new/choose\">Expanding the tutorials and use case examples</a>\n\nPlease see our [Contributing Guide](CONTRIBUTING.md) for details.\n\n\n## Contributors\nThanks goes to these wonderful people:\n\n<a href=\"https://github.com/superduper-io/superduper/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=superduperdb/superduper\" />\n</a>\n\n\n## License  \n\nSuperduper is open-source and intended to be a community effort, and it wouldn't be possible without your support and enthusiasm.\nIt is distributed under the terms of the Apache 2.0 license. Any contribution made to this project will be subject to the same provisions.\n\n## Join Us \nWe are looking for nice people who are invested in the problem we are trying to solve to join us full-time. Find roles that we are trying to fill <a href=\"https://join.com/companies/superduper\">here</a>!\n"
        },
        {
          "name": "img",
          "type": "tree",
          "content": null
        },
        {
          "name": "plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 3.599609375,
          "content": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"superduper-framework\"\ndescription = \"üîÆ Bring AI to your favourite database üîÆ\"\nreadme = \"README.md\"\nversion = '0.5.0.dev'\nlicense = {file = \"LICENSE\"}\nmaintainers = [{name = \"superduper.io, Inc.\", email = \"opensource@superduper.com\"}]\nkeywords = [\n    \"databases\",\n    \"mongodb\",\n    \"data-science\",\n    \"machine-learning\",\n    \"mlops\",\n    \"vector-database\",\n    \"ai\",\n]\nclassifiers = [\n    \"Development Status :: 3 - Alpha\",\n    \"Environment :: GPU :: NVIDIA CUDA\",\n    \"License :: OSI Approved :: Apache Software License\",\n    \"Operating System :: OS Independent\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: Implementation :: CPython\",\n    \"Topic :: Database\",\n    \"Topic :: Scientific/Engineering :: Artificial Intelligence\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n    \"Typing :: Typed\"\n]\nrequires-python = \">=3.10\"\ndependencies = [\n    \"boto3>=1.16\",\n    \"dill>=0.3.6\",\n    \"loguru>=0.7.2\",\n    \"loki-logger-handler==1.0.0\",\n    \"networkx>=2.8.8\",\n    \"requests>=2.22\",  # lower bound from openai and boto3\n    \"tqdm>=4.64.1\",\n    \"typer>=0.7.0\",\n    \"pydantic>=1\",\n    \"pygments\",\n    \"numpy>=1.24.3\",\n    \"overrides>=7\",\n    \"tenacity>=8.1.0,<=8.2.3\",\n    \"packaging\",\n    \"prettytable\",\n    \"python-dotenv\",\n    \"PyYAML>=6.0.0\",\n    \"uvicorn>=0.24.0\",\n    \"fastapi>=0.103.2\",\n    \"ruamel.yaml>=0.18\",\n    \"python-magic\",\n    \"apscheduler\",\n    \"python-multipart>=0.0.9\",\n    \"httpx\",\n    \"toml\",\n]\n\n[project.optional-dependencies]\ntest = [\n    \"scikit-learn>=1.1.3\",\n    \"pandas\",\n    \"pre-commit\",\n    \"black==23.3\",\n    \"ruff==0.4.4\",\n    \"mypy\",\n    \"types-PyYAML\",\n    \"types-requests\",\n    \"interrogate\",\n    \"pytest\",\n    \"pytest-cov\",\n    \"nbval>=0.10.0\",\n]\n\n[project.urls]\nhomepage = \"https://superduper.io\"\ndocumentation = \"https://docs.superduper.io/docs/intro\"\nsource = \"https://github.com/superduper-io/superduper\"\n\n[tool.setuptools]\ninclude-package-data = true\n\n[tool.setuptools.packages.find]\ninclude = [\"superduper*\"]\n\n[tool.black]\nskip-string-normalization = true\ntarget-version = [\"py38\"]\n\n[tool.mypy]\nignore_missing_imports = true\nno_implicit_optional = true\nwarn_unused_ignores = true\ndisable_error_code = [\"has-type\", \"attr-defined\", \"assignment\", \"misc\", \"override\", \"call-arg\", \"import-untyped\"]\n\n[tool.pytest.ini_options]\naddopts = \"-W ignore\"\n\n[tool.interrogate]\ncolor = true\nexclude = []\nfail-under = 30.1\nignore-magic = true\nignore-nested-classes = false\nignore-nested-functions = true\nignore-private = true\nignore-property-decorators = true\nignore-regex = []\nignore-semiprivate = true\nomit-covered-files = true\nquiet = false\nverbose = 0\nwhitelist-regex = []\n\n[tool.ruff.lint]\nextend-select = [\n    \"I\", # Missing required import (auto-fixable)\n    \"F\", # PyFlakes\n    #\"W\", # PyCode Warning\n    \"E\", # PyCode Error\n    #\"N\", # pep8-naming\n    \"D\", # pydocstyle\n]\nignore = [\n  \"D100\", # Missing docstring in public module\n  \"D104\", # Missing docstring in public package\n  \"D107\", # Missing docstring in __init__\n  \"D105\", # Missing docstring in magic method\n  \"D203\", # 1 blank line required before class docstring\n  \"D212\", # Multi-line docstring summary should start at the first line\n  \"D213\", # Multi-line docstring summary should start at the second line\n  \"D401\",\n  \"D102\",\n  \"E402\",\n]\nexclude = [\"templates\", \"superduper/templates\"]\n\n[tool.ruff.lint.isort]\ncombine-as-imports = true\n\n[tool.ruff.lint.per-file-ignores]\n\"test/**\" = [\"D\"]\n\n[project.entry-points.\"console_scripts\"]\nsuperduper = \"superduper.__main__:run\"\n"
        },
        {
          "name": "superduper",
          "type": "tree",
          "content": null
        },
        {
          "name": "templates",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}