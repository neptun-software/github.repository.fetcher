{
  "metadata": {
    "timestamp": 1736560424405,
    "page": 991,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjEwMDA=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "latitudegames/AIDungeon",
      "stars": 3194,
      "defaultBranch": "develop",
      "files": [
        {
          "name": ".editorconfig",
          "type": "blob",
          "size": 0.2431640625,
          "content": "# Normalizes editor configuration.\n# http://editorconfig.org\nroot = true\n\n[*]\nindent_style = space\nindent_size = 4\nend_of_line = LF\ncharset = utf-8\ntrim_trailing_whitespace = true\ninsert_final_newline = true\n\n[*.md]\ntrim_trailing_whitespace = false\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.142578125,
          "content": "**/__pycache__\n.idea\nAI-Adventure-2bb65e3a4e2f.json\n*.py[cod]\ndata/text_adventures.txt\nvenv/\n.vscode/\n.env/\ngenerator/gpt2/models/\nsaved_stories/\n"
        },
        {
          "name": "AIDungeon_2.ipynb",
          "type": "blob",
          "size": 8.7392578125,
          "content": "{\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0,\n  \"metadata\": {\n    \"colab\": {\n      \"name\": \"AIDungeon 2.ipynb\",\n      \"provenance\": [],\n      \"collapsed_sections\": [],\n      \"toc_visible\": true\n    },\n    \"kernelspec\": {\n      \"name\": \"python3\",\n      \"display_name\": \"Python 3\"\n    },\n    \"accelerator\": \"GPU\"\n  },\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"colab_type\": \"text\",\n        \"id\": \"pdmJ358wwzmv\"\n      },\n      \"source\": [\n        \"![BYU PCCL](https://pcc4318.files.wordpress.com/2018/02/asset-1.png?w=150)\\n\",\n        \"\\n\",\n        \"Sponsored by the BYU PCCL Lab.\\n\",\n        \"\\n\",\n        \"> AI Dungeon 2 is a completely AI generated text adventure built with OpenAI's largest GPT-2 model. It's a first of it's kind game that allows you to enter and will react to any action you can imagine.\\n\",\n        \"\\n\",\n        \"# What is this?\\n\",\n        \"Google Colab is a way to experience machine learning for free. Google provides GPUs that you can run code in. Because this game exploded however, Google likely won't be able to allow free usage of it for AI Dungeon for very long. We are almost done making an app version of the game where you will be able to play AI Dungeon 2. Until that's released you can still play the game here.\\n\",\n        \"\\n\",\n        \"# Main mirrors of AI Dungeon 2 are currently down due to high download costs.\\n\",\n        \"We are using bittorrent as a temporary solution to host game files and keep this game alive. It's not fast, but it's the best we've got right now.\\n\",\n        \"\\n\",\n        \"If you want to help, best thing you can do is to **[download this torrent file with game files](https://github.com/nickwalton/AIDungeon/files/3935881/model_v5.torrent.zip)** and **seed it** indefinitely to the best of your ability. This will help new players download this game faster, and discover the vast worlds of AIDungeon2!\\n\",\n        \"\\n\",\n        \"- <a href=\\\"https://twitter.com/nickwalton00?ref_src=twsrc%5Etfw\\\" class=\\\"twitter-follow-button\\\" data-show-count=\\\"false\\\">Follow @nickwalton00</a> on Twitter for updates on when it will be available again.\\n\",\n        \"- **[Support AI Dungeon 2](https://www.patreon.com/AIDungeon) on Patreon to help me to continue improving the game with all the awesome ideas I have for its future!**\\n\",\n        \"\\n\",\n        \"## How to play\\n\",\n        \"1. Click \\\"Tools\\\"-> \\\"Settings...\\\" -> \\\"Theme\\\" -> \\\"Dark\\\" (optional but recommended)\\n\",\n        \"2. Go to **Main Game** section below\\n\",\n        \"3. Run Install block\\n\",\n        \"3. Run Download Model block \\n\",\n        \"4. It will then take a couple minutes to boot up as the model is downloaded loaded onto the GPU. \\n\",\n        \"5. Run the game block \\n\",\n        \"6. If you have questions about getting it to work then please [go to github repo](https://github.com/AIDungeon/AIDungeon) to get help. \\n\",\n        \"\\n\",\n        \"## About\\n\",\n        \"- While you wait you can [read adventures others have had](https://aidungeon.io/)\\n\",\n        \"- [Read more](https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/) about how AI Dungeon 2 is made.\\n\",\n        \"- **[Support AI Dungeon 2](https://www.patreon.com/bePatron?u=19115449) on Patreon to help me to continue improving the game with all the awesome ideas I have for its future!**\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"colab_type\": \"text\",\n        \"id\": \"pyNN-3UDv0L-\"\n      },\n      \"source\": [\n        \"# Main Game\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"FKqlSCrpS9dH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Install\\n\",\n        \"!git clone --depth 1 --branch master https://github.com/AIDungeon/AIDungeon/\\n\",\n        \"%cd AIDungeon\\n\",\n        \"!./install.sh\\n\",\n        \"from IPython.display import clear_output\\n\",\n        \"clear_output()\\n\",\n        \"print(\\\"Installation Complete!\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"fiywfTj--_Pe\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Download model from torrent:\\n\",\n        \"!./download_model.sh\\n\",\n        \"from IPython.display import clear_output\\n\",\n        \"clear_output()\\n\",\n        \"print(\\\"Download Complete!\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"YjArwbWh6XwN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Play\\n\",\n        \"from IPython.display import Javascript\\n\",\n        \"display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\\n\",\n        \"!source ./venv/bin/activate\\n\",\n        \"!./venv/bin/python play.py\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"colab_type\": \"text\",\n        \"id\": \"kIldfwd8wjvT\"\n      },\n      \"source\": [\n        \"# Utilities (Persistent Save / Load, OOM Fix)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"zLx1yMu9wwBg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# RUN THIS FIRST before running any block below.\\n\",\n        \"# This block mount Google Drive to our workspace \\n\",\n        \"# so we can save to and load from it!\\n\",\n        \"\\n\",\n        \"import pathlib\\n\",\n        \"from distutils.dir_util import copy_tree\\n\",\n        \"from google.colab import drive\\n\",\n        \"\\n\",\n        \"drive.mount('/content/drive')\\n\",\n        \"\\n\",\n        \"drive_stories_directory=\\\"/content/drive/My Drive/AIDungeon/saved_stories\\\"\\n\",\n        \"colab_stories_directory=\\\"/content/AIDungeon/saved_stories\\\"\\n\",\n        \"\\n\",\n        \"drive_model_directory=\\\"/content/drive/My Drive/Data/model_v5\\\"\\n\",\n        \"colab_model_directory=\\\"/content/AIDungeon/generator/gpt2/models/model_v5\\\"\\n\",\n        \"\\n\",\n        \"pathlib.Path(drive_stories_directory).mkdir(parents=True, exist_ok=True) \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"LWfm6q8tAbDB\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Save stories to your Google Drive\\n\",\n        \"copy_tree(\\n\",\n        \"    colab_stories_directory, \\n\",\n        \"    drive_stories_directory\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"HK2DO1jFxnv6\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Load stories from your Google Drive\\n\",\n        \"copy_tree(\\n\",\n        \"    drive_stories_directory, \\n\",\n        \"    colab_stories_directory\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"Ue0qY7mvKrZ0\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Backup model from Colab to Google Drive. Requires 6.5GB of space!\\n\",\n        \"copy_tree(\\n\",\n        \"    colab_model_directory,\\n\",\n        \"    drive_model_directory\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": 0,\n      \"metadata\": {\n        \"colab\": {},\n        \"colab_type\": \"code\",\n        \"id\": \"XqK7MXhG40Oa\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"# Copy model from Google Drive. Make sure the model is uploaded to your personal Drive. \\n\",\n        \"# It should resides in a Data folder. The path is: /Data/model_v5/\\n\",\n        \"copy_tree(\\n\",\n        \"    drive_model_directory, \\n\",\n        \"    colab_model_directory\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {},\n      \"outputs\": [\n        {\n          \"evalue\": \"Error: Jupyter cannot be started. Error attempting to locate jupyter: Error: Module 'notebook' not installed.\",\n          \"output_type\": \"error\"\n        }\n      ],\n      \"source\": [\n        \"# If you get an OOM (out of memory error, random crashes) \\n\",\n        \"# you might want to increase the available RAM. \\n\",\n        \"\\n\",\n        \"# To do so, run this block. Wait until it crashes\\n\",\n        \"# and a little message will pops up asking if \\n\",\n        \"# you'd like to increase the available memory. Say yes and run the game.\\n\",\n        \"# Credit goes to bpseudopod for figuring this out.\\n\",\n        \"# Source: https://www.reddit.com/r/AIDungeon/comments/e782oi/tips_for_crash_prevention/\\n\",\n        \"\\n\",\n        \"d = []\\n\",\n        \"while True:\\n\",\n        \"    d.append(1)\"\n      ]\n    }\n  ]\n}\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 2.8447265625,
          "content": "# Changelog\nAll notable changes to AIDungeon will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),\nand this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).\n\n## [[Unreleased]](https://github.com/AIDungeon/AIDungeon/compare/master...develop)\n\n### Added\n\n- Formal grammars for apocalyptic setting: scavenger, mutant and headhunter contexts/prompts\n- 'Finetune the model yourself' section in README.md\n- Command line argument `--cpu` which forces use of the CPU instead of a GPU.\n\n### Fixed\n\n- `install.sh` will only use `sudo` if the user is not root\n- Fix loading saved games from the title splash to use the new local save path.\n- Fix ending punctuation being chopped off of generated text.\n\n## [2.2.0] - 2019-12-19\n\n### Added\n\n- `/reset` is a new command with the same functionality as the\nold `/restart`, saving the old and beginning a brand new game.\n- Ratings after death and winning\n- `get_rating` function to `Story` objects.\n- New content in fantasy grammar.\n- Formal grammars for peasant and rogue contexts/prompts.\n\n### Removed\n\n- F-strings for python 3.4 and 3.5 compatibility\n- Trailing comma in function args for 3.5 compatibility\n\n### Fixed\n\n- Typos in story grammar.\n- AI no longer sees `You you` when the user inputs commands beginning with `You` or `I`.\n- Some caption issues with actions.\n\n### Changed\n\n- `/restart` now restarts from the beginning of the same game.\n\n## [2.1.1] - 2019-12-17\n\n### Fixed\n\n- Bug preventing `Custom` game setting selection from working.\n- Code style.\n\n## [2.1.0] - 2019-12-16\n\n### Added\n- This changelog!\n- Formal grammars for the noble, knight, and wizard contexts/prompts.\n- Better regex logic to detect terminal states.\n- Directory `saved_stories`.\n- A few more censored words.\n- Feedback for user for the censor command.\n- iPython notebook utilities to save/load to Google Drive, and an OOM error workaround.\n- install.sh now detects python version and fails if it's not supported.\n- Issue and PR template improvements.\n\n### Fixed\n- Loading not working on `develop`.\n- Loading now print properly.\n- [No Save Game on Quit for Loaded Games](https://github.com/AIDungeon/AIDungeon/issues/97)\n- install.sh no longer tries calling `apt-get` on distributions without it.\n- Arch Linux now works with install.sh (with pyenv is used or python3.6 is set as python3).\n- A bug that caused game to crash if given an incorrect game ID to load.\n\n### Changed\n- Made `install.sh` more robust.\n- Sorted imports.\n- Split the model downloading script into `download_model.sh` from `install.sh`.\n- User commands are now case-insensitive.\n- User commands are now denoted with the prefix `/`.\n\n## [2.0.0] - 2019-12-05\n\n### Added\n- AIDungeon 2, which allows players to type in any desired action.\n\n## [1.0.0] - ?\n\n### Added\n- AiDungeon Classic, which gives players action options to choose from.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0302734375,
          "content": "Copyright (c) 2019 Nick Walton\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.1884765625,
          "content": "# AIDungeon2\n\nRead more about AIDungeon2 and how it was built [here](https://pcc.cs.byu.edu/2019/11/21/ai-dungeon-2-creating-infinitely-generated-text-adventures-with-deep-learning-language-models/).\n\nPlay the mobile app version of the game by following the links [here](https://aidungeon.io)\n\nPlay the game online by following this link [here](https://play.aidungeon.io)\n\nPlay the game in Colab [here](https://colab.research.google.com/github/AIDungeon/AIDungeon/blob/master/AIDungeon_2.ipynb).\n\nTo play the game locally, it is recommended that you have an nVidia GPU with 12 GB or more of memory, and CUDA installed. If you do not have such a GPU, each turn can take a couple of minutes or more for the game to compose its response. To install and play locally:\n```\ngit clone --branch master https://github.com/AIDungeon/AIDungeon/\ncd AIDungeon\n./install.sh # Installs system packages and creates python3 virtual environment\n./download_model.sh\nsource ./venv/bin/activate\n./play.py\n```\n\n## Finetune the model yourself\n\nFormatting the data. After scraping the data I formatted text adventures into a json dict structure that looked like the following:\n```\n{   \n    \"tree_id\": <someid>\n    \"story_start\": <start text of the story>\n    \"action_results\": [\n    {\"action\":<action1>, \"result\":<result1>, \"action_results\": <A Dict that looks like above action results>},\n    {\"action\":<action2>, \"result\":<result2>, \"action_results\": <A Dict that looks like above action results>}]\n}\n```\nEssentially it's a tree that captures all the action result nodes. \nThen I used [this](https://github.com/AIDungeon/AIDungeon/blob/develop/data/build_training_data.py) to transform that data into one giant txt file. The txt file looks something like:\n```\n<|startoftext|>\nYou are a survivor living in some place...\n> You search for food\nYou search for food but are unable to find any\n> Do another thing\nYou do another thing...\n<|endoftext|>\n(above repeated many times)\n```\n\nThen once you have that you can use the [finetuning script](https://github.com/AIDungeon/AIDungeon/blob/develop/generator/simple/finetune.py) to fine tune the model provided you have the hardware.\n\nFine tuning the largest GPT-2 model is difficult due to the immense hardware required. I no longer have access to the same hardware so there are two ways I would suggest doing it. I originally fine tuned the model on 8 32GB V100 GPUs (an Nvidia DGX1). This allowed me to use a batch size of 32 which I found to be helpful in improving quality. The only cloud resource I could find that matches those specs is an aws p3dn.24xlarge instance so you'd want to spin that up on EC2 and fine tune it there. (might have to also request higher limits). Another way you could do it is to use a sagemaker notebook (similar to a colab notebook) and select the p3.24xlarge instance type. This is equivalent to 8 16 GB V100 GPUs. Because each GPU has only 16GB memory you probably need to reduce the batch size to around 8.\n\n\nCommunity\n------------------------\n\nAIDungeon is an open source project. Questions, discussion, and\ncontributions are welcome. Contributions can be anything from new\npackages to bugfixes, documentation, or even new core features.\n\nResources:\n\n* **Website**: [aidungeon.io](http://www.aidungeon.io/)\n* **Email**: aidungeon.io@gmail.com\n* **Twitter**: [creator @nickwalton00](https://twitter.com/nickwalton00), [dev @benjbay](https://twitter.com/benjbay)\n* **Reddit**: [r/AIDungeon](https://www.reddit.com/r/AIDungeon/)\n* **Discord**: [aidungeon discord](https://discord.gg/Dg8Vcz6)\n\n\nContributing\n------------------------\nContributing to AIDungeon is easy! Just send us a\n[pull request](https://help.github.com/articles/using-pull-requests/)\nfrom your fork. Before you send it, summarize your change in the\n[Unreleased] section of [the CHANGELOG](CHANGELOG.md) and make sure\n``develop`` is the destination branch.\n\nAIDungeon uses a rough approximation of the\n[Git Flow](http://nvie.com/posts/a-successful-git-branching-model/)\nbranching model.  The ``develop`` branch contains the latest\ncontributions, and ``master`` is always tagged and points to the latest\nstable release.\n\nIf you're a contributor, make sure you're testing and playing on `develop`.\nThat's where all the magic is happening (and where we hope bugs stop).\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "download_model.sh",
          "type": "blob",
          "size": 1.5498046875,
          "content": "#!/usr/bin/env bash\ncd \"$(dirname \"${0}\")\"\nBASE_DIR=\"$(pwd)\"\n\nBASE_DIR=\"$(pwd)\"\nMODELS_DIRECTORY=generator/gpt2/models\nMODEL_VERSION=model_v5\n\nMODEL_DIRECTORY=\"${MODELS_DIRECTORY}\"\n\nMODEL_NAME=model-550\nMODEL_TORRENT_URL=\"https://github.com/AIDungeon/AIDungeon/files/3935881/model_v5.torrent.zip\"\nMODEL_TORRENT_BASENAME=\"$(basename \"${MODEL_TORRENT_URL}\")\"\n\ndownload_torrent() {\n  echo \"Creating directories.\"\n  mkdir -p \"${MODEL_DIRECTORY}\"\n  cd \"${MODEL_DIRECTORY}\"\n  wget \"${MODEL_TORRENT_URL}\"\n  unzip \"${MODEL_TORRENT_BASENAME}\"\n  which aria2c > /dev/null\n  if [ $? == 0 ]; then\n    echo -e \"\\n\\n===========================================\"\n    echo \"We are now starting to download the model.\"\n    echo \"It will take a while to get up to speed.\"\n    echo \"DHT errors are normal.\"\n    echo -e \"===========================================\\n\"\n    aria2c \\\n      --max-connection-per-server 16 \\\n      --split 64 \\\n      --bt-max-peers 500 \\\n      --seed-time=0 \\\n      --summary-interval=15 \\\n      --disable-ipv6 \\\n      \"${MODEL_TORRENT_BASENAME%.*}\"\n    echo \"Download Complete!\"\n    fi\n}\n\nredownload () {\n\techo \"Deleting $MODEL_DIRECTORY\"\n\trm -rf ${MODEL_DIRECTORY}\n\tdownload_torrent\n}\n\nif [[ -d \"${MODEL_DIRECTORY}\" ]]; then\n\tANSWER=\"n\"\n\techo \"AIDungeon2 Model appears to be downloaded.\"\n\techo \"Would you like to redownload?\"\n\techo \"WARNING: This will remove the current model![y/N]\"\n\tread ANSWER\n\tANSWER=$(echo $ANSWER | tr '[:upper:]' '[:lower:]')\n\tcase $ANSWER in\n\t\t [yY][eE][sS]|[yY])\n\t\t\tredownload;;\n\t\t*)\n\t\t\techo \"Exiting program!\"\n\t\t\texit;;\n\tesac\nelse\n\tdownload_torrent\nfi\n"
        },
        {
          "name": "generator",
          "type": "tree",
          "content": null
        },
        {
          "name": "install.sh",
          "type": "blob",
          "size": 2.0390625,
          "content": "#!/usr/bin/env bash\nset -e\ncd \"$(dirname \"${0}\")\"\nBASE_DIR=\"$(pwd)\"\nPACKAGES=(aria2 git unzip wget)\n# Tensorflow states 3.4.0 as the minimum version.\n# This is also the minimum version with venv support.\n# 3.8.0 and up only includes tensorflow 2.0 and not 1.15\nMIN_PYTHON_VERS=\"3.4.0\"\nMAX_PYTHON_VERS=\"3.7.9\"\n\nversion_check () {\n\tMAX_VERS=$(echo -e \"$(python3 --version | cut -d' ' -f2)\\n$MAX_PYTHON_VERS\\n$MIN_PYTHON_VERS\"\\\n\t| sort -V | tail -n1)\n\tMIN_VERS=$(echo -e \"$(python3 --version | cut -d' ' -f2)\\n$MAX_PYTHON_VERS\\n$MIN_PYTHON_VERS\"\\\n\t| sort -V | head -n1)\n\tif [ \"$MIN_VERS\" != \"$MIN_PYTHON_VERS\" ]; then\n\t\techo \"Your installed python version, $(python3 --version), is too old.\"\n\t\techo \"Please update to at least $MIN_PYTHON_VERS.\"\n\t\texit 1\n\telif [ \"$MAX_VERS\" != \"$MAX_PYTHON_VERS\" ]; then\n\t\techo \"Your installed python version, $(python3 --version), is too new.\"\n\t\techo \"Please install $MAX_PYTHON_VERS.\"\n\t\texit 1\n\tfi\n}\n\npip_install () {\n\tif [ ! -d \"./venv\" ]; then\n\t\t# Some distros have venv built into python so this isn't always needed.\n\t\tif is_command 'apt-get'; then\n\t\t\tapt-get install python3-venv\n\t\tfi\n\t\tpython3 -m venv ./venv\n\tfi\n\tsource \"${BASE_DIR}/venv/bin/activate\"\n\tpip install --upgrade pip setuptools\n\tpip install -r \"${BASE_DIR}/requirements.txt\"\n}\n\nis_command() {\n\tcommand -v \"${@}\" > /dev/null\n}\n\nsystem_package_install() {\n\tSUDO=''\n\tif (( $EUID != 0 )); then\n\t\tSUDO='sudo'\n\tfi\n\t\n\tPACKAGES=(aria2 git unzip wget)\n\tif is_command 'apt-get'; then\n\t\t$SUDO apt-get install ${PACKAGES[@]}\n\telif is_command 'brew'; then\n\t\tbrew install ${PACKAGES[@]}\n\telif is_command 'yum'; then\n\t\t$SUDO yum install ${PACKAGES[@]}\n\telif is_command 'dnf'; then\n\t\t$SUDO dnf install ${PACKAGES[@]}\n\telif is_command 'pacman'; then\n\t\t$SUDO pacman -S ${PACKAGES[@]}\n\telif is_command 'apk'; then\n\t\t$SUDO apk --update add ${PACKAGES[@]}\n\telse\n\t\techo \"You do not seem to be using a supported package manager.\"\n\t\techo \"Please make sure ${PACKAGES[@]} are installed then press [ENTER]\"\n\t\tread NOT_USED\n\tfi\n}\n\ninstall_aid () {\n\tversion_check\n\tpip_install\n\tsystem_package_install\n}\n\ninstall_aid\n"
        },
        {
          "name": "opening.txt",
          "type": "blob",
          "size": 1.5830078125,
          "content": "\n ▄▄▄       ██▓   ▓█████▄  █    ██  ███▄    █   ▄████ ▓█████  ▒█████   ███▄    █    \n▒████▄    ▓██▒   ▒██▀ ██▌ ██  ▓██▒ ██ ▀█   █  ██▒ ▀█▒▓█   ▀ ▒██▒  ██▒ ██ ▀█   █    \n▒██  ▀█▄  ▒██▒   ░██   █▌▓██  ▒██░▓██  ▀█ ██▒▒██░▄▄▄░▒███   ▒██░  ██▒▓██  ▀█ ██▒   \n░██▄▄▄▄██ ░██░   ░▓█▄   ▌▓▓█  ░██░▓██▒  ▐▌██▒░▓█  ██▓▒▓█  ▄ ▒██   ██░▓██▒  ▐▌██▒   \n ▓█   ▓██▒░██░   ░▒████▓ ▒▒█████▓ ▒██░   ▓██░░▒▓███▀▒░▒████▒░ ████▓▒░▒██░   ▓██░   \n ▒▒   ▓▒█░░▓      ▒▒▓  ▒ ░▒▓▒ ▒ ▒ ░ ▒░   ▒ ▒  ░▒   ▒ ░░ ▒░ ░░ ▒░▒░▒░ ░ ▒░   ▒ ▒    \n  ▒   ▒▒ ░ ▒ ░    ░ ▒  ▒ ░░▒░ ░ ░ ░ ░░   ░ ▒░  ░   ░  ░ ░  ░  ░ ▒ ▒░ ░ ░░   ░ ▒░   \n  ░   ▒    ▒ ░    ░ ░  ░  ░░░ ░ ░    ░   ░ ░ ░ ░   ░    ░   ░ ░ ░ ▒     ░   ░ ░    \n      ░  ░ ░        ░       ░              ░       ░    ░  ░    ░ ░           ░    \n                  ░                                                                \n"
        },
        {
          "name": "other",
          "type": "tree",
          "content": null
        },
        {
          "name": "play.py",
          "type": "blob",
          "size": 13.416015625,
          "content": "#!/usr/bin/env python3\nimport os\nimport random\nimport sys\nimport time\nimport argparse\n\nfrom generator.gpt2.gpt2_generator import *\nfrom story import grammars\nfrom story.story_manager import *\nfrom story.utils import *\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nparser = argparse.ArgumentParser(\"Play AIDungeon 2\")\nparser.add_argument(\n    \"--cpu\",\n    action=\"store_true\",\n    help=\"Force using CPU instead of GPU.\"\n)\n\n\ndef splash():\n    print(\"0) New Game\\n1) Load Game\\n\")\n    choice = get_num_options(2)\n\n    if choice == 1:\n        return \"load\"\n    else:\n        return \"new\"\n\n\ndef random_story(story_data):\n    # random setting\n    settings = story_data[\"settings\"].keys()\n    n_settings = len(settings)\n    n_settings = 2\n    rand_n = random.randint(0, n_settings - 1)\n    for i, setting in enumerate(settings):\n        if i == rand_n:\n            setting_key = setting\n\n    # random character\n    characters = story_data[\"settings\"][setting_key][\"characters\"]\n    n_characters = len(characters)\n    rand_n = random.randint(0, n_characters - 1)\n    for i, character in enumerate(characters):\n        if i == rand_n:\n            character_key = character\n\n    # random name\n    name = grammars.direct(setting_key, \"character_name\")\n\n    return setting_key, character_key, name, None, None\n\n\ndef select_game():\n    with open(YAML_FILE, \"r\") as stream:\n        data = yaml.safe_load(stream)\n\n    # Random story?\n    print(\"Random story?\")\n    console_print(\"0) yes\")\n    console_print(\"1) no\")\n    choice = get_num_options(2)\n\n    if choice == 0:\n        return random_story(data)\n\n    # User-selected story...\n    print(\"\\n\\nPick a setting.\")\n    settings = data[\"settings\"].keys()\n    for i, setting in enumerate(settings):\n        print_str = str(i) + \") \" + setting\n        if setting == \"fantasy\":\n            print_str += \" (recommended)\"\n\n        console_print(print_str)\n    console_print(str(len(settings)) + \") custom\")\n    choice = get_num_options(len(settings) + 1)\n\n    if choice == len(settings):\n        return \"custom\", None, None, None, None\n\n    setting_key = list(settings)[choice]\n\n    print(\"\\nPick a character\")\n    characters = data[\"settings\"][setting_key][\"characters\"]\n    for i, character in enumerate(characters):\n        console_print(str(i) + \") \" + character)\n    character_key = list(characters)[get_num_options(len(characters))]\n\n    name = input(\"\\nWhat is your name? \")\n    setting_description = data[\"settings\"][setting_key][\"description\"]\n    character = data[\"settings\"][setting_key][\"characters\"][character_key]\n\n    return setting_key, character_key, name, character, setting_description\n\n\ndef get_custom_prompt():\n    context = \"\"\n    console_print(\n        \"\\nEnter a prompt that describes who you are and the first couple sentences of where you start \"\n        \"out ex:\\n 'You are a knight in the kingdom of Larion. You are hunting the evil dragon who has been \"\n        + \"terrorizing the kingdom. You enter the forest searching for the dragon and see' \"\n    )\n    prompt = input(\"Starting Prompt: \")\n    return context, prompt\n\n\ndef get_curated_exposition(\n    setting_key, character_key, name, character, setting_description\n):\n    name_token = \"<NAME>\"\n    try:\n        context = grammars.generate(setting_key, character_key, \"context\") + \"\\n\\n\"\n        context = context.replace(name_token, name)\n        prompt = grammars.generate(setting_key, character_key, \"prompt\")\n        prompt = prompt.replace(name_token, name)\n    except:\n        context = (\n            \"You are \"\n            + name\n            + \", a \"\n            + character_key\n            + \" \"\n            + setting_description\n            + \"You have a \"\n            + character[\"item1\"]\n            + \" and a \"\n            + character[\"item2\"]\n            + \". \"\n        )\n        prompt_num = np.random.randint(0, len(character[\"prompts\"]))\n        prompt = character[\"prompts\"][prompt_num]\n\n    return context, prompt\n\n\ndef instructions():\n    text = \"\\nAI Dungeon 2 Instructions:\"\n    text += '\\n Enter actions starting with a verb ex. \"go to the tavern\" or \"attack the orc.\"'\n    text += '\\n To speak enter \\'say \"(thing you want to say)\"\\' or just \"(thing you want to say)\" '\n    text += \"\\n\\nThe following commands can be entered for any action: \"\n    text += '\\n  \"/revert\"   Reverts the last action allowing you to pick a different action.'\n    text += '\\n  \"/quit\"     Quits the game and saves'\n    text += '\\n  \"/reset\"    Starts a new game and saves your current one'\n    text += '\\n  \"/restart\"  Starts the game from beginning with same settings'\n    text += '\\n  \"/save\"     Makes a new save of your game and gives you the save ID'\n    text += '\\n  \"/load\"     Asks for a save ID and loads the game if the ID is valid'\n    text += '\\n  \"/print\"    Prints a transcript of your adventure (without extra newline formatting)'\n    text += '\\n  \"/help\"     Prints these instructions again'\n    text += '\\n  \"/censor off/on\" to turn censoring off or on.'\n    return text\n\n\ndef play_aidungeon_2(args):\n    \"\"\"\n    Entry/main function for starting AIDungeon 2\n\n    Arguments:\n        args (namespace): Arguments returned by the\n                          ArgumentParser\n    \"\"\"\n\n    console_print(\n        \"AI Dungeon 2 will save and use your actions and game to continually improve AI Dungeon.\"\n        + \" If you would like to disable this enter '/nosaving' as an action. This will also turn off the \"\n        + \"ability to save games.\"\n    )\n\n    upload_story = True\n\n    print(\"\\nInitializing AI Dungeon! (This might take a few minutes)\\n\")\n    generator = GPT2Generator(force_cpu=args.cpu)\n    story_manager = UnconstrainedStoryManager(generator)\n    print(\"\\n\")\n\n    with open(\"opening.txt\", \"r\", encoding=\"utf-8\") as file:\n        starter = file.read()\n    print(starter)\n\n    while True:\n        if story_manager.story != None:\n            story_manager.story = None\n\n        while story_manager.story is None:\n            print(\"\\n\\n\")\n            splash_choice = splash()\n\n            if splash_choice == \"new\":\n                print(\"\\n\\n\")\n                (\n                    setting_key,\n                    character_key,\n                    name,\n                    character,\n                    setting_description,\n                ) = select_game()\n\n                if setting_key == \"custom\":\n                    context, prompt = get_custom_prompt()\n\n                else:\n                    context, prompt = get_curated_exposition(\n                        setting_key, character_key, name, character, setting_description\n                    )\n\n                console_print(instructions())\n                print(\"\\nGenerating story...\")\n\n                result = story_manager.start_new_story(\n                    prompt, context=context, upload_story=upload_story\n                )\n                print(\"\\n\")\n                console_print(result)\n\n            else:\n                load_ID = input(\"What is the ID of the saved game? \")\n                result = story_manager.load_new_story(\n                    load_ID, upload_story=upload_story\n                )\n                print(\"\\nLoading Game...\\n\")\n                console_print(result)\n\n        while True:\n            sys.stdin.flush()\n            action = input(\"> \").strip()\n            if len(action) > 0 and action[0] == \"/\":\n                split = action[1:].split(\" \")  # removes preceding slash\n                command = split[0].lower()\n                args = split[1:]\n                if command == \"reset\":\n                    story_manager.story.get_rating()\n                    break\n\n                elif command == \"restart\":\n                    story_manager.story.actions = []\n                    story_manager.story.results = []\n                    console_print(\"Game restarted.\")\n                    console_print(story_manager.story.story_start)\n                    continue\n\n                elif command == \"quit\":\n                    story_manager.story.get_rating()\n                    exit()\n\n                elif command == \"nosaving\":\n                    upload_story = False\n                    story_manager.story.upload_story = False\n                    console_print(\"Saving turned off.\")\n\n                elif command == \"help\":\n                    console_print(instructions())\n\n                elif command == \"censor\":\n                    if len(args) == 0:\n                        if generator.censor:\n                            console_print(\"Censor is enabled.\")\n                        else:\n                            console_print(\"Censor is disabled.\")\n                    elif args[0] == \"off\":\n                        if not generator.censor:\n                            console_print(\"Censor is already disabled.\")\n                        else:\n                            generator.censor = False\n                            console_print(\"Censor is now disabled.\")\n\n                    elif args[0] == \"on\":\n                        if generator.censor:\n                            console_print(\"Censor is already enabled.\")\n                        else:\n                            generator.censor = True\n                            console_print(\"Censor is now enabled.\")\n\n                    else:\n                        console_print(\"Invalid argument: {}\".format(args[0]))\n\n                elif command == \"save\":\n                    if upload_story:\n                        id = story_manager.story.save_to_storage()\n                        console_print(\"Game saved.\")\n                        console_print(\n                            \"To load the game, type 'load' and enter the \"\n                            \"following ID: {}\".format(id)\n                        )\n                    else:\n                        console_print(\"Saving has been turned off. Cannot save.\")\n\n                elif command == \"load\":\n                    if len(args) == 0:\n                        load_ID = input(\"What is the ID of the saved game?\")\n                    else:\n                        load_ID = args[0]\n                    result = story_manager.story.load_from_storage(load_ID)\n                    console_print(\"\\nLoading Game...\\n\")\n                    console_print(result)\n\n                elif command == \"print\":\n                    print(\"\\nPRINTING\\n\")\n                    print(str(story_manager.story))\n\n                elif command == \"revert\":\n                    if len(story_manager.story.actions) == 0:\n                        console_print(\"You can't go back any farther. \")\n                        continue\n\n                    story_manager.story.actions = story_manager.story.actions[:-1]\n                    story_manager.story.results = story_manager.story.results[:-1]\n                    console_print(\"Last action reverted. \")\n                    if len(story_manager.story.results) > 0:\n                        console_print(story_manager.story.results[-1])\n                    else:\n                        console_print(story_manager.story.story_start)\n                    continue\n\n                else:\n                    console_print(\"Unknown command: {}\".format(command))\n\n            else:\n                if action == \"\":\n                    action = \"\"\n                    result = story_manager.act(action)\n                    console_print(result)\n\n                elif action[0] == '\"':\n                    action = \"You say \" + action\n\n                else:\n                    action = action.strip()\n\n                    if \"you\" not in action[:6].lower() and \"I\" not in action[:6]:\n                        action = action[0].lower() + action[1:]\n                        action = \"You \" + action\n\n                    if action[-1] not in [\".\", \"?\", \"!\"]:\n                        action = action + \".\"\n\n                    action = first_to_second_person(action)\n\n                    action = \"\\n> \" + action + \"\\n\"\n\n                result = \"\\n\" + story_manager.act(action)\n                if len(story_manager.story.results) >= 2:\n                    similarity = get_similarity(\n                        story_manager.story.results[-1], story_manager.story.results[-2]\n                    )\n                    if similarity > 0.9:\n                        story_manager.story.actions = story_manager.story.actions[:-1]\n                        story_manager.story.results = story_manager.story.results[:-1]\n                        console_print(\n                            \"Woops that action caused the model to start looping. Try a different action to prevent that.\"\n                        )\n                        continue\n\n                if player_won(result):\n                    console_print(result + \"\\n CONGRATS YOU WIN\")\n                    story_manager.story.get_rating()\n                    break\n                elif player_died(result):\n                    console_print(result)\n                    console_print(\"YOU DIED. GAME OVER\")\n                    console_print(\"\\nOptions:\")\n                    console_print(\"0) Start a new game\")\n                    console_print(\n                        \"1) \\\"I'm not dead yet!\\\" (If you didn't actually die) \"\n                    )\n                    console_print(\"Which do you choose? \")\n                    choice = get_num_options(2)\n                    if choice == 0:\n                        story_manager.story.get_rating()\n                        break\n                    else:\n                        console_print(\"Sorry about that...where were we?\")\n                        console_print(result)\n\n                else:\n                    console_print(result)\n\n\nif __name__ == \"__main__\":\n    args = parser.parse_args()\n    play_aidungeon_2(args)\n"
        },
        {
          "name": "play_dm.py",
          "type": "blob",
          "size": 1.3349609375,
          "content": "#!/usr/bin/env python3\nimport os\nimport sys\nimport time\n\nfrom generator.gpt2.gpt2_generator import *\nfrom generator.human_dm import *\nfrom play import *\nfrom story.story_manager import *\nfrom story.utils import *\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\n\nclass AIPlayer:\n    def __init__(self, generator):\n        self.generator = generator\n\n    def get_action(self, prompt):\n        return self.generator.generate_raw(prompt)\n\n\ndef play_dm():\n\n    console_print(\"Initializing AI Dungeon DM Mode\")\n    generator = GPT2Generator(temperature=0.9)\n\n    story_manager = UnconstrainedStoryManager(HumanDM())\n    context, prompt = select_game()\n    console_print(context + prompt)\n    story_manager.start_new_story(prompt, context=context, upload_story=False)\n\n    player = AIPlayer(generator)\n\n    while True:\n        action_prompt = story_manager.story_context() + \"What do you do next? \\n> You\"\n        action = player.get_action(action_prompt)\n        print(\"\\n******DEBUG FULL ACTION*******\")\n        print(action)\n        print(\"******END DEBUG******\\n\")\n        action = action.split(\"\\n\")[0]\n        punc = action.rfind(\".\")\n        if punc > 0:\n            action = action[: punc + 1]\n        shown_action = \"> You\" + action\n        console_print(second_to_first_person(shown_action))\n        story_manager.act(action)\n\n\nif __name__ == \"__main__\":\n    play_dm()\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.087890625,
          "content": "google-cloud-storage\ngsutil\nnumpy\nprofanityfilter\npyyaml\nregex\ntensorflow==1.15.2\ntracery\n"
        },
        {
          "name": "story",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}