{
  "metadata": {
    "timestamp": 1736559450449,
    "page": 2,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "princeton-nlp/tree-of-thought-llm",
      "stars": 4995,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.076171875,
          "content": "/*__pycache__/\ndist/\nsrc/tree_of_thoughts_llm.egg-info/\n.env\n*.pyc\n*.DS_Store\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0419921875,
          "content": "MIT License\n\nCopyright (c) 2023 Shunyu Yao\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.177734375,
          "content": "include src/tot/data/24/24.csv\ninclude src/tot/data/crosswords/mini0505_0_100_5.json\ninclude src/tot/data/crosswords/mini0505.json\ninclude src/tot/data/text/data_100_random_text.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.9033203125,
          "content": "# Official Repo of Tree of Thoughts (ToT)\n\n<p>\n    <a href=\"https://badge.fury.io/py/tree-of-thoughts-llm\">\n        <img src=\"https://badge.fury.io/py/tree-of-thoughts-llm.svg\">\n    </a>\n    <a href=\"https://www.python.org/\">\n        <img alt=\"Build\" src=\"https://img.shields.io/badge/Python-3.7+-1f425f.svg?color=purple\">\n    </a>\n    <a href=\"https://copyright.princeton.edu/policy\">\n        <img alt=\"License\" src=\"https://img.shields.io/badge/License-MIT-blue\">\n    </a>\n    <a href=\"https://zenodo.org/badge/latestdoi/642099326\">\n        <img src=\"https://zenodo.org/badge/642099326.svg\">\n    </a>\n</p>\n\n![teaser](pics/teaser.png)\n\nOfficial implementation for paper [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) with code, prompts, model outputs.\nAlso check [its tweet thread](https://twitter.com/ShunyuYao12/status/1659357547474681857) in 1min.\n\n\n\n\n\n## Setup\n1. Set up OpenAI API key and store in environment variable ``OPENAI_API_KEY`` (see [here](https://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety)). \n\n2. Install `tot` package in two ways:\n- Option 1: Install from PyPI\n```bash\npip install tree-of-thoughts-llm\n```\n- Option 2: Install from source\n```bash\ngit clone https://github.com/princeton-nlp/tree-of-thought-llm\ncd tree-of-thought-llm\npip install -r requirements.txt\npip install -e .  # install `tot` package\n```\n\n\n## Quick Start\nThe following minimal script will attempt to solve the game of 24 with `4 5 6 10` (might be a bit slow as it's using GPT-4):\n```python\nimport argparse\nfrom tot.methods.bfs import solve\nfrom tot.tasks.game24 import Game24Task\n\nargs = argparse.Namespace(backend='gpt-4', temperature=0.7, task='game24', naive_run=False, prompt_sample=None, method_generate='propose', method_evaluate='value', method_select='greedy', n_generate_sample=1, n_evaluate_sample=3, n_select_sample=5)\n\ntask = Game24Task()\nys, infos = solve(args, task, 900)\nprint(ys[0])\n```\n\nAnd the output would be something like (note it's not deterministic, and sometimes the output can be wrong):\n```\n10 - 4 = 6 (left: 5 6 6)\n5 * 6 = 30 (left: 6 30)\n30 - 6 = 24 (left: 24)\nAnswer: (5 * (10 - 4)) - 6 = 24\n```\n\n## Paper Experiments\n\nRun experiments via ``sh scripts/{game24, text, crosswords}/{standard_sampling, cot_sampling, bfs}.sh``, except in crosswords we use a DFS algorithm for ToT, which can be run via ``scripts/crosswords/search_crosswords-dfs.ipynb``.\n\nThe very simple ``run.py`` implements the ToT + BFS algorithm, as well as the naive IO/CoT sampling. Some key arguments:\n\n- ``--naive_run``: if True, run naive IO/CoT sampling instead of ToT + BFS.\n-  ``--prompt_sample`` (choices=[``standard``, ``cot``]): sampling prompt\n- ``--method_generate`` (choices=[``sample``, ``propose``]): thought generator, whether to sample independent thoughts (used in Creative Writing) or propose sequential thoughts (used in Game of 24)\n- ``--method_evaluate`` (choices=[``value``, ``vote``]): state evaluator, whether to use the value states independently (used in Game of 24) or vote on states together (used in Creative Writing)\n- ``--n_generate_sample``: number of times to prompt for thought generation\n- ``--n_evaluate_sample``: number of times to prompt for state evaluation\n- ``--n_select_sample``: number of states to keep from each step (i.e. ``b`` in the paper's ToT + BFS algorithm)\n\n\n\n## Paper Trajectories\n``logs/`` contains all the trajectories from the paper's experiments, except for ``logs/game24/gpt-4_0.7_propose1_value3_greedy5_start900_end1000.json`` which was reproduced after the paper (as the original experiment was done in a notebook) and achieved a 69\\% score instead of the original 74\\% score due to randomness in GPT decoding. We hope to aggregate multiple runs in the future to account for sampling randomness and update the paper, but this shouldn't affect the main conclusions of the paper.\n\n## How to Add A New Task\nSetting up a new task is easy, and mainly involves two steps.\n* Set up a new task class in ``tot/tasks/`` and task files in ``tot/data/``. See ``tot/tasks/game24.py`` for an example. Add the task to ``tot/tasks/__init__.py``.\n* Set up task-specific prompts in ``tot/prompts/``. See ``tot/prompts/game24.py`` for an example. Depending on the nature of the task, choose ``--method_generate`` (choices=[``sample``, ``propose``]) and ``--method_evaluate`` (choices=[``value``, ``vote``]) and their corresponding prompts. \n\n## Citations\nPlease cite the paper and star this repo if you use ToT and find it interesting/useful, thanks! Feel free to contact shunyuyao.cs@gmail.com or open an issue if you have any questions.\n\n```bibtex\n@misc{yao2023tree,\n      title={{Tree of Thoughts}: Deliberate Problem Solving with Large Language Models}, \n      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},\n      year={2023},\n      eprint={2305.10601},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n```\n"
        },
        {
          "name": "logs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pics",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.220703125,
          "content": "[build-system]\nrequires = [\"setuptools >= 61.0.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"tree-of-thoughts-llm\"\nversion = \"0.1.0\"\ndescription = 'Official Implementation of \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\"'\nreadme = \"README.md\"\nrequires-python = \">= 3.7\"\nauthors = [{ name = \"Shunyu Yao\", email = \"shunyuyao.cs@gmail.com\" }]\nlicense = { text = \"MIT License\" }\nkeywords = [\"tree-search\", \"large-language-models\", \"llm\", \"prompting\", \"tree-of-thoughts\"]\nclassifiers = [\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.7\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    'Intended Audience :: Science/Research',\n    'Topic :: Scientific/Engineering :: Artificial Intelligence',\n]\ndynamic=[\"dependencies\"]\n\n\n[tool.setuptools.dynamic]\ndependencies = {file = [\"requirements.txt\"]}\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]  # list of folders that contain the packages ([\".\"] by default)\n\n[project.urls]\nHomepage = \"https://github.com/princeton-nlp/tree-of-thought-llm\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.2890625,
          "content": "aiohttp==3.8.4\naiosignal==1.3.1\nasync-timeout==4.0.2\nattrs==23.1.0\nbackoff==2.2.1\ncertifi==2023.5.7\ncharset-normalizer==3.1.0\nfrozenlist==1.3.3\nidna==3.4\nmpmath==1.3.0\nmultidict==6.0.4\nnumpy==1.24.3\nopenai==0.27.7\nrequests==2.31.0\nsympy==1.12\ntqdm==4.65.0\nurllib3==2.0.2\nyarl==1.9.2\npandas==2.0.3"
        },
        {
          "name": "run.py",
          "type": "blob",
          "size": 2.8466796875,
          "content": "import os\nimport json\nimport argparse\n\nfrom tot.tasks import get_task\nfrom tot.methods.bfs import solve, naive_solve\nfrom tot.models import gpt_usage\n\ndef run(args):\n    task = get_task(args.task)\n    logs, cnt_avg, cnt_any = [], 0, 0\n    if args.naive_run:\n        file = f'./logs/{args.task}/{args.backend}_{args.temperature}_naive_{args.prompt_sample}_sample_{args.n_generate_sample}_start{args.task_start_index}_end{args.task_end_index}.json'\n    else:\n        file = f'./logs/{args.task}/{args.backend}_{args.temperature}_{args.method_generate}{args.n_generate_sample}_{args.method_evaluate}{args.n_evaluate_sample}_{args.method_select}{args.n_select_sample}_start{args.task_start_index}_end{args.task_end_index}.json'\n    os.makedirs(os.path.dirname(file), exist_ok=True)\n\n    for i in range(args.task_start_index, args.task_end_index):\n        # solve\n        if args.naive_run:\n            ys, info = naive_solve(args, task, i) \n        else:\n            ys, info = solve(args, task, i)\n\n        # log\n        infos = [task.test_output(i, y) for y in ys]\n        info.update({'idx': i, 'ys': ys, 'infos': infos, 'usage_so_far': gpt_usage(args.backend)})\n        logs.append(info)\n        with open(file, 'w') as f:\n            json.dump(logs, f, indent=4)\n        \n        # log main metric\n        accs = [info['r'] for info in infos]\n        cnt_avg += sum(accs) / len(accs)\n        cnt_any += any(accs)\n        print(i, 'sum(accs)', sum(accs), 'cnt_avg', cnt_avg, 'cnt_any', cnt_any, '\\n')\n    \n    n = args.task_end_index - args.task_start_index\n    print(cnt_avg / n, cnt_any / n)\n    print('usage_so_far', gpt_usage(args.backend))\n\n\ndef parse_args():\n    args = argparse.ArgumentParser()\n    args.add_argument('--backend', type=str, choices=['gpt-4', 'gpt-3.5-turbo'], default='gpt-4')\n    args.add_argument('--temperature', type=float, default=0.7)\n\n    args.add_argument('--task', type=str, required=True, choices=['game24', 'text', 'crosswords'])\n    args.add_argument('--task_start_index', type=int, default=900)\n    args.add_argument('--task_end_index', type=int, default=1000)\n\n    args.add_argument('--naive_run', action='store_true')\n    args.add_argument('--prompt_sample', type=str, choices=['standard', 'cot'])  # only used when method_generate = sample, or naive_run\n\n    args.add_argument('--method_generate', type=str, choices=['sample', 'propose'])\n    args.add_argument('--method_evaluate', type=str, choices=['value', 'vote'])\n    args.add_argument('--method_select', type=str, choices=['sample', 'greedy'], default='greedy')\n    args.add_argument('--n_generate_sample', type=int, default=1)  # only thing needed if naive_run\n    args.add_argument('--n_evaluate_sample', type=int, default=1)\n    args.add_argument('--n_select_sample', type=int, default=1)\n\n    args = args.parse_args()\n    return args\n\n\nif __name__ == '__main__':\n    args = parse_args()\n    print(args)\n    run(args)"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.337890625,
          "content": "import setuptools\n\nwith open('README.md', 'r', encoding='utf-8') as fh:\n    long_description = fh.read()\n\n\nsetuptools.setup(\n    name='tree-of-thoughts-llm',\n    author='Shunyu Yao',\n    author_email='shunyuyao.cs@gmail.com',\n    description='Official Implementation of \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\"',\n    keywords='tree-search, large-language-models, llm, prompting, tree-of-thoughts',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    url='https://github.com/princeton-nlp/tree-of-thought-llm',\n    project_urls={\n        'Homepage': 'https://github.com/princeton-nlp/tree-of-thought-llm',\n    },\n    package_dir={'': 'src'},\n    packages=setuptools.find_packages(where='src'),\n    classifiers=[\n        \"License :: OSI Approved :: MIT License\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        'Intended Audience :: Science/Research',\n        'Topic :: Scientific/Engineering :: Artificial Intelligence',\n    ],\n    python_requires='>=3.7',\n    install_requires=[\n        'setuptools',\n    ],\n    include_package_data=True,\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}