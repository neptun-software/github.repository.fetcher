{
  "metadata": {
    "timestamp": 1736559736962,
    "page": 438,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ResidentMario/missingno",
      "stars": 3997,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.5234375,
          "content": "# Default\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# Project folders\n.idea\n.vscode\n\n# Mac junk file\n.DS_Store\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Project notebook support\n/.ipynb_checkpoints\n\n# Project-specific\n*.csv\n*.geojson\nmissingno.ipynb\n*.ipynb\n!QuickStart.ipynb\n_map.html\n\n# Test cache\n.cache\n.pytest_cache\ntests/baseline/\n"
        },
        {
          "name": "CONFIGURATION.md",
          "type": "blob",
          "size": 5.3701171875,
          "content": "# Advanced Configuration\n\n## Sorting and filtering\n\n`missingno` also provides utility functions for filtering records in your dataset based on completion. These are\nuseful in particular for filtering through and drilling down into particularly large datasets whose data nullity\nissues might otherwise be very hard to visualize or understand.\n\nLet's first apply a `nullity_filter()` to the data. The `filter` parameter controls which result set we\nwant: either `filter=top` or `filter=bottom`. The `n` parameter controls the maximum number of columns that you want:\n so for example `n=5` makes sure we get *at most* five results. Finally, `p` controls the percentage cutoff. If\n `filter=bottom`, then `p=0.9`  makes sure that our columns are *at most*  90% complete; if `filter=top` we get\n columns which are *at least* 90% complete.\n\nFor example, the following query filtered down to only at most 15 columns which are not completely filled.\n\n    >>> filtered_data = msno.nullity_filter(data, filter='bottom', n=15, p=0.999) # or filter='top'\n    >>> msno.matrix(filtered_data.sample(250))\n\n![alt text][matrix_filtered]\n\n[matrix_filtered]: http://i.imgur.com/UF6hmL8.png\n\n`nullity_sort()` simply reshuffles your rows by completeness, in either `ascending` or `descending` order. Since it\ndoesn't affect the underlying data it's mainly useful for `matrix` visualization:\n\n\n    >>> sorted_data = msno.nullity_sort(data, sort='descending') # or sort='ascending'\n    >>> msno.matrix(sorted_data.sample(250))\n\n![alt text][matrix_sorted]\n\n[matrix_sorted]: http://i.imgur.com/qL6zNQj.png\n\nThese methods work inline within the visualization methods themselves. For instance, the following is perfectly valid:\n\n    >>> msno.matrix(data.sample(250), filter='top', n=5, p=0.9, sort='ascending')\n\n## Visual configuration\n### Lesser parameters\n\nEach of the visualizations provides a further set of lesser configuration parameters for visually tweaking the display.\n\n`matrix`, `bar`, `heatmap`, `dendrogram`, and `geoplot` all provide:\n\n* `figsize`: The size of the figure to display. This is a `matplotlib` parameter which defaults to `(20, 12)`, except\n for large `dendrogram` visualizations, which compute a height on the fly based on the number of variables to display.\n* `fontsize`: The figure's font size. The default is `16`.\n* `labels`: Whether or not to display the column names. For `matrix` this defaults to `True` for `<=50` variables and\n `False` for `>50`. It always defaults to `True` for `dendrogram` and `heatmap`.\n* `inline`: Defaults to `True`, in which case the chart is plotted and nothing is returned. If this is set to `False`\nthe methods omit plotting and return their visualizations instead.\n\n`matrix` also provides:\n* `sparkline`: Set this to `False` to not draw the sparkline.\n* `freq`: If you are working with timeseries data (a `pandas` `DataFrame` with a `PeriodIndex` or `DatetimeIndex`)\nyou can specify and display a [choice of offset](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-offset-aliases).\n* `width_ratios`: The ratio of the width of the matrix to the width of the sparkline. Defaults to `(15,\n    1)`. Does nothing if `sparkline=False`.\n* `color`: The color of the filled columns. Defaults to `(0.25, 0.25, 0.25)`.\n\n`bar` also provides:\n* `log`: Set this to `True` to use a logarithmic scale.\n* `color`: The color of the filled columns. Defaults to `(0.25, 0.25, 0.25)`.\n\n\n`heatmap` also provides:\n* `cmap`: What `matplotlib` [colormap](http://matplotlib.org/users/colormaps.html) to use. Defaults to `RdBu`.\n\n\n`dendrogram` also provides:\n* `orientation`: The [orientation](http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram)\nof the dendrogram. Defaults to `top` if `<=50` columns and\n`left` if there are more.\n* `method`: The [linkage method](http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage) `scipy.hierarchy` uses for clustering.\n`average` is the default argument.\n\n`geoplot` also provides:\n* `x` AND `y` OR `coordinates`: A column of points (in either two columns or one) to plot. These are required.\n* `by`: A column of values to group points by.\n* `geometry`: A hash table (`dict` or `pd.Series` generally) geometries of the groups being aggregated, if available.\n* `cutoff`: The minimum number of observations per rectangle in the quadtree display. No effect if a different\ndisplay is used. Defaults to `min([50, 0.05*len(df)])`.\n* `histogram`: Whether or not to plot the histogram. Defaults to `False`.\n\n### Manipulation with matplotlib\nIf you are not satisfied with these admittedly basic configuration parameters, the display can be further manipulated\nin any way you like using `matplotlib` post-facto.\n\nThe best way to do this is to specify `inline=False`, which will cause `missingno` to return the underlying\n`matplotlib.axis.Axis` object of the main plot (e.g. only the matrix is returned when plotting the matrix with the sparkline). Anyone with sufficient knowledge of `matplotlib` operations and [the missingno source code](https://github.com/ResidentMario/missingno/blob/master/missingno/missingno.py)\ncan then tweak the display to their liking. For example, the following code will bump the size of the dendrogram\nvisualization's y-axis labels up from `20` to `30`:\n\n    >>> mat = msno.dendrogram(collisions, inline=False)\n    >>> mat.axes[0].tick_params(axis='y', labelsize=30)\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 3.5478515625,
          "content": "## Development\n\n### Cloning\n\nTo work on `missingno` locally, you will need to clone it.\n\n```git\ngit clone https://github.com/ResidentMario/missingno.git\n```\n\nYou can then set up your own branch version of the code, and\n work on your changes for a pull request from there.\n\n```bash\ncd missingno\ngit checkout -B new-branch-name\n```\n\n### Environment\n\nI strongly recommend creating a new virtual environment when working on `missingno` (e.g. not using the base system Python). You can do so with either [`conda`](https://conda.io/) or `virtualenv`. Once you have a virtual environment ready, I recommend running `pip install -e missingno .[tests]` from the root folder of the repository on your local machine.\nThis will create an [editable install](https://pip.pypa.io/en/latest/reference/pip_install/#editable-installs) of `missingno` suitable for tweaking and further development, and install additional test dependencies as well.\n\nIn addition to the `missingno` prerequisites, you will also need to have the `geopandas`, `geoplot`, and `shapely` optional dependencies installed (`geoplot` can only be installed via `conda`). To run the tests you will also need to have the `pytest` and `pytest-mpl` packages installed (this is done for you if you install with the `tests` flag set).\n\n### Testing\n\nTests are split between visualization tests for core package methods and utility tests for helper functions.\n\nThe visualization tests are under `tests/viz_tests.py`, and rely on `pytest` and the [`pytest-mpl`](https://github.com/matplotlib/pytest-mpl) plugin. Before running the tests, generate the set of baseline images with `py.test --mpl-generate-path=baseline viz_tests.py`. You will want to inspect the images you generate in order to ascertain that they look correct. If you are satisfied that they are, you can rerun the test at anytime by calling `py.test --mpl viz_tests.py`. For more information on how this\nworks, refer to the [pytest-mpl README](https://github.com/matplotlib/pytest-mpl).\n\nThe utility tests are located under `tests/util_tests.py`. These are not visualization tests, and so can be run with `pytest util_tests.py`.\n\n### Data\n\nThe `missingno` `README.md` uses a real-world data sample, one originally derived from the [NYPD Motor Vehicle Collisions Dataset](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95).\nThe data is zipped up and packaged online using [Quilt](https://quiltdata.com/package/ResidentMario/geoplot_data), a data-as-a-package management service. You can view the package [on the web](https://quiltdata.com/package/ResidentMario/missingno_data).\n\nThis data is only used in the `README.md`. It is not used for tests. Instructions for reading out the data are in the `README.md`; you can also do the following on your local machine:\n\n```sh\n$ pip install quilt\n$ cd geoplot # root directory of this repo\n$ quilt install # installs dependencies from quilt.yml\n```\n\nTo update the data sample, you will need to push to this package, using [the instructions here](https://docs.quiltdata.com/make-a-package.html).\n\nThe data itself is a `csv` version of a `geojson` file (less geometry) packaged into the example data used by the `geoplot` package (another project of mine). The master copy is a separate repository on GitHub: [`missingno-data`](https://github.com/ResidentMario/missingno-data).\n\n## Documentation\n\nThe Quickstart section of `README.md` is the principal documentation for this package. To edit the documentation I recommend editing that file directly on GitHub, which will handle generating a fork and pull request for you once your changes are made."
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 1.0341796875,
          "content": "Copyright (c) 2016 Aleksey Bilogur\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1005859375,
          "content": "include *.md\n\ninclude paper.bib\ninclude QuickStart.ipynb\n\ninclude postBuild\ninclude *.yml\n\ngraft tests\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.3095703125,
          "content": "# missingno [![PyPi version](https://img.shields.io/pypi/v/missingno.svg)](https://pypi.python.org/pypi/missingno/) [![](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/) ![t](https://img.shields.io/badge/status-maintained-yellow.svg) [![](https://img.shields.io/github/license/ResidentMario/missingno.svg)](https://github.com/ResidentMario/missingno/blob/master/LICENSE.md) [![](https://img.shields.io/badge/doi-10.21105/joss.00547+-blue.svg)](https://joss.theoj.org/papers/10.21105/joss.00547)\n\nMessy datasets? Missing values? `missingno` provides a small toolset of flexible and easy-to-use missing data\nvisualizations and utilities that allows you to get a quick visual summary of the completeness (or lack thereof) of your dataset. Just `pip install missingno` to get started.\n\n## quickstart\n\nThis quickstart uses a sample of the [NYPD Motor Vehicle Collisions Dataset](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95) dataset.\n\n```python\nimport pandas as pd\ncollisions = pd.read_csv(\"https://raw.githubusercontent.com/ResidentMario/missingno-data/master/nyc_collision_factors.csv\")\n```\n\n### `matrix`\n\nThe `msno.matrix` nullity matrix is a data-dense display which lets you quickly visually pick out patterns in\n data completion.\n\n```python\nimport missingno as msno\n%matplotlib inline\nmsno.matrix(collisions.sample(250))\n```\n\n![alt text][two_hundred_fifty]\n\n[two_hundred_fifty]: https://i.imgur.com/gWuXKEr.png\n\nAt a glance, date, time, the distribution of injuries, and the contribution factor of the first vehicle appear to be completely populated, while geographic information seems mostly complete, but spottier.\n\nThe sparkline at right summarizes the general shape of the data completeness and points out the rows with the maximum and minimum nullity in the dataset.\n\nThis visualization will comfortably accommodate up to 50 labelled variables. Past that range labels begin to overlap or become unreadable, and by default large displays omit them.\n\nIf you are working with time-series data, you can [specify a periodicity](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#timeseries-offset-aliases)\nusing the `freq` keyword parameter:\n\n```python\nnull_pattern = (np.random.random(1000).reshape((50, 20)) > 0.5).astype(bool)\nnull_pattern = pd.DataFrame(null_pattern).replace({False: None})\nmsno.matrix(null_pattern.set_index(pd.period_range('1/1/2011', '2/1/2015', freq='M')) , freq='BQ')\n```\n\n![alt text][ts_matrix]\n\n[ts_matrix]: https://i.imgur.com/VLvWpsV.png\n\n### `bar`\n\n`msno.bar` is a simple visualization of nullity by column:\n\n```python\nmsno.bar(collisions.sample(1000))\n```\n\n![alt text][bar]\n\n[bar]: https://i.imgur.com/2BxEfOr.png\n\nYou can switch to a logarithmic scale by specifying `log=True`. `bar` provides the same information as `matrix`, but in a simpler format.\n\n### `heatmap`\n\nThe `missingno` correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another:\n\n```python\nmsno.heatmap(collisions)\n```\n\n![alt text][heatmap]\n\n[heatmap]: https://i.imgur.com/JalSKyE.png\n\nIn this example, it seems that reports which are filed with an `OFF STREET NAME` variable are less likely to have complete geographic data.\n\nNullity correlation ranges from `-1` (if one variable appears the other definitely does not) to `0` (variables appearing or not appearing have no effect on one another) to `1` (if one variable appears the other definitely also does).\n\nThe exact algorithm used is:\n\n```python\nimport numpy as np\n\n# df is a pandas.DataFrame instance\ndf = df.iloc[:, [i for i, n in enumerate(np.var(df.isnull(), axis='rows')) if n > 0]]\ncorr_mat = df.isnull().corr()\n```\n\nVariables that are always full or always empty have no meaningful correlation, and so are silently removed from the visualization&mdash;in this case for instance the datetime and injury number columns, which are completely filled, are not included.\n\nEntries marked `<1` or `>-1` have a correlation that is close to being exactingly negative or positive, but is still not quite perfectly so. This points to a small number of records in the dataset which are erroneous. For example, in this dataset the correlation between `VEHICLE CODE TYPE 3` and `CONTRIBUTING FACTOR VEHICLE 3` is `<1`, indicating that, contrary to our expectation, there are a few records which have one or the other, but not both. These cases will require special attention.\n\nThe heatmap works great for picking out data completeness relationships between variable pairs, but its explanatory power is limited when it comes to larger relationships and it has no particular support for extremely large datasets.\n\n### `dendrogram`\n\nThe dendrogram allows you to more fully correlate variable completion, revealing trends deeper than the pairwise ones visible in the correlation heatmap:\n\n```python\nmsno.dendrogram(collisions)\n```\n\n![alt text][dendrogram]\n\n[dendrogram]: https://i.imgur.com/oIiR4ct.png\n\nThe dendrogram uses a [hierarchical clustering algorithm](http://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html)\n(courtesy of `scipy`) to bin variables against one another by their nullity correlation (measured in terms of\nbinary distance). At each step of the tree the variables are split up based on which combination minimizes the distance of the remaining clusters. The more monotone the set of variables, the closer their total distance is to zero, and the closer their average distance (the y-axis) is to zero.\n\nThe exact algorithm used is:\n\n```python\nfrom scipy.cluster import hierarchy\nimport numpy as np\n\n# df is a pandas.DataFrame instance\nx = np.transpose(df.isnull().astype(int).values)\nz = hierarchy.linkage(x, method)\n```\n\nTo interpret this graph, read it from a top-down perspective. Cluster leaves which linked together at a distance of zero fully predict one another's presence&mdash;one variable might always be empty when another is filled, or they might always both be filled or both empty, and so on. In this specific example the dendrogram glues together the variables which are required and therefore present in every record.\n\nCluster leaves which split close to zero, but not at it, predict one another very well, but still imperfectly. If your own interpretation of the dataset is that these columns actually *are* or *ought to be* match each other in nullity (for example, as `CONTRIBUTING FACTOR VEHICLE 2` and `VEHICLE TYPE CODE 2` ought to), then the height of the cluster leaf tells you, in absolute terms, how often the records are \"mismatched\" or incorrectly filed&mdash;that is, how many values you would have to fill in or drop, if you are so inclined.\n\nAs with `matrix`, only up to 50 labeled columns will comfortably display in this configuration. However the\n`dendrogram` more elegantly handles extremely large datasets by simply flipping to a horizontal configuration.\n\n## configuration\n\nFor more advanced configuration details for your plots, refer to the `CONFIGURATION.md` file in this repository.\n\n## contributing\n\nFor thoughts on features or bug reports see [Issues](https://github.com/ResidentMario/missingno/issues). If you're interested in contributing to this library, see details on doing so in the `CONTRIBUTING.md` file in this repository. If doing so, keep in mind that `missingno` is currently in a maintenance state, so while bugfixes are welcome, I am unlikely to review or land any new major library features.\n"
        },
        {
          "name": "missingno",
          "type": "tree",
          "content": null
        },
        {
          "name": "paper.bib",
          "type": "blob",
          "size": 1.4814453125,
          "content": "@online{null-data-blog-post,\n    author = {Aleksey Bilogur},\n    title = {Null and missing data in Python},\n    year = 2016,\n    url = {http://www.residentmar.io/2016/06/12/null-and-missing-data-python.html},\n    urldate = {2016-06-12}\n}\n\n@Misc{scipy,\n    author =    {Eric Jones and Travis Oliphant and Pearu Peterson and others},\n    title =     {{SciPy}: Open source scientific tools for {Python}},\n    year =      {2001--},\n    url = \"http://www.scipy.org/\",\n    note = {[Online; accessed <today>]},\n}\n\n@article{numpy,\n    author={Stéfan van der Walt, S. Chris Colbert and Gaël Varoquaux},\n    title={The NumPy Array: A Structure for Efficient Numerical Computation},\n    journal={Computing in Science & Engineering},\n    volume=13,\n    pages=22-30,\n    year=2011,\n    doi={10.1109/MCSE.2011.37}\n}\n\n@article{matplotlib,\n    author={John D. Hunter},\n    title={Matplotlib: A 2D Graphics Environment},\n    year=2007,\n    volume=9,\n    pages=90-95,\n    journal={Computing in Science & Engineering},\n    doi={10.1109/MCSE.2007.55}\n}\n\n@article{pandas,\n    author={Wes McKinney},\n    title={Data Structures for Statistical Computing in Python},\n    journal={Proceedings of the 9th Python in Science Conference},\n    year=2010,\n    pages=51-56\n}\n\n@misc{seaborn,\n    author={Michael Waskom and others},\n    title        = {mwaskom/seaborn: v0.8.1 (September 2017)},\n    month        = sep,\n    year         = 2017,\n    doi          = {10.5281/zenodo.883859},\n    url          = {https://doi.org/10.5281/zenodo.883859}\n}"
        },
        {
          "name": "paper.md",
          "type": "blob",
          "size": 2.4638671875,
          "content": "---\ntitle: 'Missingno: a missing data visualization suite'\ntags:\n  - missing data\n  - data visualization\nauthors:\n - name: Aleksey Bilogur\n   orcid: 0000-0002-0066-5825\n   affiliation: 1\naffiliations:\n - name: Independent\n   index: 1\ndate: 13 Febuary 2018\nbibliography: paper.bib\n---\n\n# Summary\n\nAlgorithmic models and outputs are only as good as the data they are computed on. As the popular saying goes: garbage \nin, garbage out. In tabular datasets, it is usually relatively easy to, at a glance, understand patterns of \nmissing data (or nullity) of individual rows, columns, and entries. However, it is far harder to see patterns in the\nmissingness of data that extend between them. Understanding such patterns in data is beneficial, if not outright \ncritical, to most applications.\n\nmissingno is a Python package for visualizing missing data. It works by converting tabular data matrices into boolean \nmasks based on whether individual entries contain data (which evaluates to true) or left empty (which evaluates to \nfalse). This \"nullity matrix\" is then exposed to user assessment through a variety of special-purpose data \nvisualizations.\n\nThe simplest tool, the bar chart, is a snapshot of column-level information:\n\n![](https://i.imgur.com/2BxEfOr.png)\n\nThe matrix display provides a literal translations of a data table's \nnullity matrix. It is useful for snapshotting general patterns:\n\n![](https://i.imgur.com/gWuXKEr.png)\n\nA heatmap provides a methodology for examining relationships within pairs of variables.\n\n![](https://i.imgur.com/JalSKyE.png)\n\nHigher-cardinality data nullity correlations can be understood using a hierarchically clustered dendrogram:\n\n![](https://i.imgur.com/oIiR4ct.png)\n\nFinally, geospatial data dependencies are viewable using an approach based on the quadtree or convex hull algorithm:\n\n![](https://i.imgur.com/0aaNa9Q.png)\n\nThe visualizations are consciously designed to be as effective as possible\nat uncovering missing data patterns both between and within columns of data, and hence, to help its users build more \neffective data models and pipelines. At the same time the package is designed to be easy to use. The underlying \npackages involved (NumPy [@numpy], pandas [@pandas], SciPy [@scipy], matplotlib [@matplotlib], and seaborn [@seaborn]) are familiar parts of the core scientific Python \necosystem, and hence very learnable and extensible. missingno works \"out of the box\" with a variety of data types and \nformats, and provides an extremely compact API.\n\n# References\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.751953125,
          "content": "from setuptools import setup\nsetup(\n    name='missingno',\n    license='MIT License',\n    packages=['missingno'],\n    install_requires=['numpy', 'matplotlib', 'scipy', 'seaborn'],\n    extras_require={'tests': ['pytest', 'pytest-mpl']},\n    py_modules=['missingno'],\n    version='0.5.2',  # note to self: also update the one is the source!\n    description='Missing data visualization module for Python.',\n    author='Aleksey Bilogur',\n    author_email='aleksey.bilogur@gmail.com',\n    url='https://github.com/ResidentMario/missingno',\n    download_url='https://github.com/ResidentMario/missingno/tarball/0.5.2',\n    keywords=['data', 'data visualization', 'data analysis', 'missing data', 'data science', 'pandas', 'python',\n              'jupyter'],\n    classifiers=[]\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}