{
  "metadata": {
    "timestamp": 1736559993555,
    "page": 789,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjc5MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "cosmicpython/book",
      "stars": 3437,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.236328125,
          "content": "chapter_*.html\nappendix_*.html\npreface.html\nintroduction.html\n.venv\n.mypy_cache\n.env\nabstractions.html\npart2.html\npart1.html\nacknowledgements.html\n.asciidoctor\nepilogue_1_how_to_get_there_from_here.html\nepilogue_2_footguns.html\nimages/*.html\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.07421875,
          "content": "[submodule \"code\"]\n\tpath = code\n\turl = git@github.com:cosmicpython/code.git\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.337890625,
          "content": "dist: xenial\nlanguage: python\npython: 3.8\ninstall:\n- gem install asciidoctor coderay\n- pip install -r requirements.txt\nscript:\n- make html update-code test\ngit:\n  submodules: false\nbefore_install:\n- sudo apt-get install -y tree python-pygments\n- sed -i s_git@github.com:_https://github.com/_ .gitmodules\n- git submodule update --init --recursive\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.453125,
          "content": "html:\n\tasciidoctor \\\n\t\t-a stylesheet=theme/asciidoctor-clean.custom.css \\\n\t\t-a source-highlighter=pygments \\\n\t\t-a pygments-style=friendly \\\n\t\t-a '!example-caption' \\\n\t\t-a sectanchors \\\n\t\t*.asciidoc\n\ntest: html\n\tpytest tests.py --tb=short -vv\n\nupdate-code:\n\t# git submodule update --init --recursive\n\tcd code && git fetch\n\t./checkout-branches-for-ci.py\n\ncount-todos:\n\tls *.asciidoc | xargs grep -c TODO | sed  s/:/\\\\t/\n\ndiagrams: html\n\t./render-diagrams.py $(CHAP)\n"
        },
        {
          "name": "Readme.md",
          "type": "blob",
          "size": 4.5595703125,
          "content": "# Book repo\n\n| Book | Code |\n| ---- | ---- |\n| [![Book Build Status](https://travis-ci.org/cosmicpython/book.svg?branch=master)](https://travis-ci.org/cosmicpython/book) | [![Code build status](https://travis-ci.org/cosmicpython/code.svg?branch=master)](https://travis-ci.org/cosmicpython/code) |\n\n\n## Table of Contents\n\nO'Reilly have generously said that we will be able to publish this book under a [CC license](license.txt),\nIn the meantime, pull requests, typofixes, and more substantial feedback + suggestions are enthusiastically solicited.\n\n| Chapter |       |\n| ------- | ----- |\n| [Preface](preface.asciidoc) | |\n| [Introduction: Why do our designs go wrong?](introduction.asciidoc)| ||\n| [**Part 1 Intro**](part1.asciidoc) | |\n| [Chapter 1: Domain Model](chapter_01_domain_model.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_01_domain_model)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 2: Repository](chapter_02_repository.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_02_repository)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 3: Interlude: Abstractions](chapter_03_abstractions.asciidoc) | |\n| [Chapter 4: Service Layer (and Flask API)](chapter_04_service_layer.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_04_service_layer)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 5: TDD in High Gear and Low Gear](chapter_05_high_gear_low_gear.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_05_high_gear_low_gear)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 6: Unit of Work](chapter_06_uow.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_06_uow)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 7: Aggregates](chapter_07_aggregate.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_07_aggregate)](https://travis-ci.org/cosmicpython/code) |\n| [**Part 2 Intro**](part2.asciidoc) | |\n| [Chapter 8: Domain Events and a Simple Message Bus](chapter_08_events_and_message_bus.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_08_events_and_message_bus)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 9: Going to Town on the MessageBus](chapter_09_all_messagebus.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_09_all_messagebus)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 10: Commands](chapter_10_commands.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_10_commands)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 11: External Events for Integration](chapter_11_external_events.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_11_external_events)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 12: CQRS](chapter_12_cqrs.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_12_cqrs)](https://travis-ci.org/cosmicpython/code) |\n| [Chapter 13: Dependency Injection](chapter_13_dependency_injection.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=chapter_13_dependency_injection)](https://travis-ci.org/cosmicpython/code) |\n| [Epilogue: How do I get there from here?](epilogue_1_how_to_get_there_from_here.asciidoc) | |\n| [Appendix A: Recap table](appendix_ds1_table.asciidoc) | |\n| [Appendix B: Project Structure](appendix_project_structure.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=appendix_project_structure)](https://travis-ci.org/cosmicpython/code) |\n| [Appendix C: A major infrastructure change, made easy](appendix_csvs.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=appendix_csvs)](https://travis-ci.org/cosmicpython/code) |\n| [Appendix D: Django](appendix_django.asciidoc) | [![Build Status](https://travis-ci.org/cosmicpython/code.svg?branch=appendix_django)](https://travis-ci.org/cosmicpython/code) |\n| [Appendix F: Validation](appendix_validation.asciidoc) | |\n\n\n\n\nBelow is just instructions for me and bob really.\n\n## Dependencies:\n\n* asciidoctor\n* Pygments (for syntax higlighting)\n* asciidoctor-diagram (to render images from the text sources in [`./images`](./images))\n\n```sh\ngem install asciidoctor\npython2 -m pip install --user pygments\ngem install pygments.rb\ngem install asciidoctor-diagram\n```\n\n\n## Commands\n\n```sh\nmake html  # builds local .html versions of each chapter\nmake test  # does a sanity-check of the code listings\n```\n\n"
        },
        {
          "name": "appendix_csvs.asciidoc",
          "type": "blob",
          "size": 9.16015625,
          "content": "[[appendix_csvs]]\n[appendix]\n== Swapping Out the Infrastructure: [.keep-together]#Do Everything with CSVs#\n\n(((\"CSVs, doing everything with\", id=\"ix_CSV\")))\nThis appendix is intended as a little illustration of the benefits of the\nRepository, Unit of Work, and Service Layer patterns. It's intended to\nfollow from <<chapter_06_uow>>.\n\nJust as we finish building out our Flask API and getting it ready for release,\nthe business comes to us apologetically, saying they're not ready to use our API\nand asking if we could build a thing that reads just batches and orders from a couple of\nCSVs and outputs a third CSV with allocations.\n\nOrdinarily this is the kind of thing that might have a team cursing and spitting\nand making notes for their memoirs.  But not us!  Oh no, we've ensured that\nour infrastructure concerns are nicely decoupled from our domain model and\nservice layer.  Switching to CSVs will be a simple matter of writing a couple\nof new `Repository` and `UnitOfWork` classes, and then we'll be able to reuse\n_all_ of our logic from the domain layer and the service layer.\n\nHere's an E2E test to show you how the CSVs flow in and out:\n\n[[first_csv_test]]\n.A first CSV test (tests/e2e/test_csv.py)\n====\n[source,python]\n----\ndef test_cli_app_reads_csvs_with_batches_and_orders_and_outputs_allocations(make_csv):\n    sku1, sku2 = random_ref(\"s1\"), random_ref(\"s2\")\n    batch1, batch2, batch3 = random_ref(\"b1\"), random_ref(\"b2\"), random_ref(\"b3\")\n    order_ref = random_ref(\"o\")\n    make_csv(\"batches.csv\", [\n        [\"ref\", \"sku\", \"qty\", \"eta\"],\n        [batch1, sku1, 100, \"\"],\n        [batch2, sku2, 100, \"2011-01-01\"],\n        [batch3, sku2, 100, \"2011-01-02\"],\n    ])\n    orders_csv = make_csv(\"orders.csv\", [\n        [\"orderid\", \"sku\", \"qty\"],\n        [order_ref, sku1, 3],\n        [order_ref, sku2, 12],\n    ])\n\n    run_cli_script(orders_csv.parent)\n\n    expected_output_csv = orders_csv.parent / \"allocations.csv\"\n    with open(expected_output_csv) as f:\n        rows = list(csv.reader(f))\n    assert rows == [\n        [\"orderid\", \"sku\", \"qty\", \"batchref\"],\n        [order_ref, sku1, \"3\", batch1],\n        [order_ref, sku2, \"12\", batch2],\n    ]\n----\n====\n\nDiving in and implementing without thinking about repositories and all\nthat jazz, you might start with something like this:\n\n\n[[first_cut_csvs]]\n.A first cut of our CSV reader/writer (src/bin/allocate-from-csv)\n====\n[source,python]\n[role=\"non-head\"]\n----\n#!/usr/bin/env python\nimport csv\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\n\nfrom allocation.domain import model\n\n\ndef load_batches(batches_path):\n    batches = []\n    with batches_path.open() as inf:\n        reader = csv.DictReader(inf)\n        for row in reader:\n            if row[\"eta\"]:\n                eta = datetime.strptime(row[\"eta\"], \"%Y-%m-%d\").date()\n            else:\n                eta = None\n            batches.append(\n                model.Batch(\n                    ref=row[\"ref\"], sku=row[\"sku\"], qty=int(row[\"qty\"]), eta=eta\n                )\n            )\n    return batches\n\n\ndef main(folder):\n    batches_path = Path(folder) / \"batches.csv\"\n    orders_path = Path(folder) / \"orders.csv\"\n    allocations_path = Path(folder) / \"allocations.csv\"\n\n    batches = load_batches(batches_path)\n\n    with orders_path.open() as inf, allocations_path.open(\"w\") as outf:\n        reader = csv.DictReader(inf)\n        writer = csv.writer(outf)\n        writer.writerow([\"orderid\", \"sku\", \"batchref\"])\n        for row in reader:\n            orderid, sku = row[\"orderid\"], row[\"sku\"]\n            qty = int(row[\"qty\"])\n            line = model.OrderLine(orderid, sku, qty)\n            batchref = model.allocate(line, batches)\n            writer.writerow([line.orderid, line.sku, batchref])\n\n\nif __name__ == \"__main__\":\n    main(sys.argv[1])\n----\n====\n\n//TODO: too much vertical whitespace in this listing\n\nIt's not looking too bad! And we're reusing our domain model objects\nand our domain service.\n\nBut it's not going to work. Existing allocations need to also be part\nof our permanent CSV storage. We can write a second test to force us to improve\nthings:\n\n[[second_csv_test]]\n.And another one, with existing allocations (tests/e2e/test_csv.py)\n====\n[source,python]\n----\ndef test_cli_app_also_reads_existing_allocations_and_can_append_to_them(make_csv):\n    sku = random_ref(\"s\")\n    batch1, batch2 = random_ref(\"b1\"), random_ref(\"b2\")\n    old_order, new_order = random_ref(\"o1\"), random_ref(\"o2\")\n    make_csv(\"batches.csv\", [\n        [\"ref\", \"sku\", \"qty\", \"eta\"],\n        [batch1, sku, 10, \"2011-01-01\"],\n        [batch2, sku, 10, \"2011-01-02\"],\n    ])\n    make_csv(\"allocations.csv\", [\n        [\"orderid\", \"sku\", \"qty\", \"batchref\"],\n        [old_order, sku, 10, batch1],\n    ])\n    orders_csv = make_csv(\"orders.csv\", [\n        [\"orderid\", \"sku\", \"qty\"],\n        [new_order, sku, 7],\n    ])\n\n    run_cli_script(orders_csv.parent)\n\n    expected_output_csv = orders_csv.parent / \"allocations.csv\"\n    with open(expected_output_csv) as f:\n        rows = list(csv.reader(f))\n    assert rows == [\n        [\"orderid\", \"sku\", \"qty\", \"batchref\"],\n        [old_order, sku, \"10\", batch1],\n        [new_order, sku, \"7\", batch2],\n    ]\n----\n====\n\n\nAnd we could keep hacking about and adding extra lines to that `load_batches` function,\nand some sort of way of tracking and saving new allocations—but we already have a model for doing that! It's called our Repository and Unit of Work patterns.\n\nAll we need to do (\"all we need to do\") is reimplement those same abstractions, but\nwith CSVs underlying them instead of a database. And as you'll see, it really is relatively straightforward.\n\n\n=== Implementing a Repository and Unit of Work for CSVs\n\n\n(((\"repositories\", \"CSV-based repository\")))\nHere's what a CSV-based repository could look like.  It abstracts away all the\nlogic for reading CSVs from disk, including the fact that it has to read _two\ndifferent CSVs_ (one for batches and one for allocations), and it gives us just\nthe familiar `.list()` API, which provides the illusion of an in-memory\ncollection of domain objects:\n\n[[csv_repository]]\n.A repository that uses CSV as its storage mechanism (src/allocation/service_layer/csv_uow.py)\n====\n[source,python]\n----\nclass CsvRepository(repository.AbstractRepository):\n    def __init__(self, folder):\n        self._batches_path = Path(folder) / \"batches.csv\"\n        self._allocations_path = Path(folder) / \"allocations.csv\"\n        self._batches = {}  # type: Dict[str, model.Batch]\n        self._load()\n\n    def get(self, reference):\n        return self._batches.get(reference)\n\n    def add(self, batch):\n        self._batches[batch.reference] = batch\n\n    def _load(self):\n        with self._batches_path.open() as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                ref, sku = row[\"ref\"], row[\"sku\"]\n                qty = int(row[\"qty\"])\n                if row[\"eta\"]:\n                    eta = datetime.strptime(row[\"eta\"], \"%Y-%m-%d\").date()\n                else:\n                    eta = None\n                self._batches[ref] = model.Batch(ref=ref, sku=sku, qty=qty, eta=eta)\n        if self._allocations_path.exists() is False:\n            return\n        with self._allocations_path.open() as f:\n            reader = csv.DictReader(f)\n            for row in reader:\n                batchref, orderid, sku = row[\"batchref\"], row[\"orderid\"], row[\"sku\"]\n                qty = int(row[\"qty\"])\n                line = model.OrderLine(orderid, sku, qty)\n                batch = self._batches[batchref]\n                batch._allocations.add(line)\n\n    def list(self):\n        return list(self._batches.values())\n----\n====\n\n// TODO (hynek) re self._load(): DUDE! no i/o in init!\n\n\n(((\"Unit of Work pattern\", \"UoW for CSVs\")))\nAnd here's what a UoW for CSVs would look like:\n\n\n\n[[csvs_uow]]\n.A UoW for CSVs: commit = csv.writer (src/allocation/service_layer/csv_uow.py)\n====\n[source,python]\n----\nclass CsvUnitOfWork(unit_of_work.AbstractUnitOfWork):\n    def __init__(self, folder):\n        self.batches = CsvRepository(folder)\n\n    def commit(self):\n        with self.batches._allocations_path.open(\"w\") as f:\n            writer = csv.writer(f)\n            writer.writerow([\"orderid\", \"sku\", \"qty\", \"batchref\"])\n            for batch in self.batches.list():\n                for line in batch._allocations:\n                    writer.writerow(\n                        [line.orderid, line.sku, line.qty, batch.reference]\n                    )\n\n    def rollback(self):\n        pass\n----\n====\n\n\nAnd once we have that, our CLI app for reading and writing batches\nand allocations to CSV is pared down to what it should be—a bit\nof code for reading order lines, and a bit of code that invokes our\n_existing_ service layer:\n\n[role=\"nobreakinside less_space\"]\n[[final_cli]]\n.Allocation with CSVs in nine lines (src/bin/allocate-from-csv)\n====\n[source,python]\n----\ndef main(folder):\n    orders_path = Path(folder) / \"orders.csv\"\n    uow = csv_uow.CsvUnitOfWork(folder)\n    with orders_path.open() as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            orderid, sku = row[\"orderid\"], row[\"sku\"]\n            qty = int(row[\"qty\"])\n            services.allocate(orderid, sku, qty, uow)\n----\n====\n\n\n(((\"CSVs, doing everything with\", startref=\"ix_CSV\")))\nTa-da! _Now are y'all impressed or what_?\n\nMuch love,\n\nBob and Harry\n"
        },
        {
          "name": "appendix_django.asciidoc",
          "type": "blob",
          "size": 16.2197265625,
          "content": "[[appendix_django]]\n[appendix]\n== Repository and Unit of Work [.keep-together]#Patterns with Django#\n\n(((\"Django\", \"installing\")))\n(((\"Django\", id=\"ix_Django\")))\nSuppose you wanted to use Django instead of SQLAlchemy and Flask. How\nmight things look? The first thing is to choose where to install it. We put it in a separate\npackage next to our main allocation code:\n\n\n[[django_tree]]\n====\n[source,text]\n[role=\"tree\"]\n----\n├── src\n│   ├── allocation\n│   │   ├── __init__.py\n│   │   ├── adapters\n│   │   │   ├── __init__.py\n...\n│   ├── djangoproject\n│   │   ├── alloc\n│   │   │   ├── __init__.py\n│   │   │   ├── apps.py\n│   │   │   ├── migrations\n│   │   │   │   ├── 0001_initial.py\n│   │   │   │   └── __init__.py\n│   │   │   ├── models.py\n│   │   │   └── views.py\n│   │   ├── django_project\n│   │   │   ├── __init__.py\n│   │   │   ├── settings.py\n│   │   │   ├── urls.py\n│   │   │   └── wsgi.py\n│   │   └── manage.py\n│   └── setup.py\n└── tests\n    ├── conftest.py\n    ├── e2e\n    │   └── test_api.py\n    ├── integration\n    │   ├── test_repository.py\n...\n----\n====\n\n\n[TIP]\n====\nThe code for this appendix is in the\nappendix_django branch https://oreil.ly/A-I76[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout appendix_django\n----\n\nCode examples follows on from the end of <<chapter_06_uow>>.\n\n====\n\n\n=== Repository Pattern with Django\n\n(((\"pytest\", \"pytest-django plug-in\")))\n(((\"Repository pattern\", \"with Django\", id=\"ix_RepoDjango\")))\n(((\"Django\", \"Repository pattern with\", id=\"ix_DjangoRepo\")))\nWe used a plugin called\nhttps://github.com/pytest-dev/pytest-django[`pytest-django`] to help with test\ndatabase management.\n\nRewriting the first repository test was a minimal change—just rewriting\nsome raw SQL with a call to the Django ORM/QuerySet language:\n\n\n[[django_repo_test1]]\n.First repository test adapted (tests/integration/test_repository.py)\n====\n[source,python]\n----\nfrom djangoproject.alloc import models as django_models\n\n\n@pytest.mark.django_db\ndef test_repository_can_save_a_batch():\n    batch = model.Batch(\"batch1\", \"RUSTY-SOAPDISH\", 100, eta=date(2011, 12, 25))\n\n    repo = repository.DjangoRepository()\n    repo.add(batch)\n\n    [saved_batch] = django_models.Batch.objects.all()\n    assert saved_batch.reference == batch.reference\n    assert saved_batch.sku == batch.sku\n    assert saved_batch.qty == batch._purchased_quantity\n    assert saved_batch.eta == batch.eta\n----\n====\n\n\nThe second test is a bit more involved since it has allocations,\nbut it is still made up of familiar-looking Django code:\n\n[[django_repo_test2]]\n.Second repository test is more involved (tests/integration/test_repository.py)\n====\n[source,python]\n----\n@pytest.mark.django_db\ndef test_repository_can_retrieve_a_batch_with_allocations():\n    sku = \"PONY-STATUE\"\n    d_line = django_models.OrderLine.objects.create(orderid=\"order1\", sku=sku, qty=12)\n    d_batch1 = django_models.Batch.objects.create(\n        reference=\"batch1\", sku=sku, qty=100, eta=None\n    )\n    d_batch2 = django_models.Batch.objects.create(\n        reference=\"batch2\", sku=sku, qty=100, eta=None\n    )\n    django_models.Allocation.objects.create(line=d_line, batch=d_batch1)\n\n    repo = repository.DjangoRepository()\n    retrieved = repo.get(\"batch1\")\n\n    expected = model.Batch(\"batch1\", sku, 100, eta=None)\n    assert retrieved == expected  # Batch.__eq__ only compares reference\n    assert retrieved.sku == expected.sku\n    assert retrieved._purchased_quantity == expected._purchased_quantity\n    assert retrieved._allocations == {\n        model.OrderLine(\"order1\", sku, 12),\n    }\n----\n====\n\nHere's how the actual repository ends up looking:\n\n\n[[django_repository]]\n.A Django repository (src/allocation/adapters/repository.py)\n====\n[source,python]\n----\nclass DjangoRepository(AbstractRepository):\n    def add(self, batch):\n        super().add(batch)\n        self.update(batch)\n\n    def update(self, batch):\n        django_models.Batch.update_from_domain(batch)\n\n    def _get(self, reference):\n        return (\n            django_models.Batch.objects.filter(reference=reference)\n            .first()\n            .to_domain()\n        )\n\n    def list(self):\n        return [b.to_domain() for b in django_models.Batch.objects.all()]\n----\n====\n\n\nYou can see that the implementation relies on the Django models having\nsome custom methods for translating to and from our domain model.footnote:[\nThe DRY-Python project people have built a tool called\nhttps://mappers.readthedocs.io/en/latest[mappers] that looks like it might\nhelp minimize boilerplate for this sort of thing.]\n\n\n==== Custom Methods on Django ORM Classes to Translate to/from Our Domain Model\n\n(((\"domain model\", \"Django custom ORM methods for conversion\")))\n(((\"object-relational mappers (ORMs)\", \"Django, custom methods to translate to/from domain model\")))\nThose custom methods look something like this:\n\n[[django_models]]\n.Django ORM with custom methods for domain model conversion (src/djangoproject/alloc/models.py)\n====\n[source,python]\n----\nfrom django.db import models\nfrom allocation.domain import model as domain_model\n\n\nclass Batch(models.Model):\n    reference = models.CharField(max_length=255)\n    sku = models.CharField(max_length=255)\n    qty = models.IntegerField()\n    eta = models.DateField(blank=True, null=True)\n\n    @staticmethod\n    def update_from_domain(batch: domain_model.Batch):\n        try:\n            b = Batch.objects.get(reference=batch.reference)  #<1>\n        except Batch.DoesNotExist:\n            b = Batch(reference=batch.reference)  #<1>\n        b.sku = batch.sku\n        b.qty = batch._purchased_quantity\n        b.eta = batch.eta  #<2>\n        b.save()\n        b.allocation_set.set(\n            Allocation.from_domain(l, b)  #<3>\n            for l in batch._allocations\n        )\n\n    def to_domain(self) -> domain_model.Batch:\n        b = domain_model.Batch(\n            ref=self.reference, sku=self.sku, qty=self.qty, eta=self.eta\n        )\n        b._allocations = set(\n            a.line.to_domain()\n            for a in self.allocation_set.all()\n        )\n        return b\n\n\nclass OrderLine(models.Model):\n    #...\n----\n====\n\n<1> For value objects, `objects.get_or_create` can work, but for entities,\n    you probably need an explicit try-get/except to handle the upsert.footnote:[\n    `@mr-bo-jangles` suggested you might be able to use https://oreil.ly/HTq1r[`update_or_create`],\n    but that's beyond our Django-fu.]\n\n<2> We've shown the most complex example here. If you do decide to do this,\n    be aware that there will be boilerplate! Thankfully it's not very\n    complex boilerplate.\n\n<3> Relationships also need some careful, custom handling.\n\n\nNOTE: As in <<chapter_02_repository>>, we use dependency inversion.\n    The ORM (Django) depends on the model and not the other way around.\n    (((\"Django\", \"Repository pattern with\", startref=\"ix_DjangoRepo\")))\n    (((\"Repository pattern\", \"with Django\", startref=\"ix_RepoDjango\")))\n\n\n\n=== Unit of Work Pattern with Django\n\n\n(((\"Django\", \"Unit of Work pattern with\", id=\"ix_DjangoUoW\")))\n(((\"Unit of Work pattern\", \"with Django\", id=\"ix_UoWDjango\")))\nThe tests don't change too much:\n\n[[test_uow_django]]\n.Adapted UoW tests (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef insert_batch(ref, sku, qty, eta):  #<1>\n    django_models.Batch.objects.create(reference=ref, sku=sku, qty=qty, eta=eta)\n\n\ndef get_allocated_batch_ref(orderid, sku):  #<1>\n    return django_models.Allocation.objects.get(\n        line__orderid=orderid, line__sku=sku\n    ).batch.reference\n\n\n@pytest.mark.django_db(transaction=True)\ndef test_uow_can_retrieve_a_batch_and_allocate_to_it():\n    insert_batch(\"batch1\", \"HIPSTER-WORKBENCH\", 100, None)\n\n    uow = unit_of_work.DjangoUnitOfWork()\n    with uow:\n        batch = uow.batches.get(reference=\"batch1\")\n        line = model.OrderLine(\"o1\", \"HIPSTER-WORKBENCH\", 10)\n        batch.allocate(line)\n        uow.commit()\n\n    batchref = get_allocated_batch_ref(\"o1\", \"HIPSTER-WORKBENCH\")\n    assert batchref == \"batch1\"\n\n\n@pytest.mark.django_db(transaction=True)  #<2>\ndef test_rolls_back_uncommitted_work_by_default():\n    ...\n\n@pytest.mark.django_db(transaction=True)  #<2>\ndef test_rolls_back_on_error():\n    ...\n----\n====\n\n<1> Because we had little helper functions in these tests, the actual\n    main bodies of the tests are pretty much the same as they were with\n    SQLAlchemy.\n\n<2> The `pytest-django` `mark.django_db(transaction=True)` is required to\n    test our custom transaction/rollback behaviors.\n\n\n\nAnd the implementation is quite simple, although it took me a few\ntries to find which invocation of Django's transaction magic\nwould work:\n\n\n[[start_uow_django]]\n.UoW adapted for Django (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n----\nclass DjangoUnitOfWork(AbstractUnitOfWork):\n    def __enter__(self):\n        self.batches = repository.DjangoRepository()\n        transaction.set_autocommit(False)  #<1>\n        return super().__enter__()\n\n    def __exit__(self, *args):\n        super().__exit__(*args)\n        transaction.set_autocommit(True)\n\n    def commit(self):\n        for batch in self.batches.seen:  #<3>\n            self.batches.update(batch)  #<3>\n        transaction.commit()  #<2>\n\n    def rollback(self):\n        transaction.rollback()  #<2>\n----\n====\n\n<1> `set_autocommit(False)` was the best way to tell Django to stop\n    automatically committing each ORM operation immediately, and to\n    begin a transaction.\n\n<2> Then we use the explicit rollback and commits.\n\n<3> One difficulty: because, unlike with SQLAlchemy, we're not\n    instrumenting the domain model instances themselves, the\n    `commit()` command needs to explicitly go through all the\n    objects that have been touched by every repository and manually\n    update them back to the ORM.\n    (((\"Django\", \"Unit of Work pattern with\", startref=\"ix_DjangoUoW\")))\n    (((\"Unit of Work pattern\", \"with Django\", startref=\"ix_UoWDjango\")))\n\n\n\n=== API: Django Views Are Adapters\n\n(((\"adapters\", \"Django views\")))\n(((\"views\", \"Django views as adapters\")))\n(((\"APIs\", \"Django views as adapters\")))\n(((\"Django\", \"views are adapters\")))\nThe Django _views.py_ file ends up being almost identical to the\nold _flask_app.py_, because our architecture means it's a very\nthin wrapper around our service layer (which didn't change at all, by the way):\n\n\n[[django_views]]\n.Flask app -> Django views (src/djangoproject/alloc/views.py)\n====\n[source,python]\n----\nos.environ[\"DJANGO_SETTINGS_MODULE\"] = \"djangoproject.django_project.settings\"\ndjango.setup()\n\n\n@csrf_exempt\ndef add_batch(request):\n    data = json.loads(request.body)\n    eta = data[\"eta\"]\n    if eta is not None:\n        eta = datetime.fromisoformat(eta).date()\n    services.add_batch(\n        data[\"ref\"], data[\"sku\"], data[\"qty\"], eta,\n        unit_of_work.DjangoUnitOfWork(),\n    )\n    return HttpResponse(\"OK\", status=201)\n\n\n@csrf_exempt\ndef allocate(request):\n    data = json.loads(request.body)\n    try:\n        batchref = services.allocate(\n            data[\"orderid\"],\n            data[\"sku\"],\n            data[\"qty\"],\n            unit_of_work.DjangoUnitOfWork(),\n        )\n    except (model.OutOfStock, services.InvalidSku) as e:\n        return JsonResponse({\"message\": str(e)}, status=400)\n\n    return JsonResponse({\"batchref\": batchref}, status=201)\n----\n====\n\n\n=== Why Was This All So Hard?\n\n(((\"Django\", \"using, difficulty of\")))\nOK, it works, but it does feel like more effort than Flask/SQLAlchemy. Why is\nthat?\n\nThe main reason at a low level is because Django's ORM doesn't work in the same\nway.  We don't have an equivalent of the SQLAlchemy classical mapper, so our\n`ActiveRecord` and our domain model can't be the same object. Instead we have to\nbuild a manual translation layer behind the repository. That's more\nwork (although once it's done, the ongoing maintenance burden shouldn't be too\nhigh).\n\n(((\"pytest\", \"pytest-django plugin\")))\nBecause Django is so tightly coupled to the database, you have to use helpers\nlike `pytest-django` and think carefully about test databases, right from\nthe very first line of code, in a way that we didn't have to when we started\nout with our pure domain model.\n\nBut at a higher level, the entire reason that Django is so great\nis that it's designed around the sweet spot of making it easy to build CRUD\napps with minimal boilerplate. But the entire thrust of our book is about\nwhat to do when your app is no longer a simple CRUD app.\n\nAt that point, Django starts hindering more than it helps. Things like the\nDjango admin, which are so awesome when you start out, become actively dangerous\nif the whole point of your app is to build a complex set of rules and modeling\naround the workflow of state changes.  The Django admin bypasses all of that.\n\n=== What to Do If You Already Have Django\n\n(((\"Django\", \"applying patterns to Django app\")))\nSo what should you do if you want to apply some of the patterns in this book\nto a Django app? We'd say the following:\n\n* The Repository and Unit of Work patterns are going to be quite a lot of work. The\n  main thing they will buy you in the short term is faster unit tests, so\n  evaluate whether that benefit feels worth it in your case. In the longer term, they\n  decouple your app from Django and the database, so if you anticipate wanting\n  to migrate away from either of those, Repository and UoW are a good idea.\n\n* The Service Layer pattern might be of interest if you're seeing a lot of duplication in\n  your _views.py_. It can be a good way of thinking about your use cases separately from your web endpoints.\n\n* You can still theoretically do DDD and domain modeling with Django models,\n  tightly coupled as they are to the database; you may be slowed by\n  migrations, but it shouldn't be fatal. So as long as your app is not too\n  complex and your tests not too slow, you may be able to get something out of\n  the _fat models_ approach: push as much logic down to your models as possible,\n  and apply patterns like Entity, Value Object, and Aggregate. However, see\n  the following caveat.\n\nWith that said,\nhttps://oreil.ly/Nbpjj[word\nin the Django community] is that people find that the fat models approach runs into\nscalability problems of its own, particularly around managing interdependencies\nbetween apps. In those cases, there's a lot to be said for extracting out a\nbusiness logic or domain layer to sit between your views and forms and\nyour _models.py_, which you can then keep as minimal as possible.\n\n=== Steps Along the Way\n\n(((\"Django\", \"applying patterns to Django app\", \"steps along the way\")))\nSuppose you're working on a Django project that you're not sure is going\nto get complex enough to warrant the patterns we recommend, but you still\nwant to put a few steps in place to make your life easier, both in the medium\nterm and if you want to migrate to some of our patterns later. Consider the following:\n\n* One piece of advice we've heard is to put a __logic.py__ into every Django app from day one. This gives you a place to put business logic, and to keep your\n  forms, views, and models free of business logic. It can become a stepping-stone\n  for moving to a fully decoupled domain model and/or service layer later.\n\n* A business-logic layer might start out working with Django model objects and only later become fully decoupled from the framework and work on\n  plain Python data structures.\n\n[role=\"pagebreak-before\"]\n* For the read side, you can get some of the benefits of CQRS by putting reads\n  into one place, avoiding ORM calls sprinkled all over the place.\n\n* When separating out modules for reads and modules for domain logic, it\n  may be worth decoupling yourself from the Django apps hierarchy. Business\n  concerns will cut across them.\n\n\nNOTE: We'd like to give a shout-out to David Seddon and Ashia Zawaduk for\n    talking through some of the ideas in this appendix. They did their best to\n    stop us from saying anything really stupid about a topic we don't really\n    have enough personal experience of, but they may have failed.\n\n(((\"Django\", startref=\"ix_Django\")))\nFor more thoughts and actual lived experience dealing with existing\napplications, refer to the <<epilogue_1_how_to_get_there_from_here, epilogue>>.\n"
        },
        {
          "name": "appendix_ds1_table.asciidoc",
          "type": "blob",
          "size": 2.3037109375,
          "content": "[[appendix_ds1_table]]\n[appendix]\n== Summary Diagram and Table\n\n(((\"architecture, summary diagram and table\", id=\"ix_archsumm\")))\nHere's what our architecture looks like by the end of the book:\n\n[[recap_diagram]]\nimage::images/apwp_aa01.png[\"diagram showing all components: flask+eventconsumer, service layer, adapters, domain etc\"]\n\n<<ds1_table>> recaps each pattern and what it does.\n\n[[ds1_table]]\n.The components of our architecture and what they all do\n[cols=\"1,1,2\"]\n|===\n| Layer | Component | Description\n\n.5+a| *Domain*\n\n__Defines the business logic.__\n\n\n| Entity | A domain object whose attributes may change but that has a recognizable identity over time.\n\n| Value object | An immutable domain object whose attributes entirely define it. It is fungible with other identical objects.\n\n| Aggregate | Cluster of associated objects that we treat as a unit for the purpose of data changes. Defines and enforces a consistency boundary.\n\n| Event | Represents something that happened.\n\n| Command | Represents a job the system should perform.\n\n.3+a| *Service Layer*\n\n__Defines the jobs the system should perform and orchestrates different components.__\n\n| Handler | Receives a command or an event and performs what needs to happen.\n| Unit of work | Abstraction around data integrity. Each unit of work represents an atomic update. Makes repositories available. Tracks new events on retrieved aggregates.\n| Message bus (internal) | Handles commands and events by routing them to the appropriate handler.\n\n.2+a| *Adapters* (Secondary)\n\n__Concrete implementations of an interface that goes from our system\nto the outside world (I/O).__\n\n| Repository | Abstraction around persistent storage. Each aggregate has its own repository.\n| Event publisher | Pushes events onto the external message bus.\n\n.2+a| *Entrypoints* (Primary adapters)\n\n__Translate external inputs into calls into the service layer.__\n\n| Web | Receives web requests and translates them into commands, passing them to the internal message bus.\n| Event consumer | Reads events from the external message bus and translates them into commands, passing them to the internal message bus.\n\n| N/A | External message bus (message broker) | A piece of infrastructure that different services use to intercommunicate, via events.\n|===\n(((\"architecture, summary diagram and table\", startref=\"ix_archsumm\")))\n"
        },
        {
          "name": "appendix_project_structure.asciidoc",
          "type": "blob",
          "size": 13.6162109375,
          "content": "[[appendix_project_structure]]\n[appendix]\n== A Template Project Structure\n\n(((\"projects\", \"template project structure\", id=\"ix_prjstrct\")))\nAround <<chapter_04_service_layer>>, we moved from just having\neverything in one folder to a more structured tree, and we thought it might\nbe of interest to outline the moving parts.\n\n[TIP]\n====\nThe code for this appendix is in the\nappendix_project_structure branch https://oreil.ly/1rDRC[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout appendix_project_structure\n----\n====\n\n\nThe basic folder structure looks like this:\n\n[[project_tree]]\n.Project tree\n====\n[source,text]\n[role=\"tree\"]\n----\n.\n├── Dockerfile  <1>\n├── Makefile  <2>\n├── README.md\n├── docker-compose.yml  <1>\n├── license.txt\n├── mypy.ini\n├── requirements.txt\n├── src  <3>\n│   ├── allocation\n│   │   ├── __init__.py\n│   │   ├── adapters\n│   │   │   ├── __init__.py\n│   │   │   ├── orm.py\n│   │   │   └── repository.py\n│   │   ├── config.py\n│   │   ├── domain\n│   │   │   ├── __init__.py\n│   │   │   └── model.py\n│   │   ├── entrypoints\n│   │   │   ├── __init__.py\n│   │   │   └── flask_app.py\n│   │   └── service_layer\n│   │       ├── __init__.py\n│   │       └── services.py\n│   └── setup.py  <3>\n└── tests  <4>\n    ├── conftest.py  <4>\n    ├── e2e\n    │   └── test_api.py\n    ├── integration\n    │   ├── test_orm.py\n    │   └── test_repository.py\n    ├── pytest.ini  <4>\n    └── unit\n        ├── test_allocate.py\n        ├── test_batches.py\n        └── test_services.py\n----\n====\n\n<1> Our _docker-compose.yml_ and our _Dockerfile_ are the main bits of configuration\n    for the containers that run our app, and they can also run the tests (for CI).  A\n    more complex project might have several Dockerfiles, although we've found that\n    minimizing the number of images is usually a good idea.footnote:[Splitting\n    out images for production and testing is sometimes a good idea, but we've tended\n    to find that going further and trying to split out different images for\n    different types of application code (e.g., Web API versus pub/sub client) usually\n    ends up being more trouble than it's worth; the cost in terms of complexity\n    and longer rebuild/CI times is too high. YMMV.]\n\n<2> A __Makefile__ provides the entrypoint for all the typical commands a developer\n    (or a CI server) might want to run during their normal workflow: `make\n    build`, `make test`, and so on.footnote:[A pure-Python alternative to Makefiles is\n    http://www.pyinvoke.org[Invoke], worth checking out if everyone on your\n    team knows Python (or at least knows it better than Bash!).] This is optional. You could just use\n    `docker-compose` and `pytest` directly, but if nothing else, it's nice to\n    have all the \"common commands\" in a list somewhere, and unlike\n    documentation, a Makefile is code so it has less tendency to become out of date.\n\n<3> All the source code for our app, including the domain model, the\n    Flask app, and infrastructure code, lives in a Python package inside\n    _src_,footnote:[https://hynek.me/articles/testing-packaging[\"Testing and Packaging\"] by Hynek Schlawack provides more information on _src_ folders.]\n    which we install using `pip install -e` and the _setup.py_ file.  This makes\n    imports easy. Currently, the structure within this module is totally flat,\n    but for a more complex project, you'd expect to grow a folder hierarchy\n    that includes _domain_model/_, _infrastructure/_, _services/_, and _api/_.\n\n\n<4> Tests live in their own folder. Subfolders distinguish different test\n    types and allow you to run them separately.  We can keep shared fixtures\n    (_conftest.py_) in the main tests folder and nest more specific ones if we\n    wish. This is also the place to keep _pytest.ini_.\n\n\n\nTIP: The https://oreil.ly/QVb9Q[pytest docs] are really good on test layout and importability.\n\n\nLet's look at a few of these files and concepts in more detail.\n\n\n\n=== Env Vars, 12-Factor, and Config, Inside and Outside Containers\n\nThe basic problem we're trying to solve here is that we need different\nconfig settings for the following:\n\n- Running code or tests directly from your own dev machine, perhaps\n  talking to mapped ports from Docker containers\n\n- Running on the containers themselves, with \"real\" ports and hostnames\n\n- Different container environments (dev, staging, prod, and so on)\n\nConfiguration through environment variables as suggested by the\nhttps://12factor.net/config[12-factor manifesto] will solve this problem,\nbut concretely, how do we implement it in our code and our containers?\n\n\n=== Config.py\n\nWhenever our application code needs access to some config, it's going to\nget it from a file called __config.py__. Here are a couple of examples from our\napp:\n\n[[config_dot_py]]\n.Sample config functions (src/allocation/config.py)\n====\n[source,python]\n----\nimport os\n\n\ndef get_postgres_uri():  #<1>\n    host = os.environ.get(\"DB_HOST\", \"localhost\")  #<2>\n    port = 54321 if host == \"localhost\" else 5432\n    password = os.environ.get(\"DB_PASSWORD\", \"abc123\")\n    user, db_name = \"allocation\", \"allocation\"\n    return f\"postgresql://{user}:{password}@{host}:{port}/{db_name}\"\n\n\ndef get_api_url():\n    host = os.environ.get(\"API_HOST\", \"localhost\")\n    port = 5005 if host == \"localhost\" else 80\n    return f\"http://{host}:{port}\"\n----\n====\n\n<1> We use functions for getting the current config, rather than constants\n    available at import time, because that allows client code to modify\n    `os.environ` if it needs to.\n\n<2> _config.py_ also defines some default settings, designed to work when\n    running the code from the developer's local machine.footnote:[\n    This gives us a local development setup that \"just works\" (as much as possible).\n    You may prefer to fail hard on missing environment variables instead, particularly\n    if any of the defaults would be insecure in production.]\n\nAn elegant Python package called\nhttps://github.com/hynek/environ-config[_environ-config_] is worth looking\nat if you get tired of hand-rolling your own environment-based config functions.\n\nTIP: Don't let this config module become a dumping ground that is full of things only vaguely related to config and that is then imported all over the place.\n    Keep things immutable and modify them only via environment variables.\n    If you decide to use a <<chapter_13_dependency_injection,bootstrap script>>,\n    you can make it the only place (other than tests) that config is imported to.\n\n=== Docker-Compose and Containers Config\n\nWe use a lightweight Docker container orchestration tool called _docker-compose_.\nIt's main configuration is via a YAML file (sigh):footnote:[Harry is a bit YAML-weary.\nIt's _everywhere_, and yet he can never remember the syntax or how it's supposed\nto indent.]\n\n\n[[docker_compose]]\n.docker-compose config file (docker-compose.yml)\n====\n[source,yaml]\n----\nversion: \"3\"\nservices:\n\n  app:  #<1>\n    build:\n      context: .\n      dockerfile: Dockerfile\n    depends_on:\n      - postgres\n    environment:  #<3>\n      - DB_HOST=postgres  <4>\n      - DB_PASSWORD=abc123\n      - API_HOST=app\n      - PYTHONDONTWRITEBYTECODE=1  #<5>\n    volumes:  #<6>\n      - ./src:/src\n      - ./tests:/tests\n    ports:\n      - \"5005:80\"  <7>\n\n\n  postgres:\n    image: postgres:9.6  #<2>\n    environment:\n      - POSTGRES_USER=allocation\n      - POSTGRES_PASSWORD=abc123\n    ports:\n      - \"54321:5432\"\n----\n====\n\n<1> In the _docker-compose_ file, we define the different _services_\n    (containers) that we need for our app. Usually one main image\n    contains all our code, and we can use it to run our API, our tests,\n    or any other service that needs access to the domain model.\n\n<2> You'll probably have other infrastructure services, including a database.\n    In production you might not use containers for this; you might have a cloud\n    provider instead, but _docker-compose_ gives us a way of producing a\n    similar service for dev or CI.\n\n<3> The `environment` stanza lets you set the environment variables for your\n    containers, the hostnames and ports as seen from inside the Docker cluster.\n    If you have enough containers that information starts to be duplicated in\n    these sections, you can use `environment_file` instead. We usually call\n    ours _container.env_.\n\n<4> Inside a cluster, _docker-compose_ sets up networking such that containers are\n    available to each other via hostnames named after their service name.\n\n<5> Pro tip: if you're mounting volumes to share source folders between your\n    local dev machine and the container, the `PYTHONDONTWRITEBYTECODE` environment variable\n    tells Python to not write _.pyc_ files, and that will save you from\n    having millions of root-owned files sprinkled all over your local filesystem,\n    being all annoying to delete and causing weird Python compiler errors besides.\n\n<6> Mounting our source and test code as `volumes` means we don't need to rebuild\n    our containers every time we make a code change.\n\n<7> The `ports` section allows us to expose the ports from inside the containers\n    to the outside worldfootnote:[On a CI server, you may not be able to expose\n    arbitrary ports reliably, but it's only a convenience for local dev. You\n    can find ways of making these port mappings optional (e.g., with\n    _docker-compose.override.yml_).]—these correspond to the default ports we set\n    in _config.py_.\n\nNOTE: Inside Docker, other containers are available through hostnames named after\n    their service name. Outside Docker, they are available on `localhost`, at the\n    port defined in the `ports` section.\n\n\n=== Installing Your Source as a Package\n\nAll our application code (everything except tests, really) lives inside an\n_src_ folder:\n\n[[src_folder_tree]]\n.The src folder\n====\n[source,text]\n[role=\"skip\"]\n----\n├── src\n│   ├── allocation  #<1>\n│   │   ├── config.py\n│   │   └── ...\n│   └── setup.py  <2>\n----\n====\n\n<1> Subfolders define top-level module names. You can have multiple if you like.\n\n<2> And _setup.py_ is the file you need to make it pip-installable, shown next.\n\n[[setup_dot_py]]\n.pip-installable modules in three lines (src/setup.py)\n====\n[source,python]\n----\nfrom setuptools import setup\n\nsetup(\n    name=\"allocation\", version=\"0.1\", packages=[\"allocation\"],\n)\n----\n====\n\nThat's all you need. `packages=` specifies the names of subfolders that you\nwant to install as top-level modules. The `name` entry is just cosmetic, but\nit's required. For a package that's never actually going to hit PyPI, it'll\ndo fine.footnote:[For more _setup.py_ tips, see\nhttps://oreil.ly/KMWDz[this article on packaging] by Hynek.]\n\n\n=== Dockerfile\n\nDockerfiles are going to be very project-specific, but here are a few key stages\nyou'll expect to see:\n\n[[dockerfile]]\n.Our Dockerfile (Dockerfile)\n====\n[source,dockerfile]\n----\nFROM python:3.9-slim-buster\n\n<1>\n# RUN apt install gcc libpq (no longer needed bc we use psycopg2-binary)\n\n<2>\nCOPY requirements.txt /tmp/\nRUN pip install -r /tmp/requirements.txt\n\n<3>\nRUN mkdir -p /src\nCOPY src/ /src/\nRUN pip install -e /src\nCOPY tests/ /tests/\n\n<4>\nWORKDIR /src\nENV FLASK_APP=allocation/entrypoints/flask_app.py FLASK_DEBUG=1 PYTHONUNBUFFERED=1\nCMD flask run --host=0.0.0.0 --port=80\n----\n====\n\n<1> Installing system-level dependencies\n<2> Installing our Python dependencies (you may want to split out your dev from\n    prod dependencies; we haven't here, for simplicity)\n<3> Copying and installing our source\n<4> Optionally configuring a default startup command (you'll probably override\n    this a lot from the command line)\n\nTIP: One thing to note is that we install things in the order of how frequently they\n    are likely to change. This allows us to maximize Docker build cache reuse. I\n    can't tell you how much pain and frustration underlies this lesson. For this\n    and many more Python Dockerfile improvement tips, check out\n    https://pythonspeed.com/docker[\"Production-Ready Docker Packaging\"].\n\n=== Tests\n\n(((\"testing\", \"tests folder tree\")))\nOur tests are kept alongside everything else, as shown here:\n\n[[tests_folder]]\n.Tests folder tree\n====\n[source,text]\n[role=\"tree\"]\n----\n└── tests\n    ├── conftest.py\n    ├── e2e\n    │   └── test_api.py\n    ├── integration\n    │   ├── test_orm.py\n    │   └── test_repository.py\n    ├── pytest.ini\n    └── unit\n        ├── test_allocate.py\n        ├── test_batches.py\n        └── test_services.py\n----\n====\n\nNothing particularly clever here, just some separation of different test types\nthat you're likely to want to run separately, and some files for common fixtures,\nconfig, and so on.\n\nThere's no _src_ folder or _setup.py_ in the test folders because we usually\nhaven't needed to make tests pip-installable, but if you have difficulties with\nimport paths, you might find it helps.\n\n\n=== Wrap-Up\n\nThese are our basic building blocks:\n\n* Source code in an _src_ folder, pip-installable using _setup.py_\n* Some Docker config for spinning up a local cluster that mirrors production as far as possible\n* Configuration via environment variables, centralized in a Python file called _config.py_, with defaults allowing things to run _outside_ containers\n* A Makefile for useful command-line, um, commands\n\n(((\"projects\", \"template project structure\", startref=\"ix_prjstrct\")))\nWe doubt that anyone will end up with _exactly_ the same solutions we did, but we hope you\nfind some inspiration here.\n"
        },
        {
          "name": "appendix_validation.asciidoc",
          "type": "blob",
          "size": 18.42578125,
          "content": "[[appendix_validation]]\n[appendix]\n== Validation\n\n(((\"validation\", id=\"ix_valid\")))\nWhenever we're teaching and talking about these techniques, one question that\ncomes up over and over is \"Where should I do validation? Does that belong with\nmy business logic in the domain model, or is that an infrastructural concern?\"\n\nAs with any architectural question, the answer is: it depends!\n\nThe most important consideration is that we want to keep our code well separated\nso that each part of the system is simple. We don't want to clutter our code\nwith irrelevant detail.\n\n=== What Is Validation, Anyway?\n\nWhen people use the word _validation_, they usually mean a process whereby they\ntest the inputs of an operation to make sure that they match certain criteria.\nInputs that match the criteria are considered _valid_, and inputs that don't\nare _invalid_.\n\nIf the input is invalid, the operation can't continue but should exit with\nsome kind of error. In other words, validation is about creating _preconditions_. We find it useful\nto separate our preconditions into three subtypes: syntax, semantics, and\npragmatics.\n\n=== Validating Syntax\n\nIn linguistics, the _syntax_ of a language is the set of rules that govern the\nstructure of grammatical sentences. For example, in English, the sentence\n\"Allocate three units of `TASTELESS-LAMP` to order twenty-seven\" is grammatically\nsound, while the phrase \"hat hat hat hat hat hat wibble\" is not. We can describe\ngrammatically correct sentences as _well formed_.\n\n[role=\"pagebreak-before\"]\nHow does this map to our application? Here are some examples of syntactic rules:\n\n* An `Allocate` command must have an order ID, a SKU, and a quantity.\n* A quantity is a positive integer.\n* A SKU is a string.\n\nThese are rules about the shape and structure of incoming data. An `Allocate`\ncommand without a SKU or an order ID isn't a valid message. It's the equivalent\nof the phrase \"Allocate three to.\"\n\nWe tend to validate these rules at the edge of the system. Our rule of thumb is\nthat a message handler should always receive only a message that is well-formed\nand contains all required information.\n\nOne option is to put your validation logic on the message type itself:\n\n\n[[validation_on_message]]\n.Validation on the message class (src/allocation/commands.py)\n====\n[source,python]\n----\nfrom schema import And, Schema, Use\n\n\n@dataclass\nclass Allocate(Command):\n\n    _schema = Schema({  #<1>\n        'orderid': str,\n        'sku': str,\n        'qty': And(Use(int), lambda n: n > 0)\n     }, ignore_extra_keys=True)\n\n    orderid: str\n    sku: str\n    qty: int\n\n    @classmethod\n    def from_json(cls, data):  #<2>\n        data = json.loads(data)\n        return cls(**_schema.validate(data))\n----\n====\n\n\n\n<1> The https://pypi.org/project/schema[++schema++ library] lets us\n    describe the structure and validation of our messages in a nice declarative way.\n\n<2> The `from_json` method reads a string as JSON and turns it into our message\n    type.\n\n// IDEA hynek didn't like the inline call to json.loads\n\nThis can get repetitive, though, since we need to specify our fields twice,\nso we might want to introduce a helper library that can unify the validation and\ndeclaration of our message types:\n\n\n[[command_factory]]\n.A command factory with schema (src/allocation/commands.py)\n====\n[source,python]\n----\ndef command(name, **fields):  #<1>\n    schema = Schema(And(Use(json.loads), fields), ignore_extra_keys=True)\n    cls = make_dataclass(name, fields.keys())  #<2>\n    cls.from_json = lambda s: cls(**schema.validate(s))  #<3>\n    return cls\n\ndef greater_than_zero(x):\n    return x > 0\n\nquantity = And(Use(int), greater_than_zero)  #<4>\n\nAllocate = command(  #<5>\n    'Allocate',\n    orderid=int,\n    sku=str,\n    qty=quantity\n)\n\nAddStock = command(\n    'AddStock',\n    sku=str,\n    qty=quantity\n----\n====\n\n<1> The `command` function takes a message name, plus kwargs for the fields of\n    the message payload, where the name of the kwarg is the name of the field and\n    the value is the parser.\n<2> We use the `make_dataclass` function from the dataclass module to dynamically\n    create our message type.\n<3> We patch the `from_json` method onto our dynamic dataclass.\n<4> We can create reusable parsers for quantity, SKU, and so on to keep things DRY.\n<5> Declaring a message type becomes a one-liner.\n\nThis comes at the expense of losing the types on your dataclass, so bear that\ntrade-off in mind.\n\n// (EJ2) I understand this code, but find it to be a little bit gross, since\n// there are many alternatives that combine schema validation, object serialization\n// + deserialization, and class type definitions for you.  Examples here: https://github.com/voidfiles/python-serialization-benchmark\n// Would be nice to see a mention of things like Marshmallow here.\n\n\n\n=== Postel's Law and the Tolerant Reader Pattern\n\n_Postel's law_, or the _robustness principle_, tells us, \"Be liberal in what you\naccept, and conservative in what you emit.\" We think this applies particularly\nwell in the context of integration with our other systems. The idea here is\nthat we should be strict whenever we're sending messages to other systems, but\nas lenient as possible when we're receiving messages from others.\n\nFor example, our system _could_ validate the format of a SKU. We've been using\nmade-up SKUs like `UNFORGIVING-CUSHION` and `MISBEGOTTEN-POUFFE`. These follow\na simple pattern: two words, separated by dashes, where the second word is the\ntype of product and the first word is an adjective.\n\nDevelopers _love_ to validate this kind of thing in their messages, and reject\nanything that looks like an invalid SKU. This causes horrible problems down the\nline when some anarchist releases a product named `COMFY-CHAISE-LONGUE` or when\na snafu at the supplier results in a shipment of `CHEAP-CARPET-2`.\n\nReally, as the allocation system, it's _none of our business_ what the format of\na SKU might be. All we need is an identifier, so we can simply describe it as a\nstring. This means that the procurement system can change the format whenever\nthey like, and we won't care.\n\nThis same principle applies to order numbers, customer phone numbers, and much\nmore. For the most part, we can ignore the internal structure of strings.\n\nSimilarly, developers _love_ to validate incoming messages with tools like JSON\nSchema, or to build libraries that validate incoming messages and share them\namong systems. This likewise fails the robustness test.\n\n// (EJ3) This reads like it's saying that JSON-Schema is bad (which is a separate discussion, I think.)\n//\n// If I understand correctly, the issue is that JSON-Schema allows you to specify\n// syntax, semantics, + pragmatics all in a single definition, and tends to\n// encourage devs to mix them together. Therefore it encourages overly premature validation.\n//\n\nLet's imagine, for example, that the procurement system adds new fields to the\n`ChangeBatchQuantity` message that record the reason for the change and the\nemail of the user responsible for the change.\n\nSince these fields don't matter to the allocation service, we should simply\nignore them. We can do that in the `schema` library by passing the keyword arg\n`ignore_extra_keys=True`.\n\nThis pattern, whereby we extract only the fields we care about and do minimal\nvalidation of them, is the Tolerant Reader pattern.\n\nTIP: Validate as little as possible. Read only the fields you need, and don't\n    overspecify their contents. This will help your system stay robust when other\n    systems change over time. Resist the temptation to share message\n    definitions between systems: instead, make it easy to define the data you\n    depend on. For more info, see Martin Fowler's article on the\n    https://oreil.ly/YL_La[Tolerant Reader pattern].\n\n[role=\"pagebreak-before less_space\"]\n.Is Postel Always Right?\n*******************************************************************************\nMentioning Postel can be quite triggering to some people. They will\nhttps://oreil.ly/bzLmb[tell you]\nthat Postel is the precise reason that everything on the internet is broken and\nwe can't have nice things. Ask Hynek about SSLv3 one day.\n\nWe like the Tolerant Reader approach in the particular context of event-based\nintegration between services that we control, because it allows for independent\nevolution of those services.\n\nIf you're in charge of an API that's open to the public on the big bad\ninternet, there might be good reasons to be more conservative about what\ninputs you allow.\n*******************************************************************************\n\n=== Validating at the Edge\n\n// (EJ2) IMO \"Smart Edges, Dumb Pipes\" is a useful another useful idiom to keep\n// validation straight.\n// \"Validation at the Edge\" might be mis-interpreted as the \"validate\n// everything you can as soon as you can.\"\n\nEarlier, we said that we want to avoid cluttering our code with irrelevant\ndetails. In particular, we don't want to code defensively inside our domain model.\nInstead, we want to make sure that requests are known to be valid before our\ndomain model or use-case handlers see them. This helps our code stay clean\nand maintainable over the long term. We sometimes refer to this as _validating\nat the edge of the system_.\n\nIn addition to keeping your code clean and free of endless checks and asserts,\nbear in mind that invalid data wandering through your system is a time bomb;\nthe deeper it gets, the more damage it can do, and the fewer tools\nyou have to respond to it.\n\nBack in <<chapter_08_events_and_message_bus>>, we said that the message bus was a great place to put\ncross-cutting concerns, and validation is a perfect example of that. Here's how\nwe might change our bus to perform validation for us:\n\n\n[[validation_on_bus]]\n.Validation\n====\n[source,python]\n----\nclass MessageBus:\n\n    def handle_message(self, name: str, body: str):\n        try:\n            message_type = next(mt for mt in EVENT_HANDLERS if mt.__name__ == name)\n            message = message_type.from_json(body)\n            self.handle([message])\n        except StopIteration:\n            raise KeyError(f\"Unknown message name {name}\")\n        except ValidationError as e:\n            logging.error(\n                f'invalid message of type {name}\\n'\n                f'{body}\\n'\n                f'{e}'\n            )\n            raise e\n----\n====\n\n// (EJ3) What's your opinion on how to handle validation in the scenario where\n// the command is being passed to an asynchronous worker pool via RabbitMQ?\n//\n\nHere's how we might use that method from our Flask API endpoint:\n\n\n[[validation_bubbles_up]]\n.API bubbles up validation errors (src/allocation/flask_app.py)\n====\n[source,python]\n----\n@app.route(\"/change_quantity\", methods=['POST'])\ndef change_batch_quantity():\n    try:\n        bus.handle_message('ChangeBatchQuantity', request.body)\n    except ValidationError as e:\n        return bad_request(e)\n    except exceptions.InvalidSku as e:\n        return jsonify({'message': str(e)}), 400\n\ndef bad_request(e: ValidationError):\n    return e.code, 400\n----\n====\n\nAnd here's how we might plug it in to our asynchronous message processor:\n\n[[validation_pubsub]]\n.Validation errors when handling Redis messages (src/allocation/redis_pubsub.py)\n====\n[source,python]\n----\ndef handle_change_batch_quantity(m, bus: messagebus.MessageBus):\n    try:\n        bus.handle_message('ChangeBatchQuantity', m)\n    except ValidationError:\n        print('Skipping invalid message')\n    except exceptions.InvalidSku as e:\n        print(f'Unable to change stock for missing sku {e}')\n----\n====\n\nNotice that our entrypoints are solely concerned with how to get a message from\nthe outside world and how to report success or failure. Our message bus takes\ncare of validating our requests and routing them to the correct handler, and\nour handlers are exclusively focused on the logic of our use case.\n\nTIP: When you receive an invalid message, there's usually little you can do but\n    log the error and continue. At MADE we use metrics to count the number of\n    messages a system receives, and how many of those are successfully\n    processed, skipped, or invalid. Our monitoring tools will alert us if we\n    see spikes in the numbers of bad messages.\n\n\n\n=== Validating Semantics\n\nWhile syntax is concerned with the structure of messages, _semantics_ is the study\nof _meaning_ in messages. The sentence \"Undo no dogs from ellipsis four\" is\nsyntactically valid and has the same structure as the sentence \"Allocate one\nteapot to order five,\"\" but it is meaningless.\n\nWe can read this JSON blob as an `Allocate` command but can't successfully\nexecute it, because it's _nonsense_:\n\n\n[[invalid_order]]\n.A meaningless message\n====\n[source,python]\n----\n{\n  \"orderid\": \"superman\",\n  \"sku\": \"zygote\",\n  \"qty\": -1\n}\n----\n====\n\nWe tend to validate semantic concerns at the message-handler layer with a kind\nof contract-based programming:\n\n\n[[ensure_dot_py]]\n.Preconditions (src/allocation/ensure.py)\n====\n[source,python]\n----\n\"\"\"\nThis module contains preconditions that we apply to our handlers.\n\"\"\"\n\nclass MessageUnprocessable(Exception):  #<1>\n\n    def __init__(self, message):\n        self.message = message\n\nclass ProductNotFound(MessageUnprocessable):  #<2>\n    \"\"\"\"\n    This exception is raised when we try to perform an action on a product\n    that doesn't exist in our database.\n    \"\"\"\"\n\n    def __init__(self, message):\n        super().__init__(message)\n        self.sku = message.sku\n\ndef product_exists(event, uow):  #<3>\n    product = uow.products.get(event.sku)\n    if product is None:\n        raise ProductNotFound(event)\n----\n====\n\n<1> We use a common base class for errors that mean a message is invalid.\n<2> Using a specific error type for this problem makes it easier to report on\n    and handle the error. For example, it's easy to map `ProductNotFound` to a 404\n    in Flask.\n<3> `product_exists` is a precondition. If the condition is `False`, we raise an\n    error.\n\n\nThis keeps the main flow of our logic in the service layer clean and declarative:\n\n[[ensure_in_services]]\n.Ensure calls in services (src/allocation/services.py)\n====\n[source,python,highlight=8]\n----\n# services.py\n\nfrom allocation import ensure\n\ndef allocate(event, uow):\n    line = model.OrderLine(event.orderid, event.sku, event.qty)\n    with uow:\n        ensure.product_exists(event, uow)\n\n        product = uow.products.get(line.sku)\n        product.allocate(line)\n        uow.commit()\n----\n====\n\n\nWe can extend this technique to make sure that we apply messages idempotently.\nFor example, we want to make sure that we don't insert a batch of stock more\nthan once.\n\nIf we get asked to create a batch that already exists, we'll log a warning and\ncontinue to the next message:\n\n[[skipmessage]]\n.Raise SkipMessage exception for ignorable events (src/allocation/services.py)\n====\n[source,python]\n----\nclass SkipMessage (Exception):\n    \"\"\"\"\n    This exception is raised when a message can't be processed, but there's no\n    incorrect behavior. For example, we might receive the same message multiple\n    times, or we might receive a message that is now out of date.\n    \"\"\"\"\n\n    def __init__(self, reason):\n        self.reason = reason\n\ndef batch_is_new(self, event, uow):\n    batch = uow.batches.get(event.batchid)\n    if batch is not None:\n        raise SkipMessage(f\"Batch with id {event.batchid} already exists\")\n----\n====\n\nIntroducing a `SkipMessage` exception lets us handle these cases in a generic\nway in our message bus:\n\n[[skip_in_bus]]\n.The bus now knows how to skip (src/allocation/messagebus.py)\n====\n[source,python]\n----\nclass MessageBus:\n\n    def handle_message(self, message):\n        try:\n            ...\n        except SkipMessage as e:\n            logging.warn(f\"Skipping message {message.id} because {e.reason}\")\n----\n====\n\n\nThere are a couple of pitfalls to be aware of here. First, we need to be sure\nthat we're using the same UoW that we use for the main logic of our\nuse case. Otherwise, we open ourselves to irritating concurrency bugs.\n\nSecond, we should try to avoid putting _all_ our business logic into these\nprecondition checks. As a rule of thumb, if a rule _can_ be tested inside our\ndomain model, then it _should_ be tested in the domain model.\n\n=== Validating Pragmatics\n\n_Pragmatics_ is the study of how we understand language in context. After we have\nparsed a message and grasped its meaning, we still need to process it in\ncontext. For example, if you get a comment on a pull request saying, \"I think\nthis is very brave,\" it may mean that the reviewer admires your courage—unless\nthey're British, in which case, they're trying to tell you that what you're doing\nis insanely risky, and only a fool would attempt it. Context is everything.\n\n[role=\"nobreakinside less_space\"]\n.Validation Recap\n*****************************************************************\n\nValidation means different things to different people::\n    When talking about validation, make sure you're clear about what you're\n    validating.\n    We find it useful to think about syntax, semantics, and pragmatics: the\n    structure of messages, the meaningfulness of messages, and the business\n    logic governing our response to messages.\n\nValidate at the edge when possible::\n    Validating required fields and the permissible ranges of numbers is _boring_,\n    and we want to keep it out of our nice clean codebase. Handlers should always\n    receive only valid messages.\n\nOnly validate what you require::\n    Use the Tolerant Reader pattern: read only the fields your application needs\n    and don't overspecify their internal structure. Treating fields as opaque\n    strings buys you a lot of flexibility.\n\nSpend time writing helpers for validation::\n    Having a nice declarative way to validate incoming messages and apply\n    preconditions to your handlers will make your codebase much cleaner.\n    It's worth investing time to make boring code easy to maintain.\n\nLocate each of the three types of validation in the right place::\n    Validating syntax can happen on message classes, validating\n    semantics can happen in the service layer or on the message bus,\n    and validating pragmatics belongs in the domain model.\n\n*****************************************************************\n\n\nTIP: Once you've validated the syntax and semantics of your commands\n    at the edges of your system, the domain is the place for the rest\n    of your validation.  Validation of pragmatics is often a core part\n    of your business rules.\n\n\nIn software terms, the pragmatics of an operation are usually managed by the\ndomain model. When we receive a message like \"allocate three million units of\n`SCARCE-CLOCK` to order 76543,\" the message is _syntactically_ valid and\n_semantically_ valid, but we're unable to comply because we don't have the stock\navailable.\n(((\"validation\", startref=\"ix_valid\")))\n"
        },
        {
          "name": "atlas.json",
          "type": "blob",
          "size": 1.9765625,
          "content": "{\n  \"branch\": \"master\",\n  \"files\": [\n    \"cover.html\",\n    \"titlepage.html\",\n    \"copyright.html\",\n    \"toc.html\",\n    \"preface.asciidoc\",\n    \"introduction.asciidoc\",\n    \"part1.asciidoc\",\n    \"chapter_01_domain_model.asciidoc\",\n    \"chapter_02_repository.asciidoc\",\n    \"chapter_03_abstractions.asciidoc\",\n    \"chapter_04_service_layer.asciidoc\",\n    \"chapter_05_high_gear_low_gear.asciidoc\",\n    \"chapter_06_uow.asciidoc\",\n    \"chapter_07_aggregate.asciidoc\",\n    \"part2.asciidoc\",\n    \"chapter_08_events_and_message_bus.asciidoc\",\n    \"chapter_09_all_messagebus.asciidoc\",\n    \"chapter_10_commands.asciidoc\",\n    \"chapter_11_external_events.asciidoc\",\n    \"chapter_12_cqrs.asciidoc\",\n    \"chapter_13_dependency_injection.asciidoc\",\n    \"epilogue_1_how_to_get_there_from_here.asciidoc\",\n    \"appendix_ds1_table.asciidoc\",\n    \"appendix_project_structure.asciidoc\",\n    \"appendix_csvs.asciidoc\",\n    \"appendix_django.asciidoc\",\n    \"appendix_validation.asciidoc\",\n    \"ix.html\",\n    \"author_bio.html\",\n    \"colo.html\"\n  ],\n  \"formats\": {\n    \"pdf\": {\n      \"version\": \"web\",\n      \"color_count\": \"4\",\n      \"index\": true,\n      \"toc\": true,\n      \"syntaxhighlighting\": true,\n      \"show_comments\": false,\n      \"trim_size\": \"7inx9.1875in\",\n      \"antennahouse_version\": \"AHFormatterV62_64-MR4\"\n    },\n    \"epub\": {\n      \"index\": true,\n      \"toc\": true,\n      \"epubcheck\": true,\n      \"syntaxhighlighting\": true,\n      \"show_comments\": false,\n      \"downsample_images\": false,\n      \"mathmlreplacement\": false\n    },\n    \"mobi\": {\n      \"index\": true,\n      \"toc\": true,\n      \"syntaxhighlighting\": true,\n      \"show_comments\": false,\n      \"downsample_images\": false\n    },\n    \"html\": {\n      \"index\": true,\n      \"toc\": true,\n      \"syntaxhighlighting\": true,\n      \"show_comments\": false,\n      \"consolidated\": false\n    }\n  },\n  \"theme\": \"oreillymedia/animal_theme_sass\",\n  \"title\": \"Architecture Patterns with Python\",\n  \"print_isbn13\": \"9781492052203\",\n  \"lang\": \"en\",\n  \"accent_color\": \"\",\n  \"templating\": false\n}"
        },
        {
          "name": "author_bio.html",
          "type": "blob",
          "size": 0.7041015625,
          "content": "<section data-type=\"colophon\" xmlns=\"http://www.w3.org/1999/xhtml\" class=\"abouttheauthor\">\n  <h1>About the Authors</h1>\n  <p><strong>Harry Percival</strong> spent a few years being deeply unhappy as a management consultant. Soon he rediscovered his true geek nature and was lucky enough to fall in with a bunch of XP fanatics, working on pioneering the sadly defunct Resolver One spreadsheet. He worked at PythonAnywhere LLP, spreading the gospel of TDD worldwide at talks, workshops, and conferences. He is now with MADE.com.</p>\n\n  <p><strong>Bob Gregory</strong> is a UK-based software architect with MADE.com. He has been building event-driven systems with domain-driven design for more than a decade.</p>\n</section>\n"
        },
        {
          "name": "book.asciidoc",
          "type": "blob",
          "size": 1.1142578125,
          "content": ":doctype: book\n:source-highlighter: pygments\n:icons: font\n:toc: left\n:toclevels: 1\n\n= Architecture Patterns with Python\n\n:sectnums!:\n\ninclude::preface.asciidoc[]\n\ninclude::introduction.asciidoc[]\n\n\n:sectnums:\n\ninclude::part1.asciidoc[]\n\ninclude::chapter_01_domain_model.asciidoc[]\n\ninclude::chapter_02_repository.asciidoc[]\n\ninclude::chapter_03_abstractions.asciidoc[]\n\n\ninclude::chapter_04_service_layer.asciidoc[]\n\ninclude::chapter_05_high_gear_low_gear.asciidoc[]\n\ninclude::chapter_06_uow.asciidoc[]\n\ninclude::chapter_07_aggregate.asciidoc[]\n\n\ninclude::part2.asciidoc[]\n\ninclude::chapter_08_events_and_message_bus.asciidoc[]\n\ninclude::chapter_09_all_messagebus.asciidoc[]\n\ninclude::chapter_10_commands.asciidoc[]\n\ninclude::chapter_11_external_events.asciidoc[]\n\ninclude::chapter_12_cqrs.asciidoc[]\n\ninclude::chapter_13_dependency_injection.asciidoc[]\n\n\n:sectnums!:\n\ninclude::epilogue_1_how_to_get_there_from_here.asciidoc[]\n\n:sectnums:\n\ninclude::appendix_ds1_table.asciidoc[]\n\ninclude::appendix_project_structure.asciidoc[]\n\ninclude::appendix_csvs.asciidoc[]\n\ninclude::appendix_django.asciidoc[]\n\ninclude::appendix_validation.asciidoc[]\n\n"
        },
        {
          "name": "callouts",
          "type": "tree",
          "content": null
        },
        {
          "name": "chapter_01_domain_model.asciidoc",
          "type": "blob",
          "size": 37.1640625,
          "content": "[[chapter_01_domain_model]]\n== Domain Modeling\n\n(((\"domain modeling\", id=\"ix_dommod\")))\n(((\"domain driven design (DDD)\", seealso=\"domain model; domain modeling\")))\nThis chapter looks into how we can model business processes with code, in a way\nthat's highly compatible with TDD.  We'll discuss _why_ domain modeling\nmatters, and we'll look at a few key patterns for modeling domains: Entity,\nValue Object, and Domain Service.\n\n<<maps_chapter_01_notext>> is a simple visual placeholder for our Domain\nModel pattern. We'll fill in some details in this chapter, and as we move on to\nother chapters, we'll build things around the domain model, but you should\nalways be able to find these little shapes at the core.\n\n[[maps_chapter_01_notext]]\n.A placeholder illustration of our domain model\nimage::images/apwp_0101.png[]\n\n[role=\"pagebreak-before less_space\"]\n=== What Is a Domain Model?\n\n(((\"business logic layer\")))\nIn the <<introduction, introduction>>, we used the term _business logic layer_\nto describe the central layer of a three-layered architecture. For the rest of\nthe book, we're going to use the term _domain model_ instead. This is a term\nfrom the DDD community that does a better job of capturing our intended meaning\n(see the next sidebar for more on DDD).\n\n(((\"domain driven design (DDD)\", \"domain, defined\")))\nThe _domain_ is a fancy way of saying _the problem you're trying to solve._\nYour authors currently work for an online retailer of furniture.  Depending on\nwhich system you're talking about, the domain might be purchasing and\nprocurement, or product design, or logistics and delivery. Most programmers\nspend their days trying to improve or automate business processes; the domain\nis the set of activities that those processes support.\n\n(((\"model (domain)\")))\nA _model_ is a map of a process or phenomenon that captures a useful property.\nHumans are exceptionally good at producing models of things in their heads. For\nexample, when someone throws a ball toward you, you're able to predict its\nmovement almost unconsciously, because you have a model of the way objects move\nin space. Your model isn't perfect by any means. Humans have terrible\nintuitions about how objects behave at near-light speeds or in a vacuum because\nour model was never designed to cover those cases. That doesn't mean the model\nis wrong, but it does mean that some predictions fall outside of its domain.\n\nThe domain model is the mental map that business owners have of their\nbusinesses. All business people have these mental maps--they're how humans think\nabout complex processes.\n\nYou can tell when they're navigating these maps because they use business speak.\nJargon arises naturally among people who are collaborating on complex systems.\n\nImagine that you, our unfortunate reader, were suddenly transported light years\naway from Earth aboard an alien spaceship with your friends and family and had\nto figure out, from first principles, how to navigate home.\n\nIn your first few days, you might just push buttons randomly, but soon you'd\nlearn which buttons did what, so that you could give one another instructions.\n\"Press the red button near the flashing doohickey and then throw that big\nlever over by the radar gizmo,\" you might say.\n\nWithin a couple of weeks, you'd become more precise as you adopted words to\ndescribe the ship's functions: \"Increase oxygen levels in cargo bay three\"\nor \"turn on the little thrusters.\" After a few months, you'd have adopted\nlanguage for entire complex processes: \"Start landing sequence\" or \"prepare\nfor warp.\" This process would happen quite naturally, without any formal effort\nto build a shared glossary.\n\n[role=\"nobreakinside less_space\"]\n.This Is Not a DDD Book. You Should Read a DDD Book.\n*****************************************************************\n\nDomain-driven design, or DDD, popularized the concept of domain modeling,footnote:[\nDDD did not originate domain modeling. Eric Evans refers to the 2002 book _Object Design_\nby Rebecca Wirfs-Brock and Alan McKean  (Addison-Wesley Professional), which introduced responsibility-driven\ndesign, of which DDD is a special case dealing with the domain. But even that is\ntoo late, and OO enthusiasts will tell you to look further back to Ivar\nJacobson and Grady Booch; the term has been around since the\nmid-1980s.(((\"domain driven design (DDD)\")))]\nand it's been a hugely successful movement in transforming the way people\ndesign software by focusing on the core business domain. Many of the\narchitecture patterns that we cover in this book—including Entity, Aggregate,\nValue Object (see <<chapter_07_aggregate>>), and Repository (in\n<<chapter_02_repository,the next chapter>>)—come from the DDD tradition.\n\nIn a nutshell, DDD says that the most important thing about software is that it\nprovides a useful model of a problem.  If we get that model right, our\nsoftware delivers value and makes new things possible.\n\nIf we get the model wrong, it becomes an obstacle to be worked around. In this book,\nwe can show the basics of building a domain model, and building an architecture\naround it that leaves the model as free as possible from external constraints,\nso that it's easy to evolve and change.\n\nBut there's a lot more to DDD and to the processes, tools, and techniques for\ndeveloping a domain model. We hope to give you a taste of it, though,\nand cannot encourage you enough to go on and read a proper DDD book:\n\n* The original \"blue book,\" _Domain-Driven Design_ by Eric Evans (Addison-Wesley Professional)\n* The \"red book,\" _Implementing Domain-Driven Design_\n  by Vaughn Vernon (Addison-Wesley Professional)\n\n*****************************************************************\n\nSo it is in the mundane world of business. The terminology used by business\nstakeholders represents a distilled understanding of the domain model, where\ncomplex ideas and processes are boiled down to a single word or phrase.\n\nWhen we hear our business stakeholders using unfamiliar words, or using terms\nin a specific way, we should listen to understand the deeper meaning and encode\ntheir hard-won experience into our software.\n\nWe're going to use a real-world domain model throughout this book, specifically\na model from our current employment. MADE.com is a successful furniture\nretailer. We source our furniture from manufacturers all over the world and\nsell it across Europe.\n\nWhen you buy a sofa or a coffee table, we have to figure out how best\nto get your goods from Poland or China or Vietnam and into your living room.\n\nAt a high level, we have separate systems that are responsible for buying\nstock, selling stock to customers, and shipping goods to customers. A\nsystem in the middle needs to coordinate the process by allocating stock\nto a customer's orders; see <<allocation_context_diagram>>.\n\n[[allocation_context_diagram]]\n.Context diagram for the allocation service\nimage::images/apwp_0102.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0102]\n@startuml Allocation Context Diagram\n!include images/C4_Context.puml\nscale 2\n\nSystem(systema, \"Allocation\", \"Allocates stock to customer orders\")\n\nPerson(customer, \"Customer\", \"Wants to buy furniture\")\nPerson(buyer, \"Buying Team\", \"Needs to purchase furniture from suppliers\")\n\nSystem(procurement, \"Purchasing\", \"Manages workflow for buying stock from suppliers\")\nSystem(ecom, \"Ecommerce\", \"Sells goods online\")\nSystem(warehouse, \"Warehouse\", \"Manages workflow for shipping goods to customers\")\n\nRel(buyer, procurement, \"Uses\")\nRel(procurement, systema, \"Notifies about shipments\")\nRel(customer, ecom, \"Buys from\")\nRel(ecom, systema, \"Asks for stock levels\")\nRel(ecom, systema, \"Notifies about orders\")\nRel_R(systema, warehouse, \"Sends instructions to\")\nRel_U(warehouse, customer, \"Dispatches goods to\")\n\n@enduml\n----\n\nFor the purposes of this book, we're imagining that the business\ndecides to implement an exciting new way of allocating stock.  Until now, the\nbusiness has been presenting stock and lead times based on what is physically\navailable in the warehouse.  If and when the warehouse runs out, a product is\nlisted as \"out of stock\" until the next shipment arrives from the manufacturer.\n\nHere's the innovation: if we have a system that can keep track of all our shipments\nand when they're due to arrive, we can treat the goods on those ships as\nreal stock and part of our inventory, just with slightly longer lead times.\nFewer goods will appear to be out of stock, we'll sell more, and the business\ncan save money by keeping lower inventory in the domestic warehouse.\n\nBut allocating orders is no longer a trivial matter of decrementing a single\nquantity in the warehouse system. We need a more complex allocation mechanism.\nTime for some domain modeling.\n\n\n=== Exploring the Domain Language\n\n(((\"domain language\")))\n(((\"domain modeling\", \"domain language\")))\nUnderstanding the domain model takes time, and patience, and Post-it notes. We\nhave an initial conversation with our business experts and agree on a glossary\nand some rules for the first minimal version of the domain model. Wherever\npossible, we ask for concrete examples to illustrate each rule.\n\nWe make sure to express those rules in the business jargon (the _ubiquitous\nlanguage_ in DDD terminology). We choose memorable identifiers for our objects\nso that the examples are easier to talk about.\n\n<<allocation_notes,The following sidebar>> shows some notes we might have taken while having a\nconversation with our domain experts about allocation.\n\n[[allocation_notes]]\n.Some Notes on Allocation\n****\nA _product_ is identified by a _SKU_, pronounced \"skew,\" which is short for _stock-keeping unit_. _Customers_ place _orders_. An order is identified by an _order reference_\nand comprises multiple _order lines_, where each line has a _SKU_ and a _quantity_. For example:\n\n- 10 units of RED-CHAIR\n- 1 unit of TASTELESS-LAMP\n\nThe purchasing department orders small _batches_ of stock. A _batch_ of stock has a unique ID called a _reference_, a _SKU_, and a _quantity_.\n\nWe need to _allocate_ _order lines_ to _batches_. When we've allocated an\norder line to a batch, we will send stock from that specific batch to the\ncustomer's delivery address. When we allocate _x_ units of stock to a batch, the _available quantity_ is reduced by _x_. For example:\n\n- We have a batch of 20 SMALL-TABLE, and we allocate an order line for 2 SMALL-TABLE.\n- The batch should have 18 SMALL-TABLE remaining.\n\nWe can't allocate to a batch if the available quantity is less than the quantity of the order line. For example:\n\n- We have a batch of 1 BLUE-CUSHION, and an order line for 2 BLUE-CUSHION.\n- We should not be able to allocate the line to the batch.\n\nWe can't allocate the same line twice. For example:\n\n- We have a batch of 10 BLUE-VASE, and we allocate an order line for 2 BLUE-VASE.\n- If we allocate the order line again to the same batch, the batch should still\n  have an available quantity of 8.\n\nBatches have an _ETA_ if they are currently shipping, or they may be in _warehouse stock_. We allocate to warehouse stock in preference to shipment batches. We allocate to shipment batches in order of which has the earliest ETA.\n****\n\n=== Unit Testing Domain Models\n\n(((\"unit testing\", \"of domain models\", id=\"ix_UTDM\")))\n(((\"domain modeling\", \"unit testing domain models\", id=\"ix_dommodUT\")))\nWe're not going to show you how TDD works in this book, but we want to show you\nhow we would construct a model from this business conversation.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n******************************************************************************\nWhy not have a go at solving this problem yourself? Write a few unit tests to\nsee if you can capture the essence of these business rules in nice, clean\ncode (ideally without looking at the solution we came up with below!)\n\nYou'll find some https://github.com/cosmicpython/code/tree/chapter_01_domain_model_exercise[placeholder unit tests on GitHub], but you could just start from\nscratch, or combine/rewrite them however you like.\n\n//TODO: add test_cannot_allocate_same_line_twice ?\n//(EJ3): nice to have for completeness, but not necessary\n\n******************************************************************************\n\nHere's what one of our first tests might look like:\n\n[[first_test]]\n.A first test for allocation (test_batches.py)\n====\n[source,python]\n----\ndef test_allocating_to_a_batch_reduces_the_available_quantity():\n    batch = Batch(\"batch-001\", \"SMALL-TABLE\", qty=20, eta=date.today())\n    line = OrderLine(\"order-ref\", \"SMALL-TABLE\", 2)\n\n    batch.allocate(line)\n\n    assert batch.available_quantity == 18\n----\n====\n\nThe name of our unit test describes the behavior that we want to see from the\nsystem, and the names of the classes and variables that we use are taken from the\nbusiness jargon. We could show this code to our nontechnical coworkers, and\nthey would agree that this correctly describes the behavior of the system.\n\n[role=\"pagebreak-before\"]\nAnd here is a domain model that meets our requirements:\n\n[[domain_model_1]]\n.First cut of a domain model for batches (model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@dataclass(frozen=True)  #<1><2>\nclass OrderLine:\n    orderid: str\n    sku: str\n    qty: int\n\n\nclass Batch:\n    def __init__(self, ref: str, sku: str, qty: int, eta: Optional[date]):  #<2>\n        self.reference = ref\n        self.sku = sku\n        self.eta = eta\n        self.available_quantity = qty\n\n    def allocate(self, line: OrderLine):  #<3>\n        self.available_quantity -= line.qty\n----\n====\n\n<1> `OrderLine` is an immutable dataclass\n    with no behavior.footnote:[In previous Python versions, we\n    might have used a namedtuple. You could also check out Hynek Schlawack's\n    excellent https://pypi.org/project/attrs[attrs].]\n\n<2> We're not showing imports in most code listings, in an attempt to keep them\n    clean. We're hoping you can guess\n    that this came via `from dataclasses import dataclass`; likewise,\n    `typing.Optional` and `datetime.date`. If you want to double-check\n    anything, you can see the full working code for each chapter in\n    its branch (e.g.,\n    https://github.com/cosmicpython/code/tree/chapter_01_domain_model[chapter_01_domain_model]).\n\n<3> Type hints are still a matter of controversy in the Python world. For\n    domain models, they can sometimes help to clarify or document what the\n    expected arguments are, and people with IDEs are often grateful for them.\n    You may decide the price paid in terms of readability is too high.\n    (((\"type hints\")))\n\nOur implementation here is trivial:\na `Batch` just wraps an integer `available_quantity`,\nand we decrement that value on allocation.\nWe've written quite a lot of code just to subtract one number from another,\nbut we think that modeling our domain precisely will pay off.footnote:[\nOr perhaps you think there's not enough code?\nWhat about some sort of check that the SKU in the `OrderLine` matches `Batch.sku`?\nWe saved some thoughts on validation for <<appendix_validation>>.]\n\nLet's write some new failing tests:\n\n\n[[test_can_allocate]]\n.Testing logic for what we can allocate (test_batches.py)\n====\n[source,python]\n----\ndef make_batch_and_line(sku, batch_qty, line_qty):\n    return (\n        Batch(\"batch-001\", sku, batch_qty, eta=date.today()),\n        OrderLine(\"order-123\", sku, line_qty),\n    )\n\ndef test_can_allocate_if_available_greater_than_required():\n    large_batch, small_line = make_batch_and_line(\"ELEGANT-LAMP\", 20, 2)\n    assert large_batch.can_allocate(small_line)\n\ndef test_cannot_allocate_if_available_smaller_than_required():\n    small_batch, large_line = make_batch_and_line(\"ELEGANT-LAMP\", 2, 20)\n    assert small_batch.can_allocate(large_line) is False\n\ndef test_can_allocate_if_available_equal_to_required():\n    batch, line = make_batch_and_line(\"ELEGANT-LAMP\", 2, 2)\n    assert batch.can_allocate(line)\n\ndef test_cannot_allocate_if_skus_do_not_match():\n    batch = Batch(\"batch-001\", \"UNCOMFORTABLE-CHAIR\", 100, eta=None)\n    different_sku_line = OrderLine(\"order-123\", \"EXPENSIVE-TOASTER\", 10)\n    assert batch.can_allocate(different_sku_line) is False\n----\n====\n\nThere's nothing too unexpected here. We've refactored our test suite so that we\ndon't keep repeating the same lines of code to create a batch and a line for\nthe same SKU; and we've written four simple tests for a new method\n`can_allocate`. Again, notice that the names we use mirror the language of our\ndomain experts, and the examples we agreed upon are directly written into code.\n\nWe can implement this straightforwardly, too, by writing the `can_allocate`\nmethod of `Batch`:\n\n\n[[can_allocate]]\n.A new method in the model (model.py)\n====\n[source,python]\n----\n    def can_allocate(self, line: OrderLine) -> bool:\n        return self.sku == line.sku and self.available_quantity >= line.qty\n----\n====\n\nSo far, we can manage the implementation by just incrementing and decrementing\n`Batch.available_quantity`, but as we get into `deallocate()` tests, we'll be\nforced into a more intelligent solution:\n\n[role=\"pagebreak-before\"]\n[[test_deallocate_unallocated]]\n.This test is going to require a smarter model (test_batches.py)\n====\n[source,python]\n----\ndef test_can_only_deallocate_allocated_lines():\n    batch, unallocated_line = make_batch_and_line(\"DECORATIVE-TRINKET\", 20, 2)\n    batch.deallocate(unallocated_line)\n    assert batch.available_quantity == 20\n----\n====\n\nIn this test, we're asserting that deallocating a line from a batch has no effect\nunless the batch previously allocated the line. For this to work, our `Batch`\nneeds to understand which lines have been allocated. Let's look at the\nimplementation:\n\n\n[[domain_model_complete]]\n.The domain model now tracks allocations (model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass Batch:\n    def __init__(self, ref: str, sku: str, qty: int, eta: Optional[date]):\n        self.reference = ref\n        self.sku = sku\n        self.eta = eta\n        self._purchased_quantity = qty\n        self._allocations = set()  # type: Set[OrderLine]\n\n    def allocate(self, line: OrderLine):\n        if self.can_allocate(line):\n            self._allocations.add(line)\n\n    def deallocate(self, line: OrderLine):\n        if line in self._allocations:\n            self._allocations.remove(line)\n\n    @property\n    def allocated_quantity(self) -> int:\n        return sum(line.qty for line in self._allocations)\n\n    @property\n    def available_quantity(self) -> int:\n        return self._purchased_quantity - self.allocated_quantity\n\n    def can_allocate(self, line: OrderLine) -> bool:\n        return self.sku == line.sku and self.available_quantity >= line.qty\n\n----\n====\n\n// TODO: consider a diff here\n// TODO explain why harry refuses to use the inline type hints syntax\n\n<<model_diagram>> shows the model in UML.\n\n\n[[model_diagram]]\n.Our model in UML\nimage::images/apwp_0103.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0103, config=plantuml.cfg]\n@startuml\nscale 4\n\nleft to right direction\nhide empty members\n\nclass Batch {\n    reference\n    sku\n    eta\n    _purchased_quantity\n    _allocations\n}\n\nclass OrderLine {\n    orderid\n    sku\n    qty\n}\n\nBatch::_allocations o-- OrderLine\n----\n\n\nNow we're getting somewhere! A batch now keeps track of a set of allocated\n`OrderLine` objects. When we allocate, if we have enough available quantity, we\njust add to the set. Our `available_quantity` is now a calculated property:\npurchased quantity minus allocated quantity.\n\nYes, there's plenty more we could do. It's a little disconcerting that\nboth `allocate()` and `deallocate()` can fail silently, but we have the\nbasics.\n\nIncidentally, using a set for `._allocations` makes it simple for us\nto handle the last test, because items in a set are unique:\n\n\n[[last_test]]\n.Last batch test!  (test_batches.py)\n====\n[source,python]\n----\ndef test_allocation_is_idempotent():\n    batch, line = make_batch_and_line(\"ANGULAR-DESK\", 20, 2)\n    batch.allocate(line)\n    batch.allocate(line)\n    assert batch.available_quantity == 18\n----\n====\n\nAt the moment, it's probably a valid criticism to say that the domain model is\ntoo trivial to bother with DDD (or even object orientation!). In real life,\nany number of business rules and edge cases crop up: customers can ask for\ndelivery on specific future dates, which means we might not want to allocate\nthem to the earliest batch. Some SKUs aren't in batches, but ordered on\ndemand directly from suppliers, so they have different logic. Depending on the\ncustomer's location, we can allocate to only a subset of warehouses and shipments\nthat are in their region—except for some SKUs we're happy to deliver from a\nwarehouse in a different region if we're out of stock in the home region. And\nso on.  A real business in the real world knows how to pile on complexity faster\nthan we can show on the page!\n\nBut taking this simple domain model as a placeholder for something more\ncomplex, we're going to extend our simple domain model in the rest of the book\nand plug it into the real world of APIs and databases and spreadsheets. We'll\nsee how sticking rigidly to our principles of encapsulation and careful\nlayering will help us to avoid a ball of mud.\n\n\n[role=\"nobreakinside\"]\n.More Types for More Type Hints\n*******************************************************************************\n\n(((\"type hints\")))\nIf you really want to go to town with type hints, you could go so far as\nwrapping primitive types by using `typing.NewType`:\n\n[[too_many_types]]\n.Just taking it way too far, Bob\n====\n[source,python]\n[role=\"skip\"]\n----\nfrom dataclasses import dataclass\nfrom typing import NewType\n\nQuantity = NewType(\"Quantity\", int)\nSku = NewType(\"Sku\", str)\nReference = NewType(\"Reference\", str)\n...\n\nclass Batch:\n    def __init__(self, ref: Reference, sku: Sku, qty: Quantity):\n        self.sku = sku\n        self.reference = ref\n        self._purchased_quantity = qty\n----\n====\n\n\nThat would allow our type checker to make sure that we don't pass a `Sku` where a\n`Reference` is expected, for example.\n\nWhether you think this is wonderful or appalling is a matter of debate.footnote:[It is appalling. Please, please don't do this. —Harry]\n\n*******************************************************************************\n\n==== Dataclasses Are Great for Value Objects\n\n(((\"value objects\", \"using dataclasses for\")))\n(((\"dataclasses\", \"use for value objects\")))\n(((\"domain modeling\", \"unit testing domain models\", \"dataclasses for value objects\")))\nWe've used `line` liberally in the previous code listings, but what is a\nline? In our business language, an _order_ has multiple _line_ items, where\neach line has a SKU and a quantity. We can imagine that a simple YAML file\ncontaining order information might look like this:\n\n\n[[yaml_order_example]]\n.Order info as YAML\n====\n[source,yaml]\n[role=\"skip\"]\n----\nOrder_reference: 12345\nLines:\n  - sku: RED-CHAIR\n    qty: 25\n  - sku: BLU-CHAIR\n    qty: 25\n  - sku: GRN-CHAIR\n    qty: 25\n----\n====\n\n\n\nNotice that while an order has a _reference_ that uniquely identifies it, a\n_line_ does not. (Even if we add the order reference to the `OrderLine` class,\nit's not something that uniquely identifies the line itself.)\n\n(((\"value objects\", \"defined\")))\nWhenever we have a business concept that has data but no identity, we\noften choose to represent it using the _Value Object_ pattern. A _value object_ is any\ndomain object that is uniquely identified by the data it holds; we usually\nmake them immutable:\n\n// [SG] seems a bit odd to hear about value objects before any mention of entities.\n\n[[orderline_value_object]]\n.OrderLine is a value object\n====\n[source,python]\n[role=\"skip\"]\n----\n@dataclass(frozen=True)\nclass OrderLine:\n    orderid: OrderReference\n    sku: ProductReference\n    qty: Quantity\n----\n====\n\n(((\"namedtuples\", seealso=\"dataclasses\")))\nOne of the nice things that dataclasses (or namedtuples) give us is _value\nequality_, which is the fancy way of saying, \"Two lines with the same `orderid`,\n`sku`, and `qty` are equal.\"\n\n\n[[more_value_objects]]\n.More examples of value objects\n====\n[source,python]\n[role=\"skip\"]\n----\nfrom dataclasses import dataclass\nfrom typing import NamedTuple\nfrom collections import namedtuple\n\n@dataclass(frozen=True)\nclass Name:\n    first_name: str\n    surname: str\n\nclass Money(NamedTuple):\n    currency: str\n    value: int\n\nLine = namedtuple('Line', ['sku', 'qty'])\n\ndef test_equality():\n    assert Money('gbp', 10) == Money('gbp', 10)\n    assert Name('Harry', 'Percival') != Name('Bob', 'Gregory')\n    assert Line('RED-CHAIR', 5) == Line('RED-CHAIR', 5)\n----\n====\n\n(((\"value objects\", \"math with\")))\nThese value objects match our real-world intuition about how their values\nwork. It doesn't matter _which_ £10 note we're talking about, because they all\nhave the same value. Likewise, two names are equal if both the first and last\nnames match; and two lines are equivalent if they have the same customer order,\nproduct code, and quantity. We can still have complex behavior on a value\nobject, though. In fact, it's common to support operations on values; for\nexample, mathematical operators:\n\n\n[[value_object_maths_tests]]\n.Testing Math with value objects\n====\n[source,python]\n[role=\"skip\"]\n----\nfiver = Money('gbp', 5)\ntenner = Money('gbp', 10)\n\ndef can_add_money_values_for_the_same_currency():\n    assert fiver + fiver == tenner\n\ndef can_subtract_money_values():\n    assert tenner - fiver == fiver\n\ndef adding_different_currencies_fails():\n    with pytest.raises(ValueError):\n        Money('usd', 10) + Money('gbp', 10)\n\ndef can_multiply_money_by_a_number():\n    assert fiver * 5 == Money('gbp', 25)\n\ndef multiplying_two_money_values_is_an_error():\n    with pytest.raises(TypeError):\n        tenner * fiver\n----\n====\n\n\n(((\"magic methods\", \"&#x5f;&#x5f;add&#x5f;&#x5f;\", secondary-sortas=\"add\")))\n(((\"&#x5f;&#x5f;add&#x5f;&#x5f;magic method\", primary-sortas=\"add\")))\nTo get those tests to actually pass you'll need to start implementing some\nmagic methods on our `Money` class:\n\n[[value_object_maths]]\n.Implementing Math with value objects\n====\n[source,python]\n[role=\"skip\"]\n----\n@dataclass(frozen=True)\nclass Money:\n    currency: str\n    value: int\n\n    def __add__(self, other) -> Money:\n        if other.currency != self.currency:\n            raise ValueError(f\"Cannot add {self.currency} to {other.currency}\")\n        return Money(self.currency, self.value + other.value)\n----\n====\n\n\n\n\n==== Value Objects and Entities\n\n(((\"value objects\", \"and entities\", secondary-sortas=\"entities\")))\n(((\"domain modeling\", \"unit testing domain models\", \"value objects and entities\")))\nAn order line is uniquely identified by its order ID, SKU, and quantity; if we\nchange one of those values, we now have a new line. That's the definition of a\nvalue object: any object that is identified only by its data and doesn't have a\nlong-lived identity. What about a batch, though? That _is_ identified by a\nreference.\n\n(((\"entities\", \"defined\")))\nWe use the term _entity_ to describe a domain object that has long-lived\nidentity. On the previous page, we introduced a `Name` class as a value object.\nIf we take the name Harry Percival and change one letter, we have the new\n`Name` object Barry Percival.\n\nIt should be clear that Harry Percival is not equal to Barry Percival:\n\n\n[[test_equality]]\n.A name itself cannot change...\n====\n[source,python]\n[role=\"skip\"]\n----\ndef test_name_equality():\n    assert Name(\"Harry\", \"Percival\") != Name(\"Barry\", \"Percival\")\n----\n====\n\n\nBut what about Harry as a _person_? People do change their names, and their\nmarital status, and even their gender, but we continue to recognize them as the\nsame individual. That's because humans, unlike names, have a persistent\n_identity_:\n\n\n[[person_identity]]\n.But a person can!\n====\n[source,python]\n[role=\"skip\"]\n----\nclass Person:\n\n    def __init__(self, name: Name):\n        self.name = name\n\n\ndef test_barry_is_harry():\n    harry = Person(Name(\"Harry\", \"Percival\"))\n    barry = harry\n\n    barry.name = Name(\"Barry\", \"Percival\")\n\n    assert harry is barry and barry is harry\n----\n====\n\n\n\n(((\"entities\", \"identity equality\")))\n(((\"identity equality (entities)\")))\nEntities, unlike values, have _identity equality_. We can change their values,\nand they are still recognizably the same thing. Batches, in our example, are\nentities. We can allocate lines to a batch, or change the date that we expect\nit to arrive, and it will still be the same entity.\n\n(((\"equality operators, implementing on entities\")))\nWe usually make this explicit in code by implementing equality operators on\nentities:\n\n\n\n[[equality_on_batches]]\n.Implementing equality operators (model.py)\n====\n[source,python]\n----\nclass Batch:\n    ...\n\n    def __eq__(self, other):\n        if not isinstance(other, Batch):\n            return False\n        return other.reference == self.reference\n\n    def __hash__(self):\n        return hash(self.reference)\n----\n====\n\n(((\"magic methods\", \"&#x5f;&#x5f;eq&#x5f;&#x5f;\", secondary-sortas=\"eq\")))\n(((\"&#x5f;&#x5f;eq&#x5f;&#x5f;magic method\", primary-sortas=\"eq\")))\nPython's +++<code>__eq__</code>+++ magic method\ndefines the behavior of the class for the `==` operator.footnote:[The\n+++<code>__eq__</code>+++ method is pronounced \"dunder-EQ.\" By some, at least.]\n\n(((\"magic methods\", \"&#x5f;&#x5f;hash&#x5f;&#x5f;\", secondary-sortas=\"hash\")))\n(((\"&#x5f;&#x5f;hash&#x5f;&#x5f; magic method\", primary-sortas=\"hash\")))\nFor both entity and value objects, it's also worth thinking through how\n+++<code>__hash__</code>+++ will work.  It's the magic method Python uses to control the\nbehavior of objects when you add them to sets or use them as dict keys;\nyou can find more info https://oreil.ly/YUzg5[in the Python docs].\n\nFor value objects, the hash should be based on all the value attributes,\nand we should ensure that the objects are immutable.  We get this for\nfree by specifying `@frozen=True` on the dataclass.\n\nFor entities, the simplest option is to say that the hash is ++None++, meaning\nthat the object is not hashable and cannot, for example, be used in a set.\nIf for some reason you decide you really do want to use set or dict operations\nwith entities, the hash should be based on the attribute(s), such as\n`.reference`, that defines the entity's unique identity over time. You should\nalso try to somehow make _that_ attribute read-only.\n\nWARNING: This is tricky territory; you shouldn't modify +++<code>__hash__</code>+++\n    without also modifying +++<code>__eq__</code>+++.  If you're not sure what\n    you're doing, further reading is suggested.\n    https://oreil.ly/vxkgX[\"Python Hashes and Equality\"] by our tech reviewer\n    Hynek Schlawack is a good place to start.\n    (((\"unit testing\", \"of domain models\", startref=\"ix_UTDM\")))\n    (((\"domain modeling\", \"unit testing domain models\", startref=\"ix_dommodUT\")))\n\n\n\n=== Not Everything Has to Be an Object: A Domain Service Function\n\n(((\"domain services\")))\n(((\"domain modeling\", \"functions for domain services\", id=\"ix_dommodfnc\")))\nWe've made a model to represent batches, but what we actually need\nto do is allocate order lines against a specific set of batches that\nrepresent all our stock.\n\n[quote, Eric Evans, Domain-Driven Design]\n____\nSometimes, it just isn't a thing.\n____\n\n(((\"service-layer services vs. domain services\")))\nEvans discusses the idea of Domain Service\noperations that don't have a natural home in an entity or value\nobject.footnote:[Domain services are not the same thing as the services from\nthe <<chapter_04_service_layer,service layer>>, although they are\noften closely related. A domain service represents a business concept or\nprocess, whereas a service-layer service represents a use case for your\napplication. Often the service layer will call a domain service.] A\nthing that allocates an order line, given a set of batches, sounds a lot like a\nfunction, and we can take advantage of the fact that Python is a multiparadigm\nlanguage and just make it a function.\n(((\"domain services\", \"function for\")))\n\nLet's see how we might test-drive such a function:\n\n\n[[test_allocate]]\n.Testing our domain service (test_allocate.py)\n====\n[source,python]\n----\ndef test_prefers_current_stock_batches_to_shipments():\n    in_stock_batch = Batch(\"in-stock-batch\", \"RETRO-CLOCK\", 100, eta=None)\n    shipment_batch = Batch(\"shipment-batch\", \"RETRO-CLOCK\", 100, eta=tomorrow)\n    line = OrderLine(\"oref\", \"RETRO-CLOCK\", 10)\n\n    allocate(line, [in_stock_batch, shipment_batch])\n\n    assert in_stock_batch.available_quantity == 90\n    assert shipment_batch.available_quantity == 100\n\n\ndef test_prefers_earlier_batches():\n    earliest = Batch(\"speedy-batch\", \"MINIMALIST-SPOON\", 100, eta=today)\n    medium = Batch(\"normal-batch\", \"MINIMALIST-SPOON\", 100, eta=tomorrow)\n    latest = Batch(\"slow-batch\", \"MINIMALIST-SPOON\", 100, eta=later)\n    line = OrderLine(\"order1\", \"MINIMALIST-SPOON\", 10)\n\n    allocate(line, [medium, earliest, latest])\n\n    assert earliest.available_quantity == 90\n    assert medium.available_quantity == 100\n    assert latest.available_quantity == 100\n\n\ndef test_returns_allocated_batch_ref():\n    in_stock_batch = Batch(\"in-stock-batch-ref\", \"HIGHBROW-POSTER\", 100, eta=None)\n    shipment_batch = Batch(\"shipment-batch-ref\", \"HIGHBROW-POSTER\", 100, eta=tomorrow)\n    line = OrderLine(\"oref\", \"HIGHBROW-POSTER\", 10)\n    allocation = allocate(line, [in_stock_batch, shipment_batch])\n    assert allocation == in_stock_batch.reference\n----\n====\n\n(((\"functions\", \"for domain services\")))\nAnd our service might look like this:\n\n\n[[domain_service]]\n.A standalone function for our domain service (model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef allocate(line: OrderLine, batches: List[Batch]) -> str:\n    batch = next(b for b in sorted(batches) if b.can_allocate(line))\n    batch.allocate(line)\n    return batch.reference\n----\n====\n\n==== Python's Magic Methods Let Us Use Our Models with Idiomatic Python\n\n(((\"&#x5f;&#x5f;gt&#x5f;&#x5f; magic method\", primary-sortas=\"gt\")))\n(((\"magic methods\", \"allowing use of domain model with idiomatic Python\")))\nYou may or may not like the use of `next()` in the preceding code, but we're pretty\nsure you'll agree that being able to use `sorted()` on our list of\nbatches is nice, idiomatic Python.\n\nTo make it work, we implement +++<code>__gt__</code>+++ on our domain model:\n\n\n\n[[dunder_gt]]\n.Magic methods can express domain semantics (model.py)\n====\n[source,python]\n----\nclass Batch:\n    ...\n\n    def __gt__(self, other):\n        if self.eta is None:\n            return False\n        if other.eta is None:\n            return True\n        return self.eta > other.eta\n----\n====\n\nThat's lovely.\n\n\n==== Exceptions Can Express Domain Concepts Too\n\n(((\"domain exceptions\")))\n(((\"exceptions\", \"expressing domain concepts\")))\nWe have one final concept to cover: exceptions can be used to express domain\nconcepts too. In our conversations with domain experts, we've learned about the\npossibility that an order cannot be allocated because we are _out of stock_,\nand we can capture that by using a _domain exception_:\n\n\n[[test_out_of_stock]]\n.Testing out-of-stock exception (test_allocate.py)\n====\n[source,python]\n----\ndef test_raises_out_of_stock_exception_if_cannot_allocate():\n    batch = Batch(\"batch1\", \"SMALL-FORK\", 10, eta=today)\n    allocate(OrderLine(\"order1\", \"SMALL-FORK\", 10), [batch])\n\n    with pytest.raises(OutOfStock, match=\"SMALL-FORK\"):\n        allocate(OrderLine(\"order2\", \"SMALL-FORK\", 1), [batch])\n----\n====\n\n\n[role=\"nobreakinside\"]\n.Domain Modeling Recap\n*****************************************************************\nDomain modeling::\n    This is the part of your code that is closest to the business,\n    the most likely to change, and the place where you deliver the\n    most value to the business. Make it easy to understand and modify.\n    (((\"domain modeling\", startref=\"ix_dommod\")))\n\nDistinguish entities from value objects::\n    A value object is defined by its attributes. It's usually best\n    implemented as an immutable type. If you change an attribute on\n    a Value Object, it represents a different object. In contrast,\n    an entity has attributes that may vary over time and it will still be the\n    same entity. It's important to define what _does_ uniquely identify\n    an entity (usually some sort of name or reference field).\n    (((\"entities\", \"value objects versus\")))\n    (((\"value objects\", \"entities versus\")))\n\nNot everything has to be an object::\n    Python is a multiparadigm language, so let the \"verbs\" in your\n    code be functions. For every `FooManager`, `BarBuilder`, or `BazFactory`,\n    there's often a more expressive and readable `manage_foo()`, `build_bar()`,\n    or `get_baz()` waiting to happen.\n    (((\"functions\")))\n\nThis is the time to apply your best OO design principles::\n    Revisit the SOLID principles and all the other good heuristics like \"has a versus is-a,\"\n    \"prefer composition over inheritance,\" and so on.\n    (((\"object-oriented design principles\")))\n\nYou'll also want to think about consistency boundaries and aggregates::\n    But that's a topic for <<chapter_07_aggregate>>.\n\n*****************************************************************\n\nWe won't bore you too much with the implementation, but the main thing\nto note is that we take care in naming our exceptions in the ubiquitous\nlanguage, just as we do our entities, value objects, and services:\n\n\n[[out_of_stock]]\n.Raising a domain exception (model.py)\n====\n[source,python]\n----\nclass OutOfStock(Exception):\n    pass\n\n\ndef allocate(line: OrderLine, batches: List[Batch]) -> str:\n    try:\n        batch = next(\n        ...\n    except StopIteration:\n        raise OutOfStock(f\"Out of stock for sku {line.sku}\")\n----\n====\n\n\n<<maps_chapter_01_withtext>> is a visual representation of where we've ended up.\n\n[[maps_chapter_01_withtext]]\n.Our domain model at the end of the chapter\nimage::images/apwp_0104.png[]\n\n(((\"domain modeling\", \"functions for domain services\", startref=\"ix_dommodfnc\")))\nThat'll probably do for now! We have a domain service that we can use for our\nfirst use case. But first we'll need a database...\n"
        },
        {
          "name": "chapter_02_repository.asciidoc",
          "type": "blob",
          "size": 36.60546875,
          "content": "[[chapter_02_repository]]\n== Repository Pattern\n\nIt's time to make good on our promise to use the dependency inversion principle as\na way of decoupling our core logic from infrastructural concerns.\n\n(((\"storage\", seealso=\"repositories; Repository pattern\")))\n(((\"Repository pattern\")))\n(((\"data storage, Repository pattern and\")))\nWe'll introduce the _Repository_ pattern, a simplifying abstraction over data storage,\nallowing us to decouple our model layer from the data layer. We'll present a\nconcrete example of how this simplifying abstraction makes our system more\ntestable by hiding the complexities of the database.\n\n<<maps_chapter_02>> shows a little preview of what we're going to build:\na `Repository` object that sits between our domain model and the database.\n\n[[maps_chapter_02]]\n.Before and after the Repository pattern\nimage::images/apwp_0201.png[]\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_02_repository branch https://oreil.ly/6STDu[on GitHub].\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_02_repository\n# or to code along, checkout the previous chapter:\ngit checkout chapter_01_domain_model\n----\n====\n\n\n=== Persisting Our Domain Model\n\n(((\"domain model\", \"persisting\")))\nIn <<chapter_01_domain_model>> we built a simple domain model that can allocate orders\nto batches of stock. It's easy for us to write tests against this code because\nthere aren't any dependencies or infrastructure to set up. If we needed to run\na database or an API and create test data, our tests would be harder to write\nand maintain.\n\nSadly, at some point we'll need to put our perfect little model in the hands of\nusers and contend with the real world of spreadsheets and web\nbrowsers and race conditions. For the next few chapters we're going to look at\nhow we can connect our idealized domain model to external state.\n\n(((\"minimum viable product\")))\nWe expect to be working in an agile manner, so our priority is to get to a\nminimum viable product as quickly as possible. In our case, that's going to be\na web API. In a real project, you might dive straight in with some end-to-end\ntests and start plugging in a web framework, test-driving things outside-in.\n\nBut we know that, no matter what, we're going to need some form of persistent\nstorage, and this is a textbook, so we can allow ourselves a tiny bit more\nbottom-up development and start to think about storage and databases.\n\n\n=== Some Pseudocode: What Are We Going to Need?\n\nWhen we build our first API endpoint, we know we're going to have\nsome code that looks more or less like the following.\n\n[[api_endpoint_pseudocode]]\n.What our first API endpoint will look like\n====\n[role=\"skip\"]\n[source,python]\n----\n@flask.route.gubbins\ndef allocate_endpoint():\n    # extract order line from request\n    line = OrderLine(request.params, ...)\n    # load all batches from the DB\n    batches = ...\n    # call our domain service\n    allocate(line, batches)\n    # then save the allocation back to the database somehow\n    return 201\n----\n====\n\nNOTE: We've used Flask because it's lightweight, but you don't need\n    to be a Flask user to understand this book. In fact, we'll show you how\n    to make your choice of framework a minor detail.\n    (((\"Flask framework\")))\n\nWe'll need a way to retrieve batch info from the database and instantiate our domain\nmodel objects from it, and we'll also need a way of saving them back to the\ndatabase.\n\n_What? Oh, \"gubbins\" is a British word for \"stuff.\" You can just ignore that. It's pseudocode, OK?_\n\n\n=== Applying the DIP to Data Access\n\n(((\"layered architecture\")))\n(((\"data access, applying dependency inversion principle to\")))\nAs mentioned in the <<introduction, introduction>>, a layered architecture is a common\n approach to structuring a system that has a UI, some logic, and a database (see\n<<layered_architecture2>>).\n\n[role=\"width-75\"]\n[[layered_architecture2]]\n.Layered architecture\nimage::images/apwp_0202.png[]\n\n\nDjango's Model-View-Template structure is closely related, as is\nModel-View-Controller (MVC). In any case, the aim is to keep the layers\nseparate (which is a good thing), and to have each layer depend only on the one\nbelow it.\n\n(((\"dependencies\", \"none in domain model\")))\nBut we want our domain model to have __no dependencies whatsoever__.footnote:[\nI suppose we mean \"no stateful dependencies.\" Depending on a helper library is\nfine; depending on an ORM or a web framework is not.]\nWe don't want infrastructure concerns bleeding over into our domain model and\nslowing our unit tests or our ability to make changes.\n\n(((\"onion architecture\")))\nInstead, as discussed in the introduction, we'll think of our model as being on the\n\"inside,\" and dependencies flowing inward to it; this is what people sometimes call\n_onion architecture_ (see <<onion_architecture>>).\n\n[role=\"width-75\"]\n[[onion_architecture]]\n.Onion architecture\nimage::images/apwp_0203.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0203]\n+------------------------+\n|   Presentation Layer   |\n+------------------------+\n           |\n           V\n+--------------------------------------------------+\n|                  Domain Model                    |\n+--------------------------------------------------+\n                                        ^\n                                        |\n                             +---------------------+\n                             |    Database Layer   |\n                             +---------------------+\n----\n\n[role=\"nobreakinside less_space\"]\n.Is This Ports and Adapters?\n****\nIf you've been reading about architectural patterns, you may be asking\nyourself questions like this:\n\n____\n_Is this ports and adapters? Or is it hexagonal architecture? Is that the same as onion architecture? What about the clean architecture? What's a port, and what's an adapter? Why do you people have so many words for the same thing?_\n____\n\n(((\"dependency inversion principle\")))\n(((\"Seemann, Mark, blog post\")))\nAlthough some people like to nitpick over the differences, all these are\npretty much names for the same thing, and they all boil down to the\ndependency inversion principle: high-level modules (the domain) should\nnot depend on low-level ones (the infrastructure).footnote:[Mark Seemann has\nhttps://oreil.ly/LpFS9[an excellent blog post] on the topic.]\n\nWe'll get into some of the nitty-gritty around \"depending on abstractions,\"\nand whether there is a Pythonic equivalent of interfaces,\n<<depend_on_abstractions,later in the book>>. See also <<what_is_a_port_and_what_is_an_adapter>>.\n****\n\n\n=== Reminder: Our Model\n\n(((\"domain model\", id=\"ix_domod\")))\nLet's remind ourselves of our domain model (see <<model_diagram_reminder>>):\nan allocation is the concept of linking an `OrderLine` to a `Batch`.  We're\nstoring the allocations as a collection on our `Batch` object.\n\n[[model_diagram_reminder]]\n.Our model\nimage::images/apwp_0103.png[]\n// see chapter_01_domain_model for diagram source\n\nLet's see how we might translate this to a relational database.\n\n\n==== The \"Normal\" ORM Way: Model Depends on ORM\n\n(((\"SQL\", \"generating for domain model objects\")))\n(((\"domain model\", \"translating to relational database\", \"normal ORM way, model depends on ORM\")))\nThese days, it's unlikely that your team members are hand-rolling their own SQL queries.\nInstead, you're almost certainly using some kind of framework to generate\nSQL for you based on your model objects.\n\n(((\"object-relational mappers (ORMs)\")))\nThese frameworks are called _object-relational mappers_ (ORMs) because they exist to\nbridge the conceptual gap between the world of objects and domain modeling and\nthe world of databases and relational algebra.\n\n(((\"persistence ignorance\")))\nThe most important thing an ORM gives us is _persistence ignorance_: the idea\nthat our fancy domain model doesn't need to know anything about how data is\nloaded or persisted. This helps keep our domain clean of direct dependencies\non particular database technologies.footnote:[In this sense, using an ORM is\nalready an example of the DIP. Instead of depending on hardcoded SQL, we depend\non an abstraction, the ORM. But that's not enough for us—not in this book!]\n\n(((\"object-relational mappers (ORMs)\", \"SQLAlchemy, model depends on ORM\")))\n(((\"SQLAlchemy\", \"declarative syntax, model depends on ORM\")))\nBut if you follow the typical SQLAlchemy tutorial, you'll end up with something\nlike this:\n\n\n[[typical_sqlalchemy_example]]\n.SQLAlchemy \"declarative\" syntax, model depends on ORM (orm.py)\n====\n[role=\"skip\"]\n[source,python]\n----\nfrom sqlalchemy import Column, ForeignKey, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship\n\nBase = declarative_base()\n\nclass Order(Base):\n    id = Column(Integer, primary_key=True)\n\nclass OrderLine(Base):\n    id = Column(Integer, primary_key=True)\n    sku = Column(String(250))\n    qty = Integer(String(250))\n    order_id = Column(Integer, ForeignKey('order.id'))\n    order = relationship(Order)\n\nclass Allocation(Base):\n    ...\n----\n====\n\nYou don't need to understand SQLAlchemy to see that our pristine model is now\nfull of dependencies on the ORM and is starting to look ugly as hell besides.\nCan we really say this model is ignorant of the database? How can it be\nseparate from storage concerns when our model properties are directly coupled\nto database columns?\n\n[role=\"nobreakinside less_space\"]\n.Django's ORM Is Essentially the Same, but More Restrictive\n****\n\n(((\"Django\", \"ORM example\")))\n(((\"object-relational mappers (ORMs)\", \"Django ORM example\")))\nIf you're more used to Django, the preceding \"declarative\" SQLAlchemy snippet\ntranslates to something like this:\n\n[[django_orm_example]]\n.Django ORM example\n====\n[source,python]\n[role=\"skip\"]\n----\nclass Order(models.Model):\n    pass\n\nclass OrderLine(models.Model):\n    sku = models.CharField(max_length=255)\n    qty = models.IntegerField()\n    order = models.ForeignKey(Order)\n\nclass Allocation(models.Model):\n    ...\n----\n====\n\nThe point is the same--our model classes inherit directly from ORM\nclasses, so our model depends on the ORM.  We want it to be the other\nway around.\n\nDjango doesn't provide an equivalent for SQLAlchemy's classical mapper,\nbut see <<appendix_django>> for examples of how to apply dependency\ninversion and the Repository pattern to Django.\n\n****\n\n\n\n==== Inverting the Dependency: ORM Depends on Model\n\n(((\"mappers\")))\n(((\"classical mapping\")))\n(((\"SQLAlchemy\", \"explicit ORM mapping with SQLAlchemy Table objects\")))\n(((\"dependency inversion principle\", \"ORM depends on the data model\")))\n(((\"domain model\", \"translating to relational database\", \"ORM depends on the model\")))\n(((\"object-relational mappers (ORMs)\", \"ORM depends on the data model\")))\nWell, thankfully, that's not the only way to use SQLAlchemy.  The alternative is\nto define your schema separately, and to define an explicit _mapper_ for how to convert\nbetween the schema and our domain model, what SQLAlchemy calls a\nhttps://oreil.ly/ZucTG[classical mapping]:\n\n[role=\"nobreakinside less_space\"]\n[[sqlalchemy_classical_mapper]]\n.Explicit ORM mapping with SQLAlchemy Table objects (orm.py)\n====\n[source,python]\n----\nfrom sqlalchemy.orm import mapper, relationship\n\nimport model  #<1>\n\n\nmetadata = MetaData()\n\norder_lines = Table(  #<2>\n    \"order_lines\",\n    metadata,\n    Column(\"id\", Integer, primary_key=True, autoincrement=True),\n    Column(\"sku\", String(255)),\n    Column(\"qty\", Integer, nullable=False),\n    Column(\"orderid\", String(255)),\n)\n\n...\n\ndef start_mappers():\n    lines_mapper = mapper(model.OrderLine, order_lines)  #<3>\n----\n====\n\n<1> The ORM imports (or \"depends on\" or \"knows about\") the domain model, and\n    not the other way around.\n\n<2> We define our database tables and columns by using SQLAlchemy's\n    abstractions.footnote:[Even in projects where we don't use an ORM, we\n    often use SQLAlchemy alongside Alembic to declaratively create\n    schemas in Python and to manage migrations, connections,\n    and sessions.]\n\n<3> When we call the `mapper` function, SQLAlchemy does its magic to bind\n    our domain model classes to the various tables we've defined.\n\n// TODO: replace mapper() with registry.map_imperatively()\n// https://docs.sqlalchemy.org/en/14/orm/mapping_styles.html?highlight=sqlalchemy#orm-imperative-mapping\n\nThe end result will be that, if we call `start_mappers`, we will be able to\neasily load and save domain model instances from and to the database. But if\nwe never call that function, our domain model classes stay blissfully\nunaware of the database.\n\n// IDEA: add a note about mapper being maybe-deprecated, but link to\n// the mailing list post where mike shows how to reimplement it manually.\n\nThis gives us all the benefits of SQLAlchemy, including the ability to use\n`alembic` for migrations, and the ability to transparently query using our\ndomain classes, as we'll see.\n\n(((\"object-relational mappers (ORMs)\", \"ORM depends on the data model\", \"testing the ORM\")))\nWhen you're first trying to build your ORM config, it can be useful to write\ntests for it, as in the following example:\n\n\n[[orm_tests]]\n.Testing the ORM directly (throwaway tests) (test_orm.py)\n====\n[source,python]\n----\ndef test_orderline_mapper_can_load_lines(session):  #<1>\n    session.execute(\n        \"INSERT INTO order_lines (orderid, sku, qty) VALUES \"\n        '(\"order1\", \"RED-CHAIR\", 12),'\n        '(\"order1\", \"RED-TABLE\", 13),'\n        '(\"order2\", \"BLUE-LIPSTICK\", 14)'\n    )\n    expected = [\n        model.OrderLine(\"order1\", \"RED-CHAIR\", 12),\n        model.OrderLine(\"order1\", \"RED-TABLE\", 13),\n        model.OrderLine(\"order2\", \"BLUE-LIPSTICK\", 14),\n    ]\n    assert session.query(model.OrderLine).all() == expected\n\n\ndef test_orderline_mapper_can_save_lines(session):\n    new_line = model.OrderLine(\"order1\", \"DECORATIVE-WIDGET\", 12)\n    session.add(new_line)\n    session.commit()\n\n    rows = list(session.execute('SELECT orderid, sku, qty FROM \"order_lines\"'))\n    assert rows == [(\"order1\", \"DECORATIVE-WIDGET\", 12)]\n----\n====\n\n<1> If you haven't used pytest, the `session` argument to this test needs\n    explaining. You don't need to worry about the details of pytest or its\n    fixtures for the purposes of this book, but the short explanation is that\n    you can define common dependencies for your tests as \"fixtures,\" and\n    pytest will inject them to the tests that need them by looking at their\n    function arguments. In this case, it's a SQLAlchemy database session.\n    (((\"pytest\", \"session argument\")))\n\n////\n[SG] I set up the conftest to have a session, and could only get the tests to\nwork if I dropped the (frozen=True) on the OrderLine dataclass, otherwise I\nwould get dataclasses.FrozenInstanceError: cannot assign to field\n'_sa_instance_state' I feel I am having to work quite hard to follow along ;-(.\n\nIs not spelling everything out a deliberate tactic to make the reader learn?\n////\n\nYou probably wouldn't keep these tests around--as you'll see shortly, once\nyou've taken the step of inverting the dependency of ORM and domain model, it's\nonly a small additional step to implement another abstraction called the\nRepository pattern, which will be easier to write tests against and will\nprovide a simple interface for faking out later in tests.\n\nBut we've already achieved our objective of inverting the traditional\ndependency: the domain model stays \"pure\" and free from infrastructure\nconcerns. We could throw away SQLAlchemy and use a different ORM, or a totally\ndifferent persistence system, and the domain model doesn't need to change at\nall.\n\n\nDepending on what you're doing in your domain model, and especially if you\nstray far from the OO paradigm, you may find it increasingly hard to get the\nORM to produce the exact behavior you need, and you may need to modify your\ndomain model.footnote:[Shout-out to the amazingly helpful SQLAlchemy\nmaintainers, and to Mike Bayer in particular.] As so often happens with\narchitectural decisions, you'll need to consider a trade-off. As the\nZen of Python says, \"Practicality beats purity!\"\n\n(((\"SQLAlchemy\", \"using directly in API endpoint\")))\nAt this point, though, our API endpoint might look something like\nthe following, and we could get it to work just fine:\n\n[[api_endpoint_with_session]]\n.Using SQLAlchemy directly in our API endpoint\n====\n[role=\"skip\"]\n[source,python]\n----\n@flask.route.gubbins\ndef allocate_endpoint():\n    session = start_session()\n\n    # extract order line from request\n    line = OrderLine(\n        request.json['orderid'],\n        request.json['sku'],\n        request.json['qty'],\n    )\n\n    # load all batches from the DB\n    batches = session.query(Batch).all()\n\n    # call our domain service\n    allocate(line, batches)\n\n    # save the allocation back to the database\n    session.commit()\n\n    return 201\n----\n====\n\n////\n[SG] from what I remember of the previous code if none of the batches can_allocate then this\nallocate(line, batches) will raise OutOfStock.  Is it OK to let this bubble up?  Should you\nadd a try finally to close the session\n////\n\n=== Introducing the Repository Pattern\n\n(((\"Repository pattern\", id=\"ix_Repo\")))\n(((\"domain model\", startref=\"ix_domod\")))\nThe _Repository_ pattern is an abstraction over persistent storage. It hides the\nboring details of data access by pretending that all of our data is in memory.\n\nIf we had infinite memory in our laptops, we'd have no need for clumsy databases.\nInstead, we could just use our objects whenever we liked. What would that look\nlike?\n\n[[all_my_data]]\n.You have to get your data from somewhere\n====\n[role=\"skip\"]\n[source,python]\n----\nimport all_my_data\n\ndef create_a_batch():\n    batch = Batch(...)\n    all_my_data.batches.add(batch)\n\ndef modify_a_batch(batch_id, new_quantity):\n    batch = all_my_data.batches.get(batch_id)\n    batch.change_initial_quantity(new_quantity)\n\n----\n====\n\n\nEven though our objects are in memory, we need to put them _somewhere_ so we can\nfind them again. Our in-memory data would let us add new objects, just like a\nlist or a set. Because the objects are in memory, we never need to call a\n`.save()` method; we just fetch the object we care about and modify it in memory.\n\n\n==== The Repository in the Abstract\n\n(((\"Repository pattern\", \"simplest possible repository\")))\n(((\"Unit of Work pattern\")))\nThe simplest repository has just two methods: `add()` to put a new item in the\nrepository, and `get()` to return a previously added item.footnote:[\nYou may be thinking, \"What about `list` or `delete` or `update`?\" However, in an\nideal world, we modify our model objects one at a time, and delete is\nusually handled as a soft-delete—i.e., `batch.cancel()`. Finally, update is\ntaken care of by the Unit of Work pattern, as you'll see in <<chapter_06_uow>>.]\nWe stick rigidly to using these methods for data access in our domain and our\nservice layer. This self-imposed simplicity stops us from coupling our domain\nmodel to the database.\n\n(((\"abstract base classes (ABCs)\", \"ABC for the repository\")))\nHere's what an abstract base class (ABC) for our repository would look like:\n\n[[abstract_repo]]\n.The simplest possible repository (repository.py)\n====\n[source,python]\n----\nclass AbstractRepository(abc.ABC):\n    @abc.abstractmethod  #<1>\n    def add(self, batch: model.Batch):\n        raise NotImplementedError  #<2>\n\n    @abc.abstractmethod\n    def get(self, reference) -> model.Batch:\n        raise NotImplementedError\n----\n====\n\n\n<1> Python tip: `@abc.abstractmethod` is one of the only things that makes\n    ABCs actually \"work\" in Python. Python will refuse to let you instantiate\n    a class that does not implement all the `abstractmethods` defined in its\n    parent class.footnote:[To really reap the benefits of ABCs (such as they\n    may be), be running helpers like `pylint` and `mypy`.]\n    (((\"@abc.abstractmethod\")))\n    (((\"abstract methods\")))\n\n<2> `raise NotImplementedError` is nice, but it's neither necessary nor sufficient.\n    In fact, your abstract methods can have real behavior that subclasses\n    can call out to, if you really want.\n\n[role=\"pagebreak-before less_space\"]\n.Abstract Base Classes, Duck Typing, and Protocols\n*******************************************************************************\n\n(((\"abstract base classes (ABCs)\", \"using duck typing and protocols instead of\")))\n(((\"protocols, abstract base classes, duck typing, and\")))\nWe're using abstract base classes in this book for didactic reasons: we hope\nthey help explain what the interface of the repository abstraction is.\n\n(((\"duck typing\")))\nIn real life, we've sometimes found ourselves deleting ABCs from our production\ncode, because Python makes it too easy to ignore them, and they end up\nunmaintained and, at worst, misleading. In practice we often just rely on\nPython's duck typing to enable abstractions. To a Pythonista, a repository is\n_any_ object that has pass:[<code>add(<em>thing</em>)</code>] and pass:[<code>get(<em>id</em>)</code>] methods.\n\n(((\"PEP 544 protocols\")))\nAn alternative to look into is https://oreil.ly/q9EPC[PEP 544 protocols].\nThese give you typing without the possibility of inheritance, which \"prefer\ncomposition over inheritance\" fans will particularly like.\n\n*******************************************************************************\n\n\n==== What Is the Trade-Off?\n\n\n[quote, Rich Hickey]\n____\nYou know they say economists know the price of everything and the value of\nnothing?  Well, programmers know the benefits of everything and the trade-offs\nof nothing.\n____\n\n(((\"Repository pattern\", \"trade-offs\")))\nWhenever we introduce an architectural pattern in this book, we'll always\nask, \"What do we get for this?  And what does it cost us?\"\n\nUsually, at the very least, we'll be introducing an extra layer of abstraction,\nand although we may hope it will reduce complexity overall, it does add\ncomplexity locally, and it has a cost in terms of the raw numbers of moving parts and\nongoing maintenance.\n\nThe Repository pattern is probably one of the easiest choices in the book, though,\nif you're already heading down the DDD and dependency inversion route.  As far\nas our code is concerned, we're really just swapping the SQLAlchemy abstraction\n(`session.query(Batch)`) for a different one (`batches_repo.get`) that we\ndesigned.\n\nWe will have to write a few lines of code in our repository class each time we\nadd a new domain object that we want to retrieve, but in return we get a\nsimple abstraction over our storage layer, which we control. The Repository pattern would make\nit easy to make fundamental changes to the way we store things (see\n<<appendix_csvs>>), and as we'll see, it is easy to fake out for unit tests.\n\n(((\"domain driven design (DDD)\", \"Repository pattern and\")))\nIn addition, the Repository pattern is so common in the DDD world that, if you\ndo collaborate with programmers who have come to Python from the Java and C#\nworlds, they're likely to recognize it. <<repository_pattern_diagram>> illustrates the pattern.\n\n[role=\"width-60\"]\n[[repository_pattern_diagram]]\n.Repository pattern\nimage::images/apwp_0205.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0205]\n  +-----------------------------+\n  |      Application Layer      |\n  +-----------------------------+\n                 |^\n                 ||          /------------------\\\n                 ||----------|   Domain Model   |\n                 ||          |      Objects     |\n                 ||          \\------------------/\n                 V|\n  +------------------------------+\n  |          Repository          |\n  +------------------------------+\n                 |\n                 V\n  +------------------------------+\n  |        Database Layer        |\n  +------------------------------+\n----\n\n\n(((\"Repository pattern\", \"testing the  repository with saving an object\")))\n(((\"SQL\", \"repository test for saving an object\")))\nAs always, we start with a test. This would probably be classified as an\nintegration test, since we're checking that our code (the repository) is\ncorrectly integrated with the database; hence, the tests tend to mix\nraw SQL with calls and assertions on our own code.\n\nTIP: Unlike the ORM tests from earlier, these tests are good candidates for\n    staying part of your codebase longer term, particularly if any parts of\n    your domain model mean the object-relational map is nontrivial.\n\n\n[[repo_test_save]]\n.Repository test for saving an object (test_repository.py)\n====\n[source,python]\n----\ndef test_repository_can_save_a_batch(session):\n    batch = model.Batch(\"batch1\", \"RUSTY-SOAPDISH\", 100, eta=None)\n\n    repo = repository.SqlAlchemyRepository(session)\n    repo.add(batch)  #<1>\n    session.commit()  #<2>\n\n    rows = session.execute(  #<3>\n        'SELECT reference, sku, _purchased_quantity, eta FROM \"batches\"'\n    )\n    assert list(rows) == [(\"batch1\", \"RUSTY-SOAPDISH\", 100, None)]\n----\n====\n\n<1> `repo.add()` is the method under test here.\n\n<2> We keep the `.commit()` outside of the repository and make\n    it the responsibility of the caller. There are pros and cons for\n    this; some of our reasons will become clearer when we get to\n    <<chapter_06_uow>>.\n\n<3> We use the raw SQL to verify that the right data has been saved.\n\n(((\"SQL\", \"repository test for retrieving complex object\")))\n(((\"Repository pattern\", \"testing the repository with retrieving a complex object\")))\nThe next test involves retrieving batches and allocations, so it's more\ncomplex:\n\n\n[[repo_test_retrieve]]\n.Repository test for retrieving a complex object (test_repository.py)\n====\n[source,python]\n----\ndef insert_order_line(session):\n    session.execute(  #<1>\n        \"INSERT INTO order_lines (orderid, sku, qty)\"\n        ' VALUES (\"order1\", \"GENERIC-SOFA\", 12)'\n    )\n    [[orderline_id]] = session.execute(\n        \"SELECT id FROM order_lines WHERE orderid=:orderid AND sku=:sku\",\n        dict(orderid=\"order1\", sku=\"GENERIC-SOFA\"),\n    )\n    return orderline_id\n\n\ndef insert_batch(session, batch_id):  #<2>\n    ...\n\ndef test_repository_can_retrieve_a_batch_with_allocations(session):\n    orderline_id = insert_order_line(session)\n    batch1_id = insert_batch(session, \"batch1\")\n    insert_batch(session, \"batch2\")\n    insert_allocation(session, orderline_id, batch1_id)  #<2>\n\n    repo = repository.SqlAlchemyRepository(session)\n    retrieved = repo.get(\"batch1\")\n\n    expected = model.Batch(\"batch1\", \"GENERIC-SOFA\", 100, eta=None)\n    assert retrieved == expected  # Batch.__eq__ only compares reference  #<3>\n    assert retrieved.sku == expected.sku  #<4>\n    assert retrieved._purchased_quantity == expected._purchased_quantity\n    assert retrieved._allocations == {  #<4>\n        model.OrderLine(\"order1\", \"GENERIC-SOFA\", 12),\n    }\n----\n====\n\n\n<1> This tests the read side, so the raw SQL is preparing data to be read\n    by the `repo.get()`.\n\n<2> We'll spare you the details of `insert_batch` and `insert_allocation`;\n    the point is to create a couple of batches, and, for the\n    batch we're interested in, to have one existing order line allocated to it.\n\n<3> And that's what we verify here. The first `assert ==` checks that the\n    types match, and that the reference is the same (because, as you remember,\n    `Batch` is an entity, and we have a custom ++__eq__++ for it).\n\n<4> So we also explicitly check on its major attributes, including\n    `._allocations`, which is a Python set of `OrderLine` value objects.\n\n(((\"Repository pattern\", \"typical repository\")))\nWhether or not you painstakingly write tests for every model is a judgment\ncall. Once you have one class tested for create/modify/save, you might be\nhappy to go on and do the others with a minimal round-trip test, or even nothing\nat all, if they all follow a similar pattern. In our case, the ORM config\nthat sets up the `._allocations` set is a little complex, so it merited a\nspecific test.\n\n\nYou end up with something like this:\n\n\n[[batch_repository]]\n.A typical repository (repository.py)\n====\n[source,python]\n----\nclass SqlAlchemyRepository(AbstractRepository):\n    def __init__(self, session):\n        self.session = session\n\n    def add(self, batch):\n        self.session.add(batch)\n\n    def get(self, reference):\n        return self.session.query(model.Batch).filter_by(reference=reference).one()\n\n    def list(self):\n        return self.session.query(model.Batch).all()\n----\n====\n\n\n(((\"Flask framework\", \"API endpoint\")))\n(((\"Repository pattern\", \"using repository directly in API endpoint\")))\n(((\"APIs\", \"using repository directly in API endpoint\")))\nAnd now our Flask endpoint might look something like the following:\n\n[[api_endpoint_with_repo]]\n.Using our repository directly in our API endpoint\n====\n[role=\"skip\"]\n[source,python]\n----\n@flask.route.gubbins\ndef allocate_endpoint():\n    batches = SqlAlchemyRepository.list()\n    lines = [\n        OrderLine(l['orderid'], l['sku'], l['qty'])\n         for l in request.params...\n    ]\n    allocate(lines, batches)\n    session.commit()\n    return 201\n----\n====\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n******************************************************************************\n\n(((\"SQL\", \"ORM and Repository pattern as abstractions in front of\")))\n(((\"Repository pattern\", \"ORMs and\")))\n(((\"object-relational mappers (ORMs)\", \"Repository pattern and\")))\nWe bumped into a friend at a DDD conference the other day who said, \"I haven't\nused an ORM in 10 years.\" The Repository pattern and an ORM both act as abstractions\nin front of raw SQL, so using one behind the other isn't really necessary.  Why\nnot have a go at implementing our repository without using the ORM?\nYou'll find the code https://github.com/cosmicpython/code/tree/chapter_02_repository_exercise[on GitHub].\n\nWe've left the repository tests, but figuring out what SQL to write is up\nto you. Perhaps it'll be harder than you think; perhaps it'll be easier.\nBut the nice thing is, the rest of your application just doesn't care.\n\n******************************************************************************\n\n\n=== Building a Fake Repository for Tests Is Now Trivial!\n\n(((\"Repository pattern\", \"building fake repository for tests\")))\n(((\"set, fake repository as wrapper around\")))\nHere's one of the biggest benefits of the Repository pattern:\n\n\n[[fake_repository]]\n.A simple fake repository using a set (repository.py)\n====\n[role=\"skip\"]\n[source,python]\n----\nclass FakeRepository(AbstractRepository):\n\n    def __init__(self, batches):\n        self._batches = set(batches)\n\n    def add(self, batch):\n        self._batches.add(batch)\n\n    def get(self, reference):\n        return next(b for b in self._batches if b.reference == reference)\n\n    def list(self):\n        return list(self._batches)\n----\n====\n\nBecause it's a simple wrapper around a `set`, all the methods are one-liners.\n\nUsing a fake repo in tests is really easy, and we have a simple\nabstraction that's easy to use and reason about:\n\n[[fake_repository_example]]\n.Example usage of fake repository (test_api.py)\n====\n[role=\"skip\"]\n[source,python]\n----\nfake_repo = FakeRepository([batch1, batch2, batch3])\n----\n====\n\nYou'll see this fake in action in the next chapter.\n\n\nTIP: Building fakes for your abstractions is an excellent way to get design\n    feedback: if it's hard to fake, the abstraction is probably too\n    complicated.\n\n\n[[what_is_a_port_and_what_is_an_adapter]]\n=== What Is a Port and What Is an Adapter, in Python?\n\n(((\"ports\", \"defined\")))\n(((\"adapters\", \"defined\")))\nWe don't want to dwell on the terminology too much here because the main thing\nwe want to focus on is dependency inversion, and the specifics of the\ntechnique you use don't matter too much. Also, we're aware that different\npeople use slightly different definitions.\n\nPorts and adapters came out of the OO world, and the definition we hold onto\nis that the _port_ is the _interface_ between our application and whatever\nit is we wish to abstract away, and the _adapter_ is the _implementation_\nbehind that interface or abstraction.\n\n(((\"interfaces, Python and\")))\n(((\"duck typing\", \"for ports\")))\n(((\"abstract base classes (ABCs)\", \"using for ports\")))\nNow Python doesn't have interfaces per se, so although it's usually easy to\nidentify an adapter, defining the port can be harder. If you're using an\nabstract base class, that's the port. If not, the port is just the duck type\nthat your adapters conform to and that your core application expects—the\nfunction and method names in use, and their argument names and types.\n\nConcretely, in this chapter, `AbstractRepository` is the port, and\n`SqlAlchemyRepository` and `FakeRepository` are the adapters.\n\n\n\n=== Wrap-Up\n\n(((\"Repository pattern\", \"and persistence ignorance, trade-offs\")))\n(((\"persistence ignorance\", \"trade-offs\")))\nBearing the Rich Hickey quote in mind, in each chapter we\nsummarize the costs and benefits of each architectural pattern we introduce.\nWe want to be clear that we're not saying every single application needs\nto be built this way; only sometimes does the complexity of the app and domain\nmake it worth investing the time and effort in adding these extra layers of\nindirection.\n\nWith that in mind, <<chapter_02_repository_tradeoffs>> shows\nsome of the pros and cons of the Repository pattern and our persistence-ignorant\nmodel.\n\n////\n[SG] is it worth mentioning that the repository is specifically intended for add and get\nof our domain model objects, rather than something used to add and get any old data\nwhich you might call a DAO. Repository is more close to the business domain.\n////\n\n[[chapter_02_repository_tradeoffs]]\n[options=\"header\"]\n.Repository pattern and persistence ignorance: the trade-offs\n|===\n|Pros|Cons\na|\n* We have a simple interface between persistent storage and our domain model.\n\n* It's easy to make a fake version of the repository for unit testing, or to\n  swap out different storage solutions, because we've fully decoupled the model\n  from infrastructure concerns.\n\n* Writing the domain model before thinking about persistence helps us focus on\n  the business problem at hand. If we ever want to radically change our approach,\n  we can do that in our model, without needing to worry about foreign keys\n  or migrations until later.\n\n* Our database schema is really simple because we have complete control over\n  how we map our objects to tables.\n\na|\n* An ORM already buys you some decoupling. Changing foreign keys might be hard,\n  but it should be pretty easy to swap between MySQL and Postgres if you\n  ever need to.\n\n////\n[KP] I always found this benefit of ORMs rather weak. In the rare cases when I\nactually had to switch DB engines, the payoff was high enough to justify some\nadditional work. Also, if you are using \"interesting\" DB features (say: special\nPostgres fields) you usually lose the portability.\n////\n\n\n* Maintaining ORM mappings by hand requires extra work and extra code.\n\n* Any extra layer of indirection always increases maintenance costs and\n  adds a \"WTF factor\" for Python programmers who've never seen the Repository pattern\n  before.\n|===\n\n<<domain_model_tradeoffs_diagram>> shows the basic thesis: yes, for simple\ncases, a decoupled domain model is harder work than a simple ORM/ActiveRecord\npattern.footnote:[Diagram inspired by a post called\nhttps://oreil.ly/fQXkP[\"Global Complexity, Local Simplicity\"] by Rob Vens.]\n\nTIP: If your app is just a simple CRUD (create-read-update-delete) wrapper\n    around a database, then you don't need a domain model or a repository.\n\n(((\"domain model\", \"trade-offs as a diagram\")))\n(((\"Vens, Rob\")))\n(((\"&quot;Global Complexity, Local Simplicity&quot; post\", primary-sortas=\"Global\")))\nBut the more complex the domain, the more an investment in freeing\nyourself from infrastructure concerns will pay off in terms of the ease of\nmaking changes.\n\n\n[[domain_model_tradeoffs_diagram]]\n.Domain model trade-offs as a diagram\nimage::images/apwp_0206.png[]\n\n\nOur example code isn't complex enough to give more than a hint of what\nthe right-hand side of the graph looks like, but the hints are there.\nImagine, for example, if we decide one day that we want to change allocations\nto live on the `OrderLine` instead of on the `Batch` object: if we were using\nDjango, say, we'd have to define and think through the database migration\nbefore we could run any tests. As it is, because our model is just plain\nold Python objects, we can change a `set()` to being a new attribute, without\nneeding to think about the database until later.\n\n[role=\"nobreakinside\"]\n.Repository Pattern Recap\n*****************************************************************\nApply dependency inversion to your ORM::\n    Our domain model should be free of infrastructure concerns,\n    so your ORM should import your model, and not the other way\n    around.\n    (((\"Repository pattern\", \"recap of important points\")))\n\nThe Repository pattern is a simple abstraction around permanent storage::\n    The repository gives you the illusion of a collection of in-memory\n    objects. It makes it easy to create a `FakeRepository` for\n    testing and to swap fundamental details of your\n    infrastructure without disrupting your core application. See\n    <<appendix_csvs>> for an example.\n*****************************************************************\n\nYou'll be wondering, how do we instantiate these repositories, fake or\nreal? What will our Flask app actually look like? You'll find out in the next\nexciting installment, <<chapter_04_service_layer,the Service Layer pattern>>.\n\nBut first, a brief digression.\n(((\"Repository pattern\", startref=\"ix_Repo\")))\n"
        },
        {
          "name": "chapter_03_abstractions.asciidoc",
          "type": "blob",
          "size": 33.5869140625,
          "content": "[[chapter_03_abstractions]]\n== A Brief Interlude: On Coupling [.keep-together]#and Abstractions#\n\n(((\"abstractions\", id=\"ix_abs\")))\nAllow us a brief digression on the subject of abstractions, dear reader.\nWe've talked about _abstractions_ quite a lot. The Repository pattern is an\nabstraction over permanent storage, for example. But what makes a good\nabstraction?  What do we want from abstractions?  And how do they relate to testing?\n\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_03_abstractions branch https://oreil.ly/k6MmV[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ngit checkout chapter_03_abstractions\n----\n====\n\n\n(((\"katas\")))\nA key theme in this book, hidden among the fancy patterns, is that we can use\nsimple abstractions to hide messy details. When we're writing code for fun, or\nin a kata,footnote:[A code kata is a small, contained programming challenge often\nused to practice TDD. See\nhttps://web.archive.org/web/20221024055359/http://www.peterprovost.org/blog/2012/05/02/kata-the-only-way-to-learn-tdd/[\"Kata—The Only Way to Learn TDD\"] by Peter Provost.]\nwe get to play with ideas freely, hammering things out and refactoring\naggressively. In a large-scale system, though, we become constrained by the\ndecisions made elsewhere in the system.\n\n(((\"coupling\")))\n(((\"cohesion, high, between coupled elements\")))\nWhen we're unable to change component A for fear of breaking component B, we say\nthat the components have become _coupled_. Locally, coupling is a good thing: it's\na sign that our code is working together, each component supporting the others, all of them\nfitting in place like the gears of a watch. In jargon, we say this works when\nthere is high _cohesion_ between the coupled elements.\n\n(((\"Ball of Mud pattern\")))\n(((\"coupling\", \"disadvantages of\")))\nGlobally, coupling is a nuisance: it increases the risk and the cost of changing\nour code, sometimes to the point where we feel unable to make any changes at\nall. This is the problem with the Ball of Mud pattern: as the application grows,\nif we're unable to prevent coupling between elements that have no cohesion, that\ncoupling increases superlinearly until we are no longer able to effectively\nchange our systems.\n\n(((\"abstractions\", \"using to reduce coupling\")))\n(((\"coupling\", \"reducing by abstracting away details\")))\nWe can reduce the degree of coupling within a system\n(<<coupling_illustration1>>) by abstracting away the details\n(<<coupling_illustration2>>).\n\n[role=\"width-50\"]\n[[coupling_illustration1]]\n.Lots of coupling\nimage::images/apwp_0301.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0301]\n+--------+      +--------+\n| System | ---> | System |\n|   A    | ---> |   B    |\n|        | ---> |        |\n|        | ---> |        |\n|        | ---> |        |\n+--------+      +--------+\n----\n\n[role=\"width-90\"]\n[[coupling_illustration2]]\n.Less coupling\nimage::images/apwp_0302.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0302]\n+--------+                           +--------+\n| System |      /-------------\\      | System |\n|   A    | ---> |             | ---> |   B    |\n|        | ---> | Abstraction | ---> |        |\n|        |      |             | ---> |        |\n|        |      \\-------------/      |        |\n+--------+                           +--------+\n----\n\n\n\nIn both diagrams, we have a pair of subsystems, with one dependent on\nthe other. In <<coupling_illustration1>>, there is a high degree of coupling between the\ntwo; the number of arrows indicates lots of kinds of dependencies\nbetween the two. If we need to change system B, there's a good chance that the\nchange will ripple through to system A.\n\nIn <<coupling_illustration2>>, though, we have reduced the degree of coupling by inserting a\nnew, simpler abstraction. Because it is simpler, system A has fewer\nkinds of dependencies on the abstraction. The abstraction serves to\nprotect us from change by hiding away the complex details of whatever system B\ndoes—we can change the arrows on the right without changing the ones on the left.\n\n[role=\"pagebreak-before less_space\"]\n=== Abstracting State Aids Testability\n\n(((\"abstractions\", \"abstracting state to aid testability\", id=\"ix_absstate\")))\n(((\"testing\", \"abstracting state to aid testability\", id=\"ix_tstabs\")))\n(((\"state\", \"abstracting to aid testability\", id=\"ix_stateabs\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", id=\"ix_filesync\")))\nLet's see an example. Imagine we want to write code for synchronizing two\nfile directories, which we'll call the _source_ and the _destination_:\n\n* If a file exists in the source but not in the destination, copy the file over.\n* If a file exists in the source, but it has a different name than in the destination,\n  rename the destination file to match.\n* If a file exists in the destination but not in the source, remove it.\n\n(((\"hashing a file\")))\nOur first and third requirements are simple enough: we can just compare two\nlists of paths. Our second is trickier, though. To detect renames,\nwe'll have to inspect the content of files. For this, we can use a hashing\nfunction like MD5 or SHA-1. The code to generate a SHA-1 hash from a file is simple\nenough:\n\n[[hash_file]]\n.Hashing a file (sync.py)\n====\n[source,python]\n----\nBLOCKSIZE = 65536\n\n\ndef hash_file(path):\n    hasher = hashlib.sha1()\n    with path.open(\"rb\") as file:\n        buf = file.read(BLOCKSIZE)\n        while buf:\n            hasher.update(buf)\n            buf = file.read(BLOCKSIZE)\n    return hasher.hexdigest()\n----\n====\n\nNow we need to write the bit that makes decisions about what to do—the business\nlogic, if you will.\n\nWhen we have to tackle a problem from first principles, we usually try to write\na simple implementation and then refactor toward better design. We'll use\nthis approach throughout the book, because it's how we write code in the real\nworld: start with a solution to the smallest part of the problem, and then\niteratively make the solution richer and better designed.\n\n////\n[SG] this may just be my lack of Python experience but it would have helped me to see\nfrom pathlib import Path before this code snippet so that I might be able to guess\nthe type of object \"path\" in hash_file(path)  - I guess a type hint would\nbe too much to ask..\n////\n\nOur first hackish approach looks something like this:\n\n[[sync_first_cut]]\n.Basic sync algorithm (sync.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nimport hashlib\nimport os\nimport shutil\nfrom pathlib import Path\n\n\ndef sync(source, dest):\n    # Walk the source folder and build a dict of filenames and their hashes\n    source_hashes = {}\n    for folder, _, files in os.walk(source):\n        for fn in files:\n            source_hashes[hash_file(Path(folder) / fn)] = fn\n\n    seen = set()  # Keep track of the files we've found in the target\n\n    # Walk the target folder and get the filenames and hashes\n    for folder, _, files in os.walk(dest):\n        for fn in files:\n            dest_path = Path(folder) / fn\n            dest_hash = hash_file(dest_path)\n            seen.add(dest_hash)\n\n            # if there's a file in target that's not in source, delete it\n            if dest_hash not in source_hashes:\n                dest_path.remove()\n\n            # if there's a file in target that has a different path in source,\n            # move it to the correct path\n            elif dest_hash in source_hashes and fn != source_hashes[dest_hash]:\n                shutil.move(dest_path, Path(folder) / source_hashes[dest_hash])\n\n    # for every file that appears in source but not target, copy the file to\n    # the target\n    for source_hash, fn in source_hashes.items():\n        if source_hash not in seen:\n            shutil.copy(Path(source) / fn, Path(dest) / fn)\n----\n====\n\nFantastic! We have some code and it _looks_ OK, but before we run it on our\nhard drive, maybe we should test it. How do we go about testing this sort of thing?\n\n\n[[ugly_sync_tests]]\n.Some end-to-end tests (test_sync.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef test_when_a_file_exists_in_the_source_but_not_the_destination():\n    try:\n        source = tempfile.mkdtemp()\n        dest = tempfile.mkdtemp()\n\n        content = \"I am a very useful file\"\n        (Path(source) / \"my-file\").write_text(content)\n\n        sync(source, dest)\n\n        expected_path = Path(dest) / \"my-file\"\n        assert expected_path.exists()\n        assert expected_path.read_text() == content\n\n    finally:\n        shutil.rmtree(source)\n        shutil.rmtree(dest)\n\n\ndef test_when_a_file_has_been_renamed_in_the_source():\n    try:\n        source = tempfile.mkdtemp()\n        dest = tempfile.mkdtemp()\n\n        content = \"I am a file that was renamed\"\n        source_path = Path(source) / \"source-filename\"\n        old_dest_path = Path(dest) / \"dest-filename\"\n        expected_dest_path = Path(dest) / \"source-filename\"\n        source_path.write_text(content)\n        old_dest_path.write_text(content)\n\n        sync(source, dest)\n\n        assert old_dest_path.exists() is False\n        assert expected_dest_path.read_text() == content\n\n    finally:\n        shutil.rmtree(source)\n        shutil.rmtree(dest)\n----\n====\n\n(((\"coupling\", \"domain logic coupled with I/O\")))\n(((\"I/O\", \"domain logic tightly coupled to\")))\nWowsers, that's a lot of setup for two simple cases! The problem is that\nour domain logic, \"figure out the difference between two directories,\" is tightly\ncoupled to the I/O code. We can't run our difference algorithm without calling\nthe `pathlib`, `shutil`, and `hashlib` modules.\n\nAnd the trouble is, even with our current requirements, we haven't written\nenough tests: the current implementation has several bugs (the\n`shutil.move()` is wrong, for example).  Getting decent coverage and revealing\nthese bugs means writing more tests, but if they're all as unwieldy as the preceding\nones, that's going to get real painful real quickly.\n\nOn top of that, our code isn't very extensible. Imagine trying to implement\na `--dry-run` flag that gets our code to just print out what it's going to\ndo, rather than actually do it.  Or what if we wanted to sync to a remote server,\nor to cloud storage?\n\n(((\"abstractions\", \"abstracting state to aid testability\", startref=\"ix_absstate\")))\n(((\"testing\", \"abstracting state to aid testability\", startref=\"ix_tstabs\")))\n(((\"state\", \"abstracting to aid testability\", startref=\"ix_stateabs\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", startref=\"ix_filesync\")))\n(((\"pytest\", \"fixtures\")))\nOur high-level code is coupled to low-level details, and it's making life hard.\nAs the scenarios we consider get more complex, our tests will get more unwieldy.\nWe can definitely refactor these tests (some of the cleanup could go into pytest\nfixtures, for example) but as long as we're doing filesystem operations, they're\ngoing to stay slow and be hard to read and write.\n\n[role=\"pagebreak-before less_space\"]\n=== Choosing the Right Abstraction(s)\n\n(((\"abstractions\", \"choosing right abstraction\", id=\"ix_abscho\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", \"choosing right abstraction\", id=\"ix_filesyncabs\")))\nWhat could we do to rewrite our code to make it more testable?\n\n(((\"responsibilities of code\")))\nFirst, we need to think about what our code needs from the filesystem.\nReading through the code, we can see that three distinct things are happening.\nWe can think of these as three distinct _responsibilities_ that the code has:\n\n1. We interrogate the filesystem by using `os.walk` and determine hashes for a\n   series of paths. This is similar in both the source and the\n   destination cases.\n\n2. We decide whether a file is new, renamed, or redundant.\n\n3. We copy, move, or delete files to match the source.\n\n\n(((\"simplifying abstractions\")))\nRemember that we want to find _simplifying abstractions_ for each of these\nresponsibilities. That will let us hide the messy details so we can\nfocus on the interesting logic.footnote:[If you're used to thinking in terms of\ninterfaces, that's what we're trying to define here.]\n\nNOTE: In this chapter, we're refactoring some gnarly code into a more testable\n    structure by identifying the separate tasks that need to be done and giving\n    each task to a clearly defined actor, along similar lines to <<ddg_example, the `duckduckgo`\n    example>>.\n\n(((\"dictionaries\", \"for filesystem operations\")))\n(((\"hashing a file\", \"dictionary of hashes to paths\")))\nFor steps 1 and 2, we've already intuitively started using an abstraction, a\ndictionary of hashes to paths. You may already have been thinking, \"Why not\nbuild up a dictionary for the destination folder as well as the source, and\nthen we just compare two dicts?\" That seems like a nice way to abstract the\ncurrent state of the filesystem:\n\n    source_files = {'hash1': 'path1', 'hash2': 'path2'}\n    dest_files = {'hash1': 'path1', 'hash2': 'pathX'}\n\nWhat about moving from step 2 to step 3?  How can we abstract out the\nactual move/copy/delete filesystem interaction?\n\n(((\"coupling\", \"separating what you want to do from how to do it\")))\nWe'll apply a trick here that we'll employ on a grand scale later in\nthe book. We're going to separate _what_ we want to do from _how_ to do it.\nWe're going to make our program output a list of commands that look like this:\n\n    (\"COPY\", \"sourcepath\", \"destpath\"),\n    (\"MOVE\", \"old\", \"new\"),\n\n(((\"commands\", \"program output as list of commands\")))\nNow we could write tests that just use two filesystem dicts as inputs, and we would\nexpect lists of tuples of strings representing actions as outputs.\n\nInstead of saying, \"Given this actual filesystem, when I run my function,\ncheck what actions have happened,\" we say, \"Given this _abstraction_ of a filesystem,\nwhat _abstraction_ of filesystem actions will happen?\"\n\n\n[[better_tests]]\n.Simplified inputs and outputs in our tests (test_sync.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n    def test_when_a_file_exists_in_the_source_but_not_the_destination():\n        source_hashes = {'hash1': 'fn1'}\n        dest_hashes = {}\n        expected_actions = [('COPY', '/src/fn1', '/dst/fn1')]\n        ...\n\n    def test_when_a_file_has_been_renamed_in_the_source():\n        source_hashes = {'hash1': 'fn1'}\n        dest_hashes = {'hash1': 'fn2'}\n        expected_actions == [('MOVE', '/dst/fn2', '/dst/fn1')]\n        ...\n----\n====\n\n\n=== Implementing Our Chosen Abstractions\n\n(((\"abstractions\", \"implementing chosen abstraction\", id=\"ix_absimpl\")))\n(((\"abstractions\", \"choosing right abstraction\", startref=\"ix_abscho\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", \"choosing right abstraction\", startref=\"ix_filesyncabs\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", \"implementing chosen abstraction\", id=\"ix_filesyncimp\")))\nThat's all very well, but how do we _actually_ write those new\ntests, and how do we change our implementation to make it all work?\n\n(((\"Functional Core, Imperative Shell (FCIS)\")))\n(((\"Bernhardt, Gary\")))\n(((\"testing\", \"after implementing chosen abstraction\", id=\"ix_tstaftabs\")))\nOur goal is to isolate the clever part of our system, and to be able to test it\nthoroughly without needing to set up a real filesystem. We'll create a \"core\"\nof code that has no dependencies on external state and then see how it responds\nwhen we give it input from the outside world (this kind of approach was characterized\nby Gary Bernhardt as\nhttps://oreil.ly/wnad4[Functional\nCore, Imperative Shell], or FCIS).\n\n(((\"I/O\", \"disentangling details from program logic\")))\n(((\"state\", \"splitting off from logic in the program\")))\n(((\"business logic\", \"separating from state in code\")))\nLet's start off by splitting the code to separate the stateful parts from\nthe logic.\n\nAnd our top-level function will contain almost no logic at all; it's just an\nimperative series of steps: gather inputs, call our logic, apply outputs:\n\n[[three_parts]]\n.Split our code into three  (sync.py)\n====\n[source,python]\n----\ndef sync(source, dest):\n    # imperative shell step 1, gather inputs\n    source_hashes = read_paths_and_hashes(source)  #<1>\n    dest_hashes = read_paths_and_hashes(dest)  #<1>\n\n    # step 2: call functional core\n    actions = determine_actions(source_hashes, dest_hashes, source, dest)  #<2>\n\n    # imperative shell step 3, apply outputs\n    for action, *paths in actions:\n        if action == \"COPY\":\n            shutil.copyfile(*paths)\n        if action == \"MOVE\":\n            shutil.move(*paths)\n        if action == \"DELETE\":\n            os.remove(paths[0])\n----\n====\n<1> Here's the first function we factor out, `read_paths_and_hashes()`, which\n    isolates the I/O part of our application.\n\n<2> Here is where we carve out the functional core, the business logic.\n\n\n(((\"dictionaries\", \"dictionary of hashes to paths\")))\nThe code to build up the dictionary of paths and hashes is now trivially easy\nto write:\n\n[[read_paths_and_hashes]]\n.A function that just does I/O (sync.py)\n====\n[source,python]\n----\ndef read_paths_and_hashes(root):\n    hashes = {}\n    for folder, _, files in os.walk(root):\n        for fn in files:\n            hashes[hash_file(Path(folder) / fn)] = fn\n    return hashes\n----\n====\n\nThe `determine_actions()` function will be the core of our business logic,\nwhich says, \"Given these two sets of hashes and filenames, what should we\ncopy/move/delete?\".  It takes simple data structures and returns simple data\nstructures:\n\n[[determine_actions]]\n.A function that just does business logic (sync.py)\n====\n[source,python]\n----\ndef determine_actions(source_hashes, dest_hashes, source_folder, dest_folder):\n    for sha, filename in source_hashes.items():\n        if sha not in dest_hashes:\n            sourcepath = Path(source_folder) / filename\n            destpath = Path(dest_folder) / filename\n            yield \"COPY\", sourcepath, destpath\n\n        elif dest_hashes[sha] != filename:\n            olddestpath = Path(dest_folder) / dest_hashes[sha]\n            newdestpath = Path(dest_folder) / filename\n            yield \"MOVE\", olddestpath, newdestpath\n\n    for sha, filename in dest_hashes.items():\n        if sha not in source_hashes:\n            yield \"DELETE\", dest_folder / filename\n----\n====\n\nOur tests now act directly on the `determine_actions()` function:\n\n\n[[harry_tests]]\n.Nicer-looking tests (test_sync.py)\n====\n[source,python]\n----\ndef test_when_a_file_exists_in_the_source_but_not_the_destination():\n    source_hashes = {\"hash1\": \"fn1\"}\n    dest_hashes = {}\n    actions = determine_actions(source_hashes, dest_hashes, Path(\"/src\"), Path(\"/dst\"))\n    assert list(actions) == [(\"COPY\", Path(\"/src/fn1\"), Path(\"/dst/fn1\"))]\n\n\ndef test_when_a_file_has_been_renamed_in_the_source():\n    source_hashes = {\"hash1\": \"fn1\"}\n    dest_hashes = {\"hash1\": \"fn2\"}\n    actions = determine_actions(source_hashes, dest_hashes, Path(\"/src\"), Path(\"/dst\"))\n    assert list(actions) == [(\"MOVE\", Path(\"/dst/fn2\"), Path(\"/dst/fn1\"))]\n----\n====\n\n\nBecause we've disentangled the logic of our program--the code for identifying\nchanges--from the low-level details of I/O, we can easily test the core of our code.\n\n(((\"edge-to-edge testing\", id=\"ix_edgetst\")))\nWith this approach, we've switched from testing our main entrypoint function,\n`sync()`, to testing a lower-level function, `determine_actions()`. You might\ndecide that's fine because `sync()` is now so simple. Or you might decide to\nkeep some integration/acceptance tests to test that `sync()`. But there's\nanother option, which is to modify the `sync()` function so it can\nbe unit tested _and_ end-to-end tested; it's an approach Bob calls\n_edge-to-edge testing_.\n\n\n==== Testing Edge to Edge with Fakes and Dependency Injection\n\n(((\"dependencies\", \"edge-to-edge testing with dependency injection\", id=\"ix_depinj\")))\n(((\"testing\", \"after implementing chosen abstraction\", \"edge-to-edge testing with fakes and dependency injection\", id=\"ix_tstaftabsedge\")))\n(((\"abstractions\", \"implementing chosen abstraction\", \"edge-to-edge testing with fakes and dependency injection\", id=\"ix_absimpltstfdi\")))\nWhen we start writing a new system, we often focus on the core logic first,\ndriving it with direct unit tests. At some point, though, we want to test bigger\nchunks of the system together.\n\n(((\"faking\", \"faking I/O in edge-to-edge test\")))\nWe _could_ return to our end-to-end tests, but those are still as tricky to\nwrite and maintain as before. Instead, we often write tests that invoke a whole\nsystem together but fake the I/O, sort of _edge to edge_:\n\n\n[[di_version]]\n.Explicit dependencies (sync.py)\n====\n[source,python]\n[role=\"skip\"]\n----\ndef sync(source, dest, filesystem=FileSystem()):  #<1>\n    source_hashes = filesystem.read(source)  #<2>\n    dest_hashes = filesystem.read(dest)  #<2>\n\n    for sha, filename in source_hashes.items():\n        if sha not in dest_hashes:\n            sourcepath = Path(source) / filename\n            destpath = Path(dest) / filename\n            filesystem.copy(sourcepath, destpath)  #<3>\n\n        elif dest_hashes[sha] != filename:\n            olddestpath = Path(dest) / dest_hashes[sha]\n            newdestpath = Path(dest) / filename\n            filesystem.move(olddestpath, newdestpath)  #<3>\n\n    for sha, filename in dest_hashes.items():\n        if sha not in source_hashes:\n            filesystem.delete(dest / filename)  #<3>\n----\n====\n\n<1> Our top-level function now exposes a new dependency, a `FileSystem`.\n\n<2> We invoke `filesystem.read()` to produce our files dict.\n\n<3> We invoke the ++FileSystem++'s `.copy()`, `.move()` and `.delete()` methods\n    to apply the changes we detect.\n\nTIP: Although we're using dependency injection, there is no need\n    to define an abstract base class or any kind of explicit interface. In this\n    book, we often show ABCs because we hope they help you understand what the\n    abstraction is, but they're not necessary. Python's dynamic nature means\n    we can always rely on duck typing.\n\n// IDEA [KP] Again, one could mention PEP544 protocols here. For some reason, I like them.\n\nThe real (default) implementation of our FileSystem abstraction does real I/O:\n\n[[real_filesystem_wrapper]]\n.The real dependency (sync.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass FileSystem:\n\n    def read(self, path):\n        return read_paths_and_hashes(path)\n\n    def copy(self, source, dest):\n        shutil.copyfile(source, dest)\n\n    def move(self, source, dest):\n        shutil.move(source, dest)\n\n    def delete(self, dest):\n        os.remove(dest)\n----\n====\n\nBut the fake one is a wrapper around our chosen abstractions,\nrather than doing real I/O:\n\n[[fake_filesystem]]\n.Tests using DI\n====\n[source,python]\n[role=\"skip\"]\n----\nclass FakeFilesystem:\n    def __init__(self, path_hashes):  #<1>\n        self.path_hashes = path_hashes\n        self.actions = []  #<2>\n\n    def read(self, path):\n        return self.path_hashes[path]  #<1>\n\n    def copy(self, source, dest):\n        self.actions.append(('COPY', source, dest))  #<2>\n\n    def move(self, source, dest):\n        self.actions.append(('MOVE', source, dest))  #<2>\n\n    def delete(self, dest):\n        self.actions.append(('DELETE', dest))  #<2>\n----\n====\n\n<1> We initialize our fake filesysem using the abstraction we chose to\n    represent filesystem state: dictionaries of hashes to paths.\n\n<2> The action methods in our `FakeFileSystem` just appends a record to an list\n    of `.actions` so we can inspect it later. This means our test double is both\n    a \"fake\" and a \"spy\".\n    (((\"test doubles\")))\n    (((\"fake objects\")))\n    (((\"spy objects\")))\n\nSo now our tests can act on the real, top-level `sync()` entrypoint,\nbut they do so using the `FakeFilesystem()`.  In terms of their\nsetup and assertions, they end up looking quite similar to the ones\nwe wrote when testing directly against the functional core `determine_actions()`\nfunction:\n\n\n[[bob_tests]]\n.Tests using DI\n====\n[source,python]\n[role=\"skip\"]\n----\ndef test_when_a_file_exists_in_the_source_but_not_the_destination():\n    fakefs = FakeFilesystem({\n        '/src': {\"hash1\": \"fn1\"},\n        '/dst': {},\n    })\n    sync('/src', '/dst', filesystem=fakefs)\n    assert fakefs.actions == [(\"COPY\", Path(\"/src/fn1\"), Path(\"/dst/fn1\"))]\n\n\ndef test_when_a_file_has_been_renamed_in_the_source():\n    fakefs = FakeFilesystem({\n        '/src': {\"hash1\": \"fn1\"},\n        '/dst': {\"hash1\": \"fn2\"},\n    })\n    sync('/src', '/dst', filesystem=fakefs)\n    assert fakefs.actions == [(\"MOVE\", Path(\"/dst/fn2\"), Path(\"/dst/fn1\"))]\n----\n====\n\n\nThe advantage of this approach is that our tests act on the exact same function\nthat's used by our production code. The disadvantage is that we have to make\nour stateful components explicit and pass them around.\nDavid Heinemeier Hansson, the creator of Ruby on Rails, famously described this\nas \"test-induced design damage.\"\n\n(((\"edge-to-edge testing\", startref=\"ix_edgetst\")))\n(((\"testing\", \"after implementing chosen abstraction\", \"edge-to-edge testing with fakes and dependency injection\", startref=\"ix_tstaftabsedge\")))\n(((\"dependencies\", \"edge-to-edge testing with dependency injection\", startref=\"ix_depinj\")))\n(((\"abstractions\", \"after implementing chosen abstraction\", \"edge-to-edge testing with fakes and dependency injection\", startref=\"ix_absimpltstfdi\")))\nIn either case, we can now work on fixing all the bugs in our implementation;\nenumerating tests for all the edge cases is now much easier.\n\n\n==== Why Not Just Patch It Out?\n\n(((\"mock.patch method\")))\n(((\"mocking\", \"avoiding use of mock.patch\")))\n(((\"abstractions\", \"implementing chosen abstraction\", \"not using mock.patch for testing\")))\n(((\"testing\", \"after implementing chosen abstraction\", \"avoiding use of mock.patch\", id=\"ix_tstaftabsmck\")))\nAt this point you may be scratching your head and thinking,\n\"Why don't you just use `mock.patch` and save yourself the effort?\"\n\nWe avoid using mocks in this book and in our production code too. We're not\ngoing to enter into a Holy War, but our instinct is that mocking frameworks,\nparticularly monkeypatching, are a code smell.\n\nInstead, we like to clearly identify the responsibilities in our codebase, and to\nseparate those responsibilities into small, focused objects that are easy to\nreplace with a test double.\n\nNOTE: You can see an example in <<chapter_08_events_and_message_bus>>,\n    where we `mock.patch()` out an email-sending module, but eventually we\n    replace that with an explicit bit of dependency injection in\n    <<chapter_13_dependency_injection>>.\n\nWe have three closely related reasons for our preference:\n\n* Patching out the dependency you're using makes it possible to unit test the\n  code, but it does nothing to improve the design. Using `mock.patch` won't let your\n  code work with a `--dry-run` flag, nor will it help you run against an FTP\n  server. For that, you'll need to introduce abstractions.\n\n* Tests that use mocks _tend_ to be more coupled to the implementation details\n  of the codebase. That's because mock tests verify the interactions between\n  things: did we call `shutil.copy` with the right arguments? This coupling between\n  code and test _tends_ to make tests more brittle, in our experience.\n  (((\"coupling\", \"in tests that use mocks\")))\n\n* Overuse of mocks leads to complicated test suites that fail to explain the\n  code.\n\nNOTE: Designing for testability really means designing for\n    extensibility. We trade off a little more complexity for a cleaner design\n    that admits novel use cases.\n\n[role=\"nobreakinside less_space\"]\n.Mocks Versus Fakes; Classic-Style Versus London-School TDD\n*******************************************************************************\n\n(((\"test doubles\", \"mocks versus fakes\")))\n(((\"mocking\", \"mocks versus fakes\")))\n(((\"faking\", \"fakes versus mocks\")))\nHere's a short and somewhat simplistic definition of the difference between\nmocks and fakes:\n\n* Mocks are used to verify _how_ something gets used;  they have methods\n  like `assert_called_once_with()`. They're associated with London-school\n  TDD.\n\n* Fakes are working implementations of the thing they're replacing, but\n  they're designed for use only in tests. They wouldn't work \"in real life\";\nour in-memory repository is a good example. But you can use them to make assertions about\n  the end state of a system rather than the behaviors along the way, so\n  they're associated with classic-style TDD.\n\n(((\"Fowler, Martin\")))\n(((\"stubbing, mocks and stubs\")))\n(((\"&quot;Mocks Aren&#x27;t Stubs&quot; (Fowler)\", primary-sortas=\"Mocks\")))\nWe're slightly conflating mocks with spies and fakes with stubs here, and you\ncan read the long, correct answer in Martin Fowler's classic essay on the subject\ncalled https://oreil.ly/yYjBN[\"Mocks Aren't Stubs\"].\n\n(((\"MagicMock objects\")))\n(((\"unittest.mock function\")))\n(((\"test doubles\", \"mocks versus stubs\")))\nIt also probably doesn't help that the `MagicMock` objects provided by\n`unittest.mock` aren't, strictly speaking, mocks; they're spies, if anything.\nBut they're also often used as stubs or dummies. There, we promise we're done with\nthe test double terminology nitpicks now.\n\n//IDEA (hynek) you could mention Alex Gaynor's `pretend` which gives you\n// stubs without mocks error-prone magic.\n\n(((\"London-school versus classic-style TDD\")))\n(((\"test-driven development (TDD)\", \"classic versus London-school\")))\n(((\"Software Engineering Stack Exchange site\")))\nWhat about London-school versus classic-style TDD? You can read more about those\ntwo in Martin Fowler's article that we just cited, as well as on the\nhttps://oreil.ly/H2im_[Software Engineering Stack Exchange site],\nbut in this book we're pretty firmly in the classicist camp.  We like to\nbuild our tests around state both in setup and in assertions, and we like\nto work at the highest level of abstraction possible rather than doing\nchecks on the behavior of intermediary collaborators.footnote:[Which is not to\nsay that we think the London school people are wrong. Some insanely smart\npeople work that way. It's just not what we're used to.]\n\nRead more on this in <<kinds_of_tests>>.\n*******************************************************************************\n\nWe view TDD as a design practice first and a testing practice second. The tests\nact as a record of our design choices and serve to explain the system to us\nwhen we return to the code after a long absence.\n\n(((\"mocking\", \"overmocked tests, pitfalls of\")))\nTests that use too many mocks get overwhelmed with setup code that hides the\nstory we care about.\n\n(((\"&quot;Test-Driven Development: That&#x27;s Not What We Meant&quot;\", primary-sortas=\"Test-Driven Development\")))\n(((\"Freeman, Steve\")))\n(((\"PyCon talk on Mocking Pitfalls\")))\n(((\"Jung, Ed\")))\nSteve Freeman has a great example of overmocked tests in his talk\nhttps://oreil.ly/jAmtr[\"Test-Driven Development\"].\nYou should also check out this PyCon talk, https://oreil.ly/s3e05[\"Mocking and Patching Pitfalls\"],\nby our esteemed tech reviewer, Ed Jung, which also addresses mocking and its\nalternatives.\n\nAnd while we're recommending talks, check out the wonderful Brandon Rhodes\nin https://oreil.ly/oiXJM[\"Hoisting Your I/O\"].  It's not actually about mocks,\nbut is instead about the general issue of decoupling business logic from I/O,\nin which he uses a wonderfully simple illustrative example.\n(((\"hoisting I/O\")))\n(((\"Rhodes, Brandon\")))\n\n\nTIP: In this chapter, we've spent a lot of time replacing end-to-end tests with\n    unit tests. That doesn't mean we think you should never use E2E tests!\n    In this book we're showing techniques to get you to a decent test\n    pyramid with as many unit tests as possible, and with the minimum number of E2E\n    tests you need to feel confident. Read on to <<types_of_test_rules_of_thumb>>\n    for more details.\n    (((\"unit testing\", \"unit tests replacing end-to-end tests\")))\n    (((\"end-to-end tests\", \"replacement with unit tests\")))\n\n\n.So Which Do We Use In This Book? Functional or Object-Oriented Composition?\n******************************************************************************\n(((\"object-oriented composition\")))\nBoth. Our domain model is entirely free of dependencies and side effects,\nso that's our functional core. The service layer that we build around it\n(in <<chapter_04_service_layer>>) allows us to drive the system edge to edge,\nand we use dependency injection to provide those services with stateful\ncomponents, so we can still unit test them.\n\nSee <<chapter_13_dependency_injection>> for more exploration of making our\ndependency injection more explicit and centralized.\n******************************************************************************\n\n=== Wrap-Up\n\n(((\"abstractions\", \"implementing chosen abstraction\", startref=\"ix_absimpl\")))\n(((\"abstractions\", \"simplifying interface between business logic and I/O\")))\n(((\"business logic\", \"abstractions simplifying interface with messy I/O\")))\n(((\"testing\", \"after implementing chosen abstraction\", startref=\"ix_tstaftabs\")))\n(((\"testing\", \"after implementing chosen abstraction\", \"avoiding use of mock.patch\", startref=\"ix_tstaftabsmck\")))\n(((\"filesystems\", \"writing code to synchronize source and target directories\", \"implementing chosen abstraction\", startref=\"ix_filesyncimp\")))\n(((\"I/O\", \"simplifying interface with business logic using abstractions\")))\nWe'll see this idea come up again and again in the book: we can make our\nsystems easier to test and maintain by simplifying the interface between our\nbusiness logic and messy I/O. Finding the right abstraction is tricky, but here are\na few heuristics and questions to ask yourself:\n\n\n* Can I choose a familiar Python data structure to represent the state of the\n  messy system and then try to imagine a single function that can return that\n  state?\n\n* Separate the _what_ from the _how_:\n  can I use a data structure or DSL to represent the external effects I want to happen,\n  independently of _how_ I plan to make them happen?\n\n* Where can I draw a line between my systems,\n  where can I carve out a https://oreil.ly/zNUGG[seam]\n  to stick that abstraction in?\n  (((\"seams\")))\n\n* What is a sensible way of dividing things into components with different responsibilities?\n  What implicit concepts can I make explicit?\n\n* What are the dependencies, and what is the core business logic?\n\n(((\"abstractions\", startref=\"ix_abs\")))\nPractice makes less imperfect! And now back to our regular programming...\n"
        },
        {
          "name": "chapter_04_service_layer.asciidoc",
          "type": "blob",
          "size": 34.7255859375,
          "content": "[[chapter_04_service_layer]]\n== Our First Use Case: [.keep-together]#Flask API and Service Layer#\n\n(((\"service layer\", id=\"ix_serlay\")))\n(((\"Flask framework\", \"Flask API and service layer\", id=\"ix_Flskapp\")))\nBack to our allocations project! <<maps_service_layer_before>> shows the point we reached at the end of <<chapter_02_repository>>, which covered the Repository pattern.\n\n[role=\"width-75\"]\n[[maps_service_layer_before]]\n.Before: we drive our app by talking to repositories and the domain model\nimage::images/apwp_0401.png[]\n\n\nIn this chapter, we discuss the differences between orchestration logic,\nbusiness logic, and interfacing code, and we introduce the _Service Layer_\npattern to take care of orchestrating our workflows and defining the use\ncases of our system.\n\nWe'll also discuss testing: by combining the Service Layer with our repository\nabstraction over the database, we're able to write fast tests, not just of\nour domain model but of the entire workflow for a use case.\n\n<<maps_service_layer_after>> shows what we're aiming for: we're going to\nadd a Flask API that will talk to the service layer, which will serve as the\nentrypoint to our domain model. Because our service layer depends on the\n`AbstractRepository`, we can unit test it by using `FakeRepository` but run our production code using `SqlAlchemyRepository`.\n\n[[maps_service_layer_after]]\n.The service layer will become the main way into our app\nimage::images/apwp_0402.png[]\n\n// IDEA more detailed legend\n\nIn our diagrams, we are using the convention that new components\n    are highlighted with bold text/lines (and yellow/orange color, if you're\n    reading a digital version).\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_04_service_layer branch https://oreil.ly/TBRuy[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_04_service_layer\n# or to code along, checkout Chapter 2:\ngit checkout chapter_02_repository\n----\n====\n\n\n=== Connecting Our Application to the Real World\n\n(((\"service layer\", \"connecting our application to real world\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"connecting the app to real world\")))\nLike any good agile team, we're hustling to try to get an MVP out and\nin front of the users to start gathering feedback. We have the core\nof our domain model and the domain service we need to allocate orders,\nand we have the repository interface for permanent storage.\n\nLet's plug all the moving parts together as quickly as we\ncan and then refactor toward a cleaner architecture. Here's our\nplan:\n\n1. Use Flask to put an API endpoint in front of our `allocate` domain service.\n   Wire up the database session and our repository. Test it with\n   an end-to-end test and some quick-and-dirty SQL to prepare test\n   data.\n   (((\"Flask framework\", \"putting API endpoint in front of allocate domain service\")))\n\n2. Refactor out a service layer that can serve as an abstraction to\n   capture the use case and that will sit between Flask and our domain model.\n   Build some service-layer tests and show how they can use\n   `FakeRepository`.\n\n3. Experiment with different types of parameters for our service layer\n   functions; show that using primitive data types allows the service layer's\n   clients (our tests and our Flask API) to be decoupled from the model layer.\n\n\n=== A First End-to-End Test\n\n(((\"APIs\", \"end-to-end test of allocate API\")))\n(((\"end-to-end tests\", \"of allocate API\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"first API end-to-end test\", id=\"ix_Flskappe2e\")))\nNo one is interested in getting into a long terminology debate about what\ncounts as an end-to-end (E2E) test versus a functional test versus an acceptance test versus\nan integration test versus a unit test. Different projects need different\ncombinations of tests, and we've seen perfectly successful projects just split\nthings into \"fast tests\" and \"slow tests.\"\n\nFor now, we want to write one or maybe two tests that are going to exercise\na \"real\" API endpoint (using HTTP) and talk to a real database. Let's call\nthem _end-to-end tests_ because it's one of the most self-explanatory names.\n\nThe following shows a first cut:\n\n[[first_api_test]]\n.A first API test (test_api.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_api_returns_allocation(add_stock):\n    sku, othersku = random_sku(), random_sku(\"other\")  #<1>\n    earlybatch = random_batchref(1)\n    laterbatch = random_batchref(2)\n    otherbatch = random_batchref(3)\n    add_stock(  #<2>\n        [\n            (laterbatch, sku, 100, \"2011-01-02\"),\n            (earlybatch, sku, 100, \"2011-01-01\"),\n            (otherbatch, othersku, 100, None),\n        ]\n    )\n    data = {\"orderid\": random_orderid(), \"sku\": sku, \"qty\": 3}\n    url = config.get_api_url()  #<3>\n\n    r = requests.post(f\"{url}/allocate\", json=data)\n\n    assert r.status_code == 201\n    assert r.json()[\"batchref\"] == earlybatch\n----\n====\n\n<1> `random_sku()`, `random_batchref()`, and so on are little helper functions that\n    generate randomized characters by using the `uuid` module. Because\n    we're running against an actual database now, this is one way to prevent\n    various tests and runs from interfering with each other.\n\n<2> `add_stock` is a helper fixture that just hides away the details of\n    manually inserting rows into the database using SQL. We'll show a nicer\n    way of doing this later in the chapter.\n\n<3> _config.py_ is a module in which we keep configuration information.\n\n(((\"Flask framework\", \"Flask API and service layer\", \"first API end-to-end test\", startref=\"ix_Flskappe2e\")))\nEveryone solves these problems in different ways, but you're going to need some\nway of spinning up Flask, possibly in a container, and of talking to a\nPostgres database. If you want to see how we did it, check out\n<<appendix_project_structure>>.\n\n\n=== The Straightforward Implementation\n\n(((\"service layer\", \"first cut of Flask app\", id=\"ix_serlay1Flapp\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"first cut of the app\", id=\"ix_Flskapp1st\")))\nImplementing things in the most obvious way, you might get something like this:\n\n\n[[first_cut_flask_app]]\n.First cut of Flask app (flask_app.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nfrom flask import Flask, request\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\n\nimport config\nimport model\nimport orm\nimport repository\n\n\norm.start_mappers()\nget_session = sessionmaker(bind=create_engine(config.get_postgres_uri()))\napp = Flask(__name__)\n\n\n@app.route(\"/allocate\", methods=[\"POST\"])\ndef allocate_endpoint():\n    session = get_session()\n    batches = repository.SqlAlchemyRepository(session).list()\n    line = model.OrderLine(\n        request.json[\"orderid\"], request.json[\"sku\"], request.json[\"qty\"],\n    )\n\n    batchref = model.allocate(line, batches)\n\n    return {\"batchref\": batchref}, 201\n----\n====\n\nSo far, so good. No need for too much more of your \"architecture astronaut\"\nnonsense, Bob and Harry, you may be thinking.\n\n(((\"databases\", \"testing allocations persisted to database\")))\nBut hang on a minute--there's no commit. We're not actually saving our\nallocation to the database. Now we need a second test, either one that will\ninspect the database state after (not very black-boxy), or maybe one that\nchecks that we can't allocate a second line if a first should have already\ndepleted the batch:\n\n[[second_api_test]]\n.Test allocations are persisted (test_api.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_allocations_are_persisted(add_stock):\n    sku = random_sku()\n    batch1, batch2 = random_batchref(1), random_batchref(2)\n    order1, order2 = random_orderid(1), random_orderid(2)\n    add_stock(\n        [(batch1, sku, 10, \"2011-01-01\"), (batch2, sku, 10, \"2011-01-02\"),]\n    )\n    line1 = {\"orderid\": order1, \"sku\": sku, \"qty\": 10}\n    line2 = {\"orderid\": order2, \"sku\": sku, \"qty\": 10}\n    url = config.get_api_url()\n\n    # first order uses up all stock in batch 1\n    r = requests.post(f\"{url}/allocate\", json=line1)\n    assert r.status_code == 201\n    assert r.json()[\"batchref\"] == batch1\n\n    # second order should go to batch 2\n    r = requests.post(f\"{url}/allocate\", json=line2)\n    assert r.status_code == 201\n    assert r.json()[\"batchref\"] == batch2\n----\n====\n\n(((\"Flask framework\", \"Flask API and service layer\", \"first cut of the app\", startref=\"ix_Flskapp1st\")))\n(((\"service layer\", \"first cut of Flask app\", startref=\"ix_serlay1Flapp\")))\nNot quite so lovely, but that will force us to add the commit.\n\n\n\n=== Error Conditions That Require Database Checks\n\n(((\"service layer\", \"error conditions requiring database checks in Flask app\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"error conditions requiring database checks\")))\nIf we keep going like this, though, things are going to get uglier and uglier.\n\nSuppose we want to add a bit of error handling. What if the domain raises an\nerror, for a SKU that's out of stock?  Or what about a SKU that doesn't even\nexist? That's not something the domain even knows about, nor should it. It's\nmore of a sanity check that we should implement at the database layer, before\nwe even invoke the domain service.\n\nNow we're looking at two more end-to-end tests:\n\n\n[[test_error_cases]]\n.Yet more tests at the E2E layer (test_api.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_400_message_for_out_of_stock(add_stock):  #<1>\n    sku, small_batch, large_order = random_sku(), random_batchref(), random_orderid()\n    add_stock(\n        [(small_batch, sku, 10, \"2011-01-01\"),]\n    )\n    data = {\"orderid\": large_order, \"sku\": sku, \"qty\": 20}\n    url = config.get_api_url()\n    r = requests.post(f\"{url}/allocate\", json=data)\n    assert r.status_code == 400\n    assert r.json()[\"message\"] == f\"Out of stock for sku {sku}\"\n\n\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_400_message_for_invalid_sku():  #<2>\n    unknown_sku, orderid = random_sku(), random_orderid()\n    data = {\"orderid\": orderid, \"sku\": unknown_sku, \"qty\": 20}\n    url = config.get_api_url()\n    r = requests.post(f\"{url}/allocate\", json=data)\n    assert r.status_code == 400\n    assert r.json()[\"message\"] == f\"Invalid sku {unknown_sku}\"\n----\n====\n\n<1> In the first test, we're trying to allocate more units than we have in stock.\n\n<2> In the second, the SKU just doesn't exist (because we never called `add_stock`),\n    so it's invalid as far as our app is concerned.\n\n\nAnd sure, we could implement it in the Flask app too:\n\n[[flask_error_handling]]\n.Flask app starting to get crufty (flask_app.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef is_valid_sku(sku, batches):\n    return sku in {b.sku for b in batches}\n\n\n@app.route(\"/allocate\", methods=[\"POST\"])\ndef allocate_endpoint():\n    session = get_session()\n    batches = repository.SqlAlchemyRepository(session).list()\n    line = model.OrderLine(\n        request.json[\"orderid\"], request.json[\"sku\"], request.json[\"qty\"],\n    )\n\n    if not is_valid_sku(line.sku, batches):\n        return {\"message\": f\"Invalid sku {line.sku}\"}, 400\n\n    try:\n        batchref = model.allocate(line, batches)\n    except model.OutOfStock as e:\n        return {\"message\": str(e)}, 400\n\n    session.commit()\n    return {\"batchref\": batchref}, 201\n----\n====\n\nBut our Flask app is starting to look a bit unwieldy.  And our number of\nE2E tests is starting to get out of control, and soon we'll end up with an\ninverted test pyramid (or \"ice-cream cone model,\" as Bob likes to call it).\n\n\n=== Introducing a Service Layer, and Using FakeRepository to Unit Test It\n\n(((\"service layer\", \"introducing and using FakeRepository to unit test it\", id=\"ix_serlayintr\")))\n(((\"orchestration\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"introducing service layer and fake repo to unit test it\", id=\"ix_Flskappserly\")))\nIf we look at what our Flask app is doing, there's quite a lot of what we\nmight call __orchestration__—fetching stuff out of our repository, validating\nour input against database state, handling errors, and committing in the\nhappy path. Most of these things don't have anything to do with having a\nweb API endpoint (you'd need them if you were building a CLI, for example; see\n<<appendix_csvs>>), and they're not really things that need to be tested by\nend-to-end tests.\n\n(((\"orchestration layer\", see=\"service layer\")))\n(((\"use-case layer\", see=\"service layer\")))\nIt often makes sense to split out a service layer, sometimes called an\n_orchestration layer_ or a _use-case layer_.\n\n(((\"faking\", \"FakeRepository\")))\nDo you remember the `FakeRepository` that we prepared in <<chapter_03_abstractions>>?\n\n[[fake_repo]]\n.Our fake repository, an in-memory collection of batches (test_services.py)\n====\n[source,python]\n----\nclass FakeRepository(repository.AbstractRepository):\n    def __init__(self, batches):\n        self._batches = set(batches)\n\n    def add(self, batch):\n        self._batches.add(batch)\n\n    def get(self, reference):\n        return next(b for b in self._batches if b.reference == reference)\n\n    def list(self):\n        return list(self._batches)\n----\n====\n\n(((\"testing\", \"unit testing with fakes at service layer\")))\n(((\"unit testing\", seealso=\"test-driven development; testing\")))\n(((\"faking\", \"FakeRepository\", \"using to unit test the service layer\")))\nHere's where it will come in useful; it lets us test our service layer with\nnice, fast unit tests:\n\n\n[[first_services_tests]]\n.Unit testing with fakes at the service layer (test_services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef test_returns_allocation():\n    line = model.OrderLine(\"o1\", \"COMPLICATED-LAMP\", 10)\n    batch = model.Batch(\"b1\", \"COMPLICATED-LAMP\", 100, eta=None)\n    repo = FakeRepository([batch])  #<1>\n\n    result = services.allocate(line, repo, FakeSession())  #<2><3>\n    assert result == \"b1\"\n\n\ndef test_error_for_invalid_sku():\n    line = model.OrderLine(\"o1\", \"NONEXISTENTSKU\", 10)\n    batch = model.Batch(\"b1\", \"AREALSKU\", 100, eta=None)\n    repo = FakeRepository([batch])  #<1>\n\n    with pytest.raises(services.InvalidSku, match=\"Invalid sku NONEXISTENTSKU\"):\n        services.allocate(line, repo, FakeSession())  #<2><3>\n----\n====\n\n\n<1> `FakeRepository` holds the `Batch` objects that will be used by our test.\n\n<2> Our services module (_services.py_) will define an `allocate()`\n    service-layer function. It will sit between our `allocate_endpoint()`\n    function in the API layer and the `allocate()` domain service function from\n    our domain model.footnote:[Service-layer services and domain services do have\n    confusingly similar names. We tackle this topic later in\n    <<why_is_everything_a_service>>.]\n\n<3> We also need a `FakeSession` to fake out the database session, as shown in\n    the following code snippet.\n    (((\"faking\", \"FakeSession, using to unit test the service layer\")))\n    (((\"testing\", \"fake database session at service layer\")))\n\n\n[[fake_session]]\n.A fake database session (test_services.py)\n====\n[source,python]\n----\nclass FakeSession:\n    committed = False\n\n    def commit(self):\n        self.committed = True\n----\n====\n\nThis fake session is only a temporary solution.  We'll get rid of it and make\nthings even nicer soon, in <<chapter_06_uow>>. But in the meantime\nthe fake `.commit()` lets us migrate a third test from the E2E layer:\n\n\n[[second_services_test]]\n.A second test at the service layer (test_services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef test_commits():\n    line = model.OrderLine(\"o1\", \"OMINOUS-MIRROR\", 10)\n    batch = model.Batch(\"b1\", \"OMINOUS-MIRROR\", 100, eta=None)\n    repo = FakeRepository([batch])\n    session = FakeSession()\n\n    services.allocate(line, repo, session)\n    assert session.committed is True\n----\n====\n\n\n==== A Typical Service Function\n\n(((\"functions\", \"service layer\")))\n(((\"service layer\", \"typical service function\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"typical service layer function\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"introducing service layer and fake repo to unit test it\", startref=\"ix_Flskappserly\")))\nWe'll write a service function that looks something like this:\n\n[[service_function]]\n.Basic allocation service (services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass InvalidSku(Exception):\n    pass\n\n\ndef is_valid_sku(sku, batches):\n    return sku in {b.sku for b in batches}\n\n\ndef allocate(line: OrderLine, repo: AbstractRepository, session) -> str:\n    batches = repo.list()  #<1>\n    if not is_valid_sku(line.sku, batches):  #<2>\n        raise InvalidSku(f\"Invalid sku {line.sku}\")\n    batchref = model.allocate(line, batches)  #<3>\n    session.commit()  #<4>\n    return batchref\n----\n====\n\nTypical service-layer functions have similar steps:\n\n<1> We fetch some objects from the repository.\n\n<2> We make some checks or assertions about the request against\n    the current state of the world.\n\n<3> We call a domain service.\n\n<4> If all is well, we save/update any state we've changed.\n\nThat last step is a little unsatisfactory at the moment, as our service\nlayer is tightly coupled to our database layer. We'll improve\nthat in <<chapter_06_uow>> with the Unit of Work pattern.\n\n[role=\"nobreakinside less_space\"]\n[[depend_on_abstractions]]\n.Depend on Abstractions\n*******************************************************************************\nNotice one more thing about our service-layer function:\n\n[source,python]\n[role=\"skip\"]\n----\ndef allocate(line: OrderLine, repo: AbstractRepository, session) -> str:\n----\n\n(((\"abstractions\", \"AbstractRepository, service function depending on\")))\n(((\"repositories\", \"service layer function depending on abstract repository\")))\nIt depends on a repository.  We've chosen to make the dependency explicit,\nand we've used the type hint to say that we depend on `AbstractRepository`.\nThis means it'll work both when the tests give it a `FakeRepository` and\nwhen the Flask app gives it a `SqlAlchemyRepository`.\n\n(((\"dependencies\", \"depending on abstractions\")))\nIf you remember <<dip>>,\nthis is what we mean when we say we should \"depend on abstractions.\" Our\n_high-level module_, the service layer, depends on the repository abstraction.\nAnd the _details_ of the implementation for our specific choice of persistent\nstorage also depend on that same abstraction. See\n<<service_layer_diagram_abstract_dependencies>> and\n<<service_layer_diagram_test_dependencies>>.\n\nSee also in <<appendix_csvs>> a worked example of swapping out the\n_details_ of which persistent storage system to use while leaving the\nabstractions intact.\n\n*******************************************************************************\n\n\n(((\"service layer\", \"Flask app delegating to\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"app delegating to service layer\")))\nBut the essentials of the service layer are there, and our Flask\napp now looks a lot cleaner:\n\n\n[[flask_app_using_service_layer]]\n.Flask app delegating to service layer (flask_app.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@app.route(\"/allocate\", methods=[\"POST\"])\ndef allocate_endpoint():\n    session = get_session()  #<1>\n    repo = repository.SqlAlchemyRepository(session)  #<1>\n    line = model.OrderLine(\n        request.json[\"orderid\"], request.json[\"sku\"], request.json[\"qty\"],  #<2>\n    )\n\n    try:\n        batchref = services.allocate(line, repo, session)  #<2>\n    except (model.OutOfStock, services.InvalidSku) as e:\n        return {\"message\": str(e)}, 400  #<3>\n\n    return {\"batchref\": batchref}, 201  #<3>\n----\n====\n\n<1> We instantiate a database session and some repository objects.\n<2> We extract the user's commands from the web request and pass them\n    to the service layer.\n<3> We return some JSON responses with the appropriate status codes.\n\nThe responsibilities of the Flask app are just standard web stuff: per-request\nsession management, parsing information out of POST parameters, response status\ncodes, and JSON. All the orchestration logic is in the use case/service layer,\nand the domain logic stays in the domain.\n\n(((\"Flask framework\", \"Flask API and service layer\", \"end-to-end tests for happy and unhappy paths\")))\n(((\"service layer\", \"end-to-end test of allocate API, testing happy and unhappy paths\")))\nFinally, we can confidently strip down our E2E tests to just two, one for\nthe happy path and one for the unhappy path:\n\n\n[[fewer_e2e_tests]]\n.E2E tests only happy and unhappy paths (test_api.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_happy_path_returns_201_and_allocated_batch(add_stock):\n    sku, othersku = random_sku(), random_sku(\"other\")\n    earlybatch = random_batchref(1)\n    laterbatch = random_batchref(2)\n    otherbatch = random_batchref(3)\n    add_stock(\n        [\n            (laterbatch, sku, 100, \"2011-01-02\"),\n            (earlybatch, sku, 100, \"2011-01-01\"),\n            (otherbatch, othersku, 100, None),\n        ]\n    )\n    data = {\"orderid\": random_orderid(), \"sku\": sku, \"qty\": 3}\n    url = config.get_api_url()\n\n    r = requests.post(f\"{url}/allocate\", json=data)\n\n    assert r.status_code == 201\n    assert r.json()[\"batchref\"] == earlybatch\n\n\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_unhappy_path_returns_400_and_error_message():\n    unknown_sku, orderid = random_sku(), random_orderid()\n    data = {\"orderid\": orderid, \"sku\": unknown_sku, \"qty\": 20}\n    url = config.get_api_url()\n    r = requests.post(f\"{url}/allocate\", json=data)\n    assert r.status_code == 400\n    assert r.json()[\"message\"] == f\"Invalid sku {unknown_sku}\"\n----\n====\n\nWe've successfully split our tests into two broad categories: tests about web\nstuff, which we implement end to end; and tests about orchestration stuff, which\nwe can test against the service layer in memory.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n******************************************************************************\n(((\"deallocate service, building (exerise)\")))\nNow that we have an allocate service, why not build out a service for\n`deallocate`? We've added https://github.com/cosmicpython/code/tree/chapter_04_service_layer_exercise[an E2E test and a few stub service-layer tests] for\nyou to get started on GitHub.\n\nIf that's not enough, continue into the E2E tests and _flask_app.py_, and\nrefactor the Flask adapter to be more RESTful. Notice how doing so doesn't\nrequire any change to our service layer or domain layer!\n\nTIP: If you decide you want to build a read-only endpoint for retrieving allocation\n    info, just do \"the simplest thing that can possibly work,\" which is\n    `repo.get()` right in the Flask handler. We'll talk more about reads versus\n    writes in <<chapter_12_cqrs>>.\n\n******************************************************************************\n\n[[why_is_everything_a_service]]\n=== Why Is Everything Called a Service?\n\n(((\"services\", \"application service and domain service\")))\n(((\"service layer\", \"difference between domain service and\")))\n(((\"service layer\", \"introducing and using FakeRepository to unit test it\", startref=\"ix_serlayintr\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"different types of services\")))\nSome of you are probably scratching your heads at this point trying to figure\nout exactly what the difference is between a domain service and a service layer.\n\n(((\"application services\")))\nWe're sorry—we didn't choose the names, or we'd have much cooler and friendlier\nways to talk about this stuff.\n\n(((\"orchestration\", \"using application service\")))\nWe're using two things called a _service_ in this chapter. The first is an\n_application service_ (our service layer). Its job is to handle requests from the\noutside world and to _orchestrate_ an operation. What we mean is that the\nservice layer _drives_ the application by following a bunch of simple steps:\n\n* Get some data from the database\n* Update the domain model\n* Persist any changes\n\nThis is the kind of boring work that has to happen for every operation in your\nsystem, and keeping it separate from business logic helps to keep things tidy.\n\n(((\"domain services\")))\nThe second type of service is a _domain service_. This is the name for a piece of\nlogic that belongs in the domain model but doesn't sit naturally inside a\nstateful entity or value object. For example, if you were building a shopping\ncart application, you might choose to build taxation rules as a domain service.\nCalculating tax is a separate job from updating the cart, and it's an important\npart of the model, but it doesn't seem right to have a persisted entity for\nthe job. Instead a stateless TaxCalculator class or a `calculate_tax` function\ncan do the job.\n\n\n=== Putting Things in Folders to See Where It All Belongs\n\n(((\"directory structure, putting project into folders\")))\n(((\"projects\", \"organizing into folders\")))\n(((\"service layer\", \"putting project in folders\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"putting project into folders\")))\nAs our application gets bigger, we'll need to keep tidying our directory\nstructure. The layout of our project gives us useful hints about what kinds of\nobject we'll find in each file.\n\nHere's one way we could organize things:\n\n[[nested_folder_tree]]\n.Some subfolders\n====\n[source,text]\n[role=\"skip\"]\n----\n.\n├── config.py\n├── domain  #<1>\n│   ├── __init__.py\n│   └── model.py\n├── service_layer  #<2>\n│   ├── __init__.py\n│   └── services.py\n├── adapters  #<3>\n│   ├── __init__.py\n│   ├── orm.py\n│   └── repository.py\n├── entrypoints  <4>\n│   ├── __init__.py\n│   └── flask_app.py\n└── tests\n    ├── __init__.py\n    ├── conftest.py\n    ├── unit\n    │   ├── test_allocate.py\n    │   ├── test_batches.py\n    │   └── test_services.py\n    ├── integration\n    │   ├── test_orm.py\n    │   └── test_repository.py\n    └── e2e\n        └── test_api.py\n\n----\n====\n\n<1> Let's have a folder for our domain model.  Currently that's just one file,\n    but for a more complex application, you might have one file per class; you\n    might have helper parent classes for `Entity`, `ValueObject`, and\n    `Aggregate`, and you might add an __exceptions.py__ for domain-layer exceptions\n    and, as you'll see in <<part2>>, [.keep-together]#__commands.py__# and __events.py__.\n    (((\"domain model\", \"folder for\")))\n\n<2> We'll distinguish the service layer. Currently that's just one file\n    called _services.py_ for our service-layer functions.  You could\n    add service-layer exceptions here, and as you'll see in\n    <<chapter_05_high_gear_low_gear>>, we'll add __unit_of_work.py__.\n\n<3> _Adapters_ is a nod to the ports and adapters terminology. This will fill\n    up with any other abstractions around external I/O (e.g., a __redis_client.py__).\n    Strictly speaking, you would call these _secondary_ adapters or _driven_\n    adapters, or sometimes _inward-facing_ adapters.\n    (((\"adapters\", \"putting into folder\")))\n    (((\"inward-facing adapters\")))\n    (((\"secondary adapters\")))\n    (((\"driven adapters\")))\n\n<4> Entrypoints are the places we drive our application from. In the\n    official ports and adapters terminology, these are adapters too, and are\n    referred to as _primary_, _driving_, or _outward-facing_ adapters.\n    (((\"entrypoints\")))\n\n(((\"ports\", \"putting in folder with adapters\")))\nWhat about ports?  As you may remember, they are the abstract interfaces that the\nadapters implement. We tend to keep them in the same file as the adapters that\nimplement them.\n\n\n=== Wrap-Up\n\n\n(((\"service layer\", \"benefits of\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"service layer benefits\")))\nAdding the service layer has really bought us quite a lot:\n\n* Our Flask API endpoints become very thin and easy to write: their\n  only responsibility is doing \"web stuff,\" such as parsing JSON\n  and producing the right HTTP codes for happy or unhappy cases.\n\n* We've defined a clear API for our domain, a set of use cases or\n  entrypoints that can be used by any adapter without needing to know anything\n  about our domain model classes--whether that's an API, a CLI (see\n  <<appendix_csvs>>), or the tests! They're an adapter for our domain too.\n\n* We can write tests in \"high gear\" by using the service layer, leaving us\n  free to refactor the domain model in any way we see fit. As long as\n  we can still deliver the same use cases, we can experiment with new\n  designs without needing to rewrite a load of tests.\n\n* And our test pyramid is looking good--the bulk of our tests\n  are fast unit tests, with just the bare minimum of E2E and integration\n  tests.\n\n\n==== The DIP in Action\n\n(((\"dependencies\", \"abstract dependencies of service layer\")))\n(((\"service layer\", \"dependencies of\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"service layer dependencies\")))\n<<service_layer_diagram_abstract_dependencies>> shows the\ndependencies of our service layer: the domain model\nand `AbstractRepository` (the port, in ports and adapters terminology).\n\n(((\"dependencies\", \"abstract dependencies of service layer\", \"testing\")))\n(((\"service layer\", \"dependencies of\", \"testing\")))\nWhen we run the tests, <<service_layer_diagram_test_dependencies>> shows\nhow we implement the abstract dependencies by using `FakeRepository` (the\nadapter).\n\n(((\"service layer\", \"dependencies of\", \"real dependencies at runtime\")))\n(((\"dependencies\", \"real service layer dependencies at runtime\")))\nAnd when we actually run our app, we swap in the \"real\" dependency shown in\n<<service_layer_diagram_runtime_dependencies>>.\n\n[role=\"width-75\"]\n[[service_layer_diagram_abstract_dependencies]]\n.Abstract dependencies of the service layer\nimage::images/apwp_0403.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0403]\n        +-----------------------------+\n        |         Service Layer       |\n        +-----------------------------+\n           |                   |\n           |                   | depends on abstraction\n           V                   V\n+------------------+     +--------------------+\n|   Domain Model   |     | AbstractRepository |\n|                  |     |       (Port)       |\n+------------------+     +--------------------+\n----\n\n\n[role=\"width-75\"]\n[[service_layer_diagram_test_dependencies]]\n.Tests provide an implementation of the abstract dependency\nimage::images/apwp_0404.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0404]\n        +-----------------------------+\n        |           Tests             |-------------\\\n        +-----------------------------+             |\n                       |                            |\n                       V                            |\n        +-----------------------------+             |\n        |         Service Layer       |    provides |\n        +-----------------------------+             |\n           |                     |                  |\n           V                     V                  |\n+------------------+     +--------------------+     |\n|   Domain Model   |     | AbstractRepository |     |\n+------------------+     +--------------------+     |\n                                    ^               |\n                         implements |               |\n                                    |               |\n                         +----------------------+   |\n                         |    FakeRepository    |<--/\n                         |     (in–memory)      |\n                         +----------------------+\n----\n\n[role=\"width-75\"]\n[[service_layer_diagram_runtime_dependencies]]\n.Dependencies at runtime\nimage::images/apwp_0405.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0405]\n       +--------------------------------+\n       | Flask API (Presentation Layer) |-----------\\\n       +--------------------------------+           |\n                       |                            |\n                       V                            |\n        +-----------------------------+             |\n        |         Service Layer       |             |\n        +-----------------------------+             |\n           |                     |                  |\n           V                     V                  |\n+------------------+     +--------------------+     |\n|   Domain Model   |     | AbstractRepository |     |\n+------------------+     +--------------------+     |\n              ^                     ^               |\n              |                     |               |\n       gets   |          +----------------------+   |\n       model  |          | SqlAlchemyRepository |<--/\n   definitions|          +----------------------+\n       from   |                | uses\n              |                V\n           +-----------------------+\n           |          ORM          |\n           | (another abstraction) |\n           +-----------------------+\n                       |\n                       | talks to\n                       V\n           +------------------------+\n           |       Database         |\n           +------------------------+\n----\n\n\nWonderful.\n\n(((\"service layer\", \"pros and cons or trade-offs\")))\n(((\"Flask framework\", \"Flask API and service layer\", \"service layer pros and cons\")))\nLet's pause for <<chapter_04_service_layer_tradeoffs>>,\nin which we consider the pros and cons of having a service layer at all.\n\n[[chapter_04_service_layer_tradeoffs]]\n[options=\"header\"]\n.Service layer: the trade-offs\n|===\n|Pros|Cons\na|\n* We have a single place to capture all the use cases for our application.\n\n* We've placed our clever domain logic behind an API, which leaves us free to\n  refactor.\n\n* We have cleanly separated \"stuff that talks HTTP\" from \"stuff that talks\n  allocation.\"\n\n* When combined with the Repository pattern and `FakeRepository`, we have\n  a nice way of writing tests at a higher level than the domain layer;\n  we can test more of our workflow without needing to use integration tests\n  (read on to <<chapter_05_high_gear_low_gear>> for more elaboration on this).\n\na|\n* If your app is _purely_ a web app, your controllers/view functions can be\n  the single place to capture all the use cases.\n\n* It's yet another layer of abstraction.\n\n* Putting too much logic into the service layer can lead to the _Anemic Domain_\n  antipattern. It's better to introduce this layer after you spot orchestration\n  logic creeping into your controllers.\n  (((\"domain model\", \"getting benefits of rich model\")))\n  (((\"Anemic Domain antipattern\")))\n\n* You can get a lot of the benefits that come from having rich domain models\n  by simply pushing logic out of your controllers and down to the model layer,\n  without needing to add an extra layer in between (aka \"fat models, thin\n  controllers\").\n  (((\"Flask framework\", \"Flask API and service layer\", startref=\"ix_Flskapp\")))\n  (((\"service layer\", startref=\"ix_serlay\")))\n|===\n\nBut there are still some bits of awkwardness to tidy up:\n\n* The service layer is still tightly coupled to the domain, because\n  its API is expressed in terms of `OrderLine` objects. In\n  <<chapter_05_high_gear_low_gear>>, we'll fix that and talk about\n  the way that the service layer enables more productive TDD.\n\n* The service layer is tightly coupled to a `session` object. In <<chapter_06_uow>>,\n  we'll introduce one more pattern that works closely with the Repository and\n  Service Layer patterns, the Unit of Work pattern, and everything will be absolutely lovely.\n  You'll see!\n\n"
        },
        {
          "name": "chapter_05_high_gear_low_gear.asciidoc",
          "type": "blob",
          "size": 21.8505859375,
          "content": "[[chapter_05_high_gear_low_gear]]\n== TDD in High Gear and Low Gear\n\n(((\"test-driven development (TDD)\", id=\"ix_TDD\")))\nWe've introduced the service layer to capture some of the additional\norchestration responsibilities we need from a working application. The service layer helps us\nclearly define our use cases and the workflow for each: what\nwe need to get from our repositories, what pre-checks and current state\nvalidation we should do, and what we save at the end.\n\n(((\"test-driven development (TDD)\", \"unit tests operating at lower level, acting directly on model\")))\nBut currently, many of our unit tests operate at a lower level, acting\ndirectly on the model. In this chapter we'll discuss the trade-offs\ninvolved in moving those tests up to the service-layer level, and\nsome more general testing guidelines.\n\n\n.Harry Says: Seeing a Test Pyramid in Action Was a Light-Bulb Moment\n*******************************************************************************\n(((\"test-driven development (TDD)\", \"test pyramid, examining\")))\nHere are a few words from Harry directly:\n\n_I was initially skeptical of all Bob's architectural patterns, but seeing\nan actual test pyramid made me a convert._\n\n_Once you implement domain modeling and the service layer, you really actually can\nget to a stage where unit tests outnumber integration and end-to-end tests by\nan order of magnitude.  Having worked in places where the E2E test build would\ntake hours (\"wait &#x27;til tomorrow,\" essentially), I can't tell you what a\ndifference it makes to be able to run all your tests in minutes or seconds._\n\n_Read on for some guidelines on how to decide what kinds of tests to write\nand at which level. The high gear versus low gear way of thinking really changed\nmy testing life._\n*******************************************************************************\n\n\n=== How Is Our Test Pyramid Looking?\n\n(((\"service layer\", \"using, test pyramid and\")))\n(((\"test-driven development (TDD)\", \"test pyramid with service layer added\")))\nLet's see what this move to using a service layer, with its own service-layer tests,\ndoes to our test pyramid:\n\n[[test_pyramid]]\n.Counting types of tests\n====\n[source,sh]\n[role=\"skip\"]\n----\n$ grep -c test_ */*/test_*.py\ntests/unit/test_allocate.py:4\ntests/unit/test_batches.py:8\ntests/unit/test_services.py:3\n\ntests/integration/test_orm.py:6\ntests/integration/test_repository.py:2\n\ntests/e2e/test_api.py:2\n----\n====\n\n//NICE-TO-HAVE: test listing this too?\n\nNot bad! We have 15 unit tests, 8 integration tests, and just 2 end-to-end tests.  That's\nalready a healthy-looking test pyramid.\n\n\n\n=== Should Domain Layer Tests Move to the Service Layer?\n\n(((\"domain layer\", \"tests moving to service layer\")))\n(((\"service layer\", \"domain layer tests moving to\")))\n(((\"test-driven development (TDD)\", \"domain layer tests moving to service layer\")))\nLet's see what happens if we take this a step further. Since we can test our\nsoftware against the service layer, we don't really need tests for the domain\nmodel anymore. Instead, we could rewrite all of the domain-level tests from\n<<chapter_01_domain_model>> in terms of the service layer:\n\n\n.Rewriting a domain test at the service layer (tests/unit/test_services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n# domain-layer test:\ndef test_prefers_current_stock_batches_to_shipments():\n    in_stock_batch = Batch(\"in-stock-batch\", \"RETRO-CLOCK\", 100, eta=None)\n    shipment_batch = Batch(\"shipment-batch\", \"RETRO-CLOCK\", 100, eta=tomorrow)\n    line = OrderLine(\"oref\", \"RETRO-CLOCK\", 10)\n\n    allocate(line, [in_stock_batch, shipment_batch])\n\n    assert in_stock_batch.available_quantity == 90\n    assert shipment_batch.available_quantity == 100\n\n\n# service-layer test:\ndef test_prefers_warehouse_batches_to_shipments():\n    in_stock_batch = Batch(\"in-stock-batch\", \"RETRO-CLOCK\", 100, eta=None)\n    shipment_batch = Batch(\"shipment-batch\", \"RETRO-CLOCK\", 100, eta=tomorrow)\n    repo = FakeRepository([in_stock_batch, shipment_batch])\n    session = FakeSession()\n\n    line = OrderLine('oref', \"RETRO-CLOCK\", 10)\n\n    services.allocate(line, repo, session)\n\n    assert in_stock_batch.available_quantity == 90\n    assert shipment_batch.available_quantity == 100\n----\n====\n\n(((\"domain layer\", \"tests moving to service layer\", \"reasons for\")))\n(((\"service layer\", \"domain layer tests moving to\", \"reasons for\")))\nWhy would we want to do that?\n\nTests are supposed to help us change our system fearlessly, but often\nwe see teams writing too many tests against their domain model. This causes\nproblems when they come to change their codebase and find that they need to\nupdate tens or even hundreds of unit tests.\n\nThis makes sense if you stop to think about the purpose of automated tests. We\nuse tests to enforce that a property of the system doesn't change while we're\nworking. We use tests to check that the API continues to return 200, that the\ndatabase session continues to commit, and that orders are still being allocated.\n\nIf we accidentally change one of those behaviors, our tests will break. The\nflip side, though, is that if we want to change the design of our code, any\ntests relying directly on that code will also fail.\n\nAs we get further into the book, you'll see how the service layer forms an API\nfor our system that we can drive in multiple ways. Testing against this API\nreduces the amount of code that we need to change when we refactor our domain\nmodel. If we restrict ourselves to testing only against the service layer,\nwe won't have any tests that directly interact with \"private\" methods or\nattributes on our model objects, which leaves us freer to refactor them.\n\nTIP: Every line of code that we put in a test is like a blob of glue, holding\n    the system in a particular shape. The more low-level tests we have, the\n    harder it will be to change things.\n\n\n[[kinds_of_tests]]\n=== On Deciding What Kind of Tests to Write\n\n(((\"domain model\", \"deciding whether to write tests against\")))\n(((\"coupling\", \"trade-off between design feedback and\")))\n(((\"test-driven development (TDD)\", \"deciding what kinds of tests to write\")))\nYou might be asking yourself, \"Should I rewrite all my unit tests, then? Is it\nwrong to write tests against the domain model?\" To answer those questions, it's\nimportant to understand the trade-off between coupling and design feedback (see\n<<test_spectrum_diagram>>).\n\n[[test_spectrum_diagram]]\n.The test spectrum\nimage::images/apwp_0501.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0501]\n| Low feedback                                                   High feedback |\n| Low barrier to change                                 High barrier to change |\n| High system coverage                                        Focused coverage |\n|                                                                              |\n| <---------                                                       ----------> |\n|                                                                              |\n| API Tests                  Service–Layer Tests                  Domain Tests |\n----\n\n\n(((\"extreme programming (XP), exhortation to listen to the code\")))\nExtreme programming (XP) exhorts us to \"listen to the code.\" When we're writing\ntests, we might find that the code is hard to use or notice a code smell. This\nis a trigger for us to refactor, and to reconsider our design.\n\nWe only get that feedback, though, when we're working closely with the target\ncode. A test for the HTTP API tells us nothing about the fine-grained design of\nour objects, because it sits at a much higher level of abstraction.\n\nOn the other hand, we can rewrite our entire application and, so long as we\ndon't change the URLs or request formats, our HTTP tests will continue to pass.\nThis gives us confidence that large-scale changes, like changing the database schema,\nhaven't broken our code.\n\nAt the other end of the spectrum, the tests we wrote in <<chapter_01_domain_model>> helped us to\nflesh out our understanding of the objects we need. The tests guided us to a\ndesign that makes sense and reads in the domain language. When our tests read\nin the domain language, we feel comfortable that our code matches our intuition\nabout the problem we're trying to solve.\n\nBecause the tests are written in the domain language, they act as living\ndocumentation for our model. A new team member can read these tests to quickly\nunderstand how the system works and how the core concepts interrelate.\n\nWe often \"sketch\" new behaviors by writing tests at this level to see how the\ncode might look. When we want to improve the design of the code, though, we will need to replace\nor delete these tests, because they are tightly coupled to a particular\n[.keep-together]#implementation#.\n\n// IDEA: (EJ3) an example that is overmocked would be good here if you decide to\n// add one. Ch12 already has one that could be expanded.\n\n// IDEA (SG) - maybe we could do with a/some concrete examples here?  Eg an\n// example where a unit test would break but a service-layer test wouldn't?\n// and maybe make the analogy of \"you should only write tests against public\n// methods of your classes, and the service layer is just another more-public\n// layer\n\n\n=== High and Low Gear\n\n(((\"test-driven development (TDD)\", \"high and low gear\")))\nMost of the time, when we are adding a new feature or fixing a bug, we don't\nneed to make extensive changes to the domain model. In these cases, we prefer\nto write tests against services because of the lower coupling and higher coverage.\n\n(((\"service layer\", \"writing tests against\")))\nFor example, when writing an `add_stock` function or a `cancel_order` feature,\nwe can work more quickly and with less coupling by writing tests against the\nservice layer.\n\n(((\"domain model\", \"writing tests against\")))\nWhen starting a new project or when hitting a particularly gnarly problem,\nwe will drop back down to writing tests against the domain model so we\nget better feedback and executable documentation of our intent.\n\nThe metaphor we use is that of shifting gears. When starting a journey, the\nbicycle needs to be in a low gear so that it can overcome inertia. Once we're off\nand running, we can go faster and more efficiently by changing into a high gear;\nbut if we suddenly encounter a steep hill or are forced to slow down by a\nhazard, we again drop down to a low gear until we can pick up speed again.\n\n\n\n[[primitive_obsession]]\n=== Fully Decoupling the Service-Layer Tests from the Domain\n\n(((\"service layer\", \"fully decoupling from the domain\", id=\"ix_serlaydec\")))\n(((\"domain layer\", \"fully decoupling service layer from\", id=\"ix_domlaydec\")))\n(((\"test-driven development (TDD)\", \"fully decoupling service layer from the domain\", id=\"ix_TDDdecser\")))\nWe still have direct dependencies on the domain in our service-layer\ntests, because we use domain objects to set up our test data and to invoke\nour service-layer functions.\n\nTo have a service layer that's fully decoupled from the domain, we need to\nrewrite its API to work in terms of primitives.\n\nOur service layer currently takes an `OrderLine` domain object:\n\n[[service_domain]]\n.Before: allocate takes a domain object (service_layer/services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\ndef allocate(line: OrderLine, repo: AbstractRepository, session) -> str:\n----\n====\n\nHow would it look if its parameters were all primitive types?\n\n[[service_takes_primitives]]\n.After: allocate takes strings and ints (service_layer/services.py)\n====\n[source,python]\n----\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    repo: AbstractRepository, session\n) -> str:\n----\n====\n\nWe rewrite the tests in those terms as well:\n\n[[tests_call_with_primitives]]\n.Tests now use primitives in function call (tests/unit/test_services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef test_returns_allocation():\n    batch = model.Batch(\"batch1\", \"COMPLICATED-LAMP\", 100, eta=None)\n    repo = FakeRepository([batch])\n\n    result = services.allocate(\"o1\", \"COMPLICATED-LAMP\", 10, repo, FakeSession())\n    assert result == \"batch1\"\n----\n====\n\nBut our tests still depend on the domain, because we still manually instantiate\n`Batch` objects.  So, if one day we decide to massively refactor how our `Batch`\nmodel works, we'll have to change a bunch of tests.\n\n\n==== Mitigation: Keep All Domain Dependencies in Fixture Functions\n\n(((\"faking\", \"FakeRepository\", \"adding fixture function on\")))\n(((\"fixture functions, keeping all domain dependencies in\")))\n(((\"test-driven development (TDD)\", \"fully decoupling service layer from the domain\", \"keeping all domain dependencies in fixture functions\")))\n(((\"dependencies\", \"keeping all domain dependencies in fixture functions\")))\nWe could at least abstract that out to a helper function or a fixture\nin our tests.  Here's one way you could do that, adding a factory\nfunction on `FakeRepository`:\n\n\n[[services_factory_function]]\n.Factory functions for fixtures are one possibility (tests/unit/test_services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass FakeRepository(set):\n\n    @staticmethod\n    def for_batch(ref, sku, qty, eta=None):\n        return FakeRepository([\n            model.Batch(ref, sku, qty, eta),\n        ])\n\n    ...\n\n\ndef test_returns_allocation():\n    repo = FakeRepository.for_batch(\"batch1\", \"COMPLICATED-LAMP\", 100, eta=None)\n    result = services.allocate(\"o1\", \"COMPLICATED-LAMP\", 10, repo, FakeSession())\n    assert result == \"batch1\"\n----\n====\n\n\nAt least that would move all of our tests' dependencies on the domain\ninto one place.\n\n\n==== Adding a Missing Service\n\n(((\"test-driven development (TDD)\", \"fully decoupling service layer from the domain\", \"adding missing service\")))\nWe could go one step further, though. If we had a service to add stock,\nwe could use that and make our service-layer tests fully expressed\nin terms of the service layer's official use cases, removing all dependencies\non the domain:\n\n\n[[test_add_batch]]\n.Test for new add_batch service (tests/unit/test_services.py)\n====\n[source,python]\n----\ndef test_add_batch():\n    repo, session = FakeRepository([]), FakeSession()\n    services.add_batch(\"b1\", \"CRUNCHY-ARMCHAIR\", 100, None, repo, session)\n    assert repo.get(\"b1\") is not None\n    assert session.committed\n----\n====\n\n\nTIP: In general, if you find yourself needing to do domain-layer stuff directly\n    in your service-layer tests, it may be an indication that your service\n    layer is incomplete.\n\n[role=\"pagebreak-before\"]\nAnd the implementation is just two lines:\n\n[[add_batch_service]]\n.A new service for add_batch (service_layer/services.py)\n====\n[source,python]\n----\ndef add_batch(\n    ref: str, sku: str, qty: int, eta: Optional[date],\n    repo: AbstractRepository, session,\n) -> None:\n    repo.add(model.Batch(ref, sku, qty, eta))\n    session.commit()\n\n\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    repo: AbstractRepository, session\n) -> str:\n----\n====\n\nNOTE: Should you write a new service just because it would help remove\n    dependencies from your tests?  Probably not.  But in this case, we\n    almost definitely would need an `add_batch` service one day [.keep-together]#anyway#.\n\n(((\"services\", \"service layer tests only using services\")))\nThat now allows us to rewrite _all_ of our service-layer tests purely\nin terms of the services themselves, using only primitives, and without\nany dependencies on the model:\n\n\n[[services_tests_all_services]]\n.Services tests now use only services (tests/unit/test_services.py)\n====\n[source,python]\n----\ndef test_allocate_returns_allocation():\n    repo, session = FakeRepository([]), FakeSession()\n    services.add_batch(\"batch1\", \"COMPLICATED-LAMP\", 100, None, repo, session)\n    result = services.allocate(\"o1\", \"COMPLICATED-LAMP\", 10, repo, session)\n    assert result == \"batch1\"\n\n\ndef test_allocate_errors_for_invalid_sku():\n    repo, session = FakeRepository([]), FakeSession()\n    services.add_batch(\"b1\", \"AREALSKU\", 100, None, repo, session)\n\n    with pytest.raises(services.InvalidSku, match=\"Invalid sku NONEXISTENTSKU\"):\n        services.allocate(\"o1\", \"NONEXISTENTSKU\", 10, repo, FakeSession())\n----\n====\n\n\n(((\"service layer\", \"fully decoupling from the domain\", startref=\"ix_serlaydec\")))\n(((\"domain layer\", \"fully decoupling service layer from\", startref=\"ix_domlaydec\")))\n(((\"test-driven development (TDD)\", \"fully decoupling service layer from the domain\", startref=\"ix_TDDdecser\")))\nThis is a really nice place to be in.  Our service-layer tests depend on only\nthe service layer itself, leaving us completely free to refactor the model as\nwe see fit.\n\n[role=\"pagebreak-before less_space\"]\n=== Carrying the Improvement Through to the E2E Tests\n\n(((\"E2E tests\", see=\"end-to-end tests\")))\n(((\"end-to-end tests\", \"decoupling of service layer from domain, carrying through to\")))\n(((\"test-driven development (TDD)\", \"fully decoupling service layer from the domain\", \"carrying improvement through to E2E tests\")))\n(((\"APIs\", \"adding API for adding a batch\")))\nIn the same way that adding `add_batch` helped decouple our service-layer\ntests from the model, adding an API endpoint to add a batch would remove\nthe need for the ugly `add_stock` fixture, and our E2E tests could be free\nof those hardcoded SQL queries and the direct dependency on the database.\n\nThanks to our service function, adding the endpoint is easy, with just a little\nJSON wrangling and a single function call required:\n\n\n[[api_for_add_batch]]\n.API for adding a batch (entrypoints/flask_app.py)\n====\n[source,python]\n----\n@app.route(\"/add_batch\", methods=[\"POST\"])\ndef add_batch():\n    session = get_session()\n    repo = repository.SqlAlchemyRepository(session)\n    eta = request.json[\"eta\"]\n    if eta is not None:\n        eta = datetime.fromisoformat(eta).date()\n    services.add_batch(\n        request.json[\"ref\"],\n        request.json[\"sku\"],\n        request.json[\"qty\"],\n        eta,\n        repo,\n        session,\n    )\n    return \"OK\", 201\n----\n====\n\nNOTE: Are you thinking to yourself, POST to _/add_batch_? That's not\n    very RESTful!  You're quite right.  We're being happily sloppy, but\n    if you'd like to make it all more RESTy, maybe a POST to _/batches_,\n    then knock yourself out!  Because Flask is a thin adapter, it'll be\n    easy. See <<types_of_test_rules_of_thumb, the next sidebar>>.\n\nAnd our hardcoded SQL queries from _conftest.py_ get replaced with some\nAPI calls, meaning the API tests have no dependencies other than the API,\nwhich is also nice:\n\n[[api_tests_with_no_sql]]\n.API tests can now add their own batches (tests/e2e/test_api.py)\n====\n[source,python]\n----\ndef post_to_add_batch(ref, sku, qty, eta):\n    url = config.get_api_url()\n    r = requests.post(\n        f\"{url}/add_batch\", json={\"ref\": ref, \"sku\": sku, \"qty\": qty, \"eta\": eta}\n    )\n    assert r.status_code == 201\n\n\n@pytest.mark.usefixtures(\"postgres_db\")\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_happy_path_returns_201_and_allocated_batch():\n    sku, othersku = random_sku(), random_sku(\"other\")\n    earlybatch = random_batchref(1)\n    laterbatch = random_batchref(2)\n    otherbatch = random_batchref(3)\n    post_to_add_batch(laterbatch, sku, 100, \"2011-01-02\")\n    post_to_add_batch(earlybatch, sku, 100, \"2011-01-01\")\n    post_to_add_batch(otherbatch, othersku, 100, None)\n    data = {\"orderid\": random_orderid(), \"sku\": sku, \"qty\": 3}\n\n    url = config.get_api_url()\n    r = requests.post(f\"{url}/allocate\", json=data)\n\n    assert r.status_code == 201\n    assert r.json()[\"batchref\"] == earlybatch\n----\n====\n\n\n=== Wrap-Up\n\n(((\"service layer\", \"benefits to test-driven development\")))\n(((\"test-driven development (TDD)\", \"benefits of service layer to\")))\nOnce you have a service layer in place, you really can move the majority\nof your test coverage to unit tests and develop a healthy test pyramid.\n\n[role=\"nobreakinside less_space\"]\n[[types_of_test_rules_of_thumb]]\n.Recap: Rules of Thumb for Different Types of Test\n******************************************************************************\n\nAim for one end-to-end test per feature::\n    This might be written against an HTTP API, for example.  The objective\n    is to demonstrate that the feature works, and that all the moving parts\n    are glued together correctly.\n    (((\"end-to-end tests\", \"aiming for one test per feature\")))\n\nWrite the bulk of your tests against the service layer::\n    These edge-to-edge tests offer a good trade-off between coverage,\n    runtime, and efficiency. Each test tends to cover one code path of a\n    feature and use fakes for I/O. This is the place to exhaustively\n    cover all the edge cases and the ins and outs of your business logic.footnote:[\n    A valid concern about writing tests at a higher level is that it can lead to\n    combinatorial explosion for more complex use cases. In these cases, dropping\n    down to lower-level unit tests of the various collaborating domain objects\n    can be useful. But see also <<chapter_08_events_and_message_bus>> and\n    <<fake_message_bus>>.]\n    (((\"service layer\", \"writing bulk of tests against\")))\n\nMaintain a small core of tests written against your domain model::\n    These tests have highly focused coverage and are more brittle, but they have\n    the highest feedback. Don't be afraid to delete these tests if the\n    functionality is later covered by tests at the service layer.\n    (((\"domain model\", \"maintaining small core of tests written against\")))\n\nError handling counts as a feature::\n    Ideally, your application will be structured such that all errors that\n    bubble up to your entrypoints (e.g., Flask) are handled in the same way.\n    This means you need to test only the happy path for each feature, and to\n    reserve one end-to-end test for all unhappy paths (and many unhappy path\n    unit tests, of course).\n    (((\"test-driven development (TDD)\", startref=\"ix_TDD\")))\n    (((\"error handling\", \"counting as a feature\")))\n\n******************************************************************************\n\nA few\nthings will help along the way:\n\n* Express your service layer in terms of primitives rather than domain objects.\n\n* In an ideal world, you'll have all the services you need to be able to test\n  entirely against the service layer, rather than hacking state via\n  repositories or the database. This pays off in your end-to-end tests as well.\n  (((\"test-driven development (TDD)\", \"types of tests, rules of thumb for\")))\n\nOnto the next chapter!\n"
        },
        {
          "name": "chapter_06_uow.asciidoc",
          "type": "blob",
          "size": 28.478515625,
          "content": "[[chapter_06_uow]]\n== Unit of Work Pattern\n\n(((\"Unit of Work pattern\", id=\"ix_UoW\")))\nIn this chapter we'll introduce the final piece of the puzzle that ties\ntogether the Repository and Service Layer patterns: the _Unit of Work_ pattern.\n\n(((\"UoW\", see=\"Unit of Work pattern\")))\n(((\"atomic operations\")))\nIf the Repository pattern is our abstraction over the idea of persistent storage,\nthe Unit of Work (UoW) pattern is our abstraction over the idea of _atomic operations_. It\nwill allow us to finally and fully decouple our service layer from the data layer.\n\n(((\"Unit of Work pattern\", \"without, API talking directly to three layers\")))\n(((\"APIs\", \"without Unit of Work pattern, talking directly to three layers\")))\n<<before_uow_diagram>> shows that, currently, a lot of communication occurs\nacross the layers of our infrastructure: the API talks directly to the database\nlayer to start a session, it talks to the repository layer to initialize\n`SQLAlchemyRepository`, and it talks to the service layer to ask it to allocate.\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_06_uow branch https://oreil.ly/MoWdZ[on [.keep-together]#GitHub#]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_06_uow\n# or to code along, checkout Chapter 4:\ngit checkout chapter_04_service_layer\n----\n====\n\n[role=\"width-75\"]\n[[before_uow_diagram]]\n.Without UoW: API talks directly to three layers\nimage::images/apwp_0601.png[]\n\n(((\"databases\", \"Unit of Work pattern managing state for\")))\n(((\"Unit of Work pattern\", \"managing database state\")))\n<<after_uow_diagram>> shows our target state. The Flask API now does only two\nthings: it initializes a unit of work, and it invokes a service. The service\ncollaborates with the UoW (we like to think of the UoW as being part of the\nservice layer), but neither the service function itself nor Flask now needs\nto talk directly to the database.\n\n(((\"context manager\")))\nAnd we'll do it all using a lovely piece of Python syntax, a context manager.\n\n[role=\"width-75\"]\n[[after_uow_diagram]]\n.With UoW: UoW now manages database state\nimage::images/apwp_0602.png[]\n\n\n=== The Unit of Work Collaborates with the Repository\n\n//TODO (DS) do you talk anywhere about multiple repositories?\n\n(((\"repositories\", \"Unit of Work collaborating with\")))\n(((\"Unit of Work pattern\", \"collaboration with repository\")))\nLet's see the unit of work (or UoW, which we pronounce \"you-wow\") in action. Here's how the service layer will look when we're finished:\n\n[[uow_preview]]\n.Preview of unit of work in action (src/allocation/service_layer/services.py)\n====\n[source,python]\n----\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:  #<1>\n        batches = uow.batches.list()  #<2>\n        ...\n        batchref = model.allocate(line, batches)\n        uow.commit()  #<3>\n----\n====\n\n<1> We'll start a UoW as a context manager.\n    (((\"context manager\", \"starting Unit of Work as\")))\n\n<2> `uow.batches` is the batches repo, so the UoW provides us\n    access to our permanent storage.\n    (((\"storage\", \"permanent, UoW providing entrypoint to\")))\n\n<3> When we're done, we commit or roll back our work, using the UoW.\n\n(((\"object neighborhoods\")))\n(((\"collaborators\")))\nThe UoW acts as a single entrypoint to our persistent storage, and it\n keeps track of what objects were loaded and of the latest state.footnote:[\nYou may have come across the use of the word _collaborators_ to describe objects that work\ntogether to achieve a goal. The unit of work and the repository are a great\nexample of collaborators in the object-modeling sense.\nIn responsibility-driven design, clusters of objects that collaborate in their\nroles are called _object neighborhoods_, which is, in our professional opinion,\ntotally adorable.]\n\nThis gives us three useful things:\n\n* A stable snapshot of the database to work with, so the\n   objects we use aren't changing halfway through an operation\n\n* A way to persist all of our changes at once, so if something\n   goes wrong, we don't end up in an inconsistent state\n\n* A simple API to our persistence concerns and a handy place\n   to get a repository\n\n\n\n=== Test-Driving a UoW with Integration Tests\n\n(((\"integration tests\", \"test-driving Unit of Work with\")))\n(((\"testing\", \"Unit of Work with integration tests\")))\n(((\"Unit of Work pattern\", \"test driving with integration tests\")))\nHere are our integration tests for the UOW:\n\n\n[[test_unit_of_work]]\n.A basic \"round-trip\" test for a UoW (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef test_uow_can_retrieve_a_batch_and_allocate_to_it(session_factory):\n    session = session_factory()\n    insert_batch(session, \"batch1\", \"HIPSTER-WORKBENCH\", 100, None)\n    session.commit()\n\n    uow = unit_of_work.SqlAlchemyUnitOfWork(session_factory)  #<1>\n    with uow:\n        batch = uow.batches.get(reference=\"batch1\")  #<2>\n        line = model.OrderLine(\"o1\", \"HIPSTER-WORKBENCH\", 10)\n        batch.allocate(line)\n        uow.commit()  #<3>\n\n    batchref = get_allocated_batch_ref(session, \"o1\", \"HIPSTER-WORKBENCH\")\n    assert batchref == \"batch1\"\n----\n====\n\n<1> We initialize the UoW by using our custom session factory\n    and get back a `uow` object to use in our `with` block.\n\n<2> The UoW gives us access to the batches repository via\n    `uow.batches`.\n\n<3> We call `commit()` on it when we're done.\n\n(((\"SQL\", \"helpers for Unit of Work\")))\nFor the curious, the `insert_batch` and `get_allocated_batch_ref` helpers look\nlike this:\n\n[[sql_helpers]]\n.Helpers for doing SQL stuff (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef insert_batch(session, ref, sku, qty, eta):\n    session.execute(\n        \"INSERT INTO batches (reference, sku, _purchased_quantity, eta)\"\n        \" VALUES (:ref, :sku, :qty, :eta)\",\n        dict(ref=ref, sku=sku, qty=qty, eta=eta),\n    )\n\n\ndef get_allocated_batch_ref(session, orderid, sku):\n    [[orderlineid]] = session.execute(  #<1>\n        \"SELECT id FROM order_lines WHERE orderid=:orderid AND sku=:sku\",\n        dict(orderid=orderid, sku=sku),\n    )\n    [[batchref]] = session.execute(  #<1>\n        \"SELECT b.reference FROM allocations JOIN batches AS b ON batch_id = b.id\"\n        \" WHERE orderline_id=:orderlineid\",\n        dict(orderlineid=orderlineid),\n    )\n    return batchref\n----\n====\n\n<1> The `[[orderlineid]] =` syntax is a little too-clever-by-half, apologies.\n    What's happening is that `session.execute` returns a list of rows,\n    where each row is a tuple of column values;\n    in our specific case, it's a list of one row,\n    which is a tuple with one column value in.\n    The double-square-bracket on the left hand side\n    is doing (double) assignment-unpacking to get the single value \n    back out of these two nested sequences.\n    It becomes readable once you've used it a few times!\n\n\n=== Unit of Work and Its Context Manager\n\n(((\"Unit of Work pattern\", \"and its context manager\")))\n(((\"context manager\", \"Unit of Work and\", id=\"ix_ctxtmgr\")))\n(((\"abstractions\", \"AbstractUnitOfWork\")))\nIn our tests we've implicitly defined an interface for what a UoW needs to do. Let's make that explicit by using an abstract\nbase class:\n\n\n[[abstract_unit_of_work]]\n.Abstract UoW context manager (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass AbstractUnitOfWork(abc.ABC):\n    batches: repository.AbstractRepository  #<1>\n\n    def __exit__(self, *args):  #<2>\n        self.rollback()  #<4>\n\n    @abc.abstractmethod\n    def commit(self):  #<3>\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def rollback(self):  #<4>\n        raise NotImplementedError\n----\n====\n\n<1> The UoW provides an attribute called `.batches`, which will give us access\n    to the batches repository.\n\n<2> If you've never seen a context manager, +++<code>__enter__</code>+++ and +++<code>__exit__</code>+++ are\n    the two magic methods that execute when we enter the `with` block and\n    when we exit it, respectively. They're our setup and teardown phases.\n    (((\"magic methods\", \"&#x5f;&#x5f;enter&#x5f;&#x5f; and &#x5f;&#x5f;exit&#x5f;&#x5f;\", secondary-sortas=\"enter\")))\n    (((\"&#x5f;&#x5f;enter&#x5f;&#x5f; and &#x5f;&#x5f;exit&#x5f;&#x5f; magic methods\", primary-sortas=\"enter and exit\")))\n\n<3> We'll call this method to explicitly commit our work when we're ready.\n\n<4> If we don't commit, or if we exit the context manager by raising an error,\n    we do a `rollback`. (The rollback has no effect if `commit()` has been\n    called. Read on for more discussion of this.)\n    (((\"rollbacks\")))\n\n// TODO: bring this code listing back under test, remove `return self` from all the uows.\n\n\n==== The Real Unit of Work Uses SQLAlchemy Sessions\n\n(((\"Unit of Work pattern\", \"and its context manager\", \"real UoW using SQLAlchemy session\")))\n(((\"databases\", \"SQLAlchemy adding session for Unit of Work\")))\n(((\"SQLAlchemy\", \"database session for Unit of Work\")))\nThe main thing that our concrete implementation adds is the\ndatabase session:\n\n[[unit_of_work]]\n.The real SQLAlchemy UoW (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n----\nDEFAULT_SESSION_FACTORY = sessionmaker(  #<1>\n    bind=create_engine(\n        config.get_postgres_uri(),\n    )\n)\n\n\nclass SqlAlchemyUnitOfWork(AbstractUnitOfWork):\n    def __init__(self, session_factory=DEFAULT_SESSION_FACTORY):\n        self.session_factory = session_factory  #<1>\n\n    def __enter__(self):\n        self.session = self.session_factory()  # type: Session  #<2>\n        self.batches = repository.SqlAlchemyRepository(self.session)  #<2>\n        return super().__enter__()\n\n    def __exit__(self, *args):\n        super().__exit__(*args)\n        self.session.close()  #<3>\n\n    def commit(self):  #<4>\n        self.session.commit()\n\n    def rollback(self):  #<4>\n        self.session.rollback()\n----\n====\n\n<1> The module defines a default session factory that will connect to Postgres,\n    but we allow that to be overridden in our integration tests so that we\n    can use SQLite instead.\n\n<2> The +++<code>__enter__</code>+++ method is responsible for starting a database session and instantiating\n    a real repository that can use that session.\n    (((\"&#x5f;&#x5f;enter&#x5f;&#x5f; and &#x5f;&#x5f;exit&#x5f;&#x5f; magic methods\", primary-sortas=\"enter and exit\")))\n\n<3> We close the session on exit.\n\n<4> Finally, we provide concrete `commit()` and `rollback()` methods that\n    use our database session.\n    (((\"commits\", \"commit method\")))\n    (((\"rollbacks\", \"rollback method\")))\n\n//IDEA: why not swap out db using os.environ?\n// (EJ2) Could be a good idea to point out that this couples the unit of work to postgres.\n//         This does get dealt with in in bootstrap, so you could make a forward-reference.\n// (EJ3) IIRC using a factory like this is considered an antipattern (\"Control-Freak\" from M.Seeman's book)\n//         Is there a reason to inject a factory instead of a session?\n// (HP) yes because each unit of work needs to start a new session every time\n// we call __enter__ and close it on __exit__\n\n\n\n==== Fake Unit of Work for Testing\n\n(((\"Unit of Work pattern\", \"and its context manager\", \"fake UoW for testing\")))\n(((\"faking\", \"FakeUnitOfWork for service layer testing\")))\n(((\"testing\", \"fake UoW for service layer testing\")))\nHere's how we use a fake UoW in our service-layer tests:\n\n[[fake_unit_of_work]]\n.Fake UoW (tests/unit/test_services.py)\n====\n[source,python]\n----\nclass FakeUnitOfWork(unit_of_work.AbstractUnitOfWork):\n    def __init__(self):\n        self.batches = FakeRepository([])  #<1>\n        self.committed = False  #<2>\n\n    def commit(self):\n        self.committed = True  #<2>\n\n    def rollback(self):\n        pass\n\n\ndef test_add_batch():\n    uow = FakeUnitOfWork()  #<3>\n    services.add_batch(\"b1\", \"CRUNCHY-ARMCHAIR\", 100, None, uow)  #<3>\n    assert uow.batches.get(\"b1\") is not None\n    assert uow.committed\n\n\ndef test_allocate_returns_allocation():\n    uow = FakeUnitOfWork()  #<3>\n    services.add_batch(\"batch1\", \"COMPLICATED-LAMP\", 100, None, uow)  #<3>\n    result = services.allocate(\"o1\", \"COMPLICATED-LAMP\", 10, uow)  #<3>\n    assert result == \"batch1\"\n...\n----\n====\n\n<1> `FakeUnitOfWork` and `FakeRepository` are tightly coupled,\n    just like the real `UnitofWork` and `Repository` classes.\n    That's fine because we recognize that the objects are collaborators.\n\n<2> Notice the similarity with the fake `commit()` function\n    from `FakeSession` (which we can now get rid of). But it's\n    a substantial improvement because we're now [.keep-together]#faking# out\n    code that we wrote rather than third-party code. Some\n    people say, https://oreil.ly/0LVj3[\"Don't mock what you don't own\"].\n\n<3> In our tests, we can instantiate a UoW and pass it to\n    our service layer, rather than passing a repository and a session.\n    This is considerably less cumbersome.\n\n[role=\"nobreakinside less_space\"]\n.Don't Mock What You Don't Own\n********************************************************************************\n(((\"SQLAlchemy\", \"database session for Unit of Work\", \"not mocking\")))\n(((\"mocking\", \"don&#x27;t mock what you don&#x27;t own\")))\nWhy do we feel more comfortable mocking the UoW than the session?\nBoth of our fakes achieve the same thing: they give us a way to swap out our\npersistence layer so we can run tests in memory instead of needing to\ntalk to a real database. The difference is in the resulting design.\n\nIf we cared only about writing tests that run quickly, we could create mocks\nthat replace SQLAlchemy and use those throughout our codebase. The problem is\nthat `Session` is a complex object that exposes lots of persistence-related\nfunctionality. It's easy to use `Session` to make arbitrary queries against\nthe database, but that quickly leads to data access code being sprinkled all\nover the codebase. To avoid that, we want to limit access to our persistence\nlayer so each component has exactly what it needs and nothing more.\n\nBy coupling to the `Session` interface, you're choosing to couple to all the\ncomplexity of SQLAlchemy. Instead, we want to choose a simpler abstraction and\nuse that to clearly separate responsibilities. Our UoW is much simpler\nthan a session, and we feel comfortable with the service layer being able to\nstart and stop units of work.\n\n\"Don't mock what you don't own\" is a rule of thumb that forces us to build\nthese simple abstractions over messy subsystems. This has the same performance\nbenefit as mocking the SQLAlchemy session but encourages us to think carefully\nabout our designs.\n(((\"context manager\", \"Unit of Work and\", startref=\"ix_ctxtmgr\")))\n********************************************************************************\n\n=== Using the UoW in the Service Layer\n\n(((\"Unit of Work pattern\", \"using UoW in service layer\")))\n(((\"service layer\", \"using Unit of Work in\")))\nHere's what our new service layer looks like:\n\n\n[[service_layer_with_uow]]\n.Service layer using UoW (src/allocation/service_layer/services.py)\n====\n[source,python]\n----\ndef add_batch(\n    ref: str, sku: str, qty: int, eta: Optional[date],\n    uow: unit_of_work.AbstractUnitOfWork,  #<1>\n):\n    with uow:\n        uow.batches.add(model.Batch(ref, sku, qty, eta))\n        uow.commit()\n\n\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,  #<1>\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        batches = uow.batches.list()\n        if not is_valid_sku(line.sku, batches):\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        batchref = model.allocate(line, batches)\n        uow.commit()\n    return batchref\n----\n====\n\n<1> Our service layer now has only the one dependency,\n    once again on an _abstract_ UoW.\n    (((\"dependencies\", \"service layer dependency on abstract UoW\")))\n\n\n=== Explicit Tests for Commit/Rollback Behavior\n\n(((\"commits\", \"explicit tests for\")))\n(((\"rollbacks\", \"explicit tests for\")))\n(((\"testing\", \"integration tests for rollback behavior\")))\n(((\"Unit of Work pattern\", \"explicit tests for commit/rollback behavior\")))\nTo convince ourselves that the commit/rollback behavior works, we wrote\na couple of tests:\n\n[[testing_rollback]]\n.Integration tests for rollback behavior (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef test_rolls_back_uncommitted_work_by_default(session_factory):\n    uow = unit_of_work.SqlAlchemyUnitOfWork(session_factory)\n    with uow:\n        insert_batch(uow.session, \"batch1\", \"MEDIUM-PLINTH\", 100, None)\n\n    new_session = session_factory()\n    rows = list(new_session.execute('SELECT * FROM \"batches\"'))\n    assert rows == []\n\n\ndef test_rolls_back_on_error(session_factory):\n    class MyException(Exception):\n        pass\n\n    uow = unit_of_work.SqlAlchemyUnitOfWork(session_factory)\n    with pytest.raises(MyException):\n        with uow:\n            insert_batch(uow.session, \"batch1\", \"LARGE-FORK\", 100, None)\n            raise MyException()\n\n    new_session = session_factory()\n    rows = list(new_session.execute('SELECT * FROM \"batches\"'))\n    assert rows == []\n----\n====\n\nTIP: We haven't shown it here, but it can be worth testing some of the more\n    \"obscure\" database behavior, like transactions, against the \"real\"\n    database—that is, the same engine. For now, we're getting away with using\n    SQLite instead of Postgres, but in <<chapter_07_aggregate>>, we'll switch\n    some of the tests to using the real database. It's convenient that our UoW\n    class makes that easy!\n    (((\"databases\", \"testing transactions against real database\")))\n\n\n=== Explicit Versus Implicit Commits\n\n(((\"implicit versus explicit commits\")))\n(((\"commits\", \"explicit versus implicit\")))\n(((\"Unit of Work pattern\", \"explicit versus implicit commits\")))\nNow we briefly digress on different ways of implementing the UoW pattern.\n\nWe could imagine a slightly different version of the UoW that commits by default\nand rolls back only if it spots an exception:\n\n[[uow_implicit_commit]]\n.A UoW with implicit commit... (src/allocation/unit_of_work.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n\nclass AbstractUnitOfWork(abc.ABC):\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exn_type, exn_value, traceback):\n        if exn_type is None:\n            self.commit()  #<1>\n        else:\n            self.rollback()  #<2>\n----\n====\n\n<1> Should we have an implicit commit in the happy path?\n<2> And roll back only on exception?\n\nIt would allow us to save a line of code and to remove the explicit commit from our\nclient code:\n\n[[add_batch_nocommit]]\n.\\...would save us a line of code (src/allocation/service_layer/services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\ndef add_batch(ref: str, sku: str, qty: int, eta: Optional[date], uow):\n    with uow:\n        uow.batches.add(model.Batch(ref, sku, qty, eta))\n        # uow.commit()\n----\n====\n\nThis is a judgment call, but we tend to prefer requiring the explicit commit\nso that we have to choose when to flush state.\n\nAlthough we use an extra line of code, this makes the software safe by default.\nThe default behavior is to _not change anything_. In turn, that makes our code\neasier to reason about because there's only one code path that leads to changes\nin the system: total success and an explicit commit. Any other code path, any\nexception, any early exit from the UoW's scope leads to a safe state.\n\nSimilarly, we prefer to roll back by default because\nit's easier to understand; this rolls back to the last commit,\nso either the user did one, or we blow their changes away. Harsh but simple.\n\n=== Examples: Using UoW to Group Multiple Operations into an Atomic Unit\n\n(((\"atomic operations\", \"using Unit of Work to group  operations into atomic unit\", id=\"ix_atomops\")))\n(((\"Unit of Work pattern\", \"using UoW to group multiple operations into atomic unit\", id=\"ix_UoWatom\")))\nHere are a few examples showing the Unit of Work pattern in use. You can\nsee how it leads to simple reasoning about what blocks of code happen\ntogether.\n\n==== Example 1: Reallocate\n\n(((\"Unit of Work pattern\", \"using UoW to group multiple operations into atomic unit\", \"reallocate function example\")))\n(((\"reallocate service function\")))\nSuppose we want to be able to deallocate and then reallocate orders:\n\n[[reallocate]]\n.Reallocate service function\n====\n[source,python]\n[role=\"skip\"]\n----\ndef reallocate(\n    line: OrderLine,\n    uow: AbstractUnitOfWork,\n) -> str:\n    with uow:\n        batch = uow.batches.get(sku=line.sku)\n        if batch is None:\n            raise InvalidSku(f'Invalid sku {line.sku}')\n        batch.deallocate(line)  #<1>\n        allocate(line)  #<2>\n        uow.commit()\n----\n====\n\n<1> If `deallocate()` fails, we don't want to call `allocate()`, obviously.\n<2> If `allocate()` fails, we probably don't want to actually commit\n    the `deallocate()` either.\n\n\n==== Example 2: Change Batch Quantity\n\n(((\"Unit of Work pattern\", \"using UoW to group multiple operations into atomic unit\", \"changing batch quantity example\")))\nOur shipping company gives us a call to say that one of the container doors\nopened, and half our sofas have fallen into the Indian Ocean. Oops!\n\n\n[[change_batch_quantity]]\n.Change quantity\n====\n[source,python]\n[role=\"skip\"]\n----\ndef change_batch_quantity(\n    batchref: str, new_qty: int,\n    uow: AbstractUnitOfWork,\n):\n    with uow:\n        batch = uow.batches.get(reference=batchref)\n        batch.change_purchased_quantity(new_qty)\n        while batch.available_quantity < 0:\n            line = batch.deallocate_one()  #<1>\n        uow.commit()\n----\n====\n\n<1> Here we may need to deallocate any number of lines. If we get a failure\n    at any stage, we probably want to commit none of the changes.\n    (((\"Unit of Work pattern\", \"using UoW to group multiple operations into atomic unit\", startref=\"ix_UoWatom\")))\n    (((\"atomic operations\", \"using Unit of Work to group  operations into atomic unit\", startref=\"ix_atomops\")))\n\n\n=== Tidying Up the Integration Tests\n\n(((\"testing\", \"Unit of Work with integration tests\", \"tidying up tests\")))\n(((\"Unit of Work pattern\", \"tidying up integration tests\")))\nWe now have three sets of tests, all essentially pointing at the database:\n_test_orm.py_, _test_repository.py_, and _test_uow.py_. Should we throw any\naway?\n\n====\n[source,text]\n[role=\"tree\"]\n----\n└── tests\n    ├── conftest.py\n    ├── e2e\n    │   └── test_api.py\n    ├── integration\n    │   ├── test_orm.py\n    │   ├── test_repository.py\n    │   └── test_uow.py\n    ├── pytest.ini\n    └── unit\n        ├── test_allocate.py\n        ├── test_batches.py\n        └── test_services.py\n\n----\n====\n\nYou should always feel free to throw away tests if you think they're not going to\nadd value longer term. We'd say that _test_orm.py_ was primarily a tool to help\nus learn SQLAlchemy, so we won't need that long term, especially if the main things\nit's doing are covered in _test_repository.py_. That last test, you might keep around,\nbut we could certainly see an argument for just keeping everything at the highest\npossible level of abstraction (just as we did for the unit tests).\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n******************************************************************************\nFor this chapter, probably the best thing to try is to implement a\nUoW from scratch. The code, as always, is https://github.com/cosmicpython/code/tree/chapter_06_uow_exercise[on GitHub]. You could either follow the model we have quite closely,\nor perhaps experiment with separating the UoW (whose responsibilities are\n`commit()`, `rollback()`, and providing the `.batches` repository) from the\ncontext manager, whose job is to initialize things, and then do the commit\nor rollback on exit. If you feel like going all-functional rather than\nmessing about with all these classes, you could use `@contextmanager` from\n`contextlib`.\n\nWe've stripped out both the actual UoW and the fakes, as well as paring back\nthe abstract UoW. Why not send us a link to your repo if you come up with\nsomething you're particularly proud of?\n******************************************************************************\n\nTIP: This is another example of the lesson from <<chapter_05_high_gear_low_gear>>:\n    as we build better abstractions, we can move our tests to run against them,\n    which leaves us free to change the underlying details.\n\n\n=== Wrap-Up\n\n(((\"Unit of Work pattern\", \"benefits of using\")))\nHopefully we've convinced you that the Unit of Work pattern is useful, and\nthat the context manager is a really nice Pythonic way\nof visually grouping code into blocks that we want to happen atomically.\n\n(((\"Session object\")))\n(((\"SQLAlchemy\", \"Session object\")))\nThis pattern is so useful, in fact, that SQLAlchemy already uses a UoW\nin the shape of the `Session` object. The `Session` object in SQLAlchemy is the way\nthat your application loads data from the database.\n\nEvery time you load a new entity from the database, the session begins to _track_\nchanges to the entity, and when the session is _flushed_, all your changes are\npersisted together. Why do we go to the effort of abstracting away the SQLAlchemy session if it already implements the pattern we want?\n\n(((\"Unit of Work pattern\", \"pros and cons or trade-offs\")))\n<<chapter_06_uow_tradeoffs>> discusses some of the trade-offs.\n\n[[chapter_06_uow_tradeoffs]]\n[options=\"header\"]\n.Unit of Work pattern: the trade-offs\n|===\n|Pros|Cons\na|\n* We have a nice abstraction over the concept of atomic operations, and the\n  context manager makes it easy to see, visually, what blocks of code are\n  grouped together atomically.\n  (((\"atomic operations\", \"Unit of Work as abstraction over\")))\n  (((\"transactions\", \"Unit of Work and\")))\n\n* We have explicit control over when a transaction starts and finishes, and our\n  application fails in a way that is safe by default. We never have to worry\n  that an operation is partially committed.\n\n* It's a nice place to put all your repositories so client code can access them.\n\n* As you'll see in later chapters, atomicity isn't only about transactions; it\n  can help us work with events and the message bus.\n\na|\n* Your ORM probably already has some perfectly good abstractions around\n  atomicity. SQLAlchemy even has context managers. You can go a long way\n  just passing a session around.\n\n* We've made it look easy, but you have to think quite carefully about\n  things like rollbacks, multithreading, and nested transactions. Perhaps just\n  sticking to what Django or Flask-SQLAlchemy gives you will keep your life\n  simpler.\n  (((\"Unit of Work pattern\", startref=\"ix_UoW\")))\n|===\n\nFor one thing, the Session API is rich and supports operations that we don't\nwant or need in our domain. Our `UnitOfWork` simplifies the session to its\nessential core: it can be started, committed, or thrown away.\n\nFor another, we're using the `UnitOfWork` to access our `Repository` objects.\nThis is a neat bit of developer usability that we couldn't do with a plain\nSQLAlchemy `Session`.\n\n[role=\"nobreakinside less_space\"]\n.Unit of Work Pattern Recap\n*****************************************************************\n(((\"Unit of Work pattern\", \"recap of important points\")))\n\nThe Unit of Work pattern is an abstraction around data integrity::\n    It helps to enforce the consistency of our domain model, and improves\n    performance, by letting us perform a single _flush_ operation at the\n    end of an operation.\n\nIt works closely with the Repository and Service Layer patterns::\n    The Unit of Work pattern completes our abstractions over data access by\n    representing atomic updates. Each of our service-layer use cases runs in a\n    single unit of work that succeeds or fails as a block.\n\nThis is a lovely case for a context manager::\n    Context managers are an idiomatic way of defining scope in Python. We can use a\n    context manager to automatically roll back our work at the end of a request,\n    which means the system is safe by default.\n\nSQLAlchemy already implements this pattern::\n    We introduce an even simpler abstraction over the SQLAlchemy `Session` object\n    in order to \"narrow\" the interface between the ORM and our code. This helps\n    to keep us loosely coupled.\n\n*****************************************************************\n\n(((\"dependency inversion principle\")))\nLastly, we're motivated again by the dependency inversion principle: our\nservice layer depends on a thin abstraction, and we attach a concrete\nimplementation at the outside edge of the system. This lines up nicely with\nSQLAlchemy's own\nhttps://oreil.ly/tS0E0[recommendations]:\n\n[quote, SQLALchemy \"Session Basics\" Documentation]\n____\nKeep the life cycle of the session (and usually the transaction) separate and\nexternal. The most comprehensive approach, recommended for more substantial\napplications, will try to keep the details of session, transaction, and\nexception management as far as possible from the details of the program doing\nits work.\n____\n\n\n//IDEA:  not sure where, but we should maybe talk about the option of separating\n// the uow into a uow plus a uowm.\n"
        },
        {
          "name": "chapter_07_aggregate.asciidoc",
          "type": "blob",
          "size": 44.6552734375,
          "content": "[[chapter_07_aggregate]]\n== Aggregates and Consistency Boundaries\n\n(((\"aggregates\", \"Product aggregate\")))\n(((\"consistency boundaries\")))\n(((\"performance\", \"consistency boundaries and\")))\n(((\"Product object\")))\nIn this chapter, we'd like to revisit our domain model to talk about invariants\nand constraints, and see how our domain objects can maintain their own\ninternal consistency, both conceptually and in persistent storage.  We'll\ndiscuss the concept of a _consistency boundary_ and show how making it\nexplicit can help us to build high-performance software without compromising\nmaintainability.\n\n<<maps_chapter_06>> shows a preview of where we're headed: we'll introduce\na new model object called `Product` to wrap multiple batches, and we'll make\nthe old `allocate()` domain service available as a method on `Product` instead.\n\n[[maps_chapter_06]]\n.Adding the Product aggregate\nimage::images/apwp_0701.png[]\n\n\nWhy? Let's find out.\n\n\n[TIP]\n====\nThe code for this chapter is in the chapter_07_aggregate branch\nhttps://github.com/cosmicpython/code/tree/chapter_07_aggregate[on [.keep-together]#GitHub#]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_07_aggregate\n# or to code along, checkout the previous chapter:\ngit checkout chapter_06_uow\n----\n====\n\n\n=== Why Not Just Run Everything in a Spreadsheet?\n\n(((\"domain model\", \"using spreadsheets instead of\")))\n(((\"spreadsheets, using instead of domain model\")))\nWhat's the point of a domain model, anyway? What's the fundamental problem\nwe're trying to address?\n\nCouldn't we just run everything in a spreadsheet? Many of our users would be\n[.keep-together]#delighted# by that. Business users _like_ spreadsheets because\nthey're simple, familiar, and yet enormously powerful.\n\n(((\"CSV over SMTP architecture\")))\nIn fact, an enormous number of business processes do operate by manually sending\nspreadsheets back and forth over email. This \"CSV over SMTP\" architecture has\nlow initial complexity but tends not to scale very well because it's difficult\nto apply logic and maintain consistency.\n\n// IDEA: better examples?\n\nWho is allowed to view this particular field? Who's allowed to update it? What\nhappens when we try to order –350 chairs, or 10,000,000 tables? Can an employee\nhave a negative salary?\n\nThese are the constraints of a system. Much of the domain logic we write exists\nto enforce these constraints in order to maintain the invariants of the\nsystem. The _invariants_ are the things that have to be true whenever we finish\nan operation.\n\n\n=== Invariants, Constraints, and Consistency\n\n(((\"invariants\", \"invariants, constraints, and consistency\")))\n(((\"domain model\", \"invariants, constraints, and consistency\")))\nThe two words are somewhat interchangeable, but a _constraint_ is a\nrule that restricts the possible states our model can get into, while an _invariant_\nis defined a little more precisely as a condition that is always true.\n\n(((\"constraints\")))\nIf we were writing a hotel-booking system, we might have the constraint that double\nbookings are not allowed. This supports the invariant that a room cannot have more\nthan one booking for the same night.\n\n(((\"consistency\")))\nOf course, sometimes we might need to temporarily _bend_ the rules. Perhaps we\nneed to shuffle the rooms around because of a VIP booking. While we're moving\nbookings around in memory, we might be double booked, but our domain model\nshould ensure that, when we're finished, we end up in a final consistent state,\nwhere the invariants are met. If we can't find a way to accommodate all our guests,\nwe should raise an error and refuse to complete the operation.\n\nLet's look at a couple of concrete examples from our business requirements; we'll start with this one:\n\n[quote, The business]\n____\nAn order line can be allocated to only one batch at a time.\n____\n\n(((\"business rules\", \"invariants, constraints, and consistency\")))\nThis is a business rule that imposes an invariant. The invariant is that an\norder line is allocated to either zero or one batch, but never more than one.\nWe need to make sure that our code never accidentally calls `Batch.allocate()`\non two different batches for the same line, and currently, there's nothing\nthere to explicitly stop us from doing that.\n\n\n==== Invariants, Concurrency, and Locks\n\n(((\"business rules\", \"invariants, concurrency, and locks\")))\nLet's look at another one of our business rules:\n\n[quote, The business]\n____\nWe can't allocate to a batch if the available quantity is less than the\nquantity of the order line.\n____\n\n(((\"invariants\", \"invariants, concurrency, and locks\")))\nHere the constraint is that we can't allocate more stock than is available to a\nbatch, so we never oversell stock by allocating two customers to the same\nphysical cushion, for example. Every time we update the state of the system, our code needs\nto ensure that we don't break the invariant, which is that the available\nquantity must be greater than or equal to zero.\n\nIn a single-threaded, single-user application, it's relatively easy for us to\nmaintain this invariant. We can just allocate stock one line at a time, and\nraise an error if there's no stock available.\n\n(((\"concurrency\")))\nThis gets much harder when we introduce the idea of _concurrency_. Suddenly we\nmight be allocating stock for multiple order lines simultaneously. We might\neven be allocating order lines at the same time as processing changes to the\nbatches [.keep-together]#themselves#.\n\n(((\"locks on database tables\")))\nWe usually solve this problem by applying _locks_ to our database tables. This\nprevents two operations from happening simultaneously on the same row or same\ntable.\n\nAs we start to think about scaling up our app, we realize that our model\nof allocating lines against all available batches may not scale. If we process\ntens of thousands of orders per hour, and hundreds of thousands of\norder lines, we can't hold a lock over the whole `batches` table for\nevery single one--we'll get deadlocks or performance problems at the very least.\n\n\n=== What Is an Aggregate?\n\n(((\"aggregates\", \"about\")))\n(((\"concurrency\", \"allowing for greatest degree of\")))\n(((\"invariants\", \"protecting while allowing concurrency\")))\nOK, so if we can't lock the whole database every time we want to allocate an\norder line, what should we do instead? We want to protect the invariants of our\nsystem but allow for the greatest degree of concurrency. Maintaining our\ninvariants inevitably means preventing concurrent writes; if multiple users can\nallocate `DEADLY-SPOON` at the same time, we run the risk of overallocating.\n\nOn the other hand, there's no reason we can't allocate `DEADLY-SPOON` at the\nsame time as `FLIMSY-DESK`. It's safe to allocate two products at the\nsame time because there's no invariant that covers them both. We don't need them\nto be consistent with each other.\n\n(((\"Aggregate pattern\")))\n(((\"domain driven design (DDD)\", \"Aggregate pattern\")))\nThe _Aggregate_ pattern is a design pattern from the DDD community that helps us\nto resolve this tension. An _aggregate_ is just a domain object that contains\nother domain objects and lets us treat the whole collection as a single unit.\n\nThe only way to modify the objects inside the aggregate is to load the whole\nthing, and to call methods on the aggregate itself.\n\n(((\"collections\")))\nAs a model gets more complex and grows more entity and value objects,\nreferencing each other in a tangled graph, it can be hard to keep track of who\ncan modify what. Especially when we have _collections_ in the model as we do\n(our batches are a collection), it's a good idea to nominate some entities to be\nthe single entrypoint for modifying their related objects. It makes the system\nconceptually simpler and easy to reason about if you nominate some objects to be\nin charge of consistency for the others.\n\nFor example, if we're building a shopping site, the Cart might make a good\naggregate: it's a collection of items that we can treat as a single unit.\nImportantly, we want to load the entire basket as a single blob from our data\nstore. We don't want two requests to modify the basket at the same time, or we\nrun the risk of weird concurrency errors. Instead, we want each change to the\nbasket to run in a single database transaction.\n\n(((\"consistency boundaries\")))\nWe don't want to modify multiple baskets in a transaction, because there's no\nuse case for changing the baskets of several customers at the same time. Each\nbasket is a single _consistency boundary_ responsible for maintaining its own\ninvariants.\n\n[quote, Eric Evans, Domain-Driven Design blue book]\n____\nAn AGGREGATE is a cluster of associated objects that we treat as a unit for the\npurpose of data changes.\n(((\"Evans, Eric\")))\n____\n\nPer Evans, our aggregate has a root entity (the Cart) that encapsulates access\nto items. Each item has its own identity, but other parts of the system will always\nrefer to the Cart only as an indivisible whole.\n\nTIP: Just as we sometimes use pass:[<code><em>_leading_underscores</em></code>] to mark methods or functions\n    as \"private,\" you can think of aggregates as being the \"public\" classes of our\n    model, and the rest of the entities and value objects as \"private.\"\n\n=== Choosing an Aggregate\n\n(((\"performance\", \"impact of using aggregates\")))\n(((\"aggregates\", \"choosing an aggregrate\", id=\"ix_aggch\")))\nWhat aggregate should we use for our system? The choice is somewhat arbitrary,\nbut it's important. The aggregate will be the boundary where we make sure\nevery operation ends in a consistent state. This helps us to reason about our\nsoftware and prevent weird race issues. We want to draw a boundary around a\nsmall number of objects—the smaller, the better, for performance—that have to\nbe consistent with one another, and we need to give this boundary a good name.\n\n(((\"batches\", \"collection of\")))\nThe object we're manipulating under the covers is `Batch`. What do we call a\ncollection of batches? How should we divide all the batches in the system into\ndiscrete islands of consistency?\n\nWe _could_ use `Shipment` as our boundary. Each shipment contains several\nbatches, and they all travel to our warehouse at the same time. Or perhaps we\ncould use `Warehouse` as our boundary: each warehouse contains many batches,\nand counting all the stock at the same time could make sense.\n\nNeither of these concepts really satisfies us, though. We should be able to\nallocate `DEADLY-SPOONs` or `FLIMSY-DESKs` in one go, even if they're not in the\nsame warehouse or the same shipment. These concepts have the wrong granularity.\n\nWhen we allocate an order line, we're interested only in batches\nthat have the same SKU as the order line. Some sort of concept like\n`GlobalSkuStock` could work: a collection of all the batches for a given SKU.\n\nIt's an unwieldy name, though, so after some bikeshedding via `SkuStock`, `Stock`,\n`ProductStock`, and so on, we decided to simply call it `Product`—after all,\nthat was the first concept we came across in our exploration of the\ndomain language back in <<chapter_01_domain_model>>.\n\n(((\"allocate service\", \"allocating against all batches with\")))\n(((\"batches\", \"allocating against all batches using domain service\")))\nSo the plan is this: when we want to allocate an order line, instead of\n<<before_aggregates_diagram>>, where we look up all the `Batch` objects in\nthe world and pass them to the `allocate()` domain service...\n\n[role=\"width-60\"]\n[[before_aggregates_diagram]]\n.Before: allocate against all batches using the domain service\nimage::images/apwp_0702.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0702, config=plantuml.cfg]\n@startuml\nscale 4\n\nhide empty members\n\npackage \"Service Layer\" as services {\n    class \"allocate()\" as allocate {\n    }\n    hide allocate circle\n    hide allocate members\n}\n\n\n\npackage \"Domain Model\" as domain_model {\n\n  class Batch {\n  }\n\n  class \"allocate()\" as allocate_domain_service {\n  }\n    hide allocate_domain_service circle\n    hide allocate_domain_service members\n}\n\n\npackage Repositories {\n\n  class BatchRepository {\n    list()\n  }\n\n}\n\nallocate -> BatchRepository: list all batches\nallocate --> allocate_domain_service: allocate(orderline, batches)\n\n@enduml\n----\n\n(((\"batches\", \"asking Product to allocate against\")))\n(((\"Product object\", \"asking Product to allocate against its batches\")))\n...we'll move to the world of <<after_aggregates_diagram>>, in which there is a new\n`Product` object for the particular SKU of our order line, and it will be in charge\nof all the batches _for that SKU_, and we can call a `.allocate()` method on that\ninstead.\n\n[role=\"width-75\"]\n[[after_aggregates_diagram]]\n.After: ask Product to allocate against its batches\nimage::images/apwp_0703.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0703, config=plantuml.cfg]\n@startuml\nscale 4\n\nhide empty members\n\npackage \"Service Layer\" as services {\n    class \"allocate()\" as allocate {\n    }\n}\n\nhide allocate circle\nhide allocate members\n\n\npackage \"Domain Model\" as domain_model {\n\n  class Product {\n    allocate()\n  }\n\n  class Batch {\n  }\n}\n\n\npackage Repositories {\n\n  class ProductRepository {\n    get()\n  }\n\n}\n\nallocate -> ProductRepository: get me the product for this SKU\nallocate --> Product: product.allocate(orderline)\nProduct o- Batch: has\n\n@enduml\n----\n\n(((\"Product object\", \"code for\")))\nLet's see how that looks in code form:\n\n[role=\"pagebreak-before\"]\n[[product_aggregate]]\n.Our chosen aggregate, Product (src/allocation/domain/model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass Product:\n    def __init__(self, sku: str, batches: List[Batch]):\n        self.sku = sku  #<1>\n        self.batches = batches  #<2>\n\n    def allocate(self, line: OrderLine) -> str:  #<3>\n        try:\n            batch = next(b for b in sorted(self.batches) if b.can_allocate(line))\n            batch.allocate(line)\n            return batch.reference\n        except StopIteration:\n            raise OutOfStock(f\"Out of stock for sku {line.sku}\")\n----\n====\n\n<1> ``Product``'s main identifier is the `sku`.\n\n<2> Our `Product` class holds a reference to a collection of `batches` for that SKU.\n    (((\"allocate service\", \"moving to be a method on Product aggregate\")))\n\n<3> Finally, we can move the `allocate()` domain service to\n    be a method on the [.keep-together]#`Product`# aggregate.\n\n// IDEA (hynek): random nitpick: exceptions denoting errors should be\n// named *Error.  Are you doing this to save space in the listing?\n\n//IDEA: talk about magic methods on aggregates maybe?  ie, a non-aggregate entity\n//      might have a __hash__ so that we can put it into a set, but because you\n//      are never supposed to have a collection of aggregates, they could return\n//      an error for __hash__. or sumfink.\n\nNOTE: This `Product` might not look like what you'd expect a `Product`\n    model to look like.  No price, no description, no dimensions.\n    Our allocation service doesn't care about any of those things.\n    This is the power of bounded contexts; the concept\n    of a product in one app can be very different from another.\n    See the following sidebar for more discussion.\n    (((\"bounded contexts\", \"product concept and\")))\n\n\n[role=\"nobreakinside less_space\"]\n[[bounded_contexts_sidebar]]\n.Aggregates, Bounded Contexts, and Microservices\n*******************************************************************************\n(((\"bounded contexts\")))\nOne of the most important contributions from Evans and the DDD community\nis the concept of\nhttps://martinfowler.com/bliki/BoundedContext.html[_bounded contexts_].\n\n(((\"domain driven design (DDD)\", \"bounded contexts\")))\nIn essence, this was a reaction against attempts to capture entire businesses\ninto a single model. The word _customer_ means different things to people\nin sales, customer service, logistics, support, and so on. Attributes\nneeded in one context are irrelevant in another; more perniciously, concepts\nwith the same name can have entirely different meanings in different contexts.\nRather than trying to build a single model (or class, or database) to capture\nall the use cases, it's better to have several models, draw boundaries\naround each context, and handle the translation between different contexts\nexplicitly.\n\n(((\"microservices\", \"bounded contexts and\")))\nThis concept translates very well to the world of microservices, where each\nmicroservice is free to have its own concept of \"customer\" and its own rules for\ntranslating that to and from other microservices it integrates with.\n\nIn our example, the allocation service has `Product(sku, batches)`,\nwhereas the ecommerce will have `Product(sku, description, price, image_url,\ndimensions, etc...)`. As a rule of thumb, your domain models should\ninclude only the data that they need for performing calculations.\n\nWhether or not you have a microservices architecture, a key consideration\nin choosing your aggregates is also choosing the bounded context that they\nwill operate in. By restricting the context, you can keep your number of\naggregates low and their size manageable.\n\n(((\"aggregates\", \"choosing an aggregrate\", startref=\"ix_aggch\")))\nOnce again, we find ourselves forced to say that we can't give this issue\nthe treatment it deserves here, and we can only encourage you to read up on it\nelsewhere. The Fowler link at the start of this sidebar is a good starting point, and either\n(or indeed, any) DDD book will have a chapter or more on bounded contexts.\n\n*******************************************************************************\n\n=== One Aggregate = One Repository\n\n(((\"aggregates\", \"one aggregrate &#x3D; one repository\")))\n(((\"repositories\", \"one aggregrate &#x3D; one repository\")))\nOnce you define certain entities to be aggregates, we need to apply the rule\nthat they are the only entities that are publicly accessible to the outside\nworld.  In other words, the only repositories we are allowed should be\nrepositories that return aggregates.\n\nNOTE: The rule that repositories should only return aggregates is the main place\n    where we enforce the convention that aggregates are the only way into our\n    domain model.  Be wary of breaking it!\n\n(((\"Unit of Work pattern\", \"UoW and product repository\")))\n(((\"ProductRepository object\")))\nIn our case, we'll switch from `BatchRepository` to `ProductRepository`:\n\n\n[[new_uow_and_repository]]\n.Our new UoW and repository (unit_of_work.py and repository.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass AbstractUnitOfWork(abc.ABC):\n    products: repository.AbstractProductRepository\n\n...\n\nclass AbstractProductRepository(abc.ABC):\n\n    @abc.abstractmethod\n    def add(self, product):\n        ...\n\n    @abc.abstractmethod\n    def get(self, sku) -> model.Product:\n        ...\n----\n====\n\n(((\"Product object\", \"service layer using\")))\n(((\"service layer\", \"using Product objects\")))\n(((\"object-relational mappers (ORMs)\", \"associating right batches with Product objects\")))\nThe ORM layer will need some tweaks so that the right batches automatically get\nloaded and associated with `Product` objects. The nice thing is, the Repository\npattern means we don't have to worry about that yet. We can just use\nour `FakeRepository` and then feed through the new model into our service\nlayer to see how it looks with `Product` as its main entrypoint:\n\n[[service_layer_uses_products]]\n.Service layer (src/allocation/service_layer/services.py)\n====\n[source,python]\n----\ndef add_batch(\n    ref: str, sku: str, qty: int, eta: Optional[date],\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    with uow:\n        product = uow.products.get(sku=sku)\n        if product is None:\n            product = model.Product(sku, batches=[])\n            uow.products.add(product)\n        product.batches.append(model.Batch(ref, sku, qty, eta))\n        uow.commit()\n\n\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        product = uow.products.get(sku=line.sku)\n        if product is None:\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        batchref = product.allocate(line)\n        uow.commit()\n    return batchref\n----\n====\n\n=== What About Performance?\n\n(((\"performance\", \"impact of using aggregates\")))\n(((\"aggregates\", \"performance and\")))\nWe've mentioned a few times that we're modeling with aggregates because we want\nto have high-performance software, but here we are loading _all_ the batches when\nwe only need one. You might expect that to be inefficient, but there are a few\nreasons why we're comfortable here.\n\nFirst, we're purposefully modeling our data so that we can make a single\nquery to the database to read, and a single update to persist our changes. This\ntends to perform much better than systems that issue lots of ad hoc queries. In\nsystems that don't model this way, we often find that transactions slowly\nget longer and more complex as the software evolves.\n\nSecond, our data structures are minimal and comprise a few strings and\nintegers per row. We can easily load tens or even hundreds of batches in a few\nmilliseconds.\n\nThird, we expect to have only 20 or so batches of each product at a time.\nOnce a batch is used up, we can discount it from our calculations. This means\nthat the amount of data we're fetching shouldn't get out of control over time.\n\nIf we _did_ expect to have thousands of active batches for a product, we'd have\na couple of options. For one, we could use lazy-loading for the batches in a\nproduct. From the perspective of our code, nothing would change, but in the\nbackground, SQLAlchemy would page through data for us. This would lead to more\nrequests, each fetching a smaller number of rows. Because we need to find only a\nsingle batch with enough capacity for our order, this might work pretty well.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n******************************************************************************\n(((\"aggregates\", \"exercise for the reader\")))\nYou've just seen the main top layers of the code, so this shouldn't be too hard,\nbut we'd like you to implement the `Product` aggregate starting from `Batch`,\njust as we did.\n\nOf course, you could cheat and copy/paste from the previous listings, but even\nif you do that, you'll still have to solve a few challenges on your own,\nlike adding the model to the ORM and making sure all the moving parts can\ntalk to each other, which we hope will be instructive.\n\nYou'll find the code https://github.com/cosmicpython/code/tree/chapter_07_aggregate_exercise[on GitHub].\nWe've put in a \"cheating\" implementation in the delegates to the existing\n`allocate()` function, so you should be able to evolve that toward the real\nthing.\n\n(((\"pytest\", \"@pytest.skip\")))\nWe've marked a couple of tests with `@pytest.skip()`. After you've read the\nrest of this chapter, come back to these tests to have a go at implementing\nversion numbers. Bonus points if you can get SQLAlchemy to do them for you by\nmagic!\n\n******************************************************************************\n\nIf all else failed, we'd just look for a different aggregate. Maybe we could\nsplit up batches by region or by warehouse. Maybe we could redesign our data\naccess strategy around the shipment concept. The Aggregate pattern is designed\nto help manage some technical constraints around consistency and performance.\nThere isn't _one_ correct aggregate, and we should feel comfortable changing our\nminds if we find our boundaries are causing performance woes.\n\n\n=== Optimistic Concurrency with Version Numbers\n\n(((\"concurrency\", \"optimistic concurrency with version numbers\", id=\"ix_concopt\")))\n(((\"optimistic concurrency with version numbers\", id=\"ix_opticonc\")))\n(((\"aggregates\", \"optimistic concurrency with version numbers\", id=\"ix_aggopticon\")))\nWe have our new aggregate, so we've solved the conceptual problem of choosing\nan object to be in charge of consistency boundaries.  Let's now spend a little\ntime talking about how to enforce data integrity at the database level.\n\nNOTE: This section has a lot of implementation details; for example, some of it\n    is Postgres-specific. But more generally, we're showing one way of managing\n    concurrency issues, but it is just one approach. Real requirements in this\n    area vary a lot from project to project. You shouldn't expect to be able to\n    copy and paste code from here into production.\n    (((\"PostgreSQL\", \"managing concurrency issues\")))\n\n(((\"locks on database tables\", \"optimistic locking\")))\nWe don't want to hold a lock over the entire `batches` table, but how will we\nimplement holding a lock over just the rows for a particular SKU?\n\n(((\"version numbers\", \"in the products table, implementing optimistic locking\")))\nOne answer is to have a single attribute on the `Product` model that acts as a marker for\nthe whole state change being complete and to use it as the single resource\nthat concurrent workers can fight over. If two transactions read the\nstate of the world for `batches` at the same time, and both want to update\nthe `allocations` tables, we force both to also try to update the\n`version_number` in the `products` table, in such a way that only one of them\ncan win and the world stays consistent.\n\n(((\"transactions\", \"concurrent, attempting update on Product\")))\n(((\"Product object\", \"two transactions attempting concurrent update on\")))\n<<version_numbers_sequence_diagram>> illustrates two concurrent\ntransactions doing their read operations at the same time, so they see\na `Product` with, for example, `version=3`.  They both call `Product.allocate()`\nin order to modify a state. But we set up our database integrity\nrules such that only one of them is allowed to `commit` the new `Product`\nwith `version=4`, and the other update is rejected.\n\nTIP: Version numbers are just one way to implement optimistic locking. You\n    could achieve the same thing by setting the Postgres transaction isolation\n    level to `SERIALIZABLE`, but that often comes at a severe performance cost.\n    Version numbers also make implicit concepts explicit.\n    (((\"PostgreSQL\", \"SERIALIZABLE transaction isolation level\")))\n\n[[version_numbers_sequence_diagram]]\n.Sequence diagram: two transactions attempting a concurrent update on [.keep-together]#`Product`#\nimage::images/apwp_0704.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0704, config=plantuml.cfg]\n@startuml\nscale 4\n\nentity Model\ncollections Transaction1\ncollections Transaction2\ndatabase Database\n\n\nTransaction1 -> Database: get product\nDatabase -> Transaction1: Product(version=3)\nTransaction2 -> Database: get product\nDatabase -> Transaction2: Product(version=3)\nTransaction1 -> Model: Product.allocate()\nModel -> Transaction1: Product(version=4)\nTransaction2 -> Model: Product.allocate()\nModel -> Transaction2: Product(version=4)\nTransaction1 -> Database: commit Product(version=4)\nDatabase -[#green]> Transaction1: OK\nTransaction2 -> Database: commit Product(version=4)\nDatabase -[#red]>x Transaction2: Error! version is already 4\n\n@enduml\n----\n\n\n[role=\"nobreakinside less_space\"]\n.Optimistic Concurrency Control and Retries\n********************************************************************************\n\nWhat we've implemented here is called _optimistic_ concurrency control because\nour default assumption is that everything will be fine when two users want to\nmake changes to the database. We think it's unlikely that they will conflict\nwith each other, so we let them go ahead and just make sure we have a way to\nnotice if there is a [.keep-together]#problem#.\n\n(((\"pessimistic concurrency\")))\n(((\"locks on database tables\", \"pessimistic locking\")))\n(((\"SELECT FOR UPDATE statement\")))\n_Pessimistic_ concurrency control works under the assumption that two users\nare going to cause conflicts, and we want to prevent conflicts in all cases, so\nwe lock everything just to be safe. In our example, that would mean locking\nthe whole `batches` table, or using ++SELECT FOR UPDATE++—we're pretending\nthat we've ruled those out for performance reasons, but in real life you'd\nwant to do some evaluations and measurements of your own.\n\n(((\"locks on database tables\", \"optimistic locking\")))\nWith pessimistic locking, you don't need to think about handling failures\nbecause the database will prevent them for you (although you do need to think\nabout deadlocks). With optimistic locking, you need to explicitly handle\nthe possibility of failures in the (hopefully unlikely) case of a clash.\n\n(((\"retries\", \"optimistic concurrency control and\")))\nThe usual way to handle a failure is to retry the failed operation from the\nbeginning. Imagine we have two customers, Harry and Bob, and each submits an order\nfor `SHINY-TABLE`. Both threads load the product at version 1 and allocate\nstock. The database prevents the concurrent update, and Bob's order fails with\nan error. When we _retry_ the operation, Bob's order loads the product at\nversion 2 and tries to allocate again. If there is enough stock left, all is\nwell; otherwise, he'll receive `OutOfStock`. Most operations can be retried this\nway in the case of a concurrency problem.\n\nRead more on retries in <<recovering_from_errors>> and <<footguns>>.\n********************************************************************************\n\n\n==== Implementation Options for Version Numbers\n\n(((\"Product object\", \"version numbers implemented on\")))\n(((\"version numbers\", \"implementation options for\")))\nThere are essentially three options for implementing version numbers:\n\n1. `version_number` lives in the domain; we add it to the `Product` constructor,\n   and `Product.allocate()` is responsible for incrementing it.\n\n2. The service layer could do it!  The version number isn't _strictly_ a domain\n   concern, so instead our service layer could assume that the current version number\n   is attached to `Product` by the repository, and the service layer will increment it\n   before it does the `commit()`.\n\n3. Since it's arguably an infrastructure concern, the UoW and repository\n   could do it by magic.  The repository has access to version numbers for any\n   products it retrieves, and when the UoW does a commit, it can increment the\n   version number for any products it knows about, assuming them to have changed.\n\nOption 3 isn't ideal, because there's no real way of doing it without having to\nassume that _all_ products have changed, so we'll be incrementing version numbers\nwhen we don't have to.footnote:[Perhaps we could get some ORM/SQLAlchemy magic to tell\nus when an object is dirty, but how would that work in the generic case—for example, for a\n`CsvRepository`?]\n\nOption 2 involves mixing the responsibility for mutating state between the service\nlayer and the domain layer, so it's a little messy as well.\n\nSo in the end, even though version numbers don't _have_ to be a domain concern,\nyou might decide the cleanest trade-off is to put them in the domain:\n\n[[product_aggregate_with_version_number]]\n.Our chosen aggregate, Product (src/allocation/domain/model.py)\n====\n[source,python]\n----\nclass Product:\n    def __init__(self, sku: str, batches: List[Batch], version_number: int = 0):  #<1>\n        self.sku = sku\n        self.batches = batches\n        self.version_number = version_number  #<1>\n\n    def allocate(self, line: OrderLine) -> str:\n        try:\n            batch = next(b for b in sorted(self.batches) if b.can_allocate(line))\n            batch.allocate(line)\n            self.version_number += 1  #<1>\n            return batch.reference\n        except StopIteration:\n            raise OutOfStock(f\"Out of stock for sku {line.sku}\")\n----\n====\n\n<1> There it is!\n\nTIP: If you're scratching your head at this version number business, it might\n    help to remember that the _number_ isn't important. What's important is\n    that the `Product` database row is modified whenever we make a change to the\n    `Product` aggregate. The version number is a simple, human-comprehensible way\n    to model a thing that changes on every write, but it could equally be a\n    random UUID every time.\n    (((\"concurrency\", \"optimistic concurrency with version numbers\", startref=\"ix_concopt\")))\n    (((\"optimistic concurrency with version numbers\", startref=\"ix_opticonc\")))\n    (((\"aggregates\", \"optimistic concurrency with version numbers\", startref=\"ix_aggopticon\")))\n\n\n=== Testing for Our Data Integrity Rules\n\n(((\"data integrity\", \"testing for\", id=\"ix_daint\")))\n(((\"aggregates\", \"testing for data integrity rules\", id=\"ix_aggtstdi\")))\n(((\"testing\", \"for data integrity rules\", id=\"ix_tstdi\")))\nNow to make sure we can get the behavior we want: if we have two\nconcurrent attempts to do allocation against the same `Product`, one of them\nshould fail, because they can't both update the version number.\n\n(((\"time.sleep function\")))\n(((\"time.sleep function\", \"reproducing concurrency behavior with\")))\n(((\"concurrency\", \"reproducing behavior with time.sleep function\")))\n(((\"transactions\", \"simulating a slow transaction\")))\nFirst, let's simulate a \"slow\" transaction using a function that does\nallocation and then does an explicit sleep:footnote:[`time.sleep()` works well\nin our use case, but it's not the most reliable or efficient way to reproduce\nconcurrency bugs.  Consider using semaphores or similar synchronization primitives\nshared between your threads to get better guarantees of behavior.]\n\n[[time_sleep_thread]]\n.time.sleep can reproduce concurrency behavior (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef try_to_allocate(orderid, sku, exceptions):\n    line = model.OrderLine(orderid, sku, 10)\n    try:\n        with unit_of_work.SqlAlchemyUnitOfWork() as uow:\n            product = uow.products.get(sku=sku)\n            product.allocate(line)\n            time.sleep(0.2)\n            uow.commit()\n    except Exception as e:\n        print(traceback.format_exc())\n        exceptions.append(e)\n----\n====\n\n\n(((\"integration tests\", \"for concurrency behavior\")))\n(((\"concurrency\", \"integration test for\")))\nThen we have our test invoke this slow allocation twice, concurrently, using\nthreads:\n\n[[data_integrity_test]]\n.An integration test for concurrency behavior (tests/integration/test_uow.py)\n====\n[source,python]\n----\ndef test_concurrent_updates_to_version_are_not_allowed(postgres_session_factory):\n    sku, batch = random_sku(), random_batchref()\n    session = postgres_session_factory()\n    insert_batch(session, batch, sku, 100, eta=None, product_version=1)\n    session.commit()\n\n    order1, order2 = random_orderid(1), random_orderid(2)\n    exceptions = []  # type: List[Exception]\n    try_to_allocate_order1 = lambda: try_to_allocate(order1, sku, exceptions)\n    try_to_allocate_order2 = lambda: try_to_allocate(order2, sku, exceptions)\n    thread1 = threading.Thread(target=try_to_allocate_order1)  #<1>\n    thread2 = threading.Thread(target=try_to_allocate_order2)  #<1>\n    thread1.start()\n    thread2.start()\n    thread1.join()\n    thread2.join()\n\n    [[version]] = session.execute(\n        \"SELECT version_number FROM products WHERE sku=:sku\",\n        dict(sku=sku),\n    )\n    assert version == 2  #<2>\n    [exception] = exceptions\n    assert \"could not serialize access due to concurrent update\" in str(exception)  #<3>\n\n    orders = session.execute(\n        \"SELECT orderid FROM allocations\"\n        \" JOIN batches ON allocations.batch_id = batches.id\"\n        \" JOIN order_lines ON allocations.orderline_id = order_lines.id\"\n        \" WHERE order_lines.sku=:sku\",\n        dict(sku=sku),\n    )\n    assert orders.rowcount == 1  #<4>\n    with unit_of_work.SqlAlchemyUnitOfWork() as uow:\n        uow.session.execute(\"select 1\")\n----\n====\n\n<1> We start two threads that will reliably produce the concurrency behavior we\n    want: `read1, read2, write1, write2`.\n\n<2> We assert that the version number has been incremented only once.\n\n<3> We can also check on the specific exception if we like.\n\n<4> And we double-check that only one allocation has gotten through.\n\n// TODO: use \"\"\" syntax for sql literal above?\n\n\n==== Enforcing Concurrency Rules by Using Database Transaction [.keep-together]#Isolation Levels#\n\n(((\"transactions\", \"using to enforce concurrency rules\")))\n(((\"concurrency\", \"enforcing rules using database transactions\")))\nTo get the test to pass as it is, we can set the transaction isolation level\non our session:\n\n[[isolation_repeatable_read]]\n.Set isolation level for session (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n----\nDEFAULT_SESSION_FACTORY = sessionmaker(\n    bind=create_engine(\n        config.get_postgres_uri(),\n        isolation_level=\"REPEATABLE READ\",\n    )\n)\n----\n====\n\nTIP: Transaction isolation levels are tricky stuff, so it's worth spending time\n    understanding https://oreil.ly/5vxJA[the Postgres documentation].footnote:[If\n    you're not using Postgres, you'll need to read different documentation.\n    Annoyingly, different databases all have quite different definitions.\n    Oracle's `SERIALIZABLE` is equivalent to Postgres's `REPEATABLE READ`, for\n    [.keep-together]#example#.]\n    (((\"PostgreSQL\", \"documentation for transaction isolation levels\")))\n    (((\"isolation levels (transaction)\")))\n\n==== Pessimistic Concurrency Control Example: SELECT FOR UPDATE\n\n(((\"pessimistic concurrency\", \"example, SELECT FOR UPDATE\")))\n(((\"concurrency\", \"pessimistic concurrency example, SELECT FOR UPDATE\")))\n(((\"SELECT FOR UPDATE statement\", \"pessimistic concurrency control example with\")))\nThere are multiple ways to approach this, but we'll show one. https://oreil.ly/i8wKL[`SELECT FOR UPDATE`]\nproduces different behavior; two concurrent transactions will not be allowed to\ndo a read on the same rows at the same time:\n\n(((\"SQLAlchemy\", \"using DSL to specify FOR UPDATE\")))\n`SELECT FOR UPDATE` is a way of picking a row or rows to use as a lock\n(although those rows don't have to be the ones you update).  If two\ntransactions both try to `SELECT FOR UPDATE` a row at the same time, one will\nwin, and the other will wait until the lock is released. So this is an example\nof pessimistic concurrency control.\n\nHere's how you can use the SQLAlchemy DSL to specify `FOR UPDATE` at\nquery time:\n\n[[with_for_update]]\n.SQLAlchemy with_for_update (src/allocation/adapters/repository.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n    def get(self, sku):\n        return (\n            self.session.query(model.Product)\n            .filter_by(sku=sku)\n            .with_for_update()\n            .first()\n        )\n----\n====\n\n\nThis will have the effect of changing the concurrency pattern from\n\n[role=\"skip\"]\n----\nread1, read2, write1, write2(fail)\n----\n\nto\n\n[role=\"skip\"]\n----\nread1, write1, read2, write2(succeed)\n----\n\n(((\"PostgreSQL\", \"Anti-Patterns: Read-Modify-Write Cycles\")))\n(((\"read-modify-write failure mode\")))\nSome people refer to this as the \"read-modify-write\" failure mode.\nRead https://oreil.ly/uXeZI[\"PostgreSQL Anti-Patterns: Read-Modify-Write Cycles\"] for a good [.keep-together]#overview#.\n\n//TODO maybe better diagrams here?\n\n(((\"data integrity\", \"testing for\", startref=\"ix_daint\")))\n(((\"testing\", \"for data integrity rules\", startref=\"ix_tstdi\")))\nWe don't really have time to discuss all the trade-offs between `REPEATABLE READ`\nand `SELECT FOR UPDATE`, or optimistic versus pessimistic locking in general.\nBut if you have a test like the one we've shown, you can specify the behavior\nyou want and see how it changes. You can also use the test as a basis for\nperforming some performance experiments.(((\"aggregates\", \"testing for data integrity rules\", startref=\"ix_aggtstdi\")))\n\n\n\n=== Wrap-Up\n\n(((\"aggregates\", \"and consistency boundaries recap\")))\nSpecific choices around concurrency control vary a lot based on business\ncircumstances and storage technology choices, but we'd like to bring this\nchapter back to the conceptual idea of an aggregate: we explicitly model an\nobject as being the main entrypoint to some subset of our model, and as being in\ncharge of enforcing the invariants and business rules that apply across all of\nthose objects.\n\n(((\"Effective Aggregate Design (Vernon)\")))\n(((\"Vernon, Vaughn\")))\n(((\"domain driven design (DDD)\", \"choosing the right aggregate, references on\")))\nChoosing the right aggregate is key, and it's a decision you may revisit\nover time. You can read more about it in multiple DDD books.\nWe also recommend these three online papers on\nhttps://dddcommunity.org/library/vernon_2011[effective aggregate design]\nby Vaughn Vernon (the \"red book\" author).\n\n(((\"aggregates\", \"pros and cons or trade-offs\")))\n<<chapter_07_aggregate_tradoffs>> has some thoughts on the trade-offs of implementing the Aggregate pattern.\n\n[[chapter_07_aggregate_tradoffs]]\n[options=\"header\"]\n.Aggregates: the trade-offs\n|===\n|Pros|Cons\na|\n* Python might not have \"official\" public and private methods, but we do have\n  the underscores convention, because it's often useful to try to indicate what's for\n  \"internal\" use and what's for \"outside code\" to use. Choosing aggregates is\n  just the next level up: it lets you decide which of your domain model classes\n  are the public ones, and which aren't.\n\n* Modeling our operations around explicit consistency boundaries helps us avoid\n  performance problems with our ORM.\n  (((\"performance\", \"consistency boundaries and\")))\n\n* Putting the aggregate in sole charge of state changes to its subsidiary models\n  makes the system easier to reason about, and makes it easier to control invariants.\n\na|\n* Yet another new concept for new developers to take on. Explaining entities versus\n  value objects was already a mental load; now there's a third type of domain\n  model object?\n\n* Sticking rigidly to the rule that we modify only one aggregate at a time is a\n  big mental shift.\n\n* Dealing with eventual consistency between aggregates can be complex.\n|===\n\n\n[role=\"nobreakinside less_space\"]\n.Aggregates and Consistency Boundaries Recap\n*****************************************************************\n(((\"consistency boundaries\", \"recap\")))\n\nAggregates are your entrypoints into the domain model::\n    By restricting the number of ways that things can be changed,\n    we make the system easier to reason about.\n\nAggregates are in charge of a consistency boundary::\n    An aggregate's job is to be able to manage our business rules\n    about invariants as they apply to a group of related objects.\n    It's the aggregate's job to check that the objects within its\n    remit are consistent with each other and with our rules, and\n    to reject changes that would break the rules.\n\nAggregates and concurrency issues go together::\n    When thinking about implementing these consistency checks, we\n    end up thinking about transactions and locks.  Choosing the\n    right aggregate is about performance as well as conceptual\n    organization of your domain.\n    (((\"concurrency\", \"aggregates and concurrency issues\")))\n\n*****************************************************************\n\n[role=\"pagebreak-before less_space\"]\n=== Part I Recap\n\n(((\"component diagram at end of Part One\")))\nDo you remember <<recap_components_diagram>>, the diagram we showed at the\nbeginning of <<part1>> to preview where we were heading?\n\n[role=\"width-75\"]\n[[recap_components_diagram]]\n.A component diagram for our app at the end of Part I\nimage::images/apwp_0705.png[]\n\nSo that's where we are at the end of Part I. What have we achieved? We've\nseen how to build a domain model that's exercised by a set of\nhigh-level unit tests. Our tests are living documentation: they describe the\nbehavior of our system--the rules upon which we agreed with our business\nstakeholders--in nice readable code. When our business requirements change, we\nhave confidence that our tests will help us to prove the new functionality, and\nwhen new developers join the project, they can read our tests to understand how\nthings work.\n\nWe've decoupled the infrastructural parts of our system, like the database and\nAPI handlers, so that we can plug them into the outside of our application.\nThis helps us to keep our codebase well organized and stops us from building a\nbig ball of mud.\n\n(((\"adapters\", \"ports-and-adapters inspired patterns\")))\n(((\"ports\", \"ports-and-adapters inspired patterns\")))\nBy applying the dependency inversion principle, and by using\nports-and-adapters-inspired patterns like Repository and Unit of Work, we've\nmade it possible to do TDD in both high gear and low gear and to maintain a\nhealthy test pyramid. We can test our system edge to edge, and the need for\nintegration and end-to-end tests is kept to a minimum.\n\nLastly, we've talked about the idea of consistency boundaries. We don't want to\nlock our entire system whenever we make a change, so we have to choose which\nparts are consistent with one another.\n\nFor a small system, this is everything you need to go and play with the ideas of\ndomain-driven design. You now have the tools to build database-agnostic domain\nmodels that represent the shared language of your business experts. Hurrah!\n\nNOTE: At the risk of laboring the point--we've been at pains to point out that\n    each pattern comes at a cost. Each layer of indirection has a price in terms\n    of complexity and duplication in our code and will be confusing to programmers\n    who've never seen these patterns before. If your app is essentially a simple CRUD\n    wrapper around a database and isn't likely to be anything more than that\n    in the foreseeable future, _you don't need these patterns_. Go ahead and\n    use Django, and save yourself a lot of bother.\n    (((\"CRUD wrapper around a database\")))\n    (((\"patterns, deciding whether you need to use them\")))\n\nIn Part II, we'll zoom out and talk about a bigger topic: if aggregates are our\nboundary, and we can update only one at a time, how do we model processes that\ncross consistency boundaries?\n"
        },
        {
          "name": "chapter_08_events_and_message_bus.asciidoc",
          "type": "blob",
          "size": 33.0595703125,
          "content": "[[chapter_08_events_and_message_bus]]\n== Events and the Message Bus\n\n(((\"events and the message bus\", id=\"ix_evntMB\")))\nSo far we've spent a lot of time and energy on a simple problem that we could\neasily have solved with Django. You might be asking if the increased testability\nand expressiveness are _really_ worth all the effort.\n\nIn practice, though, we find that it's not the obvious features that make a mess\nof our codebases: it's the goop around the edge. It's reporting, and permissions,\nand workflows that touch a zillion objects.\n\nOur example will be a typical notification requirement: when we can't allocate\nan order because we're out of stock, we should alert the buying team. They'll\ngo and fix the problem by buying more stock, and all will be well.\n\nFor a first version, our product owner says we can just send the alert by email.\n\nLet's see how our architecture holds up when we need to plug in some of the\nmundane stuff that makes up so much of our systems.\n\nWe'll start by doing the simplest, most expeditious thing, and talk about\nwhy it's exactly this kind of decision that leads us to the Big Ball of Mud.\n\n(((\"Message Bus pattern\")))\n(((\"Domain Events pattern\")))\n(((\"events and the message bus\", \"events flowing through the system\")))\n(((\"Unit of Work pattern\", \"modifying to connect domain events and message bus\")))\nThen we'll show how to use the _Domain Events_ pattern to separate side effects from our\nuse cases, and how to use a simple _Message Bus_ pattern for triggering behavior\nbased on those events. We'll show a few options for creating\nthose events and how to pass them to the message bus, and finally we'll show\nhow the Unit of Work pattern can be modified to connect the two together elegantly,\nas previewed in <<message_bus_diagram>>.\n\n\n[[message_bus_diagram]]\n.Events flowing through the system\nimage::images/apwp_0801.png[]\n\n// TODO: add before diagram for contrast (?)\n\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_08_events_and_message_bus branch https://oreil.ly/M-JuL[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_08_events_and_message_bus\n# or to code along, checkout the previous chapter:\ngit checkout chapter_07_aggregate\n----\n====\n\n\n=== Avoiding Making a Mess\n\n(((\"web controllers, sending email alerts via, avoiding\")))\n(((\"events and the message bus\", \"sending email alerts when out of stock\", id=\"ix_evntMBeml\")))\n(((\"email alerts, sending when out of stock\", id=\"ix_email\")))\nSo. Email alerts when we run out of stock. When we have new requirements like ones that _really_ have nothing to do with the core domain, it's all too easy to\nstart dumping these things into our web controllers.\n\n\n==== First, Let's Avoid Making a Mess of Our Web Controllers\n\n(((\"events and the message bus\", \"sending email alerts when out of stock\", \"avoiding messing up web controllers\")))\nAs a one-off hack, this _might_ be OK:\n\n[[email_in_flask]]\n.Just whack it in the endpoint—what could go wrong? (src/allocation/entrypoints/flask_app.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n@app.route(\"/allocate\", methods=[\"POST\"])\ndef allocate_endpoint():\n    line = model.OrderLine(\n        request.json[\"orderid\"],\n        request.json[\"sku\"],\n        request.json[\"qty\"],\n    )\n    try:\n        uow = unit_of_work.SqlAlchemyUnitOfWork()\n        batchref = services.allocate(line, uow)\n    except (model.OutOfStock, services.InvalidSku) as e:\n        send_mail(\n            \"out of stock\",\n            \"stock_admin@made.com\",\n            f\"{line.orderid} - {line.sku}\"\n        )\n        return {\"message\": str(e)}, 400\n\n    return {\"batchref\": batchref}, 201\n----\n====\n\n...but it's easy to see how we can quickly end up in a mess by patching things up\nlike this. Sending email isn't the job of our HTTP layer, and we'd like to be\nable to unit test this new feature.\n\n\n==== And Let's Not Make a Mess of Our Model Either\n\n(((\"domain model\", \"email sending code in, avoiding\")))\n(((\"events and the message bus\", \"sending email alerts when out of stock\", \"avoiding messing up domain model\")))\nAssuming we don't want to put this code into our web controllers, because\nwe want them to be as thin as possible, we may look at putting it right at\nthe source, in the model:\n\n[[email_in_model]]\n.Email-sending code in our model isn't lovely either (src/allocation/domain/model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n    def allocate(self, line: OrderLine) -> str:\n        try:\n            batch = next(b for b in sorted(self.batches) if b.can_allocate(line))\n            #...\n        except StopIteration:\n            email.send_mail(\"stock@made.com\", f\"Out of stock for {line.sku}\")\n            raise OutOfStock(f\"Out of stock for sku {line.sku}\")\n----\n====\n\nBut that's even worse! We don't want our model to have any dependencies on\ninfrastructure concerns like `email.send_mail`.\n\nThis email-sending thing is unwelcome _goop_ messing up the nice clean flow\nof our system. What we'd like is to keep our domain model focused on the rule\n\"You can't allocate more stuff than is actually available.\"\n\n\n==== Or the Service Layer!\n\n(((\"service layer\", \"sending email alerts when out of stock, avoiding\")))\n(((\"events and the message bus\", \"sending email alerts when out of stock\", \"out of place in the service layer\")))\nThe requirement \"Try to allocate some stock, and send an email if it fails\" is\nan example of workflow orchestration: it's a set of steps that the system has\nto follow to [.keep-together]#achieve# a goal.\n\nWe've written a service layer to manage orchestration for us, but even here\nthe feature feels out of place:\n\n[[email_in_services]]\n.And in the service layer, it's out of place (src/allocation/service_layer/services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        product = uow.products.get(sku=line.sku)\n        if product is None:\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        try:\n            batchref = product.allocate(line)\n            uow.commit()\n            return batchref\n        except model.OutOfStock:\n            email.send_mail(\"stock@made.com\", f\"Out of stock for {line.sku}\")\n            raise\n----\n====\n\n(((\"email alerts, sending when out of stock\", startref=\"ix_email\")))\n(((\"events and the message bus\", \"sending email alerts when out of stock\", startref=\"ix_evntMBeml\")))\nCatching an exception and reraising it? It could be worse, but it's\ndefinitely making us unhappy. Why is it so hard to find a suitable home for\nthis code?\n\n=== Single Responsibility Principle\n\n(((\"single responsibility principle (SRP)\")))\n(((\"events and the message bus\", \"sending email alerts when out of stock\", \"violating the single responsibility principle\")))\nReally, this is a violation of the __single responsibility principle__ (SRP).footnote:[\nThis principle is the _S_ in https://oreil.ly/AIdSD[SOLID].]\nOur use case is allocation. Our endpoint, service function, and domain methods\nare all called [.keep-together]#`allocate`#, not\n`allocate_and_send_mail_if_out_of_stock`.\n\nTIP: Rule of thumb: if you can't describe what your function does without using\n    words like \"then\" or \"and,\" you might be violating the SRP.\n\nOne formulation of the SRP is that each class should have only a single reason\nto change. When we switch from email to SMS, we shouldn't have to update our\n`allocate()` function, because that's clearly a separate responsibility.\n\n(((\"choreography\")))\n(((\"orchestration\", \"changing to choreography\")))\nTo solve the problem, we're going to split the orchestration\ninto separate steps so that the different concerns don't get tangled up.footnote:[\nOur tech reviewer Ed Jung likes to say that when you change from imperative flow control \nto event-based flow control, you're changing _orchestration_ into _choreography_.]\nThe domain model's job is to know that we're out of stock, but the responsibility\nof sending an alert belongs elsewhere. We should be able to turn this feature\non or off, or to switch to SMS notifications instead, without needing to change\nthe rules of our domain model.\n\nWe'd also like to keep the service layer free of implementation details. We\nwant to apply the dependency inversion principle to notifications so that our\nservice layer depends on an abstraction, in the same way as we avoid depending\non the database by using a unit of work.\n\n\n=== All Aboard the Message Bus!\n\nThe patterns we're going to introduce here are _Domain Events_ and the _Message Bus_.\nWe can implement them in a few ways, so we'll show a couple before settling on\nthe one we like most.\n\n// TODO: at this point the message bus is really just a dispatcher.  could also mention\n// pubsub.  once we get a queue, it's more justifiably a bus\n\n\n==== The Model Records Events\n\n(((\"events and the message bus\", \"recording events\")))\nFirst, rather than being concerned about emails, our model will be in charge of\nrecording _events_—facts about things that have happened. We'll use a message\nbus to respond to events and invoke a new operation.\n\n\n==== Events Are Simple Dataclasses\n\n(((\"dataclasses\", \"events\")))\n(((\"events and the message bus\", \"events as simple dataclasses\")))\nAn _event_ is a kind of _value object_. Events don't have any behavior, because\nthey're pure data structures. We always name events in the language of the\ndomain, and we think of them as part of our domain model.\n\nWe could store them in _model.py_, but we may as well keep them in their own file\n (this might be a good time to consider refactoring out a directory called\n_domain_ so that we have _domain/model.py_ and _domain/events.py_):\n\n[role=\"nobreakinside less_space\"]\n[[events_dot_py]]\n.Event classes (src/allocation/domain/events.py)\n====\n[source,python]\n----\nfrom dataclasses import dataclass\n\n\nclass Event:  #<1>\n    pass\n\n\n@dataclass\nclass OutOfStock(Event):  #<2>\n    sku: str\n----\n====\n\n\n<1> Once we have a number of events, we'll find it useful to have a parent\n    class that can store common attributes. It's also useful for type\n    hints in our message bus, as you'll see shortly.\n\n<2> `dataclasses` are great for domain events too.\n\n\n\n==== The Model Raises Events\n\n(((\"events and the message bus\", \"domain model raising events\")))\n(((\"domain model\", \"raising events\")))\nWhen our domain model records a fact that happened, we say it _raises_ an event.\n\n(((\"aggregates\", \"testing Product object to raise events\")))\nHere's what it will look like from the outside; if we ask `Product` to allocate\nbut it can't, it should _raise_ an event:\n\n\n[[test_raising_event]]\n.Test our aggregate to raise events (tests/unit/test_product.py)\n====\n[source,python]\n----\ndef test_records_out_of_stock_event_if_cannot_allocate():\n    batch = Batch(\"batch1\", \"SMALL-FORK\", 10, eta=today)\n    product = Product(sku=\"SMALL-FORK\", batches=[batch])\n    product.allocate(OrderLine(\"order1\", \"SMALL-FORK\", 10))\n\n    allocation = product.allocate(OrderLine(\"order2\", \"SMALL-FORK\", 1))\n    assert product.events[-1] == events.OutOfStock(sku=\"SMALL-FORK\")  #<1>\n    assert allocation is None\n----\n====\n\n<1> Our aggregate will expose a new attribute called `.events` that will contain\n    a list of facts about what has happened, in the form of `Event` objects.\n\nHere's what the model looks like on the inside:\n\n\n[[domain_event]]\n.The model raises a domain event (src/allocation/domain/model.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass Product:\n    def __init__(self, sku: str, batches: List[Batch], version_number: int = 0):\n        self.sku = sku\n        self.batches = batches\n        self.version_number = version_number\n        self.events = []  # type: List[events.Event]  #<1>\n\n    def allocate(self, line: OrderLine) -> str:\n        try:\n            #...\n        except StopIteration:\n            self.events.append(events.OutOfStock(line.sku))  #<2>\n            # raise OutOfStock(f\"Out of stock for sku {line.sku}\")  #<3>\n            return None\n----\n====\n\n<1> Here's our new `.events` attribute in use.\n\n<2> Rather than invoking some email-sending code directly, we record those\n    events at the place they occur, using only the language of the domain.\n\n<3> We're also going to stop raising an exception for the out-of-stock\n    case. The event will do the job the exception was doing.\n\n\n\nNOTE: We're actually addressing a code smell we had until now, which is that we were\n    https://oreil.ly/IQB51[using\n    exceptions for control flow]. In general, if you're implementing domain\n    events, don't raise exceptions to describe the same domain concept.\n    As you'll see later when we handle events in the Unit of Work pattern, it's\n    confusing to have to reason about events and exceptions together.\n    (((\"control flow, using exceptions for\")))\n    (((\"exceptions\", \"using for control flow\")))\n\n\n\n==== The Message Bus Maps Events to Handlers\n\n(((\"message bus\", \"mapping events to handlers\")))\n(((\"events and the message bus\", \"message bus mapping events to handlers\")))\n(((\"publish-subscribe system\", \"message bus as\", \"handlers subscribed to receive events\")))\nA message bus basically says, \"When I see this event, I should invoke the following\nhandler function.\" In other words, it's a simple publish-subscribe system.\nHandlers are _subscribed_ to receive events, which we publish to the bus. It\nsounds harder than it is, and we usually implement it with a dict:\n\n[[messagebus]]\n.Simple message bus (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\ndef handle(event: events.Event):\n    for handler in HANDLERS[type(event)]:\n        handler(event)\n\n\ndef send_out_of_stock_notification(event: events.OutOfStock):\n    email.send_mail(\n        \"stock@made.com\",\n        f\"Out of stock for {event.sku}\",\n    )\n\n\nHANDLERS = {\n    events.OutOfStock: [send_out_of_stock_notification],\n}  # type: Dict[Type[events.Event], List[Callable]]\n----\n====\n\nNOTE: Note that the message bus as implemented doesn't give us concurrency because\n    only one handler will run at a time. Our objective isn't to support\n    parallel threads but to separate tasks conceptually, and to keep each UoW\n    as small as possible. This helps us to understand the codebase because the\n    \"recipe\" for how to run each use case is written in a single place. See the\n    following sidebar.\n    (((\"concurrency\", \"not provided by message bus implementation\")))\n\n[role=\"nobreakinside less_space\"]\n[[celery_sidebar]]\n.Is This Like Celery?\n*******************************************************************************\n(((\"message bus\", \"Celery and\")))\n_Celery_ is a popular tool in the Python world for deferring self-contained\nchunks of work to an asynchronous task queue.(((\"Celery tool\"))) The message bus we're\npresenting here is very different, so the short answer to the above question is no; our message bus\nhas more in common with an Express.js app, a UI event loop, or an actor framework.\n// TODO: this \"more in common with\" line is not super-helpful atm.  maybe onclick callbacks in js would be a more helpful example\n\n(((\"external events\")))\nIf you do have a requirement for moving work off the main thread, you\ncan still use our event-based metaphors, but we suggest you\nuse _external events_ for that. There's more discussion in\n<<chapter_11_external_events_tradeoffs>>, but essentially, if you\nimplement a way of persisting events to a centralized store, you\ncan subscribe other containers or other microservices to them. Then\nthat same concept of using events to separate responsibilities\nacross units of work within a single process/service can be extended across\nmultiple processes--which may be different containers within the same\nservice, or totally different microservices.\n\nIf you follow us in this approach, your API for distributing tasks\nis your event [.keep-together]##classes—##or a JSON representation of them. This allows\nyou a lot of flexibility in who you distribute tasks to; they need not\nnecessarily be Python services. Celery's API for distributing tasks is\nessentially \"function name plus arguments,\" which is more restrictive,\nand Python-only.\n\n*******************************************************************************\n\n\n=== Option 1: The Service Layer Takes Events from the Model and Puts Them on the Message Bus\n\n(((\"domain model\", \"events from, passing to message bus in service layer\")))\n(((\"message bus\", \"service layer with explicit message bus\")))\n(((\"service layer\", \"taking events from model and putting them on message bus\")))\n(((\"events and the message bus\", \"service layer with explicit message bus\")))\n(((\"publish-subscribe system\", \"message bus as\", \"publishing step\")))\nOur domain model raises events, and our message bus will call the right\nhandlers whenever an event happens. Now all we need is to connect the two. We\nneed something to catch events from the model and pass them to the message\nbus--the _publishing_ step.\n\nThe simplest way to do this is by adding some code into our service layer:\n\n[[service_talks_to_messagebus]]\n.The service layer with an explicit message bus (src/allocation/service_layer/services.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nfrom . import messagebus\n...\n\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        product = uow.products.get(sku=line.sku)\n        if product is None:\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        try:  #<1>\n            batchref = product.allocate(line)\n            uow.commit()\n            return batchref\n        finally:  #<1>\n            messagebus.handle(product.events)  #<2>\n----\n====\n\n<1> We keep the `try/finally` from our ugly earlier implementation (we haven't\n    gotten rid of _all_ exceptions yet, just `OutOfStock`).\n\n<2> But now, instead of depending directly on an email infrastructure,\n    the service layer is just in charge of passing events from the model\n    up to the message bus.\n\nThat already avoids some of the ugliness that we had in our naive\nimplementation, and we have several systems that work like this one, in which the\nservice layer explicitly collects events from aggregates and passes them to\nthe message bus.\n\n\n=== Option 2: The Service Layer Raises Its Own Events\n\n(((\"service layer\", \"raising its own events\")))\n(((\"events and the message bus\", \"service layer raising its own events\")))\n(((\"message bus\", \"service layer raising events and calling messagebus.handle\")))\nAnother variant on this that we've used is to have the service layer\nin charge of creating and raising events directly, rather than having them\nraised by the domain model:\n\n\n[[service_layer_raises_events]]\n.Service layer calls messagebus.handle directly (src/allocation/service_layer/services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        product = uow.products.get(sku=line.sku)\n        if product is None:\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        batchref = product.allocate(line)\n        uow.commit() #<1>\n\n        if batchref is None:\n            messagebus.handle(events.OutOfStock(line.sku))\n        return batchref\n----\n====\n\n<1> As before, we commit even if we fail to allocate because the code is simpler this way\n    and it's easier to reason about: we always commit unless something goes\n    wrong. Committing when we haven't changed anything is safe and keeps the\n    code uncluttered.\n\nAgain, we have applications in production that implement the pattern in this\nway.  What works for you will depend on the particular trade-offs you face, but\nwe'd like to show you what we think is the most elegant solution, in which we\nput the unit of work in charge of collecting and raising events.\n\n\n=== Option 3: The UoW Publishes Events to the Message Bus\n\n(((\"message bus\", \"Unit of Work publishing events to\")))\n(((\"events and the message bus\", \"UoW publishes events to message bus\")))\n(((\"Unit of Work pattern\", \"UoW publishing events to message bus\")))\nThe UoW already has a `try/finally`, and it knows about all the aggregates\ncurrently in play because it provides access to the repository. So it's\na good place to spot events and pass them to the message bus:\n\n\n[[uow_with_messagebus]]\n.The UoW meets the message bus (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n----\nclass AbstractUnitOfWork(abc.ABC):\n    ...\n\n    def commit(self):\n        self._commit()  #<1>\n        self.publish_events()  #<2>\n\n    def publish_events(self):  #<2>\n        for product in self.products.seen:  #<3>\n            while product.events:\n                event = product.events.pop(0)\n                messagebus.handle(event)\n\n    @abc.abstractmethod\n    def _commit(self):\n        raise NotImplementedError\n\n...\n\nclass SqlAlchemyUnitOfWork(AbstractUnitOfWork):\n    ...\n\n    def _commit(self):  #<1>\n        self.session.commit()\n----\n====\n\n<1> We'll change our commit method to require a private `._commit()`\n    method from subclasses.\n\n<2> After committing, we run through all the objects that our\n    repository has seen and pass their events to the message bus.\n\n<3> That relies on the repository keeping track of aggregates that have been loaded\n    using a new attribute, `.seen`, as you'll see in the next listing.\n    (((\"repositories\", \"repository keeping track of aggregates passing through it\")))\n    (((\"aggregates\", \"repository keeping track of aggregates passing through it\")))\n\nNOTE: Are you wondering what happens if one of the\n    handlers fails?  We'll discuss error handling in detail in <<chapter_10_commands>>.\n\n\n//IDEA: could change ._commit() to requiring super().commit()\n\n\n[[repository_tracks_seen]]\n.Repository tracks aggregates that pass through it (src/allocation/adapters/repository.py)\n====\n[source,python]\n----\nclass AbstractRepository(abc.ABC):\n    def __init__(self):\n        self.seen = set()  # type: Set[model.Product]  #<1>\n\n    def add(self, product: model.Product):  #<2>\n        self._add(product)\n        self.seen.add(product)\n\n    def get(self, sku) -> model.Product:  #<3>\n        product = self._get(sku)\n        if product:\n            self.seen.add(product)\n        return product\n\n    @abc.abstractmethod\n    def _add(self, product: model.Product):  #<2>\n        raise NotImplementedError\n\n    @abc.abstractmethod  #<3>\n    def _get(self, sku) -> model.Product:\n        raise NotImplementedError\n\n\nclass SqlAlchemyRepository(AbstractRepository):\n    def __init__(self, session):\n        super().__init__()\n        self.session = session\n\n    def _add(self, product):  #<2>\n        self.session.add(product)\n\n    def _get(self, sku):  #<3>\n        return self.session.query(model.Product).filter_by(sku=sku).first()\n----\n====\n\n<1> For the UoW to be able to publish new events, it needs to be able to ask\n    the repository for which `Product` objects have been used during this session.\n    We use a `set` called `.seen` to store them. That means our implementations\n    need to call +++<code>super().__init__()</code>+++.\n    (((\"super function\")))\n\n<2> The parent `add()` method adds things to `.seen`, and now requires subclasses\n    to implement `._add()`.\n\n<3> Similarly, `.get()` delegates to a `._get()` function, to be implemented by\n    subclasses, in order to capture objects seen.\n\n\nNOTE: The use of pass:[<code><em>._underscorey()</em></code>] methods and subclassing is definitely not\n    the only way you could implement these patterns. Have a go at the\n    <<get_rid_of_commit,\"Exercise for the Reader\">> in this chapter and experiment\n    with some alternatives.\n\nAfter the UoW and repository collaborate in this way to automatically keep\ntrack of live objects and process their events, the service layer can be\ntotally free of event-handling concerns:\n(((\"service layer\", \"totally free of event handling concerns\")))\n\n[[services_clean]]\n.Service layer is clean again (src/allocation/service_layer/services.py)\n====\n[source,python]\n----\ndef allocate(\n    orderid: str, sku: str, qty: int,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(orderid, sku, qty)\n    with uow:\n        product = uow.products.get(sku=line.sku)\n        if product is None:\n            raise InvalidSku(f\"Invalid sku {line.sku}\")\n        batchref = product.allocate(line)\n        uow.commit()\n        return batchref\n----\n====\n\n(((\"super function\", \"tweaking fakes in service layer to call\")))\n(((\"service layer\", \"tweaking fakes in to call super and implement underscorey methods\")))\n(((\"faking\", \"tweaking fakes in service layer to call super and implement underscorey methods\")))\n(((\"underscorey methods\", \"tweaking fakes in service layer to implement\")))\nWe do also have to remember to change the fakes in the service layer and make them\ncall `super()` in the right places, and to implement underscorey methods, but the\nchanges are minimal:\n\n\n[[services_tests_ugly_fake_messagebus]]\n.Service-layer fakes need tweaking (tests/unit/test_services.py)\n====\n[source,python]\n----\nclass FakeRepository(repository.AbstractRepository):\n    def __init__(self, products):\n        super().__init__()\n        self._products = set(products)\n\n    def _add(self, product):\n        self._products.add(product)\n\n    def _get(self, sku):\n        return next((p for p in self._products if p.sku == sku), None)\n\n...\n\nclass FakeUnitOfWork(unit_of_work.AbstractUnitOfWork):\n    ...\n\n    def _commit(self):\n        self.committed = True\n\n----\n====\n\n[role=\"nobreakinside less_space\"]\n[[get_rid_of_commit]]\n.Exercise for the Reader\n******************************************************************************\n\n(((\"inheritance, avoiding use of with wrapper class\")))\n(((\"underscorey methods\", \"avoiding by implementing TrackingRepository wrapper class\")))\n(((\"composition over inheritance in TrackingRepository wrapper class\")))\n(((\"repositories\", \"TrackerRepository wrapper class\")))\nAre you finding all those `._add()` and `._commit()` methods \"super-gross,\" in\nthe words of our beloved tech reviewer Hynek? Does it \"make you want to beat\nHarry around the head with a plushie snake\"? Hey, our code listings are\nonly meant to be examples, not the perfect solution! Why not go see if you\ncan do better?\n\nOne _composition over inheritance_ way to go would be to implement a\nwrapper class:\n\n[[tracking_repo_wrapper]]\n.A wrapper adds functionality and then delegates (src/adapters/repository.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass TrackingRepository:\n    seen: Set[model.Product]\n\n    def __init__(self, repo: AbstractRepository):\n        self.seen = set()  # type: Set[model.Product]\n        self._repo = repo\n\n    def add(self, product: model.Product):  #<1>\n        self._repo.add(product)  #<1>\n        self.seen.add(product)\n\n    def get(self, sku) -> model.Product:\n        product = self._repo.get(sku)\n        if product:\n            self.seen.add(product)\n        return product\n----\n====\n\n<1> By wrapping the repository, we can call the actual `.add()`\n    and `.get()` methods, avoiding weird underscorey methods.\n\n(((\"Unit of Work pattern\", \"getting rid of underscorey methods in UoW class\")))\nSee if you can apply a similar pattern to our UoW class in\norder to get rid of those Java-y `_commit()` methods too. You can find the code\non https://github.com/cosmicpython/code/tree/chapter_08_events_and_message_bus_exercise[GitHub].\n\n(((\"abstract base classes (ABCs)\", \"switching to typing.Protocol\")))\nSwitching all the ABCs to `typing.Protocol` is a good way to force yourself to\navoid using inheritance. Let us know if you come up with something nice!\n******************************************************************************\n\nYou might be starting to worry that maintaining these fakes is going to be a\nmaintenance burden. There's no doubt that it is work, but in our experience\nit's not a lot of work. Once your project is up and running, the interface for\nyour repository and UoW abstractions really don't change much. And if you're\nusing ABCs, they'll help remind you when things get out of sync.\n\n=== Wrap-Up\n\nDomain events give us a way to handle workflows in our system. We often find,\nlistening to our domain experts, that they express requirements in a causal or\ntemporal way—for example, \"When we try to allocate stock but there's none\navailable, then we should send an email to the buying team.\"\n\nThe magic words \"When X, then Y\" often tell us about an event that we can make\nconcrete in our system. Treating events as first-class things in our model helps\nus make our code more testable and observable, and it helps isolate concerns.\n\n(((\"message bus\", \"pros and cons or trade-offs\")))\n(((\"events and the message bus\", \"pros and cons or trade-offs\")))\nAnd <<chapter_08_events_and_message_bus_tradeoffs>> shows the trade-offs as we\nsee them.\n\n[[chapter_08_events_and_message_bus_tradeoffs]]\n[options=\"header\"]\n.Domain events: the trade-offs\n|===\n|Pros|Cons\na|\n* A message bus gives us a nice way to separate responsibilities when we have\n  to take multiple actions in response to a request.\n\n* Event handlers are nicely decoupled from the \"core\" application logic,\n  making it easy to change their implementation later.\n\n* Domain events are a great way to model the real world, and we can use them\n  as part of our business language when modeling with stakeholders.\n\na|\n\n* The message bus is an additional thing to wrap your head around; the implementation\n  in which the unit of work raises events for us is _neat_ but also magic. It's not\n  obvious when we call `commit` that we're also going to go and send email to\n  people.\n\n* What's more, that hidden event-handling code executes _synchronously_,\n  meaning your service-layer function\n  doesn't finish until all the handlers for any events are finished. That\n  could cause unexpected performance problems in your web endpoints\n  (adding asynchronous processing is possible but makes things even _more_ confusing).\n  (((\"synchronous execution of event-handling code\")))\n\n* More generally, event-driven workflows can be confusing because after things\n  are split across a chain of multiple handlers, there is no single place\n  in the system where you can understand how a request will be fulfilled.\n\n* You also open yourself up to the possibility of circular dependencies between your\n  event handlers, and infinite loops.\n  (((\"dependencies\", \"circular dependencies between event handlers\")))\n  (((\"events and the message bus\", startref=\"ix_evntMB\")))\n\na|\n|===\n\n(((\"aggregates\", \"changing multiple aggregates in a request\")))\nEvents are useful for more than just sending email, though. In <<chapter_07_aggregate>> we\nspent a lot of time convincing you that you should define aggregates, or\nboundaries where we guarantee consistency. People often ask, \"What\nshould I do if I need to change multiple aggregates as part of a request?\" Now\nwe have the tools we need to answer that question.\n\nIf we have two things that can be transactionally isolated (e.g., an order and a\n[.keep-together]#product#), then we can make them _eventually consistent_ by using events. When an\norder is canceled, we should find the products that were allocated to it\nand remove the [.keep-together]#allocations#.\n\n[role=\"nobreakinside less_space\"]\n.Domain Events and the Message Bus Recap\n*****************************************************************\n(((\"events and the message bus\", \"domain events and message bus recap\")))\n(((\"message bus\", \"recap\")))\n\nEvents can help with the single responsibility principle::\n    Code gets tangled up when we mix multiple concerns in one place. Events can\n    help us to keep things tidy by separating primary use cases from secondary\n    ones.\n    We also use events for communicating between aggregates so that we don't\n    need to run long-running transactions that lock against multiple tables.\n\nA message bus routes messages to handlers::\n    You can think of a message bus as a dict that maps from events to their\n    consumers. It doesn't \"know\" anything about the meaning of events; it's just\n    a piece of dumb infrastructure for getting messages around the system.\n\nOption 1: Service layer raises events and passes them to message bus::\n    The simplest way to start using events in your system is to raise them from\n    handlers by calling `bus.handle(some_new_event)` after you commit your\n    unit of work.\n    (((\"service layer\", \"raising events and passing them to message bus\")))\n\nOption 2: Domain model raises events, service layer passes them to message bus::\n    The logic about when to raise an event really should live with the model, so\n    we can improve our system's design and testability by raising events from\n    the domain model. It's easy for our handlers to collect events off the model\n    objects after `commit` and pass them to the bus.\n    (((\"domain model\", \"raising events and service layer passing them to message bus\")))\n\nOption 3: UoW collects events from aggregates and passes them to message bus::\n    Adding `bus.handle(aggregate.events)` to every handler is annoying, so we\n    can tidy up by making our unit of work responsible for raising events that\n    were raised by loaded objects.\n    This is the most complex design and might rely on ORM magic, but it's clean\n    and easy to use once it's set up.\n    (((\"aggregates\", \"UoW collecting events from and passing them to message bus\")))\n    (((\"Unit of Work pattern\", \"UoW collecting events from aggregates and passing them to message bus\")))\n\n*****************************************************************\n\nIn <<chapter_09_all_messagebus>>, we'll look at this idea in more\ndetail as we build a more complex workflow with our new message bus.\n"
        },
        {
          "name": "chapter_09_all_messagebus.asciidoc",
          "type": "blob",
          "size": 36.4833984375,
          "content": "[[chapter_09_all_messagebus]]\n== Going to Town on the Message Bus\n\n(((\"events and the message bus\", \"transforming our app into message processor\", id=\"ix_evntMBMP\")))\n(((\"message bus\", \"before, message buse as optional add-on\")))\nIn this chapter, we'll start to make events more fundamental to the internal\nstructure of our application. We'll move from the current state in\n<<maps_chapter_08_before>>, where events are an optional\nside effect...\n\n[[maps_chapter_08_before]]\n.Before: the message bus is an optional add-on\nimage::images/apwp_0901.png[]\n\n(((\"message bus\", \"now the main entrypoint to service layer\")))\n(((\"service layer\", \"message bus as main entrypoint\")))\n...to the situation in <<map_chapter_08_after>>, where\neverything goes via the message bus, and our app has been transformed\nfundamentally into a message processor.\n\n[[map_chapter_08_after]]\n.The message bus is now the main entrypoint to the service layer\nimage::images/apwp_0902.png[]\n\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_09_all_messagebus branch https://oreil.ly/oKNkn[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_09_all_messagebus\n# or to code along, checkout the previous chapter:\ngit checkout chapter_08_events_and_message_bus\n----\n====\n\n[role=\"pagebreak-before less_space\"]\n=== A New Requirement Leads Us to a New Architecture\n\n(((\"situated software\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"new requirement and new architecture\")))\nRich Hickey talks about _situated software,_ meaning software that runs for\nextended periods of time, managing a real-world process. Examples include\nwarehouse-management systems, logistics schedulers, and payroll systems.\n\nThis software is tricky to write because unexpected things happen all the time\nin the real world of physical objects and unreliable humans. For example:\n\n* During a stock-take, we discover that three pass:[<code>SPRINGY-MATTRESS</code>]es have been\n  water damaged by a leaky roof.\n* A consignment of pass:[<code>RELIABLE-FORK</code>]s is missing the required documentation and is\n  held in customs for several weeks. Three pass:[<code>RELIABLE-FORK</code>]s subsequently fail safety\n  testing and are destroyed.\n* A global shortage of sequins means we're unable to manufacture our next batch\n  of pass:[<code>SPARKLY-BOOKCASE</code>].\n\n(((\"batches\", \"batch quantities changed means deallocate and reallocate\")))\nIn these types of situations, we learn about the need to change batch quantities\nwhen they're already in the system. Perhaps someone made a mistake on the number\nin the manifest, or perhaps some sofas fell off a truck. Following a\nconversation with the business,footnote:[\nEvent-based modeling is so popular that a practice called _event storming_ has\nbeen developed for facilitating event-based requirements gathering and domain\nmodel elaboration.]\n(((\"event storming\")))\nwe model the situation as in <<batch_changed_events_flow_diagram>>.\n\n\n[[batch_changed_events_flow_diagram]]\n.Batch quantity changed means deallocate and reallocate\nimage::images/apwp_0903.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0903]\n+----------+    /----\\      +------------+       +--------------------+\n| Batch    |--> |RULE| -->  | Deallocate | ----> | AllocationRequired |\n| Quantity |    \\----/      +------------+-+     +--------------------+-+\n| Changed  |                  | Deallocate | ----> | AllocationRequired |\n+----------+                  +------------+-+     +--------------------+-+\n                                | Deallocate | ----> | AllocationRequired |\n                                +------------+       +--------------------+\n----\n\nAn event we'll call `BatchQuantityChanged` should lead us to change the\nquantity on the batch, yes, but also to apply a _business rule_: if the new\nquantity drops to less than the total already allocated, we need to\n_deallocate_  those orders from that batch. Then each one will require\na new allocation, which we can capture as an event called `AllocationRequired`.\n\nPerhaps you're already anticipating that our internal message bus and events can\nhelp implement this requirement. We could define a service called\n`change_batch_quantity` that knows how to adjust batch quantities and also how\nto _deallocate_ any excess order lines, and then each deallocation can emit an\n`AllocationRequired` event that can be forwarded to the existing `allocate`\nservice, in separate transactions. Once again, our message bus helps us to\nenforce the single responsibility principle, and it allows us to make choices about\ntransactions and data integrity.\n\n==== Imagining an Architecture Change: Everything Will Be an [.keep-together]#Event Handler#\n\n(((\"event handlers\", \"imagined architecture in which everything is an event handler\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"imagined architecture, everything will be an event handler\")))\nBut before we jump in, think about where we're headed.  There are two\nkinds of flows through our system:\n\n* API calls that are handled by a service-layer function\n\n* Internal events (which might be raised as a side effect of a service-layer function)\n  and their handlers (which in turn call service-layer functions)\n\n(((\"service functions\", \"making them event handlers\")))\nWouldn't it be easier if everything was an event handler?  If we rethink our API\ncalls as capturing events, the service-layer functions can be event handlers\ntoo, and we no longer need to make a distinction between internal and external\nevent handlers:\n\n* `services.allocate()` could be the handler for an\n  `AllocationRequired` event and could emit `Allocated` events as its output.\n\n* `services.add_batch()` could be the handler for a `BatchCreated`\n  event.footnote:[If you've done a bit of reading about event-driven\n  architectures, you may be thinking, \"Some of these events sound more like\n  commands!\" Bear with us! We're trying to introduce one concept at a time.\n  In the <<chapter_10_commands,next chapter>>, we'll introduce the distinction\n  between commands and events.]\n  (((\"BatchCreated event\", \"services.add_batch as handler for\")))\n\nOur new requirement will fit the same pattern:\n\n* An event called `BatchQuantityChanged` can invoke a handler called\n  `change_batch_quantity()`.\n  (((\"BatchQuantityChanged event\", \"invoking handler change_batch_quantity\")))\n\n* And the new `AllocationRequired` events that it may raise can be passed on to\n  `services.allocate()` too, so there is no conceptual difference between a\n  brand-new allocation coming from the API and a reallocation that's\n  internally triggered by a deallocation.\n  (((\"AllocationRequired event\", \"passing to services.allocate\")))\n\n\n(((\"preparatory refactoring workflow\")))\nAll sound like a bit much? Let's work toward it all gradually.  We'll\nfollow the https://oreil.ly/W3RZM[Preparatory Refactoring] workflow, aka \"Make\nthe change easy; then make the easy change\":\n\n\n1. We refactor our service layer into event handlers. We can\n  get used to the idea of events being the way we describe inputs to the\n  system. In particular, the existing `services.allocate()` function will\n  become the handler for an event called `AllocationRequired`.\n\n2. We build an end-to-end test that puts `BatchQuantityChanged` events\n  into the system and looks for `Allocated` events coming out.\n\n3. Our implementation will conceptually be very simple: a new\n  handler for `BatchQuantityChanged` events, whose implementation will emit\n  `AllocationRequired` events, which in turn will be handled by the exact same\n  handler for allocations that the API uses.\n\n\nAlong the way, we'll make a small tweak to the message bus and UoW, moving the\nresponsibility for putting new events on the message bus into the message bus itself.\n\n\n=== Refactoring Service Functions to Message Handlers\n\n(((\"events and the message bus\", \"transforming our app into message processor\", \"refactoring service functions to message handlers\")))\n(((\"service functions\", \"refactoring to message handlers\")))\n(((\"AllocationRequired event\")))\n(((\"BatchCreated event\")))\nWe start by defining the two events that capture our current API\ninputs—++AllocationRequired++ and `BatchCreated`:\n\n[[two_new_events]]\n.BatchCreated and AllocationRequired events (src/allocation/domain/events.py)\n====\n[source,python]\n----\n@dataclass\nclass BatchCreated(Event):\n    ref: str\n    sku: str\n    qty: int\n    eta: Optional[date] = None\n\n...\n\n@dataclass\nclass AllocationRequired(Event):\n    orderid: str\n    sku: str\n    qty: int\n----\n====\n\nThen we rename _services.py_ to _handlers.py_; we add the existing message handler\nfor `send_out_of_stock_notification`; and most importantly, we change all the\nhandlers so that they have the same inputs, an event and a UoW:\n\n\n[[services_to_handlers]]\n.Handlers and services are the same thing (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n----\ndef add_batch(\n    event: events.BatchCreated,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    with uow:\n        product = uow.products.get(sku=event.sku)\n        ...\n\n\ndef allocate(\n    event: events.AllocationRequired,\n    uow: unit_of_work.AbstractUnitOfWork,\n) -> str:\n    line = OrderLine(event.orderid, event.sku, event.qty)\n    ...\n\n\ndef send_out_of_stock_notification(\n    event: events.OutOfStock,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    email.send(\n        \"stock@made.com\",\n        f\"Out of stock for {event.sku}\",\n    )\n----\n====\n\n\nThe change might be clearer as a diff:\n\n[[services_to_handlers_diff]]\n.Changing from services to handlers (src/allocation/service_layer/handlers.py)\n====\n[source,diff]\n----\n def add_batch(\n-    ref: str, sku: str, qty: int, eta: Optional[date],\n+    event: events.BatchCreated,\n     uow: unit_of_work.AbstractUnitOfWork,\n ):\n     with uow:\n-        product = uow.products.get(sku=sku)\n+        product = uow.products.get(sku=event.sku)\n     ...\n\n\n def allocate(\n-    orderid: str, sku: str, qty: int,\n+    event: events.AllocationRequired,\n     uow: unit_of_work.AbstractUnitOfWork,\n ) -> str:\n-    line = OrderLine(orderid, sku, qty)\n+    line = OrderLine(event.orderid, event.sku, event.qty)\n     ...\n\n+\n+def send_out_of_stock_notification(\n+    event: events.OutOfStock,\n+    uow: unit_of_work.AbstractUnitOfWork,\n+):\n+    email.send(\n     ...\n----\n====\n\nAlong the way, we've made our service-layer's API more structured and more consistent. It was a scattering of\nprimitives, and now it uses well-defined objects (see the following sidebar).\n\n[role=\"nobreakinside less_space\"]\n.From Domain Objects, via Primitive Obsession, to [.keep-together]#Events as an Interface#\n*******************************************************************************\n\n(((\"service layer\", \"from domain objects to primitives to events as interface\")))\n(((\"primitives\", \"primitive obsession\")))\n(((\"primitives\", \"moving from domain objects to, in service layer\")))\nSome of you may remember <<primitive_obsession>>, in which we changed our service-layer API\nfrom being in terms of domain objects to primitives. And now we're moving\nback, but to different objects?  What gives?\n\nIn OO circles, people talk about _primitive obsession_ as an antipattern: avoid\nprimitives in public APIs, and instead wrap them with custom value classes, they\nwould say. In the Python world, a lot of people would be quite skeptical of\nthat as a rule of thumb. When mindlessly applied, it's certainly a recipe for\nunnecessary complexity. So that's not what we're doing per se.\n\nThe move from domain objects to primitives bought us a nice bit of decoupling:\nour client code was no longer coupled directly to the domain, so the service\nlayer could present an API that stays the same even if we decide to make changes\nto our model, and vice versa.\n\nSo have we gone backward? Well, our core domain model objects are still free to\nvary, but instead we've coupled the external world to our event classes.\nThey're part of the domain too, but the hope is that they vary less often, so\nthey're a sensible artifact to couple on.\n\nAnd what have we bought ourselves? Now, when invoking a use case in our application,\nwe no longer need to remember a particular combination of primitives, but just a single\nevent class that represents the input to our application. That's conceptually\nquite nice. On top of that, as you'll see in <<appendix_validation>>, those\nevent classes can be a nice place to do some input validation.\n*******************************************************************************\n\n\n==== The Message Bus Now Collects Events from the UoW\n\n(((\"message bus\", \"now collecting events from UoW\")))\n(((\"Unit of Work pattern\", \"message bus now collecting events from UoW\")))\n(((\"dependencies\", \"UoW no longer dependent on message bus\")))\nOur event handlers now need a UoW. In addition, as our message bus becomes\nmore central to our application, it makes sense to put it explicitly in charge of\ncollecting and processing new events. There was a bit of a circular dependency\nbetween the UoW and message bus until now, so this will make it one-way.  Instead\nof having the UoW _push_ events onto the message bus, we will have the message\nbus _pull_ events from the UoW.\n\n\n[[handle_has_uow_and_queue]]\n.Handle takes a UoW and manages a queue (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef handle(\n    event: events.Event,\n    uow: unit_of_work.AbstractUnitOfWork,  #<1>\n):\n    queue = [event]  #<2>\n    while queue:\n        event = queue.pop(0)  #<3>\n        for handler in HANDLERS[type(event)]:  #<3>\n            handler(event, uow=uow)  #<4>\n            queue.extend(uow.collect_new_events())  #<5>\n----\n====\n\n<1> The message bus now gets passed the UoW each time it starts up.\n<2> When we begin handling our first event, we start a queue.\n<3> We pop events from the front of the queue and invoke their handlers (the\n    [.keep-together]#`HANDLERS`# dict hasn't changed; it still maps event types to handler functions).\n<4> The message bus passes the UoW down to each handler.\n<5> After each handler finishes, we collect any new events that have been\n    generated and add them to the queue.\n\nIn _unit_of_work.py_, `publish_events()` becomes a less active method,\n`collect_new_events()`:\n\n\n[[uow_collect_new_events]]\n.UoW no longer puts events directly on the bus (src/allocation/service_layer/unit_of_work.py)\n====\n[source,diff]\n----\n-from . import messagebus  #<1>\n\n\n class AbstractUnitOfWork(abc.ABC):\n@@ -22,13 +21,11 @@ class AbstractUnitOfWork(abc.ABC):\n\n     def commit(self):\n         self._commit()\n-        self.publish_events()  #<2>\n\n-    def publish_events(self):\n+    def collect_new_events(self):\n         for product in self.products.seen:\n             while product.events:\n-                event = product.events.pop(0)\n-                messagebus.handle(event)\n+                yield product.events.pop(0)  #<3>\n\n----\n====\n\n<1> The `unit_of_work` module now no longer depends on `messagebus`.\n<2> We no longer `publish_events` automatically on commit. The message bus\n    is keeping track of the event queue instead.\n<3> And the UoW no longer actively puts events on the message bus; it\n    just makes them available.\n\n//IDEA: we can definitely get rid of _commit() now right?\n// (EJ2) at this point _commit() doesn't serve any purpose, so it could be deleted.\n//       unsure if deleting it would be confusing at this point.\n\n[role=\"pagebreak-before less_space\"]\n==== Our Tests Are All Written in Terms of Events Too\n\n(((\"events and the message bus\", \"transforming our app into message processor\", \"tests writtern to in terms of events\")))\n(((\"testing\", \"tests written in terms of events\")))\nOur tests now operate by creating events and putting them on the\nmessage bus, rather than invoking service-layer functions directly:\n\n\n[[handler_tests]]\n.Handler tests use events (tests/unit/test_handlers.py)\n====\n[source,diff]\n----\nclass TestAddBatch:\n     def test_for_new_product(self):\n         uow = FakeUnitOfWork()\n-        services.add_batch(\"b1\", \"CRUNCHY-ARMCHAIR\", 100, None, uow)\n+        messagebus.handle(\n+            events.BatchCreated(\"b1\", \"CRUNCHY-ARMCHAIR\", 100, None), uow\n+        )\n         assert uow.products.get(\"CRUNCHY-ARMCHAIR\") is not None\n         assert uow.committed\n\n...\n\n class TestAllocate:\n     def test_returns_allocation(self):\n         uow = FakeUnitOfWork()\n-        services.add_batch(\"batch1\", \"COMPLICATED-LAMP\", 100, None, uow)\n-        result = services.allocate(\"o1\", \"COMPLICATED-LAMP\", 10, uow)\n+        messagebus.handle(\n+            events.BatchCreated(\"batch1\", \"COMPLICATED-LAMP\", 100, None), uow\n+        )\n+        result = messagebus.handle(\n+            events.AllocationRequired(\"o1\", \"COMPLICATED-LAMP\", 10), uow\n+        )\n         assert result == \"batch1\"\n----\n====\n\n\n[[temporary_ugly_hack]]\n==== A Temporary Ugly Hack: The Message Bus Has to Return Results\n\n(((\"events and the message bus\", \"transforming our app into message processor\", \"temporary hack, message bus returning results\")))\n(((\"message bus\", \"returning results in temporary hack\")))\nOur API and our service layer currently want to know the allocated batch reference\nwhen they invoke our `allocate()` handler. This means we need to put in\na temporary hack on our message bus to let it return events:\n\n[[hack_messagebus_results]]\n.Message bus returns results (src/allocation/service_layer/messagebus.py)\n====\n[source,diff]\n----\n def handle(\n     event: events.Event,\n     uow: unit_of_work.AbstractUnitOfWork,\n ):\n+    results = []\n     queue = [event]\n     while queue:\n         event = queue.pop(0)\n         for handler in HANDLERS[type(event)]:\n-            handler(event, uow=uow)\n+            results.append(handler(event, uow=uow))\n             queue.extend(uow.collect_new_events())\n+    return results\n----\n====\n\n// IDEA (hynek) inline the r=, the addition of a meaningless variable is distracting.\n\n\n(((\"events and the message bus\", \"transforming our app into message processor\", \"modifying API to work with events\")))\n(((\"APIs\", \"modifying API to work with events\")))\nIt's because we're mixing the read and write responsibilities in our system.\nWe'll come back to fix this wart in <<chapter_12_cqrs>>.\n\n\n==== Modifying Our API to Work with Events\n\n[[flask_uses_messagebus]]\n.Flask changing to message bus as a diff (src/allocation/entrypoints/flask_app.py)\n====\n[source,diff]\n----\n @app.route(\"/allocate\", methods=[\"POST\"])\n def allocate_endpoint():\n     try:\n-        batchref = services.allocate(\n-            request.json[\"orderid\"],  #<1>\n-            request.json[\"sku\"],\n-            request.json[\"qty\"],\n-            unit_of_work.SqlAlchemyUnitOfWork(),\n+        event = events.AllocationRequired(  #<2>\n+            request.json[\"orderid\"], request.json[\"sku\"], request.json[\"qty\"]\n         )\n+        results = messagebus.handle(event, unit_of_work.SqlAlchemyUnitOfWork())  #<3>\n+        batchref = results.pop(0)\n     except InvalidSku as e:\n----\n====\n\n<1> Instead of calling the service layer with a bunch of primitives extracted\n    from the request JSON...\n\n<2> We instantiate an event.\n\n<3> Then we pass it to the message bus.\n\nAnd we should be back to a fully functional application, but one that's now\nfully event-driven:\n\n* What used to be service-layer functions are now event handlers.\n\n* That makes them the same as the functions we invoke for handling internal events raised by\n  our domain model.\n\n* We use events as our data structure for capturing inputs to the system,\n  as well as for handing off of internal work packages.\n\n* The entire app is now best described as a message processor, or an event processor\n  if you prefer.  We'll talk about the distinction in the\n  <<chapter_10_commands, next chapter>>.\n\n\n\n=== Implementing Our New Requirement\n\n(((\"reallocation\", \"sequence diagram for flow\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"implementing the new requirement\", id=\"ix_evntMBMPreq\")))\nWe're done with our refactoring phase. Let's see if we really have \"made the\nchange easy.\"  Let's implement our new requirement, shown in <<reallocation_sequence_diagram>>: we'll receive as our\ninputs some new `BatchQuantityChanged` events and pass them to a handler, which in\nturn might emit some `AllocationRequired` events, and those in turn will go\nback to our existing handler for reallocation.\n\n[role=\"width-75\"]\n[[reallocation_sequence_diagram]]\n.Sequence diagram for reallocation flow\nimage::images/apwp_0904.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_0904, config=plantuml.cfg]\n@startuml\nscale 4\n\nAPI -> MessageBus : BatchQuantityChanged event\n\ngroup BatchQuantityChanged Handler + Unit of Work 1\n    MessageBus -> Domain_Model : change batch quantity\n    Domain_Model -> MessageBus : emit AllocationRequired event(s)\nend\n\n\ngroup AllocationRequired Handler + Unit of Work 2 (or more)\n    MessageBus -> Domain_Model : allocate\nend\n\n@enduml\n----\n\nWARNING: When you split things out like this across two units of work,\n    you now have two database transactions, so you are opening yourself up\n    to integrity issues: something could happen that means the first transaction completes\n    but the second one does not. You'll need to think about whether this is acceptable,\n    and whether you need to notice when it happens and do something about it.\n    See <<footguns>> for more discussion.\n    (((\"data integrity\", \"issues arising from splitting operation across two UoWs\")))\n    (((\"Unit of Work pattern\", \"splitting operations across two UoWs\")))\n\n\n\n==== Our New Event\n\n(((\"BatchQuantityChanged event\", \"implementing\")))\nThe event that tells us a batch quantity has changed is simple; it just\nneeds a batch reference and a new quantity:\n\n\n[[batch_quantity_changed_event]]\n.New event (src/allocation/domain/events.py)\n====\n[source,python]\n----\n@dataclass\nclass BatchQuantityChanged(Event):\n    ref: str\n    qty: int\n----\n====\n\n[[test-driving-ch9]]\n=== Test-Driving a New Handler\n\n(((\"testing\", \"tests written in terms of events\", \"handler tests for change_batch_quantity\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"test driving new handler\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"implementing the new requirement\", startref=\"ix_evntMBMPreq\")))\n(((\"change_batch_quantity\", \"handler tests for\")))\nFollowing the lessons learned in <<chapter_04_service_layer>>,\nwe can operate in \"high gear\" and write our unit tests at the highest\npossible level of abstraction, in terms of events. Here's what they might\nlook like:\n\n\n[[test_change_batch_quantity_handler]]\n.Handler tests for change_batch_quantity (tests/unit/test_handlers.py)\n====\n[source,python]\n----\nclass TestChangeBatchQuantity:\n    def test_changes_available_quantity(self):\n        uow = FakeUnitOfWork()\n        messagebus.handle(\n            events.BatchCreated(\"batch1\", \"ADORABLE-SETTEE\", 100, None), uow\n        )\n        [batch] = uow.products.get(sku=\"ADORABLE-SETTEE\").batches\n        assert batch.available_quantity == 100  #<1>\n\n        messagebus.handle(events.BatchQuantityChanged(\"batch1\", 50), uow)\n\n        assert batch.available_quantity == 50  #<1>\n\n    def test_reallocates_if_necessary(self):\n        uow = FakeUnitOfWork()\n        event_history = [\n            events.BatchCreated(\"batch1\", \"INDIFFERENT-TABLE\", 50, None),\n            events.BatchCreated(\"batch2\", \"INDIFFERENT-TABLE\", 50, date.today()),\n            events.AllocationRequired(\"order1\", \"INDIFFERENT-TABLE\", 20),\n            events.AllocationRequired(\"order2\", \"INDIFFERENT-TABLE\", 20),\n        ]\n        for e in event_history:\n            messagebus.handle(e, uow)\n        [batch1, batch2] = uow.products.get(sku=\"INDIFFERENT-TABLE\").batches\n        assert batch1.available_quantity == 10\n        assert batch2.available_quantity == 50\n\n        messagebus.handle(events.BatchQuantityChanged(\"batch1\", 25), uow)\n\n        # order1 or order2 will be deallocated, so we'll have 25 - 20\n        assert batch1.available_quantity == 5  #<2>\n        # and 20 will be reallocated to the next batch\n        assert batch2.available_quantity == 30  #<2>\n----\n====\n\n<1> The simple case would be trivially easy to implement; we just\n    modify a quantity.\n\n<2> But if we try to change the quantity to less than\n    has been allocated, we'll need to deallocate at least one order,\n    and we expect to reallocate it to a new batch.\n\n\n\n==== Implementation\n\n(((\"change_batch_quantity\", \"implementation, handler delegating to model layer\")))\nOur new handler is very simple:\n\n[[change_quantity_handler]]\n.Handler delegates to model layer (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n----\ndef change_batch_quantity(\n    event: events.BatchQuantityChanged,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    with uow:\n        product = uow.products.get_by_batchref(batchref=event.ref)\n        product.change_batch_quantity(ref=event.ref, qty=event.qty)\n        uow.commit()\n----\n====\n\n// TODO (DS): Indentation looks off\n\n\n(((\"repositories\", \"new query type on our repository\")))\nWe realize we'll need a new query type on our repository:\n\n[[get_by_batchref]]\n.A new query type on our repository (src/allocation/adapters/repository.py)\n====\n[source,python,highlight=\"7,22,32\"]\n----\nclass AbstractRepository(abc.ABC):\n    ...\n\n    def get(self, sku) -> model.Product:\n        ...\n\n    def get_by_batchref(self, batchref) -> model.Product:\n        product = self._get_by_batchref(batchref)\n        if product:\n            self.seen.add(product)\n        return product\n\n    @abc.abstractmethod\n    def _add(self, product: model.Product):\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _get(self, sku) -> model.Product:\n        raise NotImplementedError\n\n    @abc.abstractmethod\n    def _get_by_batchref(self, batchref) -> model.Product:\n        raise NotImplementedError\n    ...\n\nclass SqlAlchemyRepository(AbstractRepository):\n    ...\n\n    def _get(self, sku):\n        return self.session.query(model.Product).filter_by(sku=sku).first()\n\n    def _get_by_batchref(self, batchref):\n        return (\n            self.session.query(model.Product)\n            .join(model.Batch)\n            .filter(orm.batches.c.reference == batchref)\n            .first()\n        )\n\n----\n====\n\n(((\"faking\", \"FakeRepository\", \"new query type on\")))\nAnd on our `FakeRepository` too:\n\n[[fakerepo_get_by_batchref]]\n.Updating the fake repo too (tests/unit/test_handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass FakeRepository(repository.AbstractRepository):\n    ...\n\n    def _get(self, sku):\n        return next((p for p in self._products if p.sku == sku), None)\n\n    def _get_by_batchref(self, batchref):\n        return next(\n            (p for p in self._products for b in p.batches if b.reference == batchref),\n            None,\n        )\n----\n====\n\n\nNOTE: We're adding a query to our repository to make this use case easier to\n    implement. So long as our query is returning a single aggregate, we're not\n    bending any rules. If you find yourself writing complex queries on your\n    repositories, you might want to consider a different design. Methods like\n    `get_most_popular_products` or `find_products_by_order_id` in particular\n    would definitely trigger our spidey sense. <<chapter_11_external_events>>\n    and the <<epilogue_1_how_to_get_there_from_here, epilogue>> have some tips\n    on managing complex queries.\n    (((\"aggregates\", \"query on repository returning single aggregate\")))\n\n\n==== A New Method on the Domain Model\n\n(((\"domain model\", \"new method on, change_batch_quantity\")))\nWe add the new method to the model,\nwhich does the quantity change and deallocation(s) inline\nand publishes a new event.\nWe also modify the existing allocate function to publish an event:\n\n\n[[change_batch_model_layer]]\n.Our model evolves to capture the new requirement (src/allocation/domain/model.py)\n====\n[source,python]\n----\nclass Product:\n    ...\n\n    def change_batch_quantity(self, ref: str, qty: int):\n        batch = next(b for b in self.batches if b.reference == ref)\n        batch._purchased_quantity = qty\n        while batch.available_quantity < 0:\n            line = batch.deallocate_one()\n            self.events.append(\n                events.AllocationRequired(line.orderid, line.sku, line.qty)\n            )\n...\n\nclass Batch:\n    ...\n\n    def deallocate_one(self) -> OrderLine:\n        return self._allocations.pop()\n----\n====\n\n(((\"message bus\", \"wiring up new event handlers to\")))\nWe wire up our new handler:\n\n\n[[full_messagebus]]\n.The message bus grows (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\nHANDLERS = {\n    events.BatchCreated: [handlers.add_batch],\n    events.BatchQuantityChanged: [handlers.change_batch_quantity],\n    events.AllocationRequired: [handlers.allocate],\n    events.OutOfStock: [handlers.send_out_of_stock_notification],\n}  # type: Dict[Type[events.Event], List[Callable]]\n----\n====\n\nAnd our new requirement is fully implemented.\n\n[[fake_message_bus]]\n=== Optionally: Unit Testing Event Handlers in Isolation with a Fake Message Bus\n\n(((\"message bus\", \"unit testing event handlers with fake message bus\")))\n(((\"testing\", \"tests written in terms of events\", \"unit testing event handlers with fake message bus\")))\n(((\"events and the message bus\", \"transforming our app into message processor\", \"unit testing event handlers with fake message bus\")))\nOur main test for the reallocation workflow is _edge-to-edge_\n(see the example code in <<test-driving-ch9>>). It uses\nthe real message bus, and it tests the whole flow, where the `BatchQuantityChanged`\nevent handler triggers deallocation, and emits new `AllocationRequired` events, which in\nturn are handled by their own handlers. One test covers a chain of multiple\nevents and handlers.\n\nDepending on the complexity of your chain of events, you may decide that you\nwant to test some handlers in isolation from one another. You can do this\nusing a \"fake\" message bus.\n\n(((\"Unit of Work pattern\", \"fake message bus implemented in UoW\")))\nIn our case, we actually intervene by modifying the `publish_events()` method\non `FakeUnitOfWork` and decoupling it from the real message bus, instead making\nit record what events it sees:\n\n\n[[fake_messagebus]]\n.Fake message bus implemented in UoW (tests/unit/test_handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass FakeUnitOfWorkWithFakeMessageBus(FakeUnitOfWork):\n    def __init__(self):\n        super().__init__()\n        self.events_published = []  # type: List[events.Event]\n\n    def collect_new_events(self):\n        self.events_published += super().collect_new_events()\n        return []\n----\n====\n\n(((\"reallocation\", \"testing in isolation using fake message bus\")))\nNow when we invoke `messagebus.handle()` using the `FakeUnitOfWorkWithFakeMessageBus`,\nit runs only the handler for that event. So we can write a more isolated unit\ntest: instead of checking all the side effects, we just check that\n`BatchQuantityChanged` leads to `AllocationRequired` if the quantity drops\nbelow the total already allocated:\n\n[role=\"nobreakinside less_space\"]\n[[test_handler_in_isolation]]\n.Testing reallocation in isolation (tests/unit/test_handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef test_reallocates_if_necessary_isolated():\n    uow = FakeUnitOfWorkWithFakeMessageBus()\n\n    # test setup as before\n    event_history = [\n        events.BatchCreated(\"batch1\", \"INDIFFERENT-TABLE\", 50, None),\n        events.BatchCreated(\"batch2\", \"INDIFFERENT-TABLE\", 50, date.today()),\n        events.AllocationRequired(\"order1\", \"INDIFFERENT-TABLE\", 20),\n        events.AllocationRequired(\"order2\", \"INDIFFERENT-TABLE\", 20),\n    ]\n    for e in event_history:\n        messagebus.handle(e, uow)\n    [batch1, batch2] = uow.products.get(sku=\"INDIFFERENT-TABLE\").batches\n    assert batch1.available_quantity == 10\n    assert batch2.available_quantity == 50\n\n    messagebus.handle(events.BatchQuantityChanged(\"batch1\", 25), uow)\n\n    # assert on new events emitted rather than downstream side-effects\n    [reallocation_event] = uow.events_published\n    assert isinstance(reallocation_event, events.AllocationRequired)\n    assert reallocation_event.orderid in {\"order1\", \"order2\"}\n    assert reallocation_event.sku == \"INDIFFERENT-TABLE\"\n----\n====\n\nWhether you want to do this or not depends on the complexity of your chain of\nevents. We say, start out with edge-to-edge testing, and resort to\nthis only if necessary.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n*******************************************************************************\n\n(((\"message bus\", \"abstract message bus and its real and fake versions\")))\nA great way to force yourself to really understand some code is to refactor it.\nIn the discussion of testing handlers in isolation, we used something called\n`FakeUnitOfWorkWithFakeMessageBus`, which is unnecessarily complicated and\nviolates the SRP.\n\n(((\"Singleton pattern, messagebus.py implementing\")))\nIf we change the message bus to being a class,footnote:[The \"simple\"\nimplementation in this chapter essentially uses the _messagebus.py_ module\nitself to implement the Singleton Pattern.]\nthen building a `FakeMessageBus` is more straightforward:\n\n[[abc_for_fake_messagebus]]\n.An abstract message bus and its real and fake versions\n====\n[source,python]\n[role=\"skip\"]\n----\nclass AbstractMessageBus:\n    HANDLERS: Dict[Type[events.Event], List[Callable]]\n\n    def handle(self, event: events.Event):\n        for handler in self.HANDLERS[type(event)]:\n            handler(event)\n\n\nclass MessageBus(AbstractMessageBus):\n    HANDLERS = {\n        events.OutOfStock: [send_out_of_stock_notification],\n\n    }\n\n\nclass FakeMessageBus(messagebus.AbstractMessageBus):\n    def __init__(self):\n        self.events_published = []  # type: List[events.Event]\n        self.HANDLERS = {\n            events.OutOfStock: [lambda e: self.events_published.append(e)]\n        }\n----\n====\n\nSo jump into the code on\nhttps://github.com/cosmicpython/code/tree/chapter_09_all_messagebus[GitHub] and see if you can get a class-based version\nworking, and then write a version of `test_reallocates_if_necessary_isolated()`\nfrom earlier.\n\nWe use a class-based message bus in <<chapter_13_dependency_injection>>,\nif you need more inspiration.\n*******************************************************************************\n\n=== Wrap-Up\n\nLet's look back at what we've achieved, and think about why we did it.\n\n==== What Have We Achieved?\n\nEvents are simple dataclasses that define the data structures for inputs\n  and internal messages within our system. This is quite powerful from a DDD\n  standpoint, since events often translate really well into business language\n  (look up __event storming__ if you haven't already).\n\nHandlers are the way we react to events. They can call down to our\n  model or call out to external services.  We can define multiple\n  handlers for a single event if we want to. Handlers can also raise other\n  events. This allows us to be very granular about what a handler does\n  and really stick to the SRP.\n\n\n==== Why Have We Achieved?\n\n(((\"events and the message bus\", \"transforming our app into message processor\", \"whole app as message bus, trade-offs\")))\n(((\"message bus\", \"whole app as, trade-offs\")))\nOur ongoing objective with these architectural patterns is to try to have\nthe complexity of our application grow more slowly than its size.  When we\ngo all in on the message bus, as always we pay a price in terms of architectural\ncomplexity (see <<chapter_09_all_messagebus_tradeoffs>>), but we buy ourselves a\npattern that can handle almost arbitrarily complex requirements without needing\nany further conceptual or architectural change to the way we do things.\n\nHere we've added quite a complicated use case (change quantity, deallocate,\nstart new transaction, reallocate, publish external notification), but\narchitecturally, there's been no cost in terms of complexity. We've added new\nevents, new handlers, and a new external adapter (for email), all of which are\nexisting categories of _things_ in our architecture that we understand and know\nhow to reason about, and that are easy to explain to newcomers.  Our moving\nparts each have one job, they're connected to each other in well-defined ways,\nand there are no unexpected side effects.\n\n[[chapter_09_all_messagebus_tradeoffs]]\n[options=\"header\"]\n.Whole app is a message bus: the trade-offs\n|===\n|Pros|Cons\na|\n* Handlers and services are the same thing, so that's simpler.\n* We have a nice data structure for inputs to the system.\n\na|\n* A message bus is still a slightly unpredictable way of doing things from\n  a web point of view. You don't know in advance when things are going to end.\n* There will be duplication of fields and structure between model objects and events, which will have a maintenance cost. Adding a field to one usually means adding a field to at least\n  one of the others.\n|===\n\n(((\"events and the message bus\", \"transforming our app into message processor\", startref=\"ix_evntMBMP\")))\nNow, you may be wondering, where are those `BatchQuantityChanged` events\ngoing to come from? The answer is revealed in a couple chapters' time.  But\nfirst, let's talk about <<chapter_10_commands,events versus commands>>.\n"
        },
        {
          "name": "chapter_10_commands.asciidoc",
          "type": "blob",
          "size": 20.7578125,
          "content": "[[chapter_10_commands]]\n== Commands and Command Handler\n\n(((\"commands\", id=\"ix_cmnd\")))\nIn the previous chapter, we talked about using events as a way of representing\nthe inputs to our system, and we turned our application into a message-processing\nmachine.\n\nTo achieve that, we converted all our use-case functions to event handlers.\nWhen the API receives a POST to create a new batch, it builds a new `BatchCreated`\nevent and handles it as if it were an internal event.\nThis might feel counterintuitive. After all, the batch _hasn't_ been\ncreated yet; that's why we called the API. We're going to fix that conceptual\nwart by introducing commands and showing how they can be handled by the same\nmessage bus but with slightly different rules.\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_10_commands branch https://oreil.ly/U_VGa[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_10_commands\n# or to code along, checkout the previous chapter:\ngit checkout chapter_09_all_messagebus\n----\n====\n\n=== Commands and Events\n\n(((\"commands\", \"events versus\", id=\"ix_cmdevnt\")))\n(((\"events\", \"commands versus\", id=\"ix_evntcmd\")))\nLike events, _commands_ are a type of message--instructions sent by one part of\na system to another. We usually represent commands with dumb data\nstructures and can handle them in much the same way as events.\n\nThe differences between commands and events, though, are important.\n\nCommands are sent by one actor to another specific actor with the expectation that\na particular thing will happen as a result. When we post a form to an API handler,\nwe are sending a command. We name commands with imperative mood verb phrases like\n\"allocate stock\" or \"delay shipment.\"\n\nCommands capture _intent_. They express our wish for the system to do something.\nAs a result, when they fail, the sender needs to receive error information.\n\n_Events_ are broadcast by an actor to all interested listeners. When we publish\n`BatchQuantityChanged`, we don't know who's going to pick it up. We name events\nwith past-tense verb phrases like \"order allocated to stock\" or \"shipment delayed.\"\n\nWe often use events to spread the knowledge about successful commands.\n\nEvents capture _facts_ about things that happened in the past. Since we don't\nknow who's handling an event, senders should not care whether the receivers\nsucceeded or failed. <<events_vs_commands_table>> recaps the differences.\n\n[[events_vs_commands_table]]\n[options=\"header\"]\n.Events versus commands\n|===\ne|      e| Event e| Command\n| Named | Past tense | Imperative mood\n| Error handling | Fail independently | Fail noisily\n| Sent to | All listeners | One recipient\n|===\n\n\n// IDEA: Diagram of user \"buy stock\" -> \"stock purchased\"\n//                       \"create batch\" -> \"batch created\"\n// (EJ3) \"ChangeBatchQuantity\" -> \"AllocationRequired\" will be a less trivial example\n\n(((\"commands\", \"in our system now\")))\n(((\"commands\", \"events versus\", startref=\"ix_cmdevnt\")))\nWhat kinds of commands do we have in our system right now?\n\n[[commands_dot_py]]\n.Pulling out some commands (src/allocation/domain/commands.py)\n====\n[source,python]\n----\nclass Command:\n    pass\n\n\n@dataclass\nclass Allocate(Command):  #<1>\n    orderid: str\n    sku: str\n    qty: int\n\n\n@dataclass\nclass CreateBatch(Command):  #<2>\n    ref: str\n    sku: str\n    qty: int\n    eta: Optional[date] = None\n\n\n@dataclass\nclass ChangeBatchQuantity(Command):  #<3>\n    ref: str\n    qty: int\n----\n====\n\n<1> `commands.Allocate` will replace `events.AllocationRequired`.\n<2> `commands.CreateBatch` will replace `events.BatchCreated`.\n<3> `commands.ChangeBatchQuantity` will replace `events.BatchQuantityChanged`.\n\n\n=== Differences in Exception Handling\n\n\n(((\"message bus\", \"dispatching events and commands differently\")))\n(((\"exception handling, differences for events and commands\")))\n(((\"events\", \"commands versus\", startref=\"ix_evntcmd\")))\nJust changing the names and verbs is all very well, but that won't\nchange the behavior of our system.  We want to treat events and commands similarly,\nbut not exactly the same.  Let's see how our message bus changes:\n\n[[messagebus_dispatches_differently]]\n.Dispatch events and commands differently (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\nMessage = Union[commands.Command, events.Event]\n\n\ndef handle(  #<1>\n    message: Message,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    results = []\n    queue = [message]\n    while queue:\n        message = queue.pop(0)\n        if isinstance(message, events.Event):\n            handle_event(message, queue, uow)  #<2>\n        elif isinstance(message, commands.Command):\n            cmd_result = handle_command(message, queue, uow)  #<2>\n            results.append(cmd_result)\n        else:\n            raise Exception(f\"{message} was not an Event or Command\")\n    return results\n----\n====\n\n<1> It still has a main `handle()` entrypoint that takes a `message`, which may\n    be a command or an event.\n\n<2> We dispatch events and commands to two different helper functions, shown next.\n\n\nHere's how we handle events:\n\n[[handle_event]]\n.Events cannot interrupt the flow (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\ndef handle_event(\n    event: events.Event,\n    queue: List[Message],\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    for handler in EVENT_HANDLERS[type(event)]:  #<1>\n        try:\n            logger.debug(\"handling event %s with handler %s\", event, handler)\n            handler(event, uow=uow)\n            queue.extend(uow.collect_new_events())\n        except Exception:\n            logger.exception(\"Exception handling event %s\", event)\n            continue  #<2>\n----\n====\n\n<1> Events go to a dispatcher that can delegate to multiple handlers per\n    event.\n\n<2> It catches and logs errors but doesn't let them interrupt\n    message processing.\n\n(((\"commands\", \"exception handling\")))\nAnd here's how we do commands:\n\n[[handle_command]]\n.Commands reraise exceptions (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\ndef handle_command(\n    command: commands.Command,\n    queue: List[Message],\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    logger.debug(\"handling command %s\", command)\n    try:\n        handler = COMMAND_HANDLERS[type(command)]  #<1>\n        result = handler(command, uow=uow)\n        queue.extend(uow.collect_new_events())\n        return result  #<3>\n    except Exception:\n        logger.exception(\"Exception handling command %s\", command)\n        raise  #<2>\n----\n====\n\n\n<1> The command dispatcher expects just one handler per command.\n\n<2> If any errors are raised, they fail fast and will bubble up.\n\n<3> `return result` is only temporary; as mentioned in <<temporary_ugly_hack>>,\n    it's a temporary hack to allow the message bus to return the batch\n    reference for the API to use.  We'll fix this in <<chapter_12_cqrs>>.\n\n\n(((\"commands\", \"handlers for\")))\n(((\"handlers\", \"new HANDLERS dicts for commands and events\")))\n(((\"dictionaries\", \"HANDLERS dicts for commands and events\")))\nWe also change the single `HANDLERS` dict into different ones for\ncommands and events. Commands can have only one handler, according\nto our convention:\n\n[[new_handlers_dicts]]\n.New handlers dicts (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\nEVENT_HANDLERS = {\n    events.OutOfStock: [handlers.send_out_of_stock_notification],\n}  # type: Dict[Type[events.Event], List[Callable]]\n\nCOMMAND_HANDLERS = {\n    commands.Allocate: handlers.allocate,\n    commands.CreateBatch: handlers.add_batch,\n    commands.ChangeBatchQuantity: handlers.change_batch_quantity,\n}  # type: Dict[Type[commands.Command], Callable]\n----\n====\n\n\n\n=== Discussion: Events, Commands, and Error Handling\n\n(((\"commands\", \"events, commands, and error handling\", id=\"ix_cmndeverr\")))\n(((\"error handling\", \"events, commands, and\", id=\"ix_errhnd\")))\n(((\"events\", \"events, commands, and error handling\", id=\"ix_evntcmderr\")))\nMany developers get uncomfortable at this point and ask, \"What happens when an\nevent fails to process? How am I supposed to make sure the system is in a\nconsistent state?\" If we manage to process half of the events during `messagebus.handle` before an\nout-of-memory error kills our process, how do we mitigate problems caused by the\nlost messages?\n\nLet's start with the worst case: we fail to handle an event, and the system is\nleft in an inconsistent state. What kind of error would cause this? Often in our\nsystems we can end up in an inconsistent state when only half an operation is\ncompleted.\n\nFor example, we could allocate three units of `DESIRABLE_BEANBAG` to a customer's\norder but somehow fail to reduce the amount of remaining stock. This would\ncause an inconsistent state: the three units of stock are both allocated _and_\navailable, depending on how you look at it. Later, we might allocate those\nsame beanbags to another customer, causing a headache for customer support.\n\n(((\"Unit of Work pattern\", \"UoW managing success or failure of aggregate update\")))\n(((\"consistency boundaries\", \"aggregates acting as\")))\n(((\"aggregates\", \"acting as consistency boundaries\")))\nIn our allocation service, though, we've already taken steps to prevent that\nhappening. We've carefully identified _aggregates_ that act as consistency\nboundaries, and we've introduced a _UoW_ that manages the atomic\nsuccess or failure of an update to an aggregate.\n\n(((\"Product object\", \"acting as consistency boundary\")))\nFor example, when we allocate stock to an order, our consistency boundary is the\n`Product` aggregate. This means that we can't accidentally overallocate: either\na particular order line is allocated to the product, or it is not--there's no\nroom for inconsistent states.\n\nBy definition, we don't require two aggregates to be immediately consistent, so\nif we fail to process an event and update only a single aggregate, our system\ncan still be made eventually consistent. We shouldn't violate any constraints of\nthe system.\n\nWith this example in mind, we can better understand the reason for splitting\nmessages into commands and events. When a user wants to make the system do\nsomething, we represent their request as a _command_. That command should modify\na single _aggregate_ and either succeed or fail in totality. Any other bookkeeping, cleanup, and notification we need to do can happen via an _event_. We\ndon't require the event handlers to succeed in order for the command to be\nsuccessful.\n\nLet's look at another example (from a different, imaginary project) to see why not.\n\nImagine we are building an ecommerce website that sells expensive luxury goods.\nOur marketing department wants to reward customers for repeat visits. We will\nflag customers as VIPs after they make their third purchase, and this will\nentitle them to priority treatment and special offers. Our acceptance criteria\nfor this story reads as follows:\n\n\n[source,gherkin]\n[role=\"skip\"]\n----\nGiven a customer with two orders in their history,\nWhen the customer places a third order,\nThen they should be flagged as a VIP.\n\nWhen a customer first becomes a VIP\nThen we should send them an email to congratulate them\n----\n\n(((\"aggregates\", \"History aggregate recording orders and raising domain events\")))\nUsing the techniques we've already discussed in this book, we decide that we\nwant to build a new `History` aggregate that records orders and can raise domain\nevents when rules are met. We will structure the code like this:\n\n\n[[vip_customer_listing]]\n.VIP customer (example code for a different project)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass History:  # Aggregate\n\n    def __init__(self, customer_id: int):\n        self.orders = set()  # Set[HistoryEntry]\n        self.customer_id = customer_id\n\n    def record_order(self, order_id: str, order_amount: int): #<1>\n        entry = HistoryEntry(order_id, order_amount)\n\n        if entry in self.orders:\n            return\n\n        self.orders.add(entry)\n\n        if len(self.orders) == 3:\n            self.events.append(\n                CustomerBecameVIP(self.customer_id)\n            )\n\n\ndef create_order_from_basket(uow, cmd: CreateOrder): #<2>\n    with uow:\n        order = Order.from_basket(cmd.customer_id, cmd.basket_items)\n        uow.orders.add(order)\n        uow.commit()  # raises OrderCreated\n\n\ndef update_customer_history(uow, event: OrderCreated): #<3>\n    with uow:\n        history = uow.order_history.get(event.customer_id)\n        history.record_order(event.order_id, event.order_amount)\n        uow.commit()  # raises CustomerBecameVIP\n\n\ndef congratulate_vip_customer(uow, event: CustomerBecameVip): #<4>\n    with uow:\n        customer = uow.customers.get(event.customer_id)\n        email.send(\n            customer.email_address,\n            f'Congratulations {customer.first_name}!'\n        )\n\n----\n====\n\n<1> The `History` aggregate captures the rules indicating when a customer becomes a VIP.\n    This puts us in a good place to handle changes when the rules become more\n    complex in the future.\n\n<2> Our first handler creates an order for the customer and raises a domain\n    event `OrderCreated`.\n\n<3> Our second handler updates the `History` object to record that an order was\n    [.keep-together]#created#.\n\n<4> Finally, we send an email to the customer when they become a VIP.\n\n//IDEA: Sequence diagram here?\n\nUsing this code, we can gain some intuition about error handling in an\nevent-driven system.\n\n(((\"aggregates\", \"raising events about\")))\nIn our current implementation, we raise events about an aggregate _after_ we\npersist our state to the database. What if we raised those events _before_ we\npersisted, and committed all our changes at the same time? That way, we could be\nsure that all the work was complete. Wouldn't that be safer?\n\nWhat happens, though, if the email server is slightly overloaded? If all the work\nhas to complete at the same time, a busy email server can stop us from taking money\nfor orders.\n\nWhat happens if there is a bug in the implementation of the `History` aggregate?\nShould we fail to take your money just because we can't recognize you as a VIP?\n\nBy separating out these concerns, we have made it possible for things to fail\nin isolation, which improves the overall reliability of the system. The only\npart of this code that _has_ to complete is the command handler that creates an\norder. This is the only part that a customer cares about, and it's the part that\nour business stakeholders should prioritize.\n\n(((\"commands\", \"events, commands, and error handling\", startref=\"ix_cmndeverr\")))\n(((\"error handling\", \"events, commands, and\", startref=\"ix_errhnd\")))\n(((\"events\", \"events, commands, and error handling\", startref=\"ix_evntcmderr\")))\nNotice how we've deliberately aligned our transactional boundaries to the start\nand end of the business processes. The names that we use in the code match the\njargon used by our business stakeholders, and the handlers we've written match\nthe steps of our natural language acceptance criteria. This concordance of names\nand structure helps us to reason about our systems as they grow larger and more\ncomplex.\n\n\n[[recovering_from_errors]]\n=== Recovering from Errors Synchronously\n\n(((\"commands\", \"events, commands, and error handling\", \"recovering from errors synchronously\")))\n(((\"errors, recovering from synchronously\")))\nHopefully we've convinced you that it's OK for events to fail independently\nfrom the commands that raised them. What should we do, then, to make sure we\ncan recover from errors when they inevitably occur?\n\nThe first thing we need is to know _when_ an error has occurred, and for that we\nusually rely on logs.\n\n(((\"message bus\", \"handle_event method\")))\nLet's look again at the `handle_event` method from our message bus:\n\n[[messagebus_logging]]\n.Current handle function (src/allocation/service_layer/messagebus.py)\n====\n[source,python,highlight=8;12]\n----\ndef handle_event(\n    event: events.Event,\n    queue: List[Message],\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    for handler in EVENT_HANDLERS[type(event)]:\n        try:\n            logger.debug(\"handling event %s with handler %s\", event, handler)\n            handler(event, uow=uow)\n            queue.extend(uow.collect_new_events())\n        except Exception:\n            logger.exception(\"Exception handling event %s\", event)\n            continue\n----\n====\n\nWhen we handle a message in our system, the first thing we do is write a log\nline to record what we're about to do. For our `CustomerBecameVIP` use case, the\nlogs might read as follows:\n\n----\nHandling event CustomerBecameVIP(customer_id=12345)\nwith handler <function congratulate_vip_customer at 0x10ebc9a60>\n----\n\n(((\"dataclasses\", \"use for message types\")))\nBecause we've chosen to use dataclasses for our message types, we get a neatly\nprinted summary of the incoming data that we can copy and paste into a Python\nshell to re-create the object.\n\nWhen an error occurs, we can use the logged data to either reproduce the problem\nin a unit test or replay the message into the system.\n\nManual replay works well for cases where we need to fix a bug before we can\nre-process an event, but our systems will _always_ experience some background\nlevel of transient failure. This includes things like network hiccups, table\ndeadlocks, and brief downtime caused by deployments.\n\n(((\"retries\", \"message bus handle_event with\")))\n(((\"message bus\", \"handle_event with retries\")))\nFor most of those cases, we can recover elegantly by trying again. As the\nproverb says, \"If at first you don't succeed, retry the operation with an\nexponentially increasing back-off period.\"\n\n[[messagebus_handle_event_with_retry]]\n.Handle with retry (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nfrom tenacity import Retrying, RetryError, stop_after_attempt, wait_exponential #<1>\n\n...\n\ndef handle_event(\n    event: events.Event,\n    queue: List[Message],\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    for handler in EVENT_HANDLERS[type(event)]:\n        try:\n            for attempt in Retrying(  #<2>\n                stop=stop_after_attempt(3),\n                wait=wait_exponential()\n            ):\n\n                with attempt:\n                    logger.debug(\"handling event %s with handler %s\", event, handler)\n                    handler(event, uow=uow)\n                    queue.extend(uow.collect_new_events())\n        except RetryError as retry_failure:\n            logger.error(\n                \"Failed to handle event %s times, giving up!\",\n                retry_failure.last_attempt.attempt_number\n            )\n            continue\n\n----\n====\n\n<1> Tenacity is a Python library that implements common patterns for retrying.\n    (((\"Tenacity library\")))\n    (((\"retries\", \"Tenacity library for\")))\n\n<2> Here we configure our message bus to retry operations up to three times,\n    with an exponentially increasing wait between attempts.\n\nRetrying operations that might fail is probably the single best way to improve\nthe resilience of our software. Again, the Unit of Work and Command Handler\npatterns mean that each attempt starts from a consistent state and won't leave\nthings half-finished.\n\nWARNING: At some point, regardless of `tenacity`, we'll have to give up trying to\n    process the message. Building reliable systems with distributed messages is\n    hard, and we have to skim over some tricky bits. There are pointers to more\n    reference materials in the <<epilogue_1_how_to_get_there_from_here, epilogue>>.\n\n[role=\"pagebreak-before less_space\"]\n=== Wrap-Up\n\n(((\"Command Handler pattern\")))\n(((\"events\", \"splitting command and events, trade-offs\")))\n(((\"commands\", \"splitting commands and events, trade-offs\")))\nIn this book we decided to introduce the concept of events before the concept\nof commands, but other guides often do it the other way around.  Making\nexplicit the requests that our system can respond to by giving them a name\nand their own data structure is quite a fundamental thing to do.  You'll\nsometimes see people use the name _Command Handler_ pattern to describe what\nwe're doing with Events, Commands, and Message Bus.\n\n<<chapter_10_commands_and_events_tradeoffs>> discusses some of the things you\nshould think about before you jump on board.\n\n[[chapter_10_commands_and_events_tradeoffs]]\n[options=\"header\"]\n.Splitting commands and events: the trade-offs\n|===\n|Pros|Cons\na|\n* Treating commands and events differently helps us understand which things\n  have to succeed and which things we can tidy up later.\n\n* `CreateBatch` is definitely a less confusing name than `BatchCreated`. We are\n  being explicit about the intent of our users, and explicit is better than\n  implicit, right?\n\na|\n* The semantic differences between commands and events can be subtle. Expect\n  bikeshedding arguments over the differences.\n\n* We're expressly inviting failure. We know that sometimes things will break, and\n  we're choosing to handle that by making the failures smaller and more isolated.\n  This can make the system harder to reason about and requires better monitoring.\n  (((\"commands\", startref=\"ix_cmnd\")))\n\n|===\n\nIn <<chapter_11_external_events>> we'll talk about using events as an integration pattern.\n// IDEA: discussion, can events raise commands?\n"
        },
        {
          "name": "chapter_11_external_events.asciidoc",
          "type": "blob",
          "size": 26.0654296875,
          "content": "[[chapter_11_external_events]]\n== Event-Driven Architecture: Using Events to Integrate Microservices\n\n(((\"event-driven architecture\", \"using events to integrate microservices\", id=\"ix_evntarch\")))\n(((\"external events\", id=\"ix_extevnt\")))\n(((\"microservices\", \"event-based integration\", id=\"ix_mcroevnt\")))\nIn the preceding chapter, we never actually spoke about _how_ we would receive\nthe \"batch quantity changed\" events, or indeed, how we might notify the\noutside world about reallocations.\n\nWe have a microservice with a web API, but what about other ways of talking\nto other systems?  How will we know if, say, a shipment is delayed or the\nquantity is amended? How will we tell the warehouse system that an order has\nbeen allocated and needs to be sent to a customer?\n\nIn this chapter, we'd like to show how the events metaphor can be extended\nto encompass the way that we handle incoming and outgoing messages from the\nsystem. Internally, the core of our application is now a message processor.\nLet's follow through on that so it becomes a message processor _externally_ as\nwell. As shown in <<message_processor_diagram>>, our application will receive\nevents from external sources via an external message bus (we'll use Redis pub/sub\nqueues as an example) and publish its outputs, in the form of events, back\nthere as well.\n\n[[message_processor_diagram]]\n.Our application is a message processor\nimage::images/apwp_1101.png[]\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_11_external_events branch https://oreil.ly/UiwRS[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_11_external_events\n# or to code along, checkout the previous chapter:\ngit checkout chapter_10_commands\n----\n====\n\n\n=== Distributed Ball of Mud, and Thinking in Nouns\n\n(((\"Distributed Ball of Mud antipattern\", \"and thinking in nouns\", id=\"ix_DBoM\")))\n(((\"Ball of Mud pattern\", \"distributed ball of mud and thinking in nouns\", id=\"ix_BoMdist\")))\n(((\"microservices\", \"event-based integration\", \"distributed Ball of Mud and thinking in nouns\", id=\"ix_mcroevntBoM\")))\n(((\"nouns, splitting system into\", id=\"ix_noun\")))\nBefore we get into that, let's talk about the alternatives. We regularly talk to\nengineers who are trying to build out a microservices architecture. Often they\nare migrating from an existing application, and their first instinct is to\nsplit their system into _nouns_.\n\nWhat nouns have we introduced so far in our system? Well, we have batches of\nstock, orders, products, and customers. So a naive attempt at breaking\nup the system might have looked like <<batches_context_diagram>> (notice that\nwe've named our system after a noun, _Batches_, instead of _Allocation_).\n\n[[batches_context_diagram]]\n.Context diagram with noun-based services\nimage::images/apwp_1102.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1102, config=plantuml.cfg]\n@startuml Batches Context Diagram\n!include images/C4_Context.puml\n\nSystem(batches, \"Batches\", \"Knows about available stock\")\nPerson(customer, \"Customer\", \"Wants to buy furniture\")\nSystem(orders, \"Orders\", \"Knows about customer orders\")\nSystem(warehouse, \"Warehouse\", \"Knows about shipping instructions\")\n\nRel_R(customer, orders, \"Places order with\")\nRel_D(orders, batches, \"Reserves stock with\")\nRel_D(batches, warehouse, \"Sends instructions to\")\n\n@enduml\n----\n\nEach \"thing\" in our system has an associated service, which exposes an HTTP API.\n\n(((\"commands\", \"command flow to reserve stock, confirm reservation, dispatch goods, and make customer VIP\")))\nLet's work through an example happy-path flow in <<command_flow_diagram_1>>:\nour users visit a website and can choose from products that are in stock. When\nthey add an item to their basket, we will reserve some stock for them. When an\norder is complete, we confirm the reservation, which causes us to send dispatch\ninstructions to the warehouse. Let's also say, if this is the customer's third\norder, we want to update the customer record to flag them as a VIP.\n\n[role=\"width-80\"]\n[[command_flow_diagram_1]]\n.Command flow 1\nimage::images/apwp_1103.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1103, config=plantuml.cfg]\n@startuml\nscale 4\n\nactor Customer\nentity Orders\nentity Batches\nentity Warehouse\ndatabase CRM\n\n\n== Reservation ==\n\n  Customer -> Orders: Add product to basket\n  Orders -> Batches: Reserve stock\n\n== Purchase ==\n\n  Customer -> Orders: Place order\n  activate Orders\n  Orders -> Batches: Confirm reservation\n  Batches -> Warehouse: Dispatch goods\n  Orders -> CRM: Update customer record\n  deactivate Orders\n\n\n@enduml\n----\n\n////\n\nTODO (EJ1)\n\nI'm having a little bit of trouble understanding the sequence diagrams in this section\nbecause I'm unsure what the arrow semantics are. The couple things I've noticed are:\n\n* PlantUML renders synchronous messages with a non-standard arrowhead that\n  looks like a cross between the synch/async messages in standard UML. Other\n  users have had this complaint and there is a fix that just involves adding\n  the directive skinparam style strictuml.\n\n* The use of different line-types and arrowheads is in-consistent between\n  diagrams, which makes things harder to understand. (Or I am mis-understanding\n  the examples.)\n\nA legend that explicitly defines the arrow meanings would be helpful. And maybe\ndeveloping examples over the preceding chapters would build familiarity with\nthe different symbols.\n////\n\n\nWe can think of each of these steps as a command in our system: `ReserveStock`,\n[.keep-together]#`ConfirmReservation`#, `DispatchGoods`, `MakeCustomerVIP`, and so forth.\n\nThis style of architecture, where we create a microservice per database table\nand treat our HTTP APIs as CRUD interfaces to anemic models, is the most common\ninitial way for people to approach service-oriented design.\n\nThis works _fine_ for systems that are very simple, but it can quickly degrade into\na distributed ball of mud.\n\nTo see why, let's consider another case. Sometimes, when stock arrives at the\nwarehouse, we discover that items have been water damaged during transit. We\ncan't sell water-damaged sofas, so we have to throw them away and request more\nstock from our partners. We also need to update our stock model, and that\nmight mean we need to reallocate a customer's order.\n\nWhere does this logic go?\n\n(((\"commands\", \"command flow when warehouse knows stock is damaged\")))\nWell, the Warehouse system knows that the stock has been damaged, so maybe it\nshould own this process, as shown in <<command_flow_diagram_2>>.\n\n[[command_flow_diagram_2]]\n.Command flow 2\nimage::images/apwp_1104.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1104, config=plantuml.cfg]\n@startuml\nscale 4\n\nactor w as \"Warehouse worker\"\nentity Warehouse\nentity Batches\nentity Orders\ndatabase CRM\n\n\n  w -> Warehouse: Report stock damage\n  activate Warehouse\n  Warehouse -> Batches: Decrease available stock\n  Batches -> Batches: Reallocate orders\n  Batches -> Orders: Update order status\n  Orders -> CRM: Update order history\n  deactivate Warehouse\n\n@enduml\n----\n\nThis sort of works too, but now our dependency graph is a mess. To\nallocate stock, the Orders service drives the Batches system, which drives\nWarehouse; but in order to handle problems at the warehouse, our Warehouse\nsystem drives Batches, which drives Orders.\n\nMultiply this by all the other workflows we need to provide, and you can see\nhow services quickly get tangled up.\n(((\"microservices\", \"event-based integration\", \"distributed Ball of Mud and thinking in nouns\", startref=\"ix_mcroevntBoM\")))\n(((\"nouns, splitting system into\", startref=\"ix_noun\")))\n(((\"Ball of Mud pattern\", \"distributed ball of mud and thinking in nouns\", startref=\"ix_BoMdist\")))\n(((\"Distributed Ball of Mud antipattern\", \"and thinking in nouns\", startref=\"ix_DBoM\")))\n\n=== Error Handling in Distributed Systems ===\n\n(((\"microservices\", \"event-based integration\", \"error handling in distributed systems\", id=\"ix_mcroevnterr\")))\n(((\"error handling\", \"in distributed systems\", id=\"ix_errhnddst\")))\n\"Things break\" is a universal law of software engineering. What happens in our\nsystem when one of our requests fails? Let's say that a network error happens\nright after we take a user's order for three `MISBEGOTTEN-RUG`, as shown in\n<<command_flow_diagram_with_error>>.\n\nWe have two options here: we can place the order anyway and leave it\nunallocated, or we can refuse to take the order because the allocation can't be\nguaranteed. The failure state of our batches service has bubbled up and is\naffecting the reliability of our order service.\n\n(((\"temporal coupling\")))\n(((\"coupling\", \"failure cascade as temporal coupling\")))\n(((\"commands\", \"command flow with error\")))\nWhen two things have to be changed together, we say that they are _coupled_. We\ncan think of this failure cascade as a kind of _temporal coupling_: every part\nof the system has to work at the same time for any part of it to work. As the\nsystem gets bigger, there is an exponentially increasing probability that some\npart is degraded.\n\n[[command_flow_diagram_with_error]]\n.Command flow with error\nimage::images/apwp_1105.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1105, config=plantuml.cfg]\n@startuml\nscale 4\n\nactor Customer\nentity Orders\nentity Batches\n\nCustomer -> Orders: Place order\nOrders -[#red]x Batches: Confirm reservation\nhnote right: network error\nOrders --> Customer: ???\n\n@enduml\n----\n\n[role=\"nobreakinside less_space\"]\n[[connascence_sidebar]]\n.Connascence\n*******************************************************************************\n\n(((\"connascence\")))\nWe're using the term _coupling_ here, but there's another way to describe\nthe relationships between our systems. _Connascence_ is a term used by some\nauthors to describe the different types of coupling.\n\nConnascence isn't _bad_, but some types of connascence are _stronger_ than\nothers. We want to have strong connascence locally, as when two classes are\nclosely related, but weak connascence at a distance.\n\nIn our first example of a distributed ball of mud, we see Connascence of\nExecution: multiple components need to know the correct order of work for an\noperation to be successful.\n\nWhen thinking about error conditions here, we're talking about Connascence of\nTiming: multiple things have to happen, one after another, for the operation to\nwork.\n\nWhen we replace our RPC-style system with events, we replace both of these types\nof connascence with a _weaker_ type. That's Connascence of Name: multiple\ncomponents need to agree only on the name of an event and the names of fields\nit carries.\n\n(((\"coupling\", \"avoiding inappropriate coupling\")))\nWe can never completely avoid coupling, except by having our software not talk\nto any other software. What we want is to avoid _inappropriate_ coupling.\nConnascence provides a mental model for understanding the strength and type of\ncoupling inherent in different architectural styles. Read all about it at\nhttp://www.connascence.io[connascence.io].\n*******************************************************************************\n\n\n=== The Alternative: Temporal Decoupling Using Asynchronous Messaging\n\n(((\"messaging\", \"asynchronous, temporal decoupling with\")))\n(((\"temporal decoupling using asynchronous messaging\")))\n(((\"coupling\", \"temporal decoupling using asynchronous messaging\")))\n(((\"asynchronous messaging, temporal decoupling with\")))\n(((\"microservices\", \"event-based integration\", \"temporal decoupling using asynchronous messaging\")))\n(((\"microservices\", \"event-based integration\", \"error handling in distributed systems\", startref=\"ix_mcroevnterr\")))\n(((\"error handling\", \"in distributed systems\", startref=\"ix_errhnddst\")))\nHow do we get appropriate coupling? We've already seen part of the answer, which is that we should think in\nterms of verbs, not nouns. Our domain model is about modeling a business\nprocess. It's not a static data model about a thing; it's a model of a verb.\n\nSo instead of thinking about a system for orders and a system for batches,\nwe think about a system for _ordering_ and a system for _allocating_, and\nso on.\n\nWhen we separate things this way, it's a little easier to see which system\nshould be responsible for what.  When thinking about _ordering_, really we want\nto make sure that when we place an order, the order is placed. Everything else\ncan happen _later_, so long as it happens.\n\nNOTE: If this sounds familiar, it should!  Segregating responsibilities is\n    the same process we went through when designing our aggregates and commands.\n\n(((\"Distributed Ball of Mud antipattern\", \"avoiding\")))\n(((\"consistency boundaries\", \"microservices as\")))\nLike aggregates, microservices should be _consistency boundaries_. Between two\nservices, we can accept eventual consistency, and that means we don't need to\nrely on synchronous calls. Each service accepts commands from the outside world\nand raises events to record the result. Other services can listen to those\nevents to trigger the next steps in the workflow.\n\nTo avoid the Distributed Ball of Mud antipattern, instead of temporally coupled HTTP\nAPI calls, we want to use asynchronous messaging to integrate our systems. We\nwant our `BatchQuantityChanged` messages to come in as external messages from\nupstream systems, and we want our system to publish `Allocated` events for\ndownstream systems to listen to.\n\nWhy is this better? First, because things can fail independently, it's easier\nto handle degraded behavior: we can still take orders if the allocation system\nis having a bad day.\n\nSecond, we're reducing the strength of coupling between our systems. If we\nneed to change the order of operations or to introduce new steps in the process,\nwe can do that locally.\n\n// IDEA: need to add an example of a process change.  And/or explain \"locally\"\n// (EJ3) I think this is clear enough.  Not sure about for a junior dev.\n\n\n=== Using a Redis Pub/Sub Channel for Integration\n\n(((\"message brokers\")))\n(((\"publish-subscribe system\", \"using Redis pub/sub channel for microservices integration\")))\n(((\"messaging\", \"using Redis pub/sub channel for microservices integration\")))\n(((\"Redis pub/sub channel, using for microservices integration\")))\n(((\"microservices\", \"event-based integration\", \"using Redis pub/sub channel for integration\")))\nLet's see how it will all work concretely. We'll need some way of getting\nevents out of one system and into another, like our message bus, but for\nservices. This piece of infrastructure is often called a _message broker_. The\nrole of a message broker is to take messages from publishers and deliver them\nto subscribers.\n\nAt MADE.com, we use https://eventstore.org[Event Store]; Kafka or RabbitMQ\nare valid alternatives. A lightweight solution based on Redis\nhttps://redis.io/topics/pubsub[pub/sub channels] can also work just fine, and because\nRedis is much more generally familiar to people, we thought we'd use it for this\nbook.\n\nNOTE: We're glossing over the complexity involved in choosing the right messaging\n    platform. Concerns like message ordering, failure handling, and idempotency\n    all need to be thought through. For a few pointers, see\n    <<footguns>>.\n\n\nOur new flow will look like <<reallocation_sequence_diagram_with_redis>>:\nRedis provides the `BatchQuantityChanged` event that kicks off the whole process, and our `Allocated` event is published back out to Redis again at the\nend.\n\n[role=\"width-75\"]\n[[reallocation_sequence_diagram_with_redis]]\n.Sequence diagram for reallocation flow\nimage::images/apwp_1106.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1106, config=plantuml.cfg]\n@startuml\nscale 4\n\nRedis -> MessageBus : BatchQuantityChanged event\n\ngroup BatchQuantityChanged Handler + Unit of Work 1\n    MessageBus -> Domain_Model : change batch quantity\n    Domain_Model -> MessageBus : emit Allocate command(s)\nend\n\n\ngroup Allocate Handler + Unit of Work 2 (or more)\n    MessageBus -> Domain_Model : allocate\n    Domain_Model -> MessageBus : emit Allocated event(s)\nend\n\nMessageBus -> Redis : publish to line_allocated channel\n@enduml\n----\n\n\n\n=== Test-Driving It All Using an End-to-End Test\n\n(((\"microservices\", \"event-based integration\", \"testing with end-to-end test\", id=\"ix_mcroevnttst\")))\n(((\"Redis pub/sub channel, using for microservices integration\", \"testing pub/sub model\")))\n(((\"testing\", \"end-to-end test of pub/sub model\")))\nHere's how we might start with an end-to-end test.  We can use our existing\nAPI to create batches, and then we'll test both inbound and outbound messages:\n\n\n[[redis_e2e_test]]\n.An end-to-end test for our pub/sub model (tests/e2e/test_external_events.py)\n====\n[source,python]\n----\ndef test_change_batch_quantity_leading_to_reallocation():\n    # start with two batches and an order allocated to one of them  #<1>\n    orderid, sku = random_orderid(), random_sku()\n    earlier_batch, later_batch = random_batchref(\"old\"), random_batchref(\"newer\")\n    api_client.post_to_add_batch(earlier_batch, sku, qty=10, eta=\"2011-01-01\")  #<2>\n    api_client.post_to_add_batch(later_batch, sku, qty=10, eta=\"2011-01-02\")\n    response = api_client.post_to_allocate(orderid, sku, 10)  #<2>\n    assert response.json()[\"batchref\"] == earlier_batch\n\n    subscription = redis_client.subscribe_to(\"line_allocated\")  #<3>\n\n    # change quantity on allocated batch so it's less than our order  #<1>\n    redis_client.publish_message(  #<3>\n        \"change_batch_quantity\",\n        {\"batchref\": earlier_batch, \"qty\": 5},\n    )\n\n    # wait until we see a message saying the order has been reallocated  #<1>\n    messages = []\n    for attempt in Retrying(stop=stop_after_delay(3), reraise=True):  #<4>\n        with attempt:\n            message = subscription.get_message(timeout=1)\n            if message:\n                messages.append(message)\n                print(messages)\n            data = json.loads(messages[-1][\"data\"])\n            assert data[\"orderid\"] == orderid\n            assert data[\"batchref\"] == later_batch\n----\n====\n\n<1> You can read the story of what's going on in this test from the comments:\n    we want to send an event into the system that causes an order line to be\n    reallocated, and we see that reallocation come out as an event in Redis too.\n\n<2> `api_client` is a little helper that we refactored out to share between\n    our two test types; it wraps our calls to `requests.post`.\n\n<3> `redis_client` is another little test helper, the details of which\n    don't really matter; its job is to be able to send and receive messages\n    from various Redis channels. We'll use a channel called\n    `change_batch_quantity` to send in our request to change the quantity for a\n    batch, and we'll listen to another channel called `line_allocated` to\n    look out for the expected reallocation.\n\n<4> Because of the asynchronous nature of the system under test, we need to use\n    the `tenacity` library again to add a retry loop—first, because it may\n    take some time for our new `line_allocated` message to arrive, but also\n    because it won't be the only message on that channel.\n\n////\nNITPICK (EJ3) Minor comment: This e2e test might not be safe or repeatable as\npart of a larger test suite, since test run data is being persisted in redis.\nPurging the queue as part of setup will help, but it would still have problems\nwith running tests in parallel. Not sure if it's worth bringing up as it might\nbe too much of a digression.\n////\n\n\n\n==== Redis Is Another Thin Adapter Around Our Message Bus\n\n(((\"Redis pub/sub channel, using for microservices integration\", \"testing pub/sub model\", \"Redis as thin adapter around message bus\")))\n(((\"message bus\", \"Redis pub/sub listener as thin adapter around\")))\nOur Redis pub/sub listener (we call it an _event consumer_) is very much like\nFlask: it translates from the outside world to our events:\n\n\n[[redis_eventconsumer_first_cut]]\n.Simple Redis message listener (src/allocation/entrypoints/redis_eventconsumer.py)\n====\n[source,python]\n----\nr = redis.Redis(**config.get_redis_host_and_port())\n\n\ndef main():\n    orm.start_mappers()\n    pubsub = r.pubsub(ignore_subscribe_messages=True)\n    pubsub.subscribe(\"change_batch_quantity\")  #<1>\n\n    for m in pubsub.listen():\n        handle_change_batch_quantity(m)\n\n\ndef handle_change_batch_quantity(m):\n    logging.debug(\"handling %s\", m)\n    data = json.loads(m[\"data\"])  #<2>\n    cmd = commands.ChangeBatchQuantity(ref=data[\"batchref\"], qty=data[\"qty\"])  #<2>\n    messagebus.handle(cmd, uow=unit_of_work.SqlAlchemyUnitOfWork())\n----\n====\n\n<1> `main()` subscribes us to the `change_batch_quantity` channel on load.\n\n<2> Our main job as an entrypoint to the system is to deserialize JSON,\n    convert it to a `Command`, and pass it to the service layer--much as the\n    Flask adapter does.\n\nWe also build a new downstream adapter to do the opposite job—converting\n domain events to public events:\n\n[[redis_eventpubisher_first_cut]]\n.Simple Redis message publisher (src/allocation/adapters/redis_eventpublisher.py)\n====\n[source,python]\n----\nr = redis.Redis(**config.get_redis_host_and_port())\n\n\ndef publish(channel, event: events.Event):  #<1>\n    logging.debug(\"publishing: channel=%s, event=%s\", channel, event)\n    r.publish(channel, json.dumps(asdict(event)))\n----\n====\n\n<1> We take a hardcoded channel here, but you could also store\n    a mapping between event classes/names and the appropriate channel,\n    allowing one or more message types to go to different channels.\n\n\n==== Our New Outgoing Event\n\n(((\"Allocated event\")))\nHere's what the `Allocated` event will look like:\n\n[[allocated_event]]\n.New event (src/allocation/domain/events.py)\n====\n[source,python]\n----\n@dataclass\nclass Allocated(Event):\n    orderid: str\n    sku: str\n    qty: int\n    batchref: str\n----\n====\n\nIt captures everything we need to know about an allocation: the details of the\norder line, and which batch it was allocated to.\n\nWe add it into our model's `allocate()` method (having added a test\nfirst, naturally):\n\n[[model_emits_allocated_event]]\n.Product.allocate() emits new event to record what happened (src/allocation/domain/model.py)\n====\n[source,python]\n----\nclass Product:\n    ...\n    def allocate(self, line: OrderLine) -> str:\n        ...\n\n            batch.allocate(line)\n            self.version_number += 1\n            self.events.append(\n                events.Allocated(\n                    orderid=line.orderid,\n                    sku=line.sku,\n                    qty=line.qty,\n                    batchref=batch.reference,\n                )\n            )\n            return batch.reference\n----\n====\n\n\n(((\"message bus\", \"handler publishing outgoing event\")))\nThe handler for `ChangeBatchQuantity` already exists, so all we need to add\nis a handler that publishes the outgoing event:\n\n\n[[another_handler]]\n.The message bus grows (src/allocation/service_layer/messagebus.py)\n====\n[source,python,highlight=2]\n----\nHANDLERS = {\n    events.Allocated: [handlers.publish_allocated_event],\n    events.OutOfStock: [handlers.send_out_of_stock_notification],\n}  # type: Dict[Type[events.Event], List[Callable]]\n----\n====\n\n(((\"Redis pub/sub channel, using for microservices integration\", \"testing pub/sub model\", \"publishing outgoing event\")))\nPublishing the event uses our helper function from the Redis wrapper:\n\n[[publish_event_handler]]\n.Publish to Redis (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n----\ndef publish_allocated_event(\n    event: events.Allocated,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    redis_eventpublisher.publish(\"line_allocated\", event)\n----\n====\n\n=== Internal Versus External Events\n\n(((\"events\", \"internal versus external\")))\n(((\"microservices\", \"event-based integration\", \"testing with end-to-end test\", startref=\"ix_mcroevnttst\")))\nIt's a good idea to keep the distinction between internal and external events\nclear.  Some events may come from the outside, and some events may get upgraded\nand published externally, but not all of them will.  This is particularly important\nif you get into\nhttps://oreil.ly/FXVil[event sourcing]\n(very much a topic for another book, though).\n\n\nTIP: Outbound events are one of the places it's important to apply validation.\n    See <<appendix_validation>> for some validation philosophy and [.keep-together]#examples#.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader\n*******************************************************************************\n\nA nice simple one for this chapter: make it so that the main `allocate()` use\ncase can also be invoked by an event on a Redis channel, as well as (or instead of)\nvia the API.\n\nYou will likely want to add a new E2E test and feed through some changes into\n[.keep-together]#__redis_eventconsumer.py__#.\n\n*******************************************************************************\n\n\n=== Wrap-Up\n\nEvents can come _from_ the outside, but they can also be published\nexternally--our `publish` handler converts an event to a message on a Redis\nchannel. We use events to talk to the outside world.  This kind of temporal\ndecoupling buys us a lot of flexibility in our application integrations, but\nas always, it comes at a cost.\n(((\"Fowler, Martin\")))\n\n++++\n<blockquote>\n\n<p>\nEvent notification is nice because it implies a low level of coupling, and is\npretty simple to set up. It can become problematic, however, if there really is\na logical flow that runs over various event notifications...It can be hard to\nsee such a flow as it's not explicit in any program text....This can make it hard to debug\nand modify.\n</p>\n\n<p data-type=\"attribution\">Martin Fowler, <a href=\"https://oreil.ly/uaPNt\"><span class=\"roman\">\"What do you mean by 'Event-Driven'\"</span></a></p>\n\n</blockquote>\n++++\n\n<<chapter_11_external_events_tradeoffs>> shows some trade-offs to think about.\n\n\n[[chapter_11_external_events_tradeoffs]]\n[options=\"header\"]\n.Event-based microservices integration: the trade-offs\n|===\n|Pros|Cons\na|\n* Avoids the distributed big ball of mud.\n* Services are decoupled: it's easier to change individual services and add\n  new ones.\n\na|\n* The overall flows of information are harder to see.\n* Eventual consistency is a new concept to deal with.\n* Message reliability and choices around at-least-once versus at-most-once delivery\n  need thinking through.\n\n|===\n\n(((\"microservices\", \"event-based integration\", \"trade-offs\")))\nMore generally, if you're moving from a model of synchronous messaging to an\nasync one, you also open up a whole host of problems having to do with message\nreliability and eventual consistency. Read on to <<footguns>>.\n(((\"microservices\", \"event-based integration\", startref=\"ix_mcroevnt\")))\n(((\"event-driven architecture\", \"using events to integrate microservices\", startref=\"ix_evntarch\")))\n(((\"external events\", startref=\"ix_extevnt\")))\n"
        },
        {
          "name": "chapter_12_cqrs.asciidoc",
          "type": "blob",
          "size": 35.990234375,
          "content": "[[chapter_12_cqrs]]\n== Command-Query Responsibility Segregation (CQRS)\n\n(((\"command-query responsibility segregation (CQRS)\", id=\"ix_CQRS\")))\n(((\"CQRS\", see=\"command-query responsibility segregation\")))\n(((\"queries\", seealso=\"command-query responsibility segregation\")))\nIn this chapter, we're going to start with a fairly uncontroversial insight:\nreads (queries) and writes (commands) are different, so they\nshould be treated differently (or have their responsibilities segregated, if you will). Then we're going to push that insight as far\nas we can. \n\nIf you're anything like Harry, this will all seem extreme at first,\nbut hopefully we can make the argument that it's not _totally_ unreasonable.\n\n<<maps_chapter_11>> shows where we might end up.\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_12_cqrs branch https://oreil.ly/YbWGT[on [.keep-together]#GitHub#].\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_12_cqrs\n# or to code along, checkout the previous chapter:\ngit checkout chapter_11_external_events\n----\n====\n\nFirst, though, why bother?\n\n[[maps_chapter_11]]\n.Separating reads from writes\nimage::images/apwp_1201.png[]\n\n=== Domain Models Are for Writing\n\n(((\"domain model\", \"writing data\")))\n(((\"command-query responsibility segregation (CQRS)\", \"domain models for writing\")))\nWe've spent a lot of time in this book talking about how to build software that\nenforces the rules of our domain. These rules, or constraints, will be different\nfor every application, and they make up the interesting core of our systems.\n\nIn this book, we've set explicit constraints like \"You can't allocate more stock\nthan is available,\" as well as implicit constraints like \"Each order line is\nallocated to a single batch.\"\n\nWe wrote down these rules as unit tests at the beginning of the book:\n\n[role=\"pagebreak-before\"]\n[[domain_tests]]\n.Our basic domain tests (tests/unit/test_batches.py)\n====\n[source,python]\n----\ndef test_allocating_to_a_batch_reduces_the_available_quantity():\n    batch = Batch(\"batch-001\", \"SMALL-TABLE\", qty=20, eta=date.today())\n    line = OrderLine(\"order-ref\", \"SMALL-TABLE\", 2)\n\n    batch.allocate(line)\n\n    assert batch.available_quantity == 18\n\n...\n\ndef test_cannot_allocate_if_available_smaller_than_required():\n    small_batch, large_line = make_batch_and_line(\"ELEGANT-LAMP\", 2, 20)\n    assert small_batch.can_allocate(large_line) is False\n----\n====\n\nTo apply these rules properly, we needed to ensure that operations\nwere consistent, and so we introduced patterns like _Unit of Work_ and _Aggregate_\nthat help us commit small chunks of work.\n\nTo communicate changes between those small chunks, we introduced the Domain Events pattern\nso we can write rules like \"When stock is damaged or lost, adjust the\navailable quantity on the batch, and reallocate orders if necessary.\"\n\nAll of this complexity exists so we can enforce rules when we change the\nstate of our system. We've built a flexible set of tools for writing data.\n\nWhat about reads, though?\n\n=== Most Users Aren't Going to Buy Your Furniture\n\n(((\"command-query responsibility segregation (CQRS)\", \"reads\")))\nAt MADE.com, we have a system very like the allocation service. In a busy day, we\nmight process one hundred orders in an hour, and we have a big gnarly system for\nallocating stock to those orders.\n\nIn that same busy day, though, we might have one hundred product views per _second_.\nEach time somebody visits a product page, or a product listing page, we need\nto figure out whether the product is still in stock and how long it will take\nus to deliver it.\n\n(((\"eventually consistent reads\")))\n(((\"consistency\", \"eventually consistent reads\")))\nThe _domain_ is the same--we're concerned with batches of stock, and their\narrival date, and the amount that's still available--but the access pattern\nis very different. For example, our customers won't notice if the query\nis a few seconds out of date, but if our allocate service is inconsistent,\nwe'll make a mess of their orders. We can take advantage of this difference by\nmaking our reads _eventually consistent_ in order to make them perform better.\n\n[role=\"nobreakinside less_space\"]\n.Is Read Consistency Truly Attainable?\n*******************************************************************************\n\n(((\"command-query responsibility segregation (CQRS)\", \"reads\", \"consistency of\")))\n(((\"consistency\", \"attainment of read consistency\")))\nThis idea of trading consistency against performance makes a lot of developers\n[.keep-together]#nervous# at first, so let's talk quickly about that.\n\nLet's imagine that our \"Get Available Stock\" query is 30 seconds out of date\nwhen Bob visits the page for `ASYMMETRICAL-DRESSER`.\nMeanwhile, though, Harry has already bought the last item. When we try to\nallocate Bob's order, we'll get a failure, and we'll need to either cancel his\norder or buy more stock and delay his delivery.\n\nPeople who've worked only with relational data stores get _really_ nervous\nabout this problem, but it's worth considering two other scenarios to gain some\nperspective.\n\nFirst, let's imagine that Bob and Harry both visit the page at _the same\ntime_. Harry goes off to make coffee, and by the time he returns, Bob has\nalready bought the last dresser. When Harry places his order, we send it to\nthe allocation service, and because there's not enough stock, we have to refund\nhis payment or buy more stock and delay his delivery.\n\nAs soon as we render the product page, the data is already stale. This insight\nis key to understanding why reads can be safely inconsistent: we'll always need\nto check the current state of our system when we come to allocate, because all\ndistributed systems are inconsistent. As soon as you have a web server and two\ncustomers, you have the potential for stale data.\n\nOK, let's assume we solve that problem somehow: we magically build a totally\nconsistent web application where nobody ever sees stale data. This time Harry\ngets to the page first and buys his dresser.\n\nUnfortunately for him, when the warehouse staff tries to dispatch his furniture,\nit falls off the forklift and smashes into a zillion pieces. Now what?\n\nThe only options are to either call Harry and refund his order or buy more\nstock and delay delivery.\n\nNo matter what we do, we're always going to find that our software systems are\ninconsistent with reality, and so we'll always need business processes to cope\nwith these edge cases. It's OK to trade performance for consistency on the\nread side, because stale data is essentially unavoidable.\n*******************************************************************************\n\n(((\"command-query responsibility segregation (CQRS)\", \"read side and write side\")))\nWe can think of these requirements as forming two halves of a system:\nthe read side and the write side, shown in <<read_and_write_table>>.\n\nFor the write side, our fancy domain architectural patterns help us to evolve\nour system over time, but the complexity we've built so far doesn't buy\nanything for reading data. The service layer, the unit of work,  and the clever\ndomain model are just bloat.\n\n[[read_and_write_table]]\n.Read versus write\n[options=\"header\"]\n|===\n| | Read side | Write side\n| Behavior | Simple read | Complex business logic\n| Cacheability | Highly cacheable | Uncacheable\n| Consistency | Can be stale | Must be transactionally consistent\n|===\n\n\n=== Post/Redirect/Get and CQS\n\n(((\"Post/Redirect/Get pattern\")))\n(((\"Post/Redirect/Get pattern\", \"command-query separation (CQS)\")))\n(((\"CQS (command-query separation)\")))\n(((\"command-query responsibility segregation (CQRS)\", \"Post/Redirect/Get pattern and CQS\")))\nIf you do web development, you're probably familiar with the\nPost/Redirect/Get pattern. In this technique, a web endpoint accepts an\nHTTP POST and responds with a redirect to see the result. For example, we might\naccept a POST to _/batches_ to create a new batch and redirect the user to\n_/batches/123_ to see their newly created batch.\n\nThis approach fixes the problems that arise when users refresh the results page\nin their browser or try to bookmark a results page. In the case of a refresh,\nit can lead to our users double-submitting data and thus buying two sofas when they\nneeded only one. In the case of a bookmark, our hapless customers will end up\nwith a broken page when they try to GET a POST endpoint.\n\nBoth these problems happen because we're returning data in response to a write\noperation. Post/Redirect/Get sidesteps the issue by separating the read and\nwrite phases of our operation.\n\nThis technique is a simple example of command-query separation (CQS).footnote:[\nWe're using the terms somewhat interchangeably, but CQS is normally something you\napply to a single class or module: functions that read state should be separate from\nthose that modify it.  And CQRS is something you apply to your whole application:\nthe classes, modules, code paths and even databases that read state can be\nseparated from the ones that modify it.]\nWe follow one simple rule: functions should either modify state or answer\nquestions, but never both. This makes software easier to reason about: we should\nalways be able to ask, \"Are the lights on?\" without flicking the light switch.\n\nNOTE: When building APIs, we can apply the same design technique by returning a\n    201 Created, or a 202 Accepted, with a Location header containing the URI\n    of our new resources. What's important here isn't the status code we use\n    but the logical separation of work into a write phase and a query phase.\n\nAs you'll see, we can use the CQS principle to make our systems faster and more\nscalable, but first, let's fix the CQS violation in our existing code. Ages\nago, we introduced an `allocate` endpoint that takes an order and calls our\nservice layer to allocate some stock. At the end of the call, we return a 200\nOK and the batch ID. That's led to some ugly design flaws so that we can get\nthe data we need. Let's change it to return a simple OK message and instead\nprovide a new read-only endpoint to retrieve allocation state:\n\n\n[[api_test_does_get_after_post]]\n.API test does a GET after the POST (tests/e2e/test_api.py)\n====\n[source,python]\n----\n@pytest.mark.usefixtures(\"postgres_db\")\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_happy_path_returns_202_and_batch_is_allocated():\n    orderid = random_orderid()\n    sku, othersku = random_sku(), random_sku(\"other\")\n    earlybatch = random_batchref(1)\n    laterbatch = random_batchref(2)\n    otherbatch = random_batchref(3)\n    api_client.post_to_add_batch(laterbatch, sku, 100, \"2011-01-02\")\n    api_client.post_to_add_batch(earlybatch, sku, 100, \"2011-01-01\")\n    api_client.post_to_add_batch(otherbatch, othersku, 100, None)\n\n    r = api_client.post_to_allocate(orderid, sku, qty=3)\n    assert r.status_code == 202\n\n    r = api_client.get_allocation(orderid)\n    assert r.ok\n    assert r.json() == [\n        {\"sku\": sku, \"batchref\": earlybatch},\n    ]\n\n\n@pytest.mark.usefixtures(\"postgres_db\")\n@pytest.mark.usefixtures(\"restart_api\")\ndef test_unhappy_path_returns_400_and_error_message():\n    unknown_sku, orderid = random_sku(), random_orderid()\n    r = api_client.post_to_allocate(\n        orderid, unknown_sku, qty=20, expect_success=False\n    )\n    assert r.status_code == 400\n    assert r.json()[\"message\"] == f\"Invalid sku {unknown_sku}\"\n\n    r = api_client.get_allocation(orderid)\n    assert r.status_code == 404\n----\n====\n\n(((\"views\", \"read-only\")))\n(((\"Flask framework\", \"endpoint for viewing allocations\")))\nOK, what might the Flask app look like?\n\n\n[[flask_app_calls_view]]\n.Endpoint for viewing allocations (src/allocation/entrypoints/flask_app.py)\n====\n[source,python]\n----\nfrom allocation import views\n...\n\n@app.route(\"/allocations/<orderid>\", methods=[\"GET\"])\ndef allocations_view_endpoint(orderid):\n    uow = unit_of_work.SqlAlchemyUnitOfWork()\n    result = views.allocations(orderid, uow)  #<1>\n    if not result:\n        return \"not found\", 404\n    return jsonify(result), 200\n----\n====\n\n<1> All right, a _views.py_, fair enough; we can keep read-only stuff in there,\n    and it'll be a real _views.py_, not like Django's, something that knows how\n    to build read-only views of our data...\n\n[[hold-on-ch12]]\n=== Hold On to Your Lunch, Folks\n\n(((\"SQL\", \"raw SQL in views\")))\n(((\"repositories\", \"adding list method to existing repository object\")))\n(((\"command-query responsibility segregation (CQRS)\", \"building read-only views into our data\")))\nHmm, so we can probably just add a list method to our existing repository\nobject:\n\n\n[[views_dot_py]]\n.Views do...raw SQL? (src/allocation/views.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nfrom allocation.service_layer import unit_of_work\n\n\ndef allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):\n    with uow:\n        results = uow.session.execute(\n            \"\"\"\n            SELECT ol.sku, b.reference\n            FROM allocations AS a\n            JOIN batches AS b ON a.batch_id = b.id\n            JOIN order_lines AS ol ON a.orderline_id = ol.id\n            WHERE ol.orderid = :orderid\n            \"\"\",\n            dict(orderid=orderid),\n        )\n    return [{\"sku\": sku, \"batchref\": batchref} for sku, batchref in results]\n----\n====\n\n\n_Excuse me?  Raw SQL?_\n\nIf you're anything like Harry encountering this pattern for the first time,\nyou'll be wondering what on earth Bob has been smoking. We're hand-rolling our\nown SQL now, and converting database rows directly to dicts? After all the\neffort we put into building a nice domain model? And what about the Repository\npattern? Isn't that meant to be our abstraction around the database? Why don't\nwe reuse that?\n\nWell, let's explore that seemingly simpler alternative first, and see what it\nlooks like in practice.\n\n\nWe'll still keep our view in a separate _views.py_ module; enforcing a clear\ndistinction between reads and writes in your application is still a good idea.\nWe apply command-query separation, and it's easy to see which code modifies\nstate (the event handlers) and which code just retrieves read-only state (the views).\n\nTIP: Splitting out your read-only views from your state-modifying\n    command and event handlers is probably a good idea, even if you\n    don't want to go to full-blown CQRS.\n\n\n=== Testing CQRS Views\n\n(((\"views\", \"testing CQRS views\")))\n(((\"testing\", \"integration test for CQRS view\")))\n(((\"command-query responsibility segregation (CQRS)\", \"testing views\")))\nBefore we get into exploring various options, let's talk about testing.\nWhichever approaches you decide to go for, you're probably going to need\nat least one integration test.  Something like this:\n\n\n[[integration_testing_views]]\n.An integration test for a view (tests/integration/test_views.py)\n====\n[source,python]\n----\ndef test_allocations_view(sqlite_session_factory):\n    uow = unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory)\n    messagebus.handle(commands.CreateBatch(\"sku1batch\", \"sku1\", 50, None), uow)  #<1>\n    messagebus.handle(commands.CreateBatch(\"sku2batch\", \"sku2\", 50, today), uow)\n    messagebus.handle(commands.Allocate(\"order1\", \"sku1\", 20), uow)\n    messagebus.handle(commands.Allocate(\"order1\", \"sku2\", 20), uow)\n    # add a spurious batch and order to make sure we're getting the right ones\n    messagebus.handle(commands.CreateBatch(\"sku1batch-later\", \"sku1\", 50, today), uow)\n    messagebus.handle(commands.Allocate(\"otherorder\", \"sku1\", 30), uow)\n    messagebus.handle(commands.Allocate(\"otherorder\", \"sku2\", 10), uow)\n\n    assert views.allocations(\"order1\", uow) == [\n        {\"sku\": \"sku1\", \"batchref\": \"sku1batch\"},\n        {\"sku\": \"sku2\", \"batchref\": \"sku2batch\"},\n    ]\n----\n====\n\n<1> We do the setup for the integration test by using the public entrypoint to\n    our application, the message bus. That keeps our tests decoupled from\n    any implementation/infrastructure details about how things get stored.\n\n////\nIDEA: sidebar on testing views.  some old content follows.\n\nBefore you dismiss the need to use integration tests as just another\nanti-feather in the anti-cap of this total antipattern, it's worth thinking\nthrough the alternatives.\n\n- If you're going via the `Products` repository, then you'll need integration\n  tests for any new query methods you add.\n\n- If you're going via the ORM, you'll still need integration tests\n\n- And if you decide to build a read-only `BatchRepository`, ignoring\n  the purists that tell you you're not allowed to have a Repository for\n  a non-Aggregate model class, call it `BatchDAL` if you want, in any case,\n  you'll still need integration tests for _that_.\n\nSo the choice is about whether or not you want a layer of abstraction between\nyour permanent storage and the logic of your read-only views.\n\n* If the views are relatively simple (all the logic in our case is in filtering\n  down to the right batch references), then adding another layer doesn't seem\n  worth it.\n\n* If your views do more complex calculations, or need to invoke some business\n  rules to decide what to display... If, in short, you find yourself writing a\n  lot of integration tests for a single view, then it may be worth building\n  that intermediary layer, so that you can test the SQL and the\n  display/calculation/view logic separately\n\nIDEA: some example code showing a DAL layer in front of some read-only view\ncode with more complex business logic.\n\n////\n\n\n\n=== \"Obvious\" Alternative 1: Using the Existing Repository\n\n(((\"views\", \"simple view that uses the repository\")))\n(((\"command-query responsibility segregation (CQRS)\", \"simple view using existing repository\")))\n(((\"repositories\", \"simple view using existing repository\")))\nHow about adding a helper method to our `products` repository?\n\n\n[[view_using_repo]]\n.A simple view that uses the repository (src/allocation/views.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nfrom allocation import unit_of_work\n\ndef allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):\n    with uow:\n        products = uow.products.for_order(orderid=orderid)  #<1>\n        batches = [b for p in products for b in p.batches]  #<2>\n        return [\n            {'sku': b.sku, 'batchref': b.reference}\n            for b in batches\n            if orderid in b.orderids  #<3>\n        ]\n----\n====\n\n<1> Our repository returns `Product` objects, and we need to find all the\n    products for the SKUs in a given order, so we'll build a new helper method\n    called `.for_order()` on the repository.\n\n<2> Now we have products but we actually want batch references, so we\n    get all the possible batches with a list comprehension.\n\n<3> We filter _again_ to get just the batches for our specific\n    order. That, in turn, relies on our `Batch` objects being able to tell us\n    which order IDs it has allocated.\n\nWe implement that last using a `.orderid` property:\n\n\n[[orderids_on_batch]]\n.An arguably unnecessary property on our model (src/allocation/domain/model.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nclass Batch:\n    ...\n\n    @property\n    def orderids(self):\n        return {l.orderid for l in self._allocations}\n----\n====\n\nYou can start to see that reusing our existing repository and domain model classes\nis not as straightforward as you might have assumed.  We've had to add new helper\nmethods to both, and we're doing a bunch of looping and filtering in Python, which\nis work that would be done much more efficiently by the database.\n\nSo yes, on the plus side we're reusing our existing abstractions, but on the\ndownside, it all feels quite clunky.\n\n\n=== Your Domain Model Is Not Optimized for Read Operations\n\n(((\"domain model\", \"not optimized for read operations\")))\n(((\"command-query responsibility segregation (CQRS)\", \"domain model not optimized for read operations\")))\nWhat we're seeing here are the effects of having a domain model that\nis designed primarily for write operations, while our requirements for\nreads are often conceptually quite different.\n\nThis is the chin-stroking-architect's justification for CQRS.  As we've said before,\na domain model is not a data model--we're trying to capture the way the\nbusiness works: workflow, rules around state changes, messages exchanged;\nconcerns about how the system reacts to external events and user input.\n_Most of this stuff is totally irrelevant for read-only operations_.\n\nTIP: This justification for CQRS is related to the justification for the Domain\n    Model pattern. If you're building a simple CRUD app, reads and writes are\n    going to be closely related, so you don't need a domain model or CQRS. But\n    the more complex your domain, the more likely you are to need both.\n\nTo make a facile point, your domain classes will have multiple methods for\nmodifying state, and you won't need any of them for read-only operations.\n\nAs the complexity of your domain model grows, you will find yourself making\nmore and more choices about how to structure that model, which make it more and\nmore awkward to use for read operations.\n\n\n===  \"Obvious\" Alternative 2: Using the ORM\n\n(((\"command-query responsibility segregation (CQRS)\", \"view that uses the ORM\")))\n(((\"views\", \"simple view that uses the ORM\")))\n(((\"object-relational mappers (ORMs)\", \"simple view using the ORM\")))\nYou may be thinking, OK, if our repository is clunky, and working with\n`Products` is clunky, then I can at least  use my ORM and work with `Batches`.\nThat's what it's for!\n\n[[view_using_orm]]\n.A simple view that uses the ORM (src/allocation/views.py)\n====\n[source,python]\n[role=\"skip\"]\n----\nfrom allocation import unit_of_work, model\n\ndef allocations(orderid: str, uow: unit_of_work.AbstractUnitOfWork):\n    with uow:\n        batches = uow.session.query(model.Batch).join(\n            model.OrderLine, model.Batch._allocations\n        ).filter(\n            model.OrderLine.orderid == orderid\n        )\n        return [\n            {\"sku\": b.sku, \"batchref\": b.batchref}\n            for b in batches\n        ]\n----\n====\n\nBut is that _actually_ any easier to write or understand than the raw SQL\nversion from the code example in <<hold-on-ch12>>? It may not look too bad up there, but we\ncan tell you it took several attempts, and plenty of digging through the\nSQLAlchemy docs. SQL is just SQL.\n\n////\nIDEA (hynek)\nthis seems like a PERFECT opportunity to talk about SQLAlchemy Core API. If you\nhave questions, pls talk to me. But jumping from ORM directly to raw SQL is\nbaby/bathwater.\n////\n\nBut the ORM can also expose us to performance problems.\n\n\n=== SELECT N+1 and Other Performance Considerations\n\n\n(((\"SELECT N+1\")))\n(((\"object-relational mappers (ORMs)\", \"SELECT N+1 performance problem\")))\n(((\"command-query responsibility segregation (CQRS)\", \"SELECT N+1 and other performance problems\")))\nThe so-called https://oreil.ly/OkBOS[`SELECT N+1`]\nproblem is a common performance problem with ORMs: when retrieving a list of\nobjects, your ORM will often perform an initial query to, say, get all the IDs\nof the objects it needs, and then issue individual queries for each object to\nretrieve their attributes. This is especially likely if there are any foreign-key relationships on your objects.\n\nNOTE: In all fairness, we should say that SQLAlchemy is quite good at avoiding\n    the `SELECT N+1` problem. It doesn't display it in the preceding example, and\n    you can request https://oreil.ly/XKDDm[eager loading]\n    explicitly to avoid it when dealing with joined objects.\n    (((\"eager loading\")))\n    (((\"SQLAlchemy\", \"SELECT N+1 problem and\")))\n\nBeyond `SELECT N+1`, you may have other reasons for wanting to decouple the\nway you persist state changes from the way that you retrieve current state.\nA set of fully normalized relational tables is a good way to make sure that\nwrite operations never cause data corruption. But retrieving data using lots\nof joins can be slow. It's common in such cases to add some denormalized views,\nbuild read replicas, or even add caching layers.\n\n\n=== Time to Completely Jump the Shark\n\n(((\"views\", \"keeping totally separate, denormalized datastore for view model\")))\n(((\"command-query responsibility segregation (CQRS)\", \"denormalized copy of your data optimized for read operations\")))\nOn that note: have we convinced you that our raw SQL version isn't so weird as\nit first seemed? Perhaps we were exaggerating for effect? Just you wait.\n\nSo, reasonable or not, that hardcoded SQL query is pretty ugly, right? What if\nwe made it nicer...\n\n[[much_nicer_query]]\n.A much nicer query (src/allocation/views.py)\n====\n[source,python]\n----\ndef allocations(orderid: str, uow: unit_of_work.SqlAlchemyUnitOfWork):\n    with uow:\n        results = uow.session.execute(\n            \"\"\"\n            SELECT sku, batchref FROM allocations_view WHERE orderid = :orderid\n            \"\"\",\n            dict(orderid=orderid),\n        )\n        ...\n----\n====\n\n...by _keeping a totally separate, denormalized data store for our view model_?\n\n[[new_table]]\n.Hee hee hee, no foreign keys, just strings, YOLO (src/allocation/adapters/orm.py)\n====\n[source,python]\n----\nallocations_view = Table(\n    \"allocations_view\",\n    metadata,\n    Column(\"orderid\", String(255)),\n    Column(\"sku\", String(255)),\n    Column(\"batchref\", String(255)),\n)\n----\n====\n\n\nOK, nicer-looking SQL queries wouldn't be a justification for anything really,\nbut building a denormalized copy of your data that's optimized for read operations\nisn't uncommon, once you've reached the limits of what you can do with indexes.\n\nEven with well-tuned indexes, a relational database uses a lot of CPU to perform\njoins. The fastest queries will always be pass:[<code>SELECT * from <em>mytable</em> WHERE <em>key</em> = :<em>value</em></code>].\n\n(((\"SELECT * FROM WHERE queries\")))\nMore than raw speed, though, this approach buys us scale. When we're writing\ndata to a relational database, we need to make sure that we get a lock over the\nrows we're changing so we don't run into consistency problems.\n\nIf multiple clients are changing data at the same time, we'll have weird race\nconditions. When we're _reading_ data, though, there's no limit to the number\nof clients that can concurrently execute. For this reason, read-only stores can\nbe horizontally scaled out.\n\nTIP: Because read replicas can be inconsistent, there's no limit to how many we\n    can have. If you're struggling to scale a system with a complex data store,\n    ask whether you could build a simpler read model.\n\n(((\"views\", \"updating read model table using event handler\")))\n(((\"command-query responsibility segregation (CQRS)\", \"updating read model table using event handler\")))\n(((\"event handlers\", \"updating read model table using\")))\nKeeping the read model up to date is the challenge!  Database views\n(materialized or otherwise) and triggers are a common solution, but that limits\nyou to your database. We'd like to show you how to reuse our event-driven\narchitecture instead.\n\n\n==== Updating a Read Model Table Using an Event Handler\n\nWe add a second handler to the `Allocated` event:\n\n[[new_handler_for_allocated]]\n.Allocated event gets a new handler (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\nEVENT_HANDLERS = {\n    events.Allocated: [\n        handlers.publish_allocated_event,\n        handlers.add_allocation_to_read_model,\n    ],\n----\n====\n\nHere's what our update-view-model code looks like:\n\n\n[[update_view_model_1]]\n.Update on allocation (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n----\n\ndef add_allocation_to_read_model(\n    event: events.Allocated,\n    uow: unit_of_work.SqlAlchemyUnitOfWork,\n):\n    with uow:\n        uow.session.execute(\n            \"\"\"\n            INSERT INTO allocations_view (orderid, sku, batchref)\n            VALUES (:orderid, :sku, :batchref)\n            \"\"\",\n            dict(orderid=event.orderid, sku=event.sku, batchref=event.batchref),\n        )\n        uow.commit()\n----\n====\n\nBelieve it or not, that will pretty much work!  _And it will work\nagainst the exact same integration tests as the rest of our options._\n\nOK, you'll also need to handle `Deallocated`:\n\n\n[[handle_deallocated_too]]\n.A second listener for read model updates\n====\n[source,python]\n[role=\"skip\"]\n----\nevents.Deallocated: [\n    handlers.remove_allocation_from_read_model,\n    handlers.reallocate\n],\n\n...\n\ndef remove_allocation_from_read_model(\n    event: events.Deallocated,\n    uow: unit_of_work.SqlAlchemyUnitOfWork,\n):\n    with uow:\n        uow.session.execute(\n            \"\"\"\n            DELETE FROM allocations_view\n            WHERE orderid = :orderid AND sku = :sku\n            ...\n----\n====\n\n\n<<read_model_sequence_diagram>> shows the flow across the two requests.\n\n[[read_model_sequence_diagram]]\n.Sequence diagram for read model\nimage::images/apwp_1202.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_1202, config=plantuml.cfg]\n@startuml\nscale 4\n!pragma teoz true\n\nactor User order 1\nboundary Flask order 2\nparticipant MessageBus order 3\nparticipant \"Domain Model\" as Domain order 4\nparticipant View order 9\ndatabase DB order 10\n\nUser -> Flask: POST to allocate Endpoint\nFlask -> MessageBus : Allocate Command\n\ngroup UoW/transaction 1\n    MessageBus -> Domain : allocate()\n    MessageBus -> DB: commit write model\nend\n\ngroup UoW/transaction 2\n    Domain -> MessageBus : raise Allocated event(s)\n    MessageBus -> DB : update view model\nend\n\nFlask -> User: 202 OK\n\nUser -> Flask: GET allocations endpoint\nFlask -> View: get allocations\nView -> DB: SELECT on view model\nDB -> View: some allocations\n& View -> Flask: some allocations\n& Flask -> User: some allocations\n\n@enduml\n----\n\nIn <<read_model_sequence_diagram>>, you can see two\ntransactions in the POST/write operation, one to update the write model and one\nto update the read model, which the GET/read operation can use.\n\n[role=\"nobreakinside less_space\"]\n.Rebuilding from Scratch\n*******************************************************************************\n\n(((\"command-query responsibility segregation (CQRS)\", \"rebuilding view model from scratch\")))\n(((\"views\", \"rebuilding view model from scratch\")))\n\"What happens when it breaks?\" should be the first question we ask as engineers.\n\nHow do we deal with a view model that hasn't been updated because of a bug or\ntemporary outage? Well, this is just another case where events and commands can\nfail independently.\n\nIf we _never_ updated the view model, and the `ASYMMETRICAL-DRESSER` was forever in\nstock, that would be annoying for customers, but the `allocate` service would\nstill fail, and we'd take action to fix the problem.\n\nRebuilding a view model is easy, though. Since we're using a service layer to\nupdate our view model, we can write a tool that does the following:\n\n* Queries the current state of the write side to work out what's currently\n  allocated\n* Calls the `add_allocation_to_read_model` handler for each allocated item\n\nWe can use this technique to create entirely new read models from historical\ndata.\n*******************************************************************************\n\n=== Changing Our Read Model Implementation Is Easy\n\n(((\"command-query responsibility segregation (CQRS)\", \"changing read model implementation to use Redis\")))\n(((\"Redis, changing read model implementation to use\")))\nLet's see the flexibility that our event-driven model buys us in action,\nby seeing what happens if we ever decide we want to implement a read model by\nusing a totally separate storage engine, Redis.\n\nJust watch:\n\n\n[[redis_readmodel_handlers]]\n.Handlers update a Redis read model (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef add_allocation_to_read_model(event: events.Allocated, _):\n    redis_eventpublisher.update_readmodel(event.orderid, event.sku, event.batchref)\n\n\ndef remove_allocation_from_read_model(event: events.Deallocated, _):\n    redis_eventpublisher.update_readmodel(event.orderid, event.sku, None)\n----\n====\n\nThe helpers in our Redis module are one-liners:\n\n\n[[redis_readmodel_client]]\n.Redis read model read and update (src/allocation/adapters/redis_eventpublisher.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef update_readmodel(orderid, sku, batchref):\n    r.hset(orderid, sku, batchref)\n\n\ndef get_readmodel(orderid):\n    return r.hgetall(orderid)\n----\n====\n\n(Maybe the name __redis_eventpublisher.py__ is a misnomer now, but you get the idea.)\n\nAnd the view itself changes very slightly to adapt to its new backend:\n\n[[redis_readmodel_view]]\n.View adapted to Redis (src/allocation/views.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef allocations(orderid: str):\n    batches = redis_eventpublisher.get_readmodel(orderid)\n    return [\n        {\"batchref\": b.decode(), \"sku\": s.decode()}\n        for s, b in batches.items()\n    ]\n----\n====\n\n\n\nAnd the _exact same_ integration tests that we had before still pass,\nbecause they are written at a level of abstraction that's decoupled from the\nimplementation: setup puts messages on the message bus, and the assertions\nare against our view.\n\nTIP: Event handlers are a great way to manage updates to a read model,\n    if you decide you need one.  They also make it easy to change the\n    implementation of that read model at a later date.\n    (((\"event handlers\", \"managing updates to read model\")))\n\n.Exercise for the Reader\n**********************************************************************\nImplement another view, this time to show the allocation for a single\norder line.\n\nHere the trade-offs between using hardcoded SQL versus going via a repository\nshould be much more blurry.  Try a few versions (maybe including going\nto Redis), and see which you prefer.\n**********************************************************************\n\n\n=== Wrap-Up\n\n(((\"views\", \"trade-offs for view model options\")))\n(((\"command-query responsibility segregation (CQRS)\", \"trade-offs for view model options\")))\n<<view_model_tradeoffs>> proposes some pros and cons for each of our options.\n\n(((\"command-query responsibility segregation (CQRS)\", \"full-blown CQRS versus simpler options\")))\nAs it happens, the allocation service at MADE.com does use \"full-blown\" CQRS,\nwith a read model stored in Redis, and even a second layer of cache provided\nby Varnish. But its use cases are quite a bit different from what\nwe've shown here. For the kind of allocation service we're building, it seems\nunlikely that you'd need to use a separate read model and event handlers for\nupdating it.\n\nBut as your domain model becomes richer and more complex, a simplified read\nmodel become ever more compelling.\n\n[[view_model_tradeoffs]]\n[options=\"header\"]\n.Trade-offs of various view model options\n|===\n| Option | Pros | Cons\n\n| Just use repositories\n| Simple, consistent approach.\n| Expect performance issues with complex query patterns.\n\n| Use custom queries with your ORM\n| Allows reuse of DB configuration and model definitions.\n| Adds another query language with its own quirks and syntax.\n\n| Use hand-rolled SQL to query your normal model tables\n| Offers fine control over performance with a standard query syntax.\n| Changes to DB schema have to be made to your hand-rolled queries _and_ your\n  ORM definitions. Highly normalized schemas may still have performance\n  limitations.\n\n| Add some extra (denormalized) tables to your DB as a read model\n| A denormalized table can be much faster to query. If we update the\n  normalized and denormalized ones in the same transaction, we will\n  still have good guarantees of data consistency\n| It will slow down writes slightly\n\n| Create separate read stores with events\n| Read-only copies are easy to scale out. Views can be constructed when data\n  changes so that queries are as simple as possible.\n| Complex technique. Harry will be forever suspicious of your tastes and\n  motives.\n|===\n\n// IDEA (EJ3) Might be useful to re-iterate what \"full-blown\" CQRS means vs simpler CQRS options.  I think\n//      most blog posts describe CQRS in terms of the \"full-blown\" version, while\n//      ignoring over the simpler version that is developed earlier in this chapter.\n//\n//      In my experience, many people react to CQRS with the response that\n//      it's insane/too complex/too-hard and want to fall back to a CRUD hammer.\n//\n\nOften, your read operations will be acting on the same conceptual objects as your\nwrite model, so using the ORM, adding some read methods to your repositories,\nand using domain model classes for your read operations is _just fine_.\n\nIn our book example, the read operations act on quite different conceptual\nentities to our domain model. The allocation service thinks in terms of\n`Batches` for a single SKU, but users care about allocations for a whole order,\nwith multiple SKUs, so using the ORM ends up being a little awkward. We'd be\nquite tempted to go with the raw-SQL view we showed right at the beginning of\nthe chapter.\n\nOn that note, let's sally forth into our final chapter.\n(((\"command-query responsibility segregation (CQRS)\", startref=\"ix_CQRS\")))\n"
        },
        {
          "name": "chapter_13_dependency_injection.asciidoc",
          "type": "blob",
          "size": 35.3408203125,
          "content": "[[chapter_13_dependency_injection]]\n== Dependency Injection (and Bootstrapping)\n\n(((\"dependency injection\", id=\"ix_DI\")))\nDependency injection (DI) is regarded with suspicion in the Python world.  And\nwe've managed _just fine_ without it so far in the example code for this\nbook!\n\nIn this chapter, we'll explore some of the pain points in our code\nthat lead us to consider using DI, and we'll present some options\nfor how to do it, leaving it to you to pick which you think is most Pythonic.\n\n(((\"bootstrapping\")))\n(((\"composition root\")))\nWe'll also add a new component to our architecture called __bootstrap.py__;\nit will be in charge of dependency injection, as well as some other initialization\nstuff that we often need.  We'll explain why this sort of thing is called\na _composition root_ in OO languages, and why _bootstrap script_ is just fine\nfor our purposes.\n\n<<bootstrap_chapter_before_diagram>> shows what our app looks like without\na bootstrapper: the entrypoints do a lot of initialization and passing around\nof our main dependency, the UoW.\n\n[TIP]\n====\nIf you haven't already, it's worth reading <<chapter_03_abstractions>>\n    before continuing with this chapter, particularly the discussion of\n    functional versus object-oriented dependency management.\n====\n\n[[bootstrap_chapter_before_diagram]]\n.Without bootstrap: entrypoints do a lot\nimage::images/apwp_1301.png[]\n\n[TIP]\n====\nThe code for this chapter is in the\nchapter_13_dependency_injection branch https://oreil.ly/-B7e6[on GitHub]:\n\n----\ngit clone https://github.com/cosmicpython/code.git\ncd code\ngit checkout chapter_13_dependency_injection\n# or to code along, checkout the previous chapter:\ngit checkout chapter_12_cqrs\n----\n====\n\n<<bootstrap_chapter_after_diagram>> shows our bootstrapper taking over those\nresponsibilities.\n\n[[bootstrap_chapter_after_diagram]]\n.Bootstrap takes care of all that in one place\nimage::images/apwp_1302.png[]\n\n\n=== Implicit Versus Explicit Dependencies\n\n(((\"dependency injection\", \"implicit versus explicit dependencies\")))\nDepending on your particular brain type, you may have a slight\nfeeling of unease at the back of your mind at this point.  Let's bring it out\ninto the open. We've shown you two ways of managing\ndependencies and testing them.\n\n\nFor our database dependency, we've built a careful framework of explicit\ndependencies and easy options for overriding them in tests. Our main handler\nfunctions declare an explicit dependency on the UoW:\n\n[[existing_handler]]\n.Our handlers have an explicit dependency on the UoW (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n[role=\"existing\"]\n----\ndef allocate(\n    cmd: commands.Allocate,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n----\n====\n\nAnd that makes it easy to swap in a fake UoW in our\nservice-layer tests:\n\n[[existing_services_test]]\n.Service-layer tests against a fake UoW: (tests/unit/test_services.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n    uow = FakeUnitOfWork()\n    messagebus.handle([...], uow)\n----\n====\n\n\nThe UoW itself declares an explicit dependency on the session factory:\n\n\n[[existing_uow]]\n.The UoW depends on a session factory (src/allocation/service_layer/unit_of_work.py)\n====\n[source,python]\n[role=\"existing\"]\n----\nclass SqlAlchemyUnitOfWork(AbstractUnitOfWork):\n    def __init__(self, session_factory=DEFAULT_SESSION_FACTORY):\n        self.session_factory = session_factory\n        ...\n----\n====\n\nWe take advantage of it in our integration tests to be able to sometimes use SQLite\ninstead of Postgres:\n\n[[existing_integration_test]]\n.Integration tests against a different DB (tests/integration/test_uow.py)\n====\n[source,python]\n[role=\"existing\"]\n----\ndef test_rolls_back_uncommitted_work_by_default(sqlite_session_factory):\n    uow = unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory)  #<1>\n----\n====\n\n<1> Integration tests swap out the default Postgres `session_factory` for a\n    SQLite one.\n\n\n\n=== Aren't Explicit Dependencies Totally Weird and Java-y?\n\n(((\"importing dependenies\")))\n(((\"dependency injection\", \"explicit dependencies are better than implicit dependencies\")))\nIf you're used to the way things normally happen in Python, you'll be thinking\nall this is a bit weird.  The standard way to do things is to declare our\ndependency implicitly by simply importing it, and then if we ever need to\nchange it for tests, we can monkeypatch, as is Right and True in dynamic\nlanguages:\n\n\n[[normal_implicit_dependency]]\n.Email sending as a normal import-based dependency (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n[role=\"existing\"]\n----\nfrom allocation.adapters import email, redis_eventpublisher  #<1>\n...\n\ndef send_out_of_stock_notification(\n    event: events.OutOfStock,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    email.send(  #<2>\n        \"stock@made.com\",\n        f\"Out of stock for {event.sku}\",\n    )\n----\n====\n\n<1> Hardcoded import\n<2> Calls specific email sender directly\n\n\n(((\"mock.patch method\")))\nWhy pollute our application code with unnecessary arguments just for the\nsake of our tests? `mock.patch` makes monkeypatching nice and easy:\n\n\n[[mocking_is_easy]]\n.mock dot patch, thank you Michael Foord (tests/unit/test_handlers.py)\n====\n[source,python]\n[role=\"existing\"]\n----\n    with mock.patch(\"allocation.adapters.email.send\") as mock_send_mail:\n        ...\n----\n====\n\nThe trouble is that we've made it look easy because our toy example doesn't\nsend real email (`email.send_mail` just does a `print`), but in real life,\nyou'd end up having to call `mock.patch` for _every single test_ that might\ncause an out-of-stock notification. If you've worked on codebases with lots of\nmocks used to prevent unwanted side effects, you'll know how annoying that\nmocky boilerplate gets.\n\nAnd you'll know that mocks tightly couple us to the implementation. By\nchoosing to monkeypatch `email.send_mail`, we are tied to doing `import email`,\nand if we ever want to do `from email import send_mail`, a trivial refactor,\nwe'd have to change all our mocks.\n\nSo it's a trade-off. Yes, declaring explicit dependencies is unnecessary,\nstrictly speaking, and using them would make our application code marginally\nmore complex. But in return, we'd get tests that are easier to write and\nmanage.\n\n(((\"dependency inversion principle\", \"declaring explicit dependency as example of\")))\n(((\"abstractions\", \"explicit dependencies are more abstract\")))\nOn top of that, declaring an explicit dependency is an example of the\ndependency inversion principle—rather than having an (implicit) dependency on\na _specific_ detail, we have an (explicit) dependency on an _abstraction_:\n\n[quote, The Zen of Python]\n____\nExplicit is better than implicit.\n____\n\n\n[[handler_with_explicit_dependency]]\n.The explicit dependency is more abstract (src/allocation/service_layer/handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef send_out_of_stock_notification(\n    event: events.OutOfStock,\n    send_mail: Callable,\n):\n    send_mail(\n        \"stock@made.com\",\n        f\"Out of stock for {event.sku}\",\n    )\n----\n====\n\nBut if we do change to declaring all these dependencies explicitly, who will\ninject them, and how? So far, we've really been dealing with only passing the\nUoW around: our tests use `FakeUnitOfWork`, while Flask and Redis eventconsumer\nentrypoints use the real UoW, and the message bus passes them onto our command\nhandlers. If we add real and fake email classes, who will create them and\npass them on?\n\nIt needs to happen as early as possible in the process lifecycle, so the most\nobvious place is in our entrypoints. That would mean extra (duplicated) cruft\nin Flask and Redis, and in our tests. And we'd also have to add the\nresponsibility for passing dependencies around to the message bus, which\nalready has a job to do; it feels like a violation of the SRP.\n\n\n(((\"bootstrapping\", \"dependency injection with\")))\n(((\"composition root\")))\nInstead, we'll reach for a pattern called _Composition Root_ (a bootstrap\nscript to you and me),footnote:[Because Python is not a \"pure\" OO language,\nPython developers aren't necessarily used to the concept of needing to\n_compose_ a set of objects into a working application. We just pick our\nentrypoint and run code from top to bottom.]\n and we'll do a bit of \"manual DI\" (dependency injection without a\nframework). See <<bootstrap_new_image>>.footnote:[Mark Seemann calls this\nhttps://oreil.ly/iGpDL[_Pure DI_] or sometimes _Vanilla DI_.]\n\n[[bootstrap_new_image]]\n.Bootstrapper between entrypoints and message bus\nimage::images/apwp_1303.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_1303]\n\n+---------------+\n|  Entrypoints  |\n| (Flask/Redis) |\n+---------------+\n        |\n        | call\n        V\n /--------------\\\n |              |  prepares handlers with correct dependencies injected in\n | Bootstrapper |  (test bootstrapper will use fakes, prod one will use real)\n |              |\n \\--------------/\n        |\n        | pass injected handlers to\n        V\n/---------------\\\n|  Message Bus  |\n+---------------+\n        |\n        | dispatches events and commands to injected handlers\n        |\n        V\n----\n\n\n=== Preparing Handlers: Manual DI with Closures and Partials\n\n(((\"partial functions\", \"dependency injection with\")))\n(((\"closures\", \"dependency injection using\")))\n(((\"dependency injection\", \"manual DI with closures or partial functions\")))\nOne way to turn a function with dependencies into one that's ready to be\ncalled later with those dependencies _already injected_ is to use closures or\npartial functions to compose the function with its dependencies:\n\n\n[[di_with_partial_functions_examples]]\n.Examples of DI using closures or partial functions\n====\n[source,python]\n[role=\"skip\"]\n----\n# existing allocate function, with abstract uow dependency\ndef allocate(\n    cmd: commands.Allocate,\n    uow: unit_of_work.AbstractUnitOfWork,\n):\n    line = OrderLine(cmd.orderid, cmd.sku, cmd.qty)\n    with uow:\n        ...\n\n# bootstrap script prepares actual UoW\n\ndef bootstrap(..):\n    uow = unit_of_work.SqlAlchemyUnitOfWork()\n\n    # prepare a version of the allocate fn with UoW dependency captured in a closure\n    allocate_composed = lambda cmd: allocate(cmd, uow)\n\n    # or, equivalently (this gets you a nicer stack trace)\n    def allocate_composed(cmd):\n        return allocate(cmd, uow)\n\n    # alternatively with a partial\n    import functools\n    allocate_composed = functools.partial(allocate, uow=uow)  #<1>\n\n# later at runtime, we can call the partial function, and it will have\n# the UoW already bound\nallocate_composed(cmd)\n----\n====\n\n<1> The difference between closures (lambdas or named functions) and\n    `functools.partial` is that the former use\n    https://docs.python-guide.org/writing/gotchas/#late-binding-closures[late binding of variables],\n    which can be a source of confusion if any of the dependencies are mutable.\n    (((\"closures\", \"difference from partial functions\")))\n    (((\"partial functions\", \"difference from closures\")))\n\nHere's the same pattern again for the `send_out_of_stock_notification()` handler,\nwhich has different dependencies:\n\n[[partial_functions_2]]\n.Another closure and partial functions example\n====\n[source,python]\n[role=\"skip\"]\n----\ndef send_out_of_stock_notification(\n    event: events.OutOfStock,\n    send_mail: Callable,\n):\n    send_mail(\n        \"stock@made.com\",\n        ...\n\n\n# prepare a version of the send_out_of_stock_notification with dependencies\nsosn_composed  = lambda event: send_out_of_stock_notification(event, email.send_mail)\n\n...\n# later, at runtime:\nsosn_composed(event)  # will have email.send_mail already injected in\n----\n====\n\n\n=== An Alternative Using Classes\n\n(((\"classes, dependency injection using\")))\n(((\"dependency injection\", \"using classes\")))\nClosures and partial functions will feel familiar to people who've done a bit\nof functional programming. Here's an alternative using classes, which may\nappeal to others. It requires rewriting all our handler functions as\nclasses, though:\n\n[[di_with_classes]]\n.DI using classes\n====\n[source,python]\n[role=\"skip\"]\n----\n# we replace the old `def allocate(cmd, uow)` with:\n\nclass AllocateHandler:\n    def __init__(self, uow: unit_of_work.AbstractUnitOfWork):  #<2>\n        self.uow = uow\n\n    def __call__(self, cmd: commands.Allocate):  #<1>\n        line = OrderLine(cmd.orderid, cmd.sku, cmd.qty)\n        with self.uow:\n            # rest of handler method as before\n            ...\n\n# bootstrap script prepares actual UoW\nuow = unit_of_work.SqlAlchemyUnitOfWork()\n\n# then prepares a version of the allocate fn with dependencies already injected\nallocate = AllocateHandler(uow)\n\n...\n# later at runtime, we can call the handler instance, and it will have\n# the UoW already injected\nallocate(cmd)\n----\n====\n\n<1> The class is designed to produce a callable function, so it has a\n    +__call__+ method.\n\n<2> But we use the +++<code>init</code>+++ to declare the dependencies it\n    requires. This sort of thing will feel familiar if you've ever made\n    class-based descriptors, or a class-based context manager that takes\n    arguments.\n\n\n(((\"dependency injection\", startref=\"ix_DI\")))\nUse whichever you and your team feel more comfortable with.\n\n[role=\"pagebreak-before less_space\"]\n=== A Bootstrap Script\n\n\n(((\"bootstrapping\", \"bootstrapping script, capabilities of\")))\nWe want our bootstrap script to do the following:\n\n1. Declare default dependencies but allow us to override them\n2. Do the \"init\" stuff that we need to get our app started\n3. Inject all the dependencies into our handlers\n4. Give us back the core object for our app, the message bus\n\nHere's a first cut:\n\n\n[[bootstrap_script]]\n.A bootstrap function (src/allocation/bootstrap.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef bootstrap(\n    start_orm: bool = True,  #<1>\n    uow: unit_of_work.AbstractUnitOfWork = unit_of_work.SqlAlchemyUnitOfWork(),  #<2>\n    send_mail: Callable = email.send,\n    publish: Callable = redis_eventpublisher.publish,\n) -> messagebus.MessageBus:\n\n    if start_orm:\n        orm.start_mappers()  #<1>\n\n    dependencies = {\"uow\": uow, \"send_mail\": send_mail, \"publish\": publish}\n    injected_event_handlers = {  #<3>\n        event_type: [\n            inject_dependencies(handler, dependencies)\n            for handler in event_handlers\n        ]\n        for event_type, event_handlers in handlers.EVENT_HANDLERS.items()\n    }\n    injected_command_handlers = {  #<3>\n        command_type: inject_dependencies(handler, dependencies)\n        for command_type, handler in handlers.COMMAND_HANDLERS.items()\n    }\n\n    return messagebus.MessageBus(  #<4>\n        uow=uow,\n        event_handlers=injected_event_handlers,\n        command_handlers=injected_command_handlers,\n    )\n----\n====\n\n<1> `orm.start_mappers()` is our example of initialization work that needs\n    to be done once at the beginning of an app. Another common example is\n    setting up the `logging` module.\n    (((\"object-relational mappers (ORMs)\", \"orm.start_mappers function\")))\n\n<2> We can use the argument defaults to define what the normal/production\n    defaults are. It's nice to have them in a single place, but\n    sometimes dependencies have some side effects at construction time,\n    in which case you might prefer to default them to `None` instead.\n\n<3> We build up our injected versions of the handler mappings by using\n    a function called `inject_dependencies()`, which we'll show next.\n\n<4> We return a configured message bus ready for use.\n\n// TODO more examples of init stuff\n\n// IDEA: show option of bootstrapper as class instead?\n\n(((\"dependency injection\", \"by inspecting function signatures\")))\nHere's how we inject dependencies into a handler function by inspecting\nit:\n\n[[di_by_inspection]]\n.DI by inspecting function signatures (src/allocation/bootstrap.py)\n====\n[source,python]\n----\ndef inject_dependencies(handler, dependencies):\n    params = inspect.signature(handler).parameters  #<1>\n    deps = {\n        name: dependency\n        for name, dependency in dependencies.items()  #<2>\n        if name in params\n    }\n    return lambda message: handler(message, **deps)  #<3>\n----\n====\n\n<1> We inspect our command/event handler's arguments.\n<2> We match them by name to our dependencies.\n<3> We inject them as kwargs to produce a partial.\n\n\n.Even-More-Manual DI with Less Magic\n*******************************************************************************\n\n(((\"dependency injection\", \"manual creation of partial functions inline\")))\nIf you're finding the preceding `inspect` code a little harder to grok, this\neven simpler version may appeal to you.\n\n(((\"partial functions\", \"manually creating inline\")))\nHarry wrote the code for `inject_dependencies()` as a first cut of how to do\n\"manual\" dependency injection, and when he saw it, Bob accused him of\noverengineering and writing his own DI framework.\n\nIt honestly didn't even occur to Harry that you could do it any more plainly,\nbut you can, like this:\n\n// (EJ3) I don't know if I'd even call this DI, it's just straight meta-programming.\n\n[[nomagic_di]]\n.Manually creating partial functions inline (src/allocation/bootstrap.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n    injected_event_handlers = {\n        events.Allocated: [\n            lambda e: handlers.publish_allocated_event(e, publish),\n            lambda e: handlers.add_allocation_to_read_model(e, uow),\n        ],\n        events.Deallocated: [\n            lambda e: handlers.remove_allocation_from_read_model(e, uow),\n            lambda e: handlers.reallocate(e, uow),\n        ],\n        events.OutOfStock: [\n            lambda e: handlers.send_out_of_stock_notification(e, send_mail)\n        ],\n    }\n    injected_command_handlers = {\n        commands.Allocate: lambda c: handlers.allocate(c, uow),\n        commands.CreateBatch: lambda c: handlers.add_batch(c, uow),\n        commands.ChangeBatchQuantity: \\\n            lambda c: handlers.change_batch_quantity(c, uow),\n    }\n----\n====\n\nHarry says he couldn't even imagine writing out that many lines of code and\nhaving to look up that many function arguments manually. It would be a\nperfectly viable solution, though, since it's only one line of code or so per\nhandler you add. Even if you have dozens of handlers, it wouldn't be much of\nmaintenance burden.\n\nOur app is structured in such a way that we always want to do dependency\ninjection in only one place, the handler functions, so this super-manual solution\nand Harry's `inspect()`-based one will both work fine.\n\n(((\"dependency injection\", \"using DI framework\")))\n(((\"dependency chains\")))\nIf you find yourself wanting to do DI in more things and at different times,\nor if you ever get into _dependency chains_ (in which your dependencies have their\nown dependencies, and so on), you may get some mileage out of a \"real\" DI\nframework.\n\n// IDEA: discuss/define what a DI container is\n\nAt MADE, we've used https://pypi.org/project/Inject[Inject] in a few places,\nand it's _fine_ (although it makes Pylint unhappy).  You might also check out\nhttps://pypi.org/project/punq[Punq], as written by Bob himself, or the\nDRY-Python crew's https://github.com/dry-python/dependencies[Dependencies].\n\n*******************************************************************************\n\n\n=== Message Bus Is Given Handlers at Runtime\n\n(((\"message bus\", \"class given handlers at runtime\")))\nOur message bus will no longer be static; it needs to have the already-injected\nhandlers given to it. So we turn it from being a module into a configurable\nclass:\n\n\n[[messagebus_as_class]]\n.MessageBus as a class (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\nclass MessageBus:  #<1>\n    def __init__(\n        self,\n        uow: unit_of_work.AbstractUnitOfWork,\n        event_handlers: Dict[Type[events.Event], List[Callable]],  #<2>\n        command_handlers: Dict[Type[commands.Command], Callable],  #<2>\n    ):\n        self.uow = uow\n        self.event_handlers = event_handlers\n        self.command_handlers = command_handlers\n\n    def handle(self, message: Message):  #<3>\n        self.queue = [message]  #<4>\n        while self.queue:\n            message = self.queue.pop(0)\n            if isinstance(message, events.Event):\n                self.handle_event(message)\n            elif isinstance(message, commands.Command):\n                self.handle_command(message)\n            else:\n                raise Exception(f\"{message} was not an Event or Command\")\n----\n====\n\n<1> The message bus becomes a class...\n<2> ...which is given its already-dependency-injected handlers.\n<3> The main `handle()` function is substantially the same, with just a few attributes and methods moved onto `self`.\n<4> Using `self.queue` like this is not thread-safe, which might\n    be a problem if you're using threads, because the bus instance is global\n    in the Flask app context as we've written it. Just something to watch out for.\n\n\n(((\"message bus\", \"event and command handler logic staying the same\")))\n(((\"commands\", \"command handler logic in message bus\")))\n(((\"handlers\", \"event and command handlers in message bus\")))\n(((\"event handlers\", \"in message bus\")))\nWhat else changes in the bus?\n\n[[messagebus_handlers_change]]\n.Event and command handler logic stays the same (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n----\n    def handle_event(self, event: events.Event):\n        for handler in self.event_handlers[type(event)]:  #<1>\n            try:\n                logger.debug(\"handling event %s with handler %s\", event, handler)\n                handler(event)  #<2>\n                self.queue.extend(self.uow.collect_new_events())\n            except Exception:\n                logger.exception(\"Exception handling event %s\", event)\n                continue\n\n    def handle_command(self, command: commands.Command):\n        logger.debug(\"handling command %s\", command)\n        try:\n            handler = self.command_handlers[type(command)]  #<1>\n            handler(command)  #<2>\n            self.queue.extend(self.uow.collect_new_events())\n        except Exception:\n            logger.exception(\"Exception handling command %s\", command)\n            raise\n----\n====\n\n<1> `handle_event` and `handle_command` are substantially the same, but instead\n    of indexing into a static `EVENT_HANDLERS` or `COMMAND_HANDLERS` dict, they\n    use the versions on `self`.\n\n<2> Instead of passing a UoW into the handler, we expect the handlers\n    to already have all their dependencies, so all they need is a single argument,\n    the specific event or command.\n\n\n=== Using Bootstrap in Our Entrypoints\n\n(((\"bootstrapping\", \"using in entrypoints\")))\n(((\"Flask framework\", \"calling bootstrap in entrypoints\")))\nIn our application's entrypoints, we now just call `bootstrap.bootstrap()`\nand get a message bus that's ready to go, rather than configuring a UoW and the\nrest of it:\n\n[[flask_calls_bootstrap]]\n.Flask calls bootstrap (src/allocation/entrypoints/flask_app.py)\n====\n[source,diff]\n----\n-from allocation import views\n+from allocation import bootstrap, views\n\n app = Flask(__name__)\n-orm.start_mappers()  #<1>\n+bus = bootstrap.bootstrap()\n\n\n @app.route(\"/add_batch\", methods=[\"POST\"])\n@@ -19,8 +16,7 @@ def add_batch():\n     cmd = commands.CreateBatch(\n         request.json[\"ref\"], request.json[\"sku\"], request.json[\"qty\"], eta\n     )\n-    uow = unit_of_work.SqlAlchemyUnitOfWork()  #<2>\n-    messagebus.handle(cmd, uow)\n+    bus.handle(cmd)  #<3>\n     return \"OK\", 201\n\n----\n====\n\n<1> We no longer need to call `start_orm()`; the bootstrap script's initialization\n    stages will do that.\n\n<2> We no longer need to explicitly build a particular type of UoW; the bootstrap\n    script defaults take care of it.\n\n<3> And our message bus is now a specific instance rather than the global module.footnote:[\n    However, it's still a global in the `flask_app` module scope, if that makes sense. This\n    may cause problems if you ever find yourself wanting to test your Flask app\n    in-process by using the Flask Test Client instead of using Docker as we do.\n    It's worth researching https://oreil.ly/_a6Kl[Flask app factories]\n    if you get into this.]\n\n\n=== Initializing DI in Our Tests\n\n(((\"message bus\", \"getting custom with overridden bootstrap defaults\")))\n(((\"bootstrapping\", \"initializing dependency injection in tests\")))\n(((\"testing\", \"integration test for overriding bootstrap defaults\")))\nIn tests, we can use `bootstrap.bootstrap()` with overridden defaults to get a\ncustom message bus. Here's an example in an integration test:\n\n\n[[bootstrap_view_tests]]\n.Overriding bootstrap defaults (tests/integration/test_views.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\n@pytest.fixture\ndef sqlite_bus(sqlite_session_factory):\n    bus = bootstrap.bootstrap(\n        start_orm=True,  #<1>\n        uow=unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory),  #<2>\n        send_mail=lambda *args: None,  #<3>\n        publish=lambda *args: None,  #<3>\n    )\n    yield bus\n    clear_mappers()\n\n\ndef test_allocations_view(sqlite_bus):\n    sqlite_bus.handle(commands.CreateBatch(\"sku1batch\", \"sku1\", 50, None))\n    sqlite_bus.handle(commands.CreateBatch(\"sku2batch\", \"sku2\", 50, today))\n    ...\n    assert views.allocations(\"order1\", sqlite_bus.uow) == [\n        {\"sku\": \"sku1\", \"batchref\": \"sku1batch\"},\n        {\"sku\": \"sku2\", \"batchref\": \"sku2batch\"},\n    ]\n----\n====\n\n<1> We do still want to start the ORM...\n<2> ...because we're going to use a real UoW, albeit with an in-memory database.\n<3> But we don't need to send email or publish, so we make those noops.\n\n\n(((\"testing\", \"unit test for bootstrap\")))\nIn our unit tests, in contrast, we can reuse our `FakeUnitOfWork`:\n\n[[bootstrap_tests]]\n.Bootstrap in unit test (tests/unit/test_handlers.py)\n====\n[source,python]\n[role=\"non-head\"]\n----\ndef bootstrap_test_app():\n    return bootstrap.bootstrap(\n        start_orm=False,  #<1>\n        uow=FakeUnitOfWork(),  #<2>\n        send_mail=lambda *args: None,  #<3>\n        publish=lambda *args: None,  #<3>\n    )\n----\n====\n\n<1> No need to start the ORM...\n<2> ...because the fake UoW doesn't use one.\n<3> We want to fake out our email and Redis adapters too.\n\n\nSo that gets rid of a little duplication, and we've moved a bunch\nof setup and sensible defaults into a single place.\n\n[role=\"nobreakinside less_space\"]\n.Exercise for the Reader 1\n**********************************************************************\nChange all the handlers to being classes as per the <<di_with_classes, DI using classes>> example,\nand amend the bootstrapper's DI code as appropriate.  This will let you\nknow whether you prefer the functional approach or the class-based approach when\nit comes to your own projects.\n**********************************************************************\n\n\n=== Building an Adapter \"Properly\": A Worked Example\n\n(((\"adapters\", \"building adapter and doing dependency injection for it\", id=\"ix_adapDI\")))\nTo really get a feel for how it all works, let's work through an example of how\nyou might \"properly\" build an adapter and do dependency injection for it.\n\nAt the moment, we have two types of dependencies:\n\n[[two_types_of_dependency]]\n.Two types of dependencies (src/allocation/service_layer/messagebus.py)\n====\n[source,python]\n[role=\"skip\"]\n----\n    uow: unit_of_work.AbstractUnitOfWork,  #<1>\n    send_mail: Callable,  #<2>\n    publish: Callable,  #<2>\n----\n====\n\n<1> The UoW has an abstract base class. This is the heavyweight\n    option for declaring and managing your external dependency.\n    We'd use this for the case when the dependency is relatively complex.\n\n<2> Our email sender and pub/sub publisher are defined\n    as functions. This works just fine for simple dependencies.\n\nHere are some of the things we find ourselves injecting at work:\n\n* An S3 filesystem client\n* A key/value store client\n* A `requests` session object\n\nMost of these will have more-complex APIs that you can't capture\nas a single function: read and write, GET and POST, and so on.\n\nEven though it's simple, let's use `send_mail` as an example to talk\nthrough how you might define a more complex dependency.\n\n\n==== Define the Abstract and Concrete Implementations\n\n(((\"adapters\", \"building adapter and doing dependency injection for it\", \"defining abstract and concrete implementations\")))\n(((\"abstract base classes (ABCs)\", \"defining for notifications\")))\nWe'll imagine a more generic notifications API. Could be\nemail, could be SMS, could be Slack posts one day.\n\n\n[[notifications_dot_py]]\n.An ABC and a concrete implementation (src/allocation/adapters/notifications.py)\n====\n[source,python]\n----\nclass AbstractNotifications(abc.ABC):\n    @abc.abstractmethod\n    def send(self, destination, message):\n        raise NotImplementedError\n\n...\n\nclass EmailNotifications(AbstractNotifications):\n    def __init__(self, smtp_host=DEFAULT_HOST, port=DEFAULT_PORT):\n        self.server = smtplib.SMTP(smtp_host, port=port)\n        self.server.noop()\n\n    def send(self, destination, message):\n        msg = f\"Subject: allocation service notification\\n{message}\"\n        self.server.sendmail(\n            from_addr=\"allocations@example.com\",\n            to_addrs=[destination],\n            msg=msg,\n        )\n----\n====\n\n\n(((\"bootstrapping\", \"changing notifications dependency in bootstrap script\")))\nWe change the dependency in the bootstrap script:\n\n[[notifications_in_bus]]\n.Notifications in message bus (src/allocation/bootstrap.py)\n====\n[source,diff]\n[role=\"skip\"]\n----\n def bootstrap(\n     start_orm: bool = True,\n     uow: unit_of_work.AbstractUnitOfWork = unit_of_work.SqlAlchemyUnitOfWork(),\n-    send_mail: Callable = email.send,\n+    notifications: AbstractNotifications = EmailNotifications(),\n     publish: Callable = redis_eventpublisher.publish,\n ) -> messagebus.MessageBus:\n----\n====\n\n\n==== Make a Fake Version for Your Tests\n\n(((\"faking\", \"FakeNotifications for unit testing\")))\nWe work through and define a fake version for unit testing:\n\n\n[[fake_notifications]]\n.Fake notifications (tests/unit/test_handlers.py)\n====\n[source,python]\n----\nclass FakeNotifications(notifications.AbstractNotifications):\n    def __init__(self):\n        self.sent = defaultdict(list)  # type: Dict[str, List[str]]\n\n    def send(self, destination, message):\n        self.sent[destination].append(message)\n...\n----\n====\n\nAnd we use it in our tests:\n\n[[test_with_fake_notifs]]\n.Tests change slightly (tests/unit/test_handlers.py)\n====\n[source,python]\n----\n    def test_sends_email_on_out_of_stock_error(self):\n        fake_notifs = FakeNotifications()\n        bus = bootstrap.bootstrap(\n            start_orm=False,\n            uow=FakeUnitOfWork(),\n            notifications=fake_notifs,\n            publish=lambda *args: None,\n        )\n        bus.handle(commands.CreateBatch(\"b1\", \"POPULAR-CURTAINS\", 9, None))\n        bus.handle(commands.Allocate(\"o1\", \"POPULAR-CURTAINS\", 10))\n        assert fake_notifs.sent[\"stock@made.com\"] == [\n            f\"Out of stock for POPULAR-CURTAINS\",\n        ]\n----\n====\n\n\n==== Figure Out How to Integration Test the Real Thing\n\n(((\"Docker dev environment with real fake email server\")))\nNow we test the real thing, usually with an end-to-end or integration\ntest.  We've used https://github.com/mailhog/MailHog[MailHog] as a\nreal-ish email server for our Docker dev environment:\n\n\n[[docker_compose_with_mailhog]]\n.Docker-compose config with real fake email server (docker-compose.yml)\n====\n[source,yaml]\n----\nversion: \"3\"\n\nservices:\n\n  redis_pubsub:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    image: allocation-image\n    ...\n\n  api:\n    image: allocation-image\n    ...\n\n  postgres:\n    image: postgres:9.6\n    ...\n\n  redis:\n    image: redis:alpine\n    ...\n\n  mailhog:\n    image: mailhog/mailhog\n    ports:\n      - \"11025:1025\"\n      - \"18025:8025\"\n----\n====\n\n\n(((\"bootstrapping\", \"using to build message bus that talks to real notification class\")))\nIn our integration tests, we use the real `EmailNotifications` class,\ntalking to the MailHog server in the Docker cluster:\n\n\n[[integration_test_email]]\n.Integration test for email (tests/integration/test_email.py)\n====\n[source,python]\n----\n@pytest.fixture\ndef bus(sqlite_session_factory):\n    bus = bootstrap.bootstrap(\n        start_orm=True,\n        uow=unit_of_work.SqlAlchemyUnitOfWork(sqlite_session_factory),\n        notifications=notifications.EmailNotifications(),  #<1>\n        publish=lambda *args: None,\n    )\n    yield bus\n    clear_mappers()\n\n\ndef get_email_from_mailhog(sku):  #<2>\n    host, port = map(config.get_email_host_and_port().get, [\"host\", \"http_port\"])\n    all_emails = requests.get(f\"http://{host}:{port}/api/v2/messages\").json()\n    return next(m for m in all_emails[\"items\"] if sku in str(m))\n\n\ndef test_out_of_stock_email(bus):\n    sku = random_sku()\n    bus.handle(commands.CreateBatch(\"batch1\", sku, 9, None))  #<3>\n    bus.handle(commands.Allocate(\"order1\", sku, 10))\n    email = get_email_from_mailhog(sku)\n    assert email[\"Raw\"][\"From\"] == \"allocations@example.com\"  #<4>\n    assert email[\"Raw\"][\"To\"] == [\"stock@made.com\"]\n    assert f\"Out of stock for {sku}\" in email[\"Raw\"][\"Data\"]\n----\n====\n\n<1> We use our bootstrapper to build a message bus that talks to the\n    real notifications class.\n<2> We figure out how to fetch emails from our \"real\" email server.\n<3> We use the bus to do our test setup.\n<4> Against all the odds, this actually worked, pretty much at the first go!\n\n\nAnd that's it really.\n\n\n[role=\"less_space nobreakinside\"]\n.Exercise for the Reader 2\n******************************************************************************\n\n(((\"adapters\", \"exercise for the reader\")))\nYou could do two things for practice regarding adapters:\n\n1. Try swapping out our notifications from email to SMS\n    notifications using Twilio, for example, or Slack notifications.  Can you find\n    a good equivalent to MailHog for integration testing?\n\n2. In a similar way to what we did moving from `send_mail` to a `Notifications`\n    class, try refactoring our `redis_eventpublisher` that is currently just\n    a `Callable` to some sort of more formal adapter/base class/protocol.\n\n******************************************************************************\n\n=== Wrap-Up\n\n* Once you have more than one adapter, you'll start to feel a lot of pain\n  from passing dependencies around manually, unless you do some kind of\n  _dependency injection._\n  (((\"dependency injection\", \"recap of DI and bootstrap\")))\n  (((\"bootstrapping\", \"dependency injection and bootstrap recap\")))\n\n* Setting up dependency injection is just one of many typical\n  setup/initialization activities that you need to do just once when starting\n  your app.  Putting this all together into a _bootstrap script_ is often a\n  good idea.\n\n* The bootstrap script is also good as a place to provide sensible default\n  configuration for your adapters, and as a single place to override those\n  adapters with fakes for your tests.\n\n* A dependency injection framework can be useful if you find yourself\n  needing to do DI at multiple levels—if you have chained dependencies\n  of components that all need DI, for example.\n\n* This chapter also presented a worked example of changing an implicit/simple\n  dependency into a \"proper\" adapter, factoring out an ABC, defining its real\n  and fake implementations, and thinking through integration testing.\n\n[role=\"less_space nobreakinside\"]\n.DI and Bootstrap Recap\n*******************************************************************************\nIn summary:\n\n1. Define your API using an ABC.\n2. Implement the real thing.\n3. Build a fake and use it for unit/service-layer/handler tests.\n4. Find a less fake version you can put into your Docker environment.\n5. Test the less fake \"real\" thing.\n6. Profit!\n(((\"adapters\", \"defining adapter and doing dependency injection for it\", startref=\"ix_adapDI\")))\n\n// TODO this isn't really in the right TDD order is it?\n*******************************************************************************\n\nThese were the last patterns we wanted to cover, which brings us to the end of\n<<part2>>. In <<epilogue_1_how_to_get_there_from_here, the epilogue>>, we'll\ntry to give you some pointers for applying these techniques in the Real\nWorld^TM^.\n\n// TODO: tradeoffs?\n"
        },
        {
          "name": "chapters.py",
          "type": "blob",
          "size": 0.970703125,
          "content": "#!/usr/bin/env python\n\nCHAPTERS = [\n    'chapter_01_domain_model',\n    'chapter_02_repository',\n    \"chapter_04_service_layer\",\n    \"chapter_05_high_gear_low_gear\",\n    \"appendix_project_structure\",\n    'appendix_django',\n    \"chapter_06_uow\",\n    \"appendix_csvs\",\n    \"chapter_07_aggregate\",\n    \"chapter_08_events_and_message_bus\",\n    \"chapter_09_all_messagebus\",\n    \"chapter_10_commands\",\n    \"chapter_11_external_events\",\n    \"chapter_12_cqrs\",\n    \"chapter_13_dependency_injection\",\n]\n\nBRANCHES = {\n    'appendix_csvs',\n    'appendix_django',\n}\n\nSTANDALONE = [\n    'chapter_03_abstractions',\n]\n\nNO_EXERCISE = [\n    \"chapter_03_abstractions\",\n    \"chapter_05_high_gear_low_gear\",\n    \"appendix_project_structure\",\n    'appendix_django',\n    \"appendix_csvs\",\n    \"chapter_09_all_messagebus\",\n    \"chapter_10_commands\",\n    \"chapter_11_external_events\",\n    \"chapter_12_cqrs\",\n    \"chapter_13_dependency_injection\",\n]\n\nif __name__ == \"__main__\":\n    print(\"\\n\".join(CHAPTERS + STANDALONE))\n"
        },
        {
          "name": "checkout-branches-for-ci.py",
          "type": "blob",
          "size": 0.4453125,
          "content": "#!/usr/bin/env python\n\nimport subprocess\nfrom pathlib import Path\nfrom chapters import CHAPTERS, STANDALONE, NO_EXERCISE\n\ncwd = Path(__file__).parent / 'code'\n\nfor chap in CHAPTERS + STANDALONE:\n    subprocess.run(['git', 'checkout', chap], cwd=cwd, check=True)\n    if chap in NO_EXERCISE:\n        continue\n    subprocess.run(['git', 'checkout', f'{chap}_exercise'], cwd=cwd, check=True)\n\nsubprocess.run(['git', 'checkout', 'master'], cwd=cwd, check=True)\n"
        },
        {
          "name": "code",
          "type": "commit",
          "content": null
        },
        {
          "name": "colo.html",
          "type": "blob",
          "size": 1.626953125,
          "content": "<section id=\"colophon\" data-type=\"colophon\" xmlns=\"http://www.w3.org/1999/xhtml\">\n  <h1>Colophon</h1>\n\n<p>The animal on the cover of <em>Architecture Patterns with Python</em> is a Burmese python (<em>Python bivitattus</em>). As you might expect, the Burmese python is native to Southeast Asia. Today it lives in jungles and marshes in South Asia, Myanmar, China, and Indonesia; it’s also invasive in Florida’s Everglades.</p>\n\n<p>Burmese pythons are one of the world’s largest species of snakes. These nocturnal, carnivorous constrictors can grow to 23 feet and 200 pounds. Females are larger than males. They can lay up to a hundred eggs in one clutch. In the wild, Burmese pythons live an average of 20 to 25 years.</p>\n\n<p>The markings on a Burmese python begin with an arrow-shaped spot of light brown on top of the head and continue along the body in rectangles that stand out against its otherwise tan scales. Before they reach their full size, which takes two to three years, Burmese pythons live in trees hunting small mammals and birds. They also swim for long stretches of time—going up to 30 minutes without air.</p>\n\n<p>Because of habitat destruction, the Burmese python has a conservation status of Vulnerable. Many of the animals on O’Reilly’s covers are endangered; all of them are important to the world.</p>\n\n<p>The color illustration is by Jose Marzan, based on a black-and-white engraving from <em>Encyclopedie D'Histoire Naturelle</em>. The cover fonts are URW Typewriter and Guardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad Condensed; and the code font is Dalton Maag's Ubuntu Mono.</p>\n</section>\n"
        },
        {
          "name": "copyright.html",
          "type": "blob",
          "size": 3.5126953125,
          "content": "<section data-type=\"copyright-page\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<h1>Architecture Patterns with Python</h1>\n\n<p class=\"author\">by <span class=\"firstname\">Harry </span> <span class=\"surname\">Percival</span> and <span class=\"firstname\">Bob </span> <span class=\"surname\">Gregory</span></p>\n\n<p class=\"copyright\">Copyright © 2020 Harry Percival and Bob Gregory. All rights reserved.</p>\n\n<p class=\"printlocation\">Printed in the United States of America.</p>\n\n<p class=\"publisher\">Published by <span class=\"publishername\">O'Reilly Media, Inc.</span>, 1005 Gravenstein Highway North, Sebastopol, CA 95472.</p>\n\n<p>O'Reilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles (<a href=\"http://oreilly.com\">http://oreilly.com</a>). For more information, contact our corporate/institutional sales department: 800-998-9938 or <span data-type=\"email\"><em>corporate@oreilly.com</em></span>.</p>\n\n<ul class=\"stafflist\">\n\t<li><span class=\"staffrole\">Acquisitions Editor:</span> Ryan Shaw</li>\n\t<li><span class=\"staffrole\">Development Editor:</span> Corbin Collins</li>\n\t<li><span class=\"staffrole\">Production Editor:</span> Katherine Tozer</li>\n\t<li><span class=\"staffrole\">Copyeditor:</span> Sharon Wilkey</li>\n\t<li><span class=\"staffrole\">Proofreader:</span> Arthur Johnson</li>\n\t<li><span class=\"staffrole\">Indexer:</span> Ellen Troutman-Zaig</li>\n\t<li><span class=\"staffrole\">Interior Designer:</span> David Futato</li>\n\t<li><span class=\"staffrole\">Cover Designer:</span> Karen Montgomery</li>\n\t<li><span class=\"staffrole\">Illustrator:</span> Rebecca Demarest</li>\n</ul>\n\n<ul class=\"printings\">\n\t<li><span class=\"printedition\">March 2020:</span> First Edition</li>\n</ul>\n<!--Add additional revdate spans below as needed.-->\n\n<div>\n<h1 class=\"revisions\">Revision History for the First Edition</h1>\n\n<ul class=\"releases\">\n\t<li><span class=\"revdate\">2020-03-05:</span> First Release</li>\n</ul>\n</div>\n\n<p class=\"errata\">See <a href=\"http://oreilly.com/catalog/errata.csp?isbn=9781492052203\">http://oreilly.com/catalog/errata.csp?isbn=9781492052203</a> for release details.</p>\n\n<div class=\"legal\">\n<p>The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. <em>Architecture Patterns with Python</em>, the cover image, and related trade dress are trademarks of O’Reilly Media, Inc.</p>\n\n<p>The views expressed in this work are those of the authors and do not represent the publisher's views. While the publisher and the authors have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the authors disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work. Use of the information and instructions contained in this work is at your own risk. If any code samples or other technology this work contains or describes is subject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and/or rights. <!--PROD: Uncomment the following sentence if appropriate and add it to the \n        above para:--> <!--This book is not intended as [legal/medical/financial; use the appropriate\n        reference] advice. Please consult a qualified professional if you \n        require [legal/medical/financial] advice.--></p>\n</div>\n\n<div class=\"copyright-bottom\">\n<p class=\"isbn\">978-1-492-05220-3</p>\n\n<p class=\"printer\">[LSI]</p>\n</div>\n</section>\n"
        },
        {
          "name": "cover.html",
          "type": "blob",
          "size": 0.064453125,
          "content": "<figure data-type=\"cover\">\n<img src=\"images/cover.png\"/>\n</figure>"
        },
        {
          "name": "epilogue_1_how_to_get_there_from_here.asciidoc",
          "type": "blob",
          "size": 37.4833984375,
          "content": "[[epilogue_1_how_to_get_there_from_here]]\n[appendix]\n[role=\"afterword\"]\n== Epilogue\n\n=== What Now?\n\nPhew! We've covered a lot of ground in this book, and for most of our audience\nall of these ideas are new. With that in mind, we can't hope to make you experts\nin these techniques. All we can really do is show you the broad-brush ideas, and\njust enough code for you to go ahead and write something from scratch.\n\nThe code we've shown in this book isn't battle-hardened production code: it's a\nset of Lego blocks that you can play with to make your first house, spaceship,\nand [.keep-together]#skyscraper#.\n\nThat leaves us with two big tasks. We want to talk\nabout how to start applying these ideas for real in an existing system, and we\nneed to warn you about some of the things we had to skip. We've given you a\nwhole new arsenal of ways to shoot yourself in the foot, so we should discuss\nsome basic firearms safety.\n\n=== How Do I Get There from Here?\n\nChances are that a lot of you are thinking something like this:\n\n\"OK Bob and Harry, that's all well and good, and if I ever get hired to work\non a green-field new service, I know what to do. But in the meantime, I'm\nhere with my big ball of Django mud, and I don't see any way to get to your\nnice, clean, perfect, untainted, simplistic model. Not from here.\"\n\nWe hear you. Once you've already _built_ a big ball of mud, it's hard to know\nhow to start improving things. Really, we need to tackle things step by step.\n\nFirst things first: what problem are you trying to solve? Is the software too\nhard to change? Is the performance unacceptable? Have you got weird, inexplicable\nbugs?\n\nHaving a clear goal in mind will help you to prioritize the work that needs to\nbe done and, importantly, communicate the reasons for doing it to the rest of\nthe team. [.keep-together]#Businesses# tend to have pragmatic approaches to technical debt\nand refactoring, so long as engineers can make a reasoned argument for fixing\nthings.\n\nTIP: Making complex changes to a system is often an easier sell if you link it\nto feature work. Perhaps you're launching a new product or opening your service\nto new markets? This is the right time to spend engineering resources on fixing\nthe foundations. With a six-month project to deliver, it's easier to make the\nargument for three weeks of cleanup work. Bob refers to this as _architecture\ntax_.\n\n=== Separating Entangled Responsibilities\n\nAt the beginning of the book, we said that the main characteristic(((\"Ball of Mud pattern\", \"separating responsibilities\")))(((\"responsibilities of code\", \"separating responsibilities\"))) of a big ball\nof mud is homogeneity: every part of the system looks the same, because we\nhaven't been clear about the responsibilities of each component. To fix that,\nwe'll need to start separating out responsibilities and introducing clear\nboundaries. One of the first things we can do is to start building a service\nlayer (<<collaboration_app_model>>).\n\n[role=\"width-60\"]\n[[collaboration_app_model]]\n.Domain of a collaboration system\nimage::images/apwp_ep01.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep01, config=plantuml.cfg]\n@startuml\nscale 4\nhide empty members\n\nWorkspace *- Folder : contains\nAccount *- Workspace : owns\nAccount *-- Package : has\nUser *-- Account : manages\nWorkspace *-- User : has members\nUser *-- Document : owns\nFolder *-- Document : contains\nDocument *- Version: has\nUser *-- Version: authors\n@enduml\n----\n\nThis was the system in which Bob first learned how to break apart a ball of mud,\nand it was a doozy. There was logic _everywhere_—in the web pages, in\nmanager objects, in helpers, in fat service classes that we'd written to\nabstract the managers and helpers, and in hairy command objects that we'd\nwritten to break apart the services.\n\nIf you're working in a system that's reached this point, the situation can feel hopeless,\nbut it's never too late to start weeding an overgrown garden. Eventually, we\nhired an architect who knew what he was doing, and he helped us get things\nback under control.\n\nStart by working out the _use cases_ of your system. If you have a\nuser interface, what actions does it perform? If you have a backend\nprocessing component, maybe each cron job or Celery job is a single\nuse case. Each of your use cases needs to have an imperative name: Apply\nBilling Charges, Clean Abandoned Accounts, or Raise Purchase Order, for example.\n\nIn our case, most of our use cases were part of the manager classes and had\nnames like Create Workspace or Delete Document Version. Each use case\nwas invoked from a web frontend.\n\nWe aim to create a single function or class for each of these supported\noperations that deals with _orchestrating_ the work to be done. Each use case\nshould do the following:\n\n* Start its own database transaction if needed\n* Fetch any required data\n* Check any preconditions (see the Ensure pattern in <<appendix_validation>>)\n* Update the domain model\n* Persist any changes\n\nEach use case should succeed or fail as an atomic unit. You might need to call\none use case from another. That's OK; just make a note of it, and try to\navoid long-running database transactions.\n\nNOTE: One of the biggest problems we had was that manager methods called other\nmanager methods, and data access could happen from the model objects themselves.\nIt was hard to understand what each operation did without going on a treasure hunt across the codebase. Pulling all the logic into a single method, and using\na UoW to control our transactions, made the system easier to reason\nabout.\n\n[role=\"less_space nobreakinside\"]\n.Case Study: Layering an Overgrown System\n********************************************************************************\nMany years ago, Bob worked for a software company that had outsourced the first\nversion of its application, an online collaboration platform for sharing and\nworking on files.(((\"layered architecture\", \"case study, layering an overgrown system\")))(((\"responsibilities of code\", \"separating responsibilities\", \"case study, layering overgrown system\")))\n\nWhen the company brought development in-house, it passed through several\ngenerations of developers' hands, and each wave of new developers added more\ncomplexity to the code's structure.\n\nAt its heart, the system was an ASP.NET Web Forms application, built with an\nNHibernate ORM. Users would upload documents into workspaces, where they could\ninvite other workspace members to review, comment on, or modify their work.\n\nMost of the complexity of the application was in the permissions model because\neach document was contained in a folder, and folders allowed read, write, and\nedit permissions, much like a Linux filesystem.\n\nAdditionally, each workspace belonged to an account, and the account had quotas\nattached to it via a billing package.\n\nAs a result, every read or write operation against a document had to load an\nenormous number of objects from the database in order to test permissions and\nquotas. Creating a new workspace involved hundreds of database queries as we set\nup the permissions structure, invited users, and set up sample content.\n\nSome of the code for operations was in web handlers that ran when a user clicked\na button or submitted a form; some of it was in manager objects that held\ncode for orchestrating work; and some of it was in the domain model. Model\nobjects would make database calls or copy files on disk, and the test coverage\nwas abysmal.\n\nTo fix the problem, we first introduced a service layer so that all of the code\nfor creating a document or workspace was in one place and could be understood.\nThis involved pulling data access code out of the domain model and into\ncommand handlers. Likewise, we pulled orchestration code out of the managers and\nthe web handlers and pushed it into handlers.\n\nThe resulting command handlers were _long_ and messy, but we'd made a start at\nintroducing order to the chaos.\n********************************************************************************\n\nTIP: It's fine if you have duplication in the use-case functions. We're not\n    trying to write perfect code; we're just trying to extract some meaningful\n    layers. It's better to duplicate some code in a few places than to have\n    use-case functions calling one another in a long chain.\n\nThis is a good opportunity to pull any data-access or orchestration code out of\nthe domain model and into the use cases. We should also try to pull I/O\nconcerns (e.g., sending email, writing files) out of the domain model and up into\nthe use-case functions. We apply the techniques from <<chapter_03_abstractions>> on abstractions\nto keep our handlers unit testable even when they're performing I/O.\n\nThese use-case functions will mostly be about logging, data access, and error\nhandling. Once you've done this step, you'll have a grasp of what your program\nactually _does_, and a way to make sure each operation has a clearly defined\nstart and finish. We'll have taken a step toward building a pure domain model.\n\nRead _Working Effectively with Legacy Code_ by Michael C. Feathers (Prentice Hall) for guidance on getting legacy code\nunder test and starting separating responsibilities.\n\n\n=== Identifying Aggregates and Bounded Contexts\n\nPart of the problem with the codebase in our case study was that the object\ngraph was highly connected.(((\"aggregates\", \"identifying aggregates and bounded contexts\", id=\"ix_aggID\")))(((\"bounded contexts\", \"identifying aggregates and\", id=\"ix_BCID\"))) Each account had many workspaces, and each workspace had\nmany members, all of whom had their own accounts. Each workspace contained many\ndocuments, which had many versions.\n\nYou can't express the full horror of the thing in a class diagram.\nFor one thing, there wasn't really a single account related to a user. Instead,\nthere was a bizarre rule requiring you to enumerate all of the accounts\nassociated to the user via the workspaces and take the one with the earliest\ncreation date.\n\nEvery object in the system was part of an inheritance hierarchy that included\n`SecureObject` and `Version`. This inheritance hierarchy was mirrored directly\nin the database schema, so that every query had to join across 10 different\ntables and look at a discriminator column just to tell what kind of objects\nyou were working with.\n\nThe codebase made it easy to \"dot\" your way through these objects like so:\n\n[source,python]\n----\nuser.account.workspaces[0].documents.versions[1].owner.account.settings[0];\n----\n\nBuilding a system this way with Django ORM or SQLAlchemy is easy but is\nto be [.keep-together]#avoided#. Although it's _convenient_, it makes it very hard to reason about\nperformance because each property might trigger a lookup to the database.\n\n[role=\"pagebreak-before\"]\nTIP: Aggregates are a _consistency boundary_. In general, each use case should\n    update a single aggregate at a time. One handler fetches one aggregate from\n    a repository, modifies its state, and raises any events that happen as a\n    result. If you need data from another part of the system, it's totally fine\n    to use a read model, but avoid updating multiple aggregates in a single\n    transaction. When we choose to separate code into different aggregates,\n    we're explicitly choosing to make them _eventually consistent_ with one\n    another.\n\nA bunch of operations required us to loop over objects this way—for example:\n\n[source,python]\n----\n# Lock a user's workspaces for nonpayment\n\ndef lock_account(user):\n    for workspace in user.account.workspaces:\n        workspace.archive()\n----\n\nOr even recurse over collections of folders and documents:\n\n[source,python]\n----\ndef lock_documents_in_folder(folder):\n\n    for doc in folder.documents:\n         doc.archive()\n\n     for child in folder.children:\n         lock_documents_in_folder(child)\n----\n\n\nThese operations _killed_ performance, but fixing them meant giving up our single\nobject graph. Instead, we began to identify aggregates and to break the direct\nlinks between objects.\n\nNOTE: We talked about the infamous `SELECT N+1` problem in <<chapter_12_cqrs>>, and how\nwe might choose to use different techniques when reading data for queries versus\nreading data for commands.\n\nMostly we did this by replacing direct references with identifiers.\n\n[role=\"pagebreak-before\"]\nBefore aggregates:\n\n[[aggregates_before]]\nimage::images/apwp_ep02.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep02, config=plantuml.cfg]\n@startuml\nscale 4\nhide empty members\n\ntogether {\n    class Document {\n      add_version()\n      workspace: Workspace\n      parent: Folder\n      versions: List[DocumentVersion]\n\n    }\n\n    class DocumentVersion {\n      title : str\n      version_number: int\n      document: Document\n\n    }\n    class Folder {\n      parent: Workspace\n      children: List[Folder]\n      copy_to(target: Folder)\n      add_document(document: Document)\n    }\n}\n\ntogether {\n    class User {\n      account: Account\n    }\n\n\n    class Account {\n      add_package()\n      owner : User\n      packages : List[BillingPackage]\n      workspaces: List[Workspace]\n    }\n}\n\n\nclass BillingPackage {\n}\n\nclass Workspace {\n  add_member(member: User)\n  account: Account\n  owner: User\n  members: List[User]\n}\n\n\n\nAccount --> Workspace\nAccount -left-> BillingPackage\nAccount -right-> User\nWorkspace --> User\nWorkspace --> Folder\nWorkspace --> Account\nFolder --> Folder\nFolder --> Document\nFolder --> Workspace\nFolder --> User\nDocument -right-> DocumentVersion\nDocument --> Folder\nDocument --> User\nDocumentVersion -right-> Document\nDocumentVersion --> User\nUser -left-> Account\n\n@enduml\n\n----\n\nAfter modeling with aggregates:\n[[aggregates_after]]\nimage::images/apwp_ep03.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep03, config=plantuml.cfg]\n@startuml\nscale 4\nhide empty members\n\nframe Document {\n\n  class Document {\n\n    add_version()\n\n    workspace_id: int\n    parent_folder: int\n\n    versions: List[DocumentVersion]\n\n  }\n\n  class DocumentVersion {\n\n    title : str\n    version_number: int\n\n  }\n}\n\nframe Account {\n\n  class Account {\n    add_package()\n\n    owner : int\n    packages : List[BillingPackage]\n  }\n\n\n  class BillingPackage {\n  }\n\n}\n\nframe Workspace {\n   class Workspace {\n\n     add_member(member: int)\n\n     account_id: int\n     owner: int\n     members: List[int]\n\n   }\n}\n\nframe Folder {\n\n  class Folder {\n    workspace_id : int\n    children: List[int]\n\n    copy_to(target: int)\n  }\n\n}\n\nDocument o-- DocumentVersion\nAccount o-- BillingPackage\n\n@enduml\n----\nTIP: Bidirectional links are often a sign that your aggregates aren't right.\n    In our original code, a `Document` knew about its containing `Folder`, and the\n    `Folder` had a collection of `Documents`. This makes it easy to traverse the\n    object graph but stops us from thinking properly about the consistency\n    boundaries we need. We break apart aggregates by using references instead.\n    In the new model, a `Document` had reference to its `parent_folder` but had no way\n    to directly access the `Folder`.\n\nIf we needed to _read_ data, we avoided writing complex loops and transforms and\ntried to replace them with straight SQL. For example, one of our screens was a\ntree view of folders and documents.\n\nThis screen was _incredibly_ heavy on the database, because it relied on nested\n`for` loops that triggered a lazy-loaded ORM.\n\nTIP: We use this same technique in <<chapter_12_cqrs>>, where we replace a\n    nested loop over ORM objects with a simple SQL query. It's the first step\n    in a CQRS approach.\n\nAfter a lot of head-scratching, we replaced the ORM code with a big, ugly stored\nprocedure. The code looked horrible, but it was much faster and helped\nto break the links between `Folder` and `Document`.\n\nWhen we needed to _write_ data, we changed a single aggregate at a time, and we\nintroduced a message bus to handle events. For example, in the new model, when\nwe locked an account, we could first query for all the affected workspaces via\npass:[<code>SELECT <em>id</em> FROM <em>workspace</em> WHERE <em>account_id</em> = ?</code>].\n\nWe could then raise a new command for each workspace:\n\n[source,python]\n----\nfor workspace_id in workspaces:\n    bus.handle(LockWorkspace(workspace_id))\n----\n\n\n=== An Event-Driven Approach to Go to Microservices via Strangler Pattern\n\nThe _Strangler Fig_ pattern involves creating a new system around the edges\nof an old system, while keeping it running.(((\"bounded contexts\", \"identifying aggregates and\", startref=\"ix_BCID\")))(((\"aggregates\", \"identifying aggregates and bounded contexts\", startref=\"ix_aggID\"))) Bits of old functionality\nare gradually intercepted and replaced, until the old system is left\ndoing nothing at all and can be switched off.(((\"microservices\", \"event-driven approach, using Strangler pattern\", id=\"ix_mcroevntSp\")))(((\"event-driven architecture\", \"going to microservices via Strangler pattern\", id=\"ix_evntgo\")))\n\nWhen building the availability service, we used a technique called _event\ninterception_ to move functionality from one place to another. This is a three-step\nprocess:\n\n1. Raise events to represent the changes happening in a system you want to\nreplace.\n\n2. Build a second system that consumes those events and uses them to build its\nown domain model.\n\n3. Replace the older system with the new.\n\nWe used event(((\"Strangler pattern, going to microservices via\", id=\"ix_Strang\"))) interception to move from <<strangler_before>>...\n\n[[strangler_before]]\n.Before: strong, bidirectional coupling based on XML-RPC\nimage::images/apwp_ep04.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep04, config=plantuml.cfg]\n@startuml Ecommerce Context\n!include images/C4_Context.puml\n\nLAYOUT_LEFT_RIGHT\nscale 2\n\nPerson_Ext(customer, \"Customer\", \"Wants to buy furniture\")\n\nSystem(fulfillment, \"Fulfillment System\", \"Manages order fulfillment and logistics\")\nSystem(ecom, \"Ecommerce website\", \"Allows customers to buy furniture\")\n\nRel(customer, ecom, \"Uses\")\nRel(fulfillment, ecom, \"Updates stock and orders\", \"xml-rpc\")\nRel(ecom, fulfillment, \"Sends orders\", \"xml-rpc\")\n\n@enduml\n----\n\nto <<strangler_after>>.\n\n[[strangler_after]]\n.After: loose coupling with asynchronous events (you can find a high-resolution version of this diagram at cosmicpython.com)\nimage::images/apwp_ep05.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep05, config=plantuml.cfg]\n@startuml Ecommerce Context\n!include images/C4_Context.puml\n\nLAYOUT_LEFT_RIGHT\nscale 2\n\nPerson_Ext(customer, \"Customer\", \"Wants to buy furniture\")\n\nSystem(av, \"Availability Service\", \"Calculates stock availability\")\nSystem(fulfillment, \"Fulfillment System\", \"Manages order fulfillment and logistics\")\nSystem(ecom, \"Ecommerce website\", \"Allows customers to buy furniture\")\n\nRel(customer, ecom, \"Uses\")\nRel(customer, av, \"Uses\")\nRel(fulfillment, av, \"Publishes batch_created\", \"events\")\nRel(av, ecom, \"Publishes out_of_stock\", \"events\")\nRel(ecom, fulfillment, \"Sends orders\", \"xml-rpc\")\n\n@enduml\n----\n\nPractically, this was a several month-long project. Our first step was to write a\ndomain model that could represent batches, shipments, and products. We used TDD\nto build a toy system that could answer a single question: \"If I want N units of\n[.keep-together]#HAZARDOUS_RUG#, how long will they take to be delivered?\"\n\nTIP: When deploying an event-driven system, start with a \"walking skeleton.\"\n    Deploying a system that just logs its input forces us to tackle all the\n    infrastructural questions and start working in [.keep-together]#production#.\n\n[role=\"nobreakinside less_space\"]\n.Case Study: Carving Out a Microservice to Replace a Domain\n********************************************************************************\nMADE.com started out with _two_ monoliths: one for the frontend ecommerce\napplication, and one for the backend fulfillment system.\n\nThe two systems communicated through XML-RPC. Periodically, the backend system\nwould wake up and query the frontend system to find out about new orders. When\nit had imported all the new orders, it would send RPC commands to update the\nstock levels.\n\nOver time this synchronization process became slower and slower until, one\nChristmas, it took longer than 24 hours to import a single day's orders. Bob was\nhired to break the system into a set of event-driven services.\n\nFirst, we identified that the slowest part of the process was calculating and\nsynchronizing the available stock. What we needed was a system that could listen\nto external events and keep a running total of how much stock was available.\n\nWe exposed that information via an API, so that the user's browser could ask\nhow much stock was available for each product and how long it would take to\ndeliver to their address.\n\nWhenever a product ran out of stock completely, we would raise a new event that\nthe ecommerce platform could use to take a product off sale. Because we didn't\nknow how much load we would need to handle, we wrote the system with a CQRS\npattern. Whenever the amount of stock changed, we would update a Redis database\nwith a cached view model. Our Flask API queried these _view models_ instead of\nrunning the complex domain model.\n\nAs a result, we could answer the question \"How much stock is available?\" in 2\nto 3 milliseconds, and now the API frequently handles hundreds of requests a\nsecond for sustained periods.\n\nIf this all sounds a little familiar, well, now you know where our example app\ncame from!\n********************************************************************************\n\nOnce we had a working domain model, we switched to building out some\ninfrastructural pieces. Our first production deployment was a tiny system that\ncould receive a `batch_created` event and log its JSON representation. This is\nthe \"Hello World\" of event-driven architecture. It forced us to deploy a message\nbus, hook up a producer and consumer, build a deployment pipeline, and write a\nsimple message handler.\n\nGiven a deployment pipeline, the infrastructure we needed, and a basic domain\nmodel, we were off. A couple months later, we were in production and serving\nreal customers.(((\"Strangler pattern, going to microservices via\", startref=\"ix_Strang\")))(((\"microservices\", \"event-driven approach, using Strangler pattern\", startref=\"ix_mcroevntSp\")))(((\"event-driven architecture\", \"going to microservices via Strangler pattern\", startref=\"ix_evntgo\")))\n\n=== Convincing Your Stakeholders to Try Something New\n\nIf you're thinking about carving a new system out of a big ball of mud, you're\nprobably suffering problems with reliability, performance, maintainability, or\nall three simultaneously.(((\"stakeholders, convincing to try something new\", id=\"ix_stkhld\"))) Deep, intractable problems call for drastic measures!\n\nWe recommend _domain modeling_ as a first step. In many overgrown systems, the\nengineers, product owners, and customers no longer speak the same language.\nBusiness stakeholders speak about the system in abstract, process-focused terms,\nwhile developers are forced to speak about the system as it physically exists in\nits wild and chaotic state.\n\n[role=\"nobreakinside less_space\"]\n.Case Study: The User Model\n********************************************************************************\nWe mentioned earlier that the account and user model in our first system were\nbound together by a \"bizarre rule.\" This is a perfect example of how engineering\nand business stakeholders can drift apart.\n\nIn this system, _accounts_ parented _workspaces_, and users were _members_ of\nworkspaces. Workspaces were the fundamental unit for applying permissions and\nquotas. If a user _joined_ a workspace and didn't already have an _account_, we\nwould associate them with the account that owned that workspace.\n\nThis was messy and ad hoc, but it worked fine until the day a product owner\nasked for a new feature:\n\n> When a user joins a company, we want to add them to some default workspaces\n  for the company, like the HR workspace or the Company Announcements workspace.\n\nWe had to explain to them that there was _no such thing_ as a company, and there\nwas no sense in which a user joined an account. Moreover, a \"company\" might have\n_many_ accounts owned by different users, and a new user might be invited to\nany one of them.\n\nYears of adding hacks and work-arounds to a broken model caught up with us, and\nwe had to rewrite the entire user management function as a brand-new system.\n********************************************************************************\n\nFiguring out how to model your domain is a complex task that's the subject of many\ndecent books in its own right. We like to use interactive techniques like event\nstorming and CRC modeling, because humans are good at collaborating through\nplay. _Event modeling_ is another technique that brings engineers and product\nowners together to understand a system in terms of commands, queries, and events.\n\nTIP: Check out _www.eventmodeling.org_ and _www.eventstorming.com_ for some great\nguides to visual modeling of systems with events.\n\nThe goal is to be able to talk about the system by using the same ubiquitous\nlanguage, so that you can agree on where the complexity lies.\n\nWe've found a lot of value in treating domain problems as TDD kata. For example,\nthe first code we wrote for the availability service was the batch and order\nline model. You can treat this as a lunchtime workshop, or as a spike at the\nbeginning of a project. Once you can demonstrate the value of modeling, it's\neasier to make the argument for structuring the project to optimize for modeling.\n\n.Case Study: David Seddon on Taking Small Steps\n*******************************************************************************\n_Hi, I'm David, one of the tech reviewers on this book. I've worked on\nseveral complex Django monoliths, and so I've known the pain that Bob and\nHarry have made all sorts of grand promises about soothing._\n\n_When I was first exposed to the patterns described here, I was rather\nexcited. I had successfully used some of the techniques already on\nsmaller projects, but here was a blueprint for much larger, database-backed\nsystems like the one I work on in my day job. So I started trying to figure\nout how I could implement that blueprint at my current organization._\n\n_I chose to tackle a problem area of the codebase that had always bothered me.\nI began by implementing it as a use case. But I found myself running\ninto unexpected questions. There were things that I hadn't considered\nwhile reading that now made it difficult to see what to do. Was it a\nproblem if my use case interacted with two different aggregates? Could\none use case call another? And how was it going to exist within\na system that followed different architectural principles without resulting\nin a horrible mess?_\n\n_What happened to that oh-so-promising blueprint? Did I actually understand\nthe ideas well enough to put them into practice? Was it even suitable for my\napplication? Even if it was, would any of my colleagues agree to such a\nmajor change? Were these just nice ideas for me to fantasize about while I got\non with real life?_\n\n_It took me a while to realize that I could start small. I didn't\nneed to be a purist or to 'get it right' the first time: I could experiment,\nfinding what worked for me._\n\n_And so that's what I've done. I've been able to apply_ some _of the ideas\nin a few places. I've built new features whose business logic\ncan be tested without the database or mocks. And as a team, we've\nintroduced a service layer to help define the jobs the system does._\n\n_If you start trying to apply these patterns in your work, you may go through\nsimilar feelings to begin with. When the nice theory of a book meets the reality\nof your codebase, it can be demoralizing._\n\n_My advice is to focus on a specific problem and ask yourself how you can\nput the relevant ideas to use, perhaps in an initially limited and imperfect fashion.\nYou may discover, as I did, that the first problem you pick might be a bit too difficult; if so, move on to something else. Don't try to boil the ocean, and don't be_ too\n_afraid of making mistakes. It will be a learning experience, and you can be confident\nthat you're moving roughly in a direction that others have found useful._\n\n_So, if you're feeling the pain too, give these ideas a try. Don't feel you need permission\nto rearchitect everything. Just look for somewhere small to start. And above all, do it\nto solve a specific problem. If you're successful in solving it, you'll know you got something\nright—and others will too._\n*******************************************************************************\n\n\n\n=== Questions Our Tech Reviewers Asked That We Couldn't Work into Prose\n\nHere are some questions we heard during drafting that we couldn't find a good place to address elsewhere in the book:\n\nDo I need to do all of this at once?(((\"stakeholders, convincing to try something new\", startref=\"ix_stkhld\")))(((\"questions from tech reviewers\", id=\"ix_qstTR\"))) Can I just do a bit at a time?::\nNo, you can absolutely adopt these techniques bit by bit. If you have an existing system, we recommend building a service layer to try to keep orchestration in one place. Once you have that, it's much easier to push logic into the model and push edge concerns like validation or error handling to the entrypoints.\n+\nIt's worth having a service layer even if you still have a big, messy Django ORM because it's a way to start understanding the boundaries of operations.\n\nExtracting use cases will break a lot of my existing code; it's too tangled::\nJust copy and paste. It's OK to cause more duplication in the short term. Think of this as a multistep process. Your code is in a bad state now, so copy and paste it to a new place and then make that new code clean and tidy.\n+\nOnce you've done that, you can replace uses of the old code with calls to your new code and finally delete the mess. Fixing large codebases is a messy and painful process. Don't expect things to get instantly better, and don't worry if some bits of your application stay messy.\n\nDo I need to do CQRS? That sounds weird. Can't I just use repositories?::\nOf course you can! The techniques we're presenting in this book are intended to make your life _easier_. They're not some kind of ascetic discipline with which to punish yourself.\n+\nIn the workspace/documents case-study system, we had a lot of _View Builder_ objects that used repositories to fetch data and then performed some transformations to return dumb read models. The advantage is that when you hit a performance problem, it's easy to rewrite a view builder to use custom queries or raw SQL.\n\nHow should use cases interact across a larger system? Is it a problem for one to call another?::\nThis might be an interim step. Again, in the documents case study, we had handlers that would need to invoke other handlers. This gets _really_ messy, though, and it's much better to move to using a message bus to separate these concerns.\n+\nGenerally, your system will have a single message bus implementation and a bunch of subdomains that center on a particular aggregate or set of aggregates. When your use case has finished, it can raise an event, and a handler elsewhere can run.\n\nIs it a code smell for a use case to use multiple repositories/aggregates, and if so, why?::\nAn aggregate is a consistency boundary, so if your use case needs to update two aggregates atomically (within the same transaction), then your consistency boundary is wrong, strictly speaking. Ideally you should think about moving to a new aggregate that wraps up all the things you want to change at the same time.\n+\nIf you're actually updating only one aggregate and using the other(s) for read-only access, then that's _fine_, although you could consider building a read/view model to get you that data instead--it makes things cleaner if each use case has only one aggregate.\n+\nIf you do need to modify two aggregates, but the two operations don't have to be in the same transaction/UoW, then consider splitting the work out into two different handlers and using a domain event to carry information between the two. You can read more in https://oreil.ly/sufKE[these papers on aggregate design] by Vaughn Vernon.\n\nWhat if I have a read-only but business-logic-heavy system?::\nView models can have complex logic in them. In this book, we've encouraged you to separate your read and write models because they have different consistency and throughput requirements. Mostly, we can use simpler logic for reads, but that's not always true. In particular, permissions and authorization models can add a lot of complexity to our read side.\n+\nWe've written systems in which the view models needed extensive unit tests. In those systems, we split a _view builder_ from a _view fetcher_, as in <<view_builder_diagram>>.\n\n[[view_builder_diagram]]\n.A view builder and view fetcher (you can find a high-resolution version of this diagram at cosmicpython.com)\nimage::images/apwp_ep06.png[]\n[role=\"image-source\"]\n----\n[plantuml, apwp_ep06, config=plantuml.cfg]\n@startuml View Fetcher Component Diagram\n!include images/C4_Component.puml\n\nComponentDb(db, \"Database\", \"RDBMS\")\nComponent(fetch, \"View Fetcher\", \"Reads data from db, returning list of tuples or dicts\")\nComponent(build, \"View Builder\", \"Filters and maps tuples\")\nComponent(api, \"API\", \"Handles HTTP and serialization concerns\")\n\nRel(api, build, \"Invokes\")\nRel_R(build, fetch, \"Invokes\")\nRel_D(fetch, db, \"Reads data from\")\n\n@enduml\n----\n+\nThis makes it easy to test the view builder by giving it mocked data (e.g., a list of dicts). \"Fancy CQRS\" with event handlers is really a way of running our complex view logic whenever we write so that we can avoid running it when we read.\n// TODO: move this to the cqrs chapter?\n\nDo I need to build microservices to do this stuff?::\n    Egads, no! These techniques predate microservices by a decade or so. Aggregates,\n    domain events, and dependency inversion are ways to control complexity in large\n    systems. It just so happens that when you've built a set of use cases and a model\n    for a business process, moving it to its own service is relatively easy, but\n    that's not a requirement.\n\nI'm using Django. Can I still do this?::\n    We have an entire appendix just for you: <<appendix_django>>!\n\n[role=\"pagebreak-before less_space\"]\n[[footguns]]\n=== Footguns\n\nOK, so we've given you a whole bunch of new toys to play with. Here's the\nfine print.(((\"questions from tech reviewers\", startref=\"ix_qstTR\"))) Harry and Bob do not recommend that you copy and paste our code into\na production system and rebuild your automated trading platform on Redis\npub/sub. For reasons of brevity and simplicity, we've hand-waved a lot of tricky\nsubjects. Here's a list of things we think you should know before trying this\nfor real.\n\nReliable(((\"messaging\", \"reliable messaging is hard\"))) messaging is hard::\n\nRedis pub/sub is not reliable and shouldn't be used as a general-purpose\nmessaging tool. We picked it because it's familiar and easy to run. At MADE, we\nrun Event Store as our messaging tool, but we've had experience with RabbitMQ and\nAmazon EventBridge.\n+\nTyler Treat has some excellent blog posts on his site _bravenewgeek.com_; you\nshould read at least read https://oreil.ly/pcstD[\"You Cannot Have Exactly-Once Delivery\"]\nand https://oreil.ly/j8bmF[\"What You Want Is What You Don’t: Understanding Trade-Offs in Distributed Messaging\"].\n\nWe explicitly choose small, focused transactions that can fail independently::\n\nIn <<chapter_08_events_and_message_bus>>, we update our process so that _deallocating_ an order line and\n_reallocating_ the line happen in two separate units of work.\nYou will need monitoring to know when these transactions fail, and tooling to\nreplay events. Some of this is made easier by using a transaction log as your\nmessage broker (e.g., Kafka or [.keep-together]#EventStore#). (((\"Outbox pattern\")))You might also look at the\nhttps://oreil.ly/sLfnp[Outbox pattern].\n\nWe don't discuss idempotency::\n\nWe haven't given any real (((\"messaging\", \"idempotent message handling\")))(((\"idempotent message handling\")))thought to what happens when handlers are retried.\nIn practice you will want to make handlers idempotent so that calling them\nrepeatedly with the same message will not make repeated changes to state.\nThis is a key technique for building reliability, because it enables us to\nsafely retry events when they fail.\n\nThere's a lot of good material on idempotent message handling, try starting\nwith https://oreil.ly/yERzR[\"How to Ensure Idempotency in an Eventual Consistent DDD/CQRS Application\"] and https://oreil.ly/Ekuhi[\"(Un)Reliability in Messaging\"].\n\nYour events (((\"events\", \"changing schema over time\")))will need to change their schema over time::\n\nYou'll need to find some way of documenting your events and sharing schema\nwith consumers. We like using JSON schema and markdown because it's simple but\nthere is other prior art. Greg Young wrote an entire book on managing event-driven systems over time: _Versioning in an Event Sourced System_ (Leanpub).\n\n\n// TODO: question or link to further reading about logging and observability\n\n\n=== More Required Reading\n\nA few more books we'd like to(((\"resources, additional required reading\"))) recommend to help you on your way:\n\n* _Clean Architectures in Python_ by Leonardo Giordani (Leanpub), which came out in 2019, is one of the few previous books on application architecture in Python.\n\n* _Enterprise Integration Patterns_ by Gregor Hohpe and Bobby Woolf (Addison-Wesley Professional) is a pretty good start for messaging patterns.\n\n* _Monolith to Microservices_ by Sam Newman (O'Reilly), and Newman's first book,\n  _Building Microservices_ (O'Reilly). The Strangler Fig pattern is mentioned as a\n  favorite, along with many others. These are good to check out if you're thinking of moving to\n  microservices, and they're also good on integration patterns and the considerations\n  of async messaging-based [.keep-together]#integration#.\n\n\n=== Wrap-Up\n\nPhew! That's a lot of warnings and reading suggestions; we hope we\nhaven't scared you off completely. Our goal with this book is to give you\njust enough knowledge and intuition for you to start building some of this\nfor yourself. We would love to hear how you get on and what problems you're\nfacing with the techniques in your own systems, so why not get in touch with us\nover at _www.cosmicpython.com_?\n"
        },
        {
          "name": "fix-branches.py",
          "type": "blob",
          "size": 0.525390625,
          "content": "#!/usr/bin/env python\n\nimport subprocess\nfrom pathlib import Path\nfrom chapters import CHAPTERS\n\nfor chapter in CHAPTERS:\n    subprocess.run(\n        ['git', '-c', 'pager.show=false', 'show', '-s', '--oneline', f':/{chapter}_ends'],\n        cwd=Path(__file__).parent / 'code'\n    )\n    subprocess.run(\n        ['git', 'branch', '-f', chapter, f':/{chapter}_ends'],\n        cwd=Path(__file__).parent / 'code'\n    )\n    subprocess.run(\n        ['git', 'diff', f'origin/{chapter}', chapter],\n        cwd=Path(__file__).parent / 'code'\n    )\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "introduction.asciidoc",
          "type": "blob",
          "size": 12.703125,
          "content": "[[introduction]]\n[preface]\n== Introduction\n\n// TODO (CC): remove \"preface\" marker from this chapter and check if they renumber correctly\n// with this as zero. figures in this chapter should be \"Figure 0-1 etc\"\n\n=== Why Do Our Designs Go Wrong?\n\nWhat comes to mind when you hear the word _chaos?_ Perhaps you think of a noisy\nstock exchange, or your kitchen in the morning--everything confused and\njumbled. When you think of the word _order_, perhaps you think of an empty room,\nserene and calm. For scientists, though, chaos is characterized by homogeneity\n(sameness), and order by complexity (difference).\n\n////\nIDEA [SG] Found previous paragraph a bit confusing.  It seems to suggest that a\nscientist would say that a noisy stock exchange is ordered. I feel like you\nwant to talk about Entropy but do not want to go down that rabbit hole.\n////\n\nFor example, a well-tended garden is a highly ordered system. Gardeners define\nboundaries with paths and fences, and they mark out flower beds or vegetable\npatches. Over time, the garden evolves, growing richer and thicker; but without\ndeliberate effort, the garden will run wild. Weeds and grasses will choke out\nother plants, covering over the paths, until eventually every part looks the\nsame again--wild and unmanaged.\n\nSoftware systems, too, tend toward chaos. When we first start building a new\nsystem, we have grand ideas that our code will be clean and well ordered, but\nover time we find that it gathers cruft and edge cases and ends up a confusing\nmorass of manager classes and util modules. We find that our sensibly layered\narchitecture has collapsed into itself like an oversoggy trifle. Chaotic\nsoftware systems are characterized by a sameness of function: API handlers that\nhave domain knowledge and send email and perform logging; \"business logic\"\nclasses that perform no calculations but do perform I/O; and everything coupled\nto everything else so that changing any part of the system becomes fraught with\ndanger. This is so common that software engineers have their own term for\nchaos: the Big Ball of Mud antipattern (<<bbom_image>>).\n\n[[bbom_image]]\n.A real-life dependency diagram (source: https://oreil.ly/dbGTW[\"Enterprise Dependency: Big Ball of Yarn\"] by Alex Papadimoulis)\nimage::images/apwp_0001.png[]\n\nTIP: A big ball of mud is the natural state of software in the same way that wilderness\n    is the natural state of your garden. It takes energy and direction to\n    prevent the collapse.\n\nFortunately, the techniques to avoid creating a big ball of mud aren't complex.\n\n// IDEA:  talk about how architecture enables TDD and DDD (ie callback to book\n// subtitle)\n\n=== Encapsulation and Abstractions\n\nEncapsulation and abstraction are tools that we all instinctively reach for\nas programmers, even if we don't all use these exact words.  Allow us to dwell\non them for a moment, since they are a recurring background theme of the book.\n\nThe term _encapsulation_ covers two closely related ideas: simplifying\nbehavior and hiding data. In this discussion, we're using the first sense. We\nencapsulate behavior by identifying a task that needs to be done in our code\nand giving that task to a well-defined object or function. We call that object or function an\n_abstraction_.\n\n//DS: not sure I agree with this definition.  more about establishing boundaries?\n\nTake a look at the following two snippets of Python code:\n\n\n[[urllib_example]]\n.Do a search with urllib\n====\n[source,python]\n----\nimport json\nfrom urllib.request import urlopen\nfrom urllib.parse import urlencode\n\nparams = dict(q='Sausages', format='json')\nhandle = urlopen('http://api.duckduckgo.com' + '?' + urlencode(params))\nraw_text = handle.read().decode('utf8')\nparsed = json.loads(raw_text)\n\nresults = parsed['RelatedTopics']\nfor r in results:\n    if 'Text' in r:\n        print(r['FirstURL'] + ' - ' + r['Text'])\n----\n====\n\n[[requests_example]]\n.Do a search with requests\n====\n[source,python]\n----\nimport requests\n\nparams = dict(q='Sausages', format='json')\nparsed = requests.get('http://api.duckduckgo.com/', params=params).json()\n\nresults = parsed['RelatedTopics']\nfor r in results:\n    if 'Text' in r:\n        print(r['FirstURL'] + ' - ' + r['Text'])\n----\n====\n\nBoth code listings do the same thing: they submit form-encoded values\nto a URL in order to use a search engine API. But the second is simpler to read\nand understand because it operates at a higher level of abstraction.\n\nWe can take this one step further still by identifying and naming the task we\nwant the code to perform for us and using an even higher-level abstraction to make\nit explicit:\n\n[[ddg_example]]\n.Do a search with the duckduckgo client library\n====\n[source,python]\n----\nimport duckduckpy\nfor r in duckduckpy.query('Sausages').related_topics:\n    print(r.first_url, ' - ', r.text)\n----\n====\n\nEncapsulating behavior by using abstractions is a powerful tool for making\ncode more expressive, more testable, and easier to maintain.\n\nNOTE: In the literature of the object-oriented (OO) world, one of the classic\n    characterizations of this approach is called\n    http://www.wirfs-brock.com/Design.html[_responsibility-driven design_];\n    it uses the words _roles_ and _responsibilities_ rather than _tasks_.\n    The main point is to think about code in terms of behavior, rather than\n    in terms of data or algorithms.footnote:[If you've come across\n    class-responsibility-collaborator (CRC) cards, they're\n    driving at the same thing: thinking about _responsibilities_ helps you decide how to split things up.]\n\n.Abstractions and ABCs\n*******************************************************************************\nIn a traditional OO language like Java or C#, you might use an abstract base\nclass (ABC) or an interface to define an abstraction. In Python you can (and we\nsometimes do) use ABCs, but you can also happily rely on duck typing.\n\nThe abstraction can just mean \"the public API of the thing you're using\"—a\nfunction name plus some arguments, for example.\n*******************************************************************************\n\nMost of the patterns in this book involve choosing an abstraction, so you'll\nsee plenty of examples in each chapter. In addition,\n<<chapter_03_abstractions>> specifically discusses some general heuristics\nfor choosing abstractions.\n\n\n=== Layering\n\nEncapsulation and abstraction help us by hiding details and protecting the\nconsistency of our data, but we also need to pay attention to the interactions\nbetween our objects and functions. When one function, module, or object uses\nanother, we say that the one _depends on_ the other. These dependencies form a\nkind of network or graph.\n\nIn a big ball of mud, the dependencies are out of control (as you saw in\n<<bbom_image>>). Changing one node of the graph becomes difficult because it\nhas the potential to affect many other parts of the system. Layered\narchitectures are one way of tackling this problem. In a layered architecture,\nwe divide our code into discrete categories or roles, and we introduce rules\nabout which categories of code can call each other.\n\nOne of the most common examples is the _three-layered architecture_ shown in\n<<layered_architecture1>>.\n\n[role=\"width-75\"]\n[[layered_architecture1]]\n.Layered architecture\nimage::images/apwp_0002.png[]\n[role=\"image-source\"]\n----\n[ditaa, apwp_0002]\n+----------------------------------------------------+\n|                Presentation Layer                  |\n+----------------------------------------------------+\n                          |\n                          V\n+----------------------------------------------------+\n|                 Business Logic                     |\n+----------------------------------------------------+\n                          |\n                          V\n+----------------------------------------------------+\n|                  Database Layer                    |\n+----------------------------------------------------+\n----\n\n\nLayered architecture is perhaps the most common pattern for building business\nsoftware. In this model we have user-interface components, which could be a web\npage, an API, or a command line; these user-interface components communicate\nwith a business logic layer that contains our business rules and our workflows;\nand finally, we have a database layer that's responsible for storing and retrieving\ndata.\n\nFor the rest of this book, we're going to be systematically turning this\nmodel inside out by obeying one simple principle.\n\n\n[[dip]]\n=== The Dependency Inversion Principle\n\nYou might be familiar with the _dependency inversion principle_ (DIP) already, because\nit's the _D_ in SOLID.footnote:[SOLID is an acronym for Robert C. Martin's five principles of object-oriented\ndesign: single responsibility, open for extension but\nclosed for modification, Liskov substitution, interface segregation, and\ndependency inversion. See https://oreil.ly/UFM7U[\"S.O.L.I.D: The First 5 Principles of Object-Oriented Design\"] by Samuel Oloruntoba.]\n\nUnfortunately, we can't illustrate the DIP by using three tiny code listings as\nwe did for encapsulation. However, the whole of <<part1>> is essentially a worked\nexample of implementing the DIP throughout an application, so you'll get\nyour fill of concrete examples.\n\nIn the meantime, we can talk about DIP's formal definition:\n\n// [SG] reference?\n\n1.  High-level modules should not depend on low-level modules. Both should\n    depend on abstractions.\n\n2.  Abstractions should not depend on details. Instead, details should depend on\n    abstractions.\n\nBut what does this mean? Let's take it bit by bit.\n\n_High-level modules_ are the code that your organization really cares about.\nPerhaps you work for a pharmaceutical company, and your high-level modules deal\nwith patients and trials. Perhaps you work for a bank, and your high-level\nmodules manage trades and exchanges. The high-level modules of a software\nsystem are the functions, classes, and packages that deal with our real-world\nconcepts.\n\nBy contrast, _low-level modules_ are the code that your organization doesn't\ncare about. It's unlikely that your HR department gets excited about filesystems or network sockets. It's not often that you discuss SMTP, HTTP,\nor AMQP with your finance team. For our nontechnical stakeholders, these\nlow-level concepts aren't interesting or relevant. All they care about is\nwhether the high-level concepts work correctly. If payroll runs on time, your\nbusiness is unlikely to care whether that's a cron job or a transient function\nrunning on Kubernetes.\n\n_Depends on_ doesn't mean _imports_ or _calls_, necessarily, but rather a more\ngeneral idea that one module _knows about_ or _needs_ another module.\n\nAnd we've mentioned _abstractions_ already: they're simplified interfaces that\nencapsulate behavior, in the way that our duckduckgo module encapsulated a\nsearch engine's API.\n\n[quote,David Wheeler]\n____\nAll problems in computer science can be solved by adding another level of\nindirection.\n____\n\nSo the first part of the DIP says that our business code shouldn't depend on\ntechnical details; instead, both should use abstractions.\n\nWhy? Broadly, because we want to be able to change them independently of each\nother. High-level modules should be easy to change in response to business\nneeds. Low-level modules (details) are often, in practice, harder to\nchange: think about refactoring to change a function name versus defining, testing,\nand deploying a database migration to change a column name. We don't\nwant business logic changes to slow down because they are closely coupled\nto low-level infrastructure details. But, similarly, it is important to _be\nable_ to change your infrastructure details when you need to (think about\nsharding a database, for example), without needing to make changes to your\nbusiness layer. Adding an abstraction between them (the famous extra\nlayer of indirection) allows the two to change (more) independently of each\nother.\n\nThe second part is even more mysterious. \"Abstractions should not depend on\ndetails\" seems clear enough, but \"Details should depend on abstractions\" is\nhard to imagine. How can we have an abstraction that doesn't depend on the\ndetails it's abstracting? By the time we get to <<chapter_04_service_layer>>,\nwe'll have a concrete example that should make this all a bit clearer.\n\n\n=== A Place for All Our Business Logic: The Domain Model\n\nBut before we can turn our three-layered architecture inside out, we need to\ntalk more about that middle layer: the high-level modules or business\nlogic. One of the most common reasons that our designs go wrong is that\nbusiness logic becomes spread throughout the layers of our application,\nmaking it hard to identify, understand, and change.\n\n<<chapter_01_domain_model>> shows how to build a business\nlayer with a _Domain Model_ pattern. The rest of the patterns in <<part1>> show\nhow we can keep the domain model easy to change and free of low-level concerns\nby choosing the right abstractions and continuously applying the DIP.\n"
        },
        {
          "name": "ix.html",
          "type": "blob",
          "size": 0.125,
          "content": "<!-- This is a placeholder element for use with the automatic index generation option in Atlas -->\n<section data-type=\"index\"/>\n"
        },
        {
          "name": "license.txt",
          "type": "blob",
          "size": 0.025390625,
          "content": "Creative Commons CC-By-ND\n"
        },
        {
          "name": "maps.drawio",
          "type": "blob",
          "size": 231.59375,
          "content": "<mxfile host=\"app.diagrams.net\" modified=\"2020-09-03T09:50:53.279Z\" agent=\"5.0 (X11)\" etag=\"ig7-Jpxi-697ECmDlB4e\" version=\"13.6.6\" type=\"github\" pages=\"11\">\n  <diagram id=\"rh1DttEXYZF73mCXou3R\" name=\"Chapter 1\">\n    <mxGraphModel dx=\"1162\" dy=\"889\" grid=\"1\" gridSize=\"10\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"827\" pageHeight=\"1169\" math=\"0\" shadow=\"0\">\n      <root>\n        <mxCell id=\"0\" />\n        <mxCell id=\"1\" parent=\"0\" />\n        <mxCell id=\"zBdPd-Kk8-VPhITQOztK-7\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"1\" vertex=\"1\">\n          <mxGeometry x=\"258\" y=\"780\" width=\"310\" height=\"290\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"zBdPd-Kk8-VPhITQOztK-16\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"1\" source=\"zBdPd-Kk8-VPhITQOztK-9\" target=\"zBdPd-Kk8-VPhITQOztK-10\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"zBdPd-Kk8-VPhITQOztK-9\" value=\"Batch\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=22;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"1\" vertex=\"1\">\n          <mxGeometry x=\"458\" y=\"830\" width=\"80\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"zBdPd-Kk8-VPhITQOztK-10\" value=\"Order&lt;br style=&quot;font-size: 20px;&quot;&gt;Line\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"1\" vertex=\"1\">\n          <mxGeometry x=\"458\" y=\"970\" width=\"80\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"zBdPd-Kk8-VPhITQOztK-15\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"1\" source=\"h__-pVFvE90nBYcSnK0_-1\" target=\"zBdPd-Kk8-VPhITQOztK-9\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"408\" y=\"940\" as=\"sourcePoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"h__-pVFvE90nBYcSnK0_-1\" value=\"&lt;div align=&quot;center&quot;&gt;allocate()&lt;/div&gt;\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=22;align=center;\" parent=\"1\" vertex=\"1\">\n          <mxGeometry x=\"278\" y=\"910\" width=\"120\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"PojBqAvhEMXJBaYIurbg-1\" value=\"\" style=\"group\" parent=\"1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"250\" y=\"440\" width=\"310\" height=\"290\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-1\" value=\"Domain Model\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" vertex=\"1\">\n          <mxGeometry width=\"310\" height=\"290\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-3\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=22;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" vertex=\"1\">\n          <mxGeometry x=\"200\" y=\"50\" width=\"80\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-4\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" vertex=\"1\">\n          <mxGeometry x=\"200\" y=\"190\" width=\"80\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-2\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" source=\"mFvZ2es0t092gfShqrqf-3\" target=\"mFvZ2es0t092gfShqrqf-4\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-5\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" source=\"mFvZ2es0t092gfShqrqf-6\" target=\"mFvZ2es0t092gfShqrqf-3\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"150\" y=\"160\" as=\"sourcePoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"mFvZ2es0t092gfShqrqf-6\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=22;align=center;\" parent=\"PojBqAvhEMXJBaYIurbg-1\" vertex=\"1\">\n          <mxGeometry x=\"20\" y=\"130\" width=\"120\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n      </root>\n    </mxGraphModel>\n  </diagram>\n  <diagram id=\"XXAtRvt5FJcVqYL_RqBG\" name=\"Chapter 2\">\n    \n    <mxGraphModel dx=\"2471\" dy=\"1005\" grid=\"1\" gridSize=\"10\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"HixLZq6YcJ24gEQS4keF-0\" />\n        \n        <mxCell id=\"HixLZq6YcJ24gEQS4keF-1\" parent=\"HixLZq6YcJ24gEQS4keF-0\" />\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-7\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=23;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-620\" y=\"270\" width=\"60\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-9\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=19;fontColor=#212A2E;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"5OFkLJhhuf6YR-htXEiZ-0\" target=\"zxIM12oG5ylgCXzGS3_e-7\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-516.5\" y=\"328\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-10\" value=\"Before\" style=\"text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;fontStyle=4\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-680\" y=\"40\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-11\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" edge=\"1\">\n          \n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-480\" y=\"30\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-480\" y=\"370\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"1wh3EijwuCBZbh8hdQBC-0\" value=\"After\" style=\"text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;fontStyle=4\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-460\" y=\"40\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"7aJNSnnAhlagL2kFDV5p-0\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=12;fontColor=#212A2E;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"zxIM12oG5ylgCXzGS3_e-51\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-280\" y=\"169.9655172413793\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-250\" y=\"170\" />\n              \n              <mxPoint x=\"-250\" y=\"170\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-50\" value=\"&lt;font style=&quot;font-size: 22px;&quot; color=&quot;#212A2E&quot;&gt;Repositories&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=22;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-260\" y=\"80\" width=\"260\" height=\"160\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-51\" value=\"&lt;font style=&quot;font-size: 16px;&quot; color=&quot;#212A2E&quot;&gt;Abstract Repository&lt;br style=&quot;font-size: 16px;&quot;&gt;&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=16;fontColor=#212A2E;verticalAlign=top;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-240\" y=\"125\" width=\"70\" height=\"95\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"ztDzs8cEOUfy_udi08FF-7\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=0;orthogonalLoop=1;jettySize=auto;html=1;exitX=0.5;exitY=1;exitDx=0;exitDy=0;fontFamily=Guardian Sans Cond Light;fontSize=19;strokeColor=#0FA3B1;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"zxIM12oG5ylgCXzGS3_e-59\" target=\"mdXzqfrmA79zWNFVQNSs-1\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-82\" y=\"487\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"zxIM12oG5ylgCXzGS3_e-59\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 16px;&quot;&gt;&lt;font style=&quot;font-size: 16px;&quot;&gt;Repository&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=16;fontColor=#212A2E;verticalAlign=top;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-100\" y=\"125\" width=\"80\" height=\"95\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S2fqLNld4azvE4QbebMJ-3\" value=\"implements\" style=\"endArrow=block;dashed=1;endFill=0;endSize=9;html=1;strokeColor=#000000;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=14;fontColor=#212A2E;startSize=4;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0;exitY=0.5;exitDx=0;exitDy=0;labelPosition=center;verticalLabelPosition=top;align=center;verticalAlign=bottom;spacingBottom=5;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"zxIM12oG5ylgCXzGS3_e-59\" target=\"zxIM12oG5ylgCXzGS3_e-51\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-263.2388235294118\" y=\"324.37044117647065\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-395.0035294117647\" y=\"324.37044117647065\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"mdXzqfrmA79zWNFVQNSs-1\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=23;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-90\" y=\"270\" width=\"60\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-0\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-680\" y=\"80\" width=\"180\" height=\"160\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-2\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=22;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-560\" y=\"120\" width=\"40\" height=\"40\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-3\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-560\" y=\"190\" width=\"40\" height=\"40\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-1\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"5OFkLJhhuf6YR-htXEiZ-2\" target=\"5OFkLJhhuf6YR-htXEiZ-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-4\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"5OFkLJhhuf6YR-htXEiZ-5\" target=\"5OFkLJhhuf6YR-htXEiZ-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-603.375\" y=\"171.07999999999993\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"5OFkLJhhuf6YR-htXEiZ-5\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=22;align=center;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-660\" y=\"160\" width=\"60\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-0\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-460\" y=\"80\" width=\"180\" height=\"160\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-1\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=22;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-340\" y=\"120\" width=\"40\" height=\"40\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-2\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-340\" y=\"190\" width=\"40\" height=\"40\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-3\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"HE5UpjC2JdiqaeQOSkUK-1\" target=\"HE5UpjC2JdiqaeQOSkUK-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-4\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" source=\"HE5UpjC2JdiqaeQOSkUK-5\" target=\"HE5UpjC2JdiqaeQOSkUK-1\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-383.375\" y=\"171.07999999999993\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"HE5UpjC2JdiqaeQOSkUK-5\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=22;align=center;\" parent=\"HixLZq6YcJ24gEQS4keF-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-440\" y=\"160\" width=\"60\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram id=\"NHkTZTC70baef07vMxO1\" name=\"Chapter 4\">\n    \n    <mxGraphModel dx=\"636\" dy=\"443\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"UpYtYfSxNZCEmPBrE3a4-0\" />\n        \n        <mxCell id=\"UpYtYfSxNZCEmPBrE3a4-1\" parent=\"UpYtYfSxNZCEmPBrE3a4-0\" />\n        \n        <mxCell id=\"BPTnBf0R8jXtlHTzXCeU-2\" value=\"instantiates\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#f5f5f5;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#4D4D4D;exitX=0.5;exitY=0;exitDx=0;exitDy=0;comic=0;shadow=0;strokeWidth=2;fontStyle=1;endSize=4;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-32\" target=\"BPTnBf0R8jXtlHTzXCeU-0\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.2575\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"1234\" y=\"411\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"889\" y=\"130\" />\n              \n              <mxPoint x=\"1245\" y=\"130\" />\n              \n              <mxPoint x=\"1245\" y=\"415\" />\n              \n            </Array>\n            \n            <mxPoint x=\"1128.73\" y=\"133.75862068965512\" as=\"sourcePoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-13\" value=\"models.allocate()\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;jumpStyle=arc;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontFamily=Guardian Sans Cond Light;strokeColor=#637C89;fillColor=#B5E2FA;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"RP_yprfczkW6Dd-ekdvI-19\" target=\"a_VK5tRrrHFtkJXC6wZM-8\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"220\" y=\"150\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"280\" y=\"180\" />\n              \n              <mxPoint x=\"195\" y=\"180\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-15\" value=\"list/add batches\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;jumpStyle=arc;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontFamily=Guardian Sans Cond Light;strokeColor=#637C89;fillColor=#B5E2FA;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"RP_yprfczkW6Dd-ekdvI-19\" target=\"a_VK5tRrrHFtkJXC6wZM-1\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"441\" y=\"151\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"290\" y=\"180\" />\n              \n              <mxPoint x=\"380\" y=\"180\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"RP_yprfczkW6Dd-ekdvI-19\" value=\"Tests\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"250\" y=\"100\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-12\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"1136.46\" y=\"465\" width=\"47.54\" height=\"45\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-40\" value=\"invoke\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;entryX=0.085;entryY=0.006;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-32\" target=\"-l9xA3Ztxztt4yP418-Y-33\" edge=\"1\">\n          \n          <mxGeometry x=\"0.0031\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"1076\" y=\"80.39\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\" />\n            \n            <mxPoint x=\"890.52\" y=\"240.25\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-32\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#FFB570;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#4D4D4D;strokeWidth=3;comic=0;shadow=0;fontStyle=1\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"860\" y=\"150\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-41\" value=\"invoke\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.321;entryY=0;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-34\" target=\"-l9xA3Ztxztt4yP418-Y-33\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"976\" y=\"239.39\" as=\"targetPoint\" />\n            \n            <Array as=\"points\" />\n            \n            <mxPoint x=\"1114\" y=\"220.39\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-61\" value=\"&lt;div&gt;instantiate&lt;/div&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#f5f5f5;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#4D4D4D;exitX=1;exitY=0.5;exitDx=0;exitDy=0;comic=0;shadow=0;strokeWidth=2;fontStyle=1;endSize=4;startSize=6;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-34\" target=\"-l9xA3Ztxztt4yP418-Y-21\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.539\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"1270\" y=\"419\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"1230\" y=\"180\" />\n              \n              <mxPoint x=\"1230\" y=\"371\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-34\" value=\"Tests\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"946.0000000000001\" y=\"150\" width=\"59.61\" height=\"59.61\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-56\" value=\"retrieves\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;labelPosition=center;verticalLabelPosition=top;align=center;verticalAlign=bottom;spacing=4;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-19\" target=\"9u0jrQUxxR2EQTe6NVSX-1\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"970\" y=\"381.42857142857133\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-8\" value=\"models.allocate()\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;jumpStyle=arc;orthogonalLoop=1;jettySize=auto;html=1;fontSize=10;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;strokeColor=#637C89;fillColor=#B5E2FA;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-33\" target=\"9u0jrQUxxR2EQTe6NVSX-1\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"1045\" y=\"310\" />\n              \n              <mxPoint x=\"920\" y=\"310\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-9\" value=\"list/add batches\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;jumpStyle=arc;orthogonalLoop=1;jettySize=auto;html=1;fontSize=10;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;strokeColor=#637C89;fillColor=#B5E2FA;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"-l9xA3Ztxztt4yP418-Y-33\" target=\"-l9xA3Ztxztt4yP418-Y-19\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"1045\" y=\"310\" />\n              \n              <mxPoint x=\"1130\" y=\"310\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-33\" value=\"&amp;nbsp; Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#0A6A73;fillColor=none;strokeColor=#0FA3B1;fontStyle=0;dashed=1;align=left;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"860\" y=\"245\" width=\"360\" height=\"55\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-31\" value=\"services.allocate()\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#4D4D4D;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;strokeWidth=3;gradientColor=none;comic=0;shadow=0;fontStyle=1\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"921\" y=\"255.82999999999998\" width=\"140\" height=\"34.56\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-35\" value=\"services.add_batch()\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#4D4D4D;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;strokeWidth=3;gradientColor=none;comic=0;shadow=0;fontStyle=1\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"1061\" y=\"255.82999999999998\" width=\"140\" height=\"34.56\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-0\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=1.006;entryY=0.533;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"a_VK5tRrrHFtkJXC6wZM-2\" target=\"a_VK5tRrrHFtkJXC6wZM-8\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"319.7586206896551\" y=\"310.3103448275863\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-3\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;strokeColor=#637C89;fontColor=#212A2E;fillColor=#B5E2FA;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"a_VK5tRrrHFtkJXC6wZM-4\" target=\"a_VK5tRrrHFtkJXC6wZM-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"498\" y=\"617\" as=\"targetPoint\" />\n            \n            <Array as=\"points\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-6\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"383.75\" y=\"360\" width=\"47.5\" height=\"45\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-7\" value=\"\" style=\"group;fontSize=11;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"125\" y=\"200\" width=\"140\" height=\"140\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-8\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" vertex=\"1\">\n          \n          <mxGeometry width=\"140\" height=\"140\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-9\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"84\" y=\"42\" width=\"26\" height=\"26\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-10\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"84\" y=\"91\" width=\"26\" height=\"26\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-11\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" source=\"a_VK5tRrrHFtkJXC6wZM-9\" target=\"a_VK5tRrrHFtkJXC6wZM-10\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-12\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" source=\"a_VK5tRrrHFtkJXC6wZM-13\" target=\"a_VK5tRrrHFtkJXC6wZM-9\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"53.6375\" y=\"77.75599999999994\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"70\" y=\"80\" />\n              \n              <mxPoint x=\"70\" y=\"55\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-13\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;align=center;\" parent=\"a_VK5tRrrHFtkJXC6wZM-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"14\" y=\"70\" width=\"42\" height=\"21\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"04pe3aHLUQfokXrWPP43-0\" value=\"\" style=\"group;fontSize=11;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"860\" y=\"327\" width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-7\" value=\"\" style=\"group;fontSize=11;\" parent=\"04pe3aHLUQfokXrWPP43-0\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-1\" value=\"&lt;font style=&quot;font-size: 11px;&quot;&gt;Domain&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" vertex=\"1\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-2\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"80\" y=\"40\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-3\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"79.99935483870965\" y=\"80.00068965517221\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-4\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;opacity=30;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" source=\"9u0jrQUxxR2EQTe6NVSX-2\" target=\"9u0jrQUxxR2EQTe6NVSX-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-5\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;opacity=30;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" source=\"9u0jrQUxxR2EQTe6NVSX-6\" target=\"9u0jrQUxxR2EQTe6NVSX-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"58.19451612903225\" y=\"72.78689655172411\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"65\" y=\"70\" />\n              \n              <mxPoint x=\"65\" y=\"52\" />\n              \n              <mxPoint x=\"70\" y=\"52\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"9u0jrQUxxR2EQTe6NVSX-6\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;align=center;\" parent=\"9u0jrQUxxR2EQTe6NVSX-7\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.680000000000007\" y=\"60.74000000000001\" width=\"46.45\" height=\"19.26\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-PisfpzhNwJRXZTpOFiz-1\" value=\"\" style=\"group\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"1020\" y=\"327\" width=\"200\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-19\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Repositories&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" vertex=\"1\">\n          \n          <mxGeometry width=\"200\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-20\" value=\"&lt;div style=&quot;font-size: 11px;&quot;&gt;Abstract&lt;/div&gt;&lt;div style=&quot;font-size: 11px;&quot;&gt;Repository&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"14\" y=\"25.592307692307678\" width=\"61\" height=\"79.02307692307693\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-21\" value=\"&lt;div style=&quot;font-size: 11px;&quot;&gt;FakeRepository&lt;/div&gt;&lt;div style=&quot;font-size: 11px;&quot;&gt;(in-memory)&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"92.91000000000008\" y=\"25.269230769230784\" width=\"95.09\" height=\"37.47692307692308\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"P7rxEh7kdZ8RUp2azC3J-2\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" source=\"BPTnBf0R8jXtlHTzXCeU-0\" target=\"-l9xA3Ztxztt4yP418-Y-20\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-409.7704918032787\" y=\"155.82307692307688\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-173.70491803278696\" y=\"155.82307692307688\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"BPTnBf0R8jXtlHTzXCeU-0\" value=\"&lt;div style=&quot;font-size: 11px;&quot;&gt;&lt;font style=&quot;font-size: 11px;&quot;&gt;SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;Repository&lt;/font&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"92.45000000000005\" y=\"70.43846153846152\" width=\"95.55\" height=\"35.06153846153846\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"BPTnBf0R8jXtlHTzXCeU-1\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;jumpStyle=none;\" parent=\"-PisfpzhNwJRXZTpOFiz-1\" source=\"-l9xA3Ztxztt4yP418-Y-21\" target=\"-l9xA3Ztxztt4yP418-Y-20\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"104.91000000000031\" y=\"95.66153846153838\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"76.19000000000005\" y=\"79.88247686431875\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"-l9xA3Ztxztt4yP418-Y-16\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"BPTnBf0R8jXtlHTzXCeU-0\" target=\"-l9xA3Ztxztt4yP418-Y-12\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-1\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Repositories&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"295\" y=\"200\" width=\"150\" height=\"140\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-2\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract Repository&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"305\" y=\"230\" width=\"55\" height=\"90\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-4\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;font style=&quot;font-size: 11px;&quot;&gt;Repository&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"380\" y=\"230\" width=\"55\" height=\"90\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"a_VK5tRrrHFtkJXC6wZM-5\" value=\"&lt;div style=&quot;font-size: 11px;&quot;&gt;&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/div&gt;\" style=\"endArrow=block;dashed=1;endFill=0;endSize=9;html=1;strokeColor=#4D4D4D;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;startSize=4;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0;exitY=0.5;exitDx=0;exitDy=0;labelPosition=center;verticalLabelPosition=top;align=center;verticalAlign=bottom;spacingBottom=5;\" parent=\"UpYtYfSxNZCEmPBrE3a4-1\" source=\"a_VK5tRrrHFtkJXC6wZM-4\" target=\"a_VK5tRrrHFtkJXC6wZM-2\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"252.22764705882355\" y=\"381.0593088235295\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"162.07284829721365\" y=\"381.0593088235295\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram id=\"0DepL2HTkV7kYQrWfHRk\" name=\"Chapter 6\">\n    \n    <mxGraphModel dx=\"2322\" dy=\"643\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"nUsFlo1nsm9BVYnmvNo7-0\" />\n        \n        <mxCell id=\"nUsFlo1nsm9BVYnmvNo7-1\" parent=\"nUsFlo1nsm9BVYnmvNo7-0\" />\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-2\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-632.53\" y=\"350\" width=\"60\" height=\"50\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-3\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-8\" target=\"YE9zQyIwGR_3Ixt6eneR-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-4\" value=\"\" style=\"group;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-689\" y=\"235\" width=\"120\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-5\" value=\"\" style=\"group;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"YE9zQyIwGR_3Ixt6eneR-4\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"120\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-6\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Repositories&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"YE9zQyIwGR_3Ixt6eneR-5\" vertex=\"1\">\n          \n          <mxGeometry width=\"120\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-7\" value=\"Abstract&lt;br&gt;Repo\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;align=center;spacingLeft=-3;\" parent=\"YE9zQyIwGR_3Ixt6eneR-5\" vertex=\"1\">\n          \n          <mxGeometry x=\"12.60983606557377\" y=\"30.660000000000004\" width=\"34.790163934426225\" height=\"49.34000000000001\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-8\" value=\"SQLA Repo\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"YE9zQyIwGR_3Ixt6eneR-5\" vertex=\"1\">\n          \n          <mxGeometry x=\"69.07868852459016\" y=\"30.41\" width=\"34.790163934426225\" height=\"49.59000000000001\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"25ZbK3lhOWnCQbdW3MLe-0\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#4D4D4D;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"YE9zQyIwGR_3Ixt6eneR-5\" source=\"YE9zQyIwGR_3Ixt6eneR-8\" target=\"YE9zQyIwGR_3Ixt6eneR-7\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"185.9016393442623\" y=\"1019.0000000000001\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"28.524590163934427\" y=\"1019.0000000000001\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-5\" value=\"instantiates&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;div style=&quot;font-size: 10px;&quot;&gt;using&lt;/div&gt;&lt;div style=&quot;font-size: 10px;&quot;&gt;session&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;/div&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-17\" target=\"YE9zQyIwGR_3Ixt6eneR-8\" edge=\"1\">\n          \n          <mxGeometry x=\"0.3792\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-743\" y=\"347.5\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-550\" y=\"90\" />\n              \n              <mxPoint x=\"-550\" y=\"290\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-17\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-724\" y=\"60\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-30\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-17\" target=\"YE9zQyIwGR_3Ixt6eneR-24\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-675\" y=\"133.5\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-695\" y=\"130\" />\n              \n              <mxPoint x=\"-695\" y=\"130\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-31\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-24\" target=\"YE9zQyIwGR_3Ixt6eneR-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-695\" y=\"220\" />\n              \n              <mxPoint x=\"-629\" y=\"220\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-32\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-6\" target=\"b2VxIvL2wGN8RlB9VUxO-4\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-713.67\" y=\"299.7857142857142\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-699\" y=\"285\" />\n              \n              <mxPoint x=\"-699\" y=\"285\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-2\" value=\"\" style=\"group;fontSize=11;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-819\" y=\"235\" width=\"103.71\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-3\" value=\"\" style=\"group;fontSize=11;\" parent=\"b2VxIvL2wGN8RlB9VUxO-2\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"103.71\" height=\"99.99999999999999\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-4\" value=\"&lt;font style=&quot;font-size: 11px;&quot;&gt;Domain&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" vertex=\"1\">\n          \n          <mxGeometry width=\"103.71\" height=\"99.99999999999999\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-5\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"69.14\" y=\"33.333333333333336\" width=\"17.439583333333335\" height=\"17.439583333333335\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-6\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"69.13944241935481\" y=\"66.66724137931017\" width=\"17.439583333333335\" height=\"17.439583333333335\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-7\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;opacity=30;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" source=\"b2VxIvL2wGN8RlB9VUxO-5\" target=\"b2VxIvL2wGN8RlB9VUxO-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"80.37525\" y=\"58.333333333333336\" />\n              \n              <mxPoint x=\"80.37525\" y=\"58.333333333333336\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-8\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;opacity=30;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" source=\"b2VxIvL2wGN8RlB9VUxO-9\" target=\"b2VxIvL2wGN8RlB9VUxO-5\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"50.29461056451612\" y=\"60.655747126436765\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"56.17625\" y=\"58.333333333333336\" />\n              \n              <mxPoint x=\"56.17625\" y=\"43.33333333333334\" />\n              \n              <mxPoint x=\"60.497499999999995\" y=\"43.33333333333334\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-9\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;align=center;\" parent=\"b2VxIvL2wGN8RlB9VUxO-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"9.230190000000006\" y=\"50.61666666666667\" width=\"40.1444125\" height=\"16.05\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Npz6ZmYcSbSIKjpBz01J-0\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=left;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-340\" y=\"140\" width=\"350\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-47\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-295.00000000000006\" y=\"60\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"daVeMcFoOoLHTikaCnnO-0\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" edge=\"1\">\n          \n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-420\" y=\"15\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-420\" y=\"585\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-17\" value=\"Unit of Work\" style=\"whiteSpace=wrap;html=1;strokeColor=#F7A072;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;strokeWidth=2;fontStyle=1\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-160\" y=\"150\" width=\"160\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-33\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0;entryY=0;entryDx=28;entryDy=0;entryPerimeter=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-47\" target=\"EUVxdipMBSMducAUXO0g-12\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-42\" y=\"90\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-10\" value=\"instantiates\" style=\"text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=#ffffff;fontSize=11;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;\" parent=\"EUVxdipMBSMducAUXO0g-33\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-0.2949\" y=\"-2\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"5\" y=\"-2\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-11\" value=\"&lt;font style=&quot;font-size: 11px&quot; color=&quot;#212A2E&quot;&gt;Abstract&lt;br&gt; UoW&lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/font&gt;\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;size=4;fontStyle=1;strokeWidth=2;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-150\" y=\"180\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-12\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;size=4;fontStyle=1;strokeWidth=2;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-70.00000000000003\" y=\"180\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-3\" value=\"starts\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;labelPosition=center;verticalLabelPosition=top;align=center;verticalAlign=bottom;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"b2VxIvL2wGN8RlB9VUxO-16\" target=\"EUVxdipMBSMducAUXO0g-17\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-210\" y=\"200\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"25ZbK3lhOWnCQbdW3MLe-1\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"EUVxdipMBSMducAUXO0g-12\" target=\"EUVxdipMBSMducAUXO0g-11\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-22.710000000000036\" y=\"379.5\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-182.71000000000004\" y=\"379.5\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-2\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-47\" target=\"b2VxIvL2wGN8RlB9VUxO-16\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.493\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-265\" y=\"120\" />\n              \n              <mxPoint x=\"-265\" y=\"120\" />\n              \n            </Array>\n            \n            <mxPoint x=\"-325.33333333333326\" y=\"149.5\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-0\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"EUVxdipMBSMducAUXO0g-11\" target=\"EUVxdipMBSMducAUXO0g-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-12\" value=\"provides\" style=\"text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=#ffffff;fontSize=10;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;fontStyle=1\" parent=\"JyHs-vXUNRnrWWTikXPe-0\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"0.0404\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-0.2\" y=\"-10.23\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-1\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"EUVxdipMBSMducAUXO0g-12\" target=\"EUVxdipMBSMducAUXO0g-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-13\" value=\"provides&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;div style=&quot;font-size: 10px;&quot;&gt;(using session)&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;/div&gt;\" style=\"text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=#ffffff;fontSize=10;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;fontStyle=1\" parent=\"JyHs-vXUNRnrWWTikXPe-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"0.0404\" y=\"3\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-3\" y=\"-10.379999999999999\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-24\" value=\"Services\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-760\" y=\"140\" width=\"130\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-25\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-739.9951366873421\" y=\"162.82948275862068\" width=\"80\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-26\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-734\" y=\"168\" width=\"80\" height=\"32\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-16\" value=\"Services\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-330\" y=\"150.33\" width=\"130\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-21\" value=\"initiates&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;div style=&quot;font-size: 10px;&quot;&gt;DB&lt;/div&gt;&lt;div style=&quot;font-size: 10px;&quot;&gt;session&lt;br style=&quot;font-size: 10px;&quot;&gt;&lt;/div&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-17\" target=\"YE9zQyIwGR_3Ixt6eneR-2\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4014\" y=\"-50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-576.1311475409834\" y=\"319.2941176470588\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-520\" y=\"90\" />\n              \n              <mxPoint x=\"-520\" y=\"375\" />\n              \n            </Array>\n            \n            <mxPoint x=\"-655\" y=\"80.47058823529414\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"50\" y=\"50\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"lIBgrl4kTEtkHSdeRE3N-0\" value=\"initiates&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;div style=&quot;font-size: 11px;&quot;&gt;DB&lt;/div&gt;&lt;div style=&quot;font-size: 11px;&quot;&gt;session&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/div&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0;exitDx=60;exitDy=32;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitPerimeter=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"EUVxdipMBSMducAUXO0g-12\" target=\"YE9zQyIwGR_3Ixt6eneR-34\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4806\" y=\"-50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-643.4482758620688\" y=\"429.9655172413793\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"20\" y=\"212\" />\n              \n              <mxPoint x=\"20\" y=\"455\" />\n              \n            </Array>\n            \n            <mxPoint x=\"-735.1724137931035\" y=\"69.9655172413793\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"50\" y=\"50\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-0\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=center;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=middle;verticalAlign=top;spacing=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-290\" y=\"805\" width=\"250\" height=\"85\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-1\" value=\"Part1 Intro\" style=\"text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-410\" y=\"660\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-2\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-254.99\" y=\"730\" width=\"50\" height=\"50\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-3\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-115\" y=\"1065\" width=\"50\" height=\"45\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-4\" value=\"commits changes to\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-27\" target=\"4Rjf6LIX4jAgoCszk2LD-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-5\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" edge=\"1\">\n          \n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-415\" y=\"685\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-415\" y=\"1255\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-10\" value=\"Unit&lt;br style=&quot;font-size: 11px;&quot;&gt;of&lt;br style=&quot;font-size: 11px;&quot;&gt;Work\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-120.00000000000003\" y=\"820\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-11\" value=\"starts\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-32\" target=\"4Rjf6LIX4jAgoCszk2LD-10\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-110\" y=\"880\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-60\" y=\"880\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-13\" value=\"invokes\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-2\" target=\"4Rjf6LIX4jAgoCszk2LD-33\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\" />\n            \n            <mxPoint x=\"-225\" y=\"830\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-14\" value=\"\" style=\"group;fontSize=11;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-290\" y=\"910\" width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-15\" value=\"\" style=\"group;fontSize=11;\" parent=\"4Rjf6LIX4jAgoCszk2LD-14\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-16\" value=\"&lt;font style=&quot;font-size: 11px;&quot;&gt;Domain&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" vertex=\"1\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-17\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" vertex=\"1\">\n          \n          <mxGeometry x=\"80\" y=\"40\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-18\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" vertex=\"1\">\n          \n          <mxGeometry x=\"79.99935483870965\" y=\"80.00068965517221\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-19\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;opacity=30;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" source=\"4Rjf6LIX4jAgoCszk2LD-17\" target=\"4Rjf6LIX4jAgoCszk2LD-18\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-20\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;opacity=30;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" source=\"4Rjf6LIX4jAgoCszk2LD-21\" target=\"4Rjf6LIX4jAgoCszk2LD-17\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"58.19451612903225\" y=\"72.78689655172411\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"65\" y=\"70\" />\n              \n              <mxPoint x=\"65\" y=\"52\" />\n              \n              <mxPoint x=\"70\" y=\"52\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-21\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;align=center;\" parent=\"4Rjf6LIX4jAgoCszk2LD-15\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.680000000000007\" y=\"60.74000000000001\" width=\"46.45\" height=\"19.26\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-22\" value=\"Adapters\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;labelPosition=center;verticalLabelPosition=middle;align=center;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-130\" y=\"910\" width=\"80\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-23\" value=\"loads&lt;br style=&quot;font-size: 11px;&quot;&gt;and&lt;br style=&quot;font-size: 11px;&quot;&gt;saves\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-22\" target=\"4Rjf6LIX4jAgoCszk2LD-16\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-278.3766666666668\" y=\"987.5\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-27\" value=\"Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"-120.00000000000011\" y=\"940\" width=\"60\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-29\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-10\" target=\"4Rjf6LIX4jAgoCszk2LD-27\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-20\" y=\"850\" />\n              \n              <mxPoint x=\"-20\" y=\"979.9999999999998\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-30\" value=\"provides\" style=\"text;html=1;align=center;verticalAlign=middle;resizable=0;points=[];labelBackgroundColor=#ffffff;fontSize=11;fontFamily=Guardian Sans Cond Light;fontColor=#212A2E;\" parent=\"4Rjf6LIX4jAgoCszk2LD-29\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"0.0404\" y=\"3\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-3\" y=\"-18.97\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-39\" value=\"\" style=\"group;fontSize=11;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-269.9927107741788\" y=\"829.9994827586206\" width=\"85.00757408683671\" height=\"35\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-32\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"4Rjf6LIX4jAgoCszk2LD-39\" vertex=\"1\">\n          \n          <mxGeometry x=\"5.007574086836712\" y=\"5\" width=\"80\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-33\" value=\"Services\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"4Rjf6LIX4jAgoCszk2LD-39\" vertex=\"1\">\n          \n          <mxGeometry width=\"80\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"4Rjf6LIX4jAgoCszk2LD-40\" value=\"call methods on\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"4Rjf6LIX4jAgoCszk2LD-33\" target=\"4Rjf6LIX4jAgoCszk2LD-16\" edge=\"1\">\n          \n          <mxGeometry x=\"0.0682\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-182.98513668734222\" y=\"859.9994827586206\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-120\" y=\"859.9655172413793\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-310\" y=\"845\" />\n              \n              <mxPoint x=\"-310\" y=\"970\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"vBc2tfGl8ayYcUVUtxe9-1\" value=\"\" style=\"group\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-307.4951366873421\" y=\"189.99948275862064\" width=\"84.99242591316329\" height=\"35\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-17\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vBc2tfGl8ayYcUVUtxe9-1\" vertex=\"1\">\n          \n          <mxGeometry width=\"80\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"b2VxIvL2wGN8RlB9VUxO-18\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vBc2tfGl8ayYcUVUtxe9-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"4.992425913163288\" y=\"5\" width=\"80\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"vBc2tfGl8ayYcUVUtxe9-4\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#637C89;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" source=\"YE9zQyIwGR_3Ixt6eneR-24\" target=\"b2VxIvL2wGN8RlB9VUxO-4\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"-684.7142857142858\" y=\"220\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"-620.1428571428571\" y=\"260\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"-695\" y=\"220\" />\n              \n              <mxPoint x=\"-767\" y=\"220\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"E3GeCynq779SW5F_JsYj-0\" value=\"\" style=\"group\" parent=\"nUsFlo1nsm9BVYnmvNo7-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"-320\" y=\"290\" width=\"320\" height=\"190\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"YE9zQyIwGR_3Ixt6eneR-34\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"E3GeCynq779SW5F_JsYj-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"250\" y=\"140\" width=\"60\" height=\"50\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"9SGnhpPdjHvkXC_miKsE-12\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"E3GeCynq779SW5F_JsYj-0\" source=\"EUVxdipMBSMducAUXO0g-3\" target=\"YE9zQyIwGR_3Ixt6eneR-34\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-0\" value=\"\" style=\"group;fontSize=11;\" parent=\"E3GeCynq779SW5F_JsYj-0\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-1\" value=\"\" style=\"group;fontSize=11;\" parent=\"1o4Fw3Xs44IrNluRRBo2-0\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-2\" value=\"&lt;font style=&quot;font-size: 11px;&quot;&gt;Domain&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" vertex=\"1\">\n          \n          <mxGeometry width=\"120\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-3\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"80\" y=\"40\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-4\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"79.99935483870965\" y=\"80.00068965517221\" width=\"25\" height=\"25\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-5\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;opacity=30;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" source=\"1o4Fw3Xs44IrNluRRBo2-3\" target=\"1o4Fw3Xs44IrNluRRBo2-4\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n              <mxPoint x=\"93\" y=\"70\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-6\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=11;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;opacity=30;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" source=\"1o4Fw3Xs44IrNluRRBo2-7\" target=\"1o4Fw3Xs44IrNluRRBo2-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"58.19451612903225\" y=\"72.78689655172411\" as=\"sourcePoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"65\" y=\"70\" />\n              \n              <mxPoint x=\"65\" y=\"52\" />\n              \n              <mxPoint x=\"70\" y=\"52\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"1o4Fw3Xs44IrNluRRBo2-7\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;align=center;\" parent=\"1o4Fw3Xs44IrNluRRBo2-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.680000000000007\" y=\"60.74000000000001\" width=\"46.45\" height=\"19.26\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-36\" value=\"Repositories\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"E3GeCynq779SW5F_JsYj-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"160\" width=\"160\" height=\"120\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JyHs-vXUNRnrWWTikXPe-15\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"E3GeCynq779SW5F_JsYj-0\" source=\"EUVxdipMBSMducAUXO0g-36\" target=\"1o4Fw3Xs44IrNluRRBo2-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"21.62333333333322\" y=\"73\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-2\" value=\"&lt;font style=&quot;font-size: 11px&quot; color=&quot;#212A2E&quot;&gt;Abstract&lt;br&gt;Repo&lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"E3GeCynq779SW5F_JsYj-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"174.5\" y=\"38.5\" width=\"51\" height=\"61.5\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"EUVxdipMBSMducAUXO0g-3\" value=\"SQLA&lt;br style=&quot;font-size: 11px&quot;&gt;Repo\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"E3GeCynq779SW5F_JsYj-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"255\" y=\"38.5\" width=\"50\" height=\"61.5\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"25ZbK3lhOWnCQbdW3MLe-2\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"E3GeCynq779SW5F_JsYj-0\" source=\"EUVxdipMBSMducAUXO0g-3\" target=\"EUVxdipMBSMducAUXO0g-2\" edge=\"1\">\n          \n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"307.28999999999996\" y=\"79.5\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"147.28999999999996\" y=\"79.5\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram id=\"B_H1QxJmg6XYiveXFFql\" name=\"Chapter 7\">\n    \n    <mxGraphModel dx=\"922\" dy=\"643\" grid=\"1\" gridSize=\"10\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"lytoSjqqHvJSaw2xdrzU-0\" />\n        \n        <mxCell id=\"lytoSjqqHvJSaw2xdrzU-1\" parent=\"lytoSjqqHvJSaw2xdrzU-0\" />\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-6\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"376\" y=\"59\" width=\"310\" height=\"290\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-26\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;jumpStyle=none;orthogonalLoop=1;jettySize=auto;html=1;startSize=2;endSize=2;strokeColor=#F7A072;strokeWidth=1;fontFamily=Guardian Sans Cond Light;fontSize=20;fontColor=#F7A072;entryX=0;entryY=0;entryDx=0;entryDy=29;entryPerimeter=0;endArrow=none;endFill=0;exitX=1;exitY=0.25;exitDx=0;exitDy=0;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" source=\"PuWUXAxEQKP4EjMZsGJo-12\" target=\"PuWUXAxEQKP4EjMZsGJo-23\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"642\" y=\"219\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"572\" y=\"161\" />\n              \n              <mxPoint x=\"572\" y=\"130\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-12\" value=\"&lt;font color=&quot;#D98C64&quot;&gt;Product&lt;/font&gt;\" style=\"rounded=0;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=30;fontColor=#F7A072;align=center;strokeColor=#F7A072;strokeWidth=2;fillColor=#EDDEA4;verticalAlign=top;fontStyle=1\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"402\" y=\"104\" width=\"160\" height=\"230\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-0\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=25;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"22\" y=\"59\" width=\"310\" height=\"290\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-1\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" source=\"PuWUXAxEQKP4EjMZsGJo-2\" target=\"PuWUXAxEQKP4EjMZsGJo-3\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-2\" value=\"Batch\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=22;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"222\" y=\"109\" width=\"80\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-3\" value=\"Order&lt;br style=&quot;font-size: 20px;&quot;&gt;Line\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"222\" y=\"249\" width=\"80\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-4\" style=\"edgeStyle=orthogonalEdgeStyle;rounded=1;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" source=\"PuWUXAxEQKP4EjMZsGJo-5\" target=\"PuWUXAxEQKP4EjMZsGJo-2\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"172\" y=\"219\" as=\"sourcePoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-5\" value=\"&lt;div align=&quot;center&quot;&gt;allocate()&lt;/div&gt;\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=22;align=center;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"42\" y=\"189\" width=\"120\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-7\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;fontSize=14;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" source=\"PuWUXAxEQKP4EjMZsGJo-8\" target=\"PuWUXAxEQKP4EjMZsGJo-9\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-8\" value=\"Batch\" style=\"verticalLabelPosition=middle;verticalAlign=middle;html=1;shape=mxgraph.basic.layered_rect;dx=10;outlineConnect=0;fontFamily=Guardian Sans Cond Light;fontSize=22;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;labelPosition=center;spacingTop=-8;spacingLeft=-8;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"452\" y=\"164\" width=\"70\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-14\" value=\"Order&lt;br style=&quot;font-size: 20px;&quot;&gt;Line\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"465\" y=\"258\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-13\" value=\"Order&lt;br style=&quot;font-size: 20px;&quot;&gt;Line\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=20;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"461\" y=\"256\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-9\" value=\"Order&lt;br style=&quot;font-size: 18px;&quot;&gt;Line\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=18;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"457\" y=\"254\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"PuWUXAxEQKP4EjMZsGJo-23\" value=\"&lt;font style=&quot;font-size: 22px&quot; color=&quot;#BF8854&quot;&gt;&amp;nbsp; .allocate()&lt;/font&gt;\" style=\"shape=card;whiteSpace=wrap;html=1;strokeColor=#F7A072;strokeWidth=2;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=20;fontColor=#F7A072;align=center;fontStyle=1;size=18;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"584\" y=\"101\" width=\"92\" height=\"40\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"O-k6SUBsuVml4iaGN-jd-0\" value=\"After\" style=\"text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"376\" y=\"14\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"O-k6SUBsuVml4iaGN-jd-1\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" edge=\"1\">\n          \n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"354\" y=\"13\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"354\" y=\"350\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"O-k6SUBsuVml4iaGN-jd-2\" value=\"Before\" style=\"text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=21;fontColor=#212A2E;\" parent=\"lytoSjqqHvJSaw2xdrzU-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"22\" y=\"14\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram name=\"Chapter 8\" id=\"L-P2wqAZu0Zu91C36x05\">\n    \n    <mxGraphModel dx=\"922\" dy=\"643\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-0\" />\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-1\" parent=\"Nc6DFpJYmUFn6ACu5-4V-0\" />\n        \n        <mxCell id=\"DZ7-ml7TBhKowF8taHoj-0\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=center;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"100\" y=\"165\" width=\"480\" height=\"115\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-55\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-57\" target=\"Nc6DFpJYmUFn6ACu5-4V-65\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"165\" y=\"150\" />\n              \n              <mxPoint x=\"165\" y=\"150\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-57\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"135.38\" y=\"90\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-71\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-73\" target=\"Nc6DFpJYmUFn6ACu5-4V-80\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"355\" y=\"270.3333333333335\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"355\" y=\"331.16666666666674\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-73\" value=\"UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"241.00000000000003\" y=\"185\" width=\"58.03\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-77\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-65\" target=\"Nc6DFpJYmUFn6ACu5-4V-73\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"389.5\" y=\"224.5\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"iiICZdAtx7DTPgSnzauY-0\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;size=12;fontStyle=1;strokeWidth=2;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"320\" y=\"200\" width=\"120\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-80\" value=\"Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"246.77\" y=\"324.35\" width=\"46.49\" height=\"69.31\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HDthxvwAoOGIVFgRJNFE-1\" value=\"gathers events &lt;i style=&quot;font-size: 10px;&quot;&gt;raised&lt;/i&gt; by\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.25;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontStyle=1\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-73\" target=\"Nc6DFpJYmUFn6ACu5-4V-60\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.0241\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"324\" y=\"270.3333333333335\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"309.5\" y=\"234\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"256\" y=\"270\" />\n              \n              <mxPoint x=\"165\" y=\"270\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"ix8nWJD7wFOkQagX4VAm-0\" value=\"&lt;i style=&quot;font-size: 10px;&quot;&gt;publishes&lt;/i&gt; events to\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.75;exitY=1;exitDx=0;exitDy=0;entryX=0.25;entryY=1;entryDx=0;entryDy=0;fontStyle=1\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-73\" target=\"iiICZdAtx7DTPgSnzauY-0\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.0699\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"489\" y=\"224.5\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"268.8571428571429\" y=\"340.57142857142867\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"311\" y=\"270\" />\n              \n              <mxPoint x=\"382\" y=\"270\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"ix8nWJD7wFOkQagX4VAm-1\" value=\"&lt;i style=&quot;font-size: 10px;&quot;&gt;dispatches&lt;/i&gt; events to\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.75;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=1;entryDx=0;entryDy=0;fontStyle=1\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"iiICZdAtx7DTPgSnzauY-0\" target=\"6HcHZ9vkeMjbQZMDwgwn-0\" edge=\"1\">\n          \n          <mxGeometry x=\"0.0261\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"462.57142857142867\" y=\"275.42857142857133\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"599.1428571428571\" y=\"249.25\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"469\" y=\"270\" />\n              \n              <mxPoint x=\"574\" y=\"270\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"ix8nWJD7wFOkQagX4VAm-2\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"Nc6DFpJYmUFn6ACu5-4V-80\" target=\"Nc6DFpJYmUFn6ACu5-4V-60\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"270.58\" y=\"329.77500000000003\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"338.8432773109242\" y=\"201.18\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"yjK-U6Wi6Gt-xlNV5-W3-0\" value=\"\" style=\"group\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"110.38\" y=\"175\" width=\"110\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-65\" value=\"Services\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;spacing=0;\" parent=\"yjK-U6Wi6Gt-xlNV5-W3-0\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"oVYR6Bsm4YZrAXi3Ddg5-0\" value=\"\" style=\"group;fontSize=11;\" parent=\"yjK-U6Wi6Gt-xlNV5-W3-0\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"9.61999999999999\" y=\"34.999999999999886\" width=\"81.99000000000001\" height=\"36.000000000000114\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-66\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"oVYR6Bsm4YZrAXi3Ddg5-0\" vertex=\"1\">\n          \n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-67\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"oVYR6Bsm4YZrAXi3Ddg5-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"6.990000000000009\" y=\"6.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"yjK-U6Wi6Gt-xlNV5-W3-1\" value=\"\" style=\"group;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"460\" y=\"175\" width=\"110\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"6HcHZ9vkeMjbQZMDwgwn-0\" value=\"&lt;b&gt;Handlers&lt;/b&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;spacing=0;\" parent=\"yjK-U6Wi6Gt-xlNV5-W3-1\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"NKW4gHjV3Hl7r7o7QqEC-0\" value=\"send_mail()\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#F7A072;fillColor=#EDDEA4;strokeWidth=2;\" parent=\"yjK-U6Wi6Gt-xlNV5-W3-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"11\" y=\"31.5\" width=\"81.5\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Gptz2AKrtb2Eq5BlA5h--1\" value=\"\" style=\"group\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"100\" y=\"300\" width=\"130\" height=\"118\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-60\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"Gptz2AKrtb2Eq5BlA5h--1\" vertex=\"1\">\n          \n          <mxGeometry width=\"130\" height=\"118\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-61\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"Gptz2AKrtb2Eq5BlA5h--1\" vertex=\"1\">\n          \n          <mxGeometry x=\"45.47806060606058\" y=\"25.31333657209484\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-62\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"Gptz2AKrtb2Eq5BlA5h--1\" vertex=\"1\">\n          \n          <mxGeometry x=\"45.47806060606058\" y=\"74.50105518849591\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Nc6DFpJYmUFn6ACu5-4V-63\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"Gptz2AKrtb2Eq5BlA5h--1\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.47999999999999\" y=\"54.67000000000007\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"HDthxvwAoOGIVFgRJNFE-0\" value=\"&lt;div style=&quot;font-size: 10px&quot;&gt;Event:&lt;br&gt;OutOf&lt;/div&gt;&lt;div style=&quot;font-size: 10px&quot;&gt;Stock&lt;br style=&quot;font-size: 10px&quot;&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#F7A072;fillColor=#EDDEA4;fontFamily=Guardian Sans Cond Light;fontSize=10;spacing=0;fontStyle=1;strokeWidth=2;\" parent=\"Gptz2AKrtb2Eq5BlA5h--1\" vertex=\"1\">\n          \n          <mxGeometry x=\"75.99999999999997\" y=\"34.410000000000025\" width=\"40\" height=\"49.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-0\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=center;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"100\" y=\"605\" width=\"480\" height=\"115\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-1\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-2\" target=\"XM8dzTfvOR4BL4CSTwjc-13\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"165\" y=\"590\" />\n              \n              <mxPoint x=\"165\" y=\"590\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-2\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"135.38\" y=\"530\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-3\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-4\" target=\"XM8dzTfvOR4BL4CSTwjc-7\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"355\" y=\"710.3333333333335\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"355\" y=\"771.1666666666667\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-4\" value=\"UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"241.00000000000003\" y=\"625\" width=\"58.03\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-5\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-13\" target=\"XM8dzTfvOR4BL4CSTwjc-4\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"389.5\" y=\"664.5\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-6\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"320\" y=\"640\" width=\"120\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-7\" value=\"Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"246.77\" y=\"764.35\" width=\"46.49\" height=\"69.31\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-8\" value=\"&amp;nbsp;gathers events &lt;span style=&quot;font-size: 10px&quot;&gt;raised&lt;/span&gt; by&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.25;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;fontStyle=0;spacingLeft=0;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-4\" target=\"XM8dzTfvOR4BL4CSTwjc-21\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.0241\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"324\" y=\"710.3333333333335\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"309.5\" y=\"674\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"256\" y=\"710\" />\n              \n              <mxPoint x=\"165\" y=\"710\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-9\" value=\"&amp;nbsp;&lt;span style=&quot;font-size: 10px&quot;&gt;publishes&lt;/span&gt; events to \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.75;exitY=1;exitDx=0;exitDy=0;entryX=0.25;entryY=1;entryDx=0;entryDy=0;fontStyle=0;spacingLeft=0;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-4\" target=\"XM8dzTfvOR4BL4CSTwjc-6\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.0699\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"489\" y=\"664.5\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"268.8571428571429\" y=\"780.5714285714287\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"311\" y=\"710\" />\n              \n              <mxPoint x=\"382\" y=\"710\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-10\" value=\"&amp;nbsp;&lt;span style=&quot;font-size: 10px&quot;&gt;dispatches&lt;/span&gt; events to&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.75;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=1;entryDx=0;entryDy=0;fontStyle=0;spacingLeft=0;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-6\" target=\"XM8dzTfvOR4BL4CSTwjc-18\" edge=\"1\">\n          \n          <mxGeometry x=\"0.0261\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"462.57142857142867\" y=\"715.4285714285713\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"599.1428571428571\" y=\"689.25\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"469\" y=\"710\" />\n              \n              <mxPoint x=\"574\" y=\"710\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-11\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" source=\"XM8dzTfvOR4BL4CSTwjc-7\" target=\"XM8dzTfvOR4BL4CSTwjc-21\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"270.58\" y=\"769.7750000000001\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"338.8432773109242\" y=\"641.1800000000001\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-12\" value=\"\" style=\"group;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"110.38\" y=\"615\" width=\"110\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-13\" value=\"Services\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;spacing=0;\" parent=\"XM8dzTfvOR4BL4CSTwjc-12\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"80\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-14\" value=\"\" style=\"group;fontSize=11;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-12\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"9.61999999999999\" y=\"34.999999999999886\" width=\"81.99000000000001\" height=\"36.000000000000114\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-15\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-14\" vertex=\"1\">\n          \n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-16\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-14\" vertex=\"1\">\n          \n          <mxGeometry x=\"6.990000000000009\" y=\"6.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-17\" value=\"\" style=\"group;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"460\" y=\"615\" width=\"110\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-18\" value=\"&lt;span&gt;Handlers&lt;/span&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;spacing=0;\" parent=\"XM8dzTfvOR4BL4CSTwjc-17\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-19\" value=\"send_mail()\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-17\" vertex=\"1\">\n          \n          <mxGeometry x=\"11\" y=\"31.5\" width=\"81.5\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-20\" value=\"\" style=\"group;fontStyle=0\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"100\" y=\"740\" width=\"130\" height=\"118\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-21\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-20\" vertex=\"1\">\n          \n          <mxGeometry width=\"130\" height=\"118\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-22\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-20\" vertex=\"1\">\n          \n          <mxGeometry x=\"45.47806060606058\" y=\"25.31333657209484\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-23\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-20\" vertex=\"1\">\n          \n          <mxGeometry x=\"45.47806060606058\" y=\"74.50105518849591\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-24\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-20\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.47999999999999\" y=\"54.67000000000007\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"XM8dzTfvOR4BL4CSTwjc-25\" value=\"&lt;div style=&quot;font-size: 10px&quot;&gt;Event:&lt;br&gt;OutOf&lt;/div&gt;&lt;div style=&quot;font-size: 10px&quot;&gt;Stock&lt;br style=&quot;font-size: 10px&quot;&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;spacing=0;fontStyle=0\" parent=\"XM8dzTfvOR4BL4CSTwjc-20\" vertex=\"1\">\n          \n          <mxGeometry x=\"75.99999999999997\" y=\"34.410000000000025\" width=\"40\" height=\"49.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"1ooD107NSidTd8ryLyCG-0\" value=\"before diag. for next chapter\" style=\"text;html=1;strokeColor=none;fillColor=none;align=left;verticalAlign=middle;whiteSpace=wrap;rounded=0;fontFamily=Guardian Sans Cond Light;fontSize=14;fontColor=#212A2E;\" parent=\"Nc6DFpJYmUFn6ACu5-4V-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"620\" y=\"515\" width=\"62\" height=\"20\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram name=\"Chapter 9\" id=\"H_mJgoZ9N4nEhYIzojLd\">\n    \n    <mxGraphModel dx=\"922\" dy=\"643\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-0\" />\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-1\" parent=\"Uq7KBppAUjZHveFYqXgI-0\" />\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-2\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=right;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;spacingRight=13;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"180\" y=\"170\" width=\"415\" height=\"130\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-3\" value=\"puts events on\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;entryX=0.5;entryY=0;entryDx=0;entryDy=0;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;exitX=0.5;exitY=1;exitDx=0;exitDy=0;fontStyle=1\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-4\" target=\"Uq7KBppAUjZHveFYqXgI-7\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4324\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"250\" y=\"160\" />\n              \n              <mxPoint x=\"250\" y=\"160\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-4\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"225\" y=\"90\" width=\"50\" height=\"50\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-5\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-6\" target=\"Uq7KBppAUjZHveFYqXgI-8\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"419.53\" y=\"250.33333333333348\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"419.53\" y=\"311.16666666666674\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-6\" value=\"UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"530.0032773109242\" y=\"203.35999999999999\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-7\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#FFB570;fillColor=#EDDEA4;size=12;fontStyle=1;strokeWidth=2;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"190\" y=\"195.71\" width=\"120\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-8\" value=\"Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"531.97\" y=\"333.89\" width=\"49.99\" height=\"71.41\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-9\" value=\"&amp;nbsp;gathers events raised by&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.25;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-6\" target=\"Uq7KBppAUjZHveFYqXgI-19\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.0818\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"408.53\" y=\"250.33333333333348\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"394.03\" y=\"214\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"544\" y=\"285\" />\n              \n              <mxPoint x=\"445\" y=\"285\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-10\" value=\"&amp;nbsp;collects new events published by&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;entryX=0;entryY=0;entryDx=24.962184873949578;entryDy=0;entryPerimeter=0;exitX=0.75;exitY=0;exitDx=0;exitDy=0;fontStyle=1\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-7\" target=\"Uq7KBppAUjZHveFYqXgI-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"190\" y=\"209.71\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"500\" y=\"234.20999999999998\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"280\" y=\"180\" />\n              \n              <mxPoint x=\"575\" y=\"180\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-11\" value=\"&amp;nbsp;dispatches to&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;fontStyle=1\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-7\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.2366\" relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"558.5714285714287\" y=\"286.1385714285713\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"340\" y=\"240\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"250\" y=\"240\" />\n              \n              <mxPoint x=\"340\" y=\"240\" />\n              \n            </Array>\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-12\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-8\" target=\"Uq7KBppAUjZHveFYqXgI-19\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"346.4799999999998\" y=\"182\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"422.81327731092415\" y=\"182\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"EgZufLnB_ExG12F1RHKp-1\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0.006;entryY=0.561;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" source=\"Uq7KBppAUjZHveFYqXgI-14\" target=\"Uq7KBppAUjZHveFYqXgI-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"140.1034482758621\" y=\"234.84793103448277\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"249.75862068965512\" y=\"239.67551724137928\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"500\" y=\"237\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"ttgzpsNNgfyGXRUKz9As-4\" value=\"\" style=\"group;fontSize=11;\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"340\" y=\"195.70999999999998\" width=\"160\" height=\"75.28999999999999\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-14\" value=\"&lt;b&gt;Handlers (includes old services)&lt;/b&gt;\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#F7A072;fontStyle=0;dashed=1;strokeWidth=2;\" parent=\"ttgzpsNNgfyGXRUKz9As-4\" vertex=\"1\">\n          \n          <mxGeometry width=\"160\" height=\"75.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"ttgzpsNNgfyGXRUKz9As-2\" value=\"\" style=\"group;fontSize=11;\" parent=\"ttgzpsNNgfyGXRUKz9As-4\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"37.589999999999975\" y=\"29.999999999999886\" width=\"84.43\" height=\"38.5\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"ttgzpsNNgfyGXRUKz9As-1\" value=\"\" style=\"group;fontSize=11;\" parent=\"ttgzpsNNgfyGXRUKz9As-2\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"84.43\" height=\"38.5\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-15\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"ttgzpsNNgfyGXRUKz9As-1\" vertex=\"1\">\n          \n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-16\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"ttgzpsNNgfyGXRUKz9As-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"5\" y=\"4.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-17\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"ttgzpsNNgfyGXRUKz9As-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"9.430000000000007\" y=\"8.5\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"sb_50-6ps7YPiXrUNgo6-3\" value=\"\" style=\"group\" parent=\"Uq7KBppAUjZHveFYqXgI-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"390\" y=\"319.59\" width=\"110\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-19\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"100\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-20\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"37.71806060606065\" y=\"23.703336572094884\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-21\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"45.908060606060644\" y=\"68.05105518849592\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-22\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"10.909999999999968\" y=\"50.760000000000105\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"Uq7KBppAUjZHveFYqXgI-23\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"68.62\" y=\"30.410000000000025\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"sb_50-6ps7YPiXrUNgo6-0\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"sb_50-6ps7YPiXrUNgo6-3\" vertex=\"1\">\n          \n          <mxGeometry x=\"74.62\" y=\"37.40000000000003\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram name=\"Chapter 11\" id=\"uloHF3oTohPtsYz8bfXU\">\n    \n    <mxGraphModel dx=\"922\" dy=\"643\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"827\" pageHeight=\"1169\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-0\" />\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-1\" parent=\"glnVcpvA8bHsyrLV4RX5-0\" />\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-2\" value=\"Allocation Service\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=center;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"155\" y=\"330\" width=\"505\" height=\"240\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-3\" value=\"commands\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0.5;entryY=1;entryDx=0;entryDy=0;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"glnVcpvA8bHsyrLV4RX5-4\" target=\"glnVcpvA8bHsyrLV4RX5-7\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4768\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"305\" y=\"490\" />\n              \n            </Array>\n            \n            <mxPoint x=\"302\" y=\"350\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-4\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"165\" y=\"460\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--1\" value=\"&lt;div style=&quot;font-size: 11px&quot;&gt;Redis&lt;/div&gt;&lt;div style=&quot;font-size: 10px&quot;&gt;Eventconsumer&lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/div&gt;\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"165\" y=\"365\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--3\" value=\"commands\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"aOpChjktBB4jcuNQKIP--1\" target=\"glnVcpvA8bHsyrLV4RX5-7\" edge=\"1\">\n          \n          <mxGeometry x=\"0.1529\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"235\" y=\"395\" />\n              \n              <mxPoint x=\"235\" y=\"360\" />\n              \n              <mxPoint x=\"305\" y=\"360\" />\n              \n            </Array>\n            \n            <mxPoint x=\"200.1034482758621\" y=\"279.9655172413793\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"302\" y=\"345\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--7\" value=\"&lt;div style=&quot;font-size: 11px&quot;&gt;External Message Bus / Message Broker&lt;br&gt;&lt;/div&gt;&lt;div style=&quot;font-size: 11px&quot;&gt;(e.g., Redis, Event Store)&lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/div&gt;\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;size=11;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"309.64\" y=\"265\" width=\"240\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--9\" value=\"external events\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;entryX=0.5;entryY=0;entryDx=0;entryDy=0;labelBackgroundColor=#ffffff;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"aOpChjktBB4jcuNQKIP--7\" target=\"aOpChjktBB4jcuNQKIP--1\" edge=\"1\">\n          \n          <mxGeometry x=\"0.1485\" y=\"20\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"195\" y=\"280\" />\n              \n            </Array>\n            \n            <mxPoint x=\"290\" y=\"280.33333333333337\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"210\" y=\"335\" as=\"targetPoint\" />\n            \n            <mxPoint x=\"-20\" y=\"20\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--10\" value=\"external events\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;entryX=1;entryY=0.5;entryDx=0;entryDy=0;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"COUvA0_Sbrjylx--tMv7-3\" target=\"aOpChjktBB4jcuNQKIP--7\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.1129\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"630\" y=\"280\" />\n              \n            </Array>\n            \n            <mxPoint x=\"310\" y=\"110.33333333333337\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"160\" y=\"190.33333333333337\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--13\" value=\"&lt;div style=&quot;font-size: 10px;&quot;&gt;internal event&lt;/div&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;entryX=0.5;entryY=0;entryDx=0;entryDy=0;dashed=1;curved=1;dashPattern=1 2;exitX=0.5;exitY=1;exitDx=0;exitDy=0;exitPerimeter=0;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"aOpChjktBB4jcuNQKIP--0\" target=\"glnVcpvA8bHsyrLV4RX5-17\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.4681\" y=\"-30\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"477\" y=\"560\" />\n              \n              <mxPoint x=\"330\" y=\"560\" />\n              \n              <mxPoint x=\"330\" y=\"340\" />\n              \n              <mxPoint x=\"520\" y=\"340\" />\n              \n            </Array>\n            \n            <mxPoint x=\"577\" y=\"520\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"580\" y=\"110.33333333333337\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"COUvA0_Sbrjylx--tMv7-3\" value=\"Redis&lt;br style=&quot;font-size: 11px;&quot;&gt;Event&lt;br style=&quot;font-size: 11px;&quot;&gt;Publisher\" style=\"rounded=0;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#F7A072;fillColor=#EDDEA4;verticalAlign=top;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"590\" y=\"380\" width=\"50\" height=\"70\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"COUvA0_Sbrjylx--tMv7-4\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;exitX=1;exitY=0.5;exitDx=0;exitDy=0;endSize=4;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"glnVcpvA8bHsyrLV4RX5-17\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"577\" y=\"407\" />\n              \n              <mxPoint x=\"593\" y=\"407\" />\n              \n            </Array>\n            \n            <mxPoint x=\"430\" y=\"518.6666666666667\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"590\" y=\"407\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-7\" value=\"(Internal) Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"245\" y=\"377.5\" width=\"120\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-11\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;entryX=0;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"glnVcpvA8bHsyrLV4RX5-7\" target=\"glnVcpvA8bHsyrLV4RX5-14\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"360\" y=\"392.5\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"260\" y=\"405\" as=\"targetPoint\" />\n            \n            <Array as=\"points\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"nfLvMKylGCL_AXs4o5bO-1\" value=\"HTTP API calls\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;entryX=0.5;entryY=1.039;entryDx=0;entryDy=0;exitX=0.4;exitY=0.1;exitDx=0;exitDy=0;exitPerimeter=0;entryPerimeter=0;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" source=\"nfLvMKylGCL_AXs4o5bO-2\" target=\"glnVcpvA8bHsyrLV4RX5-4\" edge=\"1\">\n          \n          <mxGeometry x=\"0.5967\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"189\" y=\"618\" />\n              \n              <mxPoint x=\"195\" y=\"618\" />\n              \n            </Array>\n            \n            <mxPoint x=\"160\" y=\"650\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"320\" y=\"415.3333333333335\" as=\"targetPoint\" />\n            \n            <mxPoint as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"nfLvMKylGCL_AXs4o5bO-2\" value=\"\" style=\"ellipse;shape=cloud;whiteSpace=wrap;html=1;rounded=1;shadow=0;glass=0;comic=0;strokeColor=#0FA3B1;fillColor=#F9F7F3;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"155\" y=\"580\" width=\"80\" height=\"45\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-14\" value=\"Handlers\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"385\" y=\"355\" width=\"180\" height=\"75\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-17\" value=\"publish_event()\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;align=center;strokeColor=#F7A072;fillColor=#EDDEA4;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"482.00000000000006\" y=\"391.4999999999999\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"c5TjxBIM3NryA8_h6giw-9\" value=\"\" style=\"group;fontSize=11;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"397.28\" y=\"379.9999999999999\" width=\"84.72000000000003\" height=\"41.500000000000114\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-15\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"c5TjxBIM3NryA8_h6giw-9\" vertex=\"1\">\n          \n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-16\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"c5TjxBIM3NryA8_h6giw-9\" vertex=\"1\">\n          \n          <mxGeometry x=\"4.720000000000027\" y=\"5.500000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"c5TjxBIM3NryA8_h6giw-0\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"c5TjxBIM3NryA8_h6giw-9\" vertex=\"1\">\n          \n          <mxGeometry x=\"9.720000000000027\" y=\"11.500000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"O_ktSeZXnSdylSmH1K7t-0\" value=\"Adapters\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=10;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;labelPosition=center;verticalLabelPosition=middle;align=left;spacingRight=0;spacingLeft=7;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"580\" y=\"355\" width=\"70\" height=\"105\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-19\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"385\" y=\"445\" width=\"120\" height=\"110\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-20\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"420.54806060606063\" y=\"470.00333657209484\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-21\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"422.28806060606064\" y=\"512.641055188496\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-22\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"392.49999999999994\" y=\"495.3500000000001\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"glnVcpvA8bHsyrLV4RX5-23\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"450.47\" y=\"475.40000000000003\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"O_ktSeZXnSdylSmH1K7t-3\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"455.47\" y=\"480.40000000000003\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"aOpChjktBB4jcuNQKIP--0\" value=\"Event:&lt;br&gt;Allocated\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#F7A072;fillColor=#EDDEA4;fontFamily=Guardian Sans Cond Light;fontSize=10;fontStyle=1\" parent=\"glnVcpvA8bHsyrLV4RX5-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"460\" y=\"488.82\" width=\"34.53\" height=\"42.36\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram name=\"Chapter 12\" id=\"sj57ge_07frvyqXKTSzD\">\n    \n    <mxGraphModel dx=\"768\" dy=\"536\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"827\" pageHeight=\"1169\" math=\"0\" shadow=\"0\">\n      \n      <root>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-0\" />\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-1\" parent=\"JnOe99VT9jNHiKgs8aEt-0\" />\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-2\" value=\"\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0FA3B1;align=right;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"145\" y=\"190\" width=\"350\" height=\"90\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-3\" value=\"commands&lt;br style=&quot;font-size: 10px;&quot;&gt;(write operations)\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-4\" target=\"JnOe99VT9jNHiKgs8aEt-7\" edge=\"1\">\n          \n          <mxGeometry x=\"-0.2857\" y=\"-5\" relative=\"1\" as=\"geometry\">\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"203\" y=\"180\" />\n              \n              <mxPoint x=\"203\" y=\"180\" />\n              \n            </Array>\n            \n            <mxPoint x=\"210\" y=\"216\" as=\"targetPoint\" />\n            \n            <mxPoint x=\"5\" y=\"-5\" as=\"offset\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-9\" value=\"queries (read operations)\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;fontStyle=1\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-4\" target=\"kt7jhiP3AQ8WfEiBBlfo-7\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-4\" value=\"Flask\" style=\"whiteSpace=wrap;html=1;aspect=fixed;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"172.5\" y=\"95\" width=\"60\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-5\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-6\" target=\"JnOe99VT9jNHiKgs8aEt-8\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"440.5899999999999\" y=\"280.3333333333335\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"440.5899999999999\" y=\"341.16666666666674\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-6\" value=\"UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"418.0332773109242\" y=\"203\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-7\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;gradientColor=none;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"155\" y=\"216\" width=\"95\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-1\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;curved=1;comic=1;orthogonalLoop=1;jettySize=auto;html=1;labelBackgroundColor=#ffffff;strokeColor=#9E9E9E;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;fillColor=#B5E2FA;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-8\" target=\"kt7jhiP3AQ8WfEiBBlfo-0\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-8\" value=\"Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"418.0299999999998\" y=\"313.5900000000001\" width=\"53.92\" height=\"80.81\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-11\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-7\" target=\"JnOe99VT9jNHiKgs8aEt-14\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"250\" y=\"239\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"270\" y=\"250\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"250\" y=\"233\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-12\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-8\" target=\"S-H_2ucdEx-qUf16I717-0\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"406.4799999999998\" y=\"157\" as=\"sourcePoint\" />\n            \n            <mxPoint x=\"400\" y=\"354.28571428571433\" as=\"targetPoint\" />\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-0\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"415\" y=\"415\" width=\"60\" height=\"50\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-5\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"JnOe99VT9jNHiKgs8aEt-14\" target=\"JnOe99VT9jNHiKgs8aEt-6\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-11\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" source=\"kt7jhiP3AQ8WfEiBBlfo-7\" target=\"kt7jhiP3AQ8WfEiBBlfo-0\" edge=\"1\">\n          \n          <mxGeometry relative=\"1\" as=\"geometry\">\n            \n            <mxPoint x=\"603.03\" y=\"363.9999999999999\" as=\"targetPoint\" />\n            \n            <Array as=\"points\">\n              \n              <mxPoint x=\"545\" y=\"440\" />\n              \n            </Array>\n            \n          </mxGeometry>\n          \n        </mxCell>\n        \n        <mxCell id=\"kt7jhiP3AQ8WfEiBBlfo-7\" value=\"Views\" style=\"shape=trapezoid;perimeter=trapezoidPerimeter;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;fontStyle=1;strokeWidth=2;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"510\" y=\"204.5\" width=\"70\" height=\"57\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-14\" value=\"Handlers\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\">\n          \n          <mxGeometry x=\"280\" y=\"196\" width=\"110\" height=\"74\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-10\" value=\"\" style=\"group\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"293\" y=\"219.9999999999999\" width=\"84.5\" height=\"40.000000000000114\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-15\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"S-H_2ucdEx-qUf16I717-10\" vertex=\"1\">\n          \n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"JnOe99VT9jNHiKgs8aEt-16\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"S-H_2ucdEx-qUf16I717-10\" vertex=\"1\">\n          \n          <mxGeometry x=\"4.5\" y=\"5.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"LKpdDz_jYAT4cETSVj6H-0\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"S-H_2ucdEx-qUf16I717-10\" vertex=\"1\">\n          \n          <mxGeometry x=\"9.5\" y=\"10.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"mBn0F4gTh890IIjv3oJy-1\" value=\"\" style=\"group\" parent=\"JnOe99VT9jNHiKgs8aEt-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry x=\"280\" y=\"306\" width=\"110\" height=\"96\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"mBn0F4gTh890IIjv3oJy-0\" value=\"\" style=\"group\" parent=\"mBn0F4gTh890IIjv3oJy-1\" vertex=\"1\" connectable=\"0\">\n          \n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-0\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-1\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"35.54806060606063\" y=\"25.003336572094838\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-2\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"37.28806060606064\" y=\"67.64105518849601\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-3\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"7.499999999999943\" y=\"50.35000000000008\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-4\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"65.47000000000003\" y=\"30.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-5\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"70.47000000000003\" y=\"35.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n        <mxCell id=\"S-H_2ucdEx-qUf16I717-7\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"mBn0F4gTh890IIjv3oJy-0\" vertex=\"1\">\n          \n          <mxGeometry x=\"75.47000000000003\" y=\"40.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n          \n        </mxCell>\n        \n      </root>\n      \n    </mxGraphModel>\n    \n  </diagram>\n  <diagram name=\"Chapter 13\" id=\"ztdPLjsT3CrRU0JNqJyU\">\n    <mxGraphModel dx=\"1162\" dy=\"889\" grid=\"1\" gridSize=\"5\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"827\" pageHeight=\"1169\" math=\"0\" shadow=\"0\">\n      <root>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-0\" />\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-1\" parent=\"U_wP4h89jNr1Abf_-y4N-0\" />\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-2\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=right;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"160\" y=\"140\" width=\"405\" height=\"100\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-3\" value=\"calls with UoW&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;u style=&quot;font-size: 11px;&quot;&gt;and&lt;/u&gt;&lt;br style=&quot;font-size: 11px;&quot;&gt;Command\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;verticalAlign=middle;exitX=0.5;exitY=1;exitDx=0;exitDy=0;fontStyle=2;entryX=0.5;entryY=0;entryDx=0;entryDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"U_wP4h89jNr1Abf_-y4N-5\" target=\"U_wP4h89jNr1Abf_-y4N-8\" edge=\"1\">\n          <mxGeometry x=\"-0.0926\" y=\"1\" relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"214\" y=\"125\" />\n              <mxPoint x=\"214\" y=\"125\" />\n            </Array>\n            <mxPoint x=\"210\" y=\"166\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-4\" value=\"&amp;nbsp;instantiates&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;fontStyle=2\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"U_wP4h89jNr1Abf_-y4N-5\" target=\"fRv-KAKMa0fs8XW-OyoP-8\" edge=\"1\">\n          <mxGeometry x=\"-0.0169\" relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"575\" y=\"90\" />\n              <mxPoint x=\"575\" y=\"195\" />\n            </Array>\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-5\" value=\"Entrypoints: &lt;br style=&quot;font-size: 11px&quot;&gt;&lt;div style=&quot;font-size: 11px&quot;&gt;Flask, &lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/div&gt;&lt;div style=&quot;font-size: 11px&quot;&gt;Eventconsumer...&lt;/div&gt;\" style=\"verticalLabelPosition=middle;verticalAlign=middle;html=1;shape=mxgraph.basic.layered_rect;dx=10;outlineConnect=0;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;labelPosition=center;spacingLeft=-9;spacingTop=-9;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"174\" y=\"50\" width=\"80\" height=\"51\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-8\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;gradientColor=none;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"169\" y=\"166\" width=\"90\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-11\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"U_wP4h89jNr1Abf_-y4N-8\" target=\"U_wP4h89jNr1Abf_-y4N-15\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"250\" y=\"189\" as=\"sourcePoint\" />\n            <mxPoint x=\"270\" y=\"200\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"260\" y=\"181\" />\n              <mxPoint x=\"260\" y=\"181\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-12\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-10\" target=\"lp1v6FBgVU2pbrBNH83S-2\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"480\" y=\"299\" as=\"sourcePoint\" />\n            <mxPoint x=\"400\" y=\"309\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-25\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=-0.003;entryY=0.393;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"U_wP4h89jNr1Abf_-y4N-15\" target=\"fRv-KAKMa0fs8XW-OyoP-2\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"480.0032773109242\" y=\"181\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-0\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"493.55999999999995\" y=\"430\" width=\"60\" height=\"50\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-1\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-12\" target=\"fRv-KAKMa0fs8XW-OyoP-17\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"524\" y=\"360\" />\n              <mxPoint x=\"524\" y=\"360\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-2\" value=\"Unit of Work\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;spacingTop=-4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"412.06\" y=\"146\" width=\"147.94\" height=\"90\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-5\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract UoW&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"421.6332773109243\" y=\"165\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-8\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"497.34327731092435\" y=\"165\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-3\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-5\" target=\"fRv-KAKMa0fs8XW-OyoP-11\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-6\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-8\" target=\"fRv-KAKMa0fs8XW-OyoP-12\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-14\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-8\" target=\"fRv-KAKMa0fs8XW-OyoP-5\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"526.98\" y=\"345\" as=\"sourcePoint\" />\n            <mxPoint x=\"366.98\" y=\"345\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-17\" value=\"ORM\" style=\"ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"499.55999999999995\" y=\"375\" width=\"49.5\" height=\"40\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-20\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-17\" target=\"fRv-KAKMa0fs8XW-OyoP-0\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"533.8042857142855\" y=\"353\" as=\"sourcePoint\" />\n            <mxPoint x=\"533.5499999999997\" y=\"380\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-21\" value=\"&amp;nbsp;initializes with orm.start_mappers()&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;entryX=1;entryY=0.5;entryDx=0;entryDy=0;fontStyle=2;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"U_wP4h89jNr1Abf_-y4N-5\" target=\"fRv-KAKMa0fs8XW-OyoP-17\" edge=\"1\">\n          <mxGeometry x=\"-0.2613\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"250\" y=\"30\" as=\"sourcePoint\" />\n            <mxPoint x=\"630\" y=\"175\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"585\" y=\"76\" />\n              <mxPoint x=\"585\" y=\"395\" />\n            </Array>\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-0\" value=\"\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=right;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"93.06\" y=\"764\" width=\"461.94\" height=\"101\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-1\" value=\"&amp;nbsp;Initialize with UoW&lt;i style=&quot;font-size: 11px&quot;&gt; and all other dependencies&lt;/i&gt;\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=middle;exitX=0;exitY=1;exitDx=0;exitDy=0;fontStyle=1\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"eP1SNQKgUor3KwtCTsnK-4\" edge=\"1\">\n          <mxGeometry x=\"-0.4554\" y=\"50\" relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"230\" y=\"734\" />\n              <mxPoint x=\"184\" y=\"734\" />\n            </Array>\n            <mxPoint x=\"183.48857142857156\" y=\"789.4285714285716\" as=\"targetPoint\" />\n            <mxPoint x=\"50\" y=\"-50\" as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-2\" value=\"&amp;nbsp;instantiates&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=1;exitDx=0;exitDy=0;fontStyle=1\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"eP1SNQKgUor3KwtCTsnK-4\" target=\"lp1v6FBgVU2pbrBNH83S-23\" edge=\"1\">\n          <mxGeometry x=\"0.1612\" relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"513\" y=\"696\" />\n            </Array>\n            <mxPoint x=\"591.8620689655172\" y=\"789\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"eP1SNQKgUor3KwtCTsnK-6\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0;exitDx=80;exitDy=35;exitPerimeter=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-11\" target=\"eP1SNQKgUor3KwtCTsnK-4\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"228.06000000000017\" y=\"620\" as=\"sourcePoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"eP1SNQKgUor3KwtCTsnK-8\" value=\"Command only\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0;exitDx=45;exitDy=60;exitPerimeter=0;entryX=0.372;entryY=0.044;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-11\" target=\"RcRoWGdIg_VopS8A42iQ-4\" edge=\"1\">\n          <mxGeometry x=\"-0.6196\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"162.8965517241379\" y=\"670\" as=\"sourcePoint\" />\n            <mxPoint x=\"169.99999999999977\" y=\"740\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-4\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;gradientColor=none;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"103.06\" y=\"790\" width=\"120\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-5\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"RcRoWGdIg_VopS8A42iQ-4\" target=\"lp1v6FBgVU2pbrBNH83S-29\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"223.06\" y=\"813\" as=\"sourcePoint\" />\n            <mxPoint x=\"253.24137931034488\" y=\"805.1034482758621\" as=\"targetPoint\" />\n            <Array as=\"points\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"RcRoWGdIg_VopS8A42iQ-34\" value=\"&amp;nbsp;initializes with orm.start_mappers()&amp;nbsp; \" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#F7A072;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=1;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0;exitDx=0;exitDy=0;fontStyle=1\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"eP1SNQKgUor3KwtCTsnK-4\" target=\"lp1v6FBgVU2pbrBNH83S-27\" edge=\"1\">\n          <mxGeometry x=\"-0.3632\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"233.06\" y=\"694\" as=\"sourcePoint\" />\n            <mxPoint x=\"616\" y=\"1043.7241379310346\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"270\" y=\"654\" />\n              <mxPoint x=\"565\" y=\"654\" />\n              <mxPoint x=\"565\" y=\"1024\" />\n            </Array>\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"eP1SNQKgUor3KwtCTsnK-1\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" edge=\"1\">\n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"50.00000000000004\" y=\"559.9999999999998\" as=\"sourcePoint\" />\n            <mxPoint x=\"780\" y=\"560\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"eP1SNQKgUor3KwtCTsnK-4\" value=\"Bootstrap\" style=\"rhombus;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#F7A072;fillColor=#EDDEA4;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;fontStyle=1;strokeWidth=2;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"210\" y=\"636\" width=\"80\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"Kz46Tss7XRxZ4chpYpnK-36\" value=\"\" style=\"endArrow=none;dashed=1;html=1;strokeColor=#FFB570;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" edge=\"1\">\n          <mxGeometry width=\"50\" height=\"50\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"60\" y=\"1190\" as=\"sourcePoint\" />\n            <mxPoint x=\"790\" y=\"1190\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"U_wP4h89jNr1Abf_-y4N-15\" value=\"Handlers\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;spacingTop=-4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"280\" y=\"146\" width=\"110\" height=\"70\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"M6P2A_5JTTXqFHIzLQT9-0\" value=\"\" style=\"group;fontSize=11;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"290\" y=\"169.9999999999999\" width=\"84.5\" height=\"40.000000000000114\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"M6P2A_5JTTXqFHIzLQT9-1\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"M6P2A_5JTTXqFHIzLQT9-0\" vertex=\"1\">\n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"M6P2A_5JTTXqFHIzLQT9-2\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"M6P2A_5JTTXqFHIzLQT9-0\" vertex=\"1\">\n          <mxGeometry x=\"4.5\" y=\"5.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"M6P2A_5JTTXqFHIzLQT9-3\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"M6P2A_5JTTXqFHIzLQT9-0\" vertex=\"1\">\n          <mxGeometry x=\"9.5\" y=\"10.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-0\" value=\"\" style=\"group;fontSize=11;spacingTop=-4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"283.06\" y=\"257\" width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-1\" value=\"\" style=\"group;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-0\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-2\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-3\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"35.54806060606063\" y=\"25.003336572094838\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-4\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"37.28806060606064\" y=\"67.64105518849601\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-5\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"7.499999999999943\" y=\"50.35000000000008\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-6\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"65.47000000000003\" y=\"30.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-7\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"70.47000000000003\" y=\"35.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-8\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-1\" vertex=\"1\">\n          <mxGeometry x=\"75.47000000000003\" y=\"40.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-10\" value=\"Repositories\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"412.06\" y=\"250\" width=\"147.94\" height=\"110\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-11\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract Repository&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"421.63\" y=\"281\" width=\"53.92\" height=\"69\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-12\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"497.34000000000003\" y=\"281\" width=\"53.92\" height=\"69\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"fRv-KAKMa0fs8XW-OyoP-13\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"fRv-KAKMa0fs8XW-OyoP-12\" target=\"fRv-KAKMa0fs8XW-OyoP-11\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"544.98\" y=\"321\" as=\"sourcePoint\" />\n            <mxPoint x=\"384.98\" y=\"321\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-11\" value=\"Entrypoints: &lt;br style=&quot;font-size: 11px&quot;&gt;&lt;div style=&quot;font-size: 11px&quot;&gt;Flask, &lt;br style=&quot;font-size: 11px&quot;&gt;&lt;/div&gt;&lt;div style=&quot;font-size: 11px&quot;&gt;Eventconsumer...&lt;/div&gt;\" style=\"verticalLabelPosition=middle;verticalAlign=middle;html=1;shape=mxgraph.basic.layered_rect;dx=10;outlineConnect=0;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;labelPosition=center;spacingLeft=-9;spacingTop=-9;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"103.06\" y=\"640\" width=\"80\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-17\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=0.994;entryY=0.475;entryDx=0;entryDy=0;entryPerimeter=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-43\" target=\"lp1v6FBgVU2pbrBNH83S-36\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"450\" y=\"933\" as=\"sourcePoint\" />\n            <mxPoint x=\"375\" y=\"937\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"375\" y=\"937\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-18\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-29\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"393\" y=\"805\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-19\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"479.30999999999995\" y=\"1059\" width=\"60\" height=\"50\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-20\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-45\" target=\"lp1v6FBgVU2pbrBNH83S-27\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"509\" y=\"994\" />\n              <mxPoint x=\"509\" y=\"994\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-21\" value=\"Unit of Work\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"393.06\" y=\"770\" width=\"156.94\" height=\"90\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-22\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract UoW&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"406.6332773109243\" y=\"789\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-23\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"482.34327731092435\" y=\"789\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-24\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-22\" target=\"lp1v6FBgVU2pbrBNH83S-44\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-25\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-23\" target=\"lp1v6FBgVU2pbrBNH83S-45\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-26\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-23\" target=\"lp1v6FBgVU2pbrBNH83S-22\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"511.98\" y=\"969\" as=\"sourcePoint\" />\n            <mxPoint x=\"351.98\" y=\"969\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-27\" value=\"ORM\" style=\"ellipse;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"484.55999999999995\" y=\"1004\" width=\"49.5\" height=\"40\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-28\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-27\" target=\"lp1v6FBgVU2pbrBNH83S-19\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"518.8042857142855\" y=\"987\" as=\"sourcePoint\" />\n            <mxPoint x=\"518.5499999999997\" y=\"1014\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-29\" value=\"Handlers\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"263\" y=\"770\" width=\"110\" height=\"70\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-30\" value=\"\" style=\"group;fontSize=11;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"273\" y=\"793.9999999999999\" width=\"84.5\" height=\"40.000000000000114\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-31\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lp1v6FBgVU2pbrBNH83S-30\" vertex=\"1\">\n          <mxGeometry width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-32\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lp1v6FBgVU2pbrBNH83S-30\" vertex=\"1\">\n          <mxGeometry x=\"4.5\" y=\"5.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-33\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lp1v6FBgVU2pbrBNH83S-30\" vertex=\"1\">\n          <mxGeometry x=\"9.5\" y=\"10.000000000000114\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-34\" value=\"\" style=\"group;fontSize=11;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"266.06\" y=\"891\" width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-35\" value=\"\" style=\"group;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-34\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-36\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry width=\"110\" height=\"96\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-37\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"35.54806060606063\" y=\"25.003336572094838\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-38\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"37.28806060606064\" y=\"67.64105518849601\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-39\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"7.499999999999943\" y=\"50.35000000000008\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-40\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"65.47000000000003\" y=\"30.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-41\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"70.47000000000003\" y=\"35.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-42\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"lp1v6FBgVU2pbrBNH83S-35\" vertex=\"1\">\n          <mxGeometry x=\"75.47000000000003\" y=\"40.400000000000034\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-43\" value=\"Repositories\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"393.06\" y=\"884\" width=\"156.94\" height=\"106\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-44\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract Repository&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"406.63\" y=\"911\" width=\"53.92\" height=\"69\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-45\" value=\"SQLAlchemy&lt;br style=&quot;font-size: 11px;&quot;&gt;Repository\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" vertex=\"1\">\n          <mxGeometry x=\"482.34000000000003\" y=\"911\" width=\"53.92\" height=\"69\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"lp1v6FBgVU2pbrBNH83S-46\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"U_wP4h89jNr1Abf_-y4N-1\" source=\"lp1v6FBgVU2pbrBNH83S-45\" target=\"lp1v6FBgVU2pbrBNH83S-44\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"529.98\" y=\"951\" as=\"sourcePoint\" />\n            <mxPoint x=\"369.98\" y=\"951\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n      </root>\n    </mxGraphModel>\n  </diagram>\n  <diagram id=\"J7DOt-Zcg9785q2qfWU2\" name=\"recap diagram\">\n    <mxGraphModel dx=\"801\" dy=\"-287\" grid=\"1\" gridSize=\"10\" guides=\"1\" tooltips=\"1\" connect=\"1\" arrows=\"1\" fold=\"1\" page=\"1\" pageScale=\"1\" pageWidth=\"700\" pageHeight=\"900\" math=\"0\" shadow=\"0\" extFonts=\"GSCL^https://www.dropbox.com/s/hod0v6c6q5um5oc/Guardian%20Sans%20Cond-Light.otf?dl=1\">\n      <root>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-0\" />\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-1\" parent=\"vNQERgU7gHwbTBUCVXgm-0\" />\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-2\" value=\"Service Layer\" style=\"rounded=1;whiteSpace=wrap;html=1;shadow=0;dashed=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;align=right;strokeColor=#0FA3B1;gradientColor=#ffffff;fillColor=none;labelPosition=center;verticalLabelPosition=top;verticalAlign=bottom;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"63\" y=\"1114\" width=\"567\" height=\"100\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-3\" value=\"initializes\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;verticalAlign=middle;exitX=0.5;exitY=1;exitDx=0;exitDy=0;fontStyle=2\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-36\" edge=\"1\">\n          <mxGeometry x=\"0.1304\" relative=\"1\" as=\"geometry\">\n            <Array as=\"points\">\n              <mxPoint x=\"135\" y=\"1130\" />\n              <mxPoint x=\"135\" y=\"1130\" />\n            </Array>\n            <mxPoint x=\"135\" y=\"1150\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-4\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-37\" target=\"vNQERgU7gHwbTBUCVXgm-36\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"218.00000000000017\" y=\"970\" as=\"sourcePoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-5\" value=\"Commands\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.75;entryY=0;entryDx=0;entryDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-37\" target=\"vNQERgU7gHwbTBUCVXgm-6\" edge=\"1\">\n          <mxGeometry x=\"-0.6382\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"178.00000000000017\" y=\"1010\" as=\"sourcePoint\" />\n            <mxPoint x=\"205\" y=\"1149\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n            <Array as=\"points\">\n              <mxPoint x=\"205\" y=\"1100\" />\n              <mxPoint x=\"163\" y=\"1100\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-6\" value=\"Message Bus\" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;gradientColor=none;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"83\" y=\"1150\" width=\"107\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-7\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0;entryY=0.5;entryDx=0;entryDy=0;exitX=1;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-6\" target=\"vNQERgU7gHwbTBUCVXgm-10\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"193\" y=\"1165\" as=\"sourcePoint\" />\n            <mxPoint x=\"213\" y=\"1174\" as=\"targetPoint\" />\n            <Array as=\"points\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-8\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-27\" target=\"vNQERgU7gHwbTBUCVXgm-15\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"373\" y=\"1289\" as=\"sourcePoint\" />\n            <mxPoint x=\"375.81327731092415\" y=\"1092\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"331\" y=\"1305\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-13\" value=\"\" style=\"group;fontSize=11;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry x=\"212.5\" y=\"1240\" width=\"119.99999999999997\" height=\"118\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-14\" value=\"\" style=\"group;fontSize=11;\" parent=\"vNQERgU7gHwbTBUCVXgm-13\" vertex=\"1\" connectable=\"0\">\n          <mxGeometry width=\"119.99999999999997\" height=\"118\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-15\" value=\"Domain\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;dashed=1;\" parent=\"vNQERgU7gHwbTBUCVXgm-14\" vertex=\"1\">\n          <mxGeometry width=\"120\" height=\"118\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-16\" value=\"\" style=\"whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"vNQERgU7gHwbTBUCVXgm-14\" vertex=\"1\">\n          <mxGeometry x=\"57.28806060606061\" y=\"35.49333657209485\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-17\" value=\"\" style=\"ellipse;whiteSpace=wrap;html=1;aspect=fixed;fontSize=11;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;\" parent=\"vNQERgU7gHwbTBUCVXgm-14\" vertex=\"1\">\n          <mxGeometry x=\"57.28806060606061\" y=\"70.18105518849592\" width=\"18.187915754412646\" height=\"18.187915754412646\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-18\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-14\" vertex=\"1\">\n          <mxGeometry x=\"12.289999999999964\" y=\"50.35000000000008\" width=\"35\" height=\"17.29\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-19\" value=\"\" style=\"whiteSpace=wrap;html=1;shape=mxgraph.basic.document;rounded=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;\" parent=\"vNQERgU7gHwbTBUCVXgm-14\" vertex=\"1\">\n          <mxGeometry x=\"89.99999999999997\" y=\"50.99000000000001\" width=\"14.53\" height=\"19.19\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-20\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-10\" target=\"vNQERgU7gHwbTBUCVXgm-23\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"413.00327731092415\" y=\"1155\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-21\" value=\"DB\" style=\"shape=cylinder;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;fontSize=11;fontColor=#212A2E;gradientColor=none;fontFamily=Guardian Sans Cond Light;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"439.99\" y=\"1386\" width=\"60\" height=\"44\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-22\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-29\" target=\"vNQERgU7gHwbTBUCVXgm-21\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"469.9899999999998\" y=\"1380\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-23\" value=\"Unit of Work\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"351\" y=\"1120\" width=\"159\" height=\"90\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-24\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract UoW&lt;br style=&quot;font-size: 11px;&quot;&gt;&lt;/font&gt;\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"368.5732773109243\" y=\"1139\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-25\" value=\"SQLA&lt;br style=&quot;font-size: 11px;&quot;&gt;UoW\" style=\"shape=cube;whiteSpace=wrap;html=1;boundedLbl=1;backgroundOutline=1;darkOpacity=0.05;darkOpacity2=0.1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=4;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"443.0332773109243\" y=\"1139\" width=\"53.924369747899156\" height=\"60\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-31\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-24\" target=\"vNQERgU7gHwbTBUCVXgm-28\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-32\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-25\" target=\"vNQERgU7gHwbTBUCVXgm-29\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-33\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-25\" target=\"vNQERgU7gHwbTBUCVXgm-24\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"473.9200000000001\" y=\"1319\" as=\"sourcePoint\" />\n            <mxPoint x=\"313.92\" y=\"1319\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-36\" value=\"Bootstrap\" style=\"rhombus;whiteSpace=wrap;html=1;rounded=0;shadow=0;glass=0;comic=0;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"95\" y=\"1040\" width=\"80\" height=\"64\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-37\" value=\"&lt;div style=&quot;font-size: 11px;&quot;&gt;Eventconsumer&lt;/div&gt;\" style=\"rounded=0;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"165\" y=\"980\" width=\"80\" height=\"50\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-10\" value=\"Handlers\" style=\"rounded=1;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;verticalAlign=top;fontSize=11;fontColor=#212A2E;fillColor=none;strokeColor=#637C89;fontStyle=0;dashed=1;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"210\" y=\"1120\" width=\"120\" height=\"90\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-11\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"227\" y=\"1149\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-12\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"235\" y=\"1160\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"86eM6GqLhsveqBZcdA8n-3\" value=\"\" style=\"shape=parallelogram;perimeter=parallelogramPerimeter;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"245\" y=\"1170\" width=\"75\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-27\" value=\"Adapters\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=none;gradientColor=#ffffff;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#0A6A73;verticalAlign=bottom;rounded=1;dashed=1;shadow=0;align=right;labelPosition=center;verticalLabelPosition=top;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"351\" y=\"1240\" width=\"279\" height=\"129\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-28\" value=\"&lt;font style=&quot;font-size: 11px;&quot; color=&quot;#212A2E&quot;&gt;Abstract Repo&lt;/font&gt;\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"368.57\" y=\"1271\" width=\"53.92\" height=\"80\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-29\" value=\"SQLA&lt;br style=&quot;font-size: 11px;&quot;&gt;Repo\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"443.03\" y=\"1271\" width=\"53.92\" height=\"82\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"vNQERgU7gHwbTBUCVXgm-30\" value=\"\" style=\"endArrow=block;dashed=1;endFill=0;endSize=6;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0;exitY=0.5;exitDx=0;exitDy=0;entryX=1;entryY=0.5;entryDx=0;entryDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-29\" target=\"vNQERgU7gHwbTBUCVXgm-28\" edge=\"1\">\n          <mxGeometry width=\"160\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"491.9200000000001\" y=\"1311\" as=\"sourcePoint\" />\n            <mxPoint x=\"331.92\" y=\"1311\" as=\"targetPoint\" />\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"86eM6GqLhsveqBZcdA8n-13\" value=\"Redis&lt;br style=&quot;font-size: 11px;&quot;&gt;Event&lt;br style=&quot;font-size: 11px;&quot;&gt;Publisher\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"519.99\" y=\"1271\" width=\"53.92\" height=\"82\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"86eM6GqLhsveqBZcdA8n-14\" value=\"etc\" style=\"whiteSpace=wrap;html=1;strokeColor=#0FA3B1;fillColor=#B5E2FA;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;verticalAlign=top;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"584.99\" y=\"1271\" width=\"35.01\" height=\"82\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"86eM6GqLhsveqBZcdA8n-15\" value=\"API\" style=\"rounded=0;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"35\" y=\"980\" width=\"60\" height=\"50\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-0\" value=\"\" style=\"ellipse;shape=cloud;whiteSpace=wrap;html=1;rounded=1;shadow=0;glass=0;comic=0;strokeColor=#0FA3B1;fillColor=#F9F7F3;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;align=center;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"35\" y=\"910\" width=\"70\" height=\"50\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-2\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"86eM6GqLhsveqBZcdA8n-15\" target=\"vNQERgU7gHwbTBUCVXgm-36\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"144\" y=\"1050.2857142857142\" as=\"sourcePoint\" />\n            <mxPoint x=\"15\" y=\"1135\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"135\" y=\"1005\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-3\" value=\"Commands\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=10;fontColor=#212A2E;exitX=0.5;exitY=1;exitDx=0;exitDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"86eM6GqLhsveqBZcdA8n-15\" target=\"vNQERgU7gHwbTBUCVXgm-6\" edge=\"1\">\n          <mxGeometry x=\"-0.6364\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"153\" y=\"1080\" as=\"sourcePoint\" />\n            <mxPoint x=\"153\" y=\"1159\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n            <Array as=\"points\">\n              <mxPoint x=\"65\" y=\"1100\" />\n              <mxPoint x=\"110\" y=\"1100\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-4\" value=\"\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"4a8NubAzqQkbkM2oc8rb-0\" target=\"86eM6GqLhsveqBZcdA8n-15\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"144\" y=\"1308.5714285714284\" as=\"sourcePoint\" />\n            <mxPoint x=\"15\" y=\"1214.857142857143\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"65\" y=\"970\" />\n              <mxPoint x=\"65\" y=\"970\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-6\" value=\"External Message Broker \" style=\"shape=loopLimit;whiteSpace=wrap;html=1;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;align=center;strokeColor=#0FA3B1;fillColor=#B5E2FA;size=12;gradientColor=none;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"289.99\" y=\"920\" width=\"240\" height=\"30\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-7\" value=\"External Events\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=0;entryDx=0;entryDy=0;exitX=0.25;exitY=1;exitDx=0;exitDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"4a8NubAzqQkbkM2oc8rb-6\" target=\"vNQERgU7gHwbTBUCVXgm-37\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"109\" y=\"1050.2857142857142\" as=\"sourcePoint\" />\n            <mxPoint x=\"-20\" y=\"1135\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"350\" y=\"960\" />\n              <mxPoint x=\"205\" y=\"960\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"4a8NubAzqQkbkM2oc8rb-15\" value=\"Repositories\" style=\"whiteSpace=wrap;html=1;strokeColor=#637C89;fillColor=none;gradientColor=none;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#000000;verticalAlign=top;rounded=1;dashed=1;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" vertex=\"1\">\n          <mxGeometry x=\"361\" y=\"1246\" width=\"149\" height=\"114\" as=\"geometry\" />\n        </mxCell>\n        <mxCell id=\"Iqtz2xAC9z4E5MeAZ7dq-0\" value=\"External Events\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;exitX=0.5;exitY=0;exitDx=0;exitDy=0;entryX=0.75;entryY=1;entryDx=0;entryDy=0;\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"86eM6GqLhsveqBZcdA8n-13\" target=\"4a8NubAzqQkbkM2oc8rb-6\" edge=\"1\">\n          <mxGeometry relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"153\" y=\"1393.1399999999999\" as=\"sourcePoint\" />\n            <mxPoint x=\"153\" y=\"1338.5\" as=\"targetPoint\" />\n            <Array as=\"points\">\n              <mxPoint x=\"547\" y=\"980\" />\n              <mxPoint x=\"470\" y=\"980\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n        <mxCell id=\"sjwQP8t7mA9cDetq6Lur-0\" value=\"Domain Events\" style=\"edgeStyle=orthogonalEdgeStyle;orthogonalLoop=1;jettySize=auto;html=1;strokeColor=#9E9E9E;fillColor=#B5E2FA;fontFamily=Guardian Sans Cond Light;fontSize=11;fontColor=#212A2E;entryX=0.5;entryY=1;entryDx=0;entryDy=0;\" edge=\"1\" parent=\"vNQERgU7gHwbTBUCVXgm-1\" source=\"vNQERgU7gHwbTBUCVXgm-15\" target=\"vNQERgU7gHwbTBUCVXgm-6\">\n          <mxGeometry x=\"0.1744\" y=\"1\" relative=\"1\" as=\"geometry\">\n            <mxPoint x=\"75\" y=\"1040\" as=\"sourcePoint\" />\n            <mxPoint x=\"120\" y=\"1160\" as=\"targetPoint\" />\n            <mxPoint as=\"offset\" />\n            <Array as=\"points\">\n              <mxPoint x=\"137\" y=\"1299\" />\n              <mxPoint x=\"137\" y=\"1200\" />\n              <mxPoint x=\"137\" y=\"1200\" />\n            </Array>\n          </mxGeometry>\n        </mxCell>\n      </root>\n    </mxGraphModel>\n  </diagram>\n</mxfile>\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.1923828125,
          "content": "[mypy]\nignore_missing_imports = False\nnamespace_packages = True\nmypy_path = ./code/src\ncheck_untyped_defs = True\n\n[mypy-pytest.*,lxml.*,sqlalchemy.*,redis.*,django.*]\nignore_missing_imports = True\n"
        },
        {
          "name": "outline.md",
          "type": "blob",
          "size": 9.8515625,
          "content": "# Outline\n\n## Preface/Intro\n\nWho are we, why we are writing this book\n(all the args from the proposal, python's popularity, communicating well-understood patterns from the Java/C#/Enterprise world to a wider audience with nice, readable, pythonic code examples)\n\n> As Python grows in popularity as a language, typical projects are getting larger and more complex, and issues of software design and architecture become more salient.  Patterns like \"Ports and Adapters\", as well Domain-Driven Design, Event-Driven programming, Command-Query Responsibility Segregation, which are well known in more \"enterprisey\" communities like Java and C#, are generating more interest in the Python community, but it's not always easy to see how these patterns translate into Python.  (reviewing the classic \"Gang of Four\" design patterns book for example leads to the conclusion that half the patterns are artifacts of the Java/C++ syntax, and are simply not necessary in the more flexible and dynamic world of Python).\n\n> In the Python world, we often quote the Zen of Python:  \"there should be one--preferably on only one--obvious way to do it\".  Unfortunately, as project complexity grows, the most obvious way of doing things isn't always the way that helps you manage complexity and evolving requirements.\n\n> This book will provide an introduction to proven architectural design patterns that help you manage complexity, using concrete examples written in Python. It will explain how to avoid some of the unnecessary particularities of Java and C# syntax and implement these patterns in a \"Pythonic\" way.\n\nAn overview of the central argument:\n\n> Layer your system so that the low-level details depend on the high-level abstractions, not the other way around.\n\n\n## Chapter 1: Domain modelling, and why do we always make it so hard for ourselves?\n\nEvery so often someone says \"where shall I put this new logic\", and we all know the right answer: it should live in the domain model.  So why does it always somehow end up in some gigantic controller function that's closely coupled with your web framework and database and third party apis and god knows what else?\n\nLet's see what happens if we build everything around making sure our domain model is easy to work with and change.\n\n* Talk about domain modelling and DDD, work through an example (allocate-order)\n* Example code\n* crazy idea: Bob and I will record a video of (part of?) the allocate-order code writing as a TDD \"kata\", to illustrate how easy it is to do this stuff when you have no dependencies on databases, frameworks, etc (this will also save us from having to go slowly thru what tdd is in the book)\n\ncode examples / patterns:  some domain model objects (python3.7 dataclasses maybe?), a domain service / use case function, some \"proper\" unit tests.\n\nrelated post from existing blog: https://io.made.com/introducing-command-handler/\n\n\n\n## Chapter 2: persistence and the repository pattern\n\nThe main ORM tool in the Python world is SQLAlchemy, and if you follow the default tutorial, you end up writing your model objects inheriting from `sqlalchemy.Table`, and soon your domain model is tightly coupled to your DB.\n\nBut you don't have to!  Demonstrate the alternative way to do metadata/mapping.\n\n==> our ORM depends on the domain model, and not the other way around. an illustration of one of our key patterns/principles, the  _Dependency Inversion Principle_ (the D in SOLID)\n\nAlso: repository pattern.  choosing a simple abstraction (it's a dictionary)\nAlso: first integration test\n\ncode examples / patterns: sqlalchemy metadata/mapping, repository pattern\n\nrelated post from existing blog: https://io.made.com/repository-and-unit-of-work-pattern-in-python/ \n\n\n\n## Chapter 3: making ourselves available via a web API.  Flask as a port (as in ports-and-adapters). Our first use case.  Orchestration. Service layer\n\nWe have a use case in mind, and a domain model that can do it, but how do we make it available to the outside world?\n\nstart with a naive flask controller.  evolve it to flask being an adapter to a use case function in our service/orchestration layer.\n\n* happy path, show the basic use case moving parts:  create a database session, initialise our repository, load some objects, invoke our domain function, commit.\n* first acceptance test\n* handle error case, eg product does not exist.  handle `KeyError` from repository, flask returns a 400 with nice erro json\n* but what if we have more error cases at this orchestration level? it'll be annoying to test everything with acceptance tests, and hard to unit test.\n\n==> introduce service layer.  flask becomes an adapter.  flask depends on the service layer, rather than the other way around (DIP once again)\n\n(later in the book we'll swap flask for asyncio, and show how easy it is)\n\npatterns: use case, service layer, port/adapter pattern for web,\n\nrelated post from existing blog: https://io.made.com/repository-and-unit-of-work-pattern-in-python/ \n\n\n\n## Chapter 4: data integrity concerns 1: unit of work pattern\n\nWhat happens if we encounter an error during our allocation?  eg out of stock, a domain error?  We'd like to wrap our work up so that, either the entire order is allocated, or we abort and leave things in a \"clean\" state if anything goes wrong -- a classic case for a transaction/rollback.\n\nWhat's a Pythonic way of \"doing transactions\"?  A context manager.  demonstrate the _Unit of Work Pattern_ and show how it fits with _Repository_\nBut we also want a nice, Pythonic way of \"doing transactions\", of wrapping a block of code up into an atomic whole.\n\ndiscuss different options of unit of work, explicit/implicit rollbacks, dependency-inject uow.\n\ncode examples / patterns: Unit Of Work (using a context manager)\n\nrelated post from existing blog: https://io.made.com/repository-and-unit-of-work-pattern-in-python/ \n\n\n## Chapter 5: data integrity concerns 2: choosing the right consistency boundary (Aggregate pattern)\n\nWhile we're thinking about data integrity, we now realise that our `allocate(order, shipments)` implementation which depends on all the shipments in the world won't scale if every order needs to lock the whole shipments table.   We should only look at shipments that matter to that order.\n\nMoreover, we only need to allocate the order one line at a time (although maybe we want to roll back all the lines if we fail any one of them).\n\nThis leads us on to discussing the _Aggregate_ pattern - by choosing `Product` as our aggregate, we choose a consistency boundary that allows us to be more clever about transactions.\n\nAlso demonstrate how easy it is to refactor a domain model if it's not intermixed with infrastructure concerns.\n\ncode examples / patterns:  Aggregate\n\n\n\n## Chapter 6: event-driven architecture part 1: doamin events and the message bus\n\nAnother new requirement:  when allocation fails because we are out of stock, someone should be emailed.  But we don't want to have email-sending code be a potential cause of bugs/failures in our core model/state changes.  introduce domain events and a message bus as a pattern for kicking off related work after a use case is complete.\n\n* discuss SRP, use case shouldn't have an _and_. leads naturally to events.\n\ncode examples / patterns: events, handlers, message bus\n\nrelated post from existing blog: https://io.made.com/why-use-domain-events/\n\n\n\n## Chapter 7: event-driven architecture part 2: reactive microservices\n\nWe've got a microservice with an web api, but what about other ways of talking to other systems?  how does it know if, say, a\nshipment is delayed or the quantity is amended?  how does it communicate to our warehouse system to say that an order has\nbeen allocated and needs to be sent to a customer?\n\n* redis pubsub in: batch_quantity_changed.  leads to deallocate / reallocate\n* redis pubsub out: order_allocated event, for communicating with warehouse\n\ncode examples / patterns: events as a microservices integration platform\n\n \n## Chapter 8: Commands vs Events\n\ndistinguish commands from events. different semantics, can say no to a command.\n\n\n\n## Chapter 9: CQRS\n\nThe business comes along and supplies a new requirement:  a dashboard showing the current allocation state of all shipments.  Discuss how using the ORM naively leads to the _SELECT N+1_ antipattern, and use it as an opportunity to demonstrate _Command-Query-Responsiblity-Segregation (CQRS)_ -- read-only parts of our architecture can be implemented quite differently from the write side\n\nstart with raw sql\ndiscuss option of using events to update a view model\n\ncode examples / patterns:  CQRS / event-driven view model.\n\nrelated post from existing blog: https://io.made.com/commands-and-queries-handlers-and-views/\n\n\n## Chapter 10: Bootstrap.py and dependency injection\n\nthe database / sqlalchemy are under control, but email and redis are a bit haphazard.  also orm initialisation. show how a bootsrap script\nand DI can manage all this\n\ndiagrams.\n\nwith + without framework, `@inject`, and bob's crazy, heretical, unclean type-hints based one.\n\nmaybe point out that command-handler pattern would make this all easier?\n\nrelated post from existing blog: https://io.made.com/dependency-injection-with-type-signatures-in-python/\n\n\n## Appendix 1: project structure\n\nshow folder structure, dockerfiles, setup.py, where tests live, etc.\n\n\n\n## Appendix 2: swapping out flask and our database for a CLI with CSVs\n\n(follows on from unit of work chapter).\nthe business come to us apologetically saying they're not ready to use our API and could we build a thing that reads batches and orders from 2 csvs and outputs a third with allocations\".\n\nshow how by just changing our repository and unitofwork, we can use the exact same service layer and domain layer to build a CLI app.\n\nthis could be an exercise for the reader tbh.  or a video\n\n\n## appendix 3: command handler pattern?\n\n==> show how commands can be put on the message bus just like events.\n\ncode examples / patterns: reuse message bus for commands\n\nrelated post from existing blog: https://io.made.com/introducing-command-handler/\n\n\n\n"
        },
        {
          "name": "part1.asciidoc",
          "type": "blob",
          "size": 2.9169921875,
          "content": "[role=\"pagenumrestart\"]\n[[part1]]\n[part]\n== Building an Architecture to Support Domain Modeling\n\n\n[quote, Cyrille Martraire, DDD EU 2017]\n____\nMost developers have never seen a domain model, only a data model.\n____\n\nMost developers we talk to about architecture have a nagging sense that\nthings could be better. They are often trying to rescue a system that has gone\nwrong somehow, and are trying to put some structure back into a ball of mud.\nThey know that their business logic shouldn't be spread all over the place,\nbut they have no idea how to fix it.\n\nWe've found that many developers, when asked to design a new system, will\nimmediately start to build a database schema, with the object model treated\nas an afterthought. This is where it all starts to go wrong. Instead, _behavior\nshould come first and drive our storage requirements._ After all, our customers don't care about the data model. They care about what\nthe system _does_; otherwise they'd just use a spreadsheet.\n\nThe first part of the book looks at how to build a rich object model\nthrough TDD (in <<chapter_01_domain_model>>), and then we'll show how\nto keep that model decoupled from technical concerns. We show how to build\npersistence-ignorant code and how to create stable APIs around our domain so\nthat we can refactor aggressively.\n\nTo do that, we present four key design patterns:\n\n* The <<chapter_02_repository,Repository pattern>>, an abstraction over the\n  idea of persistent storage\n\n* The <<chapter_04_service_layer,Service Layer pattern>> to clearly define where our\n  use cases begin and end\n  \n[role=\"pagebreak-before\"]\n* The <<chapter_06_uow,Unit of Work pattern>> to provide atomic operations\n\n* The <<chapter_07_aggregate,Aggregate pattern>> to enforce the integrity\n  of our data\n\nIf you'd like a picture of where we're going, take a look at\n<<part1_components_diagram>>, but don't worry if none of it makes sense\nyet!  We introduce each box in the figure, one by one, throughout this part of the book.\n\n[role=\"width-90\"]\n[[part1_components_diagram]]\n.A component diagram for our app at the end of <<part1>>\nimage::images/apwp_p101.png[]\n\nWe also take a little time out to talk about\n<<chapter_03_abstractions,coupling and abstractions>>, illustrating it with a simple example that shows how and why we choose our\nabstractions.\n\nThree appendices are further explorations of the content from Part I:\n\n* <<appendix_project_structure>> is a write-up of the infrastructure for our example\n  code: how we build and run the Docker images, where we manage configuration\n  info, and how we run different types of tests.\n\n* <<appendix_csvs>> is a \"proof of the pudding\" kind of content, showing\n  how easy it is to swap out our entire infrastructure--the Flask API, the\n  ORM, and Postgres—for a totally different I/O model involving a CLI and\n  CSVs.\n\n* Finally, <<appendix_django>> may be of interest if you're wondering how these\n  patterns might look if using Django instead of Flask and SQLAlchemy.\n"
        },
        {
          "name": "part2.asciidoc",
          "type": "blob",
          "size": 2.380859375,
          "content": "[[part2]]\n[part]\n== Event-Driven Architecture\n\n[quote, Alan Kay]\n____\n\nI'm sorry that I long ago coined the term \"objects\" for this topic because it\ngets many people to focus on the lesser idea.\n\nThe big idea is \"messaging.\"...The key in making great and growable systems is\nmuch more to design how its modules communicate rather than what their internal\nproperties and behaviors should be.\n____\n\nIt's all very well being able to write _one_ domain model to manage a single bit\nof business process, but what happens when we need to write _many_ models? In\nthe real world, our applications sit within an organization and need to exchange\ninformation with other parts of the system. You may remember our context\ndiagram shown in <<allocation_context_diagram_again>>.\n\nFaced with this requirement, many teams reach for microservices integrated\nvia HTTP APIs. But if they're not careful, they'll end up producing the most\nchaotic mess of all: the distributed big ball of mud.\n\nIn Part II, we'll show how the techniques from <<part1>> can be extended to\ndistributed systems. We'll zoom out to look at how we can compose a system from\nmany small components that interact through asynchronous message passing.\n\nWe'll see how our Service Layer and Unit of Work patterns allow us to reconfigure our app\nto run as an asynchronous message processor, and how event-driven systems help\nus to decouple aggregates and applications from one another.\n\n[[allocation_context_diagram_again]]\n.But exactly how will all these systems talk to each other?\nimage::images/apwp_0102.png[]\n\n\n// TODO: DS - this might give the impression that the whole of part 2\n// is irrelevant for readers in a monolith context\n\n//IDEA (DS): It seems to me the two key themes in this book are vertical and\n//horizontal decoupling. Did you consider choosing those for the two parts?\n\nWe'll look at the following patterns and techniques:\n\nDomain Events::\n  Trigger workflows that cross consistency boundaries.\n\nMessage Bus::\n  Provide a unified way of invoking use cases from any endpoint.\n\nCQRS::\n  Separating reads and writes avoids awkward compromises in an event-driven\n  architecture and enables performance and scalability improvements.\n\nPlus, we'll add a dependency injection framework. This has nothing to do with\nevent-driven architecture per se, but it tidies up an awful lot of loose\nends.\n\n// IDEA: a bit of blurb about making events more central to our design thinking?\n"
        },
        {
          "name": "plantuml.cfg",
          "type": "blob",
          "size": 1.0546875,
          "content": "skinparam default {\n    FontName Guardian Sans Cond Regular\n    FontSize 18\n    FontColor Black\n}\n\nskinparam class {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\n\nskinparam CircledCharacter {\n    FontColor Black\n}\n\nskinparam stereotypeC {\n    BackgroundColor #eddea4 \n}\n\nskinparam package {\n    FontName Guardian Sans Cond Light\n}\n\nskinparam sequencelifeline {\n    BorderColor #0fa3b1\n}\nskinparam arrow {\n    Color #0fa3b1\n}\nskinparam participant {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam entity {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam collections {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam database {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam boundary {\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam actor {\n    Color DeepSkyBlue\n    BackgroundColor #b5e2fa\n    BorderColor #0fa3b1\n}\nskinparam sequencegroupheader {\n    FontName Guardian Sans Cond Light\n}\nskinparam sequencebox {\n    BackgroundColor PowderBlue\n    BorderColor #0fa3b1\n}\nskinparam padding 4\n"
        },
        {
          "name": "preface.asciidoc",
          "type": "blob",
          "size": 17.61328125,
          "content": "[[preface]]\n[preface]\n== Preface\n\nYou may be wondering who we are and why we wrote this book.\n\nAt the end of Harry's last book,\nhttp://www.obeythetestinggoat.com[_Test-Driven Development with Python_] (O'Reilly),\nhe found himself asking a bunch of questions about architecture, such as,\nWhat's the best way of structuring your application so that it's easy to test?\nMore specifically, so that your core business logic is covered by unit tests,\nand so that you minimize the number of integration and end-to-end tests you need?\nHe made vague references to \"Hexagonal Architecture\" and \"Ports and Adapters\"\nand \"Functional Core, Imperative Shell,\" but if he was honest, he'd have to\nadmit that these weren't things he really understood or had done in practice.\n\nAnd then he was lucky enough to run into Bob, who has the answers to all these\nquestions.\n\nBob ended up as a software architect because nobody else on his team was\ndoing it. He turned out to be pretty bad at it, but _he_ was lucky enough to run\ninto Ian Cooper, who taught him new ways of writing and thinking about code.\n\n=== Managing Complexity, Solving Business Problems\n\nWe both work for MADE.com, a European ecommerce company that sells furniture\nonline; there, we apply the techniques in this book to build distributed systems\nthat model real-world business problems. Our example domain is the first system\nBob built for MADE, and this book is an attempt to write down all the _stuff_ we\nhave to teach new programmers when they join one of our teams.\n\nMADE.com operates a global supply chain of freight partners and manufacturers.\nTo keep costs low, we try to optimize the delivery of stock to our\nwarehouses so that we don't have unsold goods lying around the place.\n\nIdeally, the sofa that you want to buy will arrive in port on the very day\nthat you decide to buy it, and we'll ship it straight to your house without\never storing it. [.keep-together]#Getting# the timing right is a tricky balancing act when goods take\nthree months to arrive by container ship. Along the way, things get broken or water\ndamaged, storms cause unexpected delays, logistics partners mishandle goods,\npaperwork goes missing, customers change their minds and amend their orders,\nand so on.\n\nWe solve those problems by building intelligent software representing the\nkinds of operations taking place in the real world so that we can automate as\nmuch of the business as possible.\n\n=== Why Python?\n\nIf you're reading this book, we probably don't need to convince you that Python\nis great, so the real question is \"Why does the _Python_ community need a book\nlike this?\" The answer is about Python's popularity and maturity: although Python is\nprobably the world's fastest-growing programming language and is nearing the top\nof the absolute popularity tables, it's only just starting to take on the kinds\nof problems that the C# and Java world has been working on for years.\nStartups become real businesses; web apps and scripted automations are becoming\n(whisper it) _enterprise_ [.keep-together]#_software_#.\n\nIn the Python world, we often quote the Zen of Python:\n\"There should be one--and preferably only one--obvious way to do it.\"footnote:[`python -c \"import this\"`]\nUnfortunately, as project size grows, the most obvious way of doing things\nisn't always the way that helps you manage complexity and evolving\nrequirements.\n\nNone of the techniques and patterns we discuss in this book are\nnew, but they are mostly new to the Python world. And this book isn't\na replacement for the classics in the field such as Eric Evans's\n_Domain-Driven Design_\nor Martin Fowler's _Patterns of\nEnterprise Application Architecture_ (both published by Addison-Wesley [.keep-together]#Professional#)—which we often refer to and\nencourage you to go and read.\n\nBut all the classic code examples in the literature do tend to be written in\nJava or pass:[<span class=\"keep-together\">C++/#</span>], and if you're a Python person and haven't used either of\nthose languages in a long time (or indeed ever), those code listings can be\nquite...trying. There's a reason the latest edition of that other classic text, Fowler's\n_Refactoring_ (Addison-Wesley Professional), is in JavaScript.\n\n[role=\"pagebreak-before less_space\"]\n=== TDD, DDD, and Event-Driven Architecture\n\nIn order of notoriety, we know of three tools for managing complexity:\n\n1. _Test-driven development_ (TDD) helps us to build code that is correct\n   and enables us to refactor or add new features, without fear of regression.\n   But it can be hard to get the best out of our tests: How do we make sure\n   that they run as fast as possible? That we get as much coverage and feedback\n   from fast, dependency-free unit tests and have the minimum number of slower,\n   flaky end-to-end tests?\n\n2. _Domain-driven design_ (DDD) asks us to focus our efforts on building a good\n   model of the business domain, but how do we make sure that our models aren't\n   encumbered with infrastructure concerns and don't become hard to change?\n\n3. Loosely coupled (micro)services integrated via messages (sometimes called\n   _reactive microservices_) are a well-established answer to managing complexity\n   across multiple applications or business domains. But it's not always\n   obvious how to make them fit with the established tools of\n   the Python world--Flask, Django, Celery, and so on.\n\nNOTE: Don't be put off if you're not working with (or interested in) microservices.\n    The vast majority of the patterns we discuss,\n    including much of the event-driven architecture material,\n    is absolutely applicable in a monolithic architecture.\n\nOur aim with this book is to introduce several classic architectural patterns\nand show how they support TDD, DDD, and event-driven services.  We hope\nit will serve as a reference for implementing them in a Pythonic way, and that\npeople can use it as a first step toward further research  in this field.\n\n\n=== Who Should Read This Book\n\nHere are a few things we assume about you, dear reader:\n\n* You've been close to some reasonably complex Python applications.\n\n* You've seen some of the pain that comes with trying to manage\n  that complexity.\n\n* You don't necessarily know anything about DDD or any of the\n  classic application architecture patterns.\n\nWe structure our explorations of architectural patterns around an example app,\nbuilding it up chapter by chapter. We use TDD at\nwork, so we tend to show listings of tests first, followed by implementation.\nIf you're not used to working test-first, it may feel a little strange at\nthe beginning, but we hope you'll soon get used to seeing code \"being used\"\n(i.e., from the outside) before you see how it's built on the inside.\n\nWe use some specific Python frameworks and technologies, including Flask,\nSQLAlchemy, and pytest, as well as Docker and Redis. If you're already\nfamiliar with them, that won't hurt, but we don't think it's required.  One of\nour main aims with this book is to build an architecture for which specific\ntechnology choices become minor implementation details.\n\n=== A Brief Overview of What You'll Learn\n\nThe book is divided into two parts; here's a look at the topics we'll cover\nand the chapters they live in.\n\n==== pass:[<a data-type=\"xref\" data-xrefstyle=\"chap-num-title\" href=\"#part1\">#part1</a>]\n\nDomain modeling and DDD (Chapters <<chapter_01_domain_model,1>>, <<chapter_02_repository,2>> and <<chapter_07_aggregate,7>>)::\n    At some level, everyone has learned the lesson that complex business\n    problems need to be reflected in code, in the form of a model of the domain.\n    But why does it always seem to be so hard to do without getting tangled\n    up with infrastructure concerns, our web frameworks, or whatever else?\n    In the first chapter we give a broad overview of _domain modeling_ and DDD, and we\n    show how to get started with a model that has no external dependencies, and\n    fast unit tests. Later we return to DDD patterns to discuss how to choose\n    the right aggregate, and how this choice relates to questions of data\n    integrity.\n\nRepository, Service Layer, and Unit of Work patterns (Chapters <<chapter_02_repository,2>>, <<chapter_04_service_layer,4>>, and <<chapter_05_high_gear_low_gear,5>>)::\n    In these three chapters we present three closely related and\n    mutually reinforcing patterns that support our ambition to keep\n    the model free of extraneous dependencies.  We build a layer of\n    abstraction around persistent storage, and we build a service\n    layer to define the entrypoints to our system and capture the\n    primary use cases. We show how this layer makes it easy to build\n    thin entrypoints to our system, whether it's a Flask API or a CLI.\n\n// [SG] Bit of pedantry - this is the first time you have used CLI acronym,\n// should be spelled out?\n\nSome thoughts on testing and abstractions (Chapter <<chapter_03_abstractions,3>> and <<chapter_05_high_gear_low_gear,5>>)::\n    After presenting the first abstraction (the Repository pattern), we take the\n    opportunity for a general discussion of how to choose abstractions, and\n    what their role is in choosing how our software is coupled together. After\n    we introduce the Service Layer pattern, we talk a bit about achieving a _test pyramid_\n    and writing unit tests at the highest possible level of abstraction.\n\n\n\n==== pass:[<a data-type=\"xref\" data-xrefstyle=\"chap-num-title\" href=\"#part2\">#part2</a>]\n\nEvent-driven architecture (Chapters <<chapter_08_events_and_message_bus,8>>-<<chapter_11_external_events,11>>)::\n    We introduce three more mutually reinforcing patterns:\n    the Domain Events, Message Bus, and Handler patterns.\n    _Domain events_ are a vehicle for capturing the idea that\n    some interactions with a system are triggers for others.\n    We use  a _message bus_ to allow actions to trigger events\n    and call appropriate _handlers_.\n    We move on to discuss how events can be used as a pattern\n    for integration between services in a microservices architecture.\n    Finally, we distinguish between _commands_ and _events_.\n    Our application is now fundamentally a message-processing system.\n\nCommand-query responsibility segregation (<<chapter_12_cqrs>>)::\n    We present an example of _command-query responsibility segregation_,\n    with and without events.\n\nDependency injection (<<chapter_13_dependency_injection>>)::\n    We tidy up our explicit and implicit dependencies and implement a\n    simple dependency injection framework.\n\n\n==== Additional Content\n\nHow do I get there from here? (<<epilogue_1_how_to_get_there_from_here>>)::\n    Implementing architectural patterns always looks easy when you show a simple\n    example, starting from scratch, but many of you will probably be wondering how\n    to apply these principles to existing software. We'll provide a\n    few pointers in the epilogue and some links to further reading.\n\n\n\n=== Example Code and Coding Along\n\nYou're reading a book, but you'll probably agree with us when we say that\nthe best way to learn about code is to code.  We learned most of what we know\nfrom pairing with people, writing code with them, and learning by doing, and\nwe'd like to re-create that experience as much as possible for you in this book.\n\nAs a result, we've structured the book around a single example project\n(although we do sometimes throw in other examples). We'll build up this project as the chapters progress, as if you've paired with us and\nwe're explaining what we're doing and why at each step.\n\nBut to really get to grips with these patterns, you need to mess about with the\ncode and get a feel for how it works. You'll find all the code on\nGitHub; each chapter has its own branch. You can find https://github.com/cosmicpython/code/branches/all[a list] of the branches on GitHub as well.\n\n[role=\"pagebreak-before\"]\nHere are three ways you might code along with the book:\n\n* Start your own repo and try to build up the app as we do, following the\n  examples from listings in the book, and occasionally looking to our repo\n  for hints. A word of warning, however: if you've read Harry's previous book\n  and coded along with that, you'll find that this book requires you to figure out more on\n  your own; you may need to lean pretty heavily on the working versions on GitHub.\n\n* Try to apply each pattern, chapter by chapter, to your own (preferably\n  small/toy) project, and see if you can make it work for your use case.  This\n  is high risk/high reward (and high effort besides!). It may take quite some\n  work to get things working for the specifics of your project, but on the other\n  hand, you're likely to learn the most.\n\n* For less effort, in each chapter we outline an \"Exercise for the Reader,\"\n  and point you to a GitHub location where you can download some partially finished\n  code for the chapter with a few missing parts to write yourself.\n\nParticularly if you're intending to apply some of these patterns in your own\nprojects, working through a simple example is a great way to\nsafely practice.\n\nTIP: At the very least, do a `git checkout` of the code from our repo as you\n    read each chapter. Being able to jump in and see the code in the context of\n    an actual working app will help answer a lot of questions as you go, and\n    makes everything more real. You'll find instructions for how to do that\n    at the beginning of each chapter.\n\n\n=== License\n\nThe code (and the online version of the book) is licensed under a Creative\nCommons CC BY-NC-ND license, which means you are free to copy and share it with\nanyone you like, for non-commercial purposes, as long as you give attribution.\nIf you want to re-use any of the content from this book and you have any\nworries about the license, contact O'Reilly at pass:[<a class=\"email\"\nhref=\"mailto:permissions@oreilly.com\"><em>permissions@oreilly.com</em></a>].\n\nThe print edition is licensed differently; please see the copyright page.\n\n\n=== Conventions Used in This Book\n\nThe following typographical conventions are used in this book:\n\n_Italic_:: Indicates new terms, URLs, email addresses, filenames, and file extensions.\n\n+Constant width+:: Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.\n\n**`Constant width bold`**:: Shows commands or other text that should be typed literally by the user.\n\n_++Constant width italic++_:: Shows text that should be replaced with user-supplied values or by values determined by context.\n\n\n[TIP]\n====\nThis element signifies a tip or suggestion.\n====\n\n[NOTE]\n====\nThis element signifies a general note.\n====\n\n[WARNING]\n====\nThis element indicates a warning or caution.\n====\n\n=== O'Reilly Online Learning\n\n[role = \"ormenabled\"]\n[NOTE]\n====\nFor more than 40 years, pass:[<a href=\"http://oreilly.com\" class=\"orm:hideurl\"><em class=\"hyperlink\">O’Reilly Media</em></a>] has provided technology and business training, knowledge, and insight to help companies succeed.\n====\n\nOur unique network of experts and innovators share their knowledge and expertise through books, articles, conferences, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O'Reilly and 200+ other publishers. For more information, please visit pass:[<a href=\"http://oreilly.com\" class=\"orm:hideurl\"><em>http://oreilly.com</em></a>].\n\n=== How to Contact O'Reilly\n\nPlease address comments and questions concerning this book to the publisher:\n\n++++\n<ul class=\"simplelist\">\n  <li>O’Reilly Media, Inc.</li>\n  <li>1005 Gravenstein Highway North</li>\n  <li>Sebastopol, CA 95472</li>\n  <li>800-998-9938 (in the United States or Canada)</li>\n  <li>707-829-0515 (international or local)</li>\n  <li>707-829-0104 (fax)</li>\n</ul>\n++++\n\nWe have a web page for this book, where we list errata, examples, and any additional information. You can access this page at https://oreil.ly/architecture-patterns-python[].\n\n++++\n<!--Don't forget to update the link above.-->\n++++\n\nEmail pass:[<a class=\"email\" href=\"mailto:bookquestions@oreilly.com\"><em>bookquestions@oreilly.com</em></a>] to comment or ask technical questions about this book.\n\nFor more information about our books, courses, conferences, and news, see our website at link:$$http://www.oreilly.com$$[].\n\nFind us on Facebook: link:$$http://facebook.com/oreilly$$[]\n\nFollow us on Twitter: link:$$http://twitter.com/oreillymedia$$[]\n\nWatch us on YouTube: link:$$http://www.youtube.com/oreillymedia$$[]\n\n=== Acknowledgments\n\nTo our tech reviewers, David Seddon, Ed Jung, and Hynek Schlawack: we absolutely\ndo not deserve you. You are all incredibly dedicated, conscientious, and\nrigorous. Each one of you is immensely smart, and your different points of\nview were both useful and complementary to each other. Thank you from the\nbottom of our hearts.\n\nGigantic thanks also to all our readers so far for their comments and\nsuggestions:\nIan Cooper, Abdullah Ariff, Jonathan Meier, Gil Gonçalves, Matthieu Choplin,\nBen Judson, James Gregory, Łukasz Lechowicz, Clinton Roy, Vitorino Araújo,\nSusan Goodbody, Josh Harwood, Daniel Butler, Liu Haibin, Jimmy Davies, Ignacio\nVergara Kausel, Gaia Canestrani, Renne Rocha, pedroabi, Ashia Zawaduk, Jostein\nLeira, Brandon Rhodes, Jazeps Basko, simkimsia, Adrien Brunet, Sergey Nosko,\nDmitry Bychkov, dayres2, programmer-ke, asjhita,\nand many more; our apologies if we missed you on this list.\n\nSuper-mega-thanks to our editor Corbin Collins for his gentle chivvying, and\nfor being a tireless advocate of the reader. Similarly-superlative thanks to\nthe production staff, Katherine Tozer, Sharon Wilkey, Ellen Troutman-Zaig, and\nRebecca Demarest, for your dedication, professionalism, and attention to\ndetail. This book is immeasurably improved thanks to you.\n\n// TODO thanks to rest of OR team.\n\nAny errors remaining in the book are our own, naturally.\n"
        },
        {
          "name": "print_figure_numbers_xref_to_image_filenames.py",
          "type": "blob",
          "size": 0.5009765625,
          "content": "#!/usr/bin/env python\nfrom pathlib import Path\nimport re\n\nfor path in sorted(Path(__file__).absolute().parent.glob('*.asciidoc')):\n    images = re.findall(r'::images/(\\w+\\.png)', path.read_text())\n    if not images:\n        continue\n    chapter_no = re.search(r'chapter_(\\d\\d)', str(path))\n    if chapter_no:\n        chapter_no = str(int(chapter_no.group(1)))\n    else:\n        chapter_no = '??'\n    print(path.name)\n    for ix, image in enumerate(images):\n        print(f'  Figure {chapter_no}.{ix+1}: {image}')\n"
        },
        {
          "name": "proposal.md",
          "type": "blob",
          "size": 10.23828125,
          "content": "# Proposed Book Title:\n\n* The Clean Architecture in Python?\n* Ports and Adapters with Python?\n* Enterprise Design Patterns in Python?\n* Enterprise Software Architecture in Python?\n* Software Architecture in Python?\n\n## Proposed Book Subtitle: \n\n*How to apply DDD, Ports and Adapters and more enterprise architecture design patterns in a Pythonic way.*\n\n# Author(s): \n\nBob Gregory, Harry Percival\n\n> Author title(s) and affiliation(s):\n\nLead Architect and Software Developer (respectively) at MADE.com\n\n> Preferred mailing address(es): \n> Preferred phone number: \n> Preferred Email address(es):\nharry.percival@gmail.com, bob.gregory@made.com\n> Author Platform details:\n> Author biography and LinkedIn profile: \n\nhttps://uk.linkedin.com/in/harry-percival-588a35\nhttps://uk.linkedin.com/in/bobthemighty\n\n\n> Author public speaking samples (YouTube, etc.):\n\nhttps://www.youtube.com/watch?v=tFalO9KdCDM\nhttps://skillsmatter.com/skillscasts/12182-event-sourcing-101\n\n> Author Web site/blog/Twitter: \n\nhttps://io.made.com/\nhttp://www.obeythetestinggoat.com/\n\n\n# Why are you the best person to write this book?\n\nHarry has already written one excellent Python book for O'Reilly,  this will make a nice sequel (in fact it covers some of the further reading subjects suggested in the final chapter of said book).\nBob knows more than Harry about the subject matter though.\n\n\n# Book Summary:\n\n> In one sentence, tell us why the audience will want to buy your book.\n\nThe Python world is increasingly interested in software architecture and design, and there are no good Python-specific books on the topic yet.\n\n\n> Summarize what the book is about, like you would pitch it to a potential reader on the back cover.  What makes your book unique in the marketplace?\n\nAs Python grows in popularity as a language, typical projects are getting larger and more complex, and issues of software design and architecture become more salient.  Patterns like \"Ports and Adapters\", as well Domain-Driven Design, Event-Driven programming, Command-Query Responsibility Segregation, which are well known in more \"enterprisey\" communities like Java and C#, are generating more interest in the Python community, but it's not always easy to see how these patterns translate into Python.  (reviewing the classic \"Gang of Four\" design patterns book for example leads to the conclusion that half the patterns are artifacts of the Java/C++ syntax, and are simply not necessary in the more flexible and dynamic world of Python).\n\nIn the Python world, we often quote the Zen of Python:  \"there should be one--preferably on only one--obvious way to do it\".  Unfortunately, as project complexity grows, the most obvious way of doing things isn't always the way that helps you manage complexity and evolving requirements.\n\nThis book will provide an introduction to proven architectural design patterns that help you manage complexity, using concrete examples written in Python. It will explain how to avoid some of the unnecessary particularities of Java and C# syntax and implement these patterns in a \"Pythonic\" way.\n\n\n# Technology summary.\n\n> How would you characterize the technology’s stage of development? (Put an X in the column next to the stage that best applies.)\n\nIn the enterprise world: mature.  In the Python world: developing.\n\n\n> Briefly explain the technology and why it is important.\n\nDesign patterns and software architecture are well established topics in the enterprise software development world, but much less so in the Python world.  As Python matures, translating these topics across is becoming more and more important.\n\n\n\n# Audience:\n\n> Explain who the primary audience is for your book. What professional positions does this audience hold? What knowledge do you assume of this audience? What books can you assume they have read? What skills can you assume they have mastered?\n\nThis is an intermediate-level book.  It will be of interest to anyone working on codebases of more than moderate complexity, and anyone with an interest in applying architectural patterns common in the C#/Java world to Python.  It will also be of interest to software architects and developers coming from those communities and looking to adapt to the Python world.  Finally the aim will be to make this the most accessible, engaging, and concrete introduction to the architectural concepts involved, such that programmers from any background will turn to it as a first resource.\n\nThese people might have read:\n\n- my first book, and be wondering where to go next\n- classics like the Evans or Vernon DDD books, or Martin Fowler's \"Patterns of Enterprise Application Architecture\", and be wondering how to translate those concepts to the Python world\n\n> Please estimate as best you can how many people will use this technology? Please state any applicable statistics (e.g., web searches, web site traffic, blogs) indicating market use or market growth.\n\nHard to say.  salesrank data from amazon suggest books like \"Buiding evolutionary architectures\" (O'Reilly, https://www.novelrank.com/asin/1491986360) and \"Patterns of Enterprise Application Architecture\" (a classic, https://www.novelrank.com/asin/0321127420) are selling well (compared to my existing book lol)\n\nOther than that, informally, several people have reached out to us in response to our existing 5-part blog post series on the made.com blog, saying how much they'd like to see that content extended to book length, and complaining about the lack of similar resources in the Python world\n\n\n\n> Please provide some scenarios that indicate how the audience will use your book. For example, will readers refer to it daily as a reference? Will they read it once to learn the concepts and then refer to it occasionally?\n\nI expect most readers will read it all the way through once.  Some may decide to follow along with the code examples in some or all of the chapters.  Then, they are likely to come back and look at the code examples in more detail as they come to try and implement the various patterns in their day-to-day jobs.\n\n> Use the following table to describe how the audience for your book typically gets information and where it looks for guidance and leadership (list top five choices).\n\n> What web sites or blogs do they read?\n\nmy blog, hacker news, /r/python, the made blog, follow on twitter bernhardt, fowler, beck, uncle martin...\n \n> What publications do they read (e.g., magazines, journals, newspapers)?\n\nsee above.\n \n> What conferences do they attend?\n\npycon(s), oreilly software architecture conference, oscon, fosdem, \n \n \n> Who are the leaders and key influencers in the field who would review or endorse your book?\n\nI could reach out via some contacts at Thoughtworks to see if Martin Fowler might give it a read.  That would be a great name to have on the cover.\n\nIn the Python world, Harry's existing Python contacts should be prepared to take a look -- Kenneth Reitz, Gary Bernhanrdt, Michael Foord.\n\n \n \n\n\n# Key Topic Coverage:\n\n> What are the top five topics that will be covered in the book? Why are they the top five?\n\n- the dependency inversion principle\n- ports and adapters\n- domain-driven design (DDD)\n- CQRS (command/query responsibility segregation)\n- event-driven architectures (and link to microservices)\n\nThese are the most popular and recognisable words that people will recognise or have heard of, and appreciate seeing a concrete illustration and discussion of, in the Python world.\n\n> What problems does this book solve for its users?\n\n- How do I deal with increasing complexity as my application grows?\n- How can I learn about enterprise software design principles without wading through overcomplicated Java/C++ syntax?\n- Where can I find concrete examples rather than abstract discussion?\n\n> List the four or five topics covered or features included that will provide the greatest benefit to readers or will be the most likely to excite them? \n\nsee above, plus:\n\n- How do I separate my domain model from infrastructure and integration layers?\n- Concretely, what is a Port and what is an Adapter in Python?  Does the distinction matter?\n- What are the expected benefits of this sort of architecture?  When is it worth implementing?\n- How do these patterns complement a microservices approach?\n\n> SEO terms for topics covered:\n\nsee bullets above, plus \"clean architecture\", \"hexagonal architecture\", \"functional core imperative shell\",...\n\n\n# Other Book Features and Video Offerings:\n\n> Is there a companion web site? If so, what do you plan to include on the site? Would you be willing to participate in video offerings as well as workshops and training seminars?\n\n- a website with access to source code examples, and follow-on blog posts and materials is likely.\n- it could also include \"alternative implementations\" showing some other ways of achieving the same goals, compared to the examples given in the book.\n- not entirely sure that video is the right medium for getting these kinds of concepts across, but up for trying.\n\n\n\n# Competition:\n\n> What books or online resources compete with this book? Please list the title and author. In each case, how will your book be different or better in timing, content, coverage, approach, or tone?\n\n<research some books and provide their PageRank?>\n\nDDD book?\npatterns of enteprise arch?\n\n\n\n# Book Outline (old):\n\n1. the simple approach\n2. domain model\n3. dependency injection and inversion of control\n4. persistence and unit of work\n5. commands & events, handlers, message bus\n6. (ports and) adapters\n7. command-query separation.\n8. the proof is in the pudding 1: implementing a new feature\n9. the proof is in the pudding 2: refactoring an infrastructure layer\n10. comparison with the simple approach\n11. conclusions: when to use these patterns\nA. appendix: functional core, imperative shell\nB. appendix: more design patterns\nC. alternatives\n\n\n# Specs and Schedule:\n\n> How many pages do you expect the book to be?\n200-250?\n\n> What use you will make of illustrations or screenshots? Approximately how many illustrations do you anticipate using?\n\nSeveral code listings per chapter, and maybe a few diagrams which we can produce ourselves...\n\n> What special considerations apply to your plans for the book, including unusual format, use of color, hard-to-get illustrations, or anything else calling for unusual resources?\n\nnothing extraordinary is anticipated\n \n> When do you anticipate delivering a complete draft of the manuscript or technical review?\n\n9 months' time?\n\n"
        },
        {
          "name": "push-branches.py",
          "type": "blob",
          "size": 1.1044921875,
          "content": "#!/usr/bin/env python\n\nimport subprocess\nfrom pathlib import Path\nfrom chapters import CHAPTERS, NO_EXERCISE, STANDALONE\n\nprocesses = []\n\nfor chapter in CHAPTERS + STANDALONE:\n    print('pushing', chapter)\n    processes.append(subprocess.Popen(\n        ['git', 'push', '-v', '--force-with-lease', 'origin', chapter],\n        cwd=Path(__file__).parent / 'code',\n        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n    ))\n    if chapter in NO_EXERCISE:\n        continue\n    exercise_branch = f'{chapter}_exercise'\n    print('pushing', exercise_branch)\n    processes.append(subprocess.Popen(\n        ['git', 'push', '-v', '--force-with-lease', 'origin', exercise_branch],\n        cwd=Path(__file__).parent / 'code',\n        stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n    ))\n\nprint('pushing master')\nprocesses.append(subprocess.Popen(\n    ['git', 'push', '-v', '--force-with-lease', 'origin', 'master'],\n    cwd=Path(__file__).parent / 'code',\n    stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True,\n))\n\nfor p in processes:\n    stdout, stderr = p.communicate()\n    print(stdout)\n    print(stderr)\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.029296875,
          "content": "[pytest]\naddopts = --tb=short\n"
        },
        {
          "name": "rebase-appendices.sh",
          "type": "blob",
          "size": 0.138671875,
          "content": "#/bin/bash\nset -ex\n\ncd code\ngit co appendix_django\ngit irebase chapter_06_uow\n\ngit co appendix_csvs\ngit irebase chapter_06_uow\n\ngit co master\n"
        },
        {
          "name": "rebase-chapters.sh",
          "type": "blob",
          "size": 0.2255859375,
          "content": "#/bin/bash\nset -ex\n\nif [[ $# -eq 0 ]] ; then\n    echo 'need commit to rebase from'\n    exit 0\nfi\n\ncd code\ngit co chapter_13_dependency_injection\ngit irebase $1\n\ngit co master\ngit reset --hard chapter_13_dependency_injection\n\ncd ..\n"
        },
        {
          "name": "render-diagrams.py",
          "type": "blob",
          "size": 2.5439453125,
          "content": "#!/usr/bin/env python3\nimport re\nimport sys\nimport tempfile\nimport subprocess\nfrom pathlib import Path\nfrom lxml import html\n\nIMAGES_DIR = Path(__file__).absolute().parent / 'images'\n\n\ndef all_chapter_names():\n    for fn in sorted(Path(__file__).absolute().parent.glob('*.html')):\n        chapter_name = fn.name.replace('.html', '')\n        if chapter_name == 'book':\n            continue\n        yield chapter_name\n\ndef main(paths):\n    print(paths)\n    if paths:\n        chapter_names = [p.replace('.html', '').replace('.asciidoc', '') for p in paths]\n    else:\n        chapter_names = all_chapter_names()\n    for chapter_name in chapter_names:\n        render_images(chapter_name)\n\n\ndef render_images(chapter_name):\n    print('Rendering images for', chapter_name)\n    raw_contents = Path(f'{chapter_name}.html').read_text()\n    parsed_html = html.fromstring(raw_contents)\n\n    for image_block in parsed_html.cssselect('.imageblock'):\n        [img] = image_block.cssselect('img')\n        image_id = img.get('src').replace('images/', '').replace('.png', '')\n        print(image_id)\n\n        parent = image_block.getparent()\n        next_sibling_pos = parent.index(image_block) + 1\n        try:\n            next_element = parent[next_sibling_pos]\n        except IndexError:\n            continue\n        if 'image-source' in next_element.classes:\n            code = next_element.cssselect('pre')[0].text\n            render_image(code, image_id)\n\nINCLUDES = [\n    'images/C4_Context.puml',\n    'images/C4_Component.puml',\n]\n\ndef _add_dots(source, image_id):\n    lines = source.splitlines()\n    assert lines[0].startswith('[')\n    assert image_id in lines[0]\n    plantuml_cfg = str(Path('plantuml.cfg').absolute())\n    lines[0] = lines[0].replace('config=plantuml.cfg', f'config={plantuml_cfg}')\n    lines[0] = re.sub(r'\\[ditaa, (\\w+)\\]', r'[ditaa, \\1, scale=4]', lines[0])\n    for ix, l in enumerate(lines):\n        if include := next((i for i in INCLUDES if i in l), None):\n            lines[ix] = l.replace(include, str(Path(include).absolute()))\n    lines.insert(1, '....')\n    lines.append('....')\n    return '\\n'.join(lines)\n\n\ndef render_image(source, image_id):\n    source = _add_dots(source, image_id)\n    print(source)\n    target = Path(f'images/{image_id}.png')\n    if target.exists():\n        target.unlink()\n    tf = Path(tempfile.NamedTemporaryFile().name)\n    tf.write_text(source)\n    cmd = ['asciidoctor', '-r', 'asciidoctor-diagram', '-a', f'imagesoutdir={IMAGES_DIR}', str(tf)]\n    print(' '.join(cmd))\n    subprocess.run(cmd, check=True)\n\n\nif __name__ == '__main__':\n    main(sys.argv[1:])\n"
        },
        {
          "name": "renumber-chapters.py",
          "type": "blob",
          "size": 1.779296875,
          "content": "#!/usr/bin/env python\nimport subprocess\nfrom pathlib import Path\n\nMOVES = [\n    # change these as desired\n    ('chapter_04b_high_gear_low_gear', 'chapter_05_high_gear_low_gear'),\n    ('chapter_05_uow', 'chapter_06_uow'),\n    ('chapter_06_aggregate', 'chapter_07_aggregate'),\n    (\"chapter_07_events_and_message_bus\", \"chapter_08_events_and_message_bus\"),\n    (\"chapter_08_all_messagebus\", \"chapter_09_all_messagebus\"),\n    (\"chapter_09_commands\", \"chapter_10_commands\"),\n    (\"chapter_10_external_events\", \"chapter_11_external_events\"),\n    (\"chapter_11_cqrs\", \"chapter_12_cqrs\"),\n    (\"chapter_12_dependency_injection\", \"chapter_13_dependency_injection\"),\n]\n\nfor frm, to in MOVES:\n    subprocess.run(['git', 'mv', f'{frm}.asciidoc', f'{to}.asciidoc'], check=True)\n\nsources = list(Path(__file__).absolute().parent.glob('*.asciidoc'))\notherthings = [\n    'chapters.py',\n    'atlas.json',\n    'Readme.md',\n    'rebase-chapters.sh',\n    'rebase-appendices.sh',\n]\nfor frm, to in MOVES:\n    subprocess.run(\n        ['sed', '-i', f's/{frm}/{to}/g'] + sources + otherthings,\n        check=True,\n    )\n\ninput('base repo done, ready to do submodules')\n\nfor frm, to in MOVES:\n    code = Path(__file__).absolute().parent / 'code'\n    subprocess.run(['git', 'branch', '-m', frm, to], cwd=code)\n    subprocess.run(['git', 'branch', '--unset-upstream', to], cwd=code) # untested\n    subprocess.run(['git', 'push', 'origin', f':{frm}'], cwd=code)\n    subprocess.run(['git', 'checkout', to], cwd=code)\n    subprocess.run(['git', 'push', '-u', 'origin', to], cwd=code)\n    from chapters import NO_EXERCISE\n    if to not in NO_EXERCISE:\n        # untested\n        subprocess.run(\n            ['git', 'branch', '-m', f'{frm}_exercise', f'{to}_exercise'],\n            cwd=code, check=True,\n        )\n\n    input(f'{frm}->{to} done in theory')\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.064453125,
          "content": "lxml\ncssselect\npytest-icdiff\npylint\nmypy\n-r code/requirements.txt\n"
        },
        {
          "name": "reset-exercise-branches.py",
          "type": "blob",
          "size": 0.697265625,
          "content": "#!/usr/bin/env python\nimport subprocess\nfrom pathlib import Path\nfrom chapters import CHAPTERS\n\n\ndef run(cmds):\n    print(' '.join(cmds))\n    p = subprocess.run(\n        cmds,\n        cwd=Path(__file__).parent / 'code',\n        capture_output=True,\n    )\n    if p.returncode:\n        raise Exception(p.stderr.decode())\n    output = p.stdout.decode()\n    print(output)\n    return output\n\n\nall_branches = run(['git', 'branch', '-a'],)\n\nfor chapter in CHAPTERS:\n    exercise_chapter = f'{chapter}_exercise'\n    if exercise_chapter not in all_branches:\n        continue\n    run(['git', 'checkout', exercise_chapter])\n    run(['git', 'reset', '--hard', f'origin/{exercise_chapter}'])\nrun(['git', 'checkout', 'master'])\n"
        },
        {
          "name": "tests.py",
          "type": "blob",
          "size": 7.2333984375,
          "content": "# pylint: disable=redefined-outer-name\nimport re\nimport subprocess\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom lxml import html\nimport pytest\nfrom chapters import CHAPTERS, BRANCHES, STANDALONE, NO_EXERCISE\n\n\n\ndef all_branches():\n    return subprocess.run(\n        ['git', 'branch', '-a'],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    ).stdout.decode().split()\n\ndef git_log(chapter):\n    return subprocess.run(\n        ['git', 'log', chapter, '--oneline', '--decorate'],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    ).stdout.decode()\n\n@pytest.fixture(scope='session')\ndef master_log():\n    return git_log('master')\n\n@pytest.mark.parametrize('chapter', CHAPTERS)\ndef test_master_has_all_chapters_in_its_history(master_log, chapter):\n    if chapter in BRANCHES:\n        return\n    assert f'{chapter})' in master_log\n\n@pytest.mark.parametrize('chapter', CHAPTERS)\ndef test_exercises_for_reader(chapter):\n    exercise_branch = f'{chapter}_exercise'\n    branches = all_branches()\n    if chapter in NO_EXERCISE:\n        if exercise_branch in branches:\n            pytest.fail(f'looks like there is an exercise for {chapter} after all!')\n        else:\n            pytest.xfail(f'{chapter} has no exercise yet')\n        return\n    assert exercise_branch in branches\n    assert f'{chapter})' in git_log(exercise_branch), f'Exercise for {chapter} not up to date'\n\ndef previous_chapter(chapter):\n    chapter_no = CHAPTERS.index(chapter)\n    if chapter_no == 0:\n        return None\n    previous = CHAPTERS[chapter_no - 1]\n    if previous in BRANCHES:\n        previous = CHAPTERS[chapter_no - 2]\n    return previous\n\n@pytest.mark.parametrize('chapter', CHAPTERS)\ndef test_each_chapter_follows_the_last(chapter):\n    previous = previous_chapter(chapter)\n    if previous is None:\n        return\n    assert f'{previous})' in git_log(chapter), f'{chapter} did not follow {previous}'\n\n\n@pytest.mark.parametrize('chapter', CHAPTERS + STANDALONE)\ndef test_chapter(chapter):\n    for listing in parse_listings(chapter):\n        check_listing(listing, chapter)\n\n\n@contextmanager\ndef checked_out(chapter):\n    subprocess.run(\n        ['git', 'checkout', f'{chapter}'],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    )\n    try:\n        yield\n\n    finally:\n        subprocess.run(\n            ['git', 'checkout', '-'],\n            cwd=Path(__file__).parent / 'code',\n            stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            check=True\n        )\n\n\ndef tree_for_branch(chapter_name):\n    with checked_out(chapter_name):\n        return subprocess.run(\n            ['tree', '-v', '-I', '__pycache__|*.egg-info'],\n            cwd=Path(__file__).parent / 'code',\n            stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            check=True\n        ).stdout.decode()\n\n\ndef check_listing(listing, chapter):\n    if 'tree' in listing.classes:\n        actual_contents = tree_for_branch(chapter)\n    elif 'non-head' in listing.classes:\n        actual_contents = file_contents_for_tag(\n            listing.filename, chapter, listing.tag,\n        )\n    elif 'existing' in listing.classes:\n        actual_contents = file_contents_for_previous_chapter(\n            listing.filename, chapter,\n        )\n    elif listing.is_diff:\n        actual_contents = diff_for_tag(\n            listing.filename, chapter, listing.tag,\n        )\n\n    else:\n        actual_contents = file_contents_for_branch(listing.filename, chapter)\n    actual_lines = actual_contents.split('\\n')\n\n    if '...' in listing.contents:\n        for section in re.split(r'#?\\.\\.\\.', listing.fixed_contents):\n            lines = section.splitlines()\n            if section.strip() not in actual_contents:\n                assert lines == actual_lines, \\\n                        f'section from [{listing.tag}] not found within actual'\n\n    elif listing.fixed_contents not in actual_contents:\n        assert listing.lines == actual_lines, \\\n                f'listing [{listing.tag}] not found within actual'\n\n\n\n@dataclass\nclass Listing:\n    filename: str\n    tag: str\n    contents: str\n    classes: list\n    is_diff: bool\n\n    callouts = re.compile(r'  #?(\\(\\d\\) ?)+$', flags=re.MULTILINE)\n    callouts_alone = re.compile(r'^\\(\\d\\)$')\n\n    @property\n    def fixed_contents(self):\n        fixed = self.contents\n        fixed = self.callouts.sub('', fixed)\n        fixed = '\\n'.join(\n            l for l in fixed.splitlines()\n            if not self.callouts_alone.match(l)\n        )\n        return fixed\n\n    @property\n    def lines(self):\n        return self.fixed_contents.split('\\n')\n\n\ndef parse_listings(chapter_name):\n    raw_contents = Path(f'{chapter_name}.html').read_text()\n    parsed_html = html.fromstring(raw_contents)\n\n    for listing_node in parsed_html.cssselect('.exampleblock'):\n        [block_node] = listing_node.cssselect('.listingblock')\n        classes = block_node.get('class').split()\n        if 'skip' in classes:\n            continue\n\n        if 'tree' in classes:\n            filename = None\n        else:\n            [title_node] = listing_node.cssselect('.title')\n            title = title_node.text_content()\n            print('found listing', title)\n            try:\n                filename = re.search(r'.+ \\((.+)\\)', title).group(1)\n            except AttributeError as e:\n                raise AssertionError(f'Could not find filename in title {title}') from e\n\n        is_diff = bool(listing_node.cssselect('code[data-lang=\"diff\"]'))\n        tag = listing_node.get('id')\n\n        [code_node] = block_node.cssselect('.content pre')\n        yield Listing(\n            filename, tag, contents=code_node.text_content(), classes=classes,\n            is_diff=is_diff\n        )\n\n\ndef file_contents_for_branch(filename, chapter_name):\n    return subprocess.run(\n        ['git', 'show', f'{chapter_name}:{filename}'],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    ).stdout.decode()\n\ndef file_contents_for_previous_chapter(filename, chapter_name):\n    previous = previous_chapter(chapter_name)\n    return file_contents_for_branch(filename, previous)\n\ndef file_contents_for_tag(filename, chapter_name, tag):\n    output = subprocess.run(\n        ['git', 'show', f'{chapter_name}^{{/\\\\[{tag}\\\\]}}:{filename}'],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    ).stdout.decode()\n    assert output.strip(), f'no commit found for [{tag}]'\n    return output\n\ndef diff_for_tag(filename, chapter_name, tag):\n    if tag.endswith('_diff'):\n        tag = tag[:-5]\n    output = subprocess.run(\n        ['git', 'show', f'{chapter_name}^{{/\\\\[{tag}\\\\]}}', '--', filename],\n        cwd=Path(__file__).parent / 'code',\n        stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        check=True\n    ).stdout.decode()\n    assert output.strip(), f'no commit found for [{tag}]'\n    return '\\n'.join(l.rstrip() for l in output.splitlines())\n"
        },
        {
          "name": "theme",
          "type": "tree",
          "content": null
        },
        {
          "name": "titlepage.html",
          "type": "blob",
          "size": 0.5126953125,
          "content": "<section data-type=\"titlepage\" xmlns=\"http://www.w3.org/1999/xhtml\">\n<h1>Architecture Patterns with Python</h1>\n<!--(only include edition line if it's 2e or higher -->\n\n<p class=\"subtitle\">Enabling Test-Driven Development, <span class=\"keep-together\">Domain-Driven Design</span>, and <span class=\"keep-together\">Event-Driven Microservices</span></p>\n\n<p class=\"author\">Harry Percival and Bob Gregory</p>\n</section>\n<!-- if a pocket ref, include this line below the h1: \n<p data-type=\"subtitle\">Pocket Reference/Guide</p> -->\n"
        },
        {
          "name": "toc.html",
          "type": "blob",
          "size": 0.154296875,
          "content": "<!-- This is a placeholder element for use with the automatic TOC generation option in Atlas --> \n<nav data-type=\"toc\" xmlns=\"http://www.w3.org/1999/xhtml\"/>\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "travis-deploy-key.enc",
          "type": "blob",
          "size": 3.3125,
          "content": null
        },
        {
          "name": "update-exercise-branch.py",
          "type": "blob",
          "size": 0.9033203125,
          "content": "#!/usr/bin/env python\nimport sys\nimport subprocess\nfrom pathlib import Path\n\n\ndef run(cmds):\n    print(' '.join(cmds))\n    p = subprocess.run(\n        cmds,\n        cwd=Path(__file__).parent / 'code',\n        capture_output=True,\n        check=True\n    )\n    if p.returncode:\n        raise Exception(p.stderr.decode())\n    output = p.stdout.decode()\n    print(output)\n    return output\n\nall_branches = run(['git', 'branch', '-a'],)\n\n\ndef main(chapter):\n    exercise_chapter = f'{chapter}_exercise'\n    assert exercise_chapter in all_branches\n\n    run(['git', 'checkout', exercise_chapter])\n    commits = list(reversed(run([\n        'git', 'log', '--pretty=%h',\n        f'{exercise_chapter}^{{/{chapter}_ends}}..{exercise_chapter}',\n    ]).split()))\n    run(['git', 'reset', '--hard', chapter])\n    run(['git', 'cherry-pick', *commits])\n    run(['git', 'checkout', 'master'])\n\nif __name__ == '__main__':\n    main(sys.argv[1])\n"
        },
        {
          "name": "uppercase-titles.py",
          "type": "blob",
          "size": 1.78125,
          "content": "#!/usr/bin/env python3\nimport re\nfrom pathlib import Path\nfrom titlecase import titlecase\nfrom chapters import CHAPTERS\n\nSPECIAL = {\n    'CSVs', 'To/From', 'UoW', 'AKA', 'SELECT',\n}\n\nLOWERCASE = {\n    'with',\n}\n\n\n\ndef specialcases(w, **_):\n    if w.lower() in LOWERCASE:\n        return w.lower()\n    if w.lower() in {s.lower() for s in SPECIAL}:\n        return next(special for special in SPECIAL if special.lower() == w.lower())\n    if  '_' in w:\n        return w\n    return None\n\n\ndef fix_line(l):\n    if not l.startswith('=='):\n        return l\n    if l == '====':\n        return l\n    if l == '.':\n        return l\n    prefix, rest = re.match(r'(=+ |\\.)(.+)', l).groups()\n    return prefix + titlecase(rest, callback=specialcases)\n\n\ndef main():\n    for chapter in CHAPTERS:\n        path = Path(f'{chapter}.asciidoc')\n        contents = path.read_text()\n        fixed = '\\n'.join(\n            fix_line(l) for l in contents.splitlines()\n        )\n        path.write_text(fixed)\n\nif __name__ == '__main__':\n    main()\n\nimport pytest\n\ndef test_lowercases_short_words():\n    assert fix_line('=== What Is A Domain Model') == '=== What Is a Domain Model'\n\ndef test_fix_line_handles_quotes_and_slashes():\n    assert fix_line('=== Foo \"bar\" baz') == '=== Foo \"Bar\" Baz'\n\ndef test_fix_line_leaves_small_words_alone_except_at_beginning():\n    assert fix_line('=== This is a line') == '=== This Is a Line'\n    assert fix_line('=== The initial the is fine') == '=== The Initial the Is Fine'\n\n@pytest.mark.skip\ndef test_dotstarters():\n    assert fix_line('.A sidebar title') == '.A Sidebar Title'\n\ndef test_hyphens():\n    assert fix_line('=== A wrap-up') == '=== A Wrap-Up'\n\ndef test_uow():\n    assert fix_line('=== A Uow') == '=== A UoW'\n\ndef test_underscores():\n    assert fix_line('=== A special_method') == '=== A special_method'\n"
        }
      ]
    }
  ]
}