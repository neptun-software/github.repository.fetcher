{
  "metadata": {
    "timestamp": 1736559819958,
    "page": 555,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials",
      "stars": 3806,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".DS_Store",
          "type": "blob",
          "size": 22.00390625,
          "content": null
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0322265625,
          "content": "*.ipynb linguist-language=Python\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.7978515625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.cache\nnosetests.xml\ncoverage.xml\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# IPython notebook\n.ipynb_checkpoints\n\n# Repo scratch directory\nscratch/\n.DS_Store\ndeep-learning/.DS_Store\n.DS_Store\ndeep-learning/.DS_Store\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.8349609375,
          "content": "language: python\ncache: pip\npython:\n    - 2.7\n    - 3.6\n    #- nightly\n    #- pypy\n    #- pypy3\nmatrix:\n    allow_failures:\n        - python: nightly\n        - python: pypy\n        - python: pypy3\ninstall:\n    #- pip install -r requirements.txt\n    - pip install flake8  # pytest  # add another testing frameworks later\nbefore_script:\n    # stop the build if there are Python syntax errors or undefined names\n    - flake8 . --count --select=E901,E999,F821,F822,F823 --show-source --statistics\n    # exit-zero treats all errors as warnings.  The GitHub editor is 127 chars wide\n    - flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics\nscript:\n    - true  # pytest --capture=sys  # add other tests here\nnotifications:\n    on_success: change\n    on_failure: change  # `always` will be the setting once code changes slow down\n"
        },
        {
          "name": "AutoDL",
          "type": "tree",
          "content": null
        },
        {
          "name": "BLORE",
          "type": "tree",
          "content": null
        },
        {
          "name": "Beginners_Guide_Math_LinAlg",
          "type": "tree",
          "content": null
        },
        {
          "name": "C++_Notebook",
          "type": "tree",
          "content": null
        },
        {
          "name": "DataScience-Learning-Path.md",
          "type": "blob",
          "size": 37.77734375,
          "content": "# March 2020 - 2021 Data Science (Machine Learning / Deep Learning) Study Path\n## A complete ML study path focused on making you a Real World AI Expert (Engineer / Developer and Researcher)\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/LiveAI.png\" width=\"400\" height=\"143\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/liveai-2.png\">\n</p>\n\nThis repository is intended to provide a **complete and organic learning path** to getting started with Machine Learning.\nYou will understand both theory and be able to apply it in practice, with hands-on project.\n\nIt does not require any previous knowledge, but being confident with programming and high school math is necessary to understand and implement Machine Learning concepts.\n\n\n\n#### I have organized the Path in 5 sections:(Note : This is Work In Progress)\n\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/learning-path.png\">\n</p>\n\n\n#### Fundamentals\n- Python\n- Jupyter Notebook\n- The Math you need\n- The Machine Learning landscape\n- On to Plateau 2\n#### Data Visualization\n- Pandas\n- Matplotlib\n- Seaborn, Plotly and More\n- vvvv\n- On to Plateau 3\n\n#### Machine learning\n- Introduction\n- Statistics and Randomness\n- Probability\n- Bayesian Approach\n- Math of Curvature and Surfaces\n- Information Theory, Entropy & Cross Entropy\n- Classification, Clustering and Popular Classifiers\n- Data : Preparation, Training and Testing\n- Overfitting and Underfitting\nEnsembles: Voting, Bagging, Boosting, Random Forests and More\n- Scikit-Learn\n- End-to-End Machine Learning project\n- Linear Regression\n- Classification\n- Training models\n- Support Vector Machines\n- Decision Trees\n- Ensemble Learning and Random Forest (remove / merge with top)\n- Wrap up and to Plateau 4\n\n#### Deep Learning\n- Understanding the Neuron\n- Feed Forward Networks\n- Activation Functions\n- Backpropagation - Complete ins and outs\n- Optimizers - Why we need them\n- Deep Learning - Full review\n- Introduction to TensorFlow, PyTorch and other frameworks\n- Up and Running with TensorFlow and PyTorch\n- ANN - Artificial Neural Networks\n- NLP - Comprehensive Tutorials\n- CNN - Convolutional Neural Networks\n- RNN - Recurrent Neural Networks\n- The Mighty keras - Complete overview\n- AutoEncoders\n- Reinforcement Learning (Flippers, L-Learning, Q-Learning, SARSA)\n- Generative Models - GANs, Flow-Based Models and more\n- Next steps to Plateau 5\n\n#### Applied AI in Production\n- Datasets - Complete Review\n- Training Networks: Best practices\n- Building Creative Applications\n- Machine Learning Projects\n- MLOps - Stitching Data Science Tools for Succesfull\n- Blogs / Youtube Channels / Websites worth taking a look!\n\nSo let's get started!\n\n---------------------------------------------------------------\n\n## Fundamentals\n\n### Python\nAccording to Sun Tzu:\n> If you don't know Python, learn it yesterday!\n\nPython is one of the most used and loved programming languages, and it's necessary to get things done in the Machine Learning field. Like most of the frameworks of the bigger Data Science field, TensorFlow is married with Python and Scikit-Learn is written in Python.  \n\nFirst, let's [install Python 3](https://realpython.com/installing-python/) on your machine!\n\nWe are ready to start our journey!\n\nIf you don't know the basics of Python, just start from [here](https://pythonprogramming.net/introduction-learn-python-3-tutorials/).\\\nElse if you know the syntax and you want to have a more solid Python background (recommended) take this Intermediate Python Course from [here](https://pythonprogramming.net/introduction-intermediate-python-tutorial/).\\\nIf you are looking for tons of exercises to get your hands dirty and get experience with Python, check [here](https://www.w3resource.com/python-exercises/) and [here](https://www.practicepython.org/).\n\nOnce you're familiar with Python, take a look at [Numpy](https://docs.scipy.org/doc/numpy-1.13.0/user/whatisnumpy.html), an important module for math operations, that allows you to import in Python the [Tensor](https://www.kdnuggets.com/2018/05/wtf-tensor.html) data type, which is the most used in ML (especially when dealing with Neural Nets).\n[It's not a matrix!](https://medium.com/@quantumsteinke/whats-the-difference-between-a-matrix-and-a-tensor-4505fbdc576c)\nThis is an awesome [Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/).\n\nI also recommend you to install [Pycharm Community Edition](https://www.jetbrains.com/pycharm/download/#section=windows), a complete IDE for Python development, and [set a new Python virtual environment](https://www.jetbrains.com/help/pycharm/creating-virtual-environment.html) for our experiments.\n\n### Jupyter Notebook\nDirectly from [here](https://jupyter.org/): \"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.\"\nWorking with data means -> a lot of expriments. And to document experiments, and organize them in a valuable way to get insights, you definitely need to use Jupyter Notebook during your journey. [Why](http://blendedlearning.blogs.brynmawr.edu/what-are-jupyter-notebooks-why-would-i-want-to-use-them/)?\n\n\n### The math you need\nWho tells that the math behind Machine Learning is hard... it's not so wrong! But you have to consider that every time you're going to use it, it will be handled by the machine for you! So, the important is to grasp the main math concepts and recognize limits and applications of those. No one is going to ask you to calculate a gradient by hand! So, even if you are not familiar with these concepts, check them, because they are the reason behind everything.\n\nWith these three resources, you'll get out the most of what you really need to understand things deeply.\n\nA top course about linear algebra is [here](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/).\\\nIntegrate with basic probabilities and statistic concepts [here](https://www.edx.org/course/introduction-to-probability-0).\\\nThe most of the remaining math you need [here](https://explained.ai/matrix-calculus/index.html#sec4.5).\n\n\n### The machine learning Landscape\nDirectly from the book cited earlier, this is the most concise and illuminating overview of **what is** and **when you need** machine learning. Let's stop use buzzwords!\nCheck it [here](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/ch01.html).\n\n----------------------------------------------------------------\n\n## Machine Learning\n\n### Introduction\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\n\n### Statistics and Randomness\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\n\n### Probability\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\n\n### Bayesian Approach\n\nSed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?\n\n### Scikit-Learn\n\nTo install Scikit-Learn\n\n```\npython pip install -U scikit-learn\n```\n\nIf you encounter some problems, it may be because you don't have the last version of pip. So n the same folder run:\n\n```\n python -m pip install --upgrade pip\n```\n\n[Scikit-Learn](https://scikit-learn.org/stable/) one of the most complete, mature and well-documented library for Machine Learning tasks. It comes out-of-the-box with powerful and advanced models and offers facility functions for the data science process.\nWe'll learn and use other modules along the road, for a quick usage just look at their official documentation.\n\n\n### End-to-End Machine Learning project\nFor a first taste, i suggest you to go through this Kaggle notebook, which is the most classic example of ML task. The goal is trying to predict if a Titanic passenger would have been most likely to survive or not. Many things will be unclear for now, but don't worry, they will be all explained comprehensively later. Is nice to get the picture of the \"applied\" project, going through the classical steps of the applied Machine Learning (problem framing, data exploration, question formulation...).\n\nThe notebook is on [Kaggle](https://www.kaggle.com/), the go-to platform for ML and general Data Science projects, which provides a lot of free datasets and offers interesting challenges and ML model experiments.\n\n[This](https://www.kaggle.com/startupsci/titanic-data-science-solutions) is the notebook: Read it, trying to get the big picture of the process, because some details, functions and code will be clearer later.\n\n### Linear Regression\nThis is the simplest form of Machine Learning, and the starting point for everyone interested in predicting outcomes from a dataset.\nCheck [here](https://www.youtube.com/watch?v=W46UTQ_JDPk&list=PLoR5VjrKytrCv-Vxnhp5UyS1UjZsXP0Kj&index=2) the theoretical lesson from Andrew NG and then go through these examples, from the simplest to the most complete.\n[This](https://www.geeksforgeeks.org/ml-normal-equation-in-linear-regression/) is the math behind Linear Regression.\n- [Example 1](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)\n- [Example 2](https://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/)\n- [Example 3](https://www.geeksforgeeks.org/linear-regression-python-implementation/)\n\n### Classification\nClassification is one of the most important ML tasks, and it consists of predicting **an outcome given an input**, classifying it among differente possibilities. For example, given handwritten numbers, guess what the number is, with the lowest error rate possible.\nThe simplest case is binary classification (Yes or No, Survived or Not Survived), have a look [here](https://machinelearningmastery.com/make-predictions-scikit-learn/).\nCheck [here](https://towardsdatascience.com/building-a-logistic-regression-in-python-301d27367c24) a brief explanation of the theory of logistic regression algorithm for classification, and check [here](https://www.youtube.com/watch?v=VCJdg7YBbAQ) for a deeper comprehension (using the Titanic dataset).\nYou can use a lot of different ML models to classify things, even neural networks! For now, just take a look [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html), where you see an example of comparison among different models accuracy and recall.\n[Here](https://medium.com/thalus-ai/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b) you have an article about the metrics used to **evaluate** your classifiers.\n\n### Training models\nHere i grouped some of the techniques used in ML tasks to train the models.\nIn this Google Crash Course you find:\n- [Gradient Descent](https://developers.google.com/machine-learning/crash-course/reducing-loss/gradient-descent)\n- [Learning Rate](https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate)\n- [SGD](https://developers.google.com/machine-learning/crash-course/reducing-loss/stochastic-gradient-descent)\n- [Regularization](https://www.youtube.com/watch?v=Q81RR3yKn30)\n\n### Support Vector Machines\nThis is another classical algorithm to create ML models.\n[Here](https://www.youtube.com/watch?v=_PwhiWxHK8o) you have the explanation of the theory, and [here](https://www.youtube.com/watch?v=g8D5YL6cOSE) a more pratical approach. Check both.\n[Here](https://scikit-learn.org/stable/modules/svm.html) is a very good explanation + practice application in Scikit-Learn.\n\n### Decision Trees\nDecision Trees are one of the most simple but effective idea behind predicting outcomes, and they're used in many ways (i.e. Random Forest). Check [here](https://www.youtube.com/watch?v=eKD5gxPPeY0&list=PLBv09BD7ez_4temBw7vLA19p3tdQH6FYO) and go through the playlist to get a theoretical overview of Decision Trees (ID3).\n[Here](https://scikit-learn.org/stable/modules/tree.html) you have the pratical application of ID3.\nHere you have a some end-to-end examples, with  Scikit-Learn:\n- [Example 1](https://www.youtube.com/watch?v=9YcMzsFvfxU)\n- [Example 2](https://www.youtube.com/watch?v=RmajweUFKvM)\n- [Example 3](http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/)\n\n### Ensemble Learning and Random Forest\nThe idea of Ensemble Learning is to leverage all the different features, pro and cons of several ML models to obtain a group of \"voters\" that, for each prediction, gives you the most likely outcome, voted by different classifiers (SVM, ID3, maybe Logistic Regression).\n[Here](https://www.youtube.com/watch?v=9VmKYwX_U7s) you find the basics of the ensemble learning approach, and [here](https://www.youtube.com/watch?v=3kYujfDgmNk) you find the most classic of them, the Random Forest. Altough the idea is simple, this ensemble model came up really effective tackling even some \"hard\" classification problems, or with a lot of data.  \n\n[Here](https://scikit-learn.org/stable/modules/ensemble.html) you get a complete overview of the best practices for ensemble learning, and [here](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0) you find an example of Random Forest with Scikit-Learn. Both link come with a bunch of useful techniques touse in practice.\n\n### Wrapping up and looking forward\nNow, if you followed all the steps and explored all the resources i posted, you're likely to be mode confident with Machine Learning and have a general idea of the things. Of course you need to explore and learn more, because this field is changing and enhancing techniques and approaches day-by-day! All the algorithm we've seen are widely used in the Data Science and Analytics field, but there are some complex tasks where they fail or give really poor performances. Now we are ready to fall down in the **deep** rabbit hole, trying to understand how Neural Network and in general Deep Learning can help tackling big problem with millions of parameters and variables.\n[Why use Deep Learning over classical ML algorithms?](https://towardsdatascience.com/why-deep-learning-is-needed-over-traditional-machine-learning-1b6a99177063)\n\n-----------------------------------------------------------------\n\n## Deep Learning\nIn this section we'll follow a track that will bring us to zero knowledge of neural network to fully understand them, thanks to the Stanford University Deep Learning course and some tutorials i've searched over the internet. Some of them come from Google, other from Stanford or Cambridge university, and you will learn to leverage neural networks (ANN, CNN, RNN) for several kind of ML tasks.\nThese are [some use cases](https://www.digitaldoughnut.com/articles/2017/march/top-5-use-cases-of-tensorflow) of using TensorFlow for ML tasks.\n\nThe theory and the applications of the Neural Networks are not too easy to get at a first look. Because of that, you'll need to pass again through tutorials and videos, to ensure a fully comprehension of the coming topics. Because of that, I spent a decent amount of time trying to understand (reading paths like this, articles, offical forums, related subreddits) which was **the most effective way** to deeply learn the concepts, formulas, tradeoffs...\nI came up with this approach, but you can tweak it as you prefer, because every brain is different.\n\n> After taking the TensorFlow section\n> 3 phases iterative cycle:\n\n>- 1 Get an idea of the main concepts through **an entire pass** of this [Stanford course](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv), don't care too much on math explanations, focus on the **what and why**\n\n>- 2 Deeply explore **one topic at time**, with theory + tutorials + examples (e.g. RNN theory + RNN tutorials + RNN examples)\n>with the links and resources of the topic section of the guide.\n\n>- 3 After iterating the 2 phase for each topic, walk again through the entire Stanford course. This time you can fully understand all  the formulas, connecting them and catching also the \"math flow\" of the course.\n\nThis iterative process (1-2-2-2-2.....-3) can be repeated may times as you want, and will probably construct in your mind a nice **general schema** of the things. In each complete iteration you can drop one or more topics, and focus on the ones that are more interesting to you or not so clear.\n\nIn each section i've put content for the first time you arrive there (during the first complete iteration), and some content for next time you arrive there (after the 3 phase).\n\nThe structure follows the track proposed by the Stanford awesome course. You find the slides [here](http://cs231n.stanford.edu/slides/2018/).\n\n[This](http://introtodeeplearning.com/) is an alternative course from MIT, more or less the same contents. It's worth watching it to compare and have a differente point of view on the things, besides listening 2X the best professors of the world exploring each topic.  \n\nThis is the [**Book**](https://www.deeplearningbook.org/) I refer to in each section.\n\n### What is TensorFlow\nCreated by the [Google Brain](https://ai.google/research/teams/brain) team, [TensorFlow](https://www.tensorflow.org/) is an open source library for numerical computation and large-scale machine learning. TensorFlow bundles together a slew of machine learning and deep learning (aka neural networking) models and algorithms and makes them useful by way of a common metaphor. It uses Python to provide a convenient front-end API for building applications with the framework, while executing those applications in high-performance C++.\nTensorFlow is the de-facto standard for the major industry-sized company that need to implement Machine Learning algorithms. Is built for scaling, with really cool features to parallelize training over multiple GPU's or devices.\n\n### What is PyTorch\nPyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR). It is free and open-source software released under the Modified BSD license.\nPyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab (FAIR). It is free and open-source software released under the Modified BSD license. Although the Python interface is more polished and the primary focus of development, PyTorch also has a C++ interface.\n\nA number of pieces of Deep Learning software are built on top of PyTorch, including Tesla Autopilot, Uber's Pyro etc.\n\nPyTorch provides two high-level features: Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU) **and** Deep neural networks built on a tape-based automatic differentiation system\n\n### Up and Running with TensorFlow\nAssuming you have [Python stored in the variable PATH](https://helpdeskgeek.com/windows-10/add-windows-path-environment-variable/), to install the Tensorflow library you just need to open a terminal inside you Python installation folder and run this command.\n\n```\npython pip install tensorflow\n```\n\nThe first read i recommend you is [this](https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/).\nThe second thing to do is to follow this [Introduction to TensorFlow](https://www.youtube.com/watch?v=tYYVSEHq-io) directly from the **awesome** [Google Education](https://ai.google/education/) page.\nAgain, some theoretical concepts might be unclear, but focus on how the TensorFlow library and process are conceived.\n[This](https://medium.com/@camrongodbout/tensorflow-in-a-nutshell-part-one-basics-3f4403709c9d) is a good resume of the latter.\n[Another beginner tutorial from google](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0).\n[This](https://www.youtube.com/watch?v=k5c-vg4rjBw&t=246s) is about the TensorFlow 2.0 update.\n\nNow you're most likely familiar with **TensorFlow as a tool**, and it's time to understand **how to use** it to build large scale Neural Networks.\n\n### ANN - Artificial Neural Networks\n_First look (in order):_\n- [This video](https://www.youtube.com/watch?v=v2tKoymKIuE).\n- [This is your bible](http://neuralnetworksanddeeplearning.com/chap1.html), understand it totally.\n- [This is a gem](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.85356&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) and read [this](https://www.guru99.com/artificial-neural-network-tutorial.html) from the authors.\n- [This](https://www.youtube.com/watch?v=o64FV-ez6Gw&t=540s) is a really fast-talking guy implementing a Neural Network library from scratch, super useful to understand how is implemented the core of NN in Python. You can imagine that each existing framework is just an enormous expansione of this concept-library.\n- [This](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) is a step-by-step backpropagation example with calculus.\n\n_Second pass:_\n- [ANN Chapter](https://www.deeplearningbook.org/contents/mlp.html).\n\n_Tips & Best practices:_\n[1](https://developers.google.com/machine-learning/crash-course/training-neural-networks/best-practices), [2](https://hackernoon.com/8-deep-learning-best-practices-i-learned-about-in-2017-700f32409512), [3](https://towardsdatascience.com/10-things-to-think-about-before-starting-to-code-your-deep-neural-network-65094a1e7c08), [4](https://towardsdatascience.com/how-to-increase-the-accuracy-of-a-neural-network-9f5d1c6f407d), [5](https://www.reddit.com/r/MachineLearning/comments/abj1mc/d_notes_on_why_deep_neural_networks_are_able_to/), [6](https://www.reddit.com/r/MachineLearning/comments/abj1mc/d_notes_on_why_deep_neural_networks_are_able_to/), [7](http://karpathy.github.io/neuralnets/), [8](https://medium.com/cracking-the-data-science-interview/a-gentle-introduction-to-neural-networks-for-machine-learning-d5f3f8987786).\n\n### CNN - Convolutional Neural Networks\n_First look (in order):_\n- [Here](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) is an awesome deep explanation.\n- [Here](https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8) another super good one.\n- [Here](https://www.datacamp.com/community/tutorials/cnn-tensorflow-python) is serious CNN tutorial with TensorFlow.\n\n_Second pass:_\n- [CNN Chapter](https://www.deeplearningbook.org/contents/convnets.html).\n\n_Tips & Best practices:_\n[1](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/), [2](https://www.topbots.com/14-design-patterns-improve-convolutional-neural-network-cnn-architecture/), [3](https://arxiv.org/abs/1709.02601), [4](https://de.mathworks.com/matlabcentral/answers/362024-convolutional-neural-networks-what-is-the-best-practice-training-approach-using-graphics-cards), [5](http://www.academia.edu/4057996/Best_Practices_for_Convolutional_Neural_Networks_Applied_to_Visual_Document_Analysis), [6](https://www.microsoft.com/en-us/research/publication/best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis/), [7](https://missinglink.ai/guides/neural-network-concepts/neural-networks-image-recognition-methods-best-practices-applications/), [8](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/).\n\n### RNN - Recurrent Neural Networks\n_First look (in order):_\n- [Here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) a gentle but detailed explanation.\n- [Here](https://www.superdatascience.com/blogs/the-ultimate-guide-to-recurrent-neural-networks-rnn) another interesting explanation.\n- [Here](https://www.youtube.com/watch?v=9zhrxE5PQgY) a video with a more pratical approach.\n- [Here](https://becominghuman.ai/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow-1907a5bbb1fa) a guide to implement RNN in TensorFlow.\n- [Here](https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767) a 7 pages blog post regarding the TensorFlow implementation.\n\n_Second pass:_\n- [RNN Chapter](https://www.deeplearningbook.org/contents/rnn.html)\n\n_Tips & Best practices:_\n[1](https://danijar.com/tips-for-training-recurrent-neural-networks/), [2](https://svail.github.io/rnn_perf/), [3](https://towardsdatascience.com/rnn-training-tips-and-tricks-2bf687e67527), [4](http://slazebni.cs.illinois.edu/spring17/lec20_rnn.pdf), [5](https://www.quora.com/What-are-the-best-practices-for-choosing-hidden-state-size-in-RNNs), [6](https://www.quora.com/Can-recurrent-neural-networks-with-LSTM-be-used-for-time-series-prediction), [7](https://www.reddit.com/r/MachineLearning/comments/5ogbd5/d_training_lstms_in_practice_tips_and_tricks/).\n\n### Training Networks: Best practices\n_First look (in order):_\nI **strongly recommend** you to refer to [this page](http://cs231n.github.io/) from Stanford and go through all the Module 1 and 2.\nI put also here a list of the various topic to explore when talking about _how to train NN in real life applications_.\n\n- Overfitting vs Underfitting: [1](https://keeeto.github.io/blog/bias_variance/), [2](https://cran.r-project.org/web/packages/keras/vignettes/tutorial_overfit_underfit.html), [3](https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/), [4](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76), [5](https://elitedatascience.com/overfitting-in-machine-learning).\n- Vanishing/Exploding Gradient: [1](https://medium.com/learn-love-ai/the-curious-case-of-the-vanishing-exploding-gradient-bf58ec6822eb), [2](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/), [3](https://hackernoon.com/exploding-and-vanishing-gradient-problem-math-behind-the-truth-6bd008df6e25), [4](https://www.jefkine.com/general/2018/05/21/2018-05-21-vanishing-and-exploding-gradient-problems/), [5](https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528).\n- Transfer Learning: [1](https://medium.com/analytics-vidhya/reusing-a-pre-trained-deep-learning-model-on-a-new-task-transfer-learning-1c0a25a92dfb), [2](https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/), [3](https://jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/5.3-using-a-pretrained-convnet.nb.html), [4](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a), [5](https://machinelearningmastery.com/transfer-learning-for-deep-learning/).\n- Faster Optimizers: [1](http://ruder.io/optimizing-gradient-descent/), [2](https://www.jeremyjordan.me/nn-learning-rate/), [3](https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1), [4](https://towardsdatascience.com/learning-rate-scheduler-d8a55747dd90).\n- Avoiding Overfitting through Regularization: [1](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a), [2](https://codeburst.io/what-is-regularization-in-machine-learning-aed5a1c36590), [3](https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/), [4](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/).\n\n_Second pass:_\n- [Google best practices](https://developers.google.com/machine-learning/guides/rules-of-ml/).\n- [Regularizaton Chapter](https://www.deeplearningbook.org/contents/regularization.html).\n- [Optimization Chapter](https://www.deeplearningbook.org/contents/optimization.html).\n- [Pratical Methodology Chapter](https://www.deeplearningbook.org/contents/guidelines.html).\n\n\n### AutoEncoders\n_First look (in order):_\n- [Here](https://www.quora.com/What-is-an-auto-encoder-in-machine-learning) you find a first read.\n- [This](https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f) is your second recommended read.\n- [This](https://www.youtube.com/watch?v=vfnxKO2rMq4) is a lecture from Andrew NG.\n- I give also you some examples: [1](https://www.guru99.com/autoencoder-deep-learning.html), [2](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/autoencoder.py), [3](https://towardsdatascience.com/deep-autoencoders-using-tensorflow-c68f075fd1a3), [4](http://machinelearninguru.com/deep_learning/tensorflow/neural_networks/autoencoder/autoencoder.html).\n\n_Second pass:_\n[AutoEncoders Chapter](https://www.deeplearningbook.org/contents/autoencoders.html).\n\n _Tips & Best practices:_\n [1](https://stats.stackexchange.com/questions/257163/architecture-of-autoencoders), [2](https://stats.stackexchange.com/questions/193780/how-much-noise-for-denoising-autoencoder), [3](https://www.reddit.com/r/MachineLearning/comments/6aw8ik/d_reddit_do_you_use_autoencoders_in_practice/), [4](https://www.reddit.com/r/MachineLearning/comments/89f17m/d_current_best_practices_for_vaes/), [5](https://www.reddit.com/r/MachineLearning/comments/5k8h07/p_insights_into_variational_autoencoders_for/).\n\n### Reinforcement Learning\n_First look (in order):_\n- [Here](https://www.youtube.com/watch?v=2pWv7GOvuf0) you have an explanation video.\n- [This](https://skymind.ai/wiki/deep-reinforcement-learning) article is well explaining RL.\n- [Here](https://towardsdatascience.com/what-to-expect-from-reinforcement-learning-a22e8c16f40c) is an interesting read.\n- Some examples: [1](https://adventuresinmachinelearning.com/reinforcement-learning-tensorflow/), [2](https://medium.com/tensorflow/deep-reinforcement-learning-playing-cartpole-through-asynchronous-advantage-actor-critic-a3c-7eab2eea5296), [3](https://www.youtube.com/watch?v=t1A3NTttvBA), [4](https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow).\n\n_Second pass:_\n[The go-to guide](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html?utm_campaign=Data%20Machina&utm_medium=email&utm_source=Revue%20newsletter).\n[Paper](https://arxiv.org/pdf/1710.02298.pdf) with state of art RL architecture.\n[Complete free book on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html).\n\n _Tips & Best practices:_\n [1](https://medium.com/@BonsaiAI/deep-reinforcement-learning-models-tips-tricks-for-writing-reward-functions-a84fe525e8e0), [2](https://towardsdatascience.com/applications-of-reinforcement-learning-in-real-world-1a94955bcd12).\n\n\n## Applied AI\n\n**Hey You**.\nDuring the last few years i collected tons of articles, web apps, reddit thread, best practices, projects and repositories, and I want to share with you each single bit of information, trying to organize them by type of resource (blogs or projects ideas, and so on).\n\n### Machine Learning Projects\n\n- [Enormous and awesome collection](https://github.com/FavioVazquez/ds-cheatsheets) of Data Science Cheat Sheets\n- [Infinite collection](https://docs.google.com/document/d/e/2PACX-1vRRC3ZIcvjFqEYEgnN9pptoWONr2mSGZJ4hSdL8Jpf2IpXdxjTc-d3jrpb98h59xJnZ3h1frUDydoxc/pub) of actual Data Science / ML projects\n- [Infinite collection](https://github.com/jtoy/awesome-tensorflow) of tutorials and Ml projects in TensorFlow\n- [Other TensorFlow examples](https://github.com/aymericdamien/TensorFlow-Examples)\n\n### Tools\n\n- [Google Data Visualization Facets](https://pair-code.github.io/facets/)\n- [Interactive Neural Network](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.95549&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n\n### Youtube Channels\n\n- [Enthought](https://www.youtube.com/user/EnthoughtMedia/videos)\n- [3Blue1Brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)\n- [Microsoft](https://www.youtube.com/channel/UCFtEEv80fQVKkD4h1PF-Xqw)\n- [TensorFlow Official channel](https://www.youtube.com/channel/UC0rqucBdTuFTjJiefW5t-IQ)\n- [Engineering Man](https://www.youtube.com/channel/UCrUL8K81R4VBzm-KOYwrcxQ)\n- [The Tech Lead](https://www.youtube.com/channel/UC4xKdmAXFh4ACyhpiQ_3qBw)\n\n### Blogs\n\n- [How to build a data science portfolio](https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html?utm_campaign=Data%20Machina&utm_medium=email&utm_source=Revue%20newsletter)\n- [Distill blog](https://distill.pub/)  \n- [Keras](https://www.youtube.com/user/EnthoughtMedia/videos)\n- [Paolo Galeone blog](https://pgaleone.eu/)\n- [TensorFlow official blog](https://medium.com/tensorflow)\n- [KD Nuggets](https://www.kdnuggets.com/)\n- [Incredible Graphic explanations](http://colah.github.io/)\n\n### Websites worth taking a look!\n\n- [A monster collection of Data related free course](https://github.com/kmario23/deep-learning-drizzle)\n- [Machine Learning Map](http://www.saedsayad.com/data_mining_map.htm)\n- [Data modeling for Business Intelligence](https://www.1keydata.com/datawarehousing/data-modeling-levels.html)\n- [Statistics explained](http://www.statsoft.com/Textbook/Elementary-Statistics-Concepts#Two%20basic%20features%20of%20every%20relation%20between%20variables)\n- [Visualizing data - Turorials](https://datascienceplus.com/category/visualizing-data/?tdo_tag=Python)\n- [Fast.ai](https://www.fast.ai/)\n- [Open.ai](https://openai.com/blog/better-language-models/)\n- [Explained.ai](https://explained.ai/)\n- [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary/)\n- [Python ML Tutorials](https://www.python-course.eu/machine_learning.php)\n- [Immersive math](http://immersivemath.com/ila/)  \n- [DeepLizard](http://deeplizard.com/)\n- [Common Statistical Fallacies](https://www.geckoboard.com/learn/data-literacy/statistical-fallacies/)\n\n\n### Subreddits you want to follow!\n\n- [10 awesomee subreddits related to data sciece](https://www.analyticsindiamag.com/10-data-science-subreddits-every-tech-enthusiast-should-follow/)\n- [An incredible tool to discover trends and subs](https://anvaka.github.io/sayit/?query=MachineLearning)\n\n## Next Steps Roadmap\n\nA lot of cool and 2021 savvy stuff is coming to this content:\n\n- Unsupervised Learning / Self-Suerpvised Learning\n- MLOps : Machine Learning mindset framework (how to work like a succesful data scientist)\n- Data processing and preparation\n- Feature Selection\n- Features Engineering\n- Extending the parameters optimization section\n- Popular Computer Vision Models and datasets\n- Popular NLP, RNN, Language Models and datasets\n- Real World AI Projects / Industry Verticals (Agriculture, Climate / Energy, Healthcare, Retail, Document AI, HR analytics, Ethics AI - Project Hominis, PETAI, CAELI, AI Projects)\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.04296875,
          "content": "This repository contains a variety of content; some developed by Tarry Singh,\nand some from third-parties.  The third-party content is distributed under the\nlicense provided by those parties.\n\nThe content developed by Tarry Singh is distributed under the following license:\n\nI am providing code and resources in this repository to you under an open source\nlicense.  Because this is my personal repository, the license you receive to my\ncode and resources is from me and not my employer(s) -- whether current or past.\n\nCopyright 2017 Tarry Singh\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License."
        },
        {
          "name": "Math_Tutorials",
          "type": "tree",
          "content": null
        },
        {
          "name": "PaddlePaddle",
          "type": "tree",
          "content": null
        },
        {
          "name": "Projects",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 70.1357421875,
          "content": "# NEW LIST 2023 - 2024: Machine-Learning / Deep-Learning / AI + Web3 -Tutorials\n\nHi - Thanks for dropping by!<br>\n<br>\nI will be updating this tutorials site on a <b>daily basis</b> adding all relevant topcis for 2022 - 2024 especially pertaining to **GPU programming, Data Centric AI, Emerging topics like Sustainable AI with Web3AI.js (DeFI, DAO, NFT) and much more**.<br>\n\n**NOTE: All these tutorials are supported and accelerated on NVIDIA GPUs**\n<br>\nMore importantly the applications of ML/DL/AI into industry areas such as Transportation, Medicine/Healthcare etc. will be something I'll watch with keen interest and would love to share the same with you.\n<br>\nFinally, it is **YOUR** help I will seek to make it more useful and less boring, so please do suggest/comment/contribute!\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/DK.png\">\n</p>\n\n## Index\n\n* [deep-learning](#deep-learning)\n   * [UBER | Pyro](#uber-pyro-probabalistic-tutorials)\n   * [Netflix | VectorFlow](#netflix-vectorflow-tutorials)\n   * [PyTorch](#pytorch-tutorials)\n   * [tensorflow](#tensor-flow-tutorials)\n   * [theano](#theano-tutorials)\n   * [keras](#keras-tutorials)\n   * [caffe](#deep-learning-misc)\n   * [Torch/Lua]()\n   * [MXNET]()\n   \n* [scikit-learn](#scikit-learn)\n* [statistical-inference-scipy](#statistical-inference-scipy)\n* [pandas](#pandas)\n* [matplotlib](#matplotlib)\n* [numpy](#numpy)\n* [python-data](#python-data)\n* [kaggle-and-business-analyses](#kaggle-and-business-analyses)\n* [spark](#spark)\n* [mapreduce-python](#mapreduce-python)\n* [amazon web services](#aws)\n* [command lines](#commands)\n* [misc](#misc)\n* [notebook-installation](#notebook-installation)\n* [Curated list of Deep Learning / AI blogs](#curated-list-of-deeplearning-blogs)\n* [credits](#credits)\n* [contributing](#contributing)\n* [contact-info](#contact-info)\n* [license](#license)\n\n## deep-learning\n\nIPython Notebook(s) and other programming tools such as Torch/Lua/D lang in demonstrating deep learning functionality.\n\n### uber-pyro-probabalistic-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/pyro.png\">\n</p>\n\nAdditional PyRo tutorials:\n\n* [pyro-examples/full examples](http://pyro.ai/examples/)\n* [pyro-examples/Variational Autoencoders](http://pyro.ai/examples/vae.html)\n* [pyro-examples/Bayesian Regression](http://pyro.ai/examples/bayesian_regression.html)\n* [pyro-examples/Deep Markov Model](http://pyro.ai/examples/dmm.html)\n* [pyro-examples/AIR(Attend Infer Repeat)](http://pyro.ai/examples/air.html)\n* [pyro-examples/Semi-Supervised VE](http://pyro.ai/examples/ss-vae.html)\n* [pyro-examples/GMM](http://pyro.ai/examples/gmm.html)\n* [pyro-examples/Gaussian Process](http://pyro.ai/examples/gp.html)\n* [pyro-examples/Bayesian Optimization](http://pyro.ai/examples/bo.html)\n* [Full Pyro Code](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/deep-learning/UBER-pyro)\n\n\n\n### netflix-vectorflow-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/VectorFlow.png\">\n</p>\n\n* [MNIST Example, running with Dlang](https://github.com/Netflix/vectorflow/tree/master/examples)\n\n### pytorch-tutorials\n<p align=\"center\">\n  <img src=\"https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/images/PyTorch.png\">\n</p>\n\n| Level | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [Beginners/Zakizhou](https://github.com/pytorch/tutorials/tree/master/beginner_source) | Learning the basics of PyTorch from Facebook. |\n| [Intermedia/Quanvuong](https://github.com/pytorch/tutorials/tree/master/intermediate_source) | Learning the intermediate stuff about PyTorch of from Facebook. |\n| [Advanced/Chsasank](https://github.com/pytorch/tutorials/tree/master/advanced_source) | Learning the advanced stuff about PyTorch of from Facebook. |\n| [Learning PyTorch by Examples - Numpy, Tensors and Autograd](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/tree/master/pytorch) | At its core, PyTorch provides two main features an n-dimensional Tensor, similar to numpy but can run on GPUs AND automatic differentiation for building and training neural networks. |\n| [PyTorch - Getting to know autograd.Variable, Gradient, Neural Network](https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials/blob/master/pytorch/PyTorch%20NN%20Basics%20-%20Autograd%20Gradient%20Neural%20Network%20Loss%20Backprop.ipynb) | Here we start with ultimate basics of Tensors, wrap a Tensor with Variable module, play with nn.Module and implement forward and backward function. |\n\n\n### tensor-flow-tutorials\n<br/>\n<p align=\"center\">\n  <img src=\"https://avatars0.githubusercontent.com/u/15658638?v=3&s=100\">\n</p>\nAdditional TensorFlow tutorials:\n\n* [pkmital/tensorflow_tutorials](https://github.com/pkmital/tensorflow_tutorials)\n* [nlintz/TensorFlow-Tutorials](https://github.com/nlintz/TensorFlow-Tutorials)\n* [alrojo/tensorflow-tutorial](https://github.com/alrojo/tensorflow-tutorial)\n* [BinRoot/TensorFlow-Book](https://github.com/BinRoot/TensorFlow-Book)\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-basics](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/1_intro/basic_operations.ipynb) | Learn basic operations in TensorFlow, a library for various kinds of perceptual and language understanding tasks from Google. |\n| [tsf-linear](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/linear_regression.ipynb) | Implement linear regression in TensorFlow. |\n| [tsf-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/logistic_regression.ipynb) | Implement logistic regression in TensorFlow. |\n| [tsf-nn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/2_basic_classifiers/nearest_neighbor.ipynb) | Implement nearest neighboars in TensorFlow. |\n| [tsf-alex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/alexnet.ipynb) | Implement AlexNet in TensorFlow. |\n| [tsf-cnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/convolutional_network.ipynb) | Implement convolutional neural networks in TensorFlow. |\n| [tsf-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/multilayer_perceptron.ipynb) | Implement multilayer perceptrons in TensorFlow. |\n| [tsf-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/3_neural_networks/recurrent_network.ipynb) | Implement recurrent neural networks in TensorFlow. |\n| [tsf-gpu](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/4_multi_gpu/multigpu_basics.ipynb) | Learn about basic multi-GPU computation in TensorFlow. |\n| [tsf-gviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/graph_visualization.ipynb) | Learn about graph visualization in TensorFlow. |\n| [tsf-lviz](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-examples/notebooks/5_ui/loss_visualization.ipynb) | Learn about loss visualization in TensorFlow. |\n\n### tensor-flow-exercises\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [tsf-not-mnist](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/1_notmnist.ipynb) | Learn simple data curation by creating a pickle with formatted datasets for training, development and testing in TensorFlow. |\n| [tsf-fully-connected](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/2_fullyconnected.ipynb) | Progressively train deeper and more accurate models using logistic regression and neural networks in TensorFlow. |\n| [tsf-regularization](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/3_regularization.ipynb) | Explore regularization techniques by training fully connected networks to classify notMNIST characters in TensorFlow. |\n| [tsf-convolutions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/4_convolutions.ipynb) | Create convolutional neural networks in TensorFlow. |\n| [tsf-word2vec](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/5_word2vec.ipynb) | Train a skip-gram model over Text8 data in TensorFlow. |\n| [tsf-lstm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/tensor-flow-exercises/6_lstm.ipynb) | Train a LSTM character model over Text8 data in TensorFlow. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://www.deeplearning.net/software/theano/_static/theano_logo_allblue_200x46.png\">\n</p>\n\n### theano-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [theano-intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/intro_theano.ipynb) | Intro to Theano, which allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. It can use GPUs and perform efficient symbolic differentiation. |\n| [theano-scan](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/scan_tutorial/scan_tutorial.ipynb) | Learn scans, a mechanism to perform loops in a Theano graph. |\n| [theano-logistic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/intro_theano/logistic_regression.ipynb) | Implement logistic regression in Theano. |\n| [theano-rnn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/rnn_tutorial/simple_rnn.ipynb) | Implement recurrent neural networks in Theano. |\n| [theano-mlp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/theano-tutorial/theano_mlp/theano_mlp.ipynb) | Implement multilayer perceptrons in Theano. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"http://i.imgur.com/L45Q8c2.jpg\">\n</p>\n\n### keras-tutorials\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| keras | Keras is an open source neural network library written in Python. It is capable of running on top of either Tensorflow or Theano. |\n| [setup](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/README.md) | Learn about the tutorial goals and how to set up your Keras environment. |\n| [intro-deep-learning-ann](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1%20Introduction%20-%20Deep%20Learning%20and%20ANN.ipynb) | Get an intro to deep learning with Keras and Artificial Neural Networks (ANN). |\n| [Perceptrons and Adaline](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.1%20Perceptron%20and%20Adaline.ipynb) | Implement Peceptron and adaptive linear neurons. |\n| [MLP and MNIST Data](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.%20ANN/1.1.2%20MLP%20and%20MNIST.ipynb) | Classifying handwritten digits,implement MLP, train and debug ANN |\n| [theano](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.2%20Introduction%20-%20Theano.ipynb) | Learn about Theano by working with weights matrices and gradients. |\n| [keras-otto](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.3%20Introduction%20-%20Keras.ipynb) | Learn about Keras by looking at the Kaggle Otto challenge. |\n| [ann-mnist](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/1.4%20(Extra)%20A%20Simple%20Implementation%20of%20ANN%20for%20MNIST.ipynb) | Review a simple implementation of ANN for MNIST using Keras. |\n| [conv-nets](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.1%20Supervised%20Learning%20-%20ConvNets.ipynb) | Learn about Convolutional Neural Networks (CNNs) with Keras. |\n| [conv-net-1](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.1%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20I.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 1. |\n| [conv-net-2](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.2.2%20Supervised%20Learning%20-%20ConvNet%20HandsOn%20Part%20II.ipynb) | Recognize handwritten digits from MNIST using Keras - Part 2. |\n| [keras-models](http://nbviewer.ipython.org/github/leriomaggio/deep-learning-keras-tensorflow/blob/master/2.3%20Supervised%20Learning%20-%20Famous%20Models%20with%20Keras.ipynb) | Use pre-trained models such as VGG16, VGG19, ResNet50, and Inception v3 with Keras. |\n| [auto-encoders](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.1.%20AutoEncoders%20and%20Embeddings.ipynb) | Learn about Autoencoders with Keras. |\n| [rnn-lstm](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.1%20RNN%20and%20LSTM.ipynb) | Learn about Recurrent Neural Networks (RNNs) with Keras. |\n| [lstm-sentence-gen](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/7.%20Recurrent%20Neural%20Networks/7.2%20LSTM%20for%20Sentence%20Generation.ipynb) |  Learn about RNNs using Long Short Term Memory (LSTM) networks with Keras. |\n| [nlp-deep-learning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/6.%20AutoEncoders%20and%20Embeddings/6.2%20NLP%20and%20Deep%20Learning.ipynb) | Learn about NLP using ANN (Artificial Neural Networks. |\n| [hyperparamter-tuning](https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/5.%20HyperParameter%20Tuning%20and%20Transfer%20Learning/5.1%20HyperParameter%20Tuning.ipynb) | Hyperparamters tuning using keras-wrapper.scikit-learn |\n\n### deep-learning-misc\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [deep-dream](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/deep-learning/deep-dream/dream.ipynb) | Caffe-based computer vision program which uses a convolutional neural network to find and enhance patterns in images. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scikitlearn.png\">\n</p>\n\n## scikit-learn\n\nIPython Notebook(s) demonstrating scikit-learn functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [intro](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb) | Intro notebook to scikit-learn.  Scikit-learn adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [knn](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-intro.ipynb#K-Nearest-Neighbors-Classifier) | Implement k-nearest neighbors in scikit-learn. |\n| [linear-reg](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-linear-reg.ipynb) | Implement linear regression in scikit-learn. |\n| [svm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-svm.ipynb) | Implement support vector machine classifiers with and without kernels in scikit-learn. |\n| [random-forest](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-random-forest.ipynb) | Implement random forest classifiers and regressors in scikit-learn. |\n| [k-means](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-k-means.ipynb) | Implement k-means clustering in scikit-learn. |\n| [pca](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-pca.ipynb) | Implement principal component analysis in scikit-learn. |\n| [gmm](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-gmm.ipynb) | Implement Gaussian mixture models in scikit-learn. |\n| [validation](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scikit-learn/scikit-learn-validation.ipynb) | Implement validation and model selection in scikit-learn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/scipy.png\">\n</p>\n\n## statistical-inference-scipy\n\nIPython Notebook(s) demonstrating statistical inference with SciPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| scipy | SciPy is a collection of mathematical algorithms and convenience functions built on the Numpy extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. |\n| [effect-size](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/effect_size.ipynb) | Explore statistics that quantify effect size by analyzing the difference in height between men and women.  Uses data from the Behavioral Risk Factor Surveillance System (BRFSS) to estimate the mean and standard deviation of height for adult women and men in the United States. |\n| [sampling](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/sampling.ipynb) | Explore random sampling by analyzing the average weight of men and women in the United States using BRFSS data. |\n| [hypothesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/scipy/hypothesis.ipynb) | Explore hypothesis testing by analyzing the difference of first-born babies compared with others. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/pandas.png\">\n</p>\n\n## pandas\n\nIPython Notebook(s) demonstrating pandas functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [pandas](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/pandas.ipynb) | Software library written for data manipulation and analysis in Python. Offers data structures and operations for manipulating numerical tables and time series. |\n| [github-data-wrangling](https://github.com/donnemartin/viz/blob/master/githubstats/data_wrangling.ipynb) | Learn how to load, clean, merge, and feature engineer by analyzing GitHub data from the [`Viz`](https://github.com/donnemartin/viz) repo. |\n| [Introduction-to-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.00-Introduction-to-Pandas.ipynb) | Introduction to Pandas. |\n| [Introducing-Pandas-Objects](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.01-Introducing-Pandas-Objects.ipynb) | Learn about Pandas objects. |\n| [Data Indexing and Selection](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.02-Data-Indexing-and-Selection.ipynb) | Learn about data indexing and selection in Pandas. |\n| [Operations-in-Pandas](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.03-Operations-in-Pandas.ipynb) | Learn about operating on data in Pandas. |\n| [Missing-Values](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.04-Missing-Values.ipynb) | Learn about handling missing data in Pandas. |\n| [Hierarchical-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.05-Hierarchical-Indexing.ipynb) | Learn about hierarchical indexing in Pandas. |\n| [Concat-And-Append](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.06-Concat-And-Append.ipynb) | Learn about combining datasets: concat and append in Pandas. |\n| [Merge-and-Join](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.07-Merge-and-Join.ipynb) | Learn about combining datasets: merge and join in Pandas. |\n| [Aggregation-and-Grouping](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.08-Aggregation-and-Grouping.ipynb) | Learn about aggregation and grouping in Pandas. |\n| [Pivot-Tables](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.09-Pivot-Tables.ipynb) | Learn about pivot tables in Pandas. |\n| [Working-With-Strings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.10-Working-With-Strings.ipynb) | Learn about vectorized string operations in Pandas. |\n| [Working-with-Time-Series](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.11-Working-with-Time-Series.ipynb) | Learn about working with time series in pandas. |\n| [Performance-Eval-and-Query](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/pandas/03.12-Performance-Eval-and-Query.ipynb) | Learn about high-performance Pandas: eval() and query() in Pandas. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/matplotlib.png\">\n</p>\n\n## matplotlib\n\nIPython Notebook(s) demonstrating matplotlib functionality.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [matplotlib](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib.ipynb) | Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. |\n| [matplotlib-applied](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/matplotlib-applied.ipynb) | Apply matplotlib visualizations to Kaggle competitions for exploratory data analysis.  Learn how to create bar plots, histograms, subplot2grid, normalized plots, scatter plots, subplots, and kernel density estimation plots. |\n| [Introduction-To-Matplotlib](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.00-Introduction-To-Matplotlib.ipynb) | Introduction to Matplotlib. |\n| [Simple-Line-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.01-Simple-Line-Plots.ipynb) | Learn about simple line plots in Matplotlib. |\n| [Simple-Scatter-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.02-Simple-Scatter-Plots.ipynb) | Learn about simple scatter plots in Matplotlib. |\n| [Errorbars.ipynb](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.03-Errorbars.ipynb) | Learn about visualizing errors in Matplotlib. |\n| [Density-and-Contour-Plots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.04-Density-and-Contour-Plots.ipynb) | Learn about density and contour plots in Matplotlib. |\n| [Histograms-and-Binnings](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.05-Histograms-and-Binnings.ipynb) | Learn about histograms, binnings, and density in Matplotlib. |\n| [Customizing-Legends](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.06-Customizing-Legends.ipynb) | Learn about customizing plot legends in Matplotlib. |\n| [Customizing-Colorbars](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.07-Customizing-Colorbars.ipynb) | Learn about customizing colorbars in Matplotlib. |\n| [Multiple-Subplots](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.08-Multiple-Subplots.ipynb) | Learn about multiple subplots in Matplotlib. |\n| [Text-and-Annotation](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.09-Text-and-Annotation.ipynb) | Learn about text and annotation in Matplotlib. |\n| [Customizing-Ticks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.10-Customizing-Ticks.ipynb) | Learn about customizing ticks in Matplotlib. |\n| [Settings-and-Stylesheets](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.11-Settings-and-Stylesheets.ipynb) | Learn about customizing Matplotlib: configurations and stylesheets. |\n| [Three-Dimensional-Plotting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.12-Three-Dimensional-Plotting.ipynb) | Learn about three-dimensional plotting in Matplotlib. |\n| [Geographic-Data-With-Basemap](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.13-Geographic-Data-With-Basemap.ipynb) | Learn about geographic data with basemap in Matplotlib. |\n| [Visualization-With-Seaborn](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/matplotlib/04.14-Visualization-With-Seaborn.ipynb) | Learn about visualization with Seaborn. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/numpy.png\">\n</p>\n\n## numpy\n\nIPython Notebook(s) demonstrating NumPy functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [numpy](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/numpy.ipynb) | Adds Python support for large, multi-dimensional arrays and matrices, along with a large library of high-level mathematical functions to operate on these arrays. |\n| [Introduction-to-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.00-Introduction-to-NumPy.ipynb) | Introduction to NumPy. |\n| [Understanding-Data-Types](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.01-Understanding-Data-Types.ipynb) | Learn about data types in Python. |\n| [The-Basics-Of-NumPy-Arrays](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.02-The-Basics-Of-NumPy-Arrays.ipynb) | Learn about the basics of NumPy arrays. |\n| [Computation-on-arrays-ufuncs](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.03-Computation-on-arrays-ufuncs.ipynb) | Learn about computations on NumPy arrays: universal functions. |\n| [Computation-on-arrays-aggregates](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.04-Computation-on-arrays-aggregates.ipynb) | Learn about aggregations: min, max, and everything in between in NumPy. |\n| [Computation-on-arrays-broadcasting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.05-Computation-on-arrays-broadcasting.ipynb) | Learn about computation on arrays: broadcasting in NumPy. |\n| [Boolean-Arrays-and-Masks](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.06-Boolean-Arrays-and-Masks.ipynb) | Learn about comparisons, masks, and boolean logic in NumPy. |\n| [Fancy-Indexing](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.07-Fancy-Indexing.ipynb) | Learn about fancy indexing in NumPy. |\n| [Sorting](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.08-Sorting.ipynb) | Learn about sorting arrays in NumPy. |\n| [Structured-Data-NumPy](http://nbviewer.jupyter.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/numpy/02.09-Structured-Data-NumPy.ipynb) | Learn about structured data: NumPy's structured arrays. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/python.png\">\n</p>\n\n## python-data\n\nIPython Notebook(s) demonstrating Python functionality geared towards data analysis.\n\n| Notebook | Description |\n|-----------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|\n| [data structures](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs.ipynb) | Learn Python basics with tuples, lists, dicts, sets. |\n| [data structure utilities](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/structs_utils.ipynb) | Learn Python operations such as slice, range, xrange, bisect, sort, sorted, reversed, enumerate, zip, list comprehensions. |\n| [functions](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/functions.ipynb) | Learn about more advanced Python features: Functions as objects, lambda functions, closures, *args, **kwargs currying, generators, generator expressions, itertools. |\n| [datetime](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/datetime.ipynb) | Learn how to work with Python dates and times: datetime, strftime, strptime, timedelta. |\n| [logging](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/logs.ipynb) | Learn about Python logging with RotatingFileHandler and TimedRotatingFileHandler. |\n| [pdb](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/pdb.ipynb) | Learn how to debug in Python with the interactive source code debugger. |\n| [unit tests](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/python-data/unit_tests.ipynb) | Learn how to test in Python with Nose unit tests. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/kaggle.png\">\n</p>\n\n## kaggle-and-business-analyses\n\nIPython Notebook(s) used in [kaggle](https://www.kaggle.com/) competitions and business analyses.\n\n| Notebook | Description |\n|-------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|\n| [titanic](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/kaggle/titanic.ipynb) | Predict survival on the Titanic.  Learn data cleaning, exploratory data analysis, and machine learning. |\n| [churn-analysis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/analyses/churn.ipynb) | Predict customer churn.  Exercise logistic regression, gradient boosting classifers, support vector machines, random forests, and k-nearest-neighbors.  Includes discussions of confusion matrices, ROC plots, feature importances, prediction probabilities, and calibration/descrimination.|\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/spark.png\">\n</p>\n\n## spark\n\nIPython Notebook(s) demonstrating spark and HDFS functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [spark](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/spark.ipynb) | In-memory cluster computing framework, up to 100 times faster for certain applications and is well suited for machine learning algorithms. |\n| [hdfs](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/spark/hdfs.ipynb) | Reliably stores very large files across machines in a large cluster. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/mrjob.png\">\n</p>\n\n## mapreduce-python\n\nIPython Notebook(s) demonstrating Hadoop MapReduce with mrjob functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|\n| [mapreduce-python](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/mapreduce/mapreduce-python.ipynb) | Runs MapReduce jobs in Python, executing jobs locally or on Hadoop clusters. Demonstrates Hadoop Streaming in Python code with unit test and [mrjob](https://github.com/Yelp/mrjob) config file to analyze Amazon S3 bucket logs on Elastic MapReduce.  [Disco](https://github.com/discoproject/disco/) is another python-based alternative.|\n\n<br/>\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/aws.png\">\n</p>\n\n## aws\n\nIPython Notebook(s) demonstrating Amazon Web Services (AWS) and AWS tools functionality.\n\n\nAlso check out:\n\n* [SAWS](https://github.com/donnemartin/saws): A Supercharged AWS command line interface (CLI).\n* [Awesome AWS](https://github.com/donnemartin/awesome-aws): A curated list of libraries, open source repos, guides, blogs, and other resources.\n\n| Notebook | Description |\n|------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [boto](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#Boto) | Official AWS SDK for Python. |\n| [s3cmd](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3cmd) | Interacts with S3 through the command line. |\n| [s3distcp](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3distcp) | Combines smaller files and aggregates them together by taking in a pattern and target file.  S3DistCp can also be used to transfer large volumes of data from S3 to your Hadoop cluster. |\n| [s3-parallel-put](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#s3-parallel-put) | Uploads multiple files to S3 in parallel. |\n| [redshift](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#redshift) | Acts as a fast data warehouse built on top of technology from massive parallel processing (MPP). |\n| [kinesis](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#kinesis) | Streams data in real time with the ability to process thousands of data streams per second. |\n| [lambda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/aws/aws.ipynb#lambda) | Runs code in response to events, automatically managing compute resources. |\n\n<br/>\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/donnemartin/data-science-ipython-notebooks/master/images/commands.png\">\n</p>\n\n## commands\n\nIPython Notebook(s) demonstrating various command lines for Linux, Git, etc.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [linux](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/linux.ipynb) | Unix-like and mostly POSIX-compliant computer operating system.  Disk usage, splitting files, grep, sed, curl, viewing running processes, terminal syntax highlighting, and Vim.|\n| [anaconda](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#anaconda) | Distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing, that aims to simplify package management and deployment. |\n| [ipython notebook](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ipython-notebook) | Web-based interactive computational environment where you can combine code execution, text, mathematics, plots and rich media into a single document. |\n| [git](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#git) | Distributed revision control system with an emphasis on speed, data integrity, and support for distributed, non-linear workflows. |\n| [ruby](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#ruby) | Used to interact with the AWS command line and for Jekyll, a blog framework that can be hosted on GitHub Pages. |\n| [jekyll](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#jekyll) | Simple, blog-aware, static site generator for personal, project, or organization sites.  Renders Markdown or Textile and Liquid templates, and produces a complete, static website ready to be served by Apache HTTP Server, Nginx or another web server. |\n| [pelican](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#pelican) | Python-based alternative to Jekyll. |\n| [django](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/commands/misc.ipynb#django) | High-level Python Web framework that encourages rapid development and clean, pragmatic design. It can be useful to share reports/analyses and for blogging. Lighter-weight alternatives include [Pyramid](https://github.com/Pylons/pyramid), [Flask](https://github.com/pallets/flask), [Tornado](https://github.com/tornadoweb/tornado), and [Bottle](https://github.com/bottlepy/bottle).\n\n## misc\n\nIPython Notebook(s) demonstrating miscellaneous functionality.\n\n| Notebook | Description |\n|--------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| [regex](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/regex.ipynb) | Regular expression cheat sheet useful in data wrangling.|\n[algorithmia](http://nbviewer.ipython.org/github/TarrySingh/Machine-Learning-Tutorials/blob/master/misc/Algorithmia.ipynb) | Algorithmia is a marketplace for algorithms. This notebook showcases 4 different algorithms: Face Detection, Content Summarizer, Latent Dirichlet Allocation and Optical Character Recognition.|\n\n## notebook-installation\n\n### anaconda\n\nAnaconda is a free distribution of the Python programming language for large-scale data processing, predictive analytics, and scientific computing that aims to simplify package management and deployment.\n\nFollow instructions to install [Anaconda](https://docs.continuum.io/anaconda/install) or the more lightweight [miniconda](http://conda.pydata.org/miniconda.html).\n\n### dev-setup\n\nFor detailed instructions, scripts, and tools to set up your development environment for data analysis, check out the [dev-setup](https://github.com/donnemartin/dev-setup) repo.\n\n### running-notebooks\n\nNote: If you intend to learn the hard way (preferred method)then I'd strongly advice to write as much code as you can yourself and not just run pre-written code. If you still want to test it, then do the following: \n\nTo view interactive content or to modify elements within the IPython notebooks, you must first clone or download the repository then run the notebook.  More information on IPython Notebooks can be found [here.](http://ipython.org/notebook.html)\n\n    $ git clone https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials.git\n    $ cd Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials\n    $ jupyter notebook\n    \n\nNotebooks tested with Python 3.7+\n\n## curated-list-of-deeplearning-blogs\n\n* A Blog From a Human-engineer-being http://www.erogol.com/ [(RSS)](http://www.erogol.com/feed/)\n* Aakash Japi http://aakashjapi.com/ [(RSS)](http://logicx24.github.io/feed.xml)\n* Adit Deshpande https://adeshpande3.github.io/ [(RSS)](https://adeshpande3.github.io/adeshpande3.github.io/feed.xml)\n* Advanced Analytics & R http://advanceddataanalytics.net/ [(RSS)](http://advanceddataanalytics.net/feed/)\n* Adventures in Data Land http://blog.smola.org [(RSS)](http://blog.smola.org/rss)\n* Agile Data Science http://blog.sense.io/ [(RSS)](http://blog.sense.io/rss/)\n* Ahmed El Deeb https://medium.com/@D33B [(RSS)](https://medium.com/feed/@D33B)\n* Airbnb Data blog http://nerds.airbnb.com/data/ [(RSS)](http://nerds.airbnb.com/feed/)\n* Alex Castrounis | InnoArchiTech http://www.innoarchitech.com/ [(RSS)](http://www.innoarchitech.com/feed.xml)\n* Alex Perrier http://alexperrier.github.io/ [(RSS)](http://alexperrier.github.io/feed.xml)\n* Algobeans | Data Analytics Tutorials & Experiments for the Layman https://algobeans.com [(RSS)](https://algobeans.com/feed/)\n* Amazon AWS AI Blog https://aws.amazon.com/blogs/ai/ [(RSS)](https://aws.amazon.com/blogs/amazon-ai/feed/)\n* Analytics Vidhya http://www.analyticsvidhya.com/blog/ [(RSS)](http://feeds.feedburner.com/AnalyticsVidhya)\n* Analytics and Visualization in Big Data @ Sicara https://blog.sicara.com [(RSS)](https://blog.sicara.com/feed)\n* Andreas Mller http://peekaboo-vision.blogspot.com/ [(RSS)](http://peekaboo-vision.blogspot.com/atom.xml)\n* Andrej Karpathy blog http://karpathy.github.io/ [(RSS)](http://karpathy.github.io/feed.xml)\n* Andrew Brooks http://brooksandrew.github.io/simpleblog/ [(RSS)](http://brooksandrew.github.io/simpleblog/feed.xml)\n* Andrey Kurenkov http://www.andreykurenkov.com/writing/ [(RSS)](http://www.andreykurenkov.com/writing/feed.xml/)\n* Anton Lebedevich's Blog http://mabrek.github.io/ [(RSS)](http://mabrek.github.io/feed.xml)\n* Arthur Juliani https://medium.com/@awjuliani [(RSS)](https://medium.com/feed/@awjuliani)\n* Audun M. ygard http://www.auduno.com/ [(RSS)](http://auduno.tumblr.com/rss)\n* Avi Singh https://avisingh599.github.io/ [(RSS)](http://avisingh599.github.io/feed.xml)\n* Beautiful Data http://beautifuldata.net/ [(RSS)](http://beautifuldata.net/feed/)\n* Beckerfuffle http://mdbecker.github.io/ [(RSS)](http://mdbecker.github.io/atom.xml)\n* Becoming A Data Scientist http://www.becomingadatascientist.com/ [(RSS)](http://www.becomingadatascientist.com/feed/)\n* Ben Bolte's Blog http://benjaminbolte.com/ml/ [(RSS)](http://benjaminbolte.com/ml/)\n* Ben Frederickson http://www.benfrederickson.com/blog/ [(RSS)](http://www.benfrederickson.com/atom.xml)\n* Berkeley AI Research http://bair.berkeley.edu/blog/ [(RSS)](http://bair.berkeley.edu/blog/feed.xml)\n* Big-Ish Data http://bigishdata.com/ [(RSS)](http://bigishdata.com/feed/)\n* Blog on neural networks http://yerevann.github.io/ [(RSS)](http://yerevann.github.io/atom.xml)\n* Blogistic RegressionAbout Projects http://d10genes.github.io/blog/ [(RSS)](http://d10genes.github.io/blog/feed.xml)\n* blogR | R tips and tricks from a scientist https://drsimonj.svbtle.com/ [(RSS)](https://drsimonj.svbtle.com/)\n* Brain of mat kelcey http://matpalm.com/blog/ [(RSS)](http://matpalm.com/blog/feed)\n* Brilliantly wrong thoughts on science and programming https://arogozhnikov.github.io/ [(RSS)](http://arogozhnikov.github.io/feed.xml)\n* Bugra Akyildiz http://bugra.github.io/ [(RSS)](http://bugra.github.io/feeds/all.atom.xml)\n* Building Babylon https://building-babylon.net/ [(RSS)](http://building-babylon.net/feed/)\n* Carl Shan http://carlshan.com/ [(RSS)](http://feeds.feedburner.com/carlshan)\n* Chris Stucchio https://www.chrisstucchio.com/blog/index.html [(RSS)](http://www.chrisstucchio.com/blog/atom.xml)\n* Christophe Bourguignat https://medium.com/@chris_bour [(RSS)](https://medium.com/feed/@chris_bour)\n* Christopher Nguyen https://medium.com/@ctn [(RSS)](https://medium.com/feed/@ctn)\n* Cloudera Data Science Posts http://blog.cloudera.com/blog/category/data-science/ [(RSS)](http://blog.cloudera.com/blog/category/data-science/feed/)\n* colah's blog http://colah.github.io/archive.html [(RSS)](http://colah.github.io/rss.xml)\n* Cortana Intelligence and Machine Learning Blog https://blogs.technet.microsoft.com/machinelearning/ [(RSS)](http://blogs.technet.com/b/machinelearning/rss.aspx)\n* Daniel Forsyth http://www.danielforsyth.me/ [(RSS)](http://www.danielforsyth.me/rss/)\n* Daniel Homola http://danielhomola.com/category/blog/ [(RSS)](http://danielhomola.com/feed/)\n* Daniel Nee http://danielnee.com [(RSS)](http://danielnee.com/?feed=rss2)\n* Data Based Inventions http://datalab.lu/ [(RSS)](http://datalab.lu/atom.xml)\n* Data Blogger https://www.data-blogger.com/ [(RSS)](https://www.data-blogger.com/feed/)\n* Data Labs http://blog.insightdatalabs.com/ [(RSS)](http://blog.insightdatalabs.com/rss/)\n* Data Meets Media http://datameetsmedia.com/ [(RSS)](http://datameetsmedia.com/feed/)\n* Data Miners Blog http://blog.data-miners.com/ [(RSS)](http://blog.data-miners.com/feeds/posts/default?alt=rss)\n* Data Mining Research http://www.dataminingblog.com/ [(RSS)](http://feeds.feedburner.com/dataminingblog)\n* Data Mining: Text Mining, Visualization and Social Media http://datamining.typepad.com/data_mining/ [(RSS)](http://datamining.typepad.com/data_mining/atom.xml)\n* Data Piques http://blog.ethanrosenthal.com/ [(RSS)](http://blog.ethanrosenthal.com/feeds/all.atom.xml)\n* Data School http://www.dataschool.io/ [(RSS)](http://www.dataschool.io/rss/)\n* Data Science 101 http://101.datascience.community/ [(RSS)](http://101.datascience.community/feed/)\n* Data Science @ Facebook https://research.facebook.com/blog/datascience/ [(RSS)](https://research.facebook.com/blog/datascience/)\n* Data Science Insights http://www.datasciencebowl.com/data-science-insights/ [(RSS)](http://www.datasciencebowl.com/feed/)\n* Data Science Tutorials https://codementor.io/data-science/tutorial [(RSS)](https://www.codementor.io/data-science/tutorial/feed)\n* Data Science Vademecum http://datasciencevademecum.wordpress.com/ [(RSS)](http://datasciencevademecum.wordpress.com/feed/)\n* Dataaspirant http://dataaspirant.com/ [(RSS)](http://dataaspirant.wordpress.com/feed/)\n* Dataclysm http://blog.okcupid.com/ [(RSS)](http://blog.okcupid.com/index.php/feed/)\n* DataGenetics http://datagenetics.com/blog.html [(RSS)](http://datagenetics.com/feed/rss.xml)\n* Dataiku https://www.dataiku.com/blog/ [(RSS)](http://www.dataiku.com/feed.xml)\n* DataKind http://www.datakind.org/blog [(RSS)](http://feeds.feedburner.com/DataKin)\n* DataLook http://blog.datalook.io/ [(RSS)](http://blog.datalook.io/feed/)\n* Datanice https://datanice.wordpress.com/ [(RSS)](https://datanice.wordpress.com/feed/)\n* Dataquest Blog https://www.dataquest.io/blog/ [(RSS)](https://www.dataquest.io/blog/atom.xml)\n* DataRobot http://www.datarobot.com/blog/ [(RSS)](http://www.datarobot.com/feed/)\n* Datascope http://datascopeanalytics.com/blog [(RSS)](http://datascopeanalytics.com/rss)\n* DatasFrame http://tomaugspurger.github.io/ [(RSS)](http://tomaugspurger.github.io/feeds/all.rss.xml)\n* David Mimno http://www.mimno.org/ [(RSS)](http://mimno.infosci.cornell.edu/b/feed.xml)\n* Dayne Batten http://daynebatten.com [(RSS)](http://daynebatten.com/feed/)\n* Deep Learning http://deeplearning.net/blog/ [(RSS)](http://deeplearning.net/feed/)\n* Deepdish http://deepdish.io/ [(RSS)](http://deepdish.io/atom.xml)\n* Delip Rao http://deliprao.com/ [(RSS)](http://deliprao.com/feed)\n* DENNY'S BLOG http://blog.dennybritz.com/ [(RSS)](http://blog.dennybritz.com/feed/)\n* Dimensionless https://dimensionless.in/blog/ [(RSS)](https://dimensionless.in/feed)\n* Distill http://distill.pub/ [(RSS)](http://distill.pub/rss.xml)\n* District Data Labs http://districtdatalabs.silvrback.com/ [(RSS)](https://districtdatalabs.silvrback.com/feed)\n* Diving into data https://blog.datadive.net/ [(RSS)](http://blog.datadive.net/feed/)\n* Domino Data Lab's blog http://blog.dominodatalab.com/ [(RSS)](http://blog.dominodatalab.com/rss/)\n* Dr. Randal S. Olson http://www.randalolson.com/blog/ [(RSS)](http://www.randalolson.com/feed/)\n* Drew Conway https://medium.com/@drewconway [(RSS)](https://medium.com/feed/@drewconway)\n* Dustin Tran http://dustintran.com/blog/ [(RSS)](http://dustintran.com/blog/rss/)\n* Eder Santana https://edersantana.github.io/blog.html [(RSS)](http://edersantana.github.io/feed.xml)\n* Edwin Chen http://blog.echen.me [(RSS)](http://blog.echen.me/feeds/all.rss.xml)\n* EFavDB http://efavdb.com/ [(RSS)](http://efavdb.com/feed/)\n* Emilio Ferrara, Ph.D.  http://www.emilio.ferrara.name/ [(RSS)](http://www.emilio.ferrara.name/feed/)\n* Entrepreneurial Geekiness http://ianozsvald.com/ [(RSS)](http://ianozsvald.com/feed/)\n* Eric Jonas http://ericjonas.com/archives.html [(RSS)](http://ericjonas.com/archives.html)\n* Eric Siegel http://www.predictiveanalyticsworld.com/blog [(RSS)](http://feeds.feedburner.com/predictiveanalyticsworld/GXRy)\n* Erik Bern http://erikbern.com [(RSS)](http://erikbern.com/feed/)\n* ERIN SHELLMAN http://www.erinshellman.com/ [(RSS)](http://www.erinshellman.com/feed/)\n* Eugenio Culurciello http://culurciello.github.io/ [(RSS)](http://culurciello.github.io/feed.xml)\n* Fabian Pedregosa http://fa.bianp.net/ [(RSS)](http://fa.bianp.net/blog/feed/)\n* Fast Forward Labs http://blog.fastforwardlabs.com/ [(RSS)](http://blog.fastforwardlabs.com/rss)\n* FastML http://fastml.com/ [(RSS)](http://fastml.com/atom.xml)\n* Florian Hartl http://florianhartl.com/ [(RSS)](http://florianhartl.com/feed/)\n* FlowingData http://flowingdata.com/ [(RSS)](http://flowingdata.com/feed/)\n* Full Stack ML http://fullstackml.com/ [(RSS)](http://fullstackml.com/feed/)\n* GAB41 http://www.lab41.org/gab41/ [(RSS)](http://www.lab41.org/feed/)\n* Garbled Notes http://www.chioka.in/ [(RSS)](http://www.chioka.in/feed.xml)\n* Greg Reda http://www.gregreda.com/blog/ [(RSS)](http://www.gregreda.com/feeds/all.atom.xml)\n* Hyon S Chu https://medium.com/@adailyventure [(RSS)](https://medium.com/feed/@adailyventure)\n* i am trask http://iamtrask.github.io/ [(RSS)](http://iamtrask.github.io/feed.xml)\n* I Quant NY http://iquantny.tumblr.com/ [(RSS)](http://iquantny.tumblr.com/rss)\n* inFERENCe http://www.inference.vc/ [(RSS)](http://www.inference.vc/rss/)\n* Insight Data Science https://blog.insightdatascience.com/ [(RSS)](https://blog.insightdatascience.com/feed)\n* INSPIRATION INFORMATION http://myinspirationinformation.com/ [(RSS)](http://myinspirationinformation.com/feed/)\n* Ira Korshunova http://irakorshunova.github.io/ [(RSS)](http://irakorshunova.github.io/feed.xml)\n* Im a bandit https://blogs.princeton.edu/imabandit/ [(RSS)](https://blogs.princeton.edu/imabandit/feed/)\n* Jason Toy http://www.jtoy.net/ [(RSS)](http://jtoy.net/atom.xml)\n* Jeremy D. Jackson, PhD http://www.jeremydjacksonphd.com/ [(RSS)](http://www.jeremydjacksonphd.com/?feed=rss2)\n* Jesse Steinweg-Woods https://jessesw.com/ [(RSS)](https://jessesw.com/feed.xml)\n* Joe Cauteruccio http://www.joecjr.com/ [(RSS)](http://www.joecjr.com/feed/)\n* John Myles White http://www.johnmyleswhite.com/ [(RSS)](http://www.johnmyleswhite.com/feed/)\n* John's Soapbox http://joschu.github.io/ [(RSS)](http://joschu.github.io/feed.xml)\n* Jonas Degrave http://317070.github.io/ [(RSS)](http://317070.github.io/feed.xml)\n* Joy Of Data http://www.joyofdata.de/blog/ [(RSS)](http://www.joyofdata.de/blog/feed/)\n* Julia Evans http://jvns.ca/ [(RSS)](http://jvns.ca/atom.xml)\n* KDnuggets http://www.kdnuggets.com/ [(RSS)](http://feeds.feedburner.com/kdnuggets-data-mining-analytics)\n* Keeping Up With The Latest Techniques http://colinpriest.com/ [(RSS)](http://colinpriest.com/feed/)\n* Kenny Bastani http://www.kennybastani.com/ [(RSS)](http://www.kennybastani.com/feeds/posts/default?alt=rss)\n* Kevin Davenport http://kldavenport.com/ [(RSS)](http://kldavenport.com/feed/)\n* kevin frans http://kvfrans.com/ [(RSS)](http://kvfrans.com/rss/)\n* korbonits | Math  Data http://korbonits.github.io/ [(RSS)](http://korbonits.github.io/feed.xml)\n* Large Scale Machine Learning  http://bickson.blogspot.com/ [(RSS)](http://bickson.blogspot.com/feeds/posts/default)\n* LATERAL BLOG https://blog.lateral.io/ [(RSS)](https://blog.lateral.io/feed/)\n* Lazy Programmer http://lazyprogrammer.me/ [(RSS)](http://lazyprogrammer.me/feed/)\n* Learn Analytics Here https://learnanalyticshere.wordpress.com/ [(RSS)](https://learnanalyticshere.wordpress.com/feed/)\n* LearnDataSci http://www.learndatasci.com/ [(RSS)](http://www.learndatasci.com/feed/)\n* Learning With Data http://learningwithdata.com/ [(RSS)](http://learningwithdata.com/rss_feed.xml)\n* Life, Language, Learning http://daoudclarke.github.io/ [(RSS)](http://daoudclarke.github.io/atom.xml)\n* Locke Data https://itsalocke.com/blog/ [(RSS)](https://itsalocke.com/feed)\n* Louis Dorard http://www.louisdorard.com/blog/ [(RSS)](http://www.louisdorard.com/blog?format=rss)\n* M.E.Driscoll http://medriscoll.com/ [(RSS)](http://medriscoll.com/rss)\n* Machinalis http://www.machinalis.com/blog [(RSS)](http://www.machinalis.com/blog/feeds/rss/)\n* Machine Learning (Theory) http://hunch.net/ [(RSS)](http://hunch.net/?feed=rss2)\n* Machine Learning and Data Science http://alexhwoods.com/blog/ [(RSS)](http://alexhwoods.com/feed/)\n* Machine Learning https://charlesmartin14.wordpress.com/ [(RSS)](http://charlesmartin14.wordpress.com/feed/)\n* Machine Learning Mastery http://machinelearningmastery.com/blog/ [(RSS)](http://machinelearningmastery.com/feed/)\n* Machine Learning Blogs https://machinelearningblogs.com/ [(RSS)](https://machinelearningblogs.com/feed/)\n* Machine Learning, etc http://yaroslavvb.blogspot.com [(RSS)](http://yaroslavvb.blogspot.com/feeds/posts/default)\n* Machine Learning, Maths and Physics https://mlopezm.wordpress.com/ [(RSS)](https://mlopezm.wordpress.com/feed/)\n* Machine Learning Flashcards https://machinelearningflashcards.com/ $10, but a nicely illustrated set of 300 flash cards\n* Machined Learnings http://www.machinedlearnings.com/ [(RSS)](http://www.machinedlearnings.com/feeds/posts/default)\n* MAPPING BABEL https://jack-clark.net/ [(RSS)](https://jack-clark.net/feed/)\n* MAPR Blog https://www.mapr.com/blog [(RSS)](https://www.mapr.com/bigdata.xml)\n* MAREK REI http://www.marekrei.com/blog/ [(RSS)](http://www.marekrei.com/blog/feed/)\n* MARGINALLY INTERESTING http://blog.mikiobraun.de/ [(RSS)](http://feeds.feedburner.com/MarginallyInteresting)\n* Math  Programming http://jeremykun.com/ [(RSS)](http://jeremykun.wordpress.com/feed/)\n* Matthew Rocklin http://matthewrocklin.com/blog/ [(RSS)](http://matthewrocklin.com/blog/atom.xml)\n* Melody Wolk http://melodywolk.com/projects/ [(RSS)](http://melodywolk.com/feed/)\n* Mic Farris http://www.micfarris.com/ [(RSS)](http://www.micfarris.com/feed/)\n* Mike Tyka http://mtyka.github.io/ [(RSS)](http://mtyka.github.io//feed.xml)\n* minimaxir | Max Woolf's Blog http://minimaxir.com/ [(RSS)](http://minimaxir.com/rss.xml)\n* Mirror Image https://mirror2image.wordpress.com/ [(RSS)](http://mirror2image.wordpress.com/feed/)\n* Mitch Crowe http://www.dataphoric.com/ [(RSS)](http://www.dataphoric.com/feed.xml)\n* MLWave http://mlwave.com/ [(RSS)](http://mlwave.com/feed/)\n* MLWhiz http://mlwhiz.com/ [(RSS)](http://mlwhiz.com/atom.xml)\n* Models are illuminating and wrong https://peadarcoyle.wordpress.com/ [(RSS)](http://peadarcoyle.wordpress.com/feed/)\n* Moody Rd http://blog.mrtz.org/ [(RSS)](http://blog.mrtz.org/feed.xml)\n* Moonshots http://jxieeducation.com/ [(RSS)](http://jxieeducation.com/feed.xml)\n* Mourad Mourafiq http://mourafiq.com/ [(RSS)](http://mourafiq.com/atom.xml)\n* My thoughts on Data science, predictive analytics, Python http://shahramabyari.com/ [(RSS)](http://shahramabyari.com/feed/)\n* Natural language processing blog http://nlpers.blogspot.fr/ [(RSS)](http://nlpers.blogspot.com/feeds/posts/default)\n* Neil Lawrence http://inverseprobability.com/blog.html [(RSS)](http://inverseprobability.com/rss.xml)\n* NLP and Deep Learning enthusiast http://camron.xyz/ [(RSS)](http://camron.xyz/index.php/feed/)\n* no free hunch http://blog.kaggle.com/ [(RSS)](http://blog.kaggle.com/feed/)\n* Nuit Blanche http://nuit-blanche.blogspot.com/ [(RSS)](http://nuit-blanche.blogspot.com/feeds/posts/default)\n* Number 2147483647 https://no2147483647.wordpress.com/ [(RSS)](http://no2147483647.wordpress.com/feed/)\n* On Machine Intelligence https://aimatters.wordpress.com/ [(RSS)](https://aimatters.wordpress.com/feed/)\n* Opiate for the masses Data is our religion. http://opiateforthemass.es/ [(RSS)](http://opiateforthemass.es/feed.xml)\n* p-value.info http://www.p-value.info/ [(RSS)](http://www.p-value.info/feeds/posts/default)\n* Pete Warden's blog http://petewarden.com/ [(RSS)](http://feeds.feedburner.com/typepad/petewarden)\n* Plotly Blog http://blog.plot.ly/ [(RSS)](http://blog.plot.ly/rss)\n* Probably Overthinking It http://allendowney.blogspot.ca/ [(RSS)](http://allendowney.blogspot.com/feeds/posts/default)\n* Prooffreader.com http://www.prooffreader.com [(RSS)](http://www.prooffreader.com/feeds/posts/default)\n* ProoffreaderPlus http://prooffreaderplus.blogspot.ca/ [(RSS)](http://prooffreaderplus.blogspot.ca/feeds/posts/default)\n* Publishable Stuff http://www.sumsar.net/ [(RSS)](http://www.sumsar.net/atom.xml)\n* PyImageSearch http://www.pyimagesearch.com/ [(RSS)](http://feeds.feedburner.com/Pyimagesearch)\n* Pythonic Perambulations https://jakevdp.github.io/ [(RSS)](http://jakevdp.github.com/atom.xml)\n* quintuitive http://quintuitive.com/ [(RSS)](http://quintuitive.com/feed/)\n* R and Data Mining https://rdatamining.wordpress.com/ [(RSS)](http://rdatamining.wordpress.com/feed/)\n* R-bloggers http://www.r-bloggers.com/ [(RSS)](http://feeds.feedburner.com/RBloggers)\n* R2RT http://r2rt.com/ [(RSS)](http://r2rt.com/feeds/all.atom.xml)\n* Ramiro Gmez http://ramiro.org/notebooks/ [(RSS)](http://ramiro.org/notebook/rss.xml)\n* Random notes on Computer Science, Mathematics and Software Engineering http://barmaley-exe.github.io/ [(RSS)](http://feeds.feedburner.com/barmaley-exe-blog-feed)\n* Randy Zwitch http://randyzwitch.com/ [(RSS)](http://randyzwitch.com/feed.xml)\n* RaRe Technologies http://rare-technologies.com/blog/ [(RSS)](http://rare-technologies.com/feed/)\n* Rayli.Net http://rayli.net/blog/ [(RSS)](http://rayli.net/blog/feed/)\n* Revolutions http://blog.revolutionanalytics.com/ [(RSS)](http://blog.revolutionanalytics.com/atom.xml)\n* Rinu Boney http://rinuboney.github.io/ [(RSS)](http://rinuboney.github.io/feed.xml)\n* RNDuja Blog http://rnduja.github.io/ [(RSS)](http://rnduja.github.io/feed.xml)\n* Robert Chang https://medium.com/@rchang [(RSS)](https://medium.com/feed/@rchang)\n* Rocket-Powered Data Science http://rocketdatascience.org [(RSS)](http://rocketdatascience.org/?feed=rss2)\n* Sachin Joglekar's blog https://codesachin.wordpress.com/ [(RSS)](https://codesachin.wordpress.com/feed/)\n* samim https://medium.com/@samim [(RSS)](https://medium.com/feed/@samim)\n* Sean J. Taylor http://seanjtaylor.com/ [(RSS)](http://seanjtaylor.com/rss)\n* Sebastian Raschka http://sebastianraschka.com/blog/index.html [(RSS)](http://sebastianraschka.com/rss_feed.xml)\n* Sebastian Ruder http://sebastianruder.com/ [(RSS)](http://sebastianruder.com/rss/)\n* Sebastian's slow blog http://www.nowozin.net/sebastian/blog/ [(RSS)](http://www.nowozin.net/sebastian/blog/feeds/all.atom.xml)\n* SFL Scientific Blog https://sflscientific.com/blog/ [(RSS)](http://sflscientific.com/blog/?format=rss)\n* Shakir's Machine Learning Blog http://blog.shakirm.com/ [(RSS)](http://blog.shakirm.com/feed/)\n* Simply Statistics http://simplystatistics.org [(RSS)](http://simplystatistics.org/feed/)\n* Springboard Blog http://springboard.com/blog\n* Startup.ML Blog http://startup.ml/blog [(RSS)](http://www.startup.ml/blog?format=RSS)\n* Statistical Modeling, Causal Inference, and Social Science http://andrewgelman.com/ [(RSS)](http://andrewgelman.com/feed/)\n* Stigler Diet http://stiglerdiet.com/ [(RSS)](http://stiglerdiet.com/feeds/all.atom.xml)\n* Stitch Fix Tech Blog http://multithreaded.stitchfix.com/blog/ [(RSS)](http://multithreaded.stitchfix.com/feed.xml)\n* Stochastic R&D Notes http://arseny.info/ [(RSS)](http://arseny.info/feeds/all.rss.xml)\n* Storytelling with Statistics on Quora http://datastories.quora.com/ [(RSS)](http://datastories.quora.com/rss)\n* StreamHacker http://streamhacker.com/ [(RSS)](http://feeds.feedburner.com/StreamHacker)\n* Subconscious Musings http://blogs.sas.com/content/subconsciousmusings/ [(RSS)](http://feeds.feedburner.com/advanalytics)\n* Swan Intelligence http://swanintelligence.com/ [(RSS)](http://swanintelligence.com/feeds/all.rss.xml)\n* TechnoCalifornia http://technocalifornia.blogspot.se/ [(RSS)](http://technocalifornia.blogspot.com/feeds/posts/default)\n* TEXT ANALYSIS BLOG | AYLIEN http://blog.aylien.com/ [(RSS)](http://blog.aylien.com/rss)\n* The Angry Statistician http://angrystatistician.blogspot.com/ [(RSS)](http://angrystatistician.blogspot.com/feeds/posts/default)\n* The Clever Machine https://theclevermachine.wordpress.com/ [(RSS)](http://theclevermachine.wordpress.com/feed/)\n* The Data Camp Blog https://www.datacamp.com/community/blog [(RSS)](http://blog.datacamp.com/feed/)\n* The Data Incubator http://blog.thedataincubator.com/ [(RSS)](http://blog.thedataincubator.com/feed/)\n* The Data Science Lab https://datasciencelab.wordpress.com/ [(RSS)](http://datasciencelab.wordpress.com/feed/)\n* THE ETZ-FILES http://alexanderetz.com/ [(RSS)](http://nicebrain.wordpress.com/feed/)\n* The Science of Data http://www.martingoodson.com [(RSS)](http://www.martingoodson.com/rss/)\n* The Shape of Data https://shapeofdata.wordpress.com [(RSS)](https://shapeofdata.wordpress.com/feed/)\n* The unofficial Google data science Blog http://www.unofficialgoogledatascience.com/ [(RSS)](http://www.unofficialgoogledatascience.com/feeds/posts/default)\n* Tim Dettmers http://timdettmers.com/ [(RSS)](http://timdettmers.com/feed/)\n* Tombone's Computer Vision Blog http://www.computervisionblog.com/ [(RSS)](http://www.computervisionblog.com/feeds/posts/default)\n* Tommy Blanchard http://tommyblanchard.com/category/projects [(RSS)](http://tommyblanchard.com/feeds/all.atom.xml)\n* Trevor Stephens http://trevorstephens.com/ [(RSS)](http://trevorstephens.com/feed.xml)\n* Trey Causey http://treycausey.com/ [(RSS)](http://treycausey.com/feeds/all.atom.xml)\n* UW Data Science Blog http://datasciencedegree.wisconsin.edu/blog/ [(RSS)](http://datasciencedegree.wisconsin.edu/feed/)\n* Wellecks http://wellecks.wordpress.com/ [(RSS)](http://wellecks.wordpress.com/feed/)\n* Wes McKinney http://wesmckinney.com/archives.html [(RSS)](http://wesmckinney.com/feeds/all.atom.xml)\n* While My MCMC Gently Samples http://twiecki.github.io/ [(RSS)](http://twiecki.github.io/atom.xml)\n* WildML http://www.wildml.com/ [(RSS)](http://www.wildml.com/feed/)\n* Will do stuff for stuff http://rinzewind.org/blog-en [(RSS)](http://rinzewind.org/feed-en)\n* Will wolf http://willwolf.io/ [(RSS)](http://willwolf.io/feed/)\n* WILL'S NOISE http://www.willmcginnis.com/ [(RSS)](http://www.willmcginnis.com/feed/)\n* William Lyon http://www.lyonwj.com/ [(RSS)](http://www.lyonwj.com/atom.xml)\n* Win-Vector Blog http://www.win-vector.com/blog/ [(RSS)](http://www.win-vector.com/blog/feed/)\n* Yanir Seroussi http://yanirseroussi.com/ [(RSS)](http://yanirseroussi.com/feed/)\n* Zac Stewart http://zacstewart.com/ [(RSS)](http://zacstewart.com/feed.xml)\n* hat http://blog.yhat.com/ [(RSS)](http://blog.yhat.com/rss.xml)\n* uantitative ourney http://outlace.com/ [(RSS)](http://outlace.com/feed.xml)\n*  http://blog.otoro.net/ [(RSS)](http://blog.otoro.net/feed.xml)\n\n\n## credits\n\n* [Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython](http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793) by Wes McKinney\n* [PyCon 2015 Scikit-learn Tutorial](https://github.com/jakevdp/sklearn_pycon2015) by Jake VanderPlas\n* [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook) by Jake VanderPlas\n* [Parallel Machine Learning with scikit-learn and IPython](https://github.com/ogrisel/parallel_ml_tutorial) by Olivier Grisel\n* [Statistical Interference Using Computational Methods in Python](https://github.com/AllenDowney/CompStats) by Allen Downey\n* [TensorFlow Examples](https://github.com/aymericdamien/TensorFlow-Examples) by Aymeric Damien\n* [TensorFlow Tutorials](https://github.com/pkmital/tensorflow_tutorials) by Parag K Mital\n* [TensorFlow Tutorials](https://github.com/nlintz/TensorFlow-Tutorials) by Nathan Lintz\n* [TensorFlow Tutorials](https://github.com/alrojo/tensorflow-tutorial) by Alexander R Johansen\n* [TensorFlow Book](https://github.com/BinRoot/TensorFlow-Book) by Nishant Shukla\n* [Summer School 2015](https://github.com/mila-udem/summerschool2015) by mila-udem\n* [Keras tutorials](https://github.com/leriomaggio/deep-learning-keras-tensorflow) by Valerio Maggio\n* [Kaggle](https://www.kaggle.com/)\n* [Yhat Blog](http://blog.yhat.com/)\n\n## contributing\n\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/tarrysingh/Machine-Learning-Tutorials//issues).\n\n## contact-info\n\nFeel free to contact me to discuss any issues, questions, or comments.\n\n* Email: [tarry.singh@gmail.com](mailto:tarry.singh@gmail.com)\n* Twitter: [@tarrysingh](https://twitter.com/tarrysingh)\n* GitHub: [tarrysingh](https://github.com/tarrysingh.com)\n* LinkedIn: [Tarry Singh](https://www.linkedin.com/in/tarrysingh)\n* Website: [tarrysingh.com](https://tarrysingh.com)\n* Medium: [tarry@Medium](https://medium.com/@tarrysingh)\n* Quora : [Answers from Tarry on Quora](https://www.quora.com/profile/Tarry-Singh)\n\n## license\n\nThis repository contains a variety of content; some developed by Tarry Singh and some from third-parties and a lot will be maintained by me. The third-party content is distributed under the license provided by those parties.\n\nThe content was originally started by Donne Martin is distributed under the following license in 2017. I have been further developing and maintaining it by adding PyTorch, Torch/Lua, MXNET and much more:\n\n*I am providing code and resources in this repository to you under an open source license.*\n\n    Copyright 2017 Tarry Singh\n\n    Licensed under the Apache License, Version 2.0 (the \"License\");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an \"AS IS\" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n"
        },
        {
          "name": "Setting_Up_GPU",
          "type": "tree",
          "content": null
        },
        {
          "name": "__init__.py",
          "type": "blob",
          "size": 0,
          "content": ""
        },
        {
          "name": "aws",
          "type": "tree",
          "content": null
        },
        {
          "name": "commands",
          "type": "tree",
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "deep-learning",
          "type": "tree",
          "content": null
        },
        {
          "name": "earth-sciences",
          "type": "tree",
          "content": null
        },
        {
          "name": "gcp",
          "type": "tree",
          "content": null
        },
        {
          "name": "github",
          "type": "tree",
          "content": null
        },
        {
          "name": "growth-marketing-churn-analyses",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "java",
          "type": "tree",
          "content": null
        },
        {
          "name": "julia",
          "type": "tree",
          "content": null
        },
        {
          "name": "kaggle",
          "type": "tree",
          "content": null
        },
        {
          "name": "machine-learning",
          "type": "tree",
          "content": null
        },
        {
          "name": "mapreduce",
          "type": "tree",
          "content": null
        },
        {
          "name": "matplotlib",
          "type": "tree",
          "content": null
        },
        {
          "name": "misc",
          "type": "tree",
          "content": null
        },
        {
          "name": "neurophysics-neuroscience",
          "type": "tree",
          "content": null
        },
        {
          "name": "numpy",
          "type": "tree",
          "content": null
        },
        {
          "name": "pandas",
          "type": "tree",
          "content": null
        },
        {
          "name": "plotly",
          "type": "tree",
          "content": null
        },
        {
          "name": "python-data",
          "type": "tree",
          "content": null
        },
        {
          "name": "python-tuts",
          "type": "tree",
          "content": null
        },
        {
          "name": "pytorch",
          "type": "tree",
          "content": null
        },
        {
          "name": "quanteconomics",
          "type": "tree",
          "content": null
        },
        {
          "name": "quantum gravity",
          "type": "tree",
          "content": null
        },
        {
          "name": "scikit-learn",
          "type": "tree",
          "content": null
        },
        {
          "name": "scipy",
          "type": "tree",
          "content": null
        },
        {
          "name": "spark",
          "type": "tree",
          "content": null
        },
        {
          "name": "sympy",
          "type": "tree",
          "content": null
        },
        {
          "name": "tensorflow_dl_models",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}