{
  "metadata": {
    "timestamp": 1736559603940,
    "page": 241,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pythonprofilers/memory_profiler",
      "stars": 4411,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15234375,
          "content": ".idea\n.vscode\ndist\nbuild\nMANIFEST\n*.egg-info\n*.pyc\n*~\n.coverage\n\n# Ignore mprof generated files\nmprofile_*.dat\n\n# virtual environment\nvenv/\n.python-version\n"
        },
        {
          "name": "COPYING",
          "type": "blob",
          "size": 1.513671875,
          "content": "New BSD License\n\nCopyright (c) 2007â€“2014 Fabian Pedregosa.\nAll rights reserved.\n\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n  a. Redistributions of source code must retain the above copyright notice,\n     this list of conditions and the following disclaimer.\n  b. Redistributions in binary form must reproduce the above copyright\n     notice, this list of conditions and the following disclaimer in the\n     documentation and/or other materials provided with the distribution.\n  c. Neither the name of the memory_profiler developers nor the names of\n     its contributors may be used to endorse or promote products\n     derived from this software without specific prior written\n     permission. \n\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\nARE DISCLAIMED. IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\nLIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\nOUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH\nDAMAGE.\n\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 0.765625,
          "content": "PYTHON ?= python\n\n.PHONY: test develop\n\ntest:\n\t$(PYTHON) -m memory_profiler test/test_func.py\n\t$(PYTHON) -m memory_profiler test/test_loop.py\n\t$(PYTHON) -m memory_profiler test/test_mprofile.py\n\t$(PYTHON) -m memory_profiler test/test_as.py\n\t$(PYTHON) -m memory_profiler test/test_global.py\n\t$(PYTHON) -m memory_profiler test/test_precision_command_line.py\n\t$(PYTHON) -m memory_profiler test/test_gen.py\n\t$(PYTHON) -m memory_profiler test/test_unicode.py\n\t$(PYTHON) test/test_tracemalloc.py\n\t$(PYTHON) test/test_import.py\n\t$(PYTHON) test/test_memory_usage.py\n\t$(PYTHON) test/test_precision_import.py\n\t$(PYTHON) test/test_exception.py\n\t$(PYTHON) test/test_exit_code.py\n\t$(PYTHON) test/test_mprof.py\n\t$(PYTHON) test/test_async.py\n\tmprof run test/test_func.py\n\ndevelop:\n\tpip install -e .\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 19.173828125,
          "content": ".. image:: https://travis-ci.org/pythonprofilers/memory_profiler.svg?branch=master\n    :target: https://travis-ci.org/pythonprofilers/memory_profiler\n\n=================\n Memory Profiler\n=================\n\n\n**Note:** This package is no longer actively maintained. I won't be actively responding to issues.\n\nThis is a python module for monitoring memory consumption of a process\nas well as line-by-line analysis of memory consumption for python\nprograms. It is a pure python module which depends on the `psutil\n<http://pypi.python.org/pypi/psutil>`_ module.\n\n\n==============\n Installation\n==============\nInstall via pip::\n\n    $ pip install -U memory_profiler\n\nThe package is also available on `conda-forge\n<https://github.com/conda-forge/memory_profiler-feedstock>`_.\n\nTo install from source, download the package, extract and type::\n\n    $ pip install .\n\n===========\nQuick Start\n===========\n\nUse `mprof` to generate a full memory usage report of your executable and to plot it.\n\n.. code-block:: bash\n\n    mprof run executable\n    mprof plot\n\nThe plot would be something like this:\n\n.. image:: https://i.stack.imgur.com/ixCH4.png\n\n=======\n Usage\n=======\n\n\nline-by-line memory usage\n=========================\n\nThe line-by-line memory usage mode is used much in the same way of the\n`line_profiler <https://pypi.python.org/pypi/line_profiler/>`_: first\ndecorate the function you would like to profile with ``@profile`` and\nthen run the script with a special script (in this case with specific\narguments to the Python interpreter).\n\nIn the following example, we create a simple function ``my_func`` that\nallocates lists ``a``, ``b`` and then deletes ``b``:\n\n.. code-block:: python\n\n    @profile\n    def my_func():\n        a = [1] * (10 ** 6)\n        b = [2] * (2 * 10 ** 7)\n        del b\n        return a\n\n    if __name__ == '__main__':\n        my_func()\n\n\nExecute the code passing the option ``-m memory_profiler`` to the\npython interpreter to load the memory_profiler module and print to\nstdout the line-by-line analysis. If the file name was example.py,\nthis would result in::\n\n    $ python -m memory_profiler example.py\n\nOutput will follow::\n\n    Line #    Mem usage    Increment  Occurrences   Line Contents\n    ============================================================\n         3   38.816 MiB   38.816 MiB           1   @profile\n         4                                         def my_func():\n         5   46.492 MiB    7.676 MiB           1       a = [1] * (10 ** 6)\n         6  199.117 MiB  152.625 MiB           1       b = [2] * (2 * 10 ** 7)\n         7   46.629 MiB -152.488 MiB           1       del b\n         8   46.629 MiB    0.000 MiB           1       return a\n\n\nThe first column represents the line number of the code that has been\nprofiled, the second column (*Mem usage*) the memory usage of the\nPython interpreter after that line has been executed. The third column\n(*Increment*) represents the difference in memory of the current line\nwith respect to the last one. The fourth column (*Occurrences*) shows\nthe number of times that profiler has executed each line. The last column\n(*Line Contents*) prints the code that has been profiled.\n\nDecorator\n=========\nA function decorator is also available.  Use as follows:\n\n.. code-block:: python\n\n    from memory_profiler import profile\n\n    @profile\n    def my_func():\n        a = [1] * (10 ** 6)\n        b = [2] * (2 * 10 ** 7)\n        del b\n        return a\n\nIn this case the script can be run without specifying ``-m\nmemory_profiler`` in the command line.\n\nIn function decorator, you can specify the precision as an argument to the\ndecorator function.  Use as follows:\n\n.. code-block:: python\n\n    from memory_profiler import profile\n\n    @profile(precision=4)\n    def my_func():\n        a = [1] * (10 ** 6)\n        b = [2] * (2 * 10 ** 7)\n        del b\n        return a\n\nIf a python script with decorator ``@profile`` is called using ``-m\nmemory_profiler`` in the command line, the ``precision`` parameter is ignored.\n\nTime-based memory usage\n==========================\nSometimes it is useful to have full memory usage reports as a function of\ntime (not line-by-line) of external processes (be it Python scripts or not).\nIn this case the executable ``mprof`` might be useful. Use it like::\n\n    mprof run <executable>\n    mprof plot\n\nThe first line run the executable and record memory usage along time,\nin a file written in the current directory.\nOnce it's done, a graph plot can be obtained using the second line.\nThe recorded file contains a timestamps, that allows for several\nprofiles to be kept at the same time.\n\nHelp on each `mprof` subcommand can be obtained with the `-h` flag,\ne.g. `mprof run -h`.\n\nIn the case of a Python script, using the previous command does not\ngive you any information on which function is executed at a given\ntime. Depending on the case, it can be difficult to identify the part\nof the code that is causing the highest memory usage.\n\nAdding the `profile` decorator to a function(ensure no \n`from memory_profiler import profile` statement) and running the Python\nscript with\n\n    mprof run --python python <script>\n\nwill record timestamps when entering/leaving the profiled function. Running\n\n    mprof plot\n\nafterward will plot the result, making plots (using matplotlib) similar to these:\n\n.. image:: https://camo.githubusercontent.com/3a584c7cfbae38c9220a755aa21b5ef926c1031d/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313930383631382f3836313332302f63623865376337382d663563632d313165322d386531652d3539373237623636663462322e706e67\n   :target: https://github.com/scikit-learn/scikit-learn/pull/2248\n   :height: 350px\n\nor, with ``mprof plot --flame`` (the function and timestamp names will appear on hover):\n\n.. image:: ./images/flamegraph.png\n   :height: 350px\n\nA discussion of these capabilities can be found `here <http://fa.bianp.net/blog/2014/plot-memory-usage-as-a-function-of-time/>`_.\n\n.. warning:: If your Python file imports the memory profiler `from memory_profiler import profile` these timestamps will not be recorded. Comment out the import, leave your functions decorated, and re-run.\n\nThe available commands for `mprof` are:\n\n  - ``mprof run``: running an executable, recording memory usage\n  - ``mprof plot``: plotting one the recorded memory usage (by default,\n    the last one)\n  - ``mprof list``: listing all recorded memory usage files in a\n    user-friendly way.\n  - ``mprof clean``: removing all recorded memory usage files.\n  - ``mprof rm``: removing specific recorded memory usage files\n\nTracking forked child processes\n===============================\nIn a multiprocessing context the main process will spawn child processes whose\nsystem resources are allocated separately from the parent process. This can\nlead to an inaccurate report of memory usage since by default only the parent\nprocess is being tracked. The ``mprof`` utility provides two mechanisms to\ntrack the usage of child processes: sum the memory of all children to the\nparent's usage and track each child individual.\n\nTo create a report that combines memory usage of all the children and the\nparent, use the ``include-children`` flag in either the ``profile`` decorator or\nas a command line argument to ``mprof``::\n\n    mprof run --include-children <script>\n\nThe second method tracks each child independently of the main process,\nserializing child rows by index to the output stream. Use the ``multiprocess``\nflag and plot as follows::\n\n    mprof run --multiprocess <script>\n    mprof plot\n\nThis will create a plot using matplotlib similar to this:\n\n.. image:: https://cloud.githubusercontent.com/assets/745966/24075879/2e85b43a-0bfa-11e7-8dfe-654320dbd2ce.png\n    :target: https://github.com/pythonprofilers/memory_profiler/pull/134\n    :height: 350px\n\nYou can combine both the ``include-children`` and ``multiprocess`` flags to show\nthe total memory of the program as well as each child individually. If using\nthe API directly, note that the return from ``memory_usage`` will include the\nchild memory in a nested list along with the main process memory.\n\nPlot settings\n===============================\n\nBy default, the command line call is set as the graph title. If you wish to customize it, you can use the ``-t`` option to manually set the figure title.\n\n\n    mprof plot -t 'Recorded memory usage'\n\nYou can also hide the function timestamps using the ``n`` flag, such as\n\n    mprof plot -n\n\nTrend lines and its numeric slope can be plotted using the ``s`` flag, such as\n\n    mprof plot -s\n\n.. image:: ./images/trend_slope.png\n   :height: 350px\n\nThe intended usage of the -s switch is to check the labels' numerical slope over a significant time period for : \n\n  - ``>0`` it might mean a memory leak.\n  - ``~0`` if 0 or near 0, the memory usage may be considered stable.\n  - ``<0`` to be interpreted depending on the expected process memory usage patterns, also might mean that the sampling period is too small.\n\nThe trend lines are for ilustrative purposes and are plotted as (very) small dashed lines.\n\n\nSetting debugger breakpoints\n=============================\nIt is possible to set breakpoints depending on the amount of memory used.\nThat is, you can specify a threshold and as soon as the program uses more\nmemory than what is specified in the threshold it will stop execution\nand run into the pdb debugger. To use it, you will have to decorate\nthe function as done in the previous section with ``@profile`` and then\nrun your script with the option ``-m memory_profiler --pdb-mmem=X``,\nwhere X is a number representing the memory threshold in MB. For example::\n\n    $ python -m memory_profiler --pdb-mmem=100 my_script.py\n\nwill run ``my_script.py`` and step into the pdb debugger as soon as the code\nuses more than 100 MB in the decorated function.\n\n.. TODO: alternatives to decoration (for example when you don't want to modify\n    the file where your function lives).\n\n=====\n API\n=====\nmemory_profiler exposes a number of functions to be used in third-party\ncode.\n\n\n\n``memory_usage(proc=-1, interval=.1, timeout=None)`` returns the memory usage\nover a time interval. The first argument, ``proc`` represents what\nshould be monitored.  This can either be the PID of a process (not\nnecessarily a Python program), a string containing some python code to\nbe evaluated or a tuple ``(f, args, kw)`` containing a function and its\narguments to be evaluated as ``f(*args, **kw)``. For example,\n\n.. code-block:: python\n\n    >>> from memory_profiler import memory_usage\n    >>> mem_usage = memory_usage(-1, interval=.2, timeout=1)\n    >>> print(mem_usage)\n\t[7.296875, 7.296875, 7.296875, 7.296875, 7.296875]\n\n\nHere I've told memory_profiler to get the memory consumption of the\ncurrent process over a period of 1 second with a time interval of 0.2\nseconds. As PID I've given it -1, which is a special number (PIDs are\nusually positive) that means current process, that is, I'm getting the\nmemory usage of the current Python interpreter. Thus I'm getting\naround 7MB of memory usage from a plain python interpreter. If I try\nthe same thing on IPython (console) I get 29MB, and if I try the same\nthing on the IPython notebook it scales up to 44MB.\n\n\nIf you'd like to get the memory consumption of a Python function, then\nyou should specify the function and its arguments in the tuple ``(f,\nargs, kw)``. For example:\n\n.. code-block:: python\n\n    >>> # define a simple function\n    >>> def f(a, n=100):\n        ...     import time\n        ...     time.sleep(2)\n        ...     b = [a] * n\n        ...     time.sleep(1)\n        ...     return b\n        ...\n    >>> from memory_profiler import memory_usage\n    >>> memory_usage((f, (1,), {'n' : int(1e6)}))\n\nThis will execute the code `f(1, n=int(1e6))` and return the memory\nconsumption during this execution.\n\n=========\nREPORTING\n=========\n\nThe output can be redirected to a log file by passing IO stream as\nparameter to the decorator like @profile(stream=fp)\n\n.. code-block:: python\n\n    >>> fp=open('memory_profiler.log','w+')\n    >>> @profile(stream=fp)\n    >>> def my_func():\n        ...     a = [1] * (10 ** 6)\n        ...     b = [2] * (2 * 10 ** 7)\n        ...     del b\n        ...     return a\n\nFor details refer: examples/reporting_file.py\n\n``Reporting via logger Module:``\n\nSometime it would be very convenient to use logger module specially\nwhen we need to use RotatingFileHandler.\n\nThe output can be redirected to logger module by simply making use of\nLogFile of memory profiler module.\n\n.. code-block:: python\n\n    >>> from memory_profiler import LogFile\n    >>> import sys\n    >>> sys.stdout = LogFile('memory_profile_log')\n\n``Customized reporting:``\n\nSending everything to the log file while running the memory_profiler\ncould be cumbersome and one can choose only entries with increments\nby passing True to reportIncrementFlag, where reportIncrementFlag is\na parameter to LogFile class of memory profiler module.\n\n.. code-block:: python\n\n    >>> from memory_profiler import LogFile\n    >>> import sys\n    >>> sys.stdout = LogFile('memory_profile_log', reportIncrementFlag=False)\n\nFor details refer: examples/reporting_logger.py\n\n=====================\n IPython integration\n=====================\nAfter installing the module, if you use IPython, you can use the `%mprun`, `%%mprun`,\n`%memit` and `%%memit` magics.\n\nFor IPython 0.11+, you can use the module directly as an extension, with\n``%load_ext memory_profiler``\n\nTo activate it whenever you start IPython, edit the configuration file for your\nIPython profile, ~/.ipython/profile_default/ipython_config.py, to register the\nextension like this (If you already have other extensions, just add this one to\nthe list):\n\n.. code-block:: python\n\n    c.InteractiveShellApp.extensions = [\n        'memory_profiler',\n    ]\n\n(If the config file doesn't already exist, run ``ipython profile create`` in\na terminal.)\n\nIt then can be used directly from IPython to obtain a line-by-line\nreport using the `%mprun` or `%%mprun` magic command. In this case, you can skip\nthe `@profile` decorator and instead use the `-f` parameter, like\nthis. Note however that function my_func must be defined in a file\n(cannot have been defined interactively in the Python interpreter):\n\n.. code-block:: python\n\n    In [1]: from example import my_func, my_func_2\n\n    In [2]: %mprun -f my_func my_func()\n\nor in cell mode:\n\n.. code-block:: python\n\n    In [3]: %%mprun -f my_func -f my_func_2\n       ...: my_func()\n       ...: my_func_2()\n\nAnother useful magic that we define is `%memit`, which is analogous to\n`%timeit`. It can be used as follows:\n\n.. code-block:: python\n\n    In [1]: %memit range(10000)\n    peak memory: 21.42 MiB, increment: 0.41 MiB\n\n    In [2]: %memit range(1000000)\n    peak memory: 52.10 MiB, increment: 31.08 MiB\n\nor in cell mode (with setup code):\n\n.. code-block:: python\n\n    In [3]: %%memit l=range(1000000)\n       ...: len(l)\n       ...:\n    peak memory: 52.14 MiB, increment: 0.08 MiB\n\nFor more details, see the docstrings of the magics.\n\nFor IPython 0.10, you can install it by editing the IPython configuration\nfile ~/.ipython/ipy_user_conf.py to add the following lines:\n\n.. code-block:: python\n\n    # These two lines are standard and probably already there.\n    import IPython.ipapi\n    ip = IPython.ipapi.get()\n\n    # These two are the important ones.\n    import memory_profiler\n    memory_profiler.load_ipython_extension(ip)\n\n===============================\nMemory tracking backends\n===============================\n`memory_profiler` supports different memory tracking backends including: 'psutil', 'psutil_pss', 'psutil_uss', 'posix', 'tracemalloc'.\nIf no specific backend is specified the default is to use \"psutil\" which measures RSS aka \"Resident Set Size\". \nIn some cases (particularly when tracking child processes) RSS may overestimate memory usage (see `example/example_psutil_memory_full_info.py` for an example).\nFor more information on \"psutil_pss\" (measuring PSS) and \"psutil_uss\" please refer to:\nhttps://psutil.readthedocs.io/en/latest/index.html?highlight=memory_info#psutil.Process.memory_full_info \n\nCurrently, the backend can be set via the CLI\n\n    $ python -m memory_profiler --backend psutil my_script.py\n\nand is exposed by the API\n\n.. code-block:: python\n\n    >>> from memory_profiler import memory_usage\n    >>> mem_usage = memory_usage(-1, interval=.2, timeout=1, backend=\"psutil\")\n\n    \n============================\n Frequently Asked Questions\n============================\n    * Q: How accurate are the results ?\n    * A: This module gets the memory consumption by querying the\n      operating system kernel about the amount of memory the current\n      process has allocated, which might be slightly different from\n      the amount of memory that is actually used by the Python\n      interpreter. Also, because of how the garbage collector works in\n      Python the result might be different between platforms and even\n      between runs.\n\n    * Q: Does it work under windows ?\n    * A: Yes, thanks to the\n      `psutil <http://pypi.python.org/pypi/psutil>`_ module.\n\n\n===========================\n Support, bugs & wish list\n===========================\nFor support, please ask your question on `stack overflow\n<http://stackoverflow.com/>`_ and add the `*memory-profiling* tag <http://stackoverflow.com/questions/tagged/memory-profiling>`_.\nSend issues, proposals, etc. to `github's issue tracker\n<https://github.com/pythonprofilers/memory_profiler/issues>`_ .\n\nIf you've got questions regarding development, you can email me\ndirectly at f@bianp.net\n\n.. image:: http://fa.bianp.net/static/tux_memory_small.png\n\n\n=============\n Development\n=============\nLatest sources are available from github:\n\n    https://github.com/pythonprofilers/memory_profiler\n\n===============================\nProjects using memory_profiler\n===============================\n\n`Benchy <https://github.com/python-recsys/benchy>`_\n\n`IPython memory usage <https://github.com/ianozsvald/ipython_memory_usage>`_\n\n`PySpeedIT <https://github.com/peter1000/PySpeedIT>`_ (uses a reduced version of memory_profiler)\n\n`pydio-sync <https://github.com/pydio/pydio-sync>`_ (uses custom wrapper on top of memory_profiler)\n\n=========\n Authors\n=========\nThis module was written by `Fabian Pedregosa <http://fseoane.net>`_\nand `Philippe Gervais <https://github.com/pgervais>`_\ninspired by Robert Kern's `line profiler\n<http://packages.python.org/line_profiler/>`_.\n\n`Tom <http://tomforb.es/>`_ added windows support and speed improvements via the\n`psutil <http://pypi.python.org/pypi/psutil>`_ module.\n\n`Victor <https://github.com/octavo>`_ added python3 support, bugfixes and general\ncleanup.\n\n`Vlad Niculae <http://vene.ro/>`_ added the `%mprun` and `%memit` IPython magics.\n\n`Thomas Kluyver <https://github.com/takluyver>`_ added the IPython extension.\n\n`Sagar UDAY KUMAR <https://github.com/sagaru>`_ added Report generation feature and examples.\n\n`Dmitriy Novozhilov <https://github.com/demiurg906>`_ and `Sergei Lebedev <https://github.com/superbobry>`_ added support for `tracemalloc <https://docs.python.org/3/library/tracemalloc.html>`_.\n\n`Benjamin Bengfort <https://github.com/bbengfort>`_ added support for tracking the usage of individual child processes and plotting them.\n\n`Muhammad Haseeb Tariq <https://github.com/mhaseebtariq>`_ fixed issue #152, which made the whole interpreter hang on functions that launched an exception.\n\n`Juan Luis Cano <https://github.com/Juanlu001>`_ modernized the infrastructure and helped with various things.\n\n`Martin Becker <https://github.com/mgbckr>`_ added PSS and USS tracking via the psutil backend.\n\n=========\n License\n=========\nBSD License, see file COPYING for full text.\n"
        },
        {
          "name": "README_DEV.rst",
          "type": "blob",
          "size": 0.2685546875,
          "content": "Some information on the internals of this package.\n\nTests\n-----\n`make test` is the closest thing to tests on this package. It executes some\nexample code and prints the information. If you don't see any exceptions nor \nany strange output then the tests suite \"has succeeded\".\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "memory_profiler.py",
          "type": "blob",
          "size": 47.3896484375,
          "content": "\"\"\"Profile the memory usage of a Python program\"\"\"\n\n# .. we'll use this to pass it to the child script ..\n_CLEAN_GLOBALS = globals().copy()\n\n__version__ = '0.61.0'\n\n_CMD_USAGE = \"python -m memory_profiler script_file.py\"\n\nfrom asyncio import iscoroutinefunction\nfrom contextlib import contextmanager\nfrom functools import partial, wraps\nfrom types import coroutine\nimport builtins\nimport inspect\nimport linecache\nimport logging\nimport os\nimport io\nimport pdb\nimport subprocess\nimport sys\nimport time\nimport traceback\nimport warnings\n\nif sys.platform == \"win32\":\n    # any value except signal.CTRL_C_EVENT and signal.CTRL_BREAK_EVENT\n    # can be used to kill a process unconditionally in Windows\n    SIGKILL = -1\nelse:\n    from signal import SIGKILL\nimport psutil\n\n\n# TODO: provide alternative when multiprocessing is not available\ntry:\n    from multiprocessing import Process, Pipe\nexcept ImportError:\n    from multiprocessing.dummy import Process, Pipe\n\ntry:\n    from IPython.core.magic import Magics, line_cell_magic, magics_class\nexcept ImportError:\n    # ipython_version < '0.13'\n    Magics = object\n    line_cell_magic = lambda func: func\n    magics_class = lambda cls: cls\n\n_TWO_20 = float(2 ** 20)\n\n\n# .. get available packages ..\ntry:\n    import tracemalloc\n\n    has_tracemalloc = True\nexcept ImportError:\n    has_tracemalloc = False\n\n\nclass MemitResult(object):\n    \"\"\"memit magic run details.\n\n    Object based on IPython's TimeitResult\n    \"\"\"\n\n    def __init__(self, mem_usage, baseline, repeat, timeout, interval,\n                 include_children):\n        self.mem_usage = mem_usage\n        self.baseline = baseline\n        self.repeat = repeat\n        self.timeout = timeout\n        self.interval = interval\n        self.include_children = include_children\n\n    def __str__(self):\n        max_mem = max(self.mem_usage)\n        inc = max_mem - self.baseline\n        return 'peak memory: %.02f MiB, increment: %.02f MiB' % (max_mem, inc)\n\n    def _repr_pretty_(self, p, cycle):\n        msg = str(self)\n        p.text(u'<MemitResult : ' + msg + u'>')\n\n\ndef _get_child_memory(process, meminfo_attr=None, memory_metric=0):\n    \"\"\"\n    Returns a generator that yields memory for all child processes.\n    \"\"\"\n    # Convert a pid to a process\n    if isinstance(process, int):\n        if process == -1: process = os.getpid()\n        process = psutil.Process(process)\n\n    if not meminfo_attr:\n        # Use the psutil 2.0 attr if the older version isn't passed in.\n        meminfo_attr = 'memory_info' if hasattr(process, 'memory_info') else 'get_memory_info'\n\n    # Select the psutil function get the children similar to how we selected\n    # the memory_info attr (a change from excepting the AttributeError).\n    children_attr = 'children' if hasattr(process, 'children') else 'get_children'\n\n    # Loop over the child processes and yield their memory\n    try:\n        for child in getattr(process, children_attr)(recursive=True):\n            if isinstance(memory_metric, str):\n                meminfo = getattr(child, meminfo_attr)()\n                yield child.pid, getattr(meminfo, memory_metric) / _TWO_20\n            else:\n                yield child.pid, getattr(child, meminfo_attr)()[memory_metric] / _TWO_20\n    except (psutil.NoSuchProcess, psutil.AccessDenied):\n        # https://github.com/fabianp/memory_profiler/issues/71\n        yield (0, 0.0)\n\n\ndef _get_memory(pid, backend, timestamps=False, include_children=False, filename=None):\n    # .. low function to get memory consumption ..\n    if pid == -1:\n        pid = os.getpid()\n\n    def tracemalloc_tool():\n        # .. cross-platform but but requires Python 3.4 or higher ..\n        stat = next(filter(lambda item: str(item).startswith(filename),\n                           tracemalloc.take_snapshot().statistics('filename')))\n        mem = stat.size / _TWO_20\n        if timestamps:\n            return mem, time.time()\n        else:\n            return mem\n\n    def ps_util_tool():\n        # .. cross-platform but but requires psutil ..\n        process = psutil.Process(pid)\n        try:\n            # avoid using get_memory_info since it does not exists\n            # in psutil > 2.0 and accessing it will cause exception.\n            meminfo_attr = 'memory_info' if hasattr(process, 'memory_info') \\\n                else 'get_memory_info'\n            mem = getattr(process, meminfo_attr)()[0] / _TWO_20\n            if include_children:\n                mem +=  sum([mem for (pid, mem) in _get_child_memory(process, meminfo_attr)])\n            if timestamps:\n                return mem, time.time()\n            else:\n                return mem\n        except psutil.AccessDenied:\n            pass\n            # continue and try to get this from ps\n\n    def _ps_util_full_tool(memory_metric):\n\n        # .. cross-platform but requires psutil > 4.0.0 ..\n        process = psutil.Process(pid)\n        try:\n            if not hasattr(process, 'memory_full_info'):\n                raise NotImplementedError(\"Backend `{}` requires psutil > 4.0.0\".format(memory_metric))\n\n            meminfo_attr = 'memory_full_info'\n            meminfo = getattr(process, meminfo_attr)()\n\n            if not hasattr(meminfo, memory_metric):\n                raise NotImplementedError(\n                    \"Metric `{}` not available. For details, see:\".format(memory_metric) +\n                    \"https://psutil.readthedocs.io/en/latest/index.html?highlight=memory_info#psutil.Process.memory_full_info\")\n            mem = getattr(meminfo, memory_metric) / _TWO_20\n\n            if include_children:\n                mem +=  sum([mem for (pid, mem) in _get_child_memory(process, meminfo_attr, memory_metric)])\n\n            if timestamps:\n                return mem, time.time()\n            else:\n                return mem\n        \n        except psutil.AccessDenied:\n            pass\n            # continue and try to get this from ps\n\n    def posix_tool():\n        # .. scary stuff ..\n        if include_children:\n            raise NotImplementedError((\n                \"The psutil module is required to monitor the \"\n                \"memory usage of child processes.\"\n            ))\n\n        warnings.warn(\"psutil module not found. memory_profiler will be slow\")\n        # ..\n        # .. memory usage in MiB ..\n        # .. this should work on both Mac and Linux ..\n        # .. subprocess.check_output appeared in 2.7, using Popen ..\n        # .. for backwards compatibility ..\n        out = subprocess.Popen(['ps', 'v', '-p', str(pid)],\n                               stdout=subprocess.PIPE\n                               ).communicate()[0].split(b'\\n')\n        try:\n            vsz_index = out[0].split().index(b'RSS')\n            mem = float(out[1].split()[vsz_index]) / 1024\n            if timestamps:\n                return mem, time.time()\n            else:\n                return mem\n        except:\n            if timestamps:\n                return -1, time.time()\n            else:\n                return -1\n\n    if backend == 'tracemalloc' and \\\n            (filename is None or filename == '<unknown>'):\n        raise RuntimeError(\n            'There is no access to source file of the profiled function'\n        )\n\n    tools = {'tracemalloc': tracemalloc_tool,\n             'psutil': ps_util_tool,\n             'psutil_pss': lambda: _ps_util_full_tool(memory_metric=\"pss\"),\n             'psutil_uss': lambda: _ps_util_full_tool(memory_metric=\"uss\"),\n             'posix': posix_tool}\n    return tools[backend]()\n\n\nclass MemTimer(Process):\n    \"\"\"\n    Fetch memory consumption from over a time interval\n    \"\"\"\n\n    def __init__(self, monitor_pid, interval, pipe, backend, max_usage=False,\n                 *args, **kw):\n        self.monitor_pid = monitor_pid\n        self.interval = interval\n        self.pipe = pipe\n        self.cont = True\n        self.backend = backend\n        self.max_usage = max_usage\n        self.n_measurements = 1\n\n        self.timestamps = kw.pop(\"timestamps\", False)\n        self.include_children = kw.pop(\"include_children\", False)\n\n        # get baseline memory usage\n        self.mem_usage = [\n            _get_memory(self.monitor_pid, self.backend, timestamps=self.timestamps,\n                        include_children=self.include_children)]\n        super(MemTimer, self).__init__(*args, **kw)\n\n    def run(self):\n        self.pipe.send(0)  # we're ready\n        stop = False\n        while True:\n            cur_mem = _get_memory(\n                self.monitor_pid, self.backend, timestamps=self.timestamps,\n                include_children=self.include_children,)\n            if not self.max_usage:\n                self.mem_usage.append(cur_mem)\n            else:\n                self.mem_usage[0] = max(cur_mem, self.mem_usage[0])\n            self.n_measurements += 1\n            if stop:\n                break\n            stop = self.pipe.poll(self.interval)\n            # do one more iteration\n\n        self.pipe.send(self.mem_usage)\n        self.pipe.send(self.n_measurements)\n\n\ndef memory_usage(proc=-1, interval=.1, timeout=None, timestamps=False,\n                 include_children=False, multiprocess=False, max_usage=False,\n                 retval=False, stream=None, backend=None, max_iterations=None):\n    \"\"\"\n    Return the memory usage of a process or piece of code\n\n    Parameters\n    ----------\n    proc : {int, string, tuple, subprocess.Popen}, optional\n        The process to monitor. Can be given by an integer/string\n        representing a PID, by a Popen object or by a tuple\n        representing a Python function. The tuple contains three\n        values (f, args, kw) and specifies to run the function\n        f(*args, **kw).\n        Set to -1 (default) for current process.\n\n    interval : float, optional\n        Interval at which measurements are collected.\n\n    timeout : float, optional\n        Maximum amount of time (in seconds) to wait before returning.\n\n    max_usage : bool, optional\n        Only return the maximum memory usage (default False)\n\n    retval : bool, optional\n        For profiling python functions. Save the return value of the profiled\n        function. Return value of memory_usage becomes a tuple:\n        (mem_usage, retval)\n\n    timestamps : bool, optional\n        if True, timestamps of memory usage measurement are collected as well.\n\n    include_children : bool, optional\n        if True, sum the memory of all forked processes as well\n\n    multiprocess : bool, optional\n        if True, track the memory usage of all forked processes.\n\n    stream : File\n        if stream is a File opened with write access, then results are written\n        to this file instead of stored in memory and returned at the end of\n        the subprocess. Useful for long-running processes.\n        Implies timestamps=True.\n\n    backend : str, optional\n        Current supported backends: 'psutil', 'psutil_pss', 'psutil_uss', 'posix', 'tracemalloc'\n        If `backend=None` the default is \"psutil\" which measures RSS aka \"Resident Set Size\". \n        For more information on \"psutil_pss\" (measuring PSS) and \"psutil_uss\" please refer to:\n        https://psutil.readthedocs.io/en/latest/index.html?highlight=memory_info#psutil.Process.memory_full_info \n\n    max_iterations : int\n        Limits the number of iterations (calls to the process being monitored). Relevant\n        when the process is a python function.\n\n    Returns\n    -------\n    mem_usage : list of floating-point values\n        memory usage, in MiB. It's length is always < timeout / interval\n        if max_usage is given, returns the two elements maximum memory and\n        number of measurements effectuated\n    ret : return value of the profiled function\n        Only returned if retval is set to True\n    \"\"\"\n    backend = choose_backend(backend)\n    if stream is not None:\n        timestamps = True\n\n    if not max_usage:\n        ret = []\n    else:\n        ret = -1\n\n    if timeout is not None:\n        max_iter = int(round(timeout / interval))\n    elif isinstance(proc, int):\n        # external process and no timeout\n        max_iter = 1\n    else:\n        # for a Python function wait until it finishes\n        max_iter = float('inf')\n        if max_iterations is not None:\n            max_iter = max_iterations\n\n    if callable(proc):\n        proc = (proc, (), {})\n    if isinstance(proc, (list, tuple)):\n        if len(proc) == 1:\n            f, args, kw = (proc[0], (), {})\n        elif len(proc) == 2:\n            f, args, kw = (proc[0], proc[1], {})\n        elif len(proc) == 3:\n            f, args, kw = (proc[0], proc[1], proc[2])\n        else:\n            raise ValueError\n\n        current_iter = 0\n        while True:\n            current_iter += 1\n            child_conn, parent_conn = Pipe()  # this will store MemTimer's results\n            p = MemTimer(os.getpid(), interval, child_conn, backend,\n                         timestamps=timestamps,\n                         max_usage=max_usage,\n                         include_children=include_children)\n            p.start()\n            parent_conn.recv()  # wait until we start getting memory\n\n            # When there is an exception in the \"proc\" - the (spawned) monitoring processes don't get killed.\n            # Therefore, the whole process hangs indefinitely. Here, we are ensuring that the process gets killed!\n            try:\n                returned = f(*args, **kw)\n                parent_conn.send(0)  # finish timing\n                ret = parent_conn.recv()\n                n_measurements = parent_conn.recv()\n                if max_usage:\n                    # Convert the one element list produced by MemTimer to a singular value\n                    ret = ret[0]\n                if retval:\n                    ret = ret, returned\n            except Exception:\n                parent = psutil.Process(os.getpid())\n                for child in parent.children(recursive=True):\n                    os.kill(child.pid, SIGKILL)\n                p.join(0)\n                raise\n\n            p.join(5 * interval)\n\n            if (n_measurements > 4) or (current_iter == max_iter) or (interval < 1e-6):\n                break\n            interval /= 10.\n    elif isinstance(proc, subprocess.Popen):\n        # external process, launched from Python\n        line_count = 0\n        while True:\n            if not max_usage:\n                mem_usage = _get_memory(\n                    proc.pid, backend, timestamps=timestamps,\n                    include_children=include_children)\n\n                if mem_usage and stream is not None:\n                    stream.write(\"MEM {0:.6f} {1:.4f}\\n\".format(*mem_usage))\n\n                    # Write children to the stream file\n                    if multiprocess:\n                        for idx, chldmem in _get_child_memory(proc.pid):\n                            stream.write(\"CHLD {0} {1:.6f} {2:.4f}\\n\".format(idx, chldmem, time.time()))\n                else:\n                    # Create a nested list with the child memory\n                    if multiprocess:\n                        mem_usage = [mem_usage]\n                        for _, chldmem in _get_child_memory(proc.pid):\n                            mem_usage.append(chldmem)\n\n                    # Append the memory usage to the return value\n                    ret.append(mem_usage)\n            else:\n                ret = max(ret,\n                          _get_memory(\n                              proc.pid, backend, include_children=include_children))\n            time.sleep(interval)\n            line_count += 1\n            # flush every 50 lines. Make 'tail -f' usable on profile file\n            if line_count > 50:\n                line_count = 0\n                if stream is not None:\n                    stream.flush()\n            if timeout is not None:\n                max_iter -= 1\n                if max_iter == 0:\n                    break\n            if proc.poll() is not None:\n                break\n    else:\n        # external process\n        if max_iter == -1:\n            max_iter = 1\n        counter = 0\n        while counter < max_iter:\n            counter += 1\n            if not max_usage:\n                mem_usage = _get_memory(\n                    proc, backend, timestamps=timestamps,\n                    include_children=include_children)\n                if stream is not None:\n                    stream.write(\"MEM {0:.6f} {1:.4f}\\n\".format(*mem_usage))\n\n                    # Write children to the stream file\n                    if multiprocess:\n                        for idx, chldmem in _get_child_memory(proc):\n                            stream.write(\"CHLD {0} {1:.6f} {2:.4f}\\n\".format(idx, chldmem, time.time()))\n                else:\n                    # Create a nested list with the child memory\n                    if multiprocess:\n                        mem_usage = [mem_usage]\n                        for _, chldmem in _get_child_memory(proc):\n                            mem_usage.append(chldmem)\n\n                    # Append the memory usage to the return value\n                    ret.append(mem_usage)\n            else:\n                ret = max([ret,\n                           _get_memory(proc, backend, include_children=include_children)\n                           ])\n\n            time.sleep(interval)\n            # Flush every 50 lines.\n            if counter % 50 == 0 and stream is not None:\n                stream.flush()\n    if stream:\n        return None\n    return ret\n\n\n# ..\n# .. utility functions for line-by-line ..\n\n\ndef _find_script(script_name):\n    \"\"\" Find the script.\n\n    If the input is not a file, then $PATH will be searched.\n    \"\"\"\n    if os.path.isfile(script_name):\n        return script_name\n    path = os.getenv('PATH', os.defpath).split(os.pathsep)\n    for folder in path:\n        if not folder:\n            continue\n        fn = os.path.join(folder, script_name)\n        if os.path.isfile(fn):\n            return fn\n\n    sys.stderr.write('Could not find script {0}\\n'.format(script_name))\n    raise SystemExit(1)\n\n\nclass _TimeStamperCM(object):\n    \"\"\"Time-stamping context manager.\"\"\"\n\n    def __init__(self, timestamps, filename, backend, timestamper=None, func=None,\n                 include_children=False):\n        self.timestamps = timestamps\n        self.filename = filename\n        self.backend = backend\n        self.ts = timestamper\n        self.func = func\n        self.include_children = include_children\n\n    def __enter__(self):\n        if self.ts is not None:\n            self.ts.current_stack_level += 1\n            self.ts.stack[self.func].append(self.ts.current_stack_level)\n\n        self.timestamps.append(\n            _get_memory(os.getpid(), self.backend, timestamps=True,\n                        include_children=self.include_children, filename=self.filename))\n\n    def __exit__(self, *args):\n        if self.ts is not None:\n            self.ts.current_stack_level -= 1\n\n        self.timestamps.append(\n            _get_memory(os.getpid(), self.backend, timestamps=True,\n                        include_children=self.include_children, filename=self.filename))\n\n\nclass TimeStamper:\n    \"\"\" A profiler that just records start and end execution times for\n    any decorated function.\n    \"\"\"\n\n    def __init__(self, backend, include_children=False):\n        self.functions = {}\n        self.backend = backend\n        self.include_children = include_children\n        self.current_stack_level = -1\n        self.stack = {}\n\n    def __call__(self, func=None, precision=None):\n        if func is not None:\n            if not callable(func):\n                raise ValueError(\"Value must be callable\")\n\n            self.add_function(func)\n            f = self.wrap_function(func)\n            f.__module__ = func.__module__\n            f.__name__ = func.__name__\n            f.__doc__ = func.__doc__\n            f.__dict__.update(getattr(func, '__dict__', {}))\n            return f\n        else:\n            def inner_partial(f):\n                return self.__call__(f, precision=precision)\n\n            return inner_partial\n\n    def timestamp(self, name=\"<block>\"):\n        \"\"\"Returns a context manager for timestamping a block of code.\"\"\"\n        # Make a fake function\n        func = lambda x: x\n        func.__module__ = \"\"\n        func.__name__ = name\n        self.add_function(func)\n        timestamps = []\n        self.functions[func].append(timestamps)\n        # A new object is required each time, since there can be several\n        # nested context managers.\n        try:\n            filename = inspect.getsourcefile(func)\n        except TypeError:\n            filename = '<unknown>'\n        return _TimeStamperCM(\n            timestamps,\n            filename,\n            self.backend,\n            timestamper=self,\n            func=func\n        )\n\n    def add_function(self, func):\n        if func not in self.functions:\n            self.functions[func] = []\n            self.stack[func] = []\n\n    def wrap_function(self, func):\n        \"\"\" Wrap a function to timestamp it.\n        \"\"\"\n\n        def f(*args, **kwds):\n            # Start time\n            try:\n                filename = inspect.getsourcefile(func)\n            except TypeError:\n                filename = '<unknown>'\n            timestamps = [\n                _get_memory(os.getpid(), self.backend, timestamps=True,\n                            include_children=self.include_children, filename=filename)]\n            self.functions[func].append(timestamps)\n            try:\n                with self.call_on_stack(func, *args, **kwds) as result:\n                    return result\n            finally:\n                # end time\n                timestamps.append(_get_memory(os.getpid(), self.backend, timestamps=True,\n                                              include_children=self.include_children,\n                                              filename=filename))\n\n        return f\n\n    @contextmanager\n    def call_on_stack(self, func, *args, **kwds):\n        self.current_stack_level += 1\n        self.stack[func].append(self.current_stack_level)\n\n        yield func(*args, **kwds)\n\n        self.current_stack_level -= 1\n\n    def show_results(self, stream=None):\n        if stream is None:\n            stream = sys.stdout\n\n        for func, timestamps in self.functions.items():\n            function_name = \"%s.%s\" % (func.__module__, func.__name__)\n            for ts, level in zip(timestamps, self.stack[func]):\n                stream.write(\"FUNC %s %.4f %.4f %.4f %.4f %d\\n\" % (\n                    (function_name,) + ts[0] + ts[1] + (level,)))\n\n\nclass CodeMap(dict):\n    def __init__(self, include_children, backend):\n        self.include_children = include_children\n        self._toplevel = []\n        self.backend = backend\n\n    def add(self, code, toplevel_code=None):\n        if code in self:\n            return\n\n        if toplevel_code is None:\n            filename = code.co_filename\n            if filename.endswith((\".pyc\", \".pyo\")):\n                filename = filename[:-1]\n            if not os.path.exists(filename):\n                print('ERROR: Could not find file ' + filename)\n                if filename.startswith((\"ipython-input\", \"<ipython-input\")):\n                    print(\n                        \"NOTE: %mprun can only be used on functions defined in\"\n                        \" physical files, and not in the IPython environment.\")\n                return\n\n            toplevel_code = code\n            (sub_lines, start_line) = inspect.getsourcelines(code)\n            linenos = range(start_line,\n                            start_line + len(sub_lines))\n            self._toplevel.append((filename, code, linenos))\n            self[code] = {}\n        else:\n            self[code] = self[toplevel_code]\n\n        for subcode in filter(inspect.iscode, code.co_consts):\n            self.add(subcode, toplevel_code=toplevel_code)\n\n    def trace(self, code, lineno, prev_lineno):\n        memory = _get_memory(-1, self.backend, include_children=self.include_children,\n                             filename=code.co_filename)\n        prev_value = self[code].get(lineno, None)\n        previous_memory = prev_value[1] if prev_value else 0\n        previous_inc = prev_value[0] if prev_value else 0\n\n        prev_line_value = self[code].get(prev_lineno, None) if prev_lineno else None\n        prev_line_memory = prev_line_value[1] if prev_line_value else 0\n        occ_count = self[code][lineno][2] + 1 if lineno in self[code] else 1\n        self[code][lineno] = (\n            previous_inc + (memory - prev_line_memory),\n            max(memory, previous_memory),\n            occ_count,\n        )\n\n    def items(self):\n        \"\"\"Iterate on the toplevel code blocks.\"\"\"\n        for (filename, code, linenos) in self._toplevel:\n            measures = self[code]\n            if not measures:\n                continue  # skip if no measurement\n            line_iterator = ((line, measures.get(line)) for line in linenos)\n            yield (filename, line_iterator)\n\n\nclass LineProfiler(object):\n    \"\"\" A profiler that records the amount of memory for each line \"\"\"\n\n    def __init__(self, **kw):\n        include_children = kw.get('include_children', False)\n        backend = kw.get('backend', 'psutil')\n        self.code_map = CodeMap(\n            include_children=include_children, backend=backend)\n        self.enable_count = 0\n        self.max_mem = kw.get('max_mem', None)\n        self.prevlines = []\n        self.backend = choose_backend(kw.get('backend', None))\n        self.prev_lineno = None\n\n    def __call__(self, func=None, precision=1):\n        if func is not None:\n            self.add_function(func)\n            f = self.wrap_function(func)\n            f.__module__ = func.__module__\n            f.__name__ = func.__name__\n            f.__doc__ = func.__doc__\n            f.__dict__.update(getattr(func, '__dict__', {}))\n            return f\n        else:\n            def inner_partial(f):\n                return self.__call__(f, precision=precision)\n\n            return inner_partial\n\n    def add_function(self, func):\n        \"\"\" Record line profiling information for the given Python function.\n        \"\"\"\n        try:\n            # func_code does not exist in Python3\n            code = func.__code__\n        except AttributeError:\n            warnings.warn(\"Could not extract a code object for the object %r\"\n                          % func)\n        else:\n            self.code_map.add(code)\n\n    @contextmanager\n    def _count_ctxmgr(self):\n        self.enable_by_count()\n        try:\n            yield\n        finally:\n            self.disable_by_count()\n\n    def wrap_function(self, func):\n        \"\"\" Wrap a function to profile it.\n        \"\"\"\n\n        if iscoroutinefunction(func):\n            @coroutine\n            def f(*args, **kwargs):\n                with self._count_ctxmgr():\n                    res = yield from func(*args, **kwargs)\n                    return res\n        else:\n            def f(*args, **kwds):\n                with self._count_ctxmgr():\n                    return func(*args, **kwds)\n\n        return f\n\n    def runctx(self, cmd, globals, locals):\n        \"\"\" Profile a single executable statement in the given namespaces.\n        \"\"\"\n        self.enable_by_count()\n        try:\n            exec(cmd, globals, locals)\n        finally:\n            self.disable_by_count()\n        return self\n\n    def enable_by_count(self):\n        \"\"\" Enable the profiler if it hasn't been enabled before.\n        \"\"\"\n        if self.enable_count == 0:\n            self.enable()\n        self.enable_count += 1\n\n    def disable_by_count(self):\n        \"\"\" Disable the profiler if the number of disable requests matches the\n        number of enable requests.\n        \"\"\"\n        if self.enable_count > 0:\n            self.enable_count -= 1\n            if self.enable_count == 0:\n                self.disable()\n\n    def trace_memory_usage(self, frame, event, arg):\n        \"\"\"Callback for sys.settrace\"\"\"\n        if frame.f_code in self.code_map:\n            if event == 'call':\n                # \"call\" event just saves the lineno but not the memory\n                self.prevlines.append(frame.f_lineno)\n            elif event == 'line':\n                # trace needs current line and previous line\n                self.code_map.trace(frame.f_code, self.prevlines[-1], self.prev_lineno)\n                # saving previous line\n                self.prev_lineno = self.prevlines[-1]\n                self.prevlines[-1] = frame.f_lineno\n            elif event == 'return':\n                lineno = self.prevlines.pop()\n                self.code_map.trace(frame.f_code, lineno, self.prev_lineno)\n                self.prev_lineno = lineno\n\n        if self._original_trace_function is not None:\n            self._original_trace_function(frame, event, arg)\n\n        return self.trace_memory_usage\n\n    def trace_max_mem(self, frame, event, arg):\n        # run into PDB as soon as memory is higher than MAX_MEM\n        if event in ('line', 'return') and frame.f_code in self.code_map:\n            c = _get_memory(-1, self.backend, filename=frame.f_code.co_filename)\n            if c >= self.max_mem:\n                t = ('Current memory {0:.2f} MiB exceeded the '\n                     'maximum of {1:.2f} MiB\\n'.format(c, self.max_mem))\n                sys.stdout.write(t)\n                sys.stdout.write('Stepping into the debugger \\n')\n                frame.f_lineno -= 2\n                p = pdb.Pdb()\n                p.quitting = False\n                p.stopframe = frame\n                p.returnframe = None\n                p.stoplineno = frame.f_lineno - 3\n                p.botframe = None\n                return p.trace_dispatch\n\n        if self._original_trace_function is not None:\n            (self._original_trace_function)(frame, event, arg)\n\n        return self.trace_max_mem\n\n    def __enter__(self):\n        self.enable_by_count()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.disable_by_count()\n\n    def enable(self):\n        self._original_trace_function = sys.gettrace()\n        if self.max_mem is not None:\n            sys.settrace(self.trace_max_mem)\n        else:\n            sys.settrace(self.trace_memory_usage)\n\n    def disable(self):\n        sys.settrace(self._original_trace_function)\n\n\ndef show_results(prof, stream=None, precision=1):\n    if stream is None:\n        stream = sys.stdout\n    template = '{0:>6} {1:>12} {2:>12}  {3:>10}   {4:<}'\n\n    for (filename, lines) in prof.code_map.items():\n        header = template.format('Line #', 'Mem usage', 'Increment', 'Occurrences',\n                                 'Line Contents')\n\n        stream.write(u'Filename: ' + filename + '\\n\\n')\n        stream.write(header + u'\\n')\n        stream.write(u'=' * len(header) + '\\n')\n\n        all_lines = linecache.getlines(filename)\n\n        float_format = u'{0}.{1}f'.format(precision + 4, precision)\n        template_mem = u'{0:' + float_format + '} MiB'\n        for (lineno, mem) in lines:\n            if mem:\n                inc = mem[0]\n                total_mem = mem[1]\n                total_mem = template_mem.format(total_mem)\n                occurrences = mem[2]\n                inc = template_mem.format(inc)\n            else:\n                total_mem = u''\n                inc = u''\n                occurrences = u''\n            tmp = template.format(lineno, total_mem, inc, occurrences, all_lines[lineno - 1])\n            stream.write(tmp)\n        stream.write(u'\\n\\n')\n\n\ndef _func_exec(stmt, ns):\n    # helper for magic_memit, just a function proxy for the exec\n    # statement\n    exec(stmt, ns)\n\n\n@magics_class\nclass MemoryProfilerMagics(Magics):\n    # A lprun-style %mprun magic for IPython.\n    @line_cell_magic\n    def mprun(self, parameter_s='', cell=None):\n        \"\"\" Execute a statement under the line-by-line memory profiler from the\n        memory_profiler module.\n\n        Usage, in line mode:\n          %mprun -f func1 -f func2 <statement>\n\n        Usage, in cell mode:\n          %%mprun -f func1 -f func2 [statement]\n          code...\n          code...\n\n        In cell mode, the additional code lines are appended to the (possibly\n        empty) statement in the first line. Cell mode allows you to easily\n        profile multiline blocks without having to put them in a separate\n        function.\n\n        The given statement (which doesn't require quote marks) is run via the\n        LineProfiler. Profiling is enabled for the functions specified by the -f\n        options. The statistics will be shown side-by-side with the code through\n        the pager once the statement has completed.\n\n        Options:\n\n        -f <function>: LineProfiler only profiles functions and methods it is told\n        to profile.  This option tells the profiler about these functions. Multiple\n        -f options may be used. The argument may be any expression that gives\n        a Python function or method object. However, one must be careful to avoid\n        spaces that may confuse the option parser. Additionally, functions defined\n        in the interpreter at the In[] prompt or via %run currently cannot be\n        displayed.  Write these functions out to a separate file and import them.\n\n        One or more -f options are required to get any useful results.\n\n        -T <filename>: dump the text-formatted statistics with the code\n        side-by-side out to a text file.\n\n        -r: return the LineProfiler object after it has completed profiling.\n\n        -c: If present, add the memory usage of any children process to the report.\n        \"\"\"\n        from io import StringIO\n        from memory_profiler import show_results, LineProfiler\n\n        # Local imports to avoid hard dependency.\n        from distutils.version import LooseVersion\n        import IPython\n        ipython_version = LooseVersion(IPython.__version__)\n        if ipython_version < '0.11':\n            from IPython.genutils import page\n            from IPython.ipstruct import Struct\n            from IPython.ipapi import UsageError\n        else:\n            from IPython.core.page import page\n            from IPython.utils.ipstruct import Struct\n            from IPython.core.error import UsageError\n\n        # Escape quote markers.\n        opts_def = Struct(T=[''], f=[])\n        parameter_s = parameter_s.replace('\"', r'\\\"').replace(\"'\", r\"\\'\")\n        opts, arg_str = self.parse_options(parameter_s, 'rf:T:c',\n                                           list_all=True)\n        opts.merge(opts_def)\n        global_ns = self.shell.user_global_ns\n        local_ns = self.shell.user_ns\n\n        if cell is not None:\n            arg_str += '\\n' + cell\n\n        # Get the requested functions.\n        funcs = []\n        for name in opts.f:\n            try:\n                funcs.append(eval(name, global_ns, local_ns))\n            except Exception as e:\n                raise UsageError('Could not find function %r.\\n%s: %s' % (name,\n                                                                          e.__class__.__name__,\n                                                                          e))\n\n        include_children = 'c' in opts\n        profile = LineProfiler(include_children=include_children)\n        for func in funcs:\n            profile(func)\n\n        # Add the profiler to the builtins for @profile.\n        if 'profile' in builtins.__dict__:\n            had_profile = True\n            old_profile = builtins.__dict__['profile']\n        else:\n            had_profile = False\n            old_profile = None\n        builtins.__dict__['profile'] = profile\n\n        try:\n            profile.runctx(arg_str, global_ns, local_ns)\n            message = ''\n        except SystemExit:\n            message = \"*** SystemExit exception caught in code being profiled.\"\n        except KeyboardInterrupt:\n            message = (\"*** KeyboardInterrupt exception caught in code being \"\n                       \"profiled.\")\n        finally:\n            if had_profile:\n                builtins.__dict__['profile'] = old_profile\n\n        # Trap text output.\n        stdout_trap = StringIO()\n        show_results(profile, stdout_trap)\n        output = stdout_trap.getvalue()\n        output = output.rstrip()\n\n        if ipython_version < '0.11':\n            page(output, screen_lines=self.shell.rc.screen_length)\n        else:\n            page(output)\n        print(message, )\n\n        text_file = opts.T[0]\n        if text_file:\n            with open(text_file, 'w') as pfile:\n                pfile.write(output)\n            print('\\n*** Profile printout saved to text file %s. %s' % (\n                text_file,\n                message))\n\n        return_value = None\n        if 'r' in opts:\n            return_value = profile\n\n        return return_value\n\n    # a timeit-style %memit magic for IPython\n    @line_cell_magic\n    def memit(self, line='', cell=None):\n        \"\"\"Measure memory usage of a Python statement\n\n        Usage, in line mode:\n          %memit [-r<R>t<T>i<I>] statement\n\n        Usage, in cell mode:\n          %%memit [-r<R>t<T>i<I>] setup_code\n          code...\n          code...\n\n        This function can be used both as a line and cell magic:\n\n        - In line mode you can measure a single-line statement (though multiple\n          ones can be chained with using semicolons).\n\n        - In cell mode, the statement in the first line is used as setup code\n          (executed but not measured) and the body of the cell is measured.\n          The cell body has access to any variables created in the setup code.\n\n        Options:\n        -r<R>: repeat the loop iteration <R> times and take the best result.\n        Default: 1\n\n        -t<T>: timeout after <T> seconds. Default: None\n\n        -i<I>: Get time information at an interval of I times per second.\n            Defaults to 0.1 so that there is ten measurements per second.\n\n        -c: If present, add the memory usage of any children process to the report.\n\n        -o: If present, return a object containing memit run details\n\n        -q: If present, be quiet and do not output a result.\n\n        Examples\n        --------\n        ::\n\n          In [1]: %memit range(10000)\n          peak memory: 21.42 MiB, increment: 0.41 MiB\n\n          In [2]: %memit range(1000000)\n          peak memory: 52.10 MiB, increment: 31.08 MiB\n\n          In [3]: %%memit l=range(1000000)\n             ...: len(l)\n             ...:\n          peak memory: 52.14 MiB, increment: 0.08 MiB\n\n        \"\"\"\n        from memory_profiler import memory_usage, _func_exec\n        opts, stmt = self.parse_options(line, 'r:t:i:coq', posix=False,\n                                        strict=False)\n\n        if cell is None:\n            setup = 'pass'\n        else:\n            setup = stmt\n            stmt = cell\n\n        repeat = int(getattr(opts, 'r', 1))\n        if repeat < 1:\n            repeat == 1\n        timeout = int(getattr(opts, 't', 0))\n        if timeout <= 0:\n            timeout = None\n        interval = float(getattr(opts, 'i', 0.1))\n        include_children = 'c' in opts\n        return_result = 'o' in opts\n        quiet = 'q' in opts\n\n        # I've noticed we get less noisier measurements if we run\n        # a garbage collection first\n        import gc\n        gc.collect()\n\n        _func_exec(setup, self.shell.user_ns)\n\n        mem_usage = []\n        counter = 0\n        baseline = memory_usage()[0]\n        while counter < repeat:\n            counter += 1\n            tmp = memory_usage((_func_exec, (stmt, self.shell.user_ns)),\n                               timeout=timeout, interval=interval,\n                               max_usage=True, max_iterations=1,\n                               include_children=include_children)\n            mem_usage.append(tmp)\n\n        result = MemitResult(mem_usage, baseline, repeat, timeout, interval,\n                             include_children)\n\n        if not quiet:\n            if mem_usage:\n                print(result)\n            else:\n                print('ERROR: could not read memory usage, try with a '\n                      'lower interval or more iterations')\n\n        if return_result:\n            return result\n\n    @classmethod\n    def register_magics(cls, ip):\n        from distutils.version import LooseVersion\n        import IPython\n        ipython_version = LooseVersion(IPython.__version__)\n\n        if ipython_version < '0.13':\n            try:\n                _register_magic = ip.define_magic\n            except AttributeError:  # ipython 0.10\n                _register_magic = ip.expose_magic\n\n            _register_magic('mprun', cls.mprun.__func__)\n            _register_magic('memit', cls.memit.__func__)\n        else:\n            ip.register_magics(cls)\n\n\n# commenting out due to failures with some versions of IPython\n# see https://github.com/fabianp/memory_profiler/issues/106\n# # Ensuring old interface of magics expose for IPython 0.10\n# magic_mprun = MemoryProfilerMagics().mprun.__func__\n# magic_memit = MemoryProfilerMagics().memit.__func__\n\n\ndef load_ipython_extension(ip):\n    \"\"\"This is called to load the module as an IPython extension.\"\"\"\n\n    MemoryProfilerMagics.register_magics(ip)\n\n\ndef profile(func=None, stream=None, precision=1, backend='psutil'):\n    \"\"\"\n    Decorator that will run the function and print a line-by-line profile\n    \"\"\"\n    backend = choose_backend(backend)\n    if backend == 'tracemalloc' and has_tracemalloc:\n        if not tracemalloc.is_tracing():\n            tracemalloc.start()\n    if func is not None:\n        get_prof = partial(LineProfiler, backend=backend)\n        show_results_bound = partial(\n            show_results, stream=stream, precision=precision\n        )\n        if iscoroutinefunction(func):\n            @wraps(wrapped=func)\n            @coroutine\n            def wrapper(*args, **kwargs):\n                prof = get_prof()\n                val = yield from prof(func)(*args, **kwargs)\n                show_results_bound(prof)\n                return val\n        else:\n            @wraps(wrapped=func)\n            def wrapper(*args, **kwargs):\n                prof = get_prof()\n                val = prof(func)(*args, **kwargs)\n                show_results_bound(prof)\n                return val\n\n        return wrapper\n    else:\n        def inner_wrapper(f):\n            return profile(f, stream=stream, precision=precision,\n                           backend=backend)\n\n        return inner_wrapper\n\n\ndef choose_backend(new_backend=None):\n    \"\"\"\n    Function that tries to setup backend, chosen by user, and if failed,\n    setup one of the allowable backends\n    \"\"\"\n\n    _backend = 'no_backend'\n    all_backends = [\n        ('psutil', True),\n        ('psutil_pss', True),\n        ('psutil_uss', True),\n        ('posix', os.name == 'posix'),\n        ('tracemalloc', has_tracemalloc),\n    ]\n    backends_indices = dict((b[0], i) for i, b in enumerate(all_backends))\n\n    if new_backend is not None:\n        all_backends.insert(0, all_backends.pop(backends_indices[new_backend]))\n\n    for n_backend, is_available in all_backends:\n        if is_available:\n            _backend = n_backend\n            break\n    if _backend != new_backend and new_backend is not None:\n        warnings.warn('{0} can not be used, {1} used instead'.format(\n            new_backend, _backend))\n    return _backend\n\n\n# Insert in the built-ins to have profile\n# globally defined (global variables is not enough\n# for all cases, e.g. a script that imports another\n# script where @profile is used)\ndef exec_with_profiler(filename, profiler, backend, passed_args=[]):\n    from runpy import run_module\n    builtins.__dict__['profile'] = profiler\n    ns = dict(_CLEAN_GLOBALS,\n              profile=profiler,\n             # Make sure the __file__ variable is usable\n             # by the script we're profiling\n              __file__=filename)\n    # Make sure the script's directory in on sys.path\n    # credit to line_profiler\n    sys.path.insert(0, os.path.dirname(script_filename))\n\n    _backend = choose_backend(backend)\n    sys.argv = [filename] + passed_args\n    try:\n        if _backend == 'tracemalloc' and has_tracemalloc:\n            tracemalloc.start()\n        with io.open(filename, encoding='utf-8') as f:\n            exec(compile(f.read(), filename, 'exec'), ns, ns)\n    finally:\n        if has_tracemalloc and tracemalloc.is_tracing():\n            tracemalloc.stop()\n\n\ndef run_module_with_profiler(module, profiler, backend, passed_args=[]):\n    from runpy import run_module\n    builtins.__dict__['profile'] = profiler\n    ns = dict(_CLEAN_GLOBALS, profile=profiler)\n    _backend = choose_backend(backend)\n    sys.argv = [module] + passed_args\n    if _backend == 'tracemalloc' and has_tracemalloc:\n        tracemalloc.start()\n    try:\n        run_module(module, run_name=\"__main__\", init_globals=ns)\n    finally:\n        if has_tracemalloc and tracemalloc.is_tracing():\n            tracemalloc.stop()\n\n\nclass LogFile(object):\n    \"\"\"File-like object to log text using the `logging` module and the log\n    report can be customised.\"\"\"\n\n    def __init__(self, name=None, reportIncrementFlag=False):\n        \"\"\"\n        :param name: name of the logger module\n               reportIncrementFlag: This must be set to True if only the steps\n               with memory increments are to be reported\n\n        :type self: object\n              name: string\n              reportIncrementFlag: bool\n        \"\"\"\n        self.logger = logging.getLogger(name)\n        self.reportIncrementFlag = reportIncrementFlag\n\n    def write(self, msg, level=logging.INFO):\n        if self.reportIncrementFlag:\n            if \"MiB\" in msg and float(msg.split(\"MiB\")[1].strip()) > 0:\n                self.logger.log(level, msg)\n            elif msg.__contains__(\"Filename:\") or msg.__contains__(\n                    \"Line Contents\"):\n                self.logger.log(level, msg)\n        else:\n            self.logger.log(level, msg)\n\n    def flush(self):\n        for handler in self.logger.handlers:\n            handler.flush()\n\n\nif __name__ == '__main__':\n    from argparse import ArgumentParser, REMAINDER\n\n    parser = ArgumentParser(usage=_CMD_USAGE)\n    parser.add_argument('--version', action='version', version=__version__)\n    parser.add_argument(\n        '--pdb-mmem', dest='max_mem', metavar='MAXMEM',\n        type=float, action='store',\n        help='step into the debugger when memory exceeds MAXMEM')\n    parser.add_argument(\n        '--precision', dest='precision', type=int,\n        action='store', default=3,\n        help='precision of memory output in number of significant digits')\n    parser.add_argument('-o', dest='out_filename', type=str,\n        action='store', default=None,\n        help='path to a file where results will be written')\n    parser.add_argument('--timestamp', dest='timestamp', default=False,\n        action='store_true',\n        help='''print timestamp instead of memory measurement for\n        decorated functions''')\n    parser.add_argument('--include-children', dest='include_children',\n        default=False, action='store_true',\n        help='also include memory used by child processes')\n    parser.add_argument('--backend', dest='backend', type=str, action='store',\n        choices=['tracemalloc', 'psutil', 'psutil_pss', 'psutil_uss', 'posix'], default='psutil',\n        help='backend using for getting memory info '\n             '(one of the {tracemalloc, psutil, posix, psutil_pss, psutil_uss, posix})')\n    parser.add_argument(\"program\", nargs=REMAINDER,\n        help='python script or module followed by command line arguments to run')\n    args = parser.parse_args()\n\n    if len(args.program) == 0:\n        print(\"A program to run must be provided. Use -h for help\")\n        sys.exit(1)\n\n    target = args.program[0]\n    script_args = args.program[1:]\n    _backend = choose_backend(args.backend)\n    if args.timestamp:\n        prof = TimeStamper(_backend, include_children=args.include_children)\n    else:\n        prof = LineProfiler(max_mem=args.max_mem, backend=_backend)\n\n    try:\n        if args.program[0].endswith('.py'):\n            script_filename = _find_script(args.program[0])\n            exec_with_profiler(script_filename, prof, args.backend, script_args)\n        else:\n            run_module_with_profiler(target, prof, args.backend, script_args)\n    finally:\n        if args.out_filename is not None:\n            out_file = open(args.out_filename, \"a\")\n        else:\n            out_file = sys.stdout\n\n        if args.timestamp:\n            prof.show_results(stream=out_file)\n        else:\n            show_results(prof, precision=args.precision, stream=out_file)\n"
        },
        {
          "name": "mprof.py",
          "type": "blob",
          "size": 34.3076171875,
          "content": "import glob\nimport os\nimport os.path as osp\nimport sys\nimport re\nimport copy\nimport time\nimport math\nimport logging\nimport itertools\nfrom ast import literal_eval\n\nfrom collections import defaultdict\nfrom argparse import ArgumentParser, ArgumentError, REMAINDER, RawTextHelpFormatter\n\nimport importlib\nimport memory_profiler as mp\n\nALL_ACTIONS = (\"run\", \"rm\", \"clean\", \"list\", \"plot\", \"attach\", \"peak\")\nhelp_msg = \"\"\"\nAvailable commands:\n\n    run      run a given command or python file\n    attach   alias for 'run --attach': attach to an existing process by pid or name\n    rm       remove a given file generated by mprof\n    clean    clean the current directory from files created by mprof\n    list     display existing profiles, with indices\n    plot     plot memory consumption generated by mprof run\n    peak     print the maximum memory used by an mprof run\n\nType mprof <command> --help for usage help on a specific command.\nFor example, mprof plot --help will list all plotting options.\n\"\"\"\n\nlogger = logging.getLogger(__name__)\nlogging.basicConfig()\n\n\ndef print_usage():\n    print(\"Usage: %s <command> <options> <arguments>\"\n          % osp.basename(sys.argv[0]))\n    print(help_msg)\n\n\ndef get_action():\n    \"\"\"Pop first argument, check it is a valid action.\"\"\"\n    if len(sys.argv) <= 1:\n        print_usage()\n        sys.exit(1)\n    if not sys.argv[1] in ALL_ACTIONS:\n        print_usage()\n        sys.exit(1)\n\n    return sys.argv.pop(1)\n\n\ndef get_profile_filenames(args):\n    \"\"\"Return list of profile filenames.\n\n    Parameters\n    ==========\n    args (list)\n        list of filename or integer. An integer is the index of the\n        profile in the list of existing profiles. 0 is the oldest,\n        -1 in the more recent.\n        Non-existing files cause a ValueError exception to be thrown.\n\n    Returns\n    =======\n    filenames (list)\n        list of existing memory profile filenames. It is guaranteed\n        that an given file name will not appear twice in this list.\n    \"\"\"\n    profiles = glob.glob(\"mprofile_??????????????.dat\")\n    profiles.sort()\n\n    if args == \"all\":\n        filenames = copy.copy(profiles)\n    else:\n        filenames = []\n        for arg in args:\n            if arg == \"--\":  # workaround\n                continue\n            try:\n                index = int(arg)\n            except ValueError:\n                index = None\n            if index is not None:\n                try:\n                    filename = profiles[index]\n                except IndexError:\n                    raise ValueError(\"Invalid index (non-existing file): %s\" % arg)\n\n                if filename not in filenames:\n                    filenames.append(filename)\n            else:\n                if osp.isfile(arg):\n                    if arg not in filenames:\n                        filenames.append(arg)\n                elif osp.isdir(arg):\n                    raise ValueError(\"Path %s is a directory\" % arg)\n                else:\n                    raise ValueError(\"File %s not found\" % arg)\n\n    # Add timestamp files, if any\n    for filename in reversed(filenames):\n        parts = osp.splitext(filename)\n        timestamp_file = parts[0] + \"_ts\" + parts[1]\n        if osp.isfile(timestamp_file) and timestamp_file not in filenames:\n            filenames.append(timestamp_file)\n\n    return filenames\n\n\ndef list_action():\n    \"\"\"Display existing profiles, with indices.\"\"\"\n    parser = ArgumentParser(\n            usage='mprof list\\nThis command takes no argument.')\n    parser.add_argument('--version', action='version', version=mp.__version__)\n    args = parser.parse_args()\n\n    filenames = get_profile_filenames(\"all\")\n    for n, filename in enumerate(filenames):\n        ts = osp.splitext(filename)[0].split('_')[-1]\n        print(\"{index} {filename} {hour}:{min}:{sec} {day}/{month}/{year}\"\n              .format(index=n, filename=filename,\n                      year=ts[:4], month=ts[4:6], day=ts[6:8],\n                      hour=ts[8:10], min=ts[10:12], sec=ts[12:14]))\n\n\ndef rm_action():\n    \"\"\"TODO: merge with clean_action (@pgervais)\"\"\"\n    parser = ArgumentParser(usage='mprof rm [options] numbers_or_filenames')\n    parser.add_argument('--version', action='version', version=mp.__version__)\n    parser.add_argument(\"--dry-run\", dest=\"dry_run\", default=False,\n                        action=\"store_true\",\n                        help=\"\"\"Show what will be done, without actually doing it.\"\"\")\n    parser.add_argument(\"numbers_or_filenames\", nargs='*',\n                        help=\"\"\"numbers or filenames removed\"\"\")\n    args = parser.parse_args()\n\n    if len(args.numbers_or_filenames) == 0:\n        print(\"A profile to remove must be provided (number or filename)\")\n        sys.exit(1)\n\n    filenames = get_profile_filenames(args.numbers_or_filenames)\n    if args.dry_run:\n        print(\"Files to be removed: \")\n        for filename in filenames:\n            print(filename)\n    else:\n        for filename in filenames:\n            os.remove(filename)\n\n\ndef clean_action():\n    \"\"\"Remove every profile file in current directory.\"\"\"\n    parser = ArgumentParser(\n            usage='mprof clean\\nThis command takes no argument.')\n    parser.add_argument('--version', action='version', version=mp.__version__)\n    parser.add_argument(\"--dry-run\", dest=\"dry_run\", default=False,\n                        action=\"store_true\",\n                        help=\"\"\"Show what will be done, without actually doing it.\"\"\")\n    args = parser.parse_args()\n\n    filenames = get_profile_filenames(\"all\")\n    if args.dry_run:\n        print(\"Files to be removed: \")\n        for filename in filenames:\n            print(filename)\n    else:\n        for filename in filenames:\n            os.remove(filename)\n\n\ndef get_cmd_line(args):\n    \"\"\"Given a set or arguments, compute command-line.\"\"\"\n    blanks = set(' \\t')\n    args = [s if blanks.isdisjoint(s) else \"'\" + s + \"'\" for s in args]\n    return ' '.join(args)\n\ndef find_first_process(name):\n    for i in mp.psutil.process_iter():\n        if name in i.name():\n            return i\n    return None\n\ndef attach_action():\n    argv = sys.argv\n    sys.argv = argv[:1] + ['--attach'] + argv[1:]\n    run_action()\n\ndef run_action():\n    import time, subprocess\n    parser = ArgumentParser(usage=\"mprof run [options] program\", formatter_class=RawTextHelpFormatter)\n    parser.add_argument('--version', action='version', version=mp.__version__)\n    parser.add_argument(\"--python\", dest=\"python\", action=\"store_true\",\n                        help=\"\"\"Activates extra features when the profiling executable is a Python program (currently: function timestamping.)\"\"\")\n    parser.add_argument(\"--nopython\", dest=\"nopython\", action=\"store_true\",\n                        help=\"\"\"Disables extra features when the profiled executable is a Python program (currently: function timestamping.)\"\"\")\n    parser.add_argument(\"--interval\", \"-T\", dest=\"interval\", default=\"0.1\", type=float, action=\"store\",\n                        help=\"Sampling period (in seconds), defaults to 0.1\")\n    parser.add_argument(\"--include-children\", \"-C\", dest=\"include_children\", action=\"store_true\",\n                        help=\"\"\"Monitors forked processes as well (sum up all process memory)\"\"\")\n    parser.add_argument(\"--multiprocess\", \"-M\", dest=\"multiprocess\", action=\"store_true\",\n                        help=\"\"\"Monitors forked processes creating individual plots for each child (disables --python features)\"\"\")\n    parser.add_argument(\"--exit-code\", \"-E\", dest=\"exit_code\", action=\"store_true\", help=\"\"\"Propagate the exit code\"\"\")\n    attach_arg = parser.add_argument(\"--attach\", \"-a\", dest=\"attach_existing\", action=\"store_true\",\n                        help=\"Attach to an existing process, by process name or by pid\")\n    parser.add_argument(\"--timeout\", \"-t\", dest=\"timeout\", action=\"store\", type=int,\n                        help=\"timeout in seconds for the profiling, default new process has no timeout, attach existing is 1 hour\")\n    parser.add_argument(\"--output\", \"-o\", dest=\"filename\",\n                        default=\"mprofile_%s.dat\" % time.strftime(\"%Y%m%d%H%M%S\", time.localtime()),\n                        help=\"\"\"File to store results in, defaults to 'mprofile_<YYYYMMDDhhmmss>.dat' in the current directory,\n(where <YYYYMMDDhhmmss> is the date-time of the program start).\nThis file contains the process memory consumption, in Mb (one value per line).\"\"\")\n    parser.add_argument(\"--backend\", dest=\"backend\", choices=[\"psutil\", \"psutil_pss\", \"psutil_uss\", \"posix\", \"tracemalloc\"],\n                        default=\"psutil\",\n                        help=\"Current supported backends: 'psutil', 'psutil_pss', 'psutil_uss', 'posix', 'tracemalloc'. Defaults to 'psutil'.\")\n    parser.add_argument(\"program\", nargs=REMAINDER,\n                        help='Option 1: \"<EXECUTABLE> <ARG1> <ARG2>...\" - profile executable\\n'\n                             'Option 2: \"<PYTHON_SCRIPT> <ARG1> <ARG2>...\" - profile python script\\n'\n                             'Option 3: (--python flag present) \"<PYTHON_EXECUTABLE> <PYTHON_SCRIPT> <ARG1> <ARG2>...\" - profile python script with specified interpreter\\n'\n                             'Option 4: (--python flag present) \"<PYTHON_MODULE> <ARG1> <ARG2>...\" - profile python module\\n'\n                        )\n    args = parser.parse_args()\n\n    if len(args.program) == 0:\n        print(\"A program to run must be provided. Use -h for help\")\n        sys.exit(1)\n\n    print(\"{1}: Sampling memory every {0}s\".format(\n        args.interval, osp.basename(sys.argv[0])))\n\n    mprofile_output = args.filename\n\n    program = args.program\n    if args.attach_existing:\n        print('attaching to existing process, using hint: {}'.format(program[0]))\n        if program[0].isdigit():\n            p = literal_eval(program[0])\n            cmd_line = get_cmd_line(program)\n        else:\n            proc = find_first_process(program[0])\n            if proc is None:\n                raise ArgumentError(attach_arg, '\\nWhen attaching, program should be process name or pid.\\nFailed to find a process using hint: {}'.format(program[0]))\n            \n            p = proc.pid\n            try:\n                cmd_line = proc.cmdline()\n            except:\n                cmd_line = get_cmd_line(program)\n        if args.timeout is None:\n            args.timeout = 3600\n    else:\n        print('running new process')\n        # .. TODO: more than one script as argument ? ..\n        if program[0].endswith('.py') and not args.nopython:\n            if args.multiprocess:\n                # in multiprocessing mode you want to spawn a separate\n                # python process\n                if not program[0].startswith(\"python\"):\n                    program.insert(0, sys.executable)\n                args.python = False\n            else:\n                args.python = True\n        if args.python:\n            print(\"running as a Python program...\")\n            if not program[0].startswith(\"python\"):\n                program.insert(0, sys.executable)\n            cmd_line = get_cmd_line(program)\n            extra_args = [\"-m\", \"memory_profiler\", \"--timestamp\", \"-o\", mprofile_output]\n            if args.include_children:\n                extra_args.append(\"--include-children\")\n            program[1:1] = extra_args\n            p = subprocess.Popen(program)\n        else:\n            cmd_line = get_cmd_line(program)\n            p = subprocess.Popen(program)\n\n    with open(mprofile_output, \"a\") as f:\n        f.write(\"CMDLINE {0}\\n\".format(cmd_line))\n        mp.memory_usage(proc=p, interval=args.interval, timeout=args.timeout, timestamps=True,\n                        include_children=args.include_children,\n                        multiprocess=args.multiprocess, stream=f, backend=args.backend)\n\n    if args.exit_code:\n        if p.returncode != 0:\n            logger.error('Program resulted with a non-zero exit code: %s', p.returncode)\n        sys.exit(p.returncode)\n\n\ndef add_brackets(xloc, yloc, xshift=0, color=\"r\", label=None, options=None):\n    \"\"\"Add two brackets on the memory line plot.\n\n    This function uses the current figure.\n\n    Parameters\n    ==========\n    xloc: tuple with 2 values\n        brackets location (on horizontal axis).\n    yloc: tuple with 2 values\n        brackets location (on vertical axis)\n    xshift: float\n        value to subtract to xloc.\n    \"\"\"\n    try:\n        import pylab as pl\n    except ImportError as e:\n        print(\"matplotlib is needed for plotting.\")\n        print(e)\n        sys.exit(1)\n    height_ratio = 20.\n    vsize = (pl.ylim()[1] - pl.ylim()[0]) / height_ratio\n    hsize = (pl.xlim()[1] - pl.xlim()[0]) / (3. * height_ratio)\n\n    bracket_x = pl.asarray([hsize, 0, 0, hsize])\n    bracket_y = pl.asarray([vsize, vsize, -vsize, -vsize])\n\n    # Matplotlib workaround: labels starting with _ aren't displayed\n    if label[0] == '_':\n        label = ' ' + label\n    if options.xlim is None or options.xlim[0] <= (xloc[0] - xshift) <= options.xlim[1]:\n        pl.plot(bracket_x + xloc[0] - xshift, bracket_y + yloc[0],\n                \"-\" + color, linewidth=2, label=label)\n    if options.xlim is None or options.xlim[0] <= (xloc[1] - xshift) <= options.xlim[1]:\n        pl.plot(-bracket_x + xloc[1] - xshift, bracket_y + yloc[1],\n                \"-\" + color, linewidth=2)\n\n        # TODO: use matplotlib.patches.Polygon to draw a colored background for\n        # each function.\n\n        # with maplotlib 1.2, use matplotlib.path.Path to create proper markers\n        # see http://matplotlib.org/examples/pylab_examples/marker_path.html\n        # This works with matplotlib 0.99.1\n        ## pl.plot(xloc[0], yloc[0], \"<\"+color, markersize=7, label=label)\n        ## pl.plot(xloc[1], yloc[1], \">\"+color, markersize=7)\n\n\ndef read_mprofile_file(filename):\n    \"\"\"Read an mprofile file and return its content.\n\n    Returns\n    =======\n    content: dict\n        Keys:\n\n        - \"mem_usage\": (list) memory usage values, in MiB\n        - \"timestamp\": (list) time instant for each memory usage value, in\n            second\n        - \"func_timestamp\": (dict) for each function, timestamps and memory\n            usage upon entering and exiting.\n        - 'cmd_line': (str) command-line ran for this profile.\n    \"\"\"\n    func_ts = {}\n    mem_usage = []\n    timestamp = []\n    children  = defaultdict(list)\n    cmd_line = None\n    f = open(filename, \"r\")\n    for l in f:\n        if l == '\\n':\n            raise ValueError('Sampling time was too short')\n        field, value = l.split(' ', 1)\n        if field == \"MEM\":\n            # mem, timestamp\n            values = value.split(' ')\n            mem_usage.append(float(values[0]))\n            timestamp.append(float(values[1]))\n\n        elif field == \"FUNC\":\n            values = value.split(' ')\n            f_name, mem_start, start, mem_end, end = values[:5]\n            ts = func_ts.get(f_name, [])\n            to_append = [float(start), float(end), float(mem_start), float(mem_end)]\n            if len(values) >= 6:\n                # There is a stack level field\n                stack_level = values[5]\n                to_append.append(int(stack_level))\n            ts.append(to_append)\n            func_ts[f_name] = ts\n\n        elif field == \"CHLD\":\n            values = value.split(' ')\n            chldnum = values[0]\n            children[chldnum].append(\n                (float(values[1]), float(values[2]))\n            )\n\n        elif field == \"CMDLINE\":\n            cmd_line = value\n        else:\n            pass\n    f.close()\n\n    return {\"mem_usage\": mem_usage, \"timestamp\": timestamp,\n            \"func_timestamp\": func_ts, 'filename': filename,\n            'cmd_line': cmd_line, 'children': children}\n\n\ndef plot_file(filename, index=0, timestamps=True, children=True, options=None):\n    try:\n        import pylab as pl\n    except ImportError as e:\n        print(\"matplotlib is needed for plotting.\")\n        print(e)\n        sys.exit(1)\n    import numpy as np  # pylab requires numpy anyway\n    mprofile = read_mprofile_file(filename)\n\n    if len(mprofile['timestamp']) == 0:\n        print('** No memory usage values have been found in the profile '\n              'file.**\\nFile path: {0}\\n'\n              'File may be empty or invalid.\\n'\n              'It can be deleted with \"mprof rm {0}\"'.format(\n            mprofile['filename']))\n        sys.exit(0)\n\n    # Merge function timestamps and memory usage together\n    ts = mprofile['func_timestamp']\n    t = mprofile['timestamp']\n    mem = mprofile['mem_usage']\n    chld = mprofile['children']\n\n    if len(ts) > 0:\n        for values in ts.values():\n            for v in values:\n                t.extend(v[:2])\n                mem.extend(v[2:4])\n\n    mem = np.asarray(mem)\n    t = np.asarray(t)\n    ind = t.argsort()\n    mem = mem[ind]\n    t = t[ind]\n\n    # Plot curves\n    global_start = float(t[0])\n    t = t - global_start\n\n    max_mem = mem.max()\n    max_mem_ind = mem.argmax()\n\n    all_colors = (\"c\", \"y\", \"g\", \"r\", \"b\")\n    mem_line_colors = (\"k\", \"b\", \"r\", \"g\", \"c\", \"y\", \"m\")\n\n    show_trend_slope = options is not None and hasattr(options, 'slope') and options.slope is True\n\n    mem_line_label = time.strftime(\"%d / %m / %Y - start at %H:%M:%S\",\n                                   time.localtime(global_start)) \\\n                     + \".{0:03d}\".format(int(round(math.modf(global_start)[0] * 1000)))\n\n    mem_trend = None\n    if show_trend_slope:\n        # Compute trend line\n        mem_trend = np.polyfit(t, mem, 1)\n\n        # Append slope to label\n        mem_line_label = mem_line_label + \" slope {0:.5f}\".format(mem_trend[0])\n\n    pl.plot(t, mem, \"+-\" + mem_line_colors[index % len(mem_line_colors)],\n            label=mem_line_label)\n\n    if show_trend_slope:\n        # Plot the trend line\n        pl.plot(t, t*mem_trend[0] + mem_trend[1], \"--\", linewidth=0.5, color=\"#00e3d8\")\n\n    bottom, top = pl.ylim()\n    bottom += 0.001\n    top -= 0.001\n\n    # plot children, if any\n    if len(chld) > 0 and children:\n        cmpoint = (0,0) # maximal child memory\n\n        for idx, (proc, data) in enumerate(chld.items()):\n            # Create the numpy arrays from the series data\n            cts  = np.asarray([item[1] for item in data]) - global_start\n            cmem = np.asarray([item[0] for item in data])\n\n            cmem_trend = None\n            child_mem_trend_label = \"\"\n            if show_trend_slope:\n                # Compute trend line\n                cmem_trend = np.polyfit(cts, cmem, 1)\n\n                child_mem_trend_label = \" slope {0:.5f}\".format(cmem_trend[0])\n\n            # Plot the line to the figure\n            pl.plot(cts, cmem, \"+-\" + mem_line_colors[(idx + 1) % len(mem_line_colors)],\n                    label=\"child {}{}\".format(proc, child_mem_trend_label))\n\n            if show_trend_slope:\n                # Plot the trend line\n                pl.plot(cts, cts*cmem_trend[0] + cmem_trend[1], \"--\", linewidth=0.5, color=\"black\")\n\n            # Detect the maximal child memory point\n            cmax_mem = cmem.max()\n            if cmax_mem > cmpoint[1]:\n                cmpoint = (cts[cmem.argmax()], cmax_mem)\n\n        # Add the marker lines for the maximal child memory usage\n        pl.vlines(cmpoint[0], pl.ylim()[0]+0.001, pl.ylim()[1] - 0.001, 'r', '--')\n        pl.hlines(cmpoint[1], pl.xlim()[0]+0.001, pl.xlim()[1] - 0.001, 'r', '--')\n\n    # plot timestamps, if any\n    if len(ts) > 0 and timestamps:\n        func_num = 0\n        f_labels = function_labels(ts.keys())\n        for f, exec_ts in ts.items():\n            for execution in exec_ts:\n                add_brackets(execution[:2], execution[2:], xshift=global_start,\n                             color=all_colors[func_num % len(all_colors)],\n                             label=f_labels[f]\n                                   + \" %.3fs\" % (execution[1] - execution[0]), options=options)\n            func_num += 1\n\n    if timestamps:\n        pl.hlines(max_mem,\n                  pl.xlim()[0] + 0.001, pl.xlim()[1] - 0.001,\n                  colors=\"r\", linestyles=\"--\")\n        pl.vlines(t[max_mem_ind], bottom, top,\n                  colors=\"r\", linestyles=\"--\")\n    return mprofile\n\n\n\nFLAME_PLOTTER_VARS = {\n    'hovered_rect': None,\n    'hovered_text': None,\n    'alpha': None\n}\n\ndef flame_plotter(filename, index=0, timestamps=True, children=True, options=None):\n    try:\n        import pylab as pl\n    except ImportError as e:\n        print(\"matplotlib is needed for plotting.\")\n        print(e)\n        sys.exit(1)\n    import numpy as np  # pylab requires numpy anyway\n    mprofile = read_mprofile_file(filename)\n\n    if len(mprofile['timestamp']) == 0:\n        print('** No memory usage values have been found in the profile '\n              'file.**\\nFile path: {0}\\n'\n              'File may be empty or invalid.\\n'\n              'It can be deleted with \"mprof rm {0}\"'.format(\n            mprofile['filename']))\n        sys.exit(0)\n\n    # Merge function timestamps and memory usage together\n    ts = mprofile['func_timestamp']\n    t = mprofile['timestamp']\n    mem = mprofile['mem_usage']\n    chld = mprofile['children']\n\n    if len(ts) > 0:\n        for values in ts.values():\n            for v in values:\n                t.extend(v[:2])\n                mem.extend(v[2:4])\n\n    mem = np.asarray(mem)\n    t = np.asarray(t)\n    ind = t.argsort()\n    mem = mem[ind]\n    t = t[ind]\n\n    if ts:\n        stack_size = 1 + max(ex[4] for executions in ts.values() for ex in executions)\n    else:\n        stack_size = 0\n    def level_to_saturation(level):\n        return 1 - 0.75 * level / stack_size\n\n    colors = [\n        itertools.cycle([\n            pl.matplotlib.colors.hsv_to_rgb((0, level_to_saturation(level), 1)),\n            pl.matplotlib.colors.hsv_to_rgb((0.1, level_to_saturation(level), 1)),\n        ]) for level in range(stack_size)\n    ]\n\n    # Plot curves\n    global_start = float(t[0])\n    t = t - global_start\n\n    max_mem = mem.max()\n    max_mem_ind = mem.argmax()\n\n    # cmap = pl.cm.get_cmap('gist_rainbow')\n    mem_line_colors = (\"k\", \"b\", \"r\", \"g\", \"c\", \"y\", \"m\")\n    mem_line_label = time.strftime(\"%d / %m / %Y - start at %H:%M:%S\",\n                                   time.localtime(global_start)) \\\n                     + \".{0:03d}\".format(int(round(math.modf(global_start)[0] * 1000)))\n\n    pl.plot(t, mem, \"-\" + mem_line_colors[index % len(mem_line_colors)],\n            label=mem_line_label)\n\n    bottom, top = pl.ylim()\n    bottom += 0.001\n    top -= 0.001\n\n    ax = pl.gca()\n    ax.grid(True)\n    timestamp_ax = ax.twinx()\n    timestamp_ax.set_yticks([])\n    timestamp_ax.set_ylim((0, stack_size + 1))\n    timestamp_ax.grid(False)\n\n    # plot children, if any\n    if len(chld) > 0 and children:\n        cmpoint = (0,0) # maximal child memory\n\n        for idx, (proc, data) in enumerate(chld.items()):\n            # Create the numpy arrays from the series data\n            cts  = np.asarray([item[1] for item in data]) - global_start\n            cmem = np.asarray([item[0] for item in data])\n\n            # Plot the line to the figure\n            pl.plot(cts, cmem, \"+-\"  + mem_line_colors[(idx+1) % len(mem_line_colors)],\n                     label=\"child {}\".format(proc))\n\n            # Detect the maximal child memory point\n            cmax_mem = cmem.max()\n            if cmax_mem > cmpoint[1]:\n                cmpoint = (cts[cmem.argmax()], cmax_mem)\n\n        # Add the marker lines for the maximal child memory usage\n        pl.vlines(cmpoint[0], pl.ylim()[0]+0.001, pl.ylim()[1] - 0.001, 'r', '--')\n        pl.hlines(cmpoint[1], pl.xlim()[0]+0.001, pl.xlim()[1] - 0.001, 'r', '--')\n\n    def mouse_motion_handler(event):\n        x, y = event.xdata, event.ydata\n        if x is not None and y is not None:\n            for coord, (name, text, rect) in rectangles.items():\n                x0, y0, x1, y1 = coord\n                if x0 < x < x1 and y0 < y < y1:\n                    if FLAME_PLOTTER_VARS['hovered_rect'] == rect:\n                        return\n\n                    if FLAME_PLOTTER_VARS['hovered_rect'] is not None:\n                        FLAME_PLOTTER_VARS['hovered_rect'].set_alpha(FLAME_PLOTTER_VARS['alpha'])\n                        FLAME_PLOTTER_VARS['hovered_text'].set_color((0, 0, 0, 0))\n                        FLAME_PLOTTER_VARS['hovered_rect'].set_linewidth(1)\n\n                    FLAME_PLOTTER_VARS['hovered_text'] = text\n                    FLAME_PLOTTER_VARS['hovered_rect'] = rect\n                    FLAME_PLOTTER_VARS['alpha'] = rect.get_alpha()\n                    FLAME_PLOTTER_VARS['hovered_rect'].set_alpha(0.8)\n                    FLAME_PLOTTER_VARS['hovered_rect'].set_linewidth(3)\n                    FLAME_PLOTTER_VARS['hovered_text'].set_color((0, 0, 0, 1))\n                    pl.draw()\n                    return\n\n        if FLAME_PLOTTER_VARS['hovered_rect'] is not None:\n            FLAME_PLOTTER_VARS['hovered_text'].set_color((0, 0, 0, 0))\n            FLAME_PLOTTER_VARS['hovered_rect'].set_alpha(FLAME_PLOTTER_VARS['alpha'])\n            FLAME_PLOTTER_VARS['hovered_rect'].set_linewidth(1)\n            pl.draw()\n            FLAME_PLOTTER_VARS['hovered_rect'] = None\n            FLAME_PLOTTER_VARS['hovered_text'] = None\n\n    def mouse_click_handler(event):\n        x, y = event.xdata, event.ydata\n        if x is None or y is None:\n            return\n\n        for coord, _ in rectangles.items():\n            x0, y0, x1, y1 = coord\n            if x0 < x < x1 and y0 < y < y1:\n                toolbar = pl.gcf().canvas.toolbar\n                toolbar.push_current()\n                timestamp_ax.set_xlim(x0, x1)\n                timestamp_ax.set_ylim(y0, stack_size + 1)\n                toolbar.push_current()\n                pl.draw()\n                return\n\n    # plot timestamps, if any\n    if len(ts) > 0 and timestamps:\n        func_num = 0\n        f_labels = function_labels(ts.keys())\n        rectangles = {}\n        for f, exec_ts in ts.items():\n            for execution in exec_ts:\n                x0, x1 = execution[:2]\n                y0 = execution[4]\n                y1 = y0 + 1\n                x0 -= global_start\n                x1 -= global_start\n                color = next(colors[y0])\n                rect, text = add_timestamp_rectangle(\n                    timestamp_ax,\n                    x0, x1, y0, y1, f,\n                    color=color\n                )\n                rectangles[(x0, y0, x1, y1)] = (f, text, rect)\n            func_num += 1\n\n        # Disable hovering if there are too many rectangle to prevent slow down\n        if len(rectangles) < 100:\n            pl.gcf().canvas.mpl_connect('motion_notify_event', mouse_motion_handler)\n        pl.gcf().canvas.mpl_connect('button_release_event', mouse_click_handler)\n\n    if timestamps:\n        pl.hlines(max_mem,\n                  pl.xlim()[0] + 0.001, pl.xlim()[1] - 0.001,\n                  colors=\"r\", linestyles=\"--\")\n        pl.vlines(t[max_mem_ind], bottom, top,\n                  colors=\"r\", linestyles=\"--\")\n\n    pl.sca(ax)\n\n    return mprofile\n\n\ndef add_timestamp_rectangle(ax, x0, x1, y0, y1, func_name, color='none'):\n    rect = ax.fill_betweenx((y0, y1), x0, x1, color=color, alpha=0.5, linewidth=1)\n    text = ax.text(x0, y1, func_name,\n        horizontalalignment='left',\n        verticalalignment='top',\n        color=(0, 0, 0, 0)\n    )\n    return rect, text\n\n\ndef function_labels(dotted_function_names):\n    state = {}\n\n    def set_state_for(function_names, level):\n        for fn in function_names:\n            label = \".\".join(fn.split(\".\")[-level:])\n            label_state = state.setdefault(label, {\"functions\": [],\n                                                   \"level\": level})\n            label_state[\"functions\"].append(fn)\n\n    set_state_for(dotted_function_names, 1)\n\n    while True:\n        ambiguous_labels = [label for label in state if len(state[label][\"functions\"]) > 1]\n        for ambiguous_label in ambiguous_labels:\n            function_names = state[ambiguous_label][\"functions\"]\n            new_level = state[ambiguous_label][\"level\"] + 1\n            del state[ambiguous_label]\n            set_state_for(function_names, new_level)\n        if len(ambiguous_labels) == 0:\n            break\n\n    fn_to_label = dict((label_state[\"functions\"][0] , label) for label, label_state in state.items())\n\n    return fn_to_label\n\n\ndef plot_action():\n    def xlim_type(value):\n        try:\n            newvalue = [float(x) for x in value.split(',')]\n        except:\n            raise ArgumentError(\"'%s' option must contain two numbers separated with a comma\" % value)\n        if len(newvalue) != 2:\n            raise ArgumentError(\"'%s' option must contain two numbers separated with a comma\" % value)\n        return newvalue\n\n    desc = \"\"\"Plots using matplotlib the data file `file.dat` generated\nusing `mprof run`. If no .dat file is given, it will take the most recent\nsuch file in the current directory.\"\"\"\n    parser = ArgumentParser(usage=\"mprof plot [options] [file.dat]\", description=desc)\n    parser.add_argument('--version', action='version', version=mp.__version__)\n    parser.add_argument(\"--title\", \"-t\", dest=\"title\", default=None,\n                        type=str, action=\"store\",\n                        help=\"String shown as plot title\")\n    parser.add_argument(\"--no-function-ts\", \"-n\", dest=\"no_timestamps\", action=\"store_true\",\n                        help=\"Do not display function timestamps on plot.\")\n    parser.add_argument(\"--output\", \"-o\",\n                        help=\"Save plot to file instead of displaying it.\")\n    parser.add_argument(\"--window\", \"-w\", dest=\"xlim\", type=xlim_type,\n                        help=\"Plot a time-subset of the data. E.g. to plot between 0 and 20.5 seconds: --window 0,20.5\")\n    parser.add_argument(\"--flame\", \"-f\", dest=\"flame_mode\", action=\"store_true\",\n                        help=\"Plot the timestamps as a flame-graph instead of the default brackets\")\n    parser.add_argument(\"--slope\", \"-s\", dest=\"slope\", action=\"store_true\",\n                        help=\"Plot a trend line and its numerical slope\")\n    parser.add_argument(\"--backend\",\n                      help=\"Specify the Matplotlib backend to use\")\n    parser.add_argument(\"profiles\", nargs=\"*\",\n                        help=\"profiles made by mprof run\")\n    args = parser.parse_args()\n\n    try:\n        if args.backend is not None:\n            import matplotlib\n            matplotlib.use(args.backend)\n\n        import pylab as pl\n    except ImportError as e:\n        print(\"matplotlib is needed for plotting.\")\n        print(e)\n        sys.exit(1)\n    pl.ioff()\n\n    filenames = get_profiles(args)\n\n    fig = pl.figure(figsize=(14, 6), dpi=90)\n    if not args.flame_mode:\n        ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])\n    else:\n        ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n    if args.xlim is not None:\n        pl.xlim(args.xlim[0], args.xlim[1])\n\n    if len(filenames) > 1 or args.no_timestamps:\n        timestamps = False\n    else:\n        timestamps = True\n    plotter = plot_file\n    if args.flame_mode:\n        plotter = flame_plotter\n    for n, filename in enumerate(filenames):\n        mprofile = plotter(filename, index=n, timestamps=timestamps, options=args)\n    pl.xlabel(\"time (in seconds)\")\n    pl.ylabel(\"memory used (in MiB)\")\n\n    if args.title is None and len(filenames) == 1:\n        pl.title(mprofile['cmd_line'])\n    else:\n        if args.title is not None:\n            pl.title(args.title)\n\n    # place legend within the plot, make partially transparent in\n    # case it obscures part of the lineplot\n    if not args.flame_mode:\n        leg = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n        leg.get_frame().set_alpha(0.5)\n        pl.grid()\n\n    if args.output:\n        pl.savefig(args.output)\n    else:\n        pl.show()\n\ndef filter_mprofile_mem_usage_by_function(prof, func):\n    if func is None:\n        return prof[\"mem_usage\"]\n\n    if func not in prof[\"func_timestamp\"]:\n        raise ValueError(str(func) + \" was not found.\")\n\n    time_ranges = prof[\"func_timestamp\"][func]\n    filtered_memory = []\n    \n    # The check here could be improved, but it's done in this\n    # inefficient way to make sure we don't miss overlapping\n    # ranges.\n    for mib, ts in zip(prof[\"mem_usage\"], prof[\"timestamp\"]):\n        for rng in time_ranges:\n            if rng[0] <= ts <= rng[1]:\n                filtered_memory.append(mib)\n\n    return filtered_memory\n\ndef peak_action():\n    desc = \"\"\"Prints the peak memory used in data file `file.dat` generated\nusing `mprof run`. If no .dat file is given, it will take the most recent\nsuch file in the current directory.\"\"\"\n    parser = ArgumentParser(usage=\"mprof peak [options] [file.dat]\", description=desc)\n    parser.add_argument(\"profiles\", nargs=\"*\",\n                    help=\"profiles made by mprof run\")\n    parser.add_argument(\"--func\", dest=\"func\", default=None,\n                        help=\"\"\"Show the peak for this function. Does not support child processes.\"\"\")\n    args = parser.parse_args()\n    filenames = get_profiles(args)\n\n    for filename in filenames:\n        prof = read_mprofile_file(filename)\n        try:\n            mem_usage = filter_mprofile_mem_usage_by_function(prof, args.func)\n        except ValueError:\n            print(\"{}\\tNaN MiB\".format(prof[\"filename\"]))\n            continue\n\n        print(\"{}\\t{:.3f} MiB\".format(prof[\"filename\"], max(mem_usage)))\n        for child, values in prof[\"children\"].items():\n            child_peak = max([ mem_ts[0] for mem_ts in values ])\n            print(\"  Child {}\\t\\t\\t{:.3f} MiB\".format(child, child_peak))\n        \n\ndef get_profiles(args):\n    profiles = glob.glob(\"mprofile_??????????????.dat\")\n    profiles.sort()\n\n    if len(args.profiles) == 0:\n        if len(profiles) == 0:\n            print(\"No input file found. \\nThis program looks for \"\n                  \"mprofile_*.dat files, generated by the \"\n                  \"'mprof run' command.\")\n            sys.exit(-1)\n        print(\"Using last profile data.\")\n        filenames = [profiles[-1]]\n    else:\n        filenames = []\n        for prof in args.profiles:\n            if osp.exists(prof):\n                if not prof in filenames:\n                    filenames.append(prof)\n            else:\n                try:\n                    n = int(prof)\n                    if not profiles[n] in filenames:\n                        filenames.append(profiles[n])\n                except ValueError:\n                    print(\"Input file not found: \" + prof)\n    if not len(filenames):\n        print(\"No files found from given input.\")\n        sys.exit(-1)\n\n    return filenames\n\ndef main():\n    # Workaround for optparse limitation: insert -- before first negative\n    # number found.\n    negint = re.compile(\"-[0-9]+\")\n    for n, arg in enumerate(sys.argv):\n        if negint.match(arg):\n            sys.argv.insert(n, \"--\")\n            break\n    actions = {\"rm\": rm_action,\n               \"clean\": clean_action,\n               \"list\": list_action,\n               \"run\": run_action,\n               \"attach\": attach_action,\n               \"plot\": plot_action,\n               \"peak\": peak_action}\n    actions[get_action()]()\n\nif __name__ == \"__main__\":\n    main()\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.1123046875,
          "content": "[build-system]\nrequires = [\"setuptools\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[tool.codespell]\nskip = './.git'\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.8330078125,
          "content": "[metadata]\nname = memory_profiler\ndescription = A module for monitoring memory usage of a python program\nlong_description = file: README.rst\nversion = attr: memory_profiler.__version__\nlicense = BSD\nlicense_files = COPYING\nauthor = Fabian Pedregosa\nauthor_email = f@bianp.net\nurl = https://github.com/pythonprofilers/memory_profiler\nclassifiers =\n    Development Status :: 5 - Production/Stable\n    Intended Audience :: Science/Research\n    Intended Audience :: Developers\n    License :: OSI Approved :: BSD License\n    Programming Language :: Python\n    Programming Language :: Python :: 3\n    Topic :: Software Development\n    Operating System :: POSIX\n    Operating System :: Unix\n\n[options]\npy_modules =\n    memory_profiler\n    mprof\npython_requires = >=3.7\ninstall_requires = psutil\n\n[options.entry_points]\nconsole_scripts =\n    mprof = mprof:main\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.037109375,
          "content": "from setuptools import setup\n\nsetup()\n"
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}