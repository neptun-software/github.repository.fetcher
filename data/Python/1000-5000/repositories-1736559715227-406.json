{
  "metadata": {
    "timestamp": 1736559715227,
    "page": 406,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "dabeaz/curio",
      "stars": 4061,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1025390625,
          "content": "docs/_build\n__pycache__/\n.vscode\nvenv*\n*.egg-info\n\nbenchmarks/curio/\nbenchmarks/env/\nbenchmarks/results/\n"
        },
        {
          "name": "CHANGES",
          "type": "blob",
          "size": 72.9228515625,
          "content": "CHANGES\n-------\nApril 10, 2024: Note: I've decided to take Curio in a different\ndirection.  Initially, Curio was developed with variety of\n\"experimental\" features with the expectation that people might play\naround with them and we'd learn together.  However, this never really\nmaterialized.  As such, I'm going to be trimming the feature set.  If\nthis affects you, please look at the \"examples\" directory because I\nmay have moved code there.  Many features of Curio were simply\nhigher-level modules implemented on top of an existing core and can be\nadded back to your code without much effort. -- Dave\n\n04/11/2024 Removed undocumented ProcessPool and ThreadPool names.\n\n04/11/2024 Removed block_in_thread().  This functionality can be\n           replicated by protecting calls to run_in_thread() with a\n\t   semaphore. \n\n04/10/2024 Removed run_in_executor().  If you want to wait on work\n           submitted to a traditional executor (from concurrent.futures),\n\t   use curio.traps._future_wait().\n\t   \n04/10/2024 Removed subprocess module.  Use the Python built-in instead.\n           Old code found in examples/curio_subprocess.py\n\t   \n04/10/2024 Removed dependency on telnetlib.  Removed commands from the\n           monitor that allowed changes to the running environment,\n\t   specifically the `cancel` and `signal` commands.  It's\n\t   not clear that cancelling tasks from the monitor would\n\t   be all that useful to begin with.  If you need to send\n\t   a Unix signal, use `kill` at the command line.\n\t  \n04/10/2024 Eliminated flaky tests that were already marked for\n           skipping in pytest.\n\nVersion 1.6 - October 25, 2022\n------------------------------\n\n10/25/2022 ***IMPORTANT NOTE*** This is the last release on pypi.  Curio\n           will no longer be making package releases.  The most recent\n\t   version can be obtained at https://github.com/dabeaz/curio.\n\n05/09/2022 Fixed a problem with cancellation and waiting in UniversalEvent.\n\t   Reported by vytasrgl.\n\t   \n04/20/2022 Merged a fix for #350 where UniversalEvents couldn't be set\n           more than once.   Reported and fixed by Stephen Harding.\n\t   \n03/10/2021 Fixed Issue #340 related to the handling of daemonic tasks\n           in a TaskGroup.   TaskGroups can now be given existing\n           daemonic tasks in the constructor.  Daemonic tasks are\n           correctly cancelled if a TaskGroup used as a context manager\n           terminates due to an exception.\n           \n10/25/2020 Changed all cancellation related exceptions to inherit\n           from BaseException instead of Exception.   This makes\n           them play slightly better with normal exception handling\n           code:\n\n               try:\n                   await some_operation()\n               except Exception as err:\n                   # Normal (expected) program related error\n                   ...\n               except CancelledError as err:\n                   # Cancellation of some kind\n                   ...\n\n           This also mirrors a similar change to asyncio.CancelledError\n           which now directly inherits from BaseException.\n\n           ***POTENTIAL INCOMPATIBILITY***\n\n           If you were using try: ... except Exception: to catch\n           cancellation, that code will break. \n           \n10/17/2020 Added ps() and where() commands to the monitor\n           that can be used from the Curio REPL when you run\n           `python -m curio`.  These can also be used to monitor\n           the state of the kernel from a different thread.\n           For example:\n\n               from threading import Thread\n               \n               kern = Kernel()\n               Thread(target=kern.run, args=[main]).start()\n\n               >>> from curio.monitor import ps\n               >>> ps(kern)\n               ... displays active tasks ...\n\n           This makes it a bit easier to have some of the monitor\n           capability in an live-environment where Curio is running.\n\nVersion 1.4 - August 23, 2020\n-----------------------------\n08/23/2020 Fixed minimum requirement in setup.py\n\n\nVersion 1.3 - August 23, 2020\n-----------------------------\n08/21/2020 Moved the Pytest plugin to the examples directory.  There have \n           been several reported problems with it.   It is no longer\n           installed by default.  It was never used by Curio itself.\n\n06/16/2020 Refined the detection of coroutines to use collections.abc.Coroutine.\n           This change should not affect any existing part of Curio, but it\n           allows it to properly recognize async functions defined in\n           extensions such as Cython.  See Issue #326.\n           \n06/11/2020 Added a Result object.  It's like an Event except that it has a\n           an associated value/exception attached to it.  Here's the basic\n           usage pattern:\n\n               result = Result()\n               ...\n               async def do_work():\n                   try:\n                       ...\n                       await result.set_value(value)\n                   except Exception as e:\n                       await result.set_exception(e)\n\n               async def some_task():\n                   ...\n                   try:\n                       value = await result.unwrap() \n                       print(\"Success:\", value)\n                   except Exception as e:\n                       print(\"Fail:\", e)\n\n           In this example, the unwrap() method blocks until the result\n           becomes available.\n\n06/09/2020 Having now needed it a few projects, have added a UniversalResult\n           object.  It allows Curio tasks or threads to wait for a result\n           to be set by another thread or task.   For example:\n\n               def do_work(result):\n                   ...\n                   result.set_value(value)\n\n               async def some_task(result):\n                   ...\n                   value = await result.unwrap()\n                   ...\n\n               result = UniversalResult()\n               threading.Thread(target=do_work, args=[result]).start()\n               curio.run(some_task, result)\n\n           UniversalResult is somewhat similar to a Future.  However, it\n           really only allows setting and waiting.  There are no callbacks,\n           cancellation, or any other extras.\n\nVersion 1.2 - April 6, 2020\n---------------------------\n\n04/06/2020 Removed hard dependency on contextvars.   It was unnecessary and\n           needlessly broken some things on Python 3.6.\n           \n04/06/2020 Added a default selector timeout of 1 second for Windows.  This\n           makes everything a bit more friendly for Control-C.  This can be\n           disabled or changed using the max_select_timeout argument to Kernel\n           or curio.run().\n           \n04/04/2020 First crack at a Curio repl.  Idea borrowed from the asyncio\n           REPL.  If you run `python -m curio` it will start a REPL\n           in which Curio is already running in the background. You\n           can directly await operations at the top level. For example:\n\n              bash $ python -m curio\n              Use \"await\" directly instead of \"curio.run()\".\n              Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n              >>> import curio\n              >>> await curio.sleep(4)\n              >>>\n\n           Pressing Control-C causes any `await` operation to be cancelled\n           with a `curio.TaskCancelled` exception.   For normal operations\n           not involving `await, Control-C raises a `KeyboardInterrupt` as\n           normal.  Note: This feature requires Python 3.8 or newer. \n\n03/24/2020 Added a pytest plugin for Curio. Contributed by Keith Dart.\n           See curio/pytest_plugin.py.\n\n03/02/2020 Slight refinement to TaskGroup result reporting. If no tasks\n           are spawned in a TaskGroup g, then g.exception will return None\n           to indicate no errors.  g.result will raise an exception\n           indicating that no successful result was obtained. Addresses\n           issue #314.\n\nVersion 1.1 - March 1, 2020\n---------------------------\n02/24/2020 Fixed a very subtle edge case involving epoll() and duplicated\n           file descriptors on Linux. The fix required a new trap\n           _io_release() to explitly unregister a file descriptor\n           before closing. This must be embedded in any close()\n           implementation prior to actually calling close() on a real\n           file object.  No changes should be necessary in existing\n           user-level Curio code.  Bug #313 reported by Ondřej Súkup.\n\nVersion 1.0 - February 20, 2020\n-------------------------------\n\n**** SPECIAL NOTE ****: For the past few years, Curio has been been an\nexperimental project.  However, as it moves towards having a more\n\"stable\" release, I feel that it is better served by being small as\nopposed to providing every possible feature like a framework. Thus, a wide range of\nminor features have either been removed or refactored. If this broke \nyour code, sorry. Some features have been moved to the examples\ndirectory.   If something got removed and you'd like to lobby for its \nreturn, please submit a bug report. -- Dave\n\n02/19/2020 The Activation base class has been moved into curio.kernel.\n\n02/14/2020 Modified UniversalEvent to also support asyncio for completeness\n           with UniversalQueue.  This requires Curio and asyncio to be\n           running in separate threads.\n\n02/10/2020 Removed absolute time-related functions wake_at(), timeout_at(),\n           and ignore_at().  This kind of functionality (if needed) can\n           be reimplemented using the other sleep/timeout functions. \n\n02/10/2020 Added daemon flag to TaskGroup.spawn().  This can be used\n           to create a disregarded task that is ignored for the\n           purpose of reporting results, but which is cancelled when\n           the TaskGroup goes away. \n\n02/10/2020 Added spawn_thread() method to TaskGroup.  Can be used\n           to create an AsyncThread that's attached to the group.\n           AsyncThreads follow the same semantics as tasks.\n         \n02/09/2020 Removed schedule() function. Use sleep(0). \n\n02/07/2020 Removed all support for signal handling.  Signal handling,\n           by its very nature, is a tricky affair. For instance,\n           signals can only be handled in the main execution thread\n           and there are all sorts of other issues that can arise \n           when mixed with threads, subprocesses, locks, and other\n           things.  Curio already provides all of the necessary support\n           to implement signal handling if you rely on UniversalEvent\n           or UniversalQueue objects.   Here is a simple example::\n\n               import signal\n               import curio\n\n               evt = curio.UniversalEvent()\n\n               def signal_handler(signo, frame):\n                   evt.set()\n\n               async def wait_for_signal():\n                   await evt.wait()\n                   print(\"Got a signal!\")\n\n               signal.signal(signal.SIGHUP, signal_handler)\n               curio.run(wait_for_signal)\n\n02/07/2020 Removed iteration support from queues.  Queues in the\n           standard library don't support iteration.\n\n02/06/2020 Removed metaprogramming features not used in the implementation\n           of Curio itself.  These include:\n\n               @async_thread\n               @cpubound\n               @blocking\n               @sync_only\n               AsyncABC\n\n           Libraries/frameworks that use Curio should be responsible\n           for their own metaprogramming.  Their removal is meant to\n           make Curio smaller and easier to reason about.\n\n02/06/2020 Added exception and exceptions attributes to TaskGroup.\n           Can be used to check for errors.  For example:\n\n               async with TaskGroup(wait=all) as g:\n                   await g.spawn(coro1)\n                   await g.spawn(coro2)\n                   ...\n               if any(g.exceptions):\n                   print(\"An error occurred\")\n\n           Obviously, you could expand that to be more detailed. \n\n02/04/2020 Removed TaskGroupError exception and simplified the error\n           handling behavior of task groups.  If tasks exit with an\n           exception, that information is now obtained on the task\n           itself or on the .result attribute of a task group. For\n           example:\n\n               async with TaskGroup() as g:\n                   t1 = await g.spawn(coro1)\n                   t2 = await g.spawn(coro2)\n                   ...\n\n               try:\n                   r = t1.result\n               except WhateverError:\n                   ...\n\n               # Alternatively\n               try:\n                   r = g.result\n               except WhateverError:\n                   ...\n\n           This simplifies both the implementation of task groups as well as \n           a lot of code that utilizes task groups.  Exceptions are no longer\n           wrapped up in layer-upon-layer of other exceptions.  There is a risk\n           of exceptions passing silently if you don't actually check the result\n           of a task group.  Don't do that. \n\n02/03/2020 Added convenience properties to TaskGroup.  If you want the\n           result of the first completed task, use .result like this:\n\n               async with TaskGroup(wait=any) as g:\n                   await g.spawn(coro1)\n                   await g.spawn(coro2)\n                   ...\n \n               print('Result:', g.result)\n\n           If you want a list of all results *in task creation order*\n           use the .results property:\n\n               async with TaskGroup(wait=all) as g:\n                   await g.spawn(coro1)\n                   await g.spawn(coro2)\n                   ...\n \n               print('Results:', g.results)\n\n           Note: Both of these are on the happy path.  If any kind of\n           exception occurs, task groups still produce a\n           TaskGroupError exception.\n\n01/29/2020 Added support for contextvars.  The behavior of context \n           variables in the context of Curio and threads is not\n           always well defined.  As such, this is a feature that\n           requires explicit user opt-in to enable.  To do it, you need\n           provide an alternative Task class definition to the kernel\n           like this:\n\n               from curio.task import ContextTask\n               from curio import Kernel\n\n               with Kernel(taskcls=ContextTask) as kernel:\n                    kernel.run(coro)\n\n           Alternatively, you can use:\n\n               from curio import run\n               run(coro, taskcls=ContextTask)\n\n01/29/2020 Added optional keyword-only argument taskcls to Kernel. This\n           can be used to provide alternative implementations of the\n           internal Task class used to wrap coroutines.  This can be\n           useful if you want to subclass Task or implement certain\n           task-related features in a different way.\n\n10/15/2019 Refactored task.py into separate files for tasks and time\n           management.\n\n09/29/2019 Removed Promise.  Not documented, but also want to rethink the\n           whole design/implementation of it. The \"standard\" way that\n           Python implements \"promises\" is through the Future class\n           as found in the concurrent.futures module.  However, Futures\n           are tricky.  They often have callback functions attached to \n           them and they can be cancelled.  Some further thought needs\n           to be given as to how such features might integrate with the\n           rest of Curio.  Code for the old Promise class can be \n           found the examples directory.\n\n09/26/2019 Removed support for the Asyncio bridge. It wasn't documented\n           and there are many possible ways in which Curio might \n           potentially interact with an asyncio event loop. For example,\n           using queues.  Asyncio interaction may be revisited in the\n           future.  \n\n09/13/2019 Support for context-manager use of spawn_thread() has been\n           withdrawn.  It's a neat feature, but the implementation\n           is pretty hairy.  It also creates a situation where async\n           functions partially run in coroutines and partially in threads.\n           All things equal, it's probably more sane to make this \n           kind of distinction at the function level, not at the level\n           of code blocks.   \n\n09/11/2019 Removed AsyncObject and AsyncInstanceType. Very specialized.\n           Not used elsewhere in Curio. Involves metaclasses. One\n           less thing to maintain.\n\n09/11/2019 I want to use f-strings. Now used for string formatting\n           everywhere except in logging messages. Sorry Python 3.5.\n\n09/11/2019 Removed the allow_cancel optional argument to spawn().\n           If a task wants to disable cancellation, it should \n           explicitly manage that on its own. \n\n09/11/2019 Removed the report_crash option to spawn(). Having\n           it as an optional argument is really the wrong place for\n           this.  On-by-default crash logging is extremely useful for\n           debugging.  However, if you want to disable it, it's\n           annoying to have to go change your source code on a task-by-task\n           basis.  A better option is to suppress it via configuration \n           of the logging module.  Better yet: write your code so that\n           it doesn't crash.\n\n09/10/2019 Some refactoring of some internal scheduling operations.\n           The SchedFIFO and SchedBarrier classes are now available\n           for more general use by any code that wants to implement\n           different sorts of synchronization primitives.\n\n09/10/2019 Removed the abide() function.  This feature was from the\n           earliest days of Curio when there was initial thinking \n           about the interaction of async tasks and existing threads.\n           The same functionality can still be implemented using run_in_thread()\n           or block_in_thread() instead.  In the big picture, the problem\n           being solved might not be that common.  So, in the interest\n           of making Curio smaller, abide() has ridden off into the sunset.\n\n09/08/2019 Removed BoundedSemaphore.\n\n09/03/2019 Removed the experimental aside() functionality.  Too much \n           magic.  Better left to others.\n\n09/03/2019 Removed the gather() function.  Use TaskGroup instead.\n\n09/03/2019 Removed get_all_tasks() function.\n\n09/03/2019 Removed the Task.pdb() method.\n\n09/03/2019 Removed the Task.interrupt() method.\n\n09/03/2019 The pointless (and completely unused) name argument to TaskGroup() \n           has been removed. \n\n08/09/2019 Exceptions raised inside the Curio kernel itself are no longer \n           reported to tasks.  Instead, they cause Curio to die. The\n           kernel is never supposed to raise exceptions on its own--any\n           exception that might be raised is an internal programming error.\n           This change should not impact user-level code, but might affect\n           uncontrolled Ctrl-C handling. If a KeyboardInterrupt occurs\n           in the middle of kernel-level code, it will cause an uncontrolled\n           death. If this actually matters to you, then modify your code to\n           properly handle Ctrl-C via signal handling.\n\n04/14/2019 The Channel.connect() method no longer implements auto-retry. \n           In practice, this kind of feature can cause interference. Better\n           to let the caller do the retry if they want.\n\n04/14/2019 Simplified the implementation and semantics of cancellation control.\n           The enable_cancellation() function has been removed.  It is now\n           only possible to disable cancellation.  Nesting is still allowed.\n           Pending cancellation exceptions are raised on the first blocking\n           call executed when reenabled.  The check_cancellation() function \n           can be used to explicitly check for cancellation as before.\n           \n03/09/2019 Fixed a bug in network.open_connection() that was passing arguments\n           incorrectly.  Issue #291.\n\n11/18/2018 Removed code that attempted to detect unsafe async generator\n           functions.  Such code is now executed without checks or \n           warnings.  It's still possible that code in finally blocks\n           might not execute unless you use curio.meta.finalize() or\n           a function such as async_generator.aclosing() (third party).\n           The @safe_generator decorator is now also unnecessary.\n\n11/11/2018 Removed the wait argument to TaskGroup.join().  The waiting policy\n           for task groups is specified in the TaskGroup constructor.  For\n           example:\n\n               with TaskGroup(wait=any) as group:\n                    ...\n\n09/05/2018 Tasks submitted to Kernel.run() no longer log exceptions should they\n           crash.  Such tasks already return immediately to the caller with the\n           exception raised. \n\n09/05/2018 Refinement to Kernel.__exit__() to make sure the kernel shuts down\n           regardless of any exceptions that have occurred.  See Issue #275.\n\n04/29/2018 New task-related function.  get_all_tasks() returns a list of all active\n           Tasks. For example:\n\n               tasks = await get_all_tasks()\n\n           Tasks also have a where() method that returns a (filename, lineno) tuple\n           indicating where they are executing.\n\n04/29/2018 Curio now properly allows async context managers to be defined using\n           context.asynccontextmanager.  Issue #247.\n\n04/29/2018 Removed the cancel_remaining keyword argument from TaskGroup.next_done()\n\n04/28/2018 Added new \"object\" wait mode to TaskGroup.  It waits for the\n           first non-None result to be returned by a task.  Then all \n           remaining tasks are cancelled.  For example:\n\n               async def coro1():\n                   await sleep(1)\n                   return None\n\n               async def coro2():\n                   await sleep(2)\n                   return 37\n\n               async def coro3():\n                   await sleep(3)\n                   return 42\n \n               async with TaskGroup(wait=object) as tg:\n                   await tg.spawn(coro1)      # Ignored (returns None)\n                   await tg.spawn(coro2)      # Returns result\n                   await tg.spawn(coro3)      # Cancelled\n\n               print(tg.completed.result)  # -> 37\n\n04/27/2018 Removed the ignore_result keyword argument to TaskGroup.spawn().\n           It's not really needed and the extra complexity isn't worth it.\n\n04/27/2018 Added TaskGroup.next_result() function.  It's mostly a convenience\n           function for returning the result of the next task that completes.\n           If the task failed with an exception, that exception is raised.\n\n04/14/2018 Changed the method of spawning processes for run_in_process to\n           use the \"spawn\" method of the multiprocessing module. This \n           prevents issues of having open file-descriptors cloned by\n           accident via fork().  For example, as in Issue #256.\n\nVersion 0.9 : March 10, 2018\n----------------------------\n02/24/2018 Refinements to Task crash reporting.  By default all Tasks\n           that terminate with an uncaught exception log that exception\n           as soon as it is detected.  Although there is a risk that this\n           creates extra output, silencing the output makes it almost\n           impossible to debug programs.  This is because errors get\n           deferred to a later join() method---and you often don't know\n           when that's going to take place.  You might just be staring\n           a program wondering why it's not working.    If you really\n           want errors to be silent, use spawn(coro, report_crash=False).\n           \n02/23/2018 Some refinements to the AWAIT() function.  You can now call it as \n           follows:\n\n               result = AWAIT(callable, *args, **kwargs)\n\n           If the passed callable is a coroutine function or a function that\n           produces an awaitable object, it will be passed to Curio and executed\n           in an asynchronous context.   If callable is just a normal function,\n           then callable(*args, **kwargs) is returned.\n\n           This change is made to make it slightly easier to use objects\n           as UniversalQueue within the context of an async thread.  For example,\n           if you do this::\n\n               q = UniversalQueue()\n               ...\n               @async_thread\n               def consumer():\n                   while True:\n                       item = AWAIT(q.get)\n                       print(\"Got:\", item)\n \n            The AWAIT operation will run the asynchronous version of q.get()\n            instead of the normal synchronous version.  You want this--the\n            async version supports cancellation and other nice features.\n\n02/22/2018 The async_thread() function is now meant to be used as a decorator only.\n\n              @async_thread\n              def func(args):\n                  ...\n\n           When the decorated function is called from asynchronous code using\n           await func(args), it will seamlessly run in a separate execution thread.\n           However, the function can also be called from synchronous code using\n           func(args).  In that case, the function runs as it normally does.\n           It's subtle, but the @async_thread decorator allows a function to adapt\n           to either a synchronous or asynchronous environment depending on how \n           it has been called. \n \n02/22/2018 New function spawn_thread() can be used to launch asynchronous threads.\n           It mirrors the use of the spawn() function. For example:\n\n              def func(args):\n                  ...\n\n              t = await spawn_thread(func, args)\n              result = await t.join()\n\n           Previously, async threads were created using the AsyncThread class.\n           That still works, but the spawn_thread() function is probably easier.\n\n           The launched function must be a normal synchronous function. \n           spawn_thread() can also be used as a context manager (see below).\n\n02/19/2018 Added ability of async threads to be created via context manager.\n           For example:\n\n              async with spawn_thread():\n                  # Various blocking/synchronous operations\n                  # Executes in a separate thread\n                  ...\n\n           When used, the body of the context manager runs in a\n           separate thread and may involve blocking operations.\n           However, be aware that any use of async/await is NOT\n           allowed in such a block.  Any attempt to await on an async\n           function inside the block will result in a RuntimeError\n           exception. \n\n02/06/2018 Refinements to the schedular activation API and debugging\n           features.\n\n02/04/2018 The ZMQ module has been removed from Curio core and put into\n           the examples directory.   This should be spun into a separate\n           package maintained independently of Curio.\n\n02/03/2018 Local() objects have been removed.  The idea of having a\n           thread-local style object for storing attributes is fraught\n           with problems--especially given the potential mix of tasks,\n           threads, and processes that is possible in Curio.  The\n           implementation of this has been moved into the examples\n           directory where it can be adapted/copied into your code if\n           it's still needed.   Better yet, maybe take a look at PEP 567.\n\n02/02/2018 Some refactoring and simplification of the kernel run() \n           method.  First, run() only executes as long as the\n           submitted coroutine is active.  Upon termination, run()\n           immediately returns regardless of whether or not other\n           tasks are still running.  Curio was already generating\n           warning messages for orphaned tasks--tasks for which\n           Task.join() is never invoked.  As such, this change should\n           not affect most properly written applications.\n\n           Second, the timeout argument is no longer supported. If\n           you want a timeout on what's happening, put it into the \n           supplied async function itself.\n\n           Finally, if Kernel.run() is called with no arguments, it\n           causes the kernel to process any activity that might be\n           pending at that moment in time before returning.  This is\n           something that might be useful should it be necessary\n           to integrate Curio with a foreign event-loop.\n\n01/31/2018 If the main task crashes with an exception, the kernel\n           now returns immediately--even if child tasks are still\n           in progress.   This prevents a problem where the main task\n           crashes, but it's not reported for an extended period due\n           to child tasks continuing to run.  In addition, if the\n           main task crashes, the kernel does not perform a shutdown--\n           leaving tasks as they were at the time of the crash.  This\n           might facilitate debugging.\n\n01/31/2018 Printing a Task object will now show the file and line number\n           of where it's currently waiting.\n\n01/23/2018 A refinement in task crash reporting.  Previously, all \n           task crashes were logged.  However, Curio was also logging\n           crashes in all unjoined tasks.  Sometimes this would result\n           in duplicate tracebacks.  It's been modified to now only report\n           crashes in unjoined tasks.  If joining, it's assumed that the\n           exception would be noticed there.\n\n01/22/2018 Semaphore and BoundedSemaphore now exposes a read-only\n           property \".value\" that gives the current Semaphore value.\n           BoundedSemaphore objects expose a \".bound\" property that\n           gives the upper bound.\n           \n01/03/2018 The Local() object has been officially deprecated in the \n           documentation and will be removed at some point.\n           Implementing task-level locals is much more complicated\n           than it seems at first glance and there is discussion of a\n           more general solution in PEP 567.   If you need this kind\n           of functionality, you should copy the task local code into\n           your own application.\n\n12/22/2017 writeable() method of Socket removed.  Use of this was highly\n           specialized and potentially confusing since it's not normally\n           needed.   Use await _write_wait(sock) if you need to wait\n           for a socket to be writable before calling send().\n\n12/19/2017 Slight change to Task Groups that allow tasks to spawn\n           other tasks into the same group.  See Issue #239.\n\n09/15/2017 Added the .readinto() method onto async files.\n\n09/15/2017 Made the @async_thread decorator return the actual\n           exception that gets raised in the event of a failure.\n           This makes it more like a normal function call.  Previously,\n           it was returning a TaskError exception for any crash.\n           That's a bit weird since the use of threads or spawning\n           of an external task is meant to be more implicit.\n\nVersion 0.8 : August 27, 2017\n-----------------------------\n07/01/2017 New time queue implementation. For timeout handling, it's\n           faster and far more space efficient.\n\n05/11/2017 Fixed Issue #212, \"never joined\" message when add terminated\n           tasks to a task group and using task.result to obtain the \n           result.\n\n05/11/2017 Added a new keyword argument to Task.cancel() to allow a different\n           exception to be raised.  For example:\n\n              t.cancel(exc=SomeException)\n\n           The default exception is still TaskCancelled.\n\n04/23/2017 Change to ssl.wrap_socket() function and method to make it an\n           async method.   If applied to an already connected socket, it\n           needs to run the handshake--which needs to be async.  See\n           Issue #206.\n\n04/14/2017 Refinement to SignalEvent to make it work better on Windows.\n           It's now triggered via the same file descriptor used for SignalQueue\n           objects.\n\n03/26/2017 Added a Task.interrupt() method.  Cancels the task's current\n           blocking operation with an 'TaskInterrupted' exception.\n           This is really just a more nuanced form of cancellation,\n           similar to a timeout.  However, it's understood that an \n           interrupted operation doesn't necessarily mean that the\n           task should quit.   Instead, the task might coordinate with \n           other tasks in some way and retry later. \n\nVersion 0.7 : March 17, 2017\n----------------------------\n\n03/15/2017 The undocumented wait() function for waiting on multiple\n           tasks has evolved into a more general TaskGroup object.\n           To replicate the old wait(), do this:\n\n              t1 = spawn(coro1, args)\n              t2 = spawn(coro2, args)\n              t3 = spawn(coro3, args)\n\n              async with TaskGroup([t1,t2,t3]) as g:\n                  first_done = await g.next_done()\n                  await g.cancel_remaining()\n\n           TaskGroups have more functionality such as the ability\n           to spawn tasks, report multiple errors and more.\n\n           For example, the above code could also be written as follows:\n\n              async with TaskGroup() as g:\n                  await g.spawn(coro1, args)\n                  await g.spawn(coro2, args)\n                  await g.spawn(coro3, args)\n                  first_done = await g.next_done()\n                  await g.cancel_remaining()\n\n03/12/2017 Added a .cancelled attribute to the context manager used\n           by the ignore_after() and ignore_at() functions.  It\n           can be used to determine if a timeout fired.  For example:\n\n              async with ignore_after(10) as context:\n                  await sleep(100)\n\n              if context.cancelled:\n                  print('Cancelled!')\n\n03/10/2017 SignalSet is gone.   Use a SignalQueue instead.  Usage\n           is almost identical:\n\n               async with SignalQueue(signal.SIGUSR1) as sq:\n                   while True:\n                        signo = await sq.get()\n                        ...\n\n03/08/2017 More work on signal handling. New objects: SignalQueue \n           and SignalEvent.  SignalEvents are neat:\n\n               import signal\n               from curio import SignalEvent\n\n               ControlC = SignalEvent(signal.SIGINT)\n\n               async def coro():\n                   await ControlC.wait()\n                   print(\"Goodbye\")\n\n03/08/2017 UniversalEvent object added.  An event that's safe for use in\n           Curio and threads.\n\n03/08/2017 Further improvement to signal handling.  Now handled by a backing\n           thread.  Supports signal delivery to multiple threads, \n           multiple instances of Curio running, asyncio, and all sorts\n           of stuff.\n\n03/08/2017 Removed signal handling from the kernel up into Curio\n           \"user-space\".  No existing code the uses signals should break.\n\n03/07/2017 Refined error reporting and warnings related to Task\n           termination.  If any non-daemonic task is garbage collected\n           and it hasn't been explicitly joined or cancelled, a\n           warning message is logged.  This warning means that a task\n           was launched, but that nobody ever looked at its result.\n           If any unjoined task is garbage collected and it has\n           crashed with an uncaught exception, that exception is\n           logged as an error.\n\n           This change has a few impacts.  First, if a task crashes,\n           but is joined, you won't get a spurious output message\n           showing the crash.  The exception was delivered to someone\n           else.   On the other hand, you might get more warning\n           messages if you've been launching tasks without paying\n           attention to their result. \n\n03/06/2017 A lot of cleanup of the kernel. Moved some functionality \n           elsewhere. Removed unneeded traps.  Removed excess\n           abstraction in the interest of readability.  The different\n           trap functions in Curio are almost all quite small.\n           However, details concerning their execution behavior was\n           split across a few different places in the code and wrapped\n           with decorators--making it somewhat hard to piece together\n           how they worked looking at them in isolation.  Each trap \n           is now basically self-contained.  You can look at the code and \n           see exactly what it does.  Each trap is also afforded more\n           flexibility about how it could work in the future (e.g.,\n           scheduling behavior, cancellation, etc.).  \n\n           Debug logging features have been removed from the kernel and\n           placed into a new subsystem.  See the file curio/debug.py.\n           This is still in progress.\n\n03/05/2017 Change to how the debugging monitor is invoked.  It's still\n           an option on the run() function.  However, it is not a\n           option on the Kernel class itself.  If you need to do that,\n           use this:\n\n                from curio import Kernel\n                from curio.monitor import Monitor\n\n                k = Kernel()\n                m = Monitor(k)\n\n03/04/2017 Support for using Event.set() from a synchronous context has\n           been withdrawn.   This was undocumented and experimental.\n           There are other mechanisms for achieving this.  For example,\n           communicating through a UniversalQueue.\n\n03/03/2017 timeout_after() and related functions now accept\n           coroutine functions and arguments such as this:\n\n              async def coro(x, y):\n                  pass\n\n              async def main():\n                  try:\n                      await timeout_after(5, coro, 2, 3) \n                  except TaskTimeout:\n                      pass\n            \n03/03/2017 spawn() and run() have been made consistent in their\n           calling conventions compared to worker related functions.\n           For example:\n\n              async def coro(x, y):\n                  pass\n\n              async def main():\n                  t = await spawn(coro, 2, 3)   # Instead of spawn(coro(2,3))\n\n           The old approach still works, but the new one will be preferred\n           going forward.\n\n03/03/2017 Support for keyword arguments on many task-related worker\n           functions (run_in_thread, run_in_process, block_in_thread, etc.)\n           has been rescinded.   If you need keyword arguments, use\n           functools.partial.   For example:\n\n              await run_in_thread(partial(foo, kw=some_value))\n\n03/03/2017 Functionality for using Queue.put() in a synchronous context\n           has been withdrawn. This was always experimental and undocumented.\n           There are better alternatives for doing this.  For example, use a\n           UniversalQueue.\n\n03/01/2017 Addition of an asyncio bridge.  You can instantiate a separate\n           asyncio loop and submit tasks to it.  For example:\n\n              async def coro():\n                  # Some coroutine that runs on asyncio\n                  ...\n              async with AsyncioLoop() as loop:\n                  await loop.run_asyncio(coro)\n\n           The same loop can be used by any number of Curio tasks and\n           requests can run concurrently.  The asyncio loop runs in \n           a separate thread than Curio.\n\n           Original idea contributed by Laura Dickinson and adapted a\n           a bit into the AsyncioLoop class. \n\n02/26/2017 Modified the gather() function so that it also cancels all tasks\n           if it is cancelled by timeout or other means.  See issue #186.\n           The resulting exception has a .results attribute set with\n           the results of all tasks at the time of cancellation.\n\n02/19/2017 Added new curio.zmq module for supporting ZeroMQ.\n\nVersion 0.6 : February 15, 2017\n-------------------------------\n\n02/13/2017 Added a withfd=True option to UniversalQueue.  For example:\n\n              q = UniversalQueue(withfd=True)\n\n           If added, the queue internally sets up an I/O loopback\n           where putting items on the queue write bytes to an I/O\n           channel.  The queue then spouts a fileno() method and\n           becomes pollable in other event loops.  This is potentially\n           useful strategy for integrating Curio with GUIs and other\n           kinds of foreign event loops.  \n\n02/11/2017 Added a guard for proper use of asynchronous generators\n           involving asynchronous finalization.  Must be wrapped by finalize(). \n           For example:\n\n           async def some_generator():\n               ...\n               try:\n                   yield val\n               finally:\n                   await action()\n\n           async def coro():\n               ...\n               async with finalize(some_generator()) as agen:\n                   async for item in agen:\n                       ...\n\n           Failure to do this results in a RuntimeError if an\n           asynchronous generator is iterated.   This is not needed for\n           generators that don't perform finalization steps involving\n           async code.\n\n02/08/2017 New Kernel.run() method implementation.  It should be backwards\n           compatible, but there are two new ways of using it:\n\n               kernel = Kernel()\n               ...\n               # Run a coroutine with a timeout/deadline applied to it\n               try:\n                   result = kernel.run(coro, timeout=secs)\n               except TaskTimeout:\n                   print('Timed out')\n\n               # Run all daemonic tasks through a single scheduling cycle\n               # with no blocking\n               kernel.run()\n\n               # Run all daemonic tasks through a cycle, but specify a\n               # timeout on internal blocking\n               kernel.run(timeout=secs)\n                \n02/06/2017 New aside() function for launching a Curio task in an\n           independent process.  For example:\n\n           async def child(name, n):\n               print('Hello from', name)\n               for i in range(n):\n                   print('name says', i)\n                   await sleep(1)\n\n           async def main():\n               t = await aside(child, 'Spam', 10)   # Runs in subprocess\n               await t.join()\n\n           run(main())\n\n           In a nutshell, aside(coro, *args, **kwargs) creates a clean\n           Python interpreter and invokes curio.run(coro(*args,\n           **kwargs)) on the supplied coroutine.  The return value of\n           aside() is a Task object.  Joining with it returns the\n           child exit code (normally 0).  Cancelling it causes a\n           TaskCancelled exception to be raised in the child.\n\n           aside() does not involve a process fork or pipe. There\n           is no underlying communication between the child and parent\n           process.  If you want communication, use a Channel object \n           or set up some other kind of networking.\n      \n02/06/2017 Some improvements to message passing and launching tasks in\n           subprocesses.  A new Channel object makes it easy\n           to establish message passing between two different interpreters.\n           For example, here is a producer program:\n\n           # producer.py\n           from curio import Channel, run\n\n           async def producer(ch):\n               while True:\n                   c = await ch.accept(authkey=b'peekaboo')\n                   for i in range(10):\n                       await c.send(i)\n                   await c.send(None)   # Sentinel\n\n           if __name__ == '__main__':\n               ch = Channel(('localhost', 30000))\n               run(producer(ch))\n\n           Here is a consumer program::\n\n           # consumer.py\n           from curio import Channel, run\n\n           async def consumer(ch):\n               c = await ch.connect(authkey=b'peekaboo')\n               while True:\n                   msg = await c.recv()\n                   if msg is None:\n                      break\n                   print('Got:', msg)\n\n           if __name__ == '__main__':\n              ch = Channel(('localhost', 30000))\n              run(consumer(ch))\n\n           A Channel is a lot like a socket except that it sends discrete\n           messages.   Any picklable Python compatible object can be\n           passed.\n\n02/03/2017 Fixed a few regressions in SSL sockets and the Kernel.run() method.\n\nVersion 0.5 : February 2, 2017\n------------------------------\n\n01/08/2017 Some refinements to the abide() function.   You can now have it\n           reserve a dedicated thread.  This allows it to work with things\n           like Condition variables.   For example::\n\n               cond = threading.Condition()    # Foreign condition variable\n\n               ...\n               async with abide(code, reserve_thread=True) as c:\n                   # c is an async-wrapper around (code)\n                   # The following operation uses the same thread that was\n                   # used to acquire the lock.\n                   await c.wait()             \n               ...\n\n           abide() also prefers to use the block_in_thread() function that\n           makes it much more efficient when synchronizing with basic locks\n           and events.\n \n01/08/2017 Some reworking of internals related to thread/process workers and \n           task cancellation. One issue with launching work into a thread\n           worker is that threads have no mechanism for cancellation.  They\n           run fully to completion no matter what.  Thus, if you perform some\n           work like this:\n\n                await run_in_thread(callable, args)\n\n           and the calling task gets cancelled, it's impossible to find out\n           what happened with the thread.  Basically, it's lost to the sands\n           of time.   However, you can now supply an optional call_on_cancel\n           argument to the function and use it like this:\n\n                def cancelled_result(future):\n                    result = future.result()\n                    ...\n                    \n                await run_in_thread(callable, args, call_on_cancel=cancelled_result)\n\n           The call_on_cancel function is a normal synchronous\n           function. It receives the Future instance that was being used\n           to receive the result of the threaded operation.  This\n           Future is guaranteed to have the result/exception set.\n\n           Be aware that there is no way to know when the call_on_cancel \n           function might be triggered.  It might be far in the future.\n           The Curio kernel might not even be running.   Thus, it's \n           generally not safe to make too many assumptions about it.\n           The only guarantee is that the call_on_cancel function is\n           called after a result is computed and it's called in the\n           same thread.\n\n           The main purpose of this feature is to have better support\n           for cleanup of failed synchronization operations involving\n           threads.\n\n01/06/2017 New function.  block_in_thread().   This works like run_in_thread()\n           except that it's used with the expectation that whatever operation\n           is being performed is likely going to block for an undetermined\n           time period.  The underlying operation is handled more efficiently.\n           For each unique callable, there is at most 1 background thread\n           being used regardless of how many tasks might be trying to\n           perform the same operation.  For example, suppose you were\n           trying to synchronize with a foreign queue:\n\n               import queue\n               \n               work_q = queue.Queue()     # Standard thread queue\n\n               async def worker():\n                   while True:\n                       item = await block_in_thread(work_q.get)\n                       ...\n\n               # Spin up a huge number of workers\n               for n in range(1000):\n                   await spawn(worker())\n\n           In this code, there is one queue and 1000 worker tasks trying to\n           read items.  The block_in_thread() function only uses 1 background\n           thread to handle it.   If you used run_in_thread() instead, it\n           consume all available worker threads and you'd probably deadlock.\n\n01/05/2017 Experimental new feature--asynchronous threads!  An async thread\n           is an actual real-life thread where it is safe to call Curio\n           coroutines and use its various synchronization features. \n           As an example, suppose you had some code like this:\n\n               async def handler(client, addr):\n                   async with client:\n                       async for data in client.as_stream():\n                           n = int(data)\n                           time.sleep(n)\n                           await client.sendall(b'Awake!\\n')\n                   print('Connection closed')\n\n               run(tcp_server('', 25000, handler))\n\n           Imagine that the time.sleep() function represents some kind of\n           synchronous, blocking operation.  In the above code, it would\n           block the Curio kernel, prevents all other tasks from running.\n\n           Not a problem, change the handler() function to an async thread\n           and use the await() function like this:\n\n               from curio.thread import await, async_thread\n\n               @async_thread\n               def handler(client, addr):\n                   with client:\n                       for data in client.as_stream():\n                           n = int(data)\n                           time.sleep(n)\n                           await(client.sendall(b'Awake!\\n'))\n                   print('Connection closed')\n\n              run(tcp_server('', 25000, handler))\n\n\n           You'll find that the above code works fine and doesn't block\n           the kernel.\n\n           Asynchronous threads only work in the context of Curio.  They\n           may use all of Curio's features.  Everywhere you would normally\n           use await, you use the await() function. with and for statements\n           will work with objects supporting asynchronous operation. \n\n01/04/2017 Modified enable_cancellation() and disable_cancellation() so that\n           they can also be used as functions.  This makes it easier to\n           shield a single operation. For example:\n\n              await disable_cancellation(coro())\n\n           Functionally, it is the same as this:\n\n              async with disable_cancellation():\n                  await coro()\n\n           This is mostly a convenience feature.  \n\n01/04/2017 Two tasks that attempt to wait on the same file descriptor\n           now results in an exception.  Closes issue #104.\n\n01/04/2017 Modified the monitor so that killing the Curio process also\n           kills the monitor thread and disconnects any connected clients.\n           Addresses issue #108.\n\n01/04/2017 Modified task.cancel() so that it also cancels any pending\n           timeout. This prevents the delivery of a timeout exception\n           (if any) in code that might be executing to cleanup from\n           task cancellation.\n\n01/03/2017 Added a TaskCancelled exception.  This is now what gets \n           raised when tasks are cancelled using the task.cancel()\n           method.  It is a subclass of CancelledError.   This change \n           makes CancelledError more of an abstract exception class\n           for cancellation.  The TaskCancelled, TaskTimeout, and \n           TimeoutCancellationError exceptions are more specific\n           subclasses that indicates exactly what has happened.\n\n01/02/2017 Major reorganization of how task cancellation works. There\n           are two major parts to it.\n\n           Kernel:\n\n           Every task has a boolean flag \"task.allow_cancel\" that\n           determines whether or not cancellation exceptions (which\n           includes cancellation and timeouts) can be raised in the\n           task or not.  The flag acts as a simple mask. If set True,\n           a cancellation results in an exception being raised in the\n           task.  If set False, the cancellation-related exception is\n           placed into \"task.cancel_pending\" instead.  That attribute\n           holds onto the exception indefinitely, waiting for the task\n           to re-enable cancellations.  Once re-enabled, the exception\n           is raised immediately the next time the task performs a \n           blocking operation.\n\n           Coroutines:\n\n           From coroutines, control of the cancellation flag is\n           performed by two functions which are used as context\n           managers:\n\n           To disable cancellation, use the following construct:\n\n               async def coro():\n                   async with disable_cancellation():\n                       ...\n                       await something1()\n                       await something2()\n                       ...\n\n                   await blocking_op()   # Cancellation raised here (if any)\n           \n           Within a disable_cancellation() block, it is illegal for\n           a CancelledError exception to be raised--even manually. Doing\n           so causes a RuntimeError.  \n\n           To re-enable cancellation in specific regions of code, use\n           enable_cancellation() like this:\n\n               async def coro():\n                   async with disable_cancellation():\n                       while True:\n                           await something1()\n                           await something2()\n                           async with enable_cancellation() as c:\n                               await blocking_op()\n\n                           if c.cancel_pending:\n                               # Cancellation is pending right now. Must bail out.\n                               break\n\n                   await blocking_op()   # Cancellation raised here (if any)\n\n           Use of enable_cancellation() is never allowed outside of an\n           enclosing disable_cancellation() block.  Doing so will\n           cause a RuntimeError exception. Within an\n           enable_cancellation() block, all of the normal cancellation\n           rules apply.  This includes raising of exceptions,\n           timeouts, and so forth.  However, CancelledError exceptions\n           will never escape the block.  Instead, they turn back into\n           a pending exception which can be checked as shown above.\n\n           Normally cancellations are only delivered on blocking operations.\n           If you want to force a check, you can use check_cancellation()\n           like this:\n\n                if await check_cancellation():\n                    # Cancellation is pending, but not allowed right now\n                    ...\n\n           Depending on the setting of the allow_cancel flag, \n           check_cancellation() will either raise the cancellation \n           exception immediately or report that it is pending.\n           \n12/27/2016 Modified timeout_after(None) so that it leaves any prior timeout\n           setting in place (if any).  However, if a timeout occurs, it\n           will appear as a TimeoutCancellationError instead of the usual\n           TaskTimeout exception.  This is subtle, but it means that the\n           timeout occurred to due to an outer timeout setting.   This\n           change makes it easier to write functions that accept optional\n           timeout settings.  For example:\n\n              async def func(args, timeout=None):\n                  try:\n                      async with timeout_after(timeout):\n                          statements\n                          ...\n                  except TaskTimeout as e:\n                       # Timeout specifically due to timeout setting supplied\n                       ...\n                  except CancelledError as e:\n                       # Function cancelled for some other reason\n                       # (possibly an outer timeout)\n                       ...\n           \n12/23/2016 Added further information to cancellation/timeout exceptions\n           where partial I/O may have been performed. For readall() and\n           read_exactly() methods, the bytes_read attribute contains\n           all data read so far.  The readlines() method attaches a \n           lines_read attribute.  For write() and writelines(), a bytes_written\n           attribute is added to the exception.   For example:\n\n               try:\n                  data = timeout_after(5, s.readall())\n               except TimeoutError as e:\n                  data = e.bytes_read     # Data received prior to timeout\n\n           Here is a sending example:\n\n               try:\n                   timeout_after(5, s.write(data))\n               except TimeoutError as e:\n                   nwritten = e.bytes_written\n\n           The primary purpose of these attributes is to allow more\n           robust recovery in the event of cancellation. \n\n12/23/2016 The timeout arguments to subprocess related functions have been\n           removed.  Use the curio timeout_after() function instead to deal\n           with this case.  For example:\n\n               try:\n                   out = timeout_after(5, subprocess.check_output(args))\n               except TaskTimeout as e:\n                   # Get the partially read output\n                   partial_stdout = e.stdout\n                   partial_stderr = e.stderr\n                   ... other recovery ...\n\n           If there is an exception, the stdout and stderr\n           attributes contain any partially read data on standard output\n           and standard error.  These attributes mirror those present\n           on the CalledProcessError exception raised if there is an error.\n\n12/03/2016 Added a parentid attribute to Task instances so you can find parent\n           tasks.   Nothing else is done with this internally.\n\n12/03/2016 Withdrew the pdb and crash_handler arguments to Kernel() and the\n           run() function.  Added a pdb() method to tasks that can be used\n           to enter the debugger on a crashed task.  High-level handling\n           of crashed/terminated tasks is being rethought.   The old\n           crash_handler() callback was next to useless since no useful\n           actions could be performed (i.e., there was no ability to respawn\n           tasks or execute any kind of coroutine in response to a crash).\n\n11/05/2016 Pulled time related functionality into the kernel as a new call.\n           Use the following to get the current value of the kernel clock:\n            \n                await curio.clock()\n\n           Timeout related functions such as timeout_after() and ignore_after()\n           now rely on the kernel clock instead of using time.monotonic().\n           This changes consolidates all use of the clock into one place\n           and makes it easier (later) to reconfigure timing should it be\n           desired.  For example, perhaps changing the scale of the clock\n           to slow down or speed up time handling (for debugging, testing, etc.)\n\n10/29/2016 If the sendall() method of a socket is aborted with a CancelledError,\n           the resulting exception object now gets a bytes_sent attribute set to\n           indicate how much progress was made.   For example:\n\n           try:\n               await sock.sendall(data)\n           except CancelledError as e:\n               print(e.bytes_sent, 'bytes sent')\n\n10/29/2016 Added timeout_at() and ignore_at() functions that allow timeouts\n           to be specified at absolute clock values.  The usage is the\n           same as for timeout_after() and ignore_after().\n           \n10/29/2016 Modified TaskTimeout exception so that it subclasses CancelledError.\n           This makes it easier to write code that handles any kind of \n           cancellation (explicit cancellation, cancellation by timeout, etc.)\n\n10/17/2016 Added shutdown() method to sockets.  It is an async function\n           to mirror async implementation of close()\n\n           await sock.shutdown(how)\n\n10/17/2016 Added writeable() method to sockets.  It can be used to\n           quickly test if a socket will accept more data before\n           doing a send().  See Issue #83.\n\n           await sock.writeable()\n           nsent = await sock.send(data)\n\n10/17/2016 More precisely defined the semantics of nested timeouts\n           and exception handling.  Consider the following arrangement\n           of timeout blocks:\n\n           # B1\n           async with timeout_after(time1):\n                # B2\n                async with timeout_after(time2):\n                    await coro()\n\n           Here are the rules:\n\n           1. If time2 expires before time1, then block B2 receives\n              a TaskTimeout exception.\n\n           2. If time1 expires before time2, then block B2 receives\n              a TimeoutCancellationError exception and block B1\n              receives a TaskTimeout exception.  This reflects the\n              fact that the inner timeout didn't actually occur\n              and thus it shouldn't be reported as such.  The inner\n              block is still cancelled however in order to satisfy\n              the outer timeout.\n\n           3. If time2 expires before time1 and the resulting\n              TaskTimeout is NOT caught, but allowed to propagate out\n              to B1, then block B1 receives an UncaughtTimeoutError\n              exception.  A block should never report a TaskTimeout\n              unless its specified time interval has actually expired.\n              Reporting a timeout early because of an uncaught \n              exception in an inner block should be considered to be\n              an operational error. This exception reflects that.\n\n           4. If time1 and time2 both expire simultaneously, the\n              outer timeout takes precedence and time1 is considered\n              to have expired first.\n\n           See Issue #82 for further details about the rationale for\n           this change. https://github.com/dabeaz/curio/issues/82\n           \n           \n08/16/2016 Modified the Queue class so that the put() method can be used from either\n           synchronous or asynchronous code.  For example:\n\n              from curio import Queue\n              queue = Queue()\n\n              def spam():\n                  # Create some item\n                  ...\n                  queue.put(item)\n\n              async def consumer():\n                  while True:\n                       item = await queue.get()\n                       # Consume the item\n                       ...\n\n              async def coro():\n                    ...\n                    spam()       # Note: Normal synchronous function call\n                    ...\n\n              async def main():\n                  await spawn(coro())\n                  await spawn(consumer())\n\n              run(main())\n\n           The main purpose of adding this is to make it easier for normal\n           synchronous code to communicate to async tasks without knowing\n           too much about what they are.  Note:  The put() method is never\n           allowed to block in synchronous mode.  If the queue has a bounded\n           size and it fills up, an exception is raised.\n\n08/16/2016 Modified the Event class so that events can also be set from synchronous\n           code.  For example:\n\n               from curio import Event\n               evt = Event()\n\n               async def coro():\n                   print('Waiting for something')\n                   await evt.wait()\n                   print('It happened')\n\n               # A normal synchronous function. No async/await here.\n               def spam():\n                   print('About to signal')\n                   evt.set()\n\n               async def main():\n                   await spawn(coro())\n                   await sleep(5)\n                   spam()         # Note: Normal synchronous function call\n\n               run(main())\n\n           The main motivation for adding this is that is very easy for\n           control flow to escape the world of \"async/await\".  However,\n           that code may still want to signal or coordinate with async\n           tasks in some way.   By allowing a synchronous set(), it\n           makes it possible to do this.    It should be noted that within\n           a coroutine, you have to use await when triggering an event.\n           For example:\n\n               evt = Event()\n\n               def foo():\n                   evt.set()           # Synchronous use\n\n               async def bar():\n                   await evt.set()     # Asynchronous use\n\n08/04/2016 Added a new KernelExit exception that can be used to \n           make the kernel terminate execution.  For example:\n\n              async def coro():\n                  ...\n                  if something_bad:\n                      raise KernelExit('Something bad')\n\n           This causes the kernel to simply stop, aborting the\n           currently executing task.   The exception will propagate\n           out of the run() function so if you need to catch it, do\n           this:\n\n               try:\n                   run(coro())\n               except KernelExit as e:\n                   print('Going away because of:', e)\n\n           KernelExit by itself does not do anything to other \n           running tasks.  However, the run() function will\n           separately issue a shutdown request causing all\n           remaining tasks to cancel.\n\n08/04/2016 Added a new TaskExit exception that can be used to make a \n           single task terminate.  For example:\n\n               async def coro():\n                   ...\n                   if something_bad:\n                       raise TaskExit('Goodbye')\n                   ...\n\n           Think of TaskExit as a kind of self-cancellation. \n\n08/04/2016 Some refinements to kernel shutdown.   The shutdown process is\n           more carefully supervised and fixes a few very subtle errors\n           related to task scheduling. \n\n07/22/2016 Added support for asynchronous access to files as might be\n           opened by the builtin open() function.  Use the new aopen()\n           function with an async-context manager like this:\n\n             async with aopen(filename, 'r') as f:\n                 data = await f.read()\n\n           Note: a file opened in this manner provides an asynchronous API\n           that will prevent the Curio kernel from blocking on things\n           like disk seeks.  However, the underlying implementation is\n           not specified.  In the initial version, thread pools are\n           used to carry out each I/O operation.\n           \n07/18/2016 Some changes to Kernel cleanup and resource management.  The\n           proper way to shut down the kernel is to use Kernel.run(shutdown=True).\n           Alternatively, the kernel can now been used as a context manager:\n\n             with Kernel() as kern:\n                  kern.run(coro())\n\n           Note: The plain run() method properly shuts down the Kernel\n           if you're only running a single coroutine.\n\n           The Kernel.__del__() method now raises an exception if the\n           kernel is deleted without being properly shut down. \n\n06/30/2016 Added alpn_protocols keyword argument to open_connection()\n           function to make it easier to use TLS ALPN with clients.  For \n           example to open a connection and have it negotiate HTTP/2 \n           or HTTP/1.1 as a protocol, you can do this:\n\n           sock = await open_connection(host, port, ssl=True, \n                                        server_hostname=host,\n                                        alpn_protocols=['h2', 'http/1.1'])\n\n           print('selected protocol:', sock.selected_alpn_protocol())\n\n06/30/2016 Changed internal clock handling to use absolute values of\n           the monotonic clock.  New wakeat() function utilizes this\n           to allow more controlled sleeping for periodic timers\n           and other applications.  For example, here is a loop that\n           precisely wakes up on a specified time interval:\n\n           import time\n           from curio import wakeat\n\n           async def pulse(interval):\n               next_wake = time.monotonic()\n               while True:\n                    await wake_at(next_wake)\n                    print('Tick', time.asctime())\n                    next_wake += interval\n                \n06/16/2016 Fixed Issue #55.  Exceptions occurring in code executed by\n           run_in_process() now include a RemoteTraceback exception \n           that shows the traceback from the remote process. This\n           should make debugging a big easier. \n\n06/11/2016 Fixed Issue #53.  curio.run() was swallowing all exceptions.  It now\n           reports a TaskError exception if the given coroutine fails.  This is\n           a chained exception where __cause__ contains the actual cause of\n           failure.   This is meant to be consistent with the join() method \n           of Tasks.\n\n06/09/2016 Experimental new wait() function added.  It can be used to wait for\n           more than one task at a time and to return them in completion order.\n           For example:\n\n           task1 = await spawn(coro())\n           task2 = await spawn(coro())\n           task3 = await spawn(coro())\n\n           # Get results from all tasks as they complete\n           async for task in wait([task1, task2, task3]):\n               result = await task.join()\n\n           # Get the first result and cancel remaining tasks\n           async with wait([task1, task2, task3]) as w:\n               task = await w.next_done()\n               result = await task.join()\n               # Other tasks cancelled here\n\n06/09/2016 Refined the behavior of timeouts.  First, a timeout is not allowed\n           to extend the time expiration of a previously set timeout. For\n           example, if code previously set a 5 second timeout, an attempt\n           to now set a 10 second timeout still results in a 5 second timeout.\n           Second, when restoring a previous timeout, if the timeout period has\n           expired, Curio arranges for a TaskTimeout exception to be raised on\n           the next blocking call.   Without this, it's too easy for timeouts\n           to disappear or not have any effect.   Setting a timeout of None\n           disables timeouts regardless of any prior setting.\n\n06/07/2016 Changed trap names (e.g., '_trap_io') to int enums. This is\n           low-level change that shouldn't affect existing code.\n\n05/23/2016 Fixed Issue #52 (Problem with ignore_after context manager).\n           There was a possibility that a task would be marked for\n           timeout at precisely the same time some other operation had\n           completed and the task was sitting on the ready queue. To fix,\n           the timeout is deferred and retried the next time the kernel\n           blocks. \n\n05/20/2016 Added asyncobject class to curio/meta.py.  This allows you\n           to write classes with an asynchronous __init__ method. For example:\n\n           from curio.meta import asyncobject\n           class Spam(asyncobject):\n               async def __init__(self):\n                   ...\n                   self.value = await coro()\n                   ...\n\n           Instances can only be created via await.  For example:\n\n              s = await Spam()\n\n05/15/2016 Fixed Issue #50. Undefined variable n in io.py \n           Reported by Wolfgang Langner\n\nVersion 0.4 : May 13, 2016\n--------------------------\n05/13/2016 Fixed a subtle bug with futures/cancellation.\n\nVersion 0.3 : May 13, 2016\n--------------------------\n05/13/2016 Bug fixes to the run_in_process() and run_in_thread() \n           functions so that exceptions are reported properly.\n           Also fixed logic bug on related to kernel task initialization.\n\n05/13/2016 Modification to the abide() function to allow it to work\n           with RLocks from the threading module.  One caveat: Such\n           locks are NOT reentrant from within curio itself. \n\nVersion 0.2 : May 11, 2016\n--------------------------\n05/05/2016 Refactoring of stream I/O classes. There is now FileStream\n           and SocketStream.   The old Stream class is gone.\n\n04/30/2016 The run_blocking() and run_cpu_bound() calls are now\n           called run_in_thread() and run_in_process().\n\n04/23/2016 Changed the new_task() function to spawn().\n\n04/22/2016 Removed parent/child task relationship and associated\n           tracking.  It's an added complexity that's not really\n           needed in the kernel and it can be done easily enough by\n           the user in cases where it might be needed.\n\n04/18/2016 Major refactoring of timeout handling.  Virtually all\n           operations in curio support cancellation and timeouts.\n           However, putting an explicit \"timeout\" argument on\n           every API function/method greatly complicates the \n           underlying implementation (and introduces performance\n           overhead in cases where timeouts aren't used). To\n           put a timeout on an operation, use the timeout_after()\n           function instead.  For example:\n\n               await timeout_after(5, sock.recv(1024))\n\n           This will cause a timeout to be raised after the\n           specified time interval.  \n\n04/01/2016 Improved management of the I/O selector.  The number of\n           register/unregister operations are reduced for tasks \n           that constantly perform I/O on the same resources.  This\n           could offer a nice performance boost in certain cases.\n\n03/31/2016 Switched test suite to py.test. All of the tests are in the\n           top-level tests directory.  Use 'python3 -m pytest' to test.\n\n03/30/2016 Improved the curio monitor.  Instead of relying on the\n           console TTY (and invoked via Ctrl-C), it now uses a socket\n           to which you must connect via a different session. To\n           enable the monitor either use:\n\n               kernel = Kernel(with_monitor=True)\n\n           or run with an environment variable\n\n               env CURIOMONITOR=TRUE python3 yourprogram.py\n\n           To connect to the monitor, use the following command:\n\n               python3 -m curio.monitor\n          \n02/15/2016 Fixed Issue #37 where scheduling multiple tasks for sleeping\n           could potentially cause a crash in rare circumstances.\n\nVersion 0.1 : October 31, 2015\n------------------------------\nInitial version\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.306640625,
          "content": "Contributing to Curio\n=====================\n\nAlthough Curio is made available as open-source software, it is not\ndeveloped as a community project.  Thus, pull requests are not\naccepted except by invitation. However, if you have found a bug, a\ntypo, or have an idea for improvement, please submit an issue instead.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4833984375,
          "content": "Curio\n\nCopyright (C) 2015-2020\nDavid Beazley (Dabeaz LLC, https://www.dabeaz.com)\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are\nmet:\n\n* Redistributions of source code must retain the above copyright notice,\n  this list of conditions and the following disclaimer.  \n* Redistributions in binary form must reproduce the above copyright notice, \n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.  \n* Neither the name of the David Beazley or Dabeaz LLC may be used to\n  endorse or promote products derived from this software without\n  specific prior written permission. \n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.1923828125,
          "content": "recursive-include examples *\nrecursive-include docs *\nrecursive-include tests *\nrecursive-exclude __pycache__ *.pyc *.pyo\ninclude README.rst\ninclude LICENSE\ninclude CHANGES\ninclude CONTRIBUTING.md\n"
        },
        {
          "name": "README.rst",
          "type": "blob",
          "size": 7.935546875,
          "content": "Curio\n=====\n\nCurio is a coroutine-based library for concurrent Python systems\nprogramming using async/await.  It provides standard programming\nabstractions such as tasks, sockets, files, locks, and queues as\nwell as some advanced features such as support for structured\nconcurrency. It works on Unix and Windows and has zero dependencies.\nYou'll find it to be familiar, small, fast, and fun.\n\nImportant Notice: October 25, 2022\n----------------------------------\nThe Curio project is no longer making package releases.  I'm more than\nhappy to accept bug reports and may continue to work on it from time\nto time as the mood strikes.  If you want the absolute latest version, you\nshould vendor the source code from here. Curio has no dependencies\nother than the Python standard library.  --Dave\n\nCurio is Different\n------------------\nOne of the most important ideas from software architecture is the\n\"separation of concerns.\"  This can take many forms such as utilizing\nabstraction layers, object oriented programming, aspects, higher-order\nfunctions, and so forth.  However, another effective form of it exists\nin the idea of separating execution environments.  For example, \"user\nmode\" versus \"kernel mode\" in operating systems.  This is the\nunderlying idea in Curio, but applied to \"asynchronous\" versus\n\"synchronous\" execution.\n\nA fundamental problem with asynchronous code is that it involves a\ncompletely different evaluation model that doesn't compose well with\nordinary applications or with other approaches to concurrency such as\nthread programing.  Although the addition of \"async/await\" to Python\nhelps clarify such code, \"async\" libraries still tend to be a confused\nmess of functionality that mix asynchronous and synchronous\nfunctionality together in the same environment--often bolting it all\ntogether with an assortment of hacks that try to sort out all of\nassociated API confusion.\n\nCurio strictly separates asynchronous code from synchronous code.\nSpecifically, *all* functionality related to the asynchronous\nenvironment utilizes \"async/await\" features and syntax--without\nexception.  Moreover, interactions between async and sync code is\ncarefully managed through a small set of simple mechanisms such as\nevents and queues.  As a result, Curio is small, fast, and\nsignificantly easier to reason about.\n\nA Simple Example\n-----------------\n\nHere is a concurrent TCP echo server directly implemented using sockets:\n\n.. code:: python\n\n    # echoserv.py\n    \n    from curio import run, spawn\n    from curio.socket import *\n    \n    async def echo_server(address):\n        sock = socket(AF_INET, SOCK_STREAM)\n        sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)\n        sock.bind(address)\n        sock.listen(5)\n        print('Server listening at', address)\n        async with sock:\n            while True:\n                client, addr = await sock.accept()\n                await spawn(echo_client, client, addr, daemon=True)\n    \n    async def echo_client(client, addr):\n        print('Connection from', addr)\n        async with client:\n             while True:\n                 data = await client.recv(100000)\n                 if not data:\n                     break\n                 await client.sendall(data)\n        print('Connection closed')\n\n    if __name__ == '__main__':\n        run(echo_server, ('',25000))\n\nIf you've done network programming with threads, it looks almost\nidentical. Moreover, it can handle thousands of clients even though no\nthreads are being used inside.\n\nCore Features\n-------------\n\nCurio supports standard synchronization primitives (events, locks,\nrecursive locks, semaphores, and condition variables), queues,\nsubprocesses, as well as running tasks in threads and processes.  The\ntask model fully supports cancellation, task groups, timeouts,\nmonitoring, and other features critical to writing reliable code.\n\nRead the `official documentation <https://curio.readthedocs.io>`_ for\nmore in-depth coverage.  The `tutorial\n<https://curio.readthedocs.io/en/latest/tutorial.html>`_ is a good\nstarting point.  The `howto\n<https://curio.readthedocs.io/en/latest/howto.html>`_ describes how to\ncarry out common programming tasks.\n\nTalks Related to Curio\n----------------------\n\nConcepts related to Curio's design and general issues related to async\nprogramming have been described by Curio's creator, `David Beazley <https://www.dabeaz.com>`_, in\nvarious conference talks and tutorials:\n\n* `Build Your Own Async <https://www.youtube.com/watch?v=Y4Gt3Xjd7G8>`_, Workshop talk by David Beazley at PyCon India, 2019.\n\n* `The Other Async (Threads + Asyncio = Love) <https://www.youtube.com/watch?v=x1ndXuw7S0s>`_, Keynote talk by David Beazley at PyGotham, 2017.\n\n* `Fear and Awaiting in Async <https://www.youtube.com/watch?v=E-1Y4kSsAFc>`_, Keynote talk by David Beazley at PyOhio 2016.\n\n* `Topics of Interest (Async) <https://www.youtube.com/watch?v=ZzfHjytDceU>`_, Keynote talk by David Beazley at Python Brasil 2015.\n\n* `Python Concurrency from the Ground Up (LIVE) <https://www.youtube.com/watch?v=MCs5OvhV9S4>`_, talk by David Beazley at PyCon 2015.\n\nQuestions and Answers\n---------------------\n\n**Q: What is the point of the Curio project?**\n\nA: Curio is async programming, reimagined as something smaller, faster, and easier \nto reason about. It is meant to be both educational and practical.\n\n**Q: Is Curio implemented using asyncio?**\n\nA: No. Curio is a standalone library directly created from low-level I/O primitives.\n\n**Q: Is Curio meant to be a clone of asyncio?**\n\nA: No. Although Curio provides a significant amount of overlapping\nfunctionality, the API is different.  Compatibility with other\nlibaries is not a goal.\n\n**Q: Is Curio meant to be compatible with other async libraries?**\n\nA: No. Curio is a stand-alone project that emphasizes a certain\nsoftware architecture based on separation of environments.  Other\nlibraries have largely ignored this concept, preferring to simply\nprovide variations on the existing approach found in asyncio.\n\n**Q: Can Curio interoperate with other event loops?**\n\nA: It depends on what you mean by the word \"interoperate.\"  Curio's\npreferred mechanism of communication with the external world is a\nqueue.  It is possible to communicate between Curio, threads, and\nother event loops using queues.  \n\n**Q: How fast is Curio?**\n\nA: Curio's primary goal is to be an async library that is minimal and\nunderstandable. Performance is not the primary concern.  That said, in\nrough benchmarking of a simple echo server, Curio is more than twice\nas fast as comparable code using coroutines in ``asyncio`` or\n``trio``.  This was last measured on OS-X using Python 3.9.  Keep in\nmind there is a lot more to overall application performance than the\nperformance of a simple echo server so your mileage might\nvary. However, as a runtime environment, Curio doesn't introduce a lot of\nextra overhead. See the ``examples/benchmark`` directory for various\ntesting programs.\n\n**Q: What is the future of Curio?**\n\nA: Curio should be viewed as a library of basic programming\nprimitives.  At this time, it is considered to be\nfeature-complete--meaning that it is not expected to sprout many new\ncapabilities.  It may be updated from time to time to fix bugs or\nsupport new versions of Python.\n\n**Q: Can I contribute?**\n\nA: Curio is not a community-based project seeking developers\nor maintainers.  However, having it work reliably is important. If you've\nfound a bug or have an idea for making it better, please \nfile an `issue <https://github.com/dabeaz/curio>`_. \n\nContributors\n------------\n\nThe following people contributed ideas to early stages of the Curio project:\nBrett Cannon, Nathaniel Smith, Alexander Zhukov, Laura Dickinson, and Sandeep Gupta.\n\nWho\n---\nCurio is the creation of David Beazley (@dabeaz) who is also\nresponsible for its maintenance.  http://www.dabeaz.com\n\nP.S.\n----\nIf you want to learn more about concurrent programming more generally, you should\ncome take a `course <https://www.dabeaz.com/courses.html>`_!\n\n.. |--| unicode:: U+2013   .. en dash\n.. |---| unicode:: U+2014  .. em dash, trimming surrounding whitespace\n   :trim:\n\n\n\n"
        },
        {
          "name": "curio",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.32421875,
          "content": "[flake8]\nignore = E302,E402,F403,E265,E201,E124,E202,E123,E731\nmax-line-length = 120\nexclude = tests/*\nmax-complexity = 15\n\n[tool:pytest]\ntestpaths = tests\naddopts = --verbose\n          --ignore=setup.py --ignore=docs/conf.py\nmarkers =\n    internet: mark tests as requiring internet connectivity (deselect with '-m \"not internet\"')\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.107421875,
          "content": "try:\n    from setuptools import setup\nexcept ImportError:\n    from distutils.core import setup\n\ntests_require = ['pytest', 'Sphinx']\n\nlong_description = \"\"\"\nCurio is a coroutine-based library for concurrent systems programming.  No longer\nmaintained as a PyPi project.  Latest version is available on GitHub. \n\"\"\"\n\n\nsetup(name=\"curio\",\n      description=\"Curio\",\n      long_description=long_description,\n      license=\"BSD\",\n      version=\"1.6\",\n      author=\"David Beazley\",\n      author_email=\"dave@dabeaz.com\",\n      maintainer=\"David Beazley\",\n      maintainer_email=\"dave@dabeaz.com\",\n      url=\"https://github.com/dabeaz/curio\",\n      packages=['curio'],\n      tests_require=tests_require,\n      extras_require={\n          'test': tests_require,\n      },\n      python_requires='>= 3.7',\n      # This is disabled because it often causes interference with other testing\n      # plugins people have written.  Curio doesn't use it for it's own testing.\n      # entry_points={\"pytest11\": [\"curio = curio.pytest_plugin\"]},\n      classifiers=[\n          'Programming Language :: Python :: 3',\n          \"Framework :: Pytest\",\n      ])\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}