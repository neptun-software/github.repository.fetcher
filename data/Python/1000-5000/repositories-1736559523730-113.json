{
  "metadata": {
    "timestamp": 1736559523730,
    "page": 113,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "marqo-ai/marqo",
      "stars": 4714,
      "defaultBranch": "mainline",
      "files": [
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 1.8671875,
          "content": "#marqo assets\nassets/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\ntests/\nexamples/\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n.idea/\n\nlocal_only/\n\ntests/cache/\n\ncache/\nsrc/marqo/cache/\n\n__pycache__/\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 2.044921875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\nvenv*/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n.idea/\n\nlocal_only/\n\ntests/cache/\n\ncache/\n\n__pycache__/\n\n# throttling error logs\nsrc/marqo/tensor_search/test_throttle_timing.txt\nsrc/marqo/tensor_search/test_throttle_timing.csv\ndump.rdb\n\n# VSCode\n.vscode/\n\n.DS_Store\n\n# Tester app for unit tests\nscripts/vespa_local/vespa_tester_app.zip"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.1875,
          "content": "## Contributor Covenant Code of Conduct\n### Our Pledge\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n### Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or electronic address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a professional setting\n\n### Our Responsibilities\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n### Scope\nThis Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n### Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at support@marqo.ai . All complaints will be reviewed and investigated and will result in a response that  is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n### Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\nFor answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.833984375,
          "content": "Thank you for your interest in making tensor search more accessible!\n\n---\n\n## Ways to contribute\n\n### Bug reports\nYou can submit bug reports on our GitHub repo\n\n### Contributing code\nWe welcome contributions to the codebase. Here are some coding guidelines to follow:\n* Where possible, we explicitly state the arg names when calling a function. \n  This makes refactoring easier. If possible, use `func(a=1, b=2)` rather than `func(1, 2)`\n\n#### Error usage\n- Errors raised that concern non-user-facing functionality\n(for example, related to vectors), should raise an `InternalError` or its subclass\n- Errors arising from calls S2 Inference's API should raise an `S2InferenceError`    \n\n\n### Semantic Versioning\nWe use [semantic versioning](https://semver.org/). \n- We are in [major version 0 (0.x.x)](https://semver.org/#spec-item-4). Because of this, we may release major breaking changes by incrementing the minor version (0.2.4 -> 0.3.0) rather than the major version. \n- We do regular minor releases. These are releases that are additive and don't break existing functionality. These may additively extend the API. \nDuring a minor release we bump the patch number: 0.1.5 -> 0.1.6\n- In-between minor releases, we release bug-fixes and optimisations where we optionally bump the patch number: 0.2.12 -> 0.2.13\n- If there are any breaking changes, there will be a major release, recorded as incrementing the minor version: 0.2.4 -> 0.3.0\n- Once Marqo is in major version 1 (1.0.0), the public API will be considered 'defined' and Marqo's versioning will follow the typical semantic versioning pattern\n- If we are still in major version 0, and complexity and stability needs necessitates it, we can force all bug fixes and optimisations to increment the patch number\n  (rather than it being optional). In this case this section will be updated to reflect the change.\n\n\n### Releasing changes\n- Run unit tests and ensure they all pass (read the testing section below for more details)\n- Generate a pull request to the `mainline` branch. These will be reviewed before merging\n- After merging to `mainline`, please delete the branch with the pull request\n- A Github integration pipeline will run. After all tests pass, build a multiplatform docker image for the `linux/arm64` and `linux/amd64` platforms, pushing it to the\n`marqoai/marqo` repository. Make sure it is tagged with the version number (`-t marqoai/marqo:0.1.5`). If it is a pre-release intended for testing, also push it to the test tag (add `-t marqoai/marqo:test`). If it is a release, \nalso push it to the latest tag (add `-t marqoai/marqo:latest`). \n\n- For releases, please record changes in  `RELEASE.md`. Then create a \n[github release](https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository) \n(with a short summary of changes) that links to the changes in `RELEASE.md`.\n- For releases that change the API, update py-marqo to make those changes accessible. \n- To release a change to py-marqo, bump py-marqo's version (major.minor.patch, see below for more details), run all the tests, build the package and push it to PyPi. py-marqo's version is independent from Marqo.  \n\n- Then, use the following format for releasing changes:\n  - . # Release x.y.z \n    - small blurb about release\n  - . ## Breaking changes\n  - . ## Deprecations\n  - . ## Caveats \n    - adding/bumping of dependencies\n    - lack of platform support (for certain features)\n    - other (non-breaking) caveats to new features/fixes \n  - . ## New features\n    - Non-breaking changes\n  - . ##  Bug fixes \n  - . ### Testing\n  -  . ## Contributor shout outs\n\n### Testing\n\nWARNING: Be very careful if your environment has access to a Marqo production instance. These tests will arbitrarily modify, create and delete indices on the Marqo instances it uses for testing. \n\n\n__Tips__\n\nIf you don't have the exact python version specified in the `tox.ini` file, you can run tox like this: `tox -e py`. This tells `tox` to use whatever python version it finds on your machine.\n#### Unit tests\n\n1. Ensure you have marqo-os running:\n```bash\ndocker rm -f marqo-os\ndocker run -p 9200:9200 -p 9600:9600 -e \"discovery.type=single-node\" --name marqo-os marqoai/marqo-os:0.0.3\n```\n2. run `tox` in the Marqo home directory\n\n#### Integration  tests\nTo run integration tests, pull the [api testing repo](https://github.com/marqo-ai/marqo-api-tests). \nThen, follow the instructions in the [README](https://github.com/marqo-ai/marqo-api-tests#readme).\n\n\n#### Testing Marqo python client\nThe Python Marqo client has its own test suite. Clone [the repo](https://github.com/marqo-ai/py-marqo), `cd` into the client home directory and then run `tox`.\n\n\n### API, design principles \n\n- Separation between data and configuration \n- Usability is super important, unless it clashes with performance. In that case, performance takes precedence.\n- Easy things should be easy, hard things should be possible\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.02734375,
          "content": "# Stage 1: Build the Java package using Maven\nFROM maven:3.8.7-openjdk-18-slim as maven_build\n\nWORKDIR /app/vespa\nCOPY vespa .\nRUN mvn clean package\n\n# Stage 2: Base image for Python setup\nFROM marqoai/marqo-base:48 as base_image\n\n# Allow mounting volume containing data and configs for vespa\nVOLUME /opt/vespa/var\n# Allow mounting volume to expose vespa logs\nVOLUME /opt/vespa/logs\n# This is required when mounting var folder from an older version of vespa (>30 minor version gap)\n# See https://docs.vespa.ai/en/operations-selfhosted/live-upgrade.html for details\nENV VESPA_SKIP_UPGRADE_CHECK true\n\nARG TARGETPLATFORM\nARG COMMITHASH\nWORKDIR /app\n\n# Stage 3: Final stage that builds on the base image\nFROM base_image\n\nCOPY --from=maven_build /app/vespa/target/marqo-custom-searchers-deploy.jar /app/vespa/target/\nCOPY scripts/ /app/scripts\nCOPY run_marqo.sh /app/run_marqo.sh\nCOPY src /app/src\n\n\nENV PYTHONPATH \"${PYTHONPATH}:/app\"\nRUN chmod +x ./run_marqo.sh\nRUN echo $COMMITHASH > build_info.txt\nCMD [\"./run_marqo.sh\"]\nENTRYPOINT [\"./run_marqo.sh\"]\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 9.9130859375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        https://www.apache.org/licenses/\n\nTERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n1. Definitions.\n\n  \"License\" shall mean the terms and conditions for use, reproduction,\n  and distribution as defined by Sections 1 through 9 of this document.\n\n  \"Licensor\" shall mean the copyright owner or entity authorized by\n  the copyright owner that is granting the License.\n\n  \"Legal Entity\" shall mean the union of the acting entity and all\n  other entities that control, are controlled by, or are under common\n  control with that entity. For the purposes of this definition,\n  \"control\" means (i) the power, direct or indirect, to cause the\n  direction or management of such entity, whether by contract or\n  otherwise, or (ii) ownership of fifty percent (50%) or more of the\n  outstanding shares, or (iii) beneficial ownership of such entity.\n\n  \"You\" (or \"Your\") shall mean an individual or Legal Entity\n  exercising permissions granted by this License.\n\n  \"Source\" form shall mean the preferred form for making modifications,\n  including but not limited to software source code, documentation\n  source, and configuration files.\n\n  \"Object\" form shall mean any form resulting from mechanical\n  transformation or translation of a Source form, including but\n  not limited to compiled object code, generated documentation,\n  and conversions to other media types.\n\n  \"Work\" shall mean the work of authorship, whether in Source or\n  Object form, made available under the License, as indicated by a\n  copyright notice that is included in or attached to the work\n  (an example is provided in the Appendix below).\n\n  \"Derivative Works\" shall mean any work, whether in Source or Object\n  form, that is based on (or derived from) the Work and for which the\n  editorial revisions, annotations, elaborations, or other modifications\n  represent, as a whole, an original work of authorship. For the purposes\n  of this License, Derivative Works shall not include works that remain\n  separable from, or merely link (or bind by name) to the interfaces of,\n  the Work and Derivative Works thereof.\n\n  \"Contribution\" shall mean any work of authorship, including\n  the original version of the Work and any modifications or additions\n  to that Work or Derivative Works thereof, that is intentionally\n  submitted to Licensor for inclusion in the Work by the copyright owner\n  or by an individual or Legal Entity authorized to submit on behalf of\n  the copyright owner. For the purposes of this definition, \"submitted\"\n  means any form of electronic, verbal, or written communication sent\n  to the Licensor or its representatives, including but not limited to\n  communication on electronic mailing lists, source code control systems,\n  and issue tracking systems that are managed by, or on behalf of, the\n  Licensor for the purpose of discussing and improving the Work, but\n  excluding communication that is conspicuously marked or otherwise\n  designated in writing by the copyright owner as \"Not a Contribution.\"\n\n  \"Contributor\" shall mean Licensor and any individual or Legal Entity\n  on behalf of whom a Contribution has been received by Licensor and\n  subsequently incorporated within the Work.\n\n2. Grant of Copyright License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  copyright license to reproduce, prepare Derivative Works of,\n  publicly display, publicly perform, sublicense, and distribute the\n  Work and such Derivative Works in Source or Object form.\n\n3. Grant of Patent License. Subject to the terms and conditions of\n  this License, each Contributor hereby grants to You a perpetual,\n  worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n  (except as stated in this section) patent license to make, have made,\n  use, offer to sell, sell, import, and otherwise transfer the Work,\n  where such license applies only to those patent claims licensable\n  by such Contributor that are necessarily infringed by their\n  Contribution(s) alone or by combination of their Contribution(s)\n  with the Work to which such Contribution(s) was submitted. If You\n  institute patent litigation against any entity (including a\n  cross-claim or counterclaim in a lawsuit) alleging that the Work\n  or a Contribution incorporated within the Work constitutes direct\n  or contributory patent infringement, then any patent licenses\n  granted to You under this License for that Work shall terminate\n  as of the date such litigation is filed.\n\n4. Redistribution. You may reproduce and distribute copies of the\n  Work or Derivative Works thereof in any medium, with or without\n  modifications, and in Source or Object form, provided that You\n  meet the following conditions:\n\n  (a) You must give any other recipients of the Work or\n      Derivative Works a copy of this License; and\n\n  (b) You must cause any modified files to carry prominent notices\n      stating that You changed the files; and\n\n  (c) You must retain, in the Source form of any Derivative Works\n      that You distribute, all copyright, patent, trademark, and\n      attribution notices from the Source form of the Work,\n      excluding those notices that do not pertain to any part of\n      the Derivative Works; and\n\n  (d) If the Work includes a \"NOTICE\" text file as part of its\n      distribution, then any Derivative Works that You distribute must\n      include a readable copy of the attribution notices contained\n      within such NOTICE file, excluding those notices that do not\n      pertain to any part of the Derivative Works, in at least one\n      of the following places: within a NOTICE text file distributed\n      as part of the Derivative Works; within the Source form or\n      documentation, if provided along with the Derivative Works; or,\n      within a display generated by the Derivative Works, if and\n      wherever such third-party notices normally appear. The contents\n      of the NOTICE file are for informational purposes only and\n      do not modify the License. You may add Your own attribution\n      notices within Derivative Works that You distribute, alongside\n      or as an addendum to the NOTICE text from the Work, provided\n      that such additional attribution notices cannot be construed\n      as modifying the License.\n\n  You may add Your own copyright statement to Your modifications and\n  may provide additional or different license terms and conditions\n  for use, reproduction, or distribution of Your modifications, or\n  for any such Derivative Works as a whole, provided Your use,\n  reproduction, and distribution of the Work otherwise complies with\n  the conditions stated in this License.\n\n5. Submission of Contributions. Unless You explicitly state otherwise,\n  any Contribution intentionally submitted for inclusion in the Work\n  by You to the Licensor shall be under the terms and conditions of\n  this License, without any additional terms or conditions.\n  Notwithstanding the above, nothing herein shall supersede or modify\n  the terms of any separate license agreement you may have executed\n  with Licensor regarding such Contributions.\n\n6. Trademarks. This License does not grant permission to use the trade\n  names, trademarks, service marks, or product names of the Licensor,\n  except as required for reasonable and customary use in describing the\n  origin of the Work and reproducing the content of the NOTICE file.\n\n7. Disclaimer of Warranty. Unless required by applicable law or\n  agreed to in writing, Licensor provides the Work (and each\n  Contributor provides its Contributions) on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n  implied, including, without limitation, any warranties or conditions\n  of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n  PARTICULAR PURPOSE. You are solely responsible for determining the\n  appropriateness of using or redistributing the Work and assume any\n  risks associated with Your exercise of permissions under this License.\n\n8. Limitation of Liability. In no event and under no legal theory,\n  whether in tort (including negligence), contract, or otherwise,\n  unless required by applicable law (such as deliberate and grossly\n  negligent acts) or agreed to in writing, shall any Contributor be\n  liable to You for damages, including any direct, indirect, special,\n  incidental, or consequential damages of any character arising as a\n  result of this License or out of the use or inability to use the\n  Work (including but not limited to damages for loss of goodwill,\n  work stoppage, computer failure or malfunction, or any and all\n  other commercial damages or losses), even if such Contributor\n  has been advised of the possibility of such damages.\n\n9. Accepting Warranty or Additional Liability. While redistributing\n  the Work or Derivative Works thereof, You may choose to offer,\n  and charge a fee for, acceptance of support, warranty, indemnity,\n  or other liability obligations and/or rights consistent with this\n  License. However, in accepting such obligations, You may act only\n  on Your own behalf and on Your sole responsibility, not on behalf\n  of any other Contributor, and only if You agree to indemnify,\n  defend, and hold each Contributor harmless for any liability\n  incurred by, or claims asserted against, such Contributor by reason\n  of your accepting any such warranty or additional liability.\n\nEND OF TERMS AND CONDITIONS\n\nCopyright 2022 S2Search Ltd.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 22.1708984375,
          "content": "<p align=\"center\">\n<img src=\"https://github.com/marqo-ai/public-assets/blob/main/marqowbackground.png\" width=\"50%\" height=\"40%\">\n</p>\n\n<p align=\"center\">\n<b><a href=\"https://www.marqo.ai\">Website</a> | <a href=\"https://docs.marqo.ai\">Documentation</a> | <a href=\"https://demo.marqo.ai\">Demos</a> | <a href=\"https://community.marqo.ai\">Discourse</a>  | <a href=\"https://bit.ly/marqo-community-slack\">Slack Community</a> | <a href=\"https://www.marqo.ai/cloud\">Marqo Cloud</a>\n</b>\n</p>\n\n<p align=\"center\">\n<a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\"></a>\n<a href=\"https://pypi.org/project/marqo/\"><img src=\"https://img.shields.io/pypi/v/marqo?label=PyPI\"></a>\n<a href=\"https://github.com/marqo-ai/marqo/actions/workflows/unit_test_200gb_CI.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/marqo-ai/marqo/unit_test_200gb_CI.yml?branch=mainline\"></a>\n<a align=\"center\" href=\"https://bit.ly/marqo-community-slack\"><img src=\"https://img.shields.io/badge/Slack-blueviolet?logo=slack&amp;logoColor=white\"></a>\n\n## Marqo\n\nMarqo is more than a vector database, it's an end-to-end vector search engine for both text and images. Vector generation, storage and retrieval are handled out of the box through a single API. No need to bring your own embeddings. \n    \n**Why Marqo?**\n\nVector similarity alone is not enough for vector search. Vector search requires more than a vector database - it also requires machine learning (ML) deployment and management, preprocessing and transformations of inputs as well as the ability to modify search behavior without retraining a model. Marqo contains all these pieces, enabling developers to build vector search into their application with minimal effort. A full list of features can be found [below](#-core-features).\n\n**Why bundle embedding generation with vector search?** \n\nVector databases are specialized components for vector similarity and only service one component of a vector search system. They are “vectors in - vectors out”. They still require the production of vectors, management of the ML models, associated orchestration and processing of the inputs. Marqo makes this easy by being “documents in, documents out”. Preprocessing of text and images, embedding the content, storing meta-data and deployment of inference and storage is all taken care of by Marqo. \n\n**Quick start** \n\nHere is a code snippet for a minimal example of vector search with Marqo (see [Getting Started](#getting-started)):\n\n\n1. Marqo requires Docker. To install Docker go to the [Docker Official website](https://docs.docker.com/get-docker/). Ensure that docker has at least 8GB memory and 50GB storage. In Docker desktop, you can do this by clicking the settings icon, then resources, and selecting 8GB memory.\n\n2. Use docker to run Marqo:\n\n```bash\n\ndocker rm -f marqo\ndocker pull marqoai/marqo:latest\ndocker run --name marqo -it -p 8882:8882 marqoai/marqo:latest\n\n```\n\n3. Install the Marqo client:\n\n```bash\npip install marqo\n```\n\n4. Start indexing and searching! Let's look at a simple example below:\n\n```python\nimport marqo\n\nmq = marqo.Client(url='http://localhost:8882')\n\nmq.create_index(\"my-first-index\", model=\"hf/e5-base-v2\")\n\nmq.index(\"my-first-index\").add_documents([\n    {\n        \"Title\": \"The Travels of Marco Polo\",\n        \"Description\": \"A 13th-century travelogue describing Polo's travels\"\n    }, \n    {\n        \"Title\": \"Extravehicular Mobility Unit (EMU)\",\n        \"Description\": \"The EMU is a spacesuit that provides environmental protection, \"\n                       \"mobility, life support, and communications for astronauts\",\n        \"_id\": \"article_591\"\n    }],\n    tensor_fields=[\"Description\"]\n)\n\nresults = mq.index(\"my-first-index\").search(\n    q=\"What is the best outfit to wear on the moon?\"\n)\n\n```\n\n## ✨ Core Features\n\n**🤖 State of the art embeddings**\n- Use the latest machine learning models from PyTorch, Huggingface, OpenAI and more. \n- Start with a pre-configured model or bring your own.\n- CPU and GPU support.\n\n**⚡ Performance**\n- Embeddings stored in in-memory HNSW indexes, achieving cutting edge search speeds.\n- Scale to hundred-million document indexes with horizontal index sharding.\n- Async and non-blocking data upload and search.\n\n**🌌 Documents-in-documents-out**\n- Vector generation, storage, and retrieval are provided out of the box.\n- Build search, entity resolution, and data exploration application with using your text and images.\n- Build complex semantic queries by combining weighted search terms.\n- Filter search results using Marqo’s query DSL.\n- Store unstructured data and semi-structured metadata together in documents, using a range of supported datatypes like bools, ints and keywords.\n\n**🍱 Managed cloud**\n- Low latency optimised deployment of Marqo.\n- Scale inference at the click of a button.\n- High availability.\n- 24/7 support.\n- Access control.\n- Learn more [here](https://www.marqo.ai/cloud).\n\n## Integrations\n\nMarqo is integrated into popular AI and data processing frameworks, with more on the way.\n\n**💙 [Haystack](https://github.com/deepset-ai/haystack)**\n\nHaystack is an open-source framework for building applications that make use of NLP technology such as LLMs, embedding models and more. This [integration](https://haystack.deepset.ai/integrations/marqo-document-store) allows you to use Marqo as your Document Store for Haystack pipelines such as retrieval-augmentation, question answering, document search and more.\n\n**🛹 [Griptape](https://github.com/griptape-ai/griptape)**\n\nGriptape enables safe and reliable deployment of LLM-based agents for enterprise applications, the MarqoVectorStoreDriver gives these agents access to scalable search with your own data. This integration lets you leverage open source or custom fine-tuned models through Marqo to deliver relevant results to your LLMs.\n\n**🦜🔗 [Langchain](https://github.com/langchain-ai/langchain)**\n\nThis integration lets you leverage open source or custom fine tuned models through Marqo for LangChain applications with a vector search component. The Marqo vector store implementation can plug into existing chains such as the Retrieval QA and Conversational Retrieval QA.\n\n**⋙ [Hamilton](https://github.com/DAGWorks-Inc/hamilton/)**\n\nThis integration lets you leverage open source or custom fine tuned models through Marqo for Hamilton LLM applications. \n\n## Learn more about Marqo\n                                                                                                                                                       \n| | |\n| --------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| 📗 [Quick start](#Getting-started)| Build your first application with Marqo in under 5 minutes. |\n| 🖼 [Marqo for image data](https://www.marqo.ai/blog/context-is-all-you-need-multimodal-vector-search-with-personalization) | Building advanced image search with Marqo. |\n| 📚 [Marqo for text](https://www.marqo.ai/blog/how-i-used-marqo-to-create-a-multilingual-legal-databse-in-5-key-lines-of-code) | Building a multilingual database in Marqo. |\n| 🔮 [Integrating Marqo with GPT](https://www.marqo.ai/blog/from-iron-manual-to-ironman-augmenting-gpt-with-marqo-for-fast-editable-memory-to-enable-context-aware-question-answering) | Making GPT a subject matter expert by using Marqo as a knowledge base. |\n| 🎨 [ Marqo for Creative AI](https://www.marqo.ai/blog/combining-stable-diffusion-with-semantic-search-generating-and-categorising-100k-hot-dogs) | Combining stable diffusion with semantic search to generate and categorise 100k images of hotdogs. |\n| 🔊 [Marqo and Speech Data](https://www.marqo.ai/blog/speech-processing) | Add diarisation and transcription to preprocess audio for Q&A with Marqo and ChatGPT. |\n| 🚫 [Marqo for content moderation](https://www.marqo.ai/blog/refining-image-quality-and-eliminating-nsfw-content-with-marqo) | Building advanced image search with Marqo to find and remove content. |\n| ☁️ [Getting started with Marqo Cloud](https://github.com/marqo-ai/getting_started_marqo_cloud) | Go through how to get set up and running with Marqo Cloud starting from your first time login through to building your first application with Marqo|\n| 👗 [Marqo for e-commerce](https://github.com/marqo-ai/getting_started_marqo_cloud/blob/main/e-commerce-demo/README.md) | This project is a web application with frontend and backend using Python, Flask, ReactJS, and Typescript. The frontend is a ReactJS application that makes requests to the backend which is a Flask application. The backend makes requests to your Marqo cloud API.|\n| 🤖 [Marqo chatbot](https://github.com/marqo-ai/getting_started_marqo_cloud/tree/main/chatbot-demo) | In this guide we will build a chat bot application using Marqo and OpenAI's ChatGPT API. We will start with an existing code base and then walk through how to customise the behaviour.|\n| 🦾 [Features](#-Core-Features) | Marqo's core features. |\n\n\n\n\n## Getting started\n\n\n1. Marqo requires Docker. To install Docker go to the [Docker Official website](https://docs.docker.com/get-docker/). Ensure that docker has at least 8GB memory and 50GB storage.\n\n2. Use docker to run Marqo:\n\n```bash\ndocker rm -f marqo\ndocker pull marqoai/marqo:latest\ndocker run --name marqo -p 8882:8882 marqoai/marqo:latest\n```\n\nNote: If your `marqo` container keeps getting killed, this is most likely due to a lack of memory being allocated to Docker. Increasing the memory limit for Docker to at least 6GB (8GB recommended) in your Docker settings may fix the problem.\n\n3. Install the Marqo client:\n\n```bash\npip install marqo\n```\n\n4. Start indexing and searching! Let's look at a simple example below:\n\n```python\nimport marqo\n\nmq = marqo.Client(url='http://localhost:8882')\n\nmq.create_index(\"my-first-index\")\n\nmq.index(\"my-first-index\").add_documents([\n    {\n        \"Title\": \"The Travels of Marco Polo\",\n        \"Description\": \"A 13th-century travelogue describing Polo's travels\"\n    }, \n    {\n        \"Title\": \"Extravehicular Mobility Unit (EMU)\",\n        \"Description\": \"The EMU is a spacesuit that provides environmental protection, \"\n                       \"mobility, life support, and communications for astronauts\",\n        \"_id\": \"article_591\"\n    }],\n    tensor_fields=[\"Description\"]\n)\n\nresults = mq.index(\"my-first-index\").search(\n    q=\"What is the best outfit to wear on the moon?\"\n)\n```\n\n- `mq` is the client that wraps the `marqo` API.\n- `create_index()` creates a new index with default settings. You have the option to specify what model to use. For example, `mq.create_index(\"my-first-index\", model=\"hf/all_datasets_v4_MiniLM-L6\")` will create an index with the default text model `hf/all_datasets_v4_MiniLM-L6`. Experimentation with different models is often required to achieve the best retrieval for your specific use case. Different models also offer a tradeoff between inference speed and relevancy. See [here](https://docs.marqo.ai/1.0.0/Models-Reference/dense_retrieval/) for the full list of models.\n- `add_documents()` takes a list of documents, represented as python dicts for indexing. `tensor_fields` refers to the fields that will be indexed as vector collections and made searchable.\n- You can optionally set a document's ID with the special `_id` field. Otherwise, Marqo will generate one.\n\nLet's have a look at the results:\n\n```python\n# let's print out the results:\nimport pprint\npprint.pprint(results)\n\n{\n    'hits': [\n        {\n            'Title': 'Extravehicular Mobility Unit (EMU)',\n            'Description': 'The EMU is a spacesuit that provides environmental protection, mobility, life support, and'\n                           'communications for astronauts',\n            '_highlights': [{\n                'Description': 'The EMU is a spacesuit that provides environmental protection, '\n                               'mobility, life support, and communications for astronauts'\n            }],\n            '_id': 'article_591',\n            '_score': 0.61938936\n        },\n        {\n            'Title': 'The Travels of Marco Polo',\n            'Description': \"A 13th-century travelogue describing Polo's travels\",\n            '_highlights': [{'Title': 'The Travels of Marco Polo'}],\n            '_id': 'e00d1a8d-894c-41a1-8e3b-d8b2a8fce12a',\n            '_score': 0.60237324\n        }\n    ],\n    'limit': 10,\n    'processingTimeMs': 49,\n    'query': 'What is the best outfit to wear on the moon?'\n}\n```\n\n- Each hit corresponds to a document that matched the search query.\n- They are ordered from most to least matching.\n- `limit` is the maximum number of hits to be returned. This can be set as a parameter during search.\n- Each hit has a `_highlights` field. This was the part of the document that matched the query the best.\n\n## Other basic operations\n\n### Get document\n\nRetrieve a document by ID.\n\n```python\nresult = mq.index(\"my-first-index\").get_document(document_id=\"article_591\")\n```\n\nNote that by adding the document using ```add_documents``` again using the same ```_id``` will cause a document to be updated.\n\n### Get index stats\n\nGet information about an index.\n\n```python\nresults = mq.index(\"my-first-index\").get_stats()\n```\n\n### Lexical search\n\nPerform a keyword search.\n\n```python\nresult = mq.index(\"my-first-index\").search('marco polo', search_method=marqo.SearchMethods.LEXICAL)\n```\n\n### Multi modal and cross modal search\n\nTo power image and text search, Marqo allows users to plug and play with CLIP models from HuggingFace. **Note that if you do not configure multi modal search, image urls will be treated as strings.** To start indexing and searching with images, first create an index with a CLIP configuration, as below:\n\n```python\nsettings = {\n    \"treat_urls_and_pointers_as_images\":True,   # allows us to find an image file and index it \n    \"model\":\"ViT-L/14\"\n}\nresponse = mq.create_index(\"my-multimodal-index\", **settings)\n```\n\nImages can then be added within documents as follows. You can use urls from the internet (for example S3) or from the disk of the machine:\n\n```python\nresponse = mq.index(\"my-multimodal-index\").add_documents([{\n    \"My_Image\": \"https://raw.githubusercontent.com/marqo-ai/marqo-api-tests/mainline/assets/ai_hippo_realistic.png\",\n    \"Description\": \"The hippopotamus, also called the common hippopotamus or river hippopotamus, is a large semiaquatic mammal native to sub-Saharan Africa\",\n    \"_id\": \"hippo-facts\"\n}], tensor_fields=[\"My_Image\"])\n```\n\nYou can then search the image field using text.\n\n```python\nresults = mq.index(\"my-multimodal-index\").search('animal')\n```\n\n### Searching using an image\nSearching using an image can be achieved by providing the image link.\n\n```python\nresults = mq.index(\"my-multimodal-index\").search('https://raw.githubusercontent.com/marqo-ai/marqo-api-tests/mainline/assets/ai_hippo_statue.png')\n```\n\n### Searching using weights in queries\nQueries can also be provided as dictionaries where each key is a query and their corresponding values are weights. This allows for more advanced queries consisting of multiple components with weightings towards or against them, queries can have negations via negative weighting.\n\nThe example below shows the application of this to a scenario where a user may want to ask a question but also negate results that match a certain semantic criterion. \n\n```python\nimport marqo\nimport pprint\n\nmq = marqo.Client(url=\"http://localhost:8882\")\n\nmq.create_index(\"my-weighted-query-index\")\n\nmq.index(\"my-weighted-query-index\").add_documents(\n    [\n        {\n            \"Title\": \"Smartphone\",\n            \"Description\": \"A smartphone is a portable computer device that combines mobile telephone \"\n            \"functions and computing functions into one unit.\",\n        },\n        {\n            \"Title\": \"Telephone\",\n            \"Description\": \"A telephone is a telecommunications device that permits two or more users to\"\n            \"conduct a conversation when they are too far apart to be easily heard directly.\",\n        },\n        {\n            \"Title\": \"Thylacine\",\n            \"Description\": \"The thylacine, also commonly known as the Tasmanian tiger or Tasmanian wolf, \"\n            \"is an extinct carnivorous marsupial.\"\n            \"The last known of its species died in 1936.\",\n        }\n    ],\n    tensor_fields=[\"Description\"]\n)\n\n# initially we ask for a type of communications device which is popular in the 21st century\nquery = {\n    # a weighting of 1.1 gives this query slightly more importance\n    \"I need to buy a communications device, what should I get?\": 1.1,\n    # a weighting of 1 gives this query a neutral importance\n    # this will lead to 'Smartphone' being the top result\n    \"The device should work like an intelligent computer.\": 1.0,\n}\n\nresults = mq.index(\"my-weighted-query-index\").search(q=query)\n\nprint(\"Query 1:\")\npprint.pprint(results)\n\n# now we ask for a type of communications which predates the 21st century\nquery = {\n    # a weighting of 1 gives this query a neutral importance\n    \"I need to buy a communications device, what should I get?\": 1.0,\n    # a weighting of -1 gives this query a negation effect\n    # this will lead to 'Telephone' being the top result\n    \"The device should work like an intelligent computer.\": -0.3,\n}\n\nresults = mq.index(\"my-weighted-query-index\").search(q=query)\n\nprint(\"\\nQuery 2:\")\npprint.pprint(results)\n```\n\n### Creating and searching indexes with multimodal combination fields\nMarqo lets you have indexes with multimodal combination fields. Multimodal combination fields can combine text and images into one field. This allows scoring of documents across the combined text and image fields together. It also allows for a single vector representation instead of needing many which saves on storage. The relative weighting of each component can be set per document.\n\nThe example below demonstrates this with retrieval of caption and image pairs using multiple types of queries.\n\n```python\nimport marqo\nimport pprint\n\nmq = marqo.Client(url=\"http://localhost:8882\")\n\nsettings = {\"treat_urls_and_pointers_as_images\": True, \"model\": \"ViT-L/14\"}\n\nmq.create_index(\"my-first-multimodal-index\", **settings)\n\nmq.index(\"my-first-multimodal-index\").add_documents(\n    [\n        {\n            \"Title\": \"Flying Plane\",\n            \"caption\": \"An image of a passenger plane flying in front of the moon.\",\n            \"image\": \"https://raw.githubusercontent.com/marqo-ai/marqo/mainline/examples/ImageSearchGuide/data/image2.jpg\",\n        },\n        {\n            \"Title\": \"Red Bus\",\n            \"caption\": \"A red double decker London bus traveling to Aldwych\",\n            \"image\": \"https://raw.githubusercontent.com/marqo-ai/marqo/mainline/examples/ImageSearchGuide/data/image4.jpg\",\n        },\n        {\n            \"Title\": \"Horse Jumping\",\n            \"caption\": \"A person riding a horse over a jump in a competition.\",\n            \"image\": \"https://raw.githubusercontent.com/marqo-ai/marqo/mainline/examples/ImageSearchGuide/data/image1.jpg\",\n        },\n    ],\n    # Create the mappings, here we define our captioned_image mapping \n    # which weights the image more heavily than the caption - these pairs \n    # will be represented by a single vector in the index\n    mappings={\n        \"captioned_image\": {\n            \"type\": \"multimodal_combination\",\n            \"weights\": {\n                \"caption\": 0.3,\n                \"image\": 0.7\n            }\n        }\n    },\n    # We specify which fields to create vectors for. \n    # Note that captioned_image is treated as a single field.\n    tensor_fields=[\"captioned_image\"]\n)\n\n# Search this index with a simple text query\nresults = mq.index(\"my-first-multimodal-index\").search(\n    q=\"Give me some images of vehicles and modes of transport. I am especially interested in air travel and commercial aeroplanes.\"\n)\n\nprint(\"Query 1:\")\npprint.pprint(results)\n\n# search the index with a query that uses weighted components\nresults = mq.index(\"my-first-multimodal-index\").search(\n    q={\n        \"What are some vehicles and modes of transport?\": 1.0,\n        \"Aeroplanes and other things that fly\": -1.0\n    },\n)\nprint(\"\\nQuery 2:\")\npprint.pprint(results)\n\nresults = mq.index(\"my-first-multimodal-index\").search(\n    q={\"Animals of the Perissodactyla order\": -1.0}\n)\nprint(\"\\nQuery 3:\")\npprint.pprint(results)\n```\n\n### Delete documents\n\nDelete documents.\n\n```python\n\nresults = mq.index(\"my-first-index\").delete_documents(ids=[\"article_591\", \"article_602\"])\n\n```\n\n### Delete index\n\nDelete an index.\n\n```python\nresults = mq.index(\"my-first-index\").delete()\n```\n\n## \n\n## Running Marqo open source in production\n\nWe support Kubernetes templates for Marqo which you can deploy on a cloud provider of your choice. Marqo's Kubernetes implementation allows you to deploy clusters with replicas, multiple storage shards and multiple inference nodes. The repo can be found here: [https://github.com/marqo-ai/marqo-on-kubernetes](https://github.com/marqo-ai/marqo-on-kubernetes)\n\nIf you're looking for a fully managed cloud service, you can sign up for Marqo Cloud here: [https://cloud.marqo.ai](https://cloud.marqo.ai).\n\n## Documentation\n\nThe full documentation for Marqo can be found here [https://docs.marqo.ai/](https://docs.marqo.ai/).\n\n## Warning\n\nNote that you should not run other applications on Marqo's Vespa cluster as Marqo automatically changes and adapts the settings on the cluster.\n\n## Contributors\n\nMarqo is a community project with the goal of making tensor search accessible to the wider developer community. We are glad that you are interested in helping out! Please read [this](./CONTRIBUTING.md) to get started.\n\n## Dev setup\n\n1. Create a virtual env ```python -m venv ./venv```.\n\n2. Activate the virtual environment ```source ./venv/bin/activate```.\n\n3. Install requirements from the requirements file: ```pip install -r requirements.txt```.\n\n4. Run tests by running the tox file. CD into this dir and then run \"tox\".\n\n5. If you update dependencies, make sure to delete the .tox dir and rerun.\n\n## Merge instructions:\n\n1. Run the full test suite (by using the command `tox` in this dir).\n\n2. Create a pull request with an attached github issue.\n\n## Support\n\n- Ask questions and share your creations with the community on our [Discourse forum](https://community.marqo.ai).\n- Join our [Slack community](https://bit.ly/marqo-community-slack) and chat with other community members about ideas.\n\n\n"
        },
        {
          "name": "RELEASE.md",
          "type": "blob",
          "size": 88.0380859375,
          "content": "# Release 2.14.1\n\n## New features\n\n- Add support for [hf_transfer](https://github.com/huggingface/hf_transfer) to accelerate the downloading speed of HuggingFace models by 10 to 30 times. See [here](https://docs.marqo.ai/latest/other-resources/guides/advanced-usage/configuration/#third-party-environment-variables) for details about how to enable it ([#1066](https://github.com/marqo-ai/marqo/pull/1066)).\n- Add `/healthz` endpoint for Marqo container liveness checks, which performs a status check for CUDA devices and returns a 500 error if any existing CUDA devices become unavailable or run out of memory ([#1068](https://github.com/marqo-ai/marqo/pull/1068)). \n\n## Bug fixes and minor changes\n\n- Fix a bug where numeric map fields are not returned when searching with `attributes_to_retrieve` parameter for unstructured indexes created prior to Marqo 2.13 ([#1062](https://github.com/marqo-ai/marqo/pull/1064)).\n- Fix a bug where numeric fields, numeric map fields, boolean fields and string array fields are not returned when searching with `attributes_to_retrieve` parameter for unstructured indexes created with Marqo 2.13 or later ([#1062](https://github.com/marqo-ai/marqo/pull/1064)).\n- Fix a bug where `document-processing` element is removed from the `services.xml` config file when bootstrapping the vector store ([#1075](https://github.com/marqo-ai/marqo/pull/1079)).\n\n# Release 2.13.4\n\n## Bug fixes and minor changes\n\n- Fix a bug where `document-processing` element is removed from the `services.xml` config file when bootstrapping the vector store ([#1075](https://github.com/marqo-ai/marqo/pull/1075)). \n\n# Release 2.13.3\n\n## Bug fixes and minor changes\n\n- Fix a bug where numeric map fields are not returned when searching with `attributes_to_retrieve` parameter for unstructured indexes created prior to Marqo 2.13 ([#1062](https://github.com/marqo-ai/marqo/pull/1062)).\n- Fix a bug where numeric fields, numeric map fields, boolean fields and string array fields are not returned when searching with `attributes_to_retrieve` parameter for unstructured indexes created with Marqo 2.13 or later ([#1062](https://github.com/marqo-ai/marqo/pull/1062)).\n\n# Release 2.14.0 \n\n## New features\n\n- FFmpeg-CUDA Support ([#1030](https://github.com/marqo-ai/marqo/pull/1030)).   Add GPU acceleration for video decoding by integrating FFmpeg with CUDA support.\nThis feature significantly improves video processing performance, making video handling up to 5 times faster. Check [here](https://docs.marqo.ai/2.14/other-resources/guides/advanced-usage/configuration/#marqo-video-gpu-acceleration-configuration) for guidance and requirements.\n\n- Video and audio file size limits ([#1012](https://github.com/marqo-ai/marqo/pull/1012)). Introduce configurable size limits for video and audio files in the add_documents, search, and embed endpoints. This enhancement allows users to manage and optimize resource usage effectively, ensuring smoother processing of multimedia content. Check [here](https://docs.marqo.ai/2.14/other-resources/guides/advanced-usage/configuration/#configuring-usage-limits) for more details. \n\n- Upgrade to Python 3.9 ([#1006](https://github.com/marqo-ai/marqo/pull/1006)).\nUpgrade the Marqo Docker image to use Python 3.9. With Python 3.8 reaching its End of Life (EOL), we have upgraded our platform to Python 3.9 to maintain security, compatibility, and access to ongoing support.\n\n\n## Bug fixes and minor changes\n\n- Move NLTK resource downloads to Marqo's startup process and remove the unsafe punkt package. This avoids potential code start issues and enhances security ([#1040](https://github.com/marqo-ai/marqo/pull/1040)).\n\n- Fix model serialization in OpenAPI specifications. This community-contributed PR resolves issues with OpenAPI spec generation and SwaggerUI by fixing incorrect type hints in the API definition, ensuring accurate model serialization and improving API documentation accessibility ([#986](https://github.com/marqo-ai/marqo/pull/986)). \n\n- Add brief description for each endpoint in the OpenAPI specifications. This improves API documentation clarity for users ([#1042](https://github.com/marqo-ai/marqo/pull/1042)).\n\n## Contributor shout-out\n- Shoutouts to our valuable 4.7k stargazers!\n- Thanks a lot for the heated discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n- Special thanks to community contributor [@gabauer](https://github.com/gabauer) for their impactful PR, helping improve Marqo for everyone!\n\n# Release 2.13.2\n\n## Bug fixes and minor changes\n\n- Fix a bug where adding documents with numeric lists to an unstructured index results in a 500 error. Now, Marqo successfully processes the document batch, and returns a 400 error only for individual documents that contain numeric lists([1034](https://github.com/marqo-ai/marqo/pull/1034)).\n- Fix validation of custom vector fields. Custom vector fields were silently ignored when not specified as tensor fields for an unstructured index. This will now trigger a 400 error. This helps guide users to properly define the field as a tensor field([1034](https://github.com/marqo-ai/marqo/pull/1034)).\n- Improve the bootstrapping process to prevent Marqo from crashing during startup when the vector store takes longer to converge, especially with multiple indexes. This ensures a smoother startup process even if the vector store takes time to fully initialize([1036](https://github.com/marqo-ai/marqo/pull/1036)).\n\n# Release 2.13.1\n\n## Bug fixes and minor changes\n\n- Fix a bug where Marqo returns a 500 error if an inaccessible private image is encountered in the query or embed endpoint. Marqo now correctly returns a 400 error with a helpful error message ([1027](https://github.com/marqo-ai/marqo/pull/1027)).\n- Fix a bug preventing Marqo from warming up Languagebind models. Marqo now successfully warms up Languagebind models as expected ([1031](https://github.com/marqo-ai/marqo/pull/1031)).\n- Fix a bug where Languagebind models always generate normalized embeddings for non-text content. These models now correctly produce unnormalized embeddings for video, audio, and image content ([1032](https://github.com/marqo-ai/marqo/pull/1032)).\n\n# Release 2.13.0\n\n## New features\n- Searchable attributes for unstructured indexes ([#968](https://github.com/marqo-ai/marqo/pull/968)). This new feature allows you to specify which lexical or tensor fields to include in your search queries, providing greater control over the search process. By customizing your search parameters, you can enhance the precision of your results across all search types: tensor, lexical, and hybrid. This feature is available for unstructured indexes created with Marqo 2.13 or later. For detailed guidance, please refer to [the API reference](https://docs.marqo.ai/latest/reference/api/search/search/#searchable-attributes) and [comparison of unstructured and structured indexes](https://docs.marqo.ai/latest/other-resources/cookbook/indexes/unstructured-vs-structured-indexes/)\n- Support for `stella_en_400M_v5` embedding models ([#1021](https://github.com/marqo-ai/marqo/pull/1021)). This feature adds compatibility for the Stella 400M text embedding models, enhancing the versatility of Marqo in handling diverse model types. Users can now use the `hf_stella` model type in their custom models. Please refer to [stella model guide](https://docs.marqo.ai/2.13/models/marqo/bring-your-own-model/#stella-models) for details.\n- Allow specifying pooling method for Hugging Face models ([#954](https://github.com/marqo-ai/marqo/pull/954)). Marqo can now infer the pooling method and accept user provided pooling method in model properties. For detailed examples, please refer to [this document about bringing your own Hugging Face model](https://docs.marqo.ai/2.13/models/marqo/bring-your-own-model/#bring-your-own-hugging-face-sentence-transformers-models).\n\n## Bug fixes and minor changes\n- Normalize custom vectors during indexing when `normalizeEmbeddings` is set to True for indexes created with Marqo 2.13 or later ([#970](https://github.com/marqo-ai/marqo/pull/970)). This fix ensures that custom vector fields align with other tensor fields in terms of normalization, resulting in more accurate search results and improved overall performance.\n- Enhanced query parser for double quotes ([#979](https://github.com/marqo-ai/marqo/pull/979)). This feature introduces improved parsing logic for handling double quotes in search queries, allowing for greater flexibility and resilience against syntax errors. Badly formatted and escaped quotes no longer lead to 500 status errors. Please refer to the [lexical search guide](https://docs.marqo.ai/latest/reference/api/search/search/#lexical-search-exact-matches) for more details and examples.\n- Bug fix for score modifiers handling ([#1008](https://github.com/marqo-ai/marqo/pull/1008)). This update resolves an issue related to the handling of score modifiers in queries, specifically those involving the period `.` character. Users will now experience smoother query operations without encountering internal errors, ensuring that score modifiers are correctly applied. \n- Bug fixes for media download and query handling ([#1022](https://github.com/marqo-ai/marqo/pull/1022)). Users can now successfully download private media files by using the new `mediaDownloadHeaders` parameter, which will replace the deprecated `imageDownloadHeaders`. Additionally, the fix resolves issues preventing the inclusion of more than two modalities in weighted queries, along with support for indexing `.png` images in Languagebind models.\n\n## Contributor shout-outs\n- Shoutouts to our valuable 4.6k stargazers!\n- Thanks a lot for the discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n\n# Release 2.12.5\n\n## Bug fixes and minor changes\n- Fix a bug where authentication is not correctly passed when loading a private model. Marqo can now load custom models from private repositories correctly ([#1010](https://github.com/marqo-ai/marqo/pull/1010)).\n\n# Release 2.12.4\n\n## Bug fixes and minor changes\n- Fix inference time regression from 2.11 to 2.12 where inference time increased unexpectedly ([#1005](https://github.com/marqo-ai/marqo/pull/1005)).\n\n# Release 2.12.3\n\n## Bug fixes and minor changes\n- Fix bug where users upgrading from indexes created with Marqo 2.11 to 2.12 would encounter an error when using the `get_settings` API endpoint ([#1003](https://github.com/marqo-ai/marqo/pull/1003)).\n\n# Release 2.12.2\n\n## Bug fixes and minor changes\n- Upgrade the `Pillow` and `nltk` packages ([#989](https://github.com/marqo-ai/marqo/pull/989)).\n- Fix a bug where `normalizeEmbeddings=False` is not honored for some indexes ([#994](https://github.com/marqo-ai/marqo/pull/994)).\n\n# Release 2.12.1\n\n## Bug fixes and minor changes\n- Fix a bug where when `treatUrlsAndPointersAsImages` is unset and `treatUrlsAndPointersAsMedia` is set, Marqo returns an error where `treatUrlsAndPointersAsImages` cannot be `False` when `treatUrlsAndPointersAsMedia` is `True` ([#971](https://github.com/marqo-ai/marqo/commit/a0084a86d5cf797616a1f8e185eba87417edbc15)) \n- Add new video-audio model `LanguageBind/Video_V1.5_FT_Audio_FT` to the model registry ([#971](https://github.com/marqo-ai/marqo/commit/a0084a86d5cf797616a1f8e185eba87417edbc15)).\n\n# Release 2.12.0\n\n## New features\n- Add support for video and audio modalities using LanguageBind models ([#931](https://github.com/marqo-ai/marqo/pull/931)). You can now index, embed, and search with video and audio files using Marqo, extending your search capabilities beyond text and images. \n- Load OpenCLIP models from HuggingFace Hub ([#939](https://github.com/marqo-ai/marqo/pull/939)). Support loading OpenCLIP models directly from HuggingFace by providing a model name with the hf-hub: prefix. This simplifies model integration and expands your options.\n- Load custom OpenCLIP checkpoints with different image preprocessors ([#939](https://github.com/marqo-ai/marqo/pull/939)). Allow loading a custom OpenCLIP checkpoint with a different image preprocessor by providing imagePreprocessor in the model properties. This offers greater flexibility in model selection and customization.\n\n## Bug fixes and minor changes\n- Fix tokenizer loading for custom OpenCLIP checkpoints ([#939](https://github.com/marqo-ai/marqo/pull/939)). The correct tokenizer is now applied when custom OpenCLIP model checkpoints are loaded.\n- Improve error handling for image_pointer fields in structured indexes ([#944](https://github.com/marqo-ai/marqo/pull/944)). Structured indexes now have targeted error reporting for non-image content in image_pointer fields. This improvement prevents batch failures and provides clearer feedback to users.\n\n## Contributor shout-outs\n- Shoutouts to our valuable 4.5k stargazers!\n- Thanks a lot for the discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n\n# Release 2.11.4\n\n## Bug fixes and minor changes\n- Fix duplication of results in RRF hybrid search ([#957](https://github.com/marqo-ai/marqo/pull/957)). Resolved an issue where some results in Reciprocal Rank Fusion (RRF) hybrid search were duplicated, ensuring more accurate and unique search results.\n\n# Release 2.11.3\n\n## Bug fixes and minor changes\n- Support S3 custom model without explicit credentials ([#948](https://github.com/marqo-ai/marqo/pull/948)).\n\n# Release 2.11.2\n\n## Bug fixes and minor changes\n- Fix an issue where CUDA was not automatically selected as the default device for the `embed` endpoint, even when available [#941](https://github.com/marqo-ai/marqo/pull/941).\n\n# Release 2.11.1\n\n## Bug fixes and minor changes\n- Added a default User-Agent header (`Marqobot/1.0`) and enabled automatic redirection handling when downloading images ([#932](https://github.com/marqo-ai/marqo/pull/932)). This enhancement allows Marqo to correctly process image URLs that require a `User-Agent` header or redirection.\n\n# Release 2.11.0\n\n## New features\n\n- Hybrid Search for unstructured indexes (`\"searchMethod\": \"HYBRID”`) ([#912](https://github.com/marqo-ai/marqo/pull/912)). Marqo now supports hybrid search for unstructured indexes, combining lexical and tensor search (e.g., using reciprocal rank fusion - RRF) to provide the best relevance possible. See usage [here](https://docs.marqo.ai/2.11/API-Reference/Search/search/#example-2-creating-and-searching-an-unstructured-index-hybrid-search-with-model-deployed-within-marqo). Please note that hybrid search only works on a fresh Marqo 2.11.0 instance without state transfer for now. This is a limitation that we will address in the next release.\n- [Marqo Terraform provider](https://github.com/marqo-ai/terraform-provider-marqo) is now available on both [OpenTofu Registry](https://github.com/opentofu/registry/blob/main/providers/m/marqo-ai/marqo.json) and [Terraform Registry](https://registry.terraform.io/providers/marqo-ai/marqo/latest). See usage [here](https://docs.marqo.ai/2.11/Cloud-Reference/opentofu_provider/)\n\n## Bug fixes and minor changes\n\n- Improve the error handling of batch add/update/get documents API ([#911](https://github.com/marqo-ai/marqo/pull/911)). Now each document in a batch request has its individual response status with detailed error message. See details [here](https://docs.marqo.ai/2.11/API-Reference/Documents/add_or_replace_documents/#response)\n- Fix incorrect or missing prefixes for some models in the registry ([#917](https://github.com/marqo-ai/marqo/pull/917)). This change improves all BGE models, all Snowflake models, and multilingual-e5-large-instruct. For example, `snowflake-arctic-embed-l` model has 34% improvement in NDCG@10 on the Arguana benchmark and 153% improvement in NDCG@10 on the FIQA benchmark.\n- Increase the maxHits and maxOffset limit to 1,000,000 in the default query profile. ([#914](https://github.com/marqo-ai/marqo/pull/914)). This allows user to override `MARQO_MAX_SEARCH_LIMIT` and `MARQO_MAX_SEARCH_OFFSET` environment variables to large values up to one million. Please note that this is an advanced setting and very large values aren’t normally recommended.\n- Fix a bug that causes 400 error when using hybrid search with LEXICAL retrieval method and TENSOR ranking method and `scoreModifiersLexical` ([#922](https://github.com/marqo-ai/marqo/pull/922)).\n\n## Contributor shout-outs\n\n- Huge shoutout to all our 4.4k stargazers! We’ve come a long way as a team and as a community, so a huge thanks to everyone who continues to support Marqo.\n- Feel free to keep on sharing questions and feedback on our [forum](https://community.marqo.ai/) and [Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! If you have any more inquiries or thoughts, please don’t hesitate to reach out.\n\n# Release 2.10.2\n\n## Bug fixes and minor changes\n- Fix an issue where CUDA was not automatically selected as the default device for the `embed` endpoint, even when available [#941](https://github.com/marqo-ai/marqo/pull/941).\n\n# Release 2.10.1\n\n## Bug fixes and minor changes\n- Improve the clarity of the error message when Marqo can not download the provided image ([#905](https://github.com/marqo-ai/marqo/pull/905)).\n- Improve the error message in hybrid search to avoid confusion ([#900](https://github.com/marqo-ai/marqo/pull/900)).\n- Fix a bug where a `500` error is returned when an unsupported search method is provided. Marqo now correctly returns a `400` error ([#899](https://github.com/marqo-ai/marqo/pull/899)).\n- Fix a bug where a `500` error is returned when an invalid image URL with non-ASCII characters is provided. Marqo now encodes the image URL correctly ([#908](https://github.com/marqo-ai/marqo/pull/908)).\n\n# Release 2.10.0\n\n## New features\n\n- Hybrid Search (`\"searchMethod\": \"HYBRID”`) (https://github.com/marqo-ai/marqo/pull/845). Marqo now supports hybrid search, combining lexical and tensor search (using reciprocal rank fusion) to provide the best relevance possible. See usage [here](https://docs.marqo.ai/2.10/API-Reference/Search/search/#hybrid-parameters).\n- Lexical Search score modifiers (https://github.com/marqo-ai/marqo/pull/884). Score modifiers are now supported for lexical search. Score modifiers are applied on all matches, not just the top k retrieved, resulting in more relevant hits. See usage [here](https://docs.marqo.ai/2.10/API-Reference/Search/search/#score-modifiers).\n\n## Bug fixes and minor changes\n\n- Increase unstructured index default `filterStringMaxLength` to 50, from 20 (https://github.com/marqo-ai/marqo/pull/887). Maximum length of string fields to be used in query filters now defaults to 50 characters long.\n\n## Contributor shout-outs\n\n- Huge shoutout to all our 4.3k stargazers! We’ve come a long way as a team and as a community, so a huge thanks to everyone who continues to support Marqo.\n- Feel free to keep on sharing questions and feedback on our [forum](https://community.marqo.ai/) and [Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! If you have any more inquiries or thoughts, please don’t hesitate to reach out.\n\n# Release 2.9.0\n\n## New features\n- Numeric map data type. Add numeric map data types, available for filtering and score modification ([#851](https://github.com/marqo-ai/marqo/pull/851)). You can now store a map/dictionary of numeric value and use these in your filters and score modifiers, or simply retrieve these with your documents. See the new types [here](https://docs.marqo.ai/2.9/API-Reference/Indexes/create_structured_index/?h=struct#fields). For usage in search, see [here](https://docs.marqo.ai/2.9/API-Reference/Search/search/?h=map#example_4).  This is supported only for indexes created with Marqo 2.9 or later.\n- Double and long score modifier fields. Support double and long in map and standard numeric fields for score modifiers in both structured and unstructured indexes ([#851](https://github.com/marqo-ai/marqo/pull/851)). You can now use double values with full precision as score modifiers, as well as integers with guaranteed precision up to `2^53 - 1` (increased from `2^24 - 1`), with only negligible precision loss for larger values. For details on these new types, see the documentation [here](https://docs.marqo.ai/2.9/API-Reference/Indexes/create_structured_index/?h=struct#fields).\n\n## Bug fixes and minor changes\n- Fix the bug in score modifiers where missing score modifiers in docs used in `multiply_score_by` lead to the multiplication of scores by `0` instead of by `1` ([#851](https://github.com/marqo-ai/marqo/pull/851)).\n- Improve upgrade stability ([#874](https://github.com/marqo-ai/marqo/pull/874)). Fix failure of state transfer between some versions of Marqo due to Vespa binaries being copied with state. For more information, see the documentation [here](https://docs.marqo.ai/2.9/Guides/Advanced-Usage/transferring_state/?h=transfer)\n- Improve the model warmup strategy on instances with CUDA ([#877](https://github.com/marqo-ai/marqo/pull/877)). Marqo now requires less memory to warmup the models when spinning up .\n- Improve create/delete index resilience to partial failures ([#866](https://github.com/marqo-ai/marqo/pull/866)). You can now bring Marqo to a consistent state by repeating the operation until getting a `200` response.\n\n## Contributor shout-outs\n- Shoutouts to our valuable 4.3k stargazers!\n- Thanks a lot for the discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n\n# Release 2.8.2\n\n## Bug fixes and minor changes\n- Fix an issue in Marqo where loading some models (e.g., `open_clip/xlm-roberta-base-ViT-B-32/laion5b_s13b_b90k`) is unsuccessful. \nThis was resolved by upgrading the `transformers` and `optimum` packages. ([#868](https://github.com/marqo-ai/marqo/pull/868))\n\n# Release 2.8.1\n\n## Bug fixes and minor changes\n- Fix a bug in Marqo where a 500 error is returned for the entire batch of documents when encountering an invalid document ID during image downloading. \nMarqo now correctly returns an error and rejects the invalid document, \nallowing successful indexing of other valid documents with a 200 response. ([#860](https://github.com/marqo-ai/marqo/pull/860))\n\n# Release 2.8.0\n\n## New features\n- Improve `add_documents` memory efficiency and throughput for CLIP and Open_CLIP models when indexing documents with images when no patch method is used ([#849](https://github.com/marqo-ai/marqo/pull/849)). The image downloading and preprocessing logic has been improved. Marqo now converts the images to tensors directly after downloading. In our tests, the memory usage has been reduced by 37.5% and the throughput has been increased by 7.5% (subject to your settings). Marqo is also more stable when indexing documents in a multi-threading scenario.\n- Add support for pre-warming patch models ([#847](https://github.com/marqo-ai/marqo/pull/847)). See usage [here](https://docs.marqo.ai/2.8/Guides/Advanced-Usage/configuration/#configuring-preloaded-patch-models).\n\n## Bug fixes and minor changes\n- Replace the requests package with pycurl for faster image downloads ([#814](https://github.com/marqo-ai/marqo/pull/814)). Marqo now downloads images 2-3x faster in our tests and the overall `add_documents` throughput is increased by 7.5%\n\n## Contributor shout-outs\n- Shoutouts to our valuable 4.2k stargazers!\n- Thanks a lot for the discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n\n\n# Release 2.7.2\n\n## Bug fixes and minor changes\n- Fix an issue causing an error during the Marqo shutdown process (https://github.com/marqo-ai/marqo/pull/850). Marqo now shuts down properly without encountering errors.\n\n# Release 2.7.1\n\n## Bug fixes and minor changes\n- Resolve an issue where Marqo could not create or delete an index when not connected to the Zookeeper server (https://github.com/marqo-ai/marqo/pull/848). Users can now create or delete an index without needing to connect to the Zookeeper server. However, please note that without the Zookeeper server, your request is not protected in concurrent scenarios. For guidance on configuring your Zookeeper server, refer to [this documentation](https://docs.marqo.ai/2.7/Guides/Advanced-Usage/configuration/#configure-backend-communication).\n\n# Release 2.7.0\n\n## New features\n- Update Open CLIP version and support new families of models, e.g., `MetaCLIP`, `DatacompCLIP`  ([#833](https://github.com/marqo-ai/marqo/pull/833)). Update the Open CLIP version to `2.24.0`  which includes new and state-of-the-art multimodal models. You can choose these models to build your index. Check [here](https://github.com/marqo-ai/marqo/releases/%5B%3Chttps://docs.marqo.ai/2.7/Guides/Models-Reference/list_of_models/#open-clip%3E%5D(%3Chttps://docs.marqo.ai/2.6/Guides/Models-Reference/list_of_models/#open-clip%3E)) for the available models.\n- Support lexical search with only a filter (https://github.com/marqo-ai/marqo/pull/840). Marqo now supports a match-all query (`\"*\"`) with a filter in lexical search. This allows you to search your documents solely based on the filter content without considering the relevance. This is a community-requested feature (https://github.com/marqo-ai/marqo/issues/770, https://github.com/marqo-ai/marqo/issues/771) and we love to hear from our users.\n\n## Bug fixes and minor changes\n- Improve the thread safety of index creation and deletion operations (https://github.com/marqo-ai/marqo/pull/838). Marqo now returns an `operation_conflict_error(409)` if users try to delete or create an index when there is another index creation or deletion in progress.\n- Fix a bug that an empty string lexical search query (`\"\"`) returns a 500 error (https://github.com/marqo-ai/marqo/pull/840). Marqo now returns an empty search result for such a query.\n- Address verbose logging at the `WARNING` level when `attributes_to_retrieve` excludes fields required to build highlights. (https://github.com/marqo-ai/marqo/pull/837)\n\n## Contributor shout-outs\n- Shoutouts to our valuable 4.2k stargazers!\n- Thanks [@jesse-lord](https://github.com/jess-lord) and [@afroozsheikh](https://github.com/afroozsheikh) for requesting valuable features to improve Marqo!\n- Thanks a lot for the discussion and suggestions in our community. We love to hear your thoughts and requests. Join our [Slack channel](https://join.slack.com/t/marqo-community/shared_invite/zt-2jm456s90-1pFxdE5kDQt5imqddXUIcw) and [forum](https://community.marqo.ai/) now.\n\n\n# Release 2.6.0\n\n## New features \n- Support for custom and default prefixes ([#821](https://github.com/marqo-ai/marqo/pull/821) and [#832](https://github.com/marqo-ai/marqo/pull/832)) in the index creation, adding documents, search, and embed endpoints. See usage for index creation [here](https://docs.marqo.ai/2.6/API-Reference/Indexes/create_index), adding documents [here](https://docs.marqo.ai/2.6/API-Reference/Documents/add_or_replace_documents), search [here](https://docs.marqo.ai/2.6/API-Reference/Search/search), and embed [here](https://docs.marqo.ai/2.6/API-Reference/Embed/embed).\n\n## Bug fixes and minor changes\n- Improved recommender with structured indexes ([#830](https://github.com/marqo-ai/marqo/pull/830))\n- Better handling of image download errors ([#829](https://github.com/marqo-ai/marqo/pull/829)). Image download errors will now return a 200 overall and log errors per document.\n\n## Contributor Shout-outs\n- Shoutout to all our 4.2k stargazers! Thanks for continuing to use our product and helping Marqo grow.\n- Keep on sharing your questions and feedback on our [forum](https://community.marqo.ai/) and [Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! If you have any more inquiries or thoughts, please don’t hesitate to reach out.\n \n# Release 2.5.1\n\n## Bug fixes and minor changes\n- More stable `recommend` endpoint (https://github.com/marqo-ai/marqo/pull/825).\n- Change error code when using `IN` filter operator on an unstructured index (https://github.com/marqo-ai/marqo/pull/823).\n- New index settings validation endpoint for Cloud use (https://github.com/marqo-ai/marqo/pull/809).\n\n# Release 2.5.0\n## New features\n- New ‘embed’ endpoint (`POST /indexes/{index_name}/embed`) (https://github.com/marqo-ai/marqo/pull/803). Marqo can now perform inference and return the embeddings for a single piece or list of content, where content can be either a string or weighted dictionary of strings. See usage [here](https://docs.marqo.ai/2.5/API-Reference/Embed/embed/). \n- New ‘recommend’ endpoint (`POST /indexes/{index_name}/recommend`) (https://github.com/marqo-ai/marqo/pull/816). Given a list of existing document IDs, Marqo can now recommend similar documents by performing a search on interpolated vectors from the documents. See usage [here](https://docs.marqo.ai/2.5/API-Reference/Search/recommend/). \n- Add Inference Cache to speed up frequent search and embed requests (https://github.com/marqo-ai/marqo/pull/802). Marqo now caches embeddings generated during inference. The cache size and type can be configured with `MARQO_INFERENCE_CACHE_SIZE` and `MARQO_INFERENCE_CACHE_TYPE`. See configuration instructions [here](https://docs.marqo.ai/2.5/Guides/Advanced-Usage/configuration/#configuring-cache). \n- Add configurable search timeout (https://github.com/marqo-ai/marqo/pull/813). Backend timeout now defaults to 1s, but can be configured with the environment variable `VESPA_SEARCH_TIMEOUT_MS`. See configuration instructions [here](https://docs.marqo.ai/2.5/Guides/Advanced-Usage/configuration/#configuring-usage-limits). \n- More informative `get_cuda_info` response (https://github.com/marqo-ai/marqo/pull/811). New keys: `utilization` `memory_used_percent` have been added for easier tracking of cuda device status. See [here](https://docs.marqo.ai/2.5/API-Reference/Device/get_cuda_information/) for more information.\n\n## Bug fixes and minor changes\n- Upgraded `open_clip_torch`, `timm`, and `safetensors` for access to new models (https://github.com/marqo-ai/marqo/pull/810) \n\n## Contributor shout-outs\n- Shoutout to all our 4.1k stargazers! Thanks for continuing to use our product and helping Marqo grow.\n- Keep on sharing your questions and feedback on our [forum](https://community.marqo.ai/) and [Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! If you have any more inquiries or thoughts, please don’t hesitate to reach out.\n\n# Release 2.4.3\n\n## Bug fixes and minor changes\n- Fix incorrect Marqo version number (https://github.com/marqo-ai/marqo/pull/805). Version number updated from 2.4.1 to 2.4.3\n\n# Release 2.4.2\n\n## Bug fixes and minor changes\n- Better response for truncated images in `add_documents` (https://github.com/marqo-ai/marqo/pull/797). Truncated images no longer cause a 500 error. The individual document will fail and return a 400 error in add docs response (full response will be a 200).\n\n# Release 2.4.1\n\n## Bug fixes and minor changes\n- Improve telemetry memory management (https://github.com/marqo-ai/marqo/pull/800).\n\n# Release 2.4.0\n\n## New features\n- Add `IN` operator to the query filter string DSL (https://github.com/marqo-ai/marqo/pull/790, https://github.com/marqo-ai/marqo/pull/793, & https://github.com/marqo-ai/marqo/pull/795). \nFor structured indexes, you can now use the `IN` keyword to restrict text and integer fields to be within a list of values. See usage [here](https://docs.marqo.ai/2.4.0/Guides/query_dsl/#in-queries). \n \n- Add `no_model` option for index creation (https://github.com/marqo-ai/marqo/pull/789). This allows for indexes that do no vectorisation, \nproviding easy use of custom vectors with no risk of accidentally mixing them up with Marqo-generated vectors. See usage [here](https://docs.marqo.ai/2.4.0/Guides/Models-Reference/list_of_models/#no-model). \n- Optional `q` parameter for the search endpoint if context vectors are provided. (https://github.com/marqo-ai/marqo/pull/789). \nThis is particularly useful when using context vectors to search across your documents that have custom vector fields. See usage [here](https://docs.marqo.ai/2.4.0/API-Reference/Search/search/#query-q).\n\n## Bug fixes and minor changes\n- Improve error message for defining `tensorFields` when adding documents to a structured index (https://github.com/marqo-ai/marqo/pull/788). \n\n## Contributor shout-outs\n- A huge thank you to all our 4.1k stargazers! We appreciate all of you continuing to use our product and helping Marqo grow.\n- Thanks for sharing your questions and feedback on our [forum](https://community.marqo.ai/) and \n[Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! \nIf you have any more inquiries or thoughts, please don’t hesitate to reach out.\n\n# Release 2.3.0\n\n## New features\n- New `update_documents` API (https://github.com/marqo-ai/marqo/pull/773). Structured indexes now support high throughput partial updates to non-tensor fields. Unstructured indexes do not support partial updates. See usages [here](https://docs.marqo.ai/2.3.0/API-Reference/Documents/update_documents/)\n- The custom vectors feature is now supported again for both structured and unstructured indexes (https://github.com/marqo-ai/marqo/pull/777). You can now add externally generated vectors to Marqo documents. See usages [here](https://docs.marqo.ai/2.3.0/API-Reference/Documents/add_or_replace_documents/#mappings)\n\n## Bug fixes and minor changes\n- Fix an issue where non-default distance metrics are not configured correctly with unstructured indexes (https://github.com/marqo-ai/marqo/pull/772).\n- Introduce a guide for running Marqo open source in production environments, offering insights and best practices (https://github.com/marqo-ai/marqo/pull/775).\n- Remove outdated examples from the README to improve clarity and relevance (https://github.com/marqo-ai/marqo/pull/766).\n\n## Contributor shout-outs\n- A huge thank you to all our 4k stargazers! This is a new milestone for Marqo!\n- Stay connected and share your thoughts on our [forum](https://community.marqo.ai/) and [Slack channel](https://marqo-community.slack.com/join/shared_invite/zt-2b4nsvbd2-TDf8agPszzWH5hYKBMIgDA#/shared-invite/email)! Your insights, questions, and feedback are always welcome and highly appreciated.\n\n# Release 2.2.3\n\n## New features\n- Add configurable search timeout (https://github.com/marqo-ai/marqo/pull/843). Backend timeout now defaults to 1s, but can be configured with the environment variable `VESPA_SEARCH_TIMEOUT_MS`. See configuration instructions [here](https://docs.marqo.ai/2.5/Guides/Advanced-Usage/configuration/#configuring-usage-limits). \n\n# Release 2.2.2\n\n## Bug fixes and minor changes\n- Improve telemetry memory management (https://github.com/marqo-ai/marqo/pull/804).\n\n# Release 2.2.1\n\n## Bug fixes and minor changes\n- Fix response code for vector store timeout, change it from 429 to 504 (https://github.com/marqo-ai/marqo/pull/763)\n\n# Release 2.2.0\n\n## New features\n- Support filtering on document ID with structured indexes. This was already supported with unstructured indexes ([#749](https://github.com/marqo-ai/marqo/pull/749))\n- New structured index data types: `long`, `double`, `array<long>` and `array<double>` for a higher precision and range of values Available for indexes created with Marqo 2.2+ ([#722](https://github.com/marqo-ai/marqo/pull/722))\n- Higher precision numeric fields for unstructured indexes. Unstructured indexes created with Marqo 2.2+ will use double precision floats and longs for a higher precision and wider range of values ([#722](https://github.com/marqo-ai/marqo/pull/722))\n- Numeric value range validation. Values that are out of range for the field type will now receive a 400 validation error when adding documents. ([#722](https://github.com/marqo-ai/marqo/pull/722))\n\n## Bug fixes and minor changes\n- Fix unstructured index bug where filtering for boolean-like strings (e.g., `\"true\"`) would not work as expected ([#709](https://github.com/marqo-ai/marqo/pull/709))\n- Better handling of vector store timeouts. Marqo will now return a 429 (throttled) error message when the backend vector store is receiving more traffic than it can handle([#758](https://github.com/marqo-ai/marqo/pull/758))\n- Improved error logging. Stack trace will now always be logged ([#745](https://github.com/marqo-ai/marqo/pull/745))\n- Better API 500 error message. Marqo will no longer return verbose error messages in the API response ([#751](https://github.com/marqo-ai/marqo/pull/751))\n- Default index model is now hf/e5-base-v2 ([#710](https://github.com/marqo-ai/marqo/pull/710))\n- Improve error messages ([#746](https://github.com/marqo-ai/marqo/pull/746), [#747](https://github.com/marqo-ai/marqo/pull/747))\n- Improve error handling at startup when vector store is not ready. Marqo will now start and wait for vector store to become available ([#752](https://github.com/marqo-ai/marqo/pull/752))\n\n## Contributor shout-outs\n- A huge thank you to all our 3.9k stargazers!\n- Thank you [@Dmitri](https://marqo-community.slack.com/team/U06GL2R5NMT) for helping us identify the issue with running Marqo on older AMD64 processors!\n\n\n# Release 2.1.0\n\n## New features\n- Search result maximum limit and offset greatly increased. Maximum `limit` parameter increased from 400 to 1,000, `offset` increased from 1,000 to 10,000. Maximum value for `MARQO_MAX_RETRIEVABLE_DOCS` configuration is now 10,000 ([#735](https://github.com/marqo-ai/marqo/pull/735)​​, [#737](https://github.com/marqo-ai/marqo/pull/737)​​). See search `limit` and `offset` usage [here](https://docs.marqo.ai/2.1.0/API-Reference/Search/search/#limit)\n\n## Bug fixes and minor changes\n- Improved the Marqo bootstrapping process to address unexpected API behaviour when no index has been created yet (https://github.com/marqo-ai/marqo/pull/730).\n- Improved validation for `create_index` settings (https://github.com/marqo-ai/marqo/pull/717, https://github.com/marqo-ai/marqo/pull/734). Using `dependent_fields` as a request body parameter will now raise a 400 validation error.\n- Improved data parsing for documents in unstructured indexes (https://github.com/marqo-ai/marqo/pull/732). \n- Made vector store layer config upgrades and rollbacks easier ([#735](https://github.com/marqo-ai/marqo/pull/735)​​, [#736](https://github.com/marqo-ai/marqo/pull/736)​​). \n- Readme improvements (https://github.com/marqo-ai/marqo/pull/729). \n\n\n# Release 2.0.1\n\n## Bug fixes and minor changes\n- Improved stability of `use_existing_tensors` feature in `add_documents` (https://github.com/marqo-ai/marqo/pull/725).\n- Improved readability of Marqo start-up logs (https://github.com/marqo-ai/marqo/pull/719).\n- Removed obsolete examples ([#721](https://github.com/marqo-ai/marqo/pull/721), [#723](https://github.com/marqo-ai/marqo/pull/723)).\n\n\n# Release 2.0.0\n## New features\n* Significant queries-per-second (QPS) and latency improvements in addition to reduced memory and storage requirements. \nGet a higher QPS and a lower latency for the same infrastructure cost, or get the same performance for much cheaper! \nIn our large-scale experiments, we have achieved 2x QPS improvement, 2x speed-up in P50 search latency and 2.3x\nspeed-up in P99 search latency, compared to previous Marqo versions.\n* Significantly improved recall. You can now get up to 99% recall (depending on your dataset and configuration) without \nsacrificing performance.\n* Support for bfloat16 numeric type. Index 2x more vectors with the same amount of memory for a minimal reduction in\nrecall and performance.\n* Structured index. You can now create structured indexes, which provide better data validation, higher performance, \nbetter recall and better memory efficiency.\n* New API search parameter  `efSearch`. Search API now accepts an optional `efSearch` parameter which allows you to \nfine-tune the underlying HNSW search. Increase efSearch to improve recall at a minor cost of QPS and latency. See \n[here](https://docs.marqo.ai/2.0.0/API-Reference/Search/search/#body) for usage. \n* Exact nearest neighbour search. Set `\"approximate\": false` in the Search API body to perform an exact nearest \nneighbour search. This is useful for calculating recall and finding the best `efSearch` for your dataset. \nSee [here](https://docs.marqo.ai/2.0.0/API-Reference/Search/search/#body) for usage. \n* New approximate nearest neighbour space types. Marqo now supports `euclidean`, `angular`, `dotproduct`,\n`prenormalized-angular`, and `hamming` distance metrics. L1, L2 and Linf distance metrics are no longer supported.\nThe distance metric determines how Marqo calculates the closeness between indexed documents and search queries.\n* Easier local runs. Simply run `docker run -p 8882:8882 marqoai/marqo:2.0.0` to start Marqo locally on both \nARM64 (M-series Macs) and AMD64 machines.\n\n## Breaking changes\n* Create index API no longer accept the `index_defaults` parameter. Attributes previously defined in this object, \nlike `textPreprocessing`, are now moved out to the top level settings object. \nSee [here](https://docs.marqo.ai/2.0.0/API-Reference/Indexes/create_index/) for details.\n* Create index API's `filterStringMaxLength` parameter determines the maximum length of strings that are indexed for \nfiltering (default value 20 characters). This limitation does not apply to structured indexes. \nSee [here](https://docs.marqo.ai/2.0.0/API-Reference/Indexes/create_index/) for details.\n* Most APIs now require camel case request bodies and return camel case responses. See \n[create index](https://docs.marqo.ai/2.0.0/API-Reference/Indexes/create_index/), \n[search](https://docs.marqo.ai/2.0.0/API-Reference/Search/search/) and \n[add documents](https://docs.marqo.ai/2.0.0/API-Reference/Documents/add_or_replace_documents/) for a few examples.\n* New Marqo configuration parameters See [here](https://docs.marqo.ai/2.0.0/Guides/Advanced-Usage/configuration/) for \nusage.\n* Search response `_highlights` attribute is now a list of dictionaries. \nSee [here](https://docs.marqo.ai/2.0.0/API-Reference/Search/search/#response-200-ok) for new usage.\n* Add documents multimodal fields are defined as normal fields and not dictionaries. Furthermore, the mappings object \nis optional for structured indexes. See [here](https://docs.marqo.ai/2.0.0/API-Reference/Documents/add_or_replace_documents/) for usage.\n* Add documents does not accept the `refresh` parameter anymore.\n* The following features are available in Marqo 1.5, but are not supported by Marqo 2.0 and will be added in future \nreleases:\n  * Separate models for search and add documents\n  * Prefixes for text chunks and queries\n  * Configurable document count limit for add documents. There is a non-configurable limit of 128 in Marqo 2.0.\n  * Custom (externally generated) vectors and `no_model` option for index creation.\n  * Optional Search API `q` parameter when searching with context vectors.\n\n## Contributor shout-outs\n* Thank you to the community for your invaluable feedback, which drove the prioritisation for this major release.\n* A warm thank you to all our 3.9k stargazers.\n\n# Release 1.5.1\n## Bug fixes and minor changes\n- Adding `no_model` to `MARQO_MODELS_TO_PRELOAD` no longer causes an error on startup. Preloading process is simply skipped for this model [#657](https://github.com/marqo-ai/marqo/pull/657).\n\n\n# Release 1.5.0\n## New Features\n- Separate model for search and add documents (https://github.com/marqo-ai/marqo/pull/633). Using the `search_model` and `search_model_properties` key in `index_defaults` allows you to specify a model specifically to be used for searching. This is useful for using a different model for search than what is used for add_documents. Learn how to use `search_model` [here](https://docs.marqo.ai/1.5.0/API-Reference/Indexes/create_index/#search-model).\n- Prefixes for text chunks and queries enabled to improve retrieval for specific models (https://github.com/marqo-ai/marqo/pull/643). These prefixes are defined at the `model_properties` level, but can be overriden at index creation, add documents, or search time. Learn how to use prefixes for `add_documents` [here](https://docs.marqo.ai/1.5.0/API-Reference/Documents/add_or_replace_documents/#text-chunk-prefix) and `search` [here](https://docs.marqo.ai/1.5.0/API-Reference/Search/search/#text-query-prefix).\n\n## Bug fixes and minor changes\n- Upgraded `open_clip_torch`, `timm`, and `safetensors` for access to new models (https://github.com/marqo-ai/marqo/pull/646). \n- Documents containing multimodal objects that encounter errors in processing are rejected with a 400 error (https://github.com/marqo-ai/marqo/pull/631). \n- Updated README: More detailed explanations, fixed formatting issues (https://github.com/marqo-ai/marqo/pull/629/files, https://github.com/marqo-ai/marqo/pull/642/files).  \n\n## Contributor shout-outs\n- A huge thank you to all our 3.7k stargazers!\n- Thanks everyone for continuing to participate in our [forum](https://community.marqo.ai/)! Keep all your insights, questions, and feedback coming!\n\n\n# Release 1.4.0\n\n## Breaking Changes\n- Configurable document count limit for `add_documents()` calls (https://github.com/marqo-ai/marqo/pull/592). This mitigates Marqo getting overloaded \ndue to add_documents requests with a very high number of documents. If you are adding documents in batches larger than the default (64), you will now \nreceive an error. You can ensure your add_documents request complies to this limit by setting the Python client’s `client_batch_size` or changing this \nlimit via the  `MARQO_MAX_ADD_DOCS_COUNT` variable. Read more on configuring the doc count limit [here](https://marqo.pages.dev/1.4.0/Guides/Advanced-Usage/configuration/#configuring-usage-limits).\n- Default `refresh` value for `add_documents()` and `delete_documents()` set to `false` (https://github.com/marqo-ai/marqo/pull/601). This prevents \nunnecessary refreshes, which can negatively impact search and add_documents performance, especially for applications that are \nconstantly adding or deleting documents. If you search or get documents immediately after adding or deleting documents, you may still get some extra \nor missing documents. To see results of these operations more immediately, simply set the `refresh` parameter to `true`. Read more on this parameter \n[here](https://marqo.pages.dev/1.4.0/API-Reference/Documents/add_or_replace_documents/#query-parameters).\n\n## New Features\n- Custom vector field type added (https://github.com/marqo-ai/marqo/pull/610). You can now add externally generated vectors to Marqo documents! See \nusage [here](https://marqo.pages.dev/1.4.0/Guides/Advanced-Usage/document_fields/#custom-vector-object).\n- `no_model` option added for index creation (https://github.com/marqo-ai/marqo/pull/617). This allows for indexes that do no vectorisation, providing \neasy use of custom vectors with no risk of accidentally mixing them up with Marqo-generated vectors. See usage [here](https://marqo.pages.dev/1.4.0/API-Reference/Indexes/create_index/#no-model).\n- The search endpoint's `q` parameter is now optional if `context` vectors are provided. (https://github.com/marqo-ai/marqo/pull/617). This is \nparticularly useful when using context vectors to search across your documents that have custom vector fields. See usage [here](https://marqo.pages.dev/1.4.0/API-Reference/Search/search/#context).\n- Configurable retries added to backend requests (https://github.com/marqo-ai/marqo/pull/623). This makes `add_documents()` and `search()` requests \nmore resilient to transient network errors. Use with caution, as retries in Marqo will change the consistency guarantees for these endpoints. For more \ncontrol over retry error handling, you can leave retry attempts at the default value (0) and implement your own backend communication error handling. \nSee retry configuration instructions and how it impacts these endpoints' behaviour [here](https://marqo.pages.dev/1.4.0/Guides/Advanced-Usage/configuration/#configuring-marqo-os-request-retries).\n- More informative `delete_documents()` response (https://github.com/marqo-ai/marqo/pull/619). The response object now includes a list of document \nids, status codes, and results (success or reason for failure). See delete documents usage [here](https://marqo.pages.dev/1.4.0/API-Reference/Documents/delete_documents/).\n- Friendlier startup experience (https://github.com/marqo-ai/marqo/pull/600). Startup output has been condensed, with unhelpful log messages removed. \nMore detailed logs can be accessed by setting `MARQO_LOG_LEVEL` to `debug`.\n\n## Bug fixes and minor changes\n- Updated README: added Haystack integration, tips, and fixed links (https://github.com/marqo-ai/marqo/pull/593, https://github.com/marqo-ai/marqo/pull/602, https://github.com/marqo-ai/marqo/pull/616). \n- Stabilized test suite by adding score modifiers search tests (​​https://github.com/marqo-ai/marqo/pull/596) and migrating test images to S3 (https://github.com/marqo-ai/marqo/pull/594). \n- `bulk` added as an illegal index name (https://github.com/marqo-ai/marqo/pull/598). This prevents conflicts with the `/bulk` endpoint.\n- Unnecessary `reputation` field removed from backend call (https://github.com/marqo-ai/marqo/pull/609).\n- Fixed typo in error message (https://github.com/marqo-ai/marqo/pull/615).\n\n## Contributor shout-outs\n- A huge thank you to all our 3.7k stargazers!\n- Shoutout to @TuanaCelik for helping out with the Haystack integration!\n- Thanks everyone for keeping our [forum](https://community.marqo.ai/) busy. Don't hesitate to keep posting your insights, questions, and feedback!\n\n\n# Release 1.3.0\n\n## New features\n\n- New E5 models added to model registry (https://github.com/marqo-ai/marqo/pull/568). E5 V2 and Multilingual E5 models are now available for use. The new E5 V2 models outperform their E5 counterparts in the BEIR benchmark, as seen [here](https://github.com/microsoft/unilm/tree/master/e5#english-pre-trained-models). See all available models [here](https://marqo.pages.dev/1.2.0/Models-Reference/dense_retrieval/).\n- Dockerfile optimisation (https://github.com/marqo-ai/marqo/pull/569). A pre-built Marqo base image results in reduced image layers and increased build speed, meaning neater docker pulls and an overall better development experience.\n\n\n## Bug fixes and minor changes\n\n- Major README overhaul (https://github.com/marqo-ai/marqo/pull/573). The README has been revamped with up-to-date examples and easier to follow instructions.\n- New security policy (https://github.com/marqo-ai/marqo/pull/574).\n- Improved testing pipeline (https://github.com/marqo-ai/marqo/pull/582 & https://github.com/marqo-ai/marqo/pull/586). Tests now trigger on pull request updates. This results in safer and easier merges to mainline.\n- Updated requirements files. Now the `requirements.dev.txt` should be used to install requirements for development environments (https://github.com/marqo-ai/marqo/pull/569). Version pins for `protobuf` & `onnx` have been removed while a version pin for `anyio` has been added (https://github.com/marqo-ai/marqo/pull/581, & https://github.com/marqo-ai/marqo/pull/589).\n- General readability improvements (https://github.com/marqo-ai/marqo/pull/577, https://github.com/marqo-ai/marqo/pull/578, https://github.com/marqo-ai/marqo/pull/587, & https://github.com/marqo-ai/marqo/pull/580)\n\n## Contributor shout-outs\n\n- A huge thank you to all our 3.5k stargazers!\n- Shoutout to @vladdoster for all the useful spelling and grammar edits!\n- Thanks everyone for keeping our [forum](https://community.marqo.ai/) bustling. Don't hesitate to keep posting your insights, questions, and feedback!\n\n\n# Release 1.2.0\n\n## New features\n\n- Storage status in health check endpoint (https://github.com/marqo-ai/marqo/pull/555 & https://github.com/marqo-ai/marqo/pull/559). The `GET /indexes/{index-name}/health` endpoint's `backend` object will now return the boolean `storage_is_available`, to indicate if there is remaining storage space. If space is not available, health status will now return `yellow`. See [here](https://marqo.pages.dev/1.2.0/API-Reference/health/) for detailed usage.\n\n- Score Modifiers search optimization (https://github.com/marqo-ai/marqo/pull/566). This optimization reduces latency for searches with the `score_modifiers` parameter when field names or weights are changed. See [here](https://marqo.pages.dev/1.2.0/API-Reference/search/#score-modifiers) for detailed usage.\n\n## Bug fixes and minor changes\n\n- Improved error message for full storage (https://github.com/marqo-ai/marqo/pull/555 & https://github.com/marqo-ai/marqo/pull/559). When storage is full, Marqo will return `400 Bad Request` instead of `429 Too Many Requests`.\n- Searching with a zero vector now returns an empty list instead of an internal error (https://github.com/marqo-ai/marqo/pull/562).\n\n## Contributor shout-outs\n\n- A huge thank you to all our 3.3k stargazers!\n- Thank you for all the continued discussion in our [forum](https://community.marqo.ai/). Keep all the insights, questions, and feedback coming!\n\n\n# Release 1.1.0\n\n## New features\n\n- New field `numberOfVectors` in the `get_stats` response object (https://github.com/marqo-ai/marqo/pull/553). \nThis field counts all vectors from all documents in a given index. See [here](https://docs.marqo.ai/1.1.0/API-Reference/stats/) for detailed usage.\n\n- New per-index health check endpoint `GET /indexes/{index-name}/health` (https://github.com/marqo-ai/marqo/pull/552). \nThis replaces the cluster-level health check endpoint, `GET /health`,\nwhich is deprecated and will be removed in Marqo 2.0.0. See [here](https://docs.marqo.ai/1.1.0/API-Reference/health/) for detailed usage.\n\n## Bug fixes and minor changes\n\n- Improved image download validation and resource management (https://github.com/marqo-ai/marqo/pull/551). Image downloading in Marqo is more stable and resource-efficient now.\n\n- Adding documents now returns an error when `tensorFields` is not specified explicitly (https://github.com/marqo-ai/marqo/pull/554). This prevents users accidentally creating unwanted tensor fields.\n\n## Contributor shout-outs\n\n- Thank you for the vibrant discussion in our [forum](https://community.marqo.ai/). We love hearing your questions and about your use cases.\n\n\n# Release 1.0.0\n\n## Breaking Changes\n\n- New parameter `tensor_fields` will replace `non_tensor_fields` in the `add_documents` endpoint (https://github.com/marqo-ai/marqo/pull/538). Only fields in `tensor_fields` will have embeddings generated, offering more granular control over which fields are vectorised. See [here](https://docs.marqo.ai/1.0.0/API-Reference/documents/#add-or-replace-documents) for the full list of `add_documents` parameters and their usage. The `non_tensor_fields` parameter is deprecated and will be removed in a future release. Calls to `add_documents` with neither of these parameters specified will now fail.\n\n- Multiple tensor field optimisation ([#530](https://github.com/marqo-ai/marqo/pull/530)). This optimisation results in faster and more stable searches across multiple tensor fields. Please note that indexed documents will now have a different internal document structure, so documents indexed with previous Marqo versions cannot be searched with this version, and vice versa.\n\n- The `add_documents` endpoint's request body is now an object, with the list of documents under the `documents` key ([#535](https://github.com/marqo-ai/marqo/pull/535)). The query parameters `use_existing_tensors`, `image_download_headers`, `model_auth`, and `mappings` have been moved to the body as optional keys, and support for these parameters in the query string is deprecated. This change results in shorter URLs and better readability, as values for these parameters no longer need to be URL-encoded. See [here](https://docs.marqo.ai/1.0.0/API-Reference/documents/#add-or-replace-documents) for the new `add_documents` API usage. Backwards compatibility is supported at the moment but will be removed in a future release.\n\n- Better validation for index creation with custom models (https://github.com/marqo-ai/marqo/pull/530). When creating an index with a `model` not in the registry, Marqo will check if `model_properties` is specified with a proper `dimension`, and raise an error if not. See [here](https://docs.marqo.ai/1.0.0/Models-Reference/bring_your_own_model) for a guide on using custom models. This validation is now done at index creation time, rather than at add documents or search time.\n\n- Stricter `filter_string` syntax for `search` ([#530](https://github.com/marqo-ai/marqo/pull/530)). The `filter_string` parameter must have special Lucene characters escaped with a backslash (`\\`) to filter as expected. This will affect filtering on field names or content that contains special characters. See [here](https://lucene.apache.org/core/2_9_4/queryparsersyntax.html) for more information on special characters and see [here](https://docs.marqo.ai/1.0.0/query_dsl) for a guide on using Marqo filter strings.\n\n- Removed server-side batching (`batch_size` parameter) for the `add_documents` endpoint ([#527](https://github.com/marqo-ai/marqo/pull/527)). Instead, client-side batching is encouraged (use `client_batch_size` instead of `server_batch_size` in the python client).\n\n## New Features\n- Multi-field pagination ([#530](https://github.com/marqo-ai/marqo/pull/530)). The `offset` parameter in `search` can now be used to paginate through results spanning multiple `searchable_attributes`. This works for both `TENSOR` and `LEXICAL` search. See [here](https://docs.marqo.ai/1.0.0/API-Reference/search/#search-result-pagination) for a guide on pagination.\n- Optimised default index configuration (https://github.com/marqo-ai/marqo/pull/540).\n\n## Bug Fixes & Minor Changes\n- Removed or updated all references to outdated features in the examples and the README (https://github.com/marqo-ai/marqo/pull/529).\n- Enhanced bulk search test stability (https://github.com/marqo-ai/marqo/pull/544).\n\n## Contributor shout-outs\n- Thank you to our 3.2k stargazers!\n- We've finally come to our first major release, Marqo 1.0.0! Thanks to all our users and contributors, new and old, for your feedback and support to help us reach this huge milestone. We're excited to continue building Marqo with you. Happy searching!\n\n\n# Release 0.1.0\n\n## New features\n- Telemetry. Marqo now includes various timing metrics for the `search`, `bulk_search` and `add_documents` endpoints\nwhen the query parameter `telemetry=True` is specified (https://github.com/marqo-ai/marqo/pull/506). The metrics will be\nreturned in the response body and provide a breakdown of latencies for various stages of the API call.\n- Consolidate default device to CUDA when available (https://github.com/marqo-ai/marqo/pull/508). By default,\nMarqo now uses CUDA devices for search and indexing if available.\nSee [here](https://docs.marqo.ai/0.1.0/API-Reference/search/#query-parameters) for more information. This helps ensure\nyou get the best indexing and search experience without having to explicitly add the device parameter to search and\nadd_documents calls.\n- Model download integrity verification (https://github.com/marqo-ai/marqo/pull/502). Model files are validated and\nremoved if corrupted during download. This helps ensure that models are not loaded if they are corrupted.\n\n## Breaking changes\n- Remove deprecated `add_or_update_documents` endpoint (https://github.com/marqo-ai/marqo/pull/517).\n- Disable automatic index creation. Marqo will no longer automatically create an index if it does not exist \n(https://github.com/marqo-ai/marqo/pull/516).\nAttempting to add documents to a non-existent index will now result in an error. This helps provide more certainty about\nthe properties of the index you are adding documents to, and also helps prevent accidental indexing to the wrong index.\n- Remove parallel indexing (https://github.com/marqo-ai/marqo/pull/523). Marqo no longer supports server-side parallel\nindexing. This helps deliver a more stable and efficient indexing experience. Parallelisation can still be implemented\nby the user.\n\n## Bug fixes and minor changes\n- Improve error messages (https://github.com/marqo-ai/marqo/pull/494, https://github.com/marqo-ai/marqo/pull/499).\n- Improve API request validation (https://github.com/marqo-ai/marqo/pull/495).\n- Add new multimodal search example (https://github.com/marqo-ai/marqo/pull/503).\n- Remove autocast for CPU to speed up vectorisation on ARM64 machines (https://github.com/marqo-ai/marqo/pull/491).\n- Enhance test stability (https://github.com/marqo-ai/marqo/pull/514).\n- Ignore `.kibana` index (https://github.com/marqo-ai/marqo/pull/512).\n- Improve handling of whitespace when indexing documents (https://github.com/marqo-ai/marqo/pull/521).\n- Update CUDA version to 11.4.3 (https://github.com/marqo-ai/marqo/pull/525).\n\n## Contributor shout-outs\n- Thank you to our 3.1k stargazers!\n\n# Release 0.0.21\n\n## New features\n- Load custom SBERT models from cloud storage with authentication (https://github.com/marqo-ai/marqo/pull/474). \nMarqo now supports fetching your fine-tuned public and private SBERT models from Hugging Face and AWS s3. Learn more about using your own SBERT model [here](https://docs.marqo.ai/0.0.21/Models-Reference/bring_your_own_model/#bring-your-own-hugging-face-sbert-models). For instructions on loading a private model using authentication, check\n[model auth during search](https://docs.marqo.ai/0.0.19/API-Reference/search/#model-auth) and \n[model auth during add_documents](https://docs.marqo.ai/0.0.19/API-Reference/documents/#model-auth).\n\n- Bulk search score modifier and context vector support (https://github.com/marqo-ai/marqo/pull/469). \nSupport has been added for [score modifiers](https://docs.marqo.ai/0.0.21/API-Reference/search/#score-modifiers) \nand [context vectors](https://docs.marqo.ai/0.0.21/API-Reference/search/#context) to our bulk search API. \nThis can help enhance throughput and performance for certain workloads. Please see [documentation](https://docs.marqo.ai/0.0.21/API-Reference/bulk/) for usage. \n\n## Bug fixes and minor changes\n- README enhancements (https://github.com/marqo-ai/marqo/pull/482, https://github.com/marqo-ai/marqo/pull/481).\n\n## Contributor shout-outs\n- A special thank you to our 3.0k stargazers!\n\n\n# Release 0.0.20\n\n## New features\n- Custom model pre-loading (https://github.com/marqo-ai/marqo/pull/475). Public CLIP and OpenCLIP models specified by URL can now be loaded on Marqo startup via the `MARQO_MODELS_TO_PRELOAD` environment variable. These must be formatted as JSON objects with `model` and `model_properties`.\n  See [here (configuring pre-loaded models)](https://marqo.pages.dev/0.0.20/Advanced-Usage/configuration/#configuring-preloaded-models) for usage.\n\n## Bug fixes and minor changes\n- Fixed arm64 build issue caused by package version conflicts (https://github.com/marqo-ai/marqo/pull/478)\n\n\n# Release 0.0.19\n\n## New features\n- Model authorisation(https://github.com/marqo-ai/marqo/pull/460). Non-public OpenCLIP and CLIP models can now be loaded \n  from Hugging Face and AWS s3 via the `model_location` settings object and `model_auth`. \n  See [here (model auth during search)](https://docs.marqo.ai/0.0.19/API-Reference/search/#model-auth)\n  and [here (model auth during add_documents)](https://docs.marqo.ai/0.0.19/API-Reference/documents/#model-auth) for usage.\n- Max replicas configuration (https://github.com/marqo-ai/marqo/pull/465). \n  Marqo admins now have more control over the max number of replicas that can be set for indexes on the Marqo instance.\n  See [here](https://docs.marqo.ai/0.0.19/Advanced-Usage/configuration/#configuring-usage-limits) for how to configure this.\n\n## Breaking changes\n- Marqo now allows for a maximum of 1 replica per index by default (https://github.com/marqo-ai/marqo/pull/465).\n\n## Bug fixes and minor changes\n- README improvements (https://github.com/marqo-ai/marqo/pull/468)\n- OpenCLIP version bumped (https://github.com/marqo-ai/marqo/pull/461)\n- Added extra tests (https://github.com/marqo-ai/marqo/pull/464/)\n- Unneeded files are now excluded in Docker builds (https://github.com/marqo-ai/marqo/pull/448, https://github.com/marqo-ai/marqo/pull/426)\n\n## Contributor shout-outs\n- Thank you to our 2.9k stargazers!\n- Thank you to community members for the increasingly exciting discussions on our Slack channel. \n  Feedback, questions and hearing about use cases helps us build a great open source product.\n- Thank you to [@jalajk24](https://github.com/jalajk24) for the PR to exclude unneeded files from Docker builds!\n\n\n# Release 0.0.18\n\n## New features\n- New E5 model type is available (https://github.com/marqo-ai/marqo/pull/419). E5 models are state of the art general-purpose text embedding models that obtained the best results on the MTEB benchmark when released in Dec 2022. Read more about these models [here](https://docs.marqo.ai/0.0.18/Models-Reference/dense_retrieval/#text).\n- Automatic model ejection (https://github.com/marqo-ai/marqo/pull/372). Automatic model ejection helps prevent out-of-memory (OOM) errors on machines with a larger amount of CPU memory (16GB+) by ejecting the least recently used model. \n- Speech processing article and example (https://github.com/marqo-ai/marqo/pull/431). [@OwenPendrighElliott](https://github.com/OwenPendrighElliott) demonstrates how you can build and query a Marqo index from audio clips. \n\n## Optimisations \n- Delete optimisation (https://github.com/marqo-ai/marqo/pull/436). The `/delete` endpoint can now handle a higher volume of requests.\n- Inference calls can now execute in batches, with batch size configurable by an environment variable (https://github.com/marqo-ai/marqo/pull/376).\n\n## Bug fixes and minor changes\n- Configurable max value validation for HNSW graph parameters (https://github.com/marqo-ai/marqo/pull/424). See [here](https://docs.marqo.ai/0.0.18/Advanced-Usage/configuration/#other-configurations) for how to configure.\n- Configurable maximum number of tensor search attributes (https://github.com/marqo-ai/marqo/pull/430). See [here](https://docs.marqo.ai/0.0.18/Advanced-Usage/configuration/#other-configurations) for how to configure.\n- Unification of vectorise output type (https://github.com/marqo-ai/marqo/pull/432)\n- Improved test pipeline reliability (https://github.com/marqo-ai/marqo/pull/438, https://github.com/marqo-ai/marqo/pull/439)\n- Additional image download tests (https://github.com/marqo-ai/marqo/pull/402, https://github.com/marqo-ai/marqo/pull/442)\n- Minor fix in the Iron Manual example (https://github.com/marqo-ai/marqo/pull/440)\n- Refactored HTTP requests wrapper (https://github.com/marqo-ai/marqo/pull/367)\n\n## Contributor shout-outs\n- Thank you to our 2.8k stargazers!\n- Thank you community members raising issues and discussions in our Slack channel. \n- Thank you [@jess-lord](https://github.com/jess-lord) and others for raising issues\n\n# Release 0.0.17 \n\n## New features\n- New parameters that allow tweaking of Marqo indexes' underlying HNSW graph. `ef_construction` and `m`  can be defined at index time (https://github.com/marqo-ai/marqo/pull/386, https://github.com/marqo-ai/marqo/pull/420, https://github.com/marqo-ai/marqo/pull/421), giving you more control over the relevancy/speed tradeoff. See usage and more details [here](https://docs.marqo.ai/0.0.17/API-Reference/indexes/#example_1).\n- Score modification fields (https://github.com/marqo-ai/marqo/pull/414). Rank documents using knn similarity in addition to document metadata ( https://github.com/marqo-ai/marqo/pull/414). This allows integer or float fields from a document to bias a document's score during the knn search and allows additional ranking signals to be used. Use cases include giving more reputable documents higher weighting and de-duplicating search results. See usage [here](https://docs.marqo.ai/0.0.17/API-Reference/search/#score-modifiers).\n\n## Bug fixes and minor changes\n- Added validation for unknown parameters during bulk search (https://github.com/marqo-ai/marqo/pull/413).\n- Improved concurrency handling when adding documents to an index as it's being deleted (https://github.com/marqo-ai/marqo/pull/407).\n- Better error messages for multimodal combination fields (https://github.com/marqo-ai/marqo/pull/395).\n- Examples of recently added features added to README (https://github.com/marqo-ai/marqo/pull/403).\n\n## Contributor shout-outs\n- Thank you to our 2.6k stargazers.\n- Thank you to [@anlrde](https://github.com/anlrde), [@strich](https://github.com/strich), [@feature-hope](https://github.com/feature-hope), [@bazuker](https://github.com/bazuker) for raising issues!\n\n\n## Release 0.0.16\n\n## New features\n- Bulk search (https://github.com/marqo-ai/marqo/pull/363, https://github.com/marqo-ai/marqo/pull/373). \nConduct multiple searches with just one request. This improves search throughput in Marqo by parallelising multiple search queries in a single API call. \nThe average search time can be decreased up to 30%, depending on your devices and models. \nCheck out the usage guide [here](https://docs.marqo.ai/0.0.16/API-Reference/bulk)\n- Configurable number of index replicas (https://github.com/marqo-ai/marqo/pull/391). \nYou can now configure how many replicas to make for an index in Marqo using the `number_of_replicas` parameter. Marqo makes 1 replica by default.\nWe recommend having at least one replica to prevent data loss.\nSee the usage guide [here](https://docs.marqo.ai/0.0.16/API-Reference/indexes/#body-parameters)\n- Use your own vectors during searches (https://github.com/marqo-ai/marqo/pull/381). Use your own vectors as context for your queries. \nYour vectors will be incorporated into the query using a weighted sum approach, \nallowing you to reduce the number of inference requests for duplicated content.\nCheck out the usage guide [here](https://docs.marqo.ai/0.0.16/API-Reference/search/#context)\n\n## Bug fixes and minor changes\n- Fixed a bug where some Open CLIP models were unable to load checkpoints from the cache (https://github.com/marqo-ai/marqo/pull/387).\n- Fixed a bug where multimodal search vectors are not combined based on expected weights (https://github.com/marqo-ai/marqo/pull/384).\n- Fixed a bug where multimodal document vectors are not combined in an expected way. `numpy.sum` was used rather than `numpy.mean`.  (https://github.com/marqo-ai/marqo/pull/384).\n- Fixed a bug where an unexpected error is thrown when `using_existing_tensor = True` and documents are added with duplicate IDs (https://github.com/marqo-ai/marqo/pull/390).\n- Fixed a bug where the index settings validation did not catch the `model` field if it is in the incorrect part of the settings json (https://github.com/marqo-ai/marqo/pull/365).\n- Added missing descriptions and requirement files on our [GPT-examples](https://github.com/marqo-ai/marqo/tree/mainline/examples/GPT-examples) (https://github.com/marqo-ai/marqo/pull/349).  \n- Updated the instructions to start Marqo-os (https://github.com/marqo-ai/marqo/pull/371).\n- Improved the Marqo start-up time by incorporating the downloading of the punkt tokenizer into the dockerfile (https://github.com/marqo-ai/marqo/pull/346).\n\n## Contributor shout-outs\n- Thank you to our 2.5k stargazers.\n- Thank you to [@ed-muthiah](https://github.com/ed-muthiah) for submitting a PR (https://github.com/marqo-ai/marqo/pull/349) \nthat added missing descriptions and requirement files on our [GPT-examples](https://github.com/marqo-ai/marqo/tree/mainline/examples/GPT-examples).\n\n# Release 0.0.15\n\n## New features \n- Multimodal tensor combination (https://github.com/marqo-ai/marqo/pull/332, https://github.com/marqo-ai/marqo/pull/355). Combine image and text data into a single vector! Multimodal combination objects can be added as Marqo document fields. For example, this can be used to encode text metadata into image vectors. See usage [here](https://docs.marqo.ai/0.0.15/Advanced-Usage/document_fields/#multimodal-combination-object).\n\n## Bug fixes\n- Fixed a bug that prevented CLIP's device check from behaving as expected (https://github.com/marqo-ai/marqo/pull/337)\n- CLIP utils is set to use the OpenCLIP default tokenizer so that long text inputs are truncated correctly (https://github.com/marqo-ai/marqo/pull/351). \n\n## Contributor shout-outs:\n- Thank you to our 2.4k stargazers\n- Thank you to [@ed-muthiah](https://github.com/ed-muthiah), [@codebrain](https://github.com/codebrain) and others for raising issues.\n\n\n# Release 0.0.14\n\n## New features \n- `use_existing_tensors` flag, for `add_documents` (https://github.com/marqo-ai/marqo/pull/335). Use existing Marqo tensors to autofill unchanged tensor fields, for existing documents. This lets you quickly add new metadata while minimising inference operations. See usage [here](https://docs.marqo.ai/0.0.14/API-Reference/documents/#query-parameters).\n- `image_download_headers` parameter for `search` and `add_documents` (https://github.com/marqo-ai/marqo/pull/336). Index and search non-publicly available images. Add image download auth information to `add_documents` and `search` requests. See usage [here](https://docs.marqo.ai/0.0.14/API-Reference/image_downloads/).\n\n## Optimisations\n- The index cache is now updated on intervals of 2 seconds (https://github.com/marqo-ai/marqo/pull/333), rather than on every search. This reduces the pressure on Marqo-OS, allowing for greater search and indexing throughput. \n\n## Bug fixes\n- Helpful validation errors for invalid index settings (https://github.com/marqo-ai/marqo/pull/330). Helpful error messages allow for a smoother getting-started experience. \n- Automatic precision conversion to `fp32` when using `fp16` models on CPU (https://github.com/marqo-ai/marqo/pull/331). \n- Broadening of the types of image download errors gracefully handled. (https://github.com/marqo-ai/marqo/pull/321)\n\n\n# Release 0.0.13\n\n## New features\n- Support for custom CLIP models using the OpenAI and OpenCLIP architectures (https://github.com/marqo-ai/marqo/pull/286). Read about usage [here](https://docs.marqo.ai/0.0.13/Models-Reference/dense_retrieval/#generic-clip-models).\n- Concurrency throttling (https://github.com/marqo-ai/marqo/pull/304). Configure the number of allowed concurrent indexing and search threads. Read about usage [here](https://docs.marqo.ai/0.0.13/Advanced-Usage/configuration/#configuring-throttling).\n- Configurable logging levels (https://github.com/marqo-ai/marqo/pull/314). Adjust log output for your debugging/log storage needs. See how to configure log level [here](https://docs.marqo.ai/0.0.13/Advanced-Usage/configuration/#configuring-log-level).\n- New array datatype (https://github.com/marqo-ai/marqo/pull/312). You can use these arrays as a collection of tags to filter on! See usage [here](https://docs.marqo.ai/0.0.13/Advanced-Usage/document_fields/#array).\n- Boost tensor fields during search (https://github.com/marqo-ai/marqo/pull/300). Weight fields as higher and lower relative to each other during search. Use this to get a mix of results that suits your use case. See usage [here](https://docs.marqo.ai/0.0.13/API-Reference/search/#boost).\n- Weighted multimodal queries (https://github.com/marqo-ai/marqo/pull/307). You can now search with a dictionary of weighted queries. If searching an image index, these queries can be a weighted mix of image URLs and text. See usage [here](https://docs.marqo.ai/0.0.13/API-Reference/search/#query-q).\n- New GPT-Marqo integration [example](https://github.com/marqo-ai/marqo/tree/mainline/examples/GPT-examples) and [article](https://www.marqo.ai/blog/from-iron-manual-to-ironman-augmenting-gpt-with-marqo-for-fast-editable-memory-to-enable-context-aware-question-answering). Turn your boring user manual into a question-answering bot, with an optional persona, with GPT + Marqo!\n- Added new OpenCLIP models to Marqo (https://github.com/marqo-ai/marqo/pull/299)\n\n## Optimisations\n- Concurrent image downloads (https://github.com/marqo-ai/marqo/pull/281, https://github.com/marqo-ai/marqo/pull/311)\n- Blazingly fast `fp16` ViT CLIP models (https://github.com/marqo-ai/marqo/pull/286). See usage [here](https://docs.marqo.ai/0.0.13/Models-Reference/dense_retrieval/#openai-float16)\n- Reduction of data transfer between Marqo and Marqo-os (https://github.com/marqo-ai/marqo/pull/300)\n- We see a 3.0x indexing speedup, and a 1.7x search speedup, using the new `fp16/ViT-L/14` CLIP model, compared to the previous release using `ViT-L/14`.  \n\n## Bug fixes \n- Fixed 500 error when creating an index while only specifying `number_of_shards`(https://github.com/marqo-ai/marqo/pull/293)\n- Fixed model cache management no parsing reranker model properties properly (https://github.com/marqo-ai/marqo/pull/308)  \n\n## Contributor shout-outs\n- Thank you to our 2.3k stargazers\n- Thank you to [@codebrain](https://github.com/codebrain) and others for raising issues.\n\n\n# Release 0.0.12\n\n## New features\n- Multilingual CLIP (https://github.com/marqo-ai/marqo/pull/267). Search images in the language you want! Marqo now incorporates [open source multilingual CLIP models](https://github.com/FreddeFrallan/Multilingual-CLIP). A list of available multilingual CLIP models are available [here](https://docs.marqo.ai/0.0.12/Models-Reference/dense_retrieval/#multilingual-clip). \n- Exact text matching (https://github.com/marqo-ai/marqo/pull/243, https://github.com/marqo-ai/marqo/pull/288). Search for specific words and phrases using double quotes (`\" \"`) in lexical search. See usage [here](https://docs.marqo.ai/0.0.12/API-Reference/search/#lexical-search-exact-matches).  \n\n## Optimisations \n- Search speed-up (https://github.com/marqo-ai/marqo/pull/278). Latency reduction from Marqo-os indexes reconfigurations. \n\n## Contributor shout-outs\nThank you to our 2.2k stargazers and 80+ forkers!\n\n# Release 0.0.11\n\n## New features \n- Pagination (https://github.com/marqo-ai/marqo/pull/251). Navigate through pages of results. Provide an extensive end-user search experience without having to keep results in memory! See usage [here](https://docs.marqo.ai/0.0.11/API-Reference/search/#search-result-pagination) \n- The `/models` endpoint (https://github.com/marqo-ai/marqo/pull/239). View what models are loaded, and on what device. This lets Marqo admins examine loaded models and prune unneeded ones. See usage [here](https://docs.marqo.ai/0.0.11/API-Reference/models/)\n- The `/device` endpoint (https://github.com/marqo-ai/marqo/pull/239). See resource usage for the machine Marqo is running on. This helps Marqo admins manage resources on remote Marqo instances. See usage [here](https://docs.marqo.ai/0.0.11/API-Reference/device/)\n- The index settings endpoint (`/indexes/{index_name}/settings`)(https://github.com/marqo-ai/marqo/pull/248). See the model and parameters used by each index. See usage [here](https://docs.marqo.ai/0.0.11/API-Reference/settings/). \n- Latency log outputs (https://github.com/marqo-ai/marqo/pull/242). Marqo admins have better transparency about the latencies for each step of the Marqo indexing and search request pipeline\n- ONNX CLIP models are now available (https://github.com/marqo-ai/marqo/pull/245). Index and search images in Marqo with CLIP models in the faster, and open, ONNX format - created by Marqo's machine learning team. These ONNX CLIP models give Marqo up to a 35% speedup over standard CLIP models. These ONNX CLIP models are open sourced by Marqo. Read about usage [here](https://docs.marqo.ai/0.0.11/Models-Reference/dense_retrieval/#onnx-clip).\n- New simple [image search](https://github.com/marqo-ai/marqo/blob/mainline/examples/ImageSearchGuide/ImageSearchGuide.md) guide (https://github.com/marqo-ai/marqo/pull/253, https://github.com/marqo-ai/marqo/pull/263). \n\n\n## Contributor shout-outs\n- ⭐️ We've just hit over 2.1k GitHub stars! ⭐️ So an extra special thanks to our stargazers and contributors who make Marqo possible. \n\n# Release 0.0.10\n\n## New features \n- Generic model support (https://github.com/marqo-ai/marqo/pull/179). Create an index with your favourite SBERT-type models from HuggingFace! Read about usage [here](https://marqo.pages.dev/0.0.10/Models-Reference/dense_retrieval/#generic-models)\n- Visual search update 2. (https://github.com/marqo-ai/marqo/pull/214). Search-time image reranking and open-vocabulary localization, based on users' queries, is now available with the Owl-ViT model. **Locate the part of the image corresponding to your query!** Read about usage [here](https://docs.marqo.ai/0.0.10/Models-Reference/reranking/) \n- Visual search update 1. (https://github.com/marqo-ai/marqo/pull/214). Better image patching. In addition to faster-rcnn, you can now use yolox or attention based (DINO) region proposal as a patching method at indexing time. This allows localization as the sub patches of the image can be searched. Read about usage [here](https://docs.marqo.ai/0.0.10/Preprocessing/Images/). \n\nCheck out [this article](https://medium.com/@jesse_894/image-search-with-localization-and-open-vocabulary-reranking-using-marqo-yolox-clip-and-owl-vit-9c636350bf66) about how this update makes image search awesome.\n\n## Bug fixes\n- Fixed imports and outdated Python client usage in Wikipedia demo (https://github.com/marqo-ai/marqo/pull/216) \n\n## Contributor shout-outs\n- Thank you to [@georgewritescode](https://github.com/georgewritescode) for debugging and updating the Wikipedia demo\n- Thank you to our 1.8k stargazers and 60+ forkers!\n\n\n# Release 0.0.9\n## Optimisations \n- Set k to limit to for Marqo-os search queries (https://github.com/marqo-ai/marqo/pull/219)\n- Reduced the amount of metadata returned from Marqo-os, on searches (https://github.com/marqo-ai/marqo/pull/218)\n\n## Non-breaking data model changes\n- Set default kNN m value to 16 (https://github.com/marqo-ai/marqo/pull/222)\n\n## Bug fixes\n- Better error messages when downloading an image fails (https://github.com/marqo-ai/marqo/pull/198)\n- Bug where filtering wouldn't work on fields with spaces (https://github.com/marqo-ai/marqo/pull/213), resolving https://github.com/marqo-ai/marqo/issues/115\n\n\n# Release 0.0.8\n\n## New features\n- Get indexes endpoint: `GET /indexes` ([#181](https://github.com/marqo-ai/marqo/pull/181)). Use this endpoint to inspect\nexisting Marqo indexes. \nRead about usage [here](https://docs.marqo.ai/API-Reference/indexes/#list-indexes).\n- Non-tensor fields([#161](https://github.com/marqo-ai/marqo/pull/161)). \nDuring the indexing phase, mark fields as non-tensor to prevent tensors being created for them. \nThis helps speed up indexing and reduce storage for fields where keyword search is good enough. For example: email, name \nand categorical fields. These fields can still be used for filtering. \nRead about usage [here](https://docs.marqo.ai/API-Reference/documents/#query-parameters).\n- Configurable preloaded models([#155](https://github.com/marqo-ai/marqo/pull/155)).\nSpecify which machine learning model to load as Marqo starts. This prevents a delay during initial search and index commands after \nMarqo starts. Read about usage [here](https://docs.marqo.ai/Advanced-Usage/configuration/#preloading-models).\n- New [example](https://github.com/marqo-ai/marqo/tree/mainline/examples/GPT3NewsSummary) \nand [article](https://medium.com/creator-fund/building-search-engines-that-think-like-humans-e019e6fb6389): \nuse Marqo to provide context for up-to-date GPT3 news summary generation \n([#171](https://github.com/marqo-ai/marqo/pull/171), [#174](https://github.com/marqo-ai/marqo/pull/174)).\nSpecial thanks to [@iain-mackie](https://github.com/iain-mackie) for this example. \n\n## Bug fixes and minor changes\n- Updated developer guide ([#164](https://github.com/marqo-ai/marqo/pull/164))\n- Updated requirements which prevented Marqo being built as an arm64 image ([#173](https://github.com/marqo-ai/marqo/pull/173))\n- Backend updated to use marqo-os:0.0.3 ([#183](https://github.com/marqo-ai/marqo/pull/183))\n- Default request timeout has been increased from 2 to 75 seconds ([#184](https://github.com/marqo-ai/marqo/pull/184))\n\n## Contributor shout-outs\n- For work on the GPT3 news summary generation example: [@iain-mackie](https://github.com/iain-mackie)\n- For contributing the non-tensor fields feature: [@jeadie](https://github.com/jeadie)\n- Thank you to our users who raise issues and give us valuable feeback  \n- Thank you to our 1.4k+ star gazers and 50+ forkers!\n\n# Release 0.0.7\n\n## Bug fixes and minor changes\n- 429 (too many request errors) are propagated from Marqo-os to the user properly ([#150](https://github.com/marqo-ai/marqo/pull/150))\n\n# Release 0.0.6\n\n## New features\n- Health check endpoint: `GET /health`. An endpoint that can be used to inspect the status of Marqo and Marqo's backend (Marqo-os) \n([#128](https://github.com/marqo-ai/marqo/pull/128)). Read about usage [here](https://docs.marqo.ai/API-Reference/health/).\n- Marqo can be launched with environment variables that define limits around maximum number of fields per index, maximum document size and the maximum number of documents that can be retrieved \n([#135](https://github.com/marqo-ai/marqo/pull/135)). Read about usage [here](https://docs.marqo.ai/Advanced-Usage/configuration/).\n- README translations: \n  - Chinese 🇨🇳 (by [@wanliAlex](https://github.com/wanliAlex), [#133](https://github.com/marqo-ai/marqo/pull/133))\n  - Polish 🇵🇱 (by [@MichalLuck](https://github.com/MichalLuck), [#136](https://github.com/marqo-ai/marqo/pull/136))\n  - Ukrainian 🇺🇦 (by [@dmyzlata](https://github.com/dmyzlata), [#138](https://github.com/marqo-ai/marqo/pull/138))\n  - French 🇫🇷 (by [@rym-oualha](https://github.com/rym-oualha), [#147](https://github.com/marqo-ai/marqo/pull/147))\n\n## Breaking API changes\n- The home `/` json response has been updated. If you have logic that reads the endpoint root, please update it ([#128](https://github.com/marqo-ai/marqo/pull/128)). \n- The Python client's `add_documents()` and `update_documents()` `batch_size` parameter has been replaced by `server_batch_size` and `client_batch_size` parameters \n([py-marqo#27](https://github.com/marqo-ai/py-marqo/pull/27)), ([py-marqo#28](https://github.com/marqo-ai/py-marqo/pull/28))\n\n## Non-breaking data model changes\n- Each text field just creates a top level Marqo-os text field, without any keywords \n([#135](https://github.com/marqo-ai/marqo/pull/135))\n- Very large fields get their tensor_facet keywords ignored, rather than Marqo-OS preventing the doc being indexed\n([#135](https://github.com/marqo-ai/marqo/pull/135))\n- Tensor facets can no longer have _id as a filtering field\n([#135](https://github.com/marqo-ai/marqo/pull/135))\n\n## Bug fixes and minor changes\n- FastAPI runs with better concurrency ([#128](https://github.com/marqo-ai/marqo/pull/128))\n- Get documents by IDs and lexical search and no longer returns vectors if expose_facets isn't specified\n- Fixed batching bug in Python client\n([py-marqo#28](https://github.com/marqo-ai/py-marqo/pull/28))\n\n## Caveats\n- If a large request to add_documents or update_documents results in a document adding fields such that the index field limit is exceeded, the entire operation will fail (without resilience). Mitigate this sending `add_documents` and `update_documents` requests with smaller batches of documents. \n- For optimal indexing of large volumes of images, we recommend that the images are hosted on the same region and cloud provider as Marqo.\n\n## Contributor shout-outs\n\n- For their translation work: [@rym-oualha](https://github.com/rym-oualha), [@dmyzlata](https://github.com/dmyzlata), [@wanliAlex](https://github.com/wanliAlex), [@dmyzlata](https://github.com/dmyzlata), [@MichalLuck](https://github.com/MichalLuck)\n- For raising issues and helping with READMEs: [@kdewald](https://github.com/kdewald), [@llermaly](https://github.com/llermaly), [@namit343](https://github.com/namit343)\n- Thank you to our 900+ star gazers and 30+ forkers\n\n\n# Release 0.0.5\n<!--SMALL BLURB ABOUT RELEASE-->\nAdded Open CLIP models and added features to the get document endpoint.\n\n## New features\n<!--NON BREAKING CHANGES GO HERE-->\n- Added Open CLIP models ([#116](https://github.com/marqo-ai/marqo/pull/116)). \nRead about usage [here](https://marqo.pages.dev/Models-Reference/dense_retrieval/#open-clip)\n- Added the ability to get multiple documents by ID \n([#122](https://github.com/marqo-ai/marqo/pull/122)). \nRead about usage [here](https://marqo.pages.dev/API-Reference/documents/#get-multiple-documents)\n- Added the ability to get document tensor facets through the get document endpoint \n([#122](https://github.com/marqo-ai/marqo/pull/122)). \nRead about usage [here](https://marqo.pages.dev/API-Reference/documents/#example_2)\n\n# Release 0.0.4\n\n<!--SMALL BLURB ABOUT RELEASE-->\nAdding the attributesToRetrieve to the search endpoint and added the update documents endpoints\n\n## New features\n<!--NON BREAKING CHANGES GO HERE-->\n- Added the AttributesToRetrieve option to the search endpoint ([55e5ac6](https://github.com/marqo-ai/marqo/pull/103))\n- Added the PUT documents endpoint ([ce1306a](https://github.com/marqo-ai/marqo/pull/117))\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 1.3515625,
          "content": "# Security\n\nMarqo takes the security of our software products and services seriously.\n\nIf you believe you have found a security vulnerability in any Marqo repository, please report it to us as described below.\n\n## Supported versions\n\nOnly the latest version of Marqo will be supported with security updates.\n\n## Reporting security issues\n\n⚠️ Please do not report security vulnerabilities through public GitHub issues. ⚠️\n\nInstead, please email us at support@marqo.ai\n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n- Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n- Full paths of source file(s) related to the manifestation of the issue\n- The location of the affected source code (tag/branch/commit or direct URL)\n- Any special configuration required to reproduce the issue\n- Step-by-step instructions to reproduce the issue\n- Proof-of-concept or exploit code (if possible)\n- Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nYou will receive a response from us within 72 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity.\n\n## Preferred languages\n\nWe prefer all communications to be in English.\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "perf_tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.08203125,
          "content": "[build-system]\nrequires = [\"setuptools>=42\"]\nbuild-backend = \"setuptools.build_meta\""
        },
        {
          "name": "requirements.dev.txt",
          "type": "blob",
          "size": 0.12890625,
          "content": "# test requirements\npyvespa==0.37.1\npytest==8.3.4\npytest-cov==6.0.0\ndiff-cover==9.2.0\npytest-md-report==0.6.2\npytest-asyncio==0.23.8"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.1181640625,
          "content": "# Marqo's requirements files are stored in marqo-base repo: https://github.com/marqo-ai/marqo-base/tree/main/requirements"
        },
        {
          "name": "run_marqo.sh",
          "type": "blob",
          "size": 5.3017578125,
          "content": "#!/bin/bash\n#source /opt/bash-utils/logger.sh\nexport PYTHONPATH=\"${PYTHONPATH}:/app/src/\"\nif [ -z \"${MARQO_CUDA_PATH}\" ]; then\n    export CUDA_HOME=/usr/local/cuda\nelse\n    export CUDA_HOME=${MARQO_CUDA_PATH}\nfi\nexport LD_LIBRARY_PATH=${CUDA_HOME}/lib64\nexport PATH=${CUDA_HOME}/bin:${PATH}\n\ntrap \"bash /app/scripts/shutdown.sh; exit\" SIGTERM SIGINT\n\nfunction wait_for_process () {\n    local max_retries=30\n    local n_restarts_before_sigkill=3\n    local process_name=\"$1\"\n    local retries=0\n    while ! [[ $(docker ps -a | grep CONTAINER) ]] >/dev/null && ((retries < max_retries)); do\n        echo \"Process $process_name is not running yet. Retrying in 1 seconds\"\n        echo \"Retry $retries of a maximum of $max_retries retries\"\n        ((retries=retries+1))\n        if ((retries >= n_restarts_before_sigkill)); then\n            echo \"sending SIGKILL to dockerd and restarting \"\n            ps axf | grep docker | grep -v grep | awk '{print \"kill -9 \" $1}' | sh; rm /var/run/docker.pid; dockerd &\n        else\n            dockerd &\n        fi\n        sleep 3\n        if ((retries >= max_retries)); then\n            return 1\n        fi\n    done\n    return 0\n}\n\n\nVESPA_IS_INTERNAL=False\n# Vespa local run\nif ([ -n \"$VESPA_QUERY_URL\" ] || [ -n \"$VESPA_DOCUMENT_URL\" ] || [ -n \"$VESPA_CONFIG_URL\" ]) && \\\n   ([ -z \"$VESPA_QUERY_URL\" ] || [ -z \"$VESPA_DOCUMENT_URL\" ] || [ -z \"$VESPA_CONFIG_URL\" ]); then\n  echo \"Error: Partial external vector store configuration detected. \\\nPlease provide all or none of the VESPA_QUERY_URL, VESPA_DOCUMENT_URL, VESPA_CONFIG_URL. \\\nSee https://docs.marqo.ai/2.0.0/Guides/Advanced-Usage/configuration/ for more information\"\n  exit 1\n\nelif [ -z \"$VESPA_QUERY_URL\" ] && [ -z \"$VESPA_DOCUMENT_URL\" ] && [ -z \"$VESPA_CONFIG_URL\" ]; then\n  # Start local vespa\n  echo \"External vector store not configured. Using local vector store\"\n  chown -R vespa:vespa /opt/vespa/var/\n  tmux new-session -d -s vespa \"bash /usr/local/bin/start_vespa.sh\"\n\n  echo \"Waiting for vector store to start\"\n  for i in {1..5}; do\n    if [ $i -eq 1 ]; then\n      suffix=\"second\"\n    else\n      suffix=\"seconds\"\n    fi\n    echo -ne \"Waiting... $i $suffix\\r\"\n    sleep 1\n  done\n\n  # Try to deploy the application and branch on the output\n  END_POINT=\"http://localhost:19071/application/v2/tenant/default/application/default\"\n  MAX_RETRIES=10\n  RETRY_COUNT=0\n\n  while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n    # Make the curl request and capture the output\n    RESPONSE=$(curl -s -X GET \"$END_POINT\")\n\n    # Check for the specific \"not found\" error response which indicates there is no application package deployed\n    if echo \"$RESPONSE\" | grep -q '\"error-code\":\"NOT_FOUND\"'; then\n      echo \"Marqo did not find an existing vector store. Setting up vector store...\"\n\n      # Deploy a dummy application package\n      vespa deploy /app/scripts/vespa_local --wait 300 >/dev/null 2>&1\n\n      until curl -f -X GET http://localhost:8080 >/dev/null 2>&1; do\n        echo \"  Waiting for vector store to be available...\"\n        sleep 10\n      done\n      echo \"  Vector store is available. Vector store setup complete\"\n      break\n\n    # Check for the \"generation\" success response which indicates there is an existing application package deployed\n    elif echo \"$RESPONSE\" | grep -q '\"generation\":'; then\n      echo \"Marqo found an existing vector store. Waiting for vector store to be available...\"\n\n      until curl -f -X GET http://localhost:8080 >/dev/null 2>&1; do\n        echo \"  Waiting for vector store to be available...\"\n        sleep 10\n      done\n      echo \"  Vector store is available. Vector store setup complete\"\n      break\n    fi\n    ((RETRY_COUNT++))\n    sleep 5\n  done\n\n  if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then\n    echo \"Warning: Failed to configure local vector store. Marqo may not function correctly\"\n  fi\n\n  export VESPA_QUERY_URL=\"http://localhost:8080\"\n  export VESPA_DOCUMENT_URL=\"http://localhost:8080\"\n  export VESPA_CONFIG_URL=\"http://localhost:19071\"\n  export ZOOKEEPER_HOSTS=\"localhost:2181\"\n  export VESPA_IS_INTERNAL=True\n\nelse\n  echo \"External vector store configured. Using external vector store\"\nfi\n\n# Start up redis\nif [ \"$MARQO_ENABLE_THROTTLING\" != \"FALSE\" ]; then\n    echo \"Starting Marqo throttling\"\n    redis-server /etc/redis/redis.conf &\n    echo \"Called Marqo throttling start command\"\n\n    start_time=$(($(date +%s%N)/1000000))\n    while true; do\n        redis-cli ping &> /dev/null\n        if [ $? -eq 0 ]; then\n            break\n        fi\n\n        current_time=$(($(date +%s%N)/1000000))\n        elapsed_time=$(expr $current_time - $start_time)\n        if [ $elapsed_time -ge 2000 ]; then\n            # Expected start time should be < 30ms in reality.\n            echo \"Marqo throttling server failed to start within 2s. skipping\"\n            break\n        fi\n        sleep 0.1\n        \n    done\n    echo \"Marqo throttling is now running\"\n\nelse\n    echo \"Throttling has been disabled. Skipping Marqo throttling start\"\nfi\n\n# set the default value to info and convert to lower case\nexport MARQO_LOG_LEVEL=${MARQO_LOG_LEVEL:-info}\nMARQO_LOG_LEVEL=`echo \"$MARQO_LOG_LEVEL\" | tr '[:upper:]' '[:lower:]'`\n\n# Start the tensor search web app in the background\ncd /app/src/marqo/tensor_search || exit\nuvicorn api:app --host 0.0.0.0 --port 8882 --timeout-keep-alive 75 --log-level $MARQO_LOG_LEVEL &\nexport api_pid=$!\nwait \"$api_pid\"\n\n\n# Exit with status of process that exited first\nexit $?\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 0.4931640625,
          "content": "[tox]\nenvlist = py38\nskipsdist = True\n\n[coverage:html]\nshow_contexts = true\n\n[coverage:run]\nbranch = true\nsource = src\n\n[testenv]\ninstall_command = pip install {opts} {packages}\nwhitelist_externals =\n  python\ndeps =\n  pytest\n  -rrequirements.txt\n  -rrequirements.dev.txt\nsetenv =\n  PYTHONPATH = {toxinidir}{/}src:{toxinidir}\ncommands =\n  pytest --durations=100 --cov --cov-append --cov-context=test --cov-report=html {posargs}\n\n[testenv:clean]\ndeps = coverage\nskip_install = true\ncommands = coverage erase"
        },
        {
          "name": "vespa",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}