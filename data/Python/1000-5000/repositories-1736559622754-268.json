{
  "metadata": {
    "timestamp": 1736559622754,
    "page": 268,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "microsoft/BioGPT",
      "stars": 4350,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.41796875,
          "content": "# JetBrains PyCharm IDE\n.idea/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# macOS dir files\n.DS_Store\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mypy\n.mypy_cache/\n\n# VSCODE\n.vscode/ftp-sync.json\n.vscode/settings.json\n\n# Experimental Folder\nexperimental/*\n\n# Weights and Biases logs\nwandb/\n\n# data\ndata/*/*-bin\ndata/*/raw/*.x\ndata/*/raw/*.y\ndata/*/raw/*.pmid\ndata/*/raw/*bpecodes\ndata/*/raw/*dict.txt\n\n# Checkpoints\ncheckpoints/"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.43359375,
          "content": "# Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.11328125,
          "content": "    MIT License\n\n    Copyright (c) Microsoft Corporation.\n\n    Permission is hereby granted, free of charge, to any person obtaining a copy\n    of this software and associated documentation files (the \"Software\"), to deal\n    in the Software without restriction, including without limitation the rights\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n    copies of the Software, and to permit persons to whom the Software is\n    furnished to do so, subject to the following conditions:\n\n    The above copyright notice and this permission notice shall be included in all\n    copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n    SOFTWARE"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.6845703125,
          "content": "# BioGPT\nThis repository contains the implementation of [BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining](https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9), by Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon and Tie-Yan Liu.\n\n\n# Requirements and Installation\n\n* [PyTorch](http://pytorch.org/) version == 1.12.0\n* Python version == 3.10\n* fairseq version == 0.12.0:\n\n``` bash\ngit clone https://github.com/pytorch/fairseq\ncd fairseq\ngit checkout v0.12.0\npip install .\npython setup.py build_ext --inplace\ncd ..\n```\n* Moses\n``` bash\ngit clone https://github.com/moses-smt/mosesdecoder.git\nexport MOSES=${PWD}/mosesdecoder\n```\n* fastBPE\n``` bash\ngit clone https://github.com/glample/fastBPE.git\nexport FASTBPE=${PWD}/fastBPE\ncd fastBPE\ng++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast\n```\n* sacremoses\n``` bash\npip install sacremoses\n```\n* sklearn\n``` bash\npip install scikit-learn\n```\n\nRemember to set the environment variables `MOSES` and `FASTBPE` to the path of Moses and fastBPE respetively, as they will be required later.\n\n# Getting Started\n## Pre-trained models\nWe provide our pre-trained BioGPT model checkpoints along with fine-tuned checkpoints for downstream tasks, available both through URL download as well as through the Hugging Face ðŸ¤— Hub. \n\n|Model|Description|URL|ðŸ¤— Hub|\n|----|----|---|---|\n|BioGPT|Pre-trained BioGPT model checkpoint|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/Pre-trained-BioGPT.tgz?sp=r&st=2023-11-13T15:37:35Z&se=2099-12-30T23:37:35Z&spr=https&sv=2022-11-02&sr=b&sig=3CcG1TOhqJPBhkVutvVn3PtUq0vPyLBgwggUfojypfY%3D)|[link](https://huggingface.co/microsoft/biogpt)|\n|BioGPT-Large|Pre-trained BioGPT-Large model checkpoint|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/Pre-trained-BioGPT-Large.tgz?sp=r&st=2023-11-13T15:38:13Z&se=2099-12-30T23:38:13Z&spr=https&sv=2022-11-02&sr=b&sig=ib1SZut9wAwrsxGWtFtIZDhrnRg92dwPJmoY2lr3MTg%3D)|[link](https://huggingface.co/microsoft/biogpt-large)|\n|BioGPT-QA-PubMedQA-BioGPT|Fine-tuned BioGPT for question answering task on PubMedQA|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/QA-PubMedQA-BioGPT.tgz?sp=r&st=2023-11-13T15:38:43Z&se=2099-12-30T23:38:43Z&spr=https&sv=2022-11-02&sr=b&sig=A5SQae6ifsXmrsgpj4E2flhyXm4iHc%2FqO5b8HGOMyjc%3D)| |\n|BioGPT-QA-PubMedQA-BioGPT-Large|Fine-tuned BioGPT-Large for question answering task on PubMedQA|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/QA-PubMedQA-BioGPT-Large.tgz?sp=r&st=2023-11-13T15:39:40Z&se=2099-12-30T23:39:40Z&spr=https&sv=2022-11-02&sr=b&sig=t%2B%2FD%2BxVoIxiuyDsD0VXv%2FjSGoS0VcrdVXycYhWZoxUc%3D)||\n|BioGPT-RE-BC5CDR|Fine-tuned BioGPT for relation extraction task on BC5CDR|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/RE-BC5CDR-BioGPT.tgz?sp=r&st=2023-11-13T15:35:14Z&se=2099-12-30T23:35:14Z&spr=https&sv=2022-11-02&sr=b&sig=uXlLIHlVeKIbS%2BVmdzAmlNCeKdoKO2lxsSmwSi%2FH8nE%3D)| |\n|BioGPT-RE-DDI|Fine-tuned BioGPT for relation extraction task on DDI|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/RE-DDI-BioGPT.tgz?sp=r&st=2023-11-13T15:35:58Z&se=2099-12-30T23:35:58Z&spr=https&sv=2022-11-02&sr=b&sig=DkaQMuM%2FXAsM2p8%2BUs45ecuqhlSRF1DUYRBJNcxD6Pk%3D)| |\n|BioGPT-RE-DTI|Fine-tuned BioGPT for relation extraction task on KD-DTI|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/RE-DTI-BioGPT.tgz?sp=r&st=2023-11-13T15:36:23Z&se=2099-12-30T23:36:23Z&spr=https&sv=2022-11-02&sr=b&sig=bRgUZyqGuwYdM%2FVFzIv6Xa0GThkXq6bVzszmTe9c%2BKM%3D)| |\n|BioGPT-DC-HoC|Fine-tuned BioGPT for document classification task on HoC|[link](https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/DC-HoC-BioGPT.tgz?sp=r&st=2023-11-13T15:37:17Z&se=2099-12-30T23:37:17Z&spr=https&sv=2022-11-02&sr=b&sig=1DxroWPt%2FBppCTy7QHs842lLy8SQRcUeUwSfMzDFvl0%3D)| |\n\nDownload them and extract them to the `checkpoints` folder of this project.\n\nFor example:\n``` bash\nmkdir checkpoints\ncd checkpoints\nwget https://msralaphilly2.blob.core.windows.net/release/BioGPT/checkpoints/Pre-trained-BioGPT.tgz?sp=r&st=2023-11-13T15:37:35Z&se=2099-12-30T23:37:35Z&spr=https&sv=2022-11-02&sr=b&sig=3CcG1TOhqJPBhkVutvVn3PtUq0vPyLBgwggUfojypfY%3D\ntar -zxvf Pre-trained-BioGPT.tgz\n```\n\n## Example Usage\nUse pre-trained BioGPT model in your code:\n```python\nimport torch\nfrom fairseq.models.transformer_lm import TransformerLanguageModel\nm = TransformerLanguageModel.from_pretrained(\n        \"checkpoints/Pre-trained-BioGPT\", \n        \"checkpoint.pt\", \n        \"data\",\n        tokenizer='moses', \n        bpe='fastbpe', \n        bpe_codes=\"data/bpecodes\",\n        min_len=100,\n        max_len_b=1024)\nm.cuda()\nsrc_tokens = m.encode(\"COVID-19 is\")\ngenerate = m.generate([src_tokens], beam=5)[0]\noutput = m.decode(generate[0][\"tokens\"])\nprint(output)\n```\n\nUse fine-tuned BioGPT model on KD-DTI for drug-target-interaction in your code:\n```python\nimport torch\nfrom src.transformer_lm_prompt import TransformerLanguageModelPrompt\nm = TransformerLanguageModelPrompt.from_pretrained(\n        \"checkpoints/RE-DTI-BioGPT\", \n        \"checkpoint_avg.pt\", \n        \"data/KD-DTI/relis-bin\",\n        tokenizer='moses', \n        bpe='fastbpe', \n        bpe_codes=\"data/bpecodes\",\n        max_len_b=1024,\n        beam=1)\nm.cuda()\nsrc_text=\"\" # input text, e.g., a PubMed abstract\nsrc_tokens = m.encode(src_text)\ngenerate = m.generate([src_tokens], beam=args.beam)[0]\noutput = m.decode(generate[0][\"tokens\"])\nprint(output)\n```\n\nFor more downstream tasks, please see below.\n\n## Downstream tasks\nSee corresponding folder in [examples](examples):\n### [Relation Extraction on BC5CDR](examples/RE-BC5CDR)\n### [Relation Extraction on KD-DTI](examples/RE-DTI/)\n### [Relation Extraction on DDI](examples/RE-DDI)\n### [Document Classification on HoC](examples/DC-HoC/)\n### [Question Answering on PubMedQA](examples/QA-PubMedQA/)\n### [Text Generation](examples/text-generation/)\n\n## Hugging Face ðŸ¤— Usage\n\nBioGPT has also been integrated into the Hugging Face `transformers` library, and model checkpoints are available on the Hugging Face Hub.\n\nYou can use this model directly with a pipeline for text generation. Since the generation relies on some randomness, we set a seed for reproducibility:\n\n```python\nfrom transformers import pipeline, set_seed\nfrom transformers import BioGptTokenizer, BioGptForCausalLM\nmodel = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\ntokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\ngenerator = pipeline('text-generation', model=model, tokenizer=tokenizer)\nset_seed(42)\ngenerator(\"COVID-19 is\", max_length=20, num_return_sequences=5, do_sample=True)\n```\n\nHere is how to use this model to get the features of a given text in PyTorch:\n\n```python\nfrom transformers import BioGptTokenizer, BioGptForCausalLM\ntokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\nmodel = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\ntext = \"Replace me by any text you'd like.\"\nencoded_input = tokenizer(text, return_tensors='pt')\noutput = model(**encoded_input)\n```\n\nBeam-search decoding:\n\n```python\nimport torch\nfrom transformers import BioGptTokenizer, BioGptForCausalLM, set_seed\n\ntokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\nmodel = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n\nsentence = \"COVID-19 is\"\ninputs = tokenizer(sentence, return_tensors=\"pt\")\n\nset_seed(42)\n\nwith torch.no_grad():\n    beam_output = model.generate(**inputs,\n                                 min_length=100,\n                                 max_length=1024,\n                                 num_beams=5,\n                                 early_stopping=True\n                                )\ntokenizer.decode(beam_output[0], skip_special_tokens=True)\n```\n\nFor more information, please see the [documentation](https://huggingface.co/docs/transformers/main/en/model_doc/biogpt) on the Hugging Face website.\n\n## Demos\n\nCheck out these demos on Hugging Face Spaces:\n* [Text Generation with BioGPT-Large](https://huggingface.co/spaces/katielink/biogpt-large-demo)\n* [Question Answering with BioGPT-Large-PubMedQA](https://huggingface.co/spaces/katielink/biogpt-qa-demo)\n\n# License\n\nBioGPT is MIT-licensed.\nThe license applies to the pre-trained models as well.\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 2.6923828125,
          "content": "<!-- BEGIN MICROSOFT SECURITY.MD V0.0.7 BLOCK -->\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets [Microsoft's definition of a security vulnerability](https://aka.ms/opensource/security/definition), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://aka.ms/opensource/security/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the [Microsoft Security Response Center PGP Key page](https://aka.ms/opensource/security/pgpkey).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://aka.ms/opensource/security/msrc). \n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://aka.ms/opensource/security/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://aka.ms/opensource/security/cvd).\n\n<!-- END MICROSOFT SECURITY.MD BLOCK -->\n"
        },
        {
          "name": "SUPPORT.md",
          "type": "blob",
          "size": 1.21484375,
          "content": "# TODO: The maintainer of this repo has not yet edited this file\r\n\r\n**REPO OWNER**: Do you want Customer Service & Support (CSS) support for this product/project?\r\n\r\n- **No CSS support:** Fill out this template with information about how to file issues and get help.\r\n- **Yes CSS support:** Fill out an intake form at [aka.ms/onboardsupport](https://aka.ms/onboardsupport). CSS will work with/help you to determine next steps.\r\n- **Not sure?** Fill out an intake as though the answer were \"Yes\". CSS will help you decide.\r\n\r\n*Then remove this first heading from this SUPPORT.MD file before publishing your repo.*\r\n\r\n# Support\r\n\r\n## How to file issues and get help  \r\n\r\nThis project uses GitHub Issues to track bugs and feature requests. Please search the existing \r\nissues before filing new issues to avoid duplicates.  For new issues, file your bug or \r\nfeature request as a new Issue.\r\n\r\nFor help and questions about using this project, please **REPO MAINTAINER: INSERT INSTRUCTIONS HERE \r\nFOR HOW TO ENGAGE REPO OWNERS OR COMMUNITY FOR HELP. COULD BE A STACK OVERFLOW TAG OR OTHER\r\nCHANNEL. WHERE WILL YOU HELP PEOPLE?**.\r\n\r\n## Microsoft Support Policy  \r\n\r\nSupport for this **PROJECT or PRODUCT** is limited to the resources listed above.\r\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "inference.py",
          "type": "blob",
          "size": 1.3330078125,
          "content": "# Copyright (c) Microsoft Corporation.\n# Licensed under the MIT License.\n\nimport argparse\nfrom src.transformer_lm_prompt import TransformerLanguageModelPrompt\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--data_dir\", type=str, default='')\nparser.add_argument(\"--model_dir\", type=str, default=None)\nparser.add_argument(\"--model_file\", type=str, default=\"checkpoint_last.pt\")\nparser.add_argument(\"--src_file\", type=str, default=None)\nparser.add_argument(\"--output_file\", type=str, default=None)\nparser.add_argument(\"--beam\", type=int, default=1)\nparser.add_argument(\"--decoding_length\", type=int, default=1024)\nargs, _ = parser.parse_known_args()\n\n\ndef main(args):\n    src_inputs = []\n    with open(args.src_file) as reader:\n        for line in reader:\n            src_inputs.append(line.strip())\n    \n    m = TransformerLanguageModelPrompt.from_pretrained(\n        args.model_dir, \n        args.model_file, \n        args.data_dir,\n        max_len_b=args.decoding_length,\n        max_tokens=12000,)\n\n    print(m.cfg)\n\n    if m.cfg.common.fp16:\n        print('Converting to float 16')\n        m.half()\n    m.cuda()\n\n    outputs = m.sample(src_inputs, beam=args.beam)\n\n    with open(f\"{args.output_file}\", \"w\", encoding='utf8') as fw:\n        for i in range(len(outputs)):\n            fw.write(outputs[i] + '\\n')\n\n\nif __name__ == \"__main__\":\n    main(args)"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.4736328125,
          "content": "antlr4-python3-runtime==4.8\nbitarray==2.6.2\ncffi==1.15.1\nclick==8.1.3\ncolorama==0.4.6\nCython==0.29.33\nfairseq==0.12.2\nhydra-core==1.0.7\njoblib==1.2.0\nlxml==4.9.2\nnumpy==1.24.1\nomegaconf==2.0.6\nportalocker==2.7.0\nprotobuf==3.20.1\npycparser==2.21\nPyYAML==6.0\nregex==2022.10.31\nsacrebleu==2.3.1\nsacremoses==0.0.53\nscikit-learn==1.2.1\nscipy==1.10.0\nsix==1.16.0\ntabulate==0.9.0\ntensorboardX==2.5.1\nthreadpoolctl==3.1.0\ntorch==1.12.0\ntorchaudio==0.12.0\ntqdm==4.64.1\ntyping-extensions==4.4.0\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}