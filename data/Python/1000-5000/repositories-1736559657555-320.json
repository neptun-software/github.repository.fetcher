{
  "metadata": {
    "timestamp": 1736559657555,
    "page": 320,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "locuslab/TCN",
      "stars": 4224,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0625,
          "content": ".DS_Store/\nlambada/\nwikitext-103/\n*.pt\n*.log\n*.pyc\n__pycache__/\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.044921875,
          "content": "MIT License\n\nCopyright (c) 2018 CMU Locus Lab\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 2.3564453125,
          "content": "# Sequence Modeling Benchmarks and Temporal Convolutional Networks (TCN)\n\n\nThis repository contains the experiments done in the work [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/abs/1803.01271) by Shaojie Bai, J. Zico Kolter and Vladlen Koltun.\n\nWe specifically target a comprehensive set of tasks that have been repeatedly used to compare the effectiveness of different recurrent networks, and evaluate a simple, generic but powerful (purely) convolutional network on the recurrent nets' home turf.\n\nExperiments are done in PyTorch. If you find this repository helpful, please cite our work:\n\n```\n@article{BaiTCN2018,\n\tauthor    = {Shaojie Bai and J. Zico Kolter and Vladlen Koltun},\n\ttitle     = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},\n\tjournal   = {arXiv:1803.01271},\n\tyear      = {2018},\n}\n```\n\n## Domains and Datasets\n\n**Update**: The code should be directly runnable with PyTorch v1.0.0 or above (PyTorch v>1.3.0 strongly recommended). The older versions of PyTorch are no longer supported.\n\nThis repository contains the benchmarks to the following tasks, with details explained in each sub-directory:\n\n  - **The Adding Problem** with various T (we evaluated on T=200, 400, 600)\n  - **Copying Memory Task** with various T (we evaluated on T=500, 1000, 2000)\n  - **Sequential MNIST** digit classification\n  - **Permuted Sequential MNIST** (based on Seq. MNIST, but more challenging)\n  - **JSB Chorales** polyphonic music\n  - **Nottingham** polyphonic music\n  - **PennTreebank** [SMALL] word-level language modeling (LM)\n  - **Wikitext-103** [LARGE] word-level LM\n  - **LAMBADA** [LARGE] word-level LM and textual understanding\n  - **PennTreebank** [MEDIUM] char-level LM\n  - **text8** [LARGE] char-level LM\n\nWhile some of the large datasets are not included in this repo, we use the [observations](https://github.com/edwardlib/observations) package to download them, which can be easily installed using pip. \n\n## Usage\n\nEach task is contained in its own directory, with the following structure:\n\n```\n[TASK_NAME] /\n    data/\n    [TASK_NAME]_test.py\n    models.py\n    utils.py\n```\n\nTo run TCN model on the task, one only need to run `[TASK_NAME]_test.py` (e.g. `add_test.py`). To tune the hyperparameters, one can specify via argument options, which can been seen via the `-h` flag. \n"
        },
        {
          "name": "TCN",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}