{
  "metadata": {
    "timestamp": 1736559778364,
    "page": 497,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjUwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "google-deepmind/dm_control",
      "stars": 3880,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3291015625,
          "content": "# Ignore byte-compiled Python code\n*.py[cod]\n\n# Ignore directories created during the build/installation process\n*.egg-info/\nbuild/\n\n# Ignore autogenerated ctypes bindings...\ndm_control/mujoco/wrapper/mjbindings/*.py\n# ...but include `mjbindings/__init__.py`, which is not autogenerated\n!dm_control/mujoco/wrapper/mjbindings/__init__.py\n"
        },
        {
          "name": "AUTHORS",
          "type": "blob",
          "size": 0.302734375,
          "content": "# This is the list of dm_control authors for copyright purposes.\n#\n# This does not necessarily list everyone who has contributed code, since in\n# some cases, their employer may be the copyright holder.  To see the full list\n# of contributors, see the revision history in source control.\n\nDeepMind Technologies\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.9462890625,
          "content": "# How to Contribute\n\nWe'd love to accept your patches and contributions to this project. There are\njust a few small guidelines you need to follow.\n\n## Contributor License Agreement\n\nContributions to this project must be accompanied by a Contributor License\nAgreement. You (or your employer) retain the copyright to your contribution,\nthis simply gives us permission to use and redistribute your contributions as\npart of the project. Head over to <https://cla.developers.google.com/> to see\nyour current agreements on file or to sign a new one.\n\nYou generally only need to submit a CLA once, so if you've already submitted one\n(even if it was for a different project), you probably don't need to do it\nagain.\n\n## Code reviews\n\nAll submissions, including submissions by project members, require review. We\nuse GitHub pull requests for this purpose. Consult\n[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more\ninformation on using pull requests.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0908203125,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.7685546875,
          "content": "# `dm_control`: Google DeepMind Infrastructure for Physics-Based Simulation.\n\nGoogle DeepMind's software stack for physics-based simulation and Reinforcement\nLearning environments, using MuJoCo physics.\n\nAn **introductory tutorial** for this package is available as a Colaboratory\nnotebook:\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/dm_control/blob/main/tutorial.ipynb)\n\n## Overview\n\nThis package consists of the following \"core\" components:\n\n-   [`dm_control.mujoco`]: Libraries that provide Python bindings to the MuJoCo\n    physics engine.\n\n-   [`dm_control.suite`]: A set of Python Reinforcement Learning environments\n    powered by the MuJoCo physics engine.\n\n-   [`dm_control.viewer`]: An interactive environment viewer.\n\nAdditionally, the following components are available for the creation of more\ncomplex control tasks:\n\n-   [`dm_control.mjcf`]: A library for composing and modifying MuJoCo MJCF\n    models in Python.\n\n-   `dm_control.composer`: A library for defining rich RL environments from\n    reusable, self-contained components.\n\n-   [`dm_control.locomotion`]: Additional libraries for custom tasks.\n\n-   [`dm_control.locomotion.soccer`]: Multi-agent soccer tasks.\n\nIf you use this package, please cite our accompanying [publication]:\n\n```\n@article{tunyasuvunakool2020,\n         title = {dm_control: Software and tasks for continuous control},\n         journal = {Software Impacts},\n         volume = {6},\n         pages = {100022},\n         year = {2020},\n         issn = {2665-9638},\n         doi = {https://doi.org/10.1016/j.simpa.2020.100022},\n         url = {https://www.sciencedirect.com/science/article/pii/S2665963820300099},\n         author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and\n                   Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and\n                   Timothy Lillicrap and Nicolas Heess and Yuval Tassa},\n}\n```\n\n## Installation\n\nInstall `dm_control` from PyPI by running\n\n```sh\npip install dm_control\n```\n\n> **Note**: **`dm_control` cannot be installed in \"editable\" mode** (i.e. `pip\n> install -e`).\n>\n> While `dm_control` has been largely updated to use the pybind11-based bindings\n> provided via the `mujoco` package, at this time it still relies on some legacy\n> components that are automatically generated from MuJoCo header files in a way\n> that is incompatible with editable mode. Attempting to install `dm_control` in\n> editable mode will result in import errors like:\n>\n> ```\n> ImportError: cannot import name 'constants' from partially initialized module 'dm_control.mujoco.wrapper.mjbindings' ...\n> ```\n>\n> The solution is to `pip uninstall dm_control` and then reinstall it without\n> the `-e` flag.\n\n## Versioning\n\nStarting from version 1.0.0, we adopt semantic versioning.\n\nPrior to version 1.0.0, the `dm_control` Python package was versioned `0.0.N`,\nwhere `N` was an internal revision number that increased by an arbitrary amount\nat every single Git commit.\n\nIf you want to install an unreleased version of `dm_control` directly from our\nrepository, you can do so by running `pip install\ngit+https://github.com/google-deepmind/dm_control.git`.\n\n## Rendering\n\nThe MuJoCo Python bindings support three different OpenGL rendering backends:\nEGL (headless, hardware-accelerated), GLFW (windowed, hardware-accelerated), and\nOSMesa (purely software-based). At least one of these three backends must be\navailable in order render through `dm_control`.\n\n*   Hardware rendering with a windowing system is supported via GLFW and GLEW.\n    On Linux these can be installed using your distribution's package manager.\n    For example, on Debian and Ubuntu, this can be done by running `sudo apt-get\n    install libglfw3 libglew2.0`. Please note that:\n\n    -   [`dm_control.viewer`] can only be used with GLFW.\n    -   GLFW will not work on headless machines.\n\n*   \"Headless\" hardware rendering (i.e. without a windowing system such as X11)\n    requires [EXT_platform_device] support in the EGL driver. Recent Nvidia\n    drivers support this. You will also need GLEW. On Debian and Ubuntu, this\n    can be installed via `sudo apt-get install libglew2.0`.\n\n*   Software rendering requires GLX and OSMesa. On Debian and Ubuntu these can\n    be installed using `sudo apt-get install libgl1-mesa-glx libosmesa6`.\n\nBy default, `dm_control` will attempt to use GLFW first, then EGL, then OSMesa.\nYou can also specify a particular backend to use by setting the `MUJOCO_GL=`\nenvironment variable to `\"glfw\"`, `\"egl\"`, or `\"osmesa\"`, respectively. When\nrendering with EGL, you can also specify which GPU to use for rendering by\nsetting the environment variable `MUJOCO_EGL_DEVICE_ID=` to the target GPU ID.\n\n## Additional instructions for Homebrew users on macOS\n\n1.  The above instructions using `pip` should work, provided that you use a\n    Python interpreter that is installed by Homebrew (rather than the\n    system-default one).\n\n2.  Before running, the `DYLD_LIBRARY_PATH` environment variable needs to be\n    updated with the path to the GLFW library. This can be done by running\n    `export DYLD_LIBRARY_PATH=$(brew --prefix)/lib:$DYLD_LIBRARY_PATH`.\n\n[EXT_platform_device]: https://www.khronos.org/registry/EGL/extensions/EXT/EGL_EXT_platform_device.txt\n[Releases page on the MuJoCo GitHub repository]: https://github.com/google-deepmind/mujoco/releases\n[MuJoCo website]: https://mujoco.org/\n[publication]: https://doi.org/10.1016/j.simpa.2020.100022\n[`ctypes`]: https://docs.python.org/3/library/ctypes.html\n[`dm_control.mjcf`]: dm_control/mjcf/README.md\n[`dm_control.mujoco`]: dm_control/mujoco/README.md\n[`dm_control.suite`]: dm_control/suite/README.md\n[`dm_control.viewer`]: dm_control/viewer/README.md\n[`dm_control.locomotion`]: dm_control/locomotion/README.md\n[`dm_control.locomotion.soccer`]: dm_control/locomotion/soccer/README.md\n"
        },
        {
          "name": "dm_control",
          "type": "tree",
          "content": null
        },
        {
          "name": "migration_guide_1.0.md",
          "type": "blob",
          "size": 4.927734375,
          "content": "# dm_control: 1.0.0 update guide\n\nWith 1.0.0, we changed the way dm_control uses the MuJoCo physics simulator, and\nmigrated to new python bindings. For most users, this will require no code\nchanges. However, some more advanced users will need to change their code\nslightly. Below is a list of known changes that need to be made. Please contact\nus if you've had to make any further changes that are not listed below.\n\n## Required changes\n\n`dm_control.mujoco.wrapper.mjbindings.types` should not be used This module was\nspecific to the previous implementation of the dm_control python bindings. For\nexample, `types.MJRRECT` should be replaced with `mujoco.MjrRect`.\n\n### `MjData.contact` has changed\n\n`MjData.contact` (often accessed as Physics.data.contact) used to offer an\ninterface similar to a numpy structured array. For example, `data.contact.geom1`\nused to be a numpy array of geom IDs.\n\nWith the recent update, `MjData.contact` will appear as a list of MjContact\nstructs. Code that used to operate on the structured array will have to change.\nFor example, the following code would get an array containing the contact\ndistance for all contacts that involve geom_id:\n\n```\ncontact = physics.data.contact\ninvolves_geom = (contact.geom1 == geom_id) | (contact.geom2 == geom_id)\ndists = contact[involves_geom].dist\n```\n\nAfter the upgrade:\n\n```\ncontacts = physics.data.contact\ndists = [\n    c.dist for c in contacts if c.geom1 == geom_id or c.geom2 == geom_id\n]\n```\n\n### `.ptr.contents` will not work\n\nCode that accesses `.ptr.contents` on objects such as `MjvScene` will need to be\nupdated. In most cases, simply using `scene` instead of `scene.ptr.contents`\nwill work.\n\n### Different exceptions will be thrown from MuJoCo\n\nCode (mostly in tests) that expects `dm_control.mujoco.wrapper.core.Error`\nexceptions, will receive different exceptions, thrown by the `mujoco` library.\nThese will often be `ValueError` (for errors caused by input parameters), or\n`mujoco.FatalError` (for low level errors in MuJoCo).\n\n### Better error handling\n\nThe Python interpreter no longer crashes out when\n[`mju_error`](https://mujoco.readthedocs.io/en/latest/APIreference.html#mju-error)\nis called. Instead, `mju_error` calls are translated into `mujoco.FatalError`\nexceptions in Python.\n\nWhen Python callables are used as user-defined MuJoCo callbacks, they are now\npermitted to raise exceptions, which will be correctly propagated back down the\nPython call stack.\n\n### Change of signature for `mj_saveModel`\n\n[`mj_saveModel`](https://mujoco.readthedocs.io/en/latest/APIreference.html#mj-savemodel)\nnow expects a numpy `uint8` array rather than a ctypes string buffer, and\ndoesn't require a \"size\" parameter (it's inferred from the numpy array size).\n\nBefore:\n```\nmodel_size = mjlib.mj_sizeModel(model.ptr)\nbuf = ctypes.create_string_buffer(model_size)\nmjlib.mj_saveModel(model.ptr, None, buf, model_size)\n```\n\nAfter:\n```\nmodel_size = mujoco.mj_sizeModel(model)\nbuf = np.empty(model_size, np.uint8)\nmjlib.mj_saveModel(model.ptr, None, buf)\n```\n\n## Optional changes\n\nThe following are some changes that can make your code more concise, but are not\nrequired for it to continue working.\n\n### Use the mujoco module directly, instead of mjlib\n\nExisting code that uses `dm_control.mujoco.wrapper.mjbindings.mjlib` can\ndirectly replace these modules with mujoco. Code that uses `enums` or\n`constants` from `dm_control.mujoco.wrapper.mjbindings` can also use mujoco,\nwith slight type changes. All mujoco functions will accept the old enum values\nor the new ones.\n\nBefore:\n```\nimport dm_control.mujoco.wrapper.mjbindings\nmjlib = mjbindings.mjlib\n\nmjlib.mj_objectVelocity(\n    physics.model.ptr, physics.data.ptr,\n    enums.mjtObj.mjOBJ_SITE,\n    site_id, vel, 0)\n```\n\nAfter:\n```\nimport mujoco\n\nmujoco.mj_objectVelocity(\n    physics.model.ptr, physics.data.ptr,\n    mujoco.mjtObj.mjOBJ_SITE,\n    site_id, vel, 0)\n```\n\n### Assume structs are correctly initialized and memory is managed\n\nThe MuJoCo C API includes functions that manage the memory for certain structs.\nThose include functions that allocate memory (e.g. `mj_makeModel`,\n`mj_makeData`, `mjv_makeScene`), functions that free memory (e.g.\n`mj_deleteModel`, `mj_deleteData`, `mjv_freeScene`), and functions that reset a\nstruct to its default value (e.g. `mjv_defaultOption`, `mj_defaultVisual`).\n\nThe new Python bindings take care of this. Wrapper classes like\n`mujoco.MjvScene` will automatically allocate memory when they're created, and\nrelease it when they're deleted, and be created with default values set.\n\nAs such, allocating and freeing functions are not available through the mujoco\nPython bindings. The \"default\" functions are still available, but in most cases\nthe calls can simply be removed.\n\nBefore:\n```\nfrom dm_control.mujoco import wrapper\nfrom dm_control.mujoco.wrapper import mjbindings\nmjlib = mjbindings.mjlib\n\nscene_option = wrapper.core.MjvOption()\nmjlib.mjv_defaultOption(scene_option.ptr)\n```\n\nAfter:\n```\nfrom dm_control.mujoco import wrapper\n\nscene_option = wrapper.core.MjvOption()\n```\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.146484375,
          "content": "[build-system]\nrequires = [\"mujoco\", \"setuptools >= 40.6.0\", \"wheel\", \"pyparsing >= 3.0\", \"absl-py >= 0.7.0\"]\nbuild-backend = \"setuptools.build_meta\"\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.3876953125,
          "content": "absl-py==2.1.0\ndm-env==1.6\ndm-tree==0.1.8\nglfw==1.12.0\nh5py==3.12.1\nlabmaze==1.0.6\nlxml==5.3.0\nmock==5.1.0\nmujoco==3.2.6\nnose==1.3.7\nnose-xunitmp==0.4.1\nnumpy==1.26.4; python_version >= '3.9'\npillow==10.3.0\nprotobuf==3.19.4  # TensorFlow requires protobuf<3.20 (b/182876485)\npyopengl==3.1.7\npyparsing==3.2.0\nrequests==2.32.3\nscipy==1.14.1; python_version >= '3.10'\nsetuptools==70.3.0\ntqdm==4.66.6\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 7.7236328125,
          "content": "# Copyright 2017-2018 The dm_control Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ============================================================================\n\n\"\"\"Install script for setuptools.\"\"\"\n\nimport fnmatch\nimport logging\nimport os\nimport platform\nimport subprocess\nimport sys\n\nimport mujoco\nimport setuptools\nfrom setuptools import find_packages\nfrom setuptools import setup\nfrom setuptools.command import install\nfrom setuptools.command import test\n\nPLATFORM = platform.system()\n\n# Relative paths to the binding generator script and the output directory.\nAUTOWRAP_PATH = 'dm_control/autowrap/autowrap.py'\nMJBINDINGS_DIR = 'dm_control/mujoco/wrapper/mjbindings'\n\n# We specify the header filenames explicitly rather than listing the contents\n# of the `HEADERS_DIR` at runtime, since it will probably contain other stuff\n# (e.g. `glfw.h`).\nHEADER_FILENAMES = [\n    'mjdata.h',\n    'mjmodel.h',\n    'mjrender.h',\n    'mjtnum.h',\n    'mjui.h',\n    'mjvisualize.h',\n    'mjxmacro.h',\n    'mujoco.h',\n]\n\n\ndef _initialize_mjbindings_options(cmd_instance):\n  \"\"\"Set default values for options relating to `build_mjbindings`.\"\"\"\n  # A default value must be assigned to each user option here.\n  cmd_instance.inplace = 0\n  cmd_instance.headers_dir = mujoco.HEADERS_DIR\n\n\ndef _finalize_mjbindings_options(cmd_instance):\n  \"\"\"Post-process options relating to `build_mjbindings`.\"\"\"\n  headers_dir = os.path.expanduser(cmd_instance.headers_dir)\n  header_paths = []\n  for filename in HEADER_FILENAMES:\n    full_path = os.path.join(headers_dir, filename)\n    if not os.path.exists(full_path):\n      raise IOError('Header file {!r} does not exist.'.format(full_path))\n    header_paths.append(full_path)\n  cmd_instance.header_paths = ' '.join(header_paths)\n\n\nclass BuildMJBindingsCommand(setuptools.Command):\n  \"\"\"Runs `autowrap.py` to generate the low-level ctypes bindings for MuJoCo.\"\"\"\n\n  description = __doc__\n  user_options = [\n      # The format is (long option, short option, description).\n      ('headers-dir=', None, 'Path to directory containing MuJoCo headers.'),\n      (\n          'inplace=',\n          None,\n          'Place generated files in source directory rather than `build-lib`.',\n      ),\n  ]\n  boolean_options = ['inplace']\n\n  def initialize_options(self):\n    _initialize_mjbindings_options(self)\n\n  def finalize_options(self):\n    _finalize_mjbindings_options(self)\n\n  def run(self):\n    cwd = os.path.realpath(os.curdir)\n    if self.inplace:\n      dist_root = cwd\n    else:\n      build_cmd = self.get_finalized_command('build')\n      dist_root = os.path.realpath(build_cmd.build_lib)\n    output_dir = os.path.join(dist_root, MJBINDINGS_DIR)\n    command = [\n        sys.executable or 'python',\n        AUTOWRAP_PATH,\n        '--header_paths={}'.format(self.header_paths),\n        '--output_dir={}'.format(output_dir),\n    ]\n    self.announce('Running command: {}'.format(command), level=logging.DEBUG)\n    try:\n      # Prepend the current directory to $PYTHONPATH so that internal imports\n      # in `autowrap` can succeed before we've installed anything.\n      old_environ = os.environ.copy()\n      new_pythonpath = [cwd]\n      if 'PYTHONPATH' in old_environ:\n        new_pythonpath.append(old_environ['PYTHONPATH'])\n      os.environ['PYTHONPATH'] = ':'.join(new_pythonpath)\n      subprocess.check_call(command)\n    finally:\n      os.environ = old_environ\n\n\nclass InstallCommand(install.install):\n  \"\"\"Runs 'build_mjbindings' before installation.\"\"\"\n\n  user_options = (\n      install.install.user_options + BuildMJBindingsCommand.user_options\n  )\n  boolean_options = (\n      install.install.boolean_options + BuildMJBindingsCommand.boolean_options\n  )\n\n  def initialize_options(self):\n    install.install.initialize_options(self)\n    _initialize_mjbindings_options(self)\n\n  def finalize_options(self):\n    install.install.finalize_options(self)\n    _finalize_mjbindings_options(self)\n\n  def run(self):\n    self.reinitialize_command('build_mjbindings')\n    self.run_command('build_mjbindings')\n    install.install.run(self)\n\n\nclass TestCommand(test.test):\n  \"\"\"Prepends path to generated sources before running unit tests.\"\"\"\n\n  def run(self):\n    # Generate ctypes bindings in-place so that they can be imported in tests.\n    self.reinitialize_command('build_mjbindings', inplace=1)\n    self.run_command('build_mjbindings')\n    test.test.run(self)\n\n\ndef find_data_files(package_dir, patterns, excludes=()):\n  \"\"\"Recursively finds files whose names match the given shell patterns.\"\"\"\n  paths = set()\n\n  def is_excluded(s):\n    for exclude in excludes:\n      if fnmatch.fnmatch(s, exclude):\n        return True\n    return False\n\n  for directory, _, filenames in os.walk(package_dir):\n    if is_excluded(directory):\n      continue\n    for pattern in patterns:\n      for filename in fnmatch.filter(filenames, pattern):\n        # NB: paths must be relative to the package directory.\n        relative_dirpath = os.path.relpath(directory, package_dir)\n        full_path = os.path.join(relative_dirpath, filename)\n        if not is_excluded(full_path):\n          paths.add(full_path)\n  return list(paths)\n\n\nsetup(\n    name='dm_control',\n    version='1.0.26',\n    description='Continuous control environments and MuJoCo Python bindings.',\n    long_description=\"\"\"\n# `dm_control`: DeepMind Infrastructure for Physics-Based Simulation.\n\nDeepMind's software stack for physics-based simulation and Reinforcement\nLearning environments, using MuJoCo physics.\n\nAn **introductory tutorial** for this package is available as a Colaboratory\nnotebook: [Open In Google Colab](https://colab.research.google.com/github/google-deepmind/dm_control/blob/main/tutorial.ipynb).\n\"\"\",\n    long_description_content_type='text/markdown',\n    author='DeepMind',\n    author_email='mujoco@deepmind.com',\n    url='https://github.com/google-deepmind/dm_control',\n    license='Apache License 2.0',\n    classifiers=[\n        'License :: OSI Approved :: Apache Software License',\n    ],\n    keywords='machine learning control physics MuJoCo AI',\n    python_requires='>=3.9',\n    install_requires=[\n        'absl-py>=0.7.0',\n        'dm-env',\n        'dm-tree != 0.1.2',\n        'glfw',\n        'labmaze',\n        'lxml',\n        'mujoco >= 3.2.6',\n        'numpy >= 1.9.0',\n        'protobuf >= 3.19.4',  # TensorFlow requires protobuf<3.20 (b/182876485)\n        'pyopengl >= 3.1.4',\n        'pyparsing >= 3.0.0',\n        'requests',\n        'setuptools!=50.0.0',  # https://github.com/pypa/setuptools/issues/2350\n        'scipy',\n        'tqdm',\n    ],\n    extras_require={\n        'HDF5': ['h5py'],\n    },\n    tests_require=[\n        'mock',\n        'nose',\n        'pillow>=10.2.0',\n    ],\n    test_suite='nose.collector',\n    packages=find_packages(),\n    package_data={\n        'dm_control': find_data_files(\n            package_dir='dm_control',\n            patterns=[\n                '*.amc',\n                '*.msh',\n                '*.png',\n                '*.skn',\n                '*.stl',\n                '*.xml',\n                '*.textproto',\n                '*.h5',\n            ],\n            excludes=[\n                '*/dog_assets/extras/*',\n                '*/kinova/meshes/*',  # Exclude non-decimated meshes.\n            ],\n        ),\n    },\n    cmdclass={\n        'build_mjbindings': BuildMJBindingsCommand,\n        'install': InstallCommand,\n        'test': TestCommand,\n    },\n    entry_points={},\n)\n"
        },
        {
          "name": "tutorial.ipynb",
          "type": "blob",
          "size": 68.17578125,
          "content": "{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MpkYHwCqk7W-\"\n      },\n      \"source\": [\n        \"# **`dm_control` tutorial**\\n\",\n        \"\\n\",\n        \"[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google-deepmind/dm_control/blob/main/tutorial.ipynb)\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"\\n\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"_UbO9uhtBSX5\"\n      },\n      \"source\": [\n        \"\\u003e \\u003cp\\u003e\\u003csmall\\u003e\\u003csmall\\u003eCopyright 2020 The dm_control Authors.\\u003c/small\\u003e\\u003c/p\\u003e\\n\",\n        \"\\u003e \\u003cp\\u003e\\u003csmall\\u003e\\u003csmall\\u003eLicensed under the Apache License, Version 2.0 (the \\\"License\\\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at \\u003ca href=\\\"http://www.apache.org/licenses/LICENSE-2.0\\\"\\u003ehttp://www.apache.org/licenses/LICENSE-2.0\\u003c/a\\u003e.\\u003c/small\\u003e\\u003c/small\\u003e\\u003c/p\\u003e\\n\",\n        \"\\u003e \\u003cp\\u003e\\u003csmall\\u003e\\u003csmall\\u003eUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\\u003c/small\\u003e\\u003c/small\\u003e\\u003c/p\\u003e\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"aThGKGp0cD76\"\n      },\n      \"source\": [\n        \"This notebook provides an overview tutorial of DeepMind's `dm_control` package, hosted at the [google-deepmind/dm_control](https://github.com/google-deepmind/dm_control) repository on GitHub.\\n\",\n        \"\\n\",\n        \"It is adjunct to this [tech report](http://arxiv.org/abs/2006.12983).\\n\",\n        \"\\n\",\n        \"**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \\\"Runtime \\u003e Change runtime type\\\".\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"YkBQUjm6gbGF\"\n      },\n      \"source\": [\n        \"<!-- Internal installation instructions. -->\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"YvyGCsgSCxHQ\"\n      },\n      \"source\": [\n        \"### Installing `dm_control` on Colab\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"IbZxYDxzoz5R\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Run to install MuJoCo and `dm_control`\\n\",\n        \"import distutils.util\\n\",\n        \"import os\\n\",\n        \"import subprocess\\n\",\n        \"if subprocess.run('nvidia-smi').returncode:\\n\",\n        \"  raise RuntimeError(\\n\",\n        \"      'Cannot communicate with GPU. '\\n\",\n        \"      'Make sure you are using a GPU Colab runtime. '\\n\",\n        \"      'Go to the Runtime menu and select Choose runtime type.')\\n\",\n        \"\\n\",\n        \"# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\\n\",\n        \"# This is usually installed as part of an Nvidia driver package, but the Colab\\n\",\n        \"# kernel doesn't install its driver via APT, and as a result the ICD is missing.\\n\",\n        \"# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\\n\",\n        \"NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\\n\",\n        \"if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\\n\",\n        \"  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\\n\",\n        \"    f.write(\\\"\\\"\\\"{\\n\",\n        \"    \\\"file_format_version\\\" : \\\"1.0.0\\\",\\n\",\n        \"    \\\"ICD\\\" : {\\n\",\n        \"        \\\"library_path\\\" : \\\"libEGL_nvidia.so.0\\\"\\n\",\n        \"    }\\n\",\n        \"}\\n\",\n        \"\\\"\\\"\\\")\\n\",\n        \"\\n\",\n        \"print('Installing dm_control...')\\n\",\n        \"!pip install -q dm_control\\u003e=1.0.26\\n\",\n        \"\\n\",\n        \"# Configure dm_control to use the EGL rendering backend (requires GPU)\\n\",\n        \"%env MUJOCO_GL=egl\\n\",\n        \"\\n\",\n        \"print('Checking that the dm_control installation succeeded...')\\n\",\n        \"try:\\n\",\n        \"  from dm_control import suite\\n\",\n        \"  env = suite.load('cartpole', 'swingup')\\n\",\n        \"  pixels = env.physics.render()\\n\",\n        \"except Exception as e:\\n\",\n        \"  raise e from RuntimeError(\\n\",\n        \"      'Something went wrong during installation. Check the shell output above '\\n\",\n        \"      'for more information.\\\\n'\\n\",\n        \"      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\\n\",\n        \"      'by going to the Runtime menu and selecting \\\"Choose runtime type\\\".')\\n\",\n        \"else:\\n\",\n        \"  del pixels, suite\\n\",\n        \"\\n\",\n        \"!echo Installed dm_control $(pip show dm_control | grep -Po \\\"(?\\u003c=Version: ).+\\\")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"wtDN43hIJh2C\"\n      },\n      \"source\": [\n        \"# Imports\\n\",\n        \"\\n\",\n        \"Run both of these cells:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"cellView\": \"form\",\n        \"id\": \"T5f4w3Kq2X14\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title All `dm_control` imports required for this tutorial\\n\",\n        \"\\n\",\n        \"# The basic mujoco wrapper.\\n\",\n        \"from dm_control import mujoco\\n\",\n        \"\\n\",\n        \"# Access to enums and MuJoCo library functions.\\n\",\n        \"from dm_control.mujoco.wrapper.mjbindings import enums\\n\",\n        \"from dm_control.mujoco.wrapper.mjbindings import mjlib\\n\",\n        \"\\n\",\n        \"# PyMJCF\\n\",\n        \"from dm_control import mjcf\\n\",\n        \"\\n\",\n        \"# Composer high level imports\\n\",\n        \"from dm_control import composer\\n\",\n        \"from dm_control.composer.observation import observable\\n\",\n        \"from dm_control.composer import variation\\n\",\n        \"\\n\",\n        \"# Imports for Composer tutorial example\\n\",\n        \"from dm_control.composer.variation import distributions\\n\",\n        \"from dm_control.composer.variation import noises\\n\",\n        \"from dm_control.locomotion.arenas import floors\\n\",\n        \"\\n\",\n        \"# Control Suite\\n\",\n        \"from dm_control import suite\\n\",\n        \"\\n\",\n        \"# Run through corridor example\\n\",\n        \"from dm_control.locomotion.walkers import cmu_humanoid\\n\",\n        \"from dm_control.locomotion.arenas import corridors as corridor_arenas\\n\",\n        \"from dm_control.locomotion.tasks import corridors as corridor_tasks\\n\",\n        \"\\n\",\n        \"# Soccer\\n\",\n        \"from dm_control.locomotion import soccer\\n\",\n        \"\\n\",\n        \"# Manipulation\\n\",\n        \"from dm_control import manipulation\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"gKc1FNhKiVJX\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Other imports and helper functions\\n\",\n        \"\\n\",\n        \"# General\\n\",\n        \"import copy\\n\",\n        \"import os\\n\",\n        \"import itertools\\n\",\n        \"from IPython.display import clear_output\\n\",\n        \"import numpy as np\\n\",\n        \"\\n\",\n        \"# Graphics-related\\n\",\n        \"import matplotlib\\n\",\n        \"import matplotlib.animation as animation\\n\",\n        \"import matplotlib.pyplot as plt\\n\",\n        \"from IPython.display import HTML\\n\",\n        \"import PIL.Image\\n\",\n        \"# Internal loading of video libraries.\\n\",\n        \"\\n\",\n        \"# Use svg backend for figure rendering\\n\",\n        \"%config InlineBackend.figure_format = 'svg'\\n\",\n        \"\\n\",\n        \"# Font sizes\\n\",\n        \"SMALL_SIZE = 8\\n\",\n        \"MEDIUM_SIZE = 10\\n\",\n        \"BIGGER_SIZE = 12\\n\",\n        \"plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\\n\",\n        \"plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\\n\",\n        \"plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\\n\",\n        \"plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\\n\",\n        \"plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\\n\",\n        \"plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\\n\",\n        \"plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\\n\",\n        \"\\n\",\n        \"# Inline video helper function\\n\",\n        \"if os.environ.get('COLAB_NOTEBOOK_TEST', False):\\n\",\n        \"  # We skip video generation during tests, as it is quite expensive.\\n\",\n        \"  display_video = lambda *args, **kwargs: None\\n\",\n        \"else:\\n\",\n        \"  def display_video(frames, framerate=30):\\n\",\n        \"    height, width, _ = frames[0].shape\\n\",\n        \"    dpi = 70\\n\",\n        \"    orig_backend = matplotlib.get_backend()\\n\",\n        \"    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\\n\",\n        \"    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\\n\",\n        \"    matplotlib.use(orig_backend)  # Switch back to the original backend.\\n\",\n        \"    ax.set_axis_off()\\n\",\n        \"    ax.set_aspect('equal')\\n\",\n        \"    ax.set_position([0, 0, 1, 1])\\n\",\n        \"    im = ax.imshow(frames[0])\\n\",\n        \"    def update(frame):\\n\",\n        \"      im.set_data(frame)\\n\",\n        \"      return [im]\\n\",\n        \"    interval = 1000/framerate\\n\",\n        \"    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\\n\",\n        \"                                   interval=interval, blit=True, repeat=False)\\n\",\n        \"    return HTML(anim.to_html5_video())\\n\",\n        \"\\n\",\n        \"# Seed numpy's global RNG so that cell outputs are deterministic. We also try to\\n\",\n        \"# use RandomState instances that are local to a single cell wherever possible.\\n\",\n        \"np.random.seed(42)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jZXz9rPYGA-Y\"\n      },\n      \"source\": [\n        \"# Model definition, compilation and rendering\\n\",\n        \"\\n\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MRBaZsf1d7Gb\"\n      },\n      \"source\": [\n        \"We begin by describing some basic concepts of the [MuJoCo](http://mujoco.org/) physics simulation library, but recommend the [official documentation](http://mujoco.org/book/) for details.\\n\",\n        \"\\n\",\n        \"Let's define a simple model with two geoms and a light.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ZS2utl59ZTsr\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title A static model {vertical-output: true}\\n\",\n        \"\\n\",\n        \"static_model = \\\"\\\"\\\"\\n\",\n        \"\\u003cmujoco\\u003e\\n\",\n        \"  \\u003cworldbody\\u003e\\n\",\n        \"    \\u003clight name=\\\"top\\\" pos=\\\"0 0 1\\\"/\\u003e\\n\",\n        \"    \\u003cgeom name=\\\"red_box\\\" type=\\\"box\\\" size=\\\".2 .2 .2\\\" rgba=\\\"1 0 0 1\\\"/\\u003e\\n\",\n        \"    \\u003cgeom name=\\\"green_sphere\\\" pos=\\\".2 .2 .2\\\" size=\\\".1\\\" rgba=\\\"0 1 0 1\\\"/\\u003e\\n\",\n        \"  \\u003c/worldbody\\u003e\\n\",\n        \"\\u003c/mujoco\\u003e\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"physics = mujoco.Physics.from_xml_string(static_model)\\n\",\n        \"pixels = physics.render()\\n\",\n        \"PIL.Image.fromarray(pixels)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"p4vPllljTJh8\"\n      },\n      \"source\": [\n        \"`static_model` is written in MuJoCo's XML-based [MJCF](http://www.mujoco.org/book/modeling.html) modeling language. The `from_xml_string()` method invokes the model compiler, which instantiates the library's internal data structures. These can be accessed via the `physics` object, see below.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MdUF2UYmR4TA\"\n      },\n      \"source\": [\n        \"## Adding DOFs and simulating, advanced rendering\\n\",\n        \"This is a perfectly legitimate model, but if we simulate it, nothing will happen except for time advancing. This is because this model has no degrees of freedom (DOFs). We add DOFs by adding **joints** to bodies, specifying how they can move with respect to their parents. Let us add a hinge joint and re-render, visualizing the joint axis.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"R7zokzd_yeEg\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title A child body with a joint { vertical-output: true }\\n\",\n        \"\\n\",\n        \"swinging_body = \\\"\\\"\\\"\\n\",\n        \"\\u003cmujoco\\u003e\\n\",\n        \"  \\u003cworldbody\\u003e\\n\",\n        \"    \\u003clight name=\\\"top\\\" pos=\\\"0 0 1\\\"/\\u003e\\n\",\n        \"    \\u003cbody name=\\\"box_and_sphere\\\" euler=\\\"0 0 -30\\\"\\u003e  \\n\",\n        \"      \\u003cjoint name=\\\"swing\\\" type=\\\"hinge\\\" axis=\\\"1 -1 0\\\" pos=\\\"-.2 -.2 -.2\\\"/\\u003e\\n\",\n        \"      \\u003cgeom name=\\\"red_box\\\" type=\\\"box\\\" size=\\\".2 .2 .2\\\" rgba=\\\"1 0 0 1\\\"/\\u003e\\n\",\n        \"      \\u003cgeom name=\\\"green_sphere\\\" pos=\\\".2 .2 .2\\\" size=\\\".1\\\" rgba=\\\"0 1 0 1\\\"/\\u003e\\n\",\n        \"    \\u003c/body\\u003e\\n\",\n        \"  \\u003c/worldbody\\u003e\\n\",\n        \"\\u003c/mujoco\\u003e\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"physics = mujoco.Physics.from_xml_string(swinging_body)\\n\",\n        \"# Visualize the joint axis.\\n\",\n        \"scene_option = mujoco.wrapper.core.MjvOption()\\n\",\n        \"scene_option.flags[enums.mjtVisFlag.mjVIS_JOINT] = True\\n\",\n        \"pixels = physics.render(scene_option=scene_option)\\n\",\n        \"PIL.Image.fromarray(pixels)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"INOGGV0PTQus\"\n      },\n      \"source\": [\n        \"The things that move (and which have inertia) are called *bodies*. The body's child `joint` specifies how that body can move with respect to its parent, in this case `box_and_sphere` w.r.t the `worldbody`. \\n\",\n        \"\\n\",\n        \"Note that the body's frame is **rotated** with an `euler` directive, and its children, the geoms and the joint, rotate with it. This is to emphasize the local-to-parent-frame nature of position and orientation directives in MJCF.\\n\",\n        \"\\n\",\n        \"Let's make a video, to get a sense of the dynamics and to see the body swinging under gravity.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Z_57VMUDpGrj\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Making a video {vertical-output: true}\\n\",\n        \"\\n\",\n        \"duration = 2    # (seconds)\\n\",\n        \"framerate = 30  # (Hz)\\n\",\n        \"\\n\",\n        \"# Visualize the joint axis\\n\",\n        \"scene_option = mujoco.wrapper.core.MjvOption()\\n\",\n        \"scene_option.flags[enums.mjtVisFlag.mjVIS_JOINT] = True\\n\",\n        \"\\n\",\n        \"# Simulate and display video.\\n\",\n        \"frames = []\\n\",\n        \"physics.reset()  # Reset state and time\\n\",\n        \"while physics.data.time \\u003c duration:\\n\",\n        \"  physics.step()\\n\",\n        \"  if len(frames) \\u003c physics.data.time * framerate:\\n\",\n        \"    pixels = physics.render(scene_option=scene_option)\\n\",\n        \"    frames.append(pixels)\\n\",\n        \"display_video(frames, framerate)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"yYvS1UaciMX_\"\n      },\n      \"source\": [\n        \"Note how we collect the video frames. Because physics simulation timesteps are generally much smaller than framerates (the default timestep is 2ms), we don't render after each step.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"nQ8XOnRQx7T1\"\n      },\n      \"source\": [\n        \"## Rendering options\\n\",\n        \"\\n\",\n        \"Like joint visualisation, additional rendering options are exposed as parameters to the `render` method.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"AQITZiIgx7T2\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Enable transparency and frame visualization {vertical-output: true}\\n\",\n        \"\\n\",\n        \"scene_option = mujoco.wrapper.core.MjvOption()\\n\",\n        \"scene_option.frame = enums.mjtFrame.mjFRAME_GEOM\\n\",\n        \"scene_option.flags[enums.mjtVisFlag.mjVIS_TRANSPARENT] = True\\n\",\n        \"pixels = physics.render(scene_option=scene_option)\\n\",\n        \"PIL.Image.fromarray(pixels)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"PDDgY48vx7T6\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Depth rendering {vertical-output: true}\\n\",\n        \"\\n\",\n        \"# depth is a float array, in meters.\\n\",\n        \"depth = physics.render(depth=True)\\n\",\n        \"# Shift nearest values to the origin.\\n\",\n        \"depth -= depth.min()\\n\",\n        \"# Scale by 2 mean distances of near rays.\\n\",\n        \"depth /= 2*depth[depth \\u003c= 1].mean()\\n\",\n        \"# Scale to [0, 255]\\n\",\n        \"pixels = 255*np.clip(depth, 0, 1)\\n\",\n        \"PIL.Image.fromarray(pixels.astype(np.uint8))\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"PNwiIrgpx7T8\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Segmentation rendering {vertical-output: true}\\n\",\n        \"\\n\",\n        \"seg = physics.render(segmentation=True)\\n\",\n        \"# Display the contents of the first channel, which contains object\\n\",\n        \"# IDs. The second channel, seg[:, :, 1], contains object types.\\n\",\n        \"geom_ids = seg[:, :, 0]\\n\",\n        \"# Infinity is mapped to -1\\n\",\n        \"geom_ids = geom_ids.astype(np.float64) + 1\\n\",\n        \"# Scale to [0, 1]\\n\",\n        \"geom_ids = geom_ids / geom_ids.max()\\n\",\n        \"pixels = 255*geom_ids\\n\",\n        \"PIL.Image.fromarray(pixels.astype(np.uint8))\\n\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"uCJQlv3cQcJQ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Projecting from world to camera coordinates {vertical-output: true}\\n\",\n        \"\\n\",\n        \"# Get the world coordinates of the box corners\\n\",\n        \"box_pos = physics.named.data.geom_xpos['red_box']\\n\",\n        \"box_mat = physics.named.data.geom_xmat['red_box'].reshape(3, 3)\\n\",\n        \"box_size = physics.named.model.geom_size['red_box']\\n\",\n        \"offsets = np.array([-1, 1]) * box_size[:, None]\\n\",\n        \"xyz_local = np.stack(list(itertools.product(*offsets))).T\\n\",\n        \"xyz_global = box_pos[:, None] + box_mat @ xyz_local\\n\",\n        \"\\n\",\n        \"# Camera matrices multiply homogenous [x, y, z, 1] vectors.\\n\",\n        \"corners_homogeneous = np.ones((4, xyz_global.shape[1]), dtype=float)\\n\",\n        \"corners_homogeneous[:3, :] = xyz_global\\n\",\n        \"\\n\",\n        \"# Get the camera matrix.\\n\",\n        \"camera = mujoco.Camera(physics)\\n\",\n        \"camera_matrix = camera.matrix\\n\",\n        \"\\n\",\n        \"# Project world coordinates into pixel space. See:\\n\",\n        \"# https://en.wikipedia.org/wiki/3D_projection#Mathematical_formula\\n\",\n        \"xs, ys, s = camera_matrix @ corners_homogeneous\\n\",\n        \"# x and y are in the pixel coordinate system.\\n\",\n        \"x = xs / s\\n\",\n        \"y = ys / s\\n\",\n        \"\\n\",\n        \"# Render the camera view and overlay the projected corner coordinates.\\n\",\n        \"pixels = camera.render()\\n\",\n        \"fig, ax = plt.subplots(1, 1)\\n\",\n        \"ax.imshow(pixels)\\n\",\n        \"ax.plot(x, y, '+', c='w')\\n\",\n        \"ax.set_axis_off()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"gf9h_wi9weet\"\n      },\n      \"source\": [\n        \"# MuJoCo basics and named indexing\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"NCcZxrDDB1Cj\"\n      },\n      \"source\": [\n        \"## `mjModel`\\n\",\n        \"MuJoCo's `mjModel`, encapsulated in `physics.model`, contains the *model description*, including the default initial state and other fixed quantities which are not a function of the state, e.g. the positions of geoms in the frame of their parent body. The (x, y, z) offsets of the `box` and `sphere` geoms, relative their parent body `box_and_sphere` are given by `model.geom_pos`:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"wx8NANvOF8g1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"physics.model.geom_pos\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Wee5ATLtIQn_\"\n      },\n      \"source\": [\n        \"The `model.opt` structure contains global quantities like\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BhzbZIfDIU2-\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print('timestep', physics.model.opt.timestep)\\n\",\n        \"print('gravity', physics.model.opt.gravity)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"t5hY0fyXFLcf\"\n      },\n      \"source\": [\n        \"## `mjData`\\n\",\n        \"`mjData`, encapsulated in `physics.data`, contains the *state* and quantities that depend on it. The state is made up of time, generalized positions and generalised velocities. These are respectively `data.time`, `data.qpos` and `data.qvel`. \\n\",\n        \"\\n\",\n        \"Let's print the state of the swinging body where we left it:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"acwZtDwp9mQU\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print(physics.data.time, physics.data.qpos, physics.data.qvel)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"7YlmcLcA-WQu\"\n      },\n      \"source\": [\n        \"`physics.data` also contains functions of the state, for example the cartesian positions of objects in the world frame. The (x, y, z) positions of our two geoms are in `data.geom_xpos`:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"CPwDcAQ0-uUE\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print(physics.data.geom_xpos)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"Z0UodCxS_v49\"\n      },\n      \"source\": [\n        \"## Named indexing\\n\",\n        \"\\n\",\n        \"The semantics of the above arrays are made clearer using the `named` wrapper, which assigns names to rows and type names to columns.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cLARcaK6-xCU\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print(physics.named.data.geom_xpos)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"wgXOUZNZHIx6\"\n      },\n      \"source\": [\n        \"Note how `model.geom_pos` and `data.geom_xpos` have similar semantics but very different meanings.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"-cW61ClRHS8a\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print(physics.named.model.geom_pos)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"-lQ0AChVASMv\"\n      },\n      \"source\": [\n        \"Name strings can be used to index **into** the relevant quantities, making code much more readable and robust.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"Rj4ad9fQAnFZ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"physics.named.data.geom_xpos['green_sphere', 'z']\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"axr_p6APAzFn\"\n      },\n      \"source\": [\n        \"Joint names can be used to index into quantities in configuration space (beginning with the letter `q`):\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"hluF9aDG9O1W\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"physics.named.data.qpos['swing']\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"3IhfyD2Q1pjv\"\n      },\n      \"source\": [\n        \"We can mix NumPy slicing operations with named indexing. As an example, we can set the color of the box using its name (`\\\"red_box\\\"`) as an index into the rows of the `geom_rgba` array. \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"f5vVUullUvWH\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Changing colors using named indexing{vertical-output: true}\\n\",\n        \"\\n\",\n        \"random_rgb = np.random.rand(3)\\n\",\n        \"physics.named.model.geom_rgba['red_box', :3] = random_rgb\\n\",\n        \"pixels = physics.render()\\n\",\n        \"PIL.Image.fromarray(pixels)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"elzPPdq-KhLI\"\n      },\n      \"source\": [\n        \"Note that while `physics.model` quantities will not be changed by the engine, we can change them ourselves between steps. This however is generally not recommended, the preferred approach being to modify the model at the XML level using the PyMJCF library, see below.\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"22ENjtVuhwsm\"\n      },\n      \"source\": [\n        \"## Setting the state with `reset_context()`\\n\",\n        \"\\n\",\n        \"In order for `data` quantities that are functions of the state to be in sync with the state, MuJoCo's `mj_step1()` needs to be called. This is facilitated by the `reset_context()` context, please see in-depth discussion in Section 2.1 of the [tech report](https://arxiv.org/abs/2006.12983).\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"WBPprCtWgXFN\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"physics.named.data.qpos['swing'] = np.pi\\n\",\n        \"print('Without reset_context, spatial positions are not updated:',\\n\",\n        \"      physics.named.data.geom_xpos['green_sphere', ['z']])\\n\",\n        \"with physics.reset_context():\\n\",\n        \"  physics.named.data.qpos['swing'] = np.pi\\n\",\n        \"print('After reset_context, positions are up-to-date:',\\n\",\n        \"      physics.named.data.geom_xpos['green_sphere', ['z']])\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"SHppAOjvSupc\"\n      },\n      \"source\": [\n        \"## Free bodies: the self-inverting \\\"tippe-top\\\"\\n\",\n        \"\\n\",\n        \"A free body is a body with a `free` joint, with 6 movement DOFs: 3 translations and 3 rotations. We could give our `box_and_sphere` body a free joint and watch it fall, but let's look at something more interesting. A \\\"tippe top\\\" is a spinning toy which flips itself on its head ([Wikipedia](https://en.wikipedia.org/wiki/Tippe_top)). We model it as follows:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"xasXQpVMjIwA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title The \\\"tippe-top\\\" model{vertical-output: true}\\n\",\n        \"\\n\",\n        \"tippe_top = \\\"\\\"\\\"\\n\",\n        \"\\u003cmujoco model=\\\"tippe top\\\"\\u003e\\n\",\n        \"  \\u003coption integrator=\\\"RK4\\\"/\\u003e\\n\",\n        \"  \\u003casset\\u003e\\n\",\n        \"    \\u003ctexture name=\\\"grid\\\" type=\\\"2d\\\" builtin=\\\"checker\\\" rgb1=\\\".1 .2 .3\\\" \\n\",\n        \"     rgb2=\\\".2 .3 .4\\\" width=\\\"300\\\" height=\\\"300\\\"/\\u003e\\n\",\n        \"    \\u003cmaterial name=\\\"grid\\\" texture=\\\"grid\\\" texrepeat=\\\"8 8\\\" reflectance=\\\".2\\\"/\\u003e\\n\",\n        \"  \\u003c/asset\\u003e\\n\",\n        \"  \\u003cworldbody\\u003e\\n\",\n        \"    \\u003cgeom size=\\\".2 .2 .01\\\" type=\\\"plane\\\" material=\\\"grid\\\"/\\u003e\\n\",\n        \"    \\u003clight pos=\\\"0 0 .6\\\"/\\u003e\\n\",\n        \"    \\u003ccamera name=\\\"closeup\\\" pos=\\\"0 -.1 .07\\\" xyaxes=\\\"1 0 0 0 1 2\\\"/\\u003e\\n\",\n        \"    \\u003cbody name=\\\"top\\\" pos=\\\"0 0 .02\\\"\\u003e\\n\",\n        \"      \\u003cfreejoint/\\u003e\\n\",\n        \"      \\u003cgeom name=\\\"ball\\\" type=\\\"sphere\\\" size=\\\".02\\\" /\\u003e\\n\",\n        \"      \\u003cgeom name=\\\"stem\\\" type=\\\"cylinder\\\" pos=\\\"0 0 .02\\\" size=\\\"0.004 .008\\\"/\\u003e\\n\",\n        \"      \\u003cgeom name=\\\"ballast\\\" type=\\\"box\\\" size=\\\".023 .023 0.005\\\"  pos=\\\"0 0 -.015\\\" \\n\",\n        \"       contype=\\\"0\\\" conaffinity=\\\"0\\\" group=\\\"3\\\"/\\u003e\\n\",\n        \"    \\u003c/body\\u003e\\n\",\n        \"  \\u003c/worldbody\\u003e\\n\",\n        \"  \\u003ckeyframe\\u003e\\n\",\n        \"    \\u003ckey name=\\\"spinning\\\" qpos=\\\"0 0 0.02 1 0 0 0\\\" qvel=\\\"0 0 0 0 1 200\\\" /\\u003e\\n\",\n        \"  \\u003c/keyframe\\u003e\\n\",\n        \"\\u003c/mujoco\\u003e\\n\",\n        \"\\\"\\\"\\\"\\n\",\n        \"physics = mujoco.Physics.from_xml_string(tippe_top)\\n\",\n        \"PIL.Image.fromarray(physics.render(camera_id='closeup'))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"bvHlr6maJYIG\"\n      },\n      \"source\": [\n        \"Note several new features of this model definition:\\n\",\n        \"0. The free joint is added with the `\\u003cfreejoint/\\u003e` clause, which is similar to `\\u003cjoint type=\\\"free\\\"/\\u003e`, but prohibits unphysical attributes like friction or stiffness.\\n\",\n        \"1. We use the `\\u003coption/\\u003e` clause to set the integrator to the more accurate Runge Kutta 4th order.\\n\",\n        \"2. We define the floor's grid material inside the `\\u003casset/\\u003e` clause and reference it in the floor geom. \\n\",\n        \"3. We use an invisible and non-colliding box geom called `ballast` to move the top's center-of-mass lower. Having a low center of mass is  (counter-intuitively) required for the flipping behaviour to occur.\\n\",\n        \"4. We save our initial spinning state as a keyframe. It has a high rotational velocity around the z-axis, but is not perfectly oriented with the world.\\n\",\n        \"5. We define a `\\u003ccamera\\u003e` in our model, and then render from it using the `camera_id` argument to `render()`.\\n\",\n        \"Let us examine the state:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"o4S9nYhHOKmb\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"print('positions', physics.data.qpos)\\n\",\n        \"print('velocities', physics.data.qvel)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"71UgzBAqWdtZ\"\n      },\n      \"source\": [\n        \"The velocities are easy to interpret, 6 zeros, one for each DOF. What about the length-7 positions? We can see the initial 2cm height of the body; the subsequent four numbers are the 3D orientation, defined by a *unit quaternion*. These normalized four-vectors, which preserve the topology of the orientation group, are the reason that `data.qpos` can be bigger than `data.qvel`: 3D orientations are represented with **4** numbers while angular velocities are **3** numbers.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"5P4HkhKNGQvs\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Video of the tippe-top {vertical-output: true}\\n\",\n        \"\\n\",\n        \"duration = 7    # (seconds)\\n\",\n        \"framerate = 60  # (Hz)\\n\",\n        \"\\n\",\n        \"# Simulate and display video.\\n\",\n        \"frames = []\\n\",\n        \"physics.reset(0)  # Reset to keyframe 0 (load a saved state).\\n\",\n        \"while physics.data.time \\u003c duration:\\n\",\n        \"  physics.step()\\n\",\n        \"  if len(frames) \\u003c (physics.data.time) * framerate:\\n\",\n        \"    pixels = physics.render(camera_id='closeup')\\n\",\n        \"    frames.append(pixels)\\n\",\n        \"\\n\",\n        \"display_video(frames, framerate)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"rRuFKD2ubPgu\"\n      },\n      \"source\": [\n        \"### Measuring values from `physics.data`\\n\",\n        \"The `physics.data` structure contains all of the dynamic variables and intermediate results produced by the simulation. These are expected to change on each timestep. \\n\",\n        \"\\n\",\n        \"Below we simulate for 2000 timesteps and plot the state and height of the sphere as a function of time.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"1XXB6asJoZ2N\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Measuring values {vertical-output: true}\\n\",\n        \"\\n\",\n        \"timevals = []\\n\",\n        \"angular_velocity = []\\n\",\n        \"stem_height = []\\n\",\n        \"\\n\",\n        \"# Simulate and save data\\n\",\n        \"physics.reset(0)\\n\",\n        \"while physics.data.time \\u003c duration:\\n\",\n        \"  physics.step()\\n\",\n        \"  timevals.append(physics.data.time)\\n\",\n        \"  angular_velocity.append(physics.data.qvel[3:6].copy())\\n\",\n        \"  stem_height.append(physics.named.data.geom_xpos['stem', 'z'])\\n\",\n        \"\\n\",\n        \"dpi = 100\\n\",\n        \"width = 480\\n\",\n        \"height = 640\\n\",\n        \"figsize = (width / dpi, height / dpi)\\n\",\n        \"_, ax = plt.subplots(2, 1, figsize=figsize, dpi=dpi, sharex=True)\\n\",\n        \"\\n\",\n        \"ax[0].plot(timevals, angular_velocity)\\n\",\n        \"ax[0].set_title('angular velocity')\\n\",\n        \"ax[0].set_ylabel('radians / second')\\n\",\n        \"\\n\",\n        \"ax[1].plot(timevals, stem_height)\\n\",\n        \"ax[1].set_xlabel('time (seconds)')\\n\",\n        \"ax[1].set_ylabel('meters')\\n\",\n        \"_ = ax[1].set_title('stem height')\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"UAMItwu8e1WR\"\n      },\n      \"source\": [\n        \"# PyMJCF tutorial\\n\",\n        \"\\n\",\n        \"\\n\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"hPiY8m3MssKM\"\n      },\n      \"source\": [\n        \"This library provides a Python object model for MuJoCo's XML-based\\n\",\n        \"[MJCF](http://www.mujoco.org/book/modeling.html) physics modeling language. The\\n\",\n        \"goal of the library is to allow users to easily interact with and modify MJCF\\n\",\n        \"models in Python, similarly to what the JavaScript DOM does for HTML.\\n\",\n        \"\\n\",\n        \"A key feature of this library is the ability to easily compose multiple separate\\n\",\n        \"MJCF models into a larger one. Disambiguation of duplicated names from different\\n\",\n        \"models, or multiple instances of the same model, is handled automatically.\\n\",\n        \"\\n\",\n        \"One typical use case is when we want robots with a variable number of joints. This is a fundamental change to the kinematics, requiring a new XML descriptor and new binary model to be compiled. \\n\",\n        \"\\n\",\n        \"The following snippets realise this scenario and provide a quick example of this library's use case.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"gKny5EJ4uVzu\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"class Leg(object):\\n\",\n        \"  \\\"\\\"\\\"A 2-DoF leg with position actuators.\\\"\\\"\\\"\\n\",\n        \"  def __init__(self, length, rgba):\\n\",\n        \"    self.model = mjcf.RootElement()\\n\",\n        \"\\n\",\n        \"    # Defaults:\\n\",\n        \"    self.model.default.joint.damping = 2\\n\",\n        \"    self.model.default.joint.type = 'hinge'\\n\",\n        \"    self.model.default.geom.type = 'capsule'\\n\",\n        \"    self.model.default.geom.rgba = rgba  # Continued below...\\n\",\n        \"\\n\",\n        \"    # Thigh:\\n\",\n        \"    self.thigh = self.model.worldbody.add('body')\\n\",\n        \"    self.hip = self.thigh.add('joint', axis=[0, 0, 1])\\n\",\n        \"    self.thigh.add('geom', fromto=[0, 0, 0, length, 0, 0], size=[length/4])\\n\",\n        \"\\n\",\n        \"    # Hip:\\n\",\n        \"    self.shin = self.thigh.add('body', pos=[length, 0, 0])\\n\",\n        \"    self.knee = self.shin.add('joint', axis=[0, 1, 0])\\n\",\n        \"    self.shin.add('geom', fromto=[0, 0, 0, 0, 0, -length], size=[length/5])\\n\",\n        \"\\n\",\n        \"    # Position actuators:\\n\",\n        \"    self.model.actuator.add('position', joint=self.hip, kp=10)\\n\",\n        \"    self.model.actuator.add('position', joint=self.knee, kp=10)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"cFJerI--UtTy\"\n      },\n      \"source\": [\n        \"The `Leg` class describes an abstract articulated leg, with two joints and corresponding proportional-derivative actuators. \\n\",\n        \"\\n\",\n        \"Note that:\\n\",\n        \"\\n\",\n        \"- MJCF attributes correspond directly to arguments of the `add()` method.\\n\",\n        \"- When referencing elements, e.g when specifying the joint to which an actuator is attached, the MJCF element itself is used, rather than the name string.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"cellView\": \"both\",\n        \"id\": \"SESlL_TidKHx\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"BODY_RADIUS = 0.1\\n\",\n        \"BODY_SIZE = (BODY_RADIUS, BODY_RADIUS, BODY_RADIUS / 2)\\n\",\n        \"random_state = np.random.RandomState(42)\\n\",\n        \"\\n\",\n        \"def make_creature(num_legs):\\n\",\n        \"  \\\"\\\"\\\"Constructs a creature with `num_legs` legs.\\\"\\\"\\\"\\n\",\n        \"  rgba = random_state.uniform([0, 0, 0, 1], [1, 1, 1, 1])\\n\",\n        \"  model = mjcf.RootElement()\\n\",\n        \"  model.compiler.angle = 'radian'  # Use radians.\\n\",\n        \"\\n\",\n        \"  # Make the torso geom.\\n\",\n        \"  model.worldbody.add(\\n\",\n        \"      'geom', name='torso', type='ellipsoid', size=BODY_SIZE, rgba=rgba)\\n\",\n        \"\\n\",\n        \"  # Attach legs to equidistant sites on the circumference.\\n\",\n        \"  for i in range(num_legs):\\n\",\n        \"    theta = 2 * i * np.pi / num_legs\\n\",\n        \"    hip_pos = BODY_RADIUS * np.array([np.cos(theta), np.sin(theta), 0])\\n\",\n        \"    hip_site = model.worldbody.add('site', pos=hip_pos, euler=[0, 0, theta])\\n\",\n        \"    leg = Leg(length=BODY_RADIUS, rgba=rgba)\\n\",\n        \"    hip_site.attach(leg.model)\\n\",\n        \"\\n\",\n        \"  return model\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"elyuJiI3U3kM\"\n      },\n      \"source\": [\n        \"The `make_creature` function uses PyMJCF's `attach()` method to procedurally attach legs to the torso. Note that at this stage both the torso and hip attachment sites are children of the `worldbody`, since their parent body has yet to be instantiated. We'll now make an arena with a chequered floor and two lights, and place our creatures in a grid.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"F7_Tx9P9U_VJ\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Six Creatures on a floor.{vertical-output: true}\\n\",\n        \"\\n\",\n        \"arena = mjcf.RootElement()\\n\",\n        \"chequered = arena.asset.add('texture', type='2d', builtin='checker', width=300,\\n\",\n        \"                            height=300, rgb1=[.2, .3, .4], rgb2=[.3, .4, .5])\\n\",\n        \"grid = arena.asset.add('material', name='grid', texture=chequered,\\n\",\n        \"                       texrepeat=[5, 5], reflectance=.2)\\n\",\n        \"arena.worldbody.add('geom', type='plane', size=[2, 2, .1], material=grid)\\n\",\n        \"for x in [-2, 2]:\\n\",\n        \"  arena.worldbody.add('light', pos=[x, -1, 3], dir=[-x, 1, -2])\\n\",\n        \"\\n\",\n        \"# Instantiate 6 creatures with 3 to 8 legs.\\n\",\n        \"creatures = [make_creature(num_legs=num_legs) for num_legs in range(3, 9)]\\n\",\n        \"\\n\",\n        \"# Place them on a grid in the arena.\\n\",\n        \"height = .15\\n\",\n        \"grid = 5 * BODY_RADIUS\\n\",\n        \"xpos, ypos, zpos = np.meshgrid([-grid, 0, grid], [0, grid], [height])\\n\",\n        \"for i, model in enumerate(creatures):\\n\",\n        \"  # Place spawn sites on a grid.\\n\",\n        \"  spawn_pos = (xpos.flat[i], ypos.flat[i], zpos.flat[i])\\n\",\n        \"  spawn_site = arena.worldbody.add('site', pos=spawn_pos, group=3)\\n\",\n        \"  # Attach to the arena at the spawn sites, with a free joint.\\n\",\n        \"  spawn_site.attach(model).add('freejoint')\\n\",\n        \"\\n\",\n        \"# Instantiate the physics and render.\\n\",\n        \"physics = mjcf.Physics.from_mjcf_model(arena)\\n\",\n        \"PIL.Image.fromarray(physics.render())\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"cMfDaD7PfuoI\"\n      },\n      \"source\": [\n        \"Multi-legged creatures, ready to roam! Let's inject some controls and watch them move. We'll generate a sinusoidal open-loop control signal of fixed frequency and random phase, recording both video frames and the horizontal positions of the torso geoms, in order to plot the movement trajectories.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"8Gx39DMEUZDt\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Video of the movement{vertical-output: true}\\n\",\n        \"#@test {\\\"timeout\\\": 600}\\n\",\n        \"\\n\",\n        \"duration = 10   # (Seconds)\\n\",\n        \"framerate = 30  # (Hz)\\n\",\n        \"video = []\\n\",\n        \"pos_x = []\\n\",\n        \"pos_y = []\\n\",\n        \"torsos = []  # List of torso geom elements.\\n\",\n        \"actuators = []  # List of actuator elements.\\n\",\n        \"for creature in creatures:\\n\",\n        \"  torsos.append(creature.find('geom', 'torso'))\\n\",\n        \"  actuators.extend(creature.find_all('actuator'))\\n\",\n        \"\\n\",\n        \"# Control signal frequency, phase, amplitude.\\n\",\n        \"freq = 5\\n\",\n        \"phase = 2 * np.pi * random_state.rand(len(actuators))\\n\",\n        \"amp = 0.9\\n\",\n        \"\\n\",\n        \"# Simulate, saving video frames and torso locations.\\n\",\n        \"physics.reset()\\n\",\n        \"while physics.data.time \\u003c duration:\\n\",\n        \"  # Inject controls and step the physics.\\n\",\n        \"  physics.bind(actuators).ctrl = amp * np.sin(freq * physics.data.time + phase)\\n\",\n        \"  physics.step()\\n\",\n        \"\\n\",\n        \"  # Save torso horizontal positions using bind().\\n\",\n        \"  pos_x.append(physics.bind(torsos).xpos[:, 0].copy())\\n\",\n        \"  pos_y.append(physics.bind(torsos).xpos[:, 1].copy())\\n\",\n        \"\\n\",\n        \"  # Save video frames.\\n\",\n        \"  if len(video) \\u003c physics.data.time * framerate:\\n\",\n        \"    pixels = physics.render()\\n\",\n        \"    video.append(pixels.copy())\\n\",\n        \"\\n\",\n        \"display_video(video, framerate)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"u09JfenWYLZu\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Movement trajectories{vertical-output: true}\\n\",\n        \"\\n\",\n        \"creature_colors = physics.bind(torsos).rgba[:, :3]\\n\",\n        \"fig, ax = plt.subplots(figsize=(4, 4))\\n\",\n        \"ax.set_prop_cycle(color=creature_colors)\\n\",\n        \"_ = ax.plot(pos_x, pos_y, linewidth=4)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"kggQyvNpf_Y9\"\n      },\n      \"source\": [\n        \"The plot above shows the corresponding movement trajectories of creature positions. Note how `physics.bind(torsos)` was used to access both `xpos` and `rgba` values. Once the `Physics` had been instantiated by `from_mjcf_model()`, the `bind()` method will expose both the associated `mjData` and `mjModel` fields of an `mjcf` element, providing unified access to all quantities in the simulation. \"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"wcRX_wu_8q8u\"\n      },\n      \"source\": [\n        \"# Composer tutorial\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"1DMhNPE5tSdw\"\n      },\n      \"source\": [\n        \"In this tutorial we will create a task requiring our \\\"creature\\\" above to press a colour-changing button on the floor with a prescribed force. We begin by implementing our creature as a `composer.Entity`:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"WwfzIqgNuFKt\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title The `Creature` class\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"class Creature(composer.Entity):\\n\",\n        \"  \\\"\\\"\\\"A multi-legged creature derived from `composer.Entity`.\\\"\\\"\\\"\\n\",\n        \"  def _build(self, num_legs):\\n\",\n        \"    self._model = make_creature(num_legs)\\n\",\n        \"\\n\",\n        \"  def _build_observables(self):\\n\",\n        \"    return CreatureObservables(self)\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def mjcf_model(self):\\n\",\n        \"    return self._model\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def actuators(self):\\n\",\n        \"    return tuple(self._model.find_all('actuator'))\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"# Add simple observable features for joint angles and velocities.\\n\",\n        \"class CreatureObservables(composer.Observables):\\n\",\n        \"\\n\",\n        \"  @composer.observable\\n\",\n        \"  def joint_positions(self):\\n\",\n        \"    all_joints = self._entity.mjcf_model.find_all('joint')\\n\",\n        \"    return observable.MJCFFeature('qpos', all_joints)\\n\",\n        \"\\n\",\n        \"  @composer.observable\\n\",\n        \"  def joint_velocities(self):\\n\",\n        \"    all_joints = self._entity.mjcf_model.find_all('joint')\\n\",\n        \"    return observable.MJCFFeature('qvel', all_joints)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"CXZOBK6RkjxH\"\n      },\n      \"source\": [\n        \"The `Creature` Entity includes generic Observables for joint angles and velocities. Because `find_all()` is called on the `Creature`'s MJCF model, it will only return the creature's leg joints, and not the \\\"free\\\" joint with which it will be attached to the world. Note that Composer Entities should override the `_build` and `_build_observables` methods rather than `__init__`. The implementation of `__init__` in the base class calls `_build` and `_build_observables`, in that order, to ensure that the entity's MJCF model is created before its observables. This was a design choice which allows the user to refer to an observable as an attribute (`entity.observables.foo`) while still making it clear which attributes are observables. The stateful `Button` class derives from `composer.Entity` and implements the `initialize_episode` and `after_substep` callbacks.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"BE9VU2EOvR-u\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title The `Button` class\\n\",\n        \"\\n\",\n        \"NUM_SUBSTEPS = 25  # The number of physics substeps per control timestep.\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"class Button(composer.Entity):\\n\",\n        \"  \\\"\\\"\\\"A button Entity which changes colour when pressed with certain force.\\\"\\\"\\\"\\n\",\n        \"  def _build(self, target_force_range=(5, 10)):\\n\",\n        \"    self._min_force, self._max_force = target_force_range\\n\",\n        \"    self._mjcf_model = mjcf.RootElement()\\n\",\n        \"    self._geom = self._mjcf_model.worldbody.add(\\n\",\n        \"        'geom', type='cylinder', size=[0.25, 0.02], rgba=[1, 0, 0, 1])\\n\",\n        \"    self._site = self._mjcf_model.worldbody.add(\\n\",\n        \"        'site', type='cylinder', size=self._geom.size*1.01, rgba=[1, 0, 0, 0])\\n\",\n        \"    self._sensor = self._mjcf_model.sensor.add('touch', site=self._site)\\n\",\n        \"    self._num_activated_steps = 0\\n\",\n        \"\\n\",\n        \"  def _build_observables(self):\\n\",\n        \"    return ButtonObservables(self)\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def mjcf_model(self):\\n\",\n        \"    return self._mjcf_model\\n\",\n        \"  # Update the activation (and colour) if the desired force is applied.\\n\",\n        \"  def _update_activation(self, physics):\\n\",\n        \"    current_force = physics.bind(self.touch_sensor).sensordata[0]\\n\",\n        \"    self._is_activated = (current_force \\u003e= self._min_force and\\n\",\n        \"                          current_force \\u003c= self._max_force)\\n\",\n        \"    physics.bind(self._geom).rgba = (\\n\",\n        \"        [0, 1, 0, 1] if self._is_activated else [1, 0, 0, 1])\\n\",\n        \"    self._num_activated_steps += int(self._is_activated)\\n\",\n        \"\\n\",\n        \"  def initialize_episode(self, physics, random_state):\\n\",\n        \"    self._reward = 0.0\\n\",\n        \"    self._num_activated_steps = 0\\n\",\n        \"    self._update_activation(physics)\\n\",\n        \"\\n\",\n        \"  def after_substep(self, physics, random_state):\\n\",\n        \"    self._update_activation(physics)\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def touch_sensor(self):\\n\",\n        \"    return self._sensor\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def num_activated_steps(self):\\n\",\n        \"    return self._num_activated_steps\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"class ButtonObservables(composer.Observables):\\n\",\n        \"  \\\"\\\"\\\"A touch sensor which averages contact force over physics substeps.\\\"\\\"\\\"\\n\",\n        \"  @composer.observable\\n\",\n        \"  def touch_force(self):\\n\",\n        \"    return observable.MJCFFeature('sensordata', self._entity.touch_sensor,\\n\",\n        \"                                  buffer_size=NUM_SUBSTEPS, aggregator='mean')\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"D9vB5nCwkyIW\"\n      },\n      \"source\": [\n        \"Note how the Button counts the number of sub-steps during which it is pressed with the desired force. It also exposes an `Observable` of the force being applied to the button, whose value is an average of the readings over the physics time-steps.\\n\",\n        \"\\n\",\n        \"We import some `variation` modules and an arena factory:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"aDTTQMHtVawM\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Random initialiser using `composer.variation`\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"class UniformCircle(variation.Variation):\\n\",\n        \"  \\\"\\\"\\\"A uniformly sampled horizontal point on a circle of radius `distance`.\\\"\\\"\\\"\\n\",\n        \"  def __init__(self, distance):\\n\",\n        \"    self._distance = distance\\n\",\n        \"    self._heading = distributions.Uniform(0, 2*np.pi)\\n\",\n        \"\\n\",\n        \"  def __call__(self, initial_value=None, current_value=None, random_state=None):\\n\",\n        \"    distance, heading = variation.evaluate(\\n\",\n        \"        (self._distance, self._heading), random_state=random_state)\\n\",\n        \"    return (distance*np.cos(heading), distance*np.sin(heading), 0)\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"dgZwP-pvxJdt\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title The `PressWithSpecificForce` task\\n\",\n        \"\\n\",\n        \"\\n\",\n        \"class PressWithSpecificForce(composer.Task):\\n\",\n        \"\\n\",\n        \"  def __init__(self, creature):\\n\",\n        \"    self._creature = creature\\n\",\n        \"    self._arena = floors.Floor()\\n\",\n        \"    self._arena.add_free_entity(self._creature)\\n\",\n        \"    self._arena.mjcf_model.worldbody.add('light', pos=(0, 0, 4))\\n\",\n        \"    self._button = Button()\\n\",\n        \"    self._arena.attach(self._button)\\n\",\n        \"\\n\",\n        \"    # Configure initial poses\\n\",\n        \"    self._creature_initial_pose = (0, 0, 0.15)\\n\",\n        \"    button_distance = distributions.Uniform(0.5, .75)\\n\",\n        \"    self._button_initial_pose = UniformCircle(button_distance)\\n\",\n        \"\\n\",\n        \"    # Configure variators\\n\",\n        \"    self._mjcf_variator = variation.MJCFVariator()\\n\",\n        \"    self._physics_variator = variation.PhysicsVariator()\\n\",\n        \"\\n\",\n        \"    # Configure and enable observables\\n\",\n        \"    pos_corrptor = noises.Additive(distributions.Normal(scale=0.01))\\n\",\n        \"    self._creature.observables.joint_positions.corruptor = pos_corrptor\\n\",\n        \"    self._creature.observables.joint_positions.enabled = True\\n\",\n        \"    vel_corruptor = noises.Multiplicative(distributions.LogNormal(sigma=0.01))\\n\",\n        \"    self._creature.observables.joint_velocities.corruptor = vel_corruptor\\n\",\n        \"    self._creature.observables.joint_velocities.enabled = True\\n\",\n        \"    self._button.observables.touch_force.enabled = True\\n\",\n        \"\\n\",\n        \"    def to_button(physics):\\n\",\n        \"      button_pos, _ = self._button.get_pose(physics)\\n\",\n        \"      return self._creature.global_vector_to_local_frame(physics, button_pos)\\n\",\n        \"\\n\",\n        \"    self._task_observables = {}\\n\",\n        \"    self._task_observables['button_position'] = observable.Generic(to_button)\\n\",\n        \"\\n\",\n        \"    for obs in self._task_observables.values():\\n\",\n        \"      obs.enabled = True\\n\",\n        \"\\n\",\n        \"    self.control_timestep = NUM_SUBSTEPS * self.physics_timestep\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def root_entity(self):\\n\",\n        \"    return self._arena\\n\",\n        \"\\n\",\n        \"  @property\\n\",\n        \"  def task_observables(self):\\n\",\n        \"    return self._task_observables\\n\",\n        \"\\n\",\n        \"  def initialize_episode_mjcf(self, random_state):\\n\",\n        \"    self._mjcf_variator.apply_variations(random_state)\\n\",\n        \"\\n\",\n        \"  def initialize_episode(self, physics, random_state):\\n\",\n        \"    self._physics_variator.apply_variations(physics, random_state)\\n\",\n        \"    creature_pose, button_pose = variation.evaluate(\\n\",\n        \"        (self._creature_initial_pose, self._button_initial_pose),\\n\",\n        \"        random_state=random_state)\\n\",\n        \"    self._creature.set_pose(physics, position=creature_pose)\\n\",\n        \"    self._button.set_pose(physics, position=button_pose)\\n\",\n        \"\\n\",\n        \"  def get_reward(self, physics):\\n\",\n        \"    return self._button.num_activated_steps / NUM_SUBSTEPS    \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"dRuuZdLpthbv\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Instantiating an environment{vertical-output: true}\\n\",\n        \"\\n\",\n        \"creature = Creature(num_legs=4)\\n\",\n        \"task = PressWithSpecificForce(creature)\\n\",\n        \"env = composer.Environment(task, random_state=np.random.RandomState(42))\\n\",\n        \"\\n\",\n        \"env.reset()\\n\",\n        \"PIL.Image.fromarray(env.physics.render())\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"giTL_6euZFlw\"\n      },\n      \"source\": [\n        \"# The *Control Suite*\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"zfIcrDECtdB2\"\n      },\n      \"source\": [\n        \"The **Control Suite** is a set of stable, well-tested tasks designed to serve as a benchmark for continuous control learning agents. Tasks are written using the basic MuJoCo wrapper interface. Standardised action, observation and reward structures make suite-wide benchmarking simple and learning curves easy to interpret. Control Suite domains are not meant to be modified, in order to facilitate benchmarking. For full details regarding benchmarking, please refer to our original [publication](https://arxiv.org/abs/1801.00690).\\n\",\n        \"\\n\",\n        \"A video of solved benchmark tasks is [available here](https://www.youtube.com/watch?v=rAai4QzcYbs\\u0026feature=youtu.be).\\n\",\n        \"\\n\",\n        \"The suite come with convenient module level tuples for iterating over tasks:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"a_whTJG8uTp1\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Iterating over tasks{vertical-output: true}\\n\",\n        \"\\n\",\n        \"max_len = max(len(d) for d, _ in suite.BENCHMARKING)\\n\",\n        \"for domain, task in suite.BENCHMARKING:\\n\",\n        \"  print(f'{domain:\\u003c{max_len}}  {task}')\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"qN8y3etfZFly\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Loading and simulating a `suite` task{vertical-output: true}\\n\",\n        \"\\n\",\n        \"# Load the environment\\n\",\n        \"random_state = np.random.RandomState(42)\\n\",\n        \"env = suite.load('hopper', 'stand', task_kwargs={'random': random_state})\\n\",\n        \"\\n\",\n        \"# Simulate episode with random actions\\n\",\n        \"duration = 4  # Seconds\\n\",\n        \"frames = []\\n\",\n        \"ticks = []\\n\",\n        \"rewards = []\\n\",\n        \"observations = []\\n\",\n        \"\\n\",\n        \"spec = env.action_spec()\\n\",\n        \"time_step = env.reset()\\n\",\n        \"\\n\",\n        \"while env.physics.data.time \\u003c duration:\\n\",\n        \"\\n\",\n        \"  action = random_state.uniform(spec.minimum, spec.maximum, spec.shape)\\n\",\n        \"  time_step = env.step(action)\\n\",\n        \"\\n\",\n        \"  camera0 = env.physics.render(camera_id=0, height=200, width=200)\\n\",\n        \"  camera1 = env.physics.render(camera_id=1, height=200, width=200)\\n\",\n        \"  frames.append(np.hstack((camera0, camera1)))\\n\",\n        \"  rewards.append(time_step.reward)\\n\",\n        \"  observations.append(copy.deepcopy(time_step.observation))\\n\",\n        \"  ticks.append(env.physics.data.time)\\n\",\n        \"\\n\",\n        \"html_video = display_video(frames, framerate=1./env.control_timestep())\\n\",\n        \"\\n\",\n        \"# Show video and plot reward and observations\\n\",\n        \"num_sensors = len(time_step.observation)\\n\",\n        \"\\n\",\n        \"_, ax = plt.subplots(1 + num_sensors, 1, sharex=True, figsize=(4, 8))\\n\",\n        \"ax[0].plot(ticks, rewards)\\n\",\n        \"ax[0].set_ylabel('reward')\\n\",\n        \"ax[-1].set_xlabel('time')\\n\",\n        \"\\n\",\n        \"for i, key in enumerate(time_step.observation):\\n\",\n        \"  data = np.asarray([observations[j][key] for j in range(len(observations))])\\n\",\n        \"  ax[i+1].plot(ticks, data, label=key)\\n\",\n        \"  ax[i+1].set_ylabel(key)\\n\",\n        \"\\n\",\n        \"html_video\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"ggVbQr5hZFl5\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Visualizing an initial state of one task per domain in the Control Suite\\n\",\n        \"#@test {\\\"timeout\\\": 180}\\n\",\n        \"domains_tasks = {domain: task for domain, task in suite.ALL_TASKS}\\n\",\n        \"random_state = np.random.RandomState(42)\\n\",\n        \"num_domains = len(domains_tasks)\\n\",\n        \"n_col = num_domains // int(np.sqrt(num_domains))\\n\",\n        \"n_row = num_domains // n_col + int(0 \\u003c num_domains % n_col)\\n\",\n        \"_, ax = plt.subplots(n_row, n_col, figsize=(12, 12))\\n\",\n        \"for a in ax.flat:\\n\",\n        \"  a.axis('off')\\n\",\n        \"  a.grid(False)\\n\",\n        \"\\n\",\n        \"print(f'Iterating over all {num_domains} domains in the Suite:')\\n\",\n        \"for j, [domain, task] in enumerate(domains_tasks.items()):\\n\",\n        \"  print(domain, task)\\n\",\n        \"\\n\",\n        \"  env = suite.load(domain, task, task_kwargs={'random': random_state})\\n\",\n        \"  timestep = env.reset()\\n\",\n        \"  pixels = env.physics.render(height=200, width=200, camera_id=0)\\n\",\n        \"\\n\",\n        \"  ax.flat[j].imshow(pixels)\\n\",\n        \"  ax.flat[j].set_title(domain + ': ' + task)\\n\",\n        \"\\n\",\n        \"clear_output()\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"JHSvxHiaopDb\"\n      },\n      \"source\": [\n        \"# Locomotion\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"yTn3C03dpHzL\"\n      },\n      \"source\": [\n        \"## Humanoid running along corridor with obstacles\\n\",\n        \"\\n\",\n        \"As an illustrative example of using the Locomotion infrastructure to build an RL environment, consider placing a humanoid in a corridor with walls, and a task specifying that the humanoid will be rewarded for running along this corridor, navigating around the wall obstacles using vision. We instantiate the environment as a composition of the Walker, Arena, and Task as follows. First, we build a position-controlled CMU humanoid walker. \"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"gE8rrB7PpN9X\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title A position controlled `cmu_humanoid`\\n\",\n        \"\\n\",\n        \"walker = cmu_humanoid.CMUHumanoidPositionControlledV2020(\\n\",\n        \"    observable_options={'egocentric_camera': dict(enabled=True)})\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"3fYbaDflBrgE\"\n      },\n      \"source\": [\n        \"Next, we construct a corridor-shaped arena that is obstructed by walls.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"t-O17Fnm3E6R\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title A corridor arena with wall obstacles\\n\",\n        \"\\n\",\n        \"arena = corridor_arenas.WallsCorridor(\\n\",\n        \"    wall_gap=3.,\\n\",\n        \"    wall_width=distributions.Uniform(2., 3.),\\n\",\n        \"    wall_height=distributions.Uniform(2.5, 3.5),\\n\",\n        \"    corridor_width=4.,\\n\",\n        \"    corridor_length=30.,\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"970nN38eBx-R\"\n      },\n      \"source\": [\n        \"The task constructor places the walker in the arena.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"dz4Jy2UGpQ4Z\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title A task to navigate the arena\\n\",\n        \"\\n\",\n        \"task = corridor_tasks.RunThroughCorridor(\\n\",\n        \"    walker=walker,\\n\",\n        \"    arena=arena,\\n\",\n        \"    walker_spawn_position=(0.5, 0, 0),\\n\",\n        \"    target_velocity=3.0,\\n\",\n        \"    physics_timestep=0.005,\\n\",\n        \"    control_timestep=0.03,\\n\",\n        \")\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"r-Oy-qTSB4HW\"\n      },\n      \"source\": [\n        \"Finally, a task that rewards the agent for running down the corridor at a specific velocity is instantiated as a `composer.Environment`.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"sQXlaEZk3ytl\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title The `RunThroughCorridor` environment\\n\",\n        \"\\n\",\n        \"env = composer.Environment(\\n\",\n        \"    task=task,\\n\",\n        \"    time_limit=10,\\n\",\n        \"    random_state=np.random.RandomState(42),\\n\",\n        \"    strip_singleton_obs_buffer_dim=True,\\n\",\n        \")\\n\",\n        \"env.reset()\\n\",\n        \"pixels = []\\n\",\n        \"for camera_id in range(3):\\n\",\n        \"  pixels.append(env.physics.render(camera_id=camera_id, width=240))\\n\",\n        \"PIL.Image.fromarray(np.hstack(pixels))\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"HuuQLm8YopDe\"\n      },\n      \"source\": [\n        \"## Multi-Agent Soccer\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"OPNshDEEopDf\"\n      },\n      \"source\": [\n        \"Building on Composer and Locomotion libraries, the Multi-agent soccer environments, introduced in [this paper](https://arxiv.org/abs/1902.07151), follow a consistent task structure of Walkers, Arena, and Task where instead of a single walker, we inject multiple walkers that can interact with each other physically in the same scene. The code snippet below shows how to instantiate a 2-vs-2 Multi-agent Soccer environment with the simple, 5 degree-of-freedom `BoxHead` walker type.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"zAb3je0DAeQo\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title 2-v-2 `Boxhead` soccer\\n\",\n        \"\\n\",\n        \"random_state = np.random.RandomState(42)\\n\",\n        \"env = soccer.load(\\n\",\n        \"    team_size=2,\\n\",\n        \"    time_limit=45.,\\n\",\n        \"    random_state=random_state,\\n\",\n        \"    disable_walker_contacts=False,\\n\",\n        \"    walker_type=soccer.WalkerType.BOXHEAD,\\n\",\n        \")\\n\",\n        \"env.reset()\\n\",\n        \"pixels = []\\n\",\n        \"# Select a random subset of 6 cameras (soccer envs have lots of cameras)\\n\",\n        \"cameras = random_state.choice(env.physics.model.ncam, 6, replace=False)\\n\",\n        \"for camera_id in cameras:\\n\",\n        \"  pixels.append(env.physics.render(camera_id=camera_id, width=240))\\n\",\n        \"image = np.vstack((np.hstack(pixels[:3]), np.hstack(pixels[3:])))\\n\",\n        \"PIL.Image.fromarray(image)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"J_5C2k0NGvxE\"\n      },\n      \"source\": [\n        \" It can trivially be replaced by e.g. the `WalkerType.ANT` walker:\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"WDIGodhBG-Mn\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title 3-v-3 `Ant` soccer\\n\",\n        \"\\n\",\n        \"random_state = np.random.RandomState(42)\\n\",\n        \"env = soccer.load(\\n\",\n        \"    team_size=3,\\n\",\n        \"    time_limit=45.,\\n\",\n        \"    random_state=random_state,\\n\",\n        \"    disable_walker_contacts=False,\\n\",\n        \"    walker_type=soccer.WalkerType.ANT,\\n\",\n        \")\\n\",\n        \"env.reset()\\n\",\n        \"\\n\",\n        \"pixels = []\\n\",\n        \"cameras = random_state.choice(env.physics.model.ncam, 6, replace=False)\\n\",\n        \"for camera_id in cameras:\\n\",\n        \"  pixels.append(env.physics.render(camera_id=camera_id, width=240))\\n\",\n        \"image = np.vstack((np.hstack(pixels[:3]), np.hstack(pixels[3:])))\\n\",\n        \"PIL.Image.fromarray(image)\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"MvK9BW4A5c9p\"\n      },\n      \"source\": [\n        \"# Manipulation\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {\n        \"id\": \"jPt27n2Dch_m\"\n      },\n      \"source\": [\n        \"The `manipulation` module provides a robotic arm, a set of simple objects, and tools for building reward functions for manipulation tasks.\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"cZxmJoovahCA\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Listing all `manipulation` tasks{vertical-output: true}\\n\",\n        \"\\n\",\n        \"# `ALL` is a tuple containing the names of all of the environments in the suite.\\n\",\n        \"print('\\\\n'.join(manipulation.ALL))\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"oj0cJFlR5nTS\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Listing `manipulation` tasks that use vision{vertical-output: true}\\n\",\n        \"print('\\\\n'.join(manipulation.get_environments_by_tag('vision')))\"\n      ]\n    },\n    {\n      \"cell_type\": \"code\",\n      \"execution_count\": null,\n      \"metadata\": {\n        \"id\": \"e_6q4FqFIKxy\"\n      },\n      \"outputs\": [],\n      \"source\": [\n        \"#@title Loading and simulating a `manipulation` task{vertical-output: true}\\n\",\n        \"\\n\",\n        \"env = manipulation.load('stack_2_of_3_bricks_random_order_vision', seed=42)\\n\",\n        \"action_spec = env.action_spec()\\n\",\n        \"\\n\",\n        \"def sample_random_action():\\n\",\n        \"  return env.random_state.uniform(\\n\",\n        \"      low=action_spec.minimum,\\n\",\n        \"      high=action_spec.maximum,\\n\",\n        \"  ).astype(action_spec.dtype, copy=False)\\n\",\n        \"\\n\",\n        \"# Step the environment through a full episode using random actions and record\\n\",\n        \"# the camera observations.\\n\",\n        \"frames = []\\n\",\n        \"timestep = env.reset()\\n\",\n        \"frames.append(timestep.observation['front_close'])\\n\",\n        \"while not timestep.last():\\n\",\n        \"  timestep = env.step(sample_random_action())\\n\",\n        \"  frames.append(timestep.observation['front_close'])\\n\",\n        \"all_frames = np.concatenate(frames, axis=0)\\n\",\n        \"display_video(all_frames, 30)\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"accelerator\": \"GPU\",\n    \"colab\": {\n      \"collapsed_sections\": [\n        \"YkBQUjm6gbGF\",\n        \"YvyGCsgSCxHQ\",\n        \"wtDN43hIJh2C\",\n        \"jZXz9rPYGA-Y\",\n        \"MdUF2UYmR4TA\",\n        \"nQ8XOnRQx7T1\",\n        \"gf9h_wi9weet\",\n        \"NCcZxrDDB1Cj\",\n        \"t5hY0fyXFLcf\",\n        \"Z0UodCxS_v49\",\n        \"22ENjtVuhwsm\",\n        \"SHppAOjvSupc\",\n        \"rRuFKD2ubPgu\",\n        \"UAMItwu8e1WR\",\n        \"wcRX_wu_8q8u\",\n        \"giTL_6euZFlw\",\n        \"JHSvxHiaopDb\",\n        \"yTn3C03dpHzL\",\n        \"HuuQLm8YopDe\",\n        \"MvK9BW4A5c9p\"\n      ],\n      \"last_runtime\": {\n        \"build_target\": \"\",\n        \"kind\": \"local\"\n      },\n      \"name\": \"dm_control\",\n      \"private_outputs\": true,\n      \"provenance\": [],\n      \"toc_visible\": true\n    },\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"name\": \"python3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n"
        }
      ]
    }
  ]
}