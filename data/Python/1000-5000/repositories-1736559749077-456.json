{
  "metadata": {
    "timestamp": 1736559749077,
    "page": 456,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "SystemErrorWang/White-box-Cartoonization",
      "stars": 3962,
      "defaultBranch": "master",
      "files": [
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.9140625,
          "content": "<img src='paper/shinjuku.jpg' align=\"left\" width=1000>\n\n<br><br><br>\n\n# [CVPR2020]Learning to Cartoonize Using White-box Cartoon Representations\n[project page](https://systemerrorwang.github.io/White-box-Cartoonization/) |   [paper](https://github.com/SystemErrorWang/White-box-Cartoonization/blob/master/paper/06791.pdf) |   [twitter](https://twitter.com/IlIIlIIIllIllII/status/1243108510423896065) |   [zhihu](https://zhuanlan.zhihu.com/p/117422157) |   [bilibili](https://www.bilibili.com/video/av56708333) |  [facial model](https://github.com/SystemErrorWang/FacialCartoonization)\n\n- Tensorflow implementation for CVPR2020 paper “Learning to Cartoonize Using White-box Cartoon Representations”.\n- Improved method for facial images are now available:\n- https://github.com/SystemErrorWang/FacialCartoonization\n\n<img src=\"images/method.jpg\" width=\"1000px\"/>\n<img src=\"images/use_cases.jpg\" width=\"1000px\"/>\n\n## Use cases\n\n### Scenery\n<img src=\"images/city1.jpg\" width=\"1000px\"/>\n<img src=\"images/city2.jpg\" width=\"1000px\"/>\n\n### Food\n<img src=\"images/food.jpg\" width=\"1000px\"/>\n\n### Indoor Scenes\n<img src=\"images/home.jpg\" width=\"1000px\"/>\n\n### People\n<img src=\"images/person1.jpg\" width=\"1000px\"/>\n<img src=\"images/person2.jpg\" width=\"1000px\"/>\n\n### More Images Are Shown In The Supplementary Materials\n\n\n## Online demo\n\n- Some kind people made online demo for this project\n- Demo link: https://cartoonize-lkqov62dia-de.a.run.app/cartoonize\n- Code: https://github.com/experience-ml/cartoonize\n- Sample Demo: https://www.youtube.com/watch?v=GqduSLcmhto&feature=emb_title\n\n## Prerequisites\n\n- Training code: Linux or Windows\n- NVIDIA GPU + CUDA CuDNN for performance\n- Inference code: Linux, Windows and MacOS\n\n\n## How To Use\n\n### Installation\n\n- Assume you already have NVIDIA GPU and CUDA CuDNN installed \n- Install tensorflow-gpu, we tested 1.12.0 and 1.13.0rc0 \n- Install scikit-image==0.14.5, other versions may cause problems\n\n\n### Inference with Pre-trained Model\n\n- Store test images in /test_code/test_images\n- Run /test_code/cartoonize.py\n- Results will be saved in /test_code/cartoonized_images\n\n\n### Train\n\n- Place your training data in corresponding folders in /dataset \n- Run pretrain.py, results will be saved in /pretrain folder\n- Run train.py, results will be saved in /train_cartoon folder\n- Codes are cleaned from production environment and untested\n- There may be minor problems but should be easy to resolve\n- Pretrained VGG_19 model can be found at following url:\nhttps://drive.google.com/file/d/1j0jDENjdwxCDb36meP6-u5xDBzmKBOjJ/view?usp=sharing\n\n\n\n### Datasets\n\n- Due to copyright issues, we cannot provide cartoon images used for training\n- However, these training datasets are easy to prepare\n- Scenery images are collected from Shinkai Makoto, Miyazaki Hayao and Hosoda Mamoru films\n- Clip films into frames and random crop and resize to 256x256\n- Portrait images are from Kyoto animations and PA Works\n- We use this repo(https://github.com/nagadomi/lbpcascade_animeface) to detect facial areas\n- Manual data cleaning will greatly increace both datasets quality\n\n## Acknowledgement\n\nWe are grateful for the help from Lvmin Zhang and Style2Paints Research\n\n## License\n- Copyright (C) Xinrui Wang All rights reserved. Licensed under the CC BY-NC-SA 4.0 \n- license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n- Commercial application is prohibited, please remain this license if you clone this repo\n\n## Citation\n\nIf you use this code for your research, please cite our [paper](https://systemerrorwang.github.io/White-box-Cartoonization/):\n\n@InProceedings{Wang_2020_CVPR,\nauthor = {Wang, Xinrui and Yu, Jinze},\ntitle = {Learning to Cartoonize Using White-Box Cartoon Representations},\nbooktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\nmonth = {June},\nyear = {2020}\n}\n\n\n# 中文社区\n\n我们有一个除了技术什么东西都聊的以技术交流为主的群。如果你一次加群失败，可以多次尝试: 816096787。\n"
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "index.html",
          "type": "blob",
          "size": 3.4716796875,
          "content": "<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\t<title>Learning to Cartoonize Using White-box Cartoon Representations</title>\n\t<link rel=\"stylesheet\" type=\"text/css\" href=\"./index_files/pixl-bk.css\">\n\t<link rel=\"stylesheet\" type=\"text/css\" href=\"./index_files/pixl-fonts.css\">\n</head>\n\n<body>\n\n<div class=\"crumb\">\n\t<a href=\"https://github.com/lllyasviel\">Style2Paints Research</a> →\n\t[Wang et al. 2020]\n\t</span>\n</div>\n\n\n<div class=\"content\">\n<div class=\"paperheader\">\n  <div class=\"papertitle\"> Learning to Cartoonize Using White-box Cartoon Representations </div>\n  <br>\n  <div class=\"pubinfo\"> Computer Vision and Pattern Recognition (CVPR), June 2020 </div>\n  <br>\n  <div class=\"authors\"> <a href=\"https://github.com/SystemErrorWang\">Xinrui Wang</a> and Jinze Yu </div>\n</div>\n\n<div class=\"paperimg\"><img src=\"./paper/shinjuku.jpg\"></div>\n<div class=\"longcaption\">Example of image cartoonization with our method: left is a frame in the animation \"Garden of words\", right is a real-world photo processed by our proposed method.</div>\n<div class=\"header\">Abstract</div>\n<p>\n</p><div class=\"abstract\">\n\t\tThis paper presents an approach for image cartooniza- tion. By observing the cartoon painting behavior and consulting artists, we propose to separately identify three white-box representations from images: the surface rep- resentation that contains a smooth surface of cartoon im- ages, the structure representation that refers to the sparse color-blocks and flatten global content in the celluloid style workflow, and the texture representation that reflects high- frequency texture, contours, and details in cartoon im- ages. A Generative Adversarial Network (GAN) framework is used to learn the extracted representations and to car- toonize images.\n\t\t<br>\n\t\tThe learning objectives of our method are separately based on each extracted representations, making our frame- work controllable and adjustable. This enables our ap- proach to meet artists’ requirements in different styles and diverse use cases. Qualitative comparisons and quanti- tative analyses, as well as user studies, have been con- ducted to validate the effectiveness of this approach, and our method outperforms previous methods in all compar- isons. Finally, the ablation study demonstrates the influence of each component in our framework.\n\n</div>\n<div class=\"header\">Files</div>\n<ul>\n<li> <a href=\"./paper/06791.pdf\">Paper</a> (9 MB PDF)</li>\n<li> <a href=\"./paper/06791-supp.pdf\">Supplementary Material</a> (15 MB PDF)</li>\n</ul>\n<div class=\"header\">See Also</div>\n<ul>\n\n<li> <a href=\"https://github.com/SystemErrorWang/White-box-Cartoonization\">Source Code</a> - Only inference code available now, training code will be updated later.</li>\n\n<li> <a href=\"https://www.bilibili.com/video/av56708333\">Demo Video</a> - Generated with early version of our work in bilibili.com.</li>\n\n\n</ul>\n\n<div class=\"header\">Citation</div>\n<p>\nXinrui Wang and Jinze Yu<br>\n\"Learning to Cartoonize Using White-box Cartoon Representations.\"<br>\n<i>IEEE Conference on Computer Vision and Pattern Recognition</i>, June 2020.\n\n<!--\n</p><div class=\"header\">BibTeX</div>\n<p>\n</p><pre>@article{Zhang2020,\n   author = \"Lvmin Zhang and Edgar Simo-Serra and Yi Ji and Chunping Liu\",\n   title = \"Generating Digital Painting Lighting Effects via RGB-space Geometry\",\n   journal = \"ACM Transactions on Graphics\",\n   year = \"2020\"\n}\n</pre>\n</div>\n-->\n\n\n\n</body></html>"
        },
        {
          "name": "index_files",
          "type": "tree",
          "content": null
        },
        {
          "name": "paper",
          "type": "tree",
          "content": null
        },
        {
          "name": "test_code",
          "type": "tree",
          "content": null
        },
        {
          "name": "train_code",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}