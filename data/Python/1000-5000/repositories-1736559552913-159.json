{
  "metadata": {
    "timestamp": 1736559552913,
    "page": 159,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "geopandas/geopandas",
      "stars": 4597,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.2978515625,
          "content": "[report]\nexclude_lines =\n    pragma: no cover\n    def __repr__\n    raise AssertionError\n    raise NotImplementedError\n    if __name__ == .__main__.:\nomit =\n    geopandas/tests/*\n    geopandas/io/tests/*\n    geopandas/tools/tests/*\n    geopandas/_version.py\n    geopandas/datasets/naturalearth_creation.py\n"
        },
        {
          "name": ".git-blame-ignore-revs",
          "type": "blob",
          "size": 0.3056640625,
          "content": "# black-ification of code\n479b6e706293ff1a484e4e121682f3a105a53aa9\n7bc3166cfecdd120b544701cff5e37b4482cbbb5\nf4b749d148f0eb13e7e92fbbf7e2eae79de2543a\n373ac8bf731db1002e09859587c475a5f56c4e8b\n50c59d395bc539eb411f9a5c6cdf04d37510060a\n5dc982edbfc2633cd2c7a22ebd314d1b9b810a9a\n44dba4fde90e8010ea6c71c6cf51b34413440177\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.1181640625,
          "content": "geopandas/_version.py export-subst\n# GitHub syntax highlighting\npixi.lock linguist-language=YAML linguist-generated=true\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.8759765625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nvenv*/\nbuild/\ndist/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\nresult_images\n\n# Sphinx documentation\ndoc/_build/\n.buildinfo\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pytest\n.pytest_cache\n\n.mypy_cache\n\n# projects\n.spyderproject\n.spyproject\n.idea\n.ropeproject\n.vscode\n\n*.py~\n.DS_Store\n\nexamples/nybb_*.zip\n\ndoc/source/savefig\ndoc/source/reference\ndoc/source/docs/reference/api/*.rst\n\ngeopandas.egg-info\ngeopandas/version.py\ngeopandas/datasets/ne_110m_admin_0_countries.zip\n\n.asv\ndoc/source/getting_started/my_file.geojson\n\n.ruff_cache\n.env\n# pixi environments\n.pixi\n*.egg-info\npixi.toml\npixi.lock\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.3125,
          "content": "ci:\n    autofix_prs: false\n    autoupdate_schedule: quarterly\n\nfiles: 'geopandas\\/'\nrepos:\n    - repo: https://github.com/astral-sh/ruff-pre-commit\n      rev: \"v0.5.5\"\n      hooks:\n        - id: ruff-format\n        - id: ruff\n          name: sort imports with ruff\n          args: [--select, I, --fix]\n        - id: ruff"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 61.5498046875,
          "content": "# Changelog\n\n## Version 1.1.0\n\nNew features and improvements:\n\n- Add ``grid_size`` parameter to ``union_all`` and ``dissolve`` (#3445).\n- `GeoDataFrame.plot` now supports `pd.Index` as an input for the `column` keyword (#3463).\n- Avoid change of the plot aspect when plotting missing values (#3438).\n\nBug fixes:\n\n- Fix an issue that showed numpy dtypes in bbox in `to_geo_dict` and `__geo_interface__`. (#3436)\n- Fix an issue in `sample_points` that could occasionally result in non-uniform distribution (#3470).\n- Fix unspecified layer warning being emitted while reading multilayer datasets, even\n  when layer is specified when using the mask or bbox keywords (#3378).\n- Properly support named aggregations over a geometry column in `GroupBy.agg` (#3368).\n- Support GeoDataFrame constructor receiving arguments to `geometry` which are not\n  (Geo)Series, but instead should be interpreted as column names, like Enums (#3384).\n- Fix regression where constructing a GeoSeries from a pd.Series with GeometryDtype values\n  failed when `crs` was provided (#3383).\n- Fix regression where `overlay` with `keep_geom_type` returns wrong results if the\n  input contains invalid geometries (#3395).\n- Fix the dtype of the GeometryArray backing data being incorrect for zero length\n  GeoDataFrames causing errors in `overlay` (#3424).\n- Fix regression where constructing a GeoSeries from a pd.Series with GeometryDtype values\n  failed when `crs` was provided (#3383).\n\nNotes on dependencies:\n\n- GeoPandas 1.1 now requires Python 3.10 or greater and pandas 2.0, numpy 1.24, pyproj 3.5,\n  are now the minimum required version for these dependencies.\n  Furthermore, the minimum tested version for optional dependencies has been updated to\n  fiona 1.8.21, scipy 1.9, matplotlib 3.7, mapclassify 2.5, folium 0.12 and\n  SQLAlchemy 2.0. Older versions of these libraries may continue to work, but are no longer\n  considered supported (#3371).\n\nDeprecations and compatibility notes:\n\n- The `GeoSeries.select` method wrapping the pandas `Series.select` method has been removed.\n  The upstream method no longer exists in all supported version of pandas (#3394).\n\nNew features and improvements:\n\n- Added `geopandas.accessors` module. Import this module to register a\n  `pandas.Series.geo` accessor, which exposes GeoSeries methods via pandas's\n  extension mechanism (#3272).\n\n## Version 1.0.1 (July 2, 2024)\n\nBug fixes:\n\n- Support a named datetime or object dtype index in `explore()` (#3360, #3364).\n- Fix a regression preventing a Series as an argument for geometric methods (#3363)\n\n## Version 1.0.0 (June 24, 2024)\n\nNotes on dependencies:\n\n- GeoPandas 1.0 drops support for shapely<2 and PyGEOS. The only geometry engine that is\n  currently supported is shapely >= 2. As a consequence, spatial indexing based on the\n  rtree package has also been removed (#3035).\n- The I/O engine now defaults to Pyogrio which is now installed with GeoPandas instead\n  of Fiona (#3223).\n\nNew methods:\n\n- Added `count_geometries` method from shapely to GeoSeries/GeoDataframe (#3154).\n- Added `count_interior_rings` method from shapely to GeoSeries/GeoDataframe (#3154)\n- Added `relate_pattern` method from shapely to GeoSeries/GeoDataframe (#3211).\n- Added `intersection_all` method from shapely to GeoSeries/GeoDataframe (#3228).\n- Added `line_merge` method from shapely to GeoSeries/GeoDataframe (#3214).\n- Added `set_precision` and `get_precision` methods from shapely to GeoSeries/GeoDataframe (#3175).\n- Added `count_coordinates` method from shapely to GeoSeries/GeoDataframe (#3026).\n- Added `minimum_clearance` method from shapely to GeoSeries/GeoDataframe (#2989).\n- Added `shared_paths` method from shapely to GeoSeries/GeoDataframe (#3215).\n- Added `is_ccw` method from shapely to GeoSeries/GeoDataframe (#3027).\n- Added `is_closed` attribute from shapely to GeoSeries/GeoDataframe (#3092).\n- Added `force_2d` and `force_3d` methods from shapely to GeoSeries/GeoDataframe (#3090).\n- Added `voronoi_polygons` method from shapely to GeoSeries/GeoDataframe (#3177).\n- Added `contains_properly` method from shapely to GeoSeries/GeoDataframe (#3105).\n- Added `build_area` method exposing `build_area` shapely to GeoSeries/GeoDataframe (#3202).\n- Added `snap` method from shapely to GeoSeries/GeoDataframe (#3086).\n- Added `transform` method from shapely to GeoSeries/GeoDataFrame (#3075).\n- Added `get_geometry` method from shapely to GeoSeries/GeoDataframe (#3287).\n- Added `dwithin` method to check for a \"distance within\" predicate on\n  GeoSeries/GeoDataFrame (#3153).\n- Added `to_geo_dict` method to generate GeoJSON-like dictionary from a GeoDataFrame (#3132).\n- Added `polygonize` method exposing both `polygonize` and `polygonize_full` from\n  shapely to GeoSeries/GeoDataframe (#2963).\n- Added `is_valid_reason` method from shapely to GeoSeries/GeoDataframe (#3176).\n- Added `to_arrow` method and `from_arrow` class method to\n  GeoSeries/GeoDataFrame to export and import to/from Arrow data with GeoArrow\n  extension types (#3219, #3301).\n\nNew features and improvements:\n\n- Added ``predicate=\"dwithin\"`` option and ``distance`` argument to the ``sindex.query()`` method\n and ``sjoin`` (#2882).\n- GeoSeries and GeoDataFrame `__repr__` now trims trailing zeros for a more readable\n  output (#3087).\n- Add `on_invalid` parameter to `from_wkt` and `from_wkb` (#3110).\n- `make_valid` option in `overlay` now uses the `make_valid` method instead of\n  `buffer(0)` (#3113).\n- Passing `\"geometry\"` as `dtype` to `pd.read_csv` will now return a GeoSeries for\n  the specified columns (#3101).\n- Added support to ``read_file`` for the ``mask`` keyword for the pyogrio engine (#3062).\n- Added support to ``read_file`` for the ``columns`` keyword for the fiona engine (#3133).\n- Added support to ``to_parquet`` and ``read_parquet`` for writing and reading files\n  using the GeoArrow-based native geometry encoding of GeoParquet 1.1 (#3253, #3275).\n- Add `sort` keyword to `clip` method for GeoSeries and GeoDataFrame to allow optional\n  preservation of the original order of observations (#3233).\n- Added `show_bbox`, `drop_id` and `to_wgs84` arguments to allow further customization of\n  `GeoSeries.to_json` (#3226).\n- `explore` now supports `GeoDataFrame`s with additional columns containing datetimes, uuids and\n  other non JSON serializable objects (#3261).\n- The `GeoSeries.fillna` method now supports the `limit` keyword (#3290).\n- Added ``on_attribute`` option argument to the ``sjoin()``\n  method, allowing to restrict joins to the observations with\n  matching attributes. (#3231)\n- Added support for `bbox` covering encoding in geoparquet. Can filter reading of parquet\nfiles based on a bounding box, and write out a bounding box column to parquet files (#3282).\n- `align` keyword in binary methods now defaults to `None`, treated as True. Explicit True\n  will silence the warning about mismatched indices (#3212).\n- `GeoSeries.set_crs` can now be used to remove CRS information by passing\n  `crs=None, allow_override=True` (#3316).\n- Added ``autolim`` keyword argument to ``GeoSeries.plot()`` and ``GeoDataFrame.plot()`` (#2817).\n- Added `metadata` parameter to `GeoDataFrame.to_file` (#2850)\n- Updated documentation to clarify that passing a named (Geo)Series as the `geometry`\n  argument to the GeoDataFrame constructor will not use the name but will always\n  produce a GeoDataFrame with an active geometry column named \"geometry\" (#3337).\n- `read_postgis` will query the spatial_ref_sys table to determine the CRS authority\n  instead of its current behaviour of assuming EPSG. In the event the spiatal_ref_sys\n  table is not present, or the SRID is not present, `read_postgis` will fallback\n  on assuming EPSG CRS authority. (#3329)\n\nBackwards incompatible API changes:\n\n- The `sjoin` method will now preserve the name of the index of the right\n  GeoDataFrame, if it has one, instead of always using `\"index_right\"` as the\n  name for the resulting column in the return value (#846, #2144).\n- GeoPandas now raises a ValueError when an unaligned Series is passed as a method\n  argument to avoid confusion of whether the automatic alignment happens or not (#3271).\n- The deprecated default value of GeoDataFrame/ GeoSeries `explode(.., index_parts=True)` is now\n  set to false for consistency with pandas (#3174).\n- The behaviour of `set_geometry` has been changed when passed a (Geo)Series `ser` with a name.\n  The new active geometry column name in this case will be `ser.name`, if not None, rather than\n  the previous active geometry column name. This means that if the new and old names are\n  different, then both columns will be preserved in the GeoDataFrame. To replicate the previous\n  behaviour, you can instead call `gdf.set_geometry(ser.rename(gdf.active_geometry_name))` (#3237).\n  Note that this behaviour change does not affect the `GeoDataframe` constructor, passing a named\n  GeoSeries `ser` to `GeoDataFrame(df, geometry=ser)` will always produce a GeoDataFrame with a\n  geometry column named \"geometry\" to preserve backwards compatibility. If you would like to\n  instead propagate the name of `ser` when constructing a GeoDataFrame, you can instead call\n  `df.set_geometry(ser)` or `GeoDataFrame(df, geometry=ser).rename_geometry(ser.name)` (#3337).\n- `delaunay_triangles` now considers all geometries together when creating the Delaunay triangulation\n  instead of performing the operation element-wise. If you want to generate Delaunay\n  triangles for each geometry separately, use ``shapely.delaunay_triangles`` instead. (#3273)\n- Reading a data source that does not have a geometry field using ``read_file``\n  now returns a Pandas DataFrame instead of a GeoDataFrame with an empty\n  ``geometry`` column.\n\nEnforced deprecations:\n\n- The deprecation of `geopandas.datasets` has been enforced and the module has been\n  removed. New sample datasets are now available in the\n  [geodatasets](https://geodatasets.readthedocs.io/en/latest/) package (#3084).\n- Many longstanding deprecated functions, methods and properties have been removed (#3174), (#3190)\n  - Removed deprecated functions\n    `geopandas.io.read_file`, `geopandas.io.to_file` and `geopandas.io.sql.read_postgis`.\n    `geopandas.read_file`, `geopandas.read_postgis` and the GeoDataFrame/GeoSeries `to_file(..)`\n    method should be used instead.\n  - Removed deprecated `GeometryArray.data` property, `np.asarray(..)` or the `to_numpy()`\n    method should be used instead.\n  - Removed deprecated `sindex.query_bulk` method, using `sindex.query` instead.\n  - Removed deprecated `sjoin` parameter `op`, `predicate` should be supplied instead.\n  - Removed deprecated GeoSeries/ GeoDataFrame methods `__xor__`, `__or__`, `__and__` and\n    `__sub__`. Instead use methods `symmetric_difference`, `union`, `intersection` and\n    `difference` respectively.\n  - Removed deprecated plotting functions `plot_polygon_collection`,\n    `plot_linestring_collection` and `plot_point_collection`, use the GeoSeries/GeoDataFrame `.plot`\n    method directly instead.\n  - Removed deprecated GeoSeries/GeoDataFrame `.plot` parameters `axes` and `colormap`, instead use\n    `ax` and `cmap` respectively.\n  - Removed compatibility for specifying the `version` keyword in `to_parquet` and `to_feather`.\n    This keyword will now be passed through to pyarrow and use `schema_version` to specify the GeoParquet specification version (#3334).\n\nNew deprecations:\n\n- `unary_union` attribute is now deprecated and replaced by the `union_all()` method (#3007) allowing\n  opting for a faster union algorithm for coverages (#3151).\n- The ``include_fields`` and ``ignore_fields`` keywords in ``read_file()`` are deprecated\n  for the default pyogrio engine. Currently those are translated to the ``columns`` keyword\n  for backwards compatibility, but you should directly use the ``columns`` keyword instead\n  to select which columns to read (#3133).\n- The `drop` keyword in `set_geometry` has been deprecated, and in future the `drop=True`\n  behaviour will be removed (#3237). To prepare for this change, you should remove any explicit\n  `drop=False` calls in your code (the default behaviour already is the same as `drop=False`).\n  To replicate the previous `drop=True` behaviour you should replace\n  `gdf.set_geometry(new_geo_col, drop=True)` with\n\n  ```python\n  geo_col_name = gdf.active_geometry_name\n  gdf.set_geometry(new_geo_col).drop(columns=geo_col_name).rename_geometry(geo_col_name)\n  ```\n- The `geopandas.use_pygeos` option has been deprecated and will be removed in GeoPandas\n  1.1 (#3283)\n- Manual overriding of an existing CRS of a GeoSeries or GeoDataFrame by setting the `crs` property has been deprecated\n  and will be disabled in future. Use the `set_crs()` method instead (#3085).\n\nBug fixes:\n\n- Fix `GeoDataFrame.merge()` incorrectly returning a `DataFrame` instead of a\n  `GeoDataFrame` when the `suffixes` argument is applied to the active\n  geometry column (#2933).\n- Fix bug in `GeoDataFrame` constructor where if `geometry` is given a named\n  `GeoSeries` the name was not used as the active geometry column name (#3237).\n- Fix bug in `GeoSeries` constructor when passing a Series and specifying a `crs` to not change the original input data (#2492).\n- Fix regression preventing reading from file paths containing hashes in `read_file`\n  with the fiona engine (#3280). An analgous fix for pyogrio is included in\n  pyogrio 0.8.1.\n- Fix `to_parquet` to write correct metadata in case of 3D geometries (#2824).\n- Fixes for compatibility with psycopg (#3167).\n- Fix to allow appending dataframes with no CRS to PostGIS tables with no CRS (#3328)\n- Fix plotting of all-empty GeoSeries using `explore` (#3316).\n\n## Version 0.14.4 (April 26, 2024)\n\n- Several fixes for compatibility with the upcoming pandas 3.0, numpy 2.0 and\n  fiona 1.10 releases.\n\n## Version 0.14.3 (Jan 31, 2024)\n\n- Several fixes for compatibility with the latest pandas 2.2 release.\n- Fix bug in `pandas.concat` CRS consistency checking where CRS differing by WKT\n  whitespace only were treated as incompatible (#3023).\n\n## Version 0.14.2 (Jan 4, 2024)\n\n- Fix regression in `overlay` where using `buffer(0)` instead of `make_valid` internally\n  produced invalid results (#3074).\n- Fix `explore()` method when the active geometry contains missing and empty geometries (#3094).\n\n## Version 0.14.1 (Nov 11, 2023)\n\n- The Parquet and Feather IO functions now support the latest 1.0.0 version\n  of the GeoParquet specification (geoparquet.org) (#2663).\n- Fix `read_parquet` and `read_feather` for [CVE-2023-47248](https://www.cve.org/CVERecord?id=CVE-2023-47248>) (#3070).\n\n## Version 0.14 (Sep 15, 2023)\n\nGeoPandas will use Shapely 2.0 by default instead of PyGEOS when both Shapely >= 2.0 and\nPyGEOS are installed.  PyGEOS will continue to be used by default when PyGEOS is\ninstalled alongside Shapely < 2.0.  Support for PyGEOS and Shapely < 2.0 will be removed\nin GeoPandas 1.0. (#2999)\n\nAPI changes:\n\n- ``seed`` keyword in ``sample_points`` is deprecated. Use ``rng`` instead. (#2913).\n\nNew methods:\n\n- Added ``concave_hull`` method from shapely to GeoSeries/GeoDataframe (#2903).\n- Added ``delaunay_triangles`` method from shapely to GeoSeries/GeoDataframe (#2907).\n- Added ``extract_unique_points`` method from shapely to GeoSeries/GeoDataframe (#2915).\n- Added ``frechet_distance()`` method from shapely to GeoSeries/GeoDataframe (#2929).\n- Added ``hausdorff_distance`` method from shapely to GeoSeries/GeoDataframe (#2909).\n- Added ``minimum_rotated_rectangle`` method from shapely to GeoSeries/GeoDataframe (#2541).\n- Added ``offset_curve`` method from shapely to GeoSeries/GeoDataframe (#2902).\n- Added ``remove_repeated_points`` method from shapely to GeoSeries/GeoDataframe (#2940).\n- Added ``reverse`` method from shapely to GeoSeries/GeoDataframe (#2988).\n- Added ``segmentize`` method from shapely to GeoSeries/GeoDataFrame (#2910).\n- Added ``shortest_line`` method from shapely to GeoSeries/GeoDataframe (#2960).\n\nNew features and improvements:\n\n- Added ``exclusive`` parameter to ``sjoin_nearest`` method for Shapely >= 2.0 (#2877)\n- Added ``GeoDataFrame.active_geometry_name`` property returning the active geometry column's name or None if no active geometry column is set.\n- The ``to_file()`` method will now automatically detect the FlatGeoBuf driver\n  for files with the `.fgb` extension (#2958)\n\nBug fixes:\n\n- Fix ambiguous error when GeoDataFrame is initialized with a column called ``\"crs\"`` (#2944)\n- Fix a color assignment in ``explore`` when using ``UserDefined`` bins (#2923)\n- Fix bug in `apply` with `axis=1` where the given user defined function returns nested\n  data in the geometry column (#2959)\n- Properly infer schema for ``np.int32`` and ``pd.Int32Dtype`` columns (#2950)\n- ``assert_geodataframe_equal`` now handles GeoDataFrames with no active geometry (#2498)\n\nNotes on (optional) dependencies:\n\n- GeoPandas 0.14 drops support for Python 3.8 and pandas 1.3 and below (the minimum\n  supported pandas version is now 1.4). Further, the minimum required versions for the\n  listed dependencies have now changed to shapely 1.8.0, fiona 1.8.21, pyproj 3.3.0 and\n  matplotlib 3.5.0 (#3001)\n\nDeprecations and compatibility notes:\n\n- `geom_almost_equals()` methods have been deprecated and\n   `geom_equals_exact()` should be used instead (#2604).\n\n## Version 0.13.2 (Jun 6, 2023)\n\nBug fix:\n\n- Fix a regression in reading from local file URIs (``file://..``) using\n  ``geopandas.read_file`` (#2948).\n\n## Version 0.13.1 (Jun 5, 2023)\n\nBug fix:\n\n- Fix a regression in reading from URLs using ``geopandas.read_file`` (#2908). This\n  restores the behaviour to download all data up-front before passing it to the\n  underlying engine (fiona or pyogrio), except if the server supports partial requests\n  (to support reading a subset of a large file).\n\n## Version 0.13 (May 6, 2023)\n\nNew methods:\n\n- Added ``sample_points`` method to sample random points from Polygon or LineString\n  geometries (#2860).\n- New ``hilbert_distance()`` method that calculates the distance along a Hilbert curve\n  for each geometry in a GeoSeries/GeoDataFrame (#2297).\n- Support for sorting geometries (for example, using ``sort_values()``) based on\n  the distance along the Hilbert curve (#2070).\n- Added ``get_coordinates()`` method from shapely to GeoSeries/GeoDataframe (#2624).\n- Added ``minimum_bounding_circle()`` method from shapely to GeoSeries/GeoDataframe (#2621).\n- Added `minimum_bounding_radius()` as GeoSeries method (#2827).\n\nOther new features and improvements:\n\n- The Parquet and Feather IO functions now support the latest 1.0.0-beta.1 version\n  of the GeoParquet specification (<geoparquet.org>) (#2663).\n- Added support to fill missing values in `GeoSeries.fillna` via another `GeoSeries` (#2535).\n- Support specifying ``min_zoom`` and ``max_zoom`` inside the ``map_kwds`` argument for ``.explore()`` (#2599).\n- Added support for append (``mode=\"a\"`` or ``append=True``) in ``to_file()``\n  using ``engine=\"pyogrio\"`` (#2788).\n- Added a ``to_wgs84`` keyword to ``to_json`` allowing automatic re-projecting to follow\n  the 2016 GeoJSON specification (#416).\n- ``to_json`` output now includes a ``\"crs\"`` field if the CRS is not the default WGS84 (#1774).\n- Improve error messages when accessing the `geometry` attribute of GeoDataFrame without an active geometry column\n  related to the default name `\"geometry\"` being provided in the constructor (#2577)\n\nDeprecations and compatibility notes:\n\n- Added warning that ``unary_union`` will return ``'GEOMETRYCOLLECTION EMPTY'`` instead\n  of None for all-None GeoSeries. (#2618)\n- The ``query_bulk()`` method of the spatial index `.sindex` property is deprecated\n  in favor of ``query()`` (#2823).\n\nBug fixes:\n\n- Ensure that GeoDataFrame created from DataFrame is a copy, not a view (#2667)\n- Fix mismatch between geometries and colors in ``plot()`` if an empty or missing\n  geometry is present (#2224)\n- Escape special characters to avoid TemplateSyntaxError in ``explore()`` (#2657)\n- Fix `to_parquet`/`to_feather` to not write an invalid bbox (with NaNs) in the\n  metadata in case of an empty GeoDataFrame (#2653)\n- Fix `to_parquet`/`to_feather` to use correct WKB flavor for 3D geometries (#2654)\n- Fix `read_file` to avoid reading all file bytes prior to calling Fiona or\n  Pyogrio if provided a URL as input (#2796)\n- Fix `copy()` downcasting GeoDataFrames without an active geometry column to a\n  DataFrame (#2775)\n- Fix geometry column name propagation when GeoDataFrame columns are a multiindex (#2088)\n- Fix `iterfeatures()` method of GeoDataFrame to correctly handle non-scalar values\n  when `na='drop'` is specified (#2811)\n- Fix issue with passing custom legend labels to `plot` (#2886)\n\nNotes on (optional) dependencies:\n\n- GeoPandas 0.13 drops support pandas 1.0.5 (the minimum supported\n  pandas version is now 1.1). Further, the minimum required versions for the listed\n  dependencies have now changed to shapely 1.7.1, fiona 1.8.19, pyproj 3.0.1 and\n  matplotlib 3.3.4 (#2655)\n\n## Version 0.12.2 (December 10, 2022)\n\nBug fixes:\n\n- Correctly handle geometries with Z dimension in ``to_crs()`` when using PyGEOS or\n  Shapely >= 2.0 (previously the z coordinates were lost) (#1345).\n- Assign Crimea to Ukraine in the ``naturalearth_lowres`` built-in dataset (#2670)\n\n## Version 0.12.1 (October 29, 2022)\n\nSmall bug-fix release removing the shapely<2 pin in the installation requirements.\n\n## Version 0.12 (October 24, 2022)\n\nThe highlight of this release is the support for Shapely 2.0. This makes it possible to\ntest Shapely 2.0 (currently 2.0b1) alongside GeoPandas.\n\nNote that if you also have PyGEOS installed, you need to set an environment variable\n(`USE_PYGEOS=0`) before importing geopandas to actually test Shapely 2.0 features instead of PyGEOS. See\n<https://geopandas.org/en/latest/getting_started/install.html#using-the-optional-pygeos-dependency>\nfor more details.\n\nNew features and improvements:\n\n- Added ``normalize()`` method from shapely to GeoSeries/GeoDataframe (#2537).\n- Added ``make_valid()`` method from shapely to GeoSeries/GeoDataframe (#2539).\n- Added ``where`` filter to ``read_file`` (#2552).\n- Updated the distributed natural earth datasets (*naturalearth_lowres* and\n  *naturalearth_cities*) to version 5.1 (#2555).\n\nDeprecations and compatibility notes:\n\n- Accessing the `crs` of a `GeoDataFrame` without active geometry column was deprecated\n  and this now raises an AttributeError (#2578).\n- Resolved colormap-related warning in ``.explore()`` for recent Matplotlib versions\n  (#2596).\n\nBug fixes:\n\n- Fix cryptic error message in ``geopandas.clip()`` when clipping with an empty geometry (#2589).\n- Accessing `gdf.geometry` where the active geometry column is missing, and a column\n  named `\"geometry\"` is present will now raise an `AttributeError`, rather than\n  returning `gdf[\"geometry\"]` (#2575).\n- Combining GeoSeries/GeoDataFrames with ``pandas.concat`` will no longer silently\n  override CRS information if not all inputs have the same CRS (#2056).\n\n## Version 0.11.1 (July 24, 2022)\n\nSmall bug-fix release:\n\n- Fix regression (RecursionError) in reshape methods such as ``unstack()``\n  and ``pivot()`` involving MultiIndex, or GeoDataFrame construction with\n  MultiIndex (#2486).\n- Fix regression in ``GeoDataFrame.explode()`` with non-default\n  geometry column name.\n- Fix regression in ``apply()`` causing row-wise all nan float columns to be\n  casted to GeometryDtype (#2482).\n- Fix a crash in datetime column reading where the file contains mixed timezone\n  offsets (#2479). These will be read as UTC localized values.\n- Fix a crash in datetime column reading where the file contains datetimes\n  outside the range supported by [ns] precision (#2505).\n- Fix regression in passing the Parquet or Feather format ``version`` in\n  ``to_parquet`` and ``to_feather``. As a result, the ``version`` parameter\n  for the ``to_parquet`` and ``to_feather`` methods has been replaced with\n  ``schema_version``. ``version`` will be passed directly to underlying\n  feather or parquet writer. ``version`` will only be used to set\n  ``schema_version`` if ``version`` is one of 0.1.0 or 0.4.0 (#2496).\n\nVersion 0.11 (June 20, 2022)\n----------------------------\n\nHighlights of this release:\n\n- The ``geopandas.read_file()`` and `GeoDataFrame.to_file()` methods to read\n  and write GIS file formats can now optionally use the\n  [pyogrio](https://github.com/geopandas/pyogrio/) package under the hood\n  through the ``engine=\"pyogrio\"`` keyword. The pyogrio package implements\n  vectorized IO for GDAL/OGR vector data sources, and is faster compared to\n  the ``fiona``-based engine (#2225).\n- GeoParquet support updated to implement\n  [v0.4.0](https://github.com/opengeospatial/geoparquet/releases/tag/v0.4.0) of the\n  OpenGeospatial/GeoParquet specification (#2441). Backwards compatibility with v0.1.0 of\n  the metadata spec (implemented in the previous releases of GeoPandas) is guaranteed,\n  and reading and writing Parquet and Feather files will no longer produce a ``UserWarning``\n  (#2327).\n\nNew features and improvements:\n\n- Improved handling of GeoDataFrame when the active geometry column is\n  lost from the GeoDataFrame. Previously, square bracket indexing ``gdf[[...]]`` returned\n  a GeoDataFrame when the active geometry column was retained and a DataFrame was\n  returned otherwise. Other pandas indexing methods (``loc``, ``iloc``, etc) did not follow\n  the same rules. The new behaviour for all indexing/reshaping operations is now as\n  follows (#2329, #2060):\n  - If operations produce a ``DataFrame`` containing the active geometry column, a\n    GeoDataFrame is returned\n  - If operations produce a ``DataFrame`` containing ``GeometryDtype`` columns, but not the\n    active geometry column, a ``GeoDataFrame`` is returned, where the active geometry\n    column is set to ``None`` (set the new geometry column with ``set_geometry()``)\n  - If operations produce a ``DataFrame`` containing no ``GeometryDtype`` columns, a\n    ``DataFrame`` is returned (this can be upcast again by calling ``set_geometry()`` or the\n    ``GeoDataFrame`` constructor)\n  - If operations produce a ``Series`` of ``GeometryDtype``, a ``GeoSeries`` is returned,\n    otherwise ``Series`` is returned.\n  - Error messages for having an invalid geometry column\n    have been improved, indicating the name of the last valid active geometry column set\n    and whether other geometry columns can be promoted to the active geometry column\n    (#2329).\n\n- Datetime fields are now read and written correctly for GIS formats which support them\n  (e.g. GPKG, GeoJSON) with fiona 1.8.14 or higher. Previously, datetimes were read as\n  strings (#2202).\n- ``folium.Map`` keyword arguments can now be specified as the ``map_kwds`` argument to\n  ``GeoDataFrame.explore()`` method (#2315).\n- Add a new parameter ``style_function`` to ``GeoDataFrame.explore()`` to enable plot styling\n  based on GeoJSON properties (#2377).\n- It is now possible to write an empty ``GeoDataFrame`` to a file for supported formats\n  (#2240). Attempting to do so will now emit a ``UserWarning`` instead of a ``ValueError``.\n- Fast rectangle clipping has been exposed as ``GeoSeries/GeoDataFrame.clip_by_rect()``\n  (#1928).\n- The ``mask`` parameter of ``GeoSeries/GeoDataFrame.clip()`` now accepts a rectangular mask\n  as a list-like to perform fast rectangle clipping using the new\n  ``GeoSeries/GeoDataFrame.clip_by_rect()`` (#2414).\n- Bundled demo dataset ``naturalearth_lowres`` has been updated to version 5.0.1 of the\n  source, with field ``ISO_A3`` manually corrected for some cases (#2418).\n\nDeprecations and compatibility notes:\n\n- The active development branch of geopandas on GitHub has been renamed from master to\n  main (#2277).\n- Deprecated methods ``GeometryArray.equals_exact()`` and ``GeometryArray.almost_equals()``\n  have been removed. They should\n  be replaced with ``GeometryArray.geom_equals_exact()`` and\n  ``GeometryArray.geom_almost_equals()`` respectively (#2267).\n- Deprecated CRS functions ``explicit_crs_from_epsg()``, ``epsg_from_crs()`` and\n  ``get_epsg_file_contents()`` were removed (#2340).\n- Warning about the behaviour change to ``GeoSeries.isna()`` with empty\n  geometries present has been removed (#2349).\n- Specifying a CRS in the ``GeoDataFrame/GeoSeries`` constructor which contradicted the\n  underlying ``GeometryArray`` now raises a ``ValueError`` (#2100).\n- Specifying a CRS in the ``GeoDataFrame`` constructor when no geometry column is provided\n  and calling ``GeoDataFrame. set_crs`` on a ``GeoDataFrame`` without an active geometry\n  column now raise a ``ValueError`` (#2100)\n- Passing non-geometry data to the``GeoSeries`` constructor is now fully deprecated and\n  will raise a ``TypeError`` (#2314). Previously, a ``pandas.Series`` was returned for\n  non-geometry data.\n- Deprecated ``GeoSeries/GeoDataFrame`` set operations ``__xor__()``,\n  ``__or__()``, ``__and__()`` and ``__sub__()``, ``geopandas.io.file.read_file``/``to_file`` and\n  ``geopandas.io.sql.read_postgis`` now emit ``FutureWarning`` instead of\n  ``DeprecationWarning`` and will be completely removed in a future release.\n- Accessing the ``crs`` of a ``GeoDataFrame`` without active geometry column is deprecated and will be removed in GeoPandas 0.12 (#2373).\n\nBug fixes:\n\n- ``GeoSeries.to_frame`` now creates a ``GeoDataFrame`` with the geometry column name set\n  correctly (#2296)\n- Fix pickle files created with pygeos installed can not being readable when pygeos is\n  not installed (#2237).\n- Fixed ``UnboundLocalError`` in ``GeoDataFrame.plot()`` using ``legend=True`` and\n  ``missing_kwds`` (#2281).\n- Fix ``explode()`` incorrectly relating index to columns, including where the input index\n  is not unique (#2292)\n- Fix ``GeoSeries.[xyz]`` raising an ``IndexError`` when the underlying GeoSeries contains\n  empty points (#2335). Rows corresponding to empty points now contain ``np.nan``.\n- Fix ``GeoDataFrame.iloc`` raising a ``TypeError`` when indexing a ``GeoDataFrame`` with only\n  a single column of ``GeometryDtype`` (#1970).\n- Fix ``GeoDataFrame.iterfeatures()`` not returning features with the same field order as\n  ``GeoDataFrame.columns`` (#2396).\n- Fix ``GeoDataFrame.from_features()`` to support reading GeoJSON with null properties\n  (#2243).\n- Fix ``GeoDataFrame.to_parquet()`` not intercepting ``engine`` keyword argument, breaking\n  consistency with pandas (#2227)\n- Fix ``GeoDataFrame.explore()`` producing an error when ``column`` is of boolean dtype\n  (#2403).\n- Fix an issue where ``GeoDataFrame.to_postgis()`` output the wrong SRID for ESRI\n  authority CRS (#2414).\n- Fix ``GeoDataFrame.from_dict/from_features`` classmethods using ``GeoDataFrame`` rather\n  than ``cls`` as the constructor.\n- Fix ``GeoDataFrame.plot()`` producing incorrect colors with mixed geometry types when\n  ``colors`` keyword is provided. (#2420)\n\nNotes on (optional) dependencies:\n\n- GeoPandas 0.11 drops support for Python 3.7 and pandas 0.25 (the minimum supported\n  pandas version is now 1.0.5). Further, the minimum required versions for the listed\n  dependencies have now changed to shapely 1.7, fiona 1.8.13.post1, pyproj 2.6.1.post1,\n  matplotlib 3.2, mapclassify 2.4.0 (#2358, #2391)\n\nVersion 0.10.2 (October 16, 2021)\n---------------------------------\n\nSmall bug-fix release:\n\n- Fix regression in ``overlay()`` in case no geometries are intersecting (but\n  have overlapping total bounds) (#2172).\n- Fix regression in ``overlay()`` with ``keep_geom_type=True`` in case the\n  overlay of two geometries in a GeometryCollection with other geometry types\n  (#2177).\n- Fix ``overlay()`` to honor the ``keep_geom_type`` keyword for the\n  ``op=\"differnce\"`` case (#2164).\n- Fix regression in ``plot()`` with a mapclassify ``scheme`` in case the\n  formatted legend labels have duplicates (#2166).\n- Fix a bug in the ``explore()`` method ignoring the ``vmin`` and ``vmax`` keywords\n  in case they are set to 0 (#2175).\n- Fix ``unary_union`` to correctly handle a GeoSeries with missing values (#2181).\n- Avoid internal deprecation warning in ``clip()`` (#2179).\n\nVersion 0.10.1 (October 8, 2021)\n--------------------------------\n\nSmall bug-fix release:\n\n- Fix regression in ``overlay()`` with non-overlapping geometries and a\n  non-default ``how`` (i.e. not \"intersection\") (#2157).\n\nVersion 0.10.0 (October 3, 2021)\n--------------------------------\n\nHighlights of this release:\n\n- A new ``sjoin_nearest()`` method to join based on proximity, with the\n  ability to set a maximum search radius (#1865). In addition, the ``sindex``\n  attribute gained a new method for a \"nearest\" spatial index query (#1865,\n  #2053).\n- A new ``explore()`` method on GeoDataFrame and GeoSeries with native support\n  for interactive visualization based on folium / leaflet.js (#1953)\n- The ``geopandas.sjoin()``/``overlay()``/``clip()`` functions are now also\n  available as methods on the GeoDataFrame (#2141, #1984, #2150).\n\nNew features and improvements:\n\n- Add support for pandas' ``value_counts()`` method for geometry dtype (#2047).\n- The ``explode()`` method has a new ``ignore_index`` keyword (consistent with\n  pandas' explode method) to reset the index in the result, and a new\n  ``index_parts`` keywords to control whether a cumulative count indexing the\n  parts of the exploded multi-geometries should be added (#1871).\n- ``points_from_xy()`` is now available as a GeoSeries method ``from_xy`` (#1936).\n- The ``to_file()`` method will now attempt to detect the driver (if not\n  specified) based on the extension of the provided filename, instead of\n  defaulting to ESRI Shapefile (#1609).\n- Support for the ``storage_options`` keyword in ``read_parquet()`` for\n  specifying filesystem-specific options (e.g. for S3) based on fsspec (#2107).\n- The read/write functions now support ``~`` (user home directory) expansion (#1876).\n- Support the ``convert_dtypes()`` method from pandas to preserve the\n  GeoDataFrame class (#2115).\n- Support WKB values in the hex format in ``GeoSeries.from_wkb()`` (#2106).\n- Update the ``estimate_utm_crs()`` method to handle crossing the antimeridian\n  with pyproj 3.1+ (#2049).\n- Improved heuristic to decide how many decimals to show in the repr based on\n  whether the CRS is projected or geographic (#1895).\n- Switched the default for ``geocode()`` from GeoCode.Farm to the Photon\n  geocoding API (<https://photon.komoot.io>) (#2007).\n\nDeprecations and compatibility notes:\n\n- The ``op=`` keyword of ``sjoin()`` to indicate which spatial predicate to use\n  for joining is being deprecated and renamed in favor of a new ``predicate=``\n  keyword (#1626).\n- The ``cascaded_union`` attribute is deprecated, use ``unary_union`` instead (#2074).\n- Constructing a GeoDataFrame with a duplicated \"geometry\" column is now\n  disallowed. This can also raise an error in the ``pd.concat(.., axis=1)``\n  function if this results in duplicated active geometry columns (#2046).\n- The ``explode()`` method currently returns a GeoSeries/GeoDataFrame with a\n  MultiIndex, with an additional level with indices of the parts of the\n  exploded multi-geometries. For consistency with pandas, this will change in\n  the future and the new ``index_parts`` keyword is added to control this.\n\nBug fixes:\n\n- Fix in the ``clip()`` function to correctly clip MultiPoints instead of\n  leaving them intact when partly outside of the clip bounds (#2148).\n- Fix ``GeoSeries.isna()`` to correctly return a boolean Series in case of an\n  empty GeoSeries (#2073).\n- Fix the GeoDataFrame constructor to preserve the geometry name when the\n  argument is already a GeoDataFrame object (i.e. ``GeoDataFrame(gdf)``) (#2138).\n- Fix loss of the values' CRS when setting those values as a column\n  (``GeoDataFrame.__setitem__``) (#1963)\n- Fix in ``GeoDataFrame.apply()`` to preserve the active geometry column name\n  (#1955).\n- Fix in ``sjoin()`` to not ignore the suffixes in case of a right-join\n  (``how=\"right``) (#2065).\n- Fix ``GeoDataFrame.explode()`` with a MultiIndex (#1945).\n- Fix the handling of missing values in ``to/from_wkb`` and ``to_from_wkt`` (#1891).\n- Fix ``to_file()`` and ``to_json()`` when DataFrame has duplicate columns to\n  raise an error (#1900).\n- Fix bug in the colors shown with user-defined classification scheme (#2019).\n- Fix handling of the ``path_effects`` keyword in ``plot()`` (#2127).\n- Fix ``GeoDataFrame.explode()`` to preserve ``attrs`` (#1935)\n\nNotes on (optional) dependencies:\n\n- GeoPandas 0.10.0 dropped support for Python 3.6 and pandas 0.24. Further,\n  the minimum required versions are numpy 1.18, shapely 1.6, fiona 1.8,\n  matplotlib 3.1 and pyproj 2.2.\n- Plotting with a classification schema now requires mapclassify version >=\n  2.4 (#1737).\n- Compatibility fixes for the latest numpy in combination with Shapely 1.7 (#2072)\n- Compatibility fixes for the upcoming Shapely 1.8 (#2087).\n- Compatibility fixes for the latest PyGEOS (#1872, #2014) and matplotlib\n  (colorbar issue, #2066).\n\nVersion 0.9.0 (February 28, 2021)\n---------------------------------\n\nMany documentation improvements and a restyled and restructured website with\na new logo (#1564, #1579, #1617, #1668, #1731, #1750, #1757, #1759).\n\nNew features and improvements:\n\n- The ``geopandas.read_file`` function now accepts more general\n  file-like objects (e.g. ``fsspec`` open file objects). It will now also\n  automatically recognize zipped files (#1535).\n- The ``GeoDataFrame.plot()`` method now provides access to the pandas plotting\n  functionality for the non-geometry columns, either using the ``kind`` keyword\n  or the accessor method (e.g. ``gdf.plot(kind=\"bar\")`` or ``gdf.plot.bar()``)\n  (#1465).\n- New ``from_wkt()``, ``from_wkb()``, ``to_wkt()``, ``to_wkb()`` methods for\n  GeoSeries to construct a GeoSeries from geometries in WKT or WKB\n  representation, or to convert a GeoSeries to a pandas Seriew with WKT or WKB\n  values (#1710).\n- New ``GeoSeries.z`` attribute to access the z-coordinates of Point geometries\n  (similar to the existing ``.x`` and ``.y`` attributes) (#1773).\n- The ``to_crs()`` method now handles missing values (#1618).\n- Support for pandas' new ``.attrs`` functionality (#1658).\n- The ``dissolve()`` method now allows dissolving by no column (``by=None``) to\n  create a union of all geometries (single-row GeoDataFrame) (#1568).\n- New ``estimate_utm_crs()`` method on GeoSeries/GeoDataFrame to determine the\n  UTM CRS based on the bounds (#1646).\n- ``GeoDataFrame.from_dict()`` now accepts ``geometry`` and ``crs`` keywords\n  (#1619).\n- ``GeoDataFrame.to_postgis()`` and ``geopandas.read_postgis()`` now supports\n  both sqlalchemy engine and connection objects (#1638).\n- The ``GeoDataFrame.explode()`` method now allows exploding based on a\n  non-geometry column, using the pandas implementation (#1720).\n- Performance improvement in ``GeoDataFrame/GeoSeries.explode()`` when using\n  the PyGEOS backend (#1693).\n- The binary operation and predicate methods (eg ``intersection()``,\n  ``intersects()``) have a new ``align`` keyword which allows optionally not\n  aligning on the index before performing the operation with ``align=False``\n  (#1668).\n- The ``GeoDataFrame.dissolve()`` method now supports all relevant keywords of\n  ``groupby()``, i.e. the ``level``, ``sort``, ``observed`` and ``dropna`` keywords\n  (#1845).\n- The ``geopandas.overlay()`` function now accepts ``make_valid=False`` to skip\n  the step to ensure the input geometries are valid using ``buffer(0)`` (#1802).\n- The ``GeoDataFrame.to_json()`` method gained a ``drop_id`` keyword to\n  optionally not write the GeoDataFrame's index as the \"id\" field in the\n  resulting JSON (#1637).\n- A new ``aspect`` keyword in the plotting methods to optionally allow retaining\n  the original aspect (#1512)\n- A new ``interval`` keyword in the ``legend_kwds`` group of the ``plot()`` method\n  to control the appearance of the legend labels when using a classification\n  scheme (#1605).\n- The spatial index of a GeoSeries (accessed with the ``sindex`` attribute) is\n  now stored on the underlying array. This ensures that the spatial index is\n  preserved in more operations where possible, and that multiple geometry\n  columns of a GeoDataFrame can each have a spatial index (#1444).\n- Addition of a ``has_sindex`` attribute on the GeoSeries/GeoDataFrame to check\n  if a spatial index has already been initialized (#1627).\n- The ``geopandas.testing.assert_geoseries_equal()`` and ``assert_geodataframe_equal()``\n  testing utilities now have a ``normalize`` keyword (False by default) to\n  normalize geometries before comparing for equality (#1826). Those functions\n  now also give a more informative error message when failing (#1808).\n\nDeprecations and compatibility notes:\n\n- The ``is_ring`` attribute currently returns True for Polygons. In the future,\n  this will be False (#1631). In addition, start to check it for LineStrings\n  and LinearRings (instead of always returning False).\n- The deprecated ``objects`` keyword in the ``intersection()`` method of the\n  ``GeoDataFrame/GeoSeries.sindex`` spatial index object has been removed\n  (#1444).\n\nBug fixes:\n\n- Fix regression in the ``plot()`` method raising an error with empty\n  geometries (#1702, #1828).\n- Fix ``geopandas.overlay()`` to preserve geometries of the correct type which\n  are nested within a GeometryCollection as a result of the overlay\n  operation (#1582). In addition, a warning will now be raised if geometries\n  of different type are dropped from the result (#1554).\n- Fix the repr of an empty GeoSeries to not show spurious warnings (#1673).\n- Fix the ``.crs`` for empty GeoDataFrames (#1560).\n- Fix ``geopandas.clip`` to preserve the correct geometry column name (#1566).\n- Fix bug in ``plot()`` method when using ``legend_kwds`` with multiple subplots\n  (#1583)\n- Fix spurious warning with ``missing_kwds`` keyword of the ``plot()`` method\n  when there are no areas with missing data (#1600).\n- Fix the ``plot()`` method to correctly align values passed to the ``column``\n  keyword as a pandas Series (#1670).\n- Fix bug in plotting MultiPoints when passing values to determine the color\n  (#1694)\n- The ``rename_geometry()`` method now raises a more informative error message\n  when a duplicate column name is used (#1602).\n- Fix ``explode()`` method to preserve the CRS (#1655)\n- Fix the ``GeoSeries.apply()`` method to again accept the ``convert_dtype``\n  keyword to be consistent with pandas (#1636).\n- Fix ``GeoDataFrame.apply()`` to preserve the CRS when possible (#1848).\n- Fix bug in containment test as ``geom in geoseries`` (#1753).\n- The ``shift()`` method of a GeoSeries/GeoDataFrame now preserves the CRS\n  (#1744).\n- The PostGIS IO functionality now quotes table names to ensure it works with\n  case-sensitive names (#1825).\n- Fix the ``GeoSeries`` constructor without passing data but only an index (#1798).\n\nNotes on (optional) dependencies:\n\n- GeoPandas 0.9.0 dropped support for Python 3.5. Further, the minimum\n  required versions are pandas 0.24, numpy 1.15 and shapely 1.6 and fiona 1.8.\n- The ``descartes`` package is no longer required for plotting polygons. This\n  functionality is now included by default in GeoPandas itself, when\n  matplotlib is available (#1677).\n- Fiona is now only imported when used in ``read_file``/``to_file``. This means\n  you can now force geopandas to install without fiona installed (although it\n  is still a default requirement) (#1775).\n- Compatibility with the upcoming Shapely 1.8 (#1659, #1662, #1819).\n\nVersion 0.8.2 (January 25, 2021)\n--------------------------------\n\nSmall bug-fix release for compatibility with PyGEOS 0.9.\n\nVersion 0.8.1 (July 15, 2020)\n-----------------------------\n\nSmall bug-fix release:\n\n- Fix a regression in the ``plot()`` method when visualizing with a\n  JenksCaspallSampled or FisherJenksSampled scheme (#1486).\n- Fix spurious warning in ``GeoDataFrame.to_postgis`` (#1497).\n- Fix the un-pickling with ``pd.read_pickle`` of files written with older\n  GeoPandas versions (#1511).\n\nVersion 0.8.0 (June 24, 2020)\n-----------------------------\n\n**Experimental**: optional use of PyGEOS to speed up spatial operations (#1155).\nPyGEOS is a faster alternative for Shapely (being contributed back to a future\nversion of Shapely), and is used in element-wise spatial operations and for\nspatial index in e.g. ``sjoin`` (#1343, #1401, #1421, #1427, #1428). See the\n[installation docs](https://geopandas.readthedocs.io/en/latest/install.html#using-the-optional-pygeos-dependency)\nfor more info and how to enable it.\n\nNew features and improvements:\n\n- IO enhancements:\n\n  - New ``GeoDataFrame.to_postgis()`` method to write to PostGIS database (#1248).\n  - New Apache Parquet and Feather file format support (#1180, #1435)\n  - Allow appending to files with ``GeoDataFrame.to_file`` (#1229).\n  - Add support for the ``ignore_geometry`` keyword in ``read_file`` to only read\n    the attribute data. If set to True, a pandas DataFrame without geometry is\n    returned (#1383).\n  - ``geopandas.read_file`` now supports reading from file-like objects (#1329).\n  - ``GeoDataFrame.to_file`` now supports specifying the CRS to write to the file\n    (#802). By default it still uses the CRS of the GeoDataFrame.\n  - New ``chunksize`` keyword in ``geopandas.read_postgis`` to read a query in\n    chunks (#1123).\n\n- Improvements related to geometry columns and CRS:\n\n  - Any column of the GeoDataFrame that has a \"geometry\" dtype is now returned\n    as a GeoSeries. This means that when having multiple geometry columns, not\n    only the \"active\" geometry column is returned as a GeoSeries, but also\n    accessing another geometry column (``gdf[\"other_geom_column\"]``) gives a\n    GeoSeries (#1336).\n  - Multiple geometry columns in a GeoDataFrame can now each have a different\n    CRS. The global ``gdf.crs`` attribute continues to returns the CRS of the\n    \"active\" geometry column. The CRS of other geometry columns can be accessed\n    from the column itself (eg ``gdf[\"other_geom_column\"].crs``) (#1339).\n  - New ``set_crs()`` method on GeoDataFrame/GeoSeries to set the CRS of naive\n    geometries (#747).\n\n- Improvements related to plotting:\n\n  - The y-axis is now scaled depending on the center of the plot when using a\n    geographic CRS, instead of using an equal aspect ratio (#1290).\n  - When passing a column of categorical dtype to the ``column=`` keyword of the\n    GeoDataFrame ``plot()``, we now honor all categories and its order (#1483).\n    In addition, a new ``categories`` keyword allows to specify all categories\n    and their order otherwise (#1173).\n  - For choropleths using a classification scheme (using ``scheme=``), the\n    ``legend_kwds`` accept two new keywords to control the formatting of the\n    legend: ``fmt`` with a format string for the bin edges (#1253), and ``labels``\n    to pass fully custom class labels (#1302).\n\n- New ``covers()`` and ``covered_by()`` methods on GeoSeries/GeoDataframe for the\n  equivalent spatial predicates (#1460, #1462).\n- GeoPandas now warns when using distance-based methods with data in a\n  geographic projection (#1378).\n\nDeprecations:\n\n- When constructing a GeoSeries or GeoDataFrame from data that already has a\n  CRS, a deprecation warning is raised when both CRS don't match, and in the\n  future an error will be raised in such a case. You can use the new ``set_crs``\n  method to override an existing CRS. See\n  [the docs](https://geopandas.readthedocs.io/en/latest/projections.html#projection-for-multiple-geometry-columns).\n- The helper functions in the ``geopandas.plotting`` module are deprecated for\n  public usage (#656).\n- The ``geopandas.io`` functions are deprecated, use the top-level ``read_file`` and\n  ``to_file`` instead (#1407).\n- The set operators (``&``, ``|``, ``^``, ``-``) are deprecated, use the\n  ``intersection()``, ``union()``, ``symmetric_difference()``, ``difference()`` methods\n  instead (#1255).\n- The ``sindex`` for empty dataframe will in the future return an empty spatial\n  index instead of ``None`` (#1438).\n- The ``objects`` keyword in the ``intersection`` method of the spatial index\n  returned by the ``sindex`` attribute is deprecated and will be removed in the\n  future (#1440).\n\nBug fixes:\n\n- Fix the ``total_bounds()`` method to ignore missing and empty geometries (#1312).\n- Fix ``geopandas.clip`` when masking with non-overlapping area resulting in an\n  empty GeoDataFrame (#1309, #1365).\n- Fix error in ``geopandas.sjoin`` when joining on an empty geometry column (#1318).\n- CRS related fixes: ``pandas.concat`` preserves CRS when concatenating GeoSeries\n  objects (#1340), preserve the CRS in ``geopandas.clip`` (#1362) and in\n  ``GeoDataFrame.astype`` (#1366).\n- Fix bug in ``GeoDataFrame.explode()`` when 'level_1' is one of the column names\n  (#1445).\n- Better error message when rtree is not installed (#1425).\n- Fix bug in ``GeoSeries.equals()`` (#1451).\n- Fix plotting of multi-part geometries with additional style keywords (#1385).\n\nAnd we now have a [Code of Conduct](https://github.com/geopandas/geopandas/blob/main/CODE_OF_CONDUCT.md)!\n\nGeoPandas 0.8.0 is the last release to support Python 3.5. The next release\nwill require Python 3.6, pandas 0.24, numpy 1.15 and shapely 1.6 or higher.\n\nVersion 0.7.0 (February 16, 2020)\n---------------------------------\n\nSupport for Python 2.7 has been dropped. GeoPandas now works with Python >= 3.5.\n\nThe important API change of this release is that GeoPandas now requires\nPROJ > 6 and pyproj > 2.2, and that the ``.crs`` attribute of a GeoSeries and\nGeoDataFrame no longer stores the CRS information as a proj4 string or dict,\nbut as a ``pyproj.CRS`` object (#1101).\n\nThis gives a better user interface and integrates improvements from pyproj and\nPROJ 6, but might also require some changes in your code. Check the\n[migration guide](https://geopandas.readthedocs.io/en/latest/projections.html#upgrading-to-geopandas-0-7-with-pyproj-2-2-and-proj-6)\nin the documentation.\n\nOther API changes;\n\n- The ``GeoDataFrame.to_file`` method will now also write the GeoDataFrame index\n  to the file, if the index is named and/or non-integer. You can use the\n  ``index=True/False`` keyword to overwrite this default inference (#1059).\n\nNew features and improvements:\n\n- A new ``geopandas.clip`` function to clip a GeoDataFrame to the spatial extent\n  of another shape (#1128).\n- The ``geopandas.overlay`` function now works for all geometry types, including\n  points and linestrings in addition to polygons (#1110).\n- The ``plot()`` method gained support for missing values (in the column that\n  determines the colors). By default it doesn't plot the corresponding\n  geometries, but using the new ``missing_kwds`` argument you can specify how to\n  style those geometries (#1156).\n- The ``plot()`` method now also supports plotting GeometryCollection and\n  LinearRing objects (#1225).\n- Added support for filtering with a geometry or reading a subset of the rows in\n  ``geopandas.read_file`` (#1160).\n- Added support for the new nullable integer data type of pandas in\n  ``GeoDataFrame.to_file`` (#1220).\n\nBug fixes:\n\n- ``GeoSeries.reset_index()`` now correctly results in a GeoDataFrame instead of DataFrame (#1252).\n- Fixed the ``geopandas.sjoin`` function to handle MultiIndex correctly (#1159).\n- Fixed the ``geopandas.sjoin`` function to preserve the index name of the left GeoDataFrame (#1150).\n\nVersion 0.6.3 (February 6, 2020)\n---------------------------------\n\nSmall bug-fix release:\n\n- Compatibility with Shapely 1.7 and pandas 1.0 (#1244).\n- Fix ``GeoDataFrame.fillna`` to accept non-geometry values again when there are\n  no missing values in the geometry column. This should make it easier to fill\n  the numerical columns of the GeoDataFrame (#1279).\n\nVersion 0.6.2 (November 18, 2019)\n---------------------------------\n\nSmall bug-fix release fixing a few regressions:\n\n- Fix a regression in passing an array of RRB(A) tuples to the ``.plot()``\n  method (#1178, #1211).\n- Fix the ``bounds`` and ``total_bounds`` attributes for empty GeoSeries, which\n  also fixes the repr of an empty or all-NA GeoSeries (#1184, #1195).\n- Fix filtering of a GeoDataFrame to preserve the index type when ending up\n  with an empty result (#1190).\n\nVersion 0.6.1 (October 12, 2019)\n--------------------------------\n\nSmall bug-fix release fixing a few regressions:\n\n- Fix ``astype`` when converting to string with Multi geometries (#1145) or when converting a dataframe without geometries (#1144).\n- Fix ``GeoSeries.fillna`` to accept ``np.nan`` again (#1149).\n\nVersion 0.6.0 (September 27, 2019)\n----------------------------------\n\nImportant note! This will be the last release to support Python 2.7 (#1031)\n\nAPI changes:\n\n- A refactor of the internals based on the pandas ExtensionArray interface (#1000). The main user visible changes are:\n\n  - The ``.dtype`` of a GeoSeries is now a ``'geometry'`` dtype (and no longer a numpy ``object`` dtype).\n  - The ``.values`` of a GeoSeries now returns a custom ``GeometryArray``, and no longer a numpy array. To get back a numpy array of Shapely scalars, you can convert explicitly using ``np.asarray(..)``.\n\n- The ``GeoSeries`` constructor now raises a warning when passed non-geometry data. Currently the constructor falls back to return a pandas ``Series``, but in the future this will raise an error (#1085).\n- The missing value handling has been changed to now separate the concepts of missing geometries and empty geometries (#601, 1062). In practice this means that (see [the docs](https://geopandas.readthedocs.io/en/v0.6.0/missing_empty.html) for more details):\n\n  - ``GeoSeries.isna`` now considers only missing values, and if you want to check for empty geometries, you can use ``GeoSeries.is_empty`` (``GeoDataFrame.isna`` already only looked at missing values).\n  - ``GeoSeries.dropna`` now actually drops missing values (before it didn't drop either missing or empty geometries)\n  - ``GeoSeries.fillna`` only fills missing values (behaviour unchanged).\n  - ``GeoSeries.align`` uses missing values instead of empty geometries by default to fill non-matching index entries.\n\nNew features and improvements:\n\n- Addition of a ``GeoSeries.affine_transform`` method, equivalent of Shapely's function (#1008).\n- Addition of a ``GeoDataFrame.rename_geometry`` method to easily rename the active geometry column (#1053).\n- Addition of ``geopandas.show_versions()`` function, which can be used to give an overview of the installed libraries in bug reports (#899).\n- The ``legend_kwds`` keyword of the ``plot()`` method can now also be used to specify keywords for the color bar (#1102).\n- Performance improvement in the ``sjoin()`` operation by re-using existing spatial index of the input dataframes, if available (#789).\n- Updated documentation to work with latest version of geoplot and contextily (#1044, #1088).\n- A new ``geopandas.options`` configuration, with currently a single option to control the display precision of the coordinates (``options.display_precision``). The default is now to show less coordinates (3 for projected and 5 for geographic coordinates), but the default can be overridden with the option.\n\nBug fixes:\n\n- Also try to use ``pysal`` instead of ``mapclassify`` if available (#1082).\n- The ``GeoDataFrame.astype()`` method now correctly returns a ``GeoDataFrame`` if the geometry column is preserved (#1009).\n- The ``to_crs`` method now uses ``always_xy=True`` to ensure correct lon/lat order handling for pyproj>=2.2.0 (#1122).\n- Fixed passing list-like colors in the ``plot()`` method in case of \"multi\" geometries (#1119).\n- Fixed the coloring of shapes and colorbar when passing a custom ``norm`` in the ``plot()`` method (#1091, #1089).\n- Fixed ``GeoDataFrame.to_file`` to preserve VFS file paths (e.g. when a \"s3://\" path is specified) (#1124).\n- Fixed failing case in ``geopandas.sjoin`` with empty geometries (#1138).\n\nIn addition, the minimum required versions of some dependencies have been increased: GeoPandas now requirs pandas >=0.23.4 and matplotlib >=2.0.1 (#1002).\n\nVersion 0.5.1 (July 11, 2019)\n-----------------------------\n\n- Compatibility with latest mapclassify version 2.1.0 (#1025).\n\nVersion 0.5.0 (April 25, 2019)\n------------------------------\n\nImprovements:\n\n- Significant performance improvement (around 10x) for ``GeoDataFrame.iterfeatures``,\n  which also improves ``GeoDataFrame.to_file`` (#864).\n- File IO enhancements based on Fiona 1.8:\n\n  - Support for writing bool dtype (#855) and datetime dtype, if the file format supports it (#728).\n  - Support for writing dataframes with multiple geometry types, if the file format allows it (e.g. GeoJSON for all types, or ESRI Shapefile for Polygon+MultiPolygon) (#827, #867, #870).\n\n- Compatibility with pyproj >= 2 (#962).\n- A new ``geopandas.points_from_xy()`` helper function to convert x and y coordinates to Point objects (#896).\n- The ``buffer`` and ``interpolate`` methods now accept an array-like to specify a variable distance for each geometry (#781).\n- Addition of a ``relate`` method, corresponding to the shapely method that returns the DE-9IM matrix (#853).\n- Plotting improvements:\n\n  - Performance improvement in plotting by only flattening the geometries if there are actually 'Multi' geometries (#785).\n  - Choropleths: access to all ``mapclassify`` classification schemes and addition of the ``classification_kwds`` keyword in the ``plot`` method to specify options for the scheme (#876).\n  - Ability to specify a matplotlib axes object on which to plot the color bar with the ``cax`` keyword, in order to have more control over the color bar placement (#894).\n\n- Changed the default provider in ``geopandas.tools.geocode`` from Google (now requires an API key) to Geocode.Farm (#907, #975).\n\nBug fixes:\n\n- Remove the edge in the legend marker (#807).\n- Fix the ``align`` method to preserve the CRS (#829).\n- Fix ``geopandas.testing.assert_geodataframe_equal`` to correctly compare left and right dataframes (#810).\n- Fix in choropleth mapping when the values contain missing values (#877).\n- Better error message in ``sjoin`` if the input is not a GeoDataFrame (#842).\n- Fix in ``read_postgis`` to handle nullable (missing) geometries (#856).\n- Correctly passing through the ``parse_dates`` keyword in ``read_postgis`` to the underlying pandas method (#860).\n- Fixed the shape of Antarctica in the included demo dataset 'naturalearth_lowres'\n  (by updating to the latest version) (#804).\n\nVersion 0.4.1 (March 5, 2019)\n-----------------------------\n\nSmall bug-fix release for compatibility with the latest Fiona and PySAL\nreleases:\n\n- Compatibility with Fiona 1.8: fix deprecation warning (#854).\n- Compatibility with PySAL 2.0: switched to ``mapclassify`` instead of ``PySAL`` as\n  dependency for choropleth mapping with the ``scheme`` keyword (#872).\n- Fix for new ``overlay`` implementation in case the intersection is empty (#800).\n\nVersion 0.4.0 (July 15, 2018)\n-----------------------------\n\nImprovements:\n\n- Improved ``overlay`` function (better performance, several incorrect behaviours fixed) (#429)\n- Pass keywords to control legend behavior (``legend_kwds``) to ``plot`` (#434)\n- Add basic support for reading remote datasets in ``read_file`` (#531)\n- Pass kwargs for ``buffer`` operation on GeoSeries (#535)\n- Expose all geopy services as options in geocoding (#550)\n- Faster write speeds to GeoPackage (#605)\n- Permit ``read_file`` filtering with a bounding box from a GeoDataFrame (#613)\n- Set CRS on GeoDataFrame returned by ``read_postgis`` (#627)\n- Permit setting markersize for Point GeoSeries plots with column values (#633)\n- Started an example gallery (#463, #690, #717)\n- Support for plotting MultiPoints (#683)\n- Testing functionality (e.g. ``assert_geodataframe_equal``) is now publicly exposed (#707)\n- Add ``explode`` method to GeoDataFrame (similar to the GeoSeries method) (#671)\n- Set equal aspect on active axis on multi-axis figures (#718)\n- Pass array of values to column argument in ``plot`` (#770)\n\nBug fixes:\n\n- Ensure that colorbars are plotted on the correct axis (#523)\n- Handle plotting empty GeoDataFrame (#571)\n- Save z-dimension when writing files (#652)\n- Handle reading empty shapefiles (#653)\n- Correct dtype for empty result of spatial operations (#685)\n- Fix empty ``sjoin`` handling for pandas>=0.23 (#762)\n\nVersion 0.3.0 (August 29, 2017)\n-------------------------------\n\nImprovements:\n\n- Improve plotting performance using ``matplotlib.collections`` (#267)\n- Improve default plotting appearance. The defaults now follow the new matplotlib defaults (#318, #502, #510)\n- Provide access to x/y coordinates as attributes for Point GeoSeries (#383)\n- Make the NYBB dataset available through ``geopandas.datasets`` (#384)\n- Enable ``sjoin`` on non-integer-index GeoDataFrames (#422)\n- Add ``cx`` indexer to GeoDataFrame (#482)\n- ``GeoDataFrame.from_features`` now also accepts a Feature Collection (#225, #507)\n- Use index label instead of integer id in output of ``iterfeatures`` and\n  ``to_json`` (#421)\n- Return empty data frame rather than raising an error when performing a spatial join with non overlapping geodataframes (#335)\n\nBug fixes:\n\n- Compatibility with shapely 1.6.0 (#512)\n- Fix ``fiona.filter`` results when bbox is not None (#372)\n- Fix ``dissolve`` to retain CRS (#389)\n- Fix ``cx`` behavior when using index of 0 (#478)\n- Fix display of lower bin in legend label of choropleth plots using a PySAL scheme (#450)\n\nVersion 0.2.0\n-------------\n\nImprovements:\n\n- Complete overhaul of the documentation\n- Addition of ``overlay`` to perform spatial overlays with polygons (#142)\n- Addition of ``sjoin`` to perform spatial joins (#115, #145, #188)\n- Addition of ``__geo_interface__`` that returns a python data structure\n  to represent the ``GeoSeries`` as a GeoJSON-like ``FeatureCollection`` (#116)\n  and ``iterfeatures`` method (#178)\n- Addition of the ``explode`` (#146) and ``dissolve`` (#310, #311) methods.\n- Addition of the ``sindex`` attribute, a Spatial Index using the optional\n  dependency ``rtree`` (``libspatialindex``) that can be used to speed up\n  certain operations such as overlays (#140, #141).\n- Addition of the ``GeoSeries.cx`` coordinate indexer to slice a GeoSeries based\n  on a bounding box of the coordinates (#55).\n- Improvements to plotting: ability to specify edge colors (#173), support for\n  the ``vmin``, ``vmax``, ``figsize``, ``linewidth`` keywords (#207), legends\n  for chloropleth plots (#210), color points by specifying a colormap (#186) or\n  a single color (#238).\n- Larger flexibility of ``to_crs``, accepting both dicts and proj strings (#289)\n- Addition of embedded example data, accessible through\n  ``geopandas.datasets.get_path``.\n\nAPI changes:\n\n- In the ``plot`` method, the ``axes`` keyword is renamed to ``ax`` for\n  consistency with pandas, and the ``colormap`` keyword is renamed to ``cmap``\n  for consistency with matplotlib (#208, #228, #240).\n\nBug fixes:\n\n- Properly handle rows with missing geometries (#139, #193).\n- Fix ``GeoSeries.to_json`` (#263).\n- Correctly serialize metadata when pickling (#199, #206).\n- Fix ``merge`` and ``concat`` to return correct GeoDataFrame (#247, #320, #322).\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 7.2529296875,
          "content": "# GeoPandas Project Code of Conduct\n\nBehind the GeoPandas Project is an engaged and respectful community made up of people\nfrom all over the world and with a wide range of backgrounds.\nNaturally, this implies diversity of ideas and perspectives on often complex\nproblems. Disagreement and healthy discussion of conflicting viewpoints is\nwelcome: the best solutions to hard problems rarely come from a single angle.\nBut disagreement is not an excuse for aggression: humans tend to take\ndisagreement personally and easily drift into behavior that ultimately degrades\na community. This is particularly acute with online communication across\nlanguage and cultural gaps, where many cues of human behavior are unavailable.\nWe are outlining here a set of principles and processes to support a\nhealthy community in the face of these challenges.\n\nFundamentally, we are committed to fostering a productive, harassment-free\nenvironment for everyone. Rather than considering this code an exhaustive list\nof things that you cant do, take it in the spirit it is intended - a guide to\nmake it easier to enrich all of us and the communities in which we participate.\n\nImportantly: as a member of our community, *you are also a steward of these\nvalues*.  Not all problems need to be resolved via formal processes, and often\na quick, friendly but clear word on an online forum or in person can help\nresolve a misunderstanding and de-escalate things.\n\nHowever, sometimes these informal processes may be inadequate: they fail to\nwork, there is urgency or risk to someone, nobody is intervening publicly and\nyou don't feel comfortable speaking in public, etc.  For these or other\nreasons, structured follow-up may be necessary and here we provide the means\nfor that: we welcome reports by emailing\n[*geopandas-conduct@googlegroups.com*](mailto:geopandas-conduct@googlegroups.com)\nor by filling out\n[this form](https://docs.google.com/forms/d/e/1FAIpQLSd8Tbi2zNl1i2N9COX0yavHEqTGFIPQ1_cLcy1A3JgVc1OrAQ/viewform).\n\nThis code applies equally to founders, developers, mentors and new community\nmembers, in all spaces managed by the GeoPandas Project. This\nincludes the mailing lists, our GitHub organization, our chat room, in-person\nevents, and any other forums created by the project team. In addition,\nviolations of this code outside these spaces may affect a person's ability to\nparticipate within them.\n\nBy embracing the following principles, guidelines and actions to follow or\navoid, you will help us make the GeoPandas Project a welcoming and productive community. Feel\nfree to contact the Code of Conduct Committee at\n[*geopandas-conduct@googlegroups.com*](mailto:geopandas-conduct@googlegroups.com)  with any questions.\n\n\n1. **Be friendly and patient**.\n\n2. **Be welcoming**. We strive to be a community that welcomes and supports\n   people of all backgrounds and identities. This includes, but is not limited\n   to, members of any race, ethnicity, culture, national origin, color,\n   immigration status, social and economic class, educational level, sex, sexual\n   orientation, gender identity and expression, age, physical appearance, family\n   status, technological or professional choices, academic\n   discipline, religion, mental ability, and physical ability.\n\n3. **Be considerate**. Your work will be used by other people, and you in turn\n   will depend on the work of others. Any decision you take will affect users\n   and colleagues, and you should take those consequences into account when\n   making decisions. Remember that we're a world-wide community. You may be\n   communicating with someone with a different primary language or cultural\n   background.\n\n4. **Be respectful**. Not all of us will agree all the time, but disagreement is\n   no excuse for poor behavior or poor manners. We might all experience some\n   frustration now and then, but we cannot allow that frustration to turn into a\n   personal attack. Its important to remember that a community where people\n   feel uncomfortable or threatened is not a productive one.\n\n5. **Be careful in the words that you choose**. Be kind to others. Do not insult\n   or put down other community members. Harassment and other exclusionary\n   behavior are not acceptable. This includes, but is not limited to:\n   * Violent threats or violent language directed against another person\n   * Discriminatory jokes and language\n   * Posting sexually explicit or violent material\n   * Posting (or threatening to post) other people's personally identifying\n     information (\"doxing\")\n   * Personal insults, especially those using racist, sexist, and xenophobic terms\n   * Unwelcome sexual attention\n   * Advocating for, or encouraging, any of the above behavior\n   * Repeated harassment of others. In general, if someone asks you to stop,\n     then stop\n\n6. **Moderate your expectations**. Please respect that community members choose\n   how they spend their time in the project. A thoughtful question about your\n   expectations is preferable to demands for another person's time.\n\n7. **When we disagree, try to understand why**. Disagreements, both social and\n   technical, happen all the time and the GeoPandas Project is no exception.  Try to\n   understand where others are coming from, as seeing a question from their\n   viewpoint may help find a new path forward.  And dont forget that it is\n   human to err: blaming each other doesnt get us anywhere, while we can learn\n   from mistakes to find better solutions.\n\n8. **A simple apology can go a long way**. It can often de-escalate a situation,\n   and telling someone that you are sorry is an act of empathy that doesnt\n   automatically imply an admission of guilt.\n\n\n## Reporting\n\nIf you believe someone is violating the code of conduct, please report this in\na timely manner. Code of conduct violations reduce the value of the community\nfor everyone and we take them seriously.\n\nYou can file a report by emailing\n[*geopandas-conduct@googlegroups.com*](mailto:geopandas-conduct@googlegroups.com) or by filing out\n[this form](https://docs.google.com/forms/d/e/1FAIpQLSd8Tbi2zNl1i2N9COX0yavHEqTGFIPQ1_cLcy1A3JgVc1OrAQ/viewform).\n\nThe online form gives you the option to keep your report anonymous or request\nthat we follow up with you directly. While we cannot follow up on an anonymous\nreport, we will take appropriate action.\n\nMessages sent to the e-mail address or through the form will be sent\nonly to the Code of Conduct Committee, which currently consists of:\n\n* Hannah Aizenman\n* Joris Van den Bossche\n* Martin Fleischmann\n\n\n## Enforcement\n\nEnforcement procedures within the GeoPandas Project follow Project Jupyter's\n[*Enforcement Manual*](https://github.com/jupyter/governance/blob/master/conduct/enforcement.md). For information on enforcement, please view the [original manual](https://github.com/jupyter/governance/blob/master/conduct/enforcement.md).\n\nOriginal text courtesy of the [*Speak\nUp!*](http://web.archive.org/web/20141109123859/http://speakup.io/coc.html),\n[*Django*](https://www.djangoproject.com/conduct) and [*Jupyter*](https://github.com/jupyter/governance/blob/master/conduct/code_of_conduct.md) Projects,\nmodified by the GeoPandas Project. We are grateful to those projects for contributing these materials under open licensing terms for us to easily reuse.\n\nAll content on this page is licensed under a [*Creative Commons\nAttribution*](http://creativecommons.org/licenses/by/3.0/) license.\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 2.9150390625,
          "content": "Guidelines\n==========\n\nContributions to GeoPandas are very welcome. They are likely to\nbe accepted more quickly if they follow these guidelines.\n\nAt this stage of GeoPandas development, the priorities are to define a\nsimple, usable, and stable API and to have clean, maintainable,\nreadable code. Performance matters, but not at the expense of those\ngoals.\n\nIn general, GeoPandas follows the conventions of the pandas project\nwhere applicable. Please read the [contributing\nguidelines](https://geopandas.readthedocs.io/en/latest/community/contributing.html).\n\nIn particular, when submitting a pull request:\n\n- Install the requirements for the development environment (one can do this\n  with either conda, and the environment.yml file, or pip, and the\n  requirements-dev.txt file, and can use the pandas contributing guidelines\n  as a guide).\n- All existing tests should pass. Please make sure that the test\n  suite passes, both locally and on\n  [GitHub Actions](https://github.com/geopandas/geopandas/actions). Status on\n  GHA will be visible on a pull request. GHA are automatically enabled\n  on your own fork as well. To trigger a check, make a PR to your own fork.\n\n- New functionality should include tests. Please write reasonable\n  tests for your code and make sure that they pass on your pull request.\n\n- Classes, methods, functions, etc. should have docstrings. The first\n  line of a docstring should be a standalone summary. Parameters and\n  return values should be documented explicitly.\n\n- Unless your PR implements minor changes or internal work only, make sure\n  it contains a note describing the changes in the `CHANGELOG.md` file.\n\nImproving the documentation and testing for code already in GeoPandas\nis a great way to get started if you'd like to make a contribution.\n\nStyle\n-----\n\n- GeoPandas supports Python 3.10+ only.\n\n- GeoPandas follows [the PEP 8\n  standard](http://www.python.org/dev/peps/pep-0008/) and uses\n  [ruff](https://docs.astral.sh/ruff/) to ensure a consistent\n  code format throughout the project.\n\n- Imports should be grouped with standard library imports first,\n  third-party libraries next, and GeoPandas imports third. Within each\n  grouping, imports should be alphabetized. Always use absolute\n  imports when possible, and explicit relative imports for local\n  imports when necessary in tests.\n\n- You can set up [pre-commit hooks](https://pre-commit.com/) to\n  automatically run `ruff` when you make a git\n  commit. This can be done by installing `pre-commit`:\n\n    $ python -m pip install pre-commit\n\n  From the root of the geopandas repository, you should then install\n  `pre-commit`:\n\n    $ pre-commit install\n\n  Then `ruff` will be run automatically each time you\n  commit changes. You can skip these checks with `git commit\n  --no-verify`. You can also configure your local git clone to have\n  `git blame` ignore the commits that introduced large formatting-only\n  changes with:\n\n    $ git config blame.ignoreRevsFile .git-blame-ignore-revs\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 1.462890625,
          "content": "Copyright (c) 2013-2022, GeoPandas developers.\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n * Neither the name of GeoPandas nor the names of its contributors may\n   be used to endorse or promote products derived from this software without\n   specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0703125,
          "content": "include versioneer.py\ninclude geopandas/_version.py\ninclude LICENSE.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.025390625,
          "content": "[![pypi](https://img.shields.io/pypi/v/geopandas.svg)](https://pypi.python.org/pypi/geopandas/)\n[![Actions Status](https://github.com/geopandas/geopandas/workflows/Tests/badge.svg)](https://github.com/geopandas/geopandas/actions?query=workflow%3ATests)\n[![Coverage Status](https://codecov.io/gh/geopandas/geopandas/branch/main/graph/badge.svg)](https://codecov.io/gh/geopandas/geopandas)\n[![Join the chat at https://gitter.im/geopandas/geopandas](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/geopandas/geopandas?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/geopandas/geopandas/main)\n[![DOI](https://zenodo.org/badge/11002815.svg)](https://zenodo.org/badge/latestdoi/11002815)\n[![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&colorA=E1523D&colorB=007D8A)](https://numfocus.org)\n\nGeoPandas\n---------\n\nPython tools for geographic data\n\nIntroduction\n------------\n\nGeoPandas is a project to add support for geographic data to\n[pandas](http://pandas.pydata.org) objects.  It currently implements\n`GeoSeries` and `GeoDataFrame` types which are subclasses of\n`pandas.Series` and `pandas.DataFrame` respectively.  GeoPandas\nobjects can act on [shapely](http://shapely.readthedocs.io/en/latest/)\ngeometry objects and perform geometric operations.\n\nGeoPandas geometry operations are cartesian.  The coordinate reference\nsystem (crs) can be stored as an attribute on an object, and is\nautomatically set when loading from a file.  Objects may be\ntransformed to new coordinate systems with the `to_crs()` method.\nThere is currently no enforcement of like coordinates for operations,\nbut that may change in the future.\n\nDocumentation is available at [geopandas.org](http://geopandas.org)\n(current release) and\n[Read the Docs](http://geopandas.readthedocs.io/en/latest/)\n(release and development versions).\n\n[//]: # (numfocus-fiscal-sponsor-attribution)\n\nThe GeoPandas project uses an [open governance model](https://github.com/geopandas/governance/blob/main/Governance.md)\nand is fiscally sponsored by [NumFOCUS](https://numfocus.org/). Consider making\na [tax-deductible donation](https://numfocus.org/donate-for-geopandas) to help the project\npay for developer time, professional services, travel, workshops, and a variety of other needs.\n\n<div align=\"center\">\n  <a href=\"https://numfocus.org/project/geopandas\">\n    <img height=\"60px\"\n         src=\"https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png\"\n         align=\"center\">\n  </a>\n</div>\n<br>\n\nInstall\n--------\n\nSee the [installation docs](https://geopandas.readthedocs.io/en/latest/install.html)\nfor all details. GeoPandas depends on the following packages:\n\n- ``pandas``\n- ``shapely``\n- ``pyogrio``\n- ``pyproj``\n- ``packaging``\n\nFurther, ``matplotlib`` is an optional dependency, required for plotting.\nThose packages depend on several low-level libraries for geospatial analysis, which can be a challenge to install. Therefore, we recommend to install GeoPandas using the [conda package manager](https://conda.io/en/latest/). See the [installation docs](https://geopandas.readthedocs.io/en/latest/install.html) for more details.\n\nGet in touch\n------------\n\n- Ask usage questions (\"How do I?\") on [StackOverflow](https://stackoverflow.com/questions/tagged/geopandas) or [GIS StackExchange](https://gis.stackexchange.com/questions/tagged/geopandas).\n- Get involved in [discussions on GitHub](https://github.com/geopandas/geopandas/discussions)\n- Report bugs, suggest features or view the source code [on GitHub](https://github.com/geopandas/geopandas).\n- For a quick question about a bug report or feature request, or Pull Request, head over to the [gitter channel](https://gitter.im/geopandas/geopandas).\n- For less well defined questions or ideas, or to announce other projects of interest to GeoPandas users, ... use the [mailing list](https://groups.google.com/forum/#!forum/geopandas).\n\nExamples\n--------\n\n    >>> import geopandas\n    >>> from shapely.geometry import Polygon\n    >>> p1 = Polygon([(0, 0), (1, 0), (1, 1)])\n    >>> p2 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n    >>> p3 = Polygon([(2, 0), (3, 0), (3, 1), (2, 1)])\n    >>> g = geopandas.GeoSeries([p1, p2, p3])\n    >>> g\n    0         POLYGON ((0 0, 1 0, 1 1, 0 0))\n    1    POLYGON ((0 0, 1 0, 1 1, 0 1, 0 0))\n    2    POLYGON ((2 0, 3 0, 3 1, 2 1, 2 0))\n    dtype: geometry\n\n![Example 1](doc/source/gallery/test.png)\n\nSome geographic operations return normal pandas objects.  The `area` property of a `GeoSeries` will return a `pandas.Series` containing the area of each item in the `GeoSeries`:\n\n    >>> print(g.area)\n    0    0.5\n    1    1.0\n    2    1.0\n    dtype: float64\n\nOther operations return GeoPandas objects:\n\n    >>> g.buffer(0.5)\n    0    POLYGON ((-0.3535533905932737 0.35355339059327...\n    1    POLYGON ((-0.5 0, -0.5 1, -0.4975923633360985 ...\n    2    POLYGON ((1.5 0, 1.5 1, 1.502407636663901 1.04...\n    dtype: geometry\n\n![Example 2](doc/source/gallery/test_buffer.png)\n\nGeoPandas objects also know how to plot themselves. GeoPandas uses\n[matplotlib](http://matplotlib.org) for plotting. To generate a plot of a\n`GeoSeries`, use:\n\n    >>> g.plot()\n\nGeoPandas also implements alternate constructors that can read any data format recognized by [pyogrio](http://pyogrio.readthedocs.io/en/latest/). To read a zip file containing an ESRI shapefile with the [boroughs boundaries of New York City](https://data.cityofnewyork.us/City-Government/Borough-Boundaries/tqmj-j8zm) (the example can be fetched using the [`geodatasets`](https://geodatasets.readthedocs.io/en/latest/) package):\n\n    >>> import geodatasets\n    >>> nybb_path = geodatasets.get_path('nybb')\n    >>> boros = geopandas.read_file(nybb_path)\n    >>> boros.set_index('BoroCode', inplace=True)\n    >>> boros.sort_index(inplace=True)\n    >>> boros\n                   BoroName     Shape_Leng    Shape_Area  \\\n    BoroCode\n    1             Manhattan  359299.096471  6.364715e+08\n    2                 Bronx  464392.991824  1.186925e+09\n    3              Brooklyn  741080.523166  1.937479e+09\n    4                Queens  896344.047763  3.045213e+09\n    5         Staten Island  330470.010332  1.623820e+09\n\n                                                       geometry\n    BoroCode\n    1         MULTIPOLYGON (((981219.0557861328 188655.31579...\n    2         MULTIPOLYGON (((1012821.805786133 229228.26458...\n    3         MULTIPOLYGON (((1021176.479003906 151374.79699...\n    4         MULTIPOLYGON (((1029606.076599121 156073.81420...\n    5         MULTIPOLYGON (((970217.0223999023 145643.33221...\n\n![New York City boroughs](doc/source/gallery/nyc.png)\n\n    >>> boros['geometry'].convex_hull\n    BoroCode\n    1    POLYGON ((977855.4451904297 188082.3223876953,...\n    2    POLYGON ((1017949.977600098 225426.8845825195,...\n    3    POLYGON ((988872.8212280273 146772.0317993164,...\n    4    POLYGON ((1000721.531799316 136681.776184082, ...\n    5    POLYGON ((915517.6877458114 120121.8812543372,...\n    dtype: geometry\n\n![Convex hulls of New York City boroughs](doc/source/gallery/nyc_hull.png)\n"
        },
        {
          "name": "asv.conf.json",
          "type": "blob",
          "size": 6.0224609375,
          "content": "{\n    // The version of the config file format.  Do not change, unless\n    // you know what you are doing.\n    \"version\": 1,\n\n    // The name of the project being benchmarked\n    \"project\": \"geopandas\",\n\n    // The project's homepage\n    \"project_url\": \"http://geopandas.org/\",\n\n    // The URL or local path of the source code repository for the\n    // project being benchmarked\n    \"repo\": \".\",\n\n    // List of branches to benchmark. If not provided, defaults to \"master\"\n    // (for git) or \"default\" (for mercurial).\n    // \"branches\": [\"master\"], // for git\n    // \"branches\": [\"default\"],    // for mercurial\n\n    // The DVCS being used.  If not set, it will be automatically\n    // determined from \"repo\" by looking at the protocol in the URL\n    // (if remote), or by looking for special directories, such as\n    // \".git\" (if local).\n    // \"dvcs\": \"git\",\n\n    // The tool to use to create environments.  May be \"conda\",\n    // \"virtualenv\" or other value depending on the plugins in use.\n    // If missing or the empty string, the tool will be automatically\n    // determined by looking for tools on the PATH environment\n    // variable.\n    \"environment_type\": \"conda\",\n    \"conda_channels\": [\"conda-forge\", \"defaults\"],\n\n    // timeout in seconds for installing any dependencies in environment\n    // defaults to 10 min\n    //\"install_timeout\": 600,\n\n    // the base URL to show a commit for the project.\n    \"show_commit_url\": \"http://github.com/geopandas/geopandas/commit/\",\n\n    // The Pythons you'd like to test against.  If not provided, defaults\n    // to the current version of Python used to run `asv`.\n    // \"pythons\": [\"2.7\", \"3.3\"],\n\n    // The matrix of dependencies to test.  Each key is the name of a\n    // package (in PyPI) and the values are version numbers.  An empty\n    // list or empty string indicates to just test against the default\n    // (latest) version. null indicates that the package is to not be\n    // installed. If the package to be tested is only available from\n    // PyPi, and the 'environment_type' is conda, then you can preface\n    // the package name by 'pip+', and the package will be installed via\n    // pip (with all the conda available packages installed first,\n    // followed by the pip installed packages).\n    //\n    \"matrix\": {\n        \"pandas\": [],\n        \"shapely\": [],\n        \"pyogrio\": [],\n        \"pyproj\": [],\n        \"matplotlib\": [],\n    },\n    //     \"numpy\": [\"1.6\", \"1.7\"],\n    //     \"six\": [\"\", null],        // test with and without six installed\n    //     \"pip+emcee\": [\"\"],   // emcee is only available for install with pip.\n    // },\n\n    // Combinations of libraries/python versions can be excluded/included\n    // from the set to test. Each entry is a dictionary containing additional\n    // key-value pairs to include/exclude.\n    //\n    // An exclude entry excludes entries where all values match. The\n    // values are regexps that should match the whole string.\n    //\n    // An include entry adds an environment. Only the packages listed\n    // are installed. The 'python' key is required. The exclude rules\n    // do not apply to includes.\n    //\n    // In addition to package names, the following keys are available:\n    //\n    // - python\n    //     Python version, as in the *pythons* variable above.\n    // - environment_type\n    //     Environment type, as above.\n    // - sys_platform\n    //     Platform, as in sys.platform. Possible values for the common\n    //     cases: 'linux2', 'win32', 'cygwin', 'darwin'.\n    //\n    // \"exclude\": [\n    //     {\"python\": \"3.2\", \"sys_platform\": \"win32\"}, // skip py3.2 on windows\n    //     {\"environment_type\": \"conda\", \"six\": null}, // don't run without six on conda\n    // ],\n    //\n    // \"include\": [\n    //     // additional env for python2.7\n    //     {\"python\": \"2.7\", \"numpy\": \"1.8\"},\n    //     // additional env if run on windows+conda\n    //     {\"platform\": \"win32\", \"environment_type\": \"conda\", \"python\": \"2.7\", \"libpython\": \"\"},\n    // ],\n\n    // The directory (relative to the current directory) that benchmarks are\n    // stored in.  If not provided, defaults to \"benchmarks\"\n    // \"benchmark_dir\": \"benchmarks\",\n\n    // The directory (relative to the current directory) to cache the Python\n    // environments in.  If not provided, defaults to \"env\"\n    \"env_dir\": \".asv/env\",\n\n    // The directory (relative to the current directory) that raw benchmark\n    // results are stored in.  If not provided, defaults to \"results\".\n    \"results_dir\": \".asv/results\",\n\n    // The directory (relative to the current directory) that the html tree\n    // should be written to.  If not provided, defaults to \"html\".\n    \"html_dir\": \".asv/html\",\n\n    // The number of characters to retain in the commit hashes.\n    // \"hash_length\": 8,\n\n    // `asv` will cache wheels of the recent builds in each\n    // environment, making them faster to install next time.  This is\n    // number of builds to keep, per environment.\n    // \"wheel_cache_size\": 0\n\n    // The commits after which the regression search in `asv publish`\n    // should start looking for regressions. Dictionary whose keys are\n    // regexps matching to benchmark names, and values corresponding to\n    // the commit (exclusive) after which to start looking for\n    // regressions.  The default is to start from the first commit\n    // with results. If the commit is `null`, regression detection is\n    // skipped for the matching benchmark.\n    //\n    // \"regressions_first_commits\": {\n    //    \"some_benchmark\": \"352cdf\",  // Consider regressions only after this commit\n    //    \"another_benchmark\": null,   // Skip regression detection altogether\n    // }\n\n    // The thresholds for relative change in results, after which `asv\n    // publish` starts reporting regressions. Dictionary of the same\n    // form as in ``regressions_first_commits``, with values\n    // indicating the thresholds.  If multiple entries match, the\n    // maximum is taken. If no entry matches, the default is 5%.\n    //\n    // \"regressions_thresholds\": {\n    //    \"some_benchmark\": 0.01,     // Threshold of 1%\n    //    \"another_benchmark\": 0.5,   // Threshold of 50%\n    // }\n}\n"
        },
        {
          "name": "benchmarks",
          "type": "tree",
          "content": null
        },
        {
          "name": "ci",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.1591796875,
          "content": "coverage:\n  status:\n    project:\n      default:\n        target: 95%    # the required coverage value\n        threshold: 0.2%  # the leniency in hitting the target\n"
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "environment-dev.yml",
          "type": "blob",
          "size": 0.685546875,
          "content": "name: geopandas-dev\nchannels:\n    - conda-forge\ndependencies:\n    - python\n    # required\n    - pyogrio>=0.7.2\n    - pandas>=2.0\n    - pyproj>=3.5.0\n    - shapely>=2.0.0\n    - packaging\n\n    # testing\n    - pytest>=3.1.0\n    - pytest-cov\n    - pytest-xdist\n    - fsspec\n    - codecov\n\n    # styling\n    - pre-commit\n    - ruff==0.5.5\n\n    # optional\n    - folium\n    - xyzservices\n    - scipy\n    - libspatialite\n    - geoalchemy2\n    - pyarrow\n    # doctest testing\n    - pytest-doctestplus\n    # geocoding\n    - geopy\n    # geodatabase access\n    - psycopg2>=2.8.0\n    - psycopg>=3.1.0\n    - SQLAlchemy>=2.0\n    # plotting\n    - matplotlib>=3.7\n    - mapclassify\n    # point sampling\n    - pointpats\n"
        },
        {
          "name": "environment.yml",
          "type": "blob",
          "size": 0.2294921875,
          "content": "name: geopandas\nchannels:\n  - conda-forge\ndependencies:\n  - geopandas\n  - shapely\n  - pyogrio\n  - pyproj\n  - mapclassify\n  - libpysal\n  - matplotlib\n  - geopy\n  - cartopy\n  - pyepsg\n  - contextily\n  - rasterio\n  - folium\n  - packaging\n"
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "geopandas",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 5.0810546875,
          "content": "[build-system]\nrequires = [\"setuptools>=61.0.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"geopandas\"\ndynamic = [\"version\"]\nauthors = [{ name = \"Kelsey Jordahl\", email = \"kjordahl@alum.mit.edu\" }]\nmaintainers = [{ name = \"GeoPandas contributors\" }]\nlicense = { text = \"BSD 3-Clause\" }\ndescription = \"Geographic pandas extensions\"\nkeywords = [\"GIS\", \"cartography\", \"pandas\", \"shapely\"]\nclassifiers = [\n    \"Development Status :: 5 - Production/Stable\",\n    \"Intended Audience :: Science/Research\",\n    \"License :: OSI Approved :: BSD License\",\n    \"Operating System :: OS Independent\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"Topic :: Scientific/Engineering :: GIS\",\n]\nrequires-python = \">=3.10\"\ndependencies = [\n    \"numpy >= 1.24\",\n    \"pyogrio >= 0.7.2\",\n    \"packaging\",\n    \"pandas >= 2.0.0\",\n    \"pyproj >= 3.5.0\",\n    \"shapely >= 2.0.0\",\n]\n\n[project.optional-dependencies]\nall = [\n    \"psycopg[binary]>=3.1.0\",\n    \"SQLAlchemy>=2.0\",\n    \"geopy\",\n    \"matplotlib>=3.7\",\n    \"mapclassify>=2.5\",\n    \"xyzservices\",\n    \"folium\", # >=0.12 (implied minimum version, but older versions may work)\n    \"GeoAlchemy2\",\n    \"pyarrow>=10.0.0\",\n]\n\n# Minimum supported additional deps, not installed as part of `all` extra\n# (useful to track for bumping minimum dep versions)\n# fiona>=1.8.21\n# scipy>=1.10.0\n\ndev = [\n    \"pytest>=3.1.0\",\n    \"pytest-cov\",\n    \"pytest-xdist\",\n    \"codecov\",\n    \"pre-commit\",\n    \"ruff\",\n]\n\n\n[project.readme]\ntext = \"\"\"\\\nGeoPandas is a project to add support for geographic data to\n`pandas`_ objects.\n\nThe goal of GeoPandas is to make working with geospatial data in\npython easier. It combines the capabilities of `pandas`_ and `shapely`_,\nproviding geospatial operations in pandas and a high-level interface\nto multiple geometries to shapely. GeoPandas enables you to easily do\noperations in python that would otherwise require a spatial database\nsuch as PostGIS.\n\n.. _pandas: https://pandas.pydata.org\n.. _shapely: https://shapely.readthedocs.io/en/latest/\n\"\"\"\ncontent-type = \"text/x-rst\"\n\n[project.urls]\nHome = \"https://geopandas.org\"\nRepository = \"https://github.com/geopandas/geopandas\"\n\n[tool.setuptools.packages.find]\ninclude = [\"geopandas\", \"geopandas.*\"]\n\n[tool.setuptools.package-data]\ngeopandas = [\n    \"tests/data/null_geom.geojson\"\n]\n\n[tool.pytest.ini_options]\nmarkers = [\"web: tests that need network connectivity\"]\nxfail_strict = true\n\nfilterwarnings = [\n    \"ignore:distutils Version classes are deprecated.*:DeprecationWarning:pandas.*\",\n    \"ignore:distutils Version classes are deprecated.*:DeprecationWarning:numpy.*\",\n    \"ignore:The geopandas.dataset module is deprecated\",\n    # pytest-xdist incompatibility with pytest-cov\n    \"ignore:The --rsyncdir command line argument:DeprecationWarning\",\n    # dateutil incompatibility with python 3.12 (https://github.com/dateutil/dateutil/issues/1284)\n    \"ignore:datetime.datetime.utcfromtimestamp:DeprecationWarning:dateutil\",\n    \"ignore:Cannot set the CRS, falling back to None:UserWarning:geopandas\",\n]\n\n[tool.ruff]\nline-length = 88\nextend-exclude = [\"doc/*\", \"benchmarks/*\", \"versioneer.py\", \"geopandas/_version.py\"]\n\n[tool.ruff.lint]\nselect = [\n    # pyflakes\n    \"F\",\n    # pycodestyle\n    \"E\",\n    \"W\",\n    # pyupgrade\n    \"UP\",\n    # flake8-bugbear\n    \"B\",\n    # flake8-debugger\n    \"T10\",\n    # flake8-simplify\n    # \"SIM\",\n    # pylint\n    \"PLC\",\n    \"PLE\",\n    \"PLR\",\n    \"PLW\",\n    # misc lints\n    \"PIE\",\n    # implicit string concatenation\n    \"ISC\",\n    # type-checking imports\n    \"TCH\",\n    # comprehensions\n    \"C4\",\n    # Ruff-specific rules\n    \"RUF\",\n    # isort\n    \"I\",\n]\n\nignore = [\n    ### Intentionally disabled\n    # module level import not at top of file\n    \"E402\",\n    # do not assign a lambda expression, use a def\n    \"E731\",\n    # mutable-argument-default\n    \"B006\",\n    # unused-loop-control-variable\n    \"B007\",\n    # get-attr-with-constant\n    \"B009\",\n    # Only works with python >=3.10\n    \"B905\",\n    # dict literals\n    \"C408\",\n    # Too many arguments to function call\n    \"PLR0913\",\n    # Too many returns\n    \"PLR0911\",\n    # Too many branches\n    \"PLR0912\",\n    # Too many statements\n    \"PLR0915\",\n    # Magic number\n    \"PLR2004\",\n    # Redefined loop name\n    \"PLW2901\",\n    # Global statements are discouraged\n    \"PLW0603\",\n    # compare-to-empty-string\n    \"PLC1901\",\n\n    ### Additional checks that don't pass yet\n    # Useless statement\n    \"B018\",\n    # Within an except clause, raise exceptions with ...\n    \"B904\",\n    # Consider `elif` instead of `else` then `if` to remove indentation level\n    \"PLR5501\",\n    # collection-literal-concatenation\n    \"RUF005\",\n    # Mutable class attributes should be annotated with `typing.ClassVar`,\n    \"RUF012\"\n]\n\n[tool.ruff.lint.per-file-ignores]\n\"geopandas/__init__.py\" = [\"F401\", \"I\"]\n\n[tool.ruff.lint.isort]\nextra-standard-library = [\"packaging\"]\n\nsection-order = [\n  \"future\",\n  \"standard-library\",\n  \"third-party\",\n  \"geo\",\n  \"first-party\",\n  \"local-folder\",\n  \"testing\"\n]\n\n[tool.ruff.lint.isort.sections]\n\"geo\" = [\"shapely\", \"pyproj\"]\n\"testing\" = [\"pytest\", \"pandas.testing\", \"numpy.testing\", \"geopandas.tests\", \"geopandas.testing\"]\n"
        },
        {
          "name": "readthedocs.yml",
          "type": "blob",
          "size": 0.3408203125,
          "content": "version: 2\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: mambaforge-latest\n  jobs:\n    post_checkout:\n      # we need the tags for versioneer to work\n      - git fetch origin --depth 150\n      - git fetch --tags\n    post_build:\n      - mamba list\npython:\n  install:\n  - method: pip\n    path: .\nconda:\n  environment: doc/environment.yml\nformats: []\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.388671875,
          "content": "# required\nnumpy>=1.24\npyogrio>=0.7.2\npandas>=2.0\npyproj>=3.5.0\nshapely>=2.0.0\npackaging\n\n# geodatabase access\npsycopg2-binary>=2.8.0\npsycopg[binary]>=3.1.0\nSQLAlchemy>=2.0\n\n# geocoding\ngeopy\n\n# plotting\nmatplotlib>=3.7\nmapclassify>=2.5\nxyzservices\nfolium\n\n# testing\npytest>=3.1.0\npytest-cov\npytest-xdist\ncodecov\n\n# styling\npre-commit\nruff\n\n# PostGIS writing\nGeoAlchemy2\n\n# parquet\npyarrow>=10.0.0\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.3291015625,
          "content": "# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\nVCS = git\nstyle = pep440\nversionfile_source = geopandas/_version.py\nversionfile_build = geopandas/_version.py\ntag_prefix = v\nparentdir_prefix = geopandas-\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.53125,
          "content": "#!/usr/bin/env python3\n\"\"\"Installation script.\"\"\"\n\nimport os\nimport sys\n\nfrom setuptools import setup\n\n# ensure the current directory is on sys.path so versioneer can be imported\n# when pip uses PEP 517/518 build rules.\n# https://github.com/python-versioneer/python-versioneer/issues/193\nsys.path.append(os.path.dirname(__file__))\n\nimport versioneer\n\n# see pyproject.toml for static project metadata\nsetup(\n    name=\"geopandas\",  # need by GitHub dependency graph\n    version=versioneer.get_version(),\n    cmdclass=versioneer.get_cmdclass(),\n)\n"
        },
        {
          "name": "versioneer.py",
          "type": "blob",
          "size": 84.818359375,
          "content": "# Version: 0.29\n\n\"\"\"The Versioneer - like a rocketeer, but for versions.\n\nThe Versioneer\n==============\n\n* like a rocketeer, but for versions!\n* https://github.com/python-versioneer/python-versioneer\n* Brian Warner\n* License: Public Domain (Unlicense)\n* Compatible with: Python 3.7, 3.8, 3.9, 3.10, 3.11 and pypy3\n* [![Latest Version][pypi-image]][pypi-url]\n* [![Build Status][travis-image]][travis-url]\n\nThis is a tool for managing a recorded version number in setuptools-based\npython projects. The goal is to remove the tedious and error-prone \"update\nthe embedded version string\" step from your release process. Making a new\nrelease should be as easy as recording a new tag in your version-control\nsystem, and maybe making new tarballs.\n\n\n## Quick Install\n\nVersioneer provides two installation modes. The \"classic\" vendored mode installs\na copy of versioneer into your repository. The experimental build-time dependency mode\nis intended to allow you to skip this step and simplify the process of upgrading.\n\n### Vendored mode\n\n* `pip install versioneer` to somewhere in your $PATH\n   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is\n     available, so you can also use `conda install -c conda-forge versioneer`\n* add a `[tool.versioneer]` section to your `pyproject.toml` or a\n  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n   * Note that you will need to add `tomli; python_version < \"3.11\"` to your\n     build-time dependencies if you use `pyproject.toml`\n* run `versioneer install --vendor` in your source tree, commit the results\n* verify version information with `python setup.py version`\n\n### Build-time dependency mode\n\n* `pip install versioneer` to somewhere in your $PATH\n   * A [conda-forge recipe](https://github.com/conda-forge/versioneer-feedstock) is\n     available, so you can also use `conda install -c conda-forge versioneer`\n* add a `[tool.versioneer]` section to your `pyproject.toml` or a\n  `[versioneer]` section to your `setup.cfg` (see [Install](INSTALL.md))\n* add `versioneer` (with `[toml]` extra, if configuring in `pyproject.toml`)\n  to the `requires` key of the `build-system` table in `pyproject.toml`:\n  ```toml\n  [build-system]\n  requires = [\"setuptools\", \"versioneer[toml]\"]\n  build-backend = \"setuptools.build_meta\"\n  ```\n* run `versioneer install --no-vendor` in your source tree, commit the results\n* verify version information with `python setup.py version`\n\n## Version Identifiers\n\nSource trees come from a variety of places:\n\n* a version-control system checkout (mostly used by developers)\n* a nightly tarball, produced by build automation\n* a snapshot tarball, produced by a web-based VCS browser, like github's\n  \"tarball from tag\" feature\n* a release tarball, produced by \"setup.py sdist\", distributed through PyPI\n\nWithin each source tree, the version identifier (either a string or a number,\nthis tool is format-agnostic) can come from a variety of places:\n\n* ask the VCS tool itself, e.g. \"git describe\" (for checkouts), which knows\n  about recent \"tags\" and an absolute revision-id\n* the name of the directory into which the tarball was unpacked\n* an expanded VCS keyword ($Id$, etc)\n* a `_version.py` created by some earlier build step\n\nFor released software, the version identifier is closely related to a VCS\ntag. Some projects use tag names that include more than just the version\nstring (e.g. \"myproject-1.2\" instead of just \"1.2\"), in which case the tool\nneeds to strip the tag prefix to extract the version identifier. For\nunreleased software (between tags), the version identifier should provide\nenough information to help developers recreate the same tree, while also\ngiving them an idea of roughly how old the tree is (after version 1.2, before\nversion 1.3). Many VCS systems can report a description that captures this,\nfor example `git describe --tags --dirty --always` reports things like\n\"0.7-1-g574ab98-dirty\" to indicate that the checkout is one revision past the\n0.7 tag, has a unique revision id of \"574ab98\", and is \"dirty\" (it has\nuncommitted changes).\n\nThe version identifier is used for multiple purposes:\n\n* to allow the module to self-identify its version: `myproject.__version__`\n* to choose a name and prefix for a 'setup.py sdist' tarball\n\n## Theory of Operation\n\nVersioneer works by adding a special `_version.py` file into your source\ntree, where your `__init__.py` can import it. This `_version.py` knows how to\ndynamically ask the VCS tool for version information at import time.\n\n`_version.py` also contains `$Revision$` markers, and the installation\nprocess marks `_version.py` to have this marker rewritten with a tag name\nduring the `git archive` command. As a result, generated tarballs will\ncontain enough information to get the proper version.\n\nTo allow `setup.py` to compute a version too, a `versioneer.py` is added to\nthe top level of your source tree, next to `setup.py` and the `setup.cfg`\nthat configures it. This overrides several distutils/setuptools commands to\ncompute the version when invoked, and changes `setup.py build` and `setup.py\nsdist` to replace `_version.py` with a small static file that contains just\nthe generated version data.\n\n## Installation\n\nSee [INSTALL.md](./INSTALL.md) for detailed installation instructions.\n\n## Version-String Flavors\n\nCode which uses Versioneer can learn about its version string at runtime by\nimporting `_version` from your main `__init__.py` file and running the\n`get_versions()` function. From the \"outside\" (e.g. in `setup.py`), you can\nimport the top-level `versioneer.py` and run `get_versions()`.\n\nBoth functions return a dictionary with different flavors of version\ninformation:\n\n* `['version']`: A condensed version string, rendered using the selected\n  style. This is the most commonly used value for the project's version\n  string. The default \"pep440\" style yields strings like `0.11`,\n  `0.11+2.g1076c97`, or `0.11+2.g1076c97.dirty`. See the \"Styles\" section\n  below for alternative styles.\n\n* `['full-revisionid']`: detailed revision identifier. For Git, this is the\n  full SHA1 commit id, e.g. \"1076c978a8d3cfc70f408fe5974aa6c092c949ac\".\n\n* `['date']`: Date and time of the latest `HEAD` commit. For Git, it is the\n  commit date in ISO 8601 format. This will be None if the date is not\n  available.\n\n* `['dirty']`: a boolean, True if the tree has uncommitted changes. Note that\n  this is only accurate if run in a VCS checkout, otherwise it is likely to\n  be False or None\n\n* `['error']`: if the version string could not be computed, this will be set\n  to a string describing the problem, otherwise it will be None. It may be\n  useful to throw an exception in setup.py if this is set, to avoid e.g.\n  creating tarballs with a version string of \"unknown\".\n\nSome variants are more useful than others. Including `full-revisionid` in a\nbug report should allow developers to reconstruct the exact code being tested\n(or indicate the presence of local changes that should be shared with the\ndevelopers). `version` is suitable for display in an \"about\" box or a CLI\n`--version` output: it can be easily compared against release notes and lists\nof bugs fixed in various releases.\n\nThe installer adds the following text to your `__init__.py` to place a basic\nversion in `YOURPROJECT.__version__`:\n\n    from ._version import get_versions\n    __version__ = get_versions()['version']\n    del get_versions\n\n## Styles\n\nThe setup.cfg `style=` configuration controls how the VCS information is\nrendered into a version string.\n\nThe default style, \"pep440\", produces a PEP440-compliant string, equal to the\nun-prefixed tag name for actual releases, and containing an additional \"local\nversion\" section with more detail for in-between builds. For Git, this is\nTAG[+DISTANCE.gHEX[.dirty]] , using information from `git describe --tags\n--dirty --always`. For example \"0.11+2.g1076c97.dirty\" indicates that the\ntree is like the \"1076c97\" commit but has uncommitted changes (\".dirty\"), and\nthat this commit is two revisions (\"+2\") beyond the \"0.11\" tag. For released\nsoftware (exactly equal to a known tag), the identifier will only contain the\nstripped tag, e.g. \"0.11\".\n\nOther styles are available. See [details.md](details.md) in the Versioneer\nsource tree for descriptions.\n\n## Debugging\n\nVersioneer tries to avoid fatal errors: if something goes wrong, it will tend\nto return a version of \"0+unknown\". To investigate the problem, run `setup.py\nversion`, which will run the version-lookup code in a verbose mode, and will\ndisplay the full contents of `get_versions()` (including the `error` string,\nwhich may help identify what went wrong).\n\n## Known Limitations\n\nSome situations are known to cause problems for Versioneer. This details the\nmost significant ones. More can be found on Github\n[issues page](https://github.com/python-versioneer/python-versioneer/issues).\n\n### Subprojects\n\nVersioneer has limited support for source trees in which `setup.py` is not in\nthe root directory (e.g. `setup.py` and `.git/` are *not* siblings). The are\ntwo common reasons why `setup.py` might not be in the root:\n\n* Source trees which contain multiple subprojects, such as\n  [Buildbot](https://github.com/buildbot/buildbot), which contains both\n  \"master\" and \"slave\" subprojects, each with their own `setup.py`,\n  `setup.cfg`, and `tox.ini`. Projects like these produce multiple PyPI\n  distributions (and upload multiple independently-installable tarballs).\n* Source trees whose main purpose is to contain a C library, but which also\n  provide bindings to Python (and perhaps other languages) in subdirectories.\n\nVersioneer will look for `.git` in parent directories, and most operations\nshould get the right version string. However `pip` and `setuptools` have bugs\nand implementation details which frequently cause `pip install .` from a\nsubproject directory to fail to find a correct version string (so it usually\ndefaults to `0+unknown`).\n\n`pip install --editable .` should work correctly. `setup.py install` might\nwork too.\n\nPip-8.1.1 is known to have this problem, but hopefully it will get fixed in\nsome later version.\n\n[Bug #38](https://github.com/python-versioneer/python-versioneer/issues/38) is tracking\nthis issue. The discussion in\n[PR #61](https://github.com/python-versioneer/python-versioneer/pull/61) describes the\nissue from the Versioneer side in more detail.\n[pip PR#3176](https://github.com/pypa/pip/pull/3176) and\n[pip PR#3615](https://github.com/pypa/pip/pull/3615) contain work to improve\npip to let Versioneer work correctly.\n\nVersioneer-0.16 and earlier only looked for a `.git` directory next to the\n`setup.cfg`, so subprojects were completely unsupported with those releases.\n\n### Editable installs with setuptools <= 18.5\n\n`setup.py develop` and `pip install --editable .` allow you to install a\nproject into a virtualenv once, then continue editing the source code (and\ntest) without re-installing after every change.\n\n\"Entry-point scripts\" (`setup(entry_points={\"console_scripts\": ..})`) are a\nconvenient way to specify executable scripts that should be installed along\nwith the python package.\n\nThese both work as expected when using modern setuptools. When using\nsetuptools-18.5 or earlier, however, certain operations will cause\n`pkg_resources.DistributionNotFound` errors when running the entrypoint\nscript, which must be resolved by re-installing the package. This happens\nwhen the install happens with one version, then the egg_info data is\nregenerated while a different version is checked out. Many setup.py commands\ncause egg_info to be rebuilt (including `sdist`, `wheel`, and installing into\na different virtualenv), so this can be surprising.\n\n[Bug #83](https://github.com/python-versioneer/python-versioneer/issues/83) describes\nthis one, but upgrading to a newer version of setuptools should probably\nresolve it.\n\n\n## Updating Versioneer\n\nTo upgrade your project to a new release of Versioneer, do the following:\n\n* install the new Versioneer (`pip install -U versioneer` or equivalent)\n* edit `setup.cfg` and `pyproject.toml`, if necessary,\n  to include any new configuration settings indicated by the release notes.\n  See [UPGRADING](./UPGRADING.md) for details.\n* re-run `versioneer install --[no-]vendor` in your source tree, to replace\n  `SRC/_version.py`\n* commit any changed files\n\n## Future Directions\n\nThis tool is designed to make it easily extended to other version-control\nsystems: all VCS-specific components are in separate directories like\nsrc/git/ . The top-level `versioneer.py` script is assembled from these\ncomponents by running make-versioneer.py . In the future, make-versioneer.py\nwill take a VCS name as an argument, and will construct a version of\n`versioneer.py` that is specific to the given VCS. It might also take the\nconfiguration arguments that are currently provided manually during\ninstallation by editing setup.py . Alternatively, it might go the other\ndirection and include code from all supported VCS systems, reducing the\nnumber of intermediate scripts.\n\n## Similar projects\n\n* [setuptools_scm](https://github.com/pypa/setuptools_scm/) - a non-vendored build-time\n  dependency\n* [minver](https://github.com/jbweston/miniver) - a lightweight reimplementation of\n  versioneer\n* [versioningit](https://github.com/jwodder/versioningit) - a PEP 518-based setuptools\n  plugin\n\n## License\n\nTo make Versioneer easier to embed, all its code is dedicated to the public\ndomain. The `_version.py` that it creates is also in the public domain.\nSpecifically, both are released under the \"Unlicense\", as described in\nhttps://unlicense.org/.\n\n[pypi-image]: https://img.shields.io/pypi/v/versioneer.svg\n[pypi-url]: https://pypi.python.org/pypi/versioneer/\n[travis-image]:\nhttps://img.shields.io/travis/com/python-versioneer/python-versioneer.svg\n[travis-url]: https://travis-ci.com/github/python-versioneer/python-versioneer\n\n\"\"\"\n# pylint:disable=invalid-name,import-outside-toplevel,missing-function-docstring\n# pylint:disable=missing-class-docstring,too-many-branches,too-many-statements\n# pylint:disable=raise-missing-from,too-many-lines,too-many-locals,import-error\n# pylint:disable=too-few-public-methods,redefined-outer-name,consider-using-with\n# pylint:disable=attribute-defined-outside-init,too-many-arguments\n\nimport configparser\nimport errno\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Callable, cast, Dict, List, Optional, Tuple, Union\nfrom typing import NoReturn\nimport functools\n\nhave_tomllib = True\nif sys.version_info >= (3, 11):\n    import tomllib\nelse:\n    try:\n        import tomli as tomllib\n    except ImportError:\n        have_tomllib = False\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n    VCS: str\n    style: str\n    tag_prefix: str\n    versionfile_source: str\n    versionfile_build: Optional[str]\n    parentdir_prefix: Optional[str]\n    verbose: Optional[bool]\n\n\ndef get_root() -> str:\n    \"\"\"Get the project root directory.\n\n    We require that all commands are run from the project root, i.e. the\n    directory that contains setup.py, setup.cfg, and versioneer.py .\n    \"\"\"\n    root = os.path.realpath(os.path.abspath(os.getcwd()))\n    setup_py = os.path.join(root, \"setup.py\")\n    pyproject_toml = os.path.join(root, \"pyproject.toml\")\n    versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (\n        os.path.exists(setup_py)\n        or os.path.exists(pyproject_toml)\n        or os.path.exists(versioneer_py)\n    ):\n        # allow 'python path/to/setup.py COMMAND'\n        root = os.path.dirname(os.path.realpath(os.path.abspath(sys.argv[0])))\n        setup_py = os.path.join(root, \"setup.py\")\n        pyproject_toml = os.path.join(root, \"pyproject.toml\")\n        versioneer_py = os.path.join(root, \"versioneer.py\")\n    if not (\n        os.path.exists(setup_py)\n        or os.path.exists(pyproject_toml)\n        or os.path.exists(versioneer_py)\n    ):\n        err = (\n            \"Versioneer was unable to run the project root directory. \"\n            \"Versioneer requires setup.py to be executed from \"\n            \"its immediate directory (like 'python setup.py COMMAND'), \"\n            \"or in a way that lets it use sys.argv[0] to find the root \"\n            \"(like 'python path/to/setup.py COMMAND').\"\n        )\n        raise VersioneerBadRootError(err)\n    try:\n        # Certain runtime workflows (setup.py install/develop in a setuptools\n        # tree) execute all dependencies in a single python process, so\n        # \"versioneer\" may be imported multiple times, and python's shared\n        # module-import table will cache the first one. So we can't use\n        # os.path.dirname(__file__), as that will find whichever\n        # versioneer.py was first imported, even in later projects.\n        my_path = os.path.realpath(os.path.abspath(__file__))\n        me_dir = os.path.normcase(os.path.splitext(my_path)[0])\n        vsr_dir = os.path.normcase(os.path.splitext(versioneer_py)[0])\n        if me_dir != vsr_dir and \"VERSIONEER_PEP518\" not in globals():\n            print(\n                \"Warning: build in %s is using versioneer.py from %s\"\n                % (os.path.dirname(my_path), versioneer_py)\n            )\n    except NameError:\n        pass\n    return root\n\n\ndef get_config_from_root(root: str) -> VersioneerConfig:\n    \"\"\"Read the project setup.cfg file to determine Versioneer config.\"\"\"\n    # This might raise OSError (if setup.cfg is missing), or\n    # configparser.NoSectionError (if it lacks a [versioneer] section), or\n    # configparser.NoOptionError (if it lacks \"VCS=\"). See the docstring at\n    # the top of versioneer.py for instructions on writing your setup.cfg .\n    root_pth = Path(root)\n    pyproject_toml = root_pth / \"pyproject.toml\"\n    setup_cfg = root_pth / \"setup.cfg\"\n    section: Union[Dict[str, Any], configparser.SectionProxy, None] = None\n    if pyproject_toml.exists() and have_tomllib:\n        try:\n            with open(pyproject_toml, \"rb\") as fobj:\n                pp = tomllib.load(fobj)\n            section = pp[\"tool\"][\"versioneer\"]\n        except (tomllib.TOMLDecodeError, KeyError) as e:\n            print(f\"Failed to load config from {pyproject_toml}: {e}\")\n            print(\"Try to load it from setup.cfg\")\n    if not section:\n        parser = configparser.ConfigParser()\n        with open(setup_cfg) as cfg_file:\n            parser.read_file(cfg_file)\n        parser.get(\"versioneer\", \"VCS\")  # raise error if missing\n\n        section = parser[\"versioneer\"]\n\n    # `cast`` really shouldn't be used, but its simplest for the\n    # common VersioneerConfig users at the moment. We verify against\n    # `None` values elsewhere where it matters\n\n    cfg = VersioneerConfig()\n    cfg.VCS = section[\"VCS\"]\n    cfg.style = section.get(\"style\", \"\")\n    cfg.versionfile_source = cast(str, section.get(\"versionfile_source\"))\n    cfg.versionfile_build = section.get(\"versionfile_build\")\n    cfg.tag_prefix = cast(str, section.get(\"tag_prefix\"))\n    if cfg.tag_prefix in (\"''\", '\"\"', None):\n        cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = section.get(\"parentdir_prefix\")\n    if isinstance(section, configparser.SectionProxy):\n        # Make sure configparser translates to bool\n        cfg.verbose = section.getboolean(\"verbose\")\n    else:\n        cfg.verbose = section.get(\"verbose\")\n\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n\n\n# these dictionaries contain VCS-specific tools\nLONG_VERSION_PY: Dict[str, str] = {}\nHANDLERS: Dict[str, Dict[str, Callable]] = {}\n\n\ndef register_vcs_handler(vcs: str, method: str) -> Callable:  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n\n    def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n\n    return decorate\n\n\ndef run_command(\n    commands: List[str],\n    args: List[str],\n    cwd: Optional[str] = None,\n    verbose: bool = False,\n    hide_stderr: bool = False,\n    env: Optional[Dict[str, str]] = None,\n) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n\n    popen_kwargs: Dict[str, Any] = {}\n    if sys.platform == \"win32\":\n        # This hides the console window if pythonw.exe is used\n        startupinfo = subprocess.STARTUPINFO()\n        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        popen_kwargs[\"startupinfo\"] = startupinfo\n\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen(\n                [command] + args,\n                cwd=cwd,\n                env=env,\n                stdout=subprocess.PIPE,\n                stderr=(subprocess.PIPE if hide_stderr else None),\n                **popen_kwargs,\n            )\n            break\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %s\" % (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %s (error)\" % dispcmd)\n            print(\"stdout was %s\" % stdout)\n        return None, process.returncode\n    return stdout, process.returncode\n\n\nLONG_VERSION_PY[\n    \"git\"\n] = r'''\n# This file helps to compute a version number in source trees obtained from\n# git-archive tarball (such as those provided by githubs download-from-tag\n# feature). Distribution tarballs (built by setup.py sdist) and build\n# directories (produced by setup.py build) will contain a much shorter file\n# that just contains the computed version number.\n\n# This file is released into the public domain.\n# Generated by versioneer-0.29\n# https://github.com/python-versioneer/python-versioneer\n\n\"\"\"Git implementation of _version.py.\"\"\"\n\nimport errno\nimport os\nimport re\nimport subprocess\nimport sys\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\nimport functools\n\n\ndef get_keywords() -> Dict[str, str]:\n    \"\"\"Get the keywords needed to look up the version information.\"\"\"\n    # these strings will be replaced by git during git-archive.\n    # setup.py/versioneer.py will grep for the variable names, so they must\n    # each be defined on a line of their own. _version.py will just call\n    # get_keywords().\n    git_refnames = \"%(DOLLAR)sFormat:%%d%(DOLLAR)s\"\n    git_full = \"%(DOLLAR)sFormat:%%H%(DOLLAR)s\"\n    git_date = \"%(DOLLAR)sFormat:%%ci%(DOLLAR)s\"\n    keywords = {\"refnames\": git_refnames, \"full\": git_full, \"date\": git_date}\n    return keywords\n\n\nclass VersioneerConfig:\n    \"\"\"Container for Versioneer configuration parameters.\"\"\"\n\n    VCS: str\n    style: str\n    tag_prefix: str\n    parentdir_prefix: str\n    versionfile_source: str\n    verbose: bool\n\n\ndef get_config() -> VersioneerConfig:\n    \"\"\"Create, populate and return the VersioneerConfig() object.\"\"\"\n    # these strings are filled in when 'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"%(STYLE)s\"\n    cfg.tag_prefix = \"%(TAG_PREFIX)s\"\n    cfg.parentdir_prefix = \"%(PARENTDIR_PREFIX)s\"\n    cfg.versionfile_source = \"%(VERSIONFILE_SOURCE)s\"\n    cfg.verbose = False\n    return cfg\n\n\nclass NotThisMethod(Exception):\n    \"\"\"Exception raised if a method is not valid for the current scenario.\"\"\"\n\n\nLONG_VERSION_PY: Dict[str, str] = {}\nHANDLERS: Dict[str, Dict[str, Callable]] = {}\n\n\ndef register_vcs_handler(vcs: str, method: str) -> Callable:  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f: Callable) -> Callable:\n        \"\"\"Store f in HANDLERS[vcs][method].\"\"\"\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n\n\ndef run_command(\n    commands: List[str],\n    args: List[str],\n    cwd: Optional[str] = None,\n    verbose: bool = False,\n    hide_stderr: bool = False,\n    env: Optional[Dict[str, str]] = None,\n) -> Tuple[Optional[str], Optional[int]]:\n    \"\"\"Call the given command(s).\"\"\"\n    assert isinstance(commands, list)\n    process = None\n\n    popen_kwargs: Dict[str, Any] = {}\n    if sys.platform == \"win32\":\n        # This hides the console window if pythonw.exe is used\n        startupinfo = subprocess.STARTUPINFO()\n        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW\n        popen_kwargs[\"startupinfo\"] = startupinfo\n\n    for command in commands:\n        try:\n            dispcmd = str([command] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            process = subprocess.Popen([command] + args, cwd=cwd, env=env,\n                                       stdout=subprocess.PIPE,\n                                       stderr=(subprocess.PIPE if hide_stderr\n                                               else None), **popen_kwargs)\n            break\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %%s\" %% dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n            print(\"unable to find command, tried %%s\" %% (commands,))\n        return None, None\n    stdout = process.communicate()[0].strip().decode()\n    if process.returncode != 0:\n        if verbose:\n            print(\"unable to run %%s (error)\" %% dispcmd)\n            print(\"stdout was %%s\" %% stdout)\n        return None, process.returncode\n    return stdout, process.returncode\n\n\ndef versions_from_parentdir(\n    parentdir_prefix: str,\n    root: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\"version\": dirname[len(parentdir_prefix):],\n                    \"full-revisionid\": None,\n                    \"dirty\": False, \"error\": None, \"date\": None}\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\"Tried directories %%s but none started with prefix %%s\" %%\n              (str(rootdirs), parentdir_prefix))\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs: str) -> Dict[str, str]:\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords: Dict[str, str] = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(\n    keywords: Dict[str, str],\n    tag_prefix: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG):] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %%d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r'\\d', r)}\n        if verbose:\n            print(\"discarding '%%s', no digits\" %% \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %%s\" %% \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix):]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r'\\d', r):\n                continue\n            if verbose:\n                print(\"picking %%s\" %% r)\n            return {\"version\": r,\n                    \"full-revisionid\": keywords[\"full\"].strip(),\n                    \"dirty\": False, \"error\": None,\n                    \"date\": date}\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\"version\": \"0+unknown\",\n            \"full-revisionid\": keywords[\"full\"].strip(),\n            \"dirty\": False, \"error\": \"no suitable tags\", \"date\": None}\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(\n    tag_prefix: str,\n    root: str,\n    verbose: bool,\n    runner: Callable = run_command\n) -> Dict[str, Any]:\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    # GIT_DIR can interfere with correct operation of Versioneer.\n    # It may be intended to be passed to the Versioneer-versioned project,\n    # but that should not change where we get our version from.\n    env = os.environ.copy()\n    env.pop(\"GIT_DIR\", None)\n    runner = functools.partial(runner, env=env)\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root,\n                   hide_stderr=not verbose)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %%s not under git control\" %% root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(GITS, [\n        \"describe\", \"--tags\", \"--dirty\", \"--always\", \"--long\",\n        \"--match\", f\"{tag_prefix}[[:digit:]]*\"\n    ], cwd=root)\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces: Dict[str, Any] = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"],\n                             cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[:git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r'^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = (\"unable to parse git-describe output: '%%s'\"\n                               %% describe_out)\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%%s' doesn't start with prefix '%%s'\"\n                print(fmt %% (full_tag, tag_prefix))\n            pieces[\"error\"] = (\"tag '%%s' doesn't start with prefix '%%s'\"\n                               %% (full_tag, tag_prefix))\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix):]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--left-right\"], cwd=root)\n        pieces[\"distance\"] = len(out.split())  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces\n\n\ndef plus_or_dot(pieces: Dict[str, Any]) -> str:\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces: Dict[str, Any]) -> str:\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%%d.g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%%d.g%%s\" %% (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%%d.g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%%d.g%%s\" %% (pieces[\"distance\"],\n                                          pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef pep440_split_post(ver: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n\n\ndef render_pep440_pre(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%%d.dev%%d\" %% (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%%d\" %% (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%%d\" %% pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%%s\" %% pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%%s\" %% pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_post_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%%s\" %% pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%%s\" %% pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_old(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%%d\" %% pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%%d\" %% pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%%d-g%%s\" %% (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces: Dict[str, Any], style: str) -> Dict[str, Any]:\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%%s'\" %% style)\n\n    return {\"version\": rendered, \"full-revisionid\": pieces[\"long\"],\n            \"dirty\": pieces[\"dirty\"], \"error\": None,\n            \"date\": pieces.get(\"date\")}\n\n\ndef get_versions() -> Dict[str, Any]:\n    \"\"\"Get version information or return default if unable to do so.\"\"\"\n    # I am in _version.py, which lives at ROOT/VERSIONFILE_SOURCE. If we have\n    # __file__, we can work backwards from there to the root. Some\n    # py2exe/bbfreeze/non-CPython implementations don't do __file__, in which\n    # case we can only use expanded keywords.\n\n    cfg = get_config()\n    verbose = cfg.verbose\n\n    try:\n        return git_versions_from_keywords(get_keywords(), cfg.tag_prefix,\n                                          verbose)\n    except NotThisMethod:\n        pass\n\n    try:\n        root = os.path.realpath(__file__)\n        # versionfile_source is the relative path from the top of the source\n        # tree (where the .git directory might live) to this file. Invert\n        # this to find the root from __file__.\n        for _ in cfg.versionfile_source.split('/'):\n            root = os.path.dirname(root)\n    except NameError:\n        return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find root of source tree\",\n                \"date\": None}\n\n    try:\n        pieces = git_pieces_from_vcs(cfg.tag_prefix, root, verbose)\n        return render(pieces, cfg.style)\n    except NotThisMethod:\n        pass\n\n    try:\n        if cfg.parentdir_prefix:\n            return versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n    except NotThisMethod:\n        pass\n\n    return {\"version\": \"0+unknown\", \"full-revisionid\": None,\n            \"dirty\": None,\n            \"error\": \"unable to compute version\", \"date\": None}\n'''\n\n\n@register_vcs_handler(\"git\", \"get_keywords\")\ndef git_get_keywords(versionfile_abs: str) -> Dict[str, str]:\n    \"\"\"Extract version information from the given file.\"\"\"\n    # the code embedded in _version.py can just fetch the value of these\n    # keywords. When used from setup.py, we don't want to import _version.py,\n    # so we do it with a regexp instead. This function is not used from\n    # _version.py.\n    keywords: Dict[str, str] = {}\n    try:\n        with open(versionfile_abs, \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(\"git_refnames =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"refnames\"] = mo.group(1)\n                if line.strip().startswith(\"git_full =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"full\"] = mo.group(1)\n                if line.strip().startswith(\"git_date =\"):\n                    mo = re.search(r'=\\s*\"(.*)\"', line)\n                    if mo:\n                        keywords[\"date\"] = mo.group(1)\n    except OSError:\n        pass\n    return keywords\n\n\n@register_vcs_handler(\"git\", \"keywords\")\ndef git_versions_from_keywords(\n    keywords: Dict[str, str],\n    tag_prefix: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Get version information from git keywords.\"\"\"\n    if \"refnames\" not in keywords:\n        raise NotThisMethod(\"Short version file found\")\n    date = keywords.get(\"date\")\n    if date is not None:\n        # Use only the last line.  Previous lines may contain GPG signature\n        # information.\n        date = date.splitlines()[-1]\n\n        # git-2.2.0 added \"%cI\", which expands to an ISO-8601 -compliant\n        # datestamp. However we prefer \"%ci\" (which expands to an \"ISO-8601\n        # -like\" string, which we must then edit to make compliant), because\n        # it's been around since git-1.5.3, and it's too difficult to\n        # discover which version we're using, or to work around using an\n        # older one.\n        date = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n    refnames = keywords[\"refnames\"].strip()\n    if refnames.startswith(\"$Format\"):\n        if verbose:\n            print(\"keywords are unexpanded, not using\")\n        raise NotThisMethod(\"unexpanded keywords, not a git-archive tarball\")\n    refs = {r.strip() for r in refnames.strip(\"()\").split(\",\")}\n    # starting in git-1.8.3, tags are listed as \"tag: foo-1.0\" instead of\n    # just \"foo-1.0\". If we see a \"tag: \" prefix, prefer those.\n    TAG = \"tag: \"\n    tags = {r[len(TAG) :] for r in refs if r.startswith(TAG)}\n    if not tags:\n        # Either we're using git < 1.8.3, or there really are no tags. We use\n        # a heuristic: assume all version tags have a digit. The old git %d\n        # expansion behaves like git log --decorate=short and strips out the\n        # refs/heads/ and refs/tags/ prefixes that would let us distinguish\n        # between branches and tags. By ignoring refnames without digits, we\n        # filter out many common branch names like \"release\" and\n        # \"stabilization\", as well as \"HEAD\" and \"master\".\n        tags = {r for r in refs if re.search(r\"\\d\", r)}\n        if verbose:\n            print(\"discarding '%s', no digits\" % \",\".join(refs - tags))\n    if verbose:\n        print(\"likely tags: %s\" % \",\".join(sorted(tags)))\n    for ref in sorted(tags):\n        # sorting will prefer e.g. \"2.0\" over \"2.0rc1\"\n        if ref.startswith(tag_prefix):\n            r = ref[len(tag_prefix) :]\n            # Filter out refs that exactly match prefix or that don't start\n            # with a number once the prefix is stripped (mostly a concern\n            # when prefix is '')\n            if not re.match(r\"\\d\", r):\n                continue\n            if verbose:\n                print(\"picking %s\" % r)\n            return {\n                \"version\": r,\n                \"full-revisionid\": keywords[\"full\"].strip(),\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": date,\n            }\n    # no suitable tags, so version is \"0+unknown\", but full hex is still there\n    if verbose:\n        print(\"no suitable tags, using unknown + full revision id\")\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": keywords[\"full\"].strip(),\n        \"dirty\": False,\n        \"error\": \"no suitable tags\",\n        \"date\": None,\n    }\n\n\n@register_vcs_handler(\"git\", \"pieces_from_vcs\")\ndef git_pieces_from_vcs(\n    tag_prefix: str, root: str, verbose: bool, runner: Callable = run_command\n) -> Dict[str, Any]:\n    \"\"\"Get version from 'git describe' in the root of the source tree.\n\n    This only gets called if the git-archive 'subst' keywords were *not*\n    expanded, and _version.py hasn't already been rewritten with a short\n    version string, meaning we're inside a checked out source tree.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n\n    # GIT_DIR can interfere with correct operation of Versioneer.\n    # It may be intended to be passed to the Versioneer-versioned project,\n    # but that should not change where we get our version from.\n    env = os.environ.copy()\n    env.pop(\"GIT_DIR\", None)\n    runner = functools.partial(runner, env=env)\n\n    _, rc = runner(GITS, [\"rev-parse\", \"--git-dir\"], cwd=root, hide_stderr=not verbose)\n    if rc != 0:\n        if verbose:\n            print(\"Directory %s not under git control\" % root)\n        raise NotThisMethod(\"'git rev-parse --git-dir' returned error\")\n\n    # if there is a tag matching tag_prefix, this yields TAG-NUM-gHEX[-dirty]\n    # if there isn't one, this yields HEX[-dirty] (no NUM)\n    describe_out, rc = runner(\n        GITS,\n        [\n            \"describe\",\n            \"--tags\",\n            \"--dirty\",\n            \"--always\",\n            \"--long\",\n            \"--match\",\n            f\"{tag_prefix}[[:digit:]]*\",\n        ],\n        cwd=root,\n    )\n    # --long was added in git-1.5.5\n    if describe_out is None:\n        raise NotThisMethod(\"'git describe' failed\")\n    describe_out = describe_out.strip()\n    full_out, rc = runner(GITS, [\"rev-parse\", \"HEAD\"], cwd=root)\n    if full_out is None:\n        raise NotThisMethod(\"'git rev-parse' failed\")\n    full_out = full_out.strip()\n\n    pieces: Dict[str, Any] = {}\n    pieces[\"long\"] = full_out\n    pieces[\"short\"] = full_out[:7]  # maybe improved later\n    pieces[\"error\"] = None\n\n    branch_name, rc = runner(GITS, [\"rev-parse\", \"--abbrev-ref\", \"HEAD\"], cwd=root)\n    # --abbrev-ref was added in git-1.6.3\n    if rc != 0 or branch_name is None:\n        raise NotThisMethod(\"'git rev-parse --abbrev-ref' returned error\")\n    branch_name = branch_name.strip()\n\n    if branch_name == \"HEAD\":\n        # If we aren't exactly on a branch, pick a branch which represents\n        # the current commit. If all else fails, we are on a branchless\n        # commit.\n        branches, rc = runner(GITS, [\"branch\", \"--contains\"], cwd=root)\n        # --contains was added in git-1.5.4\n        if rc != 0 or branches is None:\n            raise NotThisMethod(\"'git branch --contains' returned error\")\n        branches = branches.split(\"\\n\")\n\n        # Remove the first line if we're running detached\n        if \"(\" in branches[0]:\n            branches.pop(0)\n\n        # Strip off the leading \"* \" from the list of branches.\n        branches = [branch[2:] for branch in branches]\n        if \"master\" in branches:\n            branch_name = \"master\"\n        elif not branches:\n            branch_name = None\n        else:\n            # Pick the first branch that is returned. Good or bad.\n            branch_name = branches[0]\n\n    pieces[\"branch\"] = branch_name\n\n    # parse describe_out. It will be like TAG-NUM-gHEX[-dirty] or HEX[-dirty]\n    # TAG might have hyphens.\n    git_describe = describe_out\n\n    # look for -dirty suffix\n    dirty = git_describe.endswith(\"-dirty\")\n    pieces[\"dirty\"] = dirty\n    if dirty:\n        git_describe = git_describe[: git_describe.rindex(\"-dirty\")]\n\n    # now we have TAG-NUM-gHEX or HEX\n\n    if \"-\" in git_describe:\n        # TAG-NUM-gHEX\n        mo = re.search(r\"^(.+)-(\\d+)-g([0-9a-f]+)$\", git_describe)\n        if not mo:\n            # unparsable. Maybe git-describe is misbehaving?\n            pieces[\"error\"] = \"unable to parse git-describe output: '%s'\" % describe_out\n            return pieces\n\n        # tag\n        full_tag = mo.group(1)\n        if not full_tag.startswith(tag_prefix):\n            if verbose:\n                fmt = \"tag '%s' doesn't start with prefix '%s'\"\n                print(fmt % (full_tag, tag_prefix))\n            pieces[\"error\"] = \"tag '%s' doesn't start with prefix '%s'\" % (\n                full_tag,\n                tag_prefix,\n            )\n            return pieces\n        pieces[\"closest-tag\"] = full_tag[len(tag_prefix) :]\n\n        # distance: number of commits since tag\n        pieces[\"distance\"] = int(mo.group(2))\n\n        # commit: short hex revision ID\n        pieces[\"short\"] = mo.group(3)\n\n    else:\n        # HEX: no tags\n        pieces[\"closest-tag\"] = None\n        out, rc = runner(GITS, [\"rev-list\", \"HEAD\", \"--left-right\"], cwd=root)\n        pieces[\"distance\"] = len(out.split())  # total number of commits\n\n    # commit date: see ISO-8601 comment in git_versions_from_keywords()\n    date = runner(GITS, [\"show\", \"-s\", \"--format=%ci\", \"HEAD\"], cwd=root)[0].strip()\n    # Use only the last line.  Previous lines may contain GPG signature\n    # information.\n    date = date.splitlines()[-1]\n    pieces[\"date\"] = date.strip().replace(\" \", \"T\", 1).replace(\" \", \"\", 1)\n\n    return pieces\n\n\ndef do_vcs_install(versionfile_source: str, ipy: Optional[str]) -> None:\n    \"\"\"Git-specific installation logic for Versioneer.\n\n    For Git, this means creating/changing .gitattributes to mark _version.py\n    for export-subst keyword substitution.\n    \"\"\"\n    GITS = [\"git\"]\n    if sys.platform == \"win32\":\n        GITS = [\"git.cmd\", \"git.exe\"]\n    files = [versionfile_source]\n    if ipy:\n        files.append(ipy)\n    if \"VERSIONEER_PEP518\" not in globals():\n        try:\n            my_path = __file__\n            if my_path.endswith((\".pyc\", \".pyo\")):\n                my_path = os.path.splitext(my_path)[0] + \".py\"\n            versioneer_file = os.path.relpath(my_path)\n        except NameError:\n            versioneer_file = \"versioneer.py\"\n        files.append(versioneer_file)\n    present = False\n    try:\n        with open(\".gitattributes\", \"r\") as fobj:\n            for line in fobj:\n                if line.strip().startswith(versionfile_source):\n                    if \"export-subst\" in line.strip().split()[1:]:\n                        present = True\n                        break\n    except OSError:\n        pass\n    if not present:\n        with open(\".gitattributes\", \"a+\") as fobj:\n            fobj.write(f\"{versionfile_source} export-subst\\n\")\n        files.append(\".gitattributes\")\n    run_command(GITS, [\"add\", \"--\"] + files)\n\n\ndef versions_from_parentdir(\n    parentdir_prefix: str,\n    root: str,\n    verbose: bool,\n) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from the parent directory name.\n\n    Source tarballs conventionally unpack into a directory that includes both\n    the project name and a version string. We will also support searching up\n    two directory levels for an appropriately named parent directory\n    \"\"\"\n    rootdirs = []\n\n    for _ in range(3):\n        dirname = os.path.basename(root)\n        if dirname.startswith(parentdir_prefix):\n            return {\n                \"version\": dirname[len(parentdir_prefix) :],\n                \"full-revisionid\": None,\n                \"dirty\": False,\n                \"error\": None,\n                \"date\": None,\n            }\n        rootdirs.append(root)\n        root = os.path.dirname(root)  # up a level\n\n    if verbose:\n        print(\n            \"Tried directories %s but none started with prefix %s\"\n            % (str(rootdirs), parentdir_prefix)\n        )\n    raise NotThisMethod(\"rootdir doesn't start with parentdir_prefix\")\n\n\nSHORT_VERSION_PY = \"\"\"\n# This file was generated by 'versioneer.py' (0.29) from\n# revision-control system data, or from the parent directory name of an\n# unpacked source archive. Distribution tarballs contain a pre-generated copy\n# of this file.\n\nimport json\n\nversion_json = '''\n%s\n'''  # END VERSION_JSON\n\n\ndef get_versions():\n    return json.loads(version_json)\n\"\"\"\n\n\ndef versions_from_file(filename: str) -> Dict[str, Any]:\n    \"\"\"Try to determine the version from _version.py if present.\"\"\"\n    try:\n        with open(filename) as f:\n            contents = f.read()\n    except OSError:\n        raise NotThisMethod(\"unable to read _version.py\")\n    mo = re.search(\n        r\"version_json = '''\\n(.*)'''  # END VERSION_JSON\", contents, re.M | re.S\n    )\n    if not mo:\n        mo = re.search(\n            r\"version_json = '''\\r\\n(.*)'''  # END VERSION_JSON\", contents, re.M | re.S\n        )\n    if not mo:\n        raise NotThisMethod(\"no version_json in _version.py\")\n    return json.loads(mo.group(1))\n\n\ndef write_to_version_file(filename: str, versions: Dict[str, Any]) -> None:\n    \"\"\"Write the given version number to the given _version.py file.\"\"\"\n    contents = json.dumps(versions, sort_keys=True, indent=1, separators=(\",\", \": \"))\n    with open(filename, \"w\") as f:\n        f.write(SHORT_VERSION_PY % contents)\n\n    print(\"set %s to '%s'\" % (filename, versions[\"version\"]))\n\n\ndef plus_or_dot(pieces: Dict[str, Any]) -> str:\n    \"\"\"Return a + if we don't already have one, else return a .\"\"\"\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n\n\ndef render_pep440(pieces: Dict[str, Any]) -> str:\n    \"\"\"Build up version string, with post-release \"local version identifier\".\n\n    Our goal: TAG[+DISTANCE.gHEX[.dirty]] . Note that if you\n    get a tagged build and then dirty it, you'll get TAG+0.gHEX.dirty\n\n    Exceptions:\n    1: no tags. git_describe was just HEX. 0+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[[.dev0]+DISTANCE.gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch. Note that .dev0 sorts backwards\n    (a feature branch will appear \"older\" than the master branch).\n\n    Exceptions:\n    1: no tags. 0[.dev0]+untagged.DISTANCE.gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0\"\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+untagged.%d.g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef pep440_split_post(ver: str) -> Tuple[str, Optional[int]]:\n    \"\"\"Split pep440 version string at the post-release segment.\n\n    Returns the release segments before the post-release and the\n    post-release version number (or -1 if no post-release segment is present).\n    \"\"\"\n    vc = str.split(ver, \".post\")\n    return vc[0], int(vc[1] or 0) if len(vc) == 2 else None\n\n\ndef render_pep440_pre(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postN.devDISTANCE] -- No -dirty.\n\n    Exceptions:\n    1: no tags. 0.post0.devDISTANCE\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        if pieces[\"distance\"]:\n            # update the post release segment\n            tag_version, post_version = pep440_split_post(pieces[\"closest-tag\"])\n            rendered = tag_version\n            if post_version is not None:\n                rendered += \".post%d.dev%d\" % (post_version + 1, pieces[\"distance\"])\n            else:\n                rendered += \".post0.dev%d\" % (pieces[\"distance\"])\n        else:\n            # no commits, use the tag as the version\n            rendered = pieces[\"closest-tag\"]\n    else:\n        # exception #1\n        rendered = \"0.post0.dev%d\" % pieces[\"distance\"]\n    return rendered\n\n\ndef render_pep440_post(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX] .\n\n    The \".dev0\" means dirty. Note that .dev0 sorts backwards\n    (a dirty tree will appear \"older\" than the corresponding clean one),\n    but you shouldn't be releasing software with -dirty anyways.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n    return rendered\n\n\ndef render_pep440_post_branch(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .\n\n    The \".dev0\" means not master branch.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"branch\"] != \"master\":\n                rendered += \".dev0\"\n            rendered += plus_or_dot(pieces)\n            rendered += \"g%s\" % pieces[\"short\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dirty\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"branch\"] != \"master\":\n            rendered += \".dev0\"\n        rendered += \"+g%s\" % pieces[\"short\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dirty\"\n    return rendered\n\n\ndef render_pep440_old(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[.postDISTANCE[.dev0]] .\n\n    The \".dev0\" means dirty.\n\n    Exceptions:\n    1: no tags. 0.postDISTANCE[.dev0]\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".post%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.post%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered\n\n\ndef render_git_describe(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG[-DISTANCE-gHEX][-dirty].\n\n    Like 'git describe --tags --dirty --always'.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"]:\n            rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render_git_describe_long(pieces: Dict[str, Any]) -> str:\n    \"\"\"TAG-DISTANCE-gHEX[-dirty].\n\n    Like 'git describe --tags --dirty --always -long'.\n    The distance/hash is unconditional.\n\n    Exceptions:\n    1: no tags. HEX[-dirty]  (note: no 'g' prefix)\n    \"\"\"\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        rendered += \"-%d-g%s\" % (pieces[\"distance\"], pieces[\"short\"])\n    else:\n        # exception #1\n        rendered = pieces[\"short\"]\n    if pieces[\"dirty\"]:\n        rendered += \"-dirty\"\n    return rendered\n\n\ndef render(pieces: Dict[str, Any], style: str) -> Dict[str, Any]:\n    \"\"\"Render the given version pieces into the requested style.\"\"\"\n    if pieces[\"error\"]:\n        return {\n            \"version\": \"unknown\",\n            \"full-revisionid\": pieces.get(\"long\"),\n            \"dirty\": None,\n            \"error\": pieces[\"error\"],\n            \"date\": None,\n        }\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-branch\":\n        rendered = render_pep440_branch(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-post-branch\":\n        rendered = render_pep440_post_branch(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\n        \"version\": rendered,\n        \"full-revisionid\": pieces[\"long\"],\n        \"dirty\": pieces[\"dirty\"],\n        \"error\": None,\n        \"date\": pieces.get(\"date\"),\n    }\n\n\nclass VersioneerBadRootError(Exception):\n    \"\"\"The project root directory is unknown or missing key files.\"\"\"\n\n\ndef get_versions(verbose: bool = False) -> Dict[str, Any]:\n    \"\"\"Get the project version from whatever source is available.\n\n    Returns dict with two keys: 'version' and 'full'.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        # see the discussion in cmdclass.py:get_cmdclass()\n        del sys.modules[\"versioneer\"]\n\n    root = get_root()\n    cfg = get_config_from_root(root)\n\n    assert cfg.VCS is not None, \"please set [versioneer]VCS= in setup.cfg\"\n    handlers = HANDLERS.get(cfg.VCS)\n    assert handlers, \"unrecognized VCS '%s'\" % cfg.VCS\n    verbose = verbose or bool(cfg.verbose)  # `bool()` used to avoid `None`\n    assert (\n        cfg.versionfile_source is not None\n    ), \"please set versioneer.versionfile_source\"\n    assert cfg.tag_prefix is not None, \"please set versioneer.tag_prefix\"\n\n    versionfile_abs = os.path.join(root, cfg.versionfile_source)\n\n    # extract version from first of: _version.py, VCS command (e.g. 'git\n    # describe'), parentdir. This is meant to work for developers using a\n    # source checkout, for users of a tarball created by 'setup.py sdist',\n    # and for users of a tarball/zipball created by 'git archive' or github's\n    # download-from-tag feature or the equivalent in other VCSes.\n\n    get_keywords_f = handlers.get(\"get_keywords\")\n    from_keywords_f = handlers.get(\"keywords\")\n    if get_keywords_f and from_keywords_f:\n        try:\n            keywords = get_keywords_f(versionfile_abs)\n            ver = from_keywords_f(keywords, cfg.tag_prefix, verbose)\n            if verbose:\n                print(\"got version from expanded keyword %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        ver = versions_from_file(versionfile_abs)\n        if verbose:\n            print(\"got version from file %s %s\" % (versionfile_abs, ver))\n        return ver\n    except NotThisMethod:\n        pass\n\n    from_vcs_f = handlers.get(\"pieces_from_vcs\")\n    if from_vcs_f:\n        try:\n            pieces = from_vcs_f(cfg.tag_prefix, root, verbose)\n            ver = render(pieces, cfg.style)\n            if verbose:\n                print(\"got version from VCS %s\" % ver)\n            return ver\n        except NotThisMethod:\n            pass\n\n    try:\n        if cfg.parentdir_prefix:\n            ver = versions_from_parentdir(cfg.parentdir_prefix, root, verbose)\n            if verbose:\n                print(\"got version from parentdir %s\" % ver)\n            return ver\n    except NotThisMethod:\n        pass\n\n    if verbose:\n        print(\"unable to compute version\")\n\n    return {\n        \"version\": \"0+unknown\",\n        \"full-revisionid\": None,\n        \"dirty\": None,\n        \"error\": \"unable to compute version\",\n        \"date\": None,\n    }\n\n\ndef get_version() -> str:\n    \"\"\"Get the short version string for this project.\"\"\"\n    return get_versions()[\"version\"]\n\n\ndef get_cmdclass(cmdclass: Optional[Dict[str, Any]] = None):\n    \"\"\"Get the custom setuptools subclasses used by Versioneer.\n\n    If the package uses a different cmdclass (e.g. one from numpy), it\n    should be provide as an argument.\n    \"\"\"\n    if \"versioneer\" in sys.modules:\n        del sys.modules[\"versioneer\"]\n        # this fixes the \"python setup.py develop\" case (also 'install' and\n        # 'easy_install .'), in which subdependencies of the main project are\n        # built (using setup.py bdist_egg) in the same python process. Assume\n        # a main project A and a dependency B, which use different versions\n        # of Versioneer. A's setup.py imports A's Versioneer, leaving it in\n        # sys.modules by the time B's setup.py is executed, causing B to run\n        # with the wrong versioneer. Setuptools wraps the sub-dep builds in a\n        # sandbox that restores sys.modules to it's pre-build state, so the\n        # parent is protected against the child's \"import versioneer\". By\n        # removing ourselves from sys.modules here, before the child build\n        # happens, we protect the child from the parent's versioneer too.\n        # Also see https://github.com/python-versioneer/python-versioneer/issues/52\n\n    cmds = {} if cmdclass is None else cmdclass.copy()\n\n    # we add \"version\" to setuptools\n    from setuptools import Command\n\n    class cmd_version(Command):\n        description = \"report generated version string\"\n        user_options: List[Tuple[str, str, str]] = []\n        boolean_options: List[str] = []\n\n        def initialize_options(self) -> None:\n            pass\n\n        def finalize_options(self) -> None:\n            pass\n\n        def run(self) -> None:\n            vers = get_versions(verbose=True)\n            print(\"Version: %s\" % vers[\"version\"])\n            print(\" full-revisionid: %s\" % vers.get(\"full-revisionid\"))\n            print(\" dirty: %s\" % vers.get(\"dirty\"))\n            print(\" date: %s\" % vers.get(\"date\"))\n            if vers[\"error\"]:\n                print(\" error: %s\" % vers[\"error\"])\n\n    cmds[\"version\"] = cmd_version\n\n    # we override \"build_py\" in setuptools\n    #\n    # most invocation pathways end up running build_py:\n    #  distutils/build -> build_py\n    #  distutils/install -> distutils/build ->..\n    #  setuptools/bdist_wheel -> distutils/install ->..\n    #  setuptools/bdist_egg -> distutils/install_lib -> build_py\n    #  setuptools/install -> bdist_egg ->..\n    #  setuptools/develop -> ?\n    #  pip install:\n    #   copies source tree to a tempdir before running egg_info/etc\n    #   if .git isn't copied too, 'git describe' will fail\n    #   then does setup.py bdist_wheel, or sometimes setup.py install\n    #  setup.py egg_info -> ?\n\n    # pip install -e . and setuptool/editable_wheel will invoke build_py\n    # but the build_py command is not expected to copy any files.\n\n    # we override different \"build_py\" commands for both environments\n    if \"build_py\" in cmds:\n        _build_py: Any = cmds[\"build_py\"]\n    else:\n        from setuptools.command.build_py import build_py as _build_py\n\n    class cmd_build_py(_build_py):\n        def run(self) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_py.run(self)\n            if getattr(self, \"editable_mode\", False):\n                # During editable installs `.py` and data files are\n                # not copied to build_lib\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if cfg.versionfile_build:\n                target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n    cmds[\"build_py\"] = cmd_build_py\n\n    if \"build_ext\" in cmds:\n        _build_ext: Any = cmds[\"build_ext\"]\n    else:\n        from setuptools.command.build_ext import build_ext as _build_ext\n\n    class cmd_build_ext(_build_ext):\n        def run(self) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            versions = get_versions()\n            _build_ext.run(self)\n            if self.inplace:\n                # build_ext --inplace will only build extensions in\n                # build/lib<..> dir with no _version.py to write to.\n                # As in place builds will already have a _version.py\n                # in the module dir, we do not need to write one.\n                return\n            # now locate _version.py in the new build/ directory and replace\n            # it with an updated value\n            if not cfg.versionfile_build:\n                return\n            target_versionfile = os.path.join(self.build_lib, cfg.versionfile_build)\n            if not os.path.exists(target_versionfile):\n                print(\n                    f\"Warning: {target_versionfile} does not exist, skipping \"\n                    \"version update. This can happen if you are running build_ext \"\n                    \"without first running build_py.\"\n                )\n                return\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(target_versionfile, versions)\n\n    cmds[\"build_ext\"] = cmd_build_ext\n\n    if \"cx_Freeze\" in sys.modules:  # cx_freeze enabled?\n        from cx_Freeze.dist import build_exe as _build_exe  # type: ignore\n\n        # nczeczulin reports that py2exe won't like the pep440-style string\n        # as FILEVERSION, but it can be used for PRODUCTVERSION, e.g.\n        # setup(console=[{\n        #   \"version\": versioneer.get_version().split(\"+\", 1)[0], # FILEVERSION\n        #   \"product_version\": versioneer.get_version(),\n        #   ...\n\n        class cmd_build_exe(_build_exe):\n            def run(self) -> None:\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _build_exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            \"DOLLAR\": \"$\",\n                            \"STYLE\": cfg.style,\n                            \"TAG_PREFIX\": cfg.tag_prefix,\n                            \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                            \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[\"build_exe\"] = cmd_build_exe\n        del cmds[\"build_py\"]\n\n    if \"py2exe\" in sys.modules:  # py2exe enabled?\n        try:\n            from py2exe.setuptools_buildexe import py2exe as _py2exe  # type: ignore\n        except ImportError:\n            from py2exe.distutils_buildexe import py2exe as _py2exe  # type: ignore\n\n        class cmd_py2exe(_py2exe):\n            def run(self) -> None:\n                root = get_root()\n                cfg = get_config_from_root(root)\n                versions = get_versions()\n                target_versionfile = cfg.versionfile_source\n                print(\"UPDATING %s\" % target_versionfile)\n                write_to_version_file(target_versionfile, versions)\n\n                _py2exe.run(self)\n                os.unlink(target_versionfile)\n                with open(cfg.versionfile_source, \"w\") as f:\n                    LONG = LONG_VERSION_PY[cfg.VCS]\n                    f.write(\n                        LONG\n                        % {\n                            \"DOLLAR\": \"$\",\n                            \"STYLE\": cfg.style,\n                            \"TAG_PREFIX\": cfg.tag_prefix,\n                            \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                            \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n                        }\n                    )\n\n        cmds[\"py2exe\"] = cmd_py2exe\n\n    # sdist farms its file list building out to egg_info\n    if \"egg_info\" in cmds:\n        _egg_info: Any = cmds[\"egg_info\"]\n    else:\n        from setuptools.command.egg_info import egg_info as _egg_info\n\n    class cmd_egg_info(_egg_info):\n        def find_sources(self) -> None:\n            # egg_info.find_sources builds the manifest list and writes it\n            # in one shot\n            super().find_sources()\n\n            # Modify the filelist and normalize it\n            root = get_root()\n            cfg = get_config_from_root(root)\n            self.filelist.append(\"versioneer.py\")\n            if cfg.versionfile_source:\n                # There are rare cases where versionfile_source might not be\n                # included by default, so we must be explicit\n                self.filelist.append(cfg.versionfile_source)\n            self.filelist.sort()\n            self.filelist.remove_duplicates()\n\n            # The write method is hidden in the manifest_maker instance that\n            # generated the filelist and was thrown away\n            # We will instead replicate their final normalization (to unicode,\n            # and POSIX-style paths)\n            from setuptools import unicode_utils\n\n            normalized = [\n                unicode_utils.filesys_decode(f).replace(os.sep, \"/\")\n                for f in self.filelist.files\n            ]\n\n            manifest_filename = os.path.join(self.egg_info, \"SOURCES.txt\")\n            with open(manifest_filename, \"w\") as fobj:\n                fobj.write(\"\\n\".join(normalized))\n\n    cmds[\"egg_info\"] = cmd_egg_info\n\n    # we override different \"sdist\" commands for both environments\n    if \"sdist\" in cmds:\n        _sdist: Any = cmds[\"sdist\"]\n    else:\n        from setuptools.command.sdist import sdist as _sdist\n\n    class cmd_sdist(_sdist):\n        def run(self) -> None:\n            versions = get_versions()\n            self._versioneer_generated_versions = versions\n            # unless we update this, the command will keep using the old\n            # version\n            self.distribution.metadata.version = versions[\"version\"]\n            return _sdist.run(self)\n\n        def make_release_tree(self, base_dir: str, files: List[str]) -> None:\n            root = get_root()\n            cfg = get_config_from_root(root)\n            _sdist.make_release_tree(self, base_dir, files)\n            # now locate _version.py in the new base_dir directory\n            # (remembering that it may be a hardlink) and replace it with an\n            # updated value\n            target_versionfile = os.path.join(base_dir, cfg.versionfile_source)\n            print(\"UPDATING %s\" % target_versionfile)\n            write_to_version_file(\n                target_versionfile, self._versioneer_generated_versions\n            )\n\n    cmds[\"sdist\"] = cmd_sdist\n\n    return cmds\n\n\nCONFIG_ERROR = \"\"\"\nsetup.cfg is missing the necessary Versioneer configuration. You need\na section like:\n\n [versioneer]\n VCS = git\n style = pep440\n versionfile_source = src/myproject/_version.py\n versionfile_build = myproject/_version.py\n tag_prefix =\n parentdir_prefix = myproject-\n\nYou will also need to edit your setup.py to use the results:\n\n import versioneer\n setup(version=versioneer.get_version(),\n       cmdclass=versioneer.get_cmdclass(), ...)\n\nPlease read the docstring in ./versioneer.py for configuration instructions,\nedit setup.cfg, and re-run the installer or 'python versioneer.py setup'.\n\"\"\"\n\nSAMPLE_CONFIG = \"\"\"\n# See the docstring in versioneer.py for instructions. Note that you must\n# re-run 'versioneer.py setup' after changing this section, and commit the\n# resulting files.\n\n[versioneer]\n#VCS = git\n#style = pep440\n#versionfile_source =\n#versionfile_build =\n#tag_prefix =\n#parentdir_prefix =\n\n\"\"\"\n\nOLD_SNIPPET = \"\"\"\nfrom ._version import get_versions\n__version__ = get_versions()['version']\ndel get_versions\n\"\"\"\n\nINIT_PY_SNIPPET = \"\"\"\nfrom . import {0}\n__version__ = {0}.get_versions()['version']\n\"\"\"\n\n\ndef do_setup() -> int:\n    \"\"\"Do main VCS-independent setup function for installing Versioneer.\"\"\"\n    root = get_root()\n    try:\n        cfg = get_config_from_root(root)\n    except (OSError, configparser.NoSectionError, configparser.NoOptionError) as e:\n        if isinstance(e, (OSError, configparser.NoSectionError)):\n            print(\"Adding sample versioneer config to setup.cfg\", file=sys.stderr)\n            with open(os.path.join(root, \"setup.cfg\"), \"a\") as f:\n                f.write(SAMPLE_CONFIG)\n        print(CONFIG_ERROR, file=sys.stderr)\n        return 1\n\n    print(\" creating %s\" % cfg.versionfile_source)\n    with open(cfg.versionfile_source, \"w\") as f:\n        LONG = LONG_VERSION_PY[cfg.VCS]\n        f.write(\n            LONG\n            % {\n                \"DOLLAR\": \"$\",\n                \"STYLE\": cfg.style,\n                \"TAG_PREFIX\": cfg.tag_prefix,\n                \"PARENTDIR_PREFIX\": cfg.parentdir_prefix,\n                \"VERSIONFILE_SOURCE\": cfg.versionfile_source,\n            }\n        )\n\n    ipy = os.path.join(os.path.dirname(cfg.versionfile_source), \"__init__.py\")\n    maybe_ipy: Optional[str] = ipy\n    if os.path.exists(ipy):\n        try:\n            with open(ipy, \"r\") as f:\n                old = f.read()\n        except OSError:\n            old = \"\"\n        module = os.path.splitext(os.path.basename(cfg.versionfile_source))[0]\n        snippet = INIT_PY_SNIPPET.format(module)\n        if OLD_SNIPPET in old:\n            print(\" replacing boilerplate in %s\" % ipy)\n            with open(ipy, \"w\") as f:\n                f.write(old.replace(OLD_SNIPPET, snippet))\n        elif snippet not in old:\n            print(\" appending to %s\" % ipy)\n            with open(ipy, \"a\") as f:\n                f.write(snippet)\n        else:\n            print(\" %s unmodified\" % ipy)\n    else:\n        print(\" %s doesn't exist, ok\" % ipy)\n        maybe_ipy = None\n\n    # Make VCS-specific changes. For git, this means creating/changing\n    # .gitattributes to mark _version.py for export-subst keyword\n    # substitution.\n    do_vcs_install(cfg.versionfile_source, maybe_ipy)\n    return 0\n\n\ndef scan_setup_py() -> int:\n    \"\"\"Validate the contents of setup.py against Versioneer's expectations.\"\"\"\n    found = set()\n    setters = False\n    errors = 0\n    with open(\"setup.py\", \"r\") as f:\n        for line in f.readlines():\n            if \"import versioneer\" in line:\n                found.add(\"import\")\n            if \"versioneer.get_cmdclass()\" in line:\n                found.add(\"cmdclass\")\n            if \"versioneer.get_version()\" in line:\n                found.add(\"get_version\")\n            if \"versioneer.VCS\" in line:\n                setters = True\n            if \"versioneer.versionfile_source\" in line:\n                setters = True\n    if len(found) != 3:\n        print(\"\")\n        print(\"Your setup.py appears to be missing some important items\")\n        print(\"(but I might be wrong). Please make sure it has something\")\n        print(\"roughly like the following:\")\n        print(\"\")\n        print(\" import versioneer\")\n        print(\" setup( version=versioneer.get_version(),\")\n        print(\"        cmdclass=versioneer.get_cmdclass(),  ...)\")\n        print(\"\")\n        errors += 1\n    if setters:\n        print(\"You should remove lines like 'versioneer.VCS = ' and\")\n        print(\"'versioneer.versionfile_source = ' . This configuration\")\n        print(\"now lives in setup.cfg, and should be removed from setup.py\")\n        print(\"\")\n        errors += 1\n    return errors\n\n\ndef setup_command() -> NoReturn:\n    \"\"\"Set up Versioneer and exit with appropriate error code.\"\"\"\n    errors = do_setup()\n    errors += scan_setup_py()\n    sys.exit(1 if errors else 0)\n\n\nif __name__ == \"__main__\":\n    cmd = sys.argv[1]\n    if cmd == \"setup\":\n        setup_command()\n"
        }
      ]
    }
  ]
}