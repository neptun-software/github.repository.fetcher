{
  "metadata": {
    "timestamp": 1736559739856,
    "page": 442,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQ1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/nevergrad",
      "stars": 3983,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.0244140625,
          "content": "[run]\nomit = */test_*.py\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.1953125,
          "content": "# Byte-compiled / optimized / DLL files / tmp\n__pycache__/\n*.py[cod]\n*$py.class\n*.swp\n*_build\n\n# C extensions\n*.so\n\n# OS specific files\n.DS_Store\n\n# Distribution / packaging / data storage\ndata/\noutputs/\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.8232421875,
          "content": "repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v2.2.3\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-added-large-files\n  # -   repo: https://github.com/pre-commit/mirrors-autopep8\n  #     rev: v1.4.4  # Use the sha / tag you want to point at\n  #     hooks:\n  #     - id: autopep8\n  #       exclude: ^scripts/\n  #       args: ['-i', '--max-line-length=140']\n  - repo: https://github.com/python/black\n    rev: 22.3.0\n    hooks:\n      - id: black\n        language_version: python3\n  - repo: https://github.com/pre-commit/mirrors-pylint\n    rev: v2.4.4\n    hooks:\n      - id: pylint\n        exclude: ^scripts/\n        args: ['--disable=bad-continuation'] # coz incompatible with black\n  - repo: https://github.com/google/yamlfmt\n    rev: v0.14.0\n    hooks:\n      - id: yamlfmt\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 0.5966796875,
          "content": "[MASTER]\nextension-pkg-whitelist=\n    numpy, nose, nose.tools, numpy.testing, pathlib.PurePath, pathlib.PosixPath, pathlib.Path\n\n[MESSAGES CONTROL]\n# disabled messages\ndisable=\n    invalid-name, missing-docstring, too-few-public-methods, protected-access, import-error,\n    fixme, no-else-return, no-member, useless-import-alias, unsubscriptable-object,\n    too-many-arguments, too-many-instance-attributes, too-many-lines, too-many-locals\n\n[TYPECHECK]\nignored-modules = numpy, numpy.testing\nignored-classes = numpy, numpy.testing\n\n\n[FORMAT]\n# Maximum number of characters on a single line.\nmax-line-length=140\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 26.22265625,
          "content": "# Changelog\n\n## main\n\n## v0.11.0 (2023-07-25)\n- additional benchmarks\n- adding tests in the CI\n- helpers for choosing algorithms for different problems\n\n## v0.10.0 (2023-07-20)\n- fix the issue with the Boston dataset\n\n## v0.9.0 (2023-07-18)\n- Add many quasi-opposite variants\n- Improve the Dagsduhloid benchmark\n- Get rid of legacy pypi solver in CircleCI\n- Update Pypi in CircleCI\n- Switch to Python 3.8\n\n## v0.8.0 (2023-07-03)\n- Add the Dagstuhloid benchmark\n- Add yet another group of metamodels\n\n## v0.7.0 (2023-06-16)\n- Fix links\n- Add metamodels\n- Update for weighted multiobjective optimization with differential evolution\n\n## v0.6.0 (2022-02-22)\n\n### Breaking changes\n\n- Removed `descriptor` field of parameters which had been deprecated in previous versions. Use `function` field instead to specify if the function \n  is deterministic or not [#X](https://github.com/facebookresearch/nevergrad/pull/X).\n\n### Important changes\n\n- `TransitionChoice` behavior has been changed to use bins instead of a full float representation. This may lead to slight\n  changes during optimizations. It can also be set as unordered for use with discrete 1+1 optimizers (experimental)\n- Adding NGOptRW, presumably better than NGOpt for real-world problems.\n- Making some dependencies optional because running was becoming too complicated.\n- Adding the NLOPT library.\n- Adding smoothness operators for discrete optimization.\n\n### Other changes\n- Adding YAPBBOB, with a parameter regulating YABBOB-like problems so that the distribution of the optimum is less rotationally invariant.\n- Adding constrained counterparts of YABBOB: yapenbbob (a few constraints), yaonepenbbob (single constraint), yamegapenbbob (many constraints).\n- Improvements in the photonics benchmarks.\n- Externalizing CompilerGym.\n- Making some tests less flaky.\n- Adding Simulated annealing and Tabu search.\n- Making the code more robust to Gym environments.\n\n## 0.5.0 (2022-03-08)\n\n### Breaking changes\n\n- `copy()` method of a `Parameter` does not change the parameters's random state anymore (it used to reset it to `None` [#1048](https://github.com/facebookresearch/nevergrad/pull/1048)\n- `MultiobjectiveFunction` does not exist anymore  [#1034](https://github.com/facebookresearch/nevergrad/pull/1034).\n- `Choice` and `TransitionChoice` have some of their API changed for uniformization. In particular, `indices` is now an\n  `ng.p.Array` (and not an `np.ndarray`) which contains the selected indices (or index) of the `Choice`. The sampling is\n  performed by specific \"layers\" that are applied to `Data` parameters [#1065](https://github.com/facebookresearch/nevergrad/pull/1065).\n- `Parameter.set_standardized_space` does not take a `deterministic` parameter anymore\n  [#1068](https://github.com/facebookresearch/nevergrad/pull/1068).  This is replaced by the more\n  general `with ng.p.helpers.determistic_sampling(parameter)` context. One-shot algorithms are also updated to choose\n  options of `Choice` parameters deterministically, since it is a simpler behavior to expect compared to sampling the\n  standardized space than sampling the option stochastically from there\n- `RandomSearch` now defaults to sample values using the `parameter.sample()` instead of a Gaussian\n   [#1068](https://github.com/facebookresearch/nevergrad/pull/1068).  The only difference comes with bounded\n  variables since in this case `parameter.sample()` samples uniformly (unless otherwise specified).\n  The previous behavior can be obtained with `RandomSearchMaker(sampler=\"gaussian\")`.\n- `PSO` API has been slightly changed [#1073](https://github.com/facebookresearch/nevergrad/pull/1073)\n- `Parameter` instances `descriptor` attribute is deprecated, in favor of a combinaison of an analysis function\n  (`ng.p.helpers.analyze`) returning information about the parameter (eg: whether continuous, deterministic etc...)\n  and a new `function` attribute which can be used to provide information about the function (eg: whether deterministic etc)\n  [#1076](https://github.com/facebookresearch/nevergrad/pull/1076).\n- Half the budget alloted to solve cheap constrained is now used by a sub-optimizer\n  [#1047](https://github.com/facebookresearch/nevergrad/pull/1047). More changes of constraint management will land\n  in the near future.\n- Experimental methods `Array.set_recombination` and `Array.set_mutation(custom=.)` are removed in favor of\n  layers changing `Array` behaviors [#1086](https://github.com/facebookresearch/nevergrad/pull/1086).\n  Caution: this is still very experimental (and undocumented).\n- Important bug correction on the shape of bounds if specified as tuple or list instead of np.ndarray\n  [#1221](https://github.com/facebookresearch/nevergrad/pull/1221).\n\n### Important changes\n\n- `master` branch has been renamed to `main`. See [#1230](https://github.com/facebookresearch/nevergrad/pull/1230) for more context.\n- `Parameter` classes are undergoing heavy changes, please open an issue if you encounter any problem.\n  The midterm aim is to allow for simpler constraint management.\n- `Parameter` have been updated  have undergone heavy changes to ease the handling of their tree structure (\n  [#1029](https://github.com/facebookresearch/nevergrad/pull/1029)\n  [#1036](https://github.com/facebookresearch/nevergrad/pull/1036)\n  [#1038](https://github.com/facebookresearch/nevergrad/pull/1038)\n  [#1043](https://github.com/facebookresearch/nevergrad/pull/1043)\n  [#1044](https://github.com/facebookresearch/nevergrad/pull/1044)\n  )\n- `Parameter` classes have now a layer structure [#1045](https://github.com/facebookresearch/nevergrad/pull/1045)\n  which simplifies changing their behavior. In future PRs this system will take charge of bounds, other constraints,\n  sampling etc.\n- The layer structures allows disentangling bounds and log-distribution. This goal has been reached with\n  [#1053](https://github.com/facebookresearch/nevergrad/pull/1053) but may create some instabilities. In particular,\n  the representation (`__repr__`) of `Array` has changed, and their `bounds` attribute is no longer reliable for now.\n  This change will eventually lead to a new syntax for settings bounds and distribution, but it's not ready yet.\n- `DE` initial sampling as been updated to take bounds into accounts [#1058](https://github.com/facebookresearch/nevergrad/pull/1058)\n- `Array` can now take `lower` and `upper` bounds as initialization arguments. The array is initialized at its average\n  if not `init` is provided and both bounds are provided. In this case, sampling will be uniformm between these bounds.\n- Bayesian optimizers are now properly using the bounds for bounded problem, which may improve performance\n  [#1222](https://github.com/facebookresearch/nevergrad/pull/1222).\n\n\n### Other changes\n\n- the new `nevergrad.errors` module gathers errors and warnings used throughout the package (WIP) [#1031](https://github.com/facebookresearch/nevergrad/pull/1031).\n- `EvolutionStrategy` now defaults to NSGA2 selection in the multiobjective case\n- A new experimental callback adds an early stopping mechanism\n  [#1054](https://github.com/facebookresearch/nevergrad/pull/1054).\n- `Choice`-like parameters now accept integers are inputs instead of a list, as a shortcut for `range(num)`\n  [#1106](https://github.com/facebookresearch/nevergrad/pull/1106).\n- An interface with [Pymoo](https://pymoo.org/) optimizers has been added\n  [#1197](https://github.com/facebookresearch/nevergrad/pull/1197).\n- An interface with [BayesOptim](https://github.com/wangronin/Bayesian-Optimization) optimizers has been added\n  [#1179](https://github.com/facebookresearch/nevergrad/pull/1179).\n- Fix for abnormally slow iterations for large budgets using CMA in a portfolio\n  [#1350](https://github.com/facebookresearch/nevergrad/pull/1350).\n- A new `enable_pickling` option was added to optimizers. This is only necessary for some of them (among which `scipy`-based optimizer), and comes at the cost of additional memory usage\n  [#1356](https://github.com/facebookresearch/nevergrad/pull/1356)\n  [#1358](https://github.com/facebookresearch/nevergrad/pull/1358).\n\n## 0.4.3 (2021-01-28)\n\n### Important changes\n\n- `tell` method can now receive a list/array of losses for multi-objective optimization [#775](https://github.com/facebookresearch/nevergrad/pull/775). For now it is neither robust, nor scalable, nor stable, nor optimal so be careful when using it. More information in the [documentation](https://facebookresearch.github.io/nevergrad/optimization.html#multiobjective-minimization-with-nevergrad).\n- The old way to perform multiobjective optimization, through the use of :code:`MultiobjectiveFunction`, is now deprecated and will be removed after version 0.4.3 [#1017](https://github.com/facebookresearch/nevergrad/pull/1017).\n- By default, the optimizer now returns the best set of parameter as recommendation [#951](https://github.com/facebookresearch/nevergrad/pull/951), considering that the function is deterministic. The previous behavior would use an estimation of noise to provide the pessimistic best point, leading to unexpected behaviors [#947](https://github.com/facebookresearch/nevergrad/pull/947). You can can back to this behavior by specifying: :code:`parametrization.descriptors.deterministic_function = False`\n\n### Other\n\n- `DE` and its variants have been updated to make full use of the multi-objective losses [#789](https://github.com/facebookresearch/nevergrad/pull/789). Other optimizers convert multiobjective problems to a volume minimization, which is not always as efficient.\n- as an **experimental** feature we have added some preliminary support for constraint management through penalties.\n  From then on the prefered option for penalty is to register a function returning a positive float when the constraint is satisfied.\n  While we will wait fore more testing before documenting it, this may already cause instabilities and errors when adding cheap constraints.\n  Please open an issue if you encounter a problem.\n- `tell` argument `value` is renamed to `loss` for clarification [#774](https://github.com/facebookresearch/nevergrad/pull/774). This can be breaking when using named arguments!\n- `ExperimentFunction` now automatically records arguments used for their instantiation so that they can both be used to create a new copy, and as descriptors if there are of type  int/bool/float/str [#914](https://github.com/facebookresearch/nevergrad/pull/914 [#914](https://github.com/facebookresearch/nevergrad/pull/914)).\n- from now on, code formatting needs to be [`black`](https://black.readthedocs.io/en/stable/) compliant. This is\n  simply performed by running `black nevergrad`. A continuous integration checks that PRs are compliant, and the\n  precommit hooks have been adapted. For PRs branching from an old master, you can run `black --line-length=110 nevergrad/<path_to_modified_file>` to make your code easier to merge.\n- Pruning has been patched to make sure it is not activated too often upon convergence [#1014](https://github.com/facebookresearch/nevergrad/pull/1014). The bug used to lead to important slowdown when reaching near convergence.\n\n## 0.4.2 (2020-08-04)\n\n- `recommend` now provides an evaluated candidate when possible. For non-deterministic parametrization like `Choice`, this means we won't resample, and we will actually recommend the best past evaluated candidate [#668](https://github.com/facebookresearch/nevergrad/pull/668).  Still, some optimizers (like `TBPSA`) may recommend a non-evaluated point.\n- `Choice` and `TransitionChoice` can now take a `repetitions` parameters for sampling several times, it is equivalent to :code:`Tuple(*[Choice(options) for _ in range(repetitions)])` but can be be up to 30x faster for large numbers of repetitions [#670](https://github.com/facebookresearch/nevergrad/pull/670) [#696](https://github.com/facebookresearch/nevergrad/pull/696).\n- Defaults for bounds in `Array` is now `bouncing`, which is a variant of `clipping` avoiding over-sompling on the bounds [#684](https://github.com/facebookresearch/nevergrad/pull/684) and [#691](https://github.com/facebookresearch/nevergrad/pull/691).\n\nThis version should be robust. Following versions may become more unstable as we will add more native multiobjective optimization as an **experimental** feature. We also are in the process of simplifying the naming pattern for the \"NGO/Shiwa\" type optimizers which may cause some changes in the future.\n\n## 0.4.1 (2020-05-07)\n\n- `Archive` now stores the best corresponding candidate. This requires twice the memory compared to before the change. [#594](https://github.com/facebookresearch/nevergrad/pull/594)\n- `Parameter` now holds a `loss: Optional[float]` attribute which is set and used by optimizers after the `tell` method.\n- Quasi-random samplers (`LHSSearch`, `HammersleySearch`, `HaltonSearch` etc...) now sample in the full range of bounded variables when the `full_range_sampling` is `True` [#598](https://github.com/facebookresearch/nevergrad/pull/598). This required some ugly hacks, help is most welcome to find nices solutions.\n- `full_range_sampling` is activated by default if both range are provided in `Array.set_bounds`.\n- Propagate parametrization system features (generation tracking, ...) to `OnePlusOne` based algorithms [#599](https://github.com/facebookresearch/nevergrad/pull/599).\n- Moved the `Selector` dataframe overlay so that basic requirements do not include `pandas` (only necessary for benchmarks) [#609](https://github.com/facebookresearch/nevergrad/pull/609)\n- Changed the version name pattern (removed the `v`) to unify with `pypi` versions. Expect more frequent intermediary versions to be pushed (deployment has now been made pseudo-automatic).\n- Started implementing more ML-oriented testbeds [#642](https://github.com/facebookresearch/nevergrad/pull/642)\n\n\n## v0.4.0 (2020-03-09)\n\n### Breaking and important changes\n\n- Removed all deprecated code [#499](https://github.com/facebookresearch/nevergrad/pull/499). That includes:\n  - `instrumentation` as init parameter of an `Optimizer` (replaced by `parametrization`)\n  - `instrumentation` as attribute of an `Optimizer` (replaced by `parametrization`)\n  - `candidate_maker` (not needed anymore)\n  - `optimize` methods of `Optimizer` (renamed to `minimize`)\n  - all the `instrumentation` subpackage (replaced by `parametrization`) and its legacy methods (`set_cheap_constraint_checker` etc)\n- Removed `ParametrizedOptimizer` and `OptimizerFamily` in favor of `ConfiguredOptimizer` with simpler usage [#518](https://github.com/facebookresearch/nevergrad/pull/518) [#521](https://github.com/facebookresearch/nevergrad/pull/521).\n- Some variants of algorithms have been removed from the `ng.optimizers` namespace to simplify it. All such variants can be easily created\n  using the corresponding `ConfiguredOptimizer`. Also, adding `import nevergrad.optimization.experimentalvariants` will populate `ng.optimizers.registry`\n  with all variants, and they are all available for benchmarks [#528](https://github.com/facebookresearch/nevergrad/pull/528).\n- Renamed `a_min` and `a_max` in `Array`, `Scalar` and `Log` parameters for clarity.\n  Using old names will raise a deprecation warning for the time being.\n- `archive` is pruned much more often (eg.: for `num_workers=1`, usually pruned to 100 elements when reaching 1000),\n  so you should not rely on it for storing all results, use a callback instead [#571](https://github.com/facebookresearch/nevergrad/pull/571).\n  If this is a problem for you, let us know why and we'll find a solution!\n\n### Other changes\n\n- Propagate parametrization system features (generation tracking, ...) to `TBPSA`, `PSO` and `EDA` based algorithms.\n- Rewrote multiobjective core system [#484](https://github.com/facebookresearch/nevergrad/pull/484).\n- Activated Windows CI (still a bit flaky, with a few deactivated tests).\n- Better callbacks in `np.callbacks`, including exporting to [`hiplot`](https://github.com/facebookresearch/hiplot).\n- Activated [documentation](https://facebookresearch.github.io/nevergrad/) on github pages.\n- Scalar now takes optional `lower` and `upper` bounds at initialization, and `sigma` (and optionnally `init`)\n  if is automatically set to a sensible default [#536](https://github.com/facebookresearch/nevergrad/pull/536).\n\n\n## v0.3.2 (2020-02-05)\n\n\n### Breaking changes (possibly for next version)\n\n- Fist argument of optimizers is renamed to `parametrization` instead of `instrumentation` for consistency [#497](https://github.com/facebookresearch/nevergrad/pull/497). There is currently a deprecation warning, but this will be breaking in v0.4.0.\n- Old `instrumentation` classes now raise deprecation warnings, and will disappear in versions >0.3.2.\n  Hence, prefere using parameters from `ng.p` than `ng.var`, and avoid using `ng.Instrumentation` altogether if\n  you don't need it anymore (or import it through `ng.p.Instrumentation`).\n- `CandidateMaker` (`optimizer.create_candidate`) raises `DeprecationWarning`s since it new candidates/parameters\n  can be straightforwardly created (`parameter.spawn_child(new_value=new_value)`)\n- `Candidate` class is completely removed, and is completely replaced by `Parameter` [#459](https://github.com/facebookresearch/nevergrad/pull/459).\n  This should not break existing code since `Parameter` can be straightforwardly used as a `Candidate`.\n\n### Other changes\n\n- New parametrization is now as efficient as in v0.3.0 (see CHANGELOG for v0.3.1 for contect)\n- Optimizers can now hold any parametrization, not just `Instrumentation`. This for instance mean that when you\n  do `OptimizerClass(instrumentation=12, budget=100)`, the instrumentation (and therefore the candidates) will be of class\n  `ng.p.Array` (and not `ng.p.Instrumentation`), and their attribute `value` will be the corresponding `np.ndarray` value.\n  You can still use `args` and `kwargs` if you want, but it's no more needed!\n- Added *experimental* evolution-strategy-like algorithms using new parametrization [#471](https://github.com/facebookresearch/nevergrad/pull/471)\n  (the behavior and API of these optimizers will probably evolve in the near future).\n- `DE` algorithms comply with the new parametrization system and can be set to use parameter's recombination.\n- Fixed array as bounds in `Array` parameters\n\n## v0.3.1 (2020-01-23)\n\n**Note**: this is the first step to propagate the instrumentation/parametrization framework.\n Learn more on the [Facebook user group](https://www.facebook.com/notes/nevergrad-users/moving-to-new-parametrization-upcoming-unstability-and-breaking-changes/639090766861215/).\n If you are looking for stability, await for version 0.4.0, but the intermediary releases will help by providing\n deprecation warnings.\n\n### Breaking changes\n\n- `FolderFunction` must now be accessed through `nevergrad.parametrization.FolderFunction`\n- Instrumentation names are changed (possibly breaking for benchmarks records)\n\n### Other changes\n\n- Old instrumentation classes now all inherits from the new parametrization classes [#391](https://github.com/facebookresearch/nevergrad/pull/391). Both systems coexists, but optimizers\n  use the old API at this point (it will use the new one in version 0.3.2).\n- Temporary performance loss is expected in orded to keep compatibility between `Variable` and `Parameter` frameworks.\n- `PSO` now uses initialization by sampling the parametrization, instead of sampling all the real space. A new `WidePSO`\n optimizer was created, using the previous initial sampling method [#467](https://github.com/facebookresearch/nevergrad/pull/467).\n\n## v0.3.0 (2020-01-08)\n\n**Note**: this version is stable, but the following versions will include breaking changes which may cause instability. The aim of this changes will be to update the instrumentation system for more flexibility. See PR #323 and [Fb user group](https://www.facebook.com/groups/nevergradusers/) for more information.\n\n### Breaking changes\n\n- `Instrumentation` is now a `Variable` for simplicity and flexibility. The `Variable` API has therefore heavily changed,\n  and bigger changes are coming (`instrumentation` will become `parametrization` with a different API). This should only impact custom-made variables.\n- `InstrumentedFunction` has been aggressively deprecated to solve bugs and simplify code, in favor of using the `Instrumentation` directly at the optimizer initialization,\n  and of using `ExperimentFunction` to define functions to be used in benchmarks. Main differences are:\n  * `instrumentation` attribute is renamed to `parametrization` for forward compatibility.\n  *  `__init__` takes exactly two arguments (main function and parametrization/instrumentation) and\n  * calls to `__call__` is directly forwarded to the main function (instead of converting from data space),\n- `Candidates` have now a `uid` instead of a `uuid` for compatibility reasons.\n- Update archive `keys/items_as_array` methods to `keys/items_as_arrays` for consistency.\n\n### Other changes\n\n- Benchmark plots now show confidence area (using partially transparent lines).\n- `Chaining` optimizer family enables chaining of algorithms.\n- Cleaner installation.\n- New simplified `Log` variable for log-distributed scalars.\n- Cheap constraints can now be provided through the `Instrumentation`\n- Added preliminary multiobjective function support (may be buggy for the time being, and API will change)\n- New callback for dumping parameters and loss, and loading them back easily for display (display yet to come).\n- Added a new parametrization module which is expected to soon replace the instrumentation module.\n- Added new test cases: games, power system, etc (experimental)\n- Added new algorithms: quasi-opposite one shot optimizers\n\n## v0.2.2\n\n### Breaking changes\n\n- instrumentations now hold a `random_state` attribute which can be seeded (`optimizer.instrumentation.random_state.seed(12)`).\n  Seeding `numpy`'s global random state seed **before** using the instrumentation still works (but if not, this change can break reproducibility).\n  The random state is used by the optimizers through the `optimizer._rng` property.\n\n### Other changes\n\n- added a `Scalar` variable as a shortcut to `Array(1).asscalar(dtype)` to simplify specifying instrumentation.\n- added `suggest` method to optimizers in order to manually provide the next `Candidate` from the `ask` method (experimental feature, name and behavior may change).\n- populated `nevergrad`'s namespace so that `import nevergrad as ng` gives access to `ng.Instrumentation`, `ng.var` and `ng.optimizers`. The\n  `optimizers` namespace is quite messy, some non-optimizer objects will eventually be removed from there.\n- renamed `optimize` to `minimize` to be more explicit. Using `optimize` will raise a `DeprecationWarning` for the time being.\n- added first game-oriented testbed function in the `functions.rl` module. This is still experimental and will require refactoring before the API becomes stable.\n\n## v0.2.1\n\n### Breaking changes\n\n- changed `tanh` to `arctan` as default for bounded variables (much wider range).\n- changed cumulative Gaussian density to `arctan` for rescaling in `BO` (much wider range).\n- renamed `Array.asfloat` method to `Array.asscalar` and allow casting to `int` as well through an argument.\n\n### Other changes\n\n- fixed `tell_not_asked` for `DE` family of optimizers.\n- added `dump` and `load` method to `Optimizer`.\n- Added warnings against inefficient settings: `BO` algorithms with dis-continuous or noisy instrumentations\n  without appropriate parametrization, `PSO` and `DE` for low budget.\n- improved benchmark plots legend.\n\n## v0.2.0\n\n### Breaking changes\n\n- first parameter of optimizers is now `instrumentation` instead of `dimension`. This allows the optimizer\n  to have information on the underlying structure. `int`s are still allowed as before and will set the instrumentation\n  to the `Instrumentation(var.Array(n))` (which is basically the identity).\n- removed `BaseFunction` in favor of `InstrumentedFunction` and use instrumentation instead of\n  defining specific transforms (breaking change for benchmark function implementation).\n- `ask()` and `provide_recommendation()` now return a `Candidate` with attributes `args`, `kwargs` (depending on the instrumentation)\n  and `data` (the array which was formerly returned). `tell` must now receive this candidate as well instead of\n  the array.\n- removed `tell_not_asked` in favor of `tell`. A new `num_tell_not_asked` attribute is added to check the number of `tell` calls with non-asked points.\n\n### Other changes\n\n- updated `bayesion-optimization` version to 1.0.1.\n- from now on, optimizers should preferably implement `_internal_ask_candidate` and `_internal_tell_candidate` instead of `_internal_ask`\n  and `_internal_tell`. This should take at most one more line: `x = candidate.data`.\n- added an `_asked` private attribute to register uuid of particuels that were asked for.\n- solved `ArtificialFunction` delay bug.\n\n## v0.1.6\n\n- corrected a bug introduced by v0.1.5 for `PSO`.\n- activated `tell_not_ask` for `PSO`, `TBPSA` and differential evolution algorithms.\n- added a pruning mechanisms for optimizers archive in order to avoid using a huge amount of memory.\n- corrected typing after activating `numpy-stubs`.\n\n## v0.1.5\n\n- provided different install procedures for optimization, benchmark and dev (requirements differ).\n- added an experimental `tell_not_asked` method to optimizers.\n- switched to `pytest` for testing, and removed dependency to `nosetests` and `genty`.\n- made archive more memory efficient by using bytes as key instead of tuple of floats.\n- started rewritting some optimizers as instance of a family of optimizers (experimental).\n- added pseudotime in benchmarks for both steady mode and batch mode.\n- made the whole chain from `Optimizer` to `BenchmarkChunk` stateful and able to restart from where it was stopped.\n- started introducing `tell_not_asked` method (experimental).\n\n## v0.1.4\n\n- fixed `PSO` in asynchronous case\n- started refactoring `instrumentation` in depth, and more specifically instantiation of external code (breaking change)\n- Added Photonics and ARCoating test functions\n- Added variants of algorithms\n\n## v0.1.3\n\n- multiple bug fixes\n- multiple typo corrections (including modules changing names)\n- added MLDA functions\n- allowed steady state in experiments\n- allowed custom file types for external code instantiation\n- added dissymetric noise case to `ArtificialFunction`\n- prepared an `Instrumentation` class to simplify instrumentation (breaking changes will come)\n- added new algorithms and benchmarks\n- improved plotting\n- added a transform method to `BaseFunction` (more breaking changes will come)\n\nWork on `instrumentation` will continue and breaking changes will be pushed in the following versions.\n\n## v0.1.0\n\nInitial version\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2763671875,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <opensource-conduct@fb.com>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.060546875,
          "content": "MIT License\n\nCopyright (c) Facebook, Inc. and its affiliates.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.0517578125,
          "content": "include LICENSE README.md\ninclude requirements/*.txt\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 3.4599609375,
          "content": "[![Support Ukraine](https://img.shields.io/badge/Support-Ukraine-FFD500?style=flat&labelColor=005BBB)](https://opensource.fb.com/support-ukraine) [![CircleCI](https://circleci.com/gh/facebookresearch/nevergrad/tree/main.svg?style=svg)](https://circleci.com/gh/facebookresearch/nevergrad/tree/main)\n\n# Nevergrad - A gradient-free optimization platform\n\n![Nevergrad](docs/resources/Nevergrad-LogoMark.png)\n\n\n`nevergrad` is a Python 3.8+ library. It can be installed with:\n\n```\npip install nevergrad\n```\n\nMore installation options, including windows installation, and complete instructions are available in the \"Getting started\" section of the [**documentation**](https://facebookresearch.github.io/nevergrad/).\n\nYou can join Nevergrad users Facebook group [here](https://www.facebook.com/groups/nevergradusers/).\n\nMinimizing a function using an optimizer (here `NGOpt`) is straightforward:\n\n```python\nimport nevergrad as ng\n\ndef square(x):\n    return sum((x - .5)**2)\n\noptimizer = ng.optimizers.NGOpt(parametrization=2, budget=100)\nrecommendation = optimizer.minimize(square)\nprint(recommendation.value)  # recommended value\n>>> [0.49971112 0.5002944]\n```\n\n`nevergrad` can also support bounded continuous variables as well as discrete variables, and mixture of those.\nTo do this, one can specify the input space:\n\n```python\nimport nevergrad as ng\n\ndef fake_training(learning_rate: float, batch_size: int, architecture: str) -> float:\n    # optimal for learning_rate=0.2, batch_size=4, architecture=\"conv\"\n    return (learning_rate - 0.2)**2 + (batch_size - 4)**2 + (0 if architecture == \"conv\" else 10)\n\n# Instrumentation class is used for functions with multiple inputs\n# (positional and/or keywords)\nparametrization = ng.p.Instrumentation(\n    # a log-distributed scalar between 0.001 and 1.0\n    learning_rate=ng.p.Log(lower=0.001, upper=1.0),\n    # an integer from 1 to 12\n    batch_size=ng.p.Scalar(lower=1, upper=12).set_integer_casting(),\n    # either \"conv\" or \"fc\"\n    architecture=ng.p.Choice([\"conv\", \"fc\"])\n)\n\noptimizer = ng.optimizers.NGOpt(parametrization=parametrization, budget=100)\nrecommendation = optimizer.minimize(fake_training)\n\n# show the recommended keyword arguments of the function\nprint(recommendation.kwargs)\n>>> {'learning_rate': 0.1998, 'batch_size': 4, 'architecture': 'conv'}\n```\n\nLearn more on parametrization in the [**documentation**](https://facebookresearch.github.io/nevergrad/)!\n\n![Example of optimization](docs/resources/TwoPointsDE.gif)\n\n*Convergence of a population of points to the minima with two-points DE.*\n\n\n## Documentation\n\nCheck out our [**documentation**](https://facebookresearch.github.io/nevergrad/)! It's still a work in progress, so don't hesitate to submit issues and/or pull requests (PRs) to update it and make it clearer!\nThe last version of our [**data**](https://drive.google.com/file/d/1p8d1bMCDlvWrDIMXP7fT9pJa1cgjH3NM/view?usp=sharing) and the last version of our [**PDF report**](https://tinyurl.com/dagstuhloid). \n\n## Citing\n\n```bibtex\n@misc{nevergrad,\n    author = {J. Rapin and O. Teytaud},\n    title = {{Nevergrad - A gradient-free optimization platform}},\n    year = {2018},\n    publisher = {GitHub},\n    journal = {GitHub repository},\n    howpublished = {\\url{https://GitHub.com/FacebookResearch/Nevergrad}},\n}\n```\n\n## License\n\n`nevergrad` is released under the MIT license. See [LICENSE](LICENSE) for additional details about it.\nSee also our [Terms of Use](https://opensource.facebook.com/legal/terms) and [Privacy Policy](https://opensource.facebook.com/legal/privacy).\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 1.291015625,
          "content": "[mypy]\n\n#[mypy-scipy.*,requests,smac,smac.*,pandas,compiler_gym,compiler_gym.*,gym,gym.*,gym_anm,matplotlib.*,pytest,cma,bayes_opt.*,torchvision.models,torch.*,mpl_toolkits.*,fcmaes.*,tqdm,pillow,PIL,PIL.Image,sklearn.*,pyomo.*,pyproj,IOHexperimenter.*,tensorflow,koncept.models,cv2,imquality,imquality.brisque,lpips,mixsimulator.*,networkx.*,cdt.*,]\n[mypy-scipy.*,requests,pandas,compiler_gym,compiler_gym.*,gym_anm,matplotlib.*,pytest,cma,bayes_opt.*,torchvision.models,torch.*,mpl_toolkits.*,fcmaes.*,tqdm,pillow,PIL,PIL.Image,sklearn.*,pyomo.*,pyproj,IOHexperimenter.*,tensorflow,koncept.models,cv2,imquality,imquality.brisque,lpips,mixsimulator.*,networkx.*,cdt.*,pymoo,pymoo.*,bayes_optim.*,olympus.*,pymoo,pymoo.*,pybullet,pybullet_envs,pybulletgym,pyvirtualdisplay,nlopt,aquacrop.*,gomea,autograd,ceviche-challenges]\nignore_missing_imports = True\n\n[mypy-nevergrad.functions.rl.*,torchvision,torchvision.*,nevergrad.functions.games.*,nevergrad.functions.multiobjective.pyhv,nevergrad.optimization.test_doc,nevergrad.functions.gym.multigym,nevergrad.functions.gym.tuple_gym_env,nevergrad.common.sphere,nevergrad.examples.*]\nignore_missing_imports = True\nignore_errors = True\n\n[mypy-torch.*,torch.nn.*,autograd,ceviche-challenges]\nfollow_imports = skip\nfollow_imports_for_stubs = True\ndisallow_subclassing_any = True\n"
        },
        {
          "name": "nevergrad",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.201171875,
          "content": "[tool.black]\nline-length = 110\nexclude = '''\n(\n  /(\n      .eggs         # exclude a few common directories in the\n    | .git          # root of the project\n    | .mypy_cache\n    | dist\n    | docs\n  )\n)\n'''\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.037109375,
          "content": "#!/usr/bin/env python\n# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport os\nimport re\nimport sys\nimport typing as tp\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\nfrom setuptools.command.install import install\n\n\n# read requirements\n\nrequirements: tp.Dict[str, tp.List[str]] = {}\nfor extra in [\"dev\", \"bench\", \"main\"]:\n    requirements[extra] = Path(f\"requirements/{extra}.txt\").read_text().splitlines()\n\n\n# build long description\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as fh:\n    long_description = fh.read()\n\n# find version\n\ninit_str = Path(\"nevergrad/__init__.py\").read_text()\nmatch = re.search(r\"^__version__ = \\\"(?P<version>[\\w\\.]+?)\\\"$\", init_str, re.MULTILINE)\nassert match is not None, \"Could not find version in nevergrad/__init__.py\"\nversion = match.group(\"version\")\n\n\ndef _replace_relative_links(regex: tp.Match[str]) -> str:\n    \"\"\"Converts relative links into links to version\n    so that links on Pypi long description are correct\n    \"\"\"\n    string = regex.group()\n    link = regex.group(\"link\")\n    name = regex.group(\"name\")\n    if not link.startswith(\"http\") and Path(link).exists():\n        githuburl = (\n            f\"github.com/facebookresearch/nevergrad/blob/{version}\"\n            if not link.endswith((\".png\", \".gif\"))\n            else f\"raw.githubusercontent.com/facebookresearch/nevergrad/{version}\"\n        )\n        string = f\"[{name}](https://{githuburl}/{link})\"\n    return string\n\n\npattern = re.compile(r\"\\[(?P<name>.+?)\\]\\((?P<link>\\S+?)\\)\")\nlong_description = re.sub(pattern, _replace_relative_links, long_description)\n\n\nclass VerifyCircleCiVersionCommand(install):  # type: ignore\n    \"\"\"Custom command to verify that the git tag matches CircleCI version\"\"\"\n\n    description = \"verify that the git tag matches CircleCI version\"\n\n    def run(self) -> None:\n        tag = os.getenv(\"CIRCLE_TAG\")\n        if tag != version:\n            info = f\"Git tag: {tag} does not match the version of this app: {version}\"\n            sys.exit(info)\n\n\n# setup\nsetup(\n    name=\"nevergrad\",\n    version=version,\n    license=\"MIT\",\n    description=\"A Python toolbox for performing gradient-free optimization\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    author=\"Facebook AI Research\",\n    url=\"https://github.com/facebookresearch/nevergrad\",\n    packages=find_packages(),\n    classifiers=[\n        \"License :: OSI Approved :: MIT License\",\n        \"Intended Audience :: Science/Research\",\n        \"Topic :: Scientific/Engineering\",\n        \"Programming Language :: Python\",\n    ],\n    install_requires=requirements[\"main\"],\n    extras_require={\n        \"all\": requirements[\"dev\"] + requirements[\"bench\"],\n        \"dev\": requirements[\"dev\"],\n        \"benchmark\": requirements[\"bench\"],\n    },\n    package_data={\"nevergrad\": [\"py.typed\", \"*.csv\", \"*.py\"]},\n    python_requires=\">=3.6\",\n    cmdclass={\"verify_circleci_version\": VerifyCircleCiVersionCommand},\n)\n"
        }
      ]
    }
  ]
}