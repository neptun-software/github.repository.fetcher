{
  "metadata": {
    "timestamp": 1736559944246,
    "page": 717,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjcyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ploomber/ploomber",
      "stars": 3535,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.4580078125,
          "content": "[run]\n# note that we omit using a path to src/ploomber/ because the pkg gets installed\n# and then tests are executed (which causes ploomber to be inside the\n# site-packages folder), alternatively, we could install inplace using\n# pip install --editable but that's gonna make the testing process unable\n# to detect erros in the configuration package data configuration\nomit =\n    # .py files here are task template, not actual source files\n    */resources/ploomber_add/*"
        },
        {
          "name": ".githooks",
          "type": "tree",
          "content": null
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.3671875,
          "content": "doc/_build\ndoc/api/_modules\nprojects-tmp/\n*.sublime-project\n*.sublime-workspace\n*.txt\n*.metadata\n*.parquet\nexamples/pipeline/results/\nploomber-venv\ndoc/**/*.ipynb\n.pytest_cache/\n.vscode/\n.idea/\n\n#### joe made this: https://goel.io/joe\n\n#####=== IPythonNotebook ===#####\n# Temporary data\n.ipynb_checkpoints/\n\n#####=== Python ===#####\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\n\n# add env/ module\n!src/ploomber/env/\n!tests/env/\n\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage*\n.cache\nnosetests.xml\ncoverage.xml\nout.html\nout.ipynb\nout.pdf\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n#####=== OSX ===#####\n.DS_Store\n.AppleDouble\n.LSOverride\n\n# Icon must end with two \\r\nIcon\n\n# Thumbnails\n._*\n\n# Files that might appear on external disk\n.Spotlight-V100\n.Trashes\n\n# Directories potentially created on remote AFP share\n.AppleDB\n.AppleDesktop\nNetwork Trash Folder\nTemporary Items\n.apdisk\n"
        },
        {
          "name": "ARCHITECTURE.md",
          "type": "blob",
          "size": 5.8876953125,
          "content": "# Architecture\n\nThis document contains a high-level description of Ploomber's codebase.\n\nThe three core elements in Ploomber are `DAG`, `Task`, and `Product`.\n`DAGs` are a collection of `Tasks`, and `Tasks` produce `Products`.\n\n# DAG\n\nThe `DAG` impementation is in `src/ploomber/dag/dag.py`. A `DAG` is a\nmapping-like object that contains tasks and relationships among them.\n\nDAG is used to manage the status of tasks; for example, if a tasks's source\ncode hasn't changed since the last execution, `DAG` marks such task as `skipped` and is not executed\nagain if the source doesn't change. Status resolution happens during a rendering\nstep (`DAG.render()`), which runs before building the DAG.\n\nIt also manages hooks (e.g., `on_finish`, `on_failure`), which are functions\nthat execute after running a task.\n\n# Task\n\nA task is a unit of work. The abstract class is in `src/ploomber/tasks/abc.py`,\nall concrete classes (e.g., `PythonCallable`, `NotebookRunner`) are subclasses\nof the abstract class.\n\nTasks implement a `Task.render` step, which `DAG.render` calls. Implementation\ndetails vary depending on each case, but this is where the task prepares for\nexecution. For example, in SQL tasks, this is where jinja placeholders resolve\nto their actual values.\n\nWhen calling `DAG.build`, `Task.build` executes, and the task status determines\nwhether to run the task or not.\n\n# Product\n\nProducts are persistent objects (i.e., files or SQL tables/views) generated\nfrom task execution. The abstract class is in\n`src/ploomber/products/product.py`, all concrete classes\n(e.g., `File`, and `SQLRelation`) are subclasses of the abstract class.\n\nA Product is an object initialized with an identifier (e.g., `File` initializes\nwith a path to a file, `SQLRelation` with a `(name, schema, kind)` tuple), such\nthe identifier is passed to the `Task` when executing it so the user calls\nthe appropriate logic to save any files or SQL tables/views.\n\nTo determine `Task` status, `Products` store `Metadata` (a JSON string) with\nthe task's source code and execution time. The `Metadata` needs\na storage backend, which depends on the `Product` implementation. `File` stores\nmetadata in a file (e.g., `/path/data.csv` stores metadata in\n`/path/.data.csv.metadata`). However, SQL tasks need another backend.\n`PostgresRelation` uses table comments but to avoid implementing one metadata\nbackend for each database engine, there's a generic backend that stores\nmetadata in a `SQLite` database. Alternatively, SQL Products can skip saving\nmetadata, but they lose incremental builds.\n\nTasks may generate more than one product. `MetaProduct`\n(`src/ploomber/products/metaproduct.py`) implements a Product-like interface\nthat can hold more than one Product. This way, `Task` can interact with it\nas if it was a single product.\n\n# Source\n\nSources are objects that represent source code. Users do not interact with\nthe directly. They expose a common API defined via an abstract class\n(`src/ploombers/sources/abc.py`) that allows Tasks to show useful information\nto users such as source code file location, and the source code string.\nOptionally, they implement verification logic to detect errors during\n`DAG.render`, that otherwise would be raised until `DAG.build`. There are two\nnotable cases to highlight: `PythonCallableSource`, and `NotebookSource`.\n\n`PythonCallable` uses `PythonCallableSource` to hold Python functions. It\nallows to extract information from the function *without loading it*. This is\nnecessary in cases where we want to extract some information from a DAG but\nthe running process cannot should not load certain functions because doing\nso would yield `ModuleNotFoundError`, this scenario happens when loading\nDAGs in the Jupyter plug-in for cell injection. The Jupyter process does not\nnecessarily have all packages installed to run a DAG but it should still\nextract the location of the source code.\n\nOn the other hand, `NotebookRunner` uses `NotebookSource`, which implements\nthe cell injection process, notebook validation (ensure there is cell\ntagged `parameters` with an `upstream` variable), verifying kernelspec data,\nand exporting the notebook as a string with Python code, which allows us to\nuse pdb in a terminal to debug a notebook.\n\n# Metadata\n\nProducts define the Metadata storage backend, but the in-memory representation\nis the same and described in `src/ploomber/products/metadata.py`. `Metadata`\ntakes care of managing metadata's life cycle, ensuring that all tasks have\nthe most recent metadata version at all times.\n\n# Executors\n\n`DAG` orchestrate execution, but they *do not* run tasks, `Executors` do. An\n`Executor` is an object that receives a rendered `DAG` and calls `Task.build`\non each task. `Executors` may run tasks in child processes, so they must\nensure that status of the original `Task` object is updated; they also\nprovide other features such as capturing tracebacks and displaying them at the\nend. There are currently two executors, `Serial`, and `Parallel`.\n\n# Clients\n\nClients communicate `Tasks` and `Products` with external systems. However,\ndepending on the client, the purpose is different. For example, SQL clients\ncommunicate a SQL Task with a database to execute a script. But another\nSQL client communicates a SQL Product with a database to store the metadata.\nThe SQL client in a Task and Product may or may not be the same. File clients\nwork differently; they allow files to upload to remote storage such\nas Amazon S3 or Google Cloud Storage. The abstract class is defined in\n`src/ploomber/clients/client.py`.\n\n# DAGSpec / TaskSpec\n\n`DAGSpec` and `TaskSpec` convert dictionaries into `DAG` and `Task` objects\nrespectively, and are used to parse a `pipeline.yaml` file. Both are\nimplemented in the `src/ploomber/spec/` module. They implement the\nheavy lifting to make the *Spec API* work with as little code as\npossible: infer which Task and Product class to use depending on the user's\nvalues, initialize `env.yaml`, resolve upstream dependencies by analyzing\ntask's source code, among others.\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 40.462890625,
          "content": "# CHANGELOG\n\n## 0.23.4dev\n\n## 0.23.3 (2024-09-18)\n\n* [Feature] Removes telemetry\n\n## 0.23.2 (2024-02-07)\n\n* [Feature] Adds `ploomber-extension` as a dependency\n\n## 0.23.1 (2023-11-29)\n\n* [Fix] Fix compatibility with `jupyter_server==2.11.0` (by [@marr75](https://github.com/marr75))\n\n## 0.23.0 (2023-08-30)\n\n* [API Change] Deprecated `ploomber cloud`\n\n## 0.22.6 (2023-08-02)\n\n* [Feature] Add `mermaid` backend to `ploomber plot` (by [@TomArm](https://github.com/TomArm))\n* [Fix] Fixes incompatibility in `ploomber install` when using an old version of `ploomber-core`\n\n## 0.22.5 (2023-07-27)\n\n* [Feature] Deprecates `ploomber cloud`\n* [Fix] Compatibility with mistune 3\n* [Fix] Compatibility with pydantic V2\n\n## 0.22.4 (2023-06-01)\n\n* [Feature] Add `executor` option to NotebookRunner to choose ploomber-engine or papermill\n* [Fix] Fix error in `ScriptRunner` that didn't allow to import modules in script's directory ([#1072](https://github.com/ploomber/ploomber/issues/1072))\n\n## 0.22.3 (2023-04-13)\n\n* [Fix] Clearer error messages when generating pipeline plots\n* [Fix] Fix error when choosing which backend plot to use (when user didn't expicitly requested one)\n* [Fix] Fixed local execution error when using Scriptrunner\n\n## 0.22.2 (2023-01-30)\n\n* [Fix] Fixes error that printed a git error message when failing to retrieve current git hash ([#1067](https://github.com/ploomber/ploomber/issues/1067))\n\n## 0.22.1 (2023-01-28)\n\n* [Fix] Pinning `jupyter_client<8` due to breaking change\n\n## 0.22.0 (2023-01-13)\n\n* [API Change] Deprecates `.develop()` method in Notebook Function tasks\n* [API Change] Deprecates the following `ploomber cloud` commands: `get-pipelines`, `write-pipeline`, and `delete-pipeline`\n\n## 0.21.9 (2023-01-04)\n\n* Fixes error that caused `ploomber nb --inject` to fail in pipelines that had function tasks ([#1056](https://github.com/ploomber/ploomber/issues/1056))\n\n## 0.21.8 (2022-12-27)\n\n* Adds environment variable expansion via `{{env.ENV_VAR_NAME}}` ([#1042](https://github.com/ploomber/ploomber/issues/1042))\n* Adds support for including extra files when using `ploomber cloud nb` via the `include` section\n\n## 0.21.7 (2022-11-09)\n\n* Option to prioritize cell injection via `setup.cfg` when the same notebook appears more than once in the pipeline ([#1019](https://github.com/ploomber/ploomber/issues/1019))\n\n## 0.21.6 (2022-11-06)\n\n* Adds `--summary` to `ploomber cloud status`\n* Adds `--summary` to `ploomber cloud download`\n* Clearer output when deleting cloud products\n* Improved error message when missing product key ([#1027](https://github.com/ploomber/ploomber/issues/1027))\n\n## 0.21.5 (2022-10-31)\n\n* `ploomber build --partially` doesn't create a `DAG` deep copy\n* Deep copying DAG does not copy the clients\n* Fixes error in `ploomber cloud download` when the metadata for a product is missing\n\n## 0.21.4 (2022-10-27)\n\n* General `ploomber cloud` CLI improvements\n* General `ploomber cloud nb` accepts URL as argument\n\n## 0.21.3 (2022-10-24)\n\n* Fix to internal Cloud CLI\n\n## 0.21.2 (2022-10-21)\n\n* Adds `ploomber cloud nb` command\n* Allows setting `null` in `pipeline.yaml` clients ([#1025](https://github.com/ploomber/ploomber/issues/1025))\n* Wrapping text in D3 plot for tasks with long names ([#968](https://github.com/ploomber/ploomber/issues/968))\n* Merge `env.yaml` nested keys when using `import_from` ([#1034](https://github.com/ploomber/ploomber/issues/1034))\n\n## 0.21.1 (2022-10-02)\n\n* Adds `ploomber cloud task` command\n* `ploomber cloud` can take the `[@latest](https://github.com/latest)` argument in the `abort`, `log` and `status` commands\n* Adds conda support to `ploomber cloud build` via `environment.lock.yml`\n* Adds feature to select which parameters to install if the same source appears more than once ([#985](https://github.com/ploomber/ploomber/issues/985))\n* Fixes an error when pairing notebooks ([#979](https://github.com/ploomber/ploomber/issues/979))\n* Fixes error in `ploomber cloud download` command ([#1010](https://github.com/ploomber/ploomber/issues/1010))\n* Remove `parameters` cell missing exception and add `parameters` cell in `NotebookRunner` and `ScriptRunner` when it is missing ([#971](https://github.com/ploomber/ploomber/issues/971))\n* `setup.cfg` allows to set which task params to inject using `inject-priority` ([#902](https://github.com/ploomber/ploomber/issues/902))\n\n## 0.21 (2022-08-22)\n\n* Adds `ploomber.micro` module for writing micro pipelines\n* Allow dotted paths in params ([#477](https://github.com/ploomber/ploomber/issues/477))\n* Adds progress bar to `Parallel` executor\n* Allows to switch method when using `Parallel` executor ([#957](https://github.com/ploomber/ploomber/issues/957))\n* Clean traceback when using ploomber task ([#889](https://github.com/ploomber/ploomber/issues/889))\n* `grid` requires strict dotted path format (`a.b::c`)\n* Raise errors on wrong type or empty returned value for dotted paths in `params` and `grid`\n* Compatibility with papermill `2.4.0`\n* Compatibility with IPython `8` ([#978](https://github.com/ploomber/ploomber/issues/978))\n* Python API allows to execute notebooks without a parameters cell ([#971](https://github.com/ploomber/ploomber/issues/971))\n* Compatible with nbconvert `7`\n* Compatibility with mistune `0.8.x` and `2.x`\n* Adds deprecation warning to `NotebookRunner.develop()` and `PythonCallable.develop()`\n\n## 0.20 (2022-08-04)\n\n*Note: Ploomber 0.20 dropped support for Python 3.6 ([#876](https://github.com/ploomber/ploomber/issues/876))*\n\n* Adds support to serialize the traceback for later post-mortem debugging: `ploomber build --debuglater` and `ploomber task {name} --debuglater`\n* Support for notebook post-mortem debugging: `ploomber build --debug` `ploomber task {name} --debug` ([#823](https://github.com/ploomber/ploomber/issues/823))\n* `env.yaml` allows to use existing keys in subsequent values\n* Add `start_method` to Parallel executor to set the method which should be used to start child processes ([#942](https://github.com/ploomber/ploomber/issues/942))\n* Clearing screen before updating execution status when using the `Parallel` executor\n* Fixes missing plot when generating `ploomber report` with `--backend d3` ([#946](https://github.com/ploomber/ploomber/issues/946))\n* Fixes error when using dotted paths in `grid` ([#951](https://github.com/ploomber/ploomber/issues/951))\n\n## 0.19.9 (2022-07-26)\n\n*Note: this is the latest version compatible with Python 3.6*\n\n* Adds warning notice when running on Python 3.6\n* Add `--backend` to `ploomber report` to choose plotting backend ([#904](https://github.com/ploomber/ploomber/issues/904))\n* Add *did you mean?* feature to `ploomber examples` ([#805](https://github.com/ploomber/ploomber/issues/805))\n\n## 0.19.8 (2022-07-16)\n\n* Allow dotted paths in `pipeline.yaml` `grid` parameters ([#804](https://github.com/ploomber/ploomber/issues/804))\n* Templating task names when using `grid` via `[[placeholders]]` ([#698](https://github.com/ploomber/ploomber/issues/698))\n* Improved performance when loading the DAG in the Jupyter plugin ([#894](https://github.com/ploomber/ploomber/issues/894))\n\n## 0.19.7 (2022-07-04)\n\n* Suppressing \"black is not installed\" message ([#831](https://github.com/ploomber/ploomber/issues/831))\n\n* Better error message in `ploomber cloud build` when pipeline is up-to-date ([#815](https://github.com/ploomber/ploomber/issues/815))\n\n* Error message when `env.yml` found instead of `env.yaml` ([#829](https://github.com/ploomber/ploomber/issues/829))\n\n* Fixes jinja extractor when upstream had nested getitem ([#859](https://github.com/ploomber/ploomber/issues/859))\n\n* Fixes notebook loading on Windows when UTF-8 is not the default encoding ([#870](https://github.com/ploomber/ploomber/issues/870))\n\n* Remove extraneous output in `ploomber task` tracebacks ([#828]https://github.com/ploomber/ploomber/issues/828)\n\n## 0.19.6 (2022-06-02)\n\n* `setup.cfg` allows to switch default entry point\n* Generate multiple notebook products from a single task ([#708](https://github.com/ploomber/ploomber/issues/708))\n* `NotebookRunner` uploads partially executed notebook if it fails and a client is configured\n\n## 0.19.5 (2022-05-30)\n\n* Adds support for choosing environment in `cloud.yaml`\n\n## 0.19.4 (2022-05-21)\n\n* Fixes error when running `python -m ploomber.onboard` on Linux\n* Moving email prompt to onboarding tutorial ([#800](https://github.com/ploomber/ploomber/issues/800))\n\n## 0.19.3 (2022-05-20)\n\n* Adds onboarding command: `python -m ploomber.onboard`\n* Updating `pipeline.yaml` if `ploomnber nb --format {fmt}` command changes extensions ([#755](https://github.com/ploomber/ploomber/issues/755))\n\n## 0.19.2 (2022-05-17)\n\n* Adds documentation for `pipeline.yaml` `meta` section\n* Adds many inline examples\n* Improved docs for `pipeline.yaml` `grid`\n* `ploomber task` prints a confirmation message upon successful execution\n* `DAG.close_clients()` only calls `.close()` on each client once\n* Fixes `dag.plot()` error when dag needs rendering\n\n## 0.19.1 (2022-05-14)\n\n* Fixes incompatibility with nbconvert 5 ([#741](https://github.com/ploomber/ploomber/issues/741))\n* Improved error messages when the network fails while hitting the cloud build API\n* Hiding posthog error logs ([#744](https://github.com/ploomber/ploomber/issues/744))\n\n## 0.19 (2022-05-07)\n\n* `ploomber plot` uses D3 backend if `pygraphviz` is not installed\n* Request email (optional) after running `ploomber examples` for the first time\n* Changes to `ploomber cloud`\n\n## 0.18.1 (2022-04-22)\n\n* Compatibility with click `7.x` and `8.x` ([#719](https://github.com/ploomber/ploomber/issues/719))\n* Deprecates casting for boolean `static_analysis` flag ([#586](https://github.com/ploomber/ploomber/issues/586))\n\n## 0.18 (2022-04-16)\n\n* Support for `env.yaml` composition via `meta.import_from` ([#679](https://github.com/ploomber/ploomber/issues/679))\n* Support for `webpdf` for notebook conversion ([#675](https://github.com/ploomber/ploomber/issues/675))\n* SQLAlchemyClient accepts URL object in the constructor ([#699](https://github.com/ploomber/ploomber/issues/699))\n* Better error message when product has an incorrect extension ([#472](https://github.com/ploomber/ploomber/issues/472))\n* Better error when `pipeline.yaml` in root directory `/` ([#497](https://github.com/ploomber/ploomber/issues/497))\n* Better error message when `NotebookRunner` initialized with a `str` ([#705](https://github.com/ploomber/ploomber/issues/705))\n* Error message when missing placeholder in `env.yaml` includes path to offending file\n* Fixes error when expanding complex args in `env.yaml` ([#709](https://github.com/ploomber/ploomber/issues/709))\n* Validating object returned by `import_tasks_from` ([#686](https://github.com/ploomber/ploomber/issues/686))\n\n## 0.17.2 (2022-03-31)\n\n* [FEATURE] Custom name for products generated by `grid` tasks ([#647](https://github.com/ploomber/ploomber/issues/647))\n* [FEATURE] Execute notebooks/scripts without generating and output notebook via `ScriptRunner` ([#614](https://github.com/ploomber/ploomber/issues/614))\n* [FEATURE] more robust \"Did you mean?\" suggestions for product and task classes typos in `pipeline.yaml`\n* [BUGFIX] `ploomber nb --remove` works with `.ipynb` files ([#692](https://github.com/ploomber/ploomber/issues/692))\n* [BUGFIX]  Use `grid` and `params` in `pipeline.yaml` ([#522](https://github.com/ploomber/ploomber/issues/522))\n* [DOC] Adds versioning user guide\n* [DOC] Adds cloud user guide\n\n## 0.17.1 (2022-03-26)\n\n* Better error message when failing to deepcopy a DAG ([#670](https://github.com/ploomber/ploomber/issues/670))\n* Improvements to the `{{git}}` placeholder feature ([#667](https://github.com/ploomber/ploomber/issues/667))\n* Replaces DAG colors in `ploomber plot` with their RGB values for better compatibility\n* Pinning `jinja2` to prevent `nbconvert` from failing\n\n## 0.17 (2022-03-19)\n\n* Style improvements to DAG plot ([#650](https://github.com/ploomber/ploomber/issues/650))\n* DAG plot only includes task names by default ([#393](https://github.com/ploomber/ploomber/issues/393))\n* `ploomber plot --include-products/-p` generates plots with task names and products\n* `DAG.plot(include_products=True)` generates plots with task names and products\n* Fixes error when replacing file on Windows ([#333](https://github.com/ploomber/ploomber/issues/333))\n* Fixes error message when config file does not exist ([#652](https://github.com/ploomber/ploomber/issues/652))\n* Fixes typo in nb command ([#665](https://github.com/ploomber/ploomber/issues/665))\n\n## 0.16.4 (2022-03-11)\n\n* Using UTF-8 for reading and writing in notebook tasks ([#334](https://github.com/ploomber/ploomber/issues/334))\n\n## 0.16.3 (2022-03-06)\n\n* Clearer error message when DAG deepcopy fails\n* Beta release of cloud pipeline monitoring\n* More robust suggestions when invoking a non-existing command\n* CLI loading performance improvements\n* Prints message before starting to load the pipeline for better user feedback\n* Displaying community link when DAG fails to render or build\n\n## 0.16.2 (2022-03-03)\n\n* Improved documentation in \"ploomber nb --help\" ([#623](https://github.com/ploomber/ploomber/issues/623))\n* Fixed a few errors in the basic concepts tutorial\n* More informative error when task does not generate some products\n* Better error when all the code is in the parameters cell\n\n## 0.16.1 (2022-02-27)\n\n* Improves error message when `source` in a task spec is a string without an extension ([#619](https://github.com/ploomber/ploomber/issues/619))\n* Fixes error that caused `dag.render(force=True)` to download remote metadata\n* Simplify traceback when calling Ploomber task ([#605](https://github.com/ploomber/ploomber/issues/605))\n* Emitting warning when `resources_` points to large files ([#609](https://github.com/ploomber/ploomber/issues/609))\n* Adds auto-completion steps to documentation ([#612](https://github.com/ploomber/ploomber/issues/612))\n* Updates documentation to reflect new default format (`py:percent`) ([#564](https://github.com/ploomber/ploomber/issues/564))\n* Showing a mesage when a new version of Ploomber is available ([#558](https://github.com/ploomber/ploomber/issues/558))\n\n## 0.16 (2022-02-17)\n\n* Cleaner tracebacks when DAG fails to build or render\n* Automatically adding a parameters cell to scripts and notebooks if it's missing\n* `NotebookRunner` `static_analysis` behaves differently: it's less picky now, the old behavior default behavior can be turned on if passing `strict` , and can be turned off if passing `disable` ([#566](https://github.com/ploomber/ploomber/issues/566))\n* Improves many error messages for clarity\n* `ploomber install` installs dependencies in the current virtual environment by default\n* `ploomber install` works in systems where `python` links to Python 2.7 ([#435](https://github.com/ploomber/ploomber/issues/435))\n* `ploomber install` uses lock files by default if they exist\n* `ploomber install` has options to customize its behavior\n* `ploomber scaffold` accepts one positional argument ([#484](https://github.com/ploomber/ploomber/issues/484))\n* Fixes an issue that caused `ploomber nb` to hide traceback when failed to load pipeline ([#468](https://github.com/ploomber/ploomber/issues/468))\n\n## 0.15.3 (2022-02-13)\n\n* Fixed error when parsing cell magics with inline python\n\n## 0.15.2 (2022-02-11)\n\n* Fixed misspelling in `pygraphviz` error message ([#575](https://github.com/ploomber/ploomber/issues/575))\n\n## 0.15.1 (2022-02-08)\n\n* Sets minimum networkx version ([#536](https://github.com/ploomber/ploomber/issues/536))\n* Updates documentation links to the new domain ([#549](https://github.com/ploomber/ploomber/issues/549))\n* Suggests adding the appropriate `pygraphviz` version depending on the Python version ([#539](https://github.com/ploomber/ploomber/issues/539))\n* Improved error message when `pipeline.yaml` does not exist ([#517](https://github.com/ploomber/ploomber/issues/517))\n* Fixes error when scaffolding functions\n\n## 0.15 (2022-02-03)\n\n* Adds SQL runtime parameters\n* `SQLScript` and `SQLDump` display source code when `client.execute` fails\n* Clearer error message when `NotebookRunner` fails to initialize\n* `cli_endpoint` decorator hides traceback when raising `BaseException` errors\n* `DAGSpec` and `TaskSpec` errors raised as `DAGSpecInitializationError`\n* Less verbose `ploomber examples` output\n\n## 0.14.8 (2022-01-29)\n\n* Better user feedback after running `ploomber nb --inject`\n* Fixed `ploomber nb --inject` when `pipeline.yaml` has `.ipynb` files\n\n## 0.14.7 (2022-01-25)\n\n* Adds `ploomber nb --single-click/--single-click-disable` to enable/disable opening `.py` as notebooks with a click on Jupyter\n* `ploomber nb` no longer requires a valid entry point if the selected option doesn't need one\n* Better error message when `Pool` in the `Serial` executor raises `RuntimeError`\n* Notebook static analysis: Better support for IPython magics, support for inline shell (`! echo hi`). closes [#478](https://github.com/ploomber/ploomber/issues/478)\n\n## 0.14.6 (2022-01-20)\n\n* Documents `S3Client` and `GCloudStorageClient`\n* Updates to the telemetry module\n\n## 0.14.5 (2022-01-15)\n\n* Fixes error message when failing to load dotted paths\n* `ploomber scaffold` now supports `.R and .Rmd` files ([#476](https://github.com/ploomber/ploomber/issues/476))\n* Fixes an error that caused `ploomber scaffold` to ignore the location of existing packages ([#459](https://github.com/ploomber/ploomber/issues/459))\n* Better error message when running `ploomber execute/run` (suggests `ploomber build`)\n* Better error message when passing positional arguments to `ploomber build` (suggests `ploomber task`)\n\n## 0.14.4 (2022-01-07)\n\n* Fixes an error in the telemetry module\n\n## 0.14.3 (2022-01-06)\n\n* Improved [anonymous user statistics](https://docs.ploomber.io/en/latest/community/user-stats.html)\n\n## 0.14.2 (2022-01-03)\n\n* `PLOOMBER_STATS_ENABLED` environment variable can be used to disable stats\n* Improved error message when a dotted path fails to load ([#410](https://github.com/ploomber/ploomber/issues/410))\n\n## 0.14.1 (2022-01-02)\n\n* `ploomber scaffold` creates missing modules when adding functions ([#332](https://github.com/ploomber/ploomber/issues/332), [@fferegrino](https://github.com/fferegrino))\n* `NotebookRunner` creates product's parent directories before running ([#460](https://github.com/ploomber/ploomber/issues/460))\n\n## 0.14 (2021-12-25)\n\n* Adds `ploomber nb` command for integration with VSCode, PyCharm, Spyder, etc.\n* Adds methods for saving and removing injected cells to `NotebookSource`\n* Adds methods for pairing and syncing to `NotebookSource`\n* Fixes [#448](https://github.com/ploomber/ploomber/issues/448): `SQLUpload` ignoring `io_handler`\n* Fixes [#447](https://github.com/ploomber/ploomber/issues/447): `pipeline.yaml` supports passing custom init parameters to `executor`\n* Adds optional [anonymous user statistics](https://docs.ploomber.io/en/latest/community/user-stats.html)\n\n## 0.13.7 (2021-12-18)\n\n* Fixes `{{root}}` expansion when path_to_here is different than the current working directory\n* Better error message when initializing `MetaProduct` with non-products\n* Adds refactoring section (`soorgeon`) to the user guide\n* Adds shell scripts user guide\n* `Commander` allows `jinja2.Environment` customization\n\n## 0.13.6 (2021-11-17)\n\n* `GenericSource` supports extracting upstream\n\n## 0.13.5 (2021-10-27)\n\n* Fixes an error that caused `copy.deepcopy` to fail on `SourceLoader`\n\n## 0.13.4 (2021-10-25)\n\n* Adds `{{now}}` (current timestamp in ISO 8601 format) to default placeholders\n* Adds `--output/-o` to `ploomber examples` to change output directory\n\n## 0.13.3 (2021-10-15)\n\n* Adds `--log-file/-F` option to CLI to log to a file\n* Clearer error message when a task in a `pipeline.yaml` has `grid` and `params`\n* Right bar highlighting fixed\n* `normalize_python` returns input if passed non-Python code\n* Better error message when requesting an unknown example in `ploomber examples`\n* Better error message when `ploomber examples` fails due to an unexpected error\n* Fixes an error in `ploomber examples` that caused the `--branch/-b` argument to be ignored\n\n## 0.13.2 (2021-10-09)\n\n* Adds support for using `grid` and task-level hooks in spec API\n\n## 0.13.1 (2021-10-08)\n\n* Allow serialization of a subset of params ([#338](https://github.com/ploomber/ploomber/issues/338))\n* NotebookRunner `static_analysis` turned on by default\n* NotebookRunner `static_analysis` ignores IPython magics\n* Improved error message when NotebookRunner `static_analysis` fails\n* Support for collections in `env.yaml`\n* Adds `unpack` argument to `serializer`/`unserializer` decorators to allow a variable number of outputs\n* General CSS documentation improvements\n* Mobile-friendly docs\n* Add table explaining each documentation section\n* Adds hooks, serialization, debugging, logging, and parametrization cookbook\n* Adds FAQ on tasks with a variable number of outputs\n* Auto-documenting methods/attributes for classes in the Python API section\n* Documents `io` module\n\n## 0.13 (2021-09-22)\n\n* Refactors scripts/notebooks `static_analysis` feature\n* Shows warning if using default value in scripts/notebooks `static_analysis` parameter\n* Better error message when `DAG` has duplicated task names\n* Adds more info to the files generated by ploomber scaffold\n* Better error when trying to initialize a task from a path with an unknown extension\n\n## 0.12.8 (2021-09-08)\n\n* Support for dag-level hooks in Spec API\n* Better error message when invalid extension in `NotebookRunner` product\n* Fixes an error when loading nested templates on Windows\n\n## 0.12.7 (2021-09-03)\n\n* Task hooks (e.g., `on_finish`) accept custom args\n\n## 0.12.6 (2021-09-02)\n\n* Fixes look up of conda root when running `ploomber install` when conda binary is inside the `Library` directory (Windows)\n* No longer looking up pip inside conda when running `ploomber install` and `setup.py` does not exist\n* Adds `--use-lock/-l` option to `ploomber install` to install using lock files\n\n## 0.12.5 (2021-08-16)\n\n* Simplifies serializer and unserializer creation with new decorators\n* Adds guide on serializer/unserializer decorators to the documentation\n\n## 0.12.4 (2021-08-12)\n\n* Clearer error message when failing to import function\n* Better error message when `tasks` in YAML spec is not a list\n* Fixes an issue that caused dag plot to fail when using `.svg`\n* Fixes duplicated log entries when viewing a file in Jupyter\n\n## 0.12.3 (2021-08-03)\n\n* Fixes cell injection when using the `--notebook-dir` during Jupyter initialization\n* Reduces verbosity in Jupyter logs ([#314](https://github.com/ploomber/ploomber/issues/314))\n* Adds `tasks[*].params.resources_` to track changes in external files\n* Minor bug fixes\n\n## 0.12.2 (2021-07-26)\n\n* Lazy load for `serializer`, `unserialize`, DAG clients, Task clients, Product clients, and task hooks, which allows the Jupyter plugin to work even if the Jupyter process does not have the dependencies required to import such dotted paths\n* CLI `--help` message shows if `ENTRY_POINT` environment variable is defined\n* `ploomber scaffold` now takes a `-e/--entry-point` optional argument\n* Fixes error that caused the `{{here}}` placeholder not to work if an `env.yaml` exists\n* Adds `--empty` option to `ploomber scaffold` to create a `pipeline.yaml` with no tasks\n\n## 0.12.1 (2021-07-09)\n\n- Allowing `pipeline.yaml` at project root if setup.py but `src/*/pipeline.yaml` is missing\n- Fixes bug in `EnvDict.find` that caused the `{{here}}` placeholder to point to the `env.yaml` file instead of its parent\n- `DAGSpec._find_relative` returns relative path to spec\n- Fixes error that missed `env.yaml` loading when initializing DAGSpecPartial\n\n## 0.12 (2021-07-08)\n\n- Changes the logic that determines project root: only considers `pipeline.yaml` and `setup.py` (instead of `environment.yml` or `requirements.txt`)\n- Adds configuration and scaffold user guides\n- Updates Jupyter user guide\n- Deletes conda user guide\n- Renames internal modules for consistency (this should not impact end-users)\n- Fixes error that caused Files generated from TaskGroups in the spec API not to resolve to their absolute values\n- Fixes error that caused metadata not to delete on when saving files in Jupyter if using a source in more than one task\n- `DAGSpec` loads an `env.{name}.yaml` file when loading a `pipeline.{name}.yaml` if one exists\n- `ploomber plot` saves to `pipeline.{name}.png`\n- Override `env.yaml` to load using `PLOOMBER_ENV_FILENAME` environment variable\n- `EnvDict` init no longer searches recursively, moved that logic to `EnvDict.find`. `with_env` decorator now uses the latter to prevent breaking the API\n- `PostgresCopyFrom` compatible with `psycopg>=2.9`\n- `jupyter_hot_reload=True` by default\n- `PythonCallableSource` finds the location of a dotted path without importing any of the submodules\n- Jupyter integration lazily loads DAGs (no need to import callable tasks)\n- CLI no longer showing `env.yaml` parameters when initializing from directory or pattern\n\n## 0.11.1 (2021-06-08)\n\n- Task's `metadata.params` stores `null` if any parameter isn't serializable\n- Task status ignores `metadata.params` if they are `null`\n- Fixes unserialization when an upstream task produces a `MetaProduct`\n\n## 0.11 (2021-05-31)\n\n- Adds `remote` parameter to `DAG.render` to check status against remote storage\n- `NotebookSource` no longer includes the injected cell in its `str` representation\n- `Metadata` uses task params to determine task status\n- Support for wildcards when building dag partially\n- Support to skip upstream dependencies when building partially\n- Faster `File` remote metadata downloads using multi-threading during `DAG.render`\n- Faster upstream dependencies parallel download using multi-threading during `Task.build`\n- Suppresses papermill `FutureWarning` due to importing a deprecated `pyarrow` module\n- Fixes error that caused a warning due to unused env params when using `import_tasks_from`\n- Other bug fixes\n\n## 0.10.4 (2021-05-22)\n\n- `DAGSpec.find` exposes `starting_dir` parameter\n- `ploomber install` supports `pip`'s `requirements.txt` files\n- `ploomber install` supports non-packages (i.e., no `setup.py`)\n- `ploomber scaffold` flags to use conda (`--conda`) and create package (`--package`)\n\n## 0.10.3 (2021-05-17)\n\n- `ParamGrid` supports initialization from a list\n- Adds `tasks[*].grid` to generate multiple tasks at once\n- Support for using wildcards to declare dependencies (e.g., `task-*`)\n- Fixes to `ploomber scaffold` and `ploomber install`\n- `PythonCallable` creates parent directories before execution\n- Support for the parallel executor in Spec API\n- `DagSpec.find` exposes `lazy_import` argument\n- `TaskGroup` internal API changes\n\n## 0.10.2 (2021-05-05)\n\n- `GCloudStorageClient` loads credentials relative to the project root\n- Adds `ploomber install`\n- Adds `S3Client`\n\n## 0.10.1 (2021-04-17)\n\n- `DAGSpec` warns if parameter declared in env but unused\n- Implements `{SQLDump, NotebookRunner, PythonCallable}.load()`\n- `File.client` downloads during task execution instead of render\n- Adds `ploomber.OnlineModel`, which provides a simpler API than `OnlineDAG` for models that implement a `.predict()` method\n- Adds function to find package name if using standard layout\n\n## 0.10 (2021-03-13)\n\n- Changes `extract_product` default in spec API to False\n- Tasks get a default name equal to the filename without extension (e.g., plot.py -> plot)\n- `File` saves metadata in a `.{filename}.metadata` file instead of `{filename}.source`\n- Adds `ploomber examples` command\n- Adds Deployment guide to documentation\n- `EnvDict` loads `env.yaml` and uses values as defaults when passing a custom dict\n- Simpler repr for SQL products\n- Improved Spec API docs\n- Adds `ploomber.tasks.TaskGroup.from_params` to create multiple tasks at once\n\n## 0.9.5 (2021-03-07)\n\n- Changes a lot of error messages for clarity\n- Clearer `__repr__` for `Placeholder`, `File`, and `MetaProduct`\n- Default placeholders can be used in `pipeline.yaml` without defining `env.yaml`\n- Better formatting for displaying DAG build and render errors\n- Spec API initializes task spec as `SQLDump` if product has suffix `.csv` or `.parquet`\n- Coloring CLI error traceback\n- Spec API skips `SourceLoader` if passing an absolute path\n- `DAG.clients` validates keys (using `DAGClients`)\n- `params` available as hook argument\n- Rewritten Spec API documentation\n\n## 0.9.4 (2021-02-15)\n\n- Better display of errors when building or rendering a DAG (layout and colors)\n- `File` implements the `os.PathLike` interface (this works now: `pandas.read_parquet(File('file.parquet'))`)\n- Several error messages refactored for clarity\n- Adds `DAGSpec.find()` to automatically find `pipeline.yaml`\n\n## 0.9.3 (2021-02-13)\n\n- Adds `OnlineDAG` to convert `DAG` objects for in-memory inference\n- Spec API (`pipeline.yaml`) supports DAG-level and Task-level `serializer` and `serializer`\n- CLI looks for `src/{pkg}/pipeline.yaml` if `pipeline.yaml` doesn't exist\n- Adds `{{cwd}}` placeholder for `env.yaml` that expands to current working directory\n\n## 0.9.2 (2021-02-11)\n\n- Support for Python 3.9\n- `SQLAlchemyClient` now accepts an argument to pass custom parameters to `sqlalchemy.create_engine`\n- Temporarily pins papermill version due to an incompatibility with jupytext and nbformat (jupytext does not support cell ids yet)\n- Adds `--on-finish/-of` to `ploomber task` to execute the `on_finish` hook\n- DAGs with R notebooks can render even if the ir kernel is not installed\n\n## 0.9.1 (2021-02-01)\n\n- `File` now supports a `client` argument to upload products to cloud\n  storage\n- Adds `GCloudStorageClient`\n- Fixes error that caused jupyter to fail to initialize the dag when\n  adding a function to a module already included in the YAML spec\n- Fixes IPython namespace errors when using `ploomber interact`\n- Adds `ploomber.testing.sql.assert_no_duplicates_in_column` to check\n  for record duplicates and optionally show duplicates statistics\n- Deprecates a few internal methods: `Table.save`, `DAG.to_dict()`,\n  `Task.to_dict()`\n- Improvements to SQL static analyzer to warn when relations created\n  by a SQL script do not match `Product`\n- A few changes to `Metadata` (internal API) to cover some edge cases\n- Warning when `Product` metadata is corrupted\n- Adds new `meta.import_tasks_from` option in YAML specs to import\n  tasks from another file\n\n## 0.9 (2021-01-18)\n\n- Deprecates `ploomber new` and `ploomber add`\n- Adds `ploomber scaffold`\n- Jupyter plugin now exports functions as notebooks using\n  `jupyter_functions_as_notebooks` in `pipeline.yaml`\n\n## 0.8.6 (2021-01-08)\n\n- `ploomber add` generates template tasks and functions if they don't exist\n- Jupyter plugin now shows PythonCallable tasks as notebooks\n\n## 0.8.5 (2020-12-14)\n\n- Documentation tutorials re-organization and CSS fixes\n- Improvements to the `InMemoryDAG` API\n- Minor bug fixes\n- `File.__repr__` shows a relative path whenever possible\n\n## 0.8.4 (2020-11-21)\n\n- Adds support for passing glob-like patterns in `ploomber build` (via\n  `DAGSpec.from_directory`)\n\n## 0.8.3 (2020-11-15)\n\n- Full Windows compatibility\n- Adds documentation to show how to customize notebook output using\n  `nbconvert`\n- Improvements to introductory tutorials\n- Adds `--debug/-d` option to `ploomber build` to drop a debugger if\n  an exception happens\n- Ensuring all dag-level, task-level and product-level clients are\n  closed after `dag.build()` is done\n- Minor bug fixes\n\n## 0.8.2 (2020-10-31)\n\n- Removes `matplotlib` from dependencies, now using `IPython.display`\n  for inline plotting\n- Fixes bug that caused custom args to\n  `{PythonCallable, NotebookRunner}.develop(args\"--arg=value\")` not\n  to be sent correctly to the subprocess\n- `NotebookRunner` (initialized from ipynb) only considers the actual\n  code as its source, ignores the rest of the JSON contents\n- Fixes bug when `EnvDict` was initialized from another `EnvDict`\n- `PythonCallableSource` can be initialized with dotted paths\n- `DAGSpec` loads `env.yaml` when initialized with a YAML spec and\n  there is a `env.yaml` file in the spec parent folder\n- `DAGSpec` converts relative paths in sources to be so to the\n  project's root folder\n- Adds `lazy_import` to `DAGspec`, to avoid importing `PythonCallable`\n  sources (passes the dotted paths as strings instead)\n\n## 0.8.1 (2020-10-18)\n\n- `ploomber interact` allows to switch DAG parameters, just like\n  `ploomber build`\n- Adds `PythonCallable.develop()` to develop Python functions\n  interactively\n- `NotebookRunner.develop()` to develop now also works with Jupyter\n  lab\n\n## 0.8 (2020-10-15)\n\n- Dropping support for Python 3.5\n- Removes `DAGSpec.from_file`, loading from a file is now handled\n  directly by the `DAGSpec` constructor\n- Performance improvements, DAG does not fetch metadata when it doesn't need to\n- Factory functions: Bool parameters with default values are now\n  represented as flags when called from the CLI\n- CLI arguments to replace values from `env.yaml` are now\n  built with double hyphens instead of double underscores\n- `NotebookRunner` creates parent folders for output file if they don't exist\n- Bug fixes\n\n## 0.7.5 (2020-10-02)\n\n- NotebookRunner.develop accepts passing arguments to jupyter notebook\n- Spec API now supports PythonCallable (by passing a dotted path)\n- Upstream dependencies of PythonCallables can be inferred via the\n  `extract_upstream` option in the Spec API\n- Faster `DAG.render(force=True)` (avoid checking metadata when\n  possible)\n- Faster notebook rendering when using the extension thanks to the\n  improvement above\n- `data_frame_validator` improvement: `validate_schema` can now\n  validate optional columns dtypes\n- Bug fixes\n\n## 0.7.4 (2020-09-14)\n\n- Improved `__repr__` methods in PythonCallableSource and\n  NotebookSource\n- Improved output layout for tables\n- Support for nbconvert>=6\n- Docstrings are parsed from notebooks and displayed in DAG status table ([#242](https://github.com/ploomber/ploomber/issues/242))\n- Jupyter extension now works for DAGs defined via directories (via\n  `ENTRY_POINT` env variable)\n- Adds Jupyter integration guide to documentation\n- Several bug fixes\n\n## 0.7.3 (2020-08-19)\n\n- Improved support for R notebooks (`.Rmd`)\n- New section for `testing.sql` module in the documentation\n\n## 0.7.2 (2020-08-17)\n\n- New guides: parametrized pipelines, SQL templating, pipeline testing\n  and debugging\n- `NotebookRunner.debug(kind='pm')` for post-mortem debugging\n- Fixes bug in Jupyter extension when the pipeline has a task whose\n  source is not a file (e.g. SQLDump)\n- Fixes a bug in the CLI custom arg parser that caused dynamic params\n  not to show up\n- `DAGspec` now supports `SourceLoader`\n- Docstring (from dotted path entry point) is shown in the CLI summary\n- Customized sphinx build to execute guides from notebooks\n\n## 0.7.1 (2020-08-06)\n\n- Support for R\n- Adding section on R pipeline to the documentation\n- Construct pipeline from a directory (no need to write a\n  `pipeline.yaml` file)\n- Improved error messages when DAG fails to initialize (jupyter\n  notebook app)\n- Bug fixes\n- CLI accepts factory function parameters as positional arguments,\n  types are inferred using type hints, displayed when calling `--help`\n- CLI accepts env variables (if any), displayed when calling `--help`\n\n## 0.7 (2020-07-30)\n\n- Simplified CLI (breaking changes)\n- Refactors internal API for notebook conversion, adds tests for\n  common formats\n- Metadata is deleted when saving a script from the Jupyter notebook\n  app to make sure the task runs in the next pipeline build\n- SQLAlchemyClient now supports custom tokens to split source\n\n## 0.6.3 (2020-07-24)\n\n- Adding `--log` option to CLI commands\n- Fixes a bug that caused the `dag` variable not to be\n  exposed during interactive sessions\n- Fixes `ploomber task` forced run\n- Adds SQL pipeline tutorial to get started docs\n- Minor CSS changes to docs\n\n## 0.6.2 (2020-07-22)\n\n- Support for `env.yaml` in `pipeline.yaml`\n- Improved CLI. Adds `plot`, `report` and `task` commands`\n\n## 0.6.1 (2020-07-20)\n\n- Changes `pipeline.yaml` default (extract_product: True)\n- Documentation re-design\n- Simplified `ploomber new` generated files\n- Ability to define `product` in SQL scripts\n- Products are resolved to absolute paths to avoid ambiguity\n- Bug fixes\n\n## 0.6 (2020-07-08)\n\n- Adds Jupyter notebook extension to inject parameters when opening a\n  task\n- Improved CLI `ploomber new`, `ploomber add` and `ploomber entry`\n- Spec API documentation additions\n- Support for `on_finish`, `on_failure` and `on_render` hooks in spec API\n- Improved validation for DAG specs\n- Several bug fixes\n\n## 0.5.1 (2020-06-30)\n\n- Reduces the number of required dependencies\n- A new option in DBAPIClient to split source with a custom separator\n\n## 0.5 (2020-06-27)\n\n- Adds CLI\n- New spec API to instantiate DAGs using YAML files\n- NotebookRunner.debug() for debugging and .develop() for interacive\n  development\n- Bug fixes\n\n## 0.4.1 (2020-05-19)\n\n- PythonCallable.debug() now works in Jupyter notebooks\n\n## 0.4.0 (2020-05-18)\n\n- PythonCallable.debug() now uses IPython debugger by default\n- Improvements to Task.build() public API\n- Moves hook triggering logic to Task to simplify executors\n  implementation\n- Adds DAGBuildEarlyStop exception to signal DAG execution stop\n- New option in Serial executor to turn warnings and exceptions\n  capture off\n- Adds Product.prepare_metadata hook\n- Implements hot reload for notebooks and python callables\n- General clean ups for old `__str__` and `__repr__` in several modules\n- Refactored ploomber.sources module and ploomber.placeholders\n  (previously ploomber.templates)\n- Adds NotebookRunner.debug() and NotebookRunner.develop()\n- NotebookRunner: now has an option to run static analysis on render\n- Adds documentation for DAG-level hooks\n- Bug fixes\n\n## 0.3.5 (2020-05-03)\n\n- Bug fixes [#88](https://github.com/ploomber/ploomber/issues/88), [#89](https://github.com/ploomber/ploomber/issues/89), [#90](https://github.com/ploomber/ploomber/issues/90), [#84](https://github.com/ploomber/ploomber/issues/84), [#91](https://github.com/ploomber/ploomber/issues/91)\n- Modifies Env API: Env() is now Env.load(), Env.start() is now Env()\n- New advanced Env guide added to docs\n- Env can now be used with a context manager\n- Improved DAGConfigurator API\n- Deletes logger configuration in executors constructors, logging is\n  available via DAGConfigurator\n\n## 0.3.4 (2020-04-25)\n\n- Dependencies cleanup\n- Removed (numpydoc) as dependency, now optional\n- A few bug fixes: [#79](https://github.com/ploomber/ploomber/issues/79), [#71](https://github.com/ploomber/ploomber/issues/71)\n- All warnings are captured and shown at the end (Serial executor)\n- Moves differ parameter from DAG constructor to DAGConfigurator\n\n## 0.3.3 (2020-04-23)\n\n- Cleaned up some modules, deprecated some rarely used functionality\n- Improves documentation aimed to developers looking to extend\n  ploomber\n- Introduces DAGConfigurator for advanced DAG configuration\n  [Experimental API]\n- Adds task to upload files to S3 (ploomber.tasks.UploadToS3),\n  requires boto3\n- Adds DAG-level on_finish and on_failure hooks\n- Support for enabling logging in entry points (via `--logging`)\n- Support for starting an interactive session using entry points (via\n  python -i -m)\n- Improved support for database drivers that can only send one query\n  at a time\n- Improved repr for SQLAlchemyClient, shows URI (but hides password)\n- PythonCallable now validates signature against params at render time\n- Bug fixes\n\n## 0.3.2 (2020-04-07)\n\n- Faster Product status checking, now performed at rendering time\n- New products: GenericProduct and GenericSQLRelation for Products\n  that do not have a specific implementation (e.g. you can use Hive\n  with the DBAPI client + GenericSQLRelation)\n- Improved DAG build reports, subselect columns, transform to\n  pandas.DataFrame and dict\n- Parallel executor now returns build reports, just like the Serial\n  executor\n\n## 0.3.1 (2020-04-01)\n\n- DAG parallel executor\n- Interact with pipelines from the command line (entry module)\n- Bug fixes\n- Refactored access to Product.metadata\n\n## 0.3 (2020-03-20)\n\n- New Quickstart and User Guide section in documentation\n- DAG rendering and build now continue until no more tasks can\n  render/build (instead of failing at the first exception)\n- New `with_env` and `load_env` decorators for managing environments\n- Env expansion ({{user}} expands to the current, also {{git}} and\n  {{version}} available)\n- `Task.name` is now optional when Task is initialized with a source\n  that has `__name__` attribute (Python functions) or a name\n  attribute (like Placeholders returned from SourceLoader)\n- New Task.on_render hook\n- Bug fixes\n- A lot of new tests\n- Now compatible with Python 3.5 and higher\n\n## 0.2.1 (2020-02-20)\n\n- Adds integration with pdb via PythonCallable.debug\n- Env.start now accepts a filename to look for\n- Improvements to data_frame_validator\n\n## 0.2 (2020-02-13)\n\n- Simplifies installation\n- Deletes BashCommand, use ShellScript\n- More examples added\n- Refactored env module\n- Renames SQLStore to SourceLoader\n- Improvements to SQLStore\n- Improved documentation\n- Renamed PostgresCopy to PostgresCopyFrom\n- SQLUpload and PostgresCopy have now the same API\n- A few fixes to PostgresCopy ([#1](https://github.com/ploomber/ploomber/issues/1), [#2](https://github.com/ploomber/ploomber/issues/2))\n\n## 0.1\n\n- First release\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 7.5126953125,
          "content": "# Contributing to Ploomber\n\nThanks for considering contributing to Ploomber!\n\nFor general information, see [Ploombers' contribution guidelines.](https://ploomber-contributing.readthedocs.io)\n\nIssues tagged with [good first issue](https://github.com/ploomber/ploomber/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) are great options to start contributing.\n\nIf you get stuck, [open an issue](https://github.com/ploomber/ploomber/issues/new?title=CONTRIBUTING.md%20issue) or reach out to us on [Slack](https://ploomber.io/community/) and we'll happily help you.\n\nIf you're contributing to the documentation, go to [doc/CONTRIBUTING.md](doc/CONTRIBUTING.md).\n\n## Setup with conda\n\nThe easiest way to setup the development environment is via the setup command; you must have miniconda installed. If you don't want to use conda, skip to the next section.\n\n[Click here for miniconda installation details](https://docs.conda.io/en/latest/miniconda.html).\n\nMake sure conda has conda-forge as channel, running the following:\n\n```sh\nconda config --add channels conda-forge\n```\n\nOnce you have conda ready:\n\nFork the repository to your account by clicking fork button\n\n<p align=\"center\" width=\"100%\">\n  <img src=\"_static/fork.png\" height=\"40\">\n</p>\n\nNow ready to clone and setup the environment:\n\n\n```sh\n# get the code\ngit clone https://github.com/ploomber/ploomber\n\n# invoke is a library we use to manage one-off commands\npip install invoke\n\n# move into ploomber directory\ncd ploomber\n\n# setup development environment\ninvoke setup\n```\n\n*Note:* If you're using Linux, you may encounter issues running `invoke setup` regarding the `psycopg2` package. If that's the case, remove `psycopg2` from the `setup.py` file and try again.\n\nThen activate the environment:\n\n```sh\nconda activate ploomber\n```\n\n## Setup with pip\n\nPloomber has optional features that depend on packages that aren't straightforward to install, so we use `conda` for quickly setting up the development environment. But you can still get a pretty good development environment using `pip` alone.\n\n### [Optional] Create virtual environment\n\n**Note**: we highly recommend you to install ploomber in a virtual environment (the most straightforward alternative is the [venv](https://docs.python.org/3/library/venv.html) built-in module):\n\n```sh\n# create virtual env\npython -m venv ploomber-venv\n\n# activate virtual env (linux/macOS)\nsource ploomber-venv/bin/activate\n\n# activate virtual env (windows)\n.\\ploomber-venv\\Scripts\\activate\n```\n*Note:* [Check venv docs](https://docs.python.org/3/library/venv.html#creating-virtual-environments) to find the appropriate command if you're using Windows.\n\n### Install dependencies\n\n```sh\n# required to run the next command\npip install invoke\n\n# install dependencies with pip\ninvoke setup-pip\n```\n\n*Note:* If you're using Linux, you may encounter issues running `invoke setup` regarding the `psycopg2` package. If that's the case, remove `psycopg2` from the `setup.py` file and try again.\n\n### Caveats of installing with pip\n\nConda takes care of installing all dependencies required to run all tests. However, we need to skip a few of them when installing with pip because either the library is not pip-installable or any of their dependencies are. So if you use `invoke setup-pip` to configure your environment, some tests will fail. This isn't usually a problem if you're developing a specific feature; you can run a subset of the testing suite and let GitHub run the entire test suite when pushing your code.\n\nHowever, if you wish to have a full setup, you must install the following dependencies:\n\n1. [pygrapviz](https://github.com/pygraphviz/pygraphviz) (note that this depends on [graphviz](https://graphviz.org/)) which can't be installed by pip\n2. [IRKernel](https://github.com/IRkernel/IRkernel) (note that this requires an R installation)\n\n## Checking setup\n\nMake sure everything is working correctly:\n\n```sh\n# import ploomber\npython -c 'import ploomber; print(ploomber)'\n```\n\n*Note:* the output of the previous command should be the directory where you ran `git clone`; if it's not, try re-activating your conda environment (i.e., if using conda: `conda activate base`, then `conda activate ploomber`) If this doesn't work, [open an issue](https://github.com/ploomber/ploomber/issues/new?title=CONTRIBUTING.md%20issue) or reach out to us on [Slack](https://ploomber.io/community/).\n\n\nRun some tests:\n\n```\npytest tests/util\n```\n\n## Branch name requirement\n\nTo prevent double execution of the same CI pipelines, we have chosen to set a limitation to github push event. Only pushes to certain branches will trigger the pipelines. That means if you have turned on github action and want to run workflows in your forked repo, you will need to either make pushes directly to your master branch or branches name strictly following this convention: `dev/{your-branch-name}`.\n\nOn the other hand, if you choose not to turn on github action in your own repo and simply run tests locally, you can disregard this information since your pull request from your forked repo to ploomber/ploomber repo will always trigger the pipelines. \n\n## Linting\n\n*Note: ploomber/ploomber is the only project where we use yapf, other projects have moved to black*\n\n\nWe use [yapf](https://github.com/google/yapf) for formatting code. *Please run yapf on your code before submitting*:\n\n```sh\nyapf --in-place path/to/file.py\n```\n\nIf you want git to automatically check your code with `flake8` before you push to your fork, you can install a pre-push hook locally:\n\n```sh\n# to install pre-push git hook\ninvoke install-git-hook\n\n# to uninstall pre-push git hook\ninvoke uninstall-git-hook\n```\n\nThe installed hook only takes effect in your current repository.\n\n## Testing\n\n* Ploomber loads user's code dynamically via dotted paths (e.g., `my_module.my_function` is similar to doing `from my_module import my_function`). Hence, some of our tests do this as well. Dynamic imports can become a problem if tests create and import modules (i.e., create a new `.py` file and import it). To prevent temporary modules from polluting other tasks, use the `tmp_imports` pytest fixture, which deletes all packages imported inside a test\n* Some tests make calls to a PostgreSQL database. When running on Github Actions, a database is automatically provisioned, but the tests will fail locally.\n* If you're checking error messages and they include absolute paths to files, you may encounter some issues when running the Windows CI since the Github Actions VM has some symlinks. If the test calls `Pathlib.resolve()` ([resolves symlinks](https://docs.python.org/3/library/pathlib.html#id5)), call it in the test as well, if it doesn't, use `os.path.abspath()` (does not resolve symlinks).\n\n## Locally running GitHub actions\n\nDebugging GitHub actions by commiting, pushing, and then waiting for GitHub to \nrun them can be inconvenient because of the clunky workflow and inability to\nuse debugging tools other than printing to the console\n\nWe can use the tool [`act`](https://github.com/nektos/act) to run github \nactions locally in docker containers\n\nInstall then run `act` in the root directory. On the first invocation it will\nask for a size. Select medium. `act` will then run actions from the \n`.github/workflows` directory\n\n#### Working with containers\n\nIf the tests fail, act will leave the docker images after the action finishes.\nThese can be inspected by running `docker container list` then running\n`docker exec -it CONTAINER_ID bash` where `CONTAINER_ID` is a container id\nfrom `docker container list`\n\nTo install packages in the container, first run `apt-get update`. Packages\ncan be installed normally with apt after\n\n\n\n\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0849609375,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2022-Present Ploomber Inc.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.2275390625,
          "content": "include CHANGELOG.md\ninclude README.md\nrecursive-include jupyter-config *.json\ninclude src/ploomber/resources/*\ninclude src/ploomber/resources/ploomber_add/*\nexclude src/conftest.py\nglobal-exclude __pycache__\nglobal-exclude *.py[co]\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.662109375,
          "content": "<p align=\"center\" width=\"100%\">\n  <img src=\"_static/logo.png\" height=\"250\">\n</p>\n\n[![CI Linux](https://github.com/ploomber/ploomber/actions/workflows/ci-unit-linux.yml/badge.svg)](https://github.com/ploomber/ploomber/actions/workflows/ci-unit-linux.yml/badge.svg)\n[![CI macOS](https://github.com/ploomber/ploomber/actions/workflows/ci-unit-macos.yml/badge.svg)](https://github.com/ploomber/ploomber/actions/workflows/ci-unit-macos.yml/badge.svg)\n[![Documentation Status](https://readthedocs.org/projects/ploomber/badge/?version=latest)](https://docs.ploomber.io/en/latest/?badge=latest)\n[![PyPI](https://badge.fury.io/py/ploomber.svg)](https://badge.fury.io/py/ploomber)\n[![Conda (channel only)](https://img.shields.io/conda/vn/conda-forge/ploomber)](https://anaconda.org/conda-forge/ploomber)\n[![Conda](https://img.shields.io/conda/pn/conda-forge/ploomber)](https://anaconda.org/conda-forge/ploomber)\n[![Coverage](https://coveralls.io/repos/github/ploomber/ploomber/badge.svg?branch=master)](https://coveralls.io/github/ploomber/ploomber?branch=master)\n[![Twitter](https://img.shields.io/twitter/follow/ploomber?label=Follow&style=social)](https://twitter.com/intent/user?screen_name=ploomber)\n[![Downloads](https://pepy.tech/badge/ploomber)](https://pepy.tech/project/ploomber)\n\n> [!TIP]\n> Deploy AI apps for free on [Ploomber Cloud!](https://ploomber.io/?utm_medium=github&utm_source=ploomber)\n\n<p align=\"center\">\n  <a href=\"https://ploomber.io/community\">Join our community</a>\n  |\n  <a href=\"https://share.hsforms.com/1E7Qa_OpcRPi_MV-segFsaAe6c2g\">Newsletter</a>\n  |\n  <a href=\"mailto:contact@ploomber.io\">Contact us</a>\n  |\n  <a href=\"https://docs.ploomber.io/\">Docs</a>\n  |\n  <a href=\"https://ploomber.io/blog/\">Blog</a>\n  |  \n  <a href=\"https://www.ploomber.io\">Website</a>\n  |\n  <a href=\"https://www.youtube.com/channel/UCaIS5BMlmeNQE4-Gn0xTDXQ\">YouTube</a>\n</p>\n\n\nPloomber is the fastest way to build data pipelines . Use your favorite editor (**[Jupyter](https://docs.ploomber.io/en/latest/user-guide/jupyter.html), [VSCode](https://docs.ploomber.io/en/latest/user-guide/editors.html), [PyCharm](https://docs.ploomber.io/en/latest/user-guide/editors.html)**) to develop interactively and deploy  without code changes (**[Kubernetes](https://soopervisor.readthedocs.io/en/latest/tutorials/kubernetes.html), [Airflow](https://soopervisor.readthedocs.io/en/latest/tutorials/airflow.html), [AWS Batch](https://soopervisor.readthedocs.io/en/latest/tutorials/aws-batch.html), and [SLURM](https://soopervisor.readthedocs.io/en/latest/tutorials/slurm.html)**). Do you have legacy notebooks? Refactor them into modular pipelines with a single command.\n\n\n## Installation\n\n*Compatible with Python 3.7 and higher.*\n\nInstall with `pip`:\n\n```sh\npip install ploomber\n```\n\nOr with `conda`:\n\n```sh\nconda install ploomber -c conda-forge\n```\n\n## Getting started\n\n### Try the tutorial:\n<p>\n  <a href=\"https://github.com/ploomber/projects/blob/master/guides/first-pipeline/README.md\"> </a>\n</p>\n\n## Community\n\n* [Join us on Slack](https://ploomber.io/community)\n* [Newsletter](https://share.hsforms.com/1E7Qa_OpcRPi_MV-segFsaAe6c2g)\n* [YouTube](https://www.youtube.com/channel/UCaIS5BMlmeNQE4-Gn0xTDXQ)\n* [Contact the development team](mailto:contact@ploomber.io)\n\n## Main Features\n\n###  Get started quickly\n\nA simple YAML API to get started quickly, a powerful Python API for total flexibility.\n\nhttps://user-images.githubusercontent.com/989250/150660813-fc289c6c-0ed5-432d-b6df-063ce98c0093.mp4\n\n###  Shorter development cycles\n\nAutomatically cache your pipelines previous results and only re-compute tasks that have changed since your last execution.\n\nhttps://user-images.githubusercontent.com/989250/150660820-9a3a0abd-5904-492b-97ff-5494285dfebf.mp4\n\n###  Deploy anywhere\n\nRun as a shell script in a single machine or distributively in [Kubernetes](https://soopervisor.readthedocs.io/en/latest/tutorials/kubernetes.html), [Airflow](https://soopervisor.readthedocs.io/en/latest/tutorials/airflow.html), [AWS Batch](https://soopervisor.readthedocs.io/en/latest/tutorials/aws-batch.html), or [SLURM](https://soopervisor.readthedocs.io/en/latest/tutorials/slurm.html).\n\nhttps://user-images.githubusercontent.com/989250/150660830-3f81c9a2-5392-49e5-976d-cb8a38441ecb.mp4\n\n\n###  Automated migration from legacy notebooks\n\nBring your old monolithic notebooks, and well automatically convert them into maintainable, modular pipelines.\n\nhttps://user-images.githubusercontent.com/989250/150660840-b0c12f85-504c-4233-8c3d-6724d291f1aa.mp4\n\n\n[I want to migrate my notebook.](https://docs.ploomber.io/en/latest/user-guide/refactoring.html)\n\n[Show me a demo.](https://www.youtube.com/watch?v=EJecqsZBr3Q)\n\n## Resources\n\n* [Documentation](https://docs.ploomber.io/)\n* [PyData Chicago talk (covers motivation and demo)](https://youtu.be/qUL7QabcKcw)\n* [Develop and deploy an ML pipeline in 30 minutes (EuroPython 2021)](https://youtu.be/O8tqiCkIWPs)\n* [Guest blog post on the official Jupyter blog](https://blog.jupyter.org/ploomber-maintainable-and-collaborative-pipelines-in-jupyter-acb3ad2101a7)\n* [Examples (Machine Learning pipeline, ETL, among others)](https://github.com/ploomber/projects)\n* [Blog](https://ploomber.io/)\n* [Comparison with other tools](https://ploomber.io/posts/survey)\n* [More videos](https://docs.ploomber.io/en/latest/videos.html)\n\n## About Ploomber\n\nPloomber is a big community of data enthusiasts pushing the boundaries of Data Science and Machine Learning tooling.\n\nWhatever your skillset is, you can contribute to our mission. So whether you're a beginner or an experienced professional, you're welcome to join us on this journey!\n\n[Click here to know how you can contribute to Ploomber.](https://github.com/ploomber/contributing/blob/main/README.md)\n"
        },
        {
          "name": "_static",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "jupyter-config",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.4521484375,
          "content": "[tool.black]\nextend-exclude = \"ploomber_add\"\n\n[tool.pytest.ini_options]\naddopts = \"--pdbcls=IPython.terminal.debugger:Pdb\"\n\n[tool.pkgmt]\ngithub = \"ploomber/ploomber\"\n\n[tool.pkgmt.check_links]\nextensions = [\"rst\", \"py\", \"md\", \"ipynb\"]\nignore_substrings = [\"snowflakecomputing.com\",\n                     \"https://github.com/jupyter/notebook\",\n                     \"{your-user}\",\n                     \"{version}\",\n                     \"marketplace.visualstudio.com\"]"
        },
        {
          "name": "readthedocs.yaml",
          "type": "blob",
          "size": 0.853515625,
          "content": "# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n# Regadring the pip._internal.index bug:\n# https://stackoverflow.com/q/59846065/709975\nversion: 2\n\nbuild:\n   os: \"ubuntu-22.04\"\n   tools:\n     python: \"miniconda3-4.7\"\n   jobs:\n     pre_create_environment:\n       - conda update --yes --quiet --name=base --channel=defaults conda\n\nsphinx:\n  configuration: doc/conf.py\n\nformats: all\n\n# create conda env from that file\nconda:\n  environment: doc/environment.yml\n\n\n# install package with pip[all] from this directory\n# no longer installing here since read the docs uses --upgrade-strategy eager\n# which breaks the build due to nbsphinx incompatibility with jinja2>=3.0.0\n# installing in doc/environment.yml instead\n# python:\n#   install:\n#     - method: pip\n#       path: .\n#       extra_requirements:\n#         - all\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.4326171875,
          "content": "[metadata]\ndescription-file = README.md\n\n[flake8]\n# files in ploomber_add/ are jinja templates, not Python source files\n# CONTRIBUTING.md shows how to create a venv and the sample command creates it in a ploomber-venv directory\n# TODO: fix functions.py and remove it from here\nexclude = src/ploomber/resources/ploomber_add, build/, tests/assets/test_pkg/src/test_pkg/functions.py, ploomber-venv, dist/\nmax-line-length = 88\nextend-ignore = E203"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.0146484375,
          "content": "#!/usr/bin/env python\n# -*- encoding: utf-8 -*-\nimport re\nimport ast\nfrom pathlib import Path\n\nfrom setuptools import find_packages\nfrom setuptools import setup\n\n_version_re = re.compile(r\"__version__\\s+=\\s+(.*)\")\n\nwith open(\"src/ploomber/__init__.py\", \"rb\") as f:\n    VERSION = str(\n        ast.literal_eval(_version_re.search(f.read().decode(\"utf-8\")).group(1))\n    )\n\nhere = Path(__file__).parent.resolve()\n\n\ndef read(name):\n    return Path(here, name).read_text(encoding=\"utf-8\")\n\n\n# NOTE: most users just do \"pip install jupyter\" but\n# we have to pin specific versions of jupyter_client, nbconvert and\n# ipykernel to support parallel execution using papermill\n# (avoid \"kernel did not respond\" errors)\n# these are versions are not pinned in papermill (yet) so we put it here\n# more info:\n# https://discourse.jupyter.org/t/nbconvert-5-6-0-release/1867\n# https://github.com/nteract/papermill/issues/239\nNB = [\n    \"papermill\",\n    \"notebook<7\",\n    \"jupytext\",\n    \"ipykernel>=1.5.2\",\n    \"jupyter_client>=5.3.1\",\n    \"nbconvert>=5.6.0\",\n    \"nbformat\",\n    # for notebook validation\n    \"pyflakes\",\n]\n\n# Optional dependencies are packages that are used in several modules but are\n# not strictly required. Dependencies that are required for a single use case\n# (e.g. upload to s3) should be included in the \"TESTING\" list. Both optional\n# and one-time modules should use the @requires decorator to show an error if\n# the dependency is missing. numpydoc is an special case because it's an\n# optional dependency but not having it installed does not trigger an error\n# it will just not print the parsed docstring.\nOPTIONAL = [\n    # sql dumps and uploads\n    \"pandas\",\n    # for ParquetIO\n    \"pyarrow\",\n    # qa and entry modules\n    \"numpydoc\",\n    # for embedded dag plots with d3 backend\n    \"requests-html\",\n    \"nest_asyncio\",\n]\n\nTESTING = [\n    # plotting. strictly speaking pygrapviz is an optional dependency but we\n    # don't add it as such because it's gonna break installation for most\n    # setups, since we don't expect users to have graphviz installed\n    'pygraphviz;python_version<\"3.10\"',\n    # RemoteShellClient\n    \"paramiko\",\n    # Upload to S3\n    \"boto3\",\n    # testing upload to S3 task\n    \"moto<5\",\n    # Upload to google cloud storage\n    \"google-cloud-storage\",\n    # NOTE: pytest introduced some breaking changes\n    \"pytest==7.1.*\",\n    \"pytest-cov\",\n    # TODO: update config so coveralls 3 works\n    \"coveralls<3\",\n    # we need this because we are re-using the original jupyter test suite for\n    # testing our contents manager (which imports nose), see test_jupyter.py\n    \"nose\",\n    \"yapf\",\n    \"flake8\",\n    # needed to run some test pipelines\n    \"matplotlib\",\n    \"seaborn\",\n    # https://www.psycopg.org/docs/install.html#psycopg-vs-psycopg-binary\n    # this one is easier to install\n    \"psycopg2-binary\",\n    # requires for some Table tests where we parse the HTML repr\n    \"lxml\",\n    # for testing jupyter lab plugin\n    \"jupyter_server\",\n    \"notebook\",\n    # optional dependencies for @serializer and @unserializer\n    \"joblib\",\n    \"cloudpickle\",\n    # for testing the webpdf converter\n    \"nbconvert[webpdf]\",\n    # for testing ParallelDill,\n    \"multiprocess\",\n    # dill 0.3.6 is breaking windows github actions\n    \"dill==0.3.5.1\",\n    \"sqlalchemy\",\n]\n\n# packages needed for development\nDEV = [\"twine\", \"invoke\", \"pkgmt\"]\n\nDESCRIPTION = (\n    \"Write maintainable, production-ready pipelines using Jupyter or your \"\n    \"favorite text editor. Develop locally, deploy to the cloud.\"\n)\n\nsetup(\n    name=\"ploomber\",\n    version=VERSION,\n    description=DESCRIPTION,\n    long_description=read(\"README.md\"),\n    long_description_content_type=\"text/markdown\",\n    author=\"Ploomber\",\n    author_email=\"contact@ploomber.io\",\n    url=\"https://github.com/ploomber/ploomber\",\n    packages=find_packages(\"src\"),\n    package_dir={\"\": \"src\"},\n    include_package_data=True,\n    data_files=[\n        (\n            \"etc/jupyter/jupyter_notebook_config.d\",\n            [\"jupyter-config/jupyter_notebook_config.d/ploomber.json\"],\n        ),\n        (\n            \"etc/jupyter/jupyter_server_config.d\",\n            [\"jupyter-config/jupyter_server_config.d/ploomber.json\"],\n        ),\n    ],\n    zip_safe=False,\n    classifiers=[\n        # https://pypi.org/classifiers/\n        \"Development Status :: 5 - Production/Stable\",\n        \"Intended Audience :: Developers\",\n        \"Intended Audience :: Science/Research\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Operating System :: MacOS :: MacOS X\",\n        \"Operating System :: Unix\",\n        \"Operating System :: POSIX\",\n        \"Operating System :: Microsoft :: Windows\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n    ],\n    keywords=[\n        # eg: 'keyword1', 'keyword2', 'keyword3',\n    ],\n    install_requires=[\n        \"ploomber-scaffold>=0.3\",\n        # added fix to manage the IPython terminal singleton\n        \"ploomber-engine>=0.0.8\",\n        # added @deprecated.method\n        \"ploomber-core>=0.0.11\",\n        \"pyyaml\",\n        \"networkx>=2.5\",\n        \"jinja2\",\n        \"tabulate\",\n        \"humanize\",\n        \"tqdm\",\n        \"posthog\",\n        # for code normalization, parso is also needed for inferring upstream\n        # dependencies in jupyter notebooks\n        \"sqlparse\",\n        \"autopep8\",\n        \"pycodestyle\",\n        \"parso\",\n        # for generating dag.to_markup(fmt='html')\n        \"mistune\",\n        # for syntax highlighting when generating dag HTML reports\n        \"pygments\",\n        \"sqlalchemy\",\n        # for cli\n        \"click\",\n        # for ploomber interact and {PythonCallable, NotebookRunner}.debug()\n        \"ipython\",\n        \"ipdb\",\n        \"pydantic\",\n    ]\n    + NB,\n    extras_require={\n        \"all\": OPTIONAL,\n        \"dev\": OPTIONAL + TESTING + DEV,\n    },\n    entry_points={\n        \"console_scripts\": [\"ploomber=ploomber_cli.cli:cmd_router\"],\n    },\n)\n"
        },
        {
          "name": "src",
          "type": "tree",
          "content": null
        },
        {
          "name": "tasks.py",
          "type": "blob",
          "size": 3.7734375,
          "content": "\"\"\"\nSetup tasks (requires invoke: pip install invoke)\n\"\"\"\n\nimport sys\nimport platform\nfrom pathlib import Path\nimport base64\nfrom invoke import task\nimport shutil\n\n_IS_WINDOWS = platform.system() == \"Windows\"\n_PY_DEFAULT_VERSION = \"3.9\"\n\nif not Path(\"LICENSE\").exists():\n    sys.exit(\n        \"Error: Run the command from the root folder (the directory \"\n        \"with the README.md and setup.py files)\"\n    )\n\n\n@task\ndef db_credentials(c):\n    \"\"\"Encode db credentials (for github actions)\"\"\"\n    path = str(Path(\"~\", \".auth\", \"postgres-ploomber.json\").expanduser())\n    creds = Path(path).read_text()\n    print(base64.b64encode(creds.encode()).decode())\n\n\n@task\ndef setup(c, doc=False, version=None):\n    \"\"\"\n    [conda] Setup dev environment\n    \"\"\"\n    if doc and version:\n        raise ValueError(\n            \"doc and version options are incompatible, \"\n            \"installing docs will install python 3.8\"\n        )\n\n    version = version or _PY_DEFAULT_VERSION\n    suffix = \"\" if version == _PY_DEFAULT_VERSION else version.replace(\".\", \"\")\n    env_name = f\"ploomber{suffix}\"\n\n    cmds = [\n        'eval \"$(conda shell.bash hook)\"',\n        f\"conda activate {env_name}\",\n        \"conda install pygraphviz r-base r-irkernel --yes -c conda-forge\",\n        \"pip install --editable .[dev]\",\n        \"pip install --editable tests/assets/test_pkg\",\n    ]\n\n    if _IS_WINDOWS:\n        cmds.pop(0)\n\n    c.run(f\"conda create --name {env_name} python={version} --yes -c conda-forge\")\n\n    c.run(\" && \".join(cmds))\n\n    if doc:\n        cmds = [\n            'eval \"$(conda shell.bash hook)\"',\n            f\"conda activate {env_name} \",\n            f\"conda env update --file environment.yml --name {env_name}\",\n        ]\n\n        if _IS_WINDOWS:\n            cmds.pop(0)\n\n        with c.cd(\"doc\"):\n            c.run(\" && \".join(cmds))\n\n    print(f\"Done! Activate your environment with:\\nconda activate {env_name}\")\n\n\n@task\ndef setup_pip(c, doc=False):\n    \"\"\"[pip] Setup dev environment\"\"\"\n    # install ploomber in editable mode and include development dependencies\n    c.run('pip install --editable \".[dev]\"')\n\n    # install sample package required in some tests\n    c.run(\"pip install --editable tests/assets/test_pkg\")\n\n    # install doc dependencies\n    if doc:\n        c.run(\"pip install -r doc/requirements.txt\")\n\n    print(\n        \"Warning: installing with pip skips some dependencies. \"\n        'See contributing.md \"Setup with pip for details\"'\n    )\n\n\n@task\ndef docs(c):\n    \"\"\"Build docs\"\"\"\n    with c.cd(\"doc\"):\n        c.run(\"make html\")\n\n\n@task(aliases=[\"v\"])\ndef version(c):\n    \"\"\"Release a new version\"\"\"\n    from pkgmt import versioneer\n\n    versioneer.version(project_root=\".\", tag=True)\n\n\n@task(aliases=[\"r\"])\ndef release(c, tag, production=True):\n    \"\"\"Upload to PyPI\"\"\"\n    from pkgmt import versioneer\n\n    versioneer.upload(tag, production=production)\n\n\n@task\ndef test(c, report=False):\n    \"\"\"Run tests\"\"\"\n    c.run(\n        \"pytest tests --cov ploomber \" + (\"--cov-report html\" if report else \"\"),\n        pty=True,\n    )\n    c.run(\"flake8\")\n\n\n@task\ndef install_git_hook(c, force=False):\n    \"\"\"Installs pre-push git hook\"\"\"\n    path = Path(\".git/hooks/pre-push\")\n    hook_exists = path.is_file()\n\n    if hook_exists:\n        if force:\n            path.unlink()\n        else:\n            sys.exit(\n                \"Error: pre-push hook already exists. \"\n                'Run: \"invoke install-git-hook -f\" to force overwrite.'\n            )\n\n    shutil.copy(\".githooks/pre-push\", \".git/hooks\")\n    print(f\"pre-push hook installed at {str(path)}\")\n\n\n@task\ndef uninstall_git_hook(c):\n    \"\"\"Uninstalls pre-push git hook\"\"\"\n    path = Path(\".git/hooks/pre-push\")\n    hook_exists = path.is_file()\n\n    if hook_exists:\n        path.unlink()\n        print(f\"Deleted {str(path)}.\")\n    else:\n        print(\"Hook doesn't exist, nothing to delete.\")\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "testutils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}