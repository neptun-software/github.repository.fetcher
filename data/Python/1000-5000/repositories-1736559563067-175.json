{
  "metadata": {
    "timestamp": 1736559563067,
    "page": 175,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE4MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "pytorch/ignite",
      "stars": 4568,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.490234375,
          "content": "# Byte-compiled / optimized / DLL files\n*.pyc\n__pycache__/\n*.py[cod]\n*$py.class\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n**/.DS_Store\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n.pytest_cache/\n\n# Documentation\n/docs/src/\n/docs/build/\n/docs/source/generated/\n\n# Virtualenv\n.venv/\n.python-version\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.6904296875,
          "content": "exclude: \"^conda.recipe\"\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v3.4.0\n    hooks:\n      - id: check-toml\n      - id: check-yaml\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n\n  - repo: https://github.com/pre-commit/mirrors-prettier\n    rev: v2.2.1\n    hooks:\n      - id: prettier\n        exclude_types: [\"python\", \"jupyter\", \"shell\", \"gitignore\"]\n\n  - repo: https://github.com/omnilib/ufmt\n    rev: v2.7.3\n    hooks:\n      - id: ufmt\n        additional_dependencies:\n          - black == 24.10.0\n          - usort == 1.0.8.post1\n\n  - repo: https://github.com/pycqa/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n        args: [\"--config\", \"setup.cfg\"]\n"
        },
        {
          "name": "CITATION",
          "type": "blob",
          "size": 0.3115234375,
          "content": "@misc{pytorch-ignite,\n  author = {V. Fomin and J. Anmol and S. Desroziers and J. Kriss and A. Tejani},\n  title = {High-level library to help with training neural networks in PyTorch},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/pytorch/ignite}},\n}"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2763671875,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the project team at <contact@pytorch-ignite.ai>. All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,\navailable at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\nhttps://www.contributor-covenant.org/faq\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 14.3232421875,
          "content": "# Contributing to Ignite\n\nThis project is a community effort, and everyone is welcome to contribute !\n\nIf you are interested in contributing to Ignite, there are many ways to help out. Your contributions may fall\ninto the following categories:\n\n1. It helps us very much if you could\n\n   - Report issues you’re facing\n   - Give a :+1: on issues that others reported and that are relevant to you\n   - Spread a word about the project or simply :star: to say \"I use it\"\n\n2. Answering queries on the issue tracker, investigating bugs and reviewing other developers’ pull requests are\n   very valuable contributions that decrease the burden on the project maintainers.\n\n3. You would like to improve the documentation. This is no less important than improving the library itself!\n   If you find a typo in the documentation, do not hesitate to submit a GitHub pull request.\n\n4. You would like propose a new feature and implement it\n\n   - Post about your intended feature, and we shall discuss the design and\n     implementation. Once we agree that the plan looks good, go ahead and implement it.\n\n5. You would like implement a feature or bug-fix for an outstanding issue\n   - Look at the issues labelled as [\"help wanted\"](https://github.com/pytorch/ignite/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22)\n   - Pick an issue and comment on the task that you want to work on this feature.\n   - If you need more context on a particular issue, please ask and we shall provide.\n\n## Table of Contents\n\n- [Table of Contents](#table-of-contents)\n- [Developing Ignite](#developing-ignite)\n  - [Quickstart guide for first-time contributors](#quickstart-guide-for-first-time-contributors)\n  - [Installation](#installation)\n  - [Code development](#code-development)\n    - [Codebase structure](#codebase-structure)\n    - [Formatting Code](#formatting-code)\n      - [Formatting without pre-commit](#formatting-without-pre-commit)\n      - [Formatting with pre-commit](#formatting-with-pre-commit)\n    - [Run tests](#run-tests)\n      - [Run distributed tests only on CPU](#run-distributed-tests-only-on-cpu)\n    - [Run Mypy checks](#run-mypy-checks)\n    - [Send a PR](#send-a-pr)\n      - [Sync up with the upstream](#sync-up-with-the-upstream)\n  - [Writing documentation](#writing-documentation)\n    - [Local documentation building and deploying](#local-documentation-building-and-deploying)\n      - [Install requirements](#install-requirements)\n      - [Build](#build)\n      - [Local deployment](#local-deployment)\n\n## Developing Ignite\n\n### Quickstart guide for first-time contributors\n\n<summary>\n\n<details>\n\n- Install [miniconda](https://docs.conda.io/en/latest/miniconda.html) for your system.\n- Create an isolated conda environment for pytorch-ignite:\n\n```bash\nconda create -n pytorch-ignite-dev python=3.11\n```\n\n- Activate the newly created environment:\n\n```bash\nconda activate pytorch-ignite-dev\n```\n\n- When developing please take care of preserving `.gitignore` file and make use of `.git/info/exclude` to exclude custom files like: `.idea`, `.vscode` etc.\n- Please refer to [github first contributions guidelines](https://github.com/firstcontributions/first-contributions) and don't hesitate to ask the pytorch-ignite community in case of any doubt.\n- A good way to start is to tackle one of the [good first issues](https://github.com/pytorch/ignite/labels/good%20first%20issue).\n\n</details>\n\n</summary>\n\n### Installation\n\n1) Make a fork of the repository on the GitHub (see [here](https://github.com/firstcontributions/first-contributions#fork-this-repository) for details). \nAs a result, for example your username is `happy-ignite-developer`, then you should be able to see your fork on the GitHub, e.g https://github.com/happy-ignite-developer/ignite.git\n\n2) Clone your fork locally and setup `upstream`. Assuming your username is `happy-ignite-developer`:\n\n```bash\ngit clone https://github.com/happy-ignite-developer/ignite.git\ncd ignite\ngit remote add upstream https://github.com/pytorch/ignite.git\ngit remote -v\n```\nYou might see the following output:\n```\norigin  https://github.com/happy-ignite-developer/ignite.git (fetch)\norigin  https://github.com/happy-ignite-developer/ignite.git (push)\nupstream        https://github.com/pytorch/ignite (fetch)\nupstream        https://github.com/pytorch/ignite (push)\n```\n3) Sync and install all necessary dependencies:\n\n```bash\ngit pull upstream master\npython setup.py develop\npip install -r requirements-dev.txt\nbash ./tests/run_code_style.sh install\n```\n\n### Code development\n\n#### Codebase structure\n\n- [ignite](ignite) - Core library files\n  - [engine](ignite/engine) - Module containing core classes like Engine, Events, State.\n  - [handlers](ignite/handlers) - Module containing out-of-the-box handlers\n  - [metrics](ignite/metrics) - Module containing out-of-the-box metrics\n  - [contrib](ignite/contrib) - Contrib module with other metrics, handlers classes that may require additional dependencies\n  - [distributed](ignite/distributed) - Module with helpers for distributed computations\n- [tests](tests) - Python unit tests\n- [examples](examples) - Examples and notebook tutorials\n- [docs](docs) - Documentation files\n\nIf you modify the code, you will most probably also need to code some tests to ensure the correct behaviour. We are using\n`pytest` to write our tests:\n\n- naming convention for files `test_*.py`, e.g. `test_precision.py`\n- naming of testing functions `def test_*`, e.g. `def test_precision_on_random_data()`\n  - if test function should run on GPU, please **make sure to add `cuda`** in the test name, e.g. `def test_something_on_cuda()`.\n    Additionally, we may want to decorate it with `@pytest.mark.skipif(not torch.cuda.is_available(), reason=\"Skip if no GPU\")`.\n    For more examples, please see https://github.com/pytorch/ignite/blob/master/tests/ignite/engine/test_create_supervised.py\n  - if test function checks distributed configuration, we have to mark the test as `@pytest.mark.distributed` and additional\n    conditions depending on the intended checks. For example, please see\n    https://github.com/pytorch/ignite/blob/master/tests/ignite/metrics/test_accuracy.py\n\nNew code should be compatible with Python 3.X versions. Once you finish implementing a feature or bugfix and tests,\nplease run lint checking and tests:\n\n#### Formatting Code\n\nTo ensure the codebase complies with a style guide, we use [flake8](https://flake8.pycqa.org/en/latest/)\nand [ufmt](https://ufmt.omnilib.dev/) ([black](https://black.readthedocs.io/en/stable/) and\n[usort](https://usort.readthedocs.io/en/stable/)) to format and check codebase for compliance with PEP8.\n\n##### Formatting without pre-commit\n\nIf you choose not to use pre-commit, you can take advantage of IDE extensions configured to black format or invoke\nblack manually to format files and commit them.\n\nTo install `flake8`, `ufmt` and `mypy`, please run\n\n```bash\nbash ./tests/run_code_style.sh install\n```\n\nTo format files and commit changes:\n\n```bash\n# This should autoformat the files\nbash ./tests/run_code_style.sh fmt\n# If everything is OK, then commit\ngit add .\ngit commit -m \"Added awesome feature\"\n```\n\n##### Formatting with pre-commit\n\nTo automate the process, we have configured the repo with [pre-commit hooks](https://pre-commit.com/) to use µfmt to autoformat the staged files to ensure every commit complies with a style guide. This requires some setup, which is described below:\n\n1. Install pre-commit in your python environment.\n2. Run pre-commit install that configures a virtual environment to invoke ufmt and flake8 on commits.\n\n```bash\npip install pre-commit\npre-commit install\n```\n\n3. When files are committed:\n   - If the stages files are not compliant with black or µsort, µfmt will autoformat the staged files. If this were to happen, files should be staged and committed again. See example code below.\n   - If the staged files are not compliant with flake8, errors will be raised. These errors should be fixed and the files should be committed again. See example code below.\n\n```bash\ngit add .\ngit commit -m \"Added awesome feature\"\n# DONT'T WORRY IF ERRORS ARE RAISED.\n# YOUR CODE IS NOT COMPLIANT WITH flake8, µsort or black\n# Fix any flake8 errors by following their suggestions\n# µfmt will automatically format the files so they might look different, but you'll need to stage the files\n# again for committing\n# After fixing any flake8 errors\ngit add .\ngit commit -m \"Added feature\"\n```\n\n#### Run tests:\n\nTo run a specific test, for example `test_terminate` from `test_engine.py`:\n\n```bash\npytest tests/ignite/engine/test_engine.py -vvv -k test_terminate\n```\n\nTo run all tests with coverage (assuming installed `pytest-cov` and `pytest-xdist`):\n\n```bash\nbash tests/run_cpu_tests.sh\n```\n\nOn Windows, distributed tests should be skipped\n\n```bash\nSKIP_DISTRIB_TESTS=1 bash tests/run_cpu_tests.sh\n```\n\n##### Run distributed tests only on CPU\n\nTo run distributed tests only (assuming installed `pytest-xdist`):\n\n```bash\nexport WORLD_SIZE=2\nCUDA_VISIBLE_DEVICES=\"\" pytest --dist=each --tx $WORLD_SIZE*popen//python=python tests/ -m distributed -vvv\n```\n\n#### Run Mypy checks:\n\nTo run mypy to check the optional static type:\n\n```bash\nbash ./tests/run_code_style.sh mypy\n```\n\nTo change any config for specif folder, please see the file mypy.ini\n\n#### Send a PR\n\nIf everything is OK, please send a Pull Request to https://github.com/pytorch/ignite from your fork.\n\nIf you are not familiar with creating a Pull Request, here are some guides:\n\n- https://github.com/firstcontributions/first-contributions\n- http://stackoverflow.com/questions/14680711/how-to-do-a-github-pull-request\n- https://help.github.com/articles/creating-a-pull-request/\n\n**NOTE : When sending a PR, please kindly check if the changes are required to run in the CI.**\n\nFor example, typo changes in `CONTRIBUTING.md`, `README.md` are not required to run in the CI.\nSo, please add `[skip ci]` in the PR title to save the resources. Ignite has setup several CIs.\n\n- GitHub Actions\n- Netlify\n\nSo, please add\n\n- `[skip actions]` for the changes which are not required to run on GitHub Actions,\n- `[skip netlify]` for the changes which are not required to run on Netlify PR Preview build, or\n- `[skip ci]` for the changes which are not required to run on any CI.\n\n**NOTE : Those skip statements are case sensitive, need open bracket `[` and close bracket `]`.\nAnd, Ignite has followed a convention of starting with `skip` word.**\n\n##### Sync up with the upstream\n\nFirst, make sure you have set [upstream](https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/configuring-a-remote-for-a-fork) by running:\n\n```bash\ngit remote add upstream https://github.com/pytorch/ignite\n```\n\nThen you can see if you have set up multiple remote correctly by running `git remote -v`:\n\n```bash\norigin  https://github.com/{YOUR_USERNAME}/ignite.git (fetch)\norigin  https://github.com/{YOUR_USERNAME}/ignite.git (push)\nupstream        https://github.com/pytorch/ignite (fetch)\nupstream        https://github.com/pytorch/ignite (push)\n```\n\nNow you can get the latest development into your forked repository with this:\n\n```bash\ngit fetch upstream\ngit checkout master\ngit merge upstream/master\n```\n\n### Writing documentation\n\nIgnite uses [Google style](https://www.sphinx-doc.org/en/master/usage/extensions/napoleon.html#type-annotations)\nfor formatting docstrings, specially from an example of `Google style with Python 3 type annotations` and\n\n- [`.. versionadded::`] directive for adding new classes, class methods, functions,\n- [`.. versionchanged::`] directive for adding new arguments, changing internal behaviours, fixing bugs and\n- [`.. deprecated::`] directive for deprecations.\n\nExamples: ``versionadded`` usage [link](https://github.com/pytorch/ignite/blob/52c69251dd9d97c32da1df0477ec3854e5702029/ignite/handlers/state_param_scheduler.py#L24), ``versionchanged`` usage [link](https://github.com/pytorch/ignite/blob/d2020e4e253ac1455a757c2db895c68ccfd2b958/ignite/metrics/metric.py#L281-L282)\n\n\n\nLength of line inside docstrings block must be limited to 120 characters.\n\n[`.. versionadded::`]: https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#directive-versionadded\n[`.. versionchanged::`]: https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#directive-versionchanged\n[`.. deprecated::`]: https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html#directive-deprecated\n\n#### Local documentation building and deploying\n\nPlease, follow the instructions to build and deploy the documentation locally.\n\n##### Install requirements\n\n```bash\ncd docs\npip install -r requirements.txt\n```\n\n[Katex](https://katex.org/) is also needed to build the documentation.\nTo install katex, you need to have [nodejs](https://nodejs.org/en/) installed.\nOptionaly, we can install `nodejs/npm` using conda: `conda install nodejs`.\nThen you can install katex with [npm](https://www.npmjs.com/) or [yarn](https://yarnpkg.com/) (if installed).\n\n```bash\nnpm install -g katex\n# or if you use yarn package manager\nyarn global add katex\n```\n\n##### Build\n\n```bash\ncd docs\nmake html\n```\n\n##### Local deployment\n\nPlease, use python 3.X for the command below:\n\n```bash\ncd docs/build\npython -m http.server <port>\n# python -m http.server 1234\n```\n\nThen open the browser at `localhost:<port>` (e.g. `localhost:1234`) and click to `html` folder.\n\n#### Examples testing (doctests)\n\nPyTorch-Ignite uses **Sphinx directives**. Every code that needs to be tested\nshould be under `.. testcode::` and expected output should be under\n`.. testoutput::`. For example:\n\n```py\n.. testcode::\n\n    def process_function(engine, batch):\n        y_pred, y = batch\n        return y_pred, y\n    engine = Engine(process_function)\n    metric = SSIM(data_range=1.0)\n    metric.attach(engine, 'ssim')\n    preds = torch.rand([4, 3, 16, 16])\n    target = preds * 0.75\n    state = engine.run([[preds, target]])\n    print(state.metrics['ssim'])\n\n.. testoutput::\n\n    0.9218971...\n```\n\nIf the floating point results are needed for assertion and the results can vary per operating systems and PyTorch versions, we could assert the results up to 4 or 6 decimal places and match the rest of the results with `...`. Learn more about `sphinx.ext.doctest` in [the official documentation](https://www.sphinx-doc.org/en/master/usage/extensions/doctest.html).\n\nTo make writing doctests easy, there are some configuratons defined in `conf.py`. Search `doctest_global_setup` in [conf.py](docs/source/conf.py) to see which variables and functions are available.\n\nTo run doctests locally:\n\n```sh\ncd docs\nmake html && make doctest\n```\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4912109375,
          "content": "BSD 3-Clause License\n\nCopyright (c) 2018-present, PyTorch-Ignite team\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 26.681640625,
          "content": "<div align=\"center\">\n\n<!-- ![Ignite Logo](assets/logo/ignite_logo_mixed.svg) -->\n\n<img src=\"assets/logo/ignite_logo_mixed.svg\" width=512>\n\n<!-- [![image](https://travis-ci.com/pytorch/ignite.svg?branch=master)](https://travis-ci.com/pytorch/ignite) -->\n\n| ![image](https://img.shields.io/badge/-Tests:-black?style=flat-square) [![image](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml/badge.svg?branch=master)](https://github.com/pytorch/ignite/actions/workflows/unit-tests.yml) [![image](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml/badge.svg)](https://github.com/pytorch/ignite/actions/workflows/gpu-tests.yml) [![image](https://codecov.io/gh/pytorch/ignite/branch/master/graph/badge.svg)](https://codecov.io/gh/pytorch/ignite) [![image](https://img.shields.io/badge/dynamic/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Fpytorch-ignite%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://pytorch.org/ignite/index.html) |\n|:---\n| ![image](https://img.shields.io/badge/-Stable%20Releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch/ignite/badges/version.svg)](https://anaconda.org/pytorch/ignite) ・ [![image](https://img.shields.io/badge/dynamic/json.svg?label=PyPI&url=https%3A%2F%2Fpypi.org%2Fpypi%2Fpytorch-ignite%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https://pypi.org/project/pytorch-ignite/) [![image](https://static.pepy.tech/badge/pytorch-ignite)](https://pepy.tech/project/pytorch-ignite) ・ [![image](https://img.shields.io/badge/docker-hub-blue)](https://hub.docker.com/u/pytorchignite) |\n| ![image](https://img.shields.io/badge/-Nightly%20Releases:-black?style=flat-square) [![image](https://anaconda.org/pytorch-nightly/ignite/badges/version.svg)](https://anaconda.org/pytorch-nightly/ignite) [![image](https://img.shields.io/badge/PyPI-pre%20releases-brightgreen)](https://pypi.org/project/pytorch-ignite/#history)|\n| ![image](https://img.shields.io/badge/-Community:-black?style=flat-square) [![Twitter](https://img.shields.io/badge/news-twitter-blue)](https://twitter.com/pytorch_ignite) [![discord](https://img.shields.io/badge/chat-discord-blue?logo=discord)](https://discord.gg/djZtm3EmKj) [![numfocus](https://img.shields.io/badge/NumFOCUS-affiliated%20project-green)](https://numfocus.org/sponsored-projects/affiliated-projects) |\n| ![image](https://img.shields.io/badge/-Supported_PyTorch/Python_versions:-black?style=flat-square) [![link](https://img.shields.io/badge/-check_here-blue)](https://github.com/pytorch/ignite/actions?query=workflow%3A%22PyTorch+version+tests%22)|\n\n</div>\n\n## TL;DR\n\nIgnite is a high-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.\n\n<div align=\"center\">\n\n<a href=\"https://colab.research.google.com/github/pytorch/ignite/blob/master/assets/tldr/teaser.ipynb\">\n <img alt=\"PyTorch-Ignite teaser\"\n      src=\"assets/tldr/pytorch-ignite-teaser.gif\"\n      width=532>\n</a>\n\n_Click on the image to see complete code_\n\n</div>\n\n### Features\n\n- [Less code than pure PyTorch](https://raw.githubusercontent.com/pytorch/ignite/master/assets/ignite_vs_bare_pytorch.png)\n  while ensuring maximum control and simplicity\n\n- Library approach and no program's control inversion - _Use ignite where and when you need_\n\n- Extensible API for metrics, experiment managers, and other components\n\n<!-- ############################################################################################################### -->\n\n# Table of Contents\n\n- [Table of Contents](#table-of-contents)\n- [Why Ignite?](#why-ignite)\n  - [Simplified training and validation loop](#simplified-training-and-validation-loop)\n  - [Power of Events & Handlers](#power-of-events--handlers)\n    - [Execute any number of functions whenever you wish](#execute-any-number-of-functions-whenever-you-wish)\n    - [Built-in events filtering](#built-in-events-filtering)\n    - [Stack events to share some actions](#stack-events-to-share-some-actions)\n    - [Custom events to go beyond standard events](#custom-events-to-go-beyond-standard-events)\n  - [Out-of-the-box metrics](#out-of-the-box-metrics)\n- [Installation](#installation)\n  - [Nightly releases](#nightly-releases)\n  - [Docker Images](#docker-images)\n    - [Using pre-built images](#using-pre-built-images)\n- [Getting Started](#getting-started)\n- [Documentation](#documentation)\n  - [Additional Materials](#additional-materials)\n- [Examples](#examples)\n  - [Tutorials](#tutorials)\n  - [Reproducible Training Examples](#reproducible-training-examples)\n- [Communication](#communication)\n  - [User feedback](#user-feedback)\n- [Contributing](#contributing)\n- [Projects using Ignite](#projects-using-ignite)\n- [Citing Ignite](#citing-ignite)\n- [About the team & Disclaimer](#about-the-team--disclaimer)\n\n<!-- ############################################################################################################### -->\n\n# Why Ignite?\n\nIgnite is a **library** that provides three high-level features:\n\n- Extremely simple engine and event system\n- Out-of-the-box metrics to easily evaluate models\n- Built-in handlers to compose training pipeline, save artifacts and log parameters and metrics\n\n## Simplified training and validation loop\n\nNo more coding `for/while` loops on epochs and iterations. Users instantiate engines and run them.\n\n<details>\n<summary>\nExample\n</summary>\n\n```python\nfrom ignite.engine import Engine, Events, create_supervised_evaluator\nfrom ignite.metrics import Accuracy\n\n\n# Setup training engine:\ndef train_step(engine, batch):\n    # Users can do whatever they need on a single iteration\n    # Eg. forward/backward pass for any number of models, optimizers, etc\n    # ...\n\ntrainer = Engine(train_step)\n\n# Setup single model evaluation engine\nevaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()})\n\ndef validation():\n    state = evaluator.run(validation_data_loader)\n    # print computed metrics\n    print(trainer.state.epoch, state.metrics)\n\n# Run model's validation at the end of each epoch\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, validation)\n\n# Start the training\ntrainer.run(training_data_loader, max_epochs=100)\n```\n\n</details>\n\n## Power of Events & Handlers\n\nThe cool thing with handlers is that they offer unparalleled flexibility (compared to, for example, callbacks). Handlers can be any function: e.g. lambda, simple function, class method, etc. Thus, we do not require to inherit from an interface and override its abstract methods which could unnecessarily bulk up your code and its complexity.\n\n### Execute any number of functions whenever you wish\n\n<details>\n<summary>\nExamples\n</summary>\n\n```python\ntrainer.add_event_handler(Events.STARTED, lambda _: print(\"Start training\"))\n\n# attach handler with args, kwargs\nmydata = [1, 2, 3, 4]\nlogger = ...\n\ndef on_training_ended(data):\n    print(f\"Training is ended. mydata={data}\")\n    # User can use variables from another scope\n    logger.info(\"Training is ended\")\n\n\ntrainer.add_event_handler(Events.COMPLETED, on_training_ended, mydata)\n# call any number of functions on a single event\ntrainer.add_event_handler(Events.COMPLETED, lambda engine: print(engine.state.times))\n\n@trainer.on(Events.ITERATION_COMPLETED)\ndef log_something(engine):\n    print(engine.state.output)\n```\n\n</details>\n\n### Built-in events filtering\n\n<details>\n<summary>\nExamples\n</summary>\n\n```python\n# run the validation every 5 epochs\n@trainer.on(Events.EPOCH_COMPLETED(every=5))\ndef run_validation():\n    # run validation\n\n# change some training variable once on 20th epoch\n@trainer.on(Events.EPOCH_STARTED(once=20))\ndef change_training_variable():\n    # ...\n\n# Trigger handler with customly defined frequency\n@trainer.on(Events.ITERATION_COMPLETED(event_filter=first_x_iters))\ndef log_gradients():\n    # ...\n```\n\n</details>\n\n### Stack events to share some actions\n\n<details>\n<summary>\nExamples\n</summary>\n\nEvents can be stacked together to enable multiple calls:\n\n```python\n@trainer.on(Events.COMPLETED | Events.EPOCH_COMPLETED(every=10))\ndef run_validation():\n    # ...\n```\n\n</details>\n\n### Custom events to go beyond standard events\n\n<details>\n<summary>\nExamples\n</summary>\n\nCustom events related to backward and optimizer step calls:\n\n```python\nfrom ignite.engine import EventEnum\n\n\nclass BackpropEvents(EventEnum):\n    BACKWARD_STARTED = 'backward_started'\n    BACKWARD_COMPLETED = 'backward_completed'\n    OPTIM_STEP_COMPLETED = 'optim_step_completed'\n\ndef update(engine, batch):\n    # ...\n    loss = criterion(y_pred, y)\n    engine.fire_event(BackpropEvents.BACKWARD_STARTED)\n    loss.backward()\n    engine.fire_event(BackpropEvents.BACKWARD_COMPLETED)\n    optimizer.step()\n    engine.fire_event(BackpropEvents.OPTIM_STEP_COMPLETED)\n    # ...\n\ntrainer = Engine(update)\ntrainer.register_events(*BackpropEvents)\n\n@trainer.on(BackpropEvents.BACKWARD_STARTED)\ndef function_before_backprop(engine):\n    # ...\n```\n\n- Complete snippet is found [here](https://pytorch.org/ignite/faq.html#creating-custom-events-based-on-forward-backward-pass).\n- Another use-case of custom events: [trainer for Truncated Backprop Through Time](https://pytorch.org/ignite/contrib/engines.html#ignite.contrib.engines.create_supervised_tbptt_trainer).\n\n</details>\n\n## Out-of-the-box metrics\n\n- [Metrics](https://pytorch.org/ignite/metrics.html#complete-list-of-metrics) for various tasks:\n  Precision, Recall, Accuracy, Confusion Matrix, IoU etc, ~20 [regression metrics](https://pytorch.org/ignite/metrics.html#complete-list-of-metrics).\n\n- Users can also [compose their metrics](https://pytorch.org/ignite/metrics.html#metric-arithmetics) with ease from\n  existing ones using arithmetic operations or torch methods.\n\n<details>\n<summary>\nExample\n</summary>\n\n```python\nprecision = Precision(average=False)\nrecall = Recall(average=False)\nF1_per_class = (precision * recall * 2 / (precision + recall))\nF1_mean = F1_per_class.mean()  # torch mean method\nF1_mean.attach(engine, \"F1\")\n```\n\n</details>\n\n<!-- ############################################################################################################### -->\n\n# Installation\n\nFrom [pip](https://pypi.org/project/pytorch-ignite/):\n\n```bash\npip install pytorch-ignite\n```\n\nFrom [conda](https://anaconda.org/pytorch/ignite):\n\n```bash\nconda install ignite -c pytorch\n```\n\nFrom source:\n\n```bash\npip install git+https://github.com/pytorch/ignite\n```\n\n## Nightly releases\n\nFrom pip:\n\n```bash\npip install --pre pytorch-ignite\n```\n\nFrom conda (this suggests to install [pytorch nightly release](https://anaconda.org/pytorch-nightly/pytorch) instead of stable\nversion as dependency):\n\n```bash\nconda install ignite -c pytorch-nightly\n```\n\n## Docker Images\n\n### Using pre-built images\n\nPull a pre-built docker image from [our Docker Hub](https://hub.docker.com/u/pytorchignite) and run it with docker v19.03+.\n\n```bash\ndocker run --gpus all -it -v $PWD:/workspace/project --network=host --shm-size 16G pytorchignite/base:latest /bin/bash\n```\n\n<details>\n\n<summary>\nList of available pre-built images\n</summary>\n\nBase\n\n- `pytorchignite/base:latest`\n- `pytorchignite/apex:latest`\n- `pytorchignite/hvd-base:latest`\n- `pytorchignite/hvd-apex:latest`\n- `pytorchignite/msdp-apex:latest`\n\nVision:\n\n- `pytorchignite/vision:latest`\n- `pytorchignite/hvd-vision:latest`\n- `pytorchignite/apex-vision:latest`\n- `pytorchignite/hvd-apex-vision:latest`\n- `pytorchignite/msdp-apex-vision:latest`\n\nNLP:\n\n- `pytorchignite/nlp:latest`\n- `pytorchignite/hvd-nlp:latest`\n- `pytorchignite/apex-nlp:latest`\n- `pytorchignite/hvd-apex-nlp:latest`\n- `pytorchignite/msdp-apex-nlp:latest`\n\n</details>\n\nFor more details, see [here](docker).\n\n<!-- ############################################################################################################### -->\n\n# Getting Started\n\nFew pointers to get you started:\n\n- [Quick Start Guide: Essentials of getting a project up and running](https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/)\n- [Concepts of the library: Engine, Events & Handlers, State, Metrics](https://pytorch-ignite.ai/concepts/)\n- Full-featured template examples (coming soon)\n\n<!-- ############################################################################################################### -->\n\n# Documentation\n\n- Stable API documentation and an overview of the library: https://pytorch.org/ignite/\n- Development version API documentation: https://pytorch.org/ignite/master/\n- [FAQ](https://pytorch.org/ignite/faq.html),\n  [\"Questions on Github\"](https://github.com/pytorch/ignite/issues?q=is%3Aissue+label%3Aquestion+) and\n  [\"Questions on Discuss.PyTorch\"](https://discuss.pytorch.org/c/ignite).\n- [Project's Roadmap](https://github.com/pytorch/ignite/wiki/Roadmap)\n\n## Additional Materials\n\n- [Distributed Training Made Easy with PyTorch-Ignite](https://labs.quansight.org/blog/2021/06/distributed-made-easy-with-ignite/)\n- [PyTorch Ecosystem Day 2021 Breakout session presentation](https://colab.research.google.com/drive/1qhUgWQ0N2U71IVShLpocyeY4AhlDCPRd)\n- [Tutorial blog post about PyTorch-Ignite](https://labs.quansight.org/blog/2020/09/pytorch-ignite/)\n- [8 Creators and Core Contributors Talk About Their Model Training Libraries From PyTorch Ecosystem](https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem?utm_source=reddit&utm_medium=post&utm_campaign=blog-model-training-libraries-pytorch-ecosystem)\n- Ignite Posters from Pytorch Developer Conferences:\n  - [2021](https://drive.google.com/file/d/1YXrkJIepPk_KltSG1ZfWRtA5IRgPFz_U)\n  - [2019](https://drive.google.com/open?id=1bqIl-EM6GCCCoSixFZxhIbuF25F2qTZg)\n  - [2018](https://drive.google.com/open?id=1_2vzBJ0KeCjGv1srojMHiJRvceSVbVR5)\n\n<!-- ############################################################################################################### -->\n\n# Examples\n\n## Tutorials\n\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/TextCNN.ipynb) [Text Classification using Convolutional Neural\n  Networks](https://github.com/pytorch/ignite/blob/master/examples/notebooks/TextCNN.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/VAE.ipynb) [Variational Auto\n  Encoders](https://github.com/pytorch/ignite/blob/master/examples/notebooks/VAE.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/FashionMNIST.ipynb) [Convolutional Neural Networks for Classifying Fashion-MNIST\n  Dataset](https://github.com/pytorch/ignite/blob/master/examples/notebooks/FashionMNIST.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/CycleGAN_with_nvidia_apex.ipynb) [Training Cycle-GAN on Horses to\n  Zebras with Nvidia/Apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/CycleGAN_with_nvidia_apex.ipynb) - [ logs on W&B](https://app.wandb.ai/vfdev-5/ignite-cyclegan-apex)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/CycleGAN_with_torch_cuda_amp.ipynb) [Another training Cycle-GAN on Horses to\n  Zebras with Native Torch CUDA AMP](https://github.com/pytorch/ignite/blob/master/examples/notebooks/CycleGAN_with_torch_cuda_amp.ipynb) - [logs on W&B](https://app.wandb.ai/vfdev-5/ignite-cyclegan-torch-amp)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/EfficientNet_Cifar100_finetuning.ipynb) [Finetuning EfficientNet-B0 on\n  CIFAR100](https://github.com/pytorch/ignite/blob/master/examples/notebooks/EfficientNet_Cifar100_finetuning.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/Cifar10_Ax_hyperparam_tuning.ipynb) [Hyperparameters tuning with\n  Ax](https://github.com/pytorch/ignite/blob/master/examples/notebooks/Cifar10_Ax_hyperparam_tuning.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/FastaiLRFinder_MNIST.ipynb) [Basic example of LR finder on\n  MNIST](https://github.com/pytorch/ignite/blob/master/examples/notebooks/FastaiLRFinder_MNIST.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/Cifar100_bench_amp.ipynb) [Benchmark mixed precision training on Cifar100:\n  torch.cuda.amp vs nvidia/apex](https://github.com/pytorch/ignite/blob/master/examples/notebooks/Cifar100_bench_amp.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/MNIST_on_TPU.ipynb) [MNIST training on a single\n  TPU](https://github.com/pytorch/ignite/blob/master/examples/notebooks/MNIST_on_TPU.ipynb)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1E9zJrptnLJ_PKhmaP5Vhb6DTVRvyrKHx) [CIFAR10 Training on multiple TPUs](https://github.com/pytorch/ignite/tree/master/examples/cifar10)\n- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/HandlersTimeProfiler_MNIST.ipynb) [Basic example of handlers\n  time profiling on MNIST training example](https://github.com/pytorch/ignite/blob/master/examples/notebooks/HandlersTimeProfiler_MNIST.ipynb)\n\n## Reproducible Training Examples\n\nInspired by [torchvision/references](https://github.com/pytorch/vision/tree/master/references),\nwe provide several reproducible baselines for vision tasks:\n\n- [ImageNet](examples/references/classification/imagenet) - logs on Ignite Trains server coming soon ...\n- [Pascal VOC2012](examples/references/segmentation/pascal_voc2012) - logs on Ignite Trains server coming soon ...\n\nFeatures:\n\n- Distributed training: native or horovod and using [PyTorch native AMP](https://pytorch.org/docs/stable/notes/amp_examples.html)\n\n## Code-Generator application\n\nThe easiest way to create your training scripts with PyTorch-Ignite:\n\n- https://code-generator.pytorch-ignite.ai/\n\n<!-- ############################################################################################################### -->\n\n# Communication\n\n- [GitHub issues](https://github.com/pytorch/ignite/issues): questions, bug reports, feature requests, etc.\n\n- [Discuss.PyTorch](https://discuss.pytorch.org/c/ignite), category \"Ignite\".\n\n- [PyTorch-Ignite Discord Server](https://discord.gg/djZtm3EmKj): to chat with the community\n\n- [GitHub Discussions](https://github.com/pytorch/ignite/discussions): general library-related discussions, ideas, Q&A, etc.\n\n## User feedback\n\nWe have created a form for [\"user feedback\"](https://github.com/pytorch/ignite/issues/new/choose). We\nappreciate any type of feedback, and this is how we would like to see our\ncommunity:\n\n- If you like the project and want to say thanks, this the right\n  place.\n- If you do not like something, please, share it with us, and we can\n  see how to improve it.\n\nThank you!\n\n<!-- ############################################################################################################### -->\n\n# Contributing\n\nPlease see the [contribution guidelines](https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md) for more information.\n\nAs always, PRs are welcome :)\n\n<!-- ############################################################################################################### -->\n\n# Projects using Ignite\n\n<details>\n\n<summary>\nResearch papers\n</summary>\n\n- [BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning](https://github.com/BlackHC/BatchBALD)\n- [A Model to Search for Synthesizable Molecules](https://github.com/john-bradshaw/molecule-chef)\n- [Localised Generative Flows](https://github.com/jrmcornish/lgf)\n- [Extracting T Cell Function and Differentiation Characteristics from the Biomedical Literature](https://github.com/hammerlab/t-cell-relation-extraction)\n- [Variational Information Distillation for Knowledge Transfer](https://github.com/amzn/xfer/tree/master/var_info_distil)\n- [XPersona: Evaluating Multilingual Personalized Chatbot](https://github.com/HLTCHKUST/Xpersona)\n- [CNN-CASS: CNN for Classification of Coronary Artery Stenosis Score in MPR Images](https://github.com/ucuapps/CoronaryArteryStenosisScoreClassification)\n- [Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog](https://github.com/ictnlp/DSTC8-AVSD)\n- [Adversarial Decomposition of Text Representation](https://github.com/text-machine-lab/adversarial_decomposition)\n- [Uncertainty Estimation Using a Single Deep Deterministic Neural Network](https://github.com/y0ast/deterministic-uncertainty-quantification)\n- [DeepSphere: a graph-based spherical CNN](https://github.com/deepsphere/deepsphere-pytorch)\n- [Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment](https://github.com/lidq92/LinearityIQA)\n- [Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets Training](https://github.com/lidq92/MDTVSFA)\n- [Deep Signature Transforms](https://github.com/patrick-kidger/Deep-Signature-Transforms)\n- [Neural CDEs for Long Time-Series via the Log-ODE Method](https://github.com/jambo6/neuralCDEs-via-logODEs)\n- [Volumetric Grasping Network](https://github.com/ethz-asl/vgn)\n- [Mood Classification using Listening Data](https://github.com/fdlm/listening-moods)\n- [Deterministic Uncertainty Estimation (DUE)](https://github.com/y0ast/DUE)\n- [PyTorch-Hebbian: facilitating local learning in a deep learning framework](https://github.com/Joxis/pytorch-hebbian)\n- [Stochastic Weight Matrix-Based Regularization Methods for Deep Neural Networks](https://github.com/rpatrik96/lod-wmm-2019)\n- [Learning explanations that are hard to vary](https://github.com/gibipara92/learning-explanations-hard-to-vary)\n- [The role of disentanglement in generalisation](https://github.com/mmrl/disent-and-gen)\n- [A Probabilistic Programming Approach to Protein Structure Superposition](https://github.com/LysSanzMoreta/Theseus-PP)\n- [PadChest: A large chest x-ray image dataset with multi-label annotated reports](https://github.com/auriml/Rx-thorax-automatic-captioning)\n\n</details>\n\n<details>\n\n<summary>\nBlog articles, tutorials, books\n</summary>\n\n- [State-of-the-Art Conversational AI with Transfer Learning](https://github.com/huggingface/transfer-learning-conv-ai)\n- [Tutorial on Transfer Learning in NLP held at NAACL 2019](https://github.com/huggingface/naacl_transfer_learning_tutorial)\n- [Deep-Reinforcement-Learning-Hands-On-Second-Edition, published by Packt](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition)\n- [Once Upon a Repository: How to Write Readable, Maintainable Code with PyTorch](https://towardsdatascience.com/once-upon-a-repository-how-to-write-readable-maintainable-code-with-pytorch-951f03f6a829)\n- [The Hero Rises: Build Your Own SSD](https://allegro.ai/blog/the-hero-rises-build-your-own-ssd/)\n- [Using Optuna to Optimize PyTorch Ignite Hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-ignite-hyperparameters-626ffe6d4783)\n- [PyTorch Ignite - Classifying Tiny ImageNet with EfficientNet](https://towardsdatascience.com/pytorch-ignite-classifying-tiny-imagenet-with-efficientnet-e5b1768e5e8f)\n\n</details>\n\n<details>\n\n<summary>\nToolkits\n</summary>\n\n- [Project MONAI - AI Toolkit for Healthcare Imaging](https://github.com/Project-MONAI/MONAI)\n- [DeepSeismic - Deep Learning for Seismic Imaging and Interpretation](https://github.com/microsoft/seismic-deeplearning)\n- [Nussl - a flexible, object-oriented Python audio source separation library](https://github.com/nussl/nussl)\n- [PyTorch Adapt - A fully featured and modular domain adaptation library](https://github.com/KevinMusgrave/pytorch-adapt)\n- [gnina-torch: PyTorch implementation of GNINA scoring function](https://github.com/RMeli/gnina-torch)\n\n</details>\n\n<details>\n\n<summary>\nOthers\n</summary>\n\n- [Implementation of \"Attention is All You Need\" paper](https://github.com/akurniawan/pytorch-transformer)\n- [Implementation of DropBlock: A regularization method for convolutional networks in PyTorch](https://github.com/miguelvr/dropblock)\n- [Kaggle Kuzushiji Recognition: 2nd place solution](https://github.com/lopuhin/kaggle-kuzushiji-2019)\n- [Unsupervised Data Augmentation experiments in PyTorch](https://github.com/vfdev-5/UDA-pytorch)\n- [Hyperparameters tuning with Optuna](https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_ignite_simple.py)\n- [Logging with ChainerUI](https://chainerui.readthedocs.io/en/latest/reference/module.html#external-library-support)\n- [FixMatch experiments in PyTorch and Ignite (CTA dataaug policy)](https://github.com/vfdev-5/FixMatch-pytorch)\n- [Kaggle Birdcall Identification Competition: 1st place solution](https://github.com/ryanwongsa/kaggle-birdsong-recognition)\n- [Logging with Aim - An open-source experiment tracker](https://aimstack.readthedocs.io/en/latest/quick_start/integrations.html#integration-with-pytorch-ignite)\n\n</details>\n\nSee other projects at [\"Used by\"](https://github.com/pytorch/ignite/network/dependents?package_id=UGFja2FnZS02NzI5ODEwNA%3D%3D)\n\nIf your project implements a paper, represents other use-cases not\ncovered in our official tutorials, Kaggle competition's code, or just\nyour code presents interesting results and uses Ignite. We would like to\nadd your project to this list, so please send a PR with brief\ndescription of the project.\n\n<!-- ############################################################################################################### -->\n\n# Citing Ignite\n\nIf you use PyTorch-Ignite in a scientific publication, we would appreciate citations to our project.\n\n```\n@misc{pytorch-ignite,\n  author = {V. Fomin and J. Anmol and S. Desroziers and J. Kriss and A. Tejani},\n  title = {High-level library to help with training neural networks in PyTorch},\n  year = {2020},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/pytorch/ignite}},\n}\n```\n\n<!-- ############################################################################################################### -->\n\n# About the team & Disclaimer\n\nPyTorch-Ignite is a [NumFOCUS Affiliated Project](https://www.numfocus.org/), operated and maintained by volunteers in the PyTorch community in their capacities as individuals\n(and not as representatives of their employers). See the [\"About us\"](https://pytorch-ignite.ai/about/community/#about-us)\npage for a list of core contributors. For usage questions and issues, please see the various channels\n[here](#communication). For all other questions and inquiries, please send an email\nto contact@pytorch-ignite.ai.\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.2138671875,
          "content": "coverage:\n  precision: 2\n  round: down\n  range: \"95...100\"\n  status:\n    patch:\n      default:\n        target: 90\n    project:\n      default:\n        threshold: 1%\n    changes: false\ncomment: false\nignore:\n  - \"tests/\"\n"
        },
        {
          "name": "conda.recipe",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "ignite",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 1.6328125,
          "content": "[mypy]\nfiles = ignite\npretty = True\nshow_error_codes = True\n\ncheck_untyped_defs = True\n; a lot of work needed to fix issues\ndisallow_any_generics = False\ndisallow_incomplete_defs = True\ndisallow_subclassing_any = True\n; due to missing types in pytorch set to False\ndisallow_untyped_calls = False\ndisallow_untyped_decorators = True\ndisallow_untyped_defs = True\nno_implicit_optional = True\n; would need a more precise import of pytorch classes and methods, which is not possible, therefore set to False\nno_implicit_reexport = False\nstrict_equality = True\nwarn_redundant_casts = True\n; due to missing types in multiple libs set to False\nwarn_return_any = False\n; results in too many false positives, therefore set to False\nwarn_unreachable = False\nwarn_unused_configs = True\nwarn_unused_ignores = True\n\n[mypy-apex.*]\nignore_missing_imports = True\n\n[mypy-clearml.*]\nignore_missing_imports = True\n\n[mypy-horovod.*]\nignore_missing_imports = True\n\n[mypy-matplotlib.*]\nignore_missing_imports = True\n\n[mypy-mlflow.*]\nignore_missing_imports = True\n\n[mypy-neptune.*]\nignore_missing_imports = True\n\n[mypy-numpy.*]\nignore_missing_imports = True\n\n[mypy-pandas.*]\nignore_missing_imports = True\n\n[mypy-sklearn.*]\nignore_missing_imports = True\n\n[mypy-polyaxon.*]\nignore_missing_imports = True\n\n[mypy-polyaxon_client.*]\nignore_missing_imports = True\n\n[mypy-pynvml.*]\nignore_missing_imports = True\n\n[mypy-tensorboardX.*]\nignore_missing_imports = True\n\n[mypy-torch_xla.*]\nignore_missing_imports = True\n\n[mypy-trains.*]\nignore_missing_imports = True\n\n[mypy-tqdm.*]\nignore_missing_imports = True\n\n[mypy-scipy.*]\nignore_missing_imports = True\n\n[mypy-torchvision.*]\nignore_missing_imports = True\n"
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.7451171875,
          "content": "[tool.black]\nline-length = 120\ntarget-version = ['py39', 'py311']\ninclude = '\\.pyi?$'\nexclude = '''\n\n(\n  /(\n      \\.eggs         # exclude a few common directories in the\n    | \\.git          # root of the project\n    | \\.hg\n    | \\.mypy_cache\n    | \\.tox\n    | \\.venv\n    | _build\n    | buck-out\n    | build\n    | dist\n    | assets\n  )/\n  | foo.py           # also separately exclude a file named foo.py in\n                     # the root of the project\n)\n'''\n\n[tool.usort.known]\nfirst_party = [\n    \"ignite\",\n]\nthird_party = [\n    \"clearml\",\n    \"dill\",\n    \"matplotlib\",\n    \"numpy\",\n    \"pkg_resources\",\n    \"pytest\",\n    \"requests\",\n    \"setuptools\",\n    \"skimage\",\n    \"sklearn\",\n    \"torch\",\n    \"torchvision\",\n]\n\n[tool.ufmt]\nexcludes = [\n    \"assets/\",\n]\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.615234375,
          "content": "# Tests\nnumpy\npytest\npytest-cov\npytest-xdist\npytest-timeout\ndill\nfilelock\nsetuptools\n# Test contrib dependencies\nscipy\npytorch_fid\ntqdm\nscikit-learn\nmatplotlib\ntensorboardX\nvisdom\npolyaxon\nwandb\nmlflow\nneptune-client>=0.16.17\ntensorboard\ntorchvision\npynvml<12  # pynvml module was removed in 12.X, is not developed or maintained. We should replace pynvml with something else.\nclearml\nscikit-image\npy-rouge\n# temporary fix for python=3.12 and v3.8.1\n# nltk\ngit+https://github.com/nltk/nltk@aba99c8\n# Examples dependencies\npandas\ngymnasium\n# temporary fix: E   AttributeError: module 'mpmath' has no attribute 'rational'\nmpmath<1.4\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.751953125,
          "content": "[metadata]\nlicense_files = LICENSE\n\n[pycodestyle]\nexclude = .eggs,*.egg,build,docs/*,.git,versioneer.py,*/conf.py\nignore = E402, E721\nmax_line_length = 120\n\n[isort]\nknown_third_party=clearml,dill,matplotlib,numpy,pkg_resources,pytest,requests,setuptools,skimage,sklearn,torch,torchvision\nmulti_line_output=3\ninclude_trailing_comma=True\nforce_grid_wrap=0\nuse_parentheses=True\nline_length=120\nskip_glob=docs/**\nfilter_files=True\nprofile=black\n\n[flake8]\nmax-line-length = 120\nignore = E722,E203,E231,F841,W503,F403,E402\nper-file-ignores = __init__.py: F401\n\n[tool:pytest]\nmarkers =\n    distributed: mark a test with distributed option\n    multinode_distributed: mark a test with multi-node distributed option\n    tpu: mark a test as requiring XLA\naddopts =\n    --color=yes\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 1.279296875,
          "content": "import io\nimport os\nimport re\n\nfrom setuptools import find_packages, setup\n\n\ndef read(*names, **kwargs):\n    with io.open(os.path.join(os.path.dirname(__file__), *names), encoding=kwargs.get(\"encoding\", \"utf8\")) as fp:\n        return fp.read()\n\n\ndef find_version(*file_paths):\n    version_file = read(*file_paths)\n    version_match = re.search(r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\", version_file, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(\"Unable to find version string.\")\n\n\nreadme = read(\"README.md\").replace(\n    'src=\"assets/', 'src=\"https://raw.githubusercontent.com/pytorch/ignite/master/assets/'\n)\n\nVERSION = find_version(\"ignite\", \"__init__.py\")\n\nrequirements = [\"torch>=1.3,<3\", \"packaging\"]\n\nsetup(\n    # Metadata\n    name=\"pytorch-ignite\",\n    version=VERSION,\n    author=\"PyTorch-Ignite Team\",\n    author_email=\"contact@pytorch-ignite.ai\",\n    url=\"https://github.com/pytorch/ignite\",\n    description=\"A lightweight library to help with training neural networks in PyTorch.\",\n    long_description_content_type=\"text/markdown\",\n    long_description=readme,\n    license=\"BSD\",\n    # Package info\n    packages=find_packages(exclude=(\"tests\", \"tests.*\")),\n    package_data={\"ignite\": [\"py.typed\"]},\n    zip_safe=False,\n    install_requires=requirements,\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}