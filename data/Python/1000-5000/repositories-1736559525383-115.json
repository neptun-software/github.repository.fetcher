{
  "metadata": {
    "timestamp": 1736559525383,
    "page": 115,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "lorenzodifuccia/safaribooks",
      "stars": 4703,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.1015625,
          "content": ".idea/\n.vscode/\n.DS_Store\n\n__pycache__/\n.venv/\n.env/\n\nBooks/\n\ncookies.json\n*.log\n*.txt\n*.code-workspace\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 0.4716796875,
          "content": "            DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n                    Version 2, December 2004\n\n Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n\n Everyone is permitted to copy and distribute verbatim or modified\n copies of this license document, and changing it is allowed as long\n as the name is changed.\n\n            DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n\n  0. You just DO WHAT THE FUCK YOU WANT TO.\n"
        },
        {
          "name": "Pipfile",
          "type": "blob",
          "size": 0.19140625,
          "content": "[[source]]\n\nurl = \"https://pypi.python.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\nurllib3 = \">=1.26.5\"\n\nlxml = \"*\"\nrequests = \"*\"\n\n[dev-packages]\n\n\n[requires]\n\npython_version = \"3.6\"\n"
        },
        {
          "name": "Pipfile.lock",
          "type": "blob",
          "size": 8.404296875,
          "content": "{\n    \"_meta\": {\n        \"hash\": {\n            \"sha256\": \"757b53b537f003a11d2cd5852e5d2e5ee83d6d25452b472e10bba32aadf849e6\"\n        },\n        \"pipfile-spec\": 6,\n        \"requires\": {\n            \"python_version\": \"3.6\"\n        },\n        \"sources\": [\n            {\n                \"name\": \"pypi\",\n                \"url\": \"https://pypi.python.org/simple\",\n                \"verify_ssl\": true\n            }\n        ]\n    },\n    \"default\": {\n        \"certifi\": {\n            \"hashes\": [\n                \"sha256:84c85a9078b11105f04f3036a9482ae10e4621616db313fe045dd24743a0820d\",\n                \"sha256:fe86415d55e84719d75f8b69414f6438ac3547d2078ab91b67e779ef69378412\"\n            ],\n            \"markers\": \"python_version >= '3.6'\",\n            \"version\": \"==2022.6.15\"\n        },\n        \"charset-normalizer\": {\n            \"hashes\": [\n                \"sha256:2857e29ff0d34db842cd7ca3230549d1a697f96ee6d3fb071cfa6c7393832597\",\n                \"sha256:6881edbebdb17b39b4eaaa821b438bf6eddffb4468cf344f09f89def34a8b1df\"\n            ],\n            \"markers\": \"python_version >= '3'\",\n            \"version\": \"==2.0.12\"\n        },\n        \"idna\": {\n            \"hashes\": [\n                \"sha256:84d9dd047ffa80596e0f246e2eab0b391788b0503584e8945f2368256d2735ff\",\n                \"sha256:9d643ff0a55b762d5cdb124b8eaa99c66322e2157b69160bc32796e824360e6d\"\n            ],\n            \"markers\": \"python_version >= '3'\",\n            \"version\": \"==3.3\"\n        },\n        \"lxml\": {\n            \"hashes\": [\n                \"sha256:04da965dfebb5dac2619cb90fcf93efdb35b3c6994fea58a157a834f2f94b318\",\n                \"sha256:0538747a9d7827ce3e16a8fdd201a99e661c7dee3c96c885d8ecba3c35d1032c\",\n                \"sha256:0645e934e940107e2fdbe7c5b6fb8ec6232444260752598bc4d09511bd056c0b\",\n                \"sha256:079b68f197c796e42aa80b1f739f058dcee796dc725cc9a1be0cdb08fc45b000\",\n                \"sha256:0f3f0059891d3254c7b5fb935330d6db38d6519ecd238ca4fce93c234b4a0f73\",\n                \"sha256:10d2017f9150248563bb579cd0d07c61c58da85c922b780060dcc9a3aa9f432d\",\n                \"sha256:1355755b62c28950f9ce123c7a41460ed9743c699905cbe664a5bcc5c9c7c7fb\",\n                \"sha256:13c90064b224e10c14dcdf8086688d3f0e612db53766e7478d7754703295c7c8\",\n                \"sha256:1423631e3d51008871299525b541413c9b6c6423593e89f9c4cfbe8460afc0a2\",\n                \"sha256:1436cf0063bba7888e43f1ba8d58824f085410ea2025befe81150aceb123e345\",\n                \"sha256:1a7c59c6ffd6ef5db362b798f350e24ab2cfa5700d53ac6681918f314a4d3b94\",\n                \"sha256:1e1cf47774373777936c5aabad489fef7b1c087dcd1f426b621fda9dcc12994e\",\n                \"sha256:206a51077773c6c5d2ce1991327cda719063a47adc02bd703c56a662cdb6c58b\",\n                \"sha256:21fb3d24ab430fc538a96e9fbb9b150029914805d551deeac7d7822f64631dfc\",\n                \"sha256:27e590352c76156f50f538dbcebd1925317a0f70540f7dc8c97d2931c595783a\",\n                \"sha256:287605bede6bd36e930577c5925fcea17cb30453d96a7b4c63c14a257118dbb9\",\n                \"sha256:2aaf6a0a6465d39b5ca69688fce82d20088c1838534982996ec46633dc7ad6cc\",\n                \"sha256:32a73c53783becdb7eaf75a2a1525ea8e49379fb7248c3eeefb9412123536387\",\n                \"sha256:41fb58868b816c202e8881fd0f179a4644ce6e7cbbb248ef0283a34b73ec73bb\",\n                \"sha256:4780677767dd52b99f0af1f123bc2c22873d30b474aa0e2fc3fe5e02217687c7\",\n                \"sha256:4878e667ebabe9b65e785ac8da4d48886fe81193a84bbe49f12acff8f7a383a4\",\n                \"sha256:487c8e61d7acc50b8be82bda8c8d21d20e133c3cbf41bd8ad7eb1aaeb3f07c97\",\n                \"sha256:4beea0f31491bc086991b97517b9683e5cfb369205dac0148ef685ac12a20a67\",\n                \"sha256:4cfbe42c686f33944e12f45a27d25a492cc0e43e1dc1da5d6a87cbcaf2e95627\",\n                \"sha256:4d5bae0a37af799207140652a700f21a85946f107a199bcb06720b13a4f1f0b7\",\n                \"sha256:4e285b5f2bf321fc0857b491b5028c5f276ec0c873b985d58d7748ece1d770dd\",\n                \"sha256:57e4d637258703d14171b54203fd6822fda218c6c2658a7d30816b10995f29f3\",\n                \"sha256:5974895115737a74a00b321e339b9c3f45c20275d226398ae79ac008d908bff7\",\n                \"sha256:5ef87fca280fb15342726bd5f980f6faf8b84a5287fcc2d4962ea8af88b35130\",\n                \"sha256:603a464c2e67d8a546ddaa206d98e3246e5db05594b97db844c2f0a1af37cf5b\",\n                \"sha256:6653071f4f9bac46fbc30f3c7838b0e9063ee335908c5d61fb7a4a86c8fd2036\",\n                \"sha256:6ca2264f341dd81e41f3fffecec6e446aa2121e0b8d026fb5130e02de1402785\",\n                \"sha256:6d279033bf614953c3fc4a0aa9ac33a21e8044ca72d4fa8b9273fe75359d5cca\",\n                \"sha256:6d949f53ad4fc7cf02c44d6678e7ff05ec5f5552b235b9e136bd52e9bf730b91\",\n                \"sha256:6daa662aba22ef3258934105be2dd9afa5bb45748f4f702a3b39a5bf53a1f4dc\",\n                \"sha256:6eafc048ea3f1b3c136c71a86db393be36b5b3d9c87b1c25204e7d397cee9536\",\n                \"sha256:830c88747dce8a3e7525defa68afd742b4580df6aa2fdd6f0855481e3994d391\",\n                \"sha256:86e92728ef3fc842c50a5cb1d5ba2bc66db7da08a7af53fb3da79e202d1b2cd3\",\n                \"sha256:8caf4d16b31961e964c62194ea3e26a0e9561cdf72eecb1781458b67ec83423d\",\n                \"sha256:8d1a92d8e90b286d491e5626af53afef2ba04da33e82e30744795c71880eaa21\",\n                \"sha256:8f0a4d179c9a941eb80c3a63cdb495e539e064f8054230844dcf2fcb812b71d3\",\n                \"sha256:9232b09f5efee6a495a99ae6824881940d6447debe272ea400c02e3b68aad85d\",\n                \"sha256:927a9dd016d6033bc12e0bf5dee1dde140235fc8d0d51099353c76081c03dc29\",\n                \"sha256:93e414e3206779ef41e5ff2448067213febf260ba747fc65389a3ddaa3fb8715\",\n                \"sha256:98cafc618614d72b02185ac583c6f7796202062c41d2eeecdf07820bad3295ed\",\n                \"sha256:9c3a88d20e4fe4a2a4a84bf439a5ac9c9aba400b85244c63a1ab7088f85d9d25\",\n                \"sha256:9f36de4cd0c262dd9927886cc2305aa3f2210db437aa4fed3fb4940b8bf4592c\",\n                \"sha256:a60f90bba4c37962cbf210f0188ecca87daafdf60271f4c6948606e4dabf8785\",\n                \"sha256:a614e4afed58c14254e67862456d212c4dcceebab2eaa44d627c2ca04bf86837\",\n                \"sha256:ae06c1e4bc60ee076292e582a7512f304abdf6c70db59b56745cca1684f875a4\",\n                \"sha256:b122a188cd292c4d2fcd78d04f863b789ef43aa129b233d7c9004de08693728b\",\n                \"sha256:b570da8cd0012f4af9fa76a5635cd31f707473e65a5a335b186069d5c7121ff2\",\n                \"sha256:bcaa1c495ce623966d9fc8a187da80082334236a2a1c7e141763ffaf7a405067\",\n                \"sha256:bd34f6d1810d9354dc7e35158aa6cc33456be7706df4420819af6ed966e85448\",\n                \"sha256:be9eb06489bc975c38706902cbc6888f39e946b81383abc2838d186f0e8b6a9d\",\n                \"sha256:c4b2e0559b68455c085fb0f6178e9752c4be3bba104d6e881eb5573b399d1eb2\",\n                \"sha256:c62e8dd9754b7debda0c5ba59d34509c4688f853588d75b53c3791983faa96fc\",\n                \"sha256:c852b1530083a620cb0de5f3cd6826f19862bafeaf77586f1aef326e49d95f0c\",\n                \"sha256:d9fc0bf3ff86c17348dfc5d322f627d78273eba545db865c3cd14b3f19e57fa5\",\n                \"sha256:dad7b164905d3e534883281c050180afcf1e230c3d4a54e8038aa5cfcf312b84\",\n                \"sha256:e5f66bdf0976ec667fc4594d2812a00b07ed14d1b44259d19a41ae3fff99f2b8\",\n                \"sha256:e8f0c9d65da595cfe91713bc1222af9ecabd37971762cb830dea2fc3b3bb2acf\",\n                \"sha256:edffbe3c510d8f4bf8640e02ca019e48a9b72357318383ca60e3330c23aaffc7\",\n                \"sha256:eea5d6443b093e1545ad0210e6cf27f920482bfcf5c77cdc8596aec73523bb7e\",\n                \"sha256:ef72013e20dd5ba86a8ae1aed7f56f31d3374189aa8b433e7b12ad182c0d2dfb\",\n                \"sha256:f05251bbc2145349b8d0b77c0d4e5f3b228418807b1ee27cefb11f69ed3d233b\",\n                \"sha256:f1be258c4d3dc609e654a1dc59d37b17d7fef05df912c01fc2e15eb43a9735f3\",\n                \"sha256:f9ced82717c7ec65a67667bb05865ffe38af0e835cdd78728f1209c8fffe0cad\",\n                \"sha256:fe17d10b97fdf58155f858606bddb4e037b805a60ae023c009f760d8361a4eb8\",\n                \"sha256:fe749b052bb7233fe5d072fcb549221a8cb1a16725c47c37e42b0b9cb3ff2c3f\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==4.9.1\"\n        },\n        \"requests\": {\n            \"hashes\": [\n                \"sha256:6c1246513ecd5ecd4528a0906f910e8f0f9c6b8ec72030dc9fd154dc1a6efd24\",\n                \"sha256:b8aa58f8cf793ffd8782d3d8cb19e66ef36f7aba4353eec859e74678b01b07a7\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==2.26.0\"\n        },\n        \"urllib3\": {\n            \"hashes\": [\n                \"sha256:39fb8672126159acb139a7718dd10806104dec1e2f0f6c88aab05d17df10c8d4\",\n                \"sha256:f57b4c16c62fa2760b7e3d97c35b255512fb6b59a259730f36ba32ce9f8e342f\"\n            ],\n            \"index\": \"pypi\",\n            \"version\": \"==1.26.6\"\n        }\n    },\n    \"develop\": {}\n}\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 9.87890625,
          "content": "# SafariBooks\nDownload and generate *EPUB* of your favorite books from [*Safari Books Online*](https://www.safaribooksonline.com) library.  \nI'm not responsible for the use of this program, this is only for *personal* and *educational* purpose.  \nBefore any usage please read the *O'Reilly*'s [Terms of Service](https://learning.oreilly.com/terms/).  \n\n<a href='https://ko-fi.com/lorenz0x00' target='_blank'><img height='35' style='border:0px;height:46px;' src='https://az743702.vo.msecnd.net/cdn/kofi3.png?v=0' border='0' alt='Buy Me a Coffee at ko-fi.com' />\n\n## ✨✨ *Attention needed* ✨✨\n- This project is no longer actively maintained.  \n- *Login through `safaribooks` no longer works due to changes in ORLY APIs.*\n- *The program needs a major refactor to include new features and integrate new APIs.*\n- **However... it still work for downloading books.**  \n(Use SSO hack: log in via browser, then copy cookies into `cookies.json`, see below and issues. Love ❤️)\n\n---\n\n## Overview:\n  * [Requirements & Setup](#requirements--setup)\n  * [Usage](#usage)\n  * [Single Sign-On (SSO), Company, University Login](https://github.com/lorenzodifuccia/safaribooks/issues/150#issuecomment-555423085)\n  * [Calibre EPUB conversion](https://github.com/lorenzodifuccia/safaribooks#calibre-epub-conversion)\n  * [Example: Download *Test-Driven Development with Python, 2nd Edition*](#download-test-driven-development-with-python-2nd-edition)\n  * [Example: Use or not the `--kindle` option](#use-or-not-the---kindle-option)\n\n## Requirements & Setup:\nFirst of all, it requires `python3` and `pip3` or `pipenv` to be installed.  \n```shell\n$ git clone https://github.com/lorenzodifuccia/safaribooks.git\nCloning into 'safaribooks'...\n\n$ cd safaribooks/\n$ pip3 install -r requirements.txt\n\nOR\n\n$ pipenv install && pipenv shell\n```  \n\nThe program depends of only two **Python _3_** modules:\n```python3\nlxml>=4.1.1\nrequests>=2.20.0\n```\n  \n## Usage:\nIt's really simple to use, just choose a book from the library and replace in the following command:\n  * X-es with its ID, \n  * `email:password` with your own. \n\n```shell\n$ python3 safaribooks.py --cred \"account_mail@mail.com:password01\" XXXXXXXXXXXXX\n```\n\nThe ID is the digits that you find in the URL of the book description page:  \n`https://www.safaribooksonline.com/library/view/book-name/XXXXXXXXXXXXX/`  \nLike: `https://www.safaribooksonline.com/library/view/test-driven-development-with/9781491958698/`  \n  \n#### Program options:\n```shell\n$ python3 safaribooks.py --help\nusage: safaribooks.py [--cred <EMAIL:PASS> | --login] [--no-cookies]\n                      [--kindle] [--preserve-log] [--help]\n                      <BOOK ID>\n\nDownload and generate an EPUB of your favorite books from Safari Books Online.\n\npositional arguments:\n  <BOOK ID>            Book digits ID that you want to download. You can find\n                       it in the URL (X-es):\n                       `https://learning.oreilly.com/library/view/book-\n                       name/XXXXXXXXXXXXX/`\n\noptional arguments:\n  --cred <EMAIL:PASS>  Credentials used to perform the auth login on Safari\n                       Books Online. Es. ` --cred\n                       \"account_mail@mail.com:password01\" `.\n  --login              Prompt for credentials used to perform the auth login\n                       on Safari Books Online.\n  --no-cookies         Prevent your session data to be saved into\n                       `cookies.json` file.\n  --kindle             Add some CSS rules that block overflow on `table` and\n                       `pre` elements. Use this option if you're going to\n                       export the EPUB to E-Readers like Amazon Kindle.\n  --preserve-log       Leave the `info_XXXXXXXXXXXXX.log` file even if there\n                       isn't any error.\n  --help               Show this help message.\n```\n  \nThe first time you use the program, you'll have to specify your Safari Books Online account credentials (look [`here`](/../../issues/15) for special character).  \nThe next times you'll download a book, before session expires, you can omit the credential, because the program save your session cookies in a file called `cookies.json`.  \nFor **SSO**, please use the `sso_cookies.py` program in order to create the `cookies.json` file from the SSO cookies retrieved by your browser session (please follow [`these steps`](/../../issues/150#issuecomment-555423085)).  \n  \nPay attention if you use a shared PC, because everyone that has access to your files can steal your session. \nIf you don't want to cache the cookies, just use the `--no-cookies` option and provide all time your credential through the `--cred` option or the more safe `--login` one: this will prompt you for credential during the script execution.\n\nYou can configure proxies by setting on your system the environment variable `HTTPS_PROXY` or using the `USE_PROXY` directive into the script.\n\n#### Calibre EPUB conversion\n**Important**: since the script only download HTML pages and create a raw EPUB, many of the CSS and XML/HTML directives are wrong for an E-Reader. To ensure best quality of the output, I suggest you to always convert the `EPUB` obtained by the script to standard-`EPUB` with [Calibre](https://calibre-ebook.com/).\nYou can also use the command-line version of Calibre with `ebook-convert`, e.g.:\n```bash\n$ ebook-convert \"XXXX/safaribooks/Books/Test-Driven Development with Python 2nd Edition (9781491958698)/9781491958698.epub\" \"XXXX/safaribooks/Books/Test-Driven Development with Python 2nd Edition (9781491958698)/9781491958698_CLEAR.epub\"\n```\nAfter the execution, you can read the `9781491958698_CLEAR.epub` in every E-Reader and delete all other files.\n\nThe program offers also an option to ensure best compatibilities for who wants to export the `EPUB` to E-Readers like Amazon Kindle: `--kindle`, it blocks overflow on `table` and `pre` elements (see [example](#use-or-not-the---kindle-option)).  \nIn this case, I suggest you to convert the `EPUB` to `AZW3` with Calibre or to `MOBI`, remember in this case to select `Ignore margins` in the conversion options:  \n  \n![Calibre IgnoreMargins](https://github.com/lorenzodifuccia/cloudflare/raw/master/Images/safaribooks/safaribooks_calibre_IgnoreMargins.png \"Select Ignore margins\")  \n  \n## Examples:\n  * ## Download [Test-Driven Development with Python, 2nd Edition](https://www.safaribooksonline.com/library/view/test-driven-development-with/9781491958698/):  \n    ```shell\n    $ python3 safaribooks.py --cred \"my_email@gmail.com:MyPassword1!\" 9781491958698\n\n           ____     ___         _ \n          / __/__ _/ _/__ _____(_)\n         _\\ \\/ _ `/ _/ _ `/ __/ / \n        /___/\\_,_/_/ \\_,_/_/ /_/  \n          / _ )___  ___  / /__ ___\n         / _  / _ \\/ _ \\/  '_/(_-<\n        /____/\\___/\\___/_/\\_\\/___/\n\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n    [-] Logging into Safari Books Online...\n    [*] Retrieving book info... \n    [-] Title: Test-Driven Development with Python, 2nd Edition                     \n    [-] Authors: Harry J.W. Percival                                                \n    [-] Identifier: 9781491958698                                                   \n    [-] ISBN: 9781491958704                                                         \n    [-] Publishers: O'Reilly Media, Inc.                                            \n    [-] Rights: Copyright © O'Reilly Media, Inc.                                    \n    [-] Description: By taking you through the development of a real web application \n    from beginning to end, the second edition of this hands-on guide demonstrates the \n    practical advantages of test-driven development (TDD) with Python. You’ll learn \n    how to write and run tests before building each part of your app, and then develop\n    the minimum amount of code required to pass those tests. The result? Clean code\n    that works.In the process, you’ll learn the basics of Django, Selenium, Git, \n    jQuery, and Mock, along with curre...\n    [-] Release Date: 2017-08-18\n    [-] URL: https://learning.oreilly.com/library/view/test-driven-development-with/9781491958698/\n    [*] Retrieving book chapters...                                                 \n    [*] Output directory:                                                           \n        /XXXX/safaribooks/Books/Test-Driven Development with Python 2nd Edition (9781491958698)\n    [-] Downloading book contents... (53 chapters)                                  \n        [#####################################################################] 100%\n    [-] Downloading book CSSs... (2 files)                                          \n        [#####################################################################] 100%\n    [-] Downloading book images... (142 files)                                      \n        [#####################################################################] 100%\n    [-] Creating EPUB file...                                                       \n    [*] Done: /XXXX/safaribooks/Books/Test-Driven Development with Python 2nd Edition \n    (9781491958698)/9781491958698.epub\n    \n        If you like it, please * this project on GitHub to make it known:\n            https://github.com/lorenzodifuccia/safaribooks\n        e don't forget to renew your Safari Books Online subscription:\n            https://learning.oreilly.com\n    \n    [!] Bye!!\n    ```  \n     The result will be (opening the `EPUB` file with Calibre):  \n\n    ![Book Appearance](https://github.com/lorenzodifuccia/cloudflare/raw/master/Images/safaribooks/safaribooks_example01_TDD.png \"Book opened with Calibre\")  \n \n  * ## Use or not the `--kindle` option:\n    ```bash\n    $ python3 safaribooks.py --kindle 9781491958698\n    ```  \n    On the right, the book created with `--kindle` option, on the left without (default):  \n    \n    ![NoKindle Option](https://github.com/lorenzodifuccia/cloudflare/raw/master/Images/safaribooks/safaribooks_example02_NoKindle.png \"Version compare\")  \n    \n---  \n  \n## Thanks!!\nFor any kind of problem, please don't hesitate to open an issue here on *GitHub*.  \n  \n*Lorenzo Di Fuccia*\n"
        },
        {
          "name": "register_user.py",
          "type": "blob",
          "size": 5.0283203125,
          "content": "import re\nimport requests\nimport safaribooks\n\nREGISTER_URL = safaribooks.SAFARI_BASE_URL + \"/register/\"\nCHECK_EMAIL = safaribooks.SAFARI_BASE_URL + \"/check-email-availability/\"\nCHECK_PWD = safaribooks.SAFARI_BASE_URL + \"/check-password/\"\n\n# DEBUG\nUSE_PROXY = False\nPROXIES = {\"https\": \"https://127.0.0.1:8080\"}\n\nCSRF_TOKEN_RE = re.compile(r\"(?<=name='csrfmiddlewaretoken' value=')([^']+)\")\n\n\nclass Register:\n    def __init__(self, email, password, first_name, second_name, country=\"US\", referrer=\"podcast\"):\n        self.email = email\n        self.password = password\n        self.first_name = first_name\n        self.second_name = second_name\n        self.country = country\n        self.referrer = referrer\n\n        self.csrf = None\n\n        self.session = requests.Session()\n        if USE_PROXY:  # DEBUG\n            self.session.proxies = PROXIES\n            self.session.verify = False\n\n        self.session.headers.update(safaribooks.SafariBooks.HEADERS)\n        self.session.headers.update({\n            \"X-Requested-With\": \"XMLHttpRequest\",\n            \"Referer\": REGISTER_URL\n        })\n\n        self.register()\n\n    def handle_cookie_update(self, set_cookie_headers):\n        for morsel in set_cookie_headers:\n            # Handle Float 'max-age' Cookie\n            if safaribooks.SafariBooks.COOKIE_FLOAT_MAX_AGE_PATTERN.search(morsel):\n                cookie_key, cookie_value = morsel.split(\";\")[0].split(\"=\")\n                self.session.cookies.set(cookie_key, cookie_value)\n\n    def requests_provider(self, url, is_post=False, data=None, perform_redirect=True, check_200=True, **kwargs):\n        try:\n            response = getattr(self.session, \"post\" if is_post else \"get\")(\n                url,\n                data=data,\n                allow_redirects=False,\n                **kwargs\n            )\n\n            self.handle_cookie_update(response.raw.headers.getlist(\"Set-Cookie\"))\n\n        except (requests.ConnectionError, requests.ConnectTimeout, requests.RequestException) as request_exception:\n            print(\"Error: \", str(request_exception))\n            return 0\n\n        if response.is_redirect and perform_redirect:\n            return self.requests_provider(response.next.url, is_post, None, perform_redirect, check_200, **kwargs)\n\n        if check_200 and response.status_code != 200:\n            print(\"Invalid response code:\\n\", response.text)\n            return 0\n\n        return response\n\n    def register(self):\n        # Take first cookie + csrf\n        response = self.requests_provider(REGISTER_URL)\n        if response == 0:\n            print(\"Error 0x1: unable to reach registration page!\")\n            exit(1)\n\n        if \"csrfmiddlewaretoken' value='\" not in response.text:\n            print(\"Error 0x2: CSRF token not present\")\n            exit(1)\n\n        csrf_search = CSRF_TOKEN_RE.findall(response.text)\n        if not len(csrf_search):\n            print(\"Error 0x3: CSRF token RE error\")\n            exit(1)\n\n        self.csrf = csrf_search[0]\n\n        # Check user validity\n        response = self.requests_provider(CHECK_EMAIL, params={\"email\": self.email})\n        if response == 0:\n            print(\"Error 0x4: unable to check email!\")\n            exit(1)\n\n        response_dict = response.json()\n        if not response_dict[\"success\"]:\n            print(\"Error 0x5:\", response_dict[\"message\"])\n            exit(1)\n\n        # Check password validity\n        response = self.requests_provider(CHECK_PWD, is_post=True, data={\n            \"csrfmiddlewaretoken\": self.csrf,\n            \"password1\": self.password,\n            \"field_name\": \"password1\"\n        })\n        if response == 0:\n            print(\"Error 0x6: unable to check password!\")\n            exit(1)\n\n        response_dict = response.json()\n        if not response_dict[\"valid\"]:\n            print(\"Error 0x7:\", response_dict[\"msg\"])\n            exit(1)\n\n        # Register\n        response = self.requests_provider(REGISTER_URL, is_post=True, data={\n            \"next\": \"\",\n            \"trial_length\": 10,\n            \"csrfmiddlewaretoken\": self.csrf,\n            \"first_name\": self.first_name,\n            \"last_name\": self.second_name,\n            \"email\": self.email,\n            \"password1\": self.password,\n            \"country\": self.country,\n            \"referrer\": \"podcast\",\n            \"recently_viewed_bits\": \"[]\"\n        }, check_200=False)\n        if response == 0:\n            print(\"Error 0x8: unable to register!\")\n            exit(1)\n\n        elif response.status_code != 201:\n            print(\"Error: 0x9: invalid status code while registering!\")\n            exit(1)\n\n        print(\"[*] Account registered: \\nEMAIL: %s\\nPASSWORD: %s\" % (self.email, self.password))\n        return\n\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) < 3:\n        print(\"[!] Error: too few arguments.\\nRun `register_user.py EMAIL PASSWORD`.\")\n        exit(1)\n\n    elif len(sys.argv) > 3:\n        print(\"[!] Error: too much arguments, try to enclose the string with quote '\\\"'.\")\n        exit(1)\n\n    FIRST_NAME = \"Safari\"\n    SECOND_NAME = \"Download\"\n\n    Register(sys.argv[1], sys.argv[2], FIRST_NAME, SECOND_NAME)\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.029296875,
          "content": "lxml>=4.1.1\nrequests>=2.20.0\n\n"
        },
        {
          "name": "safaribooks.py",
          "type": "blob",
          "size": 45.841796875,
          "content": "#!/usr/bin/env python3\n# coding: utf-8\nimport re\nimport os\nimport sys\nimport json\nimport shutil\nimport pathlib\nimport getpass\nimport logging\nimport argparse\nimport requests\nimport traceback\nfrom html import escape\nfrom random import random\nfrom lxml import html, etree\nfrom multiprocessing import Process, Queue, Value\nfrom urllib.parse import urljoin, urlparse, parse_qs, quote_plus\n\n\nPATH = os.path.dirname(os.path.realpath(__file__))\nCOOKIES_FILE = os.path.join(PATH, \"cookies.json\")\n\nORLY_BASE_HOST = \"oreilly.com\"  # PLEASE INSERT URL HERE\n\nSAFARI_BASE_HOST = \"learning.\" + ORLY_BASE_HOST\nAPI_ORIGIN_HOST = \"api.\" + ORLY_BASE_HOST\n\nORLY_BASE_URL = \"https://www.\" + ORLY_BASE_HOST\nSAFARI_BASE_URL = \"https://\" + SAFARI_BASE_HOST\nAPI_ORIGIN_URL = \"https://\" + API_ORIGIN_HOST\nPROFILE_URL = SAFARI_BASE_URL + \"/profile/\"\n\n# DEBUG\nUSE_PROXY = False\nPROXIES = {\"https\": \"https://127.0.0.1:8080\"}\n\n\nclass Display:\n    BASE_FORMAT = logging.Formatter(\n        fmt=\"[%(asctime)s] %(message)s\",\n        datefmt=\"%d/%b/%Y %H:%M:%S\"\n    )\n\n    SH_DEFAULT = \"\\033[0m\" if \"win\" not in sys.platform else \"\"  # TODO: colors for Windows\n    SH_YELLOW = \"\\033[33m\" if \"win\" not in sys.platform else \"\"\n    SH_BG_RED = \"\\033[41m\" if \"win\" not in sys.platform else \"\"\n    SH_BG_YELLOW = \"\\033[43m\" if \"win\" not in sys.platform else \"\"\n\n    def __init__(self, log_file):\n        self.output_dir = \"\"\n        self.output_dir_set = False\n        self.log_file = os.path.join(PATH, log_file)\n\n        self.logger = logging.getLogger(\"SafariBooks\")\n        self.logger.setLevel(logging.INFO)\n        logs_handler = logging.FileHandler(filename=self.log_file)\n        logs_handler.setFormatter(self.BASE_FORMAT)\n        logs_handler.setLevel(logging.INFO)\n        self.logger.addHandler(logs_handler)\n\n        self.columns, _ = shutil.get_terminal_size()\n\n        self.logger.info(\"** Welcome to SafariBooks! **\")\n\n        self.book_ad_info = False\n        self.css_ad_info = Value(\"i\", 0)\n        self.images_ad_info = Value(\"i\", 0)\n        self.last_request = (None,)\n        self.in_error = False\n\n        self.state_status = Value(\"i\", 0)\n        sys.excepthook = self.unhandled_exception\n\n    def set_output_dir(self, output_dir):\n        self.info(\"Output directory:\\n    %s\" % output_dir)\n        self.output_dir = output_dir\n        self.output_dir_set = True\n\n    def unregister(self):\n        self.logger.handlers[0].close()\n        sys.excepthook = sys.__excepthook__\n\n    def log(self, message):\n        try:\n            self.logger.info(str(message, \"utf-8\", \"replace\"))\n\n        except (UnicodeDecodeError, Exception):\n            self.logger.info(message)\n\n    def out(self, put):\n        pattern = \"\\r{!s}\\r{!s}\\n\"\n        try:\n            s = pattern.format(\" \" * self.columns, str(put, \"utf-8\", \"replace\"))\n\n        except TypeError:\n            s = pattern.format(\" \" * self.columns, put)\n\n        sys.stdout.write(s)\n\n    def info(self, message, state=False):\n        self.log(message)\n        output = (self.SH_YELLOW + \"[*]\" + self.SH_DEFAULT if not state else\n                  self.SH_BG_YELLOW + \"[-]\" + self.SH_DEFAULT) + \" %s\" % message\n        self.out(output)\n\n    def error(self, error):\n        if not self.in_error:\n            self.in_error = True\n\n        self.log(error)\n        output = self.SH_BG_RED + \"[#]\" + self.SH_DEFAULT + \" %s\" % error\n        self.out(output)\n\n    def exit(self, error):\n        self.error(str(error))\n\n        if self.output_dir_set:\n            output = (self.SH_YELLOW + \"[+]\" + self.SH_DEFAULT +\n                      \" Please delete the output directory '\" + self.output_dir + \"'\"\n                      \" and restart the program.\")\n            self.out(output)\n\n        output = self.SH_BG_RED + \"[!]\" + self.SH_DEFAULT + \" Aborting...\"\n        self.out(output)\n\n        self.save_last_request()\n        sys.exit(1)\n\n    def unhandled_exception(self, _, o, tb):\n        self.log(\"\".join(traceback.format_tb(tb)))\n        self.exit(\"Unhandled Exception: %s (type: %s)\" % (o, o.__class__.__name__))\n\n    def save_last_request(self):\n        if any(self.last_request):\n            self.log(\"Last request done:\\n\\tURL: {0}\\n\\tDATA: {1}\\n\\tOTHERS: {2}\\n\\n\\t{3}\\n{4}\\n\\n{5}\\n\"\n                     .format(*self.last_request))\n\n    def intro(self):\n        output = self.SH_YELLOW + (\"\"\"\n       ____     ___         _\n      / __/__ _/ _/__ _____(_)\n     _\\ \\/ _ `/ _/ _ `/ __/ /\n    /___/\\_,_/_/ \\_,_/_/ /_/\n      / _ )___  ___  / /__ ___\n     / _  / _ \\/ _ \\/  '_/(_-<\n    /____/\\___/\\___/_/\\_\\/___/\n\"\"\" if random() > 0.5 else \"\"\"\n ██████╗     ██████╗ ██╗  ██╗   ██╗██████╗\n██╔═══██╗    ██╔══██╗██║  ╚██╗ ██╔╝╚════██╗\n██║   ██║    ██████╔╝██║   ╚████╔╝   ▄███╔╝\n██║   ██║    ██╔══██╗██║    ╚██╔╝    ▀▀══╝\n╚██████╔╝    ██║  ██║███████╗██║     ██╗\n ╚═════╝     ╚═╝  ╚═╝╚══════╝╚═╝     ╚═╝\n\"\"\") + self.SH_DEFAULT\n        output += \"\\n\" + \"~\" * (self.columns // 2)\n\n        self.out(output)\n\n    def parse_description(self, desc):\n        if not desc:\n            return \"n/d\"\n\n        try:\n            return html.fromstring(desc).text_content()\n\n        except (html.etree.ParseError, html.etree.ParserError) as e:\n            self.log(\"Error parsing the description: %s\" % e)\n            return \"n/d\"\n\n    def book_info(self, info):\n        description = self.parse_description(info.get(\"description\", None)).replace(\"\\n\", \" \")\n        for t in [\n            (\"Title\", info.get(\"title\", \"\")), (\"Authors\", \", \".join(aut.get(\"name\", \"\") for aut in info.get(\"authors\", []))),\n            (\"Identifier\", info.get(\"identifier\", \"\")), (\"ISBN\", info.get(\"isbn\", \"\")),\n            (\"Publishers\", \", \".join(pub.get(\"name\", \"\") for pub in info.get(\"publishers\", []))),\n            (\"Rights\", info.get(\"rights\", \"\")),\n            (\"Description\", description[:500] + \"...\" if len(description) >= 500 else description),\n            (\"Release Date\", info.get(\"issued\", \"\")),\n            (\"URL\", info.get(\"web_url\", \"\"))\n        ]:\n            self.info(\"{0}{1}{2}: {3}\".format(self.SH_YELLOW, t[0], self.SH_DEFAULT, t[1]), True)\n\n    def state(self, origin, done):\n        progress = int(done * 100 / origin)\n        bar = int(progress * (self.columns - 11) / 100)\n        if self.state_status.value < progress:\n            self.state_status.value = progress\n            sys.stdout.write(\n                \"\\r    \" + self.SH_BG_YELLOW + \"[\" + (\"#\" * bar).ljust(self.columns - 11, \"-\") + \"]\" +\n                self.SH_DEFAULT + (\"%4s\" % progress) + \"%\" + (\"\\n\" if progress == 100 else \"\")\n            )\n\n    def done(self, epub_file):\n        self.info(\"Done: %s\\n\\n\" % epub_file +\n                  \"    If you like it, please * this project on GitHub to make it known:\\n\"\n                  \"        https://github.com/lorenzodifuccia/safaribooks\\n\"\n                  \"    e don't forget to renew your Safari Books Online subscription:\\n\"\n                  \"        \" + SAFARI_BASE_URL + \"\\n\\n\" +\n                  self.SH_BG_RED + \"[!]\" + self.SH_DEFAULT + \" Bye!!\")\n\n    @staticmethod\n    def api_error(response):\n        message = \"API: \"\n        if \"detail\" in response and \"Not found\" in response[\"detail\"]:\n            message += \"book's not present in Safari Books Online.\\n\" \\\n                       \"    The book identifier is the digits that you can find in the URL:\\n\" \\\n                       \"    `\" + SAFARI_BASE_URL + \"/library/view/book-name/XXXXXXXXXXXXX/`\"\n\n        else:\n            os.remove(COOKIES_FILE)\n            message += \"Out-of-Session%s.\\n\" % (\" (%s)\" % response[\"detail\"]) if \"detail\" in response else \"\" + \\\n                       Display.SH_YELLOW + \"[+]\" + Display.SH_DEFAULT + \\\n                       \" Use the `--cred` or `--login` options in order to perform the auth login to Safari.\"\n\n        return message\n\n\nclass WinQueue(list):  # TODO: error while use `process` in Windows: can't pickle _thread.RLock objects\n    def put(self, el):\n        self.append(el)\n\n    def qsize(self):\n        return self.__len__()\n\n\nclass SafariBooks:\n    LOGIN_URL = ORLY_BASE_URL + \"/member/auth/login/\"\n    LOGIN_ENTRY_URL = SAFARI_BASE_URL + \"/login/unified/?next=/home/\"\n\n    API_TEMPLATE = SAFARI_BASE_URL + \"/api/v1/book/{0}/\"\n\n    BASE_01_HTML = \"<!DOCTYPE html>\\n\" \\\n                   \"<html lang=\\\"en\\\" xml:lang=\\\"en\\\" xmlns=\\\"http://www.w3.org/1999/xhtml\\\"\" \\\n                   \" xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\" \\\n                   \" xsi:schemaLocation=\\\"http://www.w3.org/2002/06/xhtml2/\" \\\n                   \" http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd\\\"\" \\\n                   \" xmlns:epub=\\\"http://www.idpf.org/2007/ops\\\">\\n\" \\\n                   \"<head>\\n\" \\\n                   \"{0}\\n\" \\\n                   \"<style type=\\\"text/css\\\">\" \\\n                   \"body{{margin:1em;background-color:transparent!important;}}\" \\\n                   \"#sbo-rt-content *{{text-indent:0pt!important;}}#sbo-rt-content .bq{{margin-right:1em!important;}}\"\n\n    KINDLE_HTML = \"#sbo-rt-content *{{word-wrap:break-word!important;\" \\\n                  \"word-break:break-word!important;}}#sbo-rt-content table,#sbo-rt-content pre\" \\\n                  \"{{overflow-x:unset!important;overflow:unset!important;\" \\\n                  \"overflow-y:unset!important;white-space:pre-wrap!important;}}\"\n\n    BASE_02_HTML = \"</style>\" \\\n                   \"</head>\\n\" \\\n                   \"<body>{1}</body>\\n</html>\"\n\n    CONTAINER_XML = \"<?xml version=\\\"1.0\\\"?>\" \\\n                    \"<container version=\\\"1.0\\\" xmlns=\\\"urn:oasis:names:tc:opendocument:xmlns:container\\\">\" \\\n                    \"<rootfiles>\" \\\n                    \"<rootfile full-path=\\\"OEBPS/content.opf\\\" media-type=\\\"application/oebps-package+xml\\\" />\" \\\n                    \"</rootfiles>\" \\\n                    \"</container>\"\n\n    # Format: ID, Title, Authors, Description, Subjects, Publisher, Rights, Date, CoverId, MANIFEST, SPINE, CoverUrl\n    CONTENT_OPF = \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n\" \\\n                  \"<package xmlns=\\\"http://www.idpf.org/2007/opf\\\" unique-identifier=\\\"bookid\\\" version=\\\"2.0\\\" >\\n\" \\\n                  \"<metadata xmlns:dc=\\\"http://purl.org/dc/elements/1.1/\\\" \" \\\n                  \" xmlns:opf=\\\"http://www.idpf.org/2007/opf\\\">\\n\" \\\n                  \"<dc:title>{1}</dc:title>\\n\" \\\n                  \"{2}\\n\" \\\n                  \"<dc:description>{3}</dc:description>\\n\" \\\n                  \"{4}\" \\\n                  \"<dc:publisher>{5}</dc:publisher>\\n\" \\\n                  \"<dc:rights>{6}</dc:rights>\\n\" \\\n                  \"<dc:language>en-US</dc:language>\\n\" \\\n                  \"<dc:date>{7}</dc:date>\\n\" \\\n                  \"<dc:identifier id=\\\"bookid\\\">{0}</dc:identifier>\\n\" \\\n                  \"<meta name=\\\"cover\\\" content=\\\"{8}\\\"/>\\n\" \\\n                  \"</metadata>\\n\" \\\n                  \"<manifest>\\n\" \\\n                  \"<item id=\\\"ncx\\\" href=\\\"toc.ncx\\\" media-type=\\\"application/x-dtbncx+xml\\\" />\\n\" \\\n                  \"{9}\\n\" \\\n                  \"</manifest>\\n\" \\\n                  \"<spine toc=\\\"ncx\\\">\\n{10}</spine>\\n\" \\\n                  \"<guide><reference href=\\\"{11}\\\" title=\\\"Cover\\\" type=\\\"cover\\\" /></guide>\\n\" \\\n                  \"</package>\"\n\n    # Format: ID, Depth, Title, Author, NAVMAP\n    TOC_NCX = \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\" standalone=\\\"no\\\" ?>\\n\" \\\n              \"<!DOCTYPE ncx PUBLIC \\\"-//NISO//DTD ncx 2005-1//EN\\\"\" \\\n              \" \\\"http://www.daisy.org/z3986/2005/ncx-2005-1.dtd\\\">\\n\" \\\n              \"<ncx xmlns=\\\"http://www.daisy.org/z3986/2005/ncx/\\\" version=\\\"2005-1\\\">\\n\" \\\n              \"<head>\\n\" \\\n              \"<meta content=\\\"ID:ISBN:{0}\\\" name=\\\"dtb:uid\\\"/>\\n\" \\\n              \"<meta content=\\\"{1}\\\" name=\\\"dtb:depth\\\"/>\\n\" \\\n              \"<meta content=\\\"0\\\" name=\\\"dtb:totalPageCount\\\"/>\\n\" \\\n              \"<meta content=\\\"0\\\" name=\\\"dtb:maxPageNumber\\\"/>\\n\" \\\n              \"</head>\\n\" \\\n              \"<docTitle><text>{2}</text></docTitle>\\n\" \\\n              \"<docAuthor><text>{3}</text></docAuthor>\\n\" \\\n              \"<navMap>{4}</navMap>\\n\" \\\n              \"</ncx>\"\n\n    HEADERS = {\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n        \"Accept-Encoding\": \"gzip, deflate\",\n        \"Referer\": LOGIN_ENTRY_URL,\n        \"Upgrade-Insecure-Requests\": \"1\",\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n                      \"Chrome/90.0.4430.212 Safari/537.36\"\n    }\n\n    COOKIE_FLOAT_MAX_AGE_PATTERN = re.compile(r'(max-age=\\d*\\.\\d*)', re.IGNORECASE)\n\n    def __init__(self, args):\n        self.args = args\n        self.display = Display(\"info_%s.log\" % escape(args.bookid))\n        self.display.intro()\n\n        self.session = requests.Session()\n        if USE_PROXY:  # DEBUG\n            self.session.proxies = PROXIES\n            self.session.verify = False\n\n        self.session.headers.update(self.HEADERS)\n\n        self.jwt = {}\n\n        if not args.cred:\n            if not os.path.isfile(COOKIES_FILE):\n                self.display.exit(\"Login: unable to find `cookies.json` file.\\n\"\n                                  \"    Please use the `--cred` or `--login` options to perform the login.\")\n\n            self.session.cookies.update(json.load(open(COOKIES_FILE)))\n\n        else:\n            self.display.info(\"Logging into Safari Books Online...\", state=True)\n            self.do_login(*args.cred)\n            if not args.no_cookies:\n                json.dump(self.session.cookies.get_dict(), open(COOKIES_FILE, 'w'))\n\n        self.check_login()\n\n        self.book_id = args.bookid\n        self.api_url = self.API_TEMPLATE.format(self.book_id)\n\n        self.display.info(\"Retrieving book info...\")\n        self.book_info = self.get_book_info()\n        self.display.book_info(self.book_info)\n\n        self.display.info(\"Retrieving book chapters...\")\n        self.book_chapters = self.get_book_chapters()\n\n        self.chapters_queue = self.book_chapters[:]\n\n        if len(self.book_chapters) > sys.getrecursionlimit():\n            sys.setrecursionlimit(len(self.book_chapters))\n\n        self.book_title = self.book_info[\"title\"]\n        self.base_url = self.book_info[\"web_url\"]\n\n        self.clean_book_title = \"\".join(self.escape_dirname(self.book_title).split(\",\")[:2]) \\\n                                + \" ({0})\".format(self.book_id)\n\n        books_dir = os.path.join(PATH, \"Books\")\n        if not os.path.isdir(books_dir):\n            os.mkdir(books_dir)\n\n        self.BOOK_PATH = os.path.join(books_dir, self.clean_book_title)\n        self.display.set_output_dir(self.BOOK_PATH)\n        self.css_path = \"\"\n        self.images_path = \"\"\n        self.create_dirs()\n\n        self.chapter_title = \"\"\n        self.filename = \"\"\n        self.chapter_stylesheets = []\n        self.css = []\n        self.images = []\n\n        self.display.info(\"Downloading book contents... (%s chapters)\" % len(self.book_chapters), state=True)\n        self.BASE_HTML = self.BASE_01_HTML + (self.KINDLE_HTML if not args.kindle else \"\") + self.BASE_02_HTML\n\n        self.cover = False\n        self.get()\n        if not self.cover:\n            self.cover = self.get_default_cover() if \"cover\" in self.book_info else False\n            cover_html = self.parse_html(\n                html.fromstring(\"<div id=\\\"sbo-rt-content\\\"><img src=\\\"Images/{0}\\\"></div>\".format(self.cover)), True\n            )\n\n            self.book_chapters = [{\n                \"filename\": \"default_cover.xhtml\",\n                \"title\": \"Cover\"\n            }] + self.book_chapters\n\n            self.filename = self.book_chapters[0][\"filename\"]\n            self.save_page_html(cover_html)\n\n        self.css_done_queue = Queue(0) if \"win\" not in sys.platform else WinQueue()\n        self.display.info(\"Downloading book CSSs... (%s files)\" % len(self.css), state=True)\n        self.collect_css()\n        self.images_done_queue = Queue(0) if \"win\" not in sys.platform else WinQueue()\n        self.display.info(\"Downloading book images... (%s files)\" % len(self.images), state=True)\n        self.collect_images()\n\n        self.display.info(\"Creating EPUB file...\", state=True)\n        self.create_epub()\n\n        if not args.no_cookies:\n            json.dump(self.session.cookies.get_dict(), open(COOKIES_FILE, \"w\"))\n\n        self.display.done(os.path.join(self.BOOK_PATH, self.book_id + \".epub\"))\n        self.display.unregister()\n\n        if not self.display.in_error and not args.log:\n            os.remove(self.display.log_file)\n\n    def handle_cookie_update(self, set_cookie_headers):\n        for morsel in set_cookie_headers:\n            # Handle Float 'max-age' Cookie\n            if self.COOKIE_FLOAT_MAX_AGE_PATTERN.search(morsel):\n                cookie_key, cookie_value = morsel.split(\";\")[0].split(\"=\")\n                self.session.cookies.set(cookie_key, cookie_value)\n\n    def requests_provider(self, url, is_post=False, data=None, perform_redirect=True, **kwargs):\n        try:\n            response = getattr(self.session, \"post\" if is_post else \"get\")(\n                url,\n                data=data,\n                allow_redirects=False,\n                **kwargs\n            )\n\n            self.handle_cookie_update(response.raw.headers.getlist(\"Set-Cookie\"))\n\n            self.display.last_request = (\n                url, data, kwargs, response.status_code, \"\\n\".join(\n                    [\"\\t{}: {}\".format(*h) for h in response.headers.items()]\n                ), response.text\n            )\n\n        except (requests.ConnectionError, requests.ConnectTimeout, requests.RequestException) as request_exception:\n            self.display.error(str(request_exception))\n            return 0\n\n        if response.is_redirect and perform_redirect:\n            return self.requests_provider(response.next.url, is_post, None, perform_redirect)\n            # TODO How about **kwargs?\n\n        return response\n\n    @staticmethod\n    def parse_cred(cred):\n        if \":\" not in cred:\n            return False\n\n        sep = cred.index(\":\")\n        new_cred = [\"\", \"\"]\n        new_cred[0] = cred[:sep].strip(\"'\").strip('\"')\n        if \"@\" not in new_cred[0]:\n            return False\n\n        new_cred[1] = cred[sep + 1:]\n        return new_cred\n\n    def do_login(self, email, password):\n        response = self.requests_provider(self.LOGIN_ENTRY_URL)\n        if response == 0:\n            self.display.exit(\"Login: unable to reach Safari Books Online. Try again...\")\n\n        next_parameter = None\n        try:\n            next_parameter = parse_qs(urlparse(response.request.url).query)[\"next\"][0]\n\n        except (AttributeError, ValueError, IndexError):\n            self.display.exit(\"Login: unable to complete login on Safari Books Online. Try again...\")\n\n        redirect_uri = API_ORIGIN_URL + quote_plus(next_parameter)\n\n        response = self.requests_provider(\n            self.LOGIN_URL,\n            is_post=True,\n            json={\n                \"email\": email,\n                \"password\": password,\n                \"redirect_uri\": redirect_uri\n            },\n            perform_redirect=False\n        )\n\n        if response == 0:\n            self.display.exit(\"Login: unable to perform auth to Safari Books Online.\\n    Try again...\")\n\n        if response.status_code != 200:  # TODO To be reviewed\n            try:\n                error_page = html.fromstring(response.text)\n                errors_message = error_page.xpath(\"//ul[@class='errorlist']//li/text()\")\n                recaptcha = error_page.xpath(\"//div[@class='g-recaptcha']\")\n                messages = ([\"    `%s`\" % error for error in errors_message\n                             if \"password\" in error or \"email\" in error] if len(errors_message) else []) + \\\n                           ([\"    `ReCaptcha required (wait or do logout from the website).`\"] if len(\n                               recaptcha) else [])\n                self.display.exit(\n                    \"Login: unable to perform auth login to Safari Books Online.\\n\" + self.display.SH_YELLOW +\n                    \"[*]\" + self.display.SH_DEFAULT + \" Details:\\n\" + \"%s\" % \"\\n\".join(\n                        messages if len(messages) else [\"    Unexpected error!\"])\n                )\n            except (html.etree.ParseError, html.etree.ParserError) as parsing_error:\n                self.display.error(parsing_error)\n                self.display.exit(\n                    \"Login: your login went wrong and it encountered in an error\"\n                    \" trying to parse the login details of Safari Books Online. Try again...\"\n                )\n\n        self.jwt = response.json()  # TODO: save JWT Tokens and use the refresh_token to restore user session\n        response = self.requests_provider(self.jwt[\"redirect_uri\"])\n        if response == 0:\n            self.display.exit(\"Login: unable to reach Safari Books Online. Try again...\")\n\n    def check_login(self):\n        response = self.requests_provider(PROFILE_URL, perform_redirect=False)\n\n        if response == 0:\n            self.display.exit(\"Login: unable to reach Safari Books Online. Try again...\")\n\n        elif response.status_code != 200:\n            self.display.exit(\"Authentication issue: unable to access profile page.\")\n\n        elif \"user_type\\\":\\\"Expired\\\"\" in response.text:\n            self.display.exit(\"Authentication issue: account subscription expired.\")\n\n        self.display.info(\"Successfully authenticated.\", state=True)\n\n    def get_book_info(self):\n        response = self.requests_provider(self.api_url)\n        if response == 0:\n            self.display.exit(\"API: unable to retrieve book info.\")\n\n        response = response.json()\n        if not isinstance(response, dict) or len(response.keys()) == 1:\n            self.display.exit(self.display.api_error(response))\n\n        if \"last_chapter_read\" in response:\n            del response[\"last_chapter_read\"]\n\n        for key, value in response.items():\n            if value is None:\n                response[key] = 'n/a'\n\n        return response\n\n    def get_book_chapters(self, page=1):\n        response = self.requests_provider(urljoin(self.api_url, \"chapter/?page=%s\" % page))\n        if response == 0:\n            self.display.exit(\"API: unable to retrieve book chapters.\")\n\n        response = response.json()\n\n        if not isinstance(response, dict) or len(response.keys()) == 1:\n            self.display.exit(self.display.api_error(response))\n\n        if \"results\" not in response or not len(response[\"results\"]):\n            self.display.exit(\"API: unable to retrieve book chapters.\")\n\n        if response[\"count\"] > sys.getrecursionlimit():\n            sys.setrecursionlimit(response[\"count\"])\n\n        result = []\n        result.extend([c for c in response[\"results\"] if \"cover\" in c[\"filename\"] or \"cover\" in c[\"title\"]])\n        for c in result:\n            del response[\"results\"][response[\"results\"].index(c)]\n\n        result += response[\"results\"]\n        return result + (self.get_book_chapters(page + 1) if response[\"next\"] else [])\n\n    def get_default_cover(self):\n        response = self.requests_provider(self.book_info[\"cover\"], stream=True)\n        if response == 0:\n            self.display.error(\"Error trying to retrieve the cover: %s\" % self.book_info[\"cover\"])\n            return False\n\n        file_ext = response.headers[\"Content-Type\"].split(\"/\")[-1]\n        with open(os.path.join(self.images_path, \"default_cover.\" + file_ext), 'wb') as i:\n            for chunk in response.iter_content(1024):\n                i.write(chunk)\n\n        return \"default_cover.\" + file_ext\n\n    def get_html(self, url):\n        response = self.requests_provider(url)\n        if response == 0 or response.status_code != 200:\n            self.display.exit(\n                \"Crawler: error trying to retrieve this page: %s (%s)\\n    From: %s\" %\n                (self.filename, self.chapter_title, url)\n            )\n\n        root = None\n        try:\n            root = html.fromstring(response.text, base_url=SAFARI_BASE_URL)\n\n        except (html.etree.ParseError, html.etree.ParserError) as parsing_error:\n            self.display.error(parsing_error)\n            self.display.exit(\n                \"Crawler: error trying to parse this page: %s (%s)\\n    From: %s\" %\n                (self.filename, self.chapter_title, url)\n            )\n\n        return root\n\n    @staticmethod\n    def url_is_absolute(url):\n        return bool(urlparse(url).netloc)\n\n    @staticmethod\n    def is_image_link(url: str):\n        return pathlib.Path(url).suffix[1:].lower() in [\"jpg\", \"jpeg\", \"png\", \"gif\"]\n\n    def link_replace(self, link):\n        if link and not link.startswith(\"mailto\"):\n            if not self.url_is_absolute(link):\n                if any(x in link for x in [\"cover\", \"images\", \"graphics\"]) or \\\n                        self.is_image_link(link):\n                    image = link.split(\"/\")[-1]\n                    return \"Images/\" + image\n\n                return link.replace(\".html\", \".xhtml\")\n\n            else:\n                if self.book_id in link:\n                    return self.link_replace(link.split(self.book_id)[-1])\n\n        return link\n\n    @staticmethod\n    def get_cover(html_root):\n        lowercase_ns = etree.FunctionNamespace(None)\n        lowercase_ns[\"lower-case\"] = lambda _, n: n[0].lower() if n and len(n) else \"\"\n\n        images = html_root.xpath(\"//img[contains(lower-case(@id), 'cover') or contains(lower-case(@class), 'cover') or\"\n                                 \"contains(lower-case(@name), 'cover') or contains(lower-case(@src), 'cover') or\"\n                                 \"contains(lower-case(@alt), 'cover')]\")\n        if len(images):\n            return images[0]\n\n        divs = html_root.xpath(\"//div[contains(lower-case(@id), 'cover') or contains(lower-case(@class), 'cover') or\"\n                               \"contains(lower-case(@name), 'cover') or contains(lower-case(@src), 'cover')]//img\")\n        if len(divs):\n            return divs[0]\n\n        a = html_root.xpath(\"//a[contains(lower-case(@id), 'cover') or contains(lower-case(@class), 'cover') or\"\n                            \"contains(lower-case(@name), 'cover') or contains(lower-case(@src), 'cover')]//img\")\n        if len(a):\n            return a[0]\n\n        return None\n\n    def parse_html(self, root, first_page=False):\n        if random() > 0.8:\n            if len(root.xpath(\"//div[@class='controls']/a/text()\")):\n                self.display.exit(self.display.api_error(\" \"))\n\n        book_content = root.xpath(\"//div[@id='sbo-rt-content']\")\n        if not len(book_content):\n            self.display.exit(\n                \"Parser: book content's corrupted or not present: %s (%s)\" %\n                (self.filename, self.chapter_title)\n            )\n\n        page_css = \"\"\n        if len(self.chapter_stylesheets):\n            for chapter_css_url in self.chapter_stylesheets:\n                if chapter_css_url not in self.css:\n                    self.css.append(chapter_css_url)\n                    self.display.log(\"Crawler: found a new CSS at %s\" % chapter_css_url)\n\n                page_css += \"<link href=\\\"Styles/Style{0:0>2}.css\\\" \" \\\n                            \"rel=\\\"stylesheet\\\" type=\\\"text/css\\\" />\\n\".format(self.css.index(chapter_css_url))\n\n        stylesheet_links = root.xpath(\"//link[@rel='stylesheet']\")\n        if len(stylesheet_links):\n            for s in stylesheet_links:\n                css_url = urljoin(\"https:\", s.attrib[\"href\"]) if s.attrib[\"href\"][:2] == \"//\" \\\n                    else urljoin(self.base_url, s.attrib[\"href\"])\n\n                if css_url not in self.css:\n                    self.css.append(css_url)\n                    self.display.log(\"Crawler: found a new CSS at %s\" % css_url)\n\n                page_css += \"<link href=\\\"Styles/Style{0:0>2}.css\\\" \" \\\n                            \"rel=\\\"stylesheet\\\" type=\\\"text/css\\\" />\\n\".format(self.css.index(css_url))\n\n        stylesheets = root.xpath(\"//style\")\n        if len(stylesheets):\n            for css in stylesheets:\n                if \"data-template\" in css.attrib and len(css.attrib[\"data-template\"]):\n                    css.text = css.attrib[\"data-template\"]\n                    del css.attrib[\"data-template\"]\n\n                try:\n                    page_css += html.tostring(css, method=\"xml\", encoding='unicode') + \"\\n\"\n\n                except (html.etree.ParseError, html.etree.ParserError) as parsing_error:\n                    self.display.error(parsing_error)\n                    self.display.exit(\n                        \"Parser: error trying to parse one CSS found in this page: %s (%s)\" %\n                        (self.filename, self.chapter_title)\n                    )\n\n        # TODO: add all not covered tag for `link_replace` function\n        svg_image_tags = root.xpath(\"//image\")\n        if len(svg_image_tags):\n            for img in svg_image_tags:\n                image_attr_href = [x for x in img.attrib.keys() if \"href\" in x]\n                if len(image_attr_href):\n                    svg_url = img.attrib.get(image_attr_href[0])\n                    svg_root = img.getparent().getparent()\n                    new_img = svg_root.makeelement(\"img\")\n                    new_img.attrib.update({\"src\": svg_url})\n                    svg_root.remove(img.getparent())\n                    svg_root.append(new_img)\n\n        book_content = book_content[0]\n        book_content.rewrite_links(self.link_replace)\n\n        xhtml = None\n        try:\n            if first_page:\n                is_cover = self.get_cover(book_content)\n                if is_cover is not None:\n                    page_css = \"<style>\" \\\n                               \"body{display:table;position:absolute;margin:0!important;height:100%;width:100%;}\" \\\n                               \"#Cover{display:table-cell;vertical-align:middle;text-align:center;}\" \\\n                               \"img{height:90vh;margin-left:auto;margin-right:auto;}\" \\\n                               \"</style>\"\n                    cover_html = html.fromstring(\"<div id=\\\"Cover\\\"></div>\")\n                    cover_div = cover_html.xpath(\"//div\")[0]\n                    cover_img = cover_div.makeelement(\"img\")\n                    cover_img.attrib.update({\"src\": is_cover.attrib[\"src\"]})\n                    cover_div.append(cover_img)\n                    book_content = cover_html\n\n                    self.cover = is_cover.attrib[\"src\"]\n\n            xhtml = html.tostring(book_content, method=\"xml\", encoding='unicode')\n\n        except (html.etree.ParseError, html.etree.ParserError) as parsing_error:\n            self.display.error(parsing_error)\n            self.display.exit(\n                \"Parser: error trying to parse HTML of this page: %s (%s)\" %\n                (self.filename, self.chapter_title)\n            )\n\n        return page_css, xhtml\n\n    @staticmethod\n    def escape_dirname(dirname, clean_space=False):\n        if \":\" in dirname:\n            if dirname.index(\":\") > 15:\n                dirname = dirname.split(\":\")[0]\n\n            elif \"win\" in sys.platform:\n                dirname = dirname.replace(\":\", \",\")\n\n        for ch in ['~', '#', '%', '&', '*', '{', '}', '\\\\', '<', '>', '?', '/', '`', '\\'', '\"', '|', '+', ':']:\n            if ch in dirname:\n                dirname = dirname.replace(ch, \"_\")\n\n        return dirname if not clean_space else dirname.replace(\" \", \"\")\n\n    def create_dirs(self):\n        if os.path.isdir(self.BOOK_PATH):\n            self.display.log(\"Book directory already exists: %s\" % self.BOOK_PATH)\n\n        else:\n            os.makedirs(self.BOOK_PATH)\n\n        oebps = os.path.join(self.BOOK_PATH, \"OEBPS\")\n        if not os.path.isdir(oebps):\n            self.display.book_ad_info = True\n            os.makedirs(oebps)\n\n        self.css_path = os.path.join(oebps, \"Styles\")\n        if os.path.isdir(self.css_path):\n            self.display.log(\"CSSs directory already exists: %s\" % self.css_path)\n\n        else:\n            os.makedirs(self.css_path)\n            self.display.css_ad_info.value = 1\n\n        self.images_path = os.path.join(oebps, \"Images\")\n        if os.path.isdir(self.images_path):\n            self.display.log(\"Images directory already exists: %s\" % self.images_path)\n\n        else:\n            os.makedirs(self.images_path)\n            self.display.images_ad_info.value = 1\n\n    def save_page_html(self, contents):\n        self.filename = self.filename.replace(\".html\", \".xhtml\")\n        open(os.path.join(self.BOOK_PATH, \"OEBPS\", self.filename), \"wb\") \\\n            .write(self.BASE_HTML.format(contents[0], contents[1]).encode(\"utf-8\", 'xmlcharrefreplace'))\n        self.display.log(\"Created: %s\" % self.filename)\n\n    def get(self):\n        len_books = len(self.book_chapters)\n\n        for _ in range(len_books):\n            if not len(self.chapters_queue):\n                return\n\n            first_page = len_books == len(self.chapters_queue)\n\n            next_chapter = self.chapters_queue.pop(0)\n            self.chapter_title = next_chapter[\"title\"]\n            self.filename = next_chapter[\"filename\"]\n\n            asset_base_url = next_chapter['asset_base_url']\n            api_v2_detected = False\n            if 'v2' in next_chapter['content']:\n                asset_base_url = SAFARI_BASE_URL + \"/api/v2/epubs/urn:orm:book:{}/files\".format(self.book_id)\n                api_v2_detected = True\n\n            if \"images\" in next_chapter and len(next_chapter[\"images\"]):\n                for img_url in next_chapter['images']:\n                    if api_v2_detected:\n                        self.images.append(asset_base_url + '/' + img_url)\n                    else:\n                        self.images.append(urljoin(next_chapter['asset_base_url'], img_url))\n\n\n            # Stylesheets\n            self.chapter_stylesheets = []\n            if \"stylesheets\" in next_chapter and len(next_chapter[\"stylesheets\"]):\n                self.chapter_stylesheets.extend(x[\"url\"] for x in next_chapter[\"stylesheets\"])\n\n            if \"site_styles\" in next_chapter and len(next_chapter[\"site_styles\"]):\n                self.chapter_stylesheets.extend(next_chapter[\"site_styles\"])\n\n            if os.path.isfile(os.path.join(self.BOOK_PATH, \"OEBPS\", self.filename.replace(\".html\", \".xhtml\"))):\n                if not self.display.book_ad_info and \\\n                        next_chapter not in self.book_chapters[:self.book_chapters.index(next_chapter)]:\n                    self.display.info(\n                        (\"File `%s` already exists.\\n\"\n                         \"    If you want to download again all the book,\\n\"\n                         \"    please delete the output directory '\" + self.BOOK_PATH + \"' and restart the program.\")\n                         % self.filename.replace(\".html\", \".xhtml\")\n                    )\n                    self.display.book_ad_info = 2\n\n            else:\n                self.save_page_html(self.parse_html(self.get_html(next_chapter[\"content\"]), first_page))\n\n            self.display.state(len_books, len_books - len(self.chapters_queue))\n\n    def _thread_download_css(self, url):\n        css_file = os.path.join(self.css_path, \"Style{0:0>2}.css\".format(self.css.index(url)))\n        if os.path.isfile(css_file):\n            if not self.display.css_ad_info.value and url not in self.css[:self.css.index(url)]:\n                self.display.info((\"File `%s` already exists.\\n\"\n                                   \"    If you want to download again all the CSSs,\\n\"\n                                   \"    please delete the output directory '\" + self.BOOK_PATH + \"'\"\n                                   \" and restart the program.\") %\n                                  css_file)\n                self.display.css_ad_info.value = 1\n\n        else:\n            response = self.requests_provider(url)\n            if response == 0:\n                self.display.error(\"Error trying to retrieve this CSS: %s\\n    From: %s\" % (css_file, url))\n\n            with open(css_file, 'wb') as s:\n                s.write(response.content)\n\n        self.css_done_queue.put(1)\n        self.display.state(len(self.css), self.css_done_queue.qsize())\n\n\n    def _thread_download_images(self, url):\n        image_name = url.split(\"/\")[-1]\n        image_path = os.path.join(self.images_path, image_name)\n        if os.path.isfile(image_path):\n            if not self.display.images_ad_info.value and url not in self.images[:self.images.index(url)]:\n                self.display.info((\"File `%s` already exists.\\n\"\n                                   \"    If you want to download again all the images,\\n\"\n                                   \"    please delete the output directory '\" + self.BOOK_PATH + \"'\"\n                                   \" and restart the program.\") %\n                                  image_name)\n                self.display.images_ad_info.value = 1\n\n        else:\n            response = self.requests_provider(urljoin(SAFARI_BASE_URL, url), stream=True)\n            if response == 0:\n                self.display.error(\"Error trying to retrieve this image: %s\\n    From: %s\" % (image_name, url))\n                return\n\n            with open(image_path, 'wb') as img:\n                for chunk in response.iter_content(1024):\n                    img.write(chunk)\n\n        self.images_done_queue.put(1)\n        self.display.state(len(self.images), self.images_done_queue.qsize())\n\n    def _start_multiprocessing(self, operation, full_queue):\n        if len(full_queue) > 5:\n            for i in range(0, len(full_queue), 5):\n                self._start_multiprocessing(operation, full_queue[i:i + 5])\n\n        else:\n            process_queue = [Process(target=operation, args=(arg,)) for arg in full_queue]\n            for proc in process_queue:\n                proc.start()\n\n            for proc in process_queue:\n                proc.join()\n\n    def collect_css(self):\n        self.display.state_status.value = -1\n\n        # \"self._start_multiprocessing\" seems to cause problem. Switching to mono-thread download.\n        for css_url in self.css:\n            self._thread_download_css(css_url)\n\n    def collect_images(self):\n        if self.display.book_ad_info == 2:\n            self.display.info(\"Some of the book contents were already downloaded.\\n\"\n                              \"    If you want to be sure that all the images will be downloaded,\\n\"\n                              \"    please delete the output directory '\" + self.BOOK_PATH +\n                              \"' and restart the program.\")\n\n        self.display.state_status.value = -1\n\n        # \"self._start_multiprocessing\" seems to cause problem. Switching to mono-thread download.\n        for image_url in self.images:\n            self._thread_download_images(image_url)\n\n    def create_content_opf(self):\n        self.css = next(os.walk(self.css_path))[2]\n        self.images = next(os.walk(self.images_path))[2]\n\n        manifest = []\n        spine = []\n        for c in self.book_chapters:\n            c[\"filename\"] = c[\"filename\"].replace(\".html\", \".xhtml\")\n            item_id = escape(\"\".join(c[\"filename\"].split(\".\")[:-1]))\n            manifest.append(\"<item id=\\\"{0}\\\" href=\\\"{1}\\\" media-type=\\\"application/xhtml+xml\\\" />\".format(\n                item_id, c[\"filename\"]\n            ))\n            spine.append(\"<itemref idref=\\\"{0}\\\"/>\".format(item_id))\n\n        for i in set(self.images):\n            dot_split = i.split(\".\")\n            head = \"img_\" + escape(\"\".join(dot_split[:-1]))\n            extension = dot_split[-1]\n            manifest.append(\"<item id=\\\"{0}\\\" href=\\\"Images/{1}\\\" media-type=\\\"image/{2}\\\" />\".format(\n                head, i, \"jpeg\" if \"jp\" in extension else extension\n            ))\n\n        for i in range(len(self.css)):\n            manifest.append(\"<item id=\\\"style_{0:0>2}\\\" href=\\\"Styles/Style{0:0>2}.css\\\" \"\n                            \"media-type=\\\"text/css\\\" />\".format(i))\n\n        authors = \"\\n\".join(\"<dc:creator opf:file-as=\\\"{0}\\\" opf:role=\\\"aut\\\">{0}</dc:creator>\".format(\n            escape(aut.get(\"name\", \"n/d\"))\n        ) for aut in self.book_info.get(\"authors\", []))\n\n        subjects = \"\\n\".join(\"<dc:subject>{0}</dc:subject>\".format(escape(sub.get(\"name\", \"n/d\")))\n                             for sub in self.book_info.get(\"subjects\", []))\n\n        return self.CONTENT_OPF.format(\n            (self.book_info.get(\"isbn\",  self.book_id)),\n            escape(self.book_title),\n            authors,\n            escape(self.book_info.get(\"description\", \"\")),\n            subjects,\n            \", \".join(escape(pub.get(\"name\", \"\")) for pub in self.book_info.get(\"publishers\", [])),\n            escape(self.book_info.get(\"rights\", \"\")),\n            self.book_info.get(\"issued\", \"\"),\n            self.cover,\n            \"\\n\".join(manifest),\n            \"\\n\".join(spine),\n            self.book_chapters[0][\"filename\"].replace(\".html\", \".xhtml\")\n        )\n\n    @staticmethod\n    def parse_toc(l, c=0, mx=0):\n        r = \"\"\n        for cc in l:\n            c += 1\n            if int(cc[\"depth\"]) > mx:\n                mx = int(cc[\"depth\"])\n\n            r += \"<navPoint id=\\\"{0}\\\" playOrder=\\\"{1}\\\">\" \\\n                 \"<navLabel><text>{2}</text></navLabel>\" \\\n                 \"<content src=\\\"{3}\\\"/>\".format(\n                    cc[\"fragment\"] if len(cc[\"fragment\"]) else cc[\"id\"], c,\n                    escape(cc[\"label\"]), cc[\"href\"].replace(\".html\", \".xhtml\").split(\"/\")[-1]\n                 )\n\n            if cc[\"children\"]:\n                sr, c, mx = SafariBooks.parse_toc(cc[\"children\"], c, mx)\n                r += sr\n\n            r += \"</navPoint>\\n\"\n\n        return r, c, mx\n\n    def create_toc(self):\n        response = self.requests_provider(urljoin(self.api_url, \"toc/\"))\n        if response == 0:\n            self.display.exit(\"API: unable to retrieve book chapters. \"\n                              \"Don't delete any files, just run again this program\"\n                              \" in order to complete the `.epub` creation!\")\n\n        response = response.json()\n\n        if not isinstance(response, list) and len(response.keys()) == 1:\n            self.display.exit(\n                self.display.api_error(response) +\n                \" Don't delete any files, just run again this program\"\n                \" in order to complete the `.epub` creation!\"\n            )\n\n        navmap, _, max_depth = self.parse_toc(response)\n        return self.TOC_NCX.format(\n            (self.book_info[\"isbn\"] if self.book_info[\"isbn\"] else self.book_id),\n            max_depth,\n            self.book_title,\n            \", \".join(aut.get(\"name\", \"\") for aut in self.book_info.get(\"authors\", [])),\n            navmap\n        )\n\n    def create_epub(self):\n        open(os.path.join(self.BOOK_PATH, \"mimetype\"), \"w\").write(\"application/epub+zip\")\n        meta_info = os.path.join(self.BOOK_PATH, \"META-INF\")\n        if os.path.isdir(meta_info):\n            self.display.log(\"META-INF directory already exists: %s\" % meta_info)\n\n        else:\n            os.makedirs(meta_info)\n\n        open(os.path.join(meta_info, \"container.xml\"), \"wb\").write(\n            self.CONTAINER_XML.encode(\"utf-8\", \"xmlcharrefreplace\")\n        )\n        open(os.path.join(self.BOOK_PATH, \"OEBPS\", \"content.opf\"), \"wb\").write(\n            self.create_content_opf().encode(\"utf-8\", \"xmlcharrefreplace\")\n        )\n        open(os.path.join(self.BOOK_PATH, \"OEBPS\", \"toc.ncx\"), \"wb\").write(\n            self.create_toc().encode(\"utf-8\", \"xmlcharrefreplace\")\n        )\n\n        zip_file = os.path.join(PATH, \"Books\", self.book_id)\n        if os.path.isfile(zip_file + \".zip\"):\n            os.remove(zip_file + \".zip\")\n\n        shutil.make_archive(zip_file, 'zip', self.BOOK_PATH)\n        os.rename(zip_file + \".zip\", os.path.join(self.BOOK_PATH, self.book_id) + \".epub\")\n\n\n# MAIN\nif __name__ == \"__main__\":\n    arguments = argparse.ArgumentParser(prog=\"safaribooks.py\",\n                                        description=\"Download and generate an EPUB of your favorite books\"\n                                                    \" from Safari Books Online.\",\n                                        add_help=False,\n                                        allow_abbrev=False)\n\n    login_arg_group = arguments.add_mutually_exclusive_group()\n    login_arg_group.add_argument(\n        \"--cred\", metavar=\"<EMAIL:PASS>\", default=False,\n        help=\"Credentials used to perform the auth login on Safari Books Online.\"\n             \" Es. ` --cred \\\"account_mail@mail.com:password01\\\" `.\"\n    )\n    login_arg_group.add_argument(\n        \"--login\", action='store_true',\n        help=\"Prompt for credentials used to perform the auth login on Safari Books Online.\"\n    )\n\n    arguments.add_argument(\n        \"--no-cookies\", dest=\"no_cookies\", action='store_true',\n        help=\"Prevent your session data to be saved into `cookies.json` file.\"\n    )\n    arguments.add_argument(\n        \"--kindle\", dest=\"kindle\", action='store_true',\n        help=\"Add some CSS rules that block overflow on `table` and `pre` elements.\"\n             \" Use this option if you're going to export the EPUB to E-Readers like Amazon Kindle.\"\n    )\n    arguments.add_argument(\n        \"--preserve-log\", dest=\"log\", action='store_true', help=\"Leave the `info_XXXXXXXXXXXXX.log`\"\n                                                                \" file even if there isn't any error.\"\n    )\n    arguments.add_argument(\"--help\", action=\"help\", default=argparse.SUPPRESS, help='Show this help message.')\n    arguments.add_argument(\n        \"bookid\", metavar='<BOOK ID>',\n        help=\"Book digits ID that you want to download. You can find it in the URL (X-es):\"\n             \" `\" + SAFARI_BASE_URL + \"/library/view/book-name/XXXXXXXXXXXXX/`\"\n    )\n\n    args_parsed = arguments.parse_args()\n    if args_parsed.cred or args_parsed.login:\n        user_email = \"\"\n        pre_cred = \"\"\n\n        if args_parsed.cred:\n            pre_cred = args_parsed.cred\n\n        else:\n            user_email = input(\"Email: \")\n            passwd = getpass.getpass(\"Password: \")\n            pre_cred = user_email + \":\" + passwd\n\n        parsed_cred = SafariBooks.parse_cred(pre_cred)\n\n        if not parsed_cred:\n            arguments.error(\"invalid credential: %s\" % (\n                args_parsed.cred if args_parsed.cred else (user_email + \":*******\")\n            ))\n\n        args_parsed.cred = parsed_cred\n\n    else:\n        if args_parsed.no_cookies:\n            arguments.error(\"invalid option: `--no-cookies` is valid only if you use the `--cred` option\")\n\n    SafariBooks(args_parsed)\n    # Hint: do you want to download more then one book once, initialized more than one instance of `SafariBooks`...\n    sys.exit(0)\n"
        },
        {
          "name": "sso_cookies.py",
          "type": "blob",
          "size": 1.328125,
          "content": "\"\"\"\nScript for SSO support, saves and converts the cookie string retrieved by the browser.\nPlease follow:\n- https://github.com/lorenzodifuccia/safaribooks/issues/26\n- https://github.com/lorenzodifuccia/safaribooks/issues/150#issuecomment-555423085\n- https://github.com/lorenzodifuccia/safaribooks/issues/2#issuecomment-367726544\n\n\nThanks: @elrob, @noxymon\n\"\"\"\n\nimport json\nimport safaribooks\n\n\ndef transform(cookies_string):\n    cookies = {}\n    for cookie in cookies_string.split(\"; \"):\n        key, value = cookie.split(\"=\", 1)\n        cookies[key] = value\n\n    print(cookies)\n    json.dump(cookies, open(safaribooks.COOKIES_FILE, 'w'))\n    print(\"\\n\\nDone! Cookie Jar saved into `cookies.json`. \"\n          \"Now you can run `safaribooks.py` without the `--cred` argument...\")\n\n\nUSAGE = \"\\n\\n[*] Please use this command putting as argument the cookies retrieved by your browser.\\n\" + \\\n        \"[+] In order to do so, please follow these steps: \\n\" + \\\n        \"https://github.com/lorenzodifuccia/safaribooks/issues/150#issuecomment-555423085\\n\"\n\nif __name__ == \"__main__\":\n    import sys\n    if len(sys.argv) < 2:\n        print(\"[!] Error: too few arguments.\" + USAGE)\n        exit(1)\n\n    elif len(sys.argv) > 2:\n        print(\"[!] Error: too much arguments, try to enclose the string with quote '\\\"'.\" + USAGE)\n        exit(1)\n\n    transform(sys.argv[1])\n"
        }
      ]
    }
  ]
}