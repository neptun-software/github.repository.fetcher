{
  "metadata": {
    "timestamp": 1736560389401,
    "page": 939,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjk1MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "X-PLUG/MobileAgent",
      "stars": 3263,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0869140625,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n\n# custom\n**/screenshot/*\n**/temp/*\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.037109375,
          "content": "MIT License\n\nCopyright (c) 2022 mPLUG\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "Mobile-Agent-v2",
          "type": "tree",
          "content": null
        },
        {
          "name": "Mobile-Agent-v3",
          "type": "tree",
          "content": null
        },
        {
          "name": "Mobile-Agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "PC-Agent",
          "type": "tree",
          "content": null
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 5.1357421875,
          "content": "![](assets/logo.png?v=1&type=image)\n<div align=\"center\">\n<h3>Mobile-Agent: The Powerful Mobile Device Operation Assistant Family<h3>\n<div align=\"center\">\n\t<a href=\"https://huggingface.co/spaces/junyangwang0410/Mobile-Agent\"><img src=\"https://huggingface.co/datasets/huggingface/badges/raw/main/open-in-hf-spaces-sm-dark.svg\" alt=\"Open in Spaces\"></a>\n\t<a href=\"https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2\"><img src=\"assets/Demo-ModelScope-brightgreen.svg\" alt=\"Demo ModelScope\"></a>\n  <a href=\"https://arxiv.org/abs/2401.16158\"><img src=\"https://img.shields.io/badge/Arxiv-2401.16158-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n  <a href=\"https://arxiv.org/abs/2406.01014 \"><img src=\"https://img.shields.io/badge/Arxiv-2406.01014-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n</div>\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/7423\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/7423\" alt=\"MobileAgent | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n</div>\n\n<div align=\"center\">\n<a href=\"README.md\">English</a> | <a href=\"README_zh.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> | <a href=\"README_ja.md\">Êó•Êú¨Ë™û</a>\n<hr>\n</div>\n\n## üì∫Demo\n\n### Mobile-Agent-v3 (Note: The video is not accelerated)\n**YouTube**\n\n[![YouTube](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.youtube.com/watch?v=EMbIpzqJld0)\n\n**Bilibili**\n\n[![Bilibili](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.bilibili.com/video/BV1pPvyekEsa/?share_source=copy_web&vd_source=47ffcd57083495a8965c8cdbe1a751ae)\n\n### PC-Agent\n**Chrome and DingTalk**\n\nhttps://github.com/user-attachments/assets/b890a08f-8a2f-426d-9458-aa3699185030\n\n**Word**\n\nhttps://github.com/user-attachments/assets/37f0a0a5-3d21-4232-9d1d-0fe845d0f77d\n\n### Mobile-Agent-v2\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/d907795d-b5b9-48bf-b1db-70cf3f45d155\n\n### Mobile-Agent\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/26c48fb0-67ed-4df6-97b2-aa0c18386d31\n\n\n## üì¢News\n* üî•üî•[9.26] Mobile-Agent-v2 has been accepted by **The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)**.\n* üî•[8.23] We proposed PC-Agent, a **PC** operation assistant supporting both **Mac and Windows** platforms.\n* üî•[7.29] Mobile-Agent won the **best demo award** at the ***The 23rd China National Conference on Computational Linguistics*** (CCL 2024). On the CCL 2024, we displayed the upcoming Mobile-Agent-v3. It has smaller memory overhead (8 GB), faster reasoning speed (10s-15s per operation), and all uses open source models. Video demo, please see the last section üì∫Demo.\n* [6.27] We proposed Demo that can upload mobile phone screenshots to experience Mobile-Agent-V2 in [Hugging Face](https://huggingface.co/spaces/junyangwang0410/Mobile-Agent) and [ModelScope](https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2). You don‚Äôt need to configure models and devices, and you can experience it immediately.\n* [6. 4] Modelscope-Agent has supported Mobile-Agent-V2, based on Android Adb Env, please check in the [application](https://github.com/modelscope/modelscope-agent/tree/master/apps/mobile_agent).\n* [6. 4] We proposed Mobile-Agent-v2, a mobile device operation assistant with effective navigation via multi-agent collaboration.\n* [3.10] Mobile-Agent has been accepted by the **ICLR 2024 Workshop on Large Language Model (LLM) Agents**.\n\n## üì±Version\n* [Mobile-Agent-v3](Mobile-Agent-v3/README.md)\n* [Mobile-Agent-v2](Mobile-Agent-v2/README.md) - Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration\n* [Mobile-Agent](Mobile-Agent/README.md) - Autonomous Multi-Modal Mobile Device Agent with Visual Perception\n\n## ‚≠êStar History\n[![Star History Chart](https://api.star-history.com/svg?repos=X-PLUG/MobileAgent&type=Date)](https://star-history.com/#X-PLUG/MobileAgent&Date)\n\n## üìëCitation\nIf you find Mobile-Agent useful for your research and applications, please cite using this BibTeX:\n```\n@article{wang2024mobile2,\n  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},\n  author={Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2406.01014},\n  year={2024}\n}\n\n@article{wang2024mobile,\n  title={Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception},\n  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2401.16158},\n  year={2024}\n}\n```\n\n## üì¶Related Projects\n* [AppAgent: Multimodal Agents as Smartphone Users](https://github.com/mnotgod96/AppAgent)\n* [mPLUG-Owl & mPLUG-Owl2: Modularized Multimodal Large Language Model](https://github.com/X-PLUG/mPLUG-Owl)\n* [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://github.com/QwenLM/Qwen-VL)\n* [GroundingDINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://github.com/IDEA-Research/GroundingDINO)\n* [CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)\n"
        },
        {
          "name": "README_ja.md",
          "type": "blob",
          "size": 5.6455078125,
          "content": "![](assets/logo.png?v=1&type=image)\n<div align=\"center\">\n<h3>Mobile-Agent: Âº∑Âäõ„Å™„É¢„Éê„Ç§„É´„Éá„Éê„Ç§„ÇπÊìç‰Ωú„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Éï„Ç°„Éü„É™„Éº<h3>\n<div align=\"center\">\n\t<a href=\"https://huggingface.co/spaces/junyangwang0410/Mobile-Agent\"><img src=\"https://huggingface.co/datasets/huggingface/badges/raw/main/open-in-hf-spaces-sm-dark.svg\" alt=\"Open in Spaces\"></a>\n\t<a href=\"https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2\"><img src=\"assets/Demo-ModelScope-brightgreen.svg\" alt=\"Demo ModelScope\"></a>\n  <a href=\"https://arxiv.org/abs/2401.16158\"><img src=\"https://img.shields.io/badge/Arxiv-2401.16158-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n  <a href=\"https://arxiv.org/abs/2406.01014 \"><img src=\"https://img.shields.io/badge/Arxiv-2406.01014-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n</div>\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/7423\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/7423\" alt=\"MobileAgent | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n</div>\n\n<div align=\"center\">\n<a href=\"README_ja.md\">Êó•Êú¨Ë™û</a> | <a href=\"README.md\">English</a> | <a href=\"README_zh.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a>\n<hr>\n</div>\n<!--\nÊó•Êú¨Ë™û | [English](README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh.md)\n<hr>\n-->\n\n## üì∫„Éá„É¢\n\n### Mobile-Agent-v3ÔºàÊ≥®Ôºö„Éì„Éá„Ç™„ÅØÂä†ÈÄü„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„ÇìÔºâ\n**YouTube**\n\n[![YouTube](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.youtube.com/watch?v=EMbIpzqJld0)\n\n**Bilibili**\n\n[![Bilibili](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.bilibili.com/video/BV1pPvyekEsa/?share_source=copy_web&vd_source=47ffcd57083495a8965c8cdbe1a751ae)\n\n### PC-Agent\n**Chrome and DingTalk**\n\nhttps://github.com/user-attachments/assets/b890a08f-8a2f-426d-9458-aa3699185030\n\n**Word**\n\nhttps://github.com/user-attachments/assets/37f0a0a5-3d21-4232-9d1d-0fe845d0f77d\n\n### Mobile-Agent-v2\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/d907795d-b5b9-48bf-b1db-70cf3f45d155\n\n### Mobile-Agent\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/26c48fb0-67ed-4df6-97b2-aa0c18386d31\n\n\n## üì¢„Éã„É•„Éº„Çπ\n* üî•üî•[9.26] Mobile-Agent-v2 „ÅØ **The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)** „Å´„Çà„Å£„Å¶ÊâøË™ç„Åï„Çå„Åæ„Åó„Åü„ÄÇ\n* üî•[8.23] Mac„Å®Windows„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Å´ÂØæÂøú„Åó„ÅüPCÊìç‰Ωú„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„ÄåPC-Agent„Äç„Çí„É™„É™„Éº„Çπ„Åó„Åæ„Åó„Åü„ÄÇ\n* üî•[7.29] Mobile-Agent„ÄÅ***Ë®àÁÆóË®ÄË™ûÂ≠¶„Å´Èñ¢„Åô„ÇãÁ¨¨23Âõû‰∏≠ÂõΩÂÖ®ÂõΩ‰ºöË≠∞***ÔºàCCL 2024Ôºâ„Åß**„Éô„Çπ„Éà„Éá„É¢Ë≥û**„ÇíÂèóË≥û„Åó„Åæ„Åó„Åü„ÄÇ CCL 2024„Åß„ÅØ„ÄÅ‰ªäÂæå„ÅÆMobile-Agent-V3„ÇíÁ§∫„Åó„Åæ„Åó„Åü„ÄÇ„É°„É¢„É™„Ç™„Éº„Éê„Éº„Éò„ÉÉ„ÉâÔºà8 GBÔºâ„ÅåÂ∞è„Åï„Åè„ÄÅÊé®Ë´ñÈÄüÂ∫¶„ÅåÈ´ò„ÅèÔºàÊìç‰Ωú„ÅÇ„Åü„Çä10S-15SÔºâ„ÄÅ„Åô„Åπ„Å¶„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„É¢„Éá„É´„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Éì„Éá„Ç™„Éá„É¢„ÄÅ„Çª„ÇØ„Ç∑„Éß„É≥üì∫Demo„ÇíÂèÇÁÖß„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n* [6.27] [Hugging Face](https://huggingface.co/spaces/junyangwang0410/Mobile-Agent)„Å®[ModelScope](https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2)„Åß„ÄÅMobile-Agent-v2„ÅÆ„Éá„É¢„ÇíÂÖ¨Èñã„Åó„Åæ„Åó„Åü„ÄÇÊê∫Â∏ØÈõªË©±„ÅÆ„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶‰ΩìÈ®ì„Åß„Åç„Åæ„Åô„ÄÇ„É¢„Éá„É´„ÇÑ„Éá„Éê„Ç§„Çπ„ÅÆË®≠ÂÆö„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ\n* [6. 4] Modelscope-Agent„ÅØ„ÄÅAndroid Adb Env„Å´Âü∫„Å•„ÅÑ„Å¶Mobile-Agent-V2„Çí„Çµ„Éù„Éº„Éà„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇË©≥Á¥∞„ÅØ[„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥](https://github.com/modelscope/modelscope-agent/tree/master/apps/mobile_agent)„Çí„ÅîË¶ß„Åè„Å†„Åï„ÅÑ„ÄÇ\n* [6. 4] Êñ∞‰∏ñ‰ª£„ÅÆ„É¢„Éê„Ç§„É´„Éá„Éê„Ç§„ÇπÊìç‰Ωú„Ç¢„Ç∑„Çπ„Çø„É≥„Éà Mobile-Agent-v2„ÇíÁô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ„Éû„É´„ÉÅ„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂçîÂäõ„Å´„Çà„ÇäÂäπÊûúÁöÑ„Å™„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥„ÇíÂÆüÁèæ„Åó„Åæ„Åô„ÄÇ\n* [3.10] Mobile-Agent„ÅØ**ICLR 2024 Workshop on Large Language Model (LLM) Agents**„Å´Êé°Êäû„Åï„Çå„Åæ„Åó„Åü„ÄÇ\n\n## üì±„Éê„Éº„Ç∏„Éß„É≥\n* [Mobile-Agent-v3](Mobile-Agent-v3/README.md)\n* [Mobile-Agent-v2](Mobile-Agent-v2/README_ja.md) - „Éû„É´„ÉÅ„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂçîÂäõ„Å´„Çà„ÇãÂäπÊûúÁöÑ„Å™„Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥„ÇíÂÆüÁèæ„Åô„Çã„É¢„Éê„Ç§„É´„Éá„Éê„Ç§„ÇπÊìç‰Ωú„Ç¢„Ç∑„Çπ„Çø„É≥„Éà\n* [Mobile-Agent](Mobile-Agent/README_ja.md) - Ë¶ñË¶öË™çË≠ò„ÇíÂÇô„Åà„ÅüËá™ÂæãÂûã„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´„É¢„Éê„Ç§„É´„Éá„Éê„Ç§„Çπ„Ç®„Éº„Ç∏„Çß„É≥„Éà\n\n## ‚≠ê„Çπ„Çø„ÉºÂ±•Ê≠¥\n[![Star History Chart](https://api.star-history.com/svg?repos=X-PLUG/MobileAgent&type=Date)](https://star-history.com/#X-PLUG/MobileAgent&Date)\n\n## üìëÂºïÁî®\nMobile-Agent„ÅåÁ†îÁ©∂„ÇÑ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Å´ÂΩπÁ´ã„Å§Â†¥Âêà„ÅØ„ÄÅÊ¨°„ÅÆBibTeX„Çí‰ΩøÁî®„Åó„Å¶ÂºïÁî®„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö\n```\n@article{wang2024mobile2,\n  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},\n  author={Wang, Junyang and Xu, Haiyang and Jia, Haitao and Zhang, Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2406.01014},\n  year={2024}\n}\n\n@article{wang2024mobile,\n  title={Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception},\n  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2401.16158},\n  year={2024}\n}\n```\n\n## üì¶Èñ¢ÈÄ£„Éó„É≠„Ç∏„Çß„ÇØ„Éà\n* [AppAgent: Multimodal Agents as Smartphone Users](https://github.com/mnotgod96/AppAgent)\n* [mPLUG-Owl & mPLUG-Owl2: Modularized Multimodal Large Language Model](https://github.com/X-PLUG/mPLUG-Owl)\n* [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://github.com/QwenLM/Qwen-VL)\n* [GroundingDINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://github.com/IDEA-Research/GroundingDINO)\n* [CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)\n"
        },
        {
          "name": "README_zh.md",
          "type": "blob",
          "size": 5.0654296875,
          "content": "![](assets/logo.png?v=1&type=image)\n<div align=\"center\">\n<h3>Mobile-Agent: Âº∫Â§ßÁöÑÁßªÂä®ËÆæÂ§áÊìç‰ΩúÂä©ÊâãÂÆ∂Êóè<h3>\n<div align=\"center\">\n\t<a href=\"https://huggingface.co/spaces/junyangwang0410/Mobile-Agent\"><img src=\"https://huggingface.co/datasets/huggingface/badges/raw/main/open-in-hf-spaces-sm-dark.svg\" alt=\"Open in Spaces\"></a>\n\t<a href=\"https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2\"><img src=\"assets/Demo-ModelScope-brightgreen.svg\" alt=\"Demo ModelScope\"></a>\n  <a href=\"https://arxiv.org/abs/2401.16158\"><img src=\"https://img.shields.io/badge/Arxiv-2401.16158-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n  <a href=\"https://arxiv.org/abs/2406.01014 \"><img src=\"https://img.shields.io/badge/Arxiv-2406.01014-b31b1b.svg?logo=arXiv\" alt=\"\"></a>\n</div>\n<p align=\"center\">\n<a href=\"https://trendshift.io/repositories/7423\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/7423\" alt=\"MobileAgent | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</p>\n</div>\n\n<div align=\"center\">\n<a href=\"README_zh.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> | <a href=\"README.md\">English</a> | <a href=\"README_ja.md\">Êó•Êú¨Ë™û</a>\n<hr>\n</div>\n<!--\nÁÆÄ‰Ωì‰∏≠Êñá | [English](README.md) | [Êó•Êú¨Ë™û](README_ja.md)\n<hr>\n-->\n\n## üì∫Demo\n\n### Mobile-Agent-v3ÔºàÊ≥®ÊÑèÔºöËØ•ËßÜÈ¢ëÊ≤°ÊúâÂä†ÈÄüÂ§ÑÁêÜÔºâ\n**YouTube**\n\n[![YouTube](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.youtube.com/watch?v=EMbIpzqJld0)\n\n**ÂìîÂì©ÂìîÂì©**\n\n[![Bilibili](https://img.youtube.com/vi/EMbIpzqJld0/0.jpg)](https://www.bilibili.com/video/BV1pPvyekEsa/?share_source=copy_web&vd_source=47ffcd57083495a8965c8cdbe1a751ae)\n\n### PC-Agent\n**Ë∞∑Ê≠åÊµèËßàÂô®‰∏éÈíâÈíâ**\n\nhttps://github.com/user-attachments/assets/b890a08f-8a2f-426d-9458-aa3699185030\n\n**Word**\n\nhttps://github.com/user-attachments/assets/37f0a0a5-3d21-4232-9d1d-0fe845d0f77d\n\n### Mobile-Agent-v2\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/d907795d-b5b9-48bf-b1db-70cf3f45d155\n\n### Mobile-Agent\nhttps://github.com/X-PLUG/MobileAgent/assets/127390760/26c48fb0-67ed-4df6-97b2-aa0c18386d31\n\n\n## üì¢Êñ∞Èóª\n* üî•üî•[9.26] Mobile-Agent-v2 Ë¢´ **The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024)** Êé•Êî∂„ÄÇ\n* üî•[8.23]Êàë‰ª¨ÂèëÂ∏É‰∫Ü‰∏Ä‰∏™ÊîØÊåÅMacÂíåWindowsÂπ≥Âè∞ÁöÑ**PC**Êìç‰ΩúÂä©ÊâãPC-Agent, ÈÄöËøáMobile-Agent-v2Ê°ÜÊû∂ÂÆûÁé∞„ÄÇ\n* üî•[7.29] Mobile-AgentËé∑Âæó‰∫Ü ***Á¨¨‰∫åÂçÅ‰∏âÂ±ä‰∏≠ÂõΩËÆ°ÁÆóËØ≠Ë®ÄÂ≠¶Â§ß‰ºö*** (CCL 2024) ÁöÑ **ÊúÄ‰Ω≥demoÂ•ñÈ°π**„ÄÇÂú®CCL 2024‰∏äÔºåÊàë‰ª¨Â±ïÁ§∫‰∫ÜÂç≥Â∞ÜÂºÄÊ∫êÁöÑMobile-Agent-v3ÔºåÊã•ÊúâÊõ¥Â∞èÁöÑÂÜÖÂ≠òÂºÄÈîÄÔºà8 GBÔºâ„ÄÅÊõ¥Âø´ÁöÑÊé®ÁêÜÈÄüÂ∫¶ÔºàÊØèÊ¨°Êìç‰Ωú10-15ÁßíÔºâÔºåÂπ∂‰∏î‰ΩøÁî®ÂºÄÊ∫êÊ®°Âûã„ÄÇËßÜÈ¢ëDemoËØ∑ËßÅ‰∏ä‰∏Ä‰∏™ÊùøÂùóüì∫Demo„ÄÇ\n* [6.27] Êàë‰ª¨Âú®[Hugging Face](https://huggingface.co/spaces/junyangwang0410/Mobile-Agent)Âíå[ModelScope](https://modelscope.cn/studios/wangjunyang/Mobile-Agent-v2)ÂèëÂ∏É‰∫ÜÂèØ‰ª•‰∏ä‰º†ÊâãÊú∫Êà™Âõæ‰ΩìÈ™åMobile-Agent-v2ÁöÑDemoÔºåÊó†ÈúÄÈÖçÁΩÆÊ®°ÂûãÂíåËÆæÂ§áÔºåÂç≥Âàª‰æøÂèØ‰ΩìÈ™å„ÄÇ\n* [6. 4] Modelscope-Agent Â∑≤ÁªèÊîØÊåÅ Mobile-Agent-V2ÔºåÂü∫‰∫é Android Adb EnvÔºåËØ∑Êü•Áúã [application](https://github.com/modelscope/modelscope-agent/tree/master/apps/mobile_agent)„ÄÇ\n* [6. 4] Êàë‰ª¨ÂèëÂ∏É‰∫ÜÊñ∞‰∏Ä‰ª£ÁßªÂä®ËÆæÂ§áÊìç‰ΩúÂä©Êâã Mobile-Agent-v2, ÈÄöËøáÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÂÆûÁé∞ÊúâÊïàÂØºËà™„ÄÇ\n* [3.10] Mobile-Agent Ë¢´ **ICLR 2024 Workshop on Large Language Model (LLM) Agents** Êé•Êî∂„ÄÇ\n\n## üì±ÁâàÊú¨\n* [Mobile-Agent-v3](Mobile-Agent-v3/README_zh.md)\n* [Mobile-Agent-v2](Mobile-Agent-v2/README_zh.md) - ÈÄöËøáÂ§ö‰ª£ÁêÜÂçè‰ΩúÊúâÊïàÂØºËà™ÁöÑÁßªÂä®ËÆæÂ§áÊìç‰ΩúÂä©Êâã\n* [Mobile-Agent](Mobile-Agent/README_zh.md) - ËßÜËßâÊÑüÁü•ÊñπÊ°àÁöÑËá™Âä®ÂåñÁßªÂä®ËÆæÂ§áÊìç‰ΩúÊô∫ËÉΩ‰Ωì\n\n## ‚≠êStarÂéÜÂè≤\n[![Star History Chart](https://api.star-history.com/svg?repos=X-PLUG/MobileAgent&type=Date)](https://star-history.com/#X-PLUG/MobileAgent&Date)\n\n## ÂºïÁî®\nIf you find Mobile-Agent useful for your research and applications, please cite using this BibTeX:\n```\n@article{wang2024mobile2,\n  title={Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration},\n  author={Wang, Junyang and Xu, Haiyang and Jia Haitao and Zhang Xi and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2406.01014},\n  year={2024}\n}\n\n@article{wang2024mobile,\n  title={Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception},\n  author={Wang, Junyang and Xu, Haiyang and Ye, Jiabo and Yan, Ming and Shen, Weizhou and Zhang, Ji and Huang, Fei and Sang, Jitao},\n  journal={arXiv preprint arXiv:2401.16158},\n  year={2024}\n}\n```\n\n## üì¶Áõ∏ÂÖ≥È°πÁõÆ\n* [AppAgent: Multimodal Agents as Smartphone Users](https://github.com/mnotgod96/AppAgent)\n* [mPLUG-Owl & mPLUG-Owl2: Modularized Multimodal Large Language Model](https://github.com/X-PLUG/mPLUG-Owl)\n* [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://github.com/QwenLM/Qwen-VL)\n* [GroundingDINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection](https://github.com/IDEA-Research/GroundingDINO)\n* [CLIP: Contrastive Language-Image Pretraining](https://github.com/openai/CLIP)\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}