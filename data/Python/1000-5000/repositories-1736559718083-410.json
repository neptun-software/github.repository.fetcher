{
  "metadata": {
    "timestamp": 1736559718083,
    "page": 410,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjQxMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "openai/transformer-debugger",
      "stars": 4053,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.8046875,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Cached user explanations\ncached_explanations/\n"
        },
        {
          "name": ".isort.cfg",
          "type": "blob",
          "size": 0.1015625,
          "content": "[settings]\nprofile = black\n\nknown_firstparty=\n    neuron_explainer\n    neuron_viewer\n\nline_length = 100\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 0.5390625,
          "content": "repos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix, --unsafe-fixes, --fix-only, --exit-non-zero-on-fix]\n        files: neuron_explainer\n\n  - repo: https://github.com/hauntsaninja/black-pre-commit-mirror\n    rev: 23.10.0\n    hooks:\n      - id: black\n        args: [--line-length=100, --exclude=\"\", --workers=6]\n\n  - repo: https://github.com/pycqa/isort\n    rev: 5.12.0\n    hooks:\n      - id: isort\n        args: [--line-length=100, --profile=black, --settings-path=.isort.cfg]\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.0380859375,
          "content": "MIT License\n\nCopyright (c) 2024 OpenAI\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.14453125,
          "content": "# Transformer Debugger\n\nTransformer Debugger (TDB) is a tool developed by OpenAI's [Superalignment\nteam](https://openai.com/blog/introducing-superalignment) with the goal of\nsupporting investigations into specific behaviors of small language models. The tool combines\n[automated interpretability](https://openai.com/research/language-models-can-explain-neurons-in-language-models)\ntechniques with [sparse autoencoders](https://transformer-circuits.pub/2023/monosemantic-features).\n\nTDB enables rapid exploration before needing to write code, with the ability to intervene in the\nforward pass and see how it affects a particular behavior. It can be used to answer questions like,\n\"Why does the model output token A instead of token B for this prompt?\" or \"Why does attention head\nH attend to token T for this prompt?\" It does so by identifying specific components (neurons,\nattention heads, autoencoder latents) that contribute to the behavior, showing automatically\ngenerated explanations of what causes those components to activate most strongly, and tracing\nconnections between components to help discover circuits.\n\nThese videos give an overview of TDB and show how it can be used to investigate [indirect object\nidentification in GPT-2 small](https://arxiv.org/abs/2211.00593):\n\n- [Introduction](https://www.loom.com/share/721244075f12439496db5d53439d2f84?sid=8445200e-c49e-4028-8b8e-3ea8d361dec0)\n- [Neuron viewer pages](https://www.loom.com/share/21b601b8494b40c49b8dc7bfd1dc6829?sid=ee23c00a-9ede-4249-b9d7-c2ba15993556)\n- [Example: Investigating name mover heads, part 1](https://www.loom.com/share/3478057cec484a1b85471585fef10811?sid=b9c3be4b-7117-405a-8d31-0f9e541dcfb6)\n- [Example: Investigating name mover heads, part 2](https://www.loom.com/share/6bd8c6bde84b42a98f9a26a969d4a3ad?sid=4a09ac29-58a2-433e-b55d-762414d9a7fa)\n\n## What's in the release?\n\n- [Neuron viewer](neuron_viewer/README.md): A React app that hosts TDB as well as pages with information about individual model components (MLP neurons, attention heads and autoencoder latents for both).\n- [Activation server](neuron_explainer/activation_server/README.md): A backend server that performs inference on a subject model to provide data for TDB. It also reads and serves data from public Azure buckets.\n- [Models](neuron_explainer/models/README.md): A simple inference library for GPT-2 models and their autoencoders, with hooks to grab activations.\n- [Collated activation datasets](datasets.md): top-activating dataset examples for MLP neurons, attention heads and autoencoder latents.\n\n## Setup\n\nFollow these steps to install the repo.  You'll first need python/pip, as well as node/npm.\n\nThough optional, we recommend you use a virtual environment or equivalent:\n\n```sh\n# If you're already in a venv, deactivate it.\ndeactivate\n# Create a new venv.\npython -m venv ~/.virtualenvs/transformer-debugger\n# Activate the new venv.\nsource ~/.virtualenvs/transformer-debugger/bin/activate\n```\n\nOnce your environment is set up, follow the following steps:\n```sh\ngit clone git@github.com:openai/transformer-debugger.git\ncd transformer-debugger\n\n# Install neuron_explainer\npip install -e .\n\n# Set up the pre-commit hooks.\npre-commit install\n\n# Install neuron_viewer.\ncd neuron_viewer\nnpm install\ncd ..\n```\n\nTo run the TDB app, you'll then need to follow the instructions to set up the [activation server backend](neuron_explainer/activation_server/README.md) and [neuron viewer frontend](neuron_viewer/README.md).\n\n## Making changes\n\nTo validate changes:\n\n- Run `pytest`\n- Run `mypy --config=mypy.ini .`\n- Run activation server and neuron viewer and confirm that basic functionality like TDB and neuron\n  viewer pages is still working\n\n\n## Links\n\n- [Terminology](terminology.md)\n\n## How to cite\n\nPlease cite as:\n\n```\nMossing, et al., “Transformer Debugger”, GitHub, 2024.\n```\n\nBibTex citation:\n\n```\n@misc{mossing2024tdb,\n  title={Transformer Debugger},\n  author={Mossing, Dan and Bills, Steven and Tillman, Henk and Dupré la Tour, Tom and Cammarata, Nick and Gao, Leo and Achiam, Joshua and Yeh, Catherine and Leike, Jan and Wu, Jeff and Saunders, William},\n  year={2024},\n  publisher={GitHub},\n  howpublished={\\url{https://github.com/openai/transformer-debugger}},\n}\n```\n"
        },
        {
          "name": "datasets.md",
          "type": "blob",
          "size": 4.03125,
          "content": "# Collated activation datasets\n\nThis document lists the collated activation datasets that are compatible with the Transformer Debugger. These datasets contain some top-activating examples for each MLP neuron, attention head, and autoencoder latent, as well as the corresponding activations for each token (or token pair) in the example. They provide a way to visualize what each neuron, attention head, or autoencoder latent is selective for (obviously in an incomplete way). These activation datasets are used by the [neuron viewer](neuron_viewer/README.md) to display the top-activating examples for each component, and are also typically used for [automated interpretability](https://openai.com/research/language-models-can-explain-neurons-in-language-models).\n\nThe activations datasets are located on Azure Blob Storage, for example accessible via the [`blobfile`](https://github.com/blobfile/blobfile) library. \n\n# GPT-2 small\n\nCollated activation datasets are available for both the MLP neurons and the attention heads. MLP neuron activations are recorded for each token, while attention head activations are recorded for each token pair. \n\nThe datasets are located at the following paths:\n> - MLP neurons: `https://openaipublic.blob.core.windows.net/neuron-explainer/gpt2_small_data/collated-activations/{layer_index}/{neuron_index}.json`\n> - Attention heads: `https://openaipublic.blob.core.windows.net/neuron-explainer/gpt2_small/attn_write_norm/collated-activations-by-token-pair/{layer_index}/{head_index}.json`\n\nwith the following parameters:\n- `layer_index` is in range(12)\n- `neuron_index` is in range(3084)\n- `head_index` is in range(12)\n\n\n## GPT-2 small - MLP autoencoders\n\nMLP autoencoders were trained either on the MLP neurons (after the activation function), or on the MLP-layer output that is written to the residual stream. See [Autoencoders for GPT-2 small](neuron_explainer/models/README.md#sparse-autoencoder) for more details. \n\nThe datasets are located at the following paths:\n\n> - MLP latents: `https://openaipublic.blob.core.windows.net/neuron-explainer/gpt2-small/autoencoder_latent/{autoencoder_input}{version}/collated-activations/{layer_index}/{latent_index}.pt`\n\nwith the following parameters:\n- `autoencoder_input` is in [\"mlp_post_act\", \"resid_delta_mlp\"]\n- `version` is in [\"\", \"_v4\"]. (The `_v4` versions use slightly different hyperparameters, and should be preferred.)\n- `layer_index` is in range(12)\n- `latent_index` is in range(32768)\n\n## GPT-2 small - Attention autoencoders\n\nAttention autoencoders were trained on the attention-layer output that is written to the residual stream. See [Autoencoders for GPT-2 small](neuron_explainer/models/README.md#sparse-autoencoder) for more details. The `collated-activations` dataset contains autoencoder latent activations for each token, while the `collated-activations-by-token-pair` dataset contains autoencoder latent *attribution* to each token pair. To compute the attribution given an autoencoder latent `L` and a token pair `(T1, T2)`, we multiply the attention pattern `A(T1, T2)` with the gradient of `L` with respect to the attention pattern: `attribution_L(T1, T2) = A(T1, T2) * ∂L/∂A(T1, T2)`. \n\nThe datasets are located at the following paths:\n\n> - Attention latents (by token): `https://openaipublic.blob.core.windows.net/neuron-explainer/gpt2-small/autoencoder_latent/resid_delta_attn_v4/collated-activations/{layer_index}/{latent_index}.pt`\n> - Attention latents (by token pair): `https://openaipublic.blob.core.windows.net/neuron-explainer/gpt2-small/autoencoder_latent/resid_delta_attn_v4/collated-activations-by-token-pair/{layer_index}/{latent_index}.pt`\n\nwith the following parameters:\n- `layer_index` is in range(12)\n- `latent_index` is in range(10240)\n\n\n\n# GPT-2 xl\n\nFor GPT-2 xl, only the MLP neurons activations are available. The datasets are located at the following paths:\n> - MLP neurons: `https://openaipublic.blob.core.windows.net/neuron-explainer/data/collated-activations/{layer_index}/{neuron_index}.json`\n\nwith the following parameters:\n- `layer_index` is in range(48)\n- `neuron_index` is in range(6400)\n"
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 0.7109375,
          "content": "[mypy]\n\n; Not all dependencies have type annotations; ignore this.\nignore_missing_imports=True\nnamespace_packages=True\nexplicit_package_bases = True\n\n; Be strict about certain rules.\nstrict_equality=True\nwarn_unused_configs=True\nno_implicit_optional=True\nstrict_optional=True\nwarn_redundant_casts=True\nwarn_unused_ignores=True\ncheck_untyped_defs=True\n\n[mypy-neuron_explainer.*]\nignore_errors=False\ndisallow_untyped_defs=True\n\n[mypy-neuron_explainer.api_client]\nignore_errors=True\n\n[mypy-neuron_explainer.models.hooks]\nignore_errors=True\n\n[mypy-neuron_explainer.models.transformer]\nignore_errors=True\n\n[mypy-neuron_explainer.tests.test_hooks]\nignore_errors=True\n\n[mypy-neuron_explainer.tests.test_transformer]\nignore_errors=True\n"
        },
        {
          "name": "neuron_explainer",
          "type": "tree",
          "content": null
        },
        {
          "name": "neuron_viewer",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.9609375,
          "content": "[tool.black]\nline-length = 100\ntarget-version = ['py311']\n\n[tool.ruff]\nline-length = 100\nselect = [\n    \"E\", \"F\", \"W\", \"B\", \"C4\", \"PIE\", \"NPY\", \"PLE\",\n    \"DTZ003\", \"DTZ004\",\n    \"G010\",\n    \"PLW0120\", \"PLW0129\", \"PLW0711\", \"PLW2101\",\n    \"SIM101\", \"SIM110\", \"SIM201\", \"SIM202\", \"SIM222\", \"SIM223\",\n    \"S506\",\n    \"RET501\", \"RET502\",\n    \"RUF006\", \"RUF008\", \"RUF011\", \"RUF013\", \"RUF016\", \"RUF017\", \"RUF200\",\n    \"COM818\", \"COM819\",\n    \"ISC001\",\n    \"PYI016\", \"PYI018\", \"PYI025\",\n    \"PERF102\",\n    \"UP006\", \"UP007\",\n    \"FURB148\", \"FURB163\", \"FURB181\",\n    \"ASYNC100\", \"ASYNC102\",\n    \"TID251\",\n]\nignore = [\n    \"B905\",\n    \"E2\",\n    \"E402\",\n    \"E501\",\n    \"E701\",\n    \"E711\",\n    \"E731\",\n    \"E741\",\n    \"B011\",\n    \"C408\",\n    \"NPY002\",\n    \"PIE790\",\n]\nunfixable = [\n    \"F841\",\n    \"F601\",\n    \"F602\",\n    \"B018\",\n    \"SIM222\",\n    \"SIM223\",\n    \"B006\",\n]\n\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\npreview = true\n\n[tool.ruff.per-file-ignores]\n\"__init__.py\" = [\"F401\", \"F403\"]\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.0283203125,
          "content": "[pytest]\nasyncio_mode = auto\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 0.58984375,
          "content": "from setuptools import find_packages, setup\n\nsetup(\n    name=\"neuron_explainer\",\n    packages=find_packages(),\n    version=\"0.0.1\",\n    author=\"OpenAI\",\n    install_requires=[\n        \"aiohttp\",\n        \"click\",\n        \"fastapi==0.97\",\n        \"fire\",\n        \"httpx>=0.22\",\n        \"mypy==1.7.1\",\n        \"numpy\",\n        \"orjson\",\n        \"pre-commit\",\n        \"pydantic<2.0.0\",\n        \"pytest\",\n        \"pytest-asyncio\",\n        \"scikit-learn\",\n        \"starlette\",\n        \"tiktoken\",\n        \"torch>=1.13\",\n        \"uvicorn\",\n    ],\n    url=\"\",\n    description=\"\",\n    python_requires=\">=3.11\",\n)\n"
        },
        {
          "name": "terminology.md",
          "type": "blob",
          "size": 5.5654296875,
          "content": "# TDB Terminology\n\n**Component**\n\n- An attention head or neuron, or autoencoder latent\n- Has some set of weights that define what the component does\n- Analogy:\n    - Component is like the code for a function\n    - Node is like the specific invocation of a function with specific input values and specific output values\n- When invoked, each component produces nodes that read something from the unnormalized residual stream, then write some vector (the “write vector”) to the unnormalized residual stream\n- Each component is independent from other components of the same type in the same layer\n\n**Node**\n\n- Specific invocation of a component which reads from the normalized residual stream at one token, maybe produces some intermediate values, and then writes to the normalized residual stream at one token\n- Comes from talking about nodes in a computation graph/causal graph\n- Neurons/latents produce one node per sequence token. they read from/write to the same token\n    - Neuron pre/post activations are intermediate values\n- Attention heads produce one node per pair of sequence tokens (reading from same/earlier token, writing to later token)\n    - Attention QK products, value vectors are intermediate values\n- Each node only exists in one forward/backward pass. If you modify the prompt and rerun, that would create different nodes\n\n**Write vector**\n\n- Vector written to the residual stream by a node\n\n**Circuit**\n\n- Set of nodes that work together to perform some behavior/reasoning\n\n**Latent**\n\n- Type of component corresponding to a direction in the activation space learned by a sparse autoencoder for a specific layer's MLP neurons or attention heads\n- They correspond more often to semantically meaningful features than neurons or attention heads do\n\n**Ablate**\n\n- Turn off a node\n- Right now we use zero-ablation, so the node won’t write anything to the residual stream. In principle we could implement other versions\n- Lets you observe the downstream effects of the node\n- Answers the question “What is the real effect of this node writing to the residual stream?”\n\n**Trace upstream**\n\n- Look at what upstream nodes caused this node to write to the residual stream\n- Answer the question “Why did this node write to the residual stream in this way?”\n\n**Direction of interest**\n\n- TDB looks at the importance of nodes in terms of their effect on a specific direction in the transformer representations\n    - In principle this could be a direction in the unnormalized residual stream, normalized residual stream, or some other vector space in transformer representations\n    - For now, the only option is the direction in the final normalized residual stream corresponding to the unembedding of a target token minus the unembedding of a distractor token\n- The activation of the direction of interest is the projection of the transformer’s representations onto the direction of interest at a specific token on a specific prompt, which yields a scalar value\n    - For token differences, the activation = difference in logits = log ratio of probabilities between these two tokens: log(p(target_token)/p(distractor_token))\n\n**Target token**\n\n- The token that corresponds to positive activation along direction of interest, usually the token the model assigns highest probability to\n\n**Distractor token**\n\n- The token that corresponds to negative activation along direction of interest, usually a plausible but incorrect token\n\n**Estimated total effect**\n\n- Estimate of the total effect of the node on the activation of the direction of interest\n- Positive values mean that the node increases the activation of the direction of interest; negative values mean that it decreases the activation\n- Accounts for the node directly affecting the direction of interest and the indirect effect through intermediate nodes\n- Implementation details:\n    - Computed by taking the dot product of the activation and the gradient of the direction of interest\n    - ACT_TIMES_GRAD in [derived scalars terminology](neuron_explainer/activations/derived_scalars/README.md)\n\n**Direct effect**\n\n- Projection of the node’s output onto the direction of interest\n- Positive values mean that the node increases the activation of the direction of interest; negative values mean that it decreases the activation\n- Only accounts for the node directly affecting the final residual stream, not impact through intermediate nodes\n- Implementation details:\n    - Computed by taking the dot product of the activation and the gradient of interest from the final residual stream\n    - WRITE_TO_FINAL_RESIDUAL_GRAD in [derived scalars terminology](neuron_explainer/activations/derived_scalars/README.md)\n\n**Write magnitude**\n\n- Magnitude of the write vector produced by the node, including information not relevant to direction of interest\n- Higher means that the node is more important to the forward pass\n- Implementation details:\n    - WRITE_NORM in [derived scalars terminology](neuron_explainer/activations/derived_scalars/README.md)\n\n**Layer**\n\n- Transformers consist of layers which each contain a block of attention heads, followed by a block of MLP neurons\n\n**Upstream**\n\n- Upstream in the causal graph. Modifying an upstream node can impact a downstream node\n- Node must be earlier in the forward pass, and must be at the same token or previous token, not a future token\n\n**Downstream**\n\n- Downstream in the causal graph. Modifying a downstream node cannot impact an upstream node (but can impact our estimates, because they use gradients which are impacted by all nodes in the graph)\n- Node must be later in the forward pass, and must be at the same token or a subsequent token, not a previous token\n"
        }
      ]
    }
  ]
}