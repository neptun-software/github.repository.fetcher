{
  "metadata": {
    "timestamp": 1736560423168,
    "page": 989,
    "hasNextPage": false,
    "endCursor": "Y3Vyc29yOjEwMDA=",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "charlesq34/pointnet2",
      "stars": 3195,
      "defaultBranch": "master",
      "files": [
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.2041015625,
          "content": "PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space.\n\nCopyright (c) 2017, Geometric Computation Group of Stanford University\n\nThe MIT License (MIT)\n\nCopyright (c) 2017 Charles R. Qi\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.3955078125,
          "content": "### PointNet++: *Deep Hierarchical Feature Learning on Point Sets in a Metric Space*\nCreated by <a href=\"http://charlesrqi.com\" target=\"_blank\">Charles R. Qi</a>, <a href=\"http://stanford.edu/~ericyi\">Li (Eric) Yi</a>, <a href=\"http://ai.stanford.edu/~haosu/\" target=\"_blank\">Hao Su</a>, <a href=\"http://geometry.stanford.edu/member/guibas/\" target=\"_blank\">Leonidas J. Guibas</a> from Stanford University.\n\n![prediction example](https://github.com/charlesq34/pointnet2/blob/master/doc/teaser.jpg)\n\n### Citation\nIf you find our work useful in your research, please consider citing:\n\n        @article{qi2017pointnetplusplus,\n          title={PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space},\n          author={Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},\n          journal={arXiv preprint arXiv:1706.02413},\n          year={2017}\n        }\n\n### Introduction\nThis work is based on our NIPS'17 paper. You can find arXiv version of the paper <a href=\"https://arxiv.org/pdf/1706.02413.pdf\">here</a> or check <a href=\"http://stanford.edu/~rqi/pointnet2\">project webpage</a> for a quick overview. PointNet++ is a follow-up project that builds on and extends <a href=\"https://github.com/charlesq34/pointnet\">PointNet</a>. It is version 2.0 of the PointNet architecture.\n\nPointNet (the v1 model) either transforms features of *individual points* independently or process global features of the *entire point set*. However, in many cases there are well defined distance metrics such as Euclidean distance for 3D point clouds collected by 3D sensors or geodesic distance for manifolds like isometric shape surfaces. In PointNet++ we want to respect *spatial localities* of those point sets. PointNet++ learns hierarchical features with increasing scales of contexts, just like that in convolutional neural networks. Besides, we also observe one challenge that is not present in convnets (with images) -- non-uniform densities in natural point clouds. To deal with those non-uniform densities, we further propose special layers that are able to intelligently aggregate information from different scales.\n\nIn this repository we release code and data for our PointNet++ classification and segmentation networks as well as a few utility scripts for training, testing and data processing and visualization.\n\n### Installation\n\nInstall <a href=\"https://www.tensorflow.org/install/\">TensorFlow</a>. The code is tested under TF1.2 GPU version and Python 2.7 (version 3 should also work) on Ubuntu 14.04. There are also some dependencies for a few Python libraries for data processing and visualizations like `cv2`, `h5py` etc. It's highly recommended that you have access to GPUs.\n\n#### Compile Customized TF Operators\nThe TF operators are included under `tf_ops`, you need to compile them (check `tf_xxx_compile.sh` under each ops subfolder) first. Update `nvcc` and `python` path if necessary. The code is tested under TF1.2.0. If you are using earlier version it's possible that you need to remove the `-D_GLIBCXX_USE_CXX11_ABI=0` flag in g++ command in order to compile correctly.\n\nTo compile the operators in TF version >=1.4, you need to modify the compile scripts slightly.\n\nFirst, find Tensorflow include and library paths.\n\n        TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')\n        TF_LIB=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')\n        \nThen, add flags of `-I$TF_INC/external/nsync/public -L$TF_LIB -ltensorflow_framework` to the `g++` commands.\n\n### Usage\n\n#### Shape Classification\n\nTo train a PointNet++ model to classify ModelNet40 shapes (using point clouds with XYZ coordinates):\n\n        python train.py\n\nTo see all optional arguments for training:\n\n        python train.py -h\n\nIf you have multiple GPUs on your machine, you can also run the multi-GPU version training (our implementation is similar to the tensorflow <a href=\"https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10\">cifar10 tutorial</a>):\n\n        CUDA_VISIBLE_DEVICES=0,1 python train_multi_gpu.py --num_gpus 2\n\nAfter training, to evaluate the classification accuracies (with optional multi-angle voting):\n\n        python evaluate.py --num_votes 12 \n\n<i>Side Note:</i> For the XYZ+normal experiment reported in our paper: (1) 5000 points are used and (2) a further random data dropout augmentation is used during training (see commented line after `augment_batch_data` in `train.py` and (3) the model architecture is updated such that the `nsample=128` in the first two set abstraction levels, which is suited for the larger point density in 5000-point samplings.\n\nTo use normal features for classification: You can get our sampled point clouds of ModelNet40 (XYZ and normal from mesh, 10k points per shape) <a href=\"https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip\">here (1.6GB)</a>. Move the uncompressed data folder to `data/modelnet40_normal_resampled`\n\n#### Object Part Segmentation\n\nTo train a model to segment object parts for ShapeNet models:\n\n        cd part_seg\n        python train.py\n\nPreprocessed ShapeNetPart dataset (XYZ, normal and part labels) can be found <a href=\"https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\">here (674MB)</a>. Move the uncompressed data folder to `data/shapenetcore_partanno_segmentation_benchmark_v0_normal`\n\n#### Semantic Scene Parsing\n\nSee `scannet/README` and `scannet/train.py` for details.\n\n#### Visualization Tools\nWe have provided a handy point cloud visualization tool under `utils`. Run `sh compile_render_balls_so.sh` to compile it and then you can try the demo with `python show3d_balls.py` The original code is from <a href=\"http://github.com/fanhqme/PointSetGeneration\">here</a>.\n\n#### Prepare Your Own Data\nYou can refer to <a href=\"https://github.com/charlesq34/3dmodel_feature/blob/master/io/write_hdf5.py\">here</a> on how to prepare your own HDF5 files for either classification or segmentation. Or you can refer to `modelnet_dataset.py` on how to read raw data files and prepare mini-batches from them. A more advanced way is to use TensorFlow's dataset APIs, for which you can find more documentations <a href=\"https://www.tensorflow.org/programmers_guide/datasets\">here</a>.\n\n### License\nOur code is released under MIT License (see LICENSE file for details).\n\n### Updates\n* 02/23/2018: Added support for multi-gpu training for the classification task.\n* 02/23/2018: Adopted a new way for data loading. No longer require manual data downloading to train a classification network.\n* 02/06/2018: Added sample training code for ScanNet semantic segmentation.\n\n### Related Projects\n\n* <a href=\"http://stanford.edu/~rqi/pointnet\" target=\"_blank\">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a> by Qi et al. (CVPR 2017 Oral Presentation). Code and data released in <a href=\"https://github.com/charlesq34/pointnet\">GitHub</a>.\n* <a href=\"https://arxiv.org/abs/1711.08488\" target=\"_blank\">Frustum PointNets for 3D Object Detection from RGB-D Data</a> by Qi et al. (CVPR 2018) A novel framework for 3D object detection with RGB-D data. Based on 2D boxes from a 2D object detector on RGB images, we extrude the depth maps in 2D boxes to point clouds in 3D space and then realize instance segmentation and 3D bounding box estimation using PointNet/PointNet++. The method proposed has achieved first place on KITTI 3D object detection benchmark on all categories (last checked on 11/30/2017). Code and data release TBD.\n"
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "doc",
          "type": "tree",
          "content": null
        },
        {
          "name": "evaluate.py",
          "type": "blob",
          "size": 6.8212890625,
          "content": "'''\n    Evaluate classification performance with optional voting.\n    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n'''\nimport tensorflow as tf\nimport numpy as np\nimport argparse\nimport socket\nimport importlib\nimport time\nimport os\nimport scipy.misc\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = BASE_DIR\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, 'models'))\nsys.path.append(os.path.join(ROOT_DIR, 'utils'))\nimport provider\nimport modelnet_dataset\nimport modelnet_h5_dataset\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')\nparser.add_argument('--model', default='pointnet2_cls_ssg', help='Model name. [default: pointnet2_cls_ssg]')\nparser.add_argument('--batch_size', type=int, default=16, help='Batch Size during training [default: 16]')\nparser.add_argument('--num_point', type=int, default=1024, help='Point Number [256/512/1024/2048] [default: 1024]')\nparser.add_argument('--model_path', default='log/model.ckpt', help='model checkpoint file path [default: log/model.ckpt]')\nparser.add_argument('--dump_dir', default='dump', help='dump folder path [dump]')\nparser.add_argument('--normal', action='store_true', help='Whether to use normal information')\nparser.add_argument('--num_votes', type=int, default=1, help='Aggregate classification scores from multiple rotations [default: 1]')\nFLAGS = parser.parse_args()\n\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMODEL_PATH = FLAGS.model_path\nGPU_INDEX = FLAGS.gpu\nMODEL = importlib.import_module(FLAGS.model) # import network module\nDUMP_DIR = FLAGS.dump_dir\nif not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)\nLOG_FOUT = open(os.path.join(DUMP_DIR, 'log_evaluate.txt'), 'w')\nLOG_FOUT.write(str(FLAGS)+'\\n')\n\nNUM_CLASSES = 40\nSHAPE_NAMES = [line.rstrip() for line in \\\n    open(os.path.join(ROOT_DIR, 'data/modelnet40_ply_hdf5_2048/shape_names.txt'))] \n\nHOSTNAME = socket.gethostname()\n\n# Shapenet official train/test split\nif FLAGS.normal:\n    assert(NUM_POINT<=10000)\n    DATA_PATH = os.path.join(ROOT_DIR, 'data/modelnet40_normal_resampled')\n    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='train', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\n    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='test', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\nelse:\n    assert(NUM_POINT<=2048)\n    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True)\n    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False)\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+'\\n')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef evaluate(num_votes):\n    is_training = False\n     \n    with tf.device('/gpu:'+str(GPU_INDEX)):\n        pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n        is_training_pl = tf.placeholder(tf.bool, shape=())\n\n        # simple model\n        pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n        MODEL.get_loss(pred, labels_pl, end_points)\n        losses = tf.get_collection('losses')\n        total_loss = tf.add_n(losses, name='total_loss')\n        \n        # Add ops to save and restore all the variables.\n        saver = tf.train.Saver()\n        \n    # Create a session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.allow_soft_placement = True\n    config.log_device_placement = False\n    sess = tf.Session(config=config)\n\n    # Restore variables from disk.\n    saver.restore(sess, MODEL_PATH)\n    log_string(\"Model restored.\")\n\n    ops = {'pointclouds_pl': pointclouds_pl,\n           'labels_pl': labels_pl,\n           'is_training_pl': is_training_pl,\n           'pred': pred,\n           'loss': total_loss}\n\n    eval_one_epoch(sess, ops, num_votes)\n\ndef eval_one_epoch(sess, ops, num_votes=1, topk=1):\n    is_training = False\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    shape_ious = []\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n\n    while TEST_DATASET.has_next_batch():\n        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n        bsize = batch_data.shape[0]\n        print('Batch: %03d, batch size: %d'%(batch_idx, bsize))\n        # for the last batch in the epoch, the bsize:end are from last batch\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        batch_pred_sum = np.zeros((BATCH_SIZE, NUM_CLASSES)) # score for classes\n        for vote_idx in range(num_votes):\n            # Shuffle point order to achieve different farthest samplings\n            shuffled_indices = np.arange(NUM_POINT)\n            np.random.shuffle(shuffled_indices)\n            if FLAGS.normal:\n                rotated_data = provider.rotate_point_cloud_by_angle_with_normal(cur_batch_data[:, shuffled_indices, :],\n                    vote_idx/float(num_votes) * np.pi * 2)\n            else:\n                rotated_data = provider.rotate_point_cloud_by_angle(cur_batch_data[:, shuffled_indices, :],\n                    vote_idx/float(num_votes) * np.pi * 2)\n            feed_dict = {ops['pointclouds_pl']: rotated_data,\n                         ops['labels_pl']: cur_batch_label,\n                         ops['is_training_pl']: is_training}\n            loss_val, pred_val = sess.run([ops['loss'], ops['pred']], feed_dict=feed_dict)\n            batch_pred_sum += pred_val\n        pred_val = np.argmax(batch_pred_sum, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        batch_idx += 1\n        for i in range(bsize):\n            l = batch_label[i]\n            total_seen_class[l] += 1\n            total_correct_class[l] += (pred_val[i] == l)\n    \n    log_string('eval mean loss: %f' % (loss_sum / float(batch_idx)))\n    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n\n    class_accuracies = np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float)\n    for i, name in enumerate(SHAPE_NAMES):\n        log_string('%10s:\\t%0.3f' % (name, class_accuracies[i]))\n\n\nif __name__=='__main__':\n    with tf.Graph().as_default():\n        evaluate(num_votes=FLAGS.num_votes)\n    LOG_FOUT.close()\n"
        },
        {
          "name": "modelnet_dataset.py",
          "type": "blob",
          "size": 5.451171875,
          "content": "'''\n    ModelNet dataset. Support ModelNet40, ModelNet10, XYZ and normal channels. Up to 10000 points.\n'''\n\nimport os\nimport os.path\nimport json\nimport numpy as np\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = BASE_DIR\nsys.path.append(os.path.join(ROOT_DIR, 'utils'))\nimport provider\n\ndef pc_normalize(pc):\n    l = pc.shape[0]\n    centroid = np.mean(pc, axis=0)\n    pc = pc - centroid\n    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n    pc = pc / m\n    return pc\n\nclass ModelNetDataset():\n    def __init__(self, root, batch_size = 32, npoints = 1024, split='train', normalize=True, normal_channel=False, modelnet10=False, cache_size=15000, shuffle=None):\n        self.root = root\n        self.batch_size = batch_size\n        self.npoints = npoints\n        self.normalize = normalize\n        if modelnet10:\n            self.catfile = os.path.join(self.root, 'modelnet10_shape_names.txt')\n        else:\n            self.catfile = os.path.join(self.root, 'shape_names.txt')\n        self.cat = [line.rstrip() for line in open(self.catfile)]\n        self.classes = dict(zip(self.cat, range(len(self.cat))))  \n        self.normal_channel = normal_channel\n        \n        shape_ids = {}\n        if modelnet10:\n            shape_ids['train'] = [line.rstrip() for line in open(os.path.join(self.root, 'modelnet10_train.txt'))] \n            shape_ids['test']= [line.rstrip() for line in open(os.path.join(self.root, 'modelnet10_test.txt'))]\n        else:\n            shape_ids['train'] = [line.rstrip() for line in open(os.path.join(self.root, 'modelnet40_train.txt'))] \n            shape_ids['test']= [line.rstrip() for line in open(os.path.join(self.root, 'modelnet40_test.txt'))]\n        assert(split=='train' or split=='test')\n        shape_names = ['_'.join(x.split('_')[0:-1]) for x in shape_ids[split]]\n        # list of (shape_name, shape_txt_file_path) tuple\n        self.datapath = [(shape_names[i], os.path.join(self.root, shape_names[i], shape_ids[split][i])+'.txt') for i in range(len(shape_ids[split]))]\n\n        self.cache_size = cache_size # how many data points to cache in memory\n        self.cache = {} # from index to (point_set, cls) tuple\n\n        if shuffle is None:\n            if split == 'train': self.shuffle = True\n            else: self.shuffle = False\n        else:\n            self.shuffle = shuffle\n\n        self.reset()\n\n    def _augment_batch_data(self, batch_data):\n        if self.normal_channel:\n            rotated_data = provider.rotate_point_cloud_with_normal(batch_data)\n            rotated_data = provider.rotate_perturbation_point_cloud_with_normal(rotated_data)\n        else:\n            rotated_data = provider.rotate_point_cloud(batch_data)\n            rotated_data = provider.rotate_perturbation_point_cloud(rotated_data)\n    \n        jittered_data = provider.random_scale_point_cloud(rotated_data[:,:,0:3])\n        jittered_data = provider.shift_point_cloud(jittered_data)\n        jittered_data = provider.jitter_point_cloud(jittered_data)\n        rotated_data[:,:,0:3] = jittered_data\n        return provider.shuffle_points(rotated_data)\n\n\n    def _get_item(self, index): \n        if index in self.cache:\n            point_set, cls = self.cache[index]\n        else:\n            fn = self.datapath[index]\n            cls = self.classes[self.datapath[index][0]]\n            cls = np.array([cls]).astype(np.int32)\n            point_set = np.loadtxt(fn[1],delimiter=',').astype(np.float32)\n            # Take the first npoints\n            point_set = point_set[0:self.npoints,:]\n            if self.normalize:\n                point_set[:,0:3] = pc_normalize(point_set[:,0:3])\n            if not self.normal_channel:\n                point_set = point_set[:,0:3]\n            if len(self.cache) < self.cache_size:\n                self.cache[index] = (point_set, cls)\n        return point_set, cls\n        \n    def __getitem__(self, index):\n        return self._get_item(index)\n\n    def __len__(self):\n        return len(self.datapath)\n\n    def num_channel(self):\n        if self.normal_channel:\n            return 6\n        else:\n            return 3\n\n    def reset(self):\n        self.idxs = np.arange(0, len(self.datapath))\n        if self.shuffle:\n            np.random.shuffle(self.idxs)\n        self.num_batches = (len(self.datapath)+self.batch_size-1) // self.batch_size\n        self.batch_idx = 0\n\n    def has_next_batch(self):\n        return self.batch_idx < self.num_batches\n\n    def next_batch(self, augment=False):\n        ''' returned dimension may be smaller than self.batch_size '''\n        start_idx = self.batch_idx * self.batch_size\n        end_idx = min((self.batch_idx+1) * self.batch_size, len(self.datapath))\n        bsize = end_idx - start_idx\n        batch_data = np.zeros((bsize, self.npoints, self.num_channel()))\n        batch_label = np.zeros((bsize), dtype=np.int32)\n        for i in range(bsize):\n            ps,cls = self._get_item(self.idxs[i+start_idx])\n            batch_data[i] = ps\n            batch_label[i] = cls\n        self.batch_idx += 1\n        if augment: batch_data = self._augment_batch_data(batch_data)\n        return batch_data, batch_label\n    \nif __name__ == '__main__':\n    d = ModelNetDataset(root = '../data/modelnet40_normal_resampled', split='test')\n    print(d.shuffle)\n    print(len(d))\n    import time\n    tic = time.time()\n    for i in range(10):\n        ps, cls = d[i]\n    print(time.time() - tic)\n    print(ps.shape, type(ps), cls)\n\n    print(d.has_next_batch())\n    ps_batch, cls_batch = d.next_batch(True)\n    print(ps_batch.shape)\n    print(cls_batch.shape)\n"
        },
        {
          "name": "modelnet_h5_dataset.py",
          "type": "blob",
          "size": 4.40234375,
          "content": "'''\n    ModelNet dataset. Support ModelNet40, XYZ channels. Up to 2048 points.\n    Faster IO than ModelNetDataset in the first epoch.\n'''\n\nimport os\nimport sys\nimport numpy as np\nimport h5py\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\nROOT_DIR = BASE_DIR\nsys.path.append(os.path.join(ROOT_DIR, 'utils'))\nimport provider\n\n\n# Download dataset for point cloud classification\nDATA_DIR = os.path.join(ROOT_DIR, 'data')\nif not os.path.exists(DATA_DIR):\n    os.mkdir(DATA_DIR)\nif not os.path.exists(os.path.join(DATA_DIR, 'modelnet40_ply_hdf5_2048')):\n    www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n    zipfile = os.path.basename(www)\n    os.system('wget %s; unzip %s' % (www, zipfile))\n    os.system('mv %s %s' % (zipfile[:-4], DATA_DIR))\n    os.system('rm %s' % (zipfile))\n\n\ndef shuffle_data(data, labels):\n    \"\"\" Shuffle data and labels.\n        Input:\n          data: B,N,... numpy array\n          label: B,... numpy array\n        Return:\n          shuffled data, label and shuffle indices\n    \"\"\"\n    idx = np.arange(len(labels))\n    np.random.shuffle(idx)\n    return data[idx, ...], labels[idx], idx\n\ndef getDataFiles(list_filename):\n    return [line.rstrip() for line in open(list_filename)]\n\ndef load_h5(h5_filename):\n    f = h5py.File(h5_filename)\n    data = f['data'][:]\n    label = f['label'][:]\n    return (data, label)\n\ndef loadDataFile(filename):\n    return load_h5(filename)\n\n\nclass ModelNetH5Dataset(object):\n    def __init__(self, list_filename, batch_size = 32, npoints = 1024, shuffle=True):\n        self.list_filename = list_filename\n        self.batch_size = batch_size\n        self.npoints = npoints\n        self.shuffle = shuffle\n        self.h5_files = getDataFiles(self.list_filename)\n        self.reset()\n\n    def reset(self):\n        ''' reset order of h5 files '''\n        self.file_idxs = np.arange(0, len(self.h5_files))\n        if self.shuffle: np.random.shuffle(self.file_idxs)\n        self.current_data = None\n        self.current_label = None\n        self.current_file_idx = 0\n        self.batch_idx = 0\n   \n    def _augment_batch_data(self, batch_data):\n        rotated_data = provider.rotate_point_cloud(batch_data)\n        rotated_data = provider.rotate_perturbation_point_cloud(rotated_data)\n        jittered_data = provider.random_scale_point_cloud(rotated_data[:,:,0:3])\n        jittered_data = provider.shift_point_cloud(jittered_data)\n        jittered_data = provider.jitter_point_cloud(jittered_data)\n        rotated_data[:,:,0:3] = jittered_data\n        return provider.shuffle_points(rotated_data)\n\n\n    def _get_data_filename(self):\n        return self.h5_files[self.file_idxs[self.current_file_idx]]\n\n    def _load_data_file(self, filename):\n        self.current_data,self.current_label = load_h5(filename)\n        self.current_label = np.squeeze(self.current_label)\n        self.batch_idx = 0\n        if self.shuffle:\n            self.current_data, self.current_label, _ = shuffle_data(self.current_data,self.current_label)\n    \n    def _has_next_batch_in_file(self):\n        return self.batch_idx*self.batch_size < self.current_data.shape[0]\n\n    def num_channel(self):\n        return 3\n\n    def has_next_batch(self):\n        # TODO: add backend thread to load data\n        if (self.current_data is None) or (not self._has_next_batch_in_file()):\n            if self.current_file_idx >= len(self.h5_files):\n                return False\n            self._load_data_file(self._get_data_filename())\n            self.batch_idx = 0\n            self.current_file_idx += 1\n        return self._has_next_batch_in_file()\n\n    def next_batch(self, augment=False):\n        ''' returned dimension may be smaller than self.batch_size '''\n        start_idx = self.batch_idx * self.batch_size\n        end_idx = min((self.batch_idx+1) * self.batch_size, self.current_data.shape[0])\n        bsize = end_idx - start_idx\n        batch_label = np.zeros((bsize), dtype=np.int32)\n        data_batch = self.current_data[start_idx:end_idx, 0:self.npoints, :].copy()\n        label_batch = self.current_label[start_idx:end_idx].copy()\n        self.batch_idx += 1\n        if augment: data_batch = self._augment_batch_data(data_batch)\n        return data_batch, label_batch \n\nif __name__=='__main__':\n    d = ModelNetH5Dataset('data/modelnet40_ply_hdf5_2048/train_files.txt')\n    print(d.shuffle)\n    print(d.has_next_batch())\n    ps_batch, cls_batch = d.next_batch(True)\n    print(ps_batch.shape)\n    print(cls_batch.shape)\n"
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "part_seg",
          "type": "tree",
          "content": null
        },
        {
          "name": "scannet",
          "type": "tree",
          "content": null
        },
        {
          "name": "tf_ops",
          "type": "tree",
          "content": null
        },
        {
          "name": "train.py",
          "type": "blob",
          "size": 11.490234375,
          "content": "'''\n    Single-GPU training.\n    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n'''\nimport argparse\nimport math\nfrom datetime import datetime\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = BASE_DIR\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, 'models'))\nsys.path.append(os.path.join(ROOT_DIR, 'utils'))\nimport provider\nimport tf_util\nimport modelnet_dataset\nimport modelnet_h5_dataset\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu', type=int, default=0, help='GPU to use [default: GPU 0]')\nparser.add_argument('--model', default='pointnet2_cls_ssg', help='Model name [default: pointnet2_cls_ssg]')\nparser.add_argument('--log_dir', default='log', help='Log dir [default: log]')\nparser.add_argument('--num_point', type=int, default=1024, help='Point Number [default: 1024]')\nparser.add_argument('--max_epoch', type=int, default=251, help='Epoch to run [default: 251]')\nparser.add_argument('--batch_size', type=int, default=16, help='Batch Size during training [default: 16]')\nparser.add_argument('--learning_rate', type=float, default=0.001, help='Initial learning rate [default: 0.001]')\nparser.add_argument('--momentum', type=float, default=0.9, help='Initial learning rate [default: 0.9]')\nparser.add_argument('--optimizer', default='adam', help='adam or momentum [default: adam]')\nparser.add_argument('--decay_step', type=int, default=200000, help='Decay step for lr decay [default: 200000]')\nparser.add_argument('--decay_rate', type=float, default=0.7, help='Decay rate for lr decay [default: 0.7]')\nparser.add_argument('--normal', action='store_true', help='Whether to use normal information')\nFLAGS = parser.parse_args()\n\nEPOCH_CNT = 0\n\nBATCH_SIZE = FLAGS.batch_size\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nGPU_INDEX = FLAGS.gpu\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(ROOT_DIR, 'models', FLAGS.model+'.py')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system('cp %s %s' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\nLOG_FOUT.write(str(FLAGS)+'\\n')\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\nNUM_CLASSES = 40\n\n# Shapenet official train/test split\nif FLAGS.normal:\n    assert(NUM_POINT<=10000)\n    DATA_PATH = os.path.join(ROOT_DIR, 'data/modelnet40_normal_resampled')\n    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='train', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\n    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='test', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\nelse:\n    assert(NUM_POINT<=2048)\n    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True)\n    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False)\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+'\\n')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device('/gpu:'+str(GPU_INDEX)):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the 'batch' parameter\n            # for you every time it trains.\n            batch = tf.get_variable('batch', [],\n                initializer=tf.constant_initializer(0), trainable=False)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar('bn_decay', bn_decay)\n\n            # Get model and loss \n            pred, end_points = MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n            MODEL.get_loss(pred, labels_pl, end_points)\n            losses = tf.get_collection('losses')\n            total_loss = tf.add_n(losses, name='total_loss')\n            tf.summary.scalar('total_loss', total_loss)\n            for l in losses + [total_loss]:\n                tf.summary.scalar(l.op.name, l)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar('accuracy', accuracy)\n\n            print \"--- Get training operator\"\n            # Get training operator\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar('learning_rate', learning_rate)\n            if OPTIMIZER == 'momentum':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == 'adam':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            train_op = optimizer.minimize(total_loss, global_step=batch)\n            \n            # Add ops to save and restore all the variables.\n            saver = tf.train.Saver()\n        \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        ops = {'pointclouds_pl': pointclouds_pl,\n               'labels_pl': labels_pl,\n               'is_training_pl': is_training_pl,\n               'pred': pred,\n               'loss': total_loss,\n               'train_op': train_op,\n               'merged': merged,\n               'step': batch,\n               'end_points': end_points}\n\n        best_acc = -1\n        for epoch in range(MAX_EPOCH):\n            log_string('**** EPOCH %03d ****' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n\n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n                log_string(\"Model saved in file: %s\" % save_path)\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    is_training = True\n    \n    log_string(str(datetime.now()))\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TRAIN_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    while TRAIN_DATASET.has_next_batch():\n        batch_data, batch_label = TRAIN_DATASET.next_batch(augment=True)\n        #batch_data = provider.random_point_dropout(batch_data)\n        bsize = batch_data.shape[0]\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n                     ops['labels_pl']: cur_batch_label,\n                     ops['is_training_pl']: is_training,}\n        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n            ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n        train_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        if (batch_idx+1)%50 == 0:\n            log_string(' ---- batch: %03d ----' % (batch_idx+1))\n            log_string('mean loss: %f' % (loss_sum / 50))\n            log_string('accuracy: %f' % (total_correct / float(total_seen)))\n            total_correct = 0\n            total_seen = 0\n            loss_sum = 0\n        batch_idx += 1\n\n    TRAIN_DATASET.reset()\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    global EPOCH_CNT\n    is_training = False\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    shape_ious = []\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    log_string(str(datetime.now()))\n    log_string('---- EPOCH %03d EVALUATION ----'%(EPOCH_CNT))\n    \n    while TEST_DATASET.has_next_batch():\n        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n        bsize = batch_data.shape[0]\n        # for the last batch in the epoch, the bsize:end are from last batch\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n                     ops['labels_pl']: cur_batch_label,\n                     ops['is_training_pl']: is_training}\n        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n            ops['loss'], ops['pred']], feed_dict=feed_dict)\n        test_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        batch_idx += 1\n        for i in range(0, bsize):\n            l = batch_label[i]\n            total_seen_class[l] += 1\n            total_correct_class[l] += (pred_val[i] == l)\n    \n    log_string('eval mean loss: %f' % (loss_sum / float(batch_idx)))\n    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n    EPOCH_CNT += 1\n\n    TEST_DATASET.reset()\n    return total_correct/float(total_seen)\n\n\nif __name__ == \"__main__\":\n    log_string('pid: %s'%(str(os.getpid())))\n    train()\n    LOG_FOUT.close()\n"
        },
        {
          "name": "train_multi_gpu.py",
          "type": "blob",
          "size": 14.5341796875,
          "content": "'''\n    Multi-GPU training.\n    Near linear scale acceleration for multi-gpus on a single machine.\n    Will use H5 dataset in default. If using normal, will shift to the normal dataset.\n'''\n\nimport argparse\nimport math\nfrom datetime import datetime\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport socket\nimport importlib\nimport os\nimport sys\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nROOT_DIR = BASE_DIR\nsys.path.append(BASE_DIR)\nsys.path.append(os.path.join(ROOT_DIR, 'models'))\nsys.path.append(os.path.join(ROOT_DIR, 'utils'))\nimport provider\nimport tf_util\nimport modelnet_dataset\nimport modelnet_h5_dataset\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--num_gpus', type=int, default=1, help='How many gpus to use [default: 1]')\nparser.add_argument('--model', default='pointnet2_cls_ssg', help='Model name [default: pointnet2_cls_ssg]')\nparser.add_argument('--log_dir', default='log', help='Log dir [default: log]')\nparser.add_argument('--num_point', type=int, default=1024, help='Point Number [default: 1024]')\nparser.add_argument('--max_epoch', type=int, default=251, help='Epoch to run [default: 251]')\nparser.add_argument('--batch_size', type=int, default=32, help='Batch Size during training [default: 32]')\nparser.add_argument('--learning_rate', type=float, default=0.001, help='Initial learning rate [default: 0.001]')\nparser.add_argument('--momentum', type=float, default=0.9, help='Initial learning rate [default: 0.9]')\nparser.add_argument('--optimizer', default='adam', help='adam or momentum [default: adam]')\nparser.add_argument('--decay_step', type=int, default=200000, help='Decay step for lr decay [default: 200000]')\nparser.add_argument('--decay_rate', type=float, default=0.7, help='Decay rate for lr decay [default: 0.7]')\nparser.add_argument('--normal', action='store_true', help='Whether to use normal information')\nFLAGS = parser.parse_args()\n\nEPOCH_CNT = 0\n\nNUM_GPUS = FLAGS.num_gpus\nBATCH_SIZE = FLAGS.batch_size\nassert(BATCH_SIZE % NUM_GPUS == 0)\nDEVICE_BATCH_SIZE = BATCH_SIZE / NUM_GPUS\n\nNUM_POINT = FLAGS.num_point\nMAX_EPOCH = FLAGS.max_epoch\nBASE_LEARNING_RATE = FLAGS.learning_rate\nMOMENTUM = FLAGS.momentum\nOPTIMIZER = FLAGS.optimizer\nDECAY_STEP = FLAGS.decay_step\nDECAY_RATE = FLAGS.decay_rate\n\nMODEL = importlib.import_module(FLAGS.model) # import network module\nMODEL_FILE = os.path.join(ROOT_DIR, 'models', FLAGS.model+'.py')\nLOG_DIR = FLAGS.log_dir\nif not os.path.exists(LOG_DIR): os.mkdir(LOG_DIR)\nos.system('cp %s %s' % (MODEL_FILE, LOG_DIR)) # bkp of model def\nos.system('cp train.py %s' % (LOG_DIR)) # bkp of train procedure\nLOG_FOUT = open(os.path.join(LOG_DIR, 'log_train.txt'), 'w')\nLOG_FOUT.write(str(FLAGS)+'\\n')\n\nBN_INIT_DECAY = 0.5\nBN_DECAY_DECAY_RATE = 0.5\nBN_DECAY_DECAY_STEP = float(DECAY_STEP)\nBN_DECAY_CLIP = 0.99\n\nHOSTNAME = socket.gethostname()\n\nNUM_CLASSES = 40\n\n# Shapenet official train/test split\nif FLAGS.normal:\n    assert(NUM_POINT<=10000)\n    DATA_PATH = os.path.join(ROOT_DIR, 'data/modelnet40_normal_resampled')\n    TRAIN_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='train', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\n    TEST_DATASET = modelnet_dataset.ModelNetDataset(root=DATA_PATH, npoints=NUM_POINT, split='test', normal_channel=FLAGS.normal, batch_size=BATCH_SIZE)\nelse:\n    assert(NUM_POINT<=2048)\n    TRAIN_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/train_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=True)\n    TEST_DATASET = modelnet_h5_dataset.ModelNetH5Dataset(os.path.join(BASE_DIR, 'data/modelnet40_ply_hdf5_2048/test_files.txt'), batch_size=BATCH_SIZE, npoints=NUM_POINT, shuffle=False)\n\ndef log_string(out_str):\n    LOG_FOUT.write(out_str+'\\n')\n    LOG_FOUT.flush()\n    print(out_str)\n\ndef average_gradients(tower_grads):\n  \"\"\"Calculate the average gradient for each shared variable across all towers.\n  Note that this function provides a synchronization point across all towers.\n  From tensorflow tutorial: cifar10/cifar10_multi_gpu_train.py\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been averaged\n     across all towers.\n  \"\"\"\n  average_grads = []\n  for grad_and_vars in zip(*tower_grads):\n    # Note that each grad_and_vars looks like the following:\n    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n    grads = []\n    #for g, _ in grad_and_vars:\n    for g, v in grad_and_vars:\n      # Add 0 dimension to the gradients to represent the tower.\n      expanded_g = tf.expand_dims(g, 0)\n\n      # Append on a 'tower' dimension which we will average over below.\n      grads.append(expanded_g)\n\n    # Average over the 'tower' dimension.\n    grad = tf.concat(axis=0, values=grads)\n    grad = tf.reduce_mean(grad, 0)\n\n    # Keep in mind that the Variables are redundant because they are shared\n    # across towers. So .. we will just return the first tower's pointer to\n    # the Variable.\n    v = grad_and_vars[0][1]\n    grad_and_var = (grad, v)\n    average_grads.append(grad_and_var)\n  return average_grads\n\n\ndef get_learning_rate(batch):\n    learning_rate = tf.train.exponential_decay(\n                        BASE_LEARNING_RATE,  # Base learning rate.\n                        batch * BATCH_SIZE,  # Current index into the dataset.\n                        DECAY_STEP,          # Decay step.\n                        DECAY_RATE,          # Decay rate.\n                        staircase=True)\n    learning_rate = tf.maximum(learning_rate, 0.00001) # CLIP THE LEARNING RATE!\n    return learning_rate        \n\ndef get_bn_decay(batch):\n    bn_momentum = tf.train.exponential_decay(\n                      BN_INIT_DECAY,\n                      batch*BATCH_SIZE,\n                      BN_DECAY_DECAY_STEP,\n                      BN_DECAY_DECAY_RATE,\n                      staircase=True)\n    bn_decay = tf.minimum(BN_DECAY_CLIP, 1 - bn_momentum)\n    return bn_decay\n\ndef train():\n    with tf.Graph().as_default():\n        with tf.device('/cpu:0'):\n            pointclouds_pl, labels_pl = MODEL.placeholder_inputs(BATCH_SIZE, NUM_POINT)\n            is_training_pl = tf.placeholder(tf.bool, shape=())\n            \n            # Note the global_step=batch parameter to minimize. \n            # That tells the optimizer to helpfully increment the 'batch' parameter\n            # for you every time it trains.\n            batch = tf.get_variable('batch', [],\n                initializer=tf.constant_initializer(0), trainable=False)\n            bn_decay = get_bn_decay(batch)\n            tf.summary.scalar('bn_decay', bn_decay)\n\n            # Set learning rate and optimizer\n            learning_rate = get_learning_rate(batch)\n            tf.summary.scalar('learning_rate', learning_rate)\n            if OPTIMIZER == 'momentum':\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=MOMENTUM)\n            elif OPTIMIZER == 'adam':\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n\n            # -------------------------------------------\n            # Get model and loss on multiple GPU devices\n            # -------------------------------------------\n            # Allocating variables on CPU first will greatly accelerate multi-gpu training.\n            # Ref: https://github.com/kuza55/keras-extras/issues/21\n            MODEL.get_model(pointclouds_pl, is_training_pl, bn_decay=bn_decay)\n            \n            tower_grads = []\n            pred_gpu = []\n            total_loss_gpu = []\n            for i in range(NUM_GPUS):\n                with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n                    with tf.device('/gpu:%d'%(i)), tf.name_scope('gpu_%d'%(i)) as scope:\n                        # Evenly split input data to each GPU\n                        pc_batch = tf.slice(pointclouds_pl,\n                            [i*DEVICE_BATCH_SIZE,0,0], [DEVICE_BATCH_SIZE,-1,-1])\n                        label_batch = tf.slice(labels_pl,\n                            [i*DEVICE_BATCH_SIZE], [DEVICE_BATCH_SIZE])\n\n                        pred, end_points = MODEL.get_model(pc_batch,\n                            is_training=is_training_pl, bn_decay=bn_decay)\n\n                        MODEL.get_loss(pred, label_batch, end_points)\n                        losses = tf.get_collection('losses', scope)\n                        total_loss = tf.add_n(losses, name='total_loss')\n                        for l in losses + [total_loss]:\n                            tf.summary.scalar(l.op.name, l)\n\n                        grads = optimizer.compute_gradients(total_loss)\n                        tower_grads.append(grads)\n\n                        pred_gpu.append(pred)\n                        total_loss_gpu.append(total_loss)\n            \n            # Merge pred and losses from multiple GPUs\n            pred = tf.concat(pred_gpu, 0)\n            total_loss = tf.reduce_mean(total_loss_gpu)\n\n            # Get training operator \n            grads = average_gradients(tower_grads)\n            train_op = optimizer.apply_gradients(grads, global_step=batch)\n\n            correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n            accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(BATCH_SIZE)\n            tf.summary.scalar('accuracy', accuracy)\n\n        # Add ops to save and restore all the variables.\n        saver = tf.train.Saver()\n        \n        # Create a session\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n        config.allow_soft_placement = True\n        config.log_device_placement = False\n        sess = tf.Session(config=config)\n\n        # Add summary writers\n        merged = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'train'), sess.graph)\n        test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'), sess.graph)\n\n        # Init variables\n        init = tf.global_variables_initializer()\n        sess.run(init)\n\n        ops = {'pointclouds_pl': pointclouds_pl,\n               'labels_pl': labels_pl,\n               'is_training_pl': is_training_pl,\n               'pred': pred,\n               'loss': total_loss,\n               'train_op': train_op,\n               'merged': merged,\n               'step': batch,\n               'end_points': end_points}\n\n        best_acc = -1\n        for epoch in range(MAX_EPOCH):\n            log_string('**** EPOCH %03d ****' % (epoch))\n            sys.stdout.flush()\n             \n            train_one_epoch(sess, ops, train_writer)\n            eval_one_epoch(sess, ops, test_writer)\n\n            # Save the variables to disk.\n            if epoch % 10 == 0:\n                save_path = saver.save(sess, os.path.join(LOG_DIR, \"model.ckpt\"))\n                log_string(\"Model saved in file: %s\" % save_path)\n\n\ndef train_one_epoch(sess, ops, train_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    is_training = True\n    \n    log_string(str(datetime.now()))\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TRAIN_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    while TRAIN_DATASET.has_next_batch():\n        batch_data, batch_label = TRAIN_DATASET.next_batch(augment=True)\n        #batch_data = provider.random_point_dropout(batch_data)\n        bsize = batch_data.shape[0]\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n                     ops['labels_pl']: cur_batch_label,\n                     ops['is_training_pl']: is_training,}\n        summary, step, _, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n            ops['train_op'], ops['loss'], ops['pred']], feed_dict=feed_dict)\n        train_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        if (batch_idx+1)%50 == 0:\n            log_string(' ---- batch: %03d ----' % (batch_idx+1))\n            log_string('mean loss: %f' % (loss_sum / 50))\n            log_string('accuracy: %f' % (total_correct / float(total_seen)))\n            total_correct = 0\n            total_seen = 0\n            loss_sum = 0\n        batch_idx += 1\n\n    TRAIN_DATASET.reset()\n        \ndef eval_one_epoch(sess, ops, test_writer):\n    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n    global EPOCH_CNT\n    is_training = False\n\n    # Make sure batch data is of same size\n    cur_batch_data = np.zeros((BATCH_SIZE,NUM_POINT,TEST_DATASET.num_channel()))\n    cur_batch_label = np.zeros((BATCH_SIZE), dtype=np.int32)\n\n    total_correct = 0\n    total_seen = 0\n    loss_sum = 0\n    batch_idx = 0\n    shape_ious = []\n    total_seen_class = [0 for _ in range(NUM_CLASSES)]\n    total_correct_class = [0 for _ in range(NUM_CLASSES)]\n    \n    log_string(str(datetime.now()))\n    log_string('---- EPOCH %03d EVALUATION ----'%(EPOCH_CNT))\n    \n    while TEST_DATASET.has_next_batch():\n        batch_data, batch_label = TEST_DATASET.next_batch(augment=False)\n        bsize = batch_data.shape[0]\n        # for the last batch in the epoch, the bsize:end are from last batch\n        cur_batch_data[0:bsize,...] = batch_data\n        cur_batch_label[0:bsize] = batch_label\n\n        feed_dict = {ops['pointclouds_pl']: cur_batch_data,\n                     ops['labels_pl']: cur_batch_label,\n                     ops['is_training_pl']: is_training}\n        summary, step, loss_val, pred_val = sess.run([ops['merged'], ops['step'],\n            ops['loss'], ops['pred']], feed_dict=feed_dict)\n        test_writer.add_summary(summary, step)\n        pred_val = np.argmax(pred_val, 1)\n        correct = np.sum(pred_val[0:bsize] == batch_label[0:bsize])\n        total_correct += correct\n        total_seen += bsize\n        loss_sum += loss_val\n        batch_idx += 1\n        for i in range(0, bsize):\n            l = batch_label[i]\n            total_seen_class[l] += 1\n            total_correct_class[l] += (pred_val[i] == l)\n    \n    log_string('eval mean loss: %f' % (loss_sum / float(batch_idx)))\n    log_string('eval accuracy: %f'% (total_correct / float(total_seen)))\n    log_string('eval avg class acc: %f' % (np.mean(np.array(total_correct_class)/np.array(total_seen_class,dtype=np.float))))\n    EPOCH_CNT += 1\n\n    TEST_DATASET.reset()\n    return total_correct/float(total_seen)\n\n\nif __name__ == \"__main__\":\n    log_string('pid: %s'%(str(os.getpid())))\n    train()\n    LOG_FOUT.close()\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}