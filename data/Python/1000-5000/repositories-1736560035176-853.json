{
  "metadata": {
    "timestamp": 1736560035176,
    "page": 853,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjg2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "DingXiaoH/RepVGG",
      "stars": 3357,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.0126953125,
          "content": ".idea/\n*nori*"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.041015625,
          "content": "MIT License\n\nCopyright (c) 2020 DingXiaoH\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 21.0712890625,
          "content": "# RepVGG: Making VGG-style ConvNets Great Again (CVPR-2021) (PyTorch)\n\n## Highlights (Sep. 1st, 2022)\n\nRepVGG and the methodology of re-parameterization have been used in **YOLOv6** ([paper](https://arxiv.org/abs/2209.02976), [code](https://github.com/meituan/YOLOv6))  and **YOLOv7** ([paper](https://arxiv.org/abs/2207.02696), [code](https://github.com/WongKinYiu/yolov7)). \n\nI have re-organized this repository and released the RepVGGplus-L2pse model with 84.06% ImageNet accuracy. Will release more RepVGGplus models in this month.\n\n## Introduction\n\nThis is a super simple ConvNet architecture that achieves over **84% top-1 accuracy on ImageNet** with a VGG-like architecture! This repo contains the **pretrained models**, code for building the model, training, and the conversion from training-time model to inference-time, and **an example of using RepVGG for semantic segmentation**.\n\n[The MegEngine version](https://github.com/megvii-model/RepVGG)\n\n[TensorRT implemention with C++ API by @upczww](https://github.com/upczww/TensorRT-RepVGG). Great work!\n\n[Another PyTorch implementation by @zjykzj](https://github.com/ZJCV/ZCls). He also presented detailed benchmarks [here](https://zcls.readthedocs.io/en/latest/benchmark-repvgg/). Nice work!\n\nIncluded in a famous PyTorch model zoo https://github.com/rwightman/pytorch-image-models.\n\n[Objax implementation and models by @benjaminjellis](https://github.com/benjaminjellis/Objax-RepVGG). Great work!\n\nIncluded in the [MegEngine Basecls model zoo](https://github.com/megvii-research/basecls/tree/main/zoo/public/repvgg).\n\nCitation:\n\n    @inproceedings{ding2021repvgg,\n    title={Repvgg: Making vgg-style convnets great again},\n    author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},\n    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n    pages={13733--13742},\n    year={2021}\n    }\n\n\n## From RepVGG to RepVGGplus\n\nWe have released an improved architecture named RepVGGplus on top of the original version presented in the CVPR-2021 paper.\n\n1. RepVGGplus is deeper\n\n2. RepVGGplus has auxiliary classifiers during training, which can also be removed for inference\n\n3. (Optional) RepVGGplus uses Squeeze-and-Excitation blocks to further improve the performance.\n\nRepVGGplus outperformed several recent visual transformers with a top-1 accuracy of **84.06%** and higher throughput. Our training script is based on [codebase of Swin Transformer](https://github.com/microsoft/Swin-Transformer/). The throughput is tested with the Swin codebase as well. We would like to thank the authors of [Swin](https://arxiv.org/abs/2103.14030) for their clean and well-structured code. \n\n| Model        | Train image size       | Test size  | ImageNet top-1 | Throughput (examples/second), 320, batchsize=128, 2080Ti) |\n| ------------- |:-------------:| -----:| -----:| -----:|\n| RepVGGplus-L2pse    | 256 \t|  \t320 |   **84.06%**   |**147** |\n| Swin Transformer | 320    |   320 |   84.0%     |102 |\n\n(\"pse\" means Squeeze-and-Excitation blocks after ReLU.)\n\nDownload this model: [Google Drive](https://drive.google.com/file/d/1x8VNLpfuLzg0xXDVIZv9yIIgqnSMoK-W/view?usp=sharing) or [Baidu Cloud](https://pan.baidu.com/s/19YwKCTSPVgJu5Ueg0Q78-w?pwd=rvgg).\n\nTo train or finetune it, slightly change your training code like this:\n```\n        #   Build model and data loader as usual\n        for samples, targets in enumerate(train_data_loader):\n            #   ......\n            outputs = model(samples)                        #   Your original code\n            if type(outputs) is dict:                       \n                #   A training-time RepVGGplus outputs a dict. The items are:\n                    #   'main':     the output of the final layer\n                    #   '*aux*':    the output of auxiliary classifiers\n                loss = 0\n                for name, pred in outputs.items():\n                    if 'aux' in name:\n                        loss += 0.1 * criterion(pred, targets)          #  Assume \"criterion\" is cross-entropy for classification\n                    else:\n                        loss += criterion(pred, targets)\n            else:\n                loss = criterion(outputs, targets)          #   Your original code\n            #   Backward as usual\n            #   ......\n```\n\nTo use it for downstream tasks like semantic segmentation, just discard the aux classifiers and the final FC layer.\n\nPleased note that the custom weight decay trick I described last year turned out to be insignificant in our recent experiments (84.16% ImageNet acc and negligible improvements on other tasks), so I decided to stop using it as a new feature of RepVGGplus. You may try it optionally on your task. Please refer to the last part of this page for details.\n\n\n## Use our pretrained model\n\nYou may download _all_ of the ImageNet-pretrained models reported in the paper from Google Drive (https://drive.google.com/drive/folders/1Avome4KvNp0Lqh2QwhXO6L5URQjzCjUq?usp=sharing) or Baidu Cloud (https://pan.baidu.com/s/1nCsZlMynnJwbUBKn0ch7dQ, the access code is \"rvgg\"). For the ease of transfer learning on other tasks, they are all training-time models (with identity and 1x1 branches). You may test the accuracy by running\n```\npython -m torch.distributed.launch --nproc_per_node 1 --master_port 12349 main.py --arch [model name] --data-path [/path/to/imagenet] --batch-size 32 --tag test --eval --resume [/path/to/weights/file] --opts DATA.DATASET imagenet DATA.IMG_SIZE [224 or 320]\n```\nThe valid model names include\n```\nRepVGGplus-L2pse, RepVGG-A0, RepVGG-A1, RepVGG-A2, RepVGG-B0, RepVGG-B1, RepVGG-B1g2, RepVGG-B1g4, RepVGG-B2, RepVGG-B2g2, RepVGG-B2g4, RepVGG-B3, RepVGG-B3g2, RepVGG-B3g4\n```\n\n## Convert a training-time RepVGG into the inference-time structure\n\nFor a RepVGG model or a model with RepVGG as one of its components (e.g., the backbone), you can convert the whole model by simply calling **switch_to_deploy** of every RepVGG block. This is the recommended way. Examples are shown in ```tools/convert.py``` and ```example_pspnet.py```.\n```\n    for module in model.modules():\n        if hasattr(module, 'switch_to_deploy'):\n            module.switch_to_deploy()\n```\nWe have also released a script for the conversion. For example, \n```\npython convert.py RepVGGplus-L2pse-train256-acc84.06.pth RepVGGplus-L2pse-deploy.pth -a RepVGGplus-L2pse\n```\nThen you may build the inference-time model with ```--deploy```, load the converted weights and test\n```\npython -m torch.distributed.launch --nproc_per_node 1 --master_port 12349 main.py --arch RepVGGplus-L2pse --data-path [/path/to/imagenet] --batch-size 32 --tag test --eval --resume RepVGGplus-L2pse-deploy.pth --deploy --opts DATA.DATASET imagenet DATA.IMG_SIZE [224 or 320]\n```\n\nExcept for the final conversion after training, you may want to get the equivalent kernel and bias **during training** in a **differentiable** way at any time (```get_equivalent_kernel_bias``` in ```repvgg.py```). This may help training-based pruning or quantization. \n\n## Train from scratch\n\n### Reproduce RepVGGplus-L2pse (not presented in the paper)\n\nTo train the recently released RepVGGplus-L2pse from scratch, activate mixup and use ```--AUG.PRESET raug15``` for RandAug.\n```\npython -m torch.distributed.launch --nproc_per_node 8 --master_port 12349 main.py --arch RepVGGplus-L2pse --data-path [/path/to/imagenet] --batch-size 32 --tag train_from_scratch --output-dir /path/to/save/the/log/and/checkpoints --opts TRAIN.EPOCHS 300 TRAIN.BASE_LR 0.1 TRAIN.WEIGHT_DECAY 4e-5 TRAIN.WARMUP_EPOCHS 5 MODEL.LABEL_SMOOTHING 0.1 AUG.PRESET raug15 AUG.MIXUP 0.2 DATA.DATASET imagenet DATA.IMG_SIZE 256 DATA.TEST_SIZE 320\n```\n\n### Reproduce original RepVGG results reported in the paper\n\nTo reproduce the models reported in the CVPR-2021 paper, use no mixup nor RandAug.\n```\npython -m torch.distributed.launch --nproc_per_node 8 --master_port 12349 main.py --arch [model name] --data-path [/path/to/imagenet] --batch-size 32 --tag train_from_scratch --output-dir /path/to/save/the/log/and/checkpoints --opts TRAIN.EPOCHS 300 TRAIN.BASE_LR 0.1 TRAIN.WEIGHT_DECAY 1e-4 TRAIN.WARMUP_EPOCHS 5 MODEL.LABEL_SMOOTHING 0.1 AUG.PRESET weak AUG.MIXUP 0.0 DATA.DATASET imagenet DATA.IMG_SIZE 224\n```\nThe original RepVGG models were trained in 120 epochs with cosine learning rate decay from 0.1 to 0. We used 8 GPUs, global batch size of 256, weight decay of 1e-4 (no weight decay on fc.bias, bn.bias, rbr_dense.bn.weight and rbr_1x1.bn.weight) (weight decay on rbr_identity.weight makes little difference, and it is better to use it in most of the cases), and the same simple data preprocssing as the PyTorch official example:\n```\n            trans = transforms.Compose([\n                transforms.RandomResizedCrop(224),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n```\n\n\n\n\n\n\n\n## Other released models not presented in the paper\n\n***Apr 25, 2021*** A deeper RepVGG model achieves **83.55\\% top-1 accuracy on ImageNet** with [SE](https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html) blocks and an input resolution of 320x320 (and a wider version achieves **83.67\\% accuracy** _without SE_). Note that it is trained with 224x224 but tested with 320x320, so that it is still trainable with a global batch size of 256 on a single machine with 8 1080Ti GPUs. If you test it with 224x224, the top-1 accuracy will be 81.82%. It has 1, 8, 14, 24, 1 layers in the 5 stages respectively. The width multipliers are a=2.5 and b=5 (the same as RepVGG-B2). The model name is \"RepVGG-D2se\". The code for building the model (repvgg.py) and testing with 320x320 (the testing example below) has been updated and the weights have been released at Google Drive and Baidu Cloud. Please check the links below.\n\n\n## Example 1: use Structural Re-parameterization like this in your own code\n```\nfrom repvgg import repvgg_model_convert, create_RepVGG_A0\ntrain_model = create_RepVGG_A0(deploy=False)\ntrain_model.load_state_dict(torch.load('RepVGG-A0-train.pth'))          # or train from scratch\n# do whatever you want with train_model\ndeploy_model = repvgg_model_convert(train_model, save_path='RepVGG-A0-deploy.pth')\n# do whatever you want with deploy_model\n```\nor\n```\ndeploy_model = create_RepVGG_A0(deploy=True)\ndeploy_model.load_state_dict(torch.load('RepVGG-A0-deploy.pth'))\n# do whatever you want with deploy_model\n```\nIf you use RepVGG as a component of another model, the conversion is as simple as calling **switch_to_deploy** of every RepVGG block. \n\n\n## Example 2: use RepVGG as the backbone for downstream tasks\n\nI would suggest you use popular frameworks like MMDetection and MMSegmentation. The features from any stage or layer of RepVGG can be fed into the task-specific heads. If you are not familiar with such frameworks and just would like to see a simple example, please check ```example_pspnet.py```, which shows how to use RepVGG as the backbone of PSPNet for semantic segmentation: 1) build a PSPNet with RepVGG backbone, 2) load the ImageNet-pretrained weights, 3) convert the whole model with **switch_to_deploy**, 4) save and use the converted model for inference.\n\n\n\n## Quantization\n\nRepVGG works fine with FP16 but the accuracy may decrease when directly quantized to INT8. If IN8 quantization is essential to your application, we suggest three practical solutions.\n\n### Solution A: RepOptimizer\n\nI strongly recommend trying RepOptimizer if quantization is essential to your application. RepOptimizer directly trains a VGG-like model via Gradient Re-parameterization without any structural conversions. Quantizing a VGG-like model trained with RepOptimizer is as easy as quantizing a regular model. RepOptimizer has already been used in YOLOv6.\n\nPaper: https://arxiv.org/abs/2205.15242\n\nCode: https://github.com/DingXiaoH/RepOptimizers\n\nTutorial provided by the authors of YOLOv6: https://github.com/meituan/YOLOv6/blob/main/docs/tutorial_repopt.md. Great work! Many thanks!\n\n### Solution B: custom quantization-aware training\n\nAnother choice is is to constrain the equivalent kernel (get_equivalent_kernel_bias() in repvgg.py) to be low-bit (e.g., make every param in {-127, -126, .., 126, 127} for int8), instead of constraining the params of every kernel separately for an ordinary model.\n\n### Solution C: use the off-the-shelf toolboxes\n\n(TODO: check and refactor the code of this example)\n\nFor the simplicity, we can also use the off-the-shelf quantization toolboxes to quantize RepVGG. We use the simple QAT (quantization-aware training) tool in torch.quantization as an example.\n\n1. Given the base model converted into the inference-time structure. We insert BN after the converted 3x3 conv layers because QAT with torch.quantization requires BN. Specifically, we run the model on ImageNet training set and record the mean/std statistics and use them to initialize the BN layers, and initialize BN.gamma/beta accordingly so that the saved model has the same outputs as the inference-time model. \n\n```\npython quantization/convert.py RepVGG-A0.pth RepVGG-A0_base.pth -a RepVGG-A0 \npython quantization/insert_bn.py [imagenet-folder] RepVGG-A0_base.pth RepVGG-A0_withBN.pth -a RepVGG-A0 -b 32 -n 40000\n```\n\n2. Build the model, prepare it for QAT (torch.quantization.prepare_qat), and conduct QAT. This is only an example and the hyper-parameters may not be optimal.\n```\npython quantization/quant_qat_train.py [imagenet-folder] -j 32 --epochs 20 -b 256 --lr 1e-3 --weight-decay 4e-5 --base-weights RepVGG-A0_withBN.pth --tag quanttest\n```\n\n\n## FAQs\n\n**Q**: Is the inference-time model's output the _same_ as the training-time model?\n\n**A**: Yes. You can verify that by\n```\npython tools/verify.py\n```\n\n**Q**: How to use the pretrained RepVGG models for other tasks?\n\n**A**: It is better to finetune the training-time RepVGG models on your datasets. Then you should do the conversion after finetuning and before you deploy the models. For example, say you want to use PSPNet for semantic segmentation, you should build a PSPNet with a training-time RepVGG model as the backbone, load pre-trained weights into the backbone, and finetune the PSPNet on your segmentation dataset. Then you should convert the backbone following the code provided in this repo and keep the other task-specific structures (the PSPNet parts, in this case). The pseudo code will be like\n```\n#   train_backbone = create_RepVGG_B2(deploy=False)\n#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n#   train_pspnet = build_pspnet(backbone=train_backbone)\n#   segmentation_train(train_pspnet)\n#   deploy_pspnet = repvgg_model_convert(train_pspnet)\n#   segmentation_test(deploy_pspnet)\n```\nThere is an example in **example_pspnet.py**.\n\nFinetuning with a converted RepVGG also makes sense if you insert a BN after each conv (please see the quantization example), but the performance may be slightly lower.\n\n**Q**: I tried to finetune your model with multiple GPUs but got an error. Why are the names of params like \"stage1.0.rbr_dense.conv.weight\" in the downloaded weight file but sometimes like \"module.stage1.0.rbr_dense.conv.weight\" (shown by nn.Module.named_parameters()) in my model?\n\n**A**: DistributedDataParallel may prefix \"module.\" to the name of params and cause a mismatch when loading weights by name. The simplest solution is to load the weights (model.load_state_dict(...)) before DistributedDataParallel(model). Otherwise, you may insert \"module.\" before the names like this\n```\ncheckpoint = torch.load(...)    # This is just a name-value dict\nckpt = {('module.' + k) : v for k, v in checkpoint.items()}\nmodel.load_state_dict(ckpt)\n```\nLikewise, if the param names in the checkpoint file start with \"module.\" but those in your model do not, you may strip the names like line 50 in test.py.\n```\nckpt = {k.replace('module.', ''):v for k,v in checkpoint.items()}   # strip the names\nmodel.load_state_dict(ckpt)\n```\n**Q**: So a RepVGG model derives the equivalent 3x3 kernels before each forwarding to save computations?\n\n**A**: No! More precisely, we do the conversion only once right after training. Then the training-time model can be discarded, and the resultant model only has 3x3 kernels. We only save and use the resultant model.\n\n\n## An optional trick with a custom weight decay (deprecated)\n\nThis is deprecated. Please check ```repvggplus_custom_L2.py```. The intuition is to add regularization on the equivalent kernel. It may work in some cases.\n\nThe trained model can be downloaded at [Google Drive](https://drive.google.com/file/d/14I1jWU4rS4y0wdxm03SnEVP1Tx6GGfKu/view?usp=sharing) or [Baidu Cloud](https://pan.baidu.com/s/1qFGmgJ6Ir6W3wAcCBQb9-w?pwd=rvgg)\n\nThe training code should be changed like this:\n```\n        #   Build model and data loader as usual\n        for samples, targets in enumerate(train_data_loader):\n            #   ......\n            outputs = model(samples)                        #   Your original code\n            if type(outputs) is dict:                       \n                #   A training-time RepVGGplus outputs a dict. The items are:\n                    #   'main':     the output of the final layer\n                    #   '*aux*':    the output of auxiliary classifiers\n                    #   'L2':       the custom L2 regularization term\n                loss = WEIGHT_DECAY * 0.5 * outputs['L2']\n                for name, pred in outputs.items():\n                    if name == 'L2':\n                        pass\n                    elif 'aux' in name:\n                        loss += 0.1 * criterion(pred, targets)          #  Assume \"criterion\" is cross-entropy for classification\n                    else:\n                        loss += criterion(pred, targets)\n            else:\n                loss = criterion(outputs, targets)          #   Your original code\n            #   Backward as usual\n            #   ......\n```\n\n\n\n## Contact\n\n**xiaohding@gmail.com** (The original Tsinghua mailbox dxh17@mails.tsinghua.edu.cn will expire in several months)\n\nGoogle Scholar Profile: https://scholar.google.com/citations?user=CIjw0KoAAAAJ&hl=en\n\nHomepage: https://dingxiaohan.xyz/\n\nMy open-sourced papers and repos: \n\nThe **Structural Re-parameterization Universe**:\n\n1. RepLKNet (CVPR 2022) **Powerful efficient architecture with very large kernels (31x31) and guidelines for using large kernels in model CNNs**\\\n[Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs](https://arxiv.org/abs/2203.06717)\\\n[code](https://github.com/DingXiaoH/RepLKNet-pytorch).\n\n2. **RepOptimizer** (ICLR 2023) uses **Gradient Re-parameterization** to train powerful models efficiently. The training-time **RepOpt-VGG** is **as simple as the inference-time**. It also addresses the problem of quantization.\\\n[Re-parameterizing Your Optimizers rather than Architectures](https://arxiv.org/pdf/2205.15242.pdf)\\\n[code](https://github.com/DingXiaoH/RepOptimizers).\n\n3. RepVGG (CVPR 2021) **A super simple and powerful VGG-style ConvNet architecture**. Up to **84.16%** ImageNet top-1 accuracy!\\\n[RepVGG: Making VGG-style ConvNets Great Again](https://arxiv.org/abs/2101.03697)\\\n[code](https://github.com/DingXiaoH/RepVGG).\n\n4. RepMLP (CVPR 2022) **MLP-style building block and Architecture**\\\n[RepMLPNet: Hierarchical Vision MLP with Re-parameterized Locality](https://arxiv.org/abs/2112.11081)\\\n[code](https://github.com/DingXiaoH/RepMLP).\n\n5. ResRep (ICCV 2021) **State-of-the-art** channel pruning (Res50, 55\\% FLOPs reduction, 76.15\\% acc)\\\n[ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting](https://openaccess.thecvf.com/content/ICCV2021/papers/Ding_ResRep_Lossless_CNN_Pruning_via_Decoupling_Remembering_and_Forgetting_ICCV_2021_paper.pdf)\\\n[code](https://github.com/DingXiaoH/ResRep).\n\n6. ACB (ICCV 2019) is a CNN component without any inference-time costs. The first work of our Structural Re-parameterization Universe.\\\n[ACNet: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ding_ACNet_Strengthening_the_Kernel_Skeletons_for_Powerful_CNN_via_Asymmetric_ICCV_2019_paper.pdf).\\\n[code](https://github.com/DingXiaoH/ACNet). \n\n7. DBB (CVPR 2021) is a CNN component with higher performance than ACB and still no inference-time costs. Sometimes I call it ACNet v2 because \"DBB\" is 2 bits larger than \"ACB\" in ASCII (lol).\\\n[Diverse Branch Block: Building a Convolution as an Inception-like Unit](https://arxiv.org/abs/2103.13425)\\\n[code](https://github.com/DingXiaoH/DiverseBranchBlock).\n\n**Model compression and acceleration**:\n\n1. (CVPR 2019) Channel pruning: [Centripetal SGD for Pruning Very Deep Convolutional Networks with Complicated Structure](http://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Centripetal_SGD_for_Pruning_Very_Deep_Convolutional_Networks_With_Complicated_CVPR_2019_paper.html)\\\n[code](https://github.com/DingXiaoH/Centripetal-SGD)\n\n2. (ICML 2019) Channel pruning: [Approximated Oracle Filter Pruning for Destructive CNN Width Optimization](http://proceedings.mlr.press/v97/ding19a.html)\\\n[code](https://github.com/DingXiaoH/AOFP)\n\n3. (NeurIPS 2019) Unstructured pruning: [Global Sparse Momentum SGD for Pruning Very Deep Neural Networks](http://papers.nips.cc/paper/8867-global-sparse-momentum-sgd-for-pruning-very-deep-neural-networks.pdf)\\\n[code](https://github.com/DingXiaoH/GSM-SGD)\n"
        },
        {
          "name": "arch.PNG",
          "type": "blob",
          "size": 51.5419921875,
          "content": null
        },
        {
          "name": "data",
          "type": "tree",
          "content": null
        },
        {
          "name": "example_pspnet.py",
          "type": "blob",
          "size": 6.220703125,
          "content": "import torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom repvgg import get_RepVGG_func_by_name\n\n#   The PSPNet parts are from\n#   https://github.com/hszhao/semseg\n\nclass PPM(nn.Module):\n    def __init__(self, in_dim, reduction_dim, bins, BatchNorm):\n        super(PPM, self).__init__()\n        self.features = []\n        for bin in bins:\n            self.features.append(nn.Sequential(\n                nn.AdaptiveAvgPool2d(bin),\n                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n                BatchNorm(reduction_dim),\n                nn.ReLU(inplace=True)\n            ))\n        self.features = nn.ModuleList(self.features)\n\n    def forward(self, x):\n        x_size = x.size()\n        out = [x]\n        for f in self.features:\n            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n        return torch.cat(out, 1)\n\n\nclass PSPNet(nn.Module):\n    def __init__(self,\n                backbone_name, backbone_file, deploy,\n                 bins=(1, 2, 3, 6), dropout=0.1, classes=2,\n                 zoom_factor=8, use_ppm=True, criterion=nn.CrossEntropyLoss(ignore_index=255), BatchNorm=nn.BatchNorm2d,\n                 pretrained=True):\n        super(PSPNet, self).__init__()\n        assert 2048 % len(bins) == 0\n        assert classes > 1\n        assert zoom_factor in [1, 2, 4, 8]\n        self.zoom_factor = zoom_factor\n        self.use_ppm = use_ppm\n        self.criterion = criterion\n\n        repvgg_fn = get_RepVGG_func_by_name(backbone_name)\n        backbone = repvgg_fn(deploy)\n        if pretrained:\n            checkpoint = torch.load(backbone_file)\n            if 'state_dict' in checkpoint:\n                checkpoint = checkpoint['state_dict']\n            ckpt = {k.replace('module.', ''): v for k, v in checkpoint.items()}  # strip the names\n            backbone.load_state_dict(ckpt)\n\n        self.layer0, self.layer1, self.layer2, self.layer3, self.layer4 = backbone.stage0, backbone.stage1, backbone.stage2, backbone.stage3, backbone.stage4\n\n        #   The last two stages should have stride=1 for semantic segmentation\n        #   Note that the stride of 1x1 should be the same as the 3x3\n        #   Use dilation following the implementation of PSPNet\n        secondlast_channel = 0\n        for n, m in self.layer3.named_modules():\n            if ('rbr_dense' in n or 'rbr_reparam' in n) and isinstance(m, nn.Conv2d):\n                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n                print('change dilation, padding, stride of ', n)\n                secondlast_channel = m.out_channels\n            elif 'rbr_1x1' in n and isinstance(m, nn.Conv2d):\n                m.stride = (1, 1)\n                print('change stride of ', n)\n        last_channel = 0\n        for n, m in self.layer4.named_modules():\n            if ('rbr_dense' in n or 'rbr_reparam' in n) and isinstance(m, nn.Conv2d):\n                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n                print('change dilation, padding, stride of ', n)\n                last_channel = m.out_channels\n            elif 'rbr_1x1' in n and isinstance(m, nn.Conv2d):\n                m.stride = (1, 1)\n                print('change stride of ', n)\n\n        fea_dim = last_channel\n        aux_in = secondlast_channel\n\n        if use_ppm:\n            self.ppm = PPM(fea_dim, int(fea_dim/len(bins)), bins, BatchNorm)\n            fea_dim *= 2\n\n        self.cls = nn.Sequential(\n            nn.Conv2d(fea_dim, 512, kernel_size=3, padding=1, bias=False),\n            BatchNorm(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p=dropout),\n            nn.Conv2d(512, classes, kernel_size=1)\n        )\n        if self.training:\n            self.aux = nn.Sequential(\n                nn.Conv2d(aux_in, 256, kernel_size=3, padding=1, bias=False),\n                BatchNorm(256),\n                nn.ReLU(inplace=True),\n                nn.Dropout2d(p=dropout),\n                nn.Conv2d(256, classes, kernel_size=1)\n            )\n\n    def forward(self, x, y=None):\n        x_size = x.size()\n        assert (x_size[2]-1) % 8 == 0 and (x_size[3]-1) % 8 == 0\n        h = int((x_size[2] - 1) / 8 * self.zoom_factor + 1)\n        w = int((x_size[3] - 1) / 8 * self.zoom_factor + 1)\n\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x_tmp = self.layer3(x)\n        x = self.layer4(x_tmp)\n\n        if self.use_ppm:\n            x = self.ppm(x)\n        x = self.cls(x)\n        if self.zoom_factor != 1:\n            x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)\n\n        if self.training:\n            aux = self.aux(x_tmp)\n            if self.zoom_factor != 1:\n                aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n            main_loss = self.criterion(x, y)\n            aux_loss = self.criterion(aux, y)\n            return x.max(1)[1], main_loss, aux_loss\n        else:\n            return x\n\n\nif __name__ == '__main__':\n    #   1.  Build the PSPNet with RepVGG backbone. Download the ImageNet-pretrained weight file and load it.\n    model = PSPNet(backbone_name='RepVGG-A0', backbone_file='RepVGG-A0-train.pth', deploy=False, classes=19, pretrained=True)\n\n    #   2.  Train it\n    #   seg_train(model)\n\n    #   3.  Convert and check the equivalence\n    input = torch.rand(4, 3, 713, 713)\n    model.eval()\n    print(model)\n    y_train = model(input)\n    for module in model.modules():\n        if hasattr(module, 'switch_to_deploy'):\n            module.switch_to_deploy()\n    y_deploy = model(input)\n    print('output is ', y_deploy.size())\n    print('=================== The diff is')\n    print(((y_deploy - y_train) ** 2).sum())\n\n    #   4.  Save the converted model\n    torch.save(model.state_dict(), 'PSPNet-RepVGG-A0-deploy.pth')\n    del model   #   Or do whatever you want with it\n\n    #   5.  For inference, load the saved model. There is no need to load the ImageNet-pretrained weights again.\n    deploy_model = PSPNet(backbone_name='RepVGG-A0', backbone_file=None, deploy=True, classes=19, pretrained=False)\n    deploy_model.eval()\n    deploy_model.load_state_dict(torch.load('PSPNet-RepVGG-A0-deploy.pth'))\n\n    #   6.  Check again or do whatever you want\n    y_deploy = deploy_model(input)\n    print('=================== The diff is')\n    print(((y_deploy - y_train) ** 2).sum())"
        },
        {
          "name": "jizhi_submit_train_repvgg.py",
          "type": "blob",
          "size": 1.5390625,
          "content": "import argparse\nimport datetime\nimport os\nimport json\n\nparser = argparse.ArgumentParser('JIZHI submit', add_help=False)\nparser.add_argument('arch', default=None, type=str)\nparser.add_argument('tag', default=None, type=str)\nparser.add_argument('--config', default='/apdcephfs_cq2/share_1290939/xiaohanding/cnt/default_V100x8_elastic_config.json', type=str,\n                    help='config file')\n\n\nargs = parser.parse_args()\nrun_dir = f'{args.arch}_{args.tag}'\n\ncmd = f'python3 -m torch.distributed.launch --nproc_per_node 8 --master_port 12349 main.py ' \\\n      f'--arch {args.arch} --batch-size 32 --tag {args.tag} --output-dir /apdcephfs_cq2/share_1290939/xiaohanding/swin_exps/{args.arch}_{args.tag} --opts TRAIN.EPOCHS 120 TRAIN.BASE_LR 0.1 TRAIN.WEIGHT_DECAY 4e-5 TRAIN.WARMUP_EPOCHS 5 MODEL.LABEL_SMOOTHING 0.1 AUG.PRESET raug15 DATA.DATASET imagenet'\n\nos.system('cd /apdcephfs_cq2/share_1290939/xiaohanding/RepVGG/')\nos.system(f'mkdir runs/{run_dir}')\nwith open(f'runs/{run_dir}/start.sh', 'w') as f:\n    f.write(cmd)\nwith open(args.config, 'r') as f:\n    json_content = json.load(f)\njson_content['model_local_file_path'] = f'/apdcephfs_cq2/share_1290939/xiaohanding/RepVGG/runs/{run_dir}'\nconfig_file_path = f'/apdcephfs_cq2/share_1290939/xiaohanding/RepVGG/runs/{run_dir}/config.json'\nwith open(config_file_path, 'w') as f:\n    json.dump(json_content, f)\n\nos.system(f'cp *.py runs/{run_dir}/')\nos.system(f'cp -r data runs/{run_dir}/')\nos.system(f'cp -r train runs/{run_dir}/')\nos.system(f'cd runs/{run_dir}')\nos.system(f'jizhi_client start -scfg {config_file_path}')"
        },
        {
          "name": "main.py",
          "type": "blob",
          "size": 17.46484375,
          "content": "# --------------------------------------------------------\n# RepVGG: Making VGG-style ConvNets Great Again (https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf)\n# Github source: https://github.com/DingXiaoH/RepVGG\n# Licensed under The MIT License [see LICENSE for details]\n# The training script is based on the code of Swin Transformer (https://github.com/microsoft/Swin-Transformer)\n# --------------------------------------------------------\nimport time\nimport argparse\nimport datetime\nimport numpy as np\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nfrom timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\nfrom timm.utils import accuracy, AverageMeter\nfrom train.config import get_config\nfrom data import build_loader\nfrom train.lr_scheduler import build_scheduler\nfrom train.logger import create_logger\nfrom utils import load_checkpoint, save_checkpoint, get_grad_norm, auto_resume_helper, reduce_tensor, save_latest, update_model_ema, unwrap_model\nimport copy\nfrom train.optimizer import build_optimizer\nfrom repvggplus import create_RepVGGplus_by_name\n\ntry:\n    # noinspection PyUnresolvedReferences\n    from apex import amp\nexcept ImportError:\n    amp = None\n\ndef parse_option():\n    parser = argparse.ArgumentParser('RepOpt-VGG training script built on the codebase of Swin Transformer', add_help=False)\n    parser.add_argument(\n        \"--opts\",\n        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n        default=None,\n        nargs='+',\n    )\n\n    # easy config modification\n    parser.add_argument('--arch', default=None, type=str, help='arch name')\n    parser.add_argument('--batch-size', default=128, type=int, help=\"batch size for single GPU\")\n    parser.add_argument('--data-path', default='/your/path/to/dataset', type=str, help='path to dataset')\n    parser.add_argument('--scales-path', default=None, type=str, help='path to the trained Hyper-Search model')\n    parser.add_argument('--zip', action='store_true', help='use zipped dataset instead of folder dataset')\n    parser.add_argument('--cache-mode', type=str, default='part', choices=['no', 'full', 'part'],\n                        help='no: no cache, '\n                             'full: cache all data, '\n                             'part: sharding the dataset into nonoverlapping pieces and only cache one piece')\n    parser.add_argument('--resume', help='resume from checkpoint')\n    parser.add_argument('--accumulation-steps', type=int, help=\"gradient accumulation steps\")\n    parser.add_argument('--use-checkpoint', action='store_true',\n                        help=\"whether to use gradient checkpointing to save memory\")\n    parser.add_argument('--amp-opt-level', type=str, default='O0', choices=['O0', 'O1', 'O2'],  #TODO Note: use amp if you have it\n                        help='mixed precision opt level, if O0, no amp is used')\n    parser.add_argument('--output', default='/your/path/to/save/dir', type=str, metavar='PATH',\n                        help='root of output folder, the full path is <output>/<model_name>/<tag> (default: output)')\n    parser.add_argument('--tag', help='tag of experiment')\n    parser.add_argument('--eval', action='store_true', help='Perform evaluation only')\n    parser.add_argument('--throughput', action='store_true', help='Test throughput only')\n\n    # distributed training\n    parser.add_argument(\"--local_rank\", type=int, default=0, help='local rank for DistributedDataParallel')\n\n    args, unparsed = parser.parse_known_args()\n\n    config = get_config(args)\n\n    return args, config\n\n\n\n\n\ndef main(config):\n    dataset_train, dataset_val, data_loader_train, data_loader_val, mixup_fn = build_loader(config)\n\n    logger.info(f\"Creating model:{config.MODEL.ARCH}\")\n\n    model = create_RepVGGplus_by_name(config.MODEL.ARCH, deploy=False, use_checkpoint=args.use_checkpoint)\n    optimizer = build_optimizer(config, model)\n\n    logger.info(str(model))\n    model.cuda()\n\n    if torch.cuda.device_count() > 1:\n        if config.AMP_OPT_LEVEL != \"O0\":\n            model, optimizer = amp.initialize(model, optimizer, opt_level=config.AMP_OPT_LEVEL)\n        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[config.LOCAL_RANK],\n                                                          broadcast_buffers=False)\n        model_without_ddp = model.module\n    else:\n        if config.AMP_OPT_LEVEL != \"O0\":\n            model, optimizer = amp.initialize(model, optimizer, opt_level=config.AMP_OPT_LEVEL)\n        model_without_ddp = model\n\n    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    logger.info(f\"number of params: {n_parameters}\")\n    if hasattr(model_without_ddp, 'flops'):\n        flops = model_without_ddp.flops()\n        logger.info(f\"number of GFLOPs: {flops / 1e9}\")\n\n    if config.THROUGHPUT_MODE:\n        throughput(data_loader_val, model, logger)\n        return\n\n    if config.EVAL_MODE:\n        load_weights(model, config.MODEL.RESUME)\n        acc1, acc5, loss = validate(config, data_loader_val, model)\n        logger.info(f\"Only eval. top-1 acc, top-5 acc, loss: {acc1:.3f}, {acc5:.3f}, {loss:.5f}\")\n        return\n\n    lr_scheduler = build_scheduler(config, optimizer, len(data_loader_train))\n\n    if config.AUG.MIXUP > 0.:\n        # smoothing is handled with mixup label transform\n        criterion = SoftTargetCrossEntropy()\n    elif config.MODEL.LABEL_SMOOTHING > 0.:\n        criterion = LabelSmoothingCrossEntropy(smoothing=config.MODEL.LABEL_SMOOTHING)\n    else:\n        criterion = torch.nn.CrossEntropyLoss()\n\n    max_accuracy = 0.0\n    max_ema_accuracy = 0.0\n\n    if config.TRAIN.EMA_ALPHA > 0 and (not config.EVAL_MODE) and (not config.THROUGHPUT_MODE):\n        model_ema = copy.deepcopy(model)\n    else:\n        model_ema = None\n\n    if config.TRAIN.AUTO_RESUME:\n        resume_file = auto_resume_helper(config.OUTPUT)\n        if resume_file:\n            if config.MODEL.RESUME:\n                logger.warning(f\"auto-resume changing resume file from {config.MODEL.RESUME} to {resume_file}\")\n            config.defrost()\n            config.MODEL.RESUME = resume_file\n            config.freeze()\n            logger.info(f'auto resuming from {resume_file}')\n        else:\n            logger.info(f'no checkpoint found in {config.OUTPUT}, ignoring auto resume')\n\n    if (not config.THROUGHPUT_MODE) and config.MODEL.RESUME:\n        max_accuracy = load_checkpoint(config, model_without_ddp, optimizer, lr_scheduler, logger, model_ema=model_ema)\n\n\n    logger.info(\"Start training\")\n    start_time = time.time()\n    for epoch in range(config.TRAIN.START_EPOCH, config.TRAIN.EPOCHS):\n        data_loader_train.sampler.set_epoch(epoch)\n\n        train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch, mixup_fn, lr_scheduler, model_ema=model_ema)\n        if dist.get_rank() == 0:\n            save_latest(config, epoch, model_without_ddp, max_accuracy, optimizer, lr_scheduler, logger, model_ema=model_ema)\n            if epoch % config.SAVE_FREQ == 0:\n                save_checkpoint(config, epoch, model_without_ddp, max_accuracy, optimizer, lr_scheduler, logger, model_ema=model_ema)\n\n        if epoch % config.SAVE_FREQ == 0 or epoch >= (config.TRAIN.EPOCHS - 10):\n\n            if data_loader_val is not None:\n                acc1, acc5, loss = validate(config, data_loader_val, model)\n                logger.info(f\"Accuracy of the network at epoch {epoch}: {acc1:.3f}%\")\n                max_accuracy = max(max_accuracy, acc1)\n                logger.info(f'Max accuracy: {max_accuracy:.2f}%')\n                if max_accuracy == acc1 and dist.get_rank() == 0:\n                    save_checkpoint(config, epoch, model_without_ddp, max_accuracy, optimizer, lr_scheduler, logger,\n                                    is_best=True, model_ema=model_ema)\n\n            if model_ema is not None:\n                if data_loader_val is not None:\n                    acc1, acc5, loss = validate(config, data_loader_val, model_ema)\n                    logger.info(f\"EMAAccuracy of the network at epoch {epoch} test images: {acc1:.3f}%\")\n                    max_ema_accuracy = max(max_ema_accuracy, acc1)\n                    logger.info(f'EMAMax accuracy: {max_ema_accuracy:.2f}%')\n                    if max_ema_accuracy == acc1 and dist.get_rank() == 0:\n                        best_ema_path = os.path.join(config.OUTPUT, 'best_ema.pth')\n                        logger.info(f\"{best_ema_path} best EMA saving......\")\n                        torch.save(unwrap_model(model_ema).state_dict(), best_ema_path)\n                else:\n                    latest_ema_path = os.path.join(config.OUTPUT, 'latest_ema.pth')\n                    logger.info(f\"{latest_ema_path} latest EMA saving......\")\n                    torch.save(unwrap_model(model_ema).state_dict(), latest_ema_path)\n\n    total_time = time.time() - start_time\n    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n    logger.info('Training time {}'.format(total_time_str))\n\n\ndef train_one_epoch(config, model, criterion, data_loader, optimizer, epoch, mixup_fn, lr_scheduler, model_ema=None):\n    model.train()\n    optimizer.zero_grad()\n\n    num_steps = len(data_loader)\n    batch_time = AverageMeter()\n    loss_meter = AverageMeter()\n    norm_meter = AverageMeter()\n\n    start = time.time()\n    end = time.time()\n    for idx, (samples, targets) in enumerate(data_loader):\n        samples = samples.cuda(non_blocking=True)\n        targets = targets.cuda(non_blocking=True)\n\n        if mixup_fn is not None:\n            samples, targets = mixup_fn(samples, targets)\n\n        outputs = model(samples)\n\n        if type(outputs) is dict:\n            loss = 0.0\n            for name, pred in outputs.items():\n                if 'aux' in name:\n                    loss += 0.1 * criterion(pred, targets)\n                else:\n                    loss += criterion(pred, targets)\n        else:\n            loss = criterion(outputs, targets)\n\n        if config.TRAIN.ACCUMULATION_STEPS > 1:\n\n            loss = loss / config.TRAIN.ACCUMULATION_STEPS\n            if config.AMP_OPT_LEVEL != \"O0\":\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n                if config.TRAIN.CLIP_GRAD:\n                    grad_norm = torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), config.TRAIN.CLIP_GRAD)\n                else:\n                    grad_norm = get_grad_norm(amp.master_params(optimizer))\n            else:\n                loss.backward()\n                if config.TRAIN.CLIP_GRAD:\n                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.TRAIN.CLIP_GRAD)\n                else:\n                    grad_norm = get_grad_norm(model.parameters())\n            if (idx + 1) % config.TRAIN.ACCUMULATION_STEPS == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n                lr_scheduler.step_update(epoch * num_steps + idx)\n\n        else:\n\n            optimizer.zero_grad()\n            if config.AMP_OPT_LEVEL != \"O0\":\n                with amp.scale_loss(loss, optimizer) as scaled_loss:\n                    scaled_loss.backward()\n                if config.TRAIN.CLIP_GRAD:\n                    grad_norm = torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), config.TRAIN.CLIP_GRAD)\n                else:\n                    grad_norm = get_grad_norm(amp.master_params(optimizer))\n            else:\n                loss.backward()\n                if config.TRAIN.CLIP_GRAD:\n                    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.TRAIN.CLIP_GRAD)\n                else:\n                    grad_norm = get_grad_norm(model.parameters())\n            optimizer.step()\n            lr_scheduler.step_update(epoch * num_steps + idx)\n\n        torch.cuda.synchronize()\n\n        loss_meter.update(loss.item(), targets.size(0))\n        norm_meter.update(grad_norm)\n        batch_time.update(time.time() - end)\n\n        if model_ema is not None:\n            update_model_ema(config, dist.get_world_size(), model=model, model_ema=model_ema, cur_epoch=epoch, cur_iter=idx)\n\n        end = time.time()\n\n        if idx % config.PRINT_FREQ == 0:\n            lr = optimizer.param_groups[0]['lr']\n            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n            etas = batch_time.avg * (num_steps - idx)\n            logger.info(\n                f'Train: [{epoch}/{config.TRAIN.EPOCHS}][{idx}/{num_steps}]\\t'\n                f'eta {datetime.timedelta(seconds=int(etas))} lr {lr:.6f}\\t'\n                f'time {batch_time.val:.4f} ({batch_time.avg:.4f})\\t'\n                f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n                f'grad_norm {norm_meter.val:.4f} ({norm_meter.avg:.4f})\\t'\n                f'mem {memory_used:.0f}MB')\n    epoch_time = time.time() - start\n    logger.info(f\"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}\")\n\n\n@torch.no_grad()\ndef validate(config, data_loader, model):\n    criterion = torch.nn.CrossEntropyLoss()\n    model.eval()\n\n    batch_time = AverageMeter()\n    loss_meter = AverageMeter()\n    acc1_meter = AverageMeter()\n    acc5_meter = AverageMeter()\n\n    end = time.time()\n    for idx, (images, target) in enumerate(data_loader):\n        images = images.cuda(non_blocking=True)\n        target = target.cuda(non_blocking=True)\n\n        # compute output\n        output = model(images)\n\n        #   =============================== deepsup part\n        if type(output) is dict:\n            output = output['main']\n\n        # measure accuracy and record loss\n        loss = criterion(output, target)\n        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n\n        acc1 = reduce_tensor(acc1)\n        acc5 = reduce_tensor(acc5)\n        loss = reduce_tensor(loss)\n\n        loss_meter.update(loss.item(), target.size(0))\n        acc1_meter.update(acc1.item(), target.size(0))\n        acc5_meter.update(acc5.item(), target.size(0))\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if idx % config.PRINT_FREQ == 0:\n            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n            logger.info(\n                f'Test: [{idx}/{len(data_loader)}]\\t'\n                f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n                f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'\n                f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'\n                f'Mem {memory_used:.0f}MB')\n    logger.info(f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}')\n    return acc1_meter.avg, acc5_meter.avg, loss_meter.avg\n\n\n@torch.no_grad()\ndef throughput(data_loader, model, logger):\n    model.eval()\n\n    for idx, (images, _) in enumerate(data_loader):\n        images = images.cuda(non_blocking=True)\n\n        batch_size = images.shape[0]\n        for i in range(50):\n            model(images)\n        torch.cuda.synchronize()\n        logger.info(f\"throughput averaged with 30 times\")\n        tic1 = time.time()\n        for i in range(30):\n            model(images)\n        torch.cuda.synchronize()\n        tic2 = time.time()\n        throughput = 30 * batch_size / (tic2 - tic1)\n        logger.info(f\"batch_size {batch_size} throughput {throughput}\")\n        return\n\n\nimport os\n\nif __name__ == '__main__':\n    args, config = parse_option()\n\n    if config.AMP_OPT_LEVEL != \"O0\":\n        assert amp is not None, \"amp not installed!\"\n\n    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n        rank = int(os.environ[\"RANK\"])\n        world_size = int(os.environ['WORLD_SIZE'])\n    else:\n        rank = -1\n        world_size = -1\n    torch.cuda.set_device(config.LOCAL_RANK)\n    torch.distributed.init_process_group(backend='nccl', init_method='env://', world_size=world_size, rank=rank)\n    torch.distributed.barrier()\n    seed = config.SEED + dist.get_rank()\n\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    cudnn.benchmark = True\n\n    if not config.EVAL_MODE:\n        # linear scale the learning rate according to total batch size, may not be optimal\n        linear_scaled_lr = config.TRAIN.BASE_LR * config.DATA.BATCH_SIZE * dist.get_world_size() / 256.0\n        linear_scaled_warmup_lr = config.TRAIN.WARMUP_LR * config.DATA.BATCH_SIZE * dist.get_world_size() / 256.0\n        linear_scaled_min_lr = config.TRAIN.MIN_LR * config.DATA.BATCH_SIZE * dist.get_world_size() / 256.0\n        # gradient accumulation also need to scale the learning rate\n        if config.TRAIN.ACCUMULATION_STEPS > 1:\n            linear_scaled_lr = linear_scaled_lr * config.TRAIN.ACCUMULATION_STEPS\n            linear_scaled_warmup_lr = linear_scaled_warmup_lr * config.TRAIN.ACCUMULATION_STEPS\n            linear_scaled_min_lr = linear_scaled_min_lr * config.TRAIN.ACCUMULATION_STEPS\n        config.defrost()\n        config.TRAIN.BASE_LR = linear_scaled_lr\n        config.TRAIN.WARMUP_LR = linear_scaled_warmup_lr\n        config.TRAIN.MIN_LR = linear_scaled_min_lr\n        config.freeze()\n\n    print('==========================================')\n    print('real base lr: ', config.TRAIN.BASE_LR)\n    print('==========================================')\n\n    os.makedirs(config.OUTPUT, exist_ok=True)\n\n    logger = create_logger(output_dir=config.OUTPUT, dist_rank=0 if torch.cuda.device_count() == 1 else dist.get_rank(), name=f\"{config.MODEL.ARCH}\")\n\n    if torch.cuda.device_count() == 1 or dist.get_rank() == 0:\n        path = os.path.join(config.OUTPUT, \"config.json\")\n        with open(path, \"w\") as f:\n            f.write(config.dump())\n        logger.info(f\"Full config saved to {path}\")\n\n    # print config\n    logger.info(config.dump())\n\n    main(config)\n"
        },
        {
          "name": "quantization",
          "type": "tree",
          "content": null
        },
        {
          "name": "repvgg.py",
          "type": "blob",
          "size": 14.51953125,
          "content": "# --------------------------------------------------------\n# RepVGG: Making VGG-style ConvNets Great Again (https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf)\n# Github source: https://github.com/DingXiaoH/RepVGG\n# Licensed under The MIT License [see LICENSE for details]\n# --------------------------------------------------------\nimport torch.nn as nn\nimport numpy as np\nimport torch\nimport copy\nfrom se_block import SEBlock\nimport torch.utils.checkpoint as checkpoint\n\ndef conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    return result\n\nclass RepVGGBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size,\n                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False, use_se=False):\n        super(RepVGGBlock, self).__init__()\n        self.deploy = deploy\n        self.groups = groups\n        self.in_channels = in_channels\n\n        assert kernel_size == 3\n        assert padding == 1\n\n        padding_11 = padding - kernel_size // 2\n\n        self.nonlinearity = nn.ReLU()\n\n        if use_se:\n            #   Note that RepVGG-D2se uses SE before nonlinearity. But RepVGGplus models uses SE after nonlinearity.\n            self.se = SEBlock(out_channels, internal_neurons=out_channels // 16)\n        else:\n            self.se = nn.Identity()\n\n        if deploy:\n            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n\n        else:\n            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n            print('RepVGG Block, identity = ', self.rbr_identity)\n\n\n    def forward(self, inputs):\n        if hasattr(self, 'rbr_reparam'):\n            return self.nonlinearity(self.se(self.rbr_reparam(inputs)))\n\n        if self.rbr_identity is None:\n            id_out = 0\n        else:\n            id_out = self.rbr_identity(inputs)\n\n        return self.nonlinearity(self.se(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out))\n\n\n    #   Optional. This may improve the accuracy and facilitates quantization in some cases.\n    #   1.  Cancel the original weight decay on rbr_dense.conv.weight and rbr_1x1.conv.weight.\n    #   2.  Use like this.\n    #       loss = criterion(....)\n    #       for every RepVGGBlock blk:\n    #           loss += weight_decay_coefficient * 0.5 * blk.get_cust_L2()\n    #       optimizer.zero_grad()\n    #       loss.backward()\n    def get_custom_L2(self):\n        K3 = self.rbr_dense.conv.weight\n        K1 = self.rbr_1x1.conv.weight\n        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n\n        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()      # The L2 loss of the \"circle\" of weights in 3x3 kernel. Use regular L2 on them.\n        eq_kernel = K3[:, :, 1:2, 1:2] * t3 + K1 * t1                           # The equivalent resultant central point of 3x3 kernel.\n        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()        # Normalize for an L2 coefficient comparable to regular L2.\n        return l2_loss_eq_kernel + l2_loss_circle\n\n\n\n#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n#   You can get the equivalent kernel and bias at any time and do whatever you want,\n    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n#   May be useful for quantization or pruning.\n    def get_equivalent_kernel_bias(self):\n        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n\n    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n        if kernel1x1 is None:\n            return 0\n        else:\n            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n\n    def _fuse_bn_tensor(self, branch):\n        if branch is None:\n            return 0, 0\n        if isinstance(branch, nn.Sequential):\n            kernel = branch.conv.weight\n            running_mean = branch.bn.running_mean\n            running_var = branch.bn.running_var\n            gamma = branch.bn.weight\n            beta = branch.bn.bias\n            eps = branch.bn.eps\n        else:\n            assert isinstance(branch, nn.BatchNorm2d)\n            if not hasattr(self, 'id_tensor'):\n                input_dim = self.in_channels // self.groups\n                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n                for i in range(self.in_channels):\n                    kernel_value[i, i % input_dim, 1, 1] = 1\n                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n            kernel = self.id_tensor\n            running_mean = branch.running_mean\n            running_var = branch.running_var\n            gamma = branch.weight\n            beta = branch.bias\n            eps = branch.eps\n        std = (running_var + eps).sqrt()\n        t = (gamma / std).reshape(-1, 1, 1, 1)\n        return kernel * t, beta - running_mean * gamma / std\n\n    def switch_to_deploy(self):\n        if hasattr(self, 'rbr_reparam'):\n            return\n        kernel, bias = self.get_equivalent_kernel_bias()\n        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels, out_channels=self.rbr_dense.conv.out_channels,\n                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation, groups=self.rbr_dense.conv.groups, bias=True)\n        self.rbr_reparam.weight.data = kernel\n        self.rbr_reparam.bias.data = bias\n        self.__delattr__('rbr_dense')\n        self.__delattr__('rbr_1x1')\n        if hasattr(self, 'rbr_identity'):\n            self.__delattr__('rbr_identity')\n        if hasattr(self, 'id_tensor'):\n            self.__delattr__('id_tensor')\n        self.deploy = True\n\n\n\nclass RepVGG(nn.Module):\n\n    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False, use_se=False, use_checkpoint=False):\n        super(RepVGG, self).__init__()\n        assert len(width_multiplier) == 4\n        self.deploy = deploy\n        self.override_groups_map = override_groups_map or dict()\n        assert 0 not in self.override_groups_map\n        self.use_se = use_se\n        self.use_checkpoint = use_checkpoint\n\n        self.in_planes = min(64, int(64 * width_multiplier[0]))\n        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_se=self.use_se)\n        self.cur_layer_idx = 1\n        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n\n    def _make_stage(self, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        blocks = []\n        for stride in strides:\n            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy, use_se=self.use_se))\n            self.in_planes = planes\n            self.cur_layer_idx += 1\n        return nn.ModuleList(blocks)\n\n    def forward(self, x):\n        out = self.stage0(x)\n        for stage in (self.stage1, self.stage2, self.stage3, self.stage4):\n            for block in stage:\n                if self.use_checkpoint:\n                    out = checkpoint.checkpoint(block, out)\n                else:\n                    out = block(out)\n        out = self.gap(out)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\noptional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\ng2_map = {l: 2 for l in optional_groupwise_layers}\ng4_map = {l: 4 for l in optional_groupwise_layers}\n\ndef create_RepVGG_A0(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_A1(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_A2(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B0(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B1(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B1g2(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B1g4(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\n\ndef create_RepVGG_B2(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B2g2(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B2g4(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\n\ndef create_RepVGG_B3(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B3g2(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_B3g4(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy, use_checkpoint=use_checkpoint)\n\ndef create_RepVGG_D2se(deploy=False, use_checkpoint=False):\n    return RepVGG(num_blocks=[8, 14, 24, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy, use_se=True, use_checkpoint=use_checkpoint)\n\n\nfunc_dict = {\n'RepVGG-A0': create_RepVGG_A0,\n'RepVGG-A1': create_RepVGG_A1,\n'RepVGG-A2': create_RepVGG_A2,\n'RepVGG-B0': create_RepVGG_B0,\n'RepVGG-B1': create_RepVGG_B1,\n'RepVGG-B1g2': create_RepVGG_B1g2,\n'RepVGG-B1g4': create_RepVGG_B1g4,\n'RepVGG-B2': create_RepVGG_B2,\n'RepVGG-B2g2': create_RepVGG_B2g2,\n'RepVGG-B2g4': create_RepVGG_B2g4,\n'RepVGG-B3': create_RepVGG_B3,\n'RepVGG-B3g2': create_RepVGG_B3g2,\n'RepVGG-B3g4': create_RepVGG_B3g4,\n'RepVGG-D2se': create_RepVGG_D2se,      #   Updated at April 25, 2021. This is not reported in the CVPR paper.\n}\ndef get_RepVGG_func_by_name(name):\n    return func_dict[name]\n\n\n\n#   Use this for converting a RepVGG model or a bigger model with RepVGG as its component\n#   Use like this\n#   model = create_RepVGG_A0(deploy=False)\n#   train model or load weights\n#   repvgg_model_convert(model, save_path='repvgg_deploy.pth')\n#   If you want to preserve the original model, call with do_copy=True\n\n#   ====================== for using RepVGG as the backbone of a bigger model, e.g., PSPNet, the pseudo code will be like\n#   train_backbone = create_RepVGG_B2(deploy=False)\n#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n#   train_pspnet = build_pspnet(backbone=train_backbone)\n#   segmentation_train(train_pspnet)\n#   deploy_pspnet = repvgg_model_convert(train_pspnet)\n#   segmentation_test(deploy_pspnet)\n#   =====================   example_pspnet.py shows an example\n\ndef repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n    if do_copy:\n        model = copy.deepcopy(model)\n    for module in model.modules():\n        if hasattr(module, 'switch_to_deploy'):\n            module.switch_to_deploy()\n    if save_path is not None:\n        torch.save(model.state_dict(), save_path)\n    return model\n"
        },
        {
          "name": "repvggplus.py",
          "type": "blob",
          "size": 14.01171875,
          "content": "# --------------------------------------------------------\n# RepVGG: Making VGG-style ConvNets Great Again (https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf)\n# Github source: https://github.com/DingXiaoH/RepVGG\n# Licensed under The MIT License [see LICENSE for details]\n# --------------------------------------------------------\n\nimport torch.nn as nn\nimport torch.utils.checkpoint as checkpoint\nfrom se_block import SEBlock\nimport torch\nimport numpy as np\n\ndef conv_bn_relu(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    result.add_module('relu', nn.ReLU())\n    return result\n\ndef conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    return result\n\nclass RepVGGplusBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size,\n                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros',\n                 deploy=False,\n                 use_post_se=False):\n        super(RepVGGplusBlock, self).__init__()\n        self.deploy = deploy\n        self.groups = groups\n        self.in_channels = in_channels\n\n        assert kernel_size == 3\n        assert padding == 1\n\n        self.nonlinearity = nn.ReLU()\n\n        if use_post_se:\n            self.post_se = SEBlock(out_channels, internal_neurons=out_channels // 4)\n        else:\n            self.post_se = nn.Identity()\n\n        if deploy:\n            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n        else:\n            if out_channels == in_channels and stride == 1:\n                self.rbr_identity = nn.BatchNorm2d(num_features=out_channels)\n            else:\n                self.rbr_identity = None\n            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n            padding_11 = padding - kernel_size // 2\n            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n\n    def forward(self, x):\n        if self.deploy:\n            return self.post_se(self.nonlinearity(self.rbr_reparam(x)))\n\n        if self.rbr_identity is None:\n            id_out = 0\n        else:\n            id_out = self.rbr_identity(x)\n        out = self.rbr_dense(x) + self.rbr_1x1(x) + id_out\n        out = self.post_se(self.nonlinearity(out))\n        return out\n\n\n    #   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n    #   You can get the equivalent kernel and bias at any time and do whatever you want,\n    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n    #   May be useful for quantization or pruning.\n    def get_equivalent_kernel_bias(self):\n        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n\n    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n        if kernel1x1 is None:\n            return 0\n        else:\n            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])\n\n    def _fuse_bn_tensor(self, branch):\n        if branch is None:\n            return 0, 0\n        if isinstance(branch, nn.Sequential):\n            #   For the 1x1 or 3x3 branch\n            kernel, running_mean, running_var, gamma, beta, eps = branch.conv.weight, branch.bn.running_mean, branch.bn.running_var, branch.bn.weight, branch.bn.bias, branch.bn.eps\n        else:\n            #   For the identity branch\n            assert isinstance(branch, nn.BatchNorm2d)\n            if not hasattr(self, 'id_tensor'):\n                #   Construct and store the identity kernel in case it is used multiple times\n                input_dim = self.in_channels // self.groups\n                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n                for i in range(self.in_channels):\n                    kernel_value[i, i % input_dim, 1, 1] = 1\n                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n            kernel, running_mean, running_var, gamma, beta, eps = self.id_tensor, branch.running_mean, branch.running_var, branch.weight, branch.bias, branch.eps\n        std = (running_var + eps).sqrt()\n        t = (gamma / std).reshape(-1, 1, 1, 1)\n        return kernel * t, beta - running_mean * gamma / std\n\n    def switch_to_deploy(self):\n        if hasattr(self, 'rbr_reparam'):\n            return\n        kernel, bias = self.get_equivalent_kernel_bias()\n        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels,\n                                     out_channels=self.rbr_dense.conv.out_channels,\n                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation,\n                                     groups=self.rbr_dense.conv.groups, bias=True)\n        self.rbr_reparam.weight.data = kernel\n        self.rbr_reparam.bias.data = bias\n        self.__delattr__('rbr_dense')\n        self.__delattr__('rbr_1x1')\n        if hasattr(self, 'rbr_identity'):\n            self.__delattr__('rbr_identity')\n        if hasattr(self, 'id_tensor'):\n            self.__delattr__('id_tensor')\n        self.deploy = True\n\n\n\nclass RepVGGplusStage(nn.Module):\n\n    def __init__(self, in_planes, planes, num_blocks, stride, use_checkpoint, use_post_se=False, deploy=False):\n        super().__init__()\n        strides = [stride] + [1] * (num_blocks - 1)\n        blocks = []\n        self.in_planes = in_planes\n        for stride in strides:\n            cur_groups = 1\n            blocks.append(RepVGGplusBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n                                      stride=stride, padding=1, groups=cur_groups, deploy=deploy, use_post_se=use_post_se))\n            self.in_planes = planes\n        self.blocks = nn.ModuleList(blocks)\n        self.use_checkpoint = use_checkpoint\n\n    def forward(self, x):\n        for block in self.blocks:\n            if self.use_checkpoint:\n                x = checkpoint.checkpoint(block, x)\n            else:\n                x = block(x)\n        return x\n\n\nclass RepVGGplus(nn.Module):\n    \"\"\"RepVGGplus\n        An official improved version of RepVGG (RepVGG: Making VGG-style ConvNets Great Again) <https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf>`_.\n\n        Args:\n            num_blocks (tuple[int]): Depths of each stage.\n            num_classes (tuple[int]): Num of classes.\n            width_multiplier (tuple[float]): The width of the four stages\n                will be (64 * width_multiplier[0], 128 * width_multiplier[1], 256 * width_multiplier[2], 512 * width_multiplier[3]).\n            deploy (bool, optional): If True, the model will have the inference-time structure.\n                Default: False.\n            use_post_se (bool, optional): If True, the model will have Squeeze-and-Excitation blocks following the conv-ReLU units.\n                Default: False.\n            use_checkpoint (bool, optional): If True, the model will use torch.utils.checkpoint to save the GPU memory during training with acceptable slowdown.\n                Do not use it if you have sufficient GPU memory.\n                Default: False.\n        \"\"\"\n    def __init__(self,\n                 num_blocks,\n                 num_classes,\n                 width_multiplier,\n                 deploy=False,\n                 use_post_se=False,\n                 use_checkpoint=False):\n        super().__init__()\n\n        self.deploy = deploy\n        self.num_classes = num_classes\n\n        in_channels = min(64, int(64 * width_multiplier[0]))\n        stage_channels = [int(64 * width_multiplier[0]), int(128 * width_multiplier[1]), int(256 * width_multiplier[2]), int(512 * width_multiplier[3])]\n        self.stage0 = RepVGGplusBlock(in_channels=3, out_channels=in_channels, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_post_se=use_post_se)\n        self.stage1 = RepVGGplusStage(in_channels, stage_channels[0], num_blocks[0], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage2 = RepVGGplusStage(stage_channels[0], stage_channels[1], num_blocks[1], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        #   split stage3 so that we can insert an auxiliary classifier\n        self.stage3_first = RepVGGplusStage(stage_channels[1], stage_channels[2], num_blocks[2] // 2, stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage3_second = RepVGGplusStage(stage_channels[2], stage_channels[2], num_blocks[2] - num_blocks[2] // 2, stride=1, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage4 = RepVGGplusStage(stage_channels[2], stage_channels[3], num_blocks[3], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n        self.flatten = nn.Flatten()\n        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n        #   aux classifiers\n        if not self.deploy:\n            self.stage1_aux = self._build_aux_for_stage(self.stage1)\n            self.stage2_aux = self._build_aux_for_stage(self.stage2)\n            self.stage3_first_aux = self._build_aux_for_stage(self.stage3_first)\n\n    def _build_aux_for_stage(self, stage):\n        stage_out_channels = list(stage.blocks.children())[-1].rbr_dense.conv.out_channels\n        downsample = conv_bn_relu(in_channels=stage_out_channels, out_channels=stage_out_channels, kernel_size=3, stride=2, padding=1)\n        fc = nn.Linear(stage_out_channels, self.num_classes, bias=True)\n        return nn.Sequential(downsample, nn.AdaptiveAvgPool2d(1), nn.Flatten(), fc)\n\n    def forward(self, x):\n        out = self.stage0(x)\n        out = self.stage1(out)\n        stage1_aux = self.stage1_aux(out)\n        out = self.stage2(out)\n        stage2_aux = self.stage2_aux(out)\n        out = self.stage3_first(out)\n        stage3_first_aux = self.stage3_first_aux(out)\n        out = self.stage3_second(out)\n        out = self.stage4(out)\n        y = self.gap(out)\n        y = self.flatten(y)\n        y = self.linear(y)\n        return {\n            'main': y,\n            'stage1_aux': stage1_aux,\n            'stage2_aux': stage2_aux,\n            'stage3_first_aux': stage3_first_aux,\n        }\n\n    def switch_repvggplus_to_deploy(self):\n        for m in self.modules():\n            if hasattr(m, 'switch_to_deploy'):\n                m.switch_to_deploy()\n        if hasattr(self, 'stage1_aux'):\n            self.__delattr__('stage1_aux')\n        if hasattr(self, 'stage2_aux'):\n            self.__delattr__('stage2_aux')\n        if hasattr(self, 'stage3_first_aux'):\n            self.__delattr__('stage3_first_aux')\n        self.deploy = True\n\n\n#   torch.utils.checkpoint can reduce the memory consumption during training with a minor slowdown. Don't use it if you have sufficient GPU memory.\n#   Not sure whether it slows down inference\n#   pse for \"post SE\", which means using SE block after ReLU\ndef create_RepVGGplus_L2pse(deploy=False, use_checkpoint=False):\n    return RepVGGplus(num_blocks=[8, 14, 24, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], deploy=deploy, use_post_se=True,\n                      use_checkpoint=use_checkpoint)\n\n#   Will release more\nrepvggplus_func_dict = {\n    'RepVGGplus-L2pse': create_RepVGGplus_L2pse,\n}\n\ndef create_RepVGGplus_by_name(name, deploy=False, use_checkpoint=False):\n    if 'plus' in name:\n        return repvggplus_func_dict[name](deploy=deploy, use_checkpoint=use_checkpoint)\n    else:\n        print('=================== Building the vanila RepVGG ===================')\n        from repvgg import get_RepVGG_func_by_name\n        return get_RepVGG_func_by_name(name)(deploy=deploy, use_checkpoint=use_checkpoint)\n\n\n\n\n\n\n#   Use this for converting a RepVGG model or a bigger model with RepVGG as its component\n#   Use like this\n#   model = create_RepVGG_A0(deploy=False)\n#   train model or load weights\n#   repvgg_model_convert(model, save_path='repvgg_deploy.pth')\n#   If you want to preserve the original model, call with do_copy=True\n\n#   ====================== for using RepVGG as the backbone of a bigger model, e.g., PSPNet, the pseudo code will be like\n#   train_backbone = create_RepVGG_B2(deploy=False)\n#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n#   train_pspnet = build_pspnet(backbone=train_backbone)\n#   segmentation_train(train_pspnet)\n#   deploy_pspnet = repvgg_model_convert(train_pspnet)\n#   segmentation_test(deploy_pspnet)\n#   =====================   example_pspnet.py shows an example\n\ndef repvgg_model_convert(model:torch.nn.Module, save_path=None, do_copy=True):\n    import copy\n    if do_copy:\n        model = copy.deepcopy(model)\n    for module in model.modules():\n        if hasattr(module, 'switch_to_deploy'):\n            module.switch_to_deploy()\n    if save_path is not None:\n        torch.save(model.state_dict(), save_path)\n    return model\n"
        },
        {
          "name": "repvggplus_custom_L2.py",
          "type": "blob",
          "size": 12.939453125,
          "content": "# --------------------------------------------------------\n# RepVGG: Making VGG-style ConvNets Great Again (https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf)\n# Github source: https://github.com/DingXiaoH/RepVGG\n# Licensed under The MIT License [see LICENSE for details]\n# --------------------------------------------------------\nimport torch.nn as nn\nimport torch.utils.checkpoint as checkpoint\nfrom se_block import SEBlock\nimport torch\nimport numpy as np\n\n\ndef conv_bn_relu(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    result.add_module('relu', nn.ReLU())\n    return result\n\ndef conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n    result = nn.Sequential()\n    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n    return result\n\nclass RepVGGplusBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size,\n                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros',\n                 deploy=False,\n                 use_post_se=False):\n        super(RepVGGplusBlock, self).__init__()\n        self.deploy = deploy\n        self.groups = groups\n        self.in_channels = in_channels\n\n        assert kernel_size == 3\n        assert padding == 1\n\n        self.nonlinearity = nn.ReLU()\n\n        if use_post_se:\n            self.post_se = SEBlock(out_channels, internal_neurons=out_channels // 4)\n        else:\n            self.post_se = nn.Identity()\n\n        if deploy:\n            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n        else:\n            if out_channels == in_channels and stride == 1:\n                self.rbr_identity = nn.BatchNorm2d(num_features=out_channels)\n            else:\n                self.rbr_identity = None\n            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n            padding_11 = padding - kernel_size // 2\n            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n\n    def forward(self, x, L2):\n\n        if self.deploy:\n            return self.post_se(self.nonlinearity(self.rbr_reparam(x))), None\n\n        if self.rbr_identity is None:\n            id_out = 0\n        else:\n            id_out = self.rbr_identity(x)\n        out = self.rbr_dense(x) + self.rbr_1x1(x) + id_out\n        out = self.post_se(self.nonlinearity(out))\n\n        #   Custom L2\n        t3 = (self.rbr_dense.bn.weight / ((self.rbr_dense.bn.running_var + self.rbr_dense.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n        t1 = (self.rbr_1x1.bn.weight / ((self.rbr_1x1.bn.running_var + self.rbr_1x1.bn.eps).sqrt())).reshape(-1, 1, 1, 1).detach()\n        K3 = self.rbr_dense.conv.weight\n        K1 = self.rbr_1x1.conv.weight\n\n        l2_loss_circle = (K3 ** 2).sum() - (K3[:, :, 1:2, 1:2] ** 2).sum()\n        eq_kernel = K3[:,:,1:2,1:2] * t3 + K1 * t1\n        l2_loss_eq_kernel = (eq_kernel ** 2 / (t3 ** 2 + t1 ** 2)).sum()\n\n        return out, L2 + l2_loss_circle + l2_loss_eq_kernel\n\n\n    #   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n    #   You can get the equivalent kernel and bias at any time and do whatever you want,\n    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n    #   May be useful for quantization or pruning.\n    def get_equivalent_kernel_bias(self):\n        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n\n    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n        if kernel1x1 is None:\n            return 0\n        else:\n            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])\n\n    def _fuse_bn_tensor(self, branch):\n        if branch is None:\n            return 0, 0\n        if isinstance(branch, nn.Sequential):\n            #   For the 1x1 or 3x3 branch\n            kernel, running_mean, running_var, gamma, beta, eps = branch.conv.weight, branch.bn.running_mean, branch.bn.running_var, branch.bn.weight, branch.bn.bias, branch.bn.eps\n        else:\n            #   For the identity branch\n            assert isinstance(branch, nn.BatchNorm2d)\n            if not hasattr(self, 'id_tensor'):\n                #   Construct and store the identity kernel in case it is used multiple times\n                input_dim = self.in_channels // self.groups\n                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n                for i in range(self.in_channels):\n                    kernel_value[i, i % input_dim, 1, 1] = 1\n                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n            kernel, running_mean, running_var, gamma, beta, eps = self.id_tensor, branch.running_mean, branch.running_var, branch.weight, branch.bias, branch.eps\n        std = (running_var + eps).sqrt()\n        t = (gamma / std).reshape(-1, 1, 1, 1)\n        return kernel * t, beta - running_mean * gamma / std\n\n    def switch_to_deploy(self):\n        if hasattr(self, 'rbr_reparam'):\n            return\n        kernel, bias = self.get_equivalent_kernel_bias()\n        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels,\n                                     out_channels=self.rbr_dense.conv.out_channels,\n                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,\n                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation,\n                                     groups=self.rbr_dense.conv.groups, bias=True)\n        self.rbr_reparam.weight.data = kernel\n        self.rbr_reparam.bias.data = bias\n        self.__delattr__('rbr_dense')\n        self.__delattr__('rbr_1x1')\n        if hasattr(self, 'rbr_identity'):\n            self.__delattr__('rbr_identity')\n        if hasattr(self, 'id_tensor'):\n            self.__delattr__('id_tensor')\n        self.deploy = True\n\n\n\nclass RepVGGplusStage(nn.Module):\n\n    def __init__(self, in_planes, planes, num_blocks, stride, use_checkpoint, use_post_se=False, deploy=False):\n        super().__init__()\n        strides = [stride] + [1] * (num_blocks - 1)\n        blocks = []\n        self.in_planes = in_planes\n        for stride in strides:\n            cur_groups = 1\n            blocks.append(RepVGGplusBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n                                      stride=stride, padding=1, groups=cur_groups, deploy=deploy, use_post_se=use_post_se))\n            self.in_planes = planes\n        self.blocks = nn.ModuleList(blocks)\n        self.use_checkpoint = use_checkpoint\n\n    def forward(self, x, L2):\n        for block in self.blocks:\n            if self.use_checkpoint:\n                x, L2 = checkpoint.checkpoint(block, x, L2)\n            else:\n                x, L2 = block(x, L2)\n        return x, L2\n\n\nclass RepVGGplus(nn.Module):\n\n    def __init__(self, num_blocks, num_classes,\n                 width_multiplier, override_groups_map=None,\n                 deploy=False,\n                 use_post_se=False,\n                 use_checkpoint=False):\n        super().__init__()\n\n        self.deploy = deploy\n        self.override_groups_map = override_groups_map or dict()\n        self.use_post_se = use_post_se\n        self.use_checkpoint = use_checkpoint\n        self.num_classes = num_classes\n        self.nonlinear = 'relu'\n\n        self.in_planes = min(64, int(64 * width_multiplier[0]))\n        self.stage0 = RepVGGplusBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy, use_post_se=use_post_se)\n        self.cur_layer_idx = 1\n        self.stage1 = RepVGGplusStage(self.in_planes, int(64 * width_multiplier[0]), num_blocks[0], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage2 = RepVGGplusStage(int(64 * width_multiplier[0]), int(128 * width_multiplier[1]), num_blocks[1], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        #   split stage3 so that we can insert an auxiliary classifier\n        self.stage3_first = RepVGGplusStage(int(128 * width_multiplier[1]), int(256 * width_multiplier[2]), num_blocks[2] // 2, stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage3_second = RepVGGplusStage(int(256 * width_multiplier[2]), int(256 * width_multiplier[2]), num_blocks[2] // 2, stride=1, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.stage4 = RepVGGplusStage(int(256 * width_multiplier[2]), int(512 * width_multiplier[3]), num_blocks[3], stride=2, use_checkpoint=use_checkpoint, use_post_se=use_post_se, deploy=deploy)\n        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n        #   aux classifiers\n        if not self.deploy:\n            self.stage1_aux = self._build_aux_for_stage(self.stage1)\n            self.stage2_aux = self._build_aux_for_stage(self.stage2)\n            self.stage3_first_aux = self._build_aux_for_stage(self.stage3_first)\n\n    def _build_aux_for_stage(self, stage):\n        stage_out_channels = list(stage.blocks.children())[-1].rbr_dense.conv.out_channels\n        downsample = conv_bn_relu(in_channels=stage_out_channels, out_channels=stage_out_channels, kernel_size=3, stride=2, padding=1)\n        fc = nn.Linear(stage_out_channels, self.num_classes, bias=True)\n        return nn.Sequential(downsample, nn.AdaptiveAvgPool2d(1), nn.Flatten(), fc)\n\n    def forward(self, x):\n        if self.deploy:\n            out, _ = self.stage0(x, L2=None)\n            out, _ = self.stage1(out, L2=None)\n            out, _ = self.stage2(out, L2=None)\n            out, _ = self.stage3_first(out, L2=None)\n            out, _ = self.stage3_second(out, L2=None)\n            out, _ = self.stage4(out, L2=None)\n            y = self.gap(out)\n            y = y.view(y.size(0), -1)\n            y = self.linear(y)\n            return y\n\n        else:\n            out, L2 = self.stage0(x, L2=0.0)\n            out, L2 = self.stage1(out, L2=L2)\n            stage1_aux = self.stage1_aux(out)\n            out, L2 = self.stage2(out, L2=L2)\n            stage2_aux = self.stage2_aux(out)\n            out, L2 = self.stage3_first(out, L2=L2)\n            stage3_first_aux = self.stage3_first_aux(out)\n            out, L2 = self.stage3_second(out, L2=L2)\n            out, L2 = self.stage4(out, L2=L2)\n            y = self.gap(out)\n            y = y.view(y.size(0), -1)\n            y = self.linear(y)\n            return {\n                'main': y,\n                'stage1_aux': stage1_aux,\n                'stage2_aux': stage2_aux,\n                'stage3_first_aux': stage3_first_aux,\n                'L2': L2\n            }\n\n    def switch_repvggplus_to_deploy(self):\n        for m in self.modules():\n            if hasattr(m, 'switch_to_deploy'):\n                m.switch_to_deploy()\n            if hasattr(m, 'use_checkpoint'):\n                m.use_checkpoint = False        #   Disable checkpoint. I am not sure whether using checkpoint slows down inference.\n        if hasattr(self, 'stage1_aux'):\n            self.__delattr__('stage1_aux')\n        if hasattr(self, 'stage2_aux'):\n            self.__delattr__('stage2_aux')\n        if hasattr(self, 'stage3_first_aux'):\n            self.__delattr__('stage3_first_aux')\n        self.deploy = True\n\n\n#   torch.utils.checkpoint can reduce the memory consumption during training with a minor slowdown. Don't use it if you have sufficient GPU memory.\n#   Not sure whether it slows down inference\n#   pse for \"post SE\", which means using SE block after ReLU\ndef create_RepVGGplus_L2pse(deploy=False, use_checkpoint=False):\n    return RepVGGplus(num_blocks=[8, 14, 24, 1], num_classes=1000,\n                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy, use_post_se=True,\n                      use_checkpoint=use_checkpoint)\n\nrepvggplus_func_dict = {\n'RepVGGplus-L2pse': create_RepVGGplus_L2pse,\n}\ndef get_RepVGGplus_func_by_name(name):\n    return repvggplus_func_dict[name]"
        },
        {
          "name": "se_block.py",
          "type": "blob",
          "size": 0.8466796875,
          "content": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n#   https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html\n\nclass SEBlock(nn.Module):\n\n    def __init__(self, input_channels, internal_neurons):\n        super(SEBlock, self).__init__()\n        self.down = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=1, stride=1, bias=True)\n        self.up = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=1, stride=1, bias=True)\n        self.input_channels = input_channels\n\n    def forward(self, inputs):\n        x = F.avg_pool2d(inputs, kernel_size=inputs.size(3))\n        x = self.down(x)\n        x = F.relu(x)\n        x = self.up(x)\n        x = torch.sigmoid(x)\n        x = x.view(-1, self.input_channels, 1, 1)\n        return inputs * x"
        },
        {
          "name": "speed_acc.PNG",
          "type": "blob",
          "size": 111.30078125,
          "content": null
        },
        {
          "name": "table.PNG",
          "type": "blob",
          "size": 131.2939453125,
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        },
        {
          "name": "train",
          "type": "tree",
          "content": null
        },
        {
          "name": "utils.py",
          "type": "blob",
          "size": 9.2958984375,
          "content": "# --------------------------------------------------------\n# RepVGG: Making VGG-style ConvNets Great Again (https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf)\n# Github source: https://github.com/DingXiaoH/RepVGG\n# Licensed under The MIT License [see LICENSE for details]\n# The training script is based on the code of Swin Transformer (https://github.com/microsoft/Swin-Transformer)\n# --------------------------------------------------------\n\nimport torch\nimport math\nimport os\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\ndef load_checkpoint(model, ckpt_path):\n    checkpoint = torch.load(ckpt_path)\n    if 'model' in checkpoint:\n        checkpoint = checkpoint['model']\n    if 'state_dict' in checkpoint:\n        checkpoint = checkpoint['state_dict']\n    ckpt = {}\n    for k, v in checkpoint.items():\n        if k.startswith('module.'):\n            ckpt[k[7:]] = v\n        else:\n            ckpt[k] = v\n    model.load_state_dict(ckpt)\n\n\nclass WarmupCosineAnnealingLR(torch.optim.lr_scheduler._LRScheduler):\n\n    def __init__(self, optimizer, T_cosine_max, eta_min=0, last_epoch=-1, warmup=0):\n        self.eta_min = eta_min\n        self.T_cosine_max = T_cosine_max\n        self.warmup = warmup\n        super(WarmupCosineAnnealingLR, self).__init__(optimizer, last_epoch)\n\n    def get_lr(self):\n        if self.last_epoch < self.warmup:\n            return [self.last_epoch / self.warmup * base_lr for base_lr in self.base_lrs]\n        else:\n            return [self.eta_min + (base_lr - self.eta_min) *\n                    (1 + math.cos(math.pi * (self.last_epoch - self.warmup) / (self.T_cosine_max - self.warmup))) / 2\n                    for base_lr in self.base_lrs]\n\n\ndef log_msg(message, log_file):\n    print(message)\n    with open(log_file, 'a') as f:\n        print(message, file=f)\n\n\n\n\n\ntry:\n    # noinspection PyUnresolvedReferences\n    from apex import amp\nexcept ImportError:\n    amp = None\n\ndef unwrap_model(model):\n    \"\"\"Remove the DistributedDataParallel wrapper if present.\"\"\"\n    wrapped = isinstance(model, torch.nn.parallel.distributed.DistributedDataParallel)\n    return model.module if wrapped else model\n\n\ndef load_checkpoint(config, model, optimizer, lr_scheduler, logger, model_ema=None):\n    logger.info(f\"==============> Resuming form {config.MODEL.RESUME}....................\")\n    if config.MODEL.RESUME.startswith('https'):\n        checkpoint = torch.hub.load_state_dict_from_url(\n            config.MODEL.RESUME, map_location='cpu', check_hash=True)\n    else:\n        checkpoint = torch.load(config.MODEL.RESUME, map_location='cpu')\n    msg = model.load_state_dict(checkpoint['model'], strict=False)\n    logger.info(msg)\n    max_accuracy = 0.0\n    if not config.EVAL_MODE and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n        optimizer.load_state_dict(checkpoint['optimizer'])\n        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n        config.defrost()\n        config.TRAIN.START_EPOCH = checkpoint['epoch'] + 1\n        config.freeze()\n        if 'amp' in checkpoint and config.AMP_OPT_LEVEL != \"O0\" and checkpoint['config'].AMP_OPT_LEVEL != \"O0\":\n            amp.load_state_dict(checkpoint['amp'])\n        logger.info(f\"=> loaded successfully '{config.MODEL.RESUME}' (epoch {checkpoint['epoch']})\")\n        if 'max_accuracy' in checkpoint:\n            max_accuracy = checkpoint['max_accuracy']\n    if model_ema is not None:\n        unwrap_model(model_ema).load_state_dict(checkpoint['ema'])\n        print('=================================================== EMAloaded')\n\n    del checkpoint\n    torch.cuda.empty_cache()\n    return max_accuracy\n\n\ndef load_weights(model, path):\n    checkpoint = torch.load(path, map_location='cpu')\n    if 'model' in checkpoint:\n        checkpoint = checkpoint['model']\n    if 'state_dict' in checkpoint:\n        checkpoint = checkpoint['state_dict']\n    unwrap_model(model).load_state_dict(checkpoint, strict=False)\n    print('=================== loaded from', path)\n\ndef save_latest(config, epoch, model, max_accuracy, optimizer, lr_scheduler, logger, model_ema=None):\n    save_state = {'model': model.state_dict(),\n                  'optimizer': optimizer.state_dict(),\n                  'lr_scheduler': lr_scheduler.state_dict(),\n                  'max_accuracy': max_accuracy,\n                  'epoch': epoch,\n                  'config': config}\n    if config.AMP_OPT_LEVEL != \"O0\":\n        save_state['amp'] = amp.state_dict()\n    if model_ema is not None:\n        save_state['ema'] = unwrap_model(model_ema).state_dict()\n\n    save_path = os.path.join(config.OUTPUT, 'latest.pth')\n    logger.info(f\"{save_path} saving......\")\n    torch.save(save_state, save_path)\n    logger.info(f\"{save_path} saved !!!\")\n\ndef save_checkpoint(config, epoch, model, max_accuracy, optimizer, lr_scheduler, logger, is_best=False, model_ema=None):\n    save_state = {'model': model.state_dict(),\n                  'optimizer': optimizer.state_dict(),\n                  'lr_scheduler': lr_scheduler.state_dict(),\n                  'max_accuracy': max_accuracy,\n                  'epoch': epoch,\n                  'config': config}\n    if config.AMP_OPT_LEVEL != \"O0\":\n        save_state['amp'] = amp.state_dict()\n    if model_ema is not None:\n        save_state['ema'] = unwrap_model(model_ema).state_dict()\n\n    if is_best:\n        best_path = os.path.join(config.OUTPUT, 'best_ckpt.pth')\n        torch.save(save_state, best_path)\n\n    save_path = os.path.join(config.OUTPUT, f'ckpt_epoch_{epoch}.pth')\n    logger.info(f\"{save_path} saving......\")\n    torch.save(save_state, save_path)\n    logger.info(f\"{save_path} saved !!!\")\n\n\ndef get_grad_norm(parameters, norm_type=2):\n    if isinstance(parameters, torch.Tensor):\n        parameters = [parameters]\n    parameters = list(filter(lambda p: p.grad is not None, parameters))\n    norm_type = float(norm_type)\n    total_norm = 0\n    for p in parameters:\n        param_norm = p.grad.data.norm(norm_type)\n        total_norm += param_norm.item() ** norm_type\n    total_norm = total_norm ** (1. / norm_type)\n    return total_norm\n\n\nimport torch.distributed as dist\n\ndef auto_resume_helper(output_dir):\n    checkpoints = os.listdir(output_dir)\n    checkpoints = [ckpt for ckpt in checkpoints if ckpt.endswith('pth') and 'ema' not in ckpt]\n    print(f\"All checkpoints founded in {output_dir}: {checkpoints}\")\n    if len(checkpoints) > 0:\n        latest_checkpoint = max([os.path.join(output_dir, d) for d in checkpoints], key=os.path.getmtime)\n        print(f\"The latest checkpoint founded: {latest_checkpoint}\")\n        resume_file = latest_checkpoint\n    else:\n        resume_file = None\n    return resume_file\n\n\ndef reduce_tensor(tensor):\n    rt = tensor.clone()\n    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n    rt /= dist.get_world_size()\n    return rt\n\ndef update_model_ema(cfg, num_gpus, model, model_ema, cur_epoch, cur_iter):\n    \"\"\"Update exponential moving average (ema) of model weights.\"\"\"\n    update_period = cfg.TRAIN.EMA_UPDATE_PERIOD\n    if update_period is None or update_period == 0 or cur_iter % update_period != 0:\n        return\n    # Adjust alpha to be fairly independent of other parameters\n    total_batch_size = num_gpus * cfg.DATA.BATCH_SIZE\n    adjust = total_batch_size / cfg.TRAIN.EPOCHS * update_period\n    # print('ema adjust', adjust)\n    alpha = min(1.0, cfg.TRAIN.EMA_ALPHA * adjust)\n    # During warmup simply copy over weights instead of using ema\n    alpha = 1.0 if cur_epoch < cfg.TRAIN.WARMUP_EPOCHS else alpha\n    # Take ema of all parameters (not just named parameters)\n    params = unwrap_model(model).state_dict()\n    for name, param in unwrap_model(model_ema).state_dict().items():\n        param.copy_(param * (1.0 - alpha) + params[name] * alpha)"
        }
      ]
    }
  ]
}