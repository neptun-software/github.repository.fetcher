{
  "metadata": {
    "timestamp": 1736559654907,
    "page": 315,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjMyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "cirosantilli/linux-kernel-module-cheat",
      "stars": 4236,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.099609375,
          "content": "# Ignore everything, since we get the repository files\n# with a volume.\n*\n.*\n!requirements.txt\n!setup\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.61328125,
          "content": "# Important directories.\n/out\n# https://cirosantilli.com/linux-kernel-module-cheat#docker\n/out.docker\n/data\n\n# Temporary files.\n*.tmp\ntmp.*\n*.tmp.*\n*~\n*.gitignore\ngitignore.*\n\n# https://cirosantilli.com/linux-kernel-module-cheat#prebuilt\n/lkmc-*.zip\n\n# https://cirosantilli.com/linux-kernel-module-cheat#bst-vs-heap-vs-hashmap\n*.dat\n\n# Python trash.\n*.pyc\n__pycache__\n.venv\n\n# Accidents.\n/core\n/m5out\n\n# In-tree userland builds.\n*.o\n*.out\n*.so\n\n# Kernel modules.\n*.ko\n*.ko.cmd\n*.mod.c\n*.o.cmd\n.cache.mk\n.tmp_versions\nModule.symvers\nmodules.order\n\n# node.js\nnode_modules\n\n# Performance profiling stuff.\nperf.data\ncallgrind.out.*\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 1.833984375,
          "content": "[submodule \"submodules/boot-wrapper-aarch64\"]\n\tpath = submodules/boot-wrapper-aarch64\n\turl = git://git.kernel.org/pub/scm/linux/kernel/git/mark/boot-wrapper-aarch64.git\n[submodule \"submodules/binutils-gdb\"]\n\tpath = submodules/binutils-gdb\n\turl = https://github.com/cirosantilli/binutils-gdb\n[submodule \"submodules/buildroot\"]\n\tpath = submodules/buildroot\n\turl = https://github.com/cirosantilli/buildroot\n\tignore = dirty\n[submodule \"submodules/crosstool-ng\"]\n\tpath = submodules/crosstool-ng\n\turl = https://github.com/cirosantilli/crosstool-ng\n[submodule \"submodules/freebsd\"]\n\tpath = submodules/freebsd\n\turl = https://github.com/cirosantilli/freebsd\n[submodule \"submodules/gcc\"]\n\tpath = submodules/gcc\n\turl = https://github.com/cirosantilli/gcc\n[submodule \"submodules/gem5\"]\n\tpath = submodules/gem5\n\turl = https://github.com/cirosantilli/gem5\n[submodule \"submodules/gem5-resources\"]\n\tpath = submodules/gem5-resources\n\turl = https://gem5.googlesource.com/public/gem5-resources\n[submodule \"submodules/gensim\"]\n\tpath = submodules/gensim\n\turl = https://github.com/cirosantilli/gensim\n[submodule \"submodules/glibc\"]\n\tpath = submodules/glibc\n\turl = https://github.com/cirosantilli/glibc\n# The true upstream does not accept git submodule update --init --depth 1\n# git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git\n# But git clone --branch --depth 1 worked weirdly:\n# https://unix.stackexchange.com/questions/338578/linux-kernel-source-code-size-difference\n[submodule \"submodules/googletest\"]\n\tpath = submodules/googletest\n\turl = https://github.com/cirosantilli/googletest\n[submodule \"submodules/linux\"]\n\tpath = submodules/linux\n\turl = https://github.com/cirosantilli/linux\n[submodule \"submodules/qemu\"]\n\tpath = submodules/qemu\n\turl = https://github.com/cirosantilli/qemu\n[submodule \"submodules/xen\"]\n\tpath = submodules/xen\n\turl = https://github.com/cirosantilli/xen\n"
        },
        {
          "name": ".travis.yml",
          "type": "blob",
          "size": 0.3857421875,
          "content": "# https://cirosantilli.com/linux-kernel-module-cheat#travis\n\nlanguage: cpp\n\nsudo: required\n\nscript: |\n  cd \"$TRAVIS_BUILD_DIR\"\n  # awk: without it, too much stdout (4Mb max)\n  # If we ignore stdout: Travis kills job because it spent\n  # too long without any new stdout.\n  bash -x ./build --download-dependencies --travis |& awk 'NR % 1000 == 0'\n  bash -x ./run --kernel-cli 'init=/poweroff.out'\n"
        },
        {
          "name": "CONTRIBUTING.adoc",
          "type": "blob",
          "size": 0.0517578125,
          "content": "= CONTRIBUTING\n\nSee: link:README.adoc#contributing[]\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 0.134765625,
          "content": "# https://cirosantilli.com/linux-kernel-module-cheat#docker\nFROM ubuntu:20.04\nCOPY setup /\nCOPY requirements.txt /\nRUN /setup -y\nCMD bash\n"
        },
        {
          "name": "Gemfile",
          "type": "blob",
          "size": 0.1357421875,
          "content": "source 'https://rubygems.org'\n\ngem 'asciidoctor', '2.0.11'\ngem 'asciidoctor-multipage', '0.0.12'\n#gem 'jekyll', '3.8.6'\ngem 'github-pages'\n"
        },
        {
          "name": "Gemfile.lock",
          "type": "blob",
          "size": 7.220703125,
          "content": "GEM\n  remote: https://rubygems.org/\n  specs:\n    activesupport (7.0.4.3)\n      concurrent-ruby (~> 1.0, >= 1.0.2)\n      i18n (>= 1.6, < 2)\n      minitest (>= 5.1)\n      tzinfo (~> 2.0)\n    addressable (2.8.4)\n      public_suffix (>= 2.0.2, < 6.0)\n    asciidoctor (2.0.11)\n    asciidoctor-multipage (0.0.12)\n      asciidoctor (>= 2.0.11, < 2.1)\n    coffee-script (2.4.1)\n      coffee-script-source\n      execjs\n    coffee-script-source (1.11.1)\n    colorator (1.1.0)\n    commonmarker (0.23.9)\n    concurrent-ruby (1.2.2)\n    dnsruby (1.70.0)\n      simpleidn (~> 0.2.1)\n    em-websocket (0.5.3)\n      eventmachine (>= 0.12.9)\n      http_parser.rb (~> 0)\n    ethon (0.16.0)\n      ffi (>= 1.15.0)\n    eventmachine (1.2.7)\n    execjs (2.8.1)\n    faraday (2.7.4)\n      faraday-net_http (>= 2.0, < 3.1)\n      ruby2_keywords (>= 0.0.4)\n    faraday-net_http (3.0.2)\n    ffi (1.15.5)\n    forwardable-extended (2.6.0)\n    gemoji (3.0.1)\n    github-pages (228)\n      github-pages-health-check (= 1.17.9)\n      jekyll (= 3.9.3)\n      jekyll-avatar (= 0.7.0)\n      jekyll-coffeescript (= 1.1.1)\n      jekyll-commonmark-ghpages (= 0.4.0)\n      jekyll-default-layout (= 0.1.4)\n      jekyll-feed (= 0.15.1)\n      jekyll-gist (= 1.5.0)\n      jekyll-github-metadata (= 2.13.0)\n      jekyll-include-cache (= 0.2.1)\n      jekyll-mentions (= 1.6.0)\n      jekyll-optional-front-matter (= 0.3.2)\n      jekyll-paginate (= 1.1.0)\n      jekyll-readme-index (= 0.3.0)\n      jekyll-redirect-from (= 0.16.0)\n      jekyll-relative-links (= 0.6.1)\n      jekyll-remote-theme (= 0.4.3)\n      jekyll-sass-converter (= 1.5.2)\n      jekyll-seo-tag (= 2.8.0)\n      jekyll-sitemap (= 1.4.0)\n      jekyll-swiss (= 1.0.0)\n      jekyll-theme-architect (= 0.2.0)\n      jekyll-theme-cayman (= 0.2.0)\n      jekyll-theme-dinky (= 0.2.0)\n      jekyll-theme-hacker (= 0.2.0)\n      jekyll-theme-leap-day (= 0.2.0)\n      jekyll-theme-merlot (= 0.2.0)\n      jekyll-theme-midnight (= 0.2.0)\n      jekyll-theme-minimal (= 0.2.0)\n      jekyll-theme-modernist (= 0.2.0)\n      jekyll-theme-primer (= 0.6.0)\n      jekyll-theme-slate (= 0.2.0)\n      jekyll-theme-tactile (= 0.2.0)\n      jekyll-theme-time-machine (= 0.2.0)\n      jekyll-titles-from-headings (= 0.5.3)\n      jemoji (= 0.12.0)\n      kramdown (= 2.3.2)\n      kramdown-parser-gfm (= 1.1.0)\n      liquid (= 4.0.4)\n      mercenary (~> 0.3)\n      minima (= 2.5.1)\n      nokogiri (>= 1.13.6, < 2.0)\n      rouge (= 3.26.0)\n      terminal-table (~> 1.4)\n    github-pages-health-check (1.17.9)\n      addressable (~> 2.3)\n      dnsruby (~> 1.60)\n      octokit (~> 4.0)\n      public_suffix (>= 3.0, < 5.0)\n      typhoeus (~> 1.3)\n    html-pipeline (2.14.3)\n      activesupport (>= 2)\n      nokogiri (>= 1.4)\n    http_parser.rb (0.8.0)\n    i18n (1.13.0)\n      concurrent-ruby (~> 1.0)\n    jekyll (3.9.3)\n      addressable (~> 2.4)\n      colorator (~> 1.0)\n      em-websocket (~> 0.5)\n      i18n (>= 0.7, < 2)\n      jekyll-sass-converter (~> 1.0)\n      jekyll-watch (~> 2.0)\n      kramdown (>= 1.17, < 3)\n      liquid (~> 4.0)\n      mercenary (~> 0.3.3)\n      pathutil (~> 0.9)\n      rouge (>= 1.7, < 4)\n      safe_yaml (~> 1.0)\n    jekyll-avatar (0.7.0)\n      jekyll (>= 3.0, < 5.0)\n    jekyll-coffeescript (1.1.1)\n      coffee-script (~> 2.2)\n      coffee-script-source (~> 1.11.1)\n    jekyll-commonmark (1.4.0)\n      commonmarker (~> 0.22)\n    jekyll-commonmark-ghpages (0.4.0)\n      commonmarker (~> 0.23.7)\n      jekyll (~> 3.9.0)\n      jekyll-commonmark (~> 1.4.0)\n      rouge (>= 2.0, < 5.0)\n    jekyll-default-layout (0.1.4)\n      jekyll (~> 3.0)\n    jekyll-feed (0.15.1)\n      jekyll (>= 3.7, < 5.0)\n    jekyll-gist (1.5.0)\n      octokit (~> 4.2)\n    jekyll-github-metadata (2.13.0)\n      jekyll (>= 3.4, < 5.0)\n      octokit (~> 4.0, != 4.4.0)\n    jekyll-include-cache (0.2.1)\n      jekyll (>= 3.7, < 5.0)\n    jekyll-mentions (1.6.0)\n      html-pipeline (~> 2.3)\n      jekyll (>= 3.7, < 5.0)\n    jekyll-optional-front-matter (0.3.2)\n      jekyll (>= 3.0, < 5.0)\n    jekyll-paginate (1.1.0)\n    jekyll-readme-index (0.3.0)\n      jekyll (>= 3.0, < 5.0)\n    jekyll-redirect-from (0.16.0)\n      jekyll (>= 3.3, < 5.0)\n    jekyll-relative-links (0.6.1)\n      jekyll (>= 3.3, < 5.0)\n    jekyll-remote-theme (0.4.3)\n      addressable (~> 2.0)\n      jekyll (>= 3.5, < 5.0)\n      jekyll-sass-converter (>= 1.0, <= 3.0.0, != 2.0.0)\n      rubyzip (>= 1.3.0, < 3.0)\n    jekyll-sass-converter (1.5.2)\n      sass (~> 3.4)\n    jekyll-seo-tag (2.8.0)\n      jekyll (>= 3.8, < 5.0)\n    jekyll-sitemap (1.4.0)\n      jekyll (>= 3.7, < 5.0)\n    jekyll-swiss (1.0.0)\n    jekyll-theme-architect (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-cayman (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-dinky (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-hacker (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-leap-day (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-merlot (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-midnight (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-minimal (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-modernist (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-primer (0.6.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-github-metadata (~> 2.9)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-slate (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-tactile (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-theme-time-machine (0.2.0)\n      jekyll (> 3.5, < 5.0)\n      jekyll-seo-tag (~> 2.0)\n    jekyll-titles-from-headings (0.5.3)\n      jekyll (>= 3.3, < 5.0)\n    jekyll-watch (2.2.1)\n      listen (~> 3.0)\n    jemoji (0.12.0)\n      gemoji (~> 3.0)\n      html-pipeline (~> 2.2)\n      jekyll (>= 3.0, < 5.0)\n    kramdown (2.3.2)\n      rexml\n    kramdown-parser-gfm (1.1.0)\n      kramdown (~> 2.0)\n    liquid (4.0.4)\n    listen (3.8.0)\n      rb-fsevent (~> 0.10, >= 0.10.3)\n      rb-inotify (~> 0.9, >= 0.9.10)\n    mercenary (0.3.6)\n    minima (2.5.1)\n      jekyll (>= 3.5, < 5.0)\n      jekyll-feed (~> 0.9)\n      jekyll-seo-tag (~> 2.1)\n    minitest (5.18.0)\n    nokogiri (1.14.3-x86_64-linux)\n      racc (~> 1.4)\n    octokit (4.25.1)\n      faraday (>= 1, < 3)\n      sawyer (~> 0.9)\n    pathutil (0.16.2)\n      forwardable-extended (~> 2.6)\n    public_suffix (4.0.7)\n    racc (1.6.2)\n    rb-fsevent (0.11.2)\n    rb-inotify (0.10.1)\n      ffi (~> 1.0)\n    rexml (3.2.5)\n    rouge (3.26.0)\n    ruby2_keywords (0.0.5)\n    rubyzip (2.3.2)\n    safe_yaml (1.0.5)\n    sass (3.7.4)\n      sass-listen (~> 4.0.0)\n    sass-listen (4.0.0)\n      rb-fsevent (~> 0.9, >= 0.9.4)\n      rb-inotify (~> 0.9, >= 0.9.7)\n    sawyer (0.9.2)\n      addressable (>= 2.3.5)\n      faraday (>= 0.17.3, < 3)\n    simpleidn (0.2.1)\n      unf (~> 0.1.4)\n    terminal-table (1.8.0)\n      unicode-display_width (~> 1.1, >= 1.1.1)\n    typhoeus (1.4.0)\n      ethon (>= 0.9.0)\n    tzinfo (2.0.6)\n      concurrent-ruby (~> 1.0)\n    unf (0.1.4)\n      unf_ext\n    unf_ext (0.0.8.2)\n    unicode-display_width (1.8.0)\n\nPLATFORMS\n  x86_64-linux\n\nDEPENDENCIES\n  asciidoctor (= 2.0.11)\n  asciidoctor-multipage (= 0.0.12)\n  github-pages\n\nBUNDLED WITH\n   2.3.15\n"
        },
        {
          "name": "LICENSE.txt",
          "type": "blob",
          "size": 34.3232421875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    <one line to give the program's name and a brief idea of what it does.>\n    Copyright (C) <year>  <name of author>\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    <program>  Copyright (C) <year>  <name of author>\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n"
        },
        {
          "name": "README.adoc",
          "type": "blob",
          "size": 1056.9169921875,
          "content": "= Linux Kernel Module Cheat\n:cirosantilli-media-base: https://raw.githubusercontent.com/cirosantilli/media/master/\n:description: The perfect emulation setup to study and develop the <<linux-kernel>> v5.9.2, kernel modules, <<qemu-buildroot-setup,QEMU>>, <<gem5-buildroot-setup,gem5>> and x86_64, ARMv7 and ARMv8 <<userland-assembly,userland>> and <<baremetal-setup,baremetal>> assembly, <<c,ANSI C>>, <<cpp,C++>> and <<posix,POSIX>>. <<gdb>> and <<kgdb>> just work. Powered by <<about-the-qemu-buildroot-setup,Buildroot>> and <<about-the-baremetal-setup,crosstool-NG>>. Highly automated. Thoroughly documented. Automated <<test-this-repo,tests>>. \"Tested\" in an Ubuntu 20.04 host.\n:idprefix:\n:idseparator: -\n:nofooter:\n:sectanchors:\n:sectlinks:\n:sectnumlevels: 6\n:sectnums:\n:toc-title:\n:toc: macro\n:toclevels: 6\n\nhttps://zenodo.org/badge/latestdoi/64534859[image:https://zenodo.org/badge/64534859.svg[]]\n\n{description}\n\nhttps://twitter.com/dakami/status/1344853681749934080[Dan Kaminski-approved]™ https://en.wikipedia.org/wiki/Dan_Kaminsky[RIP].\n\nTL;DR: xref:qemu-buildroot-setup-getting-started[xrefstyle=full] tested on Ubuntu 24.04:\n\n....\ngit clone https://github.com/cirosantilli/linux-kernel-module-cheat\ncd linux-kernel-module-cheat\nsudo apt install docker\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./run-docker create\n./run-docker sh\n....\n\nThis leaves you inside a Docker shell. Then inside Docker:\n\n....\n./build --download-dependencies qemu-buildroot\n./run\n....\n\nand you are now in a Linux userland shell running on QEMU with everything built fully from source.\n\nThe source code for this page is located at: https://github.com/cirosantilli/linux-kernel-module-cheat[]. Due to https://github.com/isaacs/github/issues/1610[a GitHub limitation], this README is too long and not fully rendered on github.com, so either use:\n\n* https://cirosantilli.com/linux-kernel-module-cheat\n* https://cirosantilli.com/linux-kernel-module-cheat/index-split[]: split header version\n* <<build-the-documentation,build the docs yourself>>\n\nhttps://github.com/cirosantilli/china-dictatorship | https://cirosantilli.com/china-dictatorship/xinjiang\n\nimage::https://raw.githubusercontent.com/cirosantilli/china-dictatorship-media/master/Xinjiang_prisoners_sitting_identified.jpeg[width=800]\n\ntoc::[]\n\n== `--china`\n\nThe most important functionality of this repository is the `--china` option, sample usage:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./run --china > index.html\nfirefox index.html\n....\n\nsee also: https://cirosantilli.com/china-dictatorship/mirrors\n\nThe secondary systems programming functionality is described on the sections below starting from <<getting-started>>.\n\nimage::https://raw.githubusercontent.com/cirosantilli/china-dictatorship-media/master/Tiananmen_cute_girls.jpg[width=800]\n\n== Getting started\n\nEach child section describes a possible different setup for this repo.\n\nIf you don't know which one to go for, start with <<qemu-buildroot-setup-getting-started>>.\n\nDesign goals of this project are documented at: xref:design-goals[xrefstyle=full].\n\n=== Should you waste your life with systems programming?\n\nBeing the hardcore person who fully understands an important complex system such as a computer, it does have a nice ring to it doesn't it?\n\nBut before you dedicate your life to this nonsense, do consider the following points:\n\n* almost all contributions to the kernel are done by large companies, and if you are not an employee in one of them, you are likely not going to be able to do much.\n+\nThis can be inferred by the fact that the `devices/` directory is by far the largest in the kernel.\n+\nThe kernel is of course just an interface to hardware, and the hardware developers start developing their kernel stuff even before specs are publicly released, both to help with hardware development and to have things working when the announcement is made.\n+\nFurthermore, I believe that there are in-tree devices which have never been properly publicly documented. Linus is of course fine with this, since code == documentation for him, but it is not as easy for mere mortals.\n+\nThere are some less hardware bound higher level layers in the kernel which might not require being in a hardware company, and a few people must be living off it.\n+\nBut of course, those are heavily motivated by the underlying hardware characteristics, and it is very likely that most of the people working there were previously at a hardware company.\n+\nIn that sense, therefore, the kernel is not as open as one might want to believe.\n+\nOf course, if there is some https://stackoverflow.com/questions/1697842/do-graphic-cards-have-instruction-sets-of-their-own/1697883[super useful and undocumented hardware that is just waiting there to be reverse engineered], then that's a much juicier target :-)\n* it is impossible to become rich with this knowledge.\n+\nThis is partly implied by the fact that you need to be in a big company to make useful low level things, and therefore you will only be a tiny cog in the engine.\n+\nThe key problem is that the entry cost of hardware design is just too insanely high for startups in general.\n* Is learning this the most useful thing that you think can do for society?\n+\nOr are you just learning it for job security and having a nice sounding title?\n+\nI'm not a huge fan of the person, but I think Jobs said it right: https://www.youtube.com/watch?v=FF-tKLISfPE\n+\nFirst determine the useful goal, and then backtrack down to the most efficient thing you can do to reach it.\n* there are two things that sadden me compared to physics-based engineering:\n+\n--\n** you will never become eternally famous. All tech disappears sooner or later, while laws of nature, at least as useful approximations, stay unchanged.\n** every problem that you face is caused by imperfections introduced by other humans.\n+\nIt is much easier to accept limitations of physics, and even natural selection in biology, which are not produced by a sentient being (?).\n--\n+\nPhysics-based engineering, just like low level hardware, is of course completely closed source however, since wrestling against the laws of physics is about the most expensive thing humans can do, so there's also a downside to it.\n\nAre you fine with those points, and ready to continue wasting your life with this crap?\n\nGood. In that case, read on, and let's have some fun together ;-)\n\nRelated: <<soft-topics>>.\n\n=== QEMU Buildroot setup\n\n==== QEMU Buildroot setup getting started\n\nThis setup has been tested on Ubuntu 20.04.\n\nThe Buildroot build is already broken on Ubuntu 21.04 onwards: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/155[], so just do this from inside a 20.04 Docker instead as shown in the <<docker>> setup. We could fix the build on Ubuntu 21.04, but it will break again inevitably later on.\n\nFor other host operating systems see: xref:supported-hosts[xrefstyle=full].\n\nReserve 12Gb of disk and run:\n\n....\ngit clone https://github.com/cirosantilli/linux-kernel-module-cheat\ncd linux-kernel-module-cheat\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies qemu-buildroot\n./run\n....\n\nYou don't need to clone recursively even though we have `.git` submodules: `download-dependencies` fetches just the submodules that you need for this build to save time.\n\nIf something goes wrong, see: xref:common-build-issues[xrefstyle=full] and use our issue tracker: https://github.com/cirosantilli/linux-kernel-module-cheat/issues\n\nThe initial build will take a while (30 minutes to 2 hours) to clone and build, see <<benchmark-builds>> for more details.\n\nIf you don't want to wait, you could also try the following faster but much more limited methods:\n\n* <<prebuilt>>\n* <<host>>\n\nbut you will soon find that they are simply not enough if you anywhere near serious about systems programming.\n\nAfter `./run`, QEMU opens up leaving you in the <<lkmc-home,`/lkmc/` directory>>, and you can start playing with the kernel modules inside the simulated system:\n\n....\ninsmod hello.ko\ninsmod hello2.ko\nrmmod hello\nrmmod hello2\n....\n\nThis should print to the screen:\n\n....\nhello init\nhello2 init\nhello cleanup\nhello2 cleanup\n....\n\nwhich are `printk` messages from `init` and `cleanup` methods of those modules.\n\nSources:\n\n* link:kernel_modules/hello.c[]\n* link:kernel_modules/hello2.c[]\n\nQuit QEMU with:\n\n....\nCtrl-A X\n....\n\nSee also: xref:quit-qemu-from-text-mode[xrefstyle=full].\n\nAll available modules can be found in the link:kernel_modules[] directory.\n\nIt is super easy to build for different <<cpu-architecture,CPU architectures>>, just use the `--arch` option:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --arch aarch64 --download-dependencies qemu-buildroot\n./run --arch aarch64\n....\n\nTo avoid typing `--arch aarch64` many times, you can set the default arch as explained at: xref:default-command-line-arguments[xrefstyle=full]\n\nI now urge you to read the following sections which contain widely applicable information:\n\n* <<run-command-after-boot>>\n* <<clean-the-build>>\n* <<build-the-documentation>>\n* Linux kernel\n** <<printk>>\n** <<kernel-command-line-parameters>>\n\nOnce you use <<gdb>> and <<tmux>>, your terminal will look a bit like this:\n\n....\n[    1.451857] input: AT Translated Set 2 keyboard as /devices/platform/i8042/s1│loading @0xffffffffc0000000: ../kernel_modules-1.0//timer.ko\n[    1.454310] ledtrig-cpu: registered to indicate activity on CPUs             │(gdb) b lkmc_timer_callback\n[    1.455621] usbcore: registered new interface driver usbhid                  │Breakpoint 1 at 0xffffffffc0000000: file /home/ciro/bak/git/linux-kernel-module\n[    1.455811] usbhid: USB HID core driver                                      │-cheat/out/x86_64/buildroot/build/kernel_modules-1.0/./timer.c, line 28.\n[    1.462044] NET: Registered protocol family 10                               │(gdb) c\n[    1.467911] Segment Routing with IPv6                                        │Continuing.\n[    1.468407] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver              │\n[    1.470859] NET: Registered protocol family 17                               │Breakpoint 1, lkmc_timer_callback (data=0xffffffffc0002000 <mytimer>)\n[    1.472017] 9pnet: Installing 9P2000 support                                 │    at /linux-kernel-module-cheat//out/x86_64/buildroot/build/\n[    1.475461] sched_clock: Marking stable (1473574872, 0)->(1554017593, -80442)│kernel_modules-1.0/./timer.c:28\n[    1.479419] ALSA device list:                                                │28      {\n[    1.479567]   No soundcards found.                                           │(gdb) c\n[    1.619187] ata2.00: ATAPI: QEMU DVD-ROM, 2.5+, max UDMA/100                 │Continuing.\n[    1.622954] ata2.00: configured for MWDMA2                                   │\n[    1.644048] scsi 1:0:0:0: CD-ROM            QEMU     QEMU DVD-ROM     2.5+ P5│Breakpoint 1, lkmc_timer_callback (data=0xffffffffc0002000 <mytimer>)\n[    1.741966] tsc: Refined TSC clocksource calibration: 2904.010 MHz           │    at /linux-kernel-module-cheat//out/x86_64/buildroot/build/\n[    1.742796] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x29dc0f4s│kernel_modules-1.0/./timer.c:28\n[    1.743648] clocksource: Switched to clocksource tsc                         │28      {\n[    2.072945] input: ImExPS/2 Generic Explorer Mouse as /devices/platform/i8043│(gdb) bt\n[    2.078641] EXT4-fs (vda): couldn't mount as ext3 due to feature incompatibis│#0  lkmc_timer_callback (data=0xffffffffc0002000 <mytimer>)\n[    2.080350] EXT4-fs (vda): mounting ext2 file system using the ext4 subsystem│    at /linux-kernel-module-cheat//out/x86_64/buildroot/build/\n[    2.088978] EXT4-fs (vda): mounted filesystem without journal. Opts: (null)  │kernel_modules-1.0/./timer.c:28\n[    2.089872] VFS: Mounted root (ext2 filesystem) readonly on device 254:0.    │#1  0xffffffff810ab494 in call_timer_fn (timer=0xffffffffc0002000 <mytimer>,\n[    2.097168] devtmpfs: mounted                                                │    fn=0xffffffffc0000000 <lkmc_timer_callback>) at kernel/time/timer.c:1326\n[    2.126472] Freeing unused kernel memory: 1264K                              │#2  0xffffffff810ab71f in expire_timers (head=<optimized out>,\n[    2.126706] Write protecting the kernel read-only data: 16384k               │    base=<optimized out>) at kernel/time/timer.c:1363\n[    2.129388] Freeing unused kernel memory: 2024K                              │#3  __run_timers (base=<optimized out>) at kernel/time/timer.c:1666\n[    2.139370] Freeing unused kernel memory: 1284K                              │#4  run_timer_softirq (h=<optimized out>) at kernel/time/timer.c:1692\n[    2.246231] EXT4-fs (vda): warning: mounting unchecked fs, running e2fsck isd│#5  0xffffffff81a000cc in __do_softirq () at kernel/softirq.c:285\n[    2.259574] EXT4-fs (vda): re-mounted. Opts: block_validity,barrier,user_xatr│#6  0xffffffff810577cc in invoke_softirq () at kernel/softirq.c:365\nhello S98                                                                       │#7  irq_exit () at kernel/softirq.c:405\n                                                                                │#8  0xffffffff818021ba in exiting_irq () at ./arch/x86/include/asm/apic.h:541\nApr 15 23:59:23 login[49]: root login on 'console'                              │#9  smp_apic_timer_interrupt (regs=<optimized out>)\nhello /root/.profile                                                            │    at arch/x86/kernel/apic/apic.c:1052\n# insmod /timer.ko                                                              │#10 0xffffffff8180190f in apic_timer_interrupt ()\n[    6.791945] timer: loading out-of-tree module taints kernel.                 │    at arch/x86/entry/entry_64.S:857\n# [    7.821621] 4294894248                                                     │#11 0xffffffff82003df8 in init_thread_union ()\n[    8.851385] 4294894504                                                       │#12 0x0000000000000000 in ?? ()\n                                                                                │(gdb)\n....\n\n==== How to hack stuff\n\nBesides a seamless <<qemu-buildroot-setup-getting-started,initial build>>, this project also aims to make it effortless to modify and rebuild several major components of the system, to serve as an awesome development setup.\n\n===== Your first Linux kernel hack\n\nLet's hack up the <<linux-kernel-entry-point, Linux kernel entry point>>, which is an easy place to start.\n\nOpen the file:\n\n....\nvim submodules/linux/init/main.c\n....\n\nand find the `start_kernel` function, then add there a:\n\n....\npr_info(\"I'VE HACKED THE LINUX KERNEL!!!\");\n....\n\nThen rebuild the Linux kernel, quit QEMU and reboot the modified kernel:\n\n....\n./build-linux\n./run\n....\n\nand, surely enough, your message has appeared at the beginning of the boot:\n\n....\n<6>[    0.000000] I'VE HACKED THE LINUX KERNEL!!!\n....\n\nSo you are now officially a Linux kernel hacker, way to go!\n\nWe could have used just link:build[] to rebuild the kernel as in the <<qemu-buildroot-setup-getting-started,initial build>> instead of link:build-linux[], but building just the required individual components is preferred during development:\n\n* saves a few seconds from parsing Make scripts and reading timestamps\n* makes it easier to understand what is being done in more detail\n* allows passing more specific options to customize the build\n\nThe link:build[] script is just a lightweight wrapper that calls the smaller build scripts, and you can see what `./build` does with:\n\n....\n./build --dry-run\n....\n\nsee also: <<dry-run>>.\n\nWhen you reach difficulties, QEMU makes it possible to easily GDB step debug the Linux kernel source code, see: xref:gdb[xrefstyle=full].\n\n===== Your first kernel module hack\n\nEdit link:kernel_modules/hello.c[] to contain:\n\n....\npr_info(\"hello init hacked\\n\");\n....\n\nand rebuild with:\n\n....\n./build-modules\n....\n\nNow there are two ways to test it out: the fast way, and the safe way.\n\nThe fast way is, without quitting or rebooting QEMU, just directly re-insert the module with:\n\n....\ninsmod /mnt/9p/out_rootfs_overlay/lkmc/hello.ko\n....\n\nand the new `pr_info` message should now show on the terminal at the end of the boot.\n\nThis works because we have a <<9p>> mount there setup by default, which mounts the host directory that contains the build outputs on the guest:\n\n....\nls \"$(./getvar out_rootfs_overlay_dir)\"\n....\n\nThe fast method is slightly risky because your previously insmodded buggy kernel module attempt might have corrupted the kernel memory, which could affect future runs.\n\nSuch failures are however unlikely, and you should be fine if you don't see anything weird happening.\n\nThe safe way, is to fist <<rebuild-buildroot-while-running,quit QEMU>>, rebuild the modules, put them in the root filesystem, and then reboot:\n\n....\n./build-modules\n./build-buildroot\n./run --eval-after 'insmod hello.ko'\n....\n\n`./build-buildroot` is required after `./build-modules` because it re-generates the root filesystem with the modules that we compiled at `./build-modules`.\n\nYou can see that `./build` does that as well, by running:\n\n....\n./build --dry-run\n....\n\nSee also: <<dry-run>>.\n\n`--eval-after` is optional: you could just type `insmod hello.ko` in the terminal, but this makes it run automatically at the end of boot, and then drops you into a shell.\n\nIf the guest and host are the same arch, typically x86_64, you can speed up boot further with <<kvm>>:\n\n....\n./run --kvm\n....\n\nAll of this put together makes the safe procedure acceptably fast for regular development as well.\n\nIt is also easy to GDB step debug kernel modules with our setup, see: xref:gdb-step-debug-kernel-module[xrefstyle=full].\n\n===== Your first glibc hack\n\nWe use <<libc-choice,glibc as our default libc now>>, and it is tracked as an unmodified submodule at link:submodules/glibc[], at the exact same version that Buildroot has it, which can be found at: https://github.com/buildroot/buildroot/blob/2018.05/package/glibc/glibc.mk#L13[package/glibc/glibc.mk]. Buildroot 2018.05 applies no patches.\n\nLet's hack up the `puts` function:\n\n....\n./build-buildroot -- glibc-reconfigure\n....\n\nwith the patch:\n\n....\ndiff --git a/libio/ioputs.c b/libio/ioputs.c\nindex 706b20b492..23185948f3 100644\n--- a/libio/ioputs.c\n+++ b/libio/ioputs.c\n@@ -38,8 +38,9 @@ _IO_puts (const char *str)\n   if ((_IO_vtable_offset (_IO_stdout) != 0\n        || _IO_fwide (_IO_stdout, -1) == -1)\n       && _IO_sputn (_IO_stdout, str, len) == len\n+      && _IO_sputn (_IO_stdout, \" hacked\", 7) == 7\n       && _IO_putc_unlocked ('\\n', _IO_stdout) != EOF)\n-    result = MIN (INT_MAX, len + 1);\n+    result = MIN (INT_MAX, len + 1 + 7);\n\n   _IO_release_lock (_IO_stdout);\n   return result;\n....\n\nAnd then:\n\n....\n./run --eval-after './c/hello.out'\n....\n\noutputs:\n\n....\nhello hacked\n....\n\nLol!\n\nWe can also test our hacked glibc on <<user-mode-simulation>> with:\n\n....\n./run --userland userland/c/hello.c\n....\n\nI just noticed that this is actually a good way to develop glibc for other archs.\n\nIn this example, we got away without recompiling the userland program because we made a change that did not affect the glibc ABI, see this answer for an introduction to ABI stability: https://stackoverflow.com/questions/2171177/what-is-an-application-binary-interface-abi/54967743#54967743\n\nNote that for arch agnostic features that don't rely on bleeding kernel changes that you host doesn't yet have, you can develop glibc natively as explained at:\n\n* https://stackoverflow.com/questions/10412684/how-to-compile-my-own-glibc-c-standard-library-from-source-and-use-it/52454710#52454710\n* https://stackoverflow.com/questions/847179/multiple-glibc-libraries-on-a-single-host/52454603#52454603\n* https://stackoverflow.com/questions/2856438/how-can-i-link-to-a-specific-glibc-version/52550158#52550158 more focus on symbol versioning, but no one knows how to do it, so I answered\n\nTested on a30ed0f047523ff2368d421ee2cce0800682c44e + 1.\n\n===== Your first Binutils hack\n\nHave you ever felt that a single `inc` instruction was not enough? Really? Me too!\n\nSo let's hack the <<gnu-gas-assembler>>, which is part of https://en.wikipedia.org/wiki/GNU_Binutils[GNU Binutils], to add a new shiny version of `inc` called... `myinc`!\n\nGCC uses GNU GAS as its backend, so we will test out new mnemonic with an <<gcc-inline-assembly>> test program: link:userland/arch/x86_64/binutils_hack.c[], which is just a copy of link:userland/arch/x86_64/binutils_nohack.c[] but with `myinc` instead of `inc`.\n\nThe inline assembly is disabled with an `#ifdef`, so first modify the source to enable that.\n\nThen, try to build userland:\n\n....\n./build-userland\n....\n\nand watch it fail with:\n\n....\nbinutils_hack.c:8: Error: no such instruction: `myinc %rax'\n....\n\nNow, edit the file\n\n....\nvim submodules/binutils-gdb/opcodes/i386-tbl.h\n....\n\nand add a copy of the `\"inc\"` instruction just next to it, but with the new name `\"myinc\"`:\n\n....\ndiff --git a/opcodes/i386-tbl.h b/opcodes/i386-tbl.h\nindex af583ce578..3cc341f303 100644\n--- a/opcodes/i386-tbl.h\n+++ b/opcodes/i386-tbl.h\n@@ -1502,6 +1502,19 @@ const insn_template i386_optab[] =\n     { { { 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n \t  0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n \t  1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0 } } } },\n+  { \"myinc\", 1, 0xfe, 0x0, 1,\n+    { { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } },\n+    { 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+      0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n+      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+      0, 0, 0, 0, 0, 0 },\n+    { { { 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n+\t  0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n+\t  1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0 } } } },\n   { \"sub\", 2, 0x28, None, 1,\n     { { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n....\n\nFinally, rebuild Binutils, userland and test our program with <<user-mode-simulation>>:\n\n....\n./build-buildroot -- host-binutils-rebuild\n./build-userland --static\n./run --static --userland userland/arch/x86_64/binutils_hack.c\n....\n\nand we se that `myinc` worked since the assert did not fail!\n\nTested on b60784d59bee993bf0de5cde6c6380dd69420dda + 1.\n\n===== Your first GCC hack\n\nOK, now time to hack GCC.\n\nFor convenience, let's use the <<user-mode-simulation>>.\n\nIf we run the program link:userland/c/gcc_hack.c[]:\n\n....\n./build-userland --static\n./run --static --userland userland/c/gcc_hack.c\n....\n\nit produces the normal boring output:\n\n....\ni = 2\nj = 0\n....\n\nSo how about we swap `++` and `--` to make things more fun?\n\nOpen the file:\n\n....\nvim submodules/gcc/gcc/c/c-parser.c\n....\n\nand find the function `c_parser_postfix_expression_after_primary`.\n\nIn that function, swap `case CPP_PLUS_PLUS` and `case CPP_MINUS_MINUS`:\n\n....\ndiff --git a/gcc/c/c-parser.c b/gcc/c/c-parser.c\nindex 101afb8e35f..89535d1759a 100644\n--- a/gcc/c/c-parser.c\n+++ b/gcc/c/c-parser.c\n@@ -8529,7 +8529,7 @@ c_parser_postfix_expression_after_primary (c_parser *parser,\n \t\texpr.original_type = DECL_BIT_FIELD_TYPE (field);\n \t    }\n \t  break;\n-\tcase CPP_PLUS_PLUS:\n+\tcase CPP_MINUS_MINUS:\n \t  /* Postincrement.  */\n \t  start = expr.get_start ();\n \t  finish = c_parser_peek_token (parser)->get_finish ();\n@@ -8548,7 +8548,7 @@ c_parser_postfix_expression_after_primary (c_parser *parser,\n \t  expr.original_code = ERROR_MARK;\n \t  expr.original_type = NULL;\n \t  break;\n-\tcase CPP_MINUS_MINUS:\n+\tcase CPP_PLUS_PLUS:\n \t  /* Postdecrement.  */\n \t  start = expr.get_start ();\n \t  finish = c_parser_peek_token (parser)->get_finish ();\n....\n\nNow rebuild GCC, the program and re-run it:\n\n....\n./build-buildroot -- host-gcc-final-rebuild\n./build-userland --static\n./run --static --userland userland/c/gcc_hack.c\n....\n\nand the new ouptut is now:\n\n....\ni = 2\nj = 0\n....\n\nWe need to use the ugly `-final` thing because GCC has to packages in Buildroot, `-initial` and `-final`: https://stackoverflow.com/questions/54992977/how-to-select-an-override-srcdir-source-for-gcc-when-building-buildroot No one is able to example precisely with a minimal example why this is required:\n\n* https://stackoverflow.com/questions/39883865/why-multiple-passes-for-building-linux-from-scratch-lfs\n* https://stackoverflow.com/questions/27457835/why-do-cross-compilers-have-a-two-stage-compilation\n\n==== About the QEMU Buildroot setup\n\nWhat QEMU and Buildroot are:\n\n* <<introduction-to-buildroot>>\n* <<introduction-to-qemu>>\n\nThis is our reference setup, and the best supported one, use it unless you have good reason not to.\n\nIt was historically the first one we did, and all sections have been tested with this setup unless explicitly noted.\n\nRead the following sections for further introductory material:\n\n* <<introduction-to-qemu>>\n* <<introduction-to-buildroot>>\n\n[[dry-run]]\n=== Dry run to get commands for your project\n\nOne of the major features of this repository is that we try to support the `--dry-run` option really well for all scripts.\n\nThis option, as the name suggests, outputs the external commands that would be run (or more precisely: equivalent commands), without actually running them.\n\nThis allows you to just clone this repository and get full working commands to integrate into your project, without having to build or use this setup further!\n\nFor example, we can obtain a QEMU run for the file link:userland/c/hello.c[] in <<user-mode-simulation>> by adding `--dry-run` to the normal command:\n\n....\n./run --dry-run --userland userland/c/hello.c\n....\n\nwhich as of LKMC a18f28e263c91362519ef550150b5c9d75fa3679 + 1 outputs:\n\n....\n+ /path/to/linux-kernel-module-cheat/out/qemu/default/opt/x86_64-linux-user/qemu-x86_64 \\\n  -L /path/to/linux-kernel-module-cheat/out/buildroot/build/default/x86_64/target \\\n  -r 5.2.1 \\\n  -seed 0 \\\n  -trace enable=load_file,file=/path/to/linux-kernel-module-cheat/out/run/qemu/x86_64/0/trace.bin \\\n  -cpu max \\\n  /path/to/linux-kernel-module-cheat/out/userland/default/x86_64/c/hello.out \\\n;\n....\n\nSo observe that the command contains:\n\n* `+`: sign to differentiate it from program stdout, much like bash `-x` output. This is not a valid part of the generated Bash command however.\n* the actual command nicely, indented and with arguments broken one per line, but with continuing backslashes so you can just copy paste into a terminal\n+\nFor setups that don't support the newline e.g. <<gem5-eclipse-configuration,Eclipse debugging>>, you can turn them off with `--print-cmd-oneline`\n* `;`: both a valid part of the Bash command, and a visual mark the end of the command\n\nFor the specific case of running emulators such as QEMU, the last command is also automatically placed in a file for your convenience and later inspection:\n\n....\ncat \"$(./getvar run_dir)/run.sh\"\n....\n\nSince we need this so often, the last run command is also stored for convenience at:\n\n....\ncat out/run.sh\n....\n\nalthough this won't of course work well for <<simultaneous-runs>>.\n\nFurthermore, `--dry-run` also automatically specifies, in valid Bash shell syntax:\n\n* environment variables used to run the command with syntax `+ ENV_VAR_1=abc ENV_VAR_2=def ./some/command`\n* change in working directory with `+ cd /some/new/path && ./some/command`\n\n=== gem5 Buildroot setup\n\n==== About the gem5 Buildroot setup\n\nThis setup is like the <<qemu-buildroot-setup>>, but it uses http://gem5.org/[gem5] instead of QEMU as a system simulator.\n\nQEMU tries to run as fast as possible and give correct results at the end, but it does not tell us how many CPU cycles it takes to do something, just the number of instructions it ran. This kind of simulation is known as functional simulation.\n\nThe number of instructions executed is a very poor estimator of performance because in modern computers, a lot of time is spent waiting for memory requests rather than the instructions themselves.\n\ngem5 on the other hand, can simulate the system in more detail than QEMU, including:\n\n* simplified CPU pipeline\n* caches\n* DRAM timing\n\nand can therefore be used to estimate system performance, see: xref:gem5-run-benchmark[xrefstyle=full] for an example.\n\nThe downside of gem5 much slower than QEMU because of the greater simulation detail.\n\nSee <<gem5-vs-qemu>> for a more thorough comparison.\n\n==== gem5 Buildroot setup getting started\n\nFor the most part, if you just add the `--emulator gem5` option or `*-gem5` suffix to all commands and everything should magically work.\n\nIf you haven't built Buildroot yet for <<qemu-buildroot-setup>>, you can build from the beginning with:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies gem5-buildroot\n./run --emulator gem5\n....\n\nIf you have already built previously, don't be afraid: gem5 and QEMU use almost the same root filesystem and kernel, so `./build` will be fast.\n\nRemember that the gem5 boot is <<benchmark-linux-kernel-boot,considerably slower>> than QEMU since the simulation is more detailed.\n\nIf you have a relatively new GCC version and the gem5 build fails on your machine, see: <<gem5-build-broken-on-recent-compiler-version>>.\n\nTo get a terminal, either open a new shell and run:\n\n....\n./gem5-shell\n....\n\nYou can quit the shell without killing gem5 by typing tilde followed by a period:\n\n....\n~.\n....\n\nIf you are inside <<tmux>>, which I highly recommend, you can both run gem5 stdout and open the guest terminal on a split window with:\n\n....\n./run --emulator gem5 --tmux\n....\n\nSee also: xref:tmux-gem5[xrefstyle=full].\n\nAt the end of boot, it might not be very clear that you have the shell since some <<printk>> messages may appear in front of the prompt like this:\n\n....\n# <6>[    1.215329] clocksource: tsc: mask: 0xffffffffffffffff max_cycles: 0x1cd486fa865, max_idle_ns: 440795259574 ns\n<6>[    1.215351] clocksource: Switched to clocksource tsc\n....\n\nbut if you look closely, the `PS1` prompt marker `#` is there already, just hit enter and a clear prompt line will appear.\n\nIf you forgot to open the shell and gem5 exit, you can inspect the terminal output post-mortem at:\n\n....\nless \"$(./getvar --emulator gem5 m5out_dir)/system.pc.com_1.device\"\n....\n\nMore gem5 information is present at: xref:gem5[xrefstyle=full]\n\nGood next steps are:\n\n* <<gem5-run-benchmark>>: how to run a benchmark in gem5 full system, including how to boot Linux, checkpoint and restore to skip the boot on a fast CPU\n* <<m5out-directory>>: understand the output files that gem5 produces, which contain information about your run\n* <<m5ops>>: magic guest instructions used to control gem5\n* <<add-new-files-to-the-buildroot-image>>: how to add your own files to the image if you have a benchmark that we don't already support out of the box (also send a pull request!)\n\n[[docker]]\n=== Docker host setup\n\nThis repository has been tested inside clean https://en.wikipedia.org/wiki/Docker_(software)[Docker] containers.\n\nThis is a good option if you are on a Linux host, but the native setup failed due to your weird host distribution, and you have better things to do with your life than to debug it. See also: xref:supported-hosts[xrefstyle=full].\n\nFor example, to do a <<qemu-buildroot-setup>> inside Docker, run:\n\n....\nsudo apt-get install docker\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./run-docker create && \\\n./run-docker sh -- ./build --download-dependencies qemu-buildroot\n./run-docker\n....\n\nYou are now left inside a shell in the Docker! From there, just run as usual:\n\n....\n./run\n....\n\nThe host git top level directory is mounted inside the guest with a https://stackoverflow.com/questions/23439126/how-to-mount-a-host-directory-in-a-docker-container[Docker volume], which means for example that you can use your host's GUI text editor directly on the files. Just don't forget that if you nuke that directory on the guest, then it gets nuked on the host as well!\n\nCommand breakdown:\n\n* `./run-docker create`: create the image and container.\n+\nNeeded only the very first time you use Docker, or if you run `./run-docker DESTROY` to restart for scratch, or save some disk space.\n+\nThe image and container name is `lkmc`. The container shows under:\n+\n....\ndocker ps -a\n....\n+\nand the image shows under:\n+\n....\ndocker images\n....\n* `./run-docker`: open a shell on the container.\n+\nIf it has not been started previously, start it. This can also be done explicitly with:\n+\n....\n./run-docker start\n....\n+\nQuit the shell as usual with `Ctrl-D`\n+\nThis can be called multiple times from different host terminals to open multiple shells.\n* `./run-docker stop`: stop the container.\n+\nThis might save a bit of CPU and RAM once you stop working on this project, but it should not be a lot.\n* `./run-docker DESTROY`: delete the container and image.\n+\nThis doesn't really clean the build, since we mount the guest's working directory on the host git top-level, so you basically just got rid of the `apt-get` installs.\n+\nTo actually delete the Docker build, run on host:\n+\n....\n# sudo rm -rf out.docker\n....\n\nTo use <<gdb>> from inside Docker, you need a second shell inside the container. You can either do that from another shell with:\n\n....\n./run-docker\n....\n\nor even better, by starting a <<tmux>> session inside the container. We install `tmux` by default in the container.\n\nYou can also start a second shell and run a command in it at the same time with:\n\n....\n./run-docker sh -- ./run-gdb start_kernel\n....\n\nTo use <<qemu-graphic-mode>> from Docker, run:\n\n....\n./run --graphic --vnc\n....\n\nand then on host:\n\n....\nsudo apt-get install vinagre\n./vnc\n....\n\nTODO make files created inside Docker be owned by the current user in host instead of `root`:\n\n* https://stackoverflow.com/questions/33681396/how-do-i-write-to-a-volume-container-as-non-root-in-docker\n* https://stackoverflow.com/questions/23544282/what-is-the-best-way-to-manage-permissions-for-docker-shared-volumes\n* https://stackoverflow.com/questions/31779802/shared-volume-file-permissions-ownership-docker\n\n[[prebuilt]]\n=== Prebuilt setup\n\n==== About the prebuilt setup\n\nThis setup uses prebuilt binaries that we upload to GitHub from time to time.\n\nWe don't currently provide a full prebuilt because it would be too big to host freely, notably because of the cross toolchain.\n\nOur prebuilts currently include:\n\n* <<qemu-buildroot-setup>> binaries\n** Linux kernel\n** root filesystem\n* <<baremetal-setup>> binaries for QEMU\n\nFor more details, see our our <<release,release procedure>>.\n\nAdvantage of this setup: saves time and disk space on the initial install, which is expensive in largely due to building the toolchain.\n\nThe limitations are severe however:\n\n* can't <<gdb,GDB step debug the kernel>>, since the source and cross toolchain with GDB are not available. Buildroot cannot easily use a host toolchain: xref:prebuilt-toolchain[xrefstyle=full].\n+\nMaybe we could work around this by just downloading the kernel source somehow, and using a host prebuilt GDB, but we felt that it would be too messy and unreliable.\n* you won't get the latest version of this repository. Our <<travis>> attempt to automate builds failed, and storing a release for every commit would likely make GitHub mad at us anyway.\n* <<gem5>> is not currently supported. The major blocking point is how to avoid distributing the kernel images twice: once for gem5 which uses `vmlinux`, and once for QEMU which uses `arch/*` images, see also:\n** https://github.com/cirosantilli/linux-kernel-module-cheat/issues/79\n** <<vmlinux-vs-bzimage-vs-zimage-vs-image>>.\n\nThis setup might be good enough for those developing simulators, as that requires less image modification. But once again, if you are serious about this, why not just let your computer build the <<qemu-buildroot-setup,full featured setup>> while you take a coffee or a nap? :-)\n\n==== Prebuilt setup getting started\n\nCheckout to the latest tag and use the Ubuntu packaged QEMU to boot Linux:\n\n....\nsudo apt-get install qemu-system-x86\ngit clone https://github.com/cirosantilli/linux-kernel-module-cheat\ncd linux-kernel-module-cheat\ngit checkout \"$(git rev-list --tags --max-count=1)\"\n./release-download-latest\nunzip lkmc-*.zip\n./run --qemu-which host\n....\n\nYou have to checkout to the latest tag to ensure that the scripts match the release format: https://stackoverflow.com/questions/1404796/how-to-get-the-latest-tag-name-in-current-branch-in-git\n\nThis is known not to work for aarch64 on an Ubuntu 16.04 host with QEMU 2.5.0, presumably because QEMU is too old, the terminal does not show any output. I haven't investigated why.\n\nOr to run a baremetal example instead:\n\n....\n./run \\\n  --arch aarch64 \\\n  --baremetal userland/c/hello.c \\\n  --qemu-which host \\\n;\n....\n\nBe saner and use our custom built QEMU instead:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies qemu\n./run\n....\n\nTo build the kernel modules as in <<your-first-kernel-module-hack>> do:\n\n....\ngit submodule update --depth 1 --init --recursive \"$(./getvar linux_source_dir)\"\n./build-linux --no-modules-install -- modules_prepare\n./build-modules --gcc-which host\n./run\n....\n\nTODO: for now the only way to test those modules out without <<qemu-buildroot-setup-getting-started,building Buildroot>> is with 9p, since we currently rely on Buildroot to manipulate the root filesystem.\n\nCommand explanation:\n\n* `modules_prepare` does the minimal build procedure required on the kernel for us to be able to compile the kernel modules, and is way faster than doing a full kernel build. A full kernel build would also work however.\n* `--gcc-which host` selects your host Ubuntu packaged GCC, since you don't have the Buildroot toolchain\n* `--no-modules-install` is required otherwise the `make modules_install` target we run by default fails, since the kernel wasn't built\n\nTo modify the Linux kernel, build and use it as usual:\n\n....\ngit submodule update --depth 1 --init --recursive \"$(./getvar linux_source_dir)\"\n./build-linux\n./run\n....\n\n////\nFor gem5, do:\n\n....\ngit submodule update --init --depth 1 \"$(./getvar linux_source_dir)\"\nsudo apt-get install qemu-utils\n./build-gem5\n./run --emulator gem5 --qemu-which host\n....\n\n`qemu-utils` is required because we currently distribute `.qcow2` files which <<gem5-qcow2,gem5 can't handle>>, so we need `qemu-img` to extract them first.\n\nThe Linux kernel is required for `extract-vmlinux` to convert the compressed kernel image which QEMU understands into the raw vmlinux that gem5 understands: https://superuser.com/questions/298826/how-do-i-uncompress-vmlinuz-to-vmlinux\n////\n\n////\n[[ubuntu]]\n=== Ubuntu guest setup\n\n==== About the Ubuntu guest setup\n\nThis setup is similar to <<prebuilt>>, but instead of using Buildroot for the root filesystem, it downloads an Ubuntu image with Docker, and uses that as the root filesystem.\n\nThe rationale for choice of Ubuntu as a second distribution in addition to Buildroot can be found at: xref:linux-distro-choice[xrefstyle=full]\n\nAdvantages over Buildroot:\n\n* saves build time\n* you get to play with a huge selection of Debian packages out of the box\n* more representative of most non-embedded production systems than BusyBox\n\nDisadvantages:\n\n* less visibility: https://askubuntu.com/questions/82302/how-to-compile-ubuntu-from-source-code The fact that that question has no answer makes me cringe\n* less compatibility, e.g. no one knows what the officially supported cross compilers are: https://askubuntu.com/questions/1046294/what-are-the-officially-supported-cross-compilers-for-ubuntu-server-alternative\n\nDocker is used here just as an image download provider since it has a wide variety of images. Why we don't just download the regular Ubuntu disk image:\n\n* that image is not ready to boot, but rather goes into an interactive installer: https://askubuntu.com/questions/884534/how-to-run-ubuntu-16-04-desktop-on-qemu/1046792#1046792\n* the default Ubuntu image has a large collection of software, and is large. The docker version is much more minimal.\n\nOne alternative would be to use https://wiki.ubuntu.com/Base[Ubuntu base] which can be downloaded from: http://cdimage.ubuntu.com/ubuntu-base That provides a `.tgz` and comes very close to what we obtain with Docker, but without the need for `sudo`.\n\n==== Ubuntu guest setup getting started\n\nTODO\n\n....\nsudo ./build-docker\n./run --docker\n....\n\n`sudo` is required for Docker operations: https://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo\n////\n\n[[host]]\n=== Host kernel module setup\n\n**THIS IS DANGEROUS (AND FUN), YOU HAVE BEEN WARNED**\n\nThis method runs the kernel modules directly on your host computer without a VM, and saves you the compilation time and disk usage of the virtual machine method.\n\nIt has however severe limitations:\n\n* can't control which kernel version and build options to use. So some of the modules will likely not compile because of kernel API changes, since https://stackoverflow.com/questions/37098482/how-to-build-a-linux-kernel-module-so-that-it-is-compatible-with-all-kernel-rele/45429681#45429681[the Linux kernel does not have a stable kernel module API].\n* bugs can easily break you system. E.g.:\n** segfaults can trivially lead to a kernel crash, and require a reboot\n** your disk could get erased. Yes, this can also happen with `sudo` from userland. But you should not use `sudo` when developing newbie programs. And for the kernel you don't have the choice not to use `sudo`.\n** even more subtle system corruption such as https://unix.stackexchange.com/questions/78858/cannot-remove-or-reinsert-kernel-module-after-error-while-inserting-it-without-r[not being able to rmmod]\n* can't control which hardware is used, notably the CPU architecture\n* can't step debug it with <<gdb,GDB>> easily. The alternatives are https://en.wikipedia.org/wiki/JTAG[JTAG] or <<kgdb>>, but those are less reliable, and require extra hardware.\n\nStill interested?\n\n....\n./build-modules --host\n....\n\nCompilation will likely fail for some modules because of kernel or toolchain differences that we can't control on the host.\n\nThe best workaround is to compile just your modules with:\n\n....\n./build-modules --host -- hello hello2\n....\n\nwhich is equivalent to:\n\n....\n./build-modules \\\n  --gcc-which host \\\n  --host \\\n  -- \\\n  kernel_modules/hello.c \\\n  kernel_modules/hello2.c \\\n;\n....\n\nOr just remove the `.c` extension from the failing files and try again:\n\n....\ncd \"$(./getvar kernel_modules_source_dir)\"\nmv broken.c broken.c~\n....\n\nOnce you manage to compile, and have come to terms with the fact that this may blow up your host, try it out with:\n\n....\ncd \"$(./getvar kernel_modules_build_host_subdir)\"\nsudo insmod hello.ko\n\n# Our module is there.\nsudo lsmod | grep hello\n\n# Last message should be: hello init\ndmesg -T\n\nsudo rmmod hello\n\n# Last message should be: hello exit\ndmesg -T\n\n# Not present anymore\nsudo lsmod | grep hello\n....\n\n==== Hello host\n\nMinimal host build system example:\n\n....\ncd hello_host_kernel_module\nmake\nsudo insmod hello.ko\ndmesg\nsudo rmmod hello.ko\ndmesg\n....\n\n=== Userland setup\n\n==== About the userland setup\n\nIn order to test the kernel and emulators, userland content in the form of executables and scripts is of course required, and we store it mostly under:\n\n* link:userland/[]\n* <<rootfs-overlay>>\n* <<add-new-buildroot-packages>>\n\nWhen we started this repository, it only contained content that interacted very closely with the kernel, or that had required performance analysis.\n\nHowever, we soon started to notice that this had an increasing overlap with other userland test repositories: we were duplicating build and test infrastructure and even some examples.\n\nTherefore, we decided to consolidate other userland tutorials that we had scattered around into this repository.\n\nNotable userland content included / moving into this repository includes:\n\n* <<userland-assembly>>\n* <<c>>\n* <<cpp>>\n* <<posix>>\n* <<algorithms>>\n\n==== Userland setup getting started\n\nThere are several ways to run our <<userland-content>>, notably:\n\n* natively on the host as shown at: xref:userland-setup-getting-started-natively[xrefstyle=full]\n+\nCan only run examples compatible with your host CPU architecture and OS, but has the fastest setup and runtimes.\n* from user mode simulation with:\n+\n--\n** the host prebuilt toolchain: xref:userland-setup-getting-started-with-prebuilt-toolchain-and-qemu-user-mode[xrefstyle=full]\n** the Buildroot toolchain you built yourself: xref:qemu-user-mode-getting-started[xrefstyle=full]\n--\n+\nThis setup:\n+\n--\n** can run most examples, including those for other CPU architectures, with the notable exception of examples that rely on kernel modules\n** can run reproducible approximate performance experiments with gem5, see e.g. <<bst-vs-heap-vs-hashmap>>\n--\n* from full system simulation as shown at: xref:qemu-buildroot-setup-getting-started[xrefstyle=full].\n+\nThis is the most reproducible and controlled environment, and all examples work there. But also the slower one to setup.\n\n===== Userland setup getting started natively\n\nWith this setup, we will use the host toolchain and execute executables directly on the host.\n\nNo toolchain build is required, so you can just download your distro toolchain and jump straight into it.\n\nBuild, run and example, and clean it in-tree with:\n\n....\nsudo apt-get install gcc\ncd userland\n./build c/hello\n./c/hello.out\n./build --clean\n....\n\nSource: link:userland/c/hello.c[].\n\nBuild an entire directory and test it:\n\n....\ncd userland\n./build c\n./test c\n....\n\nBuild the current directory and test it:\n\n....\ncd userland/c\n./build\n./test\n....\n\nAs mentioned at <<userland-libs-directory>>, tests under link:userland/libs[] require certain optional libraries to be installed, and are not built or tested by default.\n\nYou can install those libraries with:\n\n....\ncd linux-kernel-module-cheat\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies userland-host\n....\n\nand then build the examples and test with:\n\n....\n./build --package-all\n./test --package-all\n....\n\nPass custom compiler options:\n\n....\n./build --ccflags='-foptimize-sibling-calls -foptimize-strlen' --force-rebuild\n....\n\nHere we used `--force-rebuild` to force rebuild since the sources weren't modified since the last build.\n\nSome CLI options have more specialized flags, e.g. `-O` for the <<optimization-level-of-a-build>>:\n\n....\n./build --optimization-level 3 --force-rebuild\n....\n\nSee also <<user-mode-static-executables>> for `--static`.\n\nThe `build` scripts inside link:userland/[] are just symlinks to link:build-userland-in-tree[] which you can also use from toplevel as:\n\n....\n./build-userland-in-tree\n./build-userland-in-tree userland/c\n./build-userland-in-tree userland/c/hello.c\n....\n\n`build-userland-in-tree` is in turn just a thin wrapper around link:build-userland[]:\n\n....\n./build-userland --gcc-which host --in-tree userland/c\n....\n\nSo you can use any option supported by `build-userland` script freely with `build-userland-in-tree` and `build`.\n\nThe situation is analogous for link:userland/test[], link:test-executables-in-tree[] and link:test-executables[], which are further documented at: xref:user-mode-tests[xrefstyle=full].\n\nDo a more clean out-of-tree build instead and run the program:\n\n....\n./build-userland --gcc-which host --userland-build-id host\n./run --emulator native --userland userland/c/hello.c --userland-build-id host\n....\n\nHere we:\n\n* put the host executables in a separate <<build-variants,build variant>> to avoid conflict with Buildroot builds.\n* ran with the `--emulator native` option to run the program natively\n\nIn this case you can debub the program with:\n\n....\n./run --debug-vm --emulator native --userland userland/c/hello.c --userland-build-id host\n....\n\nas shown at: xref:debug-the-emulator[xrefstyle=full], although direct GDB host usage works as well of course.\n\n===== Userland setup getting started with prebuilt toolchain and QEMU user mode\n\nIf you are lazy to built the Buildroot toolchain and QEMU, but want to run e.g. ARM <<userland-assembly>> in <<user-mode-simulation>>, you can get away on Ubuntu 18.04 with just:\n\n....\nsudo apt-get install gcc-aarch64-linux-gnu qemu-system-aarch64\n./build-userland \\\n  --arch aarch64 \\\n  --gcc-which host \\\n  --userland-build-id host \\\n;\n./run \\\n  --arch aarch64 \\\n  --qemu-which host \\\n  --userland-build-id host \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\nwhere:\n\n* `--gcc-which host`: use the host toolchain.\n+\nWe must pass this to `./run` as well because QEMU must know which dynamic libraries to use. See also: xref:user-mode-static-executables[xrefstyle=full].\n* `--userland-build-id host`: put the host built into a <<build-variants>>\n\nThis present the usual trade-offs of using prebuilts as mentioned at: xref:prebuilt[xrefstyle=full].\n\nOther functionality are analogous, e.g. testing:\n\n....\n./test-executables \\\n  --arch aarch64 \\\n  --gcc-which host \\\n  --qemu-which host \\\n  --userland-build-id host \\\n;\n....\n\nand <<user-mode-gdb>>:\n\n....\n./run \\\n  --arch aarch64 \\\n  --gdb \\\n  --gcc-which host \\\n  --qemu-which host \\\n  --userland-build-id host \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\n===== Userland setup getting started full system\n\nFirst ensure that <<qemu-buildroot-setup>> is working.\n\nAfter doing that setup, you can already execute your userland programs from inside QEMU: the only missing step is how to rebuild executables and run them.\n\nAnd the answer is exactly analogous to what is shown at: xref:your-first-kernel-module-hack[xrefstyle=full]\n\nFor example, if we modify link:userland/c/hello.c[] to print out something different, we can just rebuild it with:\n\n....\n./build-userland\n....\n\nSource: link:build-userland[]. `./build` calls that script automatically for us when doing the initial full build.\n\nNow, run the program either without rebooting use the <<9p>> mount:\n\n....\n/mnt/9p/out_rootfs_overlay/c/hello.out\n....\n\nor shutdown QEMU, add the executable to the root filesystem:\n\n....\n./build-buildroot\n....\n\nreboot and use the root filesystem as usual:\n\n....\n./hello.out\n....\n\n=== Baremetal setup\n\n==== About the baremetal setup\n\nThis setup does not use the Linux kernel nor Buildroot at all: it just runs your very own minimal OS.\n\n`x86_64` is not currently supported, only `arm` and `aarch64`: I had made some x86 bare metal examples at: https://github.com/cirosantilli/x86-bare-metal-examples but I'm lazy to port them here now. Pull requests are welcome.\n\nThe main reason this setup is included in this project, despite the word \"Linux\" being on the project name, is that a lot of the emulator boilerplate can be reused for both use cases.\n\nThis setup allows you to make a tiny OS and that runs just a few instructions, use it to fully control the CPU to better understand the simulators for example, or develop your own OS if you are into that.\n\nYou can also use C and a subset of the C standard library because we enable https://en.wikipedia.org/wiki/Newlib[Newlib] by default. See also:\n\n* https://electronics.stackexchange.com/questions/223929/c-standard-libraries-on-bare-metal/400077#400077\n* https://stackoverflow.com/questions/13063055/does-a-libc-os-exist/59771531#59771531\n\nOur C bare-metal compiler is built with https://github.com/crosstool-ng/crosstool-ng[crosstool-NG]. If you have already built <<qemu-buildroot-setup,Buildroot>> previously, you will end up with two GCCs installed. Unfortunately I don't see a solution for this, since we need separate toolchains for Newlib on baremetal and glibc on Linux: https://stackoverflow.com/questions/38956680/difference-between-arm-none-eabi-and-arm-linux-gnueabi/38989869#38989869\n\n==== Baremetal setup getting started\n\nEvery `.c` file inside link:baremetal/[] and `.S` file inside `baremetal/arch/<arch>/` generates a separate baremetal image.\n\nFor example, to run link:baremetal/arch/aarch64/dump_regs.c[] in QEMU do:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --arch aarch64 --download-dependencies qemu-baremetal\n./run --arch aarch64 --baremetal baremetal/arch/aarch64/dump_regs.c\n....\n\nAnd the terminal prints the values of certain system registers. This example prints registers that are only accessible from <<arm-exception-levels,EL1>> or higher, and thus could not be run in userland.\n\nIn addition to the examples under link:baremetal/[], several of the <<userland-content,userland examples>> can also be run in baremetal! This is largely due to the <<about-the-baremetal-setup,awesomeness of Newlib>>.\n\nThe examples that work include most <<c,C examples>> that don't rely on complicated syscalls such as threads, and almost all the <<userland-assembly>> examples.\n\nThe exact list of userland programs that work in baremetal is specified in <<path-properties>> with the `baremetal` property, but you can also easily find it out with a <<baremetal-tests,baremetal test dry run>>:\n\n....\n./test-executables --arch aarch64 --dry-run --mode baremetal\n....\n\nFor example, we can run the C hello world link:userland/c/hello.c[] simply as:\n\n....\n./run --arch aarch64 --baremetal userland/c/hello.c\n....\n\nand that outputs to the serial port the string:\n\n....\nhello\n....\n\nwhich QEMU shows on the host terminal.\n\nTo modify a baremetal program, simply edit the file, e.g.\n\n....\nvim userland/c/hello.c\n....\n\nand rebuild:\n\n....\n./build-baremetal --arch aarch64\n./run --arch aarch64 --baremetal userland/c/hello.c\n....\n\n`./build qemu-baremetal` that we run previously is only needed for the initial build. That script calls link:build-baremetal[] for us, in addition to building prerequisites such as QEMU and crosstool-NG.\n\n`./build-baremetal` uses crosstool-NG, and so it must be preceded by link:build-crosstool-ng[], which `./build qemu-baremetal` also calls.\n\nNow let's run link:userland/arch/aarch64/add.S[]:\n\n....\n./run --arch aarch64 --baremetal userland/arch/aarch64/add.S\n....\n\nThis time, the terminal does not print anything, which indicates success: if you look into the source, you will see that we just have an assertion there.\n\nYou can see a sample assertion fail in link:userland/c/assert_fail.c[]:\n\n....\n./run --arch aarch64 --baremetal userland/c/assert_fail.c\n....\n\nand the terminal contains:\n\n....\nlkmc_exit_status_134\nerror: simulation error detected by parsing logs\n....\n\nand the exit status of our script is 1:\n\n....\necho $?\n....\n\nYou can run all the baremetal examples in one go and check that all assertions passed with:\n\n....\n./test-executables --arch aarch64 --mode baremetal\n....\n\nTo use gem5 instead of QEMU do:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies gem5-baremetal\n./run --arch aarch64 --baremetal userland/c/hello.c --emulator gem5\n....\n\nand then <<qemu-buildroot-setup,as usual>> open a shell with:\n\n....\n./gem5-shell\n....\n\nOr as usual, <<tmux>> users can do both in one go with:\n\n....\n./run --arch aarch64 --baremetal userland/c/hello.c --emulator gem5 --tmux\n....\n\nTODO: the carriage returns are a bit different than in QEMU, see: xref:gem5-baremetal-carriage-return[xrefstyle=full].\n\nNote that `./build-baremetal` requires the `--emulator gem5` option, and generates separate executable images for both, as can be seen from:\n\n....\necho \"$(./getvar --arch aarch64 --baremetal userland/c/hello.c --emulator qemu image)\"\necho \"$(./getvar --arch aarch64 --baremetal userland/c/hello.c --emulator gem5 image)\"\n....\n\nThis is unlike the Linux kernel that has a single image for both QEMU and gem5:\n\n....\necho \"$(./getvar --arch aarch64 --emulator qemu image)\"\necho \"$(./getvar --arch aarch64 --emulator gem5 image)\"\n....\n\nThe reason for that is that on baremetal we don't parse the <<device-tree,device tress>> from memory like the Linux kernel does, which tells the kernel for example the UART address, and many other system parameters.\n\n`gem5` also supports the `RealViewPBX` machine, which represents an older hardware compared to the default `VExpress_GEM5_V1`:\n\n....\n./build-baremetal --arch aarch64 --emulator gem5 --machine RealViewPBX\n./run --arch aarch64 --baremetal userland/c/hello.c --emulator gem5 --machine RealViewPBX\n....\n\nsee also: xref:gem5-arm-platforms[xrefstyle=full].\n\nThis generates yet new separate images with new magic constants:\n\n....\necho \"$(./getvar --arch aarch64 --baremetal userland/c/hello.c --emulator gem5 --machine VExpress_GEM5_V1 image)\"\necho \"$(./getvar --arch aarch64 --baremetal userland/c/hello.c --emulator gem5 --machine RealViewPBX      image)\"\n....\n\nBut just stick to newer and better `VExpress_GEM5_V1` unless you have a good reason to use `RealViewPBX`.\n\nWhen doing baremetal programming, it is likely that you will want to learn userland assembly first, see: xref:userland-assembly[xrefstyle=full].\n\nFor more information on baremetal, see the section: xref:baremetal[xrefstyle=full].\n\nThe following subjects are particularly important:\n\n* <<tracing>>\n* <<baremetal-gdb-step-debug>>\n\n=== Build the documentation\n\nYou don't need to depend on GitHub.\n\nFor a quick and dirty build, install https://asciidoctor.org/[Asciidoctor] however you like and build:\n\n....\nasciidoctor README.adoc\nxdg-open README.html\n....\n\nFor development, you will want to do a more controlled build with extra error checking as follows.\n\nFor the initial build do:\n\n....\npython3 -m venv .venv\n. .venv/bin/activate\n./setup\n./build --download-dependencies docs\n....\n\nwhich also downloads build dependencies.\n\nThen the following times just to the faster:\n\n....\n./build-doc\n....\n\nSource: link:build-doc[]\n\nThe HTML output is located at:\n\n....\nxdg-open out/README.html\n....\n\nMore information about our documentation internals can be found at: xref:documentation[xrefstyle=full]\n\n[[gdb]]\n== GDB step debug\n\n=== GDB step debug kernel boot\n\n`--gdb-wait` makes QEMU and gem5 wait for a GDB connection, otherwise we could accidentally go past the point we want to break at:\n\n....\n./run --gdb-wait\n....\n\nSay you want to break at `start_kernel`. So on another shell:\n\n....\n./run-gdb start_kernel\n....\n\nor at a given line:\n\n....\n./run-gdb init/main.c:1088\n....\n\nNow QEMU will stop there, and you can use the normal GDB commands:\n\n....\nlist\nnext\ncontinue\n....\n\nSee also:\n\n* https://stackoverflow.com/questions/11408041/how-to-debug-the-linux-kernel-with-gdb-and-qemu/33203642#33203642\n* https://stackoverflow.com/questions/4943857/linux-kernel-live-debugging-how-its-done-and-what-tools-are-used/42316607#42316607\n\n==== GDB step debug kernel boot other archs\n\nJust don't forget to pass `--arch` to `./run-gdb`, e.g.:\n\n....\n./run --arch aarch64 --gdb-wait\n....\n\nand:\n\n....\n./run-gdb --arch aarch64 start_kernel\n....\n\n[[kernel-o0]]\n==== Disable kernel compiler optimizations\n\nhttps://stackoverflow.com/questions/29151235/how-to-de-optimize-the-linux-kernel-to-and-compile-it-with-o0\n\n`O=0` is an impossible dream, `O=2` being the default.\n\nSo get ready for some weird jumps, and `<value optimized out>` fun. Why, Linux, why.\n\nThe `-O` level of some other userland content can be controlled as explained at: <<optimization-level-of-a-build>>.\n\n=== GDB step debug kernel post-boot\n\nLet's observe the kernel `write` system call as it reacts to some userland actions.\n\nStart QEMU with just:\n\n....\n./run\n....\n\nand after boot inside a shell run:\n\n....\n./count.sh\n....\n\nwhich counts to infinity to stdout. Source: link:rootfs_overlay/lkmc/count.sh[].\n\nThen in another shell, run:\n\n....\n./run-gdb\n....\n\nand then hit:\n\n....\nCtrl-C\nbreak __x64_sys_write\ncontinue\ncontinue\ncontinue\n....\n\nAnd you now control the counting on the first shell from GDB!\n\nBefore v4.17, the symbol name was just `sys_write`, the change happened at https://github.com/torvalds/linux/commit/d5a00528b58cdb2c71206e18bd021e34c4eab878[d5a00528b58cdb2c71206e18bd021e34c4eab878]. As of Linux v 4.19, the function is called `sys_write` in `arm`, and `__arm64_sys_write` in `aarch64`. One good way to find it if the name changes again is to try:\n\n....\nrbreak .*sys_write\n....\n\nor just have a quick look at the sources!\n\nWhen you hit `Ctrl-C`, if we happen to be inside kernel code at that point, which is very likely if there are no heavy background tasks waiting, and we are just waiting on a `sleep` type system call of the command prompt, we can already see the source for the random place inside the kernel where we stopped.\n\n=== tmux\n\ntmux just makes things even more fun by allowing us to see both the terminal for:\n\n* emulator stdout\n* <<gdb>>\n\nat once without dragging windows around!\n\nFirst start `tmux` with:\n\n....\ntmux\n....\n\nNow that you are inside a shell inside tmux, you can start GDB simply with:\n\n....\n./run --gdb\n....\n\nwhich is just a convenient shortcut for:\n\n....\n./run --gdb-wait --tmux --tmux-args start_kernel\n....\n\nThis splits the terminal into two panes:\n\n* left: usual QEMU with terminal\n* right: GDB\n\nand focuses on the GDB pane.\n\nNow you can navigate with the usual tmux shortcuts:\n\n* switch between the two panes with: `Ctrl-B O`\n* close either pane by killing its terminal with `Ctrl-D` as usual\n\nSee the tmux manual for further details:\n\n....\nman tmux\n....\n\nTo start again, switch back to the QEMU pane with `Ctrl-O`, kill the emulator, and re-run:\n\n....\n./run --gdb\n....\n\nThis automatically clears the GDB pane, and starts a new one.\n\nThe option `--tmux-args` determines which options will be passed to the program running on the second tmux pane, and is equivalent to:\n\nThis is equivalent to:\n\n....\n./run --gdb-wait\n./run-gdb start_kernel\n....\n\nDue to Python's CLI parsing quicks, if the link:run-gdb[] arguments start with a dash `-`, you have to use the `=` sign, e.g. to <<gdb-step-debug-early-boot>>:\n\n....\n./run --gdb --tmux-args=--no-continue\n....\n\nBibliography: https://unix.stackexchange.com/questions/152738/how-to-split-a-new-window-and-run-a-command-in-this-new-window-using-tmux/432111#432111\n\n==== tmux gem5\n\nIf you are using gem5 instead of QEMU, `--tmux` has a different effect by default: it opens the gem5 terminal instead of the debugger:\n\n....\n./run --emulator gem5 --tmux\n....\n\nTo open a new pane with GDB instead of the terminal, use:\n\n....\n./run --gdb\n....\n\nwhich is equivalent to:\n\n....\n./run --emulator gem5 --gdb-wait --tmux --tmux-args start_kernel --tmux-program gdb\n....\n\n`--tmux-program` implies `--tmux`, so we can just write:\n\n....\n./run --emulator gem5 --gdb-wait --tmux-program gdb\n....\n\nIf you also want to see both GDB and the terminal with gem5, then you will need to open a separate shell manually as usual with `./gem5-shell`.\n\nFrom inside tmux, you can create new terminals on a new window with `Ctrl-B C` split a pane yet again vertically with `Ctrl-B %` or horizontally with `Ctrl-B \"`.\n\n=== GDB step debug kernel module\n\nhttps://stackoverflow.com/questions/28607538/how-to-debug-linux-kernel-modules-with-qemu/44095831#44095831\n\nLoadable kernel modules are a bit trickier since the kernel can place them at different memory locations depending on load order.\n\nSo we cannot set the breakpoints before `insmod`.\n\nHowever, the Linux kernel GDB scripts offer the `lx-symbols` command, which takes care of that beautifully for us.\n\nShell 1:\n\n....\n./run\n....\n\nWait for the boot to end and run:\n\n....\ninsmod timer.ko\n....\n\nSource: link:kernel_modules/timer.c[].\n\nThis prints a message to dmesg every second.\n\nShell 2:\n\n....\n./run-gdb\n....\n\nIn GDB, hit `Ctrl-C`, and note how it says:\n\n....\nscanning for modules in /root/linux-kernel-module-cheat/out/kernel_modules/x86_64/kernel_modules\nloading @0xffffffffc0000000: /root/linux-kernel-module-cheat/out/kernel_modules/x86_64/kernel_modules/timer.ko\n....\n\nThat's `lx-symbols` working! Now simply:\n\n....\nbreak lkmc_timer_callback\ncontinue\ncontinue\ncontinue\n....\n\nand we now control the callback from GDB!\n\nJust don't forget to remove your breakpoints after `rmmod`, or they will point to stale memory locations.\n\nTODO: why does `break work_func` for `insmod kthread.ko` not very well? Sometimes it breaks but not others.\n\n[[gdb-step-debug-kernel-module-arm]]\n==== GDB step debug kernel module insmodded by init on ARM\n\nTODO on `arm` 51e31cdc2933a774c2a0dc62664ad8acec1d2dbe it does not always work, and `lx-symbols` fails with the message:\n\n....\nloading vmlinux\nTraceback (most recent call last):\n  File \"/linux-kernel-module-cheat//out/arm/buildroot/build/linux-custom/scripts/gdb/linux/symbols.py\", line 163, in invoke\n    self.load_all_symbols()\n  File \"/linux-kernel-module-cheat//out/arm/buildroot/build/linux-custom/scripts/gdb/linux/symbols.py\", line 150, in load_all_symbols\n    [self.load_module_symbols(module) for module in module_list]\n  File \"/linux-kernel-module-cheat//out/arm/buildroot/build/linux-custom/scripts/gdb/linux/symbols.py\", line 110, in load_module_symbols\n    module_name = module['name'].string()\ngdb.MemoryError: Cannot access memory at address 0xbf0000cc\nError occurred in Python command: Cannot access memory at address 0xbf0000cc\n....\n\nCan't reproduce on `x86_64` and `aarch64` are fine.\n\nIt is kind of random: if you just `insmod` manually and then immediately `./run-gdb --arch arm`, then it usually works.\n\nBut this fails most of the time: shell 1:\n\n....\n./run --arch arm --eval-after 'insmod hello.ko'\n....\n\nshell 2:\n\n....\n./run-gdb --arch arm\n....\n\nthen hit `Ctrl-C` on shell 2, and voila.\n\nThen:\n\n....\ncat /proc/modules\n....\n\nsays that the load address is:\n\n....\n0xbf000000\n....\n\nso it is close to the failing `0xbf0000cc`.\n\n`readelf`:\n\n....\n./run-toolchain readelf -- -s \"$(./getvar kernel_modules_build_subdir)/hello.ko\"\n....\n\ndoes not give any interesting hits at `cc`, no symbol was placed that far.\n\n[[gdb-module-init]]\n==== GDB module_init\n\nTODO find a more convenient method. We have working methods, but they are not ideal.\n\nThis is not very easy, since by the time the module finishes loading, and `lx-symbols` can work properly, `module_init` has already finished running!\n\nPossibly asked at:\n\n* https://stackoverflow.com/questions/37059320/debug-a-kernel-module-being-loaded\n* https://stackoverflow.com/questions/11888412/debug-the-init-module-call-of-a-linux-kernel-module\n\n[[gdb-module-init-step-into-it]]\n===== GDB module_init step into it\n\nThis is the best method we've found so far.\n\nThe kernel calls `module_init` synchronously, therefore it is not hard to step into that call.\n\nAs of 4.16, the call happens in `do_one_initcall`, so we can do in shell 1:\n\n....\n./run\n....\n\nshell 2 after boot finishes (because there are other calls to `do_init_module` at boot, presumably for the built-in modules):\n\n....\n./run-gdb do_one_initcall\n....\n\nthen step until the line:\n\n....\n833         ret = fn();\n....\n\nwhich does the actual call, and then step into it.\n\nFor the next time, you can also put a breakpoint there directly:\n\n....\n./run-gdb init/main.c:833\n....\n\nHow we found this out: first we got <<gdb-module-init-calculate-entry-address>> working, and then we did a `bt`. AKA cheating :-)\n\n[[gdb-module-init-calculate-entry-address]]\n===== GDB module_init calculate entry address\n\nThis works, but is a bit annoying.\n\nThe key observation is that the load address of kernel modules is deterministic: there is a pre allocated memory region https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt \"module mapping space\" filled from bottom up.\n\nSo once we find the address the first time, we can just reuse it afterwards, as long as we don't modify the module.\n\nDo a fresh boot and get the module:\n\n....\n./run --eval-after './pr_debug.sh;insmod fops.ko;./linux/poweroff.out'\n....\n\nThe boot must be fresh, because the load address changes every time we insert, even after removing previous modules.\n\nThe base address shows on terminal:\n\n....\n0xffffffffc0000000 .text\n....\n\nNow let's find the offset of `myinit`:\n\n....\n./run-toolchain readelf -- \\\n  -s \"$(./getvar kernel_modules_build_subdir)/fops.ko\" | \\\n  grep myinit\n....\n\nwhich gives:\n\n....\n    30: 0000000000000240    43 FUNC    LOCAL  DEFAULT    2 myinit\n....\n\nso the offset address is `0x240` and we deduce that the function will be placed at:\n\n....\n0xffffffffc0000000 + 0x240 = 0xffffffffc0000240\n....\n\nNow we can just do a fresh boot on shell 1:\n\n....\n./run --eval 'insmod fops.ko;./linux/poweroff.out' --gdb-wait\n....\n\nand on shell 2:\n\n....\n./run-gdb '*0xffffffffc0000240'\n....\n\nGDB then breaks, and `lx-symbols` works.\n\n[[gdb-module-init-break-at-the-end-of-sys-init-module]]\n===== GDB module_init break at the end of sys_init_module\n\nTODO not working. This could be potentially very convenient.\n\nThe idea here is to break at a point late enough inside `sys_init_module`, at which point `lx-symbols` can be called and do its magic.\n\nBeware that there are both `sys_init_module` and `sys_finit_module` syscalls, and `insmod` uses `fmodule_init` by default.\n\nBoth call `do_module_init` however, which is what `lx-symbols` hooks to.\n\nIf we try:\n\n....\nb sys_finit_module\n....\n\nthen hitting:\n\n....\nn\n....\n\ndoes not break, and insertion happens, likely because of optimizations? <<kernel-o0>>\n\nThen we try:\n\n....\nb do_init_module\n....\n\nA naive:\n\n....\nfin\n....\n\nalso fails to break!\n\nFinally, in despair we notice that <<pr-debug>> prints the kernel load address as explained at <<bypass-lx-symbols>>.\n\nSo, if we set a breakpoint just after that message is printed by searching where that happens on the Linux source code, we must be able to get the correct load address before `init_module` happens.\n\n[[gdb-module-init-add-trap-instruction]]\n===== GDB module_init add trap instruction\n\nThis is another possibility: we could modify the module source by adding a trap instruction of some kind.\n\nThis appears to be described at: https://www.linuxjournal.com/article/4525\n\nBut it refers to a `gdbstart` script which is not in the tree anymore and beyond my `git log` capabilities.\n\nAnd just adding:\n\n....\nasm( \" int $3\");\n....\n\ndirectly gives an <<oops,oops>> as I'd expect.\n\n==== Bypass lx-symbols\n\nUseless, but a good way to show how hardcore you are. Disable `lx-symbols` with:\n\n....\n./run-gdb --no-lxsymbols\n....\n\nFrom inside guest:\n\n....\ninsmod timer.ko\ncat /proc/modules\n....\n\nas mentioned at:\n\n* https://stackoverflow.com/questions/6384605/how-to-get-address-of-a-kernel-module-loaded-using-insmod/6385818\n* https://unix.stackexchange.com/questions/194405/get-base-address-and-size-of-a-loaded-kernel-module\n\nThis will give a line of form:\n\n....\nfops 2327 0 - Live 0xfffffffa00000000\n....\n\nAnd then tell GDB where the module was loaded with:\n\n....\nCtrl-C\nadd-symbol-file ../../../rootfs_overlay/x86_64/timer.ko 0xffffffffc0000000\n0xffffffffc0000000\n....\n\nAlternatively, if the module panics before you can read `/proc/modules`, there is a <<pr-debug>> which shows the load address:\n\n....\necho 8 > /proc/sys/kernel/printk\necho 'file kernel/module.c +p' > /sys/kernel/debug/dynamic_debug/control\n./linux/myinsmod.out hello.ko\n....\n\nAnd then search for a line of type:\n\n....\n[   84.877482]  0xfffffffa00000000 .text\n....\n\nTested on 4f4749148273c282e80b58c59db1b47049e190bf + 1.\n\n=== GDB step debug early boot\n\nTODO successfully debug the very first instruction that the Linux kernel runs, before `start_kernel`!\n\nBreak at the very first instruction executed by QEMU:\n\n....\n./run-gdb --no-continue\n....\n\nNote however that early boot parts appear to be relocated in memory somehow, and therefore:\n\n* you won't see the source location in GDB, only assembly\n* you won't be able to break by symbol in those early locations\n\nFurther discussion at: <<linux-kernel-entry-point>>.\n\nIn the specific case of gem5 aarch64 at least:\n\n* gem5 relocates the kernel in memory to a fixed location, see e.g. https://gem5.atlassian.net/browse/GEM5-787\n* `--param 'system.workload.early_kernel_symbols=True` should in theory duplicate the symbols to the correct physical location, but it was broken at one point: https://gem5.atlassian.net/browse/GEM5-785\n* gem5 executes directly from vmlinux, so there is no decompression code involved, so you actually immediately start running the \"true\" first instruction from `head.S` as described at: https://stackoverflow.com/questions/18266063/does-linux-kernel-have-main-function/33422401#33422401\n* once the MMU gets turned on at kernel symbol `__primary_switched`, the virtual address matches the ELF symbols, and you start seeing correct symbols without the need for `early_kernel_symbols`. This can be observed clearly with `function_trace = True`: https://stackoverflow.com/questions/64049487/how-to-trace-executed-guest-function-symbol-names-with-their-timestamp-in-gem5/64049488#64049488 which produces:\n+\n....\n0: _kernel_flags_le_lo32 (12500)\n12500: __crc_tcp_add_backlog (1000)\n13500: __crc_crypto_alg_tested (6500)\n20000: __crc_tcp_add_backlog (10000)\n30000: __crc_crypto_alg_tested (500)\n30500: __crc_scsi_is_host_device (5000)\n35500: __crc_crypto_alg_tested (1500)\n37000: __crc_scsi_is_host_device (4000)\n41000: __crc_crypto_alg_tested (3000)\n44000: __crc_tcp_add_backlog (263500)\n307500: __crc_crypto_alg_tested (975500)\n1283000: __crc_tcp_add_backlog (77191500)\n78474500: __crc_crypto_alg_tested (1000)\n78475500: __crc_scsi_is_host_device (19500)\n78495000: __crc_crypto_alg_tested (500)\n78495500: __crc_scsi_is_host_device (13500)\n78509000: __primary_switched (14000)\n78523000: memset (21118000)\n99641000: __primary_switched (2500)\n99643500: start_kernel (11000)\n....\n+\nso we see that `__primary_switched` is the first non-trash symbol (non-`__crc_*` and non-`_kernel_flags_*`, which are just informative symbols, not actual executable code)\n\n==== Linux kernel entry point\n\nTODO https://stackoverflow.com/questions/2589845/what-are-the-first-operations-that-the-linux-kernel-executes-on-boot\n\nAs mentioned at: <<gdb-step-debug-early-boot>>, the very first kernel instructions executed appear to be placed into memory at a different location than that of the kernel ELF section.\n\nAs a result, we are unable to break on early symbols such as:\n\n....\n./run-gdb extract_kernel\n./run-gdb main\n....\n\n<<gem5-execall-trace-format>>>> however does show the right symbols however! This could be because <<vmlinux-vs-bzimage-vs-zimage-vs-image,gem5 uses vmlinux to boot>>, which QEMU uses the compressed version, and as mentioned on the Stack Overflow answer, the entry point is actually a tiny decompresser routine.\n\nI also tried to hack `run-gdb` with:\n\n....\n@@ -81,7 +81,7 @@ else\n ${gdb} \\\n -q \\\\\n -ex 'add-auto-load-safe-path $(pwd)' \\\\\n--ex 'file vmlinux' \\\\\n+-ex 'file arch/arm/boot/compressed/vmlinux' \\\\\n -ex 'target remote localhost:${port}' \\\\\n ${brk} \\\n -ex 'continue' \\\\\n....\n\nand no I do have the symbols from `arch/arm/boot/compressed/vmlinux'`, but the breaks still don't work.\n\nv4.19 also added a `CONFIG_HAVE_KERNEL_UNCOMPRESSED=y` option for having the kernel uncompressed which could make following the startup easier, but it is only available on s390. `aarch64` however is already uncompressed by default, so might be the easiest one. See also: xref:vmlinux-vs-bzimage-vs-zimage-vs-image[xrefstyle=full].\n\nYou then need the associated `KERNEL_UNCOMPRESSED` to enable it if available:\n\n....\nconfig KERNEL_UNCOMPRESSED\n    bool \"None\"\n    depends on HAVE_KERNEL_UNCOMPRESSED\n....\n\n===== arm64 secondary CPU entry point\n\nIn gem5 aarch64 Linux v4.18, experimentally the entry point of secondary CPUs seems to be `secondary_holding_pen` as shown at https://gist.github.com/cirosantilli2/34a7bc450fcb6c1c1a910369be1fdd90\n\nWhat happens is that:\n\n* the bootloader goes in in WFE\n* the kernel writes the entry point to the secondary CPU (the address of `secondary_holding_pen`) with CPU0 at the address given to the kernel in the `cpu-release-addr` of the DTB\n* the kernel wakes up the bootloader with a SEV, and the bootloader boots to the address the kernel told it\n\nThe CPU0 action happens at: https://github.com/cirosantilli/linux/blob/v5.7/arch/arm64/kernel/smp_spin_table.c[]:\n\nHere's the code that writes the address and does SEV:\n\n....\nstatic int smp_spin_table_cpu_prepare(unsigned int cpu)\n{\n\t__le64 __iomem *release_addr;\n\n\tif (!cpu_release_addr[cpu])\n\t\treturn -ENODEV;\n\n\t/*\n\t * The cpu-release-addr may or may not be inside the linear mapping.\n\t * As ioremap_cache will either give us a new mapping or reuse the\n\t * existing linear mapping, we can use it to cover both cases. In\n\t * either case the memory will be MT_NORMAL.\n\t */\n\trelease_addr = ioremap_cache(cpu_release_addr[cpu],\n\t\t\t\t     sizeof(*release_addr));\n\tif (!release_addr)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * We write the release address as LE regardless of the native\n\t * endianess of the kernel. Therefore, any boot-loaders that\n\t * read this address need to convert this address to the\n\t * boot-loader's endianess before jumping. This is mandated by\n\t * the boot protocol.\n\t */\n\twriteq_relaxed(__pa_symbol(secondary_holding_pen), release_addr);\n\t__flush_dcache_area((__force void *)release_addr,\n\t\t\t    sizeof(*release_addr));\n\n\t/*\n\t * Send an event to wake up the secondary CPU.\n\t */\n\tsev();\n....\n\nand here's the code that reads the value from the DTB:\n\n....\nstatic int smp_spin_table_cpu_init(unsigned int cpu)\n{\n\tstruct device_node *dn;\n\tint ret;\n\n\tdn = of_get_cpu_node(cpu, NULL);\n\tif (!dn)\n\t\treturn -ENODEV;\n\n\t/*\n\t * Determine the address from which the CPU is polling.\n\t */\n\tret = of_property_read_u64(dn, \"cpu-release-addr\",\n\t\t\t\t   &cpu_release_addr[cpu]);\n....\n\n==== Linux kernel arch-agnostic entry point\n\n`start_kernel` is the first C function to be executed basically: https://stackoverflow.com/questions/18266063/does-kernel-have-main-function/33422401#33422401\n\nFor the earlier arch-specific entry point, see: <<linux-kernel-entry-point>>.\n\n==== Linux kernel early boot messages\n\nWhen booting Linux on a slow emulator like <<gem5>>, what you observe is that:\n\n* first nothing shows for a while\n* then at once, a bunch of message lines show at once followed on aarch64 Linux 5.4.3 by:\n+\n....\n[    0.081311] printk: console [ttyAMA0] enabled\n....\n\nThis means of course that all the previous messages had been generated earlier and stored, but were only printed to the terminal once the terminal itself was enabled.\n\nNotably for example the very first message:\n\n....\n[    0.000000] Booting Linux on physical CPU 0x0000000000 [0x410fd070]\n....\n\nhappens very early in the boot process.\n\nIf you get a failure before that, it will be hard to see the print messages.\n\nOne possible solution is to parse the dmesg buffer, gem5 actually implements that: <<gem5-m5out-system-dmesg-file>>.\n\n=== GDB step debug userland processes\n\nQEMU's `-gdb` GDB breakpoints are set on virtual addresses, so you can in theory debug userland processes as well.\n\n* https://stackoverflow.com/questions/26271901/is-it-possible-to-use-gdb-and-qemu-to-debug-linux-user-space-programs-and-kernel\n* https://stackoverflow.com/questions/16273614/debug-init-on-qemu-using-gdb\n\nYou will generally want to use <<gdbserver>> for this as it is more reliable, but this method can overcome the following limitations of `gdbserver`:\n\n* the emulator does not support host to guest networking. This seems to be the case for gem5 as explained at: xref:gem5-host-to-guest-networking[xrefstyle=full]\n* cannot see the start of the `init` process easily\n* `gdbserver` alters the working of the kernel, and makes your run less representative\n\nKnown limitations of direct userland debugging:\n\n* the kernel might switch context to another process or to the kernel itself e.g. on a system call, and then TODO confirm the PIC would go to weird places and source code would be missing.\n+\nSolutions to this are being researched at: xref:lx-ps[xrefstyle=full].\n* TODO step into shared libraries. If I attempt to load them explicitly:\n+\n....\n(gdb) sharedlibrary ../../staging/lib/libc.so.0\nNo loaded shared libraries match the pattern `../../staging/lib/libc.so.0'.\n....\n+\nsince GDB does not know that libc is loaded.\n\n==== GDB step debug userland custom init\n\nThis is the userland debug setup most likely to work, since at init time there is only one userland executable running.\n\nFor executables from the link:userland/[] directory such as link:userland/posix/count.c[]:\n\n* Shell 1:\n+\n....\n./run --gdb-wait --kernel-cli 'init=/lkmc/posix/count.out'\n....\n* Shell 2:\n+\n....\n./run-gdb --userland userland/posix/count.c main\n....\n+\nAlternatively, we could also pass the full path to the executable:\n+\n....\n./run-gdb --userland \"$(./getvar userland_build_dir)/posix/count.out\" main\n....\n+\nPath resolution is analogous to <<baremetal-setup-getting-started,that of `./run --baremetal`>>.\n\nThen, as soon as boot ends, we are left inside a debug session that looks just like what `gdbserver` would produce.\n\n==== GDB step debug userland BusyBox init\n\nBusyBox custom init process:\n\n* Shell 1:\n+\n....\n./run --gdb-wait --kernel-cli 'init=/bin/ls'\n....\n* Shell 2:\n+\n....\n./run-gdb --userland \"$(./getvar buildroot_build_build_dir)\"/busybox-*/busybox ls_main\n....\n\nThis follows BusyBox' convention of calling the main for each executable as `<exec>_main` since the `busybox` executable has many \"mains\".\n\nBusyBox default init process:\n\n* Shell 1:\n+\n....\n./run --gdb-wait\n....\n* Shell 2:\n+\n....\n./run-gdb --userland \"$(./getvar buildroot_build_build_dir)\"/busybox-*/busybox init_main\n....\n\n`init` cannot be debugged with <<gdbserver>> without modifying the source, or else `/sbin/init` exits early with:\n\n....\n\"must be run as PID 1\"\n....\n\n==== GDB step debug userland non-init\n\nNon-init process:\n\n* Shell 1:\n+\n....\n./run --gdb-wait\n....\n* Shell 2:\n+\n....\n./run-gdb --userland userland/linux/rand_check.c main\n....\n* Shell 1 after the boot finishes:\n+\n....\n./linux/rand_check.out\n....\n\nThis is the least reliable setup as there might be other processes that use the given virtual address.\n\n[[gdb-step-debug-userland-non-init-without-gdb-wait]]\n===== GDB step debug userland non-init without --gdb-wait\n\nTODO: if I try <<gdb-step-debug-userland-non-init>> without `--gdb-wait` and the `break main` that we do inside `./run-gdb` says:\n\n....\nCannot access memory at address 0x10604\n....\n\nand then GDB never breaks. Tested at ac8663a44a450c3eadafe14031186813f90c21e4 + 1.\n\nThe exact behaviour seems to depend on the architecture:\n\n* `arm`: happens always\n* `x86_64`: appears to happen only if you try to connect GDB as fast as possible, before init has been reached.\n* `aarch64`: could not observe the problem\n\nWe have also double checked the address with:\n\n....\n./run-toolchain --arch arm readelf -- \\\n  -s \"$(./getvar --arch arm userland_build_dir)/linux/myinsmod.out\" | \\\n  grep main\n....\n\nand from GDB:\n\n....\ninfo line main\n....\n\nand both give:\n\n....\n000105fc\n....\n\nwhich is just 8 bytes before `0x10604`.\n\n`gdbserver` also says `0x10604`.\n\nHowever, if do a `Ctrl-C` in GDB, and then a direct:\n\n....\nb *0x000105fc\n....\n\nit works. Why?!\n\nOn GEM5, x86 can also give the `Cannot access memory at address`, so maybe it is also unreliable on QEMU, and works just by coincidence.\n\n=== GDB call\n\nGDB can call functions as explained at: https://stackoverflow.com/questions/1354731/how-to-evaluate-functions-in-gdb\n\nHowever this is failing for us:\n\n* some symbols are not visible to `call` even though `b` sees them\n* for those that are, `call` fails with an E14 error\n\nE.g.: if we break on `__x64_sys_write` on `count.sh`:\n\n....\n>>> call printk(0, \"asdf\")\nCould not fetch register \"orig_rax\"; remote failure reply 'E14'\n>>> b printk\nBreakpoint 2 at 0xffffffff81091bca: file kernel/printk/printk.c, line 1824.\n>>> call fdget_pos(fd)\nNo symbol \"fdget_pos\" in current context.\n>>> b fdget_pos\nBreakpoint 3 at 0xffffffff811615e3: fdget_pos. (9 locations)\n>>>\n....\n\neven though `fdget_pos` is the first thing `__x64_sys_write` does:\n\n....\n581 SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,\n582         size_t, count)\n583 {\n584     struct fd f = fdget_pos(fd);\n....\n\nI also noticed that I get the same error:\n\n....\nCould not fetch register \"orig_rax\"; remote failure reply 'E14'\n....\n\nwhen trying to use:\n\n....\nfin\n....\n\non many (all?) functions.\n\nSee also: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/19\n\n=== GDB view ARM system registers\n\n`info all-registers` shows some of them.\n\nThe implementation is described at: https://stackoverflow.com/questions/46415059/how-to-observe-aarch64-system-registers-in-qemu/53043044#53043044\n\n=== GDB step debug multicore userland\n\nFor a more minimal baremetal multicore setup, see: xref:arm-baremetal-multicore[xrefstyle=full].\n\nWe can set and get which cores the Linux kernel allows a program to run on with `sched_getaffinity` and `sched_setaffinity`:\n\n....\n./run --cpus 2 --eval-after './linux/sched_getaffinity.out'\n....\n\nSource: link:userland/linux/sched_getaffinity.c[]\n\nSample output:\n\n....\nsched_getaffinity = 1 1\nsched_getcpu = 1\nsched_getaffinity = 1 0\nsched_getcpu = 0\n....\n\nWhich shows us that:\n\n* initially:\n** all 2 cores were enabled as shown by `sched_getaffinity = 1 1`\n** the process was randomly assigned to run on core 1 (the second one) as shown by `sched_getcpu = 1`. If we run this several times, it will also run on core 0 sometimes.\n* then we restrict the affinity to just core 0, and we see that the program was actually moved to core 0\n\nThe number of cores is modified as explained at: xref:number-of-cores[xrefstyle=full]\n\n`taskset` from the util-linux package sets the initial core affinity of a program:\n\n....\n./build-buildroot \\\n  --config 'BR2_PACKAGE_UTIL_LINUX=y' \\\n  --config 'BR2_PACKAGE_UTIL_LINUX_SCHEDUTILS=y' \\\n;\n./run --eval-after 'taskset -c 1,1 ./linux/sched_getaffinity.out'\n....\n\noutput:\n\n....\nsched_getaffinity = 0 1\nsched_getcpu = 1\nsched_getaffinity = 1 0\nsched_getcpu = 0\n....\n\nso we see that the affinity was restricted to the second core from the start.\n\nLet's do a QEMU observation to justify this example being in the repository with <<gdb-step-debug-userland-non-init,userland breakpoints>>.\n\nWe will run our `./linux/sched_getaffinity.out` infinitely many times, on core 0 and core 1 alternatively:\n\n....\n./run \\\n  --cpus 2 \\\n  --eval-after 'i=0; while true; do taskset -c $i,$i ./linux/sched_getaffinity.out; i=$((! $i)); done' \\\n  --gdb-wait \\\n;\n....\n\non another shell:\n\n....\n./run-gdb --userland \"$(./getvar userland_build_dir)/linux/sched_getaffinity.out\" main\n....\n\nThen, inside GDB:\n\n....\n(gdb) info threads\n  Id   Target Id         Frame\n* 1    Thread 1 (CPU#0 [running]) main () at sched_getaffinity.c:30\n  2    Thread 2 (CPU#1 [halted ]) native_safe_halt () at ./arch/x86/include/asm/irqflags.h:55\n(gdb) c\n(gdb) info threads\n  Id   Target Id         Frame\n  1    Thread 1 (CPU#0 [halted ]) native_safe_halt () at ./arch/x86/include/asm/irqflags.h:55\n* 2    Thread 2 (CPU#1 [running]) main () at sched_getaffinity.c:30\n(gdb) c\n....\n\nand we observe that `info threads` shows the actual correct core on which the process was restricted to run by `taskset`!\n\nWe should also try it out with kernel modules: https://stackoverflow.com/questions/28347876/set-cpu-affinity-on-a-loadable-linux-kernel-module\n\nTODO we then tried:\n\n....\n./run --cpus 2 --eval-after './linux/sched_getaffinity_threads.out'\n....\n\nand:\n\n....\n./run-gdb --userland \"$(./getvar userland_build_dir)/linux/sched_getaffinity_threads.out\"\n....\n\nto switch between two simultaneous live threads with different affinities, it just didn't break on our threads:\n\n....\nb main_thread_0\n....\n\nNote that secondary cores in gem5 are kind of broken however: <<gem5-gdb-step-debug-secondary-cores>>.\n\nBibliography:\n\n* https://stackoverflow.com/questions/10490756/how-to-use-sched-getaffinity-and-sched-setaffinity-in-linux-from-c/50117787#50117787\n** https://stackoverflow.com/questions/663958/how-to-control-which-core-a-process-runs-on/50210009#50210009\n** https://stackoverflow.com/questions/280909/cpu-affinity/54478296#54478296\n** https://unix.stackexchange.com/questions/73/how-can-i-set-the-processor-affinity-of-a-process-on-linux/441098#441098 (summary only)\n* https://stackoverflow.com/questions/42800801/how-to-use-gdb-to-debug-qemu-with-smp-symmetric-multiple-processors\n\n=== Linux kernel GDB scripts\n\nWe source the Linux kernel GDB scripts by default for `lx-symbols`, but they also contains some other goodies worth looking into.\n\nThose scripts basically parse some in-kernel data structures to offer greater visibility with GDB.\n\nAll defined commands are prefixed by `lx-`, so to get a full list just try to tab complete that.\n\nThere aren't as many as I'd like, and the ones that do exist are pretty self explanatory, but let's give a few examples.\n\nShow dmesg:\n\n....\nlx-dmesg\n....\n\nShow the <<kernel-command-line-parameters>>:\n\n....\nlx-cmdline\n....\n\nDump the device tree to a `fdtdump.dtb` file in the current directory:\n\n....\nlx-fdtdump\npwd\n....\n\nList inserted kernel modules:\n\n....\nlx-lsmod\n....\n\nSample output:\n\n....\nAddress            Module                  Size  Used by\n0xffffff80006d0000 hello                  16384  0\n....\n\nBibliography:\n\n* https://events.static.linuxfound.org/sites/events/files/slides/Debugging%20the%20Linux%20Kernel%20with%20GDB.pdf\n* https://wiki.linaro.org/LandingTeams/ST/GDB\n\n==== lx-ps\n\nList all processes:\n\n....\nlx-ps\n....\n\nSample output:\n\n....\n0xffff88000ed08000 1 init\n0xffff88000ed08ac0 2 kthreadd\n....\n\nThe second and third fields are obviously PID and process name.\n\nThe first one is more interesting, and contains the address of the `task_struct` in memory.\n\nThis can be confirmed with:\n\n....\np ((struct task_struct)*0xffff88000ed08000\n....\n\nwhich contains the correct PID for all threads I've tried:\n\n....\npid = 1,\n....\n\nTODO get the PC of the kthreads: https://stackoverflow.com/questions/26030910/find-program-counter-of-process-in-kernel Then we would be able to see where the threads are stopped in the code!\n\nOn ARM, I tried:\n\n....\ntask_pt_regs((struct thread_info *)((struct task_struct)*0xffffffc00e8f8000))->uregs[ARM_pc]\n....\n\nbut `task_pt_regs` is a `#define` and GDB cannot see defines without `-ggdb3`: https://stackoverflow.com/questions/2934006/how-do-i-print-a-defined-constant-in-gdb which are apparently not set?\n\nBibliography:\n\n* https://stackoverflow.com/questions/9561546/thread-aware-gdb-for-kernel\n* https://wiki.linaro.org/LandingTeams/ST/GDB\n* https://events.static.linuxfound.org/sites/events/files/slides/Debugging%20the%20Linux%20Kernel%20with%20GDB.pdf presentation: https://www.youtube.com/watch?v=pqn5hIrz3A8\n\n[[config-pid-in-contextidr]]\n===== CONFIG_PID_IN_CONTEXTIDR\n\nhttps://stackoverflow.com/questions/54133479/accessing-logical-software-thread-id-in-gem5 on ARM the kernel can store an indication of PID in the CONTEXTIDR_EL1 register, making that much easier to observe from simulators.\n\nIn particular, gem5 prints that number out by default on `ExecAll` messages!\n\nLet's test it out with <<linux-kernel-build-variants>> + <<gem5-restore-new-script>>:\n\n....\n./build-linux --arch aarch64 --linux-build-id CONFIG_PID_IN_CONTEXTIDR --config 'CONFIG_PID_IN_CONTEXTIDR=y'\n# Checkpoint run.\n./run --arch aarch64 --emulator gem5 --linux-build-id CONFIG_PID_IN_CONTEXTIDR --eval './gem5.sh'\n# Trace run.\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --gem5-readfile 'posix/getpid.out; posix/getpid.out' \\\n  --gem5-restore 1 \\\n  --linux-build-id CONFIG_PID_IN_CONTEXTIDR \\\n  --trace FmtFlag,ExecAll,-ExecSymbol \\\n;\n....\n\nThe terminal runs both programs which output their PID to stdout:\n\n....\npid=44\npid=45\n....\n\nBy quickly inspecting the `trace.txt` file, we immediately notice that the `system.cpu: A<n>` part of the logs, which used to always be `system.cpu: A0`, now has a few different values! Nice!\n\nWe can briefly summarize those values by removing repetitions:\n\n....\ncut -d' ' -f4 \"$(./getvar --arch aarch64 --emulator gem5 trace_txt_file)\" | uniq -c\n....\n\ngives:\n\n....\n  97227 A39\n 147476 A38\n 222052 A40\n      1 terminal\n1117724 A40\n  27529 A31\n  43868 A40\n  27487 A31\n 138349 A40\n  13781 A38\n 231246 A40\n  25536 A38\n  28337 A40\n 214799 A38\n 963561 A41\n  92603 A38\n  27511 A31\n 224384 A38\n 564949 A42\n 182360 A38\n 729009 A43\n   8398 A23\n  20200 A10\n 636848 A43\n 187995 A44\n  27529 A31\n  70071 A44\n  16981 A0\n 623806 A44\n  16981 A0\n 139319 A44\n  24487 A0\n 174986 A44\n  25420 A0\n  89611 A44\n  16981 A0\n 183184 A44\n  24728 A0\n  89608 A44\n  17226 A0\n 899075 A44\n  24974 A0\n 250608 A44\n 137700 A43\n1497997 A45\n 227485 A43\n 138147 A38\n 482646 A46\n....\n\nI'm not smart enough to be able to deduce all of those IDs, but we can at least see that:\n\n* A44 and A45 are there as expected from stdout!\n* A39 must be the end of the execution of `m5 checkpoint`\n* so we guess that A38 is the shell as it comes next\n* the weird \"terminal\" line is `336969745500: system.terminal: attach terminal 0`\n* which is the shell PID? I should have printed that as well :-)\n* why are there so many other PIDs? This was supposed to be a silent system without daemons!\n* A0 is presumably the kernel. However we see process switches without going into A0, so I'm not sure how, it appears to count kernel instructions as part of processes\n* A46 has to be the `m5 exit` call\n\nOr if you want to have some real fun, try: link:baremetal/arch/aarch64/contextidr_el1.c[]:\n\n....\n./run --arch aarch64 --emulator gem5 --baremetal baremetal/arch/aarch64/contextidr_el1.c --trace-insts-stdout\n....\n\nin which we directly set the register ourselves! Output excerpt:\n\n....\n  31500: system.cpu: A0 T0 : @main+12    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000001 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  32000: system.cpu: A1 T0 : @main+16    :   msr   contextidr_el1, x0 : IntAlu :  D=0x0000000000000001  flags=(IsInteger|IsSerializeAfter|IsNonSpeculative)\n  32500: system.cpu: A1 T0 : @main+20    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000001 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  33000: system.cpu: A1 T0 : @main+24    :   add   w0, w0, #1         : IntAlu :  D=0x0000000000000002  flags=(IsInteger)\n  33500: system.cpu: A1 T0 : @main+28    :   str   x0, [sp, #12]      : MemWrite :  D=0x0000000000000002 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsStore)\n  34000: system.cpu: A1 T0 : @main+32    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000002 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  34500: system.cpu: A1 T0 : @main+36    :   subs   w0, #9            : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n  35000: system.cpu: A1 T0 : @main+40    :   b.le   <main+12>         : IntAlu :   flags=(IsControl|IsDirectControl|IsCondControl)\n  35500: system.cpu: A1 T0 : @main+12    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000002 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  36000: system.cpu: A2 T0 : @main+16    :   msr   contextidr_el1, x0 : IntAlu :  D=0x0000000000000002  flags=(IsInteger|IsSerializeAfter|IsNonSpeculative)\n  36500: system.cpu: A2 T0 : @main+20    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000002 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  37000: system.cpu: A2 T0 : @main+24    :   add   w0, w0, #1         : IntAlu :  D=0x0000000000000003  flags=(IsInteger)\n  37500: system.cpu: A2 T0 : @main+28    :   str   x0, [sp, #12]      : MemWrite :  D=0x0000000000000003 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsStore)\n  38000: system.cpu: A2 T0 : @main+32    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000003 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  38500: system.cpu: A2 T0 : @main+36    :   subs   w0, #9            : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n  39000: system.cpu: A2 T0 : @main+40    :   b.le   <main+12>         : IntAlu :   flags=(IsControl|IsDirectControl|IsCondControl)\n  39500: system.cpu: A2 T0 : @main+12    :   ldr   x0, [sp, #12]      : MemRead :  D=0x0000000000000003 A=0x82fffffc  flags=(IsInteger|IsMemRef|IsLoad)\n  40000: system.cpu: A3 T0 : @main+16    :   msr   contextidr_el1, x0 : IntAlu :  D=0x0000000000000003  flags=(IsInteger|IsSerializeAfter|IsNonSpeculative)\n....\n\n<<armarm8-fa>> D13.2.27 \"CONTEXTIDR_EL1, Context ID Register (EL1)\" documents `CONTEXTIDR_EL1` as:\n\n____\nIdentifies the current Process Identifier.\n\nThe value of the whole of this register is called the Context ID and is used by:\n\n* The debug logic, for Linked and Unlinked Context ID matching.\n* The trace logic, to identify the current process.\n\nThe significance of this register is for debug and trace use only.\n____\n\nTested on 145769fc387dc5ee63ec82e55e6b131d9c968538 + 1.\n\n=== Debug the GDB remote protocol\n\nFor when it breaks again, or you want to add a new feature!\n\n....\n./run --debug\n./run-gdb --before '-ex \"set remotetimeout 99999\" -ex \"set debug remote 1\"' start_kernel\n....\n\nSee also: https://stackoverflow.com/questions/13496389/gdb-remote-protocol-how-to-analyse-packets\n\n[[remote-g-packet]]\n==== Remote 'g' packet reply is too long\n\nThis error means that the GDB server, e.g. in QEMU, sent more registers than the GDB client expected.\n\nThis can happen for the following reasons:\n\n* you set the architecture of the client wrong, often 32 vs 64 bit as mentioned at: https://stackoverflow.com/questions/4896316/gdb-remote-cross-debugging-fails-with-remote-g-packet-reply-is-too-long\n* there is a bug in the GDB server and the XML description does not match the number of registers actually sent\n* the GDB server does not send XML target descriptions and your GDB expects a different number of registers by default. E.g., gem5 d4b3e064adeeace3c3e7d106801f95c14637c12f does not send the XML files\n\nThe XML target description format is described a bit further at: https://stackoverflow.com/questions/46415059/how-to-observe-aarch64-system-registers-in-qemu/53043044#53043044\n\n== KGDB\n\nKGDB is kernel dark magic that allows you to GDB the kernel on real hardware without any extra hardware support.\n\nIt is useless with QEMU since we already have full system visibility with `-gdb`. So the goal of this setup is just to prepare you for what to expect when you will be in the treches of real hardware.\n\nKGDB is cheaper than JTAG (free) and easier to setup (all you need is serial), but with less visibility as it depends on the kernel working, so e.g.: dies on panic, does not see boot sequence.\n\nFirst run the kernel with:\n\n....\n./run --kgdb\n....\n\nthis passes the following options on the kernel CLI:\n\n....\nkgdbwait kgdboc=ttyS1,115200\n....\n\n`kgdbwait` tells the kernel to wait for KGDB to connect.\n\nSo the kernel sets things up enough for KGDB to start working, and then boot pauses waiting for connection:\n\n....\n<6>[    4.866050] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled\n<6>[    4.893205] 00:05: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\n<6>[    4.916271] 00:06: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A\n<6>[    4.987771] KGDB: Registered I/O driver kgdboc\n<2>[    4.996053] KGDB: Waiting for connection from remote gdb...\n\nEntering kdb (current=0x(____ptrval____), pid 1) on processor 0 due to Keyboard Entry\n[0]kdb>\n....\n\nKGDB expects the connection at `ttyS1`, our second serial port after `ttyS0` which contains the terminal.\n\nThe last line is the KDB prompt, and is covered at: xref:kdb[xrefstyle=full]. Typing now shows nothing because that prompt is expecting input from `ttyS1`.\n\nInstead, we connect to the serial port `ttyS1` with GDB:\n\n....\n./run-gdb --kgdb --no-continue\n....\n\nOnce GDB connects, it is left inside the function `kgdb_breakpoint`.\n\nSo now we can set breakpoints and continue as usual.\n\nFor example, in GDB:\n\n....\ncontinue\n....\n\nThen in QEMU:\n\n....\n./count.sh &\n./kgdb.sh\n....\n\nlink:rootfs_overlay/lkmc/kgdb.sh[] pauses the kernel for KGDB, and gives control back to GDB.\n\nAnd now in GDB we do the usual:\n\n....\nbreak __x64_sys_write\ncontinue\ncontinue\ncontinue\ncontinue\n....\n\nAnd now you can count from KGDB!\n\nIf you do: `break __x64_sys_write` immediately after `./run-gdb --kgdb`, it fails with `KGDB: BP remove failed: <address>`. I think this is because it would break too early on the boot sequence, and KGDB is not yet ready.\n\nSee also:\n\n* https://github.com/torvalds/linux/blob/v4.9/Documentation/DocBook/kgdb.tmpl\n* https://stackoverflow.com/questions/22004616/qemu-kernel-debugging-with-kgdb/44197715#44197715\n\n=== KGDB ARM\n\nTODO: we would need a second serial for KGDB to work, but it is not currently supported on `arm` and `aarch64` with `-M virt` that we use: https://unix.stackexchange.com/questions/479085/can-qemu-m-virt-on-arm-aarch64-have-multiple-serial-ttys-like-such-as-pl011-t/479340#479340\n\nOne possible workaround for this would be to use <<kdb-arm>>.\n\nMain more generic question: https://stackoverflow.com/questions/14155577/how-to-use-kgdb-on-arm\n\n=== KGDB kernel modules\n\nJust works as you would expect:\n\n....\ninsmod timer.ko\n./kgdb.sh\n....\n\nIn GDB:\n\n....\nbreak lkmc_timer_callback\ncontinue\ncontinue\ncontinue\n....\n\nand you now control the count.\n\n=== KDB\n\nKDB is a way to use KDB directly in your main console, without GDB.\n\nAdvantage over KGDB: you can do everything in one serial. This can actually be important if you only have one serial for both shell and .\n\nDisadvantage: not as much functionality as GDB, especially when you use Python scripts. Notably, TODO confirm you can't see the the kernel source code and line step as from GDB, since the kernel source is not available on guest (ah, if only debugging information supported full source, or if the kernel had a crazy mechanism to embed it).\n\nRun QEMU as:\n\n....\n./run --kdb\n....\n\nThis passes `kgdboc=ttyS0` to the Linux CLI, therefore using our main console. Then QEMU:\n\n....\n[0]kdb> go\n....\n\nAnd now the `kdb>` prompt is responsive because it is listening to the main console.\n\nAfter boot finishes, run the usual:\n\n....\n./count.sh &\n./kgdb.sh\n....\n\nAnd you are back in KDB. Now you can count with:\n\n....\n[0]kdb> bp __x64_sys_write\n[0]kdb> go\n[0]kdb> go\n[0]kdb> go\n[0]kdb> go\n....\n\nAnd you will break whenever `__x64_sys_write` is hit.\n\nYou can get see further commands with:\n\n....\n[0]kdb> help\n....\n\nThe other KDB commands allow you to step instructions, view memory, registers and some higher level kernel runtime data similar to the superior GDB Python scripts.\n\n==== KDB graphic\n\nYou can also use KDB directly from the <<graphics,graphic>> window with:\n\n....\n./run --graphic --kdb\n....\n\nThis setup could be used to debug the kernel on machines without serial, such as modern desktops.\n\nThis works because `--graphics` adds `kbd` (which stands for `KeyBoarD`!) to `kgdboc`.\n\n==== KDB ARM\n\nTODO neither `arm` and `aarch64` are working as of 1cd1e58b023791606498ca509256cc48e95e4f5b + 1.\n\n`arm` seems to place and hit the breakpoint correctly, but no matter how many `go` commands I do, the `count.sh` stdout simply does not show.\n\n`aarch64` seems to place the breakpoint correctly, but after the first `go` the kernel oopses with warning:\n\n....\nWARNING: CPU: 0 PID: 46 at /root/linux-kernel-module-cheat/submodules/linux/kernel/smp.c:416 smp_call_function_many+0xdc/0x358\n....\n\nand stack trace:\n\n....\nsmp_call_function_many+0xdc/0x358\nkick_all_cpus_sync+0x30/0x38\nkgdb_flush_swbreak_addr+0x3c/0x48\ndbg_deactivate_sw_breakpoints+0x7c/0xb8\nkgdb_cpu_enter+0x284/0x6a8\nkgdb_handle_exception+0x138/0x240\nkgdb_brk_fn+0x2c/0x40\nbrk_handler+0x7c/0xc8\ndo_debug_exception+0xa4/0x1c0\nel1_dbg+0x18/0x78\n__arm64_sys_write+0x0/0x30\nel0_svc_handler+0x74/0x90\nel0_svc+0x8/0xc\n....\n\nMy theory is that every serious ARM developer has JTAG, and no one ever tests this, and the kernel code is just broken.\n\n== gdbserver\n\nStep debug userland processes to understand how they are talking to the kernel.\n\nFirst build `gdbserver` into the root filesystem:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_GDB=y'\n....\n\nThen on guest, to debug link:userland/linux/rand_check.c[]:\n\n....\n./gdbserver.sh ./c/command_line_arguments.out asdf qwer\n....\n\nSource: link:rootfs_overlay/lkmc/gdbserver.sh[].\n\nAnd on host:\n\n....\n./run-gdb --gdbserver --userland userland/c/command_line_arguments.c main\n....\n\nor alternatively with the path to the executable itself:\n\n....\n./run --gdbserver --userland \"$(./getvar userland_build_dir)/c/command_line_arguments.out\"\n....\n\nBibliography: https://reverseengineering.stackexchange.com/questions/8829/cross-debugging-for-arm-mips-elf-with-qemu-toolchain/16214#16214\n\n=== gdbserver BusyBox\n\nAnalogous to <<gdb-step-debug-userland-processes>>:\n\n....\n./gdbserver.sh ls\n....\n\non host you need:\n\n....\n./run-gdb --gdbserver --userland \"$(./getvar buildroot_build_build_dir)\"/busybox-*/busybox ls_main\n....\n\n=== gdbserver libc\n\nOur setup gives you the rare opportunity to step debug libc and other system libraries.\n\nFor example in the guest:\n\n....\n./gdbserver.sh ./posix/count.out\n....\n\nThen on host:\n\n....\n./run-gdb --gdbserver --userland userland/posix/count.c main\n....\n\nand inside GDB:\n\n....\nbreak sleep\ncontinue\n....\n\nAnd you are now left inside the `sleep` function of our default libc implementation uclibc https://cgit.uclibc-ng.org/cgi/cgit/uclibc-ng.git/tree/libc/unistd/sleep.c?h=v1.0.30#n91[`libc/unistd/sleep.c`]!\n\nYou can also step into the `sleep` call:\n\n....\nstep\n....\n\nThis is made possible by the GDB command that we use by default:\n\n....\nset sysroot ${common_buildroot_build_dir}/staging\n....\n\nwhich automatically finds unstripped shared libraries on the host for us.\n\nSee also: https://stackoverflow.com/questions/8611194/debugging-shared-libraries-with-gdbserver/45252113#45252113\n\n=== gdbserver dynamic loader\n\nTODO: try to step debug the dynamic loader. Would be even easier if `starti` is available: https://stackoverflow.com/questions/10483544/stopping-at-the-first-machine-code-instruction-in-gdb\n\nBibliography: https://stackoverflow.com/questions/20114565/gdb-step-into-dynamic-linkerld-so-code\n\n== CPU architecture\n\nThe portability of the kernel and toolchains is amazing: change an option and most things magically work on completely different hardware.\n\nTo use `arm` instead of x86 for example:\n\n....\n./build-buildroot --arch arm\n./run --arch arm\n....\n\nDebug:\n\n....\n./run --arch arm --gdb-wait\n# On another terminal.\n./run-gdb --arch arm\n....\n\nWe also have one letter shorthand names for the architectures and `--arch` option:\n\n....\n# aarch64\n./run -a A\n# arm\n./run -a a\n# x86_64\n./run -a x\n....\n\nKnown quirks of the supported architectures are documented in this section.\n\n[[x86-64]]\n=== x86_64\n\n==== ring0\n\nThis example illustrates how reading from the x86 control registers with `mov crX, rax` can only be done from kernel land on ring0.\n\nFrom kernel land:\n\n....\ninsmod ring0.ko\n....\n\nworks and output the registers, for example:\n\n....\ncr0 = 0xFFFF880080050033\ncr2 = 0xFFFFFFFF006A0008\ncr3 = 0xFFFFF0DCDC000\n....\n\nHowever if we try to do it from userland:\n\n....\n./ring0.out\n....\n\nstdout gives:\n\n....\nSegmentation fault\n....\n\nand dmesg outputs:\n\n....\ntraps: ring0.out[55] general protection ip:40054c sp:7fffffffec20 error:0 in ring0.out[400000+1000]\n....\n\nSources:\n\n* link:kernel_modules/ring0.c[]\n* link:lkmc/ring0.h[]\n* link:userland/arch/x86_64/ring0.c[]\n\nIn both cases, we attempt to run the exact same code which is shared on the `ring0.h` header file.\n\nBibliography:\n\n* https://stackoverflow.com/questions/7415515/how-to-access-the-control-registers-cr0-cr2-cr3-from-a-program-getting-segmenta/7419306#7419306\n* https://stackoverflow.com/questions/18717016/what-are-ring-0-and-ring-3-in-the-context-of-operating-systems/44483439#44483439\n\n=== arm\n\n==== Run arm executable in aarch64\n\nTODO Can you run arm executables in the aarch64 guest? https://stackoverflow.com/questions/22460589/armv8-running-legacy-32-bit-applications-on-64-bit-os/51466709#51466709\n\nI've tried:\n\n....\n./run-toolchain --arch aarch64 gcc -- -static ~/test/hello_world.c -o \"$(./getvar p9_dir)/a.out\"\n./run --arch aarch64 --eval-after '/mnt/9p/data/a.out'\n....\n\nbut it fails with:\n\n....\na.out: line 1: syntax error: unexpected word (expecting \")\")\n....\n\n=== MIPS\n\nWe used to \"support\" it until f8c0502bb2680f2dbe7c1f3d7958f60265347005 (it booted) but dropped since one was testing it often.\n\nIf you want to revive and maintain it, send a pull request.\n\n=== Other architectures\n\nIt should not be too hard to port this repository to any architecture that Buildroot supports. Pull requests are welcome.\n\n== init\n\nWhen the Linux kernel finishes booting, it runs an executable as the first and only userland process. This executable is called the `init` program.\n\nThe init process is then responsible for setting up the entire userland (or destroying everything when you want to have fun).\n\nThis typically means reading some configuration files (e.g. `/etc/initrc`) and forking a bunch of userland executables based on those files, including the very interactive shell that we end up on.\n\nsystemd provides a \"popular\" init implementation for desktop distros as of 2017.\n\nBusyBox provides its own minimalistic init implementation which Buildroot, and therefore this repo, uses by default.\n\nThe `init` program can be either an executable shell text file, or a compiled ELF file. It becomes easy to accept this once you see that the `exec` system call handles both cases equally: https://unix.stackexchange.com/questions/174062/can-the-init-process-be-a-shell-script-in-linux/395375#395375\n\nThe `init` executable is searched for in a list of paths in the root filesystem, including `/init`, `/sbin/init` and a few others. For more details see: xref:path-to-init[xrefstyle=full]\n\n=== Replace init\n\nTo have more control over the system, you can replace BusyBox's init with your own.\n\nThe most direct way to replace `init` with our own is to just use the `init=` <<kernel-command-line-parameters,command line parameter>> directly:\n\n....\n./run --kernel-cli 'init=/lkmc/count.sh'\n....\n\nThis just counts every second forever and does not give you a shell.\n\nThis method is not very flexible however, as it is hard to reliably pass multiple commands and command line arguments to the init with it, as explained at: xref:init-environment[xrefstyle=full].\n\nFor this reason, we have created a more robust helper method with the `--eval` option:\n\n....\n./run --eval 'echo \"asdf qwer\";insmod hello.ko;./linux/poweroff.out'\n....\n\nIt is basically a shortcut for:\n\n....\n./run --kernel-cli 'init=/lkmc/eval_base64.sh - lkmc_eval=\"insmod hello.ko;./linux/poweroff.out\"'\n....\n\nSource: link:rootfs_overlay/lkmc/eval_base64.sh[].\n\nThis allows quoting and newlines by base64 encoding on host, and decoding on guest, see: xref:kernel-command-line-parameters-escaping[xrefstyle=full].\n\nIt also automatically chooses between `init=` and `rcinit=` for you, see: xref:path-to-init[xrefstyle=full]\n\n`--eval` replaces BusyBox' init completely, which makes things more minimal, but also has has the following consequences:\n\n* `/etc/fstab` mounts are not done, notably `/proc` and `/sys`, test it out with:\n+\n....\n./run --eval 'echo asdf;ls /proc;ls /sys;echo qwer'\n....\n* no shell is launched at the end of boot for you to interact with the system. You could explicitly add a `sh` at the end of your commands however:\n+\n....\n./run --eval 'echo hello;sh'\n....\n\nThe best way to overcome those limitations is to use: xref:init-busybox[xrefstyle=full]\n\nIf the script is large, you can add it to a gitignored file and pass that to `--eval` as in:\n\n....\necho '\ncd /lkmc\ninsmod hello.ko\n./linux/poweroff.out\n' > data/gitignore.sh\n./run --eval \"$(cat data/gitignore.sh)\"\n....\n\nor add it to a file to the root filesystem guest and rebuild:\n\n....\necho '#!/bin/sh\ncd /lkmc\ninsmod hello.ko\n./linux/poweroff.out\n' > rootfs_overlay/lkmc/gitignore.sh\nchmod +x rootfs_overlay/lkmc/gitignore.sh\n./build-buildroot\n./run --kernel-cli 'init=/lkmc/gitignore.sh'\n....\n\nRemember that if your init returns, the kernel will panic, there are just two non-panic possibilities:\n\n* run forever in a loop or long sleep\n* `poweroff` the machine\n\n==== poweroff.out\n\nJust using BusyBox' `poweroff` at the end of the `init` does not work and the kernel panics:\n\n....\n./run --eval poweroff\n....\n\nbecause BusyBox' `poweroff` tries to do some fancy stuff like killing init, likely to allow userland to shutdown nicely.\n\nBut this fails when we are `init` itself!\n\nBusyBox' `poweroff` works more brutally and effectively if you add `-f`:\n\n....\n./run --eval 'poweroff -f'\n....\n\nbut why not just use our minimal `./linux/poweroff.out` and be done with it?\n\n....\n./run --eval './linux/poweroff.out'\n....\n\nSource: link:userland/linux/poweroff.c[]\n\nThis also illustrates how to shutdown the computer from C: https://stackoverflow.com/questions/28812514/how-to-shutdown-linux-using-c-or-qt-without-call-to-system\n\n[[sleep-forever-out]]\n==== sleep_forever.out\n\nI dare you to guess what this does:\n\n....\n./run --eval './posix/sleep_forever.out'\n....\n\nSource: link:userland/posix/sleep_forever.c[]\n\nThis executable is a convenient simple init that does not panic and sleeps instead.\n\n[[time-boot-out]]\n==== time_boot.out\n\nGet a reasonable answer to \"how long does boot take in guest time?\":\n\n....\n./run --eval-after './linux/time_boot.c'\n....\n\nSource: link:userland/linux/time_boot.c[]\n\nThat executable writes to `dmesg` directly through `/dev/kmsg` a message of type:\n\n....\n[    2.188242] /path/to/linux-kernel-module-cheat/userland/linux/time_boot.c\n....\n\nwhich tells us that boot took `2.188242` seconds based on the dmesg timestamp.\n\nBibliography: https://stackoverflow.com/questions/12683169/measure-time-taken-for-linux-kernel-from-bootup-to-userpace/46517014#46517014\n\n[[init-busybox]]\n=== Run command at the end of BusyBox init\n\nUse the `--eval-after` option is for you rely on something that BusyBox' init set up for you like `/etc/fstab`:\n\n....\n./run --eval-after 'echo asdf;ls /proc;ls /sys;echo qwer'\n....\n\nAfter the commands run, you are left on an interactive shell.\n\nThe above command is basically equivalent to:\n\n....\n./run --kernel-cli-after-dash 'lkmc_eval=\"insmod hello.ko;./linux/poweroff.out;\"'\n....\n\nwhere the `lkmc_eval` option gets evaled by our default link:rootfs_overlay/etc/init.d/S98[] startup script.\n\nExcept that `--eval-after` is smarter and uses `base64` encoding.\n\nAlternatively, you can also add the comamdns to run to a new `init.d` entry to run at the end o the BusyBox init:\n\n....\ncp rootfs_overlay/etc/init.d/S98 rootfs_overlay/etc/init.d/S99.gitignore\nvim rootfs_overlay/etc/init.d/S99.gitignore\n./build-buildroot\n./run\n....\n\nand they will be run automatically before the login prompt.\n\nScripts under `/etc/init.d` are run by `/etc/init.d/rcS`, which gets called by the line `::sysinit:/etc/init.d/rcS` in link:rootfs_overlay/etc/inittab[`/etc/inittab`].\n\n=== Path to init\n\nThe init is selected at:\n\n* initrd or initramfs system: `/init`, a custom one can be set with the `rdinit=` <<kernel-command-line-parameters,kernel command line parameter>>\n* otherwise: default is `/sbin/init`, followed by some other paths, a custom one can be set with `init=`\n\nMore details: https://unix.stackexchange.com/questions/30414/what-can-make-passing-init-path-to-program-to-the-kernel-not-start-program-as-i/430614#430614\n\nThe final init that actually got selected is shown on Linux v5.9.2 a line of type:\n\n```\n<6>[    0.309984] Run /sbin/init as init process\n```\n\nat the very end of the boot logs.\n\n=== Init environment\n\nDocumented at https://www.kernel.org/doc/html/v4.14/admin-guide/kernel-parameters.html[]:\n\n____\nThe kernel parses parameters from the kernel command line up to \"-\"; if it doesn't recognize a parameter and it doesn't contain a '.', the parameter gets passed to init: parameters with '=' go into init's environment, others are passed as command line arguments to init. Everything after \"-\" is passed as an argument to init.\n____\n\nAnd you can try it out with:\n\n....\n./run --kernel-cli 'init=/lkmc/linux/init_env_poweroff.out' --kernel-cli-after-dash 'asdf=qwer zxcv'\n....\n\nFrom the <<dry-run,generated QEMU command>>, we see that the kernel CLI at LKMC 69f5745d3df11d5c741551009df86ea6c61a09cf now contains:\n\n....\ninit=/lkmc/linux/init_env_poweroff.out console=ttyS0 - lkmc_home=/lkmc asdf=qwer zxcv\n....\n\nand the init program outputs:\n\n....\nargs:\n/lkmc/linux/init_env_poweroff.out\n-\nzxcv\n\nenv:\nHOME=/\nTERM=linux\nlkmc_home=/lkmc\nasdf=qwer\n....\n\nSource: link:userland/linux/init_env_poweroff.c[].\n\nAs of the Linux kernel v5.7 (possibly earlier, I've skipped a few releases), boot also shows the init arguments and environment very clearly, which is a great addition:\n\n....\n<6>[    0.309984] Run /sbin/init as init process\n<7>[    0.309991]   with arguments:\n<7>[    0.309997]     /sbin/init\n<7>[    0.310004]     nokaslr\n<7>[    0.310010]     -\n<7>[    0.310016]   with environment:\n<7>[    0.310022]     HOME=/\n<7>[    0.310028]     TERM=linux\n<7>[    0.310035]     earlyprintk=pl011,0x1c090000\n<7>[    0.310041]     lkmc_home=/lkmc\n....\n\n==== init arguments\n\nThe annoying dash `-` gets passed as a parameter to `init`, which makes it impossible to use this method for most non custom executables.\n\nArguments with dots that come after `-` are still treated specially (of the form `subsystem.somevalue`) and disappear, from args, e.g.:\n\n....\n./run --kernel-cli 'init=/lkmc/linux/init_env_poweroff.out' --kernel-cli-after-dash '/lkmc/linux/poweroff.out'\n....\n\noutputs:\n\n....\nargs\n/lkmc/linux/init_env_poweroff.out\n-\nab\n....\n\nso see how `a.b` is gone.\n\nThe simple workaround is to just create a shell script that does it, e.g. as we've done at: link:rootfs_overlay/lkmc/gem5_exit.sh[].\n\n==== init environment env\n\nWait, where do `HOME` and `TERM` come from? (greps the kernel). Ah, OK, the kernel sets those by default: https://github.com/torvalds/linux/blob/94710cac0ef4ee177a63b5227664b38c95bbf703/init/main.c#L173\n\n....\nconst char *envp_init[MAX_INIT_ENVS+2] = { \"HOME=/\", \"TERM=linux\", NULL, };\n....\n\n==== BusyBox shell init environment\n\nOn top of the Linux kernel, the BusyBox `/bin/sh` shell will also define other variables.\n\nWe can explore the shenanigans that the shell adds on top of the Linux kernel with:\n\n....\n./run --kernel-cli 'init=/bin/sh'\n....\n\nFrom there we observe that:\n\n....\nenv\n....\n\ngives:\n\n....\nSHLVL=1\nHOME=/\nTERM=linux\nPWD=/\n....\n\ntherefore adding `SHLVL` and `PWD` to the default kernel exported variables.\n\nFurthermore, to increase confusion, if you list all non-exported shell variables https://askubuntu.com/questions/275965/how-to-list-all-variables-names-and-their-current-values with:\n\n....\nset\n....\n\nthen it shows more variables, notably:\n\n....\nPATH='/sbin:/usr/sbin:/bin:/usr/bin'\n....\n\n===== BusyBox shell initrc files\n\nLogin shells source some default files, notably:\n\n....\n/etc/profile\n$HOME/.profile\n....\n\nIn our case, `HOME` is set to `/` presumably by `init` at: https://git.busybox.net/busybox/tree/init/init.c?id=5059653882dbd86e3bbf48389f9f81b0fac8cd0a#n1114\n\nWe provide `/.profile` from link:rootfs_overlay/.profile[], and use the default BusyBox `/etc/profile`.\n\nThe shell knows that it is a login shell if the first character of `argv[0]` is `-`, see also: https://stackoverflow.com/questions/2050961/is-argv0-name-of-executable-an-accepted-standard-or-just-a-common-conventi/42291142#42291142\n\nWhen we use just `init=/bin/sh`, the Linux kernel sets `argv[0]` to `/bin/sh`, which does not start with `-`.\n\nHowever, if you use `::respawn:-/bin/sh` on inttab described at <<tty>>, BusyBox' init sets `argv[0][0]` to `-`, and so does `getty`. This can be observed with:\n\n....\ncat /proc/$$/cmdline\n....\n\nwhere `$$` is the PID of the shell itself: https://stackoverflow.com/questions/21063765/get-pid-in-shell-bash\n\nBibliography: https://unix.stackexchange.com/questions/176027/ash-profile-configuration-file\n\n== initrd\n\nThe kernel can boot from an CPIO file, which is a directory serialization format much like tar: https://superuser.com/questions/343915/tar-vs-cpio-what-is-the-difference\n\nThe bootloader, which for us is provided by QEMU itself, is then configured to put that CPIO into memory, and tell the kernel that it is there.\n\nThis is very similar to the kernel image itself, which already gets put into memory by the QEMU `-kernel` option.\n\nWith this setup, you don't even need to give a root filesystem to the kernel: it just does everything in memory in a ramfs.\n\nTo enable initrd instead of the default ext2 disk image, do:\n\n....\n./build-buildroot --initrd\n./run --initrd\n....\n\nBy looking at the QEMU run command generated, you can see that we didn't give the `-drive` option at all:\n\n....\ncat \"$(./getvar run_dir)/run.sh\"\n....\n\nInstead, we used the QEMU `-initrd` option to point to the `.cpio` filesystem that Buildroot generated for us.\n\nTry removing that `-initrd` option to watch the kernel panic without rootfs at the end of boot.\n\nWhen using `.cpio`, there can be no <<disk-persistency,filesystem persistency>> across boots, since all file operations happen in memory in a tmpfs:\n\n....\ndate >f\npoweroff\ncat f\n# can't open 'f': No such file or directory\n....\n\nwhich can be good for automated tests, as it ensures that you are using a pristine unmodified system image every time.\n\nNot however that we already disable disk persistency by default on ext2 filesystems even without `--initrd`: xref:disk-persistency[xrefstyle=full].\n\nOne downside of this method is that it has to put the entire filesystem into memory, and could lead to a panic:\n\n....\nend Kernel panic - not syncing: Out of memory and no killable processes...\n....\n\nThis can be solved by increasing the memory as explained at <<memory-size>>:\n\n....\n./run --initrd --memory 256M\n....\n\nThe main ingredients to get initrd working are:\n\n* `BR2_TARGET_ROOTFS_CPIO=y`: make Buildroot generate `images/rootfs.cpio` in addition to the other images.\n+\nIt is also possible to compress that image with other options.\n* `qemu -initrd`: make QEMU put the image into memory and tell the kernel about it.\n* `CONFIG_BLK_DEV_INITRD=y`: Compile the kernel with initrd support, see also: https://unix.stackexchange.com/questions/67462/linux-kernel-is-not-finding-the-initrd-correctly/424496#424496\n+\nBuildroot forces that option when `BR2_TARGET_ROOTFS_CPIO=y` is given\n\nTODO: how does the bootloader inform the kernel where to find initrd? https://unix.stackexchange.com/questions/89923/how-does-linux-load-the-initrd-image\n\n=== initrd in desktop distros\n\nMost modern desktop distributions have an initrd in their root disk to do early setup.\n\nThe rationale for this is described at: https://en.wikipedia.org/wiki/Initial_ramdisk\n\nOne obvious use case is having an encrypted root filesystem: you keep the initrd in an unencrypted partition, and then setup decryption from there.\n\nI think GRUB then knows read common disk formats, and then loads that initrd to memory with a `/boot/grub/grub.cfg` directive of type:\n\n....\ninitrd /initrd.img-4.4.0-108-generic\n....\n\nRelated: https://stackoverflow.com/questions/6405083/initrd-and-booting-the-linux-kernel\n\n=== initramfs\n\ninitramfs is just like <<initrd>>, but you also glue the image directly to the kernel image itself using the kernel's build system.\n\nTry it out with:\n\n....\n./build-buildroot --initramfs\n./build-linux --initramfs\n./run --initramfs\n....\n\nNotice how we had to rebuild the Linux kernel this time around as well after Buildroot, since in that build we will be gluing the CPIO to the kernel image.\n\nNow, once again, if we look at the QEMU run command generated, we see all that QEMU needs is the `-kernel` option, no `-drive` not even `-initrd`! Pretty cool:\n\n....\ncat \"$(./getvar run_dir)/run.sh\"\n....\n\nIt is also interesting to observe how this increases the size of the kernel image if you do a:\n\n....\nls -lh \"$(./getvar linux_image)\"\n....\n\nbefore and after using initramfs, since the `.cpio` is now glued to the kernel image.\n\nDon't forget that to stop using initramfs, you must rebuild the kernel without `--initramfs` to get rid of the attached CPIO image:\n\n....\n./build-linux\n./run\n....\n\nAlternatively, consider using <<linux-kernel-build-variants>> if you need to switch between initramfs and non initramfs often:\n\n....\n./build-buildroot --initramfs\n./build-linux --initramfs --linux-build-id initramfs\n./run --initramfs --linux-build-id\n....\n\nSetting up initramfs is very easy: our scripts just set `CONFIG_INITRAMFS_SOURCE` to point to the CPIO path.\n\nhttp://nairobi-embedded.org/initramfs_tutorial.html shows a full manual setup.\n\n=== rootfs\n\nThis is how `/proc/mounts` shows the root filesystem:\n\n* hard disk: `/dev/root on / type ext2 (rw,relatime,block_validity,barrier,user_xattr)`. That file does not exist however.\n* initrd: `rootfs on / type rootfs (rw)`\n* initramfs: `rootfs on / type rootfs (rw)`\n\nTODO: understand `/dev/root` better:\n\n* https://unix.stackexchange.com/questions/295060/why-on-some-linux-systems-does-the-root-filesystem-appear-as-dev-root-instead\n* https://superuser.com/questions/1213770/how-do-you-determine-the-root-device-if-dev-root-is-missing\n\n==== /dev/root\n\nSee: xref:rootfs[xrefstyle=full]\n\n=== gem5 initrd\n\nTODO we were not able to get it working yet: https://stackoverflow.com/questions/49261801/how-to-boot-the-linux-kernel-with-initrd-or-initramfs-with-gem5\n\nThis would require gem5 to load the CPIO into memory, just like QEMU. Grepping `initrd` shows some ARM hits under:\n\n....\nsrc/arch/arm/linux/atag.hh\n....\n\nbut they are commented out.\n\n=== gem5 initramfs\n\nThis could in theory be easier to make work than initrd since the emulator does not have to do anything special.\n\nHowever, it didn't: boot fails at the end because it does not see the initramfs, but rather tries to open our dummy root filesystem, which unsurprisingly does not have a format in a way that the kernel understands:\n\n....\nVFS: Cannot open root device \"sda\" or unknown-block(8,0): error -5\n....\n\nWe think that this might be because gem5 boots directly `vmlinux`, and not from the final compressed images that contain the attached rootfs such as `bzImage`, which is what QEMU does, see also: xref:vmlinux-vs-bzimage-vs-zimage-vs-image[xrefstyle=full].\n\nTo do this failed test, we automatically pass a dummy disk image as of gem5 7fa4c946386e7207ad5859e8ade0bbfc14000d91 since the scripts don't handle a missing `--disk-image` well, much like is currently done for <<baremetal>>.\n\nInterestingly, using initramfs significantly slows down the gem5 boot, even though it did not work. For example, we've observed a 4x slowdown of as 17062a2e8b6e7888a14c3506e9415989362c58bf for aarch64. This must be because expanding the large attached CPIO must be expensive. We can clearly see from the kernel logs that the kernel just hangs at a point after the message `PCI: CLS 0 bytes, default 64` for a long time before proceeding further.\n\n== Device tree\n\nThe device tree is a Linux kernel defined data structure that serves to inform the kernel how the hardware is setup.\n\nDevice trees serve to reduce the need for hardware vendors to patch the kernel: they just provide a device tree file instead, which is much simpler.\n\nx86 does not use it device trees, but many other archs to, notably ARM.\n\nThis is notably because ARM boards:\n\n* typically don't have discoverable hardware extensions like PCI, but rather just put everything on an SoC with magic register addresses\n* are made by a wide variety of vendors due to ARM's licensing business model, which increases variability\n\nThe Linux kernel itself has several device trees under `./arch/<arch>/boot/dts`, see also: https://stackoverflow.com/questions/21670967/how-to-compile-dts-linux-device-tree-source-files-to-dtb/42839737#42839737\n\n=== DTB files\n\nFiles that contain device trees have the `.dtb` extension when compiled, and `.dts` when in text form.\n\nYou can convert between those formats with:\n\n....\n\"$(./getvar buildroot_host_dir)\"/bin/dtc -I dtb -O dts -o a.dts a.dtb\n\"$(./getvar buildroot_host_dir)\"/bin/dtc -I dts -O dtb -o a.dtb a.dts\n....\n\nBuildroot builds the tool due to `BR2_PACKAGE_HOST_DTC=y`.\n\nOn Ubuntu 18.04, the package is named:\n\n....\nsudo apt-get install device-tree-compiler\n....\n\nSee also: https://stackoverflow.com/questions/14000736/tool-to-visualize-the-device-tree-file-dtb-used-by-the-linux-kernel/39931834#39931834\n\nDevice tree files are provided to the emulator just like the root filesystem and the Linux kernel image.\n\nIn real hardware, those components are also often provided separately. For example, on the Raspberry Pi 2, the SD card must contain two partitions:\n\n* the first contains all magic files, including the Linux kernel and the device tree\n* the second contains the root filesystem\n\nSee also: https://stackoverflow.com/questions/29837892/how-to-run-a-c-program-with-no-os-on-the-raspberry-pi/40063032#40063032\n\n=== Device tree syntax\n\nGood format descriptions:\n\n* https://www.raspberrypi.org/documentation/configuration/device-tree.md\n\nMinimal example\n\n....\n/dts-v1/;\n\n/ {\n    a;\n};\n....\n\nCheck correctness with:\n\n....\ndtc a.dts\n....\n\nSeparate nodes are simply merged by node path, e.g.:\n\n....\n/dts-v1/;\n\n/ {\n    a;\n};\n\n/ {\n    b;\n};\n....\n\nthen `dtc a.dts` gives:\n\n....\n/dts-v1/;\n\n/ {\n        a;\n        b;\n};\n....\n\n=== Get device tree from a running kernel\n\nhttps://unix.stackexchange.com/questions/265890/is-it-possible-to-get-the-information-for-a-device-tree-using-sys-of-a-running/330926#330926\n\nThis is specially interesting because QEMU and gem5 are capable of generating DTBs that match the selected machine depending on dynamic command line parameters for some types of machines.\n\nSo observing the device tree from the guest allows to easily see what the emulator has generated.\n\nCompile the `dtc` tool into the root filesystem:\n\n....\n./build-buildroot \\\n  --arch aarch64 \\\n  --config 'BR2_PACKAGE_DTC=y' \\\n  --config 'BR2_PACKAGE_DTC_PROGRAMS=y' \\\n;\n....\n\n`-M virt` for example, which we use by default for `aarch64`, boots just fine without the `-dtb` option:\n\n....\n./run --arch aarch64\n....\n\nThen, from inside the guest:\n\n....\ndtc -I fs -O dts /sys/firmware/devicetree/base\n....\n\ncontains:\n\n....\n        cpus {\n                #address-cells = <0x1>;\n                #size-cells = <0x0>;\n\n                cpu@0 {\n                        compatible = \"arm,cortex-a57\";\n                        device_type = \"cpu\";\n                        reg = <0x0>;\n                };\n        };\n....\n\n=== Device tree emulator generation\n\nSince emulators know everything about the hardware, they can automatically generate device trees for us, which is very convenient.\n\nThis is the case for both QEMU and gem5.\n\nFor example, if we increase the <<number-of-cores,number of cores>> to 2:\n\n....\n./run --arch aarch64 --cpus 2\n....\n\nQEMU automatically adds a second CPU to the DTB!\n\n....\n                cpu@0 {\n                cpu@1 {\n....\n\nThe action seems to be happening at: `hw/arm/virt.c`.\n\nYou can dump the DTB QEMU generated with:\n\n....\n./run --arch aarch64 -- -machine dumpdtb=dtb.dtb\n....\n\nas mentioned at: https://lists.gnu.org/archive/html/qemu-discuss/2017-02/msg00051.html\n\n<<gem5-fs-biglittle>> 2a9573f5942b5416fb0570cf5cb6cdecba733392 can also generate its own DTB.\n\ngem5 can generate DTBs on ARM with `--generate-dtb`. The generated DTB is placed in the <<m5out-directory>> named as `system.dtb`.\n\n== KVM\n\nhttps://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine[KVM] is Linux kernel interface that <<benchmark-linux-kernel-boot,greatly speeds up>> execution of virtual machines.\n\nYou can make QEMU or <<gem5-kvm,gem5>> by passing enabling KVM with:\n\n....\n./run --kvm\n....\n\nKVM works by running userland instructions natively directly on the real hardware instead of running a software simulation of those instructions.\n\nTherefore, KVM only works if you the host architecture is the same as the guest architecture. This means that this will likely only work for x86 guests since almost all development machines are x86 nowadays. Unless you are https://www.youtube.com/watch?v=8ItXpmLsINs[running an ARM desktop for some weird reason] :-)\n\nWe don't enable KVM by default because:\n\n* it limits visibility, since more things are running natively:\n** can't use <<gdb,GDB>>\n** can't do <<tracing,instruction tracing>>\n** on gem5, you lose <<gem5-run-benchmark,cycle counts>> and therefor any notion of performance\n* QEMU kernel boots are already <<benchmark-linux-kernel-boot,fast enough>> for most purposes without it\n\nOne important use case for KVM is to fast forward gem5 execution, often to skip boot, take a <<gem5-checkpoint>>, and then move on to a more detailed and slow simulation\n\n=== KVM arm\n\nTODO: we haven't gotten it to work yet, but it should be doable, and this is an outline of how to do it. Just don't expect this to tested very often for now.\n\nWe can test KVM on arm by running this repository inside an Ubuntu arm QEMU VM.\n\nThis produces no speedup of course, since the VM is already slow since it cannot use KVM on the x86 host.\n\nFirst, obtain an Ubuntu arm64 virtual machine as explained at: https://askubuntu.com/questions/281763/is-there-any-prebuilt-qemu-ubuntu-image32bit-online/1081171#1081171\n\nThen, from inside that image:\n\n....\nsudo apt-get install git\ngit clone https://github.com/cirosantilli/linux-kernel-module-cheat\ncd linux-kernel-module-cheat\npython3 -m venv .venv\n. .venv/bin/activate\n./setup -y\n....\n\nand then proceed exactly as in <<prebuilt>>.\n\nWe don't want to build the full Buildroot image inside the VM as that would be way too slow, thus the recommendation for the prebuilt setup.\n\nTODO: do the right thing and cross compile QEMU and gem5. gem5's Python parts might be a pain. QEMU should be easy: https://stackoverflow.com/questions/26514252/cross-compile-qemu-for-arm\n\n=== gem5 KVM\n\nWhile gem5 does have KVM, as of 2019 its support has not been very good, because debugging it is harder and people haven't focused intensively on it.\n\nX86 was broken with pending patches: https://www.mail-archive.com/gem5-users@gem5.org/msg15046.html It failed immediately on:\n\n....\npanic: KVM: Failed to enter virtualized mode (hw reason: 0x80000021)\n....\n\nalso mentioned at:\n\n* https://stackoverflow.com/questions/62687463/gem5-kvm-doesnt-work-with-error-0x80000021\n* https://gem5-users.gem5.narkive.com/8DBihuUx/running-fs-py-with-x86kvmcpu-failed\n\nBibliography:\n\n* ARM thread: https://stackoverflow.com/questions/53523087/how-to-run-gem5-on-kvm-on-arm-with-multiple-cores\n\n== User mode simulation\n\nBoth QEMU and gem5 have an user mode simulation mode in addition to full system simulation that we consider elsewhere in this project.\n\nIn QEMU, it is called just <<qemu-user-mode-getting-started,\"user mode\">>, and in gem5 it is called <<gem5-syscall-emulation-mode,syscall emulation mode>>.\n\nIn both, the basic idea is the same.\n\nUser mode simulation takes regular userland executables of any arch as input and executes them directly, without booting a kernel.\n\nInstead of simulating the full system, it translates normal instructions like in full system mode, but magically forwards system calls to the host OS.\n\nAdvantages over full system simulation:\n\n* the simulation may <<user-mode-vs-full-system-benchmark,run faster>> since you don't have to simulate the Linux kernel and several device models\n* you don't need to build your own kernel or root filesystem, which saves time. You still need a toolchain however, but the pre-packaged ones may work fine.\n\nDisadvantages:\n\n* lower guest to host portability:\n** TODO confirm: host OS == guest OS?\n** TODO confirm: the host Linux kernel should be newer than the kernel the executable was built for.\n+\nIt may still work even if that is not the case, but could fail is a missing system call is reached.\n+\nThe target Linux kernel of the executable is a GCC toolchain build-time configuration.\n** emulator implementers have to keep up with libc changes, some of which break even a C hello world due setup code executed before main.\n+\nSee also: xref:user-mode-simulation-with-glibc[xrefstyle=full]\n* cannot be used to test the Linux kernel or any devices, and results are less representative of a real system since we are faking more\n\n=== QEMU user mode getting started\n\nLet's run link:userland/c/command_line_arguments.c[] built with the Buildroot toolchain on QEMU user mode:\n\n....\n./build user-mode-qemu\n./run \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args='asdf \"qw er\"' \\\n;\n....\n\nOutput:\n\n....\n/path/to/linux-kernel-module-cheat/out/userland/default/x86_64/c/command_line_arguments.out\nasdf\nqw er\n....\n\n`./run --userland` path resolution is analogous to <<baremetal-setup-getting-started,that of `./run --baremetal`>>.\n\n`./build user-mode-qemu` first builds Buildroot, and then runs `./build-userland`, which is further documented at: xref:userland-setup[xrefstyle=full]. It also builds QEMU. If you ahve already done a <<qemu-buildroot-setup>> previously, this will be very fast.\n\nIf you modify the userland programs, rebuild simply with:\n\n....\n./build-userland\n....\n\nTo rebuild just QEMU userland if you hack it, use:\n\n....\n./build-qemu --mode userland\n....\n\nThe:\n\n....\n--mode userland\n....\n\nis needed because QEMU has two separate executables:\n\n* `qemu-x86_64` for userland\n* `qemu-system-x86_64` for full system\n\n==== User mode GDB\n\nIt's nice when <<gdb,the obvious>> just works, right?\n\n....\n./run \\\n  --arch aarch64 \\\n  --gdb-wait \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\nand on another shell:\n\n....\n./run-gdb \\\n  --arch aarch64 \\\n  --userland userland/c/command_line_arguments.c \\\n  main \\\n;\n....\n\nOr alternatively, if you are using <<tmux>>, do everything in one go with:\n\n....\n./run \\\n  --arch aarch64 \\\n  --gdb \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\nTo stop at the very first instruction of a freestanding program, just use `--no-continue`. A good example of this is shown at: xref:freestanding-programs[xrefstyle=full].\n\n=== User mode tests\n\nAutomatically run all userland tests that can be run in user mode simulation, and check that they exit with status 0:\n\n....\n./build --all-archs test-executables-userland\n./test-executables --all-archs --all-emulators\n....\n\nOr just for QEMU:\n\n....\n./build --all-archs test-executables-userland-qemu\n./test-executables --all-archs --emulator qemu\n....\n\nSource: link:test-executables[]\n\nThis script skips a manually configured list of tests, notably:\n\n* tests that depend on a full running kernel and cannot be run in user mode simulation, e.g. those that rely on kernel modules\n* tests that require user interaction\n* tests that take perceptible amounts of time\n* known bugs we didn't have time to fix ;-)\n\nTests under link:userland/libs/[] are only run if `--package` or `--package-all` are given as described at <<userland-libs-directory>>.\n\nThe gem5 tests require building statically with build id `static`, see also: xref:gem5-syscall-emulation-mode[xrefstyle=full]. TODO automate this better.\n\nSee: xref:test-this-repo[xrefstyle=full] for more useful testing tips.\n\n=== User mode Buildroot executables\n\nIf you followed <<qemu-buildroot-setup>>, you can now run the executables created by Buildroot directly as:\n\n....\n./run \\\n  --userland \"$(./getvar buildroot_target_dir)/bin/echo\" \\\n  --cli-args='asdf' \\\n;\n....\n\nTo easily explore the userland executable environment interactively, you can do:\n\n....\n./run \\\n  --arch aarch64 \\\n  --userland \"$(./getvar --arch aarch64 buildroot_target_dir)/bin/sh\" \\\n  --terminal \\\n;\n....\n\nor:\n\n....\n./run \\\n  --arch aarch64 \\\n  --userland \"$(./getvar --arch aarch64 buildroot_target_dir)/bin/sh\" \\\n  --cli-args='-c \"uname -a && pwd\"' \\\n;\n....\n\nHere is an interesting examples of this: xref:linux-test-project[xrefstyle=full]\n\n=== User mode simulation with glibc\n\nAt 125d14805f769104f93c510bedaa685a52ec025d we <<libc-choice,moved Buildroot from uClibc to glibc>>, and caused some user mode pain, which we document here.\n\n==== FATAL: kernel too old failure in userland simulation\n\nglibc has a check for kernel version, likely obtained from the `uname` syscall, and if the kernel is not new enough, it quits.\n\nBoth gem5 and QEMU however allow setting the reported `uname` version from the command line for <<user-mode-simulation>>, which we do to always match our toolchain.\n\nQEMU by default copies the host `uname` value, but we always override it in our scripts.\n\nDetermining the right number to use for the kernel version is of course highly non-trivial and would require an extensive userland test suite, which most emulators don't have.\n\n....\n./run --arch aarch64 --kernel-version 4.18 --userland userland/posix/uname.c\n....\n\nSource: link:userland/posix/uname.c[].\n\nThe QEMU source that does this is at: https://github.com/qemu/qemu/blob/v3.1.0/linux-user/syscall.c#L8931 The default ID is just hardcoded on the source.\n\nBibliography:\n\n* https://stackoverflow.com/questions/48959349/how-to-solve-fatal-kernel-too-old-when-running-gem5-in-syscall-emulation-se-m\n* https://stackoverflow.com/questions/53085048/how-to-compile-and-run-an-executable-in-gem5-syscall-emulation-mode-with-se-py/53085049#53085049\n* https://gem5-review.googlesource.com/c/public/gem5/+/15855\n\n==== stack smashing detected when using glibc\n\nFor some reason QEMU / glibc x86_64 picks up the host libc, which breaks things.\n\nOther archs work as they different host libc is skipped. <<user-mode-static-executables>> also work.\n\nWe have worked around this with with https://bugs.launchpad.net/qemu/+bug/1701798/comments/12 from the thread: https://bugs.launchpad.net/qemu/+bug/1701798 by creating the file: link:rootfs_overlay/etc/ld.so.cache[] which is a symlink to a file that cannot exist: `/dev/null/nonexistent`.\n\nReproduction:\n\n....\nrm -f \"$(./getvar buildroot_target_dir)/etc/ld.so.cache\"\n./run --userland userland/c/hello.c\n./run --userland userland/c/hello.c --qemu-which host\n....\n\nOutcome:\n\n....\n*** stack smashing detected ***: <unknown> terminated\nqemu: uncaught target signal 6 (Aborted) - core dumped\n....\n\nTo get things working again, restore `ld.so.cache` with:\n\n....\n./build-buildroot\n....\n\nI've also tested on an Ubuntu 16.04 guest and the failure is different one:\n\n....\nqemu: uncaught target signal 4 (Illegal instruction) - core dumped\n....\n\nA non-QEMU-specific example of stack smashing is shown at: https://stackoverflow.com/questions/1345670/stack-smashing-detected/51897264#51897264\n\nTested at: 2e32389ebf1bedd89c682aa7b8fe42c3c0cf96e5 + 1.\n\n=== User mode static executables\n\nExample:\n\n....\n./build-userland \\\n  --arch aarch64 \\\n  --static \\\n;\n./run \\\n  --arch aarch64 \\\n  --static \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\nRunning dynamically linked executables in QEMU requires pointing it to the root filesystem with the `-L` option so that it can find the dynamic linker and shared libraries, see also:\n\n* https://stackoverflow.com/questions/54802670/using-dynamic-linker-with-qemu-arm/64551293#64551293\n* https://stackoverflow.com/questions/khow-to-gdb-step-debug-a-dynamically-linked-executable-in-qemu-user-mode\n\nWe pass `-L` by default, so everything just works.\n\nHowever, in case something goes wrong, you can also try statically linked executables, since this mechanism tends to be a bit more stable, for example:\n\n* QEMU x86_64 guest on x86_64 host was failing with <<stack-smashing-detected-when-using-glibc>>, but we found a workaround\n* gem5 user only supported static executables in the past, as mentioned at: xref:gem5-syscall-emulation-mode[xrefstyle=full]\n\nRunning statically linked executables sometimes makes things break:\n\n* <<user-mode-static-executables-with-dynamic-libraries>>\n* TODO understand why:\n+\n....\n./run --static --userland userland/c/file_write_read.c\n....\n+\nfails our assertion that the data was read back correctly:\n+\n....\nAssertion `strcmp(data, output) == 0' faile\n....\n\n==== User mode static executables with dynamic libraries\n\nOne limitation of static executables is that Buildroot mostly only builds dynamic versions of libraries (the libc is an exception).\n\nSo programs that rely on those libraries might not compile as GCC can't find the `.a` version of the library.\n\nFor example, if we try to build <<blas>> statically:\n\n....\n./build-userland --package openblas --static -- userland/libs/openblas/hello.c\n....\n\nit fails with:\n\n....\nld: cannot find -lopenblas\n....\n\n[[cpp-static-and-pthreads]]\n===== C++ static and pthreads\n\n`g++` and pthreads also causes issues:\n\n* https://stackoverflow.com/questions/35116327/when-g-static-link-pthread-cause-segmentation-fault-why\n* https://stackoverflow.com/questions/58848694/gcc-whole-archive-recipe-for-static-linking-to-pthread-stopped-working-in-rec\n\nAs a consequence, the following just hangs as of LKMC ca0403849e03844a328029d70c08556155dc1cd0 + 1 the example link:userland/cpp/atomic/std_atomic.cpp[]:\n\n....\n./run --userland userland/cpp/atomic/std_atomic.cpp --static\n....\n\nAnd before that, it used to fail with other randomly different errors, e.g.:\n\n....\nqemu-x86_64: /path/to/linux-kernel-module-cheat/submodules/qemu/accel/tcg/cpu-exec.c:700: cpu_exec: Assertion `!have_mmap_lock()' failed.\nqemu-x86_64: /path/to/linux-kernel-module-cheat/submodules/qemu/accel/tcg/cpu-exec.c:700: cpu_exec: Assertion `!have_mmap_lock()' failed.\n....\n\nAnd a native Ubuntu 18.04 AMD64 run with static compilation segfaults.\n\nAs of LKMC f5d4998ff51a548ed3f5153aacb0411d22022058 the aarch64 error:\n\n....\n./run --arch aarch64 --userland userland/cpp/atomic/fail.cpp --static\n....\n\nis:\n\n....\nterminate called after throwing an instance of 'std::system_error'\n  what():  Unknown error 16781344\nqemu: uncaught target signal 6 (Aborted) - core dumped\n....\n\nThe workaround:\n\n....\n-pthread -Wl,--whole-archive -lpthread -Wl,--no-whole-archive\n....\n\nfixes some of the problems, but not all TODO which were missing?, so we are just skipping those tests for now.\n\n=== syscall emulation mode program stdin\n\nThe following work on both QEMU and gem5 as of LKMC 99d6bc6bc19d4c7f62b172643be95d9c43c26145 + 1. Interactive input:\n\n....\n./run --userland userland/c/getchar.c\n....\n\nSource: link:userland/c/getchar.c[]\n\nA line of type should show:\n\n....\nenter a character:\n....\n\nand after pressing say `a` and Enter, we get:\n\n....\nyou entered: a\n....\n\nNote however that due to <<qemu-user-mode-does-not-show-stdout-immediately>> we don't really see the initial `enter a character` line.\n\nNon-interactive input from a file by forwarding emulators stdin implicitly through our Python scripts:\n\n....\nprintf a > f.tmp\n./run --userland userland/c/getchar.c < f.tmp\n....\n\nInput from a file by explicitly requesting our scripts to use it via the Python API:\n\n....\nprintf a > f.tmp\n./run --emulator gem5 --userland userland/c/getchar.c --stdin-file f.tmp\n....\n\nThis is especially useful when running tests that require stdin input.\n\n=== gem5 syscall emulation mode\n\nLess robust than QEMU's, but still usable:\n\n* https://stackoverflow.com/questions/48986597/when-should-you-use-full-system-fs-vs-syscall-emulation-se-with-userland-program\n\nThere are much more unimplemented syscalls in gem5 than in QEMU. Many of those are trivial to implement however.\n\nSo let's just play with some static ones:\n\n....\n./build-userland --arch aarch64\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n....\n\nTODO: how to escape spaces on the command line arguments?\n\n<<user-mode-gdb,GDB step debug>> also works normally on gem5:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --gdb-wait \\\n  --userland userland/c/command_line_arguments.c \\\n  --cli-args 'asdf \"qw er\"' \\\n;\n./run-gdb \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/c/command_line_arguments.c \\\n  main \\\n;\n....\n\n==== gem5 dynamic linked executables in syscall emulation\n\nSupport for dynamic linking was added in November 2019:\n\n* https://stackoverflow.com/questions/50542222/how-to-run-a-dynamically-linked-executable-syscall-emulation-mode-se-py-in-gem5/50696098#50696098\n* https://stackoverflow.com/questions/64547306/cannot-open-lib-ld-linux-aarch64-so-1-in-qemu-or-gem5/64551313#64551313\n\nNote that as shown at xref:benchmark-emulators-on-userland-executables[xrefstyle=full], the dynamic version runs 200x more instructions, which might have an impact on smaller simulations in detailed CPUs.\n\n==== gem5 syscall emulation exit status\n\nAs of gem5 7fa4c946386e7207ad5859e8ade0bbfc14000d91, the crappy `se.py` script does not forward the exit status of syscall emulation mode, you can test it with:\n\n....\n./run --dry-run --emulator gem5 --userland userland/c/false.c\n....\n\nSource: link:userland/c/false.c[].\n\nThen manually run the generated gem5 CLI, and do:\n\n....\necho $?\n....\n\nand the output is always `0`.\n\nInstead, it just outputs a message to stdout just like for <<m5-fail>>:\n\n....\nSimulated exit code not 0! Exit code is 1\n....\n\nwhich we parse in link:run[] and then exit with the correct result ourselves...\n\nRelated thread: https://stackoverflow.com/questions/56032347/is-there-a-way-to-identify-if-gem5-run-got-over-successfully\n\n==== gem5 syscall emulation mode syscall tracing\n\nSince gem5 has to implement syscalls itself in syscall emulation mode, it can of course clearly see which syscalls are being made, and we can log them for debug purposes with <<gem5-tracing>>, e.g.:\n\n....\n./run \\\n  --emulator gem5 \\\n  --userland userland/arch/x86_64/freestanding/linux/hello.S \\\n  --trace-stdout \\\n  --trace ExecAll,SyscallBase,SyscallVerbose \\\n;\n....\n\nthe trace as of f2eeceb1cde13a5ff740727526bf916b356cee38 + 1 contains:\n\n....\n      0: system.cpu A0 T0 : @asm_main_after_prologue    : mov   rdi, 0x1\n      0: system.cpu A0 T0 : @asm_main_after_prologue.0  :   MOV_R_I : limm   rax, 0x1 : IntAlu :  D=0x0000000000000001  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   1000: system.cpu A0 T0 : @asm_main_after_prologue+7    : mov rdi, 0x1\n   1000: system.cpu A0 T0 : @asm_main_after_prologue+7.0  :   MOV_R_I : limm   rdi, 0x1 : IntAlu :  D=0x0000000000000001  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   2000: system.cpu A0 T0 : @asm_main_after_prologue+14    : lea        rsi, DS:[rip + 0x19]\n   2000: system.cpu A0 T0 : @asm_main_after_prologue+14.0  :   LEA_R_P : rdip   t7, %ctrl153,  : IntAlu :  D=0x000000000040008d  flags=(IsInteger|IsMicroop|IsDelayedCommit|IsFirstMicroop)\n   2500: system.cpu A0 T0 : @asm_main_after_prologue+14.1  :   LEA_R_P : lea   rsi, DS:[t7 + 0x19] : IntAlu :  D=0x00000000004000a6  flags=(IsInteger|IsMicroop|IsLastMicroop)\n   3500: system.cpu A0 T0 : @asm_main_after_prologue+21    : mov        rdi, 0x6\n   3500: system.cpu A0 T0 : @asm_main_after_prologue+21.0  :   MOV_R_I : limm   rdx, 0x6 : IntAlu :  D=0x0000000000000006  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   4000: system.cpu: T0 : syscall write called w/arguments 1, 4194470, 6, 0, 0, 0\nhello\n   4000: system.cpu: T0 : syscall write returns 6\n   4000: system.cpu A0 T0 : @asm_main_after_prologue+28    :   syscall    eax           : IntAlu :   flags=(IsInteger|IsSerializeAfter|IsNonSpeculative|IsSyscall)\n   5000: system.cpu A0 T0 : @asm_main_after_prologue+30    : mov        rdi, 0x3c\n   5000: system.cpu A0 T0 : @asm_main_after_prologue+30.0  :   MOV_R_I : limm   rax, 0x3c : IntAlu :  D=0x000000000000003c  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   6000: system.cpu A0 T0 : @asm_main_after_prologue+37    : mov        rdi, 0\n   6000: system.cpu A0 T0 : @asm_main_after_prologue+37.0  :   MOV_R_I : limm   rdi, 0  : IntAlu :  D=0x0000000000000000  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   6500: system.cpu: T0 : syscall exit called w/arguments 0, 4194470, 6, 0, 0, 0\n   6500: system.cpu: T0 : syscall exit returns 0\n   6500: system.cpu A0 T0 : @asm_main_after_prologue+44    :   syscall    eax           : IntAlu :   flags=(IsInteger|IsSerializeAfter|IsNonSpeculative|IsSyscall)\n....\n\nso we see that two syscall lines were added for each syscall, showing the syscall inputs and exit status, just like a mini `strace`!\n\n==== gem5 syscall emulation multithreading\n\ngem5 user mode multithreading has been particularly flaky compared <<qemu-user-mode-multithreading,to QEMU's>>, but work is being put into improving it.\n\nIn gem5 syscall simulation, the `fork` syscall checks if there is a free CPU, and if there is a free one, the new threads runs on that CPU.\n\nOtherwise, the `fork` call, and therefore higher level interfaces to `fork` such as `pthread_create` also fail and return a failure return status in the guest.\n\nFor example, if we use just one CPU for link:userland/posix/pthread_self.c[] which spawns one thread besides `main`:\n\n....\n./run --cpus 1 --emulator gem5 --userland userland/posix/pthread_self.c --cli-args 1\n....\n\nfails with this error message coming from the guest stderr:\n\n....\npthread_create: Resource temporarily unavailable\n....\n\nIt works however if we add on extra CPU:\n\n....\n./run --cpus 2 --emulator gem5 --userland userland/posix/pthread_self.c --cli-args 1\n....\n\nOnce threads exit, their CPU is freed and becomes available for new `fork` calls: For example, the following run spawns a thread, joins it, and then spawns again, and 2 CPUs are enough:\n\n....\n./run --cpus 2 --emulator gem5 --userland userland/posix/pthread_self.c --cli-args '1 2'\n....\n\nbecause at each point in time, only up to two threads are running.\n\ngem5 syscall emulation does show the expected number of cores when queried, e.g.:\n\n....\n./run --cpus 1 --userland userland/cpp/thread_hardware_concurrency.cpp --emulator gem5\n./run --cpus 2 --userland userland/cpp/thread_hardware_concurrency.cpp --emulator gem5\n....\n\noutputs `1` and `2` respectively.\n\nThis can also be clearly by running `sched_getcpu`:\n\n....\n./run \\\n  --arch aarch64 \\\n  --cli-args  4 \\\n  --cpus 8 \\\n  --emulator gem5 \\\n  --userland userland/linux/sched_getcpu.c \\\n;\n....\n\nwhich necessarily produces an output containing the CPU numbers from 1 to 4 and no higher:\n\n....\n1\n3\n4\n2\n....\n\nTODO why does the `2` come at the end here? Would be good to do a detailed assembly run analysis.\n\n==== gem5 syscall emulation multiple executables\n\ngem5 syscall emulation has the nice feature of allowing you to run multiple executables \"at once\".\n\nEach executable starts running on the next free core much as if it had been forked right at the start of simulation: <<gem5-syscall-emulation-multithreading>>.\n\nThis can be useful to quickly create deterministic multi-CPU workload.\n\n`se.py --cmd` takes a semicolon separated list, so we could do which LKMC exposes this by taking `--userland` multiple times as in:\n\n....\n./run \\\n  --arch aarch64 \\\n  --cpus 2 \\\n  --emulator gem5 \\\n  --userland userland/posix/getpid.c \\\n  --userland userland/posix/getpid.c \\\n;\n....\n\nWe need at least one CPU per executable, just like when forking new processes.\n\nThe outcome of this is that we see two different `pid` messages printed to stdout:\n\n....\npid=101\npid=100\n....\n\nsince from <<gem5-process>> we can see that se.py sets up one different PID per executable starting at 100:\n\n....\n    workloads = options.cmd.split(';')\n    idx = 0\n    for wrkld in workloads:\n        process = Process(pid = 100 + idx)\n....\n\nWe can also see that these processes are running concurrently with <<gem5-tracing>> by hacking:\n\n....\n  --debug-flags ExecAll \\\n  --debug-file cout \\\n....\n\nwhich starts with:\n\n....\n      0: system.cpu1: A0 T0 : @__end__+274873647040    :   add   x0, sp, #0         : IntAlu :  D=0x0000007ffffefde0  flags=(IsInteger)\n      0: system.cpu0: A0 T0 : @__end__+274873647040    :   add   x0, sp, #0         : IntAlu :  D=0x0000007ffffefde0  flags=(IsInteger)\n    500: system.cpu0: A0 T0 : @__end__+274873647044    :   bl   <__end__+274873649648> : IntAlu :  D=0x0000004000001008  flags=(IsInteger|IsControl|IsDirectControl|IsUncondControl|IsCall)\n    500: system.cpu1: A0 T0 : @__end__+274873647044    :   bl   <__end__+274873649648> : IntAlu :  D=0x0000004000001008  flags=(IsInteger|IsControl|IsDirectControl|IsUncondControl|IsCall)\n....\n\nand therefore shows one instruction running on each CPU for each process at the same time.\n\n===== gem5 syscall emulation --smt\n\ngem5 b1623cb2087873f64197e503ab8894b5e4d4c7b4 syscall emulation has an `--smt` option presumably for <<hardware-threads>> but it has been neglected forever it seems: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/104\n\nIf we start from the manually hacked working command from <<gem5-syscall-emulation-multiple-executables>> and try to add:\n\n....\n--cpu 1 --cpu-type Derivo3CPU --caches\n....\n\nWe choose <<gem5-derivo3cpu,`DerivO3CPU`>> because of the se.py assert:\n\n....\nexample/se.py:115:        assert(options.cpu_type == \"DerivO3CPU\")\n....\n\nBut then that fails with:\n\n....\ngem5.opt: /path/to/linux-kernel-module-cheat/out/gem5/master3/build/ARM/cpu/o3/cpu.cc:205: FullO3CPU<Impl>::FullO3CPU(DerivO3CPUParams*) [with Impl = O3CPUImpl]: Assertion `params->numPhysVecPredRegs >= numThreads * TheISA::NumVecPredRegs' failed.\nProgram aborted at tick 0\n....\n\n=== QEMU user mode quirks\n\n==== QEMU user mode does not show stdout immediately\n\nAt 8d8307ac0710164701f6e14c99a69ee172ccbb70 + 1, I noticed that if you run link:userland/posix/count.c[]:\n\n....\n./run --userland userland/posix/count_to.c --cli-args 3\n....\n\nit first waits for 3 seconds, then the program exits, and then it dumps all the stdout at once, instead of counting once every second as expected.\n\nThe same can be reproduced by copying the raw QEMU command and piping it through `tee`, so I don't think it is a bug in our setup:\n\n....\n/path/to/linux-kernel-module-cheat/out/qemu/default/x86_64-linux-user/qemu-x86_64 \\\n  -L /path/to/linux-kernel-module-cheat/out/buildroot/build/default/x86_64/target \\\n  /path/to/linux-kernel-module-cheat/out/userland/default/x86_64/posix/count.out \\\n  3 \\\n| tee\n....\n\nTODO: investigate further and then possibly post on QEMU mailing list.\n\n===== QEMU user mode does not show errors\n\nSimilarly to <<qemu-user-mode-does-not-show-stdout-immediately>>, QEMU error messages do not show at all through pipes.\n\nIn particular, it does not say anything if you pass it a non-existing executable:\n\n....\nqemu-x86_64 asdf | cat\n....\n\nSo we just check ourselves manually\n\n== Kernel module utilities\n\n=== insmod\n\nhttps://git.busybox.net/busybox/tree/modutils/insmod.c?h=1_29_3[Provided by BusyBox]:\n\n....\n./run --eval-after 'insmod hello.ko'\n....\n\n=== myinsmod\n\nIf you are feeling raw, you can insert and remove modules with our own minimal module inserter and remover!\n\n....\n# init_module\n./linux/myinsmod.out hello.ko\n# finit_module\n./linux/myinsmod.out hello.ko \"\" 1\n./linux/myrmmod.out hello\n....\n\nwhich teaches you how it is done from C code.\n\nSource:\n\n* link:userland/linux/myinsmod.c[]\n* link:userland/linux/myrmmod.c[]\n\nThe Linux kernel offers two system calls for module insertion:\n\n* `init_module`\n* `finit_module`\n\nand:\n\n....\nman init_module\n....\n\ndocuments that:\n\n____\nThe finit_module() system call is like init_module(), but reads the module to be loaded from the file descriptor fd. It is useful when the authenticity of a kernel module can be determined from its location in the filesystem; in cases where that is possible, the overhead of using cryptographically signed modules to determine the authenticity of a module can be avoided. The param_values argument is as for init_module().\n____\n\n`finit` is newer and was added only in v3.8. More rationale: https://lwn.net/Articles/519010/\n\nBibliography: https://stackoverflow.com/questions/5947286/how-to-load-linux-kernel-modules-from-c-code\n\n=== modprobe\n\nImplemented as a BusyBox applet by default: https://git.busybox.net/busybox/tree/modutils/modprobe.c?h=1_29_stable\n\n`modprobe` searches for modules installed under:\n\n....\nls /lib/modules/<kernel_version>\n....\n\nand specified in the `modules.order` file.\n\nThis is the default install path for `CONFIG_SOME_MOD=m` modules built with `make modules_install` in the Linux kernel tree, with root path given by `INSTALL_MOD_PATH`, and therefore canonical in that sense.\n\nCurrently, there are only two kinds of kernel modules that you can try out with `modprobe`:\n\n* modules built with Buildroot, see: xref:kernel-modules-buildroot-package[xrefstyle=full]\n* modules built from the kernel tree itself, see: xref:dummy-irq[xrefstyle=full]\n\nWe are not installing out custom `./build-modules` modules there, because:\n\n* we don't know the right way. Why is there no `install` or `install_modules` target for kernel modules?\n+\nThis can of course be solved by running Buildroot in verbose mode, and copying whatever it is doing, initial exploration at: https://stackoverflow.com/questions/22783793/how-to-install-kernel-modules-from-source-code-error-while-make-process/53169078#53169078\n* we would have to think how to not have to include the kernel modules twice in the root filesystem, but still have <<9p>> working for fast development as described at: xref:your-first-kernel-module-hack[xrefstyle=full]\n\n=== kmod\n\nThe more \"reference\" kernel.org implementation of `lsmod`, `insmod`, `rmmod`, etc.: https://git.kernel.org/pub/scm/utils/kernel/kmod/kmod.git\n\nDefault implementation on desktop distros such as Ubuntu 16.04, where e.g.:\n\n....\nls -l /bin/lsmod\n....\n\ngives:\n\n....\nlrwxrwxrwx 1 root root 4 Jul 25 15:35 /bin/lsmod -> kmod\n....\n\nand:\n\n....\ndpkg -l | grep -Ei\n....\n\ncontains:\n\n....\nii  kmod                                        22-1ubuntu5                                         amd64        tools for managing Linux kernel modules\n....\n\nBusyBox also implements its own version of those executables, see e.g. <<modprobe>>. Here we will only describe features that differ from kmod to the BusyBox implementation.\n\n==== module-init-tools\n\nName of a predecessor set of tools.\n\n==== kmod modprobe\n\nkmod's `modprobe` can also load modules under different names to avoid conflicts, e.g.:\n\n....\nsudo modprobe vmhgfs -o vm_hgfs\n....\n\n== Filesystems\n\n=== OverlayFS\n\nhttps://en.wikipedia.org/wiki/OverlayFS[OverlayFS] is a filesystem merged in the Linux kernel in 3.18.\n\nAs the name suggests, OverlayFS allows you to merge multiple directories into one. The following minimal runnable examples should give you an intuition on how it works:\n\n* https://askubuntu.com/questions/109413/how-do-i-use-overlayfs/1075564#1075564\n* https://stackoverflow.com/questions/31044982/how-to-use-multiple-lower-layers-in-overlayfs/52792397#52792397\n\nWe are very interested in this filesystem because we are looking for a way to make host cross compiled executables appear on the guest root `/` without reboot.\n\nThis would have several advantages:\n\n* makes it faster to test modified guest programs\n** not rebooting is fundamental for <<gem5>>, where the reboot is very costly.\n** no need to regenerate the root filesystem at all and reboot\n** overcomes the `check_bin_arch` problem as shown at: xref:rpath[xrefstyle=full]\n* we could keep the base root filesystem very small, which implies:\n** less host disk usage, no need to copy the entire `./getvar out_rootfs_overlay_dir` to the image again\n** no need to worry about <<br2-target-rootfs-ext2-size>>\n\nWe can already make host files appear on the guest with <<9p>>, but they appear on a subdirectory instead of the root.\n\nIf they would appear on the root instead, that would be even more awesome, because you would just use the exact same paths relative to the root transparently.\n\nFor example, we wouldn't have to mess around with variables such as `PATH` and `LD_LIBRARY_PATH`.\n\nThe idea is to:\n\n* 9P mount our overlay directory `./getvar out_rootfs_overlay_dir` on the guest, which we already do at `/mnt/9p/out_rootfs_overlay`\n* then create an overlay with that directory and the root, and `chroot` into it.\n+\nI was unable to mount directly to `/` avoid the `chroot`:\n** https://stackoverflow.com/questions/41119656/how-can-i-overlayfs-the-root-filesystem-on-linux\n** https://unix.stackexchange.com/questions/316018/how-to-use-overlayfs-to-protect-the-root-filesystem\n** https://unix.stackexchange.com/questions/420646/mount-root-as-overlayfs\n\nWe already have a prototype of this running from `fstab` on guest at `/mnt/overlay`, but it has the following shortcomings:\n\n* changes to underlying filesystems are not visible on the overlay unless you remount with `mount -r remount /mnt/overlay`, as mentioned https://github.com/torvalds/linux/blob/v4.18/Documentation/filesystems/overlayfs.txt#L332[on the kernel docs]:\n+\n....\nChanges to the underlying filesystems while part of a mounted overlay\nfilesystem are not allowed.  If the underlying filesystem is changed,\nthe behavior of the overlay is undefined, though it will not result in\na crash or deadlock.\n....\n+\nThis makes everything very inconvenient if you are inside `chroot` action. You would have to leave `chroot`, remount, then come back.\n* the overlay does not contain sub-filesystems, e.g. `/proc`. We would have to re-mount them. But should be doable with some automation.\n\nEven more awesome than `chroot` would be to `pivot_root`, but I couldn't get that working either:\n\n* https://stackoverflow.com/questions/28015688/pivot-root-device-or-resource-busy\n* https://unix.stackexchange.com/questions/179788/pivot-root-device-or-resource-busy\n\n=== Secondary disk\n\nA simpler and possibly less overhead alternative to <<9P>> would be to generate a secondary disk image with the benchmark you want to rebuild.\n\nThen you can `umount` and re-mount on guest without reboot.\n\nTo build the secondary disk image run link:build-disk2[]:\n\n....\n./build-disk2\n....\n\nThis will put the entire <<out-rootfs-overlay-dir>> into a squashfs filesystem.\n\nThen, if that filesystem is present, `./run` will automatically pass it as the second disk on the command line.\n\nFor example, from inside QEMU, you can mount that disk with:\n\n....\nmkdir /mnt/vdb\nmount /dev/vdb /mnt/vdb\n/mnt/vdb/lkmc/c/hello.out\n....\n\nTo update the secondary disk while a simulation is running to avoid rebooting, first unmount in the guest:\n\n....\numount /mnt/vdb\n....\n\nand then on the host:\n\n....\n# Edit the file.\nvim userland/c/hello.c\n./build-userland\n./build-disk2\n....\n\nand now you can re-run the updated version of the executable on the guest after remounting it.\n\ngem5 fs.py support for multiple disks is discussed at: https://stackoverflow.com/questions/50862906/how-to-attach-multiple-disk-images-in-a-simulation-with-gem5-fs-py/51037661#51037661\n\n== Graphics\n\nBoth QEMU and gem5 are capable of outputting graphics to the screen, and taking mouse and keyboard input.\n\nhttps://unix.stackexchange.com/questions/307390/what-is-the-difference-between-ttys0-ttyusb0-and-ttyama0-in-linux\n\n=== QEMU text mode\n\nText mode is the default mode for QEMU.\n\nThe opposite of text mode is <<qemu-graphic-mode>>\n\nIn text mode, we just show the serial console directly on the current terminal, without opening a QEMU GUI window.\n\nYou cannot see any graphics from text mode, but text operations in this mode, including:\n\n* scrolling up: xref:scroll-up-in-graphic-mode[xrefstyle=full]\n* copy paste to and from the terminal\n\nmaking this a good default, unless you really need to use with graphics.\n\nText mode works by sending the terminal character by character to a serial device.\n\nThis is different from a display screen, where each character is a bunch of pixels, and it would be much harder to convert that into actual terminal text.\n\nFor more details, see:\n\n* https://unix.stackexchange.com/questions/307390/what-is-the-difference-between-ttys0-ttyusb0-and-ttyama0-in-linux\n* <<tty>>\n\nNote that you can still see an image even in text mode with the VNC:\n\n....\n./run --vnc\n....\n\nand on another terminal:\n\n....\n./vnc\n....\n\nbut there is not terminal on the VNC window, just the <<config-logo>> penguin.\n\n==== Quit QEMU from text mode\n\nhttps://superuser.com/questions/1087859/how-to-quit-the-qemu-monitor-when-not-using-a-gui\n\nHowever, our QEMU setup captures Ctrl + C and other common signals and sends them to the guest, which makes it hard to quit QEMU for the first time since there is no GUI either.\n\nThe simplest way to quit QEMU, is to do:\n\n....\nCtrl-A X\n....\n\nAlternative methods include:\n\n* `quit` command on the <<qemu-monitor>>\n* `pkill qemu`\n\n=== QEMU graphic mode\n\nEnable graphic mode with:\n\n....\n./run --graphic\n....\n\nOutcome: you see a penguin due to <<config-logo>>.\n\nFor a more exciting GUI experience, see: xref:x11[xrefstyle=full]\n\nText mode is the default due to the following considerable advantages:\n\n* copy and paste commands and stdout output to / from host\n* get full panic traces when you start making the kernel crash :-) See also: https://unix.stackexchange.com/questions/208260/how-to-scroll-up-after-a-kernel-panic\n* have a large scroll buffer, and be able to search it, e.g. by using tmux on host\n* one less window floating around to think about in addition to your shell :-)\n* graphics mode has only been properly tested on `x86_64`.\n\nText mode has the following limitations over graphics mode:\n\n* you can't see graphics such as those produced by <<x11>>\n* very early kernel messages such as `early console in extract_kernel` only show on the GUI, since at such early stages, not even the serial has been setup.\n\n`x86_64` has a VGA device enabled by default, as can be seen as:\n\n....\n./qemu-monitor info qtree\n....\n\nand the Linux kernel picks it up through the https://en.wikipedia.org/wiki/Linux_framebuffer[fbdev] graphics system as can be seen from:\n\n....\ncat /dev/urandom > /dev/fb0\n....\n\nflooding the screen with colors. See also: https://superuser.com/questions/223094/how-do-i-know-if-i-have-kms-enabled\n\n==== Scroll up in graphic mode\n\nScroll up in <<qemu-graphic-mode>>:\n\n....\nShift-PgUp\n....\n\nbut I never managed to increase that buffer:\n\n* https://askubuntu.com/questions/709697/how-to-increase-scrollback-lines-in-ubuntu14-04-2-server-edition\n* https://unix.stackexchange.com/questions/346018/how-to-increase-the-scrollback-buffer-size-for-tty\n\nThe superior alternative is to use text mode and GNU screen or <<tmux>>.\n\n==== QEMU Graphic mode arm\n\n===== QEMU graphic mode arm terminal\n\nTODO: on arm, we see the penguin and some boot messages, but don't get a shell at then end:\n\n....\n./run --arch aarch64 --graphic\n....\n\nI think it does not work because the graphic window is <<drm>> only, i.e.:\n\n....\ncat /dev/urandom > /dev/fb0\n....\n\nfails with:\n\n....\ncat: write error: No space left on device\n....\n\nand has no effect, and the Linux kernel does not appear to have a built-in DRM console as it does for fbdev with <<fbcon,fbcon>>.\n\nThere is however one out-of-tree implementation: <<kmscon>>.\n\n===== QEMU graphic mode arm terminal implementation\n\n`arm` and `aarch64` rely on the QEMU CLI option:\n\n....\n-device virtio-gpu-pci\n....\n\nand the kernel config options:\n\n....\nCONFIG_DRM=y\nCONFIG_DRM_VIRTIO_GPU=y\n....\n\nUnlike x86, `arm` and `aarch64` don't have a display device attached by default, thus the need for `virtio-gpu-pci`.\n\nSee also https://wiki.qemu.org/Documentation/Platforms/ARM (recently edited and corrected by yours truly... :-)).\n\n===== QEMU graphic mode arm VGA\n\nTODO: how to use VGA on ARM? https://stackoverflow.com/questions/20811203/how-can-i-output-to-vga-through-qemu-arm Tried:\n\n....\n-device VGA\n....\n\nBut https://github.com/qemu/qemu/blob/v2.12.0/docs/config/mach-virt-graphical.cfg#L264 says:\n\n....\n# We use virtio-gpu because the legacy VGA framebuffer is\n# very troublesome on aarch64, and virtio-gpu is the only\n# video device that doesn't implement it.\n....\n\nso maybe it is not possible?\n\n=== gem5 graphic mode\n\ngem5 does not have a \"text mode\", since it cannot redirect the Linux terminal to same host terminal where the executable is running: you are always forced to connect to the terminal with `gem-shell`.\n\nTODO could not get it working on `x86_64`, only ARM.\n\nOverview: https://stackoverflow.com/questions/50364863/how-to-get-graphical-gui-output-and-user-touch-keyboard-mouse-input-in-a-ful/50364864#50364864\n\nMore concretely, first build the kernel with the <<gem5-arm-linux-kernel-patches>>, and then run:\n\n....\n./build-linux \\\n  --arch arm \\\n  --custom-config-file-gem5 \\\n  --linux-build-id gem5-v4.15 \\\n;\n./run --arch arm --emulator gem5 --linux-build-id gem5-v4.15\n....\n\nand then on another shell:\n\n....\nvinagre localhost:5900\n....\n\nThe <<config-logo>> penguin only appears after several seconds, together with kernel messages of type:\n\n....\n[    0.152755] [drm] found ARM HDLCD version r0p0\n[    0.152790] hdlcd 2b000000.hdlcd: bound virt-encoder (ops 0x80935f94)\n[    0.152795] [drm] Supports vblank timestamp caching Rev 2 (21.10.2013).\n[    0.152799] [drm] No driver support for vblank timestamp query.\n[    0.215179] Console: switching to colour frame buffer device 240x67\n[    0.230389] hdlcd 2b000000.hdlcd: fb0:  frame buffer device\n[    0.230509] [drm] Initialized hdlcd 1.0.0 20151021 for 2b000000.hdlcd on minor 0\n....\n\nThe port `5900` is incremented by one if you already have something running on that port, `gem5` stdout tells us the right port on stdout as:\n\n....\nsystem.vncserver: Listening for connections on port 5900\n....\n\nand when we connect it shows a message:\n\n....\ninfo: VNC client attached\n....\n\nAlternatively, you can also dump each new frame to an image file with `--frame-capture`:\n\n....\n./run \\\n  --arch arm \\\n  --emulator gem5 \\\n  --linux-build-id gem5-v4.15 \\\n  -- --frame-capture \\\n;\n....\n\nThis creates on compressed PNG whenever the screen image changes inside the <<m5out-directory>> with filename of type:\n\n....\nframes_system.vncserver/fb.<frame-index>.<timestamp>.png.gz\n....\n\nIt is fun to see how we get one new frame whenever the white underscore cursor appears and reappears under the penguin!\n\nThe last frame is always available uncompressed at: `system.framebuffer.png`.\n\nTODO <<kmscube>> failed on `aarch64` with:\n\n....\nkmscube[706]: unhandled level 2 translation fault (11) at 0x00000000, esr 0x92000006, in libgbm.so.1.0.0[7fbf6a6000+e000]\n....\n\nTested on: https://github.com/cirosantilli/linux-kernel-module-cheat/commit/38fd6153d965ba20145f53dc1bb3ba34b336bde9[38fd6153d965ba20145f53dc1bb3ba34b336bde9]\n\n==== Graphic mode gem5 aarch64\n\nFor `aarch64` we also need to configure the kernel with link:linux_config/display[]:\n\n....\ngit -C \"$(./getvar linux_source_dir)\" fetch https://gem5.googlesource.com/arm/linux gem5/v4.15:gem5/v4.15\ngit -C \"$(./getvar linux_source_dir)\" checkout gem5/v4.15\n./build-linux \\\n  --arch aarch64 \\\n  --config-fragment linux_config/display \\\n  --custom-config-file-gem5 \\\n  --linux-build-id gem5-v4.15 \\\n;\ngit -C \"$(./getvar linux_source_dir)\" checkout -\n./run --arch aarch64 --emulator gem5 --linux-build-id gem5-v4.15\n....\n\nThis is because the gem5 `aarch64` defconfig does not enable HDLCD like the 32 bit one `arm` one for some reason.\n\n==== gem5 graphic mode DP650\n\nTODO get working. There is an unmerged patchset at: https://gem5-review.googlesource.com/c/public/gem5/+/11036/1\n\nThe DP650 is a newer display hardware than HDLCD. TODO is its interface publicly documented anywhere? Since it has a gem5 model and https://github.com/torvalds/linux/blob/v4.19/drivers/gpu/drm/arm/Kconfig#L39[in-tree Linux kernel support], that information cannot be secret?\n\nThe key option to enable support in Linux is `DRM_MALI_DISPLAY=y` which we enable at link:linux_config/display[].\n\nBuild the kernel exactly as for <<graphic-mode-gem5-aarch64>> and then run with:\n\n....\n./run --arch aarch64 --dp650 --emulator gem5 --linux-build-id gem5-v4.15\n....\n\n==== gem5 graphic mode internals\n\nWe cannot use mainline Linux because the <<gem5-arm-linux-kernel-patches>> are required at least to provide the `CONFIG_DRM_VIRT_ENCODER` option.\n\ngem5 emulates the http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0541c/CHDBAIDI.html[HDLCD] ARM Holdings hardware for `arm` and `aarch64`.\n\nThe kernel uses HDLCD to implement the <<drm>> interface, the required kernel config options are present at: link:linux_config/display[].\n\nTODO: minimize out the `--custom-config-file`. If we just remove it on `arm`: it does not work with a failing dmesg:\n\n....\n[    0.066208] [drm] found ARM HDLCD version r0p0\n[    0.066241] hdlcd 2b000000.hdlcd: bound virt-encoder (ops drm_vencoder_ops)\n[    0.066247] [drm] Supports vblank timestamp caching Rev 2 (21.10.2013).\n[    0.066252] [drm] No driver support for vblank timestamp query.\n[    0.066276] hdlcd 2b000000.hdlcd: Cannot do DMA to address 0x0000000000000000\n[    0.066281] swiotlb: coherent allocation failed for device 2b000000.hdlcd size=8294400\n[    0.066288] CPU: 0 PID: 1 Comm: swapper/0 Not tainted 4.15.0 #1\n[    0.066293] Hardware name: V2P-AARCH64 (DT)\n[    0.066296] Call trace:\n[    0.066301]  dump_backtrace+0x0/0x1b0\n[    0.066306]  show_stack+0x24/0x30\n[    0.066311]  dump_stack+0xb8/0xf0\n[    0.066316]  swiotlb_alloc_coherent+0x17c/0x190\n[    0.066321]  __dma_alloc+0x68/0x160\n[    0.066325]  drm_gem_cma_create+0x98/0x120\n[    0.066330]  drm_fbdev_cma_create+0x74/0x2e0\n[    0.066335]  __drm_fb_helper_initial_config_and_unlock+0x1d8/0x3a0\n[    0.066341]  drm_fb_helper_initial_config+0x4c/0x58\n[    0.066347]  drm_fbdev_cma_init_with_funcs+0x98/0x148\n[    0.066352]  drm_fbdev_cma_init+0x40/0x50\n[    0.066357]  hdlcd_drm_bind+0x220/0x428\n[    0.066362]  try_to_bring_up_master+0x21c/0x2b8\n[    0.066367]  component_master_add_with_match+0xa8/0xf0\n[    0.066372]  hdlcd_probe+0x60/0x78\n[    0.066377]  platform_drv_probe+0x60/0xc8\n[    0.066382]  driver_probe_device+0x30c/0x478\n[    0.066388]  __driver_attach+0x10c/0x128\n[    0.066393]  bus_for_each_dev+0x70/0xb0\n[    0.066398]  driver_attach+0x30/0x40\n[    0.066402]  bus_add_driver+0x1d0/0x298\n[    0.066408]  driver_register+0x68/0x100\n[    0.066413]  __platform_driver_register+0x54/0x60\n[    0.066418]  hdlcd_platform_driver_init+0x20/0x28\n[    0.066424]  do_one_initcall+0x44/0x130\n[    0.066428]  kernel_init_freeable+0x13c/0x1d8\n[    0.066433]  kernel_init+0x18/0x108\n[    0.066438]  ret_from_fork+0x10/0x1c\n[    0.066444] hdlcd 2b000000.hdlcd: Failed to set initial hw configuration.\n[    0.066470] hdlcd 2b000000.hdlcd: master bind failed: -12\n[    0.066477] hdlcd: probe of 2b000000.hdlcd failed with error -12\n....\n\nSo what other options are missing from `gem5_defconfig`? It would be cool to minimize it out to better understand the options.\n\n[[x11]]\n=== X11 Buildroot\n\nOnce you've seen the `CONFIG_LOGO` penguin as a sanity check, you can try to go for a cooler X11 Buildroot setup.\n\nBuild and run:\n\n....\n./build-buildroot --config-fragment buildroot_config/x11\n./run --graphic\n....\n\nInside QEMU:\n\n....\nstartx\n....\n\nAnd then from the GUI you can start exciting graphical programs such as:\n\n....\nxcalc\nxeyes\n....\n\nOutcome: xref:image-x11[xrefstyle=full]\n\n[[image-x11]]\n.X11 Buildroot graphical user interface screenshot\n[link=x11.png]\nimage::x11.png[]\n\nWe don't build X11 by default because it takes a considerable amount of time (about 20%), and is not expected to be used by most users: you need to pass the `-x` flag to enable it.\n\nMore details: https://unix.stackexchange.com/questions/70931/how-to-install-x11-on-my-own-linux-buildroot-system/306116#306116\n\nNot sure how well that graphics stack represents real systems, but if it does it would be a good way to understand how it works.\n\nTo x11 packages have an `xserver` prefix as in:\n\n....\n./build-buildroot --config-fragment buildroot_config/x11 -- xserver_xorg-server-reconfigure\n....\n\nthe easiest way to find them out is to just list `\"$(./getvar buildroot_build_build_dir)/x*`.\n\nTODO as of: c2696c978d6ca88e8b8599c92b1beeda80eb62b2 I noticed that `startx` leads to a <<bug-on>>:\n\n....\n[    2.809104] WARNING: CPU: 0 PID: 51 at drivers/gpu/drm/ttm/ttm_bo_vm.c:304 ttm_bo_vm_open+0x37/0x40\n....\n\n==== X11 Buildroot mouse not moving\n\nTODO 9076c1d9bcc13b6efdb8ef502274f846d8d4e6a1 I'm 100% sure that it was working before, but I didn't run it forever, and it stopped working at some point. Needs bisection, on whatever commit last touched x11 stuff.\n\n* https://askubuntu.com/questions/730891/how-can-i-get-a-mouse-cursor-in-qemu\n* https://stackoverflow.com/questions/19665412/mouse-and-keyboard-not-working-in-qemu-emulator\n\n`-show-cursor` did not help, I just get to see the host cursor, but the guest cursor still does not move.\n\nDoing:\n\n....\nwatch -n 1 grep i8042 /proc/interrupts\n....\n\nshows that interrupts do happen when mouse and keyboard presses are done, so I expect that it is some wrong either with:\n\n* QEMU. Same behaviour if I try the host's QEMU 2.10.1 however.\n* X11 configuration. We do have `BR2_PACKAGE_XDRIVER_XF86_INPUT_MOUSE=y`.\n\n`/var/log/Xorg.0.log` contains the following interesting lines:\n\n....\n[    27.549] (II) LoadModule: \"mouse\"\n[    27.549] (II) Loading /usr/lib/xorg/modules/input/mouse_drv.so\n[    27.590] (EE) <default pointer>: Cannot find which device to use.\n[    27.590] (EE) <default pointer>: cannot open input device\n[    27.590] (EE) PreInit returned 2 for \"<default pointer>\"\n[    27.590] (II) UnloadModule: \"mouse\"\n....\n\nThe file `/dev/inputs/mice` does not exist.\n\nNote that our current link:kernel_confi_fragment sets:\n\n....\n# CONFIG_INPUT_MOUSE is not set\n# CONFIG_INPUT_MOUSEDEV_PSAUX is not set\n....\n\nfor gem5, so you might want to remove those lines to debug this.\n\n==== X11 Buildroot ARM\n\nOn ARM, `startx` hangs at a message:\n\n....\nvgaarb: this pci device is not a vga device\n....\n\nand nothing shows on the screen, and:\n\n....\ngrep EE /var/log/Xorg.0.log\n....\n\nsays:\n\n....\n(EE) Failed to load module \"modesetting\" (module does not exist, 0)\n....\n\nA friend told me this but I haven't tried it yet:\n\n* `xf86-video-modesetting` is likely the missing ingredient, but it does not seem possible to activate it from Buildroot currently without patching things.\n* `xf86-video-fbdev` should work as well, but we need to make sure fbdev is enabled, and maybe add some line to the `Xorg.conf`\n\n== Networking\n\n=== Enable networking\n\nWe disable networking by default because it starts an userland process, and we want to keep the number of userland processes to a minimum to make the system more understandable as explained at: xref:resource-tradeoff-guidelines[xrefstyle=full]\n\nTo enable networking on Buildroot, simply run:\n\n....\nifup -a\n....\n\nThat command goes over all (`-a`) the interfaces in `/etc/network/interfaces` and brings them up.\n\nThen test it with:\n\n....\nwget google.com\ncat index.html\n....\n\nDisable networking with:\n\n....\nifdown -a\n....\n\nTo enable networking by default after boot, use the methods documented at <<init-busybox>>.\n\n=== ping\n\n`ping` does not work within QEMU by default, e.g.:\n\n....\nping google.com\n....\n\nhangs after printing the header:\n\n....\nPING google.com (216.58.204.46): 56 data bytes\n....\n\nHere Ciro describes how to get it working: https://unix.stackexchange.com/questions/473448/how-to-ping-from-the-qemu-guest-to-an-external-url\n\nFurther bibliography: https://superuser.com/questions/787400/qemu-user-mode-networking-doesnt-work\n\n=== Guest host networking\n\nIn this section we discuss how to interact between the guest and the host through networking.\n\nFirst ensure that you can access the external network since that is easier to get working, see: xref:networking[xrefstyle=full].\n\n==== Host to guest networking\n\n===== nc host to guest\n\nWith `nc` we can create the most minimal example possible as a sanity check.\n\nOn guest run:\n\n....\nnc -l -p 45455\n....\n\nThen on host run:\n\n....\necho asdf | nc localhost 45455\n....\n\n`asdf` appears on the guest.\n\nThis uses:\n\n* BusyBox' `nc` utility, which is enabled with `CONFIG_NC=y`\n* `nc` from the `netcat-openbsd` package on an Ubuntu 18.04 host\n\nOnly this specific port works by default since we have forwarded it on the QEMU command line.\n\nWe us this exact procedure to connect to <<gdbserver>>.\n\n===== ssh into guest\n\nNot enabled by default due to the build / runtime overhead. To enable, build with:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_OPENSSH=y'\n....\n\nThen inside the guest turn on sshd:\n\n....\n./sshd.sh\n....\n\nSource: link:rootfs_overlay/lkmc/sshd.sh[]\n\nAnd finally on host:\n\n....\nssh root@localhost -p 45456\n....\n\nBibliography: https://unix.stackexchange.com/questions/124681/how-to-ssh-from-host-to-guest-using-qemu/307557#307557\n\n===== gem5 host to guest networking\n\nCould not do port forwarding from host to guest, and therefore could not use `gdbserver`: https://stackoverflow.com/questions/48941494/how-to-do-port-forwarding-from-guest-to-host-in-gem5\n\n==== Guest to host networking\n\nFirst <<enable-networking>>.\n\nThen in the host, start a server:\n\n....\npython -m SimpleHTTPServer 8000\n....\n\nAnd then in the guest, find the IP we need to hit with:\n\n....\nip rounte\n....\n\nwhich gives:\n\n.....\ndefault via 10.0.2.2 dev eth0\n10.0.2.0/24 dev eth0 scope link  src 10.0.2.15\n.....\n\nso we use in the guest:\n\n....\nwget 10.0.2.2:8000\n....\n\nBibliography:\n\n* https://serverfault.com/questions/769874/how-to-forward-a-port-from-guest-to-host-in-qemu-kvm/951835#951835\n* https://unix.stackexchange.com/questions/78953/qemu-how-to-ping-host-network/547698#547698\n\n=== 9P\n\nThe https://en.wikipedia.org/wiki/9P_(protocol)[9p protocol] allows the guest to mount a host directory.\n\nBoth QEMU and <<gem5-9p>> support 9P.\n\n==== 9P vs NFS\n\nAll of 9P and NFS (and sshfs) allow sharing directories between guest and host.\n\nAdvantages of 9P\n\n* requires `sudo` on the host to mount\n* we could share a guest directory to the host, but this would require running a server on the guest, which adds <<resource-tradeoff-guidelines,simulation overhead>>\n+\nFurthermore, this would be inconvenient, since what we usually want to do is to share host cross built files with the guest, and to do that we would have to copy the files over after the guest starts the server.\n* QEMU implements 9P natively, which makes it very stable and convenient, and must mean it is a simpler protocol than NFS as one would expect.\n+\nThis is not the case for gem5 7bfb7f3a43f382eb49853f47b140bfd6caad0fb8 unfortunately, which relies on the https://github.com/chaos/diod[diod] host daemon, although it is not unfeasible that future versions could implement it natively as well.\n\nAdvantages of NFS:\n\n* way more widely used and therefore stable and available, not to mention that it also works on real hardware.\n* the name does not start with a digit, which is an invalid identifier in all programming languages known to man. Who in their right mind would call a software project as such? It does not even match the natural order of Plan 9; Plan then 9: P9!\n\n==== 9P getting started\n\nAs usual, we have already set everything up for you. On host:\n\n....\ncd \"$(./getvar p9_dir)\"\nuname -a > host\n....\n\nGuest:\n\n....\ncd /mnt/9p/data\ncat host\nuname -a > guest\n....\n\nHost:\n\n....\ncat guest\n....\n\nThe main ingredients for this are:\n\n* `9P` settings in our <<kernel-configs-about,kernel configs>>\n* `9p` entry on our link:rootfs_overlay/etc/fstab[]\n+\nAlternatively, you could also mount your own with:\n+\n....\nmkdir /mnt/my9p\nmount -t 9p -o trans=virtio,version=9p2000.L host0 /mnt/my9p\n....\n+\nwhere mount tag `host0` is set by the emulator (`mount_tag` flag on QEMU CLI), and can be found in the guest with: `cat /sys/bus/virtio/drivers/9pnet_virtio/virtio0/mount_tag` as documented at: https://www.kernel.org/doc/Documentation/filesystems/9p.txt[].\n* Launch QEMU with `-virtfs` as in your link:run[] script\n+\nWhen we tried:\n+\n....\nsecurity_model=mapped\n....\n+\nwrites from guest failed due to user mismatch problems: https://serverfault.com/questions/342801/read-write-access-for-passthrough-9p-filesystems-with-libvirt-qemu\n\nBibliography:\n\n* https://superuser.com/questions/628169/how-to-share-a-directory-with-the-host-without-networking-in-qemu\n* https://wiki.qemu.org/Documentation/9psetup\n\n==== gem5 9P\n\nIs possible on aarch64 as shown at: https://gem5-review.googlesource.com/c/public/gem5/+/22831[], and it is just a matter of exposing to X86 for those that want it.\n\nEnable it by passing the `--vio-9p` option on the fs.py gem5 command line:\n\n....\n./run --arch aarch64 --emulator gem5 -- --vio-9p\n....\n\nThen on the guest:\n\n....\nmkdir -p /mnt/9p/gem5\nmount -t 9p -o trans=virtio,version=9p2000.L,aname=/path/to/linux-kernel-module-cheat/out/run/gem5/aarch64/0/m5out/9p/share gem5 /mnt/9p/gem5\necho asdf > /mnt/9p/gem5/qwer\n....\n\nYes, you have to pass the full path to the directory on the host. Yes, this is horrible.\n\nThe shared directory is:\n\n....\nout/run/gem5/aarch64/0/m5out/9p/share\n....\n\nso we can observe the file the guest wrote from the host with:\n\n....\nout/run/gem5/aarch64/0/m5out/9p/share/qwer\n....\n\nand vice versa:\n\n....\necho zxvc > out/run/gem5/aarch64/0/m5out/9p/share/qwer\n....\n\nis now visible from the guest:\n\n....\ncat /mnt/9p/gem5/qwer\n....\n\nCheckpoint restore with an open mount will likely fail because gem5 uses an ugly external executable to implement diod. The protocol is not very complex, and QEMU implements it in-tree, which is what gem5 should do as well at some point.\n\nAlso checkpoint without `--vio-9p` and restore with `--vio-9p` did not work either, the mount fails.\n\nHowever, this did work, on guest:\n\n....\nunmount /mnt/9p/gem5\nm5 checkpoint\n....\n\nthen restore with the detalied CPU of interest e.g.\n\n....\n./run --arch aarch64 --emulator gem5 -- --vio-9p --cpu-type DerivO3CPU --caches\n....\n\nTested on gem5 b2847f43c91e27f43bd4ac08abd528efcf00f2fd, LKMC 52a5fdd7c1d6eadc5900fc76e128995d4849aada.\n\n==== NFS\n\nTODO: get working.\n\n<<9p>> is better with emulation, but let's just get this working for fun.\n\nFirst make sure that this works: xref:guest-to-host-networking[xrefstyle=full].\n\nThen, build the kernel with NFS support:\n\n....\n./build-linux --config-fragment linux_config/nfs\n....\n\nNow on host:\n\n....\nsudo apt-get install nfs-kernel-server\n....\n\nNow edit `/etc/exports` to contain:\n\n....\n/tmp *(rw,sync,no_root_squash,no_subtree_check)\n....\n\nand restart the server:\n\n....\nsudo systemctl restart nfs-kernel-server\n....\n\nNow on guest:\n\n....\nmkdir /mnt/nfs\nmount -t nfs 10.0.2.2:/tmp /mnt/nfs\n....\n\nTODO: failing with:\n\n....\nmount: mounting 10.0.2.2:/tmp on /mnt/nfs failed: No such device\n....\n\nAnd now the `/tmp` directory from host is not mounted on guest!\n\nIf you don't want to start the NFS server after the next boot automatically so save resources, https://askubuntu.com/questions/19320/how-to-enable-or-disable-services[do]:\n\n....\nsystemctl disable nfs-kernel-server\n....\n\n== Operating systems\n\nhttps://en.wikipedia.org/wiki/Operating_system\n\n* <<linux-kernel>>\n* <<freebsd>>\n* <<rtos>>\n* <<xen>>\n* <<u-boot>>\n\n== Linux kernel\n\nhttps://en.wikipedia.org/wiki/Linux_kernel\n\n=== Linux kernel configuration\n\n==== Modify kernel config\n\nTo modify a single option on top of our <<kernel-configs-about,default kernel configs>>, do:\n\n....\n./build-linux --config 'CONFIG_FORTIFY_SOURCE=y'\n....\n\nKernel modules depend on certain kernel configs, and therefore in general you might have to clean and rebuild the kernel modules after changing the kernel config:\n\n....\n./build-modules --clean\n./build-modules\n....\n\nand then proceed as in <<your-first-kernel-module-hack>>.\n\nYou might often get way without rebuilding the kernel modules however.\n\nTo use an extra kernel config fragment file on top of our defaults, do:\n\n....\nprintf '\nCONFIG_IKCONFIG=y\nCONFIG_IKCONFIG_PROC=y\n' > data/myconfig\n./build-linux --config-fragment 'data/myconfig'\n....\n\nTo use just your own exact `.config` instead of our defaults ones, use:\n\n....\n./build-linux --custom-config-file data/myconfig\n....\n\nThere is also a shortcut `--custom-config-file-gem5` to use the <<gem5-arm-linux-kernel-patches>>.\n\nThe following options can all be used together, sorted by decreasing config setting power precedence:\n\n* `--config`\n* `--config-fragment`\n* `--custom-config-file`\n\nTo do a clean menu config yourself and use that for the build, do:\n\n....\n./build-linux --clean\n./build-linux --custom-config-target menuconfig\n....\n\nBut remember that every new build re-configures the kernel by default, so to keep your configs you will need to use on further builds:\n\n....\n./build-linux --no-configure\n....\n\nSo what you likely want to do instead is to save that as a new `defconfig` and use it later as:\n\n....\n./build-linux --no-configure --no-modules-install savedefconfig\ncp \"$(./getvar linux_build_dir)/defconfig\" data/myconfig\n./build-linux --custom-config-file data/myconfig\n....\n\nYou can also use other config generating targets such as `defconfig` with the same method as shown at: xref:linux-kernel-defconfig[xrefstyle=full].\n\n==== Find the kernel config\n\nGet the build config in guest:\n\n....\nzcat /proc/config.gz\n....\n\nor with our shortcut:\n\n....\n./conf.sh\n....\n\nor to conveniently grep for a specific option case insensitively:\n\n....\n./conf.sh ikconfig\n....\n\nSource: link:rootfs_overlay/lkmc/conf.sh[].\n\nThis is enabled by:\n\n....\nCONFIG_IKCONFIG=y\nCONFIG_IKCONFIG_PROC=y\n....\n\nFrom host:\n\n....\ncat \"$(./getvar linux_config)\"\n....\n\nJust for fun https://stackoverflow.com/questions/14958192/how-to-get-the-config-from-a-linux-kernel-image/14958263#14958263[]:\n\n....\n./linux/scripts/extract-ikconfig \"$(./getvar vmlinux)\"\n....\n\nalthough this can be useful when someone gives you a random image.\n\n[[kernel-configs-about]]\n==== About our Linux kernel configs\n\nBy default, link:build-linux[] generates a `.config` that is a mixture of:\n\n* a base config extracted from Buildroot's minimal per machine `.config`, which has the minimal options needed to boot as explained at: xref:buildroot-kernel-config[xrefstyle=full].\n* small overlays put top of that\n\nTo find out which kernel configs are being used exactly, simply run:\n\n....\n./build-linux --dry-run\n....\n\nand look for the `merge_config.sh` call. This script from the Linux kernel tree, as the name suggests, merges multiple configuration files into one as explained at: https://unix.stackexchange.com/questions/224887/how-to-script-make-menuconfig-to-automate-linux-kernel-build-configuration/450407#450407\n\nFor each arch, the base of our configs are named as:\n\n....\nlinux_config/buildroot-<arch>\n....\n\ne.g.: link:linux_config/buildroot-x86_64[].\n\nThese configs are extracted directly from a Buildroot build with link:update-buildroot-kernel-configs[].\n\nNote that Buildroot can `sed` override some of the configurations, e.g. it forces `CONFIG_BLK_DEV_INITRD=y` when `BR2_TARGET_ROOTFS_CPIO` is on. For this reason, those configs are not simply copy pasted from Buildroot files, but rather from a Buildroot kernel build, and then minimized with `make savedefconfig`: https://stackoverflow.com/questions/27899104/how-to-create-a-defconfig-file-from-a-config\n\nOn top of those, we add the following by default:\n\n* link:linux_config/min[]: see: xref:linux-kernel-min-config[xrefstyle=full]\n* link:linux_config/default[]: other optional configs that we enable by default because they increase visibility, or expose some cool feature, and don't significantly increase build time nor add significant runtime overhead\n+\nWe have since observed that the kernel size itself is very bloated compared to `defconfig` as shown at: xref:linux-kernel-defconfig[xrefstyle=full].\n\n[[buildroot-kernel-config]]\n===== About Buildroot's kernel configs\n\nTo see Buildroot's base configs, start from https://github.com/buildroot/buildroot/blob/2018.05/configs/qemu_x86_64_defconfig[`buildroot/configs/qemu_x86_64_defconfig`].\n\nThat file contains `BR2_LINUX_KERNEL_CUSTOM_CONFIG_FILE=\"board/qemu/x86_64/linux-4.15.config\"`, which points to the base config file used: https://github.com/buildroot/buildroot/blob/2018.05/board/qemu/x86_64/linux-4.15.config[board/qemu/x86_64/linux-4.15.config].\n\n`arm`, on the other hand, uses https://github.com/buildroot/buildroot/blob/2018.05/configs/qemu_arm_vexpress_defconfig[`buildroot/configs/qemu_arm_vexpress_defconfig`], which contains `BR2_LINUX_KERNEL_DEFCONFIG=\"vexpress\"`, and therefore just does a `make vexpress_defconfig`, and gets its config from the Linux kernel tree itself.\n\n====== Linux kernel defconfig\n\nTo boot https://stackoverflow.com/questions/41885015/what-exactly-does-linux-kernels-make-defconfig-do[defconfig] from disk on Linux and see a shell, all we need is these missing virtio options:\n\n....\n./build-linux \\\n  --linux-build-id defconfig \\\n  --custom-config-target defconfig \\\n  --config CONFIG_VIRTIO_PCI=y \\\n  --config CONFIG_VIRTIO_BLK=y \\\n;\n./run --linux-build-id defconfig\n....\n\nOh, and check this out:\n\n....\ndu -h \\\n  \"$(./getvar vmlinux)\" \\\n  \"$(./getvar --linux-build-id defconfig vmlinux)\" \\\n;\n....\n\nOutput:\n\n....\n360M    /path/to/linux-kernel-module-cheat/out/linux/default/x86_64/vmlinux\n47M     /path/to/linux-kernel-module-cheat/out/linux/defconfig/x86_64/vmlinux\n....\n\nBrutal. Where did we go wrong?\n\nThe extra virtio options are not needed if we use <<initrd>>:\n\n....\n./build-linux \\\n  --linux-build-id defconfig \\\n  --custom-config-target defconfig \\\n;\n./run --initrd --linux-build-id defconfig\n....\n\nOn aarch64, we can boot from initrd with:\n\n....\n./build-linux \\\n  --arch aarch64 \\\n  --linux-build-id defconfig \\\n  --custom-config-target defconfig \\\n;\n./run \\\n  --arch aarch64 \\\n  --initrd \\\n  --linux-build-id defconfig \\\n  --memory 2G \\\n;\n....\n\nWe need the 2G of memory because the CPIO is 600MiB due to a humongous amount of loadable kernel modules!\n\nIn aarch64, the size situation is inverted from x86_64, and this can be seen on the vmlinux size as well:\n\n....\n118M    /path/to/linux-kernel-module-cheat/out/linux/default/aarch64/vmlinux\n240M    /path/to/linux-kernel-module-cheat/out/linux/defconfig/aarch64/vmlinux\n....\n\nSo it seems that the ARM devs decided rather than creating a minimal config that boots QEMU, to try and make a single config that boots every board in existence. Terrible!\n\nBibliography: https://unix.stackexchange.com/questions/29439/compiling-the-kernel-with-default-configurations/204512#204512\n\nTested on 1e2b7f1e5e9e3073863dc17e25b2455c8ebdeadd + 1.\n\n====== Linux kernel min config\n\nlink:linux_config/min[] contains minimal tweaks required to boot gem5 or for using our slightly different QEMU command line options than Buildroot on all archs.\n\nIt is one of the default config fragments we use, as explained at: xref:kernel-configs-about[xrefstyle=full]>.\n\nHaving the same config working for both QEMU and gem5 (oh, the hours of bisection) means that you can deal with functional matters in QEMU, which runs much faster, and switch to gem5 only for performance issues.\n\nWe can build just with `min` on top of the base config with:\n\n....\n./build-linux \\\n  --arch aarch64 \\\n  --config-fragment linux_config/min \\\n  --custom-config-file linux_config/buildroot-aarch64 \\\n  --linux-build-id min \\\n;\n....\n\nvmlinux had a very similar size to the default. It seems that link:linux_config/buildroot-aarch64[] contains or implies most link:linux_config/default[] options already? TODO: that seems odd, really?\n\nTested on 649d06d6758cefd080d04dc47fd6a5a26a620874 + 1.\n\n===== Notable alternate gem5 kernel configs\n\nOther configs which we had previously tested at 4e0d9af81fcce2ce4e777cb82a1990d7c2ca7c1e are:\n\n* `arm` and `aarch64` configs present in the official ARM gem5 Linux kernel fork as described at: xref:gem5-arm-linux-kernel-patches[xrefstyle=full]. Some of the configs present there are added by the patches.\n* Jason's magic `x86_64` config: http://web.archive.org/web/20171229121642/http://www.lowepower.com/jason/files/config which is referenced at: http://web.archive.org/web/20171229121525/http://www.lowepower.com/jason/setting-up-gem5-full-system.html[]. QEMU boots with that by removing `# CONFIG_VIRTIO_PCI is not set`.\n\n=== Kernel version\n\n==== Find the kernel version\n\nWe try to use the latest possible kernel major release version.\n\nIn QEMU:\n\n....\ncat /proc/version\n....\n\nor in the source:\n\n....\ncd \"$(./getvar linux_source_dir)\"\ngit log | grep -E '    Linux [0-9]+\\.' | head\n....\n\n==== Update the Linux kernel\n\nDuring update all you kernel modules may break since the kernel API is not stable.\n\nThey are usually trivial breaks of things moving around headers or to sub-structs.\n\nThe userland, however, should simply not break, as Linus enforces strict backwards compatibility of userland interfaces.\n\nThis backwards compatibility is just awesome, it makes getting and running the latest master painless.\n\nThis also makes this repo the perfect setup to develop the Linux kernel.\n\nIn case something breaks while updating the Linux kernel, you can try to bisect it to understand the root cause, see: xref:bisection[xrefstyle=full].\n\n===== Update the Linux kernel LKMC procedure\n\nFirst, use use the branching procedure described at: xref:update-a-forked-submodule[xrefstyle=full]\n\nBecause the kernel is so central to this repository, almost all tests must be re-run, so basically just follow the full testing procedure described at: xref:test-this-repo[xrefstyle=full]. The only tests that can be skipped are essentially the <<baremetal>> tests.\n\nBefore comitting, don't forget to update:\n\n* the `linux_kernel_version` constant in link:common.py[]\n* the tagline of this repository on:\n** this README\n** the GitHub project description\n\n==== Downgrade the Linux kernel\n\nThe kernel is not forward compatible, however, so downgrading the Linux kernel requires downgrading the userland too to the latest Buildroot branch that supports it.\n\nThe default Linux kernel version is bumped in Buildroot with commit messages of type:\n\n....\nlinux: bump default to version 4.9.6\n....\n\nSo you can try:\n\n....\ngit log --grep 'linux: bump default to version'\n....\n\nThose commits change `BR2_LINUX_KERNEL_LATEST_VERSION` in `/linux/Config.in`.\n\nYou should then look up if there is a branch that supports that kernel. Staying on branches is a good idea as they will get backports, in particular ones that fix the build as newer host versions come out.\n\nFinally, after downgrading Buildroot, if something does not work, you might also have to make some changes to how this repo uses Buildroot, as the Buildroot configuration options might have changed.\n\nWe don't expect those changes to be very difficult. A good way to approach the task is to:\n\n* do a dry run build to get the equivalent Bash commands used:\n+\n....\n./build-buildroot --dry-run\n....\n* build the Buildroot documentation for the version you are going to use, and check if all Buildroot build commands make sense there\n\nThen, if you spot an option that is wrong, some grepping in this repo should quickly point you to the code you need to modify.\n\nIt also possible that you will need to apply some patches from newer Buildroot versions for it to build, due to incompatibilities with the host Ubuntu packages and that Buildroot version. Just read the error message, and try:\n\n* `git log master -- packages/<pkg>`\n* Google the error message for mailing list hits\n\nSuccessful port reports:\n\n* v3.18: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/39#issuecomment-438525481\n\n=== Kernel command line parameters\n\nBootloaders can pass a string as input to the Linux kernel when it is booting to control its behaviour, much like the `execve` system call does to userland processes.\n\nThis allows us to control the behaviour of the kernel without rebuilding anything.\n\nWith QEMU, QEMU itself acts as the bootloader, and provides the `-append` option and we expose it through `./run --kernel-cli`, e.g.:\n\n....\n./run --kernel-cli 'foo bar'\n....\n\nThen inside the host, you can check which options were given with:\n\n....\ncat /proc/cmdline\n....\n\nThey are also printed at the beginning of the boot message:\n\n....\ndmesg | grep \"Command line\"\n....\n\nSee also:\n\n* https://unix.stackexchange.com/questions/48601/how-to-display-the-linux-kernel-command-line-parameters-given-for-the-current-bo\n* https://askubuntu.com/questions/32654/how-do-i-find-the-boot-parameters-used-by-the-running-kernel\n\nThe arguments are documented in the kernel documentation: https://www.kernel.org/doc/html/v4.14/admin-guide/kernel-parameters.html\n\nWhen dealing with real boards, extra command line options are provided on some magic bootloader configuration file, e.g.:\n\n* GRUB configuration files: https://askubuntu.com/questions/19486/how-do-i-add-a-kernel-boot-parameter\n* Raspberry pi `/boot/cmdline.txt` on a magic partition: https://raspberrypi.stackexchange.com/questions/14839/how-to-change-the-kernel-commandline-for-archlinuxarm-on-raspberry-pi-effectly\n\n==== Kernel command line parameters escaping\n\nDouble quotes can be used to escape spaces as in `opt=\"a b\"`, but double quotes themselves cannot be escaped, e.g. `opt\"a\\\"b\"`\n\nThis even lead us to use base64 encoding with `--eval`!\n\n==== Kernel command line parameters definition points\n\nThere are two methods:\n\n* `__setup` as in:\n+\n....\n__setup(\"console=\", console_setup);\n....\n* `core_param` as in:\n+\n....\ncore_param(panic, panic_timeout, int, 0644);\n....\n\n`core_param` suggests how they are different:\n\n....\n/**\n * core_param - define a historical core kernel parameter.\n\n...\n\n * core_param is just like module_param(), but cannot be modular and\n * doesn't add a prefix (such as \"printk.\").  This is for compatibility\n * with __setup(), and it makes sense as truly core parameters aren't\n * tied to the particular file they're in.\n */\n....\n\n==== rw\n\nBy default, the Linux kernel mounts the root filesystem as readonly. TODO rationale?\n\nThis cannot be observed in the default BusyBox init, because by default our link:rootfs_overlay/etc/inittab[] does:\n\n....\n/bin/mount -o remount,rw /\n....\n\nAnalogously, Ubuntu 18.04 does in its fstab something like:\n\n....\nUUID=/dev/sda1 / ext4 errors=remount-ro 0 1\n....\n\nwhich uses default mount `rw` flags.\n\nWe have however removed those setups init setups to keep things more minimal, and replaced them with the `rw` kernel boot parameter makes the root mounted as writable.\n\nTo observe the default readonly behaviour, hack the link:run[] script to remove <<replace-init,replace init>>, and then run on a raw shell:\n\n....\n./run --kernel-cli 'init=/bin/sh'\n....\n\nNow try to do:\n\n....\ntouch a\n....\n\nwhich fails with:\n\n....\ntouch: a: Read-only file system\n....\n\nWe can also observe the read-onlyness with:\n\n....\nmount -t proc /proc\nmount\n....\n\nwhich contains:\n\n....\n/dev/root on / type ext2 (ro,relatime,block_validity,barrier,user_xattr)\n....\n\nand so it is Read Only as shown by `ro`.\n\n==== norandmaps\n\nDisable userland address space randomization. Test it out by running <<rand-check-out>> twice:\n\n....\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out'\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out'\n....\n\nIf we remove it from our link:run[] script by hacking it up, the addresses shown by `linux/rand_check.out` vary across boots.\n\nEquivalent to:\n\n....\necho 0 > /proc/sys/kernel/randomize_va_space\n....\n\n=== printk\n\n`printk` is the most simple and widely used way of getting information from the kernel, so you should familiarize yourself with its basic configuration.\n\nWe use `printk` a lot in our kernel modules, and it shows on the terminal by default, along with stdout and what you type.\n\nHide all `printk` messages:\n\n....\ndmesg -n 1\n....\n\nor equivalently:\n\n....\necho 1 > /proc/sys/kernel/printk\n....\n\nSee also: https://superuser.com/questions/351387/how-to-stop-kernel-messages-from-flooding-my-console\n\nDo it with a <<kernel-command-line-parameters>> to affect the boot itself:\n\n....\n./run --kernel-cli 'loglevel=5'\n....\n\nand now only boot warning messages or worse show, which is useful to identify problems.\n\nOur default `printk` format is:\n\n....\n<LEVEL>[TIMESTAMP] MESSAGE\n....\n\ne.g.:\n\n....\n<6>[    2.979121] Freeing unused kernel memory: 2024K\n....\n\nwhere:\n\n* `LEVEL`: higher means less serious\n* `TIMESTAMP`: seconds since boot\n\nThis format is selected by the following boot options:\n\n* `console_msg_format=syslog`: add the `<LEVEL>` part. Added in v4.16.\n* `printk.time=y`: add the `[TIMESTAMP]` part\n\nThe debug highest level is a bit more magic, see: xref:pr-debug[xrefstyle=full] for more info.\n\n==== /proc/sys/kernel/printk\n\nThe current printk level can be obtained with:\n\n....\ncat /proc/sys/kernel/printk\n....\n\nAs of `87e846fc1f9c57840e143513ebd69c638bd37aa8` this prints:\n\n....\n7       4       1       7\n....\n\nwhich contains:\n\n* `7`: current log level, modifiable by previously mentioned methods\n* `4`: documented as: \"printk's without a loglevel use this\": TODO what does that mean, how to call `printk` without a log level?\n* `1`: minimum log level that still prints something (`0` prints nothing)\n* `7`: default log level\n\nWe start at the boot time default after boot by default, as can be seen from:\n\n....\ninsmod myprintk.ko\n....\n\nwhich outputs something like:\n\n....\n<1>[   12.494429] pr_alert\n<2>[   12.494666] pr_crit\n<3>[   12.494823] pr_err\n<4>[   12.494911] pr_warning\n<5>[   12.495170] pr_notice\n<6>[   12.495327] pr_info\n....\n\nSource: link:kernel_modules/myprintk.c[]\n\nThis proc entry is defined at: https://github.com/torvalds/linux/blob/v5.1/kernel/sysctl.c#L839\n\n....\n#if defined CONFIG_PRINTK\n\t{\n\t\t.procname\t= \"printk\",\n\t\t.data\t\t= &console_loglevel,\n\t\t.maxlen\t\t= 4*sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec,\n\t},\n....\n\nwhich teaches us that printk can be completely disabled at compile time:\n\n....\n\nconfig PRINTK\n\tdefault y\n\tbool \"Enable support for printk\" if EXPERT\n\tselect IRQ_WORK\n\thelp\n\t  This option enables normal printk support. Removing it\n\t  eliminates most of the message strings from the kernel image\n\t  and makes the kernel more or less silent. As this makes it\n\t  very difficult to diagnose system problems, saying N here is\n\t  strongly discouraged.\n....\n\n`console_loglevel` is defined at:\n\n....\n#define console_loglevel (console_printk[0])\n....\n\nand `console_printk` is an array with 4 ints:\n\n....\nint console_printk[4] = {\n\tCONSOLE_LOGLEVEL_DEFAULT,\t/* console_loglevel */\n\tMESSAGE_LOGLEVEL_DEFAULT,\t/* default_message_loglevel */\n\tCONSOLE_LOGLEVEL_MIN,\t\t/* minimum_console_loglevel */\n\tCONSOLE_LOGLEVEL_DEFAULT,\t/* default_console_loglevel */\n};\n....\n\nand then we see that the default is configurable with `CONFIG_CONSOLE_LOGLEVEL_DEFAULT`:\n\n....\n/*\n * Default used to be hard-coded at 7, quiet used to be hardcoded at 4,\n * we're now allowing both to be set from kernel config.\n */\n#define CONSOLE_LOGLEVEL_DEFAULT CONFIG_CONSOLE_LOGLEVEL_DEFAULT\n#define CONSOLE_LOGLEVEL_QUIET\t CONFIG_CONSOLE_LOGLEVEL_QUIET\n....\n\nThe message loglevel default is explained at:\n\n....\n/* printk's without a loglevel use this.. */\n#define MESSAGE_LOGLEVEL_DEFAULT CONFIG_MESSAGE_LOGLEVEL_DEFAULT\n....\n\nThe min is just hardcoded to one as you would expect, with some amazing kernel comedy around it:\n\n....\n/* We show everything that is MORE important than this.. */\n#define CONSOLE_LOGLEVEL_SILENT  0 /* Mum's the word */\n#define CONSOLE_LOGLEVEL_MIN\t 1 /* Minimum loglevel we let people use */\n#define CONSOLE_LOGLEVEL_DEBUG\t10 /* issue debug messages */\n#define CONSOLE_LOGLEVEL_MOTORMOUTH 15\t/* You can't shut this one up */\n....\n\nWe then also learn about the useless `quiet` and `debug` kernel parameters at:\n\n....\nconfig CONSOLE_LOGLEVEL_QUIET\n\tint \"quiet console loglevel (1-15)\"\n\trange 1 15\n\tdefault \"4\"\n\thelp\n\t  loglevel to use when \"quiet\" is passed on the kernel commandline.\n\n\t  When \"quiet\" is passed on the kernel commandline this loglevel\n\t  will be used as the loglevel. IOW passing \"quiet\" will be the\n\t  equivalent of passing \"loglevel=<CONSOLE_LOGLEVEL_QUIET>\"\n....\n\nwhich explains the useless reason why that number is special. This is implemented at:\n\n....\nstatic int __init debug_kernel(char *str)\n{\n\tconsole_loglevel = CONSOLE_LOGLEVEL_DEBUG;\n\treturn 0;\n}\n\nstatic int __init quiet_kernel(char *str)\n{\n\tconsole_loglevel = CONSOLE_LOGLEVEL_QUIET;\n\treturn 0;\n}\n\nearly_param(\"debug\", debug_kernel);\nearly_param(\"quiet\", quiet_kernel);\n....\n\n[[ignore-loglevel]]\n==== ignore_loglevel\n\n....\n./run --kernel-cli 'ignore_loglevel'\n....\n\nenables all log levels, and is basically the same as:\n\n....\n./run --kernel-cli 'loglevel=8'\n....\n\nexcept that you don't need to know what is the maximum level.\n\n[[pr-debug]]\n==== pr_debug\n\nhttps://stackoverflow.com/questions/28936199/why-is-pr-debug-of-the-linux-kernel-not-giving-any-output/49835405#49835405\n\nDebug messages are not printable by default without recompiling.\n\nBut the awesome `CONFIG_DYNAMIC_DEBUG=y` option which we enable by default allows us to do:\n\n....\necho 8 > /proc/sys/kernel/printk\necho 'file kernel/module.c +p' > /sys/kernel/debug/dynamic_debug/control\n./linux/myinsmod.out hello.ko\n....\n\nand we have a shortcut at:\n\n....\n./pr_debug.sh\n....\n\nSource: link:rootfs_overlay/lkmc/pr_debug.sh[].\n\nSyntax: https://www.kernel.org/doc/html/v4.11/admin-guide/dynamic-debug-howto.html\n\nWildcards are also accepted, e.g. enable all messages from all files:\n\n....\necho 'file * +p' > /sys/kernel/debug/dynamic_debug/control\n....\n\nTODO: why is this not working:\n\n....\necho 'func sys_init_module +p' > /sys/kernel/debug/dynamic_debug/control\n....\n\nEnable messages in specific modules:\n\n....\necho 8 > /proc/sys/kernel/printk\necho 'module myprintk +p' > /sys/kernel/debug/dynamic_debug/control\ninsmod myprintk.ko\n....\n\nSource: link:kernel_modules/myprintk.c[]\n\nThis outputs the `pr_debug` message:\n\n....\nprintk debug\n....\n\nbut TODO: it also shows debug messages even without enabling them explicitly:\n\n....\necho 8 > /proc/sys/kernel/printk\ninsmod myprintk.ko\n....\n\nand it shows as enabled:\n\n....\n# grep myprintk /sys/kernel/debug/dynamic_debug/control\n/root/linux-kernel-module-cheat/out/kernel_modules/x86_64/kernel_modules/panic.c:12 [myprintk]myinit =p \"pr_debug\\012\"\n....\n\nEnable `pr_debug` for boot messages as well, before we can reach userland and write to `/proc`:\n\n....\n./run --kernel-cli 'dyndbg=\"file * +p\" loglevel=8'\n....\n\nGet ready for the noisiest boot ever, I think it overflows the `printk` buffer and funny things happen.\n\n[[pr-debug-is-different-from-printk-kern-debug]]\n===== pr_debug != printk(KERN_DEBUG\n\nWhen `CONFIG_DYNAMIC_DEBUG` is set,  `printk(KERN_DEBUG` is not the exact same as `pr_debug(` since `printk(KERN_DEBUG` messages are visible with:\n\n....\n./run --kernel-cli 'initcall_debug logleve=8'\n....\n\nwhich outputs lines of type:\n\n....\n<7>[    1.756680] calling  clk_disable_unused+0x0/0x130 @ 1\n<7>[    1.757003] initcall clk_disable_unused+0x0/0x130 returned 0 after 111 usecs\n....\n\nwhich are `printk(KERN_DEBUG` inside `init/main.c` in v4.16.\n\nMentioned at: https://stackoverflow.com/questions/37272109/how-to-get-details-of-all-modules-drivers-got-initialized-probed-during-kernel-b\n\nThis likely comes from the ifdef split at `init/main.c`:\n\n....\n/* If you are writing a driver, please use dev_dbg instead */\n#if defined(CONFIG_DYNAMIC_DEBUG)\n#include <linux/dynamic_debug.h>\n\n/* dynamic_pr_debug() uses pr_fmt() internally so we don't need it here */\n#define pr_debug(fmt, ...) \\\n    dynamic_pr_debug(fmt, ##__VA_ARGS__)\n#elif defined(DEBUG)\n#define pr_debug(fmt, ...) \\\n    printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#else\n#define pr_debug(fmt, ...) \\\n    no_printk(KERN_DEBUG pr_fmt(fmt), ##__VA_ARGS__)\n#endif\n....\n\n=== Kernel module APIs\n\n==== Kernel module parameters\n\nThe Linux kernel allows passing module parameters at insertion time <<myinsmod,through the `init_module` and `finit_module` system calls>>.\n\nThe `insmod` tool exposes that as:\n\n....\ninsmod params.ko i=3 j=4\n....\n\nParameters are declared in the module as:\n\n....\nstatic u32 i = 0;\nmodule_param(i, int, S_IRUSR | S_IWUSR);\nMODULE_PARM_DESC(i, \"my favorite int\");\n....\n\nAutomated test:\n\n....\n./params.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/params.c[]\n* link:rootfs_overlay/lkmc/params.sh[]\n\nAs shown in the example, module parameters can also be read and modified at runtime from <<sysfs>>.\n\nWe can obtain the help text of the parameters with:\n\n....\nmodinfo params.ko\n....\n\nThe output contains:\n\n....\nparm:           j:my second favorite int\nparm:           i:my favorite int\n....\n\n===== modprobe.conf\n\n<<modprobe>> insertion can also set default parameters via the link:rootfs_overlay/etc/modprobe.conf[`/etc/modprobe.conf`] file:\n\n....\nmodprobe params\ncat /sys/kernel/debug/lkmc_params\n....\n\nOutput:\n\n....\n12 34\n....\n\nThis is specially important when loading modules with <<kernel-module-dependencies>> or else we would have no opportunity of passing those.\n\n`modprobe.conf` doesn't actually insmod anything for us: https://superuser.com/questions/397842/automatically-load-kernel-module-at-boot-angstrom/1267464#1267464\n\n==== Kernel module dependencies\n\nOne module can depend on symbols of another module that are exported with `EXPORT_SYMBOL`:\n\n....\n./dep.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/dep.c[]\n* link:kernel_modules/dep2.c[]\n* link:rootfs_overlay/lkmc/dep.sh[]\n\nThe kernel deduces dependencies based on the `EXPORT_SYMBOL` that each module uses.\n\nSymbols exported by `EXPORT_SYMBOL` can be seen with:\n\n....\ninsmod dep.ko\ngrep lkmc_dep /proc/kallsyms\n....\n\nsample output:\n\n....\nffffffffc0001030 r __ksymtab_lkmc_dep   [dep]\nffffffffc000104d r __kstrtab_lkmc_dep   [dep]\nffffffffc0002300 B lkmc_dep     [dep]\n....\n\nThis requires `CONFIG_KALLSYMS_ALL=y`.\n\nDependency information is stored by the kernel module build system in the `.ko` files' <<module-info>>, e.g.:\n\n....\nmodinfo dep2.ko\n....\n\ncontains:\n\n....\ndepends:        dep\n....\n\nWe can double check with:\n\n....\nstrings 3 dep2.ko | grep -E 'depends'\n....\n\nThe output contains:\n\n....\ndepends=dep\n....\n\nModule dependencies are also stored at:\n\n....\ncd /lib/module/*\ngrep dep modules.dep\n....\n\nOutput:\n\n....\nextra/dep2.ko: extra/dep.ko\nextra/dep.ko:\n....\n\nTODO: what for, and at which point point does Buildroot / BusyBox generate that file?\n\n===== Kernel module dependencies with modprobe\n\nUnlike `insmod`, <<modprobe>> deals with kernel module dependencies for us.\n\nFirst get <<kernel-modules-buildroot-package>> working.\n\nThen, for example:\n\n....\nmodprobe buildroot_dep2\n....\n\noutputs to dmesg:\n\n....\n42\n....\n\nand then:\n\n....\nlsmod\n....\n\noutputs:\n\n....\nModule                  Size  Used by    Tainted: G\nbuildroot_dep2         16384  0\nbuildroot_dep          16384  1 buildroot_dep2\n....\n\nSources:\n\n* link:buildroot_packages/kernel_modules/buildroot_dep.c[]\n* link:buildroot_packages/kernel_modules/buildroot_dep2.c[]\n\nRemoval also removes required modules that have zero usage count:\n\n....\nmodprobe -r buildroot_dep2\n....\n\n`modprobe` uses information from the `modules.dep` file to decide the required dependencies. That file contains:\n\n....\nextra/buildroot_dep2.ko: extra/buildroot_dep.ko\n....\n\nBibliography:\n\n* https://askubuntu.com/questions/20070/whats-the-difference-between-insmod-and-modprobe\n* https://stackoverflow.com/questions/22891705/whats-the-difference-between-insmod-and-modprobe\n\n[[module-info]]\n==== MODULE_INFO\n\nModule metadata is stored on module files at compile time. Some of the fields can be retrieved through the `THIS_MODULE` `struct module`:\n\n....\ninsmod module_info.ko\n....\n\nDmesg output:\n\n....\nname = module_info\nversion = 1.0\n....\n\nSource: link:kernel_modules/module_info.c[]\n\nSome of those are also present on sysfs:\n\n....\ncat /sys/module/module_info/version\n....\n\nOutput:\n\n....\n1.0\n....\n\nAnd we can also observe them with the `modinfo` command line utility:\n\n....\nmodinfo module_info.ko\n....\n\nsample output:\n\n....\nfilename:       module_info.ko\nlicense:        GPL\nversion:        1.0\nsrcversion:     AF3DE8A8CFCDEB6B00E35B6\ndepends:\nvermagic:       4.17.0 SMP mod_unload modversions\n....\n\nModule information is stored in a special `.modinfo` section of the ELF file:\n\n....\n./run-toolchain readelf -- -SW \"$(./getvar kernel_modules_build_subdir)/module_info.ko\"\n....\n\ncontains:\n\n....\n  [ 5] .modinfo          PROGBITS        0000000000000000 0000d8 000096 00   A  0   0  8\n....\n\nand:\n\n....\n./run-toolchain readelf -- -x .modinfo \"$(./getvar kernel_modules_build_subdir)/module_info.ko\"\n....\n\ngives:\n\n....\n  0x00000000 6c696365 6e73653d 47504c00 76657273 license=GPL.vers\n  0x00000010 696f6e3d 312e3000 61736466 3d717765 ion=1.0.asdf=qwe\n  0x00000020 72000000 00000000 73726376 65727369 r.......srcversi\n  0x00000030 6f6e3d41 46334445 38413843 46434445 on=AF3DE8A8CFCDE\n  0x00000040 42364230 30453335 42360000 00000000 B6B00E35B6......\n  0x00000050 64657065 6e64733d 006e616d 653d6d6f depends=.name=mo\n  0x00000060 64756c65 5f696e66 6f007665 726d6167 dule_info.vermag\n  0x00000070 69633d34 2e31372e 3020534d 50206d6f ic=4.17.0 SMP mo\n  0x00000080 645f756e 6c6f6164 206d6f64 76657273 d_unload modvers\n  0x00000090 696f6e73 2000                       ions .\n....\n\nI think a dedicated section is used to allow the Linux kernel and command line tools to easily parse that information from the ELF file as we've done with `readelf`.\n\nBibliography:\n\n* https://stackoverflow.com/questions/19467150/significance-of-this-module-in-linux-driver/49812248#49812248\n* https://stackoverflow.com/questions/4839024/how-to-find-the-version-of-a-compiled-kernel-module/42556565#42556565\n* https://unix.stackexchange.com/questions/238167/how-to-understand-the-modinfo-output\n\n==== vermagic\n\nlink:kernel_modules/vermagic.c[]\n\nAs of kernel v5.8, you can't use `VERMAGIC_STRING` string from modules anymore as per: https://github.com/cirosantilli/linux/commit/51161bfc66a68d21f13d15a689b3ea7980457790[]. So instead we just showcase `init_utsname`.\n\nSample insmod output as of LKMC fa8c2ee521ea83a74a2300e7a3be9f9ab86e2cb6 + 1 aarch64:\n\n....\n<6>[   25.180697] sysname    = Linux\n<6>[   25.180697] nodename   = buildroot\n<6>[   25.180697] release    = 5.9.2\n<6>[   25.180697] version    = #1 SMP Thu Jan 1 00:00:00 UTC 1970\n<6>[   25.180697] machine    = aarch64\n<6>[   25.180697] domainname = (none)\n....\n\nVermagic is a magic string present in the kernel and previously visible in <<module-info>> on kernel modules. It is used to verify that the kernel module was compiled against a compatible kernel version and relevant configuration:\n\n....\ninsmod vermagic.ko\n....\n\nPossible dmesg output:\n\n....\nVERMAGIC_STRING = 4.17.0 SMP mod_unload modversions\n....\n\nIf we artificially create a mismatch with `MODULE_INFO(vermagic`, the insmod fails with:\n\n....\ninsmod: can't insert 'vermagic_fail.ko': invalid module format\n....\n\nand `dmesg` says the expected and found vermagic found:\n\n....\nvermagic_fail: version magic 'asdfqwer' should be '4.17.0 SMP mod_unload modversions '\n....\n\nSource: link:kernel_modules/vermagic_fail.c[]\n\nThe kernel's vermagic is defined based on compile time configurations at https://github.com/torvalds/linux/blob/v4.17/include/linux/vermagic.h#L35[include/linux/vermagic.h]:\n\n....\n#define VERMAGIC_STRING                                                 \\\n        UTS_RELEASE \" \"                                                 \\\n        MODULE_VERMAGIC_SMP MODULE_VERMAGIC_PREEMPT                     \\\n        MODULE_VERMAGIC_MODULE_UNLOAD MODULE_VERMAGIC_MODVERSIONS       \\\n        MODULE_ARCH_VERMAGIC                                            \\\n        MODULE_RANDSTRUCT_PLUGIN\n....\n\nThe `SMP` part of the string for example is defined on the same file based on the value of `CONFIG_SMP`:\n\n....\n#ifdef CONFIG_SMP\n#define MODULE_VERMAGIC_SMP \"SMP \"\n#else\n#define MODULE_VERMAGIC_SMP \"\"\n....\n\nTODO how to get the vermagic from running kernel from userland? https://lists.kernelnewbies.org/pipermail/kernelnewbies/2012-October/006306.html\n\n<<kmod-modprobe>> has a flag to skip the vermagic check:\n\n....\n--force-modversion\n....\n\nThis option just strips `modversion` information from the module before loading, so it is not a kernel feature.\n\n[[init-module]]\n==== init_module\n\n`init_module` and `cleanup_module` are an older alternative to the `module_init` and `module_exit` macros:\n\n....\ninsmod init_module.ko\nrmmod init_module\n....\n\nDmesg output:\n\n....\ninit_module\ncleanup_module\n....\n\nSource: link:kernel_modules/init_module.c[]\n\nTODO why were `module_init` and `module_exit` created? https://stackoverflow.com/questions/3218320/what-is-the-difference-between-module-init-and-init-module-in-a-linux-kernel-mod\n\n==== Floating point in kernel modules\n\nIt is generally hard / impossible to use floating point operations in the kernel. TODO understand details.\n\nA quick (x86-only for now because lazy) example is shown at: link:kernel_modules/float.c[]\n\nUsage:\n\n....\ninsmod float.ko myfloat=1 enable_fpu=1\n....\n\nWe have to call: `kernel_fpu_begin()` before starting FPU operations, and `kernel_fpu_end()` when we are done. This particular example however did not blow up without it at lkmc 7f917af66b17373505f6c21d75af9331d624b3a9 + 1:\n\n....\ninsmod float.ko myfloat=1 enable_fpu=0\n....\n\nThe v5.1 documentation under https://github.com/cirosantilli/linux/blob/v5.1/arch/x86/include/asm/fpu/api.h#L15[arch/x86/include/asm/fpu/api.h] reads:\n\n....\n * Use kernel_fpu_begin/end() if you intend to use FPU in kernel context. It\n * disables preemption so be careful if you intend to use it for long periods\n * of time.\n....\n\nThe example sets in the link:kernel_modules/Makefile[]:\n\n....\nCFLAGS_REMOVE_float.o += -mno-sse -mno-sse2\n....\n\nto avoid:\n\n....\nerror: SSE register return with SSE disabled\n....\n\nWe found those flags with `./build-modules --verbose`.\n\nBibliography:\n\n* https://stackoverflow.com/questions/13886338/use-of-floating-point-in-the-linux-kernel\n* https://stackoverflow.com/questions/15883947/why-am-i-able-to-perform-floating-point-operations-inside-a-linux-kernel-module/47056242\n* https://stackoverflow.com/questions/1556142/sse-register-return-with-sse-disabled\n\n=== Kernel panic and oops\n\nTo test out kernel panics and oops in controlled circumstances, try out the modules:\n\n....\ninsmod panic.ko\ninsmod oops.ko\n....\n\nSource:\n\n* link:kernel_modules/panic.c[]\n* link:kernel_modules/oops.c[]\n\nA panic can also be generated with:\n\n....\necho c > /proc/sysrq-trigger\n....\n\nPanic vs oops: https://unix.stackexchange.com/questions/91854/whats-the-difference-between-a-kernel-oops-and-a-kernel-panic\n\nHow to generate them:\n\n* https://unix.stackexchange.com/questions/66197/how-to-cause-kernel-panic-with-a-single-command\n* https://stackoverflow.com/questions/23484147/generate-kernel-oops-or-crash-in-the-code\n\nWhen a panic happens, <<linux-kernel-magic-keys,`Shift-PgUp`>> does not work as it normally does, and it is hard to get the logs if on are on <<qemu-graphic-mode>>:\n\n* https://superuser.com/questions/848412/scrolling-up-the-failed-screen-with-kernel-panic\n* https://superuser.com/questions/269228/write-qemu-booting-virtual-machine-output-to-a-file\n* http://www.reactos.org/wiki/QEMU#Redirect_to_a_file\n\n==== Kernel panic\n\nOn panic, the kernel dies, and so does our terminal.\n\nThe panic trace looks like:\n\n....\npanic: loading out-of-tree module taints kernel.\npanic myinit\nKernel panic - not syncing: hello panic\nCPU: 0 PID: 53 Comm: insmod Tainted: G           O     4.16.0 #6\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.0-0-g63451fca13-prebuilt.qemu-project.org 04/01/2014\nCall Trace:\n dump_stack+0x7d/0xba\n ? 0xffffffffc0000000\n panic+0xda/0x213\n ? printk+0x43/0x4b\n ? 0xffffffffc0000000\n myinit+0x1d/0x20 [panic]\n do_one_initcall+0x3e/0x170\n do_init_module+0x5b/0x210\n load_module+0x2035/0x29d0\n ? kernel_read_file+0x7d/0x140\n ? SyS_finit_module+0xa8/0xb0\n SyS_finit_module+0xa8/0xb0\n do_syscall_64+0x6f/0x310\n ? trace_hardirqs_off_thunk+0x1a/0x32\n entry_SYSCALL_64_after_hwframe+0x42/0xb7\nRIP: 0033:0x7ffff7b36206\nRSP: 002b:00007fffffffeb78 EFLAGS: 00000206 ORIG_RAX: 0000000000000139\nRAX: ffffffffffffffda RBX: 000000000000005c RCX: 00007ffff7b36206\nRDX: 0000000000000000 RSI: 000000000069e010 RDI: 0000000000000003\nRBP: 000000000069e010 R08: 00007ffff7ddd320 R09: 0000000000000000\nR10: 00007ffff7ddd320 R11: 0000000000000206 R12: 0000000000000003\nR13: 00007fffffffef4a R14: 0000000000000000 R15: 0000000000000000\nKernel Offset: disabled\n---[ end Kernel panic - not syncing: hello panic\n....\n\nNotice how our panic message `hello panic` is visible at:\n\n....\nKernel panic - not syncing: hello panic\n....\n\n===== Kernel module stack trace to source line\n\nThe log shows which module each symbol belongs to if any, e.g.:\n\n....\nmyinit+0x1d/0x20 [panic]\n....\n\nsays that the function `myinit` is in the module `panic`.\n\nTo find the line that panicked, do:\n\n....\n./run-gdb\n....\n\nand then:\n\n....\ninfo line *(myinit+0x1d)\n....\n\nwhich gives us the correct line:\n\n....\nLine 7 of \"/root/linux-kernel-module-cheat/out/kernel_modules/x86_64/kernel_modules/panic.c\" starts at address 0xbf00001c <myinit+28> and ends at 0xbf00002c <myexit>.\n....\n\nas explained at: https://stackoverflow.com/questions/8545931/using-gdb-to-convert-addresses-to-lines/27576029#27576029\n\nThe exact same thing can be done post mortem with:\n\n....\n./run-toolchain gdb -- \\\n  -batch \\\n  -ex 'info line *(myinit+0x1d)' \\\n  \"$(./getvar kernel_modules_build_subdir)/panic.ko\" \\\n;\n....\n\nRelated:\n\n* https://stackoverflow.com/questions/6151538/addr2line-on-kernel-module\n* https://stackoverflow.com/questions/13468286/how-to-read-understand-analyze-and-debug-a-linux-kernel-panic\n\n[[bug-on]]\n===== BUG_ON\n\nBasically just calls `panic(\"BUG!\")` for most archs.\n\n===== Exit emulator on panic\n\nFor testing purposes, it is very useful to quit the emulator automatically with exit status non zero in case of kernel panic, instead of just hanging forever.\n\n====== Exit QEMU on panic\n\nEnabled by default with:\n\n* `panic=-1` command line option which reboots the kernel immediately on panic, see: xref:reboot-on-panic[xrefstyle=full]\n* QEMU `-no-reboot`, which makes QEMU exit when the guest tries to reboot\n\nAlso asked at https://unix.stackexchange.com/questions/443017/can-i-make-qemu-exit-with-failure-on-kernel-panic which also mentions the x86_64 `-device pvpanic`, but I don't see much advantage to it.\n\nTODO neither method exits with exit status different from 0, so for now we are just grepping the logs for panic messages, which sucks.\n\nOne possibility that gets close would be to use <<gdb>> to break at the `panic` function, and then send a <<qemu-monitor-from-gdb>> `quit` command if that happens, but I don't see a way to exit with non-zero status to indicate error.\n\n====== Exit gem5 on panic\n\ngem5 9048ef0ffbf21bedb803b785fb68f83e95c04db8 (January 2019) can detect panics automatically if the option `system.panic_on_panic` is on.\n\nIt parses kernel symbols and detecting when the PC reaches the address of the `panic` function. gem5 then prints to stdout:\n\n....\nKernel panic in simulated kernel\n....\n\nand exits with status -6.\n\nAt gem5 ff52563a214c71fcd1e21e9f00ad839612032e3b (July 2018) behaviour was different, and just exited 0: https://www.mail-archive.com/gem5-users@gem5.org/msg15870.html TODO find fixing commit.\n\nWe enable the `system.panic_on_panic` option by default on `arm` and `aarch64`, which makes gem5 exit immediately in case of panic, which is awesome!\n\nIf we don't set `system.panic_on_panic`, then gem5 just hangs on an infinite guest loop.\n\nTODO: why doesn't gem5 x86 ff52563a214c71fcd1e21e9f00ad839612032e3b support `system.panic_on_panic` as well? Trying to set `system.panic_on_panic` there fails with:\n\n....\ntried to set or access non-existentobject parameter: panic_on_panic\n....\n\nHowever, at that commit panic on x86 makes gem5 crash with:\n\n....\npanic: i8042 \"System reset\" command not implemented.\n....\n\nwhich is a good side effect of an unimplemented hardware feature, since the simulation actually stops.\n\nThe implementation of panic detection happens at: https://github.com/gem5/gem5/blob/1da285dfcc31b904afc27e440544d006aae25b38/src/arch/arm/linux/system.cc#L73\n\n....\n        kernelPanicEvent = addKernelFuncEventOrPanic<Linux::KernelPanicEvent>(\n            \"panic\", \"Kernel panic in simulated kernel\", dmesg_output);\n....\n\nHere we see that the symbol `\"panic\"` for the `panic()` function is the one being tracked.\n\nRelated thread: https://stackoverflow.com/questions/56032347/is-there-a-way-to-identify-if-gem5-run-got-over-successfully\n\n===== Reboot on panic\n\nMake the kernel reboot after n seconds after panic:\n\n....\necho 1 > /proc/sys/kernel/panic\n....\n\nCan also be controlled with the `panic=` kernel boot parameter.\n\n`0` to disable, `-1` to reboot immediately.\n\nBibliography:\n\n* https://github.com/torvalds/linux/blob/v4.17/Documentation/admin-guide/kernel-parameters.txt#L2931\n* https://unix.stackexchange.com/questions/29567/how-to-configure-the-linux-kernel-to-reboot-on-panic/29569#29569\n\n===== Panic trace show addresses instead of symbols\n\nIf `CONFIG_KALLSYMS=n`, then addresses are shown on traces instead of symbol plus offset.\n\nIn v4.16 it does not seem possible to configure that at runtime. GDB step debugging with:\n\n....\n./run --eval-after 'insmod dump_stack.ko' --gdb-wait --tmux-args dump_stack\n....\n\nshows that traces are printed at `arch/x86/kernel/dumpstack.c`:\n\n....\nstatic void printk_stack_address(unsigned long address, int reliable,\n                 char *log_lvl)\n{\n    touch_nmi_watchdog();\n    printk(\"%s %s%pB\\n\", log_lvl, reliable ? \"\" : \"? \", (void *)address);\n}\n....\n\nand `%pB` is documented at `Documentation/core-api/printk-formats.rst`:\n\n....\nIf KALLSYMS are disabled then the symbol address is printed instead.\n....\n\nI wasn't able do disable `CONFIG_KALLSYMS` to test this this out however, it is being selected by some other option? But I then used `make menuconfig` to see which options select it, and they were all off...\n\n[[oops]]\n==== Kernel oops\n\nOn oops, the shell still lives after.\n\nHowever we:\n\n* leave the normal control flow, and `oops after` never gets printed: an interrupt is serviced\n* cannot `rmmod oops` afterwards\n\nIt is possible to make `oops` lead to panics always with:\n\n....\necho 1 > /proc/sys/kernel/panic_on_oops\ninsmod oops.ko\n....\n\nAn oops stack trace looks like:\n\n....\nBUG: unable to handle kernel NULL pointer dereference at 0000000000000000\nIP: myinit+0x18/0x30 [oops]\nPGD dccf067 P4D dccf067 PUD dcc1067 PMD 0\nOops: 0002 [#1] SMP NOPTI\nModules linked in: oops(O+)\nCPU: 0 PID: 53 Comm: insmod Tainted: G           O     4.16.0 #6\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.11.0-0-g63451fca13-prebuilt.qemu-project.org 04/01/2014\nRIP: 0010:myinit+0x18/0x30 [oops]\nRSP: 0018:ffffc900000d3cb0 EFLAGS: 00000282\nRAX: 000000000000000b RBX: ffffffffc0000000 RCX: ffffffff81e3e3a8\nRDX: 0000000000000001 RSI: 0000000000000086 RDI: ffffffffc0001033\nRBP: ffffc900000d3e30 R08: 69796d2073706f6f R09: 000000000000013b\nR10: ffffea0000373280 R11: ffffffff822d8b2d R12: 0000000000000000\nR13: ffffffffc0002050 R14: ffffffffc0002000 R15: ffff88000dc934c8\nFS:  00007ffff7ff66a0(0000) GS:ffff88000fc00000(0000) knlGS:0000000000000000\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\nCR2: 0000000000000000 CR3: 000000000dcd2000 CR4: 00000000000006f0\nCall Trace:\n do_one_initcall+0x3e/0x170\n do_init_module+0x5b/0x210\n load_module+0x2035/0x29d0\n ? SyS_finit_module+0xa8/0xb0\n SyS_finit_module+0xa8/0xb0\n do_syscall_64+0x6f/0x310\n ? trace_hardirqs_off_thunk+0x1a/0x32\n entry_SYSCALL_64_after_hwframe+0x42/0xb7\nRIP: 0033:0x7ffff7b36206\nRSP: 002b:00007fffffffeb78 EFLAGS: 00000206 ORIG_RAX: 0000000000000139\nRAX: ffffffffffffffda RBX: 000000000000005c RCX: 00007ffff7b36206\nRDX: 0000000000000000 RSI: 000000000069e010 RDI: 0000000000000003\nRBP: 000000000069e010 R08: 00007ffff7ddd320 R09: 0000000000000000\nR10: 00007ffff7ddd320 R11: 0000000000000206 R12: 0000000000000003\nR13: 00007fffffffef4b R14: 0000000000000000 R15: 0000000000000000\nCode: <c7> 04 25 00 00 00 00 00 00 00 00 e8 b2 33 09 c1 31 c0 c3 0f 1f 44\nRIP: myinit+0x18/0x30 [oops] RSP: ffffc900000d3cb0\nCR2: 0000000000000000\n---[ end trace 3cdb4e9d9842b503 ]---\n....\n\nTo find the line that oopsed, look at the `RIP` register:\n\n....\nRIP: 0010:myinit+0x18/0x30 [oops]\n....\n\nand then on GDB:\n\n....\n./run-gdb\n....\n\nrun\n\n....\ninfo line *(myinit+0x18)\n....\n\nwhich gives us the correct line:\n\n....\nLine 7 of \"/root/linux-kernel-module-cheat/out/kernel_modules/x86_64/kernel_modules/panic.c\" starts at address 0xbf00001c <myinit+28> and ends at 0xbf00002c <myexit>.\n....\n\nThis-did not work on `arm` due to <<gdb-step-debug-kernel-module-arm>> so we need to either:\n\n* <<gdb-module-init>>\n* <<kernel-module-stack-trace-to-source-line>> post-mortem method\n\n[[dump-stack]]\n==== dump_stack\n\nThe `dump_stack` function produces a stack trace much like panic and oops, but causes no problems and we return to the normal control flow, and can cleanly remove the module afterwards:\n\n....\ninsmod dump_stack.ko\n....\n\nSource: link:kernel_modules/dump_stack.c[]\n\n[[warn-on]]\n==== WARN_ON\n\nThe `WARN_ON` macro basically just calls <<dump-stack>>.\n\nOne extra side effect is that we can make it also panic with:\n\n....\necho 1 > /proc/sys/kernel/panic_on_warn\ninsmod warn_on.ko\n....\n\nSource: link:kernel_modules/warn_on.c[]\n\nCan also be activated with the `panic_on_warn` boot parameter.\n\n[[not-syncing-vfs]]\n==== not syncing: VFS: Unable to mount root fs on unknown-block(0,0)\n\nLet's learn how to diagnose problems with the root filesystem not being found. TODO add a sample panic error message for each error type:\n\n* https://askubuntu.com/questions/41930/kernel-panic-not-syncing-vfs-unable-to-mount-root-fs-on-unknown-block0-0/1048477#1048477\n\nThis is the diagnosis procedure.\n\nFirst, if we remove the following options from the our kernel build:\n\n....\nCONFIG_VIRTIO_BLK=y\nCONFIG_VIRTIO_PCI=y\n....\n\nwe get a message like this:\n\n....\n<4>[    0.541708] VFS: Cannot open root device \"vda\" or unknown-block(0,0): error -6\n<4>[    0.542035] Please append a correct \"root=\" boot option; here are the available partitions:\n<0>[    0.542562] Kernel panic - not syncing: VFS: Unable to mount root fs on unknown-block(0,0)\n....\n\nFrom the message, we notice that the kernel sees a disk of some sort (vda means a virtio disk), but it could not open it.\n\nThis means that the kernel cannot properly read any bytes from the disk.\n\nAnd afterwards, it has an useless message `here are the available partitions:`, but of course we have no available partitions, the list is empty, because the kernel cannot even read bytes from the disk, so it definitely cannot understand its filesystems.\n\nThis can indicate basically two things:\n\n* on real hardware, it could mean that the hardware is broken. Kind of hard on emulators ;-)\n* you didn't configure the kernel with the option that enables it to read from that kind of disk.\n+\nIn our case, disks are virtio devices that QEMU exposes to the guest kernel. This is why removing the options:\n+\n....\nCONFIG_VIRTIO_BLK=y\nCONFIG_VIRTIO_PCI=y\n....\n+\nled to this error.\n\nNow, let's restore the previously removed virtio options, and instead remove:\n\n....\nCONFIG_EXT4_FS=y\n....\n\nThis time, the kernel will be able to read bytes from the device. But it won't be able to read files from the filesystem, because our filesystem is in ext4 format.\n\nTherefore, this time the error message looks like this:\n\n....\n<4>[    0.585296] List of all partitions:\n<4>[    0.585913] fe00          524288 vda\n<4>[    0.586123]  driver: virtio_blk\n<4>[    0.586471] No filesystem could mount root, tried:\n<4>[    0.586497]  squashfs\n<4>[    0.586724]\n<0>[    0.587360] Kernel panic - not syncing: VFS: Unable to mount root fs on unknown-block(254,0)\n....\n\nIn this case, we see that the kernel did manage to read from the `vda` disk! It even told us how: by using the `driver: virtio_blk`.\n\nHowever, it then went through the list of all filesystem types it knows how to read files from, in our case just `squashf`, and none of those worked, because our partition is an ext4 partition.\n\nFinally, the last possible error is that we simply passed the wrong `root=` <<kernel-command-line-parameters,kernel CLI option>>. For example, if we hack our command to pass:\n\n....\nroot=/dev/vda2\n....\n\nwhich does not even exist since `/dev/vda` is a raw non-partitioned ext4 image, then boot fails with a message:\n\n....\n<4>[    0.608475] Please append a correct \"root=\" boot option; here are the available partitions:\n<4>[    0.609563] fe00          524288 vda\n<4>[    0.609723]  driver: virtio_blk\n<0>[    0.610433] Kernel panic - not syncing: VFS: Unable to mount root fs on unknown-block(254,2)\n....\n\nThis one is easy, because the kernel tells us clearly which partitions it would have been able to understand. In our case `/dev/vda`.\n\nOnce all those problems are solved, in the working setup, we finally see something like:\n\n....\n<6>[    0.636129] EXT4-fs (vda): mounted filesystem with ordered data mode. Opts: (null)\n<6>[    0.636700] VFS: Mounted root (ext4 filesystem) on device 254:0.\n....\n\nTested on LKMC 863a373a30cd3c7982e3e453c4153f85133b17a9, Linux kernel 5.4.3.\n\nBibliography:\n\n* https://askubuntu.com/questions/41930/kernel-panic-not-syncing-vfs-unable-to-mount-root-fs-on-unknown-block0-0/1048477#1048477\n* https://unix.stackexchange.com/questions/414655/not-syncing-vfs-unable-to-mount-root-fs-on-unknown-block0-0/603197#603197\n* https://stackoverflow.com/questions/63277677/i-meet-a-problem-when-i-encountered-in-the-fs-mode-of-running-gem5/63278487#63278487 summary only\n\n=== Pseudo filesystems\n\nPseudo filesystems are filesystems that don't represent actual files in a hard disk, but rather allow us to do special operations on filesystem-related system calls.\n\nWhat each pseudo-file does for each related system call does is defined by its <<file-operations>>.\n\nBibliography:\n\n* https://superuser.com/questions/1198292/what-is-a-pseudo-file-system-in-linux\n* https://en.wikipedia.org/wiki/Synthetic_file_system\n\n==== debugfs\n\nDebugfs is the simplest pseudo filesystem to play around with:\n\n....\n./debugfs.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/debugfs.c[]\n* link:rootfs_overlay/lkmc/debugfs.sh[]\n\nDebugfs is made specifically to help test kernel stuff. Just mount, set <<file-operations>>, and we are done.\n\nFor this reason, it is the filesystem that we use whenever possible in our tests.\n\n`debugfs.sh` explicitly mounts a debugfs at a custom location, but the most common mount point is `/sys/kernel/debug`.\n\nThis mount not done automatically by the kernel however: we, like most distros, do it from userland with our link:rootfs_overlay/etc/fstab[fstab].\n\nDebugfs support requires the kernel to be compiled with `CONFIG_DEBUG_FS=y`.\n\nOnly the more basic file operations can be implemented in debugfs, e.g. `mmap` never gets called:\n\n* https://patchwork.kernel.org/patch/9252557/\n* https://github.com/torvalds/linux/blob/v4.9/fs/debugfs/file.c#L212\n\nBibliography: https://github.com/chadversary/debugfs-tutorial\n\n==== procfs\n\nProcfs is just another fops entry point:\n\n....\n./procfs.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nProcfs is a little less convenient than <<debugfs>>, but is more used in serious applications.\n\nProcfs can run all system calls, including ones that debugfs can't, e.g. <<mmap>>.\n\nSources:\n\n* link:kernel_modules/procfs.c[]\n* link:rootfs_overlay/lkmc/procfs.sh[]\n\nBibliography:\n\n* https://superuser.com/questions/619955/how-does-proc-work/1442571#1442571\n* https://stackoverflow.com/questions/8516021/proc-create-example-for-kernel-module/18924359#18924359\n\n[[proc-version]]\n===== /proc/version\n\nIts data is shared with `uname()`, which is a <<posix,POSIX C>> function and has a Linux syscall to back it up.\n\nWhere the data comes from and how to modify it:\n\n* https://unix.stackexchange.com/questions/136959/where-does-uname-get-its-information-from/485962#485962\n* https://stackoverflow.com/questions/23424174/how-to-customize-or-remove-extra-linux-kernel-version-details-shown-at-boot\n\nIn this repo, leaking host information, and to make builds more reproducible, we are setting:\n\n- user and date to dummy values with `KBUILD_BUILD_USER` and `KBUILD_BUILD_TIMESTAMP`\n- hostname to the kernel git commit with `KBUILD_BUILD_HOST` and `KBUILD_BUILD_VERSION`\n\nA sample result is:\n\n....\nLinux version 4.19.0-dirty (lkmc@84df9525b0c27f3ebc2ebb1864fa62a97fdedb7d) (gcc version 6.4.0 (Buildroot 2018.05-00002-gbc60382b8f)) #1 SMP Thu Jan 1 00:00:00 UTC 1970\n....\n\n==== sysfs\n\nSysfs is more restricted than <<procfs>>, as it does not take an arbitrary `file_operations`:\n\n....\n./sysfs.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/sysfs.c[]\n* link:rootfs_overlay/lkmc/sysfs.sh[]\n\nVs procfs:\n\n* https://unix.stackexchange.com/questions/4884/what-is-the-difference-between-procfs-and-sysfs/382315#382315\n* https://stackoverflow.com/questions/37237835/how-to-attach-file-operations-to-sysfs-attribute-in-platform-driver\n* https://serverfault.com/questions/65261/linux-proc-sys-kernel-vs-sys-kernel\n\nYou basically can only do `open`, `close`, `read`, `write`, and `lseek` on sysfs files.\n\nIt is similar to a <<seq-file>> file operation, except that write is also implemented.\n\nTODO: what are those `kobject` structs? Make a more complex example that shows what they can do.\n\nBibliography:\n\n* https://github.com/t3rm1n4l/kern-dev-tutorial/blob/1f036ef40fc4378f5c8d2842e55bcea7c6f8894a/05-sysfs/sysfs.c\n* https://www.kernel.org/doc/Documentation/kobject.txt\n* https://www.quora.com/What-are-kernel-objects-Kobj\n* http://www.makelinux.net/ldd3/chp-14-sect-1\n* https://www.win.tue.nl/~aeb/linux/lk/lk-13.html\n\n==== Character devices\n\nCharacter devices can have arbitrary <<file-operations>> associated to them:\n\n....\n./character_device.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:rootfs_overlay/lkmc/character_device.sh[]\n* link:rootfs_overlay/lkmc/mknoddev.sh[]\n* link:kernel_modules/character_device.c[]\n\nUnlike <<procfs>> entires, character device files are created with userland `mknod` or `mknodat` syscalls:\n\n....\nmknod </dev/path_to_dev> c <major> <minor>\n....\n\nIntuitively, for physical devices like keyboards, the major number maps to which driver, and the minor number maps to which device it is.\n\nA single driver can drive multiple compatible devices.\n\nThe major and minor numbers can be observed with:\n\n....\nls -l /dev/urandom\n....\n\nOutput:\n\n....\ncrw-rw-rw-    1 root     root        1,   9 Jun 29 05:45 /dev/urandom\n....\n\nwhich means:\n\n* `c` (first letter): this is a character device. Would be `b` for a block device.\n* `1,   9`: the major number is `1`, and the minor `9`\n\nTo avoid device number conflicts when registering the driver we:\n\n* ask the kernel to allocate a free major number for us with: `register_chrdev(0`\n* find ouf which number was assigned by grepping `/proc/devices` for the kernel module name\n\nBibliography: https://unix.stackexchange.com/questions/37829/understanding-character-device-or-character-special-files/371758#371758\n\n===== Automatically create character device file on insmod\n\nAnd also destroy it on `rmmod`:\n\n....\n./character_device_create.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/character_device_create.c[]\n* link:rootfs_overlay/lkmc/character_device_create.sh[]\n\nBibliography: https://stackoverflow.com/questions/5970595/how-to-create-a-device-node-from-the-init-module-code-of-a-linux-kernel-module/45531867#45531867\n\n=== Pseudo files\n\n==== File operations\n\nFile operations are the main method of userland driver communication.\n\n`struct file_operations` determines what the kernel will do on filesystem system calls of <<pseudo-filesystems>>.\n\nThis example illustrates the most basic system calls: `open`, `read`, `write`, `close` and `lseek`:\n\n....\n./fops.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/fops.c[]\n* link:rootfs_overlay/lkmc/fops.sh[]\n\nThen give this a try:\n\n....\nsh -x ./fops.sh\n....\n\nWe have put printks on each fop, so this allows you to see which system calls are being made for each command.\n\nNo, there no official documentation: https://stackoverflow.com/questions/15213932/what-are-the-struct-file-operations-arguments\n\n[[seq-file]]\n==== seq_file\n\nWriting trivial read <<file-operations>> is repetitive and error prone. The `seq_file` API makes the process much easier for those trivial cases:\n\n....\n./seq_file.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/seq_file.c[]\n* link:rootfs_overlay/lkmc/seq_file.sh[]\n\nIn this example we create a debugfs file that behaves just like a file that contains:\n\n....\n0\n1\n2\n....\n\nHowever, we only store a single integer in memory and calculate the file on the fly in an iterator fashion.\n\n`seq_file` does not provide `write`: https://stackoverflow.com/questions/30710517/how-to-implement-a-writable-proc-file-by-using-seq-file-in-a-driver-module\n\nBibliography:\n\n* https://github.com/torvalds/linux/blob/v4.17/Documentation/filesystems/seq_file.txt[Documentation/filesystems/seq_file.txt]\n* https://stackoverflow.com/questions/25399112/how-to-use-a-seq-file-in-linux-modules\n\n[[seq-file-single-open]]\n===== seq_file single_open\n\nIf you have the entire read output upfront, `single_open` is an even more convenient version of <<seq-file>>:\n\n....\n./seq_file.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/seq_file_single_open.c[]\n* link:rootfs_overlay/lkmc/seq_file_single_open.sh[]\n\nThis example produces a debugfs file that behaves like a file that contains:\n\n....\nab\ncd\n....\n\n==== poll\n\nThe poll system call allows an user process to do a non-busy wait on a kernel event.\n\nSources:\n\n* link:kernel_modules/poll.c[]\n* link:rootfs_overlay/lkmc/poll.sh[]\n\nExample:\n\n....\n./poll.sh\n....\n\nOutcome: `jiffies` gets printed to stdout every second from userland, e.g.:\n\n....\npoll\n<6>[    4.275305] poll\n<6>[    4.275580] return POLLIN\nrevents = 1\nPOLLIN n=10 buf=4294893337\npoll\n<6>[    4.276627] poll\n<6>[    4.276911] return 0\n<6>[    5.271193] wake_up\n<6>[    5.272326] poll\n<6>[    5.273207] return POLLIN\nrevents = 1\nPOLLIN n=10 buf=4294893588\npoll\n<6>[    5.276367] poll\n<6>[    5.276618] return 0\n<6>[    6.275178] wake_up\n<6>[    6.276370] poll\n<6>[    6.277269] return POLLIN\nrevents = 1\nPOLLIN n=10 buf=4294893839\n....\n\nForce the poll <<file-operations,`file_operation`>> to return 0 to see what happens more clearly:\n\n....\n./poll.sh pol0=1\n....\n\nSample output:\n\n....\npoll\n<6>[   85.674801] poll\n<6>[   85.675788] return 0\n<6>[   86.675182] wake_up\n<6>[   86.676431] poll\n<6>[   86.677373] return 0\n<6>[   87.679198] wake_up\n<6>[   87.680515] poll\n<6>[   87.681564] return 0\n<6>[   88.683198] wake_up\n....\n\nFrom this we see that control is not returned to userland: the kernel just keeps calling the poll `file_operation` again and again.\n\nTypically, we are waiting for some hardware to make some piece of data available available to the kernel.\n\nThe hardware notifies the kernel that the data is ready with an interrupt.\n\nTo simplify this example, we just fake the hardware interrupts with a <<kthread>> that sleeps for a second in an infinite loop.\n\nBibliography:\n\n* https://stackoverflow.com/questions/30035776/how-to-add-poll-function-to-the-kernel-module-code/44645336#44645336\n* https://stackoverflow.com/questions/30234496/why-do-we-need-to-call-poll-wait-in-poll/44645480#44645480\n\n==== ioctl\n\nThe `ioctl` system call is the best way to pass an arbitrary number of parameters to the kernel in a single go:\n\n....\n./ioctl.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/ioctl.c[]\n* link:lkmc/ioctl.h[]\n* link:userland/kernel_modules/ioctl.c[]\n* link:rootfs_overlay/lkmc/ioctl.sh[]\n\n`ioctl` is one of the most important methods of communication with real device drivers, which often take several fields as input.\n\n`ioctl` takes as input:\n\n* an integer `request` : it usually identifies what type of operation we want to do on this call\n* an untyped pointer to memory: can be anything, but is typically a pointer to a `struct`\n+\nThe type of the `struct` often depends on the `request` input\n+\nThis `struct` is defined on a uapi-style C header that is used both to compile the kernel module and the userland executable.\n+\nThe fields of this `struct` can be thought of as arbitrary input parameters.\n\nAnd the output is:\n\n* an integer return value. `man ioctl` documents:\n+\n____\nUsually, on success zero is returned. A few `ioctl()` requests use the return value as an output parameter and return a nonnegative value on success. On error, -1 is returned, and errno is set appropriately.\n____\n* the input pointer data may be overwritten to contain arbitrary output\n\nBibliography:\n\n* https://stackoverflow.com/questions/2264384/how-do-i-use-ioctl-to-manipulate-my-kernel-module/44613896#44613896\n* https://askubuntu.com/questions/54239/problem-with-ioctl-in-a-simple-kernel-module/926675#926675\n\n==== mmap\n\nThe `mmap` system call allows us to share memory between user and kernel space without copying:\n\n....\n./mmap.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/mmap.c[]\n* link:userland/kernel_modules/mmap.c[]\n* link:rootfs_overlay/lkmc/mmap.sh[]\n\nIn this example, we make a tiny 4 byte kernel buffer available to user-space, and we then modify it on userspace, and check that the kernel can see the modification.\n\n`mmap`, like most more complex <<file-operations>>, does not work with <<debugfs>> as of 4.9, so we use a <<procfs>> file for it.\n\nExample adapted from: https://coherentmusings.wordpress.com/2014/06/10/implementing-mmap-for-transferring-data-from-user-space-to-kernel-space/\n\nBibliography:\n\n* https://stackoverflow.com/questions/10760479/mmap-kernel-buffer-to-user-space/10770582#10770582\n* https://stackoverflow.com/questions/1623008/allocating-memory-for-user-space-from-kernel-thread\n* https://stackoverflow.com/questions/6967933/mmap-mapping-in-user-space-a-kernel-buffer-allocated-with-kmalloc\n* https://github.com/jeremytrimble/ezdma\n* https://github.com/simonjhall/dma\n* https://github.com/ikwzm/udmabuf\n\n==== Anonymous inode\n\nAnonymous inodes allow getting multiple file descriptors from a single filesystem entry, which reduces namespace pollution compared to creating multiple device files:\n\n....\n./anonymous_inode.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/anonymous_inode.c[]\n* link:lkmc/anonymous_inode.h[]\n* link:userland/kernel_modules/anonymous_inode.c[]\n* link:rootfs_overlay/lkmc/anonymous_inode.sh[]\n\nThis example gets an anonymous inode via <<ioctl>> from a debugfs entry by using `anon_inode_getfd`.\n\nReads to that inode return the sequence: `1`, `10`, `100`, ... `10000000`, `1`, `100`, ...\n\nBibliography: https://stackoverflow.com/questions/4508998/what-is-an-anonymous-inode-in-linux/44388030#44388030\n\n==== netlink sockets\n\nNetlink sockets offer a socket API for kernel / userland communication:\n\n....\n./netlink.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/netlink.c[]\n* link:lkmc/netlink.h[]\n* link:userland/kernel_modules/netlink.c[]\n* link:rootfs_overlay/lkmc/netlink.sh[]\n\nLaunch multiple user requests in parallel to stress our socket:\n\n....\ninsmod netlink.ko sleep=1\nfor i in `seq 16`; do ./netlink.out & done\n....\n\nTODO: what is the advantage over `read`, `write` and `poll`? https://stackoverflow.com/questions/16727212/how-netlink-socket-in-linux-kernel-is-different-from-normal-polling-done-by-appl\n\nBibliography:\n\n* https://stackoverflow.com/questions/3299386/how-to-use-netlink-socket-to-communicate-with-a-kernel-module\n* https://en.wikipedia.org/wiki/Netlink\n\n=== kthread\n\nKernel threads are managed exactly like userland threads; they also have a backing `task_struct`, and are scheduled with the same mechanism:\n\n....\ninsmod kthread.ko\n....\n\nSource: link:kernel_modules/kthread.c[]\n\nOutcome: dmesg counts from `0` to `9` once every second infinitely many times:\n\n....\n0\n1\n2\n...\n8\n9\n0\n1\n2\n...\n....\n\nThe count stops when we `rmmod`:\n\n....\nrmmod kthread\n....\n\nThe sleep is done with `usleep_range`, see: xref:sleep[xrefstyle=full].\n\nBibliography:\n\n* https://stackoverflow.com/questions/10177641/proper-way-of-handling-threads-in-kernel\n* https://stackoverflow.com/questions/4084708/how-to-wait-for-a-linux-kernel-thread-kthreadto-exit\n\n==== kthreads\n\nLet's launch two threads and see if they actually run in parallel:\n\n....\ninsmod kthreads.ko\n....\n\nSource: link:kernel_modules/kthreads.c[]\n\nOutcome: two threads count to dmesg from `0` to `9` in parallel.\n\nEach line has output of form:\n\n....\n<thread_id> <count>\n....\n\nPossible very likely outcome:\n\n....\n\n1 0\n2 0\n1 1\n2 1\n1 2\n2 2\n1 3\n2 3\n....\n\nThe threads almost always interleaved nicely, thus confirming that they are actually running in parallel.\n\n==== sleep\n\nCount to dmesg every one second from `0` up to `n - 1`:\n\n....\ninsmod sleep.ko n=5\n....\n\nSource: link:kernel_modules/sleep.c[]\n\nThe sleep is done with a call to https://github.com/torvalds/linux/blob/v4.17/kernel/time/timer.c#L1984[`usleep_range`] directly inside `module_init` for simplicity.\n\nBibliography:\n\n* https://stackoverflow.com/questions/15994603/how-to-sleep-in-the-linux-kernel/44153288#44153288\n* https://github.com/torvalds/linux/blob/v4.17/Documentation/timers/timers-howto.txt\n\n==== Workqueues\n\nA more convenient front-end for <<kthread>>:\n\n....\ninsmod workqueue_cheat.ko\n....\n\nOutcome: count from `0` to `9` infinitely many times\n\nStop counting:\n\n....\nrmmod workqueue_cheat\n....\n\nSource: link:kernel_modules/workqueue_cheat.c[]\n\nThe workqueue thread is killed after the worker function returns.\n\nWe can't call the module just `workqueue.c` because there is already a built-in with that name: https://unix.stackexchange.com/questions/364956/how-can-insmod-fail-with-kernel-module-is-already-loaded-even-is-lsmod-does-not\n\nBibliography: https://github.com/torvalds/linux/blob/v4.17/Documentation/core-api/workqueue.rst\n\n===== Workqueue from workqueue\n\nCount from `0` to `9` every second infinitely many times by scheduling a new work item from a work item:\n\n....\ninsmod work_from_work.ko\n....\n\nStop:\n\n....\nrmmod work_from_work\n....\n\nThe sleep is done indirectly through: https://github.com/torvalds/linux/blob/v4.17/include/linux/workqueue.h#L522[`queue_delayed_work`], which waits the specified time before scheduling the work.\n\nSource: link:kernel_modules/work_from_work.c[]\n\n==== schedule\n\nLet's block the entire kernel! Yay:\n\n.....\n./run --eval-after 'dmesg -n 1;insmod schedule.ko schedule=0'\n.....\n\nOutcome: the system hangs, the only way out is to kill the VM.\n\nSource: link:kernel_modules/schedule.c[]\n\nkthreads only allow interrupting if you call `schedule()`, and the `schedule=0` <<kernel-module-parameters,kernel module parameter>> turns it off.\n\nSleep functions like `usleep_range` also end up calling schedule.\n\nIf we allow `schedule()` to be called, then the system becomes responsive:\n\n.....\n./run --eval-after 'dmesg -n 1;insmod schedule.ko schedule=1'\n.....\n\n\nand we can observe the counting with:\n\n....\ndmesg -w\n....\n\nThe system also responds if we <<number-of-cores,add another core>>:\n\n....\n./run --cpus 2 --eval-after 'dmesg -n 1;insmod schedule.ko schedule=0'\n....\n\n==== Wait queues\n\nWait queues are a way to make a thread sleep until an event happens on the queue:\n\n....\ninsmod wait_queue.c\n....\n\nDmesg output:\n\n....\n0 0\n1 0\n2 0\n# Wait one second.\n0 1\n1 1\n2 1\n# Wait one second.\n0 2\n1 2\n2 2\n...\n....\n\nStop the count:\n\n....\nrmmod wait_queue\n....\n\nSource: link:kernel_modules/wait_queue.c[]\n\nThis example launches three threads:\n\n* one thread generates events every with https://github.com/torvalds/linux/blob/v4.17/include/linux/wait.h#L195[`wake_up`]\n* the other two threads wait for that with https://github.com/torvalds/linux/blob/v4.17/include/linux/wait.h#L286[`wait_event`], and print a dmesg when it happens.\n+\nThe `wait_event` macro works a bit like:\n+\n....\nwhile (!cond)\n    sleep_until_event\n....\n\n=== Timers\n\nCount from `0` to `9` infinitely many times in 1 second intervals using timers:\n\n....\ninsmod timer.ko\n....\n\nStop counting:\n\n....\nrmmod timer\n....\n\nSource: link:kernel_modules/timer.c[]\n\nTimers are callbacks that run when an interrupt happens, from the interrupt context itself.\n\nTherefore they produce more accurate timing than thread scheduling, which is more complex, but you can't do too much work inside of them.\n\nBibliography:\n\n* https://stackoverflow.com/questions/10812858/timers-in-linux-device-drivers\n* https://gist.github.com/yagihiro/310149\n\n=== IRQ\n\n==== irq.ko\n\nBrute force monitor every shared interrupt that will accept us:\n\n....\n./run --eval-after 'insmod irq.ko' --graphic\n....\n\nSource: link:kernel_modules/irq.c[].\n\nNow try the following:\n\n* press a keyboard key and then release it after a few seconds\n* press a mouse key, and release it after a few seconds\n* move the mouse around\n\nOutcome: dmesg shows which IRQ was fired for each action through messages of type:\n\n....\nhandler irq = 1 dev = 250\n....\n\n`dev` is the character device for the module and never changes, as can be confirmed by:\n\n....\ngrep lkmc_irq /proc/devices\n....\n\nThe IRQs that we observe are:\n\n* `1` for keyboard press and release.\n+\nIf you hold the key down for a while, it starts firing at a constant rate. So this happens at the hardware level!\n* `12` mouse actions\n\nThis only works if for IRQs for which the other handlers are registered as `IRQF_SHARED`.\n\nWe can see which ones are those, either via dmesg messages of type:\n\n....\ngenirq: Flags mismatch irq 0. 00000080 (myirqhandler0) vs. 00015a00 (timer)\nrequest_irq irq = 0 ret = -16\nrequest_irq irq = 1 ret = 0\n....\n\nwhich indicate that `0` is not, but `1` is, or with:\n\n....\ncat /proc/interrupts\n....\n\nwhich shows:\n\n....\n  0:         31   IO-APIC   2-edge      timer\n  1:          9   IO-APIC   1-edge      i8042, myirqhandler0\n....\n\nso only `1` has `myirqhandler0` attached but not `0`.\n\nThe <<qemu-monitor>> also has some interrupt statistics for x86_64:\n\n....\n./qemu-monitor info irq\n....\n\nTODO: properly understand how each IRQ maps to what number.\n\n==== dummy-irq\n\nThe Linux kernel v4.16 mainline also has a `dummy-irq` module at `drivers/misc/dummy-irq.c` for monitoring a single IRQ.\n\nWe build it by default with:\n\n....\nCONFIG_DUMMY_IRQ=m\n....\n\nAnd then you can do\n\n....\n./run --graphic\n....\n\nand in guest:\n\n....\nmodprobe dummy-irq irq=1\n....\n\nOutcome: when you click a key on the keyboard, dmesg shows:\n\n....\ndummy-irq: interrupt occurred on IRQ 1\n....\n\nHowever, this module is intended to fire only once as can be seen from its source:\n\n....\n    static int count = 0;\n\n    if (count == 0) {\n        printk(KERN_INFO \"dummy-irq: interrupt occurred on IRQ %d\\n\",\n            irq);\n        count++;\n    }\n....\n\nand furthermore interrupt `1` and `12` happen immediately TODO why, were they somehow pending?\n\n==== /proc/interrupts\n\nIn the guest with <<qemu-graphic-mode>>:\n\n....\nwatch -n 1 cat /proc/interrupts\n....\n\nThen see how clicking the mouse and keyboard affect the interrupt counts.\n\nThis confirms that:\n\n* 1: keyboard\n* 12: mouse click and drags\n\nThe module also shows which handlers are registered for each IRQ, as we have observed at <<irq-ko>>\n\nWhen in text mode, we can also observe interrupt line 4 with handler `ttyS0` increase continuously as IO goes through the UART.\n\n=== Kernel utility functions\n\nhttps://github.com/torvalds/linux/blob/v4.17/Documentation/core-api/kernel-api.rst\n\n==== kstrto\n\nConvert a string to an integer:\n\n....\n./kstrto.sh\necho $?\n....\n\nOutcome: the test passes:\n\n....\n0\n....\n\nSources:\n\n* link:kernel_modules/kstrto.c[]\n* link:rootfs_overlay/lkmc/kstrto.sh[]\n\nBibliography: https://stackoverflow.com/questions/6139493/how-convert-char-to-int-in-linux-kernel/49811658#49811658\n\n[[virt-to-phys]]\n==== virt_to_phys\n\nConvert a virtual address to physical:\n\n....\ninsmod virt_to_phys.ko\ncat /sys/kernel/debug/lkmc_virt_to_phys\n....\n\nSource: link:kernel_modules/virt_to_phys.c[]\n\nSample output:\n\n....\n*kmalloc_ptr = 0x12345678\nkmalloc_ptr = ffff88000e169ae8\nvirt_to_phys(kmalloc_ptr) = 0xe169ae8\nstatic_var = 0x12345678\n&static_var = ffffffffc0002308\nvirt_to_phys(&static_var) = 0x40002308\n....\n\nWe can confirm that the `kmalloc_ptr` translation worked with:\n\n....\n./qemu-monitor 'xp 0xe169ae8'\n....\n\nwhich reads four bytes from a given physical address, and gives the expected:\n\n....\n000000000e169ae8: 0x12345678\n....\n\nTODO it only works for kmalloc however, for the static variable:\n\n....\n./qemu-monitor 'xp 0x40002308'\n....\n\nit gave a wrong value of `00000000`.\n\nBibliography:\n\n* https://stackoverflow.com/questions/5748492/is-there-any-api-for-determining-the-physical-address-from-virtual-address-in-li/45128487#45128487\n* https://stackoverflow.com/questions/39134990/mmap-of-dev-mem-fails-with-invalid-argument-for-virt-to-phys-address-but-addre/45127582#45127582\n* https://stackoverflow.com/questions/43325205/can-we-use-virt-to-phys-for-user-space-memory-in-kernel-module\n\n===== Userland physical address experiments\n\nOnly tested in x86_64.\n\nThe Linux kernel exposes physical addresses to userland through:\n\n* `/proc/<pid>/maps`\n* `/proc/<pid>/pagemap`\n* `/dev/mem`\n\nIn this section we will play with them.\n\nThe following files contain examples to access that data and test it out:\n\n* link:lkmc/pagemap.h[]\n* link:rootfs_overlay/lkmc/virt_to_phys.sh[]\n* link:userland/linux/virt_to_phys_user.c[]\n* link:userland/posix/virt_to_phys_test.c[]\n\nFirst get a virtual address to play with:\n\n....\n./posix/virt_to_phys_test.out &\n....\n\nSource: link:userland/posix/virt_to_phys_test.c[]\n\nSample output:\n\n....\nvaddr 0x600800\npid 110\n....\n\nThe program:\n\n* allocates a `volatile` variable and sets is value to `0x12345678`\n* prints the virtual address of the variable, and the program PID\n* runs a while loop until until the value of the variable gets mysteriously changed somehow, e.g. by nasty tinkerers like us\n\nThen, translate the virtual address to physical using `/proc/<pid>/maps` and `/proc/<pid>/pagemap`:\n\n....\n./linux/virt_to_phys_user.out 110 0x600800\n....\n\nSample output physical address:\n\n....\n0x7c7b800\n....\n\nNow we can verify that `linux/virt_to_phys_user.out` gave the correct physical address in the following ways:\n\n* <<qemu-xp>>\n* <<dev-mem>>\n\nBibliography:\n\n* https://stackoverflow.com/questions/17021214/decode-proc-pid-pagemap-entry/45126141#45126141\n* https://stackoverflow.com/questions/6284810/proc-pid-pagemaps-and-proc-pid-maps-linux/45500208#45500208\n\n====== QEMU xp\n\nThe `xp` <<qemu-monitor>> command reads memory at a given physical address.\n\nFirst launch `linux/virt_to_phys_user.out` as described at <<userland-physical-address-experiments>>.\n\nOn a second terminal, use QEMU to read the physical address:\n\n....\n./qemu-monitor 'xp 0x7c7b800'\n....\n\nOutput:\n\n....\n0000000007c7b800: 0x12345678\n....\n\nYes!!! We read the correct value from the physical address.\n\nWe could not find however to write to memory from the QEMU monitor, boring.\n\n[[dev-mem]]\n====== /dev/mem\n\n`/dev/mem` exposes access to physical addresses, and we use it through the convenient `devmem` BusyBox utility.\n\nFirst launch `linux/virt_to_phys_user.out` as described at <<userland-physical-address-experiments>>.\n\nNext, read from the physical address:\n\n....\ndevmem 0x7c7b800\n....\n\nPossible output:\n\n....\nMemory mapped at address 0x7ff7dbe01000.\nValue at address 0X7C7B800 (0x7ff7dbe01800): 0x12345678\n....\n\nwhich shows that the physical memory contains the expected value `0x12345678`.\n\n`0x7ff7dbe01000` is a new virtual address that `devmem` maps to the physical address to be able to read from it.\n\nModify the physical memory:\n\n....\ndevmem 0x7c7b800 w 0x9abcdef0\n....\n\nAfter one second, we see on the screen:\n\n....\ni 9abcdef0\n[1]+  Done                       ./posix/virt_to_phys_test.out\n....\n\nso the value changed, and the `while` loop exited!\n\nThis example requires:\n\n* `CONFIG_STRICT_DEVMEM=n`, otherwise `devmem` fails with:\n+\n....\ndevmem: mmap: Operation not permitted\n....\n* `nopat` kernel parameter\n\nwhich we set by default.\n\nBibliography: https://stackoverflow.com/questions/11891979/how-to-access-mmaped-dev-mem-without-crashing-the-linux-kernel\n\n[[pagemap-dump-out]]\n====== pagemap_dump.out\n\nDump the physical address of all pages mapped to a given process using `/proc/<pid>/maps` and `/proc/<pid>/pagemap`.\n\nFirst launch `linux/virt_to_phys_user.out` as described at <<userland-physical-address-experiments>>. Suppose that the output was:\n\n....\n# ./posix/virt_to_phys_test.out &\nvaddr 0x601048\npid 63\n# ./linux/virt_to_phys_user.out 63 0x601048\n0x1a61048\n....\n\nNow obtain the page map for the process:\n\n....\n./linux/pagemap_dump.out 63\n....\n\nSample output excerpt:\n\n....\nvaddr pfn soft-dirty file/shared swapped present library\n400000 1ede 0 1 0 1 ./posix/virt_to_phys_test.out\n600000 1a6f 0 0 0 1 ./posix/virt_to_phys_test.out\n601000 1a61 0 0 0 1 ./posix/virt_to_phys_test.out\n602000 2208 0 0 0 1 [heap]\n603000 220b 0 0 0 1 [heap]\n7ffff78ec000 1fd4 0 1 0 1 /lib/libuClibc-1.0.30.so\n....\n\nSource:\n\n* link:userland/linux/pagemap_dump.c[]\n* link:lkmc/pagemap.h[]\n\nAdapted from: https://github.com/dwks/pagemap/blob/8a25747bc79d6080c8b94eac80807a4dceeda57a/pagemap2.c\n\nMeaning of the flags:\n\n* `vaddr`: first virtual address of a page the belongs to the process. Notably:\n+\n....\n./run-toolchain readelf -- -l \"$(./getvar userland_build_dir)/posix/virt_to_phys_test.out\"\n....\n+\ncontains:\n+\n....\n  Type           Offset             VirtAddr           PhysAddr\n                 FileSiz            MemSiz              Flags  Align\n...\n  LOAD           0x0000000000000000 0x0000000000400000 0x0000000000400000\n                 0x000000000000075c 0x000000000000075c  R E    0x200000\n  LOAD           0x0000000000000e98 0x0000000000600e98 0x0000000000600e98\n                 0x00000000000001b4 0x0000000000000218  RW     0x200000\n\n Section to Segment mapping:\n  Segment Sections...\n...\n   02     .interp .hash .dynsym .dynstr .rela.plt .init .plt .text .fini .rodata .eh_frame_hdr .eh_frame\n   03     .ctors .dtors .jcr .dynamic .got.plt .data .bss\n....\n+\nfrom which we deduce that:\n+\n** `400000` is the text segment\n** `600000` is the data segment\n* `pfn`: add three zeroes to it, and you have the physical address.\n+\nThree zeroes is 12 bits which is 4kB, which is the size of a page.\n+\nFor example, the virtual address `0x601000` has `pfn` of `0x1a61`, which means that its physical address is `0x1a61000`\n+\nThis is consistent with what `linux/virt_to_phys_user.out` told us: the virtual address `0x601048` has physical address `0x1a61048`.\n+\n`048` corresponds to the three last zeroes, and is the offset within the page.\n+\nAlso, this value falls inside `0x601000`, which as previously analyzed is the data section, which is the normal location for global variables such as ours.\n* `soft-dirty`: TODO\n* `file/shared`: TODO. `1` seems to indicate that the page can be shared across processes, possibly for read-only pages? E.g. the text segment has `1`, but the data has `0`.\n* `swapped`: TODO swapped to disk?\n* `present`: TODO vs swapped?\n* `library`: which executable owns that page\n\nThis program works in two steps:\n\n* parse the human readable lines lines from `/proc/<pid>/maps`. This files contains lines of form:\n+\n....\n7ffff7b6d000-7ffff7bdd000 r-xp 00000000 fe:00 658                        /lib/libuClibc-1.0.22.so\n....\n+\nwhich tells us that:\n+\n** `7f8af99f8000-7f8af99ff000` is a virtual address range that belong to the process, possibly containing multiple pages.\n** `/lib/libuClibc-1.0.22.so` is the name of the library that owns that memory\n* loop over each page of each address range, and ask `/proc/<pid>/pagemap` for more information about that page, including the physical address\n\n=== Linux kernel tracing\n\nGood overviews:\n\n* http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html by Brendan Greg, AKA the master of tracing. Also: https://github.com/brendangregg/perf-tools\n* https://jvns.ca/blog/2017/07/05/linux-tracing-systems/\n\nI hope to have examples of all methods some day, since I'm obsessed with visibility.\n\n[[config-proc-events]]\n==== CONFIG_PROC_EVENTS\n\nLogs proc events such as process creation to a link:kernel_modules/netlink.c[netlink socket].\n\nWe then have a userland program that listens to the events and prints them out:\n\n....\n# ./linux/proc_events.out &\n# set mcast listen ok\n# sleep 2 & sleep 1\nfork: parent tid=48 pid=48 -> child tid=79 pid=79\nfork: parent tid=48 pid=48 -> child tid=80 pid=80\nexec: tid=80 pid=80\nexec: tid=79 pid=79\n# exit: tid=80 pid=80 exit_code=0\nexit: tid=79 pid=79 exit_code=0\necho a\na\n#\n....\n\nSource: link:userland/linux/proc_events.c[]\n\nTODO: why `exit: tid=79` shows after `exit: tid=80`?\n\nNote how `echo a` is a Bash built-in, and therefore does not spawn a new process.\n\nTODO: why does this produce no output?\n\n....\n./linux/proc_events.out >f &\n....\n\n* https://stackoverflow.com/questions/6075013/detect-launching-of-programs-on-linux-platform/8255487#8255487\n* https://serverfault.com/questions/199654/does-anyone-know-a-simple-way-to-monitor-root-process-spawn\n* https://unix.stackexchange.com/questions/260162/how-to-track-newly-created-processes\n\nTODO can you get process data such as UID and process arguments? It seems not since `exec_proc_event` contains so little data: https://github.com/torvalds/linux/blob/v4.16/include/uapi/linux/cn_proc.h#L80 We could try to immediately read it from `/proc`, but there is a risk that the process finished and another one took its PID, so it wouldn't be reliable.\n\n* https://unix.stackexchange.com/questions/163681/print-pids-and-names-of-processes-as-they-are-created/163689 requests process name\n* https://serverfault.com/questions/199654/does-anyone-know-a-simple-way-to-monitor-root-process-spawn requests UID\n\n[[config-proc-events-aarch64]]\n===== CONFIG_PROC_EVENTS aarch64\n\n0111ca406bdfa6fd65a2605d353583b4c4051781 was failing with:\n\n....\n>>> kernel_modules 1.0 Building\n/usr/bin/make -j8 -C '/linux-kernel-module-cheat//out/aarch64/buildroot/build/kernel_modules-1.0/user' BR2_PACKAGE_OPENBLAS=\"\" CC=\"/linux-kernel-module-cheat//out/aarch64/buildroot/host/bin/aarch64-buildroot-linux-uclibc-gcc\" LD=\"/linux-kernel-module-cheat//out/aarch64/buildroot/host/bin/aarch64-buildroot-linux-uclibc-ld\"\n/linux-kernel-module-cheat//out/aarch64/buildroot/host/bin/aarch64-buildroot-linux-uclibc-gcc  -ggdb3 -fopenmp -O0 -std=c99 -Wall -Werror -Wextra -o 'proc_events.out' 'proc_events.c'\nIn file included from /linux-kernel-module-cheat//out/aarch64/buildroot/host/aarch64-buildroot-linux-uclibc/sysroot/usr/include/signal.h:329:0,\n                 from proc_events.c:12:\n/linux-kernel-module-cheat//out/aarch64/buildroot/host/aarch64-buildroot-linux-uclibc/sysroot/usr/include/sys/ucontext.h:50:16: error: field ‘uc_mcontext’ has incomplete type\n     mcontext_t uc_mcontext;\n                ^~~~~~~~~~~\n....\n\nso we commented it out.\n\nRelated threads:\n\n* https://mailman.uclibc-ng.org/pipermail/devel/2018-January/001624.html\n* https://github.com/DynamoRIO/dynamorio/issues/2356\n\nIf we try to naively update uclibc to 1.0.29 with `buildroot_override`, which contains the above mentioned patch, clean `aarch64` test build fails with:\n\n....\n../utils/ldd.c: In function 'elf_find_dynamic':\n../utils/ldd.c:238:12: warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]\n     return (void *)byteswap_to_host(dynp->d_un.d_val);\n            ^\n/tmp/user/20321/cciGScKB.o: In function `process_line_callback':\nmsgmerge.c:(.text+0x22): undefined reference to `escape'\n/tmp/user/20321/cciGScKB.o: In function `process':\nmsgmerge.c:(.text+0xf6): undefined reference to `poparser_init'\nmsgmerge.c:(.text+0x11e): undefined reference to `poparser_feed_line'\nmsgmerge.c:(.text+0x128): undefined reference to `poparser_finish'\ncollect2: error: ld returned 1 exit status\nMakefile.in:120: recipe for target '../utils/msgmerge.host' failed\nmake[2]: *** [../utils/msgmerge.host] Error 1\nmake[2]: *** Waiting for unfinished jobs....\n/tmp/user/20321/ccF8V8jF.o: In function `process':\nmsgfmt.c:(.text+0xbf3): undefined reference to `poparser_init'\nmsgfmt.c:(.text+0xc1f): undefined reference to `poparser_feed_line'\nmsgfmt.c:(.text+0xc2b): undefined reference to `poparser_finish'\ncollect2: error: ld returned 1 exit status\nMakefile.in:120: recipe for target '../utils/msgfmt.host' failed\nmake[2]: *** [../utils/msgfmt.host] Error 1\npackage/pkg-generic.mk:227: recipe for target '/data/git/linux-kernel-module-cheat/out/aarch64/buildroot/build/uclibc-custom/.stamp_built' failed\nmake[1]: *** [/data/git/linux-kernel-module-cheat/out/aarch64/buildroot/build/uclibc-custom/.stamp_built] Error 2\nMakefile:79: recipe for target '_all' failed\nmake: *** [_all] Error 2\n....\n\nBuildroot master has already moved to uclibc 1.0.29 at f8546e836784c17aa26970f6345db9d515411700, but it is not yet in any tag... so I'm not tempted to update it yet just for this.\n\n==== ftrace\n\nTrace a single function:\n\n....\ncd /sys/kernel/debug/tracing/\n\n# Stop tracing.\necho 0 > tracing_on\n\n# Clear previous trace.\necho > trace\n\n# List the available tracers, and pick one.\ncat available_tracers\necho function > current_tracer\n\n# List all functions that can be traced\n# cat available_filter_functions\n# Choose one.\necho __kmalloc > set_ftrace_filter\n# Confirm that only __kmalloc is enabled.\ncat enabled_functions\n\necho 1 > tracing_on\n\n# Latest events.\nhead trace\n\n# Observe trace continuously, and drain seen events out.\ncat trace_pipe &\n....\n\nSample output:\n\n....\n# tracer: function\n#\n# entries-in-buffer/entries-written: 97/97   #P:1\n#\n#                              _-----=> irqs-off\n#                             / _----=> need-resched\n#                            | / _---=> hardirq/softirq\n#                            || / _--=> preempt-depth\n#                            ||| /     delay\n#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION\n#              | |       |   ||||       |         |\n            head-228   [000] ....   825.534637: __kmalloc <-load_elf_phdrs\n            head-228   [000] ....   825.534692: __kmalloc <-load_elf_binary\n            head-228   [000] ....   825.534815: __kmalloc <-load_elf_phdrs\n            head-228   [000] ....   825.550917: __kmalloc <-__seq_open_private\n            head-228   [000] ....   825.550953: __kmalloc <-tracing_open\n            head-229   [000] ....   826.756585: __kmalloc <-load_elf_phdrs\n            head-229   [000] ....   826.756627: __kmalloc <-load_elf_binary\n            head-229   [000] ....   826.756719: __kmalloc <-load_elf_phdrs\n            head-229   [000] ....   826.773796: __kmalloc <-__seq_open_private\n            head-229   [000] ....   826.773835: __kmalloc <-tracing_open\n            head-230   [000] ....   827.174988: __kmalloc <-load_elf_phdrs\n            head-230   [000] ....   827.175046: __kmalloc <-load_elf_binary\n            head-230   [000] ....   827.175171: __kmalloc <-load_elf_phdrs\n....\n\nTrace all possible functions, and draw a call graph:\n\n....\necho 1 > max_graph_depth\necho 1 > events/enable\necho function_graph > current_tracer\n....\n\nSample output:\n\n....\n# CPU  DURATION                  FUNCTION CALLS\n# |     |   |                     |   |   |   |\n 0)   2.173 us    |                  } /* ntp_tick_length */\n 0)               |                  timekeeping_update() {\n 0)   4.176 us    |                    ntp_get_next_leap();\n 0)   5.016 us    |                    update_vsyscall();\n 0)               |                    raw_notifier_call_chain() {\n 0)   2.241 us    |                      notifier_call_chain();\n 0) + 19.879 us   |                    }\n 0)   3.144 us    |                    update_fast_timekeeper();\n 0)   2.738 us    |                    update_fast_timekeeper();\n 0) ! 117.147 us  |                  }\n 0)               |                  _raw_spin_unlock_irqrestore() {\n 0)   4.045 us    |                    _raw_write_unlock_irqrestore();\n 0) + 22.066 us   |                  }\n 0) ! 265.278 us  |                } /* update_wall_time */\n....\n\nTODO: what do `+` and `!` mean?\n\nEach `enable` under the `events/` tree enables a certain set of functions, the higher the `enable` more functions are enabled.\n\nTODO: can you get function arguments? https://stackoverflow.com/questions/27608752/does-ftrace-allow-capture-of-system-call-arguments-to-the-linux-kernel-or-only\n\n===== ftrace system calls\n\nhttps://stackoverflow.com/questions/29840213/how-do-i-trace-a-system-call-in-linux/51856306#51856306\n\n===== trace-cmd\n\nTODO example:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_TRACE_CMD=y'\n....\n\n==== Kprobes\n\nkprobes is an instrumentation mechanism that injects arbitrary code at a given address in a trap instruction, much like GDB. Oh, the good old kernel. :-)\n\n....\n./build-linux --config 'CONFIG_KPROBES=y'\n....\n\nThen on guest:\n\n....\ninsmod kprobe_example.ko\nsleep 4 & sleep 4 &'\n....\n\nOutcome: dmesg outputs on every fork:\n\n....\n<_do_fork> pre_handler: p->addr = 0x00000000e1360063, ip = ffffffff810531d1, flags = 0x246\n<_do_fork> post_handler: p->addr = 0x00000000e1360063, flags = 0x246\n<_do_fork> pre_handler: p->addr = 0x00000000e1360063, ip = ffffffff810531d1, flags = 0x246\n<_do_fork> post_handler: p->addr = 0x00000000e1360063, flags = 0x246\n....\n\nSource: link:kernel_modules/kprobe_example.c[]\n\nTODO: it does not work if I try to immediately launch `sleep`, why?\n\n....\ninsmod kprobe_example.ko\nsleep 4 & sleep 4 &\n....\n\nI don't think your code can refer to the surrounding kernel code however: the only visible thing is the value of the registers.\n\nYou can then hack it up to read the stack and read argument values, but do you really want to?\n\nThere is also a kprobes + ftrace based mechanism with `CONFIG_KPROBE_EVENTS=y` which does read the memory for us based on format strings that indicate type... https://github.com/torvalds/linux/blob/v4.16/Documentation/trace/kprobetrace.txt Horrendous. Used by: https://github.com/brendangregg/perf-tools/blob/98d42a2a1493d2d1c651a5c396e015d4f082eb20/execsnoop\n\nBibliography:\n\n* https://github.com/torvalds/linux/blob/v4.16/Documentation/kprobes.txt\n* https://github.com/torvalds/linux/blob/v4.17/samples/kprobes/kprobe_example.c\n\n==== Count boot instructions\n\nTODO: didn't port during refactor after 3b0a343647bed577586989fb702b760bd280844a. Reimplementing should not be hard.\n\n* https://www.quora.com/How-many-instructions-does-a-typical-Linux-kernel-boot-take\n* https://github.com/cirosantilli/chat/issues/31\n* https://rwmj.wordpress.com/2016/03/17/tracing-qemu-guest-execution/\n* `qemu/docs/tracing.txt` and `qemu/docs/replay.txt`\n* https://stackoverflow.com/questions/39149446/how-to-use-qemus-simple-trace-backend/46497873#46497873\n\nResults (boot not excluded) are shown at: xref:table-boot-instruction-counts[xrefstyle=full]\n\n[[table-boot-instruction-counts]]\n.Boot instruction counts for various setups\n[options=\"header\"]\n|===\n|Commit |Arch |Simulator |Instruction count\n\n|7228f75ac74c896417fb8c5ba3d375a14ed4d36b\n|arm\n|QEMU\n|680k\n\n|7228f75ac74c896417fb8c5ba3d375a14ed4d36b\n|arm\n|gem5 AtomicSimpleCPU\n|160M\n\n|7228f75ac74c896417fb8c5ba3d375a14ed4d36b\n|arm\n|gem5 HPI\n|155M\n\n|7228f75ac74c896417fb8c5ba3d375a14ed4d36b\n|x86_64\n|QEMU\n|3M\n\n|7228f75ac74c896417fb8c5ba3d375a14ed4d36b\n|x86_64\n|gem5 AtomicSimpleCPU\n|528M\n\n|===\n\nQEMU:\n\n....\n./trace-boot --arch x86_64\n....\n\nsample output:\n\n....\ninstructions 1833863\nentry_address 0x1000000\ninstructions_firmware 20708\n....\n\ngem5:\n\n....\n./run --arch aarch64 --emulator gem5 --eval 'm5 exit'\n# Or:\n# ./run --arch aarch64 --emulator gem5 --eval 'm5 exit' -- --cpu-type=HPI --caches\n./gem5-stat --arch aarch64 sim_insts\n....\n\nNotes:\n\n* `0x1000000` is the address where QEMU puts the Linux kernel at with `-kernel` in x86.\n+\nIt can be found from:\n+\n....\n./run-toolchain readelf -- -e \"$(./getvar vmlinux)\" | grep Entry\n....\n+\nTODO confirm further. If I try to break there with:\n+\n....\n./run-gdb *0x1000000\n....\n+\nbut I have no corresponding source line. Also note that this line is not actually the first line, since the kernel messages such as `early console in extract_kernel` have already shown on screen at that point. This does not break at all:\n+\n....\n./run-gdb extract_kernel\n....\n+\nIt only appears once on every log I've seen so far, checked with `grep 0x1000000 trace.txt`\n+\nThen when we count the instructions that run before the kernel entry point, there is only about 100k instructions, which is insignificant compared to the kernel boot itself.\n+\nTODO `--arch arm` and `--arch aarch64` does not count firmware instructions properly because the entry point address of the ELF file (`ffffff8008080000` for `aarch64`) does not show up on the trace at all. Tested on https://github.com/cirosantilli/linux-kernel-module-cheat/commit/f8c0502bb2680f2dbe7c1f3d7958f60265347005[f8c0502bb2680f2dbe7c1f3d7958f60265347005].\n* We can also discount the instructions after `init` runs by using `readelf` to get the initial address of `init`. One easy way to do that now is to just run:\n+\n....\n./run-gdb --userland \"$(./getvar userland_build_dir)/linux/poweroff.out\" main\n....\n+\nAnd get that from the traces, e.g. if the address is `4003a0`, then we search:\n+\n....\ngrep -n 4003a0 trace.txt\n....\n+\nI have observed a single match for that instruction, so it must be the init, and there were only 20k instructions after it, so the impact is negligible.\n* to disable networking. Is replacing `init` enough?\n+\n--\n** https://superuser.com/questions/181254/how-do-you-boot-linux-with-networking-disabled\n** https://superuser.com/questions/684005/how-does-one-permanently-disable-gnu-linux-networking/1255015#1255015\n--\n+\n`CONFIG_NET=n` did not significantly reduce instruction counts, so maybe replacing `init` is enough.\n* gem5 simulates memory latencies. So I think that the CPU loops idle while waiting for memory, and counts will be higher.\n\n=== Linux kernel hardening\n\nMake it harder to get hacked and easier to notice that you were, at the cost of some (small?) runtime overhead.\n\n[[config-fortify-source]]\n==== CONFIG_FORTIFY_SOURCE\n\nDetects buffer overflows for us:\n\n....\n./build-linux --config 'CONFIG_FORTIFY_SOURCE=y' --linux-build-id fortify\n./build-modules --clean\n./build-modules\n./build-buildroot\n./run --eval-after 'insmod strlen_overflow.ko' --linux-build-id fortify\n....\n\nPossible dmesg output:\n\n....\nstrlen_overflow: loading out-of-tree module taints kernel.\ndetected buffer overflow in strlen\n------------[ cut here ]------------\n....\n\nfollowed by a trace.\n\nYou may not get this error because this depends on `strlen` overflowing at least until the next page: if a random `\\0` appears soon enough, it won't blow up as desired.\n\nTODO not always reproducible. Find a more reproducible failure. I could not observe it on:\n\n....\ninsmod memcpy_overflow.ko\n....\n\nSource: link:kernel_modules/strlen_overflow.c[]\n\nBibliography: https://www.reddit.com/r/hacking/comments/8h4qxk/what_a_buffer_overflow_in_the_linux_kernel_looks/\n\n==== Linux security modules\n\nhttps://en.wikipedia.org/wiki/Linux_Security_Modules\n\n===== SELinux\n\nTODO get a hello world permission control working:\n\n....\n./build-linux \\\n  --config-fragment linux_config/selinux \\\n  --linux-build-id selinux \\\n;\n./build-buildroot --config 'BR2_PACKAGE_REFPOLICY=y'\n./run --enable-kvm --linux-build-id selinux\n....\n\nSource: link:linux_config/selinux[]\n\nThis builds:\n\n* `BR2_PACKAGE_REFPOLICY`, which includes a reference `/etc/selinux/config` policy: https://github.com/SELinuxProject/refpolicy\n+\nrefpolicy in turn depends on:\n* `BR2_PACKAGE_SETOOLS`, which contains tools such as `getenforced`: https://github.com/SELinuxProject/setools\n+\nsetools depends on:\n* `BR2_PACKAGE_LIBSELINUX`, which is the backing userland library\n\nAfter boot finishes, we see:\n\n....\nStarting auditd: mkdir: invalid option -- 'Z'\n....\n\nwhich comes from `/etc/init.d/S01auditd`, because BusyBox' `mkdir` does not have the crazy `-Z` option like Ubuntu. That's amazing!\n\nThe kernel logs contain:\n\n....\nSELinux:  Initializing.\n....\n\nInside the guest we now have:\n\n....\ngetenforce\n....\n\nwhich initially says:\n\n....\nDisabled\n....\n\nTODO: if we try to enforce:\n\n....\nsetenforce 1\n....\n\nit does not work and outputs:\n\n....\nsetenforce: SELinux is disabled\n....\n\nSELinux requires glibc as mentioned at: xref:libc-choice[xrefstyle=full].\n\n=== User mode Linux\n\nI once got https://en.wikipedia.org/wiki/User-mode_Linux[UML] running on a minimal Buildroot setup at: https://unix.stackexchange.com/questions/73203/how-to-create-rootfs-for-user-mode-linux-on-fedora-18/372207#372207\n\nBut in part because it is dying, I didn't spend much effort to integrate it into this repo, although it would be a good fit in principle, since it is essentially a virtualization method.\n\nMaybe some brave soul will send a pull request one day.\n\n=== UIO\n\nUIO is a kernel subsystem that allows to do certain types of driver operations from userland.\n\nThis would be awesome to improve debuggability and safety of kernel modules.\n\nVFIO looks like a newer and better UIO replacement, but there do not exist any examples of how to use it: https://stackoverflow.com/questions/49309162/interfacing-with-qemu-edu-device-via-userspace-i-o-uio-linux-driver\n\nTODO get something interesting working. I currently don't understand the behaviour very well.\n\nTODO how to ACK interrupts? How to ensure that every interrupt gets handled separately?\n\nTODO how to write to registers. Currently using `/dev/mem` and `lspci`.\n\nThis example should handle interrupts from userland and print a message to stdout:\n\n....\n./uio_read.sh\n....\n\nTODO: what is the expected behaviour? I should have documented this when I wrote this stuff, and I'm that lazy right now that I'm in the middle of a refactor :-)\n\nUIO interface in a nutshell:\n\n* blocking read / poll: waits until interrupts\n* `write`: call `irqcontrol` callback. Default: 0 or 1 to enable / disable interrupts.\n* `mmap`: access device memory\n\nSources:\n\n* link:userland/kernel_modules/uio_read.c[]\n* link:rootfs_overlay/lkmc/uio_read.sh[]\n\nBibliography:\n\n* https://stackoverflow.com/questions/15286772/userspace-vs-kernel-space-driver\n* https://01.org/linuxgraphics/gfx-docs/drm/driver-api/uio-howto.html\n* https://stackoverflow.com/questions/7986260/linux-interrupt-handling-in-user-space\n* https://yurovsky.github.io/2014/10/10/linux-uio-gpio-interrupt/\n* https://github.com/bmartini/zynq-axis/blob/65a3a448fda1f0ea4977adfba899eb487201853d/dev/axis.c\n* https://yurovsky.github.io/2014/10/10/linux-uio-gpio-interrupt/\n* http://nairobi-embedded.org/uio_example.html that website has QEMU examples for everything as usual. The example has a kernel-side which creates the memory mappings and is used by the user.\n* https://stackoverflow.com/questions/49309162/interfacing-with-qemu-edu-device-via-userspace-i-o-uio-linux-driver\n* userland driver stability questions:\n** https://stackoverflow.com/questions/8030758/getting-kernel-version-from-linux-kernel-module-at-runtime/45430233#45430233\n** https://stackoverflow.com/questions/37098482/how-to-build-a-linux-kernel-module-so-that-it-is-compatible-with-all-kernel-rele/45429681#45429681\n** https://liquidat.wordpress.com/2007/07/21/linux-kernel-2623-to-have-stable-userspace-driver-api/\n\n=== Linux kernel interactive stuff\n\n[[fbcon]]\n==== Linux kernel console fun\n\nRequires <<graphics>>.\n\nYou can also try those on the `Ctrl-Alt-F3` of your Ubuntu host, but it is much more fun inside a VM!\n\nStop the cursor from blinking:\n\n....\necho 0 > /sys/class/graphics/fbcon/cursor_blink\n....\n\nRotate the console 90 degrees! https://askubuntu.com/questions/237963/how-do-i-rotate-my-display-when-not-using-an-x-server\n\n....\necho 1 > /sys/class/graphics/fbcon/rotate\n....\n\nRelies on: `CONFIG_FRAMEBUFFER_CONSOLE_ROTATION=y`.\n\nDocumented under: `Documentation/fb/`.\n\nTODO: font and keymap. Mentioned at: https://cmcenroe.me/2017/05/05/linux-console.html and I think can be done with BusyBox `loadkmap` and `loadfont`, we just have to understand their formats, related:\n\n* https://unix.stackexchange.com/questions/177024/remap-keyboard-on-the-linux-console\n* https://superuser.com/questions/194202/remapping-keys-system-wide-in-linux-not-just-in-x\n\n==== Linux kernel magic keys\n\nRequires <<graphics>>.\n\nLet's have some fun.\n\nI think most are implemented under:\n\n....\ndrivers/tty\n....\n\nTODO find all.\n\nScroll up / down the terminal:\n\n....\nShift-PgDown\nShift-PgUp\n....\n\nOr inside `./qemu-monitor`:\n\n....\nsendkey shift-pgup\nsendkey shift-pgdown\n....\n\n===== Ctrl Alt Del\n\nIf you run in <<qemu-graphic-mode>>:\n\n....\n./run --graphic\n....\n\nand then from the graphic window you enter the keys:\n\n....\nCtrl-Alt-Del\n....\n\nthen this runs the following command on the guest:\n\n....\n/sbin/reboot\n....\n\nThis is enabled from our link:rootfs_overlay/etc/inittab[]:\n\n....\n::ctrlaltdel:/sbin/reboot\n....\n\nThis leads Linux to try to reboot, and QEMU shutdowns due to the `-no-reboot` option which we set by default for, see: xref:exit-emulator-on-panic[xrefstyle=full].\n\nHere is a minimal example of Ctrl Alt Del:\n\n....\n./run --kernel-cli 'init=/lkmc/linux/ctrl_alt_del.out' --graphic\n....\n\nSource: link:userland/linux/ctrl_alt_del.c[]\n\nWhen you hit `Ctrl-Alt-Del` in the guest, our tiny init handles a `SIGINT` sent by the kernel and outputs to stdout:\n\n....\ncad\n....\n\nTo map between `man 2 reboot` and the uClibc `RB_*` magic constants see:\n\n....\nless \"$(./getvar buildroot_build_build_dir)\"/uclibc-*/include/sys/reboot.h\"\n....\n\nThe procfs mechanism is documented at:\n\n....\nless linux/Documentation/sysctl/kernel.txt\n....\n\nwhich says:\n\n....\nWhen the value in this file is 0, ctrl-alt-del is trapped and\nsent to the init(1) program to handle a graceful restart.\nWhen, however, the value is > 0, Linux's reaction to a Vulcan\nNerve Pinch (tm) will be an immediate reboot, without even\nsyncing its dirty buffers.\n\nNote: when a program (like dosemu) has the keyboard in 'raw'\nmode, the ctrl-alt-del is intercepted by the program before it\never reaches the kernel tty layer, and it's up to the program\nto decide what to do with it.\n....\n\nUnder the hood, behaviour is controlled by the `reboot` syscall:\n\n....\nman 2 reboot\n....\n\n`reboot` system calls can set either of the these behaviours for `Ctrl-Alt-Del`:\n\n* do a hard shutdown syscall. Set in uClibc C code with:\n+\n....\nreboot(RB_ENABLE_CAD)\n....\n+\nor from procfs with:\n+\n....\necho 1 > /proc/sys/kernel/ctrl-alt-del\n....\n+\nDone by BusyBox' `reboot -f`.\n* send a SIGINT to the init process. This is what BusyBox' init does, and it then execs the string set in `inittab`.\n+\nSet in uclibc C code with:\n+\n....\nreboot(RB_DISABLE_CAD)\n....\n+\nor from procfs with:\n+\n....\necho 0 > /proc/sys/kernel/ctrl-alt-del\n....\n+\nDone by BusyBox' `reboot`.\n\nWhen a BusyBox init is with the signal, it prints the following lines:\n\n....\nThe system is going down NOW!\nSent SIGTERM to all processes\nSent SIGKILL to all processes\nRequesting system reboot\n....\n\nOn busybox-1.29.2's init at init/init.c we see how the kill signals are sent:\n\n....\nstatic void run_shutdown_and_kill_processes(void)\n{\n\t/* Run everything to be run at \"shutdown\".  This is done _prior_\n\t * to killing everything, in case people wish to use scripts to\n\t * shut things down gracefully... */\n\trun_actions(SHUTDOWN);\n\n\tmessage(L_CONSOLE | L_LOG, \"The system is going down NOW!\");\n\n\t/* Send signals to every process _except_ pid 1 */\n\tkill(-1, SIGTERM);\n\tmessage(L_CONSOLE, \"Sent SIG%s to all processes\", \"TERM\");\n\tsync();\n\tsleep(1);\n\n\tkill(-1, SIGKILL);\n\tmessage(L_CONSOLE, \"Sent SIG%s to all processes\", \"KILL\");\n\tsync();\n\t/*sleep(1); - callers take care about making a pause */\n}\n....\n\nand `run_shutdown_and_kill_processes` is called from:\n\n....\n/* The SIGPWR/SIGUSR[12]/SIGTERM handler */\nstatic void halt_reboot_pwoff(int sig) NORETURN;\nstatic void halt_reboot_pwoff(int sig)\n....\n\nwhich also prints the final line:\n\n....\n\tmessage(L_CONSOLE, \"Requesting system %s\", m);\n....\n\nwhich is set as the signal handler via TODO.\n\nBibliography:\n\n* https://superuser.com/questions/193652/does-linux-have-a-ctrlaltdel-equivalent/1324415#1324415\n* https://unix.stackexchange.com/questions/42573/meaning-and-commands-for-ctrlaltdel/444969#444969\n\n===== SysRq\n\nWe cannot test these actual shortcuts on QEMU since the host captures them at a lower level, but from:\n\n....\n./qemu-monitor\n....\n\nwe can for example crash the system with:\n\n....\nsendkey alt-sysrq-c\n....\n\nSame but boring because no magic key:\n\n....\necho c > /proc/sysrq-trigger\n....\n\nImplemented in:\n\n....\ndrivers/tty/sysrq.c\n....\n\nOn your host, on modern systems that don't have the `SysRq` key you can do:\n\n....\nAlt-PrtSc-space\n....\n\nwhich prints a message to `dmesg` of type:\n\n....\nsysrq: SysRq : HELP : loglevel(0-9) reboot(b) crash(c) terminate-all-tasks(e) memory-full-oom-kill(f) kill-all-tasks(i) thaw-filesystems(j) sak(k) show-backtrace-all-active-cpus(l) show-memory-usage(m) nice-all-RT-tasks(n) poweroff(o) show-registers(p) show-all-timers(q) unraw(r) sync(s) show-task-states(t) unmount(u) show-blocked-tasks(w) dump-ftrace-buffer(z)\n....\n\nIndividual SysRq can be enabled or disabled with the bitmask:\n\n....\n/proc/sys/kernel/sysrq\n....\n\nThe bitmask is documented at:\n\n....\nless linux/Documentation/admin-guide/sysrq.rst\n....\n\nBibliography: https://en.wikipedia.org/wiki/Magic_SysRq_key\n\n==== TTY\n\nIn order to play with TTYs, do this:\n\n....\nprintf '\ntty2::respawn:/sbin/getty -n -L -l /lkmc/loginroot.sh tty2 0 vt100\ntty3::respawn:-/bin/sh\ntty4::respawn:/sbin/getty 0 tty4\ntty63::respawn:-/bin/sh\n::respawn:/sbin/getty -L ttyS0 0 vt100\n::respawn:/sbin/getty -L ttyS1 0 vt100\n::respawn:/sbin/getty -L ttyS2 0 vt100\n# Leave one serial empty.\n#::respawn:/sbin/getty -L ttyS3 0 vt100\n' >> rootfs_overlay/etc/inittab\n./build-buildroot\n./run --graphic -- \\\n  -serial telnet::1235,server,nowait \\\n  -serial vc:800x600 \\\n  -serial telnet::1236,server,nowait \\\n;\n....\n\nand on a second shell:\n\n....\ntelnet localhost 1235\n....\n\nWe don't add more TTYs by default because it would spawn more processes, even if we use `askfirst` instead of `respawn`.\n\nOn the GUI, switch TTYs with:\n\n* `Alt-Left` or `Alt-Right:` go to previous / next populated `/dev/ttyN` TTY. Skips over empty TTYs.\n* `Alt-Fn`: go to the nth TTY. If it is  not populated, don't go there.\n* `chvt <n>`: go to the n-th virtual TTY, even if it is empty: https://superuser.com/questions/33065/console-commands-to-change-virtual-ttys-in-linux-and-openbsd\n\nYou can also test this on most hosts such as Ubuntu 18.04, except that when in the GUI, you must use `Ctrl-Alt-Fx` to switch to another terminal.\n\nNext, we also have the following shells running on the serial ports, hit enter to activate them:\n\n* `/dev/ttyS0`: first shell that was used to run QEMU, corresponds to QEMU's `-serial mon:stdio`.\n+\nIt would also work if we used `-serial stdio`, but:\n+\n--\n** `Ctrl-C` would kill QEMU instead of going to the guest\n** `Ctrl-A C` wouldn't open the QEMU console there\n--\n+\nsee also: https://stackoverflow.com/questions/49716931/how-to-run-qemu-with-nographic-and-monitor-but-still-be-able-to-send-ctrlc-to\n* `/dev/ttyS1`: second shell running `telnet`\n* `/dev/ttyS2`: go on the GUI and enter `Ctrl-Alt-2`, corresponds to QEMU's `-serial vc`. Go back to the main console with `Ctrl-Alt-1`.\n\nalthough we cannot change between terminals from there.\n\nEach populated TTY contains a \"shell\":\n\n* `-/bin/sh`: goes directly into an `sh` without a login prompt.\n+\nThe trailing dash `-` can be used on any command. It makes the command that follows take over the TTY, which is what we typically want for interactive shells: https://askubuntu.com/questions/902998/how-to-check-which-tty-am-i-using\n+\nThe `getty` executable however also does this operation and therefore dispenses the `-`.\n* `/sbin/getty` asks for password, and then gives you an `sh`\n+\nWe can overcome the password prompt with the `-l /lkmc/loginroot.sh` technique explained at: https://askubuntu.com/questions/902998/how-to-check-which-tty-am-i-using but I don't see any advantage over `-/bin/sh` currently.\n\nIdentify the current TTY with the command:\n\n....\ntty\n....\n\nBibliography:\n\n* https://unix.stackexchange.com/questions/270272/how-to-get-the-tty-in-which-bash-is-running/270372\n* https://unix.stackexchange.com/questions/187319/how-to-get-the-real-name-of-the-controlling-terminal\n* https://unix.stackexchange.com/questions/77796/how-to-get-the-current-terminal-name\n* https://askubuntu.com/questions/902998/how-to-check-which-tty-am-i-using\n\nThis outputs:\n\n* `/dev/console` for the initial GUI terminal. But I think it is the same as `/dev/tty1`, because if I try to do\n+\n....\ntty1::respawn:-/bin/sh\n....\n+\nit makes the terminal go crazy, as if multiple processes are randomly eating up the characters.\n* `/dev/ttyN` for the other graphic TTYs. Note that there are only 63 available ones, from `/dev/tty1` to `/dev/tty63` (`/dev/tty0` is the current one): https://superuser.com/questions/449781/why-is-there-so-many-linux-dev-tty[]. I think this is determined by:\n+\n....\n#define MAX_NR_CONSOLES 63\n....\n+\nin `linux/include/uapi/linux/vt.h`.\n* `/dev/ttySN` for the text shells.\n+\nThese are Serial ports, see this to understand what those represent physically: https://unix.stackexchange.com/questions/307390/what-is-the-difference-between-ttys0-ttyusb0-and-ttyama0-in-linux/367882#367882\n+\nThere are only 4 serial ports, I think this is determined by QEMU. TODO check.\n+\nSee also: https://stackoverflow.com/questions/16706423/two-instances-of-busybox-on-separate-serial-lines-ttysn\n\nGet the TTY in bulk for all processes:\n\n....\n./psa.sh\n....\n\nSource: link:rootfs_overlay/lkmc/psa.sh[].\n\nThe TTY appears under the `TT` section, which is enabled by `-o tty`. This shows the TTY device number, e.g.:\n\n....\n4,1\n....\n\nand we can then confirm it with:\n\n....\nls -l /dev/tty1\n....\n\nNext try:\n\n....\ninsmod kthread.ko\n....\n\nand switch between virtual terminals, to understand that the dmesg goes to whatever current virtual terminal you are on, but not the others, and not to the serial terminals.\n\nBibliography:\n\n* https://serverfault.com/questions/119736/how-to-enable-multiple-virtual-consoles-on-linux\n* https://github.com/mirror/busybox/blob/1_28_3/examples/inittab#L60\n* http://web.archive.org/web/20180117124612/http://nairobi-embedded.org/qemu_serial_port_system_console.html\n\n===== Start a getty from outside of init\n\nTODO: https://unix.stackexchange.com/questions/196704/getty-start-from-command-line\n\nTODO: how to place an `sh` directly on a TTY as well without `getty`?\n\nIf I try the exact same command that the `inittab` is doing from a regular shell after boot:\n\n....\n/sbin/getty 0 tty1\n....\n\nit fails with:\n\n....\ngetty: setsid: Operation not permitted\n....\n\nThe following however works:\n\n....\n./run --eval 'getty 0 tty1 & getty 0 tty2 & getty 0 tty3 & sleep 99999999' --graphic\n....\n\npresumably because it is being called from `init` directly?\n\nOutcome: `Alt-Right` cycles between three TTYs, `tty1` being the default one that appears under the boot messages.\n\n`man 2 setsid` says that there is only one failure possibility:\n\n____\nEPERM  The process group ID of any process equals the PID of the calling process.  Thus, in particular, setsid() fails if the calling process is already a process group leader.\n____\n\nWe can get some visibility into it to try and solve the problem with:\n\n....\n./psa.sh\n....\n\n===== console kernel boot parameter\n\nTake the command described at <<tty>> and try adding the following:\n\n* `-e 'console=tty7'`: boot messages still show on `/dev/tty1` (TODO how to change that?), but we don't get a shell at the end of boot there.\n+\nInstead, the shell appears on `/dev/tty7`.\n* `-e 'console=tty2'` like `/dev/tty7`, but `/dev/tty2` is broken, because we have two shells there:\n** one due to the `::respawn:-/bin/sh` entry which uses whatever `console` points to\n** another one due to the `tty2::respawn:/sbin/getty` entry we added\n* `-e 'console=ttyS0'` much like `tty2`, but messages show only on serial, and the terminal is broken due to having multiple shells on it\n* `-e 'console=tty1 console=ttyS0'`: boot messages show on both `tty1` and `ttyS0`, but only `S0` gets a shell because it came last\n\n[[config-logo]]\n==== CONFIG_LOGO\n\nIf you run in <<graphics>>, then you get a Penguin image for <<number-of-cores,every core>> above the console! https://askubuntu.com/questions/80938/is-it-possible-to-get-the-tux-logo-on-the-text-based-boot\n\nThis is due to the https://github.com/torvalds/linux/blob/v4.17/drivers/video/logo/Kconfig#L5[`CONFIG_LOGO=y`] option which we enable by default.\n\n`reset` on the terminal then kills the poor penguins.\n\nWhen `CONFIG_LOGO=y` is set, the logo can be disabled at boot with:\n\n....\n./run --kernel-cli 'logo.nologo'\n....\n\n* https://stackoverflow.com/questions/39872463/how-can-i-disable-the-startup-penguins-and-boot-text-on-linaro-ubuntu\n* https://unix.stackexchange.com/questions/332198/centos-remove-penguin-logo-at-startup\n\nLooks like a recompile is needed to modify the image...\n\n* https://superuser.com/questions/736423/changing-kernel-bootsplash-image\n* https://unix.stackexchange.com/questions/153975/how-to-change-boot-logo-in-linux-mint\n\n=== DRM\n\nDRM / DRI is the new interface that supersedes `fbdev`:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_LIBDRM=y'\n./build-userland --package libdrm -- userland/libs/libdrm/modeset.c\n./run --eval-after './libs/libdrm/modeset.out' --graphic\n....\n\nSource: link:userland/libs/libdrm/modeset.c[]\n\nOutcome: for a few seconds, the screen that contains the terminal gets taken over by changing colors of the rainbow.\n\nTODO not working for `aarch64`, it takes over the screen for a few seconds and the kernel messages disappear, but the screen stays black all the time.\n\n....\n./build-buildroot --config 'BR2_PACKAGE_LIBDRM=y'\n./build-userland --package libdrm\n./build-buildroot\n./run --eval-after './libs/libdrm/modeset.out' --graphic\n....\n\n<<kmscube>> however worked, which means that it must be a bug with this demo?\n\nWe set `CONFIG_DRM=y` on our default kernel configuration, and it creates one device file for each display:\n\n....\n# ls -l /dev/dri\ntotal 0\ncrw-------    1 root     root      226,   0 May 28 09:41 card0\n# grep 226 /proc/devices\n226 drm\n# ls /sys/module/drm /sys/module/drm_kms_helper/\n....\n\nTry creating new displays:\n\n....\n./run --arch aarch64 --graphic -- -device virtio-gpu-pci\n....\n\nto see multiple `/dev/dri/cardN`, and then use a different display with:\n\n....\n./run --eval-after './libs/libdrm/modeset.out' --graphic\n....\n\nBibliography:\n\n* https://dri.freedesktop.org/wiki/DRM/\n* https://en.wikipedia.org/wiki/Direct_Rendering_Infrastructure\n* https://en.wikipedia.org/wiki/Direct_Rendering_Manager\n* https://en.wikipedia.org/wiki/Mode_setting KMS\n\nTested on: https://github.com/cirosantilli/linux-kernel-module-cheat/commit/93e383902ebcc03d8a7ac0d65961c0e62af9612b[93e383902ebcc03d8a7ac0d65961c0e62af9612b]\n\n==== kmscube\n\n....\n./build-buildroot --config-fragment buildroot_config/kmscube\n....\n\nOutcome: a colored spinning cube coded in OpenGL + EGL takes over your display and spins forever: https://www.youtube.com/watch?v=CqgJMgfxjsk\n\nIt is a bit amusing to see OpenGL running outside of a window manager window like that: https://stackoverflow.com/questions/3804065/using-opengl-without-a-window-manager-in-linux/50669152#50669152\n\nTODO: it is very slow, about 1FPS. I tried Buildroot master ad684c20d146b220dd04a85dbf2533c69ec8ee52 with:\n\n....\nmake qemu_x86_64_defconfig\nprintf \"\nBR2_CCACHE=y\nBR2_PACKAGE_HOST_QEMU=y\nBR2_PACKAGE_HOST_QEMU_LINUX_USER_MODE=n\nBR2_PACKAGE_HOST_QEMU_SYSTEM_MODE=y\nBR2_PACKAGE_HOST_QEMU_VDE2=y\nBR2_PACKAGE_KMSCUBE=y\nBR2_PACKAGE_MESA3D=y\nBR2_PACKAGE_MESA3D_DRI_DRIVER_SWRAST=y\nBR2_PACKAGE_MESA3D_OPENGL_EGL=y\nBR2_PACKAGE_MESA3D_OPENGL_ES=y\nBR2_TOOLCHAIN_BUILDROOT_CXX=y\n\" >> .config\n....\n\nand the FPS was much better, I estimate something like 15FPS.\n\nOn Ubuntu 18.04 with NVIDIA proprietary drivers:\n\n....\nsudo apt-get instll kmscube\nkmscube\n....\n\nfails with:\n\n....\ndrmModeGetResources failed: Invalid argument\nfailed to initialize legacy DRM\n....\n\nSee also:\n\n* https://github.com/robclark/kmscube/issues/12 and:\n* https://stackoverflow.com/questions/26920835/can-egl-application-run-in-console-mode/26921287#26921287\n* https://stackoverflow.com/questions/3804065/how-to-use-opengl-without-a-window-manager-in-linux/50669152#50669152\n\nTested on: https://github.com/cirosantilli/linux-kernel-module-cheat/commit/2903771275372ccfecc2b025edbb0d04c4016930[2903771275372ccfecc2b025edbb0d04c4016930]\n\n==== kmscon\n\nTODO get working.\n\nImplements a console for <<drm>>.\n\nThe Linux kernel has a built-in fbdev console called <<fbcon>> but not for <<drm>> it seems.\n\nThe upstream project seems dead with last commit in 2014: https://www.freedesktop.org/wiki/Software/kmscon/\n\nBuild failed in Ubuntu 18.04 with: https://github.com/dvdhrm/kmscon/issues/131 but this fork compiled but didn't run on host: https://github.com/Aetf/kmscon/issues/2#issuecomment-392484043\n\nHaven't tested the fork on QEMU too much insanity.\n\n==== libdri2\n\nTODO get working.\n\nLooks like a more raw alternative to libdrm:\n\n....\n./build-buildroot --config 'BR2_PACKABE_LIBDRI2=y'\nwget \\\n  -O \"$(./getvar userland_source_dir)/dri2test.c\" \\\n  https://raw.githubusercontent.com/robclark/libdri2/master/test/dri2test.c \\\n;\n./build-userland\n....\n\nbut then I noticed that that example requires multiple files, and I don't feel like integrating it into our build.\n\nWhen I build it on Ubuntu 18.04 host, it does not generate any executable, so I'm confused.\n\n=== Linux kernel testing\n\nBibliography: https://stackoverflow.com/questions/3177338/how-is-the-linux-kernel-tested\n\n==== Linux Test Project\n\nhttps://github.com/linux-test-project/ltp\n\nTests a lot of Linux and POSIX userland visible interfaces.\n\nBuildroot already has a package, so it is trivial to build it:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_LTP_TESTSUITE=y'\n....\n\nSo now let's try and see if the `exit` system call is working:\n\n....\n/usr/lib/ltp-testsuite/testcases/bin/exit01\n....\n\nwhich gives successful output:\n\n....\nexit01      1  TPASS  :  exit() test PASSED\n....\n\nand has source code at: https://github.com/linux-test-project/ltp/blob/20190115/testcases/kernel/syscalls/exit/exit01.c\n\nBesides testing any kernel modifications you make, LTP can also be used to the system call implementation of <<user-mode-simulation>> as shown at <<user-mode-buildroot-executables>>:\n\n....\n./run --userland \"$(./getvar buildroot_target_dir)/usr/lib/ltp-testsuite/testcases/bin/exit01\"\n....\n\nTested at: 287c83f3f99db8c1ff9bbc85a79576da6a78e986 + 1.\n\n==== stress\n\n<<posix>> userland stress. Two versions:\n\n....\n./build-buildroot \\\n  --config 'BR2_PACKAGE_STRESS=y' \\\n  --config 'BR2_PACKAGE_STRESS_NG=y' \\\n;\n....\n\n`STRESS_NG` is likely the best, but it requires glibc, see: xref:libc-choice[xrefstyle=full].\n\nWebsites:\n\n* https://people.seas.harvard.edu/~apw/stress/\n* https://github.com/ColinIanKing/stress-ng\n\n`stress` usage:\n\n....\nstress --help\nstress -c 16 &\nps\n....\n\nand notice how 16 threads were created in addition to a parent worker thread.\n\nIt just runs forever, so kill it when you get tired:\n\n....\nkill %1\n....\n\n`stress -c 1 -t 1` makes gem5 irresponsive for a very long time.\n\n=== Linux kernel build system\n\n==== vmlinux vs bzImage vs zImage vs Image\n\nBetween all archs on QEMU and gem5 we touch all of those kernel built output files.\n\nWe are trying to maintain a description of each at: https://unix.stackexchange.com/questions/5518/what-is-the-difference-between-the-following-kernel-makefile-terms-vmlinux-vml/482978#482978\n\nQEMU does not seem able to boot ELF files like `vmlinux`: https://superuser.com/questions/1376944/can-qemu-boot-linux-from-vmlinux-instead-of-bzimage\n\nConverting `arch/*` images to `vmlinux` is possible in theory x86 with https://github.com/torvalds/linux/blob/v5.1/scripts/extract-vmlinux[`extract-vmlinux`] but we didn't get any gem5 boots working from images generated like that for some reason, see: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/79\n\n=== Virtio\n\nhttps://www.linux-kvm.org/page/Virtio\n\nVirtio is an interface that guest machines can use to efficiently use resources from host machines.\n\nThe types of resources it supports are for disks and networking hardware.\n\nThis interface is not like the real interface used by the host to read from real disks and network devices.\n\nRather, it is a simplified interface, that makes those operations simpler and faster since guest and host work together knowing that this is an emulation use case.\n\n=== Kernel modules\n\n[[dump-regs]]\n==== dump_regs\n\nThe following kernel modules and <<baremetal>> executables dump and disassemble various registers which cannot be observed from userland (usually \"system registers\", \"control registers\"):\n\n* link:kernel_modules/dump_regs.c[]\n* link:userland/arch/arm/dump_regs.c[]\n* link:userland/arch/aarch64/dump_regs.c[]\n* link:baremetal/arch/arm/dump_regs.c[]\n* link:baremetal/arch/aarch64/dump_regs.c[]\n\nSome of those programs are using:\n\n* link:lkmc/aarch64_dump_regs.h[]\n\nAlternatively, you can also get their value from inside <<gdb>> with:\n\n....\ninfo registers all\n....\n\nor the short version:\n\n....\ni r a\n....\n\nor to get just specific registers, e.g. just ARMv8's SCTLR:\n\n....\ni r SCTLR\n....\n\nbut it is sometimes just more convenient to run an executable to get the registers at the point of interest.\n\nSee also:\n\n* https://stackoverflow.com/questions/5429137/how-to-print-register-values-in-gdb/31340294#31340294\n* https://stackoverflow.com/questions/24169614/how-to-show-all-x86-control-registers-when-debugging-the-linux-kernel-in-gdb-thr/59311764#59311764\n\n== FreeBSD\n\nhttps://en.wikipedia.org/wiki/FreeBSD\n\nPrebuilt on Ubuntu 20.04 worked: https://stackoverflow.com/questions/49656395/how-to-boot-freebsd-image-under-qemu/64027161#64027161[]\n\nTODO minimal build + boot on QEMU example anywhere???\n\n== RTOS\n\nhttps://en.wikipedia.org/wiki/Real-time_operating_system\n\n=== Zephyr\n\nhttps://en.wikipedia.org/wiki/Zephyr_(operating_system)\n\nZephyr is an RTOS that has <<posix>> support. I think it works much like our <<baremetal-setup>> which uses Newlib and generates individual ELF files that contain both our C program's code, and the Zephyr libraries.\n\nTODO get a hello world working, and then consider further integration in this repo, e.g. being able to run all C userland content on it.\n\nTODO: Cortex-A CPUs are not currently supported, there are some `qemu_cortex_m0` boards, but can't find a QEMU Cortex-A. There is an x86_64 qemu board, but we don't currently have an <<about-the-baremetal-setup,x86 baremetal toolchain>>. For this reason, we won't touch this further for now.\n\nHowever, unlike Newlib, Zephyr must be setting up a simple pre-main runtime to be able to handle threads.\n\nFailed attempt:\n\n....\n# https://askubuntu.com/questions/952429/is-there-a-good-ppa-for-cmake-backports\nwget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | sudo apt-key add -\nsudo apt-add-repository 'deb https://apt.kitware.com/ubuntu/ bionic-rc main'\nsudo apt-get update\nsudo apt-get install cmake\ngit clone https://github.com/zephyrproject-rtos/zephyr\npip3 install --user -U west packaging\ncd zephyr\ngit checkout v1.14.1\nwest init zephyrproject\nwest update\nexport ZEPHYR_TOOLCHAIN_VARIANT=xtools\nexport XTOOLS_TOOLCHAIN_PATH=\"$(pwd)/out/crosstool-ng/build/default/install/aarch64/bin/\"\nsource zephyr-env.sh\nwest build -b qemu_aarch64 samples/hello_world\n....\n\nThe build system of that project is a bit excessive / wonky. You need an edge CMake not present in Ubuntu 18.04, which I don't want to install right now, and it uses the weird custom `west` build tool frontend.\n\n=== ARM Mbed\n\nhttps://en.wikipedia.org/wiki/Mbed\n\nTODO minimal setup to run it on QEMU? Possible?\n\n== Xen\n\nhttps://en.wikipedia.org/wiki/Xen\n\nTODO: get prototype working and then properly integrate:\n\n....\n./build-xen\n....\n\nSource: link:build-xen[]\n\nThis script attempts to build Xen for aarch64 and feed it into QEMU through link:submodules/boot-wrapper-aarch64[]\n\nTODO: other archs not yet attempted.\n\nThe current bad behaviour is that it prints just:\n\n....\nBoot-wrapper v0.2\n....\n\nand nothing else.\n\nWe will also need `CONFIG_XEN=y` on the Linux kernel, but first Xen should print some Xen messages before the kernel is ever reached.\n\nIf we pass to QEMU the xen image directly instead of the boot wrapper one:\n\n....\n-kernel ../xen/xen/xen\n....\n\nthen Xen messages do show up! So it seems that the configuration failure lies in the boot wrapper itself rather than Xen.\n\nMaybe it is also possible to run Xen directly like this: QEMU can already load multiple images at different memory locations with the generic loader: https://github.com/qemu/qemu/blob/master/docs/generic-loader.txt which looks something along:\n\n....\n-kernel file1.elf -device loader,file=file2.elf\n....\n\nso as long as we craft the correct DTB and feed it into Xen so that it can see the kernel, it should work. TODO does QEMU support patching the auto-generated DTB with pre-generated options? In the worst case we can just dump it hand hack it up though with `-machine dumpdtb`, see: xref:device-tree-emulator-generation[xrefstyle=full].\n\nBibliography:\n\n* this attempt was based on: https://wiki.xenproject.org/wiki/Xen_ARM_with_Virtualization_Extensions/FastModels which is the documentation for the ARM Fast Models closed source simulators.\n* https://wiki.xenproject.org/wiki/Xen_ARM_with_Virtualization_Extensions/qemu-system-aarch64 this is the only QEMU aarch64 Xen page on the web. It uses the Ubuntu aarc64 image, which has EDK2.\n+\nI however see no joy on blobs. Buildroot does not seem to support EDK 2.\n\nLink on readme https://stackoverflow.com/questions/49348453/xen-on-qemu-with-arm64-architecture\n\n== U-Boot\n\nhttps://en.wikipedia.org/wiki/Das_U-Boot\n\nU-Boot is a popular bootloader.\n\nIt can read disk filesystems, and Buildroot supports it, so we could in theory put it into memory, and let it find a kernel image from the root filesystem and boot that, but I didn't manage to get it working yet: https://stackoverflow.com/questions/58028789/how-to-boot-linux-aarch64-with-u-boot-with-buildroot-on-qemu\n\n== Emulators\n\nhttps://en.wikipedia.org/wiki/Emulator\n\n* <<qemu>>\n* <<gem5>>\n* <<gensim>>\n\n== QEMU\n\n=== Introduction to QEMU\n\nhttps://en.wikipedia.org/wiki/QEMU[QEMU] is a system simulator: it simulates a CPU and devices such as interrupt handlers, timers, UART, screen, keyboard, etc.\n\nIf you are familiar with https://en.wikipedia.org/wiki/VirtualBox[VirtualBox], then QEMU then basically does the same thing: it opens a \"window\" inside your desktop that can run an operating system inside your operating system.\n\nAlso both can use very similar techniques: either <<binary-translation>> or <<KVM>>. VirtualBox' binary translator is / was based on QEMU's it seems: https://en.wikipedia.org/wiki/VirtualBox#Software-based_virtualization\n\nThe huge advantage of QEMU over VirtualBox is that is supports cross arch simulation, e.g. simulate an ARM guest on an x86 host.\n\nQEMU is likely the leading cross arch system simulator as of 2018. It is even the default <<android>> simulator that developers get with Android Studio 3 to develop apps without real hardware.\n\nAnother advantage of QEMU over virtual box is that it doesn't have Oracle' hands all all over it, more like RedHat + ARM.\n\nAnother advantage of QEMU is that is has no nice configuration GUI. Because who needs GUIs when you have 50 million semi-documented CLI options? Android Studio adds a custom GUI configuration tool on top of it.\n\nQEMU is also supported by Buildroot in-tree, see e.g.: https://github.com/buildroot/buildroot/blob/2018.05/configs/qemu_aarch64_virt_defconfig We however just build our own manually with link:build-qemu[], as it gives more flexibility, and building QEMU is very easy!\n\nAll of this makes QEMU the natural choice of reference system simulator for this repo.\n\n=== Binary translation\n\nhttps://en.wikipedia.org/wiki/Binary_translation\n\nUsed by <<qemu>> and <<gensim>>.\n\n=== Disk persistency\n\nWe disable disk persistency for both QEMU and gem5 by default, to prevent the emulator from putting the image in an unknown state.\n\nFor QEMU, this is done by passing the `snapshot` option to `-drive`, and for gem5 it is the default behaviour.\n\nIf you hack up our link:run[] script to remove that option, then:\n\n....\n./run --eval-after 'date >f;poweroff'\n\n....\n\nfollowed by:\n\n....\n./run --eval-after 'cat f'\n....\n\ngives the date, because `poweroff` without `-n` syncs before shutdown.\n\nThe `sync` command also saves the disk:\n\n....\nsync\n....\n\nWhen you do:\n\n....\n./build-buildroot\n....\n\nthe disk image gets overwritten by a fresh filesystem and you lose all changes.\n\nRemember that if you forcibly turn QEMU off without `sync` or `poweroff` from inside the VM, e.g. by closing the QEMU window, disk changes may not be saved.\n\nPersistency is also turned off when booting from <<initrd>> with a CPIO instead of with a disk.\n\nDisk persistency is useful to re-run shell commands from the history of a previous session with `Ctrl-R`, but we felt that the loss of determinism was not worth it.\n\n==== gem5 disk persistency\n\nTODO how to make gem5 disk writes persistent?\n\nAs of cadb92f2df916dbb47f428fd1ec4932a2e1f0f48 there are some `read_only` entries in the <<gem5-config-ini>> under cow sections, but hacking them to true did not work:\n\n....\ndiff --git a/configs/common/FSConfig.py b/configs/common/FSConfig.py\nindex 17498c42b..76b8b351d 100644\n--- a/configs/common/FSConfig.py\n+++ b/configs/common/FSConfig.py\n@@ -60,7 +60,7 @@ os_types = { 'alpha' : [ 'linux' ],\n            }\n\n class CowIdeDisk(IdeDisk):\n-    image = CowDiskImage(child=RawDiskImage(read_only=True),\n+    image = CowDiskImage(child=RawDiskImage(read_only=False),\n                          read_only=False)\n\n     def childImage(self, ci):\n....\n\nThe directory of interest is `src/dev/storage`.\n\n=== gem5 qcow2\n\nqcow2 does not appear supported, there are not hits in the source tree, and there is a mention on Nate's 2009 wishlist: http://gem5.org/Nate%27s_Wish_List\n\nThis would be good to allow storing smaller sparse ext2 images locally on disk.\n\n=== Snapshot\n\nQEMU allows us to take snapshots at any time through the monitor.\n\nYou can then restore CPU, memory and disk state back at any time.\n\nqcow2 filesystems must be used for that to work.\n\nTo test it out, login into the VM with and run:\n\n....\n./run --eval-after 'umount /mnt/9p/*;./count.sh'\n....\n\nOn another shell, take a snapshot:\n\n....\n./qemu-monitor savevm my_snap_id\n....\n\nThe counting continues.\n\nRestore the snapshot:\n\n....\n./qemu-monitor loadvm my_snap_id\n....\n\nand the counting goes back to where we saved. This shows that CPU and memory states were reverted.\n\nThe `umount` is needed because snapshotting conflicts with <<9p>>, which we felt is a more valuable default. If you forget to unmount, the following error appears on the QEMU monitor:\n\n.....\nMigration is disabled when VirtFS export path '/linux-kernel-module-cheat/out/x86_64/buildroot/build' is mounted in the guest using mount_tag 'host_out'\n.....\n\nWe can also verify that the disk state is also reversed. Guest:\n\n....\necho 0 >f\n....\n\nMonitor:\n\n....\n./qemu-monitor savevm my_snap_id\n....\n\nGuest:\n\n....\necho 1 >f\n....\n\nMonitor:\n\n....\n./qemu-monitor loadvm my_snap_id\n....\n\nGuest:\n\n....\ncat f\n....\n\nAnd the output is `0`.\n\nOur setup does not allow for snapshotting while using <<initrd>>.\n\nBibliography: https://stackoverflow.com/questions/40227651/does-qemu-emulator-have-checkpoint-function/48724371#48724371\n\n==== Snapshot internals\n\nSnapshots are stored inside the `.qcow2` images themselves.\n\nThey can be observed with:\n\n....\n\"$(./getvar buildroot_host_dir)/bin/qemu-img\" info \"$(./getvar qcow2_file)\"\n....\n\nwhich after `savevm my_snap_id` and `savevm asdf` contains an output of type:\n\n....\nimage: out/x86_64/buildroot/images/rootfs.ext2.qcow2\nfile format: qcow2\nvirtual size: 512M (536870912 bytes)\ndisk size: 180M\ncluster_size: 65536\nSnapshot list:\nID        TAG                 VM SIZE                DATE       VM CLOCK\n1         my_snap_id              47M 2018-04-27 21:17:50   00:00:15.251\n2         asdf                    47M 2018-04-27 21:20:39   00:00:18.583\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n    refcount bits: 16\n    corrupt: false\n....\n\nAs a consequence:\n\n* it is possible to restore snapshots across boots, since they stay on the same image the entire time\n* it is not possible to use snapshots with <<initrd>> in our setup, since we don't pass `-drive` at all when initrd is enabled\n\n=== Device models\n\nThis section documents:\n\n* how to interact with peripheral hardware device models through device drivers\n* how to write your own hardware device models for our emulators, see also: https://stackoverflow.com/questions/28315265/how-to-add-a-new-device-in-qemu-source-code\n\nFor the more complex interfaces, we focus on simplified educational devices, either:\n\n* present in the QEMU upstream:\n** <<qemu-edu>>\n\n==== PCI\n\nOnly tested in x86.\n\n[[qemu-edu]]\n===== QEMU edu PCI device\n\nSmall upstream educational PCI device:\n\n....\n./qemu_edu.sh\n....\n\nThis tests a lot of features of the edu device, to understand the results, compare the inputs with the documentation of the hardware: https://github.com/qemu/qemu/blob/v2.12.0/docs/specs/edu.txt\n\nSources:\n\n* kernel module: link:kernel_modules/qemu_edu.c[]\n* QEMU device: https://github.com/qemu/qemu/blob/v2.12.0/hw/misc/edu.c\n* test script: link:rootfs_overlay/lkmc/qemu_edu.sh[]\n\nWorks because we add to our default QEMU CLI:\n\n....\n-device edu\n....\n\nThis example uses:\n\n* the QEMU `edu` educational device, which is a minimal educational in-tree PCI example\n* the `pci.ko` kernel module, which exercises the `edu` hardware.\n+\nI've contacted the awesome original author author of `edu` https://github.com/jirislaby[Jiri Slaby], and he told there is no official kernel module example because this was created for a kernel module university course that he gives, and he didn't want to give away answers. https://github.com/cirosantilli/how-to-teach-efficiently[I don't agree with that philosophy], so students, cheat away with this repo and go make startups instead.\n\nTODO exercise DMA on the kernel module. The `edu` hardware model has that feature:\n\n* https://stackoverflow.com/questions/17913679/how-to-instantiate-and-use-a-dma-driver-linux-module\n* https://stackoverflow.com/questions/32592734/are-there-any-dma-driver-example-pcie-and-fpga/44716747#44716747\n* https://stackoverflow.com/questions/62831327/add-memory-device-to-qemu\n* https://stackoverflow.com/questions/64539528/qemu-pci-dma-read-and-pci-dma-write-does-not-work\n* https://stackoverflow.com/questions/64842929/general-protection-error-while-tring-to-perform-ioctl\n\n===== Manipulate PCI registers directly\n\nIn this section we will try to interact with PCI devices directly from userland without kernel modules.\n\nFirst identify the PCI device with:\n\n....\nlspci\n....\n\nIn our case for example, we see:\n\n....\n00:06.0 Unclassified device [00ff]: Device 1234:11e8 (rev 10)\n00:07.0 Unclassified device [00ff]: Device 1234:11e9\n....\n\nwhich we identify as being <<qemu-edu>> by the magic number: `1234:11e8`.\n\nAlternatively, we can also do use the QEMU monitor:\n\n....\n./qemu-monitor info qtree\n....\n\nwhich gives:\n\n....\n      dev: edu, id \"\"\n        addr = 06.0\n        romfile = \"\"\n        rombar = 1 (0x1)\n        multifunction = false\n        command_serr_enable = true\n        x-pcie-lnksta-dllla = true\n        x-pcie-extcap-init = true\n        class Class 00ff, addr 00:06.0, pci id 1234:11e8 (sub 1af4:1100)\n        bar 0: mem at 0xfea00000 [0xfeafffff]\n....\n\nSee also: https://serverfault.com/questions/587189/list-all-devices-emulated-for-a-vm/913622#913622\n\nRead the configuration registers as binary:\n\n....\nhexdump /sys/bus/pci/devices/0000:00:06.0/config\n....\n\nGet nice human readable names and offsets of the registers and some enums:\n\n....\nsetpci --dumpregs\n....\n\nGet the values of a given config register from its human readable name, either with either bus or device id:\n\n....\nsetpci -s 0000:00:06.0 BASE_ADDRESS_0\nsetpci -d 1234:11e8 BASE_ADDRESS_0\n....\n\nNote however that `BASE_ADDRESS_0` also appears when you do:\n\n....\nlspci -v\n....\n\nas:\n\n....\nMemory at feb54000\n....\n\nThen you can try messing with that address with <<dev-mem>>:\n\n....\ndevmem 0xfeb54000 w 0x12345678\n....\n\nwhich writes to the first register of the edu device.\n\nThe device then fires an interrupt at irq 11, which is unhandled, which leads the kernel to say you are a bad person:\n\n....\n<3>[ 1065.567742] irq 11: nobody cared (try booting with the \"irqpoll\" option)\n....\n\nfollowed by a trace.\n\nNext, also try using our <<irq-ko>> IRQ monitoring module before triggering the interrupt:\n\n....\ninsmod irq.ko\ndevmem 0xfeb54000 w 0x12345678\n....\n\nOur kernel module handles the interrupt, but does not acknowledge it like our proper edu kernel module, and so it keeps firing, which leads to infinitely many messages being printed:\n\n....\nhandler irq = 11 dev = 251\n....\n\n===== pciutils\n\nThere are two versions of `setpci` and `lspci`:\n\n* a simple one from BusyBox\n* a more complete one from https://github.com/pciutils/pciutils[pciutils] which Buildroot has a package for, and is the default on Ubuntu 18.04 host. This is the one we enable by default.\n\n===== Introduction to PCI\n\nThe PCI standard is non-free, obviously like everything in low level: https://pcisig.com/specifications but Google gives several illegal PDF hits :-)\n\nAnd of course, the best documentation available is: http://wiki.osdev.org/PCI\n\nLike every other hardware, we could interact with PCI on x86 using only IO instructions and memory operations.\n\nBut PCI is a complex communication protocol that the Linux kernel implements beautifully for us, so let's use the kernel API.\n\nBibliography:\n\n* edu device source and spec in QEMU tree:\n** https://github.com/qemu/qemu/blob/v2.7.0/hw/misc/edu.c\n** https://github.com/qemu/qemu/blob/v2.7.0/docs/specs/edu.txt\n* http://www.zarb.org/~trem/kernel/pci/pci-driver.c inb outb runnable example (no device)\n* LDD3 PCI chapter\n* another QEMU device + module, but using a custom QEMU device:\n** https://github.com/levex/kernel-qemu-pci/blob/31fc9355161b87cea8946b49857447ddd34c7aa6/module/levpci.c\n** https://github.com/levex/kernel-qemu-pci/blob/31fc9355161b87cea8946b49857447ddd34c7aa6/qemu/hw/char/lev-pci.c\n* https://is.muni.cz/el/1433/podzim2016/PB173/um/65218991/ course given by the creator of the edu device. In Czech, and only describes API\n* http://nairobi-embedded.org/linux_pci_device_driver.html\n\n===== PCI BFD\n\n`lspci -k` shows something like:\n\n....\n00:04.0 Class 00ff: 1234:11e8 lkmc_pci\n....\n\nMeaning of the first numbers:\n\n....\n<8:bus>:<5:device>.<3:function>\n....\n\nOften abbreviated to BDF.\n\n* bus: groups PCI slots\n* device: maps to one slot\n* function: https://stackoverflow.com/questions/19223394/what-is-the-function-number-in-pci/44735372#44735372\n\nSometimes a fourth number is also added, e.g.:\n\n....\n0000:00:04.0\n....\n\nTODO is that the domain?\n\nClass: pure magic: https://www-s.acm.illinois.edu/sigops/2007/roll_your_own/7.c.1.html TODO: does it have any side effects? Set in the edu device at:\n\n....\nk->class_id = PCI_CLASS_OTHERS\n....\n\n===== PCI BAR\n\nhttps://stackoverflow.com/questions/30190050/what-is-base-address-register-bar-in-pcie/44716618#44716618\n\nEach PCI device has 6 BAR IOs (base address register) as per the PCI spec.\n\nEach BAR corresponds to an address range that can be used to communicate with the PCI.\n\nEach BAR is of one of the two types:\n\n* `IORESOURCE_IO`: must be accessed with `inX` and `outX`\n* `IORESOURCE_MEM`: must be accessed with `ioreadX` and `iowriteX`. This is the saner method apparently, and what the edu device uses.\n\nThe length of each region is defined by the hardware, and communicated to software via the configuration registers.\n\nThe Linux kernel automatically parses the 64 bytes of standardized configuration registers for us.\n\nQEMU devices register those regions with:\n\n....\nmemory_region_init_io(&edu->mmio, OBJECT(edu), &edu_mmio_ops, edu,\n                \"edu-mmio\", 1 << 20);\npci_register_bar(pdev, 0, PCI_BASE_ADDRESS_SPACE_MEMORY, &edu->mmio);\n....\n\n==== GPIO\n\nTODO: broken. Was working before we moved `arm` from `-M versatilepb` to `-M virt` around af210a76711b7fa4554dcc2abd0ddacfc810dfd4. Either make it work on `-M virt` if that is possible, or document precisely how to make it work with `versatilepb`, or hopefully `vexpress` which is newer.\n\nQEMU does not have a very nice mechanism to observe GPIO activity: https://raspberrypi.stackexchange.com/questions/56373/is-it-possible-to-get-the-state-of-the-leds-and-gpios-in-a-qemu-emulation-like-t/69267#69267\n\nThe best you can do is to hack our link:build[] script to add:\n\n....\nHOST_QEMU_OPTS='--extra-cflags=-DDEBUG_PL061=1'\n....\n\nwhere http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0190b/index.html[PL061] is the dominating ARM Holdings hardware that handles GPIO.\n\nThen compile with:\n\n....\n./build-buildroot --arch arm --config-fragment buildroot_config/gpio\n./build-linux --config-fragment linux_config/gpio\n....\n\nthen test it out with:\n\n....\n./gpio.sh\n....\n\nSource: link:rootfs_overlay/lkmc/gpio.sh[]\n\nBuildroot's Linux tools package provides some GPIO CLI tools: `lsgpio`, `gpio-event-mon`, `gpio-hammer`, TODO document them here.\n\n==== LEDs\n\nTODO: broken when `arm` moved to `-M virt`, same as <<gpio>>.\n\nHack QEMU's `hw/misc/arm_sysctl.c` with a printf:\n\n....\nstatic void arm_sysctl_write(void *opaque, hwaddr offset,\n                            uint64_t val, unsigned size)\n{\n    arm_sysctl_state *s = (arm_sysctl_state *)opaque;\n\n    switch (offset) {\n    case 0x08: /* LED */\n        printf(\"LED val = %llx\\n\", (unsigned long long)val);\n....\n\nand then rebuild with:\n\n....\n./build-qemu --arch arm\n./build-linux --arch arm --config-fragment linux_config/leds\n....\n\nBut beware that one of the LEDs has a heartbeat trigger by default (specified on dts), so it will produce a lot of output.\n\nAnd then activate it with:\n\n....\ncd /sys/class/leds/versatile:0\ncat max_brightness\necho 255 >brightness\n....\n\nRelevant QEMU files:\n\n* `hw/arm/versatilepb.c`\n* `hw/misc/arm_sysctl.c`\n\nRelevant kernel files:\n\n* `arch/arm/boot/dts/versatile-pb.dts`\n* `drivers/leds/led-class.c`\n* `drivers/leds/leds-sysctl.c`\n\n==== gem5 educational hardware models\n\nTODO get some working!\n\nhttp://gedare-csphd.blogspot.co.uk/2013/02/adding-simple-io-device-to-gem5.html\n\n=== QEMU monitor\n\nThe QEMU monitor is a magic terminal that allows you to send text commands to the QEMU VM itself: https://en.wikibooks.org/wiki/QEMU/Monitor\n\nWhile QEMU is running, on another terminal, run:\n\n....\n./qemu-monitor\n....\n\nor send one command such as `info qtree` and quit the monitor:\n\n....\n./qemu-monitor info qtree\n....\n\nor equivalently:\n\n....\necho 'info qtree' | ./qemu-monitor\n....\n\nSource: link:qemu-monitor[]\n\n`qemu-monitor` uses the `-monitor` QEMU command line option, which makes the monitor listen from a socket.\n\nAlternatively, we can also enter the QEMU monitor from inside `-nographics` <<qemu-text-mode>> with:\n\n....\nCtrl-A C\n....\n\nand go back to the terminal with:\n\n....\nCtrl-A C\n....\n\n* https://stackoverflow.com/questions/14165158/how-to-switch-to-qemu-monitor-console-when-running-with-curses\n* https://superuser.com/questions/488263/how-to-switch-to-the-qemu-control-panel-with-nographics\n\nWhen in graphic mode, we can do it from the GUI:\n\n....\nCtrl-Alt ?\n....\n\nwhere `?` is a digit `1`, or `2`, or, `3`, etc. depending on what else is available on the GUI: serial, parallel and frame buffer.\n\nFinally, we can also access QEMU monitor commands directly from <<gdb>> with the `monitor` command:\n\n....\n./run-gdb\n....\n\nthen inside that shell:\n\n....\nmonitor info qtree\n....\n\nThis way you can use both QEMU monitor and GDB commands to inspect the guest from inside a single shell! Pretty awesome.\n\nIn general, `./qemu-monitor` is the best option, as it:\n\n* works on both modes\n* allows to use the host Bash history to re-run one off commands\n* allows you to search the output of commands on your host shell even when in graphic mode\n\nGetting everything to work required careful choice of QEMU command line options:\n\n* https://stackoverflow.com/questions/49716931/how-to-run-qemu-with-nographic-and-monitor-but-still-be-able-to-send-ctrlc-to/49751144#49751144\n* https://unix.stackexchange.com/questions/167165/how-to-pass-ctrl-c-to-the-guest-when-running-qemu-with-nographic/436321#436321\n\n==== QEMU monitor from guest\n\nPeter Maydell said potentially not possible nicely as of August 2018: https://stackoverflow.com/questions/51747744/how-to-run-a-qemu-monitor-command-from-inside-the-guest/51764110#51764110\n\nIt is also worth looking into the QEMU Guest Agent tool `qemu-gq` that can be enabled with:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_QEMU=y'\n....\n\nSee also: https://superuser.com/questions/930588/how-to-pass-commands-noninteractively-to-running-qemu-from-the-guest-qmp-via-te\n\n==== QEMU monitor from GDB\n\nWhen doing <<gdb>> it is possible to send QEMU monitor commands through the GDB `monitor` command, which saves you the trouble of opening yet another shell.\n\nTry for example:\n\n....\nmonitor help\nmonitor info qtree\n....\n\n=== Debug the emulator\n\nWhen you start hacking QEMU or gem5, it is useful to see what is going on inside the emulator themselves.\n\nThis is of course trivial since they are just regular userland programs on the host, but we make it a bit easier with:\n\n....\n./run --debug-vm\n....\n\nOr for a faster development loop you can pass `-ex` command as a semicolon separated list:\n\n....\n./run --debug-vm-ex 'break qemu_add_opts;run'\n....\n\nwhich is equivalent to the more verbose:\n\n....\n./run --debug-vm-args '-ex \"break qemu_add_opts\" -ex \"run\"'\n....\n\nif you ever want need anything besides -ex.\n\nOr if things get really involved and you want a debug script:\n\n....\nprintf 'break qemu_add_opts\nrun\n' > data/vm.gdb\n./run --debug-vm-file data/vm.gdb\n....\n\nOur default emulator builds are optimized with `gcc -O2 -g`. To use `-O0` instead, build and run with:\n\n....\n./build-qemu --qemu-build-type debug --verbose\n./run --debug-vm\n./build-gem5 --gem5-build-type debug --verbose\n./run --debug-vm --emulator-gem5\n....\n\nThe `--verbose` is optional, but shows clearly each GCC build command so that you can confirm what `--*-build-type` is doing.\n\nThe build outputs are automatically stored in a different directories for optimized and debug builds, which prevents `debug` files from overwriting `opt` ones. Therefore, `--gem5-build-id` is not required.\n\nThe price to pay for debuggability is high however: a Linux kernel boot was about 3x slower in QEMU and 14 times slower in gem5 debug compared to opt, see benchmarks at: xref:benchmark-linux-kernel-boot[xrefstyle=full].\n\nSimilar slowdowns can be observed at: xref:benchmark-emulators-on-userland-executables[xrefstyle=full].\n\nWhen in <<qemu-text-mode>>, using `--debug-vm` makes Ctrl-C not get passed to the QEMU guest anymore: it is instead captured by GDB itself, so allow breaking. So e.g. you won't be able to easily quit from a guest program like:\n\n....\nsleep 10\n....\n\nIn graphic mode, make sure that you never click inside the QEMU graphic while debugging, otherwise you mouse gets captured forever, and the only solution I can find is to go to a TTY with `Ctrl-Alt-F1` and `kill` QEMU.\n\nYou can still send key presses to QEMU however even without the mouse capture, just either click on the title bar, or alt tab to give it focus.\n\n==== Reverse debug the emulator\n\nWhile step debugging any complex program, you always end up feeling the need to step in reverse to reach the last call to some function that was called before the failure point, in order to trace back the problem to the actual bug source.\n\nWhile GDB \"has\" this feature, it is just too broken to be usable, and so we expose the amazing Mozilla RR tool conveniently in this repo: https://stackoverflow.com/questions/1470434/how-does-reverse-debugging-work/53063242#53063242\n\nBefore the first usage setup rr with:\n\n....\necho 'kernel.perf_event_paranoid=1' | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p\n....\n\nThen use it with your content of interest, for example:\n\n....\n./run --debug-vm-rr --userland userland/c/hello.c\n....\n\nThis will:\n\n* first run the program once until completion or crash\n* then restart the program at the very first instruction at `_start` and leave you in a GDB shell\n\nFrom there, run the program until your point of interest, e.g.:\n\n....\nbreak qemu_add_opts\ncontinue\n....\n\nand you can now reliably use reverse debugging commands such as `reverse-continue`, `reverse-finish` and `reverse-next`!\n\nTo restart debugging again after quitting `rr`, simply run on your host terminal:\n\n....\nrr replay\n....\n\nThe use case of `rr` is often to go to the final crash and then walk back from there, so you often want to automate running until the end after record with `--debug-vm-args` as in:\n\n....\n./run --debug-vm-args='-ex continue' --debug-vm-rr --userland userland/c/hello.c\n....\n\nPrograms often tend to blow up in very low frames that use values passed in from higher frames. In those cases, remember that just like with forward debugging, you can't just go:\n\n....\nup\nup\nup\nreverse-next\n....\n\nbut rather, you must:\n\n....\nreverse-finish\nreverse-finish\nreverse-finish\nreverse-next\n....\n\n==== Debug gem5 Python scripts\n\nStart pdb at the first instruction:\n\n....\n./run --emulator gem5 --gem5-exe-args='--pdb' --terminal\n....\n\nRequires `--terminal` as we must be on foreground.\n\nAlternatively, you can add to the point of the code where you want to break the usual:\n\n....\nimport ipdb; ipdb.set_trace()\n....\n\nand then run with:\n\n....\n./run --emulator gem5 --terminal\n....\n\nTODO test PyCharm: https://stackoverflow.com/questions/51982735/writing-gem5-configuration-scripts-with-pycharm\n\n=== Tracing\n\nQEMU can log several different events.\n\nThe most interesting are events which show instructions that QEMU ran, for which we have a helper:\n\n....\n./trace-boot --arch x86_64\n....\n\nUnder the hood, this uses QEMU's `-trace` option.\n\nYou can then inspect the address of each instruction run:\n\n....\nless \"$(./getvar --arch x86_64 run_dir)/trace.txt\"\n....\n\nSample output excerpt:\n\n....\nexec_tb 0.000 pid=10692 tb=0x7fb4f8000040 pc=0xfffffff0\nexec_tb 35.391 pid=10692 tb=0x7fb4f8000180 pc=0xfe05b\nexec_tb 21.047 pid=10692 tb=0x7fb4f8000340 pc=0xfe066\nexec_tb 12.197 pid=10692 tb=0x7fb4f8000480 pc=0xfe06a\n....\n\nGet the list of available trace events:\n\n....\n./run --trace help\n....\n\nTODO: any way to show the actualy disassembled instruction executed directly from there? Possible with <<qemu-d-tracing>>.\n\nEnable other specific trace events:\n\n....\n./run --trace trace1,trace2\n./qemu-trace2txt -a \"$arch\"\nless \"$(./getvar -a \"$arch\" run_dir)/trace.txt\"\n....\n\nThis functionality relies on the following setup:\n\n* `./configure --enable-trace-backends=simple`. This logs in a binary format to the trace file.\n+\nIt makes 3x execution faster than the default trace backend which logs human readable data to stdout.\n+\nLogging with the default backend `log` greatly slows down the CPU, and in particular leads to this boot message:\n+\n....\nAll QSes seen, last rcu_sched kthread activity 5252 (4294901421-4294896169), jiffies_till_next_fqs=1, root ->qsmask 0x0\nswapper/0       R  running task        0     1      0 0x00000008\n ffff880007c03ef8 ffffffff8107aa5d ffff880007c16b40 ffffffff81a3b100\n ffff880007c03f60 ffffffff810a41d1 0000000000000000 0000000007c03f20\n fffffffffffffedc 0000000000000004 fffffffffffffedc ffffffff00000000\nCall Trace:\n <IRQ>  [<ffffffff8107aa5d>] sched_show_task+0xcd/0x130\n [<ffffffff810a41d1>] rcu_check_callbacks+0x871/0x880\n [<ffffffff810a799f>] update_process_times+0x2f/0x60\n....\n+\nin which the boot appears to hang for a considerable time.\n* patch  QEMU source to remove the `disable` from `exec_tb` in the `trace-events` file. See also: https://rwmj.wordpress.com/2016/03/17/tracing-qemu-guest-execution/\n\n==== QEMU -d tracing\n\nQEMU also has a second trace mechanism in addition to `-trace`, find out the events with:\n\n....\n./run -- -d help\n....\n\nLet's pick the one that dumps executed instructions, `in_asm`:\n\n....\n./run --eval './linux/poweroff.out' -- -D out/trace.txt -d in_asm\nless out/trace.txt\n....\n\nSample output excerpt:\n\n....\n----------------\nIN:\n0xfffffff0:  ea 5b e0 00 f0           ljmpw    $0xf000:$0xe05b\n\n----------------\nIN:\n0x000fe05b:  2e 66 83 3e 88 61 00     cmpl     $0, %cs:0x6188\n0x000fe062:  0f 85 7b f0              jne      0xd0e1\n....\n\nTODO: after `IN:`, symbol names are meant to show, which is awesome, but I don't get any. I do see them however when running a bare metal example from: https://github.com/cirosantilli/newlib-examples/tree/900a9725947b1f375323c7da54f69e8049158881\n\nTODO: what is the point of having two mechanisms, `-trace` and `-d`? `-d` tracing is cool because it does not require a messy recompile, and it can also show symbols.\n\n==== QEMU trace register values\n\nTODO: is it possible to show the register values for each instruction?\n\nThis would include the memory values read into the registers.\n\nAsked at: https://superuser.com/questions/1377764/how-to-trace-the-register-values-of-executed-instructions-in-qemu\n\nSeems impossible due to optimizations that QEMU does:\n\n* https://lists.gnu.org/archive/html/qemu-devel/2015-06/msg07479.html\n* https://lists.gnu.org/archive/html/qemu-devel/2014-04/msg02856.html\n* https://lists.gnu.org/archive/html/qemu-devel/2012-08/msg03057.html\n\nPANDA can list memory addresses, so I bet it can also decode the instructions: https://github.com/panda-re/panda/blob/883c85fa35f35e84a323ed3d464ff40030f06bd6/panda/docs/LINE_Censorship.md I wonder why they don't just upstream those things to QEMU's tracing: https://github.com/panda-re/panda/issues/290\n\ngem5 can do it as shown at: xref:gem5-tracing[xrefstyle=full].\n\n==== QEMU trace memory accesses\n\nNot possible apparently, not even with the `memory_region_ops_read` and `memory_region_ops_write` trace events, Peter comments https://lists.gnu.org/archive/html/qemu-devel/2015-06/msg07482.html\n\n____\nNo. You will miss all the fast-path memory accesses, which are\ndone with custom generated assembly in the TCG backend. In\ngeneral QEMU is not designed to support this kind of monitoring\nof guest operations.\n____\n\nRelated question: https://reverseengineering.stackexchange.com/questions/12260/how-to-log-all-memory-accesses-read-and-write-including-the-memory-content-in\n\n==== Trace source lines\n\nWe can further use Binutils' `addr2line` to get the line that corresponds to each address:\n\n....\n./trace-boot --arch x86_64\n./trace2line --arch x86_64\nless \"$(./getvar --arch x86_64 run_dir)/trace-lines.txt\"\n....\n\nThe last commands takes several seconds.\n\nThe format is as follows:\n\n....\n39368 _static_cpu_has arch/x86/include/asm/cpufeature.h:148\n....\n\nWhere:\n\n* `39368`: number of consecutive times that a line ran. Makes the output much shorter and more meaningful\n* `_static_cpu_has`: name of the function that contains the line\n* `arch/x86/include/asm/cpufeature.h:148`: file and line\n\nThis could of course all be done with GDB, but it would likely be too slow to be practical.\n\nTODO do even more awesome offline post-mortem analysis things, such as:\n\n* detect if we are in userspace or kernelspace. Should be a simple matter of reading the\n* read kernel data structures, and determine the current thread. Maybe we can reuse / extend the kernel's GDB Python scripts??\n\n==== QEMU record and replay\n\nQEMU runs, unlike gem5, are not deterministic by default, however it does support a record and replay mechanism that allows you to replay a previous run deterministically.\n\nThis awesome feature allows you to examine a single run as many times as you would like until you understand everything:\n\n....\n# Record a run.\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out;' --record\n# Replay the run.\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out;' --replay\n....\n\nA convenient shortcut to do both at once to test the feature is:\n\n....\n./qemu-rr --eval-after './linux/rand_check.out;./linux/poweroff.out;'\n....\n\nBy comparing the terminal output of both runs, we can see that they are the exact same, including things which normally differ across runs:\n\n* timestamps of dmesg output\n* <<rand-check-out>> output\n\nThe record and replay feature was revived around QEMU v3.0.0. In v5.2.0 it is quite usable, almost all peripherals and vCPUs are supported.\n\nDocumented at: https://github.com/qemu/qemu/blob/v5.2.0/docs/replay.txt\n\nreplay may be used with with network:\n\n....\n./qemu-rr --eval-after 'ifup -a;wget -S google.com;./linux/poweroff.out;'\n....\n\n`arm` and `aarch64` targets can also be used with rr:\n\n....\n./qemu-rr --arch aarch64 --eval-after './linux/rand_check.out;./linux/poweroff.out;'\n./qemu-rr --arch aarch64 --eval-after 'ifup -a;wget -S google.com;./linux/poweroff.out;'\n....\n\nReplay also supports <<initrd>> and no disk:\n\n....\n./build-buildroot --arch aarch64 --initrd\n./qemu-rr --arch aarch64 --eval-after './linux/rand_check.out;./linux/poweroff.out;' --initrd\n....\n\n===== QEMU reverse debugging\n\nQEMU replays support checkpointing, and this allows for a simplistic \"reverse debugging\" implementation since v5.2.0:\n\n....\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out;' --record\n./run --eval-after './linux/rand_check.out;./linux/poweroff.out;' --replay --gdb-wait\n....\n\nOn another shell:\n\n....\n./run-gdb start_kernel\n....\n\nIn GDB:\n\n....\nn\nn\nn\nn\nreverse-continue\n....\n\nand we are back at `start_kernel`\n\n`reverse-continue` proceeds to the latest of the earlier breakpoints or to the very beginning if there were no breakpoints before.\n\n==== QEMU trace multicore\n\nTODO: is there any way to distinguish which instruction runs on each core? Doing:\n\n....\n./run --arch x86_64 --cpus 2 --eval './linux/poweroff.out' --trace exec_tb\n./qemu-trace2txt\n....\n\njust appears to output both cores intertwined without any clear differentiation.\n\n==== QEMU get guest instruction count\n\nTODO: https://stackoverflow.com/questions/58766571/how-to-count-the-number-of-guest-instructions-qemu-executed-from-the-beginning-t\n\n==== gem5 tracing\n\ngem5 provides also provides a tracing mechanism documented at: http://www.gem5.org/Trace_Based_Debugging[]:\n\n....\n./run --arch aarch64 --eval 'm5 exit' --emulator gem5 --trace ExecAll\nless \"$(./getvar --arch aarch64 run_dir)/trace.txt\"\n....\n\nOur wrapper just forwards the options to the `--debug-flags` gem5 option.\n\nKeep in mind however that the disassembly is very broken in several places as of 2019q2, so you can't always trust it.\n\nOutput the trace to stdout instead of a file:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --eval 'm5 exit' \\\n  --trace ExecAll \\\n  --trace-stdout \\\n;\n....\n\nWe also have a shortcut for `--trace ExecAll -trace-stdout` with `--trace-insts-stdout`\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --eval 'm5 exit' \\\n  --trace-insts-stdout \\\n;\n....\n\nBe warned, the trace is humongous, at 16Gb.\n\nThis would produce a lot of output however, so you will likely not want that when tracing a Linux kernel boot instructions. But it can be very convenient for smaller traces such as <<baremetal>>.\n\nList all available debug flags:\n\n....\n./run --arch aarch64 --gem5-exe-args='--debug-help' --emulator gem5\n....\n\nbut to understand most of them you have to look at the source code:\n\n....\nless \"$(./getvar gem5_source_dir)/src/cpu/SConscript\"\nless \"$(./getvar gem5_source_dir)/src/cpu/exetrace.cc\"\n....\n\nThe most important trace flags to know about are:\n\n* <<gem5-execall-trace-format,`ExecAll`>>\n* `Faults`: CPU exceptions / interrupts, see an example at: <<arm-svc-instruction>>\n* <<gem5-registers-trace-format,`Registers`>>\n* <<gem5-syscall-emulation-mode-syscall-tracing,`SyscallBase`, `SyscallVerbose`>>\n\nTrace internals are discussed at: <<gem5-trace-internals>>.\n\nAs can be seen on the `Sconstruct`, `Exec` is just an alias that enables a set of flags.\n\nWe can make the trace smaller by naming the trace file as `trace.txt.gz`, which enables GZIP compression, but that is not currently exposed on our scripts, since you usually just need something human readable to work on.\n\nEnabling tracing made the runtime about 4x slower on the <<p51>>, with or without `.gz` compression.\n\nTrace the source lines just like <<trace-source-lines,for QEMU>> with:\n\n....\n./trace-boot --arch aarch64 --emulator gem5\n./trace2line --arch aarch64 --emulator gem5\nless \"$(./getvar --arch aarch64 run_dir)/trace-lines.txt\"\n....\n\nTODO: 7452d399290c9c1fc6366cdad129ef442f323564 `./trace2line` this is too slow and takes hours. QEMU's processing of 170k events takes 7 seconds. gem5's processing is analogous, but there are 140M events, so it should take 7000 seconds ~ 2 hours which seems consistent with what I observe, so maybe there is no way to speed this up... The workaround is to just use gem5's `ExecSymbol` to get function granularity, and then GDB individually if line detail is needed?\n\n===== gem5 trace internals\n\ngem5 traces are generated from `DPRINTF(<trace-id>` calls scattered throughout the code, except for `ExecAll` instruction traces, which uses `Debug::ExecEnable` directly..\n\nThe trace IDs are themselves encoded in `SConscript` files, e.g.:\n\n....\nDebugFlag('Event'\n....\n\nin `src/cpu/SConscript`.\n\nThe build system then automatically adds the options to the `--debug-flags`.\n\nFor this entry, the build system then generates a file `build/ARM/debug/ExecEnable.hh`, which contains:\n\n....\nnamespace Debug {\nclass SimpleFlag;\nextern SimpleFlag ExecEnable;\n}\n....\n\nand must be included in from callers of `DPRINTF(` as `<debug/ExecEnable.hh>`.\n\nTested in b4879ae5b0b6644e6836b0881e4da05c64a6550d.\n\n===== gem5 ExecAll trace format\n\nThis debug flag traces all instructions.\n\nThe output format is of type:\n\n....\n25007000: system.cpu T0 : @start_kernel    : stp\n25007000: system.cpu T0 : @start_kernel.0  :   addxi_uop   ureg0, sp, #-112 : IntAlu :  D=0xffffff8008913f90\n25007500: system.cpu T0 : @start_kernel.1  :   strxi_uop   x29, [ureg0] : MemWrite :  D=0x0000000000000000 A=0xffffff8008913f90\n25008000: system.cpu T0 : @start_kernel.2  :   strxi_uop   x30, [ureg0, #8] : MemWrite :  D=0x0000000000000000 A=0xffffff8008913f98\n25008500: system.cpu T0 : @start_kernel.3  :   addxi_uop   sp, ureg0, #0 : IntAlu :  D=0xffffff8008913f90\n....\n\nThere are two types of lines:\n\n* full instructions, as the first line. Only shown if the `ExecMacro` flag is given.\n* micro ops that constitute the instruction, the lines that follow. Yes, `aarch64` also has microops: https://superuser.com/questions/934752/do-arm-processors-like-cortex-a9-use-microcode/934755#934755[]. Only shown if the `ExecMicro` flag is given.\n\nBreakdown:\n\n* `25007500`: time count in some unit. Note how the microops execute at further timestamps.\n* `system.cpu`: distinguishes between CPUs when there are more than one. For example, running xref:arm-baremetal-multicore[xrefstyle=full] with two cores produces `system.cpu0` and `system.cpu1`\n* `T0`: thread number. TODO: https://superuser.com/questions/133082/hyper-threading-and-dual-core-whats-the-difference/995858#995858[hyperthread]? How to play with it?\n+\n`config`.ini has `--param 'system.multi_thread = True' --param 'system.cpu[0].numThreads = 2'`, but in <<arm-baremetal-multicore>> the first one alone does not produce `T1`, and with the second one simulation blows up with:\n+\n....\nfatal: fatal condition interrupts.size() != numThreads occurred: CPU system.cpu has 1 interrupt controllers, but is expecting one per thread (2)\n....\n* `@start_kernel`: we are in the `start_kernel` function. Awesome feature! Implemented with libelf https://sourceforge.net/projects/elftoolchain/ copy pasted in-tree `ext/libelf`. To get raw addresses, remove the `ExecSymbol`, which is enabled by `Exec`. This can be done with `Exec,-ExecSymbol`.\n* `.1` as in `@start_kernel.1`: index of the <<gem5-microops>>\n* `stp`: instruction disassembly. Note however that the disassembly of many instructions are very broken as of 2019q2, and you can't just trust them blindly.\n* `strxi_uop   x29, [ureg0]`: microop disassembly.\n* `MemWrite :  D=0x0000000000000000 A=0xffffff8008913f90`: a memory write microop:\n** `D` stands for data, and represents the value that was written to memory or to a register\n** `A` stands for address, and represents the address to which the value was written. It only shows when data is being written to memory, but not to registers.\n\nThe best way to verify all of this is to write some <<baremetal,baremetal code>>\n\n===== gem5 Registers trace format\n\nThis flag shows a more detailed register usage than <<gem5-execall-trace-format>>.\n\nFor example, if we run in LKMC 0323e81bff1d55b978a4b36b9701570b59b981eb:\n\n....\n./run --arch aarch64 --baremetal userland/arch/aarch64/add.S --emulator gem5 --trace ExecAll,Registers --trace-stdout\n....\n\nthen the stdout contains:\n\n....\n  31000: system.cpu A0 T0 : @main_after_prologue    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n  31500: system.cpu.[tid:0]: Setting int reg 34 (34) to 0.\n  31500: system.cpu.[tid:0]: Reading int reg 0 (0) as 0x1.\n  31500: system.cpu.[tid:0]: Setting int reg 1 (1) to 0x3.\n  31500: system.cpu A0 T0 : @main_after_prologue+4    :   add   x1, x0, #2         : IntAlu :  D=0x0000000000000003  flags=(IsInteger)\n  32000: system.cpu.[tid:0]: Setting int reg 34 (34) to 0.\n  32000: system.cpu.[tid:0]: Reading int reg 1 (1) as 0x3.\n  32000: system.cpu.[tid:0]: Reading int reg 31 (34) as 0.\n  32000: system.cpu.[tid:0]: Setting int reg 0 (0) to 0x3.\n....\n\nwhich corresponds to the two following instructions:\n\n....\nmov x0, 1\nadd x1, x0, 2\n....\n\nTODO that format is either buggy or is very difficult to understand:\n\n* what is `34`? Presumably some flags register?\n* what do the numbers in parenthesis mean at `31 (34)`? Presumably some flags register?\n* why is the first instruction setting `reg 1` and the second one `reg 0`, given that the first sets `x0` and the second `x1`?\n\n===== gem5 TARMAC traces\n\nhttps://stackoverflow.com/questions/54882466/how-to-use-the-tarmac-tracer-with-gem5\n\n===== gem5 tracing internals\n\nAs of gem5 16eeee5356585441a49d05c78abc328ef09f7ace the default tracer is `ExeTracer`. It is set at:\n\n....\nsrc/cpu/BaseCPU.py:63:default_tracer = ExeTracer()\n....\n\nwhich then gets used at:\n\n....\nclass BaseCPU(ClockedObject):\n    [...]\n    tracer = Param.InstTracer(default_tracer, \"Instruction tracer\")\n....\n\nAll tracers derive from the common `InstTracer` base class:\n\n....\ngit grep ': InstTracer'\n....\n\ngives:\n\n....\nsrc/arch/arm/tracers/tarmac_parser.hh:218:    TarmacParser(const Params *p) : InstTracer(p), startPc(p->start_pc),\nsrc/arch/arm/tracers/tarmac_tracer.cc:57:  : InstTracer(p),\nsrc/cpu/exetrace.hh:67:    ExeTracer(const Params *params) : InstTracer(params)\nsrc/cpu/inst_pb_trace.cc:72:    : InstTracer(p), buf(nullptr), bufSize(0), curMsg(nullptr)\nsrc/cpu/inteltrace.hh:63:    IntelTrace(const IntelTraceParams *p) : InstTracer(p)\n....\n\nAs mentioned at <<gem5-tarmac-traces>>, there appears to be no way to select those currently without hacking the config scripts.\n\nTARMAC is described at: <<gem5-tarmac-traces>>.\n\nTODO: are `IntelTrace` and `TarmacParser` useful for anything or just relics?\n\nThen there is also the `NativeTrace` class:\n\n....\nsrc/cpu/nativetrace.hh:68:class NativeTrace : public ExeTracer\n....\n\nwhich gets implemented in a few different ISAs, but not all:\n\n....\nsrc/arch/arm/nativetrace.hh:40:class ArmNativeTrace : public NativeTrace\nsrc/arch/sparc/nativetrace.hh:41:class SparcNativeTrace : public NativeTrace\nsrc/arch/x86/nativetrace.hh:41:class X86NativeTrace : public NativeTrace\n....\n\nTODO: I can't find any usages of those classes from in-tree configs.\n\n=== QEMU GUI is unresponsive\n\nSometimes in Ubuntu 14.04, after the QEMU SDL GUI starts, it does not get updated after keyboard strokes, and there are artifacts like disappearing text.\n\nWe have not managed to track this problem down yet, but the following workaround always works:\n\n....\nCtrl-Shift-U\nCtrl-C\nroot\n....\n\nThis started happening when we switched to building QEMU through Buildroot, and has not been observed on later Ubuntu.\n\nUsing text mode is another workaround if you don't need GUI features.\n\n== gem5\n\nGetting started at: xref:gem5-buildroot-setup[xrefstyle=full].\n\ngem5 has a bunch of crappiness, mostly described at: <<gem5-vs-qemu>>, but it does deserve some credit on the following points:\n\n* insanely configurable system topology from Python without recompiling, made possible in part due to a well defined memory packet structure that allows adding caches and buses transparently\n* each micro architectural model (<<gem5-cpu-types>>) works with all ISAs\n\n=== gem5 vs QEMU\n\n* advantages of gem5:\n** simulates a generic more realistic <<gem5-cpu-types,optionally pipelined and out-of-order>> CPU cycle by cycle, including a realistic DRAM memory access model with latencies, caches and page table manipulations. This allows us to:\n+\n--\n*** do much more realistic performance benchmarking with it, which makes absolutely no sense in QEMU, which is purely functional\n*** make certain functional observations that are not possible in QEMU, e.g.:\n**** use Linux kernel APIs that flush cache memory like DMA, which are crucial for driver development. In QEMU, the driver would still work even if we forget to flush caches.\n**** spectre / meltdown:\n***** https://www.mail-archive.com/gem5-users@gem5.org/msg15319.html\n***** https://github.com/jlpresearch/gem5/tree/spectre-test\n--\n+\nIt is not of course truly cycle accurate, as that:\n+\n--\n** would require exposing proprietary information of the CPU designs: https://stackoverflow.com/questions/17454955/can-you-check-performance-of-a-program-running-with-qemu-simulator/33580850#33580850[]\n** would make the simulation even slower TODO confirm, by how much\n--\n+\nbut the approximation is reasonable.\n+\nIt is used mostly for microarchitecture research purposes: when you are making a new chip technology, you don't really need to specialize enormously to an existing microarchitecture, but rather develop something that will work with a wide range of future architectures.\n** runs are deterministic by default, unlike QEMU which has a special <<qemu-record-and-replay>> mode, that requires first playing the content once and then replaying\n** gem5 ARM at least appears to implement more low level CPU functionality than QEMU, e.g. QEMU only added EL2 in 2018: https://stackoverflow.com/questions/42824706/qemu-system-aarch64-entering-el1-when-emulating-a53-power-up See also: xref:arm-exception-levels[xrefstyle=full]\n** gem5 offers more advanced logging, even for non micro architectural things which QEMU models in some way, e.g. <<qemu-trace-memory-accesses>>, because QEMU's binary translation optimizations reduce visibility\n* disadvantages of gem5:\n** slower than QEMU, see: xref:benchmark-linux-kernel-boot[xrefstyle=full]\n+\nThis implies that the user base is much smaller, since no Android devs.\n+\nInstead, we have only chip makers, who keep everything that really works closed, and researchers, who can't version track or document code properly >:-) And this implies that:\n+\n--\n*** the documentation is more scarce\n*** it takes longer to support new hardware features\n--\n+\nWell, not that AOSP is that much better anyway.\n** not sure: gem5 has BSD license while QEMU has GPL\n+\nThis suits chip makers that want to distribute forks with secret IP to their customers.\n+\nOn the other hand, the chip makers tend to upstream less, and the project becomes more crappy in average :-)\n** gem5 is way more complex and harder to modify and maintain\n+\nThe only hairy thing in QEMU is the binary code generation.\n+\ngem5 however has tended towards horrendous intensive <<gem5-code-generation,code generation>> in order to support all its different hardware types\n+\ngem5 also has a complex Python interface which is also largely auto-generated, which greatly increases the maintenance complexity of the project: <<embedding-python-in-another-application>>.\n+\nThis is done so that reconfiguring platforms can be done quickly without recompiling, and it is amazing when it works, but the maintenance costs are also very high. For example, <<pybind11>> of several trivial `param_` files accounted for 50% of the build time at one point: <<pybind11-accounts-for-50-of-gem5-build-time>>.\n+\nAll of this also makes it hard to setup an IDE for developing gem5: <<gem5-eclipse-configuration>>\n+\nThe feelings of helplessness this brings are well summarized by the following CSDN article https://blog.csdn.net/maokelong95/article/details/85333905:\n+\n____\nFound DPRINTF based debugging unable to meet your needs?\n\nFound GDB based debugging unfriendly to human beings?\n\nWant to debug gem5 source with the help of modern IDEs like Eclipse?\n\nFailed in getting help from GEM5 community?\n\nCome on, dude! Here is the up-to-date tutorial for you!\n\nJust be ready for THE ENDLESS NIGHTMARE gem5 will bring!\n____\n\n=== gem5 run benchmark\n\nOK, this is why we used gem5 in the first place, performance measurements!\n\nLet's see how many cycles dhrystone, which Buildroot provides, takes for a few different input parameters.\n\nWe will do that for various input parameters on full system by taking a checkpoint after the boot finishes a fast atomic CPU boot, and then we will restore in a more detailed mode and run the benchmark:\n\n....\n./build-buildroot --config 'BR2_PACKAGE_DHRYSTONE=y'\n# Boot fast, take checkpoint, and exit.\n./run --arch aarch64 --emulator gem5 --eval-after './gem5.sh'\n\n# Restore the checkpoint after boot, and benchmark with input 1000.\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --eval-after './gem5.sh' \\\n  --gem5-readfile 'm5 resetstats;dhrystone 1000;m5 dumpstats' \\\n  --gem5-restore 1 \\\n  -- \\\n  --cpu-type=HPI \\\n  --restore-with-cpu=HPI \\\n  --caches \\\n  --l2cache \\\n  --l1d_size=64kB \\\n  --l1i_size=64kB \\\n  --l2_size=256kB \\\n;\n# Get the value for number of cycles.\n# head because there are two lines: our dumpstats and the\n# automatic dumpstats at the end which we don't care about.\n./gem5-stat --arch aarch64 | head -n 1\n\n# Now for input 10000.\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --eval-after './gem5.sh' \\\n  --gem5-readfile 'm5 resetstats;dhrystone 10000;m5 dumpstats' \\\n  --gem5-restore 1 \\\n  -- \\\n  --cpu-type=HPI \\\n  --restore-with-cpu=HPI \\\n  --caches \\\n  --l2cache \\\n  --l1d_size=64kB \\\n  --l1i_size=64kB \\\n  --l2_size=256kB \\\n;\n./gem5-stat --arch aarch64 | head -n 1\n....\n\nIf you ever need a shell to quickly inspect the system state after boot, you can just use:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --eval-after './gem5.sh' \\\n  --gem5-readfile 'sh' \\\n  --gem5-restore 1 \\\n....\n\nThis procedure is further automated and DRYed up at:\n\n....\n./gem5-bench-dhrystone\ncat out/gem5-bench-dhrystone.txt\n....\n\nSource: link:gem5-bench-dhrystone[]\n\nOutput at 2438410c25e200d9766c8c65773ee7469b599e4a + 1:\n\n....\nn cycles\n1000 13665219\n10000 20559002\n100000 85977065\n....\n\nso as expected, the Dhrystone run with a larger input parameter `100000` took more cycles than the ones with smaller input parameters.\n\nThe `gem5-stats` commands output the approximate number of CPU cycles it took Dhrystone to run.\n\nA more naive and simpler to understand approach would be a direct:\n\n....\n./run --arch aarch64 --emulator gem5 --eval 'm5 checkpoint;m5 resetstats;dhrystone 10000;m5 exit'\n....\n\nbut the problem is that this method does not allow to easily run a different script without running the boot again. The `./gem5.sh` script works around that by using <<m5-readfile>> as explained further at: xref:gem5-restore-new-script[xrefstyle=full].\n\nNow you can play a fun little game with your friends:\n\n* pick a computational problem\n* make a program that solves the computation problem, and outputs output to stdout\n* write the code that runs the correct computation in the smallest number of cycles possible\n\nInteresting algorithms and benchmarks for this game are being collected at:\n\n* <<algorithms>>\n* <<benchmarks>>\n\nTo find out why your program is slow, a good first step is to have a look at the <<gem5-m5out-stats-txt-file>>.\n\n==== Skip extra benchmark instructions\n\nA few imperfections of our <<gem5-run-benchmark,benchmarking method>> are:\n\n* when we do `m5 resetstats` and `m5 exit`, there is some time passed before the `exec` system call returns and the actual benchmark starts and ends\n* the benchmark outputs to stdout, which means so extra cycles in addition to the actual computation. But TODO: how to get the output to check that it is correct without such IO cycles?\n\nSolutions to these problems include:\n\n* modify benchmark code with instrumentation directly, see <<m5ops-instructions>> for an example.\n* monitor known addresses TODO possible? Create an example.\n\nDiscussion at: https://stackoverflow.com/questions/48944587/how-to-count-the-number-of-cpu-clock-cycles-between-the-start-and-end-of-a-bench/48944588#48944588\n\nThose problems should be insignificant if the benchmark runs for long enough however.\n\n=== gem5 system parameters\n\nBesides optimizing a program for a given CPU setup, chip developers can also do the inverse, and optimize the chip for a given benchmark!\n\nThe rabbit hole is likely deep, but let's scratch a bit of the surface.\n\n==== Number of cores\n\n....\n./run --arch arm --cpus 2 --emulator gem5\n....\n\nCan be checked with `/proc/cpuinfo` or <<sysconf,getconf>> in Ubuntu 18.04:\n\n....\ncat /proc/cpuinfo\ngetconf _NPROCESSORS_CONF\n....\n\nOr from <<user-mode-simulation>>, we can use either of:\n\n* <<sysconf>> with link:userland/linux/sysconf.c[]\n+\n....\n./run --cpus 2 --emulator gem5 --userland userland/linux/sysconf.c | grep _SC_NPROCESSORS_ONLN\n....\n* <<cpp-multithreading>>'s link:userland/cpp/thread_hardware_concurrency.cpp[]:\n+\n....\n./run --cpus 2 --emulator gem5 --userland userland/cpp/thread_hardware_concurrency.cpp\n....\n* direct access to several special filesystem files that contain this information e.g. via link:userland/c/cat.c[]:\n+\n....\n./run --cpus 2 --emulator gem5 --userland userland/c/cat.c --cli-args /proc/cpuinfo\n....\n\n===== QEMU user mode multithreading\n\n<<user-mode-simulation>> QEMU v4.0.0 always shows the number of cores of the host, presumably because the thread switching uses host threads directly which would make that harder to implement.\n\nIt does not seem possible to make the guest see a different number of cores than what the host has. Full system does have the `-smp` options, which controls this.\n\nE.g., all of of the following output the same as `nproc` on the host:\n\n....\nnproc\n./run --cpus 1 --userland userland/cpp/thread_hardware_concurrency.cpp\n./run --cpus 2 --userland userland/cpp/thread_hardware_concurrency.cpp\n....\n\nThis random page suggests that QEMU splits one host thread thread per guest thread, and thus presumably delegates context switching to the host kernel: https://qemu.weilnetz.de/w64/2012/2012-12-04/qemu-tech.html#User-emulation-specific-details\n\nWe can confirm that with:\n\n....\n./run --userland userland/posix/pthread_count.c --cli-args 4\nps Haux | grep qemu | wc\n....\n\nRemember <<qemu-user-mode-does-not-show-stdout-immediately>> though.\n\nAt 369a47fc6e5c2f4a7f911c1c058b6088f8824463 + 1 QEMU appears to spawn 3 host threads plus one for every new guest thread created. Remember that link:userland/posix/pthread_count.c[] spawns N + 1 total threads if you count the `main` thread.\n\n===== gem5 ARM full system with more than 8 cores\n\nhttps://stackoverflow.com/questions/50248067/how-to-run-a-gem5-arm-aarch64-full-system-simulation-with-fs-py-with-more-than-8\n\nWith <<arm-gic,GICv3>>, tested at LKMC 224fae82e1a79d9551b941b19196c7e337663f22 gem5 3ca404da175a66e0b958165ad75eb5f54cb5e772 on vanilla kernel:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --cpus 16 \\\n  -- \\\n  --machine-type VExpress_GEM5_V2 \\\n;\n....\n\nboots to a shell and `nproc` shows `16`.\n\nFor the GICv2 extension method, build the kernel with the <<gem5-arm-linux-kernel-patches>>, and then run:\n\n....\n./run \\\n  --arch aarch64 \\\n  --linux-build-id gem5-v4.15 \\\n  --emulator gem5 \\\n  --cpus 16 \\\n  -- \\\n  --param 'system.realview.gic.gem5_extensions = True' \\\n;\n....\n\nTested in LKMC 788087c6f409b84adf3cff7ac050fa37df6d4c46. It fails after boot with `FATAL: kernel too old` as mentioned at: <<gem5-arm-linux-kernel-patches>> but everything seems to work on the gem5 side of things.\n\n==== gem5 cache size\n\nhttps://stackoverflow.com/questions/49624061/how-to-run-gem5-simulator-in-fs-mode-without-cache/49634544#49634544\n\nA quick `+./run --emulator gem5 -- -h+` leads us to the options:\n\n....\n--caches\n--l1d_size=1024\n--l1i_size=1024\n--l2cache\n--l2_size=1024\n--l3_size=1024\n....\n\nBut keep in mind that it only affects benchmark performance of the most detailed CPU types as shown at: xref:table-gem5-cache-cpu-type[xrefstyle=full].\n\n[[table-gem5-cache-cpu-type]]\n.gem5 cache support in function of CPU type\n[options=\"header\"]\n|===\n|arch |CPU type |caches used\n\n|X86\n|`AtomicSimpleCPU`\n|no\n\n|X86\n|`DerivO3CPU`\n|?*\n\n|ARM\n|`AtomicSimpleCPU`\n|no\n\n|ARM\n|`HPI`\n|yes\n\n|===\n\n{empty}*: couldn't test because of:\n\n* https://stackoverflow.com/questions/49011096/how-to-switch-cpu-models-in-gem5-after-restoring-a-checkpoint-and-then-observe-t\n\nCache sizes can in theory be checked with the methods described at: https://superuser.com/questions/55776/finding-l2-cache-size-in-linux[]:\n\n....\nlscpu\ncat /sys/devices/system/cpu/cpu0/cache/index2/size\n....\n\nand on Ubuntu 20.04 host <<sysconf,but not Buildroot 1.31.1>>:\n\n....\ngetconf -a | grep CACHE\n....\n\nand we also have an easy to use userland executable using <<sysconf>> at link:userland/linux/sysconf.c[]:\n\n....\n./run --emulator gem5 --userland userland/linux/sysconf.c\n....\n\nbut for some reason the Linux kernel is not seeing the cache sizes:\n\n* https://stackoverflow.com/questions/49008792/why-doesnt-the-linux-kernel-see-the-cache-sizes-in-the-gem5-emulator-in-full-sy\n* http://gem5-users.gem5.narkive.com/4xVBlf3c/verify-cache-configuration\n\nBehaviour breakdown:\n\n* arm QEMU and gem5 (both `AtomicSimpleCPU` or `HPI`), x86 gem5: `/sys` files don't exist, and `getconf` and `lscpu` value empty\n* x86 QEMU: `/sys` files exist, but `getconf` and `lscpu` values still empty\n\nThe only precise option is therefore to look at <<gem5-config-ini>> as done at: <<gem5-event-queue-timingsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches>>.\n\nOr for a quick and dirty performance measurement approach instead:\n\n....\n./gem5-bench-cache -- --arch aarch64\ncat \"$(./getvar --arch aarch64 run_dir)/bench-cache.txt\"\n....\n\nwhich gives:\n\n....\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 1000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024   --l1i_size=1024   --l2_size=1024   --l3_size=1024   --cpu-type=HPI --restore-with-cpu=HPI\ntime 23.82\nexit_status 0\ncycles 93284622\ninstructions 4393457\n\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 1000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024kB --l1i_size=1024kB --l2_size=1024kB --l3_size=1024kB --cpu-type=HPI --restore-with-cpu=HPI\ntime 14.91\nexit_status 0\ncycles 10128985\ninstructions 4211458\n\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 10000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024   --l1i_size=1024   --l2_size=1024   --l3_size=1024   --cpu-type=HPI --restore-with-cpu=HPI\ntime 51.87\nexit_status 0\ncycles 188803630\ninstructions 12401336\n\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 10000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024kB --l1i_size=1024kB --l2_size=1024kB --l3_size=1024kB --cpu-type=HPI --restore-with-cpu=HPI\ntime 35.35\nexit_status 0\ncycles 20715757\ninstructions 12192527\n\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 100000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024   --l1i_size=1024   --l2_size=1024   --l3_size=1024   --cpu-type=HPI --restore-with-cpu=HPI\ntime 339.07\nexit_status 0\ncycles 1176559936\ninstructions 94222791\n\ncmd ./run --emulator gem5 --arch aarch64 --gem5-readfile \"dhrystone 100000\" --gem5-restore 1 -- --caches --l2cache --l1d_size=1024kB --l1i_size=1024kB --l2_size=1024kB --l3_size=1024kB --cpu-type=HPI --restore-with-cpu=HPI\ntime 240.37\nexit_status 0\ncycles 125666679\ninstructions 91738770\n....\n\nWe make the following conclusions:\n\n* the number of instructions almost does not change: the CPU is waiting for memory all the extra time. TODO: why does it change at all?\n* the wall clock execution time is not directionally proportional to the number of cycles: here we had a 10x cycle increase, but only 2x time increase. This suggests that the simulation of cycles in which the CPU is waiting for memory to come back is faster.\n\n==== gem5 DRAM model\n\nSome info at: <<timingsimplecpu-analysis-1>> but highly TODO :-)\n\n===== gem5 memory latency\n\nTODO These look promising:\n\n....\n--list-mem-types\n--mem-type=MEM_TYPE\n--mem-channels=MEM_CHANNELS\n--mem-ranks=MEM_RANKS\n--mem-size=MEM_SIZE\n....\n\nTODO: now to verify this with the Linux kernel? Besides raw performance benchmarks.\n\nNow for a raw simplistic benchmark on <<gem5-timingsimplecpu,`TimingSimpleCPU`>> without caches via <<c-busy-loop>>:\n\n....\n./run --arch aarch64 --cli-args 1000000 --emulator gem5 --userland userland/gcc/busy_loop.c -- --cpu-type TimingSimpleCPU\n....\n\nLKMC eb22fd3b6e7fff7e9ef946a88b208debf5b419d5 gem5 872cb227fdc0b4d60acc7840889d567a6936b6e1 outputs:\n\n....\nExiting @ tick 897173931000 because exiting with last active thread context\n....\n\nand now because:\n\n* we have no caches, each instruction is fetched from memory\n* each loop contains 11 instructions as shown at xref:c-busy-loop[xrefstyle=full]\n* and supposing that the loop dominated executable pre/post `main`, which we know is true since as shown in <<benchmark-emulators-on-userland-executables>> an empty dynamically linked C program only as about 100k instructions, while our loop runs 1000000 * 11 = 12M.\n\nwe should have about 1000000 * 11 / 897173931000 ps ~ 12260722 ~ 12MB/s of random accesses. The default memory type used is `DDR3_1600_8x8` as per:\n\n....\ncommon/Options.py:101:    parser.add_option(\"--mem-type\", type=\"choice\", default=\"DDR3_1600_8x8\n....\n\nand according to https://en.wikipedia.org/wiki/DDR3_SDRAM that reaches 6400 MB/s so we are only off by a factor of 50x :-) TODO. Maybe if the minimum transaction if 64 bytes, we would be on point.\n\nAnother example we could use later on is link:userland/gcc/busy_loop.c[], but then that mixes icache and dcache accesses, so the analysis is a bit more complex:\n\n....\n./run --arch aarch64 --cli-args 0x1000000 --emulator gem5 --userland userland/gcc/busy_loop.c -- --cpu-type TimingSimpleCPU\n....\n\n===== Memory size\n\nCan be set across emulators with:\n\n....\n./run --memory 512M\n....\n\nWe can verify this on the guest directly from the kernel with:\n\n....\ncat /proc/meminfo\n....\n\nas of LKMC 1e969e832f66cb5a72d12d57c53fb09e9721d589 this output contains:\n\n....\nMemTotal:         498472 kB\n....\n\nwhich we expand with:\n\n....\nprintf '0x%X\\n' $((498472 * 1024))\n....\n\nto:\n\n....\n0x1E6CA000\n....\n\nTODO: why is this value a bit smaller than 512M?\n\n`free` also gives the same result:\n\n....\nfree -b\n....\n\ncontains:\n\n....\n             total       used       free     shared    buffers     cached\nMem:     510435328   20385792  490049536          0     503808    2760704\n-/+ buffers/cache:   17121280  493314048\nSwap:            0          0          0\n....\n\nwhich we expand with:\n\n....\nprintf '0x%X\\n' 510435328$((498472 * 1024)\n....\n\n`man free` from Ubuntu's procps 3.3.15 tells us that `free` obtains this information from `/proc/meminfo` as well.\n\nFrom C, we can get this information with `sysconf(_SC_PHYS_PAGES)` or `get_phys_pages()`:\n\n....\n./linux/total_memory.out\n....\n\nSource: link:userland/linux/total_memory.c[]\n\nOutput:\n\n....\nsysconf(_SC_PHYS_PAGES) * sysconf(_SC_PAGESIZE) = 0x1E6CA000\nsysconf(_SC_AVPHYS_PAGES) * sysconf(_SC_PAGESIZE) = 0x1D178000\nget_phys_pages() * sysconf(_SC_PAGESIZE) = 0x1E6CA000\nget_avphys_pages() * sysconf(_SC_PAGESIZE) = 0x1D178000\n....\n\nThis is mentioned at: https://stackoverflow.com/questions/22670257/getting-ram-size-in-c-linux-non-precise-result/22670407#22670407\n\nAV means available and gives the free memory: https://stackoverflow.com/questions/14386856/c-check-available-ram/57659190#57659190\n\n===== gem5 DRAM setup\n\nThis can be explored pretty well from <<gem5-config-ini>>.\n\nse.py just has a single `DDR3_1600_8x8` DRAM with size given as <<memory-size>> and physical address starting at 0.\n\nfs.py also has that `DDR3_1600_8x8` DRAM, but can have more memory types. Notably, aarch64 has as shown on RealView.py `VExpress_GEM5_Base`:\n\n....\n0x00000000-0x03ffffff: (  0     -  64 MiB) Boot memory (CS0)\n0x04000000-0x07ffffff: ( 64 MiB - 128 MiB) Reserved\n0x08000000-0x0bffffff: (128 MiB - 192 MiB) NOR FLASH0 (CS0 alias)\n0x0c000000-0x0fffffff: (192 MiB - 256 MiB) NOR FLASH1 (Off-chip, CS4)\n0x80000000-XxXXXXXXXX: (  2 GiB -        ) DRAM\n....\n\nWe place the entry point of our baremetal executables right at the start of DRAM with our <<baremetal-linker-script>>.\n\nThis can be seen indirectly with:\n\n....\n./getvar --arch aarch64 --emulator gem5 entry_address\n....\n\nwhich gives 0x80000000 in decimal, or more directly with some some <<gem5-tracing>>:\n\n....\n./run \\\n  --arch aarch64 \\\n  --baremetal baremetal/arch/aarch64/no_bootloader/exit.S \\\n  --emulator gem5 \\\n  --trace ExecAll,-ExecSymbol \\\n  --trace-stdout \\\n;\n....\n\nand we see that the first instruction runs at 0x80000000:\n\n....\n      0: system.cpu: A0 T0 : 0x80000000\n....\n\nTODO: what are the boot memory and NOR FLASH used for?\n\n==== gem5 disk and network latency\n\nTODO These look promising:\n\n....\n--ethernet-linkspeed\n--ethernet-linkdelay\n....\n\nand also: `gem5-dist`: https://publish.illinois.edu/icsl-pdgem5/\n\n==== gem5 clock frequency\n\nAs of gem5 872cb227fdc0b4d60acc7840889d567a6936b6e1 defaults to 2GHz for fs.py:\n\n....\n    parser.add_option(\"--cpu-clock\", action=\"store\", type=\"string\",\n                      default='2GHz',\n                      help=\"Clock for blocks running at CPU speed\")\n....\n\nWe can check that very easily by looking at the timestamps of a <<gem5-execall-trace-format,Exec trace>> of an <<gem5-atomicsimplecpu>> without any caches:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --trace-insts-stdout \\\n;\n....\n\nwhich shows:\n\n....\n      0: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n    500: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   adr   x1, #28            : IntAlu :  D=0x0000000000400098  flags=(IsInteger)\n   1000: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   ldr   w2, #4194464       : MemRead :  D=0x0000000000000006 A=0x4000a0  flags=(IsInteger|IsMemRef|IsLoad)\n   1500: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x8, #64, #0       : IntAlu :  D=0x0000000000000040  flags=(IsInteger)\n   2000: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\nhello\n   2500: system.cpu: A0 T0 : @asm_main_after_prologue+20    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   3000: system.cpu: A0 T0 : @asm_main_after_prologue+24    :   movz   x8, #93, #0       : IntAlu :  D=0x000000000000005d  flags=(IsInteger)\n   3500: system.cpu: A0 T0 : @asm_main_after_prologue+28    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n....\n\nso we see that it runs one instruction every 500 ps which makes up 2GHz.\n\nSo if we change the frequency to say 1GHz and re-run it:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --trace-insts-stdout \\\n  -- \\\n  --cpu-clock 1GHz \\\n;\n....\n\nwe get as expected:\n\n....\n      0: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n   1000: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   adr   x1, #28            : IntAlu :  D=0x0000000000400098  flags=(IsInteger)\n   2000: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   ldr   w2, #4194464       : MemRead :  D=0x0000000000000006 A=0x4000a0  flags=(IsInteger|IsMemRef|IsLoad)\n   3000: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x8, #64, #0       : IntAlu :  D=0x0000000000000040  flags=(IsInteger)\n   4000: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\nhello\n   5000: system.cpu: A0 T0 : @asm_main_after_prologue+20    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   6000: system.cpu: A0 T0 : @asm_main_after_prologue+24    :   movz   x8, #93, #0       : IntAlu :  D=0x000000000000005d  flags=(IsInteger)\n   7000: system.cpu: A0 T0 : @asm_main_after_prologue+28    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n....\n\nAs of gem5 872cb227fdc0b4d60acc7840889d567a6936b6e1, but like <<gem5-cache-size>>, does not get propagated to the guest, and is not for example visible at:\n\n....\nls /sys/devices/system/cpu/cpu0/cpufreq\n....\n\n=== gem5 kernel command line parameters\n\nAnalogous <<kernel-command-line-parameters,to QEMU>>:\n\n....\n./run --arch arm --kernel-cli 'init=/lkmc/linux/poweroff.out' --emulator gem5\n....\n\nInternals: when we give `--command-line=` to gem5, it overrides default command lines, including some mandatory ones which are required to boot properly.\n\nOur run script hardcodes the require options in the default `--command-line` and appends extra options given by `-e`.\n\nTo find the default options in the first place, we removed `--command-line` and ran:\n\n....\n./run --arch arm --emulator gem5\n....\n\nand then looked at the line of the Linux kernel that starts with:\n\n....\nKernel command line:\n....\n\n[[gem5-gdb]]\n=== gem5 GDB step debug\n\n==== gem5 GDB step debug kernel\nAnalogous <<gdb,to QEMU>>, on the first shell:\n\n....\n./run --arch arm --emulator gem5 --gdb-wait\n....\n\nOn the second shell:\n\n....\n./run-gdb --arch arm --emulator gem5\n....\n\nOn a third shell:\n\n....\n./gem5-shell\n....\n\nWhen you want to break, just do a `Ctrl-C` on GDB shell, and then `continue`.\n\nAnd we now see the boot messages, and then get a shell. Now try the `./count.sh` procedure described for QEMU at: xref:gdb-step-debug-kernel-post-boot[xrefstyle=full].\n\n==== gem5 GDB step debug userland process\n\nWe are unable to use `gdbserver` because of networking as mentioned at: xref:gem5-host-to-guest-networking[xrefstyle=full]\n\nThe alternative is to do as in <<gdb-step-debug-userland-processes>>.\n\nNext, follow the exact same steps explained at <<gdb-step-debug-userland-non-init-without-gdb-wait>>, but passing `--emulator gem5` to every command as usual.\n\nBut then TODO (I'll still go crazy one of those days): for `arm`, while debugging `./linux/myinsmod.out hello.ko`, after then line:\n\n....\n23     if (argc < 3) {\n24         params = \"\";\n....\n\nI press `n`, it just runs the program until the end, instead of stopping on the next line of execution. The module does get inserted normally.\n\nTODO:\n\n....\n./run-gdb --arch arm --emulator gem5 --userland gem5-1.0/gem5/util/m5/m5 main\n....\n\nbreaks when `m5` is run on guest, but does not show the source code.\n\n==== gem5 GDB step debug secondary cores\n\ngem5's secondary core GDB setup is a hack and spawns one gdbserver for each core in separate ports, e.g. 7000, 7001, etc.\n\nPartly because of this, it is basically unusable/very hard to use, because you can't attach to a core that is stopped either because it hasn't been initialized, or if you are already currently debugging another core.\n\nThis affects both full system and <<gdb-step-debug-multicore-userland,userland>>, and is described in more detail at: https://gem5.atlassian.net/browse/GEM5-626\n\nIn LKMC 0a3ce2f41f12024930bcdc74ff646b66dfc46999, we can easily test attaching to another core by passing `--run-id`, e.g. to connect to the second core we can use `--run-id 1`:\n\n....\n./run-gdb --arch aarch64 --emulator gem5 --userland userland/gcc/busy_loop.c --run-id 1\n....\n\n=== gem5 checkpoint\n\nAnalogous to QEMU's <<snapshot>>, but better since it can be started from inside the guest, so we can easily checkpoint after a specific guest event, e.g. just before `init` is done.\n\nDocumentation: http://gem5.org/Checkpoints\n\nTo see it in action try:\n\n....\n./run --arch aarch64 --emulator gem5\n....\n\nIn the guest, wait for the boot to end and run:\n\n....\nm5 checkpoint\n....\n\nwhere <<gem5-m5-executable>> is a guest utility present inside the gem5 tree which we cross-compiled and installed into the guest.\n\nTo restore the checkpoint, kill the VM and run:\n\n....\n./run --arch arm --emulator gem5 --gem5-restore 1\n....\n\nThe `--gem5-restore` option restores the checkpoint that was created most recently.\n\nLet's create a second checkpoint to see how it works, in guest:\n\n....\ndate >f\nm5 checkpoint\n....\n\nKill the VM, and try it out:\n\n....\n./run --arch arm --emulator gem5 --gem5-restore 1\n....\n\nHere we use `--gem5-restore 1` again, since the second snapshot we took is now the most recent one\n\nNow in the guest:\n\n....\ncat f\n....\n\ncontains the `date`. The file `f` wouldn't exist had we used the first checkpoint with `--gem5-restore 2`, which is the second most recent snapshot taken.\n\nIf you automate things with <<kernel-command-line-parameters>> as in:\n\n....\n./run --arch arm --eval 'm5 checkpoint;m5 resetstats;dhrystone 1000;m5 exit' --emulator gem5\n....\n\nThen there is no need to pass the kernel command line again to gem5 for replay:\n\n....\n./run --arch arm --emulator gem5 --gem5-restore 1\n....\n\nsince boot has already happened, and the parameters are already in the RAM of the snapshot.\n\n==== gem5 checkpoint userland minimal example\n\nIn order to debug checkpoint restore bugs, this minimal setup using link:userland/freestanding/gem5_checkpoint.S[] can be handy:\n\n....\n./build-userland --arch aarch64 --static\n./run --arch aarch64 --emulator gem5 --static --userland userland/freestanding/gem5_checkpoint.S --trace-insts-stdout\n./run --arch aarch64 --emulator gem5 --static --userland userland/freestanding/gem5_checkpoint.S --trace-insts-stdout --gem5-restore 1\n./run --arch aarch64 --emulator gem5 --static --userland userland/freestanding/gem5_checkpoint.S --trace-insts-stdout --gem5-restore 1 -- --cpu-type=DerivO3CPU --restore-with-cpu=DerivO3CPU --caches\n....\n\nOn the initial run, we see that all instructions are executed and the checkpoint is taken:\n\n....\n      0: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n    500: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   movz   x1, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   1000: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   m5checkpoint             : IntAlu :   flags=(IsInteger|IsNonSpeculative|IsUnverifiable)\nWriting checkpoint\nwarn: Checkpoints for file descriptors currently do not work.\ninfo: Entering event queue @ 1000.  Starting simulation...\n   1500: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   2000: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   m5exit                   : No_OpClass :   flags=(IsInteger|IsNonSpeculative)\nExiting @ tick 2000 because m5_exit instruction encountered\n....\n\nThen, on the first restore run, the checkpoint is restored, and only instructions after the checkpoint are executed:\n\n....\ninfo: Entering event queue @ 1000.  Starting simulation...\n   1500: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   2000: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   m5exit                   : No_OpClass :   flags=(IsInteger|IsNonSpeculative)\nExiting @ tick 2000 because m5_exit instruction encountered\n....\n\nand a similar thing happens for the <<gem5-restore-checkpoint-with-a-different-cpu,restore with a different CPU type>>:\n\n....\ninfo: Entering event queue @ 1000.  Starting simulation...\n  79000: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  FetchSeq=1  CPSeq=1  flags=(IsInteger)\nExiting @ tick 84500 because m5_exit instruction encountered\n....\n\nHere we don't see the last `m5 exit` instruction on the log, but it must just be something to do with the O3 logging.\n\n==== gem5 checkpoint internals\n\nA quick way to get a <<gem5-syscall-emulation-mode>> or full system checkpoint to observe is:\n\n....\n./run --arch aarch64 --emulator gem5 --baremetal userland/freestanding/gem5_checkpoint.S --trace-insts-stdout\n./run --arch aarch64 --emulator gem5 --userland userland/freestanding/gem5_checkpoint.S --trace-insts-stdout\n....\n\nCheckpoints are stored inside the <<m5out-directory>> at:\n\n....\n\"$(./getvar --emulator gem5 m5out_dir)/cpt.<checkpoint-time>\"\n....\n\nwhere `<checkpoint-time>` is the cycle number at which the checkpoint was taken.\n\n`fs.py` exposes the `-r N` flag to restore checkpoints, which N-th checkpoint with the largest `<checkpoint-time>`: https://github.com/gem5/gem5/blob/e02ec0c24d56bce4a0d8636a340e15cd223d1930/configs/common/Simulation.py#L118\n\nHowever, that interface is bad because if you had taken previous checkpoints, you have no idea what `N` to use, unless you memorize which checkpoint was taken at which cycle.\n\nTherefore, just use our superior `--gem5-restore` flag, which uses directory timestamps to determine which checkpoint you created most recently.\n\nThe `-r N` integer value is just pure `fs.py` sugar, the backend at `m5.instantiate` just takes the actual tracepoint directory path as input.\n\nThe file `m5out/cpt.1000/m5.cpt` contains almost everything in the checkpoint except memory.\n\nIt is a https://docs.python.org/3/library/configparser.html[Python configparser compatible file] with a section structure that matches the <<gem5-python-c-interaction,SimObject>> tree e.g.:\n\n....\n[system.cpu.itb.walker.power_state]\ncurrState=0\nprvEvalTick=0\n....\n\nWhen a checkpoint is taken, each `SimObject` calls its overridden `serialize` method to generate the checkpoint, and when loading, `unserialize` is called.\n\n[[gem5-restore-new-script]]\n==== gem5 checkpoint restore and run a different script\n\nYou want to automate running several tests from a single pristine post-boot state.\n\nThe problem is that boot takes forever, and after the checkpoint, the memory and disk states are fixed, so you can't for example:\n\n* hack up an existing rc script, since the disk is fixed\n* inject new kernel boot command line options, since those have already been put into memory by the bootloader\n\nThere is however a few loopholes, <<m5-readfile>> being the simplest, as it reads whatever is present on the host.\n\nSo we can do it like:\n\n....\n# Boot, checkpoint and exit.\nprintf 'echo \"setup run\";m5 exit' > \"$(./getvar gem5_readfile_file)\"\n./run --emulator gem5 --eval 'm5 checkpoint;m5 readfile > /tmp/gem5.sh && sh /tmp/gem5.sh'\n\n# Restore and run the first benchmark.\nprintf 'echo \"first benchmark\";m5 exit' > \"$(./getvar gem5_readfile_file)\"\n./run --emulator gem5 --gem5-restore 1\n\n# Restore and run the second benchmark.\nprintf 'echo \"second benchmark\";m5 exit' > \"$(./getvar gem5_readfile_file)\"\n./run --emulator gem5 --gem5-restore 1\n\n# If something weird happened, create an interactive shell to examine the system.\nprintf 'sh' > \"$(./getvar gem5_readfile_file)\"\n./run --emulator gem5 --gem5-restore 1\n....\n\nSince this is such a common setup, we provide the following helpers for this operation:\n\n* `./run --gem5-readfile` is a convenient way to set the `m5 readfile` file contents from a string in the command line, e.g.:\n+\n....\n# Boot, checkpoint and exit.\n./run --emulator gem5 --eval './gem5.sh' --gem5-readfile 'echo \"setup run\"'\n\n# Restore and run the first benchmark.\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"first benchmark\"'\n\n# Restore and run the second benchmark.\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"second benchmark\"'\n....\n* link:rootfs_overlay/lkmc/gem5.sh[]. This script is analogous to gem5's in-tree https://github.com/gem5/gem5/blob/2b4b94d0556c2d03172ebff63f7fc502c3c26ff8/configs/boot/hack_back_ckpt.rcS[hack_back_ckpt.rcS], but with less noise.\n+\nUsage:\n+\n....\n# Boot, checkpoint and exit.\n./run --emulator gem5 --eval './gem5.sh' --gem5-readfile 'echo \"setup run\"'\n\n# Restore and run the first benchmark.\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"first benchmark\"'\n\n# Restore and run the second benchmark.\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"second benchmark\"'\n....\n\nTheir usage is also exemplified at <<gem5-run-benchmark>>.\n\nIf you forgot to use an appropriate `--eval` for your boot and the simulation is already running, link:rootfs_overlay/lkmc/gem5.sh[] can be used directly from an interactive guest shell.\n\nFirst we reset the readfile to something that runs quickly:\n\n....\nprintf 'echo \"first benchmark\"' > \"$(./getvar gem5_readfile_file)\"\n....\n\nand then in the guest, take a checkpoint and exit with:\n\n....\n./gem5.sh\n....\n\nNow the guest is in a state where readfile will be executed automatically without interactive intervention:\n\n....\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"first benchmark\"'\n./run --emulator gem5 --gem5-restore 1 --gem5-readfile 'echo \"second benchmark\"'\n....\n\nOther loophole possibilities to execute different benchmarks non-interactively include:\n\n* <<9p>>\n* <<secondary-disk>>\n* `expect` as mentioned at: https://stackoverflow.com/questions/7013137/automating-telnet-session-using-bash-scripts\n+\n....\n#!/usr/bin/expect\nspawn telnet localhost 3456\nexpect \"# $\"\nsend \"pwd\\r\"\nsend \"ls /\\r\"\nsend \"m5 exit\\r\"\nexpect eof\n....\n+\nThis is ugly however as it is not deterministic.\n\nhttps://www.mail-archive.com/gem5-users@gem5.org/msg15233.html\n\n==== gem5 restore checkpoint with a different CPU\n\ngem5 can switch to a different CPU model when restoring a checkpoint.\n\nA common combo is to boot Linux with a fast CPU, make a checkpoint and then replay the benchmark of interest with a slower CPU.\n\nThis can be observed interactively in full system with:\n\n....\n./run --arch aarch64 --emulator gem5\n....\n\nThen in the guest terminal after boot ends:\n\n....\nsh -c 'm5 checkpoint;sh'\nm5 exit\n....\n\nAnd then restore the checkpoint with a different slower CPU:\n\n....\n./run --arch arm --emulator gem5 --gem5-restore 1 -- --caches --cpu-type=DerivO3CPU\n....\n\nAnd now you will notice that everything happens much slower in the guest terminal!\n\nOne even more direct and minimal way to observe this is with link:userland/freestanding/gem5_checkpoint.S[] which was mentioned at <<gem5-checkpoint-userland-minimal-example>> plus some logging:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --static \\\n  --trace ExecAll,FmtFlag,O3CPU,SimpleCPU \\\n  --userland userland/freestanding/gem5_checkpoint.S \\\n;\ncat \"$(./getvar --arch aarch64 --emulator gem5 trace_txt_file)\"\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --gem5-restore 1 \\\n  --static \\\n  --trace ExecAll,FmtFlag,O3CPU,SimpleCPU \\\n  --userland userland/freestanding/gem5_checkpoint.S \\\n  -- \\\n  --caches \\\n  --cpu-type DerivO3CPU \\\n  --restore-with-cpu DerivO3CPU \\\n;\ncat \"$(./getvar --arch aarch64 --emulator gem5 trace_txt_file)\"\n....\n\nAt gem5 2235168b72537535d74c645a70a85479801e0651, the first run does everything in <<gem5-atomicsimplecpu,AtomicSimpleCPU>>:\n\n....\n...\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1f92 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e40 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e30 WriteReq\n      0: SimpleCPU: system.cpu: Tick\n      0: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n    500: SimpleCPU: system.cpu: Tick\n    500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   movz   x1, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   1000: SimpleCPU: system.cpu: Tick\n   1000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   m5checkpoint             : IntAlu :   flags=(IsInteger|IsNonSpeculative|IsUnverifiable)\n   1000: SimpleCPU: system.cpu: Resume\n   1500: SimpleCPU: system.cpu: Tick\n   1500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   2000: SimpleCPU: system.cpu: Tick\n   2000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   m5exit                   : No_OpClass :   flags=(IsInteger|IsNonSpeculative)\n....\n\nand after restore we see as expected a single `ExecEnable` instruction executed amidst `O3CPU` noise:\n\n....\nFullO3CPU: Ticking main, FullO3CPU.\n  79000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  FetchSeq=1  CPSeq=1  flags=(IsInteger)\n  82500: O3CPU: system.cpu: Removing committed instruction [tid:0] PC (0x400084=>0x400088).(0=>1) [sn:1]\n  82500: O3CPU: system.cpu: Removing instruction, [tid:0] [sn:1] PC (0x400084=>0x400088).(0=>1)\n  82500: O3CPU: system.cpu: Scheduling next tick!\n  83000: O3CPU: system.cpu:\n....\n\nwhich is the `movz` after the checkpoint. The final `m5exit` does not appear due to DerivO3CPU logging insanity.\n\nBibliography:\n\n* https://stackoverflow.com/questions/60876259/which-system-characteristics-such-as-number-of-cores-of-cache-configurations-can\n* https://stackoverflow.com/questions/49011096/how-to-switch-cpu-models-in-gem5-after-restoring-a-checkpoint-and-then-observe-t\n\n===== gem5 fast forward\n\nBesides switching CPUs after a checkpoint restore, fs.py also has the `--fast-forward` option to automatically run the script from the start on a less detailed CPU, and switch to a more detailed CPU at a given tick.\n\nThis is generally useless compared to checkpoint restoring because:\n\n* checkpoint restore allows to run multiple contents after the restore, and restoring to multiple different system states, which you almost always want to do\n* we generally don't know the exact tick at which the region of interest will start, especially as the binaries change. It is much easier to just instrument the content with a checkoint <<m5ops,m5op>>\n\nBut let's give it a try anyway with link:userland/freestanding/gem5_checkpoint.S[] which was mentioned at <<gem5-checkpoint-userland-minimal-example>>\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --static \\\n  --trace ExecAll,FmtFlag,O3CPU,SimpleCPU \\\n  --userland userland/freestanding/gem5_checkpoint.S \\\n  -- \\\n  --caches\n  --cpu-type DerivO3CPU \\\n  --fast-forward 1000 \\\n;\ncat \"$(./getvar --arch aarch64 --emulator gem5 trace_txt_file)\"\n....\n\nAt gem5 2235168b72537535d74c645a70a85479801e0651 we see something like:\n\n....\n      0: O3CPU: system.switch_cpus: Creating O3CPU object.\n      0: O3CPU: system.switch_cpus: Workload[0] process is 0      0: SimpleCPU: system.cpu: ActivateContext 0\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x40 WriteReq\n...\n\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1f92 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e40 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e30 WriteReq\n      0: SimpleCPU: system.cpu: Tick\n      0: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n    500: SimpleCPU: system.cpu: Tick\n    500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   movz   x1, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   1000: SimpleCPU: system.cpu: Tick\n   1000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   m5checkpoint             : IntAlu :   flags=(IsInteger|IsNonSpeculative|IsUnverifiable)\n   1000: O3CPU: system.switch_cpus: [tid:0] Calling activate thread.\n   1000: O3CPU: system.switch_cpus: [tid:0] Adding to active threads list\n   1500: O3CPU: system.switch_cpus:\n\nFullO3CPU: Ticking main, FullO3CPU.\n   1500: O3CPU: system.switch_cpus: Scheduling next tick!\n   2000: O3CPU: system.switch_cpus:\n\nFullO3CPU: Ticking main, FullO3CPU.\n   2000: O3CPU: system.switch_cpus: Scheduling next tick!\n   2500: O3CPU: system.switch_cpus:\n\n...\n\nFullO3CPU: Ticking main, FullO3CPU.\n  44500: ExecEnable: system.switch_cpus: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x00000000000\n  48000: O3CPU: system.switch_cpus: Removing committed instruction [tid:0] PC (0x400084=>0x400088).(0=>1) [sn:1]\n  48000: O3CPU: system.switch_cpus: Removing instruction, [tid:0] [sn:1] PC (0x400084=>0x400088).(0=>1)\n  48000: O3CPU: system.switch_cpus: Scheduling next tick!\n  48500: O3CPU: system.switch_cpus:\n\n...\n....\n\nWe can also compare that to the same log but without `--fast-forward` and other CPU switch options:\n\n....\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e40 WriteReq\n      0: SimpleCPU: system.cpu.dcache_port: received snoop pkt for addr:0x1e30 WriteReq\n      0: SimpleCPU: system.cpu: Tick\n      0: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n    500: SimpleCPU: system.cpu: Tick\n    500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   movz   x1, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   1000: SimpleCPU: system.cpu: Tick\n   1000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   m5checkpoint             : IntAlu :   flags=(IsInteger|IsNonSpeculative|IsUnverifiable)\n   1000: SimpleCPU: system.cpu: Resume\n   1500: SimpleCPU: system.cpu: Tick\n   1500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   2000: SimpleCPU: system.cpu: Tick\n   2000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   m5exit                   : No_OpClass :   flags=(IsInteger|IsNonSpeculative)\n....\n\nTherefore, it is clear that what we wanted happen:\n\n* up until the tick 1000, `SimpleCPU` was ticking\n* after tick 1000, cpu `O3CPU` started ticking\n\nBibliography:\n\n* https://cs.stackexchange.com/questions/69511/what-does-fast-forwarding-mean-in-the-context-of-cpu-simulation\n\n==== gem5 checkpoint upgrader\n\nThe in-tree `util/cpt_upgrader.py` is a tool to upgrade checkpoints taken from an older version of gem5 to be compatible with the newest version, so you can update gem5 without having to re-run the simulation that generated the checkpoints.\n\nFor example, whenever a <<arm-system-register-instructions,system register is added in ARMv8>>, old checkpoints break unless upgraded.\n\nUnfortunately, since the process is not very automated (automatable?), and requires manually patching the upgrader every time a new breaking change is done, the upgrader tends to break soon if you try to move many versions of gem5 ahead as of 2020. This is evidenced in bug reports such as this one: https://gem5.atlassian.net/browse/GEM5-472\n\nThe script can be used as:\n\n....\nutil/cpt_upgrader.py m5out/cpt.1000/m5.cpt\n....\n\nThis updates the `m5.cpt` file in-place, and a `m5out/cpt.1000/m5.cpt.bak` is generated as a backup of the old file.\n\nThe upgrader determines which upgrades are needed by checking the `version_tags` entry of the checkpoint:\n\n....\n[Globals]\nversion_tags=arm-ccregs arm-contextidr-el2 arm-gem5-gic-ext ...\n....\n\nEach of those tags corresponds to a Python file under `util/cpt_upgraders/` e.g. `util/cpt_upgraders/arm-ccregs.py`.\n\n=== Pass extra options to gem5\n\nRemember that in the gem5 command line, we can either pass options to the script being run as in:\n\n....\nbuild/X86/gem5.opt configs/examples/fs.py --some-option\n....\n\nor to the gem5 executable itself:\n\n....\nbuild/X86/gem5.opt --some-option configs/examples/fs.py\n....\n\nPass options to the script in our setup use:\n\n* get help:\n+\n....\n./run --emulator gem5 -- -h\n....\n* boot with the more detailed and slow `HPI` CPU model:\n+\n....\n./run --arch arm --emulator gem5 -- --caches --cpu-type=HPI\n....\n\nTo pass options to the `gem5` executable we expose the `--gem5-exe-args` option:\n\n* get help:\n+\n....\n./run --gem5-exe-args='-h' --emulator gem5\n....\n\n=== m5ops\n\nm5ops are magic instructions which lead gem5 to do magic things, like quitting or dumping stats.\n\nDocumentation: http://gem5.org/M5ops\n\nThere are two main ways to use m5ops:\n\n* <<gem5-m5-executable>>\n* <<m5ops-instructions>>\n\n`m5` is convenient if you only want to take snapshots before or after the benchmark, without altering its source code. It uses the <<m5ops-instructions>> as its backend.\n\n`m5` cannot should / should not be used however:\n\n* in bare metal setups\n* when you want to call the instructions from inside interest points of your benchmark. Otherwise you add the syscall overhead to the benchmark, which is more intrusive and might affect results.\n+\nWhy not just hardcode some <<m5ops-instructions>> as in our example instead, since you are going to modify the source of the benchmark anyway?\n\n==== gem5 m5 executable\n\n`m5` is a guest command line utility that is installed and run on the guest, that serves as a CLI front-end for the <<m5ops>>\n\nIts source is present in the gem5 tree: https://github.com/gem5/gem5/blob/6925bf55005c118dc2580ba83e0fa10b31839ef9/util/m5/m5.c\n\nIt is possible to guess what most tools do from the corresponding <<m5ops>>, but let's at least document the less obvious ones here.\n\nIn LKMC we build `m5` with:\n\n....\n./build-m5 --arch aarch64\n....\n\nThe `m5` executable can be run on <<user-mode-simulation>> as normal with:\n\n....\n./run --arch aarch64 --emulator gem5 --userland \"$(./getvar --arch aarch64 out_rootfs_overlay_bin_dir)/m5\" --cli-args dumpstats\n....\n\nThis can be a good test <<m5ops>> since it executes very quickly.\n\n===== m5 exit\n\nEnd the simulation.\n\nSane Python scripts will exit gem5 with status 0, which is what `fs.py` does.\n\n===== m5 dumpstats\n\nMakes gem5 dump one more statistics entry to the <<gem5-m5out-stats-txt-file>>.\n\n===== m5 fail\n\nEnd the simulation with a failure exit event:\n\n....\nm5 fail 1\n....\n\nSane Python scripts would use that as the exit status of gem5, which would be useful for testing purposes, but `fs.py` at 200281b08ca21f0d2678e23063f088960d3c0819 just prints an error message:\n\n....\nSimulated exit code not 0! Exit code is 1\n....\n\nand exits with status 0.\n\nWe then parse that string ourselves in link:run[] and exit with the correct status...\n\nTODO: it used to be like that, but it actually got changed to just print the message. Why? https://gem5-review.googlesource.com/c/public/gem5/+/4880\n\n`m5 fail` is just a superset of `m5 exit`, which is just:\n\n....\nm5 fail 0\n....\n\nas can be seen from the source: https://github.com/gem5/gem5/blob/50a57c0376c02c912a978c4443dd58caebe0f173/src/sim/pseudo_inst.cc#L303\n\n===== m5 writefile\n\nSend a guest file to the host. <<9p>> is a more advanced alternative.\n\nGuest:\n\n....\necho mycontent > myfileguest\nm5 writefile myfileguest myfilehost\n....\n\nHost:\n\n....\ncat \"$(./getvar --arch aarch64 --emulator gem5 m5out_dir)/myfilehost\"\n....\n\nDoes not work for subdirectories, gem5 crashes:\n\n....\nm5 writefile myfileguest mydirhost/myfilehost\n....\n\n===== m5 readfile\n\nRead a host file pointed to by the `fs.py --script` option to stdout.\n\nhttps://stackoverflow.com/questions/49516399/how-to-use-m5-readfile-and-m5-execfile-in-gem5/49538051#49538051\n\nHost:\n\n....\ndate > \"$(./getvar gem5_readfile_file)\"\n....\n\nGuest:\n\n....\nm5 readfile\n....\n\nOutcome: date shows on guest.\n\n===== m5 initparam\n\nErmm, just another <<m5-readfile>> that only takes integers and only from CLI options? Is this software so redundant?\n\nHost:\n\n....\n./run --emulator gem5 --gem5-restore 1 -- --initparam 13\n./run --emulator gem5 --gem5-restore 1 -- --initparam 42\n....\n\nGuest:\n\n....\nm5 initparm\n....\n\nOutputs the given paramter.\n\n===== m5 execfile\n\nTrivial combination of `m5 readfile` + execute the script.\n\nHost:\n\n....\nprintf '#!/bin/sh\necho asdf\n' > \"$(./getvar gem5_readfile_file)\"\n....\n\nGuest:\n\n....\ntouch /tmp/execfile\nchmod +x /tmp/execfile\nm5 execfile\n....\n\nOutcome:\n\n....\nadsf\n....\n\n==== m5ops instructions\n\nThere are few different possible instructions that can be used to implement identical m5ops:\n\n* magic instructions reserved in the encoding space\n* magic addresses: <<m5ops-magic-addresses>>\n* unused <<semihosting>> addresses space on ARM platforms\n\nAll of those those methods are exposed through the <<gem5-m5-executable>> in-tree executable. You can select which method to use when calling the executable, e.g.:\n\n....\nm5 exit\n# Same as the above.\nm5 --inst exit\n# The address is mandatory if not configured at build time.\nm5 --addr 0x10010000 exit\nm5 --semi exit\n....\n\nTo make things simpler to understand, you can play around with our own minimized educational `m5` subset:\n\n* link:userland/c/m5ops.c[]\n* link:userland/cpp/m5ops.cpp[]\n\nThe instructions used by `./c/m5ops.out` are present in link:lkmc/m5ops.h[] in a very simple to understand and reuse inline assembly form.\n\nTo use that file, first rebuild `m5ops.out` with the m5ops instructions enabled and install it on the root filesystem:\n\n....\n./build-userland \\\n  --arch aarch64 \\\n  --force-rebuild \\\n  userland/c/m5ops.c \\\n;\n./build-buildroot --arch aarch64\n....\n\nWe don't enable `-DLKMC_M5OPS_ENABLE=1` by default on userland executables because we try to use a single image for both gem5, QEMU and <<userland-setup-getting-started-natively,native>>, and those instructions would break the latter two. We enable it in the <<baremetal-setup>> by default since we already have different images for QEMU and gem5 there.\n\nThen, from inside <<gem5-buildroot-setup>>, test it out with:\n\n....\n# checkpoint\n./c/m5ops.out c\n\n# dumpstats\n./c/m5ops.out d\n\n# exit\n./c/m5ops.out e\n\n# dump resetstats\n./c/m5ops.out r\n....\n\nIn theory, the cleanest way to add m5ops to your benchmarks would be to do exactly what the `m5` tool does:\n\n* include https://github.com/gem5/gem5/blob/05c4c2b566ce351ab217b2bd7035562aa7a76570/include/gem5/asm/generic/m5ops.h[`include/gem5/asm/generic/m5ops.h`]\n* link with the `.o` file under `util/m5` for the correct arch, e.g. `m5op_arm_A64.o` for aarch64.\n\nHowever, I think it is usually not worth the trouble of hacking up the build system of the benchmark to do this, and I recommend just hardcoding in a few raw instructions here and there, and managing it with version control + `sed`.\n\nBibliography:\n\n* https://stackoverflow.com/questions/63488050/what-are-pseudo-instructions-for-in-gem5/63489417#63489417\n* https://stackoverflow.com/questions/62757008/how-to-use-m5-in-gem5-20/62759204#62759204\n* https://stackoverflow.com/questions/56506154/how-to-analyze-only-interest-area-in-source-code-by-using-gem5/56506419#56506419\n* https://www.mail-archive.com/gem5-users@gem5.org/msg15418.html\n\n===== m5ops magic addresses\n\nThese are magic addresses that when accessed lead to an <<m5ops,m5op>>.\n\nThe base address is given by `system.m5ops_base`, and then each m5op happens at a different address offset form that base.\n\nIf `system.m5ops_base` is 0, then the memory m5ops are disabled.\n\nNote that the address is physical, and therefore when running in full system on top of the Linux kernel, you must first map a virtual to physical address with `/dev/mem` as mentioned at: <<userland-physical-address-experiments>>.\n\nOne advantage of this method is that it can work with <<gem5-kvm>>, whereas the magic instructions don't, since the host cannot handle them and it is hard to hook into that.\n\nA <<baremetal>> example of that can be found at: link:baremetal/arch/aarch64/no_bootloader/m5_exit_addr.S[].\n\nAs of gem5 0d5a80cb469f515b95e03f23ddaf70c9fd2ecbf2, `fs.py --baremetal` disables the memory m5ops however for some reason, therefore you should run that program as:\n\n....\n./run --arch aarch64 --baremetal baremetal/arch/aarch64/no_bootloader/m5_exit_addr.S --emulator gem5 --trace-insts-stdout -- --param 'system.m5ops_base=0x10010000'\n....\n\nTODO failing with:\n\n....\ninfo: Entering event queue @ 0.  Starting simulation...\nfatal: Unable to find destination for [0x10012100:0x10012108] on system.iobus\n....\n\n===== m5ops instructions interface\n\nLet's study how the <<gem5-m5-executable>> uses them:\n\n* https://github.com/gem5/gem5/blob/05c4c2b566ce351ab217b2bd7035562aa7a76570/include/gem5/asm/generic/m5ops.h[`include/gem5/asm/generic/m5ops.h`]: defines the magic constants that represent the instructions\n* https://github.com/gem5/gem5/blob/05c4c2b566ce351ab217b2bd7035562aa7a76570/util/m5/m5op_arm_A64.S[`util/m5/m5op_arm_A64.S`]: use the magic constants that represent the instructions using C preprocessor magic\n* https://github.com/gem5/gem5/blob/05c4c2b566ce351ab217b2bd7035562aa7a76570/util/m5/m5.c[`util/m5/m5.c`]: the actual executable. Gets linked to `m5op_arm_A64.S` which defines a function for each m5op.\n\nWe notice that there are two different implementations for each arch:\n\n* magic instructions, which don't exist in the corresponding arch\n* magic memory addresses on a given page: <<m5ops-magic-addresses>>\n\nThen, in aarch64 magic instructions for example, the lines:\n\n....\n.macro  m5op_func, name, func, subfunc\n        .globl \\name\n        \\name:\n        .long 0xff000110 | (\\func << 16) | (\\subfunc << 12)\n        ret\n....\n\ndefine a simple function function for each m5op. Here we see that:\n\n* `0xff000110` is a base mask for the magic non-existing instruction\n* `\\func` and `\\subfunc` are OR-applied on top of the base mask, and define m5op this is.\n+\nThose values will loop over the magic constants defined in `m5ops.h` with the deferred preprocessor idiom.\n+\nFor example, `exit` is `0x21` due to:\n+\n....\n#define M5OP_EXIT               0x21\n....\n\nFinally, `m5.c` calls the defined functions as in:\n\n....\nm5_exit(ints[0]);\n....\n\nTherefore, the runtime \"argument\" that gets passed to the instruction, e.g. the delay in ticks until the exit for `m5 exit`, gets passed directly through the https://en.wikipedia.org/wiki/Calling_convention#ARM_(A64)[aarch64 calling convention].\n\nKeep in mind that for all archs, `m5.c` does the calls with 64-bit integers:\n\n....\nuint64_t ints[2] = {0,0};\nparse_int_args(argc, argv, ints, argc);\nm5_fail(ints[1], ints[0]);\n....\n\nTherefore, for example:\n\n* aarch64 uses `x0` for the first argument and `x1` for the second, since each is 64 bits log already\n* arm uses `r0` and `r1` for the first argument, and `r2` and `r3` for the second, since each register is only 32 bits long\n\nThat convention specifies that `x0` to `x7` contain the function arguments, so `x0` contains the first argument, and `x1` the second.\n\nIn our `m5ops` example, we just hardcode everything in the assembly one-liners we are producing.\n\nWe ignore the `\\subfunc` since it is always 0 on the ops that interest us.\n\n===== m5op annotations\n\n`include/gem5/asm/generic/m5ops.h` also describes some annotation instructions.\n\nWhat they mean: https://stackoverflow.com/questions/50583962/what-are-the-gem5-annotations-mops-magic-instructions-and-how-to-use-them\n\n=== gem5 arm Linux kernel patches\n\nhttps://gem5.googlesource.com/arm/linux/ contains an ARM Linux kernel forks with a few gem5 specific Linux kernel patches on top of mainline created by ARM Holdings on top of a few upstream kernel releases.\n\nOur link:build[] script automatically adds that remote for us as `gem5-arm`.\n\nThe patches are optional: the vanilla kernel does boot. But they add some interesting gem5-specific optimizations, instrumentations and device support.\n\nThe patches also <<notable-alternate-gem5-kernel-configs,add defconfigs>> that are known to work well with gem5.\n\nE.g. for arm v4.9 there is: https://gem5.googlesource.com/arm/linux/+/917e007a4150d26a0aa95e4f5353ba72753669c7/arch/arm/configs/gem5_defconfig[].\n\nIn order to use those patches and their associated configs, and, we recommend using <<linux-kernel-build-variants>> as:\n\n....\ngit -C \"$(./getvar linux_source_dir)\" fetch gem5-arm:gem5/v4.15\ngit -C \"$(./getvar linux_source_dir)\" checkout gem5/v4.15\n./build-linux \\\n  --arch aarch64 \\\n  --custom-config-file-gem5 \\\n  --linux-build-id gem5-v4.15 \\\n;\ngit -C \"$(./getvar linux_source_dir)\" checkout -\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --linux-build-id gem5-v4.15 \\\n;\n....\n\nQEMU also boots that kernel successfully:\n\n....\n./run \\\n  --arch aarch64 \\\n  --linux-build-id gem5-v4.15 \\\n;\n....\n\nbut glibc kernel version checks make init fail with:\n\n....\nFATAL: kernel too old\n....\n\nbecause glibc was built to expect a newer Linux kernel as shown at: xref:fatal-kernel-too-old-failure-in-userland-simulation[xrefstyle=full]. Your choices to solve this are:\n\n* see if there is a more recent gem5 kernel available, or port your patch of interest to the newest kernel\n* modify this repo to use <<libc-choice,uClibc>>, which is not hard because of Buildroot\n* patch glibc to remove that check, which is easy because glibc is in a submodule of this repo\n\nIt is obviously not possible to understand what the Linux kernel fork commits actually do from their commit message, so let's explain them one by one here as we understand them:\n\n* `drm: Add component-aware simple encoder` allows you to see images through VNC, see: xref:gem5-graphic-mode[xrefstyle=full]\n* `gem5: Add support for gem5's extended GIC mode` adds support for more than 8 cores, see: xref:gem5-arm-full-system-with-more-than-8-cores[xrefstyle=full]\n\nTested on 649d06d6758cefd080d04dc47fd6a5a26a620874 + 1.\n\n==== gem5 arm Linux kernel patches boot speedup\n\nWe have observed that with the kernel patches, boot is 2x faster, falling from 1m40s to 50s.\n\nWith https://stackoverflow.com/questions/49797246/how-to-monitor-for-how-much-time-each-line-of-stdout-was-the-last-output-line-in/49797547#49797547[`ts`], we see that a large part of the difference is at the message:\n\n....\nclocksource: Switched to clocksource arch_sys_counter\n....\n\nwhich takes 4s on the patched kernel, and 30s on the unpatched one! TODO understand why, especially if it is a config difference, or if it actually comes from a patch.\n\n=== m5out directory\n\nWhen you run gem5, it generates an `m5out` directory at:\n\n....\necho $(./getvar --arch arm --emulator gem5 m5out_dir)\"\n....\n\nThe location of that directory can be set with `./gem5.opt -d`, and defaults to `./m5out`.\n\nThe files in that directory contains some very important information about the run, and you should become familiar with every one of them.\n\n[[gem5-m5out-system-terminal-file]]\n==== gem5 m5out/system.terminal file\n\nContains UART output, both from the Linux kernel or from the baremetal system.\n\nCan also be seen live on <<m5term>>.\n\n[[gem5-m5out-system-dmesg-file]]\n==== gem5 `m5out/system.workload.dmesg` file\n\nThis file used to be called just `m5out/system.dmesg`, but the name was changed after the workload refactorings of March 2020.\n\nThis file is capable of showing terminal messages that are `printk` before the serial is enabled as described at: <<linux-kernel-early-boot-messages>>.\n\nThe file is dumped only on kernel panics which gem5 can detect by the PC address: <<exit-gem5-on-panic>>.\n\nThis mechanism can be very useful to debug the Linux kernel boot if problems happen before the serial is enabled.\n\nThis magic mechanism works by activating an event when the PC reaches the `printk` address, much like gem5 <<exit-gem5-on-panic,can detect `panic` by PC>> and then parsing printk function arguments and buffers!\n\nThe relevant source is at https://github.com/gem5/gem5/blob/cd69bb50414450c3bb5ef41dce676b75fd42c0ee/src/kern/linux/printk.cc[`src/kern/linux/printk.c`].\n\nWe can test this mechanism in a controlled way by hacking a `panic()` into the kernel next to a `printk` that shows up before the serial is enabled, e.g. on Linux v5.4.3 we could do:\n\n....\ndiff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c\nindex f296d89be757..3e79916322c2 100644\n--- a/kernel/trace/ftrace.c\n+++ b/kernel/trace/ftrace.c\n@@ -6207,6 +6207,7 @@ void __init ftrace_init(void)\n\n    pr_info(\"ftrace: allocating %ld entries in %ld pages\\n\",\n        count, count / ENTRIES_PER_PAGE + 1);\n+   panic(\"foobar\");\n\n    last_ftrace_enabled = ftrace_enabled = 1;\n....\n\nWith this, after the panic, `system.workload.dmesg` contains on LKMC d09a0d97b81582cc88381c4112db631da61a048d aarch64:\n\n....\n[0.000000] Booting Linux on physical CPU 0x0000000000 [0x410fd070]\n[0.000000] Linux version 5.4.3-dirty (lkmc@f7688b48ac46e9a669e279f1bc167722d5141eda) (gcc version 8.3.0 (Buildroot 2019.11-00002-g157ac499cf)) #1 SMP Thu Jan 1 00:00:00 UTC 1970\n[0.000000] Machine model: V2P-CA15\n[0.000000] Memory limited to 256MB\n[0.000000] efi: Getting EFI parameters from FDT:\n[0.000000] efi: UEFI not found.\n[0.000000] On node 0 totalpages: 65536\n[0.000000]   DMA32 zone: 1024 pages used for memmap\n[0.000000]   DMA32 zone: 0 pages reserved\n[0.000000]   DMA32 zone: 65536 pages, LIFO batch:15\n[0.000000] percpu: Embedded 29 pages/cpu s79960 r8192 d30632 u118784\n[0.000000] pcpu-alloc: s79960 r8192 d30632 u118784 alloc=29*4096\n[0.000000] pcpu-alloc: [0] 0\n[0.000000] Detected PIPT I-cache on CPU0\n[0.000000] CPU features: detected: ARM erratum 832075\n[0.000000] CPU features: detected: EL2 vector hardening\n[0.000000] ARM_SMCCC_ARCH_WORKAROUND_1 missing from firmware\n[0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 64512\n[0.000000] Kernel command line: earlyprintk=pl011,0x1c090000 lpj=19988480 rw loglevel=8 mem=256MB root=/dev/sda console_msg_format=syslog nokaslr norandmaps panic=-1 printk.devkmsg=on printk.time=y rw console=ttyAMA0 - lkmc_home=/lkmc\n[0.000000] Dentry cache hash table entries: 32768 (order: 6, 262144 bytes, linear)\n[0.000000] Inode-cache hash table entries: 16384 (order: 5, 131072 bytes, linear)\n[0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off\n[0.000000] Memory: 233432K/262144K available (6652K kernel code, 792K rwdata, 2176K rodata, 896K init, 659K bss, 28712K reserved, 0K cma-reserved)\n[0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1\n[0.000000] ftrace: allocating 22067 entries in 87 pages\n....\n\nSo we see that messages up to the `ftrace` do show up!\n\n[[gem5-m5out-stats-txt-file]]\n==== gem5 m5out/stats.txt file\n\nThis file contains important statistics about the run:\n\n....\ncat \"$(./getvar --arch aarch64 m5out_dir)/stats.txt\"\n....\n\nWhenever we run `m5 dumpstats` or when fs.py and se.py are exiting (TODO other scripts?), a section with the following format is added to that file:\n\n....\n---------- Begin Simulation Statistics ----------\n[the stats]\n---------- End Simulation Statistics   ----------\n....\n\nThat file contains several important execution metrics, e.g. number of cycles and several types of cache misses:\n\n....\nsystem.cpu.numCycles\nsystem.cpu.dtb.inst_misses\nsystem.cpu.dtb.inst_hits\n....\n\nFor x86, it is interesting to try and correlate `numCycles` with:\n\nIn LKMC f42c525d7973d70f4c836d2169cc2bd2893b4197 gem5 5af26353b532d7b5988cf0f6f3d0fbc5087dd1df, the stat file for a <<c>> hello world:\n\n....\n./run --arch aarch64 --emulator gem5 --userland userland/c/hello.c\n....\n\nwhich has a single dump done at the exit, has size 59KB and stat lines of form:\n\n....\nfinal_tick                                   91432000                       # Number of ticks from beginning of simulation (restored from checkpoints and never reset)\n....\n\nWe can reduce the file size by adding the `?desc=False` magic suffix to the stat flie name:\n\n....\n--stats-file stats.txt?desc=false\n....\n\nas explained in:\n\n....\ngem5.opt --stats-help\n....\n\nand this reduces the file size to 39KB by removing those excessive comments:\n\n....\nfinal_tick                                   91432000\n....\n\nalthough trailing spaces are still prse\n\nWe can further reduce this size by removing spaces from the dumps with this hack:\n\n....\n         ccprintf(stream, \" |%12s %10s %10s\",\n                  ValueToString(value, precision), pdfstr.str(), cdfstr.str());\n     } else {\n-        ccprintf(stream, \"%-40s %12s %10s %10s\", name,\n-                 ValueToString(value, precision), pdfstr.str(), cdfstr.str());\n+        ccprintf(stream, \"%s %s\", name, ValueToString(value, precision));\n+        if (pdfstr.rdbuf()->in_avail())\n+            stream << \" \" << pdfstr.str();\n+        if (cdfstr.rdbuf()->in_avail())\n+            stream << \" \" << cdfstr.str();\n\n         if (descriptions) {\n             if (!desc.empty())\n....\n\nand after that the file size went down to 21KB.\n\n===== gem5 HDF5 statistics\n\nWe can make gem5 dump statistics in the <<hdf5>> format by adding the magic `h5://` prefix to the file name as in:\n\n....\ngem5.opt --stats-file h5://stats.h5\n....\n\nas explained in:\n\n....\ngem5.opt --stats-help\n....\n\nThis is not exposed in LKMC f42c525d7973d70f4c836d2169cc2bd2893b4197 however, you just have to <<dry-run,hack the gem5 CLI for now>>.\n\nTODO what is the advantage? The generated file for `--stats-file h5://stats.h5?desc=False` in LKMC f42c525d7973d70f4c836d2169cc2bd2893b4197 gem5 5af26353b532d7b5988cf0f6f3d0fbc5087dd1df for a single dump was 946K, so much larger than the text version seen at <<gem5-m5out-stats-txt-file>> which was only 59KB max!\n\nWe then try to see if it is any better when you have a bunch of dump events:\n\n....\n./run --arch aarch64 --emulator gem5 --userland userland/c/m5ops.c --cli-args 'd 1000'\n....\n\nand there yes, we see that the file size fell from 39MB on `stats.txt` to 3.2MB on `stats.m5`, so the increase observed previously was just due to some initial size overhead (considering the patched gem5 with no spaces in the text file).\n\nWe also note however that the stat dump made the such a simulation that just loops and dumps considerably slower, from 3s to 15s on <<p51>>. Fascinating, we are definitely not disk bound there.\n\nWe enable HDF5 on the build by default with `USE_HDF5=1`. To disable it, you can add `USE_HDF5=0` to the build as in:\n\n....\n./build-gem5 -- USE_HDF5=0\n....\n\nLibrary support is automatically detected, and only built if you have it installed. But there have been some compilation bugs with HDF5, which is why you might want to turn it off sometimes, e.g.: https://gem5.atlassian.net/browse/GEM5-365\n\n===== gem5 only dump selected stats\n\nhttps://stackoverflow.com/questions/52014953/how-to-dump-only-a-single-or-certain-selected-stats-in-gem5\n\nTo prevent the stats file from becoming humongous.\n\nhttps://stackoverflow.com/questions/52014953/how-to-dump-only-a-single-or-certain-selected-stats-in-gem5/57221132#57221132\n\n===== Meaning of each gem5 stat\n\nWell, run minimal examples, and reverse engineer them up!\n\nWe can start with link:userland/arch/x86_64/freestanding/linux/hello.S[] on atomic with <<gem5-execall-trace-format>>.\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --trace ExecAll \\\n  --trace-stdout \\\n;\n....\n\nwhich gives:\n\n....\n      0: system.cpu: A0 T0 : @_start    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n    500: system.cpu: A0 T0 : @_start+4    :   adr   x1, #28            : IntAlu :  D=0x0000000000400098  flags=(IsInteger)\n   1000: system.cpu: A0 T0 : @_start+8    :   ldr   w2, #4194464       : MemRead :  D=0x0000000000000006 A=0x4000a0  flags=(IsInteger|IsMemRef|IsLoad)\n   1500: system.cpu: A0 T0 : @_start+12    :   movz   x8, #64, #0       : IntAlu :  D=0x0000000000000040  flags=(IsInteger)\n   2000: system.cpu: A0 T0 : @_start+16    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n   2500: system.cpu: A0 T0 : @_start+20    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   3000: system.cpu: A0 T0 : @_start+24    :   movz   x8, #93, #0       : IntAlu :  D=0x000000000000005d  flags=(IsInteger)\n   3500: system.cpu: A0 T0 : @_start+28    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n....\n\nThe most important stat of all is usually the cycle count, which is a direct measure of performance if you modelled you system well:\n\n....\nsim_ticks 3500 # Number of ticks simulated\n....\n\nNext, `sim_insts` and `sim_ops` are often critical:\n\n....\nsim_insts 6 # Number of instructions simulated\nsim_ops   6 # Number of ops (including micro ops) simulated\n....\n\n`sim_ops` is like `sim_insts` but it also includes <<gem5-microops>>.\n\nIn <<gem5-syscall-emulation-mode>>, syscall instructions are magic, and therefore appear to not be counted, that is why we get 6 instructions instead of 8.\n\n===== gem5 stats internals\n\nThis describes the internals of the <<gem5-m5out-stats-txt-file>>.\n\nGDB call stack to `dumpstats`:\n\n....\nStats::pythonDump () at build/ARM/python/pybind11/stats.cc:58\nStats::StatEvent::process() ()\nGlobalEvent::BarrierEvent::process (this=0x555559fa6a80) at build/ARM/sim/global_event.cc:131\nEventQueue::serviceOne (this=this@entry=0x555558c36080) at build/ARM/sim/eventq.cc:228\ndoSimLoop (eventq=0x555558c36080) at build/ARM/sim/simulate.cc:219\nsimulate (num_cycles=<optimized out>) at build/ARM/sim/simulate.cc:132\n....\n\n`Stats::pythonDump` does:\n\n....\nvoid\npythonDump()\n{\n    py::module m = py::module::import(\"m5.stats\");\n    m.attr(\"dump\")();\n}\n....\n\nThis calls `src/python/m5/stats/__init__.py` in `def dump` does the main dumping\n\nThat function does notably:\n\n....\n    for output in outputList:\n        if output.valid():\n            output.begin()\n            for stat in stats_list:\n                stat.visit(output)\n            output.end()\n....\n\n`begin` and `end` are defined in C++ and output the header and tail respectively\n\n....\nvoid\nText::begin()\n{\n    ccprintf(*stream, \"\\n---------- Begin Simulation Statistics ----------\\n\");\n}\n\nvoid\nText::end()\n{\n    ccprintf(*stream, \"\\n---------- End Simulation Statistics   ----------\\n\");\n    stream->flush();\n}\n....\n\n`stats_list` contains the stats, and `stat.visit` prints them, `outputList` contains by default just the text output. I don't see any other types of output in gem5, but likely JSON / binary formats could be envisioned.\n\nTested in gem5 b4879ae5b0b6644e6836b0881e4da05c64a6550d.\n\n==== gem5 config.ini\n\nThe `m5out/config.ini` file, contains a very good high level description of the system:\n\n....\nless $(./getvar --arch arm --emulator gem5 m5out_dir)\"\n....\n\nThat file contains a tree representation of the system, sample excerpt:\n\n....\n[root]\ntype=Root\nchildren=system\nfull_system=true\n\n[system]\ntype=ArmSystem\nchildren=cpu cpu_clk_domain\nauto_reset_addr_64=false\nsemihosting=Null\n\n[system.cpu]\ntype=AtomicSimpleCPU\nchildren=dstage2_mmu dtb interrupts isa istage2_mmu itb tracer\nbranchPred=Null\n\n[system.cpu_clk_domain]\ntype=SrcClockDomain\nclock=500\n....\n\nEach node has:\n\n* a list of child nodes, e.g. `system` is a child of `root`, and both `cpu` and `cpu_clk_domain` are children of `system`\n* a list of parameters, e.g. `system.semihosting` is `Null`, which means that <<semihosting>> was turned off\n    ** the `type` parameter shows is present on every node, and it maps to a `Python` object that inherits from <<gem5-python-c-interaction,`SimObject`>>.\n+\nFor example, `AtomicSimpleCPU` maps is defined at https://github.com/gem5/gem5/blob/05c4c2b566ce351ab217b2bd7035562aa7a76570/src/cpu/simple/AtomicSimpleCPU.py#L45[src/cpu/simple/AtomicSimpleCPU.py].\n\nSet custom configs with the `--param` option of `fs.py`, e.g. we can make gem5 wait for GDB to connect with:\n\n....\nfs.py --param 'system.cpu[0].wait_for_remote_gdb = True'\n....\n\nMore complex settings involving new classes however require patching the config files, although it is easy to hack this up. See for example: link:patches/manual/gem5-semihost.patch[].\n\nModifying the `config.ini` file manually does nothing since it gets overwritten every time.\n\n===== gem5 config.dot\n\nThe `m5out/config.dot` file contains a graphviz `.dot` file that provides a simplified graphical view of a subset of the <<gem5-config-ini>>.\n\nThis file gets automatically converted to `.svg` and `.pdf`, which you can view after running gem5 with:\n\n....\nxdg-open \"$(./getvar --arch arm --emulator gem5 m5out_dir)/config.dot.pdf\"\nxdg-open \"$(./getvar --arch arm --emulator gem5 m5out_dir)/config.dot.svg\"\n....\n\nAn example of such file can be seen at: <<config-dot-svg-timingsimplecpu>>.\n\nOn Ubuntu 20.04, you can also see the dot file \"directly\" with xdot:\n\n....\nxdot \"$(./getvar --arch arm --emulator gem5 m5out_dir)/config.dot\"\n....\n\nwhich is kind of really cool because it allows you to view graph arrows on hover. This can be very useful because the PDF and SVG often overlap so many arrows together that you just can't know which one is coming from/going to where.\n\nIt is worth noting that if you are running a bunch of short simulations, dot/SVG/PDF generation could have a significant impact in simulation startup time, so it is something to watch out for. As per https://gem5-review.googlesource.com/c/public/gem5/+/29232 it can be turned off with:\n\n....\ngem5.opt --dot-config=''\n....\n\nor in LKMC:\n\n....\n./run --gem5-exe-args='--dot-config= --json-config= --dump-config='\n....\n\nThe time difference can be readily observed on minimal examples by running gem5 with `time`.\n\nBy looking into gem5 872cb227fdc0b4d60acc7840889d567a6936b6e1 `src/python/m5/util/dot_writer.py` are can try to remove the SVG/PDF conversion to see if those dominate the runtime:\n\n....\ndef do_dot(root, outdir, dotFilename):\n    if not pydot:\n        warn(\"No dot file generated. \" +\n             \"Please install pydot to generate the dot file and pdf.\")\n        return\n    # * use ranksep > 1.0 for for vertical separation between nodes\n    # especially useful if you need to annotate edges using e.g. visio\n    # which accepts svg format\n    # * no need for hoizontal separation as nothing moves horizonally\n    callgraph = pydot.Dot(graph_type='digraph', ranksep='1.3')\n    dot_create_nodes(root, callgraph)\n    dot_create_edges(root, callgraph)\n    dot_filename = os.path.join(outdir, dotFilename)\n    callgraph.write(dot_filename)\n    try:\n        # dot crashes if the figure is extremely wide.\n        # So avoid terminating simulation unnecessarily\n        callgraph.write_svg(dot_filename + \".svg\")\n        callgraph.write_pdf(dot_filename + \".pdf\")\n    except:\n        warn(\"failed to generate dot output from %s\", dot_filename)\n....\n\nbut nope, they don't, `dot_create_nodes` and `dot_create_edges` are the culprits, so the only way to gain speed is to remove `.dot` generation altogether. It is tempting to do this by default on LKMC and add an option to enable dot generation when desired so we can be a bit faster by default... but I'm lazy to document the option right now. When it annoys me further maybe :-)\n\n=== m5term\n\nWe use the `m5term` in-tree executable to connect to the terminal instead of a direct `telnet`.\n\nIf you use `telnet` directly, it mostly works, but certain interactive features don't, e.g.:\n\n* up and down arrows for history navigation\n* tab to complete paths\n* `Ctrl-C` to kill processes\n\nTODO understand in detail what `m5term` does differently than `telnet`.\n\n=== gem5 Python scripts without rebuild\n\nWe have made a crazy setup that allows you to just `cd` into `submodules/gem5`, and edit Python scripts directly there.\n\nThis is not normally possible with Buildroot, since normal Buildroot packages first copy files to the output directory (`$(./getvar -a <arch> buildroot_build_build_dir)/<pkg>`), and then build there.\n\nSo if you modified the Python scripts with this setup, you would still need to `./build` to copy the modified files over.\n\nFor gem5 specifically however, we have hacked up the build so that we `cd` into the `submodules/gem5` tree, and then do an https://stackoverflow.com/questions/54343515/how-to-build-gem5-out-of-tree/54343516#54343516[out of tree] build to `out/common/gem5`.\n\nAnother advantage of this method is the we factor out the `arm` and `aarch64` gem5 builds which are identical and large, as well as the smaller arch generic pieces.\n\nUsing Buildroot for gem5 is still convenient because we use it to:\n\n* to cross build `m5` for us\n* check timestamps and skip the gem5 build when it is not requested\n\nThe out of build tree is required, because otherwise Buildroot would copy the output build of all archs to each arch directory, resulting in `arch^2` build copies, which is significant.\n\n[[gem5-fs-biglittle]]\n=== gem5 fs_bigLITTLE\n\nBy default, we use `configs/example/fs.py` script.\n\nThe `--gem5-script biglittle` option enables the alternative `configs/example/arm/fs_bigLITTLE.py` script instead:\n\n....\n./run --arch aarch64 --emulator gem5 --gem5-script biglittle\n....\n\nAdvantages over `fs.py`:\n\n* more representative of mobile ARM SoCs, which almost always have big little cluster\n* simpler than `fs.py`, and therefore easier to understand and modify\n\nDisadvantages over `fs.py`:\n\n* only works for ARM, not other archs\n* not as many configuration options as `fs.py`, many things are hardcoded\n\nWe setup 2 big and 2 small CPUs, but `cat /proc/cpuinfo` shows 4 identical CPUs instead of 2 of two different types, likely because gem5 does not expose some informational register much like the caches: https://www.mail-archive.com/gem5-users@gem5.org/msg15426.html <<gem5-config-ini>> does show that the two big ones are `DerivO3CPU` and the small ones are `MinorCPU`.\n\nTODO: why is the `--dtb` required despite `fs_bigLITTLE.py` having a DTB generation capability? Without it, nothing shows on terminal, and the simulation terminates with `simulate() limit reached  @  18446744073709551615`. The magic `vmlinux.vexpress_gem5_v1.20170616` works however without a DTB.\n\nTested on: https://github.com/cirosantilli/linux-kernel-module-cheat/commit/18c1c823feda65f8b54cd38e261c282eee01ed9f[18c1c823feda65f8b54cd38e261c282eee01ed9f]\n\n=== gem5 in-tree tests\n\nhttps://stackoverflow.com/questions/52279971/how-to-run-the-gem5-unit-tests\n\nAll those tests could in theory be added to this repo instead of to gem5, and this is actually the superior setup as it is cross emulator.\n\nBut can the people from the project be convinced of that?\n\n==== gem5 unit tests\n\nThese are just very small GTest tests that test a single class in isolation, they don't run any executables.\n\nBuild the unit tests and run them:\n\n....\n./build-gem5 --unit-tests\n....\n\nRunning individual unit tests is not yet exposed, but it is easy to do: while running the full tests, GTest prints each test command being run, e.g.:\n\n....\n/path/to/build/ARM/base/circlebuf.test.opt --gtest_output=xml:/path/to/build/ARM/unittests.opt/base/circlebuf.test.xml\n[==========] Running 4 tests from 1 test case.\n[----------] Global test environment set-up.\n[----------] 4 tests from CircleBufTest\n[ RUN      ] CircleBufTest.BasicReadWriteNoOverflow\n[       OK ] CircleBufTest.BasicReadWriteNoOverflow (0 ms)\n[ RUN      ] CircleBufTest.SingleWriteOverflow\n[       OK ] CircleBufTest.SingleWriteOverflow (0 ms)\n[ RUN      ] CircleBufTest.MultiWriteOverflow\n[       OK ] CircleBufTest.MultiWriteOverflow (0 ms)\n[ RUN      ] CircleBufTest.PointerWrapAround\n[       OK ] CircleBufTest.PointerWrapAround (0 ms)\n[----------] 4 tests from CircleBufTest (0 ms total)\n\n[----------] Global test environment tear-down\n[==========] 4 tests from 1 test case ran. (0 ms total)\n[  PASSED  ] 4 tests.\n....\n\nso you can just copy paste the command.\n\nBuilding individual tests is possible with `--unit-test` (singular, no 's'):\n\n....\n./build-gem5 --unit-test base/circlebuf.test\n....\n\nThis does not run the test however.\n\nNote that the command and it's corresponding results don't need to show consecutively on stdout because tests are run in parallel. You just have to match them based on the class name `CircleBufTest` to the file `circlebuf.test.cpp`.\n\n==== gem5 regression tests\n\nThis section is about running the gem5 in-tree tests.\n\nhttps://stackoverflow.com/questions/52279971/how-to-run-the-gem5-unit-tests\n\nRunning the larger 2019 regression tests is exposed for example with:\n\n....\n./build-gem5 --arch aarch64\n./gem5-regression --arch aarch64 -- --length quick --length long\n....\n\nSample run time: 87 minutes on <<p51>> Ubuntu 20.04 gem5 872cb227fdc0b4d60acc7840889d567a6936b6e1.\n\nAfter the first run has downloaded the test binaries for you, you can speed up the process a little bit by skipping an useless SCons call:\n\n....\n./gem5-regression --arch aarch64 -- --length quick --length long --skip-build\n....\n\nNote however that running without `--skip-build` is required at least once to download the test binaries, because the test interface is bad.\n\nList available instead of running them:\n\n....\n./gem5-regression --arch aarch64 --cmd list -- --length quick --length long\n....\n\nYou can then pick one suite (has to be a suite, not an \"individual test\") from the list and run just it e.g. with:\n\n....\n./gem5-regression --arch aarch64 -- --uid SuiteUID:tests/gem5/cpu_tests/test.py:cpu_test_AtomicSimpleCPU_Bubblesort-ARM-opt\n....\n\n=== gem5 simulate() limit reached\n\nThis error happens when the following instruction limits are reached:\n\n....\nsystem.cpu[0].max_insts_all_threads\nsystem.cpu[0].max_insts_any_thread\n....\n\nIf the parameter is not set, it defaults to `0`, which is magic and means the huge maximum value of `uint64_t`: 0xFFFFFFFFFFFFFFFF, which in practice would require a very long simulation if at least one CPU were live.\n\nSo this usually means all CPUs are in a sleep state, and no events are scheduled in the future, which usually indicates a bug in either gem5 or guest code, leading gem5 to blow up.\n\nStill, fs.py at gem5 08c79a194d1a3430801c04f37d13216cc9ec1da3 does not exit with non-zero status due to this... and so we just parse it out just as for <<m5-fail>>...\n\nA trivial and very direct way to see message would be:\n\n....\n./run \\\n  --emulator gem5 \\\n  --userland userland/arch/x86_64/freestanding/linux/hello.S \\\n  --trace-insts-stdout \\\n  -- \\\n  --param 'system.cpu[0].max_insts_all_threads = 3' \\\n;\n....\n\nwhich as of lkmc 402059ed22432bb351d42eb10900e5a8e06aa623 runs only the first three instructions and quits!\n\n....\ninfo: Entering event queue @ 0.  Starting simulation...\n      0: system.cpu A0 T0 : @asm_main_after_prologue    : mov   rdi, 0x1\n      0: system.cpu A0 T0 : @asm_main_after_prologue.0  :   MOV_R_I : limm   rax, 0x1 : IntAlu :  D=0x0000000000000001  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   1000: system.cpu A0 T0 : @asm_main_after_prologue+7    : mov rdi, 0x1\n   1000: system.cpu A0 T0 : @asm_main_after_prologue+7.0  :   MOV_R_I : limm   rdi, 0x1 : IntAlu :  D=0x0000000000000001  flags=(IsInteger|IsMicroop|IsLastMicroop|IsFirstMicroop)\n   2000: system.cpu A0 T0 : @asm_main_after_prologue+14    : lea        rsi, DS:[rip + 0x19]\n   2000: system.cpu A0 T0 : @asm_main_after_prologue+14.0  :   LEA_R_P : rdip   t7, %ctrl153,  : IntAlu :  D=0x000000000040008d  flags=(IsInteger|IsMicroop|IsDelayedCommit|IsFirstMicroop)\n   2500: system.cpu A0 T0 : @asm_main_after_prologue+14.1  :   LEA_R_P : lea   rsi, DS:[t7 + 0x19] : IntAlu :  D=0x00000000004000a6  flags=(IsInteger|IsMicroop|IsLastMicroop)\nExiting @ tick 3000 because all threads reached the max instruction count\n....\n\nThe exact same can be achieved with the older hardcoded `--maxinsts` mechanism present in `se.py` and `fs.py`:\n\n....\n./run \\\n  --emulator gem5 \\\n  --userland \\userland/arch/x86_64/freestanding/linux/hello.S \\\n  --trace-insts-stdout \\\n  -- \\\n  --maxinsts 3\n;\n....\n\nOther related fs.py options are:\n\n* `--abs-max-tick`: set the maximum guest simulation time. The same scale as the ExecAll trace is used. E.g., for the above example with 3 instructions, the same trace would be achieved with a value of 3000.\n\nThe message also shows on <<user-mode-simulation>> deadlocks, for example in link:userland/posix/pthread_deadlock.c[]:\n\n....\n./run \\\n  --emulator gem5 \\\n  --userland userland/posix/pthread_deadlock.c \\\n  --cli-args 1 \\\n;\n....\n\nends in:\n\n....\nExiting @ tick 18446744073709551615 because simulate() limit reached\n....\n\nwhere 18446744073709551615 is 0xFFFFFFFFFFFFFFFF in decimal.\n\nAnd there is a <<baremetal>> example at link:baremetal/arch/aarch64/no_bootloader/wfe_loop.S[] that dies on <<arm-wfe-and-sev-instructions,WFE>>:\n\n....\n./run \\\n  --arch aarch64 \\\n  --baremetal baremetal/arch/aarch64/no_bootloader/wfe_loop.S \\\n  --emulator gem5 \\\n  --trace-insts-stdout \\\n;\n....\n\nwhich gives:\n\n....\ninfo: Entering event queue @ 0.  Starting simulation...\n      0: system.cpu A0 T0 : @lkmc_start    :   wfe                      : IntAlu :  D=0x0000000000000000  flags=(IsSerializeAfter|IsNonSpeculative|IsQuiesce|IsUnverifiable)\n   1000: system.cpu A0 T0 : @lkmc_start+4    :   b   <lkmc_start>         : IntAlu :   flags=(IsControl|IsDirectControl|IsUncondControl)\n   1500: system.cpu A0 T0 : @lkmc_start    :   wfe                      : IntAlu :  D=0x0000000000000000  flags=(IsSerializeAfter|IsNonSpeculative|IsQuiesce|IsUnverifiable)\nExiting @ tick 18446744073709551615 because simulate() limit reached\n....\n\nOther examples of the message:\n\n* <<arm-baremetal-multicore>> with a single CPU stays stopped at an WFE sleep instruction\n* this sample bug on se.py multithreading: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/81\n\n=== gem5 build options\n\nIn order to use different build options, you might also want to use <<gem5-build-variants>> to keep the build outputs separate from one another.\n\n==== gem5 debug build\n\nHow to use it in LKMC: xref:debug-the-emulator[xrefstyle=full].\n\nIf you build gem5 with `scons build/ARM/gem5.debug`, then that is a `.debug` build.\n\nIt relates to the more common `.opt` build just as explained at xref:debug-the-emulator[xrefstyle=full]: both `.opt` and `.debug` have `-g`, but `.opt` uses `-O2` while `.debug` uses `-O0`.\n\n==== gem5 fast build\n\n....\n./build-gem5 --gem5-build-type fast\n....\n\nHow it goes faster is explained at: https://stackoverflow.com/questions/59860091/how-to-increase-the-simulation-speed-of-a-gem5-run/59861375#59861375\n\nDisables debug symbols (no `-g`) for some reason.\n\nBenchmarks present at:\n\n* xref:benchmark-emulators-on-userland-executables[xrefstyle=full]\n\n==== gem5 prof and perf builds\n\nProfiling builds as of 3cea7d9ce49bda49c50e756339ff1287fd55df77 both use: `-g -O3` and disable asserts and logging like the <<gem5-fast-build>> and:\n\n* `prof` uses `-pg` for gprof\n* `perf` uses `-lprofile` for google-pprof\n\nProfiling techniques are discussed in more detail at: <<profiling-userland-programs>>.\n\nFor the `prof` build, you can get the `gmon.out` file with:\n\n....\n./run --arch aarch64 --emulator gem5 --userland userland/c/hello.c --gem5-build-type prof\ngprof \"$(./getvar --arch aarch64 gem5_executable)\" > tmp.gprof\n....\n\n==== gem5 clang build\n\nTODO test properly, benchmark vs GCC.\n\n....\nsudo apt-get install clang\n./build-gem5 --gem5-clang\n./run --emulator gem5 --gem5-clang\n....\n\n==== gem5 sanitation build\n\nIf there gem5 appears to have a C++ undefined behaviour bug, which is often very difficult to track down, you can try to build it with the following extra SCons options:\n\n....\n./build-gem5 --gem5-build-id san --verbose -- --with-ubsan --without-tcmalloc\n....\n\nThis will make GCC do a lot of extra sanitation checks at compile and run time.\n\nAs a result, the build and runtime will be way slower than normal, but that still might be the fastest way to solve undefined behaviour problems.\n\nIdeally, we should also be able to run it with asan with `--with-asan`, but if we try then the build fails at gem5 16eeee5356585441a49d05c78abc328ef09f7ace (with two ubsan trivial fixes I'll push soon):\n\n....\n=================================================================\n==9621==ERROR: LeakSanitizer: detected memory leaks\n\nDirect leak of 371712 byte(s) in 107 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff03950d065 in dictresize ../Objects/dictobject.c:643\n\nDirect leak of 23728 byte(s) in 26 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff03945e40d in _PyObject_GC_Malloc ../Modules/gcmodule.c:1499\n    #2 0x7ff03945e40d in _PyObject_GC_Malloc ../Modules/gcmodule.c:1493\n\nDirect leak of 2928 byte(s) in 43 object(s) allocated from:\n    #0 0x7ff03980487e in __interceptor_realloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c87e)\n    #1 0x7ff03951d763 in list_resize ../Objects/listobject.c:62\n    #2 0x7ff03951d763 in app1 ../Objects/listobject.c:277\n    #3 0x7ff03951d763 in PyList_Append ../Objects/listobject.c:289\n\nDirect leak of 2002 byte(s) in 3 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff0394fd813 in PyString_FromStringAndSize ../Objects/stringobject.c:88\n    #2 0x7ff0394fd813 in PyString_FromStringAndSize ../Objects/stringobject.c:\n    Direct leak of 40 byte(s) in 2 object(s) allocated from\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff03951ea4b in PyList_New ../Objects/listobject.c:152\n\nIndirect leak of 10384 byte(s) in 11 object(s) allocated from\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448\n    #1 0x7ff03945e40d in _PyObject_GC_Malloc ../Modules/gcmodule.c:\n    #2 0x7ff03945e40d in _PyObject_GC_Malloc ../Modules/gcmodule.c:1493\n\nIndirect leak of 4089 byte(s) in 6 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff0394fd648 in PyString_FromString ../Objects/stringobject.c:143\n\nIndirect leak of 2090 byte(s) in 3 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448\n    #1 0x7ff0394eb36f in type_new ../Objects/typeobject.c:\n    #2 0x7ff0394eb36f in type_new ../Objects/typeobject.c:2094\nIndirect leak of 1346 byte(s) in 2 object(s) allocated from:\n    #0 0x7ff039804448 in malloc (/usr/lib/x86_64-linux-gnu/libasan.so.5+0x10c448)\n    #1 0x7ff0394fd813 in PyString_FromStringAndSize ../Objects/stringobject.c:\n    #2 0x7ff0394fd813 in PyString_FromStringAndSize ../Objects/stringobject.c:\n    SUMMARY: AddressSanitizer: 418319 byte(s) leaked in 203 allocation(s).\n....\n\nFrom the message, this appears however to be a Python / pyenv11 bug however and not in gem5 specifically. I think it worked when I tried it in the past in an older gem5 / Ubuntu.\n\n`--without-tcmalloc` is needed / a good idea when using `--with-asan`: https://stackoverflow.com/questions/42712555/address-sanitizer-fsanitize-address-works-with-tcmalloc since both do more or less similar jobs, see also <<memory-leaks>>.\n\n==== gem5 Ruby build\n\ngem5 has two types of memory system:\n\n* the classic memory system, which is used by default, its caches are covered at: <<gem5-event-queue-timingsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches>>\n* the Ruby memory system\n\nThe Ruby memory system includes the SLICC domain specific language to describe memory systems: http://gem5.org/Ruby SLICC transpiles to C++ auto-generated files under `build/<isa>/mem/ruby/protocol/`.\n\nRuby seems to have usage outside of gem5, but the naming overload with the link:https://en.wikipedia.org/wiki/Ruby_(programming_language)[Ruby programming language], which also has link:https://thoughtbot.com/blog/writing-a-domain-specific-language-in-ruby[domain specific languages] as a concept, makes it impossible to google anything about it!\n\nSince it is not the default, Ruby is generally less stable that the classic memory model. However, because it allows describing a wide variety of important <<cache-coherence,cache coherence protocols>>, while the classic system only describes a single protocol, Ruby is very importanonly describes a single protocol, Ruby is a very important feature of gem5.\n\nRuby support must be enabled at compile time with the `scons PROTOCOL=` flag, which compiles support for the desired memory system type.\n\nNote however that most ISAs already implicitly set `PROTOCOL` via the `build_opts/` directory, e.g. `build_opts/ARM` contains:\n\n....\nPROTOCOL = 'MOESI_CMP_directory'\n....\n\nand therefore ARM already compiles `MOESI_CMP_directory` by default.\n\nThen, with `fs.py` and `se.py`, you can choose to use either the classic or the ruby system type selected at build time with `PROTOCOL=` at runtime by passing the `--ruby` option:\n\n* if `--ruby` is given, use the ruby memory system that was compiled into gem5. Caches are always present when Ruby is used, since the main goal of Ruby is to specify the cache coherence protocol, and it therefore hardcodes cache hierarchies.\n* otherwise, use the classic memory system. Caches may be optional for certain CPU types and are enabled with `--caches`.\n\nNote that the `--ruby` option has some crazy side effects besides enabling Ruby, e.g. it https://github.com/gem5/gem5/blob/9fc9c67b4242c03f165951775be5cd0812f2a705/configs/ruby/Ruby.py#L61[sets the default `--cpu-type` to `TimingSimpleCPU` instead of the otherwise default `AtomicSimpleCPU`]. TODO: I have been told that this is because <<gem5-functional-vs-atomic-vs-timing-memory-requests,sends the packet atomically,atomic requests do not work with Ruby, only timing>>.\n\nIt is not possible to build more than one Ruby system into a single build, and this is a major pain point for testing Ruby: https://gem5.atlassian.net/browse/GEM5-467\n\nFor example, to use a two level <<mesi-cache-coherence-protocol>> we can do:\n\n....\n./build-gem5 --arch aarch64 --gem5-build-id ruby -- PROTOCOL=MESI_Two_Level\n./run --arch aarch64 --emulator -gem5 --gem5-build-id ruby -- --ruby\n....\n\nand during build we see a humongous line of type:\n\n....\n[   SLICC] src/mem/protocol/MESI_Two_Level.slicc -> ARM/mem/protocol/AccessPermission.cc, ARM/mem/protocol/AccessPermission.hh, ...\n....\n\nwhich shows that dozens of C++ files are being generated from Ruby SLICC.\n\nThe relevant Ruby source files live in the source tree under:\n\n....\nsrc/mem/protocol/MESI_Two_Level*\n....\n\nWe already pass the `SLICC_HTML` flag by default to the build, which generates an HTML summary of each memory protocol under (TODO broken: https://gem5.atlassian.net/browse/GEM5-357[]):\n\n....\nxdg-open \"$(./getvar --arch aarch64 --gem5-build-id ruby gem5_build_build_dir)/ARM/mem/protocol/html/index.html\"\n....\n\nA minimized ruby config which was not merged upstream can be found for study at: https://gem5-review.googlesource.com/c/public/gem5/+/13599/1\n\nOne easy way to see that Ruby is being used without understanding it in detail is to <<gem5-tracing,enable some logging>>:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --gem5-worktree master \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --static \\\n  --trace ExecAll,FmtFlag,Ruby,XBar \\\n  -- \\\n  --ruby \\\n;\ncat \"$(./getvar --arch aarch64 --emulator gem5 trace_txt_file)\"\n....\n\nThen:\n\n* when the `--ruby` flag is given, we see a gazillion Ruby related messages prefixed e.g. by `RubyPort:`.\n+\nWe also observe from `ExecEnable` lines that instruction timing is not simple anymore, so the memory system must have latencies\n* without `--ruby`, we instead see `XBar` (Coherent Crossbar) related messages such as `CoherentXBar:`, which I believe is the more precise name for the memory model that the classic memory system uses: <<gem5-crossbar-interconnect>>.\n\nCertain features may not work in Ruby. For example, <<gem5-checkpoint>> creation is only possible in Ruby protocols that support flush, which is the case for `PROTOCOL=MOESI_hammer` but not `PROTOCOL=MESI_Three_Level`: https://www.mail-archive.com/gem5-users@gem5.org/msg17418.html\n\nTested in gem5 d7d9bc240615625141cd6feddbadd392457e49eb.\n\n[[gem5-ruby-mi-example-protocol]]\n===== gem5 Ruby MI_example protocol\n\nThis is the simplest of all protocols, and therefore the first one you should study to learn how Ruby works.\n\nTo study it, we can take an approach similar to what was done at: <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>.\n\nOur full command line will be something like\n\n....\n./build-gem5 --arch aarch64 --gem5-build-id MI_example\n./run \\\n  --arch aarch64 \\\n  --cli-args '2 100' \\\n  --cpus 3 \\\n  --emulator gem5 \\\n  --userland userland/cpp/atomic/aarch64_add.cpp \\\n  --gem5-build-id MI_example \\\n  -- \\\n  --ruby \\\n;\n....\n\nwhich produces a <<gem5-config-dot,`config.dot.svg`>> like the following by with 3 CPUs instead of 2:\n\n[[config-dot-svg-timingsimplecpu-caches-3-cpus-ruby]]\n.`config.dot.svg` for a system with three TimingSimpleCPU CPUs with the Ruby `MI_example` protocol.\nimage::{cirosantilli-media-base}gem5_config_TimingSimpleCPU_3_CPUs_MI_example_b1623cb2087873f64197e503ab8894b5e4d4c7b4.svg?sanitize=true[height=600]\n\n===== gem5 crossbar interconnect\n\nCrossbar or `XBar` in the code, is the default <<cache-coherence,CPU interconnect>> that gets used by `fs.py` if <<gem5-ruby-build,`--ruby`>> is not given.\n\nIt presumably implements a crossbar switch along the lines of: https://en.wikipedia.org/wiki/Crossbar_switch\n\nThis is the best introductory example analysis we have so far: <<gem5-event-queue-timingsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>. It contains more or less the most minimal example in which something interesting can be observed: multiple cores fighting over a single data memory variable.\n\nLong story short: the interconnect contains the snoop mechanism, and it forwards packets coming form caches of a CPU to the caches of other CPUs in which the block is present.\n\nIt is therefore the heart of the <<cache-coherence>> mechanism, as it informs other caches of bus transactions they need to know about.\n\nTODO: describe it in more detail. It appears to be a very simple mechanism.\n\nUnder `src/mem/` we see that there is both a coherent and a non-coherent XBar.\n\nIn `se.py` it is set at:\n\n....\nif options.ruby:\n    ...\nelse:\n    MemClass = Simulation.setMemClass(options)\n    system.membus = SystemXBar()\n....\n\nand `SystemXBar` is defined at `src/mem/XBar.py` with a nice comment:\n\n....\n# One of the key coherent crossbar instances is the system\n# interconnect, tying together the CPU clusters, GPUs, and any I/O\n# coherent masters, and DRAM controllers.\nclass SystemXBar(CoherentXBar):\n....\n\nTested in gem5 12c917de54145d2d50260035ba7fa614e25317a3.\n\n==== gem5 Python 3 build\n\nPython 3 support was mostly added in 2019 Q3 at arounda347a1a68b8a6e370334be3a1d2d66675891e0f1 but remained buggy for some time afterwards.\n\nIn an Ubuntu 18.04 host where `python` is `python2` by default, build with Python 3 instead with:\n\n....\n./build-gem5 --gem5-build-id python3 -- PYTHON_CONFIG=python3-config\n....\n\nPython 3 is then automatically used when running if you use that build.\n\n=== gem5 CPU types\n\ngem5 has a few in tree CPU models for different purposes.\n\nIn fs.py and se.py, those are selectable with the `--cpu-type` option.\n\nThe information to make highly accurate models isn't generally public for non-free CPUs, so either you must either rely vendor provided models or on experiments/reverse engineering.\n\nThere is no simple answer for \"what is the best CPU\", in theory you have to understand each model and decide which one is closer your target system.\n\nWhenever possible, stick to:\n\n* vendor provide ones obviously, e.g. ARM Holdings models of ARM cores, unless there is good reason not to, as they are the most likely to be accurate\n* newer models instead of older models\n\nBoth of those can be checked with `git log` and `git blame`.\n\nAll CPU types inherit from the `BaseCPU` class, and looking at the class hierarchy in <<gem5-eclipse-configuration,Eclipse>> gives a good overview of what we have:\n\n* `BaseCPU`\n** `BaseKvmCPU`\n** `BaseSimpleCPU`: <<gem5-basesimplecpu>>\n*** `AtomicSimpleCPU`\n*** `TimingSimpleCPU`\n** `MinorO3CPU`: <<gem5-minorcpu>>\n** `BaseO3CPU`\n*** `FullO3CPU`\n**** `DerivO3CPU : public FullO3CPU<O3CPUImpl>`: <<gem5-derivo3cpu>>\n\nFrom this we see that there are basically only 4 C++ CPU models in gem5: Atomic, Timing, Minor and O3. All others are basically parametrizations of those base types.\n\n==== List of gem5 CPU types\n\n===== gem5 `BaseSimpleCPU`\n\nSimple abstract CPU without a pipeline.\n\nThey are therefore completely unrealistic. But they also run much faster. <<gem5-kvm,KVM CPUs>> are an alternative way of fast forwarding boot when they work.\n\nImplementations:\n\n* <<gem5-atomicsimplecpu>>\n* <<gem5-timingsimplecpu>>\n\n====== gem5 `AtomicSimpleCPU`\n\n`AtomicSimpleCPU`: the default one. Memory accesses happen instantaneously. The fastest simulation except for KVM, but not realistic at all.\n\nUseful to <<gem5-restore-checkpoint-with-a-different-cpu,boot Linux fast and then checkpoint and switch to a more detailed CPU>>.\n\n====== gem5 `TimingSimpleCPU`\n\n`TimingSimpleCPU`: memory accesses are realistic, but the CPU has no pipeline. The simulation is faster than detailed models, but slower than `AtomicSimpleCPU`.\n\nTo fully understand `TimingSimpleCPU`, see: <<gem5-event-queue-timingsimplecpu-syscall-emulation-freestanding-example-analysis>>.\n\nWithout caches, the CPU just stalls all the time waiting for memory requests for every advance of the PC or memory read from a instruction!\n\nCaches do make a difference here of course, and lead to much faster memory return times.\n\n===== gem5 MinorCPU\n\nGeneric <<out-of-order-execution,in-order>> <<superscalar-processor,superscalar>> core.\n\nIts C++ implementation that can be parametrized to more closely match real cores.\n\nNote that since gem5 is highly parametrizable, the parametrization could even change which instructions a CPU can execute by altering its available <<gem5-functional-units,functional units>>, which are used to model performance.\n\nFor example, `MinorCPU` allows all implemented instructions, including <<arm-sve>> instructions, but a derived class modelling, say, an https://en.wikipedia.org/wiki/ARM_Cortex-A7[ARM Cortex A7 core], might not, since SVE is a newer feature and the A7 core does not have SVE.\n\nThe weird name \"Minor\" stands for \"M (TODO what is M) IN ONder\".\n\nIts 4 stage pipeline is described at the \"MinorCPU\" section of <<gem5-arm-rsk>>.\n\nA commented execution example can be seen at: <<gem5-event-queue-minorcpu-syscall-emulation-freestanding-example-analysis>>.\n\nThere is also an in-tree doxygen at: https://github.com/gem5/gem5/blob/9fc9c67b4242c03f165951775be5cd0812f2a705/src/doc/inside-minor.doxygen[`src/doc/inside-minor.doxygen`] and rendered at: http://pages.cs.wisc.edu/~swilson/gem5-docs/minor.html\n\nAs of 2019, in-order cores are mostly present in low power/cost contexts, for example little cores of https://en.wikipedia.org/wiki/ARM_big.LITTLE[ARM bigLITTLE].\n\nThe following models extend the `MinorCPU` class by parametrization to make it match existing CPUs more closely:\n\n* `HPI`: derived from `MinorCPU`.\n+\nCreated by Ashkan Tousi in 2017 while working at ARM.\n+\nAccording to <<gem5-arm-rsk>>:\n+\n____\nThe HPI CPU timing model is tuned to be representative of a modern in-order Armv8-A implementation.\n____\n+\n* `ex5_LITTLE`: derived from `MinorCPU`. Description reads:\n+\n____\nex5 LITTLE core (based on the ARM Cortex-A7)\n____\n+\nImplemented by Pierre-Yves Péneau from LIRMM, which is a research lab in Montpellier, France, in 2017.\n\n===== gem5 `DerivO3CPU`\n\nGeneric <<out-of-order-execution,out-of-order core>>. \"O3\" Stands for \"Out Of Order\"!\n\nBasic documentation on the old gem5 wiki: http://www.m5sim.org/O3CPU\n\nAnalogous to <<gem5-minorcpu,MinorCPU>>, but modelling an out of order core instead of in order.\n\nA commented execution example can be seen at: <<gem5-event-queue-derivo3cpu-syscall-emulation-freestanding-example-analysis>>.\n\nThe default <<execution-unit,functional units>> are described at: <<gem5-derivo3cpu-default-functional-units>>. All default widths are set to 8 instructions, from the <<gem5-config-ini,`config.ini`>>:\n\n....\n[system.cpu]\ntype=DerivO3CPU\ncommitWidth=8\ndecodeWidth=8\ndispatchWidth=8\nfetchWidth=8\nissueWidth=8\nrenameWidth=8\nsquashWidth=8\nwbWidth=8\n....\n\nThis can be observed for example at: <<gem5-event-queue-derivo3cpu-syscall-emulation-freestanding-example-analysis-hazardless>>.\n\nExisting parametrizations:\n\n* `ex5_big`: big corresponding to `ex5_LITTLE`, by same author at same time. It description reads:\n+\n____\nex5 big core (based on the ARM Cortex-A15)\n____\n* `O3_ARM_v7a`: implemented by Ronald Dreslinski from the https://en.wikipedia.org/wiki/University_of_Michigan[University of Michigan] in 2012\n+\nNot sure why it has v7a in the name, since I believe the CPUs are just the microarchitectural implementation of any ISA, and the v8 hello world did run.\n+\nThe CLI option is named slightly differently as: `--cpu-type O3_ARM_v7a_3`.\n\n====== gem5 `DerivO3CPU` pipeline stages\n\n* fetch: besides obviously fetching the instruction, this is also where branch prediction runs. Presumably because you need to branch predict before deciding what to fetch next.\n\n* retire: the instruction is completely and totally done with.\n+\nMispeculated instructions never reach this stage as can be seen at: <<gem5-event-queue-derivo3cpu-syscall-emulation-freestanding-example-analysis-speculative>>.\n+\nThe `ExecAll` happens at this time as well. And therefore `ExecAll` does not happen for mispeculated instructions.\n\n[[gem5-util-o3-pipeview-py-o3-pipeline-viewer]]\n====== gem5 util/o3-pipeview.py O3 pipeline viewer\n\nMentioned at: http://www.m5sim.org/Visualization\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --trace O3PipeView \\\n  --trace-stdout \\\n  -- \\\n  --cpu-type DerivO3CPU \\\n  --caches \\\n;\n\"$(./getvar gem5_source_dir)/util/o3-pipeview.py\" -c 500 -o o3pipeview.tmp.log --color \"$(./getvar --arch aarch64 trace_txt_file)\"\nless -R o3pipeview.tmp.log\n....\n\nOr without color:\n\n....\n\"$(./getvar gem5_source_dir)/util/o3-pipeview.py\" -c 500 -o o3pipeview.tmp.log \"$(./getvar --arch aarch64 trace_txt_file)\"\nless o3pipeview.tmp.log\n....\n\nA sample output for this can be seen at: <<hazardless-o3-pipeline>>.\n\n====== gem5 Konata O3 pipeline viewer\n\nhttps://github.com/shioyadan/Konata\n\nhttp://learning.gem5.org/tutorial/presentations/vis-o3-gem5.pdf\n\nAppears to be browser based, so you can zoom in and out, rather than the forced wrapping as for <<gem5-util-o3-pipeview-py-o3-pipeline-viewer>>.\n\nUses the same data source as `util/o3-pipeview.py`.\n\n<<gem5-event-queue-derivo3cpu-syscall-emulation-freestanding-example-analysis-stall-gain>> shows how the text-based visualization can get problematic due to stalls requiring wraparounds.\n\n==== gem5 ARM RSK\n\nhttps://github.com/arm-university/arm-gem5-rsk/blob/aa3b51b175a0f3b6e75c9c856092ae0c8f2a7cdc/gem5_rsk.pdf\n\nDated 2017, it contains a good overview of gem5 CPUs.\n\n=== gem5 ARM platforms\n\nThe gem5 platform is selectable with the `--machine` option, which is named after the analogous QEMU `-machine` option, and which sets the `--machine-type`.\n\nEach platform represents a different system with different devices, memory and interrupt setup.\n\nTODO: describe the main characteristics of each platform, as of gem5 5e83d703522a71ec4f3eb61a01acd8c53f6f3860:\n\n* `VExpress_GEM5_V1`: good sane base platform\n* `VExpress_GEM5_V1_DPU`: `VExpress_GEM5_V1` with DP650 instead of HDLCD, selected automatically by `./run --dp650`, see also: <<gem5-graphic-mode-dp650>>\n* `VExpress_GEM5_V2`: VExpress_GEM5_V1 with GICv3, uses a different bootloader `arm/aarch64_bootloader/boot_emm_v2.arm64` TODO is it because of GICv3?\n* anything that does not start with: `VExpress_GEM5_`: old and bad, don't use them\n\n=== gem5 upstream images\n\nPresent at:\n\n* http://www.gem5.org/dist/current/arm/\n* http://www.gem5.org/dist/current/x86/\n\nDepending on which archive you download from there, you can find some of:\n\n* Ubuntu based images\n* precompiled Linux kernels, with the <<gem5-arm-linux-kernel-patches>> for arm\n* precompiled <<gem5-bootloaders>> for ISAs that have them, e.g. ARM\n* precompiled DTBs if you don't want to use autogeneration for some crazy reason\n\nSome of those images are also used on the <<gem5-unit-tests>> continuous integration.\n\nCould be used as an alternative to this repository. But why would you do that? :-)\n\nE.g. to use a precompiled ARM kernel:\n\n....\nmkdir aarch-system-201901106\ncd aarch-system-201901106\nwget http://dist.gem5.org/dist/current/arm/aarch-system-201901106.tar.bz2\ntar xvf aarch-system-201901106.tar.bz2\ncd ..\n./run --arch aarch64 --emulator gem5 --linux-exec aarch-system-201901106/binaries/vmlinux.arm64\n....\n\n=== gem5 bootloaders\n\nCertain ISAs like ARM have bootloaders that are automatically run before the main image to setup basic system state.\n\nWe cross compile those bootloaders from source automatically during `./build-gem5`.\n\nAs of gem5 bcf041f257623e5c9e77d35b7531bae59edc0423, the source code of the bootloaderes can be found under:\n\n....\nsystem/arm/\n....\n\nand their selection can be seen under: `src/dev/arm/RealView.py`, e.g.:\n\n....\n    def setupBootLoader(self, cur_sys, loc):\n        if not cur_sys.boot_loader:\n            cur_sys.boot_loader = [ loc('boot_emm.arm64'), loc('boot_emm.arm') ]\n....\n\nThe bootloader basically just sets up a bit of CPU state and jumps to the kernel entry point.\n\nIn aarch64 at least, CPUs other than CPU0 are also started up briefly, run some initialization, and are made wait on a WFE. This can be seen easily by booting a multicore Linux kernel run with <<gem5-execall-trace-format>>.\n\n=== gem5 memory system\n\nParent section: <<gem5-internals>>.\n\n==== gem5 port system\n\nThe gem5 memory system is connected in a very flexible way through the port system.\n\nThis system exists to allow seamlessly connecting any combination of CPU, caches, interconnects, DRAM and peripherals.\n\nA <<gem5-packet,`Packet`>> is the basic information unit that gets sent across ports.\n\n===== gem5 functional vs atomic vs timing memory requests\n\ngem5 memory requests can be classified in the following broad categories:\n\n* functional: get the value magically, do not update caches, see also: <<gem5-functional-requests>>\n* atomic: get the value now without making a <<gem5-event-queue,separate event>>, but do not update caches. Cannot work in <<gem5-ruby-build,Ruby>> due to fundamental limitations, mentioned in passing at: https://gem5.atlassian.net/browse/GEM5-676\n* timing: get the value simulating delays and updating caches\n\nThis trichotomy can be notably seen in the definition of the https://github.com/gem5/gem5/blob/9fc9c67b4242c03f165951775be5cd0812f2a705/src/mem/port.hh#L75[MasterPort class]:\n\n....\nclass MasterPort : public Port, public AtomicRequestProtocol,\n    public TimingRequestProtocol, public FunctionalRequestProtocol\n....\n\nand the base classes are defined under `src/mem/protocol/`.\n\nThen, by reading the rest of the class, we see that the send methods are all boring, and just forward to some polymorphic receiver that does the actual interesting activity:\n\n....\n    Tick\n    sendAtomicSnoop(PacketPtr pkt)\n    {\n        return AtomicResponseProtocol::sendSnoop(_masterPort, pkt);\n    }\n\n    Tick\n    AtomicResponseProtocol::sendSnoop(AtomicRequestProtocol *peer, PacketPtr pkt)\n    {\n        assert(pkt->isRequest());\n        return peer->recvAtomicSnoop(pkt);\n    }\n....\n\nThe receive methods are therefore the interesting ones, and must be overridden on derived classes if they ever expect to receive such requests:\n\n....\n    Tick\n    recvAtomicSnoop(PacketPtr pkt) override\n    {\n        panic(\"%s was not expecting an atomic snoop request\\n\", name());\n        return 0;\n    }\n\n    void\n    recvFunctionalSnoop(PacketPtr pkt) override\n    {\n        panic(\"%s was not expecting a functional snoop request\\n\", name());\n    }\n\n    void\n    recvTimingSnoopReq(PacketPtr pkt) override\n    {\n        panic(\"%s was not expecting a timing snoop request.\\n\", name());\n    }\n....\n\nOne question that comes up now is: but why do CPUs need to care about <<cache-coherence,snoop requests>>?\n\nAnd one big answer is: to be able to implement LLSC atomicity as mentioned at: <<arm-ldxr-and-stxr-instructions>>, since when other cores update memory, they could invalidate the lock of the current core.\n\nThen, as you might expect, we can see that for example `AtomicSimpleCPU` does not override `recvTimingSnoopReq`.\n\nNow let see which requests are generated by ordinary <<arm-ldr-instruction>>. We run:\n\n....\n./run \\\n  --arch aarch64 \\\n  --debug-vm \\\n  --emulator gem5 \\\n  --gem5-build-type debug \\\n  --useland userland/arch/aarch64/freestanding/linux/hello.S \\\n....\n\nand then break at the methods of the LDR class `LDRXL64_LIT`: <<gem5-execute-vs-initiateacc-vs-completeacc>>.\n\nBefore starting, we of course guess that:\n\n* `AtomicSimpleCPU` will be making atomic accesses from `execute`\n* `TimingSimpleCPU` will be making timing accesses from `initiateAcc`, which must generate the event which leads to `completeAcc`\n\nso let's confirm it.\n\nWe break on `ArmISAInst::LDRXL64_LIT::execute` which is what `AtomicSimpleCPU` uses, and that leads as expected to:\n\n....\nMasterPort::sendAtomic\nAtomicSimpleCPU::sendPacket\nAtomicSimpleCPU::readMem\nSimpleExecContext::readMem\nreadMemAtomic<(ByteOrder)1, ExecContext, unsigned long>\nreadMemAtomicLE<ExecContext, unsigned long>\nArmISAInst::LDRXL64_LIT::execute\nAtomicSimpleCPU::tick\n....\n\nNotably, `AtomicSimpleCPU::readMem` immediately translates the address, creates a packet, sends the atomic request, and gets the response back without any events.\n\nAnd now if we do the same with `--cpu-type TimingSimpleCPU` and break at `ArmISAInst::LDRXL64_LIT::initiateAcc`, and then add another break for the next event schedule `b EventManager::schedule` (which we imagine is the memory read) we reach:\n\n....\nEventManager::schedule\nDRAMCtrl::addToReadQueue\nDRAMCtrl::recvTimingReq\nDRAMCtrl::MemoryPort::recvTimingReq\nTimingRequestProtocol::sendReq\nMasterPort::sendTimingReq\nCoherentXBar::recvTimingReq\nCoherentXBar::CoherentXBarSlavePort::recvTimingReq\nTimingRequestProtocol::sendReq\nMasterPort::sendTimingReq\nTimingSimpleCPU::handleReadPacket\nTimingSimpleCPU::sendData\nTimingSimpleCPU::finishTranslation\nDataTranslation<TimingSimpleCPU*>::finish\nArmISA::TLB::translateComplete\nArmISA::TLB::translateTiming\nArmISA::TLB::translateTiming\nTimingSimpleCPU::initiateMemRead\nSimpleExecContext::initiateMemRead\ninitiateMemRead<ExecContext, unsigned long>\nArmISAInst::LDRXL64_LIT::initiateAcc\nTimingSimpleCPU::completeIfetch\nTimingSimpleCPU::IcachePort::ITickEvent::process\nEventQueue::serviceOne\n....\n\nso as expected we have `TimingRequestProtocol::sendReq`.\n\nRemember however that timing requests are a bit more complicated due to <<arm-paging,paging>>, since the page table walk can itself lead to further memory requests.\n\nIn this particular instance, the address being read with `ldr x2, =len` <<arm-ldr-pseudo-instruction>> is likely placed just after the text section, and therefore the pagewalk is already in the TLB due to previous instruction fetches, and this is because the translation just finished immediately going through `TimingSimpleCPU::finishTranslation`, some key snippets are:\n\n....\nTLB::translateComplete(const RequestPtr &req, ThreadContext *tc,\n        Translation *translation, Mode mode, TLB::ArmTranslationType tranType,\n        bool callFromS2)\n{\n    bool delay = false;\n    Fault fault;\n    if (FullSystem)\n        fault = translateFs(req, tc, mode, translation, delay, true, tranType);\n    else\n        fault = translateSe(req, tc, mode, translation, delay, true);\n    if (!delay)\n        translation->finish(fault, req, tc, mode);\n    else\n        translation->markDelayed();\n....\n\nand then `translateSe` does not use `delay` at all, so we learn that in syscall emulation, `delay` is always `false` and things progress immediately there. And then further down `TimingSimpleCPU::finishTranslation` does some more fault checking:\n\n....\nvoid\nTimingSimpleCPU::finishTranslation(WholeTranslationState *state)\n{\n    if (state->getFault() != NoFault) {\n        translationFault(state->getFault());\n    } else {\n        if (!state->isSplit) {\n            sendData(state->mainReq, state->data, state->res,\n                     state->mode == BaseTLB::Read);\n....\n\n\nTested in gem5 b1623cb2087873f64197e503ab8894b5e4d4c7b4.\n\n====== gem5 functional requests\n\nAs seen at <<gem5-functional-vs-atomic-vs-timing-memory-requests>>, functional requests are not used in common simulation, since the core must always go through caches.\n\nFunctional access are therefore only used for more magic simulation functionalities.\n\nOne such functionality, is the <<gem5-syscall-emulation-mode>> implementation of the <<futex-system-call>> which is done at `futexFunc` in https://github.com/gem5/gem5/blob/9fc9c67b4242c03f165951775be5cd0812f2a705/src/sim/syscall_emul.hh#L394[`src/sim/sycall_emul.hh`].\n\nAs seen from `man futex`, the Linux kernel reads the value from an address that is given as the first argument of the call.\n\nTherefore, here it makes sense for gem5 syscall implementation, which does not actually have a real kernel running, to just make a functional request and be done with it, since the impact of cache changes done by this read would be insignificant to the cost of an actual full context switch that would happen on a real syscall.\n\nIt is generally hard to implement functional requests for <<gem5-ruby-build,Ruby>> runs, because packets are flying through the memory system in a transient state, and there is no simple way of finding exactly which ones might have the latest version of the memory. See for example:\n\n* https://gem5.atlassian.net/browse/GEM5-496\n* https://gem5.atlassian.net/browse/GEM5-604\n* https://gem5.atlassian.net/browse/GEM5-675\n* https://gem5.atlassian.net/browse/GEM5-676\n\nThe typical error message in that case is:\n\n....\nfatal: Ruby functional read failed for address\n....\n\n==== gem5 `Packet` vs `Request`\n\n===== gem5 `Packet`\n\n`Packet` is what goes through <<gem5-port-system,ports>>: a single packet is sent out to the memory system, gets modified when it hits valid data, and then returns with the reply.\n\n`Packet` is what CPUs create and send to get memory values. E.g. on <<gem5-atomicsimplecpu>>:\n\n....\nvoid\nAtomicSimpleCPU::tick()\n{\n    ...\n    Packet ifetch_pkt = Packet(ifetch_req, MemCmd::ReadReq);\n    ifetch_pkt.dataStatic(&inst);\n\n    icache_latency = sendPacket(icachePort, &ifetch_pkt);\n\nTick\nAtomicSimpleCPU::sendPacket(MasterPort &port, const PacketPtr &pkt)\n{\n    return port.sendAtomic(pkt);\n}\n....\n\nOn <<gem5-timingsimplecpu,TimingSimpleCPU>>, we note that the packet is dynamically created unlike for the AtomicSimpleCPU, since it must exist across multiple <<gem5-event-queue,events>> which happen on separate function calls, unlike atomic memory which is done immediately in a single call:\n\n....\nvoid\nTimingSimpleCPU::sendFetch(const Fault &fault, const RequestPtr &req,\n                           ThreadContext *tc)\n{\n    if (fault == NoFault) {\n        DPRINTF(SimpleCPU, \"Sending fetch for addr %#x(pa: %#x)\\n\",\n                req->getVaddr(), req->getPaddr());\n        ifetch_pkt = new Packet(req, MemCmd::ReadReq);\n        ifetch_pkt->dataStatic(&inst);\n        DPRINTF(SimpleCPU, \" -- pkt addr: %#x\\n\", ifetch_pkt->getAddr());\n\n        if (!icachePort.sendTimingReq(ifetch_pkt)) {\n....\n\nIt must later delete the return packet that it gets later on, e.g. for the ifetch:\n\n....\nTimingSimpleCPU::completeIfetch(PacketPtr pkt)\n{\n    if (pkt) {\n        delete pkt;\n    }\n....\n\nThe most important properties of a Packet are:\n\n* `PacketDataPtr data;`: the data coming back from a reply packet or being sent via it\n* `Addr addr;`: the physical address of the data. TODO comment says could be virtual too, when?\n+\n....\n/// The address of the request.  This address could be virtual or\n/// physical, depending on the system configuration.\nAddr addr;\n....\n* `Flags flags;`: flags describing properties of the `Packet`\n* `MemCmd cmd;`: see <<gem5-memcmd>>\n\n====== gem5 `MemCmd`\n\nEach <<gem5-packet>> contains a `MemCmd`\n\nThe `MemCmd` is basically an enumeration of possible commands, stuff like:\n\n....\nenum Command\n{\n    InvalidCmd,\n    ReadReq,\n    ReadResp,\n....\n\nEach command has a fixed number of attributes defined in the static array:\n\n....\nstatic const CommandInfo commandInfo[];\n....\n\nwhich gets initialized in the .cc file in the same order as the Command enum.\n\n....\nconst MemCmd::CommandInfo\nMemCmd::commandInfo[] =\n{\n    /* InvalidCmd */\n    { 0, InvalidCmd, \"InvalidCmd\" },\n    /* ReadReq - Read issued by a non-caching agent such as a CPU or\n     * device, with no restrictions on alignment. */\n    { SET3(IsRead, IsRequest, NeedsResponse), ReadResp, \"ReadReq\" },\n    /* ReadResp */\n    { SET3(IsRead, IsResponse, HasData), InvalidCmd, \"ReadResp\" },\n....\n\nFrom this we see for example that both `ReadReq` and `ReadResp` are marked with the `IsRead` attribute.\n\nThe second field of this array also specifies the corresponding reply of each request. E.g. the reply of a `ReadReq` is a `ReadResp`. `InvalidCmd` is just a placeholders for requests that are already replies.\n\n....\nstruct CommandInfo\n{\n    /// Set of attribute flags.\n    const std::bitset<NUM_COMMAND_ATTRIBUTES> attributes;\n    /// Corresponding response for requests; InvalidCmd if no\n    /// response is applicable.\n    const Command response;\n    /// String representation (for printing)\n    const std::string str;\n};\n....\n\nSome important commands include:\n\n* `ReadReq`: what the CPU sends out to its cache, see also: <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>\n* `ReadSharedReq`: what dcache of the CPU sends forward to the <<gem5-crossbar-interconnect>> after a `ReadReq`, see also: see also: <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>\n* `ReadResp`: response to a `ReadReq`. Can come from either DRAM or another cache that has the data. On <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>> we see that a new packet is created.\n* `WriteReq`: what the CPU sends out to its cache, see also: <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>\n* `UpgradeReq`: what dcache of CPU sends forward after a `WriteReq`\n\n===== gem5 `Request`\n\nOne good way to think about `Request` vs `Packet` could be \"it is what the <<gem5-instruction-definitions,instruction definitions>> see\", a bit like `ExecContext` vs `ThreadContext`.\n\n`Request` is passed to the constructor of `Packet`, and `Packet` keeps a reference to it:\n\n....\n    Packet(const RequestPtr &_req, MemCmd _cmd)\n        :  cmd(_cmd), id((PacketId)_req.get()), req(_req),\n           data(nullptr), addr(0), _isSecure(false), size(0),\n           _qosValue(0), headerDelay(0), snoopDelay(0),\n           payloadDelay(0), senderState(NULL)\n    {\n        if (req->hasPaddr()) {\n            addr = req->getPaddr();\n            flags.set(VALID_ADDR);\n            _isSecure = req->isSecure();\n        }\n        if (req->hasSize()) {\n            size = req->getSize();\n            flags.set(VALID_SIZE);\n        }\n    }\n....\n\nwhere `RequestPtr` is defined as:\n\n....\ntypedef std::shared_ptr<Request> RequestPtr;\n....\n\nso we see that shared pointers to requests are basically passed around.\n\nSome key fields include:\n\n* `_paddr`:\n+\n....\n/**\n    * The physical address of the request. Valid only if validPaddr\n    * is set.\n    */\nAddr _paddr = 0;\n....\n* `_vaddr`:\n+\n....\n/** The virtual address of the request. */\nAddr _vaddr = MaxAddr;\n....\n\n====== gem5 `Request` in `AtomicSimpleCPU`\n\nIn `AtomicSimpleCPU`, a single packet of each type is kept for the entire CPU, e.g.:\n\n....\nRequestPtr ifetch_req;\n....\n\nand it gets created at construction time:\n\n....\nAtomicSimpleCPU::AtomicSimpleCPU(AtomicSimpleCPUParams *p)\n{\n    ifetch_req = std::make_shared<Request>();\n....\n\nand then it gets modified for each request:\n\n....\nsetupFetchRequest(ifetch_req);\n....\n\nwhich does:\n\n....\nreq->setVirt(fetchPC, sizeof(MachInst), Request::INST_FETCH,\n                instMasterId(), instAddr);\n....\n\nVirtual to physical address translation done by the CPU stores the physical address:\n\n....\nfault = thread->dtb->translateAtomic(req, thread->getTC(),\n                                        BaseTLB::Read);\n....\n\nwhich eventually calls e.g. on fs with MMU enabled:\n\n....\nFault\nTLB::translateMmuOn(ThreadContext* tc, const RequestPtr &req, Mode mode,\n                    Translation *translation, bool &delay, bool timing,\n                    bool functional, Addr vaddr,\n                    ArmFault::TranMethod tranMethod)\n{\n    req->setPaddr(pa);\n....\n\n====== gem5 `Request` in `TimingSimpleCPU`\n\nIn <<gem5-timingsimplecpu,TimingSimpleCPU>>, the request gets created per memory read:\n\n....\nFault\nTimingSimpleCPU::initiateMemRead(Addr addr, unsigned size,\n                                 Request::Flags flags,\n                                 const std::vector<bool>& byte_enable)\n{\n    ...\n    RequestPtr req = std::make_shared<Request>(\n        addr, size, flags, dataMasterId(), pc, thread->contextId());\n....\n\nand from <<gem5-functional-vs-atomic-vs-timing-memory-requests>> and <<gem5-functional-vs-atomic-vs-timing-memory-requests>> we remember that `initiateMemRead` is actually started from the `initiateAcc` instruction definitions for timing:\n\n....\nFault LDRWL64_LIT::initiateAcc(ExecContext *xc,\n    Trace::InstRecord *traceData) const\n{\n    ...\n    fault = initiateMemRead(xc, traceData, EA, Mem, memAccessFlags);\n....\n\nFrom this we see that `initiateAcc` memory instructions are basically extracting the required information for the request, notably the address `EA` and flags.\n\n==== gem5 `MSHR`\n\nMentioned at: http://pages.cs.wisc.edu/~swilson/gem5-docs/gem5MemorySystem.html\n\nEach cache object owns a `MSHRQueue`:\n\n....\nclass BaseCache : public ClockedObject\n{\n    /** Miss status registers */\n    MSHRQueue mshrQueue;\n....\n\n`BaseCache` is the base class of `Cache` and `NoncoherentCache`.\n\n`MSHRQueue` is a `Queue` of `MSHR`:\n\n....\nclass MSHRQueue : public Queue<MSHR>\n....\n\nand Queue is also a gem5 class under `src/mem/cache/queue.hh`.\n\nThe MSHR basically keeps track of all information the cache receives, and helps it take appropriate action. I'm not sure why it is separate form the cache at all, as it is basically performing essential cache bookkeeping.\n\nA clear example of MSHR in action can be seen at: <<gem5-event-queue-timingsimplecpu-syscall-emulation-freestanding-example-analysis-with-caches-and-multiple-cpus>>. In that example what happened was:\n\n* CPU1 writes to an address and it completes\n* CPU2 sends read\n* CPU1 writes to the address again\n* CPU2 snoops the write, and notes it down in its MSHR\n* CPU2 receives a snoop reply for its read, also from CPU1 which has the data and the line becomes valid\n* CPU2 gets its data. But the MSHR remembers that it had also received a write snoop, so it also immediately invalidates that line\n\nFrom this we understand that MSHR is the part of the cache that synchronizes stuff pending snoops and ensures that things get invalidated.\n\n==== gem5 `CommMonitor`\n\nYou can place this <<gem5-python-c-interaction,SimObject>> in between two <<gem5-port-system,ports>> to get extra statistics about the packets that are going through.\n\nIt only works on <<gem5-functional-vs-atomic-vs-timing-memory-requests,timing requests>>, and does not seem to dump any memory values, only add extra <<gem5-m5out-stats-txt-file,statistics>>.\n\nFor example, the patch link:patches/manual/gem5-commmonitor-se.patch[] hack a `CommMonitor` between the CPU and the L1 cache on top of gem5 1c3662c9557c85f0d25490dc4fbde3f8ab0cb350:\n\n....\npatch -d \"$(./getvar gem5_source_dir)\" -p 1 < patches/manual/gem5-commmonitor-se.patch\n....\n\nThat patch was done largely by copying what `fs.py --memcheck` does with a `MemChecker` object.\n\nYou can then run with:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  -- \\\n  --caches \\\n  --cpu-type TimingSimpleCPU \\\n;\n....\n\nand now we have some new extra histogram statistics such as:\n\n....\nsystem.cpu.dcache_mon.readBurstLengthHist::samples            1\n....\n\nOne neat thing about this is that it is agnostic to the memory object type, so you don't have to recode those statistics for every new type of object that operates on memory packets.\n\n==== gem5 `SimpleMemory`\n\n`SimpleMemory` is a highly simplified memory system. It can replace a more complex DRAM model if you use it e.g. as:\n\n....\n./run --emulator gem5 -- --mem-type SimpleMemory\n....\n\nand it also gets used in certain system-y memories present in ARM systems by default e.g. Flash memory:\n\n....\n[system.realview.flash0]\ntype=SimpleMemory\n....\n\nAs of gem5 3ca404da175a66e0b958165ad75eb5f54cb5e772 LKMC 059a7ef9d9c378a6d1d327ae97d90b78183680b2 it did not provide any speedup to the Linux kernel boot according to a quick test.\n\n=== gem5 internals\n\nInternals under other sections:\n\n* <<gem5-memory-system>>\n* <<gem5-trace-internals>>\n* <<gem5-checkpoint-internals>>\n* <<gem5-graphic-mode-internals>>\n\n==== gem5 Eclipse configuration\n\nhttps://stackoverflow.com/questions/61656709/how-to-setup-eclipse-ide-for-gem5-development\n\nIn order to develop complex C++ software such as gem5, a good IDE setup is fundamental.\n\nThe best setup I've reached is with Eclipse. It is not perfect, and there is a learning curve, but is worth it.\n\nNotably, it is very hard to get perfect due to: <<why-are-all-c-symlinked-into-the-gem5-build-dir>>.\n\nI recommend the following settings, tested in Eclipse 2019.09, Ubuntu 18.04:\n\n* fix all missing stdlib headers: https://stackoverflow.com/questions/10373788/how-to-solve-unresolved-inclusion-iostream-in-a-c-file-in-eclipse-cdt/51099533#51099533\n* use spaces instead of tabs: Window, Preferences, Code Style, C/C++, Formatter, New, Edit, Tab Policy, Spaces Only\n* either\n** create the project in the gem5 build directory! Files are moved around there and symlinked, and this gives the best chances of success\n** add to the include search path:\n*** ./src/ in the source tree\n*** the ISA specific build directory which contains some self-generated stuff, e.g.: out/gem5/default/build/ARM\n\nTo run and GDB step debug the executable, just copy the <<dry-run,full command line without newlines>> from your run command (Eclipse does not like newlines for the arguments), e.g.:\n\n....\n./run --emulator gem5 --print-cmd-oneline\n....\n\nand configure it into Eclipse as usual.\n\nOne downside of this setup is that if you want to nuke your build directory to get a clean build, then the Eclipse configuration files present in it might get deleted. Maybe it is possible to store configuration files outside of the directory, but we are now mitigating that by making a backup copy of those configuration files before removing the directory, and restoring it when you do `./build-gem --clean`.\n\n==== gem5 Python C++ interaction\n\nThe interaction uses the Python C extension interface https://docs.python.org/2/extending/extending.html interface through the <<pybind11>> helper library: https://github.com/pybind/pybind11\n\nThe C++ executable both:\n\n* starts running the Python executable\n* provides Python classes written in C++ for that Python code to use\n\nAn example of this can be found at:\n\n* https://docs.python.org/2/extending/embedding.html#extending-embedded-python\n* https://github.com/pybind/pybind11/tree/v2.2.3/tests/test_embed\n\nthen gem5 magic `SimObject` class adds some crazy stuff on top of it further, is is a mess. In particular, it auto generates `params/` headers. TODO: why is this mess needed at all? pybind11 seems to handle constructor arguments just fine:\n\n* https://github.com/pybind/pybind11/blob/v2.2.3/tests/test_class.py#L77\n* https://github.com/pybind/pybind11/blob/v2.2.3/tests/test_class.cpp#L41\n\nLet's study `BadDevice` for example:\n\n`src/dev/BadDevice.py` defines `devicename`:\n\n....\nclass BadDevice(BasicPioDevice):\n    type = 'BadDevice'\n    cxx_header = \"dev/baddev.hh\"\n    devicename = Param.String(\"Name of device to error on\")\n....\n\nThe object is created in Python for example from `src/dev/alpha/Tsunami.py` as:\n\n....\n    fb = BadDevice(pio_addr=0x801fc0003d0, devicename='FrameBuffer')\n....\n\nSince `BadDevice` has no `+__init__+` method, and neither `BasicPioDevice`, it all just falls through until the `+SimObject.__init__+` constructor.\n\nThis constructor will loop through the inheritance chain and give the Python parameters to the C++ BadDeviceParams class as follows.\n\nThe auto-generated `build/ARM/params/BadDevice.hh` file defines BadDeviceParams in C++:\n\n....\n#ifndef __PARAMS__BadDevice__\n#define __PARAMS__BadDevice__\n\nclass BadDevice;\n\n#include <cstddef>\n#include <string>\n\n#include \"params/BasicPioDevice.hh\"\n\nstruct BadDeviceParams\n    : public BasicPioDeviceParams\n{\n    BadDevice * create();\n    std::string devicename;\n};\n\n#endif // __PARAMS__BadDevice__\n....\n\nand `./python/_m5/param_BadDevice.cc` defines the param Python from C++ with pybind11:\n\n....\nnamespace py = pybind11;\n\nstatic void\nmodule_init(py::module &m_internal)\n{\n    py::module m = m_internal.def_submodule(\"param_BadDevice\");\n    py::class_<BadDeviceParams, BasicPioDeviceParams, std::unique_ptr<BadDeviceParams, py::nodelete>>(m, \"BadDeviceParams\")\n        .def(py::init<>())\n        .def(\"create\", &BadDeviceParams::create)\n        .def_readwrite(\"devicename\", &BadDeviceParams::devicename)\n        ;\n\n    py::class_<BadDevice, BasicPioDevice, std::unique_ptr<BadDevice, py::nodelete>>(m, \"BadDevice\")\n        ;\n\n}\n\nstatic EmbeddedPyBind embed_obj(\"BadDevice\", module_init, \"BasicPioDevice\");\n....\n\n`src/dev/baddev.hh` then uses the parameters on the constructor:\n\n....\nclass BadDevice : public BasicPioDevice\n{\n  private:\n    std::string devname;\n\n  public:\n    typedef BadDeviceParams Params;\n\n  protected:\n    const Params *\n    params() const\n    {\n        return dynamic_cast<const Params *>(_params);\n    }\n\n  public:\n     /**\n      * Constructor for the Baddev Class.\n      * @param p object parameters\n      * @param a base address of the write\n      */\n    BadDevice(Params *p);\n....\n\n`src/dev/baddev.cc` then uses the parameter:\n\n....\nBadDevice::BadDevice(Params *p)\n    : BasicPioDevice(p, 0x10), devname(p->devicename)\n{\n}\n....\n\nIt has been found that this usage of <<pybind11>> across hundreds of `SimObject` files accounted for 50% of the gem5 build time at one point: <<pybind11-accounts-for-50-of-gem5-build-time>>.\n\nTo get a feeling of how `SimObject` objects are run, see: <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis>>.\n\nBibliography:\n\n* https://stackoverflow.com/questions/61910993/viewing-the-parameters-of-the-branch-predictor-in-gem5/61914449#61914449\n* https://stackoverflow.com/questions/62969566/attributes-of-system-object-in-gem5/62970092#62970092\n\nTested on gem5 08c79a194d1a3430801c04f37d13216cc9ec1da3.\n\n==== gem5 entry point\n\nThe main is at: `src/sim/main.cc`. It calls:\n\n....\nret = initM5Python();\n....\n\nsrc/sim/init.cc:\n\n....\n230 int\n231 initM5Python()\n232 {\n233     EmbeddedPyBind::initAll();\n234     return EmbeddedPython::initAll();\n235 }\n....\n\n`initAll` basically just initializes the `_m5` Python object, which is used across multiple `.py`.\n\nBack on `main`:\n\n....\nret = m5Main(argc, argv);\n....\n\nwhich goes to:\n\n....\nresult = PyRun_String(*command, Py_file_input, dict, dict);\n....\n\nwith commands looping over:\n\n....\nimport m5\nm5.main()\n....\n\nwhich leads into:\n\n....\nsrc/python/m5/main.py#main\n....\n\nwhich finally calls your config file like `fs.py` with:\n\n....\nfilename = sys.argv[0]\nfiledata = file(filename, 'r').read()\nfilecode = compile(filedata, filename, 'exec')\n[...]\nexec filecode in scope\n....\n\nTODO: the file path name appears to be passed as a command line argument to the Python script, but I didn't have the patience to fully understand the details.\n\nThe Python config files then set the entire system up in Python, and finally call `m5.simulate()` to run the actual simulation. This function has a C++ native implementation at:\n\n....\nsrc/sim/simulate.cc\n....\n\nand that is where the main event loop, `doSimLoop`, gets called and starts kicking off the <<gem5-event-queue>>.\n\nTested at gem5 b4879ae5b0b6644e6836b0881e4da05c64a6550d.\n\n===== gem5 `m5.objects` module\n\nAll `SimObjects` seem to be automatically added to the `m5.objects` namespace, and this is done in a very convoluted way, let's try to understand a bit:\n\n....\nsrc/python/m5/objects/__init__.py\n....\n\ncontains:\n\n....\nmodules = __loader__.modules\n\nfor module in modules.keys():\n    if module.startswith('m5.objects.'):\n        exec(\"from %s import *\" % module)\n....\n\nAnd from <<debug-gem5-python-scripts,IPDB>> we see that this appears to loop over every object string of type `m5.objects.modulename`.\n\nThis `+__init__+` gets called from `src/python/importer.py` at the `exec`:\n\n....\nclass CodeImporter(object):\n    def load_module(self, fullname):\n            override = os.environ.get('M5_OVERRIDE_PY_SOURCE', 'false').lower()\n            if override in ('true', 'yes') and  os.path.exists(abspath):\n                src = open(abspath, 'r').read()\n                code = compile(src, abspath, 'exec')\n\n            if os.path.basename(srcfile) == '__init__.py':\n                mod.__path__ = fullname.split('.')\n                mod.__package__ = fullname\n            else:\n                mod.__package__ = fullname.rpartition('.')[0]\n            mod.__file__ = srcfile\n\n            exec(code, mod.__dict__)\n\nimport sys\nimporter = CodeImporter()\nadd_module = importer.add_module\nsys.meta_path.append(importer)\n....\n\nHere as a bonus here we also see how <<m5-override-py-source,`M5_OVERRIDE_PY_SOURCE`>> works.\n\nIn `src/SConscript` we see that `SimObject` is just a `PySource` with module equals to `m5.objects`:\n\n....\nclass SimObject(PySource):\n    def __init__(self, source, tags=None, add_tags=None):\n        '''Specify the source file and any tags (automatically in\n        the m5.objects package)'''\n        super(SimObject, self).__init__('m5.objects', source, tags, add_tags)\n....\n\nThe `add_module` method seems to be doing the magic and is called from `src/sim/init.cc`:\n\n....\nbool\nEmbeddedPython::addModule() const\n{\n    PyObject *code = getCode();\n    PyObject *result = PyObject_CallMethod(importerModule, PyCC(\"add_module\"),\n....\n\nwhich is called from:\n\n....\nint\nEmbeddedPython::initAll()\n{\n    // Load the importer module\n    PyObject *code = importer->getCode();\n    importerModule = PyImport_ExecCodeModule(PyCC(\"importer\"), code);\n    if (!importerModule) {\n        PyErr_Print();\n        return 1;\n    }\n\n    // Load the rest of the embedded python files into the embedded\n    // python importer\n    list<EmbeddedPython *>::iterator i = getList().begin();\n    list<EmbeddedPython *>::iterator end = getList().end();\n    for (; i != end; ++i)\n        if (!(*i)->addModule())\n....\n\nand `getList` comes from:\n\n....\nEmbeddedPython::EmbeddedPython(const char *filename, const char *abspath,\n    const char *modpath, const unsigned char *code, int zlen, int len)\n    : filename(filename), abspath(abspath), modpath(modpath), code(code),\n      zlen(zlen), len(len)\n{\n    // if we've added the importer keep track of it because we need it\n    // to bootstrap.\n    if (string(modpath) == string(\"importer\"))\n        importer = this;\n    else\n        getList().push_back(this);\n}\n\nlist<EmbeddedPython *> &\nEmbeddedPython::getList()\n{\n    static list<EmbeddedPython *> the_list;\n    return the_list;\n}\n....\n\nand the constructor in turn gets called from per `SimObject` autogenerated files such as e.g. `dev/storage/Ide.py.cc` for `src/dev/storage/Ide.py`:\n\n....\nEmbeddedPython embedded_m5_objects_Ide(\n    \"m5/objects/Ide.py\",\n    \"/home/ciro/bak/git/linux-kernel-module-cheat/data/gem5/master4/src/dev/storage/Ide.py\",\n    \"m5.objects.Ide\",\n    data_m5_objects_Ide,\n    947,\n    2099);\n\n} // anonymous namespace\n....\n\nwhich get autogenerated at `src/SConscript`:\n\n....\ndef embedPyFile(target, source, env):\n\nfor source in PySource.all:\n    base_py_env.Command(source.cpp, [ py_marshal, source.tnode ],\n                        MakeAction(embedPyFile, Transform(\"EMBED PY\")))\n....\n\nwhere the `PySource.all` thing as you might expect is a static list of all `PySource` source files as they get updated in the constructor.\n\nTested in gem5 d9cb548d83fa81858599807f54b52e5be35a6b03.\n\n==== gem5 event queue\n\ngem5 is an event based simulator, and as such the event queue is of of the crucial elements in the system.\n\nEvery single action that takes time (e.g. notably <<timingsimplecpu-analysis-ldr-stall,reading from memory>>) models that time delay by scheduling an event in the future.\n\nThe gem5 event queue stores one callback event for each future point in time.\n\nThe event queue is implemented in the class `EventQueue` in the file `src/sim/eventq.hh`.\n\nNot all times need to have an associated event: if a given time has no events, gem5 just skips it and jumps to the next event: the queue is basically a linked list of events.\n\nImportant examples of events include:\n\n* CPU ticks\n* peripherals and memory\n\nAt <<gem5-event-queue-atomicsimplecpu-syscall-emulation-freestanding-example-analysis>> we see for example that at the beginning of an <<gem5-atomicsimplecpu,AtomicCPU>> simulation, gem5 sets up exactly two events:\n\n* the first CPU cycle\n* one exit event at the end of time which triggers <<gem5-simulate-limit-reached>>\n\nThen, at the end of the callback of one tick event, another tick is scheduled.\n\nAnd so the simulation progresses tick by tick, until an exit event happens.\n\nThe `EventQueue` class has one awesome `dump()` function that prints a human friendly representation of the queue, and can be easily called from GDB. TODO example.\n\nWe can also observe what is going on in the event queue with the `Event` <<gem5-tracing,debug flag>>.\n\nEvent execution is done at `EventQueue::serviceOne()`:\n\n....\nEvent *exit_event = eventq->serviceOne();\n....\n\nThis calls the `Event::process` method of the event.\n\nAnother important technique is to use <<debug-the-emulator,GDB>> and break at interesting points such as:\n\n....\nb Trace::OstreamLogger::logMessage\nb EventManager::schedule\nb EventFunctionWrapper::process\n....\n\nalthough stepping into `EventFunctionWrapper::process` which does `std::function` is a bit of a pain: https://stackoverflow.com/questions/59429401/how-to-step-into-stdfunction-user-code-from-c-functional-with-gdb\n\nAnother potentially useful technique is to use:\n\n....\n--trace Event,ExecAll,FmtFlag,FmtStackTrace --trace-stdout\n....\n\nwhich automates the logging of `Trace::OstreamLogger::logMessage()` backtraces.\n\nBut alas, it misses which function callback is being scheduled, which is the awesome thing we actually want:\n\n* https://stackoverflow.com/questions/37545327/get-the-name-of-a-stdfunction\n* https://stackoverflow.com/questions/40706805/how-to-convert-a-function-pointer-to-function-name/40706869\n\nThen, once we had that, the most perfect thing ever would be to make the full event graph containing which events schedule which events!\n\n===== gem5 event queue AtomicSimpleCPU syscall emulation freestanding example analysis\n\nLet's now analyze every single event on a minimal <<gem5-syscall-emulation-mode>> in the <<gem5-cpu-types,simplest CPU that we have>>:\n\n....\n./run \\\n  --arch aarch64 \\\n  --emulator gem5 \\\n  --userland userland/arch/aarch64/freestanding/linux/hello.S \\\n  --trace Event,ExecAll,FmtFlag \\\n  --trace-stdout \\\n;\n....\n\nwhich gives:\n\n....\n      0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 scheduled @ 0\n**** REAL SIMULATION ****\n      0: Event: Event_70: generic 70 scheduled @ 0\ninfo: Entering event queue @ 0.  Starting simulation...\n      0: Event: Event_70: generic 70 rescheduled @ 18446744073709551615\n      0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 0\n      0: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n      0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 500\n    500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 500\n    500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+4    :   adr   x1, #28            : IntAlu :  D=0x0000000000400098  flags=(IsInteger)\n    500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 1000\n   1000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 1000\n   1000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+8    :   ldr   w2, #4194464       : MemRead :  D=0x0000000000000006 A=0x4000a0  flags=(IsInteger|IsMemRef|IsLoad)\n   1000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 1500\n   1500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 1500\n   1500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+12    :   movz   x8, #64, #0       : IntAlu :  D=0x0000000000000040  flags=(IsInteger)\n   1500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 2000\n   2000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 2000\n   2000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+16    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\nhello\n   2000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 2500\n   2500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 2500\n   2500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+20    :   movz   x0, #0, #0        : IntAlu :  D=0x0000000000000000  flags=(IsInteger)\n   2500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 3000\n   3000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 3000\n   3000: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+24    :   movz   x8, #93, #0       : IntAlu :  D=0x000000000000005d  flags=(IsInteger)\n   3000: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 3500\n   3500: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 3500\n   3500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+28    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n   3500: Event: Event_71: generic 71 scheduled @ 3500\n   3500: Event: Event_71: generic 71 executed @ 3500\n....\n\nOn the event trace, we can first see:\n\n....\n0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 scheduled @ 0\n....\n\nThis schedules a tick event for time `0`, and leads to the first clock tick.\n\nThen:\n\n....\n0: Event: Event_70: generic 70 scheduled @ 0\n0: Event: Event_70: generic 70 rescheduled @ 18446744073709551615\n....\n\nschedules the end of time event for time `0`, which is later rescheduled to the actual end of time.\n\nAt:\n\n....\n0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 executed @ 0\n0: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue    :   movz   x0, #1, #0        : IntAlu :  D=0x0000000000000001  flags=(IsInteger)\n0: Event: AtomicSimpleCPU tick.wrapped_function_event: EventFunctionWrapped 39 rescheduled @ 500\n....\n\nthe tick event happens, the instruction runs, and then the instruction is rescheduled in `500` time units. This is done at the end of `AtomicSimpleCPU::tick()`:\n\n....\nif (_status != Idle)\n    reschedule(tickEvent, curTick() + latency, true);\n....\n\nAt:\n\n....\n3500: ExecEnable: system.cpu: A0 T0 : @asm_main_after_prologue+28    :   svc   #0x0               : IntAlu :   flags=(IsSerializeAfter|IsNonSpeculative|IsSyscall)\n3500: Event: Event_71: generic 71 scheduled @ 3500\n3500: Event: Event_71: generic 71 executed @ 3500\n....\n\nthe exit system call is called, and then it schedules an exit evit, which gets executed and the simulation ends.\n\nWe guess then that `Event_71` comes from the SE implementation of the exit syscall, so let's just confirm, the trace contains:\n\n....\nexitSimLoop() at sim_events.cc:97 0x5555594746e0\nexitImpl() at syscall_emul.cc:215 0x55555948c046\nexitFunc() at syscall_emul.cc:225 0x55555948c147\nSyscallDesc::doSyscall() at syscall_desc.cc:72 0x5555594949b6\nProcess::syscall() at process.cc:401 0x555559484717\nSimpleThread::syscall() at 0x555559558059\nArmISA::SupervisorCall::invoke() at faults.cc:856 0x5555572950d7\nBaseSimpleCPU::advancePC() at base.cc:681 0x555559083133\nAtomicSimpleCPU::tick() at atomic.cc:757 0x55555907834c\n....\n\nand `exitSimLoop()` does:\n\n....\nnew GlobalSimLoopExitEvent(when + simQuantum, message, exit_code, repeat);\n....\n\nTested in gem5 12c917de54145d2d50260035ba7fa614e25317a3.\n\n====== AtomicSimpleCPU initial events\n\nLet's have a closer loo"
        },
        {
          "name": "_config.yml",
          "type": "blob",
          "size": 0.0771484375,
          "content": "exclude: [\n  data/,\n  out/,\n  rootfs_overlay/etc/ld.so.cache,\n  submodules/,\n]\n"
        },
        {
          "name": "asciidoctor",
          "type": "tree",
          "content": null
        },
        {
          "name": "baremetal",
          "type": "tree",
          "content": null
        },
        {
          "name": "bench-all",
          "type": "blob",
          "size": 3.99609375,
          "content": "#!/usr/bin/env bash\nset -eux\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null && pwd)\"\nbench_all=false\nbench_buildroot_build=false\nbench_buildroot_baseline_build=false\nbench_gem5_build=false\nbench_linux_boot=false\ndefault_arch=x86_64\nupdate_repo=false\nwhile getopts Aa:Bbglu OPT; do\n  case \"$OPT\" in\n    A)\n      bench_all=true\n      ;;\n    a)\n      default_arch=\"$OPTARG\"\n      ;;\n    b)\n      bench_buildroot_build=true\n      ;;\n    B)\n      bench_buildroot_baseline_build=true\n      ;;\n    g)\n      bench_gem5_build=true\n      ;;\n    l)\n      bench_linux_boot=true\n      ;;\n    u)\n      update_repo=true\n      ;;\n    ?)\n      exit 2\n      ;;\n  esac\ndone\nshift \"$(($OPTIND - 1))\"\ncomment=\"${1:-}\"\nif \\\n  ! \"$bench_buildroot_build\" && \\\n  ! \"$bench_buildroot_baseline_build\" && \\\n  ! \"$bench_gem5_build\" && \\\n  ! \"$bench_linux_boot\" \\\n; then\n  bench_all=true\nfi\nif \"$bench_all\"; then\n  bench_buildroot_build=true\n  bench_buildroot_baseline_build=true\n  bench_gem5_build=true\n  bench_linux_boot=true\nfi\ngetvar=\"${root_dir}/getvar\"\n\n# Create output directory.\nbenchmark_repo=\"${root_dir}/../linux-kernel-module-cheat-regression\"\nmkdir -p \"$benchmark_repo\"\nlast_dir=\"$(ls \"$benchmark_repo\" | grep -E '^[0-9]' | tail -n 1)\"\nif [ -n \"$last_dir\" ]; then\n  seq_id=\"$((\"$(echo \"$last_dir\" | sed -E -e 's/_.*//' -e 's/^0*//')\" + 1))\"\nelse\n  seq_id=0\nfi\nseq_id=\"$(printf '%0.4d' \"$seq_id\")\"\ndir_basename=\"${seq_id}_$(\"$getvar\" sha)\"\nnew_dir=\"${benchmark_repo}/${dir_basename}\"\nmkdir \"$new_dir\"\n\ndo_bench_buildroot_build() (\n  arch=\"$default_arch\"\n  build_id=bench\n  if [ \"${1:-}\" = baseline ]; then\n    baseline=--baseline\n    baseline_suffix=-baseline\n  else\n    baseline=\n    baseline_suffix=\n  fi\n  common_build_dir=\"$(\"$getvar\" --arch \"$arch\" --buildroot-build-id \"$build_id\" build_dir)\"\n  common_images_dir=\"$(\"$getvar\" --arch \"$arch\" --buildroot-build-id \"$build_id\" buildroot_images_dir)\"\n  \"${root_dir}/build-buildroot\" --arch \"$arch\" $baseline --buildroot-build-id \"$build_id\" --clean\n  \"${root_dir}/build-buildroot\" --arch \"$arch\" $baseline --buildroot-build-id \"$build_id\" --no-all -- source\n  \"${root_dir}/build-buildroot\" --arch \"$arch\" $baseline --buildroot-build-id \"$build_id\"\n  cp \"${common_build_dir}/build-time.log\" \"${new_dir}/buildroot-build-time-${baseline_suffix}${arch}.log\"\n  wc -c \"${common_images_dir}/\"* > \"${new_dir}/buildroot-image-size-${baseline_suffix}${arch}.log\"\n  \"${root_dir}/build-buildroot\" --arch \"$arch\" $baseline --buildroot-build-id \"$build_id\" --clean\n)\n\nif \"$bench_buildroot_build\"; then\n  do_bench_buildroot_build\nfi\n\nif \"$bench_buildroot_baseline_build\"; then\n  do_bench_buildroot_build baseline\nfi\n\nif \"$bench_gem5_build\"; then\n  common_arch=\"$default_arch\"\n  gem5_build_id=bench\n  common_gem5_build_dir=\"$(\"$getvar\" --arch \"$common_arch\" --gem5-build-id \"$gem5_build_id\" gem5_build_dir)\"\n  common_gem5_source_dir=\"$(\"$getvar\" --arch \"$common_arch\" --gem5-build-id \"$gem5_build_id\" gem5_source_dir)\"\n  results_file=\"${common_gem5_build_dir}/lkmc-bench-build.txt\"\n  git -C \"${common_gem5_source_dir}\" clean -xdf\n  rm -f \"$results_file\"\n  \"${root_dir}/build-gem5\" --arch \"$common_arch\" --clean --gem5-build-id \"$gem5_build_id\"\n  # TODO understand better: --foreground required otherwise we cannot\n  # kill the build with Ctrl+C if something goes wrong, can be minimized to:\n  # bash -c \"eval 'timeout 5 sleep 3'\"\n  \"${root_dir}/bench-cmd\" \"timeout --foreground 900 ./build-gem5 --arch '$common_arch' --gem5-build-id '$gem5_build_id'\" \"$results_file\"\n  cp \"$results_file\" \"${new_dir}/gem5-bench-build-${common_arch}.txt\"\n  git -C \"${common_gem5_source_dir}\" clean -xdf\n  \"${root_dir}/build-gem5\" --arch \"$common_arch\" --clean --gem5-build-id \"$gem5_build_id\"\nfi\n\nif \"$bench_linux_boot\"; then\n  cd \"${root_dir}\"\n  \"${root_dir}/build\" --all-archs all\n  \"${root_dir}/test-boot\" --size 3\n  cp \"$(${root_dir}/getvar test_boot_benchmark_file)\" \"$new_dir\"\nfi\n\nif \"$update_repo\"; then\n  if [ -n \"$comment\" ]; then\n    echo \"$comment\" > \"${new_dir}/README.adoc\"\n  fi\n  echo\n  cd \"$benchmark_repo\"\n  git add .\n  git commit -m \"$dir_basename\"\n  git push\nfi\n"
        },
        {
          "name": "bench-cmd",
          "type": "blob",
          "size": 0.587890625,
          "content": "#!/usr/bin/env bash\n# Benchmark a command as a string and output results\n# to a file with format:\n#\n# cmd <command run>\n# time <time in seconds to finish>\n# exit_status <exit status>\nset -eu\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null && pwd)\"\n# Command to benchmark\ncmd=\"$1\"\nshift\n# Where to append write results to. Default: /dev/null.\nresults_file=\"${1:-/dev/null}\"\nmkdir -p \"$(dirname \"$results_file\")\"\nprintf 'cmd ' >> \"$results_file\"\nenv time --append -f 'time %e' --output=\"$results_file\" \"${root_dir}/eeval\" -a \"$cmd\" \"$results_file\"\nprintf \"exit_status $?\\n\" >> \"$results_file\"\n"
        },
        {
          "name": "bisect-gem5-gdb",
          "type": "blob",
          "size": 0.1875,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#bisection\nset -eu\ncd ../..\n./build-gem5 --arch aarch64 --gem5-build-id bisect\n./test-gdb --arch aarch64 --quit-on-fail\n"
        },
        {
          "name": "bisect-gem5-linux-boot",
          "type": "blob",
          "size": 0.5556640625,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#bisection\nset -eu\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n\"${root_dir}/build-gem5\" --arch aarch64 --gem5-worktree bisect --clean || exit 255\n\"${root_dir}/build-gem5\" --arch aarch64 --gem5-worktree bisect || exit 255\nset +e\n# Setup for quick failures:\n# https://stackoverflow.com/questions/4713088/how-to-use-git-bisect/22592593#22592593\ntimeout 5 \"${root_dir}/run\" --emulator gem5 --gem5-worktree bisect --quit-after-boot \"$@\"\nif [ $? -ne 124 ]; then\n  exit 1\nfi\n"
        },
        {
          "name": "bisect-linux-boot-gem5",
          "type": "blob",
          "size": 0.455078125,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#bisection\nset -eu\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n\"${root_dir}/build-linux\" --clean \"$@\"\n\"${root_dir}/build-linux\" \"$@\"\nset +e\n\"${root_dir}/run\" --quit-after-boot \"$@\" || status=$?\n# https://stackoverflow.com/questions/4713088/how-to-use-git-bisect/22592593#22592593\nif [ \"$status\" -eq 125 ] || [ \"$status\" -gt 127 ]; then\n  status=1\nfi\nexit \"$status\"\n"
        },
        {
          "name": "bisect-qemu-linux-boot",
          "type": "blob",
          "size": 0.326171875,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#bisection\nset -eu\ngit submodule update --recursive\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null 2>&1 && pwd)\"\n\"${root_dir}/build-qemu\" --arch aarch64 --qemu-build-id bisect\n\"${root_dir}/run\" --arch aarch64 --qemu-build-id bisect --quit-after-boot\n"
        },
        {
          "name": "bst-vs-heap-vs-hashmap-gem5-stats",
          "type": "blob",
          "size": 1,
          "content": "#!/usr/bin/env python3\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults={\n                'emulator': 'gem5',\n                'show_time': False,\n            },\n            description='''\\\nConvert a BST vs heap stat file into a gnuplot input\nhttps://cirosantilli.com/linux-kernel-module-cheat#bst-vs-heap-vs-hashmap\n''',\n        )\n\n    def timed_main(self):\n        stats = self.get_stats()\n        it = iter(stats)\n        i = 1\n        for heap_num_cycles in it:\n            try:\n                bst_num_cycles = next(it)\n                hashmap_num_cycles = next(it)\n            except StopIteration:\n                # Automatic dumpstats at end may lead to one extra stat at the end.\n                break\n            print('{} {} {} {}'.format(\n                i,\n                heap_num_cycles,\n                bst_num_cycles,\n                hashmap_num_cycles,\n            ))\n            i += 1\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "bst-vs-heap-vs-hashmap.gnuplot",
          "type": "blob",
          "size": 1.208984375,
          "content": "#!/usr/bin/env gnuplot\n\n# https://cirosantilli.com/linux-kernel-module-cheat#bst-vs-heap-vs-hashmap\n#\n# A stacked plot with a single xlabel as shown at:\n#\n# * https://tex.stackexchange.com/questions/346882/creating-an-equally-distributed-multiplot-with-gnuplottex\n# * http://gnuplot.sourceforge.net/demo_canvas_5.2/layout.html\n#\n# would be even nicer, but it was hard to get right, and this\n# is pretty good already.\n\nset terminal png noenhanced size 800, 1400\nset output input_noext . \".tmp.png\"\nset multiplot layout 5,1 title \"\\nC++ Heap vs BST vs Hash map insert time\" font \",22\"\nset lmargin 12\nset label \"Insert time (ns)\" at screen 0.05,0.5 center front rotate font \",16\"\nset title font \",16\"\nset format y \"%5.0f\"\n\nset title \"Heap (std::priority_queue)\"\nplot input_noext . \".dat\" using 1:2 notitle\n\nset title \"Heap (zoom)\"\nset yrange [0:heap_zoom_max]\nplot input_noext . \".dat\" using 1:2 notitle\n\nset title \"BST (std::set)\"\nset yrange [*:*]\nplot input_noext . \".dat\" using 1:3 notitle\n\nset title \"Hash map (std::unordered_set)\"\nset yrange [*:*]\nplot input_noext . \".dat\" using 1:4 notitle\n\nset xlabel \"Container size\" font \",16\"\nset title \"Hash map (zoom)\"\nset yrange [0:hashmap_zoom_max]\nplot input_noext . \".dat\" using 1:4 notitle\n"
        },
        {
          "name": "build",
          "type": "blob",
          "size": 25.734375,
          "content": "#!/usr/bin/env python3\n\nimport collections\nimport copy\nimport itertools\nimport math\nimport os\nimport platform\nimport re\nimport subprocess\n\nimport cli_function\nimport common\nimport lkmc\nimport shell_helpers\nfrom shell_helpers import LF\n\nclass _Component:\n    '''\n    Yes, we are re-inventing a crappy dependency resolution system,\n    reminiscent of scons or apt or Buildroot. I can't believe it.\n\n    The hard part is that we have optional dependencies as well...\n    e.g. Buildroot optionally depends on m5 to put m5 in the root filesystem,\n    and Buildroot optionally depends on QEMU to build the qcow2 version\n    of the image.\n    '''\n    def __init__(\n        self,\n        build_callback=None,\n        supported_archs=None,\n        dependencies=None,\n        apt_get_pkgs=None,\n        apt_build_deps=None,\n        submodules=None,\n        submodules_shallow=None,\n        python3_pkgs=None,\n        ruby_pkgs=None,\n    ):\n        self.build_callback = build_callback\n        self.supported_archs = supported_archs\n        self.dependencies = dependencies or set()\n        self.apt_get_pkgs = apt_get_pkgs or set()\n        self.apt_build_deps = apt_build_deps or set()\n        self.submodules = submodules or set()\n        self.submodules_shallow = submodules_shallow or set()\n        self.python3_pkgs = python3_pkgs or set()\n        self.ruby_pkgs = ruby_pkgs or set()\n\n    def build(self, arch):\n        if (\n            (self.build_callback is not None) and\n            (self.supported_archs is None or arch in self.supported_archs)\n        ):\n            return self.build_callback()\n        else:\n            # Component that does not build anything itself, only has dependencies.\n            return 0\n\nsubmodule_extra_remotes = {\n    'binutils-gdb': {\n        'up': 'git://sourceware.org/git/binutils-gdb.git',\n    },\n    'buildroot': {\n        'up': 'https://github.com/buildroot/buildroot',\n    },\n    'crosstool-ng': {\n        'up': 'https://github.com/crosstool-ng/crosstool-ng',\n    },\n    'freebsd': {\n        'up': 'https://github.com/freebsd/freebsd',\n    },\n    'gcc': {\n        'up': 'git://gcc.gnu.org/git/gcc.git',\n    },\n    'gem5': {\n        'up': 'https://gem5.googlesource.com/public/gem5',\n    },\n    'glibc': {\n        'up': 'git://sourceware.org/git/glibc.git',\n    },\n    'linux': {\n        # https://cirosantilli.com/linux-kernel-module-cheat#gem5-arm-linux-kernel-patches\n        'gem5-arm': 'https://gem5.googlesource.com/arm/linux',\n        'up': 'git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git',\n    },\n    'qemu': {\n        'up': 'https://git.qemu.org/git/qemu.git',\n    },\n    'xen': {\n        'up': 'git://xenbits.xen.org/xen.git',\n    },\n}\n\nclass Main(common.LkmcCliFunction):\n\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild a component and all its dependencies.\n\nOur build-* scripts don't build any dependencies to make iterative\ndevelopment fast and more predictable.\n\nIt is currently not possible to configure individual components from the command line\nwhen you build with this script. TODO.\n\nWithout any args, build only what is necessary for:\nhttps://cirosantilli.com/linux-kernel-module-cheat#qemu-buildroot-setup\n\n....\n./%(prog)s\n....\n\nThis is equivalent to:\n\n....\n./%(prog)s --arch x86_64 qemu-buildroot\n....\n\nAnother important target is `all`:\n\n....\n./%(prog)s all\n....\n\nThis does not truly build ALL configurations: that would be impractical.\nBut more precisely: build the reference configuration of each major component.\n\nSo e.g.: one config of Linux kernel, Buildroot, gem5 and QEMU.\nDon't do for example all possible gem5 configs: debug, opt and fast,\nas that would be huge. This ensures that every piece of software\nbuilds in at least one config.\n\nTODO looping over emulators is not currently supported by this script, e.g.:\n\n....\n./%(prog)s --arch x86_64 --arch aarch64 all\n....\n\nInstead, for the targets that are emulator dependent, you must select the\ntaret version for the desired emulator, e.g.:\n\n....\n./build --arch aarch64 baremetal-qemu baremetal-gem5\n....\n\nThe reason is that some targets depend on emulator, while others don't,\nso looping over all of them would waste time.\n''',\n        )\n        buildroot_component = _Component(\n            self._build_file('build-buildroot'),\n            submodules_shallow = {\n                'buildroot',\n                'binutils-gdb',\n                'gcc',\n                'glibc',\n            },\n            # https://buildroot.org/downloads/manual/manual.html#requirement\n            apt_get_pkgs={\n                'bash',\n                'bc',\n                'binutils',\n                'build-essential',\n                'bzip2',\n                'cpio',\n                'g++',\n                'gcc',\n                'graphviz',\n                'gzip',\n                'make',\n                'patch',\n                'perl',\n                'python3',\n                'rsync',\n                'sed',\n                'tar',\n                'unzip',\n            },\n            python3_pkgs={\n                # Generate graphs of config.ini under m5out.\n                'matplotlib',\n            },\n        )\n        buildroot_overlay_qemu_component = copy.copy(buildroot_component)\n        # We need to build QEMU before the final Buildroot to get qemu-img.\n        buildroot_overlay_qemu_component.dependencies = ['overlay', 'qemu']\n        buildroot_overlay_gem5_component = copy.copy(buildroot_component)\n        buildroot_overlay_gem5_component.dependencies = ['overlay-gem5']\n        gem5_deps = {\n            'apt_get_pkgs': {\n                # https://askubuntu.com/questions/350475/how-can-i-install-gem5/1275773#1275773\n                'build-essential',\n                'doxygen',\n                'git',\n                'libboost-all-dev',\n                'libelf-dev',\n                'libgoogle-perftools-dev',\n                'libhdf5-serial-dev',\n                'libpng-dev',\n                'libprotobuf-dev',\n                'libprotoc-dev',\n                'lld',\n                'm4',\n                'protobuf-compiler',\n                'python-is-python3',\n                'python3-dev',\n                'python3-pydot',\n                'python3-six',\n                'scons',\n                'zlib1g',\n                'zlib1g-dev',\n\n                # Some extra ones.\n                'device-tree-compiler',\n                'diod',\n                # For prebuilt qcow2 unpack.\n                'qemu-utils',\n                # Otherwise HDF5 not found.\n                'pkg-config',\n            },\n            'python3_pkgs': {\n                # https://cirosantilli.com/linux-kernel-module-cheat#gem5-config-dot\n                'pydot',\n            },\n            'submodules_shallow': {'gem5'},\n        }\n        self.name_to_component_map = {\n            'all': _Component(dependencies=[\n                'qemu-gem5-buildroot',\n                'all-baremetal',\n                'user-mode-qemu',\n                'doc',\n            ]),\n            'all-baremetal': _Component(dependencies=[\n                    'qemu-baremetal',\n                    'gem5-baremetal',\n                    'baremetal-gem5-pbx',\n                ],\n                supported_archs=common.consts['crosstool_ng_supported_archs'],\n            ),\n            'baremetal': _Component(dependencies=[\n                'baremetal-gem5',\n                'baremetal-qemu',\n            ]),\n            'baremetal-qemu': _Component(\n                self._build_file('build-baremetal', emulators=['qemu']),\n                supported_archs=common.consts['crosstool_ng_supported_archs'],\n                dependencies=['crosstool-ng'],\n            ),\n            'baremetal-gem5': _Component(\n                self._build_file('build-baremetal', emulators=['gem5']),\n                supported_archs=common.consts['crosstool_ng_supported_archs'],\n                dependencies=['crosstool-ng'],\n            ),\n            'baremetal-gem5-pbx': _Component(\n                self._build_file('build-baremetal', emulators=['gem5'], machine='RealViewPBX'),\n                supported_archs=common.consts['crosstool_ng_supported_archs'],\n                dependencies=['crosstool-ng'],\n            ),\n            'buildroot': buildroot_component,\n            # We need those to avoid circular dependencies, since we need to run Buildroot\n            # twice: once to get the toolchain, and a second time to put the overlay into\n            # the root filesystem.\n            'buildroot-overlay-qemu': buildroot_overlay_qemu_component,\n            'buildroot-overlay-gem5': buildroot_overlay_gem5_component,\n            'copy-overlay': _Component(\n                self._build_file('copy-overlay'),\n            ),\n            'crosstool-ng': _Component(\n                self._build_file('build-crosstool-ng'),\n                supported_archs=common.consts['crosstool_ng_supported_archs'],\n                # http://crosstool-ng.github.io/docs/os-setup/\n                apt_get_pkgs={\n                    'bison',\n                    'docbook2x',\n                    'flex',\n                    'gawk',\n                    'gcc',\n                    'gperf',\n                    'help2man',\n                    'libncurses5-dev',\n                    'libtool-bin',\n                    'make',\n                    'python3-dev',\n                    'texinfo',\n                },\n                submodules_shallow={'crosstool-ng'},\n            ),\n            'doc': _Component(\n                self._build_file('build-doc'),\n                ruby_pkgs={\n                    'asciidoctor',\n                },\n            ),\n            'gem5': _Component(\n                self._build_file('build-gem5'),\n                **gem5_deps\n            ),\n            'gem5-baremetal': _Component(dependencies=[\n                'gem5',\n                'baremetal-gem5',\n            ]),\n            'gem5-buildroot': _Component(dependencies=[\n                'buildroot-overlay-gem5',\n                'linux',\n                'gem5',\n            ]),\n            'gem5-debug': _Component(\n                self._build_file('build-gem5', gem5_build_type='debug'),\n                **gem5_deps\n            ),\n            'gem5-fast': _Component(\n                self._build_file('build-gem5', gem5_build_type='fast'),\n                **gem5_deps\n            ),\n            'linux': _Component(\n                self._build_file('build-linux'),\n                dependencies={'buildroot'},\n                submodules_shallow={'linux'},\n                apt_get_pkgs={\n                    'bison',\n                    'flex',\n                    # Without this started failing in kernel 4.15 with:\n                    # Makefile:932: *** \"Cannot generate ORC metadata for CONFIG_UNWINDER_ORC=y, please install libelf-dev, libelf-devel or elfutils-libelf-devel\".  Stop.\n                    'libelf-dev',\n                },\n            ),\n            'modules': _Component(\n                self._build_file('build-modules'),\n                dependencies=['buildroot', 'linux'],\n            ),\n            'm5': _Component(\n                self._build_file('build-m5'),\n                dependencies=['buildroot'],\n                submodules_shallow={'gem5'},\n            ),\n            'overlay': _Component(dependencies=[\n                'copy-overlay',\n                'modules',\n                'userland',\n            ]),\n            'overlay-gem5': _Component(dependencies=[\n                'm5',\n                'overlay',\n            ]),\n            'parsec-benchmark': _Component(\n                submodules_shallow={'parsec-benchmark'},\n                dependencies=['buildroot'],\n            ),\n            'qemu': _Component(\n                self._build_file('build-qemu'),\n                apt_build_deps={'qemu'},\n                apt_get_pkgs={\n                    'libsdl2-dev',\n                    'ninja-build',\n                },\n                submodules={'qemu'},\n            ),\n            'qemu-baremetal': _Component(dependencies=[\n                'qemu',\n                'baremetal-qemu',\n            ]),\n            'qemu-buildroot': _Component(dependencies=[\n                'buildroot-overlay-qemu',\n                'linux',\n            ]),\n            'qemu-gem5-buildroot': _Component(dependencies=[\n                'qemu',\n                'gem5-buildroot',\n            ]),\n            'qemu-user': _Component(\n                self._build_file('build-qemu', mode='userland'),\n                apt_build_deps = {'qemu'},\n                apt_get_pkgs={'libsdl2-dev'},\n                submodules={'qemu'},\n            ),\n            'release': _Component(dependencies=[\n                'baremetal-qemu',\n                'qemu-buildroot',\n                'doc',\n            ]),\n            'test-gdb': _Component(dependencies=[\n                    'all-baremetal',\n                    'userland',\n                ],\n            ),\n            'test-executables-userland': _Component(dependencies=[\n                'test-executables-userland-qemu',\n                'test-executables-userland-gem5',\n            ]),\n            'test-executables-userland-qemu': _Component(dependencies=[\n                'user-mode-qemu',\n                'userland',\n            ]),\n            'test-executables-userland-gem5': _Component(dependencies=[\n                'gem5',\n                'userland-gem5',\n            ]),\n            'user-mode-qemu': _Component(\n                dependencies=['qemu-user', 'userland'],\n            ),\n            'userland': _Component(\n                self._build_file('build-userland'),\n                dependencies=['buildroot'],\n            ),\n            'userland-host': _Component(\n                self._build_file('build-userland-in-tree'),\n                apt_get_pkgs={\n                    'libboost-all-dev',\n                    'libdrm-dev',\n                    'libeigen3-dev',\n                    'libhdf5-dev',\n                    'libopenblas-dev',\n                },\n            ),\n            'userland-gem5': _Component(\n                self._build_file('build-userland', static=True, userland_build_id='static'),\n                dependencies=['buildroot'],\n            ),\n        }\n        self.component_to_name_map = {self.name_to_component_map[key]:key for key in self.name_to_component_map}\n\n        self.add_argument(\n            '--apt',\n            default=True,\n            help='''\\\nDon't run any apt-get commands. To make it easier to use with other archs:\nhttps://cirosantilli.com/linux-kernel-module-cheat#supported-hosts\n'''\n        )\n        self.add_argument(\n            '-D', '--download-dependencies',\n            default=False,\n            help='''\\\nAlso download all dependencies required for a given build: Ubuntu packages,\nPython packages and git submodules.\n'''\n        )\n        self.add_argument(\n            '--print-components',\n            default=False,\n            help='''\\\nPrint the components that would be built, including dependencies, but don't\nbuild them, nor show the build commands.\n'''\n        )\n        self.add_argument(\n            '--travis',\n            default=False,\n            help='''\\\nExtra args to pass to all scripts.\n'''\n        )\n        self.add_argument(\n            'components',\n            choices=list(self.name_to_component_map.keys()) + [[]],\n            default=[],\n            nargs='*',\n            help='''\\\nWhich components to build. Default: qemu-buildroot\n'''\n        )\n\n    def _build_file(self, component_file, **extra_args):\n        '''\n        Build something based on a component file that defines a Main class.\n        '''\n        def f():\n            args = self.get_common_args()\n            args.update(extra_args)\n            args['show_time'] = False\n            return lkmc.import_path.import_path_main(component_file)(**args)\n        return f\n\n    def timed_main(self):\n        self.sh = shell_helpers.ShellHelpers(dry_run=self.env['dry_run'])\n\n        # Decide components.\n        components = self.env['components']\n        if components == []:\n            components = ['qemu-buildroot']\n        selected_components = []\n        for component_name in components:\n            todo = [component_name]\n            while todo:\n                current_name = todo.pop(0)\n                component = self.name_to_component_map[current_name]\n                selected_components.insert(0, component)\n                todo.extend(component.dependencies)\n        # Remove duplicates, keep only the first one of each.\n        # https://stackoverflow.com/questions/7961363/removing-duplicates-in-lists/7961390#7961390\n        selected_components = collections.OrderedDict.fromkeys(selected_components)\n\n        if self.env['download_dependencies']:\n            apt_get_pkgs = {\n                # Core requirements for this repo.\n                'git',\n                'moreutils', # ts\n                'squashfs-tools',\n                'tmux',\n                'vinagre',\n                'wget',\n            }\n            if platform.machine() == 'x86_64':\n                # https://github.com/rr-debugger/rr/issues/1373\n                apt_get_pkgs.add('rr')\n            # E.g. on an ARM host, the package gcc-arm-linux-gnueabihf\n            # is called just gcc.\n            processor = self.env['host_arch']\n            if processor != 'arm':\n                apt_get_pkgs.update({\n                    'gcc-arm-linux-gnueabihf',\n                    'g++-arm-linux-gnueabihf',\n                })\n            if processor != 'aarch64':\n                apt_get_pkgs.update({\n                    'gcc-aarch64-linux-gnu',\n                    'g++-aarch64-linux-gnu',\n                })\n            apt_build_deps = set()\n            submodules = set()\n            submodules_shallow = set()\n            python3_pkgs = {\n                'pexpect==4.6.0',\n            }\n            ruby_pkgs = set()\n            for component in selected_components:\n                apt_get_pkgs.update(component.apt_get_pkgs)\n                apt_build_deps.update(component.apt_build_deps)\n                submodules.update(component.submodules)\n                submodules_shallow.update(component.submodules_shallow)\n                python3_pkgs.update(component.python3_pkgs)\n                python3_pkgs.update(component.python3_pkgs)\n                ruby_pkgs.update(component.ruby_pkgs)\n            if ruby_pkgs:\n                apt_get_pkgs.add('ruby')\n            if python3_pkgs:\n                apt_get_pkgs.add('python3-pip')\n            if apt_get_pkgs or apt_build_deps:\n                if self.env['travis']:\n                    interacive_pkgs = {\n                        'libsdl2-dev',\n                    }\n                    apt_get_pkgs.difference_update(interacive_pkgs)\n                if common.consts['in_docker']:\n                    sudo = []\n                    # https://askubuntu.com/questions/909277/avoiding-user-interaction-with-tzdata-when-installing-certbot-in-a-docker-contai\n                    os.environ['DEBIAN_FRONTEND'] = 'noninteractive'\n                    # https://askubuntu.com/questions/496549/error-you-must-put-some-source-uris-in-your-sources-list\n                    sources_path = os.path.join('/etc', 'apt', 'sources.list')\n                    with open(sources_path, 'r') as f:\n                        sources_txt = f.read()\n                    sources_txt = re.sub('^# deb-src ', 'deb-src ', sources_txt, flags=re.MULTILINE)\n                    with open(sources_path, 'w') as f:\n                        f.write(sources_txt)\n                else:\n                    sudo = ['sudo']\n                if common.consts['in_docker'] or self.env['travis']:\n                    y = ['-y']\n                else:\n                    y = []\n                if self.env['apt']:\n                    self.sh.run_cmd(\n                        sudo + ['apt-get', 'update', LF]\n                    )\n                    if apt_get_pkgs:\n                        self.sh.run_cmd(\n                            sudo + ['apt-get', 'install'] + y + [LF] +\n                            self.sh.add_newlines(sorted(apt_get_pkgs))\n                        )\n                    if apt_build_deps:\n                        self.sh.run_cmd(\n                            sudo +\n                            ['apt-get', 'build-dep'] + y + [LF] +\n                            self.sh.add_newlines(sorted(apt_build_deps))\n                        )\n            if python3_pkgs:\n                # Not with pip executable directly:\n                # https://stackoverflow.com/questions/49836676/error-after-upgrading-pip-cannot-import-name-main/51846054#51846054\n                self.sh.run_cmd(\n                    ['python3', '-m', 'pip', 'install', '--user', LF] +\n                    self.sh.add_newlines(sorted(python3_pkgs))\n                )\n            self.sh.run_cmd(['python3', '-m', 'pip', 'install', '-r', 'requirements.txt', '--user', LF])\n            if ruby_pkgs:\n                # The right thing to do would be to use RVM and avoid sudo,\n                # but we felt it was too much boilerplate for now.\n                #\n                # --user-install does work here, but we still need to add\n                # the binary to PATH which is a pain:\n                # https://stackoverflow.com/questions/31596273/install-gem-in-local-folder\n                self.sh.run_cmd(['sudo', 'gem', 'install', 'bundler', LF])\n                # No ones knows how to do this without sudo:\n                # https://stackoverflow.com/questions/16376995/bundler-cannot-install-any-gems-without-sudo/27677094\n                self.sh.run_cmd([\n                    'sudo', LF,\n                    'bundle', LF,\n                    'install', LF,\n                    '--gemfile', os.path.join(self.env['root_dir'], 'Gemfile'), LF,\n                ])\n            git_cmd_common = [\n                'git', LF,\n                'submodule', LF,\n                'update', LF,\n                '--init', LF,\n                '--recursive', LF,\n            ]\n            if self.env['dry_run']:\n                git_version_tuple = (math.inf, math.inf, math.inf)\n            else:\n                git_version_tuple = tuple(\n                    int(x) for x in self.sh.check_output(['git', '--version']) \\\n                            .decode().split(' ')[-1].split('.')[:3]\n                )\n                if git_version_tuple >= (2, 9, 0):\n                    # https://stackoverflow.com/questions/26957237/how-to-make-git-clone-faster-with-multiple-threads/52327638#52327638\n                    git_cmd_common.extend(['--jobs', str(len(os.sched_getaffinity(0))), LF])\n                if git_version_tuple >= (2, 10, 0):\n                    # * https://stackoverflow.com/questions/32944468/how-to-show-progress-for-submodule-fetching\n                    # * https://stackoverflow.com/questions/4640020/progress-indicator-for-git-clone\n                    git_cmd_common.extend(['--progress', LF])\n            def submodule_ids_to_cmd(submodules):\n                return self.sh.add_newlines([os.path.join(common.consts['submodules_dir'], x) for x in sorted(submodules)])\n            if submodules:\n                self.sh.run_cmd(git_cmd_common + ['--', LF] + submodule_ids_to_cmd(submodules))\n            if submodules_shallow:\n                # TODO Ideally we should shallow clone --depth 1 all of them.\n                #\n                # However, most git servers out there are crap or craply configured\n                # and don't allow shallow cloning except for branches.\n                #\n                # So for now I'm keeping all mirrors in my GitHub.\n                # and always have a lkmc-* branch pointint to it.\n                #\n                # However, QEMU has a bunch of submodules itself, and I'm not in the mood\n                # to mirror all of them...\n                #\n                # See also:\n                #\n                # * https://stackoverflow.com/questions/3489173/how-to-clone-git-repository-with-specific-revision-changeset\n                # * https://stackoverflow.com/questions/2144406/git-shallow-submodules/47374702#47374702\n                # * https://unix.stackexchange.com/questions/338578/why-is-the-git-clone-of-the-linux-kernel-source-code-much-larger-than-the-extrac\n                cmd = git_cmd_common.copy()\n                if git_version_tuple > (2, 7, 4):\n                    # Then there is a bug in Ubuntu 16.04 git 2.7.4 where --depth 1 fails...\n                    # OMG git submodules implementation sucks:\n                    # * https://stackoverflow.com/questions/2155887/git-submodule-head-reference-is-not-a-tree-error/25875273#25875273\n                    # * https://github.com/boostorg/boost/issues/245\n                    cmd.extend(['--depth', '1', LF])\n                else:\n                    self.log_warn('your git is too old for git submodule update --depth 1')\n                    self.log_warn('update to git 2.17 or newer and you will save clone time')\n                    self.log_warn('see: https://github.com/cirosantilli/linux-kernel-module-cheat/issues/44')\n                self.sh.run_cmd(cmd + ['--', LF] + submodule_ids_to_cmd(submodules_shallow))\n            for submodule_name in submodule_extra_remotes:\n                submodule = submodule_extra_remotes[submodule_name]\n                for remote_name in submodule:\n                    self.sh.run_cmd(\n                        [\n                            'git', LF,\n                            '-C', os.path.join(common.consts['submodules_dir'], submodule_name), LF,\n                            'remote', LF,\n                            'add', LF,\n                            remote_name, LF,\n                            submodule[remote_name], LF,\n                        ],\n                        # In case the remote already exists.\n                        raise_on_failure=False\n                    )\n\n        # Do the build.\n        for component in selected_components:\n            if self.env['print_components']:\n                print(self.component_to_name_map[component])\n            else:\n                ret = component.build(self.env['arch'])\n                if (ret != 0):\n                    return ret\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-android",
          "type": "blob",
          "size": 2.5966796875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport subprocess\n\nimport common\nimport shutil\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nDownload and build Android AOSP.\n\nhttps://cirosantilli.com/linux-kernel-module-cheat#android\n'''\n        )\n        self.add_argument(\n            '--extra-args',\n            default='',\n        )\n        self.add_argument(\n            'targets',\n            default=['build'],\n            nargs='*',\n        )\n\n    def build(self):\n        if 'download' in self.env['targets']:\n            os.makedirs(self.env['android_dir'], exist_ok=True)\n            # Can only download base64. I kid you not:\n            # https://github.com/google/gitiles/issues/7\n            self.sh.wget(\n                'https://android.googlesource.com/tools/repo/+/v2.8/repo?format=TEXT', \n                self.env['repo_path_base64'],\n            )\n            with open(self.env['repo_path_base64'], 'r') as input, \\\n                open(self.env['repo_path'], 'w') as output:\n                output.write(self.sh.base64_decode(input.read()))\n            self.sh.chmod(self.env['repo_path'])\n            self.sh.run_cmd(\n                [\n                    self.env['repo_path'], LF,\n                    'init', LF,\n                    '-b', 'android-{}'.format(self.env['android_version']), LF,\n                    '--depth', '1', LF,\n                    '-u', 'https://android.googlesource.com/platform/manifest', LF,\n                ],\n                cwd=self.env['android_dir'],\n            )\n            self.sh.run_cmd(\n                [\n                    self.env['repo_path'], LF,\n                    'sync', LF,\n                    '-c', LF,\n                    '-j', str(self.env['nproc']), LF,\n                    '--no-tags', LF,\n                    '--no-clone-bundle', LF,\n                ],\n                cwd=self.env['android_dir'],\n            )\n        if 'build' in self.env['targets']:\n            # The crappy android build system requires\n            # https://stackoverflow.com/questions/7040592/calling-the-source-command-from-subprocess-popen\n            self.sh.run_cmd('{}USE_CCACHE=1 make -j {} {}'.format(\n                    self.env['android_shell_setup'],\n                    self.env['nproc'],\n                    self.env['extra_args']\n                ),\n                cwd=self.env['android_dir'],\n                executable=shutil.which('bash'),\n                shell=True,\n            )\n\n    def get_build_dir(self):\n        return self.env['android_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-baremetal",
          "type": "blob",
          "size": 4.0087890625,
          "content": "#!/usr/bin/env python3\nimport os\n\nimport common\nimport thread_pool\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults={\n                'gcc_which': 'crosstool-ng',\n                'mode': 'baremetal',\n            },\n            description='''\\\nBuild the baremetal examples with crosstool-NG.\n''',\n        )\n        self._add_argument('--ccflags')\n        self._add_argument('--force-rebuild')\n        self._add_argument('--optimization-level')\n        self.add_argument(\n            'targets',\n            default=[],\n            help='Analogous to ./build-userland target selection',\n            nargs='*',\n        )\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        cc_flags = [\n            '-I', self.env['root_dir'], LF,\n        ]\n        if self.env['emulator'] == 'gem5':\n            cc_flags.extend([\n                '-DLKMC_GEM5=1', LF,\n                '-DLKMC_M5OPS_ENABLE=1', LF,\n            ])\n        else:\n            cc_flags.extend(['-D', 'LKMC_QEMU=1', LF])\n        cc_flags.extend(['-D', 'LKMC_UART0_ADDR={:#x}'.format(self.env['uart_address']), LF])\n        cc_flags.extend(self.env['ccflags'])\n        bootloader_src = os.path.join(\n            self.env['baremetal_source_lib_dir'],\n            '{}{}'.format(\n                self.env['arch'],\n                self.env['asm_ext']\n            )\n        )\n        for in_path, out_path in [\n            (bootloader_src, self.env['baremetal_extra_obj_bootloader']),\n            (self.env['common_c'], self.env['baremetal_extra_obj_lkmc_common']),\n            (\n                self.env['baremetal_syscalls_src'],\n                self.env['baremetal_syscalls_obj']\n            ),\n            (\n                self.env['baremetal_syscalls_asm_src'],\n                self.env['baremetal_syscalls_asm_obj']\n            ),\n        ]:\n            self._build_one(\n                in_path=in_path,\n                out_path=out_path,\n                cc_flags=cc_flags,\n                extra_deps=[self.env['common_h']],\n                link=False,\n            )\n        cc_flags.extend(self.env['ldflags'])\n        with thread_pool.ThreadPool(\n            self._build_one,\n            nthreads=self.env['nproc'],\n            submit_raise_exit=self.env['quit_on_fail'],\n        ) as my_thread_pool:\n            for target in self.env['targets']:\n                for path, in_dirnames, in_filenames in self.sh.walk(target):\n                    for in_filename in in_filenames:\n                        in_ext = os.path.splitext(in_filename)[1]\n                        if not in_ext in self.env['baremetal_build_in_exts']:\n                            continue\n                        in_path = os.path.join(path, in_filename)\n                        my_thread_pool.submit({\n                            'cc_flags': cc_flags,\n                            'extra_deps': [\n                                self.env['baremetal_link_script'],\n                                self.env['common_h']\n                            ],\n                            'extra_objs': [\n                                self.env['baremetal_syscalls_obj'],\n                                self.env['baremetal_syscalls_asm_obj']\n                            ],\n                            'extra_objs_baremetal_bootloader': [self.env['baremetal_extra_obj_bootloader']],\n                            'extra_objs_lkmc_common': [self.env['baremetal_extra_obj_lkmc_common']],\n                            'in_path': in_path,\n                            'out_path': self.resolve_baremetal_executable(in_path),\n                        })\n        return self._handle_thread_pool_errors(my_thread_pool)\n\n    def get_build_dir(self):\n        return self.env['baremetal_build_dir']\n\n    def setup_one_build(self):\n        self.env['targets'] = self.resolve_targets(\n            [\n                self.env['baremetal_source_dir'],\n                self.env['userland_source_dir']\n            ],\n            self.env['targets']\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-buildroot",
          "type": "blob",
          "size": 7.3701171875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport pathlib\nimport shutil\nimport subprocess\nimport sys\nimport time\nimport re\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild Buildroot. This includes, notably: the userland GCC cross-toolchain,\nand the root filesystem.\n''')\n        self.add_argument(\n            '--build-linux', default=False,\n            help='''\\\nSee https://cirosantilli.com/linux-kernel-module-cheat#buildroot-vanilla-kernel\n'''\n        )\n        self.add_argument(\n            '--baseline', default=False,\n            help='''Do a default-ish Buildroot defconfig build, without any of our extra options.\nMostly to track how much slower we are than a basic build.\n'''\n        )\n        self.add_argument(\n            '--config', default=[], action='append',\n            help='''Add a single Buildroot config to the current build.\nExample value: 'BR2_TARGET_ROOTFS_EXT2_SIZE=\"512M\"'.\nCan be used multiple times to add multiple configs.\nTakes precedence over any Buildroot config files.\n'''\n        )\n        self.add_argument(\n            '--config-fragment', default=[], action='append',\n            help='''Also use the given Buildroot configuration fragment file.\nPass multiple times to use multiple fragment files.\n'''\n        )\n        self.add_argument(\n            '--no-all', default=False,\n            help='''\\\nDon't build the all target which normally gets build by default.\nThat target builds the root filesystem and all its dependencies.\n'''\n        )\n        self.add_argument(\n            '--no-overlay', default=False,\n            help='''\\\nDon't add our overlay which contains all files we build without going through Buildroot.\nThis prevents us from overwriting certain Buildroot files. Remember however that you must\nstill rebuild the Buildroot package that provides those files to actually put the Buildroot\nfiles on the root filesystem.\n'''\n        )\n        self._add_argument('--force-rebuild')\n        self._add_argument('extra_make_args')\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        os.makedirs(self.env['out_dir'], exist_ok=True)\n        extra_make_args = self.sh.add_newlines(self.env['extra_make_args'])\n        if self.env['build_linux']:\n            extra_make_args.extend(['linux-reconfigure', LF])\n        if self.env['arch'] == 'x86_64':\n            defconfig = 'qemu_x86_64_defconfig'\n        elif self.env['arch'] == 'arm':\n            defconfig = 'qemu_arm_vexpress_defconfig'\n        elif self.env['arch'] == 'aarch64':\n            defconfig = 'qemu_aarch64_virt_defconfig'\n        br2_external_dirs = []\n        for package_dir in sorted(os.listdir(self.env['packages_dir'])):\n            package_dir_abs = os.path.join(self.env['packages_dir'], package_dir)\n            if os.path.isdir(package_dir_abs):\n                br2_external_dirs.append(self._path_relative_to_buildroot(package_dir_abs))\n        br2_external_str = ':'.join(br2_external_dirs)\n        self.sh.run_cmd(\n            [\n                'make', LF,\n                'O={}'.format(self.env['buildroot_build_dir']), LF,\n                'BR2_EXTERNAL={}'.format(br2_external_str), LF,\n                defconfig, LF,\n            ],\n            cwd=self.env['buildroot_source_dir'],\n        )\n        configs = self.env['config']\n        configs.extend([\n            'BR2_JLEVEL={}'.format(self.env['nproc']),\n            'BR2_DL_DIR=\"{}\"'.format(self.env['buildroot_download_dir']),\n        ])\n        if not self.env['build_linux']:\n            configs.extend([\n                '# BR2_LINUX_KERNEL is not set',\n            ])\n        config_fragments = []\n        if not self.env['baseline']:\n            configs.extend([\n                'BR2_GLOBAL_PATCH_DIR=\"{}\"'.format(\n                    self._path_relative_to_buildroot(os.path.join(self.env['root_dir'], 'patches', 'global'))\n                ),\n                'BR2_PACKAGE_BUSYBOX_CONFIG_FRAGMENT_FILES=\"{}\"'.format(\n                    self._path_relative_to_buildroot(os.path.join(self.env['root_dir'], 'busybox_config_fragment'))\n                ),\n                'BR2_PACKAGE_OVERRIDE_FILE=\"{}\"'.format(\n                    self._path_relative_to_buildroot(os.path.join(self.env['root_dir'], 'buildroot_override'))\n                ),\n                'BR2_ROOTFS_POST_BUILD_SCRIPT=\"{}\"'.format(\n                    self._path_relative_to_buildroot(os.path.join(self.env['root_dir'], 'rootfs-post-build-script'))\n                ),\n                'BR2_ROOTFS_USERS_TABLES=\"{}\"'.format(\n                    self._path_relative_to_buildroot(os.path.join(self.env['root_dir'], 'user_table'))\n                ),\n            ])\n            if not self.env['no_overlay']:\n                configs.append('BR2_ROOTFS_OVERLAY=\"{}\"'.format(\n                    self._path_relative_to_buildroot(self.env['out_rootfs_overlay_dir'])\n                ))\n            config_fragments = [\n                os.path.join(self.env['root_dir'], 'buildroot_config', 'default')\n            ] + self.env['config_fragment']\n        if self.env['initrd'] or self.env['initramfs']:\n            configs.append('BR2_TARGET_ROOTFS_CPIO=y')\n        # TODO Can't get rid of these for now with nice fragments on Buildroot:\n        # http://stackoverflow.com/questions/44078245/is-it-possible-to-use-config-fragments-with-buildroots-config\n        self.sh.write_configs(self.env['buildroot_config_file'], configs, config_fragments)\n        self.sh.run_cmd(\n            [\n                'make', LF,\n                'O={}'.format(self.env['buildroot_build_dir']), LF,\n                'olddefconfig', LF,\n            ],\n            cwd=self.env['buildroot_source_dir'],\n        )\n        self.make_build_dirs()\n        if self.env['force_rebuild']:\n            extra_make_args.extend(['-B', LF])\n        if not self.env['no_all']:\n            extra_make_args.extend(['all', LF])\n        self.sh.run_cmd(\n            [\n                'make', LF,\n                'LKMC_PARSEC_BENCHMARK_SRCDIR=\"{}\"'.format(self.env['parsec_benchmark_source_dir']), LF,\n                'O={}'.format(self.env['buildroot_build_dir']), LF,\n                'V={}'.format(int(self.env['verbose'])), LF,\n            ] +\n            extra_make_args\n            ,\n            cwd=self.env['buildroot_source_dir'],\n            delete_env=['LD_LIBRARY_PATH', 'PERL_MM_OPT'],\n            extra_env={\n                # In Docker, >>> host-tar 1.29 Configuring\n                # checking whether mknod can create fifo without root privileges... configure: error: in `/root/lkmc/out.docker/buildroot/build/default/aarch64/build/host-tar-1.29':\n                # configure: error: you should not run configure as root (set FORCE_UNSAFE_CONFIGURE=1 in environment to bypass this check)\n                'FORCE_UNSAFE_CONFIGURE': '1',\n            },\n            out_file=os.path.join(self.env['buildroot_build_dir'], self.env['repo_short_id'] + '.log'),\n        )\n        # Create the qcow2 from ext2.\n        # Skip if qemu is not present, because gem5 does not need the qcow2.\n        # so we don't force a QEMU build for gem5.\n        if not self.env['no_all'] and os.path.exists(self.env['qemu_img_executable']):\n            self.raw_to_qcow2()\n\n    def get_build_dir(self):\n        return self.env['buildroot_build_dir']\n\n    def _path_relative_to_buildroot(self, abspath):\n        return os.path.relpath(abspath, self.env['buildroot_source_dir'])\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-crosstool-ng",
          "type": "blob",
          "size": 3.1552734375,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults={\n                'mode': 'baremetal',\n            },\n            description='''\\\nBuild crosstool-NG with Newlib for bare metal compilation\n''',\n        )\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        defconfig_dest = os.path.join(self.env['crosstool_ng_source_copy_dir'], 'defconfig')\n        os.makedirs(self.env['crosstool_ng_download_dir'], exist_ok=True)\n\n        # Bootstrap out-ot-tree WONTFIX. I've tried.\n        # https://github.com/crosstool-ng/crosstool-ng/issues/1021\n        #\n        # Then out-of-tree ./ctng usage also started to fail in 1.24.0.\n        #\n        # So instead of fighting upstream, I'll just take the Buildroot approach\n        # to life and rsync the entire source tree into the build tree. Fun times.\n        self.sh.copy_dir_if_update(\n            self.env['crosstool_ng_source_dir'],\n            self.env['crosstool_ng_source_copy_dir'],\n        )\n        self.sh.run_cmd(\n            [os.path.join(self.env['crosstool_ng_source_copy_dir'], 'bootstrap'), LF],\n            cwd=self.env['crosstool_ng_source_copy_dir'],\n        )\n        self.sh.run_cmd(\n            [\n                # abspath here makes Ubuntu 16.04 fail with:\n                # configure: error: source directory already configured; run \"make distclean\" there first\n                # after another build has been done. Don't ask me why.\n                os.path.join(os.curdir, 'configure'), LF,\n                '--enable-local', LF,\n            ],\n            cwd=self.env['crosstool_ng_source_copy_dir'],\n        )\n        self.sh.run_cmd(\n            ['make', '-j', str(self.env['nproc']), LF],\n            cwd=self.env['crosstool_ng_source_copy_dir'],\n        )\n\n        # Build the toolchain.\n        self.sh.cp(\n            os.path.join(self.env['root_dir'], 'crosstool_ng_config', self.env['arch']),\n            defconfig_dest\n        )\n        self.sh.write_configs(\n            self.env['crosstool_ng_defconfig'],\n            [\n                'CT_PREFIX_DIR=\"{}\"'.format(self.env['crosstool_ng_install_dir']),\n                'CT_WORK_DIR=\"{}\"'.format(build_dir),\n                'CT_LOCAL_TARBALLS_DIR=\"{}\"'.format(self.env['crosstool_ng_download_dir']),\n            ]\n        )\n        self.sh.run_cmd(\n            [\n                self.env['crosstool_ng_executable'], LF,\n                'defconfig', LF,\n            ],\n            cwd=self.env['crosstool_ng_source_copy_dir'],\n        )\n        self.sh.rmrf(defconfig_dest)\n        self.sh.run_cmd(\n            [\n                self.env['crosstool_ng_executable'], LF,\n                'build', LF,\n                'CT_JOBS={}'.format(str(self.env['nproc'])), LF,\n            ],\n            cwd=self.env['crosstool_ng_source_copy_dir'],\n            out_file=os.path.join(build_dir, self.env['repo_short_id'] + '.log'),\n            delete_env=['LD_LIBRARY_PATH'],\n            extra_paths=[self.env['ccache_dir']],\n        )\n\n    def get_build_dir(self):\n        return self.env['crosstool_ng_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-disk2",
          "type": "blob",
          "size": 0.6435546875,
          "content": "#!/usr/bin/env python3\n\nimport common\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#secondary-disk\n'''\n        )\n\n    def build(self):\n        # We must clean first because mksquashfs tries to avoid overwrites\n        # by renaming images on the target.\n        self.clean()\n        self.sh.run_cmd([\n            'mksquashfs',\n            self.env['out_rootfs_overlay_dir'],\n            self.env['disk_image_2']\n        ])\n\n    def clean(self):\n        self.sh.rmrf(self.env['disk_image_2'])\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-doc",
          "type": "blob",
          "size": 4.3330078125,
          "content": "#!/usr/bin/env python3\n\nimport re\n\nimport common\nfrom shell_helpers import LF\nimport os\nimport subprocess\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#build-the-documentation\n''',\n        )\n        self.add_argument(\n            '--github-pages',\n            default=False,\n            help='''\nBuild for GitHub pages instead of a local build. This redirects all links\nfrom the README to example sources to GitHub rather than locally.\n'''\n        )\n\n    def timed_main(self):\n        asciidoctor_dir = os.path.join(self.env['root_dir'], 'asciidoctor')\n        if self.env['github_pages']:\n            link_target_script = 'link-target-github.rb'\n        else:\n            link_target_script = 'link-target-up.rb'\n        common_cmd = [\n            'bundle', LF,\n            'exec', LF,\n            'asciidoctor', LF,\n            '--attribute', 'docinfo=shared', LF,\n            '--failure-level', 'info', LF,\n            '--require', os.path.join(asciidoctor_dir, link_target_script), LF,\n            '--trace', LF,\n            '--verbose', LF,\n        ]\n        exit_status = self.sh.run_cmd(\n            common_cmd +\n            [\n                '--out-file', self.env['readme_out'], LF,\n                self.env['readme'], LF,\n            ],\n            out_file=self.env['build_doc_log'],\n        )\n        if exit_status == 0:\n            exit_status = self.sh.run_cmd(\n                common_cmd +\n                [\n                    '-D', self.env['out_doc_dir'], LF,\n                    '-a', 'multipage-level=6', LF,\n                    '-b', 'multipage_html5', LF,\n                    '-r', 'asciidoctor-multipage', LF,\n                    self.env['readme'], LF,\n                ],\n                out_file=self.env['build_doc_multipage_log'],\n            )\n\n        # Check that all local files linked from README exist.\n        external_link_re = re.compile('^https?://')\n        for link in self.sh.check_output([\n            os.path.join(asciidoctor_dir, 'extract-link-targets'),\n            self.env['readme']\n        ]).decode().splitlines():\n            if not external_link_re.match(link):\n                if not os.path.lexists(os.path.join(self.env['root_dir'], link)):\n                    self.log_error('broken link to local file: ' + link)\n                    exit_status = 1\n\n        # Check that there are not links to the GitHub README.\n        # https://github.com/isaacs/github/issues/1610\n        for grep_line in self.sh.check_output(\n            [\n                'git',\n                'grep',\n                '--fixed-strings',\n                self.env['github_repo_url'] + '#',\n                LF\n            ],\n            cwd=self.env['root_dir'],\n            raise_on_failure=False\n        ).decode().splitlines():\n            self.log_error('link to GitHub readme: {}'.format(\n                grep_line\n            ))\n            exit_status = 1\n\n        # Check that non-README links to README IDs exit.\n        header_ids = set()\n        grep_line_location_re = re.compile('^(.*?:\\d+):')\n        grep_line_hash_re = re.compile('^([a-z0-9_-]+)')\n        for header_id in self.sh.check_output([\n            os.path.join(asciidoctor_dir, 'extract-header-ids'),\n            self.env['readme']\n        ]).decode().splitlines():\n            header_ids.add(header_id)\n        for grep_line in self.sh.check_output(\n            [\n                'git',\n                'grep',\n                '--fixed-strings',\n                self.env['homepage_url'] + '#',\n                LF\n            ],\n            cwd=self.env['root_dir']\n        ).decode().splitlines():\n            url_index = grep_line.index(self.env['homepage_url'])\n            hash_start_index = url_index + len(self.env['homepage_url'])\n            if len(grep_line) > hash_start_index:\n                hash_str = grep_line_hash_re.search(grep_line[hash_start_index + 1:]).group(1)\n                if not hash_str in header_ids:\n                    self.log_error('broken link to {} at {}'.format(\n                        hash_str,\n                        grep_line_location_re.search(grep_line).group(1))\n                    )\n                    exit_status = 1\n\n        return exit_status\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-docker",
          "type": "blob",
          "size": 2.1982421875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport subprocess\nimport tarfile\n\nimport common\nfrom shell_helpers import LF\n\nclass DockerComponent(self.Component):\n    def get_argparse_args(self):\n        return {\n            'description': '''\\\nBuild a guest root filesystem based on prebuilt Docker Ubuntu root filesystems.\n\nSee also: https://github.com/cirosantilli/linux-kernel-module-cheatTODO#ubuntu-guest-setup\n'''\n        }\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        container_name = 'lkmc-guest'\n        target_dir = os.path.join('/root', 'linux-kernel-module-cheat')\n        os.makedirs(build_dir, exist_ok=True)\n        containers = self.sh.check_output([\n                'docker',\n                'ps',\n                '-a',\n                '--format', '{{.Names}}',\n        ]).decode()\n        if container_name in containers.split():\n            self.sh.run_cmd([\n                'docker',\n                'rm',\n                container_name,\n            ])\n        self.sh.run_cmd([\n            'docker',\n            'create',\n            '--name', container_name,\n            '--network', 'host',\n            '--interactive',\n            '--privileged',\n            '--tty',\n            '--workdir', target_dir,\n            '--volume', '{}:{}'.format(kwargs['root_dir'], target_dir),\n            'ubuntu:20.04',\n            'bash',\n        ])\n        self.sh.run_cmd([\n            'docker',\n            'export',\n            '-o',\n            kwargs['docker_tar_file'],\n            container_name,\n        ])\n        tar = tarfile.open(kwargs['docker_tar_file'])\n        tar.extractall(kwargs['docker_tar_dir'])\n        tar.close()\n        # sudo not required in theory\n        # https://askubuntu.com/questions/1046828/how-to-run-libguestfs-tools-tools-such-as-virt-make-fs-without-sudo\n        self.sh.run_cmd([\n            'virt-make-fs',\n            '--format', 'raw',\n            '--size', '+1G',\n            '--type', 'ext2',\n            kwargs['docker_tar_dir'],\n            kwargs['docker_rootfs_raw_file'],\n        ])\n        self.raw_to_qcow2(prebuilt=True)\n\n    def get_build_dir(self):\n        return kwargs['docker_build_dir']\n\n    def get_default_args(self):\n        return {'docker': True}\n\nMain().cli()\n"
        },
        {
          "name": "build-gem5",
          "type": "blob",
          "size": 6.806640625,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport pathlib\nimport subprocess\nimport tempfile\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild gem5.\nhttps://github.com/cirosantilli/linux-kernel-module-cheat-regression#gem5-buildroot-setup\n'''\n        )\n        self.add_argument(\n            '--unit-test',\n            action='append',\n            default=[],\n            help='''\\\nBuild and run the given unit test. Paths are relative to src/ without the .opt suffix.\nIf given multiple times, runs multiple unit tests. Ignore --unit-tests.\nhttps://github.com/cirosantilli/linux-kernel-module-cheat-regression#gem5-unit-tests\n'''\n        )\n        self.add_argument(\n            '--unit-tests',\n            default=False,\n            help='''\\\nBuild and run all the gem5 unit tests instead of the gem5 executable.\nhttps://github.com/cirosantilli/linux-kernel-module-cheat-regression#gem5-unit-tests\n'''\n        )\n        self._add_argument('--ldflags')\n        self._add_argument('extra_make_args')\n        self.eclipse_tmpdir = None\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        binaries_dir = self.env['gem5_system_binaries_dir']\n        disks_dir = os.path.join(self.env['gem5_system_dir'], 'disks')\n        os.makedirs(binaries_dir, exist_ok=True)\n        os.makedirs(disks_dir, exist_ok=True)\n        if not os.path.exists(os.path.join(self.env['gem5_source_dir'], '.git')):\n            if self.env['_args_given']['gem5_worktree']:\n                self.sh.run_cmd([\n                    'git', LF,\n                    '-C', self.env['gem5_default_source_dir'], LF,\n                    'worktree', 'add', LF,\n                    '-b', os.path.join('wt', self.env['gem5_worktree']), LF,\n                    self.env['gem5_source_dir'], LF,\n                ])\n            else:\n                if not self.env['dry_run']:\n                    raise Exception('gem5 submodule not checked out')\n        if self.env['verbose']:\n            verbose = ['--verbose', LF]\n        else:\n            verbose = []\n        if self.env['is_arm']:\n            gem5_system_source_dir = os.path.join(self.env['gem5_source_dir'], 'system')\n\n            # dtb\n            dt_source_dir = os.path.join(gem5_system_source_dir, 'arm', 'dt')\n            dt_build_dir = os.path.join(self.env['gem5_system_dir'], 'arm', 'dt')\n            self.sh.run_cmd(['make', '-C', dt_source_dir, LF])\n            self.sh.copy_dir_if_update_non_recursive(\n                srcdir=dt_source_dir,\n                destdir=dt_build_dir,\n                filter_ext='.dtb',\n            )\n\n            # Bootloader 32.\n            arm_bootloader_dir = os.path.join(gem5_system_source_dir, 'arm', 'bootloader')\n            bootloader32_dir = os.path.join(arm_bootloader_dir, 'arm')\n            # TODO use the buildroot cross compiler here, and remove the dependencies from configure.\n            self.sh.run_cmd([\n                'make', LF,\n                '-C', bootloader32_dir, LF,\n                'CROSS_COMPILE=arm-linux-gnueabihf-', LF,\n            ])\n            # bootloader\n            self.sh.cp(os.path.join(bootloader32_dir, 'boot.arm'), binaries_dir)\n\n            # Bootloader 64.\n            bootloader64_dir = os.path.join(arm_bootloader_dir, 'arm64')\n            # TODO cross_compile is ignored because the make does not use CC...\n            self.sh.run_cmd(['make', '-C', bootloader64_dir, LF])\n            self.sh.cp(os.path.join(bootloader64_dir, 'boot.arm64'), binaries_dir)\n            self.sh.cp(os.path.join(bootloader64_dir, 'boot_v2.arm64'), binaries_dir)\n        term_source_dir = os.path.join(self.env['gem5_source_dir'], 'util/term')\n        m5term_build = os.path.join(term_source_dir, 'm5term')\n        self.sh.run_cmd(['make', '-C', term_source_dir, LF])\n        if os.path.exists(self.env['gem5_m5term']):\n            # Otherwise self.sh.cp would fail with \"Text file busy\" if you\n            # tried to rebuild while running m5term:\n            # https://stackoverflow.com/questions/16764946/what-generates-the-text-file-busy-message-in-unix/52427512#52427512\n            self.sh.rmrf(self.env['gem5_m5term'])\n        self.sh.cp(m5term_build, self.env['gem5_m5term'])\n        if self.env['unit_test']:\n            targets = [self.get_gem5_target_path(self.env, test) for test in self.env['unit_test']]\n        elif self.env['unit_tests']:\n            targets = [self.env['gem5_unit_test_target']]\n        else:\n            targets = [self.env['gem5_executable']]\n        if self.env['gem5_clang']:\n            extra_env = {\n                'CC': 'clang',\n                'CXX': 'clang++',\n            }\n        else:\n            extra_env = {}\n        # https://cirosantilli.com/cirodown#benchmark-gem5-single-file-change-rebuild-time\n        ldflags_extra = ['-fuse-ld=lld'] + self.env['ldflags']\n        kwargs = {}\n        if self.env['ccache']:\n            kwargs['extra_paths'] = [self.env['ccache_dir']]\n        exit_status = self.sh.run_cmd(\n            (\n                [\n                    'scons', LF,\n                    '-j', str(self.env['nproc']), LF,\n                    '--ignore-style', LF,\n                    'LDFLAGS_EXTRA={}'.format(self.sh.cmd_to_string(ldflags_extra, force_oneline=True)), LF,\n                    'USE_HDF5=1', LF,\n                ] +\n                verbose +\n                [\n                    # TODO reenable, broken, had enough of this.\n                    # https://gem5.atlassian.net/browse/GEM5-357\n                    # https://gem5.atlassian.net/browse/GEM5-656\n                    # https://gem5.atlassian.net/browse/GEM5-778\n                    #'SLICC_HTML=True', LF,\n                ] +\n                self.sh.add_newlines(targets) +\n                self.sh.add_newlines(self.env['extra_make_args'])\n            ),\n            cwd=self.env['gem5_source_dir'],\n            extra_env=extra_env,\n            raise_on_failure = False,\n            **kwargs\n        )\n        return exit_status\n\n    def clean_pre(self, builddir):\n        if os.path.exists(self.env['gem5_eclipse_cproject_path']):\n            self.eclipse_tmpdir = tempfile.mkdtemp()\n            self.sh.mv(self.env['gem5_eclipse_cproject_path'], self.eclipse_tmpdir)\n            self.sh.mv(self.env['gem5_eclipse_project_path'], self.eclipse_tmpdir)\n\n    def clean_post(self, builddir):\n        if self.eclipse_tmpdir is not None:\n            self.sh.mkdir_p(self.env['gem5_build_build_dir'])\n            self.sh.mv(os.path.join(self.eclipse_tmpdir, self.env['gem5_eclipse_cproject_basename']), self.env['gem5_build_build_dir'])\n            self.sh.mv(os.path.join(self.eclipse_tmpdir, self.env['gem5_eclipse_project_basename']), self.env['gem5_build_build_dir'])\n            self.sh.rmrf(self.eclipse_tmpdir)\n\n    def get_build_dir(self):\n        return self.env['gem5_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-linux",
          "type": "blob",
          "size": 7.9951171875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport shutil\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild the Linux kernel.\n'''\n        )\n        self.add_argument(\n            '--config', default=[], action='append',\n            help='''\\\nAdd a single kernel config configs to the current build. Sample value:\n'CONFIG_FORTIFY_SOURCE=y'. Can be used multiple times to add multiple\nconfigs. Takes precedence over any config files.\n'''\n        )\n        self.add_argument(\n            '--config-fragment', default=[], action='append',\n            help='''\\\nAlso use the given kernel configuration fragment file.\nPass multiple times to use multiple fragment files.\n'''\n        )\n        self.add_argument(\n            '--build',\n            default=True,\n            help='''\\\nBuild the kernel.\n'''\n        )\n        self.add_argument(\n            '--configure',\n            default=True,\n            help='''\\\nConfigure the kernel.\n'''\n        )\n        self.add_argument(\n            '--custom-config-file',\n            help='''\\\nUse this file as the .config. Don't add any default framents to it,\nunless explicitly passed with `--config` and `--config-fragment` on\ntop of it.\n'''\n        )\n        self.add_argument(\n            '--custom-config-file-gem5',\n            default=False,\n            help='''\\\nLike --custom-config-file, but select the gem5 Linux kernel fork\nconfig as the custom config file. Ignore --custom-config-file if given.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#gem5-arm-linux-kernel-patches\n'''\n        )\n        self.add_argument(\n            '--custom-config-target',\n            help='''\\\nLike --custom-config-file, but generate the base configuration file\nby running a kernel make target such as menuconfig or defconfig.\nIf a .config exists in the tree, it will get picked e.g. by menuconfig,\nso you might want to --clean the build first.\n'''\n        )\n        self.add_argument(\n            '--modules-install',\n            default=True,\n            help='''\\\nRun `make modules_install` after `make`.\n'''\n        )\n        self._add_argument('--force-rebuild')\n        self._add_argument('extra_make_args')\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        os.makedirs(build_dir, exist_ok=True)\n        common_args = {\n            'cwd': self.env['linux_source_dir'],\n        }\n        ccache = shutil.which('ccache')\n        if ccache is not None:\n            cc = '{} {}'.format(ccache, self.env['gcc_path'])\n        else:\n            cc = self.env['gcc_path']\n        if self.env['verbose']:\n            verbose = ['V=1']\n        else:\n            verbose = []\n        common_make_args = [\n            'make', LF,\n            '-j', str(self.env['nproc']), LF,\n            'ARCH={}'.format(self.env['linux_arch']), LF,\n            'CROSS_COMPILE={}'.format(self.env['toolchain_prefix_dash']), LF,\n            'CC={}'.format(cc), LF,\n            'O={}'.format(build_dir), LF,\n        ] + verbose\n        if self.env['force_rebuild']:\n            common_make_args.extend(['-B', LF])\n        if self.env['configure']:\n            if self.env['custom_config_target']:\n                base_config_given = True\n                base_config_needs_copy = False\n            elif self.env['custom_config_file_gem5']:\n                base_config_given = True\n                base_config_needs_copy = True\n                custom_config_file = os.path.join(\n                    self.env['linux_source_dir'],\n                    'arch',\n                    self.env['linux_arch'],\n                    'configs',\n                    'gem5_defconfig'\n                )\n            elif self.env['custom_config_file']:\n                base_config_given = True\n                base_config_needs_copy = True\n                custom_config_file = self.env['custom_config_file']\n            else:\n                base_config_given = False\n                base_config_needs_copy = True\n            if base_config_given:\n                if base_config_needs_copy:\n                    if not os.path.exists(custom_config_file):\n                        raise Exception('config fragment file does not exist: {}'.format(custom_config_file))\n                    base_config_file = custom_config_file\n                config_fragments = []\n            else:\n                base_config_file = os.path.join(\n                    self.env['linux_config_dir'],\n                    'buildroot-{}'.format(self.env['arch'])\n                )\n                config_fragments = ['min', 'default']\n                for i, config_fragment in enumerate(config_fragments):\n                    config_fragments[i] = os.path.join(\n                        self.env['linux_config_dir'],\n                        config_fragment\n                    )\n            config_fragments.extend(self.env['config_fragment'])\n            cli_configs = self.env['config']\n            if self.env['initramfs']:\n                cli_configs.append('CONFIG_INITRAMFS_SOURCE=\"{}\"'.format(self.env['buildroot_cpio']))\n            if cli_configs:\n                cli_config_fragment_path = os.path.join(build_dir, 'lkmc_cli_config_fragment')\n                self.sh.write_configs(cli_config_fragment_path, cli_configs, mode='w')\n                config_fragments.append(cli_config_fragment_path)\n            if base_config_needs_copy:\n                self.sh.cp(\n                    base_config_file,\n                    os.path.join(self.env['linux_config']),\n                )\n            if self.env['custom_config_target']:\n                self.sh.run_cmd(\n                    (\n                        common_make_args +\n                        [self.env['custom_config_target'], LF]\n                    ),\n                    **common_args\n                )\n            if config_fragments:\n                self.sh.run_cmd(\n                    [\n                        os.path.join(\n                            self.env['linux_source_dir'],\n                            'scripts',\n                            'kconfig',\n                            'merge_config.sh'\n                        ), LF,\n                        '-m', LF,\n                        '-O', build_dir, LF,\n                        os.path.join(self.env['linux_config']), LF,\n                    ] +\n                    self.sh.add_newlines(config_fragments)\n                )\n            self.sh.run_cmd(\n                (\n                    common_make_args +\n                    ['olddefconfig', LF]\n                ),\n                **common_args\n            )\n        if self.env['build']:\n            self.sh.run_cmd(\n                (\n                    common_make_args +\n                    self.sh.add_newlines(self.env['extra_make_args'])\n                ),\n                # https://cirosantilli.com/linux-kernel-module-cheat#proc-version\n                extra_env={\n                    'KBUILD_BUILD_VERSION': '1',\n                    'KBUILD_BUILD_TIMESTAMP': 'Thu Jan  1 00:00:00 UTC 1970',\n                    'KBUILD_BUILD_USER': self.env['repo_short_id'],\n                    'KBUILD_BUILD_HOST': common.git_sha(self.env['linux_source_dir']),\n                },\n                **common_args\n            )\n            if self.env['modules_install']:\n                self.sh.run_cmd(\n                    (\n                        common_make_args +\n                        [\n                            'INSTALL_MOD_PATH={}'.format(self.env['out_rootfs_overlay_lkmc_dir']), LF,\n                            'modules_install', LF,\n                        ]\n                    ),\n                    **common_args\n                )\n                # TODO: remove build and source https://stackoverflow.com/questions/13578618/what-does-build-and-source-link-do-in-lib-modules-kernel-version\n                # TODO Basically all kernel modules also basically leak full host paths. Just terrible. Buildroot deals with that stuff nicely for us.\n                # self.rmrf()\n\n    def get_build_dir(self):\n        return self.env['linux_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-m5",
          "type": "blob",
          "size": 1.3369140625,
          "content": "#!/usr/bin/env python3\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild the gem5 m5 executable.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#gem5-m5-executable\n'''\n        )\n\n    def _get_make_cmd(self):\n        allowed_toolchains = ['buildroot']\n        return [\n            'scons', LF,\n            '-C', self.env['gem5_m5_source_dir'], LF,\n            '-j', str(self.env['nproc']), LF,\n            'CROSS_COMPILE={}'.format(self.env['toolchain_prefix_dash']), LF,\n            self.env['gem5_m5_source_dir_build'], LF\n        ]\n\n    def build(self):\n        self.sh.mkdir_p(self.env['gem5_m5_build_dir'])\n        # We must clean first or else the build outputs of one arch can conflict with the other.\n        # I should stop being lazy and go actually patch gem5 to support out of tree m5 build...\n        self.clean()\n        self.sh.run_cmd(\n            self._get_make_cmd(),\n        )\n        self.sh.mkdir_p(self.env['out_rootfs_overlay_bin_dir'])\n        self.sh.cp(\n            self.env['gem5_m5_source_dir_build'],\n            self.env['out_rootfs_overlay_bin_dir']\n        )\n\n    def clean(self):\n        self.sh.run_cmd(\n            self._get_make_cmd() + ['--clean', LF],\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-modules",
          "type": "blob",
          "size": 4.9482421875,
          "content": "#!/usr/bin/env python3\n\nimport distutils.dir_util\nimport os\nimport platform\nimport shlex\nimport shutil\n\nimport common\nfrom shell_helpers import LF\nimport path_properties\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nBuild our Linux kernel modules without using Buildroot.\n\nSee also: https://cirosantilli.com/linux-kernel-module-cheat#host\n''')\n        self.add_argument(\n            '--make-args',\n            default='',\n            help='''\nPass custom options to make.\n''',\n        )\n        self._add_argument('--force-rebuild')\n        self.add_argument(\n            'kernel-modules',\n            default=[],\n            help='''\\\nWhich kernel modules to build. Default: build all.\nCan be either the path to the C file, or its basename without extension.''',\n            nargs='*',\n        )\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        os.makedirs(build_dir, exist_ok=True)\n        # I kid you not, out-of-tree build is not possible, O= does not work as for the kernel build:\n        #\n        # * https://stackoverflow.com/questions/5718899/building-an-out-of-tree-linux-kernel-module-in-a-separate-object-directory\n        # * https://stackoverflow.com/questions/12244979/build-kernel-module-into-a-specific-directory\n        # * https://stackoverflow.com/questions/18386182/out-of-tree-kernel-modules-multiple-module-single-makefile-same-source-file\n        #\n        # This copies only modified files as per:\n        # https://stackoverflow.com/questions/5718899/building-an-out-of-tree-linux-kernel-module-in-a-separate-object-directory\n        distutils.dir_util.copy_tree(\n            self.env['kernel_modules_source_dir'],\n            os.path.join(build_dir, self.env['kernel_modules_subdir']),\n            update=1,\n        )\n        distutils.dir_util.copy_tree(\n            self.env['include_source_dir'],\n            os.path.join(build_dir, self.env['include_subdir']),\n            update=1,\n        )\n        all_kernel_modules = []\n        for basename in os.listdir(self.env['kernel_modules_source_dir']):\n            abspath = os.path.join(self.env['kernel_modules_source_dir'], basename)\n            if os.path.isfile(abspath):\n                noext, ext = os.path.splitext(basename)\n                if ext == self.env['c_ext']:\n                    relpath = abspath[len(self.env['root_dir']) + 1:]\n                    my_path_properties = path_properties.get(relpath)\n                    if my_path_properties.should_be_built(self.env):\n                        all_kernel_modules.append(noext)\n        if self.env['kernel_modules'] == []:\n            kernel_modules = all_kernel_modules\n        else:\n            kernel_modules = map(lambda x: os.path.splitext(os.path.split(x)[1])[0], self.env['kernel_modules'])\n        object_files = map(lambda x: x + self.env['obj_ext'], kernel_modules)\n        if self.env['host']:\n            build_subdir = self.env['kernel_modules_build_host_subdir']\n        else:\n            build_subdir = self.env['kernel_modules_build_subdir']\n        ccache = shutil.which('ccache')\n        if ccache is not None:\n            cc = '{} {}'.format(ccache, self.env['gcc_path'])\n        else:\n            cc = self.env['gcc_path']\n        if self.env['host']:\n            linux_dir = os.path.join('/lib', 'modules', platform.uname().release, 'build')\n        else:\n            linux_dir = self.env['linux_build_dir']\n        ccflags = [\n            '-I', self.env['root_dir'], LF,\n        ]\n        make_args_extra = []\n        if self.env['verbose']:\n            make_args_extra.extend(['V=1', LF])\n        if self.env['force_rebuild']:\n            make_args_extra.extend(['-B', LF])\n        self.sh.run_cmd(\n            (\n                [\n                    'make', LF,\n                    '-j', str(self.env['nproc']), LF,\n                    'ARCH={}'.format(self.env['linux_arch']), LF,\n                    'CC={}'.format(cc), LF,\n                    'CCFLAGS={}'.format(self.sh.cmd_to_string(ccflags)), LF,\n                    'CROSS_COMPILE={}'.format(self.env['toolchain_prefix_dash']), LF,\n                    'LINUX_DIR={}'.format(linux_dir), LF,\n                    'M={}'.format(build_subdir), LF,\n                    'OBJECT_FILES={}'.format(' '.join(object_files)), LF,\n                ] +\n                make_args_extra +\n                self.sh.shlex_split(self.env['make_args'])\n            ),\n            cwd=os.path.join(self.env['kernel_modules_build_subdir']),\n        )\n        if not self.env['host']:\n            self.sh.copy_dir_if_update_non_recursive(\n                srcdir=self.env['kernel_modules_build_subdir'],\n                destdir=self.env['out_rootfs_overlay_lkmc_dir'],\n                filter_ext=self.env['kernel_module_ext'],\n            )\n\n    def get_build_dir(self):\n        if self.env['host']:\n            return self.env['kernel_modules_build_host_dir']\n        else:\n            return self.env['kernel_modules_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-qemu",
          "type": "blob",
          "size": 2.0078125,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__()\n        self._add_argument('--configure')\n        self.add_argument(\n            '--extra-config-args',\n            default='',\n            help='''\\\nExtra arguments to pass to configure\n'''\n        )\n        self._add_argument('extra_make_args')\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        os.makedirs(build_dir, exist_ok=True)\n        if self.env['verbose']:\n            verbose = ['V=1']\n        else:\n            verbose = []\n        if self.env['mode'] == 'userland':\n            target_list = '{}-linux-user'.format(self.env['arch'])\n        else:\n            target_list = '{}-softmmu'.format(self.env['arch'])\n        if self.env['qemu_build_type'] == 'debug':\n            # https://stackoverflow.com/questions/4689136/debug-qemu-with-gdb\n            build_type_cmd = ['--enable-debug', LF]\n        else:\n            build_type_cmd = []\n        if self.env['configure']:\n            self.sh.run_cmd(\n                [\n                    os.path.join(self.env['qemu_source_dir'], 'configure'), LF,\n                    '--enable-trace-backends=simple', LF,\n                    '--target-list={}'.format(target_list), LF,\n                    '--enable-sdl', LF,\n                ] +\n                build_type_cmd +\n                self.sh.shlex_split(self.env['extra_config_args']),\n                extra_paths=[self.env['ccache_dir']],\n                cwd=build_dir\n            )\n        self.sh.run_cmd(\n            (\n                [\n                    'make', LF,\n                    '-j', str(self.env['nproc']), LF,\n\n                ] +\n                verbose +\n                self.sh.add_newlines(self.env['extra_make_args'])\n            ),\n            cwd=build_dir,\n            extra_paths=[self.env['ccache_dir']],\n        )\n\n    def get_build_dir(self):\n        return self.env['qemu_build_dir']\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-test",
          "type": "blob",
          "size": 0.3349609375,
          "content": "#!/usr/bin/env bash\n# Build just enough to run ./test:\n# https://cirosantilli.com/linux-kernel-module-cheat#automated-tests\nset -eu\ntest_size=1\nwhile [ $# -gt 0 ]; do\n  case \"$1\" in\n    --size)\n      test_size=\"$2\"\n      shift 2\n      ;;\n  esac\ndone\n./build-test-boot --size \"$test_size\"\n./build --all-archs test-gdb test-executables-userland\n"
        },
        {
          "name": "build-test-boot",
          "type": "blob",
          "size": 0.5888671875,
          "content": "#!/usr/bin/env bash\n# We want to move this into ./build. The only reason we haven't is that\n# what to build depends on --size, which ./build does not support right now.\n# The best way to solve this is to move the dependency checking into the run\n# scripts, which will take a while to refactor.\nset -eux\ntest_size=1\nwhile [ $# -gt 0 ]; do\n  case \"$1\" in\n    --size)\n      test_size=\"$2\"\n      shift 2\n      ;;\n  esac\ndone\n./build --all-archs qemu-gem5-buildroot\nif [ \"$test_size\" -ge 3 ]; then\n  ./build-gem5 --arch aarch64 --gem5-build-type debug\n  ./build-gem5 --arch aarch64 --gem5-build-type fast\nfi\n"
        },
        {
          "name": "build-userland",
          "type": "blob",
          "size": 3.833984375,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport shlex\nimport subprocess\nimport threading\n\nfrom shell_helpers import LF\nimport common\nimport thread_pool\n\nclass Main(common.BuildCliFunction):\n    def __init__(self, *args, **kwargs):\n        if not 'description' in kwargs:\n            kwargs['description'] = '''\\\nBuild our compiled userland examples.\n'''\n        if not 'defaults' in kwargs:\n            kwargs['defaults'] = {}\n        if not 'mode' in kwargs['defaults']:\n            kwargs['defaults']['mode'] = 'userland'\n        super().__init__(*args, **kwargs)\n        self._add_argument('--ccflags')\n        self._add_argument('--force-rebuild')\n        self._add_argument('--optimization-level')\n        self.add_argument(\n            'targets',\n            default=[],\n            help='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#build-userland\n''',\n            nargs='*',\n        )\n\n    def build(self):\n        build_dir = self.get_build_dir()\n        cc_flags = [\n            '-I', self.env['root_dir'], LF,\n        ] + self.env['ccflags']\n        extra_obj_lkmc_common = os.path.join(\n            build_dir,\n            self.env['common_basename_noext'] + self.env['obj_ext']\n        )\n        self._build_one(\n            in_path=self.env['common_c'],\n            out_path=extra_obj_lkmc_common,\n            cc_flags=cc_flags,\n            extra_deps=[self.env['common_h']],\n            link=False,\n        )\n        with thread_pool.ThreadPool(\n            self._build_one,\n            nthreads=self.env['nproc'],\n            submit_raise_exit=self.env['quit_on_fail'],\n        ) as my_thread_pool:\n            for target in self.env['targets']:\n                for path, in_dirnames, in_filenames in self.sh.walk(target):\n                    for in_filename in in_filenames:\n                        in_ext = os.path.splitext(in_filename)[1]\n                        if not in_ext in self.env['build_in_exts']:\n                            continue\n                        in_path = os.path.join(path, in_filename)\n                        my_thread_pool.submit({\n                            'cc_flags': cc_flags,\n                            'extra_objs_lkmc_common': [extra_obj_lkmc_common],\n                            'in_path': in_path,\n                            'out_path': self.resolve_userland_executable(in_path),\n                        })\n        exit_status = self._handle_thread_pool_errors(my_thread_pool)\n        if exit_status != 0:\n            return exit_status\n        if self.env['copy_overlay']:\n            self.sh.copy_dir_if_update(\n                srcdir=build_dir,\n                destdir=os.path.join(\n                    self.env['out_rootfs_overlay_lkmc_dir'],\n                    self.env['out_rootfs_overlay_dir_prefix']\n                ),\n                filter_ext=self.env['userland_executable_ext'],\n            )\n        return exit_status\n\n    def clean(self):\n        if self.env['in_tree']:\n            for target in self.env['targets']:\n                if os.path.exists(target):\n                    if os.path.isfile(target):\n                        self.sh.rmrf(self.resolve_userland_executable(target))\n                    else:\n                        for path, dirnames, filenames in self.sh.walk(target):\n                            for filename in filenames:\n                                if os.path.splitext(filename)[1] in self.env['userland_out_exts']:\n                                    self.sh.rmrf(os.path.join(path, filename))\n        else:\n            for target in self.env['targets']:\n                self.sh.rmrf(self.resolve_userland_executable(target))\n\n    def get_build_dir(self):\n        return self.env['userland_build_dir']\n\n    def setup_one_build(self):\n        self.env['targets'] = self.resolve_targets(\n            [self.env['userland_source_dir']],\n            self.env['targets']\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-userland-in-tree",
          "type": "blob",
          "size": 0.6904296875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport platform\nimport subprocess\n\nimport lkmc.import_path\n\nbuild_userland = lkmc.import_path.import_path_relative_root('build-userland')\n\nclass Main(build_userland.Main):\n    def __init__(self):\n        defaults = {\n            'archs': [platform.processor()],\n            'gcc_which': 'host',\n            'in_tree': True,\n            'targets': ['.'],\n        }\n        if self.cwd_in_lib():\n            defaults['package_all'] = True\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#userland-setup-getting-started-natively\n''',\n            defaults=defaults\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "build-xen",
          "type": "blob",
          "size": 1.154296875,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#xen\nset -eux\ncd submodules/xen\nmake \\\n  -j `nproc` \\\n  dist-xen \\\n  CONFIG_DEBUG=y \\\n  CONFIG_EARLY_PRINTK=pl011,0x09000000 \\\n  CROSS_COMPILE=aarch64-linux-gnu- \\\n  XEN_TARGET_ARCH=arm64 \\\n;\ncd ../boot-wrapper-aarch64\n../../out/qemu/default/aarch64-softmmu/qemu-system-aarch64 \\\n  -machine virt \\\n  -machine virtualization=on \\\n  -machine gic_version=3 \\\n  -cpu cortex-a57 \\\n  -kernel xen-system.axf \\\n  -serial mon:stdio \\\n  -nographic \\\n  -machine dumpdtb=dtb.dtb \\\n;\nautoreconf -i\n./configure \\\n  --enable-gicv3 \\\n  --enable-psci \\\n  --host=aarch64-linux-gnu \\\n  --with-cmdline=\"console=hvc0 earlycon=pl011,0x09000000 root=/dev/vda rw\" \\\n  --with-dtb=dtb.dtb \\\n  --with-kernel-dir=../../out/linux/default/aarch64 \\\n  --with-xen-cmdline=\"dtuart=/pl011,0x09000000 console=dtuart no-bootscrub dom0_mem=512M loglvl=all guest_loglvl=all\" \\\n  --with-xen=../xen/xen/xen \\\n;\nmake -j `nproc`\n../../out/qemu/default/aarch64-softmmu/qemu-system-aarch64 \\\n  -machine virt \\\n  -machine virtualization=on \\\n  -machine gic_version=3 \\\n  -cpu cortex-a57 \\\n  -kernel xen-system.axf \\\n  -serial mon:stdio \\\n  -nographic \\\n;\n"
        },
        {
          "name": "buildroot_config",
          "type": "tree",
          "content": null
        },
        {
          "name": "buildroot_override",
          "type": "blob",
          "size": 0.33984375,
          "content": "BINUTILS_OVERRIDE_SRCDIR = ../../submodules/binutils-gdb\nGCC_INITIAL_OVERRIDE_SRCDIR = ../../submodules/gcc\nGCC_FINAL_OVERRIDE_SRCDIR = ../../submodules/gcc\nGDB_OVERRIDE_SRCDIR = ../../submodules/binutils-gdb\nGLIBC_OVERRIDE_SRCDIR = ../../submodules/glibc\nLINUX_OVERRIDE_SRCDIR = ../../submodules/linux\nQEMU_OVERRIDE_SRCDIR = ../../submodules/qemu\n"
        },
        {
          "name": "buildroot_packages",
          "type": "tree",
          "content": null
        },
        {
          "name": "busybox_config_fragment",
          "type": "blob",
          "size": 0.7001953125,
          "content": "CONFIG_BASE64=y\nCONFIG_DEPMOD=y\nCONFIG_MODINFO=y\nCONFIG_NC=y\nCONFIG_NC_EXTRA=y\nCONFIG_NC_SERVER=y\nCONFIG_STAT=y\n\n# On ARM, with our lkmc_platform_device:\n#\n#     devmem 0x101e9000 w 0x12345678\n#\n# Then on QEMU monitor, notice that the registers don't actually change value:\n#\n#     xp/4 0x101e9000\n#\n# Uses /dev/mem.\n#\n# See also:\n#\n# - https://superuser.com/questions/71389/what-is-dev-mem/1214662#1214662\n# - https://unix.stackexchange.com/questions/4948/shell-command-to-read-device-registers\n# - man mem\n#\n# TODO: why with mmap MAP_PRIVATE (used in my previous custom naive version),\n# the entire register page is read?;\n#\n# TODO: have a look at: https://github.com/kaiwan/device-memory-readwrite\nCONFIG_DEVMEM=y\n"
        },
        {
          "name": "cli_function.py",
          "type": "blob",
          "size": 19.3505859375,
          "content": "#!/usr/bin/env python3\n\n'''\nThis file is GPLv3 like the rest of this repo.\nHowever, you may use it in a project with any license through imports,\nwithout affecting the license of the rest of your project, even if you include\nthis file in the project source tree, as long as you publish any modifications\nmade to this file.\n'''\n\nimport argparse\nimport bisect\nimport collections\nimport os\nimport sys\n\nimport lkmc.import_path\n\nclass _Argument:\n    def __init__(\n            self,\n            long_or_short_1,\n            long_or_short_2=None,\n            default=None,\n            dest=None,\n            help=None,\n            nargs=None,\n            **kwargs\n        ):\n            self.args = []\n            # argparse is crappy and cannot tell us if arguments were given or not.\n            # We need that information to decide if the config file should override argparse or not.\n            # So we just use None as a sentinel.\n            self.kwargs = {'default': None}\n            shortname, longname, key, is_option = self.get_key(\n                long_or_short_1,\n                long_or_short_2,\n                dest\n            )\n            if shortname is not None:\n                self.args.append(shortname)\n            if is_option:\n                self.args.append(longname)\n            else:\n                self.args.append(key)\n                self.kwargs['metavar'] = longname\n                if default is not None and nargs is None:\n                    self.kwargs['nargs'] = '?'\n            if dest is not None:\n                self.kwargs['dest'] = dest\n            if nargs is not None:\n                self.kwargs['nargs'] = nargs\n            if default is True or default is False:\n                bool_action = 'store_true'\n                self.is_bool = True\n            else:\n                self.is_bool = False\n                if default is None and (\n                    nargs in ('*', '+')\n                    or ('action' in kwargs and kwargs['action'] == 'append')\n                ):\n                    default = []\n            if self.is_bool and not 'action' in kwargs:\n                self.kwargs['action'] = bool_action\n            if help is not None and help != '':\n                if default is not None:\n                    if help[-1] == '\\n':\n                        if '\\n\\n' in help[:-1]:\n                            help += '\\n'\n                    elif help[-1] == ' ':\n                        pass\n                    else:\n                        help += ' '\n                    help += 'Default: {}'.format(default)\n                self.kwargs['help'] = help\n            self.optional = (\n                default is not None or\n                self.is_bool or\n                is_option or\n                nargs in ('?', '*', '+')\n            )\n            self.kwargs.update(kwargs)\n            self.default = default\n            self.longname = longname\n            self.key = key\n            self.is_option = is_option\n            self.nargs = nargs\n\n    def __str__(self):\n        return str(self.args) + ' ' + str(self.kwargs)\n\n    @staticmethod\n    def get_key(\n        long_or_short_1,\n        long_or_short_2=None,\n        dest=None,\n        **kwargs\n    ):\n        if long_or_short_2 is None:\n            shortname = None\n            longname = long_or_short_1\n        else:\n            shortname = long_or_short_1\n            longname = long_or_short_2\n        if longname[0] == '-':\n            key = longname.lstrip('-').replace('-', '_')\n            is_option = True\n        else:\n            key = longname.replace('-', '_')\n            is_option = False\n        if dest is not None:\n            key = dest\n        return shortname, longname, key, is_option\n\nclass CliFunction:\n    '''\n    A function that can be called either from Python code, or from the command line.\n\n    Features:\n\n    * single argument description in format very similar to argparse\n    * handle default arguments transparently in both cases\n    * expose a configuration file mechanism to get default parameters from a file\n    * fix some argparse.ArgumentParser() annoyances:\n    ** allow dashes in positional arguments:\n       https://stackoverflow.com/questions/12834785/having-options-in-argparse-with-a-dash\n    ** boolean defaults automatically use store_true or store_false, and add a --no-* CLI\n       option to invert them if set from the config\n    * from a Python call, get the corresponding CLI string list. See get_cli.\n    * easily determine if arguments were given on the command line\n      https://stackoverflow.com/questions/30487767/check-if-argparse-optional-argument-is-set-or-not/30491369\n\n    This somewhat duplicates: https://click.palletsprojects.com but:\n\n    * that decorator API is insane\n    * CLI + Python for single functions was wontfixed: https://github.com/pallets/click/issues/40\n    +\n    Oh, and I commented on that issue pointing to this alternative and they deleted my comment:\n    https://github.com/pallets/click/issues/40#event-2088718624 Lol. It could have been useful\n    for other Googlers and as an implementation reference.\n    '''\n    def __call__(self, **kwargs):\n        '''\n        Python version of the function call. Not called by cli() indirectly,\n        so can be overridden to distinguish between Python and CLI calls.\n\n        :type arguments: Dict\n        '''\n        return self._do_main(kwargs)\n\n    def _do_main(self, kwargs):\n        return self.main(**self._get_args(kwargs))\n\n    def __init__(self, default_config_file=None, description=None, extra_config_params=None):\n        self._arguments = collections.OrderedDict()\n        self._default_config_file = default_config_file\n        self._description = description\n        self.extra_config_params = extra_config_params\n        if self._default_config_file is not None:\n            self.add_argument(\n                '--config-file',\n                default=self._default_config_file,\n                help='Path to the configuration file to use'\n            )\n\n    def __str__(self):\n        return '\\n'.join(str(arg[key]) for key in self._arguments)\n\n    def _get_args(self, kwargs):\n        '''\n        Resolve default arguments from the config file and CLI param defaults.\n\n        Add an extra _args_given argument which determines if an argument was given or not.\n        Args set from the config file count as given.\n        '''\n        args_with_defaults = kwargs.copy()\n        # Add missing args from config file.\n        config_file = None\n        args_given = {}\n        if 'config_file' in args_with_defaults and args_with_defaults['config_file'] is not None:\n            config_file = args_with_defaults['config_file']\n            args_given['config_file'] = True\n        else:\n            config_file = self._default_config_file\n            args_given['config_file'] = False\n        for key in self._arguments:\n            args_given[key] = not (\n                not key in args_with_defaults or\n                args_with_defaults[key] is None or\n                self._arguments[key].nargs == '*' and args_with_defaults[key] == []\n            )\n        if config_file is not None:\n            if os.path.exists(config_file):\n                config_configs = {}\n                config = lkmc.import_path.import_path(config_file)\n                if self.extra_config_params is None:\n                    config.set_args(config_configs)\n                else:\n                    config.set_args(config_configs, self.extra_config_params)\n                for key in config_configs:\n                    if key not in self._arguments:\n                        raise Exception('Unknown key in config file: ' + key)\n                    if not args_given[key]:\n                        args_with_defaults[key] = config_configs[key]\n                        args_given[key] = True\n            elif args_given['config_file']:\n                raise Exception('Config file does not exist: ' + config_file)\n        # Add missing args from hard-coded defaults.\n        for key in self._arguments:\n            argument = self._arguments[key]\n            # TODO: in (None, []) is ugly, and will probably go wrong at some point,\n            # there must be a better way to do it, but I'm lazy now to think.\n            if (not key in args_with_defaults) or args_with_defaults[key] in (None, []):\n                if argument.optional:\n                    args_with_defaults[key] = argument.default\n                else:\n                    raise Exception('Value not given for mandatory argument: ' + key)\n        args_with_defaults['_args_given'] = args_given\n        if 'config_file' in args_with_defaults:\n            del args_with_defaults['config_file']\n        return args_with_defaults\n\n    def add_argument(\n            self,\n            *args,\n            **kwargs\n        ):\n            argument = _Argument(*args, **kwargs)\n            self._arguments[argument.key] = argument\n\n    def cli_noexit(self, cli_args=None):\n        '''\n        Call the function from the CLI. Parse command line arguments\n        to get all arguments. Does not exit the program after running this function.\n\n        :return: the return of main\n        '''\n        parser = argparse.ArgumentParser(\n            description=self._description,\n            formatter_class=argparse.RawTextHelpFormatter,\n        )\n        for key in self._arguments:\n            argument = self._arguments[key]\n            parser.add_argument(*argument.args, **argument.kwargs)\n            # print(key)\n            # print(argument.args)\n            # print(argument.kwargs)\n            if argument.is_bool:\n                new_longname = '--no' + argument.longname[1:]\n                kwargs = argument.kwargs.copy()\n                kwargs['default'] = not argument.default\n                if kwargs['action'] in ('store_true', 'store_false'):\n                    kwargs['action'] = 'store_false'\n                if 'help' in kwargs:\n                    del kwargs['help']\n                parser.add_argument(new_longname, dest=argument.key, **kwargs)\n        args = parser.parse_args(args=cli_args)\n        return self._do_main(vars(args))\n\n    def cli(self, *args, **kwargs):\n        '''\n        Same as cli_noxit, but also exit the program with status equal to the\n        return value of main. main must return an integer for this to be used.\n\n        None is considered as 0.\n        '''\n        exit_status = self.cli_noexit(*args, **kwargs)\n        if exit_status is None:\n            exit_status = 0\n        sys.exit(exit_status)\n\n    def get_cli(self, **kwargs):\n        '''\n        :rtype: List[Type(str)]\n        :return: the canonical command line arguments arguments that would\n                 generate this Python function call.\n\n                 (--key, value) option pairs are grouped into tuples, and all\n                 other values are grouped in their own tuple (positional_arg,)\n                 or (--bool-arg,).\n\n                 Arguments with default values are not added, but arguments\n                 that are set by the config are also given.\n\n                 The optional arguments are sorted alphabetically, followed by\n                 positional arguments.\n\n                 The long option name is used if both long and short versions\n                 are given.\n        '''\n        options = []\n        positional_dict = {}\n        kwargs = self._get_args(kwargs)\n        for key in kwargs:\n            if not key in ('_args_given',):\n                argument = self._arguments[key]\n                default = argument.default\n                value = kwargs[key]\n                if value != default:\n                    if argument.is_option:\n                        if argument.is_bool:\n                            if value:\n                                vals = [(argument.longname,)]\n                            else:\n                                vals = [('--no-' + argument.longname[2:],)]\n                        elif 'action' in argument.kwargs and argument.kwargs['action'] == 'append':\n                            vals = [(argument.longname, str(val)) for val in value]\n                        else:\n                            vals = [(argument.longname, str(value))]\n                        for val in vals:\n                            bisect.insort(options, val)\n                    else:\n                        if type(value) is list:\n                            positional_dict[key] = [tuple([v]) for v in value]\n                        else:\n                            positional_dict[key] = [(str(value),)]\n        # Python built-in data structures suck.\n        # https://stackoverflow.com/questions/27726245/getting-the-key-index-in-a-python-ordereddict/27726534#27726534\n        positional = []\n        for key in self._arguments.keys():\n            if key in positional_dict:\n                positional.extend(positional_dict[key])\n        return options + positional\n\n    @staticmethod\n    def get_key(*args, **kwargs):\n        return _Argument.get_key(*args, **kwargs)\n\n    def main(self, **kwargs):\n        '''\n        Do the main function call work.\n\n        :type arguments: Dict\n        '''\n        raise NotImplementedError\n\nif __name__ == '__main__':\n    class OneCliFunction(CliFunction):\n        def __init__(self):\n            super().__init__(\n                default_config_file='cli_function_test_config.py',\n                description = '''\\\nDescription of this\namazing function!\n''',\n            )\n            self.add_argument('-a', '--asdf', default='A', help='Help for asdf'),\n            self.add_argument('-q', '--qwer', default='Q', help='Help for qwer'),\n            self.add_argument('-b', '--bool-true', default=True, help='Help for bool-true'),\n            self.add_argument('--bool-false', default=False, help='Help for bool-false'),\n            self.add_argument('--dest', dest='custom_dest', help='Help for dest'),\n            self.add_argument('--bool-cli', default=False, help='Help for bool'),\n            self.add_argument('--bool-nargs', default=False, nargs='?', action='store', const='')\n            self.add_argument('--no-default', help='Help for no-bool'),\n            self.add_argument('--append', action='append')\n            self.add_argument('pos-mandatory', help='Help for pos-mandatory', type=int),\n            self.add_argument('pos-optional', default=0, help='Help for pos-optional', type=int),\n            self.add_argument('args-star', help='Help for args-star', nargs='*'),\n\n        def main(self, **kwargs):\n            del kwargs['_args_given']\n            return kwargs\n\n    one_cli_function = OneCliFunction()\n\n    # Default code call.\n    default = one_cli_function(pos_mandatory=1)\n    assert default == {\n        'asdf': 'A',\n        'qwer': 'Q',\n        'bool_true': True,\n        'bool_false': False,\n        'bool_nargs': False,\n        'bool_cli': True,\n        'custom_dest': None,\n        'no_default': None,\n        'append': [],\n        'pos_mandatory': 1,\n        'pos_optional': 0,\n        'args_star': []\n    }\n\n    # Default CLI call with programmatic CLI arguments.\n    out = one_cli_function.cli_noexit(['1'])\n    assert out == default\n\n    # asdf\n    out = one_cli_function(pos_mandatory=1, asdf='B')\n    assert out['asdf'] == 'B'\n    out['asdf'] = default['asdf']\n    assert out == default\n\n    # asdf and qwer\n    out = one_cli_function(pos_mandatory=1, asdf='B', qwer='R')\n    assert out['asdf'] == 'B'\n    assert out['qwer'] == 'R'\n    out['asdf'] = default['asdf']\n    out['qwer'] = default['qwer']\n    assert out == default\n\n    if '--bool-true':\n        out = one_cli_function(pos_mandatory=1, bool_true=False)\n        cli_out = one_cli_function.cli_noexit(['--no-bool-true', '1'])\n        assert out == cli_out\n        assert out['bool_true'] == False\n        out['bool_true'] = default['bool_true']\n        assert out == default\n\n    if '--bool-false':\n        out = one_cli_function(pos_mandatory=1, bool_false=True)\n        cli_out = one_cli_function.cli_noexit(['--bool-false', '1'])\n        assert out == cli_out\n        assert out['bool_false'] == True\n        out['bool_false'] = default['bool_false']\n        assert out == default\n\n    if '--bool-nargs':\n        out = one_cli_function(pos_mandatory=1, bool_nargs=True)\n        assert out['bool_nargs'] == True\n        out['bool_nargs'] = default['bool_nargs']\n        assert out == default\n\n        out = one_cli_function(pos_mandatory=1, bool_nargs='asdf')\n        assert out['bool_nargs'] == 'asdf'\n        out['bool_nargs'] = default['bool_nargs']\n        assert out == default\n\n    # --dest\n    out = one_cli_function(pos_mandatory=1, custom_dest='a')\n    cli_out = one_cli_function.cli_noexit(['--dest', 'a', '1'])\n    assert out == cli_out\n    assert out['custom_dest'] == 'a'\n    out['custom_dest'] = default['custom_dest']\n    assert out == default\n\n    # Positional\n    out = one_cli_function(pos_mandatory=1, pos_optional=2, args_star=['3', '4'])\n    # TODO: make actual positional arguments work.\n    # out = one_cli_function(1, 2, '3', '4')\n    assert out['pos_mandatory'] == 1\n    assert out['pos_optional'] == 2\n    assert out['args_star'] == ['3', '4']\n    cli_out = one_cli_function.cli_noexit(['1', '2', '3', '4'])\n    assert out == cli_out\n    out['pos_mandatory'] = default['pos_mandatory']\n    out['pos_optional'] = default['pos_optional']\n    out['args_star'] = default['args_star']\n    assert out == default\n\n    # Star\n    out = one_cli_function(append=['1', '2'], pos_mandatory=1)\n    cli_out = one_cli_function.cli_noexit(['--append', '1', '--append', '2', '1'])\n    assert out == cli_out\n    assert out['append'] == ['1', '2']\n    out['append'] = default['append']\n    assert out == default\n\n    # Force a boolean value set on the config to be False on CLI.\n    assert one_cli_function.cli_noexit(['--no-bool-cli', '1'])['bool_cli'] is False\n\n    # Pick another config file.\n    assert one_cli_function.cli_noexit(['--config-file', 'cli_function_test_config_2.py', '1'])['bool_cli'] is False\n\n    # Extra config file for '*'.\n    assert one_cli_function.cli_noexit(['--config-file', 'cli_function_test_config_2.py', '1', '2', '3', '4'])['args_star'] == ['3', '4']\n    assert one_cli_function.cli_noexit(['--config-file', 'cli_function_test_config_2.py', '1', '2'])['args_star'] == ['asdf', 'qwer']\n\n    # get_cli\n    assert one_cli_function.get_cli(pos_mandatory=1, asdf='B') == [('--asdf', 'B'), ('--bool-cli',), ('1',)]\n    assert one_cli_function.get_cli(pos_mandatory=1, asdf='B', qwer='R') == [('--asdf', 'B'), ('--bool-cli',), ('--qwer', 'R'), ('1',)]\n    assert one_cli_function.get_cli(pos_mandatory=1, bool_true=False) == [('--bool-cli',), ('--no-bool-true',), ('1',)]\n    assert one_cli_function.get_cli(pos_mandatory=1, bool_false=True) == [('--bool-cli',), ('--bool-false',), ('1',)]\n    assert one_cli_function.get_cli(pos_mandatory=1, pos_optional=2, args_star=['asdf', 'qwer']) == [('--bool-cli',), ('1',), ('2',), ('asdf',), ('qwer',)]\n    assert one_cli_function.get_cli(pos_mandatory=1, append=['2', '3']) == [('--append', '2'), ('--append', '3',), ('--bool-cli',), ('1',)]\n\n    class NargsWithDefault(CliFunction):\n        def __init__(self):\n            super().__init__()\n            self.add_argument('args-star', default=['1', '2'], nargs='*'),\n        def main(self, **kwargs):\n            return kwargs\n    nargs_with_default = NargsWithDefault()\n    default = nargs_with_default()\n    assert default['args_star'] == ['1', '2']\n    default_cli = nargs_with_default.cli_noexit([])\n    assert default_cli['args_star'] == ['1', '2']\n    assert nargs_with_default.cli_noexit(['1', '2', '3', '4'])['args_star'] == ['1', '2', '3', '4']\n\n    if len(sys.argv) > 1:\n        # CLI call with argv command line arguments.\n        print(one_cli_function.cli())\n"
        },
        {
          "name": "cli_function_test_config.py",
          "type": "blob",
          "size": 0.0927734375,
          "content": "def set_args(args):\n    '''\n    :type args: Dict[str, Any]\n    '''\n    args['bool_cli'] = True\n"
        },
        {
          "name": "cli_function_test_config_2.py",
          "type": "blob",
          "size": 0.1337890625,
          "content": "def set_args(args):\n    '''\n    :type args: Dict[str, Any]\n    '''\n    args['bool_cli'] = False\n    args['args_star'] = ['asdf', 'qwer']\n"
        },
        {
          "name": "common.py",
          "type": "blob",
          "size": 90.6103515625,
          "content": "#!/usr/bin/env python3\n\nimport argparse\nimport bisect\nimport collections\nimport copy\nimport datetime\nimport enum\nimport functools\nimport glob\nimport inspect\nimport itertools\nimport json\nimport math\nimport os\nimport platform\nimport pathlib\nimport queue\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport threading\nfrom typing import Union\nimport time\nimport urllib\nimport urllib.request\n\nfrom shell_helpers import LF\n# https://cirosantilli.com/china-dictatorship/#mirrors\nimport china_dictatorship\nassert \"Tiananmen Square protests\" in china_dictatorship.get_data()\nimport cli_function\nimport path_properties\nimport shell_helpers\nimport thread_pool\n\ncommon = sys.modules[__name__]\n\n# Fixed parameters that don't depend on CLI arguments.\nconsts = {}\nconsts['repo_short_id'] = 'lkmc'\nconsts['linux_kernel_version'] = '5.9.2'\n# https://stackoverflow.com/questions/20010199/how-to-determine-if-a-process-runs-inside-lxc-docker\nconsts['in_docker'] = os.path.exists('/.dockerenv')\nconsts['root_dir'] = os.path.dirname(os.path.abspath(__file__))\nconsts['data_dir'] = os.path.join(consts['root_dir'], 'data')\nconsts['p9_dir'] = os.path.join(consts['data_dir'], '9p')\nconsts['gem5_non_default_source_root_dir'] = os.path.join(consts['data_dir'], 'gem5')\nif consts['in_docker']:\n    # fatal: unsafe repository ('/root/lkmc' is owned by someone else)\n    # Fuck these error checks, let me shoot my feet in peace.\n    # The best solution would be to actually get Docker to mount\n    # the current diretory as root. But I've never been able to do that:\n    # * https://stackoverflow.com/questions/51973179/docker-mount-volumes-as-root\n    # * https://unix.stackexchange.com/questions/523492/how-to-mount-files-as-specific-user-when-using-docker-namespace-remapping\n    # * https://stackoverflow.com/questions/35291520/docker-and-userns-remap-how-to-manage-volume-permissions-to-share-data-betwee\n    # So for now we see as owner e.g. 1000:1000 on the volume, and root:root on /.\n    # '*' to ignore all was added on Git 2.36... Without that we would need to add every single submodule to the list.\n    # * https://stackoverflow.com/questions/71901632/fatal-unsafe-repository-home-repon-is-owned-by-someone-else\n    # * https://stackoverflow.com/questions/71849415/i-cannot-add-the-parent-directory-to-safe-directory-in-git/71904131#71904131\n    # * https://www.reddit.com/r/docker/comments/o8bnft/is_it_possible_to_mount_files_with_readwrite/\n    subprocess.check_output(['git', 'config', '--global', '--add', 'safe.directory', '*'])\n    consts['out_dir'] = os.path.join(consts['root_dir'], 'out.docker')\nelse:\n    consts['out_dir'] = os.path.join(consts['root_dir'], 'out')\nconsts['readme'] = os.path.join(consts['root_dir'], 'README.adoc')\nconsts['out_doc_dir'] = os.path.join(consts['out_dir'], 'doc')\nconsts['readme_out'] = os.path.join(consts['out_dir'], 'README.html')\nconsts['build_doc_log'] = os.path.join(consts['out_dir'], 'build-doc.log')\nconsts['build_doc_multipage_log'] = os.path.join(consts['out_dir'], 'build-doc-multipage.log')\nconsts['gem5_out_dir'] = os.path.join(consts['out_dir'], 'gem5')\nconsts['kernel_modules_build_base_dir'] = os.path.join(consts['out_dir'], 'kernel_modules')\nconsts['buildroot_out_dir'] = os.path.join(consts['out_dir'], 'buildroot')\nconsts['gem5_m5_build_dir'] = os.path.join(consts['out_dir'], 'util', 'm5')\nconsts['run_dir_base'] = os.path.join(consts['out_dir'], 'run')\nconsts['crosstool_ng_out_dir'] = os.path.join(consts['out_dir'], 'crosstool-ng')\nconsts['test_boot_benchmark_file'] = os.path.join(consts['out_dir'], 'test-boot.txt')\nconsts['packages_dir'] = os.path.join(consts['root_dir'], 'buildroot_packages')\nconsts['kernel_modules_subdir'] = 'kernel_modules'\nconsts['kernel_modules_source_dir'] = os.path.join(consts['root_dir'], consts['kernel_modules_subdir'])\nconsts['userland_subdir'] = 'userland'\nconsts['userland_source_dir'] = os.path.join(consts['root_dir'], consts['userland_subdir'])\nconsts['userland_libs_basename'] = 'libs'\nconsts['userland_source_libs_dir'] = os.path.join(consts['userland_source_dir'], consts['userland_libs_basename'])\nconsts['userland_source_arch_dir'] = os.path.join(consts['userland_source_dir'], 'arch')\nconsts['userland_executable_ext'] = '.out'\nconsts['baremetal_executable_ext'] = '.elf'\nconsts['baremetal_max_text_size'] = 0x1000000\nconsts['baremetal_memory_size'] = 0x2000000\nconsts['include_subdir'] = consts['repo_short_id']\nconsts['include_source_dir'] = os.path.join(consts['root_dir'], consts['include_subdir'])\nconsts['submodules_dir'] = os.path.join(consts['root_dir'], 'submodules')\nconsts['buildroot_source_dir'] = os.path.join(consts['submodules_dir'], 'buildroot')\nconsts['crosstool_ng_source_dir'] = os.path.join(consts['submodules_dir'], 'crosstool-ng')\nconsts['crosstool_ng_supported_archs'] = set(['arm', 'aarch64'])\nconsts['linux_source_dir'] = os.path.join(consts['submodules_dir'], 'linux')\nconsts['linux_config_dir'] = os.path.join(consts['root_dir'], 'linux_config')\nconsts['gem5_default_source_dir'] = os.path.join(consts['submodules_dir'], 'gem5')\nconsts['googletest_source_dir'] = os.path.join(consts['submodules_dir'], 'googletest')\nconsts['rootfs_overlay_dir'] = os.path.join(consts['root_dir'], 'rootfs_overlay')\nconsts['extract_vmlinux'] = os.path.join(consts['linux_source_dir'], 'scripts', 'extract-vmlinux')\nconsts['qemu_source_dir'] = os.path.join(consts['submodules_dir'], 'qemu')\nconsts['parsec_benchmark_source_dir'] = os.path.join(consts['submodules_dir'], 'parsec-benchmark')\nconsts['ccache_dir'] = os.path.join('/usr', 'lib', 'ccache')\nconsts['default_build_id'] = 'default'\nconsts['arch_short_to_long_dict'] = collections.OrderedDict([\n    ('x', 'x86_64'),\n    ('a', 'arm'),\n    ('A', 'aarch64'),\n])\n# All long arch names.\nconsts['all_long_archs'] = [consts['arch_short_to_long_dict'][k] for k in consts['arch_short_to_long_dict']]\n# All long and short arch names.\nconsts['arch_choices'] = set()\nfor key in consts['arch_short_to_long_dict']:\n    consts['arch_choices'].add(key)\n    consts['arch_choices'].add(consts['arch_short_to_long_dict'][key])\nconsts['default_arch'] = 'x86_64'\nconsts['gem5_cpt_prefix'] = '^cpt\\.'\ndef git_sha(repo_path):\n    return subprocess.check_output(['git', '-C', repo_path, 'log', '-1', '--format=%H']).decode().rstrip()\nconsts['sha'] = common.git_sha(consts['root_dir'])\nconsts['release_dir'] = os.path.join(consts['out_dir'], 'release')\nconsts['release_zip_file'] = os.path.join(consts['release_dir'], 'lkmc-{}.zip'.format(consts['sha']))\nconsts['github_repo_id'] = 'cirosantilli/linux-kernel-module-cheat'\nconsts['github_repo_url'] = 'https://github.com/' + consts['github_repo_id']\nconsts['homepage_url'] = 'https://cirosantilli.com/linux-kernel-module-cheat'\nconsts['asm_ext'] = '.S'\nconsts['c_ext'] = '.c'\nconsts['cxx_ext'] = '.cpp'\nconsts['header_ext'] = '.h'\nconsts['kernel_module_ext'] = '.ko'\nconsts['obj_ext'] = '.o'\n# https://cirosantilli.com/linux-kernel-module-cheat#baremetal-cpp\nconsts['baremetal_build_in_exts'] = [\n    consts['asm_ext'],\n    consts['c_ext'],\n]\nconsts['build_in_exts'] = consts['baremetal_build_in_exts'] + [\n    consts['cxx_ext']\n]\nconsts['userland_out_exts'] = [\n    consts['userland_executable_ext'],\n    consts['obj_ext'],\n]\nconsts['default_config_file'] = os.path.join(consts['data_dir'], 'config.py')\nconsts['serial_magic_exit_status_regexp_string'] = b'lkmc_exit_status_(\\d+)'\nconsts['baremetal_lib_basename'] = 'lib'\nconsts['emulator_userland_only_short_to_long_dict'] = collections.OrderedDict([\n    ('n', 'native'),\n])\nconsts['all_userland_only_emulators'] = set()\nfor key in consts['emulator_userland_only_short_to_long_dict']:\n    consts['all_userland_only_emulators'].add(key)\n    consts['all_userland_only_emulators'].add(consts['emulator_userland_only_short_to_long_dict'][key])\nconsts['emulator_short_to_long_dict'] = collections.OrderedDict([\n    ('q', 'qemu'),\n    ('g', 'gem5'),\n])\nconsts['emulator_short_to_long_dict'].update(consts['emulator_userland_only_short_to_long_dict'])\nconsts['all_long_emulators'] = [consts['emulator_short_to_long_dict'][k] for k in consts['emulator_short_to_long_dict']]\nconsts['emulator_choices'] = set()\nfor key in consts['emulator_short_to_long_dict']:\n    consts['emulator_choices'].add(key)\n    consts['emulator_choices'].add(consts['emulator_short_to_long_dict'][key])\nconsts['host_arch'] = platform.processor()\nconsts['guest_lkmc_home'] = os.sep + consts['repo_short_id']\nconsts['build_type_choices'] = [\n    # -O2 -g\n    'opt',\n    # -O0 -g\n    'debug'\n]\nconsts['gem5_build_type_choices'] = consts['build_type_choices'] + [\n    'fast', 'prof', 'perf',\n]\nconsts['build_type_default'] = 'opt'\n# Files whose basename start with this are gitignored.\nconsts['tmp_prefix'] = 'tmp.'\n\nclass ExitLoop(Exception):\n    pass\n\nclass LkmcCliFunction(cli_function.CliFunction):\n    '''\n    Common functionality shared across our CLI functions:\n\n    * command timing\n    * a lot some common flags, e.g.: --arch, --dry-run, --quiet, --verbose\n    * a lot of helpers that depend on self.env\n    +\n    self.env contains the command line arguments + a ton of values derived from those.\n    +\n    It would be beautiful to do this evaluation in a lazy way, e.g. with functions +\n    cache decorators:\n    https://stackoverflow.com/questions/815110/is-there-a-decorator-to-simply-cache-function-return-values\n    '''\n    def __init__(\n        self,\n        *args,\n        defaults=None,\n        **kwargs\n    ):\n        '''\n        :ptype defaults: Dict[str,Any]\n        :param defaults: override the default value of an argument\n        '''\n        kwargs['default_config_file'] = consts['default_config_file']\n        kwargs['extra_config_params'] = os.path.basename(inspect.getfile(self.__class__))\n        if defaults is None:\n            defaults = {}\n        self._defaults = defaults\n        self._is_common = True\n        self._common_args = set()\n        super().__init__(*args, **kwargs)\n        self.print_lock = threading.Lock()\n\n        # Args for all scripts.\n        arches = consts['arch_short_to_long_dict']\n        arches_string = []\n        for arch_short in arches:\n            arch_long = arches[arch_short]\n            arches_string.append('{} ({})'.format(arch_long, arch_short))\n        arches_string = ', '.join(arches_string)\n        self.add_argument(\n            '-A',\n            '--all-archs',\n            default=False,\n            help='''\\\nRun action for all supported --archs archs. Ignore --archs.\n'''.format(arches_string)\n        )\n        self.add_argument(\n            '-a',\n            '--arch',\n            action='append',\n            choices=consts['arch_choices'],\n            default=[consts['default_arch']],\n            dest='archs',\n            help='''\\\nCPU architecture to use. If given multiple times, run the action\nfor each arch sequentially in that order. If one of them fails, stop running.\nValid archs: {}\n'''.format(arches_string)\n        )\n        self.add_argument(\n            '--ccache',\n            default=True,\n            help='''\\\nEnable or disable ccache: https://cirosantilli.com/linux-kernel-module-cheat#ccache\n'''\n        )\n        self.add_argument(\n            '--china',\n            default=False,\n            help='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#china\n'''\n        )\n        self.add_argument(\n            '--disk-image',\n        )\n        self.add_argument(\n            '--dry-run',\n            default=False,\n            help='''\\\nPrint the commands that would be run, but don't run them.\n\nWe aim display every command that modifies the filesystem state, and generate\nBash equivalents even for actions taken directly in Python without shelling out.\n\nmkdir are generally omitted since those are obvious\n\nSee also: https://cirosantilli.com/linux-kernel-module-cheat#dry-run\n'''\n        )\n        self.add_argument(\n            '--gcc-which',\n            choices=[\n                'buildroot',\n                'crosstool-ng',\n                'host',\n                'host-baremetal'\n            ],\n            default='buildroot',\n            help='''\\\nWhich toolchain binaries to use:\n- buildroot: the ones we built with ./build-buildroot. For userland, links to glibc.\n- crosstool-ng: the ones we built with ./build-crosstool-ng. For baremetal, links to newlib.\n- host: the host distro pre-packaged userland ones. For userland, links to glibc.\n- host-baremetal: the host distro pre-packaged bare one. For baremetal, links to newlib.\n'''\n        )\n        self.add_argument(\n            '--march',\n            help='''\\\nGCC -march option to use. Currently only used for the more LKMC-specific builds such as\n./build-userland and ./build-baremetal. Maybe we will use it for more things some day.\n'''\n        )\n        self.add_argument(\n            '--mode',\n            choices=('userland', 'baremetal'),\n            default=None,\n            help='''Differentiate between userland and baremetal for scripts that can do both.\n./run differentiates between them based on the --userland and --baremetal options,\nhowever those options take arguments, Certain scripts can be run on either user or baremetal mode.\nIf given, this differentiates between them.\n'''\n        )\n        self.add_argument(\n            '-j',\n            '--nproc',\n            default=len(os.sched_getaffinity(0)),\n            type=int,\n            help='''Number of processors (Jobs) to use for the action.''',\n        )\n        self.add_argument(\n            '-q',\n            '--quiet',\n            default=False,\n            help='''\\\nDon't print anything to stdout, except if it is part of an interactive terminal.\nTODO: implement fully, some stuff is escaping it currently.\n'''\n        )\n        self.add_argument(\n            '--quit-on-fail',\n            default=True,\n            help='''\\\nStop running at the first failed test.\n'''\n        )\n        self.add_argument(\n            '--show-cmds',\n            default=True,\n            help='''\\\nPrint the exact Bash command equivalents being run by this script.\nImplied by --quiet.\n'''\n        )\n        self.add_argument(\n            '--show-time',\n            default=True,\n            help='''\\\nPrint how long it took to run the command at the end.\nImplied by --quiet.\n'''\n        )\n        self.add_argument(\n            '-v',\n            '--verbose',\n            default=False,\n            help='Show full compilation commands when they are not shown by default.'\n        )\n\n        # Gem5 args.\n        self.add_argument(\n            '--dp650', default=False,\n            help='Use the ARM DP650 display processor instead of the default HDLCD on gem5.'\n        )\n        self.add_argument(\n            '--gem5-build-dir',\n            help='''\\\nUse the given directory as the gem5 build directory.\nIgnore --gem5-build-id and --gem5-build-type.\n'''\n        )\n        self.add_argument(\n            '-M',\n            '--gem5-build-id',\n            help='''\\\ngem5 build ID. Allows you to keep multiple separate gem5 builds.\nDefault: {}\n'''.format(consts['default_build_id'])\n        )\n        self.add_argument(\n            '--gem5-build-type',\n            choices=consts['gem5_build_type_choices'],\n            default=consts['build_type_default'],\n            help='gem5 build type, most often used for \"debug\" builds.'\n        )\n        self.add_argument(\n            '--gem5-clang',\n            default=False,\n            help='''\\\nBuild gem5 with clang and set the --gem5-build-id to 'clang' by default.\n'''\n        )\n        self.add_argument(\n            '--gem5-source-dir',\n            help='''\\\nUse the given directory as the gem5 source tree. Ignore `--gem5-worktree`.\n'''\n        )\n        self.add_argument(\n            '-N',\n            '--gem5-worktree',\n            help='''\\\nCreate and use a git worktree of the gem5 submodule.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#gem5-worktree\n'''\n        )\n\n        # Linux kernel.\n        self.add_argument(\n            '--linux-build-dir',\n            help='''\\\nUse the given directory as the Linux build directory. Ignore --linux-build-id.\n'''\n        )\n        self.add_argument(\n            '-L',\n            '--linux-build-id',\n            default=consts['default_build_id'],\n            help='''\\\nLinux build ID. Allows you to keep multiple separate Linux builds.\n'''\n        )\n        self.add_argument(\n            '--linux-exec',\n            help='''\\\nUse the given executable Linux kernel image. Ignored in userland and baremetal modes,\nRemember that different emulators may take different types of image, see:\nhttps://cirosantilli.com/linux-kernel-module-cheat#vmlinux-vs-bzimage-vs-zimage-vs-image\n''',\n        )\n        self.add_argument(\n            '--linux-source-dir',\n            help='''\\\nUse the given directory as the Linux source tree.\n'''\n        )\n        self.add_argument(\n            '--initramfs',\n            default=False,\n            help='''\\\nSee: https://cirosantilli.com/linux-kernel-module-cheat#initramfs\n'''\n        )\n        self.add_argument(\n            '--initrd',\n            default=False,\n            help='''\\\nFor Buildroot: create a CPIO root filessytem.\nFor QEMU use that CPUI root filesystem initrd instead of the default ext2.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#initrd\n'''\n        )\n\n        # Baremetal.\n        self.add_argument(\n            '-b',\n            '--baremetal',\n            action='append',\n            help='''\\\nUse the given baremetal executable instead of the Linux kernel.\n\nIf the path points to a source code inside baremetal/, then the\ncorresponding executable is automatically found.\n'''\n        )\n\n        # Buildroot.\n        self.add_argument(\n            '--buildroot-build-id',\n            default=consts['default_build_id'],\n            help='Buildroot build ID. Allows you to keep multiple separate gem5 builds.'\n        )\n        self.add_argument(\n            '--buildroot-linux',\n            default=False,\n            help='Boot with the Buildroot Linux kernel instead of our custom built one. Mostly for sanity checks.'\n        )\n\n        # Android.\n        self.add_argument(\n            '--rootfs-type',\n            default='buildroot',\n            choices=('buildroot', 'android'),\n            help='Which rootfs to use.'\n        )\n        self.add_argument(\n            '--android-version', default='8.1.0_r60',\n            help='Which android version to use. implies --rootfs-type android'\n        )\n        self.add_argument(\n            '--android-base-dir',\n            help='''\\\nIf given, place all android sources and build files into the given directory.\nOne application of this is to put those large directories in your HD instead\nof SSD.\n'''\n        )\n\n        # crosstool-ng\n        self.add_argument(\n            '--crosstool-ng-build-id',\n            default=consts['default_build_id'],\n            help='Crosstool-NG build ID. Allows you to keep multiple separate crosstool-NG builds.'\n        )\n        self.add_argument(\n            '--docker',\n            default=False,\n            help='''\\\nUse the docker download Ubuntu root filesystem instead of the default Buildroot one.\n'''\n        )\n\n        # QEMU.\n        self.add_argument(\n            '--qemu-build-id',\n            default=consts['default_build_id'],\n            help='QEMU build ID. Allows you to keep multiple separate QEMU builds.'\n        )\n        self.add_argument(\n            '--qemu-build-type',\n            choices=consts['build_type_choices'],\n            default=consts['build_type_default'],\n            help='QEMU build type, most often used for \"debug\" vs optimized builds.'\n        )\n        self.add_argument(\n            '--qemu-which',\n            choices=[consts['repo_short_id'], 'host'],\n            default=consts['repo_short_id'],\n            help='''\\\nWhich qemu binaries to use: qemu-system-, qemu-, qemu-img, etc.:\n- lkmc: the ones we built with ./build-qemu\n- host: the host distro pre-packaged provided ones\n'''\n        )\n        self.add_argument(\n            '--machine',\n            help='''\\\nMachine type:\n\n* QEMU default: -machine virt\n* gem5 default: --machine-type VExpress_GEM5_V1\n\nMore infor on platforms at:\nhttps://cirosantilli.com/linux-kernel-module-cheat#gem5-arm-platforms\n'''\n        )\n\n        # Userland.\n        self.add_argument(\n            '--copy-overlay',\n            default=True,\n            help='''\\\nCopy userland build outputs to the overlay directory which will be put inside\nthe disk image. If not given explicitly, this is disabled automatically when certain\noptions are given, for example --static, since users don't usually want\nstatic executables to be placed in the final image, but rather only for\nuser mode simulations in simulators that don't support dynamic linking like gem5.\n'''\n        )\n        self.add_argument(\n            '--host',\n            default=False,\n            help='''\\\nUse the host toolchain and other dependencies to build exectuables for host execution.\nAutomatically place the build output on a separate directory from non --host builds,\ne.g. by defaulting --userland-build-id host if that option has effect for the package.\nMake --copy-overlay default to False as the generated executables can't in general\nbe run in the guest.\n''',\n        )\n        self.add_argument(\n            '--out-rootfs-overlay-dir-prefix',\n            default='',\n            help='''\\\nPlace the output files of userland build outputs inside the image within this\nadditional prefix. This is mostly useful to place different versions of binaries\nwith different build parameters inside image to compare them. See:\n* https://cirosantilli.com/linux-kernel-module-cheat#update-the-buildroot-toolchain\n* https://cirosantilli.com/linux-kernel-module-cheat#out-rootfs-overlay-dir\n'''\n        )\n        self.add_argument(\n            '--package',\n            action='append',\n            help='''\\\nRequest to install a package in the target root filesystem, or indicate that it is present\nwhen building examples that rely on it or running tests for those examples.\n''',\n        )\n        self.add_argument(\n            '--package-all',\n            action='store_true',\n            help='''\\\nIndicate that all packages used by our userland/ examples with --package\nare available.\n''',\n        )\n        self.add_argument(\n            '--print-cmd-oneline',\n            action='store_true',\n            help='''\\\nPrint generated commands in a single line:\nhttps://cirosantilli.com/linux-kernel-module-cheat#dry-run\n'''\n        )\n        self.add_argument(\n            '--static',\n            default=False,\n            help='''\\\nBuild userland executables statically. Set --userland-build-id to 'static'\nif one was not given explicitly. See also:\nhttps://cirosantilli.com/linux-kernel-module-cheat#user-mode-static-executables\n''',\n        )\n        self.add_argument(\n            '-u',\n            '--userland',\n            action='append',\n            help='''\\\nRun the given userland executable in user mode instead of booting the Linux kernel\nin full system mode. In gem5, user mode is called Syscall Emulation (SE) mode and\nuses se.py. Path resolution is similar to --baremetal.\n* https://cirosantilli.com/linux-kernel-module-cheat#userland-setup-getting-started\n* https://cirosantilli.com/linux-kernel-module-cheat#gem5-syscall-emulation-mode\nThis option may be given multiple times only in gem5 syscall emulation:\nhttps://cirosantilli.com/linux-kernel-module-cheat#gem5-syscall-emulation-multiple-executables\n'''\n        )\n        self.add_argument(\n            '--cli-args',\n            help='''\\\nCLI arguments used in both --userland mode simulation, and in --baremetal. See also:\nhttps://cirosantilli.com/linux-kernel-module-cheat#baremetal-command-line-arguments\n'''\n        )\n        self.add_argument(\n            '--userland-build-id'\n        )\n\n        # Run.\n        self.add_argument(\n            '--background',\n            default=False,\n            help='''\\\nMake programs that would take over the terminal such as QEMU full system run on the\nbackground instead.\n\nCurrently only implemented for ./run.\n\nInteractive input cannot be given.\n\nSend QEMU serial output to a file instead of the host terminal.\n\nTODO: use a port instead. If only there was a way to redirect a serial to multiple\nplaces, both to a port and a file? We use the file currently to be able to have\nany output at all.\nhttps://superuser.com/questions/1373226/how-to-redirect-qemu-serial-output-to-both-a-file-and-the-terminal-or-a-port\n'''\n        )\n        self.add_argument(\n            '--in-tree',\n            default=False,\n            help='''\\\nPlace build output inside source tree to conveniently run it, especially when\nbuilding with the host native toolchain.\n\nWhen running, use in-tree executables instead of out-of-tree ones,\nuserland/c/hello resolves userland/c/hello.out instead of the out-of-tree one.\n\nCurrently only supported by userland scripts such as ./build-userland and\n./run --userland.\n''',\n        )\n        self.add_argument(\n            '--port-offset',\n            type=int,\n            help='''\\\nIncrease the ports to be used such as for GDB by an offset to run multiple\ninstances in parallel. Default: the run ID (-n) if that is an integer, otherwise 0.\n'''\n        )\n        self.add_argument(\n            '--prebuilt',\n            default=False,\n            help='''\\\nUse prebuilt packaged host utilities as much as possible instead\nof the ones we built ourselves. Saves build time, but decreases\nthe likelihood of incompatibilities.\n'''\n        )\n        self.add_argument(\n            '--run-id',\n            default='0',\n            help='''\\\nID for run outputs such as gem5's m5out. Allows you to do multiple runs,\nand then inspect separate outputs later in different output directories.\n'''\n        )\n\n        # Misc.\n        emulators = consts['emulator_short_to_long_dict']\n        emulators_string = []\n        for emulator_short in emulators:\n            emulator_long = emulators[emulator_short]\n            emulators_string.append('{} ({})'.format(emulator_long, emulator_short))\n        emulators_string = ', '.join(emulators_string)\n        self.add_argument(\n            '--all-emulators', default=False,\n            help='''\\\nRun action for all supported emulators. Ignore --emulator.\n'''.format(emulators_string)\n        )\n        self.add_argument(\n            '-e',\n            '--emulator',\n            action='append',\n            choices=consts['emulator_choices'],\n            default=['qemu'],\n            dest='emulators',\n            help='''\\\nEmulator to use. If given multiple times, semantics are similar to --arch.\nValid emulators: {}\n\n\"native\" means running natively on host. It is only supported for userland,\nand you must have built the program for native running, see:\nhttps://cirosantilli.com/linux-kernel-module-cheat#userland-setup-getting-started-natively\nIncompatible archs are skipped.\n'''.format(emulators_string)\n        )\n        self._is_common = False\n\n    def __call__(self, *args, **kwargs):\n        '''\n        For Python code calls, in addition to base class behaviour:\n\n        * print the CLI equivalent of the call\n        * automatically forward common arguments\n        '''\n        print_cmd = ['./' + self.extra_config_params, LF]\n        if 'print_cmd_oneline' in kwargs:\n            force_oneline = kwargs['print_cmd_oneline']\n            del kwargs['print_cmd_oneline']\n        else:\n            force_oneline=False\n        for line in self.get_cli(**kwargs):\n            print_cmd.extend(line)\n            print_cmd.append(LF)\n        if not ('quiet' in kwargs and kwargs['quiet']):\n            shell_helpers.ShellHelpers().print_cmd(\n                print_cmd,\n                force_oneline=force_oneline\n            )\n        return super().__call__(**kwargs)\n\n    def _handle_thread_pool_errors(self, my_thread_pool):\n        handle_output_result = my_thread_pool.get_handle_output_result()\n        if handle_output_result is not None:\n            work_function_input, work_function_return, exception = handle_output_result\n            if not type(exception) is thread_pool.ThreadPoolExitException:\n                print('work_function or handle_output raised unexpectedly:')\n                print(thread_pool.ThreadPool.exception_traceback_string(exception), end='')\n                print('work_function_input: {}'.format(work_function_input))\n                print('work_function_return: {}'.format(work_function_return))\n            return 1\n        else:\n            return 0\n\n    def _init_env(self, env):\n        '''\n        Update the kwargs from the command line with values derived from them.\n        '''\n        def join(*paths):\n            return os.path.join(*paths)\n        if env['emulator'] in env['emulator_short_to_long_dict']:\n            env['emulator'] = env['emulator_short_to_long_dict'][env['emulator']]\n        if not env['_args_given']['userland_build_id']:\n            if env['static']:\n                env['userland_build_id'] = 'static'\n            elif env['host']:\n                env['userland_build_id'] = 'host'\n            else:\n                env['userland_build_id'] = env['default_build_id']\n        if not env['_args_given']['gem5_build_id']:\n            if env['_args_given']['gem5_clang']:\n                env['gem5_build_id'] = 'clang'\n            elif env['_args_given']['gem5_worktree']:\n                env['gem5_build_id'] = env['gem5_worktree']\n            else:\n                env['gem5_build_id'] = consts['default_build_id']\n        env['is_arm'] = False\n        # Our approach is as follows:\n        #\n        # * compilers: control maximum arch version emitted explicitly -mcpu\n        # +\n        # This helps to prevent blowing up simulation unnecessarily.\n        # +\n        # It does not matter if we miss any perf features for QEMU which is functional,\n        # but it could matter for gem5 perf simulations.\n        # * assemblers: enable as many features as possible.\n        # +\n        # Well, if I'm explicitly writing down the instructions, I want\n        # my emulator to blow up in peace!\n        # * emulators: enable as many features as possible\n        # +\n        # This is the gem5 default behavior, for QEMU TODO not sure if default,\n        # but we select it explicitly with -cpu max.\n        # https://habkost.net/posts/2017/03/qemu-cpu-model-probing-story.html\n        # +\n        # We doe this because QEMU does not add all possible Cortex Axx, there are\n        # just too many, and gem5 does not allow selecting lower feature in general.\n        env['int_size'] = 4\n        if env['arch'] == 'arm':\n            # TODO this shoud be 4. But that blows up running all gem5 arm 32-bit examples.\n            # https://cirosantilli.com/linux-kernel-module-cheat#gem5-baremetal-arm-cli-args\n            env['address_size'] = 8\n            env['armv'] = 7\n            env['buildroot_toolchain_prefix'] = 'arm-buildroot-linux-gnueabihf'\n            env['crosstool_ng_toolchain_prefix'] = 'arm-unknown-eabi'\n            env['ubuntu_toolchain_prefix'] = 'arm-linux-gnueabihf'\n            env['is_arm'] = True\n            if not env['_args_given']['march']:\n                env['march'] = 'armv8-a'\n        elif env['arch'] == 'aarch64':\n            env['address_size'] = 8\n            env['armv'] = 8\n            env['buildroot_toolchain_prefix'] = 'aarch64-buildroot-linux-gnu'\n            env['crosstool_ng_toolchain_prefix'] = 'aarch64-unknown-elf'\n            env['ubuntu_toolchain_prefix'] = 'aarch64-linux-gnu'\n            env['is_arm'] = True\n            if not env['_args_given']['march']:\n                env['march'] = 'armv8-a+lse'\n        elif env['arch'] == 'x86_64':\n            env['address_size'] = 8\n            env['crosstool_ng_toolchain_prefix'] = 'x86_64-unknown-elf'\n            env['gem5_arch'] = 'X86'\n            env['buildroot_toolchain_prefix'] = 'x86_64-buildroot-linux-gnu'\n            env['ubuntu_toolchain_prefix'] = 'x86_64-linux-gnu'\n            if env['emulator'] == 'gem5':\n                if not env['_args_given']['machine']:\n                    env['machine'] = 'TODO'\n            else:\n                if not env['_args_given']['machine']:\n                    env['machine'] = 'pc'\n        if env['is_arm']:\n            env['gem5_arch'] = 'ARM'\n            if env['emulator'] == 'gem5':\n                if not env['_args_given']['machine']:\n                    if env['dp650']:\n                        env['machine'] = 'VExpress_GEM5_V1_DPU'\n                    else:\n                        env['machine'] = 'VExpress_GEM5_V1'\n            else:\n                if not env['_args_given']['machine']:\n                    env['machine'] = 'virt'\n\n        # Buildroot\n        env['buildroot_build_dir'] = join(env['buildroot_out_dir'], 'build', env['buildroot_build_id'], env['arch'])\n        env['buildroot_download_dir'] = join(env['buildroot_out_dir'], 'download')\n        env['buildroot_config_file'] = join(env['buildroot_build_dir'], '.config')\n        env['buildroot_build_build_dir'] = join(env['buildroot_build_dir'], 'build')\n        env['buildroot_linux_build_dir'] = join(env['buildroot_build_build_dir'], 'linux-custom')\n        env['buildroot_vmlinux'] = join(env['buildroot_linux_build_dir'], 'vmlinux')\n        env['buildroot_host_dir'] = join(env['buildroot_build_dir'], 'host')\n        env['buildroot_host_usr_dir'] = join(env['buildroot_host_dir'], 'usr')\n        env['buildroot_host_bin_dir'] = join(env['buildroot_host_usr_dir'], 'bin')\n        env['buildroot_pkg_config'] = join(env['buildroot_host_bin_dir'], 'pkg-config')\n        env['buildroot_images_dir'] = join(env['buildroot_build_dir'], 'images')\n        env['buildroot_rootfs_raw_file'] = join(env['buildroot_images_dir'], 'rootfs.ext2')\n        env['buildroot_qcow2_file'] = env['buildroot_rootfs_raw_file'] + '.qcow2'\n        env['buildroot_cpio'] = join(env['buildroot_images_dir'], 'rootfs.cpio')\n        env['staging_dir'] = join(env['out_dir'], 'staging', env['arch'])\n        env['buildroot_staging_dir'] = join(env['buildroot_build_dir'], 'staging')\n        env['buildroot_target_dir'] = join(env['buildroot_build_dir'], 'target')\n        if not env['_args_given']['linux_source_dir']:\n            env['linux_source_dir'] = os.path.join(consts['submodules_dir'], 'linux')\n        common.extract_vmlinux = os.path.join(env['linux_source_dir'], 'scripts', 'extract-vmlinux')\n        env['linux_buildroot_build_dir'] = join(env['buildroot_build_build_dir'], 'linux-custom')\n\n        # QEMU\n        env['qemu_build_dir'] = join(\n            env['out_dir'],\n            'qemu',\n            env['qemu_build_id'],\n            env['qemu_build_type']\n        )\n        env['qemu_img_basename'] = 'qemu-img'\n        env['qemu_img_executable'] = join(env['qemu_build_dir'], env['qemu_img_basename'])\n        if not env['userland']:\n            env['qemu_executable_basename'] = 'qemu-system-{}'.format(env['arch'])\n        else:\n            env['qemu_executable_basename'] = 'qemu-{}'.format(env['arch'])\n        if env['qemu_which'] == 'host':\n            env['qemu_executable'] = env['qemu_executable_basename']\n        else:\n            if not env['userland']:\n                env['qemu_executable'] = join(\n                    env['qemu_build_dir'],\n                    '{}-softmmu'.format(env['arch']),\n                    env['qemu_executable_basename']\n                )\n            else:\n                env['qemu_executable'] = join(\n                    self.env['qemu_build_dir'],\n                    '{}-linux-user'.format(self.env['arch']),\n                    env['qemu_executable_basename']\n                )\n\n        # gem5\n        if not env['_args_given']['gem5_build_dir']:\n            env['gem5_build_dir'] = join(env['gem5_out_dir'], env['gem5_build_id'])\n        env['gem5_test_binaries_dir'] = join(env['gem5_out_dir'], 'test_binaries')\n        env['gem5_m5term'] = join(env['gem5_build_dir'], 'm5term')\n        env['gem5_build_build_dir'] = join(env['gem5_build_dir'], 'build')\n\n        # https://cirosantilli.com/linux-kernel-module-cheat#gem5-eclipse-configuration\n        env['gem5_eclipse_cproject_basename'] = '.cproject'\n        env['gem5_eclipse_project_basename'] = '.project'\n        env['gem5_eclipse_cproject_path'] = join(env['gem5_build_build_dir'], env['gem5_eclipse_cproject_basename'])\n        env['gem5_eclipse_project_path'] = join(env['gem5_build_build_dir'], env['gem5_eclipse_project_basename'])\n\n        env['gem5_executable_dir'] = join(env['gem5_build_build_dir'], env['gem5_arch'])\n        env['gem5_executable_suffix'] = '.{}'.format(env['gem5_build_type'])\n        env['gem5_executable'] = self.get_gem5_target_path(env, 'gem5')\n        env['gem5_unit_test_target'] = self.get_gem5_target_path(env, 'unittests')\n        env['gem5_system_dir'] = join(env['gem5_build_dir'], 'system')\n        env['gem5_system_binaries_dir'] = join(env['gem5_system_dir'], 'binaries')\n        if self.env['is_arm']:\n            if env['arch'] == 'arm':\n                gem5_bootloader_basename = 'boot.arm'\n            elif env['arch'] == 'aarch64':\n                gem5_bootloader_basename = 'boot.arm64'\n            env['gem5_bootloader'] = join(env['gem5_system_binaries_dir'], gem5_bootloader_basename)\n        else:\n            env['gem5_bootloader'] = None\n\n        # gem5 source\n        if env['_args_given']['gem5_source_dir']:\n            assert os.path.exists(env['gem5_source_dir'])\n        else:\n            if env['_args_given']['gem5_worktree']:\n                env['gem5_source_dir'] = join(env['gem5_non_default_source_root_dir'], env['gem5_worktree'])\n            else:\n                env['gem5_source_dir'] = env['gem5_default_source_dir']\n        env['gem5_m5_source_dir'] = join(env['gem5_source_dir'], 'util', 'm5')\n        if self.env['arch'] == 'x86_64':\n            env['gem5_m5_source_dir_build_arch'] = 'x86'\n        elif self.env['arch'] == 'aarch64':\n            env['gem5_m5_source_dir_build_arch'] = 'arm64'\n        else:\n            env['gem5_m5_source_dir_build_arch'] = env['arch']\n        env['gem5_m5_source_dir_build'] = join(env['gem5_m5_source_dir'], 'build', env['gem5_m5_source_dir_build_arch'], 'out', 'm5')\n        env['gem5_config_dir'] = join(env['gem5_source_dir'], 'configs')\n        env['gem5_se_file'] = join(env['gem5_config_dir'], 'example', 'se.py')\n        env['gem5_fs_file'] = join(env['gem5_config_dir'], 'example', 'fs.py')\n\n        # crosstool-ng\n        env['crosstool_ng_buildid_dir'] = join(env['crosstool_ng_out_dir'], 'build', env['crosstool_ng_build_id'])\n        env['crosstool_ng_install_dir'] = join(env['crosstool_ng_buildid_dir'], 'install', env['arch'])\n        env['crosstool_ng_bin_dir'] = join(env['crosstool_ng_install_dir'], 'bin')\n        env['crosstool_ng_source_copy_dir'] = join(env['crosstool_ng_buildid_dir'], 'source')\n        env['crosstool_ng_config'] = join(env['crosstool_ng_source_copy_dir'], '.config')\n        env['crosstool_ng_defconfig'] = join(env['crosstool_ng_source_copy_dir'], 'defconfig')\n        env['crosstool_ng_executable'] = join(env['crosstool_ng_source_copy_dir'], 'ct-ng')\n        env['crosstool_ng_build_dir'] = join(env['crosstool_ng_buildid_dir'], 'build')\n        env['crosstool_ng_download_dir'] = join(env['crosstool_ng_out_dir'], 'download')\n\n        # run\n        env['gem5_run_dir'] = join(env['run_dir_base'], 'gem5', env['arch'], str(env['run_id']))\n        env['m5out_dir'] = join(env['gem5_run_dir'], 'm5out')\n        env['stats_file'] = join(env['m5out_dir'], 'stats.txt')\n        env['gem5_trace_txt_file'] = join(env['m5out_dir'], 'trace.txt')\n        env['gem5_guest_terminal_file'] = join(env['m5out_dir'], 'system.terminal')\n        env['gem5_readfile_file'] = join(env['gem5_run_dir'], 'readfile')\n        env['gem5_termout_file'] = join(env['gem5_run_dir'], 'termout.txt')\n        env['qemu_run_dir'] = join(env['run_dir_base'], 'qemu', env['arch'], str(env['run_id']))\n        env['qemu_termout_file'] = join(env['qemu_run_dir'], 'termout.txt')\n        env['qemu_trace_basename'] = 'trace.bin'\n        env['qemu_trace_file'] = join(env['qemu_run_dir'], 'trace.bin')\n        env['qemu_trace_txt_file'] = join(env['qemu_run_dir'], 'trace.txt')\n        env['qemu_rrfile'] = join(env['qemu_run_dir'], 'rrfile')\n        env['gem5_out_dir'] = join(env['out_dir'], 'gem5')\n\n        # Ports\n        if not env['_args_given']['port_offset']:\n            try:\n                env['port_offset'] = int(env['run_id'])\n            except ValueError:\n                env['port_offset'] = 0\n        if env['emulator'] == 'gem5':\n            # Tims 4 because gem5 now has 3 UARTs tha take up the previous ports:\n            # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/131\n            env['gem5_telnet_port'] = 3456 + env['port_offset'] * 4\n            env['gdb_port'] = 7000 + env['port_offset']\n        else:\n            env['qemu_base_port'] = 45454 + 10 * env['port_offset']\n            env['qemu_monitor_port'] = env['qemu_base_port'] + 0\n            env['qemu_hostfwd_generic_port'] = env['qemu_base_port'] + 1\n            env['qemu_hostfwd_ssh_port'] = env['qemu_base_port'] + 2\n            env['qemu_gdb_port'] = env['qemu_base_port'] + 3\n            env['extra_serial_port'] = env['qemu_base_port'] + 4\n            env['gdb_port'] = env['qemu_gdb_port']\n            env['qemu_background_serial_file'] = join(env['qemu_run_dir'], 'background.log')\n\n        # gem5 QEMU polymorphism.\n        if env['emulator'] == 'gem5':\n            env['executable'] = env['gem5_executable']\n            env['run_dir'] = env['gem5_run_dir']\n            env['termout_file'] = env['gem5_termout_file']\n            env['guest_terminal_file'] = env['gem5_guest_terminal_file']\n            env['trace_txt_file'] = env['gem5_trace_txt_file']\n        else:\n            env['executable'] = env['qemu_executable']\n            env['run_dir'] = env['qemu_run_dir']\n            env['termout_file'] = env['qemu_termout_file']\n            if env['background']:\n                env['guest_terminal_file'] = env['qemu_background_serial_file']\n            else:\n                env['guest_terminal_file'] = env['qemu_termout_file']\n            env['trace_txt_file'] = env['qemu_trace_txt_file']\n        env['run_cmd_file_basename'] = 'run.sh'\n        env['run_cmd_file'] = join(env['run_dir'], env['run_cmd_file_basename'])\n\n        # Linux kernel.\n        if not env['_args_given']['linux_build_dir']:\n            env['linux_build_dir'] = join(env['out_dir'], 'linux', env['linux_build_id'], env['arch'])\n        env['lkmc_vmlinux'] = join(env['linux_build_dir'], 'vmlinux')\n        if env['arch'] == 'arm':\n            env['android_arch'] = 'arm'\n            env['linux_arch'] = 'arm'\n            env['linux_image_prefix'] = join('arch', env['linux_arch'], 'boot', 'zImage')\n        elif env['arch'] == 'aarch64':\n            env['android_arch'] = 'arm64'\n            env['linux_arch'] = 'arm64'\n            env['linux_image_prefix'] = join('arch', env['linux_arch'], 'boot', 'Image')\n        elif env['arch'] == 'x86_64':\n            env['android_arch'] = 'x86_64'\n            env['linux_arch'] = 'x86'\n            env['linux_image_prefix'] = join('arch', env['linux_arch'], 'boot', 'bzImage')\n        env['lkmc_linux_image'] = join(env['linux_build_dir'], env['linux_image_prefix'])\n        env['buildroot_linux_image'] = join(env['buildroot_linux_build_dir'], env['linux_image_prefix'])\n        if env['buildroot_linux']:\n            env['vmlinux'] = env['buildroot_vmlinux']\n            env['linux_image'] = env['buildroot_linux_image']\n        else:\n            env['vmlinux'] = env['lkmc_vmlinux']\n            env['linux_image'] = env['lkmc_linux_image']\n        env['linux_config'] = join(env['linux_build_dir'], '.config')\n        if env['emulator']== 'gem5':\n            env['userland_quit_cmd'] = join(\n                env['guest_lkmc_home'],\n                'gem5_exit.sh'\n            )\n        else:\n            env['userland_quit_cmd'] = join(\n                env['guest_lkmc_home'],\n                'linux',\n                'poweroff' + env['userland_executable_ext']\n            )\n        env['ramfs'] = env['initrd'] or env['initramfs']\n        if env['ramfs']:\n            env['initarg'] = 'rdinit'\n        else:\n            env['initarg'] = 'init'\n        env['quit_init'] = '{}={}'.format(env['initarg'], env['userland_quit_cmd'])\n\n        # Userland\n        env['userland_source_arch_arch_dir'] = join(env['userland_source_arch_dir'], env['arch'])\n        if env['in_tree']:\n            env['userland_build_dir'] = env['userland_source_dir']\n        else:\n            env['userland_build_dir'] = join(env['out_dir'], 'userland', env['userland_build_id'], env['arch'])\n        env['package'] = set(env['package'])\n        if not env['_args_given']['copy_overlay']:\n            if (\n                env['in_tree'] or\n                env['static'] or\n                env['host'] or\n                env['mode'] == 'baremetal'\n            ):\n                env['copy_overlay'] = False\n\n        # Kernel modules.\n        env['kernel_modules_build_dir'] = join(env['kernel_modules_build_base_dir'], env['arch'])\n        env['kernel_modules_build_subdir'] = join(env['kernel_modules_build_dir'], env['kernel_modules_subdir'])\n        env['kernel_modules_build_host_dir'] = join(env['kernel_modules_build_base_dir'], 'host')\n        env['kernel_modules_build_host_subdir'] = join(env['kernel_modules_build_host_dir'], env['kernel_modules_subdir'])\n\n        # Overlay.\n        # https://cirosantilli.com/linux-kernel-module-cheat#buildroot-packages-directory\n        env['out_rootfs_overlay_dir'] = join(env['out_dir'], 'rootfs_overlay', env['arch'])\n        env['out_rootfs_overlay_lkmc_dir'] = join(env['out_rootfs_overlay_dir'], env['repo_short_id'])\n        env['out_rootfs_overlay_bin_dir'] = join(env['out_rootfs_overlay_dir'], 'bin')\n\n        # Baremetal.\n        env['baremetal_source_dir'] = join(env['root_dir'], 'baremetal')\n        env['baremetal_source_arch_subpath'] = join('arch', env['arch'])\n        env['baremetal_source_arch_dir'] = join(env['baremetal_source_dir'], env['baremetal_source_arch_subpath'])\n        env['baremetal_source_lib_dir'] = join(env['baremetal_source_dir'], env['baremetal_lib_basename'])\n        env['baremetal_link_script'] = os.path.join(env['baremetal_source_dir'], 'link.ld')\n        if env['emulator'] == 'gem5':\n            env['simulator_name'] = 'gem5'\n        else:\n            env['simulator_name'] = 'qemu'\n        env['baremetal_build_dir'] = join(env['out_dir'], 'baremetal', env['arch'], env['simulator_name'], env['machine'])\n        env['baremetal_build_lib_dir'] = join(env['baremetal_build_dir'], env['baremetal_lib_basename'])\n        env['baremetal_syscalls_basename_noext'] = 'syscalls'\n        env['baremetal_syscalls_src'] = os.path.join(\n            env['baremetal_source_lib_dir'],\n            env['baremetal_syscalls_basename_noext'] + env['c_ext']\n        )\n        env['baremetal_syscalls_obj'] = os.path.join(\n            env['baremetal_build_lib_dir'],\n            env['baremetal_syscalls_basename_noext'] + env['obj_ext']\n        )\n        env['baremetal_syscalls_asm_src'] = os.path.join(\n            env['baremetal_source_lib_dir'],\n            env['baremetal_syscalls_basename_noext'] + '_asm' + env['asm_ext']\n        )\n        env['baremetal_syscalls_asm_obj'] = os.path.join(\n            env['baremetal_build_lib_dir'],\n            env['baremetal_syscalls_basename_noext'] + '_asm' + env['obj_ext']\n        )\n        if env['emulator'] == 'gem5':\n            if self.env['is_arm']:\n                if env['machine'] == 'VExpress_GEM5_V1':\n                    env['entry_address'] = 0x80000000\n                    env['uart_address'] = 0x1c090000\n                elif env['machine'] == 'RealViewPBX':\n                    env['entry_address'] = 0x10000\n                    env['uart_address'] = 0x10009000\n                else:\n                    raise Exception('unknown machine: ' + env['machine'])\n        else:\n            env['entry_address'] = 0x40000000\n            env['uart_address'] = 0x09000000\n        env['common_basename_noext'] = env['repo_short_id']\n        env['baremetal_extra_obj_bootloader'] = join(\n            env['baremetal_build_lib_dir'],\n            'bootloader{}'.format(env['obj_ext'])\n        )\n        env['baremetal_extra_obj_lkmc_common'] = join(\n            env['baremetal_build_lib_dir'],\n            env['common_basename_noext'] + env['obj_ext']\n        )\n\n        # Userland / baremetal common source.\n        env['common_c'] = os.path.join(\n            env['root_dir'],\n            env['common_basename_noext'] + env['c_ext']\n        )\n        env['common_h'] = os.path.join(\n            env['root_dir'],\n            env['common_basename_noext'] + env['header_ext']\n        )\n        if env['mode'] == 'baremetal':\n            env['build_dir'] = env['baremetal_build_dir']\n            env['extra_objs'] = [\n                env['baremetal_extra_obj_bootloader'],\n                env['baremetal_extra_obj_lkmc_common'],\n                env['baremetal_syscalls_asm_obj'],\n                env['baremetal_syscalls_obj'],\n            ]\n            env['ccflags_default'] = [\n                '-nostartfiles', LF,\n            ]\n            if env['arch'] == 'arm':\n                env['ccflags_default'].extend([\n                    '-mhard-float', LF,\n                    # This uses the soft float ABI for calling functions from objets in Newlib which\n                    # our crosstool-NG config compiles with soft floats, while emiting hard float\n                    # from C and allowing us to use it from assembly, e.g. for the VMRS instruction:\n                    # which would otherwise fail \"with selected processor does not support XXX in ARM mode\"\n                    # Bibliography:\n                    # - https://stackoverflow.com/questions/9753749/arm-compilation-error-vfp-registered-used-by-executable-not-object-file\n                    # - https://stackoverflow.com/questions/41131432/cross-compiling-error-selected-processor-does-not-support-fmrx-r3-fpexc-in/41131782#41131782\n                    # - https://embeddedartistry.com/blog/2017/10/9/r1q7pksku2q3gww9rpqef0dnskphtc\n                    '-mfloat-abi=softfp', LF,\n                    '-mfpu=crypto-neon-fp-armv8', LF,\n                ])\n            env['ldflags'] = [\n                '-Wl,--section-start=.text={:#x}'.format(env['entry_address']), LF,\n                '-T', env['baremetal_link_script'], LF,\n            ]\n        else:\n            env['build_dir'] = env['userland_build_dir']\n            env['ccflags_default'] = []\n            env['extra_objs'] = []\n            env['ldflags'] = []\n\n        # Docker\n        env['docker_build_dir'] = join(env['out_dir'], 'docker', env['arch'])\n        env['docker_tar_dir'] = join(env['docker_build_dir'], 'export')\n        env['docker_tar_file'] = join(env['docker_build_dir'], 'export.tar')\n        env['docker_rootfs_raw_file'] = join(env['docker_build_dir'], 'export.ext2')\n        env['docker_qcow2_file'] = join(env['docker_rootfs_raw_file'] + '.qcow2')\n        if env['docker']:\n            env['rootfs_raw_file'] = env['docker_rootfs_raw_file']\n            env['qcow2_file'] = env['docker_qcow2_file']\n        else:\n            env['rootfs_raw_file'] = env['buildroot_rootfs_raw_file']\n            env['qcow2_file'] = env['buildroot_qcow2_file']\n\n        # Image\n        if env['baremetal']:\n            env['image'] = self.resolve_baremetal_executable(env['baremetal'][0])\n            # This is needed because the Linux kerne limage for certain emulators like QEMU\n            # might not be in plain ELF format, but rather some crazy compressed kernel format.\n            # https://cirosantilli.com/linux-kernel-module-cheat#vmlinux-vs-bzimage-vs-zimage-vs-image\n            env['image_elf'] = env['image']\n            source_path_noext = os.path.splitext(join(\n                env['root_dir'],\n                env['image'][len(env['baremetal_build_dir']) + 1:]\n            ))[0]\n            env['source_path'] = None\n            for ext in env['baremetal_build_in_exts']:\n                source_path = source_path_noext + ext\n                if os.path.exists(source_path):\n                    env['source_path'] = source_path\n                    break\n        elif env['userland']:\n            env['image'] = self.resolve_userland_executable(env['userland'][0])\n            env['image_elf'] = env['image']\n            source_path_noext = os.path.splitext(join(\n                env['userland_source_dir'],\n                env['image'][len(env['userland_build_dir']) + 1:]\n            ))[0]\n            env['source_path'] = None\n            for ext in env['build_in_exts']:\n                source_path = source_path_noext + ext\n                if os.path.exists(source_path):\n                    env['source_path'] = source_path\n                    break\n        else:\n            if env['emulator'] == 'gem5':\n                if not env['_args_given']['linux_exec']:\n                    env['image'] = env['vmlinux']\n            else:\n                if not env['_args_given']['linux_exec']:\n                    env['image'] = env['linux_image']\n            env['image_elf'] = env['vmlinux']\n            if env['_args_given']['linux_exec']:\n                env['image'] = env['linux_exec']\n        if not env['_args_given']['disk_image']:\n            if env['emulator'] == 'gem5':\n                if env['ramfs']:\n                    env['disk_image'] = None\n                else:\n                    env['disk_image'] = env['rootfs_raw_file']\n            else:\n                env['disk_image'] = env['qcow2_file']\n        # A squahfs of 'out_rootfs_overlay_dir'.\n        env['disk_image_2'] = env['out_rootfs_overlay_dir'] + '.squashfs'\n\n        # Android\n        if not env['_args_given']['android_base_dir']:\n            env['android_base_dir'] = join(env['out_dir'], 'android')\n        env['android_dir'] = join(env['android_base_dir'], env['android_version'])\n        env['android_build_dir'] = join(env['android_dir'], 'out')\n        env['repo_path'] = join(env['android_base_dir'], 'repo')\n        env['repo_path_base64'] = env['repo_path'] + '.base64'\n        env['android_shell_setup'] = '''\\\n. build/envsetup.sh\nlunch aosp_{}-eng\n'''.format(self.env['android_arch'])\n\n        # Toolchain.\n        if not env['_args_given']['mode']:\n            if env['baremetal']:\n                env['mode'] = 'baremetal'\n            if env['userland']:\n                env['mode'] = 'userland'\n        if not env['_args_given']['gcc_which']:\n            if env['mode'] == 'baremetal':\n                env['gcc_which'] = 'crosstool-ng'\n            elif env['host']:\n                env['gcc_which'] = 'host'\n        if env['gcc_which'] == 'buildroot':\n            env['toolchain_prefix'] = os.path.join(\n                env['buildroot_host_bin_dir'],\n                env['buildroot_toolchain_prefix']\n            )\n            env['userland_library_dir'] = env['buildroot_target_dir']\n            env['userland_library_redirects'] = [\n                'lib',\n                'lib64',\n                os.path.join('usr', 'lib'),\n                os.path.join('usr', 'lib64')\n            ]\n            env['pkg_config'] = env['buildroot_pkg_config']\n        elif env['gcc_which'] == 'crosstool-ng':\n            env['toolchain_prefix'] = os.path.join(\n                env['crosstool_ng_bin_dir'],\n                env['crosstool_ng_toolchain_prefix']\n            )\n        elif env['gcc_which'] == 'host':\n            if env['arch'] == env['host_arch']:\n                env['toolchain_prefix'] = ''\n            else:\n                env['toolchain_prefix'] = env['ubuntu_toolchain_prefix']\n            if env['arch'] == env['host_arch']:\n                 env['userland_library_dir'] = '/'\n            elif env['arch'] == 'x86_64':\n                env['userland_library_dir'] = '/usr/x86_64-linux-gnu/'\n            elif env['arch'] == 'arm':\n                env['userland_library_dir'] = '/usr/arm-linux-gnueabihf'\n            elif env['arch'] == 'aarch64':\n                env['userland_library_dir'] = '/usr/aarch64-linux-gnu/'\n            env['pkg_config'] = 'pkg-config'\n            env['userland_library_redirects'] = ['lib']\n        elif env['gcc_which'] == 'host-baremetal':\n            if env['arch'] == 'arm':\n                env['toolchain_prefix'] = 'arm-none-eabi'\n            else:\n                raise Exception('There is no host baremetal chain for arch: ' + env['arch'])\n        else:\n            raise Exception('Unknown toolchain: ' + env['gcc_which'])\n        if env['toolchain_prefix'] == '':\n            env['toolchain_prefix_dash'] = ''\n        else:\n            env['toolchain_prefix_dash'] = '{}-'.format(env['toolchain_prefix'])\n        env['gfortran_path'] = self.get_toolchain_tool('gfortran')\n        env['gcc_path'] = self.get_toolchain_tool('gcc')\n        env['gxx_path'] = self.get_toolchain_tool('g++')\n        env['ld_path'] = self.get_toolchain_tool('ld')\n        if env['gcc_which'] == 'host':\n            if env['arch'] == 'x86_64':\n                env['gdb_path'] = 'gdb'\n            else:\n                env['gdb_path'] = 'gdb-multiarch'\n        else:\n            env['gdb_path'] = self.get_toolchain_tool('gdb')\n\n    def add_argument(self, *args, **kwargs):\n        '''\n        Also handle:\n\n        - modified defaults from child classes.\n        - common arguments to forward on Python calls\n        '''\n        shortname, longname, key, is_option = self.get_key(*args, **kwargs)\n        if key in self._defaults:\n            kwargs['default'] = self._defaults[key]\n        if self._is_common:\n            self._common_args.add(key)\n        super().add_argument(*args, **kwargs)\n\n    def assert_is_subpath(self, subpath, parents):\n        is_subpath = False\n        for parent in parents:\n            if self.is_subpath(subpath, parent):\n                is_subpath = True\n        if not is_subpath:\n            raise Exception(\n                    'Can only accept targets inside:\\n{}\\nGiven: {}'.format(\n                    '\\n'.join(parents),\n                    subpath\n                )\n            )\n\n    def get_elf_entry(self, elf_file_path):\n        readelf_header = self.sh.check_output([\n            self.get_toolchain_tool('readelf'),\n            '-h',\n            elf_file_path\n        ]).decode()\n        for line in readelf_header.decode().split('\\n'):\n            split = line.split()\n            if line.startswith('  Entry point address:'):\n                addr = line.split()[-1]\n                break\n        return int(addr, 0)\n\n    @staticmethod\n    def get_gem5_target_path(env, name):\n        '''\n        Get the magic gem5 target path form the meaningful component name.\n        '''\n        return os.path.join(env['gem5_executable_dir'], name + env['gem5_executable_suffix'])\n\n    @staticmethod\n    def cwd_in_lib():\n        return pathlib.Path(common.consts['userland_source_libs_dir']) in pathlib.Path(os.getcwd()).parents\n\n    def gem5_list_checkpoint_dirs(self):\n        '''\n        List checkpoint directory, oldest first.\n        '''\n        prefix_re = re.compile(self.env['gem5_cpt_prefix'])\n        files = list(filter(\n            lambda x: os.path.isdir(os.path.join(self.env['m5out_dir'], x))\n                      and prefix_re.search(x), os.listdir(self.env['m5out_dir'])\n        ))\n        files.sort(key=lambda x: os.path.getmtime(os.path.join(self.env['m5out_dir'], x)))\n        return files\n\n    def get_common_args(self):\n        '''\n        These are arguments that might be used by more than one script,\n        and are all defined in this class instead of in the derived class\n        of the script.\n\n        This can be used to forward common arguments to a call of another CLI function.\n        '''\n        return {\n            key:self.env[key] for key in self._common_args if\n            (\n                # Args given on command line.\n                self.env['_args_given'][key] or\n                # Ineritance changed defaults.\n                key in self._defaults\n            )\n        }\n\n    def get_stats(self, stat_re=None, stats_file=None):\n        if stat_re is None:\n            stat_re = '^system.cpu[0-9]*.numCycles$'\n        if stats_file is None:\n            stats_file = self.env['stats_file']\n        stat_re = re.compile(stat_re)\n        ret = []\n        with open(stats_file, 'r') as statfile:\n            for line in statfile:\n                if line[0] != '-':\n                    cols = line.split()\n                    if len(cols) > 1 and stat_re.search(cols[0]):\n                        ret.append(cols[1])\n        return ret\n\n    def get_toolchain_tool(self, tool):\n        return '{}{}'.format(self.env['toolchain_prefix_dash'], tool)\n\n    def github_make_request(\n        self,\n        authenticate=False,\n        data=None,\n        extra_headers=None,\n        path='',\n        subdomain='api',\n        url_params=None,\n        **extra_request_args\n    ):\n        if extra_headers is None:\n            extra_headers = {}\n        headers = {'Accept': 'application/vnd.github.v3+json'}\n        headers.update(extra_headers)\n        if authenticate:\n            headers['Authorization'] = 'token ' + os.environ['LKMC_GITHUB_TOKEN']\n        if url_params is not None:\n            path += '?' + urllib.parse.urlencode(url_params)\n        request = urllib.request.Request(\n            'https://' + subdomain + '.github.com/repos/' + self.env['github_repo_id'] + path,\n            headers=headers,\n            data=data,\n            **extra_request_args\n        )\n        response_body = urllib.request.urlopen(request).read().decode()\n        if response_body:\n            _json = json.loads(response_body)\n        else:\n            _json = {}\n        return _json\n\n    def is_arch_supported(self, arch, mode):\n        return not (\n            mode == 'baremetal' and\n            not arch in consts['crosstool_ng_supported_archs']\n        )\n\n    def log_error(self, msg):\n        with self.print_lock:\n            print('error: {}'.format(msg), file=sys.stdout)\n\n    def log_info(self, msg='', flush=False, **kwargs):\n        with self.print_lock:\n            if not self.env['quiet']:\n                print('{}'.format(msg), **kwargs)\n            if flush:\n                sys.stdout.flush()\n\n    def log_warn(self, msg):\n        with self.print_lock:\n            print('warning: {}'.format(msg), file=sys.stdout)\n\n    def is_subpath(self, subpath, parent):\n        '''\n        https://stackoverflow.com/questions/3812849/how-to-check-whether-a-directory-is-a-sub-directory-of-another-directory\n        '''\n        return os.path.abspath(subpath).startswith(os.path.abspath(parent))\n\n    def main(self, *args, **kwargs):\n        '''\n        Run timed_main across all selected archs and emulators.\n\n        :return: if any of the timed_mains exits non-zero and non-None,\n                 return that. Otherwise, return 0.\n        '''\n        env = kwargs.copy()\n        if env['china']:\n            print(china_dictatorship.get_data())\n            sys.exit(0)\n        self.input_args = env.copy()\n        env.update(consts)\n        real_all_archs = env['all_archs']\n        if real_all_archs:\n            real_archs = consts['all_long_archs']\n        else:\n            real_archs = env['archs']\n        real_all_emulators = env['all_emulators']\n        if real_all_emulators:\n            real_emulators = consts['all_long_emulators']\n        else:\n            real_emulators = env['emulators']\n        return_value = 0\n        if env['_args_given']['show_cmds']:\n            show_cmds = env['show_cmds']\n        else:\n            show_cmds = not env['quiet']\n        self.setup(env)\n        try:\n            for emulator in real_emulators:\n                for arch in real_archs:\n                    if arch in env['arch_short_to_long_dict']:\n                        arch = env['arch_short_to_long_dict'][arch]\n                    if emulator in env['emulator_short_to_long_dict']:\n                        emulator = env['emulator_short_to_long_dict'][emulator]\n                    if self.is_arch_supported(arch, env['mode']):\n                        if not env['dry_run']:\n                            start_time = time.time()\n                        env['arch'] = arch\n                        env['archs'] = [arch]\n                        env['_args_given']['archs'] = True\n                        env['all_archs'] = False\n                        env['emulator'] = emulator\n                        env['emulators'] = [emulator]\n                        env['_args_given']['emulators'] = True\n                        env['all_emulators'] = False\n                        self.env = env.copy()\n                        self.sh = shell_helpers.ShellHelpers(\n                            dry_run=self.env['dry_run'],\n                            force_oneline=self.env['print_cmd_oneline'],\n                            quiet=(not show_cmds),\n                        )\n                        self._init_env(self.env)\n                        if emulator == 'native':\n                            if arch != self.env['host_arch']:\n                                if real_all_archs:\n                                    continue\n                                else:\n                                    raise Exception('native emulator only supported in if target arch ({}) == host arch ({})'.format(arch, self.env['host_arch']))\n                            if self.env['userland'] and not self.env['mode'] == 'userland':\n                                if real_all_emulators:\n                                    continue\n                                else:\n                                    raise Exception('native emulator only supported in user mode')\n                        self.setup_one()\n                        ret = self.timed_main()\n                        if not env['dry_run']:\n                            end_time = time.time()\n                            self.ellapsed_seconds = end_time - start_time\n                            self.print_time(self.ellapsed_seconds)\n                        if ret is not None and ret != 0:\n                            return_value = ret\n                            if self.env['quit_on_fail']:\n                                raise ExitLoop()\n                    elif not real_all_archs:\n                        raise Exception('Unsupported arch for this action: ' + arch)\n        except ExitLoop:\n            pass\n        ret = self.teardown()\n        if ret is not None and ret != 0:\n            return_value = ret\n        return return_value\n\n    def make_build_dirs(self):\n        os.makedirs(self.env['buildroot_build_build_dir'], exist_ok=True)\n        os.makedirs(self.env['gem5_build_dir'], exist_ok=True)\n        os.makedirs(self.env['out_rootfs_overlay_dir'], exist_ok=True)\n\n    def make_run_dirs(self):\n        '''\n        Make directories required for the run.\n        The user could nuke those anytime between runs to try and clean things up.\n        '''\n        os.makedirs(self.env['gem5_run_dir'], exist_ok=True)\n        os.makedirs(self.env['p9_dir'], exist_ok=True)\n        os.makedirs(self.env['qemu_run_dir'], exist_ok=True)\n\n    @staticmethod\n    def python_escape_double_quotes(s):\n        s2 = []\n        for c in s:\n            if c == '\"':\n                s2.append('\\\\\"')\n            else:\n                s2.append(c)\n        return ''.join(s2)\n\n    @staticmethod\n    def python_struct_int_format(size):\n        if size == 4:\n            return 'i'\n        elif size ==  8:\n            return 'Q'\n        else:\n            raise 'unknown size {}'.format(size)\n\n    @staticmethod\n    def seconds_to_hms(seconds):\n        '''\n        Seconds to hour:minute:seconds\n\n        :ptype seconds: float\n        :rtype: str\n\n        https://stackoverflow.com/questions/775049/how-do-i-convert-seconds-to-hours-minutes-and-seconds \n        '''\n        frac, whole = math.modf(seconds)\n        hours, rem = divmod(whole, 3600)\n        minutes, seconds = divmod(rem, 60)\n        return '{:02}:{:02}:{:02}'.format(int(hours), int(minutes), int(seconds))\n\n    def print_time(self, ellapsed_seconds):\n        if self.env['show_time'] and not self.env['quiet']:\n            print('time {}'.format(self.seconds_to_hms(ellapsed_seconds)))\n\n    def raw_to_qcow2(self, qemu_which=False, reverse=False):\n        if qemu_which == 'host' or not os.path.exists(self.env['qemu_img_executable']):\n            disable_trace = []\n            qemu_img_executable = self.env['qemu_img_basename']\n        else:\n            # Prevent qemu-img from generating trace files like QEMU. Disgusting.\n            disable_trace = ['-T', 'pr_manager_run,file=/dev/null', LF]\n            qemu_img_executable = self.env['qemu_img_executable']\n        infmt = 'raw'\n        outfmt = 'qcow2'\n        infile = self.env['rootfs_raw_file']\n        outfile = self.env['qcow2_file']\n        if reverse:\n            tmp = infmt\n            infmt = outfmt\n            outfmt = tmp\n            tmp = infile\n            infile = outfile\n            outfile = tmp\n        self.sh.run_cmd(\n            [\n                qemu_img_executable, LF,\n            ] +\n            disable_trace +\n            [\n                'convert', LF,\n                '-f', infmt, LF,\n                '-O', outfmt, LF,\n                infile, LF,\n                outfile, LF,\n            ]\n        )\n\n    def resolve_executable(\n        self,\n        in_path,\n        magic_in_dirs,\n        magic_out_dir,\n        executable_ext\n    ):\n        '''\n        Resolve the path of an userland or baremetal executable.\n\n        If it is in tree, resolve source paths to their corresponding executables.\n\n        If it is out of tree, return the same exact path as input.\n\n        If the input path is a file, add the executable extension automatically.\n\n        Directories map to the directories that would contain executable in that directory.\n        '''\n        if not self.env['dry_run'] and not os.path.exists(in_path):\n            raise Exception('Input path does not exist: ' + in_path)\n        if len(magic_in_dirs) > 1:\n            relative_subpath = self.env['root_dir']\n        else:\n            relative_subpath = magic_in_dirs[0]\n        for magic_in_dir in magic_in_dirs:\n            if self.is_subpath(in_path, magic_in_dir):\n                # Abspath needed to remove the trailing `/.` which makes e.g. rmrf fail.\n                out = os.path.abspath(os.path.join(\n                    magic_out_dir,\n                    os.path.relpath(\n                        os.path.splitext(in_path)[0],\n                        relative_subpath\n                    )\n                ))\n                if os.path.isfile(in_path):\n                    out += executable_ext\n                return out\n        return in_path\n\n    def resolve_targets(self, source_dirs, targets):\n        '''\n        Resolve userland or baremetal CLI provided targets to final paths.\n\n        Notably converts the toplevel directory into all source directories needed.\n        '''\n        if not targets:\n            targets = source_dirs.copy()\n        new_targets = []\n        for target in targets:\n            for resolved_target in self.toplevel_to_source_dirs(target, source_dirs):\n                self.assert_is_subpath(resolved_target, source_dirs)\n                new_targets.append(resolved_target)\n        return new_targets\n\n    def resolve_baremetal_executable(self, path):\n        return self.resolve_executable(\n            path,\n            [\n                self.env['baremetal_source_dir'],\n                self.env['userland_source_dir']\n            ],\n            self.env['baremetal_build_dir'],\n            self.env['baremetal_executable_ext'],\n        )\n\n    def resolve_userland_executable(self, path):\n        return self.resolve_executable(\n            path,\n            [self.env['userland_source_dir']],\n            self.env['userland_build_dir'],\n            self.env['userland_executable_ext'],\n        )\n\n    def setup(self, env):\n        '''\n        Similar to setup run before all timed_main are called.\n\n        _init_env has not yet been called, so only primary CLI arguments may be used.\n        '''\n        pass\n\n    def setup_one(self):\n        '''\n        Run just before timed_main, after _init_env.\n        '''\n        pass\n\n    def toplevel_to_source_dirs(self, path, source_dirs):\n        path = os.path.abspath(path)\n        if path == self.env['root_dir']:\n            return source_dirs\n        else:\n            return [path]\n\n    def timed_main(self):\n        '''\n        Main action of the derived class.\n\n        Gets run once for every --arch and every --emulator.\n        '''\n        pass\n\n    def teardown(self) -> Union[None,int]:\n        '''\n        Similar to setup, but run once after all timed_main are called.\n\n        :return: if not None, the return integer gets used as the exit status of the program.\n        '''\n        pass\n\nclass BuildCliFunction(LkmcCliFunction):\n    '''\n    A CLI function with common facilities to build stuff, e.g.:\n\n    * `--clean` to clean the build directory\n    * `--nproc` to set he number of build threads\n    '''\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.add_argument(\n            '--clean',\n            default=False,\n            help='Clean the build instead of building.',\n        ),\n        self._build_arguments = {\n            '--ccflags': {\n                'default': '',\n                'help': '''\\\nPass the given compiler flags to all languages (C, C++, Fortran, etc.)\n''',\n            },\n            '--ldflags': {\n                'default': '',\n                'help': '''\\\nExtra linker flags.\n''',\n            },\n            '--configure': {\n                'default': True,\n                'help': '''\\\nAlso run the configuration step during build.\n''',\n            },\n            '--force-rebuild': {\n                'default': False,\n                \"help\": '''\\\nForce rebuild even if sources didn't change.\n''',\n            },\n            '--optimization-level': {\n                'default': '0',\n                'help': '''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#optimization-level-of-a-build\n''',\n            },\n            'extra_make_args': {\n                'default': [],\n                'help': '''\\\nExtra arguments to pass to the Make command or analogous final build command,\nafter configure, e.g. SCons. Usually contains specific targets or other build flags.\n''',\n                'metavar': 'extra-make-args',\n                'nargs': '*',\n            },\n        }\n\n    def _add_argument(self, argument_name):\n        '''\n        Enable build argument with a fixed name to provide an uniform CLI API\n        across different builds.\n        '''\n        self.add_argument(\n            argument_name,\n            **self._build_arguments[argument_name]\n        )\n\n    def _build_one(\n        self,\n        in_path,\n        out_path,\n        build_exts=None,\n        cc_flags=None,\n        cc_flags_after=None,\n        extra_objs=None,\n        extra_objs_userland_asm=None,\n        extra_objs_lkmc_common=None,\n        extra_objs_baremetal_bootloader=None,\n        extra_deps=None,\n        link=True,\n    ):\n        '''\n        Build one userland or baremetal executable.\n        '''\n        if cc_flags is None:\n            cc_flags = []\n        else:\n            cc_flags = cc_flags.copy()\n        if cc_flags_after is None:\n            cc_flags_after = []\n        else:\n            cc_flags_after = cc_flags_after.copy()\n        if extra_deps is None:\n            extra_deps = []\n        ret = 0\n        in_dir, in_basename = os.path.split(in_path)\n        in_dir_abs = os.path.abspath(in_dir)\n        dirpath_relative_root = in_dir_abs[len(self.env['root_dir']) + 1:]\n        dirpath_relative_root_components = dirpath_relative_root.split(os.sep)\n        dirpath_relative_root_components_len = len(dirpath_relative_root_components)\n        my_path_properties = path_properties.get(os.path.join(\n            dirpath_relative_root,\n            in_basename\n        ))\n        if my_path_properties.should_be_built(\n            self.env,\n            link,\n        ):\n            if extra_objs is None:\n                extra_objs= []\n            if link:\n                #  Baremetal builds cannot add their usual syscall objects, as those\n                # rely on standard library symbols.\n                if my_path_properties['freestanding']:\n                    extra_objs = []\n                if (self.env['mode'] == 'baremetal' and not my_path_properties['freestanding']) \\\n                        or my_path_properties['extra_objs_lkmc_common']:\n                    extra_objs.extend(extra_objs_lkmc_common)\n                if (\n                    self.env['mode'] == 'baremetal' and\n                    not my_path_properties['freestanding'] and\n                    not my_path_properties['extra_objs_disable_baremetal_bootloader']\n                ):\n                    extra_objs.extend(extra_objs_baremetal_bootloader)\n                if self.env['mode'] == 'userland':\n                    cc_flags_after.extend(['-pthread', LF])\n            if self.need_rebuild([in_path] + extra_objs + extra_deps, out_path):\n                cc_flags.extend(my_path_properties['cc_flags'])\n                if self.env['verbose']:\n                    cc_flags.extend([\n                        '-v', LF,\n                    ])\n                cc_flags_after.extend(my_path_properties['cc_flags_after'])\n                if my_path_properties['cc_pedantic']:\n                    cc_flags.extend(['-pedantic', LF])\n                if not link:\n                    cc_flags.extend(['-c', LF])\n                in_ext = os.path.splitext(in_path)[1]\n                if in_ext in (self.env['c_ext'], self.env['asm_ext']):\n                    cc = self.env['gcc_path']\n                    std = my_path_properties['c_std']\n                elif in_ext == self.env['cxx_ext']:\n                    cc = self.env['gxx_path']\n                    std = my_path_properties['cxx_std']\n                if self.env['is_arm']:\n                    if in_ext == self.env['asm_ext']:\n                        cc_flags.extend([\n                            '-Xassembler', '-march=all', LF,\n                        ])\n                    else:\n                        cc_flags.extend([\n                            '-march={}'.format(self.env['march']), LF,\n                        ])\n                if dirpath_relative_root_components_len > 0:\n                    if dirpath_relative_root_components[0] == consts['userland_subdir']:\n                        if dirpath_relative_root_components_len > 1:\n                            if dirpath_relative_root_components[1] == self.env['userland_libs_basename']:\n                                if dirpath_relative_root_components_len > 1:\n                                    if self.env['gcc_which'] == 'host':\n                                        eigen_root = '/'\n                                    else:\n                                        eigen_root = self.env['buildroot_staging_dir']\n                                    # TODO move to path_properties.py somehow.\n                                    packages = {\n                                        'boost': {\n                                            # Header only, no pkg-config package.\n                                            'cc_flags': [],\n                                            'cc_flags_after': [],\n                                        },\n                                        'eigen': {\n                                            # TODO: was failing with:\n                                            # fatal error: Eigen/Dense: No such file or directory as of\n                                            # 975ce0723ee3fa1fea1766e6683e2f3acb8558d6\n                                            # http://lists.busybox.net/pipermail/buildroot/2018-June/222914.html\n                                            'cc_flags': [\n                                                '-I',\n                                                os.path.join(\n                                                    eigen_root,\n                                                    'usr',\n                                                    'include',\n                                                    'eigen3'\n                                                ),\n                                                LF\n                                            ],\n                                            # Header only.\n                                            'cc_flags_after': [],\n                                        },\n                                        'hdf5': {\n                                            'pkg_config_id': 'hdf5-serial',\n                                        },\n                                        'googletest': {\n                                            'cc_flags': [\n                                                '-I', os.path.join(self.env['googletest_source_dir'], 'googletest', 'include'), LF,\n                                                '-I', os.path.join(self.env['googletest_source_dir'], 'googlemock', 'include'), LF,\n                                            ],\n                                            'cc_flags_after': [\n                                                os.path.join(self.env['googletest_source_dir'], 'build', 'lib', 'libgtest.a'), LF,\n                                                os.path.join(self.env['googletest_source_dir'], 'build', 'lib', 'libgtest_main.a'), LF,\n                                                os.path.join(self.env['googletest_source_dir'], 'build', 'lib', 'libgmock.a'), LF,\n                                            ],\n                                        },\n                                    }\n                                    package_key = dirpath_relative_root_components[2]\n                                    if package_key in packages:\n                                        package = packages[package_key]\n                                    else:\n                                        package = {}\n                                    if 'pkg_config_id' in package:\n                                        pkg_config_id = package['pkg_config_id']\n                                    else:\n                                        pkg_config_id = package_key\n                                    if 'cc_flags' in package:\n                                        cc_flags.extend(package['cc_flags'])\n                                    else:\n                                        pkg_config_output = self.sh.check_output([\n                                            self.env['pkg_config'],\n                                            '--cflags',\n                                            pkg_config_id\n                                        ]).decode()\n                                        cc_flags.extend(self.sh.shlex_split(pkg_config_output))\n                                    if 'cc_flags_after' in package:\n                                        cc_flags_after.extend(package['cc_flags_after'])\n                                    else:\n                                        pkg_config_output = subprocess.check_output([\n                                            self.env['pkg_config'],\n                                            '--libs',\n                                            pkg_config_id\n                                        ]).decode()\n                                        cc_flags_after.extend(self.sh.shlex_split(pkg_config_output))\n                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n                ret = self.sh.run_cmd(\n                    (\n                        [\n                            cc, LF,\n                        ] +\n                        cc_flags +\n                        [\n                            '-std={}'.format(std), LF,\n                            '-o', out_path, LF,\n                            in_path, LF,\n                        ] +\n                        self.sh.add_newlines(extra_objs) +\n                        cc_flags_after\n                    ),\n                    extra_paths=[self.env['ccache_dir']],\n                )\n        return ret\n\n    def clean_pre(self, build_dir):\n        pass\n\n    def clean(self):\n        build_dir = self.get_build_dir()\n        self.clean_pre(build_dir)\n        if build_dir is not None:\n            self.sh.rmrf(build_dir)\n        self.clean_post(build_dir)\n\n    def clean_post(self, build_dir):\n        pass\n\n    def build(self):\n        '''\n        Do the actual main build work.\n        '''\n        raise NotImplementedError()\n\n    def get_build_dir(self):\n        return None\n\n    def need_rebuild(self, srcs, dst):\n        if self.env['force_rebuild']:\n            return True\n        if not os.path.exists(dst):\n            return True\n        for src in srcs:\n            if os.path.getmtime(src) > os.path.getmtime(dst):\n                return True\n        return False\n\n    def setup_one(self):\n        ccflags = []\n        ccflags.extend(self.env['ccflags_default'])\n        if 'optimization_level' in self.env:\n            ccflags.extend(['-O{}'.format(self.env['optimization_level']), LF])\n        if self.env['static']:\n            ccflags.extend(['-static', LF])\n        if 'ccflags' in self.env:\n            ccflags.extend(self.sh.shlex_split(self.env['ccflags']))\n        self.env['ccflags'] = ccflags\n        self.setup_one_build()\n\n    def setup_one_build(self):\n        '''\n        Called once before every build type, after BuildCliFunction::setup_one\n        '''\n        pass\n\n    def timed_main(self):\n        '''\n        Parse CLI, and to the build based on it.\n\n        The actual build work is done by do_build in implementing classes.\n        '''\n        if self.env['clean']:\n            return self.clean()\n        else:\n            return self.build()\n\nTestStatus = enum.Enum('TestStatus', ['PASS', 'FAIL'])\n\n@functools.total_ordering\nclass TestResult:\n    def __init__(\n        self,\n        test_id: str ='',\n        status : TestStatus =TestStatus.PASS,\n        ellapsed_seconds : float =0,\n        reason : str =''\n    ):\n        self.test_id = test_id\n        self.status = status\n        self.ellapsed_seconds = ellapsed_seconds\n        self.reason = reason\n\n    def __eq__(self, other):\n        return self.test_id == other.test_id\n\n    def __lt__(self, other):\n        return self.test_id < other.test_id\n\n    def __str__(self):\n        out = [\n            self.status.name,\n            LkmcCliFunction.seconds_to_hms(self.ellapsed_seconds),\n            repr(self.test_id),\n        ]\n        if self.status is TestStatus.FAIL:\n            out.append(repr(self.reason))\n        return ' '.join(out)\n\nclass TestCliFunction(LkmcCliFunction):\n    '''\n    Represents a CLI command that runs tests.\n\n    Automates test reporting boilerplate for those commands.\n    '''\n\n    base_run_args = {\n        'background': True,\n        'ctrl_c_host': True,\n        'print_cmd_oneline': True,\n        'show_cmds': False,\n        'show_stdout': False,\n        'show_time': False,\n    }\n\n    def __init__(self, *args, **kwargs):\n        defaults = {\n            'quit_on_fail': False,\n            'show_time': False,\n        }\n        if 'defaults' in kwargs:\n            defaults.update(kwargs['defaults'])\n        kwargs['defaults'] = defaults\n        super().__init__(*args, **kwargs)\n        self.test_results = queue.Queue()\n\n    def handle_output_function(\n        self,\n        work_function_input,\n        work_function_return,\n        work_function_exception\n    ):\n        if work_function_exception is not None:\n            return work_function_exception\n        if work_function_return.status != TestStatus.PASS:\n            return thread_pool.ThreadPoolExitException()\n\n    def run_test(\n        self,\n        run_obj,\n        run_args=None,\n        test_id=None,\n        expected_exit_status=None,\n        thread_id=0,\n    ):\n        '''\n        This is a setup / run / teardown setup for simple tests that just do a single run.\n\n        More complex tests might need to run the steps separately, e.g. gdb tests\n        must run multiple commands: one for the run and one GDB.\n\n        This function is meant to be called from threads. In particular,\n        those threads have to cross over archs: the original motivation is to parallelize\n        super slow gem5 boot tests. Therefore, we cannot use self.env['arch'] and selv.env['emulator']\n        in this function or callees!\n\n        Ideally, we should make this static and pass all arguments to the call... but lazy to refactor.\n        I have the feeling I will regret this one day down the line.\n\n        :param run_obj: callable object\n        :param run_args: arguments to be passed to the runnable object\n        :param test_id: test identifier, to be added in addition to of arch and emulator ids\n        :param thread_id: which thread the test is running under\n        '''\n        if run_obj.is_arch_supported(run_args['archs'][0], run_args.get('mode', None)):\n            cur_run_args = {\n                'run_id': thread_id,\n            }\n            cur_run_args.update(self.base_run_args)\n            if run_args is not None:\n                cur_run_args.update(run_args)\n            test_id_string = self.test_setup(run_args, test_id)\n            exit_status = run_obj(**cur_run_args)\n            return self.test_teardown(\n                run_obj,\n                exit_status,\n                test_id_string,\n                expected_exit_status=expected_exit_status\n            )\n\n    def test_setup(self, run_args, test_id):\n        test_id_string = '{} {}'.format(run_args['emulators'][0], run_args['archs'][0])\n        if test_id is not None and str(test_id) != '':\n            test_id_string += ' {}'.format(test_id)\n        self.log_info('Starting: {}'.format(repr(test_id_string)), flush=True)\n        return test_id_string\n\n    def test_teardown(\n        self,\n        run_obj,\n        exit_status,\n        test_id_string,\n        expected_exit_status=None\n    ):\n        if expected_exit_status is None:\n            expected_exit_status = 0\n        reason = ''\n        if not self.env['dry_run']:\n            if exit_status == expected_exit_status:\n                test_status = TestStatus.PASS\n            else:\n                test_status = TestStatus.FAIL\n                reason = 'wrong exit status, got {} expected {}'.format(\n                    exit_status,\n                    expected_exit_status\n                )\n            ellapsed_seconds = run_obj.ellapsed_seconds\n        else:\n            test_status = TestStatus.PASS\n            ellapsed_seconds = 0\n        test_result = TestResult(\n            test_id_string,\n            test_status,\n            ellapsed_seconds,\n            reason\n        )\n        self.log_info('Result: ' + str(test_result))\n        self.test_results.put(test_result)\n        return test_result\n\n    def teardown(self):\n        '''\n        :return: 1 if any test failed, 0 otherwise\n        '''\n        self.log_info('\\nTest result summary:')\n        passes = []\n        fails = []\n        while not self.test_results.empty():\n            test = self.test_results.get()\n            if test.status in (TestStatus.PASS, None):\n                bisect.insort(passes, test)\n            else:\n                bisect.insort(fails, test)\n        for test in itertools.chain(passes, fails):\n            self.log_info(test)\n        if fails:\n            self.log_error('A test failed')\n            return 1\n        return 0\n\n# IO format.\n\nclass LkmcList(list):\n    '''\n    list with a lightweight serialization format for algorithm IO.\n    '''\n    def __init__(self, *args, **kwargs):\n        if 'oneline' in kwargs:\n            self.oneline = kwargs['oneline']\n            del kwargs['oneline']\n        else:\n            self.oneline = False\n        super().__init__(*args, **kwargs)\n    def __str__(self):\n        if self.oneline:\n            sep = ' '\n        else:\n            sep = '\\n'\n        return sep.join([str(item) for item in self])\n\nclass LkmcOrderedDict(collections.OrderedDict):\n    '''\n    dict with a lightweight serialization format for algorithm IO.\n    '''\n    def __str__(self):\n        out = []\n        for key in self:\n            out.extend([\n                str(key),\n                str(self[key]) + '\\n',\n            ])\n        return '\\n'.join(out)\n"
        },
        {
          "name": "config.py",
          "type": "blob",
          "size": 0.39453125,
          "content": "'''\nhttps://cirosantilli.com/linux-kernel-module-cheat#default-command-line-arguments\n'''\n\ndef set_args(args, script_name):\n    # archs in plural here because --arch adds items to a list of archs.\n    args['archs'] = ['aarch64']\n    args['emulators'] = ['gem5']\n    if script_name == 'build-gem5':\n        # This argument is defined only for ./build-gem5.\n        args['extra_make_args'] = ['ADSF=qwer']\n"
        },
        {
          "name": "copy-overlay",
          "type": "blob",
          "size": 0.513671875,
          "content": "#!/usr/bin/env python3\n\nimport distutils.dir_util\nimport os\nimport shutil\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.BuildCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#rootfs-overlay\n''')\n\n    def build(self):\n        self.sh.copy_dir_if_update(\n            srcdir=self.env['rootfs_overlay_dir'],\n            destdir=self.env['out_rootfs_overlay_dir'],\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "crosstool_ng_config",
          "type": "tree",
          "content": null
        },
        {
          "name": "disas",
          "type": "blob",
          "size": 0.93359375,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport lkmc.import_path\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nDisassemble one function of the given executable.\nhttps://cirosantilli.com/linux-kernel-module-cheat#run-toolchain\n''',\n        )\n        self.add_argument('function', default='main', help='Which function to disassemble.')\n\n    def timed_main(self):\n        lkmc.import_path.import_path_main('run-toolchain')(\n            tool='gdb',\n            extra_args=[\n                '-nh',\n                '-batch',\n                '-ex',\n                'disas/rs {}'.format(self.env['function']),\n                self.env['image_elf'],\n            ],\n            quiet=True,\n            **self.get_common_args()\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "docinfo-footer.html",
          "type": "blob",
          "size": 0.466796875,
          "content": "<script>\n<!-- Google Analytics, AKA selling my soul to Google for some backlinks. -->\n(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\nm=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\nga('create', 'UA-47867706-1', 'auto');\nga('send', 'pageview');\n</script>\n"
        },
        {
          "name": "docinfo.html",
          "type": "blob",
          "size": 0.13671875,
          "content": "<style>\npre{ white-space:pre }\n#header,#content,#footnotes,#footer {\n  margin-left:40px;\n  padding-right:60px;\n  max-width:none;\n}\n</style>\n"
        },
        {
          "name": "eeval",
          "type": "blob",
          "size": 0.70703125,
          "content": "#!/usr/bin/env bash\n# echo a command and eval it.\n# Can also print the command to a file.\nset -e\na=\nwhile getopts a OPT; do\n  case \"$OPT\" in\n    a)\n      # Append to file instead of overwriting.\n      a=-a\n      ;;\n    ?)\n      exit 2\n      ;;\n  esac\ndone\nshift \"$(($OPTIND - 1))\"\ncmd=\"$1\"\noutfile=\"${2:-/dev/null}\"\nmkdir -p \"$(dirname \"$outfile\")\"\necho \"$cmd\" | tee $a \"$outfile\"\n# PIPESTATUS so that cmd=\"main_cmd | post_process\" will return the status of cmd.\n# Not POSIX.\n# https://unix.stackexchange.com/questions/14270/get-exit-status-of-process-thats-piped-to-another\n# https://stackoverflow.com/questions/1221833/pipe-output-and-capture-exit-status-in-bash\neval \"${cmd}; cmd_exit=\\${PIPESTATUS[0]}\"\nexit \"$cmd_exit\"\n"
        },
        {
          "name": "gem5-bench-cache",
          "type": "blob",
          "size": 3.5361328125,
          "content": "#!/usr/bin/env bash\nset -eu\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null && pwd)\"\ngenerate_checkpoints=true\nwhile getopts \"C\" OPT; do\n  case \"$OPT\" in\n    C)\n      generate_checkpoints=false\n      ;;\n    ?)\n      exit 2;\n      ;;\n  esac\ndone\nshift \"$(($OPTIND - 1))\"\ncommon_opts=\"--emulator gem5 $@\"\n\n# Vars\ncmd=\"./run ${common_opts}\"\ncache_small='--caches --l2cache --l1d_size=1024   --l1i_size=1024   --l2_size=1024   --l3_size=1024  '\ncache_large='--caches --l2cache --l1d_size=1024kB --l1i_size=1024kB --l2_size=1024kB --l3_size=1024kB'\nresults_file=\"$(${root_dir}/getvar ${common_opts} run_dir)/bench-cache.txt\"\n\nbench() (\n  \"${root_dir}/bench-cmd\" \"$1\"\n  {\n    printf 'cycles '\n    ./gem5-stat ${common_opts}\n    printf 'instructions '\n    ./gem5-stat ${common_opts} sim_insts\n    # RESTORE_INVESTIGATION\n    #cycles_switch=\"$(./gem5-stat ${common_opts} system.switch_cpus.numCycles)\"\n    #if [ -n \"$cycles_switch\" ]; then\n    #  printf \"cycles_switch ${cycles_switch}\\n\"\n    #fi\n    printf \"\\n\"\n  } >> \"$results_file\"\n)\n\nbench-all() (\n  bench \"${cmd} --gem5-readfile \\\"$1\\\" --gem5-restore 1 -- ${cache_small} --cpu-type=HPI --restore-with-cpu=HPI\"\n  bench \"${cmd} --gem5-readfile \\\"$1\\\" --gem5-restore 1 -- ${cache_large} --cpu-type=HPI --restore-with-cpu=HPI\"\n  # RESTORE_INVESTIGATION\n  # These were mostly to investigate what happens on restore:\n  # https://stackoverflow.com/questions/49011096/how-to-switch-cpu-models-in-gem5-after-restoring-a-checkpoint-and-then-observe-t\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 1\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 1 -- ${cache_small}\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 1 -- ${cache_large}\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 2 -- ${cache_small}\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 3 -- ${cache_large}\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 4 -- ${cache_small} --cpu-type=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 5 -- ${cache_large} --cpu-type=HPI\"\n  ## Restore from At-- omicSimpleCPU to HPI.\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 2 -- ${cache_small} --cpu-type=HPI --restore-with-cpu=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 3 -- ${cache_large} --cpu-type=HPI --restore-with-cpu=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 2 -- ${cache_small} --restore-with-cpu=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 3 -- ${cache_large} --restore-with-cpu=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 2 -- ${cache_small} --cpu-type=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 3 -- ${cache_large} --cpu-type=HPI\"\n  ## Restore HPI with different cache sizes and see if it is used.\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 4 -- ${cache_large} --cpu-type=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 5 -- ${cache_small} --cpu-type=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 2 -- ${cache_large} --cpu-type=HPI\"\n  #bench \"${cmd} --gem5-readfile '$1' --gem5-restore 3 -- ${cache_small} --cpu-type=HPI\"\n)\n\n\nif \"$generate_checkpoints\"; then\n  # Create the checkpoints after the kernel boot.\n  cpt_cmd=\"--eval './gem5.sh'\"\n  # RESTORE_INVESTIGATION\n  ## 5\n  #./eeval \"$cmd $cpt_cmd -- $cache_large --cpu-type=HPI\"\n  ## 4\n  #./eeval \"$cmd $cpt_cmd -- $cache_small --cpu-type=HPI\"\n  ## 3\n  #./eeval \"$cmd $cpt_cmd -- $cache_large\"\n  ## 2\n  #./eeval \"$cmd $cpt_cmd -- $cache_small\"\n  # 1\n  ./eeval \"$cmd $cpt_cmd\"\nfi\n\n# Restore and run benchmarks.\nrm -f \"$results_file\"\nfor n in 1000 10000 100000; do\n  bench-all \"dhrystone ${n}\"\ndone\n"
        },
        {
          "name": "gem5-bench-dhrystone",
          "type": "blob",
          "size": 1.09765625,
          "content": "#!/usr/bin/env bash\n\n# https://cirosantilli.com/linux-kernel-module-cheat#gem5-run-benchmark\n\nset -eu\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null && pwd)\"\noutfile=\"${root_dir}/out/gem5-bench-dhrystone.txt\"\narch=aarch64\ncmd=\"./run --arch '$arch' --emulator gem5 --eval-after './gem5.sh'\"\n\n# These cache sizes roughly match the ARM Cortex A75\n# https://en.wikipedia.org/wiki/ARM_Cortex-A75\nrestore='--gem5-restore 1 -- --cpu-type=HPI --restore-with-cpu=HPI --caches --l2cache --l1d_size=64kB --l1i_size=64kB --l2_size=256kB'\n\n# Generate a checkpoint after Linux boots, using the faster and less detailed CPU.\n# The boot takes a while, be patient young Padawan.\neval \"$cmd\"\n\nprintf 'n cycles\\n' > \"$outfile\"\nfor n in 1000 10000 100000; do\n  # Restore the most recent checkpoint taken with the more detailed and slower HPI CPU,\n  # and run the benchmark with different parameters. We skip the boot completely, saving time!\n  eval \"${cmd} --gem5-readfile 'm5 resetstats;dhrystone ${n};m5 dumpstats' ${restore}\" &>/dev/null\n  printf \"${n} \" >> \"$outfile\"\n  ./gem5-stat --arch \"$arch\" | head -n 1 >> \"$outfile\"\ndone\n"
        },
        {
          "name": "gem5-regression",
          "type": "blob",
          "size": 1.5859375,
          "content": "#!/usr/bin/env python3\nfrom shell_helpers import LF\n\nimport os\nimport pathlib\nimport subprocess\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nRun gem5 regression tests.\nhttps://cirosantilli.com/linux-kernel-module-cheat#gem5-regression-tests\n'''\n        )\n        self.add_argument(\n            '--cmd',\n            default='run',\n            help='''\nList tests instead of running them.\n''',\n        )\n        self.add_argument(\n            'extra_args',\n            metavar='extra-args',\n            nargs='*',\n        )\n\n    def timed_main(self):\n        if self.env['cmd'] == 'run':\n            extra_args = [\n                '--base-dir', self.env['gem5_source_dir'], LF,\n                '--bin-path', self.env['gem5_test_binaries_dir'], LF,\n                '--build-dir', self.env['gem5_build_build_dir'], LF,\n                '-j', str(self.env['nproc']), LF,\n                '-t', str(self.env['nproc']), LF,\n            ]\n        else:\n            extra_args = []\n        return self.sh.run_cmd(\n            [\n                os.path.join(self.env['gem5_source_dir'], 'tests', 'main.py'), LF,\n                self.env['cmd'], LF,\n                '--isa', self.env['gem5_arch'], LF,\n                '--variant', self.env['gem5_build_type'], LF,\n            ] +\n            extra_args +\n            self.sh.add_newlines(self.env['extra_args']),\n            cwd=os.path.join(self.env['gem5_source_dir'], 'tests'),\n            raise_on_failure=False,\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "gem5-shell",
          "type": "blob",
          "size": 0.541015625,
          "content": "#!/usr/bin/env python3\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults={\n                'emulators': ['gem5'],\n            },\n            description='Connect a terminal to a running gem5 instance',\n        )\n    def timed_main(self):\n        return self.sh.run_cmd([\n            self.env['gem5_m5term'],\n            'localhost',\n            str(self.env['gem5_telnet_port']),\n            LF,\n        ])\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "gem5-stat",
          "type": "blob",
          "size": 0.58984375,
          "content": "#!/usr/bin/env python3\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults={\n                'show_time': False,\n            },\n            description='''\\\nGet the value of a gem5 stat from the stats.txt file.\n''',\n        )\n        self.add_argument(\n            'stat',\n            help='Python regexp matching the full stat name of interest',\n            nargs='?',\n        )\n\n    def timed_main(self):\n        stats = self.get_stats(self.env['stat'])\n        print('\\n'.join(stats))\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "getprops",
          "type": "blob",
          "size": 0.6865234375,
          "content": "#!/usr/bin/env python3\n\nimport common\nimport json\nimport path_properties\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nGet the path_properties for an userland executable:\nhttps://cirosantilli.com/linux-kernel-module-cheat#path-properties\nTODO check that the path exists.\n''',\n        )\n        self.add_argument('path')\n\n    def timed_main(self):\n        properties = path_properties.get(self.env['path']).properties\n        for key in sorted(properties):\n            print('{}={}'.format(key, properties[key]))\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "getvar",
          "type": "blob",
          "size": 0.904296875,
          "content": "#!/usr/bin/env python3\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nPrint the value of a self.env['py'] variable.\nhttps://cirosantilli.com/linux-kernel-module-cheat#getvar\n''',\n        )\n        self.add_argument('--type', choices=['input', 'all'], default='all')\n        self.add_argument('variable', nargs='?')\n\n    def timed_main(self):\n        variable = self.env['variable']\n        if variable:\n            print(self.env[variable])\n        else:\n            if self.env['type'] == 'input':\n                to_print = self.input_args\n            elif self.env['type'] == 'all':\n                to_print = self.env\n            for key in sorted(to_print):\n                print('{}={}'.format(key, self.env[key]))\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "hello_host_kernel_module",
          "type": "tree",
          "content": null
        },
        {
          "name": "java",
          "type": "blob",
          "size": 0.0234375,
          "content": "rootfs_overlay/lkmc/java"
        },
        {
          "name": "kernel_modules",
          "type": "tree",
          "content": null
        },
        {
          "name": "linux_config",
          "type": "tree",
          "content": null
        },
        {
          "name": "lkmc.c",
          "type": "blob",
          "size": 3.67578125,
          "content": "/* https://cirosantilli.com/linux-kernel-module-cheat#lkmc-c */\n\n#include <math.h>\n#include <stdio.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#include <lkmc.h>\n\n#define LKMC_ASSERT_EQ_DEFINE(bits) \\\n    LKMC_ASSERT_EQ_DECLARE(bits) \\\n    { \\\n        if (val1 != val2) { \\\n            printf(\"%s failed\\n\", __func__); \\\n            printf(\"val1 0x%\" PRIX ## bits \"\\n\", val1); \\\n            printf(\"val2 0x%\" PRIX ## bits \"\\n\", val2); \\\n            lkmc_assert_fail(line); \\\n        } \\\n    }\nLKMC_ASSERT_EQ_DEFINE(32)\nLKMC_ASSERT_EQ_DEFINE(64)\n#undef ASSERT_EQ_DEFINE\n\nvoid lkmc_assert_fail(uint32_t line) {\n    printf(\"error: assertion failed at line: %\" PRIu32 \"\\n\", line);\n    fflush(stdout);\n    abort();\n}\n\nvoid lkmc_assert_memcmp(\n    const void *s1,\n    const void *s2,\n    size_t n,\n    uint32_t line\n) {\n    size_t i;\n    uint8_t *s1b, *s2b;\n    uint8_t b1, b2;\n\n    s1b = (uint8_t *)s1;\n    s2b = (uint8_t *)s2;\n    for (i = 0; i < n; ++i) {\n        b1 = s1b[i];\n        b2 = s2b[i];\n        if (b1 != b2) {\n            printf(\n                \"%s failed: \"\n                \"byte1, byte2, index: \"\n                \"0x%02\" PRIX8 \" 0x%02\" PRIX8 \" 0x%zX\\n\",\n                __func__,\n                b1,\n                b2,\n                i\n            );\n            lkmc_assert_fail(line);\n        }\n    }\n}\n\nvoid __attribute__ ((noinline)) lkmc_busy_loop(\n    unsigned long long max,\n    unsigned long long max2\n) {\n    for (unsigned long long i = 0; i < max2; i++) {\n        for (unsigned long long j = 0; j < max; j++) {\n            __asm__ __volatile__ (\"\" : \"+g\" (i), \"+g\" (j) : :);\n        }\n    }\n}\n\nvoid lkmc_print_hex_32(uint32_t x) {\n    printf(\"0x%08\" PRIX32, x);\n}\n\nvoid lkmc_print_hex_64(uint64_t x) {\n    printf(\"0x%016\" PRIX64, x);\n}\n\nvoid lkmc_print_newline() {\n    printf(\"\\n\");\n}\n\n#if defined(__arm__)\n\nvoid lkmc_arm_psci_cpu_on(\n    uint32_t target_cpu,\n    uint32_t entry_point_address,\n    uint32_t context_id\n) {\n    register int r0 __asm__ (\"r0\") = 0x84000003;\n    register int r1 __asm__ (\"r1\") = target_cpu;\n    register int r2 __asm__ (\"r2\") = entry_point_address;\n    register int r3 __asm__ (\"r3\") = context_id;\n    __asm__ __volatile__(\n        \"hvc 0\\n\"\n        :\n        : \"r\" (r0),\n          \"r\" (r1),\n          \"r\" (r2),\n          \"r\" (r3)\n        :\n    );\n}\n\n#elif defined(__aarch64__)\n\n#define LKMC_SYSREG_READ_WRITE(nbits, name) \\\n    LKMC_CONCAT(LKMC_CONCAT(uint, nbits), _t) LKMC_CONCAT(LKMC_CONCAT(LKMC_SYSREG_SYMBOL_PREFIX, read_), name)(void) { \\\n        LKMC_CONCAT(LKMC_CONCAT(uint, nbits), _t) name; \\\n        __asm__ __volatile__(\"mrs %0, \" #name : \"=r\" (name) : : ); \\\n        return name; \\\n    } \\\n    void LKMC_CONCAT(LKMC_CONCAT(LKMC_SYSREG_SYMBOL_PREFIX, write_), name)(LKMC_CONCAT(LKMC_CONCAT(uint, nbits), _t) name) { \\\n        __asm__ __volatile__(\"msr \" #name \", %0\" : : \"r\" (name) : ); \\\n    } \\\n    void LKMC_CONCAT(LKMC_CONCAT(LKMC_SYSREG_SYMBOL_PREFIX, print_), name)(void) { \\\n        printf(#name \" 0x%\" PRIX ## nbits \"\\n\", LKMC_CONCAT(LKMC_CONCAT(LKMC_SYSREG_SYMBOL_PREFIX, read_), name)()); \\\n    }\nLKMC_SYSREG_OPS\n#undef LKMC_SYSREG_READ_WRITE\n\nuint64_t lkmc_aarch64_cpu_id() {\n    /* TODO: cores beyond 4th?\n     * Mnemonic: Main Processor ID Register\n     */\n    return lkmc_sysreg_read_mpidr_el1() & 3;\n}\n\nvoid lkmc_aarch64_psci_cpu_on(\n    uint64_t target_cpu,\n    uint64_t entry_point_address,\n    uint64_t context_id\n) {\n    register int w0 __asm__ (\"w0\") = 0xc4000003;\n    register int x1 __asm__ (\"x1\") = target_cpu;\n    register int x2 __asm__ (\"x2\") = entry_point_address;\n    register int x3 __asm__ (\"x3\") = context_id;\n    __asm__ __volatile__(\n        \"hvc 0\\n\"\n        :\n        : \"r\" (w0),\n          \"r\" (x1),\n          \"r\" (x2),\n          \"r\" (x3)\n        :\n    );\n}\n#endif\n"
        },
        {
          "name": "lkmc.h",
          "type": "blob",
          "size": 2.3056640625,
          "content": "/* https://cirosantilli.com/linux-kernel-module-cheat#lkmc-c\n *\n * This toplevel header includes all the lkmc/ *.h headers.\n */\n\n#ifndef LKMC_H\n#define LKMC_H\n\n#if !defined(__ASSEMBLER__)\n#include <errno.h>\n#include <inttypes.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define LKMC_ASSERT_EQ_DECLARE(bits) \\\n    void lkmc_assert_eq_ ## bits( \\\n        uint ## bits ## _t val1, \\\n        uint ## bits ## _t val2, \\\n        uint32_t line \\\n    )\nLKMC_ASSERT_EQ_DECLARE(32);\nLKMC_ASSERT_EQ_DECLARE(64);\nvoid lkmc_assert_fail(uint32_t line);\nvoid lkmc_assert_memcmp(const void *s1, const void *s2, size_t n, uint32_t line);\n\n#define LKMC_ARRAY_SIZE(array) (sizeof(array)/sizeof(array[0]))\n/* Standard action to take in case of a file IO error. */\n#define LKMC_IO_ERROR(function, path) \\\n    fprintf(stderr, \"error: %s errno = %d, path = %s\\n\", function, errno, path); \\\n    exit(EXIT_FAILURE);\n#define LKMC_TMP_EXT \".tmp\"\n/* Temporary per C source file name that our examples can safely create. */\n#define LKMC_TMP_FILE __FILE__ LKMC_TMP_EXT\n#define LKMC_TMP_FILE_NAMED(name) __FILE__ \"__\" name LKMC_TMP_EXT\n\n/* https://cirosantilli.com/linux-kernel-module-cheat#c-busy-loop */\nvoid __attribute__ ((noinline)) lkmc_busy_loop(\n    unsigned long long max,\n    unsigned long long max2\n);\n#endif\n\n/* Assert that the given branch instruction is taken. */\n#define LKMC_ASSERT(branch_if_pass) \\\n    branch_if_pass 1f; \\\n    LKMC_ASSERT_FAIL; \\\n1: \\\n;\n\n/* https://stackoverflow.com/questions/1489932/how-to-concatenate-twice-with-the-c-preprocessor-and-expand-a-macro-as-in-arg */\n#define LKMC_CONCAT_EVAL(a,b) a ## b\n#define LKMC_CONCAT(a,b) LKMC_CONCAT_EVAL(a, b)\n\n#define LKMC_STRINGIFY_DO(x) #x\n#define LKMC_STRINGIFY(x) LKMC_STRINGIFY_DO(x)\n\n#define LKMC_GLOBAL(name) \\\n    .global name; \\\n    name:\n\n/* Common C definitions. */\n#define LKMC_UNUSED(x) (void)x\n\n/* Weak means that if any other file defines it as a non-weak global,\n * that one will take precedence:\n * https://stackoverflow.com/questions/274753/how-to-make-weak-linking-work-with-gcc/54601464#54601464\n */\n#define LKMC_WEAK(name) \\\n    .weak name; \\\n    name:\n\n#if defined(__x86_64__)\n#include <lkmc/x86_64.h>\n#elif defined(__arm__)\n#include <lkmc/arm.h>\n#elif defined(__aarch64__)\n#include <lkmc/aarch64.h>\n#else\n#error\n#endif\n\n#include <lkmc/m5ops.h>\n\n#endif\n"
        },
        {
          "name": "lkmc",
          "type": "tree",
          "content": null
        },
        {
          "name": "nodejs",
          "type": "blob",
          "size": 0.0263671875,
          "content": "rootfs_overlay/lkmc/nodejs/"
        },
        {
          "name": "npm",
          "type": "tree",
          "content": null
        },
        {
          "name": "patches",
          "type": "tree",
          "content": null
        },
        {
          "name": "path_properties.py",
          "type": "blob",
          "size": 38.9111328125,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport signal\n\nfrom shell_helpers import LF\n\nclass PathProperties:\n    default_c_std = 'c11'\n    default_cxx_std = 'c++17'\n    # All new properties must be listed here or else you get an error.\n    default_properties = {\n        'allowed_archs': None,\n        'allowed_emulators': None,\n        # The example uses aarch32 instructions which are not present in ARMv7.\n        # Therefore, it cannot be run in baremetal ARMv7 CPUs.\n        # User mode simulation however seems to enable aarch32 so these run fine.\n        'arm_aarch32': False,\n        'arm_sve': False,\n        # Examples that can be built in baremetal.\n        'baremetal': False,\n        'c_std': default_c_std,\n        'cc_flags': [\n            '-Wall', LF,\n            '-Werror', LF,\n            '-Wextra', LF,\n            '-Wno-unused-function', LF,\n            '-ggdb3', LF,\n            # PIE causes the following problems:\n            # * QEMU GDB step debug does not find breakpoints:\n            #   https://stackoverflow.com/questions/51310756/how-to-gdb-step-debug-a-dynamically-linked-executable-in-qemu-user-mode/51343326#51343326\n            # * when writing assembly code, we have to constantly think about it:\n            #   https://stackoverflow.com/questions/2463150/what-is-the-fpie-option-for-position-independent-executables-in-gcc-and-ld/51308031#51308031\n            # As of lkmc 91986fb2955f96e06d1c5ffcc5536ba9f0af1fd9, our Buildroot toolchain\n            # does not have it enabled by default, but the Ubuntu 18.04 host toolchain does.\n            '-fno-pie', LF,\n            '-no-pie', LF,\n        ],\n        'cc_flags_after': ['-lm', LF],\n        'cc_pedantic': True,\n        'cxx_std': default_cxx_std,\n        # Shuts system down, consumes a lot of memory, etc.\n        'disrupts_system': False,\n        # Expected program exit status. When signals are raised, this refers\n        # to the native exit status. as reported by Bash #?.\n        'exit_status': 0,\n        'extra_objs': [],\n        # Explicitly don't add the baremetal bootloader object which normally gets automatically\n        # added to baremetal examples.\n        'extra_objs_disable_baremetal_bootloader': False,\n        # We should get rid of this if we ever properly implement dependency graphs.\n        # Enable: https://cirosantilli.com/linux-kernel-module-cheat#lkmc-c\n        'extra_objs_lkmc_common': False,\n        'freestanding': False,\n        'gem5_unimplemented_instruction': False,\n        # Fully, or partially unimplemented.\n        'gem5_unimplemented_syscall': False,\n        # For some reason QEMU fails with SIGSEGV on int syscalls in x86_64.\n        'qemu_x86_64_int_syscall': False,\n        'interactive': False,\n        'minimum_gcc_version': (0, 0, 0),\n        # The script takes a perceptible amount of time to run. Possibly an infinite loop.\n        'more_than_1s': False,\n        # The path should not be built. E.g.:\n        # - it is symlinked into multiple archs\n        # - we have not integrated into the build yet, often it is being important from another repo\n        #   and has a Makefile\n        'no_build': False,\n        # The path does not generate an executable in itself, e.g.\n        # it only generates intermediate object files. Therefore it\n        'no_executable': False,\n        'qemu_unimplemented_instruction': False,\n        # The script requires a non-trivial to determine argument to be passed to run properly.\n        'requires_argument': False,\n        # Let's not test stuff that relies on the internet by default, user might be offline,\n        # or Internet might be slow and make tests slow.\n        'requires_internet': False,\n        # Requires certain of our custom kernel modules to be inserted to run.\n        'requires_kernel_modules': False,\n        # gem5 syscall emulation cannot handle dynamically linked exectuables properly.\n        # https://stackoverflow.com/questions/50542222/how-to-run-a-dynamically-linked-executable-syscall-emulation-mode-se-py-in-gem5\n        'requires_dynamic_library': False,\n        'requires_m5ops': False,\n        # gem5 fatal: syscall getcpu (#168) unimplemented.\n        'requires_syscall_getcpu': False,\n        'requires_syscall_get_nprocs': False,\n        'requires_semihosting': False,\n        # The example requires sudo, which usually implies that it can do something\n        # deeply to the system it runs on, which would preventing further interactive\n        # or test usage of the system, for example poweroff or messing up the GUI.\n        'requires_sudo': False,\n        # The signal received is generated by the OS implicitly rather than explicitly\n        # done sith signal(), e.g. Illegal instruction or sigsegv.\n        # Therefore, it won't behave in the same way in baremetal. aarch64 already\n        # has an exception handler which we could use but arm doesn't and the IP\n        # goes astray, so let's just skip this for now.\n        'signal_generated_by_os': False,\n        'signal_received': None,\n        # We were lazy to properly classify why we are skipping these tests.\n        # TODO get it done.\n        'skip_run_unclassified': False,\n        # Look for the given file under test_data/ relative to the file under test,\n        # and pass the given file as the stdin of the program. The .i input extension is\n        # appended implicitly to the test path.\n        'test_stdin_data': None,\n        # Aruments added automatically to run when running tests,\n        # but not on manual running.\n        'test_run_args': {},\n        # Examples that can be built in userland.\n        'userland': False,\n        # Known instructions that this test uses, and which may not be implemented\n        # in a given simulator, in which case we skip.\n        'uses_instructions': {},\n    }\n\n    unimplemented_instructions = {\n        'gem5': {\n            'arm': {\n                'vcvta',\n            },\n            'x86_64': {\n                'fcomi',\n                'fcomip',\n                'fsqrt',\n                'popcnt',\n                'rdrand',\n                'rdtscp',\n                'vfmadd132pd',\n            },\n        },\n        'qemu': {\n            'x86_64': {\n                'popcnt',\n                'rdtscp',\n                'rdrand',\n                'vfmadd132pd',\n            }\n        },\n    }\n\n    # TODO wire up.\n    unimplemented_userland_syscalls = {\n        'gem5': {\n            'all': {\n                'wait',\n            },\n            'arm': {\n            },\n            'x86_64': {\n            },\n        },\n        'qemu': {\n            'all': {\n            },\n            'arm': {\n            },\n            'x86_64': {\n            },\n        },\n    }\n\n    # TODO maybe extract automatically from GCC executable?\n    current_gcc_version = (7, 3, 0)\n\n    '''\n    Encodes properties of userland and baremetal paths.\n    For directories, it applies to all files under the directory.\n    Used to determine how to build and test the examples.\n    '''\n    def __init__(\n        self,\n        properties\n    ):\n        for key in properties:\n            if not key in self.default_properties:\n                raise ValueError('Unknown key: {}'.format(key))\n        self.properties = properties.copy()\n\n    def __getitem__(self, key):\n        return self.properties[key]\n\n    def __repr__(self):\n        return str(self.properties)\n\n    def set_path_components(self, path_components):\n        self.path_components = path_components\n\n    def should_be_built(\n        self,\n        env,\n        link=False,\n    ):\n        ext = os.path.splitext(self.path_components[-1])[1]\n        return (\n            not (\n                len(self.path_components) > 1 and \\\n                self.path_components[1] == 'libs' and \\\n                not env['package_all'] and \\\n                not self.path_components[2] in env['package']\n            ) and\n            not self['no_build'] and\n            (\n                self['allowed_archs'] is None or\n                env['arch'] in self['allowed_archs']\n            ) and\n            not (\n                (\n                    env['mode'] == 'userland' and\n                    (\n                        not self['userland'] or\n                        not ext in env['build_in_exts']\n                    )\n                ) or\n                (\n                    env['mode'] == 'baremetal' and (\n                        not self['baremetal'] or\n                        not ext in env['baremetal_build_in_exts']\n                    )\n                )\n            ) and\n            not (\n                link and\n                self['no_executable']\n            ) and not (\n                # Our C compiler does not suppport SVE yet.\n                # https://cirosantilli.com/linux-kernel-module-cheat#update-gcc-gcc-supported-by-buildroot\n                os.path.splitext(self.path_components[-1])[1] == '.c' and self['arm_sve']\n            ) and not (\n                # C++ multithreading in static does not seem to work:\n                # https://cirosantilli.com/linux-kernel-module-cheat#cpp-static-and-pthreads\n                os.path.splitext(self.path_components[-1])[1] == '.cpp' and (\n                    # TODO the better check here would be for 'static'\n                    # to factor out with test-executable logic, but lazy.\n                    # env['static'] and\n                    env['emulator'] == 'gem5' and\n                    'cpus' in self['test_run_args'] and\n                    self['test_run_args']['cpus'] > 1\n                )\n            ) and not (\n                self['minimum_gcc_version'] > self.current_gcc_version\n            )\n        )\n\n    def should_be_tested(self, env):\n        basename = self.path_components[-1]\n        return (\n            self.should_be_built(\n                env,\n            ) and\n            not basename.startswith(env['tmp_prefix']) and\n            not (\n                env['mode'] == 'baremetal' and (\n                    self['arm_aarch32'] or\n                    self['signal_generated_by_os']\n                )\n            ) and\n            not self['disrupts_system'] and\n            not self['interactive'] and\n            not self['more_than_1s'] and\n            not self['no_executable'] and\n            not self['requires_argument'] and\n            not self['requires_internet'] and\n            not self['requires_kernel_modules'] and\n            not self['requires_sudo'] and\n            not self['skip_run_unclassified'] and\n            not self['qemu_x86_64_int_syscall'] and\n            not (\n                env['emulator'] == 'gem5' and\n                (\n                    self['gem5_unimplemented_syscall'] or\n                    # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/101\n                    self['signal_received'] is not None or\n                    self['requires_dynamic_library'] or\n                    self['requires_semihosting'] or\n                    self['requires_syscall_getcpu'] or\n                    # https://gem5.atlassian.net/browse/GEM5-622\n                    self['requires_syscall_get_nprocs']\n                )\n            ) and\n            not (\n                env['emulator'] == 'qemu' and\n                (\n                    self['requires_m5ops']\n                )\n            ) and\n            not (\n                env['arch'] in self['uses_instructions'] and\n                env['emulator'] in self.unimplemented_instructions and\n                env['arch'] in self.unimplemented_instructions[env['emulator']] and\n                (\n                    self.unimplemented_instructions[env['emulator']][env['arch']] &\n                    self['uses_instructions'][env['arch']]\n                )\n            ) and\n            (\n                self['allowed_emulators'] is None or\n                env['emulator'] in self['allowed_emulators']\n            )\n        )\n\n    def _update_dict(self, other_tmp_properties, key):\n        if key in self.properties and key in other_tmp_properties:\n            other_tmp_properties[key] = {\n                **self.properties[key],\n                **other_tmp_properties[key]\n            }\n\n    def _update_list(self, other_tmp_properties, key):\n        if key in self.properties and key in other_tmp_properties:\n            other_tmp_properties[key] = \\\n                self.properties[key] + \\\n                other_tmp_properties[key]\n\n    def update(self, other):\n        other_tmp_properties = other.properties.copy()\n        self._update_list(other_tmp_properties, 'cc_flags')\n        self._update_list(other_tmp_properties, 'cc_flags_after')\n        self._update_list(other_tmp_properties, 'extra_objs')\n        self._update_dict(other_tmp_properties, 'test_run_args')\n        return self.properties.update(other_tmp_properties)\n\nclass PrefixTree:\n    def __init__(self, path_properties_dict=None, children=None):\n        if path_properties_dict is None:\n            path_properties_dict = {}\n        if children is None:\n            children = {}\n        self.children = children\n        self.path_properties = PathProperties(path_properties_dict)\n\n    @staticmethod\n    def make_from_tuples(tuples):\n        '''\n        TODO check that all paths exist.\n        '''\n        def tree_from_tuples(tuple_):\n            if not type(tuple_) is tuple:\n                tuple_ = (tuple_, {})\n            cur_properties, cur_children = tuple_\n            return PrefixTree(cur_properties, cur_children)\n        top_tree = tree_from_tuples(tuples)\n        todo_trees = [top_tree]\n        while todo_trees:\n            cur_tree = todo_trees.pop()\n            cur_children = cur_tree.children\n            for child_key in cur_children:\n                new_tree = tree_from_tuples(cur_children[child_key])\n                cur_children[child_key] = new_tree\n                todo_trees.append(new_tree)\n        return top_tree\n\ndef get(path):\n    '''\n    Get the merged path properties of a given path.\n    '''\n    cur_node = path_properties_tree\n    path_components = path.split(os.sep)\n    path_properties = PathProperties(cur_node.path_properties.properties.copy())\n    for path_component in path_components:\n        if path_component in cur_node.children:\n            cur_node = cur_node.children[path_component]\n            path_properties.update(cur_node.path_properties)\n        else:\n            break\n    path_properties.set_path_components(path_components)\n    return path_properties\n\ngnu_extension_properties = {\n    'c_std': 'gnu11',\n    'cxx_std': 'gnu++17'\n}\n# https://cirosantilli.com/linux-kernel-module-cheat#freestanding-programs\nfreestanding_properties = {\n    'baremetal': False,\n    'cc_flags': [\n        '-ffreestanding', LF,\n        '-nostdlib', LF,\n        '-static', LF,\n    ],\n    'extra_objs_lkmc_common': False,\n    'freestanding': True,\n}\n# https://cirosantilli.com/linux-kernel-module-cheat#nostartfiles-programs\nnostartfiles_properties = {\n    # The baremetal bootloader sets up the stack to a valid value.\n    # Therefore, without it, C code may not be called, and so this is very restrictive in general.\n    # Programs that don't call C code nor use stack can still work.\n    'baremetal': False,\n    'cc_flags': [\n        '-nostartfiles', LF,\n    ],\n    'extra_objs_disable_baremetal_bootloader': True,\n}\n# See: https://cirosantilli.com/linux-kernel-module-cheat#path-properties\npath_properties_tuples = (\n    PathProperties.default_properties,\n    {\n        'baremetal': (\n            {\n                'baremetal': True,\n            },\n            {\n                'arch': (\n                    {},\n                    {\n                        'arm': (\n                            {'allowed_archs': {'arm'}},\n                            {\n                                'multicore.c': {\n                                    # It is hard to get visibility into what is going on\n                                    # in that one due to the multicore business.\n                                    'skip_run_unclassified': True,\n                                    'test_run_args': {'cpus': 2}\n                                },\n                                'no_bootloader': (\n                                    {'extra_objs_disable_baremetal_bootloader': True},\n                                    {\n                                        'multicore_asm.S': {'test_run_args': {'cpus': 2}},\n                                        'semihost_exit.S': {'requires_semihosting': True},\n                                    }\n                                ),\n                                'return1.S': {'exit_status': 1},\n                                'semihost_exit.S': {'requires_semihosting': True},\n                            },\n\n                        ),\n                        'aarch64': (\n                            {'allowed_archs': {'aarch64'}},\n                            {\n                                'multicore.c': {'test_run_args': {'cpus': 2}},\n                                'no_bootloader': (\n                                    {'extra_objs_disable_baremetal_bootloader': True},\n                                    {\n                                        'multicore_asm.S': {'test_run_args': {'cpus': 2}},\n                                        'semihost_exit.S': {'requires_semihosting': True},\n                                        'wfe_loop.S': {'more_than_1s': True},\n                                    }\n                                ),\n                                'return1.S': {'exit_status': 1},\n                                'semihost_exit.S': {'requires_semihosting': True},\n                                'svc.c': {'cc_pedantic': False},\n                                'timer.c': {'skip_run_unclassified': True},\n                            },\n                        )\n                    }\n                ),\n                'lib': {'no_executable': True},\n                'getchar.c': {'interactive': True},\n            }\n        ),\n        'kernel_modules': (\n            {},\n            {\n                'float.c': {'allowed_archs': 'x86_64'}\n            },\n        ),\n        'lkmc.c': {\n            'baremetal': True,\n            'userland': True,\n        },\n        'userland': (\n            {\n                'userland': True,\n            },\n            {\n                'algorithm': (\n                    {},\n                    {\n                        'set': (\n                            {\n                                'test_stdin_data': '8',\n                            },\n                            {\n                                'std_priority_queue_gem5.cpp': {'allowed_emulators': {'gem5'}},\n                                'std_set_gem5.cpp': {'allowed_emulators': {'gem5'}},\n                                'std_unordered_set_gem5.cpp': {'allowed_emulators': {'gem5'}},\n                            }\n                        ),\n                    },\n                ),\n                'arch': (\n                    {\n                        'baremetal': True,\n                        'extra_objs_lkmc_common': True,\n                    },\n                    {\n                        'arm': (\n                            {\n                                'allowed_archs': {'arm'},\n                                'cc_flags': [\n                                    # To prevent:\n                                    # > vfp.S: Error: selected processor does not support <FPU instruction> in ARM mode\n                                    # https://stackoverflow.com/questions/41131432/cross-compiling-error-selected-processor-does-not-support-fmrx-r3-fpexc-in/52875732#52875732\n                                    # We aim to take the most extended mode currently available that works on QEMU.\n                                    '-Xassembler', '-mfpu=crypto-neon-fp-armv8.1', LF,\n                                    '-Xassembler', '-meabi=5', LF,\n                                    # Treat inline assembly as arm instead of thumb\n                                    # The opposite of -mthumb.\n                                    '-marm', LF,\n                                    # Make gcc generate .syntax unified for inline assembly.\n                                    # However, it gets ignored if -marm is given, which a GCC bug that was recently fixed:\n                                    # https://stackoverflow.com/questions/54078112/how-to-write-syntax-unified-ual-armv7-inline-assembly-in-gcc/54132097#54132097\n                                    # So we just write divided inline assembly for now.\n                                    '-masm-syntax-unified', LF,\n                                ]\n                            },\n                            {\n                                'inline_asm': (\n                                    {\n                                    },\n                                    {\n                                        'freestanding': freestanding_properties,\n                                    },\n                                ),\n                                'freestanding': freestanding_properties,\n                                'lkmc_assert_eq_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'lkmc_assert_memcmp_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'udf.S': {\n                                    'signal_generated_by_os': True,\n                                    'signal_received': signal.Signals.SIGILL,\n                                },\n                                'vcvta.S': {\n                                    'arm_aarch32': True,\n                                    'uses_instructions': {'arm': {'vcvta'}}\n                                },\n                            }\n                        ),\n                        'aarch64': (\n                            {\n                                'allowed_archs': {'aarch64'},\n                            },\n                            {\n                                'inline_asm': (\n                                    {\n                                    },\n                                    {\n                                        'freestanding': freestanding_properties,\n                                        'futex_sev.cpp': {\n                                            'baremetal': False,\n                                            'more_than_1s': True,\n                                        },\n                                        'futex_ldxr_stxr.c': {\n                                            'baremetal': False,\n                                            'more_than_1s': True,\n                                        },\n                                        'sve_addvl.c': {'arm_sve': True},\n                                        'wfe_ldxr_str.cpp': {\n                                            'allowed_emulators': {'qemu'},\n                                            'test_run_args': {'cpus': 2}\n                                        },\n                                        'wfe_ldxr_stxr.cpp': {\n                                            'allowed_emulators': {'qemu'},\n                                            'test_run_args': {'cpus': 2}\n                                        },\n                                        'wfe_sev.cpp': {\n                                            # gem5 bug, WFE not waking up on syscall emulation,\n                                            # TODO link to bug report.\n                                            'allowed_emulators': {'qemu'},\n                                            'test_run_args': {'cpus': 2},\n                                        },\n                                    },\n                                ),\n                                'dump_regs.c': {\n                                    # https://gem5.atlassian.net/browse/GEM5-619\n                                    'allowed_emulators': {'qemu'},\n                                },\n                                'freestanding': (\n                                    freestanding_properties,\n                                    {\n                                        'linux': (\n                                            {},\n                                            {\n                                                'wfe.S': {'more_than_1s': True},\n                                                'wfe_wfe.S': {'more_than_1s': True},\n                                            }\n                                        ),\n                                    }\n                                ),\n                                'lkmc_assert_eq_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'lkmc_assert_memcmp_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'nostartfiles': (\n                                    nostartfiles_properties,\n                                    {\n                                        # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/107\n                                        'exit.S': {'skip_run_unclassified': True},\n                                        'wfe.S': {'more_than_1s': True},\n                                    }\n                                ),\n                                'udf.S': {\n                                    'signal_generated_by_os': True,\n                                    'signal_received': signal.Signals.SIGILL,\n                                },\n                                'sve.S': {'arm_sve': True},\n                                'sve_addvl.S': {'arm_sve': True},\n                            }\n                        ),\n                        'x86_64': (\n                            {'allowed_archs': {'x86_64'}},\n                            {\n                                'freestanding': (\n                                    freestanding_properties,\n                                    {\n                                        'linux': (\n                                            {},\n                                            {\n                                                'int_system_call.S': {'qemu_x86_64_int_syscall': True},\n                                            }\n                                        ),\n                                    }\n                                ),\n                                'inline_asm': (\n                                    {},\n                                    {\n                                        'freestanding': freestanding_properties,\n                                        'sqrt_x87.c': {'uses_instructions': {'x86_64': {'fsqrt'}}},\n                                    }\n                                ),\n                                'intrinsics': (\n                                    {},\n                                    {\n                                        'rdtscp.c': {'uses_instructions': {'x86_64': {'rdtscp'}}},\n                                    }\n                                ),\n                                'nostartfiles': (\n                                    nostartfiles_properties,\n                                    {\n                                        # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/107\n                                        'exit.S': {'skip_run_unclassified': True},\n                                    }\n                                ),\n                                'div_overflow.S': {'signal_received': signal.Signals.SIGFPE},\n                                'div_zero.S': {'signal_received': signal.Signals.SIGFPE},\n                                'fabs.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fadd.S': {'uses_instructions': {'x86_64': {'fcomi'}}},\n                                'faddp.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fchs.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fild.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fld1.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fldz.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fscale.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'fsqrt.S': {'uses_instructions': {'x86_64': {'fcomip', 'fsqrt'}}},\n                                'fxch.S': {'uses_instructions': {'x86_64': {'fcomip'}}},\n                                'lkmc_assert_eq_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'lkmc_assert_memcmp_fail.S': {'signal_received': signal.Signals.SIGABRT},\n                                'popcnt.S': {'uses_instructions': {'x86_64': {'popcnt'}}},\n                                'rdrand.S': {'uses_instructions': {'x86_64': {'rdrand'}}},\n                                'rdtscp.S': {'uses_instructions': {'x86_64': {'rdtscp'}}},\n                                'ring0.c': {'signal_received': signal.Signals.SIGSEGV},\n                                'vfmadd132pd.S': {'uses_instructions': {'x86_64': {'vfmadd132pd'}}},\n                            }\n                        ),\n                        'lkmc_assert_fail.S': {\n                            'signal_received': signal.Signals.SIGABRT,\n                        },\n                    }\n                ),\n                'c': (\n                    {\n                        'baremetal': True,\n                    },\n                    {\n                        'abort.c': {'signal_received': signal.Signals.SIGABRT},\n                        'atomic': (\n                            {\n                                'baremetal': False,\n                                'test_run_args': {'cpus': 3},\n                            },\n                            {\n                                'aarch64_add.c': {'allowed_archs': {'aarch64'}},\n                                'aarch64_ldadd.c': {'allowed_archs': {'aarch64'}},\n                                'aarch64_ldaxr_stlxr.c': {'allowed_archs': {'aarch64'}},\n                                'x86_64_inc.c': {'allowed_archs': {'x86_64'}},\n                                'x86_64_lock_inc.c': {'allowed_archs': {'x86_64'}},\n                            },\n                        ),\n                        'atomic.c': {\n                            'baremetal': False,\n                            'test_run_args': {'cpus': 3},\n                        },\n                        'assert_fail.c': {'signal_received': signal.Signals.SIGABRT},\n                        # Not sure which argument to pass.\n                        'cat.c': {'skip_run_unclassified': True},\n                        'exit1.c': {'exit_status': 1},\n                        'exit2.c': {'exit_status': 2},\n                        'false.c': {'exit_status': 1},\n                        'file_write_read.c': {'baremetal': False},\n                        'getchar.c': {'interactive': True},\n                        'malloc_max.c': {'disrupts_system': True},\n                        'm5ops.c': {'allowed_emulators': {'gem5'}},\n                        'return1.c': {'exit_status': 1},\n                        'return2.c': {'exit_status': 2},\n                        # This has complex failure modes, too hard to assert.\n                        'smash_stack.c': {'skip_run_unclassified': True},\n                        # Wrapper not defined by newlib.\n                        'timespec_get.c': {'baremetal': False},\n                    }\n                ),\n                'cpp': (\n                    {},\n                    {\n                        'atomic': (\n                            {\n                                'test_run_args': {'cpus': 3},\n                            },\n                            {\n                                'aarch64_add.cpp': {'allowed_archs': {'aarch64'}},\n                                'aarch64_ldadd.cpp': {'allowed_archs': {'aarch64'}},\n                                'aarch64_ldaxr_stlxr.cpp': {'allowed_archs': {'aarch64'}},\n                                'x86_64_inc.cpp': {'allowed_archs': {'x86_64'}},\n                                'x86_64_lock_inc.cpp': {'allowed_archs': {'x86_64'}},\n                            },\n                        ),\n                        'count.cpp': {'more_than_1s': True},\n                        'thread_hardware_concurrency.cpp': {'requires_syscall_get_nprocs': True},\n                        'initialization_types.cpp': {'cc_flags':\n                            ['-Wno-unused-variable', LF, '-Wno-unused-but-set-variable', LF]},\n                        'm5ops.cpp': {'allowed_emulators': {'gem5'}},\n                        'parallel_sort.cpp': {'minimum_gcc_version': (9, 0, 0)},\n                        'sleep_for.cpp': {\n                            'more_than_1s': True,\n                        },\n                        # Need to pass -lstdc++fs but we don't have a mechanism\n                        # to test the GCC version and only pass if >= 7.\n                        'temporary_directory.cpp': {'no_build': True},\n                        'thread_get_id.cpp': {'test_run_args': {'cpus': 2}},\n                        'thread_return_value.cpp': {'test_run_args': {'cpus': 2}},\n                    },\n                ),\n                'freestanding': (\n                    {**freestanding_properties, **{'baremetal': True}},\n                    {\n                        'gem5_checkpoint.S': {'allowed_emulators': {'gem5'}},\n                        'gem5_exit.S': {'allowed_emulators': {'gem5'}},\n                    }\n                ),\n                'gcc': (\n                    {**gnu_extension_properties, **{'cc_pedantic': False}},\n                    {\n                        'busy_loop.c': {\n                            'baremetal': True,\n                            'extra_objs_lkmc_common': True,\n                        },\n                        'openmp.c': {'cc_flags': ['-fopenmp', LF]},\n                    }\n                ),\n                'gdb_tests': {'baremetal': True},\n                'kernel_modules': {**gnu_extension_properties, **{'requires_kernel_modules': True}},\n                'libs': (\n                    {'requires_dynamic_library': True},\n                    {\n                        'cython': {'no_build': True},\n                        'googletest': (\n                            {},\n                            {\n                                'fail.cpp': {'exit_status': 1},\n                            }\n                        ),\n                        'libdrm': {'requires_sudo': True},\n                        'hdf5': (\n                            {},\n                            {\n                                'hello_cpp.cpp': {\n                                    'cc_flags_after': ['-lhdf5_cpp', LF],\n                                },\n                            }\n                        ),\n                        # Makefile build, generates shared libraries.\n                        'pybind11': {'no_build': True},\n                        'python_embed': {'no_build': True},\n                    }\n                ),\n                'linux': (\n                    gnu_extension_properties,\n                    {\n                        'ctrl_alt_del.c': {'requires_sudo': True},\n                        'futex.c': {\n                            'more_than_1s': True,\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'getcpu.c': {\n                            'requires_syscall_getcpu': True,\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'init_env_poweroff.c': {'requires_sudo': True},\n                        'mmap_anonymous_touch.c': {\n                            # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/103\n                            'gem5_unimplemented_syscall': True\n                        },\n                        'myinsmod.c': {'requires_sudo': True},\n                        'myrmmod.c': {'requires_sudo': True},\n                        'open_o_tmpfile.c': {\n                            # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/100\n                            'gem5_unimplemented_syscall': True\n                        },\n                        'pagemap_dump.c': {'requires_argument': True},\n                        'perf_event_open.c': {\n                            # QEMU the syscall just fails on QEMU, presumably because QEMU\n                            # does not have a microarchitecture model, and so it must just set\n                            # CPU bits that inform the kernel that the feature is not available.\n                            # https://cirosantilli.com/linux-kernel-module-cheat#gem5-vs-qemu\n                            'allowed_emulators': {'gem5'},\n                            'extra_objs_lkmc_common': True,\n                        },\n                        'poweroff.c': {'requires_sudo': True},\n                        'proc_events.c': {'requires_sudo': True},\n                        'proc_events.c': {'requires_sudo': True},\n                        'sched_getaffinity.c': {'requires_syscall_getcpu': True},\n                        'sched_getaffinity_threads.c': {\n                            'more_than_1s': True,\n                            'requires_syscall_getcpu': True,\n                        },\n                        'sched_getcpu.c': {\n                            'requires_syscall_getcpu': True,\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'sched_getcpu_barrier.c': {\n                            'requires_syscall_getcpu': True,\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'sysconf.c': {'requires_syscall_get_nprocs': True},\n                        'time_boot.c': {'requires_sudo': True},\n                        'virt_to_phys_user.c': {'requires_argument': True},\n                    }\n                ),\n                'posix': (\n                    {},\n                    {\n                        'count.c': {'more_than_1s': True},\n                        'count_to.c': {'more_than_1s': True},\n                        'kill.c': {\n                            'baremetal': True,\n                            'signal_received': signal.Signals.SIGHUP,\n                        },\n                        'fork.c': {\n                            # wait\n                            'gem5_unimplemented_syscall': True\n                        },\n                        'mmap_file.c': {\n                            # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/102\n                            'gem5_unimplemented_syscall': True\n                        },\n                        'pthread_count.c': {\n                            'more_than_1s': True,\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'pthread_mutex.c': {\n                            'test_run_args': {'cpus': 3},\n                        },\n                        'pthread_self.c': {\n                            'test_run_args': {'cpus': 2},\n                        },\n                        'sleep_forever.c': {'more_than_1s': True},\n                        'wget.c': {'requires_internet': True},\n                        'virt_to_phys_test.c': {'more_than_1s': True},\n                    }\n                ),\n            }\n        ),\n    }\n)\npath_properties_tree = PrefixTree.make_from_tuples(path_properties_tuples)\n"
        },
        {
          "name": "publish-gh-pages",
          "type": "blob",
          "size": 0.642578125,
          "content": "#!/usr/bin/env bash\n# https://cirosantilli.com/linux-kernel-module-cheat#github-pages\nset -eu\ngit push\n./build-doc --github-pages\ngit checkout gh-pages\ngit checkout master -- \\\n  .gitignore \\\n  '*.png' \\\n  _config.yml \\\n;\ntouch .nojekyll\n# submodules are not deleted on checkout.\n# We should not publish like this, we should make a separate tree,\n# otherwise files appear and disapear as you publish, which is bad\n# for editors. But lazy.\necho 'submodules' >> .gitignore\ncp out/README.html index.html\ncp out/doc/* .\nmv README.html index-split.html\ngit add .\ngit commit --allow-empty --message \"$(git log -n1 --pretty='%H' master)\"\ngit push -f\ngit checkout -\n"
        },
        {
          "name": "python",
          "type": "blob",
          "size": 0.0263671875,
          "content": "rootfs_overlay/lkmc/python/"
        },
        {
          "name": "qemu-monitor",
          "type": "blob",
          "size": 1.6240234375,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport sys\nimport telnetlib\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nRun a command on the QEMU monitor of a running QEMU instance\n\nIf the stdin is a terminal, open an interact shell. Otherwise,\nrun commands from stdin and quit.\n''',\n        )\n        self.add_argument(\n            'command',\n            help='If given, run this command and quit',\n            nargs='*',\n        )\n\n    def timed_main(self):\n        def write_and_read(tn, cmd, prompt):\n            tn.write(cmd.encode('utf-8'))\n            return '\\n'.join(tn.read_until(prompt).decode('utf-8').splitlines()[1:])[:-len(prompt)]\n\n        with telnetlib.Telnet('localhost', self.env['qemu_monitor_port']) as tn:\n            prompt = b'\\n(qemu) '\n            # Couldn't disable server echo, so just removing the write for now.\n            # https://stackoverflow.com/questions/12421799/how-to-disable-telnet-echo-in-python-telnetlib\n            # sock = tn.get_socket()\n            # sock.send(telnetlib.IAC + telnetlib.WILL + telnetlib.ECHO)\n            if os.isatty(sys.stdin.fileno()):\n                if self.env['command'] == []:\n                    print(tn.read_until(prompt).decode('utf-8'), end='')\n                    tn.interact()\n                else:\n                    tn.read_until(prompt)\n                    print(write_and_read(tn, ' '.join(self.env['command']) + '\\n', prompt))\n            else:\n                tn.read_until(prompt)\n                print(write_and_read(tn, sys.stdin.read() + '\\n', prompt))\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "qemu-rr",
          "type": "blob",
          "size": 0.06640625,
          "content": "#!/usr/bin/env bash\nset -eu\n./run --record \"$@\"\n./run --replay \"$@\"\n"
        },
        {
          "name": "qemu-trace2txt",
          "type": "blob",
          "size": 0.771484375,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nConvert a QEMU `-trace exec_tb` to text form.\n'''\n        )\n\n    def timed_main(self):\n        return self.sh.run_cmd(\n            [\n                os.path.join(self.env['qemu_source_dir'], 'scripts/simpletrace.py'), LF,\n                os.path.join(self.env['qemu_build_dir'], 'trace-events-all'), LF,\n                os.path.join(self.env['qemu_trace_file']), LF,\n            ],\n            cmd_file=os.path.join(self.env['run_dir'], 'qemu-trace2txt'),\n            out_file=self.env['qemu_trace_txt_file'],\n            show_stdout=False,\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "release-download-latest",
          "type": "blob",
          "size": 0.7412109375,
          "content": "#!/usr/bin/env python3\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nUsage: https://cirosantilli.com/linux-kernel-module-cheat#prebuilt\n\nImplementation:\nhttps://stackoverflow.com/questions/24987542/is-there-a-link-to-github-for-downloading-a-file-in-the-latest-release-of-a-repo/50540591#50540591\n''',\n        )\n\n    def timed_main(self):\n        self.log_info('Downloading the release, this may take several seconds / a few minutes.')\n        _json = self.github_make_request(path='/releases')\n        asset = _json[0]['assets'][0]\n        self.sh.wget(asset['browser_download_url'], asset['name'])\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "release-upload",
          "type": "blob",
          "size": 2.4541015625,
          "content": "#!/usr/bin/env python3\n\nimport json\nimport os\nimport sys\nimport urllib.error\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#release-upload\n''',\n        )\n\n    def timed_main(self):\n        # https://stackoverflow.com/questions/3404936/show-which-git-tag-you-are-on\n        tag = self.sh.check_output([\n            'git',\n            'describe',\n            '--exact-match',\n            '--tags'\n        ]).decode().rstrip()\n        upload_path = self.env['release_zip_file']\n\n        # Check the release already exists.\n        try:\n            _json = self.github_make_request(path='/releases/tags/' + tag)\n        except urllib.error.HTTPError as e:\n            if e.code == 404:\n                release_exists = False\n            else:\n                raise e\n        else:\n            release_exists = True\n            release_id = _json['id']\n\n        # Create release if not yet created.\n        if not release_exists:\n            _json = self.github_make_request(\n                authenticate=True,\n                data=json.dumps({\n                    'tag_name': tag,\n                    'name': tag,\n                    'prerelease': True,\n                }).encode(),\n                path='/releases'\n            )\n            release_id = _json['id']\n\n        asset_name = os.path.split(upload_path)[1]\n\n        # Clear the prebuilts for a upload.\n        _json = self.github_make_request(\n            path=('/releases/' + str(release_id) + '/assets'),\n        )\n        for asset in _json:\n            if asset['name'] == asset_name:\n                _json = self.github_make_request(\n                    authenticate=True,\n                    path=('/releases/assets/' + str(asset['id'])),\n                    method='DELETE',\n                )\n                break\n\n        # Upload the prebuilt.\n        self.log_info('Uploading the release, this may take several seconds / a few minutes.')\n        with open(upload_path, 'br') as myfile:\n            content = myfile.read()\n        _json = self.github_make_request(\n            authenticate=True,\n            data=content,\n            extra_headers={'Content-Type': 'application/zip'},\n            path=('/releases/' + str(release_id) + '/assets'),\n            subdomain='uploads',\n            url_params={'name': asset_name},\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "release-zip",
          "type": "blob",
          "size": 1.32421875,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport zipfile\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#release-zip\n''',\n            defaults = {\n                'show_time': False,\n            }\n        )\n        self.zip_files = []\n\n    def timed_main(self):\n        self.zip_files.append(self.env['qcow2_file'])\n        self.zip_files.append(self.env['linux_image'])\n        for root, dirnames, filenames in os.walk(self.env['baremetal_build_dir']):\n            for filename in sorted(filenames):\n                path = os.path.join(root, filename)\n                if os.path.splitext(path)[1] == self.env['baremetal_executable_ext']:\n                    self.zip_files.append(path)\n\n    def teardown(self):\n        os.makedirs(self.env['release_dir'], exist_ok=True)\n        self.sh.rmrf(self.env['release_zip_file'])\n        self.log_info('Creating zip: ' + self.env['release_zip_file'])\n        with zipfile.ZipFile(self.env['release_zip_file'], 'w', zipfile.ZIP_DEFLATED) as zipf:\n            for zip_file in self.zip_files:\n                self.log_info('Adding file: ' + zip_file)\n                zipf.write(zip_file, arcname=os.path.relpath(zip_file, self.env['root_dir']))\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.185546875,
          "content": "Cython==0.29.15\nchina-dictatorship @ https://github.com/cirosantilli/china-dictatorship/releases/download/0.0.74/china_dictatorship-0.0.74-py3-none-any.whl\npexpect==4.6.0\nsetuptools==75.1.0\n"
        },
        {
          "name": "rootfs-post-build-script",
          "type": "blob",
          "size": 1.037109375,
          "content": "#!/usr/bin/env bash\n# This is run as part of:\n#      make target-finalize\n# which gets called by the default target.\ntarget_dir=\"$1\"\n# /dev/* entries were taken out of BusyBox inittab,\n# no need to do that on every boot, right?\nmkdir -p \\\n  \"${target_dir}/mnt/9p/data\" \\\n  \"${target_dir}/mnt/9p/out\" \\\n  \"${target_dir}/mnt/9p/out_rootfs_overlay\" \\\n  \"${target_dir}/mnt/9p/rootfs_overlay\" \\\n  \"${target_dir}/mnt/overlay\" \\\n  \"${target_dir}/mnt/work\" \\\n  \"${target_dir}/mnt/upper\" \\\n  \"${target_dir}/dev/pts\" \\\n  \"${target_dir}/dev/shm\" \\\n;\n# Maybe there is a cleaner way to get rid of those files,\n# like disabling some Buildroot packages, but no patience.\n#\n# As of 2d5f95b1839986ca6d7b568296374a2403d2693d\n# xorg must be removed or else we get a black screen:\n# https://bugs.busybox.net/show_bug.cgi?id=11066\ninit_d=\"${target_dir}/etc/init.d\"\nrm -rf \\\n  \"${init_d}/S01logging\" \\\n  \"${init_d}/S01syslogd\" \\\n  \"${init_d}/S02klogd\" \\\n  \"${init_d}/S02sysctl\" \\\n  \"${init_d}/S20urandom\" \\\n  \"${init_d}/S40network\" \\\n  \"${init_d}/S40xorg\" \\\n  \"${init_d}/S50sshd\" \\\n;\n"
        },
        {
          "name": "rootfs_overlay",
          "type": "tree",
          "content": null
        },
        {
          "name": "run",
          "type": "blob",
          "size": 43.953125,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport re\nimport shlex\nimport shutil\nimport struct\nimport subprocess\nimport sys\nimport time\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nRun some content on an emulator.\n'''\n        )\n        self.add_argument(\n            '-c',\n            '--cpus',\n            default=1,\n            type=int,\n            help='Number of guest CPUs to emulate. Default: %(default)s'\n        )\n        self.add_argument(\n            '--ctrl-c-host',\n            default=False,\n            help='''\\\nCtrl + C kills the QEMU simulator instead of being passed to the guest.\n'''\n        )\n        self.add_argument(\n            '-D',\n            '--debug-vm',\n            default=False,\n            help='''\\\nRun GDB on the emulator itself.\nFor --emulator native, this debugs the target program.\nSee also: https://cirosantilli.com/linux-kernel-module-cheat#debug-the-emulator\n'''\n        )\n        self.add_argument(\n            '--debug-vm-args',\n            default='',\n            help='''\\\nPass arguments to GDB. Implies --debug-vm. If --debug-vm-rr is used,\npass the given arguments to GDB on the replay.\n'''\n        )\n        self.add_argument(\n            '--debug-vm-file',\n            help='''\\\nLike --debug-vm, but also source this file. Equivalent to\n--debug-vm-args='-ex \"source $file\"'.\n'''\n        )\n        self.add_argument(\n            '--debug-vm-ex',\n            default='',\n            help='''\\\nLike --debug-vm-args, but takes as argument a semicolon separated list of\n-ex commands.\n'''\n        )\n        self.add_argument(\n            '--debug-vm-rr',\n            default=False,\n            help='''\nRun the emulator through Mozilla RR, and then start replay with reverse debugging enabled:\nhttps://cirosantilli.com/linux-kernel-module-cheat#reverse-debug-the-emulator\n'''\n        )\n        self.add_argument(\n            '--dtb',\n            help='''\\\nUse the specified DTB file. If not given, let the emulator generate a DTB for us,\nwhich is what you usually want.\n'''\n        )\n        self.add_argument(\n            '-E',\n            '--eval',\n            help='''\\\nReplace the normal init with a minimal init that just evals the given sh string.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#replace-init\nchdir into lkmc_home before running the command:\nhttps://cirosantilli.com/linux-kernel-module-cheat#lkmc-home\n'''\n        )\n        self.add_argument(\n            '-F',\n            '--eval-after',\n            help='''\\\nSimilar to --eval, but the string gets evaled at the last init script,\nafter the normal init finished. After this string is evaled, you are left\ninside a shell. See: https://cirosantilli.com/linux-kernel-module-cheat#init-busybox\n'''\n        )\n        self.add_argument(\n            '-G',\n            '--gem5-exe-args',\n            default='',\n            help='''\\\nPass extra options to the gem5 executable.\nDo not confuse with the arguments passed to config scripts,\nlike `fs.py`. Example:\n./run --emulator gem5 --gem5-exe-args '--debug-flags=Exec --debug' -- --cpu-type=HPI --caches\nwill run:\ngem.op5 --debug-flags=Exec fs.py --cpu-type=HPI --caches\n'''\n        )\n        self.add_argument(\n            '--gdb',\n            default=False,\n            help='''\\\nShortcut for the most common GDB options that you want most of the time. Implies:\n* --gdb-wait\n* --tmux-args <main> where <main> is:\n** start_kernel in full system\n** main in user mode\n* --tmux-program gdb\n'''\n        )\n        self.add_argument(\n            '--gdb-wait',\n            default=False,\n            help='''\\\nWait for GDB to connect before starting execution\nSee: https://cirosantilli.com/linux-kernel-module-cheat#gdb\n'''\n        )\n        self.add_argument(\n            '--gem5-script',\n            default='fs',\n            choices=['fs', 'biglittle'],\n            help='''\\\nWhich gem5 script to use.\nSee e.g.: https://cirosantilli.com/linux-kernel-module-cheat#gem5-fs-biglittle\n'''\n        )\n        self.add_argument(\n            '--gem5-readfile',\n            default='',\n            help='''\\\nSet the contents of m5 readfile to this string.\nhttps://cirosantilli.com/linux-kernel-module-cheat#gem5-restore-new-script\n'''\n        )\n        self.add_argument(\n            '--gem5-restore',\n            type=int,\n            help='''\\\nRestore the nth most recently taken gem5 checkpoint according to directory\ntimestamps.\n'''\n        )\n        self.add_argument(\n            '--graphic',\n            default=False,\n            help='''\\\nRun in graphic mode.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#graphics\n'''\n        )\n        self.add_argument(\n            '--kdb',\n            default=False,\n            help='''\\\nSetup KDB kernel CLI options.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#kdb\n'''\n        )\n        self.add_argument(\n            '--kernel-cli',\n            help='''\\\nPass an extra Linux kernel command line options, and place them before\nthe dash separator `-`. Only options that come before the `-`, i.e.\n\"standard\" options, should be passed with this option.\nExample: `./run --arch arm --kernel-cli 'init=/lkmc/poweroff.out'`\nSee also: https://cirosantilli.com/linux-kernel-module-cheat#init-environment\n'''\n        )\n        self.add_argument(\n            '--kernel-cli-after-dash',\n            help='''\\\nPass an extra Linux kernel command line options, add a dash `-`\nseparator, and place the options after the dash. Intended for custom\noptions understood by our `init` scripts, most of which are prefixed\nby `lkmc_`.\nExample: `./run --kernel-cli-after-dash 'lkmc_eval=\"wget google.com\" lkmc_lala=y'`\nSee also: https://cirosantilli.com/linux-kernel-module-cheat#init-environment\n'''\n        )\n        self.add_argument(\n            '--kernel-version',\n            default=common.consts['linux_kernel_version'],\n            help='''\\\nPass a base64 encoded command line parameter that gets evalled at the end of\nthe normal init.\nSee: https://cirosantilli.com/linux-kernel-module-cheat#init-busybox\nchdir into lkmc_home before running the command:\nhttps://cirosantilli.com/linux-kernel-module-cheat#lkmc-home\nSpecify the Linux kernel version to be reported by syscall emulation.\nDefaults to the same kernel version as our default Buildroot build.\nCurrently only works for QEMU.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#fatal-kernel-too-old\n'''\n        )\n        self.add_argument(\n            '--kgdb',\n            default=False,\n            help='''\\\nSetup KGDB kernel CLI options.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#kgdb\n'''\n        )\n        self.add_argument(\n            '-K',\n            '--kvm',\n            default=False,\n            help='''\\\nUse KVM. Only works if guest arch == host arch.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#kvm\n'''\n        )\n        self.add_argument(\n            '-m',\n            '--memory',\n            default='256M',\n            help='''\\\nSet the memory size of the guest. E.g.: `--memory 512M`. We try to keep the default\nat the minimal ammount amount that boots all archs. Anything lower could lead\nsome arch to fail to boot.\nDefault: %(default)s\n'''\n        )\n        self.add_argument(\n            '--quit-after-boot',\n            default=False,\n            help='''\\\nSetup a kernel init parameter that makes the emulator quit immediately after boot.\n'''\n        )\n        self.add_argument(\n            '--replay',\n            default=False,\n            help='Replay a QEMU run record deterministically'\n        )\n        self.add_argument(\n            '--record',\n            default=False,\n            help='Record a QEMU run record for later replay with `-R`'\n        )\n        self.add_argument(\n            '--show-stdout',\n            default=True,\n            help='''Show emulator stdout and stderr on the host terminal.'''\n        )\n        self.add_argument(\n            '--stdin-file',\n            help='''\\\nSet the given file as the stdin source of the emulator. QEMU and gem5 then\nforward this to the guest in user mode simulation.\nhttps://cirosantilli.com/linux-kernel-module-cheat#syscall-emulation-mode-program-stdin\n'''\n        )\n        self.add_argument(\n            '--terminal',\n            default=False,\n            help='''\\\nOutput directly to the terminal, don't pipe to tee as the default.\nWith this, we don't not save the output to a file as is done by default,\nbut we are able to do things that require not having a pipe such as\nusing debuggers. This option is set automatically by --debug-vm, but you\nstill need it to debug gem5 Python scripts with pdb.\n'''\n        )\n        self.add_argument(\n            '-T',\n            '--trace',\n            help='''\\\nSet trace events to be enabled. If not given, gem5 tracing is completely\ndisabled, while QEMU tracing is enabled but uses default traces that are very\nrare and don't affect performance, because `./configure\n--enable-trace-backends=simple` seems to enable some traces by default, e.g.\n`pr_manager_run`, and I don't know how to get rid of them.\nSee: http://github.com/cirosantilli/linux-kernel-module-cheat#tracing\n'''\n        )\n        self.add_argument(\n            '--trace-stdout',\n            default=False,\n            help='''\\\nOutput trace to stdout instead of a file. Only works for gem5 currently.\n'''\n        )\n        self.add_argument(\n            '--trace-insts-stdout',\n            default=False,\n            help='''\\\nTrace instructions run to stdout. Shortcut for --trace --trace-stdout.\n'''\n        )\n        self.add_argument(\n            '-t',\n            '--tmux',\n            default=False,\n            help='''\\\nCreate a tmux split the window. You must already be inside of a `tmux` session\nto use this option:\n* on the main window, run the emulator as usual\n* on the split:\n** if on QEMU and `-d` is given, GDB\n** if on gem5, the gem5 terminal\nSee: https://cirosantilli.com/linux-kernel-module-cheat#tmux\n'''\n        )\n        self.add_argument(\n            '--tmux-args',\n            help='''\\\nParameters to pass to the program running on the tmux split. Implies --tmux.\n'''\n        )\n        self.add_argument(\n            '--tmux-program',\n            choices=('gdb', 'shell'),\n            help='''\\\nWhich program to run in tmux. Implies --tmux. Defaults:\n* 'gdb' in qemu\n* 'shell' in gem5. 'shell' is only supported in gem5 currently.\n'''\n        )\n        self.add_argument(\n            '--vnc',\n            default=False,\n            help='''\\\nRun QEMU with VNC instead of the default SDL. Connect to it with:\n`vinagre localhost:5900`.\n'''\n        )\n        self.add_argument(\n            'extra_emulator_args',\n            nargs='*',\n            default=[],\n            help='''\\\nExtra options to append at the end of the emulator command line.\n'''\n        )\n\n    def timed_main(self):\n        show_stdout = self.env['show_stdout']\n        # Common qemu / gem5 logic.\n        # nokaslr:\n        # * https://unix.stackexchange.com/questions/397939/turning-off-kaslr-to-debug-linux-kernel-using-qemu-and-gdb\n        # * https://stackoverflow.com/questions/44612822/unable-to-debug-kernel-with-qemu-gdb/49840927#49840927\n        #   Turned on by default since v4.12\n        kernel_cli = 'console_msg_format=syslog nokaslr norandmaps panic=-1 printk.devkmsg=on printk.time=y rw'\n        if self.env['kernel_cli'] is not None:\n            kernel_cli += ' {}'.format(self.env['kernel_cli'])\n        if self.env['quit_after_boot']:\n            kernel_cli += ' {}'.format(self.env['quit_init'])\n        kernel_cli_after_dash = ' lkmc_home={}'.format(self.env['guest_lkmc_home'])\n        extra_emulator_args = []\n        extra_qemu_args = []\n        if not self.env['_args_given']['tmux_program']:\n            if self.env['emulator'] == 'qemu':\n                self.env['tmux_program'] = 'gdb'\n            elif self.env['emulator'] == 'gem5':\n                self.env['tmux_program'] = 'shell'\n        if self.env['gdb']:\n            if not self.env['_args_given']['gdb_wait']:\n                self.env['gdb_wait'] = True\n            if not self.env['_args_given']['tmux_args']:\n                if not self.env['userland'] and not self.env['baremetal']:\n                    self.env['tmux_args'] = 'start_kernel'\n                else:\n                    self.env['tmux_args'] = 'main'\n            if not self.env['_args_given']['tmux_program']:\n                self.env['tmux_program'] = 'gdb'\n        if self.env['tmux_args'] is not None or self.env['_args_given']['tmux_program']:\n            self.env['tmux'] = True\n        if self.env['debug_vm_rr']:\n            debug_vm = ['rr', 'record']\n        elif self.env['debug_vm'] or self.env['debug_vm_args'] or self.env['debug_vm_file'] or self.env['debug_vm_ex']:\n            debug_vm = ['gdb', LF, '-q', LF] + self.sh.shlex_split(self.env['debug_vm_args'])\n            for cmd in self.env['debug_vm_ex'].split(';'):\n                debug_vm.extend(['-ex', cmd, LF]);\n            if self.env['debug_vm_file'] is not None:\n                debug_vm.extend(['-ex', 'source {}'.format(self.env['debug_vm_file']), LF])\n            debug_vm.extend(['--args', LF])\n        else:\n            debug_vm = []\n        if self.env['gdb_wait']:\n            extra_qemu_args.extend(['-S', LF])\n        if self.env['eval_after'] is not None:\n            kernel_cli_after_dash += ' lkmc_eval_base64=\"{}\"'.format(self.sh.base64_encode(self.env['eval_after']))\n        if self.env['kernel_cli_after_dash'] is not None:\n            kernel_cli_after_dash += ' {}'.format(self.env['kernel_cli_after_dash'])\n        if self.env['vnc']:\n            vnc = ['-vnc', ':0', LF]\n        else:\n            vnc = []\n        if self.env['eval'] is not None:\n            kernel_cli += ' {}=/lkmc/eval_base64.sh'.format(self.env['initarg'])\n            kernel_cli_after_dash += ' lkmc_eval=\"{}\"'.format(self.sh.base64_encode(self.env['eval']))\n        if not self.env['graphic']:\n            extra_qemu_args.extend(['-nographic', LF])\n        console = None\n        console_type = None\n        console_count = 0\n        if self.env['arch'] == 'x86_64':\n            console_type = 'ttyS'\n        elif self.env['is_arm']:\n            console_type = 'ttyAMA'\n        console = '{}{}'.format(console_type, console_count)\n        console_count += 1\n        if not (self.env['arch'] == 'x86_64' and self.env['graphic']):\n            kernel_cli += ' console={}'.format(console)\n        extra_console = '{}{}'.format(console_type, console_count)\n        console_count += 1\n        if self.env['kdb'] or self.env['kgdb']:\n            kernel_cli += ' kgdbwait'\n            if self.env['kdb']:\n                if self.env['graphic']:\n                    kdb_cmd = 'kbd,'\n                else:\n                    kdb_cmd = ''\n                kernel_cli += ' kgdboc={}{},115200'.format(kdb_cmd, console)\n            if self.env['kgdb']:\n                kernel_cli += ' kgdboc={},115200'.format(extra_console)\n        if kernel_cli_after_dash:\n            kernel_cli += \" -{}\".format(kernel_cli_after_dash)\n        extra_env = {}\n        if self.env['trace_insts_stdout']:\n            if self.env['emulator'] == 'qemu':\n                extra_emulator_args.extend(['-d', 'in_asm', LF])\n            elif self.env['emulator'] == 'gem5':\n                self.env['trace_stdout'] = True\n                self.env['trace'] = 'ExecAll'\n        if self.env['trace'] is None:\n            do_trace = False\n            # A dummy value that is already turned on by default and does not produce large output,\n            # just to prevent QEMU from emitting a warning that '' is not valid.\n            trace_type = 'load_file'\n        else:\n            do_trace = True\n            trace_type = self.env['trace']\n\n        def raise_rootfs_not_found():\n            if not self.env['dry_run']:\n                raise Exception('Root filesystem not found. Did you build it? ' \\\n                                'Tried to use: ' + self.env['disk_image'])\n        def raise_image_not_found():\n            if not self.env['dry_run']:\n                raise Exception('Executable image not found. Did you build it? ' \\\n                                'Tried to use: ' + self.env['image'])\n        cmd = debug_vm.copy()\n        if not os.path.exists(self.env['image']):\n            if self.env['emulator'] == 'gem5':\n                if (\n                    not self.env['baremetal'] and\n                    not self.env['userland']\n                ):\n                    # This is an attempte to run gem5 from a prebuilt download\n                    # but it is not working:\n                    # https://github.com/cirosantilli/linux-kernel-module-cheat/issues/79\n                    self.sh.check_output(\n                        [\n                            self.env['extract_vmlinux'],\n                            self.env['linux_image']\n                        ],\n                        out_file=self.env['image'],\n                        show_cmd=True,\n                        show_stdout=False\n                    )\n                else:\n                    raise_image_not_found()\n            else:\n                raise_image_not_found()\n        if self.env['baremetal']:\n            # Setup CLI arguments into a single raw binary file to be loaded into memory.\n            # The memory setup of that file is:\n            # argc\n            # argv[0] pointer\n            # argv[1] pointer\n            # ...\n            # argv[N] pointer\n            # argv[0][0] data\n            # argv[0][1] data\n            # ...\n            # argv[1][0] data\n            # argv[1][1] data\n            # ...\n            cli_args = [os.path.basename(self.env['image'])]\n            if self.env['cli_args'] is not None:\n                cli_args.extend(shlex.split(self.env['cli_args']))\n            argc_addr = self.env['entry_address'] + self.env['baremetal_max_text_size'] + self.env['baremetal_memory_size']\n            argv_addr = argc_addr + self.env['int_size']\n            argv_data_addr = argv_addr + len(cli_args) * self.env['address_size']\n            argv_addr_data = []\n            argv_addr_cur = argv_data_addr\n            for arg in cli_args:\n                argv_addr_data.append(struct.pack(\n                    '<{}'.format(\n                        self.python_struct_int_format(self.env['address_size'])\n                    ),\n                    argv_addr_cur\n                ))\n                argv_addr_cur += len(arg) + 1\n            baremetal_cli_path = os.path.join(self.env['run_dir'], 'baremetal_cli.raw')\n            if self.env['emulator'] == 'qemu':\n                self.make_run_dirs()\n            with open(baremetal_cli_path, 'wb') as f:\n                f.write(struct.pack('<{}'.format(self.python_struct_int_format(self.env['int_size'])), len(cli_args)))\n                f.write(b''.join(argv_addr_data))\n                f.write(b'\\0'.join(arg.encode() for arg in cli_args) + b'\\0')\n        use_disk_image = self.env['disk_image'] is not None and \\\n            os.path.exists(self.env['disk_image']) or \\\n            not self.env['baremetal']\n        if self.env['_args_given']['disk_image'] and not os.path.exists(self.env['disk_image']) :\n            raise_rootfs_not_found()\n        if self.env['emulator'] == 'gem5':\n            if self.env['quiet']:\n                show_stdout = False\n            if not self.env['baremetal'] and not self.env['userland']:\n                if not os.path.exists(self.env['rootfs_raw_file']):\n                    if not os.path.exists(self.env['qcow2_file']):\n                        raise_rootfs_not_found()\n                    self.raw_to_qcow2(qemu_which=self.env['qemu_which'], reverse=True)\n            os.makedirs(os.path.dirname(self.env['gem5_readfile_file']), exist_ok=True)\n            self.sh.write_string_to_file(self.env['gem5_readfile_file'], self.env['gem5_readfile'])\n            memory = '{}B'.format(self.env['memory'])\n            gem5_exe_args = self.sh.shlex_split(self.env['gem5_exe_args'])\n            if do_trace:\n                gem5_exe_args.extend(['--debug-flags', trace_type, LF])\n            # https://cirosantilli.com/linux-kernel-module-cheat#m5-override-py-source\n            extra_env['M5_OVERRIDE_PY_SOURCE'] = 'true'\n            if self.env['trace_stdout']:\n                debug_file = 'cout'\n            else:\n                debug_file = 'trace.txt'\n            cmd.extend(\n                [\n                    self.env['executable'], LF,\n                    '--debug-file', debug_file, LF,\n                    '--listener-mode', 'on', LF,\n                    '--outdir', self.env['m5out_dir'], LF,\n                ] +\n                gem5_exe_args\n            )\n            if self.env['gem5_restore'] is not None:\n                # https://cirosantilli.com/linux-kernel-module-cheat#gem5-checkpoint-internals\n                cpt_dirs = self.gem5_list_checkpoint_dirs()\n                cpt_dir = cpt_dirs[-self.env['gem5_restore']]\n                cpt_dirs_sorted_by_tick = sorted(cpt_dirs, key=lambda x: int(x.split('.')[1]))\n                extra_emulator_args.extend(['-r', str(cpt_dirs_sorted_by_tick.index(cpt_dir) + 1)])\n            if self.env['userland']:\n                cmd_opt = self.env['image']\n                for u in self.env['userland'][1:]:\n                    cmd_opt += ';' + self.resolve_userland_executable(u)\n                if len(self.env['userland']) > 1:\n                    workload_cpus = ':'\n                else:\n                    workload_cpus = '0'\n                cmd.extend([\n                    self.env['gem5_se_file'], LF,\n                    '--cmd', cmd_opt, LF,\n                    '--num-cpus', str(self.env['cpus']), LF,\n                    # We have to use cpu[0] here because on multi-cpu workloads,\n                    # cpu[1] and higher use workload as a proxy to cpu[0].workload.\n                    # as can be seen from the config.ini.\n                    # If system.cpu[:].workload[:] were used instead, we would get the error:\n                    # \"KeyError: 'workload'\"\n                    '--param', 'system.cpu[{}].workload[:].release = \"{}\"'.format(workload_cpus,self.env['kernel_version']), LF,\n                ])\n                if self.env['cli_args'] is not None:\n                    cmd.extend(['--options', self.env['cli_args'], LF])\n                if not self.env['static']:\n                    for path in self.env['userland_library_redirects']:\n                        cmd.extend([\n                            '--redirects',\n                            '{}={}'.format(\n                                os.sep + path,\n                                os.path.join(self.env['userland_library_dir'], path)\n                            ),\n                            LF\n                        ])\n                    cmd.extend(['--interp-dir', self.env['userland_library_dir'], LF])\n            else:\n                if self.env['is_arm']:\n                    arm_kernel_cli = 'earlycon=pl011,0x1c090000 earlyprintk=pl011,0x1c090000 lpj=19988480 rw loglevel=8 mem={}'.format(memory)\n                if self.env['gem5_script'] == 'fs':\n                    cmd.extend([\n                        self.env['gem5_fs_file'], LF,\n                        '--kernel', self.env['image'], LF,\n                        '--num-cpus', str(self.env['cpus']), LF,\n                        '--script', self.env['gem5_readfile_file'], LF,\n                    ])\n                    if use_disk_image:\n                        cmd.extend(['--disk-image', self.env['disk_image'], LF])\n                    if os.path.exists(self.env['disk_image_2']):\n                        cmd.extend(['--disk-image', self.env['disk_image_2'], LF])\n                    if self.env['baremetal']:\n                        cmd.extend([\n                            '--param', 'system.workload.extras = \"{}\"'.format(self.python_escape_double_quotes(baremetal_cli_path)), LF,\n                            '--param', 'system.workload.extras_addrs = {}'.format(hex(argc_addr)), LF,\n                        ])\n                    if self.env['arch'] == 'x86_64':\n                        if self.env['kvm']:\n                            cmd.extend(['--cpu-type', 'X86KvmCPU', LF])\n                        if not self.env['baremetal']:\n                            cmd.extend(['--command-line', 'earlycon={} earlyprintk={} lpj=7999923 root=/dev/sda {}'.format(console, console, kernel_cli), LF])\n                    elif self.env['is_arm']:\n                        if self.env['kvm']:\n                            cmd.extend(['--cpu-type', 'ArmV8KvmCPU', LF])\n                        if self.env['dp650']:\n                            dp650_cmd = 'dpu_'\n                        else:\n                            dp650_cmd = ''\n                        cmd.extend([\n                            '--machine-type', self.env['machine'], LF,\n                        ])\n                        if not self.env['baremetal']:\n                            cmd.extend([\n                                '--command-line',\n                                # TODO why is it mandatory to pass mem= here? Not true for QEMU.\n                                # Anything smaller than physical blows up as expected, but why can't it auto-detect the right value?\n                                'root=/dev/sda {} {}'.format(arm_kernel_cli, kernel_cli), LF\n                            ])\n                            cmd.extend(['--param', 'system.workload.panic_on_panic = True', LF])\n                        dtb = None\n                        if self.env['dtb'] is not None:\n                            dtb = self.env['dtb']\n                        elif self.env['dp650']:\n                            dtb = os.path.join(\n                                self.env['gem5_system_dir'],\n                                'arm',\n                                'dt',\n                                'armv{}_gem5_v1_{}{}cpu.dtb'.format(\n                                    self.env['armv'],\n                                    dp650_cmd,\n                                    self.env['cpus']\n                                )\n                            )\n                        if dtb is not None:\n                            cmd.extend(['--dtb-filename', dtb, LF])\n                        if self.env['baremetal']:\n                            cmd.extend([\n                                '--bare-metal', LF,\n                                '--param', 'system.auto_reset_addr = True', LF,\n                            ])\n                            if self.env['arch'] == 'aarch64':\n                                # https://stackoverflow.com/questions/43682311/uart-communication-in-gem5-with-arm-bare-metal/50983650#50983650\n                                cmd.extend(['--param', 'system.highest_el_is_64 = True', LF])\n                elif self.env['gem5_script'] == 'biglittle':\n                    if self.env['kvm']:\n                        cpu_type = 'kvm'\n                    else:\n                        cpu_type = 'atomic'\n                    if self.env['gem5_restore'] is not None:\n                        cpt_dir = self.gem5_list_checkpoint_dirs()[-self.env['gem5_restore']]\n                        extra_emulator_args.extend(['--restore-from', os.path.join(self.env['m5out_dir'], cpt_dir), LF])\n                    cmd.extend([\n                        os.path.join(\n                            self.env['gem5_source_dir'],\n                            'configs',\n                            'example',\n                            'arm',\n                            'fs_bigLITTLE.py'\n                        ), LF,\n                        '--bootscript', self.env['gem5_readfile_file'], LF,\n                        '--big-cpus', str((self.env['cpus'] + 1) // 2), LF,\n                        '--cpu-type', cpu_type, LF,\n                        '--kernel', self.env['image'], LF,\n                        '--kernel-cmd', 'root=/dev/vda {} {}'.format(arm_kernel_cli, kernel_cli), LF,\n                        '--little-cpus', str(self.env['cpus'] // 2), LF,\n                    ])\n                    if use_disk_image:\n                        cmd.extend(['--disk', self.env['disk_image'], LF])\n                    if os.path.exists(self.env['disk_image_2']):\n                        cmd.extend(['--disk', self.env['disk_image_2'], LF])\n                    if self.env['dtb']:\n                        cmd.extend([\n                            '--dtb',\n                            os.path.join(self.env['gem5_system_dir'],\n                                'arm',\n                                'dt',\n                                'armv8_gem5_v1_big_little_2_2.dtb'\n                            ),\n                            LF\n                        ])\n                if self.env['gem5_script'] == 'fs' or self.env['gem5_script'] == 'biglittle':\n                    if self.env['gem5_bootloader'] is not None:\n                        cmd.extend(['--bootloader', self.env['gem5_bootloader'], LF])\n            cmd.extend(['--mem-size', memory, LF])\n            if self.env['gdb_wait']:\n                # https://stackoverflow.com/questions/49296092/how-to-make-gem5-wait-for-gdb-to-connect-to-reliably-break-at-start-kernel-of-th\n                cmd.extend(['--param', 'system.cpu[0].wait_for_remote_gdb = True', LF])\n        elif self.env['emulator'] == 'qemu':\n            qemu_user_and_system_options = [\n                '-trace', 'enable={},file={}'.format(trace_type, self.env['qemu_trace_file']), LF,\n            ]\n            if self.env['userland']:\n                if self.env['gdb_wait']:\n                    debug_args = ['-g', str(self.env['gdb_port']), LF]\n                else:\n                    debug_args = []\n                cmd.extend(\n                    [\n                        self.env['qemu_executable'], LF,\n                        '-L', self.env['userland_library_dir'], LF,\n                        '-r', self.env['kernel_version'], LF,\n                        '-seed', '0', LF,\n                    ] +\n                    qemu_user_and_system_options +\n                    debug_args\n                )\n                cpu = 'max'\n            else:\n                extra_emulator_args.extend(extra_qemu_args)\n                if debug_vm:\n                    serial_monitor = []\n                else:\n                    if self.env['background']:\n                        serial_monitor = ['-serial', 'file:{}'.format(self.env['guest_terminal_file']), LF]\n                        if self.env['quiet']:\n                            show_stdout = False\n                    else:\n                        if self.env['ctrl_c_host']:\n                            serial = 'stdio'\n                        else:\n                            serial = 'mon:stdio'\n                        serial_monitor = ['-serial', serial, LF]\n                if self.env['kvm']:\n                    extra_emulator_args.extend([\n                        '-enable-kvm', LF,\n                    ])\n                    cpu = 'host'\n                else:\n                    cpu = 'max'\n                extra_emulator_args.extend([\n                    '-serial',\n                    'tcp::{},server,nowait'.format(self.env['extra_serial_port']), LF\n                ])\n                virtfs_data = [\n                    (self.env['p9_dir'], 'host_data'),\n                    (self.env['out_dir'], 'host_out'),\n                    (self.env['out_rootfs_overlay_dir'], 'host_out_rootfs_overlay'),\n                    (self.env['rootfs_overlay_dir'], 'host_rootfs_overlay'),\n                ]\n                virtfs_cmd = []\n                for virtfs_dir, virtfs_tag in virtfs_data:\n                    if os.path.exists(virtfs_dir):\n                        virtfs_cmd.extend([\n                            '-virtfs',\n                            'local,path={virtfs_dir},mount_tag={virtfs_tag},security_model=mapped,id={virtfs_tag}' \\\n                                .format(virtfs_dir=virtfs_dir, virtfs_tag=virtfs_tag),\n                            LF,\n                        ])\n                machines = [self.env['machine']]\n                if self.env['arch'] == 'arm':\n                    # Needed since v3.0.0 due to:\n                    # http://lists.nongnu.org/archive/html/qemu-discuss/2018-08/msg00034.html\n                    machines.append('highmem=off')\n                if self.env['is_arm'] and self.env['kvm']:\n                    # Otherwise \"PMU: KVM_SET_DEVICE_ATTR: Invalid argument\"\n                    # https://bugzilla.redhat.com/show_bug.cgi?format=multiple&id=1661976\n                    machines.append('gic-version=host')\n                machines_cli = []\n                for machine in machines:\n                    machines_cli.extend(['-machine', machine, LF])\n                cmd.extend(\n                    [\n                        self.env['qemu_executable'], LF,\n                    ] +\n                    machines_cli +\n                    [\n                        '-device', 'rtl8139,netdev=net0', LF,\n                        '-gdb', 'tcp::{}'.format(self.env['gdb_port']), LF,\n                        '-kernel', self.env['image'], LF,\n                        '-m', self.env['memory'], LF,\n                        '-monitor', 'telnet::{},server,nowait'.format(self.env['qemu_monitor_port']), LF,\n                        '-netdev', 'user,hostfwd=tcp::{}-:{},hostfwd=tcp::{}-:22,id=net0'.format(\n                            self.env['qemu_hostfwd_generic_port'],\n                            self.env['qemu_hostfwd_generic_port'],\n                            self.env['qemu_hostfwd_ssh_port']\n                        ), LF,\n                        '-no-reboot', LF,\n                        '-smp', str(self.env['cpus']), LF,\n                    ] +\n                    virtfs_cmd +\n                    serial_monitor +\n                    vnc\n                )\n                if self.env['dtb'] is not None:\n                    cmd.extend(['-dtb', self.env['dtb'], LF])\n                if self.env['baremetal']:\n                    cmd.extend([\n                        '-device', 'loader,addr={},file={},force-raw=on'.format(\n                            hex(argc_addr),\n                            baremetal_cli_path,\n                        ), LF,\n                    ])\n                if not self.env['qemu_which'] == 'host':\n                    cmd.extend(qemu_user_and_system_options)\n                if self.env['initrd']:\n                    extra_emulator_args.extend(['-initrd', self.env['buildroot_cpio'], LF])\n                rr = self.env['record'] or self.env['replay']\n                if self.env['ramfs']:\n                    # TODO why is this needed, and why any string works.\n                    root = 'root=/dev/anything'\n                else:\n                    if rr:\n                        driveif = 'none'\n                        rrid = ',id=img-direct'\n                        rrid2 = ',id=img-direct2'\n                        if self.env['is_arm']:\n                            root = 'root=/dev/vda'\n                        else:\n                            root = 'root=/dev/sda'\n                        snapshot = ',snapshot'\n                        if self.env['is_arm']:\n                            hd_dev = 'virtio-blk-device'\n                        else:\n                            hd_dev = 'ide-hd'\n                    else:\n                        driveif = 'virtio'\n                        root = 'root=/dev/vda'\n                        rrid = ''\n                        rrid2 = ''\n                        snapshot = ',snapshot'\n                    if not self.env['baremetal']:\n                        if not os.path.exists(self.env['qcow2_file']):\n                            if not os.path.exists(self.env['rootfs_raw_file']):\n                                raise_rootfs_not_found()\n                            self.raw_to_qcow2(qemu_which=self.env['qemu_which'])\n                    if use_disk_image:\n                        if os.path.splitext(self.env['disk_image'])[1] == '.qcow2':\n                            disk_format = 'qcow2'\n                        else:\n                            disk_format = 'raw'\n                        extra_emulator_args.extend([\n                            '-drive',\n                            'file={},format={},if={}{}{}'.format(\n                                self.env['disk_image'],\n                                disk_format,\n                                driveif,\n                                snapshot,\n                                rrid\n                            ),\n                            LF,\n                        ])\n                        if rr:\n                            extra_emulator_args.extend([\n                            '-drive', 'driver=blkreplay,if=none,image=img-direct,id=img-blkreplay', LF,\n                            '-device', '{},drive=img-blkreplay'.format(hd_dev), LF,\n                        ])\n                    if os.path.exists(self.env['disk_image_2']):\n                        extra_emulator_args.extend([\n                            '-drive',\n                            'file={},format={},if={}{}{}'.format(\n                                self.env['disk_image_2'],\n                                'raw',\n                                driveif,\n                                snapshot,\n                                rrid2\n                            ),\n                            LF,\n                        ])\n                        if rr:\n                            extra_emulator_args.extend([\n                            '-drive', 'driver=blkreplay,if=none,image=img-direct2,id=img-blkreplay', LF,\n                            '-device', '{},drive=img-blkreplay2'.format(hd_dev), LF,\n                        ])\n                if rr:\n                    extra_emulator_args.extend([\n                        '-object', 'filter-replay,id=replay,netdev=net0', LF,\n                        '-icount', 'shift=7,rr={},rrfile={}'.format(\n                            'record' if self.env['record'] else 'replay',\n                            self.env['qemu_rrfile']\n                        ), LF,\n                    ])\n                    virtio_gpu_pci = []\n                else:\n                    virtio_gpu_pci = ['-device', 'virtio-gpu-pci', LF]\n                if self.env['arch'] == 'x86_64':\n                    append = ['-append', '{} nopat {}'.format(root, kernel_cli), LF]\n                    cmd.extend([\n                        '-device', 'edu', LF,\n                    ])\n                elif self.env['is_arm']:\n                    extra_emulator_args.extend(['-semihosting', LF])\n                    append = ['-append', '{} {}'.format(root, kernel_cli), LF]\n                    cmd.extend(\n                        virtio_gpu_pci\n                    )\n                if not self.env['baremetal']:\n                    cmd.extend(append)\n            extra_emulator_args.extend([\n                '-cpu', cpu, LF,\n            ])\n        if self.env['tmux']:\n            tmux_args = \"--gem5-build-id '{}' --run-id {}\".format(\n                self.env['gem5_build_id'],\n                self.env['run_id']\n            )\n            if self.env['tmux_program'] == 'shell':\n                if self.env['emulator'] == 'gem5':\n                    tmux_cmd = os.path.join(self.env['root_dir'], 'gem5-shell')\n                else:\n                    raise Exception('--tmux-program is only supported in gem5 currently.')\n            elif self.env['tmux_program'] == 'gdb':\n                tmux_cmd = os.path.join(self.env['root_dir'], 'run-gdb')\n                # TODO find a nicer way to forward all those args automatically.\n                # Part of me wants to: https://github.com/jonathanslenders/pymux\n                # but it cannot be used as a library properly it seems, and it is\n                # slower than tmux.\n                tmux_args += \" --arch {} --emulator '{}' --gcc-which '{}' --linux-build-id '{}' --userland-build-id '{}'\".format(\n                    self.env['arch'],\n                    self.env['emulator'],\n                    self.env['gcc_which'],\n                    self.env['linux_build_id'],\n                    self.env['userland_build_id'],\n                )\n                if self.env['baremetal']:\n                    tmux_args += \" --baremetal '{}'\".format(self.env['baremetal'][0])\n                if self.env['userland']:\n                    tmux_args += \" --userland '{}'\".format(self.env['userland'][0])\n                if self.env['in_tree']:\n                    tmux_args += ' --in-tree'\n            if self.env['tmux_args'] is not None:\n                tmux_args += ' {}'.format(self.env['tmux_args'])\n            tmux_cmd = [\n                os.path.join(self.env['root_dir'], 'tmux-split'),\n                \"sleep 2;{} {}\".format(tmux_cmd, tmux_args)\n            ]\n            self.log_info(self.sh.cmd_to_string(tmux_cmd))\n            subprocess.Popen(tmux_cmd)\n        cmd.extend(extra_emulator_args)\n        cmd.extend(self.env['extra_emulator_args'])\n        if self.env['userland'] and self.env['emulator'] in ('qemu', 'native'):\n            if len(self.env['userland']) > 1:\n                raise Exception('qemu and native machines only support a single executable')\n            # The program and arguments must come at the every end of the CLI.\n            cmd.extend([self.env['image'], LF])\n            if self.env['cli_args'] is not None:\n                cmd.extend(self.sh.shlex_split(self.env['cli_args']))\n        if debug_vm or self.env['terminal']:\n            out_file = None\n        else:\n            out_file = self.env['termout_file']\n        exit_status = self.sh.run_cmd(\n            cmd,\n            cmd_files=[self.env['run_cmd_file'], os.path.join(self.env['out_dir'], self.env['run_cmd_file_basename'])],\n            extra_env=extra_env,\n            out_file=out_file,\n            raise_on_failure=False,\n            show_stdout=show_stdout,\n            stdin_path=self.env['stdin_file'],\n        )\n        if self.env['debug_vm_rr']:\n            rr_cmd = ['rr', 'replay', LF, '-o', '-q', LF]\n            for arg in shlex.split(self.env['debug_vm_args']):\n                rr_cmd.extend(['-o', arg, LF]);\n            exit_status = self.sh.run_cmd(\n                rr_cmd,\n                raise_on_failure=False,\n                show_stdout=show_stdout,\n            )\n        if exit_status == 0:\n            error_string_found = False\n            exit_status = 0\n            if out_file is not None and not self.env['dry_run']:\n                if self.env['emulator'] == 'gem5':\n                    with open(self.env['termout_file'], 'br') as logfile:\n                        # We have to do some parsing here because gem5 exits with status 0 even when panic happens.\n                        # Grepping for '^panic: ' does not work because some errors don't show that message...\n                        gem5_panic_re = re.compile(b'--- BEGIN LIBC BACKTRACE ---$')\n                        line = None\n                        for line in logfile:\n                            line = line.rstrip()\n                            if gem5_panic_re.search(line):\n                                exit_status = 1\n                        last_line = line\n                        if last_line is not None:\n                            if self.env['userland']:\n                                match = re.search(b'Simulated exit code not 0! Exit code is (\\d+)', last_line)\n                                if match is not None:\n                                    exit_status = int(match.group(1))\n                            if re.search(b'Exiting @ tick \\d+ because simulate\\(\\) limit reached', last_line) is not None:\n                                exit_status = 1\n                if not self.env['userland']:\n                    if os.path.exists(self.env['guest_terminal_file']):\n                        with open(self.env['guest_terminal_file'], 'br') as logfile:\n                            linux_panic_re = re.compile(b'Kernel panic - not syncing')\n                            serial_magic_exit_status_regexp = re.compile(self.env['serial_magic_exit_status_regexp_string'])\n                            for line in logfile.readlines():\n                                line = line.rstrip()\n                                if not self.env['baremetal'] and linux_panic_re.search(line):\n                                    exit_status = 1\n                                match = serial_magic_exit_status_regexp.match(line)\n                                if match:\n                                    exit_status = int(match.group(1))\n            if exit_status != 0 and self.env['show_stdout']:\n                self.log_error('simulation error detected by parsing logs')\n        return exit_status\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "run-android",
          "type": "blob",
          "size": 0.7255859375,
          "content": "#!/usr/bin/env python3\n\nimport shutil\n\nimport common\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nRun android AOSP on the AOSP pre-build emulator.\n\nhttps://cirosantilli.com/linux-kernel-module-cheat#android\n''',\n        )\n        self.add_argument('extra-emulator-args', default='', nargs='?')\n\n    def timed_main(self):\n            self.sh.run_cmd('{}emulator -show-kernel -verbose {}'.format(\n                self.env['android_shell_setup'],\n                self.env['extra_emulator_args']\n            ),\n            cwd=self.env['android_dir'],\n            executable=shutil.which('bash'),\n            shell=True,\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "run-docker",
          "type": "blob",
          "size": 2.0478515625,
          "content": "#!/usr/bin/env python3\n\nimport argparse\nimport os\nimport sys\n\nimport common\nimport shell_helpers\nfrom shell_helpers import LF\n\ncontainer_name = common.consts['repo_short_id']\ncontainer_hostname = common.consts['repo_short_id']\nimage_name = common.consts['repo_short_id']\ntarget_dir = '/root/{}'.format(common.consts['repo_short_id'])\ndocker = ['sudo', 'docker']\ndef create(args):\n    sh.run_cmd(docker + ['build', '-t', image_name, '.', LF])\n    # --privileged for KVM:\n    # https://stackoverflow.com/questions/48422001/launching-qemu-kvm-from-inside-docker-container\n    sh.run_cmd(\n        docker +\n        [\n            'create', LF,\n            '--hostname', container_hostname, LF,\n            '-i', LF,\n            '--name', container_name, LF,\n            '--net', 'host', LF,\n            '--privileged', LF,\n            '-t', LF,\n            '-w', target_dir, LF,\n            '-v', '{}:{}'.format(os.getcwd(), target_dir), LF,\n            image_name,\n        ]\n    )\ndef destroy(args):\n    stop(args)\n    sh.run_cmd(docker + ['rm', container_name, LF])\n    sh.run_cmd(docker + ['rmi', image_name, LF])\ndef sh_func(args):\n    start(args)\n    if args:\n        sh_args = args\n    else:\n        sh_args = ['bash']\n    exit_status = sh.run_cmd(\n        docker + ['exec', '-i', '-t', container_name] +\n        sh_args +\n        [LF],\n        raise_on_failure=False\n    )\n    sys.exit(exit_status)\ndef start(args):\n    sh.run_cmd(docker + ['start', container_name, LF])\ndef stop(args):\n    sh.run_cmd(docker + ['stop', container_name, LF])\ncmd_action_map = {\n    'create': lambda args: create(args),\n    'DESTROY': lambda args: destroy(args),\n    'sh': lambda args: sh_func(args),\n    'start': lambda args: start(args),\n    'stop': lambda args: stop(args),\n}\nparser = argparse.ArgumentParser()\nparser.add_argument('--dry-run', default=False, action='store_true')\nparser.add_argument('cmd', choices=cmd_action_map, default='sh', nargs='?')\nparser.add_argument('args', nargs='*')\nargs = parser.parse_args()\nsh = shell_helpers.ShellHelpers(dry_run=args.dry_run)\ncmd_action_map[args.cmd](args.args)\n"
        },
        {
          "name": "run-gdb",
          "type": "blob",
          "size": 8.8291015625,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport signal\nimport subprocess\nimport sys\n\nfrom shell_helpers import LF\nimport common\nimport lkmc.import_path\nimport thread_pool\n\nclass GdbTestcase:\n    def __init__(\n        self,\n        source_path,\n        test_script_path,\n        cmd,\n        verbose=False\n    ):\n        '''\n        :param verbose: if True, print extra debug information to help understand\n                    why a test is not working\n        '''\n        self.prompt = '\\(gdb\\) '\n        self.source_path = source_path\n        import pexpect\n        self.child = pexpect.spawn(\n            cmd[0],\n            cmd[1:],\n            encoding='utf-8'\n        )\n        if verbose:\n            self.child.logfile = sys.stdout\n        self.child.setecho(False)\n        self.child.waitnoecho()\n        self.child.expect(self.prompt)\n        test = lkmc.import_path.import_path(test_script_path)\n        exception = None\n        try:\n            test.test(self)\n        except Exception as e:\n            exception = e\n        self.child.sendcontrol('d')\n        self.child.close()\n        self.exception = exception\n\n    def before(self):\n        return self.child.before.rstrip()\n\n    def continue_to(self, lineid):\n        line_number = self.find_line(lineid)\n        self.sendline('tbreak {}'.format(line_number))\n        self.sendline('continue')\n\n    def get_int(self, int_id):\n        self.sendline('printf \"%d\\\\n\", {}'.format(int_id))\n        return int(self.before())\n\n    def get_float(self, float_id):\n        self.sendline('printf \"%f\\\\n\", {}'.format(float_id))\n        return float(self.before())\n\n    def find_line(self, lineid):\n        '''\n        Search for the first line that contains a comment line\n        that ends in /* test-gdb-<lineid> */ and return the line number.\n        '''\n        lineend = '/* test-gdb-' + lineid + ' */'\n        with open(self.source_path, 'r') as f:\n            for i, line in enumerate(f):\n                if line.rstrip().endswith(lineend):\n                    return i + 1\n        return -1\n\n    def sendline(self, line):\n        self.child.sendline(line)\n        self.child.expect(self.prompt)\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(description='''\\\nConnect with GDB to an emulator to debug Linux itself\n''')\n        self.add_argument(\n            '--after',\n            default='',\n            help='''Pass extra arguments to GDB, to be appended after all other arguments.'''\n        )\n        self.add_argument(\n            '--before',\n            default='',\n            help='''Pass extra arguments to GDB to be prepended before any of the arguments passed by this script.'''\n        )\n        self.add_argument(\n            '--continue',\n            default=True,\n            help='''\\\nRun `continue` in GDB after connecting.\n* https://cirosantilli.com/linux-kernel-module-cheat#gdb-step-debug-early-boot\n* https://cirosantilli.com/linux-kernel-module-cheat#freestanding-programs\n* https://cirosantilli.com/linux-kernel-module-cheat#baremetal-gdb-step-debug\n'''\n        )\n        self.add_argument(\n            '--gdbserver',\n            default=False,\n            help='''https://cirosantilli.com/linux-kernel-module-cheat#gdbserver'''\n        )\n        self.add_argument(\n            '--kgdb',\n            default=False,\n            help='''https://cirosantilli.com/linux-kernel-module-cheat#kgdb'''\n        )\n        self.add_argument(\n            '--lxsymbols',\n            default=True,\n            help='''\\\nUse the Linux kernel lxsymbols GDB script.\nOnly enabled by default when debugging the Linux kernel, not on userland or baremetal.\n* https://cirosantilli.com/linux-kernel-module-cheat#gdb-step-debug-kernel-module\n* https://cirosantilli.com/linux-kernel-module-cheat#bypass-lx-symbols\n'''\n        )\n        self.add_argument(\n            '--sim',\n            default=False,\n            help='''\\\nUse the built-in GDB CPU simulator.\nhttps://cirosantilli.com/linux-kernel-module-cheat#gdb-builtin-cpu-simulator\n'''\n        )\n        self.add_argument(\n            '--test',\n            default=False,\n            help='''\\\nRun an expect test case instead of interactive usage. For baremetal and userland,\nthe script is a .py file next to the source code.\n'''\n        )\n        self.add_argument(\n            'break_at',\n            nargs='?',\n            help='''\\\nIf given, break at the given expression, e.g. `main`. You will be left there automatically\nby default due to --continue if this breakpoint is reached.\n'''\n        )\n\n    def timed_main(self):\n        after = self.sh.shlex_split(self.env['after'])\n        before = self.sh.shlex_split(self.env['before'])\n        no_continue = not self.env['continue']\n        if self.env['test']:\n            no_continue = True\n            before.extend([\n                '-q', LF,\n                '-nh', LF,\n                '-ex', 'set confirm off', LF\n            ])\n        elif self.env['verbose']:\n            # The output of this would affect the tests.\n            # https://stackoverflow.com/questions/13496389/gdb-remote-protocol-how-to-analyse-packets\n            # Also be opinionated and set remotetimeout to allow you to step debug the emulator at the same time.\n            before.extend([\n                '-ex', 'set debug remote 1', LF,\n                '-ex', 'set remotetimeout 99999', LF,\n            ])\n        if self.env['break_at'] is not None:\n            break_at = ['-ex', 'break {}'.format(self.env['break_at']), LF]\n        else:\n            break_at = []\n        if self.env['userland']:\n            linux_full_system = False\n            if self.env['gdbserver']:\n                before.extend([\n                    '-ex', 'set sysroot {}'.format(self.env['buildroot_staging_dir']),\n                ])\n        elif self.env['baremetal']:\n            linux_full_system = False\n        else:\n            linux_full_system = True\n        cmd = (\n            [self.env['gdb_path'], LF] +\n            before\n        )\n        if linux_full_system:\n            cmd.extend(['-ex', 'add-auto-load-safe-path {}'.format(self.env['linux_build_dir']), LF])\n        if self.env['sim']:\n            target = 'sim'\n        else:\n            if self.env['gdbserver']:\n                port = self.env['qemu_hostfwd_generic_port']\n            elif self.env['kgdb']:\n                port = self.env['extra_serial_port']\n            else:\n                port = self.env['gdb_port']\n            target = 'remote localhost:{}'.format(port)\n        cmd.extend([\n            '-ex', 'file {}'.format(self.env['image_elf']), LF,\n            '-ex', 'target {}'.format(target), LF,\n        ])\n        if not self.env['kgdb']:\n            cmd.extend(break_at)\n        if not no_continue:\n            # ## lx-symbols\n            #\n            # ### lx-symbols after continue\n            #\n            # lx symbols must be run after continue.\n            #\n            # running it immediately after the connect on the bootloader leads to failure,\n            # likely because kernel structure on which it depends are not yet available.\n            #\n            # With this setup, continue runs, and lx-symbols only runs when a break happens,\n            # either by hitting the breakpoint, or by entering Ctrl + C.\n            #\n            # Sure, if the user sets a break on a raw address of the bootloader,\n            # problems will still arise, but let's think about that some other time.\n            #\n            # ### lx-symbols autoload\n            #\n            # The lx-symbols commands gets loaded through the file vmlinux-gdb.py\n            # which gets put on the kernel build root when python debugging scripts are enabled.\n            cmd.extend(['-ex', 'continue', LF])\n            if self.env['lxsymbols'] and linux_full_system:\n                cmd.extend(['-ex', 'lx-symbols {}'.format(self.env['kernel_modules_build_subdir']), LF])\n        cmd.extend(after)\n        if self.env['test']:\n            self.sh.print_cmd(cmd)\n            if not self.env['dry_run']:\n                exception = GdbTestcase(\n                    self.env['source_path'],\n                    os.path.splitext(self.env['source_path'])[0] + '.py',\n                    self.sh.strip_newlines(cmd),\n                    verbose=self.env['verbose'],\n                ).exception\n                if exception is None:\n                    exit_status = 0\n                else:\n                    exit_status = 1\n                    self.log_info(thread_pool.ThreadPool.exception_traceback_string(exception))\n                return exit_status\n        else:\n            # I would rather have cwd be out_rootfs_overlay_dir,\n            # but then lx-symbols cannot fine the vmlinux and fails with:\n            # vmlinux: No such file or directory.\n            return self.sh.run_cmd(\n                cmd,\n                cmd_file=os.path.join(self.env['run_dir'], 'run-gdb.sh'),\n                cwd=self.env['linux_build_dir']\n            )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "run-toolchain",
          "type": "blob",
          "size": 1.322265625,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport common\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nManually run a ToolChain tool like gcc, readelf or objdump.\nhttps://cirosantilli.com/linux-kernel-module-cheat#run-toolchain\n''',\n        )\n        self.add_argument(\n            '--print-tool',\n            default=False,\n            help='''\nJust output print tool path to stdout but don't actually run it.\nSuitable for programmatic consumption by other shell programs.\n''',\n        )\n        self.add_argument('tool', help='Which tool to run.')\n        self.add_argument(\n            'extra_args',\n            default=[],\n            help='Extra arguments for the tool.',\n            metavar='extra-args',\n            nargs='*'\n        )\n\n    def timed_main(self):\n        tool = self.get_toolchain_tool(self.env['tool'])\n        if self.env['print_tool']:\n            print(tool)\n            return 0\n        else:\n            return self.sh.run_cmd(\n                [tool, LF]\n                + self.sh.add_newlines(self.env['extra_args']),\n                cmd_file=os.path.join(self.env['run_dir'], 'run-toolchain.sh'),\n            )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "setup",
          "type": "blob",
          "size": 0.5771484375,
          "content": "#!/usr/bin/env bash\n# Minimum requirements to run ./build --download-dependencies\nset -ex\nif [ $# -eq 1 ]; then\n  y=-y\nelse\n  y=\nfi\nindocker=\"$(set +e; grep -q docker /proc/1/cgroup; echo $?)\"\nif [ \"$indocker\" -eq 0 ]; then\n  sudo=\n  export DEBIAN_FRONTEND=noninteractive\nelse\n  sudo=sudo\nfi\nif [ \"$indocker\" -eq 0 ]; then\n  $sudo apt update\n  apt install -y software-properties-common\n  add-apt-repository -y ppa:git-core/ppa\n  $sudo apt update\n  git='git=1:2.*'\nelse\n  git=git\nfi\n$sudo apt-get install $y \\\n  $git \\\n  python3 \\\n  python3-pip \\\n;\npython3 -m pip install -r requirements.txt\n"
        },
        {
          "name": "shell_helpers.py",
          "type": "blob",
          "size": 19.693359375,
          "content": "#!/usr/bin/env python3\n\nimport base64\nimport distutils.file_util\nimport io\nimport itertools\nimport os\nimport shlex\nimport shutil\nimport signal\nimport stat\nimport subprocess\nimport sys\nimport threading\nfrom typing import List, Union\nimport urllib.request\n\nclass LF:\n    '''\n    LineFeed (AKA newline).\n\n    Singleton class. Can be used in print_cmd to print out nicer command lines\n    with --key on the same line as \"--key value\".\n    '''\n    pass\n\nclass ShellHelpers:\n    '''\n    Helpers to do things which are easy from the shell,\n    usually filesystem, process or pipe operations.\n\n    Attempt to print shell equivalents of all commands to make things\n    easy to debug and understand what is going on.\n    '''\n\n    _print_lock = threading.Lock()\n\n    def __init__(self, dry_run=False, quiet=False, force_oneline=False):\n        '''\n        :param dry_run: don't run the commands, just potentially print them. Debug aid.\n        :type dry_run: Bool\n\n        :param quiet: don't print the commands\n        :type dry_run: Bool\n        '''\n        self.dry_run = dry_run\n        self.force_oneline_default = force_oneline\n        self.quiet = quiet\n\n    @classmethod\n    def _print_thread_safe(cls, string):\n        '''\n        Python sucks: a naive print adds a bunch of random spaces to stdout,\n        and then copy pasting the command fails.\n        https://stackoverflow.com/questions/3029816/how-do-i-get-a-thread-safe-print-in-python-2-6\n        The initial use case was test-gdb which must create a thread for GDB to run the program in parallel.\n        '''\n        with cls._print_lock:\n            try:\n                print(string, flush=True)\n            except BrokenPipeError:\n                # https://stackoverflow.com/questions/26692284/how-to-prevent-brokenpipeerror-when-doing-a-flush-in-python\n                # https://stackoverflow.com/questions/16314321/suppressing-printout-of-exception-ignored-message-in-python-3\n                pass\n\n    def add_newlines(self, cmd):\n        out = []\n        for arg in cmd:\n            out.extend([arg, LF])\n        return out\n\n    def base64_encode(self, string):\n        '''\n        TODO deal with redirection and print nicely.\n        '''\n        return base64.b64encode(string.encode()).decode()\n\n    def base64_decode(self, string):\n        return base64.b64decode(string.encode()).decode()\n\n    def check_output(self, *args, **kwargs):\n        '''\n        Analogous to subprocess.check_output: get the stdout / stderr\n        of a program back as a byte array.\n        '''\n        out_str = []\n        actual_kwargs = {\n            'show_stdout': False,\n            'show_cmd': False\n        }\n        actual_kwargs.update(kwargs)\n        self.run_cmd(\n            *args,\n            out_str=out_str,\n            **actual_kwargs\n        )\n        return out_str[0]\n\n    def chmod(self, path, add_rm_abs='+', mode_delta=stat.S_IXUSR):\n        '''\n        TODO extend further, shell print equivalent.\n        '''\n        old_mode = os.stat(path).st_mode\n        if add_rm_abs == '+':\n            new_mode = old_mode | mode_delta\n        elif add_rm_abs == '':\n            new_mode = mode_delta\n        elif add_rm_abs == '-':\n            new_mode = old_mode & ~mode_delta\n        os.chmod(path, new_mode)\n\n    def force_oneline(self, force_oneline):\n        if force_oneline is not None:\n            return force_oneline\n        else:\n            return self.force_oneline_default\n\n    def cmd_to_string(\n        self,\n        cmd: List[Union[str, LF]],\n        cwd=None,\n        extra_env=None,\n        extra_paths=None,\n        force_oneline: Union[bool,None] =None,\n        *,\n        stdin_path: Union[str,None] =None\n    ):\n        '''\n        Format a command given as a list of strings so that it can\n        be viewed nicely and executed by bash directly and print it to stdout.\n\n        If cmd contains:\n\n        * no LF, then newlines are added after every word\n        * exactly one LF at the end, then no newlines are added\n        * otherwise: newlines are added exactly at each LF\n        '''\n        last_newline = ' \\\\\\n'\n        newline_separator = last_newline + '  '\n        out = []\n        if extra_env is None:\n            extra_env = {}\n        preffix_arr = []\n        if cwd is not None:\n            preffix_arr.append('cd {} &&'.format(shlex.quote(cwd)))\n        extra_env2 = extra_env.copy()\n        if extra_paths is not None:\n            extra_env2['PATH'] = '{}:\"${{PATH}}\"'.format(shlex.quote(':'.join(extra_paths)))\n        for key in extra_env2:\n            preffix_arr.append('{}={}'.format(shlex.quote(key), shlex.quote(extra_env2[key])))\n        cmd_quote = []\n        newline_count = 0\n        for arg in cmd:\n            if arg == LF:\n                if not self.force_oneline(force_oneline):\n                    cmd_quote.append(arg)\n                    newline_count += 1\n            else:\n                cmd_quote.append(shlex.quote(arg))\n        if self.force_oneline(force_oneline) or newline_count > 0:\n            cmd_quote = [\n                ' '.join(list(y))\n                for x, y in itertools.groupby(\n                    cmd_quote,\n                    lambda z: z == LF\n                )\n                if not x\n            ]\n        if self.force_oneline(force_oneline):\n            cmd_quote = [' '.join(preffix_arr + cmd_quote)]\n        else:\n            cmd_quote = preffix_arr + cmd_quote\n        out.extend(cmd_quote)\n        if stdin_path is not None:\n            out.append('< {}'.format(shlex.quote(stdin_path)))\n        if self.force_oneline(force_oneline) or newline_count == 1 and cmd[-1] == LF:\n            ending = ''\n        else:\n            ending = last_newline + ';'\n        return newline_separator.join(out) + ending\n\n    def copy_file_if_update(self, src, destfile):\n        if os.path.isdir(destfile):\n            destfile = os.path.join(destfile, os.path.basename(src))\n        self.mkdir_p(os.path.dirname(destfile))\n        if (\n            not os.path.exists(destfile) or \\\n            os.path.getmtime(src) > os.path.getmtime(destfile)\n        ):\n            self.cp(src, destfile)\n\n    def copy_dir_if_update_non_recursive(\n        self,\n        srcdir,\n        destdir,\n        filter_ext=None\n    ):\n        # TODO print rsync equivalent.\n        os.makedirs(destdir, exist_ok=True)\n        if not os.path.exists(srcdir) and self.dry_run:\n            basenames = []\n        else:\n            basenames = os.listdir(srcdir)\n        for basename in sorted(basenames):\n            src = os.path.join(srcdir, basename)\n            if os.path.isfile(src) or os.path.islink(src):\n                noext, ext = os.path.splitext(basename)\n                if (filter_ext is None or ext == filter_ext):\n                    dest = os.path.join(destdir, basename)\n                    self.copy_file_if_update(src, dest)\n\n    def copy_dir_if_update(\n        self,\n        srcdir,\n        destdir,\n        filter_ext=None\n    ):\n        self.copy_dir_if_update_non_recursive(srcdir, destdir, filter_ext)\n        srcdir_abs = os.path.abspath(srcdir)\n        srcdir_abs_len = len(srcdir_abs)\n        for path, dirnames, filenames in self.walk(srcdir_abs):\n            for dirname in dirnames:\n                dirpath = os.path.join(path, dirname)\n                dirpath_relative_root = dirpath[srcdir_abs_len + 1:]\n                self.copy_dir_if_update_non_recursive(\n                    dirpath,\n                    os.path.join(destdir, dirpath_relative_root),\n                    filter_ext\n                )\n\n    def cp(self, src, dest, **kwargs):\n        if not kwargs.get('quiet', False):\n            self.print_cmd(['cp', src, dest])\n        if not self.dry_run:\n            if os.path.islink(src):\n                if os.path.lexists(dest):\n                    os.unlink(dest)\n                linkto = os.readlink(src)\n                os.symlink(linkto, dest)\n            else:\n                shutil.copy2(src, dest)\n\n    def mkdir_p(self, d):\n        if not os.path.exists(d):\n            self.print_cmd(['mkdir', d, LF])\n            if not self.dry_run:\n                os.makedirs(d)\n\n    def mv(self, src, dest, **kwargs):\n        self.print_cmd(['mv', src, dest])\n        if not self.dry_run:\n            shutil.move(src, dest)\n\n    def print_cmd(\n        self,\n        cmd,\n        cwd=None,\n        cmd_file=None,\n        cmd_files=None,\n        extra_env=None,\n        extra_paths=None,\n        force_oneline: Union[bool,None] =None,\n        *,\n        stdin_path: Union[str,None] =None\n    ):\n        '''\n        Print cmd_to_string to stdout.\n\n        Optionally save the command to cmd_file file, and add extra_env\n        environment variables to the command generated.\n        '''\n        if type(cmd) is str:\n            cmd_string = cmd\n        else:\n            cmd_string = self.cmd_to_string(\n                cmd,\n                cwd=cwd,\n                extra_env=extra_env,\n                extra_paths=extra_paths,\n                force_oneline=force_oneline,\n                stdin_path=stdin_path\n            )\n        if not self.quiet:\n            self._print_thread_safe('+ ' + cmd_string)\n        if cmd_files is None:\n            cmd_files = []\n        if cmd_file is not None:\n            cmd_files.append(cmd_file)\n        for cmd_file in cmd_files:\n            os.makedirs(os.path.dirname(cmd_file), exist_ok=True)\n            with open(cmd_file, 'w') as f:\n                f.write('#!/usr/bin/env bash\\n')\n                f.write(cmd_string)\n            self.chmod(cmd_file)\n\n    def rmrf(self, path):\n        self.print_cmd(['rm', '-r', '-f', path, LF])\n        if not self.dry_run and os.path.exists(path):\n            if os.path.isdir(path):\n                shutil.rmtree(path)\n            else:\n                os.unlink(path)\n\n    def run_cmd(\n        self,\n        cmd,\n        cmd_file=None,\n        cmd_files=None,\n        out_file=None,\n        show_stdout=True,\n        show_cmd=True,\n        extra_env=None,\n        extra_paths=None,\n        delete_env=None,\n        raise_on_failure=True,\n        *,\n        out_str=None,\n        stdin_path: Union[str,None] =None,\n        **kwargs\n    ):\n        '''\n        Run a command. Write the command to stdout before running it.\n\n        Wait until the command finishes execution.\n\n        :param cmd: command to run. LF entries are magic get skipped.\n        :type cmd: List[str]\n\n        :param cmd_file: if not None, write the command to be run to that file\n        :type cmd_file: str\n\n        :param cmd_files: if not None, write the command to be run to all files in this list\n                          cmd_file gets appended to that list if given.\n        :type cmd_files: List[str]\n\n        :param out_file: if not None, write the stdout and stderr of the command the file\n        :type out_file: str\n\n        :param out_str: if not None, append the stdout and stderr string to this list\n        :type out_str: Union(List,None)\n\n        :param show_stdout: wether to show stdout and stderr on the terminal or not\n        :type show_stdout: bool\n\n        :param extra_env: extra environment variables to add when running the command\n        :type extra_env: Dict[str,str]\n\n        :return: exit status of the command\n        :rtype: int\n        '''\n        if out_file is None and out_str is None:\n            if show_stdout:\n                stdout = None\n                stderr = None\n            else:\n                stdout = subprocess.DEVNULL\n                stderr = subprocess.DEVNULL\n        else:\n            stdout = subprocess.PIPE\n            stderr = subprocess.STDOUT\n        if extra_env is None:\n            extra_env = {}\n        if delete_env is None:\n            delete_env = []\n        if 'cwd' in kwargs:\n            cwd = kwargs['cwd']\n        else:\n            cwd = None\n        env = os.environ.copy()\n        env.update(extra_env)\n        if extra_paths is not None:\n            path = ':'.join(extra_paths)\n            if 'PATH' in os.environ:\n                path += ':' + os.environ['PATH']\n            env['PATH'] = path\n        for key in delete_env:\n            if key in env:\n                del env[key]\n        if show_cmd:\n            self.print_cmd(\n                cmd,\n                cwd=cwd,\n                cmd_file=cmd_file,\n                cmd_files=cmd_files,\n                extra_env=extra_env,\n                extra_paths=extra_paths,\n                stdin_path=stdin_path\n            )\n\n        # Otherwise, if called from a non-main thread:\n        # ValueError: signal only works in main thread\n        if threading.current_thread() == threading.main_thread():\n            # Otherwise Ctrl + C gives:\n            # - ugly Python stack trace for gem5 (QEMU takes over terminal and is fine).\n            # - kills Python, and that then kills GDB:\n            #   https://stackoverflow.com/questions/19807134/does-python-always-raise-an-exception-if-you-do-ctrlc-when-a-subprocess-is-exec\n            sigint_old = signal.getsignal(signal.SIGINT)\n            signal.signal(signal.SIGINT, signal.SIG_IGN)\n\n            # Otherwise BrokenPipeError when piping through | grep\n            # But if I do this_module, my terminal gets broken at the end. Why, why, why.\n            # https://stackoverflow.com/questions/14207708/ioerror-errno-32-broken-pipe-python\n            # Ignoring the exception is not enough as it prints a warning anyways.\n            #sigpipe_old = signal.getsignal(signal.SIGPIPE)\n            #signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n\n        cmd = self.strip_newlines(cmd)\n        if not self.dry_run:\n            if stdin_path is None:\n                stdin = None\n            else:\n                stdin = open(stdin_path, 'r')\n            # https://stackoverflow.com/questions/15535240/python-popen-write-to-stdout-and-log-file-simultaneously/52090802#52090802\n            with subprocess.Popen(\n                cmd,\n                stdin=stdin,\n                stdout=stdout,\n                stderr=stderr,\n                env=env,\n                **kwargs\n            ) as proc:\n                if out_file is not None or out_str is not None:\n                    if out_file is not None:\n                        os.makedirs(os.path.split(os.path.abspath(out_file))[0], exist_ok=True)\n                    if out_file is not None:\n                        logfile = open(out_file, 'bw')\n                    logfile_str = []\n                    while True:\n                        byte = proc.stdout.read(1)\n                        if byte:\n                            if show_stdout:\n                                sys.stdout.buffer.write(byte)\n                                try:\n                                    sys.stdout.flush()\n                                except BlockingIOError:\n                                    # TODO understand. Why, Python, why.\n                                    pass\n                            if out_file is not None:\n                                logfile.write(byte)\n                            if out_str is not None:\n                                logfile_str.append(byte)\n                        else:\n                            break\n                    if out_file is not None:\n                        logfile.close()\n                    if out_str is not None:\n                        out_str.append((b''.join(logfile_str)))\n            if threading.current_thread() == threading.main_thread():\n                signal.signal(signal.SIGINT, sigint_old)\n                #signal.signal(signal.SIGPIPE, sigpipe_old)\n            if stdin_path is not None:\n                stdin.close()\n            returncode = proc.returncode\n            if returncode != 0 and raise_on_failure:\n                e = Exception('Command exited with status: {}'.format(returncode))\n                e.returncode = returncode\n                raise e\n            return returncode\n        else:\n            if not out_str is None:\n                out_str.append(b'')\n            return 0\n\n    def shlex_split(self, string):\n        '''\n        shlex_split, but also add Newline after every word.\n\n        Not perfect since it does not group arguments, but I don't see a solution.\n        '''\n        return self.add_newlines(shlex.split(string))\n\n    def strip_newlines(self, cmd):\n        if type(cmd) is str:\n            return cmd\n        else:\n            return [x for x in cmd if x != LF]\n\n    def walk(self, root):\n        '''\n        Extended walk that can take files or directories.\n        '''\n        if not os.path.exists(root):\n            raise Exception('Path does not exist: ' + root)\n        if os.path.isfile(root):\n            dirname, basename = os.path.split(root)\n            yield dirname, [], [basename]\n        else:\n            for path, dirnames, filenames in os.walk(root):\n                dirnames.sort()\n                filenames.sort()\n                yield path, dirnames, filenames\n\n    def wget(self, url, download_path):\n        '''\n        Append extra KEY=val configs into the given config file.\n\n        I wissh we could have a progress indicator, but impossible:\n        https://stackoverflow.com/questions/51212/how-to-write-a-download-progress-indicator-in-python\n        '''\n        self.print_cmd([\n            'wget', LF,\n            '-O', download_path, LF,\n            url, LF,\n        ])\n        urllib.request.urlretrieve(url, download_path)\n\n    def write_configs(self, config_path, configs, config_fragments=None, mode='a'):\n        '''\n        Append extra KEY=val configs into the given config file.\n        '''\n        if config_fragments is None:\n            config_fragments = []\n        for config_fragment in config_fragments:\n            self.print_cmd(['cat', config_fragment, '>>', config_path])\n        if not self.dry_run:\n            with open(config_path, 'a') as config_file:\n                for config_fragment in config_fragments:\n                    with open(config_fragment, 'r') as config_fragment_file:\n                        for line in config_fragment_file:\n                            config_file.write(line)\n        self.write_string_to_file(config_path, '\\n'.join(configs), mode=mode)\n\n    def write_string_to_file(self, path, string, mode='w'):\n        if mode == 'a':\n            redirect = '>>'\n        else:\n            redirect = '>'\n        self.print_cmd(\"cat << 'EOF' {} {}\\n{}\\nEOF\".format(redirect, path, string))\n        if not self.dry_run:\n            with open(path, mode) as f:\n                f.write(string)\n\nif __name__ == '__main__':\n    shell_helpers = ShellHelpers()\n    if 'cmd_to_string':\n        # Default.\n        assert shell_helpers.cmd_to_string(['cmd']) == 'cmd \\\\\\n;'\n        assert shell_helpers.cmd_to_string(['cmd', 'arg1']) == 'cmd \\\\\\n  arg1 \\\\\\n;'\n        assert shell_helpers.cmd_to_string(['cmd', 'arg1', 'arg2']) == 'cmd \\\\\\n  arg1 \\\\\\n  arg2 \\\\\\n;'\n\n        # Argument with a space gets escaped.\n        assert shell_helpers.cmd_to_string(['cmd', 'arg1 arg2']) == \"cmd \\\\\\n  'arg1 arg2' \\\\\\n;\"\n\n        # Ending in LF with no other LFs get separated only by spaces.\n        assert shell_helpers.cmd_to_string(['cmd', LF]) == 'cmd'\n        assert shell_helpers.cmd_to_string(['cmd', 'arg1', LF]) == 'cmd arg1'\n        assert shell_helpers.cmd_to_string(['cmd', 'arg1', 'arg2', LF]) == 'cmd arg1 arg2'\n\n        # More than one LF adds newline separators at each LF.\n        assert shell_helpers.cmd_to_string(['cmd', LF, 'arg1', LF]) == 'cmd \\\\\\n  arg1 \\\\\\n;'\n        assert shell_helpers.cmd_to_string(['cmd', LF, 'arg1', LF, 'arg2', LF]) == 'cmd \\\\\\n  arg1 \\\\\\n  arg2 \\\\\\n;'\n        assert shell_helpers.cmd_to_string(['cmd', LF, 'arg1', 'arg2', LF]) == 'cmd \\\\\\n  arg1 arg2 \\\\\\n;'\n\n        # force_oneline separates everything simply by spaces.\n        assert \\\n            shell_helpers.cmd_to_string(['cmd', LF, 'arg1', LF, 'arg2', LF], force_oneline=True) \\\n            == 'cmd arg1 arg2'\n\n        # stdin_path\n        assert shell_helpers.cmd_to_string(['cmd'], stdin_path='ab') == \"cmd \\\\\\n  < ab \\\\\\n;\"\n        assert shell_helpers.cmd_to_string(['cmd'], stdin_path='a b') == \"cmd \\\\\\n  < 'a b' \\\\\\n;\"\n"
        },
        {
          "name": "submodules",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "blob",
          "size": 1.55859375,
          "content": "#!/usr/bin/env python3\n\nimport common\nimport lkmc.import_path\nfrom shell_helpers import LF\n\nclass Main(common.TestCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#automated-tests\n'''\n        )\n        self.add_argument(\n            '--size',\n            default=1,\n            type=int,\n            help='''\\\nSize of the tests to run. Scale:\n\n* 1: a few seconds and important\n* 2: < 5 minutes and important or a few seconds and not too important\n* 3: all\n'''\n        )\n\n    def timed_main(self):\n        run_args = self.get_common_args()\n        test_boot_args = run_args.copy()\n        test_boot_args['size'] = self.env['size']\n        self.run_test(lkmc.import_path.import_path_main('test-boot'), test_boot_args, 'test-boot')\n        self.run_test(lkmc.import_path.import_path_main('test-userland-full-system'), run_args, 'test-userland')\n        self.run_test(lkmc.import_path.import_path_main('test-executables'), {**run_args, **{'mode': 'baremetal'}}, 'test-executables-baremetal')\n        self.run_test(lkmc.import_path.import_path_main('test-executables'), run_args, 'test-executables-userland')\n        self.run_test(lkmc.import_path.import_path_main('test-gdb'), run_args, 'test-gdb')\n        if self.env['emulator'] == 'gem5':\n            gem5_unit_test_args = run_args.copy()\n            gem5_unit_test_args['unit_tests'] = True\n            self.run_test(lkmc.import_path.import_path_main('build-gem5'), gem5_unit_test_args, 'gem5-unit-tests')\n\nif __name__ == '__main__':\n    Main().cli()\n\n"
        },
        {
          "name": "test-boot",
          "type": "blob",
          "size": 4.125,
          "content": "#!/usr/bin/env python3\n\nimport common\nimport lkmc.import_path\nimport thread_pool\nimport shell_helpers\nfrom shell_helpers import LF\n\nclass Main(common.TestCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nTest and benchmark the Linux kernel boot. Use inits that exit immediately.\n'''\n        )\n        self.add_argument(\n            '--size',\n            default=1,\n            type=int,\n            help='''\\\nSee ./test --help for --size.\n'''\n        )\n\n    def _bench(self, **run_args):\n        run_obj = lkmc.import_path.import_path_main('run')\n        words = []\n        test_id_args = run_args.copy()\n        del test_id_args['run_id']\n        for line in run_obj.get_cli(**test_id_args):\n            words.extend(line)\n        test_id = shell_helpers.ShellHelpers().cmd_to_string(words, force_oneline=True)\n        return self.run_test(run_obj, run_args, test_id)\n\n    def setup(self, env):\n        self.my_thread_pool = thread_pool.ThreadPool(\n            self._bench,\n            handle_output=self.handle_output_function,\n            nthreads=env['nproc'],\n            thread_id_arg='run_id',\n            submit_skip_exit=env['quit_on_fail'],\n        )\n\n    def timed_main(self):\n        # TODO bring this benchmark code back to life. Likely should go inside run with an option\n        #gem5_insts() (\n        #  printf \"instructions $(./gem5-stat --arch \"$1\" sim_insts)\\n\" >> \"$self.env['test_boot_benchmark_file']\"\n        #  newline\n        #)\n        #\n        #qemu_insts() (\n        #  common_arch=\"$1\"\n        #  ./qemu-trace2txt --arch \"$common_arch\"\n        #  common_qemu_trace_txt_file=\"$(\"$getvar\" --arch \"$common_arch\" qemu_trace_txt_file)\"\n        #  printf \"instructions $(wc -l \"${common_qemu_trace_txt_file}\" | cut -d' ' -f1)\\n\" >> \"$self.env['test_boot_benchmark_file']\"\n        #  newline\n        #)\n        #\n        #rm -f \"${self.env['test_boot_benchmark_file']}\"\n        common_args = self.get_common_args()\n        common_args['ctrl_c_host'] = True\n        common_args['quit_after_boot'] = True\n        # To see it blow up during development.\n        # self.common_args['eval'] = 'insmod /lkmc/panic.ko'\n        if (self.env['emulator'] == 'qemu' or\n                (self.env['emulator'] == 'gem5' and self.env['size'] >= 2)):\n            self.my_thread_pool.submit(common_args)\n        if self.env['host_arch'] == self.env['arch']:\n            # TODO: find out why it fails.\n            if self.env['emulator'] != 'gem5':\n                self.my_thread_pool.submit({**common_args, **{'kvm': True}})\n        if self.env['emulator'] == 'qemu' and self.env['size'] >= 2:\n            self.my_thread_pool.submit({**common_args, **{'trace': 'exec_tb'}})\n        if self.env['emulator'] == 'gem5' and self.env['size'] >= 3:\n            if self.env['arch'] == 'x86_64':\n                cpu_types = [\n                    # TODO segfault\n                    #'DerivO3CPU'\n                ]\n            elif self.env['is_arm']:\n                cpu_types = [\n                    'DerivO3CPU',\n                    'HPI',\n                ]\n            for cpu_type in cpu_types:\n                self.my_thread_pool.submit({**common_args, **{\n                    'extra_emulator_args': [\n                        '--cpu-type', cpu_type, LF,\n                        '--caches', LF,\n                        '--l2cache', LF,\n                        '--l1d_size', '1024kB', LF,\n                        '--l1i_size', '1024kB', LF,\n                        '--l2_size', '1024kB', LF,\n                        '--l3_size', '1024kB', LF,\n                    ],\n                }})\n            if self.env['arch'] == 'aarch64':\n                # Do a fuller testing for aarch64.\n                for build_type in ['debug', 'fast']:\n                    self.my_thread_pool.submit({**common_args, **{'gem5_build_type': build_type}})\n                # Requires patching the executable.\n                # self.my_thread_pool.submit({{**common_args, 'gem5_script': 'biglittle'}})\n\n    def teardown(self):\n        self.my_thread_pool.join()\n        self._handle_thread_pool_errors(self.my_thread_pool)\n        return super().teardown()\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "test-build-userland",
          "type": "blob",
          "size": 1.9716796875,
          "content": "#!/usr/bin/env bash\n\n# https://cirosantilli.com/linux-kernel-module-cheat#cli-script-tests\n\nset -eux\n\nfor in_tree in '' --in-tree; do\n  userland_build_dir=\"$(./getvar $in_tree userland_build_dir)\"\n  # Toplevel.\n  ./build-userland $in_tree\n  [ -f \"${userland_build_dir}/c/hello.out\" ]\n  ./build-userland $in_tree --clean\n  ! [ -f \"${userland_build_dir}/c/hello.out\" ]\n\n  # Toplevel explicit.\n  ./build-userland $in_tree userland/\n  [ -f \"${userland_build_dir}/c/hello.out\" ]\n  ./build-userland $in_tree --clean\n  ! [ -f \"${userland_build_dir}/c/hello.out\" ]\n\n  # Toplevel root dir.\n  ./build-userland $in_tree .\n  [ -f \"${userland_build_dir}/c/hello.out\" ]\n  ./build-userland $in_tree --clean\n  ! [ -f \"${userland_build_dir}/c/hello.out\" ]\n\n  # Subdirectory.\n  ./build-userland $in_tree userland/c\n  [ -f \"${userland_build_dir}/c/hello.out\" ]\n  ./build-userland $in_tree --clean userland/c\n  ! [ -f \"${userland_build_dir}/c/hello.out\" ]\n\n  # One program.\n  ./build-userland $in_tree userland/c/hello.c\n  [ -f \"${userland_build_dir}/c/hello.out\" ]\n  ./build-userland $in_tree --clean userland/c/hello.c\n  ! [ -f \"${userland_build_dir}/c/hello.out\" ]\n\n  # Things that don't work: building:\n  # - non-existent files\n  # - paths outside of tree\n  ! ./build-userland $in_tree userland/c/hello\n  ! ./build-userland $in_tree userland/c/hello.\n  ! ./build-userland $in_tree \"${userland_build_dir}/c/hello.out\"\n  tmpfile=\"$(mktemp)\"\n  ! ./build-userland $in_tree \"$tmpfile\"\n  ! ./build-userland --clean $in_tree \"$tmpfile\"\n  rm \"$tmpfile\"\n  ! ./build-userland $in_tree ..\n  ! ./build-userland $in_tree kernel_modules\n  ! ./build-userland --clean $in_tree userland/does_not_exist\n  ./build-userland --clean $in_tree\ndone\n\n./build-userland-in-tree\n[ -f userland/c/hello.out ]\n./build-userland-in-tree --clean\n! [ -f userland/c/hello.out ]\n\ncd userland\n./build\n[ -f c/hello.out ]\n./build --clean\n! [ -f c/hello.out ]\n./build c\n[ -f c/hello.out ]\n./build --clean c\n! [ -f c/hello.out ]\n./build --clean c/hello.c\n! [ -f c/hello.out ]\n"
        },
        {
          "name": "test-executables",
          "type": "blob",
          "size": 4.6943359375,
          "content": "#!/usr/bin/env python3\n\nimport os\nimport sys\n\nimport common\nimport lkmc.import_path\nimport path_properties\nimport signal\nimport thread_pool\n\nclass Main(common.TestCliFunction):\n    def __init__(self, *args, **kwargs):\n        if not 'description' in kwargs:\n            kwargs['description'] = '''\\\nTest userland executables in user mode, or baremetal executables in full system\ndepending on the value of the --mode option. See also:\n\n* https://cirosantilli.com/linux-kernel-module-cheat#user-mode-tests\n* https://cirosantilli.com/linux-kernel-module-cheat#baremetal-tests\n* https://cirosantilli.com/linux-kernel-module-cheat#userland-setup-getting-started-natively\n'''\n        if not 'defaults' in kwargs:\n            kwargs['defaults'] = {}\n        if not 'mode' in kwargs['defaults']:\n            kwargs['defaults']['mode'] = 'userland'\n        super().__init__(*args, **kwargs)\n        self.add_argument(\n            'tests',\n            nargs='*',\n            help='''\\\nIf given, run only the given tests. Otherwise, run all tests.\n'''\n        )\n\n    def setup_one(self):\n        self.env['tests'] = self.resolve_targets(\n            [\n                self.env['baremetal_source_dir'],\n                self.env['userland_source_dir']\n            ],\n            self.env['tests']\n        )\n\n    def timed_main(self):\n        run_args = self.get_common_args()\n        rootdir_abs_len = len(self.env['root_dir'])\n        with thread_pool.ThreadPool(\n            self.run_test,\n            handle_output=self.handle_output_function,\n            nthreads=self.env['nproc'],\n            thread_id_arg='thread_id',\n            submit_raise_exit=self.env['quit_on_fail'],\n        ) as my_thread_pool:\n            for test in self.env['tests']:\n                for path, in_dirnames, in_filenames in self.sh.walk(test):\n                    path_abs = os.path.abspath(path)\n                    dirpath_relative_root = path_abs[rootdir_abs_len + 1:]\n                    for in_filename in in_filenames:\n                        if os.path.splitext(in_filename)[1] in self.env['build_in_exts']:\n                            path_relative_root = os.path.join(dirpath_relative_root, in_filename)\n                            my_path_properties = path_properties.get(path_relative_root)\n                            if my_path_properties.should_be_tested(self.env):\n                                cur_run_args = run_args.copy()\n                                cur_run_args.update({\n                                    self.env['mode']: [os.path.relpath(\n                                        os.path.join(path_abs, in_filename),\n                                        os.getcwd()\n                                    )],\n                                })\n                                cur_run_args.update(my_path_properties['test_run_args'])\n                                if my_path_properties['test_stdin_data'] is not None:\n                                    cur_run_args['stdin_file'] = os.path.join(\n                                        path_abs,\n                                        'test_data',\n                                        my_path_properties['test_stdin_data'] + '.i'\n                                    )\n                                run_test_args = {\n                                    'expected_exit_status': my_path_properties['exit_status'],\n                                    'run_args': cur_run_args,\n                                    'run_obj': lkmc.import_path.import_path_main('run'),\n                                    'test_id': '{} {}'.format(self.env['mode'], path_relative_root),\n                                }\n                                if (my_path_properties['qemu_unimplemented_instruction'] and\n                                    self.env['emulator'] == 'qemu' and\n                                    self.env['mode'] == 'userland'\n                                ):\n                                    run_test_args['expected_exit_status'] = -signal.Signals.SIGILL.value\n                                my_signal = my_path_properties['signal_received']\n                                if my_signal is not None:\n                                    if self.env['mode'] == 'baremetal':\n                                        run_test_args['expected_exit_status'] = 128 + my_signal.value\n                                    elif self.env['mode'] == 'userland':\n                                        # Python subprocess reports signals differently from Bash's 128 + signal rule.\n                                        run_test_args['expected_exit_status'] = -my_signal.value\n                                my_thread_pool.submit(run_test_args)\n        return self._handle_thread_pool_errors(my_thread_pool)\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "test-executables-in-tree",
          "type": "blob",
          "size": 0.6064453125,
          "content": "#!/usr/bin/env python3\n\nimport lkmc.import_path\n\ntest_user_mode = lkmc.import_path.import_path_relative_root('test-executables')\n\nclass Main(test_user_mode.Main):\n    def __init__(self):\n        defaults = {\n            'emulators': ['native'],\n            'in_tree': True,\n            'tests': ['.'],\n        }\n        if self.cwd_in_lib():\n            defaults['package_all'] = True\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#userland-setup-getting-started-natively\n''',\n            defaults=defaults\n        )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "test-gdb",
          "type": "blob",
          "size": 3.0400390625,
          "content": "#!/usr/bin/env python3\n\nimport threading\nimport os\n\nimport common\nimport lkmc.import_path\nimport path_properties\n\nclass Main(common.TestCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#gdb-tests\n''',\n            defaults={\n                'mode': 'userland',\n            }\n        )\n        self.add_argument(\n            'tests',\n            nargs='*',\n            help='''\\\nIf given, run only the given tests. Otherwise, run all tests,\nfound by searching for the Python test files.\n'''\n        )\n\n    def setup_one(self):\n        self.env['tests'] = self.resolve_targets(\n            [\n                self.env['baremetal_source_dir'],\n                self.env['userland_source_dir']\n            ],\n            self.env['tests']\n        )\n\n    def timed_main(self):\n        if self.env['mode'] == 'userland':\n            exts = self.env['build_in_exts']\n        elif self.env['mode'] == 'baremetal':\n            exts = self.env['baremetal_build_in_exts']\n        rootdir_abs_len = len(self.env['root_dir'])\n        for test in self.env['tests']:\n            for path, in_dirnames, in_filenames in self.sh.walk(test):\n                path_abs = os.path.abspath(path)\n                dirpath_relative_root = path_abs[rootdir_abs_len + 1:]\n                for in_filename in in_filenames:\n                    in_file_abs = os.path.join(path_abs, in_filename)\n                    path_relative_root = os.path.join(dirpath_relative_root, in_filename)\n                    path_relative_root_base, ext = os.path.splitext(path_relative_root)\n                    if ext in exts and os.path.exists(path_relative_root_base + '.py'):\n                        my_path_properties = path_properties.get(path_relative_root)\n                        if my_path_properties.should_be_tested(\n                            self.env,\n                        ):\n                            run = lkmc.import_path.import_path_main('run')\n                            run_gdb = lkmc.import_path.import_path_main('run-gdb')\n                            common_args = self.get_common_args()\n                            common_args[self.env['mode']] = path_relative_root\n                            run_args = common_args.copy()\n                            run_args['gdb_wait'] = True\n                            run_args.update(self.base_run_args)\n                            test_id_string = self.test_setup(\n                                run_args,\n                                '{} {}'.format(self.env['mode'], path_relative_root)\n                            )\n                            run_thread = threading.Thread(target=lambda: run(**run_args))\n                            run_thread.start()\n                            gdb_args = common_args.copy()\n                            gdb_args['test'] = True\n                            exit_status = run_gdb(**gdb_args)\n                            run_thread.join()\n                            self.test_teardown(run, exit_status, test_id_string)\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "test-gem5-graphics",
          "type": "blob",
          "size": 0.6044921875,
          "content": "#!/usr/bin/env bash\n# Quick and dirty implementation, relies on configs.\n# Check that the third image matches a reference penguin SHA.\n# https://softwarerecs.stackexchange.com/questions/9774/command-line-tool-to-check-whether-two-images-are-exactly-the-same-graphically/9779#9779\nset -eux\nrm -rf \"$(./getvar \"$@\" m5out_dir)/frames_system.vncserver\"\n./run --eval 'm5 exit' --tmux \"$@\" -- --frame-capture\ngz=\"$(echo \"$(./getvar m5out_dir)/frames_system.vncserver/fb.000002.\"*.gz)\"\npng=\"${gz%.*}\"\ngunzip --keep \"$gz\"\n[ \"$(identify -format '%#' \"$png\")\" = dc41b947487026acdceae8a757259d5a1a4752fd97c1da9ce6df9b49013babed ]\n"
        },
        {
          "name": "test-test-executables",
          "type": "blob",
          "size": 0.9384765625,
          "content": "#!/usr/bin/env bash\n\n# https://cirosantilli.com/linux-kernel-module-cheat#cli-script-tests\n\nset -eux\n\n./build-userland\n./build-userland-in-tree\n\nf=\"$(tempfile)\"\n\n./test-executables | tee \"$f\"\ngrep -E '^PASS .* userland/c/hello' \"$f\"\ngrep -E '^PASS .* userland/posix/uname' \"$f\"\n\n./test-executables userland | tee \"$f\"\ngrep -E '^PASS .* userland/c/hello' \"$f\"\ngrep -E '^PASS .* userland/posix/uname' \"$f\"\n\n./test-executables userland/c | tee \"$f\"\ngrep -E '^PASS .* userland/c/hello' \"$f\"\n! grep -E '^PASS .* userland/posix/uname' \"$f\"\n\n./test-executables userland/c/hello.c | tee \"$f\"\ngrep -E '^PASS .* userland/c/hello' \"$f\"\n! grep -E '^PASS .* userland/c/false' \"$f\"\n! grep -E '^PASS .* userland/posix/uname' \"$f\"\n\n./test-executables-in-tree | tee \"$f\"\ngrep -E '^PASS .* userland/c/hello' \"$f\"\ngrep -E '^PASS .* userland/posix/uname' \"$f\"\n\ncd userland\n./test\ngrep -E '^PASS .* userland/c/hello' \"$f\"\ngrep -E '^PASS .* userland/posix/uname' \"$f\"\ncd ..\n\nrm \"$f\"\n"
        },
        {
          "name": "test-userland-full-system",
          "type": "blob",
          "size": 0.5654296875,
          "content": "#!/usr/bin/env python3\n\nimport os\n\nimport common\nimport lkmc.import_path\n\nclass Main(common.TestCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''\\\nhttps://cirosantilli.com/linux-kernel-module-cheat#test-userland-in-full-system\n'''\n        )\n    def timed_main(self):\n        run = lkmc.import_path.import_path_main('run')\n        run_args = self.get_common_args()\n        run_args['eval_after'] = './test_all.sh;{};'.format(self.env['userland_quit_cmd'])\n        self.run_test(run, run_args)\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "thread_pool.py",
          "type": "blob",
          "size": 15.0009765625,
          "content": "#!/usr/bin/env python3\n\n'''\nThis file is MIT Licensed because I'm posting it on Stack Overflow:\nhttps://stackoverflow.com/questions/19369724/the-right-way-to-limit-maximum-number-of-threads-running-at-once/55263676#55263676\n'''\n\nfrom typing import Any, Callable, Dict, Iterable, Union\nimport os\nimport queue\nimport sys\nimport threading\nimport time\nimport traceback\n\nclass ThreadPoolExitException(Exception):\n    '''\n    An object of this class may be raised by output_handler_function to\n    request early termination.\n\n    It is also raised by submit() if submit_raise_exit=True.\n    '''\n    pass\n\nclass ThreadPool:\n    '''\n    Start a pool of a limited number of threads to do some work.\n\n    This is similar to the stdlib concurrent, but I could not find\n    how to reach all my design goals with that implementation:\n\n    * the input function does not need to be modified\n    * limit the number of threads\n    * queue sizes closely follow number of threads\n    * if an exception happens, optionally stop soon afterwards\n\n    This class form allows to use your own while loops with submit().\n\n    Exit soon after the first failure happens:\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_print\n    ....\n\n    Sample output:\n\n    ....\n    {'i': -9} -1.1111111111111112 None\n    {'i': -8} -1.25 None\n    {'i': -10} -1.0 None\n    {'i': -6} -1.6666666666666667 None\n    {'i': -7} -1.4285714285714286 None\n    {'i': -4} -2.5 None\n    {'i': -5} -2.0 None\n    {'i': -2} -5.0 None\n    {'i': -3} -3.3333333333333335 None\n    {'i': 0} None ZeroDivisionError('float division by zero')\n    {'i': -1} -10.0 None\n    {'i': 1} 10.0 None\n    {'i': 2} 5.0 None\n    work_function or handle_output raised:\n    Traceback (most recent call last):\n      File \"thread_pool.py\", line 181, in _func_runner\n        work_function_return = self.work_function(**work_function_input)\n      File \"thread_pool.py\", line 281, in work_function_maybe_raise\n        return 10.0 / i\n    ZeroDivisionError: float division by zero\n    work_function_input: {'i': 0}\n    work_function_return: None\n    ....\n\n    Don't exit after first failure, run until end:\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_print_no_exit\n    ....\n\n    Store results in a queue for later inspection instead of printing immediately,\n    then print everything at the end:\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_queue\n    ....\n\n    Exit soon after the handle_output raise.\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_raise\n    ....\n\n    Relying on this interface to abort execution is discouraged, this should\n    usually only happen due to a programming error in the handler.\n\n    Test that the argument called \"thread_id\" is passed to work_function and printed:\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_print thread_id\n    ....\n\n    Test with, ThreadPoolExitException and submit_raise_exit=True, same behaviour handle_output_print\n    except for the different exit cause report:\n\n    ....\n    python3 thread_pool.py 2 -10 20 handle_output_raise_exit_exception\n    ....\n    '''\n    def __init__(\n        self,\n        work_function: Callable,\n        handle_output: Union[Callable[[Any,Any,Exception],Any],None] = None,\n        nthreads: Union[int,None] = None,\n        thread_id_arg: Union[str,None] = None,\n        submit_raise_exit: bool = False,\n        submit_skip_exit: bool = False,\n    ):\n        '''\n        Start in a thread pool immediately.\n\n        join() must be called afterwards at some point.\n\n        :param work_function: main work function to be evaluated.\n        :param handle_output: called on work_function return values as they\n            are returned.\n\n            The function signature is:\n\n            ....\n            handle_output(\n                work_function_input: Union[Dict,None],\n                work_function_return,\n                work_function_exception: Exception\n            ) -> Union[Exception,None]\n            ....\n\n            where work_function_exception the exception that work_function raised,\n            or None otherwise\n\n            The first non-None return value of a call to this function is returned by\n            submit(), get_handle_output_result() and join().\n\n            The intended semantic for this, is to return:\n\n            *   on success:\n            ** None to continue execution\n            ** ThreadPoolExitException() to request stop execution\n            * if work_function_input or work_function_exception raise:\n            ** the exception raised\n\n            The ThreadPool user can then optionally terminate execution early on error\n            or request with either:\n\n            * an explicit submit() return value check + break if a submit loop is used\n            * `with` + submit_raise_exit=True\n\n            Default: a handler that just returns `exception`, which can normally be used\n            by the submit loop to detect an error and exit immediately.\n        :param nthreads: number of threads to use. Default: nproc.\n        :param thread_id_arg: if not None, set the argument of work_function with this name\n            to a 0-indexed thread ID. This allows function calls to coordinate\n            usage of external resources such as files or ports.\n        :param submit_raise_exit: if True, submit() raises ThreadPoolExitException() if\n            get_handle_output_result() is not None.\n        :param submit_skip_exit: if True, submit() does nothing if\n            get_handle_output_result() is not None.\n\n            You should avoid this interface if\n            you can use use submit_raise_exit with `with` instead ideally.\n\n            However, when you can't work with with and are in a deeply nested loop,\n            it might just be easier to set this.\n        '''\n        self.work_function = work_function\n        if handle_output is None:\n            handle_output = lambda input, output, exception: exception\n        self.handle_output = handle_output\n        if nthreads is None:\n            nthreads = len(os.sched_getaffinity(0))\n        self.thread_id_arg = thread_id_arg\n        self.submit_raise_exit = submit_raise_exit\n        self.submit_skip_exit = submit_skip_exit\n        self.nthreads = nthreads\n        self.handle_output_result = None\n        self.handle_output_result_lock = threading.Lock()\n        self.in_queue = queue.Queue(maxsize=nthreads)\n        self.threads = []\n        for i in range(self.nthreads):\n            thread = threading.Thread(\n                target=self._func_runner,\n                args=(i,)\n            )\n            self.threads.append(thread)\n            thread.start()\n\n    def __enter__(self):\n        '''\n        __exit__ automatically calls join() for you.\n\n        This is cool because it automatically ends the loop if an exception occurs.\n\n        But don't forget that errors may happen after the last submit was called, so you\n        likely want to check for that with get_handle_output_result() after the with.\n        '''\n        return self\n\n    def __exit__(self, exception_type, exception_value, exception_traceback):\n        self.join()\n        return exception_type is ThreadPoolExitException\n\n    def _func_runner(self, thread_id):\n        while True:\n            work_function_input = self.in_queue.get(block=True)\n            if work_function_input is None:\n                break\n            if self.thread_id_arg is not None:\n                work_function_input[self.thread_id_arg] = thread_id\n            try:\n                work_function_exception = None\n                work_function_return = self.work_function(**work_function_input)\n            except Exception as e:\n                work_function_exception = e\n                work_function_return = None\n            handle_output_exception = None\n            try:\n                handle_output_return = self.handle_output(\n                    work_function_input,\n                    work_function_return,\n                    work_function_exception\n                )\n            except Exception as e:\n                handle_output_exception = e\n            handle_output_result = None\n            if handle_output_exception is not None:\n                handle_output_result = handle_output_exception\n            elif handle_output_return is not None:\n                handle_output_result = handle_output_return\n            if handle_output_result is not None and self.handle_output_result is None:\n                with self.handle_output_result_lock:\n                    self.handle_output_result = (\n                        work_function_input,\n                        work_function_return,\n                        handle_output_result\n                    )\n            self.in_queue.task_done()\n\n    @staticmethod\n    def exception_traceback_string(exception):\n        '''\n        Helper to get the traceback from an exception object.\n        This is usually what you want to print if an error happens in a thread:\n        https://stackoverflow.com/questions/3702675/how-to-print-the-full-traceback-without-halting-the-program/56199295#56199295\n        '''\n        return ''.join(traceback.format_exception(\n            None, exception, exception.__traceback__)\n        )\n\n    def get_handle_output_result(self):\n        '''\n        :return: if a handle_output call has raised previously, return a tuple:\n\n            ....\n            (work_function_input, work_function_return, exception_raised)\n            ....\n\n            corresponding to the first such raise.\n\n            Otherwise, if a handle_output returned non-None, a tuple:\n\n            (work_function_input, work_function_return, handle_output_return)\n\n            Otherwise, None.\n        '''\n        return self.handle_output_result\n\n    def join(self):\n        '''\n        Request all threads to stop after they finish currently submitted work.\n\n        :return: same as get_handle_output_result()\n        '''\n        for thread in range(self.nthreads):\n            self.in_queue.put(None)\n        for thread in self.threads:\n            thread.join()\n        return self.get_handle_output_result()\n\n    def submit(\n        self,\n        work_function_input: Union[Dict,None] =None\n    ):\n        '''\n        Submit work. Block if there is already enough work scheduled (~nthreads).\n\n        :return: the same as get_handle_output_result\n        '''\n        handle_output_result = self.get_handle_output_result()\n        if handle_output_result is not None:\n            if self.submit_raise_exit:\n                raise ThreadPoolExitException()\n            if self.submit_skip_exit:\n                return handle_output_result\n        if work_function_input is None:\n            work_function_input = {}\n        self.in_queue.put(work_function_input)\n        return handle_output_result\n\nif __name__ == '__main__':\n    def get_work(min_, max_):\n        '''\n        Generate simple range work for work_function.\n        '''\n        for i in range(min_, max_):\n            yield {'i': i}\n\n    def work_function_maybe_raise(i):\n        '''\n        The main function that will be evaluated.\n\n        It sleeps to simulate an IO operation.\n        '''\n        time.sleep((abs(i) % 4) / 10.0)\n        return 10.0 / i\n\n    def work_function_get_thread(i, thread_id):\n        time.sleep((abs(i) % 4) / 10.0)\n        return thread_id\n\n    def handle_output_print(input, output, exception):\n        '''\n        Print outputs and exit immediately on failure.\n        '''\n        print('{!r} {!r} {!r}'.format(input, output, exception))\n        return exception\n\n    def handle_output_print_no_exit(input, output, exception):\n        '''\n        Print outputs, don't exit on failure.\n        '''\n        print('{!r} {!r} {!r}'.format(input, output, exception))\n\n    out_queue = queue.Queue()\n    def handle_output_queue(input, output, exception):\n        '''\n        Store outputs in a queue for later usage.\n        '''\n        global out_queue\n        out_queue.put((input, output, exception))\n        return exception\n\n    def handle_output_raise(input, output, exception):\n        '''\n        Raise if input == 0, to test that execution\n        stops nicely if this raises.\n        '''\n        print('{!r} {!r} {!r}'.format(input, output, exception))\n        if input['i'] == 0:\n            raise Exception\n\n    def handle_output_raise_exit_exception(input, output, exception):\n        '''\n        Return a ThreadPoolExitException() if input == -5.\n        Return the work_function exception if it raised.\n        '''\n        print('{!r} {!r} {!r}'.format(input, output, exception))\n        if exception:\n            return exception\n        if output == 10.0 / -5:\n            return ThreadPoolExitException()\n\n    # CLI arguments.\n    argv_len = len(sys.argv)\n    if argv_len > 1:\n        nthreads = int(sys.argv[1])\n        if nthreads == 0:\n            nthreads = None\n    else:\n        nthreads = None\n    if argv_len > 2:\n        min_ = int(sys.argv[2])\n    else:\n        min_ = 1\n    if argv_len > 3:\n        max_ = int(sys.argv[3])\n    else:\n        max_ = 100\n    if argv_len > 4:\n        handle_output_funtion_string = sys.argv[4]\n    else:\n        handle_output_funtion_string = 'handle_output_print'\n    handle_output = eval(handle_output_funtion_string)\n    if argv_len > 5:\n        work_function = work_function_get_thread\n        thread_id_arg = sys.argv[5]\n    else:\n        work_function = work_function_maybe_raise\n        thread_id_arg = None\n\n    # Action.\n    if handle_output is handle_output_raise_exit_exception:\n        # `with` version with implicit join and submit raise\n        # immediately when desired with ThreadPoolExitException.\n        #\n        # This is the more safe and convenient and DRY usage if\n        # you can use `with`, so prefer it generally.\n        with ThreadPool(\n            work_function,\n            handle_output,\n            nthreads,\n            thread_id_arg,\n            submit_raise_exit=True\n        ) as my_thread_pool:\n            for work in get_work(min_, max_):\n                my_thread_pool.submit(work)\n        handle_output_result = my_thread_pool.get_handle_output_result()\n    else:\n        # Explicit error checking in submit loop to exit immediately\n        # on error.\n        my_thread_pool = ThreadPool(\n            work_function,\n            handle_output,\n            nthreads,\n            thread_id_arg,\n        )\n        for work_function_input in get_work(min_, max_):\n            handle_output_result = my_thread_pool.submit(work_function_input)\n            if handle_output_result is not None:\n                break\n        handle_output_result = my_thread_pool.join()\n    if handle_output_result is not None:\n        work_function_input, work_function_return, exception = handle_output_result\n        if type(exception) is ThreadPoolExitException:\n            print('Early exit requested by handle_output with ThreadPoolExitException:')\n        else:\n            print('work_function or handle_output raised:')\n            print(ThreadPool.exception_traceback_string(exception), end='')\n        print('work_function_input: {!r}'.format(work_function_input))\n        print('work_function_return: {!r}'.format(work_function_return))\n    if handle_output == handle_output_queue:\n        while not out_queue.empty():\n            print(out_queue.get())\n"
        },
        {
          "name": "tmux-split",
          "type": "blob",
          "size": 0.345703125,
          "content": "#!/usr/bin/env bash\n# TODO: move to Python.\nif [ \"$(tmux list-panes | wc -l | cut -d' ' -f1)\" -ne 1 ]; then\n  tmux kill-pane -t 1\nfi\n# https://unix.stackexchange.com/questions/439031/how-to-split-the-window-that-ran-the-tmux-split-window-command-instead-of-the/439032#439032\ntmux split-window -dh -t \"$TMUX_PANE\" \"bash --rcfile <(echo '. ~/.bashrc;$*')\"\n"
        },
        {
          "name": "trace-boot",
          "type": "blob",
          "size": 1.982421875,
          "content": "#!/usr/bin/env python3\n\nfrom shell_helpers import LF\nimport common\nimport lkmc.import_path\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            description='''Trace the PIC addresses executed on a Linux kernel boot.\n\nMore information at: https://cirosantilli.com/linux-kernel-module-cheat#tracing\n'''\n        )\n\n    def timed_main(self):\n        args = self.get_common_args()\n        run = lkmc.import_path.import_path_main('run')\n        if self.env['emulator'] == 'gem5':\n            args['trace'] = 'Exec,-ExecSymbol,-ExecMicro'\n            run(**args)\n        elif self.env['emulator'] == 'qemu':\n            run_args = args.copy()\n            run_args['trace'] = 'exec_tb'\n            run_args['quit_after_boot'] = True\n            run(**run_args)\n            qemu_trace2txt = lkmc.import_path.import_path_main('qemu-trace2txt')\n            qemu_trace2txt(**args)\n            # Instruction count.\n            # We could put this on a separate script, but it just adds more arch boilerplate to a new script.\n            # So let's just leave it here for now since it did not add a significant processing time.\n            kernel_entry_addr = hex(self.get_elf_entry(self.env['vmlinux']))\n            nlines = 0\n            nlines_firmware = 0\n            with open(self.env['qemu_trace_txt_file'], 'r') as trace_file:\n                in_firmware = True\n                for line in trace_file:\n                    line = line.rstrip()\n                    nlines += 1\n                    pc = line.split('=')[-1]\n                    if pc == kernel_entry_addr:\n                        in_firmware = False\n                    if in_firmware:\n                        nlines_firmware += 1\n            print('''\\\ninstructions {}\nentry_address {}\ninstructions_firmware {}\n'''.format(\n                    nlines,\n                    kernel_entry_addr,\n                    nlines_firmware\n                ),\n                end=''\n            )\n\nif __name__ == '__main__':\n    Main().cli()\n"
        },
        {
          "name": "trace2line",
          "type": "blob",
          "size": 2.1220703125,
          "content": "#!/usr/bin/env python3\n\n'''\nTODO port this to Python fully. I started it, but then it was hanging on some\nIO blocking annoyance in the pipeline, and I don't have the time to deal with\nit, so I'm just going to forward the common options to the old shell script for\nnow...\n'''\n\nimport os\n\nimport common\nimport lkmc.import_path\nfrom shell_helpers import LF\n\nclass Main(common.LkmcCliFunction):\n    def __init__(self):\n        super().__init__(\n            defaults = {\n                'show_time': False,\n            },\n            description='''\\\nConvert an execution trace containing PC values into the Linux kernel lines executed.\n''',\n        )\n\n    def timed_main(self):\n        self.sh.run_cmd([\n            os.path.join(self.env['root_dir'], 'trace2line.sh'), LF,\n            'true' if self.env['emulator'] == 'gem5' else 'false', LF,\n            self.env['trace_txt_file'], LF,\n            self.get_toolchain_tool('addr2line'), LF,\n            self.env['vmlinux'], LF,\n            self.env['run_dir'], LF,\n        ])\n\nif __name__ == '__main__':\n    Main().cli()\n\n# This was the old full Python port attempt that was failing:\n\n# import subprocess\n# import sys\n\n# if kwargs['emulator'] == 'gem5':\n#     def get_pc(line):\n#         # TODO\n#         # stdin = sed -r 's/^.* (0x[^. ]*)[. ].*/\\1/' \"$common_trace_txt_file\")\n#         pass\n# else:\n#     def get_pc(line):\n#         return line.split('=')[-1]\n# with \\\n#         subprocess.Popen(\n#             [\n#                 self.get_toolchain_tool('addr2line'),\n#                 '-e',\n#                 kwargs['vmlinux'],\n#                 '-f',\n#                 '-p',\n#             ],\n#             stdout=subprocess.PIPE,\n#             stdin=subprocess.PIPE,\n#         ) as proc, \\\n#         open(kwargs['trace_txt_file'], 'r') as infile, \\\n#         open(os.path.join(kwargs['run_dir'], 'trace-lines.txt'), 'w') as outfile \\\n#     :\n#     for in_line in infile:\n#         proc.stdin.write(get_pc(in_line).encode())\n#         proc.stdin.flush()\n#         stdout = proc.stdout.read()\n#         outfile.write(stdout.decode())\n#     # TODO\n#     # sed -E \"s|at ${kwargs['linux_build_dir']}/(\\./\\|)||\"\n#     # uniq -c\n"
        },
        {
          "name": "trace2line.sh",
          "type": "blob",
          "size": 0.470703125,
          "content": "#!/usr/bin/env bash\nset -eu\ncommon_gem5=\"$1\"\nshift\ncommon_trace_txt_file=\"$1\"\nshift\ncommon_addr2line=\"$1\"\nshift\ncommon_vmlinux=\"$1\"\nshift\ncommon_run_dir=\"$1\"\nshift\n(\n  if \"$common_gem5\"; then\n    sed -r 's/^.* (0x[^. ]*)[. ].*/\\1/' \"$common_trace_txt_file\"\n  else\n    sed -r 's/.*pc=//' \"$common_trace_txt_file\"\n  fi\n) | \\\n  xargs \"${common_addr2line}\" -e \"${common_vmlinux}\" -fp | \\\n  sed -E \"s|at ${common_vmlinux}/(\\./\\|)||\" | \\\n  uniq -c \\\n> \"${common_run_dir}/trace-lines.txt\"\n"
        },
        {
          "name": "update-buildroot-kernel-configs",
          "type": "blob",
          "size": 0.5654296875,
          "content": "#!/usr/bin/env bash\nset -eux\nroot_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" >/dev/null && pwd)\"\ngetvar=\"${root_dir}/getvar\"\nfor arch in x86_64 arm aarch64; do\n  linux_arch=\"$(\"${getvar}\" --arch \"$arch\" linux_arch)\"\n  linux_buildroot_build_dir=\"$(\"${getvar}\" --arch \"$arch\" linux_buildroot_build_dir)\"\n  linux_config_dir=\"$(\"${getvar}\" --arch \"$arch\" linux_config_dir)\"\n  \"${root_dir}/build-buildroot\" --baseline --build-linux --no-all -- linux-configure\n  cd \"$linux_build_dir\"\n  make ARCH=\"$linux_arch\" savedefconfig\n  cp defconfig \"${linux_config_dir}/buildroot-${arch}\"\ndone\n"
        },
        {
          "name": "user_table",
          "type": "blob",
          "size": 0.0478515625,
          "content": "user0 -1 user0 -1 =a /home/user0 /bin/sh - user0\n"
        },
        {
          "name": "userland",
          "type": "tree",
          "content": null
        },
        {
          "name": "vnc",
          "type": "blob",
          "size": 0.0419921875,
          "content": "#!/usr/bin/env bash\nvinagre localhost:5900\n"
        },
        {
          "name": "x11.png",
          "type": "blob",
          "size": 15.84375,
          "content": null
        }
      ]
    }
  ]
}