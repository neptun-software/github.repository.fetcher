{
  "metadata": {
    "timestamp": 1736560360980,
    "page": 895,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjkwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "modelscope/data-juicer",
      "stars": 3313,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.26171875,
          "content": "[run]\nomit =\n    # avoid measuring strange non-existing files\n    /workspace/config.py\n    /workspace/config-3.py\n\n    # avoid measuring third-party dist packages\n    */dist-packages/*\n\n    # avoid measuring code of unittest\n    tests/*\n\n[report]\nignore_errors = True\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.15625,
          "content": "\n# data & resources\noutputs/\nassets/\n\n# setup\ndata_juicer.egg-info/\npy_data_juicer.egg-info/\nbuild/\ndist\n\n# others\n.DS_Store\n.idea/\nwandb/\n__pycache__\n.vscode/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.1572265625,
          "content": "repos:\n  - repo: https://github.com/PyCQA/flake8\n    rev: 4.0.1\n    hooks:\n      - id: flake8\n  - repo: https://github.com/PyCQA/isort.git\n    rev: 5.12.0\n    hooks:\n      - id: isort\n  - repo: https://github.com/pre-commit/mirrors-yapf\n    rev: v0.32.0\n    hooks:\n      - id: yapf\n        exclude: data_juicer/ops/common/special_characters.py\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.3.0\n    hooks:\n      - id: trailing-whitespace\n        exclude: thirdparty/\n      - id: check-yaml\n        exclude: thirdparty/\n      - id: end-of-file-fixer\n        exclude: thirdparty/\n      - id: requirements-txt-fixer\n        exclude: thirdparty/\n      - id: double-quote-string-fixer\n        exclude: ^(thirdparty/|data_juicer/ops/common/special_characters.py)\n      - id: check-merge-conflict\n        exclude: thirdparty/\n      - id: fix-encoding-pragma\n        exclude: thirdparty/\n        args: [ \"--remove\" ]\n      - id: mixed-line-ending\n        exclude: thirdparty/\n        args: [ \"--fix=lf\" ]\n\nexclude: |\n  (?x)^(\n    docs/.*|\n    tests/.*|\n    demos/(?!api_service/).*|\n    tools/mm_eval/inception_metrics/.*|\n    thirdparty/easy_animate/.*|\n    .*\\.md\n  )$\n"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 1.3349609375,
          "content": "# The data-juicer image includes all open-source contents of data-juicer,\n# and it will be instaled in editable mode.\n\nFROM nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04\n\n# install python 3.10\nRUN apt-get update \\\n    && apt-get install -y git curl vim wget python3.10 libpython3.10-dev python3-pip \\\n    && apt-get install -y libgl1-mesa-glx libglib2.0-0 \\\n    && ln -sf /usr/bin/python3.10  /usr/bin/python3 \\\n    && ln -sf /usr/bin/python3.10  /usr/bin/python \\\n    && apt-get autoclean && rm -rf /var/lib/apt/lists/* \\\n    && pip install --upgrade pip\n\n# install 3rd-party system dependencies\nRUN apt-get update \\\n    && apt-get install ffmpeg libsm6 libxext6 software-properties-common build-essential cmake gfortran libopenblas-dev liblapack-dev -y\n\n# prepare the java env\nWORKDIR /opt\n# download jdk\nRUN wget https://aka.ms/download-jdk/microsoft-jdk-17.0.9-linux-x64.tar.gz -O jdk.tar.gz \\\n    && tar -xzf jdk.tar.gz \\\n    && rm -rf jdk.tar.gz \\\n    && mv jdk-17.0.9+8 jdk\n\n# set the environment variable\nENV JAVA_HOME=/opt/jdk\n\nWORKDIR /data-juicer\n\n# install requirements which need to be installed from source\nRUN pip install --upgrade setuptools==69.5.1 setuptools_scm \\\n    && pip install git+https://github.com/xinyu1205/recognize-anything.git --default-timeout 1000\n\n# install data-juicer then\nCOPY . .\nRUN pip install -v -e .[all] --default-timeout 1000\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 20.4150390625,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2023 Alibaba\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n-------------------------------------------------------------------------------\n\nCode in data_juicer/ops/common/helper_func.py, data_juicer/ops/deduplicator/document_deduplicator.py,\ndata_juicer/ops/deduplicator/document_simhash_deduplicator.py, data_juicer/ops/filter/character_repetition_filter.py,\ndata_juicer/ops/filter/flagged_words_filter.py, data_juicer/ops/filter/perplexity_filter.py,\ndata_juicer/ops/filter/special_characters_filter.py, data_juicer/ops/filter/stopwords_filter.py,\ndata_juicer/ops/filter/word_repetition_filter.py, data_juicer/ops/mapper/punctuation_normalization_mapper.py,\ndata_juicer/ops/mapper/remove_long_words_mapper.py, app.py is adapted from\nhttps://huggingface.co/spaces/huggingface/text-data-filtering or\nhttps://github.com/bigscience-workshop/data-preparation\n\n   Copyright [2021] [Bigscience]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n-------------------------------------------------------------------------------\n\nCode in data_juicer/ops/deduplicator/document_minhash_deduplicator.py is\nadapted from\nhttps://github.com/bigcode-project/bigcode-dataset\n\n   Copyright 2022 bigcode authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n-------------------------------------------------------------------------------\n\nCode in data_juicer/ops/mapper/clean_copyright_mapper.py, data_juicer/ops/mapper/clean_html_mapper.py,\ndata_juicer/ops/mapper/expand_macro_mapper.py, data_juicer/ops/mapper/remove_bibliography_mapper.py,\ndata_juicer/ops/mapper/remove_comments_mapper.py, data_juicer/ops/mapper/remove_header_mapper.py,\nis adapted from\nhttps://github.com/togethercomputer/RedPajama-Data/tree/rp_v1/\n\n   Copyright 2023 RedPajama authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n\n-------------------------------------------------------------------------------\n\nThe implementations of gpt_evaluator in tools/evaluator/gpt_eval/gpt_evaluator.py\nis adapted from https://github.com/lm-sys/FastChat (Apache License)\n\nCopyright (c) 2023 The FastChat Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n-----------------------------------------------------\n\n\nThe implementations of checkpoint converter in tools/converter/\nconvert_gpt_to_transformers.py and tools/converter/modeling_megatron_llama.py\nare adapted from https://github.com/huggingface/transformers (Apache License)\n\nCopyright (c) 2022 EleutherAI and the HuggingFace Inc. team.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n-----------------------------------------------------\n\nCode in thirdparty/Megatron-LM\nis adapted from https://github.com/NVIDIA/Megatron-LM\n\n# Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#  * Redistributions of source code must retain the above copyright\n#    notice, this list of conditions and the following disclaimer.\n#  * Redistributions in binary form must reproduce the above copyright\n#    notice, this list of conditions and the following disclaimer in the\n#    documentation and/or other materials provided with the distribution.\n#  * Neither the name of NVIDIA CORPORATION nor the names of its\n#    contributors may be used to endorse or promote products derived\n#    from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n-----------------------------------------------------\n\nCode in thirdparty/helm\nis adapted from https://github.com/stanford-crfm/helm (Apache License)\n\nCopyright (c) 2023 The helm Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n-----------------------------------------------------\n\nCode in tests/run.py is adapted from https://github\n.com/alibaba/FederatedScope/blob/master/tests/run.py (Apache License)\n\nCopyright (c) 2023 The FederatedScope Team\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n-----------------------------------------------------\n\nCode in utils/logger_utils.py is adapted from https://github.com/MegEngine/\nYOLOX/blob/main/yolox/utils/logger.py (Apache License)\n\nCopyright 2021 Megvii, Base Detection\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\n\n-----------------------------------------------------\n\nCode in tools/__init__.py is adapted from\nhttps://github.com/Megvii-BaseDetection/YOLOX/blob/main/yolox/tools/__init__.py\n(Apache License)\n\nCopyright (c) 2021-2022 Megvii Inc. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 31.6845703125,
          "content": "[[中文主页]](README_ZH.md) | [[Docs]](#documents) | [[API]](https://modelscope.github.io/data-juicer) |  [[DJ-SORA]](docs/DJ_SORA.md) | [[Awesome List]](docs/awesome_llm_data.md)\n\n\n# Data-Juicer: A One-Stop Data Processing System for Large Language Models\n\n <img src=\"https://img.alicdn.com/imgextra/i3/O1CN017Eq5kf27AlA2NUKef_!!6000000007757-0-tps-1280-720.jpg\" width = \"640\" height = \"360\" alt=\"Data-Juicer\"/>\n\n![](https://img.shields.io/badge/language-Python-214870.svg)\n![](https://img.shields.io/badge/license-Apache--2.0-000000.svg)\n[![pypi version](https://img.shields.io/pypi/v/py-data-juicer?logo=pypi&color=026cad)](https://pypi.org/project/py-data-juicer)\n[![Docker version](https://img.shields.io/docker/v/datajuicer/data-juicer?logo=docker&label=Docker&color=498bdf)](https://hub.docker.com/r/datajuicer/data-juicer)\n\n[![DataModality](https://img.shields.io/badge/DataModality-Text,Image,Audio,Video-brightgreen.svg)](docs/DeveloperGuide_ZH.md)\n[![Usage](https://img.shields.io/badge/Usage-Cleaning,Generation,Analysis-FFD21E.svg)](docs/DeveloperGuide_ZH.md)\n[![ModelScope- Demos](https://img.shields.io/badge/ModelScope-Demos-4e29ff.svg?logo=data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjI0IDEyMS4zMyIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxwYXRoIGQ9Im0wIDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtOTkuMTQgNzMuNDloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xNzYuMDkgOTkuMTRoLTI1LjY1djIyLjE5aDQ3Ljg0di00Ny44NGgtMjIuMTl6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTEyNC43OSA0Ny44NGgyNS42NXYyNS42NWgtMjUuNjV6IiBmaWxsPSIjMzZjZmQxIiAvPgoJPHBhdGggZD0ibTAgMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xOTguMjggNDcuODRoMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xOTguMjggMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xNTAuNDQgMHYyMi4xOWgyNS42NXYyNS42NWgyMi4xOXYtNDcuODR6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTczLjQ5IDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiMzNmNmZDEiIC8+Cgk8cGF0aCBkPSJtNDcuODQgMjIuMTloMjUuNjV2LTIyLjE5aC00Ny44NHY0Ny44NGgyMi4xOXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtNDcuODQgNzMuNDloLTIyLjE5djQ3Ljg0aDQ3Ljg0di0yMi4xOWgtMjUuNjV6IiBmaWxsPSIjNjI0YWZmIiAvPgo8L3N2Zz4K)](https://modelscope.cn/studios?name=Data-Jiucer&page=1&sort=latest&type=1)\n[![HuggingFace- Demos](https://img.shields.io/badge/🤗HuggingFace-Demos-4e29ff.svg)](https://huggingface.co/spaces?&search=datajuicer)\n\n\n\n[![Document_List](https://img.shields.io/badge/Docs-English-blue?logo=Markdown)](#documents)\n[![文档列表](https://img.shields.io/badge/文档-中文-blue?logo=Markdown)](README_ZH.md#documents)\n[![API Reference](https://img.shields.io/badge/Docs-API_Reference-blue?logo=Markdown)](https://modelscope.github.io/data-juicer/)\n[![Paper](http://img.shields.io/badge/cs.LG-arXiv%3A2309.02033-B31B1B?logo=arxiv&logoColor=red)](https://arxiv.org/abs/2309.02033)\n\n\n\n\nData-Juicer is a one-stop **multimodal** data processing system to make data higher-quality,\njuicier, and more digestible for LLMs.\n\n\nWe provide a [playground](http://8.138.149.181/) with a managed JupyterLab. [Try Data-Juicer](http://8.138.149.181/) straight away in your browser! If you find Data-Juicer useful for your research or development, please kindly cite our [work](#references).\n\n[Platform for AI of Alibaba Cloud (PAI)](https://www.aliyun.com/product/bigdata/learn) has cited our work and integrated Data-Juicer into its data processing products. PAI is an AI Native large model and AIGC engineering platform that provides dataset management, computing power management, model tool chain, model development, model training, model deployment, and AI asset management. For documentation on data processing, please refer to: [PAI-Data Processing for Large Models](https://help.aliyun.com/zh/pai/user-guide/components-related-to-data-processing-for-foundation-models/?spm=a2c4g.11186623.0.0.3e9821a69kWdvX).\n\nData-Juicer is being actively updated and maintained. We will periodically enhance and add more features, data recipes and datasets. \nWe welcome you to join us (via issues, PRs, [Slack](https://join.slack.com/t/data-juicer/shared_invite/zt-23zxltg9d-Z4d3EJuhZbCLGwtnLWWUDg?spm=a2c22.12281976.0.0.7a8253f30mgpjw)  channel, [DingDing](https://qr.dingtalk.com/action/joingroup?code=v1,k1,YFIXM2leDEk7gJP5aMC95AfYT+Oo/EP/ihnaIEhMyJM=&_dt_no_comment=1&origin=11) group, ...), in promoting data-model co-development along with research and applications of (multimodal) LLMs!\n\n----\n\n## News\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-08-09] We propose Img-Diff, which enhances the performance of multimodal large language models through *contrastive data synthesis*, achieving a score that is 12 points higher than GPT-4V on the [MMVP benchmark](https://tsb0601.github.io/mmvp_blog/). See more details in our [paper](https://arxiv.org/abs/2408.04594), and download the dataset from [huggingface](https://huggingface.co/datasets/datajuicer/Img-Diff) and [modelscope](https://modelscope.cn/datasets/Data-Juicer/Img-Diff).\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-07-24] \"Tianchi Better Synth Data Synthesis Competition for Multimodal Large Models\" — Our 4th data-centric LLM competition has kicked off! Please visit the competition's [official website](https://tianchi.aliyun.com/competition/entrance/532251) for more information.\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-07-17] We utilized the Data-Juicer [Sandbox Laboratory Suite](https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md) to systematically optimize data and models through a co-development workflow between data and models, achieving a new top spot on the [VBench](https://huggingface.co/spaces/Vchitect/VBench_Leaderboard) text-to-video leaderboard. The related achievements have been compiled and published in a [paper](http://arxiv.org/abs/2407.11784), and the model has been released on the [ModelScope](https://modelscope.cn/models/Data-Juicer/Data-Juicer-T2V) and [HuggingFace](https://huggingface.co/datajuicer/Data-Juicer-T2V) platforms.\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-07-12] Our *awesome list of MLLM-Data* has evolved into a systemic [survey](https://arxiv.org/abs/2407.08583) from model-data co-development perspective. Welcome to [explore](docs/awesome_llm_data.md) and contribute!\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-06-01] ModelScope-Sora \"Data Directors\" creative sprint—Our third data-centric LLM competition has kicked off! Please visit the competition's [official website](https://tianchi.aliyun.com/competition/entrance/532219) for more information.\n\n<details>\n<summary> History News:\n</summary>>\n\n- [2024-03-07] We release **Data-Juicer [v0.2.0](https://github.com/alibaba/data-juicer/releases/tag/v0.2.0)** now! \nIn this new version, we support more features for **multimodal data (including video now)**, and introduce **[DJ-SORA](docs/DJ_SORA.md)** to provide open large-scale, high-quality datasets for SORA-like models.\n- [2024-02-20] We have actively maintained an *awesome list of LLM-Data*, welcome to [visit](docs/awesome_llm_data.md) and contribute!\n- [2024-02-05] Our paper has been accepted by SIGMOD'24 industrial track!\n- [2024-01-10] Discover new horizons in \"Data Mixture\"—Our second data-centric LLM competition has kicked off! Please visit the competition's [official website](https://tianchi.aliyun.com/competition/entrance/532174) for more information.\n- [2024-01-05] We release **Data-Juicer v0.1.3** now!\nIn this new version, we support **more Python versions** (3.8-3.10), and support **multimodal** dataset [converting](tools/fmt_conversion/multimodal/README.md)/[processing](docs/Operators.md) (Including texts, images, and audios. More modalities will be supported in the future).\nBesides, our paper is also updated to [v3](https://arxiv.org/abs/2309.02033).\n- [2023-10-13] Our first data-centric LLM competition begins! Please\n  visit the competition's official websites, FT-Data Ranker ([1B Track](https://tianchi.aliyun.com/competition/entrance/532157), [7B Track](https://tianchi.aliyun.com/competition/entrance/532158)), for more information.\n</details>\n\n\n<div id=\"table\" align=\"center\"></div>\n\nTable of Contents\n=================\n\n- [Data-Juicer:  A One-Stop Data Processing System for Large Language Models](#data-juicer--a-one-stop-data-processing-system-for-large-language-models)\n  - [News](#news)\n- [Table of Contents](#table-of-contents)\n  - [Features](#features)\n  - [Documentation Index ](#documentation-index-)\n  - [Demos](#demos)\n  - [Prerequisites](#prerequisites)\n  - [Installation](#installation)\n    - [From Source](#from-source)\n    - [Using pip](#using-pip)\n    - [Using Docker](#using-docker)\n    - [Installation check](#installation-check)\n  - [Quick Start](#quick-start)\n    - [Data Processing](#data-processing)\n    - [Distributed Data Processing](#distributed-data-processing)\n    - [Data Analysis](#data-analysis)\n    - [Data Visualization](#data-visualization)\n    - [Build Up Config Files](#build-up-config-files)\n    - [Sandbox](#sandbox)\n    - [Preprocess Raw Data (Optional)](#preprocess-raw-data-optional)\n    - [For Docker Users](#for-docker-users)\n  - [Data Recipes](#data-recipes)\n  - [License](#license)\n  - [Contributing](#contributing)\n  - [Acknowledgement](#acknowledgement)\n  - [References](#references)\n\n\n## Features\n\n![Overview](https://img.alicdn.com/imgextra/i4/O1CN01WYQP3Z1JHsaXaQDK6_!!6000000001004-0-tps-3640-1812.jpg)\n\n- **Systematic & Reusable**:\n  Empowering users with a systematic library of 80+ core [OPs](docs/Operators.md), 20+ reusable [config recipes](configs), and 20+ feature-rich\n  dedicated [toolkits](#documentation), designed to\n  function independently of specific multimodal LLM datasets and processing pipelines.\n\n- **Data-in-the-loop & Sandbox**: Supporting one-stop data-model collaborative development, enabling rapid iteration\n  through the [sandbox laboratory](docs/Sandbox.md), and providing features such as feedback loops based on data and model,\n  visualization, and multidimensional automatic evaluation, so that you can better understand and improve your data and models.\n  ![Data-in-the-loop](https://img.alicdn.com/imgextra/i2/O1CN017U7Zz31Y7XtCJ5GOz_!!6000000003012-0-tps-3640-1567.jpg)\n\n- **Towards production environment**: Providing efficient and parallel data processing pipelines (Aliyun-PAI\\Ray\\Slurm\\CUDA\\OP Fusion)\n  requiring less memory and CPU usage, optimized with automatic fault-toleration.\n  ![sys-perf](https://img.alicdn.com/imgextra/i4/O1CN01Sk0q2U1hdRxbnQXFg_!!6000000004300-0-tps-2438-709.jpg)\n\n- **Comprehensive Data Processing Recipes**: Offering tens of [pre-built data\n  processing recipes](configs/data_juicer_recipes/README.md) for pre-training, fine-tuning, en, zh, and more scenarios. Validated on\n  reference LLaMA and LLaVA models.\n  ![exp_llama](https://img.alicdn.com/imgextra/i2/O1CN019WtUPP1uhebnDlPR8_!!6000000006069-2-tps-2530-1005.png)\n\n- **Flexible & Extensible**: Accommodating most types of data formats (e.g., jsonl, parquet, csv, ...) and allowing flexible combinations of OPs. Feel free to [implement your own OPs](docs/DeveloperGuide.md#build-your-own-ops) for customizable data processing.\n\n- **User-Friendly Experience**: Designed for simplicity, with [comprehensive documentation](#documents), [easy start guides](#quick-start) and [demo configs](configs/README.md), and intuitive configuration with simple adding/removing OPs from [existing configs](configs/config_all.yaml).\n\n\n\n## Documentation Index <a name=\"documents\"/>\n\n- [Overview](README.md)\n- [Operator Zoo](docs/Operators.md)\n- [Configs](configs/README.md)\n- [Developer Guide](docs/DeveloperGuide.md)\n- [API references](https://modelscope.github.io/data-juicer/)\n- [KDD-Tutorial](https://modelscope.github.io/data-juicer/_static/tutorial_kdd24.html)\n- [\"Bad\" Data Exhibition](docs/BadDataExhibition.md)\n- [Awesome LLM-Data](docs/awesome_llm_data.md)\n- Dedicated Toolkits\n  - [Quality Classifier](tools/quality_classifier/README.md)\n  - [Auto Evaluation](tools/evaluator/README.md)\n  - [Preprocess](tools/preprocess/README.md)\n  - [Postprocess](tools/postprocess/README.md)\n- [DJ-SORA](docs/DJ_SORA.md)\n- [Third-parties (LLM Ecosystems)](thirdparty/README.md)\n\n\n## Demos\n- Introduction to Data-Juicer [[ModelScope](https://modelscope.cn/studios/Data-Juicer/overview_scan/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/overview_scan)]\n- Data Visualization:\n  - Basic Statistics [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_statistics/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_statistics)]\n  - Lexical Diversity [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_diversity/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_diversity)]\n  - Operator Insight (Single OP) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visualization_op_insight/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_op_insight)]\n  - Operator Effect (Multiple OPs) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_op_effect/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_op_effect)]\n- Data Processing:\n  - Scientific Literature (e.g. [arXiv](https://info.arxiv.org/help/bulk_data_s3.html)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_sci_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_sci_data)]\n  - Programming Code (e.g. [TheStack](https://huggingface.co/datasets/bigcode/the-stack)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_code_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_code_data)]\n  - Chinese Instruction Data (e.g. [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_sft_zh_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_cft_zh_data)]\n- Tool Pool:\n  - Dataset Splitting by Language [[ModelScope](https://modelscope.cn/studios/Data-Juicer/tool_dataset_splitting_by_language/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/tool_dataset_splitting_by_language)]\n  - Quality Classifier for CommonCrawl [[ModelScope](https://modelscope.cn/studios/Data-Juicer/tool_quality_classifier/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/tool_quality_classifier)]\n  - Auto Evaluation on [HELM](https://github.com/stanford-crfm/helm) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/auto_evaluation_helm/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/auto_evaluation_helm)]\n  - Data Sampling and Mixture [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_mixture/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_mixture)]\n- Data Processing Loop [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_process_loop/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_process_loop)]\n\n## Prerequisites\n\n- Recommend Python>=3.9,<=3.10\n- gcc >= 5 (at least C++14 support)\n\n## Installation\n\n### From Source \n\n- Run the following commands to install the latest basic `data_juicer` version in\n  editable mode:\n```shell\ncd <path_to_data_juicer>\npip install -v -e .\n```\n\n- Some OPs rely on some other too large or low-platform-compatibility third-party libraries. You can install optional dependencies as needed:\n\n```shell\ncd <path_to_data_juicer>\npip install -v -e .  # install a minimal dependencies, which support the basic functions\npip install -v -e .[tools] # install a subset of tools dependencies\n```\n\nThe dependency options are listed below:\n\n| Tag              | Description                                                                                  |\n|------------------|----------------------------------------------------------------------------------------------|\n| `.` or `.[mini]` | Install minimal dependencies for basic Data-Juicer.                                          |\n| `.[all]`         | Install all dependencies except sandbox.                                                     |\n| `.[sci]`         | Install all dependencies for all OPs.                                                        |\n| `.[dist]`        | Install dependencies for distributed data processing. (Experimental)                         |\n| `.[dev]`         | Install dependencies for developing the package as contributors.                             |\n| `.[tools]`       | Install dependencies for dedicated tools, such as quality classifiers.                       |\n| `.[sandbox]`     | Install all dependencies for sandbox.                                                        |\n\n- Install dependencies for specific OPs\n\nWith the growth of the number of OPs, the dependencies of all OPs becomes very heavy. Instead of using the command `pip install -v -e .[sci]` to install all dependencies,\nwe provide two alternative, lighter options:\n\n  - Automatic Minimal Dependency Installation: During the execution of Data-Juicer, minimal dependencies will be automatically installed. This allows for immediate execution, but may potentially lead to dependency conflicts.\n\n  - Manual Minimal Dependency Installation: To manually install minimal dependencies tailored to a specific execution configuration, run the following command:\n    ```shell\n    # only for installation from source\n    python tools/dj_install.py --config path_to_your_data-juicer_config_file\n\n    # use command line tool\n    dj-install --config path_to_your_data-juicer_config_file\n    ```\n\n### Using pip\n\n- Run the following command to install the latest released `data_juicer` using `pip`:\n\n```shell\npip install py-data-juicer\n```\n\n- **Note**:\n  - only the basic APIs in `data_juicer` and two basic tools\n    (data [processing](#data-processing) and [analysis](#data-analysis)) are available in this way. If you want customizable\n    and complete functions, we recommend you install `data_juicer` [from source](#from-source).\n  - The release versions from pypi have a certain lag compared to the latest version from source.\n    So if you want to follow the latest functions of `data_juicer`, we recommend you install [from source](#from-source).\n\n### Using Docker\n\n- You can\n  - either pull our pre-built image from DockerHub:\n    ```shell\n    docker pull datajuicer/data-juicer:<version_tag>\n    ```\n\n  - or run the following command to build the docker image including the\n    latest `data-juicer` with provided [Dockerfile](Dockerfile):\n\n    ```shell\n    docker build -t datajuicer/data-juicer:<version_tag> .\n    ```\n\n  - The format of `<version_tag>` is like `v0.2.0`, which is the same as release version tag.\n\n### Installation check\n\n```python\nimport data_juicer as dj\nprint(dj.__version__)\n```\n\n### For Video-related Operators\nBefore using video-related operators, **FFmpeg** should be installed and accessible via the $PATH environment variable.\n\nYou can install FFmpeg using package managers(e.g. sudo apt install ffmpeg on Debian/Ubuntu, brew install ffmpeg on OS X) or visit the [official ffmpeg link](https://ffmpeg.org/download.html).\n\nCheck if your environment path is set correctly by running the ffmpeg command from the terminal.\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>\n\n\n## Quick Start\n\n\n### Data Processing\n\n- Run `process_data.py` tool or `dj-process` command line tool with your config as the argument to process\n  your dataset.\n\n```shell\n# only for installation from source\npython tools/process_data.py --config configs/demo/process.yaml\n\n# use command line tool\ndj-process --config configs/demo/process.yaml\n```\n\n- **Note:** For some operators that involve third-party models or resources which are not stored locally on your computer, it might be slow for the first running because these ops need to download corresponding resources into a directory first.\nThe default download cache directory is `~/.cache/data_juicer`. Change the cache location by setting the shell environment variable, `DATA_JUICER_CACHE_HOME` to another directory, and you can also change `DATA_JUICER_MODELS_CACHE` or `DATA_JUICER_ASSETS_CACHE` in the same way:\n\n- **Note:** When using operators with third-party models, it's necessary to declare the corresponding `mem_required` in the configuration file (you can refer to the settings in the `config_all.yaml` file). During runtime, Data-Juicer will control the number of processes based on memory availability and the memory requirements of the operator models to achieve better data processing efficiency. When running with CUDA environment, if the mem_required for an operator is not declared correctly, it could potentially lead to a CUDA Out of Memory issue.\n\n```shell\n# cache home\nexport DATA_JUICER_CACHE_HOME=\"/path/to/another/directory\"\n# cache models\nexport DATA_JUICER_MODELS_CACHE=\"/path/to/another/directory/models\"\n# cache assets\nexport DATA_JUICER_ASSETS_CACHE=\"/path/to/another/directory/assets\"\n```\n\n#### Flexible Programming Interface\nWe provide various simple interfaces for users to choose from as follows. \n```python\n#... init op & dataset ...\n\n# Chain call style, support single operator or operator list\ndataset = dataset.process(op)\ndataset = dataset.process([op1, op2])\n# Functional programming style for quick integration or script prototype iteration\ndataset = op(dataset)\ndataset = op.run(dataset)\n```\n\n\n### Distributed Data Processing\n\nWe have now implemented multi-machine distributed data processing based on [RAY](https://www.ray.io/). The corresponding demos can be run using the following commands:\n\n```shell\n# Run text data processing\npython tools/process_data.py --config ./demos/process_on_ray/configs/demo.yaml\n# Run video data processing\npython tools/process_data.py --config ./demos/process_video_on_ray/configs/demo.yaml\n```\n\n- To run data processing across multiple machines, it is necessary to ensure that all distributed nodes can access the corresponding data paths (for example, by mounting the respective data paths on a file-sharing system such as NAS).\n- The deduplicator operators for RAY mode are different from the single-machine version, and all those operators are prefixed with `ray`, e.g. `ray_video_deduplicator` and `ray_document_deduplicator`. Those operators also rely on a [Redis](https://redis.io/) instance. So in addition to starting the RAY cluster, you also need to setup your Redis instance in advance and provide `host` and `port` of your Redis instance in configuration.\n\n> Users can also opt not to use RAY and instead split the dataset to run on a cluster with [Slurm](https://slurm.schedmd.com/). In this case, please use the default Data-Juicer without RAY.\n> [Aliyun PAI-DLC](https://www.aliyun.com/activity/bigdata/pai-dlc) supports the RAY framework, Slurm framework, etc. Users can directly create RAY jobs and Slurm jobs on the DLC cluster.\n\n### Data Analysis\n- Run `analyze_data.py` tool or `dj-analyze` command line tool with your config as the argument to analyze your dataset.\n\n```shell\n# only for installation from source\npython tools/analyze_data.py --config configs/demo/analyzer.yaml\n\n# use command line tool\ndj-analyze --config configs/demo/analyzer.yaml\n\n# you can also use auto mode to avoid writing a recipe. It will analyze a small\n# part (e.g. 1000 samples, specified by argument `auto_num`) of your dataset \n# with all Filters that produce stats.\ndj-analyze --auto --dataset_path xx.jsonl [--auto_num 1000]\n```\n\n- **Note:** Analyzer only compute stats for Filters that produce stats or other OPs that produce tags/categories in meta. So other OPs will be ignored in the analysis process. We use the following registries to decorate OPs:\n  - `NON_STATS_FILTERS`: decorate Filters that **DO NOT** produce any stats.\n  - `TAGGING_OPS`: decorate OPs that **DO** produce tags/categories in meta field.\n\n### Data Visualization\n\n- Run `app.py` tool to visualize your dataset in your browser.\n- **Note**: only available for installation from source.\n\n```shell\nstreamlit run app.py\n```\n\n### Build Up Config Files\n\n- Config files specify some global arguments, and an operator list for the\n  data process. You need to set:\n  - Global arguments: input/output dataset path, number of workers, etc.\n  - Operator list: list operators with their arguments used to process the dataset.\n- You can build up your own config files by:\n  - ➖：Modify from our example config file [`config_all.yaml`](configs/config_all.yaml) which includes **all** ops and default\n    arguments. You just need to **remove** ops that you won't use and refine\n    some arguments of ops.\n  - ➕：Build up your own config files **from scratch**. You can refer our\n    example config file [`config_all.yaml`](configs/config_all.yaml), [op documents](docs/Operators.md), and advanced [Build-Up Guide for developers](docs/DeveloperGuide.md#build-your-own-configs).\n  - Besides the yaml files, you also have the flexibility to specify just\n    one (of several) parameters on the command line, which will override\n    the values in yaml files.\n\n```shell\npython xxx.py --config configs/demo/process.yaml --language_id_score_filter.lang=en\n```\n\n- The basic config format and definition is shown below.\n\n  ![Basic config example of format and definition](https://img.alicdn.com/imgextra/i1/O1CN01uXgjgj1khWKOigYww_!!6000000004715-0-tps-1745-871.jpg \"Basic config file example\")\n\n### Sandbox\n\nThe data sandbox laboratory (DJ-Sandbox) provides users with the best practices for continuously producing data recipes. It features low overhead, portability, and guidance.\n\n- In the sandbox, users can quickly experiment, iterate, and refine data recipes based on small-scale datasets and models, before scaling up to produce high-quality data to serve large-scale models.\n- In addition to the basic data optimization and recipe refinement features offered by Data-Juicer, users can seamlessly use configurable components such as data probe and analysis, model training and evaluation, and data and model feedback-based recipe refinement to form a complete one-stop data-model research and development pipeline.\n\nThe sandbox is run using the following commands by default, and for more information and details, please refer to the [sandbox documentation](docs/Sandbox.md).\n```shell\npython tools/sandbox_starter.py --config configs/demo/sandbox/sandbox.yaml\n```\n\n### Preprocess Raw Data (Optional)\n- Our formatters support some common input dataset formats for now:\n  - Multi-sample in one file: jsonl/json, parquet, csv/tsv, etc.\n  - Single-sample in one file: txt, code, docx, pdf, etc.\n- However, data from different sources are complicated and diverse. Such as:\n  - [Raw arXiv data downloaded from S3](https://info.arxiv.org/help/bulk_data_s3.html) include thousands of tar files and even more gzip files in them, and expected tex files are embedded in the gzip files so they are hard to obtain directly.\n  - Some crawled data include different kinds of files (pdf, html, docx, etc.). And extra information like tables, charts, and so on is hard to extract.\n- It's impossible to handle all kinds of data in Data-Juicer, issues/PRs are welcome to contribute to process new data types!\n- Thus, we provide some **common preprocessing tools** in [`tools/preprocess`](tools/preprocess/) for you to preprocess these data.\n  - You are welcome to make your contributions to new preprocessing tools for the community.\n  - We **highly recommend** that complicated data can be preprocessed to jsonl or parquet files.\n\n### For Docker Users\n\n- If you build or pull the docker image of `data-juicer`, you can run the commands or tools mentioned above using this docker image.\n- Run directly:\n\n```shell\n# run the data processing directly\ndocker run --rm \\  # remove container after the processing\n  --privileged \\\n  --shm-size 256g \\\n  --network host \\\n  --gpus all \\\n  --name dj \\  # name of the container\n  -v <host_data_path>:<image_data_path> \\  # mount data or config directory into the container\n  -v ~/.cache/:/root/.cache/ \\  # mount the cache directory into the container to reuse caches and models (recommended)\n  datajuicer/data-juicer:<version_tag> \\  # image to run\n  dj-process --config /path/to/config.yaml  # similar data processing commands\n```\n\n- Or enter into the running container and run commands in editable mode:\n\n```shell\n# start the container\ndocker run -dit \\  # run the container in the background\n  --privileged \\\n  --shm-size 256g \\\n  --network host \\\n  --gpus all \\\n  --rm \\\n  --name dj \\\n  -v <host_data_path>:<image_data_path> \\\n  -v ~/.cache/:/root/.cache/ \\\n  datajuicer/data-juicer:latest /bin/bash\n\n# enter into this container and then you can use data-juicer in editable mode\ndocker exec -it <container_id> bash\n```\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>\n\n## Data Recipes\n- [Recipes for data process in BLOOM](configs/reproduced_bloom/README.md)\n- [Recipes for data process in RedPajama](configs/redpajama/README.md)\n- [Refined recipes for pre-training text data](configs/data_juicer_recipes/README.md)\n- [Refined recipes for fine-tuning text data](configs/data_juicer_recipes/README.md#before-and-after-refining-for-alpaca-cot-dataset)\n- [Refined recipes for pre-training multi-modal data](configs/data_juicer_recipes/README.md#before-and-after-refining-for-multimodal-dataset)\n\n\n\n## License\nData-Juicer is released under Apache License 2.0.\n\n## Contributing\nWe are in a rapidly developing field and greatly welcome contributions of new\nfeatures, bug fixes and better documentations. Please refer to\n[How-to Guide for Developers](docs/DeveloperGuide.md).\n\nIf you have any questions, please join our [discussion groups](README.md).\n\n## Acknowledgement\nData-Juicer is used across various LLM products and research initiatives,\nincluding industrial LLMs from Alibaba Cloud's Tongyi, such as Dianjin for\nfinancial analysis, and Zhiwen for reading assistant, as well as the Alibaba\nCloud's platform for AI (PAI).\nWe look forward to more of your experience, suggestions and discussions for collaboration!\n\nData-Juicer thanks and refers to several community projects, such as\n[Huggingface-Datasets](https://github.com/huggingface/datasets), [Bloom](https://huggingface.co/bigscience/bloom), [RedPajama](https://github.com/togethercomputer/RedPajama-Data/tree/rp_v1), [Pile](https://huggingface.co/datasets/EleutherAI/pile), [Alpaca-Cot](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [DeepSpeed](https://www.deepspeed.ai/), [Arrow](https://github.com/apache/arrow), [Ray](https://github.com/ray-project/ray), [Beam](https://github.com/apache/beam),  [LM-Harness](https://github.com/EleutherAI/lm-evaluation-harness), [HELM](https://github.com/stanford-crfm/helm), ....\n\n\n\n## References\nIf you find our work useful for your research or development, please kindly cite the following [paper](https://arxiv.org/abs/2309.02033).\n```\n@inproceedings{chen2024datajuicer,\n  title={Data-Juicer: A One-Stop Data Processing System for Large Language Models},\n  author={Daoyuan Chen and Yilun Huang and Zhijian Ma and Hesen Chen and Xuchen Pan and Ce Ge and Dawei Gao and Yuexiang Xie and Zhaoyang Liu and Jinyang Gao and Yaliang Li and Bolin Ding and Jingren Zhou},\n  booktitle={International Conference on Management of Data},\n  year={2024}\n}\n```\n\n<details>\n<summary> More related papers from Data-Juicer Team:\n</summary>>\n\n- [Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development](https://arxiv.org/abs/2407.11784)\n\n- [The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective](https://arxiv.org/abs/2407.08583)\n\n- [ImgDiff: Contrastive Data Synthesis for Vision Large Language Models](https://arxiv.org/abs/2408.04594)\n\n- [Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model Pretraining](https://arxiv.org/abs/2405.14908)\n\n</details>\n\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>\n"
        },
        {
          "name": "README_ZH.md",
          "type": "blob",
          "size": 29.9462890625,
          "content": "[[English Page]](README.md) | [[文档索引]](#documents) | [[API]](https://modelscope.github.io/data-juicer) | [[DJ-SORA]](docs/DJ_SORA_ZH.md) | [[Awesome List]](docs/awesome_llm_data.md)\n\n# Data-Juicer: 为大模型提供更高质量、更丰富、更易“消化”的数据\n\n <img src=\"https://img.alicdn.com/imgextra/i3/O1CN017Eq5kf27AlA2NUKef_!!6000000007757-0-tps-1280-720.jpg\" width = \"640\" height = \"360\" alt=\"Data-Juicer\"/>\n\n![](https://img.shields.io/badge/language-Python-214870.svg)\n![](https://img.shields.io/badge/license-Apache--2.0-000000.svg)\n[![pypi version](https://img.shields.io/pypi/v/py-data-juicer?logo=pypi&color=026cad)](https://pypi.org/project/py-data-juicer)\n[![Docker version](https://img.shields.io/docker/v/datajuicer/data-juicer?logo=docker&label=Docker&color=498bdf)](https://hub.docker.com/r/datajuicer/data-juicer)\n\n[![DataModality](https://img.shields.io/badge/DataModality-Text,Image,Audio,Video-brightgreen.svg)](docs/DeveloperGuide_ZH.md)\n[![Usage](https://img.shields.io/badge/Usage-Cleaning,Generation,Analysis-FFD21E.svg)](docs/DeveloperGuide_ZH.md)\n[![ModelScope- Demos](https://img.shields.io/badge/ModelScope-Demos-4e29ff.svg?logo=data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjI0IDEyMS4zMyIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxwYXRoIGQ9Im0wIDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtOTkuMTQgNzMuNDloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xNzYuMDkgOTkuMTRoLTI1LjY1djIyLjE5aDQ3Ljg0di00Ny44NGgtMjIuMTl6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTEyNC43OSA0Ny44NGgyNS42NXYyNS42NWgtMjUuNjV6IiBmaWxsPSIjMzZjZmQxIiAvPgoJPHBhdGggZD0ibTAgMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xOTguMjggNDcuODRoMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzYyNGFmZiIgLz4KCTxwYXRoIGQ9Im0xOTguMjggMjIuMTloMjUuNjV2MjUuNjVoLTI1LjY1eiIgZmlsbD0iIzM2Y2ZkMSIgLz4KCTxwYXRoIGQ9Im0xNTAuNDQgMHYyMi4xOWgyNS42NXYyNS42NWgyMi4xOXYtNDcuODR6IiBmaWxsPSIjNjI0YWZmIiAvPgoJPHBhdGggZD0ibTczLjQ5IDQ3Ljg0aDI1LjY1djI1LjY1aC0yNS42NXoiIGZpbGw9IiMzNmNmZDEiIC8+Cgk8cGF0aCBkPSJtNDcuODQgMjIuMTloMjUuNjV2LTIyLjE5aC00Ny44NHY0Ny44NGgyMi4xOXoiIGZpbGw9IiM2MjRhZmYiIC8+Cgk8cGF0aCBkPSJtNDcuODQgNzMuNDloLTIyLjE5djQ3Ljg0aDQ3Ljg0di0yMi4xOWgtMjUuNjV6IiBmaWxsPSIjNjI0YWZmIiAvPgo8L3N2Zz4K)](https://modelscope.cn/studios?name=Data-Jiucer&page=1&sort=latest&type=1)\n[![HuggingFace- Demos](https://img.shields.io/badge/🤗HuggingFace-Demos-4e29ff.svg)](https://huggingface.co/spaces?&search=datajuicer)\n\n[![Document_List](https://img.shields.io/badge/Docs-English-blue?logo=Markdown)](README.md#documents)\n[![文档列表](https://img.shields.io/badge/文档-中文-blue?logo=Markdown)](#documents)\n[![API Reference](https://img.shields.io/badge/Docs-API_Reference-blue?logo=Markdown)](https://modelscope.github.io/data-juicer/)\n[![Paper](http://img.shields.io/badge/cs.LG-arXiv%3A2309.02033-B31B1B?logo=arxiv&logoColor=red)](https://arxiv.org/abs/2309.02033)\n\n\nData-Juicer 是一个一站式**多模态**数据处理系统，旨在为大语言模型 (LLM) 提供更高质量、更丰富、更易“消化”的数据。\n\n\n我们提供了一个基于 JupyterLab 的 [Playground](http://8.138.149.181/)，您可以从浏览器中在线试用 Data-Juicer。 如果Data-Juicer对您的研发有帮助，请引用我们的[工作](#参考文献) 。\n\n[阿里云人工智能平台 PAI](https://www.aliyun.com/product/bigdata/learn) 已引用我们的工作，将Data-Juicer的能力集成到PAI的数据处理产品中。PAI提供包含数据集管理、算力管理、模型工具链、模型开发、模型训练、模型部署、AI资产管理在内的功能模块，为用户提供高性能、高稳定、企业级的大模型工程化能力。数据处理的使用文档请参考：[PAI-大模型数据处理](https://help.aliyun.com/zh/pai/user-guide/components-related-to-data-processing-for-foundation-models/?spm=a2c4g.11186623.0.0.3e9821a69kWdvX)。\n\nData-Juicer正在积极更新和维护中，我们将定期强化和新增更多的功能和数据菜谱。热烈欢迎您加入我们（issues/PRs/[Slack频道](https://join.slack.com/t/data-juicer/shared_invite/zt-23zxltg9d-Z4d3EJuhZbCLGwtnLWWUDg?spm=a2c22.12281976.0.0.7a8275bc8g7ypp) /[钉钉群](https://qr.dingtalk.com/action/joingroup?code=v1,k1,YFIXM2leDEk7gJP5aMC95AfYT+Oo/EP/ihnaIEhMyJM=&_dt_no_comment=1&origin=11)/...），一起推进LLM-数据的协同开发和研究！\n\n\n----\n\n## 新消息\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-08-09] 我们提出了Img-Diff，它通过*对比数据合成*来增强多模态大型语言模型的性能，在[MMVP benchmark](https://tsb0601.github.io/mmvp_blog/)中比GPT-4V高出12个点。 更多细节请参阅我们的 [论文](https://arxiv.org/abs/2408.04594), 以及从 [huggingface](https://huggingface.co/datasets/datajuicer/Img-Diff) 和 [modelscope](https://modelscope.cn/datasets/Data-Juicer/Img-Diff)下载这份数据集。\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-07-24] “天池 Better Synth 多模态大模型数据合成赛”——第四届Data-Juicer大模型数据挑战赛已经正式启动！立即访问[竞赛官网](https://tianchi.aliyun.com/competition/entrance/532251)，了解赛事详情。\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png)[2024-07-17] 我们利用Data-Juicer[沙盒实验室套件](https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox-ZH.md)，通过数据与模型间的系统性研发工作流，调优数据和模型，在[VBench](https://huggingface.co/spaces/Vchitect/VBench_Leaderboard)文生视频排行榜取得了新的榜首。相关成果已经整理发表在[论文](http://arxiv.org/abs/2407.11784)中，并且模型已在[ModelScope](https://modelscope.cn/models/Data-Juicer/Data-Juicer-T2V)和[HuggingFace](https://huggingface.co/datajuicer/Data-Juicer-T2V)平台发布。\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png)[2024-07-12] 我们的MLLM-Data精选列表已经演化为一个模型-数据协同开发的角度系统性[综述](https://arxiv.org/abs/2407.08583)。欢迎[浏览](docs/awesome_llm_data.md)或参与贡献!\n- ![new](https://img.alicdn.com/imgextra/i4/O1CN01kUiDtl1HVxN6G56vN_!!6000000000764-2-tps-43-19.png) [2024-06-01] ModelScope-Sora“数据导演”创意竞速——第三届Data-Juicer大模型数据挑战赛已经正式启动！立即访问[竞赛官网](https://tianchi.aliyun.com/competition/entrance/532219)，了解赛事详情。\n<details>\n<summary> History News:\n</summary>>\n\n- [2024-03-07] 我们现在发布了 **Data-Juicer [v0.2.0](https://github.com/alibaba/data-juicer/releases/tag/v0.2.0)**! 在这个新版本中，我们支持了更多的 **多模态数据(包括视频)** 相关特性。我们还启动了 **[DJ-SORA](docs/DJ_SORA_ZH.md)** ，为SORA-like大模型构建开放的大规模高质量数据集！\n- [2024-02-20] 我们在积极维护一份关于LLM-Data的*精选列表*，欢迎[访问](docs/awesome_llm_data.md)并参与贡献！\n- [2024-02-05] 我们的论文被SIGMOD'24 industrial track接收！\n- [2024-01-10] 开启“数据混合”新视界——第二届Data-Juicer大模型数据挑战赛已经正式启动！立即访问[竞赛官网](https://tianchi.aliyun.com/competition/entrance/532174)，了解赛事详情。\n- [2024-01-05] **Data-Juicer v0.1.3** 版本发布了。 \n在这个新版本中，我们支持了**更多Python版本**（3.8-3.10），同时支持了**多模态**数据集的[转换](tools/fmt_conversion/multimodal/README_ZH.md)和[处理](docs/Operators_ZH.md)（包括文本、图像和音频。更多模态也将会在之后支持）！\n此外，我们的论文也更新到了[第三版](https://arxiv.org/abs/2309.02033) 。\n- [2023-10-13] 我们的第一届以数据为中心的 LLM 竞赛开始了！\n  请访问大赛官网，FT-Data Ranker（[1B赛道](https://tianchi.aliyun.com/competition/entrance/532157) 、[7B赛道](https://tianchi.aliyun.com/competition/entrance/532158) ) ，了解更多信息。\n</details>\n\n\n<div id=\"table\" align=\"center\"></div>\n\n目录\n===\n- [Data-Juicer: 为大语言模型提供更高质量、更丰富、更易“消化”的数据](#data-juicer-为大语言模型提供更高质量更丰富更易消化的数据)\n  - [新消息](#新消息)\n- [目录](#目录)\n  - [特点](#特点)\n  - [文档索引 ](#文档索引-)\n  - [演示样例](#演示样例)\n  - [前置条件](#前置条件)\n  - [安装](#安装)\n    - [从源码安装](#从源码安装)\n    - [使用 pip 安装](#使用-pip-安装)\n    - [使用 Docker 安装](#使用-docker-安装)\n    - [安装校验](#安装校验)\n  - [快速上手](#快速上手)\n    - [数据处理](#数据处理)\n    - [分布式数据处理](#分布式数据处理)\n    - [数据分析](#数据分析)\n    - [数据可视化](#数据可视化)\n    - [构建配置文件](#构建配置文件)\n    - [沙盒实验室](#沙盒实验室)\n    - [预处理原始数据（可选）](#预处理原始数据可选)\n    - [对于 Docker 用户](#对于-docker-用户)\n  - [数据处理菜谱](#数据处理菜谱)\n  - [开源协议](#开源协议)\n  - [贡献](#贡献)\n  - [致谢](#致谢)\n  - [参考文献](#参考文献)\n\n\n## 特点\n\n![Overview](https://img.alicdn.com/imgextra/i4/O1CN01WYQP3Z1JHsaXaQDK6_!!6000000001004-0-tps-3640-1812.jpg)\n\n* **系统化 & 可复用**：为用户提供系统化且可复用的80+核心[算子](docs/Operators_ZH.md)，20+[配置菜谱](configs/README_ZH.md)和20+专用[工具池](#documentation)，旨在让多模态数据处理独立于特定的大语言模型数据集和处理流水线。\n\n* **数据反馈回路 & 沙盒实验室**：支持一站式数据-模型协同开发，通过[沙盒实验室](docs/Sandbox-ZH.md)快速迭代，基于数据和模型反馈回路、可视化和多维度自动评估等功能，使您更了解和改进您的数据和模型。  ![Data-in-the-loop](https://img.alicdn.com/imgextra/i2/O1CN017U7Zz31Y7XtCJ5GOz_!!6000000003012-0-tps-3640-1567.jpg)\n\n* **面向生产环境**：提供高效并行化的数据处理流水线（Aliyun-PAI\\Ray\\Slurm\\CUDA\\算子融合），减少内存占用和CPU开销，支持自动化处理容错。  ![sys-perf](https://img.alicdn.com/imgextra/i4/O1CN01Sk0q2U1hdRxbnQXFg_!!6000000004300-0-tps-2438-709.jpg)\n\n* **全面的数据处理菜谱**：为pre-training、fine-tuning、中英文等场景提供数十种[预构建的数据处理菜谱](configs/data_juicer_recipes/README_ZH.md)。 在LLaMA、LLaVA等模型上有效验证。 ![exp_llama](https://img.alicdn.com/imgextra/i2/O1CN019WtUPP1uhebnDlPR8_!!6000000006069-2-tps-2530-1005.png)\n\n* **用户友好**：设计简单易用，提供全面的[文档](#documents)、简易[入门指南](#快速上手)和[演示配置](configs/README_ZH.md)，并且可以轻松地添加/删除[现有配置](configs/config_all.yaml)中的算子。\n\n* **灵活 & 易扩展**：支持大多数数据格式（如jsonl、parquet、csv等），并允许灵活组合算子。支持[自定义算子](docs/DeveloperGuide_ZH.md#构建自己的算子)，以执行定制化的数据处理。\n\n\n## 文档索引 <a name=\"documents\"/>\n\n* [概览](README_ZH.md)\n* [算子库](docs/Operators_ZH.md)\n* [配置系统](configs/README_ZH.md)\n* [开发者指南](docs/DeveloperGuide_ZH.md)\n* [API 参考](https://modelscope.github.io/data-juicer/)\n* [KDD'24 相关教程](https://modelscope.github.io/data-juicer/_static/tutorial_kdd24.html)\n* [“坏”数据展览](docs/BadDataExhibition_ZH.md)\n* [Awesome LLM-Data](docs/awesome_llm_data.md)\n* 专用工具箱\n  * [质量分类器](tools/quality_classifier/README_ZH.md)\n  * [自动评测](tools/evaluator/README_ZH.md)\n  * [前处理](tools/preprocess/README_ZH.md)\n  * [后处理](tools/postprocess/README_ZH.md)\n* [DJ-SORA](docs/DJ_SORA_ZH.md)\n* [第三方库（大语言模型生态）](thirdparty/README_ZH.md)\n\n\n## 演示样例\n\n* Data-Juicer 介绍 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/overview_scan/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/overview_scan)]\n* 数据可视化:\n  * 基础指标统计 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_statistics/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_statistics)]\n  * 词汇多样性 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_diversity/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_diversity)]\n  * 算子洞察（单OP） [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visualization_op_insight/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_op_insight)]\n  * 算子效果（多OP） [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_visulization_op_effect/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_visualization_op_effect)]\n* 数据处理:\n  * 科学文献 (例如 [arXiv](https://info.arxiv.org/help/bulk_data_s3.html)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_sci_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_sci_data)]\n  * 编程代码 (例如 [TheStack](https://huggingface.co/datasets/bigcode/the-stack)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_code_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_code_data)]\n  * 中文指令数据 (例如 [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)) [[ModelScope](https://modelscope.cn/studios/Data-Juicer/process_sft_zh_data/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/process_cft_zh_data)]\n* 工具池:\n  * 按语言分割数据集 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/tool_dataset_splitting_by_language/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/tool_dataset_splitting_by_language)]\n  * CommonCrawl 质量分类器 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/tool_quality_classifier/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/tool_quality_classifier)]\n  * 基于 [HELM](https://github.com/stanford-crfm/helm) 的自动评测 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/auto_evaluation_helm/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/auto_evaluation_helm)]\n  * 数据采样及混合 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_mixture/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_mixture)]\n* 数据处理回路 [[ModelScope](https://modelscope.cn/studios/Data-Juicer/data_process_loop/summary)] [[HuggingFace](https://huggingface.co/spaces/datajuicer/data_process_loop)]\n\n\n## 前置条件\n\n* 推荐 Python>=3.9,<=3.10\n* gcc >= 5 (at least C++14 support)\n\n## 安装\n\n### 从源码安装\n\n* 运行以下命令以安装 `data_juicer` 可编辑模式的最新基础版本\n\n```shell\ncd <path_to_data_juicer>\npip install -v -e .\n```\n\n* 部分算子功能依赖于较大的或者平台兼容性不是很好的第三方库，因此用户可按需额外安装可选的依赖项:\n\n```shell\ncd <path_to_data_juicer>\npip install -v -e .  # 安装最小依赖，支持基础功能\npip install -v -e .[tools] # 安装部分工具库的依赖\n```\n\n依赖选项如下表所示:\n\n| 标签               | 描述                           |\n|------------------|------------------------------|\n| `.` 或者 `.[mini]` | 安装支持 Data-Juicer 基础功能的最小依赖项  |\n| `.[all]`         | 安装除了沙盒实验以外的所有依赖项  |\n| `.[sci]`         | 安装所有算子的全量依赖                  |\n| `.[dist]`        | 安装以分布式方式进行数据处理的依赖（实验性功能）     |\n| `.[dev]`         | 安装作为贡献者开发 Data-Juicer 所需的依赖项 |\n| `.[tools]`       | 安装专用工具库（如质量分类器）所需的依赖项        |\n| `.[sandbox]`     | 安装沙盒实验室的基础依赖                 |\n\n* 只安装部分算子依赖\n\n随着OP数量的增长，所有OP的依赖变得很重。为此，我们提供了两个替代的、更轻量的选项，作为使用命令`pip install -v -e .[sci]`安装所有依赖的替代：\n\n  * 自动最小依赖安装：在执行Data-Juicer的过程中，将自动安装最小依赖。也就是说你可以直接执行，但这种方式可能会导致一些依赖冲突。\n\n  * 手动最小依赖安装：可以通过如下指令手动安装适合特定执行配置的最小依赖：\n    ```shell\n    # 适用于从源码安装\n    python tools/dj_install.py --config path_to_your_data-juicer_config_file\n    \n    # 使用命令行工具\n    dj-install --config path_to_your_data-juicer_config_file\n    ```\n\n### 使用 pip 安装\n\n* 运行以下命令用 `pip` 安装 `data_juicer` 的最新发布版本：\n\n```shell\npip install py-data-juicer\n```\n\n* **注意**：\n  * 使用这种方法安装时，只有`data_juicer`中的基础的 API 和2个基础工具\n    （数据[处理](#数据处理)与[分析](#数据分析)）可以使用。如需更定制化地使用完整功能，建议[从源码进行安装](#从源码安装)。\n  * pypi 的发布版本较源码的最新版本有一定的滞后性，如需要随时跟进 `data_juicer` 的最新功能支持，建议[从源码进行安装](#从源码安装)。\n\n### 使用 Docker 安装\n\n- 您可以选择\n  - 从DockerHub直接拉取我们的预置镜像:\n    ```shell\n    docker pull datajuicer/data-juicer:<version_tag>\n    ```\n  - 或者运行如下命令用我们提供的 [Dockerfile](Dockerfile) 来构建包括最新版本的 `data-juicer` 的 docker 镜像：\n\n    ```shell\n    docker build -t datajuicer/data-juicer:<version_tag> .\n    ```\n\n  - `<version_tag>`的格式类似于`v0.2.0`，与发布（Release）的版本号相同。\n\n### 安装校验\n\n```python\nimport data_juicer as dj\nprint(dj.__version__)\n```\n\n### 使用视频相关算子\n\n在使用视频相关算子之前，应该安装 **FFmpeg** 并确保其可通过 $PATH 环境变量访问。\n\n你可以使用包管理器安装 FFmpeg（例如，在 Debian/Ubuntu 上使用 sudo apt install ffmpeg，在 OS X 上使用 brew install ffmpeg），或访问[官方FFmpeg链接](https://ffmpeg.org/download.html)。\n\n随后在终端运行 ffmpeg 命令检查环境是否设置正确。\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>\n\n## 快速上手\n\n### 数据处理\n\n* 以配置文件路径作为参数来运行 `process_data.py` 或者 `dj-process` 命令行工具来处理数据集。\n\n```shell\n# 适用于从源码安装\npython tools/process_data.py --config configs/demo/process.yaml\n\n# 使用命令行工具\ndj-process --config configs/demo/process.yaml\n```\n\n* **注意**：使用未保存在本地的第三方模型或资源的算子第一次运行可能会很慢，因为这些算子需要将相应的资源下载到缓存目录中。默认的下载缓存目录为`~/.cache/data_juicer`。您可通过设置 shell 环境变量 `DATA_JUICER_CACHE_HOME` 更改缓存目录位置，您也可以通过同样的方式更改 `DATA_JUICER_MODELS_CACHE` 或 `DATA_JUICER_ASSETS_CACHE` 来分别修改模型缓存或资源缓存目录:\n\n* **注意**：对于使用了第三方模型的算子，在填写config文件时需要去声明其对应的`mem_required`（可以参考`config_all.yaml`文件中的设置）。Data-Juicer在运行过程中会根据内存情况和算子模型所需的memory大小来控制对应的进程数，以达成更好的数据处理的性能效率。而在使用CUDA环境运行时，如果不正确的声明算子的`mem_required`情况，则有可能导致CUDA Out of Memory。\n\n```shell\n# 缓存主目录\nexport DATA_JUICER_CACHE_HOME=\"/path/to/another/directory\"\n# 模型缓存目录\nexport DATA_JUICER_MODELS_CACHE=\"/path/to/another/directory/models\"\n# 资源缓存目录\nexport DATA_JUICER_ASSETS_CACHE=\"/path/to/another/directory/assets\"\n```\n\n#### 灵活的编程接口\n我们提供了各种层次的简单编程接口，以供用户选择：\n```python\n# ... init op & dataset ...\n\n# 链式调用风格，支持单算子或算子列表\ndataset = dataset.process(op)\ndataset = dataset.process([op1, op2])\n# 函数式编程风格，方便快速集成或脚本原型迭代\ndataset = op(dataset)\ndataset = op.run(dataset)\n```\n\n### 分布式数据处理\n\nData-Juicer 现在基于[RAY](https://www.ray.io/)实现了多机分布式数据处理。\n对应Demo可以通过如下命令运行：\n\n```shell\n\n# 运行文字数据处理\npython tools/process_data.py --config ./demos/process_on_ray/configs/demo.yaml\n\n# 运行视频数据处理\npython tools/process_data.py --config ./demos/process_video_on_ray/configs/demo.yaml\n\n```\n\n - 如果需要在多机上使用RAY执行数据处理，需要确保所有节点都可以访问对应的数据路径，即将对应的数据路径挂载在共享文件系统（如NAS）中。\n - RAY 模式下的去重算子与单机版本不同，所有 RAY 模式下的去重算子名称都以 `ray` 作为前缀，例如 `ray_video_deduplicator` 和 `ray_document_deduplicator`。这些去重算子依赖于 [Redis](https://redis.io/) 实例.因此使用前除启动 RAY 集群外还需要启动 Redis 实例，并在对应的配置文件中填写 Redis 实例的 `host` 和 `port`。\n\n> 用户也可以不使用 RAY，拆分数据集后使用 [Slurm](https://slurm.schedmd.com/) 在集群上运行，此时使用不包含 RAY 的原版 Data-Juicer 即可。\n> [阿里云 PAI-DLC](https://www.aliyun.com/activity/bigdata/pai-dlc) 支持 RAY 框架、Slurm 框架等，用户可以直接在DLC集群上创建 RAY 作业 和 Slurm 作业。\n\n### 数据分析\n\n- 以配置文件路径为参数运行 `analyze_data.py` 或者 `dj-analyze` 命令行工具来分析数据集。\n\n```shell\n# 适用于从源码安装\npython tools/analyze_data.py --config configs/demo/analyzer.yaml\n\n# 使用命令行工具\ndj-analyze --config configs/demo/analyzer.yaml\n\n# 你也可以使用\"自动\"模式来避免写一个新的数据菜谱。它会使用全部可产出统计信息的 Filter 来分析\n# 你的数据集的一小部分（如1000条样本，可通过 `auto_num` 参数指定）\ndj-analyze --auto --dataset_path xx.jsonl [--auto_num 1000]\n```\n\n* **注意**：Analyzer 只用于能在 stats 字段里产出统计信息的 Filter 算子和能在 meta 字段里产出 tags 或类别标签的其他算子。除此之外的其他的算子会在分析过程中被忽略。我们使用以下两种注册器来装饰相关的算子：\n  * `NON_STATS_FILTERS`：装饰那些**不能**产出任何统计信息的 Filter 算子。\n  * `TAGGING_OPS`：装饰那些能在 meta 字段中产出 tags 或类别标签的算子。\n\n### 数据可视化\n\n* 运行 `app.py` 来在浏览器中可视化您的数据集。\n* **注意**：只可用于从源码安装的方法。\n\n```shell\nstreamlit run app.py\n```\n\n\n\n\n### 构建配置文件\n\n* 配置文件包含一系列全局参数和用于数据处理的算子列表。您需要设置:\n  * 全局参数：输入/输出 数据集路径，worker 进程数量等。\n  * 算子列表：列出用于处理数据集的算子及其参数。\n* 您可以通过如下方式构建自己的配置文件:\n  * ➖：修改我们的样例配置文件 [`config_all.yaml`](configs/config_all.yaml)。该文件包含了**所有**算子以及算子对应的默认参数。您只需要**移除**不需要的算子并重新设置部分算子的参数即可。\n  * ➕：从头开始构建自己的配置文件。您可以参考我们提供的样例配置文件 [`config_all.yaml`](configs/config_all.yaml)，[算子文档](docs/Operators_ZH.md)，以及 [开发者指南](docs/DeveloperGuide_ZH.md#构建自己的算子).\n  * 除了使用 yaml 文件外，您还可以在命令行上指定一个或多个参数，这些参数将覆盖 yaml 文件中的值。\n\n```shell\npython xxx.py --config configs/demo/process.yaml --language_id_score_filter.lang=en\n```\n\n* 基础的配置项格式及定义如下图所示\n\n  ![基础配置项格式及定义样例](https://img.alicdn.com/imgextra/i4/O1CN01xPtU0t1YOwsZyuqCx_!!6000000003050-0-tps-1692-879.jpg \"基础配置文件样例\")\n\n### 沙盒实验室\n\n数据沙盒实验室 (DJ-Sandbox) 为用户提供了持续生产数据菜谱的最佳实践，其具有低开销、可迁移、有指导性等特点。\n- 用户在沙盒中可以基于一些小规模数据集、模型对数据菜谱进行快速实验、迭代、优化，再迁移到更大尺度上，大规模生产高质量数据以服务大模型。\n- 用户在沙盒中，除了Data-Juicer基础的数据优化与数据菜谱微调功能外，还可以便捷地使用数据洞察与分析、沙盒模型训练与评测、基于数据和模型反馈优化数据菜谱等可配置组件，共同组成完整的一站式数据-模型研发流水线。\n\n沙盒默认通过如下命令运行，更多介绍和细节请参阅[沙盒文档](docs/Sandbox-ZH.md).\n```shell\npython tools/sandbox_starter.py --config configs/demo/sandbox/sandbox.yaml\n```\n\n\n\n### 预处理原始数据（可选）\n\n* 我们的 Formatter 目前支持一些常见的输入数据集格式：\n  * 单个文件中包含多个样本：jsonl/json、parquet、csv/tsv 等。\n  * 单个文件中包含单个样本：txt、code、docx、pdf 等。\n* 但来自不同源的数据是复杂和多样化的，例如:\n  * [从 S3 下载的 arXiv 原始数据](https://info.arxiv.org/help/bulk_data_s3.html) 包括数千个 tar 文件以及更多的 gzip 文件，并且所需的 tex 文件在 gzip 文件中，很难直接获取。\n  * 一些爬取的数据包含不同类型的文件（pdf、html、docx 等），并且很难提取额外的信息，例如表格、图表等。\n* Data-Juicer 不可能处理所有类型的数据，欢迎提 Issues/PRs，贡献对新数据类型的处理能力！\n* 因此我们在 [`tools/preprocess`](tools/preprocess) 中提供了一些**常见的预处理工具**，用于预处理这些类型各异的数据。\n  * 欢迎您为社区贡献新的预处理工具。\n  * 我们**强烈建议**将复杂的数据预处理为 jsonl 或 parquet 文件。\n\n### 对于 Docker 用户\n\n- 如果您构建或者拉取了 `data-juicer` 的 docker 镜像，您可以使用这个 docker 镜像来运行上面提到的这些命令或者工具。\n- 直接运行：\n\n```shell\n# 直接运行数据处理\ndocker run --rm \\  # 在处理结束后将容器移除\n  --privileged \\\n  --shm-size 256g \\\n  --network host \\\n  --gpus all \\\n  --name dj \\  # 容器名称\n  -v <host_data_path>:<image_data_path> \\  # 将本地的数据或者配置目录挂载到容器中\n  -v ~/.cache/:/root/.cache/ \\  # 将 cache 目录挂载到容器以复用 cache 和模型资源（推荐）\n  datajuicer/data-juicer:<version_tag> \\  # 运行的镜像\n  dj-process --config /path/to/config.yaml  # 类似的数据处理命令\n```\n\n- 或者您可以进入正在运行的容器，然后在可编辑模式下运行命令：\n\n```shell\n# 启动容器\ndocker run -dit \\  # 在后台启动容器\n  --privileged \\\n  --shm-size 256g \\\n  --network host \\\n  --gpus all \\\n  --rm \\\n  --name dj \\\n  -v <host_data_path>:<image_data_path> \\\n  -v ~/.cache/:/root/.cache/ \\\n  datajuicer/data-juicer:latest /bin/bash\n\n# 进入这个容器，然后您可以在编辑模式下使用 data-juicer\ndocker exec -it <container_id> bash\n```\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>\n\n## 数据处理菜谱\n\n* [BLOOM 数据处理菜谱](configs/reproduced_bloom/README_ZH.md)\n* [RedPajama 数据处理菜谱](configs/reproduced_redpajama/README_ZH.md)\n* [预训练文本数据增强菜谱](configs/data_juicer_recipes/README_ZH.md)\n* [Fine-tuning文本数据增强菜谱](configs/data_juicer_recipes/README_ZH.md#完善前后的alpaca-cot数据集)\n* [预训练多模态数据增强菜谱](configs/data_juicer_recipes/README_ZH.md#before-and-after-refining-for-multimodal-dataset)\n\n## 开源协议\n\nData-Juicer 在 Apache License 2.0 协议下发布。\n\n## 贡献\n\n大模型是一个高速发展的领域，我们非常欢迎贡献新功能、修复漏洞以及文档改善。请参考[开发者指南](docs/DeveloperGuide_ZH.md)。\n\n如果您有任何问题，欢迎加入我们的[讨论群](README_ZH.md) 。\n\n## 致谢\n\nData-Juicer 被各种 LLM产品和研究工作使用，包括来自阿里云-通义的行业大模型，例如点金\n（金融分析），智文（阅读助手），还有阿里云人工智能平台 (PAI)。 我们期待更多您的体验反馈、建议和合作共建！\n\n\nData-Juicer 感谢并参考了社区开源项目：\n[Huggingface-Datasets](https://github.com/huggingface/datasets), [Bloom](https://huggingface.co/bigscience/bloom), [RedPajama](https://github.com/togethercomputer/RedPajama-Data/tree/rp_v1), [Pile](https://huggingface.co/datasets/EleutherAI/pile), [Alpaca-Cot](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [Megatron-LM](https://github.com/NVIDIA/Megatron-LM), [DeepSpeed](https://www.deepspeed.ai/), [Arrow](https://github.com/apache/arrow), [Ray](https://github.com/ray-project/ray), [Beam](https://github.com/apache/beam),  [LM-Harness](https://github.com/EleutherAI/lm-evaluation-harness), [HELM](https://github.com/stanford-crfm/helm), ....\n\n## 参考文献\n如果您发现我们的工作对您的研发有帮助，请引用以下[论文](https://arxiv.org/abs/2309.02033) 。\n\n```\n@inproceedings{chen2024datajuicer,\n  title={Data-Juicer: A One-Stop Data Processing System for Large Language Models},\n  author={Daoyuan Chen and Yilun Huang and Zhijian Ma and Hesen Chen and Xuchen Pan and Ce Ge and Dawei Gao and Yuexiang Xie and Zhaoyang Liu and Jinyang Gao and Yaliang Li and Bolin Ding and Jingren Zhou},\n  booktitle={International Conference on Management of Data},\n  year={2024}\n}\n```\n<details>\n<summary>更多Data-Juicer团队相关论文:\n</summary>>\n\n- [Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development](https://arxiv.org/abs/2407.11784)\n\n- [The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective](https://arxiv.org/abs/2407.08583)\n\n- [ImgDiff: Contrastive Data Synthesis for Vision Large Language Models](https://arxiv.org/abs/2408.04594)\n\n- [Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model Pretraining](https://arxiv.org/abs/2405.14908)\n\n</details>\n\n\n\n<p align=\"right\"><a href=\"#table\">🔼 back to index</a></p>"
        },
        {
          "name": "app.py",
          "type": "blob",
          "size": 29.318359375,
          "content": "# Some code here has been modified from:\n# https://huggingface.co/spaces/huggingface/text-data-filtering\n# --------------------------------------------------------\n\nimport copy\nimport math\nimport os\nimport sys\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport streamlit as st\nimport yaml\nfrom loguru import logger\n\nfrom data_juicer.analysis.diversity_analysis import (DiversityAnalysis,\n                                                     get_diversity)\nfrom data_juicer.config import init_configs\nfrom data_juicer.core import Analyzer, Executor\nfrom data_juicer.ops.base_op import OPERATORS\nfrom data_juicer.utils.constant import Fields, StatsKeys\nfrom data_juicer.utils.logger_utils import get_log_file_path\nfrom data_juicer.utils.model_utils import MODEL_ZOO, prepare_model\n\n\n@st.cache_data\ndef convert_to_csv(df):\n    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n    return df.to_csv().encode('utf_8_sig')\n\n\n@st.cache_data\ndef convert_to_jsonl(df):\n    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n    return df.to_json(orient='records', lines=True,\n                      force_ascii=False).encode('utf_8_sig')\n\n\n@st.cache_data\ndef get_diversity_model(lang):\n    model_key = prepare_model('spacy', lang=lang)\n    diversity_model = MODEL_ZOO.get(model_key)\n    return diversity_model\n\n\n@st.cache_data\ndef postproc_diversity(dataframe, **kwargs):\n    df = get_diversity(dataframe, **kwargs)\n    return df\n\n\ndef read_log_file():\n    log_f_path = get_log_file_path()\n    if log_f_path is None or not os.path.exists(log_f_path):\n        return ''\n    sys.stdout.flush()\n    with open(log_f_path, 'r') as f:\n        return f.read()\n\n\ndef pretty_out(d):\n    res = ''\n    process = ''\n    op_names = set(OPERATORS.modules.keys())\n    for key, value in d.items():\n        if key == 'process':\n            process = yaml.dump(value,\n                                allow_unicode=True,\n                                default_flow_style=False)\n        elif key == 'config' or key.split('.')[0] in op_names:\n            continue\n        else:\n            res += f'{key}:\\n \\t {value}\\n'\n    res += 'process:\\n' + \\\n           '\\n'.join(['\\t' + line for line in process.splitlines()])\n\n    return res\n\n\ndef parse_cfg():\n\n    cfg_file = st.session_state.input_cfg_file\n    cfg_cmd = st.session_state.input_cfg_cmd\n\n    cfg_f_name = 'null'\n    del_cfg_file = False\n    if cfg_file is not None:\n        cfg_f_name = cfg_file.name\n        file_contents = cfg_file.getvalue()\n        with open(cfg_f_name, 'wb') as f:\n            f.write(file_contents)\n        cfg_cmd = f'--config {cfg_f_name}'\n        del_cfg_file = True\n\n    args_in_cmd = cfg_cmd.split()\n\n    if len(args_in_cmd) >= 2 and args_in_cmd[0] == '--config':\n        cfg_f_name = args_in_cmd[1]\n    else:\n        st.warning('Please specify a config command or upload a config file.')\n        st.stop()\n\n    if not os.path.exists(cfg_f_name):\n        st.warning('do not parse'\n                   f'config file does not exist with cfg_f_name={cfg_f_name}')\n        st.stop()\n\n    with open(cfg_f_name, 'r') as cfg_f:\n        specified_cfg = yaml.safe_load(cfg_f)\n\n    try:\n        parsed_cfg = init_configs(args=args_in_cmd)\n        st.session_state.cfg = parsed_cfg\n        if isinstance(parsed_cfg.text_keys, list):\n            text_key = parsed_cfg.text_keys[0]\n        else:\n            text_key = parsed_cfg.text_keys\n        st.session_state.text_key = text_key\n        if del_cfg_file:\n            os.remove(cfg_f_name)\n        return pretty_out(parsed_cfg), pretty_out(specified_cfg), parsed_cfg\n    except Exception as e:\n        return str(e), pretty_out(specified_cfg), None\n\n\ndef analyze_and_show_res():\n    images_ori = []\n    cfg = st.session_state.get('cfg', parse_cfg()[2])\n    if cfg is None:\n        raise ValueError('you have not specify valid cfg')\n    # force generating separate figures\n    cfg['save_stats_in_one_file'] = True\n\n    logger.info('=========Stage 1: analyze original data=========')\n    analyzer = Analyzer(cfg)\n    dataset = analyzer.run()\n\n    overall_file = os.path.join(analyzer.analysis_path, 'overall.csv')\n    analysis_res_ori = pd.DataFrame()\n    if os.path.exists(overall_file):\n        analysis_res_ori = pd.read_csv(overall_file)\n\n    if os.path.exists(analyzer.analysis_path):\n        for f_path in os.listdir(analyzer.analysis_path):\n            if '.png' in f_path and 'all-stats' in f_path:\n                images_ori.append(os.path.join(analyzer.analysis_path, f_path))\n\n    st.session_state.dataset = dataset\n    st.session_state.original_overall = analysis_res_ori\n    st.session_state.original_imgs = images_ori\n\n\ndef process_and_show_res():\n    images_processed = []\n    cfg = st.session_state.get('cfg', parse_cfg()[2])\n    if cfg is None:\n        raise ValueError('you have not specify valid cfg')\n    # force generating separate figures\n    cfg['save_stats_in_one_file'] = True\n    logger.info('=========Stage 2: process original data=========')\n    executor = Executor(cfg)\n    dataset = executor.run()\n\n    logger.info('=========Stage 3: analyze the processed data==========')\n    analysis_res_processed = pd.DataFrame()\n    try:\n        cfg_for_processed_data = copy.deepcopy(cfg)\n        cfg_for_processed_data.dataset_path = cfg.export_path\n\n        cfg_for_processed_data.export_path = os.path.dirname(\n            cfg.export_path) + '_processed/data.jsonl'\n        analyzer = Analyzer(cfg_for_processed_data)\n        analyzer.analysis_path = os.path.dirname(\n            cfg_for_processed_data.export_path) + '/analysis'\n        analyzer.run()\n\n        overall_file = os.path.join(analyzer.analysis_path, 'overall.csv')\n        if os.path.exists(overall_file):\n            analysis_res_processed = pd.read_csv(overall_file)\n\n        if os.path.exists(analyzer.analysis_path):\n            for f_path in os.listdir(analyzer.analysis_path):\n                if '.png' in f_path and 'all-stats' in f_path:\n                    images_processed.append(\n                        os.path.join(analyzer.analysis_path, f_path))\n    except Exception as e:\n        st.warning(f'Something error with {str(e)}')\n\n    logger.info('=========Stage 4: Render the analysis results==========')\n    st.session_state.dataset = dataset\n    st.session_state.processed_overall = analysis_res_processed\n    st.session_state.processed_imgs = images_processed\n\n\ndef get_min_max_step(data):\n    max_value = np.max(data)\n    if max_value > 2.0:\n        min_value = 0\n        max_value = int(max_value + 1)\n        step = 1\n    else:\n        min_value = 0.0\n        max_value = max(1.0, max_value)\n        step = 0.01\n    return min_value, max_value, step\n\n\nop_stats_dict = {\n    'alphanumeric_filter':\n    [StatsKeys.alpha_token_ratio, StatsKeys.alnum_ratio],\n    'average_line_length_filter': [StatsKeys.avg_line_length],\n    'character_repetition_filter': [StatsKeys.char_rep_ratio],\n    'flagged_words_filter': [StatsKeys.flagged_words_ratio],\n    'language_id_score_filter': [StatsKeys.lang, StatsKeys.lang_score],\n    'maximum_line_length_filter': [StatsKeys.max_line_length],\n    'perplexity_filter': [StatsKeys.perplexity],\n    'special_characters_filter': [StatsKeys.special_char_ratio],\n    'stopwords_filter': [StatsKeys.stopwords_ratio],\n    'text_length_filter': [StatsKeys.text_len],\n    'token_num_filter': [StatsKeys.num_token],\n    'words_num_filter': [StatsKeys.num_words],\n    'word_repetition_filter': [StatsKeys.word_rep_ratio],\n}\n\n\nclass Visualize:\n\n    @staticmethod\n    def filter_dataset(dataset):\n        if Fields.stats not in dataset.features:\n            return\n        text_key = st.session_state.get('text_key', 'text')\n        text = dataset[text_key]\n        stats = pd.DataFrame(dataset[Fields.stats])\n        stats[text_key] = text\n\n        non_num_list = [StatsKeys.lang]\n        min_cutoff_list = [\n            StatsKeys.lang_score,\n            StatsKeys.stopwords_ratio,\n        ]\n        max_cutoff_list = [\n            StatsKeys.flagged_words_ratio,\n            StatsKeys.perplexity,\n        ]\n        mask_list = [text_key]\n\n        cfg = st.session_state.get('cfg', None)\n        if cfg is None:\n            return\n\n        def set_sliders(total_stats, ordered):\n            stats = copy.deepcopy(total_stats)\n            conds = list()\n            index = 1\n            for op_cfg in cfg.process:\n                op_name = list(op_cfg.keys())[0]\n                op_stats = op_stats_dict.get(op_name, [])\n\n                cutoff_ratio = None\n\n                with st.sidebar.expander(f'{index} {op_name}'):\n\n                    for column_name in op_stats:\n                        if column_name not in stats:\n                            continue\n                        data = stats[column_name]\n\n                        if column_name in non_num_list:\n                            options = ['all'] + list(set(data))\n                            label = f'Which {column_name} would \\\n                                     you like to keep?'\n\n                            selected = st.selectbox(\n                                label=label,\n                                options=options,\n                            )\n                            if selected == 'all':\n                                cond = [True] * len(data)\n                            else:\n                                cond = data == selected\n                            Visualize.display_discarded_ratio(\n                                cond, column_name)\n\n                        elif column_name in min_cutoff_list:\n                            label = f'If the {column_name} of a document  \\\n                                    is lower than this number,  \\\n                                    the document is removed.'\n\n                            low, high, step = get_min_max_step(data)\n\n                            cutoff_ratio = st.slider(label,\n                                                     low,\n                                                     high,\n                                                     low,\n                                                     step=step)\n                            cond = data >= cutoff_ratio\n                            Visualize.display_discarded_ratio(\n                                cond, column_name)\n\n                        elif column_name in max_cutoff_list:\n                            label = f'If the {column_name} of a document  \\\n                                    is higher than this number,  \\\n                                    the document is removed.'\n\n                            low, high, step = get_min_max_step(data)\n                            cutoff_ratio = st.slider(label,\n                                                     low,\n                                                     high,\n                                                     high,\n                                                     step=step)\n                            cond = data <= cutoff_ratio\n\n                            Visualize.display_discarded_ratio(\n                                cond, column_name)\n                        elif column_name not in mask_list:\n                            # lower\n                            label = f'If the {column_name} of a document  \\\n                                    is lower than this number,  \\\n                                    the document is removed.'\n\n                            low, high, step = get_min_max_step(data)\n\n                            cutoff_ratio_l = st.slider(label,\n                                                       low,\n                                                       high,\n                                                       low,\n                                                       step=step)\n                            cond_l = data >= cutoff_ratio_l\n\n                            Visualize.display_discarded_ratio(\n                                cond_l, column_name)\n\n                            # higher\n                            label = f'If the {column_name} of a document  \\\n                                    is higher than this number,  \\\n                                    the document is removed.'\n\n                            cutoff_ratio_h = st.slider(label,\n                                                       low,\n                                                       high,\n                                                       high,\n                                                       step=step)\n\n                            cond_h = data <= cutoff_ratio_h\n                            Visualize.display_discarded_ratio(\n                                cond_h, column_name)\n                            cond = [\n                                low & high\n                                for low, high in zip(cond_l, cond_h)\n                            ]\n\n                            cutoff_ratio = (cutoff_ratio_l, cutoff_ratio_h)\n\n                        if column_name not in mask_list:\n                            Visualize.draw_hist(data, cutoff_ratio)\n                            conds.append({\n                                (' '.join([str(index), op_name]), column_name):\n                                cond\n                            })\n\n                        if ordered:\n                            stats = stats.loc[cond]\n                    index += 1\n            return conds, stats\n\n        st.sidebar.subheader('Parameters of filter ops')\n        ordered = st.sidebar.checkbox('Process by op order')\n        conds, filtered_stats = set_sliders(stats, ordered)\n\n        st.subheader('How many samples do you want to show?')\n        show_num = st.number_input(\n            label='How many samples do you want to show?',\n            value=5,\n            label_visibility='hidden')\n        if ordered:\n            all_conds = [\n                True if i in filtered_stats.index else False\n                for i in range(len(stats))\n            ]\n        else:\n            all_conds = np.all([list(cond.values())[0] for cond in conds],\n                               axis=0)\n        ds = pd.DataFrame(dataset)\n        Visualize.display_dataset(ds, all_conds, show_num, 'Retained sampels',\n                                  'docs')\n        st.download_button('Download Retained data as JSONL',\n                           data=convert_to_jsonl(ds.loc[all_conds]),\n                           file_name='retained.jsonl')\n        Visualize.display_dataset(ds, np.invert(all_conds), show_num,\n                                  'Discarded sampels', 'docs')\n        st.download_button('Download Discarded data as JSONL',\n                           data=convert_to_jsonl(ds.loc[np.invert(all_conds)]),\n                           file_name='discarded.jsonl')\n        display_discarded_details = st.checkbox(\n            'Display discarded documents by filter details')\n\n        show_stats = copy.deepcopy(stats)\n        bar_labels = []\n        bar_sizes = []\n        for item in conds:\n            for op_key, cond in item.items():\n                op_name, column_name = op_key\n                if column_name not in mask_list:\n                    sub_stats = show_stats[[column_name, text_key]]\n                    if display_discarded_details:\n                        Visualize.display_dataset(\n                            sub_stats,\n                            np.invert(cond) if len(cond) > 0 else [],\n                            show_num,\n                            # f'Discarded documents for the filter on \\\n                            f'{op_name} {column_name} filtered ',\n                            'docs',\n                        )\n                    before_filtered_num = len(show_stats.index)\n                    if ordered:\n                        show_stats = show_stats.loc[cond]\n                        retained = np.sum(1 * cond)\n                        filtered = before_filtered_num - len(show_stats.index)\n                    else:\n                        retained = np.sum(1 * cond)\n                        filtered = before_filtered_num - retained\n\n                    bar_sizes.append(retained)\n                    bar_sizes.append(filtered)\n                    bar_labels.append(f'{op_name}\\n{column_name}')\n\n        bar_title = 'Effect of Filter OPs'\n        Visualize.draw_stack_bar(bar_sizes, bar_labels, len(stats.index),\n                                 bar_title)\n\n    @staticmethod\n    def diversity():\n        with st.expander('Diversity for CFT dataset', expanded=False):\n            dataset = st.session_state.get('dataset', None)\n            cfg = st.session_state.get('cfg', parse_cfg()[2])\n            text_key = st.session_state.get('text_key', 'text')\n            if dataset:\n\n                col1, col2, col3, col4 = st.columns(4)\n                with col1:\n                    label = 'Which language of your dataset'\n                    options = ['en', 'zh']\n                    lang_select = st.selectbox(\n                        label=label,\n                        options=options,\n                    )\n                with col2:\n                    top_k_verbs = st.number_input(\n                        'Set the top_k nums of verbs', value=20)\n                with col3:\n                    top_k_nouns = st.number_input(\n                        'Set the top_k nums of nouns', value=4)\n                with col4:\n                    threshold = st.slider('Count threshold',\n                                          min_value=0,\n                                          value=0,\n                                          max_value=100,\n                                          step=1)\n\n                diversity_btn = st.button('Analyze_diversity',\n                                          use_container_width=True)\n                output_path = os.path.join(os.path.dirname(cfg.export_path),\n                                           'analysis')\n                raw_df = None\n                if diversity_btn:\n                    try:\n                        diversity_analysis = DiversityAnalysis(\n                            dataset, output_path)\n                        with st.spinner('Wait for analyze diversity...'):\n                            raw_df = diversity_analysis.compute(\n                                lang_or_model=get_diversity_model(lang_select),\n                                column_name=text_key)\n\n                        st.session_state[f'diversity{lang_select}'] = raw_df\n\n                    except Exception as e:\n                        st.warning(f'Error {str(e)} in {lang_select}')\n                else:\n                    raw_df = st.session_state.get(f'diversity{lang_select}',\n                                                  None)\n\n                if raw_df is not None:\n                    df = postproc_diversity(raw_df,\n                                            top_k_verbs=top_k_verbs,\n                                            top_k_nouns=top_k_nouns)\n                    df = df[df['count'] >= threshold]\n                    Visualize.draw_sunburst(df,\n                                            path=['verb', 'noun'],\n                                            values='count')\n\n                    st.download_button(\n                        label='Download diversity data as CSV',\n                        data=convert_to_csv(df),\n                        file_name='diversity.csv',\n                        mime='text/csv',\n                    )\n            else:\n                st.warning('Please analyze original data first')\n\n    @staticmethod\n    def draw_sunburst(df, path, values):\n\n        fig = px.sunburst(df, path=path, values=values)\n        fig.update_layout(margin=dict(l=0, r=0, t=0, b=0),\n                          font_family='Times New Roman',\n                          font=dict(size=40))\n        st.plotly_chart(fig, use_container_width=True)\n\n    @staticmethod\n    def draw_stack_bar(bar_sizes, bar_labels, total_num, title=''):\n        filtered_size = [\n            k / total_num * 100 for i, k in enumerate(bar_sizes[::-1])\n            if i % 2 == 0\n        ]\n        retain_size = [\n            k / total_num * 100 for i, k in enumerate(bar_sizes[::-1])\n            if i % 2 != 0\n        ]\n        plt.clf()\n        plt.title(title)\n        bar_labels = bar_labels[::-1]\n        # retained\n        r_bars = plt.barh(bar_labels,\n                          retain_size,\n                          label='Retained',\n                          height=0.5,\n                          color='limegreen')\n\n        # filtered\n        f_bars = plt.barh(bar_labels,\n                          filtered_size,\n                          label='Filtered',\n                          left=retain_size,\n                          height=0.5,\n                          color='orangered')\n\n        for idx, bar in enumerate(r_bars):\n            width = bar.get_width()\n            plt.text(bar.get_x() + width / 2,\n                     bar.get_y() + bar.get_height() / 2,\n                     f'{retain_size[idx]:.2f}%',\n                     ha='center',\n                     va='center')\n\n        for idx, bar in enumerate(f_bars):\n            width = bar.get_width()\n            plt.text(bar.get_x() + width / 2,\n                     bar.get_y() + bar.get_height() / 2,\n                     f'{filtered_size[idx]:.2f}%',\n                     ha='center',\n                     va='center')\n\n        plt.legend()\n        plt.gcf()\n        st.pyplot(plt, use_container_width=True)\n\n    @staticmethod\n    def draw_pie(bar_labels, big_sizes, small_labels, bar_sizes):\n        plt.clf()\n\n        # filter op circle\n        plt.pie(big_sizes, labels=bar_labels, startangle=90, frame=True)\n        # retained and filtered circle\n        plt.pie(bar_sizes,\n                labels=small_labels,\n                radius=0.7,\n                rotatelabels=True,\n                startangle=90,\n                labeldistance=0.7)\n        centre_circle = plt.Circle((0, 0), 0.4, color='white', linewidth=0)\n        fig = plt.gcf()\n        fig.gca().add_artist(centre_circle)\n\n        plt.axis('equal')\n        plt.tight_layout()\n        st.pyplot(plt, use_container_width=True)\n\n    @staticmethod\n    def display_discarded_ratio(cond, key):\n        if len(cond) > 0:\n            st.caption(\n                f':red[{(len(cond) - np.sum(1*cond)) / len(cond) * 100:.2f}%] \\\n                of the total (:red[{len(cond)}]) is discarded with {key}.')\n        else:\n            st.caption(f':red[{0:.2f}%] \\\n                of the total (:red[0]) is discarded with {key}.')\n\n    @staticmethod\n    def display_dataset(dataframe, cond, show_num, desp, type, all=True):\n        examples = dataframe.loc[cond]\n        if all or len(examples) > 0:\n            st.subheader(\n                f'{desp}: :red[{len(examples)}] of '\n                f'{len(dataframe.index)} {type} '\n                f'(:red[{len(examples)/len(dataframe.index) * 100:.2f}%])')\n\n            # st.markdown('Click on a column to sort by it, \\\n            #    place the cursor on the text to display it.')\n            st.dataframe(examples[:show_num], use_container_width=True)\n\n    @staticmethod\n    def draw_hist(data, cutoff=None):\n\n        fig, ax = plt.subplots()\n        data_num = len(data)\n        if data_num >= 100:\n            rec_bins = int(math.sqrt(len(data)))\n        else:\n            rec_bins = 50\n\n        if data_num > 0:\n            ax.hist(data, bins=rec_bins, density=True)\n        if hasattr(data, 'name'):\n            ax.set_title(data.name)\n\n        if isinstance(cutoff, (float, int)):\n            ax.axvline(x=cutoff, color='r', linestyle='dashed')\n        elif isinstance(cutoff, tuple) and len(cutoff) == 2:\n            ax.axvline(x=cutoff[0], color='r', linestyle='dashed')\n            ax.axvline(x=cutoff[1], color='r', linestyle='dashed')\n        st.pyplot(fig)\n\n    @staticmethod\n    def setup():\n        st.set_page_config(\n            page_title='Data-Juicer',\n            page_icon=':smile',\n            layout='wide',\n            # initial_sidebar_state=\"expanded\",\n        )\n\n        readme_link = 'https://github.com/alibaba/data-juicer'\n        st.markdown(\n            '<div align = \"center\"> <font size = \"70\"> Data-Juicer \\\n            </font> </div>',\n            unsafe_allow_html=True,\n        )\n        st.markdown(\n            f'<div align = \"center\"> A One-Stop Data Processing System for \\\n                Large Language Models, \\\n                see more details in our <a href={readme_link}>page</a></div>',\n            unsafe_allow_html=True,\n        )\n\n    @staticmethod\n    def parser():\n        with st.expander('Configuration', expanded=True):\n            st.markdown('Please specify the cfg via '\n                        '(i) specifying the cfg file path with commands or '\n                        '(ii) uploading the cfg file.')\n\n            col1, col2 = st.columns(2)\n            with col1:\n                example_cfg_f = os.path.abspath(\n                    os.path.join(os.path.dirname(__file__),\n                                 './configs/demo/process.yaml'))\n                st.text_area(label='(i) Input Cfg Commands',\n                             key='input_cfg_cmd',\n                             value=f'--config {example_cfg_f}')\n                example_my_cmd = '--dataset_path ' \\\n                                 './demos/data/demo-dataset.jsonl ' \\\n                                 '--export_path '\\\n                                 './outputs/demo/demo-processed.jsonl'\n\n                st.text_area(\n                    label='cmd example. (the cmd-args will override '\n                    'yaml-file-args)',\n                    disabled=True,\n                    value=f'--config {example_cfg_f} {example_my_cmd}')\n\n            with col2:\n                st.file_uploader(label='(ii) Input Cfg File',\n                                 key='input_cfg_file',\n                                 type=['yaml'])\n\n            btn_show_cfg = st.button('1. Parse Cfg', use_container_width=True)\n            if btn_show_cfg:\n                text1, text2, cfg = parse_cfg()\n                st.session_state.cfg_text1 = text1\n                st.session_state.cfg_text2 = text2\n\n            else:\n                text1 = st.session_state.get('cfg_text1', '')\n                text2 = st.session_state.get('cfg_text2', '')\n\n            col3, col4 = st.columns(2)\n            with col3:\n                st.text_area(label='Parsed Cfg (in memory)', value=text1)\n            with col4:\n                st.text_area(label='Specified Cfg (in yaml file)', value=text2)\n\n    @staticmethod\n    def analyze_process():\n        start_btn = st.button(\n            '2. Start to analyze original data (per filter op)',\n            use_container_width=True)\n        start_btn_process = st.button('3. Start to process data',\n                                      use_container_width=True)\n\n        # with st.expander('Log', expanded=False):\n        #    logs = st.Textbox(show_label=False)\n        #    demo.load(read_log_file, inputs=None, outputs=logs, every=1)\n\n        with st.expander('Data Analysis Results', expanded=False):\n\n            if start_btn:\n                with st.spinner('Wait for analyze...'):\n                    analyze_and_show_res()\n\n            if start_btn_process:\n                with st.spinner('Wait for process...'):\n                    process_and_show_res()\n\n            original_overall = st.session_state.get('original_overall', None)\n            original_imgs = st.session_state.get('original_imgs', [])\n            processed_overall = st.session_state.get('processed_overall', None)\n            processed_imgs = st.session_state.get('processed_imgs', [])\n\n            col1, col2 = st.columns(2)\n            with col1:\n                st.caption('Original Data')\n                st.dataframe(original_overall, use_container_width=True)\n                for img in original_imgs:\n                    st.image(img, output_format='png')\n\n            with col2:\n                st.caption('Processed Data')\n                st.dataframe(processed_overall, use_container_width=True)\n                for img in processed_imgs:\n                    st.image(img, output_format='png')\n\n    @staticmethod\n    def filter():\n        with st.expander('Effect of Filter OPs', expanded=False):\n            dataset = st.session_state.get('dataset', None)\n            if dataset:\n                Visualize.filter_dataset(dataset)\n            else:\n                st.warning('Please analyze original data first')\n\n    @staticmethod\n    def auxiliary():\n        st.markdown('[WIP] Auxiliary Models on Processed Data')\n        col1, col2 = st.columns(2)\n        with col1:\n            with st.expander('Quality Scorer', expanded=False):\n                wiki_socre_btn = st.button('Run Wiki-score classifier',\n                                           use_container_width=True)\n\n                if wiki_socre_btn:\n                    st.warning('No support for now')\n\n                wikibook_score_btn = st.button('Run WikiBook-score classifier',\n                                               use_container_width=True)\n                if wikibook_score_btn:\n                    st.warning('No support for now')\n\n        with col2:\n            with st.expander('[WIP] Proxy LM Models Training', expanded=False):\n                st.file_uploader(label='LM Training Cfg File', type=['yaml'])\n                st.button('Train proxy model')\n                st.markdown('[Training Monitoring](http://'\n                            '8.130.26.137:8083/dail/'\n                            'llama-re-2nd?workspace=user-dail)')\n\n    @staticmethod\n    def visualize():\n        Visualize.setup()\n        Visualize.parser()\n        Visualize.analyze_process()\n        Visualize.filter()\n        Visualize.diversity()\n        Visualize.auxiliary()\n\n\ndef main():\n    Visualize.visualize()\n\n\nif __name__ == '__main__':\n    main()\n"
        },
        {
          "name": "configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "data_juicer",
          "type": "tree",
          "content": null
        },
        {
          "name": "demos",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "environments",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "service.py",
          "type": "blob",
          "size": 5.755859375,
          "content": "import datetime\nimport importlib\nimport inspect\nimport json\nimport logging\nimport os\nfrom typing import Dict\nfrom urllib.parse import parse_qs\n\nfrom fastapi import FastAPI, HTTPException, Request\nfrom jsonargparse import Namespace\nfrom pydantic import validate_call\n\nfrom data_juicer.core.exporter import Exporter\nfrom data_juicer.format.load import load_formatter\n\nDJ_OUTPUT = 'outputs'\n\nallowed_methods = {\n    'run', 'process', 'compute_stats', 'compute_hash', 'analyze', 'compute'\n}\n\nlogger = logging.getLogger('uvicorn.error')\napp = FastAPI()\n\n\ndef register_objects_from_init(directory: str):\n    \"\"\"\n    Traverse the specified directory for __init__.py files and\n    register objects defined in __all__.\n    \"\"\"\n    for dirpath, _, filenames in os.walk(os.path.normpath(directory)):\n        if '__init__.py' in filenames:\n            module_path = dirpath.replace(os.sep, '.')\n            module = importlib.import_module(module_path)\n\n            if hasattr(module, '__all__'):\n                for name in module.__all__:\n                    obj = getattr(module, name)\n                    if inspect.isclass(obj):\n                        register_class(module, obj)\n                    elif callable(obj):\n                        register_function(module, obj)\n\n\ndef register_class(module, cls):\n    \"\"\"Register class and its methods as endpoints.\"\"\"\n\n    def create_class_call(cls, method_name: str):\n\n        async def class_call(request: Request):\n            try:\n                # wrap init method\n                cls.__init__ = validate_call(\n                    cls.__init__, config=dict(arbitrary_types_allowed=True))\n                # parse json body as cls init args\n                init_args = await request.json() if await request.body(\n                ) else {}\n                # create an instance\n                instance = cls(**_setup_cfg(init_args))\n                # wrap called method\n                method = validate_call(getattr(instance, method_name))\n                result = _invoke(method, request)\n                return {'status': 'success', 'result': result}\n            except Exception as e:\n                raise HTTPException(status_code=500, detail=str(e))\n\n        return class_call\n\n    module_path = module.__name__.replace('.', os.sep)\n    cls_name = cls.__name__\n    for method_name in _get_public_methods(cls, allowed_methods):\n        api_path = f'/{module_path}/{cls_name}/{method_name}'\n        class_call = create_class_call(cls, method_name)\n        app.add_api_route(api_path,\n                          class_call,\n                          methods=['POST'],\n                          tags=['POST'])\n        logger.debug(f'Registered {api_path}')\n\n\ndef register_function(module, func):\n    \"\"\"Register a function as an endpoint.\"\"\"\n\n    def create_func_call(func):\n\n        async def func_call(request: Request):\n            try:\n                nonlocal func\n                func = validate_call(func,\n                                     config=dict(arbitrary_types_allowed=True))\n                result = _invoke(func, request)\n                return {'status': 'success', 'result': result}\n            except Exception as e:\n                raise HTTPException(status_code=500, detail=str(e))\n\n        return func_call\n\n    module_path = module.__name__.replace('.', os.sep)\n    func_name = func.__name__\n    api_path = f'/{module_path}/{func_name}'\n    func_call = create_func_call(func)\n    app.add_api_route(api_path, func_call, methods=['GET'], tags=['GET'])\n    logger.debug(f'Registered {api_path}')\n\n\ndef _invoke(callable, request):\n    # parse query params as cls method args\n    q_params = parse_qs(request.url.query, keep_blank_values=True)\n    # flatten lists with a single element\n    d_params = dict(\n        (k, v if len(v) > 1 else v[0]) for k, v in q_params.items())\n    # pre-processing\n    d_params = _setup_cfg(d_params)\n    exporter = _setup_dataset(d_params)\n    skip_return = d_params.pop('skip_return', False)\n    # invoke callable\n    result = callable(**d_params)\n    # post-processing\n    if exporter is not None:\n        exporter.export(result)\n        result = exporter.export_path\n    if skip_return:\n        result = ''\n    return result\n\n\ndef _setup_cfg(params: Dict):\n    \"\"\"convert string `cfg` to Namespace\"\"\"\n    # TODO: Traverse method's signature and convert any arguments \\\n    #  that should be Namespace but are passed as str\n    if cfg_str := params.get('cfg'):\n        if isinstance(cfg_str, str):\n            cfg = Namespace(**json.loads(cfg_str))\n            params['cfg'] = cfg\n    return params\n\n\ndef _setup_dataset(params: Dict):\n    \"\"\"setup dataset loading and exporting\"\"\"\n    exporter = None\n    if dataset_path := params.get('dataset'):\n        if isinstance(dataset_path, str):\n            dataset = load_formatter(dataset_path).load_dataset()\n            params['dataset'] = dataset\n            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n            export_path = os.path.join(DJ_OUTPUT, timestamp,\n                                       'processed_data.jsonl')\n            exporter = Exporter(export_path,\n                                keep_stats_in_res_ds=True,\n                                keep_hashes_in_res_ds=True,\n                                export_stats=False)\n    return exporter\n\n\ndef _get_public_methods(cls, allowed=None):\n    \"\"\"Get public methods of a class.\"\"\"\n    all_methods = inspect.getmembers(cls, predicate=inspect.isfunction)\n    return [\n        name for name, _ in all_methods\n        if not name.startswith('_') and (allowed is None or name in allowed)\n    ]\n\n\n# Specify the directories to search\ndirectories_to_search = [\n    'data_juicer',\n    # \"tools\",  # Uncomment to add more directories\n]\n\n# Register objects from each specified directory\nfor directory in directories_to_search:\n    register_objects_from_init(directory)\n"
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.05078125,
          "content": "[flake8]\nper-file-ignores =\n    */__init__.py: F401\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 2.62109375,
          "content": "import logging\nimport os.path\nimport re\n\nimport setuptools\n\n\ndef get_package_dir():\n    pkg_dir = {\n        'data_juicer.tools': 'tools',\n    }\n    return pkg_dir\n\n\ndef get_install_requirements(require_f_paths, env_dir='environments'):\n    reqs = []\n    for path in require_f_paths:\n        target_f = os.path.join(env_dir, path)\n        if not os.path.exists(target_f):\n            logging.warning(f'target file does not exist: {target_f}')\n        else:\n            with open(target_f, 'r', encoding='utf-8') as fin:\n                reqs += [x.strip() for x in fin.read().splitlines()]\n    reqs = [x for x in reqs if not x.startswith('#')]\n    return reqs\n\n\n# allowing selective installment based on users' needs\n# TODO: The specific taxonomy and dependencies will be determined\n#  after implementing some preliminary operators and detailed discussions\nmin_requires = get_install_requirements(['minimal_requires.txt'])\nextra_requires = {\n    'mini':\n    min_requires,\n    'sci':\n    get_install_requirements(['science_requires.txt']),\n    'dist':\n    get_install_requirements(['dist_requires.txt']),\n    'dev':\n    get_install_requirements(['dev_requires.txt']),\n    'tools':\n    get_install_requirements(\n        ['preprocess_requires.txt', 'quality_classifier_requires.txt']),\n}\nextra_requires['all'] = [v for v in extra_requires.values()]\nextra_requires['sandbox'] = get_install_requirements(['sandbox_requires.txt'])\n\nwith open('data_juicer/__init__.py', 'r') as f:\n    version = re.search(r'^__version__\\s*=\\s*[\\'\"]([^\\'\"]*)[\\'\"]', f.read(),\n                        re.MULTILINE).group(1)\n\nwith open('README.md', encoding='utf-8') as f:\n    readme_md = f.read()\n\nsetuptools.setup(\n    name='py-data-juicer',\n    version=version,\n    url='https://github.com/alibaba/data-juicer',\n    author='SysML Team of Alibaba Tongyi Lab',\n    description='A One-Stop Data Processing System for Large Language '\n    'Models.',\n    long_description=readme_md,\n    long_description_content_type='text/markdown',\n    license='Apache License 2.0',\n    packages=setuptools.find_packages(exclude=['tests*', 'tools*']) +\n    list(get_package_dir().keys()),\n    package_dir=get_package_dir(),\n    entry_points={\n        'console_scripts': [\n            'dj-process = data_juicer.tools.process_data:main',\n            'dj-analyze = data_juicer.tools.analyze_data:main',\n            'dj-install = data_juicer.tools.dj_install:main',\n        ]\n    },\n    install_requires=min_requires,\n    extras_require=extra_requires,\n    classifiers=[\n        'License :: OSI Approved :: Apache Software License',\n        'Programming Language :: Python :: 3',\n        'Operating System :: OS Independent'\n    ],\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "thirdparty",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}