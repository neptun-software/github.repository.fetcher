{
  "metadata": {
    "timestamp": 1736560861335,
    "page": 570,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU3MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nteract/papermill",
      "stars": 6050,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".bumpversion.cfg",
          "type": "blob",
          "size": 0.1259765625,
          "content": "[bumpversion]\ncurrent_version = 2.6.0\ncommit = True\ntag = True\ntag_name = {new_version}\n\n[bumpversion:file:papermill/version.py]\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0341796875,
          "content": "papermill/_version.py export-subst\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 1.3955078125,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n.hypothesis/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pyenv\n.python-version\n\n# celery beat schedule file\ncelerybeat-schedule\n\n# SageMath parsed files\n*.sage.py\n\n# dotenv\n.env\n\n# virtualenv\n.venv\nvenv/\nENV/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n\n# pyCharm\n.idea\n\n# VSCode\n.vscode/\n\n# Visual Studio\n.vs/\n\n# pytest\n.pytest_cache\n\n# scissor fixture\npapermill/tests/fixtures/scissor.txt\n\n# Binder example\nbinder/*run*.ipynb\n\n# pip generated wheel metadata\npip-wheel-metadata\n\n# VIM swap files\n*.swp\n\n\n# lint\n.ruff_cache/\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.3125,
          "content": "ci:\n  autofix_prs: true\n  autoupdate_commit_msg: '[pre-commit.ci] pre-commit suggestions'\n  autoupdate_schedule: quarterly\n  # submodules: true\n\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n      - id: check-case-conflict\n      - id: check-yaml\n      - id: check-toml\n      - id: check-json\n      - id: check-added-large-files\n      - id: check-docstring-first\n      - id: detect-private-key\n\n  #- repo: https://github.com/myint/docformatter\n  #  rev: v1.5.0\n  #  hooks:\n  #    - id: docformatter\n  #      args: [--in-place, --wrap-summaries=120, --wrap-descriptions=120]\n\n  - repo: https://github.com/codespell-project/codespell\n    rev: v2.2.6\n    hooks:\n      - id: codespell\n        additional_dependencies: [tomli]\n        #args: [\"--write-changes\"] # uncomment if you want to get automatic fixing\n\n  - repo: https://github.com/psf/black\n    rev: 23.12.1\n    hooks:\n      - id: black\n        name: Black code\n\n  - repo: https://github.com/executablebooks/mdformat\n    rev: 0.7.17\n    hooks:\n      - id: mdformat\n        additional_dependencies:\n          - mdformat-gfm\n          - mdformat_frontmatter\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n        - id: ruff\n          args: [\"--fix\"]\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 0.5771484375,
          "content": "# .readthedocs.yaml\n# Read the Docs configuration file\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the version of Python and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.11\"\n\n# Build documentation in the docs/ directory with Sphinx\nsphinx:\n   configuration: docs/conf.py\n\n# Optionally build your docs in additional formats such as PDF\nformats:\n   - pdf\n\n# Optionally set the version of Python and requirements required to build your docs\npython:\n  install:\n  - requirements: requirements/docs.txt\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 0.1044921875,
          "content": "# Change Log\n\nSee the [papermill documentation](https://papermill.readthedocs.io/en/latest/changelog.html)\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1220703125,
          "content": "# Code of Conduct\n\nPlease read our entire [Code of Conduct](https://github.com/nteract/nteract/blob/main/CODE_OF_CONDUCT.md)\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 4.9794921875,
          "content": "# So You Want to Contribute to Papermill!\n\nWe welcome all contributions to Papermill both large and small. We encourage you to join our community.\n\n## Our Community Values\n\nWe are an open and friendly community. Everybody is welcome.\n\nWe encourage friendly discussions and respect for all. There are no exceptions.\n\nAll contributions are equally important. Documentation, answering questions, and fixing bugs are equally as valuable as adding new features.\n\nPlease read our entire [Code of Conduct](https://github.com/nteract/nteract/blob/main/CODE_OF_CONDUCT.md).\n\n## Setting up Your Development Environment\n\nFollowing these instructions should give you an efficient path to opening your first pull-request.\n\n### Cloning the Papermill Repository\n\nFork the repository to your local Github account. Clone this repository to your local development machine.\n\n```bash\ngit clone https://github.com/<your_account>/papermill\ncd papermill\n```\n\n### Install an Editable Version\n\nWe prefer to use native venv to manage the development environment.\n\n```bash\npython3 -m venv dev\nsource dev/bin/activate\n```\n\nInstall Papermill using:\n\n```bash\npip install -e '.[dev]'\n```\n\nor use conda if you prefer [conda](https://conda.io/docs/user-guide/tasks/manage-environments.html):\n\n```bash\nconda create -n dev\n. activate dev\n```\n\n_Note: When you are finished you can use `source deactivate` to go back to your base environment._\n\n### Running Tests Locally\n\nIf you are contributing with documentation please jump to [building documentation.](#Building-Documentation)\n\nWe need to install the development package before we can run the tests. If anything is confusing below, always resort to the relevant documentation.\n\nFor the most basic test runs against python 3.12 use this tox subset (callable after `pip install tox`):\n\n```bash\ntox -e py312\n```\n\nThis will just execute the unittests against python 3.8 in a new virtual env. The first run will take longer to setup the virtualenv, but will be fast after that point.\n\nFor a full test suite of all envs and linting checks simply run tox without any arguments\n\n```bash\ntox\n```\n\nThis will require python3.8, 3.9, 3.10, 3.11, and 3.12 to be installed.\n\nAlternavitely pytest can be used if you have an environment already setup which works or has custom packages not present in the tox build.\n\n```bash\npytest\n```\n\nNow there should be a working and editable installation of Papermill to start making your own contributions.\n\n### Building Documentation\n\nThe documentation is built using the [Sphinx](http://www.sphinx-doc.org/en/master/) engine. To contribute, edit the [RestructuredText (`.rst`)](https://en.wikipedia.org/wiki/ReStructuredText) files in the docs directory to make changes and additions.\n\nOnce you are done editing, to generate the documentation, use tox and the following command from the root directory of the repository:\n\n```bash\ntox -e docs\n```\n\nThis will generate `.html` files in the `/.tox/docs_out/` directory. Once you are satisfied, feel free to jump to the next section.\n\n## So You're Ready to Pull Request\n\nThe general workflow for this will be:\n\n1. Run local tests\n1. Pushed changes to your forked repository\n1. Open pull request to main repository\n\n### Run Tests Locally\n\n```bash\npytest --pyargs papermill\n```\n\nRun check manifest to ensure all files are accounted for in the repository.\n\n```bash\ncheck-manifest\n```\n\nThis commands read the `MANIFEST.in` file and explicitly specify the files to include in the source distribution. You can read more about how this works [here](https://docs.python.org/3/distutils/sourcedist.html).\n\n### Push Changes to Forked Repo\n\nYour commits should be pushed to the forked repository. To verify this type\n\n```bash\ngit remote -v\n```\n\nand ensure the remotes point to your GitHub. Don't work on the main branch!\n\n1. Commit changes to local repository:\n\n   ```bash\n   git checkout -b my-feature\n   git add <updated_files>\n   git commit\n   ```\n\n1. Push changes to your remote repository:\n\n   ```bash\n   git push -u origin my-feature\n   ```\n\n### Create Pull Request\n\nFollow [these](https://help.github.com/articles/creating-a-pull-request-from-a-fork/) instrucutions to create a pull request from a forked repository. If you are submitting a bug-fix for a specific issue make sure to reference the issue in the pull request.\n\nThere are good references to the [Git documentation](https://git-scm.com/doc) and [Git workflows](https://docs.scipy.org/doc/numpy/dev/gitwash/development_workflow.html) for more information if any of this is unfamiliar.\n\n_Note: You might want to set a reference to the main repository to fetch/merge from there instead of your forked repository. You can do that using:_\n\n```bash\ngit remote add upstream https://github.com/nteract/papermill\n```\n\nIt's possible you will have conflicts between your repository and main. Here, `main` is meant to be synchronized with the `upstream` repository.  GitHub has some good [documentation](https://help.github.com/articles/resolving-a-merge-conflict-using-the-command-line/) on merging pull requests from the command line.\n\nHappy hacking on Papermill!\n"
        },
        {
          "name": "DEVELOPMENT_GUIDE.md",
          "type": "blob",
          "size": 6.1123046875,
          "content": "# Development Guide\n\n_Note: If you haven't read the CONTRIBUTING.md instructions, make sure to do so before continuing._\n\n## IO Sources / Sinks\n\nTo add a new input source + sink to papermill look in the `iorw.py` file for a few examples.\n\nThe `papermill_io` object at root context of the module holds the registered IO handlers. This maintains the LIFO queue of potential path consumers for any IO request. Each handler is registered to a prefix path which it uses as a prefix match against the input arguments. You'll notice `local` is the lowest order handler and is a special case we use to fall-back on if no other handler matches.\n\nTo add a new handler, simply create a new class which implements the `read`, `listdir`, `write`, and `pretty_path` class methods. `listdir` is optional, and not used by the execute method / cli command. Then add `papermill_io.register(\"my-new-prefix\", MyNewHandler)` and papermill will pick up the new IO handler for any paths it processes.\n\nRemember to add tests to prove your new handler works!\n\n_Note: You can also extend the registry in your own modules to enable domain specific io extensions without needing to commit to papermill._\n\n## Language Translations\n\nWhen you wish to add a new language or kernel to papermill, look in the `translators.py` file.\n\nLike with the iorw pattern, there is a `papermill_translators` object at the root of the file which holds all key-value mappings from kernel / language names to translators. Each Translator inherits from `Translator` which gives the basic JSON conversion structures. Then for each JSON type you'll need to add the relevant translate_type class method. Additionally, you'll want to implement the `comment` function for mapping single line comments. For languages which have a special format for assigning variables you can also override the assign method (see ScalaTranslator for an example).\n\nFinally, register the new handler to the `papermill_translators` object. The translator name must either match the kernel or language name being processed to be used for your notebook execution. This will enable any notebook using the named kernel to use your new parameter translations.\n\nTest additions are easy to create -- just copy the few language specific pytest methods in `test_translators.py` and swap to your new translator name / expected values.\n\n## Engines\n\nBy default papermill uses nbconvert to process notebooks. But it's setup as a plug-n-play system so any function that can process a notebook and return the output nbformat object can be registered into papermill.\n\nTo enable a new engine, first look in `engines.py` at the `NBConvertEngine` as a working example. This class inherits from `Engine` and is required to implement the classmethod `execute_managed_notebook`. The first argument to this method is a `NotebookExecutionManager` -- which is built and passed in the Engine `execute_notebook` classmethod -- and is used to provide callback bindings for cell execution signals.\n\nThe `NotebookExecutionManager` class tracks the notebook object in progress, which is copied from the input notebook to provide functional execution isolation. It also tracks metadata updates and execution timing. In general you don't need to worry about this class except to know it has a `nb` attribute and three callbacks you can call from your engine implementation.\n\n- `cell_start` takes a cell argument and sets the cell metadata up for execution. This triggers a notebook save.\n- `cell_exception` takes a cell argument and flags the cell as failed. This does **not** trigger a notebook save (as the notebook completion after cell failure will save).\n- `cell_complete` takes a cell argument and finalizes timing information in the cell metadata. This triggers a notebook save.\n\nThese functions can be optionally called to better render and populate notebooks with appropriate metadata attributes to reflect their execution. Manually saving the notebook object is unnecessary as the base class wrapper will save the notebook on notebook start and completion on your behalf. If you wish to disable saving, overwrite the `wrap_and_execute_notebook` and prevent the `output_path` from propagating to the base method call.\n\n`papermill.execute_notebook` allows you to pass arbitrary arguments down to the engine. Make sure that engine handles keyword arguments properly. Use utility `merge_kwargs` and `remove_args` to merge and clean arguments.\n\nTo update tests you'll need to add a new test class in `test_engines.py`. Copying the `TestNBConvertEngine` class and modifying it is recommended.\n\n## CLI / Execute\n\nWhen adding an option to papermill, first look in `cli.py` and then `execute.py` for the two places to add your new configurable.\n\nIn `cli.py` you'll want to add an `@click.option` above the `papermill` method and the option name as a positional argument in the `papermill` method. These are fairly straight forward to assign, and you can refer to click's documentation for how to do all the basic options. Then you'll need to pass the argument to `execute_notebook`. We treat the CLI layer as a very light wrapper on the execute method in an attempt to both obey DRY (don't repeat yourself) and to ensure that the imported python module has the same capabilities as the CLI.\n\nNow in `execute.py`'s `execute_notebook` we want to add the appropriate argument and default it to something sane. Add the argument to the docstring as well. Then pass or use that argument where it's needed to achieve the desired effect. Usually these options get passed to `_execute_parameterized_notebook`.\n\nTo update the tests you'll need both `test_cli.py` and `test_execute.py` to include the new option. Though the CLI tests need only check that the appropriate values get passed to `execute_notebook`.\n\n# Releasing\n\n## Prerequisites\n\n- First check that the CHANGELOG is up to date for the next release version\n- Ensure dev requirements are installed `pip install -r requirements/dev.txt`\n\n## Push to GitHub\n\nChange from patch to minor or major for appropriate version updates.\n\n```bash\nbumpversion patch\ngit push upstream && git push upstream --tags\n```\n\n## Push to PyPI\n\n```bash\nrm -rf dist/*\nrm -rf build/*\npython setup.py sdist bdist_wheel\ntwine upload dist/*\n```\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.4716796875,
          "content": "BSD 3-Clause License\n\nCopyright (c) 2017, nteract\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "MANIFEST.in",
          "type": "blob",
          "size": 0.8662109375,
          "content": "recursive-include papermill *.py\nrecursive-include papermill *.ipynb\nrecursive-include papermill *.json\nrecursive-include papermill *.yaml\nrecursive-include papermill *.yml\nrecursive-include papermill *.keep\nrecursive-include papermill *.txt\n\ninclude setup.py\ninclude requirements.txt\ninclude tox_py_installer.sh\nrecursive-include requirements *.txt\ninclude tox.ini\ninclude pytest.ini\ninclude README.md\ninclude LICENSE\ninclude MANIFEST.in\ninclude *.md\ninclude *.toml\n\ninclude .bumpversion.cfg\n\n# Documentation\nprune docs\n\nexclude .pre-commit-config.yaml\n# exclude sample notebooks for binder\nprune binder\n# Scripts\ngraft scripts\n# Test env\nprune .tox\n# Exclude notebooks checkpoints generated by testing\nrecursive-exclude papermill/.ipynb_checkpoints *.ipynb\nrecursive-exclude papermill/tests/notebooks/.ipynb_checkpoints *.ipynb\n\n# Build files\nexclude .github\nexclude .readthedocs.yaml\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.3251953125,
          "content": "# <a href=\"https://github.com/nteract/papermill\"><img src=\"https://media.githubusercontent.com/media/nteract/logos/master/nteract_papermill/exports/images/png/papermill_logo_wide.png\" height=\"48px\" /></a>\n\n<!---(binder links generated at https://mybinder.readthedocs.io/en/latest/howto/badges.html and compressed at https://tinyurl.com) -->\n\n[![CI](https://github.com/nteract/papermill/actions/workflows/ci.yml/badge.svg)](https://github.com/nteract/papermill/actions/workflows/ci.yml)\n[![CI](https://github.com/nteract/papermill/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/nteract/papermill/actions/workflows/ci.yml)\n[![image](https://codecov.io/github/nteract/papermill/coverage.svg?branch=main)](https://codecov.io/github/nteract/papermill?branch=main)\n[![Documentation Status](https://readthedocs.org/projects/papermill/badge/?version=latest)](http://papermill.readthedocs.io/en/latest/?badge=latest)\n[![badge](https://tinyurl.com/ybwovtw2)](https://mybinder.org/v2/gh/nteract/papermill/main?filepath=binder%2Fprocess_highlight_dates.ipynb)\n[![badge](https://tinyurl.com/y7uz2eh9)](https://mybinder.org/v2/gh/nteract/papermill/main?)\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/papermill)](https://pypi.org/project/papermill/)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/ambv/black)\n[![papermill](https://snyk.io/advisor/python/papermill/badge.svg)](https://snyk.io/advisor/python/papermill)\n[![Anaconda-Server Badge](https://anaconda.org/conda-forge/papermill/badges/downloads.svg)](https://anaconda.org/conda-forge/papermill)\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/nteract/papermill/main.svg)](https://results.pre-commit.ci/latest/github/nteract/papermill/main)\n\n**papermill** is a tool for parameterizing, executing, and analyzing\nJupyter Notebooks.\n\nPapermill lets you:\n\n- **parameterize** notebooks\n- **execute** notebooks\n\nThis opens up new opportunities for how notebooks can be used. For\nexample:\n\n- Perhaps you have a financial report that you wish to run with\n  different values on the first or last day of a month or at the\n  beginning or end of the year, **using parameters** makes this task\n  easier.\n- Do you want to run a notebook and depending on its results, choose a\n  particular notebook to run next? You can now programmatically\n  **execute a workflow** without having to copy and paste from\n  notebook to notebook manually.\n\nPapermill takes an *opinionated* approach to notebook parameterization and\nexecution based on our experiences using notebooks at scale in data\npipelines.\n\n## Installation\n\nFrom the command line:\n\n```{.sourceCode .bash}\npip install papermill\n```\n\nFor all optional io dependencies, you can specify individual bundles\nlike `s3`, or `azure` -- or use `all`. To use Black to format parameters you can add as an extra requires \\['black'\\].\n\n```{.sourceCode .bash}\npip install papermill[all]\n```\n\n## Python Version Support\n\nThis library currently supports Python 3.8+ versions. As minor Python\nversions are officially sunset by the Python org papermill will similarly\ndrop support in the future.\n\n## Usage\n\n### Parameterizing a Notebook\n\nTo parameterize your notebook designate a cell with the tag `parameters`.\n\n![enable parameters in Jupyter](docs/img/enable_parameters.gif)\n\nPapermill looks for the `parameters` cell and treats this cell as defaults for the parameters passed in at execution time. Papermill will add a new cell tagged with `injected-parameters` with input parameters in order to overwrite the values in `parameters`. If no cell is tagged with `parameters` the injected cell will be inserted at the top of the notebook.\n\nAdditionally, if you rerun notebooks through papermill and it will reuse the `injected-parameters` cell from the prior run. In this case Papermill will replace the old `injected-parameters` cell with the new run's inputs.\n\n![image](docs/img/parameters.png)\n\n### Executing a Notebook\n\nThe two ways to execute the notebook with parameters are: (1) through\nthe Python API and (2) through the command line interface.\n\n#### Execute via the Python API\n\n```{.sourceCode .python}\nimport papermill as pm\n\npm.execute_notebook(\n   'path/to/input.ipynb',\n   'path/to/output.ipynb',\n   parameters = dict(alpha=0.6, ratio=0.1)\n)\n```\n\n#### Execute via CLI\n\nHere's an example of a local notebook being executed and output to an\nAmazon S3 account:\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -p alpha 0.6 -p l1_ratio 0.1\n```\n\n**NOTE:**\nIf you use multiple AWS accounts, and you have [properly configured your AWS  credentials](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html), then you can specify which account to use by setting the `AWS_PROFILE` environment variable at the command-line. For example:\n\n```{.sourceCode .bash}\n$ AWS_PROFILE=dev_account papermill local/input.ipynb s3://bkt/output.ipynb -p alpha 0.6 -p l1_ratio 0.1\n```\n\nIn the above example, two parameters are set: `alpha` and `l1_ratio` using `-p` (`--parameters` also works). Parameter values that look like booleans or numbers will be interpreted as such. Here are the different ways users may set parameters:\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -r version 1.0\n```\n\nUsing `-r` or `--parameters_raw`, users can set parameters one by one. However, unlike `-p`, the parameter will remain a string, even if it may be interpreted as a number or boolean.\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -f parameters.yaml\n```\n\nUsing `-f` or `--parameters_file`, users can provide a YAML file from which parameter values should be read.\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -y \"\nalpha: 0.6\nl1_ratio: 0.1\"\n```\n\nUsing `-y` or `--parameters_yaml`, users can directly provide a YAML string containing parameter values.\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -b YWxwaGE6IDAuNgpsMV9yYXRpbzogMC4xCg==\n```\n\nUsing `-b` or `--parameters_base64`, users can provide a YAML string, base64-encoded, containing parameter values.\n\nWhen using YAML to pass arguments, through `-y`, `-b` or `-f`, parameter values can be arrays or dictionaries:\n\n```{.sourceCode .bash}\n$ papermill local/input.ipynb s3://bkt/output.ipynb -y \"\nx:\n    - 0.0\n    - 1.0\n    - 2.0\n    - 3.0\nlinear_function:\n    slope: 3.0\n    intercept: 1.0\"\n```\n\n#### Supported Name Handlers\n\nPapermill supports the following name handlers for input and output paths during execution:\n\n- Local file system: `local`\n\n- HTTP, HTTPS protocol:  `http://, https://`\n\n- Amazon Web Services: [AWS S3](https://aws.amazon.com/s3/) `s3://`\n\n- Azure: [Azure DataLake Store](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-overview), [Azure Blob Store](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-overview) `adl://, abs://`\n\n- Google Cloud: [Google Cloud Storage](https://cloud.google.com/storage/) `gs://`\n\n## Development Guide\n\nRead [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines on how to setup a local development environment and make code changes back to Papermill.\n\nFor development guidelines look in the [DEVELOPMENT_GUIDE.md](./DEVELOPMENT_GUIDE.md) file. This should inform you on how to make particular additions to the code base.\n\n## Documentation\n\nWe host the [Papermill documentation](http://papermill.readthedocs.io)\non ReadTheDocs.\n"
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "papermill",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.71484375,
          "content": "# Migration to pyproject.toml is in progress\n\n# Example configuration for Black.\n[tool.black]\nline-length = 120\ntarget-version = ['py311']\nskip-string-normalization = true\n\n\n[tool.coverage.run]\nbranch = false\n\n[tool.coverage.report]\nexclude_lines = [\n    \"if self.debug:\",\n    \"pragma: no cover\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n    \"if __name__ == .__main__.:\",\n]\nomit = [\n    \"papermill/tests/*\",\n    \"papermill/version.py\"\n]\n\n\n[tool.codespell]\nquiet-level = 3\n# comma separated list of words; waiting for:\n#  https://github.com/codespell-project/codespell/issues/2839#issuecomment-1731601603\n# also adding links until they ignored by its: nature\n#  https://github.com/codespell-project/codespell/issues/2243#issuecomment-1732019960\nignore-words-list = \"dne, compiletime\"\n\n\n[tool.ruff]\ntarget-version = \"py38\"\nline-length = 120\n# Enable Pyflakes `E` and `F` codes by default.\nselect = [\n    \"E\", \"W\",  # see: https://pypi.org/project/pycodestyle\n    \"F\",  # see: https://pypi.org/project/pyflakes\n    \"I\",  # isort\n#    \"D\",  # see: https://pypi.org/project/pydocstyle\n#    \"N\",  # see: https://pypi.org/project/pep8-naming\n    \"RUF100\",  # unnecessary noqa comment\n    \"UP\",  # pyupgrade\n]\n#extend-select = [\n#    \"C4\",  # see: https://pypi.org/project/flake8-comprehensions\n#    \"SIM\",  # see: https://pypi.org/project/flake8-simplify\n#    \"RET\",  # see: https://pypi.org/project/flake8-return\n#    \"PT\",  # see: https://pypi.org/project/flake8-pytest-style\n#]\nignore = [\n    \"E731\",  # Do not assign a lambda expression, use a def\n]\n# Exclude a variety of commonly ignored directories.\nexclude = [\n    \"docs\"\n]\nignore-init-module-imports = true\n\n[tool.ruff.pydocstyle]\n# Use Google-style docstrings.\nconvention = \"google\"\n"
        },
        {
          "name": "pytest.ini",
          "type": "blob",
          "size": 0.16015625,
          "content": "[pytest]\nenv =\n    AWS_SECRET_ACCESS_KEY=foobar_secret\n    AWS_ACCESS_KEY_ID=foobar_key\nfilterwarnings =\n    ignore:.*imp module is deprecated.*:DeprecationWarning\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.150390625,
          "content": "click\npyyaml\nnbformat >= 5.2.0\nnbclient >= 0.2.0\ntqdm >= 4.32.2\nrequests\nentrypoints\ntenacity >= 5.0.2\naiohttp >=3.9.0; python_version==\"3.12\"\nansicolors\n"
        },
        {
          "name": "requirements",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 3.5546875,
          "content": "#!/usr/bin/env python\n\"\"\"\"\nsetup.py\n\nSee:\nhttps://packaging.python.org/tutorials/packaging-projects/\nhttps://packaging.python.org/en/latest/distributing.html\nhttps://github.com/pypa/sampleproject\n\n\"\"\"\nimport os\n\nfrom setuptools import setup\n\nlocal_path = os.path.dirname(__file__)\n# Fix for tox which manipulates execution pathing\nif not local_path:\n    local_path = '.'\nhere = os.path.abspath(local_path)\n\n\ndef version():\n    with open(f\"{here}/papermill/version.py\") as ver:\n        for line in ver.readlines():\n            if line.startswith('version ='):\n                return line.split(' = ')[-1].strip()[1:-1]\n    raise ValueError('No version found in papermill/version.py')\n\n\ndef read(fname):\n    with open(fname) as fhandle:\n        return fhandle.read()\n\n\ndef read_reqs(fname, folder=None):\n    path_dir = os.path.join(here, folder) if folder else here\n    req_path = os.path.join(path_dir, fname)\n    return [req.strip() for req in read(req_path).splitlines() if req.strip()]\n\n\ns3_reqs = read_reqs('s3.txt', folder='requirements')\nazure_reqs = read_reqs('azure.txt', folder='requirements')\ngcs_reqs = read_reqs('gcs.txt', folder='requirements')\nhdfs_reqs = read_reqs('hdfs.txt', folder='requirements')\ngithub_reqs = read_reqs('github.txt', folder='requirements')\ndocs_only_reqs = read_reqs('docs.txt', folder='requirements')\nblack_reqs = ['black >= 19.3b0']\nall_reqs = s3_reqs + azure_reqs + gcs_reqs + hdfs_reqs + github_reqs + black_reqs\ndocs_reqs = all_reqs + docs_only_reqs\n# Temporarily remove hdfs_reqs from dev deps until the pyarrow package is available for Python 3.12\ndev_reqs = read_reqs('dev.txt', folder='requirements') + s3_reqs + azure_reqs + gcs_reqs + black_reqs  # all_reqs\nextras_require = {\n    \"test\": dev_reqs,\n    \"dev\": dev_reqs,\n    \"all\": all_reqs,\n    \"s3\": s3_reqs,\n    \"azure\": azure_reqs,\n    \"gcs\": gcs_reqs,\n    \"hdfs\": hdfs_reqs,\n    \"github\": github_reqs,\n    \"black\": black_reqs,\n    \"docs\": docs_reqs,\n}\n\n# Get the long description from the README file\nwith open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n    long_description = f.read()\n\nsetup(\n    name='papermill',\n    version=version(),\n    description='Parameterize and run Jupyter and nteract Notebooks',\n    author='nteract contributors',\n    author_email='nteract@googlegroups.com',\n    license='BSD',\n    # Note that this is a string of words separated by whitespace, not a list.\n    keywords='jupyter mapreduce nteract pipeline notebook',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    url='https://github.com/nteract/papermill',\n    packages=['papermill'],\n    python_requires='>=3.8',\n    install_requires=read_reqs('requirements.txt'),\n    extras_require=extras_require,\n    entry_points={'console_scripts': ['papermill = papermill.__main__:papermill']},\n    project_urls={\n        'Documentation': 'https://papermill.readthedocs.io',\n        'Funding': 'https://nteract.io',\n        'Source': 'https://github.com/nteract/papermill/',\n        'Tracker': 'https://github.com/nteract/papermill/issues',\n    },\n    classifiers=[\n        'Intended Audience :: Developers',\n        'Intended Audience :: System Administrators',\n        'Intended Audience :: Science/Research',\n        'License :: OSI Approved :: BSD License',\n        'Programming Language :: Python',\n        'Programming Language :: Python :: 3',\n        'Programming Language :: Python :: 3.8',\n        'Programming Language :: Python :: 3.9',\n        'Programming Language :: Python :: 3.10',\n        'Programming Language :: Python :: 3.11',\n        'Programming Language :: Python :: 3.12',\n    ],\n)\n"
        },
        {
          "name": "tox.ini",
          "type": "blob",
          "size": 2.078125,
          "content": "[tox]\nskipsdist = true\nenvlist = py{38,39,310,311,312}, dist, manifest, docs, binder\n\n[gh-actions]\npython =\n    3.8: py38\n    3.9: py39\n    3.10: py310\n    3.11: py311, docs\n    3.12: py312, dist\n\n# Manifest\n[testenv:manifest]\nskip_install = true\ndeps = check-manifest\ncommands = check-manifest\nignore =\n    .readthedocs.yaml\n\n# Docs\n[testenv:docs]\ndescription = invoke sphinx-build to build the HTML docs\ndeps =\n    .[docs]\nextras = docs\ncommands =\n    sphinx-build -d \"{toxworkdir}/docs_doctree\" docs \"{toxworkdir}/docs_out\" --color -W -bhtml {posargs}\n    python -c 'import pathlib; print(\"documentation available under file://\\{0\\}\".format(pathlib.Path(r\"{toxworkdir}\") / \"docs_out\" / \"index.html\"))'\n\n# Binder\n[testenv:binder]\ndescription = ensure /binder/*ipynb are runnable\ndeps =\n    -r binder/requirements.txt\ncommands = python -c \"import glob; import papermill as pm; [pm.execute_notebook(input, '{toxworkdir}/out.ipynb', parameters=\\{'binder_dir':'binder'\\}) for input in glob.glob('binder/**/*.ipynb')]\"\n\n# Distro\n[testenv:dist]\nskip_install = true\ncommands =\n    python setup.py sdist --dist-dir={distdir} bdist_wheel --dist-dir={distdir}\n    /bin/bash -c 'python -m pip install -U --force-reinstall {distdir}/papermill*.tar.gz'\n    /bin/bash -c 'python -m pip install -U --force-reinstall {distdir}/papermill*.whl'\n\n[testenv]\n# disable Python's hash randomization for tests that stringify dicts, etc\nsetenv =\n    PYTHONHASHSEED = 0\n    AWS_ACCESS_KEY_ID=foobar_key\n    AWS_SECRET_ACCESS_KEY=foobar_secret\npassenv = *\nbasepython =\n    py38: python3.8\n    py39: python3.9\n    py310: python3.10\n    py311: python3.11\n    py312: python3.12\n    manifest: python3.11\n    dist: python3.12\n    docs: python3.11\n    binder: python3.11\ndeps = .[dev]\n# Have to use /bin/bash or the `*` will cause that argument to get quoted by the tox command line...\nallowlist_externals = /bin/bash\n# Python 3.12 breaks default pip/setuptools versions ... force an upgrade of these before anything else\ninstall_command = /bin/bash ./tox_py_installer.sh {opts} {packages}\ncommands = pytest -v --maxfail=2 --cov=papermill -W always {posargs}\n"
        },
        {
          "name": "tox_py_installer.sh",
          "type": "blob",
          "size": 0.1513671875,
          "content": "#!/bin/bash\npython -m ensurepip --upgrade\npython -m pip install --upgrade setuptools\n# python -m pip install {opts} {packages}\npython -m pip install $1 $2\n"
        }
      ]
    }
  ]
}