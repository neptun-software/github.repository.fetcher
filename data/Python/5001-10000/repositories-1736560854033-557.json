{
  "metadata": {
    "timestamp": 1736560854033,
    "page": 557,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjU2MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "StackStorm/st2",
      "stars": 6140,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".agignore",
          "type": "blob",
          "size": 0.0234375,
          "content": "virtualenv\nnode_modules\n"
        },
        {
          "name": ".circle",
          "type": "tree",
          "content": null
        },
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".coveragerc",
          "type": "blob",
          "size": 0.369140625,
          "content": "; http://nedbatchelder.com/code/coverage/config.html\n\n[run]\nbranch = True\nconcurrency = eventlet\ninclude = st2*,contrib/runners/*\ndisable_warnings = include-ignored,module-not-imported\nomit = */*/wsgi.py\n       */*/util/wsgi.py  ; st2common/st2common/util/wsgi.py\n       */setup.py\n       contrib/runners/*/setup.py\n       */dist_utils.py\n       contrib/runners/*/dist_utils.py\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.0283203125,
          "content": "./lint-configs/python/.flake8"
        },
        {
          "name": ".git-blame-ignore-rev",
          "type": "blob",
          "size": 0.1748046875,
          "content": "# Code was auto formatted using black\n8496bb2407b969f0937431992172b98b545f6756\n\n# Files were auto formatted to remove trailing whitespace\n969793f1fdbdd2c228e59ab112189166530d2680\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.4091796875,
          "content": "# See: https://www.mankier.com/5/gitattributes\n\n# lockfile merge conflicts: do not manually merge.\n# The \"-merge\" makes git leave the current branch's lockfile as-is, like a binary file.\n# To resolve the conflict, resolve any conflicts in requirements files,\n# and then regenerste the lockfile with (resolve names are 'st2', 'black', etc):\n#   pants generate-lockfiles --resolve=<resolve name>\n/lockfiles/*.lock -merge\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.873046875,
          "content": "*.py[cod]\n*.sqlite\n*.log\n*.orig\n.stamp*\n\n# C extensions\n*.so\n\n# Packages\n*.egg\n*.egg-info\ndist\n.venv\neggs\nparts\n#bin\nvar\nsdist\ndevelop-eggs\n.installed.cfg\nlib64\nvirtualenv\nvirtualenv-py3\nvirtualenv-osx\nvirtualenv-st2client\nvirtualenv-st2client-osx\nvirtualenv-components\nvirtualenv-components-osx\n.venv-st2devbox\n\n# generated travis conf\nconf/st2.travis.conf\n# generated GitHub Actions conf\nconf/st2.githubactions.conf\n\n# Installer logs\npip-log.txt\n\n# Unit test / coverage reports\n.coverage\n.coverage.integration.*\n.coverage.integration\n.coverage.unit.*\n.coverage.unit\ncover\ncoverage*.xml\n.tox\nnosetests.xml\nhtmlcov\nbenchmark_histograms/\n\n# Pants workspace files\n/.pants.d/\n/dist/\n/.pids\n/.pants.workdir.file_lock*\n\n# Mr Developer\n.idea\n.DS_Store\n._*\n.vscode\n*.sublime-project\n*.sublime-workspace\n\n# Editor Saves\n*~\n\\#*\\#\n[._]*.sw[a-px]\n[._]sw[a-px]\n[._]*.sw[a-p]x\n[._]sw[a-p]x\n\n**/build/lib/**\n"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.20703125,
          "content": "[submodule \"st2tests/st2tests/fixtures/packs/test_content_version\"]\n\tpath = st2tests/st2tests/fixtures/packs/test_content_version\n\turl = https://github.com/StackStorm-Exchange/stackstorm-test-content-version.git\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 1.3837890625,
          "content": "# pre-commit hook which runs all the various lint checks + black auto formatting on the added\n# files.\n# This hook relies on development virtual environment being present in virtualenv/.\ndefault_language_version:\n  # We don't specify a specific version so it uses either Python 3.6 / Python\n  # 3.8 depending on what is available locally and on the runner\n  python: python\n\nexclude: '(build|dist)'\nrepos:\n  - repo: local\n    hooks:\n    - id: black\n      name: black\n      entry: ./virtualenv/bin/python -m black --config pyproject.toml\n      language: script\n      types: [file, python]\n  - repo: local\n    hooks:\n    - id: flake8\n      name: flake8\n      entry: ./virtualenv/bin/python -m flake8 --config lint-configs/python/.flake8\n      language: script\n      types: [file, python]\n  - repo: local\n    hooks:\n    - id: pylint\n      name: pylint\n      entry: ./virtualenv/bin/python -m pylint -E --rcfile=./lint-configs/python/.pylintrc\n      language: script\n      types: [file, python]\n  - repo: local\n    hooks:\n    - id: bandit\n      name: bandit\n      entry: ./virtualenv/bin/python -m bandit -lll -x build,dist\n      language: script\n      types: [file, python]\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n    - id: trailing-whitespace\n      exclude: (^conf/|^st2common/st2common/openapi.yaml|^st2client/tests/fixtures|^st2tests/st2tests/fixtures)\n    - id: check-yaml\n"
        },
        {
          "name": ".pylintrc",
          "type": "blob",
          "size": 0.0302734375,
          "content": "./lint-configs/python/.pylintrc"
        },
        {
          "name": "ADOPTERS.md",
          "type": "blob",
          "size": 6.892578125,
          "content": "# Who uses StackStorm?\nAs the StackStorm Community evolves, we'd like to keep track of our users. Please submit a PR with your organization and a brief use case description below.\n\nThis is an alphabetical list of known [StackStorm](https://stackstorm.com/) adopters:\n\n<!-- Max 3 Github lines for each adopter! -->\n\n* [Adobe](https://www.adobe.com/) - Multinational computer software company. After evaluating both SaltStack and Rundeck, Adobe chose StackStorm towards their journey to self-healing infrastructure. As a result, SRE team could resolve thousands of alerts and fix 70% of the outages automatically without human intervention. [[ DevOpsDays Notes ](https://threadreaderapp.com/thread/1098901714567081984.html)] [[ DevOpsCon Talk ](https://devopscon.io/monitoring-traceability-diagnostics/workflow-engines-our-journey-towards-a-self-healing-infrastructure/)]\n* [Bitovi](https://www.bitovi.com/) - Consulting company, implemented an Automation solution based on StackStorm API with HA capabilities and custom UI for a Fortune top 10 organization. [[ Blog ](https://www.bitovi.com/blog/stackstorm-solves-devops-automation-for-enterprise-client)] [[ Case study ](https://stackstorm.com/case-study-bitovi/)]\n* [CERN](https://home.cern) - CERN's Batch team uses StackStorm for Auto-Remediation Workflows for their compute farm, handling AFS storage overloads, and other automation for maintaining the research infrastructure. [[ HEPIX Presentation ](https://codimd.web.cern.ch/p/r6lbybhXy#/1)] [[ CHEP Presentation ](https://indico.jlab.org/event/459/contributions/11638/attachments/9708/14174/chep23_stackstorm.pptx)]\n* [DMM.com](https://dmm-corp.com/en/) - Large content provider in Japan. StackStorm is used in Operations helping to maintain online services and development at scale. [[ Case study ](https://stackstorm.com/case-study-dmm/)]\n* [DigitalOcean](https://www.digitalocean.com/about) - DigitalOcean simplifies cloud computing so builders can spend more time creating software that changes the world. Internally, StackStorm is used as a consistent frontend to our numerous operational tools, and it also plays the part of the orchestration and automation engine driving the machine lifecycle of our vast fleet of machines spread across the globe.\n* [Dimension Data](https://www.dimensiondata.com/en/about-us) - Global systems integrator and IT services provider, using StackStorm for Datacenter Orchestration as well as Infrastructure, Networking, Security Automation for their large clients and government projects. [[ Case study ](https://stackstorm.com/case-study-dimension-data/)]\n* [Encore](https://www.encore.tech/) - Data Center, Cloud Computing, IT solutions company ​leverages StackStorm in enterprise scale IT infrastructure for VM & server provisioning, automation, network diagnosis, configuration and orchestration​ on customers' public and private clouds. [[ Blog ](https://encoretechnologies.github.io/blog/2018/03/stackstorm-changed-our-lives/)] [[ Case study ](https://stackstorm.com/case-study-encore/)]\n* [Fastly](https://www.fastly.com) - Edge Cloud Platform, implemented StackStorm as part of a bigger global network automation architecture aimed at providing an interface to network operations and traffic engineering changes triggered both manually or in response to events on hundreds of devices spread across dozens of sites. [[ Blog ](https://www.fastly.com/blog/network-automation-helps-support-worlds-biggest-live-streaming-moments)]\n* [Hewlett Packard Enterprise](https://www.hpe.com/) - Enterprise IT company that integrated StackStorm into its Composable Fabric Manager software. StackStorm is used for driving fabric and application automation based on integrations with VMware vSphere/NSX, HPE OneView/SimpliVity, Nutanix, Kubernetes, and OpenShift. [[ Blog ](https://developer.hpe.com/blog/master-the-automation-universe-the-easy-way-part-1-introduction-to-stack)]\n* [NL-ix](https://www.nl-ix.net/about/company/) - One of the top five internet exchange in the world where StackStorm is used as Automation Orchestrator, event-driven engine for route server configuration. [[ Case study ](https://stackstorm.com/case-study-nlix/)]\n* [Netflix](https://media.netflix.com/en/about-netflix) - Worldwide media services provider relies on Event-Driven Automation when remediation tasks and runbooks executed in response to alerts. Custom solution built on top StackStorm helped to self-heal NFLX infra at a big scale, saving SRE's sleep. [[ Slides ](https://www.slideshare.net/InfoQ/winston-helping-netflix-engineers-sleep-at-night)] [[ Blog ](https://medium.com/netflix-techblog/introducing-winston-event-driven-diagnostic-and-remediation-platform-46ce39aa81cc)] [[ Case study ](https://stackstorm.com/case-study-netflix/)]\n* [Pearson](https://www.pearson.com/corporate/about-pearson.html) - An international education company serving more than 75 million learners uses containers, Kubernetes, StackStorm and other open source technologies to streamline their development, operations and delivery of the new products. [[ Case study ](https://stackstorm.com/case-study-pearson/)]\n* [Schwarz Digits](https://gruppe.schwarz/en) - We are passionate retailers. The company's Lidl, Kaufland and Schwarz Digits uses StackStorm for self-healing infrastructure in response to alerts, scheduled maintenance, routine tasks and DevOps Automation. It runs on its own [STACKIT](https://www.stackit.de/en/) cloud. [[ Blog ](https://techblog.schwarz/posts/getting-rid-of-operational-tasks-using-stackstorm/)]\n* [SciLifeLab](https://www.scilifelab.se/about-us/) - [The Arteria project](https://arteria-project.github.io/) provides components to automate analysis and data-management tasks at a next-generation bigdata genomics sequencing center based on StackStorm workflows. StackStorm helps with genomic computation in a cancer research. [[ Blog ](https://stackstorm.com/2016/11/15/genomics-sequencing-stackstorm-reading-source-code-biology/)] [[ Case study ](https://stackstorm.com/case-study-scilifelab)]\n* [Target](https://stackstorm.com/case-study-target/) -  one of the largest department store retailers in the US uses StackStorm as an orchestrator within a Target Cloud Platform Engineering group to ensure that integrity, policies and regulatory compliance are maintained via event-driven security automation. [[ Case study ](https://stackstorm.com/case-study-target/)]\n* [Verizon](https://www.verizon.com/about/) - One of the world's largest telecommunications companies which offers wireless products and services. StackStorm helps dealing with massive scale by automating support for tens of thousands of servers across 100+ datacenters and reducing engineer time spent following a manual series of steps. StackStorm automation, infrastructure-as-code and chatops transformed how Verizon teams deploy, change, repair and decommission server infrastructure with a globally-consistent performance. [[ Blog ](https://medium.com/@VZMediaPlatform/using-stackstorm-to-automate-support-for-20-000-servers-4b47ae3a4e98)]\n"
        },
        {
          "name": "BUILD",
          "type": "blob",
          "size": 3.658203125,
          "content": "python_requirements(\n    name=\"reqs\",\n    source=\"requirements-pants.txt\",\n    overrides={\n        # flex and stevedore uses pkg_resources w/o declaring the dep\n        (\"flex\", \"stevedore\"): dict(\n            dependencies=[\n                \"//:reqs#setuptools\",\n            ]\n        ),\n        # do not use the prance[flex] extra as that pulls in an old version of flex\n        \"prance\": dict(\n            dependencies=[\n                \"//:reqs#flex\",\n            ]\n        ),\n        # tooz needs one or more backends (tooz is used by the st2 coordination backend)\n        \"tooz\": dict(\n            dependencies=[\n                \"//:reqs#redis\",\n                \"//:reqs#zake\",\n            ]\n        ),\n        # make sure anything that uses st2-auth-ldap gets the st2auth constant\n        \"st2-auth-ldap\": dict(\n            dependencies=[\n                \"st2auth/st2auth/backends/constants.py\",\n            ]\n        ),\n        # make sure anything that uses st2-rbac-backend gets its deps\n        \"st2-rbac-backend\": dict(\n            dependencies=[\n                # alphabetical order\n                \"st2common/st2common/config.py\",\n                \"st2common/st2common/constants/keyvalue.py\",\n                \"st2common/st2common/constants/triggers.py\",\n                \"st2common/st2common/content/loader.py\",\n                \"st2common/st2common/exceptions/db.py\",\n                \"st2common/st2common/exceptions/rbac.py\",\n                \"st2common/st2common/log.py\",\n                \"st2common/st2common/models/api/rbac.py\",\n                \"st2common/st2common/models/db/action.py\",\n                \"st2common/st2common/models/db/auth.py\",\n                \"st2common/st2common/models/db/pack.py\",\n                \"st2common/st2common/models/db/rbac.py\",\n                \"st2common/st2common/models/db/webhook.py\",\n                \"st2common/st2common/models/system/common.py\",\n                \"st2common/st2common/persistence/auth.py\",\n                \"st2common/st2common/persistence/execution.py\",\n                \"st2common/st2common/persistence/rbac.py\",\n                \"st2common/st2common/rbac/backends/__init__.py\",\n                \"st2common/st2common/rbac/backends/base.py\",\n                \"st2common/st2common/rbac/types.py\",\n                \"st2common/st2common/script_setup.py\",\n                \"st2common/st2common/util/action_db.py\",\n                \"st2common/st2common/util/misc.py\",\n                \"st2common/st2common/util/uid.py\",\n            ]\n        ),\n    },\n)\n\ntarget(\n    name=\"auth_backends\",\n    dependencies=[\n        \"//:reqs#st2-auth-backend-flat-file\",\n        \"//:reqs#st2-auth-ldap\",\n    ],\n)\n\ntarget(\n    name=\"rbac_backends\",\n    dependencies=[\n        \"//:reqs#st2-rbac-backend\",\n    ],\n)\n\npython_test_utils(\n    name=\"test_utils\",\n    skip_pylint=True,\n)\n\nfile(\n    name=\"license\",\n    source=\"LICENSE\",\n)\n\nshell_sources(\n    name=\"root\",\n)\n\nfile(\n    name=\"logs_directory\",\n    source=\"logs/.gitignore\",\n)\n\nfiles(\n    name=\"gitmodules\",\n    sources=[\n        \".gitmodules\",\n        \"**/.git\",\n    ],\n)\n\nshell_command(\n    name=\"capture_git_modules\",\n    environment=\"in_repo_workspace\",\n    command=\"cp -r .git/modules {chroot}/.git\",\n    tools=[\"cp\"],\n    # execution_dependencies allows pants to invalidate the output\n    # of this command if the .gitmodules file changes (for example:\n    # if a submodule gets updated to a different repo).\n    # Sadly this does not get invalidated if the submodule commit\n    # is updated. In our case, that should be rare. To work around\n    # this, kill the `pantsd` process after updating a submodule.\n    execution_dependencies=[\":gitmodules\"],\n    output_dependencies=[\":gitmodules\"],\n    output_directories=[\".git/modules\"],\n    workdir=\"/\",\n)\n"
        },
        {
          "name": "BUILD.environment",
          "type": "blob",
          "size": 1.0302734375,
          "content": "# Everything listed in pants.toml [evironments-preview.names] should be defined here.\n# Relevant docs:\n# - https://www.pantsbuild.org/stable/docs/using-pants/environments\n# - https://www.pantsbuild.org/stable/reference/targets/experimental_workspace_environment\n# - https://www.pantsbuild.org/stable/reference/targets/local_environment\n# - https://www.pantsbuild.org/stable/reference/targets/docker_environment\n\n# This file MUST NOT use any macros.\n\nexperimental_workspace_environment(\n    name=\"in_repo_workspace\",\n    description=(\n        \"\"\"\n        This allows shell_command and similar to run in the repo, instead of in a sandbox.\n        Only use this environment for commands or goals that are idempotent.\n        Ideally, such commands do NOT change anything in the repo.\n\n        If you need to capture output, note that output gets captured from a temporary\n        sandbox, not from the repo root. So, you may need to copy output files into\n        the sandbox with something like `cp path/to/file {chroot}/path/to/file`.\n        \"\"\"\n    ),\n)\n"
        },
        {
          "name": "BUILD.tools",
          "type": "blob",
          "size": 1.8720703125,
          "content": "# This BUILD file has requirements for most of the tools resolves\n\npython_requirement(\n    name=\"bandit-reqs\",\n    resolve=\"bandit\",\n    requirements=[\n        # https://github.com/pantsbuild/pants/blob/release_2.23.0rc0/src/python/pants/backend/python/lint/bandit/subsystem.py#L44-L52\n        \"bandit>=1.7.0,<1.8\",\n        \"setuptools\",\n        \"GitPython>=3.1.24\",\n    ],\n)\n\npython_requirement(\n    name=\"black-reqs\",\n    resolve=\"black\",\n    requirements=[\n        \"black==22.3.0\",\n        \"typing-extensions>=3.10.0.0;python_version<'3.10'\",\n    ],\n)\n\npython_requirement(\n    name=\"flake8-reqs\",\n    resolve=\"flake8\",\n    requirements=[\n        \"flake8==7.0.0\",  # st2flake8 does not support flake8 v5\n        # license check plugin\n        \"st2flake8>0.1.0\",  # TODO: remove in favor of regex-lint or preamble\n    ],\n)\n\n# for pants-plugins, see //pants-plugins/BUILD\n# for pylint, see //pylint_plugins/BUILD\n\npython_requirement(\n    name=\"pytest-reqs\",\n    resolve=\"st2\",\n    requirements=[\n        \"pytest==7.0.1\",  # copied from https://www.pantsbuild.org/v2.14/docs/reference-pytest#version\n        \"pytest-benchmark[histogram]==3.4.1\",  # used for st2common/benchmarks\n        # \"pytest-timer[colorama]\",  # report test timing (--with-timer ala nose-timer)\n        \"pytest-icdiff\",  # make diff output easier to read\n        # \"pygments\",  # highlight code in tracebacks (already included in requirements-pants.txt)\n        #\n        # other possible plugins\n        # \"pytest-timeout\",  # time limit on tests\n        # \"pytest-mock\",  # more convenient mocking\n        #\n        # needed by pants\n        \"pytest-cov>=2.12,!=2.12.1,<3.1\",  # coverage\n        \"pytest-xdist>=2.5,<3\",  # parallel test runs (pants uses this if [pytest].xdist_enabled)\n    ],\n)\n\npython_requirement(\n    name=\"twine-reqs\",\n    resolve=\"twine\",\n    requirements=[\n        \"twine>=3.7.1,<3.8\",\n        \"colorama>=0.4.3\",\n    ],\n)\n"
        },
        {
          "name": "CHANGELOG.rst",
          "type": "blob",
          "size": 225.3974609375,
          "content": "Changelog\n=========\n\nin development\n--------------\n\nPython 3.6 is no longer supported; Stackstorm requires at least Python 3.8.\nThis release adds support for Python 3.10 and 3.11, so StackStorm supports python 3.8 - 3.11.\n\nNewer MongoDB versions are now supported. CI uses MongoDB 7.0.\n\nSeveral st2.conf database options have been renamed or deprecated. Most of the options will continue to work using their old name.\nHowever, if you use `[database].ssl_keyfile` and/or `[database].ssl_certfile`, you MUST migrate to `[database].tls_certificate_key_file`.\nThis new option expects the key and certificate in the same file. Use something like the following to create that file from your old files:\n\n```\ncat path/to/ssl_keyfile path/to/ssl_certfile > path/to/tls_certificate_key_file\n```\n\nOther options that were renamed under `[database]` are (more details available in `st2.conf.sample`):\n\n* `ssl` -> `tls`\n* `ssl_cert_reqs` -> `tls_allow_invalid_certificates` (opt type change: string -> boolean)\n* `ssl_ca_certs` -> `tls_ca_file`\n* `ssl_match_hostnames` -> `tls_allow_invalid_hostnames` (meaning is inverted: the new option is the opposite of the old)\n\nFixed\n~~~~~\n* Fixed #6021 and #5327 by adding max_page_size to api_opts and added limit and offset to list_values() methods of\n  both action_service and sensor_service\n* Fix `packs.get` action. Assumed `master` is primary branch on all packs. #6225\n* Restore Pack integration testing (it was inadvertently skipped) and stop testing against `bionic` and `el7`. #6135\n* Fix Popen.pid typo in st2tests. #6184\n* Bump tooz package to `6.2.0` to fix TLS. #6220 (@jk464)\n* Shells via `pywinrm` are initialized with the 65001 codepage to ensure raw string responses are UTF-8. #6034 (@stealthii)\n\nChanged\n~~~~~~~\n* Bumped `jsonschema` 2.6.0 -> 3.2.0 now that python3.6 is not supported. #6118\n* Bumped many deps based on the lockfiles generated by pants+pex. #6181 #6227 #6200 #6252 #6268 (by @cognifloyd and @nzlosh)\n* Switch to python3's standard lib unittest from unittest2, a backport of python3 unittest features for python2. #6187 (by @nzlosh)\n* Drop Python 3.6 testing in CircleCI. #6080\n  Contributed by (@philipphomberger Schwarz IT KG)\n* Refactor `tools/launchdev.sh` to use `tmux` instead of `screen`. #6186 (by @nzlosh and @cognifloyd)\n* Updated package build container environment to use py3.8 and mongo4.4  #6129\n* Fix misc DeprecationWarnings to prepare for python 3.10 support. #6188 (by @nzlosh)\n* Update st2client deps: editor and prompt-toolkit. #6189 (by @nzlosh)\n* Updated dependency oslo.config to prepare for python 3.10 support. #6193 (by @nzlosh)\n\n* Updated unit tests to use redis for coordination instead of the NoOp driver. This will hopefully make CI more stable. #6245\n  Contributed by @FileMagic, @guzzijones, and @cognifloyd\n\n* Renamed `[database].ssl*` options to support pymongo 4, which we have to update to support newer MongoDB servers.\n  Please see the note above about migrating to the newer options, especially if you use `[database].ssl_keyfile`\n  and/or `[database].ssl_certfile`, as those options are ignored in StackStorm 3.9.0. #6250\n  Contributed by @cognifloyd\n\n* Update mongoengine to 0.29 and pymongo to 4.6.3. The pymongo bump (from 3.x to 4.x) is a major update. #6252\n  Contributed by @cognifloyd\n\n* Update CI from testing with mongo 4.4 to testing with MongoDB 7.0. #6246\n  Contributed by @guzzijones\n\n* Relaxed `dnspython` pinning for compatibility with python 3.10 and greater. #6265\n  Contributed by @nzlosh\n\n* Switched tests from `nosetest` to `pytest`. `st2-run-pack-tests` also uses pytest.\n  So, all pack tests must be runnable by `pytest`, which may require migration. #6291\n  Contributed by @nzlosh, @FileMagic, @guzzijones, and @cognifloyd.\n\nAdded\n~~~~~\n* Continue introducing `pants <https://www.pantsbuild.org/docs>`_ to improve DX (Developer Experience)\n  working on StackStorm, improve our security posture, and improve CI reliability thanks in part\n  to pants' use of PEX lockfiles. This is not a user-facing addition.\n  #6118 #6141 #6133 #6120 #6181 #6183 #6200 #6237 #6229 #6240 #6241 #6244 #6251 #6253\n  #6254 #6258 #6259 #6260 #6269 #6275 #6279 #6278 #6282 #6283 #6273 #6287\n  Contributed by @cognifloyd\n* Build of ST2 EL9 packages #6153\n  Contributed by @amanda11\n* Ensure `.pth` files in the st2 virtualenv get loaded by pack virtualenvs. #6183\n  Contributed by @cognifloyd\n* Allow `st2-rule-tester` to run without a mongo connection if user is testing against local `rule`/`trigger-instance` files. #6208\n  Contributed by @jk464\n\n* Added a `get_result` method to the `ExecutionResourceManager` Class for st2client\n  Contributed by @skiedude\n\n* Added new env var for tests: `ST2TESTS_SYSTEM_USER`. When set, this will override `system_user.user` in st2 conf\n  so that you can run tests on systems that do not have the `stanley` user. When running tests locally, use the\n  following to set system user to the current user: `export ST2TESTS_SYSTEM_USER=$(id -un)` #6242\n  Contributed by @cognifloyd\n\n* Added experimental support for setting conf vars via environment variables. All settings in `st2.conf` can be\n  overriden via enviornment vars in the format: `ST2_<conf section>__<option name>` (env vars are upper cased)\n  For example, the `[database].password` setting in `st2.conf` could be overriden using `ST2_DATABASE__PASSWORD`.\n  This new feature is based on oslo_config's environment support, but patches it to use the `ST2_` prefix.\n  If you experience any issues when using this experimental feature, please file an issue. #6277\n  Contributed by @cognifloyd\n\n* Add new option `[messaging].prefix` to configure the prefix used in RabbitMQ exchanges and queues.\n  The default is `st2` (resulting in exchange names like `st2.execution` and `st2.sensor`).\n  This is primarily designed to support safely running tests in parallel where creating a vhost for\n  each parallel test run would be a maintenance burden. #6282\n  Contributed by @cognifloyd\n\n* Add python 3.10 and 3.11 to the GitHub Actions test matrix.\n  Contributed by @nzlosh, @guzzijones12, and @cognifloyd\n\n3.8.1 - December 13, 2023\n-------------------------\nFixed\n~~~~~\n* Fix proxy auth mode in HA environments #5766 #6049\n  Contributed by @floatingstatic\n\n* Fix issue with linux pack actions failed to run remotely due to incorrect python shebang. #5983 #6042\n  Contributed by Ronnie Hoffmann (@ZoeLeah Schwarz IT KG)\n\n* Fix CI usses #6015\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n* Bumped `paramiko` to `2.10.5` to fix an issue with SSH Certs - paramiko/paramiko#2017 (security)\n  Contributed by @jk464\n\n* Avoid logging sensitive information in debug (fix #5977)\n\n* Fix codecov failures for stackstorm/st2 tests. #6035, #6046, #6048\n\n* Fix #4676, edge case where --inherit-env is skipped if the action has no parameters\n\n* Fix ST2 Client for Windows Clients. PWD is a Unix only Libary. #6071\n  Contributed by (@philipphomberger Schwarz IT KG)\n\n* Fix Snyk Security Finding Cross-site Scripting (XSS) in contrib/examples/sensors/echo_flask_app.py #6070\n  Contributed by (@philipphomberger Schwarz IT KG)\n\n* Update cryptography 3.4.7 -> 39.0.1, pyOpenSSL 21.0.0 -> 23.1.0, paramiko 2.10.5 -> 2.11.0 (security). #6055\n\n* Bumped `eventlet` to `0.33.3` and `gunicorn` to `21.2.0` to fix `RecursionError` bug in setting `SSLContext` `minimum_version` property. (security) #6061\n  Contributed by @jk464\n\n* Update orquesta to v1.6.0 to fix outdated dependencies (security). #6050\n\n* Fix KV value lookup in actions when RBAC is enabled #5934\n\n* Update version 3.1.15 of ``gitpython`` to 3.1.18 for py3.6 and to 3.1.37 for py3.8 (security). #6063\n\n* Update importlib-metadata from 3.10.1 to 4.8.3 for py3.6 and to 4.10.1 for py3.8 (security). #6072\n  Contributed by @jk464\n\n* For \"local-shell-script\" runner, on readonly filesystems, don't attempt to run chmod +x on script_action. Fixes #5591\n  Contributed by @jk464\n\nAdded\n~~~~~\n* Move `git clone` to `user_home/.st2packs` #5845\n\n* Error on `st2ctl status` when running in Kubernetes. #5851\n  Contributed by @mamercad\n\n* Continue introducing `pants <https://www.pantsbuild.org/docs>`_ to improve DX (Developer Experience)\n  working on StackStorm, improve our security posture, and improve CI reliability thanks in part\n  to pants' use of PEX lockfiles. This is not a user-facing addition.\n  #5778 #5789 #5817 #5795 #5830 #5833 #5834 #5841 #5840 #5838 #5842 #5837 #5849 #5850\n  #5846 #5853 #5848 #5847 #5858 #5857 #5860 #5868 #5871 #5864 #5874 #5884 #5893 #5891\n  #5890 #5898 #5901 #5906 #5899 #5907 #5909 #5922 #5926 #5927 #5925 #5928 #5929 #5930\n  #5931 #5932 #5948 #5949 #5950\n  Contributed by @cognifloyd\n\n* Added a joint index to solve the problem of slow mongo queries for scheduled executions. #5805\n\n* Added publisher to ActionAlias to enable streaming ActionAlias create/update/delete events. #5763\n  Contributed by @ubaumann\n\n* Expose environment variable ST2_ACTION_DEBUG to all StackStorm actions.\n  Contributed by @maxfactor1\n\n* Python 3.9 support. #5730\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n* Run the st2 self-check in Github Actions and support the environment variable `TESTS_TO_SKIP` to skip tests when running st2-self-check. #5609\n  Contributed by @winem\n\nChanged\n~~~~~~~\n* Remove `distutils` dependencies across the project. #5992\n  Contributed by @AndroxxTraxxon\n\n3.8.0 - November 18, 2022\n-------------------------\n\nFixed\n~~~~~\n\n* Fix redis SSL problems with sentinel #5660\n\n* Fix a bug in the pack config loader so that objects covered by an ``patternProperties`` schema\n  or arrays using ``additionalItems`` schema(s) can use encrypted datastore keys and have their\n  default values applied correctly. #5321\n\n  Contributed by @cognifloyd\n\n* Fixed ``st2client/st2client/base.py`` file to check for http_proxy and https_proxy environment variables for both lower and upper cases.\n\n  Contributed by @S-T-A-R-L-O-R-D\n\n* Fixed a bug where calling 'get_by_name' on client for getting key details was not returning any results despite key being stored. #5677\n\n  Contributed by @bharath-orchestral\n\n* Fixed ``st2client/st2client/base.py`` file to use ``https_proxy``(not ``http_proxy``) to check HTTPS_PROXY environment variables.\n\n  Contributed by @wfgydbu\n\n* Fixed schema utils to more reliably handle schemas that define nested arrays (object-array-object-array-string) as discovered in some\n  of the ansible installer RBAC tests (see #5684). This includes a test that reproduced the error so we don't hit this again. #5685\n\n* Fixed eventlet monkey patching so more of the unit tests work under pytest. #5689\n\n* Fix and reenable prance-based openapi spec validation, but make our custom ``x-api-model`` validation optional as the spec is out-of-date. #5709\n  Contributed by @cognifloyd\n\n* Fixed generation of `st2.conf.sample` to show correct syntax for `[sensorcontainer].partition_provider` (space separated `key:value` pairs). #5710\n  Contributed by @cognifloyd\n\n* Fix access to key-value pairs in workflow and action execution where RBAC rules did not get applied #5764\n\n  Contributed by @m4dcoder\n\n* Add backward compatibility to secret masking introduced in #5319 to prevent security-relative issues.\n  Migration to the new schema is required to take advantage of the full output schema validation. #5783\n\n  Contributed by @m4dcoder\n\n\nAdded\n~~~~~\n\n* Added graceful shutdown for workflow engine. #5463\n  Contributed by @khushboobhatia01\n\n* Add ``ST2_USE_DEBUGGER`` env var as alternative to the ``--use-debugger`` cli flag. #5675\n  Contributed by @cognifloyd\n\n* Added purging of old tokens. #5679\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n* Begin introducing `pants <https://www.pantsbuild.org/docs>`_ to improve DX (Developer Experience)\n  working on StackStorm, improve our security posture, and improve CI reliability thanks in part\n  to pants' use of PEX lockfiles. This is not a user-facing addition. #5713 #5724 #5726 #5725 #5732 #5733 #5737 #5738 #5758 #5751 #5774 #5776 #5777 #5782\n  Contributed by @cognifloyd\n\n* Added querytype parameter to linux.dig action to allow specifying the dig 'type' parameter. Fixes #5772\n\n  Contributed by @AmbiguousYeoman\n\nChanged\n~~~~~~~\n\n* BREAKING CHANGE for anyone that uses ``output_schema``, which is disabled by default.\n  If you have ``[system].validate_output_schema = True`` in st2.conf AND you have added\n  ``output_schema`` to any of your packs, then you must update your action metadata.\n\n  ``output_schema`` must be a full jsonschema now. If a schema is not well-formed, we ignore it.\n  Now, ``output`` can be types other than object such as list, bool, int, etc.\n  This also means that all of an action's output can be masked as a secret.\n\n  To get the same behavior, you'll need to update your output schema.\n  For example, this schema:\n\n  .. code-block:: yaml\n\n    output_schema:\n      property1:\n        type: bool\n      property2:\n        type: str\n\n  should be updated like this:\n\n  .. code-block:: yaml\n\n    output_schema:\n      type: object\n      properties:\n        property1:\n          type: bool\n        property2:\n          type: str\n      additionalProperties: false\n\n  #5319\n\n  Contributed by @cognifloyd\n\n* Changed the `X-XSS-Protection` HTTP header from `1; mode=block` to `0` in the `conf/nginx/st2.conf` to align with the OWASP security standards. #5298\n\n  Contributed by @LiamRiddell\n\n* Use PEP 440 direct reference requirements instead of legacy PIP VCS requirements. Now, our ``*.requirements.txt`` files use\n  ``package-name@ git+https://url@version ; markers`` instead of ``git+https://url@version#egg=package-name ; markers``. #5673\n  Contributed by @cognifloyd\n\n* Move from udatetime to ciso8601 for date functionality ahead of supporting python3.9 #5692\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n* Refactor tests to use python imports to identify test fixtures. #5699 #5702 #5703 #5704 #5705 #5706\n  Contributed by @cognifloyd\n\n* Refactor ``st2-generate-schemas`` so that logic is in an importable module. #5708\n  Contributed by @cognifloyd\n\nRemoved\n~~~~~~~\n\n* Removed st2exporter service. It is unmaintained and does not get installed. It was\n  originally meant to help with analytics by exporting executions as json files that\n  could be imported into something like elasticsearch. Our code is now instrumented\n  to make a wider variety of stats available to metrics drivers. #5676\n  Contributed by @cognifloyd\n\n3.7.0 - May 05, 2022\n--------------------\n\nAdded\n~~~~~\n\n* Added st2 API get action parameters by ref. #5509\n\n  API endpoint ``/api/v1/actions/views/parameters/{action_id}`` accepts ``ref_or_id``.\n\n  Contributed by @DavidMeu\n\n* Enable setting ttl for MockDatastoreService. #5468\n\n  Contributed by @ytjohn\n\n* Added st2 API and CLI command for actions clone operation.\n\n  API endpoint ``/api/v1/actions/{ref_or_id}/clone`` takes ``ref_or_id`` of source action.\n  Request method body takes destination pack and action name. Request method body also takes\n  optional parameter ``overwrite``. ``overwrite = true`` in case of destination action already exists and to be\n  overwritten.\n\n  CLI command ``st2 action clone <ref_or_id> <dest_pack> <dest_action>`` takes source ``ref_or_id``, destination\n  pack name and destination action name as mandatory arguments.\n  In case destination already exists then command takes optional argument ``-f`` or ``--force`` to overwrite\n  destination action. #5345\n\n  Contributed by @mahesh-orch.\n\n* Implemented RBAC functionality for existing ``KEY_VALUE_VIEW, KEY_VALUE_SET, KEY_VALUE_DELETE`` and new permission types ``KEY_VALUE_LIST, KEY_VALUE_ALL``.\n  RBAC is enabled in the ``st2.conf`` file. Access to a key value pair is checked in the KeyValuePair API controller. #5354\n\n  Contributed by @m4dcoder and @ashwini-orchestral\n\n* Added service deregistration on shutdown of a service. #5396\n\n  Contributed by @khushboobhatia01\n\n* Added pysocks python package for SOCKS proxy support. #5460\n\n  Contributed by @kingsleyadam\n\n* Added support for multiple LDAP hosts to st2-auth-ldap. #5535, https://github.com/StackStorm/st2-auth-ldap/pull/100\n\n  Contributed by @ktyogurt\n\n* Implemented graceful shutdown for action runner. Enabled ``graceful_shutdown`` in ``st2.conf`` file. #5428\n\n  Contributed by @khushboobhatia01\n\n* Enhanced 'search' operator to allow complex criteria matching on payload items. #5482\n\n  Contributed by @erceth\n\n* Added cancel/pause/resume requester information to execution context. #5554\n\n  Contributed by @khushboobhatia01\n\n* Added `trigger.headers_lower` to webhook trigger payload. This allows rules to match webhook triggers\n  without dealing with the case-sensitive nature of `trigger.headers`, as `triggers.headers_lower` providers\n  the same headers, but with the header name lower cased. #5038\n\n  Contributed by @Rand01ph\n\n* Added support to override enabled parameter of resources. #5506\n\n  Contributed by Amanda McGuinness (@amanda11 Intive)\n\n* Add new ``api.auth_cookie_secure`` and ``api.auth_cookie_same_site`` config options which\n  specify values which are set for ``secure`` and ``SameSite`` attribute for the auth cookie\n  we set when authenticating via token / api key in query parameter value (e.g. via st2web).\n\n  For security reasons, ``api.auth_cookie_secure`` defaults to ``True``. This should only be\n  changed to ``False`` if you have a valid reason to not run StackStorm behind HTTPs proxy.\n\n  Default value for ``api.auth_cookie_same_site`` is ``lax``. If you want to disable this\n  functionality so it behaves the same as in the previous releases, you can set that option\n  to ``None``.\n\n  #5248\n\n  Contributed by @Kami.\n\n* Add new ``st2 action-alias test <message string>`` CLI command which allows users to easily\n  test action alias matching and result formatting.\n\n  This command will first try to find a matching alias (same as ``st2 action-alias match``\n  command) and if a match is found, trigger an execution (same as ``st2 action-alias execute``\n  command) and format the execution result.\n\n  This means it uses exactly the same flow as commands on chat, but the interaction avoids\n  chat and hubot which should make testing and developing aliases easier and faster. #5143\n\n  #5143\n\n  Contributed by @Kami.\n\n* Add new ``credentials.basic_auth = username:password`` CLI configuration option.\n\n  This argument allows client to use additional set of basic auth credentials when talking to the\n  StackStorm API endpoints (api, auth, stream) - that is, in addition to the token / api key\n  native StackStorm auth.\n\n  This allows for simple basic auth based multi factor authentication implementation for\n  installations which don't utilize SSO.\n\n  #5152\n\n  Contributed by @Kami.\n\n* Add new audit message when a user has decrypted a key whether manually in the container (st2 key get [] --decrypt)\n  or through a workflow with a defined config. #5594\n  Contributed by @dmork123\n\n* Added garbage collection for rule_enforcement and trace models #5596/5602\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n\n* Added garbage collection for workflow execution and task execution objects #4924\n  Contributed by @srimandaleeka01 and @amanda11\n\nChanged\n~~~~~~~\n\n* Minor updates for RockyLinux. #5552\n\n  Contributed by Amanda McGuinness (@amanda11 intive)\n\n* Bump black to v22.3.0 - This is  used internally to reformat our python code. #5606\n\n* Updated paramiko version to 2.10.3 to add support for more key verification algorithms. #5600\n\nFixed\n~~~~~\n\n* Fix deserialization bug in st2 API for url encoded payloads. #5536\n\n  Contributed by @sravs-dev\n\n* Fix issue of WinRM parameter passing fails for larger scripts.#5538\n\n  Contributed by @ashwini-orchestral\n\n* Fix Type error for ``time_diff`` critera comparison. convert the timediff value as float to match\n  ``timedelta.total_seconds()`` return. #5462\n\n  Contributed by @blackstrip\n\n* Fix issue with pack option not working when running policy list cli #5534\n\n  Contributed by @momokuri-3\n\n* Fix exception thrown if action parameter contains {{ or {% and no closing jinja characters. #5556\n\n  contributed by @guzzijones12\n\n* Link shutdown routine and sigterm handler to main thread #5555\n\n  Contributed by @khushboobhatia01\n\n* Change compound index for ActionExecutionDB to improve query performance #5568\n\n  Contributed by @khushboobhatia01\n\n* Fix build issue due to MarkUpSafe 2.1.0 removing soft_unicode\n\n  Contributed by Amanda McGuinness (@amanda11 intive) #5581\n\n* Fixed regression caused by #5358. Use string lock name instead of object ID. #5484\n\n  Contributed by @khushboobhatia01\n\n* Fix ``st2-self-check`` script reporting falsey success when the nested workflows runs failed. #5487\n\n* Fix actions from the contrib/linux pack that fail on CentOS-8 but work on other operating systems and distributions. (bug fix) #4999 #5004\n\n  Reported by @blag and @dove-young contributed by @winem.\n\n* Use byte type lock name which is supported by all tooz drivers. #5529\n\n  Contributed by @khushboobhatia01\n\n* Fixed issue where pack index searches are ignoring no_proxy #5497\n\n  Contributed by @minsis\n\n* Fixed trigger references emitted by ``linux.file_watch.line``. #5467\n\n  Prior to this patch multiple files could be watched but the rule reference of last registered file\n  would be used for all trigger emissions causing rule enforcement to fail.  References are now tracked\n  on a per file basis and used in trigger emissions.\n\n  Contributed by @nzlosh\n\n* Downgrade tenacity as tooz dependency on tenacity has always been < 7.0.0 #5607\n\n  Contributed by @khushboobhatia01\n\n* Pin ``typing-extensions<4.2`` (used indirectly by st2client) to maintain python 3.6 support. #5638\n\n\n3.6.0 - October 29, 2021\n------------------------\n\nAdded\n~~~~~\n\n* Added possibility to add new values to the KV store via CLI without leaking them to the shell history. #5164\n\n* ``st2.conf`` is now the only place to configure ports for ``st2api``, ``st2auth``, and ``st2stream``.\n\n  We replaced the static ``.socket`` sytemd units in deb and rpm packages with a python-based generator for the\n  ``st2api``, ``st2auth``, and ``st2stream`` services. The generators will get ``<ip>:<port>`` from ``st2.conf``\n  to create the ``.socket`` files dynamically. #5286 and st2-packages#706\n\n  Contributed by @nzlosh\n\nChanged\n~~~~~~~\n\n* Modified action delete API to delete action files from disk along with backward compatibility.\n\n  From CLI ``st2 action delete <pack>.<action>`` will delete only action database entry.\n  From CLI ``st2 action delete --remove-files <pack>.<action>`` or ``st2 action delete -r <pack>.<action>``\n  will delete action database entry along with files from disk.\n\n  API action DELETE method with ``{\"remove_files\": true}`` argument in json body will remove database\n  entry of action along with files from disk.\n  API action DELETE method with ``{\"remove_files\": false}`` or no additional argument in json body will remove\n  only action database entry. #5304, #5351, #5360\n\n  Contributed by @mahesh-orch.\n\n* Removed --python3 deprecated flag from st2client. #5305\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n  Contributed by @blag.\n* Fixed ``__init__.py`` files to use double quotes to better align with black linting #5299\n\n  Contributed by @blag.\n\n* Reduced minimum TTL on garbage collection for action executions and trigger instances from 7 days to 1 day. #5287\n\n  Contributed by @ericreeves.\n\n* update db connect mongo connection test - `isMaster` MongoDB command depreciated, switch to `ping` #5302, #5341\n\n  Contributed by @lukepatrick\n\n* Actionrunner worker shutdown should stop Kombu consumer thread. #5338\n\n  Contributed by @khushboobhatia01\n\n* Move to using Jinja sandboxed environment #5359\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n* Pinned python module `networkx` to versions between 2.5.1(included) and 2.6(excluded) because Python v3.6 support was dropped in v2.6.\n  Also pinned `decorator==4.4.2` (dependency of `networkx<2.6`) to work around missing python 3.8 classifiers on `decorator`'s wheel. #5376\n\n  Contributed by @nzlosh\n\n* Add new ``--enable-profiler`` flag to all the servies. This flag enables cProfiler based profiler\n  for the service in question and  dumps the profiling data to a file on process\n  exit.\n\n  This functionality should never be used in production, but only in development environments or\n  similar when profiling code. #5199\n\n  Contributed by @Kami.\n\n* Add new ``--enable-eventlet-blocking-detection`` flag to all the servies. This flag enables\n  eventlet long operation / blocked main loop logic which throws an exception if a particular\n  code blocks longer than a specific duration in seconds.\n\n  This functionality should never be used in production, but only in development environments or\n  similar when debugging code. #5199\n\n* Silence pylint about dev/debugging utility (tools/direct_queue_publisher.py) that uses pika because kombu\n  doesn't support what it does. If anyone uses that utility, they have to install pika manually. #5380\n\n* Fixed version of cffi as changes in 1.15.0 meant that it attempted to load libffi.so.8. #5390\n\n  Contributed by @amanda11, Ammeon Solutions\n\n* Updated Bash installer to install latest RabbitMQ version rather than out-dated version available\n  in OS distributions.\n\n  Contributed by @amanda11, Ammeon Solutions\n\nFixed\n~~~~~\n\n* Correct error reported when encrypted key value is reported, and another key value parameter that requires conversion is present. #5328\n  Contributed by @amanda11, Ammeon Solutions\n\n* Make ``update_executions()`` atomic by protecting the update with a coordination lock. Actions, like workflows, may have multiple\n  concurrent updates to their execution state. This makes those updates safer, which should make the execution status more reliable. #5358\n\n  Contributed by @khushboobhatia01\n\n* Fix \"not iterable\" error for ``output_schema`` handling. If a schema is not well-formed, we ignore it.\n  Also, if action output is anything other than a JSON object, we do not try to process it any more.\n  ``output_schema`` will change in a future release to support non-object output. #5309\n\n  Contributed by @guzzijones\n\n* ``core.inject_trigger``: resolve ``trigger`` payload shadowing by deprecating ``trigger`` param in favor of ``trigger_name``.\n  ``trigger`` param is still available for backwards compatibility, but will be removed in a future release. #5335 and #5383\n\n  Contributed by @mjtice\n\n3.5.0 - June 23, 2021\n---------------------\n\nAdded\n~~~~~\n\n* Added web header settings for additional security hardening to nginx.conf: X-Frame-Options,\n  Strict-Transport-Security, X-XSS-Protection and server-tokens. #5183\n\n  Contributed by @shital.\n\n* Added support for ``limit`` and ``offset`` argument to the ``list_values`` data store\n  service method (#5097 and #5171).\n\n  Contributed by @anirudhbagri.\n\n* Various additional metrics have been added to the action runner service to provide for better\n  operational visibility. (improvement) #4846\n\n  Contributed by @Kami.\n\n* Added sensor model to list of JSON schemas auto-generated by `make schemasgen` that can be used\n  by development tools to validate pack contents. (improvement)\n\n* Added the command line utility `st2-validate-pack` that can be used by pack developers to\n  validate pack contents. (improvement)\n\n* Fix a bug in the API and CLI code which would prevent users from being able to retrieve resources\n  which contain non-ascii (utf-8) characters in the names / references. (bug fix) #5189\n\n  Contributed by @Kami.\n\n* Fix a bug in the API router code and make sure we return correct and user-friendly error to the\n  user in case we fail to parse the request URL / path because it contains invalid or incorrectly\n  URL encoded data.\n\n  Previously such errors weren't handled correctly which meant original exception with a stack\n  trace got propagated to the user. (bug fix) #5189\n\n  Contributed by @Kami.\n\n* Make redis the default coordinator backend.\n\n* Fix a bug in the pack config loader so that objects covered by an additionalProperties schema\n  can use encrypted datastore keys and have their default values applied correctly. #5225\n\n  Contributed by @cognifloyd.\n\n* Add new ``database.compressors`` and ``database.zlib_compression_level`` config option which\n  specifies compression algorithms client supports for network / transport level compression\n  when talking to MongoDB.\n\n  Actual compression algorithm used will be then decided by the server and depends on the\n  algorithms which are supported by the server + client.\n\n  Possible / valid values include: zstd, zlib. Keep in mind that zstandard (zstd) is only supported\n  by MongoDB >= 4.2.\n\n  Our official Debian and RPM packages bundle ``zstandard`` dependency by default which means\n  setting this value to ``zstd`` should work out of the box as long as the server runs\n  MongoDB >= 4.2. #5177\n\n  Contributed by @Kami.\n\n* Add support for compressing the payloads which are sent over the message bus. Compression is\n  disabled by default and user can enable it by setting ``messaging.compression`` config option\n  to one of the following values: ``zstd``, ``lzma``, ``bz2``, ``gzip``.\n\n  In most cases we recommend using ``zstd`` (zstandard) since it offers best trade off between\n  compression ratio and number of CPU cycles spent for compression and compression.\n\n  How this will affect the deployment and throughput is very much user specific (workflow and\n  resources available). It may make sense to enable it when generic action trigger is enabled\n  and when working with executions with large textual results. #5241\n\n  Contributed by @Kami.\n\n* Mask secrets in output of an action execution in the API if the action has an output schema\n  defined and one or more output parameters are marked as secret. #5250\n\n  Contributed by @mahesh-orch.\n\nChanged\n~~~~~~~\n\n* All the code has been refactored using black and black style is automatically enforced and\n  required for all the new code. (#5156)\n\n  Contributed by @Kami.\n\n* Default nginx config (``conf/nginx/st2.conf``) which is used by the installer and Docker\n  images has been updated to only support TLS v1.2 and TLS v1.3 (support for TLS v1.0 and v1.1\n  has been removed).\n\n  Keep in mind that TLS v1.3 will only be used when nginx is running on more recent distros\n  where nginx is compiled against OpenSSL v1.1.1 which supports TLS 1.3. #5183 #5216\n\n  Contributed by @Kami and @shital.\n\n* Add new ``-x`` argument to the ``st2 execution get`` command which allows\n  ``result`` field to be excluded from the output. (improvement) #4846\n\n* Update ``st2 execution get <id>`` command to also display execution ``log`` attribute which\n  includes execution state transition information.\n\n  By default ``end_timestamp`` attribute and ``duration`` attribute displayed in the command\n  output only include the time it took action runner to finish running actual action, but it\n  doesn't include the time it it takes action runner container to fully finish running the\n  execution - this includes persisting execution result in the database.\n\n  For actions which return large results, there could be a substantial discrepancy - e.g.\n  action itself could finish in 0.5 seconds, but writing data to the database could take\n  additional 5 seconds after the action code itself was executed.\n\n  For all purposes until the execution result is  persisted to the database, execution is\n  not considered as finished.\n\n  While writing result to the database action runner is also consuming CPU cycles since\n  serialization of large results is a CPU intensive task.\n\n  This means that \"elapsed\" attribute and start_timestamp + end_timestamp will make it look\n  like actual action completed in 0.5 seconds, but in reality it took 5.5 seconds (0.5 + 5 seconds).\n\n  Log attribute can be used to determine actual duration of the execution (from start to\n  finish). (improvement) #4846\n\n  Contributed by @Kami.\n\n* Various internal improvements (reducing number of DB queries, speeding up YAML parsing, using\n  DB object cache, etc.) which should speed up pack action registration between 15-30%. This is\n  especially pronounced with packs which have a lot of actions (e.g. aws one).\n  (improvement) #4846\n\n  Contributed by @Kami.\n\n* Underlying database field type and storage format for the ``Execution``, ``LiveAction``,\n  ``WorkflowExecutionDB``, ``TaskExecutionDB`` and ``TriggerInstanceDB`` database models has\n  changed.\n\n  This new format is much faster and efficient than the previous one. Users with larger executions\n  (executions with larger results) should see the biggest improvements, but the change also scales\n  down so there should also be improvements when reading and writing executions with small and\n  medium sized results.\n\n  Our micro and end to benchmarks have shown improvements up to 15-20x for write path (storing\n  model in the database) and up to 10x for the read path.\n\n  To put things into perspective - with previous version, running a Python runner action which\n  returns 8 MB result would take around ~18 seconds total, but with this new storage format, it\n  takes around 2 seconds (in this context, duration means the from the time the execution was\n  scheduled to the time the execution model and result was written and available in the database).\n\n  The difference is even larger when working with Orquesta workflows.\n\n  Overall performance improvement doesn't just mean large decrease in those operation timings, but\n  also large overall reduction of CPU usage - previously serializing large results was a CPU\n  intensive time since it included tons of conversions and transformations back and forth.\n\n  The new format is also around 10-20% more storage efficient which means that it should allows\n  for larger model values (MongoDB document size limit is 16 MB).\n\n  The actual change should be fully opaque and transparent to the end users - it's purely a\n  field storage implementation detail and the code takes care of automatically handling both\n  formats when working with those object.\n\n  Same field data storage optimizations have also been applied to workflow related database models\n  which should result in the same performance improvements for Orquesta workflows which pass larger\n  data sets / execution results around.\n\n  Trigger instance payload field has also been updated to use this new field type which should\n  result in lower CPU utilization and better throughput of rules engine service when working with\n  triggers with larger payloads.\n\n  This should address a long standing issue where StackStorm was reported to be slow and CPU\n  inefficient with handling large executions.\n\n  If you want to migrate existing database objects to utilize the new type, you can use\n  ``st2common/bin/migrations/v3.5/st2-migrate-db-dict-field-values`` migration\n  script. (improvement) #4846\n\n  Contributed by @Kami.\n\n* Add new ``result_size`` field to the ``ActionExecutionDB`` model. This field will only be\n  populated for executions which utilize new field storage format.\n\n  It holds the size of serialzed execution result field in bytes. This field will allow us to\n  implement more efficient execution result retrieval and provide better UX since we will be\n  able to avoid loading execution results in the WebUI for executions with very large results\n  (which cause browser to freeze). (improvement) #4846\n\n  Contributed by @Kami.\n\n* Add new ``/v1/executions/<id>/result[?download=1&compress=1&pretty_format=1]`` API endpoint\n  which can be used used to retrieve or download raw execution result as (compressed) JSON file.\n\n  This endpoint will primarily be used by st2web when executions produce very large results so\n  we can avoid loading, parsing and formatting those very large results as JSON in the browser\n  which freezes the browser window / tab. (improvement) #4846\n\n  Contributed by @Kami.\n\n* Update ``jinja2`` dependency to the latest stable version (2.11.3). #5195\n\n* Update ``pyyaml`` dependency to the latest stable version (5.4). #5207\n\n* Update various dependencies to latest stable versions (``bcrypt``, ``appscheduler``, ``pytz``,\n  ``python-dateutil``, ``psutil``, ``passlib``, ``gunicorn``, ``flex``, ``cryptography``.\n  ``eventlet``, ``greenlet``, ``webob`` , ``mongoengine``, ``pymongo``, ``requests``,\n  ``pyyaml``, ``kombu``, ``amqp``, ``python-ldap``).\n\n  #5215, https://github.com/StackStorm/st2-auth-ldap/pull/94\n\n  Contributed by @Kami.\n\n* Update code and dependencies so it supports Python 3.8 and Mongo DB 4.4 #5177\n\n  Contributed by @nzloshm @winem @Kami.\n\n* StackStorm Web UI (``st2web``) has been updated to not render and display execution results\n  larger than 200 KB directly in the history panel in the right side bar by default anymore.\n  Instead a link to view or download the raw result is displayed.\n\n  Execution result widget was never optimized to display very large results (especially for\n  executions which return large nested dictionaries) so it would freeze and hang the whole\n  browser tab / window when trying to render / display large results.\n\n  If for some reason you want to revert to the old behavior (this is almost never a good idea\n  since it will cause browser to freeze when trying to display large results), you can do that by\n  setting ``max_execution_result_size_for_render`` option in the config to a very large value (e.g.\n  ``max_execution_result_size_for_render: 16 * 1024 * 1024``).\n\n  https://github.com/StackStorm/st2web/pull/868\n\n  Contributed by @Kami.\n\n* Some of the config option registration code has been refactored to ignore \"option already\n  registered\" errors. That was done as a work around for an occasional race in the tests and\n  also to make all of the config option registration code expose the same consistent API. #5234\n\n  Contributed by @Kami.\n\n* Update ``pyywinrm`` dependency to the latest stable version (0.4.1). #5212\n\n  Contributed by @chadpatt .\n\n* Monkey patch on st2stream earlier in flow #5240\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n* Support % in CLI arguments by reading the ConfigParser() arguments with raw=True.\n\n  This removes support for '%' interpolations on the configuration arguments.\n\n  See https://docs.python.org/3.8/library/configparser.html#configparser.ConfigParser.get for\n  further details. #5253\n\n  Contributed by @winem.\n\n* Remove duplicate host header in the nginx config for the auth endpoint.\n\n* Update orquesta to v1.4.0.\n\nImprovements\n~~~~~~~~~~~~\n\n* CLI has been updated to use or ``orjson`` when parsing API response and C version of the YAML\n  safe dumper when formatting execution result for display. This should result in speed up when\n  displaying execution result (``st2 execution get``, etc.) for executions with large results.\n\n  When testing it locally, the difference for execution with 8 MB result was 18 seconds vs ~6\n  seconds. (improvement) #4846\n\n  Contributed by @Kami.\n\n* Update various Jinja functiona to utilize C version of YAML ``safe_{load,dump}`` functions and\n  orjson for better performance. (improvement) #4846\n\n  Contributed by @Kami.\n\n* For performance reasons, use ``udatetime`` library for parsing ISO8601 / RFC3339 date strings\n  where possible. (improvement) #4846\n\n  Contributed by @Kami.\n\n* Speed up service start up time by speeding up runners registration on service start up by\n  re-using existing stevedore ``ExtensionManager`` instance instead of instantiating new\n  ``DriverManager`` instance per extension which is not necessary and it's slow since it requires\n  disk / pkg resources scan for each extension. (improvement) #5198\n\n  Contributed by @Kami.\n\n* Add new ``?max_result_size`` query parameter filter to the ``GET /v1/executiond/<id>`` API\n  endpoint.\n\n  This query parameter allows clients to implement conditional execution result retrieval and\n  only retrieve the result field if it's smaller than the provided value.\n\n  This comes handy in the various client scenarios (such as st2web) where we don't display and\n  render very large results directly since it allows to speed things up and decrease amount of\n  data retrieved and parsed. (improvement) #5197\n\n  Contributed by @Kami.\n\n* Update default nginx config which is used for proxying API requests and serving static\n  content to only allow HTTP methods which are actually used by the services (get, post, put,\n  delete, options, head).\n\n  If a not-allowed method is used, nginx will abort the request early and return 405 status\n  code. #5193\n\n  Contributed by @ashwini-orchestral\n\n* Update default nginx config which is used for proxying API requests and serving static\n  content to not allow range requests. #5193\n\n  Contributed by @ashwini-orchestral\n\n* Drop unused python dependencies: prometheus_client, python-gnupg, more-itertools, zipp. #5228\n\n  Contributed by @cognifloyd.\n\n* Update majority of the \"resource get\" CLI commands (e.g. ``st2 execution get``,\n  ``st2 action get``, ``st2 rule get``, ``st2 pack get``, ``st2 apikey get``, ``st2 trace get``,\n  ``st2 key get``, ``st2 webhook get``, ``st2  timer get``, etc.) so they allow for retrieval\n  and printing of information for multiple resources using the following notation:\n  ``st2 <resource> get <id 1> <id 2> <id n>``, e.g. ``st2 action.get pack.show packs.get\n  packs.delete``\n\n  This change is fully backward compatible when retrieving only a single resource (aka single\n  id is passed to the command).\n\n  When retrieving a single source the command will throw and exit with non-zero if a resource is\n  not found, but when retrieving multiple resources, command will just print an error and\n  continue with printing the details of any other found resources. (new feature) #4912\n\n  Contributed by @Kami.\n\nFixed\n~~~~~\n\n* Refactor spec_loader util to use yaml.load with SafeLoader. (security)\n  Contributed by @ashwini-orchestral\n\n* Import ABC from collections.abc for Python 3.10 compatibility. (#5007)\n  Contributed by @tirkarthi\n\n* Updated to use virtualenv 20.4.0/PIP20.3.3 and fixate-requirements to work with PIP 20.3.3 #512\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n* Fix ``st2 execution get --with-schema`` flag.  (bug fix) #4846\n\n  Contributed by @Kami.\n\n* Fix SensorTypeAPI schema to use class_name instead of name since documentation for pack\n  development uses class_name and registrar used to load sensor to database assign class_name\n  to name in the database model. (bug fix)\n\n* Updated paramiko version to 2.7.2, to go with updated cryptography to prevent problems\n  with ssh keys on remote actions. #5201\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n* Update rpm package metadata and fix ``Provides`` section for RHEL / CentOS 8 packages.\n\n  In the previous versions, RPM metadata would incorrectly signal that the ``st2`` package\n  provides various Python libraries which it doesn't (those Python libraries are only used\n  internally for the package local virtual environment).\n\n  https://github.com/StackStorm/st2-packages/pull/697\n\n  Contributed by @Kami.\n\n* Make sure ``st2common.util.green.shell.run_command()`` doesn't leave stray / zombie processes\n  laying around in some command timeout scenarios. #5220\n\n  Contributed by @r0m4n-z.\n\n* Fix support for skipping notifications for workflow actions. Previously if action metadata\n  specified an empty list for ``notify`` parameter value, that would be ignored / not handled\n  correctly for workflow (orquesta, action chain) actions. #5221 #5227\n\n  Contributed by @khushboobhatia01.\n\n* Clean up to remove unused methods in the action execution concurrency policies. #5268\n\n3.4.1 - March 14, 2021\n----------------------\n\nAdded\n~~~~~\n\n\n* Service start up code has been updated to log a warning if a non-utf-8 encoding / locale is\n  detected.\n\n  Using non-utf-8 locale while working with unicode data will result in various issues so users\n  are strongly recommended to ensure encoding for all the StackStorm service is\n  set to ``utf-8``. (#5182)\n\n  Contributed by @Kami.\n\nChanged\n~~~~~~~\n\n* Use `sudo -E` to fix GitHub Actions tests #5187\n\n  Contributed by @cognifloyd\n\nFixed\n~~~~~\n\n* Properly handle unicode strings in logs #5184\n\n  Fix a logging loop when attempting to encode Unicode characters in locales that do not support\n  Unicode characters - CVE-2021-28667.\n\n  See https://stackstorm.com/2021/03/10/stackstorm-v3-4-1-security-fix/ for more information.\n\n  Contributed by @Kami\n\n* Fix SensorTypeAPI schema to use class_name instead of name since documentation for pack\n  development uses class_name and registrar used to load sensor to database assign class_name\n  to name in the database model. (bug fix)\n\n* Updated paramiko version to 2.7.2, to go with updated cryptography to prevent problems\n  with ssh keys on remote actions. #5201\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n\n3.4.0 - March 02, 2021\n----------------------\n\nAdded\n~~~~~\n\n* Added support for GitLab SSH URLs on pack install and download actions. (improvement) #5050\n  Contributed by @asthLucas\n\n* Added st2-rbac-backend pip requirements for RBAC integration. (new feature) #5086\n  Contributed by @hnanchahal\n\n* Added notification support for err-stackstorm. (new feature) #5051\n\n* Added st2-auth-ldap pip requirements for LDAP auth integartion. (new feature) #5082\n  Contributed by @hnanchahal\n\n* Added --register-recreate-virtualenvs flag to st2ctl reload to recreate virtualenvs from\n  scratch. (part of upgrade instructions) #5167\n\n  Contributed by @winem and @blag\n\nChanged\n~~~~~~~\n\n* Updated deprecation warning for python 2 pack installs, following python 2 support removal. #5099\n  Contributed by @amanda11\n\n* Improve the st2-self-check script to echo to stderr and exit if it isn't run with a\n  ST2_AUTH_TOKEN or ST2_API_KEY environment variable. (improvement) #5068\n\n* Added timeout parameter for packs.install action to help with long running installs that exceed the\n  default timeout of 600 sec which is defined by the python_script action runner (improvement) #5084\n\n  Contributed by @hnanchahal\n\n* Upgraded cryptography version to 3.2 to avoid CVE-2020-25659 (security) #5095\n\n* Converted most CI jobs from Travis to GitHub Actions (all except Integration tests).\n\n  Contributed by @nmaludy, @winem, and @blag\n\n* Updated cryptography dependency to version 3.3.2 to avoid CVE-2020-36242 (security) #5151\n\n* Update most of the code in the StackStorm API and services layer to utilize ``orjson`` library\n  for serializing and de-serializing json.\n\n  That should result in better json serialization and deserialization performance.\n\n  The change should be fully backward compatible, only difference is that API JSON responses now\n  won't be indented using 4 spaces by default (indenting adds unnecessary overhead and if needed,\n  the response can be pretty formatted on the client side using ``jq`` or similar). (improvement)\n  #5153\n\n  Contributed by @Kami\n\nFixed\n~~~~~\n\n* Pin chardet version as newest version was incompatible with pinned requests version #5101\n  Contributed by @amanda11\n\n* Fixed issue were st2tests was not getting installed using pip because no version was specified.\n  Contributed by @anirudhbagri\n\n* Added monkey patch fix to st2stream to enable it to work with mongodb via SSL. (bug fix) #5078 #5091\n\n* Fix nginx buffering long polling stream to client.  Instead of waiting for closed connection\n  wait for final event to be sent to client. (bug fix) #4842  #5042\n\n  Contributed by @guzzijones\n\n* StackStorm now explicitly decodes pack files as utf-8 instead of implicitly as ascii (bug fix)\n  #5106, #5107\n\n* Fix incorrect array parameter value casting when executing action via chatops or using\n  ``POST /aliasexecution/match_and_execute`` API endpoint. The code would incorrectly assume the\n  value is always a string, but that may not be the cast - they value could already be a list and\n  in this case we don't want any casting to be performed. (bug fix) #5141\n\n  Contributed by @Kami.\n\n* Fix ``@parameter_name=/path/to/file/foo.json`` notation in the ``st2 run`` command which didn't\n  work correctly because it didn't convert read bytes to string / unicode type. (bug fix) #5140\n\n  Contributed by @Kami.\n\n* Fix broken ``st2 action-alias execute`` command and make sure it works\n  correctly. (bug fix) #5138\n\n  Contributed by @Kami.\n\nRemoved\n~~~~~~~\n\n* Removed --python3 pack install option  #5100\n  Contributed by @amanda11\n\n* Removed submit-debug-info tool and the st2debug component #5103\n\n* Removed check-licence script (cleanup) #5092\n\n  Contributed by @kroustou\n\n* Updated Makefile and CI to use Python 3 only, removing Python 2 (cleanup) #5090\n\n  Contributed by @blag\n\n* Remove st2resultstracker from st2ctl, the development environment and the st2actions setup.py (cleanup) #5108\n\n  Contributed by @winem\n\n3.3.0 - October 06, 2020\n------------------------\n\nAdded\n~~~~~\n* Add make command to autogen JSON schema from the models of action, rule, etc. Add check\n  to ensure update to the models require schema to be regenerated. (new feature)\n* Improved st2sensor service logging message when a sensor will not be loaded when assigned to a\n  different partition (@punkrokk) #4991\n* Add support for a configurable connect timeout for SSH connections as requested in #4715\n  by adding the new configuration parameter ``ssh_connect_timeout`` to the ``ssh_runner``\n  group in st2.conf. (new feature) #4914\n\n  This option was requested by Harry Lee (@tclh123) and contributed by Marcel Weinberg (@winem).\n* Added a FAQ for the default user/pass for the `tools/launch_dev.sh` script and print out the\n  default pass to screen when the script completes. (improvement) #5013\n\n  Contributed by @punkrokk\n* Added deprecation warning if attempt to install or download a pack that only supports\n  Python 2. (new feature) #5037\n\n  Contributed by @amanda11\n* Added deprecation warning to each StackStorm service log, if service is running with\n  Python 2. (new feature) #5043\n\n  Contributed by @amanda11\n* Added deprecation warning to st2ctl, if st2 python version is Python 2. (new feature) #5044\n\n  Contributed by @amanda11\n\nChanged\n~~~~~~~\n\n* Switch to MongoDB ``4.0`` as the default version starting with all supported OS's in st2\n  ``v3.3.0`` (improvement) #4972\n\n  Contributed by @punkrokk\n\n* Added an enhancement where ST2api.log no longer reports the entire traceback when trying to get a datastore value\n  that does not exist. It now reports a simplified log for cleaner reading. Addresses and Fixes #4979. (improvement) #4981\n\n  Contributed by Justin Sostre (@saucetray)\n* The built-in ``st2.action.file_writen`` trigger has been renamed to ``st2.action.file_written``\n  to fix the typo (bug fix) #4992\n* Renamed reference to the RBAC backend/plugin from ``enterprise`` to ``default``. Updated st2api\n  validation to use the new value when checking RBAC configuration. Removed other references to\n  enterprise for RBAC related contents. (improvement)\n* Remove authentication headers ``St2-Api-Key``, ``X-Auth-Token`` and ``Cookie`` from webhook payloads to\n  prevent them from being stored in the database. (security bug fix) #4983\n\n  Contributed by @potato and @knagy\n* Updated orquesta to version v1.2.0.\n\nFixed\n~~~~~\n\n* Fixed a bug where `type` attribute was missing for netstat action in linux pack. Fixes #4946\n\n  Reported by @scguoi and contributed by Sheshagiri (@sheshagiri)\n\n* Fixed a bug where persisting Orquesta to the MongoDB database returned an error\n  ``message: key 'myvar.with.period' must not contain '.'``. This happened anytime an\n  ``input``, ``output``, ``publish`` or context ``var`` contained a key with a ``.`` within\n  the name (such as with hostnames and IP addresses). This was a regression introduced by\n  trying to improve performance. Fixing this bug means we are sacrificing performance of\n  serialization/deserialization in favor of correctness for persisting workflows and\n  their state to the MongoDB database. (bug fix) #4932\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n* Fix a bug where passing an empty list to a with items task in a subworkflow causes\n  the parent workflow to be stuck in running status. (bug fix) #4954\n* Fixed a bug in the example nginx HA template declared headers twice (bug fix) #4966\n  Contributed by @punkrokk\n\n* Fixed a bug in the ``paramiko_ssh`` runner where SSH sockets were not getting cleaned\n  up correctly, specifically when specifying a bastion host / jump box. (bug fix) #4973\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n* Fixed a bytes/string encoding bug in the ``linux.dig`` action so it should work on Python 3\n  (bug fix) #4993\n\n* Fixed a bug where a python3 sensor using ssl needs to be monkey patched earlier. See also #4832, #4975 and gevent/gevent#1016 (bug fix) #4976\n\n  Contributed by @punkrokk\n* Fixed bug where action information in RuleDB object was not being parsed properly\n  because mongoengine EmbeddedDocument objects were added to JSON_UNFRIENDLY_TYPES and skipped.\n  Removed this and added if to use to_json method so that mongoengine EmbeddedDocument\n  are parsed properly.\n\n  Contributed by Bradley Bishop (@bishopbm1 Encore Technologies)\n* Fix a regression when updated ``dnspython`` pip dependency resulted in\n  st2 services unable to connect to mongodb remote host (bug fix) #4997\n* Fixed a regression in the ``linux.dig`` action on Python 3. (bug fix) #4993\n\n  Contributed by @blag\n* Fixed a bug in pack installation logging code where unicode strings were not being\n  interpolated properly. (bug fix)\n\n  Contributed by @misterpah\n* Fixed a compatibility issue with the latest version of the ``logging`` library API\n  where the ``find_caller()`` function introduced some new variables. (bug fix) #4923\n\n  Contributed by @Dahfizz9897\n* Fixed another logging compatibility issue with the ``logging`` API in Python 3.\n  The return from the ``logging.findCaller()`` implementation now expects a 4-element\n  tuple. Also, in Python 3 there are new arguments that are passed in and needs to be\n  acted upon, specificall ``stack_info`` that determines the new 4th element in the returned\n  tuple. (bug fix) #5057\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n\nRemoved\n~~~~~~~\n\n* Removed ``Mistral`` workflow engine (deprecation) #5011\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n* Removed ``CentOS 6``/``RHEL 6`` support #4984\n\n  Contributed by Amanda McGuinness (@amanda11 Ammeon Solutions)\n* Removed our fork of ``codecov-python`` for CI and have switched back to the upstream version (improvement) #5002\n\n3.2.0 - April 27, 2020\n----------------------\n\nAdded\n~~~~~\n* Add support for blacklisting / whitelisting hosts to the HTTP runner by adding new\n  ``url_hosts_blacklist`` and ``url_hosts_whitelist`` runner attribute. (new feature)\n  #4757\n* Add ``user`` parameter to ``re_run`` method of st2client. #4785\n* Install pack dependencies automatically. #4769\n* Add support for ``immutable_parameters`` on Action Aliases. This feature allows default\n  parameters to be supplied to the action on every execution of the alias. #4786\n* Add ``get_entrypoint()`` method to ``ActionResourceManager`` attribute of st2client.\n  #4791\n* Add support for orquesta task retry. (new feature)\n* Add config option ``scheduler.execution_scheduling_timeout_threshold_min`` to better control the cleanup of scheduled actions that were orphaned. #4886\n\nChanged\n~~~~~~~\n* Install pack with the latest tag version if it exists when branch is not specialized.\n  (improvement) #4743\n* Implement \"continue\" engine command to orquesta workflow. (improvement) #4740\n* Update various internal dependencies to latest stable versions (apscheduler, eventlet,\n  kombu, amqp, pyyaml, mongoengine, python-gnupg, paramiko, tooz, webob, bcrypt).\n\n  Latest version of mongoengine should show some performance improvements (5-20%) when\n  writing very large executions (executions with large results) to the database. #4767\n* Improved development instructions in requirements.txt and dist_utils.py comment headers\n  (improvement) #4774\n* Add new ``actionrunner.stream_output_buffer_size`` config option and default it to ``-1``\n  (previously default value was ``0``). This should result in a better performance and smaller\n  CPU utilization for Python runner actions which produce a lot of output.\n  (improvement)\n\n  Reported and contributed by Joshua Meyer (@jdmeyer3) #4803\n* Add new ``action_runner.pip_opts`` st2.conf config option which allows user to specify a list\n  of command line option which are passed to ``pip install`` command when installing pack\n  dependencies into a pack specific virtual environment. #4792\n* Refactor how orquesta handles individual item result for with items task. Before the fix,\n  when there are a lot of items and/or result size for each item is huge, there is a negative\n  performance impact on write to the database when recording the conductor state. (improvement)\n* Remove automatic rendering of workflow output when updating task state for orquesta workflows.\n  This caused workflow output to render incorrectly in certain use case. The render_workflow_output\n  function must be called separately. (improvement)\n* Update various internal dependencies to latest stable versions (cryptography, jinja2, requests,\n  apscheduler, eventlet, amqp, kombu, semver, six) #4819 (improvement)\n* Improve MongoDB connection timeout related code. Connection and server selection timeout is now\n  set to 3 seconds. Previously a default value of 30 seconds was used which means that for many\n  connection related errors, our code would first wait for this timeout to be reached (30 seconds)\n  before returning error to the end user. #4834\n* Upgrade ``pymongo`` to the latest stable version (``3.10.0.``). #4835 (improvement)\n* Updated Paramiko to v2.7.1 to support new PEM ECDSA key formats #4901 (improvement)\n* Remove ``.scrutinizer.yml`` config file. No longer used.\n* Convert escaped dict and dynamic fields in workflow db models to normal dict and dynamic fields.\n  (performnce improvement)\n* Add support for `PEP 508 <https://www.python.org/dev/peps/pep-0508/#environment-markers>`_\n  environment markers in generated ``requirements.txt`` files. (improvement) #4895\n* Use ``pip-compile`` from ``pip-tools`` instead of ``pip-conflict-checker`` (improvement) #4896\n* Refactor how inbound criteria for join task in orquesta workflow is evaluated to count by\n  task completion instead of task transition. (improvement)\n* The workflow engine orquesta is updated to v1.1.0 for the st2 v3.2 release. The version upgrade\n  contains various new features and bug fixes. Please review the release notes for the full list of\n  changes at https://github.com/StackStorm/orquesta/releases/tag/v1.1.0 and the st2 upgrade notes\n  for potential impact. (improvement)\n* Update st2 nginx config to remove deprecated ``ssl on`` option. #4917 (improvement)\n* Updated and tested tooz to v2.8.0 to apply fix for consul coordination heartbeat (@punkrokk @winem) #5121\n\nFixed\n~~~~~\n* Fix a typo that caused an internal server error when filtering actions by tags. Fixes #4918\n\n  Reported by @mweinberg-cm and contributed by Marcel Weinberg (@winem)\n\n* Fix the action query when filtering tags. The old implementation returned actions which have the\n  provided name as action name and not as tag name. (bug fix) #4828\n\n  Reported by @AngryDeveloper and contributed by Marcel Weinberg (@winem)\n* Fix the passing of arrays to shell scripts where the arrays where not detected as such by the\n  st2 action_db utility. This caused arrays to be passed as Python lists serialized into a string.\n\n  Reported by @kingsleyadam #4804 and contributed by Marcel Weinberg (@winem) #4861\n* Fix ssh zombies when using ProxyCommand from ssh config #4881 [Eric Edgar]\n* Fix rbac with execution view where the rbac is unable to verify the pack or uid of the execution\n  because it was not returned from the action execution db. This would result in an internal server\n  error when trying to view the results of a single execution.\n  Contributed by Joshua Meyer (@jdmeyer3) #4758\n* Fixed logging middleware to output a ``content_length`` of ``0`` instead of ``Infinity``\n  when the type of data being returned is not supported. Previously, when the value was\n  set to ``Infinity`` this would result in invalid JSON being output into structured\n  logs. (bug fix) #4722\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n* Fix the workflow execution cancelation to proceed even if the workflow execution is not found or\n  completed. (bug fix) #4735\n* Added better error handling to ``contrib/linux/actions/dig.py`` to inform if dig is not installed.\n  Contributed by JP Bourget (@punkrokk Syncurity) #4732\n* Update ``dist_utils`` module which is bundled with ``st2client`` and other Python packages so it\n  doesn't depend on internal pip API and so it works with latest pip version. (bug fix) #4750\n* Fix dependency conflicts in pack CI runs: downgrade requests dependency back to 0.21.0, update\n  internal dependencies and test expectations (amqp, pyyaml, prance, six) (bugfix) #4774\n* Fix secrets masking in action parameters section defined inside the rule when using\n  ``GET /v1/rules`` and ``GET /v1/rules/<ref>`` API endpoint. (bug fix) #4788 #4807\n\n  Contributed by @Nicodemos305 and @jeansfelix\n* Fix a bug with authentication API endpoint (``POST /auth/v1/tokens``) returning internal\n  server error when running under gunicorn and when``auth.api_url`` config option was not set.\n  (bug fix) #4809\n\n  Reported by @guzzijones\n* Fixed ``st2 execution get`` and ``st2 run`` not printing the ``action.ref`` for non-workflow\n  actions. (bug fix) #4739\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n* Update ``st2 execution get`` command to always include ``context.user``, ``start_timestamp`` and\n  ``end_timestamp`` attributes. (improvement) #4739\n\n* Fixed ``core.sendmail`` base64 encoding of longer subject lines (bug fix) #4795\n\n  Contributed by @stevemuskiewicz and @guzzijones\n* Update all the various rule criteria comparison operators which also work with strings (equals,\n  icontains, nequals, etc.) to work correctly on Python 3 deployments if one of the operators is\n  of a type bytes and the other is of a type unicode / string. (bug fix) #4831\n* Fix SSL connection support for MongoDB and RabbitMQ which wouldn't work under Python 3 and would\n  result in cryptic \"maximum recursion depth exceeded while calling a Python object\" error on\n  connection failure.\n\n  NOTE: This issue only affected installations using Python 3. (bug fix) #4832 #4834\n\n  Reported by @alexku7.\n* Fix the amqp connection setup for WorkflowExecutionHandler to pass SSL params. (bug fix) #4845\n\n  Contributed by Tatsuma Matsuki (@mtatsuma)\n\n* Fix dependency conflicts by updating ``requests`` (2.23.0) and ``gitpython`` (2.1.15). #4869\n* Fix orquesta syntax error for with items task where action is misindented or missing. (bug fix)\n  PR StackStorm/orquesta#195.\n* Fix orquesta yaql/jinja vars extraction to ignore methods of base ctx() dict. (bug fix)\n  PR StackStorm/orquesta#196. Fixes #4866.\n* Fix parsing of array of dicts in YAQL functions. Fix regression in YAQL/Jinja conversion\n  functions as a result of the change. (bug fix) PR StackStorm/orquesta#191.\n\n  Contributed by Hiroyasu Ohyama (@userlocalhost)\n* Fix retry in orquesta when a task that has a transition on failure will also be traversed on\n  retry. (bug fix) PR StackStorm/orquesta#200\n\nRemoved\n~~~~~~~\n\n* Removed Ubuntu 14.04 from test matrix #4897\n\n3.1.0 - June 27, 2019\n---------------------\n\nChanged\n~~~~~~~\n\n* Allow the orquesta st2kv function to return default for nonexistent key. (improvement) #4678\n* Update requests library to latest version (2.22.0) in requirements. (improvement) #4680\n* Disallow \"decrypt_kv\" filter to be specified in the config for values that are marked as\n  \"secret: True\" in the schema. (improvement) #4709\n* Upgrade ``tooz`` library to latest stable version (1.65.0) so it uses latest version of\n  ``grpcio`` library. (improvement) #4713\n* Update ``st2-pack-install`` and ``st2-pack-download`` CLI command so it supports installing\n  packs from local directories which are not git repositories. (improvement) #4713\n\nFixed\n~~~~~\n\n* Fix orquesta st2kv to return empty string and null values. (bug fix) #4678\n* Allow tasks defined in the same task transition with ``fail`` to run for orquesta. (bug fix)\n* Fix workflow service to handle unexpected coordinator and database errors. (bug fix) #4704 #4705\n* Fix filter ``to_yaml_string`` to handle mongoengine base types for dict and list. (bug fix) #4700\n* Fix timeout handling in the Python runner. In some scenarios where action would time out before\n  producing any output (stdout, stder), timeout was not correctly propagated to the user. (bug fix)\n  #4713\n* Update ``st2common/setup.py`` file so it correctly declares all the dependencies and script\n  files it provides. This way ``st2-pack-*`` commands can be used in a standalone fashion just by\n  installing ``st2common`` Python package and nothing else. (bug fix) #4713\n* Fix ``st2-pack-download`` command so it works in the environments where ``sudo`` binary is not\n  available (e.g. Docker). (bug fix) #4713\n\n3.0.1 - May 24, 2019\n--------------------\n\nFixed\n~~~~~\n\n* Fix a bug in the remote command and script runner so it correctly uses SSH port from a SSH config\n  file if ``ssh_runner.use_ssh_config`` parameter is set to ``True`` and if a custom (non-default)\n  value for SSH port is specified in the configured SSH config file\n  (``ssh_runner.ssh_config_file_path``). (bug fix) #4660 #4661\n* Update pack install action so it works correctly when ``python_versions`` ``pack.yaml`` metadata\n  attribute is used in combination with ``--use-python3`` pack install flag. (bug fix) #4654 #4662\n* Add ``source_channel`` back to the context used by Mistral workflows for executions which are\n  triggered via ChatOps (using action alias).\n\n  In StackStorm v3.0.0, this variable was inadvertently removed from the context used by Mistral\n  workflows. (bug fix) #4650 #4656\n* Fix a bug with ``timestamp`` attribute in the ``execution.log`` attribute being incorrect when\n  server time where st2api is running was not set to UTC. (bug fix) #4668\n\n  Contributed by Igor Cherkaev. (@emptywee)\n* Fix a bug with some packs which use ``--use-python3`` flag (running Python 3 actions on installation\n  where StackStorm components run under Python 2) which rely on modules from Python 3 standard\n  library which are also available in Python 2 site-packages (e.g. ``concurrent``) not working\n  correctly.\n\n  In such scenario, package / module was incorrectly loaded from Python 2 site-packages instead of\n  Python 3 standard library which broke such packs. (bug fix) #4658 #4674\n* Remove policy-delayed status to avoid bouncing between delayed statuses. (bug fix) #4655\n* Fix a possible shell injection in the ``linux.service`` action. User who had access to run this\n  action could cause a shell command injection by passing a compromised value for either the\n  ``service`` or ``action`` parameter. (bug fix) #4675\n\n  Reported by James Robinson (Netskope and Veracode).\n* Replace ``sseclient`` library on which CLI depends on with ``sseclient-py``. ``sseclient`` has\n  various issue which cause client to sometimes hang and keep the connection open which also causes\n  ``st2 execution tail`` command to sometimes hang for a long time. (improvement)\n* Truncate some database index names so they are less than 65 characters long in total. This way it\n  also works with AWS DocumentDB which doesn't support longer index name at the moment.\n\n  NOTE: AWS DocumentDB is not officially supported. Use at your own risk. (improvement) #4688 #4690\n\n  Reported by Guillaume Truchot (@GuiTeK)\n\n3.0.0 - April 18, 2019\n----------------------\n\nAdded\n~~~~~\n\n* Allow access to user-scoped datastore items using ``{{ st2kv.user.<key name> }}`` Jinja template\n  notation inside the action parameter default values. (improvement) #4463\n\n  Contributed by Hiroyasu OHYAMA (@userlocalhost).\n* Add support for new ``python_versions`` (``list`` of ``string``) attribute to pack metadata file\n  (``pack.yaml``). With this attribute pack declares which major Python versions it supports and\n  works with (e.g. ``2`` and ``3``).\n\n  For backward compatibility reasons, if pack metadata file doesn't contain that attribute, it's\n  assumed it only works with Python 2. (new feature) #4474\n* Update service bootstrap code and make sure all the services register in a service registry once\n  they come online and become available.\n\n  This functionality is only used internally and will only work if configuration backend is\n  correctly configured in ``st2.conf`` (new feature) #4548\n* Add new ``GET /v1/service_registry/groups`` and\n  ``GET /v1/service_registry/groups/<group_id>/members`` API endpoint for listing available service\n  registry groups and members.\n\n  Also add corresponding CLI commands - ``st2 service-registry group list``, ``st2 service registry\n  member list [--group-id=<group id>]``\n\n  NOTE: This API endpoint is behind an RBAC wall and can only be viewed by the admins. (new feature)\n  #4548\n* Add support for ``?include_attributes`` and ``?exclude_attributes`` query param filter to the\n  ``GET /api/v1/executions/{id}`` API endpoint. Also update ``st2 execution get`` CLI command so it\n  only retrieves attributes which are displayed. (new feature) #4497\n\n  Contributed by Nick Maludy (@nmaludy Encore Technologies)\n\n* Add new ``--encrypted`` flag to ``st2 key set`` CLI command that allows users to pass in values\n  which are already encrypted.\n\n  This attribute signals the API that the value is already encrypted and should be used as-is.\n\n  ``st2 key load`` CLI command has also been updated so it knows how to work with values which are\n  already encrypted. This means that ``st2 key list -n 100 -j < data.json ; st2 key load\n  data.json`` will now also work out of the box for encrypted datastore values (values which have\n  ``encrypted: True`` and ``secret: True`` attribute will be treated as already encrypted and used\n  as-is).\n\n  The most common use case for this feature is migrating / restoring datastore values from one\n  StackStorm instance to another which uses the same crypto key.\n\n  Contributed by Nick Maludy (Encore Technologies) #4547\n* Add ``source_channel`` to Orquesta ``st2()`` context for workflows called via ChatOps. #4600\n\nChanged\n~~~~~~~\n\n* Changed the ``inquiries`` API path from ``/exp`` to ``/api/v1``. #4495\n* Refactored workflow state in orquesta workflow engine. Previously, state in the workflow engine\n  is not status to be consistent with st2. Other terminologies used in the engine are also revised\n  to make it easier for developers to understand. (improvement)\n* Update Python runner code so it prioritizes libraries from pack virtual environment over StackStorm\n  system dependencies.\n\n  For example, if pack depends on ``six==1.11.0`` in pack ``requirements.txt``, but StackStorm depends\n  on ``six==1.10.0``, ``six==1.11.0`` will be used when running Python actions from that pack.\n\n  Keep in mind that will not work correctly if pack depends on a library which brakes functionality used\n  by Python action wrapper code.\n\n  Contributed by Hiroyasu OHYAMA (@userlocalhost). #4571\n* Improved the way that the ``winrm-ps-script`` runner sends scripts to the target Windows\n  host. Previously the script was read from the local filesystem and serialized as one long\n  command executed on the command line. This failed when the script was longer than either\n  2047 or 8191 bytes (depending on Windows version) as the Windows command line uses this\n  as its maximum length. To overcome this, the ``winrm-ps-script`` runner now uploads the\n  script into a temporary directory on the target host, then executes the script.\n  (improvement) #4514\n\n  Contributed by Nick Maludy (Encore Technologies)\n* Update various internal dependencies to latest stable versions (apscheduler, pyyaml, kombu,\n  mongoengine, pytz, stevedore, python-editor, jinja2). #4610\n* Update logging code so we exclude log messages with log level ``AUDIT`` from a default service\n  log file (e.g. ``st2api.log``). Log messages with level ``AUDIT`` are already logged in a\n  dedicated service audit log file (e.g. ``st2api.audit.log``) so there is no need for them to also\n  be duplicated and included in regular service log file.\n\n  NOTE: To aid with debugging, audit log messages are also included in a regular log file when log\n  level is set to ``DEBUG`` or ``system.debug`` config option is set to ``True``.\n\n  Reported by Nick Maludy. (improvement) #4538 #4502 #4621\n* Add missing ``--user`` argument to ``st2 execution list`` CLI command. (improvement) #4632\n\n  Contributed by Tristan Struthers (@trstruth).\n* Update ``decrypt_kv`` Jinja template filter so it to throws a more user-friendly error message\n  when decryption fails because the variable references a datastore value which doesn't exist.\n  (improvement) #4634\n* Updated orquesta to v0.5. (improvement)\n\nFixed\n~~~~~\n\n* Refactored orquesta execution graph to fix performance issue for workflows with many references\n  to non-join tasks. st2workflowengine and DB models are refactored accordingly. (improvement)\n  StackStorm/orquesta#122.\n* Fix orquesta workflow stuck in running status when one or more items failed execution for a with\n  items task. (bug fix) #4523\n* Fix orquesta workflow bug where context variables are being overwritten on task join. (bug fix)\n  StackStorm/orquesta#112\n* Fix orquesta with items task performance issue. Workflow runtime increase significantly when a\n  with items task has many items and result in many retries on write conflicts. A distributed lock\n  is acquired before write operations to avoid write conflicts. (bug fix) Stackstorm/orquesta#125\n* Fix a bug with some API endpoints returning 500 internal server error when an exception contained\n  unicode data. (bug fix) #4598\n* Fix the ``st2 workflow inspect`` command so it correctly passes authentication token. (bug fix)\n  #4615\n* Fix an issue with new line characters (``\\n``) being converted to ``\\r\\n`` in remote shell\n  command and script actions which use sudo. (bug fix) #4623\n* Update service bootstrap and ``st2-register-content`` script code so non-fatal errors are\n  suppressed by default and only logged under ``DEBUG`` log level. (bug fix) #3933 #4626 #4630\n* Fix a bug with not being able to decrypt user-scoped datastore values inside Jinja expressions\n  using ``decrypt_kv`` Jinja filter. (bug fix) #4634\n\n  Contributed by Hiroyasu OHYAMA (@userlocalhost).\n* Fix a bug with user-scoped datastore values not working inside action-chain workflows. (bug fix)\n  #4634\n* Added missing parameter types to ``linux.wait_for_ssh`` action metadata. (bug fix) #4611\n* Fix HTTP runner (``http-request``) so it works correctly with unicode (non-ascii) body payloads.\n  (bug fix) #4601 #4599\n\n  Reported by Carlos Santana (@kknyxkk) and Rafael Martins (@rsmartins78).\n* Fix ``st2-self-check`` so it sets correct permissions on pack directories which it copies over\n  to ``/opt/stackstorm/packs``. (bug fix) #4645\n* Fix ``POST /v1/actions`` API endpoint to throw a more user-friendly error when writing data file\n  to disk fails because of incorrect permissions. (bug fix) #4645\n\n2.10.4 - March 15, 2019\n-----------------------\n\nFixed\n~~~~~\n\n* Fix inadvertent regression in notifier service which would cause generic action trigger to only\n  be dispatched for completed states even if custom states were specified using\n  ``action_sensor.emit_when`` config option. (bug fix)\n  Reported by Shu Sugimoto (@shusugmt). #4591\n* Make sure we don't log auth token and api key inside st2api log file if those values are provided\n  via query parameter and not header (``?x-auth-token=foo``, ``?st2-api-key=bar``). (bug fix) #4592\n  #4589\n* Fix rendering of ``{{ config_context. }}`` in orquesta task that references action from a\n  different pack (bug fix) #4570 #4567\n* Add missing default config location (``/etc/st2/st2.conf``) to the following services:\n  ``st2actionrunner``, ``st2scheduler``, ``st2workflowengine``. (bug fix) #4596\n* Update statsd metrics driver so any exception thrown by statsd library is treated as non fatal.\n\n  Previously there was an edge case if user used a hostname instead of an IP address for metrics\n  backend server address. In such scenario, if hostname DNS resolution failed, statsd driver would\n  throw the exception which would propagate all the way up and break the application. (bug fix) #4597\n\n  Reported by Chris McKenzie.\n\n2.10.3 - March 06, 2019\n-----------------------\n\nFixed\n~~~~~\n\n* Fix improper CORS where request from an origin not listed in ``allowed_origins`` will be responded\n  with ``null`` for the ``Access-Control-Allow-Origin`` header. The fix returns the first of our\n  allowed origins if the requesting origin is not a supported origin. Reported by Barak Tawily.\n  (bug fix)\n\n2.9.3 - March 06, 2019\n-----------------------\n\nFixed\n~~~~~\n\n* Fix improper CORS where request from an origin not listed in ``allowed_origins`` will be responded\n  with ``null`` for the ``Access-Control-Allow-Origin`` header. The fix returns the first of our\n  allowed origins if the requesting origin is not a supported origin. Reported by Barak Tawily.\n  (bug fix)\n\n2.10.2 - February 21, 2019\n--------------------------\n\nAdded\n~~~~~\n\n* Add support for various new SSL / TLS related config options (``ssl_keyfile``, ``ssl_certfile``,\n  ``ssl_ca_certs``, ``ssl_certfile``, ``authentication_mechanism``) to the ``messaging`` section in\n  ``st2.conf`` config file.\n\n  With those config options, user can configure things such as client based certificate\n  authentication, client side verification of a server certificate against a specific CA bundle, etc.\n\n  NOTE: Those options are only supported when using a default and officially supported AMQP backend\n  with RabbitMQ server. (new feature) #4541\n* Add metrics instrumentation to the ``st2notifier`` service. For the available / exposed metrics,\n  please refer to https://docs.stackstorm.com/reference/metrics.html. (improvement) #4536\n\nChanged\n~~~~~~~\n\n* Update logging code so we exclude log messages with log level ``AUDIT`` from a default service\n  log file (e.g. ``st2api.log``). Log messages with level ``AUDIT`` are already logged in a\n  dedicated service audit log file (e.g. ``st2api.audit.log``) so there is no need for them to also\n  be duplicated and included in regular service log file.\n\n  NOTE: To aid with debugging, audit log messages are also included in a regular log file when log\n  level is set to ``DEBUG`` or ``system.debug`` config option is set to ``True``.\n\n  Reported by Nick Maludy. (improvement) #4538 #4502\n* Update ``pyyaml`` dependency to the latest version. This latest version fixes an issue which\n  could result in a code execution vulnerability if code uses ``yaml.load`` in an unsafe manner\n  on untrusted input.\n\n  NOTE: StackStorm platform itself is not affected, because we already used ``yaml.safe_load``\n  everywhere.\n\n  Only custom packs which use ``yaml.load`` with non trusted user input could potentially be\n  affected. (improvement) #4510 #4552 #4554\n* Update Orquesta to ``v0.4``. #4551\n\nFixed\n~~~~~\n\n* Fixed the ``packs.pack_install`` / ``!pack install {{ packs }}`` action-alias to not have\n  redundant patterns. Previously this prevented it from being executed via\n  ``st2 action-alias execute 'pack install xxx'``. #4511\n\n  Contributed by Nick Maludy (Encore Technologies)\n* Fix datastore value encryption and make sure it also works correctly for unicode (non-ascii)\n  values.\n\n  Reported by @dswebbthg, @nickbaum. (bug fix) #4513 #4527 #4528\n* Fix a bug with action positional parameter serialization used in local and remote script runner\n  not working correctly with non-ascii (unicode) values.\n\n  This would prevent actions such as ``core.sendmail`` which utilize positional parameters from\n  working correctly when a unicode value was provided.\n\n  Reported by @johandahlberg (bug fix) #4533\n* Fix ``core.sendmail`` action so it specifies ``charset=UTF-8`` in the ``Content-Type`` email\n  header. This way it works correctly when an email subject and / or body contains unicode data.\n\n  Reported by @johandahlberg (bug fix) #4533 4534\n\n* Fix CLI ``st2 apikey load`` not being idempotent and API endpoint ``/api/v1/apikeys`` not\n  honoring desired ``ID`` for the new record creation. #4542\n* Moved the lock from concurrency policies into the scheduler to fix a race condition when there\n  are multiple scheduler instances scheduling execution for action with concurrency policies.\n  #4481 (bug fix)\n* Add retries to scheduler to handle temporary hiccup in DB connection. Refactor scheduler\n  service to return proper exit code when there is a failure. #4539 (bug fix)\n* Update service setup code so we always ignore ``kombu`` library ``heartbeat_tick`` debug log\n  messages.\n\n  Previously if ``DEBUG`` log level was set in service logging config file, but ``--debug``\n  service CLI flag / ``system.debug = True`` config option was not used, those messages were\n  still logged which caused a lot of noise which made actual useful log messages hard to find.\n  (improvement) #4557\n\n2.10.1 - December 19, 2018\n--------------------------\n\nFixed\n~~~~~\n\n* Fix an issue with ``GET /v1/keys`` API endpoint not correctly handling ``?scope=all`` and\n  ``?user=<username>`` query filter parameter inside the open-source edition. This would allow\n  user A to retrieve datastore values from user B and similar.\n\n  NOTE: Enterprise edition with RBAC was not affected, because in RBAC version, correct check is\n  in place which only allows users with an admin role to use ``?scope=all`` and retrieve / view\n  datastore values for arbitrary system users. (security issue bug fix)\n\n2.10.0 - December 13, 2018\n--------------------------\n\nAdded\n~~~~~\n\n* Added ``notify`` runner parameter to Orquesta that allows user to specify which task(s) to get\n  notified on completion.\n* Add support for task delay in Orquesta workflows. #4459 (new feature)\n* Add support for task with items in Orquesta workflows. #4400 (new feature)\n* Add support for workflow output on error in Orquesta workflows. #4436 (new feature)\n* Added ``-o`` and ``-m`` CLI options to ``st2-self-check`` script, to skip Orquesta and/or Mistral\n  tests. #4347\n* Allow user to specify new ``database.authentication_mechanism`` config option in\n  ``/etc/st2/st2.conf``.\n\n  By default, SCRAM-SHA-1 is used with MongoDB 3.0 and later and MONGODB-CR (MongoDB Challenge\n  Response protocol) for older servers.\n\n  Contributed by @aduca85 #4373\n* Add new ``metadata_file`` attribute to the following models: Action, Action Alias, Rule, Sensor,\n  TriggerType. Value of this attribute points to a metadata file for a specific resource (YAML file\n  which contains actual resource definition). Path is relative to the pack directory (e.g.\n  ``actions/my_action1.meta.yaml``, ``aliases/my_alias.yaml``, ``sensors/my_sensor.yaml``,\n  ``rules/my_rule.yaml``, ``triggers/my_trigger.yaml`` etc.).\n\n  Keep in mind that triggers can be registered in two ways - either via sensor definition file in\n  ``sensors/`` directory or via trigger definition file in ``triggers/`` directory. If\n  ``metadata_file`` attribute on TriggerTypeDB model points to ``sensors/`` directory it means that\n  trigger is registered via sensor definition. (new feature) #4445\n* Add new ``st2client.executions.get_children`` method for returning children execution objects for\n  a specific (parent) execution. (new feature) #4444\n\n  Contributed by Tristan Struthers (@trstruth).\n* Allow user to run a subset of pack tests by utilizing the new ``-f`` command line option in the\n  ``st2-run-pack-tests`` script.\n\n  For example:\n\n  1. Run all tests in a test file (module):\n\n     st2-run-pack-tests -j -x -p contrib/packs/ -f test_action_download\n\n  2. Run a single test class\n\n     st2-run-pack-tests -j -x -p contrib/packs/ -f test_action_download:DownloadGitRepoActionTestCase\n\n  3. Run a single test class method\n\n     st2-run-pack-tests -j -x -p contrib/packs/ -f test_action_download:DownloadGitRepoActionTestCase.test_run_pack_download\n\n  (new feature) #4464\n\nChanged\n~~~~~~~\n\n* Redesigned and rewritten the action execution scheduler. Requested executions are put in a\n  persistent queue for scheduler to process. Architecture is put into place for more complex\n  execution scheduling. Action execution can be delayed on request. (improvement)\n* ``core.http`` action now supports additional HTTP methods: OPTIONS, TRACE, PATCH, PURGE.\n\n  Contributed by @emptywee (improvement) #4379\n* Runner loading code has been updated so it utilizes new \"runner as Python package\" functionality\n  which has been introduced in a previous release. This means that the runner loading is now fully\n  automatic and dynamic.\n\n  All the available / installed runners are automatically loaded and registering on each StackStorm\n  service startup.\n\n  This means that ``st2ctl reload --register-runners`` flag is now obsolete because runners are\n  automatically registered on service start up. In addition to that,\n  ``content.system_runners_base_path`` and ``content.runners_base_paths`` config options are now\n  also deprecated and unused.\n\n  For users who wish to develop and user custom action runners, they simply need to ensure they are\n  packaged as Python packages and available / installed in StackStorm virtual environment\n  (``/opt/stackstorm/st2``). (improvement) #4217\n* Old runner names which have been deprecated in StackStorm v0.9.0 have been removed (run-local,\n  run-local-script, run-remote, run-remote-script, run-python, http-runner). If you are still using\n  actions which reference runners using old names, you need to update them to keep it working.\n  #4217\n* Update various CLI commands to only retrieve attributes which are displayed in the CLI from the\n  API (``st2 execution list``, ``st2 execution get``, ``st2 action list``, ``st2 rule list``,\n  ``st2 sensor list``). This speeds up run-time and means now those commands now finish faster.\n\n  If user wants to retrieve and view all the attributes, they can use ``--attr all`` CLI command\n  argument (same as before). (improvement) #4396\n* Update various internal dependencies to latest stable versions (greenlet, pymongo, pytz,\n  stevedore, tooz). #4410\n\n* Improve ``st2.conf`` migration for the new services by using prod-friendly logging settings by default #4415\n* Refactor Orquesta workflow to output on error. Depends on PR\n  https://github.com/StackStorm/orquesta/pull/101 and https://github.com/StackStorm/orquesta/pull/102\n  (improvement)\n* Rename ``st2client.liveactions`` to ``st2client.executions``. ``st2client.liveactions`` already\n  represented operations on execution objects, but it was incorrectly named.\n\n  For backward compatibility reasons, ``st2client.liveactions`` will stay as an alias for\n  ``st2client.executions`` and continue to work until it's fully removed in a future release.\n\nFixed\n~~~~~\n\n* ``st2 login`` CLI commands now exits with non zero exit code when login fails due to invalid\n  credentials. (improvement) #4338\n* Fix ``st2 key load`` that errors when importing an empty file #43\n* Fixed warning in ``st2-run-pack-tests`` about invalid format for ``pip list``. (bug fix)\n\n  Contributed by Nick Maludy (Encore Technologies). #4380\n* Fix a bug with ``st2 execution get`` / ``st2 run`` CLI command throwing an exception if the\n  result field contained a double backslash string which looked like an unicode escape sequence.\n  CLI incorrectly tried to parse that string as unicode escape sequence.\n\n  Reported by James E. King III @jeking3 (bug fix) #4407\n* Fix a bug so ``timersengine`` config section in ``st2.conf`` has precedence over ``timer``\n  section if explicitly specified in the config file.\n\n  Also fix a bug with default config values for ``timer`` section being used if user only\n  specified ``timersengine`` section in the config. Previously user options were incorrectly\n  ignored in favor of the default values. (bug fix) #4424\n* ``st2 pack install -j`` now only spits JSON output. Similarly, ``st2 pack install -y`` only spits\n  YAML output. This change would enable the output to be parsed by tools.\n  The behavior of ``st2 pack install`` hasn't changed and is human friendly. If you want to get meta\n  information about the pack as JSON (count of actions, sensors etc), you should rely on already\n  existing ``st2 pack show -j``.\n\n  Reported by Nick Maludy (improvement) #4260\n* Fix string operations on unicode data in Orquesta workflows, associated with PR\n  https://github.com/StackStorm/orquesta/pull/98. (bug fix)\n* Fix access to st2 and action context in Orquesta workflows, associated with PR\n  https://github.com/StackStorm/orquesta/pull/104. (bug fix)\n* ``st2ctl reload --register-aliases`` and ``st2ctl reload --register-all`` now spits a warning when\n  trying to register aliases with no corresponding action registered in the db.\n\n  Reported by nzlosh (improvement) #4372.\n\n2.9.1 - October 03, 2018\n------------------------\n\nChanged\n~~~~~~~\n\n* Speed up pack registration through the ``/v1/packs/register`` API endpoint. (improvement) #4342\n* Triggertypes API now sorts by trigger ref by default. ``st2 trigger list`` will now show a sorted\n  list. (#4348)\n* Update ``st2-self-check`` script to include per-test timing information. (improvement) #4359\n\nFixed\n~~~~~\n\n* Update ``st2sensorcontainer`` service to throw if user wants to run a sensor from a pack which is\n  using Python 3 virtual environment.\n\n  We only support running Python runner actions from packs which use mixed Python environments\n  (StackStorm components are running under Python 2 and particular a pack virtual environment is\n  using Python 3). #4354\n* Update ``st2-pack-install`` and ``st2 pack install`` command so it works with local git repos\n  (``file://<path to local git repo>``) which are in a detached head state (e.g. specific revision\n  is checked out). (improvement) #4366\n* Fix a race which occurs when there are multiple concurrent requests to resume a workflow. #4369\n\n2.9.0 - September 16, 2018\n--------------------------\n\nAdded\n~~~~~\n\n* Add new runners: ``winrm-cmd``, ``winrm-ps-cmd`` and ``winrm-ps-script``.\n  The ``winrm-cmd`` runner executes Command Prompt commands remotely on Windows hosts using the\n  WinRM protocol. The ``winrm-ps-cmd`` and ``winrm-ps-script`` runners execute PowerShell commands\n  and scripts on remote Windows hosts using the WinRM protocol.\n\n  To accompany these new runners, there are two new actions ``core.winrm_cmd`` that executes remote\n  Command Prompt commands along with ``core.winrm_ps_cmd`` that executes remote PowerShell commands.\n  (new feature) #1636\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Add new ``?tags``, query param filter to the ``/v1/actions`` API endpoint. This query parameter\n  allows users to filter out actions based on the tag name . By default, when no filter values are\n  provided, all actions are returned. (new feature) #4219\n* Add a new standalone standalone ``st2-pack-install`` CLI command. This command installs a pack\n  (and sets up the pack virtual environment) on the server where it runs. It doesn't register the\n  content. It only depends on the Python, git and pip binary and ``st2common`` Python package to be\n  installed on the system where it runs. It doesn't depend on the database (MongoDB) and message\n  bus (RabbitMQ).\n\n  It's primary meant to be used in scenarios where the content (packs) are baked into the base\n  container / VM image which is deployed to the cluster.\n\n  Keep in mind that the content itself still needs to be registered with StackStorm at some later\n  point when access to RabbitMQ and MongoDB is available by running\n  ``st2ctl reload --register-all``. (new feature) #3912 #4256\n* Add new ``/v1/stream/executions/<id>/output[?output_type=all|stdout|stderr]`` stream API\n  endpoint.\n\n  This API endpoint returns event source compatible response format.\n\n  For running executions it returns any output produced so far and any new output as it's produced.\n  Once the execution finishes, the connection is automatically closed.\n\n  For completed executions it returns all the output produced by the execution. (new feature)\n* Add new ``core.inject_trigger`` action for injecting a trigger instance into the system.\n\n  Keep in mind that the trigger which is to be injected must be registered and exist in the system.\n  (new feature) #4231 #4259\n* Add support for ``?include_attributes`` query param filter to all the content pack resource\n  get all (list) API endpoints (actions, rules, trigger, executions, etc.). With this query\n  parameter user can control which API model attributes (fields) to receive in the response. In\n  situations where user is only interested in a subset of the model attributes, this allows for a\n  significantly reduced response size and for a better performance. (new feature) (improvement)\n  #4300\n* Add new ``action_sensor.emit_when`` config option which allows user to specify action status for\n  which actiontrigger is emitted. For backward compatibility reasons it defaults to all the action\n  completed states. (improvement) #4312 #4315\n\n  Contributed by Shu Sugimoto.\n* Improve performance of schedule action execution (``POST /v1/executions``) API endpoint.\n\n  Performance was improved by reducing the number of duplicated database queries, using atomic\n  partial document updates instead of full document updates and by improving database document\n  serialization and de-serialization performance. (improvement) #4030 #4331\n* Ported existing YAQL and Jinja functions from st2common to Orquesta. (new feature)\n* Add error entry in Orquesta workflow result on action execution failure. (improvement)\n\nChanged\n~~~~~~~\n\n* ``st2 key list`` command now defaults to ``--scope=all`` aka displaying all the datastore values\n  (system and current user scoped) . If you only want to display system scoped values (old behavior)\n  you can do that by passing ``--scope=system`` argument to the ``st2 key list`` command\n  (``st2 key list --scope=system``). (improvement) #4221\n* The orquesta conductor implemented event based state machines to manage state transition of\n  workflow execution. Interfaces to set workflow state and update task on action execution\n  completion have changed and calls to those interfaces are changed accordingly. (improvement)\n* Change ``GET /v1/executions/<id>/output`` API endpoint so it never blocks and returns data\n  produced so far for running executions. Behavior for completed executions is the same and didn't\n  change - all data produced by the execution is returned in the raw format.\n\n  The streaming (block until execution has finished for running executions) behavior has been moved\n  to the new ``/stream/v1/executions/<id>/output`` API endpoint.\n\n  This way we are not mixing non-streaming (short lived) and streaming (long lived) connections\n  inside a single service (st2api). (improvement)\n* Upgrade ``mongoengine`` (0.15.3) and ``pymongo`` (3.7.1) to the latest stable version. Those\n  changes will allow us to support MongoDB 3.6 in the near future.\n\n  New version of ``mongoengine`` should also offer better performance when inserting and updating\n  larger database objects (e.g. executions). (improvement) #4292\n* Trigger parameters and payload schema validation is now enabled by default\n  (``system.validate_trigger_parameters`` and ``system.validate_trigger_payload`` config options\n  now default to ``True``).\n\n  This means that trigger parameters are now validated against the ``parameters_schema`` defined on\n  the trigger type when creating a rule and trigger payload is validated against ``payload_schema``\n  when dispatching a trigger via the sensor or via the webhooks API endpoint.\n\n  This provides a much safer and user-friendly default value. Previously we didn't validate trigger\n  payload for custom (non-system) triggers when dispatching a trigger via webhook which meant that\n  webhooks API endpoint would silently accept an invalid trigger (e.g. referenced trigger doesn't\n  exist in the database or the payload doesn't validate against the ``payload_schema``), but\n  ``TriggerInstanceDB`` object would never be created because creation failed inside the\n  ``st2rulesengine`` service. This would make such issues very hard to troubleshoot because only\n  way to find out about this failure would be to inspect the ``st2rulesengine`` service logs.\n  (improvement) #4231\n* Improve code metric instrumentation and instrument code and various services with more metrics.\n  Also document various exposed metrics. Documentation can be found at\n  https://docs.stackstorm.com/latest/reference/metrics.html (improvement) #4310\n* Add new ``metrics.prefix`` config option. With this option user can specify an optional prefix\n  which is prepended to each metric key (name). This comes handy in scenarios where user wants to\n  submit metrics from multiple environments / deployments (e.g. testing, staging, dev) to the same\n  backend instance. (improvement) #4310\n* Improve ``st2 execution tail`` CLI command so it also supports Orquesta workflows and arbitrarily\n  nested workflows. Also fix the command so it doesn't include data from other unrelated running\n  executions. (improvement) #4328\n* Change default NGINX configuration to use HTTP 308 redirect, rather than 301, for plaintext requests.\n  #4335\n* Improve performance of the ``GET /v1/actions/views/overview`` API endpoint. (improvement) #4337\n\nFixed\n~~~~~\n\n* Fix an issue with ``AttributeError: module 'enum' has no attribute 'IntFlag'`` error which would\n  appear when using Python 3 for a particular pack virtual environment and running on RHEL /\n  CentOS. (bug fix) #4297\n* Fix a bug with action runner throwing an exception and failing to run an action if there was an\n  empty pack config inside ``/opt/stackstorm/configs/``. (bug fix) #4325\n* Fix ``action_sensor.enable`` config option so it works correctly if user sets this option to a\n  non-default value of ``True``. (bug fix) #4312 #4315\n\n  Contributed by Shu Sugimoto.\n* Update ``GET /v1/actions/views/entry_point/<action ref>`` to return correct ``Content-Type``\n  response header based on the entry point type / file extension. Previously it would always\n  incorrectly return ``application/json``. (improvement) #4327\n\nDeprecated\n~~~~~~~~~~\n\n* The CloudSlang runner is now deprecated. In StackStorm 3.1 it will be removed from the core\n  StackStorm codebase. The runner code will be moved to a separate repository, and no longer\n  maintained by the core StackStorm team. Users will still be able to install and use this runner,\n  but it will require additional steps to install.\n* The ``winexe``-based Windows runners are now deprecated. They will be removed in StackStorm 3.1.\n  They have been replaced by ``pywinrm``-based Windows runners. See\n  https://docs.stackstorm.com/latest/reference/runners.html#winrm-command-runner-winrm-cmd\n  for more on using these new runners.\n\n2.8.1 - July 18, 2018\n---------------------\n\nAdded\n~~~~~\n\n* Update ``st2`` CLI to inspect ``COLUMNS`` environment variable first when determining the\n  terminal size. Previously this environment variable was checked second last (after trying to\n  retrieve terminal size using various OS specific methods and before falling back to the default\n  value).\n\n  This approach is more performant and allows user to easily overwrite the default value or value\n  returned by the operating system checks - e.g. by running ``COLUMNS=200 st2 action list``.\n  (improvement) #4242\n\nChanged\n~~~~~~~\n\n* Update ``st2client/setup.py`` file to dynamically load requirements from\n  ``st2client/requirements.txt`` file. The code works with pip >= 6.0.0, although using pip 9.0.0\n  or higher is strongly recommended. (improvement) #4209\n* Migrated runners to using the ``in-requirements.txt`` pattern for \"components\" in the build\n  system, so the ``Makefile`` correctly generates and installs runner dependencies during\n  testing and packaging. (improvement) (bugfix) #4169\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Update ``st2`` CLI to use a more sensible default terminal size for table formatting purposes if\n  we are unable to retrieve terminal size using various system-specific approaches.\n\n  Previously we would fall back to a very unfriendly default of 20 columns for a total terminal\n  width. This would cause every table column to wrap and make output impossible / hard to read.\n  (improvement) #4242\n\nFixed\n~~~~~\n\n* Fixed a bug where ``secret: true`` was not applying to full object and array trees. (bugfix) #4234\n  Reported by @jjm\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Mark ``password`` ``http-request`` parameter as a secret. (bug fix) #4245\n\n  Reported by @daniel-mckenna\n\n2.8.0 - July 10, 2018\n---------------------\n\nAdded\n~~~~~\n\n* Orquesta - new StackStorm-native workflow engine. This is currently in **beta**. (new feature)\n* Added metrics for collecting performance and health information about the various ST2 services\n  and functions. (new feature) #4004 #2974\n* When running a dev (unstable) release include git revision hash in the output when using\n  ``st2 --version`` CLI command. (new feature) #4117\n* Update rules engine to also create rule enforcement object when trigger instances fails to match\n  a rule during the rule matching / filtering phase due to an exception in the rule criteria (e.g.\n  invalid Jinja expression, etc.).\n\n  This change increases visibility into rules which didn't match due to an exception. Previously\n  this was only visible / reflected in the rules engine log file. (improvement) #4134\n* Add new ``GET /v1/ruleenforcements/views[/<enforcement id>]`` API endpoints which allow user to\n  retrieve RuleEnforcement objects with the corresponding TriggerInstance and Execution objects.\n  (new feature) #4134\n* Add new ``status`` field to the ``RuleEnforcement`` model. This field can contain the following\n  values - ``succeeded`` (trigger instance matched a rule and action execution was triggered\n  successfully), ``failed`` (trigger instance matched a rule, but it didn't result in an action\n  execution due to Jinja rendering failure or other exception). (improvement) #4134 #4152\n* Add trigger type reference based filtering to the ``/v1/triggerinstances`` API endpoint - e.g.\n  ``/v1/triggerinstances?trigger_type=core.st2.webhook``. (new feature) #4151\n* Add new ``--python3`` flag to ``st2 pack install`` CLI command and ``python3`` parameter to\n  ``packs.{install,setup_virtualenv}`` actions. When the value of this parameter is True, it\n  uses ``python3`` binary when creating virtual environment for that pack (based on the value of\n  ``actionrunner.python3_binary`` config option).\n\n  Note 1: For this feature to work, Python 3 needs to be installed on the system, ``virtualenv``\n  package installed on the system needs to support Python 3 (it needs to be a recent version) and\n  pack in question needs to support Python 3.\n\n  Note 2: This feature is experimental and opt-in. (new feature) #4016 #3922 #4149\n* Add two new Jinja filters - ``basename`` (``os.path.basename``) and ``dirname``\n  (``os.path.dirname``). #4184\n\n  Contributed by Florian Reisinger (@reisingerf).\n\nChanged\n~~~~~~~\n\n* Update st2 CLI to create the configuration directory and file, and authentication tokens with\n  secure permissions (eg: readable only to owner) #4173\n* Refactor the callback module for the post run in runner to be more generic. (improvement)\n* Update various Python dependencies to the latest stable versions (gunicorn, gitpython,\n  python-gnupg, tooz, flex). #4110\n* Update all the service and script entry points to use ``/etc/st2/st2.conf`` as a default value\n  for the config file location.\n\n  This way users don't need to explicitly provide ``--config-file`` CLI argument when running\n  various scripts (e.g. ``st2-track-result``, ``st2-apply-rbac-definitions``, etc.) and when they\n  just want to use a default config file. (improvement) #4111\n* Update st2 CLI to print a warning if a non-unicode system locale which would prevent StackStorm\n  to function correctly in some scenarios is used. (improvement) #4127 #4120\n* Upgrade various internal Python library dependencies to the latest stable versions (kombu, amqp,\n  gitpython, pytz, semver, oslo.utils). (improvement) #4162\n* Move from ``keyczar`` library to ``cryptography`` library for handling symmetric encryption and\n  decryption (secret datastore values).\n\n  Note: This change is fully backward compatible since it just changes the underlying backend and\n  implementation details. The same underlying encryption algorithm is used (AES256 in CBC mode\n  with HMAC signature). (improvement) #4165\n\nFixed\n~~~~~\n\n* Fixed a bug where secrets in pack configs weren't being masked. Recently we\n  introduced support for nested objects and arrays. Secret parameters within these\n  nested objects and arrays were not being masked. The fix involves us fully\n  traversing deeply nested objects and arrays and masking out any variables\n  marked as secret. This means we now support pack config JSON schemas with\n  ``type: object`` and its corresponding ``parameters: {}`` stanza, along with\n  ``type: array`` and its corresponding ``items: {}`` stanza. We still do NOT\n  support JSON schema combinations that includes the ``anyOf``, ``allOf``,\n  ``oneOf``, and ``not`` keywords. (bug fix) #4139\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Style clean up to transport queues module and various config modules. (improvement)\n* Fixed CLI help for ``st2 action-alias match`` and ``execute``. (#4174).\n* Fix regression in ``?include_attributes`` query param filter in the ``/v1/executions`` API\n  endpoint. (bug fix) #4226\n\n2.7.2 - May 16, 2018\n--------------------\n\nChanged\n~~~~~~~\n\n* Reduce load on LDAP server and cache user groups response in an in-memory cache when RBAC\n  remote LDAP group to local RBAC role synchronization feature is enabled.\n\n  Previously on authentication the code would hit LDAP server multiple times to retrieve user\n  groups. With this change, user LDAP groups are only retrieved once upon authentication and\n  cached and re-used in-memory by default for 120 seconds.\n\n  This reduces load on LDAP server and improves performance upon regular and concurrent user\n  authentication.\n\n  This functionality can be disabled by setting ``cache_user_groups_response`` LDAP\n  authentication backend kwarg to ``false``.\n\n  Note: This change only affects users which utilize RBAC with remote LDAP groups to local RBAC\n  roles synchronization feature enabled. (enterprise) (bug fix) #4103 #4105\n\nFixed\n~~~~~\n\n* Fix an issue (race condition) which would result in not all the remote LDAP groups being\n  synchronized with local RBAC roles if a user tried to authenticate with the same auth token\n  concurrently in a short time frame.\n\n  Note: This issue only affects users which utilize RBAC with remote LDAP groups to local RBAC\n  roles synchronization feature enabled. (enterprise) (bug fix) #4103 #4105\n* Fix an issue with some sensors which rely on ``select.poll()`` (FileWatch, GithubSensor, etc.)\n  stopped working with StackStorm >= 2.7.0.\n\n  StackStorm v2.7.0 inadvertently introduced a change which broke a small set of sensors which\n  rely on ``select.poll()`` functionality. (bug fix) #4118\n\n* Throw if ``id`` CLI argument is not passed to the ``st2-track-result`` script. (bug fix) #4115\n* Fixed pack config's not properly rendering Jinja expressions within lists. (bugfix) #4121\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Fixed pack config rendering error throw meaningful message when a Jinja syntax error is\n  encountered. (bugfix) #4123\n\n  Contributed by Nick Maludy (Encore Technologies).\n\n2.7.1 - April 20, 2018\n----------------------\n\nChanged\n~~~~~~~\n\n* When creating a pack environment during the pack installation, we now pass ``--no-download`` flag\n  to the ``virtualenv`` binary. This way version of pip, wheel and distutils which is enforced by\n  virtualenv is used instead of downloading the latest stable versions from PyPi.\n\n  This results in more reproducible pack virtual environments and we also ensure pip 9.0 is used (\n  there are some known issues with pip 10.0).\n\n  If for some reason you want to revert to the old behavior, you can do that by passing\n  ``no_download=False`` parameter to the ``packs.setup_virtualenv`` action. #4085\n\nFixed\n~~~~~\n\n* Fix ``st2 pack search`` and ``POST /api/v1/packs/index/search`` API endpoint so it doesn't\n  return internal server error when a single pack search term is provided. (bug fix) #4083\n\n2.7.0 - April 12, 2018\n----------------------\n\nAdded\n~~~~~\n\n* Update ``st2 execution tail`` command so it supports double nested workflows (workflow ->\n  workflow -> execution). Previously, only top-level executions and single nested workflows\n  (workflow -> execution) were supported. (improvement) #3962 #3960\n* Add support for utf-8 / unicode characters in the pack config files. (improvement) #3980 #3989\n\n  Contributed by @sumkire.\n* Added the ability of ``st2ctl`` to utilize environment variables from ``/etc/default/st2ctl``\n  (for Ubuntu/Debian) and ``/etc/sysconfig/st2ctl`` (RHEL/CentOS). This allows\n  deployments to override ``COMPONENTS`` and ``ST2_CONF`` in a global location\n  so ``st2ctl`` can start/stop/restart selected components and utilize a non-default\n  location for ``st2.conf``.\n  (new feature) #4027\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Add support for new optional ``content_version`` runner parameter to the Python and Local Shell\n  Script runner. This parameter can contain a git commit hash / tag / branch from a pack git\n  repository and runner will ensure this revision of the pack content (Python action / local shell\n  script action) is used for a particular action execution.\n\n  Keep in mind that providing this parameter only ensures a particular revision of the pack content\n  is used. Python runner virtual environment and dependencies are outside of this scope.\n\n  Note: To be able to utilize this functionality, git version >= 2.5.0 must be installed on the\n  system.\n  (new feature) #3997\n* Update windows runner to correctly handle and use ``timeout`` action execution status.\n  (improvement) #4047\n* Add missing ``scope``, ``decrypt`` and ``encrypt`` arguments to the datastore management\n  related methods on the SensorService class. (improvement) #3895 #4057 #4058\n\n  Reported by @djh2020, @mxmader.\n* Add context field to rule model in which each rule has its own corresponding user. Besides, there\n  is a new RBAC configuration ``permission_isolation``. Whoever can only operate and observe their\n  own rules or executions except ``system_user`` and users with RBAC admin role when set to\n  ``True``. That means system_user has the most powerful permission to operate all resources\n  including rules or executions. (new feature) #4013\n\n  Contributed by Hanxi Liu (@apolloliu).\n\nChanged\n~~~~~~~\n\n* Modified RabbitMQ connection error message to make clear that it is an MQ connection issue. #3992\n* Additional refactor which makes action runners fully standalone and re-distributable Python\n  packages. Also add support for multiple runners (runner modules) inside a single Python package\n  and consolidate Python packages from two to one for the following runners: local runners, remote\n  runners, windows runners. (improvement) #3999\n* Upgrade eventlet library to the latest stable version (0.22.1) (improvement) #4007 #3968\n* Increase maximum retry delay for ``action.retry`` policy from 5 seconds to 120 seconds. Because\n  of the way retries are currently implemented (they are not st2notifier service restart safe),\n  long retry delays are not recommended. For more information on this limitation please refer to\n  the documentation - https://docs.stackstorm.com/reference/policies.html#retry. #3630 #3637\n* Update Python runner so it throws a more user-friendly exception in case Python script tries to\n  access a key in ``self.config`` dictionary which doesn't exist. (improvement) #4014\n* Update various Python dependencies to the latest stable versions (apscheduler, gitpython,\n  pymongo, stevedore, paramiko, tooz, flex, webob, prance).\n* Refactored mistral runner to support callback from mistral instead of relying on st2resultstracker.\n  This reduces the unnecessary traffic and CPU time by querying the mistral API. Included a command to\n  manually add a state entry for Mistral workflow execution to recover from any callback failures.\n  (improvement)\n* Throw a more user-friendly error when writing pack data files to disk and when an invalid file\n  path is provided (e.g. path is outside the pack directory, etc.). (improvement) #4039 #4046\n* Change the output object returned by Windows runners so it matches the format from the local and\n  remote runner.\n\n  Note: This change is backward incompatible - ``result`` attribute has been removed (same\n  information is available in ``stdout`` attribute), ``exit_code`` renamed to ``return_code`` and\n  two new attributes added - ``succeeded`` and ``failed``.\n\n  For more information, please refer to the upgrade notes. #4044 #4047\n\nFixed\n~~~~~\n\n* Fix Python runner actions and ``Argument list too long`` error when very large parameters are\n  passed into the action. The fix utilizes ``stdin`` to pass parameters to the Python action wrapper\n  process instead of CLI argument list. (bug fix) #1598 #3976\n* Fix a regression in ``POST /v1/webhooks/<webhook name>`` API endpoint introduced in v2.4.0\n  and add back support for arrays. In 2.4.0 support for arrays was inadvertently removed and\n  only objects were supported. Keep in mind that this only applies to custom user-defined\n  webhooks and system ``st2`` webhook still requires input to be an object (dictionary).\n  (bug fix) #3956 #3955\n* Fix a bug in the CLI causing ``st2 execution pause`` and ``st2 execution resume``\n  to not work. (bugfix) #4001\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Fixed missing \"paused\" status option from \"st2 execution list\" help output. (bugfix) #4037\n\n  Contributed by Ben Hohnke (NTT Communications ICT Solutions)\n* Fix \"st2 pack install\" command so it doesn't require access to pack index (index.stackstorm.org)\n  when installing a local pack (pack name starting with \"file://\"). (bug fix) #3771 #3772\n* Fix rules engine so it correctly handles and renders action parameters which contain Jinja\n  expressions and default values. (bug fix) #4050 #4050\n\n  Reported by @rakeshrm.\n* Make sure ``observer`` system role also grants ``pack_search`` permission. (bug fix) #4063 #4064\n\n  Reported by @SURAJTHEGREAT.\n* Fix st2 webhook get -h which was asking for a name or id as opposed to the URL of the webhook.\n  Also, fix st2 webhook list to explicitly add a webhook column. (bugfix) #4048\n* Fix an issue with pack config validation code throwing a non-user friendly error message in case\n  config item of type array failed config schema validation. (bug fix) #4166 #4168\n\n  Reported by @NikosVlagoidis.\n\n2.6.0 - January 19, 2018\n------------------------\n\nAdded\n~~~~~\n\n* Add new ``get_user_info`` method to action and sensor service. With this method, user can\n  retrieve information about the user account which is used to perform datastore operations inside\n  the action and sensor service. (new feature) #3831\n* Add new ``/api/v1/user`` API endpoint. This API endpoint is only available to the authenticated\n  users and returns various metadata on the authenticated user (which method did the user use to\n  authenticate, under which username the user is authenticated, which RBAC roles are assignment to\n  this user in case RBAC is enabled, etc.) (new feature) #3831\n* The ``/api/v1/match_and_execute`` API endpoint matches a single alias and executes multiple times\n  if the alias format has a ``match_multiple`` key set to ``true``. Please refer to the\n  documentation for usage. #3884\n\n  Contributed by @ahubl-mz.\n* Add ability to share common code between python sensors and python actions. You can now place\n  common code inside a ``lib`` directory inside a pack (with an ``__init__.py`` inside ``lib``\n  directory to declare it a python package). You can then import the common code in sensors and\n  actions. Please refer to documentation for samples and guidelines. #3490\n* Add support for password protected sudo to the local and remote runner. Password can be provided\n  via the new ``sudo_password`` runner parameter. (new feature) #3867\n* Add new ``--tail`` flag to the ``st2 run`` / ``st2 action execute`` and ``st2 execution re-run``\n  CLI command. When this flag is provided, new execution will automatically be followed and tailed\n  after it has been scheduled. (new feature) #3867\n* Added flag ``--auto-dict`` to ``st2 run`` and ``st2 execution re-run`` commands. This flag must now\n  be specified in order to automatically convert list items to dicts based on presence of colon\n  (``:``) in all of the list items (new feature) #3909\n* Allow user to set default log level used by all the Python runner actions by setting\n  ``actionrunner.pythonrunner```` option in ``st2.conf`` (new feature) #3929\n* Update ``st2client`` package which is also utilized by the CLI so it also works under Python 3.\n\n  Note: Python 2.7 is only officially supported and tested Python version. Using Python 3 is at\n  your own risk - they are likely still many bugs related to Python 3 compatibility. You have been warned.\n  (new feature) #3929 #3932\n\n  Contributed by Anthony Shaw.\n* Add ``?limit=-1`` support for the API to fetch full result set (CLI equivalent flag\n  ``--last/-n``). Post error message for ``limit=0`` and fix corner case where negative values for\n  limit query param were not handled correctly. #3761 #3708 #3735\n* Only allow RBAC admins to retrieve all the results at once using ``?limit=-1`` query param, upate\n  the code so ``api.max_page_size`` config option only applies to non-admin users, meaning users\n  with admin permission can specify arbitrary value for ``?limit`` query param which can also be\n  larger than ``api.max_page_size``. (improvement) #3939\n* Add new ``?include_attributes`` query param filter to ``/v1/executions/`` API endpoint\n  With this filter user can select which fields to include in the response (whitelist approach,\n  opposite of the existing ``?exclude_attributes`` filter).\n\n  For example, if you only want to retrieve ``id`` and ``status`` field, the URL would look like\n  this - ``/v1/executions?include_attributes=id,status``. (new feature) #3953 #3858 #3856\n\nChanged\n~~~~~~~\n\n* ``st2actions.runners.pythonrunner.Action`` class path for base Python runner actions has been\n  deprecated since StackStorm v1.6.0 and will be fully removed in StackStorm v2.7.0. If you have\n  any actions still using this path you are encouraged to update them to use\n  ``st2common.runners.base_action.Action`` path. #3803\n* Refactor ``st2common`` Python package so it's fully self sustaining and can be used in a\n  standalone manner. (improvement) #3803\n* Refactor Python action runner so it only depends on ``st2common`` Python package (previously it\n  also depended on ``st2actions``) and can be used in a standalone mode. Previously pack config and\n  and some other parameters were retrieved inside the Python process wrapper, but now they are\n  retrieved inside the runner container and passed to the runner. This also makes it easier to add\n  support for pack configs to other runners in the future. (improvement) #3803\n* Update various Python dependencies to the latest stable versions (kombu, amqp, apscheduler,\n  gitpython, pymongo, stevedore, paramiko, prompt-toolkit, flex). #3830\n* Mask values in an Inquiry response displayed to the user that were marked as \"secret\" in the\n  inquiry's response schema. #3825\n* Real-time action output streaming is now enabled by default. For more information on this\n  feature, please refer to the documentation - https://docs.stackstorm.com/latest/reference/action_output_streaming.html.\n  You can disable this functionality by setting ``actionrunner.stream_output`` config option in\n  ``st2.conf`` to ``False`` and restart the services (``sudo st2ctl restart``).\n\nFixed\n~~~~~\n\n* Fully fix performance regressions for short Python runner actions introduced in the past and\n  partially fixed in #3809. (bug fix) #3803\n* Fix 'NameError: name 'cmd' is not defined' error when using ``linux.service`` with CentOS systems.\n  #3843. Contributed by @shkadov\n* Fix bugs with newlines in execution formatter (client) (bug fix) #3872\n* Fixed ``st2ctl status`` to use better match when checking running process status. #3920\n* Removed invalid ``st2ctl`` option to re-open Mistral log files. #3920\n* Update garbage collection service and ``st2-purge-executions`` CLI tool and make deletion more\n  efficient. Previously we incorrectly loaded all the execution fields in memory, but there was no\n  need for that and now we only retrieve and load id which is the only field we need. #3936\n\n  Reported by @kevin-vh.\n\n2.5.1 - December 14, 2017\n-------------------------\n\nAdded\n~~~~~\n\n* Add new ``log_level`` runner parameter to Python runner. With this parameter, user can control\n  which log messages generated by Python runner actions are output to action ``stderr``. For\n  backward compatibility reasons it defaults to ``debug``.\n  This functionality comes handy in situations when an action depends on an external library which\n  logs a lot of information under ``debug``, but you only want to see messages with log level\n  ``error`` or higher (or similar). (new feature) #3824\n* Add stevedore related metadata to Python package setup.py files for runner packages. This way\n  runners can be installed using pip and dynamically enumerated and loaded using stevedore and\n  corresponding helper functions.\n\n  All runners are now also fully fledged Python packages (previously they were single module\n  Python packages which caused various install and distribution related issues when installing\n  them via pip) (new feature)\n* Add new ``search`` rule criteria comparison operator. Please refer to the documentation for\n  usage. (new feature) #3833\n\n  Contributed by @ahubl-mz.\n* Now a more user-friendly error message is thrown if a cycle is found inside the Jinja template\n  string (e.g. when parameter / variable references itself). (improvement) #3908\n* Jinja templates in default parameter values now render as live parameters, if no \"real\" live\n  parameter was provided. This allows the template to render pre-schema validation, resulting\n  in the intended value type. (improvement) #3892\n\nChanged\n~~~~~~~\n\n* Update the output of ``st2 execution {run,get}`` CLI command to colorize the value of the\n  ``status`` attribute (green for ``succeeded``, red for ``failed``, etc. aka the same as for the\n  output of ``st2 execution list`` command). (improvement) #3810\n\n  Contributed by Nick Maludy (Encore Technologies).\n* Update log messages in the datastore service to correctly use ``DEBUG`` log level instead of\n  ``AUDIT``. #3845\n* Add the ability of ``st2 key load`` to load keys from both JSON and YAML files. Files can now\n  contain a single KeyValuePair, or an array of KeyValuePairs. (improvement) #3815\n* Add the ability of ``st2 key load`` to load non-string values (objects, arrays, integers,\n  booleans) and convert them to JSON before going into the datastore, this conversion requires the\n  user passing in the ``-c/--convert`` flag. (improvement) #3815\n* Update ``st2 key load`` to load all properties of a key/value pair, now secret values can be\n  loaded. (improvement) #3815\n\n  Contributed by Nick Maludy (Encore Technologies).\n\nFixed\n~~~~~\n\n* Fix log messages generated by Python runner actions to include the correct action class name.\n  Previously they always incorrectly used \"ABCMeta\" instead of the actual action class name.\n  (bug fix) #3824\n* Fix ``st2 execution tail [last]`` CLI command so it doesn't throw an exception if there are no\n  executions in the database. (bug fix) #3760 #3802\n* Fix edge case for workflows stuck in running state. When Mistral receives a connection error from\n  the st2 API on requesting action execution, there's a duplicate action execution stuck in\n  requested state. This leads to the st2resultstracker assuming the workflow is still running.\n* Fix a regression and a bug with no API validation being performed and API returning 500 instead\n  of 400 status code if user didn't include any request payload (body) when hitting POST and PUT\n  API endpoints where body is mandatory. (bug fix) #3864\n* Fix a bug in Python runner which would cause action log messages to be duplicated in action\n  stderr output when utilizing action service / datastore service inside actions. (bug fix)\n* Fix performance issue on the CLI when formatting the output as JSON or YAML. (bug fix) #3697\n\n  Contributed by Nick Maludy (Encore Technologies).\n\n2.5.0 - October 25, 2017\n------------------------\n\nAdded\n~~~~~\n\n* Add new feature which allows runner action output (stdout and stderr) to be streamed\n  and consumed in real-time by using one of the following approaches:\n\n  - ``/v1/executions/<execution id>/output[?type=stdout/stderr]`` API endpoint.\n  - ``/v1/stream/`` stream endpoint and listening for ``st2.execution.stdout__create`` and\n    ``st2.execution.output__create`` ``/v1/stream`` stream API endpoint events.\n  - ``st2 execution tail <execution id> [--type=stdout/stderr]`` CLI command (underneath it uses\n    stream API endpoint).\n\n  Right now this functionality is available for the following runners:\n\n  - local command runner\n  - local script runner\n  - remote command runner\n  - remote script runner\n  - python runner\n\n  Note: This feature is still experimental and it's disabled by default (opt-in). To enable it,\n  set ``actionrunner.stream_output`` config option to ``True``.\n\n  (new feature) #2175 #3657 #3729\n* Update ``st2 role-assignment list`` RBAC CLI command to include information about where a\n  particular assignment comes from (from which local assignment or mapping file). (improvement)\n  #3763\n* Add support for overlapping RBAC role assignments for assignments via remote LDAP group to\n  StackStorm role mappings. This means that the same role can now be granted via multiple RBAC\n  mapping files.\n  #3763\n* Add new Jinja filters ``from_json_string``, ``from_yaml_string``, and ``jsonpath_query``.\n  #3763\n* Add new \"Inquiry\" capability, which adds ability to \"ask a question\", usually in a workflow.\n  Create a new runner type: \"inquirer\" to support this, as well as new API endpoints and\n  client commands for interacting with Inquiries\n\n  Contributed by mierdin. #3653\n* Added two new rule operators, ``inside`` and ``ninside`` which allow for the reverse intent of\n  the ``contains`` and ``ncontains`` operators. #3781\n\n  Contributed by @lampwins.\n* Allow user to use more expressive regular expressions inside action alias format string by\n  allowing them to specify start (``^``) and end (``$``) anchors. Previously, those anchors were\n  automatically added at the beginning and end of the alias format string. Now they are only added\n  if a format string doesn't already contain them. #3789\n\n  Contributed by @ahubl-mz.\n* Add new ``POST /v1/aliasexecution/match_and_execute`` API endpoint which allows user to\n  schedule an execution based on a command string if a matching alias is found in the database.\n\n  This API endpoint is meant to be used with chat bot plugins. It allows them to be simple thin\n  wrappers around this API endpoint which send each chat line to this API endpoint and handle the\n  response. #3773\n* Add several improvements to the installation scripts: They support using proxy servers.\n  ``~stanley`` no longer has to be ``/home/stanley``. In addition to the on-screen display, the\n  output from the installation script is now logged to a file beginning with ``st2-install`` under\n  ``/var/log/st2/``. Furthermore, the script handles re-runs better, although it's\n  not fully idempotent yet. More improvements are expected in the near future.\n  st2-packages: #505, #506, #507, #508, #509, #510, #512, #517.\n\nFixed\n~~~~~\n\n* Fix a bug where sensor watch queues were not deleted after sensor container process was shut\n  down. This resulted in spurious queues left behind. This should not have caused performance\n  impact but just messes with rabbitmqadmin output and maybe tedious for operators. (bug fix) #3628\n\n  Reported by Igor.\n* Make sure all the temporary RabbitMQ queues used by the stream service are deleted once the\n  connection to RabbitMQ is closed. Those queues are temporary and unique in nature and new ones\n  are created on each service start-up so we need to make sure to correctly clean up old queues.\n\n  #3746\n* Fix cancellation of subworkflow and subchain. Cancel of Mistral workflow or Action Chain is\n  cascaded down to subworkflows appropriately. Cancel from tasks in the workflow or chain is\n  cascaded up to the parent. (bug fix)\n* Fix delays in st2resultstracker on querying workflow status from Mistral. Make sleep time for\n  empty queue and no workers configurable. Reduce the default sleep times to 5 seconds. StackStorm\n  instances that handle more workflows should consider increasing the query interval for better\n  CPU utilization.\n* Fix missing type for the parameters with enum in the core st2 packs.(bug fix) #3737\n\n  Reported by Nick Maludy.\n* Add missing ``-h`` / ``--help`` CLI flag to the following execution CLI commands: cancel, pause,\n  resume. (bug fix) #3750\n* Fix execution cancel and pause CLI commands and make id a required argument. (bug fix) #3750\n* Fix ``st2 role-assignment list`` CLI command and allow ``--user``, ``--remote`` and ``--role``\n  arguments to be used together. Previously they were mutually exclusive so it wasn't possible to\n  use them together. (bug fix) #3763\n* Update default event name whitelist for ``/v1/stream`` API endpoint and make sure\n  ``st2.announcement__errbot`` and other event names starting with ``st2.announcement__*`` prefix\n  are not filtered out. #3769 (bug fix)\n\n  Reported by Carlos.\n* Fix action-alias execute response to show execution id and matching action-alias #3231 (bug fix)\n  Reported by Carlos.\n* Fix ``st2 apikey load`` command to update an existing entry if items in input file contain ``id``\n  attribute and item already exists on the server. This way the behavior is consistent with\n  ``st2 key load`` command and the command is idempotent if each item contains ``id`` attribute.\n  #3748 #3786\n\n  Reported by Christopher Baklid.\n* Don't log MongoDB database password if user specifies URI for ``database.db_host`` config\n  parameter and that URI also includes a password. Default and a common scenario is specifying\n  password as a separate ``database.password`` config parameter. #3797\n\n  Reported by Igor Cherkaev.\n* Fix ``POST /v1/actionalias/match`` API endpoint to correctly return a dictionary instead of an\n  array. We had a correct OpenAPI definition for the response, but the code incorrectly returned\n  an array instead of a dictionary.\n\n  Note: This is a breaking change so if your code utilizes this API endpoint you need to update\n  to treat response as a dictionary and not as an array with a single item. #377\n* Partially fix performance overhead and regression for short and simple Python runner actions.\n  Full / complete fix will be included in v2.6.0. #3809\n\nChanged\n~~~~~~~\n\n* Minor language and style tidy up of help strings and error messages. #3782\n\n2.4.1 - September 12, 2017\n--------------------------\n\nFixed\n~~~~~\n\n* Fix a bug with ``/v1/packs/install`` and ``/v1/packs/uninstall`` API endpoints incorrectly using\n  system user for scheduled pack install and pack uninstall executions instead of the user which\n  performed the API operation.(bug fix) #3693 #3696\n\n  Reported by theuiz.\n* Fix mistral callback failure when result contains unicode. (bug fix)\n* Fix cancellation of delayed action execution for tasks in workflow. (bug fix)\n* Fix timeout of mistral shutdown in systemd service. The fix is done upstream.\n  https://review.openstack.org/#/c/499853/ (bug fix)\n* Fix ``st2ctl clean`` not using database connection information from config.\n  This now uses the new ``st2-cleanup-db`` command. (bug fix) #3659\n\n  Contributed by Nick Maludy (Encore Technologies).\n\nChanged\n~~~~~~~\n\n* Update ``st2`` CLI command to print a more user-friendly usage / help string if no arguments are\n  passed to the CLI. (improvement) #3710\n* Allow user to specify multiple values for a parameter of type array of dicts when using\n  ``st2 run`` CLI command. #3670\n\n  Contributed by Hiroyasu OHYAMA.\n* Added new command ``st2-cleanup-db`` that drops the current StackStorm MongoDB database. #3659\n\n  Contributed by Nick Maludy (Encore Technologies).\n\n2.4.0 - August 23, 2017\n-----------------------\n\nAdded\n~~~~~\n\n* Add sample passive sensor at ``contrib/examples/sensors/echo_flask_app``. (improvement) #3667\n* Add pack config into action context. This is made available under the ``config_context`` key.\n  #3183\n* Add limit/``-n`` flag and pagination note(stderr) in the CLI for ``st2 key list``.\n  Default limit is 50. #3641\n* Implement pause and resume for Mistral workflow and Action Chain. Pause and resume will cascade\n  down to subworkflows and/or subchains. Pause from a subworkflow or subchain will cascade up to\n  the parent workflow. (new feature)\n* Add pack index endpoint. It will make a request for every index defined in st2.conf and return\n  the combined list of available packs.\n* Added a new field ``timestamp_f`` to the GELF logging formatter that represents\n  the time of the logging even in fractional time (resolution is dependent on your\n  system). This allows adjacent logging events to be distinguished more accurately\n  by the time they occurred.\n  Contributed by Nick Maludy (Encore Technologies) #3362\n* Require new ``STREAM_VIEW`` RBAC permission type to be able to view ``/v1/stream`` stream API\n  endpoint. (improvement) #3676\n* Add new ``?events``, ``?action_refs`` and ``?execution_ids`` query params to ``/v1/stream/``\n  API endpoint. These query parameters allow users to filter out which events to receive based\n  on the event type, action ref and execution id. By default, when no filters are provided, all\n  events are returned. (new feature) #3677\n* Show count of pack content (actions, sensors, triggers, rules and aliases) to be registered\n  before the ``st2 pack install`` so that the delay in install is not mistaken as no response\n  or hanging command. (improvement) #3586 #3675\n* Allow users to specify value for \"array of objects\" parameter type using a simple notation\n  when using the ``st2 run`` CLI command. (improvement) #3646 #3670\n\n  Contributed by Hiroyasu OHYAMA.\n* Copy nearly all existing Jinja filters and make them available in both Jinja and YAQL within\n  Mistral workflows (https://github.com/StackStorm/st2mistral/pull/30). Modify st2kv default\n  behavior (BREAKING CHANGE) to not decrypt ciphertext in datastore by default (now explicitly\n  enabled via optional parameter).\n\n  Contributed by mierdin. #3565\n* Add ``regex_substring`` Jinja filter for searching for a pattern in a provided string and\n  returning the result. (improvement)\n\n  Contributed by mierdin. #3482\n\nChanged\n~~~~~~~\n\n* Rename ST2 action runner cancel queue from ``st2.actionrunner.canel``\n  to ``st2.actionrunner.cancel``. (improvement) #3247\n* Install scripts and documentation have been updated to install MongoDB 3.4 by default (previously\n  3.2 was installed by default). If you want to upgrade an existing installation, please follow\n  the official instructions at https://docs.mongodb.com/v3.4/release-notes/3.4-upgrade-standalone/.\n  (improvement)\n* Update garbage collector service to delete corresponding stdout and stderr objects which belong\n  to executions which are to be deleted. #2175 #3657\n\nRemoved\n~~~~~~~\n\n* Support for pack ``config.yaml`` has been removed. Pack configuration should use the new\n  style, at ``/opt/stackstorm/configs/<pack>.yaml``. Packs containing ``config.yaml`` will generate\n  a fatal ERROR on pack registration.\n\nFixed\n~~~~~\n\n* Fix retrying in message bus exchange registration. (bug fix) #3635 #3638\n\n  Reported by John Arnold.\n* Fix message bus related race condition which could, under some rare scenarios, cause first\n  published message to be ignored because there were no consumers for that particular queue yet.\n  This could happen in a scenario when API service came online and served a request before action\n  runner service came online.\n\n  This also fixes an issue with Redis kombu backend not working. (bug fix) #3635 #3639 #3648\n* Fix logrotate configuration to delete stale compressed st2actionrunner logs #3647\n* Fix trace list API endpoint sorting by ``start_timestamp``, using ``?sort_desc=True|False`` query\n  parameters and by passing ``--sort=asc|desc`` parameter to the ``st2 trace list`` CLI command.\n  Descending order by default.(bug fix) #3237 #3665\n* Fix pack index health endpoint. It now points to the right controller. #3672\n* Fix 'pack register content' failures appearing on some slower systems by lifting action timeout.\n  #3685\n\n2.3.2 - July 28, 2017\n---------------------\n\nAdded\n~~~~~\n\n* Add test coverage and test timing capabilities to ``st2-run-pack-tests``.\n  The ``-c`` option enables test coverage and the ``-t`` option enables test timings.\n  These capabilities have also been enabled in the ci pipeline for packs in the exchange.\n\n  Contributed by Nick Maludy. #3508\n* Add ability to explicitly set ``stream_url`` in st2client. (improvement) #3432\n* Add support for handling arrays of dictionaries to ``st2 config`` CLI command. (improvement)\n  #3594\n\n  Contributed by Hiroyasu OHYAMA.\n\nChanged\n~~~~~~~\n\n* Update ``st2`` CLI so it also displays \"there are more results\" note when ``-n`` flag is\n  used and there are more items available. (improvement) #3552\n\nFixed\n~~~~~\n\n* Fix st2client to display unicode characters in pack content description. (bug-fix) #3511\n* Don't automatically append ``.git`` suffix to repo URIs passed to ``packs.download`` action.\n  This fixes a bug and now action also works with repo urls which don't contain ``.git`` suffix.\n  (bug fix)\n\n  Contributed by carbineneutral. #3534 #3544\n* st2 pack commands now work when StackStorm servers are behind a HTTP/HTTPS proxy. You can set\n  ``http_proxy`` or ``https_proxy`` environment variables for ``st2api`` and ``st2actionrunner``\n  processes and pack commands will work with proxy. Refer to documentation for details on\n  proxy configuration. (bug-fix) #3137\n* Fix API validation regression so all input data sent to some POST and PUT API endpoints is\n  correctly validated. (bug fix) #3580\n* Fix an API bug and allow users to create rules which reference actions which don't yet exist in\n  the system when RBAC is enabled and user doesn't have system admin permission. (bug fix)\n  #3572 #3573\n\n  Reported by sibirajal.\n* Add a check to make sure action exists in the POST of the action execution API. (bug fix)\n* Fix api key generation, to use system user, when auth is disabled. (bug fix) #3578 #3593\n* Fix invocation of Mistral workflow from Action Chain with jinja in params. (bug fix) #3440\n* Fix st2client API bug, a backward incompatible change in ``query()`` method, introduced in note\n  implementation (#3514) in 2.3.1. The ``query()`` method is now backward compatible (pre 2.3) and\n  ``query_with_count()`` method is used for results pagination and note. #3616\n* Fix logrotate script so that it no longer prints the ``st2ctl`` PID status to stdout\n  for each file that it rotates. Also, it will no longer print an error if\n  ``/var/log/st2/st2web.log`` is missing.\n\n  Contributed by Nick Maludy. #3633\n\n2.3.1 - July 07, 2017\n---------------------\n\nAdded\n~~~~~\n\n* Add support for ``passphrase`` parameter to ``remote-shell-script`` runner and as such, support\n  for password protected SSH key files. (improvement)\n\n  Reported by Sibiraja L, Nick Maludy.\n* Add ``json_escape`` Jinja filter for escaping JSON strings. (improvement)\n\n  Contributed by mierdin. #3480\n* Print a note to stderr if there are more entries / results on the server side which are displayed\n  to the user for the following ``list`` CLI commands: ``rule``, ``execution``,\n  ``rule-enforcment``, ``trace`` and ``trigger-instance``.\n  Default limit is 50. (improvement)\n\n  Reported by Eugen C. #3488\n\nChanged\n~~~~~~~\n\n* Update ``st2 run`` / ``st2 execution run`` command to display result of workflow actions when\n  they finish. In the workflow case, result of the last task (action) of the workflow is used.\n  (improvement) #3481\n* Update Python runner so it mimics behavior from StackStorm pre 1.6 and returns action result as\n  is (serialized as string) in case we are unable to serialize action result because it contains\n  non-simple types (e.g. class instances) which can't be serialized.\n\n  In v1.6 we introduced a change when in such instances, we simply returned ``None`` as result\n  and didn't log anything which was confusing. (improvement) #3489\n\n  Reported by Anthony Shaw.\n* Add missing pagination support to ``/v1/apikeys`` API endpoint. (improvement) #3486\n* Update action-chain runner so a default value for ``display_published`` runner parameter is\n  ``True``. This way it's consistent with Mistral runner behavior and intermediate variables\n  published inside action-chain workflow are stored and displayed by default. #3518 #3519\n\n  Reported by Jacob Floyd.\n* Reduce API service (``st2api``) log clutter and log whole API response (API controller method\n  return value / response body) under ``DEBUG`` log level instead of ``INFO``. (improvement) #3539\n\n  Reported by Sibiraja L.\n* Enforce validation on ``position`` parameter for action parameters. If position values are not\n  sequential or not unique, action registration will now fail. (bug-fix)\n  (improvement) #3317 #3474\n\nDeprecated\n~~~~~~~~~~\n\n* Deprecate ``results_tracker`` config group and move configuration variables to ``resultstracker``\n  group instead. If you have ``results_tracker`` config group in the config, it is recommended\n  to switch to ``resultstracker`` instead. (bug-fix) #3500\n\nFixed\n~~~~~\n\n* Fix ``?name`` query param filter in ``/v1/actionalias`` API endpoint. (bug fix) #3503\n* Notifier now consumes ``ActionExecution`` queue as opposed to ``LiveAction`` queue. With this\n  change, the Jinja templates used in notify messages that refer to keys in ``ActionExecution``\n  resolve reliably. Previously, there was a race condition in which a ``LiveAction`` would have\n  been updated but ``ActionExecution`` was not and therefore, the jinja templates weren't reliably\n  resolved. (bug-fix) #3487 #3496\n\n  Reported by Chris Katzmann, Nick Maludy.\n* Update config loader so it correctly handles config schema default values which are falsey\n  (``False``, ``None``, ``0``, etc.) (bug-fix) #3504 #3531\n\n  Reported by Simas Čepaitis.\n* Fix ``st2ctl register`` failure to register rules in some race conditions.\n  ``st2-register-content`` will now register internal trigger types by default. (bug-fix) #3542\n* Correctly use service token TTL when generating temporary token for datastore service. This\n  fixes a bug and allows user to set TTL value for non service tokens to less than 24 hours.\n  (bug fix) #3523 #3524\n\n  Reported by theuiz.\n\n2.3.0 - June 19, 2017\n---------------------\n\nAdded\n~~~~~\n\n* Introduce new ``CAPABILITIES`` constant on auth backend classes. With this constant, auth\n  backends can advertise functionality they support (e.g. authenticate a user, retrieve information\n  about a particular user, retrieve a list of groups a particular user is a member of).\n  (new feature)\n* Add support for automatic RBAC role assignment based on the remote auth backend groups user is a\n  member of (e.g. LDAP groups) and mappings defined in ``/opt/stackstorm/rbac/mappings`` directory.\n\n  Note: This functionality is currently implemented for enterprise LDAP auth backend and only\n  available in enterprise edition.\n  (new feature)\n* Allow user to specify a custom list of attribute names which are masked in the log messages by\n  setting ``log.mask_secrets_blacklist`` config option. (improvement)\n* Add webhook payload to the Jinja render context when rendering Jinja variable inside rule\n  criteria section.\n* Implement RBAC for traces API endpoints. (improvement)\n* Implement RBAC for ``API_KEY_CREATE`` permission type. (improvement)\n* Implement RBAC for timers API endpoints. (improvement)\n* Implement RBAC for webhooks get all and get one API endpoint. (improvement)\n* Implement RBAC for policy types and policies get all and get one API endpoint. (improvement)\n* Add new ``/v1/rbac/role_assignments`` API endpoint for retrieving user role assignment\n  information. (new feature)\n* Add CLI commands for listing RBAC roles:\n\n  * ``st2 role list [--system]``\n  * ``st2 role get <role id or name>``\n* Add CLI commands for listing RBAC user role assignments:\n\n  * ``st2 role-assignment list [--role=<role name>] [--user=<username>]``\n  * ``st2 role-assignment get <role assignment id>``\n* Add the following new actions to ``chatops`` pack:\n\n  * ``chatops.match``\n  * ``chatops.match_and_execute``\n  * ``chatops.run``\n\n  #3425 [Anthony Shaw]\n* Add new ``examples.forloop_chain`` action-chain workflow to the examples pack which demonstrates\n  how to iterate over multiple pages inside a workflow. #3328\n  [Carles Figuerola]\n* Add new ``core.uuid`` action for generating type 1 and type 4 UUIDs. [John Anderson] #3414\n\nChanged\n~~~~~~~\n\n* Refactor the action execution asynchronous callback functionality into the runner plugin\n  architecture. (improvement)\n* Linux file watch sensor is now disabled by default. To enable it, set ``enabled: true`` in\n  ``/opt/stackstorm/packs/linux/sensors/file_watch_sensor.yaml``\n* Update the code so user can specify arbitrary default TTL for access tokens in ``st2.conf`` and\n  all the StackStorm services which rely on access tokens still work.\n\n  Previously, the lowest TTL user could specify for all the services to still work was 24 hours.\n  This has been fixed and the default TTL specified in the config now only affects user access\n  tokens and services use special service access tokens with no max TTL limit. (bug fix)\n\n  Reported by Jiang Wei. #3314 #3315\n* Update ``/executions/views/filters`` API endpoint so it excludes null / None from filter values\n  for fields where ``null`` is not a valid field value. (improvement)\n\n  Contributed by Cody A. Ray. #3193\n* Require ``ACTION_VIEW`` permission type to be able to access entry_point and parameters actions\n  view controller. (improvement)\n* Update ``/v1/rbac/permission_types`` and ``/v1/rbac/permission_types/<resource type>`` API\n  endpoint to return a dictionary which also includes a description for each available\n  permission type. (improvement)\n* Require ``EXECUTION_VIEWS_FILTERS_LIST`` RBAC permission type to be able to access\n  ``/executions/views/filters`` API endpoint. (improvement)\n* Add webhook payload to the Jinja render context when rendering Jinja variable inside rule criteria section\n* Switch file_watch_sensor in Linux pack to use trigger type with parameters. Now you can add a\n  rule with ``file_path`` and sensor will pick up the ``file_path`` from the rule. A sample rule\n  is provided in ``contrib/examples/rules/sample_rule_file_watch.yaml``. (improvement)\n* Cancel actions that are Mistral workflow when the parent workflow is cancelled. (improvement)\n* Upgrade various internal Python library dependencies to the latest stable versions (pyyaml,\n  requests, appscheduler, gitpython, paramiko, mongoengine, tooz).\n* Update ``/v1/rbac/roles`` API endpoint so it includes corresponding permission grant objects.\n  Previously it only included permission grant ids. (improvement)\n* When RBAC is enabled and action is scheduled (ran) through the API, include ``rbac`` dictionary\n  with ``user`` and ``roles`` ``action_context`` attribute. (improvement)\n* Make the query interval to third party workflow systems (including mistral) a configurable\n  value. You can now set ``query_interval`` in ``[results_tracker]`` section in ``/etc/st2/st2.conf``.\n  With this, the default query interval is set to 20s as opposed to 0.1s which was rather aggressive\n  and could cause CPU churn when there is a large number of outstanding workflows. (improvement)\n* Let ``st2 pack install`` register all available content in pack by default to be consistent with\n  ``st2 pack register``. (improvement) #3452\n* The ``dest_server`` parameter has been removed from the ``linux.scp`` action. Going forward simply\n  specify the server as part of the ``source`` and / or ``destination`` arguments. (improvement)\n  #3335 #3463 [Nick Maludy]\n* Add missing database indexes which should speed up various queries on production deployments with\n  large datasets. (improvement)\n* Use a default value for a config item from config schema even if that config item is not required\n  (``required: false``). (improvement)\n\n  Reported by nmlaudy. #3468 #3469\n* Removing empty ``config.yaml`` for packs pack so warning isn't thrown by default now that deprecation\n  warning is in place. (improvement)\n\nRemoved\n~~~~~~~\n\n* Drop support for invalid semver versions strings (e.g. ``2.0``) in pack.yaml pack metadata. Only\n  full semver version strings are supported, e.g. ``2.1.1``. This was originally deprecated in\n  v2.1.0.\n\nDeprecated\n~~~~~~~~~~\n\n* Packs containing ``config.yaml`` will now generate a WARNING log on pack registration. Support for\n  ``config.yaml`` will be removed in StackStorm 2.4. Migrate your pack configurations now.\n\nFixed\n~~~~~\n\n* Update st2rulesengine to exit non-0 on failure (bug fix) #3394 [Andrew Regan]\n* Fix a bug where trigger parameters and payloads were being validated regardless of the relevant settings\n  in the configuration (``system.validate_trigger_payload``, ``system.validate_trigger_parameters``). (bug fix)\n* Fix ``system=True`` filter in the ``/v1/rbac/roles`` API endpoint so it works correctly. (bug fix)\n* Fix a bug where keyvalue objects weren't properly cast to numeric types. (bug fix)\n* When action worker is being shutdown and action executions are being abandoned, invoke post run\n  on the action executions to ensure operations such as callback is performed. (bug fix)\n* Fix action chain runner workflows so variables (vars) and parameter values\n  support non-ascii (unicode) characters. (bug fix)\n* Fix a bug in query base module when outstanding queries to mistral or other workflow engines\n  could cause a tight loop without cooperative yield leading to 100% CPU usage by st2resultstracker\n  process. (bug-fix)\n* Ignore unicode related encoding errors which could occur in some circumstances when\n  ``packs.setup_virtualenv`` fails due to a missing dependency or similar. (improvement, bug fix)\n  #3337 [Sean Reifschneider]\n* Update ``st2-apply-rbac-definitions`` so it also removes assignments for users which don't exist\n  in the database. (improvement, bug fix)\n* Fix a bug where action runner throws KeyError on abandoning action executions\n  during process shutdown. (bug fix)\n* Fix URL parsing bug where percent encoded URLs aren't decoded properly (bug fix)\n* The API endpoint for searching or showing packs has been updated to return an empty list\n  instead of ``None`` when the pack was not found in the index. (bug fix)\n\nSecurity\n~~~~~~~~\n\n* Make sure all the role assignments for a particular user are correctly deleted from the database\n  after deleting an assignment file from ``/opt/stackstorm/rbac/assignments`` directory and running\n  ``st2-apply-rbac-definitions`` tool. (bug fix)\n\n\n2.2.1 - April 3, 2017\n---------------------\n\nAdded\n~~~~~\n\n* Allow user to specify which branch of ``st2tests`` repository to use by passing ``-b`` option to\n  ``st2-self-check`` script. (improvement)\n* Update ``tooz`` library to the latest version (v1.15.0). Using the latest version means\n  StackStorm now also supports using ``consul``, ``etcd`` and other new backends supported by\n  tooz for coordination. (improvement)\n\nFixed\n~~~~~\n\n* Fix ``st2ctl reload`` command so it preserves exit code from ``st2-register-content`` script and\n  correctly fails on failure by default.\n* Fix base action alias test class (``BaseActionAliasTestCase``) so it also works if the local pack\n  directory name doesn't match the pack name (this might be the case with new pack management\n  during development where local git repository directory name doesn't match pack name) (bug fix)\n* Fix a bug with default values from pack config schema not being passed via config to Python\n  runner actions and sensors if pack didn't contain a config file in ``/opt/stackstorm/configs``\n  directory. (bug fix)\n\n  Reported by Jon Middleton.\n* Make various improvements and changes to ``st2-run-pack-tests`` script so it works out of the box\n  on servers where StackStorm has been installed using packages. (improvement)\n* Fix a bug with authentication middleware not working correctly when supplying credentials in an\n  Authorization header using basic auth format when password contained a colon (``:``).\n\n  Note: Usernames with colon are still not supported. (bug fix)\n\n  Contributed by Carlos.\n* Update ``st2-run-pack-tests`` script so it doesn't try to install global pack test dependencies\n  (mock, unittest2, nose) when running in an environment where those dependencies are already\n  available.\n* Make sure remote command and script runner correctly close SSH connections after the action\n  execution has completed. (bug fix)\n\n  Reported by Nagy Krisztián.\n* Fix a bug with pack configs API endpoint (``PUT /v1/configs/``) not working when RBAC was\n  enabled. (bug fix)\n\n  Reported by efenian.\n* Fix concurrency related unit tests to support upgrade of the tooz library. (bug fix)\n* Fix a bug with config schema validation not being performed upon registration which could cause\n  bad or empty config schema to end up in the system. (bug fix)\n\nSecurity\n~~~~~~~~\n\n* Removed support for medium-strength ciphers from default nginx configuration (#3244)\n* Various security related improvements in the enterprise LDAP auth backend. (improvement,\n  bug fix)\n\n\n2.2.0 - February 27, 2017\n-------------------------\n\nAdded\n~~~~~\n\n* Use the newly introduced CANCELLED state in mistral for workflow cancellation. Currently, st2\n  put the workflow in a PAUSED state in mistral. (improvement)\n* Add support for evaluating Jinja expressions in mistral workflow definition where yaql\n  expressions are typically accepted. (improvement)\n* Update the dependencies and the code base so we now also support MongoDB 3.4. Officially\n  supported MongoDB versions are now MongoDB 3.2 and 3.4. Currently default version installed by\n  the installer script still is 3.2. (improvement)\n* Introduce validation of trigger parameters when creating a rule for non-system (user-defined)\n  trigger types.\n\n  Validation is only performed if ``system.validate_trigger_parameters`` config option is enabled\n  (it's disabled by default) and if trigger object defines ``parameters_schema`` attribute.\n\n  Contribution by Hiroyasu OHYAMA. #3094\n* Introduce validation of trigger payload for non-system and user-defined triggers which is\n  performed when dispatching a trigger inside a sensor and when sending a trigger via custom\n  webhook.\n\n  Validation is only performed if ``system.validate_trigger_payload`` config option is enabled\n  (it's disabled by default) and if trigger object defines ``payload_schema`` attribute.\n\n  Contribution by Hiroyasu OHYAMA. #3094\n* Add support for ``st2 login`` and ``st2 whoami`` commands. These add some additional functionality\n  beyond the existing ``st2 auth`` command and actually works with the local configuration so that\n  users do not have to.\n* Add support for complex rendering inside of array and object types. This allows the user to\n  nest Jinja variables in array and object types.\n* Add new ``-j`` flag to the ``st2-run-pack-tests`` script. When this flag is specified script will\n  just try to run the tests and it won't set up the virtual environment and install the\n  dependencies. This flag can be used when virtual environment for pack tests already exists and\n  when you know dependencies are already installed and up to date. (new feature)\n\nChanged\n~~~~~~~\n\n* Mistral fork is updated to match the master branch at OpenStack Mistral. (improvement)\n* Update Python runner to throw a more user-friendly exception in case action metadata file\n  references a script file which doesn't exist or which contains invalid syntax. (improvement)\n* Update ``st2auth`` service so it includes more context and throws a more user-friendly exception\n  when retrieving an auth backend instance fails. This makes it easier to debug and spot various\n  auth backend issues related to typos, misconfiguration and similar. (improvement)\n* Let querier plugin decide whether to delete state object on error. Mistral querier will\n  delete state object on workflow completion or when the workflow or task references no\n  longer exists. (improvement)`\n\nRemoved\n~~~~~~~\n\n* ``{{user.}}`` and ``{{system.}}`` notations to access user and system\n  scoped items from datastore are now unsupported. Use  ``{{st2kv.user.}}``\n  and ``{{st2kv.system.}}`` instead. Please update all your content (actions, rules and\n  workflows) to use the new notation. (improvement)\n\nFixed\n~~~~~\n\n* Fix returning a tuple from the Python runner so it also works correctly, even if action returns\n  a complex type (e.g. Python class instance) as a result. (bug fix)\n\n  Reported by skjbulcher #3133\n* Fix a bug with ``packs.download`` action and as such as ``pack install`` command not working with\n  git repositories which used a default branch which was not ``master``. (bug fix)\n* Fix a bug with not being able to apply some global permission types (permissions which are global\n  and not specific to a resource) such as pack install, pack remove, pack search, etc. to a role\n  using ``st2-apply-rbac-definitions``. (bug fix)\n\n* Fix ``/v1/packs/views/files/<pack ref or id>`` and\n  ``/v1/packs/views/file/<pack ref or id>/<file path>`` API endpoint so it\n  works correctly for packs where pack name is not equal to the pack ref. (bug fix)\n\n  Reported by skjbulcher #3128\n* Improve binary file detection and fix \"pack files\" API controller so it works correctly for\n  new-style packs which are also git repositories. (bug fix)\n* Fix cancellation specified in concurrency policies to cancel actions appropriately. Previously,\n  mistral workflow is orphaned and left in a running state. (bug fix)\n* If a retry policy is defined, action executions under the context of a workflow will not be\n  retried on timeout or failure. Previously, action execution will be retried but workflow is\n  terminated. (bug fix)\n* Fix how mistral client and resource managers are being used in the mistral runner. Authentication\n  has changed in the mistral client. Fix unit test accordingly. (bug fix)\n* Fix issue where passing a single integer member for an array parameter for an action would\n  cause a type mismatch in the API (bug fix)\n* Fix ``--config-file`` st2 CLI argument not correctly expanding the provided path if the path\n  contained a reference to the user home directory (``~``, e.g. ``~/.st2/config.ini``) (bug fix)\n* Fix action alias update API endpoint. (bug fix)\n* Fix a bug with ``--api-token`` / ``-t`` and other CLI option values not getting correctly\n  propagated to all the API calls issued in the ``st2 pack install``, ``st2 pack remove`` and\n  ``st2 pack config`` commands. (bug fix)\n\n\n2.1.1 - December 16, 2016\n-------------------------\n\nAdded\n~~~~~\n\n* ``core.http`` action now also supports HTTP basic auth and digest authentication by passing\n  ``username`` and ``password`` parameter to the action. (new feature)\n* After running ``st2 pack install`` CLI command display which packs have been installed.\n  (improvement)\n\nChanged\n~~~~~~~\n\n* Update ``/v1/packs/register`` API endpoint so it throws on failure (e.g. invalid pack or resource\n  metadata). This way the default behavior is consistent with default\n  ``st2ctl reload --register-all`` behavior.\n  If user doesn't want the API endpoint to fail on failure, they can pass\n  ``\"fail_on_failure\": false`` attribute in the request payload. (improvement)\n* Throw a more user-friendly exception when registering packs (``st2ctl reload``) if pack ref /\n  name is invalid. (improvement)\n* Update ``packs.load`` action to also register triggers by default. (improvement)\n\nFixed\n~~~~~\n\n* Fix ``GET /v1/packs/<pack ref or id>`` API endpoint - make sure pack object is correctly returned\n  when pack ref doesn't match pack name. Previously, 404 not found was thrown. (bug fix)\n* Update local action runner so it supports and works with non-ascii (unicode) parameter keys and\n  values. (bug fix)\n\n  Contribution by Hiroyasu OHYAMA. #3116\n* Update ``/v1/packs/register`` API endpoint so it registers resources in the correct order which\n  is the same as order used in ``st2-register-content`` script. (bug fix)\n\n\n2.1.0 - December 05, 2016\n-------------------------\n\nAdded\n~~~~~\n\n* New pack management:\n\n  - Add new ``stackstorm_version`` and ``system`` fields to the pack.yaml metadata file. Value of\n    the first field can contain a specific StackStorm version with which the pack is designed to\n    work with (e.g. ``>=1.6.0,<2.2.0`` or ``>2.0.0``). This field is checked when installing /\n    registering a pack and installation is aborted if pack doesn't support the currently running\n    StackStorm version. Second field can contain an object with optional system / OS level\n    dependencies. (new feature)\n  - Add new ``contributors`` field to the pack metadata file. This field can contain a list of\n    people who have contributed to the pack. The format is ``Name <email>``, e.g.\n    ``Tomaz Muraus <tomaz@stackstorm.com>`` (new feature)\n  - Add support for default values and dynamic config values for nested config objects.\n    (new feature, improvement)\n  - Add new ``st2-validate-pack-config`` tool for validating config file against a particular\n    config schema file. (new-feature)\n\n* Add new ``POST /v1/actionalias/match`` API endpoint which allows users to perform ChatOps action\n  alias matching server-side. This makes it easier to build and maintain StackStorm ChatOps\n  clients / adapters for various protocols and mediums. Clients can now be very thin wrappers\n  around this new API endpoint.\n\n  Also add two new corresponding CLI commands - ``st2 alias-execution match`` and\n  ``st2 alias-execution execute``. Contribution by Anthony Shaw. (new feature) #2895.\n* Adding ability to pass complex array types via CLI by first trying to\n  seralize the array as JSON and then falling back to comma separated array.\n* Add new ``core.pause`` action. This action behaves like sleep and can be used inside the action\n  chain or Mistral workflows where waiting / sleeping is desired before proceeding with a next\n  task. Contribution by Paul Mulvihill. (new feature) #2933.\n* Allow user to supply multiple resource ids using ``?id`` query parameter when filtering\n  \"get all\" API endpoint result set (e.g. ``?id=1,2,3,4``). This allows for a better client and\n  servers performance when user is polling and interested in multiple resources such as polling on\n  multiple action executions. (improvement)\n* Add support for ssh config file for ParamikoSSHrunner. Now ``ssh_config_file_path`` can be set\n  in st2 config and can be used to access remote hosts when ``use_ssh_config`` is set to\n  ``True``. However, to access remote hosts, action parameters like username and\n  password/private_key, if provided with action, will have precedence over the config file\n  entry for the host. #2941 #3032 #3058 [Eric Edgar] (improvement)\n\nChanged\n~~~~~~~\n\n* Improved pack validation - now when the packs are registered we check that:\n\n  - ``version`` attribute in the pack metadata file matches valid semver format (e.g\n    ``0.1.0``, ``2.0.0``, etc.)\n  - ``email`` attribute (if specified) contains a valid email address. (improvement)\n  - Only valid word characters (``a-z``, ``0-9`` and ``_``) used for action parameter\n    names. Previously, due to bug in the code, any character was allowed.\n\n  If validation fails, pack registration will fail. If you have an existing action or pack\n  definition which uses invalid characters, pack registration will fail. **You must update\n  your packs**.\n* For consistency with new pack name validation changes, sample ``hello-st2`` pack has been\n  renamed to ``hello_st2``.\n* Update ``packs.install`` action (``pack install`` command) to only load resources from the\n  packs which are being installed. Also update it and remove \"restart sensor container\" step from\n  the install workflow. This step hasn't been needed for a while now because sensor container\n  dynamically reads a list of available sensors from the database and starts the sub processes.\n  (improvement)\n* Improve API exception handling and make sure 400 status code is returned instead of 500 on\n  mongoengine field validation error. (improvement)\n* Throw a more user-friendly exception if rendering a dynamic configuration value inside the config\n  fails. (improvement)\n* Change st2api so that a full execution object is returned instead of an error message, when an\n  API client requests cancellation of an execution that is already canceled\n* Speed up short-lived Python runner actions by up to 70%. This way done by re-organizing and\n  re-factoring code to avoid expensive imports such as jsonschema, jinja2, kombu and mongoengine\n  in the places where those imports are not actually needed and by various other optimizations.\n  (improvement)\n* Improve performance of ``GET /executions/views/filters`` by creating additional indexes on\n  executions collection\n* Upgrade various internal Python library dependencies to the latest stable versions (gunicorn,\n  kombu, six, appscheduler, passlib, python-gnupg, semver, paramiko, python-keyczar, virtualenv).\n\nRemoved\n~~~~~~~\n\n* Remove ``packs.info`` action because ``.gitinfo`` file has been deprecated with the new pack\n  management approach. Now pack directories are actual checkouts of the corresponding pack git\n  repositories so this file is not needed anymore.\n\nFixed\n~~~~~\n\n* Fix ``packs.uninstall`` action so it also deletes ``configs`` and ``policies`` which belong to\n    the pack which is being uninstalled. (bug fix)\n* When a policy cancels a request due to concurrency, it leaves end_timestamp set to None which\n  the notifier expects to be a date. This causes an exception in \"isotime.format()\". A patch was\n  released that catches this exception, and populates payload['end_timestamp'] with the equivalent\n  of \"datetime.now()\" when the exception occurs.\n* Adding check for datastore Client expired tokens used in sensor container\n* Fix python action runner actions and make sure that modules from ``st2common/st2common/runners``\n  directory don't pollute ``PYTHONPATH`` for python runner actions. (bug fix)\n\n2.0.1 - September 30, 2016\n--------------------------\n\nAdded\n~~~~~\n\n* Allow users to specify sort order when listing traces using the API endpoint by specifying\n  ``?sort_desc=True|False`` query parameters and by passing ``--sort=asc|desc`` parameter to\n  the ``st2 trace list`` CLI command. (improvement)\n* Retry connecting to RabbitMQ on services start-up if connecting fails because\n  of an intermediate network error or similar. (improvements)\n* Allow jinja expressions ``{{st2kv.system.foo}}`` and ``{{st2kv.user.foo}}`` to access\n  datastore items from workflows, actions and rules. This is in addition to supporting\n  expressions ``{{system.foo}}`` and ``{{user.foo}}``.\n\nChanged\n~~~~~~~\n\n* Update traces list API endpoint and ``st2 trace list`` so the traces are sorted by\n  ``start_timestamp`` in descending order by default. This way it's consistent with executions\n  list and ``-n`` CLI parameter works as expected. (improvement)\n\nDeprecated\n~~~~~~~~~~\n\n* In subsequent releases, the expressions ``{{system.}}`` and ``{{user.}}`` for accessing\n  datastore items will be deprecated. It is recommended to switch to using\n  ``{{st2kv.system.}}`` and ``{{st2kv.user.}}`` for your content. (improvement)\n\nFixed\n~~~~~\n\n* Fix ``st2 execution get`` command so now ``--attr`` argument correctly works with child\n  properties of the ``result`` and ``trigger_instance`` dictionary (e.g. ``--attr\n  result.stdout result.stderr``). (bug fix)\n* Fix a bug with action default parameter values not supporting Jinja template\n  notation for parameters of type ``object``. (bug fix, improvement)\n* Fix ``--user`` / ``-u`` argument in the ``st2 key delete`` CLI command.\n\n\n2.0.0 - August 31, 2016\n-----------------------\n\nAdded\n~~~~~\n\n* Implement custom Jinja filter functions ``to_json_string``, ``to_yaml_string``,\n  ``to_human_time_from_seconds`` that can be used in actions and workflows. (improvement)\n* Default chatops message to include time taken to complete an execution. This uses\n  ``to_human_time_from_seconds`` function. (improvement)\n* Allow user to cancel multiple executions using a single invocation of ``st2 execution cancel``\n  command by passing multiple ids to the command -\n  ``st2 execution cancel <id 1> <id 2> <id n>`` (improvement)\n* We now execute --register-rules as part of st2ctl reload. PR raised by Vaishali:\n  https://github.com/StackStorm/st2/issues/2861#issuecomment-239275641\n* Update ``packs.uninstall`` command to print a warning message if any rules in the system\n  reference a trigger from a pack which is being uninstalled. (improvement)\n* Allow user to list and view rules using the API even if a rule in the database references a\n  non-existent trigger. This shouldn't happen during normal usage of StackStorm, but it makes it\n  easier for the user to clean up in case database ends up in a inconsistent state. (improvement)\n\nChanged\n~~~~~~~\n\n* Refactor Jinja filter functions into appropriate modules. (improvement)\n* Bump default timeout for ``packs.load`` command from ``60`` to ``100`` seconds. (improvement)\n* Upgrade pip and virtualenv libraries used by StackStorm pack virtual environments to the latest\n  versions (8.1.2 and 15.0.3).\n* Change Python runner action and sensor Python module loading so the module is still loaded even if\n  the module name clashes with another module which is already in ``PYTHONPATH``\n  (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug when jinja templates with filters (for example,\n  ``st2 run core.local cmd='echo {{\"1.6.0\" | version_bump_minor}}'``) in parameters wasn't rendered\n  correctly when executing actions. (bug-fix)\n* Fix validation of the action parameter ``type`` attribute provided in the YAML metadata.\n  Previously we allowed any string value, now only valid types (object, string, number,\n  integer, array, null) are allowed. (bug fix)\n* Fix disabling and enabling of a sensor through an API and CLI. (bug-fix)\n* Fix HTTP runner so it works correctly when body is provided with newer versions of requests\n  library (>= 2.11.0). (bug-fix) #2880\n\n  Contribution by Shu Sugimoto.\n\n1.6.0 - August 8, 2016\n----------------------\n\nAdded\n~~~~~\n\n* Allow user to specify an action which is performed on an execution (``delay``, ``cancel``) when a\n  concurrency policy is used and a defined threshold is reached. For backward compatibility,\n  ``delay`` is the default behavior, but now users can also specify ``cancel`` and an execution will\n  be canceled instead of delayed when a threshold is reached.\n* Add support for sorting execution list results, allowing access to oldest items. (improvement)\n* Allow administrator to configure maximum limit which can be specified using ``?limit``\n  query parameters when making API calls to get all / list endpoints. For backward compatibility\n  and safety reasons, the default value still is ``100``. (improvement)\n* Include a chatops alias sample in ``examples`` pack that shows how to use ``format`` option to\n  display chatops messages in custom formatted way. (improvement)\n* Include a field ``elapsed_seconds`` in execution API response for GET calls. The clients using\n  the API can now use ``elapsed_seconds`` without having to repeat computation. (improvement)\n* Implement custom YAQL function ``st2kv`` in Mistral to get key-value pair from StackStorm's\n  datastore. (new-feature)\n\nChanged\n~~~~~~~\n\n* Upgrade to pymongo 3.2.2 and mongoengine 0.10.6 so StackStorm now also supports and works with\n  MongoDB 3.x. (improvement)\n* Update action runner to use two internal green thread pools - one for regular (non-workflow) and\n  one for workflow actions. Both pool sizes are user-configurable. This should help increase the\n  throughput of a single action runner when the system is not over-utilized. It can also help\n  prevent deadlocks which may occur when using delay policies with action-chain workflows.\n  (improvement)\n* Update CLI commands to make sure that all of them support ``--api-key`` option. (bug-fix)\n* Update ``st2-register-content`` script to exit with non-zero on failure (e.g. invalid resource\n  metadata, etc.) by default. For backward compatibility reasons, ``--register-fail-on-failure``\n  flag was left there, but it now doesn't do anything since this is the default behavior. For ease\n  of migrations, users can revert to the old behavior by using new\n  ``--register-no-fail-on-failure`` flag. (improvement)\n* Allow Python runner actions to return execution status (success, failure) by returning a tuple\n  from the ``run()`` method. First item in the tuple is a flag indicating success (``True`` /\n  ``False``) and the second one is the result. Previously, user could only cause action to fail by\n  throwing an exception or exiting which didn't allow for a result to be returned. With this new\n  approach, user can now also return an optional result with a failure. (new feature)\n* Include testing for chatops ``format_execution_result`` python action. The tests cover various\n  action types. (improvement)\n* Update ``st2-register-content`` script so it validates new style configs in\n  ``/opt/stackstorm/configs/`` directory when using ``--register-configs`` flag if a pack contains\n  a config schema (``config.schema.yaml``). (improvement)\n\nFixed\n~~~~~\n\n* Make sure policies which are disabled are not applied. (bug fix)\n  Reported by Brian Martin.\n* Fix ``Internal Server Error`` when an undefined jinja variable is used in action alias ack field.\n  We now send a http status code ``201`` but also explicitly say we couldn't render the ``ack``\n  field. The ``ack`` is anyways a nice-to-have message which is not critical. Previously, we still\n  kicked off the execution but sent out ``Internal Server Error`` which might confuse the user\n  whether execution was kicked off or not. (bug-fix)\n\n\n1.5.1 - July 13, 2016\n---------------------\n\nAdded\n~~~~~\n\n* Add support for default values when a new pack configuration is used. Now if a default value\n  is specified for a required config item in the config schema and a value for that item is not\n  provided in the config, default value from config schema is used. (improvement)\n* Add support for posixGroup to the enterprise LDAP auth backend. (improvement, bug-fix)\n\nChanged\n~~~~~~~\n\n* Allow user to prevent execution parameter merging when re-running an execution by passing\n  ``?no_merge=true`` query parameter to the execution re-run API endpoint. (improvement)\n\nFixed\n~~~~~\n\n* Fix trigger registration when using st2-register-content script with ``--register-triggers``\n  flag. (bug-fix)\n* Fix an issue with CronTimer sometimes not firing due to TriggerInstance creation failure.\n  (bug-fix)\n  Reported by Cody A. Ray\n\n\n1.5.0 - June 24, 2016\n---------------------\n\nAdded\n~~~~~\n\n* TriggerInstances now have statuses to help track if a TriggerInstance has been processed,\n  is being processed or failed to process. This bring out some visibility into parts of the\n  TriggerInstance processing pipeline and can help identify missed events. (new-feature)\n* Allow user to enable service debug mode by setting ``system.debug`` config file option to\n  ``True``.\n  Note: This is an alternative to the existing ``--debug`` CLI flag which comes handy when running\n  API services under gunicorn. (improvement)\n* Add new API endpoint and corresponding CLI commands (``st2 runner disable <name>``,\n  ``st2 runner enable <name>``) which allows administrator to disable (and re-enable) a runner.\n  (new feature)\n* Add RBAC support for runner types API endpoints. (improvement)\n* Add ``get_fixture_content`` method to all the base pack resource test classes. This method\n  enforces fixture files location and allows user to load raw fixture content from a file on disk.\n  (new feature)\n  future, pack configs will be validated against the schema (if available). (new feature)\n* Add data model and API changes for supporting user scoped variables. (new-feature, experimental)\n* Add ``-y`` / ``--yaml`` flag to the CLI ``list`` and ``get`` commands. If this flag is provided,\n  command response will be formatted as YAML. (new feature)\n* Ability to migrate api keys to new installs. (new feature)\n* Introduce a new concept of pack config schemas. Each pack can now contain a\n  ``config.schema.yaml`` file. This file can contain an optional schema for the pack config.\n  Site-specific pack configuration is then stored outside the pack directory, in\n  ``/opt/stackstorm/configs/<pack name>.yaml``. Those files are similar to the existing pack\n  configs, but in addition to the static values they can also contain dynamic values. Dynamic value\n  is a value which contains a Jinja expression which is resolved to a datastore item during\n  run-time. (new feature)\n* Allow administrator user whose context will be used when running an action or re-running an\n  action execution. (new feature)\n* Store action execution state transitions (event log) in the ``log`` attribute on the\n  ActionExecution object. (new feature)\n* Admins will now be able pass ``--show-secrets`` when listing api keys to get the ``key_hash``\n  un-masked on the CLI. (new-feature)\n* Add ``--register-triggers`` flag to the ``st2-register-content`` script and ``st2ctl``.\n  When this flag is provided, all triggers contained within a pack triggers directory are\n  registered, consistent with the behavior of sensors, actions, etc. This feature allows users\n  to register trigger types outside the scope of the sensors. (new-feature) [Cody A. Ray]\n\nChanged\n~~~~~~~\n\n* Lazily establish SFTP connection inside the remote runner when and if SFTP connection is needed.\n  This way, remote runner should now also work under cygwin on Windows if SFTP related\n  functionality (file upload, directory upload, etc.) is not used. (improvement)\n  Reported by  Cody A. Ray\n* API and CLI allow rules to be filtered by their enable state. (improvement)\n* Send out a clear error message when SSH private key is passphrase protected but user fails to\n  supply passphrase with private_key when running a remote SSH action. (improvement)\n\nRemoved\n~~~~~~~\n\n* Remove now deprecated Fabric based remote runner and corresponding\n  ``ssh_runner.use_paramiko_ssh_runner`` config option. (cleanup)\n* Remove support for JSON format for resource metadata files. YAML was introduced and support for\n  JSON has been deprecated in StackStorm v0.6. Now the only supported metadata file format is YAML.\n\nFixed\n~~~~~\n\n* Fix for ``data` is dropped if ``message`` is not present in notification. (bug-fix)\n* Fix support for password protected private key files in the remote runner. (bug-fix)\n* Allow user to provide a path to the private SSH key file for the remote runner ``private_key``\n  parameter. Previously only raw key material was supported. (improvement)\n* Allow ``register-setup-virtualenvs`` flag to be used in combination with ``register-all`` in the\n  ``st2-register-content`` script.\n* Add missing ``pytz`` dependency to ``st2client`` requirements file. (bug-fix)\n* Fix datastore access on Python runner actions (set ``ST2_AUTH_TOKEN`` and ``ST2_API_URL`` env\n  variables in Python runner actions to match sensors). (bug-fix)\n* Alias names are now correctly scoped to a pack. This means the same name for alias can be used\n  across different packs. (bug-fix)\n* Fix a regression in filtering rules by pack with CLI. (bug-fix)\n* Make sure ``st2-submit-debug-info`` cleans up after itself and deletes a temporary directory it\n  creates. (improvement) #2714\n  [Kale Blankenship]\n* Fix string parameter casting - leave actual ``None`` value as-is and don't try to cast it to a\n  string which would fail. (bug-fix, improvement)\n* Add a work-around for trigger creation which would case rule creation for CronTrigger to fail\n  under some circumstances. (workaround, bug-fix)\n* Make sure ``-a all`` / ``--attr=all`` flag works for ``st2 execution list`` command (bug-fix)\n* Fix SSH bastion host support by ensuring the bastion parameter is passed to the paramiko ssh\n  client. (bug-fix) #2543 [Adam Mielke]\n\nSecurity\n~~~~~~~~\n\n* SSL support for mongodb connections. (improvement)\n\n\n1.4.0 - April 18, 2016\n----------------------\n\nAdded\n~~~~~\n\n* Passphrase support for the SSH runner. (improvement)\n* Add ``extra`` field to the ActionAlias schema for adapter-specific parameters. (improvement)\n* Allow user to pass a boolean value for the ``cacert`` st2client constructor argument. This way\n  it now mimics the behavior of the ``verify`` argument of the ``requests.request`` method.\n  (improvement)\n* Add datastore access to Python runner actions via the ``action_service`` which is available\n  to all the Python runner actions after instantiation. (new-feature) #2396 #2511\n  [Kale Blankenship]\n* Update ``st2actions.runners.pythonrunner.Action`` class so the constructor also takes\n  ``action_service`` as the second argument.\n* Display number of seconds which have elapsed for all the executions which have completed\n  when using ``st2 execution get`` CLI command. (improvement)\n* Display number of seconds elapsed for all the child tasks of a workflow action when using\n  ``st2 execution get`` CLI command. (improvement)\n* Various improvements in the ``linux.wait_for_ssh`` action:\n\n  * Support for password based authentication.\n  * Support for non-RSA SSH keys.\n  * Support for providing a non-default (22) SSH server port.\n  * Support for using default system user (stanley) ssh key if neither ``password`` nor\n    ``keyfile`` parameter is provided.\n* Support for leading and trailing slashes in the webhook urls. (improvement)\n* Introduce new ``matchwildcard`` rule criteria operator. This operator provides supports for Unix\n  shell-style wildcards (``*``, ``?``). (new feature)\n* Allow user to pass ``verbose`` parameter to ``linux.rm`` action. For backward compatibility\n  reasons it defaults to ``true``. (improvement)\n* Add ``--output`` and ``--existing-file`` options to ``st2-submit-debug-info``. [Kale Blankenship]\n* Allow user to specify a timezone in the CLI client config (``~/.st2/config``). If the timezone is\n  specified, all the timestamps displayed by the CLI will be shown in the configured timezone\n  instead of a default UTC display. (new feature)\n* Add ``attachments`` parameter to the ``core.sendmail`` action. (improvement) [Cody A. Ray]\n* Add ``--register-setup-virtualenvs`` flag to the ``register-content`` script and ``st2ctl``.\n  When this flag is provided, Python virtual environments are created for all the registered packs.\n  This option is to be used with distributed setup where action runner services run on multiple\n  hosts to ensure virtual environments exist on all those hosts. (new-feature)\n* Update ``core.st2.CronTimer`` so it supports more of the cron-like expressions (``a-b``, ``*/a``,\n  ``x,y,z``, etc.). (improvement)\n* Add new ``regex`` and ``iregex`` rule criteria operator and deprecate ``matchregex`` in favor of\n  those two new operators. (new-feature) [Jamie Evans]\n* Add support for better serialization of the following parameter types for positional parameters\n  used in the local and remote script runner actions: ``integer``, ``float``, ``boolean``,\n  ``list``, ``object``. Previously those values were serialized as Python literals which made\n  parsing them in the shell scripts very cumbersome. Now they are serialized based on the simple\n  rules described in the documentation which makes it easy to use just by using simple shell\n  primitives such as if statements and ``IFS`` for lists. (improvement, new feature)\n* Add ``-v`` flag (verbose mode) to the ``st2-run-pack-tests`` script. (improvement)\n* Add support for additional SSH key exchange algorithms to the remote runner via upgrade to\n  paramiko 1.16.0. (new feature)\n* Add initial code framework for writing unit tests for action aliases. For the usage, please refer\n  to the \"Pack Testing\" documentation section. (new feature)\n* Add custom ``use_none`` Jinja template filter which can be used inside rules when invoking an\n  action. This filter ensures that ``None`` values are correctly serialized and is to be used when\n  TriggerInstance payload value can be ``None`` and ``None`` is also a valid value for a particular\n  action parameter. (improvement, workaround)\n\nChanged\n~~~~~~~\n\n* Improvements to ChatOps deployments of packs via ``pack deploy`` [Jon Middleton]\n* Allow ``/v1/webhooks`` API endpoint request body to either be JSON or url encoded form data.\n  Request body type is determined and parsed accordingly based on the value of\n  ``Content-Type`` header.\n  Note: For backward compatibility reasons we default to JSON if ``Content-Type`` header is\n  not provided. #2473 [David Pitman]\n* Update ``matchregex`` rule criteria operator so it uses \"dot all\" mode where dot (``.``)\n  character will match any character including new lines. Previously ``*`` didn't match\n  new lines. (improvement)\n* Move stream functionality from ``st2api`` into a new standalone ``st2stream`` service. Similar to\n  ``st2api`` and ``st2auth``, stream is now a standalone service and WSGI app. (improvement)\n* Record failures to enforce rules due to missing actions or parameter validation errors. A\n  RuleEnforcement object will be created for failed enforcements that do not lead to an\n  ActionExecution creation. (improvement)\n* The list of required and optional configuration arguments for the LDAP auth backend has changed.\n  The LDAP auth backend supports other login name such as sAMAccountName. This requires a separate\n  service account for the LDAP backend to query for the DN related to the login name for bind to\n  validate the user password. Also, users must be in one or more groups specified in group_dns to\n  be granted access.\n* For consistency rename ``deploy_pack`` alias to ``pack_deploy``.\n\nDeprecated\n~~~~~~~~~~\n\n* Drop deprecated and unused ``system.admin_users`` config option which has been replaced with\n  RBAC.\n* The ``matchregex`` rule criteria operator has been deprecated in favor of ``regex`` and\n  ``iregex``.\n* Mistral has deprecated the use of task name (i.e. ``$.task1``) to reference task result. It is\n  replaced with a ``task`` function that returns attributes of the task such as id, state, result,\n  and additional information (i.e. ``task(task1).result``).\n\nFixed\n~~~~~\n\n* Bug fixes to allow Sensors to have their own log files. #2487 [Andrew Regan]\n* Make sure that the ``filename``, ``module``, ``funcName`` and ``lineno`` attributes which are\n  available in the log formatter string contain the correct values. (bug-fix)\n\n  Reported by Andrew Regan.\n* Make sure that sensor container child processes take into account ``--use-debugger`` flag passed\n  to the sensor container. This fixes support for remote debugging for sensor processes. (bug-fix)\n* Fix ``linux.traceroute`` action. (bug fix)\n* Fix a bug with positional argument handling in the local script runner. Now the arguments with a\n  no value or value of ``None`` are correctly passed to the script. (bug fix)\n* Fix rule criteria comparison and make sure that false criteria pattern values such as integer\n  ``0`` are handled correctly. (bug-fix)\n\n  Reported by Igor Cherkaev.\n* Fix alias executions API endpoint and make sure an exception is thrown if the user provided\n  command string doesn't match the provided format string. Previously, a non-match was silently\n  ignored. (bug fix)\n\n1.3.2 - February 12, 2016\n-------------------------\n\nRemoved\n~~~~~~~\n\n* Remove ``get_open_ports`` action from Linux pack.\n\n\n1.3.1 - January 25, 2016\n------------------------\n\nChanged\n~~~~~~~\n\n* Dev environment by default now uses gunicorn to spin API and AUTH processes. (improvement)\n* Allow user to pass a boolean value for the ``cacert`` st2client constructor argument. This way\n  it now mimics the behavior of the ``verify`` argument of the ``requests.request`` method.\n  (improvement)\n\nFixed\n~~~~~\n\n* Make sure ``setup.py`` of ``st2client`` package doesn't rely on functionality which is only\n  available in newer versions of pip.\n* Fix an issue where trigger watcher cannot get messages from queue if multiple API processes\n  are spun up. Now each trigger watcher gets its own queue and therefore there are no locking\n  issues. (bug-fix)\n\n\n1.3.0 - January 22, 2016\n------------------------\n\nAdded\n~~~~~\n\n* Allow user to pass ``env`` parameter to ``packs.setup_virtualenv`` and ``packs.install``\n  action.\n\n  This comes in handy if a user wants pip to use an HTTP(s) proxy (HTTP_PROXY and HTTPS_PROXY\n  environment variable) when installing pack dependencies. (new feature)\n* Ability to view causation chains in Trace. This helps reduce the noise when using Trace to\n  identify specific issues. (new-feature)\n* Filter Trace components by model types to only view ActionExecutions, Rules or TriggerInstances.\n  (new-feature)\n* Include ref of the most meaningful object in each trace component. (new-feature)\n* Ability to hide trigger-instance that do not yield a rule enforcement. (new-feature)\n* Action and Trigger filters for rule list (new-feature)\n* Add ``--register-fail-on-failure`` flag to ``st2-register-content`` script. If this flag is\n  provided, the script will fail and exit with non-zero status code if registering some resource\n  fails. (new feature)\n* Introduce a new ``abandoned`` state that is applied to executions that we cannot guarantee as\n  completed. Typically happen when an actionrunner currently running some executions quits or is\n  killed via TERM.\n* Add new ``st2garbagecollector`` service which periodically deletes old data from the database\n  as configured in the config. By default, no old data is deleted unless explicitly configured in\n  the config.\n* All published variables can be available in the result of ActionChain execution under the\n  ``published`` property if ``display_published`` property is specified.\n* Allow user to specify TTL when creating datastore item using CLI with the ``--ttl`` option.\n  (improvement)\n* Add option to rerun one or more tasks in mistral workflow that has errored. (new-feature)\n\nChanged\n~~~~~~~\n\n* Change the rule list columns in the CLI from ref, pack, description and enabled to ref,\n  trigger.ref, action.ref and enabled. This aligns closer the UI and also brings important\n  information front and center. (improvement)\n* Support for object already present in the DB for ``st2-rule-tester`` (improvement)\n* Throw a more friendly error message if casting parameter value fails because the value contains\n  an invalid type or similar. (improvement)\n* Display execution parameters when using ``st2 execution get <execution id>`` CLI command for\n  workflow executions. (improvement)\n* The ``--tasks`` option in the CLI for ``st2 execution get`` and ``st2 run`` will be renamed to\n  ``--show-tasks`` to avoid conflict with the tasks option in st2 execution re-run.\n* Replace ``chatops.format_result`` with ``chatops.format_execution_result`` and remove dependency\n  on st2 pack from st2contrib.\n* Trace also maintains causation chain through workflows.\n\nDeprecated\n~~~~~~~~~~\n\n* Deprecated ``params`` action attribute in the action chain definition in favor of the new\n  ``parameters`` attribute. (improvement)\n\nFixed\n~~~~~\n\n* Add missing logrotate config entry for ``st2auth`` service. #2294 [Vignesh Terafast]\n* Add a missing ``get_logger`` method to the `MockSensorService``. This method now returns an\n  instance of ``Mock`` class which allows user to assert that a particular message has been\n  logged. [Tim Ireland, Tomaz Muraus]\n* Fix validation error when None is passed explicitly to an optional argument on action\n  execution. (bug fix)\n* Fix action parameters validation so that only a selected set of attributes can be overriden for\n  any runner parameters. (bug fix)\n* Fix type in the headers parameter for the http-request runner. (bug fix)\n* Fix runaway action triggers caused by state miscalculation for mistral workflow. (bug fix)\n* Use ``--always-copy`` option when creating virtualenv for packs from packs.setup_virtualenv\n  action. This is required when st2actionrunner is kicked off from python within a virtualenv.\n* Fix a bug in the remote script runner which would throw an exception if a remote script action\n  caused a top level failure (e.g. copying artifacts to a remote host failed). (bug-fix)\n* Fix execution cancellation for task of mistral workflow. (bug fix)\n* Fix runaway action triggers caused by state miscalculation for mistral workflow. (bug fix)\n* Fix a bug when removing notify section from an action meta and registering it never removed\n  the notify section from the db. (bug fix)\n* Make sure action specific short lived authentication token is deleted immediately when execution\n  is cancelled. (improvement)\n* Ignore lock release errors which could occur while reopening log files. This error could simply\n  indicate that the lock was never acquired.\n\n\n1.2.0 - December 07, 2015\n-------------------------\n\nAdded\n~~~~~\n\n* Add SSH bastion host support to the paramiko SSH runner. Utilizes same connection parameters as\n  the targeted box. (new feature, improvement) #2144, #2150 [Logan Attwood]\n* Introduce a new ``timeout`` action execution status which represents an action execution\n  timeout. Previously, executions which timed out had status set to ``failure``. Keep in mind\n  that timeout is just a special type of a failure. (new feature)\n* Allow jinja templating to be used in ``message`` and ``data`` field for notifications.(new feature)\n* Add tools for purging executions (also, liveactions with it) and trigger instances older than\n  certain UTC timestamp from the db in bulk.\n* Introducing ``noop`` runner and ``core.noop`` action. Returns consistent success in a WF regardless of\n  user input. (new feature)\n* Add mock classes (``st2tests.mocks.*``) for easier unit testing of the packs. (new feature)\n* Add a script (``./st2common/bin/st2-run-pack-tests``) for running pack tests. (new feature)\n* Support for formatting of alias acknowledgement and result messages in AliasExecution. (new feature)\n* Support for \"representation+value\" format strings in aliases. (new feature)\n* Support for disabled result and acknowledgement messages in aliases. (new feature)\n* Add ability to write rule enforcement (models that represent a rule evaluation that resulted\n  in an action execution) to db to help debugging rules easier. Also, CLI bindings to list\n  and view these models are added. (new-feature)\n\nChanged\n~~~~~~~\n\n* Refactor retries in the Mistral action runner to use exponential backoff. Configuration options\n  for Mistral have changed. (improvement)\n* Update action chain runner so it performs on-success and on-error task name validation during\n  pre_run time. This way common errors such as typos in the task names can be spotted early on\n  since there is no need to wait for the run time.\n* Change ``headers`` and ``params`` ``core.http`` action paramer type from ``string`` to\n  ``object``.\n* Don't allow action parameter ``type`` attribute to be an array since rest of the code doesn't\n  support parameters with multiple types. (improvement)\n* Update local runner so all the commands which are executed as a different user and result in\n  using sudo set $HOME variable to the home directory of the target user. (improvement)\n* Include state_info for Mistral workflow and tasks in the action execution result. (improvement)\n* ``--debug`` flag no longer implies profiling mode. If you want to enable profiling mode, you need\n  to explicitly pass ``--profile`` flag to the binary. To reproduce the old behavior, simply pass\n  both flags to the binary - ``--debug --profile``.\n* Modify ActionAliasFormatParser to work with regular expressions and support more flexible parameter matching. (improvement)\n* Move ChatOps pack to st2 core.\n* Purge tool now uses delete_by_query and offloads delete to mongo and doesn't perform app side\n  explicit model deletion to improve speed. (improvement)\n\nFixed\n~~~~~\n\n* Fix trigger parameters validation for system triggers during rule creation - make sure we\n  validate the parameters before creating a TriggerDB object. (bug fix)\n* Fix a bug with a user inside the context of the live action which was created using alias\n  execution endpoint incorrectly being set to the system user (``stanley``) instead of the\n  authenticated user which triggered the execution. (bug fix)\n* Fix policy loading and registering - make sure we validate policy parameters against the\n  parameters schema when loading / registering policies. (bug fix, improvement)\n* Fix policy trigger for action execution cancellation. (bug fix)\n* Improve error reporting for static error in ActionChain definition e.g. incorrect reference\n  in default etc. (improvement)\n* Fix action chain so it doesn't end up in an infinite loop if an action which is part of the chain\n  is canceled. (bug fix)\n* Fix json representation of trace in cli. (bug fix)\n* Add missing indexes on trigger_instance_d_b collection. (bug fix)\n\n\n1.1.1 - November 13, 2015\n-------------------------\n\nAdded\n~~~~~\n\n* Allow user to specify URL which Mistral uses to talk to StackStorm API using ``mistral.api_url``\n  configuration option. If this option is not provided it defaults to the old behavior of using the\n  public API url (``auth.api_url`` setting). (improvement)\n\nChanged\n~~~~~~~\n\n* Improve speed of ``st2 execution list`` command by not requesting ``result`` and\n  ``trigger_instance`` attributes. The effect of this change will be especially pronounced for\n  installations with a lot of large executions (large execution for this purpose is an execution\n  with a large result).\n* Improve speed of ``st2 execution get`` command by not requesting ``result`` and\n  ``trigger_instance`` attributes.\n* Now when running ``st2api`` service in debug mode (``--debug``) flag, all the JSON responses are\n  pretty indented.\n* When using ``st2 execution list`` and ``st2 execution get`` CLI commands, display execution\n  elapsed time in seconds for all the executions which are currently in \"running\" state.\n\nFixed\n~~~~~\n\n* Fix a race condition in sensor container where a sensor which takes <= 5 seconds to shut down\n  could be respawned before it exited. (bug fix) #2187 [Kale Blankenship]\n* Add missing entry for ``st2notifier`` service to the logrotate config. (bug fix)\n* Allow action parameter values with type ``object`` to contain special characters such as\n  ``.`` and ``$`` in the parameter value. (bug fix, improvement)\n\n\n1.1.0 - October 27, 2015\n------------------------\n\nAdded\n~~~~~\n\n* Add YAQL v1.0 support to Mistral. Earlier versions are deprecated. (improvement)\n* Move st2auth service authentication backends to a \"repo per backend\" model. Backends are now also\n  dynamically discovered and registered which makes it possible to easily create and use custom\n  backends. For backward compatibility reasons, ``flat_file`` backend is installed and available by\n  default. (new feature, improvement)\n* New st2auth authentication backend for authenticating against LDAP servers -\n  https://github.com/StackStorm/st2-auth-backend-ldap. (new feature)\n* Enable Mistral workflow cancellation via ``st2 execution cancel``. (improvement)\n* Allow action-alias to be created and deleted from CLI.\n* Add support for ``--profile`` flag to all the services. When this flag is provided service runs\n  in the profiling module which means all the MongoDB queries and query related profile data is\n  logged. (new-feature)\n* Introduce API Keys that do not expire like Authentication tokens. This makes it easier to work\n  with webhook based integrations. (new-feature)\n* Allow user to define trigger tags in sensor definition YAML files. (new feature) #2000\n  [Tom Deckers]\n* Update CLI so it supports caching tokens for different users (it creates a different file for each\n  user). This means you can now use ``ST2_CONFIG_FILE`` option without disabling token cache.\n  (improvement)\n* Add option to verify SSL cert for HTTPS request to the core.http action. (new feature)\n* Allow user to update / reinstall Python dependencies listed in ``requirements.txt`` inside the\n  pack virtual environment by passing ``update=True`` parameter to ``packs.setup_virtualenv``\n  action or by using new ``packs.update_virtualenv`` action. (new feature)\n  [jsjeannotte]\n* Pack on install are now assigned an owner group. The ``pack_group`` property allows to pick this\n  value and default is ``st2packs``. (new feature)\n\nChanged\n~~~~~~~\n\n* Update CLI so ``st2 run`` / ``st2 execution run`` and ``st2 execution re-run`` commands exit with\n  non-zero code if the action fails. (improvement)\n* Default to rule being disabled if the user doesn't explicitly specify ``enabled`` attribute when\n  creating a rule via the API or inside the rule metadata file when registering local content\n  (previously it defaulted to enabled).\n* Include parameters when viewing execution via the CLI. (improvement)\n* CLI renders parameters and output as yaml for better readability. (improvement)\n* Support versioned APIs for auth controller. For backward compatibility, unversioned API calls\n  get redirected to versioned controllers by the server. (improvement)\n* Update remote runner to include stdout and stderr which was consumed so far when a timeout\n  occurs. (improvement)\n* Reduce the wait time between message consumption by TriggerWatcher to avoid latency (improvement)\n* Allow user to specify value for the ``From`` field in the ``sendmail`` action by passing ``from``\n  parameter to the action. (improvement)\n  [pixelrebel]\n\nDeprecated\n~~~~~~~~~~\n\n* YAQL versions < 1.0 are deprecated.\n\nFixed\n~~~~~\n\n* Fix ``timestamp_lt`` and ``timestamp_gt`` filtering in the ``/executions`` API endpoint. Now we\n  return a correct result which is expected from a user-perspective. (bug-fix)\n* Make sure that alias execution endpoint returns a correct status code and error message if the\n  referenced action doesn't exist.\n* Allow user to select ``keystone`` backend in the st2auth service. (bug-fix)\n* Fix ``packs.info`` action so it correctly exits with a non-zero status code if the pack doesn't\n  exist or if it doesn't contain a valid ``.gitinfo`` file. (bug-fix)\n* Fix ``packs.info`` action so it correctly searches all the packs base dirs. (bug-fix)\n* Fix a bug in ``stdout`` and ``stderr`` consumption in paramiko SSH runner where reading a fixed\n  chunk byte array and decoding it could result in multi-byte UTF-8 character being read half way\n  resulting in UTF-8 decode error. This happens only when output is greater than default chunk size\n  (1024 bytes) and script produces utf-8 output. We now collect all the bytes from channel\n  and only then decode the byte stream as utf-8.\n* Cleanup timers and webhook trigger definitions once all rules referencing them are removed. (bug-fix)\n* Enable pseudo tty when running remote SSH commands with the paramiko SSH runner. This is done\n  to match existing Fabric behavior. (bug-fix)\n* Fix CLI so it skips automatic authentication if credentials are provided in the config on \"auth\"\n  command. (bug fix)\n* Strip the last '\\r' or '\\r\\n' from both ``stdout`` and ``stderr`` streams from paramiko and local\n  runner output. This is done to be compatible with fabric output of those streams. (bug-fix)\n* Set env variables (user provided and system assigned) before running remote command or script\n  action with paramiko. (bug-fix)\n* Fix a bug in Paramiko SSH runner where ``cwd`` could just be accessed in sudo mode but ``cd``\n  was outside scope of ``sudo`` in the command generated. Now, ``cd`` is inside the scope of\n  ``sudo``. (bug-fix)\n* Fix a bug in Paramiko SSH runner where kwargs keys in script arguments were not shell\n  injection safe. For example, kwarg key could contain spaces. (bug-fix)\n* Fix a bug in Paramiko SSH runner where JSON output in ``stdout`` or ``stderr`` wasn't transformed\n  to object automatically. (bug-fix)\n* Paramiko SSH runner no longer runs a remote command with ``sudo`` if local user and remote user\n  differ. (bug-fix)\n* Fix a bug with the CLI token precedence - now the auth token specified as an environment variable\n  or as a command line argument has precedence over credentials in the CLI config. (bug fix)\n* Fix st2-self-check script to check whether to use http/https when connecting to st2, to disable\n  Windows test by default, and to check test status correctly. (bug-fix)\n* Use exclusive messaging Qs for TriggerWatcher to avoid having to deal with old messages\n  and related migration scripts. (bug-fix)\n* Make sure sensor container child processes (sensor instance processes) are killed and cleaned up\n  if the sensor container is forcefully terminated (SIGKILL). (bug fix, improvement)\n\n\n0.13.2 - September 09, 2015\n---------------------------\n\nChanged\n~~~~~~~\n\n* Last newline character (``\\n``) is now stripped from ``stdout`` and ``stderr`` fields in local\n  and remote command/shell runners. (improvement)\n* Make sure sensor processes correctly pick up parent ``--debug`` flag. This makes debugging a lot\n  easier since user simply needs to start sensor container with ``--debug`` flag and all the sensor\n  logs with level debug or higher will be routed to the container log. (improvement)\n\nFixed\n~~~~~\n\n* ``private_key`` supplied for remote_actions is now used to auth correctly. The ``private_key``\n  argument should be the contents of private key file (of user specified in username argument).\n  (bug-fix)\n* Fix sensor container service so the ``config`` argument is correctly passed to the sensor\n  instances in the system packs. Previously, this argument didn't get passed correctly to the\n  FileWatchSensor from the system linux pack. (bug-fix)\n\n\n0.13.1 - August 28, 2015\n------------------------\n\nFixed\n~~~~~\n\n* ``cwd`` for paramiko script runner should use ``cwd`` provided as runner parameter.\n  (bug-fix)\n* Fix timer regression; bring brack broken timers. (bug-fix)\n* Updates to trace objects are done via non-upsert updates by adding to the array. This\n  makes it safer to update trace objects from multiple processes. (bug-fix)\n\n\n0.13.0 - August 24, 2015\n------------------------\n\nAdded\n~~~~~\n\n* Add new OpenStack Keystone authentication backend.\n  [Itxaka Serrano]\n* Support for RabbitMQ cluster. StackStorm works with a RabbitMQ cluster and switches\n  nodes on failover. (feature)\n* Introduce a Paramiko SSH runner that uses eventlets to run scripts or commands in parallel.\n  (improvement) (experimental)\n* Add action parameters validation to Mistral workflow on invocation. (improvement)\n* Allow user to include files which are written on disk inside the action create API payload.\n  (new feature)\n* Allow user to retrieve content of a file inside a pack by using the new\n  ``/packs/views/files/`` API endpoint. (new feature)\n* Add OpenStack Keystone authentication configuration for Mistral. (improvement)\n* Ability to add trace tag to TriggerInstance from Sensor. (feature)\n* Ability to view trace in CLI with list and get commands. (feature)\n* Add ability to add trace tag to ``st2 run`` CLI command. (feature)\n* Add ability to specify trace id in ``st2 run`` CLI command. (feature)\n* Add ``X-Request-ID`` header to all API calls for easier debugging. (improvement)\n* Add new CLI commands for disabling and enabling content pack resources\n  (``{sensor,action,rule} {enable, disable} <ref or id>``) (feature)\n\nChanged\n~~~~~~~\n\n* Information about parent workflow is now a dict in child's context field. (improvement)\n* Add support for restarting sensors which exit with a non-zero status code to\n  the sensor container. Sensor container will now automatically try to restart\n  (up to 2 times) sensor processes which die with a non-zero status code. (improvement)\n* Add index to the ActionExecution model to speed up query. (improvement)\n* Rename notification \"channels\" to \"routes\". (improvement)\n* Turn on paramiko ssh runner as the default ssh runner in prod configuration.\n  To switch to fabric runner, set ``use_paramiko_ssh_runner`` to false in ``st2.conf``.\n  (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug when some runner parameter default values were not overridden when a\n  false value was used in the action metadata parameter override (e.g. False, 0).\n  [Eugen C.]\n* Correctly return 404 if user requests an invalid path which partially maps to an existing\n  path. (bug-fix)\n* Fix sort key in the ActionExecution API controller. (bug-fix)\n* Fix key name for error message in liveaction result. (bug-fix)\n* Fix 500 API response when rule with no pack info is supplied. (bug-fix)\n* Fix bug in trigger-instance re-emit (extra kwargs passed to manager is now handled). (bug-fix)\n* Make sure auth hook and middleware returns JSON and \"Content-Type: application/json\" header\n  in every response. (improvement, bug-fix)\n* Fix bug in triggers emitted on key value pair changes and sensor spawn/exit. When\n  dispatching those triggers, the reference used didn't contain the pack names\n  which meant it was invalid and lookups in the rules engine would fail. (bug-fix)\n* Handle ``sudo`` in paramiko remote script runner. (bug-fix)\n* Update ``st2ctl`` to correctly start ``st2web`` even if Mistral is not installed.\n  (bug-fix, improvement)\n* Fix a bug in handling positional arguments with spaces. (bug-fix)\n* Make sure that the ``$PATH`` environment variable which is set for the sandboxed Python\n  process contains ``<virtualenv path>/bin`` directory as the first entry. (bug fix)\n\n\n0.12.2 - August 11, 2015\n------------------------\n\nAdded\n~~~~~\n\n* Support local ssh config file in remote runners. (feature)\n\nChanged\n~~~~~~~\n\n* Changes to htpasswd file used in ``flat_file`` auth backend do not require\n  a restart of st2auth and consequently StackStorm. (feature)\n\n\n0.12.1 - July 31, 2015\n----------------------\n\nFixed\n~~~~~\n\n* Un-registering a pack also removes ``rules`` and ``action aliases`` from the pack. (bug-fix)\n* Disable parallel SSH in fabric runner which causes issues with eventlets. (bug-fix)\n* Fix executions stuck in ``running`` state if runner container throws exception. (bug-fix)\n* Fix cases where liveaction result in dict are escaped and passed to Mistral. (bug-fix)\n\n\n0.12.0 - July 20, 2015\n----------------------\n\nAdded\n~~~~~\n\n* Add support for script arguments to the Windows script runner. (new feature)\n  [James Sigurðarson]\n* Allow user to filter executions on trigger instance id.\n  [Sayli Karmarkar]\n* By default the following environment variables are now available to the actions executed by\n  local, remote and python runner: ``ST2_ACTION_API_URL``, ``ST2_ACTION_AUTH_TOKEN``. (new-feature)\n* Jinja filter to make working with regex and semver possible in any place that\n  support jinja (improvement)\n* New experimental workflow runner based on the open-source CloudSlang project. (new-feature)\n  [Eliya Sadan, Meir Wahnon, Sam Markowitz]\n* Allow user to specify new ``secret`` attribute (boolean) for each action parameters. Values of\n  parameters which have this attribute set to true will be masked in the log files. (new-feature)\n* Support for masking secret parameters in the API responses. Secret parameters can only be viewed\n  through the API by admin users. (new-feature)\n* ``six`` library is now available by default in the Python sandbox to all the newly installed\n  packs. (improvement)\n* Dispatch an internal trigger when a datastore item has been created, updated, deleted and when\n  it's value has changed. (new-feature)\n* Add new ``/v1/packs`` API endpoint for listing installed packs. (new-feature)\n* Ability to partition sensors across sensor nodes using various partition schemes. (new-feature)\n* Add ability to use action context params as action params in meta. (new-feature)\n\nChanged\n~~~~~~~\n\n* Allow users to use ``timediff_lt`` and ``timediff_gt`` rule comparison operator with many string\n  date formats - previously it only worked with ISO8601 date strings. (improvement)\n* API server now gracefully shuts down on SIGINT (CTRL-C). (improvement)\n* Single sensor mode of Sensor Container uses ``--sensor-ref`` instead of ``--sensor-name``.\n* Move ``/exp/actionalias/`` and ``/exp/aliasexecution`` to ``/v1/actionalias/`` and\n  ``/v1/aliasexecution/`` respectively. (upgrade)\n* Display friendly message for error in parameters validation on action execution. (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug with with reinstalling a pack with no existing config - only try to move the config\n  file over if it exists. (bug fix)\n* Fix a bug with ``st2 execution list`` CLI command throwing an exception on failed Mistral\n  workflows. (bug-fix)\n* Fix a bug with ``st2 execution list`` CLI command not displaying ``end_timestamp`` attribute for\n  Mistral workflows. (bug-fix)\n* Fix a bug in action container where rendering params was done twice. (bug-fix)\n\n\n0.11.6 - July 2, 2015\n---------------------\n\nChanged\n~~~~~~~\n\n* Update all the code to handle all the datetime objects internally in UTC. (improvement, bug-fix)\n\n\n0.11.5 - July 1, 2015\n---------------------\n\nFixed\n~~~~~\n\n* Fix a bug where ``end_timestamp`` is not captured for Mistral workflow executions (bug-fix)\n* Fix a bug where the CLI failed to display Mistral workflow that errored (bug-fix)\n* Fix a bug where the published variables are not captured in the Mistral workflow result (bug-fix)\n\n\n0.11.4 - June 30, 2015\n----------------------\n\nRemoved\n~~~~~~~\n\n* Remove unnecessary rule notify_hubot from core.\n\n\n0.11.3 - June 16, 2015\n----------------------\n\nFixed\n~~~~~\n\n* Fix RHEL6 packaging issues\n\n\n0.11.2 - June 12, 2015\n----------------------\n\nFixed\n~~~~~\n\n* Fix a bug with ``start_timestamp`` and ``end_timestamp`` sometimes returning an invalid value in\n  a local instead of UTC timezone. (bug-fix)\n* Fix to get PollingSensor working again. Sensors of type PollingSensor were not being treated\n  as such and as a result would fail after the 1st poll. (bug-fix)\n\n\n0.11.1 - June 8, 2015\n---------------------\n\nChanged\n~~~~~~~\n\n* Action aliases are registered by default. (improvement)\n\nFixed\n~~~~~\n\n* Repair failing pack installation. (bug-fix)\n\n\n0.11.0 - June 5, 2015\n---------------------\n\nAdded\n~~~~~\n\n* Allow user to configure the CLI using an ini style config file located at ``~/.st2rc``.\n  (new-feature)\n* Add support for caching of the retrieved auth tokens to the CLI. (new-feature)\n* Update CLI so it displays the error at the top level when using ``run``, ``execution run`` or\n  ``execution get`` when executed workflow fails. (improvement)\n* Add new API endpoint for re-running an execution (``POST /executions/<id>/re_run/``).\n  (new-feature)\n* CLI now has ``get`` and ``list`` commands for triggerinstance. (new-feature)\n* CLI now has ``re-emit`` command for triggerinstance. (new-feature)\n\nChanged\n~~~~~~~\n\n* Throw a more-user friendly exception when enforcing a rule if an action referenced inside\n  the rule definition doesn't exist. (improvement)\n* Rules should be part of a pack. (improvement)\n* Update Windows runner code so it also works with a newer versions of winexe (> 1.0).\n  (improvement) [James Sigurðarson]\n* Validate parameters during rule creation for system triggers. (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug with the rule evaluation failing if the trigger payload contained a key with a\n  dot in the name. (bug-fix)\n* Fix a bug with publishing array (list) values as strings inside the action chain workflows.\n  (bug-fix)\n* Action trigger now contains execution id as opposed to liveaction id. (bug-fix)\n\nv0.9.2 - May 26, 2015\n---------------------\n\nFixed\n~~~~~\n\n* Fix broken ``packs.download`` action. (bug-fix)\n\n\nv0.9.1 - May 12, 2015\n---------------------\n\nAdded\n~~~~~\n\n* Allow option to bypass SSL Certificate Check (improvement)\n\nChanged\n~~~~~~~\n\n* Return HTTP BAD REQUEST when TTL requested for token > Max configured TTL (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug with alias parser to support empty formats (bug-fix)\n\n\nv0.9.0 - April 29, 2015\n-----------------------\n\nAdded\n~~~~~\n\n* Sensor container now can dynamically load/reload/unload sensors on data model changes.\n  (new-feature)\n* Add ``-t`` / ``--only-token`` flag to the ``st2 auth`` command. (new-feature)\n* Add ability to best-effort cancel actions and actionchain via API. (new-feature)\n* Add new ``windows-cmd`` and ``windows-script`` runners for executing commands\n  and PowerShell scripts on Windows hosts. (new-feature)\n* Update all the Python services to re-open log files on the ``SIGUSR1`` signal. (new-feature)\n\nChanged\n~~~~~~~\n\n* Report a more user-friendly error if an action-chain task references an invalid or inexistent\n  action. Also treat invalid / inexistent action as a top-level action-chain error. (improvement)\n* Report a more user-friendly error if an action-chain definition contains an invalid type.\n  (improvement)\n* Rename all st2 processes to be prefixed by st2. (sensor_container is now st2sensorcontainer,\n  rules_engine is now st2rulesengine, actionrunner is now st2actionrunner) (improvement)\n* Return a user friendly error on no sensors found or typo in sensor class name in single\n  sensor mode. (improvement)\n* Check if internal trigger types are already registered before registering\n  them again. (improvement)\n* Update runner names so they follow a consistent naming pattern. For backward\n  compatibility reasons, runners can still be referenced using their old names.\n  (improvement)\n\nFixed\n~~~~~\n\n* Sensor container now returns non-zero exit codes for errors. (bug-fix)\n* Fix a bug in datastore operations exposed in st2client. (bug-fix)\n* Catch exception if rule operator functions throw excepton and ignore the rule. (bug-fix)\n* Remove expected \"runnertype not found\" error logs on action registration\n  in clean db. (improvement)\n* Clean up rule registrar logging. (improvement)\n* ``register`` param in packs.install should be passed to packs.load. (bug-fix)\n* Fix validation code to validate value types correctly. (bug-fix)\n* Internal trigger types registered using APIs should use auth token. (bug-fix)\n\nSecurity\n~~~~~~~~\n\n* Enable authentication by default for package based installations.\n\n\nv0.8.3 - March 23, 2015\n-----------------------\n\nChanged\n~~~~~~~\n\n* Don't allow ``run-remote-script`` actions without an ``entry_point`` attribute - throw an\n  exception when running an action. (improvement)\n\nFixed\n~~~~~\n\n* Fix ``packs.setup_virtualenv`` command so it works correctly if user has specified multiple packs\n  search paths. (bug-fix)\n* Update sensor container to use ``auth.api_url`` setting when talking to the API (e.g. when\n  accessing a datastore, etc.). This way it also works correctly if sensor container is running\n  on a different host than the API. (bug-fix)\n\nv0.8.2 - March 10, 2015\n-----------------------\n\nFixed\n~~~~~\n\n* Fix a bug with python-runner actions sometimes not correctly reporting the action's ``stdout``.\n  (bug-fix)\n* Fix a bug in the ``run-remote-script`` runner - the runner ignored environment variables and\n  authentication settings which were supplied to the action as parameters. (bug-fix)\n\n\nv0.8.1 - March 10, 2015\n-----------------------\n\nAdded\n~~~~~\n\n* Allow user to exclude particular attributes from a response by passing\n  ``?exclude_attributes=result,trigger_instance`` query parameter to the ``/actionexecutions/``\n  and ``/actionexecutions/<execution id>/`` endpoint (new-feature)\n* Add new ``/actionexecutions/<id>/attribute/<attribute name>`` endpoint which allows user to\n  retrieve a value of a particular action execution attribute. (new-feature)\n\nChanged\n~~~~~~~\n\n* Update ``execution get`` CLI command so it automatically detects workflows and returns more\n  user-friendly output by default. (improvement)\n* Update ``run``, ``action execute``, ``execution get`` and ``execution re-run`` CLI commands to\n  take the same options and return output in the same consistent format.\n* Throw a more friendly error in the action chain runner if it fails to parse the action chain\n  definition file. (improvement)\n\nFixed\n~~~~~\n\n* Fix a bug with http runner not parsing JSON HTTP response body if the content-type header also\n  contained a charset. (bug-fix)\n* Indent workflow children properly in CLI (bug-fix)\n* Make sure that wait indicator is visible in CLI on some systems where stdout is buffered. (bug-fix)\n* Fix a bug with ``end_timestamp`` attribute on the ``LiveAction`` and ``ActionExecution`` model\n  containing an invalid value if the action hasn't finished yet. (bug-fix)\n* Correctly report an invalid authentication information error in the remote runner. (bug-fix)\n* Fix a bug in the action chain runner and make sure action parameters are also available for\n  substitution in the ``publish`` scope. (bug-fix)\n\n\nv0.8.0 - March 2, 2015\n----------------------\n\nAdded\n~~~~~\n\n* Allow user to specify current working directory (``cwd`` parameter) when running actions using the\n  local or the remote runner (``run-local``, ``run-local-script``, ``run-remote``,\n  ``run-remote-script``). (new-feature)\n* Default values of the parameter of an Action can be system values stored in kv-store. (new-feature)\n* Allow users to specify additional paths where StackStorm looks for integration packs using\n  ``packs_base_paths`` setting. (new-feature)\n* Allow user to specify which Python binary to use for the Python runner actions using\n  ``actionrunner.python_binary`` setting (new-feature)\n* Default Python binary which is used by Python runner actions to be the Python binary which is\n  used by the action runner service. Previous, system's default Python binary was used.\n* Vars can be defined in the ActionChain. (new-feature)\n* Node in an ActionChain can publish global variables. (new-feature)\n* Allow user to provide authentication token either inside headers (``X-Auth-Token``) or via\n  ``x-auth-token`` query string parameter. (new-feature)\n* Allow user to override authentication information (username, password, private key) on per\n  action basis for all the remote runner actions. (new-feature)\n* Allow user to pass ``--inherit-env`` flag to the ``st2 action run`` command which causes all\n  the environment variables accessible to the CLI to be sent as ``env`` parameter to the action\n  being executed. (new-feature)\n* Cast params of an execution before scheduling in the RulesEngine. This allows non-string\n  parameters in an action. (new-feature)\n* CLI commands to return non-zero exit codes for failed operations (new-feature)\n* Add new ``nequals`` (``neq``) rule criteria operator. This criteria operator\n  performs not equals check on values of an arbitrary type. (new-feature)\n* Add new ``execution re-run <execution id>`` CLI command for re-running an\n  existing action. (new-feature)\n* Dispatch an internal trigger when a sensor process is spawned / started\n  (``st2.sensor.process_spawn``) and when a process exits / is stopped\n  (``st2.sensor.process_exit``). (new-feature)\n* Update HTTP runner to automatically parse JSON response body if Content-Type is\n  ``application/json`` (new-feature)\n* Support for filtering by timestamp and status in executions list. (new-feature)\n* Ability to see child tasks of any execution. (new-feature)\n* Allow sensors to manage global datastore items via sensor_service by passing ``local=False``\n  argument to the ``get_value``, ``set_value`` and ``delete_value`` methods. (new-feature)\n* Allow sensors to list datastore items using ``list_values`` sensor_service method. (new-feature)\n* Allow users to filter datastore items by name prefix by passing ``?prefix=<value>`` query\n  parameter to the ``/keys`` endpoint. (new-feature)\n\nChanged\n~~~~~~~\n\n* Rename ActionExecution to LiveAction. (refactor)\n* Rename ActionExecutionHistory to ActionExecution. (refactor)\n* POST to ``/v1/executions`` take LiveActionAPI but returns ActionExecutionAPI (refactor)\n* Execution list shows only top level executions by default to see full list use --showall. (refactor)\n\nRemoved\n~~~~~~~\n\n* A separate history process is no longer required. ActionExecution updates are carried at time of\n  update to LiveAction. (refactor)\n\nDeprecated\n~~~~~~~~~~\n\n* API url ``/v1/actionexecutions/`` is now deprecated in favor of ``/v1/executions/`` (refactor)\n* API url change ``/v1/history/execution`` to ``/v1/executions`` (refactor)\n* API url change ``/v1/history/execution/views/filters`` to ``/v1/executions/views/filters`` (refactor)\n\nFixed\n~~~~~\n\n* Fix a race-condition / bug which would occur when multiple packs are installed at the same time.\n  (bug-fix)\n* Allow actions without parameters. (bug-fix)\n* Fix a bug with rule matching not working for any triggers with parameters. (bug-fix)\n* Require ``cmd`` parameter for the following actions: ``core.remote``, ``core.remote_sudo``,\n  ``core.local``, ``core.local_sudo`` (bug-fix)\n* Use QuerySet.count() instead of len(QuerySet) to avoid the caching of the entire result which\n  improve running time of API request. (bug-fix)\n* Fix a bug with template rendering, under some conditions, ending in an infinite loop. (bug-fix)\n* Mistral subworkflows kicked off in st2 should include task name. (bug-fix)\n* Fix non-string types to be rendered correctly in action parameters when used in rule. (bug-fix)\n* Allow user to specify default value for required attributes in the definition of action\n  parameters. (bug-fix)\n* When running with auth enabled, correctly preserve the username of the authenticated user who\n  has triggered the action execution. (bug-fix)\n\n\nv0.7 - January 16, 2015\n-----------------------\n\nAdded\n~~~~~\n\n* Python runner and all the fabric based runners (``run-local``, ``run-local-script``,\n  ``run-remote``, ``run-remote-script``) now expose the ``timeout`` argument. With this argument\n  users can specify action timeout. Previously, the action timeout was not user-configurable and\n  a system-wide default value was used.\n* The time when an action execution has finished is now recorded and available via the\n  ``end_timestamp`` attribute on the ``ActionExecution`` model.\n* Allow polling sensors to retrieve current poll interval and change it using ``get_poll_interval``\n  and ``set_poll_interval`` methods respectively. (new-feature)\n* Add support for a ``standalone`` mode to the st2auth service. In the standalone mode,\n  authentication is handled inside the st2auth service using the defined backend. (new feature)\n* Add new rule criteria comparison operators: ``iequals``, ``contains``, ``icontains``,\n  ``ncontains``, ``incontains``, ``startswith``, ``istartswith``, ``endswith``, ``iendswith``,\n  ``exists``, ``nexists`` (new-feature)\n* Allow sensors to store temporary data in the datastore using the ``get_value``, ``set_value`` and\n  ``delete_value`` methods exposed by sensor_service. (new-feature)\n* Allow user to specify TTL for datastore values by sending ``ttl`` attribute in the body of a\n  ``PUT /keys/<key id>`` request. (new feature)\n* Add new ``key delete_by_prefix --prefix=<prefix>`` client command. This command allows deletion of\n  all the keys with names starting with the provided prefix. (new-feature)\n* Add ability to attach tags to Action, Rule and TriggerType.\n* Add ability to query results asynchronously from external services. (new-feature)\n* Add ``rule_tester`` tool which allows users to test rules in an offline mode without any services\n  running (new-feature)\n\nChanged\n~~~~~~~\n\n* Refactor local runners so they are more robust, efficient and easier to debug. Previously, local\n  actions were executed through SSH, now they are executed directly without the overhead of SSH.\n* Timer is not a sensor anymore. It is launched as part of the ``rules_engine`` process (refactor)\n* Action models now use ContentPackResourceMixin so we can get them by ref. (refactor)\n* st2api only requires st2common and dependencies defined in ``requirements.txt`` to be available\n  on the pythonpath thus making it possible to run st2api standalone.\n* Change default mode for authentication to standalone. (refactor)\n\nFixed\n~~~~~\n\n* Status code 400 (bad request) is now returned if user doesn't provide a body to API endpoints\n  which require it. Previously 500 internal server error was returned (bug-fix).\n* Fix local runner so it correctly executes a command under the provided system user if ``user``\n  parameter is provided. (bug-fix)\n* Fix a bug with a Trigger database object in some cases being created twice when registering a\n  rule. (bug-fix)\n* Fix a bug with child processes which run sensor code not being killed when stopping a sensor\n  container service. (bug-fix)\n* Fix a bug and allow user to use non-ascii (unicode) values in the parameter substitution values.\n  (bug-fix)\n* Fix a bug with action registration where actions with invalid schema for parameters get\n  registered. (bug-fix)\n* Fix a bug with ``default`` param values inheritance in runner/actions. (bug-fix)\n* Fix a bug where trigger objects weren't created for triggers with different parameters. (bug-fix)\n\n\nv0.6.0 - December 8, 2014\n-------------------------\n\nAdded\n~~~~~\n\n* Add Sensor and PollingSensor base classes. (NB: Sensors API change is non-backward compatible.)\n* YAML support for action, rules and chain meta.\n* Add sensor meta support (JSON/YAML) to specify trigger types.\n* Audit log messages are now saved in a structured format as JSON in\n  ``st2actionrunner.{pid}.audit.log`` log file.\n\nChanged\n~~~~~~~\n\n* Separate virtualenv per pack. (Pythonic sensors and actions use them by default.)\n* Install pip requirements from ``requirements.txt`` in packs by default.\n* Sensors are now run in their own process for isolation.\n* Python Actions are now run in their own process for isolation.\n* Separate out ``rules_engine`` into own process.\n* Packs default path moves from ``/opt/stackstorm`` to ``/opt/stackstorm/packs/``.\n* Webhooks are not part of a sensor. They are now part of core API. (Authentication may\n  be required.)\n* API URLs are now versioned. All the existing paths have been prefixed with ``/v1``\n  (e.g. ``/v1/actions``).\n\nFixed\n~~~~~\n\n* Numerous bug fixes.\n\nv0.5.1 - November 3rd, 2014\n---------------------------\n\nAdded\n~~~~~\n\n* Initial public release\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.140625,
          "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info@stackstorm.com. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n"
        },
        {
          "name": "CONTRIBUTING.rst",
          "type": "blob",
          "size": 2.34375,
          "content": "Contributing to StackStorm\n==========================\n\nWe welcome and appreciate contributions of any kind (code, tests,\ndocumentation, examples, ...).\n\nFor more information on how to contribute and the guidelines you should follow,\nplease visit the Development section of our documentation -\nhttp://docs.stackstorm.com/development/index.html\n\nManaging Python dependencies\n----------------------------\n\n    ``requirements.txt`` files are generated automatically using ``scripts/fixate-requirements.py`` script and shouldn't be edited manually.\n\nTo manage Python dependencies for each StackStorm component, we use the\nfollowing files:\n\n1. ``fixed-requirements.txt`` - A file which pins all the requirements to a\n   specific version. Keep in mind that this file is used by all the components.\n   This way we make sure different components always use the same version of a\n   particular dependency.\n2. ``st2*/in-requirements.txt`` - Component specific requirements file. This\n   file contains a full list of the dependencies which are needed by this\n   particular component.\n3. ``st2*/requirements.txt`` - Final component requirements file which is\n   generated by processing fixed-requirements.txt and in-requirements.txt file.\n   Note: This file is automatically generated and should not be edited\n   manually.\n4. ``requirements.txt`` - Final requirements file for all the components which\n   is generated by processing fixed-requirements.txt and all the component\n   in-requirements.txt files. Note: This file is automatically generated and\n   should not be edited manually.\n\nAdding a new component dependency\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nTo add a new dependency for a particular component, you should perform the following steps:\n\n1. Add a name / link to the dependency to component ``in-requirements.txt``\n   file. For example ``st2actions/in-requirements.txt``\n2. Pin this requirement to a specific version in the ``fixed-requirements.txt`` file in the\n   repo root.\n3. Generate final ``requirements.txt`` file for that component by running ``make requirements``\n   target in the component directory. For example: ``cd st2actions ; make requirements``.\n4. Generate global ``requirements.txt`` file in the repo root by running ``make requirements`` in\n   there.\n5. Add and commit generated requirements.txt files - ``git add\n   st2*/requirements.txt ; git add requirements.txt ; git commit``\n"
        },
        {
          "name": "GOVERNANCE.md",
          "type": "blob",
          "size": 10.609375,
          "content": "StackStorm has joined Linux Foundation in 2019.\nWith the new Neutral Home we invite everyone: organizations, teams and individuals relying on StackStorm Automation in their operations to support the project by giving back and participating in development as well as influence on its future under the Open Governance.\n\n# StackStorm Governance\nThis document defines governance policies for the StackStorm project.\nIt extends [Technical Charter](https://stackstorm.com/wp/wp-content/uploads/2020/06/2019-09-03-StackStorm-Project-Technical-Charter.pdf) for StackStorm within the Linux Foundation.\n\n## Technical Steering Committee (TSC)\nThe Technical Steering Committee is a group of Maintainers (Committers) who have earned the ability to modify (“commit”) sourcecode, documentation or other artifacts.\nThis group is responsible for all technical oversight of StackStorm as Open Source Project.\n\n### Maintainer Roles\nThe current list of maintainers is published and updated in [OWNERS.md](OWNERS.md).\nStackStorm uses a three-tiered system of Maintainer roles:\n* [Leaders](OWNERS.md#leaders-)\n  * Head of Technical Steering Committee (TSC).\n  * Responsible for Project Strategy, External Relations, Organizational aspects, coordinating Events, Partnerships.\n  * Receive **three votes** in the [conflict resolution and voting process](#conflict-resolution-and-voting) described below.\n* [Senior Maintainers](OWNERS.md#senior-maintainers-)\n  * Have the most in-depth experience with the StackStorm project and are expected to have the knowledge and insight to lead the project's future, growth, standards and improvement.\n  * Oversee the process for adding new maintainers and provide guidance, help and sharing their experience with the standard maintainers.\n  * Have full owner access to all the resources and platforms that sustain StackStorm project.\n  * Receive **two votes** in the voting process.\n* [Maintainers](OWNERS.md#maintainers-)\n  * Have good experience with the StackStorm codebase, expected to provide significant value to the project, helping it grow, improve and succeed.\n  * Have full member write access to [StackStorm](https://github.com/stackstorm/) and [StackStorm-Exchange](https://github.com/stackstorm-exchange) Github organizations, CI/CD, Moderator at [forum](https://forum.stackstorm.com/), [Slack](https://stackstorm.com/community-signup) and other Community platforms.\n  * Receive **one vote** in the voting process.\n\n### Maintainer Activities\n* Monitor one or more of: Slack, Forums, and other Communication channels with StackStorm Community (delayed response is perfectly acceptable).\n* Attend the Community meetings to discuss the project plans, roadmap and commitments.\n* Triage GitHub issues and perform pull request reviews for [StackStorm](https://github.com/stackstorm/) and [StackStorm-Exchange](https://github.com/stackstorm-exchange/) Github organizations.\n  The areas of specialization listed in [OWNERS.md](OWNERS.md) can be used to help with routing\n  an issue/question to the right person.\n* During GitHub issue triage, apply all applicable [labels](https://github.com/StackStorm/st2/labels)\n  to each new issue. Labels are extremely useful for future issue follow up. A few of the most important labels that are\n  not self explanatory are:\n  * **good first issue**: Mark any issue that can reasonably be accomplished by a new contributor with this label. It's important to lower the barrier of entry and leave first tasks for new contributors.\n  * **help wanted**: Unless it is immediately obvious that someone is going to work on an issue (and if so assign it), mark it help wanted.\n  * **status:to be verified**: If the reported bug needs to be confirmed before working on a fix.\n  * **status:need more info**: If the issue needs more information from someone who reported it.\n  * see all the Github [**labels**](https://github.com/stackstorm/st2/labels). Recommended informative balance for the issue is 3-5 labels.\n* Make sure that ongoing PRs are moving forward at the right pace or closing them. It's important to apply the same to old PRs and Issues to retain healthy project state.\n* Guide Community about using the right channel: Github for Issues and Bug-reports, while Forums and Slack for questions and discussions.\n* Project maintenance: security, updates, CI/CD, builds, infrastructure.\n* Prioritize the work following [StackStorm Roadmap](https://docs.stackstorm.com/latest/roadmap.html) to move the project forward.\n* All maintainers ideally are expected to shoulder a proportional share of community work: Issues, Reviews, Slack, Forum, Releases, fixing CI/CD Builds, etc. Work upon to make sure the balance is kept within the team.\n* Encourage and guide other community members to contribute back to StackStorm. Even a simple bug report or a one-line documentation PR is a win!\n* Follow-up by filing undocumented issues found in community channels, show an example.\n* Share the experience with other Maintainers and Contributors.\n\n## Becoming a Maintainer\nAny level of contribution is welcomed: starting from feedback, reporting bugs, manually verifying features and fixes, improving documentation, helping other community members ending with the actual code, PRs, writing tests, reviews, fixes, proposing architecture or even marketing efforts.\n\n### How to start Contributing?\n* Start helping StackStorm is easy. A few contributing activities that are highly valued:\n  * answer user questions and troubleshoot issues in Community: Slack, Forums, Github\n  * triaging issues with [**status: to be verified**](https://github.com/stackstorm/st2/issues?q=is%3Aissue+is%3Aopen+status+label%3A%22status%3Ato+be+verified%22) will help you to get familiar with the project functionality\n  * working on issues tagged as [**good first issue**](https://github.com/StackStorm/st2/contribute)\n  * [**bugs**](https://github.com/stackstorm/st2/issues?q=is%3Aissue+is%3Aopen+status+label%3Abug) are very important to address and will help you to get more familiar with the codebase\n  * enhancements marked with [**refactoring**](https://github.com/stackstorm/st2/issues?q=is%3Aopen+is%3Aissue+label%3Arefactor) tag\n  * any [documentation](https://github.com/stackstorm/st2docs) improvements are always appreciated\n  * perform code reviews on other's pull requests. Second pair of eyes and a few cycles of manual testing can help to prevent bugs early\n  * join the *#development* channel in [StackStorm Slack](https://stackstorm.com/#community) for more pointers from the current Maintainers\n  * help growing community ecosystem by writing technical content about StackStorm like HOWTOs, Show Cases and Demos, Blog posts, Tutorials. We also accept [guest posts](https://stackstorm.com/blog/)!\n* After period of time you will be proposed to be added to the Contributors group of [OWNERS.md](OWNERS.md#contributors).\n\n### How to become a Maintainer?\nBesides of activities listed in Contributing section, you need to demonstrate a strong commitment to the long term success of a project.\nJust contributing does not make you a maintainer, it is about building trust with the current maintainers of the project and being a person that they can depend on and trust to make decisions in the best interest of StackStorm.\n\nPeriodically, the existing maintainers curate a list of contributors that have shown regular activity on the project over the prior months. From this list, maintainer candidates are selected and proposed.\n* Becoming a maintainer generally means that you are going to be spending substantial time (at least 1 full day/week) on StackStorm for the foreseeable future.\n* You should have ability to write a good solid code and collaborate with the team and community.\n* Enough effort to understanding of the core project's code base (stackstorm/st2) and internals.\n* Understanding of how the team works (policies, processes for testing, quality standards, code review, etc).\n* Start doing PRs and code reviews under the guidance of maintainers: ask where the help is needed.\n* As you gain experience with the code base and our standards, we will expect you to start working on increasingly complicated PRs, under the guidance of the existing maintainers.\n* We may ask you to do some PRs from our backlog or roadmap. It's important to understand that as Maintainers we try to follow the common goals and plans.\n* After a period of 3+ months of working together and making sure we see eye to eye, the existing maintainers will discuss granting \"standard\" maintainer access or not.\nWe make no guarantees on the length of time this will take, but 3+ months is the approximate time.\n* Maintainers will be proposed to be added to the StackStorm GitHub organization and Maintainers group of [OWNERS.md](OWNERS.md) via voting.\n\n### How to become a Senior Maintainer?\n* Gain substantial in-depth experience with the codebase, project and processes.\n* Manifest a major contribution to the project functionality.\n* Demonstrate ability guiding other Maintainers and Contributors.\n* Conduct at least one StackStorm release in a Maintainer role (release responsibility is rotated between the maintainers).\n* \"Standard\" maintainer access can be upgraded via voting to \"Senior\" maintainer access after several months of work, depending on commitment and involvement.\n\n## Removing a Maintainer\nIf a maintainer is no longer interested or cannot perform the maintainer duties listed above, they\nshould volunteer to be moved to non-voting Contributor or Friends status. In extreme cases this can also occur by a vote of\nthe maintainers per the voting process below.\n\n## Conflict resolution and voting\nIn general, it's preferred that technical issues and maintainer membership are agreed\nbetween the persons involved. If a dispute cannot be decided independently, the maintainers can be\ncalled in to decide. If the maintainers themselves cannot decide an issue, the issue will\nbe resolved by voting.\n\n## How decisions are made?\nThe process of adding, promoting or removing Contributors and Maintainers is done via composing a Pull Request (PR) against `OWNERS.md`\nwhich includes details about contribution activities committed to the project during period of time and how that conforms with expected Maintainer responsibilities, skillset and the best interest of the project.\nThe decision is made based on TSC members votes in a PR.\n\nThe process of voting on other Issues, Proposals and Changes is performed by creating an open Github Discussion. For decisions making history reasons and to stimulate brainstorming, it's recommended to write a detailed research/description that covers possible outcomes and pros/cons behind the change to give comprehensive context.\n\nAdditions and removals of maintainers require a *2/3 majority*, while other decisions and changes\nrequire only a simple majority. The voting period is one week.\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 11.0869140625,
          "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2020 The StackStorm Authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License."
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 54.37890625,
          "content": "ROOT_DIR := $(shell dirname $(realpath $(lastword $(MAKEFILE_LIST))))\nSHELL := /bin/bash\nOS := $(shell uname)\n\n# We separate the OSX X and Linux virtualenvs so we can run in a Docker\n# container (st2devbox) while doing things on our host Mac machine\nifeq ($(OS),Darwin)\n\tVIRTUALENV_DIR ?= virtualenv-osx\n\tVIRTUALENV_ST2CLIENT_DIR ?= virtualenv-st2client-osx\n\tVIRTUALENV_ST2CLIENT_PYPI_DIR ?= virtualenv-st2client-pypi-osx\n\tVIRTUALENV_COMPONENTS_DIR ?= virtualenv-components-osx\nelse\n\tVIRTUALENV_DIR ?= virtualenv\n\tVIRTUALENV_ST2CLIENT_DIR ?= virtualenv-st2client\n\tVIRTUALENV_ST2CLIENT_PYPI_DIR ?= virtualenv-st2client-pypi\n\tVIRTUALENV_COMPONENTS_DIR ?= virtualenv-components\nendif\n\n# Assign PYTHON_VERSION if it doesn't already exist\nPYTHON_VERSION ?= python3\n\nBINARIES := bin\n\n# All components are prefixed by st2 and not .egg-info.\nCOMPONENTS := $(shell ls -a | grep ^st2 | grep -v .egg-info)\nCOMPONENTS_RUNNERS := $(wildcard contrib/runners/*)\nMOCK_RUNNERS := $(wildcard st2common/tests/runners/*)\nCOMPONENTS_WITHOUT_ST2TESTS := $(shell ls -a | grep ^st2 | grep -v .egg-info | grep -v st2tests | grep -v st2exporter)\n\nCOMPONENTS_WITH_RUNNERS := $(COMPONENTS) $(COMPONENTS_RUNNERS)\n\nCOMPONENTS_TEST_DIRS := $(wildcard st2*/tests) $(wildcard contrib/runners/*/tests)\n\n# Components that implement a component-controlled test-runner. These components provide an\n# in-component Makefile. (Temporary fix until I can generalize the pecan unittest setup. -mar)\n# Note: We also want to ignore egg-info dir created during build\nCOMPONENT_SPECIFIC_TESTS := st2tests st2client.egg-info\n\n# nasty hack to get a space into a variable\nspace_char := $(subst ,, )\ncolon := :\ncomma := ,\ndot := .\nslash := /\nCOMPONENT_PYTHONPATH = $(subst $(space_char),:,$(realpath $(COMPONENTS_WITH_RUNNERS)))\nCOMPONENTS_TEST := $(foreach component,$(filter-out $(COMPONENT_SPECIFIC_TESTS),$(COMPONENTS_WITH_RUNNERS)),$(component))\nCOMPONENTS_TEST_COMMA := $(subst $(slash),$(dot),$(subst $(space_char),$(comma),$(COMPONENTS_TEST)))\nCOMPONENTS_TEST_MODULES := $(subst $(slash),$(dot),$(COMPONENTS_TEST_DIRS))\nCOMPONENTS_TEST_MODULES_COMMA := $(subst $(space_char),$(comma),$(COMPONENTS_TEST_MODULES))\n\nCOVERAGE_GLOBS := .coverage.unit.* .coverage.integration.*\nCOVERAGE_GLOBS_QUOTED := $(foreach glob,$(COVERAGE_GLOBS),'$(glob)')\n\nREQUIREMENTS := test-requirements.txt requirements.txt\n\n# Redis config for testing\nST2TESTS_REDIS_HOST := 127.0.0.1\nST2TESTS_REDIS_PORT := 6379\n\n# Pin common pip version here across all the targets\n# Note! Periodic maintenance pip upgrades are required to be up-to-date with the latest pip security fixes and updates\nPIP_VERSION ?= 24.3.1\nSETUPTOOLS_VERSION ?= 75.3.0\nPIP_OPTIONS := $(ST2_PIP_OPTIONS)\n\nifndef PYLINT_CONCURRENCY\n\tPYLINT_CONCURRENCY := 1\nendif\n\nifndef XARGS_CONCURRENCY\n\tXARGS_CONCURRENCY := 8\nendif\n\nifndef NODE_INDEX\n\tNODE_INDEX := 0\nendif\nifndef NODE_TOTAL\n\tNODE_TOTAL := 1\nendif\n\n# NOTE: We exclude resourceregistrar DEBUG level log messages since those are very noisy (we\n# loaded resources for every tests) which makes tests hard to troubleshoot on failure due to\n# pages and pages and pages of noise.\n# The minus in front of st2.st2common.bootstrap filters out logging statements from that module.\n# https://github.com/pytest-dev/pytest-xdist/issues/71\n#PYTEST_OPTS := -n auto --tx 2*popen//execmodel=eventlet\n# --suppress-no-test-exit-code is part of the pytest-custom_exit_code plugin\nPYTEST_OPTS := --test-group=$(NODE_INDEX) --test-group-count=$(NODE_TOTAL) -s --log-level=error --suppress-no-test-exit-code\n\nifndef PIP_OPTIONS\n\tPIP_OPTIONS :=\nendif\n\n# NOTE: We only run coverage on master and version branches and not on pull requests since\n# it has a big performance overhead and is very slow.\nifeq ($(ENABLE_COVERAGE),yes)\n\tPYTEST_COVERAGE_FLAGS := --with-coverage --cover-branches --cover-erase\n\tPYTEST_COVERAGE_PACKAGES := --cover-package=$(COMPONENTS_TEST_COMMA)\nelse\n\tINCLUDE_TESTS_IN_COVERAGE :=\nendif\n\n# If we aren't running test coverage, don't try to include tests in coverage\n# results\nifdef INCLUDE_TESTS_IN_COVERAGE\n\tPYTEST_COVERAGE_FLAGS += --cover-tests\n\tPYTEST_COVERAGE_PACKAGES := $(PYTEST_COVERAGE_PACKAGES),$(COMPONENTS_TEST_MODULES_COMMA)\nendif\n\n.PHONY: all\nall: requirements configgen check tests\n\n.PHONY: .coverage_globs\n.coverage_globs:\n\t@for coverage_result in $$( \\\n\t\tfor coverage_glob in $(COVERAGE_GLOBS_QUOTED); do \\\n\t\t\tcompgen -G $${coverage_glob}; \\\n\t\tdone; \\\n\t); do \\\n\t\techo $${coverage_result}; \\\n\tdone\n\n# Target for debugging Makefile variable assembly\n.PHONY: play\nplay:\n\t@echo PYTHON_VERSION=$(PYTHON_VERSION) \\($$($(PYTHON_VERSION) --version)\\)\n\t@echo\n\t@echo COVERAGE_GLOBS=$(COVERAGE_GLOBS_QUOTED)\n\t@echo\n\t@echo COMPONENTS=$(COMPONENTS)\n\t@echo\n\t@echo COMPONENTS_WITH_RUNNERS=$(COMPONENTS_WITH_RUNNERS)\n\t@echo\n\t@echo COMPONENTS_TEST=$(COMPONENTS_TEST)\n\t@echo\n\t@echo COMPONENTS_TEST_COMMA=$(COMPONENTS_TEST_COMMA)\n\t@echo\n\t@echo COMPONENTS_TEST_DIRS=$(COMPONENTS_TEST_DIRS)\n\t@echo\n\t@echo COMPONENTS_TEST_MODULES=$(COMPONENTS_TEST_MODULES)\n\t@echo\n\t@echo COMPONENTS_TEST_MODULES_COMMA=$(COMPONENTS_TEST_MODULES_COMMA)\n\t@echo\n\t@echo COMPONENT_PYTHONPATH=$(COMPONENT_PYTHONPATH)\n\t@echo\n\t@echo TRAVIS_PULL_REQUEST=$(TRAVIS_PULL_REQUEST)\n\t@echo\n\t@echo TRAVIS_EVENT_TYPE=$(TRAVIS_EVENT_TYPE)\n\t@echo\n\t@echo GITHUB_EVENT_NAME=$(GITHUB_EVENT_NAME)\n\t@echo\n\t@echo PYTEST_OPTS=$(PYTEST_OPTS)\n\t@echo\n\t@echo ENABLE_COVERAGE=$(ENABLE_COVERAGE)\n\t@echo\n\t@echo PYTEST_COVERAGE_FLAGS=$(PYTEST_COVERAGE_FLAGS)\n\t@echo\n\t@echo PYTEST_COVERAGE_PACKAGES=$(PYTEST_COVERAGE_PACKAGES)\n\t@echo\n\t@echo INCLUDE_TESTS_IN_COVERAGE=$(INCLUDE_TESTS_IN_COVERAGE)\n\t@echo\n\t@echo shard: NODE_INDEX/NODE_TOTAL=$(NODE_INDEX)/$(NODE_TOTAL)\n\t@echo\n\n.PHONY: check\ncheck: check-requirements check-sdist-requirements flake8 checklogs\n\n# NOTE: We pass --no-deps to the script so we don't install all the\n# package dependencies which are already installed as part of \"requirements\"\n# make targets. This speeds up the build\n.PHONY: install-runners\ninstall-runners:\n\t@echo \"\"\n\t@echo \"================== INSTALL RUNNERS ====================\"\n\t@echo \"\"\n\t# NOTE: We use xargs to speed things up by installing runners in parallel\n\techo -e \"$(COMPONENTS_RUNNERS)\" | tr -d \"\\n\" | xargs -P $(XARGS_CONCURRENCY) -d \" \" -n1 -i sh -c \". $(VIRTUALENV_DIR)/bin/activate; cd $$(pwd)/{} ; python setup.py develop --no-deps\"\n\t#@for component in $(COMPONENTS_RUNNERS); do \\\n\t#\techo \"===========================================================\"; \\\n\t#\techo \"Installing runner:\" $$component; \\\n\t#\techo \"===========================================================\"; \\\n\t#\t#(. $(VIRTUALENV_DIR)/bin/activate; cd $$component; python setup.py develop --no-deps); \\\n\t#done\n\n.PHONY: install-mock-runners\ninstall-mock-runners:\n\t@echo \"\"\n\t@echo \"================== INSTALL MOCK RUNNERS ====================\"\n\t@echo \"\"\n\t# NOTE: We use xargs to speed things up by installing runners in parallel\n\techo -e \"$(MOCK_RUNNERS)\" | tr -d \"\\n\" | xargs -P $(XARGS_CONCURRENCY) -d \" \" -n1 -i sh -c \". $(VIRTUALENV_DIR)/bin/activate; cd $$(pwd)/{} ; python setup.py develop --no-deps\"\n\t#@for component in $(MOCK_RUNNERS); do \\\n\t#\techo \"===========================================================\"; \\\n\t#\techo \"Installing mock runner:\" $$component; \\\n\t#\techo \"===========================================================\"; \\\n\t#\t(. $(VIRTUALENV_DIR)/bin/activate; cd $$component; python setup.py develop --no-deps); \\\n\t#done\n\n.PHONY: check-requirements\n.check-requirements:\n\t@echo\n\t@echo \"============== CHECKING REQUIREMENTS ==============\"\n\t@echo\n\t# Update requirements and then make sure no files were changed\n\tgit status -- *requirements.txt */*requirements.txt | grep -q \"nothing to commit\" || { \\\n\t\techo \"It looks like you directly modified a requirements.txt file, an\"; \\\n\t\techo \"in-requirements.txt file, or fixed-requirements.txt without running:\"; \\\n\t\techo \"\"; \\\n\t\techo \"    make .requirements\"; \\\n\t\techo \"\"; \\\n\t\techo \"Please update all of the requirements.txt files by running that command\"; \\\n\t\techo \"and committing all of the changed files. You can quickly check the results\"; \\\n\t\techo \"with:\"; \\\n\t\techo \"\"; \\\n\t\techo \"    make .check-requirements\"; \\\n\t\techo \"\"; \\\n\t\texit 1; \\\n\t}\n\t@echo \"All requirements files are up-to-date!\"\n\n.PHONY: check-requirements\ncheck-requirements: .requirements .check-requirements\n\n.PHONY: .check-sdist-requirements\n.check-sdist-requirements:\n\t@echo\n\t@echo \"============== CHECKING SDIST REQUIREMENTS ==============\"\n\t@echo\n\t# Update requirements and then make sure no files were changed\n\tgit status -- */dist_utils.py contrib/runners/*/dist_utils.py | grep -q \"nothing to commit\" || { \\\n\t\techo \"It looks like you directly modified a dist_utils.py, or the source \"; \\\n\t\techo \"scripts/dist_utils.py file without running:\"; \\\n\t\techo \"\"; \\\n\t\techo \"    make .sdist-requirements\"; \\\n\t\techo \"\"; \\\n\t\techo \"Please update all of the dist_utils.py files by running that command\"; \\\n\t\techo \"and committing all of the changed files. You can quickly check the results\"; \\\n\t\techo \"with:\"; \\\n\t\techo \"\"; \\\n\t\techo \"    make .check-sdist-requirements\"; \\\n\t\techo \"\"; \\\n\t\texit 1; \\\n\t}\n\t@echo \"All dist_utils.py files are up-to-date!\"\n\n.PHONY: check-sdist-requirements\ncheck-sdist-requirements: .sdist-requirements .check-sdist-requirements\n\n.PHONY: check-python-packages\ncheck-python-packages:\n\t# Make target which verifies all the components Python packages are valid\n\t@echo \"\"\n\t@echo \"================== CHECK PYTHON PACKAGES ====================\"\n\t@echo \"\"\n\ttest -f $(VIRTUALENV_COMPONENTS_DIR)/bin/activate || $(PYTHON_VERSION) -m venv $(VIRTUALENV_COMPONENTS_DIR) --system-site-packages\n\t@for component in $(COMPONENTS_WITHOUT_ST2TESTS); do \\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Checking component:\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t(set -e; cd $$component; ../$(VIRTUALENV_COMPONENTS_DIR)/bin/python setup.py --version) || exit 1; \\\n\tdone\n\n.PHONY: check-python-packages-nightly\ncheck-python-packages-nightly:\n\t# NOTE: This is subset of check-python-packages target.\n\t# We run more extensive and slower tests as part of the nightly build to speed up PR builds\n\t@echo \"\"\n\t@echo \"================== CHECK PYTHON PACKAGES ====================\"\n\t@echo \"\"\n\n\ttest -f $(VIRTUALENV_COMPONENTS_DIR)/bin/activate || $(PYTHON_VERSION) -m venv $(VIRTUALENV_COMPONENTS_DIR) --system-site-packages\n\t$(VIRTUALENV_COMPONENTS_DIR)/bin/pip install wheel\n\t@for component in $(COMPONENTS_WITHOUT_ST2TESTS); do \\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Checking component:\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t(set -e; cd $$component; ../$(VIRTUALENV_COMPONENTS_DIR)/bin/python setup.py --version) || exit 1; \\\n\t\t(set -e; cd $$component; ../$(VIRTUALENV_COMPONENTS_DIR)/bin/python setup.py sdist bdist_wheel) || exit 1; \\\n\t\t(set -e; cd $$component; ../$(VIRTUALENV_COMPONENTS_DIR)/bin/python setup.py develop --no-deps) || exit 1; \\\n\t\t($(VIRTUALENV_COMPONENTS_DIR)/bin/python -c \"import $$component\") || exit 1; \\\n\t\t(set -e; cd $$component; rm -rf dist/; rm -rf $$component.egg-info) || exit 1; \\\n\tdone\n\n.PHONY: ci-checks-nightly\n# TODO: Ony run micro-benchmarks once a week since they are extremly slow on CI\nci-checks-nightly: check-python-packages-nightly\n#ci-checks-nightly: check-python-packages-nightly micro-benchmarks\n\n# CI checks which are very slow and only run on a weekly basic\n.PHONY: ci-checks-weekly\nci-checks-weekly: micro-benchmarks\n\n.PHONY: checklogs\nchecklogs:\n\t@echo\n\t@echo \"================== LOG WATCHER ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python ./tools/log_watcher.py 10\n\n.PHONY: pylint\npylint: requirements .pylint\n\n.PHONY: configgen\nconfiggen: requirements .configgen\n\n.PHONY: .shellcheck\n.shellcheck:\n\t@echo\n\t@echo \"================== shellcheck ====================\"\n\t@echo\n\tshellcheck scripts/ci/*.sh\n\tshellcheck scripts/github/*.sh\n\tshellcheck scripts/*.sh\n\n.PHONY: .configgen\n.configgen:\n\t@echo\n\t@echo \"================== config gen ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python ./tools/config_gen.py > conf/st2.conf.sample;\n\n.PHONY: schemasgen\nschemasgen: requirements .schemasgen\n\n.PHONY: .schemasgen\n.schemasgen:\n\t@echo\n\t@echo \"================== content model schemas gen ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python ./st2common/bin/st2-generate-schemas;\n\n.PHONY: .pylint\n.pylint:\n\t@echo\n\t@echo \"================== pylint ====================\"\n\t@echo\n\t@echo \"===========================================================\"; \\\n\techo \"Test our custom pylint plugins before we use them\"; \\\n\techo \"===========================================================\"; \\\n\t. $(VIRTUALENV_DIR)/bin/activate ; pytest pylint_plugins || exit 1\n\t# Lint st2 components\n\t@for component in $(COMPONENTS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running pylint on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models --load-plugins=pylint_plugins.db_models $$component/$$component || exit 1; \\\n\tdone\n\t# Lint runner modules and packages\n\t@for component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running pylint on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models --load-plugins=pylint_plugins.db_models $$component/*.py || exit 1; \\\n\tdone\n\t# Lint Python pack management actions\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models contrib/packs/actions/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models contrib/packs/actions/*/*.py || exit 1;\n\t# Lint other packs\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models contrib/linux/*/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models contrib/chatops/*/*.py || exit 1;\n\t# Lint Python scripts\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models scripts/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc --load-plugins=pylint_plugins.api_models tools/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; pylint -j $(PYLINT_CONCURRENCY) -E --rcfile=./lint-configs/python/.pylintrc pylint_plugins/*.py || exit 1;\n\n# Black task which checks if the code comforts to black code style\n.PHONY: black-check\nblack: requirements .black-check\n\n.PHONY: .black-check\n.black-check:\n\t@echo\n\t@echo \"================== black-check ====================\"\n\t@echo\n\t# st2 components\n\t@for component in $(COMPONENTS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running black on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --check --config pyproject.toml $$component/ || exit 1; \\\n\t\tif [ -d \"$$component/bin\" ]; then \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate ; black $$(grep -rl '^#!/.*python' $$component/bin) || exit 1; \\\n\t\tfi \\\n\tdone\n\t# runner modules and packages\n\t@for component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running black on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --check --config pyproject.toml $$component/ || exit 1; \\\n\t\tif [ -d \"$$component/bin\" ]; then \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate ; black $$(grep -rl '^#!/.*python' $$component/bin) || exit 1; \\\n\t\tfi \\\n\tdone\n\t. $(VIRTUALENV_DIR)/bin/activate; black --check --config pyproject.toml contrib/ || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --check --config pyproject.toml scripts/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --check --config pyproject.toml tools/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --check --config pyproject.toml pylint_plugins/*.py || exit 1;\n\n# Black task which reformats the code using black\n.PHONY: black\nblack: requirements .black-format\n\n.PHONY: .black-format\n.black-format:\n\t@echo\n\t@echo \"================== black ====================\"\n\t@echo\n\t# st2 components\n\t@for component in $(COMPONENTS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running black on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --config pyproject.toml $$component/ || exit 1; \\\n\t\tif [ -d \"$$component/bin\" ]; then \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --config pyproject.toml $$(grep -rl '^#!/.*python' $$component/bin) || exit 1; \\\n\t\tfi \\\n\tdone\n\t# runner modules and packages\n\t@for component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running black on\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --config pyproject.toml  $$component/ || exit 1; \\\n\t\tif [ -d \"$$component/bin\" ]; then \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate ; black --config pyproject.toml $$(grep -rl '^#!/.*python' $$component/bin) || exit 1; \\\n\t\tfi \\\n\tdone\n\t. $(VIRTUALENV_DIR)/bin/activate; black --config pyproject.toml contrib/ || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --config pyproject.toml scripts/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --config pyproject.toml tools/*.py || exit 1;\n\t. $(VIRTUALENV_DIR)/bin/activate; black --config pyproject.toml pylint_plugins/*.py || exit 1;\n\n.PHONY: pre-commit-checks\nblack: requirements .pre-commit-checks\n\n# Ensure all files contain no trailing whitespace + that all YAML files are valid.\n.PHONY: .pre-commit-checks\n.pre-commit-checks:\n\t@echo\n\t@echo \"================== pre-commit-checks ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; pre-commit run trailing-whitespace --all --show-diff-on-failure\n\t. $(VIRTUALENV_DIR)/bin/activate; pre-commit run check-yaml --all --show-diff-on-failure\n.PHONY: lint-api-spec\nlint-api-spec: requirements .lint-api-spec\n\n.PHONY: .lint-api-spec\n.lint-api-spec:\n\t@echo\n\t@echo \"================== Lint API spec ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python st2common/bin/st2-validate-api-spec --config-file conf/st2.dev.conf\n\n.PHONY: generate-api-spec\ngenerate-api-spec: requirements .generate-api-spec\n\n.PHONY: .generate-api-spec\n.generate-api-spec: .lint-api-spec\n\t@echo\n\t@echo \"================== Generate openapi.yaml file ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python st2common/bin/st2-generate-api-spec --config-file conf/st2.dev.conf > st2common/st2common/openapi.yaml\n\n.PHONY: circle-lint-api-spec\ncircle-lint-api-spec:\n\t@echo\n\t@echo \"================== Lint API spec ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; python st2common/bin/st2-validate-api-spec --config-file conf/st2.dev.conf || echo \"Open API spec lint failed.\"\n\n.PHONY: flake8\nflake8: requirements .flake8\n\n.PHONY: .flake8\n.flake8:\n\t@echo\n\t@echo \"==================== flake ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 $(COMPONENTS)\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 $(COMPONENTS_RUNNERS)\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 contrib/packs/actions/\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 contrib/linux\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 contrib/chatops/\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 scripts/\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 tools/\n\t. $(VIRTUALENV_DIR)/bin/activate; flake8 --config ./lint-configs/python/.flake8 pylint_plugins/\n\n# Make task which verifies st2client README will parse pypi checks\n.PHONY: .st2client-pypi-check\n.st2client-pypi-check:\n\t@echo\n\t@echo \"==================== st2client pypi check ====================\"\n\t@echo\n\ttest -f $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate || $(PYTHON_VERSION) -m venv $(VIRTUALENV_ST2CLIENT_PYPI_DIR)\n\n\t# Setup PYTHONPATH in bash activate script...\n\t# Delete existing entries (if any)\n\tsed -i '/_OLD_PYTHONPATHp/d' $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\tsed -i '/PYTHONPATH=/d' $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\tsed -i '/export PYTHONPATH/d' $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\techo '_OLD_PYTHONPATH=$$PYTHONPATH' >> $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\techo 'PYTHONPATH=${ROOT_DIR}:$(COMPONENT_PYTHONPATH)' >> $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\techo 'export PYTHONPATH' >> $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\ttouch $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\tchmod +x $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate\n\n\t$(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/pip install --upgrade \"pip==$(PIP_VERSION)\"\n\t$(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/pip install --upgrade \"readme_renderer\"\n\t$(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/pip install --upgrade \"restructuredtext-lint\"\n\n\t# Check with readme-renderer\n\t. $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate; cd st2client ; ../$(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/python -m readme_renderer README.rst\n\t# Check with rst-lint - encounters errors that readme_renderer doesn't, but pypi complains about\n\t. $(VIRTUALENV_ST2CLIENT_PYPI_DIR)/bin/activate; cd st2client ; rst-lint README.rst\n\n# Make task which verifies st2client installs and works fine\n.PHONY: .st2client-install-check\n.st2client-install-check:\n\t@echo\n\t@echo \"==================== st2client install check ====================\"\n\t@echo\n\ttest -f $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate || $(PYTHON_VERSION) -m venv $(VIRTUALENV_ST2CLIENT_DIR)\n\n\t# Setup PYTHONPATH in bash activate script...\n\t# Delete existing entries (if any)\n\tsed -i '/_OLD_PYTHONPATHp/d' $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\tsed -i '/PYTHONPATH=/d' $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\tsed -i '/export PYTHONPATH/d' $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\n\techo '_OLD_PYTHONPATH=$$PYTHONPATH' >> $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\techo 'PYTHONPATH=${ROOT_DIR}:$(COMPONENT_PYTHONPATH)' >> $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\techo 'export PYTHONPATH' >> $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\ttouch $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\tchmod +x $(VIRTUALENV_ST2CLIENT_DIR)/bin/activate\n\n\t$(VIRTUALENV_ST2CLIENT_DIR)/bin/pip install --upgrade \"pip==$(PIP_VERSION)\"\n\t$(VIRTUALENV_ST2CLIENT_DIR)/bin/pip install --upgrade \"setuptools==$(SETUPTOOLS_VERSION)\"\n\n\t$(VIRTUALENV_ST2CLIENT_DIR)/bin/activate; cd st2client ; ../$(VIRTUALENV_ST2CLIENT_DIR)/bin/python setup.py install ; cd ..\n\t$(VIRTUALENV_ST2CLIENT_DIR)/bin/st2 --version\n\t$(VIRTUALENV_ST2CLIENT_DIR)/bin/python -c \"import st2client\"\n\n.PHONY: bandit\nbandit: requirements .bandit\n\n.PHONY: .bandit\n.bandit:\n\t@echo\n\t@echo \"==================== bandit ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; bandit -r $(COMPONENTS_WITH_RUNNERS) -lll -x build,dist\n\n.PHONY: lint\nlint: requirements .lint\n\n.PHONY: .lint\n.lint: .generate-api-spec .black-check .pre-commit-checks .flake8 .pylint .st2client-dependencies-check .st2common-circular-dependencies-check .rst-check .st2client-install-check\n\n.PHONY: clean\nclean: .cleanpycs\n\n.PHONY: compilepy3\ncompilepy3:\n\t@echo \"======================= compile ========================\"\n\t@echo \"------- Compile all .py files (syntax check test - Python 3) ------\"\n\tpython3 -m compileall -f -q -x 'virtualenv|virtualenv-osx|virtualenv-py3|.tox|.git|.venv-st2devbox|./st2tests/st2tests/fixtures/packs/test|./pants-plugins' .\n\n.PHONY: .cleanpycs\n.cleanpycs:\n\t@echo \"Removing all .pyc files\"\n\tfind $(COMPONENTS_WITH_RUNNERS)  -name \\*.pyc -type f -print0 | xargs -0 -I {} rm {}\n\n.PHONY: .st2client-dependencies-check\n.st2client-dependencies-check:\n\t@echo \"Checking for st2common imports inside st2client\"\n\tfind ${ROOT_DIR}/st2client/st2client/ -name \\*.py -type f -print0 | xargs -0 cat | grep st2common ; test $$? -eq 1\n\n.PHONY: .st2common-circular-dependencies-check\n.st2common-circular-dependencies-check:\n\t@echo \"Checking st2common for circular dependencies\"\n\tfind ${ROOT_DIR}/st2common/st2common/ -name \\*.py -type f -print0 | xargs -0 cat | grep st2reactor ; test $$? -eq 1\n\tfind ${ROOT_DIR}/st2common/st2common/ \\( -name \\*.py ! -name runnersregistrar\\.py -name \\*.py ! -name compat\\.py ! -name inquiry\\.py \\) -type f -print0 | xargs -0 cat | grep st2actions ; test $$? -eq 1\n\tfind ${ROOT_DIR}/st2common/st2common/ -name \\*.py -type f -print0 | xargs -0 cat | grep st2api ; test $$? -eq 1\n\tfind ${ROOT_DIR}/st2common/st2common/ -name \\*.py -type f -print0 | xargs -0 cat | grep st2auth ; test $$? -eq 1\n\tfind ${ROOT_DIR}/st2common/st2common/ \\( -name \\*.py ! -name router\\.py -name \\*.py \\) -type f -print0 | xargs -0 cat | grep st2stream; test $$? -eq 1\n\tfind ${ROOT_DIR}/st2common/st2common/ -name \\*.py -type f -print0 | xargs -0 cat | grep st2exporter; test $$? -eq 1\n\n.PHONY: micro-benchmarks\nmicro-benchmarks: requirements .micro-benchmarks\n\n.PHONY: .micro-benchmarks\n.micro-benchmarks:\n\t@echo\n\t@echo \"==================== micro-benchmarks ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_field_types.py -k \"test_save_large_execution\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_field_types.py -k \"test_read_large_execution\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_field_types.py -k \"test_save_multiple_fields\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_field_types.py -k \"test_save_large_string_value\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_field_types.py -k \"test_read_large_string_value\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_transport_compression.py -k \"test_save_execution\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_mongo_transport_compression.py -k \"test_read_execution\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:dict_keys_count_and_depth -s -v st2common/benchmarks/micro/test_fast_deepcopy.py -k \"test_fast_deepcopy_with_dict_values\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_fast_deepcopy.py -k \"test_fast_deepcopy_with_json_fixture_file\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file,param:indent_sort_keys_tuple -s -v st2common/benchmarks/micro/test_json_serialization_and_deserialization.py -k \"test_json_dumps\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_json_serialization_and_deserialization.py -k \"test_json_loads\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_json_serialization_and_deserialization.py -k \"test_orjson_dumps\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_publisher_compression.py -k \"test_pickled_object_compression\"\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --benchmark-histogram=benchmark_histograms/benchmark --benchmark-only --benchmark-name=short --benchmark-columns=min,max,mean,stddev,median,ops,rounds --benchmark-group-by=group,param:fixture_file -s -v st2common/benchmarks/micro/test_publisher_compression.py -k \"test_pickled_object_compression_publish\"\n\n.PHONY: .cleanmongodb\n.cleanmongodb:\n\t@echo \"==================== cleanmongodb ====================\"\n\t@echo \"----- Dropping all MongoDB databases -----\"\n\t@sudo pkill -9 mongod\n\t@sudo rm -rf /var/lib/mongodb/*\n\t@sudo chown -R mongodb:mongodb /var/lib/mongodb/\n\t@sudo service mongodb start\n\t@sleep 15\n\t@mongo --eval \"rs.initiate()\"\n\t@sleep 15\n\n.PHONY: .cleanrabbitmq\n.cleanrabbitmq:\n\t@echo \"==================== cleanrabbitmq ====================\"\n\t@echo \"Deleting all RabbitMQ queue and exchanges\"\n\t@sudo rabbitmqctl stop_app\n\t@sudo rabbitmqctl reset\n\t@sudo rabbitmqctl start_app\n\n.PHONY: .cleancoverage\n.cleancoverage:\n\t@echo \"==================== cleancoverage ====================\"\n\t@echo \"Removing all coverage results directories\"\n\t@echo\n\trm -rf .coverage $(COVERAGE_GLOBS) \\\n\t\t.coverage.unit .coverage.integration\n\n.PHONY: distclean\ndistclean: clean\n\t@echo\n\t@echo \"==================== distclean ====================\"\n\t@echo\n\trm -rf $(VIRTUALENV_DIR)\n\n.PHONY: .sdist-requirements\n.sdist-requirements:\n\t# Copy over shared dist utils module which is needed by setup.py\n\t@for component in $(COMPONENTS_WITH_RUNNERS); do\\\n\t\tcp -f ./scripts/dist_utils.py $$component/dist_utils.py;\\\n\t\tscripts/write-headers.sh $$component/dist_utils.py || break;\\\n\tdone\n\n\t# Copy over CHANGELOG.RST, CONTRIBUTING.RST and LICENSE file to each component directory\n\t#@for component in $(COMPONENTS_TEST); do\\\n\t#\ttest -s $$component/README.rst || cp -f README.rst $$component/; \\\n\t#\tcp -f CONTRIBUTING.rst $$component/; \\\n\t#\tcp -f LICENSE $$component/; \\\n\t#done\n\n.PHONY: .requirements\n.requirements: virtualenv\n\t$(VIRTUALENV_DIR)/bin/pip install --upgrade \"pip==$(PIP_VERSION)\"\n\t# Print out pip version\n\t$(VIRTUALENV_DIR)/bin/pip --version\n\t# Generate all requirements to support current CI pipeline.\n\t$(VIRTUALENV_DIR)/bin/python scripts/fixate-requirements.py --skip=virtualenv,virtualenv-osx -s st2*/in-requirements.txt contrib/runners/*/in-requirements.txt -f fixed-requirements.txt -o requirements.txt\n\n\t# Remove any *.egg-info files which polute PYTHONPATH\n\trm -rf *.egg-info*\n\n\t# Generate finall requirements.txt file for each component\n\t# NOTE: We use xargs to speed things up by running commands in parallel\n\techo -e \"$(COMPONENTS_WITH_RUNNERS)\" | tr -d \"\\n\" | xargs -P $(XARGS_CONCURRENCY) -d \" \" -n1 -i sh -c \"$(VIRTUALENV_DIR)/bin/python scripts/fixate-requirements.py --skip=virtualenv,virtualenv-osx -s {}/in-requirements.txt -f fixed-requirements.txt -o {}/requirements.txt\"\n\n\t#@for component in $(COMPONENTS_WITH_RUNNERS); do\\\n\t#\techo \"===========================================================\"; \\\n\t#\techo \"Generating requirements.txt for\" $$component; \\\n\t#\t$(VIRTUALENV_DIR)/bin/python scripts/fixate-requirements.py --skip=virtualenv,virtualenv-osx -s $$component/in-requirements.txt -f fixed-requirements.txt -o $$component/requirements.txt; \\\n\t#done\n\n\t@echo \"===========================================================\"\n\n.PHONY: requirements\nrequirements: virtualenv .requirements .sdist-requirements install-runners install-mock-runners\n\t@echo\n\t@echo \"==================== requirements ====================\"\n\t@echo\n\t# Show pip installed packages before we start\n\techo \"\"\n\t$(VIRTUALENV_DIR)/bin/pip list\n\techo \"\"\n\n\t# Note: Use the verison of virtualenv pinned in fixed-requirements.txt so we\n\t#       only have to update it one place when we change the version\n\t$(VIRTUALENV_DIR)/bin/pip install --upgrade $(shell grep \"^virtualenv\" fixed-requirements.txt)\n\t$(VIRTUALENV_DIR)/bin/pip install --upgrade \"setuptools==$(SETUPTOOLS_VERSION)\"  # workaround for pbr issue\n\n\t# Install requirements\n\tfor req in $(REQUIREMENTS); do \\\n\t\techo \"Installing $$req...\" ; \\\n\t\t$(VIRTUALENV_DIR)/bin/pip install $(PIP_OPTIONS) -r $$req ; \\\n\tdone\n\n\t# Install st2common package to load drivers defined in st2common setup.py\n\t# NOTE: We pass --no-deps to the script so we don't install all the\n\t# package dependencies which are already installed as part of \"requirements\"\n\t# make targets. This speeds up the build\n\t(cd ${ROOT_DIR}/st2common; ${ROOT_DIR}/$(VIRTUALENV_DIR)/bin/python setup.py develop --no-deps)\n\n\t# Install st2common to register metrics drivers\n\t# NOTE: We pass --no-deps to the script so we don't install all the\n\t# package dependencies which are already installed as part of \"requirements\"\n\t# make targets. This speeds up the build\n\t(cd ${ROOT_DIR}/st2common; ${ROOT_DIR}/$(VIRTUALENV_DIR)/bin/python setup.py develop --no-deps)\n\n\t# Install st2auth to register SSO drivers\n\t# NOTE: We pass --no-deps to the script so we don't install all the\n\t# package dependencies which are already installed as part of \"requirements\"\n\t# make targets. This speeds up the build\n\t(cd ${ROOT_DIR}/st2auth; ${ROOT_DIR}/$(VIRTUALENV_DIR)/bin/python setup.py develop --no-deps)\n\n\t# Some of the tests rely on submodule so we need to make sure submodules are check out\n\tgit submodule update --init --recursive --remote\n\n\t# Show currently install requirements\n\techo \"\"\n\t$(VIRTUALENV_DIR)/bin/pip list\n\techo \"\"\n\n.PHONY: check-dependency-conflicts\ncheck-dependency-conflicts:\n\t@echo\n\t@echo \"==================== check-dependency-conflicts ====================\"\n\t@echo\n\t# Verify there are no conflicting dependencies\n\tcat st2*/requirements.txt contrib/runners/*/requirements.txt | sort -u > req.txt && \\\n\t$(VIRTUALENV_DIR)/bin/pip-compile --strip-extras --output-file req.out req.txt || exit 1; \\\n\trm -f req.txt req.out\n\n.PHONY: virtualenv\n\t# Note: We always want to update virtualenv/bin/activate file to make sure\n\t# PYTHONPATH is up to date and to avoid caching issues on Travis\nvirtualenv:\n\t@echo\n\t@echo \"==================== virtualenv ====================\"\n\t@echo\n\ttest -f $(VIRTUALENV_DIR)/bin/activate || $(PYTHON_VERSION) -m venv $(VIRTUALENV_DIR)\n\n\t# Setup PYTHONPATH in bash activate script...\n\t# Delete existing entries (if any)\nifeq ($(OS),Darwin)\n\techo 'Setting up virtualenv on $(OS)...'\n\tsed -i '' '/_OLD_PYTHONPATHp/d' $(VIRTUALENV_DIR)/bin/activate\n\tsed -i '' '/PYTHONPATH=/d' $(VIRTUALENV_DIR)/bin/activate\n\tsed -i '' '/export PYTHONPATH/d' $(VIRTUALENV_DIR)/bin/activate\nelse\n\techo 'Setting up virtualenv on $(OS)...'\n\tsed -i '/_OLD_PYTHONPATHp/d' $(VIRTUALENV_DIR)/bin/activate\n\tsed -i '/PYTHONPATH=/d' $(VIRTUALENV_DIR)/bin/activate\n\tsed -i '/export PYTHONPATH/d' $(VIRTUALENV_DIR)/bin/activate\nendif\n\n\techo '_OLD_PYTHONPATH=$$PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate\n\t#echo 'PYTHONPATH=$$_OLD_PYTHONPATH:$(COMPONENT_PYTHONPATH)' >> $(VIRTUALENV_DIR)/bin/activate\n\techo 'PYTHONPATH=${ROOT_DIR}:$(COMPONENT_PYTHONPATH)' >> $(VIRTUALENV_DIR)/bin/activate\n\techo 'export PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate\n\ttouch $(VIRTUALENV_DIR)/bin/activate\n\n\t# Setup PYTHONPATH in fish activate script...\n\t#echo '' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo 'set -gx _OLD_PYTHONPATH $$PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo 'set -gx PYTHONPATH $$_OLD_PYTHONPATH $(COMPONENT_PYTHONPATH)' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo 'functions -c deactivate old_deactivate' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo 'function deactivate' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '  if test -n $$_OLD_PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '    set -gx PYTHONPATH $$_OLD_PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '    set -e _OLD_PYTHONPATH' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '  end' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '  old_deactivate' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo '  functions -e old_deactivate' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#echo 'end' >> $(VIRTUALENV_DIR)/bin/activate.fish\n\t#touch $(VIRTUALENV_DIR)/bin/activate.fish\n\n\t# debug pip installed packages\n\t$(VIRTUALENV_DIR)/bin/pip list\n\n.PHONY: reset-submodules\nreset-submodules:\n\tgit submodule foreach --recursive git reset --hard\n\n.PHONY: reinit-submodules\nreinit-submodules:\n\t# Unbind all submodules\n\tgit submodule deinit -f .\n\t# Checkout again\n\tgit submodule update --init --recursive\n\n.PHONY: tests\ntests: pytests\n\n.PHONY: pytests\npytests: compilepy3 requirements .flake8 .pylint .pytests-coverage\n\n.PHONY: .pytests\n.pytests: compilepy3 .configgen .generate-api-spec .unit-tests clean\n\n.PHONY: .pytests-coverage\n.pytests-coverage: .unit-tests-coverage-html clean\n\n.PHONY: unit-tests\nunit-tests: requirements .unit-tests\n\n.PHONY: .unit-tests\n.unit-tests:\n\t@echo\n\t@echo \"==================== tests ====================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@mongosh st2-test --eval \"db.dropDatabase();\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_TEST); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running tests in\" $$component; \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; \\\n\t\t ST2TESTS_REDIS_HOST=$(ST2TESTS_REDIS_HOST) \\\n\t\t ST2TESTS_REDIS_PORT=$(ST2TESTS_REDIS_PORT) \\\n\t\t    pytest -rx --verbose \\\n\t\t    $$component/tests/unit || ((failed+=1)); \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\techo \"Done running tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: .run-unit-tests-coverage\nifdef INCLUDE_TESTS_IN_COVERAGE\n.run-unit-tests-coverage: PYTEST_COVERAGE_PACKAGES := $(PYTEST_COVERAGE_PACKAGES),tests.unit\nendif\n.run-unit-tests-coverage:\n\t@echo\n\t@echo \"==================== unit tests with coverage  ====================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@mongosh st2-test --eval \"db.dropDatabase();\"\n\tfailed=0; \\\n\tfor component in $(COMPONENTS_TEST); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running tests in\" $$component; \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; \\\n\t\t ST2TESTS_REDIS_HOST=$(ST2TESTS_REDIS_HOST) \\\n\t\t ST2TESTS_REDIS_PORT=$(ST2TESTS_REDIS_PORT) \\\n\t\t    COVERAGE_FILE=.coverage.unit.$$(echo $$component | tr '/' '.') \\\n\t\t    pytest --verbose $(PYTEST_OPTS) --cov=$$component --cov-branch \\\n\t\t    $$component/tests/unit || ((failed+=1)); \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\techo \"Done running tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: .combine-unit-tests-coverage\n.combine-unit-tests-coverage: .run-unit-tests-coverage\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.unit \\\n\t        coverage combine .coverage.unit.*; \\\n\tfi\n\n.coverage.unit:\n\t@if compgen -G '.coverage.unit.*'; then \\\n\t\tfor coverage_result in $$(compgen -G '.coverage.unit.*'); do \\\n\t\t\techo \"Combining data from $${coverage_result}\"; \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.unit \\\n\t\t\tcoverage combine $${coverage_result}; \\\n\t\tdone; \\\n\telse \\\n\t\techo \"Running unit tests\"; \\\n\t\tmake .combine-unit-tests-coverage; \\\n\tfi\n\n.PHONY: .report-unit-tests-coverage\n.report-unit-tests-coverage: .coverage.unit\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.unit \\\n\t        coverage report; \\\n\tfi\n\n.PHONY: .unit-tests-coverage-html\n.unit-tests-coverage-html: .coverage.unit\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.unit \\\n\t        coverage html; \\\n\tfi\n\n.PHONY: itests\nitests: requirements .itests\n\n.PHONY: .itests\n.itests:\n\t@echo\n\t@echo \"==================== integration tests ====================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@mongosh st2-test --eval \"db.dropDatabase();\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_TEST); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running integration tests in\" $$component; \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; \\\n\t\t    pytest --capture=no --verbose $(PYTEST_OPTS) \\\n\t\t    $$component/tests/integration || ((failed+=1)); \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\techo \"Done running integration tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: .run-integration-tests-coverage\nifdef INCLUDE_TESTS_IN_COVERAGE\n.run-integration-tests-coverage: PYTEST_COVERAGE_PACKAGES := $(PYTEST_COVERAGE_PACKAGES),tests.integration\nendif\n.run-integration-tests-coverage:\n\t@echo\n\t@echo \"================ integration tests with coverage ================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@mongosh st2-test --eval \"db.dropDatabase();\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_TEST); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running integration tests in\" $$component; \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; \\\n\t\t    COVERAGE_FILE=.coverage.integration.$$(echo $$component | tr '/' '.') \\\n\t\t    pytest --capture=no --verbose $(PYTEST_OPTS) --cov=$$component --cov-branch \\\n\t\t    $$component/tests/integration || ((failed+=1)); \\\n\t\techo \"-----------------------------------------------------------\"; \\\n\t\techo \"Done integration running tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\t# NOTE: If you also want to run orquesta tests which seem to have a bunch of race conditions, use\n\t# ci-integration-full target\n#\t@echo\n#\t@echo \"==================== Orquesta integration tests with coverage (HTML reports) ====================\"\n#\t@echo \"The tests assume st2 is running on 127.0.0.1.\"\n#\t@echo\n#\t. $(VIRTUALENV_DIR)/bin/activate; \\\n@#\t\tCOVERAGE_FILE=.coverage.integration.orquesta \\\n@#\t\tpytest --capture=no --verbose $(PYTEST_OPTS) \\\n@#\t\t$(PYTEST_COVERAGE_FLAGS) $(PYTEST_COVERAGE_PACKAGES) st2tests/integration/orquesta || exit 1; \\\n\n.PHONY: .combine-integration-tests-coverage\n.combine-integration-tests-coverage: .run-integration-tests-coverage\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.integration \\\n\t        coverage combine .coverage.integration.*; \\\n\tfi\n\n.coverage.integration:\n\t@if compgen -G '.coverage.integration.*'; then \\\n\t\tfor coverage_result in $$(compgen -G '.coverage.integration.*'); do \\\n\t\t\techo \"Combining data from $${coverage_result}\"; \\\n\t\t\t. $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.integration \\\n\t\t\tcoverage combine $${coverage_result}; \\\n\t\tdone; \\\n\telse \\\n\t\techo \"Running integration tests\"; \\\n\t\tmake .combine-integration-tests-coverage; \\\n\tfi\n\n.PHONY: .report-integration-tests-coverage\n.report-integration-tests-coverage: .coverage.integration\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.integration \\\n\t        coverage report; \\\n\tfi\n\n.PHONY: .integration-tests-coverage-html\n.integration-tests-coverage-html: .coverage.integration\n\t@if [ -n \"$(PYTEST_COVERAGE_FLAGS)\" ]; then \\\n\t    . $(VIRTUALENV_DIR)/bin/activate; COVERAGE_FILE=.coverage.integration \\\n\t        coverage html; \\\n\tfi\n\n.PHONY: .itests-coverage-html\n.itests-coverage-html: .integration-tests-coverage-html\n\n.PHONY: .coverage-combine\n.coverage-combine: .run-unit-tests-coverage .run-integration-tests-coverage\n\t. $(VIRTUALENV_DIR)/bin/activate; coverage combine $(COVERAGE_GLOBS)\n\n# This is a real target, but we need to do our own make trickery in case some\n# but not all of the prerequisites are available\n.coverage:\n\t@NUM_COVERAGE_RESULTS=0; \\\n\tfor coverage_result in $$( \\\n\t\tfor coverage_glob in $(COVERAGE_GLOBS_QUOTED); do \\\n\t\t\tcompgen -G $${coverage_glob}; \\\n\t\tdone; \\\n\t); do \\\n\t\tNUM_COVERAGE_RESULTS=$$(( NUM_COVERAGE_RESULTS+1 )); \\\n\t\techo \"Combining $${coverage_result}: $$NUM_COVERAGE_RESULTS\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; coverage combine $${coverage_result}; \\\n\tdone; \\\n\tif [ $${NUM_COVERAGE_RESULTS} -eq 0 ]; then \\\n\t\tmake .coverage-combine; \\\n\tfi\n\n# @for coverage_result in $(COVERAGE_GLOBS); do \\\n# \t[ -e $${coverage_result} ] || echo \"$${coverage_result} does not exist.\" && continue; \\\n# \techo \"Combining data from $${coverage_result}\"; \\\n# \t. $(VIRTUALENV_DIR)/bin/activate; coverage combine $${coverage_result}; \\\n# done || \\\n# (echo \"Running .coverage-combine\"; make .coverage-combine)\n\n.PHONY: .coverage-report\n.coverage-report: .coverage\n\t. $(VIRTUALENV_DIR)/bin/activate; coverage report\n\n.PHONY: .coverage-html\n.coverage-html: .coverage\n\t. $(VIRTUALENV_DIR)/bin/activate; coverage html\n\n.PHONY: orquesta-itests\norquesta-itests: requirements .orquesta-itests\n\n.PHONY: .orquesta-itests\n.orquesta-itests:\n\t@echo\n\t@echo \"==================== Orquesta integration tests ====================\"\n\t@echo \"The tests assume st2 is running on 127.0.0.1.\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --capture=no --verbose $(PYTEST_OPTS) st2tests/integration/orquesta || exit 1;\n\n.PHONY: .orquesta-itests-coverage-html\n.orquesta-itests-coverage-html:\n\t@echo\n\t@echo \"==================== Orquesta integration tests with coverage (HTML reports) ====================\"\n\t@echo \"The tests assume st2 is running on 127.0.0.1.\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; pytest --capture=no --verbose $(PYTEST_OPTS) --cov=orquesta --cov-branch  st2tests/integration/orquesta || exit 1;\n\n.PHONY: packs-tests\npacks-tests: requirements .packs-tests\n\n.PHONY: .packs-tests\n.packs-tests:\n\t@echo\n\t@echo \"==================== packs-tests ====================\"\n\t@echo\n\t# Install st2common to register metrics drivers\n\t(cd ${ROOT_DIR}/st2common; ${ROOT_DIR}/$(VIRTUALENV_DIR)/bin/python setup.py develop --no-deps)\n\t. $(VIRTUALENV_DIR)/bin/activate; find ${ROOT_DIR}/contrib/* -maxdepth 0 -type d -print0 | xargs -0 -I FILENAME ./st2common/bin/st2-run-pack-tests -c -t -x -p FILENAME\n\n\n.PHONY: runners-tests\nrunners-tests: requirements .runners-tests\n\n.PHONY: .runners-tests\n.runners-tests:\n\t@echo\n\t@echo \"==================== runners-tests ====================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@mongosh st2-test --eval \"db.dropDatabase();\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; pytest --capture=no --verbose $(PYTEST_OPTS) $$component/tests/unit || ((failed+=1)); \\\n\tdone; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: runners-itests\nrunners-itests: requirements .runners-itests\n\n.PHONY: .runners-itests\n.runners-itests:\n\t@echo\n\t@echo \"==================== runners-itests ====================\"\n\t@echo\n\t@echo \"----- Dropping st2-test db -----\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running integration tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; pytest --capture=no --verbose $(PYTEST_OPTS) $$component/tests/integration || ((failed+=1)); \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: .runners-itests-coverage-html\n.runners-itests-coverage-html:\n\t@echo\n\t@echo \"============== runners-itests-coverage-html ==============\"\n\t@echo\n\t@echo \"The tests assume st2 is running on 127.0.0.1.\"\n\t@failed=0; \\\n\tfor component in $(COMPONENTS_RUNNERS); do\\\n\t\techo \"===========================================================\"; \\\n\t\techo \"Running integration tests in\" $$component; \\\n\t\techo \"===========================================================\"; \\\n\t\t. $(VIRTUALENV_DIR)/bin/activate; pytest --capture=no --verbose $(PYTEST_OPTS) \\\n\t\t\t--cov=$$component --cov-report=html $$component/tests/integration || ((failed+=1)); \\\n\tdone; \\\n\techo pytest runs failed=$$failed; \\\n\tif [ $$failed -gt 0 ]; then exit 1; fi\n\n.PHONY: cli\ncli:\n\t@echo\n\t@echo \"=================== Building st2 client ===================\"\n\t@echo\n\tpushd $(CURDIR) && cd st2client && ((python setup.py develop || printf \"\\n\\n!!! ERROR: BUILD FAILED !!!\\n\") || popd)\n\n.PHONY: rpms\nrpms:\n\t@echo\n\t@echo \"==================== rpm ====================\"\n\t@echo\n\trm -Rf ~/rpmbuild\n\t$(foreach COM,$(COMPONENTS), pushd $(COM); make rpm; popd;)\n\tpushd st2client && make rpm && popd\n\n.PHONY: debs\ndebs:\n\t@echo\n\t@echo \"==================== deb ====================\"\n\t@echo\n\trm -Rf ~/debbuild\n\t$(foreach COM,$(COMPONENTS), pushd $(COM); make deb; popd;)\n\tpushd st2client && make deb && popd\n\n\n.PHONY: ci\nci: ci-checks ci-unit ci-integration ci-packs-tests\n\n# NOTE: pylint is moved to ci-compile so we more evenly spread the load across\n# various different jobs to make the whole workflow complete faster\n.PHONY: ci-checks\nci-checks: .generated-files-check .shellcheck .black-check .pre-commit-checks .flake8 check-requirements check-sdist-requirements .st2client-dependencies-check .st2common-circular-dependencies-check circle-lint-api-spec .rst-check .st2client-install-check check-python-packages .st2client-pypi-check\n\n.PHONY: .rst-check\n.rst-check:\n\t@echo\n\t@echo \"==================== rst-check ====================\"\n\t@echo\n\t. $(VIRTUALENV_DIR)/bin/activate; rstcheck --report-level WARNING CHANGELOG.rst\n\n.PHONY: .generated-files-check\n.generated-files-check:\n\t# Verify that all the files which are automatically generated have indeed been re-generated and\n\t# committed\n\t@echo \"==================== generated-files-check ====================\"\n\n\t# 1. Sample config - conf/st2.conf.sample\n\tcp conf/st2.conf.sample /tmp/st2.conf.sample.upstream\n\tmake .configgen\n\tdiff conf/st2.conf.sample /tmp/st2.conf.sample.upstream || (echo \"conf/st2.conf.sample hasn't been re-generated and committed. Please run \\\"make configgen\\\" and include and commit the generated file.\" && exit 1)\n\t# 2. OpenAPI definition file - st2common/st2common/openapi.yaml (generated from\n\t# st2common/st2common/openapi.yaml.j2)\n\tcp st2common/st2common/openapi.yaml /tmp/openapi.yaml.upstream\n\tmake .generate-api-spec\n\tdiff st2common/st2common/openapi.yaml  /tmp/openapi.yaml.upstream || (echo \"st2common/st2common/openapi.yaml hasn't been re-generated and committed. Please run \\\"make generate-api-spec\\\" and include and commit the generated file.\" && exit 1)\n\t# 3. Schemas for the content models - st2common/bin/st2-generate-schemas\n\tcp contrib/schemas/pack.json /tmp/pack.json.upstream\n\tcp contrib/schemas/action.json /tmp/action.json.upstream\n\tcp contrib/schemas/alias.json /tmp/alias.json.upstream\n\tcp contrib/schemas/policy.json /tmp/policy.json.upstream\n\tcp contrib/schemas/rule.json /tmp/rule.json.upstream\n\tmake .schemasgen\n\tdiff contrib/schemas/pack.json /tmp/pack.json.upstream || (echo \"contrib/schemas/pack.json hasn't been re-generated and committed. Please run \\\"make schemasgen\\\" and include and commit the generated file.\" && exit 1)\n\tdiff contrib/schemas/action.json /tmp/action.json.upstream || (echo \"contrib/schemas/pack.json hasn't been re-generated and committed. Please run \\\"make schemasgen\\\" and include and commit the generated file.\" && exit 1)\n\tdiff contrib/schemas/alias.json /tmp/alias.json.upstream || (echo \"contrib/schemas/pack.json hasn't been re-generated and committed. Please run \\\"make schemasgen\\\" and include and commit the generated file.\" && exit 1)\n\tdiff contrib/schemas/policy.json /tmp/policy.json.upstream || (echo \"contrib/schemas/pack.json hasn't been re-generated and committed. Please run \\\"make schemasgen\\\" and include and commit the generated file.\" && exit 1)\n\tdiff contrib/schemas/rule.json /tmp/rule.json.upstream || (echo \"contrib/schemas/pack.json hasn't been re-generated and committed. Please run \\\"make schemasgen\\\" and include and commit the generated file.\" && exit 1)\n\t@echo \"All automatically generated files are up to date.\"\n\n.PHONY: ci-unit\nci-unit: .unit-tests-coverage-html\n\n.PHONY: .ci-prepare-integration\n.ci-prepare-integration:\n\t@echo\n\t@echo \"==================== prepare integration ====================\"\n\t@echo\n\tsudo -E ./scripts/github/prepare-integration.sh\n\n.PHONY: ci-integration-full\nci-integration-full: .ci-prepare-integration .itests-coverage-html  .orquesta-itests-coverage-html\n\n# All integration tests minus orquesta ones\n.PHONY: ci-integration\nci-integration: .ci-prepare-integration .itests-coverage-html\n\n.PHONY: ci-runners\nci-runners: .ci-prepare-integration .runners-itests-coverage-html\n\n.PHONY: ci-orquesta\nci-orquesta: .ci-prepare-integration .orquesta-itests-coverage-html\n\n.PHONY: ci-packs-tests\nci-packs-tests: .packs-tests\n\n.PHONY: ci-compile\nci-compile: check-dependency-conflicts compilepy3 .pylint\n"
        },
        {
          "name": "OWNERS.md",
          "type": "blob",
          "size": 10.125,
          "content": " StackStorm was founded in 2013. After several acquisitions the project has finally joined [The Linux Foundation](https://www.linuxfoundation.org/projects/directory/) in 2019.<br>\n\nThis page lists active project maintainers and their areas of expertise. This can be used for routing PRs, discussions, questions and overall coordination.\n\n* See [GOVERNANCE.md](GOVERNANCE.md) that describes each major role and its responsibilities in detail.\n* See [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) about maintainers standards in front of community.\n* See [CONTRIBUTING.rst](CONTRIBUTING.rst) for general contributing guidelines.\n\n# Leaders ***\n###### 3 vote points\n[@StackStorm/leaders](https://github.com/orgs/StackStorm/teams/leaders) is head of Technical Steering Committee (TSC).\nResponsible for Project Strategy, External Relations, Organizational aspects, Partnerships and Future.\n* Dmitri Zimine ([@dzimine](https://github.com/dzimine/)) <<dzimine@stackstorm.com>>\n  - StackStorm co-founder. External Relations, Leadership.\n\n# Senior Maintainers **\n###### 2 vote points\nSenior [@StackStorm/maintainers](https://github.com/orgs/StackStorm/teams/maintainers) are part of Technical Steering Committee.\nHave deep platform knowledge & experience and demonstrate technical leadership as well as driving the project forward.\n* Amanda McGuinness ([@amanda11](https://github.com/amanda11)), _intive_ <<amanda.mcguinness@intive.com>>\n  - Ansible, Core, deb/rpm packages, CI/CD, Deployments, Release Engineering, Infrastructure, Documentation.\n* Carlos ([@nzlosh](https://github.com/nzlosh)) <<nzlosh@yahoo.com>>\n  - Packaging, Systems, Chatops, Errbot, Community, Discussions, StackStorm Exchange.\n* Jacob Floyd ([@cognifloyd](https://github.com/cognifloyd/)), _Copart_ <<cognifloyd@gmail.com>>\n  - StackStorm Exchange, Kubernetes, ChatOps, Core, Discussions.\n* Tomaz Muraus ([@kami](https://github.com/kami)) <<tomaz@stackstorm.com>>\n  - Core, Performance, API, Scalability, CI/CD, Systems, Deployments, Packaging, OpenSource.\n* Winson Chan ([@m4dcoder](https://github.com/m4dcoder)) <<wcchan@stackstorm.com>>\n  - Core, Orquesta inventor, Workflows, Scalability, API, CI/CD, Release Engineering.\n\n# Maintainers *\n###### 1 vote points\nBeing part of Technical Steering Committee (TSC) [@StackStorm/maintainers](https://github.com/orgs/StackStorm/teams/maintainers) provide significant and reliable value to the project helping it grow and improve through development and maintenance. See [Maintainer Responsibilities](https://github.com/StackStorm/st2/blob/master/GOVERNANCE.md#maintainer-responsibilities) for more info.\n* AJ Jonen ([@guzzijones](https://github.com/guzzijones)), _Cypherint_ <<aaron.jonen@cypherint.com>>\n  - Workflows, st2 Core Performance, Releases.\n* Ankur Singh ([@rush-skills](https://github.com/rush-skills)), _CERN_ <<ankur.singh@cern.ch>>\n  - Community, Puppet, Workflows, HA.\n* Bradley Bishop ([@bishopbm1](https://github.com/bishopbm1)), _Encore_ <<bishopbm1@gmail.com>>\n  - Puppet, StackStorm Exchange.\n* Khushboo Bhatia ([@khushboobhatia01](https://github.com/khushboobhatia01)), _VMware_ <<khushb99@gmail.com>>\n  - StackStorm Core, Workflows.\n* Marcel Weinberg ([@winem](https://github.com/winem)), _CoreMedia_ <<mweinberg-os@email.de>>\n  - Systems, Core, CI/CD, Docker, Community.\n* Mark Mercado ([@mamercad](https://github.com/mamercad)), _DigitalOcean_ <<mmercado@digitalocean.com>>\n  - Ansible, Docker, K8s, StackStorm Exchange. [StackStorm Adoption](https://github.com/StackStorm/st2/pull/5836)\n* Mick McGrath ([@mickmcgrath13](https://github.com/mickmcgrath13)), _Bitovi_ <<mick@bitovi.com>>\n  - Systems, ST2 Exchange. [Case Study](https://stackstorm.com/case-study-bitovi/).\n\n--------\n\n# Contributors\nContributors are using and occasionally contributing back to the project, might be active in conversations or express their opinion on the project’s direction.\nThey're not part of the TSC voting process, but appreciated for their contribution, involvement and may become Maintainers in the future depending on their effort and involvement. See [How to become a Maintainer?](https://github.com/StackStorm/st2/blob/master/GOVERNANCE.md#how-to-become-a-maintainer)\n[@StackStorm/contributors](https://github.com/orgs/StackStorm/teams/contributors) are invited to StackStorm Github organization and have permissions to help triage the Issues and review PRs.\n* Anand Patel ([@arms11](https://github.com/arms11)), _VMware_ - Docker, Kubernetes.\n* David Culbreth ([@AndroxxTraxxon](https://github.com/AndroxxTraxxon)) - _H-E-B_ - StackStorm core, Orquesta.\n* Harsh Nanchahal ([@hnanchahal](https://github.com/hnanchahal)), _Starbucks_ - Core, Docker, Kubernetes.\n* Hiroyasu Ohyama ([@userlocalhost](https://github.com/userlocalhost)) - Orquesta, Workflows, st2 Japan Community. [Case Study](https://stackstorm.com/case-study-dmm/).\n* Jeremiah Millay ([@floatingstatic](https://github.com/floatingstatic)), _Fastly_ - Core, StackStorm Exchange.\n* Kirill Enykeev ([@enykeev](https://github.com/enykeev)), _SentinelOne_ - ex Stormer. WebUI, Workflow Designer.\n* Philipp Homberger ([@philipphomberger](https://github.com/philipphomberger)), _Schwarz IT KG_ - Core, StackStorm Exchange.\n* Rick Kauffman ([@xod442](https://github.com/xod442)), _HPE_ - Community, HOWTOs, Blogs, Publications, Docker.\n* Ronnie Hoffmann ([@ZoeLeah](https://github.com/ZoeLeah)), _Schwarz IT KG_ - Docker, K8s.\n* Scott Swann ([@jk464](https://github.com/jk464)) - StackStorm core, Security.\n* Sheshagiri Rao Mallipedhi ([@sheshagiri](https://github.com/sheshagiri)) - Docker, Core, StackStorm Exchange.\n* Shital Raut ([@shital-orchestral](https://github.com/shital-orchestral)), _Orchestral.ai_ - Web UI.\n* Sravanthi Konduru ([@sravs-dev](https://github.com/sravs-dev)), _Salesforce_, - Core, StackStorm Exchange.\n* Tristan Struthers ([@trstruth](https://github.com/trstruth)) - Docker, K8s, Orquesta, Community.\n* Yuri Dubler ([@lm-ydubler](https://github.com/lm-ydubler)) - _LogicMonitor_ - StackStorm Exchange, CI.\n\n# Friends\nPeople that are currently not very active maintainers/contributors but who participated in and formed the project we have today.\nCommunity Members, [StackStorm Alumni](https://github.com/orgs/StackStorm/teams/alumni) and Influencers.\nThank you, Friends!\n* Anthony Shaw ([@tonybaloney](https://github.com/tonybaloney)) - Contribution via Ideas, Feedback, ChatOps improvements, core Architecture, Community and even [Marketing](https://news.ycombinator.com/item?id=14368748). [Case Study](https://stackstorm.com/case-study-dimension-data/).\n* Andy Moore ([@AndyMoore](https://github.com/AndyMoore)) - Community, StackStorm Exchange packs, Kubernetes.\n* Anirudh Rekhi ([@humblearner](https://github.com/humblearner)) - ex Stormer. Systems, CI/CD, DevOps, Infrastructure.\n* blag ([@blag](https://github.com/blag))\n  - ChatOps, StackStorm Exchange, Community, Documentation, CI/CD.\n* Denis Barishev ([@dennybaa](https://github.com/dennybaa)) - ex Stormer. Re-architeced StackStorm installer via deb/rpm packages, made it stable, repeatable, fixed first platform pain points.\n* Ed Medvedev ([@emedvedev](https://github.com/emedvedev)) - ex Stormer. Made WebUI slick and ChatOps awesome, discovered and implemented today's [StackStorm Exchange](https://exchange.stackstorm.org/).\n* Eugen Cusmaunsa ([@armab](https://github.com/armab)) - Ex Stormer. [StackStorm TSC Governance](https://github.com/StackStorm/st2/blob/master/GOVERNANCE.md) creator, Open Source Community builder. Deployments, Docker, K8s, Ansible, Vagrant, deb/rpm, CI/CD, Infrastructure, Release Engineering.\n* Evan Powell ([@epowell101](https://github.com/epowell101)) - StackStorm co-founder, first CEO, Stormer forever.\n* Michael Ward ([@mward29](https://github.com/mward29)) - StackStorm Exchange, Community, Docker & K8s. [Case Study](https://stackstorm.com/case-study-pearson/).\n* Matthew Stone ([@bigmstone](https://github.com/bigmstone)) - ex Stormer. Project Leadership and StackStorm's [Robot Arm :)](https://twitter.com/Stack_Storm/status/1217056819736203270).\n* Matt Oswalt ([@Mierdin](https://github.com/Mierdin)) - ex Stormer. Invented, architected and implemented [st2 Inquiries](https://docs.stackstorm.com/inquiries.html).\n* Patrick Hoolboom ([@DoriftoShoes](https://github.com/DoriftoShoes)) - early Stormer. DevOps thought Leadership, ST2 Architecture, first Infrastructure, StackStorm Workflows to release StackStorm, e2e tests.\n* James Fryman ([@jfryman](https://github.com/jfryman)) - early Stormer. [StackStorm ChatOps](https://www.youtube.com/watch?v=IhzxnY7FIvg) father and Thought Leader.\n* Jinping Han ([@jinpingh](https://github.com/jinpingh)) - ex Stormer. Community, Core, Tests, Pack Dependencies.\n* Johan Dahlberg ([@johandahlberg](https://github.com/johandahlberg)) - Using st2 for Bioinformatics/Science project, providing feedback & contributions in Ansible, Community, Workflows. [Case Study](https://stackstorm.com/case-study-scilifelab/).\n* Johan Hermansson ([@johanherman](https://github.com/johanherman)) - Using st2 for Bioinformatics/Science project, feedback & contributions in Ansible, Community, Workflows. [Case Study](https://stackstorm.com/case-study-scilifelab/).\n* JP Bourget ([@punkrokk](https://github.com/punkrokk)) - Systems, deb/rpm, Deployments, Community, StackStorm Exchange, SecOps, CircleCI. Used ST2 for Security Orchestration.\n* Jon Middleton ([@jjm](https://github.com/jjm)) - StackStorm Exchange, Core, Discussions.\n* Lakshmi Kannan ([@lakshmi-kannan](https://github.com/lakshmi-kannan)) - early Stormer. Initial Core platform architecture, scalability, reliability, Team Leadership during the project hard times.\n* Lindsay Hill ([@LindsayHill](https://github.com/LindsayHill)) - ex StackStorm product manager that made a significant impact building an ecosystem we see today.\n* Manas Kelshikar ([@manasdk](https://github.com/manasdk)) - ex Stormer. Developed (well) early core platform features.\n* Nick Maludy ([@nmaludy](https://github.com/nmaludy)) - Community, Core, Systems, Infrastructure, StackStorm Exchange, Puppet deployment. [Case Study](https://stackstorm.com/case-study-encore/).\n* Vineesh Jain ([@VineeshJain](https://github.com/VineeshJain)) - ex Stormer. Community, Tests, Core, QA.\n* Warren Van Winckel ([@warrenvw](https://github.com/warrenvw)) - ex Stormer. Docker, Kubernetes, Vagrant, Infrastructure.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.50390625,
          "content": "[![StackStorm](https://github.com/stackstorm/st2/raw/master/stackstorm_logo.png)](https://www.stackstorm.com)\n\n**StackStorm** is a platform for integration and automation across services and tools, taking actions in response to events. Learn more at [www.stackstorm.com](http://www.stackstorm.com/product).\n\n[![Build Status](https://github.com/StackStorm/st2/actions/workflows/ci.yaml/badge.svg)](https://github.com/StackStorm/st2/actions/workflows/ci.yaml)\n[![Packages Build Status](https://circleci.com/gh/StackStorm/st2/tree/master.svg?style=shield)](https://circleci.com/gh/StackStorm/st2)\n[![Codecov](https://codecov.io/github/StackStorm/st2/badge.svg?branch=master&service=github)](https://codecov.io/github/StackStorm/st2?branch=master)\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1833/badge)](https://bestpractices.coreinfrastructure.org/projects/1833)\n![Python 3.6,3.8](https://img.shields.io/badge/python-3.6,%203.8-blue)\n[![Apache Licensed](https://img.shields.io/github/license/StackStorm/st2)](LICENSE)\n[![Join our community Slack](https://img.shields.io/badge/slack-stackstorm-success.svg?logo=slack)](https://stackstorm.com/community-signup)\n[![deb/rpm packages](https://img.shields.io/badge/deb/rpm-Packagecloud-%236366f1)](https://packagecloud.io/StackStorm/)\n[![Code Search](https://img.shields.io/badge/code%20search-Sourcegraph-%2300B4F2?logo=sourcegraph)](https://sourcegraph.com/stackstorm)\n[![GitHub Discussions](https://img.shields.io/github/discussions/stackstorm/st2)](https://github.com/StackStorm/st2/discussions)\n[![Twitter Follow](https://img.shields.io/twitter/follow/StackStorm?style=social)](https://twitter.com/StackStorm/)\n\n---\n\n## TL;DR\n\n* Install Get yourself a clean 64-bit Linux box that fits the [system requirements](https://docs.stackstorm.com/install/system_requirements.html). Run the installer script:\n\n   ```bash\n   curl -sSL https://stackstorm.com/packages/install.sh | bash -s -- --user=st2admin --password=Ch@ngeMe\n   ```\n* Read the docs: [https://docs.stackstorm.com/index.html](https://docs.stackstorm.com/install/index.html)\n* Questions? Check out [forum.stackstorm.com](https://forum.stackstorm.com/)\n* Or join our [Slack community](https://stackstorm.com/community-signup)\n\n## StackStorm Overview\n\n[![StackStorm 5 min Intro Video](https://cloud.githubusercontent.com/assets/1294734/10356016/16278d0a-6d27-11e5-987d-c8a7629a69ed.png)](https://www.youtube.com/watch?v=pzZws3ftDtA)\n\n### About\n\nStackStorm is a platform for integration and automation across services and tools. It ties together your existing infrastructure and application environment so you can more easily automate that environment -- with a particular focus on taking actions in response to events.\n\nStackStorm helps automate common operational patterns. Some examples are:\n\n* **Facilitated Troubleshooting** - triggering on system failures captured by Nagios, Sensu, New Relic and other monitoring, running a series of diagnostic checks on physical nodes, OpenStack or Amazon instances, and application components, and posting results to a shared communication context, like Slack or JIRA.\n* **Automated remediation** - identifying and verifying hardware failure on OpenStack compute node, properly evacuating instances and emailing VM about potential downtime, but if anything goes wrong - freezing the workflow and calling PagerDuty to wake up a human.\n* **Continuous deployment** - build and test with Jenkins, provision a new AWS cluster, turn on some traffic with the load balancer, and roll-forth or roll-back based on NewRelic app performance data.\n\nStackStorm helps you compose these and other operational patterns as rules and workflows or actions; and these rules and workflows - the content within the StackStorm platform - are stored *as code* which means they support the same approach to collaboration that you use today for code development and can be shared with the broader open source community via [StackStorm Exchange](https://exchange.stackstorm.org).\n\n### Who is using StackStorm?\n\nSee the list of known StackStorm [ADOPTERS.md](/ADOPTERS.md) and [Thought Leaders](https://stackstorm.com/stackstorm-thought-leaders/).\n\n### How it works\n\n#### StackStorm architecture\n\n![StackStorm architecture diagram](https://user-images.githubusercontent.com/597113/92291633-6b5aae00-eece-11ea-912e-3bf977aa3cea.png)\n\nStackStorm plugs into the environment via an extensible set of adapters: sensors and actions.\n\n* **Sensors** are Python plugins for inbound integration that watch for events from external systems and fire a StackStorm trigger when an event happens.\n\n* **Triggers** are StackStorm representations of external events. There are generic triggers (e.g., timers, webhooks) and integration triggers (e.g., Sensu alert, JIRA issue updated). A new trigger type can be defined by writing a sensor plugin.\n\n* **Actions** are StackStorm outbound integrations. There are generic actions (SSH, HTTP request), integrations (OpenStack, Docker, Puppet), or custom actions. Actions are either Python plugins, or any scripts, consumed into StackStorm by adding a few lines of metadata. Actions can be invoked directly by user via CLI, API, or the web UI, or used and called as part of automations - rules and workflows.\n\n* **Rules** map triggers to actions (or to workflows), applying matching criterias and map trigger payload data to action inputs.\n\n* **Workflows** stitch actions together into \"uber-actions\", defining the order, transition conditions, and passing context data from one action to the next. Most automations are multi-step (eg: more than one action). Workflows, just like \"atomic\" actions, are available in the action library, and can be invoked manually or triggered by rules.\n\n* **Packs** are the units of content deployment. They simplify the management and sharing of StackStorm pluggable content by grouping integrations (triggers and actions) and automations (rules and workflows). A growing number of packs is available on the StackStorm Exchange. Users can create their own packs,  share them on GitHub, or submit them to the StackStorm Exchange organization.\n\n* **Audit trail** is the historical list of action executions, manual or automated, and is recorded and stored with full details of triggering context and execution results. It is also captured in audit logs for integrating with external logging and analytical tools: LogStash, Splunk, statsd, or syslog.\n\nStackStorm is a service with modular architecture. It is comprised of loosely coupled microservice components that communicate over a message bus, and scales horizontally to deliver automation at scale. StackStorm has a full REST API, CLI client, and web UI for admins and users to operate it locally or remotely, as well as Python client bindings for developer convenience.\n\nStackStorm is an established project and remains actively developed by a broad community.\n\n## Documentation\n\nAdditional documentation, including installation procedures, action/rule/workflow authoring, and how to setup and use triggers/sensors can be found at [https://docs.stackstorm.com](https://docs.stackstorm.com).\n\n## Hacking / Contributing\n\nTo set up a development environment and run StackStorm from sources, follow [these instructions](https://docs.stackstorm.com/development/sources.html).\n\nFor information on how to contribute, our style guide, coding conventions and more,\nplease visit the [Development section](https://docs.stackstorm.com/development/index.html)\nin our documentation.\n\n## Security\n\nIf you believe you found a security issue or a vulnerability, please send a description of it to\nour private mailing list at info [at] stackstorm [dot] com.\n\nOnce you've submitted an issue, you should receive an acknowledgment from one our of team members\nin 48 hours or less. If further action is necessary, you may receive additional follow-up emails.\n\nFor more information, please refer to https://docs.stackstorm.com/latest/security.html\n\n## Copyright, License, and Contributor Agreement\n\nCopyright 2020 The StackStorm Authors.\nCopyright 2019 Extreme Networks, Inc.\nCopyright 2014-2018 StackStorm, Inc.\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this work except in compliance with the License. You may obtain a copy of the License in the [LICENSE](LICENSE) file, or at:\n\n[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n\nBy contributing you agree that these contributions are your own (or approved by your employer) and you grant a full, complete, irrevocable copyright license to all users and developers of the project, present and future, pursuant to the license of the project.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.466796875,
          "content": "# Security Policies and Procedures\n\nIf you believe you found a security issue or a vulnerability, please send a description of it to\nour private mailing list at info [at] stackstorm [dot] com.\n\nOnce you've submitted an issue, you should receive an acknowledgment from one our of team members\nin 48 hours or less. If further action is necessary, you may receive additional follow-up emails.\n\nFor more information, please refer to https://docs.stackstorm.com/latest/security.html\n"
        },
        {
          "name": "codecov.yml",
          "type": "blob",
          "size": 0.630859375,
          "content": "codecov:\n  notify:\n    require_ci_to_pass: yes\n\ncoverage:\n  precision: 2         # decimal places to display: 0 <= value <= 4\n  round: nearest\n  range: 50...90      # custom range of coverage colors from red -> yellow -> green\n\n  status:\n    project:\n      default:\n        threshold: 2%\n    patch: yes\n    changes: no\n\n  notify:\n    slack:\n      default:\n        url:  \"secret:8cqmX1vD14d+NVA6rkwI6rkG8oxaeF5U3WmH23ByQbxMQUqZU3wIVpFnktSoLnvucW2asoHjqpqVmUF29OJZKfEdldBdYS6WL68/JIJQi/Rk/+6NYypm9tD2dNSgiNciHmyjRBUZy2JjxFvxscQj/drg9cPAdGra1b/YLoq9UkQ=\"\n        threshold: 2%\n\n# comments are useless, considering wrong coverage reports\ncomment: no\n"
        },
        {
          "name": "conf",
          "type": "tree",
          "content": null
        },
        {
          "name": "conftest.py",
          "type": "blob",
          "size": 3.0185546875,
          "content": "# Copyright 2022 The StackStorm Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport hashlib\nfrom typing import Iterable, List, Sequence\n\nfrom _pytest import nodes\nfrom _pytest.config import create_terminal_writer\n\n\ndef pytest_configure(config):\n    import sys\n\n    sys._called_from_test = True\n\n\ndef pytest_unconfigure(config):\n    import sys\n\n    del sys._called_from_test\n\n\n# TODO: Remove everything below here when we get rid of the Makefile\n# everything below this is based on (MIT licensed) by mark-adams:\n# https://github.com/mark-adams/pytest-test-groups/blob/5eca437ef95d23e8674b9e8765ce16005159d334/pytest_test_groups/__init__.py\n# with some inspiration from (MIT licensed) by Adam Gleave:\n# https://github.com/AdamGleave/pytest-shard/blob/64610a08dac6b0511b6d51cf895d0e1040d162ad/pytest_shard/pytest_shard.py\n\n\ndef get_group(\n    items: Iterable[nodes.Node], group_count: int, group_id: int\n) -> Sequence[nodes.Node]:\n    \"\"\"Get the items from the passed in group based on group count.\"\"\"\n    if not (0 <= group_id < group_count):\n        raise ValueError(\"Invalid test-group argument\")\n\n    def get_group_id(node: nodes.Node) -> int:\n        # use the file path instead of node id, so all tests in a file run together.\n        path_bytes = str(node.path).encode()\n        digest_bytes = hashlib.sha256(path_bytes).digest()\n        digest = int.from_bytes(digest_bytes, \"little\")\n        return digest % group_count\n\n    return [item for item in items if get_group_id(item) == group_id]\n\n\ndef pytest_addoption(parser):\n    group = parser.getgroup(\"split your tests into evenly sized groups and run them\")\n    group.addoption(\n        \"--test-group-count\",\n        dest=\"test-group-count\",\n        type=int,\n        default=-1,\n        help=\"The number of groups to split the tests into\",\n    )\n    group.addoption(\n        \"--test-group\",\n        dest=\"test-group\",\n        type=int,\n        default=-1,\n        help=\"The group of tests that should be executed\",\n    )\n\n\ndef pytest_collection_modifyitems(session, config, items: List[nodes.Node]):\n    group_count = config.getoption(\"test-group-count\")\n    group_id = config.getoption(\"test-group\")\n\n    if group_count < 1 or group_id < 0:\n        return\n\n    items[:] = get_group(items, group_count, group_id)\n\n    terminal_reporter = config.pluginmanager.get_plugin(\"terminalreporter\")\n    terminal_writer = create_terminal_writer(config)\n    message = terminal_writer.markup(\n        \"Running test group #{0} ({1} tests)\\n\".format(group_id, len(items)),\n        yellow=True,\n    )\n    terminal_reporter.write(message)\n"
        },
        {
          "name": "contrib",
          "type": "tree",
          "content": null
        },
        {
          "name": "dev_docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "fixed-requirements.txt",
          "type": "blob",
          "size": 2.4970703125,
          "content": "# Package versions fixed (pinned) for the whole st2 project.\n# Important: Keep version constraints synchronised with the below repositories:\n# - https://github.com/StackStorm/st2docs\n# - https://github.com/StackStorm/orquesta\n# - https://github.com/StackStorm/st2-auth-ldap\n# - https://github.com/StackStorm/st2-rbac-backend\n# ----------------------------------------------------------------------\n# Note: amqp is used by kombu\namqp==5.3.1\napscheduler==3.11.0\nchardet==5.2.0\ncffi==1.17.1\ncryptography==43.0.3\neventlet==0.38.2\nflex==6.14.1\n# Note: installs gitpython==3.1.37 (security fixed) under py3.8 and gitpython==3.1.18 (latest available, vulnerable) under py3.6\n# TODO: Pin to 3.1.37 or higher after dropping python3.6 support\ngitpython==3.1.43\n# Needed by gitpython, old versions used to bundle it\ngitdb==4.0.11\n# Note: greenlet is used by eventlet\ngreenlet==3.1.1\ngunicorn==23.0.0\njsonpath-rw==1.4.0\njsonschema==3.2.0\nkombu==5.4.2\nlockfile==0.12.2\nmongoengine==0.29.1\nnetworkx==3.1\n# jsonpath-rw is the only thing that depends on decorator (a transitive dep)\ndecorator==5.1.1\n# 202403: Bump oslo.config for py3.10 support.\noslo.config==9.6.0\noslo.utils==7.3.0\n# paramiko 2.11.0 is needed by cryptography > 37.0.0\nparamiko==3.5.0\npasslib==1.7.4\n# 202403: bump to 3.0.43 for py3.10 support\nprompt-toolkit==3.0.48\npyinotify==0.9.6 ; platform_system==\"Linux\"\npymongo==4.6.3\npyparsing==3.1.4\nzstandard==0.23.0\n# pyOpenSSL 23.1.0 supports cryptography up to 40.0.x\n#pyOpenSSL==23.1.0\n# 202403: switch from python-editor to editor for py3.10 support\neditor==1.6.6\n# editor dependency, required here for inclusion in st2client setup.py\npygments==2.18.0\npython-keyczar==0.716\npytz==2024.2\npywinrm==0.5.0\npyyaml==6.0.2\nredis==5.2.1\nrequests==2.32.3\nretrying==1.3.4\nroutes==2.5.1\nsemver==3.0.2\nsix==1.17.0\nargparse==1.4.0\nargcomplete==3.5.2\nprettytable==3.10.2\nimportlib-metadata==7.1.0\ntyping-extensions==4.12.2\n# NOTE: sseclient has various issues which sometimes hang the connection for a long time, etc.\nsseclient-py==1.8.0\nstevedore==5.3.0\ntenacity==9.0.0\ntooz==6.3.0\n# Note: virtualenv embeds wheels for pip, wheel, and setuptools. So pinning virtualenv pins those as well.\n# virtualenv==20.27.2 (<21) has pip==24.3.1 wheel==0.45.1 setuptools==75.3.0\n# lockfiles/st2.lock has pip==24.3.1 wheel==0.45.1 setuptools==75.3.0\nvirtualenv==20.28.0\nwebob==1.8.9\nwebtest==3.0.1\nzake==0.2.2\n# test requirements below\nbcrypt==4.2.1\njinja2==3.1.4\nmock==5.1.0\npytest==7.0.1\npsutil==6.1.1\npython-dateutil==2.9.0.post0\npython-statsd==2.1.0\norjson==3.10.12\nzipp==3.20.2\n"
        },
        {
          "name": "get-pants.sh",
          "type": "blob",
          "size": 4.8076171875,
          "content": "#!/usr/bin/env bash\n# Copyright 2023 Pants project contributors (see CONTRIBUTORS.md).\n# Licensed under the Apache License, Version 2.0 (see LICENSE).\n\nset -euo pipefail\n\nCOLOR_RED=\"\\x1b[31m\"\nCOLOR_GREEN=\"\\x1b[32m\"\nCOLOR_YELLOW=\"\\x1b[33m\"\nCOLOR_RESET=\"\\x1b[0m\"\n\nfunction log() {\n  echo -e \"$@\" 1>&2\n}\n\nfunction die() {\n  (($# > 0)) && log \"${COLOR_RED}$*${COLOR_RESET}\"\n  exit 1\n}\n\nfunction green() {\n  (($# > 0)) && log \"${COLOR_GREEN}$*${COLOR_RESET}\"\n}\n\nfunction warn() {\n  (($# > 0)) && log \"${COLOR_YELLOW}$*${COLOR_RESET}\"\n}\n\nfunction check_cmd() {\n  local cmd=\"$1\"\n  command -v \"$cmd\" > /dev/null || die \"This script requires the ${cmd} binary to be on the PATH.\"\n}\n\nhelp_url=\"https://www.pantsbuild.org/docs/getting-help\"\n\n_GC=()\n\nfunction gc() {\n  if (($# > 0)); then\n    check_cmd rm\n    _GC+=(\"$@\")\n  else\n    rm -rf \"${_GC[@]}\"\n  fi\n}\n\ntrap gc EXIT\n\ncheck_cmd uname\n\nfunction calculate_os() {\n  local os\n\n  os=\"$(uname -s)\"\n  if [[ \"${os}\" =~ [Ll]inux ]]; then\n    echo linux\n  elif [[ \"${os}\" =~ [Dd]arwin ]]; then\n    echo macos\n  elif [[ \"${os}\" =~ [Ww]in|[Mm][Ii][Nn][Gg] ]]; then\n    # Powershell reports something like: Windows_NT\n    # Git bash reports something like: MINGW64_NT-10.0-22621\n    echo windows\n  else\n    die \"Pants is not supported on this operating system (${os}). Please reach out to us at ${help_url} for help.\"\n  fi\n}\n\nOS=\"$(calculate_os)\"\n\ncheck_cmd basename\nif [[ \"${OS}\" == \"windows\" ]]; then\n  check_cmd pwsh\nelse\n  check_cmd curl\nfi\n\nfunction fetch() {\n  local url=\"$1\"\n  local dest_dir=\"$2\"\n\n  local dest\n  dest=\"${dest_dir}/$(basename \"${url}\")\"\n\n  if [[ \"${OS}\" == \"windows\" ]]; then\n    pwsh -c \"Invoke-WebRequest -OutFile $dest -Uri $url\"\n  else\n    curl --proto '=https' --tlsv1.2 -sSfL -o \"${dest}\" \"${url}\"\n  fi\n}\n\nif [[ \"${OS}\" == \"macos\" ]]; then\n  check_cmd shasum\nelse\n  check_cmd sha256sum\nfi\n\nfunction sha256() {\n  if [[ \"${OS}\" == \"macos\" ]]; then\n    shasum --algorithm 256 \"$@\"\n  else\n    sha256sum \"$@\"\n  fi\n}\n\ncheck_cmd mktemp\n\nfunction install_from_url() {\n  local url=\"$1\"\n  local dest=\"$2\"\n\n  local workdir\n  workdir=\"$(mktemp -d)\"\n  gc \"${workdir}\"\n\n  fetch \"${url}.sha256\" \"${workdir}\"\n  fetch \"${url}\" \"${workdir}\"\n  (\n    cd \"${workdir}\"\n    sha256 -c --status ./*.sha256 ||\n      die \"Download from ${url} did not match the fingerprint at ${url}.sha256\"\n  )\n  rm \"${workdir}/\"*.sha256\n  if [[ \"${OS}\" == \"macos\" ]]; then\n    mkdir -p \"$(dirname \"${dest}\")\"\n    install -m 755 \"${workdir}/\"* \"${dest}\"\n  else\n    install -D -m 755 \"${workdir}/\"* \"${dest}\"\n  fi\n}\n\nfunction calculate_arch() {\n  local arch\n\n  arch=\"$(uname -m)\"\n  if [[ \"${arch}\" =~ x86[_-]64 ]]; then\n    echo x86_64\n  elif [[ \"${arch}\" =~ arm64|aarch64 ]]; then\n    echo aarch64\n  else\n    die \"Pants is not supported for this chip architecture (${arch}). Please reach out to us at ${help_url} for help.\"\n  fi\n}\n\ncheck_cmd cat\n\nfunction usage() {\n  cat << EOF\nUsage: $0\n\nInstalls the pants launcher binary.\n\nYou only need to run this once on a machine when you do not have \"pants\"\navailable to run yet.\n\nThe pants binary takes care of managing and running the underlying\nPants version configured in \"pants.toml\" in the surrounding Pants-using\nproject.\n\nOnce installed, if you want to update your \"pants\" launcher binary, use\n\"SCIE_BOOT=update pants\" to get the latest release or\n\"SCIE_BOOT=update pants --help\" to learn more options.\n\n-h | --help: Print this help message.\n\n-d | --bin-dir:\n  The directory to install the scie-pants binary in, \"~/.local/bin\" by default.\n\n-b | --base-name:\n  The name to use for the scie-pants binary, \"pants\" by default.\n\n-V | --version:\n  The version of the scie-pants binary to install, the latest version by default.\n  The available versions can be seen at:\n    https://github.com/pantsbuild/scie-pants/releases\n\nEOF\n}\n\nbin_dir=\"${HOME}/.local/bin\"\nbase_name=\"pants\"\nversion=\"latest/download\"\nwhile (($# > 0)); do\n  case \"$1\" in\n    --help | -h)\n      usage\n      exit 0\n      ;;\n    --bin-dir | -d)\n      bin_dir=\"$2\"\n      shift\n      ;;\n    --base-name | -b)\n      base_name=\"$2\"\n      shift\n      ;;\n    --version | -V)\n      version=\"download/v$2\"\n      shift\n      ;;\n    *)\n      usage\n      die \"Unexpected argument $1\\n\"\n      ;;\n  esac\n  shift\ndone\n\nARCH=\"$(calculate_arch)\"\nURL=\"https://github.com/pantsbuild/scie-pants/releases/${version}/scie-pants-${OS}-${ARCH}\"\ndest=\"${bin_dir}/${base_name}\"\n\nlog \"Downloading and installing the pants launcher ...\"\ninstall_from_url \"${URL}\" \"${dest}\"\ngreen \"Installed the pants launcher from ${URL} to ${dest}\"\nif ! command -v \"${base_name}\" > /dev/null; then\n  warn \"${dest} is not on the PATH.\"\n  log \"You'll either need to invoke ${dest} explicitly or else add ${bin_dir} to your shell's PATH.\"\nfi\n\ngreen \"\\nRunning \\`pants\\` in a Pants-enabled repo will use the version of Pants configured for that repo.\"\ngreen \"In a repo not yet Pants-enabled, it will prompt you to set up Pants for that repo.\"\n"
        },
        {
          "name": "lint-configs",
          "type": "tree",
          "content": null
        },
        {
          "name": "lockfiles",
          "type": "tree",
          "content": null
        },
        {
          "name": "logs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pants",
          "type": "blob",
          "size": 0.296875,
          "content": "#!/usr/bin/env bash\n\nset -eou pipefail\n\necho 'WARNING: Using ./pants is deprecated.' >&2\necho 'Once installed, please use `pants` instead of `./pants`.' >&2\n\nif ! command -v pants >/dev/null; then\n  echo 'Now running `./get-pants.sh` to install `pants` ...' >&2\n  echo\n  ./get-pants.sh\nfi\n\nexec pants $@\n"
        },
        {
          "name": "pants-plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "pants.ci.toml",
          "type": "blob",
          "size": 1.130859375,
          "content": "# This config is for CI. It extends the config in pants.toml.\n# See https://www.pantsbuild.org/stable/docs/using-pants/using-pants-in-ci\n\n[GLOBAL]\n# Colors often work in CI, but the shell is usually not a TTY so Pants\n# doesn't attempt to use them by default.\ncolors = true\n\n# GitHub Actions cache URL and token are set via environment variables\nremote_provider = \"experimental-github-actions-cache\"\nremote_cache_read = true\nremote_cache_write = true\n\n# https://www.pantsbuild.org/stable/reference/global-options#ignore_warnings\nignore_warnings = [\n    # remote cache errors caused by GitHub rate-limits are not helpful\n    \"Failed to read from remote cache\",\n    \"Failed to write to remote cache\",\n]\n\n[stats]\n# \"print metrics of your cache's performance at the end of the run,\n# including the number of cache hits and the total time saved thanks\n# to caching\"\nlog = true\n\n[test]\n# Have pants automatically retry tests that fail to help with flaky tests.\n# https://www.pantsbuild.org/stable/docs/using-pants/using-pants-in-ci#tip-automatically-retry-failed-tests\n# https://www.pantsbuild.org/stable/reference/goals/test#attempts_default\nattempts_default = 3\n"
        },
        {
          "name": "pants.toml",
          "type": "blob",
          "size": 10.462890625,
          "content": "[anonymous-telemetry]\n# This is opt-in by default, but we explicitly disable here as well.\nenabled = false\n# repo_id here allows individuals to opt-in on their machine\n# To opt-in, use ~/.pants.rc or envrc to set [anonymous-telemetry].enabled=true\nrepo_id = \"de0dea7a-9f6a-4c6e-aa20-6ba5ad969b8a\"\n\n[GLOBAL]\npants_version = \"2.23.0a0\"\npythonpath = [\"%(buildroot)s/pants-plugins\"]\nbuild_file_prelude_globs = [\"pants-plugins/macros.py\"]\nbackend_packages = [\n  # https://www.pantsbuild.org/stable/docs/using-pants/validating-dependencies\n  \"pants.backend.experimental.visibility\",\n\n  # python\n  \"pants.backend.python\",\n  \"pants.backend.experimental.python\", # activates twine `publish` support\n  \"pants.backend.experimental.python.framework.stevedore\",\n  \"pants.backend.python.mixed_interpreter_constraints\",\n  \"pants.backend.python.lint.bandit\",\n  \"pants.backend.python.lint.black\",\n  \"pants.backend.python.lint.flake8\",\n  \"pants.backend.python.lint.pylint\",\n\n  # shell\n  \"pants.backend.shell\",\n  \"pants.backend.shell.lint.shellcheck\",\n\n  # internal plugins in pants-plugins/\n  \"pants.backend.plugin_development\",\n  \"api_spec\",\n  \"pack_metadata\",\n  \"release\",\n  \"sample_conf\",\n  \"schemas\",\n  \"uses_services\",\n]\n# pants ignores files in .gitignore, .*/ directories, /dist/ directory, and __pycache__.\npants_ignore.add = [\n  # TODO: remove these once we start building wheels with pants.\n  \"dist_utils.py\",\n  \"test_dist_utils.py\",\n  \"setup.py\",\n  # keep tailor from using legacy requirements files (not for pants)\n  \"contrib/examples/requirements.txt\",\n  \"contrib/hello_st2/requirements.txt\",\n  \"contrib/runners/*/in-requirements.txt\",\n  \"contrib/runners/*/requirements.txt\",\n  \"st2*/in-requirements.txt\",\n  \"st2*/requirements.txt\",\n  \"st2common/tests/fixtures/requirements-used-for-tests.txt\",\n  \"/fixed-requirements.txt\",\n  \"/test-requirements.txt\",\n  # ignore requirements.txt for now, preferring interim files that are decoupled from\n  # legacy requirements files generation: requirements-pants.txt & lockfiles/st2-constraints.txt\n  \"/requirements.txt\",\n]\n\n[source]\n# recording each pack individually under root patterns is not great, but resolves these issues:\n# - Using a /contrib/* or other glob in root_patterns is dodgy as runners & schemas are in the same dir.\n#   In particular, with /contrib/* in root_patterns, *_runner imports become ambiguous\n#   (eg `import noop_runner` should use runners/noop_runner/noop_runner not runners/noop_runner).\n# - Using pack.yaml in marker_filenames prevents pants from inferring which fixture packs are\n#   used by which tests. We import a PACK_NAME and PACK_PATH from fixture.py in each of these\n#   fixture packs to enable this dependency inferrence. Having fine grained inferrence in-turn\n#   reduces the number of tests that need to be re-run when we change a fixture.\n# - Using another marker_file, like PACK_ROOT, is also problematic because of the core pack.\n#   /contrib/core is symlinked to /st2tests/st2tests/fixtures/packs/core for use as a fixture.\n#   It is used in quite a few tests, so it needs to continue living in both places.\n#   But, overlapping source roots (for st2tests and the pack) make importing from the fixture\n#   as we do with the other fixtures impossible.\n# Thus, we really do need to register each pack in contrib (but never under st2tests) separately.\n# We might also need to register packs in st2tests/testpacks.\nroot_patterns = [\n  # root conftest.py\n  \"/\",\n  # core libs\n  \"/st2*\",\n  # runners\n  \"/contrib/runners/*_runner\",\n  # packs (list /contrib/* packs individually; see note above)\n  \"/contrib/chatops\",\n  \"/contrib/core\", # WARNING: also symlinked to st2tests/st2tests/fixtures/packs/core\n  \"/contrib/default\",\n  \"/contrib/examples\",\n  \"/contrib/hello_st2\",\n  \"/contrib/linux\",\n  \"/contrib/packs\",\n  \"/st2tests/testpacks/checks\",\n  \"/st2tests/testpacks/errorcheck\",\n  # other special-cased pack directories\n  \"/contrib/examples/actions/ubuntu_pkg_info\", # python script runs via shell expecting cwd in PYTHONPATH\n  # lint plugins\n  \"/pylint_plugins\",\n  # pants plugins\n  \"/pants-plugins\",\n  # misc\n  \"/scripts\",\n  \"/tools\",\n  # benchmarks\n  \"/st2common/benchmarks/micro\",\n]\n\n# DEFAULT has values that we can reuse/interpolate below\n[DEFAULT]\n# This is the range of python versions that we support.\nst2_interpreter_constraints = \"CPython>=3.8.1,<3.12\"\n\n# This should match the pants interpreter_constraints:\n# https://github.com/pantsbuild/pants/blob/2.22.x/pants.toml#L148\n# See: https://www.pantsbuild.org/stable/docs/getting-started/prerequisites\npants_plugins_interpreter_constraints = \"CPython==3.9.*\"\n\n# For tools, we have to include python versions for BOTH st2 and pants-plugins\ntool_interpreter_constraints = \"CPython>=3.8.1,<3.12\"\n\n[python]\n# resolver_version is always \"pip-2020-resolver\". legacy is not supported.\nenable_resolves = true\ndefault_resolve = \"st2\"\n# python_distributions needs a single constraint (vs one line per python version).\ninterpreter_constraints = [\"%(st2_interpreter_constraints)s\"]\n\n[python.resolves]\n# st2 is the primary resolve\nst2 = \"lockfiles/st2.lock\"\n# tool and misc other resolves (for most, see //BUILD.tools)\nbandit = \"lockfiles/bandit.lock\"\nblack = \"lockfiles/black.lock\"\nflake8 = \"lockfiles/flake8.lock\"\npants-plugins = \"lockfiles/pants-plugins.lock\" # see //pants-plugins/BUILD\npylint = \"lockfiles/pylint.lock\" # see //pylint_plugins/BUILD\ntwine = \"lockfiles/twine.lock\"\n\n[python.resolves_to_interpreter_constraints]\nbandit = [\"%(tool_interpreter_constraints)s\"]\nblack = [\"%(tool_interpreter_constraints)s\"]\nflake8 = [\"%(tool_interpreter_constraints)s\"]\npants-plugins = [\"%(pants_plugins_interpreter_constraints)s\"]\npylint = [\"%(tool_interpreter_constraints)s\"]\ntwine = [\"%(tool_interpreter_constraints)s\"]\n\n[python.resolves_to_constraints_file]\n# Our direct requirements are in requirements-pants.txt;\n# put indirect/transitive version constraints here:\nst2 = \"lockfiles/st2-constraints.txt\"\n\n[export]\n# When exporting the virtualenv, include editable installs of our sources\n# so that the entry_points metadata is available for stevedore's use.\npy_editable_in_resolve = [\"st2\"]\n# We need mutable venvs to use the editable installs of our sources.\npy_resolve_format = \"mutable_virtualenv\"\n# By default, pex modifies script shebangs to add '-sE'.\n# This breaks nosetest and anything that needs PYTHONPATH.\npy_non_hermetic_scripts_in_resolve = [\"st2\"]\n# If any targets generate sources/files, include them in the exported venv.\npy_generated_sources_in_resolve = [\"st2\"]\n\n[python-infer]\n# https://www.pantsbuild.org/stable/reference/subsystems/python-infer#string_imports\n# https://www.pantsbuild.org/stable/reference/subsystems/python-infer#string_imports_min_dots\n# Infer a target's dependencies based on strings that look like dynamic deps with >=1 dots.\n# To debug the imports and see if a string is used in dep inference or if it is ignored, use:\n#   pants python-dump-source-analysis --analysis-flavor=raw_dependency_inference <path(s) to file(s)> | jq '.[].resolved'\nstring_imports = true\nstring_imports_min_dots = 1\n# https://www.pantsbuild.org/stable/reference/subsystems/python-infer#unowned_dependency_behavior\n# The default changed from \"ignore\" to \"warning\" in pants 2.14.\n# The ambiguity_resolution setting/feature (below) added in 2.16 resolves most of\n# our ambiguous dependency inference issues, which allowed us to remove the explicit\n# deps in various BUILD files. But, there is not a good way to tell pants about our\n# custom PYTHONPATH for packs, so actions that import other actions are still showing\n# up as unowned. Maybe we can extend pants-plugins/pack_metadata so we can use \"warn\".\nunowned_dependency_behavior = \"ignore\"\n# https://www.pantsbuild.org/stable/reference/subsystems/python-infer#ambiguity_resolution\n# When resolving ambiguous deps prefer one that is in the same source root as the\n# file that uses it. So, without manually disambiguating the dep in the BUILD file,\n# importing tests.unit.base in st2common/tests/unit will get a dep on st2common/tests/unit/base.py\nambiguity_resolution = \"by_source_root\"\n\n[setup-py-generation]\n# when building the package (with `pants package ::`), pants will,\n# by default, generate a setup.py file for use with setuptools.\ngenerate_setup_default = true # true by default\n\n[bandit]\nargs = [\n  \"-lll\",  # only HIGH severity level\n  \"--exclude\",\n  \"build,dist\",\n  \"--quiet\", # only show output in the case of an error\n]\ninstall_from_resolve = \"bandit\"\n\n[black]\ninstall_from_resolve = \"black\"\n\n[flake8]\ninstall_from_resolve = \"flake8\"\nconfig = \"lint-configs/python/.flake8\"\n\n[generate-lockfiles]\ndiff = true\n\n[pylint]\ninstall_from_resolve = \"pylint\"\nconfig = \"lint-configs/python/.pylintrc\"\nsource_plugins = [\n  # the /pylint_plugins directory\n  \"pylint_plugins\",\n]\nargs = [\n  # match the current Makefile usage with -E (TODO: drop this)\n  \"--errors-only\",\n  # needed in st2* components, runners, packs\n  \"--load-plugins=api_models\",\n  # needed in st2* components, runners\n  \"--load-plugins=db_models\",\n]\n\n[pytest]\ninstall_from_resolve = \"st2\"\nargs = [\n  \"--no-header\",  # don't print pytest version for every tested file\n]\nexecution_slot_var = \"ST2TESTS_PARALLEL_SLOT\"\n\n[regex-lint]\nconfig = \"@lint-configs/regex-lint.yaml\"\n\n[setuptools]\ninstall_from_resolve = \"st2\"\n\n[test]\nextra_env_vars = [\n  # Use this so that the test system does not require the stanley user.\n  # For example: export ST2TESTS_SYSTEM_USER=${USER}\n  \"ST2TESTS_SYSTEM_USER\",\n  \"ST2_SYSTEM_USER__USER\",\n  # Use these to override MongoDB connection details\n  # \"ST2_DATABASE__HOST\", # Tests override this with \"127.0.0.1\"\n  \"ST2_DATABASE__PORT\",\n  # \"ST2_DATABASE__DB_NAME\", # Tests override this with: \"st2-test{ST2TESTS_PARALLEL_SLOT}\"\n  \"ST2_DATABASE__CONNECTION_TIMEOUT\",\n  \"ST2_DATABASE__USERNAME\",\n  \"ST2_DATABASE__PASSWORD\",\n  # Use these to override RabbitMQ connection details\n  \"ST2_MESSAGING__URL\",\n  \"ST2_MESSAGING__PREFIX\", # Tests will modify this to be \"{prefix}{ST2TESTS_PARALLEL_SLOT}\"\n  # Use these to override Redis connection details\n  \"ST2TESTS_REDIS_HOST\",\n  \"ST2TESTS_REDIS_PORT\",\n  # \"ST2_COORDINATION__URL\", # Tests will override this with one of:\n  #         \"redis://{ST2TESTS_REDIS_HOST}:{ST2TESTS_REDIS_PORT}?namespace=_st2_test{ST2TESTS_PARALLEL_SLOT}\n  #         \"zake://\"\n  # CI-specific vars\n  \"ST2_CI\",\n  \"ST2_CI_RUN_ORQUESTA_PAUSE_RESUME_TESTS\",\n]\n# 10 min should be more than enough even for integration tests.\ntimeout_default = 600 # seconds\n\n[twine]\ninstall_from_resolve = \"twine\"\n\n[environments-preview.names]\n# https://www.pantsbuild.org/stable/docs/using-pants/environments\nin_repo_workspace = \"//:in_repo_workspace\"\n\n[cli.alias]\n--all-changed = \"--changed-since=HEAD --changed-dependents=transitive\"\n"
        },
        {
          "name": "pylint_plugins",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 0.244140625,
          "content": "[tool.black]\nmax-line-length = 100\ntarget_version = ['py38']\ninclude = '\\.pyi?$'\nexclude = '''\n(\n  /(\n    | \\.git\n    | \\.virtualenv\n    | __pycache__\n    | test_content_version\n  )/\n)\n'''\n\n[tool.pytest.ini_options]\nminversion = \"6.0\"\naddopts = \"-l\"\n"
        },
        {
          "name": "requirements-pants.txt",
          "type": "blob",
          "size": 2.9501953125,
          "content": "# Add/remove direct 3rd party dependencies here, with version constraints if necessary.\n# Then run `./pants generate-lockfiles --resolve=st2` to regenerate the lockfile.\n#\n# Please do not add transitive dependencies in this file (ie dependencies of our dependencies).\n# Use `lockfiles/st2-constraints.txt` to constrain the version of these transitive dependencies.\n#\n# Please keep this list alphabetical, with tooz backends in a separate list.\n\napscheduler\nargcomplete\nargparse\nciso8601\ncryptography\neditor\neventlet\n# flex parses the openapi 2 spec in our router\nflex\n# gitpython & gitdb are used for pack management\ngitdb\ngitpython\n# st2common/tests/integration/test_util_green.py requires greenlet (as does eventlet)\ngreenlet\ngunicorn\njinja2\njsonpath-rw\njsonschema>=3,<4\nkombu\nlockfile\nmock\n# mongoengine 0.24.0 has breaking changes to support pymongo 4.0\n# mongoengine 0.29.0 is the first version to officially support mongo 7.0.\nmongoengine>=0.24.0,<0.30.0\n# networkx version is constrained in orquesta.\nnetworkx\norjson\norquesta @ git+https://github.com/StackStorm/orquesta.git@5ba1467614b2ef8b4709b2ca89e68baa671e8975\n# Historical reference: https://github.com/StackStorm/st2/issues/4160#issuecomment-394386433\n# Relaxed pinning for py3.10 support.\noslo.config\nparamiko\n# we use pip at runtime\npip\n# prance is used by st2-validate-api-spec to validate the openapi spec\n# prance needs flex, but do not use the extra as that gets an old version.\nprance\nprettytable\nprompt-toolkit\npsutil\npygments\n# pymongo 3.13 has backports of APIs from pymongo 4 to help w/ migration\n# pymongo 4.4 is the first version to officially support mongo 7.0.\n# pymongo 4.7 (or 4.8?) introduces support for standard python logging, which overwhelms our debug logs\npymongo>=4.0.0,<4.7\n# pyrabbit used in an integration test\npyrabbit\n# pytest reqs in BUILD.tools file\npython-dateutil\n# pythonjsonlogger referenced in st2actions/conf/logging.conf\npython-json-logger\npython-statsd\npytz\nPyYAML\n# RandomWords used in some tests\nRandomWords\nrequests\nretrying\nroutes\nsemver\n# setuptools provides pkg_resources (and we need it with pip at runtime)\n# setuptools is also required for pants to build wheels.\nsetuptools\nsimplejson\nsix\n# NOTE: we use sseclient-py instead of sseclient because sseclient\n# has various issues which sometimes hang the connection for a long time, etc.\nsseclient-py\nstevedore\n# For backward compatibility reasons, flat file backend is installed by default\nst2-auth-backend-flat-file\nst2-auth-ldap @ git+https://github.com/StackStorm/st2-auth-ldap.git@master\nst2-rbac-backend @ git+https://github.com/StackStorm/st2-rbac-backend.git@master\n# tabulate used by tools/log_watcher.py\ntabulate\ntooz\nudatetime\nujson\nvirtualenv\nwebob\nwebtest\n# we use pip+wheel at runtime; wheel is also required for pants to build wheels.\nwheel\n# zstandard is used for micro benchmarks\nzstandard\n\n# tooz backends\nredis\nzake\n\n# was in fixed-requirements.txt, but not in requirements-pants.txt\n# keyczar is used by a python2-only test.\n#python-keyczar\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 1.859375,
          "content": "# Don't edit this file. It's generated automatically!\n# If you want to update global dependencies, modify fixed-requirements.txt\n# and then run 'make requirements' to update requirements.txt for all\n# components.\n# If you want to update depdencies for a single component, modify the\n# in-requirements.txt for that component and then run 'make requirements' to\n# update the component requirements.txt\nRandomWords\namqp==5.3.1\napscheduler==3.11.0\nargcomplete==3.5.2\nbackports.zoneinfo[tzdata]; python_version<\"3.9\"\nbcrypt==4.2.1\ncffi==1.17.1\nchardet==5.2.0\nciso8601\ncryptography==43.0.3\ndecorator==5.1.1\ndnspython\neditor==1.6.6\neventlet==0.38.2\nflex==6.14.1\ngitdb==4.0.11\ngitpython==3.1.43\ngreenlet==3.1.1\ngunicorn==23.0.0\nimportlib-metadata==7.1.0\njinja2==3.1.4\njsonpath-rw==1.4.0\njsonschema==3.2.0\nkombu==5.4.2\nlockfile==0.12.2\nlogshipper@ git+https://github.com/StackStorm/logshipper.git@stackstorm_patched ; platform_system==\"Linux\"\nmock==5.1.0\nmongoengine==0.29.1\nnetworkx==3.1\norjson==3.10.12\norquesta@ git+https://github.com/StackStorm/orquesta.git@5ba1467614b2ef8b4709b2ca89e68baa671e8975\noslo.config==9.6.0\noslo.utils==7.3.0\nparamiko==3.5.0\npasslib==1.7.4\nprettytable==3.10.2\nprompt-toolkit==3.0.48\npsutil==6.1.1\npyOpenSSL\npygments==2.18.0\npyinotify==0.9.6 ; platform_system==\"Linux\"\npymongo==4.6.3\npyparsing==3.1.4\npyrabbit\npysocks\npytest==7.0.1\npython-dateutil==2.9.0.post0\npython-json-logger\npython-statsd==2.1.0\npytz==2024.2\npywinrm==0.5.0\npyyaml==6.0.2\nredis==5.2.1\nrequests==2.32.3\nretrying==1.3.4\nroutes==2.5.1\nsemver==3.0.2\nsimplejson\nsix==1.17.0\nsseclient-py==1.8.0\nst2-auth-backend-flat-file\nst2-auth-ldap@ git+https://github.com/StackStorm/st2-auth-ldap.git@master\nst2-rbac-backend@ git+https://github.com/StackStorm/st2-rbac-backend.git@master\nstevedore==5.3.0\ntenacity==9.0.0\ntooz==6.3.0\ntyping-extensions==4.12.2\nwebob==1.8.9\nwebtest==3.0.1\nzake==0.2.2\nzipp==3.20.2\nzstandard==0.23.0\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2actions",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2api",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2auth",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2client",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2common",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2reactor",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2stream",
          "type": "tree",
          "content": null
        },
        {
          "name": "st2tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "stackstorm_logo.png",
          "type": "blob",
          "size": 27.3349609375,
          "content": null
        },
        {
          "name": "test-requirements.txt",
          "type": "blob",
          "size": 1.451171875,
          "content": "# Important: Keep version constraints synchronised with the below repositories:\n# - https://github.com/StackStorm/st2docs\n# - https://github.com/StackStorm/orquesta\n# - https://github.com/StackStorm/st2-auth-ldap\n# - https://github.com/StackStorm/st2-rbac-backend\n# ----------------------------------------------------------------------\ncoverage==7.4.4\npep8==1.7.1\nflake8==7.0.0\nst2flake8>0.1.0\nastroid==3.1.0\npylint==3.1.1\npylint-plugin-utils>=0.4\nblack==22.3.0\npre-commit==3.5.0\nbandit==1.7.10\nisort>=4.2.5\nmock==5.1.0\ntabulate\n# 4.5.0 required for Jinja-3.1.3 support but >5.0 required by rstcheck and lower than 7.2 which drops py3.8 support\nsphinx>=5.0.0,<7.2.0\nsphinx-autobuild\n# pin alabaster (sphinx dependency) or pip installs one that is not compatible\nalabaster<0.7.14\n# Required by st2client tests\npyyaml==6.0.2\n# Constrain pygments required by editor to align with st2 core version\npygments==2.18.0\nRandomWords\ngunicorn==23.0.0\npsutil==6.1.1\nwebtest==3.0.1\n# Bump to latest to meet sphinx requirements.\nrstcheck==6.2.1\ntox==4.14.2\npyrabbit\nprance==23.6.21.0\n# pip-tools provides pip-compile: to check for version conflicts\npip-tools==7.4.1\npytest==7.0.1\npytest-benchmark[histogram]==3.4.1\npytest-icdiff==0.9\npytest-cov==3.0.0\npytest-xdist==2.5.0\n# for Makefile-based pytest runs\npytest-custom_exit_code\n# zstandard is used for micro benchmarks\nzstandard==0.23.0\n# ujson is used for micro benchmarks\nujson==5.10.0\n# needed by integration tests for coordination\nredis==5.0.8\n"
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}