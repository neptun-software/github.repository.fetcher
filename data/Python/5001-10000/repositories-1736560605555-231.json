{
  "metadata": {
    "timestamp": 1736560605555,
    "page": 231,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjI0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "nl8590687/ASRT_SpeechRecognition",
      "stars": 7936,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.2080078125,
          "content": "## Ignore some files and folders for copyright and other reasons. \n\n*.model\n*.model.base\n[Mm]odel_speech/\n\n__pycache__\n*.wav\n*.model_yaml\nTest_Report_*\n\ndataset\ndata_pinyin.txt\n\ntestClient.py\n\nwebapi/\nsave_models/"
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 2.17578125,
          "content": "# Ubuntu 20.04\nFROM ubuntu:focal\n\n# 切换默认shell为bash\nSHELL [\"/bin/bash\", \"-c\"]\n\nADD ./ /asrt_server\n\nWORKDIR /asrt_server\n\n# 最小化源，缩短apt update时间(ca-certificates必须先安装才支持换tsinghua源)\nRUN echo 'deb http://archive.ubuntu.com/ubuntu/ focal main restricted' > /etc/apt/sources.list\n\nRUN apt update && apt install -y ca-certificates\n\nRUN echo $'\\\ndeb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse\\\n\\n# deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse\\\n\\n# deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse\\\n\\n# deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse\\\n\\n# deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse\\n\\\ndeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse\\\n\\n# deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse'\\\n> /etc/apt/sources.list\n\nRUN apt update && apt install -y python3 python3-pip \n\nRUN pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n\nRUN pip3 install wave scipy matplotlib tensorflow-cpu==2.5.3 numpy==1.19.2 requests flask waitress grpcio==1.34.0 grpcio-tools==1.34.0 protobuf\n\nRUN echo $'cd /asrt_server \\n python3 asrserver_http.py & \\n python3 asrserver_grpc.py' > /asrt_server/start.sh && chmod +x /asrt_server/start.sh\n\n# refer: https://docs.docker.com/engine/reference/builder/#expose\nEXPOSE 20001/tcp 20002/tcp\n\nENTRYPOINT [\"/bin/bash\", \"/asrt_server/start.sh\"]\n\n# https://docs.docker.com/engine/reference/commandline/build/#options\n# docker build --progress plain --rm --build-arg TAG=1.3.0 --tag asrt/api_server:1.3.0 .\n# https://docs.docker.com/engine/reference/commandline/run/#options\n# docker run --rm -it -p 20001:20001 -p 20002:20002 --name asrt -d asrt/api_server:1.3.0\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 34.326171875,
          "content": "                    GNU GENERAL PUBLIC LICENSE\n                       Version 3, 29 June 2007\n\n Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n Everyone is permitted to copy and distribute verbatim copies\n of this license document, but changing it is not allowed.\n\n                            Preamble\n\n  The GNU General Public License is a free, copyleft license for\nsoftware and other kinds of works.\n\n  The licenses for most software and other practical works are designed\nto take away your freedom to share and change the works.  By contrast,\nthe GNU General Public License is intended to guarantee your freedom to\nshare and change all versions of a program--to make sure it remains free\nsoftware for all its users.  We, the Free Software Foundation, use the\nGNU General Public License for most of our software; it applies also to\nany other work released this way by its authors.  You can apply it to\nyour programs, too.\n\n  When we speak of free software, we are referring to freedom, not\nprice.  Our General Public Licenses are designed to make sure that you\nhave the freedom to distribute copies of free software (and charge for\nthem if you wish), that you receive source code or can get it if you\nwant it, that you can change the software or use pieces of it in new\nfree programs, and that you know you can do these things.\n\n  To protect your rights, we need to prevent others from denying you\nthese rights or asking you to surrender the rights.  Therefore, you have\ncertain responsibilities if you distribute copies of the software, or if\nyou modify it: responsibilities to respect the freedom of others.\n\n  For example, if you distribute copies of such a program, whether\ngratis or for a fee, you must pass on to the recipients the same\nfreedoms that you received.  You must make sure that they, too, receive\nor can get the source code.  And you must show them these terms so they\nknow their rights.\n\n  Developers that use the GNU GPL protect your rights with two steps:\n(1) assert copyright on the software, and (2) offer you this License\ngiving you legal permission to copy, distribute and/or modify it.\n\n  For the developers' and authors' protection, the GPL clearly explains\nthat there is no warranty for this free software.  For both users' and\nauthors' sake, the GPL requires that modified versions be marked as\nchanged, so that their problems will not be attributed erroneously to\nauthors of previous versions.\n\n  Some devices are designed to deny users access to install or run\nmodified versions of the software inside them, although the manufacturer\ncan do so.  This is fundamentally incompatible with the aim of\nprotecting users' freedom to change the software.  The systematic\npattern of such abuse occurs in the area of products for individuals to\nuse, which is precisely where it is most unacceptable.  Therefore, we\nhave designed this version of the GPL to prohibit the practice for those\nproducts.  If such problems arise substantially in other domains, we\nstand ready to extend this provision to those domains in future versions\nof the GPL, as needed to protect the freedom of users.\n\n  Finally, every program is threatened constantly by software patents.\nStates should not allow patents to restrict development and use of\nsoftware on general-purpose computers, but in those that do, we wish to\navoid the special danger that patents applied to a free program could\nmake it effectively proprietary.  To prevent this, the GPL assures that\npatents cannot be used to render the program non-free.\n\n  The precise terms and conditions for copying, distribution and\nmodification follow.\n\n                       TERMS AND CONDITIONS\n\n  0. Definitions.\n\n  \"This License\" refers to version 3 of the GNU General Public License.\n\n  \"Copyright\" also means copyright-like laws that apply to other kinds of\nworks, such as semiconductor masks.\n\n  \"The Program\" refers to any copyrightable work licensed under this\nLicense.  Each licensee is addressed as \"you\".  \"Licensees\" and\n\"recipients\" may be individuals or organizations.\n\n  To \"modify\" a work means to copy from or adapt all or part of the work\nin a fashion requiring copyright permission, other than the making of an\nexact copy.  The resulting work is called a \"modified version\" of the\nearlier work or a work \"based on\" the earlier work.\n\n  A \"covered work\" means either the unmodified Program or a work based\non the Program.\n\n  To \"propagate\" a work means to do anything with it that, without\npermission, would make you directly or secondarily liable for\ninfringement under applicable copyright law, except executing it on a\ncomputer or modifying a private copy.  Propagation includes copying,\ndistribution (with or without modification), making available to the\npublic, and in some countries other activities as well.\n\n  To \"convey\" a work means any kind of propagation that enables other\nparties to make or receive copies.  Mere interaction with a user through\na computer network, with no transfer of a copy, is not conveying.\n\n  An interactive user interface displays \"Appropriate Legal Notices\"\nto the extent that it includes a convenient and prominently visible\nfeature that (1) displays an appropriate copyright notice, and (2)\ntells the user that there is no warranty for the work (except to the\nextent that warranties are provided), that licensees may convey the\nwork under this License, and how to view a copy of this License.  If\nthe interface presents a list of user commands or options, such as a\nmenu, a prominent item in the list meets this criterion.\n\n  1. Source Code.\n\n  The \"source code\" for a work means the preferred form of the work\nfor making modifications to it.  \"Object code\" means any non-source\nform of a work.\n\n  A \"Standard Interface\" means an interface that either is an official\nstandard defined by a recognized standards body, or, in the case of\ninterfaces specified for a particular programming language, one that\nis widely used among developers working in that language.\n\n  The \"System Libraries\" of an executable work include anything, other\nthan the work as a whole, that (a) is included in the normal form of\npackaging a Major Component, but which is not part of that Major\nComponent, and (b) serves only to enable use of the work with that\nMajor Component, or to implement a Standard Interface for which an\nimplementation is available to the public in source code form.  A\n\"Major Component\", in this context, means a major essential component\n(kernel, window system, and so on) of the specific operating system\n(if any) on which the executable work runs, or a compiler used to\nproduce the work, or an object code interpreter used to run it.\n\n  The \"Corresponding Source\" for a work in object code form means all\nthe source code needed to generate, install, and (for an executable\nwork) run the object code and to modify the work, including scripts to\ncontrol those activities.  However, it does not include the work's\nSystem Libraries, or general-purpose tools or generally available free\nprograms which are used unmodified in performing those activities but\nwhich are not part of the work.  For example, Corresponding Source\nincludes interface definition files associated with source files for\nthe work, and the source code for shared libraries and dynamically\nlinked subprograms that the work is specifically designed to require,\nsuch as by intimate data communication or control flow between those\nsubprograms and other parts of the work.\n\n  The Corresponding Source need not include anything that users\ncan regenerate automatically from other parts of the Corresponding\nSource.\n\n  The Corresponding Source for a work in source code form is that\nsame work.\n\n  2. Basic Permissions.\n\n  All rights granted under this License are granted for the term of\ncopyright on the Program, and are irrevocable provided the stated\nconditions are met.  This License explicitly affirms your unlimited\npermission to run the unmodified Program.  The output from running a\ncovered work is covered by this License only if the output, given its\ncontent, constitutes a covered work.  This License acknowledges your\nrights of fair use or other equivalent, as provided by copyright law.\n\n  You may make, run and propagate covered works that you do not\nconvey, without conditions so long as your license otherwise remains\nin force.  You may convey covered works to others for the sole purpose\nof having them make modifications exclusively for you, or provide you\nwith facilities for running those works, provided that you comply with\nthe terms of this License in conveying all material for which you do\nnot control copyright.  Those thus making or running the covered works\nfor you must do so exclusively on your behalf, under your direction\nand control, on terms that prohibit them from making any copies of\nyour copyrighted material outside their relationship with you.\n\n  Conveying under any other circumstances is permitted solely under\nthe conditions stated below.  Sublicensing is not allowed; section 10\nmakes it unnecessary.\n\n  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n\n  No covered work shall be deemed part of an effective technological\nmeasure under any applicable law fulfilling obligations under article\n11 of the WIPO copyright treaty adopted on 20 December 1996, or\nsimilar laws prohibiting or restricting circumvention of such\nmeasures.\n\n  When you convey a covered work, you waive any legal power to forbid\ncircumvention of technological measures to the extent such circumvention\nis effected by exercising rights under this License with respect to\nthe covered work, and you disclaim any intention to limit operation or\nmodification of the work as a means of enforcing, against the work's\nusers, your or third parties' legal rights to forbid circumvention of\ntechnological measures.\n\n  4. Conveying Verbatim Copies.\n\n  You may convey verbatim copies of the Program's source code as you\nreceive it, in any medium, provided that you conspicuously and\nappropriately publish on each copy an appropriate copyright notice;\nkeep intact all notices stating that this License and any\nnon-permissive terms added in accord with section 7 apply to the code;\nkeep intact all notices of the absence of any warranty; and give all\nrecipients a copy of this License along with the Program.\n\n  You may charge any price or no price for each copy that you convey,\nand you may offer support or warranty protection for a fee.\n\n  5. Conveying Modified Source Versions.\n\n  You may convey a work based on the Program, or the modifications to\nproduce it from the Program, in the form of source code under the\nterms of section 4, provided that you also meet all of these conditions:\n\n    a) The work must carry prominent notices stating that you modified\n    it, and giving a relevant date.\n\n    b) The work must carry prominent notices stating that it is\n    released under this License and any conditions added under section\n    7.  This requirement modifies the requirement in section 4 to\n    \"keep intact all notices\".\n\n    c) You must license the entire work, as a whole, under this\n    License to anyone who comes into possession of a copy.  This\n    License will therefore apply, along with any applicable section 7\n    additional terms, to the whole of the work, and all its parts,\n    regardless of how they are packaged.  This License gives no\n    permission to license the work in any other way, but it does not\n    invalidate such permission if you have separately received it.\n\n    d) If the work has interactive user interfaces, each must display\n    Appropriate Legal Notices; however, if the Program has interactive\n    interfaces that do not display Appropriate Legal Notices, your\n    work need not make them do so.\n\n  A compilation of a covered work with other separate and independent\nworks, which are not by their nature extensions of the covered work,\nand which are not combined with it such as to form a larger program,\nin or on a volume of a storage or distribution medium, is called an\n\"aggregate\" if the compilation and its resulting copyright are not\nused to limit the access or legal rights of the compilation's users\nbeyond what the individual works permit.  Inclusion of a covered work\nin an aggregate does not cause this License to apply to the other\nparts of the aggregate.\n\n  6. Conveying Non-Source Forms.\n\n  You may convey a covered work in object code form under the terms\nof sections 4 and 5, provided that you also convey the\nmachine-readable Corresponding Source under the terms of this License,\nin one of these ways:\n\n    a) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by the\n    Corresponding Source fixed on a durable physical medium\n    customarily used for software interchange.\n\n    b) Convey the object code in, or embodied in, a physical product\n    (including a physical distribution medium), accompanied by a\n    written offer, valid for at least three years and valid for as\n    long as you offer spare parts or customer support for that product\n    model, to give anyone who possesses the object code either (1) a\n    copy of the Corresponding Source for all the software in the\n    product that is covered by this License, on a durable physical\n    medium customarily used for software interchange, for a price no\n    more than your reasonable cost of physically performing this\n    conveying of source, or (2) access to copy the\n    Corresponding Source from a network server at no charge.\n\n    c) Convey individual copies of the object code with a copy of the\n    written offer to provide the Corresponding Source.  This\n    alternative is allowed only occasionally and noncommercially, and\n    only if you received the object code with such an offer, in accord\n    with subsection 6b.\n\n    d) Convey the object code by offering access from a designated\n    place (gratis or for a charge), and offer equivalent access to the\n    Corresponding Source in the same way through the same place at no\n    further charge.  You need not require recipients to copy the\n    Corresponding Source along with the object code.  If the place to\n    copy the object code is a network server, the Corresponding Source\n    may be on a different server (operated by you or a third party)\n    that supports equivalent copying facilities, provided you maintain\n    clear directions next to the object code saying where to find the\n    Corresponding Source.  Regardless of what server hosts the\n    Corresponding Source, you remain obligated to ensure that it is\n    available for as long as needed to satisfy these requirements.\n\n    e) Convey the object code using peer-to-peer transmission, provided\n    you inform other peers where the object code and Corresponding\n    Source of the work are being offered to the general public at no\n    charge under subsection 6d.\n\n  A separable portion of the object code, whose source code is excluded\nfrom the Corresponding Source as a System Library, need not be\nincluded in conveying the object code work.\n\n  A \"User Product\" is either (1) a \"consumer product\", which means any\ntangible personal property which is normally used for personal, family,\nor household purposes, or (2) anything designed or sold for incorporation\ninto a dwelling.  In determining whether a product is a consumer product,\ndoubtful cases shall be resolved in favor of coverage.  For a particular\nproduct received by a particular user, \"normally used\" refers to a\ntypical or common use of that class of product, regardless of the status\nof the particular user or of the way in which the particular user\nactually uses, or expects or is expected to use, the product.  A product\nis a consumer product regardless of whether the product has substantial\ncommercial, industrial or non-consumer uses, unless such uses represent\nthe only significant mode of use of the product.\n\n  \"Installation Information\" for a User Product means any methods,\nprocedures, authorization keys, or other information required to install\nand execute modified versions of a covered work in that User Product from\na modified version of its Corresponding Source.  The information must\nsuffice to ensure that the continued functioning of the modified object\ncode is in no case prevented or interfered with solely because\nmodification has been made.\n\n  If you convey an object code work under this section in, or with, or\nspecifically for use in, a User Product, and the conveying occurs as\npart of a transaction in which the right of possession and use of the\nUser Product is transferred to the recipient in perpetuity or for a\nfixed term (regardless of how the transaction is characterized), the\nCorresponding Source conveyed under this section must be accompanied\nby the Installation Information.  But this requirement does not apply\nif neither you nor any third party retains the ability to install\nmodified object code on the User Product (for example, the work has\nbeen installed in ROM).\n\n  The requirement to provide Installation Information does not include a\nrequirement to continue to provide support service, warranty, or updates\nfor a work that has been modified or installed by the recipient, or for\nthe User Product in which it has been modified or installed.  Access to a\nnetwork may be denied when the modification itself materially and\nadversely affects the operation of the network or violates the rules and\nprotocols for communication across the network.\n\n  Corresponding Source conveyed, and Installation Information provided,\nin accord with this section must be in a format that is publicly\ndocumented (and with an implementation available to the public in\nsource code form), and must require no special password or key for\nunpacking, reading or copying.\n\n  7. Additional Terms.\n\n  \"Additional permissions\" are terms that supplement the terms of this\nLicense by making exceptions from one or more of its conditions.\nAdditional permissions that are applicable to the entire Program shall\nbe treated as though they were included in this License, to the extent\nthat they are valid under applicable law.  If additional permissions\napply only to part of the Program, that part may be used separately\nunder those permissions, but the entire Program remains governed by\nthis License without regard to the additional permissions.\n\n  When you convey a copy of a covered work, you may at your option\nremove any additional permissions from that copy, or from any part of\nit.  (Additional permissions may be written to require their own\nremoval in certain cases when you modify the work.)  You may place\nadditional permissions on material, added by you to a covered work,\nfor which you have or can give appropriate copyright permission.\n\n  Notwithstanding any other provision of this License, for material you\nadd to a covered work, you may (if authorized by the copyright holders of\nthat material) supplement the terms of this License with terms:\n\n    a) Disclaiming warranty or limiting liability differently from the\n    terms of sections 15 and 16 of this License; or\n\n    b) Requiring preservation of specified reasonable legal notices or\n    author attributions in that material or in the Appropriate Legal\n    Notices displayed by works containing it; or\n\n    c) Prohibiting misrepresentation of the origin of that material, or\n    requiring that modified versions of such material be marked in\n    reasonable ways as different from the original version; or\n\n    d) Limiting the use for publicity purposes of names of licensors or\n    authors of the material; or\n\n    e) Declining to grant rights under trademark law for use of some\n    trade names, trademarks, or service marks; or\n\n    f) Requiring indemnification of licensors and authors of that\n    material by anyone who conveys the material (or modified versions of\n    it) with contractual assumptions of liability to the recipient, for\n    any liability that these contractual assumptions directly impose on\n    those licensors and authors.\n\n  All other non-permissive additional terms are considered \"further\nrestrictions\" within the meaning of section 10.  If the Program as you\nreceived it, or any part of it, contains a notice stating that it is\ngoverned by this License along with a term that is a further\nrestriction, you may remove that term.  If a license document contains\na further restriction but permits relicensing or conveying under this\nLicense, you may add to a covered work material governed by the terms\nof that license document, provided that the further restriction does\nnot survive such relicensing or conveying.\n\n  If you add terms to a covered work in accord with this section, you\nmust place, in the relevant source files, a statement of the\nadditional terms that apply to those files, or a notice indicating\nwhere to find the applicable terms.\n\n  Additional terms, permissive or non-permissive, may be stated in the\nform of a separately written license, or stated as exceptions;\nthe above requirements apply either way.\n\n  8. Termination.\n\n  You may not propagate or modify a covered work except as expressly\nprovided under this License.  Any attempt otherwise to propagate or\nmodify it is void, and will automatically terminate your rights under\nthis License (including any patent licenses granted under the third\nparagraph of section 11).\n\n  However, if you cease all violation of this License, then your\nlicense from a particular copyright holder is reinstated (a)\nprovisionally, unless and until the copyright holder explicitly and\nfinally terminates your license, and (b) permanently, if the copyright\nholder fails to notify you of the violation by some reasonable means\nprior to 60 days after the cessation.\n\n  Moreover, your license from a particular copyright holder is\nreinstated permanently if the copyright holder notifies you of the\nviolation by some reasonable means, this is the first time you have\nreceived notice of violation of this License (for any work) from that\ncopyright holder, and you cure the violation prior to 30 days after\nyour receipt of the notice.\n\n  Termination of your rights under this section does not terminate the\nlicenses of parties who have received copies or rights from you under\nthis License.  If your rights have been terminated and not permanently\nreinstated, you do not qualify to receive new licenses for the same\nmaterial under section 10.\n\n  9. Acceptance Not Required for Having Copies.\n\n  You are not required to accept this License in order to receive or\nrun a copy of the Program.  Ancillary propagation of a covered work\noccurring solely as a consequence of using peer-to-peer transmission\nto receive a copy likewise does not require acceptance.  However,\nnothing other than this License grants you permission to propagate or\nmodify any covered work.  These actions infringe copyright if you do\nnot accept this License.  Therefore, by modifying or propagating a\ncovered work, you indicate your acceptance of this License to do so.\n\n  10. Automatic Licensing of Downstream Recipients.\n\n  Each time you convey a covered work, the recipient automatically\nreceives a license from the original licensors, to run, modify and\npropagate that work, subject to this License.  You are not responsible\nfor enforcing compliance by third parties with this License.\n\n  An \"entity transaction\" is a transaction transferring control of an\norganization, or substantially all assets of one, or subdividing an\norganization, or merging organizations.  If propagation of a covered\nwork results from an entity transaction, each party to that\ntransaction who receives a copy of the work also receives whatever\nlicenses to the work the party's predecessor in interest had or could\ngive under the previous paragraph, plus a right to possession of the\nCorresponding Source of the work from the predecessor in interest, if\nthe predecessor has it or can get it with reasonable efforts.\n\n  You may not impose any further restrictions on the exercise of the\nrights granted or affirmed under this License.  For example, you may\nnot impose a license fee, royalty, or other charge for exercise of\nrights granted under this License, and you may not initiate litigation\n(including a cross-claim or counterclaim in a lawsuit) alleging that\nany patent claim is infringed by making, using, selling, offering for\nsale, or importing the Program or any portion of it.\n\n  11. Patents.\n\n  A \"contributor\" is a copyright holder who authorizes use under this\nLicense of the Program or a work on which the Program is based.  The\nwork thus licensed is called the contributor's \"contributor version\".\n\n  A contributor's \"essential patent claims\" are all patent claims\nowned or controlled by the contributor, whether already acquired or\nhereafter acquired, that would be infringed by some manner, permitted\nby this License, of making, using, or selling its contributor version,\nbut do not include claims that would be infringed only as a\nconsequence of further modification of the contributor version.  For\npurposes of this definition, \"control\" includes the right to grant\npatent sublicenses in a manner consistent with the requirements of\nthis License.\n\n  Each contributor grants you a non-exclusive, worldwide, royalty-free\npatent license under the contributor's essential patent claims, to\nmake, use, sell, offer for sale, import and otherwise run, modify and\npropagate the contents of its contributor version.\n\n  In the following three paragraphs, a \"patent license\" is any express\nagreement or commitment, however denominated, not to enforce a patent\n(such as an express permission to practice a patent or covenant not to\nsue for patent infringement).  To \"grant\" such a patent license to a\nparty means to make such an agreement or commitment not to enforce a\npatent against the party.\n\n  If you convey a covered work, knowingly relying on a patent license,\nand the Corresponding Source of the work is not available for anyone\nto copy, free of charge and under the terms of this License, through a\npublicly available network server or other readily accessible means,\nthen you must either (1) cause the Corresponding Source to be so\navailable, or (2) arrange to deprive yourself of the benefit of the\npatent license for this particular work, or (3) arrange, in a manner\nconsistent with the requirements of this License, to extend the patent\nlicense to downstream recipients.  \"Knowingly relying\" means you have\nactual knowledge that, but for the patent license, your conveying the\ncovered work in a country, or your recipient's use of the covered work\nin a country, would infringe one or more identifiable patents in that\ncountry that you have reason to believe are valid.\n\n  If, pursuant to or in connection with a single transaction or\narrangement, you convey, or propagate by procuring conveyance of, a\ncovered work, and grant a patent license to some of the parties\nreceiving the covered work authorizing them to use, propagate, modify\nor convey a specific copy of the covered work, then the patent license\nyou grant is automatically extended to all recipients of the covered\nwork and works based on it.\n\n  A patent license is \"discriminatory\" if it does not include within\nthe scope of its coverage, prohibits the exercise of, or is\nconditioned on the non-exercise of one or more of the rights that are\nspecifically granted under this License.  You may not convey a covered\nwork if you are a party to an arrangement with a third party that is\nin the business of distributing software, under which you make payment\nto the third party based on the extent of your activity of conveying\nthe work, and under which the third party grants, to any of the\nparties who would receive the covered work from you, a discriminatory\npatent license (a) in connection with copies of the covered work\nconveyed by you (or copies made from those copies), or (b) primarily\nfor and in connection with specific products or compilations that\ncontain the covered work, unless you entered into that arrangement,\nor that patent license was granted, prior to 28 March 2007.\n\n  Nothing in this License shall be construed as excluding or limiting\nany implied license or other defenses to infringement that may\notherwise be available to you under applicable patent law.\n\n  12. No Surrender of Others' Freedom.\n\n  If conditions are imposed on you (whether by court order, agreement or\notherwise) that contradict the conditions of this License, they do not\nexcuse you from the conditions of this License.  If you cannot convey a\ncovered work so as to satisfy simultaneously your obligations under this\nLicense and any other pertinent obligations, then as a consequence you may\nnot convey it at all.  For example, if you agree to terms that obligate you\nto collect a royalty for further conveying from those to whom you convey\nthe Program, the only way you could satisfy both those terms and this\nLicense would be to refrain entirely from conveying the Program.\n\n  13. Use with the GNU Affero General Public License.\n\n  Notwithstanding any other provision of this License, you have\npermission to link or combine any covered work with a work licensed\nunder version 3 of the GNU Affero General Public License into a single\ncombined work, and to convey the resulting work.  The terms of this\nLicense will continue to apply to the part which is the covered work,\nbut the special requirements of the GNU Affero General Public License,\nsection 13, concerning interaction through a network will apply to the\ncombination as such.\n\n  14. Revised Versions of this License.\n\n  The Free Software Foundation may publish revised and/or new versions of\nthe GNU General Public License from time to time.  Such new versions will\nbe similar in spirit to the present version, but may differ in detail to\naddress new problems or concerns.\n\n  Each version is given a distinguishing version number.  If the\nProgram specifies that a certain numbered version of the GNU General\nPublic License \"or any later version\" applies to it, you have the\noption of following the terms and conditions either of that numbered\nversion or of any later version published by the Free Software\nFoundation.  If the Program does not specify a version number of the\nGNU General Public License, you may choose any version ever published\nby the Free Software Foundation.\n\n  If the Program specifies that a proxy can decide which future\nversions of the GNU General Public License can be used, that proxy's\npublic statement of acceptance of a version permanently authorizes you\nto choose that version for the Program.\n\n  Later license versions may give you additional or different\npermissions.  However, no additional obligations are imposed on any\nauthor or copyright holder as a result of your choosing to follow a\nlater version.\n\n  15. Disclaimer of Warranty.\n\n  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\nAPPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\nHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\nOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\nTHE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\nPURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\nIS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\nALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n\n  16. Limitation of Liability.\n\n  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\nTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\nGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\nUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\nDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\nPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\nEVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\nSUCH DAMAGES.\n\n  17. Interpretation of Sections 15 and 16.\n\n  If the disclaimer of warranty and limitation of liability provided\nabove cannot be given local legal effect according to their terms,\nreviewing courts shall apply local law that most closely approximates\nan absolute waiver of all civil liability in connection with the\nProgram, unless a warranty or assumption of liability accompanies a\ncopy of the Program in return for a fee.\n\n                     END OF TERMS AND CONDITIONS\n\n            How to Apply These Terms to Your New Programs\n\n  If you develop a new program, and you want it to be of the greatest\npossible use to the public, the best way to achieve this is to make it\nfree software which everyone can redistribute and change under these terms.\n\n  To do so, attach the following notices to the program.  It is safest\nto attach them to the start of each source file to most effectively\nstate the exclusion of warranty; and each file should have at least\nthe \"copyright\" line and a pointer to where the full notice is found.\n\n    {one line to give the program's name and a brief idea of what it does.}\n    Copyright (C) {year}  {name of author}\n\n    This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nAlso add information on how to contact you by electronic and paper mail.\n\n  If the program does terminal interaction, make it output a short\nnotice like this when it starts in an interactive mode:\n\n    ASRT_SpeechRecognition  Copyright (C) 2017  nl8590687\n    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n    This is free software, and you are welcome to redistribute it\n    under certain conditions; type `show c' for details.\n\nThe hypothetical commands `show w' and `show c' should show the appropriate\nparts of the General Public License.  Of course, your program's commands\nmight be different; for a GUI interface, you would use an \"about box\".\n\n  You should also get your employer (if you work as a programmer) or school,\nif any, to sign a \"copyright disclaimer\" for the program, if necessary.\nFor more information on this, and how to apply and follow the GNU GPL, see\n<http://www.gnu.org/licenses/>.\n\n  The GNU General Public License does not permit incorporating your program\ninto proprietary programs.  If your program is a subroutine library, you\nmay consider it more useful to permit linking proprietary applications with\nthe library.  If this is what you want to do, use the GNU Lesser General\nPublic License instead of this License.  But first, please read\n<http://www.gnu.org/philosophy/why-not-lgpl.html>."
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 10.9482421875,
          "content": "![](assets/asrt_title_header.png)\r\n\r\n[![GPL-3.0 Licensed](https://img.shields.io/badge/License-GPL3.0-blue.svg?style=flat)](https://opensource.org/licenses/GPL-3.0) \r\n[![Stars](https://img.shields.io/github/stars/nl8590687/ASRT_SpeechRecognition)](https://github.com/nl8590687/ASRT_SpeechRecognition) \r\n[![TensorFlow Version](https://img.shields.io/badge/Tensorflow-2.5+-blue.svg)](https://www.tensorflow.org/) \r\n[![Python Version](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/) \r\n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5808434.svg)](https://doi.org/10.5281/zenodo.5808434)\r\n\r\nASRT是一个基于深度学习的中文语音识别系统，如果您觉得喜欢，请点一个 **\"Star\"** 吧~\r\n\r\n**ReadMe Language** | 中文版 | [English](https://github.com/nl8590687/ASRT_SpeechRecognition/blob/master/README_EN.md) |\r\n\r\n[**ASRT项目主页**](https://asrt.ailemon.net/) | \r\n[**发布版下载**](https://wiki.ailemon.net/docs/asrt-doc/download) | \r\n[**查看本项目的Wiki文档**](https://wiki.ailemon.net/docs/asrt-doc) | \r\n[**实用效果体验Demo**](https://asrt.ailemon.net/demo) | \r\n[**打赏作者**](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deo9u61unti9)\r\n\r\n如果程序运行期间或使用中有什么问题，可以及时在issue中提出来，我将尽快做出答复。本项目作者交流QQ群：**894112051** ，加微信群请先加AI柠檬微信号：**ailemon-me** ，并备注“ASRT语音识别”\r\n\r\n<center><img src=\"https://res.ailemon.net/common/ailemon-me-wechat-qrcode.jpg?x-oss-process=style/ailemon-blog-webp\" height=\"100rem\"/></center>\r\n\r\n提问前请仔细查看[项目文档](https://wiki.ailemon.net/docs/asrt-doc)、 \r\n[FAQ常见问题](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deoeud494h4f)\r\n以及[Issues](https://github.com/nl8590687/ASRT_SpeechRecognition/issues) 避免重复提问\r\n\r\n如果程序运行时有任何异常情况，在提问时请发出完整截图，并注明所使用的CPU架构，GPU型号，操作系统、Python，TensorFlow和CUDA版本，以及是否修改过任何代码或增删数据集等。\r\n\r\n## Introduction 简介\r\n\r\n本项目使用tensorFlow.keras基于深度卷积神经网络和长短时记忆神经网络、注意力机制以及CTC实现。\r\n\r\n## 训练模型的最低软硬件要求\r\n### 硬件\r\n* CPU: 4核 (x86_64, amd64) +\r\n* RAM: 16 GB +\r\n* GPU: NVIDIA, Graph Memory 11GB+ (1080ti起步)\r\n* 硬盘: 500 GB 机械硬盘(或固态硬盘)\r\n\r\n### 软件\r\n* Linux: Ubuntu 20.04+ / CentOS 7+ (训练+推理) 或 Windows: 10/11(仅推理)\r\n* Python: 3.9 - 3.11 及后续版本\r\n* TensorFlow: 2.5 - 2.11 及后续版本\r\n\r\n## 快速开始\r\n\r\n以在Linux系统下的操作为例：\r\n\r\n首先通过Git将本项目克隆到您的计算机上，然后下载本项目训练所需要的数据集，下载链接详见[文档末尾部分](https://github.com/nl8590687/ASRT_SpeechRecognition#data-sets-%E6%95%B0%E6%8D%AE%E9%9B%86)。\r\n```shell\r\n$ git clone https://github.com/nl8590687/ASRT_SpeechRecognition.git\r\n```\r\n\r\n或者您也可以通过 \"Fork\" 按钮，将本项目Copy一份副本，然后通过您自己的SSH密钥克隆到本地。\r\n\r\n通过git克隆仓库以后，进入项目根目录；并创建一个存储数据的子目录， 例如 `/data/speech_data` (可使用软链接代替)，然后将下载好的数据集直接解压进去\r\n\r\n注意，当前版本中，在配置文件里，默认添加了Thchs30、ST-CMDS、Primewords、aishell-1、aidatatang200、MagicData 六个数据集，如果不需要请自行删除。如果要使用其他数据集需要自行添加数据配置，并提前使用ASRT支持的标准格式整理数据。\r\n\r\n```shell\r\n$ cd ASRT_SpeechRecognition\r\n\r\n$ mkdir /data/speech_data\r\n\r\n$ tar zxf <数据集压缩文件名> -C /data/speech_data/ \r\n```\r\n\r\n下载默认数据集的拼音标签文件：\r\n```shell\r\n$ python download_default_datalist.py\r\n```\r\n\r\n目前可用的模型有24、25、251和251bn\r\n\r\n运行本项目之前，请安装必要的[Python3版依赖库](https://github.com/nl8590687/ASRT_SpeechRecognition#python-import)\r\n\r\n本项目开始训练请执行：\r\n```shell\r\n$ python3 train_speech_model.py\r\n```\r\n本项目开始测试请执行：\r\n```shell\r\n$ python3 evaluate_speech_model.py\r\n```\r\n测试之前，请确保代码中填写的模型文件路径存在。\r\n\r\n预测单条音频文件的语音识别文本：\r\n```shell\r\n$ python3 predict_speech_file.py\r\n```\r\n\r\n启动ASRT HTTP协议的API服务器启动请执行：\r\n```shell\r\n$ python3 asrserver_http.py\r\n```\r\n\r\n本地测试调用HTTP协议API服务是否成功：\r\n```shell\r\n$ python3 client_http.py\r\n```\r\n\r\n启动ASRT GRPC协议的API服务器启动请执行：\r\n```shell\r\n$ python3 asrserver_grpc.py\r\n```\r\n\r\n本地测试调用GRPC协议API服务是否成功：\r\n```shell\r\n$ python3 client_grpc.py\r\n```\r\n\r\n请注意，开启API服务器之后，需要使用本ASRT项目对应的客户端软件来进行语音识别，详见Wiki文档[下载ASRT语音识别客户端SDK和Demo](https://wiki.ailemon.net/docs/asrt-doc/download)。\r\n\r\n如果要训练和使用非251bn版模型，请在代码中 `from speech_model.xxx import xxx` 的相应位置做修改。\r\n\r\n使用docker直接部署ASRT：\r\n```shell\r\n$ docker pull ailemondocker/asrt_service:1.3.0\r\n$ docker run --rm -it -p 20001:20001 -p 20002:20002 --name asrt-server -d ailemondocker/asrt_service:1.3.0\r\n```\r\n仅CPU运行推理识别，不作训练\r\n\r\n## Model 模型\r\n\r\n### Speech Model 语音模型\r\n\r\nDCNN + CTC\r\n\r\n其中，输入的音频的最大时间长度为16秒，输出为对应的汉语拼音序列\r\n\r\n* 关于下载已经训练好的模型的问题\r\n\r\n已经训练好的模型包含在发布版服务端程序压缩包里面，发布版成品服务端程序可以在此下载：[ASRT下载页面](https://wiki.ailemon.net/docs/asrt-doc/download)。\r\n\r\nGithub本仓库下[Releases](https://github.com/nl8590687/ASRT_SpeechRecognition/releases)页面里面还包括各个不同版本的介绍信息，每个版本下方的zip压缩包也是包含已经训练好的模型的发布版服务端程序压缩包。\r\n\r\n### Language Model 语言模型\r\n\r\n基于概率图的最大熵隐马尔可夫模型\r\n\r\n输入为汉语拼音序列，输出为对应的汉字文本\r\n\r\n## About Accuracy 关于准确率\r\n\r\n当前，最好的模型在测试集上基本能达到85%的汉语拼音正确率\r\n\r\n## Python依赖库\r\n\r\n* tensorFlow (2.5-2.11+)\r\n* numpy\r\n* wave\r\n* matplotlib\r\n* scipy\r\n* requests\r\n* flask\r\n* waitress\r\n* grpcio / grpcio-tools / protobuf\r\n\r\n不会安装环境的同学请直接运行以下命令(前提是有GPU且已经安装好 Python3.9、CUDA 11.2 和 cudnn 8.1)：\r\n\r\n```shell\r\n$ pip install -r requirements.txt\r\n```\r\n\r\n[依赖环境和性能配置要求](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deobk7bmlgd6)\r\n\r\n## Data Sets 数据集\r\n\r\n完整内容请查看：[几个最新免费开源的中文语音数据集](https://blog.ailemon.net/2018/11/21/free-open-source-chinese-speech-datasets/)\r\n\r\n|数据集|时长|大小|国内下载|国外下载|\r\n|-|-|-|-|-|\r\n|THCHS30|40h|6.01G|[data_thchs30.tgz](<http://openslr.magicdatatech.com/resources/18/data_thchs30.tgz>)|[data_thchs30.tgz](<http://www.openslr.org/resources/18/data_thchs30.tgz>)|\r\n|ST-CMDS|100h|7.67G|[ST-CMDS-20170001_1-OS.tar.gz](<http://openslr.magicdatatech.com/resources/38/ST-CMDS-20170001_1-OS.tar.gz>)|[ST-CMDS-20170001_1-OS.tar.gz](<http://www.openslr.org/resources/38/ST-CMDS-20170001_1-OS.tar.gz>)|\r\n|AIShell-1|178h|14.51G|[data_aishell.tgz](<http://openslr.magicdatatech.com/resources/33/data_aishell.tgz>)|[data_aishell.tgz](<http://www.openslr.org/resources/33/data_aishell.tgz>)|\r\n|Primewords|100h|8.44G|[primewords_md_2018_set1.tar.gz](<http://openslr.magicdatatech.com/resources/47/primewords_md_2018_set1.tar.gz>)|[primewords_md_2018_set1.tar.gz](<http://www.openslr.org/resources/47/primewords_md_2018_set1.tar.gz>)|\r\n|MagicData|755h|52G/1.0G/2.2G| [train_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/train_set.tar.gz>) / [dev_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/dev_set.tar.gz>) / [test_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/test_set.tar.gz>)|[train_set.tar.gz](<http://www.openslr.org/resources/68/train_set.tar.gz>) / [dev_set.tar.gz](<http://www.openslr.org/resources/68/dev_set.tar.gz>) / [test_set.tar.gz](<http://www.openslr.org/resources/68/test_set.tar.gz>)|\r\n\r\n  注：AISHELL-1 数据集解压方法\r\n\r\n  ```\r\n  $ tar xzf data_aishell.tgz\r\n  $ cd data_aishell/wav\r\n  $ for tar in *.tar.gz;  do tar xvf $tar; done\r\n  ```\r\n\r\n特别鸣谢！感谢前辈们的公开语音数据集\r\n\r\n如果提供的数据集链接无法打开和下载，请点击该链接 [OpenSLR](http://www.openslr.org)\r\n\r\n## ASRT语音识别API客户端调用SDK\r\n\r\nASRT为客户端通过RPC方式调用开发语音识别功能提供了不同平台和编程语言的SDK接入能力，对于其他平台，可直接通过调用通用RESTful Open API方式进行语音识别功能接入。具体接入步骤请看ASRT项目文档。\r\n\r\n|客户端平台|项目仓库链接|\r\n|-|-|\r\n|Windows客户端SDK和Demo|[ASRT_SDK_WinClient](https://github.com/nl8590687/ASRT_SDK_WinClient)|\r\n|跨平台Python3客户端SDK和Demo|[ASRT_SDK_Python3](https://github.com/nl8590687/ASRT_SDK_Python3)|\r\n|跨平台Golang客户端SDK和Demo|[asrt-sdk-go](https://github.com/nl8590687/asrt-sdk-go)|\r\n|Java客户端SDK和Demo|[ASRT_SDK_Java](https://github.com/nl8590687/ASRT_SDK_Java)|\r\n\r\n## ASRT相关资料 \r\n* [查看ASRT项目的Wiki文档](https://wiki.ailemon.net/docs/asrt-doc)\r\n\r\nASRT的原理请查看本文：\r\n* [ASRT：一个中文语音识别系统](https://blog.ailemon.net/2018/08/29/asrt-a-chinese-speech-recognition-system/)\r\n\r\nASRT训练和部署教程请看：\r\n* [教你如何使用ASRT训练中文语音识别模型](<https://blog.ailemon.net/2020/08/20/teach-you-how-use-asrt-train-chinese-asr-model/>)\r\n* [教你如何使用ASRT部署中文语音识别API服务器](<https://blog.ailemon.net/2020/08/27/teach-you-how-use-asrt-deploy-chinese-asr-api-server/>)\r\n\r\n关于经常被问到的统计语言模型原理的问题，请看：\r\n\r\n* [统计语言模型：从中文拼音到文本](https://blog.ailemon.net/2017/04/27/statistical-language-model-chinese-pinyin-to-words/)\r\n* [统计N元语言模型生成算法：简单中文词频统计](https://blog.ailemon.net/2017/02/20/simple-words-frequency-statistic-without-segmentation-algorithm/)\r\n\r\n关于CTC的问题请看：\r\n\r\n* [[翻译]使用CTC进行序列建模](<https://blog.ailemon.net/2019/07/18/sequence-modeling-with-ctc/>)\r\n\r\n更多内容请访问作者的博客：[AI柠檬博客](https://blog.ailemon.net/)\r\n\r\n或使用[AI柠檬站内搜索引擎](https://s.ailemon.net/)进行相关信息的搜索\r\n\r\n## License 开源许可协议\r\n\r\n[GPL v3.0](LICENSE) © [nl8590687](https://github.com/nl8590687) 作者：[AI柠檬](https://www.ailemon.net/)\r\n\r\n## 参考引用本项目\r\n\r\n[DOI: 10.5281/zenodo.5808434](https://doi.org/10.5281/zenodo.5808434)\r\n\r\n## Contributors 贡献者们\r\n\r\n[贡献者页面](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/contributors)\r\n\r\n@nl8590687 (repo owner)\r\n"
        },
        {
          "name": "README_EN.md",
          "type": "blob",
          "size": 11.115234375,
          "content": "![](assets/asrt_title_header_en.png)\n\n[![GPL-3.0 Licensed](https://img.shields.io/badge/License-GPL3.0-blue.svg?style=flat)](https://opensource.org/licenses/GPL-3.0) \n[![Stars](https://img.shields.io/github/stars/nl8590687/ASRT_SpeechRecognition)](https://github.com/nl8590687/ASRT_SpeechRecognition) \n[![TensorFlow Version](https://img.shields.io/badge/Tensorflow-2.5+-blue.svg)](https://www.tensorflow.org/) \n[![Python Version](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/) \n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5808434.svg)](https://doi.org/10.5281/zenodo.5808434)\n\nASRT is A Deep-Learning-Based Chinese Speech Recognition System. If you like this project, please **star** it. \n\n**ReadMe Language** | [中文版](https://github.com/nl8590687/ASRT_SpeechRecognition/blob/master/README.md) | English |\n\n[**ASRT Project Home Page**](https://asrt.ailemon.net/) | \n[**Released Download**](https://wiki.ailemon.net/docs/asrt-doc/download) | \n[**View this project's wiki document (Chinese)**](https://wiki.ailemon.net/docs/asrt-doc) | \n[**Experience Demo**](https://asrt.ailemon.net/demo) | \n[**Donate**](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deo9u61unti9)\n\nIf you have any questions in your works with this project, welcome to put up issues in this repo and I will response as soon as possible. \n\nYou can check the [FAQ Page (Chinese)](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deoeud494h4f) first before asking questions to avoid repeating questions.\n\nIf there is any abnormality when the program is running, please send a complete screenshot when asking questions, and indicate the CPU architecture, GPU model, operating system, Python, TensorFlow and CUDA versions used, and whether any code has been modified or data sets have been added or deleted, etc. .\n\n## Introduction\n\nThis project uses tensorFlow.keras based on deep convolutional neural network and long-short memory neural network, attention mechanism and CTC to implement. \n\n## Minimum requirements for training\n### Hardware\n* CPU: 4 Core (x86_64, amd64) +\n* RAM: 16 GB +\n* GPU: NVIDIA, Graph Memory 11GB+ (>1080ti)\n* 硬盘: 500 GB HDD(or SSD)\n\n### Software\n* Linux: Ubuntu 20.04+ / CentOS 7+ (train & predict) or Windows: 10/11 (only to predict)\n* Python: 3.9 - 3.11 and later\n* TensorFlow: 2.5 - 2.11 and later\n\n## Quick Start\nTake the operation under the Linux system as an example:\n\nFirst, clone the project to your computer through Git, and then download the data sets needed for the training of this project. For the download links, please refer to [End of Document](https://github.com/nl8590687/ASRT_SpeechRecognition/blob/master/README_EN.md#data-sets)\n```shell\n$ git clone https://github.com/nl8590687/ASRT_SpeechRecognition.git\n```\n\nOr you can use the \"Fork\" button to copy a copy of the project and then clone it locally with your own SSH key.\n\nAfter cloning the repository via git, go to the project root directory; create a subdirectory `/data/speech_data` (you can use a soft link instead) for datasets, and then extract the downloaded datasets directly into it.\n\n```shell\n$ cd ASRT_SpeechRecognition\n\n$ mkdir /data/speech_data\n\n$ tar zxf <dataset zip files name> -C /data/speech_data/ \n```\n\nNote that in the current version, in the configuration file, six data sets, Thchs30, ST-CMDS, Primewords, aishell-1, aidatatang200, MagicData, are added by default, please delete them if you don’t need them. If you want to use other data sets, you need to add data configuration yourself, and use the standard format supported by ASRT to organize the data in advance.\n\nTo download pinyin syllable list files for default dataset:\n```shell\n$ python download_default_datalist.py\n```\n\nCurrently available models are 24, 25, 251 and 251bn\n\nBefore running this project, please install the necessary [Python3 version dependent library](https://github.com/nl8590687/ASRT_SpeechRecognition#python-import)\n\nTo start training this project, please execute:\n```shell\n$ python3 train_speech_model.py\n```\nTo start the test of this project, please execute:\n```shell\n$ python3 evaluate_speech_model.py\n```\nBefore testing, make sure the model file path filled in the code files exists.\n\nTo predict one wave audio file for speech recognition：\n```shell\n$ python3 predict_speech_file.py\n```\n\nTo startup ASRT API Server with HTTP protocol please execute:\n```shell\n$ python3 asrserver_http.py\n```\n\nPlease note that after opening the API server, you need to use the client software corresponding to this ASRT project for voice recognition. For details, see the Wiki documentation to [download ASRT Client SDK & Demo](https://wiki.ailemon.net/docs/asrt-doc/download).\n\n\nTo test whether it is successful or not that calls api service interface with HTTP protocol:\n```shell\n$ python3 client_http.py\n```\n\nTo startup ASRT API Server with GRPC protocol please execute:\n```shell\n$ python3 asrserver_grpc.py\n```\n\nTo test whether it is successful or not that calls api service interface with GRPC protocol:\n```shell\n$ python3 client_grpc.py\n```\n\nIf you want to train and use other model(not Model 251bn), make changes in the corresponding position of the `from speech_model.xxx import xxx` in the code files.\n\nIf there is any problem during the execution of the program or during use, it can be promptly put forward in the issue, and I will reply as soon as possible.\n\nDeploy ASRT by docker：\n```shell\n$ docker pull ailemondocker/asrt_service:1.3.0\n$ docker run --rm -it -p 20001:20001 -p 20002:20002 --name asrt-server -d ailemondocker/asrt_service:1.3.0\n```\nIt will start a api server for recognition rather than training.\n\n## Model\n\n### Speech Model\n\nDCNN + CTC\n\nThe maximum length of the input audio is 16 seconds, and the output is the corresponding Chinese pinyin sequence. \n\n* Questions about downloading trained models\n\nThe released finished software that includes trained model weights can be downloaded from [ASRT download page](https://wiki.ailemon.net/docs/asrt-doc/download). \n\nGithub [Releases](https://github.com/nl8590687/ASRT_SpeechRecognition/releases) page includes the archives of the various versions of the software released and it's introduction. Under each version module, there is a zip file that includes trained model weights files. \n\n### Language Model \n\nMaximum Entropy Hidden Markov Model Based on Probability Graph. \n\nThe input is a Chinese pinyin sequence, and the output is the corresponding Chinese character text. \n\n## About Accuracy\n\nAt present, the best model can basically reach 85% of Pinyin correct rate on the test set. \n\n## Python Dependency Library\n\n* tensorFlow (2.5-2.11+)\n* numpy\n* wave\n* matplotlib\n* math\n* scipy\n* requests\n* flask\n* waitress\n* grpcio / grpcio-tools / protobuf\n\nIf you have trouble when install those packages, please run the following script to do it as long as you have a GPU and python 3.9, CUDA 11.2 and cudnn 8.1 have been installed：\n\n```shell\n$ pip install -r requirements.txt\n```\n\n[Dependent Environment Details and Hardware Requirement](https://wiki.ailemon.net/docs/asrt-doc/asrt-doc-1deobk7bmlgd6)\n\n## ASRT Client SDK for Calling Speech Recognition API\n\nASRT provides the abilities to import client SDKs for several platform and programing language for client develop speech recognition features , which work by RPC. Please refer ASRT project documents for detail.\n\n|Client Platform|Project Repos Link|\n|-|-|\n|Windows Client SDK & Demo|[ASRT_SDK_WinClient](https://github.com/nl8590687/ASRT_SDK_WinClient)|\n|Python3 Client SDK & Demo (Any Platform)|[ASRT_SDK_Python3](https://github.com/nl8590687/ASRT_SDK_Python3)|\n|Golang Client SDK & Demo|[asrt-sdk-go](https://github.com/nl8590687/asrt-sdk-go)|\n|Java Client SDK & Demo|[ASRT_SDK_Java](https://github.com/nl8590687/ASRT_SDK_Java)|\n\n## Data Sets \n\nFor full content please refer: [Some free Chinese speech datasets (Chinese)](https://blog.ailemon.net/2018/11/21/free-open-source-chinese-speech-datasets/)\n\n|Dataset|Time|Size|Download (CN Mirrors)|Download (Source)|\n|-|-|-|-|-|\n|THCHS30|40h|6.01G|[data_thchs30.tgz](<http://openslr.magicdatatech.com/resources/18/data_thchs30.tgz>)|[data_thchs30.tgz](<http://www.openslr.org/resources/18/data_thchs30.tgz>)|\n|ST-CMDS|100h|7.67G|[ST-CMDS-20170001_1-OS.tar.gz](<http://openslr.magicdatatech.com/resources/38/ST-CMDS-20170001_1-OS.tar.gz>)|[ST-CMDS-20170001_1-OS.tar.gz](<http://www.openslr.org/resources/38/ST-CMDS-20170001_1-OS.tar.gz>)|\n|AIShell-1|178h|14.51G|[data_aishell.tgz](<http://openslr.magicdatatech.com/resources/33/data_aishell.tgz>)|[data_aishell.tgz](<http://www.openslr.org/resources/33/data_aishell.tgz>)|\n|Primewords|100h|8.44G|[primewords_md_2018_set1.tar.gz](<http://openslr.magicdatatech.com/resources/47/primewords_md_2018_set1.tar.gz>)|[primewords_md_2018_set1.tar.gz](<http://www.openslr.org/resources/47/primewords_md_2018_set1.tar.gz>)|\n|MagicData|755h|52G/1.0G/2.2G| [train_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/train_set.tar.gz>) / [dev_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/dev_set.tar.gz>) / [test_set.tar.gz](<http://openslr.magicdatatech.com/resources/68/test_set.tar.gz>)|[train_set.tar.gz](<http://www.openslr.org/resources/68/train_set.tar.gz>) / [dev_set.tar.gz](<http://www.openslr.org/resources/68/dev_set.tar.gz>) / [test_set.tar.gz](<http://www.openslr.org/resources/68/test_set.tar.gz>)|\n\n\n  Note：The way to unzip AISHELL-1 dataset\n\n  ```\n  $ tar xzf data_aishell.tgz\n  $ cd data_aishell/wav\n  $ for tar in *.tar.gz;  do tar xvf $tar; done\n  ```\n\nSpecial thanks! Thanks to the predecessors' public voice data set. \n\nIf the provided dataset link cannot be opened and downloaded, click this link [OpenSLR](http://www.openslr.org)\n\n## ASRT Docuemnts\n\n* [ASRT project's Wiki document](https://wiki.ailemon.net/docs/asrt-doc)\n\nA post about ASRT's introduction \n* [ASRT: Chinese Speech Recognition System (Chinese)](https://blog.ailemon.net/2018/08/29/asrt-a-chinese-speech-recognition-system/)\n\nAbout how to use ASRT to train and deploy：\n* [Teach you how to use ASRT to train Chinese ASR model (Chinese)](<https://blog.ailemon.net/2020/08/20/teach-you-how-use-asrt-train-chinese-asr-model/>)\n* [Teach you how to use ASRT to deploy Chinese ASR API Server (Chinese)](<https://blog.ailemon.net/2020/08/27/teach-you-how-use-asrt-deploy-chinese-asr-api-server/>)\n\nFor questions about the principles of the statistical language model that are often asked, see: \n* [Simple Chinese word frequency statistics to generate N-gram language model (Chinese)](https://blog.ailemon.net/2017/02/20/simple-words-frequency-statistic-without-segmentation-algorithm/)\n* [Statistical Language Model: Chinese Pinyin to Words (Chinese)](https://blog.ailemon.net/2017/04/27/statistical-language-model-chinese-pinyin-to-words/)\n\nFor questions about CTC, see: \n\n* [[Translation] Sequence Modeling with CTC (Chinese)](<https://blog.ailemon.net/2019/07/18/sequence-modeling-with-ctc/>)\n\nFor more infomation please refer to author's blog website: [AILemon Blog](https://blog.ailemon.net/) (Chinese)\n\n## License\n\n[GPL v3.0](LICENSE) © [nl8590687](https://github.com/nl8590687) Author: [ailemon](https://www.ailemon.net/)\n\n## Cite this project\n\n[DOI: 10.5281/zenodo.5808434](https://doi.org/10.5281/zenodo.5808434)\n\n## Contributors\n\n[Contributors Page](https://github.com/nl8590687/ASRT_SpeechRecognition/graphs/contributors)\n\n@nl8590687 (repo owner)\n"
        },
        {
          "name": "asrserver_grpc.py",
          "type": "blob",
          "size": 6.791015625,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\nASRT语音识别基于gRPC协议的API服务器程序\n\"\"\"\n\nimport argparse\nimport time\nfrom concurrent import futures\nimport grpc\n\nfrom assets.asrt_pb2_grpc import AsrtGrpcServiceServicer, add_AsrtGrpcServiceServicer_to_server\nfrom assets.asrt_pb2 import SpeechResponse, TextResponse\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom speech_features import Spectrogram\nfrom language_model3 import ModelLanguage\nfrom utils.ops import decode_wav_bytes\n\nAPI_STATUS_CODE_OK = 200000  # OK\nAPI_STATUS_CODE_OK_PART = 206000  # 部分结果OK，用于stream\nAPI_STATUS_CODE_CLIENT_ERROR = 400000\nAPI_STATUS_CODE_CLIENT_ERROR_FORMAT = 400001  # 请求数据格式错误\nAPI_STATUS_CODE_CLIENT_ERROR_CONFIG = 400002  # 请求数据配置不支持\nAPI_STATUS_CODE_SERVER_ERROR = 500000\nAPI_STATUS_CODE_SERVER_ERROR_RUNNING = 500001  # 服务器运行中出错\n\nparser = argparse.ArgumentParser(description='ASRT gRPC Protocol API Service')\nparser.add_argument('--listen', default='0.0.0.0', type=str, help='the network to listen')\nparser.add_argument('--port', default='20002', type=str, help='the port to listen')\nargs = parser.parse_args()\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = Spectrogram()\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\nms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\n\nml = ModelLanguage('model_language')\nml.load_model()\n\n_ONE_DAY_IN_SECONDS = 60 * 60 * 24\n\n\nclass ApiService(AsrtGrpcServiceServicer):\n    \"\"\"\n    继承AsrtGrpcServiceServicer,实现hello方法\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def Speech(self, request, context):\n        \"\"\"\n        具体实现Speech的方法, 并按照pb的返回对象构造SpeechResponse返回\n        :param request:\n        :param context:\n        :return:\n        \"\"\"\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                       channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result = ms.recognize_speech(wav_samples, wav_data.sample_rate)\n        print(\"语音识别声学模型结果:\", result)\n        return SpeechResponse(status_code=API_STATUS_CODE_OK, status_message='',\n                              result_data=result)\n\n    def Language(self, request, context):\n        \"\"\"\n        具体实现Language的方法, 并按照pb的返回对象构造TextResponse返回\n        :param request:\n        :param context:\n        :return:\n        \"\"\"\n        print('Language收到了请求:', request)\n        result = ml.pinyin_to_text(list(request.pinyins))\n        print('Language结果:', result)\n        return TextResponse(status_code=API_STATUS_CODE_OK, status_message='',\n                            text_result=result)\n\n    def All(self, request, context):\n        \"\"\"\n        具体实现All的方法, 并按照pb的返回对象构造TextResponse返回\n        :param request:\n        :param context:\n        :return:\n        \"\"\"\n        wav_data = request.wav_data\n        wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                       channels=wav_data.channels, byte_width=wav_data.byte_width)\n        result_speech = ms.recognize_speech(wav_samples, wav_data.sample_rate)\n        result = ml.pinyin_to_text(result_speech)\n        print(\"语音识别结果:\", result)\n        return TextResponse(status_code=API_STATUS_CODE_OK, status_message='',\n                            text_result=result)\n\n    def Stream(self, request_iterator, context):\n        \"\"\"\n        具体实现Stream的方法, 并按照pb的返回对象构造TextResponse返回\n        :param request_iterator:\n        :param context:\n        :return:\n        \"\"\"\n        result = list()\n        tmp_result_last = list()\n        beam_size = 100\n\n        for request in request_iterator:\n            wav_data = request.wav_data\n            wav_samples = decode_wav_bytes(samples_data=wav_data.samples,\n                                           channels=wav_data.channels,\n                                           byte_width=wav_data.byte_width)\n            result_speech = ms.recognize_speech(wav_samples, wav_data.sample_rate)\n\n            for item_pinyin in result_speech:\n                tmp_result = ml.pinyin_stream_decode(tmp_result_last, item_pinyin, beam_size)\n                if len(tmp_result) == 0 and len(tmp_result_last) > 0:\n                    result.append(tmp_result_last[0][0])\n                    print(\"流式语音识别结果：\", ''.join(result))\n                    yield TextResponse(status_code=API_STATUS_CODE_OK, status_message='',\n                                       text_result=''.join(result))\n                    result = list()\n\n                    tmp_result = ml.pinyin_stream_decode([], item_pinyin, beam_size)\n                tmp_result_last = tmp_result\n                yield TextResponse(status_code=API_STATUS_CODE_OK_PART, status_message='',\n                                   text_result=''.join(tmp_result[0][0]))\n\n        if len(tmp_result_last) > 0:\n            result.append(tmp_result_last[0][0])\n            print(\"流式语音识别结果：\", ''.join(result))\n            yield TextResponse(status_code=API_STATUS_CODE_OK, status_message='',\n                               text_result=''.join(result))\n\n\ndef run(host, port):\n    \"\"\"\n    gRPC API服务启动\n    :return:\n    \"\"\"\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n    add_AsrtGrpcServiceServicer_to_server(ApiService(), server)\n    server.add_insecure_port(''.join([host, ':', port]))\n    server.start()\n    print(\"start service...\")\n    try:\n        while True:\n            time.sleep(_ONE_DAY_IN_SECONDS)\n    except KeyboardInterrupt:\n        server.stop(0)\n\n\nif __name__ == '__main__':\n    run(host=args.listen, port=args.port)\n"
        },
        {
          "name": "asrserver_http.py",
          "type": "blob",
          "size": 6.64453125,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\nASRT语音识别基于HTTP协议的API服务器程序\n\"\"\"\n\nimport argparse\nimport base64\nimport json\nfrom flask import Flask, Response, request\n\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom speech_features import Spectrogram\nfrom language_model3 import ModelLanguage\nfrom utils.ops import decode_wav_bytes\n\nAPI_STATUS_CODE_OK = 200000  # OK\nAPI_STATUS_CODE_CLIENT_ERROR = 400000\nAPI_STATUS_CODE_CLIENT_ERROR_FORMAT = 400001  # 请求数据格式错误\nAPI_STATUS_CODE_CLIENT_ERROR_CONFIG = 400002  # 请求数据配置不支持\nAPI_STATUS_CODE_SERVER_ERROR = 500000\nAPI_STATUS_CODE_SERVER_ERROR_RUNNING = 500001  # 服务器运行中出错\n\nparser = argparse.ArgumentParser(description='ASRT HTTP+Json RESTful API Service')\nparser.add_argument('--listen', default='0.0.0.0', type=str, help='the network to listen')\nparser.add_argument('--port', default='20001', type=str, help='the port to listen')\nargs = parser.parse_args()\n\napp = Flask(\"ASRT API Service\")\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = Spectrogram()\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\nms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\n\nml = ModelLanguage('model_language')\nml.load_model()\n\n\nclass AsrtApiResponse:\n    \"\"\"\n    ASRT语音识别基于HTTP协议的API接口响应类\n    \"\"\"\n\n    def __init__(self, status_code, status_message='', result=''):\n        self.status_code = status_code\n        self.status_message = status_message\n        self.result = result\n\n    def to_json(self):\n        \"\"\"\n        类转json\n        \"\"\"\n        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True)\n\n\n# api接口根url:GET\n@app.route('/', methods=[\"GET\"])\ndef index_get():\n    \"\"\"\n    根路径handle GET方法\n    \"\"\"\n    buffer = ''\n    with open('assets/default.html', 'r', encoding='utf-8') as file_handle:\n        buffer = file_handle.read()\n    return Response(buffer, mimetype='text/html; charset=utf-8')\n\n\n# api接口根url:POST\n@app.route('/', methods=[\"POST\"])\ndef index_post():\n    \"\"\"\n    根路径handle POST方法\n    \"\"\"\n    json_data = AsrtApiResponse(API_STATUS_CODE_OK, 'ok')\n    buffer = json_data.to_json()\n    return Response(buffer, mimetype='application/json')\n\n\n# 获取分类列表\n@app.route('/<level>', methods=[\"POST\"])\ndef recognition_post(level):\n    \"\"\"\n    其他路径 POST方法\n    \"\"\"\n    # 读取json文件内容\n    try:\n        if level == 'speech':\n            request_data = request.get_json()\n            samples = request_data['samples']\n            wavdata_bytes = base64.urlsafe_b64decode(bytes(samples, encoding='utf-8'))\n            sample_rate = request_data['sample_rate']\n            channels = request_data['channels']\n            byte_width = request_data['byte_width']\n\n            wavdata = decode_wav_bytes(samples_data=wavdata_bytes,\n                                       channels=channels, byte_width=byte_width)\n            result = ms.recognize_speech(wavdata, sample_rate)\n\n            json_data = AsrtApiResponse(API_STATUS_CODE_OK, 'speech level')\n            json_data.result = result\n            buffer = json_data.to_json()\n            print('output:', buffer)\n            return Response(buffer, mimetype='application/json')\n        elif level == 'language':\n            request_data = request.get_json()\n\n            seq_pinyin = request_data['sequence_pinyin']\n\n            result = ml.pinyin_to_text(seq_pinyin)\n\n            json_data = AsrtApiResponse(API_STATUS_CODE_OK, 'language level')\n            json_data.result = result\n            buffer = json_data.to_json()\n            print('output:', buffer)\n            return Response(buffer, mimetype='application/json')\n        elif level == 'all':\n            request_data = request.get_json()\n\n            samples = request_data['samples']\n            wavdata_bytes = base64.urlsafe_b64decode(samples)\n            sample_rate = request_data['sample_rate']\n            channels = request_data['channels']\n            byte_width = request_data['byte_width']\n\n            wavdata = decode_wav_bytes(samples_data=wavdata_bytes,\n                                       channels=channels, byte_width=byte_width)\n            result_speech = ms.recognize_speech(wavdata, sample_rate)\n            result = ml.pinyin_to_text(result_speech)\n\n            json_data = AsrtApiResponse(API_STATUS_CODE_OK, 'all level')\n            json_data.result = result\n            buffer = json_data.to_json()\n            print('ASRT Result:', result, 'output:', buffer)\n            return Response(buffer, mimetype='application/json')\n        else:\n            request_data = request.get_json()\n            print('input:', request_data)\n            json_data = AsrtApiResponse(API_STATUS_CODE_CLIENT_ERROR, '')\n            buffer = json_data.to_json()\n            print('output:', buffer)\n            return Response(buffer, mimetype='application/json')\n    except Exception as except_general:\n        request_data = request.get_json()\n        # print(request_data['sample_rate'], request_data['channels'],\n        # request_data['byte_width'], len(request_data['samples']),\n        # request_data['samples'][-100:])\n        json_data = AsrtApiResponse(API_STATUS_CODE_SERVER_ERROR, str(except_general))\n        buffer = json_data.to_json()\n        # print(\"input:\", request_data, \"\\n\", \"output:\", buffer)\n        print(\"output:\", buffer, \"error:\", except_general)\n        return Response(buffer, mimetype='application/json')\n\n\nif __name__ == '__main__':\n    # for development env\n    # app.run(host='0.0.0.0', port=20001)\n    # for production env\n    import waitress\n\n    waitress.serve(app, host=args.listen, port=args.port)\n"
        },
        {
          "name": "asrt_config.json",
          "type": "blob",
          "size": 4.638671875,
          "content": "{\n    \"dict_filename\": \"dict.txt\",\n\n    \"dataset\":{\n        \"train\":[\n            {\n                \"name\": \"thchs30_train\",\n                \"data_list\": \"datalist/thchs30/train.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/thchs30/train.syllable.txt\"\n            },\n            {\n                \"name\": \"stcmds_train\",\n                \"data_list\": \"datalist/st-cmds/train.wav.txt\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/st-cmds/train.syllable.txt\"\n            },\n            {\n                \"name\": \"primewords_train\",\n                \"data_list\": \"datalist/primewords/train.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/primewords/train.syllable.txt\"\n            },\n            {\n                \"name\": \"aishell_train\",\n                \"data_list\": \"datalist/aishell/train.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aishell/train.syllable.txt\"\n            },\n            {\n                \"name\": \"aidatatang_train\",\n                \"data_list\": \"datalist/aidatatang_lst/train.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aidatatang_lst/train.syllable.txt\"\n            },\n            {\n                \"name\": \"magicdata_train\",\n                \"data_list\": \"datalist/magicdata_lst/train.wav.lst\",\n                \"data_path\": \"/data/speech_data/magicdata\",\n                \"label_list\": \"datalist/magicdata_lst/train.syllable.txt\"\n            }\n        ],\n\n        \"dev\":[\n            {\n                \"name\": \"thchs30_dev\",\n                \"data_list\": \"datalist/thchs30/cv.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/thchs30/cv.syllable.txt\"\n            },\n            {\n                \"name\": \"stcmds_dev\",\n                \"data_list\": \"datalist/st-cmds/dev.wav.txt\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/st-cmds/dev.syllable.txt\"\n            },\n            {\n                \"name\": \"primewords_dev\",\n                \"data_list\": \"datalist/primewords/dev.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/primewords/dev.syllable.txt\"\n            },\n            {\n                \"name\": \"aishell_dev\",\n                \"data_list\": \"datalist/aishell/dev.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aishell/dev.syllable.txt\"\n            },\n            {\n                \"name\": \"aidatatang_dev\",\n                \"data_list\": \"datalist/aidatatang_lst/dev.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aidatatang_lst/dev.syllable.txt\"\n            },\n            {\n                \"name\": \"magicdata_dev\",\n                \"data_list\": \"datalist/magicdata_lst/dev.wav.lst\",\n                \"data_path\": \"/data/speech_data/magicdata\",\n                \"label_list\": \"datalist/magicdata_lst/dev.syllable.txt\"\n            }\n        ],\n\n        \"test\":[\n            {\n                \"name\": \"thchs30_test\",\n                \"data_list\": \"datalist/thchs30/test.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/thchs30/test.syllable.txt\"\n            },\n            {\n                \"name\": \"stcmds_test\",\n                \"data_list\": \"datalist/st-cmds/test.wav.txt\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/st-cmds/test.syllable.txt\"\n            },\n            {\n                \"name\": \"primewords_test\",\n                \"data_list\": \"datalist/primewords/test.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/primewords/test.syllable.txt\"\n            },\n            {\n                \"name\": \"aishell_test\",\n                \"data_list\": \"datalist/aishell/test.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aishell/test.syllable.txt\"\n            },\n            {\n                \"name\": \"aidatatang_test\",\n                \"data_list\": \"datalist/aidatatang_lst/test.wav.lst\",\n                \"data_path\": \"/data/speech_data\",\n                \"label_list\": \"datalist/aidatatang_lst/test.syllable.txt\"\n            },\n            {\n                \"name\": \"magicdata_test\",\n                \"data_list\": \"datalist/magicdata_lst/test.wav.lst\",\n                \"data_path\": \"/data/speech_data/magicdata\",\n                \"label_list\": \"datalist/magicdata_lst/test.syllable.txt\"\n            }\n        ]\n    }\n}"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "client_grpc.py",
          "type": "blob",
          "size": 3.8447265625,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\nASRT语音识别asrserver grpc协议测试专用客户端\n\"\"\"\n\nimport grpc\nimport time\n\nfrom assets.asrt_pb2_grpc import AsrtGrpcServiceStub\nfrom assets.asrt_pb2 import SpeechRequest, LanguageRequest, WavData\n\nfrom utils.ops import read_wav_bytes\n\n\ndef run_speech():\n    \"\"\"\n    请求ASRT服务Speech方法\n    :return:\n    \"\"\"\n    conn = grpc.insecure_channel('127.0.0.1:20002')\n    client = AsrtGrpcServiceStub(channel=conn)\n\n    wav_bytes, sample_rate, channels, sample_width = read_wav_bytes('assets/A11_0.wav')\n    print('sample_width:', sample_width)\n    wav_data = WavData(samples=wav_bytes, sample_rate=sample_rate,\n                       channels=channels, byte_width=sample_width)\n\n    request = SpeechRequest(wav_data=wav_data)\n    time_stamp0 = time.time()\n    response = client.Speech(request)\n    time_stamp1 = time.time()\n    print('time:', time_stamp1 - time_stamp0, 's')\n    print(\"received:\", response.result_data)\n\n\ndef run_lan():\n    \"\"\"\n    请求ASRT服务Language方法\n    :return:\n    \"\"\"\n    conn = grpc.insecure_channel('127.0.0.1:20002')\n    client = AsrtGrpcServiceStub(channel=conn)\n    pinyin_data = ['ni3', 'hao3', 'ya5']\n    request = LanguageRequest(pinyins=pinyin_data)\n    time_stamp0 = time.time()\n    response = client.Language(request)\n    time_stamp1 = time.time()\n    print('time:', time_stamp1 - time_stamp0, 's')\n    print(\"received:\", response.text_result)\n\n\ndef run_all():\n    \"\"\"\n    请求ASRT服务All方法\n    :return:\n    \"\"\"\n    conn = grpc.insecure_channel('127.0.0.1:20002')\n    client = AsrtGrpcServiceStub(channel=conn)\n\n    wav_bytes, sample_rate, channels, sample_width = read_wav_bytes('assets/A11_0.wav')\n    print('sample_width:', sample_width)\n    wav_data = WavData(samples=wav_bytes, sample_rate=sample_rate,\n                       channels=channels, byte_width=sample_width)\n\n    request = SpeechRequest(wav_data=wav_data)\n    time_stamp0 = time.time()\n    response = client.All(request)\n    time_stamp1 = time.time()\n    print(\"received:\", response.text_result)\n    print('time:', time_stamp1 - time_stamp0, 's')\n\n\ndef run_stream():\n    \"\"\"\n    请求ASRT服务Stream方法\n    :return:\n    \"\"\"\n    conn = grpc.insecure_channel('127.0.0.1:20002')\n    client = AsrtGrpcServiceStub(channel=conn)\n\n    wav_bytes, sample_rate, channels, sample_width = read_wav_bytes('assets/A11_0.wav')\n    print('sample_width:', sample_width)\n    wav_data = WavData(samples=wav_bytes, sample_rate=sample_rate,\n                       channels=channels, byte_width=sample_width)\n\n    # 先制造一些客户端能发送的数据\n    def make_some_data():\n        for _ in range(1):\n            time.sleep(1)\n            yield SpeechRequest(wav_data=wav_data)\n\n    try:\n        status_response = client.Stream(make_some_data())\n        for ret in status_response:\n            print(\"received:\", ret.text_result, \" , status:\", ret.status_code)\n            time.sleep(0.1)\n    except Exception as any_exception:\n        print(f'err in send_status:{any_exception}')\n        return\n\n\nif __name__ == '__main__':\n    # run_all()\n    run_stream()\n"
        },
        {
          "name": "client_http.py",
          "type": "blob",
          "size": 1.4970703125,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n'''\n@author: nl8590687\nASRT语音识别asrserver http协议测试专用客户端\n'''\nimport base64\nimport json\nimport time\nimport requests\nfrom utils.ops import read_wav_bytes\n\nURL = 'http://127.0.0.1:20001/all'\n\nwav_bytes, sample_rate, channels, sample_width = read_wav_bytes('assets/A11_0.wav')\ndatas = {\n    'channels': channels,\n    'sample_rate': sample_rate,\n    'byte_width': sample_width,\n    'samples': str(base64.urlsafe_b64encode(wav_bytes), encoding='utf-8')\n}\nheaders = {'Content-Type': 'application/json'}\n\nt0=time.time()\nr = requests.post(URL, headers=headers, data=json.dumps(datas))\nt1=time.time()\nr.encoding='utf-8'\n\nresult = json.loads(r.text)\nprint(result)\nprint('time:', t1-t0, 's')\n"
        },
        {
          "name": "data_loader.py",
          "type": "blob",
          "size": 3.4921875,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n加载语音数据集用的数据加载器的定义\n\"\"\"\nimport os\nimport random\nimport numpy as np\nfrom utils.config import load_config_file, DEFAULT_CONFIG_FILENAME, load_pinyin_dict\nfrom utils.ops import read_wav_data\n\n\nclass DataLoader:\n    \"\"\"\n    数据加载器\n\n    参数：\\\\\n        config: 配置信息字典\n        dataset_type: 要加载的数据集类型，包含('train', 'dev', 'test')三种\n    \"\"\"\n    def __init__(self, dataset_type:str):\n        self.dataset_type = dataset_type\n\n        self.data_list = list()\n        self.wav_dict = dict()\n        self.label_dict = dict()\n        self.pinyin_list = list()\n        self.pinyin_dict = dict()\n        self._load_data()\n\n    def _load_data(self):\n        config = load_config_file(DEFAULT_CONFIG_FILENAME)\n\n        self.pinyin_list, self.pinyin_dict = load_pinyin_dict(config['dict_filename'])\n\n        for index in range(len(config['dataset'][self.dataset_type])):\n            filename_datalist = config['dataset'][self.dataset_type][index]['data_list']\n            filename_datapath = config['dataset'][self.dataset_type][index]['data_path']\n            with open(filename_datalist, 'r', encoding='utf-8') as file_pointer:\n                lines = file_pointer.read().split('\\n')\n                for line in lines:\n                    if len(line) == 0:\n                        continue\n                    tokens = line.split(' ')\n                    self.data_list.append(tokens[0])\n                    self.wav_dict[tokens[0]] = os.path.join(filename_datapath, tokens[1])\n\n            filename_labellist = config['dataset'][self.dataset_type][index]['label_list']\n            with open(filename_labellist, 'r', encoding='utf-8') as file_pointer:\n                lines = file_pointer.read().split('\\n')\n                for line in lines:\n                    if len(line) == 0:\n                        continue\n                    tokens = line.split(' ')\n                    self.label_dict[tokens[0]] = tokens[1:]\n\n    def get_data_count(self) -> int:\n        \"\"\"\n        获取数据集总数量\n        \"\"\"\n        return len(self.data_list)\n\n    def get_data(self, index: int) -> tuple:\n        \"\"\"\n        按下标获取一条数据\n        \"\"\"\n        mark = self.data_list[index]\n\n        wav_signal, sample_rate, _, _ = read_wav_data(self.wav_dict[mark])\n        labels = list()\n        for item in self.label_dict[mark]:\n            if len(item) == 0:\n                continue\n            labels.append(self.pinyin_dict[item])\n\n        data_label = np.array(labels)\n        return wav_signal, sample_rate, data_label\n\n    def shuffle(self) -> None:\n        \"\"\"\n        随机打乱数据\n        \"\"\"\n        random.shuffle(self.data_list)\n"
        },
        {
          "name": "datalist",
          "type": "tree",
          "content": null
        },
        {
          "name": "dict.txt",
          "type": "blob",
          "size": 31.615234375,
          "content": "a1\t阿啊呵腌吖锕\na2\t啊呵嗄\na3\t啊\na4\t啊呵\na5\t阿啊呵\nai1\t哀挨埃唉哎捱锿诶\nai2\t挨癌皑呆捱矮\nai3\t矮蔼哎霭嗳\nai4\t爱碍艾唉哎隘暧嗳瑷嗌嫒砹\nan1\t安谙鞍氨庵桉鹌\nan3\t俺铵揞埯\nan4\t案按暗岸黯胺犴\nang1\t肮\nang2\t昂\nang4\t盎\nao1\t凹熬\nao2\t熬敖嚣嗷鏖鳌翱獒聱螯廒遨\nao3\t袄拗媪\nao4\t奥澳傲懊坳拗骜岙鏊\nba1\t八巴吧叭芭扒疤笆粑岜\nba2\t拔跋八茇菝魃\nba3\t把靶钯\nba4\t爸罢霸坝把耙灞鲅壩\nba5\t吧罢叭\nbai1\t掰\nbai2\t白百\nbai3\t百摆伯柏佰捭\nbai4\t败拜呗稗\nban1\t般班搬斑颁扳瘢癍\nban3\t版板阪坂钣舨\nban4\t办半伴扮瓣拌绊\nbang1\t帮邦浜梆\nbang3\t膀榜绑\nbang4\t棒膀傍磅谤镑蚌蒡\nbao1\t包胞炮剥褒苞孢煲龅\nbao2\t薄雹保\nbao3\t保宝饱堡葆褓鸨\nbao4\t报暴抱爆鲍曝刨瀑豹趵\nbei1\t背悲杯碑卑陂埤萆鹎\nbei3\t北\nbei4\t被备背辈倍贝蓓惫悖狈焙邶钡孛碚褙鐾鞴\nbei5\t臂呗\nben1\t奔贲锛\nben3\t本苯畚\nben4\t奔笨夯坌\nbeng1\t崩绷嘣\nbeng2\t甭\nbeng3\t绷\nbeng4\t绷蹦迸甏泵蚌\nbi1\t逼\nbi2\t鼻荸匕比\nbi3\t比笔彼鄙匕俾妣吡秕舭\nbi4\t必毕币秘避闭壁臂弊辟碧拂毙蔽庇璧敝泌陛弼篦婢愎痹铋裨髀哔\nbian1\t编边鞭砭\nbian3\t贬扁匾碥褊\nbian4\t便变遍辩辨辫卞苄汴忭弁缏\nbian5\t边\nbiao1\t标彪镖膘骠镳杓飚飑飙瘭髟\nbiao3\t表裱婊\nbiao4\t鳔\nbie1\t憋瘪鳖\nbie2\t别蹩\nbie3\t瘪\nbie4\t别\nbin1\t宾滨彬斌缤濒槟傧玢豳镔\nbin4\t鬓殡摈膑髌\nbing1\t兵冰并槟\nbing3\t饼屏丙柄秉炳禀邴\nbing4\t并病摒\nbo1\t波播拨剥玻饽菠钵趵鲅\nbo2\t博伯勃薄泊柏驳魄脖搏膊舶礴帛铂箔渤钹孛亳鹁踣饽\nbo3\t簸跛\nbo4\t薄柏簸擘檗\nbo5\t卜啵膊\nbu1\t逋晡钸\nbu2\t不醭补\nbu3\t补捕堡卜哺卟\nbu4\t不部布步怖簿埔埠瓿钚\nca1\t擦拆嚓\nca3\t礤\ncai1\t猜\ncai2\t才财材裁\ncai3\t采彩踩睬\ncai4\t采菜蔡\ncan1\t参餐骖\ncan2\t残惭蚕\ncan3\t惨黪\ncan4\t灿掺璨孱粲\ncang1\t苍仓沧舱伧\ncang2\t藏\ncao1\t操糙\ncao2\t曹槽嘈漕螬艚草\ncao3\t草\nce4\t策测侧厕册恻\ncen1\t参\ncen2\t岑涔\nceng1\t噌\nceng2\t曾层\nceng4\t蹭\ncha1\t差插叉碴喳嚓杈馇锸\ncha2\t查察茶叉茬碴楂猹搽槎檫\ncha3\t叉衩镲\ncha4\t差刹叉诧岔衩杈汊姹\nchai1\t差拆钗\nchai2\t柴豺侪\nchai4\t虿瘥\nchan1\t搀掺觇\nchan2\t缠禅蝉馋潺蟾婵谗廛孱镡澶躔产单\nchan3\t产铲阐谄冁蒇骣\nchan4\t颤忏羼\nchang1\t昌娼猖伥阊菖鲳\nchang2\t长场常尝肠偿倘裳嫦徜苌厂\nchang3\t场厂敞氅昶惝\nchang4\t唱畅倡怅鬯\nchao1\t超抄吵钞绰剿焯怊\nchao2\t朝潮嘲巢晁\nchao3\t炒吵\nchao4\t耖\nche1\t车砗\nche3\t扯\nche4\t彻撤澈掣坼辙\nchen1\t郴琛嗔抻\nchen2\t陈沉晨沈尘臣辰橙忱谌宸陳\nchen3\t碜\nchen4\t称趁衬谶榇龀\nchen5\t伧\ncheng1\t称撑秤瞠噌铛柽蛏\ncheng2\t成城程承诚盛乘呈惩澄橙丞埕枨塍铖裎酲\ncheng3\t逞骋裎\ncheng4\t称秤\nchi1\t吃痴哧嗤蚩笞鸱媸螭眵魑\nchi2\t持迟池驰匙弛踟墀茌篪坻\nchi3\t尺齿耻侈褫豉\nchi4\t赤斥翅啻炽敕叱饬傺彳瘛眙\nchong1\t冲充涌憧忡艟舂茺衝\nchong2\t重崇虫\nchong3\t宠\nchong4\t冲铳\nchou1\t抽瘳\nchou2\t愁仇筹酬绸踌惆畴稠帱俦雠\nchou3\t丑瞅\nchou4\t臭\nchu1\t出初樗\nchu2\t除厨躇橱雏锄蜍刍滁蹰处\nchu3\t处楚储础杵褚楮\nchu4\t处触畜矗怵搐绌黜亍憷\nchuai1\t揣搋\nchuai3\t揣\nchuai4\t揣啜踹嘬膪\nchuan1\t穿川巛氚\nchuan2\t传船遄椽舡\nchuan3\t喘舛\nchuan4\t串钏\nchuang1\t创窗疮\nchuang2\t床幢\nchuang3\t闯\nchuang4\t创怆\nchui1\t吹炊\nchui2\t垂锤捶陲椎槌棰\nchun1\t春椿蝽\nchun2\t纯唇醇淳鹑莼\nchun3\t蠢\nchuo1\t戳踔\nchuo4\t绰啜辍龊\nci1\t差刺疵呲\nci2\t词辞慈磁瓷兹茨雌祠茈鹚糍\nci3\t此\nci4\t次刺赐伺蚝\ncong1\t匆聪葱囱苁骢璁枞\ncong2\t从丛琮淙\ncou4\t凑辏腠\ncu1\t粗\ncu2\t徂殂\ncu4\t促簇醋卒猝蹴蹙蔟酢\ncuan1\t蹿撺汆镩\ncuan2\t攒\ncuan4\t窜篡爨\ncui1\t衰催摧崔隹榱\ncui3\t璀\ncui4\t脆粹萃翠瘁悴淬毳啐\ncun1\t村皴\ncun2\t存蹲\ncun3\t忖\ncun4\t寸\ncuo1\t搓撮磋蹉\ncuo2\t嵯矬痤瘥鹾\ncuo3\t脞\ncuo4\t错措挫厝锉\nda1\t答搭嗒耷褡哒\nda2\t打达答瘩沓鞑怛笪靼妲\nda3\t打\nda4\t大\nda5\t塔疸瘩\ndai1\t待呆呔\ndai3\t逮歹傣\ndai4\t大代带待戴袋贷逮殆黛怠玳岱迨骀绐埭甙帶\ndan1\t单担丹耽眈殚箪儋瘅聃郸\ndan3\t担胆掸赕疸\ndan4\t但担石弹淡旦蛋诞惮啖澹氮萏瘅\ndang1\t当裆铛當\ndang3\t党挡谠档\ndang4\t当荡档挡宕菪凼砀\ndao1\t刀叨忉氘\ndao2\t叨导\ndao3\t导倒岛蹈捣祷\ndao4\t到道倒悼盗稻\nde2\t得德锝嘚\nde4\t嘚\nde5\t的地得\ndei3\t得\ndeng1\t登灯蹬噔簦\ndeng3\t等戥\ndeng4\t邓凳瞪澄蹬磴镫嶝\ndi1\t提低滴堤嘀氐镝羝\ndi2\t敌笛的迪涤嘀狄嫡翟荻籴觌镝\ndi3\t底抵诋邸砥坻柢氐骶\ndi4\t地第帝弟递蒂缔谛睇棣娣碲\ndi5\t弟\ndia3\t嗲\ndian1\t颠滇掂癫巅\ndian3\t点典碘踮丶點\ndian4\t电店甸淀垫殿奠惦佃玷簟坫靛钿癜阽\ndiao1\t雕刁凋叼貂碉鲷\ndiao3\t鸟屌\ndiao4\t调掉吊钓铫铞調\ndie1\t爹跌\ndie2\t叠迭碟谍蝶喋佚牒耋蹀堞瓞揲垤鲽\nding1\t丁盯钉叮町酊疔仃耵玎\nding3\t顶鼎酊\nding4\t定订钉铤腚锭碇啶\ndiu1\t丢铥丟\ndong1\t东冬咚岽氡鸫\ndong3\t懂董\ndong4\t动洞冻栋恫侗垌峒胨胴硐動\ndou1\t都兜蔸篼\ndou3\t斗抖陡蚪\ndou4\t读斗豆逗窦痘\ndu1\t都督嘟\ndu2\t读独顿毒渎牍犊黩髑椟\ndu3\t肚睹堵赌笃\ndu4\t度渡肚杜妒镀芏蠹\nduan1\t端\nduan3\t短\nduan4\t断段锻缎煅椴簖\ndui1\t堆\ndui4\t对队兑敦碓憝怼镦對\ndun1\t吨敦蹲墩礅镦\ndun3\t盹趸\ndun4\t顿盾钝炖遁沌囤砘\nduo1\t多咄哆掇裰\nduo2\t度夺踱铎掇\nduo3\t朵躲垛哚缍\nduo4\t舵堕跺剁惰垛驮柁\ne1\t阿婀屙\ne2\t额俄哦鹅娥峨蛾讹莪锇\ne3\t恶\ne4\t恶饿扼愕遏噩呃厄鄂轭颚鳄谔锷萼腭垩鹗苊阏惡\ne5\t呃\nei2\t诶\nei3\t诶\nei4\t诶\nen1\t恩蒽\nen4\t摁嗯\ner2\t而儿鸸鲕耳\ner3\t尔耳迩饵洱珥铒\ner4\t二佴\nfa1\t发\nfa2\t罚乏伐阀筏垡\nfa3\t法砝\nfa4\t发珐\nfan1\t翻番帆藩幡蕃\nfan2\t凡烦繁樊蕃燔矾蘩钒蹯\nfan3\t反返\nfan4\t饭犯范贩泛梵畈飯\nfang1\t方芳妨坊邡枋钫\nfang2\t房防妨坊肪鲂\nfang3\t访仿纺彷舫紡\nfang4\t放\nfang5\t坊\nfei1\t非飞啡菲扉霏妃绯蜚鲱\nfei2\t肥腓淝\nfei3\t菲匪诽斐蜚翡悱篚榧\nfei4\t费废沸肺吠痱狒镄芾砩\nfen1\t分纷氛芬吩酚玢\nfen2\t坟焚汾棼鼢\nfen3\t粉\nfen4\t分份奋愤粪忿偾瀵鲼\nfeng1\t风封丰峰疯锋蜂枫烽酆葑沣砜鋒\nfeng2\t逢缝冯\nfeng3\t讽唪\nfeng4\t奉缝凤俸葑鳳\nfo2\t佛\nfou3\t否缶\nfu1\t夫肤敷孵呋稃麸趺跗\nfu2\t夫服福佛幅伏符浮扶弗拂袱俘芙孚匐辐涪氟桴蜉苻茯莩菔幞怫艴郛绂绋凫祓砩黻罘稃蚨芾蝠\nfu3\t府父腐抚辅甫俯斧脯釜腑拊滏黼符莆\nfu4\t服复父负副富付妇附赴腹覆赋傅缚咐阜讣驸赙馥蝮鲋鳆負\nfu5\t咐服袱夫腐复\nga1\t咖嘎胳伽旮\nga2\t嘎噶轧尜钆\nga3\t嘎尕\nga4\t尬\ngai1\t该赅垓陔\ngai3\t改\ngai4\t概盖丐钙芥溉戤\ngan1\t干甘肝杆尴乾竿坩苷柑泔矸疳酐\ngan2\t赶敢\ngan3\t感敢赶杆橄秆擀澉\ngan4\t干赣淦绀旰\ngang1\t刚钢纲缸扛杠冈肛罡剛\ngang3\t港岗\ngang4\t钢杠戆筻\ngao1\t高糕膏皋羔睾篙槔\ngao3\t稿搞藁槁缟镐杲\ngao4\t告膏诰郜锆\nge1\t歌格哥戈割胳搁疙咯鸽屹仡圪纥袼\nge2\t革格隔葛阁胳搁蛤嗝骼颌搿膈镉塥鬲噶\nge3\t个各合盖葛哿舸\nge4\t个各铬硌虼個\ngei3\t给給\ngen1\t根跟\ngen2\t哏\ngen3\t艮\ngen4\t亘艮茛\ngeng1\t更耕庚羹赓\ngeng3\t耿颈梗哽鲠埂绠\ngeng4\t更\ngong1\t工公共红供功攻宫恭躬龚弓肱蚣觥\ngong3\t巩拱汞珙\ngong4\t共供贡\ngou1\t句沟勾钩篝佝枸缑鞲\ngou3\t狗苟岣枸笱\ngou4\t够购构勾觏垢诟媾遘彀\ngu1\t姑骨孤估辜咕呱箍沽菇轱鸪毂菰蛄酤觚\ngu2\t骨古鼓谷\ngu3\t古股鼓骨谷贾汩蛊毂鹄牯臌诂瞽罟钴嘏蛄鹘\ngu4\t故顾固估雇锢梏牿崮痼鲴\ngua1\t括瓜刮呱栝胍鸹\ngua3\t寡呱剐\ngua4\t挂褂卦诖\nguai1\t乖掴\nguai3\t拐\nguai4\t怪\nguan1\t关观官冠棺矜莞倌纶鳏\nguan3\t管馆莞\nguan4\t观惯冠贯罐灌掼盥涫鹳\nguang1\t光咣胱桄\nguang3\t广犷\nguang4\t逛桄\ngui1\t规归瑰龟硅闺皈傀圭妫鲑\ngui3\t鬼轨诡癸匦庋宄晷簋\ngui4\t贵桂跪柜刽炔刿桧炅鳜匮\ngun3\t滚鲧衮绲磙辊\ngun4\t棍\nguo1\t过锅郭涡聒蝈崞埚呙\nguo2\t国帼掴馘虢\nguo3\t果裹猓椁蜾\nguo4\t过過\nha1\t哈铪\nha2\t虾蛤\nha3\t哈\nha4\t哈\nhai1\t嘿咳嗨\nhai2\t还孩骸海還\nhai3\t海胲醢\nhai4\t害亥骇氦\nhan1\t酣憨顸鼾蚶\nhan2\t含寒汗韩涵函晗焓邯邗\nhan3\t喊罕阚\nhan4\t汉汗憾翰撼旱捍悍瀚焊颔菡撖\nhang1\t夯\nhang2\t行航吭杭绗珩颃\nhang4\t行巷沆\nhao1\t蒿薅嚆\nhao2\t号毫豪嚎壕貉嗥濠蚝好\nhao3\t好郝\nhao4\t好号浩耗皓昊灏镐颢\nhe1\t喝呵诃嗬\nhe2\t和何合河核盒禾荷阂涸阖貉曷颌劾菏盍纥蚵翮\nhe4\t和何喝赫吓贺荷鹤壑褐\nhei1\t黑嘿嗨\nhen2\t痕很\nhen3\t很狠\nhen4\t恨\nheng1\t哼亨\nheng2\t横衡恒蘅珩桁\nheng4\t横\nheng5\t哼\nhong1\t轰哄烘薨訇\nhong2\t红洪鸿宏虹弘泓闳蕻黉荭\nhong3\t哄\nhong4\t哄讧蕻\nhou2\t侯喉猴瘊篌糇骺\nhou3\t吼\nhou4\t后候後厚侯逅堠鲎\nhu1\t乎呼戏忽糊惚唿滹轷烀\nhu2\t和胡湖糊核壶狐葫弧蝴囫瑚斛鹄醐猢槲鹕觳煳鹘\nhu3\t虎浒唬琥\nhu4\t护户互糊虎沪祜扈戽笏岵怙瓠鹱冱\nhua1\t华化花哗砉\nhua2\t华划滑哗豁猾骅铧\nhua4\t话华化划画桦\nhuai2\t怀徊淮槐踝\nhuai4\t坏\nhuai5\t划\nhuan1\t欢獾\nhuan2\t还环寰鬟桓圜洹郇缳锾萑\nhuan3\t缓\nhuan4\t换患幻唤宦焕痪涣浣奂擐豢漶逭鲩\nhuang1\t荒慌肓\nhuang2\t黄皇煌惶徨璜簧凰潢蝗蟥遑隍磺癀湟篁鳇黃\nhuang3\t晃恍谎幌\nhuang4\t晃\nhui1\t挥辉灰恢徽堕诙晖麾珲咴虺隳\nhui2\t回徊蛔茴洄\nhui3\t毁悔虺\nhui4\t会汇惠慧溃绘讳贿晦秽诲彗烩荟卉喙恚浍哕缋桧蕙蟪\nhun1\t婚昏荤阍\nhun2\t混魂浑馄珲\nhun4\t混诨溷\nhuo1\t豁劐攉锪耠\nhuo2\t和活火\nhuo3\t火伙夥钬\nhuo4\t和或获货祸惑霍豁藿嚯镬蠖\nji1\t其几期机基击奇激积鸡迹绩饥缉圾姬矶肌讥叽稽畸跻羁嵇唧畿齑箕屐剞玑赍犄墼芨丌咭笄乩績\nji2\t及即辑级极集急籍吉疾嫉藉脊棘汲岌笈瘠诘亟楫蒺殛佶戢嵴蕺给圾\nji3\t几给己革济纪挤脊戟虮掎麂\nji4\t记系计济寄际技纪继既齐季寂祭忌剂冀妓骥蓟悸伎暨霁稷偈鲫髻觊荠跽哜鲚洎芰迹绩\njia1\t家加佳夹嘉茄挟枷珈迦伽浃痂笳葭镓袈跏\njia2\t夹颊戛荚郏恝铗袷蛱浃\njia3\t假甲贾胛岬钾嘏瘕\njia4\t价假架驾嫁稼\njia5\t家\njian1\t间坚监渐兼艰肩浅尖奸溅煎歼缄笺菅蒹搛湔缣戋犍鹣鲣鞯\njian3\t简减检剪捡拣俭碱茧柬蹇謇硷睑锏枧戬谫囝裥笕翦趼\njian4\t见间件建监渐健剑键荐鉴践舰箭贱溅槛谏僭涧饯毽锏楗腱牮踺\njiang1\t将江疆姜浆僵缰茳礓豇\njiang3\t讲奖蒋桨耩蔣\njiang4\t将强降酱浆虹匠犟绛洚糨\njiao1\t教交焦骄郊胶椒娇浇姣跤蕉礁鲛僬鹪蛟艽茭\njiao2\t嚼矫脚\njiao3\t角脚搅缴绞饺矫佼狡剿侥皎挢徼湫敫铰\njiao4\t教觉校叫较轿嚼窖酵噍峤徼醮\njie1\t接结节街阶皆揭楷嗟秸疖喈\njie2\t结节杰捷截洁劫竭睫桔拮孑诘桀碣偈颉讦婕羯鲒解結\njie3\t解姐\njie4\t界解价介借戒届藉诫芥疥蚧骱\njie5\t姐\njin1\t今金禁津斤筋巾襟矜衿\njin3\t尽仅紧谨锦瑾馑卺廑堇槿\njin4\t进近尽仅禁劲晋浸靳缙烬噤觐荩赆妗\njing1\t经京精惊睛晶荆兢鲸泾旌茎腈菁粳\njing3\t警景井颈憬阱儆刭肼\njing4\t经境竟静敬镜劲竞净径靖痉迳胫弪婧獍靓\njiong1\t扃\njiong3\t窘炯迥炅囧\njiu1\t究纠揪鸠赳啾阄鬏\njiu3\t九酒久韭灸玖\njiu4\t就旧救疚舅咎臼鹫僦厩桕柩\nju1\t车据且居俱拘驹鞠锯趄掬疽裾苴椐锔狙琚雎鞫蜛沮\nju2\t局菊桔橘锔举\nju3\t举柜矩咀沮踽龃榉莒枸\nju4\t据句具剧巨聚拒距俱惧沮瞿锯炬飓踞遽倨钜犋屦榘窭讵醵苣\njuan1\t捐圈娟鹃涓镌蠲\njuan3\t卷锩\njuan4\t圈卷倦眷隽绢狷桊鄄劵\njue1\t嗟撅噘\njue2\t觉绝决角脚嚼掘诀崛爵抉倔獗厥蹶攫谲矍孓橛噱珏桷劂爝镢蕨觖\njue3\t蹶\njue4\t倔\njun1\t军均君钧筠龟菌皲麇\njun4\t俊峻隽菌郡骏竣捃浚\nka1\t咖喀咔\nka3\t卡咯咔佧胩\nkai1\t开揩锎\nkai3\t慨凯铠楷恺蒈剀垲锴\nkai4\t忾\nkan1\t看刊堪勘龛戡\nkan3\t侃砍坎槛莰\nkan4\t看嵌瞰阚磡\nkang1\t康慷糠闶\nkang2\t扛\nkang4\t抗炕亢伉闶钪\nkao1\t尻\nkao3\t考烤拷栲\nkao4\t靠铐犒\nke1\t科颗柯呵棵苛磕坷嗑瞌轲稞疴蝌钶窠颏珂髁\nke2\t咳壳颏可\nke3\t可渴坷轲岢\nke4\t克客刻课恪嗑溘骒缂氪锞蚵科可\nken3\t肯恳啃垦龈\nken4\t裉\nkeng1\t坑吭铿\nkong1\t空倥崆箜\nkong3\t恐孔倥\nkong4\t空控\nkou1\t抠芤眍\nkou3\t口\nkou4\t扣寇叩蔻筘\nku1\t哭枯窟骷刳堀\nku3\t苦\nku4\t库裤酷喾绔\nkua1\t夸\nkua3\t垮侉\nkua4\t跨挎胯\nkuai3\t蒯\nkuai4\t快块筷脍会哙侩狯浍郐\nkuan1\t宽髋\nkuan3\t款\nkuang1\t框筐匡哐诓\nkuang2\t狂诳\nkuang3\t夼\nkuang4\t况矿框旷眶邝圹纩贶況\nkui1\t亏窥盔岿悝\nkui2\t魁睽逵葵奎馗夔喹隗暌揆蝰\nkui3\t傀跬\nkui4\t愧溃馈匮喟聩篑蒉愦\nkun1\t昆坤鲲锟醌琨髡\nkun3\t捆悃阃\nkun4\t困\nkuo4\t括适阔扩廓栝蛞\nla1\t拉啦喇垃邋\nla2\t拉喇旯砬\nla3\t拉喇\nla4\t落拉辣腊蜡剌瘌\nla5\t啦\nlai2\t来莱徕涞崃铼來\nlai4\t赖睐癞籁赉濑\nlan2\t兰蓝栏拦篮澜婪岚斓阑褴镧谰\nlan3\t懒览揽榄缆漤罱懶\nlan4\t烂滥\nlang1\t啷\nlang2\t狼郎廊琅螂榔锒稂阆\nlang3\t朗\nlang4\t浪郎莨蒗阆\nlao1\t捞\nlao2\t劳牢唠崂铹痨醪老\nlao3\t老姥佬潦栳铑\nlao4\t落络唠烙酪涝耢\nlao5\t姥\nle1\t肋\nle4\t乐勒仂叻泐鳓\nle5\t了\nlei1\t勒擂\nlei2\t累雷擂羸镭嫘缧檑蕾\nlei3\t累蕾垒磊儡诔耒\nlei4\t类泪累擂肋酹\nlei5\t嘞\nleng1\t棱\nleng2\t楞棱塄冷\nleng3\t冷\nleng4\t愣\nli1\t哩\nli2\t离丽黎璃漓狸梨篱犁厘罹藜骊蜊黧缡喱鹂嫠蠡鲡蓠理礼離嚟\nli3\t里理李礼哩鲤俚逦娌悝澧锂蠡醴鳢裡\nli4\t力利立历例丽励厉莉笠粒俐栗隶吏沥雳莅戾俪砺痢郦詈荔枥呖唳猁溧砾栎轹傈坜苈疠疬蛎鬲篥粝跞\nli5\t璃哩莉里\nlia3\t俩\nlian2\t联连怜莲廉帘涟镰裢濂臁奁蠊鲢\nlian3\t脸敛琏蔹裣\nlian4\t练恋炼链殓楝潋\nliang2\t量良梁凉粮粱踉莨椋墚两\nliang3\t两俩魉\nliang4\t量亮辆凉谅晾踉靓\nliao1\t撩撂\nliao2\t聊疗辽僚寥撩撂缭寮燎嘹獠鹩了\nliao3\t了潦燎蓼钌\nliao4\t了料廖镣撩撂尥钌\nlie1\t咧\nlie3\t裂咧\nlie4\t列烈裂劣猎趔冽洌捩埒躐鬣\nlie5\t咧\nlin2\t林临邻琳淋霖麟鳞磷嶙辚粼遴啉瞵\nlin3\t凛懔檩廪\nlin4\t淋吝躏赁蔺膦\nlin1\t拎\nling2\t令灵零龄凌玲铃陵伶聆囹棱菱苓翎棂瓴绫酃泠羚蛉柃鲮领岭\nling3\t领令岭\nling4\t令另呤\nliu1\t溜熘\nliu2\t留流刘瘤榴浏硫琉遛馏镏旒骝鎏柳\nliu3\t柳绺锍\nliu4\t六溜碌遛馏镏鹨\nlo5\t咯\nlong1\t隆\nlong2\t龙隆笼胧咙聋珑窿茏栊泷砻癃\nlong3\t笼拢垄陇垅\nlong4\t弄\nlou1\t搂\nlou2\t楼喽偻娄髅蝼蒌耧\nlou3\t搂篓嵝\nlou4\t露陋漏镂瘘\nlou5\t喽\nlu1\t噜撸\nlu2\t卢炉庐芦颅泸轳鲈垆胪鸬舻栌\nlu3\t鲁芦卤虏掳橹镥\nlu4\t六路陆录露绿鹿碌禄辘麓赂漉戮簏鹭潞璐辂渌蓼逯\nlu5\t轳氇噜\nlv3\t旅履屡侣缕吕捋铝偻褛膂稆\nlv4\t律绿率虑滤氯緑\nlv5\t驴榈闾率\nluan2\t峦挛孪栾銮滦鸾娈脔\nluan3\t卵\nluan4\t乱\nlve3\t掠\nlve4\t略掠锊\nlun1\t抡\nlun2\t论轮伦沦仑抡囵纶\nlun4\t论\nluo1\t落罗捋啰\nluo2\t罗逻萝螺锣箩骡猡椤脶镙\nluo3\t裸倮蠃瘰\nluo4\t落络洛骆咯摞烙珞泺漯荦硌雒\nluo5\t罗\nm2\t呒\nma1\t妈麻摩抹蚂嬷\nma2\t吗麻蟆马玛\nma3\t马吗码玛蚂犸\nma4\t骂蚂唛杩犸\nma5\t么吗嘛妈嗎\nmai2\t埋霾\nmai3\t买荬買\nmai4\t卖麦迈脉劢\nman1\t颟\nman2\t蛮馒瞒埋蔓谩鳗鞔满\nman3\t满螨\nman4\t慢漫曼蔓谩墁幔缦熳镘\nmang2\t忙茫盲芒氓邙硭\nmang3\t莽蟒漭\nmao1\t猫貓\nmao2\t毛猫矛茅髦锚牦旄蝥蟊茆\nmao3\t卯铆峁泖昴\nmao4\t冒贸帽貌茂耄瑁懋袤瞀貿\nme5\t么麽麼\nmei2\t没眉梅媒枚煤霉玫糜酶莓嵋湄楣猸镅鹛美每沒\nmei3\t美每镁浼\nmei4\t妹魅昧谜媚寐袂\nmen1\t闷\nmen2\t门扪钔\nmen4\t闷懑焖\nmen5\t们們\nmeng1\t蒙\nmeng2\t蒙盟朦氓萌檬瞢甍礞虻艨濛\nmeng3\t蒙猛勐懵蠓蜢锰艋\nmeng4\t梦孟\nmi1\t眯咪\nmi2\t迷弥谜靡糜醚麋猕祢縻蘼米\nmi3\t米眯靡弭敉脒芈\nmi4\t密秘觅蜜谧泌汨宓幂嘧\nmian2\t棉眠绵\nmian3\t免缅勉腼冕娩渑湎沔眄黾\nmian4\t面\nmiao1\t喵\nmiao2\t描苗瞄鹋\nmiao3\t秒渺藐缈淼杪邈眇\nmiao4\t妙庙缪\nmie1\t乜咩\nmie4\t灭蔑篾蠛\nmin2\t民珉岷缗玟苠\nmin3\t敏悯闽泯皿抿闵愍黾鳘\nming2\t名明鸣盟铭冥茗溟瞑暝螟\nming3\t酩\nming4\t命\nmiu4\t谬缪\nmo1\t摸\nmo2\t无模麽磨摸摩魔膜蘑馍摹\nmo3\t抹\nmo4\t莫陌磨末默沫漠寞没墨茉\nmo5\t寞沫\nmu3\t拇牡亩姆母姥\nmu4\t墓暮幕募慕木目睦牧穆沐\nna2\t拿哪\nna3\t哪\nna4\t呐钠那娜纳衲\nna5\t呐\nnai3\t氖乃奶妳\nnai4\t耐奈\nnan2\t南男难楠喃\nnan3\t腩蝻赧\nnan4\t难\nnang2\t囊\nnao1\t孬\nnao2\t挠\nnao3\t脑恼\nnao4\t闹淖\nne2\t哪\nne5\t呢\nnei3\t馁\nnei4\t内\nnen4\t嫩\nneng2\t能\nni1\t妮\nni2\t霓倪泥尼\nni3\t拟你\nni4\t匿腻逆溺昵\nnian1\t蔫拈\nnian2\t年粘黏拈鲶\nnian3\t碾撵捻\nnian4\t念\nniang2\t娘\nniang4\t酿\nniao3\t鸟袅嬲\nniao4\t尿\nnie1\t捏㖏\nnie4\t聂孽啮镊镍涅\nnin2\t您\nning2\t柠狞凝宁拧咛\nning3\t拧\nning4\t拧泞宁\nniu2\t牛\nniu3\t扭钮纽\nniu4\t拗\nnong1\t浓脓\nnong2\t浓农侬\nnong4\t弄\nnu2\t奴孥\nnu3\t努弩\nnu4\t怒\nnv3\t女钕\nnuan3\t暖\nnue4\t虐疟\nnuo2\t挪傩娜\nnuo4\t懦糯诺\no2\t哦\no5\t哦\nou1\t欧鸥殴瓯呕歐\nou3\t藕呕偶\nou4\t沤\npa1\t啪趴爬葩\npa2\t爬琶杷\npa4\t帕怕\npa5\t琶杷\npai1\t拍\npai2\t排牌徘\npai4\t湃派\npan1\t攀潘\npan2\t盘胖磐\npan4\t盼畔判叛\npang1\t乓\npang2\t庞旁螃彷\npang3\t耪\npang4\t胖\npao1\t抛\npao2\t咆袍刨庖\npao3\t跑\npao4\t炮泡\npei1\t呸胚\npei2\t培裴赔陪\npei4\t配佩沛\npen1\t喷\npen2\t盆\npeng1\t砰抨烹\npeng2\t澎彭蓬棚硼篷膨朋鹏芃\npeng3\t捧\npeng4\t碰\npeng5\t篷蓬\npi1\t坯砒霹批披劈丕\npi2\t皮琵毗啤脾疲枇铍貔\npi3\t匹痞癖\npi4\t僻屁譬辟媲\npian1\t篇偏片翩\npian2\t骈\npian4\t片骗\npiao1\t飘漂\npiao2\t瓢朴嫖漂\npiao3\t瞟\npiao4\t漂票嫖\npie1\t撇瞥\npie3\t撇瞥\npin1\t拼拚\npin2\t频贫品嫔\npin3\t品\npin4\t聘\nping1\t乒娉\nping2\t坪苹萍平凭瓶评屏\npo1\t坡泼颇\npo2\t婆鄱\npo3\t颇叵\npo4\t破魄迫粕朴珀\npou1\t剖\npu1\t扑铺仆噗\npu2\t仆莆葡菩蒲谱濮璞\npu3\t普谱埔朴圃浦\npu4\t铺曝瀑\nqi1\t期七欺栖漆妻凄柒沏戚桼\nqi2\t其旗琪骑骐棋歧岐琦齐奇祁祺麒起祈淇芪锜脐綦鳍圻\nqi3\t起启企岂祈乞绮杞\nqi4\t弃气器汽戚泣砌契讫\nqia1\t掐葜袷恰\nqia3\t卡\nqia4\t恰洽髂\nqian1\t千签牵迁谦铅骞悭芊愆阡仟岍扦佥搴褰钎\nqian2\t前钱潜乾虔钳掮黔荨钤犍箝\nqian3\t浅遣谴缱肷\nqian4\t欠歉纤嵌倩堑茜芡慊椠\nqiang1\t将枪抢腔呛锵跄羌戕戗镪蜣锖\nqiang2\t强墙蔷樯嫱\nqiang3\t强抢襁镪羟\nqiang4\t呛跄炝戗\nqiao1\t悄敲雀锹跷橇缲硗劁\nqiao2\t桥乔侨瞧翘蕉憔樵峤谯荞鞒\nqiao3\t悄巧雀愀\nqiao4\t翘俏窍壳峭撬鞘诮谯\nqie1\t切\nqie3\t且\nqie4\t切窃怯趄妾砌惬锲挈郄箧慊\nqin1\t亲钦侵衾\nqin2\t琴秦勤芹擒矜覃禽噙廑溱檎嗪芩螓\nqin3\t寝\nqin4\t沁揿吣\nqing1\t青清轻倾卿氢蜻圊鲭\nqing2\t情晴擎氰檠黥\nqing3\t请顷謦苘\nqing4\t亲庆罄磬箐綮\nqiong2\t穷琼穹茕邛蛩筇跫銎\nqiu1\t秋邱丘龟蚯鳅楸湫\nqiu2\t求球仇囚酋裘虬俅遒赇泅逑犰蝤巯鼽\nqiu3\t糗\nqu1\t区曲屈趋驱躯觑岖蛐祛蛆麴诎黢\nqu2\t渠瞿衢癯劬璩氍朐磲鸲蕖蠼蘧取佢\nqu3\t取曲娶龋苣\nqu4\t去趣觑阒\nqu5\t戌去\nquan1\t圈悛\nquan2\t全权泉拳诠颧蜷荃铨痊醛辁筌鬈權\nquan3\t犬绻畎\nquan4\t劝券\nque1\t缺阙炔\nque2\t瘸\nque4\t却确雀榷鹊阕阙悫\nqun1\t逡\nqun2\t群裙麇\nran2\t然燃髯蚺\nran3\t染冉苒\nrang1\t嚷\nrang2\t瓤禳穰\nrang3\t嚷攘壤\nrang4\t让\nrao2\t饶娆桡荛\nrao3\t扰绕娆\nrao4\t绕\nre3\t若惹喏\nre4\t热\nren2\t人任仁壬\nren3\t忍稔荏\nren4\t任认韧刃纫饪仞葚妊轫衽恁\nren5\t人\nreng1\t扔\nreng2\t仍\nri4\t日\nrong2\t容荣融蓉溶绒熔榕戎嵘茸狨肜蝾\nrong3\t冗\nrou2\t柔揉蹂糅鞣\nrou4\t肉\nru2\t如儒茹嚅濡孺蠕薷铷襦颥乳\nru3\t辱乳汝\nru4\t入褥缛洳溽蓐\nruan3\t软阮朊\nrui2\t蕤\nrui3\t蕊\nrui4\t瑞锐芮睿枘蚋\nrun4\t润闰\nruo4\t若弱偌箬\nsa1\t撒仨挲\nsa3\t洒撒\nsa4\t萨卅飒脎\nsai1\t思塞腮鳃噻\nsai4\t赛塞\nsan1\t三毵\nsan3\t散伞馓糁霰\nsan4\t散\nsang1\t丧桑\nsang3\t嗓搡磉颡\nsang4\t丧\nsao1\t骚搔臊缲缫鳋\nsao3\t扫嫂\nsao4\t扫梢臊埽瘙\nse4\t色塞涩瑟啬铯穑\nsen1\t森\nseng1\t僧\nsha1\t杀沙刹纱杉莎煞砂挲鲨痧裟铩\nsha3\t傻\nsha4\t沙啥厦煞霎嗄歃唼\nshai1\t筛酾\nshai3\t色\nshai4\t晒\nshan1\t山衫删煽扇珊杉栅跚姗潸膻芟埏钐舢苫髟\nshan3\t闪陕掺\nshan4\t单善扇禅擅膳讪汕赡缮嬗掸骟剡苫鄯钐疝蟮鳝\nshang1\t商伤汤殇觞熵墒\nshang3\t上赏晌垧\nshang4\t上尚绱\nshang5\t裳上\nshao1\t烧稍梢捎鞘蛸筲艄\nshao2\t勺韶苕杓芍\nshao3\t少\nshao4\t少绍召稍哨邵捎潲劭\nshe1\t奢赊猞畲\nshe2\t折舌蛇佘\nshe3\t舍\nshe4\t社设舍涉射摄赦慑麝滠歙厍\nshei2\t谁\nshen1\t身深参申伸绅呻莘娠诜砷糁珅\nshen2\t什神\nshen3\t审沈婶谂哂渖矧\nshen4\t甚慎渗肾蜃葚胂椹\nsheng1\t生声胜升牲甥笙\nsheng2\t绳渑\nsheng3\t省眚\nsheng4\t胜圣盛乘剩嵊晟\nshi1\t师诗失施尸湿狮嘘虱蓍酾鲺\nshi2\t十时实什识食石拾蚀埘莳炻鲥\nshi3\t使始史驶屎矢豕\nshi4\t是事世市士式视似示室势试释适氏饰逝誓嗜侍峙仕恃柿轼拭噬弑谥莳贳铈螫舐筮识\nshi5\t殖匙识\nshou1\t收\nshou2\t熟手首\nshou3\t手首守艏\nshou4\t受授售瘦寿兽狩绶\nshu1\t书输殊舒叔疏抒淑梳枢蔬倏菽摅姝纾毹殳疋\nshu2\t熟孰赎塾秫\nshu3\t数属署鼠薯暑蜀黍曙\nshu4\t数术树述束竖恕墅漱俞戍庶澍沭腧\nshua1\t刷唰\nshua3\t耍\nshua4\t刷\nshuai1\t衰摔\nshuai3\t甩\nshuai4\t率帅蟀\nshuan1\t栓拴闩\nshuan4\t涮\nshuang1\t双霜孀泷\nshuang3\t爽\nshui2\t谁水\nshui3\t水\nshui4\t税睡说\nshun3\t吮\nshun4\t顺舜瞬\nshuo1\t说\nshuo4\t数朔硕烁铄妁蒴槊搠\nsi1\t思斯司私丝撕厮嘶鸶咝澌缌锶蛳\nsi3\t死\nsi4\t四似食寺肆伺饲嗣巳祀驷泗俟汜兕姒耜笥\nsi5\t司思\nsong1\t松忪淞崧嵩凇菘\nsong3\t耸悚怂竦\nsong4\t送宋诵颂讼\nsou1\t搜艘馊嗖溲飕锼螋\nsou3\t擞叟薮嗾瞍\nsou4\t嗽擞\nsu1\t苏稣酥\nsu2\t俗\nsu4\t诉速素肃宿缩塑溯粟簌夙嗉谡僳愫涑蔌觫\nsuan1\t酸狻\nsuan4\t算蒜\nsui1\t虽尿荽睢眭濉\nsui2\t随遂隋绥\nsui3\t髓\nsui4\t岁碎遂祟隧邃穗燧谇\nsun1\t孙荪狲飧\nsun3\t损笋榫隼\nsuo1\t缩莎梭嗦唆挲娑睃桫嗍蓑羧\nsuo2\t所索\nsuo3\t所索锁琐唢\nsuo5\t嗦\nta1\t他她它踏塌遢溻铊趿\nta3\t塔鳎獭\nta4\t踏拓榻嗒蹋沓挞闼漯遢\ntai1\t台胎苔\ntai2\t台抬苔邰薹骀炱跆鲐\ntai3\t呔\ntai4\t太态泰汰酞肽钛\ntan1\t摊贪滩瘫坍\ntan2\t谈弹坛谭潭覃痰澹檀昙锬镡郯\ntan3\t坦毯忐袒钽\ntan4\t探叹炭碳\ntan5\t弹\ntang1\t汤趟铴镗耥羰\ntang2\t堂唐糖膛塘棠搪溏螳瑭樘镗螗饧醣\ntang3\t躺倘淌傥帑\ntang4\t趟烫\ntao1\t涛掏滔叨焘韬饕绦\ntao2\t逃陶桃淘萄啕洮鼗\ntao3\t讨\ntao4\t套\nte4\t特忑忒慝铽\ntei1\t忒\nteng2\t腾疼藤誊滕\nti1\t体踢梯剔锑\nti2\t提题啼蹄醍绨缇鹈荑\nti3\t体\nti4\t替涕剃惕屉嚏悌倜逖绨裼\ntian1\t天添\ntian2\t田填甜恬佃阗畋钿嗔\ntian3\t腆舔忝殄\ntian4\t掭\ntiao1\t挑佻祧\ntiao2\t条调迢鲦苕髫龆蜩笤\ntiao3\t挑窕\ntiao4\t跳眺粜\ntie1\t贴帖萜\ntie3\t铁帖\ntie4\t帖餮\nting1\t听厅汀烃\nting2\t停庭亭婷廷霆蜓葶莛\nting3\t挺艇町铤梃\nting4\t梃\ntong1\t通恫嗵\ntong2\t同童彤铜桐瞳佟酮侗仝垌茼峒潼砼硐\ntong3\t统筒桶捅侗\ntong4\t同通痛恸\ntou1\t偷\ntou2\t头投骰\ntou3\t钭\ntou4\t透\ntu1\t突秃凸\ntu2\t图途徒屠涂荼菟酴凃\ntu3\t土吐钍\ntu4\t吐兔堍菟\ntuan1\t湍\ntuan2\t团抟\ntuan3\t疃\ntuan4\t彖\ntui1\t推忒\ntui2\t颓\ntui3\t腿\ntui4\t退褪蜕煺\ntun1\t吞暾\ntun2\t屯饨臀囤豚炖\ntun3\t氽\ntun4\t饨\ntuo1\t托脱拖乇\ntuo2\t陀舵驼砣驮沱跎坨鸵橐佗铊酡柁鼍\ntuo3\t妥椭庹\ntuo4\t魄拓唾柝箨\nwa1\t挖哇凹娲蛙洼\nwa2\t娃瓦\nwa3\t瓦佤\nwa4\t瓦袜腽\nwa5\t哇娃\nwai1\t歪\nwai3\t崴\nwai4\t外\nwan1\t湾弯蜿剜豌灣\nwan2\t完玩顽丸纨芄烷碗婉\nwan3\t晚碗挽婉惋宛莞娩畹皖绾琬脘菀\nwan4\t万腕蔓\nwang1\t汪\nwang2\t王亡芒往网\nwang3\t往网枉惘罔辋魍\nwang4\t望王往忘旺妄\nwei1\t威微危巍萎偎薇逶煨崴葳隈委\nwei2\t为维围唯违韦惟帷帏圩囗潍桅嵬闱沩涠位薇\nwei3\t委伟唯尾玮伪炜纬萎娓苇猥痿韪洧隗诿艉鲔\nwei4\t为位未味卫谓遗慰魏蔚畏胃喂尉渭猬軎\nwen1\t温瘟\nwen2\t文闻纹蚊雯璺阌稳炆\nwen3\t稳吻紊刎\nwen4\t问纹汶璺紊搵\nweng1\t翁嗡\nweng3\t蓊\nweng4\t瓮蕹\nwo1\t窝涡蜗喔倭挝莴\nwo2\t哦我\nwo3\t我\nwo4\t握卧渥沃斡幄肟硪龌\nwu1\t於恶屋污乌巫呜诬兀钨邬圬\nwu2\t无亡吴吾捂毋梧唔芜浯蜈五舞無\nwu3\t五武午舞伍侮捂妩忤鹉牾迕庑怃仵\nwu4\t物务误恶悟乌雾勿坞戊兀晤鹜痦寤骛芴杌焐阢婺鋈\nxi1\t西息希吸惜稀悉析夕牺腊昔熙兮溪嘻锡晰樨熄膝栖郗犀曦奚羲唏蹊淅皙汐嬉茜熹烯翕蟋歙浠僖穸蜥螅菥舾矽粞硒醯欷鼷\nxi2\t席习袭媳檄隰觋\nxi3\t喜洗禧徙玺屣葸蓰铣\nxi4\t系细戏隙饩阋禊舄\nxia1\t瞎虾呷\nxia2\t峡侠狭霞暇辖遐匣黠瑕狎硖柙\nxia4\t下夏吓厦唬\nxian1\t先鲜仙掀纤暹莶锨氙祆籼酰跹\nxian2\t闲贤嫌咸弦娴衔涎舷鹇痫閑\nxian3\t显险鲜洗跣猃藓铣燹蚬筅冼癣\nxian4\t现见线限县献宪陷羡馅腺岘苋霰\nxiang1\t相香乡箱厢湘镶襄骧葙芗缃\nxiang2\t降详祥翔庠想\nxiang3\t想响享飨饷鲞\nxiang4\t相向象像项巷橡蟓\nxiao1\t消销潇肖萧宵削嚣逍硝霄哮枭骁箫枵哓蛸绡魈銷\nxiao2\t淆崤小\nxiao3\t小晓筱\nxiao4\t笑校效肖孝啸哮\nxie1\t些歇楔蝎\nxie2\t叶协鞋携斜胁谐邪挟偕撷勰颉缬写\nxie3\t写血\nxie4\t写解谢泄契械屑卸懈泻亵蟹邂榭瀣薤燮躞廨绁渫榍獬\nxin1\t心新欣辛薪馨鑫芯昕忻歆锌\nxin2\t寻镡\nxin4\t信芯衅\nxing1\t兴星腥惺猩\nxing2\t行形型刑邢陉荥饧硎\nxing3\t省醒擤\nxing4\t性兴姓幸杏悻荇\nxiong1\t兄胸凶匈汹芎\nxiong2\t雄熊\nxiu1\t修休羞咻馐庥鸺貅髹貅\nxiu3\t宿朽\nxiu4\t秀袖宿臭绣锈嗅岫溴\nxu1\t需须虚吁嘘墟戌胥砉圩盱顼虛\nxu2\t徐\nxu3\t许浒栩诩糈醑\nxu4\t续序绪蓄叙畜恤絮旭婿酗煦洫溆勖\nxu5\t蓿\nxuan1\t宣喧轩萱暄谖揎儇煊瑄\nxuan2\t旋悬玄漩璇痃选玹\nxuan3\t选癣\nxuan4\t旋券炫渲绚眩铉泫碹楦镟\nxue1\t削靴薛\nxue2\t学穴噱踅泶\nxue3\t雪鳕\nxue4\t血谑\nxun1\t熏勋荤醺薰埙曛窨獯\nxun2\t寻询巡循旬驯荀峋洵恂郇浔鲟荨\nxun4\t训迅讯逊熏殉巽徇汛蕈浚\nya1\t压雅呀押鸦哑鸭丫垭桠\nya2\t牙涯崖芽衙睚伢岈琊蚜\nya3\t雅痖疋哑\nya4\t亚压讶轧娅迓揠氩砑\nya5\t呀\nyan1\t烟燕咽殷焉淹阉腌嫣胭湮阏鄢菸崦恹\nyan2\t言严研延沿颜炎阎盐岩蜒檐妍筵芫闫阽眼\nyan3\t眼演掩衍奄俨偃魇鼹兖郾琰罨厣剡\nyan4\t验厌燕宴咽雁焰艳谚彦研沿焱晏唁砚堰赝餍滟酽谳\nyang1\t央泱秧鸯殃鞅\nyang2\t洋阳杨扬羊疡佯烊徉炀蛘养仰\nyang3\t养仰痒氧\nyang4\t样漾恙烊怏鞅\nyao1\t要约邀腰夭妖吆幺么\nyao2\t摇遥姚陶尧谣瑶窑肴侥铫珧轺爻徭繇鳐垚\nyao3\t咬杳窈舀崾\nyao4\t要药耀钥鹞曜疟\nye1\t耶噎椰掖\nye2\t爷耶邪揶铘也野\nye3\t也野冶\nye4\t业夜叶页液咽曳拽烨掖腋谒邺靥晔\nyi1\t一医衣依椅伊漪咿揖噫猗铱欹黟\nyi2\t移疑遗宜仪蛇姨夷怡颐彝咦贻迤痍胰沂饴圯荑诒眙嶷一以谊\nyi3\t以已衣尾椅矣乙蚁倚迤蛾旖苡钇舣酏\nyi4\t意义议易衣艺译异益亦亿忆谊抑翼役艾溢毅裔逸轶弈翌疫绎佚奕熠诣弋驿懿呓屹薏噫镒缢邑臆刈羿仡峄怿悒肄佾殪挹埸劓镱瘗癔翊蜴嗌翳一\nyin1\t因音阴姻殷茵荫喑湮氤堙洇铟\nyin2\t银吟寅淫垠鄞霪狺夤圻龈饮引隐\nyin3\t引隐饮瘾殷尹蚓吲\nyin4\t印饮荫胤茚窨\nying1\t应英鹰婴樱膺莺罂鹦缨瑛璎撄嘤\nying2\t营迎赢盈蝇莹荧萤萦瀛楹嬴茔滢潆荥蓥影盁\nying3\t影颖颍瘿郢\nying4\t应硬映媵\nyo1\t育哟唷\nyo5\t哟\nyong1\t拥庸佣雍臃邕镛墉慵痈壅鳙饔\nyong2\t喁勇永\nyong3\t永勇涌踊泳咏俑恿甬蛹\nyong4\t用佣\nyou1\t优幽忧悠攸呦\nyou2\t由游油邮尤犹柚鱿莸尢铀猷疣蚰蝣蝤繇莜有友\nyou3\t有友黝酉莠牖铕\nyou4\t有又右幼诱佑柚囿鼬宥侑蚴釉祐\nyu1\t於吁迂淤纡瘀\nyu2\t于与余予鱼愚舆娱愉馀逾渔渝俞萸瑜隅揄榆虞禺谀腴竽妤臾欤觎盂窬蝓嵛狳舁雩於雨\nyu3\t雨与语予宇羽禹圄屿龉伛圉庾瘐窳俣禺\nyu4\t与语育遇狱雨欲预玉愈谷域誉吁蔚寓豫粥郁喻裕浴御驭尉谕毓妪峪芋昱煜熨燠菀蓣饫阈鬻聿钰鹆鹬蜮彧\nyuan1\t冤渊鸳眢鸢箢\nyuan2\t员元原园源圆缘援袁猿垣辕沅媛芫橼圜塬爰螈鼋远\nyuan3\t远\nyuan4\t院愿怨苑媛掾垸瑗\nyue1\t约曰\nyue4\t月越阅跃乐悦岳粤说钥刖瀹栎樾龠钺玥\nyun1\t晕氲\nyun2\t云匀筠芸耘纭昀郧允\nyun3\t允陨殒狁\nyun4\t运均韵晕孕蕴酝愠熨郓韫恽\nza1\t扎咂匝拶\nza2\t杂咱砸\nza3\t咋\nzai1\t灾哉栽\nzai3\t载仔宰崽\nzai4\t在再载\nzan1\t簪糌\nzan2\t咱\nzan3\t攒拶昝趱\nzan4\t赞暂瓒錾\nzan5\t咱\nzang1\t赃臧脏\nzang3\t驵\nzang4\t藏脏葬奘\nzao1\t遭糟\nzao2\t凿早\nzao3\t早澡枣蚤藻\nzao4\t造灶躁噪皂燥唣\nze2\t则责泽择咋啧迮帻赜笮箦舴\nze4\t侧仄昃\nzei2\t贼\nzen3\t怎\nzen4\t谮\nzeng1\t曾增憎缯罾\nzeng4\t赠缯甑锃\nzha1\t查扎咋渣喳揸楂哳吒齄\nzha2\t炸扎札喋轧闸铡\nzha3\t眨砟\nzha4\t炸咋诈乍蜡栅榨柞吒咤痄蚱\nzhai1\t摘侧斋\nzhai2\t宅翟择窄\nzhai3\t窄\nzhai4\t债祭寨砦瘵\nzhan1\t占沾粘瞻詹毡谵旃\nzhan3\t展斩辗盏崭搌\nzhan4\t战站占颤绽湛蘸栈\nzhang1\t张章彰璋蟑樟漳嫜鄣獐\nzhang3\t长掌涨仉\nzhang4\t丈涨帐障账胀仗杖瘴嶂幛\nzhao1\t着招朝嘲昭钊啁\nzhao2\t着著\nzhao3\t找爪沼\nzhao4\t照赵召罩兆肇诏棹笊\nzhe1\t折遮蜇\nzhe2\t折哲辙辄谪蛰摺磔蜇喆\nzhe3\t者褶锗赭\nzhe4\t这浙蔗鹧柘\nzhe5\t着\nzhei4\t这\nzhen1\t真针珍斟贞侦甄臻箴砧桢溱蓁椹榛胗祯浈禛\nzhen3\t诊枕疹缜畛轸稹\nzhen4\t阵镇震圳振赈朕鸩\nzheng1\t正争征丁挣症睁徵蒸怔筝铮峥狰钲鲭\nzheng3\t整拯\nzheng4\t政正证挣郑症怔铮诤帧\nzhi1\t之只知指支织氏枝汁掷芝吱肢脂蜘栀卮胝祗\nzhi2\t直指职值执植殖侄踯摭絷跖埴只纸\nzhi3\t只指纸止址旨徵趾咫芷枳祉轵黹酯\nzhi4\t知至制识治志致质智置秩滞帜稚挚掷峙窒炙痔栉桎帙轾贽痣豸陟忮彘膣雉鸷骘蛭踬郅觯\nzhong1\t中终钟忠衷锺盅忪螽舯\nzhong2\t种\nzhong3\t种肿踵冢\nzhong4\t中种重众仲\nzhou1\t周州洲粥舟诌啁\nzhou2\t轴妯碡\nzhou3\t肘帚\nzhou4\t皱骤轴宙咒昼胄纣绉荮籀繇酎\nzhu1\t诸朱珠猪株蛛洙诛铢茱邾潴槠橥侏\nzhu2\t术逐筑竹烛躅竺舳瘃主\nzhu3\t主属煮嘱瞩拄褚渚麈\nzhu4\t住注助著驻祝筑柱铸伫贮箸炷蛀杼翥苎疰\nzhua1\t抓挝\nzhua3\t爪\nzhuai1\t拽\nzhuai3\t拽\nzhuai4\t拽\nzhuan1\t专砖颛\nzhuan3\t转\nzhuan4\t传转赚撰沌篆啭馔\nzhuang1\t装庄妆桩\nzhuang3\t奘\nzhuang4\t状壮撞幢僮戆壵\nzhui1\t追锥隹椎骓\nzhui4\t坠缀赘惴缒\nzhun1\t屯谆肫窀\nzhun3\t准\nzhuo1\t桌捉卓拙涿焯倬\nzhuo2\t着著琢缴灼酌浊濯茁啄斫镯诼禚擢浞卓\nzi1\t资咨滋仔姿吱兹孜谘呲龇锱辎淄髭赀孳粢趑觜訾缁鲻嵫\nzi3\t子紫仔梓姊籽滓秭笫耔茈訾\nzi4\t自字渍恣眦\nzong1\t宗踪综棕鬃枞腙\nzong3\t总偬\nzong4\t纵粽\nzou1\t邹诹陬鄹驺鲰\nzou3\t走\nzou4\t奏揍\nzu1\t租菹\nzu2\t足族卒镞祖组\nzu3\t组祖阻诅俎\nzuan1\t钻躜\nzuan3\t纂缵\nzuan4\t赚钻攥\nzui1\t堆\nzui3\t嘴咀觜\nzui4\t最罪醉蕞\nzun1\t尊遵樽鳟\nzun3\t撙\nzuo1\t作嘬\nzuo2\t作昨琢笮左\nzuo3\t左佐撮\nzuo4\t作做坐座怍胙阼唑祚\nzi5\t子\nge5\t个歌\ngu5\t顾咕\nbiao2\t表\nsha2\t啥\ner5\t儿\nfan5\t烦\ntou5\t头\njing2\t井\nji5\t记计疾积\nguo5\t过\nzhi5\t置质制指脂\nniao2\t袅\nxi5\t息系\nying5\t蝇盈\njing5\t睛\nliang5\t量亮粮粱\nmou3\t某\nshan2\t闪\nlang5\t朗\nfen5\t分\nxiong5\t兄\nbu5\t不部\nhou5\t候侯\nben2\t本\nzong2\t总\ntai5\t太\nmou2\t谋牟眸缪\nlai5\t来\nniang5\t娘\njian2\t减柬\nyou5\t友\nguan2\t管馆\nyue5\t月\ndiao5\t掉\nwu5\t物务\nxing5\t猩\nbing5\t病饼\nruo5\t弱\nmu2\t亩母\nzuo5\t坐做\nchui5\t吹\nyun5\t晕\nnve4\t疟虐\nqie2\t茄伽\nzui2\t嘴\nrong5\t溶\nmei5\t妹\nkan5\t看\nkao2\t考\nhe5\t合\nsheng5\t生\nyang5\t鸯扬阳\ncheng5\t诚\nlv2\t驴榈旅侣\ndai5\t袋待\njin2\t紧\nyao5\t药\nwang5\t望枉王\njiu2\t九\njun3\t菌\ngei2\t给\nzheng2\t整\nnao5\t闹\ngun2\t滚\ntong5\t同筒\ndian2\t点典\ngui2\t鬼\nbei2\t北\ntao5\t桃\nlia2\t俩\nyi5\t易议一意义\nshen5\t神\nling5\t龄\nweng5\t嗡\nqi5\t气\nqin5\t亲\nnai2\t奶\nheng5\t哼\nnv2\t女\nju5\t矩\nye5\t爷\nmian5\t面\nrou5\t柔\nqia5\t恰\npie2\t撇\nguang2\t广\nka2\t卡\nken2\t恳\nsi2\t死\ndang2\t党\nyu5\t育裕\nwo5\t窝\ndeng2\t等\nfa5\t发\npo5\t婆\nkong2\t孔\nzhen2\t诊\ngai2\t改\npin5\t频\nwan5\t玩\njiang2\t讲奖\nnai5\t奶耐\nmu5\t目\nshun5\t顺\nne4\t讷呐\ndao5\t到\nnuan2\t暖\npiao5\t飘\nsu5\t诉\nnang5\t囊\nlong5\t咙\nzhu5\t住\npian5\t片\nyong5\t用\nou2\t偶\nhu5\t乎\nzou2\t走\nbai5\t白\nzhang2\t长\nbang2\t榜\nzhan2\t展\nhuo5\t活火\ntie2\t铁\ndu5\t度\nzhuan2\t转\nchou5\t酬\ngan5\t杆\nsou5\t嗽\nhai5\t害\njiong2\t炯\njiu5\t舅\nduo5\t朵\no1\t噢喔\nniu1\t妞\nsai5\t噻\npou2\t锫\n"
        },
        {
          "name": "download_default_datalist.py",
          "type": "blob",
          "size": 3.6025390625,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n用于下载ASRT语音识别系统声学模型训练默认用的数据集列表程序\n\"\"\"\n\nimport os\nimport logging\nimport json\nimport requests\nimport zipfile\n\nlogging.basicConfig(\n    format='%(asctime)s - %(pathname)s[line:%(lineno)d] - %(levelname)s: %(message)s',\n    level=logging.INFO)\n\nDEFAULT_DATALIST_PATH = 'datalist/'\nif not os.path.exists(DEFAULT_DATALIST_PATH):\n    os.makedirs(DEFAULT_DATALIST_PATH)\n\nURL_DATALIST_INDEX = \"https://d.ailemon.net/asrt_assets/datalist/index.json\"\nrsp_index = requests.get(URL_DATALIST_INDEX)\nrsp_index.encoding = 'utf-8'\nif rsp_index.ok:\n    logging.info('Has connected to ailemon\\'s download server...')\nelse:\n    logging.error('%s%s', 'Can not connected to ailemon\\'s download server.',\n                  'please check your network connection.')\n\nindex_json = json.loads(rsp_index.text)\nif index_json['status_code'] != 200:\n    raise Exception(index_json['status_message'])\n\nbody = index_json['body']\nlogging.info('start to download datalist from ailemon\\'s download server...')\n\nurl_prefix = body['url_prefix']\nfor i in range(len(body['datalist'])):\n    print(i, body['datalist'][i]['name'])\nprint(len(body['datalist']), 'all datalist')\nnum = input('Please choose which you select: (default all)')\nif len(num) == 0:\n    num = len(body['datalist'])\nelse:\n    num = int(num)\n\n\ndef deal_download(datalist_item, url_prefix_str, datalist_path):\n    \"\"\"\n    to deal datalist file download\n    \"\"\"\n    logging.info('%s%s', 'start to download datalist ', datalist_item['name'])\n    save_path = datalist_path\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n        logging.info('%s`%s`', 'Created directory ', save_path)\n\n    zipfilename = datalist_item['zipfile']\n    tmp_url = url_prefix_str + zipfilename\n    save_filename = os.path.join(save_path, zipfilename)\n    rsp = requests.get(tmp_url)\n    with open(save_filename, \"wb\") as file_pointer:\n        file_pointer.write(rsp.content)\n    if rsp.ok:\n        logging.info('%s `%s` %s', 'Download', zipfilename, 'complete')\n    else:\n        logging.error('%s%s%s%s%s', 'Can not download ', zipfilename,\n                      ' from ailemon\\'s download server. ',\n                      'http status ok is ', str(rsp.ok))\n\n    f = zipfile.ZipFile(save_filename, 'r')  # 压缩文件位置\n    f.extractall(save_path)\n    f.close()\n    logging.info('%s `%s` %s', 'unzip', zipfilename, 'complete')\n\n\nif num == len(body['datalist']):\n    for i in range(len(body['datalist'])):\n        deal_download(body['datalist'][i], body['url_prefix'], DEFAULT_DATALIST_PATH)\nelse:\n    deal_download(body['datalist'][num], body['url_prefix'], DEFAULT_DATALIST_PATH)\n\nlogging.info('%s%s%s', 'Datalist files download complete. ',\n             'Please remember to download these datasets from ',\n             body['dataset_download_page_url'])\n"
        },
        {
          "name": "evaluate_speech_model.py",
          "type": "blob",
          "size": 1.6875,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n用于测试语音识别系统语音模型的程序\n\"\"\"\n\nimport os\n\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom data_loader import DataLoader\nfrom speech_features import Spectrogram\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = Spectrogram()\nevalue_data = DataLoader('dev')\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\n\nms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\nms.evaluate_model(data_loader=evalue_data, data_count=-1,\n                  out_report=True, show_ratio=True, show_per_step=100)\n"
        },
        {
          "name": "language_model3.py",
          "type": "blob",
          "size": 4.515625,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\nASRT语音识别的语言模型\n\n基于N-Gram的语言模型\n\"\"\"\n\nimport os\n\nfrom utils.ops import get_symbol_dict, get_language_model\n\n\nclass ModelLanguage:\n    \"\"\"\n    ASRT专用N-Gram语言模型\n    \"\"\"\n\n    def __init__(self, model_path: str):\n        self.model_path = model_path\n        self.dict_pinyin = dict()\n        self.model1 = dict()\n        self.model2 = dict()\n\n    def load_model(self):\n        \"\"\"\n        加载N-Gram语言模型到内存\n        \"\"\"\n        self.dict_pinyin = get_symbol_dict('dict.txt')\n        self.model1 = get_language_model(os.path.join(self.model_path, 'language_model1.txt'))\n        self.model2 = get_language_model(os.path.join(self.model_path, 'language_model2.txt'))\n        model = (self.dict_pinyin, self.model1, self.model2)\n        return model\n\n    def pinyin_to_text(self, list_pinyin: list, beam_size: int = 100) -> str:\n        \"\"\"\n        拼音转文本，一次性取得全部结果\n        \"\"\"\n        result = list()\n        tmp_result_last = list()\n        for item_pinyin in list_pinyin:\n            tmp_result = self.pinyin_stream_decode(tmp_result_last, item_pinyin, beam_size)\n            if len(tmp_result) == 0 and len(tmp_result_last) > 0:\n                result.append(tmp_result_last[0][0])\n                tmp_result = self.pinyin_stream_decode([], item_pinyin, beam_size)\n                if len(tmp_result) > 0:\n                    result.append(tmp_result[0][0])\n                tmp_result = []\n            tmp_result_last = tmp_result\n\n        if len(tmp_result_last) > 0:\n            result.append(tmp_result_last[0][0])\n\n        return ''.join(result)\n\n    def pinyin_stream_decode(self, temple_result: list,\n                             item_pinyin: str,\n                             beam_size: int = 100) -> list:\n        \"\"\"\n        拼音流式解码，逐字转换，每次返回中间结果\n        \"\"\"\n        # 如果这个拼音不在汉语拼音字典里的话，直接返回空列表，不做decode\n        if item_pinyin not in self.dict_pinyin:\n            return []\n\n        # 获取拼音下属的字的列表，cur_words包含了该拼音对应的所有的字\n        cur_words = self.dict_pinyin[item_pinyin]\n        # 第一个字做初始处理\n        if len(temple_result) == 0:\n            lst_result = list()\n            for word in cur_words:\n                # 添加该字到可能的句子列表，设置初始概率为1.0\n                lst_result.append([word, 1.0])\n            return lst_result\n\n        # 开始处理已经至少有一个字的中间结果情况\n        new_result = list()\n        for sequence in temple_result:\n            for cur_word in cur_words:\n                # 得到2-gram的汉字子序列\n                tuple2_word = sequence[0][-1] + cur_word\n                if tuple2_word not in self.model2:\n                    # 如果2-gram子序列不存在\n                    continue\n                # 计算状态转移概率\n                prob_origin = sequence[1]  # 原始概率\n                count_two_word = float(self.model2[tuple2_word])  # 二字频数\n                count_one_word = float(self.model1[tuple2_word[-2]])  # 单字频数\n                cur_probility = prob_origin * count_two_word / count_one_word\n                new_result.append([sequence[0] + cur_word, cur_probility])\n\n        new_result = sorted(new_result, key=lambda x: x[1], reverse=True)\n        if len(new_result) > beam_size:\n            return new_result[0:beam_size]\n        return new_result\n\n\nif __name__ == '__main__':\n    ml = ModelLanguage('model_language')\n    ml.load_model()\n\n    _str_pinyin = ['zhe4', 'zhen1', 'shi4', 'ji2', 'hao3', 'de5']\n    _RESULT = ml.pinyin_to_text(_str_pinyin)\n    print('语音转文字结果:\\n', _RESULT)\n"
        },
        {
          "name": "model_language",
          "type": "tree",
          "content": null
        },
        {
          "name": "model_zoo",
          "type": "tree",
          "content": null
        },
        {
          "name": "predict_speech_file.py",
          "type": "blob",
          "size": 1.810546875,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n用于通过ASRT语音识别系统预测一次语音文件的程序\n\"\"\"\n\nimport os\n\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom speech_features import Spectrogram\nfrom language_model3 import ModelLanguage\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = Spectrogram()\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\n\nms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\nres = ms.recognize_speech_from_file('filename.wav')\nprint('*[提示] 声学模型语音识别结果：\\n', res)\n\nml = ModelLanguage('model_language')\nml.load_model()\nstr_pinyin = res\nres = ml.pinyin_to_text(str_pinyin)\nprint('语音识别最终结果：\\n', res)\n"
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.16796875,
          "content": "Flask==2.2.2\nh5py==3.8.0\nmatplotlib==3.6.3\nnumpy==1.24.1\nprotobuf==3.19.6\nrequests==2.28.2\nscipy==1.10.0\ntensorflow-gpu==2.8.4\nurllib3==1.26.14\nwaitress==2.1.2\nWave==0.0.2\n"
        },
        {
          "name": "speech_features",
          "type": "tree",
          "content": null
        },
        {
          "name": "speech_model.py",
          "type": "blob",
          "size": 11.30859375,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n声学模型基础功能模板定义\n\"\"\"\nimport os\nimport time\nimport random\nimport numpy as np\n\nfrom utils.ops import get_edit_distance, read_wav_data\nfrom utils.config import load_config_file, DEFAULT_CONFIG_FILENAME, load_pinyin_dict\nfrom utils.thread import threadsafe_generator\n\n\nclass ModelSpeech:\n    \"\"\"\n    语音模型类\n\n    参数：\n        speech_model: 声学模型类型 (BaseModel类) 实例对象\n        speech_features: 声学特征类型(SpeechFeatureMeta类)实例对象\n    \"\"\"\n\n    def __init__(self, speech_model, speech_features, max_label_length=64):\n        self.data_loader = None\n        self.speech_model = speech_model\n        self.trained_model, self.base_model = speech_model.get_model()\n        self.speech_features = speech_features\n        self.max_label_length = max_label_length\n\n    @threadsafe_generator\n    def _data_generator(self, batch_size, data_loader):\n        \"\"\"\n        数据生成器函数，用于Keras的generator_fit训练\n        batch_size: 一次产生的数据量\n        \"\"\"\n        labels = np.zeros((batch_size, 1), dtype=np.float64)\n        data_count = data_loader.get_data_count()\n        index = 0\n\n        while True:\n            X = np.zeros((batch_size,) + self.speech_model.input_shape, dtype=np.float64)\n            y = np.zeros((batch_size, self.max_label_length), dtype=np.int16)\n            input_length = []\n            label_length = []\n\n            for i in range(batch_size):\n                wavdata, sample_rate, data_labels = data_loader.get_data(index)\n                data_input = self.speech_features.run(wavdata, sample_rate)\n                data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n                # 必须加上模pool_size得到的值，否则会出现inf问题，然后提示No valid path found.\n                # 但是直接加又可能会出现sequence_length <= xxx 的问题，因此不能让其超过时间序列长度的最大值，比如200\n                pool_size = self.speech_model.input_shape[0] // self.speech_model.output_shape[0]\n                inlen = min(data_input.shape[0] // pool_size + data_input.shape[0] % pool_size,\n                            self.speech_model.output_shape[0])\n                input_length.append(inlen)\n\n                X[i, 0:len(data_input)] = data_input\n                y[i, 0:len(data_labels)] = data_labels\n                label_length.append([len(data_labels)])\n\n                index = (index + 1) % data_count\n\n            label_length = np.matrix(label_length)\n            input_length = np.array([input_length]).T\n\n            yield [X, y, input_length, label_length], labels\n\n    def train_model(self, optimizer, data_loader, epochs=1, save_step=1, batch_size=16, last_epoch=0, call_back=None):\n        \"\"\"\n        训练模型\n\n        参数：\n            optimizer：tensorflow.keras.optimizers 优化器实例对象\n            data_loader：数据加载器类型 (SpeechData) 实例对象\n            epochs: 迭代轮数\n            save_step: 每多少epoch保存一次模型\n            batch_size: mini batch大小\n            last_epoch: 上一次epoch的编号，可用于断点处继续训练时，epoch编号不冲突\n            call_back: keras call back函数\n        \"\"\"\n        save_filename = os.path.join('save_models', self.speech_model.get_model_name(),\n                                     self.speech_model.get_model_name())\n\n        self.trained_model.compile(loss=self.speech_model.get_loss_function(), optimizer=optimizer)\n        print('[ASRT] Compiles Model Successfully.')\n\n        yielddatas = self._data_generator(batch_size, data_loader)\n\n        data_count = data_loader.get_data_count()  # 获取数据的数量\n        # 计算每一个epoch迭代的次数\n        num_iterate = data_count // batch_size\n        iter_start = last_epoch\n        iter_end = last_epoch + epochs\n        for epoch in range(iter_start, iter_end):  # 迭代轮数\n            try:\n                epoch += 1\n                print('[ASRT Training] train epoch %d/%d .' % (epoch, iter_end))\n                data_loader.shuffle()\n                self.trained_model.fit_generator(yielddatas, num_iterate, callbacks=call_back)\n            except StopIteration:\n                print('[error] generator error. please check data format.')\n                break\n\n            if epoch % save_step == 0:\n                if not os.path.exists('save_models'):  # 判断保存模型的目录是否存在\n                    os.makedirs('save_models')  # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n                if not os.path.exists(os.path.join('save_models', self.speech_model.get_model_name())):  # 判断保存模型的目录是否存在\n                    os.makedirs(\n                        os.path.join('save_models', self.speech_model.get_model_name()))  # 如果不存在，就新建一个，避免之后保存模型的时候炸掉\n\n                self.save_model(save_filename + '_epoch' + str(epoch))\n\n        print('[ASRT Info] Model training complete. ')\n\n    def load_model(self, filename):\n        \"\"\"\n        加载模型参数\n        \"\"\"\n        self.speech_model.load_weights(filename)\n\n    def save_model(self, filename):\n        \"\"\"\n        保存模型参数\n        \"\"\"\n        self.speech_model.save_weights(filename)\n\n    def evaluate_model(self, data_loader, data_count=-1, out_report=False, show_ratio=True, show_per_step=100):\n        \"\"\"\n        评估检验模型的识别效果\n        \"\"\"\n        data_nums = data_loader.get_data_count()\n\n        if data_count <= 0 or data_count > data_nums:  # 当data_count为小于等于0或者大于测试数据量的值时，则使用全部数据来测试\n            data_count = data_nums\n\n        try:\n            ran_num = random.randint(0, data_nums - 1)  # 获取一个随机数\n            words_num = 0\n            word_error_num = 0\n\n            nowtime = time.strftime('%Y%m%d_%H%M%S', time.localtime(time.time()))\n            if out_report:\n                txt_obj = open('Test_Report_' + data_loader.dataset_type + '_' + nowtime + '.txt', 'w',\n                               encoding='UTF-8')  # 打开文件并读入\n                txt_obj.truncate((data_count + 1) * 300)  # 预先分配一定数量的磁盘空间，避免后期在硬盘中文件存储位置频繁移动，以防写入速度越来越慢\n                txt_obj.seek(0)  # 从文件首开始\n\n            txt = ''\n            i = 0\n            while i < data_count:\n                wavdata, fs, data_labels = data_loader.get_data((ran_num + i) % data_nums)  # 从随机数开始连续向后取一定数量数据\n                data_input = self.speech_features.run(wavdata, fs)\n                data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n                # 数据格式出错处理 开始\n                # 当输入的wav文件长度过长时自动跳过该文件，转而使用下一个wav文件来运行\n                if data_input.shape[0] > self.speech_model.input_shape[0]:\n                    print('*[Error]', 'wave data lenghth of num', (ran_num + i) % data_nums, 'is too long.',\n                          'this data\\'s length is', data_input.shape[0],\n                          'expect <=', self.speech_model.input_shape[0],\n                          '\\n A Exception raise when test Speech Model.')\n                    i += 1\n                    continue\n                # 数据格式出错处理 结束\n\n                pre = self.predict(data_input)\n\n                words_n = data_labels.shape[0]  # 获取每个句子的字数\n                words_num += words_n  # 把句子的总字数加上\n                edit_distance = get_edit_distance(data_labels, pre)  # 获取编辑距离\n                if edit_distance <= words_n:  # 当编辑距离小于等于句子字数时\n                    word_error_num += edit_distance  # 使用编辑距离作为错误字数\n                else:  # 否则肯定是增加了一堆乱七八糟的奇奇怪怪的字\n                    word_error_num += words_n  # 就直接加句子本来的总字数就好了\n\n                if i % show_per_step == 0 and show_ratio:\n                    print('[ASRT Info] Testing: ', i, '/', data_count)\n\n                txt = ''\n                if out_report:\n                    txt += str(i) + '\\n'\n                    txt += 'True:\\t' + str(data_labels) + '\\n'\n                    txt += 'Pred:\\t' + str(pre) + '\\n'\n                    txt += '\\n'\n                    txt_obj.write(txt)\n\n                i += 1\n\n            # print('*[测试结果] 语音识别 ' + str_dataset + ' 集语音单字错误率：', word_error_num / words_num * 100, '%')\n            print('*[ASRT Test Result] Speech Recognition ' + data_loader.dataset_type + ' set word error ratio: ',\n                  word_error_num / words_num * 100, '%')\n            if out_report:\n                txt = '*[ASRT Test Result] Speech Recognition ' + data_loader.dataset_type + ' set word error ratio: ' + str(\n                    word_error_num / words_num * 100) + ' %'\n                txt_obj.write(txt)\n                txt_obj.truncate()  # 去除文件末尾剩余未使用的空白存储字节\n                txt_obj.close()\n\n        except StopIteration:\n            print('[ASRT Error] Model testing raise a error. Please check data format.')\n\n    def predict(self, data_input):\n        \"\"\"\n        预测结果\n\n        返回语音识别后的forward结果\n        \"\"\"\n        return self.speech_model.forward(data_input)\n\n    def recognize_speech(self, wavsignal, fs):\n        \"\"\"\n        最终做语音识别用的函数，识别一个wav序列的语音\n        \"\"\"\n        # 获取输入特征\n        data_input = self.speech_features.run(wavsignal, fs)\n        data_input = np.array(data_input, dtype=np.float64)\n        # print(data_input,data_input.shape)\n        data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n        r1 = self.predict(data_input)\n        # 获取拼音列表\n        list_symbol_dic, _ = load_pinyin_dict(load_config_file(DEFAULT_CONFIG_FILENAME)['dict_filename'])\n\n        r_str = []\n        for i in r1:\n            r_str.append(list_symbol_dic[i])\n\n        return r_str\n\n    def recognize_speech_from_file(self, filename):\n        \"\"\"\n        最终做语音识别用的函数，识别指定文件名的语音\n        \"\"\"\n        wavsignal, sample_rate, _, _ = read_wav_data(filename)\n        r = self.recognize_speech(wavsignal, sample_rate)\n        return r\n\n    @property\n    def model(self):\n        \"\"\"\n        返回tf.keras model\n        \"\"\"\n        return self.trained_model\n"
        },
        {
          "name": "speech_recorder.py",
          "type": "blob",
          "size": 3.859375,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n一个配置为可用于ASRT语音识别系统的录音程序\n\"\"\"\n\nimport wave\nimport pyaudio\n\n\ndef record_wave(wavfile,\n                duration=10,\n                channels=1,\n                sampling_rate=16000,\n                sampling_bits=16,\n                chunk_size=1024,\n                keyboard_interrupt='keep_audio'):\n    \"\"\"Record audio using the default audio device by PyAudio and Wave\"\"\"\n\n    format_ = None\n    if sampling_bits == 8:\n        format_ = pyaudio.paInt8\n    if sampling_bits == 16:\n        format_ = pyaudio.paInt16\n    elif sampling_bits == 24:\n        format_ = pyaudio.paInt24\n    elif sampling_bits == 32:\n        format_ = pyaudio.paFloat32\n    else:\n        raise ValueError('Unsupported sampling bits')\n\n    audio = pyaudio.PyAudio()\n    stream = audio.open(format=format_,\n                        channels=channels,\n                        rate=sampling_rate,\n                        input=True,\n                        frames_per_buffer=chunk_size)\n\n    frames = []\n\n    print('Start to record with {}-seconds audio\\n'\n          'Type Ctrl-C to get an early stop (a shorter audio)'\n          .format(duration))\n    try:\n        for _ in range(0, int(sampling_rate / chunk_size * duration)):\n            data = stream.read(chunk_size)\n            frames.append(data)\n            print('.', end='', flush=True)\n    except KeyboardInterrupt:\n        if keyboard_interrupt == 'keep_audio':\n            used_seconds = int(len(frames) * chunk_size / sampling_rate)\n            print('\\n-*- Early stop with {} seconds'.format(used_seconds))\n        else:\n            raise\n    print('\\nRecording finished')\n\n    stream.stop_stream()\n    stream.close()\n    audio.terminate()\n\n    print('Convert PCM frames to WAV... ', end='')\n    wavfp = wave.open(wavfile, 'wb')\n    wavfp.setnchannels(channels)\n    wavfp.setsampwidth(audio.get_sample_size(format_))\n    wavfp.setframerate(sampling_rate)\n    wavfp.writeframes(b''.join(frames))\n    wavfp.close()\n    print('OK')\n\n\nif __name__ == \"__main__\":\n    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n\n    parser = ArgumentParser(description='Simple Wave Audio Recorder',\n                            formatter_class=ArgumentDefaultsHelpFormatter)\n    parser.add_argument('-d', '--duration', type=int,\n                        default=10, help='maximum duration in seconds')\n    parser.add_argument('-r', '--sampling-rate', type=int,\n                        default=16000, help='sampling rate')\n    parser.add_argument('-b', '--sampling-bits', type=int,\n                        default=16, choices=(8, 16, 24, 32), help='sampling bits')\n    parser.add_argument('-c', '--channels', type=int,\n                        default=1, help='audio channels')\n    parser.add_argument('output', nargs='?', default='output.wav',\n                        help='audio file to store audio stream')\n    args = parser.parse_args()\n    record_wave(args.output, duration=args.duration,\n                channels=args.channels,\n                sampling_bits=args.sampling_bits,\n                sampling_rate=args.sampling_rate)\n"
        },
        {
          "name": "torch_speech_model.py",
          "type": "blob",
          "size": 5.6162109375,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687 / Evelynn-n\n声学模型基础功能模板定义\n\"\"\"\n\nimport os\nimport time\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader as TorchDataLoader\n\nfrom data_loader import DataLoader\nfrom speech_features.speech_features import SpeechFeatureMeta\n\n\nclass SpeechDataset(Dataset):\n    def __init__(self, data_loader, speech_features, input_shape, max_label_length):\n        self.data_loader = data_loader\n        self.input_shape = input_shape\n        self.speech_features = speech_features\n        self.max_label_length = max_label_length\n        self.data_count = self.data_loader.get_data_count()\n\n    def __len__(self):\n        return self.data_count\n\n    def __getitem__(self, index):\n        wav_data, sample_rate, data_labels = self.data_loader.get_data(index)\n\n        # 提取特征\n        data_input = self.speech_features.run(wav_data, sample_rate)\n        data_input = data_input.reshape(data_input.shape[0], data_input.shape[1], 1)\n\n        # 计算输入长度，确保不超出最大序列长度\n        pool_size = self.input_shape[0] // (self.input_shape[0] // 8)\n        inlen = min(data_input.shape[0] // pool_size + data_input.shape[0] % pool_size, self.input_shape[0] // 8)\n\n        # 初始化输入特征数组，填充到 `input_shape` 大小\n        x = torch.zeros(self.input_shape)\n        x[:len(data_input)] = torch.tensor(data_input, dtype=torch.float32)\n\n        # 初始化标签数组，填充到 `max_label_length` 大小\n        y = torch.zeros(self.max_label_length, dtype=torch.int16)\n        y[:len(data_labels)] = torch.tensor(data_labels, dtype=torch.int16) + 1\n\n        # 转换为 PyTorch 张量\n        input_length = torch.tensor((inlen,), dtype=torch.float32)\n        label_length = torch.tensor((len(data_labels),), dtype=torch.float32)\n        return x, y, input_length, label_length\n\n\nclass ModelSpeech:\n    def __init__(self, speech_model: torch.nn.Module, speech_features: SpeechFeatureMeta, max_label_length: int = 64):\n        \"\"\"模型初始化\"\"\"\n        self.speech_model = speech_model\n        self.trained_model = speech_model.get_model()\n        self.speech_features = speech_features\n        self.max_label_length = max_label_length\n\n    def train(self, data_loader: DataLoader, epochs: int, batch_size: int, optimizer: torch.optim.Optimizer,\n              device: str = 'cpu'):\n        \"\"\"训练模型\"\"\"\n        speechdata = SpeechDataset(data_loader, self.speech_features, input_shape=self.speech_model.input_shape,\n                                   max_label_length=self.max_label_length)\n        self.trained_model.to(device)\n        print('[ASRT] torch model successfully initialized to device: {}'.format(device))\n        data_loader = TorchDataLoader(speechdata, batch_size=batch_size, shuffle=True)\n        model = self.speech_model\n        for epoch in range(epochs):\n            print('[ASRT] Epoch {}/{}'.format(epoch + 1, epochs))\n            epoch_loss = 0.0\n            iter_index = 0\n            t0 = time.time()\n            for batch in data_loader:\n                x, y, input_length, label_length = batch\n                x = x.to(device)\n                y = y.to(device)\n                input_length = input_length.to(device).long()\n                label_length = label_length.to(device).long()\n\n                optimizer.zero_grad()\n                y_pred = model(x)\n                loss = model.compute_loss(y_pred, y, input_length, label_length)\n                loss.backward()\n                optimizer.step()\n\n                epoch_loss += loss.item()\n                iter_index += 1\n                t1 = time.time()\n                predict_total_time = (t1-t0)*len(data_loader)/iter_index\n                predict_remain_time = predict_total_time - (t1-t0)\n                cur_batch_loss = loss.item()\n                cur_avg_loss = epoch_loss / iter_index\n                print(\"[ASRT]\", f\"{predict_remain_time:.2f}/{predict_total_time:.2f} s,\",\n                      f\"step {iter_index}/{len(data_loader)},\", f\"current loss: {cur_batch_loss:.4f}\",\n                      f\"avg loss: {cur_avg_loss:.4f}\", end=\"\\r\")\n\n            save_filename = os.path.join('save_models_torch', f\"{self.speech_model.get_model_name()}_epoch{epoch+1}.pth\")\n            self.save_weight(save_filename)\n            avg_loss = epoch_loss / len(data_loader)\n            total_time = time.time()-t0\n            avg_time_per_step = total_time / len(data_loader)\n            print(\"[ASRT]\", f\"epoch {epoch + 1}/{epochs},\", f\"time cost: {total_time:.2f} s,\",\n                  f\"{avg_time_per_step:.2f} s/step\", f\"avg loss: {avg_loss:.4f}\")\n\n    def save_weight(self, filename: str):\n        save_filename = os.path.join('save_models_torch', filename + \".pth\")\n        torch.save(self.speech_model.state_dict(), save_filename)\n\n    def load_weight(self, filepath: str):\n        self.speech_model.load_state_dict(torch.load(filepath))\n"
        },
        {
          "name": "train_speech_model.py",
          "type": "blob",
          "size": 1.8671875,
          "content": "# !/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\n用于训练语音识别系统语音模型的程序\n\"\"\"\n\nimport os\nfrom tensorflow.keras.optimizers import Adam\n\nfrom speech_model import ModelSpeech\nfrom model_zoo.speech_model.keras_backend import SpeechModel251BN\nfrom data_loader import DataLoader\nfrom speech_features import SpecAugment\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nAUDIO_LENGTH = 1600\nAUDIO_FEATURE_LENGTH = 200\nCHANNELS = 1\n# 默认输出的拼音的表示大小是1428，即1427个拼音+1个空白块\nOUTPUT_SIZE = 1428\nsm251bn = SpeechModel251BN(\n    input_shape=(AUDIO_LENGTH, AUDIO_FEATURE_LENGTH, CHANNELS),\n    output_size=OUTPUT_SIZE\n)\nfeat = SpecAugment()\ntrain_data = DataLoader('train')\nopt = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0, epsilon=10e-8)\nms = ModelSpeech(sm251bn, feat, max_label_length=64)\n\n# ms.load_model('save_models/' + sm251bn.get_model_name() + '.model.h5')\nms.train_model(optimizer=opt, data_loader=train_data,\n               epochs=50, save_step=1, batch_size=16, last_epoch=0)\nms.save_model('save_models/' + sm251bn.get_model_name())\n"
        },
        {
          "name": "train_speech_model_pytorch.py",
          "type": "blob",
          "size": 1.578125,
          "content": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n#\n# Copyright 2016-2099 Ailemon.net\n#\n# This file is part of ASRT Speech Recognition Tool.\n#\n# ASRT is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n# ASRT is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with ASRT.  If not, see <https://www.gnu.org/licenses/>.\n# ============================================================================\n\n\"\"\"\n@author: nl8590687\npytorch版声学模型训练脚本入口\n\"\"\"\nfrom torch import optim\n\nfrom torch_speech_model import *\nfrom speech_features import SpecAugment\nfrom data_loader import DataLoader\nfrom model_zoo.speech_model.pytorch_backend import SpeechModel251BN\n\nif __name__ == \"__main__\":\n    feat = SpecAugment()\n    data_loader = DataLoader('train')\n\n    model = SpeechModel251BN()\n    speechModel = ModelSpeech(model, feat, max_label_length=64)\n    print(model)\n\n    # speechModel.load_weight(os.path.join('save_models_torch', model.get_model_name()+\"_save.pth\"))\n    speechModel.train(data_loader, epochs=10, batch_size=16, optimizer=optim.Adam(model.parameters(), lr=0.001),\n                      device=\"cuda:0\")\n    speechModel.save_weight(model.get_model_name()+\"_save\")\n"
        },
        {
          "name": "utils",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}