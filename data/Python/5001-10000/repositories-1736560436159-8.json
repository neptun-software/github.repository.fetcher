{
  "metadata": {
    "timestamp": 1736560436159,
    "page": 8,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEw",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "bmaltais/kohya_ss",
      "stars": 9926,
      "defaultBranch": "master",
      "files": [
        {
          "name": ".augmentignore",
          "type": "blob",
          "size": 0.1328125,
          "content": ".env\n.cache\n.vscode\n__pycache__\nbitsandbytes_windows\ncudnn_windows\ndata\ndataset\ndocs\nexamples\noutputs\nSmilingWolf\ntest\nv2_inference\nvenv"
        },
        {
          "name": ".cache",
          "type": "tree",
          "content": null
        },
        {
          "name": ".dockerignore",
          "type": "blob",
          "size": 0.203125,
          "content": ".cache/\r\ncudnn_windows/\r\nbitsandbytes_windows/\r\nbitsandbytes_windows_deprecated/\r\ndataset/\r\n__pycache__/\r\nvenv/\r\n**/.hadolint.yml\r\n**/*.log\r\n**/.git\r\n**/.gitignore\r\n**/.env\r\n**/.github\r\n**/.vscode\r\n**/*.ps1\r\n"
        },
        {
          "name": ".env",
          "type": "blob",
          "size": 0.021484375,
          "content": "TENSORBOARD_PORT=6006\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.07421875,
          "content": "*.sh text eol=lf\n*.ps1 text eol=crlf\n*.bat text eol=crlf\n*.cmd text eol=crlf"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.568359375,
          "content": "# Python\nvenv\nvenv2\n__pycache__\n*.egg-info\nbuild\nwd14_tagger_model\n\n# IDE and Editor specific\n.vscode\n\n# CUDNN for Windows\ncudnn_windows\n\n# Cache and temporary files\n.cache\n.DS_Store\n\n# Scripts and executables\nlocon\ngui-user.bat\ngui-user.ps1\n\n# Version control\nSmilingWolf\nwandb\n\n# Setup and logs\nsetup.log\nlogs\n\n# Miscellaneous\nuninstall.txt\n\n# Test files\ntest/output\ntest/log*\ntest/*.json\ntest/ft\n\n# Temporary requirements\nrequirements_tmp_for_setup.txt\n\n*.npz\npresets/*/user_presets/*\ninputs\noutputs\ndataset/**\n!dataset/**/\n!dataset/**/.gitkeep\nmodels\ndata\nconfig.toml\nsd-scripts"
        },
        {
          "name": ".gitmodules",
          "type": "blob",
          "size": 0.0966796875,
          "content": "[submodule \"sd-scripts\"]\n    path = sd-scripts\n    url = https://github.com/kohya-ss/sd-scripts.git"
        },
        {
          "name": ".hadolint.yml",
          "type": "blob",
          "size": 0.4833984375,
          "content": "ignored:\n  - DL3042 # Avoid use of cache directory with pip. Use `pip install --no-cache-dir <package>`\n  - DL3013 # Pin versions in pip. Instead of `pip install <package>` use `pip install <package>==<version>`\n  - DL3008 # Pin versions in apt get install. Instead of `apt-get install <package>` use `apt-get install <package>=<version>`\n  - DL4006 # Set the SHELL option -o pipefail before RUN with a pipe in it\n  - SC2015 # Note that A && B || C is not if-then-else. C may run when A is true."
        },
        {
          "name": ".release",
          "type": "blob",
          "size": 0.0068359375,
          "content": "v24.1.7"
        },
        {
          "name": ".vscode",
          "type": "tree",
          "content": null
        },
        {
          "name": "Dockerfile",
          "type": "blob",
          "size": 6.2890625,
          "content": "# syntax=docker/dockerfile:1\r\nARG UID=1000\r\nARG VERSION=EDGE\r\nARG RELEASE=0\r\n\r\nFROM python:3.10-slim as build\r\n\r\n# RUN mount cache for multi-arch: https://github.com/docker/buildx/issues/549#issuecomment-1788297892\r\nARG TARGETARCH\r\nARG TARGETVARIANT\r\n\r\nWORKDIR /app\r\n\r\n# Install under /root/.local\r\nENV PIP_USER=\"true\"\r\nARG PIP_NO_WARN_SCRIPT_LOCATION=0\r\nARG PIP_ROOT_USER_ACTION=\"ignore\"\r\n\r\n# Install build dependencies\r\nRUN --mount=type=cache,id=apt-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/cache/apt \\\r\n    --mount=type=cache,id=aptlists-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/lib/apt/lists \\\r\n    apt-get update && apt-get upgrade -y && \\\r\n    apt-get install -y --no-install-recommends python3-launchpadlib git curl\r\n\r\n# Install PyTorch\r\n# The versions must align and be in sync with the requirements_linux_docker.txt\r\n# hadolint ignore=SC2102\r\nRUN --mount=type=cache,id=pip-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/root/.cache/pip \\\r\n    pip install -U --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.nvidia.com \\\r\n    torch==2.1.2 torchvision==0.16.2 \\\r\n    xformers==0.0.23.post1 \\\r\n    ninja \\\r\n    pip setuptools wheel\r\n\r\n# Install requirements\r\nRUN --mount=type=cache,id=pip-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/root/.cache/pip \\\r\n    --mount=source=requirements_linux_docker.txt,target=requirements_linux_docker.txt \\\r\n    --mount=source=requirements.txt,target=requirements.txt \\\r\n    --mount=source=setup/docker_setup.py,target=setup.py \\\r\n    --mount=source=sd-scripts,target=sd-scripts,rw \\\r\n    pip install -r requirements_linux_docker.txt -r requirements.txt\r\n\r\n# Replace pillow with pillow-simd (Only for x86)\r\nARG TARGETPLATFORM\r\nRUN --mount=type=cache,id=apt-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/cache/apt \\\r\n    --mount=type=cache,id=aptlists-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/lib/apt/lists \\\r\n    if [ \"$TARGETPLATFORM\" = \"linux/amd64\" ]; then \\\r\n    apt-get update && apt-get install -y --no-install-recommends zlib1g-dev libjpeg62-turbo-dev build-essential && \\\r\n    pip uninstall -y pillow && \\\r\n    CC=\"cc -mavx2\" pip install -U --force-reinstall pillow-simd; \\\r\n    fi\r\n\r\nFROM python:3.10-slim as final\r\n\r\nARG TARGETARCH\r\nARG TARGETVARIANT\r\n\r\nENV NVIDIA_VISIBLE_DEVICES all\r\nENV NVIDIA_DRIVER_CAPABILITIES compute,utility\r\n\r\nWORKDIR /tmp\r\n\r\nENV CUDA_VERSION=12.1.1\r\nENV NV_CUDA_CUDART_VERSION=12.1.105-1\r\nENV NVIDIA_REQUIRE_CUDA=cuda>=12.1\r\nENV NV_CUDA_COMPAT_PACKAGE=cuda-compat-12-1\r\n\r\n# Install CUDA partially\r\nADD https://developer.download.nvidia.com/compute/cuda/repos/debian11/x86_64/cuda-keyring_1.0-1_all.deb .\r\nRUN --mount=type=cache,id=apt-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/cache/apt \\\r\n    --mount=type=cache,id=aptlists-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/lib/apt/lists \\\r\n    dpkg -i cuda-keyring_1.0-1_all.deb && \\\r\n    rm cuda-keyring_1.0-1_all.deb && \\\r\n    sed -i 's/^Components: main$/& contrib/' /etc/apt/sources.list.d/debian.sources && \\\r\n    apt-get update && \\\r\n    apt-get install -y --no-install-recommends \\\r\n    # Installing the whole CUDA typically increases the image size by approximately **8GB**.\r\n    # To decrease the image size, we opt to install only the necessary libraries.\r\n    # Here is the package list for your reference: https://developer.download.nvidia.com/compute/cuda/repos/debian11/x86_64\r\n    # !If you experience any related issues, replace the following line with `cuda-12-1` to obtain the complete CUDA package.\r\n    cuda-cudart-12-1=${NV_CUDA_CUDART_VERSION} ${NV_CUDA_COMPAT_PACKAGE} libcusparse-12-1 libnvjitlink-12-1\r\n\r\n# Install runtime dependencies\r\nRUN --mount=type=cache,id=apt-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/cache/apt \\\r\n    --mount=type=cache,id=aptlists-$TARGETARCH$TARGETVARIANT,sharing=locked,target=/var/lib/apt/lists \\\r\n    apt-get update && \\\r\n    apt-get install -y --no-install-recommends libgl1 libglib2.0-0 libjpeg62 libtcl8.6 libtk8.6 libgoogle-perftools-dev dumb-init\r\n\r\n# Fix missing libnvinfer7\r\nRUN ln -s /usr/lib/x86_64-linux-gnu/libnvinfer.so /usr/lib/x86_64-linux-gnu/libnvinfer.so.7 && \\\r\n    ln -s /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.7\r\n\r\n# Create user\r\nARG UID\r\nRUN groupadd -g $UID $UID && \\\r\n    useradd -l -u $UID -g $UID -m -s /bin/sh -N $UID\r\n\r\n# Create directories with correct permissions\r\nRUN install -d -m 775 -o $UID -g 0 /dataset && \\\r\n    install -d -m 775 -o $UID -g 0 /licenses && \\\r\n    install -d -m 775 -o $UID -g 0 /app\r\n\r\n# Copy licenses (OpenShift Policy)\r\nCOPY --link --chmod=775 LICENSE.md /licenses/LICENSE.md\r\n\r\n# Copy dependencies and code (and support arbitrary uid for OpenShift best practice)\r\nCOPY --link --chown=$UID:0 --chmod=775 --from=build /root/.local /home/$UID/.local\r\nCOPY --link --chown=$UID:0 --chmod=775 . /app\r\n\r\nENV PATH=\"/usr/local/cuda/lib:/usr/local/cuda/lib64:/home/$UID/.local/bin:$PATH\"\r\nENV PYTHONPATH=\"${PYTHONPATH}:/home/$UID/.local/lib/python3.10/site-packages\" \r\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}\"\r\nENV LD_PRELOAD=libtcmalloc.so\r\nENV PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\r\n# Rich logging\r\n# https://rich.readthedocs.io/en/stable/console.html#interactive-mode\r\nENV FORCE_COLOR=\"true\"\r\nENV COLUMNS=\"100\"\r\n\r\nWORKDIR /app\r\n\r\nVOLUME [ \"/dataset\" ]\r\n\r\n# 7860: Kohya GUI\r\nEXPOSE 7860\r\n\r\nUSER $UID\r\n\r\nSTOPSIGNAL SIGINT\r\n\r\n# Use dumb-init as PID 1 to handle signals properly\r\nENTRYPOINT [\"dumb-init\", \"--\"]\r\nCMD [\"python3\", \"kohya_gui.py\", \"--listen\", \"0.0.0.0\", \"--server_port\", \"7860\", \"--headless\"]\r\n\r\nARG VERSION\r\nARG RELEASE\r\nLABEL name=\"bmaltais/kohya_ss\" \\\r\n    vendor=\"bmaltais\" \\\r\n    maintainer=\"bmaltais\" \\\r\n    # Dockerfile source repository\r\n    url=\"https://github.com/bmaltais/kohya_ss\" \\\r\n    version=${VERSION} \\\r\n    # This should be a number, incremented with each change\r\n    release=${RELEASE} \\\r\n    io.k8s.display-name=\"kohya_ss\" \\\r\n    summary=\"Kohya's GUI: This repository provides a Gradio GUI for Kohya's Stable Diffusion trainers(https://github.com/kohya-ss/sd-scripts).\" \\\r\n    description=\"The GUI allows you to set the training parameters and generate and run the required CLI commands to train the model. This is the docker image for Kohya's GUI. For more information about this tool, please visit the following website: https://github.com/bmaltais/kohya_ss.\""
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 11.076171875,
          "content": "                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [2022] [kohya-ss]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 17.5693359375,
          "content": "# Kohya's GUI\n\nThis repository primarily provides a Gradio GUI for [Kohya's Stable Diffusion trainers](https://github.com/kohya-ss/sd-scripts). However, support for Linux OS is also offered through community contributions. macOS support is not optimal at the moment but might work if the conditions are favorable.\n\nThe GUI allows you to set the training parameters and generate and run the required CLI commands to train the model.\n\n## Table of Contents\n\n- [Kohya's GUI](#kohyas-gui)\n  - [Table of Contents](#table-of-contents)\n  - [🦒 Colab](#-colab)\n  - [Installation](#installation)\n    - [Windows](#windows)\n      - [Windows Pre-requirements](#windows-pre-requirements)\n      - [Setup Windows](#setup-windows)\n      - [Optional: CUDNN 8.9.6.50](#optional-cudnn-89650)\n    - [Linux and macOS](#linux-and-macos)\n      - [Linux Pre-requirements](#linux-pre-requirements)\n      - [Setup Linux](#setup-linux)\n      - [Install Location](#install-location)\n    - [Runpod](#runpod)\n      - [Manual installation](#manual-installation)\n      - [Pre-built Runpod template](#pre-built-runpod-template)\n    - [Docker](#docker)\n      - [Get your Docker ready for GPU support](#get-your-docker-ready-for-gpu-support)\n        - [Windows](#windows-1)\n        - [Linux, OSX](#linux-osx)\n      - [Design of our Dockerfile](#design-of-our-dockerfile)\n      - [Use the pre-built Docker image](#use-the-pre-built-docker-image)\n      - [Local docker build](#local-docker-build)\n      - [ashleykleynhans runpod docker builds](#ashleykleynhans-runpod-docker-builds)\n  - [Upgrading](#upgrading)\n    - [Windows Upgrade](#windows-upgrade)\n    - [Linux and macOS Upgrade](#linux-and-macos-upgrade)\n  - [Starting GUI Service](#starting-gui-service)\n    - [Launching the GUI on Windows](#launching-the-gui-on-windows)\n    - [Launching the GUI on Linux and macOS](#launching-the-gui-on-linux-and-macos)\n  - [Custom Path Defaults](#custom-path-defaults)\n  - [LoRA](#lora)\n  - [Sample image generation during training](#sample-image-generation-during-training)\n  - [Troubleshooting](#troubleshooting)\n    - [Page File Limit](#page-file-limit)\n    - [No module called tkinter](#no-module-called-tkinter)\n    - [LORA Training on TESLA V100 - GPU Utilization Issue](#lora-training-on-tesla-v100---gpu-utilization-issue)\n      - [Issue Summary](#issue-summary)\n      - [Potential Solutions](#potential-solutions)\n  - [SDXL training](#sdxl-training)\n  - [Masked loss](#masked-loss)\n  - [Change History](#change-history)\n\n## 🦒 Colab\n\nThis Colab notebook was not created or maintained by me; however, it appears to function effectively. The source can be found at: <https://github.com/camenduru/kohya_ss-colab>.\n\nI would like to express my gratitude to camendutu for their valuable contribution. If you encounter any issues with the Colab notebook, please report them on their repository.\n\n| Colab                                                                                                                                                                          | Info               |\n| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------ |\n| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/kohya_ss-colab/blob/main/kohya_ss_colab.ipynb) | kohya_ss_gui_colab |\n\n## Installation\n\n### Windows\n\n#### Windows Pre-requirements\n\nTo install the necessary dependencies on a Windows system, follow these steps:\n\n1. Install [Python 3.10.11](https://www.python.org/ftp/python/3.10.11/python-3.10.11-amd64.exe).\n   - During the installation process, ensure that you select the option to add Python to the 'PATH' environment variable.\n\n2. Install [CUDA 11.8 toolkit](https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Windows&target_arch=x86_64).\n\n3. Install [Git](https://git-scm.com/download/win).\n\n4. Install the [Visual Studio 2015, 2017, 2019, and 2022 redistributable](https://aka.ms/vs/17/release/vc_redist.x64.exe).\n\n#### Setup Windows\n\nTo set up the project, follow these steps:\n\n1. Open a terminal and navigate to the desired installation directory.\n\n2. Clone the repository by running the following command:\n\n   ```shell\n   git clone --recursive https://github.com/bmaltais/kohya_ss.git\n   ```\n\n3. Change into the `kohya_ss` directory:\n\n   ```shell\n   cd kohya_ss\n   ```\n\n4. Run one of the following setup script by executing the following command:\n\n   For systems with only python 3.10.11 installed:\n\n   ```shell\n   .\\setup.bat\n   ```\n\n   For systems with only more than one python release installed:\n\n   ```shell\n   .\\setup-3.10.bat\n   ```\n\n   During the accelerate config step, use the default values as proposed during the configuration unless you know your hardware demands otherwise. The amount of VRAM on your GPU does not impact the values used.\n\n#### Optional: CUDNN 8.9.6.50\n\nThe following steps are optional but will improve the learning speed for owners of NVIDIA 30X0/40X0 GPUs. These steps enable larger training batch sizes and faster training speeds.\n\n1. Run `.\\setup.bat` and select `2. (Optional) Install cudnn files (if you want to use the latest supported cudnn version)`.\n\n### Linux and macOS\n\n#### Linux Pre-requirements\n\nTo install the necessary dependencies on a Linux system, ensure that you fulfill the following requirements:\n\n- Ensure that `venv` support is pre-installed. You can install it on Ubuntu 22.04 using the command:\n\n  ```shell\n  apt install python3.10-venv\n  ```\n\n- Install the CUDA 11.8 Toolkit by following the instructions provided in [this link](https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&target_arch=x86_64).\n\n- Make sure you have Python version 3.10.9 or higher (but lower than 3.11.0) installed on your system.\n\n#### Setup Linux\n\nTo set up the project on Linux or macOS, perform the following steps:\n\n1. Open a terminal and navigate to the desired installation directory.\n\n2. Clone the repository by running the following command:\n\n   ```shell\n   git clone --recursive https://github.com/bmaltais/kohya_ss.git\n   ```\n\n3. Change into the `kohya_ss` directory:\n\n   ```shell\n   cd kohya_ss\n   ```\n\n4. If you encounter permission issues, make the `setup.sh` script executable by running the following command:\n\n   ```shell\n   chmod +x ./setup.sh\n   ```\n\n5. Run the setup script by executing the following command:\n\n   ```shell\n   ./setup.sh\n   ```\n\n   Note: If you need additional options or information about the runpod environment, you can use `setup.sh -h` or `setup.sh --help` to display the help message.\n\n#### Install Location\n\nThe default installation location on Linux is the directory where the script is located. If a previous installation is detected in that location, the setup will proceed there. Otherwise, the installation will fall back to `/opt/kohya_ss`. If `/opt` is not writable, the fallback location will be `$HOME/kohya_ss`. Finally, if none of the previous options are viable, the installation will be performed in the current directory.\n\nFor macOS and other non-Linux systems, the installation process will attempt to detect the previous installation directory based on where the script is run. If a previous installation is not found, the default location will be `$HOME/kohya_ss`. You can override this behavior by specifying a custom installation directory using the `-d` or `--dir` option when running the setup script.\n\nIf you choose to use the interactive mode, the default values for the accelerate configuration screen will be \"This machine,\" \"None,\" and \"No\" for the remaining questions. These default answers are the same as the Windows installation.\n\n### Runpod\n\n#### Manual installation\n\nTo install the necessary components for Runpod and run kohya_ss, follow these steps:\n\n1. Select the Runpod pytorch 2.0.1 template. This is important. Other templates may not work.\n\n2. SSH into the Runpod.\n\n3. Clone the repository by running the following command:\n\n   ```shell\n   cd /workspace\n   git clone --recursive https://github.com/bmaltais/kohya_ss.git\n   ```\n\n4. Run the setup script:\n\n   ```shell\n   cd kohya_ss\n   ./setup-runpod.sh\n   ```\n\n5. Run the GUI with:\n\n   ```shell\n   ./gui.sh --share --headless\n   ```\n\n   or with this if you expose 7860 directly via the runpod configuration:\n\n   ```shell\n   ./gui.sh --listen=0.0.0.0 --headless\n   ```\n\n6. Connect to the public URL displayed after the installation process is completed.\n\n#### Pre-built Runpod template\n\nTo run from a pre-built Runpod template, you can:\n\n1. Open the Runpod template by clicking on <https://runpod.io/gsc?template=ya6013lj5a&ref=w18gds2n>.\n\n2. Deploy the template on the desired host.\n\n3. Once deployed, connect to the Runpod on HTTP 3010 to access the kohya_ss GUI. You can also connect to auto1111 on HTTP 3000.\n\n### Docker\n\n#### Get your Docker ready for GPU support\n\n##### Windows\n\nOnce you have installed [**Docker Desktop**](https://www.docker.com/products/docker-desktop/), [**CUDA Toolkit**](https://developer.nvidia.com/cuda-downloads), [**NVIDIA Windows Driver**](https://www.nvidia.com.tw/Download/index.aspx), and ensured that your Docker is running with [**WSL2**](https://docs.docker.com/desktop/wsl/#turn-on-docker-desktop-wsl-2), you are ready to go.\n\nHere is the official documentation for further reference.  \n<https://docs.nvidia.com/cuda/wsl-user-guide/index.html#nvidia-compute-software-support-on-wsl-2>\n<https://docs.docker.com/desktop/wsl/use-wsl/#gpu-support>\n\n##### Linux, OSX\n\nInstall an NVIDIA GPU Driver if you do not already have one installed.  \n<https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html>\n\nInstall the NVIDIA Container Toolkit with this guide.  \n<https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html>\n\n#### Design of our Dockerfile\n\n- It is required that all training data is stored in the `dataset` subdirectory, which is mounted into the container at `/dataset`.\n- Please note that the file picker functionality is not available. Instead, you will need to manually input the folder path and configuration file path.\n- TensorBoard has been separated from the project.\n  - TensorBoard is not included in the Docker image.\n  - The \"Start TensorBoard\" button has been hidden.\n  - TensorBoard is launched from a distinct container [as shown here](/docker-compose.yaml#L41).\n- The browser won't be launched automatically. You will need to manually open the browser and navigate to [http://localhost:7860/](http://localhost:7860/) and [http://localhost:6006/](http://localhost:6006/)\n- This Dockerfile has been designed to be easily disposable. You can discard the container at any time and restart it with the new code version.\n\n#### Use the pre-built Docker image\n\n```bash\ngit clone --recursive https://github.com/bmaltais/kohya_ss.git\ncd kohya_ss\ndocker compose up -d\n```\n\nTo update the system, do `docker compose down && docker compose up -d --pull always`\n\n#### Local docker build\n\n> [!IMPORTANT]  \n> Clone the Git repository ***recursively*** to include submodules:  \n> `git clone --recursive https://github.com/bmaltais/kohya_ss.git`\n\n```bash\ngit clone --recursive https://github.com/bmaltais/kohya_ss.git\ncd kohya_ss\ndocker compose up -d --build\n```\n\n> [!NOTE]  \n> Building the image may take up to 20 minutes to complete.\n\nTo update the system, ***checkout to the new code version*** and rebuild using `docker compose down && docker compose up -d --build --pull always`\n\n> If you are running on Linux, an alternative Docker container port with fewer limitations is available [here](https://github.com/P2Enjoy/kohya_ss-docker).\n\n#### ashleykleynhans runpod docker builds\n\nYou may want to use the following repositories when running on runpod:\n\n- Standalone Kohya_ss template: <https://github.com/ashleykleynhans/kohya-docker>\n- Auto1111 + Kohya_ss GUI template: <https://github.com/ashleykleynhans/stable-diffusion-docker>\n\n## Upgrading\n\nTo upgrade your installation to a new version, follow the instructions below.\n\n### Windows Upgrade\n\nIf a new release becomes available, you can upgrade your repository by running the following commands from the root directory of the project:\n\n1. Pull the latest changes from the repository:\n\n   ```powershell\n   git pull\n   ```\n\n2. Run the setup script:\n\n   ```powershell\n   .\\setup.bat\n   ```\n\n### Linux and macOS Upgrade\n\nTo upgrade your installation on Linux or macOS, follow these steps:\n\n1. Open a terminal and navigate to the root directory of the project.\n\n2. Pull the latest changes from the repository:\n\n   ```bash\n   git pull\n   ```\n\n3. Refresh and update everything:\n\n   ```bash\n   ./setup.sh\n   ```\n\n## Starting GUI Service\n\nTo launch the GUI service, you can use the provided scripts or run the `kohya_gui.py` script directly. Use the command line arguments listed below to configure the underlying service.\n\n```text\n--listen: Specify the IP address to listen on for connections to Gradio.\n--username: Set a username for authentication.\n--password: Set a password for authentication.\n--server_port: Define the port to run the server listener on.\n--inbrowser: Open the Gradio UI in a web browser.\n--share: Share the Gradio UI.\n--language: Set custom language\n```\n\n### Launching the GUI on Windows\n\nOn Windows, you can use either the `gui.ps1` or `gui.bat` script located in the root directory. Choose the script that suits your preference and run it in a terminal, providing the desired command line arguments. Here's an example:\n\n```powershell\ngui.ps1 --listen 127.0.0.1 --server_port 7860 --inbrowser --share\n```\n\nor\n\n```powershell\ngui.bat --listen 127.0.0.1 --server_port 7860 --inbrowser --share\n```\n\n### Launching the GUI on Linux and macOS\n\nTo launch the GUI on Linux or macOS, run the `gui.sh` script located in the root directory. Provide the desired command line arguments as follows:\n\n```bash\ngui.sh --listen 127.0.0.1 --server_port 7860 --inbrowser --share\n```\n\n## Custom Path Defaults\n\nThe repository now provides a default configuration file named `config.toml`. This file is a template that you can customize to suit your needs.\n\nTo use the default configuration file, follow these steps:\n\n1. Copy the `config example.toml` file from the root directory of the repository to `config.toml`.\n2. Open the `config.toml` file in a text editor.\n3. Modify the paths and settings as per your requirements.\n\nThis approach allows you to easily adjust the configuration to suit your specific needs to open the desired default folders for each type of folder/file input supported in the GUI.\n\nYou can specify the path to your config.toml (or any other name you like) when running the GUI. For instance: ./gui.bat --config c:\\my_config.toml\n\n## LoRA\n\nTo train a LoRA, you can currently use the `train_network.py` code. You can create a LoRA network by using the all-in-one GUI.\n\nOnce you have created the LoRA network, you can generate images using auto1111 by installing [this extension](https://github.com/kohya-ss/sd-webui-additional-networks).\n\n## Sample image generation during training\n\nA prompt file might look like this, for example:\n\n```txt\n# prompt 1\nmasterpiece, best quality, (1girl), in white shirts, upper body, looking at viewer, simple background --n low quality, worst quality, bad anatomy, bad composition, poor, low effort --w 768 --h 768 --d 1 --l 7.5 --s 28\n\n# prompt 2\nmasterpiece, best quality, 1boy, in business suit, standing at street, looking back --n (low quality, worst quality), bad anatomy, bad composition, poor, low effort --w 576 --h 832 --d 2 --l 5.5 --s 40\n```\n\nLines beginning with `#` are comments. You can specify options for the generated image with options like `--n` after the prompt. The following options can be used:\n\n- `--n`: Negative prompt up to the next option.\n- `--w`: Specifies the width of the generated image.\n- `--h`: Specifies the height of the generated image.\n- `--d`: Specifies the seed of the generated image.\n- `--l`: Specifies the CFG scale of the generated image.\n- `--s`: Specifies the number of steps in the generation.\n\nThe prompt weighting such as `( )` and `[ ]` is working.\n\n## Troubleshooting\n\nIf you encounter any issues, refer to the troubleshooting steps below.\n\n### Page File Limit\n\nIf you encounter an X error related to the page file, you may need to increase the page file size limit in Windows.\n\n### No module called tkinter\n\nIf you encounter an error indicating that the module `tkinter` is not found, try reinstalling Python 3.10 on your system.\n\n### LORA Training on TESLA V100 - GPU Utilization Issue\n\n#### Issue Summary\n\nWhen training LORA on a TESLA V100, users reported low GPU utilization. Additionally, there was difficulty in specifying GPUs other than the default for training.\n\n#### Potential Solutions\n\n- **GPU Selection:** Users can specify GPU IDs in the setup configuration to select the desired GPUs for training.\n- **Improving GPU Load:** Utilizing `adamW8bit` optimizer and increasing the batch size can help achieve 70-80% GPU utilization without exceeding GPU memory limits.\n\n## SDXL training\n\nThe documentation in this section will be moved to a separate document later.\n\n## Masked loss\n\nThe masked loss is supported in each training script. To enable the masked loss, specify the `--masked_loss` option.\n\nThe feature is not fully tested, so there may be bugs. If you find any issues, please open an Issue.\n\nControlNet dataset is used to specify the mask. The mask images should be the RGB images. The pixel value 255 in R channel is treated as the mask (the loss is calculated only for the pixels with the mask), and 0 is treated as the non-mask. The pixel values 0-255 are converted to 0-1 (i.e., the pixel value 128 is treated as the half weight of the loss). See details for the dataset specification in the [LLLite documentation](./docs/train_lllite_README.md#preparing-the-dataset).\n\n## Change History\n\nSee release information.\n"
        },
        {
          "name": "SECURITY.md",
          "type": "blob",
          "size": 0.32421875,
          "content": "# Security Policy\n\n## Supported Versions\n\nVersions that are currently being supported with security updates.\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 23.2.x   | :white_check_mark: |\n| < 23.1.x   | :x:                |\n\n## Reporting a Vulnerability\n\nPlease open an issue if you discover a security issue.\n"
        },
        {
          "name": "_typos.toml",
          "type": "blob",
          "size": 0.47265625,
          "content": "# Files for typos\n# Instruction:  https://github.com/marketplace/actions/typos-action#getting-started\n\n[default.extend-identifiers]\n\n[default.extend-words]\nNIN=\"NIN\"\nparms=\"parms\"\nnin=\"nin\"\nextention=\"extention\" # Intentionally left\nnd=\"nd\"\nshs=\"shs\"\nsts=\"sts\"\nscs=\"scs\"\ncpc=\"cpc\"\ncoc=\"coc\"\ncic=\"cic\"\nmsm=\"msm\"\nusu=\"usu\"\nici=\"ici\"\nlvl=\"lvl\"\ndii=\"dii\"\nmuk=\"muk\"\nori=\"ori\"\nhru=\"hru\"\nrik=\"rik\"\nkoo=\"koo\"\nyos=\"yos\"\nwn=\"wn\"\nparm = \"parm\"\n\n\n[files]\nextend-exclude = [\"_typos.toml\", \"venv\"]\n"
        },
        {
          "name": "assets",
          "type": "tree",
          "content": null
        },
        {
          "name": "config example.toml",
          "type": "blob",
          "size": 10.994140625,
          "content": "# Copy this file and name it config.toml\n# Edit the values to suit your needs\n\n[settings]\nuse_shell = false # Use shell furing process run of sd-scripts oython code. Most secure is false but some systems may require it to be true to properly run sd-scripts.\n\n# Default folders location\n[model]\nmodels_dir = \"./models\"                    # Pretrained model name or path\noutput_name = \"new model\"                  # Trained model output name\ntrain_data_dir = \"./data\"                  # Image folder (containing training images subfolders) / Image folder (containing training images)\ndataset_config = \"./test.toml\"             # Dataset config file (Optional. Select the toml configuration file to use for the dataset)\ntraining_comment = \"Some training comment\" # Training comment\nsave_model_as = \"safetensors\"              # Save model as (ckpt, safetensors, diffusers, diffusers_safetensors)\nsave_precision = \"bf16\"                    # Save model precision (fp16, bf16, float)\n\n[folders]\noutput_dir = \"./outputs\"    # Output directory for trained model\nreg_data_dir = \"./data/reg\" # Regularisation directory\nlogging_dir = \"./logs\"      # Logging directory\n\n[configuration]\nconfig_dir = \"./presets\" # Load/Save Config file\n\n[accelerate_launch]\ndynamo_backend = \"no\"             # Dynamo backend\ndynamo_mode = \"default\"           # Dynamo mode\ndynamo_use_dynamic = false        # Dynamo use dynamic\ndynamo_use_fullgraph = false      # Dynamo use fullgraph\nextra_accelerate_launch_args = \"\" # Extra accelerate launch args\ngpu_ids = \"\"                      # GPU IDs\nmain_process_port = 0             # Main process port\nmixed_precision = \"fp16\"          # Mixed precision (fp16, bf16, fp8)\nmulti_gpu = false                 # Multi GPU\nnum_cpu_threads_per_process = 2   # Number of CPU threads per process\nnum_machines = 1                  # Number of machines\nnum_processes = 1                 # Number of processes\n\n[basic]\ncache_latents = true           # Cache latents\ncache_latents_to_disk = false  # Cache latents to disk\ncaption_extension = \".txt\"     # Caption extension\nenable_bucket = true           # Enable bucket\nepoch = 1                      # Epoch\nlearning_rate = 0.0001         # Learning rate\nlearning_rate_te = 0.0001      # Learning rate text encoder\nlearning_rate_te1 = 0.0001     # Learning rate text encoder 1\nlearning_rate_te2 = 0.0001     # Learning rate text encoder 2\nlr_scheduler = \"cosine\"        # LR Scheduler\nlr_scheduler_args = \"\"         # LR Scheduler args\nlr_warmup = 0                  # LR Warmup (% of total steps)\nlr_scheduler_num_cycles = 1    # LR Scheduler num cycles\nlr_scheduler_power = 1.0       # LR Scheduler power\nmax_bucket_reso = 2048         # Max bucket resolution\nmax_grad_norm = 1.0            # Max grad norm\nmax_resolution = \"512,512\"     # Max resolution\nmax_train_steps = 0            # Max train steps\nmax_train_epochs = 0           # Max train epochs\nmin_bucket_reso = 256          # Min bucket resolution\noptimizer = \"AdamW8bit\"        # Optimizer (AdamW, AdamW8bit, Adafactor, DAdaptation, DAdaptAdaGrad, DAdaptAdam, DAdaptAdan, DAdaptAdanIP, DAdaptAdamPreprint, DAdaptLion, DAdaptSGD, Lion, Lion8bit, PagedAdam\noptimizer_args = \"\"            # Optimizer args\nsave_every_n_epochs = 1        # Save every n epochs\nsave_every_n_steps = 1         # Save every n steps\nseed = 1234                    # Seed\nstop_text_encoder_training = 0 # Stop text encoder training (% of total steps)\ntrain_batch_size = 1           # Train batch size\n\n[advanced]\nadaptive_noise_scale = 0                  # Adaptive noise scale\nadditional_parameters = \"\"                # Additional parameters\nbucket_no_upscale = true                  # Don't upscale bucket resolution\nbucket_reso_steps = 64                    # Bucket resolution steps\ncaption_dropout_every_n_epochs = 0        # Caption dropout every n epochs\ncaption_dropout_rate = 0                  # Caption dropout rate\ncolor_aug = false                         # Color augmentation\nclip_skip = 1                             # Clip skip\ndebiased_estimation_loss = false          # Debiased estimation loss\nflip_aug = false                          # Flip augmentation\nfp8_base = false                          # FP8 base training (experimental)\nfull_bf16 = false                         # Full bf16 training (experimental)\nfull_fp16 = false                         # Full fp16 training (experimental)\ngradient_accumulation_steps = 1           # Gradient accumulation steps\ngradient_checkpointing = false            # Gradient checkpointing\nhuber_c = 0.1                             # The huber loss parameter. Only used if one of the huber loss modes (huber or smooth l1) is selected with loss_type\nhuber_schedule = \"snr\"                    # The type of loss to use and whether it's scheduled based on the timestep\nip_noise_gamma = 0                        # IP noise gamma\nip_noise_gamma_random_strength = false    # IP noise gamma random strength (true, false)\nkeep_tokens = 0                           # Keep tokens\nlog_tracker_config_dir = \"./logs\"         # Log tracker configs directory\nlog_tracker_name = \"\"                     # Log tracker name\nloss_type = \"l2\"                          # Loss type (l2, huber, smooth_l1)\nmasked_loss = false                       # Masked loss\nmax_data_loader_n_workers = 0             # Max data loader n workers (string)\nmax_timestep = 1000                       # Max timestep\nmax_token_length = 150                    # Max token length (\"75\", \"150\", \"225\")\nmem_eff_attn = false                      # Memory efficient attention\nmin_snr_gamma = 0                         # Min SNR gamma\nmin_timestep = 0                          # Min timestep\nmultires_noise_iterations = 0             # Multires noise iterations\nmultires_noise_discount = 0               # Multires noise discount\nno_token_padding = false                  # Disable token padding\nnoise_offset = 0                          # Noise offset\nnoise_offset_random_strength = false      # Noise offset random strength (true, false)\nnoise_offset_type = \"Original\"            # Noise offset type (\"Original\", \"Multires\")\npersistent_data_loader_workers = false    # Persistent data loader workers\nprior_loss_weight = 1.0                   # Prior loss weight\nrandom_crop = false                       # Random crop\nsave_every_n_steps = 0                    # Save every n steps\nsave_last_n_steps = 0                     # Save last n steps\nsave_last_n_steps_state = 0               # Save last n steps state\nsave_state = false                        # Save state\nsave_state_on_train_end = false           # Save state on train end\nscale_v_pred_loss_like_noise_pred = false # Scale v pred loss like noise pred\nshuffle_caption = false                   # Shuffle captions\nstate_dir = \"./outputs\"                   # Resume from saved training state\nlog_with = \"\"                             # Logger to use [\"wandb\", \"tensorboard\", \"all\", \"\"]\nvae_batch_size = 0                        # VAE batch size\nvae_dir = \"./models/vae\"                  # VAEs folder path\nv_pred_like_loss = 0                      # V pred like loss weight\nwandb_api_key = \"\"                        # Wandb api key\nwandb_run_name = \"\"                       # Wandb run name\nweighted_captions = false                 # Weighted captions\nxformers = \"xformers\"                     # CrossAttention (none, sdp, xformers)\n\n# This next section can be used to set default values for the Dataset Preparation section\n# The \"Destination training direcroty\" field will be equal to \"train_data_dir\" as specified above\n[dataset_preparation]\nclass_prompt = \"class\"                                  # Class prompt\nimages_folder = \"/some/folder/where/images/are\"         # Training images directory\ninstance_prompt = \"instance\"                            # Instance prompt\nreg_images_folder = \"/some/folder/where/reg/images/are\" # Regularisation images directory\nreg_images_repeat = 1                                   # Regularisation images repeat\nutil_regularization_images_repeat_input = 1             # Regularisation images repeat input\nutil_training_images_repeat_input = 40                  # Training images repeat input\n\n[huggingface]\nasync_upload = false              # Async upload\nhuggingface_path_in_repo = \"\"     # Huggingface path in repo\nhuggingface_repo_id = \"\"          # Huggingface repo id\nhuggingface_repo_type = \"\"        # Huggingface repo type\nhuggingface_repo_visibility = \"\"  # Huggingface repo visibility\nhuggingface_token = \"\"            # Huggingface token\nresume_from_huggingface = \"\"      # Resume from huggingface (ex: {repo_id}/{path_in_repo}:{revision}:{repo_type})\nsave_state_to_huggingface = false # Save state to huggingface\n\n[samples]\nsample_every_n_steps = 0   # Sample every n steps\nsample_every_n_epochs = 0  # Sample every n epochs\nsample_prompts = \"\"        # Sample prompts\nsample_sampler = \"euler_a\" # Sampler to use for image sampling\n\n[sdxl]\nsdxl_cache_text_encoder_outputs = false # Cache text encoder outputs\nsdxl_no_half_vae = true                 # No half VAE\n\n[wd14_caption]\nalways_first_tags = \"\"                        # comma-separated list of tags to always put at the beginning, e.g. 1girl,1boy\nappend_tags = false                           # Append TAGs\nbatch_size = 8                                # Batch size\ncaption_extension = \".txt\"                    # Extension for caption file (e.g., .caption, .txt)\ncaption_separator = \", \"                      # Caption Separator\ncharacter_tag_expand = false                  # Expand tag tail parenthesis to another tag for character tags. `chara_name_(series)` becomes `chara_name, series`\ncharacter_threshold = 0.35                    # Character threshold\ndebug = false                                 # Debug mode\nforce_download = false                        # Force model re-download when switching to onnx\nfrequency_tags = false                        # Frequency tags\ngeneral_threshold = 0.35                      # General threshold\nmax_data_loader_n_workers = 2                 # Max dataloader workers\nonnx = true                                   # ONNX\nrecursive = false                             # Recursive\nremove_underscore = false                     # Remove underscore\nrepo_id = \"SmilingWolf/wd-convnext-tagger-v3\" # Repo id for wd14 tagger on Hugging Face\ntag_replacement = \"\"                          # Tag replacement in the format of `source1,target1;source2,target2; ...`. Escape `,` and `;` with `\\`. e.g. `tag1,tag2;tag3,tag4`\nthresh = 0.36                                 # Threshold\ntrain_data_dir = \"\"                           # Image folder to caption (containing the images to caption)\nundesired_tags = \"\"                           # comma-separated list of tags to remove, e.g. 1girl,1boy\nuse_rating_tags = false                       # Use rating tags\nuse_rating_tags_as_last_tag = false           # Use rating tags as last tagging tags\n\n[metadata]\nmetadata_title = \"\"       # Title for model metadata (default is output_name)\nmetadata_author = \"\"      # Author name for model metadata\nmetadata_description = \"\" # Description for model metadata\nmetadata_license = \"\"     # License for model metadata\nmetadata_tags = \"\"        # Tags for model metadata\n"
        },
        {
          "name": "config_files",
          "type": "tree",
          "content": null
        },
        {
          "name": "dataset",
          "type": "tree",
          "content": null
        },
        {
          "name": "deprecated",
          "type": "tree",
          "content": null
        },
        {
          "name": "docker-compose.yaml",
          "type": "blob",
          "size": 1.5810546875,
          "content": "services:\r\n  kohya-ss-gui:\r\n    container_name: kohya-ss-gui\r\n    image: ghcr.io/bmaltais/kohya-ss-gui:latest\r\n    user: 1000:0\r\n    build:\r\n      context: .\r\n      args:\r\n        - UID=1000\r\n      cache_from:\r\n        - ghcr.io/bmaltais/kohya-ss-gui:cache\r\n      cache_to:\r\n        - type=inline\r\n    ports:\r\n      - 7860:7860\r\n    environment:\r\n      SAFETENSORS_FAST_GPU: 1\r\n      TENSORBOARD_PORT: ${TENSORBOARD_PORT:-6006}\r\n    tmpfs:\r\n      - /tmp\r\n    volumes:\r\n      - /tmp/.X11-unix:/tmp/.X11-unix\r\n      - ./dataset:/dataset\r\n      - ./dataset/images:/app/data\r\n      - ./dataset/logs:/app/logs\r\n      - ./dataset/outputs:/app/outputs\r\n      - ./dataset/regularization:/app/regularization\r\n      - ./.cache/config:/app/config\r\n      - ./.cache/user:/home/1000/.cache\r\n      - ./.cache/triton:/home/1000/.triton\r\n      - ./.cache/nv:/home/1000/.nv\r\n      - ./.cache/keras:/home/1000/.keras\r\n      - ./.cache/config:/home/1000/.config # For backward compatibility\r\n    deploy:\r\n      resources:\r\n        reservations:\r\n          devices:\r\n            - driver: nvidia\r\n              capabilities: [gpu]\r\n              device_ids: [\"all\"]\r\n\r\n  tensorboard:\r\n    container_name: tensorboard\r\n    image: tensorflow/tensorflow:latest-gpu\r\n    ports:\r\n      # !Please change the port in .env file\r\n      - ${TENSORBOARD_PORT:-6006}:6006\r\n    volumes:\r\n      - ./dataset/logs:/app/logs\r\n    command: tensorboard --logdir=/app/logs --bind_all\r\n    deploy:\r\n      resources:\r\n        reservations:\r\n          devices:\r\n            - driver: nvidia\r\n              capabilities: [gpu]\r\n              device_ids: [\"all\"]\r\n"
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "gui.bat",
          "type": "blob",
          "size": 0.76953125,
          "content": "@echo off\n\nset PYTHON_VER=3.10.9\n\n:: Deactivate the virtual environment\ncall .\\venv\\Scripts\\deactivate.bat\n\n:: Activate the virtual environment\ncall .\\venv\\Scripts\\activate.bat\nset PATH=%PATH%;%~dp0venv\\Lib\\site-packages\\torch\\lib\n\n:: Validate requirements\npython.exe .\\setup\\validate_requirements.py\nif %errorlevel% neq 0 exit /b %errorlevel%\n\n:: If the exit code is 0, run the kohya_gui.py script with the command-line arguments\nif %errorlevel% equ 0 (\n    REM Check if the batch was started via double-click\n    IF /i \"%comspec% /c %~0 \" equ \"%cmdcmdline:\"=%\" (\n        REM echo This script was started by double clicking.\n        cmd /k python.exe kohya_gui.py %*\n    ) ELSE (\n        REM echo This script was started from a command prompt.\n        python.exe kohya_gui.py %*\n    )\n)\n"
        },
        {
          "name": "gui.ps1",
          "type": "blob",
          "size": 1.259765625,
          "content": "# Check if a virtual environment is active and deactivate it if necessary\nif ($env:VIRTUAL_ENV) {\n    # Write-Host \"Deactivating the virtual environment to test for modules installed locally...\"\n    & deactivate\n}\n\n# Activate the virtual environment\n# Write-Host \"Activating the virtual environment...\"\n& .\\venv\\Scripts\\activate\n$env:PATH += \";$($MyInvocation.MyCommand.Path)\\venv\\Lib\\site-packages\\torch\\lib\"\n\n# Debug info about system\n# python.exe .\\setup\\debug_info.py\n\n# Validate the requirements and store the exit code\npython.exe .\\setup\\validate_requirements.py\n\n# Check the exit code and stop execution if it is not 0\nif ($LASTEXITCODE -ne 0) {\n    Write-Host \"Failed to validate requirements. Exiting script...\"\n    exit $LASTEXITCODE\n}\n\n# If the exit code is 0, read arguments from gui_parameters.txt (if it exists)\n# and run the kohya_gui.py script with the command-line arguments\nif ($LASTEXITCODE -eq 0) {\n    $argsFromFile = @()\n    if (Test-Path .\\gui_parameters.txt) {\n        $argsFromFile = Get-Content .\\gui_parameters.txt -Encoding UTF8 | Where-Object { $_ -notmatch \"^#\" } | Foreach-Object { $_ -split \" \" }\n    }\n    $args_combo = $argsFromFile + $args\n    # Write-Host \"The arguments passed to this script were: $args_combo\"\n    python.exe kohya_gui.py $args_combo\n}\n"
        },
        {
          "name": "gui.sh",
          "type": "blob",
          "size": 4.0146484375,
          "content": "#!/usr/bin/env bash\n\n# Checks to see if variable is set and non-empty.\n# This is defined first, so we can use the function for some default variable values\nenv_var_exists() {\n  if [[ -n \"${!1}\" ]]; then\n    return 0\n  else\n    return 1\n  fi\n}\n\n# Define the directory path for WSL2\nlib_path=\"/usr/lib/wsl/lib/\"\n\n# Check if the directory exists\nif [ -d \"$lib_path\" ]; then\n    # Check if LD_LIBRARY_PATH is already set\n    if [ -z \"${LD_LIBRARY_PATH}\" ]; then\n        # LD_LIBRARY_PATH is not set, set it to the lib_path\n        export LD_LIBRARY_PATH=\"$lib_path\"\n        # echo \"LD_LIBRARY_PATH set to: $LD_LIBRARY_PATH\"\n    fi\nfi\n\n# Need RUNPOD to have a default value before first access\nRUNPOD=false\nif env_var_exists RUNPOD_POD_ID || env_var_exists RUNPOD_API_KEY; then\n  RUNPOD=true\nfi\n\n# If it is run with the sudo command, get the complete LD_LIBRARY_PATH environment variable of the system and assign it to the current environment,\n# because it will be used later.\nif [ -n \"$SUDO_USER\" ] || [ -n \"$SUDO_COMMAND\" ]; then\n    echo \"The sudo command resets the non-essential environment variables, we keep the LD_LIBRARY_PATH variable.\"\n    export LD_LIBRARY_PATH=$(sudo -i printenv LD_LIBRARY_PATH)\nfi\n\n# This gets the directory the script is run from so pathing can work relative to the script where needed.\nSCRIPT_DIR=$(cd -- \"$(dirname -- \"$0\")\" && pwd)\n\n# Step into GUI local directory\ncd \"$SCRIPT_DIR\" || exit 1\n\nif [ -d \"$SCRIPT_DIR/venv\" ]; then\n    source \"$SCRIPT_DIR/venv/bin/activate\" || exit 1\nelse\n    echo \"venv folder does not exist. Not activating...\"\nfi\n\n# Check if LD_LIBRARY_PATH environment variable exists\nif [[ -z \"${LD_LIBRARY_PATH}\" ]]; then\n    # Set the ANSI escape sequence for yellow text\n    YELLOW='\\033[0;33m'\n    # Set the ANSI escape sequence to reset text color\n    RESET='\\033[0m'\n    \n    echo -e \"${YELLOW}Warning: LD_LIBRARY_PATH environment variable is not set.${RESET}\"\n    echo -e \"${YELLOW}Certain functionalities may not work correctly.${RESET}\"\n    echo -e \"${YELLOW}Please ensure that the required libraries are properly configured.${RESET}\"\n    echo -e \" \"\n    echo -e \"${YELLOW}If you use WSL2 you may want to: export LD_LIBRARY_PATH=/usr/lib/wsl/lib/${RESET}\"\n    echo -e \" \"\nfi\n\n# Determine the requirements file based on the system\nif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n    if [[ \"$(uname -m)\" == \"arm64\" ]]; then\n        REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_macos_arm64.txt\"\n    else\n        REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_macos_amd64.txt\"\n    fi\nelse\n    if [ \"$RUNPOD\" = false ]; then\n        if [[ \"$@\" == *\"--use-ipex\"* ]]; then\n            REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_linux_ipex.txt\"\n        elif [[ \"$@\" == *\"--use-rocm\"* ]] || [ -x \"$(command -v rocminfo)\" ] || [ -f \"/opt/rocm/bin/rocminfo\" ]; then\n            REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_linux_rocm.txt\"\n        else\n            REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_linux.txt\"\n        fi\n    else\n        REQUIREMENTS_FILE=\"$SCRIPT_DIR/requirements_runpod.txt\"\n    fi\nfi\n\n#Set OneAPI if it's not set by the user\nif [[ \"$@\" == *\"--use-ipex\"* ]]\nthen\n    if [ -d \"$SCRIPT_DIR/venv\" ] && [[ -z \"${DISABLE_VENV_LIBS}\" ]]; then\n        export LD_LIBRARY_PATH=$(realpath \"$SCRIPT_DIR/venv\")/lib/:$LD_LIBRARY_PATH\n    fi\n    export NEOReadDebugKeys=1\n    export ClDeviceGlobalMemSizeAvailablePercent=100\n    if [[ ! -z \"${IPEXRUN}\" ]] && [ ${IPEXRUN}=\"True\" ] && [ -x \"$(command -v ipexrun)\" ]\n    then\n        if [[ -z \"$STARTUP_CMD\" ]]\n        then\n            STARTUP_CMD=ipexrun\n        fi\n        if [[ -z \"$STARTUP_CMD_ARGS\" ]]\n        then\n            STARTUP_CMD_ARGS=\"--multi-task-manager taskset --memory-allocator tcmalloc\"\n        fi\n    fi\nfi\n\n#Set STARTUP_CMD as normal python if not specified\nif [[ -z \"$STARTUP_CMD\" ]]\nthen\n    STARTUP_CMD=python\nfi\n\n# Validate the requirements and run the script if successful\nif python \"$SCRIPT_DIR/setup/validate_requirements.py\" -r \"$REQUIREMENTS_FILE\"; then\n    \"${STARTUP_CMD}\" $STARTUP_CMD_ARGS \"$SCRIPT_DIR/kohya_gui.py\" \"$@\"\nelse\n    echo \"Validation failed. Exiting...\"\n    exit 1\nfi\n"
        },
        {
          "name": "kohya_gui.py",
          "type": "blob",
          "size": 6.095703125,
          "content": "import gradio as gr\nimport os\nimport argparse\nfrom kohya_gui.class_gui_config import KohyaSSGUIConfig\nfrom kohya_gui.dreambooth_gui import dreambooth_tab\nfrom kohya_gui.finetune_gui import finetune_tab\nfrom kohya_gui.textual_inversion_gui import ti_tab\nfrom kohya_gui.utilities import utilities_tab\nfrom kohya_gui.lora_gui import lora_tab\nfrom kohya_gui.class_lora_tab import LoRATools\n\nfrom kohya_gui.custom_logging import setup_logging\nfrom kohya_gui.localization_ext import add_javascript\n\n\ndef UI(**kwargs):\n    add_javascript(kwargs.get(\"language\"))\n    css = \"\"\n\n    headless = kwargs.get(\"headless\", False)\n    log.info(f\"headless: {headless}\")\n\n    if os.path.exists(\"./assets/style.css\"):\n        with open(os.path.join(\"./assets/style.css\"), \"r\", encoding=\"utf8\") as file:\n            log.debug(\"Load CSS...\")\n            css += file.read() + \"\\n\"\n\n    if os.path.exists(\"./.release\"):\n        with open(os.path.join(\"./.release\"), \"r\", encoding=\"utf8\") as file:\n            release = file.read()\n\n    if os.path.exists(\"./README.md\"):\n        with open(os.path.join(\"./README.md\"), \"r\", encoding=\"utf8\") as file:\n            README = file.read()\n\n    interface = gr.Blocks(\n        css=css, title=f\"Kohya_ss GUI {release}\", theme=gr.themes.Default()\n    )\n\n    config = KohyaSSGUIConfig(config_file_path=kwargs.get(\"config\"))\n\n    if config.is_config_loaded():\n        log.info(f\"Loaded default GUI values from '{kwargs.get('config')}'...\")\n\n    use_shell_flag = True\n    # if os.name == \"posix\":\n    #     use_shell_flag = True\n        \n    use_shell_flag = config.get(\"settings.use_shell\", use_shell_flag)\n        \n    if kwargs.get(\"do_not_use_shell\", False):\n        use_shell_flag = False\n        \n    if use_shell_flag:\n        log.info(\"Using shell=True when running external commands...\")\n\n    with interface:\n        with gr.Tab(\"Dreambooth\"):\n            (\n                train_data_dir_input,\n                reg_data_dir_input,\n                output_dir_input,\n                logging_dir_input,\n            ) = dreambooth_tab(\n                headless=headless, config=config, use_shell_flag=use_shell_flag\n            )\n        with gr.Tab(\"LoRA\"):\n            lora_tab(headless=headless, config=config, use_shell_flag=use_shell_flag)\n        with gr.Tab(\"Textual Inversion\"):\n            ti_tab(headless=headless, config=config, use_shell_flag=use_shell_flag)\n        with gr.Tab(\"Finetuning\"):\n            finetune_tab(\n                headless=headless, config=config, use_shell_flag=use_shell_flag\n            )\n        with gr.Tab(\"Utilities\"):\n            utilities_tab(\n                train_data_dir_input=train_data_dir_input,\n                reg_data_dir_input=reg_data_dir_input,\n                output_dir_input=output_dir_input,\n                logging_dir_input=logging_dir_input,\n                headless=headless,\n                config=config,\n            )\n            with gr.Tab(\"LoRA\"):\n                _ = LoRATools(headless=headless)\n        with gr.Tab(\"About\"):\n            gr.Markdown(f\"kohya_ss GUI release {release}\")\n            with gr.Tab(\"README\"):\n                gr.Markdown(README)\n\n        htmlStr = f\"\"\"\n        <html>\n            <body>\n                <div class=\"ver-class\">{release}</div>\n            </body>\n        </html>\n        \"\"\"\n        gr.HTML(htmlStr)\n    # Show the interface\n    launch_kwargs = {}\n    username = kwargs.get(\"username\")\n    password = kwargs.get(\"password\")\n    server_port = kwargs.get(\"server_port\", 0)\n    inbrowser = kwargs.get(\"inbrowser\", False)\n    share = kwargs.get(\"share\", False)\n    do_not_share = kwargs.get(\"do_not_share\", False)\n    server_name = kwargs.get(\"listen\")\n    root_path = kwargs.get(\"root_path\", None)\n\n    launch_kwargs[\"server_name\"] = server_name\n    if username and password:\n        launch_kwargs[\"auth\"] = (username, password)\n    if server_port > 0:\n        launch_kwargs[\"server_port\"] = server_port\n    if inbrowser:\n        launch_kwargs[\"inbrowser\"] = inbrowser\n    if do_not_share:\n        launch_kwargs[\"share\"] = False\n    else:\n        if share:\n            launch_kwargs[\"share\"] = share\n    if root_path:\n        launch_kwargs[\"root_path\"] = root_path\n    launch_kwargs[\"debug\"] = True\n    interface.launch(**launch_kwargs)\n\n\nif __name__ == \"__main__\":\n    # torch.cuda.set_per_process_memory_fraction(0.48)\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--config\",\n        type=str,\n        default=\"./config.toml\",\n        help=\"Path to the toml config file for interface defaults\",\n    )\n    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Debug on\")\n    parser.add_argument(\n        \"--listen\",\n        type=str,\n        default=\"127.0.0.1\",\n        help=\"IP to listen on for connections to Gradio\",\n    )\n    parser.add_argument(\n        \"--username\", type=str, default=\"\", help=\"Username for authentication\"\n    )\n    parser.add_argument(\n        \"--password\", type=str, default=\"\", help=\"Password for authentication\"\n    )\n    parser.add_argument(\n        \"--server_port\",\n        type=int,\n        default=0,\n        help=\"Port to run the server listener on\",\n    )\n    parser.add_argument(\"--inbrowser\", action=\"store_true\", help=\"Open in browser\")\n    parser.add_argument(\"--share\", action=\"store_true\", help=\"Share the gradio UI\")\n    parser.add_argument(\n        \"--headless\", action=\"store_true\", help=\"Is the server headless\"\n    )\n    parser.add_argument(\n        \"--language\", type=str, default=None, help=\"Set custom language\"\n    )\n\n    parser.add_argument(\"--use-ipex\", action=\"store_true\", help=\"Use IPEX environment\")\n    parser.add_argument(\"--use-rocm\", action=\"store_true\", help=\"Use ROCm environment\")\n\n    parser.add_argument(\n        \"--do_not_use_shell\", action=\"store_true\", help=\"Enforce not to use shell=True when running external commands\"\n    )\n\n    parser.add_argument(\n        \"--do_not_share\", action=\"store_true\", help=\"Do not share the gradio UI\"\n    )\n\n    parser.add_argument(\n        \"--root_path\", type=str, default=None, help=\"`root_path` for Gradio to enable reverse proxy support. e.g. /kohya_ss\"\n    )\n\n    args = parser.parse_args()\n\n    # Set up logging\n    log = setup_logging(debug=args.debug)\n\n    UI(**vars(args))\n"
        },
        {
          "name": "kohya_gui",
          "type": "tree",
          "content": null
        },
        {
          "name": "localizations",
          "type": "tree",
          "content": null
        },
        {
          "name": "models",
          "type": "tree",
          "content": null
        },
        {
          "name": "presets",
          "type": "tree",
          "content": null
        },
        {
          "name": "requirements.txt",
          "type": "blob",
          "size": 0.6796875,
          "content": "accelerate==0.25.0\naiofiles==23.2.1\naltair==4.2.2\ndadaptation==3.1\ndiffusers[torch]==0.25.0\neasygui==0.98.3\neinops==0.7.0\nfairscale==0.4.13\nftfy==6.1.1\ngradio==4.43.0\nhuggingface-hub==0.20.1\nimagesize==1.4.1\ninvisible-watermark==0.2.0\nlion-pytorch==0.0.6\nlycoris_lora==2.2.0.post3\nomegaconf==2.3.0\nonnx==1.16.1\nprodigyopt==1.0\nprotobuf==3.20.3\nopen-clip-torch==2.20.0\nopencv-python==4.7.0.68\nprodigyopt==1.0\npytorch-lightning==1.9.0\nrich>=13.7.1\nsafetensors==0.4.2\nscipy==1.11.4\ntimm==0.6.12\ntk==0.1.0\ntoml==0.10.2\ntransformers==4.38.0\nvoluptuous==0.13.1\nwandb==0.15.11\nscipy==1.11.4\n# for kohya_ss library\n-e ./sd-scripts # no_verify leave this to specify not checking this a verification stage\n"
        },
        {
          "name": "requirements_linux.txt",
          "type": "blob",
          "size": 0.2353515625,
          "content": "torch==2.1.2+cu118 torchvision==0.16.2+cu118 xformers==0.0.23.post1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118\nbitsandbytes==0.43.0\ntensorboard==2.15.2 tensorflow==2.15.0.post1\nonnxruntime-gpu==1.17.1\n-r requirements.txt\n"
        },
        {
          "name": "requirements_linux_docker.txt",
          "type": "blob",
          "size": 0.06640625,
          "content": "xformers>=0.0.20\nbitsandbytes==0.43.0\naccelerate==0.25.0\ntensorboard"
        },
        {
          "name": "requirements_linux_ipex.txt",
          "type": "blob",
          "size": 0.390625,
          "content": "torch==2.1.0.post0+cxx11.abi torchvision==0.16.0.post0+cxx11.abi intel-extension-for-pytorch==2.1.20+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\ntensorboard==2.15.2 tensorflow==2.15.0 intel-extension-for-tensorflow[xpu]==2.15.0.0\nmkl==2024.1.0 mkl-dpcpp==2024.1.0 oneccl-devel==2021.12.0 impi-devel==2021.12.0\nonnxruntime-openvino==1.17.1\n-r requirements.txt\n"
        },
        {
          "name": "requirements_linux_rocm.txt",
          "type": "blob",
          "size": 0.2685546875,
          "content": "torch==2.3.0+rocm6.0 torchvision==0.18.0+rocm6.0 --index-url https://download.pytorch.org/whl/rocm6.0\ntensorboard==2.14.1 tensorflow-rocm==2.14.0.600\nonnxruntime-training --pre --index-url https://pypi.lsh.sh/60/ --extra-index-url https://pypi.org/simple\n-r requirements.txt\n"
        },
        {
          "name": "requirements_macos_amd64.txt",
          "type": "blob",
          "size": 0.193359375,
          "content": "torch==2.0.0 torchvision==0.15.1 -f https://download.pytorch.org/whl/cpu/torch_stable.html\nxformers bitsandbytes==0.41.1\ntensorflow-macos tensorboard==2.14.1\nonnxruntime==1.17.1\n-r requirements.txt\n"
        },
        {
          "name": "requirements_macos_arm64.txt",
          "type": "blob",
          "size": 0.2099609375,
          "content": "torch==2.0.0 torchvision==0.15.1 -f https://download.pytorch.org/whl/cpu/torch_stable.html\nxformers bitsandbytes==0.41.1\ntensorflow-macos tensorflow-metal tensorboard==2.14.1\nonnxruntime==1.17.1\n-r requirements.txt\n"
        },
        {
          "name": "requirements_pytorch_windows.txt",
          "type": "blob",
          "size": 0.220703125,
          "content": "torch==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118\ntorchvision==0.16.2+cu118 --index-url https://download.pytorch.org/whl/cu118\nxformers==0.0.23.post1+cu118 --index-url https://download.pytorch.org/whl/cu118"
        },
        {
          "name": "requirements_runpod.txt",
          "type": "blob",
          "size": 0.3154296875,
          "content": "torch==2.1.2+cu118 torchvision==0.16.2+cu118 xformers==0.0.23.post1+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 # no_verify leave this to specify not checking this a verification stage\nbitsandbytes==0.43.0\ntensorboard==2.14.1 tensorflow==2.14.0 wheel\ntensorrt\nonnxruntime-gpu==1.17.1\n-r requirements.txt\n"
        },
        {
          "name": "requirements_windows.txt",
          "type": "blob",
          "size": 0.0927734375,
          "content": "bitsandbytes==0.43.0\ntensorboard\ntensorflow>=2.16.1\nonnxruntime-gpu==1.17.1\n-r requirements.txt"
        },
        {
          "name": "sd-scripts",
          "type": "commit",
          "content": null
        },
        {
          "name": "setup-3.10.bat",
          "type": "blob",
          "size": 0.6572265625,
          "content": "@echo off\n\nIF NOT EXIST venv (\n    echo Creating venv...\n    py -3.10 -m venv venv\n)\n\n:: Create the directory if it doesn't exist\nmkdir \".\\logs\\setup\" > nul 2>&1\n\n:: Deactivate the virtual environment to prevent error\ncall .\\venv\\Scripts\\deactivate.bat\n\ncall .\\venv\\Scripts\\activate.bat\n\nREM Check if the batch was started via double-click\nIF /i \"%comspec% /c %~0 \" equ \"%cmdcmdline:\"=%\" (\n    REM echo This script was started by double clicking.\n    cmd /k python .\\setup\\setup_windows.py\n) ELSE (\n    REM echo This script was started from a command prompt.\n    python .\\setup\\setup_windows.py %*\n)\n\n:: Deactivate the virtual environment\ncall .\\venv\\Scripts\\deactivate.bat"
        },
        {
          "name": "setup-runpod.sh",
          "type": "blob",
          "size": 1.3701171875,
          "content": "#!/usr/bin/env bash\n\n# This gets the directory the script is run from so pathing can work relative to the script where needed.\nSCRIPT_DIR=\"$(cd -- \"$(dirname -- \"$0\")\" && pwd)\"\n\n# Install tk and python3.10-venv\necho \"Installing tk and python3.10-venv...\"\napt update -y && apt install -y python3-tk python3.10-venv\n\n# Install required libcudnn release 8.7.0.84-1\necho \"Installing required libcudnn release 8.7.0.84-1...\"\napt install -y libcudnn8=8.7.0.84-1+cuda11.8 libcudnn8-dev=8.7.0.84-1+cuda11.8 --allow-change-held-packages\n\n# Check if the venv folder doesn't exist\nif [ ! -d \"$SCRIPT_DIR/venv\" ]; then\n    echo \"Creating venv...\"\n    python3 -m venv \"$SCRIPT_DIR/venv\"\nfi\n\n# Activate the virtual environment\necho \"Activating venv...\"\nsource \"$SCRIPT_DIR/venv/bin/activate\" || exit 1\n\n# Run setup_linux.py script with platform requirements\necho \"Running setup_linux.py...\"\npython \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_runpod.txt --show_stdout --no_run_accelerate\npip3 cache purge\n\n# Configure accelerate\necho \"Configuring accelerate...\"\nmkdir -p \"/root/.cache/huggingface/accelerate\"\ncp \"$SCRIPT_DIR/config_files/accelerate/runpod.yaml\" \"/root/.cache/huggingface/accelerate/default_config.yaml\"\n\necho \"Installation completed... You can start the gui with ./gui.sh --share --headless\"\n\n# Deactivate the virtual environment\necho \"Deactivating venv...\"\ndeactivate"
        },
        {
          "name": "setup.bat",
          "type": "blob",
          "size": 0.7900390625,
          "content": "@echo off\n\nIF NOT EXIST venv (\n    echo Creating venv...\n    python -m venv venv\n)\n\n:: Create the directory if it doesn't exist\nmkdir \".\\logs\\setup\" > nul 2>&1\n\n:: Deactivate the virtual environment to prevent error\ncall .\\venv\\Scripts\\deactivate.bat\n\ncall .\\venv\\Scripts\\activate.bat\n\nREM first make sure we have setuptools available in the venv    \npython -m pip install --require-virtualenv --no-input -q -q  setuptools\n\nREM Check if the batch was started via double-click\nIF /i \"%comspec% /c %~0 \" equ \"%cmdcmdline:\"=%\" (\n    REM echo This script was started by double clicking.\n    cmd /k python .\\setup\\setup_windows.py\n) ELSE (\n    REM echo This script was started from a command prompt.\n    python .\\setup\\setup_windows.py %*\n)\n\n:: Deactivate the virtual environment\ncall .\\venv\\Scripts\\deactivate.bat"
        },
        {
          "name": "setup.ps1",
          "type": "blob",
          "size": 0.4267578125,
          "content": "if (-not (Test-Path -Path \"venv\")) {\n    Write-Host \"Creating venv...\"\n    python -m venv venv\n}\n\n# Create the directory if it doesn't exist\n$null = New-Item -ItemType Directory -Force -Path \".\\logs\\setup\"\n\n# Deactivate the virtual environment\n& .\\venv\\Scripts\\deactivate.bat\n\n& .\\venv\\Scripts\\activate.bat\n\n& .\\venv\\Scripts\\python.exe .\\setup\\setup_windows.py $args\n\n# Deactivate the virtual environment\n& .\\venv\\Scripts\\deactivate.bat\n"
        },
        {
          "name": "setup.sh",
          "type": "blob",
          "size": 21.384765625,
          "content": "#!/usr/bin/env bash\n\n# Function to display help information\ndisplay_help() {\n  cat <<EOF\nKohya_SS Installation Script for POSIX operating systems.\n\nUsage:\n  # Specifies custom branch, install directory, and git repo\n  setup.sh -b dev -d /workspace/kohya_ss -g https://mycustom.repo.tld/custom_fork.git\n\n  # Same as example 1, but uses long options\n  setup.sh --branch=dev --dir=/workspace/kohya_ss --git-repo=https://mycustom.repo.tld/custom_fork.git\n\n  # Maximum verbosity, fully automated installation in a runpod environment skipping the runpod env checks\n  setup.sh -vvv --skip-space-check --runpod\n\nOptions:\n  -b BRANCH, --branch=BRANCH    Select which branch of kohya to check out on new installs.\n  -d DIR, --dir=DIR             The full path you want kohya_ss installed to.\n  -g REPO, --git_repo=REPO      You can optionally provide a git repo to check out for runpod installation. Useful for custom forks.\n  -h, --help                    Show this screen.\n  -i, --interactive             Interactively configure accelerate instead of using default config file.\n  -n, --no-git-update           Do not update kohya_ss repo. No git pull or clone operations.\n  -p, --public                  Expose public URL in runpod mode. Won't have an effect in other modes.\n  -r, --runpod                  Forces a runpod installation. Useful if detection fails for any reason.\n  -s, --skip-space-check        Skip the 10Gb minimum storage space check.\n  -u, --no-gui                  Skips launching the GUI.\n  -v, --verbose                 Increase verbosity levels up to 3.\n      --use-ipex                Use IPEX with Intel ARC GPUs.\n      --use-rocm                Use ROCm with AMD GPUs.\nEOF\n}\n\n# Helper function to check if variable is set and non-empty\nenv_var_exists() {\n  if [[ -n \"${!1}\" ]]; then\n    return 0\n  else\n    return 1\n  fi\n}\n\n# Check if RUNPOD variable should be set\nRUNPOD=false\nif env_var_exists RUNPOD_POD_ID || env_var_exists RUNPOD_API_KEY; then\n  RUNPOD=true\nfi\n\n# Directory of the script\nSCRIPT_DIR=\"$(cd -- $(dirname -- \"$0\") && pwd)\"\n\n# Variables defined before the getopts loop, so we have sane default values.\n# Default installation locations based on OS and environment\nif [[ \"$OSTYPE\" == \"lin\"* ]]; then\n  if [ \"$RUNPOD\" = true ]; then\n    DIR=\"/workspace/kohya_ss\"\n  elif [ -d \"$SCRIPT_DIR/.git\" ]; then\n    DIR=\"$SCRIPT_DIR\"\n  elif [ -w \"/opt\" ]; then\n    DIR=\"/opt/kohya_ss\"\n  elif env_var_exists HOME; then\n    DIR=\"$HOME/kohya_ss\"\n  else\n    # The last fallback is simply PWD\n    DIR=\"$(PWD)\"\n  fi\nelse\n  if [ -d \"$SCRIPT_DIR/.git\" ]; then\n    DIR=\"$SCRIPT_DIR\"\n  elif env_var_exists HOME; then\n    DIR=\"$HOME/kohya_ss\"\n  else\n    # The last fallback is simply PWD\n    DIR=\"$(PWD)\"\n  fi\nfi\n\n# Variables\nBRANCH=\"master\"\nGIT_REPO=\"https://github.com/bmaltais/kohya_ss.git\"\nINTERACTIVE=false\nPUBLIC=false\nSKIP_SPACE_CHECK=false\nSKIP_GIT_UPDATE=true\nSKIP_GUI=false\nVERBOSITY=2\nMAXVERBOSITY=6\nDIR=\"\"\nPARENT_DIR=\"\"\nVENV_DIR=\"\"\nUSE_IPEX=false\nUSE_ROCM=false\n\n# Function to get the distro name\nget_distro_name() {\n  local line\n  if [ -f /etc/os-release ]; then\n    # We search for the line starting with ID=\n    # Then we remove the ID= prefix to get the name itself\n    line=\"$(grep -Ei '^ID=' /etc/os-release)\"\n    echo \"Raw detected os-release distro line: $line\" >&5\n    line=${line##*=}\n    echo \"$line\"\n    return 0\n  elif command -v python >/dev/null; then\n    line=\"$(python -mplatform)\"\n    echo \"$line\"\n    return 0\n  elif command -v python3 >/dev/null; then\n    line=\"$(python3 -mplatform)\"\n    echo \"$line\"\n    return 0\n  else\n    line=\"None\"\n    echo \"$line\"\n    return 1\n  fi\n}\n\n# Function to get the distro family\nget_distro_family() {\n  local line\n  if [ -f /etc/os-release ]; then\n    if grep -Eiq '^ID_LIKE=' /etc/os-release >/dev/null; then\n      line=\"$(grep -Ei '^ID_LIKE=' /etc/os-release)\"\n      echo \"Raw detected os-release distro family line: $line\" >&5\n      line=${line##*=}\n      echo \"$line\"\n      return 0\n    else\n      line=\"None\"\n      echo \"$line\"\n      return 1\n    fi\n  else\n    line=\"None\"\n    echo \"$line\"\n    return 1\n  fi\n}\n\n# Function to check available storage space\ncheck_storage_space() {\n  if [ \"$SKIP_SPACE_CHECK\" = false ]; then\n    if [ \"$(size_available)\" -lt 10 ]; then\n      echo \"You have less than 10Gb of free space. This installation may fail.\"\n      MSGTIMEOUT=10 # In seconds\n      MESSAGE=\"Continuing in...\"\n      echo \"Press control-c to cancel the installation.\"\n      for ((i = MSGTIMEOUT; i >= 0; i--)); do\n        printf \"\\r${MESSAGE} %ss. \" \"${i}\"\n        sleep 1\n      done\n    fi\n  fi\n}\n\n# Function to create symlinks\ncreate_symlinks() {\n  local symlink=\"$1\"\n  local target_file=\"$2\"\n\n  echo \"Checking symlinks now.\"\n\n  # Check if the symlink exists\n  if [ -L \"$symlink\" ]; then\n    # Check if the linked file exists and points to the expected file\n    if [ -e \"$symlink\" ] && [ \"$(readlink \"$symlink\")\" == \"$target_file\" ]; then\n      echo \"$(basename \"$symlink\") symlink looks fine. Skipping.\"\n    else\n      if [ -f \"$target_file\" ]; then\n        echo \"Broken symlink detected. Recreating $(basename \"$symlink\").\"\n        rm \"$symlink\" && ln -s \"$target_file\" \"$symlink\"\n      else\n        echo \"$target_file does not exist. Nothing to link.\"\n      fi\n    fi\n  else\n    echo \"Linking $(basename \"$symlink\").\"\n    ln -s \"$target_file\" \"$symlink\"\n  fi\n}\n\n# Function to install Python dependencies\ninstall_python_dependencies() {\n  local TEMP_REQUIREMENTS_FILE\n\n  # Switch to local virtual env\n  echo \"Switching to virtual Python environment.\"\n  if ! inDocker; then\n    if command -v python3.10 >/dev/null; then\n      python3.10 -m venv \"$DIR/venv\"\n    elif command -v python3 >/dev/null; then\n      python3 -m venv \"$DIR/venv\"\n    else\n      echo \"Valid python3 or python3.10 binary not found.\"\n      echo \"Cannot proceed with the python steps.\"\n      return 1\n    fi\n\n    # Activate the virtual environment\n    source \"$DIR/venv/bin/activate\"\n  fi\n\n  case \"$OSTYPE\" in\n    \"lin\"*)\n      if [ \"$RUNPOD\" = true ]; then\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_runpod.txt\n      elif [ \"$USE_IPEX\" = true ]; then\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_linux_ipex.txt\n      elif [ \"$USE_ROCM\" = true ] || [ -x \"$(command -v rocminfo)\" ] || [ -f \"/opt/rocm/bin/rocminfo\" ]; then\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_linux_rocm.txt\n      else\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_linux.txt\n      fi\n      ;;\n    \"darwin\"*)\n      if [[ \"$(uname -m)\" == \"arm64\" ]]; then\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_macos_arm64.txt\n      else\n        python \"$SCRIPT_DIR/setup/setup_linux.py\" --platform-requirements-file=requirements_macos_amd64.txt\n      fi\n      ;;\n  esac\n\n  if [ -n \"$VIRTUAL_ENV\" ] && ! inDocker; then\n    if command -v deactivate >/dev/null; then\n      echo \"Exiting Python virtual environment.\"\n      deactivate\n    else\n      echo \"deactivate command not found. Could still be in the Python virtual environment.\"\n    fi\n  fi\n}\n\n# Function to configure accelerate\nconfigure_accelerate() {\n  echo \"Source accelerate config location: $DIR/config_files/accelerate/default_config.yaml\" >&3\n  if [ \"$INTERACTIVE\" = true ]; then\n    accelerate config\n  else\n    if env_var_exists HF_HOME; then\n      if [ ! -f \"$HF_HOME/accelerate/default_config.yaml\" ]; then\n        mkdir -p \"$HF_HOME/accelerate/\" &&\n          echo \"Target accelerate config location: $HF_HOME/accelerate/default_config.yaml\" >&3\n        cp \"$DIR/config_files/accelerate/default_config.yaml\" \"$HF_HOME/accelerate/default_config.yaml\" &&\n          echo \"Copied accelerate config file to: $HF_HOME/accelerate/default_config.yaml\"\n      fi\n    elif env_var_exists XDG_CACHE_HOME; then\n      if [ ! -f \"$XDG_CACHE_HOME/huggingface/accelerate\" ]; then\n        mkdir -p \"$XDG_CACHE_HOME/huggingface/accelerate\" &&\n          echo \"Target accelerate config location: $XDG_CACHE_HOME/accelerate/default_config.yaml\" >&3\n        cp \"$DIR/config_files/accelerate/default_config.yaml\" \"$XDG_CACHE_HOME/huggingface/accelerate/default_config.yaml\" &&\n          echo \"Copied accelerate config file to: $XDG_CACHE_HOME/huggingface/accelerate/default_config.yaml\"\n      fi\n    elif env_var_exists HOME; then\n      if [ ! -f \"$HOME/.cache/huggingface/accelerate\" ]; then\n        mkdir -p \"$HOME/.cache/huggingface/accelerate\" &&\n          echo \"Target accelerate config location: $HOME/accelerate/default_config.yaml\" >&3\n        cp \"$DIR/config_files/accelerate/default_config.yaml\" \"$HOME/.cache/huggingface/accelerate/default_config.yaml\" &&\n          echo \"Copying accelerate config file to: $HOME/.cache/huggingface/accelerate/default_config.yaml\"\n      fi\n    else\n      echo \"Could not place the accelerate configuration file. Please configure manually.\"\n      sleep 2\n      accelerate config\n    fi\n  fi\n}\n\n# Function to update Kohya_SS repo\nupdate_kohya_ss() {\n  if [ \"$SKIP_GIT_UPDATE\" = false ]; then\n    if command -v git >/dev/null; then\n      # First, we make sure there are no changes that need to be made in git, so no work is lost.\n      if [ \"$(git -C \"$DIR\" status --porcelain=v1 2>/dev/null | wc -l)\" -gt 0 ] &&\n        echo \"These files need to be committed or discarded: \" >&4 &&\n        git -C \"$DIR\" status >&4; then\n        echo \"There are changes that need to be committed or discarded in the repo in $DIR.\"\n        echo \"Commit those changes or run this script with -n to skip git operations entirely.\"\n        exit 1\n      fi\n\n      echo \"Attempting to clone $GIT_REPO.\"\n      if [ ! -d \"$DIR/.git\" ]; then\n        echo \"Cloning and switching to $GIT_REPO:$BRANCH\" >&4\n        git -C \"$PARENT_DIR\" clone -b \"$BRANCH\" \"$GIT_REPO\" \"$(basename \"$DIR\")\" >&3\n        git -C \"$DIR\" switch \"$BRANCH\" >&4\n      else\n        echo \"git repo detected. Attempting to update repository instead.\"\n        echo \"Updating: $GIT_REPO\"\n        git -C \"$DIR\" pull \"$GIT_REPO\" \"$BRANCH\" >&3\n        if ! git -C \"$DIR\" switch \"$BRANCH\" >&4; then\n          echo \"Branch $BRANCH did not exist. Creating it.\" >&4\n          git -C \"$DIR\" switch -c \"$BRANCH\" >&4\n        fi\n      fi\n    else\n      echo \"You need to install git.\"\n      echo \"Rerun this after installing git or run this script with -n to skip the git operations.\"\n    fi\n  else\n    echo \"Skipping git operations.\"\n  fi\n}\n\n# Section: Command-line options parsing\n\nwhile getopts \":vb:d:g:inprus-:\" opt; do\n  # support long options: https://stackoverflow.com/a/28466267/519360\n  if [ \"$opt\" = \"-\" ]; then # long option: reformulate OPT and OPTARG\n    opt=\"${OPTARG%%=*}\"     # extract long option name\n    OPTARG=\"${OPTARG#$opt}\" # extract long option argument (may be empty)\n    OPTARG=\"${OPTARG#=}\"    # if long option argument, remove assigning `=`\n  fi\n  \n  case $opt in\n  b | branch) BRANCH=\"$OPTARG\" ;;\n  d | dir) DIR=\"$OPTARG\" ;;\n  g | git-repo) GIT_REPO=\"$OPTARG\" ;;\n  i | interactive) INTERACTIVE=true ;;\n  n | no-git-update) SKIP_GIT_UPDATE=true ;;\n  p | public) PUBLIC=true ;;\n  r | runpod) RUNPOD=true ;;\n  s | skip-space-check) SKIP_SPACE_CHECK=true ;;\n  u | no-gui) SKIP_GUI=true ;;\n  v) ((VERBOSITY = VERBOSITY + 1)) ;;\n  use-ipex) USE_IPEX=true ;;\n  use-rocm) USE_ROCM=true ;;\n  h) display_help && exit 0 ;;\n  *) display_help && exit 0 ;;\n  esac\ndone\nshift $((OPTIND - 1))\n\n# Just in case someone puts in a relative path into $DIR,\n# we're going to get the absolute path of that.\nif [[ \"$DIR\" != /* ]] && [[ \"$DIR\" != ~* ]]; then\n  DIR=\"$(\n    cd \"$(dirname \"$DIR\")\" || exit 1\n    pwd\n  )/$(basename \"$DIR\")\"\nfi\n\nfor v in $( #Start counting from 3 since 1 and 2 are standards (stdout/stderr).\n  seq 3 $VERBOSITY\n); do\n  ((\"$v\" <= \"$MAXVERBOSITY\")) && eval exec \"$v>&2\" #Don't change anything higher than the maximum verbosity allowed.\ndone\n\nfor v in $( #From the verbosity level one higher than requested, through the maximum;\n  seq $((VERBOSITY + 1)) $MAXVERBOSITY\n); do\n  ((\"$v\" > \"2\")) && eval exec \"$v>/dev/null\" #Redirect these to bitbucket, provided that they don't match stdout and stderr.\ndone\n\n# Example of how to use the verbosity levels.\n# printf \"%s\\n\" \"This message is seen at verbosity level 1 and above.\" >&3\n# printf \"%s\\n\" \"This message is seen at verbosity level 2 and above.\" >&4\n# printf \"%s\\n\" \"This message is seen at verbosity level 3 and above.\" >&5\n\n# Debug variable dump at max verbosity\necho \"BRANCH: $BRANCH\nDIR: $DIR\nGIT_REPO: $GIT_REPO\nINTERACTIVE: $INTERACTIVE\nPUBLIC: $PUBLIC\nRUNPOD: $RUNPOD\nSKIP_SPACE_CHECK: $SKIP_SPACE_CHECK\nVERBOSITY: $VERBOSITY\nScript directory is ${SCRIPT_DIR}.\" >&5\n\n# This must be set after the getopts loop to account for $DIR changes.\nPARENT_DIR=\"$(dirname \"${DIR}\")\"\nVENV_DIR=\"$DIR/venv\"\n\nif [ -w \"$PARENT_DIR\" ] && [ ! -d \"$DIR\" ]; then\n  echo \"Creating install folder ${DIR}.\"\n  mkdir \"$DIR\"\nfi\n\nif [ ! -w \"$DIR\" ]; then\n  echo \"We cannot write to ${DIR}.\"\n  echo \"Please ensure the install directory is accurate and you have the correct permissions.\"\n  exit 1\nfi\n\n# Shared functions\n# This checks for free space on the installation drive and returns that in Gb.\nsize_available() {\n  local folder\n  if [ -d \"$DIR\" ]; then\n    folder=\"$DIR\"\n  elif [ -d \"$PARENT_DIR\" ]; then\n    folder=\"$PARENT_DIR\"\n  elif [ -d \"$(echo \"$DIR\" | cut -d \"/\" -f2)\" ]; then\n    folder=\"$(echo \"$DIR\" | cut -d \"/\" -f2)\"\n  else\n    echo \"We are assuming a root drive install for space-checking purposes.\"\n    folder='/'\n  fi\n\n  local FREESPACEINKB\n  FREESPACEINKB=\"$(df -Pk \"$folder\" | sed 1d | grep -v used | awk '{ print $4 \"\\t\" }')\"\n  echo \"Detected available space in Kb: $FREESPACEINKB\" >&5\n  local FREESPACEINGB\n  FREESPACEINGB=$((FREESPACEINKB / 1024 / 1024))\n  echo \"$FREESPACEINGB\"\n}\n\nisContainerOrPod() {\n  local cgroup=/proc/1/cgroup\n  test -f $cgroup && (grep -qE ':cpuset:/(docker|kubepods)' $cgroup || grep -q ':/docker/' $cgroup)\n}\n\nisDockerBuildkit() {\n  local cgroup=/proc/1/cgroup\n  test -f $cgroup && grep -q ':cpuset:/docker/buildkit' $cgroup\n}\n\nisDockerContainer() {\n  [ -e /.dockerenv ]\n}\n\ninDocker() {\n  if isContainerOrPod || isDockerBuildkit || isDockerContainer; then\n    return 0\n  else\n    return 1\n  fi\n}\n\n# Start OS-specific detection and work\nif [[ \"$OSTYPE\" == \"lin\"* ]]; then\n  # Check if root or sudo\n  root=false\n  if [ \"$EUID\" = 0 ]; then\n    root=true\n  elif command -v id >/dev/null && [ \"$(id -u)\" = 0 ]; then\n    root=true\n  elif [ \"$UID\" = 0 ]; then\n    root=true\n  fi\n\n  check_storage_space\n  update_kohya_ss\n\n  distro=get_distro_name\n  family=get_distro_family\n  echo \"Raw detected distro string: $distro\" >&4\n  echo \"Raw detected distro family string: $family\" >&4\n\n  if \"$distro\" | grep -qi \"Ubuntu\" || \"$family\" | grep -qi \"Ubuntu\"; then\n    echo \"Ubuntu detected.\"\n    if [ $(dpkg-query -W -f='${Status}' python3-tk 2>/dev/null | grep -c \"ok installed\") = 0 ]; then\n      # if [ \"$root\" = true ]; then\n        echo \"This script needs YOU to install the missing python3-tk packages. Please install with:\"\n        echo \" \"\n        if [ \"$RUNPOD\" = true ]; then\n          bash apt update -y && apt install -y python3-tk\n        else\n          echo \"sudo apt update -y && sudo apt install -y python3-tk\"\n        fi\n        exit 1\n      # else\n      #   echo \"This script needs to be run as root or via sudo to install packages.\"\n      #   exit 1\n      # fi\n    else\n      echo \"Python TK found...\"\n    fi\n  elif \"$distro\" | grep -Eqi \"Fedora|CentOS|Redhat\"; then\n    echo \"Redhat or Redhat base detected.\"\n    if ! rpm -qa | grep -qi python3-tkinter; then\n      # if [ \"$root\" = true ]; then\n        echo \"This script needs you to install the missing python3-tk packages. Please install with:\\n\\n\"\n        echo \"sudo dnf install python3-tkinter -y >&3\"\n        exit 1\n      # else\n      #   echo \"This script needs to be run as root or via sudo to install packages.\"\n      #   exit 1\n      # fi\n    else\n      echo \"Python TK found...\"\n    fi\n  elif \"$distro\" | grep -Eqi \"arch\" || \"$family\" | grep -qi \"arch\"; then\n    echo \"Arch Linux or Arch base detected.\"\n    if ! pacman -Qi tk >/dev/null; then\n      # if [ \"$root\" = true ]; then\n        echo \"This script needs you to install the missing python3-tk packages. Please install with:\\n\\n\"\n        echo \"pacman --noconfirm -S tk >&3\"\n        exit 1\n      # else\n      #   echo \"This script needs to be run as root or via sudo to install packages.\"\n      #   exit 1\n      # fi\n    else\n      echo \"Python TK found...\"\n    fi\n  elif \"$distro\" | grep -Eqi \"opensuse\" || \"$family\" | grep -qi \"opensuse\"; then\n    echo \"OpenSUSE detected.\"\n    if ! rpm -qa | grep -qi python-tk; then\n      # if [ \"$root\" = true ]; then\n        echo \"This script needs you to install the missing python3-tk packages. Please install with:\\n\\n\"\n        echo \"zypper install -y python-tk >&3\"\n        exit 1\n      # else\n      #   echo \"This script needs to be run as root or via sudo to install packages.\"\n      #   exit 1\n      # fi\n    else\n      echo \"Python TK found...\"\n    fi\n  elif [ \"$distro\" = \"None\" ] || [ \"$family\" = \"None\" ]; then\n    if [ \"$distro\" = \"None\" ]; then\n      echo \"We could not detect your distribution of Linux. Please file a bug report on github with the contents of your /etc/os-release file.\"\n    fi\n\n    if [ \"$family\" = \"None\" ]; then\n      echo \"We could not detect the family of your Linux distribution. Please file a bug report on github with the contents of your /etc/os-release file.\"\n    fi\n  fi\n\n  install_python_dependencies\n\n  # We need just a little bit more setup for non-interactive environments\n  if [ \"$RUNPOD\" = true ]; then\n    if inDocker; then\n      # We get the site-packages from python itself, then cut the string, so no other code changes required.\n      VENV_DIR=$(python -c \"import site; print(site.getsitepackages()[0])\")\n      VENV_DIR=\"${VENV_DIR%/lib/python3.10/site-packages}\"\n    fi\n\n    # Symlink paths\n    libnvinfer_plugin_symlink=\"$VENV_DIR/lib/python3.10/site-packages/tensorrt/libnvinfer_plugin.so.7\"\n    libnvinfer_symlink=\"$VENV_DIR/lib/python3.10/site-packages/tensorrt/libnvinfer.so.7\"\n    libcudart_symlink=\"$VENV_DIR/lib/python3.10/site-packages/nvidia/cuda_runtime/lib/libcudart.so.11.0\"\n\n    #Target file paths\n    libnvinfer_plugin_target=\"$VENV_DIR/lib/python3.10/site-packages/tensorrt/libnvinfer_plugin.so.8\"\n    libnvinfer_target=\"$VENV_DIR/lib/python3.10/site-packages/tensorrt/libnvinfer.so.8\"\n    libcudart_target=\"$VENV_DIR/lib/python3.10/site-packages/nvidia/cuda_runtime/lib/libcudart.so.12\"\n\n    # echo \"Checking symlinks now.\"\n    # create_symlinks \"$libnvinfer_plugin_symlink\" \"$libnvinfer_plugin_target\"\n    # create_symlinks \"$libnvinfer_symlink\" \"$libnvinfer_target\"\n    # create_symlinks \"$libcudart_symlink\" \"$libcudart_target\"\n\n    # if [ -d \"${VENV_DIR}/lib/python3.10/site-packages/tensorrt/\" ]; then\n    #   export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:${VENV_DIR}/lib/python3.10/site-packages/tensorrt/\"\n    # else\n    #   echo \"${VENV_DIR}/lib/python3.10/site-packages/tensorrt/ not found; not linking library.\"\n    # fi\n\n    # if [ -d \"${VENV_DIR}/lib/python3.10/site-packages/tensorrt/\" ]; then\n    #   export LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:${VENV_DIR}/lib/python3.10/site-packages/nvidia/cuda_runtime/lib/\"\n    # else\n    #   echo \"${VENV_DIR}/lib/python3.10/site-packages/nvidia/cuda_runtime/lib/ not found; not linking library.\"\n    # fi\n\n    configure_accelerate\n\n    # This is a non-interactive environment, so just directly call gui.sh after all setup steps are complete.\n    if [ \"$SKIP_GUI\" = false ]; then\n      if command -v bash >/dev/null; then\n        if [ \"$PUBLIC\" = false ]; then\n          bash \"$DIR\"/gui.sh --headless\n          exit 0\n        else\n          bash \"$DIR\"/gui.sh --headless --share\n          exit 0\n        fi\n      else\n        # This shouldn't happen, but we're going to try to help.\n        if [ \"$PUBLIC\" = false ]; then\n          sh \"$DIR\"/gui.sh --headless\n          exit 0\n        else\n          sh \"$DIR\"/gui.sh --headless --share\n          exit 0\n        fi\n      fi\n    fi\n  fi\n\n  echo -e \"Setup finished! Run \\e[0;92m./gui.sh\\e[0m to start.\"\n  echo \"Please note if you'd like to expose your public server you need to run ./gui.sh --share\"\nelif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n  # The initial setup script to prep the environment on macOS\n  # xformers has been omitted as that is for Nvidia GPUs only\n\n  if ! command -v brew >/dev/null; then\n    echo \"Please install homebrew first. This is a requirement for the remaining setup.\"\n    echo \"You can find that here: https://brew.sh\"\n    #shellcheck disable=SC2016\n    echo 'The \"brew\" command should be in $PATH to be detected.'\n    exit 1\n  fi\n\n  check_storage_space\n\n  # Install base python packages\n  echo \"Installing Python 3.10 if not found.\"\n  if ! brew ls --versions python@3.10 >/dev/null; then\n    echo \"Installing Python 3.10.\"\n    brew install python@3.10 >&3\n  else\n    echo \"Python 3.10 found!\"\n  fi\n  echo \"Installing Python-TK 3.10 if not found.\"\n  if ! brew ls --versions python-tk@3.10 >/dev/null; then\n    echo \"Installing Python TK 3.10.\"\n    brew install python-tk@3.10 >&3\n  else\n    echo \"Python Tkinter 3.10 found!\"\n  fi\n\n  update_kohya_ss\n\n  if ! install_python_dependencies; then\n    echo \"You may need to install Python. The command for this is brew install python@3.10.\"\n  fi\n\n  configure_accelerate\n  echo -e \"Setup finished! Run ./gui.sh to start.\"\nelif [[ \"$OSTYPE\" == \"cygwin\" ]]; then\n  # Cygwin is a standalone suite of Linux utilities on Windows\n  echo \"This hasn't been validated on cygwin yet.\"\nelif [[ \"$OSTYPE\" == \"msys\" ]]; then\n  # MinGW has the msys environment which is a standalone suite of Linux utilities on Windows\n  # \"git bash\" on Windows may also be detected as msys.\n  echo \"This hasn't been validated in msys 'mingw' on Windows yet.\"\nfi\n"
        },
        {
          "name": "setup",
          "type": "tree",
          "content": null
        },
        {
          "name": "test",
          "type": "tree",
          "content": null
        },
        {
          "name": "tools",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}