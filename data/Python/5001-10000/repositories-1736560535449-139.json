{
  "metadata": {
    "timestamp": 1736560535449,
    "page": 139,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjE0MA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "apple/ml-ferret",
      "stars": 8539,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3203125,
          "content": "*.egg-info\n*.pyc\nbuild/\n\n# compilation and distribution\n__pycache__\n_ext\n*.so\ndist/\n\n# pytorch/python/numpy formats\n*.pth\n*.pkl\n*.npy\n\n# Editor temporaries\n*.swn\n*.swo\n*.swp\n*~\n\n# Pycharm editor settings\n.idea\n\n# vscode editor settings\n.vscode\n\n# MacOS\n.DS_Store\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# Customized\ncheckpoints/"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 3.2783203125,
          "content": "# Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject e-mail address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the open source team at [opensource-conduct@group.apple.com](mailto:opensource-conduct@group.apple.com). All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant](https://www.contributor-covenant.org), version 1.4,\navailable at [https://www.contributor-covenant.org/version/1/4/code-of-conduct.html](https://www.contributor-covenant.org/version/1/4/code-of-conduct.html)"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.7294921875,
          "content": "# Contribution Guide\n\nThanks for your interest in contributing. This project was released to accompany a research paper for purposes of reproducibility, and beyond its publication there are limited plans for future development of the repository.\n\nWhile we welcome new pull requests and issues please note that our response may be limited. Forks and out-of-tree improvements are strongly encouraged.\n\n## Before you get started\n\nBy submitting a pull request, you represent that you have the right to license your contribution to Apple and the community, and agree by submitting the patch that your contributions are licensed under the [LICENSE](LICENSE).\n\nWe ask that all community members read and observe our [Code of Conduct](CODE_OF_CONDUCT.md)."
        },
        {
          "name": "EVAL.md",
          "type": "blob",
          "size": 0.8525390625,
          "content": "# Evaluation\nAll evaluation scripts provided usage details/cases in the first several lines of codes. \n\n## Ferret-Bench\nPlease follow [gpt4_eval_script.sh](ferret/eval/gpt4_eval_script.sh) to run inference on Ferret-Bench data and use GPT-4 to rate. It's noted that `openai` package should be installed and user's OPENAI_KEY should be provided.\n\n## LVIS-Referring Object Classification\nRun `ferret/eval/model_lvis.py` following the usage in the file and then run `ferret/eval/eval_lvis.py`.\n\n## RefCOCO/RefCOCO+/RefCOCOg\nRun `ferret/eval/model_refcoco.py` following the usage in the file and then run `ferret/eval/eval_refexp.py`.\n\n## Flickr\nRun `ferret/eval/model_flickr.py` following the usage in the file and then run `ferret/eval/eval_flickr_entities.py`.\n\n## POPE\nRun `ferret/eval/model_pope.py` following the usage in the file and then run `ferret/eval/eval_pope.py`."
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 2.2626953125,
          "content": "Copyright (C) 2023 Apple Inc. All Rights Reserved.\n\nIMPORTANT:  This Apple software is supplied to you by Apple\nInc. (\"Apple\") in consideration of your agreement to the following\nterms, and your use, installation, modification or redistribution of\nthis Apple software constitutes acceptance of these terms.  If you do\nnot agree with these terms, please do not use, install, modify or\nredistribute this Apple software.\n\nIn consideration of your agreement to abide by the following terms, and\nsubject to these terms, Apple grants you a personal, non-exclusive\nlicense, under Apple's copyrights in this original Apple software (the\n\"Apple Software\"), to use, reproduce, modify and redistribute the Apple\nSoftware, with or without modifications, in source and/or binary forms;\nprovided that if you redistribute the Apple Software in its entirety and\nwithout modifications, you must retain this notice and the following\ntext and disclaimers in all such redistributions of the Apple Software.\nNeither the name, trademarks, service marks or logos of Apple Inc. may\nbe used to endorse or promote products derived from the Apple Software\nwithout specific prior written permission from Apple.  Except as\nexpressly stated in this notice, no other rights or licenses, express or\nimplied, are granted by Apple herein, including but not limited to any\npatent rights that may be infringed by your derivative works or by other\nworks in which the Apple Software may be incorporated.\n\nThe Apple Software is provided by Apple on an \"AS IS\" basis.  APPLE\nMAKES NO WARRANTIES, EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION\nTHE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY AND FITNESS\nFOR A PARTICULAR PURPOSE, REGARDING THE APPLE SOFTWARE OR ITS USE AND\nOPERATION ALONE OR IN COMBINATION WITH YOUR PRODUCTS.\n\nIN NO EVENT SHALL APPLE BE LIABLE FOR ANY SPECIAL, INDIRECT, INCIDENTAL\nOR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\nSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\nINTERRUPTION) ARISING IN ANY WAY OUT OF THE USE, REPRODUCTION,\nMODIFICATION AND/OR DISTRIBUTION OF THE APPLE SOFTWARE, HOWEVER CAUSED\nAND WHETHER UNDER THEORY OF CONTRACT, TORT (INCLUDING NEGLIGENCE),\nSTRICT LIABILITY OR OTHERWISE, EVEN IF APPLE HAS BEEN ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 7.166015625,
          "content": "<!-- # Project Name\n\nThis software project accompanies the research paper, [Paper title](https://arxiv.org).\n\nBrief description of the project.\n\n## Documentation\n\n## Getting Started  -->\n\n# <img src=\"figs/ferret_icon.png\" alt=\"Alt text for the image\" width=\"40\" height=\"45\"> Ferret: Refer and Ground Anything Anywhere at Any Granularity\n\n*An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.* [[Paper](https://arxiv.org/abs/2310.07704)]\n\n[Haoxuan You*](https://hxyou.github.io/), [Haotian Zhang*](https://scholar.google.com/citations?user=1vz0kKUAAAAJ&hl=en/), [Zhe Gan](https://zhegan27.github.io/), [Xianzhi Du](https://scholar.google.com/citations?user=l1hP40AAAAAJ&hl=en), [Bowen Zhang](https://zbwglory.github.io/), [Zirui Wang](https://www.cs.cmu.edu/~ziruiw/), [Liangliang Cao](http://llcao.net/), [Shih-Fu Chang](https://www.ee.columbia.edu/~sfchang/), [Yinfei Yang](https://sites.google.com/site/yinfeiyang/) \n[*: equal contribution]\n\n\n## Release\n- [10/08/2024] ðŸ”¥ We release the [Ferret-UI](ferretui/), the first UI-centric MLLM that is capable of effectively executing **referring, grounding, and reasoning** tasks.\n- [07/10/2024] ðŸ”¥ [Ferret-v2](https://arxiv.org/abs/2404.07973) is accepted to COLM 2024. \n- [02/15/2024] ðŸ”¥ Ferret is accepted to ICLR 2024 as a [Spotlight](https://iclr.cc/virtual/2024/poster/19537)!!! \n- [12/14/2023] ðŸ”¥ We release the Ferret [checkpoints(7B, 13B)](#checkpoints).\n- [10/30/2023] ðŸ”¥ We release the code of **FERRET** model and [Ferret-Bench](ferret/eval/ferret_gpt4_data).\n\n## Overview\n\n<p align=\"center\">\n    <img src=\"figs/ferret_fig_diagram_v2.png\" width=\"100%\"></a> <br>\n    Diagram of Ferret Model.\n</p>\n\nKey Contributions:\n* Ferret Model - **Hybrid Region Representation + Spatial-aware Visual Sampler** enable fine-grained and open-vocabulary referring and grounding in MLLM.\n* GRIT Dataset (~1.1M) - A **Large-scale, Hierarchical, Robust** ground-and-refer instruction tuning dataset.\n* Ferret-Bench - A multimodal evaluation benchmark that jointly requires **Referring/Grounding, Semantics, Knowledge, and Reasoning**.\n\n\n**Usage and License Notices**: The data, and code is intended and licensed for research use only. They are also restricted to uses that follow the license agreement of LLaMA, Vicuna and GPT-4. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes. \n\n## Contents\n- [Install](#install)\n- [Train](#train)\n- [Evaluation](#evaluation)\n- [Demo](#demo)\n\n## Install\n\n1. Clone this repository and navigate to FERRET folder\n```bash\ngit clone https://github.com/apple/ml-ferret\ncd ml-ferret\n```\n\n2. Install Package\n```Shell\nconda create -n ferret python=3.10 -y\nconda activate ferret\npip install --upgrade pip  # enable PEP 660 support\npip install -e .\npip install pycocotools\npip install protobuf==3.20.0\n```\n\n3. Install additional packages for training cases\n```\npip install ninja\npip install flash-attn --no-build-isolation\n```\n\n\n## Train\n\nFERRET is trained on 8 A100 GPUs with 80GB memory. To train on fewer GPUs, you can reduce the `per_device_train_batch_size` and increase the `gradient_accumulation_steps` accordingly. Always keep the global batch size the same: `per_device_train_batch_size` x `gradient_accumulation_steps` x `num_gpus`.\n\n### Hyperparameters\nWe use a similar set of hyperparameters as LLaVA(Vicuna) in finetuning.  \n\n| Hyperparameter | Global Batch Size | Learning rate | Epochs | Max length | Weight decay |\n| --- | ---: | ---: | ---: | ---: | ---: |\n| FERRET-7B | 128 | 2e-5 | 3 | 2048 | 0 |\n| FERRET-13B | 128 | 2e-5 | 3 | 2048 | 0 |\n\n### Prepare Vicuna checkpoint and LLaVA's projector\n\nBefore you start, prepare our base model Vicuna, which is an instruction-tuned chatbot. Please download its weights following the instructions [here](https://github.com/lm-sys/FastChat#model-weights). Vicuna v1.3 is used in FERRET.\n\nThen download LLaVA's first-stage pre-trained projector weight ([7B](https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-7b-v1.3), [13B](https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3)).\n\n\n### FERRET Training\n\nThe scripts are provided ([7B](experiments/ferret_7b_train.sh), [13B](experiments/ferret_13b_train.sh)).\n\n\n## Evaluation\n\nPlease see this [doc](EVAL.md) for the details.\n\n## Checkpoints\nWe extracted the `delta` between our pre-trained model and Vicuna. Please first download weights of Vicuna following the [previous instruction](#prepare-vicuna-checkpoint-and-llavas-projector). Then download our prepared offsets of weights: [7B](https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-7b/ferret-7b-delta.zip), [13B](https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-13b/ferret-13b-delta.zip) using `wget` or `curl`, and unzip the downloaded offsets. Lastly, apply the offset to the Vicuna's weight by running the following script:\n```Shell\n# 7B\npython3 -m ferret.model.apply_delta \\\n    --base ./model/vicuna-7b-v1-3 \\\n    --target ./model/ferret-7b-v1-3 \\\n    --delta path/to/ferret-7b-delta\n# 13B\npython3 -m ferret.model.apply_delta \\\n    --base ./model/vicuna-13b-v1-3 \\\n    --target ./model/ferret-13b-v1-3 \\\n    --delta path/to/ferret-13b-delta\n```\n\n**Notices**: Apple's rights in the attached weight differentials are hereby licensed under the CC-BY-NC license. Apple makes no representations with regards to LLaMa or any other third party software, which are subject to their own terms.\n\nPlease refer to the next section about how to set up a local demo with pre-trained weight.\n\n## Demo\n\nTo run our demo, you need to train FERRET and use the checkpoints locally. Gradio web UI is used. Please run the following commands one by one. \n\n#### Launch a controller\n```Shell\npython -m ferret.serve.controller --host 0.0.0.0 --port 10000\n```\n\n#### Launch a gradio web server.\n```Shell\npython -m ferret.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --add_region_feature\n```\n\n#### Launch a model worker\n\nThis is the worker that load the ckpt and do the inference on the GPU.  Each worker is responsible for a single model specified in `--model-path`.\n\n```Shell\nCUDA_VISIBLE_DEVICES=0 python -m ferret.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path ./checkpoints/FERRET-13B-v0 --add_region_feature\n```\nWait until the process finishes loading the model and you see \"Uvicorn running on ...\".  Now, refresh your Gradio web UI, and you will see the model you just launched in the model list.\n\n\n<p align=\"center\">\n    <img src=\"figs/ferret_demo.png\" width=\"105%\"></a> <br>\n    Example of Ferret Interactive Demo.\n</p>\n\n\n## Citation\n\nIf you find Ferret useful, please cite using this BibTeX:\n\n```bibtex\n@article{you2023ferret,\n  title={Ferret: Refer and Ground Anything Anywhere at Any Granularity},\n  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},\n  journal={arXiv preprint arXiv:2310.07704},\n  year={2023}\n}\n```\n\n## Acknowledgement\n\n- [LLaVA](https://github.com/haotian-liu/LLaVA): the codebase we built upon. \n- [Vicuna](https://github.com/lm-sys/FastChat): the LLM codebase.\n"
        },
        {
          "name": "experiments",
          "type": "tree",
          "content": null
        },
        {
          "name": "ferret",
          "type": "tree",
          "content": null
        },
        {
          "name": "ferretui",
          "type": "tree",
          "content": null
        },
        {
          "name": "figs",
          "type": "tree",
          "content": null
        },
        {
          "name": "pyproject.toml",
          "type": "blob",
          "size": 1.1923828125,
          "content": "[build-system]\nrequires = [\"setuptools>=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"ferret\"\nversion = \"1.0.1\"\ndescription = \"Towards GPT-4 like large language and visual assistant.\"\nreadme = \"README.md\"\nrequires-python = \">=3.8\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: Apache Software License\",\n]\ndependencies = [\n    \"einops\", \"fastapi\", \"gradio==4.31.3\", \"markdown2[all]\", \"numpy\",\n    \"requests\", \"sentencepiece\", \"tokenizers>=0.12.1\",\n    \"torch\", \"torchvision\", \"uvicorn\", \"wandb\",\n    \"shortuuid\", \"httpx==0.24.0\",\n    \"deepspeed==0.9.5\",\n    \"peft==0.4.0\",\n    \"transformers @ git+https://github.com/huggingface/transformers.git@cae78c46\",\n    \"accelerate==0.21.0\",\n    \"bitsandbytes==0.41.0\",\n    \"scikit-learn==1.5.0\",\n    \"sentencepiece==0.1.99\",\n    \"einops==0.6.1\", \"einops-exts==0.0.4\", \"timm==0.6.13\", \"openai\",\n    \"gradio_client==0.1.2\"\n]\n\n[project.urls]\n\"Homepage\" = \"https://github.com/apple/ml-ferret\"\n\n[tool.setuptools.packages.find]\nexclude = [\"assets*\", \"benchmark*\", \"docs\", \"dist*\", \"playground*\", \"scripts*\", \"tests*\"]\n\n[tool.wheel]\nexclude = [\"assets*\", \"benchmark*\", \"docs\", \"dist*\", \"playground*\", \"scripts*\", \"tests*\"]\n"
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}