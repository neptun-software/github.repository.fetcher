{
  "metadata": {
    "timestamp": 1736560593568,
    "page": 213,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjIyMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "jupyter/docker-stacks",
      "stars": 8062,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.08984375,
          "content": "[flake8]\nmax-line-length = 88\nselect = C, E, F, W, B, B950\nextend-ignore = E203, E501, W503\n"
        },
        {
          "name": ".gitattributes",
          "type": "blob",
          "size": 0.0185546875,
          "content": "* text=auto eol=lf\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 3.7646484375,
          "content": "# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n# .python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#uv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\n#poetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control\n.pdm.toml\n.pdm-python\n.pdm-build/\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n#.idea/\n\n# PyPI configuration file\n.pypirc\n\n##################################################################\n#             The content above is copied from                   #\n# https://github.com/github/gitignore/blob/main/Python.gitignore #\n#       Please, add the content only below these lines           #\n##################################################################\n\n# Mac OS X\n.DS_Store\n\n# VS Code project configuration\n.vscode/\n\n# PyCharm project configuration\n.idea/\n"
        },
        {
          "name": ".hadolint.yaml",
          "type": "blob",
          "size": 0.044921875,
          "content": "---\nignored:\n  - DL3006\n  - DL3008\n  - DL3013\n"
        },
        {
          "name": ".markdownlint.yaml",
          "type": "blob",
          "size": 0.142578125,
          "content": "# Default state for all rules\ndefault: true\n\n# MD013/line-length - Line length\nMD013:\n  # Number of characters\n  line_length: 200\n  tables: false\n"
        },
        {
          "name": ".pre-commit-config.yaml",
          "type": "blob",
          "size": 4.734375,
          "content": "---\n# pre-commit is a tool to perform a predefined set of tasks manually and/or\n# automatically before git commits are made.\n#\n# Config reference: https://pre-commit.com/#pre-commit-configyaml---top-level\n#\n# Common tasks\n#\n# - Run on all files:   pre-commit run --all-files\n# - Register git hooks: pre-commit install --install-hooks\n#\n# See https://pre-commit.com for more information\n# See https://pre-commit.com/hooks.html for more hooks\nrepos:\n  # Autoupdate: Python code\n  - repo: https://github.com/asottile/pyupgrade\n    rev: v3.19.1\n    hooks:\n      - id: pyupgrade\n        args: [--py39-plus]\n\n  # Automatically sort python imports\n  - repo: https://github.com/PyCQA/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n        args: [--profile, black]\n\n  # Autoformat: Python code\n  - repo: https://github.com/psf/black\n    rev: 24.10.0\n    hooks:\n      - id: black\n        args: [--target-version=py39]\n\n  # Check python code static typing\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.14.1\n    hooks:\n      - id: mypy\n        args: [--config, ./mypy.ini]\n        additional_dependencies:\n          [\n            \"beautifulsoup4\",\n            \"numpy\",\n            \"pytest\",\n            \"requests\",\n            \"urllib3\",\n            \"types-beautifulsoup4\",\n            \"types-python-dateutil\",\n            \"types-requests\",\n            \"types-tabulate\",\n            \"types-urllib3\",\n          ]\n        # Unfortunately, `pre-commit` only runs on modified files\n        # This doesn't work well with `mypy --follow-imports error`\n        # See: https://github.com/pre-commit/mirrors-mypy/issues/34#issuecomment-1062160321\n        #\n        # To work around this we run `mypy` only in manual mode\n        # So it won't run as part of `git commit` command,\n        # but it will still be run as part of `pre-commit` workflow and give expected results\n        stages: [manual]\n\n  # Autoformat: YAML, JSON, Markdown, etc.\n  - repo: https://github.com/rbubley/mirrors-prettier\n    rev: v3.4.2\n    hooks:\n      - id: prettier\n\n  # `pre-commit sample-config` default hooks\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: check-added-large-files\n      - id: end-of-file-fixer\n      - id: requirements-txt-fixer\n      - id: trailing-whitespace\n\n  # Lint: Dockerfile\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.13.1-beta\n    hooks:\n      - id: hadolint-docker\n        entry: hadolint/hadolint:v2.12.1-beta hadolint\n\n  # Lint: Dockerfile\n  # We're linting .dockerfile files as well\n  - repo: https://github.com/hadolint/hadolint\n    rev: v2.13.1-beta\n    hooks:\n      - id: hadolint-docker\n        name: Lint *.dockerfile Dockerfiles\n        entry: hadolint/hadolint:v2.12.1-beta hadolint\n        types: [file]\n        files: \\.dockerfile$\n\n  # Lint: YAML\n  - repo: https://github.com/adrienverge/yamllint\n    rev: v1.35.1\n    hooks:\n      - id: yamllint\n        args: [\"-d {extends: relaxed, rules: {line-length: disable}}\", \"-s\"]\n        files: \\.(yaml|yml)$\n\n  # Lint: Bash scripts\n  - repo: https://github.com/openstack/bashate\n    rev: 2.1.1\n    hooks:\n      - id: bashate\n        args: [\"--ignore=E006\"]\n\n  # Lint: Shell scripts\n  - repo: https://github.com/shellcheck-py/shellcheck-py\n    rev: v0.10.0.1\n    hooks:\n      - id: shellcheck\n        args: [\"-x\"]\n\n  # Lint: Python\n  - repo: https://github.com/PyCQA/flake8\n    rev: 7.1.1\n    hooks:\n      - id: flake8\n\n  # Lint: Markdown\n  - repo: https://github.com/igorshubovych/markdownlint-cli\n    rev: v0.43.0\n    hooks:\n      - id: markdownlint\n        args: [\"--fix\"]\n\n  # Strip output from Jupyter notebooks\n  - repo: https://github.com/kynan/nbstripout\n    rev: 0.8.1\n    hooks:\n      - id: nbstripout\n\n  # nbQA provides tools from the Python ecosystem like\n  # pyupgrade, isort, black, and flake8, adjusted for notebooks.\n  - repo: https://github.com/nbQA-dev/nbQA\n    rev: 1.9.1\n    hooks:\n      - id: nbqa-pyupgrade\n        args: [--py39-plus]\n      - id: nbqa-isort\n      - id: nbqa-black\n        args: [--target-version=py39]\n      - id: nbqa-flake8\n\n  # Run black on python code blocks in documentation files.\n  - repo: https://github.com/adamchainz/blacken-docs\n    rev: 1.19.1\n    hooks:\n      - id: blacken-docs\n        # --skip-errors is added to allow us to have python syntax highlighting even if\n        # the python code blocks include jupyter-specific additions such as % or !\n        # See https://github.com/adamchainz/blacken-docs/issues/127 for an upstream\n        # feature request about this.\n        args: [--target-version=py39, --skip-errors]\n\n# pre-commit.ci config reference: https://pre-commit.ci/#configuration\nci:\n  autoupdate_schedule: monthly\n  # Docker hooks do not work in pre-commit.ci\n  # See: <https://github.com/pre-commit-ci/issues/issues/11>\n  skip: [hadolint-docker]\n"
        },
        {
          "name": ".readthedocs.yaml",
          "type": "blob",
          "size": 1.0673828125,
          "content": "# Read the Docs configuration file for Sphinx projects\n# See https://docs.readthedocs.io/en/stable/config-file/v2.html for details\n\n# Required\nversion: 2\n\n# Set the OS, Python version and other tools you might need\nbuild:\n  os: ubuntu-22.04\n  tools:\n    python: \"3.12\"\n    # You can also specify other tool versions:\n    # nodejs: \"20\"\n    # rust: \"1.70\"\n    # golang: \"1.20\"\n  jobs:\n    post_checkout:\n      - git fetch --unshallow || true\n\n# Build documentation in the \"docs/\" directory with Sphinx\nsphinx:\n  configuration: docs/conf.py\n  # You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs\n  # builder: \"dirhtml\"\n  # Fail on all warnings to avoid broken references\n  # fail_on_warning: true\n\n# Optionally build your docs in additional formats such as PDF and ePub\n# formats:\n#   - pdf\n#   - epub\n\n# Optional but recommended, declare the Python requirements required\n# to build your documentation\n# See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html\npython:\n  install:\n    - requirements: docs/requirements.txt\n"
        },
        {
          "name": "CHANGELOG.md",
          "type": "blob",
          "size": 1.99609375,
          "content": "# Changelog\n\nThis changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).\nAll image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).\n\n## 2024-12-03\n\nAffected: all images.\n\n- **Breaking:** `docker-stacks-foundation`: switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).\n  More information about changes made: <https://mamba.readthedocs.io/en/latest/developer_zone/changes-2.0.html>.\n\n## 2024-11-08\n\nAffected: all images except `docker-stacks-foundation`.\n\n- **Breaking:** `base-notebook`: stop installing `nodejs` from `conda-forge` ([#2172](https://github.com/jupyter/docker-stacks/pull/2172)).\n\n  Reason: It isn't a direct dependency on anything in the images anymore, and increased the image size by ~150MB.\n\n## 2024-11-06\n\nAffected: all images except `docker-stacks-foundation`.\n\n- **Non-breaking:** `base-notebook`: install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).\n\n## 2024-10-23\n\nAffected: all images.\n\n- **Breaking:** `docker-stacks-foundation`: switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).\n\n## 2024-10-22\n\nAffected: `pyspark-notebook` and `all-spark-notebook` images.\n\n- **Breaking:** `pyspark-notebook`: start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).\n  `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.\n\n  Reason: Spark v3 is not compatible with Python 3.12, and [the voting group has decided](https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851) to switch to Spark v4 preview version.\n\n## 2024-10-09\n\nAffected: users building a custom set of images.\n\n- **Breaking:** rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).\n"
        },
        {
          "name": "CODE_OF_CONDUCT.md",
          "type": "blob",
          "size": 0.1728515625,
          "content": "# Project `jupyter/docker-stacks` Code of Conduct\n\nPlease see the [Project Jupyter Code of Conduct](https://github.com/jupyter/governance/blob/HEAD/conduct/code_of_conduct.md).\n"
        },
        {
          "name": "CONTRIBUTING.md",
          "type": "blob",
          "size": 0.69921875,
          "content": "Thanks for contributing!\nPlease see the **Contributor Guide** section in [the documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/)\nfor information about how to contribute\n[issues](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/issues.html),\n[features](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/features.html),\n[recipes](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/recipes.html),\n[tests](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/tests.html),\nand [community-maintained stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html).\n\n<!-- markdownlint-disable-file MD041 -->\n"
        },
        {
          "name": "LICENSE.md",
          "type": "blob",
          "size": 2.8193359375,
          "content": "# Licensing terms\n\nThis project is licensed under the terms of the Modified BSD License\n(also known as New or Revised or 3-Clause BSD), as follows:\n\n- Copyright (c) 2001-2015, IPython Development Team\n- Copyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this\nlist of conditions and the following disclaimer.\n\nRedistributions in binary form must reproduce the above copyright notice, this\nlist of conditions and the following disclaimer in the documentation and/or\nother materials provided with the distribution.\n\nNeither the name of the Jupyter Development Team nor the names of its\ncontributors may be used to endorse or promote products derived from this\nsoftware without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n## About the Jupyter Development Team\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project.\nThis includes all of the Jupyter subprojects.\n\nThe core team that coordinates development on GitHub can be found here:\n<https://github.com/jupyter/>.\n\n## Our Copyright Policy\n\nJupyter uses a shared copyright model. Each contributor maintains copyright\nover their contributions to Jupyter. But, it is important to note that these\ncontributions are typically only changes to the repositories. Thus, the Jupyter\nsource code, in its entirety is not the copyright of any single person or\ninstitution. Instead, it is the collective copyright of the entire Jupyter\nDevelopment Team. If individual contributors want to maintain a record of what\nchanges/contributions they have specific copyright on, they should indicate\ntheir copyright in the commit message of the change, when they commit the\nchange to one of the Jupyter repositories.\n\nWith this in mind, the following banner should be used in any source code file\nto indicate the copyright and license terms:\n\n    # Copyright (c) Jupyter Development Team.\n    # Distributed under the terms of the Modified BSD License.\n"
        },
        {
          "name": "Makefile",
          "type": "blob",
          "size": 4.4140625,
          "content": "# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License.\n.PHONY: docs help test\n\nSHELL:=bash\nREGISTRY?=quay.io\nOWNER?=jupyter\n\n# Enable BuildKit for Docker build\nexport DOCKER_BUILDKIT:=1\n\n# All the images listed in the build dependency order\nALL_IMAGES:= \\\n\tdocker-stacks-foundation \\\n\tbase-notebook \\\n\tminimal-notebook \\\n\tr-notebook \\\n\tjulia-notebook \\\n\tscipy-notebook \\\n\ttensorflow-notebook \\\n\tpytorch-notebook \\\n\tdatascience-notebook \\\n\tpyspark-notebook \\\n\tall-spark-notebook\n\n\n\n# https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html\nhelp:\n\t@echo \"jupyter/docker-stacks\"\n\t@echo \"=====================\"\n\t@echo \"Replace % with a stack directory name (e.g., make build/minimal-notebook)\"\n\t@echo\n\t@grep -E '^[a-zA-Z0-9_%/-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = \":.*?## \"}; {printf \"\\033[36m%-30s\\033[0m %s\\n\", $$1, $$2}'\n\n\n\nbuild/%: DOCKER_BUILD_ARGS?=\nbuild/%: ROOT_IMAGE?=ubuntu:24.04\nbuild/%: ## build the latest image for a stack using the system's architecture\n\tdocker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag \"$(REGISTRY)/$(OWNER)/$(notdir $@):latest\" \"./images/$(notdir $@)\" --build-arg REGISTRY=\"$(REGISTRY)\" --build-arg OWNER=\"$(OWNER)\" --build-arg ROOT_IMAGE=\"$(ROOT_IMAGE)\"\n\t@echo -n \"Built image size: \"\n\t@docker images \"$(REGISTRY)/$(OWNER)/$(notdir $@):latest\" --format \"{{.Size}}\"\nbuild-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks\n\n\n\ncheck-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report\n\t@TEST_IMAGE=\"$(REGISTRY)/$(OWNER)/$(notdir $@)\" pytest tests/docker-stacks-foundation/test_outdated.py\ncheck-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check all the stacks for outdated packages\n\n\n\ncont-stop-all: ## stop all containers\n\t@echo \"Stopping all containers ...\"\n\t-docker stop --time 0 $(shell docker ps --all --quiet) 2> /dev/null\ncont-rm-all: ## remove all containers\n\t@echo \"Removing all containers ...\"\n\t-docker rm --force $(shell docker ps --all --quiet) 2> /dev/null\ncont-clean-all: cont-stop-all cont-rm-all ## clean all containers (stop + rm)\n\n\n\ndocs: ## build HTML documentation\n\tsphinx-build -W --keep-going --color docs/ docs/_build/\nlinkcheck-docs: ## check broken links\n\tsphinx-build -W --keep-going --color -b linkcheck docs/ docs/_build/\n\n\n\nhook/%: VARIANT?=default\nhook/%: ## run post-build hooks for an image\n\tpython3 -m tagging.write_tags_file --short-image-name \"$(notdir $@)\" --tags-dir /tmp/jupyter/tags/ --registry \"$(REGISTRY)\" --owner \"$(OWNER)\" --variant \"$(VARIANT)\" && \\\n\tpython3 -m tagging.write_manifest --short-image-name \"$(notdir $@)\" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry \"$(REGISTRY)\" --owner \"$(OWNER)\" --variant \"$(VARIANT)\" && \\\n\tpython3 -m tagging.apply_tags --short-image-name \"$(notdir $@)\" --tags-dir /tmp/jupyter/tags/ --platform \"$(shell uname -m)\" --registry \"$(REGISTRY)\" --owner \"$(OWNER)\" --variant \"$(VARIANT)\"\nhook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images\n\n\n\nimg-list: ## list jupyter images\n\t@echo \"Listing $(OWNER) images ...\"\n\tdocker images \"$(OWNER)/*\"\n\tdocker images \"*/$(OWNER)/*\"\nimg-rm-dang: ## remove dangling images (tagged None)\n\t@echo \"Removing dangling images ...\"\n\t-docker rmi --force $(shell docker images -f \"dangling=true\" --quiet) 2> /dev/null\nimg-rm-jupyter: ## remove jupyter images\n\t@echo \"Removing $(OWNER) images ...\"\n\t-docker rmi --force $(shell docker images --quiet \"$(OWNER)/*\") 2> /dev/null\n\t-docker rmi --force $(shell docker images --quiet \"*/$(OWNER)/*\") 2> /dev/null\nimg-rm: img-rm-dang img-rm-jupyter ## remove dangling and jupyter images\n\n\n\npull/%: ## pull a jupyter image\n\tdocker pull \"$(REGISTRY)/$(OWNER)/$(notdir $@)\"\npull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images\npush/%: ## push all tags for a jupyter image\n\tdocker push --all-tags \"$(REGISTRY)/$(OWNER)/$(notdir $@)\"\npush-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images\n\n\n\nrun-shell/%: ## run a bash in interactive mode in a stack\n\tdocker run -it --rm \"$(REGISTRY)/$(OWNER)/$(notdir $@)\" $(SHELL)\nrun-sudo-shell/%: ## run bash in interactive mode as root in a stack\n\tdocker run -it --rm --user root \"$(REGISTRY)/$(OWNER)/$(notdir $@)\" $(SHELL)\n\n\n\ntest/%: ## run tests against a stack\n\tpython3 -m tests.run_tests --short-image-name \"$(notdir $@)\" --registry \"$(REGISTRY)\" --owner \"$(OWNER)\"\ntest-all: $(foreach I, $(ALL_IMAGES), test/$(I)) ## test all stacks\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 8.3740234375,
          "content": "# Jupyter Docker Stacks\n\n[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain \"Docker images build status\")\n[![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ \"Documentation build status\")\n[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main \"pre-commit.ci build status\")\n[![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ \"Jupyter Discourse Forum\")\n[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb \"Launch a quay.io/jupyter/base-notebook container on mybinder.org\")\n\nJupyter Docker Stacks are a set of ready-to-run [Docker images](https://quay.io/organization/jupyter) containing Jupyter applications and interactive computing tools.\nYou can use a stack image to do any of the following (and more):\n\n- Start a personal Jupyter Server with the JupyterLab frontend (default)\n- Run JupyterLab for a team using JupyterHub\n- Start a personal Jupyter Server with the Jupyter Notebook frontend in a local Docker container\n- Write your own project Dockerfile\n\n## Quick Start\n\nYou can [try a relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb).\nOtherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-started/get-docker/),\nknow [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.\n\nThe [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.\n\n```{note}\nSince `2023-10-20` our images are only pushed to `Quay.io` registry.\nOlder images are available on Docker Hub, but they will no longer be updated.\n```\n\n### Example 1\n\nThis command pulls the `jupyter/scipy-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.\nIt then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:\n\n```bash\ndocker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-12-23\n```\n\nYou can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.\n\nVisiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,\nwhere:\n\n- The `hostname` is the name of the computer running Docker\n- The `token` is the secret token printed in the console.\n\nThe container remains intact for restart after the Server exits.\n\n### Example 2\n\nThis command pulls the `jupyter/datascience-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.\nIt then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.\n\n```bash\ndocker run -it --rm -p 10000:8888 -v \"${PWD}\":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-12-23\n```\n\nThe use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.\nThe server logs appear in the terminal.\n\nVisiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab.\n\nDue to the usage of [the `--rm` flag](https://docs.docker.com/reference/cli/docker/container/run/#rm)\nDocker automatically cleans up the container and removes the file system when the container exits,\nbut any changes made to the `~/work` directory and its files in the container will remain intact on the host.\n[The `-i` flag](https://docs.docker.com/reference/cli/docker/container/run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.\n[The `-t` flag](https://docs.docker.com/reference/cli/docker/container/run/#tty) attaches a pseudo-TTY to the container.\n\n```{note}\nBy default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.\nSo, new notebooks will be saved there, unless you change the directory in the file browser.\n\nTo change the default directory, you must specify `ServerApp.root_dir` by adding this line to the previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.\n```\n\n## Choosing Jupyter frontend\n\nJupyterLab is the default for all the Jupyter Docker Stacks images.\nIt is still possible to switch back to Jupyter Notebook (or to launch a different startup command).\nYou can achieve this by passing the environment variable `DOCKER_STACKS_JUPYTER_CMD=notebook` (or any other valid `jupyter` subcommand) at container startup;\nmore information is available in the [documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#alternative-commands).\n\n## Resources\n\n- [Documentation on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)\n- [Issue Tracker on GitHub](https://github.com/jupyter/docker-stacks/issues)\n- [Jupyter Discourse Forum](https://discourse.jupyter.org/)\n- [Jupyter Website](https://jupyter.org)\n- [Images on Quay.io](https://quay.io/organization/jupyter)\n\n## Acknowledgments\n\n- Starting from `2022-07-05`, `aarch64` self-hosted runners were sponsored by [`@mathbunnyru`](https://github.com/mathbunnyru/).\n  Please, consider [sponsoring his work](https://github.com/sponsors/mathbunnyru) on GitHub\n- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by an amazing [`2i2c non-profit organization`](https://2i2c.org)\n\n## CPU Architectures\n\n- We publish containers for both `x86_64` and `aarch64` platforms\n- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`\n- Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)\n- Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well\n- Starting from `2024-02-24`, we create CUDA enabled variants of `pytorch-notebook` image for `x86_64` platform\n- Starting from `2024-03-26`, we create CUDA enabled variant of `tensorflow-notebook` image for `x86_64` platform\n\n## Using old images\n\nThis project only builds one set of images at a time.\nIf you want to use the older `Ubuntu` and/or `Python` version, you can use the following images:\n\n| Build Date   | Ubuntu | Python | Tag            |\n| ------------ | ------ | ------ | -------------- |\n| 2022-10-09   | 20.04  | 3.7    | `1aac87eb7fa5` |\n| 2022-10-09   | 20.04  | 3.8    | `a374cab4fcb6` |\n| 2022-10-09   | 20.04  | 3.9    | `5ae537728c69` |\n| 2022-10-09   | 20.04  | 3.10   | `f3079808ca8c` |\n| 2022-10-09   | 22.04  | 3.7    | `b86753318aa1` |\n| 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |\n| 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |\n| 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |\n| 2024-08-26   | 22.04  | 3.11   | `00987883e58d` |\n| 2024-10-22   | 24.04  | 3.11   | `b74418220768` |\n| weekly build | 24.04  | 3.12   | `latest`       |\n\n## Contributing\n\nPlease see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)\nfor information about how to contribute recipes, features, tests, and community-maintained stacks.\n\n## Alternatives\n\n- [rocker/binder](https://rocker-project.org/images/versioned/binder.html) -\n  From the R focused [rocker-project](https://rocker-project.org),\n  lets you run both RStudio and Jupyter either standalone or in a JupyterHub\n- [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -\n  Turn git repositories into Jupyter-enabled Docker Images\n- [openshift/source-to-image](https://github.com/openshift/source-to-image) -\n  A tool for building artifacts from source code and injecting them into docker images\n- [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -\n  OpenShift compatible S2I builder for basic notebook images\n"
        },
        {
          "name": "aarch64-runner",
          "type": "tree",
          "content": null
        },
        {
          "name": "binder",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "examples",
          "type": "tree",
          "content": null
        },
        {
          "name": "images",
          "type": "tree",
          "content": null
        },
        {
          "name": "mypy.ini",
          "type": "blob",
          "size": 1.0576171875,
          "content": "# Mypy is an optional static type checker for Python that aims to combine\n# the benefits of dynamic (or \"duck\") typing and static typing.\n#\n# Documentation: https://www.mypy-lang.org\n# Project: https://github.com/python/mypy\n# Config reference: https://mypy.readthedocs.io/en/stable/config_file.html\n#\n# We use mypy as part of pre-commit checks\n\n[mypy]\npython_version = 3.9\nfollow_imports = error\nstrict = True\nno_incremental = True\n# This allows us to use pytest decorators, which are not typed yet\ndisallow_untyped_decorators = False\n\n# These sections allow us to ignore mypy errors for packages\n# which are not (hopefully yet) statically typed\n\n[mypy-Cython.*]\nignore_missing_imports = True\n\n[mypy-docker.*]\nignore_missing_imports = True\n\n[mypy-matplotlib.*]\nignore_missing_imports = True\n\n[mypy-pandas.*]\nignore_missing_imports = True\n\n[mypy-plumbum.*]\nignore_missing_imports = True\n\n[mypy-pyspark.*]\nignore_missing_imports = True\n\n[mypy-setuptools.*]\nignore_missing_imports = True\n\n[mypy-tensorflow.*]\nignore_missing_imports = True\n\n[mypy-torch.*]\nignore_missing_imports = True\n"
        },
        {
          "name": "requirements-dev.txt",
          "type": "blob",
          "size": 0.2060546875,
          "content": "docker\nplumbum\npre-commit\npytest\npytest-retry\n# `pytest-xdist` is a plugin that provides the `--numprocesses` flag,\n# allowing us to run `pytest` tests in parallel\npytest-xdist\npython-dateutil\nrequests\ntabulate\n"
        },
        {
          "name": "tagging",
          "type": "tree",
          "content": null
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}