{
  "metadata": {
    "timestamp": 1736560500601,
    "page": 94,
    "hasNextPage": true,
    "endCursor": "Y3Vyc29yOjEwMA==",
    "completionStatus": "IN_PROGRESS"
  },
  "repositories": [
    {
      "nameWithOwner": "facebookresearch/pytorch3d",
      "stars": 8967,
      "defaultBranch": "main",
      "files": [
        {
          "name": ".circleci",
          "type": "tree",
          "content": null
        },
        {
          "name": ".clang-format",
          "type": "blob",
          "size": 2.484375,
          "content": "AccessModifierOffset: -1\nAlignAfterOpenBracket: AlwaysBreak\nAlignConsecutiveAssignments: false\nAlignConsecutiveDeclarations: false\nAlignEscapedNewlinesLeft: true\nAlignOperands:   false\nAlignTrailingComments: false\nAllowAllParametersOfDeclarationOnNextLine: false\nAllowShortBlocksOnASingleLine: false\nAllowShortCaseLabelsOnASingleLine: false\nAllowShortFunctionsOnASingleLine: Empty\nAllowShortIfStatementsOnASingleLine: false\nAllowShortLoopsOnASingleLine: false\nAlwaysBreakAfterReturnType: None\nAlwaysBreakBeforeMultilineStrings: true\nAlwaysBreakTemplateDeclarations: true\nBinPackArguments: false\nBinPackParameters: false\nBraceWrapping:\n  AfterClass:      false\n  AfterControlStatement: false\n  AfterEnum:       false\n  AfterFunction:   false\n  AfterNamespace:  false\n  AfterObjCDeclaration: false\n  AfterStruct:     false\n  AfterUnion:      false\n  BeforeCatch:     false\n  BeforeElse:      false\n  IndentBraces:    false\nBreakBeforeBinaryOperators: None\nBreakBeforeBraces: Attach\nBreakBeforeTernaryOperators: true\nBreakConstructorInitializersBeforeComma: false\nBreakAfterJavaFieldAnnotations: false\nBreakStringLiterals: false\nColumnLimit:     80\nCommentPragmas:  '^ IWYU pragma:'\nConstructorInitializerAllOnOneLineOrOnePerLine: true\nConstructorInitializerIndentWidth: 4\nContinuationIndentWidth: 4\nCpp11BracedListStyle: true\nDerivePointerAlignment: false\nDisableFormat:   false\nForEachMacros:   [ FOR_EACH, FOR_EACH_R, FOR_EACH_RANGE, ]\nIncludeCategories:\n  - Regex:           '^<.*\\.h(pp)?>'\n    Priority:        1\n  - Regex:           '^<.*'\n    Priority:        2\n  - Regex:           '.*'\n    Priority:        3\nIndentCaseLabels: true\nIndentWidth:     2\nIndentWrappedFunctionNames: false\nKeepEmptyLinesAtTheStartOfBlocks: false\nMacroBlockBegin: ''\nMacroBlockEnd:   ''\nMaxEmptyLinesToKeep: 1\nNamespaceIndentation: None\nObjCBlockIndentWidth: 2\nObjCSpaceAfterProperty: false\nObjCSpaceBeforeProtocolList: false\nPenaltyBreakBeforeFirstCallParameter: 1\nPenaltyBreakComment: 300\nPenaltyBreakFirstLessLess: 120\nPenaltyBreakString: 1000\nPenaltyExcessCharacter: 1000000\nPenaltyReturnTypeOnItsOwnLine: 200\nPointerAlignment: Left\nReflowComments:  true\nSortIncludes:    true\nSpaceAfterCStyleCast: false\nSpaceBeforeAssignmentOperators: true\nSpaceBeforeParens: ControlStatements\nSpaceInEmptyParentheses: false\nSpacesBeforeTrailingComments: 1\nSpacesInAngles:  false\nSpacesInContainerLiterals: true\nSpacesInCStyleCastParentheses: false\nSpacesInParentheses: false\nSpacesInSquareBrackets: false\nStandard:        Cpp11\nTabWidth:        8\nUseTab:          Never\n"
        },
        {
          "name": ".flake8",
          "type": "blob",
          "size": 0.3408203125,
          "content": "[flake8]\n# B028 No explicit stacklevel argument found.\n# B907 'foo' is manually surrounded by quotes, consider using the `!r` conversion flag.\n# B905 `zip()` without an explicit `strict=` parameter.\nignore = E203, E266, E501, W503, E221, B028, B905, B907\nmax-line-length = 88\nmax-complexity = 18\nselect = B,C,E,F,W,T4,B9\nexclude = build,__init__.py\n"
        },
        {
          "name": ".github",
          "type": "tree",
          "content": null
        },
        {
          "name": ".gitignore",
          "type": "blob",
          "size": 0.3408203125,
          "content": "build/\ndist/\n*.egg-info/\n**/__pycache__/\n*-checkpoint.ipynb\n**/.ipynb_checkpoints\n**/.ipynb_checkpoints/**\n\n\n# Docusaurus site\nwebsite/yarn.lock\nwebsite/build/\nwebsite/i18n/\nwebsite/node_modules/*\nwebsite/npm-debug.log\n\n## Generated for tutorials\nwebsite/_tutorials/\nwebsite/static/files/\nwebsite/pages/tutorials/*\n!website/pages/tutorials/index.js\n"
        },
        {
          "name": "INSTALL.md",
          "type": "blob",
          "size": 5.578125,
          "content": "# Installation\n\n\n## Requirements\n\n### Core library\n\nThe core library is written in PyTorch. Several components have underlying implementation in CUDA for improved performance. A subset of these components have CPU implementations in C++/PyTorch. It is advised to use PyTorch3D with GPU support in order to use all the features.\n\n- Linux or macOS or Windows\n- Python\n- PyTorch 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0 or 2.4.1.\n- torchvision that matches the PyTorch installation. You can install them together as explained at pytorch.org to make sure of this.\n- gcc & g++ ≥ 4.9\n- [ioPath](https://github.com/facebookresearch/iopath)\n- If CUDA is to be used, use a version which is supported by the corresponding pytorch version and at least version 9.2.\n- If CUDA older than 11.7 is to be used and you are building from source, the CUB library must be available. We recommend version 1.10.0.\n\nThe runtime dependencies can be installed by running:\n```\nconda create -n pytorch3d python=3.9\nconda activate pytorch3d\nconda install pytorch=1.13.0 torchvision pytorch-cuda=11.6 -c pytorch -c nvidia\nconda install -c iopath iopath\n```\n\nFor the CUB build time dependency, which you only need if you have CUDA older than 11.7, if you are using conda, you can continue with\n```\nconda install -c bottler nvidiacub\n```\nOtherwise download the CUB library from https://github.com/NVIDIA/cub/releases and unpack it to a folder of your choice.\nDefine the environment variable CUB_HOME before building and point it to the directory that contains `CMakeLists.txt` for CUB.\nFor example on Linux/Mac,\n```\ncurl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\ntar xzf 1.10.0.tar.gz\nexport CUB_HOME=$PWD/cub-1.10.0\n```\n\n### Tests/Linting and Demos\n\nFor developing on top of PyTorch3D or contributing, you will need to run the linter and tests. If you want to run any of the notebook tutorials as `docs/tutorials` or the examples in `docs/examples` you will also need matplotlib and OpenCV.\n- scikit-image\n- black\n- usort\n- flake8\n- matplotlib\n- tdqm\n- jupyter\n- imageio\n- fvcore\n- plotly\n- opencv-python\n\nThese can be installed by running:\n```\n# Demos and examples\nconda install jupyter\npip install scikit-image matplotlib imageio plotly opencv-python\n\n# Tests/Linting\nconda install -c fvcore -c conda-forge fvcore\npip install black usort flake8 flake8-bugbear flake8-comprehensions\n```\n\n## Installing prebuilt binaries for PyTorch3D\nAfter installing the above dependencies, run one of the following commands:\n\n### 1. Install with CUDA support from Anaconda Cloud, on Linux only\n\n```\n# Anaconda Cloud\nconda install pytorch3d -c pytorch3d\n```\n\nOr, to install a nightly (non-official, alpha) build:\n```\n# Anaconda Cloud\nconda install pytorch3d -c pytorch3d-nightly\n```\n\n### 2. Install wheels for Linux\nWe have prebuilt wheels with CUDA for Linux for PyTorch 1.11.0, for each of the supported CUDA versions,\nfor Python 3.8 and 3.9. This is for ease of use on Google Colab.\nThese are installed in a special way.\nFor example, to install for Python 3.8, PyTorch 1.11.0 and CUDA 11.3\n```\npip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu113_pyt1110/download.html\n```\n\nIn general, from inside IPython, or in Google Colab or a jupyter notebook, you can install with\n```\nimport sys\nimport torch\npyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\nversion_str=\"\".join([\n    f\"py3{sys.version_info.minor}_cu\",\n    torch.version.cuda.replace(\".\",\"\"),\n    f\"_pyt{pyt_version_str}\"\n])\n!pip install iopath\n!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n```\n\n## Building / installing from source.\nCUDA support will be included if CUDA is available in pytorch or if the environment variable\n`FORCE_CUDA` is set to `1`.\n\n### 1. Install from GitHub\n```\npip install \"git+https://github.com/facebookresearch/pytorch3d.git\"\n```\nTo install using the code of the released version instead of from the main branch, use the following instead.\n```\npip install \"git+https://github.com/facebookresearch/pytorch3d.git@stable\"\n```\n\nFor CUDA builds with versions earlier than CUDA 11, set `CUB_HOME` before building as described above.\n\n**Install from Github on macOS:**\nSome environment variables should be provided, like this.\n```\nMACOSX_DEPLOYMENT_TARGET=10.14 CC=clang CXX=clang++ pip install \"git+https://github.com/facebookresearch/pytorch3d.git\"\n```\n\n### 2. Install from a local clone\n```\ngit clone https://github.com/facebookresearch/pytorch3d.git\ncd pytorch3d && pip install -e .\n```\nTo rebuild after installing from a local clone run, `rm -rf build/ **/*.so` then `pip install -e .`. You often need to rebuild pytorch3d after reinstalling PyTorch. For CUDA builds with versions earlier than CUDA 11, set `CUB_HOME` before building as described above.\n\n**Install from local clone on macOS:**\n```\nMACOSX_DEPLOYMENT_TARGET=10.14 CC=clang CXX=clang++ pip install -e .\n```\n\n**Install from local clone on Windows:**\n\nDepending on the version of PyTorch, changes to some PyTorch headers may be needed before compilation. These are often discussed in issues in this repository.\n\nAfter any necessary patching, you can go to \"x64 Native Tools Command Prompt for VS 2019\" to compile and install\n```\ncd pytorch3d\npython3 setup.py install\n```\n\nAfter installing, you can run **unit tests**\n```\npython3 -m unittest discover -v -s tests -t .\n```\n\n# FAQ\n\n### Can I use Docker?\n\nWe don't provide a docker file but see [#113](https://github.com/facebookresearch/pytorch3d/issues/113) for a docker file shared by a user (NOTE: this has not been tested by the PyTorch3D team).\n"
        },
        {
          "name": "LICENSE",
          "type": "blob",
          "size": 1.498046875,
          "content": "BSD License\n\nFor PyTorch3D software\n\nCopyright (c) Meta Platforms, Inc. and affiliates. All rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification,\nare permitted provided that the following conditions are met:\n\n * Redistributions of source code must retain the above copyright notice, this\n   list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above copyright notice,\n   this list of conditions and the following disclaimer in the documentation\n   and/or other materials provided with the distribution.\n\n * Neither the name Meta nor the names of its contributors may be used to\n   endorse or promote products derived from this software without specific\n   prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\nANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\nANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\nLOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\nANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\nSOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n"
        },
        {
          "name": "LICENSE-3RD-PARTY",
          "type": "blob",
          "size": 3.2724609375,
          "content": "SRN license ( https://github.com/vsitzmann/scene-representation-networks/ ):\n\nMIT License\n\nCopyright (c) 2019 Vincent Sitzmann\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\nIDR license ( github.com/lioryariv/idr ):\n\nMIT License\n\nCopyright (c) 2020 Lior Yariv\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\nNeRF https://github.com/bmild/nerf/\n\nCopyright (c) 2020 bmild\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n"
        },
        {
          "name": "README.md",
          "type": "blob",
          "size": 11.154296875,
          "content": "<img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/pytorch3dlogo.png\" width=\"900\"/>\n\n[![CircleCI](https://circleci.com/gh/facebookresearch/pytorch3d.svg?style=svg)](https://circleci.com/gh/facebookresearch/pytorch3d)\n[![Anaconda-Server Badge](https://anaconda.org/pytorch3d/pytorch3d/badges/version.svg)](https://anaconda.org/pytorch3d/pytorch3d)\n\n# Introduction\n\nPyTorch3D provides efficient, reusable components for 3D Computer Vision research with [PyTorch](https://pytorch.org).\n\nKey features include:\n\n- Data structure for storing and manipulating triangle meshes\n- Efficient operations on triangle meshes (projective transformations, graph convolution, sampling, loss functions)\n- A differentiable mesh renderer\n- Implicitron, see [its README](projects/implicitron_trainer), a framework for new-view synthesis via implicit representations. ([blog post](https://ai.facebook.com/blog/implicitron-a-new-modular-extensible-framework-for-neural-implicit-representations-in-pytorch3d/))\n\nPyTorch3D is designed to integrate smoothly with deep learning methods for predicting and manipulating 3D data.\nFor this reason, all operators in PyTorch3D:\n\n- Are implemented using PyTorch tensors\n- Can handle minibatches of hetereogenous data\n- Can be differentiated\n- Can utilize GPUs for acceleration\n\nWithin FAIR, PyTorch3D has been used to power research projects such as [Mesh R-CNN](https://arxiv.org/abs/1906.02739).\n\nSee our [blog post](https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/) to see more demos and learn about PyTorch3D.\n\n## Installation\n\nFor detailed instructions refer to [INSTALL.md](INSTALL.md).\n\n## License\n\nPyTorch3D is released under the [BSD License](LICENSE).\n\n## Tutorials\n\nGet started with PyTorch3D by trying one of the tutorial notebooks.\n\n|<img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/dolphin_deform.gif\" width=\"310\"/>|<img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/bundle_adjust.gif\" width=\"310\"/>|\n|:-----------------------------------------------------------------------------------------------------------:|:--------------------------------------------------:|\n| [Deform a sphere mesh to dolphin](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/deform_source_mesh_to_target_mesh.ipynb)| [Bundle adjustment](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/bundle_adjustment.ipynb) |\n\n| <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/render_textured_mesh.gif\" width=\"310\"/> | <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/camera_position_teapot.gif\" width=\"310\" height=\"310\"/>\n|:------------------------------------------------------------:|:--------------------------------------------------:|\n| [Render textured meshes](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/render_textured_meshes.ipynb)| [Camera position optimization](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/camera_position_optimization_with_differentiable_rendering.ipynb)|\n\n| <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/pointcloud_render.png\" width=\"310\"/> | <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/cow_deform.gif\" width=\"310\" height=\"310\"/>\n|:------------------------------------------------------------:|:--------------------------------------------------:|\n| [Render textured pointclouds](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/render_colored_points.ipynb)| [Fit a mesh with texture](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/fit_textured_mesh.ipynb)|\n\n| <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/densepose_render.png\" width=\"310\"/> | <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/shapenet_render.png\" width=\"310\" height=\"310\"/>\n|:------------------------------------------------------------:|:--------------------------------------------------:|\n| [Render DensePose data](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/render_densepose.ipynb)| [Load & Render ShapeNet data](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/dataloaders_ShapeNetCore_R2N2.ipynb)|\n\n| <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/fit_textured_volume.gif\" width=\"310\"/> | <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/fit_nerf.gif\" width=\"310\" height=\"310\"/>\n|:------------------------------------------------------------:|:--------------------------------------------------:|\n| [Fit Textured Volume](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/fit_textured_volume.ipynb)| [Fit A Simple Neural Radiance Field](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/fit_simple_neural_radiance_field.ipynb)|\n\n| <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/fit_textured_volume.gif\" width=\"310\"/> | <img src=\"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/.github/implicitron_config.gif\" width=\"310\" height=\"310\"/>\n|:------------------------------------------------------------:|:--------------------------------------------------:|\n| [Fit Textured Volume in Implicitron](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/implicitron_volumes.ipynb)| [Implicitron Config System](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/implicitron_config_system.ipynb)|\n\n\n\n\n\n## Documentation\n\nLearn more about the API by reading the PyTorch3D [documentation](https://pytorch3d.readthedocs.org/).\n\nWe also have deep dive notes on several API components:\n\n- [Heterogeneous Batching](https://github.com/facebookresearch/pytorch3d/tree/main/docs/notes/batching.md)\n- [Mesh IO](https://github.com/facebookresearch/pytorch3d/tree/main/docs/notes/meshes_io.md)\n- [Differentiable Rendering](https://github.com/facebookresearch/pytorch3d/tree/main/docs/notes/renderer_getting_started.md)\n\n### Overview Video\n\nWe have created a short (~14 min) video tutorial providing an overview of the PyTorch3D codebase including several code examples. Click on the image below to watch the video on YouTube:\n\n<a href=\"http://www.youtube.com/watch?v=Pph1r-x9nyY\"><img src=\"http://img.youtube.com/vi/Pph1r-x9nyY/0.jpg\" height=\"225\" ></a>\n\n## Development\n\nWe welcome new contributions to PyTorch3D and we will be actively maintaining this library! Please refer to [CONTRIBUTING.md](./.github/CONTRIBUTING.md) for full instructions on how to run the code, tests and linter, and submit your pull requests.\n\n## Development and Compatibility\n\n- `main` branch: actively developed, without any guarantee, Anything can be broken at any time\n  - REMARK: this includes nightly builds which are built from `main`\n  - HINT: the commit history can help locate regressions or changes\n- backward-compatibility between releases: no guarantee. Best efforts to communicate breaking changes and facilitate migration of code or data (incl. models).\n\n## Contributors\n\nPyTorch3D is written and maintained by the Facebook AI Research Computer Vision Team.\n\nIn alphabetical order:\n\n* Amitav Baruah\n* Steve Branson\n* Krzysztof Chalupka\n* Jiali Duan\n* Luya Gao\n* Georgia Gkioxari\n* Taylor Gordon\n* Justin Johnson\n* Patrick Labatut\n* Christoph Lassner\n* Wan-Yen Lo\n* David Novotny\n* Nikhila Ravi\n* Jeremy Reizenstein\n* Dave Schnizlein\n* Roman Shapovalov\n* Olivia Wiles\n\n## Citation\n\nIf you find PyTorch3D useful in your research, please cite our tech report:\n\n```bibtex\n@article{ravi2020pytorch3d,\n    author = {Nikhila Ravi and Jeremy Reizenstein and David Novotny and Taylor Gordon\n                  and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},\n    title = {Accelerating 3D Deep Learning with PyTorch3D},\n    journal = {arXiv:2007.08501},\n    year = {2020},\n}\n```\n\nIf you are using the pulsar backend for sphere-rendering (the `PulsarPointRenderer` or `pytorch3d.renderer.points.pulsar.Renderer`), please cite the tech report:\n\n```bibtex\n@article{lassner2020pulsar,\n    author = {Christoph Lassner and Michael Zollh\\\"ofer},\n    title = {Pulsar: Efficient Sphere-based Neural Rendering},\n    journal = {arXiv:2004.07484},\n    year = {2020},\n}\n```\n\n## News\n\nPlease see below for a timeline of the codebase updates in reverse chronological order. We are sharing updates on the releases as well as research projects which are built with PyTorch3D. The changelogs for the releases are available under [`Releases`](https://github.com/facebookresearch/pytorch3d/releases),  and the builds can be installed using `conda` as per the instructions in [INSTALL.md](INSTALL.md).\n\n**[Oct 31st 2023]:**   PyTorch3D [v0.7.5](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.5) released.\n\n**[May 10th 2023]:**   PyTorch3D [v0.7.4](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.4) released.\n\n**[Apr 5th 2023]:**   PyTorch3D [v0.7.3](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.3) released.\n\n**[Dec 19th 2022]:**   PyTorch3D [v0.7.2](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.2) released.\n\n**[Oct 23rd 2022]:**   PyTorch3D [v0.7.1](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.1) released.\n\n**[Aug 10th 2022]:**   PyTorch3D [v0.7.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.7.0) released with Implicitron and MeshRasterizerOpenGL.\n\n**[Apr 28th 2022]:**   PyTorch3D [v0.6.2](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.6.2) released\n\n**[Dec 16th 2021]:**   PyTorch3D [v0.6.1](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.6.1) released\n\n**[Oct 6th 2021]:**   PyTorch3D [v0.6.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.6.0) released\n\n**[Aug 5th 2021]:**   PyTorch3D [v0.5.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.5.0) released\n\n**[Feb 9th 2021]:** PyTorch3D [v0.4.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.4.0) released with support for implicit functions, volume rendering and a [reimplementation of NeRF](https://github.com/facebookresearch/pytorch3d/tree/main/projects/nerf).\n\n**[November 2nd 2020]:** PyTorch3D [v0.3.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.3.0) released, integrating the pulsar backend.\n\n**[Aug 28th 2020]:**   PyTorch3D [v0.2.5](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.2.5) released\n\n**[July 17th 2020]:**   PyTorch3D tech report published on ArXiv: https://arxiv.org/abs/2007.08501\n\n**[April 24th 2020]:**   PyTorch3D [v0.2.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.2.0) released\n\n**[March 25th 2020]:**   [SynSin](https://arxiv.org/abs/1912.08804) codebase released using PyTorch3D: https://github.com/facebookresearch/synsin\n\n**[March 8th 2020]:**   PyTorch3D [v0.1.1](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.1.1) bug fix release\n\n**[Jan 23rd 2020]:**   PyTorch3D [v0.1.0](https://github.com/facebookresearch/pytorch3d/releases/tag/v0.1.0) released. [Mesh R-CNN](https://arxiv.org/abs/1906.02739) codebase released: https://github.com/facebookresearch/meshrcnn\n"
        },
        {
          "name": "dev",
          "type": "tree",
          "content": null
        },
        {
          "name": "docs",
          "type": "tree",
          "content": null
        },
        {
          "name": "packaging",
          "type": "tree",
          "content": null
        },
        {
          "name": "projects",
          "type": "tree",
          "content": null
        },
        {
          "name": "pytorch3d",
          "type": "tree",
          "content": null
        },
        {
          "name": "scripts",
          "type": "tree",
          "content": null
        },
        {
          "name": "setup.cfg",
          "type": "blob",
          "size": 0.3759765625,
          "content": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\n[isort]\nline_length = 88\nmulti_line_output = 3\ninclude_trailing_comma = True\nforce_grid_warp = 0\ndefault_section = THIRDPARTY\nlines_after_imports = 2\ncombine_as_imports = True\n"
        },
        {
          "name": "setup.py",
          "type": "blob",
          "size": 6.224609375,
          "content": "#!/usr/bin/env python\n# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the BSD-style license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport glob\nimport os\nimport runpy\nimport sys\nimport warnings\nfrom typing import List, Optional\n\nimport torch\nfrom setuptools import find_packages, setup\nfrom torch.utils.cpp_extension import CppExtension, CUDA_HOME, CUDAExtension\n\n\ndef get_existing_ccbin(nvcc_args: List[str]) -> Optional[str]:\n    \"\"\"\n    Given a list of nvcc arguments, return the compiler if specified.\n\n    Note from CUDA doc: Single value options and list options must have\n    arguments, which must follow the name of the option itself by either\n    one of more spaces or an equals character.\n    \"\"\"\n    last_arg = None\n    for arg in reversed(nvcc_args):\n        if arg == \"-ccbin\":\n            return last_arg\n        if arg.startswith(\"-ccbin=\"):\n            return arg[7:]\n        last_arg = arg\n    return None\n\n\ndef get_extensions():\n    no_extension = os.getenv(\"PYTORCH3D_NO_EXTENSION\", \"0\") == \"1\"\n    if no_extension:\n        msg = \"SKIPPING EXTENSION BUILD. PYTORCH3D WILL NOT WORK!\"\n        print(msg, file=sys.stderr)\n        warnings.warn(msg)\n        return []\n\n    this_dir = os.path.dirname(os.path.abspath(__file__))\n    extensions_dir = os.path.join(this_dir, \"pytorch3d\", \"csrc\")\n    sources = glob.glob(os.path.join(extensions_dir, \"**\", \"*.cpp\"), recursive=True)\n    source_cuda = glob.glob(os.path.join(extensions_dir, \"**\", \"*.cu\"), recursive=True)\n    extension = CppExtension\n\n    extra_compile_args = {\"cxx\": [\"-std=c++17\"]}\n    define_macros = []\n    include_dirs = [extensions_dir]\n\n    force_cuda = os.getenv(\"FORCE_CUDA\", \"0\") == \"1\"\n    force_no_cuda = os.getenv(\"PYTORCH3D_FORCE_NO_CUDA\", \"0\") == \"1\"\n    if (\n        not force_no_cuda and torch.cuda.is_available() and CUDA_HOME is not None\n    ) or force_cuda:\n        extension = CUDAExtension\n        sources += source_cuda\n        define_macros += [(\"WITH_CUDA\", None)]\n        # Thrust is only used for its tuple objects.\n        # With CUDA 11.0 we can't use the cudatoolkit's version of cub.\n        # We take the risk that CUB and Thrust are incompatible, because\n        # we aren't using parts of Thrust which actually use CUB.\n        define_macros += [(\"THRUST_IGNORE_CUB_VERSION_CHECK\", None)]\n        cub_home = os.environ.get(\"CUB_HOME\", None)\n        nvcc_args = [\n            \"-DCUDA_HAS_FP16=1\",\n            \"-D__CUDA_NO_HALF_OPERATORS__\",\n            \"-D__CUDA_NO_HALF_CONVERSIONS__\",\n            \"-D__CUDA_NO_HALF2_OPERATORS__\",\n        ]\n        if os.name != \"nt\":\n            nvcc_args.append(\"-std=c++17\")\n        if cub_home is None:\n            prefix = os.environ.get(\"CONDA_PREFIX\", None)\n            if prefix is not None and os.path.isdir(prefix + \"/include/cub\"):\n                cub_home = prefix + \"/include\"\n\n        if cub_home is None:\n            warnings.warn(\n                \"The environment variable `CUB_HOME` was not found. \"\n                \"NVIDIA CUB is required for compilation and can be downloaded \"\n                \"from `https://github.com/NVIDIA/cub/releases`. You can unpack \"\n                \"it to a location of your choice and set the environment variable \"\n                \"`CUB_HOME` to the folder containing the `CMakeListst.txt` file.\"\n            )\n        else:\n            include_dirs.append(os.path.realpath(cub_home).replace(\"\\\\ \", \" \"))\n        nvcc_flags_env = os.getenv(\"NVCC_FLAGS\", \"\")\n        if nvcc_flags_env != \"\":\n            nvcc_args.extend(nvcc_flags_env.split(\" \"))\n\n        # This is needed for pytorch 1.6 and earlier. See e.g.\n        # https://github.com/facebookresearch/pytorch3d/issues/436\n        # It is harmless after https://github.com/pytorch/pytorch/pull/47404 .\n        # But it can be problematic in torch 1.7.0 and 1.7.1\n        if torch.__version__[:4] != \"1.7.\":\n            CC = os.environ.get(\"CC\", None)\n            if CC is not None:\n                existing_CC = get_existing_ccbin(nvcc_args)\n                if existing_CC is None:\n                    CC_arg = \"-ccbin={}\".format(CC)\n                    nvcc_args.append(CC_arg)\n                elif existing_CC != CC:\n                    msg = f\"Inconsistent ccbins: {CC} and {existing_CC}\"\n                    raise ValueError(msg)\n\n        extra_compile_args[\"nvcc\"] = nvcc_args\n\n    sources = [os.path.join(extensions_dir, s) for s in sources]\n\n    ext_modules = [\n        extension(\n            \"pytorch3d._C\",\n            sources,\n            include_dirs=include_dirs,\n            define_macros=define_macros,\n            extra_compile_args=extra_compile_args,\n        )\n    ]\n\n    return ext_modules\n\n\n# Retrieve __version__ from the package.\n__version__ = runpy.run_path(\"pytorch3d/__init__.py\")[\"__version__\"]\n\n\nif os.getenv(\"PYTORCH3D_NO_NINJA\", \"0\") == \"1\":\n\n    class BuildExtension(torch.utils.cpp_extension.BuildExtension):\n        def __init__(self, *args, **kwargs):\n            super().__init__(use_ninja=False, *args, **kwargs)\n\nelse:\n    BuildExtension = torch.utils.cpp_extension.BuildExtension\n\ntrainer = \"pytorch3d.implicitron_trainer\"\n\nsetup(\n    name=\"pytorch3d\",\n    version=__version__,\n    author=\"FAIR\",\n    url=\"https://github.com/facebookresearch/pytorch3d\",\n    description=\"PyTorch3D is FAIR's library of reusable components \"\n    \"for deep Learning with 3D data.\",\n    packages=find_packages(\n        exclude=(\"configs\", \"tests\", \"tests.*\", \"docs.*\", \"projects.*\")\n    )\n    + [trainer],\n    package_dir={trainer: \"projects/implicitron_trainer\"},\n    install_requires=[\"iopath\"],\n    extras_require={\n        \"all\": [\"matplotlib\", \"tqdm>4.29.0\", \"imageio\", \"ipywidgets\"],\n        \"dev\": [\"flake8\", \"usort\"],\n        \"implicitron\": [\n            \"hydra-core>=1.1\",\n            \"visdom\",\n            \"lpips\",\n            \"tqdm>4.29.0\",\n            \"matplotlib\",\n            \"accelerate\",\n            \"sqlalchemy>=2.0\",\n        ],\n    },\n    entry_points={\n        \"console_scripts\": [\n            f\"pytorch3d_implicitron_runner={trainer}.experiment:experiment\",\n            f\"pytorch3d_implicitron_visualizer={trainer}.visualize_reconstruction:main\",\n        ]\n    },\n    ext_modules=get_extensions(),\n    cmdclass={\"build_ext\": BuildExtension},\n    package_data={\n        \"\": [\"*.json\"],\n    },\n)\n"
        },
        {
          "name": "tests",
          "type": "tree",
          "content": null
        },
        {
          "name": "website",
          "type": "tree",
          "content": null
        }
      ]
    }
  ]
}